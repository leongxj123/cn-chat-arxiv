<rss version="2.0"><channel><title>Chat Arxiv cs.SC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SC</description><item><title>&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#65292;&#23454;&#39564;&#32467;&#26524;&#26377;&#21161;&#20110;&#25552;&#20986;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;</title><link>https://arxiv.org/abs/2403.11793</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65306;&#23545;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#30340;&#28145;&#20837;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11793
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#65292;&#23454;&#39564;&#32467;&#26524;&#26377;&#21161;&#20110;&#25552;&#20986;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25512;&#29702;&#33021;&#21147;&#30340;&#29616;&#26377;&#26041;&#27861;&#20197;&#32467;&#26524;&#20026;&#20013;&#24515;&#65292;&#20351;&#24471;&#35780;&#20272;&#25512;&#29702;&#36807;&#31243;&#21464;&#24471;&#22256;&#38590;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#20197;&#36807;&#31243;&#20026;&#20013;&#24515;&#30340;&#26041;&#24335;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#12290;ARC&#35201;&#27714;&#35299;&#20915;&#38382;&#39064;&#26102;&#20855;&#26377;&#20005;&#35880;&#30340;&#36923;&#36753;&#32467;&#26500;&#65292;&#36825;&#20351;&#24471;&#23427;&#25104;&#20026;&#19968;&#20010;&#33021;&#22815;&#20419;&#36827;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#19982;&#20154;&#31867;&#36827;&#34892;&#27604;&#36739;&#30340;&#22522;&#20934;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#65292;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#31361;&#26174;&#20102;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11793v1 Announce Type: cross  Abstract: The existing methods for evaluating the inference abilities of Large Language Models (LLMs) have been results-centric, making it difficult to assess the inference process. We introduce a new approach using the Abstract and Reasoning Corpus (ARC) dataset to evaluate the inference and contextual understanding abilities of large language models in a process-centric manner. ARC demands rigorous logical structures for problem-solving, making it a benchmark that facilitates the comparison of model inference abilities with humans. Experimental results confirm that while large language models possess weak inference abilities, they still lag in terms of logical coherence, compositionality, and productivity. Our experiments highlight the reasoning capabilities of LLMs, proposing development paths for achieving human-level reasoning.
&lt;/p&gt;</description></item></channel></rss>