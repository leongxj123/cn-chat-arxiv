<rss version="2.0"><channel><title>Chat Arxiv cs.SC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SC</description><item><title>SymbolicAI&#26159;&#19968;&#20010;&#22522;&#20110;&#36923;&#36753;&#30340;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#27169;&#22411;&#19982;&#22810;&#31181;&#27714;&#35299;&#22120;&#26080;&#32541;&#38598;&#25104;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#35821;&#20041;&#35299;&#26512;&#22120;&#65292;&#23454;&#29616;&#20102;&#31526;&#21495;&#25512;&#29702;&#19982;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#34701;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.00854</link><description>&lt;p&gt;
SymbolicAI: &#19968;&#20010;&#32467;&#21512;&#29983;&#25104;&#27169;&#22411;&#21644;&#27714;&#35299;&#22120;&#30340;&#22522;&#20110;&#36923;&#36753;&#30340;&#26041;&#27861;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
SymbolicAI: A framework for logic-based approaches combining generative models and solvers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00854
&lt;/p&gt;
&lt;p&gt;
SymbolicAI&#26159;&#19968;&#20010;&#22522;&#20110;&#36923;&#36753;&#30340;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#27169;&#22411;&#19982;&#22810;&#31181;&#27714;&#35299;&#22120;&#26080;&#32541;&#38598;&#25104;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#35821;&#20041;&#35299;&#26512;&#22120;&#65292;&#23454;&#29616;&#20102;&#31526;&#21495;&#25512;&#29702;&#19982;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#34701;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;SymbolicAI&#65292;&#36825;&#26159;&#19968;&#20010;&#22810;&#21151;&#33021;&#19988;&#27169;&#22359;&#21270;&#30340;&#26694;&#26550;&#65292;&#37319;&#29992;&#22522;&#20110;&#36923;&#36753;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#27010;&#24565;&#23398;&#20064;&#21644;&#27969;&#31243;&#31649;&#29702;&#12290;SymbolicAI&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20316;&#20026;&#35821;&#20041;&#35299;&#26512;&#22120;&#26469;&#25191;&#34892;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#21644;&#24418;&#24335;&#35821;&#35328;&#25351;&#20196;&#30340;&#20219;&#21153;&#65292;&#20174;&#32780;&#24357;&#21512;&#20102;&#31526;&#21495;&#25512;&#29702;&#21644;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#20351;&#29983;&#25104;&#27169;&#22411;&#19982;&#21508;&#31181;&#27714;&#35299;&#22120;&#26080;&#32541;&#38598;&#25104;&#12290;&#25105;&#20204;&#21033;&#29992;&#27010;&#29575;&#32534;&#31243;&#21407;&#29702;&#26469;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#65292;&#24182;&#21033;&#29992;&#21487;&#24494;&#20998;&#21644;&#32463;&#20856;&#32534;&#31243;&#33539; paradigms &#30340;&#21508;&#33258;&#20248;&#21183;&#12290;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#22810;&#24577;&#30340;&#12289;&#32452;&#21512;&#30340;&#21644;&#33258;&#25351;&#30340;&#25968;&#25454;&#27969;&#25805;&#20316;&#65292;&#23558;LLM&#30340;&#36755;&#20986;&#19982;&#29992;&#25143;&#30340;&#30446;&#26631;&#23545;&#40784;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#20855;&#26377;&#38646;&#27425;&#21644;&#23569;&#27425;&#23398;&#20064;&#33021;&#21147;&#30340;&#21508;&#31181;&#22522;&#30784;&#27169;&#22411;&#20043;&#38388;&#36827;&#34892;&#36807;&#28193;&#65292;&#24182;&#19982;&#25797;&#38271;&#35299;&#20915;&#29305;&#23450;&#38382;&#39064;&#30340;&#19987;&#19994;&#21270;&#35843;&#20248;&#27169;&#22411;&#25110;&#27714;&#35299;&#22120;&#37197;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce SymbolicAI, a versatile and modular framework employing a logic-based approach to concept learning and flow management in generative processes. SymbolicAI enables the seamless integration of generative models with a diverse range of solvers by treating large language models (LLMs) as semantic parsers that execute tasks based on both natural and formal language instructions, thus bridging the gap between symbolic reasoning and generative AI. We leverage probabilistic programming principles to tackle complex tasks, and utilize differentiable and classical programming paradigms with their respective strengths. The framework introduces a set of polymorphic, compositional, and self-referential operations for data stream manipulation, aligning LLM outputs with user objectives. As a result, we can transition between the capabilities of various foundation models endowed with zero- and few-shot learning capabilities and specialized, fine-tuned models or solvers proficient in addres
&lt;/p&gt;</description></item></channel></rss>