# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario](https://arxiv.org/abs/2403.00108) | LoRA作为攻击者渗透LLM安全，研究探讨了在共享与玩耍场景下可能实现的攻击机会。 |

# 详细

[^1]: 将LoRA作为攻击！在Share-and-Play场景下穿透LLM安全

    LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario

    [https://arxiv.org/abs/2403.00108](https://arxiv.org/abs/2403.00108)

    LoRA作为攻击者渗透LLM安全，研究探讨了在共享与玩耍场景下可能实现的攻击机会。

    

    对LLMs进行微调对于增强其特定任务的性能并确保模型行为与人类偏好保持一致至关重要。在各种微调方法中，LoRA因其效率和易用性而备受推崇，允许最终用户轻松在开源平台上发布和采用轻量的LoRA模块，以定制其模型以适应不同需求。然而，这种方便的共享与玩耍设置打开了新的攻击面，攻击者可以将LoRA作为攻击者，例如背门注入，并广泛分发对抗性LoRA给社区。这可能导致不利的后果。尽管共享LoRA模块存在巨大的潜在风险，但这一方面尚未得到充分探讨。为了填补这一空白，在本研究中，我们深入探讨了在不断增长的共享与玩耍场景中可能做出的攻击机会。具体而言，我们研究了如何将后门注入LoRA模块并深入探讨。

    arXiv:2403.00108v1 Announce Type: cross  Abstract: Fine-tuning LLMs is crucial to enhancing their task-specific performance and ensuring model behaviors are aligned with human preferences. Among various fine-tuning methods, LoRA is popular for its efficiency and ease to use, allowing end-users to easily post and adopt lightweight LoRA modules on open-source platforms to tailor their model for different customization. However, such a handy share-and-play setting opens up new attack surfaces, that the attacker can render LoRA as an attacker, such as backdoor injection, and widely distribute the adversarial LoRA to the community easily. This can result in detrimental outcomes. Despite the huge potential risks of sharing LoRA modules, this aspect however has not been fully explored. To fill the gap, in this study we thoroughly investigate the attack opportunities enabled in the growing share-and-play scenario. Specifically, we study how to inject backdoor into the LoRA module and dive deep
    

