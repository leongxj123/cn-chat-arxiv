<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#33258;&#21160;&#21270;&#26694;&#26550;&#8220;ChemBench&#8221;&#65292;&#26088;&#22312;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21270;&#23398;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#19982;&#20154;&#31867;&#21270;&#23398;&#23478;&#19987;&#19994;&#30693;&#35782;&#30340;&#23545;&#27604;&#12290;</title><link>https://arxiv.org/abs/2404.01475</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#26159;&#36229;&#20154;&#31867;&#21270;&#23398;&#23478;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are large language models superhuman chemists?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01475
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#33258;&#21160;&#21270;&#26694;&#26550;&#8220;ChemBench&#8221;&#65292;&#26088;&#22312;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21270;&#23398;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#19982;&#20154;&#31867;&#21270;&#23398;&#23478;&#19987;&#19994;&#30693;&#35782;&#30340;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22240;&#20854;&#22788;&#29702;&#20154;&#31867;&#35821;&#35328;&#24182;&#25191;&#34892;&#26410;&#32463;&#26126;&#30830;&#35757;&#32451;&#30340;&#20219;&#21153;&#30340;&#33021;&#21147;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#36825;&#23545;&#21270;&#23398;&#31185;&#23398;&#26159;&#30456;&#20851;&#30340;&#65292;&#22240;&#20026;&#21270;&#23398;&#38754;&#20020;&#30528;&#25968;&#25454;&#38598;&#23567;&#19988;&#22810;&#26679;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#36890;&#24120;&#20197;&#25991;&#26412;&#24418;&#24335;&#21576;&#29616;&#12290; LLMs&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#65292;&#24182;&#19988;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#21033;&#29992;&#26469;&#39044;&#27979;&#21270;&#23398;&#24615;&#36136;&#65292;&#20248;&#21270;&#21453;&#24212;&#65292;&#29978;&#33267;&#33258;&#20027;&#35774;&#35745;&#21644;&#36827;&#34892;&#23454;&#39564;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;LLMs&#30340;&#21270;&#23398;&#25512;&#29702;&#33021;&#21147;&#20165;&#26377;&#38750;&#24120;&#26377;&#38480;&#30340;&#31995;&#32479;&#24615;&#29702;&#35299;&#65292;&#36825;&#26159;&#25913;&#36827;&#27169;&#22411;&#21644;&#20943;&#36731;&#28508;&#22312;&#21361;&#23475;&#25152;&#24517;&#38656;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#8220;ChemBench&#8221;&#65292;&#36825;&#26159;&#19968;&#20010;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#26088;&#22312;&#20005;&#26684;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;LLMs&#30340;&#21270;&#23398;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#20197;&#19982;&#20154;&#31867;&#21270;&#23398;&#23478;&#30340;&#19987;&#19994;&#30693;&#35782;&#30456;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01475v1 Announce Type: cross  Abstract: Large language models (LLMs) have gained widespread interest due to their ability to process human language and perform tasks on which they have not been explicitly trained. This is relevant for the chemical sciences, which face the problem of small and diverse datasets that are frequently in the form of text. LLMs have shown promise in addressing these issues and are increasingly being harnessed to predict chemical properties, optimize reactions, and even design and conduct experiments autonomously. However, we still have only a very limited systematic understanding of the chemical reasoning capabilities of LLMs, which would be required to improve models and mitigate potential harms. Here, we introduce "ChemBench," an automated framework designed to rigorously evaluate the chemical knowledge and reasoning abilities of state-of-the-art LLMs against the expertise of human chemists. We curated more than 7,000 question-answer pairs for a 
&lt;/p&gt;</description></item><item><title>JailbreakBench&#26159;&#19968;&#20010;&#29992;&#20110;&#23545;&#25239;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36234;&#29425;&#30340;&#24320;&#25918;&#22522;&#20934;&#65292;&#25552;&#20379;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#23545;&#25239;&#25552;&#31034;&#21644;&#35780;&#20272;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2404.01318</link><description>&lt;p&gt;
JailbreakBench: &#19968;&#20010;&#29992;&#20110;&#23545;&#25239;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36234;&#29425;&#30340;&#24320;&#25918;&#40065;&#26834;&#24615;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01318
&lt;/p&gt;
&lt;p&gt;
JailbreakBench&#26159;&#19968;&#20010;&#29992;&#20110;&#23545;&#25239;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36234;&#29425;&#30340;&#24320;&#25918;&#22522;&#20934;&#65292;&#25552;&#20379;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#23545;&#25239;&#25552;&#31034;&#21644;&#35780;&#20272;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#29425;&#25915;&#20987;&#20250;&#23548;&#33268;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#26377;&#23475;&#12289;&#19981;&#36947;&#24503;&#25110;&#20196;&#20154;&#21453;&#24863;&#30340;&#20869;&#23481;&#12290;&#35780;&#20272;&#36825;&#20123;&#25915;&#20987;&#23384;&#22312;&#35768;&#22810;&#25361;&#25112;&#65292;&#24403;&#21069;&#30340;&#22522;&#20934;&#21644;&#35780;&#20272;&#25216;&#26415;&#24182;&#26410;&#20805;&#20998;&#35299;&#20915;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;JailbreakBench&#65292;&#19968;&#20010;&#24320;&#28304;&#22522;&#20934;&#65292;&#21253;&#25324;&#20855;&#26377;100&#20010;&#29420;&#29305;&#34892;&#20026;&#30340;&#26032;&#36234;&#29425;&#25968;&#25454;&#38598;&#65288;&#31216;&#20026;JBB-Behaviors&#65289;&#12289;&#19968;&#32452;&#26368;&#20808;&#36827;&#30340;&#23545;&#25239;&#25552;&#31034;&#65288;&#31216;&#20026;&#36234;&#29425;&#24037;&#20214;&#65289;&#21644;&#19968;&#20010;&#26631;&#20934;&#21270;&#35780;&#20272;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01318v1 Announce Type: cross  Abstract: Jailbreak attacks cause large language models (LLMs) to generate harmful, unethical, or otherwise objectionable content. Evaluating these attacks presents a number of challenges, which the current collection of benchmarks and evaluation techniques do not adequately address. First, there is no clear standard of practice regarding jailbreaking evaluation. Second, existing works compute costs and success rates in incomparable ways. And third, numerous works are not reproducible, as they withhold adversarial prompts, involve closed-source code, or rely on evolving proprietary APIs. To address these challenges, we introduce JailbreakBench, an open-sourced benchmark with the following components: (1) a new jailbreaking dataset containing 100 unique behaviors, which we call JBB-Behaviors; (2) an evolving repository of state-of-the-art adversarial prompts, which we refer to as jailbreak artifacts; (3) a standardized evaluation framework that i
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;C-Flat&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24179;&#22374;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#21487;&#29992;&#20110;&#25345;&#32493;&#23398;&#20064;&#65292;&#31616;&#21270;&#20102;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#24182;&#25552;&#39640;&#20102;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.00986</link><description>&lt;p&gt;
&#36890;&#36807;C-Flat&#20351;&#25345;&#32493;&#23398;&#20064;&#26356;&#24378;&#22823;
&lt;/p&gt;
&lt;p&gt;
Make Continual Learning Stronger via C-Flat
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00986
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;C-Flat&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24179;&#22374;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#21487;&#29992;&#20110;&#25345;&#32493;&#23398;&#20064;&#65292;&#31616;&#21270;&#20102;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#24182;&#25552;&#39640;&#20102;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#23398;&#20064;&#20013;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#23545;&#20110;&#22788;&#29702;&#36830;&#32493;&#21040;&#36798;&#20219;&#21153;&#30340;&#21160;&#24577;&#26356;&#26032;&#30693;&#35782;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20026;&#20102;&#35299;&#20915;&#25345;&#32493;&#23398;&#20064;&#20013;&#30340;&#25935;&#24863;&#24615;-&#31283;&#23450;&#24615;&#22256;&#22659;&#12290;&#30740;&#31350;&#35777;&#26126;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#26435;&#37325;&#25439;&#22833;&#26223;&#35266;&#30340;&#38497;&#23789;&#24230;&#65292;&#23547;&#25214;&#20301;&#20110;&#20855;&#26377;&#32479;&#19968;&#20302;&#25439;&#22833;&#25110;&#24179;&#31283;&#26799;&#24230;&#30340;&#37051;&#22495;&#20013;&#30340;&#24179;&#22374;&#26368;&#23567;&#20540;&#65292;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#35757;&#32451;&#26041;&#24335;&#65292;&#30456;&#36739;&#20110;&#22522;&#20110;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#20248;&#21270;&#22120;&#22914;SGD&#26469;&#25552;&#39640;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#12290;&#28982;&#32780;&#65292;&#21482;&#26377;&#23569;&#25968;&#20316;&#21697;&#35752;&#35770;&#20102;&#36825;&#31181;&#35757;&#32451;&#26041;&#24335;&#22312;&#25345;&#32493;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#29305;&#23450;&#35774;&#35745;&#30340;&#38646;&#38454;&#38497;&#23789;&#24230;&#20248;&#21270;&#22120;&#21487;&#20197;&#25552;&#21319;&#25345;&#32493;&#23398;&#20064;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Continual Flatness&#65288;C-Flat&#65289;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#20026;&#25345;&#32493;&#23398;&#20064;&#23450;&#21046;&#30340;&#26356;&#24179;&#22374;&#30340;&#25439;&#22833;&#26223;&#35266;&#12290;C-Flat&#21482;&#38656;&#19968;&#34892;&#20195;&#30721;&#21363;&#21487;&#36731;&#26494;&#35843;&#29992;&#65292;&#24182;&#21487;&#19982;&#20219;&#20309;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#25554;&#25773;&#12290;C-Flat&#24212;&#29992;&#20110;&#25152;&#26377;&#25345;&#32493;&#23398;&#20064;&#31867;&#21035;&#30340;&#19968;&#33324;&#26694;&#26550;&#65292;&#24182;&#19982;&#25439;&#22833;&#26368;&#23567;&#21270;&#20248;&#21270;&#22120;&#36827;&#34892;&#20102;&#24443;&#24213;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00986v1 Announce Type: new  Abstract: Model generalization ability upon incrementally acquiring dynamically updating knowledge from sequentially arriving tasks is crucial to tackle the sensitivity-stability dilemma in Continual Learning (CL). Weight loss landscape sharpness minimization seeking for flat minima lying in neighborhoods with uniform low loss or smooth gradient is proven to be a strong training regime improving model generalization compared with loss minimization based optimizer like SGD. Yet only a few works have discussed this training regime for CL, proving that dedicated designed zeroth-order sharpness optimizer can improve CL performance. In this work, we propose a Continual Flatness (C-Flat) method featuring a flatter loss landscape tailored for CL. C-Flat could be easily called with only one line of code and is plug-and-play to any CL methods. A general framework of C-Flat applied to all CL categories and a thorough comparison with loss minima optimizer an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#20027;&#30340;&#12289;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#25805;&#20316;&#22120;&#26694;&#26550;&#65292;&#23558;&#20154;&#22312;&#22238;&#36335;&#21407;&#21017;&#21644;&#25193;&#23637;&#29616;&#23454;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#20419;&#36827;&#20154;&#19982;&#26426;&#22120;&#20154;&#20043;&#38388;&#30452;&#35266;&#30340;&#27807;&#36890;&#21644;&#32534;&#31243;&#12290;</title><link>https://arxiv.org/abs/2403.14597</link><description>&lt;p&gt;
&#25193;&#23637;&#29616;&#23454;&#29992;&#20110;&#22686;&#24378;&#20154;&#26426;&#21327;&#20316;&#65306;&#19968;&#31181;&#20154;&#22312;&#22238;&#36335;&#20013;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Extended Reality for Enhanced Human-Robot Collaboration: a Human-in-the-Loop Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#20027;&#30340;&#12289;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#25805;&#20316;&#22120;&#26694;&#26550;&#65292;&#23558;&#20154;&#22312;&#22238;&#36335;&#21407;&#21017;&#21644;&#25193;&#23637;&#29616;&#23454;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#20419;&#36827;&#20154;&#19982;&#26426;&#22120;&#20154;&#20043;&#38388;&#30452;&#35266;&#30340;&#27807;&#36890;&#21644;&#32534;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#30340;&#23835;&#36215;&#20026;&#21046;&#36896;&#36807;&#31243;&#30340;&#39640;&#25928;&#29575;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#20294;&#24448;&#24448;&#29306;&#29298;&#20102;&#21450;&#26102;&#21709;&#24212;&#19981;&#26029;&#21464;&#21270;&#30340;&#24066;&#22330;&#38656;&#27714;&#21644;&#28385;&#36275;&#23450;&#21046;&#38656;&#27714;&#25152;&#38656;&#30340;&#28789;&#27963;&#24615;&#12290;&#20154;&#26426;&#21327;&#20316;&#35797;&#22270;&#36890;&#36807;&#23558;&#26426;&#22120;&#30340;&#21147;&#37327;&#21644;&#31934;&#24230;&#19982;&#20154;&#31867;&#30340;&#26426;&#26234;&#21644;&#24863;&#30693;&#29702;&#35299;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#26412;&#25991;&#27010;&#24565;&#21270;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29616;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#20154;&#22312;&#22238;&#36335;&#21407;&#21017;&#19982;&#25193;&#23637;&#29616;&#23454;&#65288;XR&#65289;&#30456;&#32467;&#21512;&#65292;&#20197;&#20415;&#20110;&#20154;&#19982;&#26426;&#22120;&#20154;&#20043;&#38388;&#36827;&#34892;&#30452;&#35266;&#27807;&#36890;&#21644;&#32534;&#31243;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#27010;&#24565;&#26694;&#26550;&#39044;&#35265;&#21040;&#20102;&#20154;&#30452;&#25509;&#21442;&#19982;&#26426;&#22120;&#20154;&#23398;&#20064;&#36807;&#31243;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#36866;&#24212;&#24615;&#21644;&#20219;&#21153;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#37325;&#28857;&#20171;&#32461;&#20102;&#25903;&#25345;&#25152;&#25552;&#20986;&#26694;&#26550;&#30340;&#20851;&#38190;&#25216;&#26415;&#65292;&#24378;&#35843;&#20102;&#23454;&#29616;&#36825;&#19968;&#26694;&#26550;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14597v1 Announce Type: cross  Abstract: The rise of automation has provided an opportunity to achieve higher efficiency in manufacturing processes, yet it often compromises the flexibility required to promptly respond to evolving market needs and meet the demand for customization. Human-robot collaboration attempts to tackle these challenges by combining the strength and precision of machines with human ingenuity and perceptual understanding. In this paper, we conceptualize and propose an implementation framework for an autonomous, machine learning-based manipulator that incorporates human-in-the-loop principles and leverages Extended Reality (XR) to facilitate intuitive communication and programming between humans and robots. Furthermore, the conceptual framework foresees human involvement directly in the robot learning process, resulting in higher adaptability and task generalization. The paper highlights key technologies enabling the proposed framework, emphasizing the im
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CoDA-NO&#30340;&#31070;&#32463;&#31639;&#23376;&#65292;&#36890;&#36807;&#22312;&#35937;&#22495;&#25110;&#36890;&#36947;&#31354;&#38388;&#23545;&#20989;&#25968;&#36827;&#34892;&#26631;&#35760;&#65292;&#23454;&#29616;&#20102;&#22810;&#20010;PDE&#31995;&#32479;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#25110;&#39044;&#35757;&#32451;&#65292;&#20026;&#35299;&#20915;&#28041;&#21450;&#32806;&#21512;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#22810;&#29289;&#29702;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;</title><link>https://arxiv.org/abs/2403.12553</link><description>&lt;p&gt;
&#20026;&#27714;&#35299;&#22810;&#29289;&#29702;&#23398;&#20559;&#24494;&#20998;&#26041;&#31243;&#39044;&#35757;&#32451;&#35937;&#22495;&#20851;&#27880;&#31070;&#32463;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Pretraining Codomain Attention Neural Operators for Solving Multiphysics PDEs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12553
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CoDA-NO&#30340;&#31070;&#32463;&#31639;&#23376;&#65292;&#36890;&#36807;&#22312;&#35937;&#22495;&#25110;&#36890;&#36947;&#31354;&#38388;&#23545;&#20989;&#25968;&#36827;&#34892;&#26631;&#35760;&#65292;&#23454;&#29616;&#20102;&#22810;&#20010;PDE&#31995;&#32479;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#25110;&#39044;&#35757;&#32451;&#65292;&#20026;&#35299;&#20915;&#28041;&#21450;&#32806;&#21512;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#22810;&#29289;&#29702;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#22312;&#35299;&#20915;&#28041;&#21450;&#32806;&#21512;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#22810;&#29289;&#29702;&#38382;&#39064;&#26102;&#38754;&#20020;&#25361;&#25112;&#65292;&#36825;&#26159;&#30001;&#20110;&#22797;&#26434;&#30340;&#20960;&#20309;&#24418;&#29366;&#12289;&#29289;&#29702;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#20197;&#21450;&#32570;&#20047;&#22823;&#37327;&#39640;&#20998;&#36776;&#29575;&#35757;&#32451;&#25968;&#25454;&#25152;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35937;&#22495;&#20851;&#27880;&#31070;&#32463;&#31639;&#23376;&#65288;CoDA-NO&#65289;&#65292;&#35813;&#31639;&#23376;&#23558;&#20989;&#25968;&#22312;&#35937;&#22495;&#25110;&#36890;&#36947;&#31354;&#38388;&#19978;&#36827;&#34892;&#26631;&#35760;&#65292;&#23454;&#29616;&#20102;&#22810;&#20010;PDE&#31995;&#32479;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#25110;&#39044;&#35757;&#32451;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#20301;&#32622;&#32534;&#30721;&#12289;&#33258;&#27880;&#24847;&#21147;&#21644;&#24402;&#19968;&#21270;&#23618;&#25193;&#23637;&#21040;&#20989;&#25968;&#31354;&#38388;&#12290;CoDA-NO&#21487;&#20197;&#20351;&#29992;&#21333;&#20010;&#27169;&#22411;&#23398;&#20064;&#19981;&#21516;PDE&#31995;&#32479;&#30340;&#34920;&#31034;&#12290;&#36890;&#36807;&#32771;&#34385;&#23569;&#26679;&#26412;&#23398;&#20064;&#35774;&#32622;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;CoDA-NO&#20316;&#20026;&#23398;&#20064;&#22810;&#29289;&#29702;PDE&#30340;&#39592;&#24178;&#30340;&#28508;&#21147;&#12290;&#22312;&#20855;&#26377;&#26377;&#38480;&#25968;&#25454;&#30340;&#22797;&#26434;&#19979;&#28216;&#20219;&#21153;&#65288;&#22914;&#27969;&#20307;&#27969;&#21160;&#27169;&#25311;&#21644;&#27969;&#22266;&#30456;&#20114;&#20316;&#29992;&#65289;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;CoDA-N
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12553v1 Announce Type: new  Abstract: Existing neural operator architectures face challenges when solving multiphysics problems with coupled partial differential equations (PDEs), due to complex geometries, interactions between physical variables, and the lack of large amounts of high-resolution training data. To address these issues, we propose Codomain Attention Neural Operator (CoDA-NO), which tokenizes functions along the codomain or channel space, enabling self-supervised learning or pretraining of multiple PDE systems. Specifically, we extend positional encoding, self-attention, and normalization layers to the function space. CoDA-NO can learn representations of different PDE systems with a single model. We evaluate CoDA-NO's potential as a backbone for learning multiphysics PDEs over multiple systems by considering few-shot learning settings. On complex downstream tasks with limited data, such as fluid flow simulations and fluid-structure interactions, we found CoDA-N
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;&#65288;DSPNs&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21551;&#21457;&#30340;GPC-ready&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#23376;&#27169;&#20989;&#25968;&#23398;&#20064;&#20013;&#30340;&#20004;&#22823;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.08199</link><description>&lt;p&gt;
&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep Submodular Peripteral Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08199
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;&#65288;DSPNs&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21551;&#21457;&#30340;GPC-ready&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#23376;&#27169;&#20989;&#25968;&#23398;&#20064;&#20013;&#30340;&#20004;&#22823;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23376;&#27169;&#20989;&#25968;&#23545;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#36890;&#24120;&#32570;&#20047;&#23454;&#29992;&#30340;&#23398;&#20064;&#26041;&#27861;&#26469;&#33719;&#21462;&#23427;&#20204;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;&#65288;DSPNs&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#23376;&#27169;&#20989;&#25968;&#21442;&#25968;&#21270;&#26063;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21551;&#21457;&#30340;GPC-ready&#31574;&#30053;&#23545;&#20854;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20197;&#36830;&#25509;&#24182;&#35299;&#20915;&#19978;&#36848;&#20004;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08199v1 Announce Type: cross  Abstract: Submodular functions, crucial for various applications, often lack practical learning methods for their acquisition. Seemingly unrelated, learning a scaling from oracles offering graded pairwise preferences (GPC) is underexplored, despite a rich history in psychometrics. In this paper, we introduce deep submodular peripteral networks (DSPNs), a novel parametric family of submodular functions, and methods for their training using a contrastive-learning inspired GPC-ready strategy to connect and then tackle both of the above challenges. We introduce newly devised GPC-style "peripteral" loss which leverages numerically graded relationships between pairs of objects (sets in our case). Unlike traditional contrastive learning, our method utilizes graded comparisons, extracting more nuanced information than just binary-outcome comparisons, and contrasts sets of any size (not just two). We also define a novel suite of automatic sampling strate
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#36719;&#32422;&#26463;&#21462;&#20195;&#30828;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19987;&#23478;&#28151;&#21512;&#20808;&#39564;&#65292;&#25913;&#21892;&#20102;&#22810;&#27169;&#24577;VAEs&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.05300</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;VAEs&#20013;&#30340;&#32479;&#19968;&#22810;&#26679;&#24615;&#65306;&#25913;&#36827;&#30340;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unity by Diversity: Improved Representation Learning in Multimodal VAEs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05300
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36719;&#32422;&#26463;&#21462;&#20195;&#30828;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19987;&#23478;&#28151;&#21512;&#20808;&#39564;&#65292;&#25913;&#21892;&#20102;&#22810;&#27169;&#24577;VAEs&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#22312;&#25968;&#25454;&#20998;&#26512;&#30340;&#35768;&#22810;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#65292;&#22914;&#34920;&#31034;&#23398;&#20064;&#12289;&#26377;&#26465;&#20214;&#29983;&#25104;&#21644;&#22635;&#34917;&#12290;&#30446;&#21069;&#30340;&#26550;&#26500;&#35201;&#20040;&#36328;&#27169;&#24577;&#20849;&#20139;&#32534;&#30721;&#22120;&#36755;&#20986;&#12289;&#35299;&#30721;&#22120;&#36755;&#20837;&#65292;&#35201;&#20040;&#20004;&#32773;&#37117;&#35201;&#23398;&#20064;&#20849;&#20139;&#34920;&#31034;&#12290;&#36825;&#26679;&#30340;&#26550;&#26500;&#23545;&#27169;&#22411;&#26045;&#21152;&#20102;&#20005;&#26684;&#32422;&#26463;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#29992;&#36719;&#32422;&#26463;&#21462;&#20195;&#36825;&#20123;&#30828;&#32422;&#26463;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19987;&#23478;&#28151;&#21512;&#20808;&#39564;&#65292;&#36719;&#24615;&#22320;&#24341;&#23548;&#27599;&#20010;&#27169;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#26397;&#30528;&#20849;&#20139;&#30340;&#21518;&#39564;&#12290;&#36825;&#31181;&#26041;&#27861;&#23548;&#33268;&#20102;&#20248;&#31168;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#24182;&#20801;&#35768;&#27599;&#20010;&#32534;&#30721;&#20445;&#30041;&#26469;&#33258;&#20854;&#26410;&#21387;&#32553;&#21407;&#22987;&#29305;&#24449;&#26356;&#22909;&#30340;&#20449;&#24687;&#12290;&#36890;&#36807;&#23545;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29616;&#23454;&#19990;&#30028;&#31070;&#32463;&#31185;&#23398;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25913;&#36827;&#30340;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#21644;&#22635;&#34917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05300v1 Announce Type: cross  Abstract: Variational Autoencoders for multimodal data hold promise for many tasks in data analysis, such as representation learning, conditional generation, and imputation. Current architectures either share the encoder output, decoder input, or both across modalities to learn a shared representation. Such architectures impose hard constraints on the model. In this work, we show that a better latent representation can be obtained by replacing these hard constraints with a soft constraint. We propose a new mixture-of-experts prior, softly guiding each modality's latent representation towards a shared aggregate posterior. This approach results in a superior latent representation and allows each encoding to preserve information from its uncompressed original features better. In extensive experiments on multiple benchmark datasets and a challenging real-world neuroscience data set, we show improved learned latent representations and imputation of m
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20026;R&#233;nyi-DP&#25512;&#23548;&#36890;&#36807;&#23376;&#25277;&#26679;&#30340;&#25918;&#22823;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#38024;&#23545;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#30340;&#26694;&#26550;&#65292;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04867</link><description>&lt;p&gt;
&#32452;&#38544;&#31169;&#25918;&#22823;&#21644;&#23376;&#25277;&#26679;&#30340;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#32479;&#19968;&#25918;&#22823;
&lt;/p&gt;
&lt;p&gt;
Group Privacy Amplification and Unified Amplification by Subsampling for R\'enyi Differential Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04867
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20026;R&#233;nyi-DP&#25512;&#23548;&#36890;&#36807;&#23376;&#25277;&#26679;&#30340;&#25918;&#22823;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#38024;&#23545;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#30340;&#26694;&#26550;&#65292;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;(DP)&#20855;&#26377;&#22810;&#31181;&#29702;&#24819;&#23646;&#24615;&#65292;&#22914;&#23545;&#21518;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#12289;&#32452;&#38544;&#31169;&#21644;&#36890;&#36807;&#23376;&#25277;&#26679;&#25918;&#22823;&#65292;&#36825;&#20123;&#23646;&#24615;&#21487;&#20197;&#30456;&#20114;&#29420;&#31435;&#25512;&#23548;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#26159;&#21542;&#36890;&#36807;&#32852;&#21512;&#32771;&#34385;&#36825;&#20123;&#23646;&#24615;&#20013;&#30340;&#22810;&#20010;&#21487;&#20197;&#33719;&#24471;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#32452;&#38544;&#31169;&#21644;&#36890;&#36807;&#23376;&#25277;&#26679;&#25918;&#22823;&#30340;&#32452;&#21512;&#12290;&#20026;&#20102;&#25552;&#20379;&#36866;&#21512;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#20445;&#35777;&#65292;&#25105;&#20204;&#22312;R&#233;nyi-DP&#26694;&#26550;&#20013;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#36825;&#27604;$(\epsilon,\delta)$-DP&#20855;&#26377;&#26356;&#26377;&#21033;&#30340;&#32452;&#21512;&#23646;&#24615;&#12290;&#20316;&#20026;&#36825;&#20010;&#20998;&#26512;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20026;R&#233;nyi-DP&#25512;&#23548;&#36890;&#36807;&#23376;&#25277;&#26679;&#30340;&#25918;&#22823;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#38024;&#23545;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#30340;&#26694;&#26550;&#65292;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23427;&#19981;&#20165;&#35753;&#25105;&#20204;&#25913;&#36827;&#21644;&#27867;&#21270;&#29616;&#26377;&#30340;&#25918;&#22823;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04867v1 Announce Type: cross  Abstract: Differential privacy (DP) has various desirable properties, such as robustness to post-processing, group privacy, and amplification by subsampling, which can be derived independently of each other. Our goal is to determine whether stronger privacy guarantees can be obtained by considering multiple of these properties jointly. To this end, we focus on the combination of group privacy and amplification by subsampling. To provide guarantees that are amenable to machine learning algorithms, we conduct our analysis in the framework of R\'enyi-DP, which has more favorable composition properties than $(\epsilon,\delta)$-DP. As part of this analysis, we develop a unified framework for deriving amplification by subsampling guarantees for R\'enyi-DP, which represents the first such framework for a privacy accounting method and is of independent interest. We find that it not only lets us improve upon and generalize existing amplification results 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29289;&#29702;&#30693;&#35782;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#20165;&#20351;&#29992;&#38750;&#20405;&#20837;&#24335;&#24739;&#32773;&#20581;&#24247;&#25968;&#25454;&#35782;&#21035;&#25968;&#23383;&#23402;&#29983;&#20307;&#27169;&#22411;&#21442;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#38750;&#20405;&#20837;&#24335;&#21307;&#23398;&#25968;&#23383;&#23402;&#29983;&#20307;&#30340;&#26500;&#24314;&#12290;</title><link>https://arxiv.org/abs/2403.00177</link><description>&lt;p&gt;
&#20351;&#29992;&#29289;&#29702;&#30693;&#35782;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26500;&#24314;&#38750;&#20405;&#20837;&#24335;&#21307;&#23398;&#25968;&#23383;&#23402;&#29983;&#20307;
&lt;/p&gt;
&lt;p&gt;
Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00177
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29289;&#29702;&#30693;&#35782;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#20165;&#20351;&#29992;&#38750;&#20405;&#20837;&#24335;&#24739;&#32773;&#20581;&#24247;&#25968;&#25454;&#35782;&#21035;&#25968;&#23383;&#23402;&#29983;&#20307;&#27169;&#22411;&#21442;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#38750;&#20405;&#20837;&#24335;&#21307;&#23398;&#25968;&#23383;&#23402;&#29983;&#20307;&#30340;&#26500;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#23402;&#29983;&#20307;&#26159;&#23454;&#29616;&#23454;&#38469;&#29289;&#29702;&#29616;&#35937;&#30340;&#34394;&#25311;&#22797;&#21046;&#21697;&#65292;&#21033;&#29992;&#25968;&#23398;&#24314;&#27169;&#26469;&#34920;&#24449;&#21644;&#27169;&#25311;&#20854;&#23450;&#20041;&#29305;&#24449;&#12290;&#36890;&#36807;&#20026;&#30142;&#30149;&#36807;&#31243;&#26500;&#24314;&#25968;&#23383;&#23402;&#29983;&#20307;&#65292;&#25105;&#20204;&#21487;&#20197;&#36827;&#34892;&#20223;&#30495;&#65292;&#27169;&#25311;&#24739;&#32773;&#22312;&#34394;&#25311;&#29615;&#22659;&#20013;&#30340;&#20581;&#24247;&#29366;&#20917;&#21644;&#22312;&#20551;&#35774;&#24178;&#39044;&#19979;&#30340;&#23545;&#29031;&#32467;&#26524;&#12290;&#36825;&#28040;&#38500;&#20102;&#20405;&#20837;&#24615;&#31243;&#24207;&#25110;&#19981;&#30830;&#23450;&#27835;&#30103;&#20915;&#31574;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#21033;&#29992;&#38750;&#20405;&#20837;&#24335;&#24739;&#32773;&#20581;&#24247;&#25968;&#25454;&#26469;&#35782;&#21035;&#25968;&#23383;&#23402;&#29983;&#20307;&#27169;&#22411;&#21442;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#25968;&#23383;&#23402;&#29983;&#20307;&#24314;&#27169;&#30475;&#20316;&#19968;&#20010;&#22797;&#21512;&#36870;&#38382;&#39064;&#65292;&#24182;&#35266;&#23519;&#21040;&#20854;&#32467;&#26500;&#31867;&#20284;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#12290;&#21033;&#29992;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#30693;&#35782;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65292;&#36825;&#31181;&#31639;&#27861;&#39318;&#20808;&#22312;&#35299;&#20915;&#29289;&#29702;&#27169;&#22411;&#26041;&#31243;&#30340;&#20551;&#23450;&#20219;&#21153;&#19978;&#23545;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#39044;&#35757;&#32451;&#12290;&#38543;&#21518;&#65292;&#35813;&#27169;&#22411;&#34987;&#35757;&#32451;&#20197;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00177v1 Announce Type: new  Abstract: A digital twin is a virtual replica of a real-world physical phenomena that uses mathematical modeling to characterize and simulate its defining features. By constructing digital twins for disease processes, we can perform in-silico simulations that mimic patients' health conditions and counterfactual outcomes under hypothetical interventions in a virtual setting. This eliminates the need for invasive procedures or uncertain treatment decisions. In this paper, we propose a method to identify digital twin model parameters using only noninvasive patient health data. We approach the digital twin modeling as a composite inverse problem, and observe that its structure resembles pretraining and finetuning in self-supervised learning (SSL). Leveraging this, we introduce a physics-informed SSL algorithm that initially pretrains a neural network on the pretext task of solving the physical model equations. Subsequently, the model is trained to rec
&lt;/p&gt;</description></item><item><title>&#38543;&#30528;GateLoop&#12289;Mamba&#21644;GLA&#31561;&#20855;&#26377;&#20056;&#27861;&#20132;&#20114;&#30340;&#32447;&#24615;&#36882;&#24402;&#39537;&#21160;&#19979;&#30340;&#28145;&#24230;SSM&#26550;&#26500;&#30340;&#20986;&#29616;&#65292;&#23427;&#20204;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#19978;&#36229;&#36234;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#25991;&#26412;&#35757;&#32451;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.19047</link><description>&lt;p&gt;
&#28145;&#24230;&#36873;&#25321;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#29702;&#35770;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Theoretical Foundations of Deep Selective State-Space Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19047
&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;GateLoop&#12289;Mamba&#21644;GLA&#31561;&#20855;&#26377;&#20056;&#27861;&#20132;&#20114;&#30340;&#32447;&#24615;&#36882;&#24402;&#39537;&#21160;&#19979;&#30340;&#28145;&#24230;SSM&#26550;&#26500;&#30340;&#20986;&#29616;&#65292;&#23427;&#20204;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#19978;&#36229;&#36234;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#25991;&#26412;&#35757;&#32451;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;SSM&#65289;&#22914;S4&#65292;&#28304;&#33258;Gu&#31561;&#20154;&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#65292;&#20316;&#20026;&#24314;&#27169;&#24207;&#21015;&#25968;&#25454;&#30340;&#26377;&#25928;&#26041;&#27861;&#32780;&#26085;&#30410;&#21463;&#21040;&#38738;&#30544;&#12290;&#28145;&#24230;SSM&#22312;&#21508;&#31181;&#39046;&#22495;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#30456;&#36739;&#20110;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;transformers&#65292;&#35757;&#32451;&#21644;&#25512;&#29702;&#25104;&#26412;&#38477;&#20302;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#39537;&#21160;SSM&#30340;&#32447;&#24615;&#36882;&#24402;&#20801;&#35768;&#36755;&#20837;&#21644;&#38544;&#34255;&#29366;&#24577;&#20043;&#38388;&#30340;&#20056;&#27861;&#20132;&#20114;&#65288;&#22914;GateLoop&#65292;Mamba&#65292;GLA&#65289;&#65292;&#37027;&#20040;&#25152;&#24471;&#21040;&#30340;&#26550;&#26500;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#19978;&#36229;&#36234;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#25991;&#26412;&#35757;&#32451;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#21442;&#25968;&#35268;&#27169;&#36798;&#21040;&#21313;&#20159;&#32423;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;Rough Path Theory&#30340;&#24037;&#20855;&#65292;&#20026;&#36825;&#19968;&#26368;&#36817;&#30340;&#21457;&#29616;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#65306;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#38543;&#26426;&#32447;&#24615;&#36882;&#24402;&#37197;&#22791;&#31616;&#21333;&#30340;&#36755;&#20837;&#25511;&#21046;&#36716;&#25442;&#65288;&#36873;&#25321;&#24615;&#26426;&#21046;&#65289;&#26102;&#65292;&#38544;&#34255;&#29366;&#24577;&#21487;&#34987;&#35777;&#26126;&#26159;&#20302;&#32500;&#30340;&#25237;&#24433;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19047v1 Announce Type: new  Abstract: Structured state-space models (SSMs) such as S4, stemming from the seminal work of Gu et al., are gaining popularity as effective approaches for modeling sequential data. Deep SSMs demonstrate outstanding performance across a diverse set of domains, at a reduced training and inference cost compared to attention-based transformers. Recent developments show that if the linear recurrence powering SSMs allows for multiplicative interactions between inputs and hidden states (e.g. GateLoop, Mamba, GLA), then the resulting architecture can surpass in both in accuracy and efficiency attention-powered foundation models trained on text, at scales of billion parameters. In this paper, we give theoretical grounding to this recent finding using tools from Rough Path Theory: we show that when random linear recurrences are equipped with simple input-controlled transitions (selectivity mechanism), then the hidden state is provably a low-dimensional proj
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#20581;&#22766;&#24230;&#37327;&#65288;DRM&#65289;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36873;&#25321;&#29702;&#24819;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#20013;&#20581;&#22766;&#20272;&#35745;&#22120;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.18392</link><description>&lt;p&gt;
&#25581;&#31034;&#20581;&#22766;&#24615;&#22312;&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unveiling the Potential of Robustness in Evaluating Causal Inference Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18392
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#20581;&#22766;&#24230;&#37327;&#65288;DRM&#65289;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36873;&#25321;&#29702;&#24819;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#20013;&#20581;&#22766;&#20272;&#35745;&#22120;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#23545;&#20010;&#24615;&#21270;&#20915;&#31574;&#21046;&#23450;&#30340;&#38656;&#27714;&#23548;&#33268;&#20154;&#20204;&#23545;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#20135;&#29983;&#20102;&#20852;&#36259;&#12290;&#26426;&#22120;&#23398;&#20064;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#20132;&#21449;&#39046;&#22495;&#24050;&#32463;&#20135;&#29983;&#20102;&#21508;&#31181;&#26377;&#25928;&#30340;CATE&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#36825;&#20123;&#20272;&#35745;&#22120;&#36890;&#24120;&#21463;&#21046;&#20110;&#32570;&#20047;&#21453;&#20107;&#23454;&#26631;&#31614;&#65292;&#22240;&#27492;&#20351;&#29992;&#20256;&#32479;&#30340;&#20132;&#21449;&#39564;&#35777;&#31561;&#27169;&#22411;&#36873;&#25321;&#31243;&#24207;&#26469;&#36873;&#25321;&#29702;&#24819;&#30340;CATE&#20272;&#35745;&#22120;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;CATE&#20272;&#35745;&#22120;&#36873;&#25321;&#26041;&#27861;&#65292;&#22914;&#25554;&#20540;&#21644;&#20266;&#32467;&#26524;&#24230;&#37327;&#65292;&#38754;&#20020;&#30528;&#20004;&#20010;&#22266;&#26377;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#23427;&#20204;&#38656;&#35201;&#30830;&#23450;&#24230;&#37327;&#24418;&#24335;&#21644;&#25311;&#21512;&#24178;&#25200;&#21442;&#25968;&#25110;&#25554;&#20214;&#23398;&#20064;&#32773;&#30340;&#22522;&#30784;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#32570;&#20047;&#38024;&#23545;&#36873;&#25321;&#20581;&#22766;&#20272;&#35745;&#22120;&#30340;&#29305;&#23450;&#37325;&#28857;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20998;&#24067;&#24335;&#20581;&#22766;&#24230;&#37327;&#65288;DRM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18392v1 Announce Type: cross  Abstract: The growing demand for personalized decision-making has led to a surge of interest in estimating the Conditional Average Treatment Effect (CATE). The intersection of machine learning and causal inference has yielded various effective CATE estimators. However, deploying these estimators in practice is often hindered by the absence of counterfactual labels, making it challenging to select the desirable CATE estimator using conventional model selection procedures like cross-validation. Existing approaches for CATE estimator selection, such as plug-in and pseudo-outcome metrics, face two inherent challenges. Firstly, they are required to determine the metric form and the underlying machine learning models for fitting nuisance parameters or plug-in learners. Secondly, they lack a specific focus on selecting a robust estimator. To address these challenges, this paper introduces a novel approach, the Distributionally Robust Metric (DRM), for 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#31471;&#21040;&#31471;&#22320;&#24378;&#21270;&#23398;&#20064;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#21644;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#33719;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2402.17423</link><description>&lt;p&gt;
&#21152;&#24378;&#19978;&#19979;&#25991;&#40657;&#30418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Reinforced In-Context Black-Box Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17423
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#31471;&#21040;&#31471;&#22320;&#24378;&#21270;&#23398;&#20064;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#21644;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#33719;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40657;&#30418;&#20248;&#21270;&#65288;BBO&#65289;&#24050;&#32463;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#25104;&#21151;&#24212;&#29992;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#20803;&#23398;&#20064;BBO&#31639;&#27861;&#30340;&#29305;&#23450;&#32452;&#20214;&#65292;&#20197;&#21152;&#24555;&#20248;&#21270;&#36895;&#24230;&#24182;&#25670;&#33073;&#32321;&#29712;&#30340;&#25163;&#24037;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#20316;&#20026;&#25193;&#23637;&#65292;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#25972;&#20010;&#31639;&#27861;&#38656;&#35201;&#19987;&#23478;&#26368;&#23569;&#30340;&#24037;&#20316;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#25552;&#20379;&#26368;&#22823;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RIBBO&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#24378;&#21270;&#23398;&#20064;BBO&#31639;&#27861;&#12290;RIBBO&#21033;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#26469;&#23398;&#20064;&#22810;&#20010;&#34892;&#20026;&#31639;&#27861;&#21644;&#20219;&#21153;&#20135;&#29983;&#30340;&#20248;&#21270;&#21382;&#21490;&#65292;&#21033;&#29992;&#22823;&#22411;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#26469;&#25552;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#30456;&#24212;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#22686;&#21152;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#22686;&#24378;&#20248;&#21270;&#21382;&#21490;&#65292;&#36825;&#20123;&#20196;&#29260;&#26088;&#22312;&#22522;&#20110;&#32047;&#31215;&#34920;&#29616;&#26469;&#34920;&#31034;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17423v1 Announce Type: cross  Abstract: Black-Box Optimization (BBO) has found successful applications in many fields of science and engineering. Recently, there has been a growing interest in meta-learning particular components of BBO algorithms to speed up optimization and get rid of tedious hand-crafted heuristics. As an extension, learning the entire algorithm from data requires the least labor from experts and can provide the most flexibility. In this paper, we propose RIBBO, a method to reinforce-learn a BBO algorithm from offline data in an end-to-end fashion. RIBBO employs expressive sequence models to learn the optimization histories produced by multiple behavior algorithms and tasks, leveraging the in-context learning ability of large models to extract task information and make decisions accordingly. Central to our method is to augment the optimization histories with regret-to-go tokens, which are designed to represent the performance of an algorithm based on cumul
&lt;/p&gt;</description></item><item><title>&#37325;&#35201;&#21457;&#29616;&#21253;&#25324;&#39640;&#32500;&#24773;&#20917;&#19979;&#37325;&#25277;&#26679;&#26041;&#27861;&#30340;&#38382;&#39064;&#65292;&#20165;&#24403;$\alpha$&#36275;&#22815;&#22823;&#26102;&#25552;&#20379;&#19968;&#33268;&#21487;&#38752;&#30340;&#35823;&#24046;&#20272;&#35745;&#65292;&#20197;&#21450;&#22312;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;$\alpha\!&lt;\!1$&#30340;&#24773;&#20917;&#19979;&#23427;&#20204;&#30340;&#39044;&#27979;&#34920;&#29616;</title><link>https://arxiv.org/abs/2402.13622</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#27491;&#21017;&#21270;&#22238;&#24402;&#20013;&#23545;&#33258;&#20030;&#21644;&#23376;&#25277;&#26679;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of Bootstrap and Subsampling in High-dimensional Regularized Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13622
&lt;/p&gt;
&lt;p&gt;
&#37325;&#35201;&#21457;&#29616;&#21253;&#25324;&#39640;&#32500;&#24773;&#20917;&#19979;&#37325;&#25277;&#26679;&#26041;&#27861;&#30340;&#38382;&#39064;&#65292;&#20165;&#24403;$\alpha$&#36275;&#22815;&#22823;&#26102;&#25552;&#20379;&#19968;&#33268;&#21487;&#38752;&#30340;&#35823;&#24046;&#20272;&#35745;&#65292;&#20197;&#21450;&#22312;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;$\alpha\!&lt;\!1$&#30340;&#24773;&#20917;&#19979;&#23427;&#20204;&#30340;&#39044;&#27979;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#27969;&#34892;&#37325;&#25277;&#26679;&#26041;&#27861;&#65292;&#22914;&#23376;&#25277;&#26679;&#12289;&#33258;&#20030;&#21644;jackknife&#65292;&#20197;&#21450;&#23427;&#20204;&#22312;&#39640;&#32500;&#30417;&#30563;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#24773;&#22659;&#19979;&#65292;&#20363;&#22914;&#23725;&#22238;&#24402;&#21644;&#36923;&#36753;&#22238;&#24402;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#26041;&#27861;&#20272;&#35745;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#25552;&#20379;&#20102;&#32039;&#33268;&#30340;&#28176;&#36817;&#25551;&#36848;&#65292;&#32771;&#34385;&#21040;&#26679;&#26412;&#25968;&#37327;$n$&#21644;&#21327;&#21464;&#37327;&#32500;&#24230;$d$&#20197;&#21487;&#27604;&#22266;&#23450;&#36895;&#29575;$\alpha\!=\! n/d$&#22686;&#38271;&#30340;&#26497;&#38480;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26377;&#19977;&#20010;&#26041;&#38754;&#65306;i&#65289;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#37325;&#25277;&#26679;&#26041;&#27861;&#23384;&#22312;&#38382;&#39064;&#65292;&#24182;&#34920;&#29616;&#20986;&#36825;&#20123;&#24773;&#20917;&#20856;&#22411;&#30340;&#21452;&#23792;&#34892;&#20026;&#65307;ii&#65289;&#21482;&#26377;&#22312;$\alpha$&#36275;&#22815;&#22823;&#26102;&#65292;&#23427;&#20204;&#25165;&#25552;&#20379;&#19968;&#33268;&#21487;&#38752;&#30340;&#35823;&#24046;&#20272;&#35745;&#65288;&#25105;&#20204;&#32473;&#20986;&#25910;&#25947;&#29575;&#65289;&#65307;iii&#65289;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#30456;&#20851;&#30340;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;$\alpha\!&lt;\!1$&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#26159;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13622v1 Announce Type: cross  Abstract: We investigate popular resampling methods for estimating the uncertainty of statistical models, such as subsampling, bootstrap and the jackknife, and their performance in high-dimensional supervised regression tasks. We provide a tight asymptotic description of the biases and variances estimated by these methods in the context of generalized linear models, such as ridge and logistic regression, taking the limit where the number of samples $n$ and dimension $d$ of the covariates grow at a comparable fixed rate $\alpha\!=\! n/d$. Our findings are three-fold: i) resampling methods are fraught with problems in high dimensions and exhibit the double-descent-like behavior typical of these situations; ii) only when $\alpha$ is large enough do they provide consistent and reliable error estimations (we give convergence rates); iii) in the over-parametrized regime $\alpha\!&lt;\!1$ relevant to modern machine learning practice, their predictions are
&lt;/p&gt;</description></item><item><title>&#22312;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#22996;&#25176;&#20154;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#26080;&#38480;&#25509;&#36817;&#30340;&#25928;&#26524;&#65307;&#22312;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09721</link><description>&lt;p&gt;
&#35828;&#26381;&#19968;&#20301;&#23398;&#20064;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Persuading a Learning Agent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09721
&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#22996;&#25176;&#20154;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#26080;&#38480;&#25509;&#36817;&#30340;&#25928;&#26524;&#65307;&#22312;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#65288;&#26356;&#19968;&#33324;&#22320;&#65292;&#20219;&#20309;&#20855;&#26377;&#23436;&#20840;&#20449;&#24687;&#30340;&#24191;&#20041;&#22996;&#25176;-&#20195;&#29702;&#38382;&#39064;&#65289;&#65292;&#20854;&#20013;&#22996;&#25176;&#20154;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#20195;&#29702;&#20154;&#20351;&#29992;&#31639;&#27861;&#26469;&#23398;&#20064;&#22914;&#20309;&#23545;&#22996;&#25176;&#20154;&#30340;&#20449;&#21495;&#20570;&#20986;&#21709;&#24212;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31616;&#21270;&#20026;&#19968;&#20010;&#19968;&#27425;&#24615;&#30340;&#24191;&#20041;&#22996;&#25176;-&#20195;&#29702;&#38382;&#39064;&#65292;&#20195;&#29702;&#20154;&#36817;&#20284;&#22320;&#26368;&#20339;&#21709;&#24212;&#12290;&#36890;&#36807;&#36825;&#20010;&#31616;&#21270;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#65306;&#22914;&#26524;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#65292;&#21017;&#22996;&#25176;&#20154;&#21487;&#20197;&#20445;&#35777;&#20854;&#25928;&#29992;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#20043;&#38388;&#21487;&#20197;&#26080;&#38480;&#25509;&#36817;&#65307;&#22914;&#26524;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#65292;&#21017;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#22996;&#25176;&#20154;&#22312;&#23398;&#20064;&#27169;&#22411;&#19982;&#38750;&#23398;&#20064;&#27169;&#22411;&#20013;&#21487;&#20197;&#33719;&#24471;&#30340;&#25928;&#29992;&#20043;&#38388;&#30340;&#24046;&#36317;&#26159;&#26377;&#30028;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09721v1 Announce Type: cross  Abstract: We study a repeated Bayesian persuasion problem (and more generally, any generalized principal-agent problem with complete information) where the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal's signals. We reduce this problem to a one-shot generalized principal-agent problem with an approximately-best-responding agent. This reduction allows us to show that: if the agent uses contextual no-regret learning algorithms, then the principal can guarantee a utility that is arbitrarily close to the principal's optimal utility in the classic non-learning model with commitment; if the agent uses contextual no-swap-regret learning algorithms, then the principal cannot obtain any utility significantly more than the optimal utility in the non-learning model with commitment. The difference between the principal's obtainable utility in the learning model and the non-learning model is bound
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InfoRM&#30340;&#22870;&#21169;&#24314;&#27169;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#30446;&#26631;&#21644;&#27169;&#22411;&#22797;&#26434;&#24230;&#35843;&#33410;&#26426;&#21046;&#65292;&#35299;&#20915;&#20102;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#38598;&#25104;&#32858;&#31867;&#20559;&#24046;&#24471;&#20998;&#65288;ICDS&#65289;&#26469;&#26816;&#27979;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.09345</link><description>&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#35770;&#22870;&#21169;&#24314;&#27169;&#26469;&#20943;&#36731;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Mitigating Reward Hacking via Information-Theoretic Reward Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InfoRM&#30340;&#22870;&#21169;&#24314;&#27169;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#30446;&#26631;&#21644;&#27169;&#22411;&#22797;&#26434;&#24230;&#35843;&#33410;&#26426;&#21046;&#65292;&#35299;&#20915;&#20102;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#38598;&#25104;&#32858;&#31867;&#20559;&#24046;&#24471;&#20998;&#65288;ICDS&#65289;&#26469;&#26816;&#27979;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#20013;&#30340;&#25104;&#21151;&#22312;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#26041;&#38754;&#65292;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;&#65292;&#20063;&#34987;&#31216;&#20026;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#20027;&#35201;&#28304;&#20110;&#22870;&#21169;&#24314;&#27169;&#30340;&#23616;&#38480;&#24615;&#65292;&#21363;&#22870;&#21169;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#20559;&#22909;&#25968;&#25454;&#38598;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#20449;&#24687;&#35770;&#30340;&#35270;&#35282;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25512;&#24191;&#21644;&#40065;&#26834;&#30340;&#22870;&#21169;&#24314;&#27169;&#26694;&#26550;&#65292;&#31216;&#20026;InfoRM&#65292;&#36890;&#36807;&#24341;&#20837;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#30446;&#26631;&#26469;&#36807;&#28388;&#20986;&#19981;&#30456;&#20851;&#30340;&#20449;&#24687;&#65292;&#24182;&#24320;&#21457;&#19968;&#31181;&#27169;&#22411;&#22797;&#26434;&#24230;&#35843;&#33410;&#26426;&#21046;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#20102;&#36807;&#24230;&#20248;&#21270;&#19982;&#28508;&#21464;&#37327;&#31354;&#38388;&#30340;&#24322;&#24120;&#20540;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#23558;InfoRM&#20316;&#20026;&#26816;&#27979;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;&#21463;&#21040;&#36825;&#19968;&#21457;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38598;&#25104;&#32858;&#31867;&#20559;&#24046;&#24471;&#20998;&#65288;ICDS&#65289;&#65292;&#29992;&#20110;&#37327;&#21270;&#36807;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09345v1 Announce Type: cross Abstract: Despite the success of reinforcement learning from human feedback (RLHF) in aligning language models with human values, reward hacking, also termed reward overoptimization, remains a critical challenge, which primarily stems from limitations in reward modeling, i.e., generalizability of the reward model and inconsistency in the preference dataset. In this work, we tackle this problem from an information theoretic-perspective, and propose a generalizable and robust framework for reward modeling, namely InfoRM, by introducing a variational information bottleneck objective to filter out irrelevant information and developing a mechanism for model complexity modulation. Notably, we further identify a correlation between overoptimization and outliers in the latent space, establishing InfoRM as a promising tool for detecting reward overoptimization. Inspired by this finding, we propose the Integrated Cluster Deviation Score (ICDS), which quant
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#29992;&#20110;&#20174;&#22270;&#20687;&#30340;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;</title><link>https://arxiv.org/abs/2402.07419</link><description>&lt;p&gt;
&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#36275;&#20197;&#20174;&#20219;&#20309;&#22240;&#26524;&#25928;&#24212;&#27979;&#24230;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#29992;&#20110;&#20174;&#22270;&#20687;&#30340;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20174;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#23384;&#22312;&#35745;&#31639;&#22240;&#26524;&#25928;&#24212;&#30340;&#21487;&#38752;&#19988;&#23436;&#22791;&#30340;&#31639;&#27861;&#65292;&#20294;&#20854;&#20013;&#35768;&#22810;&#31639;&#27861;&#38656;&#35201;&#26174;&#24335;&#35775;&#38382;&#35266;&#27979;&#20998;&#24067;&#19978;&#30340;&#26465;&#20214;&#20284;&#28982;&#65292;&#32780;&#22312;&#39640;&#32500;&#22330;&#26223;&#20013;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#20272;&#35745;&#36825;&#20123;&#20284;&#28982;&#26159;&#22256;&#38590;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#27169;&#22411;&#27169;&#25311;&#22240;&#26524;&#20851;&#31995;&#65292;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#20013;&#27809;&#26377;&#19968;&#20010;&#21487;&#20197;&#24212;&#29992;&#20110;&#36890;&#29992;&#22330;&#26223;&#65292;&#20363;&#22914;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#22270;&#20687;&#25968;&#25454;&#30340;&#22240;&#26524;&#22270;&#65292;&#25110;&#32773;&#33719;&#24471;&#26465;&#20214;&#24178;&#39044;&#26679;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20219;&#24847;&#22240;&#26524;&#22270;&#19979;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#22522;&#20110;&#27492;&#32467;&#26524;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#37319;&#26679;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference from observational data has recently found many applications in machine learning. While sound and complete algorithms exist to compute causal effects, many of these algorithms require explicit access to conditional likelihoods over the observational distribution, which is difficult to estimate in the high-dimensional regime, such as with images. To alleviate this issue, researchers have approached the problem by simulating causal relations with neural models and obtained impressive results. However, none of these existing approaches can be applied to generic scenarios such as causal graphs on image data with latent confounders, or obtain conditional interventional samples. In this paper, we show that any identifiable causal effect given an arbitrary causal graph can be computed through push-forward computations of conditional generative models. Based on this result, we devise a diffusion-based approach to sample from any (conditional) interventional distribution on ima
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06963</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;
&lt;/p&gt;
&lt;p&gt;
Tree Ensembles for Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#19978;&#20449;&#24515;&#30028;&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#65292;&#25972;&#21512;&#21040;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#12290;&#36890;&#36807;&#20351;&#29992;&#27969;&#34892;&#30340;&#26641;&#38598;&#25104;&#26041;&#27861;XGBoost&#36827;&#34892;&#22810;&#27425;&#23454;&#39564;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;&#24403;&#24212;&#29992;&#20110;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#36947;&#36335;&#32593;&#32476;&#23548;&#33322;&#30340;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#26102;&#65292;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework for contextual multi-armed bandits based on tree ensembles. Our framework integrates two widely used bandit methods, Upper Confidence Bound and Thompson Sampling, for both standard and combinatorial settings. We demonstrate the effectiveness of our framework via several experimental studies, employing XGBoost, a popular tree ensemble method. Compared to state-of-the-art methods based on neural networks, our methods exhibit superior performance in terms of both regret minimization and computational runtime, when applied to benchmark datasets and the real-world application of navigation over road networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#26469;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06160</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06160
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#26469;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#29616;&#20195;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#65292;&#20854;&#20013;&#36890;&#36807;&#26368;&#23567;&#21270;&#29305;&#23450;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35757;&#32451;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20197;&#23398;&#20064;&#39044;&#27979;&#20998;&#24067;&#19978;&#30340;&#20803;&#20998;&#24067;&#12290;&#23613;&#31649;&#29616;&#26377;&#26041;&#27861;&#22312;&#32463;&#39564;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#24378;&#22823;&#65292;&#20294;Bengs&#31561;&#20154;&#30340;&#26368;&#36817;&#30740;&#31350;&#21457;&#29616;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19968;&#20010;&#26681;&#26412;&#32570;&#38519;&#65306;&#21363;&#20351;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#65292;&#23398;&#20064;&#21040;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#12290;&#36890;&#36807;&#25552;&#20379;&#25991;&#29486;&#20013;&#19968;&#31867;&#24191;&#27867;&#20351;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36825;&#20010;&#35266;&#23519;&#30340;&#35777;&#23454;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;EDL&#26041;&#27861;&#26412;&#36136;&#19978;&#36890;&#36807;&#26368;&#23567;&#21270;&#20998;&#24067;&#19982;&#19982;&#26679;&#26412;&#22823;&#23567;&#26080;&#20851;&#30340;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#29305;&#23450;&#24046;&#24322;&#24230;&#37327;&#26469;&#35757;&#32451;&#20803;&#20998;&#24067;&#65292;&#20174;&#32780;&#20135;&#29983;&#38169;&#35823;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#29702;&#35770;&#21407;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#23558;&#20854;&#24314;&#27169;&#20026;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#28151;&#21512;&#29289;&#26469;&#23398;&#20064;&#19968;&#33268;&#30446;&#26631;&#20998;&#24067;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;EDL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores a modern predictive uncertainty estimation approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their strong empirical performance, recent studies by Bengs et al. identify a fundamental pitfall of the existing methods: the learned epistemic uncertainty may not vanish even in the infinite-sample limit. We corroborate the observation by providing a unifying view of a class of widely used objectives from the literature. Our analysis reveals that the EDL methods essentially train a meta distribution by minimizing a certain divergence measure between the distribution and a sample-size-independent target distribution, resulting in spurious epistemic uncertainty. Grounded in theoretical principles, we propose learning a consistent target distribution by modeling it with a mixture of Dirichlet distributions and lear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#26080;&#31351;&#29366;&#24577;&#24179;&#22343;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#31639;&#27861;&#36827;&#34892;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#33391;&#22909;&#30340;&#21021;&#22987;&#31574;&#30053;&#26465;&#20214;&#19979;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#20197;$O(1/\sqrt{T})$&#30340;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#12290;&#21516;&#26102;&#65292;&#23545;&#20110;&#19968;&#31867;&#22823;&#31867;&#25490;&#38431;MDPs&#65292;MaxWeight&#31574;&#30053;&#36275;&#20197;&#28385;&#36275;&#21021;&#22987;&#31574;&#30053;&#35201;&#27714;&#24182;&#23454;&#29616;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2402.05274</link><description>&lt;p&gt;
&#26080;&#31351;&#29366;&#24577;&#24179;&#22343;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence for Natural Policy Gradient on Infinite-State Average-Reward Markov Decision Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05274
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26080;&#31351;&#29366;&#24577;&#24179;&#22343;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#31639;&#27861;&#36827;&#34892;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#33391;&#22909;&#30340;&#21021;&#22987;&#31574;&#30053;&#26465;&#20214;&#19979;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#20197;$O(1/\sqrt{T})$&#30340;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#12290;&#21516;&#26102;&#65292;&#23545;&#20110;&#19968;&#31867;&#22823;&#31867;&#25490;&#38431;MDPs&#65292;MaxWeight&#31574;&#30053;&#36275;&#20197;&#28385;&#36275;&#21021;&#22987;&#31574;&#30053;&#35201;&#27714;&#24182;&#23454;&#29616;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#31351;&#29366;&#24577;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#22312;&#24314;&#27169;&#21644;&#20248;&#21270;&#21508;&#31181;&#24037;&#31243;&#38382;&#39064;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#29615;&#22659;&#20013;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#31639;&#27861;&#26469;&#23398;&#20064;&#21644;&#20248;&#21270;&#36825;&#20123;MDPs&#12290;&#22312;&#35768;&#22810;&#27969;&#34892;&#30340;&#22522;&#20110;&#31574;&#30053;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#22914;&#33258;&#28982;&#28436;&#21592;-&#35780;&#35770;&#23478;&#12289;TRPO&#21644;PPO&#65292;&#37117;&#22522;&#20110;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#31639;&#27861;&#12290;&#36825;&#20123;RL&#31639;&#27861;&#30340;&#25910;&#25947;&#32467;&#26524;&#24314;&#31435;&#22312;NPG&#31639;&#27861;&#30340;&#25910;&#25947;&#32467;&#26524;&#19978;&#12290;&#28982;&#32780;&#65292;&#25152;&#26377;&#29616;&#26377;&#30340;NPG&#31639;&#27861;&#25910;&#25947;&#24615;&#32467;&#26524;&#22343;&#20165;&#38480;&#20110;&#26377;&#38480;&#29366;&#24577;&#35774;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;NPG&#31639;&#27861;&#22312;&#26080;&#31351;&#29366;&#24577;&#24179;&#22343;&#22870;&#21169;MDPs&#20013;&#30340;&#39318;&#20010;&#25910;&#25947;&#36895;&#29575;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;$O(1/\sqrt{T})$&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#22914;&#26524;NPG&#31639;&#27861;&#20197;&#33391;&#22909;&#30340;&#21021;&#22987;&#31574;&#30053;&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#22823;&#31867;&#25490;&#38431;MDPs&#30340;&#24773;&#20917;&#19979;&#65292;MaxWeight&#31574;&#30053;&#36275;&#22815;&#28385;&#36275;&#25105;&#20204;&#30340;&#21021;&#22987;&#31574;&#30053;&#35201;&#27714;&#65292;&#24182;&#23454;&#29616;&#20102;$O(1/...
&lt;/p&gt;
&lt;p&gt;
Infinite-state Markov Decision Processes (MDPs) are essential in modeling and optimizing a wide variety of engineering problems. In the reinforcement learning (RL) context, a variety of algorithms have been developed to learn and optimize these MDPs. At the heart of many popular policy-gradient based learning algorithms, such as natural actor-critic, TRPO, and PPO, lies the Natural Policy Gradient (NPG) algorithm. Convergence results for these RL algorithms rest on convergence results for the NPG algorithm. However, all existing results on the convergence of the NPG algorithm are limited to finite-state settings.   We prove the first convergence rate bound for the NPG algorithm for infinite-state average-reward MDPs, proving a $O(1/\sqrt{T})$ convergence rate, if the NPG algorithm is initialized with a good initial policy. Moreover, we show that in the context of a large class of queueing MDPs, the MaxWeight policy suffices to satisfy our initial-policy requirement and achieve a $O(1/\
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;QGFN&#65292;&#36890;&#36807;&#23558;GFN&#31574;&#30053;&#19982;&#21160;&#20316;&#20540;&#20272;&#35745;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#29983;&#25104;&#26356;&#22810;&#39640;&#22870;&#21169;&#30340;&#26679;&#26412;&#32780;&#19981;&#29306;&#29298;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05234</link><description>&lt;p&gt;
QGFN:&#20855;&#26377;&#21160;&#20316;&#20540;&#30340;&#21487;&#25511;&#36138;&#23146;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
QGFN: Controllable Greediness with Action Values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;QGFN&#65292;&#36890;&#36807;&#23558;GFN&#31574;&#30053;&#19982;&#21160;&#20316;&#20540;&#20272;&#35745;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#29983;&#25104;&#26356;&#22810;&#39640;&#22870;&#21169;&#30340;&#26679;&#26412;&#32780;&#19981;&#29306;&#29298;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets;GFNs&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#32452;&#21512;&#23545;&#35937;&#30340;&#22522;&#20110;&#22870;&#21169;/&#33021;&#37327;&#30340;&#29983;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#21270;&#21644;&#39640;&#25928;&#30340;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#20559;&#21521;&#20110;&#29983;&#25104;&#39640;&#25928;&#26679;&#26412;&#30340;GFNs&#24182;&#19981;&#23481;&#26131;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;GFNs&#21644;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#23558;GFN&#31574;&#30053;&#19982;&#21160;&#20316;&#20540;&#20272;&#35745;$Q$&#30456;&#32467;&#21512;&#65292;&#20174;&#32780;&#21019;&#24314;&#21487;&#20197;&#36890;&#36807;&#28151;&#21512;&#21442;&#25968;&#25511;&#21046;&#30340;&#36138;&#23146;&#37319;&#26679;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;QGFN&#30340;&#21464;&#20307;&#33021;&#22815;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#25913;&#21892;&#29983;&#25104;&#39640;&#22870;&#21169;&#26679;&#26412;&#30340;&#25968;&#37327;&#65292;&#21516;&#26102;&#19981;&#29306;&#29298;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets; GFNs) are a family of reward/energy-based generative methods for combinatorial objects, capable of generating diverse and high-utility samples. However, biasing GFNs towards producing high-utility samples is non-trivial. In this work, we leverage connections between GFNs and reinforcement learning (RL) and propose to combine the GFN policy with an action-value estimate, $Q$, to create greedier sampling policies which can be controlled by a mixing parameter. We show that several variants of the proposed method, QGFN, are able to improve on the number of high-reward samples generated in a variety of tasks without sacrificing diversity.
&lt;/p&gt;</description></item><item><title>PowerGraph&#26159;&#19968;&#20010;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30005;&#32593;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23454;&#29616;&#30005;&#21147;&#32593;&#26684;&#26029;&#30005;&#30340;&#22312;&#32447;&#26816;&#27979;&#12290;</title><link>https://arxiv.org/abs/2402.02827</link><description>&lt;p&gt;
PowerGraph: &#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30005;&#32593;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
PowerGraph: A power grid benchmark dataset for graph neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02827
&lt;/p&gt;
&lt;p&gt;
PowerGraph&#26159;&#19968;&#20010;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30005;&#32593;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23454;&#29616;&#30005;&#21147;&#32593;&#26684;&#26029;&#30005;&#30340;&#22312;&#32447;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#20849;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22522;&#20934;&#25968;&#25454;&#38598;&#26377;&#21161;&#20110;&#20351;&#29992;GNN&#65292;&#24182;&#22686;&#24378;GNN&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#30446;&#21069;&#65292;&#31038;&#21306;&#20013;&#32570;&#20047;&#29992;&#20110;GNN&#24212;&#29992;&#30340;&#30005;&#21147;&#32593;&#26684;&#20844;&#20849;&#25968;&#25454;&#38598;&#12290;&#20107;&#23454;&#19978;&#65292;&#19982;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30456;&#27604;&#65292;GNN&#21487;&#20197;&#28508;&#22312;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#30005;&#21147;&#32593;&#26684;&#29616;&#35937;&#12290;&#30005;&#21147;&#32593;&#26684;&#26159;&#22797;&#26434;&#30340;&#24037;&#31243;&#32593;&#32476;&#65292;&#22825;&#28982;&#36866;&#21512;&#20110;&#22270;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;GNN&#26377;&#28508;&#21147;&#25429;&#25417;&#21040;&#30005;&#21147;&#32593;&#26684;&#30340;&#34892;&#20026;&#65292;&#32780;&#19981;&#29992;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#20110;&#32423;&#32852;&#25925;&#38556;&#20107;&#20214;&#30340;&#22270;&#25968;&#25454;&#38598;&#65292;&#36825;&#26159;&#23548;&#33268;&#30005;&#21147;&#32593;&#26684;&#26029;&#30005;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#21382;&#21490;&#26029;&#30005;&#25968;&#25454;&#38598;&#31232;&#32570;&#19988;&#19981;&#23436;&#25972;&#12290;&#36890;&#24120;&#36890;&#36807;&#35745;&#31639;&#26114;&#36149;&#30340;&#31163;&#32447;&#32423;&#32852;&#25925;&#38556;&#27169;&#25311;&#26469;&#35780;&#20272;&#33030;&#24369;&#24615;&#21644;&#35782;&#21035;&#20851;&#38190;&#32452;&#20214;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#22312;&#32447;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Public Graph Neural Networks (GNN) benchmark datasets facilitate the use of GNN and enhance GNN applicability to diverse disciplines. The community currently lacks public datasets of electrical power grids for GNN applications. Indeed, GNNs can potentially capture complex power grid phenomena over alternative machine learning techniques. Power grids are complex engineered networks that are naturally amenable to graph representations. Therefore, GNN have the potential for capturing the behavior of power grids over alternative machine learning techniques. To this aim, we develop a graph dataset for cascading failure events, which are the major cause of blackouts in electric power grids. Historical blackout datasets are scarce and incomplete. The assessment of vulnerability and the identification of critical components are usually conducted via computationally expensive offline simulations of cascading failures. Instead, we propose using machine learning models for the online detection of
&lt;/p&gt;</description></item><item><title>Neur2BiLO&#26159;&#19968;&#20010;&#38024;&#23545;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#24341;&#20837;&#21040;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#20013;&#65292;&#21487;&#20197;&#24555;&#36895;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02552</link><description>&lt;p&gt;
Neur2BiLO: &#31070;&#32463;&#21452;&#23618;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Neur2BiLO: Neural Bilevel Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02552
&lt;/p&gt;
&lt;p&gt;
Neur2BiLO&#26159;&#19968;&#20010;&#38024;&#23545;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#24341;&#20837;&#21040;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#20013;&#65292;&#21487;&#20197;&#24555;&#36895;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22788;&#29702;&#23884;&#22871;&#38382;&#39064;&#65292;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#39046;&#23548;&#32773;&#39318;&#20808;&#20570;&#20986;&#20915;&#31574;&#20197;&#26368;&#23567;&#21270;&#33258;&#24049;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#36861;&#38543;&#32773;&#30340;&#26368;&#22909;&#21453;&#24212;&#12290;&#25972;&#25968;&#21464;&#37327;&#32422;&#26463;&#30340;&#21452;&#23618;&#38382;&#39064;&#29305;&#21035;&#38590;&#20197;&#22788;&#29702;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#29992;&#20110;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#21452;&#23618;&#20248;&#21270;&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#20294;&#23427;&#20204;&#22312;&#38382;&#39064;&#35268;&#27169;&#36739;&#22823;&#26102;&#24448;&#24448;&#26080;&#27861;&#25193;&#23637;&#65292;&#24182;&#19988;&#38590;&#20197;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#24773;&#20917;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#38382;&#39064;&#29305;&#23450;&#30340;&#31639;&#27861;&#65288;&#31934;&#30830;&#21644;&#21551;&#21457;&#24335;&#65289;&#23616;&#38480;&#20110;&#29305;&#23450;&#33539;&#22260;&#12290;&#22312;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#29615;&#22659;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;Neur2BiLO&#23558;&#36890;&#36807;&#30417;&#30563;&#22238;&#24402;&#35757;&#32451;&#30340;&#39046;&#23548;&#32773;&#25110;&#36861;&#38543;&#32773;&#30340;&#20540;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#23884;&#20837;&#21040;&#26131;&#20110;&#35299;&#20915;&#30340;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#20013;&#12290; Neur2BiLO&#20316;&#20026;&#19968;&#31181;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#21452;&#23618;&#32972;&#21253;&#25318;&#25130;&#38382;&#39064;&#65292;&#21363;&#8220;&#20851;&#38190;n&#20010;&#38382;&#39064;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization deals with nested problems in which a leader takes the first decision to minimize their objective function while accounting for a follower's best-response reaction. Constrained bilevel problems with integer variables are particularly notorious for their hardness. While exact solvers have been proposed for mixed-integer linear bilevel optimization, they tend to scale poorly with problem size and are hard to generalize to the non-linear case. On the other hand, problem-specific algorithms (exact and heuristic) are limited in scope. Under a data-driven setting in which similar instances of a bilevel problem are solved routinely, our proposed framework, Neur2BiLO, embeds a neural network approximation of the leader's or follower's value function, trained via supervised regression, into an easy-to-solve mixed-integer program. Neur2BiLO serves as a heuristic that produces high-quality solutions extremely fast for the bilevel knapsack interdiction problem, the "critical n
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01763</link><description>&lt;p&gt;
&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36935;&#19978;&#21521;&#37327;&#25968;&#25454;&#24211;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
When Large Language Models Meet Vector Databases: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#22312;&#20154;&#31867;&#25991;&#23383;&#22788;&#29702;&#21644;&#29983;&#25104;&#26041;&#38754;&#24320;&#21551;&#20102;&#26032;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#30340;&#26174;&#33879;&#22686;&#38271;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30528;&#21253;&#25324;&#24187;&#35273;&#12289;&#20559;&#35265;&#12289;&#23454;&#26102;&#30693;&#35782;&#26356;&#26032;&#20197;&#21450;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#23454;&#26045;&#21644;&#32500;&#25252;&#30340;&#39640;&#25104;&#26412;&#31561;&#37325;&#35201;&#25361;&#25112;&#12290;&#32780;&#21478;&#19968;&#31181;&#26085;&#30410;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#21521;&#37327;&#25968;&#25454;&#24211;&#21017;&#20026;&#36825;&#20123;&#25361;&#25112;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20123;&#25968;&#25454;&#24211;&#25797;&#38271;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#19988;&#23545;&#20110;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#21644;&#35821;&#20041;&#25628;&#32034;&#31561;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25972;&#21512;&#65292;&#23427;&#20204;&#26174;&#33879;&#22686;&#24378;&#20102;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#26356;&#26377;&#25928;&#22320;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#36827;&#34892;&#20102;&#28145;&#20837;&#32780;&#29420;&#29305;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent burst in Large Language Models has opened new frontiers in human-like text processing and generation. However, alongside their remarkable growth, Large Language Models have encountered critical challenges including issues of hallucination, bias, real-time knowledge updates, and the high costs of implementation and maintenance in commercial settings. Vector Databases, another increasingly popular tool, offer potential solutions to these challenges. These databases are adept at handling high-dimensional data and are crucial for tasks such as efficient information retrieval and semantic search. By integrating with Large Language Models, they significantly enhance AI systems' ability to manage and utilize diverse data more effectively. This survey paper provides an in-depth and unique analysis of the intersection between Large Language Models and Vector Databases.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#25552;&#20986;&#20102;&#20174;&#19968;&#32452;&#21516;&#26679;&#22909;&#30340;&#27169;&#22411;&#20013;&#36873;&#25321;&#20855;&#22791;&#39044;&#26399;&#35299;&#37322;&#30340;&#20934;&#30830;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20197;&#21152;&#24378;&#29289;&#29702;&#23450;&#24459;&#24182;&#28385;&#36275;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#35201;&#27714;&#65292;&#24182;&#20026;&#23558;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25972;&#21512;&#21040;&#31185;&#23398;&#39046;&#22495;&#20570;&#20986;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2402.00347</link><description>&lt;p&gt;
&#26469;&#33258;&#25968;&#25454;&#39537;&#21160;&#21644;&#39046;&#22495;&#39537;&#21160;&#35270;&#35282;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22810;&#26679;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Diverse Explanations from Data-driven and Domain-driven Perspectives for Machine Learning Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#25552;&#20986;&#20102;&#20174;&#19968;&#32452;&#21516;&#26679;&#22909;&#30340;&#27169;&#22411;&#20013;&#36873;&#25321;&#20855;&#22791;&#39044;&#26399;&#35299;&#37322;&#30340;&#20934;&#30830;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20197;&#21152;&#24378;&#29289;&#29702;&#23450;&#24459;&#24182;&#28385;&#36275;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#35201;&#27714;&#65292;&#24182;&#20026;&#23558;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25972;&#21512;&#21040;&#31185;&#23398;&#39046;&#22495;&#20570;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#37322;&#26159;&#37325;&#35201;&#30340;&#65292;&#29305;&#21035;&#26159;&#22312;&#21270;&#23398;&#12289;&#29983;&#29289;&#21644;&#29289;&#29702;&#31561;&#31185;&#23398;&#39046;&#22495;&#20013;&#65292;&#23427;&#20204;&#25351;&#23548;&#26410;&#26469;&#30340;&#23454;&#39564;&#23460;&#23454;&#39564;&#21644;&#36164;&#28304;&#38656;&#27714;&#12290;&#36825;&#20123;&#35299;&#37322;&#21487;&#20197;&#20174;&#35757;&#32451;&#33391;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;&#25968;&#25454;&#39537;&#21160;&#35270;&#35282;&#65289;&#25110;&#29305;&#23450;&#39046;&#22495;&#30693;&#35782;&#65288;&#39046;&#22495;&#39537;&#21160;&#35270;&#35282;&#65289;&#20013;&#33719;&#24471;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20934;&#30830;&#20294;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#20855;&#26377;&#29305;&#23450;&#38656;&#27714;&#12289;&#24895;&#26395;&#25110;&#30446;&#26631;&#30340;&#21508;&#26041;&#23384;&#22312;&#19981;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#36825;&#20123;&#19981;&#19968;&#33268;&#24615;&#30340;&#20851;&#27880;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20174;&#19968;&#32452;&#21516;&#26679;&#22909;&#30340;&#27169;&#22411;&#20013;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#39044;&#26399;&#35299;&#37322;&#30340;&#20934;&#30830;&#27169;&#22411;&#65292;&#20197;&#21152;&#24378;&#29289;&#29702;&#23450;&#24459;&#24182;&#28385;&#36275;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#35201;&#27714;&#65292;&#36825;&#20123;&#27169;&#22411;&#20063;&#34987;&#31216;&#20026;&#25289;&#35799;&#23391;&#65288;Rashomon&#65289;&#27169;&#22411;&#38598;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20419;&#36827;&#23545;&#36825;&#20123;&#19981;&#19968;&#33268;&#24615;&#30340;&#20840;&#38754;&#29702;&#35299;&#65292;&#24182;&#26368;&#32456;&#20026;&#23558;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#25972;&#21512;&#21040;&#31185;&#23398;&#39046;&#22495;&#20570;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explanations of machine learning models are important, especially in scientific areas such as chemistry, biology, and physics, where they guide future laboratory experiments and resource requirements. These explanations can be derived from well-trained machine learning models (data-driven perspective) or specific domain knowledge (domain-driven perspective). However, there exist inconsistencies between these perspectives due to accurate yet misleading machine learning models and various stakeholders with specific needs, wants, or aims. This paper calls attention to these inconsistencies and suggests a way to find an accurate model with expected explanations that reinforce physical laws and meet stakeholders' requirements from a set of equally-good models, also known as Rashomon sets. Our goal is to foster a comprehensive understanding of these inconsistencies and ultimately contribute to the integration of eXplainable Artificial Intelligence (XAI) into scientific domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#26041;&#26696;&#65292;&#36890;&#36807;&#31616;&#21270;&#27169;&#22411;&#30340;&#28508;&#22312;&#21160;&#24577;&#65292;&#20351;&#24471;&#19990;&#30028;&#27169;&#22411;&#26356;&#21152;&#21487;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#22312;&#26410;&#26469;&#28508;&#22312;&#29366;&#24577;&#39044;&#27979;&#12289;&#35270;&#39057;&#39044;&#27979;&#21644;&#35268;&#21010;&#20013;&#23637;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.17835</link><description>&lt;p&gt;
&#29992;&#31616;&#21333;&#30340;&#19990;&#30028;&#27169;&#22411;&#39044;&#27979;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
Predicting the Future with Simple World Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#26041;&#26696;&#65292;&#36890;&#36807;&#31616;&#21270;&#27169;&#22411;&#30340;&#28508;&#22312;&#21160;&#24577;&#65292;&#20351;&#24471;&#19990;&#30028;&#27169;&#22411;&#26356;&#21152;&#21487;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#22312;&#26410;&#26469;&#28508;&#22312;&#29366;&#24577;&#39044;&#27979;&#12289;&#35270;&#39057;&#39044;&#27979;&#21644;&#35268;&#21010;&#20013;&#23637;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19990;&#30028;&#27169;&#22411;&#21487;&#20197;&#29992;&#32039;&#20945;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#28508;&#22312;&#39640;&#32500;&#24230;&#20687;&#32032;&#35266;&#23519;&#65292;&#20174;&#32780;&#20351;&#24471;&#23545;&#29615;&#22659;&#21160;&#24577;&#24314;&#27169;&#25104;&#20026;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#25512;&#23548;&#20986;&#30340;&#28508;&#22312;&#21160;&#24577;&#21487;&#33021;&#20173;&#28982;&#38750;&#24120;&#22797;&#26434;&#12290;&#36890;&#36807;&#31616;&#21270;&#27169;&#22411;&#26469;&#25277;&#35937;&#29615;&#22659;&#30340;&#21160;&#24577;&#21487;&#20197;&#24102;&#26469;&#20960;&#20010;&#22909;&#22788;&#12290;&#22914;&#26524;&#28508;&#22312;&#21160;&#24577;&#31616;&#21333;&#65292;&#27169;&#22411;&#21487;&#33021;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#30340;&#36716;&#25442;&#65292;&#24182;&#21457;&#29616;&#26377;&#29992;&#30340;&#29615;&#22659;&#29366;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#19990;&#30028;&#27169;&#22411;&#28508;&#22312;&#21160;&#24577;&#30340;&#27491;&#21017;&#21270;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#31616;&#32422;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#65288;PLSM&#65289;&#65292;&#26368;&#23567;&#21270;&#20102;&#28508;&#22312;&#29366;&#24577;&#19982;&#20854;&#20043;&#38388;&#20135;&#29983;&#30340;&#21160;&#24577;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#36825;&#20351;&#24471;&#21160;&#24577;&#22312;&#29366;&#24577;&#19978;&#20855;&#26377;&#36719;&#24615;&#19981;&#21464;&#24615;&#65292;&#24182;&#20351;&#24471;&#26234;&#33021;&#20307;&#34892;&#20026;&#30340;&#24433;&#21709;&#26356;&#21152;&#21487;&#39044;&#27979;&#12290;&#25105;&#20204;&#23558;PLSM&#19982;&#29992;&#20110;i)&#26410;&#26469;&#28508;&#22312;&#29366;&#24577;&#39044;&#27979;&#12289;ii)&#35270;&#39057;&#39044;&#27979;&#21644;iii)&#35268;&#21010;&#30340;&#19977;&#31181;&#19981;&#21516;&#27169;&#22411;&#31867;&#32467;&#21512;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#27169;&#22411;&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
World models can represent potentially high-dimensional pixel observations in compact latent spaces, making it tractable to model the dynamics of the environment. However, the latent dynamics inferred by these models may still be highly complex. Abstracting the dynamics of the environment with simple models can have several benefits. If the latent dynamics are simple, the model may generalize better to novel transitions, and discover useful latent representations of environment states. We propose a regularization scheme that simplifies the world model's latent dynamics. Our model, the Parsimonious Latent Space Model (PLSM), minimizes the mutual information between latent states and the dynamics that arise between them. This makes the dynamics softly state-invariant, and the effects of the agent's actions more predictable. We combine the PLSM with three different model classes used for i) future latent state prediction, ii) video prediction, and iii) planning. We find that our regulariz
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.16054</link><description>&lt;p&gt;
&#29992;&#20110;&#35780;&#20272;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#30340;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;
&lt;/p&gt;
&lt;p&gt;
Metric Space Magnitude for Evaluating the Diversity of Latent Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16054
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24230;&#37327;&#31354;&#38388;&#30340;&#22823;&#23567;&#26159;&#19968;&#31181;&#36817;&#26399;&#24314;&#31435;&#30340;&#19981;&#21464;&#24615;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#25552;&#20379;&#31354;&#38388;&#30340;&#8220;&#26377;&#25928;&#22823;&#23567;&#8221;&#30340;&#34913;&#37327;&#65292;&#24182;&#25429;&#25417;&#21040;&#35768;&#22810;&#20960;&#20309;&#23646;&#24615;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#20869;&#22312;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#24418;&#24335;&#21270;&#20102;&#26377;&#38480;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#20989;&#25968;&#20043;&#38388;&#30340;&#26032;&#39062;&#19981;&#30456;&#20284;&#24615;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#25968;&#25454;&#25200;&#21160;&#19979;&#20445;&#35777;&#31283;&#23450;&#65292;&#21487;&#20197;&#39640;&#25928;&#35745;&#31639;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#28508;&#22312;&#34920;&#31034;&#36827;&#34892;&#20005;&#26684;&#30340;&#22810;&#23610;&#24230;&#27604;&#36739;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#23454;&#39564;&#22871;&#20214;&#20013;&#30340;&#23454;&#29992;&#24615;&#21644;&#21331;&#36234;&#24615;&#33021;&#65292;&#21253;&#25324;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#12289;&#27169;&#24335;&#23849;&#28291;&#26816;&#27979;&#20197;&#21450;&#29992;&#20110;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The magnitude of a metric space is a recently-established invariant, providing a measure of the 'effective size' of a space across multiple scales while also capturing numerous geometrical properties. We develop a family of magnitude-based measures of the intrinsic diversity of latent representations, formalising a novel notion of dissimilarity between magnitude functions of finite metric spaces. Our measures are provably stable under perturbations of the data, can be efficiently calculated, and enable a rigorous multi-scale comparison of latent representations. We show the utility and superior performance of our measures in an experimental suite that comprises different domains and tasks, including the evaluation of diversity, the detection of mode collapse, and the evaluation of generative models for text, image, and graph data.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#22270;&#21367;&#31215;&#26469;&#25913;&#36827;Transformer&#27169;&#22411;&#20013;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#22810;&#20010;&#39046;&#22495;&#23637;&#31034;&#20102;&#20854;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2312.04234</link><description>&lt;p&gt;
&#22270;&#21367;&#31215;&#22312;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#36215;&#21040;&#20102;&#25913;&#36827;&#30340;&#20316;&#29992;&#65281;&#65288;arXiv&#65306;2312.04234v2 [cs.LG]&#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
Graph Convolutions Enrich the Self-Attention in Transformers!. (arXiv:2312.04234v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.04234
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#22270;&#21367;&#31215;&#26469;&#25913;&#36827;Transformer&#27169;&#22411;&#20013;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#22810;&#20010;&#39046;&#22495;&#23637;&#31034;&#20102;&#20854;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#22240;&#20854;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#32780;&#38395;&#21517;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#31561;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;Transformer&#27169;&#22411;&#38754;&#20020;&#30340;&#25361;&#25112;&#20043;&#19968;&#26159;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#21363;&#34920;&#31034;&#22312;&#21508;&#20010;&#23618;&#20043;&#38388;&#36235;&#20110;&#26080;&#27861;&#21306;&#20998;&#30340;&#20540;&#65292;&#23548;&#33268;&#24615;&#33021;&#20005;&#37325;&#19979;&#38477;&#12290;&#25105;&#20204;&#23558;&#21407;&#22987;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#37322;&#20026;&#19968;&#31181;&#31616;&#21333;&#30340;&#22270;&#28388;&#27874;&#22120;&#65292;&#24182;&#20174;&#22270;&#20449;&#21495;&#22788;&#29702;&#65288;GSP&#65289;&#30340;&#35282;&#24230;&#37325;&#26032;&#35774;&#35745;&#23427;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#22270;&#28388;&#27874;&#22120;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GFSA&#65289;&#65292;&#20197;&#23398;&#20064;&#19968;&#31181;&#26082;&#36890;&#29992;&#21448;&#26377;&#25928;&#30340;&#26426;&#21046;&#65292;&#20854;&#22797;&#26434;&#24230;&#30053;&#39640;&#20110;&#21407;&#22987;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;GFSA&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#22270;&#27169;&#24335;&#20998;&#31867;&#12289;&#35821;&#38899;&#35782;&#21035;&#21644;&#20195;&#30721;&#20998;&#31867;&#31561;&#22810;&#20010;&#39046;&#22495;&#20013;&#25913;&#36827;&#20102;Transformer&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers, renowned for their self-attention mechanism, have achieved state-of-the-art performance across various tasks in natural language processing, computer vision, time-series modeling, etc. However, one of the challenges with deep Transformer models is the oversmoothing problem, where representations across layers converge to indistinguishable values, leading to significant performance degradation. We interpret the original self-attention as a simple graph filter and redesign it from a graph signal processing (GSP) perspective. We propose graph-filter-based self-attention (GFSA) to learn a general yet effective one, whose complexity, however, is slightly larger than that of the original self-attention mechanism. We demonstrate that GFSA improves the performance of Transformers in various fields, including computer vision, natural language processing, graph pattern classification, speech recognition, and code classification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#25512;&#29702;&#36807;&#31243;&#35299;&#37322;&#20026;&#23545;&#27604;&#23398;&#20064;&#27169;&#24335;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#36890;&#36807;&#24314;&#31435;&#26799;&#24230;&#19979;&#38477;&#19982;&#33258;&#27880;&#24847;&#26426;&#21046;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#20998;&#26512;&#20102;&#23545;&#24212;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#35774;&#35745;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#35266;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.13220</link><description>&lt;p&gt;
&#20351;&#29992;Transformer&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#19982;&#23545;&#27604;&#23398;&#20064;&#27169;&#24335;&#26159;&#31561;&#20215;&#30340;
&lt;/p&gt;
&lt;p&gt;
In-context Learning with Transformer Is Really Equivalent to a Contrastive Learning Pattern. (arXiv:2310.13220v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13220
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#25512;&#29702;&#36807;&#31243;&#35299;&#37322;&#20026;&#23545;&#27604;&#23398;&#20064;&#27169;&#24335;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#36890;&#36807;&#24314;&#31435;&#26799;&#24230;&#19979;&#38477;&#19982;&#33258;&#27880;&#24847;&#26426;&#21046;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#20998;&#26512;&#20102;&#23545;&#24212;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#35774;&#35745;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#24778;&#20154;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#12290;&#22312;&#32473;&#23450;&#20960;&#20010;&#31034;&#20363;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#21487;&#20197;&#22312;&#19981;&#36827;&#34892;&#20219;&#20309;&#21442;&#25968;&#26356;&#26032;&#30340;&#24773;&#20917;&#19979;&#25191;&#34892;&#26032;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#29702;&#35299;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#26426;&#21046;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#25512;&#29702;&#36807;&#31243;&#35299;&#37322;&#20026;&#23545;&#27604;&#23398;&#20064;&#27169;&#24335;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#26680;&#26041;&#27861;&#24314;&#31435;&#26799;&#24230;&#19979;&#38477;&#19982;&#33258;&#27880;&#24847;&#26426;&#21046;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#22312;&#19968;&#33324;&#20351;&#29992;&#30340;softmax&#27880;&#24847;&#35774;&#32622;&#19979;&#32780;&#19981;&#26159;&#32447;&#24615;&#27880;&#24847;&#35774;&#32622;&#19979;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#23545;&#27604;&#23398;&#20064;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#23545;&#24212;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#35752;&#35770;&#20102;&#22312;&#36825;&#31181;&#23545;&#27604;&#23398;&#20064;&#27169;&#24335;&#19979;&#21487;&#33021;&#30340;&#25913;&#36827;&#65292;&#22522;&#20110;&#36825;&#20123;&#25913;&#36827;&#21487;&#20197;&#36827;&#19968;&#27493;&#20462;&#25913;&#33258;&#27880;&#24847;&#23618;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#23454;&#39564;&#26469;&#25903;&#25345;&#25105;&#20204;&#30340;&#35266;&#28857;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#31532;&#19968;&#20010;&#23558;&#19978;&#19979;&#25991;&#23398;&#20064;&#19982;&#23545;&#27604;&#23398;&#20064;&#27169;&#24335;&#31561;&#20215;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained large language models based on Transformers have demonstrated amazing in-context learning (ICL) abilities. Given several demonstration examples, the models can implement new tasks without any parameter updates. However, it is still an open question to understand the mechanism of ICL. In this paper, we interpret the inference process of ICL as a gradient descent process in a contrastive learning pattern. Firstly, leveraging kernel methods, we establish the relationship between gradient descent and self-attention mechanism under generally used softmax attention setting instead of linear attention setting. Then, we analyze the corresponding gradient descent process of ICL from the perspective of contrastive learning without negative samples and discuss possible improvements of this contrastive learning pattern, based on which the self-attention layer can be further modified. Finally, we design experiments to support our opinions. To the best of our knowledge, our work is the f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#24494;&#35843;&#25152;&#24102;&#26469;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;&#22312;&#31616;&#21270;&#30340;&#32447;&#24615;&#32593;&#32476;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#24494;&#35843;&#25152;&#23545;&#29305;&#24449;&#20849;&#20139;&#21644;&#23398;&#20064;&#29305;&#23450;&#29305;&#24449;&#31232;&#30095;&#24615;&#30340;&#40723;&#21169;&#20316;&#29992;&#65292;&#24182;&#21457;&#29616;&#24494;&#35843;&#36807;&#31243;&#21516;&#26102;&#20855;&#26377;&#20869;&#26680;&#21644;&#29305;&#24449;&#23398;&#20064;&#30340;&#28151;&#21512;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;&#24494;&#35843;&#36824;&#21487;&#20197;&#23637;&#29616;&#19968;&#31181;&#23884;&#22871;&#29305;&#24449;&#23398;&#20064;&#34892;&#20026;&#65292;&#20351;&#20854;&#20559;&#21521;&#20110;&#25552;&#21462;&#19968;&#32452;&#31232;&#30095;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;</title><link>http://arxiv.org/abs/2310.02396</link><description>&lt;p&gt;
&#29992;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#26041;&#27861;&#36827;&#34892;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Implicit regularization of multi-task learning and finetuning in overparameterized neural networks. (arXiv:2310.02396v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02396
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#24494;&#35843;&#25152;&#24102;&#26469;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;&#22312;&#31616;&#21270;&#30340;&#32447;&#24615;&#32593;&#32476;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#24494;&#35843;&#25152;&#23545;&#29305;&#24449;&#20849;&#20139;&#21644;&#23398;&#20064;&#29305;&#23450;&#29305;&#24449;&#31232;&#30095;&#24615;&#30340;&#40723;&#21169;&#20316;&#29992;&#65292;&#24182;&#21457;&#29616;&#24494;&#35843;&#36807;&#31243;&#21516;&#26102;&#20855;&#26377;&#20869;&#26680;&#21644;&#29305;&#24449;&#23398;&#20064;&#30340;&#28151;&#21512;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;&#24494;&#35843;&#36824;&#21487;&#20197;&#23637;&#29616;&#19968;&#31181;&#23884;&#22871;&#29305;&#24449;&#23398;&#20064;&#34892;&#20026;&#65292;&#20351;&#20854;&#20559;&#21521;&#20110;&#25552;&#21462;&#19968;&#32452;&#31232;&#30095;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#24120;&#24120;&#20351;&#29992;&#35757;&#32451;&#36741;&#21161;&#20219;&#21153;&#30340;&#26041;&#27861;&#26469;&#26399;&#26395;&#23398;&#20064;&#21487;&#20197;&#37096;&#20998;&#22320;&#36716;&#31227;&#21040;&#20854;&#20182;&#24863;&#20852;&#36259;&#30340;&#20219;&#21153;&#19978;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23398;&#20064;&#36741;&#21161;&#20219;&#21153;&#25152;&#20135;&#29983;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#21253;&#25324;&#21516;&#26102;&#23398;&#20064;&#65288;&#22810;&#20219;&#21153;&#23398;&#20064;&#65292;MTL&#65289;&#21644;&#20381;&#24207;&#23398;&#20064;&#65288;&#39044;&#35757;&#32451;&#21644;&#38543;&#21518;&#24494;&#35843;&#65292;PT+FT&#65289;&#12290;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35757;&#32451;&#20004;&#23618;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#30340;&#31616;&#21270;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19982;MTL&#21644;PT+FT&#30456;&#20851;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#24809;&#32602;&#65292;&#20004;&#32773;&#37117;&#40723;&#21169;&#20219;&#21153;&#20043;&#38388;&#30340;&#29305;&#24449;&#20849;&#20139;&#21644;&#23398;&#20064;&#20219;&#21153;&#29305;&#23450;&#29305;&#24449;&#30340;&#31232;&#30095;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#65292;&#32593;&#32476;&#22312;&#20808;&#21069;&#30740;&#31350;&#20013;&#30830;&#23450;&#30340;&#20869;&#26680;&#65288;&#25110;&#8220;&#24816;&#24615;&#8221;&#65289;&#29366;&#24577;&#21644;&#29305;&#24449;&#23398;&#20064;&#65288;&#8220;&#20016;&#23500;&#8221;&#65289;&#29366;&#24577;&#20043;&#38388;&#20855;&#26377;&#28151;&#21512;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;PT+FT&#36824;&#21487;&#20197;&#23637;&#29616;&#19968;&#31181;&#26032;&#39062;&#30340;&#8220;&#23884;&#22871;&#29305;&#24449;&#23398;&#20064;&#8221;&#34892;&#20026;&#65292;&#35813;&#34892;&#20026;&#26080;&#27861;&#34987;&#20219;&#20309;&#29366;&#24577;&#25152;&#25429;&#25417;&#65292;&#20351;&#20854;&#20559;&#21521;&#20110;&#25552;&#21462;&#19968;&#32452;&#31232;&#30095;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is common in deep learning to train networks on auxiliary tasks with the expectation that the learning will transfer, at least partially, to another task of interest. In this work, we investigate the inductive biases that result from learning auxiliary tasks, either simultaneously (multi-task learning, MTL) or sequentially (pretraining and subsequent finetuning, PT+FT). In the simplified setting of two-layer diagonal linear networks trained with gradient descent, we identify implicit regularization penalties associated with MTL and PT+FT, both of which incentivize feature sharing between tasks and sparsity in learned task-specific features. Notably, our results imply that during finetuning, networks operate in a hybrid of the kernel (or "lazy") regime and the feature learning ("rich") regime identified in prior work. Moreover, PT+FT can exhibit a novel "nested feature learning" behavior not captured by either regime, which biases it to extract a sparse subset of the features learned
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#34892;&#20026;&#24178;&#39044;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26469;&#39044;&#38450;&#34880;&#31958;&#24322;&#24120;&#65292;&#26377;&#26395;&#23545;&#31038;&#20250;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.01684</link><description>&lt;p&gt;
&#35774;&#35745;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#34892;&#20026;&#24178;&#39044;&#26469;&#39044;&#38450;&#34880;&#31958;&#24322;&#24120;&#65292;&#24182;&#25552;&#20379;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Designing User-Centric Behavioral Interventions to Prevent Dysglycemia with Novel Counterfactual Explanations. (arXiv:2310.01684v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01684
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#34892;&#20026;&#24178;&#39044;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26469;&#39044;&#38450;&#34880;&#31958;&#24322;&#24120;&#65292;&#26377;&#26395;&#23545;&#31038;&#20250;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29983;&#27963;&#26041;&#24335;&#34892;&#20026;&#32500;&#25345;&#27491;&#24120;&#34880;&#31958;&#27700;&#24179;&#23545;&#20110;&#20445;&#25345;&#20581;&#24247;&#21644;&#39044;&#38450;&#30142;&#30149;&#33267;&#20851;&#37325;&#35201;&#12290;&#39057;&#32321;&#25509;&#35302;&#34880;&#31958;&#24322;&#24120;&#65288;&#21363;&#39640;&#34880;&#31958;&#21644;&#20302;&#34880;&#31958;&#31561;&#24322;&#24120;&#20107;&#20214;&#65289;&#20250;&#23548;&#33268;&#24930;&#24615;&#24182;&#21457;&#30151;&#65292;&#21253;&#25324;&#31958;&#23615;&#30149;&#12289;&#32958;&#33039;&#30142;&#30149;&#21450;&#38656;&#36879;&#26512;&#27835;&#30103;&#12289;&#24515;&#32908;&#26775;&#27515;&#12289;&#20013;&#39118;&#12289;&#25130;&#32930;&#21644;&#27515;&#20129;&#12290;&#22240;&#27492;&#65292;&#33021;&#22815;&#39044;&#27979;&#34880;&#31958;&#24322;&#24120;&#24182;&#21521;&#29992;&#25143;&#25552;&#20379;&#34892;&#21160;&#21453;&#39304;&#20197;&#25913;&#21464;&#39278;&#39135;&#12289;&#36816;&#21160;&#21644;&#33647;&#29289;&#27835;&#30103;&#26469;&#39044;&#38450;&#24322;&#24120;&#34880;&#31958;&#20107;&#20214;&#30340;&#24037;&#20855;&#21487;&#33021;&#20855;&#26377;&#37325;&#35201;&#30340;&#31038;&#20250;&#24433;&#21709;&#12290;&#21453;&#20107;&#23454;&#35299;&#37322;&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#31867;&#20284;&#20110;&#21407;&#22987;&#36755;&#20837;&#20294;&#23548;&#33268;&#19981;&#21516;&#39044;&#27979;&#32467;&#26524;&#30340;&#20551;&#35774;&#23454;&#20363;&#65292;&#25552;&#20379;&#27169;&#22411;&#20026;&#20309;&#23545;&#29305;&#23450;&#39044;&#27979;&#30340;&#35265;&#35299;&#12290;&#22240;&#27492;&#65292;&#21453;&#20107;&#23454;&#35299;&#37322;&#21487;&#20197;&#34987;&#35270;&#20026;&#35774;&#35745;AI&#39537;&#21160;&#30340;&#20581;&#24247;&#24178;&#39044;&#26469;&#39044;&#38450;&#19981;&#33391;&#20581;&#24247;&#32467;&#26524;&#65288;&#22914;&#34880;&#31958;&#24322;&#24120;&#65289;&#30340;&#19968;&#31181;&#25163;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;GlyCoa...
&lt;/p&gt;
&lt;p&gt;
Maintaining normal blood glucose levels through lifestyle behaviors is central to maintaining health and preventing disease. Frequent exposure to dysglycemia (i.e., abnormal glucose events such as hyperlycemia and hypoglycemia) leads to chronic complications including diabetes, kidney disease and need for dialysis, myocardial infarction, stroke, amputation, and death. Therefore, a tool capable of predicting dysglycemia and offering users actionable feedback about how to make changes in their diet, exercise, and medication to prevent abnormal glycemic events could have significant societal impacts. Counterfactual explanations can provide insights into why a model made a particular prediction by generating hypothetical instances that are similar to the original input but lead to a different prediction outcome. Therefore, counterfactuals can be viewed as a means to design AI-driven health interventions to prevent adverse health outcomes such as dysglycemia. In this paper, we design GlyCoa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#26426;&#21327;&#21516;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#25353;&#29031;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#30340;&#20449;&#24565;&#20998;&#24067;&#37319;&#26679;&#31062;&#20808;&#22270;&#65292;&#24182;&#24341;&#20837;&#26368;&#20339;&#23454;&#39564;&#35774;&#35745;&#19982;&#19987;&#23478;&#20114;&#21160;&#65292;&#20197;&#25552;&#20379;&#19987;&#23478;&#21487;&#39564;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24182;&#36845;&#20195;&#25913;&#36827;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.12032</link><description>&lt;p&gt;
&#20154;&#26426;&#21327;&#21516;&#19979;&#20351;&#29992;&#31062;&#20808;GFlowNets&#36827;&#34892;&#28508;&#22312;&#28151;&#28102;&#30340;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets. (arXiv:2309.12032v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12032
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#26426;&#21327;&#21516;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#25353;&#29031;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#30340;&#20449;&#24565;&#20998;&#24067;&#37319;&#26679;&#31062;&#20808;&#22270;&#65292;&#24182;&#24341;&#20837;&#26368;&#20339;&#23454;&#39564;&#35774;&#35745;&#19982;&#19987;&#23478;&#20114;&#21160;&#65292;&#20197;&#25552;&#20379;&#19987;&#23478;&#21487;&#39564;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24182;&#36845;&#20195;&#25913;&#36827;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#23398;&#20064;&#26159;&#22240;&#26524;&#25512;&#26029;&#30340;&#20851;&#38190;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#24403;&#25968;&#25454;&#31232;&#32570;&#26102;&#65292;&#22240;&#26524;&#21457;&#29616;&#65288;CD&#65289;&#31639;&#27861;&#24456;&#33030;&#24369;&#65292;&#21487;&#33021;&#25512;&#26029;&#20986;&#19982;&#19987;&#23478;&#30693;&#35782;&#30456;&#30683;&#30462;&#30340;&#19981;&#20934;&#30830;&#22240;&#26524;&#20851;&#31995;&#65292;&#23588;&#20854;&#26159;&#32771;&#34385;&#21040;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#26102;&#26356;&#26159;&#22914;&#27492;&#12290;&#20026;&#20102;&#21152;&#37325;&#36825;&#20010;&#38382;&#39064;&#65292;&#22823;&#22810;&#25968;CD&#26041;&#27861;&#24182;&#19981;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#36825;&#20351;&#24471;&#29992;&#25143;&#38590;&#20197;&#35299;&#37322;&#32467;&#26524;&#21644;&#25913;&#36827;&#25512;&#26029;&#36807;&#31243;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23613;&#31649;CD&#26159;&#19968;&#20010;&#20197;&#20154;&#20026;&#20013;&#24515;&#30340;&#20107;&#21153;&#65292;&#20294;&#27809;&#26377;&#20219;&#20309;&#30740;&#31350;&#19987;&#27880;&#20110;&#26500;&#24314;&#26082;&#33021;&#36755;&#20986;&#19987;&#23478;&#21487;&#39564;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21448;&#33021;&#19982;&#19987;&#23478;&#36827;&#34892;&#20132;&#20114;&#36845;&#20195;&#25913;&#36827;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#65292;&#26681;&#25454;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#65288;&#22914;&#36125;&#21494;&#26031;&#20449;&#24687;&#20934;&#21017;&#65289;&#30340;&#20449;&#24565;&#20998;&#24067;&#65292;&#25353;&#27604;&#20363;&#23545;&#65288;&#22240;&#26524;&#65289;&#31062;&#20808;&#22270;&#36827;&#34892;&#37319;&#26679;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20505;&#36873;&#22270;&#30340;&#22810;&#26679;&#24615;&#24182;&#24341;&#20837;&#26368;&#20339;&#23454;&#39564;&#35774;&#35745;&#65292;&#20197;&#36845;&#20195;&#24615;&#22320;&#25506;&#32034;&#23454;&#39564;&#26469;&#19982;&#19987;&#23478;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structure learning is the crux of causal inference. Notably, causal discovery (CD) algorithms are brittle when data is scarce, possibly inferring imprecise causal relations that contradict expert knowledge -- especially when considering latent confounders. To aggravate the issue, most CD methods do not provide uncertainty estimates, making it hard for users to interpret results and improve the inference process. Surprisingly, while CD is a human-centered affair, no works have focused on building methods that both 1) output uncertainty estimates that can be verified by experts and 2) interact with those experts to iteratively refine CD. To solve these issues, we start by proposing to sample (causal) ancestral graphs proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC), using generative flow networks. Then, we leverage the diversity in candidate graphs and introduce an optimal experimental design to iteratively probe the expe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#26102;&#38388;q-learning&#22312;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#19979;&#29992;&#20110;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;&#65292;&#24182;&#25581;&#31034;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;q&#20989;&#25968;&#30340;&#23384;&#22312;&#21450;&#20854;&#31215;&#20998;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2306.16208</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;q-learning&#29992;&#20110;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Continuous-Time q-learning for McKean-Vlasov Control Problems. (arXiv:2306.16208v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#26102;&#38388;q-learning&#22312;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#19979;&#29992;&#20110;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;&#65292;&#24182;&#25581;&#31034;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;q&#20989;&#25968;&#30340;&#23384;&#22312;&#21450;&#20854;&#31215;&#20998;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;q-learning&#65292;&#22312;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#19979;&#65292;&#29992;&#20110;&#36830;&#32493;&#26102;&#38388;&#30340;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;&#12290;&#19982;Jia&#21644;Zhou&#65288;2022c&#65289;&#30340;&#21333;&#20010;&#20195;&#29702;&#25511;&#21046;&#38382;&#39064;&#19981;&#21516;&#65292;&#20195;&#29702;&#20043;&#38388;&#30340;&#22343;&#22330;&#30456;&#20114;&#20316;&#29992;&#20351;&#24471;q&#20989;&#25968;&#30340;&#23450;&#20041;&#26356;&#21152;&#22797;&#26434;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#33258;&#28982;&#20135;&#29983;&#20004;&#31181;&#19981;&#21516;q&#20989;&#25968;&#30340;&#24773;&#20917;&#65306;&#65288;i&#65289;&#34987;&#31216;&#20026;&#38598;&#25104;q&#20989;&#25968;&#65288;&#29992;$q$&#34920;&#31034;&#65289;&#65292;&#20316;&#20026;Gu&#12289;Guo&#12289;Wei&#21644;Xu&#65288;2023&#65289;&#24341;&#20837;&#30340;&#38598;&#25104;Q&#20989;&#25968;&#30340;&#19968;&#38454;&#36817;&#20284;&#65292;&#21487;&#20197;&#36890;&#36807;&#28041;&#21450;&#27979;&#35797;&#31574;&#30053;&#30340;&#24369;&#38789;&#26465;&#20214;&#36827;&#34892;&#23398;&#20064;&#65307;&#65288;ii&#65289;&#20316;&#20026;&#31574;&#30053;&#25913;&#36827;&#36845;&#20195;&#20013;&#25152;&#20351;&#29992;&#30340;&#23454;&#36136;q&#20989;&#25968;&#65288;&#29992;$q_e$&#34920;&#31034;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;q&#20989;&#25968;&#22312;&#25152;&#26377;&#27979;&#35797;&#31574;&#30053;&#19979;&#36890;&#36807;&#31215;&#20998;&#34920;&#31034;&#30456;&#20851;&#32852;&#12290;&#22522;&#20110;&#38598;&#25104;q&#20989;&#25968;&#30340;&#24369;&#38789;&#26465;&#20214;&#21644;&#25105;&#20204;&#25552;&#20986;&#30340;&#25628;&#32034;&#26041;&#27861;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#31639;&#27861;&#26469;&#23398;&#20064;&#20004;&#20010;q&#20989;&#25968;&#20197;&#35299;&#20915;Mckean-Vlasov&#25511;&#21046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the q-learning, recently coined as the continuous-time counterpart of Q-learning by Jia and Zhou (2022c), for continuous time Mckean-Vlasov control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2022c), the mean-field interaction of agents render the definition of q-function more subtle, for which we reveal that two distinct q-functions naturally arise: (i) the integrated q-function (denoted by $q$) as the first-order approximation of the integrated Q-function introduced in Gu, Guo, Wei and Xu (2023) that can be learnt by a weak martingale condition involving test policies; and (ii) the essential q-function (denoted by $q_e$) that is employed in the policy improvement iterations. We show that two q-functions are related via an integral representation under all test policies. Based on the weak martingale condition of the integrated q-function and our proposed searching method of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;$FPDM$&#65292;&#20351;&#29992;&#25991;&#26723;&#20803;&#25968;&#25454;&#21644;&#39046;&#22495;&#29305;&#23450;&#20998;&#31867;&#20316;&#20026;&#30417;&#30563;&#20449;&#21495;&#65292;&#23545;&#39046;&#22495;&#29305;&#23450;&#35821;&#26009;&#24211;&#36827;&#34892;transformer&#32534;&#30721;&#22120;&#30340;&#39044;&#35757;&#32451;&#12290;$FPDM$&#36890;&#36807;&#21477;&#23376;&#32423;&#21035;&#30340;&#36755;&#20837;&#39044;&#35757;&#32451;&#24320;&#25918;&#39046;&#22495;&#30340;&#32534;&#30721;&#22120;&#65292;&#22312;&#24494;&#35843;&#26102;&#20351;&#29992;&#35789;&#27719;&#32423;&#21035;&#30340;&#36755;&#20837;&#65292;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#22522;&#20110;transformer&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.06190</link><description>&lt;p&gt;
&#20351;&#29992;&#25991;&#26723;&#32423;&#20803;&#25968;&#25454;&#30340;&#39046;&#22495;&#29305;&#23450;&#24555;&#36895;&#39044;&#35757;&#32451;&#25216;&#26415;$FPDM$
&lt;/p&gt;
&lt;p&gt;
$FPDM$: Domain-Specific Fast Pre-training Technique using Document-Level Metadata. (arXiv:2306.06190v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06190
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;$FPDM$&#65292;&#20351;&#29992;&#25991;&#26723;&#20803;&#25968;&#25454;&#21644;&#39046;&#22495;&#29305;&#23450;&#20998;&#31867;&#20316;&#20026;&#30417;&#30563;&#20449;&#21495;&#65292;&#23545;&#39046;&#22495;&#29305;&#23450;&#35821;&#26009;&#24211;&#36827;&#34892;transformer&#32534;&#30721;&#22120;&#30340;&#39044;&#35757;&#32451;&#12290;$FPDM$&#36890;&#36807;&#21477;&#23376;&#32423;&#21035;&#30340;&#36755;&#20837;&#39044;&#35757;&#32451;&#24320;&#25918;&#39046;&#22495;&#30340;&#32534;&#30721;&#22120;&#65292;&#22312;&#24494;&#35843;&#26102;&#20351;&#29992;&#35789;&#27719;&#32423;&#21035;&#30340;&#36755;&#20837;&#65292;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#22522;&#20110;transformer&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#39046;&#22495;&#30340;&#39044;&#35757;&#32451;&#24050;&#26174;&#31034;&#20986;&#22312;&#24320;&#25918;&#39046;&#22495;&#21644;&#39046;&#22495;&#29305;&#23450;&#19979;&#28216;&#20219;&#21153;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#26368;&#20808;&#36827;&#30340;transformers&#38656;&#35201;&#22823;&#37327;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#21644;&#35745;&#31639;&#36164;&#28304;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$FPDM$&#65288;Fast Pre-training Technique using Document Level Metadata&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#25991;&#26723;&#20803;&#25968;&#25454;&#21644;&#39046;&#22495;&#29305;&#23450;&#30340;&#20998;&#31867;&#20316;&#20026;&#30417;&#30563;&#20449;&#21495;&#65292;&#23545;&#39046;&#22495;&#29305;&#23450;&#35821;&#26009;&#24211;&#36827;&#34892;transformer&#32534;&#30721;&#22120;&#30340;&#39044;&#35757;&#32451;&#12290;&#26368;&#20027;&#35201;&#30340;&#21019;&#26032;&#22312;&#20110;&#65292;&#22312;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#20351;&#29992;&#21477;&#23376;&#32423;&#21035;&#30340;&#23884;&#20837;&#20316;&#20026;&#36755;&#20837;&#65292;&#25345;&#32493;&#23545;&#24320;&#25918;&#39046;&#22495;&#30340;&#32534;&#30721;&#22120;&#36827;&#34892;&#39044;&#35757;&#32451;&#65288;&#20197;&#36866;&#24212;&#38271;&#25991;&#26723;&#65289;&#65292;&#20294;&#22312;&#23545;&#35813;&#32534;&#30721;&#22120;&#36827;&#34892;&#24494;&#35843;&#26102;&#65292;&#21017;&#20351;&#29992;&#35789;&#27719;&#32423;&#21035;&#23884;&#20837;&#20316;&#20026;&#36755;&#20837;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;$FPDM$&#22312;&#23458;&#25143;&#25903;&#25345;&#12289;&#31185;&#23398;&#21644;&#27861;&#24459;&#31561;&#39046;&#22495;&#30340;&#23383;&#31526;&#32423;F1&#20998;&#25968;&#21644;&#20854;&#20182;&#33258;&#21160;&#21270;&#25351;&#26631;&#26041;&#38754;&#20248;&#20110;&#20960;&#31181;&#22522;&#20110;transformer&#30340;&#22522;&#20934;&#65292;&#19988;&#22312;&#19979;&#28216;&#20219;&#21153;&#24494;&#35843;&#21518;&#24615;&#33021;&#19979;&#38477;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-training Transformers has shown promising results on open-domain and domain-specific downstream tasks. However, state-of-the-art Transformers require an unreasonably large amount of pre-training data and compute. In this paper, we propose $FPDM$ (Fast Pre-training Technique using Document Level Metadata), a novel, compute-efficient framework that utilizes Document metadata and Domain-Specific Taxonomy as supervision signals to pre-train transformer encoder on a domain-specific corpus. The main innovation is that during domain-specific pretraining, an open-domain encoder is continually pre-trained using sentence-level embeddings as inputs (to accommodate long documents), however, fine-tuning is done with token-level embeddings as inputs to this encoder. We show that $FPDM$ outperforms several transformer-based baselines in terms of character-level F1 scores and other automated metrics in the Customer Support, Scientific, and Legal Domains, and shows a negligible drop in performance 
&lt;/p&gt;</description></item><item><title>AGNES&#26159;&#19968;&#31181;&#33021;&#22312;&#24179;&#28369;&#20984;&#20248;&#21270;&#20219;&#21153;&#20013;&#23454;&#29616;&#21152;&#36895;&#30340;&#31639;&#27861;&#65292;&#21363;&#20351;&#26799;&#24230;&#20272;&#35745;&#30340;&#20449;&#22122;&#27604;&#24456;&#23567;&#65292;&#23427;&#20063;&#33021;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#25928;&#26524;&#26174;&#33879;&#20248;&#20110;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.05515</link><description>&lt;p&gt;
&#23454;&#29616;&#21152;&#36895;&#23613;&#31649;&#26799;&#24230;&#38750;&#24120;&#22024;&#26434;&#12290;
&lt;/p&gt;
&lt;p&gt;
Achieving acceleration despite very noisy gradients. (arXiv:2302.05515v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05515
&lt;/p&gt;
&lt;p&gt;
AGNES&#26159;&#19968;&#31181;&#33021;&#22312;&#24179;&#28369;&#20984;&#20248;&#21270;&#20219;&#21153;&#20013;&#23454;&#29616;&#21152;&#36895;&#30340;&#31639;&#27861;&#65292;&#21363;&#20351;&#26799;&#24230;&#20272;&#35745;&#30340;&#20449;&#22122;&#27604;&#24456;&#23567;&#65292;&#23427;&#20063;&#33021;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#25928;&#26524;&#26174;&#33879;&#20248;&#20110;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;Nesterov&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#19968;&#33324;&#21270;&#12290;&#22914;&#26524;&#22122;&#22768;&#30340;&#24378;&#24230;&#19982;&#26799;&#24230;&#30340;&#22823;&#23567;&#25104;&#27604;&#20363;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#65288;AGNES&#65289;&#21487;&#20197;&#35777;&#26126;&#22312;&#20855;&#26377;&#22024;&#26434;&#26799;&#24230;&#20272;&#35745;&#30340;&#24179;&#28369;&#20984;&#20248;&#21270;&#20219;&#21153;&#20013;&#23454;&#29616;&#21152;&#36895;&#12290;&#22914;&#26524;&#24120;&#25968;&#27604;&#20363;&#36229;&#36807;&#19968;&#65292;Nesterov&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#22312;&#36825;&#31181;&#22122;&#22768;&#27169;&#22411;&#19979;&#19981;&#20250;&#25910;&#25947;&#12290;AGNES&#33021;&#20462;&#22797;&#36825;&#31181;&#19981;&#36275;&#65292;&#24182;&#19988;&#21487;&#20197;&#35777;&#26126;&#23427;&#30340;&#25910;&#25947;&#36895;&#24230;&#21152;&#24555;&#65292;&#26080;&#35770;&#26799;&#24230;&#20272;&#35745;&#30340;&#20449;&#22122;&#27604;&#26377;&#22810;&#23567;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#26159;&#29992;&#20110;&#36229;&#21442;&#25968;&#36807;&#22810;&#30340;&#28145;&#24230;&#23398;&#20064;&#23567;&#25209;&#37327;&#26799;&#24230;&#30340;&#36866;&#24403;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;AGNES&#22312;CNN&#35757;&#32451;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a generalization of Nesterov's accelerated gradient descent algorithm. Our algorithm (AGNES) provably achieves acceleration for smooth convex minimization tasks with noisy gradient estimates if the noise intensity is proportional to the magnitude of the gradient. Nesterov's accelerated gradient descent does not converge under this noise model if the constant of proportionality exceeds one. AGNES fixes this deficiency and provably achieves an accelerated convergence rate no matter how small the signal to noise ratio in the gradient estimate. Empirically, we demonstrate that this is an appropriate model for mini-batch gradients in overparameterized deep learning. Finally, we show that AGNES outperforms stochastic gradient descent with momentum and Nesterov's method in the training of CNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#26102;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#21487;&#20197;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;</title><link>http://arxiv.org/abs/2206.03861</link><description>&lt;p&gt;
&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Decentralized Online Regularized Learning Over Random Time-Varying Graphs. (arXiv:2206.03861v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#26102;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#21487;&#20197;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20013;&#65292;&#27599;&#20010;&#33410;&#28857;&#37117;&#36816;&#34892;&#19968;&#20010;&#22312;&#32447;&#20272;&#35745;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21253;&#25324;&#21019;&#26032;&#39033;&#65288;&#22788;&#29702;&#33258;&#36523;&#26032;&#27979;&#37327;&#20540;&#65289;&#12289;&#20849;&#35782;&#39033;&#65288;&#21152;&#26435;&#24179;&#22343;&#33258;&#36523;&#21450;&#20854;&#37051;&#23621;&#30340;&#20272;&#35745;&#65292;&#24102;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#36890;&#20449;&#22122;&#22768;&#65289;&#21644;&#27491;&#21017;&#21270;&#39033;&#65288;&#38450;&#27490;&#36807;&#24230;&#25311;&#21512;&#65289;&#12290;&#19981;&#35201;&#27714;&#22238;&#24402;&#30697;&#38453;&#21644;&#22270;&#28385;&#36275;&#29305;&#27530;&#30340;&#32479;&#35745;&#20551;&#35774;&#65292;&#22914;&#30456;&#20114;&#29420;&#31435;&#12289;&#26102;&#31354;&#29420;&#31435;&#25110;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#24182;&#35777;&#26126;&#20102;&#22914;&#26524;&#31639;&#27861;&#22686;&#30410;&#12289;&#22270;&#21644;&#22238;&#24402;&#30697;&#38453;&#20849;&#21516;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#20960;&#20046;&#21487;&#20197;&#32943;&#23450;&#22320;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#31639;&#27861;&#22686;&#30410;&#65292;&#35813;&#26465;&#20214;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the decentralized online regularized linear regression algorithm over random time-varying graphs. At each time step, every node runs an online estimation algorithm consisting of an innovation term processing its own new measurement, a consensus term taking a weighted sum of estimations of its own and its neighbors with additive and multiplicative communication noises and a regularization term preventing over-fitting. It is not required that the regression matrices and graphs satisfy special statistical assumptions such as mutual independence, spatio-temporal independence or stationarity. We develop the nonnegative supermartingale inequality of the estimation error, and prove that the estimations of all nodes converge to the unknown true parameter vector almost surely if the algorithm gains, graphs and regression matrices jointly satisfy the sample path spatio-temporal persistence of excitation condition. Especially, this condition holds by choosing appropriate algorithm gains 
&lt;/p&gt;</description></item></channel></rss>