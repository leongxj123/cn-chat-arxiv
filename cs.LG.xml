<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>ALERT-Transformer&#26159;&#19968;&#31181;&#23558;&#24322;&#27493;&#24863;&#30693;&#19982;&#21516;&#27493;&#22788;&#29702;&#30456;&#32467;&#21512;&#30340;&#26032;&#39062;&#26725;&#25509;&#26041;&#24335;&#65292;&#36890;&#36807;ALERT&#27169;&#22359;&#12289;&#28789;&#27963;&#30340;&#25968;&#25454;&#35835;&#21462;&#21644;&#22522;&#20110;&#22359;&#30340;&#31232;&#30095;&#24615;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#23545;&#23454;&#26102;&#20107;&#20214;&#39537;&#21160;&#26102;&#31354;&#25968;&#25454;&#30340;&#32463;&#20856;&#22788;&#29702;&#65292;&#20854;&#24615;&#33021;&#36229;&#36807;&#31454;&#20105;&#23545;&#25163;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#24310;&#36831;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01393</link><description>&lt;p&gt;
ALERT-Transformer: &#23558;&#24322;&#27493;&#21644;&#21516;&#27493;&#26426;&#22120;&#23398;&#20064;&#26725;&#25509;&#22312;&#23454;&#26102;&#20107;&#20214;&#39537;&#21160;&#30340;&#26102;&#31354;&#25968;&#25454;&#19978;
&lt;/p&gt;
&lt;p&gt;
ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01393
&lt;/p&gt;
&lt;p&gt;
ALERT-Transformer&#26159;&#19968;&#31181;&#23558;&#24322;&#27493;&#24863;&#30693;&#19982;&#21516;&#27493;&#22788;&#29702;&#30456;&#32467;&#21512;&#30340;&#26032;&#39062;&#26725;&#25509;&#26041;&#24335;&#65292;&#36890;&#36807;ALERT&#27169;&#22359;&#12289;&#28789;&#27963;&#30340;&#25968;&#25454;&#35835;&#21462;&#21644;&#22522;&#20110;&#22359;&#30340;&#31232;&#30095;&#24615;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#23545;&#23454;&#26102;&#20107;&#20214;&#39537;&#21160;&#26102;&#31354;&#25968;&#25454;&#30340;&#32463;&#20856;&#22788;&#29702;&#65292;&#20854;&#24615;&#33021;&#36229;&#36807;&#31454;&#20105;&#23545;&#25163;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#31264;&#23494;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23454;&#29616;&#23545;&#30001;&#20107;&#20214;&#24863;&#24212;&#22120;&#20135;&#29983;&#30340;&#36830;&#32493;&#36229;&#31232;&#30095;&#26102;&#31354;&#25968;&#25454;&#30340;&#32463;&#20856;&#22788;&#29702;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#31649;&#36947;&#65292;&#30001;&#24322;&#27493;&#24863;&#30693;&#21644;&#21516;&#27493;&#22788;&#29702;&#32452;&#25104;&#65292;&#32467;&#21512;&#20102;&#20960;&#20010;&#24605;&#36335;&#65306;&#65288;1&#65289;&#22522;&#20110;PointNet&#27169;&#22411;&#30340;&#23884;&#20837;&#8212;&#8212;ALERT&#27169;&#22359;&#65292;&#21487;&#20197;&#36890;&#36807;&#27844;&#28431;&#26426;&#21046;&#19981;&#26029;&#25972;&#21512;&#26032;&#20107;&#20214;&#24182;&#28040;&#38500;&#26087;&#20107;&#20214;&#65292;&#65288;2&#65289;&#23884;&#20837;&#25968;&#25454;&#30340;&#28789;&#27963;&#35835;&#21462;&#65292;&#21487;&#20197;&#20197;&#20219;&#20309;&#37319;&#26679;&#29575;&#23558;&#22987;&#32456;&#26368;&#26032;&#30340;&#29305;&#24449;&#36755;&#20837;&#21040;&#19979;&#28216;&#27169;&#22411;&#20013;&#65292;&#65288;3&#65289;&#20511;&#37492;Vision Transformer&#30340;&#22522;&#20110;&#22359;&#30340;&#26041;&#27861;&#26469;&#21033;&#29992;&#36755;&#20837;&#30340;&#31232;&#30095;&#24615;&#20197;&#20248;&#21270;&#26041;&#27861;&#30340;&#25928;&#29575;&#12290;&#36825;&#20123;&#23884;&#20837;&#28982;&#21518;&#30001;&#19968;&#20010;&#32463;&#36807;&#23545;&#35937;&#21644;&#25163;&#21183;&#35782;&#21035;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#36827;&#34892;&#22788;&#29702;&#12290;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#20302;&#30340;&#24310;&#36831;&#65292;&#36798;&#21040;&#20102;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#24322;&#27493;&#27169;&#22411;&#21487;&#20197;&#20197;&#20219;&#20309;&#25152;&#38656;&#30340;&#37319;&#26679;&#29575;&#36827;&#34892;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#26368;&#22823;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#20256;&#32479;&#22870;&#21169;&#20989;&#25968;&#30340;&#23398;&#20064;&#26041;&#24335;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01361</link><description>&lt;p&gt;
&#23613;&#21892;&#23613;&#32654;&#65306;&#37325;&#26032;&#23450;&#20041;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#22870;&#21169;
&lt;/p&gt;
&lt;p&gt;
To the Max: Reinventing Reward in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#26368;&#22823;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#20256;&#32479;&#22870;&#21169;&#20989;&#25968;&#30340;&#23398;&#20064;&#26041;&#24335;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#19981;&#21516;&#30340;&#22870;&#21169;&#21487;&#20197;&#23450;&#20041;&#30456;&#21516;&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#20294;&#23398;&#20064;&#24615;&#33021;&#21364;&#20250;&#26377;&#24456;&#22823;&#24046;&#24322;&#12290;&#23545;&#20110;&#26576;&#20123;&#24773;&#20917;&#65292;&#26234;&#33021;&#20307;&#20250;&#38519;&#20837;&#27425;&#20248;&#34892;&#20026;&#65292;&#32780;&#23545;&#20110;&#20854;&#20182;&#24773;&#20917;&#65292;&#21017;&#33021;&#39640;&#25928;&#22320;&#35299;&#20915;&#20219;&#21153;&#12290;&#36873;&#25321;&#19968;&#20010;&#22909;&#30340;&#22870;&#21169;&#20989;&#25968;&#22240;&#27492;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#26367;&#20195;&#22870;&#21169;&#29992;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26368;&#22823;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#65288;max-reward RL&#65289;&#65292;&#20854;&#20013;&#26234;&#33021;&#20307;&#20248;&#21270;&#30340;&#26159;&#26368;&#22823;&#22870;&#21169;&#32780;&#19981;&#26159;&#32047;&#31215;&#22870;&#21169;&#12290;&#19982;&#26089;&#26399;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#29615;&#22659;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36731;&#26494;&#32467;&#21512;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;max-reward RL&#31639;&#27861;&#22312;Gymnasium-Robotics&#20013;&#30340;&#20004;&#20010;&#30446;&#26631;&#36798;&#25104;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#23637;&#31034;&#20854;&#30456;&#23545;&#20110;&#26631;&#20934;RL&#30340;&#20248;&#21183;&#12290;&#20195;&#30721;&#20844;&#24320;&#21487;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reinforcement learning (RL), different rewards can define the same optimal policy but result in drastically different learning performance. For some, the agent gets stuck with a suboptimal behavior, and for others, it solves the task efficiently. Choosing a good reward function is hence an extremely important yet challenging problem. In this paper, we explore an alternative approach to using rewards for learning. We introduce max-reward RL, where an agent optimizes the maximum rather than the cumulative reward. Unlike earlier works, our approach works for deterministic and stochastic environments and can be easily combined with state-of-the-art RL algorithms. In the experiments, we study the performance of max-reward RL algorithms in two goal-reaching environments from Gymnasium-Robotics and demonstrate its benefits over standard RL. The code is publicly available.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#22914;&#20309;&#20174;&#20855;&#26377;&#32454;&#31890;&#24230;&#27010;&#24565;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#27010;&#24565;&#65292;&#20197;&#23454;&#29616;&#27169;&#22411;&#36755;&#20986;&#30340;&#20869;&#22312;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00912</link><description>&lt;p&gt;
&#33021;&#22815;&#32422;&#26463;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#23398;&#20064;&#35821;&#20041;&#19978;&#26377;&#24847;&#20041;&#30340;&#36755;&#20837;&#29305;&#24449;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can we Constrain Concept Bottleneck Models to Learn Semantically Meaningful Input Features?
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#22914;&#20309;&#20174;&#20855;&#26377;&#32454;&#31890;&#24230;&#27010;&#24565;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#27010;&#24565;&#65292;&#20197;&#23454;&#29616;&#27169;&#22411;&#36755;&#20986;&#30340;&#20869;&#22312;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBM&#65289;&#34987;&#35748;&#20026;&#20855;&#26377;&#20869;&#22312;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#39318;&#20808;&#39044;&#27979;&#19968;&#32452;&#20154;&#20026;&#23450;&#20041;&#30340;&#27010;&#24565;&#65292;&#28982;&#21518;&#21033;&#29992;&#36825;&#20123;&#27010;&#24565;&#26469;&#39044;&#27979;&#19979;&#28216;&#20219;&#21153;&#30340;&#36755;&#20986;&#12290;&#20026;&#20102;&#23454;&#29616;&#23436;&#20840;&#30340;&#20869;&#22312;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#21450;&#30830;&#20445;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#20449;&#20219;&#65292;&#25105;&#20204;&#38656;&#35201;&#20445;&#35777;&#27010;&#24565;&#30340;&#39044;&#27979;&#26159;&#22522;&#20110;&#35821;&#20041;&#26144;&#23556;&#30340;&#36755;&#20837;&#29305;&#24449;&#12290;&#20363;&#22914;&#65292;&#20154;&#20204;&#21487;&#33021;&#26399;&#26395;&#22270;&#20687;&#20013;&#34920;&#31034;&#39592;&#25240;&#30340;&#20687;&#32032;&#34987;&#29992;&#20110;&#39044;&#27979;&#39592;&#25240;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#25991;&#29486;&#34920;&#26126;&#36825;&#24182;&#19981;&#26159;&#20107;&#23454;&#65292;&#22240;&#20026;&#27010;&#24565;&#39044;&#27979;&#36890;&#24120;&#19982;&#19981;&#30456;&#20851;&#30340;&#36755;&#20837;&#29305;&#24449;&#26144;&#23556;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#20551;&#35774;&#36825;&#26159;&#30001;&#20110;&#27010;&#24565;&#27880;&#37322;&#30340;&#19981;&#20934;&#30830;&#25110;&#32773;&#36755;&#20837;&#29305;&#24449;&#19982;&#27010;&#24565;&#20043;&#38388;&#30340;&#20851;&#31995;&#19981;&#28165;&#26224;&#23548;&#33268;&#30340;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25968;&#25454;&#38598;&#26631;&#27880;&#23545;CBMs&#20013;&#27010;&#24565;&#34920;&#31034;&#30340;&#24433;&#21709;&#20173;&#28982;&#26159;&#19968;&#20010;&#30740;&#31350;&#36739;&#23569;&#30340;&#39046;&#22495;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;CBMs&#22914;&#20309;&#20174;&#20855;&#26377;&#32454;&#31890;&#24230;&#27010;&#24565;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#27010;&#24565;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Concept Bottleneck Models (CBMs) are considered inherently interpretable because they first predict a set of human-defined concepts before using these concepts to predict the output of a downstream task. For inherent interpretability to be fully realised, and ensure trust in a model's output, we need to guarantee concepts are predicted based on semantically mapped input features. For example, one might expect the pixels representing a broken bone in an image to be used for the prediction of a fracture. However, current literature indicates this is not the case, as concept predictions are often mapped to irrelevant input features. We hypothesise that this occurs when concept annotations are inaccurate or how input features should relate to concepts is unclear. In general, the effect of dataset labelling on concept representations in CBMs remains an understudied area. Therefore, in this paper, we examine how CBMs learn concepts from datasets with fine-grained concept annotations. We demo
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#26041;&#27861;&#65292;&#26412;&#25991;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#65292;&#20445;&#35777;&#20102;&#23545;&#35937;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#65292;&#21253;&#25324;&#20102;&#38169;&#35823;&#20998;&#31867;&#30340;&#23545;&#35937;&#65292;&#21516;&#26102;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.07263</link><description>&lt;p&gt;
&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#23454;&#29616;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07263
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#26041;&#27861;&#65292;&#26412;&#25991;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#65292;&#20445;&#35777;&#20102;&#23545;&#35937;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#65292;&#21253;&#25324;&#20102;&#38169;&#35823;&#20998;&#31867;&#30340;&#23545;&#35937;&#65292;&#21516;&#26102;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#20687;&#33258;&#21160;&#39550;&#39542;&#36825;&#26679;&#30340;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#32771;&#34385;&#20026;&#22810;&#29289;&#20307;&#26816;&#27979;&#37327;&#21270;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#24418;&#24335;&#39044;&#27979;&#26469;&#33719;&#24471;&#20855;&#26377;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#29289;&#20307;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#12290;&#36825;&#26679;&#20570;&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#36793;&#30028;&#26694;&#30340;&#39044;&#27979;&#21462;&#20915;&#20110;&#29289;&#20307;&#30340;&#31867;&#21035;&#26631;&#31614;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#27493;&#24418;&#24335;&#26041;&#27861;&#65292;&#23558;&#23545;&#39044;&#27979;&#31867;&#21035;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#21040;&#36793;&#30028;&#26694;&#30340;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#20013;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#30340;&#24418;&#24335;&#35206;&#30422;&#20445;&#35777;&#30340;&#26377;&#25928;&#24615;&#26356;&#24191;&#27867;&#65292;&#21253;&#25324;&#20102;&#34987;&#38169;&#35823;&#20998;&#31867;&#30340;&#29289;&#20307;&#65292;&#30830;&#20445;&#23427;&#20204;&#22312;&#38656;&#35201;&#26368;&#22823;&#23433;&#20840;&#20445;&#35777;&#26102;&#30340;&#23454;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26032;&#39062;&#30340;&#38598;&#25104;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#24418;&#24335;&#65292;&#20197;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07263v1 Announce Type: cross  Abstract: Quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. We consider quantifying such uncertainty for multi-object detection. In particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. One challenge in doing so is that bounding box predictions are conditioned on the object's class label. Thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals for the bounding boxes. This broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, ensuring their usefulness when maximal safety assurances are required. Moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage across
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#39318;&#27425;&#25552;&#20986;&#20102;&#20026;&#24503;&#22269;&#36830;&#32493;&#26085;&#20869;&#24066;&#22330;&#20132;&#26131;&#30340;&#30005;&#21147;&#20215;&#26684;&#36827;&#34892;&#36125;&#21494;&#26031;&#39044;&#27979;&#65292;&#32771;&#34385;&#20102;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#22312;2022&#24180;&#30340;&#30005;&#21147;&#20215;&#26684;&#39564;&#35777;&#20013;&#21462;&#24471;&#20102;&#32479;&#35745;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2403.05441</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#23618;&#27425;&#27010;&#29575;&#30340;&#26085;&#20869;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Bayesian Hierarchical Probabilistic Forecasting of Intraday Electricity Prices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05441
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#39318;&#27425;&#25552;&#20986;&#20102;&#20026;&#24503;&#22269;&#36830;&#32493;&#26085;&#20869;&#24066;&#22330;&#20132;&#26131;&#30340;&#30005;&#21147;&#20215;&#26684;&#36827;&#34892;&#36125;&#21494;&#26031;&#39044;&#27979;&#65292;&#32771;&#34385;&#20102;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#22312;2022&#24180;&#30340;&#30005;&#21147;&#20215;&#26684;&#39564;&#35777;&#20013;&#21462;&#24471;&#20102;&#32479;&#35745;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#23545;&#24503;&#22269;&#36830;&#32493;&#26085;&#20869;&#24066;&#22330;&#20132;&#26131;&#30340;&#30005;&#21147;&#20215;&#26684;&#36827;&#34892;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#30740;&#31350;&#65292;&#20805;&#20998;&#32771;&#34385;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#21464;&#37327;&#26159;IDFull&#20215;&#26684;&#25351;&#25968;&#65292;&#39044;&#27979;&#20197;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#30340;&#24418;&#24335;&#32473;&#20986;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;2022&#24180;&#26497;&#24230;&#27874;&#21160;&#30340;&#30005;&#21147;&#20215;&#26684;&#36827;&#34892;&#39564;&#35777;&#65292;&#22312;&#20043;&#21069;&#20960;&#20046;&#27809;&#26377;&#25104;&#20026;&#39044;&#27979;&#30740;&#31350;&#23545;&#35937;&#12290;&#20316;&#20026;&#22522;&#20934;&#27169;&#22411;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#39044;&#27979;&#21019;&#24314;&#26102;&#30340;&#25152;&#26377;&#21487;&#29992;&#26085;&#20869;&#20132;&#26131;&#26469;&#35745;&#31639;IDFull&#30340;&#24403;&#21069;&#20540;&#12290;&#26681;&#25454;&#24369;&#24335;&#26377;&#25928;&#20551;&#35774;&#65292;&#20174;&#26368;&#21518;&#20215;&#26684;&#20449;&#24687;&#24314;&#31435;&#30340;&#22522;&#20934;&#26080;&#27861;&#26174;&#33879;&#25913;&#21892;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#28857;&#24230;&#37327;&#21644;&#27010;&#29575;&#35780;&#20998;&#26041;&#38754;&#23384;&#22312;&#30528;&#32479;&#35745;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#22312;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#20013;&#20351;&#29992;LASSO&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#30340;&#23459;&#24067;&#30340;&#40644;&#37329;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05441v1 Announce Type: cross  Abstract: We present a first study of Bayesian forecasting of electricity prices traded on the German continuous intraday market which fully incorporates parameter uncertainty. Our target variable is the IDFull price index, forecasts are given in terms of posterior predictive distributions. For validation we use the exceedingly volatile electricity prices of 2022, which have hardly been the subject of forecasting studies before. As a benchmark model, we use all available intraday transactions at the time of forecast creation to compute a current value for the IDFull. According to the weak-form efficiency hypothesis, it would not be possible to significantly improve this benchmark built from last price information. We do, however, observe statistically significant improvement in terms of both point measures and probability scores. Finally, we challenge the declared gold standard of using LASSO for feature selection in electricity price forecastin
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#31639;&#23376;&#25512;&#26029;&#23398;&#20064;&#30340;&#38477;&#38454;&#27169;&#22411;&#22312;&#36807;&#31243;&#24037;&#31243;&#20013;&#24314;&#27169;&#21160;&#24577;&#31995;&#32479;&#65292;&#20026;&#23454;&#29616;&#24555;&#36895;&#21487;&#38752;&#30340;&#25968;&#23383;&#23402;&#29983;&#26550;&#26500;&#36808;&#20986;&#37325;&#35201;&#19968;&#27493;&#12290;</title><link>https://arxiv.org/abs/2402.17698</link><description>&lt;p&gt;
&#22312;&#36807;&#31243;&#24037;&#31243;&#20013;&#20351;&#29992;&#31639;&#23376;&#25512;&#26029;&#23398;&#20064;&#38477;&#38454;&#20108;&#27425;-&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning reduced-order Quadratic-Linear models in Process Engineering using Operator Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17698
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#31639;&#23376;&#25512;&#26029;&#23398;&#20064;&#30340;&#38477;&#38454;&#27169;&#22411;&#22312;&#36807;&#31243;&#24037;&#31243;&#20013;&#24314;&#27169;&#21160;&#24577;&#31995;&#32479;&#65292;&#20026;&#23454;&#29616;&#24555;&#36895;&#21487;&#38752;&#30340;&#25968;&#23383;&#23402;&#29983;&#26550;&#26500;&#36808;&#20986;&#37325;&#35201;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#36807;&#31243;&#24037;&#31243;&#20013;&#39640;&#25928;&#24314;&#27169;&#21160;&#24577;&#31995;&#32479;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#20351;&#29992;&#38477;&#38454;&#27169;&#22411;&#23398;&#20064;&#65292;&#20855;&#20307;&#26469;&#35828;&#26159;&#31639;&#23376;&#25512;&#26029;&#12290;&#36825;&#26159;&#19968;&#31181;&#38750;&#20405;&#20837;&#24335;&#12289;&#25968;&#25454;&#39537;&#21160;&#30340;&#20174;&#26102;&#22495;&#25968;&#25454;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24212;&#29992;&#26159;&#20108;&#27687;&#21270;&#30899;&#30002;&#28919;&#21270;&#21453;&#24212;&#65292;&#36825;&#26159;&#30005;&#21147;&#36716;&#21270;&#25216;&#26415;&#26694;&#26550;&#20013;&#30340;&#37325;&#35201;&#21453;&#24212;&#65292;&#20197;&#23637;&#31034;&#20854;&#28508;&#21147;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#29992;&#31639;&#23376;&#25512;&#26029;&#26500;&#24314;&#30340;&#38477;&#38454;&#27169;&#22411;&#33021;&#22815;&#25552;&#20379;&#19968;&#20010;&#31616;&#21270;&#20294;&#20934;&#30830;&#30340;&#26367;&#20195;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#26631;&#24535;&#30528;&#23454;&#29616;&#24555;&#36895;&#21487;&#38752;&#25968;&#23383;&#23402;&#29983;&#26550;&#26500;&#30340;&#37325;&#35201;&#37324;&#31243;&#30865;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17698v1 Announce Type: cross  Abstract: In this work, we address the challenge of efficiently modeling dynamical systems in process engineering. We use reduced-order model learning, specifically operator inference. This is a non-intrusive, data-driven method for learning dynamical systems from time-domain data. The application in our study is carbon dioxide methanation, an important reaction within the Power-to-X framework, to demonstrate its potential. The numerical results show the ability of the reduced-order models constructed with operator inference to provide a reduced yet accurate surrogate solution. This represents an important milestone towards the implementation of fast and reliable digital twin architectures.
&lt;/p&gt;</description></item><item><title>&#35843;&#26597;&#20102;&#22810;&#26234;&#33021;&#20307;&#12289;&#20154;&#26234;&#33021;&#20307;&#21644;&#20154;&#24037;&#26234;&#33021;&#26234;&#33021;&#20307;&#22312;&#31038;&#20250;&#22256;&#22659;&#21512;&#20316;&#20013;&#30340;&#19977;&#20010;&#20851;&#38190;&#39046;&#22495;&#65292;&#35752;&#35770;&#20102;&#21512;&#20316;&#30340;&#21160;&#26426;&#12289;&#31574;&#30053;&#12289;&#20154;&#31867;&#20559;&#35265;&#65292;&#20197;&#21450;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2402.17270</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#12289;&#20154;&#26234;&#33021;&#20307;&#21450;&#20854;&#36827;&#23637;&#65306;&#21512;&#20316;&#22312;&#31038;&#20250;&#22256;&#22659;&#20013;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17270
&lt;/p&gt;
&lt;p&gt;
&#35843;&#26597;&#20102;&#22810;&#26234;&#33021;&#20307;&#12289;&#20154;&#26234;&#33021;&#20307;&#21644;&#20154;&#24037;&#26234;&#33021;&#26234;&#33021;&#20307;&#22312;&#31038;&#20250;&#22256;&#22659;&#21512;&#20316;&#20013;&#30340;&#19977;&#20010;&#20851;&#38190;&#39046;&#22495;&#65292;&#35752;&#35770;&#20102;&#21512;&#20316;&#30340;&#21160;&#26426;&#12289;&#31574;&#30053;&#12289;&#20154;&#31867;&#20559;&#35265;&#65292;&#20197;&#21450;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20250;&#22256;&#22659;&#20013;&#30740;&#31350;&#21512;&#20316;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#26159;&#21508;&#31181;&#23398;&#31185;&#30340;&#22522;&#26412;&#35838;&#39064;&#65292;&#21253;&#25324;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#12290;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#26174;&#33879;&#37325;&#22609;&#20102;&#36825;&#19968;&#39046;&#22495;&#65292;&#20026;&#29702;&#35299;&#21644;&#22686;&#24378;&#21512;&#20316;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#26412;&#35843;&#26597;&#32771;&#23519;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#31038;&#20250;&#22256;&#22659;&#21512;&#20316;&#20132;&#27719;&#22788;&#30340;&#19977;&#20010;&#20851;&#38190;&#39046;&#22495;&#12290;&#39318;&#20808;&#65292;&#30528;&#37325;&#20110;&#22810;&#26234;&#33021;&#20307;&#21512;&#20316;&#65292;&#25105;&#20204;&#23457;&#26597;&#20102;&#25903;&#25345;&#29702;&#24615;&#26234;&#33021;&#20307;&#20043;&#38388;&#21512;&#20316;&#30340;&#20869;&#22312;&#21644;&#22806;&#22312;&#21160;&#26426;&#65292;&#20197;&#21450;&#29992;&#20110;&#21046;&#23450;&#26377;&#25928;&#31574;&#30053;&#23545;&#25239;&#19981;&#21516;&#23545;&#25163;&#30340;&#26041;&#27861;&#12290;&#20854;&#27425;&#65292;&#25506;&#35752;&#20102;&#20154;&#26234;&#33021;&#20307;&#21512;&#20316;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#24403;&#21069;&#29992;&#20110;&#19982;&#20154;&#31867;&#21512;&#20316;&#30340;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#65292;&#20197;&#21450;&#20154;&#31867;&#23545;&#20154;&#24037;&#26234;&#33021;&#26234;&#33021;&#20307;&#30340;&#20559;&#35265;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#23457;&#26597;&#20102;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#26234;&#33021;&#20307;&#22686;&#24378;&#20154;&#31867;&#21512;&#20316;&#30340;&#26032;&#20852;&#39046;&#22495;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#65292;&#20363;&#22914; u
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17270v1 Announce Type: new  Abstract: The study of cooperation within social dilemmas has long been a fundamental topic across various disciplines, including computer science and social science. Recent advancements in Artificial Intelligence (AI) have significantly reshaped this field, offering fresh insights into understanding and enhancing cooperation. This survey examines three key areas at the intersection of AI and cooperation in social dilemmas. First, focusing on multi-agent cooperation, we review the intrinsic and external motivations that support cooperation among rational agents, and the methods employed to develop effective strategies against diverse opponents. Second, looking into human-agent cooperation, we discuss the current AI algorithms for cooperating with humans and the human biases towards AI agents. Third, we review the emergent field of leveraging AI agents to enhance cooperation among humans. We conclude by discussing future research avenues, such as u
&lt;/p&gt;</description></item><item><title>SimPro&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#24230;&#36866;&#24212;&#30340;&#26694;&#26550;&#65292;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20851;&#20110;&#26410;&#26631;&#35760;&#25968;&#25454;&#20998;&#24067;&#30340;&#39044;&#23450;&#20041;&#20551;&#35774;&#65292;&#36890;&#36807;&#21019;&#26032;&#22320;&#25913;&#36827;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#65292;&#26126;&#30830;&#20998;&#31163;&#26465;&#20214;&#21644;&#36793;&#32536;&#31867;&#21035;&#20998;&#24067;&#30340;&#24314;&#27169;&#12290;</title><link>https://arxiv.org/abs/2402.13505</link><description>&lt;p&gt;
SimPro&#65306;&#19968;&#20010;&#31616;&#21333;&#30340;&#27010;&#29575;&#26694;&#26550;&#23454;&#29616;&#36924;&#30495;&#30340;&#38271;&#23614;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SimPro: A Simple Probabilistic Framework Towards Realistic Long-Tailed Semi-Supervised Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13505
&lt;/p&gt;
&lt;p&gt;
SimPro&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#24230;&#36866;&#24212;&#30340;&#26694;&#26550;&#65292;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20851;&#20110;&#26410;&#26631;&#35760;&#25968;&#25454;&#20998;&#24067;&#30340;&#39044;&#23450;&#20041;&#20551;&#35774;&#65292;&#36890;&#36807;&#21019;&#26032;&#22320;&#25913;&#36827;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#65292;&#26126;&#30830;&#20998;&#31163;&#26465;&#20214;&#21644;&#36793;&#32536;&#31867;&#21035;&#20998;&#24067;&#30340;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#38598;&#20013;&#22312;&#35299;&#20915;&#19968;&#20010;&#26356;&#20026;&#36924;&#30495;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65306;&#35299;&#20915;&#26631;&#35760;&#25968;&#25454;&#30340;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#21516;&#26102;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#31867;&#21035;&#20998;&#24067;&#26082;&#26410;&#30693;&#21448;&#21487;&#33021;&#19981;&#21305;&#37197;&#12290;&#24403;&#21069;&#36825;&#19968;&#39046;&#22495;&#30340;&#26041;&#27861;&#24448;&#24448;&#39044;&#35774;&#20102;&#20851;&#20110;&#26410;&#26631;&#35760;&#25968;&#25454;&#31867;&#21035;&#20998;&#24067;&#30340;&#20005;&#26684;&#20551;&#35774;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#27169;&#22411;&#20165;&#36866;&#24212;&#20110;&#26576;&#20123;&#20998;&#24067;&#33539;&#22260;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#39640;&#24230;&#36866;&#24212;&#24615;&#30340;&#26694;&#26550;&#65292;&#21629;&#21517;&#20026;SimPro&#65292;&#23427;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20851;&#20110;&#26410;&#26631;&#35760;&#25968;&#25454;&#20998;&#24067;&#30340;&#39044;&#23450;&#20041;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24314;&#31435;&#22312;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#19978;&#65292;&#36890;&#36807;&#26126;&#30830;&#20998;&#31163;&#26465;&#20214;&#21644;&#36793;&#32536;&#31867;&#21035;&#20998;&#24067;&#30340;&#24314;&#27169;&#65292;&#21019;&#26032;&#22320;&#25913;&#36827;&#20102;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#12290;&#36825;&#31181;&#20998;&#31163;&#20419;&#36827;&#20102;&#22312;&#26368;&#22823;&#21270;&#36807;&#31243;&#20013;&#23545;&#31867;&#21035;&#20998;&#24067;&#36827;&#34892;&#20272;&#35745;&#30340;&#38381;&#21512;&#24418;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13505v1 Announce Type: new  Abstract: Recent advancements in semi-supervised learning have focused on a more realistic yet challenging task: addressing imbalances in labeled data while the class distribution of unlabeled data remains both unknown and potentially mismatched. Current approaches in this sphere often presuppose rigid assumptions regarding the class distribution of unlabeled data, thereby limiting the adaptability of models to only certain distribution ranges. In this study, we propose a novel approach, introducing a highly adaptable framework, designated as SimPro, which does not rely on any predefined assumptions about the distribution of unlabeled data. Our framework, grounded in a probabilistic model, innovatively refines the expectation-maximization (EM) algorithm by explicitly decoupling the modeling of conditional and marginal class distributions. This separation facilitates a closed-form solution for class distribution estimation during the maximization p
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#65292;&#22312;&#20248;&#21270;&#22823;&#35268;&#27169;&#20154;&#32676;&#20013;&#30340;&#34920;&#29616;&#26041;&#38754;&#25552;&#20379;&#20102;&#23574;&#38160;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;&#26032;&#39062;&#30340;&#35265;&#35299;</title><link>https://arxiv.org/abs/2402.10592</link><description>&lt;p&gt;
&#20248;&#21270;&#33258;&#36866;&#24212;&#23454;&#39564;&#65306;&#26368;&#23567;&#21270;&#21518;&#24724;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#32479;&#19968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimizing Adaptive Experiments: A Unified Approach to Regret Minimization and Best-Arm Identification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10592
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#65292;&#22312;&#20248;&#21270;&#22823;&#35268;&#27169;&#20154;&#32676;&#20013;&#30340;&#34920;&#29616;&#26041;&#38754;&#25552;&#20379;&#20102;&#23574;&#38160;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;&#26032;&#39062;&#30340;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#34892;&#33258;&#36866;&#24212;&#23454;&#39564;&#30340;&#20174;&#19994;&#32773;&#36890;&#24120;&#38754;&#20020;&#20004;&#20010;&#31454;&#20105;&#24615;&#20248;&#20808;&#32423;&#65306;&#36890;&#36807;&#22312;&#23454;&#39564;&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#20998;&#37197;&#27835;&#30103;&#26469;&#38477;&#20302;&#23454;&#39564;&#25104;&#26412;&#65292;&#20197;&#21450;&#36805;&#36895;&#25910;&#38598;&#20449;&#24687;&#20197;&#32467;&#26463;&#23454;&#39564;&#24182;&#22312;&#25972;&#20010;&#20154;&#32676;&#20013;&#23454;&#26045;&#27835;&#30103;&#12290;&#24403;&#21069;&#65292;&#25991;&#29486;&#24847;&#35265;&#20998;&#27495;&#65292;&#26377;&#20851;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#30740;&#31350;&#29420;&#31435;&#22320;&#22788;&#29702;&#21069;&#32773;&#30340;&#20248;&#20808;&#32423;&#65292;&#32780;&#26377;&#20851;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#30740;&#31350;&#21017;&#19987;&#27880;&#20110;&#21518;&#32773;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#32771;&#34385;&#21040;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20379;&#20102;&#19968;&#20010;&#38024;&#23545;&#22823;&#35268;&#27169;&#20154;&#32676;&#30340;&#26368;&#20339;&#24615;&#33021;&#30340;&#23574;&#38160;&#29702;&#35770;&#65292;&#23558;&#25991;&#29486;&#20013;&#30340;&#32463;&#20856;&#32467;&#26524;&#32479;&#19968;&#36215;&#26469;&#12290;&#36825;&#31181;&#32479;&#19968;&#36824;&#25581;&#31034;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#20363;&#22914;&#65292;&#29702;&#35770;&#25581;&#31034;&#20102;&#31867;&#20284;&#26368;&#36817;&#25552;&#20986;&#30340;&#39030;&#37096;&#20004;&#20010;Thompson&#25277;&#26679;&#31639;&#27861;&#31561;&#29087;&#24713;&#31639;&#27861;&#21487;&#34987;&#35843;&#25972;&#20197;&#20248;&#21270;&#24191;&#27867;&#31867;&#21035;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10592v1 Announce Type: new  Abstract: Practitioners conducting adaptive experiments often encounter two competing priorities: reducing the cost of experimentation by effectively assigning treatments during the experiment itself, and gathering information swiftly to conclude the experiment and implement a treatment across the population. Currently, the literature is divided, with studies on regret minimization addressing the former priority in isolation, and research on best-arm identification focusing solely on the latter. This paper proposes a unified model that accounts for both within-experiment performance and post-experiment outcomes. We then provide a sharp theory of optimal performance in large populations that unifies canonical results in the literature. This unification also uncovers novel insights. For example, the theory reveals that familiar algorithms, like the recently proposed top-two Thompson sampling algorithm, can be adapted to optimize a broad class of obj
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#21407;&#23376;&#38388;&#21183;&#27169;&#22411;&#65292;&#20351;&#29992;&#22522;&#20110;&#31515;&#21345;&#23572;&#22352;&#26631;&#30340;&#21407;&#23376;&#23494;&#24230;&#23637;&#24320;&#26469;&#26367;&#20195;&#20256;&#32479;&#30340;&#21407;&#23376;&#22242;&#31751;&#23637;&#24320;&#26041;&#27861;&#65292;&#24182;&#32467;&#21512;&#20302;&#32500;&#23884;&#20837;&#21644;&#21407;&#23376;&#38388;&#28040;&#24687;&#20256;&#36882;&#12290;&#35813;&#27169;&#22411;&#22312;&#19981;&#21516;&#31995;&#32479;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07472</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21407;&#23376;&#22242;&#31751;&#23637;&#24320;&#22312;&#29289;&#36136;&#31185;&#23398;&#21644;&#21270;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Cartesian atomic cluster expansion for machine learning interatomic potentials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#21407;&#23376;&#38388;&#21183;&#27169;&#22411;&#65292;&#20351;&#29992;&#22522;&#20110;&#31515;&#21345;&#23572;&#22352;&#26631;&#30340;&#21407;&#23376;&#23494;&#24230;&#23637;&#24320;&#26469;&#26367;&#20195;&#20256;&#32479;&#30340;&#21407;&#23376;&#22242;&#31751;&#23637;&#24320;&#26041;&#27861;&#65292;&#24182;&#32467;&#21512;&#20302;&#32500;&#23884;&#20837;&#21644;&#21407;&#23376;&#38388;&#28040;&#24687;&#20256;&#36882;&#12290;&#35813;&#27169;&#22411;&#22312;&#19981;&#21516;&#31995;&#32479;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21407;&#23376;&#38388;&#21183;&#27491;&#22312;&#38761;&#26032;&#26448;&#26009;&#31185;&#23398;&#21644;&#21270;&#23398;&#20013;&#30340;&#22823;&#35268;&#27169;&#12289;&#20934;&#30830;&#30340;&#21407;&#23376;&#27169;&#25311;&#12290;&#36825;&#20123;&#21183;&#20989;&#25968;&#36890;&#24120;&#20351;&#29992;&#21407;&#23376;&#22242;&#31751;&#23637;&#24320;&#25110;&#21464;&#25442;&#28040;&#24687;&#20256;&#36882;&#19982;&#29699;&#35856;&#22522;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#20445;&#25345;&#26059;&#36716;&#23545;&#31216;&#24615;&#65292;&#20381;&#36182;Clebsch-Gordan&#31995;&#25968;&#20250;&#23548;&#33268;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#21644;&#20887;&#20313;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65306;&#22522;&#20110;&#31515;&#21345;&#23572;&#22352;&#26631;&#30340;&#21407;&#23376;&#23494;&#24230;&#23637;&#24320;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#30456;&#20114;&#20316;&#29992;&#20307;&#31995;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#23545;&#21407;&#23376;&#29615;&#22659;&#30340;&#23436;&#25972;&#25551;&#36848;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25972;&#21512;&#20102;&#21508;&#31181;&#21270;&#23398;&#20803;&#32032;&#30340;&#20302;&#32500;&#23884;&#20837;&#21644;&#21407;&#23376;&#38388;&#28040;&#24687;&#20256;&#36882;&#12290;&#25152;&#24471;&#21040;&#30340;&#21183;&#20989;&#25968;&#34987;&#21629;&#21517;&#20026;Cartesian Atomic Cluster Expansion(CACE)&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#31995;&#32479;&#20013;&#36827;&#34892;&#39564;&#35777;&#65292;&#21253;&#25324;&#22823;&#35268;&#27169;&#27700;&#12289;&#23567;&#20998;&#23376;&#21644;25&#31181;&#20803;&#32032;&#39640;&#29109;&#21512;&#37329;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning interatomic potentials are revolutionizing large-scale, accurate atomistic modelling in material science and chemistry. These potentials often use atomic cluster expansion or equivariant message passing with spherical harmonics as basis functions. However, the dependence on Clebsch-Gordan coefficients for maintaining rotational symmetry leads to computational inefficiencies and redundancies. We propose an alternative: a Cartesian-coordinates-based atomic density expansion. This approach provides a complete description of atomic environments while maintaining interaction body orders. Additionally, we integrate low-dimensional embeddings of various chemical elements and inter-atomic message passing. The resulting potential, named Cartesian Atomic Cluster Expansion (CACE), exhibits good accuracy, stability, and generalizability. We validate its performance in diverse systems, including bulk water, small molecules, and 25-element high-entropy alloys.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#26680;&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#24182;&#39564;&#35777;&#20102;&#19981;&#21516;&#30340;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06763</link><description>&lt;p&gt;
&#20351;&#29992;Nystr\"om&#36817;&#20284;&#30340;&#21487;&#25193;&#23637;&#26680;&#36923;&#36753;&#22238;&#24402;&#65306;&#29702;&#35770;&#20998;&#26512;&#21644;&#31163;&#25955;&#36873;&#25321;&#24314;&#27169;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Scalable Kernel Logistic Regression with Nystr\"om Approximation: Theoretical Analysis and Application to Discrete Choice Modelling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#26680;&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#24182;&#39564;&#35777;&#20102;&#19981;&#21516;&#30340;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22522;&#20110;&#26680;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#24212;&#29992;&#20110;&#20351;&#29992;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#31163;&#25955;&#36873;&#25321;&#24314;&#27169;&#26102;&#65292;&#32463;&#24120;&#38754;&#20020;&#23384;&#20648;&#38656;&#27714;&#21644;&#27169;&#22411;&#20013;&#28041;&#21450;&#30340;&#22823;&#37327;&#21442;&#25968;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#24433;&#21709;&#20102;&#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#26680;&#36923;&#36753;&#22238;&#24402;&#12290;&#30740;&#31350;&#39318;&#20808;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20854;&#20013;&#65306;i) &#23545;KLR&#35299;&#30340;&#38598;&#21512;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;ii) &#32473;&#20986;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#30340;KLR&#35299;&#30340;&#19978;&#30028;&#65292;&#24182;&#26368;&#21518;&#25551;&#36848;&#20102;&#19987;&#38376;&#29992;&#20110;Nystr\"om KLR&#30340;&#20248;&#21270;&#31639;&#27861;&#30340;&#29305;&#21270;&#12290;&#20043;&#21518;&#65292;&#23545;Nystr\"om KLR&#36827;&#34892;&#20102;&#35745;&#31639;&#39564;&#35777;&#12290;&#27979;&#35797;&#20102;&#22235;&#31181;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#26412;&#22343;&#21248;&#37319;&#26679;&#12289;k-means&#37319;&#26679;&#31574;&#30053;&#21644;&#22522;&#20110;&#26464;&#26438;&#24471;&#20998;&#30340;&#20004;&#31181;&#38750;&#22343;&#21248;&#26041;&#27861;&#12290;&#36825;&#20123;&#31574;&#30053;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The application of kernel-based Machine Learning (ML) techniques to discrete choice modelling using large datasets often faces challenges due to memory requirements and the considerable number of parameters involved in these models. This complexity hampers the efficient training of large-scale models. This paper addresses these problems of scalability by introducing the Nystr\"om approximation for Kernel Logistic Regression (KLR) on large datasets. The study begins by presenting a theoretical analysis in which: i) the set of KLR solutions is characterised, ii) an upper bound to the solution of KLR with Nystr\"om approximation is provided, and finally iii) a specialisation of the optimisation algorithms to Nystr\"om KLR is described. After this, the Nystr\"om KLR is computationally validated. Four landmark selection methods are tested, including basic uniform sampling, a k-means sampling strategy, and two non-uniform methods grounded in leverage scores. The performance of these strategi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#38480;&#21046;&#65292;&#36890;&#36807;&#20248;&#21270;&#34203;&#23450;&#35860;&#26725;&#30340;&#21442;&#25968;&#21270;&#26469;&#24674;&#22797;&#36755;&#36816;&#35745;&#21010;&#12290;</title><link>https://arxiv.org/abs/2402.03207</link><description>&lt;p&gt;
&#20809;&#23398;&#19982;&#20248;&#21270;&#30340;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Light and Optimal Schr\"odinger Bridge Matching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03207
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#38480;&#21046;&#65292;&#36890;&#36807;&#20248;&#21270;&#34203;&#23450;&#35860;&#26725;&#30340;&#21442;&#25968;&#21270;&#26469;&#24674;&#22797;&#36755;&#36816;&#35745;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;(SB)&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#26426;&#22120;&#23398;&#20064;&#30028;&#30340;&#20851;&#27880;&#65292;&#20316;&#20026;&#32463;&#20856;&#25193;&#25955;&#27169;&#22411;&#30340;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#25193;&#23637;&#65292;&#20063;&#19982;&#29109;&#26368;&#20248;&#36755;&#36816;(EOT)&#30456;&#20114;&#20851;&#32852;&#12290;&#26368;&#36817;&#30340;SB&#27714;&#35299;&#22120;&#21033;&#29992;&#20102;&#26222;&#36941;&#30340;&#26725;&#21305;&#37197;&#31243;&#24207;&#12290;&#36825;&#20123;&#31243;&#24207;&#26088;&#22312;&#22312;&#21482;&#26377;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#36755;&#36816;&#35745;&#21010;&#30340;&#24773;&#20917;&#19979;&#65292;&#24674;&#22797;&#19968;&#31181;&#38543;&#26426;&#36807;&#31243;&#26469;&#36755;&#36816;&#36136;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#32473;&#23450;EOT&#35745;&#21010;&#65292;&#36825;&#20123;&#31243;&#24207;&#21487;&#20197;&#34987;&#36866;&#24212;&#29992;&#20110;&#35299;&#20915;SB&#12290;&#36825;&#20010;&#20107;&#23454;&#34987;&#26368;&#36817;&#30340;&#30740;&#31350;&#24037;&#20316;&#24191;&#27867;&#21033;&#29992;&#65292;&#24418;&#25104;&#20102;&#22522;&#20110;&#21305;&#37197;&#30340;SB&#27714;&#35299;&#22120;&#12290;&#20851;&#38190;&#23601;&#26159;&#24674;&#22797;EOT&#35745;&#21010;&#65306;&#26368;&#36817;&#30340;&#24037;&#20316;&#35201;&#20040;&#20351;&#29992;&#21551;&#21457;&#24335;&#30340;&#36817;&#20284;&#26041;&#27861;(&#22914;&#23567;&#25209;&#37327;&#36755;&#36816;)&#25110;&#32773;&#24314;&#31435;&#36845;&#20195;&#21305;&#37197;&#31243;&#24207;&#65292;&#36825;&#26679;&#35774;&#35745;&#19978;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#32047;&#31215;&#20102;&#35823;&#24046;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;SB&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;\textbf{&#20248;&#21270;&#30340;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;}&#12290;&#23427;&#21033;&#29992;&#20102;&#34203;&#23450;&#35860;&#26725;&#30340;&#26368;&#20248;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Schr\"odinger Bridges (SB) have recently gained the attention of the ML community as a promising extension of classic diffusion models which is also interconnected to the Entropic Optimal Transport (EOT). Recent solvers for SB exploit the pervasive bridge matching procedures. Such procedures aim to recover a stochastic process transporting the mass between distributions given only a transport plan between them. In particular, given the EOT plan, these procedures can be adapted to solve SB. This fact is heavily exploited by recent works giving rives to matching-based SB solvers. The cornerstone here is recovering the EOT plan: recent works either use heuristical approximations (e.g., the minibatch OT) or establish iterative matching procedures which by the design accumulate the error during the training. We address these limitations and propose a novel procedure to learn SB which we call the \textbf{optimal Schr\"odinger bridge matching}. It exploits the optimal parameterization of the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#29983;&#25104;AI&#27169;&#22411;&#22312;&#29983;&#25104;&#28145;&#24230;&#20266;&#36896;&#22270;&#20687;&#26102;&#22312;&#39057;&#22495;&#20013;&#30340;DCT&#31995;&#25968;&#30340;&#32479;&#35745;&#29305;&#24449;&#12290;&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#8220;&#36776;&#21035;&#25351;&#32441;&#8221;&#65292;&#21487;&#20197;&#21033;&#29992;&#23427;&#26469;&#25913;&#21892;&#29616;&#26377;&#30340;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.02209</link><description>&lt;p&gt;
&#20851;&#20110;&#22312;&#29983;&#25104;AI&#39046;&#22495;&#21033;&#29992;DCT&#36712;&#36857;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
On the Exploitation of DCT-Traces in the Generative-AI Domain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#29983;&#25104;AI&#27169;&#22411;&#22312;&#29983;&#25104;&#28145;&#24230;&#20266;&#36896;&#22270;&#20687;&#26102;&#22312;&#39057;&#22495;&#20013;&#30340;DCT&#31995;&#25968;&#30340;&#32479;&#35745;&#29305;&#24449;&#12290;&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#8220;&#36776;&#21035;&#25351;&#32441;&#8221;&#65292;&#21487;&#20197;&#21033;&#29992;&#23427;&#26469;&#25913;&#21892;&#29616;&#26377;&#30340;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#20266;&#36896;&#23545;&#20110;&#32593;&#32476;&#23433;&#20840;&#21644;&#25968;&#23383;&#21462;&#35777;&#39046;&#22495;&#26469;&#35828;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#32771;&#34385;&#21040;&#26368;&#36817;&#22522;&#20110;&#29983;&#25104;AI&#30340;&#35299;&#20915;&#26041;&#26696;&#25152;&#33719;&#24471;&#30340;&#39640;&#36136;&#37327;&#32467;&#26524;&#12290;&#20960;&#20046;&#25152;&#26377;&#29983;&#25104;&#27169;&#22411;&#22312;&#21512;&#25104;&#25968;&#25454;&#20013;&#30041;&#19979;&#20102;&#29420;&#29305;&#30340;&#30165;&#36857;&#65292;&#22914;&#26524;&#23545;&#20854;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#21644;&#35782;&#21035;&#65292;&#21487;&#20197;&#21033;&#29992;&#36825;&#20123;&#30165;&#36857;&#26469;&#25913;&#21892;&#29616;&#26377;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#22120;&#30340;&#27867;&#21270;&#38480;&#21046;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#30001;GAN&#21644;&#25193;&#25955;&#27169;&#22411;&#24341;&#25806;&#29983;&#25104;&#30340;&#28145;&#24230;&#20266;&#36896;&#22270;&#20687;&#22312;&#39057;&#22495;&#20013;&#30340;&#29305;&#24449;&#65292;&#35814;&#32454;&#30740;&#31350;&#20102;&#31163;&#25955;&#20313;&#24358;&#21464;&#25442;(DCT)&#31995;&#25968;&#30340;&#32479;&#35745;&#20998;&#24067;&#12290;&#25105;&#20204;&#35748;&#35782;&#21040;&#24182;&#38750;&#25152;&#26377;&#31995;&#25968;&#23545;&#22270;&#20687;&#26816;&#27979;&#30340;&#36129;&#29486;&#30456;&#21516;&#65292;&#25105;&#20204;&#20551;&#35774;&#23384;&#22312;&#19968;&#31181;&#29420;&#29305;&#30340;&#8220;&#36776;&#21035;&#25351;&#32441;&#8221;&#65292;&#23884;&#20837;&#22312;&#29305;&#23450;&#31995;&#25968;&#32452;&#21512;&#20013;&#12290;&#20026;&#20102;&#35782;&#21035;&#23427;&#20204;&#65292;&#25105;&#20204;&#23545;&#21508;&#31181;&#31995;&#25968;&#32452;&#21512;&#36827;&#34892;&#20102;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#21487;&#35299;&#37322;AI(XAI)&#30340;LIME&#31639;&#27861;&#26469;&#25628;&#32034;...
&lt;/p&gt;
&lt;p&gt;
Deepfakes represent one of the toughest challenges in the world of Cybersecurity and Digital Forensics, especially considering the high-quality results obtained with recent generative AI-based solutions. Almost all generative models leave unique traces in synthetic data that, if analyzed and identified in detail, can be exploited to improve the generalization limitations of existing deepfake detectors. In this paper we analyzed deepfake images in the frequency domain generated by both GAN and Diffusion Model engines, examining in detail the underlying statistical distribution of Discrete Cosine Transform (DCT) coefficients. Recognizing that not all coefficients contribute equally to image detection, we hypothesize the existence of a unique "discriminative fingerprint", embedded in specific combinations of coefficients. To identify them, Machine Learning classifiers were trained on various combinations of coefficients. In addition, the Explainable AI (XAI) LIME algorithm was used to sea
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;Infinite dSprites&#24037;&#20855;&#65292;&#29992;&#20110;&#21019;&#24314;&#20219;&#24847;&#38271;&#24230;&#30340;&#36830;&#32493;&#20998;&#31867;&#21644;&#20998;&#35299;&#22522;&#20934;&#65292;&#21487;&#20197;&#20840;&#38754;&#25511;&#21046;&#29983;&#25104;&#22240;&#32032;&#65292;&#26377;&#26395;&#32553;&#23567;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#19982;&#20154;&#31867;&#23398;&#20064;&#22312;&#21160;&#24577;&#24320;&#25918;&#29615;&#22659;&#20013;&#30340;&#24046;&#36317;</title><link>https://arxiv.org/abs/2312.16731</link><description>&lt;p&gt;
&#29992;&#20110;&#20998;&#35299;&#36830;&#32493;&#23398;&#20064;&#30340;&#26080;&#38480;dSprites&#65306;&#23558;&#35760;&#24518;&#32534;&#36753;&#19982;&#27867;&#21270;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16731
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;Infinite dSprites&#24037;&#20855;&#65292;&#29992;&#20110;&#21019;&#24314;&#20219;&#24847;&#38271;&#24230;&#30340;&#36830;&#32493;&#20998;&#31867;&#21644;&#20998;&#35299;&#22522;&#20934;&#65292;&#21487;&#20197;&#20840;&#38754;&#25511;&#21046;&#29983;&#25104;&#22240;&#32032;&#65292;&#26377;&#26395;&#32553;&#23567;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#19982;&#20154;&#31867;&#23398;&#20064;&#22312;&#21160;&#24577;&#24320;&#25918;&#29615;&#22659;&#20013;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#25345;&#32493;&#23398;&#20064;&#30340;&#33021;&#21147;&#21463;&#21040;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#38459;&#30861;&#65292;&#21363;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#26032;&#20219;&#21153;&#26102;&#20250;&#35206;&#30422;&#29616;&#26377;&#30693;&#35782;&#12290;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#12289;&#21442;&#25968;&#38548;&#31163;&#25110;&#25490;&#32451;&#26469;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#22312;&#20165;&#21253;&#21547;&#23569;&#25968;&#20219;&#21153;&#30340;&#22522;&#20934;&#27979;&#35797;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#20102;&#21462;&#24471;&#36827;&#23637;&#20197;&#32553;&#23567;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Infinite dSprites&#65292;&#36825;&#26159;&#19968;&#20010;&#31616;&#27905;&#30340;&#24037;&#20855;&#65292;&#21487;&#21019;&#24314;&#20219;&#24847;&#38271;&#24230;&#30340;&#36830;&#32493;&#20998;&#31867;&#21644;&#20998;&#35299;&#22522;&#20934;&#65292;&#24182;&#23545;&#29983;&#25104;&#22240;&#32032;&#25317;&#26377;&#23436;&#20840;&#25511;&#21046;&#12290;&#25105;&#20204;&#23637;&#31034;&#65292;&#22312;&#36275;&#22815;&#38271;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#65292;&#25152;&#26377;&#20027;&#35201;&#31867;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#37117;&#34920;&#29616;&#20986;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.16731v2 Announce Type: replace  Abstract: The ability of machine learning systems to learn continually is hindered by catastrophic forgetting, the tendency of neural networks to overwrite existing knowledge when learning a new task. Continual learning methods alleviate this problem through regularization, parameter isolation, or rehearsal, but they are typically evaluated on benchmarks comprising only a handful of tasks. In contrast, humans are able to learn continually in dynamic, open-world environments, effortlessly achieving one-shot memorization of unfamiliar objects and reliably recognizing them under various transformations. To make progress towards closing this gap, we introduce Infinite dSprites, a parsimonious tool for creating continual classification and disentanglement benchmarks of arbitrary length and with full control over generative factors. We show that over a sufficiently long time horizon, the performance of all major types of continual learning methods d
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GEEL&#30340;&#26032;&#22411;&#12289;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#22270;&#34920;&#31034;&#65292;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#37051;&#25509;&#30697;&#38453;&#22823;&#23567;&#21644;&#35789;&#27719;&#37327;&#65292;&#21516;&#26102;&#36890;&#36807;&#33410;&#28857;&#20301;&#32622;&#32534;&#30721;&#23454;&#29616;&#33258;&#22238;&#24402;&#29983;&#25104;&#65292;&#24182;&#38024;&#23545;&#23646;&#24615;&#22270;&#35774;&#35745;&#20102;&#26032;&#30340;&#25193;&#23637;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2312.02230</link><description>&lt;p&gt;
&#19968;&#31181;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#22270;&#29983;&#25104;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
A Simple and Scalable Representation for Graph Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02230
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GEEL&#30340;&#26032;&#22411;&#12289;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#22270;&#34920;&#31034;&#65292;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#37051;&#25509;&#30697;&#38453;&#22823;&#23567;&#21644;&#35789;&#27719;&#37327;&#65292;&#21516;&#26102;&#36890;&#36807;&#33410;&#28857;&#20301;&#32622;&#32534;&#30721;&#23454;&#29616;&#33258;&#22238;&#24402;&#29983;&#25104;&#65292;&#24182;&#38024;&#23545;&#23646;&#24615;&#22270;&#35774;&#35745;&#20102;&#26032;&#30340;&#25193;&#23637;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20154;&#20204;&#23545;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22270;&#29983;&#25104;&#20135;&#29983;&#20102;&#27987;&#21402;&#20852;&#36259;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#20851;&#38190;&#24212;&#29992;&#20215;&#20540;&#30340;&#22522;&#26412;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#65292;&#22914;&#20998;&#23376;&#35774;&#35745;&#21644;&#31038;&#21306;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#22312;&#29983;&#25104;&#22823;&#35268;&#27169;&#22270;&#26102;&#36935;&#21040;&#20102;&#37325;&#22823;&#38480;&#21046;&#12290;&#36825;&#26159;&#30001;&#20110;&#23427;&#20204;&#38656;&#35201;&#36755;&#20986;&#38543;&#30528;&#33410;&#28857;&#25968;&#37327;&#21576;&#20108;&#27425;&#22686;&#38271;&#30340;&#23436;&#25972;&#37051;&#25509;&#30697;&#38453;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#22270;&#34920;&#31034;&#65292;&#21517;&#20026;&#38388;&#38553;&#32534;&#30721;&#36793;&#21015;&#34920;&#65288;GEEL&#65289;&#65292;&#20854;&#34920;&#31034;&#22823;&#23567;&#36739;&#23567;&#19988;&#19982;&#36793;&#25968;&#37327;&#19968;&#33268;&#12290;&#27492;&#22806;&#65292;GEEL&#36890;&#36807;&#32467;&#21512;&#38388;&#38553;&#32534;&#30721;&#21644;&#24102;&#23485;&#38480;&#21046;&#26041;&#26696;&#26174;&#33879;&#20943;&#23569;&#20102;&#35789;&#27719;&#37327;&#12290;&#36890;&#36807;&#21152;&#20837;&#33410;&#28857;&#20301;&#32622;&#32534;&#30721;&#65292;GEEL&#21487;&#20197;&#33258;&#22238;&#24402;&#29983;&#25104;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;GEEL&#25193;&#23637;&#21040;&#22788;&#29702;&#23646;&#24615;&#22270;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#35821;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02230v2 Announce Type: replace-cross  Abstract: Recently, there has been a surge of interest in employing neural networks for graph generation, a fundamental statistical learning problem with critical applications like molecule design and community analysis. However, most approaches encounter significant limitations when generating large-scale graphs. This is due to their requirement to output the full adjacency matrices whose size grows quadratically with the number of nodes. In response to this challenge, we introduce a new, simple, and scalable graph representation named gap encoded edge list (GEEL) that has a small representation size that aligns with the number of edges. In addition, GEEL significantly reduces the vocabulary size by incorporating the gap encoding and bandwidth restriction schemes. GEEL can be autoregressively generated with the incorporation of node positional encoding, and we further extend GEEL to deal with attributed graphs by designing a new grammar
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2401.14283</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;
&lt;/p&gt;
&lt;p&gt;
Information Leakage Detection through Approximate Bayes-optimal Prediction. (arXiv:2401.14283v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20170;&#22825;&#30340;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#19990;&#30028;&#20013;&#65292;&#20844;&#24320;&#21487;&#33719;&#24471;&#30340;&#20449;&#24687;&#30340;&#22686;&#21152;&#21152;&#21095;&#20102;&#20449;&#24687;&#27844;&#28431;&#65288;IL&#65289;&#30340;&#25361;&#25112;&#65292;&#24341;&#21457;&#20102;&#23433;&#20840;&#38382;&#39064;&#12290;IL&#28041;&#21450;&#36890;&#36807;&#31995;&#32479;&#30340;&#21487;&#35266;&#23519;&#20449;&#24687;&#26080;&#24847;&#22320;&#23558;&#31192;&#23494;&#65288;&#25935;&#24863;&#65289;&#20449;&#24687;&#26292;&#38706;&#32473;&#26410;&#32463;&#25480;&#26435;&#30340;&#26041;&#65292;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#21487;&#35266;&#23519;&#20449;&#24687;&#21644;&#31192;&#23494;&#20449;&#24687;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#26469;&#26816;&#27979;IL&#65292;&#38754;&#20020;&#32500;&#24230;&#28798;&#38590;&#12289;&#25910;&#25947;&#12289;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;MI&#20272;&#35745;&#38169;&#35823;&#31561;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#26032;&#20852;&#30340;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#22312;&#20108;&#36827;&#21046;&#31995;&#32479;&#25935;&#24863;&#20449;&#24687;&#30340;&#26816;&#27979;&#19978;&#26377;&#25928;&#65292;&#20294;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#24314;&#31435;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;IL&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;MI&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predict
&lt;/p&gt;</description></item><item><title>SMOOTHIE&#26159;&#19968;&#31181;&#36890;&#36807;&#32771;&#34385;&#25439;&#22833;&#20989;&#25968;&#30340;&#8220;&#20809;&#28369;&#24230;&#8221;&#26469;&#24341;&#23548;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#26032;&#22411;&#26041;&#27861;&#65292;&#22312;&#36719;&#20214;&#20998;&#26512;&#20013;&#24212;&#29992;&#21487;&#20197;&#24102;&#26469;&#26174;&#33879;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.09622</link><description>&lt;p&gt;
SMOOTHIE: &#36719;&#20214;&#20998;&#26512;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
SMOOTHIE: A Theory of Hyper-parameter Optimization for Software Analytics. (arXiv:2401.09622v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09622
&lt;/p&gt;
&lt;p&gt;
SMOOTHIE&#26159;&#19968;&#31181;&#36890;&#36807;&#32771;&#34385;&#25439;&#22833;&#20989;&#25968;&#30340;&#8220;&#20809;&#28369;&#24230;&#8221;&#26469;&#24341;&#23548;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#26032;&#22411;&#26041;&#27861;&#65292;&#22312;&#36719;&#20214;&#20998;&#26512;&#20013;&#24212;&#29992;&#21487;&#20197;&#24102;&#26469;&#26174;&#33879;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#21442;&#25968;&#20248;&#21270;&#26159;&#35843;&#25972;&#23398;&#20064;&#22120;&#25511;&#21046;&#21442;&#25968;&#30340;&#40657;&#39764;&#27861;&#12290;&#22312;&#36719;&#20214;&#20998;&#26512;&#20013;&#65292;&#32463;&#24120;&#21457;&#29616;&#35843;&#20248;&#21487;&#20197;&#24102;&#26469;&#26174;&#33879;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#36229;&#21442;&#25968;&#20248;&#21270;&#22312;&#36719;&#20214;&#20998;&#26512;&#20013;&#36890;&#24120;&#34987;&#24456;&#23569;&#25110;&#24456;&#24046;&#22320;&#24212;&#29992;&#65292;&#21487;&#33021;&#26159;&#22240;&#20026;&#25506;&#32034;&#25152;&#26377;&#21442;&#25968;&#36873;&#39033;&#30340;CPU&#25104;&#26412;&#22826;&#39640;&#12290;&#25105;&#20204;&#20551;&#35774;&#24403;&#25439;&#22833;&#20989;&#25968;&#30340;&#8220;&#20809;&#28369;&#24230;&#8221;&#26356;&#22909;&#26102;&#65292;&#23398;&#20064;&#22120;&#30340;&#27867;&#21270;&#33021;&#21147;&#26356;&#24378;&#12290;&#36825;&#20010;&#29702;&#35770;&#38750;&#24120;&#26377;&#29992;&#65292;&#22240;&#20026;&#21487;&#20197;&#24456;&#24555;&#27979;&#35797;&#19981;&#21516;&#36229;&#21442;&#25968;&#36873;&#25321;&#23545;&#8220;&#20809;&#28369;&#24230;&#8221;&#30340;&#24433;&#21709;&#65288;&#20363;&#22914;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#22120;&#65292;&#22312;&#19968;&#20010;epoch&#20043;&#21518;&#23601;&#21487;&#20197;&#36827;&#34892;&#27979;&#35797;&#65289;&#12290;&#20026;&#20102;&#27979;&#35797;&#36825;&#20010;&#29702;&#35770;&#65292;&#26412;&#25991;&#23454;&#29616;&#21644;&#27979;&#35797;&#20102;SMOOTHIE&#65292;&#19968;&#31181;&#36890;&#36807;&#32771;&#34385;&#8220;&#20809;&#28369;&#24230;&#8221;&#26469;&#24341;&#23548;&#20248;&#21270;&#30340;&#26032;&#22411;&#36229;&#21442;&#25968;&#20248;&#21270;&#22120;&#12290;&#26412;&#25991;&#30340;&#23454;&#39564;&#23558;SMOOTHIE&#24212;&#29992;&#20110;&#22810;&#20010;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#65292;&#21253;&#25324;&#65288;a&#65289;GitHub&#38382;&#39064;&#23551;&#21629;&#39044;&#27979;&#65307;&#65288;b&#65289;&#38745;&#24577;&#20195;&#30721;&#35686;&#21578;&#20013;&#38169;&#35823;&#35686;&#25253;&#30340;&#26816;&#27979;&#65307;&#65288;c&#65289;&#32570;&#38519;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hyper-parameter optimization is the black art of tuning a learner's control parameters. In software analytics, a repeated result is that such tuning can result in dramatic performance improvements. Despite this, hyper-parameter optimization is often applied rarely or poorly in software analytics--perhaps due to the CPU cost of exploring all those parameter options can be prohibitive.  We theorize that learners generalize better when the loss landscape is ``smooth''. This theory is useful since the influence on ``smoothness'' of different hyper-parameter choices can be tested very quickly (e.g. for a deep learner, after just one epoch).  To test this theory, this paper implements and tests SMOOTHIE, a novel hyper-parameter optimizer that guides its optimizations via considerations of ``smothness''. The experiments of this paper test SMOOTHIE on numerous SE tasks including (a) GitHub issue lifetime prediction; (b) detecting false alarms in static code warnings; (c) defect prediction, and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;"&#65288;DSGNN&#65289;&#30340;&#26694;&#26550;&#65292;&#23427;&#23558;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#21160;&#24577;&#22270;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#24320;&#38144;&#38382;&#39064;&#12290;DSGNN&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#23574;&#23792;&#31070;&#32463;&#20803;&#30340;&#29366;&#24577;&#21644;&#36830;&#25509;&#26435;&#37325;&#65292;&#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#20445;&#25345;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#23436;&#25972;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.05373</link><description>&lt;p&gt;
&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Dynamic Spiking Graph Neural Networks. (arXiv:2401.05373v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05373
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;"&#65288;DSGNN&#65289;&#30340;&#26694;&#26550;&#65292;&#23427;&#23558;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#21160;&#24577;&#22270;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#24320;&#38144;&#38382;&#39064;&#12290;DSGNN&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#23574;&#23792;&#31070;&#32463;&#20803;&#30340;&#29366;&#24577;&#21644;&#36830;&#25509;&#26435;&#37325;&#65292;&#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#20445;&#25345;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30456;&#32467;&#21512;&#28176;&#28176;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#36825;&#26159;&#22240;&#20026;&#23427;&#22312;&#22788;&#29702;&#30001;&#22270;&#34920;&#31034;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#26102;&#20855;&#26377;&#20302;&#21151;&#32791;&#21644;&#39640;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#65292;&#21160;&#24577;&#22270;&#34920;&#31034;&#23398;&#20064;&#38754;&#20020;&#30528;&#39640;&#22797;&#26434;&#24615;&#21644;&#22823;&#20869;&#23384;&#24320;&#38144;&#30340;&#25361;&#25112;&#12290;&#30446;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#36890;&#36807;&#20351;&#29992;&#20108;&#36827;&#21046;&#29305;&#24449;&#32780;&#19981;&#26159;&#36830;&#32493;&#29305;&#24449;&#30340;SNNs&#26469;&#26367;&#20195;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNNs&#65289;&#36827;&#34892;&#39640;&#25928;&#35757;&#32451;&#65292;&#36825;&#20250;&#24573;&#35270;&#22270;&#32467;&#26500;&#20449;&#24687;&#24182;&#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#23548;&#33268;&#32454;&#33410;&#30340;&#20002;&#22833;&#12290;&#27492;&#22806;&#65292;&#20248;&#21270;&#21160;&#24577;&#23574;&#23792;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#22312;&#26102;&#38388;&#27493;&#20043;&#38388;&#20256;&#25773;&#20449;&#24687;&#65292;&#36825;&#22686;&#21152;&#20102;&#20869;&#23384;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;"&#65288;\method{}&#65289;&#30340;&#26694;&#26550;&#12290;&#20026;&#20102;&#20943;&#36731;&#20449;&#24687;&#20002;&#22833;&#38382;&#39064;&#65292;\method{} &#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#21046;&#65292;&#23427;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20013;&#21160;&#24577;&#22320;&#35843;&#25972;&#23574;&#23792;&#31070;&#32463;&#20803;&#30340;&#29366;&#24577;&#21644;&#36830;&#25509;&#26435;&#37325;&#65292;&#20197;&#20445;&#25345;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The integration of Spiking Neural Networks (SNNs) and Graph Neural Networks (GNNs) is gradually attracting attention due to the low power consumption and high efficiency in processing the non-Euclidean data represented by graphs. However, as a common problem, dynamic graph representation learning faces challenges such as high complexity and large memory overheads. Current work often uses SNNs instead of Recurrent Neural Networks (RNNs) by using binary features instead of continuous ones for efficient training, which would overlooks graph structure information and leads to the loss of details during propagation. Additionally, optimizing dynamic spiking models typically requires propagation of information across time steps, which increases memory requirements. To address these challenges, we present a framework named \underline{Dy}namic \underline{S}p\underline{i}king \underline{G}raph \underline{N}eural Networks (\method{}). To mitigate the information loss problem, \method{} propagates
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#30340;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;DQNLog&#65292;&#36890;&#36807;&#32467;&#21512;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;DQN&#31639;&#27861;&#65292;&#21033;&#29992;&#23569;&#37327;&#26377;&#26631;&#35760;&#30340;&#25968;&#25454;&#21644;&#22823;&#35268;&#27169;&#26080;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#21644;&#26631;&#35760;&#25968;&#37327;&#26377;&#38480;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#24322;&#24120;&#29615;&#22659;&#20132;&#20114;&#21644;&#20027;&#21160;&#25506;&#32034;&#26080;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#65292;&#23398;&#20064;&#24050;&#30693;&#30340;&#24322;&#24120;&#24182;&#21457;&#29616;&#26410;&#30693;&#30340;&#24322;&#24120;&#12290;</title><link>http://arxiv.org/abs/2401.03151</link><description>&lt;p&gt;
&#36890;&#36807;DQN&#36827;&#34892;&#21322;&#30417;&#30563;&#23398;&#20064;&#29992;&#20110;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning via DQN for log anomaly detection. (arXiv:2401.03151v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#30340;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;DQNLog&#65292;&#36890;&#36807;&#32467;&#21512;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;DQN&#31639;&#27861;&#65292;&#21033;&#29992;&#23569;&#37327;&#26377;&#26631;&#35760;&#30340;&#25968;&#25454;&#21644;&#22823;&#35268;&#27169;&#26080;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#21644;&#26631;&#35760;&#25968;&#37327;&#26377;&#38480;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#24322;&#24120;&#29615;&#22659;&#20132;&#20114;&#21644;&#20027;&#21160;&#25506;&#32034;&#26080;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#65292;&#23398;&#20064;&#24050;&#30693;&#30340;&#24322;&#24120;&#24182;&#21457;&#29616;&#26410;&#30693;&#30340;&#24322;&#24120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;&#22312;&#20445;&#38556;&#29616;&#20195;&#36719;&#20214;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#21644;&#32500;&#25252;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#30446;&#21069;&#65292;&#26816;&#27979;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#24322;&#24120;&#30340;&#20027;&#35201;&#26041;&#27861;&#26159;&#36890;&#36807;&#30417;&#30563;&#24335;&#24322;&#24120;&#26816;&#27979;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30417;&#30563;&#24335;&#26041;&#27861;&#24448;&#24448;&#20381;&#36182;&#20110;&#26377;&#26631;&#35760;&#30340;&#25968;&#25454;&#65292;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#24448;&#24448;&#21463;&#21040;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#30340;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#32467;&#21512;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;DQN&#31639;&#27861;&#65292;&#31216;&#20026;DQNLog&#12290;DQNLog&#21033;&#29992;&#23569;&#37327;&#26377;&#26631;&#35760;&#30340;&#25968;&#25454;&#21644;&#22823;&#35268;&#27169;&#26080;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#21644;&#26631;&#35760;&#25968;&#37327;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#36890;&#36807;&#19982;&#20559;&#21521;&#20110;&#24322;&#24120;&#30340;&#29615;&#22659;&#36827;&#34892;&#20132;&#20114;&#26469;&#23398;&#20064;&#24050;&#30693;&#30340;&#24322;&#24120;&#65292;&#36824;&#36890;&#36807;&#20027;&#21160;&#25506;&#32034;&#26080;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#26469;&#21457;&#29616;&#26410;&#30693;&#30340;&#24322;&#24120;&#12290;&#27492;&#22806;&#65292;DQNLog&#36824;&#24341;&#20837;&#20102;&#20132;&#21449;&#29109;&#25439;&#22833;&#39033;&#65292;&#38450;&#27490;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#20986;&#29616;&#27169;&#22411;&#36807;&#39640;&#20272;&#35745;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Log anomaly detection plays a critical role in ensuring the security and maintenance of modern software systems. At present, the primary approach for detecting anomalies in log data is through supervised anomaly detection. Nonetheless, existing supervised methods heavily rely on labeled data, which can be frequently limited in real-world scenarios. In this paper, we propose a semi-supervised log anomaly detection method that combines the DQN algorithm from deep reinforcement learning, which is called DQNLog. DQNLog leverages a small amount of labeled data and a large-scale unlabeled dataset, effectively addressing the challenges of imbalanced data and limited labeling. This approach not only learns known anomalies by interacting with an environment biased towards anomalies but also discovers unknown anomalies by actively exploring the unlabeled dataset. Additionally, DQNLog incorporates a cross-entropy loss term to prevent model overestimation during Deep Reinforcement Learning (DRL). 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;RKKS&#20013;&#23398;&#20064;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#26680;&#30340;&#20998;&#35299;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#65292;&#24182;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2310.13821</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Geometric Learning with Positively Decomposable Kernels. (arXiv:2310.13821v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;RKKS&#20013;&#23398;&#20064;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#26680;&#30340;&#20998;&#35299;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#65292;&#24182;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26041;&#27861;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;&#32463;&#20856;&#30340;&#26680;&#26041;&#27861;&#22522;&#20110;&#27491;&#23450;&#26680;&#65292;&#23558;&#25968;&#25454;&#31354;&#38388;&#26144;&#23556;&#21040;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#12290;&#23545;&#20110;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#31354;&#38388;&#65292;&#24456;&#38590;&#25214;&#21040;&#27491;&#23450;&#26680;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;&#37325;&#29616;&#26680;&#25511;&#21046;&#31354;&#38388;(RKKS)&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#21482;&#38656;&#35201;&#20855;&#26377;&#27491;&#20998;&#35299;&#30340;&#26680;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;RKKS&#20013;&#23398;&#20064;&#26102;&#65292;&#24182;&#19981;&#38656;&#35201;&#35775;&#38382;&#36825;&#20010;&#20998;&#35299;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#26680;&#27491;&#21487;&#20998;&#35299;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#21487;&#22788;&#29702;&#30340;&#27491;&#21017;&#24615;&#20551;&#35774;&#19979;&#65292;&#19981;&#21464;&#26680;&#22312;&#40784;&#27425;&#31354;&#38388;&#19978;&#20801;&#35768;&#27491;&#20998;&#35299;&#12290;&#36825;&#20351;&#24471;&#23427;&#20204;&#27604;&#27491;&#23450;&#26680;&#26356;&#23481;&#26131;&#26500;&#36896;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#12290;&#21516;&#26679;&#65292;&#36825;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#33324;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel methods are powerful tools in machine learning. Classical kernel methods are based on positive-definite kernels, which map data spaces into reproducing kernel Hilbert spaces (RKHS). For non-Euclidean data spaces, positive-definite kernels are difficult to come by. In this case, we propose the use of reproducing kernel Krein space (RKKS) based methods, which require only kernels that admit a positive decomposition. We show that one does not need to access this decomposition in order to learn in RKKS. We then investigate the conditions under which a kernel is positively decomposable. We show that invariant kernels admit a positive decomposition on homogeneous spaces under tractable regularity assumptions. This makes them much easier to construct than positive-definite kernels, providing a route for learning with kernels for non-Euclidean data. By the same token, this provides theoretical foundations for RKKS-based methods in general.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#30340;&#26032;&#22411;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#20351;&#29992;&#20998;&#27835;&#31574;&#30053;&#23558;&#27880;&#24847;&#21147;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#20174;O(n^2)&#38477;&#20302;&#21040;O(n log n)&#25110;O(n)&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#20840;&#23616;&#24863;&#30693;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2310.11960</link><description>&lt;p&gt;
&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#65306;&#19968;&#31181;&#29992;&#20110;&#38271;&#24207;&#21015;&#30340;&#20998;&#27835;&#27880;&#24847;&#21147;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for Long Sequences. (arXiv:2310.11960v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11960
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#30340;&#26032;&#22411;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#20351;&#29992;&#20998;&#27835;&#31574;&#30053;&#23558;&#27880;&#24847;&#21147;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#20174;O(n^2)&#38477;&#20302;&#21040;O(n log n)&#25110;O(n)&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#20840;&#23616;&#24863;&#30693;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#24050;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#33258;&#27880;&#24847;&#21147;&#23545;&#20110;&#36755;&#20837;&#38271;&#24230;&#30340;&#20108;&#27425;&#22797;&#26434;&#24230;&#38480;&#21046;&#20102;Transformer&#27169;&#22411;&#22312;&#38271;&#24207;&#21015;&#19978;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#65292;&#19968;&#31181;&#20351;&#29992;&#20998;&#27835;&#31574;&#30053;&#26469;&#20943;&#23569;&#27880;&#24847;&#21147;&#26102;&#38388;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#30340;&#26032;&#22411;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23558;&#38271;&#24230;&#20026;n&#30340;&#24207;&#21015;&#30340;&#27880;&#24847;&#21147;&#22797;&#26434;&#24230;&#20174;O(n^2)&#38477;&#20302;&#21040;O(n log n)&#25110;O(n)&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#20840;&#23616;&#24863;&#30693;&#33539;&#22260;&#12290;&#36825;&#31181;&#20998;&#23618;&#26041;&#27861;&#23558;&#26597;&#35810;&#12289;&#38190;&#21644;&#20540;&#20998;&#20026;O(log n)&#32423;&#30340;&#20998;&#36776;&#29575;&#65292;&#36739;&#36828;&#36317;&#31163;&#30340;&#32452;&#32676;&#36234;&#26469;&#36234;&#22823;&#65292;&#24182;&#23398;&#20064;&#35745;&#31639;&#32452;&#32676;&#25968;&#37327;&#30340;&#26435;&#37325;&#12290;&#22240;&#27492;&#65292;&#20197;&#39640;&#25928;&#20998;&#23618;&#30340;&#26041;&#24335;&#22312;&#36739;&#20302;&#30340;&#20998;&#36776;&#29575;&#20013;&#32771;&#34385;&#36828;&#31163;&#24444;&#27492;&#30340;&#26631;&#35760;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#30340;&#24635;&#20307;&#22797;&#26434;&#24230;&#20026;O(n)&#25110;O(n log n)&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer-based models have achieved state-of-the-art performance in many areas. However, the quadratic complexity of self-attention with respect to the input length hinders the applicability of Transformer-based models to long sequences. To address this, we present Fast Multipole Attention, a new attention mechanism that uses a divide-and-conquer strategy to reduce the time and memory complexity of attention for sequences of length $n$ from $\mathcal{O}(n^2)$ to $\mathcal{O}(n \log n)$ or $O(n)$, while retaining a global receptive field. The hierarchical approach groups queries, keys, and values into $\mathcal{O}( \log n)$ levels of resolution, where groups at greater distances are increasingly larger in size and the weights to compute group quantities are learned. As such, the interaction between tokens far from each other is considered in lower resolution in an efficient hierarchical manner. The overall complexity of Fast Multipole Attention is $\mathcal{O}(n)$ or $\mathcal{O}(n \
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#27867;&#21270;&#33021;&#21147;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#20851;&#27880;&#35757;&#32451;&#20998;&#24067;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#19981;&#21305;&#37197;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#30340;&#27867;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.07171</link><description>&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#35770;&#20998;&#24067;&#22810;&#26679;&#21270;&#23454;&#29616;&#32852;&#37030;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Federated Generalization via Information-Theoretic Distribution Diversification. (arXiv:2310.07171v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07171
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#27867;&#21270;&#33021;&#21147;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#20851;&#27880;&#35757;&#32451;&#20998;&#24067;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#19981;&#21305;&#37197;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#30340;&#27867;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#22240;&#20854;&#22312;&#26080;&#38656;&#30452;&#25509;&#25968;&#25454;&#20849;&#20139;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21327;&#21516;&#27169;&#22411;&#35757;&#32451;&#30340;&#33021;&#21147;&#32780;&#26085;&#30410;&#31361;&#20986;&#12290;&#28982;&#32780;&#65292;&#23458;&#25143;&#31471;&#20043;&#38388;&#26412;&#22320;&#25968;&#25454;&#20998;&#24067;&#30340;&#24040;&#22823;&#24046;&#24322;&#65292;&#36890;&#24120;&#34987;&#31216;&#20026;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;non-IID&#65289;&#25361;&#25112;&#65292;&#23545;FL&#30340;&#27867;&#21270;&#33021;&#21147;&#26500;&#25104;&#20102;&#37325;&#22823;&#38556;&#30861;&#12290;&#24403;&#24182;&#38750;&#25152;&#26377;&#23458;&#25143;&#31471;&#37117;&#21442;&#19982;&#35757;&#32451;&#36807;&#31243;&#26102;&#65292;&#24773;&#20917;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#65292;&#36825;&#26159;&#30001;&#20110;&#19981;&#31283;&#23450;&#30340;&#32593;&#32476;&#36830;&#25509;&#25110;&#26377;&#38480;&#30340;&#35745;&#31639;&#33021;&#21147;&#32780;&#24120;&#35265;&#12290;&#36825;&#21487;&#33021;&#26497;&#22823;&#22320;&#22797;&#26434;&#21270;&#20102;&#23545;&#35757;&#32451;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#30340;&#35780;&#20272;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;&#22823;&#37327;&#30740;&#31350;&#38598;&#20013;&#22312;&#28041;&#21450;&#20855;&#26377;&#19981;&#21516;&#20998;&#24067;&#30340;&#21442;&#19982;&#23458;&#25143;&#31471;&#30340;&#26410;&#35265;&#25968;&#25454;&#30340;&#27867;&#21270;&#24046;&#36317;&#38382;&#39064;&#19978;&#65292;&#20294;&#21442;&#19982;&#23458;&#25143;&#31471;&#30340;&#35757;&#32451;&#20998;&#24067;&#21644;&#38750;&#21442;&#19982;&#23458;&#25143;&#31471;&#30340;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#21364;&#34987;&#22823;&#37096;&#20998;&#24573;&#35270;&#20102;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30340;&#35770;&#25991;&#25581;&#31034;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#27867;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) has surged in prominence due to its capability of collaborative model training without direct data sharing. However, the vast disparity in local data distributions among clients, often termed the non-Independent Identically Distributed (non-IID) challenge, poses a significant hurdle to FL's generalization efficacy. The scenario becomes even more complex when not all clients participate in the training process, a common occurrence due to unstable network connections or limited computational capacities. This can greatly complicate the assessment of the trained models' generalization abilities. While a plethora of recent studies has centered on the generalization gap pertaining to unseen data from participating clients with diverse distributions, the divergence between the training distributions of participating clients and the testing distributions of non-participating ones has been largely overlooked. In response, our paper unveils an information-theoretic genera
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22122;&#22768;&#23481;&#24525;&#30340;&#26080;&#30417;&#30563;&#36866;&#37197;&#22120;(NtUA)&#65292;&#23427;&#21487;&#20197;&#20351;&#29992;&#23569;&#26679;&#26412;&#26080;&#26631;&#31614;&#30446;&#26631;&#26679;&#26412;&#26469;&#23398;&#20064;&#20248;&#31168;&#30340;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#12290;NtUA&#36890;&#36807;&#33258;&#36866;&#24212;&#32531;&#23384;&#24418;&#25104;&#21644;&#20266;&#26631;&#31614;&#20462;&#27491;&#26469;&#23545;&#25239;&#20266;&#26631;&#31614;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2309.14928</link><description>&lt;p&gt;
&#22122;&#22768;&#23481;&#24525;&#30340;&#26080;&#30417;&#30563;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#36866;&#37197;&#22120;
&lt;/p&gt;
&lt;p&gt;
Noise-Tolerant Unsupervised Adapter for Vision-Language Models. (arXiv:2309.14928v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14928
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22122;&#22768;&#23481;&#24525;&#30340;&#26080;&#30417;&#30563;&#36866;&#37197;&#22120;(NtUA)&#65292;&#23427;&#21487;&#20197;&#20351;&#29992;&#23569;&#26679;&#26412;&#26080;&#26631;&#31614;&#30446;&#26631;&#26679;&#26412;&#26469;&#23398;&#20064;&#20248;&#31168;&#30340;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#12290;NtUA&#36890;&#36807;&#33258;&#36866;&#24212;&#32531;&#23384;&#24418;&#25104;&#21644;&#20266;&#26631;&#31614;&#20462;&#27491;&#26469;&#23545;&#25239;&#20266;&#26631;&#31614;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#22823;&#35268;&#27169;&#30340;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#20013;&#21462;&#24471;&#20102;&#38750;&#24120;&#26174;&#33879;&#30340;&#34920;&#29616;&#65292;&#22312;&#21508;&#31181;&#38646;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#33719;&#24471;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23569;&#26679;&#26412;&#26377;&#26631;&#31614;&#30446;&#26631;&#26679;&#26412;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#20173;&#38656;&#35201;&#30446;&#26631;&#26679;&#26412;&#30340;&#26631;&#27880;&#65292;&#36825;&#22312;&#22788;&#29702;&#21508;&#31181;&#35270;&#35273;&#35782;&#21035;&#20219;&#21153;&#26102;&#22823;&#22823;&#38477;&#20302;&#20102;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22122;&#22768;&#23481;&#24525;&#30340;&#26080;&#30417;&#30563;&#36866;&#37197;&#22120;(NtUA)&#65292;&#23427;&#20801;&#35768;&#20351;&#29992;&#23569;&#26679;&#26412;&#26080;&#26631;&#31614;&#30446;&#26631;&#26679;&#26412;&#26469;&#23398;&#20064;&#20248;&#31168;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;NtUA&#20316;&#20026;&#19968;&#20010;&#38190;&#20540;&#32531;&#23384;&#65292;&#23558;&#23569;&#26679;&#26412;&#26080;&#26631;&#31614;&#30446;&#26631;&#26679;&#26412;&#30340;&#35270;&#35273;&#29305;&#24449;&#21644;&#39044;&#27979;&#30340;&#20266;&#26631;&#31614;&#20316;&#20026;&#38190;&#20540;&#23545;&#36827;&#34892;&#24314;&#27169;&#12290;&#23427;&#30001;&#20004;&#20010;&#20114;&#34917;&#30340;&#35774;&#35745;&#32452;&#25104;&#12290;&#31532;&#19968;&#20010;&#26159;&#33258;&#36866;&#24212;&#32531;&#23384;&#24418;&#25104;&#65292;&#36890;&#36807;&#26681;&#25454;&#20854;&#39044;&#27979;&#32622;&#20449;&#24230;&#23545;&#38190;&#20540;&#23545;&#36827;&#34892;&#21152;&#26435;&#65292;&#20197;&#23545;&#25239;&#20266;&#26631;&#31614;&#30340;&#22122;&#22768;&#12290;&#31532;&#20108;&#20010;&#26159;&#20266;&#26631;&#31614;&#20462;&#27491;&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;&#38190;&#20540;&#23545;&#30340;&#26435;&#37325;&#26469;&#20462;&#27491;&#20266;&#26631;&#31614;&#20197;&#21450;&#32531;&#23384;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in large-scale vision-language models have achieved very impressive performance in various zero-shot image classification tasks. While prior studies have demonstrated significant improvements by introducing few-shot labelled target samples, they still require labelling of target samples, which greatly degrades their scalability while handling various visual recognition tasks. We design NtUA, a Noise-tolerant Unsupervised Adapter that allows learning superior target models with few-shot unlabelled target samples. NtUA works as a key-value cache that formulates visual features and predicted pseudo-labels of the few-shot unlabelled target samples as key-value pairs. It consists of two complementary designs. The first is adaptive cache formation that combats pseudo-label noises by weighting the key-value pairs according to their prediction confidence. The second is pseudo-label rectification, which corrects both pair values (i.e., pseudo-labels) and cache weights by leverag
&lt;/p&gt;</description></item><item><title>&#33258;&#22238;&#24402;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#21487;&#20197;&#26377;&#25928;&#22320;&#36817;&#20284;&#22270;&#28789;&#26426;&#35745;&#31639;&#30340;&#20219;&#20309;&#20989;&#25968;&#65292;&#24182;&#19988;&#22312;&#25991;&#26412;&#29983;&#25104;&#21644;&#31639;&#26415;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#38750;&#24179;&#20961;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.06979</link><description>&lt;p&gt;
&#33258;&#22238;&#24402;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#26159;&#36890;&#29992;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Auto-Regressive Next-Token Predictors are Universal Learners. (arXiv:2309.06979v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06979
&lt;/p&gt;
&lt;p&gt;
&#33258;&#22238;&#24402;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#21487;&#20197;&#26377;&#25928;&#22320;&#36817;&#20284;&#22270;&#28789;&#26426;&#35745;&#31639;&#30340;&#20219;&#20309;&#20989;&#25968;&#65292;&#24182;&#19988;&#22312;&#25991;&#26412;&#29983;&#25104;&#21644;&#31639;&#26415;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#38750;&#24179;&#20961;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#29616;&#20986;&#22312;&#36923;&#36753;&#21644;&#25968;&#23398;&#25512;&#29702;&#26041;&#38754;&#30340;&#38750;&#20961;&#33021;&#21147;&#65292;&#20351;&#20854;&#33021;&#22815;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#20123;&#33021;&#21147;&#22312;&#35757;&#32451;&#20110;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#31616;&#21333;&#20219;&#21153;&#19978;&#30340;&#32593;&#32476;&#20013;&#20986;&#29616;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#33258;&#22238;&#24402;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#26159;&#31616;&#21333;&#30340;&#27169;&#22411;&#65292;&#22914;&#32447;&#24615;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#65292;&#24403;&#20854;&#22312;&#24605;&#32500;&#38142;&#25968;&#25454;&#19978;&#35757;&#32451;&#26102;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36817;&#20284;&#22270;&#28789;&#26426;&#35745;&#31639;&#30340;&#20219;&#20309;&#20989;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#8212;&#8212;&#38271;&#24230;&#22797;&#26434;&#24230;&#65292;&#23427;&#34913;&#37327;&#20102;&#22312;&#36817;&#20284;&#26576;&#20010;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#24605;&#32500;&#38142;&#24207;&#21015;&#20013;&#25152;&#38656;&#30340;&#20013;&#38388;&#26631;&#35760;&#30340;&#25968;&#37327;&#65292;&#24182;&#20998;&#26512;&#20102;&#38271;&#24230;&#22797;&#26434;&#24230;&#21644;&#20854;&#20182;&#22797;&#26434;&#24615;&#27010;&#24565;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#31616;&#21333;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#65292;&#22914;&#32447;&#24615;&#32593;&#32476;&#21644;&#27973;&#23618;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#65292;&#22312;&#25991;&#26412;&#29983;&#25104;&#21644;&#31639;&#26415;&#20219;&#21153;&#19978;&#23637;&#31034;&#20986;&#38750;&#24179;&#20961;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks. Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction. In this work, we present a theoretical framework for studying auto-regressive next-token predictors. We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine. We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity. Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks. Our resul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;SMARLA&#65292;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#12290;&#35813;&#26041;&#27861;&#35774;&#35745;&#20026;&#40657;&#30418;&#23376;&#65292;&#21033;&#29992;&#29366;&#24577;&#25277;&#35937;&#20943;&#23569;&#29366;&#24577;&#31354;&#38388;&#65292;&#23454;&#29616;&#23545;&#26234;&#33021;&#20307;&#29366;&#24577;&#30340;&#23433;&#20840;&#36829;&#35268;&#39044;&#27979;&#12290;&#32463;&#39564;&#35777;&#65292;SMARLA&#20855;&#26377;&#20934;&#30830;&#30340;&#36829;&#35268;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#21487;&#22312;&#26234;&#33021;&#20307;&#25191;&#34892;&#30340;&#26089;&#26399;&#38454;&#27573;&#36827;&#34892;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.02594</link><description>&lt;p&gt;
SMARLA&#65306;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents. (arXiv:2308.02594v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02594
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;SMARLA&#65292;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#12290;&#35813;&#26041;&#27861;&#35774;&#35745;&#20026;&#40657;&#30418;&#23376;&#65292;&#21033;&#29992;&#29366;&#24577;&#25277;&#35937;&#20943;&#23569;&#29366;&#24577;&#31354;&#38388;&#65292;&#23454;&#29616;&#23545;&#26234;&#33021;&#20307;&#29366;&#24577;&#30340;&#23433;&#20840;&#36829;&#35268;&#39044;&#27979;&#12290;&#32463;&#39564;&#35777;&#65292;SMARLA&#20855;&#26377;&#20934;&#30830;&#30340;&#36829;&#35268;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#21487;&#22312;&#26234;&#33021;&#20307;&#25191;&#34892;&#30340;&#26089;&#26399;&#38454;&#27573;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;(DRL)&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#12290;&#30830;&#20445;DRL&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#24615;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20165;&#20381;&#38752;&#27979;&#35797;&#26159;&#19981;&#36275;&#20197;&#30830;&#20445;&#23433;&#20840;&#24615;&#30340;&#65292;&#22240;&#20026;&#23427;&#19981;&#33021;&#25552;&#20379;&#20445;&#35777;&#12290;&#26500;&#24314;&#23433;&#20840;&#30417;&#27979;&#22120;&#26159;&#32531;&#35299;&#36825;&#19968;&#25361;&#25112;&#30340;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;SMARLA&#65292;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;&#65292;&#19987;&#20026;DRL&#26234;&#33021;&#20307;&#35774;&#35745;&#12290;&#20986;&#20110;&#23454;&#38469;&#21407;&#22240;&#65292;SMARLA&#34987;&#35774;&#35745;&#20026;&#40657;&#30418;&#23376;(&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#35775;&#38382;&#26234;&#33021;&#20307;&#30340;&#20869;&#37096;)&#65292;&#24182;&#21033;&#29992;&#29366;&#24577;&#25277;&#35937;&#26469;&#20943;&#23569;&#29366;&#24577;&#31354;&#38388;&#65292;&#20174;&#32780;&#20419;&#36827;&#20174;&#26234;&#33021;&#20307;&#30340;&#29366;&#24577;&#23398;&#20064;&#23433;&#20840;&#36829;&#35268;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#30693;&#21517;&#30340;RL&#26696;&#20363;&#30740;&#31350;&#20013;&#39564;&#35777;&#20102;SMARLA&#12290;&#32463;&#39564;&#20998;&#26512;&#34920;&#26126;&#65292;SMARLA&#20855;&#26377;&#20934;&#30830;&#30340;&#36829;&#35268;&#39044;&#27979;&#33021;&#21147;&#65292;&#35823;&#25253;&#29575;&#20302;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#26234;&#33021;&#20307;&#25191;&#34892;&#30340;&#19968;&#21322;&#24038;&#21491;&#30340;&#26089;&#26399;&#38454;&#27573;&#39044;&#27979;&#23433;&#20840;&#36829;&#35268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning algorithms (DRL) are increasingly being used in safety-critical systems. Ensuring the safety of DRL agents is a critical concern in such contexts. However, relying solely on testing is not sufficient to ensure safety as it does not offer guarantees. Building safety monitors is one solution to alleviate this challenge. This paper proposes SMARLA, a machine learning-based safety monitoring approach designed for DRL agents. For practical reasons, SMARLA is designed to be black-box (as it does not require access to the internals of the agent) and leverages state abstraction to reduce the state space and thus facilitate the learning of safety violation prediction models from agent's states. We validated SMARLA on two well-known RL case studies. Empirical analysis reveals that SMARLA achieves accurate violation prediction with a low false positive rate, and can predict safety violations at an early stage, approximately halfway through the agent's execution before 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#35270;&#21548;&#23398;&#20064;&#65288;VAVL&#65289;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#22788;&#29702;&#24773;&#24863;&#22238;&#24402;&#21644;&#24773;&#24863;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#31995;&#32479;&#65292;&#21363;&#20351;&#25968;&#25454;&#32570;&#22833;&#25110;&#19981;&#21305;&#37197;&#20063;&#33021;&#36827;&#34892;&#26377;&#25928;&#35757;&#32451;&#21644;&#20999;&#25442;&#12290;</title><link>http://arxiv.org/abs/2305.07216</link><description>&lt;p&gt;
&#22788;&#29702;&#24773;&#24863;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#30340;&#36890;&#29992;&#35270;&#21548;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Versatile Audio-Visual Learning for Handling Single and Multi Modalities in Emotion Regression and Classification Tasks. (arXiv:2305.07216v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07216
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#35270;&#21548;&#23398;&#20064;&#65288;VAVL&#65289;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#22788;&#29702;&#24773;&#24863;&#22238;&#24402;&#21644;&#24773;&#24863;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#31995;&#32479;&#65292;&#21363;&#20351;&#25968;&#25454;&#32570;&#22833;&#25110;&#19981;&#21305;&#37197;&#20063;&#33021;&#36827;&#34892;&#26377;&#25928;&#35757;&#32451;&#21644;&#20999;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#38899;&#35270;&#39057;&#24773;&#24863;&#35782;&#21035;&#27169;&#22411;&#32570;&#20047;&#23454;&#38469;&#24212;&#29992;&#25152;&#38656;&#30340;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#35774;&#24819;&#20102;&#19968;&#20010;&#22810;&#27169;&#24577;&#31995;&#32479;&#65292;&#21363;&#20351;&#21482;&#26377;&#19968;&#20010;&#27169;&#24577;&#21487;&#29992;&#65292;&#20063;&#21487;&#20197;&#20114;&#25442;&#22320;&#23454;&#29616;&#39044;&#27979;&#24773;&#24863;&#23646;&#24615;&#25110;&#35782;&#21035;&#20998;&#31867;&#24773;&#24863;&#12290;&#22312;&#19968;&#20010;&#22810;&#27169;&#24577;&#24773;&#24863;&#35782;&#21035;&#31995;&#32479;&#20013;&#23454;&#29616;&#36825;&#26679;&#30340;&#28789;&#27963;&#24615;&#23384;&#22312;&#22256;&#38590;&#65292;&#22240;&#20026;&#20934;&#30830;&#35299;&#37322;&#21644;&#25972;&#21512;&#21508;&#31181;&#25968;&#25454;&#26469;&#28304;&#26159;&#22256;&#38590;&#30340;&#12290;&#21516;&#26102;&#65292;&#20801;&#35768;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20043;&#38388;&#30452;&#25509;&#20999;&#25442;&#65292;&#21516;&#26102;&#22788;&#29702;&#32570;&#22833;&#25110;&#37096;&#20998;&#20449;&#24687;&#20063;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#22788;&#29702;&#24773;&#24863;&#22238;&#24402;&#21644;&#24773;&#24863;&#20998;&#31867;&#20219;&#21153;&#30340;&#36890;&#29992;&#35270;&#21548;&#23398;&#20064;&#65288;VAVL&#65289;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#22788;&#29702;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#31995;&#32479;&#30340;&#38899;&#35270;&#39057;&#26694;&#26550;&#65292;&#21363;&#20351;&#38899;&#39057;&#21644;&#35270;&#35273;&#25968;&#25454;&#19981;&#21305;&#37197;&#65292;&#20063;&#21487;&#20197;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most current audio-visual emotion recognition models lack the flexibility needed for deployment in practical applications. We envision a multimodal system that works even when only one modality is available and can be implemented interchangeably for either predicting emotional attributes or recognizing categorical emotions. Achieving such flexibility in a multimodal emotion recognition system is difficult due to the inherent challenges in accurately interpreting and integrating varied data sources. It is also a challenge to robustly handle missing or partial information while allowing direct switch between regression and classification tasks. This study proposes a \emph{versatile audio-visual learning} (VAVL) framework for handling unimodal and multimodal systems for emotion regression and emotion classification tasks. We implement an audio-visual framework that can be trained even when audio and visual paired data is not available for part of the training set (i.e., audio only or only
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#23454;&#29616;&#21464;&#37327;&#36873;&#25321;&#65292;&#35813;&#31639;&#27861;&#20272;&#35745;&#20102;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#65292;&#30830;&#20445;&#23398;&#20064;&#36827;&#31243;&#33391;&#22909;&#32780;&#19981;&#20250;&#20943;&#32531;&#12290;</title><link>http://arxiv.org/abs/2303.14281</link><description>&lt;p&gt;
&#22522;&#20110;&#24207;&#21015; Knockoffs &#30340;&#24378;&#21270;&#23398;&#20064;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Sequential Knockoffs for Variable Selection in Reinforcement Learning. (arXiv:2303.14281v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14281
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#23454;&#29616;&#21464;&#37327;&#36873;&#25321;&#65292;&#35813;&#31639;&#27861;&#20272;&#35745;&#20102;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#65292;&#30830;&#20445;&#23398;&#20064;&#36827;&#31243;&#33391;&#22909;&#32780;&#19981;&#20250;&#20943;&#32531;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#24456;&#38590;&#33719;&#24471;&#19968;&#20010;&#26082;&#31616;&#27905;&#21448;&#28385;&#36275;&#39532;&#23572;&#21487;&#22827;&#23646;&#24615;&#30340;&#29366;&#24577;&#34920;&#31034;&#65292;&#32780;&#19981;&#38656;&#35201;&#20351;&#29992;&#20808;&#39564;&#30693;&#35782;&#12290;&#22240;&#27492;&#65292;&#24120;&#35268;&#20570;&#27861;&#26159;&#26500;&#36896;&#19968;&#20010;&#27604;&#24517;&#35201;&#30340;&#35201;&#22823;&#30340;&#29366;&#24577;&#65292;&#20363;&#22914;&#23558;&#36830;&#32493;&#26102;&#38388;&#28857;&#19978;&#30340;&#27979;&#37327;&#20018;&#32852;&#36215;&#26469;&#12290;&#28982;&#32780;&#65292;&#22686;&#21152;&#29366;&#24577;&#30340;&#32500;&#25968;&#21487;&#33021;&#20250;&#20943;&#32531;&#23398;&#20064;&#36827;&#31243;&#24182;&#20351;&#23398;&#20064;&#31574;&#30053;&#27169;&#31946;&#19981;&#28165;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#20013;&#30340;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#21407;&#22987;&#29366;&#24577;&#19979;&#26368;&#23567;&#30340;&#23376;&#21521;&#37327;&#65292;&#20351;&#35813;&#36807;&#31243;&#20173;&#28982;&#26159;MDP&#65292;&#24182;&#19988;&#19982;&#21407;&#22987;&#36807;&#31243;&#20849;&#20139;&#30456;&#21516;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#39640;&#32500;&#22797;&#26434;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#31995;&#32479;&#20013;&#30340;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#12290;&#22312;&#22823;&#26679;&#26412;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25511;&#21046;&#20102;&#20551;&#21457;&#29616;&#29575;&#65292;&#24182;&#19988;&#36873;&#25321;&#25152;&#26377;&#20805;&#20998;&#30340;&#21464;&#37327;&#30340;&#27010;&#29575;&#36235;&#36817;&#20110;1&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world applications of reinforcement learning, it is often challenging to obtain a state representation that is parsimonious and satisfies the Markov property without prior knowledge. Consequently, it is common practice to construct a state which is larger than necessary, e.g., by concatenating measurements over contiguous time points. However, needlessly increasing the dimension of the state can slow learning and obfuscate the learned policy. We introduce the notion of a minimal sufficient state in a Markov decision process (MDP) as the smallest subvector of the original state under which the process remains an MDP and shares the same optimal policy as the original process. We propose a novel sequential knockoffs (SEEK) algorithm that estimates the minimal sufficient state in a system with high-dimensional complex nonlinear dynamics. In large samples, the proposed method controls the false discovery rate, and selects all sufficient variables with probability approaching one. As
&lt;/p&gt;</description></item><item><title>&#24378;&#21270;&#23398;&#20064;&#26159;&#19968;&#31181;&#38761;&#26032;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#22522;&#22240;&#32452;&#23398;&#39046;&#22495;&#20013;&#35299;&#20915;&#33258;&#21160;&#25968;&#25454;&#20998;&#26512;&#21644;&#22788;&#29702;&#30340;&#38382;&#39064;&#12290;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#38477;&#20302;&#25910;&#38598;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#30340;&#25104;&#26412;&#65292;&#36866;&#29992;&#20110;&#22522;&#22240;&#32452;&#25968;&#25454;&#20998;&#26512;&#21644;&#35299;&#37322;&#12290;&#26412;&#35843;&#26597;&#37325;&#28857;&#20851;&#27880;&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#39046;&#22495;&#20013;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#12289;&#22522;&#22240;&#32452;&#32452;&#35013;&#21644;&#24207;&#21015;&#27604;&#23545;&#12290;</title><link>http://arxiv.org/abs/2302.13268</link><description>&lt;p&gt;
&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#38761;&#26032;&#22522;&#22240;&#32452;&#23398;
&lt;/p&gt;
&lt;p&gt;
Revolutionizing Genomics with Reinforcement Learning Techniques. (arXiv:2302.13268v2 [q-bio.GN] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13268
&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#26159;&#19968;&#31181;&#38761;&#26032;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#22522;&#22240;&#32452;&#23398;&#39046;&#22495;&#20013;&#35299;&#20915;&#33258;&#21160;&#25968;&#25454;&#20998;&#26512;&#21644;&#22788;&#29702;&#30340;&#38382;&#39064;&#12290;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#38477;&#20302;&#25910;&#38598;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#30340;&#25104;&#26412;&#65292;&#36866;&#29992;&#20110;&#22522;&#22240;&#32452;&#25968;&#25454;&#20998;&#26512;&#21644;&#35299;&#37322;&#12290;&#26412;&#35843;&#26597;&#37325;&#28857;&#20851;&#27880;&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#39046;&#22495;&#20013;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#12289;&#22522;&#22240;&#32452;&#32452;&#35013;&#21644;&#24207;&#21015;&#27604;&#23545;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#20986;&#29616;&#22312;&#35299;&#20915;&#21508;&#31181;&#38382;&#39064;&#20013;&#65292;&#21253;&#25324;&#20915;&#31574;&#21644;&#22522;&#22240;&#32452;&#23398;&#12290;&#36807;&#21435;&#20108;&#21313;&#24180;&#30340;&#21407;&#22987;&#22522;&#22240;&#32452;&#25968;&#25454;&#25351;&#25968;&#22686;&#38271;&#24050;&#32463;&#36229;&#20986;&#20102;&#25163;&#21160;&#20998;&#26512;&#30340;&#33021;&#21147;&#65292;&#36825;&#23548;&#33268;&#23545;&#33258;&#21160;&#25968;&#25454;&#20998;&#26512;&#21644;&#22788;&#29702;&#30340;&#20852;&#36259;&#36234;&#26469;&#36234;&#22823;&#12290;RL&#31639;&#27861;&#33021;&#22815;&#22312;&#26368;&#23567;&#30340;&#20154;&#24037;&#30417;&#30563;&#19979;&#20174;&#32463;&#39564;&#20013;&#23398;&#20064;&#65292;&#20351;&#20854;&#38750;&#24120;&#36866;&#21512;&#22522;&#22240;&#32452;&#25968;&#25454;&#20998;&#26512;&#21644;&#35299;&#37322;&#12290;&#20351;&#29992;RL&#30340;&#19968;&#20010;&#20851;&#38190;&#22909;&#22788;&#26159;&#38477;&#20302;&#20102;&#25910;&#38598;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#30340;&#25104;&#26412;&#65292;&#36825;&#26159;&#30417;&#30563;&#23398;&#20064;&#25152;&#38656;&#30340;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#35768;&#22810;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#22522;&#22240;&#32452;&#23398;&#20013;&#30340;&#24212;&#29992;&#65292;&#20294;&#26412;&#35843;&#26597;&#20165;&#19987;&#27880;&#20110;&#22312;&#21508;&#31181;&#22522;&#22240;&#32452;&#30740;&#31350;&#39046;&#22495;&#65288;&#21253;&#25324;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#65292;&#22522;&#22240;&#32452;&#32452;&#35013;&#21644;&#24207;&#21015;&#27604;&#23545;&#65289;&#20013;&#20351;&#29992;RL&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#23545;&#29616;&#26377;&#30740;&#31350;&#30340;&#25216;&#26415;&#32454;&#33410;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, Reinforcement Learning (RL) has emerged as a powerful tool for solving a wide range of problems, including decision-making and genomics. The exponential growth of raw genomic data over the past two decades has exceeded the capacity of manual analysis, leading to a growing interest in automatic data analysis and processing. RL algorithms are capable of learning from experience with minimal human supervision, making them well-suited for genomic data analysis and interpretation. One of the key benefits of using RL is the reduced cost associated with collecting labeled training data, which is required for supervised learning. While there have been numerous studies examining the applications of Machine Learning (ML) in genomics, this survey focuses exclusively on the use of RL in various genomics research fields, including gene regulatory networks (GRNs), genome assembly, and sequence alignment. We present a comprehensive technical overview of existing studies on the applic
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102; Adversarial Minority Influence (AMI) &#40657;&#30418;&#25915;&#20987;&#65292;&#33021;&#22815;&#22312;&#32771;&#34385;&#22810;&#26234;&#33021;&#20307;&#20114;&#21160;&#21644;&#21512;&#20316;&#30446;&#26631;&#19979;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#26368;&#22351;&#24773;&#20917;&#21512;&#20316;&#65292;&#25915;&#20987;&#25104;&#21151;&#29575;&#27604;&#29616;&#26377;&#26041;&#27861;&#39640;&#20986; 2.2&#20493;&#12290;</title><link>http://arxiv.org/abs/2302.03322</link><description>&lt;p&gt;
&#12298;&#36890;&#36807;&#23545;&#25239;&#24615;&#23569;&#25968;&#27966;&#24433;&#21709;&#25915;&#20987;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#12299;
&lt;/p&gt;
&lt;p&gt;
Attacking Cooperative Multi-Agent Reinforcement Learning by Adversarial Minority Influence. (arXiv:2302.03322v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102; Adversarial Minority Influence (AMI) &#40657;&#30418;&#25915;&#20987;&#65292;&#33021;&#22815;&#22312;&#32771;&#34385;&#22810;&#26234;&#33021;&#20307;&#20114;&#21160;&#21644;&#21512;&#20316;&#30446;&#26631;&#19979;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#26368;&#22351;&#24773;&#20917;&#21512;&#20316;&#65292;&#25915;&#20987;&#25104;&#21151;&#29575;&#27604;&#29616;&#26377;&#26041;&#27861;&#39640;&#20986; 2.2&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(c-MARL)&#22312;&#23545;&#25239;&#24615;&#25915;&#20987;&#19979;&#30340;&#24369;&#28857;&#65292;&#36825;&#26159;&#22312;&#23454;&#38469;&#23454;&#29616;&#20043;&#21069;c-MARL&#26368;&#22351;&#24773;&#20917;&#19979;&#24615;&#33021;&#30340;&#37325;&#35201;&#20915;&#23450;&#22240;&#32032;&#12290;&#30446;&#21069;&#22522;&#20110;&#35266;&#23519;&#30340;&#25915;&#20987;&#65292;&#21463;&#21040;&#30333;&#30418;&#20551;&#35774;&#30340;&#38480;&#21046;&#65292;&#24573;&#35270;&#20102;c-MARL&#30340;&#22797;&#26434;&#22810;&#26234;&#33021;&#20307;&#20132;&#20114;&#21644;&#21512;&#20316;&#30446;&#26631;&#65292;&#23548;&#33268;&#25915;&#20987;&#33021;&#21147;&#21463;&#21040;&#23454;&#38469;&#21644;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Adversarial Minority Influence (AMI)&#65292;&#36825;&#26159;&#19968;&#20010;&#23454;&#29992;&#32780;&#24378;&#22823;&#30340;&#38024;&#23545;c-MARL&#30340;&#40657;&#30418;&#25915;&#20987;&#12290;AMI&#26159;&#19968;&#20010;&#23454;&#29992;&#30340;&#40657;&#30418;&#25915;&#20987;&#65292;&#21487;&#20197;&#22312;&#19981;&#20102;&#35299;&#21463;&#23475;&#32773;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#21457;&#21160;&#25915;&#20987;&#12290;AMI&#20063;&#26159;&#24378;&#22823;&#30340;&#65292;&#22240;&#20026;&#23427;&#32771;&#34385;&#20102;&#22797;&#26434;&#30340;&#22810;&#26234;&#33021;&#20307;&#20114;&#21160;&#21644;&#20195;&#29702;&#30340;&#21512;&#20316;&#30446;&#26631;&#65292;&#20351;&#21333;&#20010;&#23545;&#25239;&#24615;&#20195;&#29702;&#33021;&#22815;&#21333;&#26041;&#38754;&#35823;&#23548;&#22823;&#22810;&#25968;&#21463;&#23475;&#32773;&#24418;&#25104;&#26377;&#38024;&#23545;&#24615;&#30340;&#26368;&#22351;&#24773;&#20917;&#21512;&#20316;&#12290;&#36825;&#21453;&#26144;&#20102;&#31038;&#20250;&#24515;&#29702;&#23398;&#20013;&#30340;&#23569;&#25968;&#27966;&#24433;&#21709;&#29616;&#35937;&#12290;&#20026;&#20102;&#22312;&#22797;&#26434;&#30340;&#20195;&#29702;&#26041;&#24335;&#20132;&#20114;&#19979;&#23454;&#29616;&#26368;&#22823;&#30340;&#21463;&#23475;&#32773;&#25919;&#31574;&#20559;&#24046;&#65292;&#25105;&#20204;&#22522;&#20110;&#21338;&#24328;&#29702;&#35770;&#20998;&#26512;&#25512;&#23548;&#20986;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;AMI&#20248;&#21270;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;AMI&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#32771;&#34385;&#22810;&#26234;&#33021;&#20307;&#20132;&#20114;&#30340;&#24517;&#35201;&#24615;&#65292;&#34920;&#26126;AMI&#21487;&#20197;&#23454;&#29616;&#27604;&#29616;&#26377;&#26041;&#27861;&#39640;&#20986;2.2&#20493;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study probes the vulnerabilities of cooperative multi-agent reinforcement learning (c-MARL) under adversarial attacks, a critical determinant of c-MARL's worst-case performance prior to real-world implementation. Current observation-based attacks, constrained by white-box assumptions, overlook c-MARL's complex multi-agent interactions and cooperative objectives, resulting in impractical and limited attack capabilities. To address these shortcomes, we propose Adversarial Minority Influence (AMI), a practical and strong for c-MARL. AMI is a practical black-box attack and can be launched without knowing victim parameters. AMI is also strong by considering the complex multi-agent interaction and the cooperative goal of agents, enabling a single adversarial agent to unilaterally misleads majority victims to form targeted worst-case cooperation. This mirrors minority influence phenomena in social psychology. To achieve maximum deviation in victim policies under complex agent-wise intera
&lt;/p&gt;</description></item></channel></rss>