<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20998;&#21035;&#35299;&#20915;&#20102;&#26053;&#34892;&#36141;&#20080;&#32773;&#38382;&#39064;&#20013;&#30340;&#36335;&#30001;&#26500;&#24314;&#21644;&#36141;&#20080;&#35268;&#21010;&#38382;&#39064;&#65292;&#24182;&#20174;&#20840;&#23616;&#35282;&#24230;&#35780;&#20272;&#21644;&#20248;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2404.02476</link><description>&lt;p&gt;
&#29992;&#20110;&#26053;&#34892;&#36141;&#20080;&#32773;&#38382;&#39064;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deep Reinforcement Learning for Traveling Purchaser Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02476
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20998;&#21035;&#35299;&#20915;&#20102;&#26053;&#34892;&#36141;&#20080;&#32773;&#38382;&#39064;&#20013;&#30340;&#36335;&#30001;&#26500;&#24314;&#21644;&#36141;&#20080;&#35268;&#21010;&#38382;&#39064;&#65292;&#24182;&#20174;&#20840;&#23616;&#35282;&#24230;&#35780;&#20272;&#21644;&#20248;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26053;&#34892;&#36141;&#20080;&#32773;&#38382;&#39064;&#65288;TPP&#65289;&#26159;&#19968;&#31181;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#37325;&#35201;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20998;&#21035;&#35299;&#20915;&#20102;&#36335;&#30001;&#26500;&#24314;&#21644;&#36141;&#20080;&#35268;&#21010;&#38382;&#39064;&#65292;&#21516;&#26102;&#20174;&#20840;&#23616;&#35282;&#24230;&#35780;&#20272;&#21644;&#20248;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#21253;&#25324;&#29992;&#20110;&#25429;&#25417;&#24066;&#22330;-&#20135;&#21697;&#20851;&#31995;&#30340;TPP&#30340;&#20108;&#37096;&#22270;&#34920;&#31034;&#65292;&#20197;&#21450;&#20174;&#20108;&#37096;&#22270;&#20013;&#25552;&#21462;&#20449;&#24687;&#24182;&#23558;&#20854;&#29992;&#20110;&#39034;&#24207;&#26500;&#24314;&#36335;&#30001;&#30340;&#31574;&#30053;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02476v1 Announce Type: cross  Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently const
&lt;/p&gt;</description></item><item><title>&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21453;&#36951;&#24536;&#26041;&#27861;&#65292;&#20026;&#36817;&#20284;&#21453;&#36951;&#24536;&#38382;&#39064;&#25552;&#20379;&#20102;&#38544;&#31169;&#20445;&#38556;&#65292;&#24182;&#23637;&#31034;&#20102;&#23567;&#25209;&#27425;&#26799;&#24230;&#26356;&#26032;&#30456;&#36739;&#20110;&#20840;&#25209;&#27425;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.17105</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#21453;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Langevin Unlearning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21453;&#36951;&#24536;&#26041;&#27861;&#65292;&#20026;&#36817;&#20284;&#21453;&#36951;&#24536;&#38382;&#39064;&#25552;&#20379;&#20102;&#38544;&#31169;&#20445;&#38556;&#65292;&#24182;&#23637;&#31034;&#20102;&#23567;&#25209;&#27425;&#26799;&#24230;&#26356;&#26032;&#30456;&#36739;&#20110;&#20840;&#25209;&#27425;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#8220;&#34987;&#36951;&#24536;&#30340;&#26435;&#21033;&#8221;&#26159;&#29992;&#25143;&#25968;&#25454;&#38544;&#31169;&#30340;&#27861;&#24459;&#25152;&#30830;&#20445;&#30340;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#26426;&#22120;&#21453;&#36951;&#24536;&#26088;&#22312;&#39640;&#25928;&#22320;&#28040;&#38500;&#24050;&#35757;&#32451;&#27169;&#22411;&#21442;&#25968;&#19978;&#26576;&#20123;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#65292;&#20351;&#20854;&#36817;&#20284;&#20110;&#20174;&#22836;&#24320;&#22987;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21453;&#36951;&#24536;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#24102;&#26377;&#38544;&#31169;&#20445;&#38556;&#30340;&#22122;&#22768;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#21453;&#36951;&#24536;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#20984;&#24615;&#20551;&#35774;&#19979;&#30340;&#36817;&#20284;&#21453;&#36951;&#24536;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20840;&#25209;&#27425;&#23545;&#24212;&#26041;&#27861;&#30456;&#27604;&#65292;&#23567;&#25209;&#27425;&#26799;&#24230;&#26356;&#26032;&#22312;&#38544;&#31169;&#22797;&#26434;&#24230;&#26435;&#34913;&#26041;&#38754;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#21453;&#36951;&#24536;&#26041;&#27861;&#20855;&#26377;&#35832;&#22810;&#31639;&#27861;&#20248;&#21183;&#65292;&#21253;&#25324;&#19982;&#37325;&#26032;&#35757;&#32451;&#30456;&#27604;&#30340;&#22797;&#26434;&#24230;&#33410;&#30465;&#65292;&#20197;&#21450;&#25903;&#25345;&#39034;&#24207;&#21644;&#25209;&#37327;&#21453;&#36951;&#24536;&#12290;&#20026;&#20102;&#26816;&#39564;&#25105;&#20204;&#26041;&#27861;&#30340;&#38544;&#31169;-&#25928;&#29992;-&#22797;&#26434;&#24230;&#26435;&#34913;&#65292;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17105v1 Announce Type: new  Abstract: ``The right to be forgotten'' ensured by laws for user data privacy becomes increasingly important. Machine unlearning aims to efficiently remove the effect of certain data points on the trained model parameters so that it can be approximately the same as if one retrains the model from scratch. This work proposes stochastic gradient Langevin unlearning, the first unlearning framework based on noisy stochastic gradient descent (SGD) with privacy guarantees for approximate unlearning problems under convexity assumption. Our results show that mini-batch gradient updates provide a superior privacy-complexity trade-off compared to the full-batch counterpart. There are numerous algorithmic benefits of our unlearning approach, including complexity saving compared to retraining, and supporting sequential and batch unlearning. To examine the privacy-utility-complexity trade-off of our method, we conduct experiments on benchmark datasets compared 
&lt;/p&gt;</description></item><item><title>CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.13583</link><description>&lt;p&gt;
CONLINE: &#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#19982;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#30340;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13583
&lt;/p&gt;
&lt;p&gt;
CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#25442;&#20026;&#21487;&#25191;&#34892;&#20195;&#30721;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#22330;&#26223;&#19979;&#29983;&#25104;&#22797;&#26434;&#20195;&#30721;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21407;&#22240;&#22312;&#20110;&#22797;&#26434;&#30340;&#32467;&#26500;&#12289;&#24494;&#22937;&#30340;&#38169;&#35823;&#12289;&#23545;&#39640;&#32423;&#25968;&#25454;&#31867;&#22411;&#30340;&#29702;&#35299;&#20197;&#21450;&#32570;&#23569;&#36741;&#21161;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CONLINE&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#21010;&#30340;&#22312;&#32447;&#25628;&#32034;&#20449;&#24687;&#26816;&#32034;&#21644;&#33258;&#21160;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#20195;&#30721;&#29983;&#25104;&#65292;&#36827;&#34892;&#36845;&#20195;&#31934;&#28860;&#12290;CONLINE&#36824;&#20018;&#34892;&#21270;&#20102;&#22797;&#26434;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#65292;&#20197;&#25913;&#21892;&#29702;&#35299;&#65292;&#24182;&#29983;&#25104;&#27979;&#35797;&#29992;&#20363;&#65292;&#30830;&#20445;&#26694;&#26550;&#36866;&#29992;&#20110;&#29616;&#23454;&#24212;&#29992;&#12290;CONLINE&#36890;&#36807;&#23545;DS-1000&#21644;ClassEval&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#23454;&#39564;&#39564;&#35777;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;CONLINE&#26174;&#33879;&#25552;&#39640;&#20102;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#36136;&#37327;&#65292;&#31361;&#26174;&#20102;&#20854;&#25552;&#21319;&#23454;&#36341;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13583v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement. CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications. CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets. It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the pra
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#24471;&#20986;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.11637</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
The Value of Reward Lookahead in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11637
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#24471;&#20986;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#65292;&#20195;&#29702;&#20204;&#19982;&#19981;&#26029;&#21464;&#21270;&#30340;&#29615;&#22659;&#36827;&#34892;&#39034;&#24207;&#20132;&#20114;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#33719;&#24471;&#30340;&#22870;&#21169;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22870;&#21169;&#20165;&#22312;&#34892;&#21160;&#21518;&#34987;&#35266;&#23519;&#21040;&#65292;&#22240;&#27492;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#22870;&#21169;&#20449;&#24687;&#26159;&#25552;&#21069;&#35266;&#23519;&#21040;&#30340; -- &#20132;&#26131;&#21069;&#35266;&#23519;&#21040;&#20215;&#26684;&#65307;&#20102;&#35299;&#37096;&#20998;&#38468;&#36817;&#20132;&#36890;&#20449;&#24687;&#65307;&#32463;&#24120;&#22312;&#20114;&#21160;&#20043;&#21069;&#20026;&#20195;&#29702;&#20998;&#37197;&#30446;&#26631;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#30340;&#35270;&#35282;&#65292;&#23450;&#37327;&#20998;&#26512;&#36825;&#31181;&#26410;&#26469;&#22870;&#21169;&#20449;&#24687;&#30340;&#20215;&#20540;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#27979;&#37327;&#20102;&#26631;&#20934;RL&#20195;&#29702;&#30340;&#20215;&#20540;&#19982;&#20855;&#26377;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#27604;&#29575;&#12290;&#25105;&#20204;&#21051;&#30011;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#22870;&#21169;&#20998;&#24067;&#65292;&#24182;&#25512;&#23548;&#20986;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#32467;&#26524;&#27604;&#29575;&#19982;&#31163;&#32447;RL&#21644;r&#20013;&#24050;&#30693;&#30340;&#25968;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11637v1 Announce Type: new  Abstract: In reinforcement learning (RL), agents sequentially interact with changing environments while aiming to maximize the obtained rewards. Usually, rewards are observed only after acting, and so the goal is to maximize the expected cumulative reward. Yet, in many practical settings, reward information is observed in advance -- prices are observed before performing transactions; nearby traffic information is partially known; and goals are oftentimes given to agents prior to the interaction. In this work, we aim to quantifiably analyze the value of such future reward information through the lens of competitive analysis. In particular, we measure the ratio between the value of standard RL agents and that of agents with partial future-reward lookahead. We characterize the worst-case reward distribution and derive exact ratios for the worst-case reward expectations. Surprisingly, the resulting ratios relate to known quantities in offline RL and r
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25345;&#32493;&#30340;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#20998;&#25955;&#30340;&#23398;&#20064;&#26550;&#26500;&#65292;&#26469;&#35299;&#20915;&#20132;&#36890;&#36335;&#21475;&#31359;&#36234;&#21644;&#33258;&#20027;&#36187;&#36710;&#31561;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.10996</link><description>&lt;p&gt;
&#19968;&#20010;&#21487;&#25193;&#23637;&#19988;&#21487;&#24182;&#34892;&#21270;&#30340;&#25968;&#23383;&#23402;&#29983;&#26694;&#26550;&#65292;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#21487;&#25345;&#32493;Sim2Real&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
A Scalable and Parallelizable Digital Twin Framework for Sustainable Sim2Real Transition of Multi-Agent Reinforcement Learning Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10996
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25345;&#32493;&#30340;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#20998;&#25955;&#30340;&#23398;&#20064;&#26550;&#26500;&#65292;&#26469;&#35299;&#20915;&#20132;&#36890;&#36335;&#21475;&#31359;&#36234;&#21644;&#33258;&#20027;&#36187;&#36710;&#31561;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25345;&#32493;&#30340;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#25353;&#38656;&#25193;&#23637;&#24182;&#34892;&#21270;&#35757;&#32451;&#24037;&#20316;&#36127;&#36733;&#65292;&#24182;&#21033;&#29992;&#26368;&#23569;&#30340;&#30828;&#20214;&#36164;&#28304;&#23558;&#35757;&#32451;&#22909;&#30340;&#31574;&#30053;&#20174;&#27169;&#25311;&#29615;&#22659;&#36716;&#31227;&#21040;&#29616;&#23454;&#19990;&#30028;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;AutoDRIVE&#29983;&#24577;&#31995;&#32479;&#20316;&#20026;&#19968;&#20010;&#21551;&#21160;&#25968;&#23383;&#23402;&#29983;&#26694;&#26550;&#65292;&#29992;&#20110;&#35757;&#32451;&#12289;&#37096;&#32626;&#21644;&#36716;&#31227;&#21512;&#20316;&#21644;&#31454;&#20105;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20174;&#27169;&#25311;&#29615;&#22659;&#21040;&#29616;&#23454;&#19990;&#30028;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25506;&#31350;&#20102;4&#21488;&#21512;&#20316;&#36710;&#36742;(Nigel)&#22312;&#21333;&#26234;&#33021;&#20307;&#21644;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#29615;&#22659;&#20013;&#20849;&#20139;&#26377;&#38480;&#29366;&#24577;&#20449;&#24687;&#30340;&#20132;&#21449;&#36941;&#21382;&#38382;&#39064;&#65292;&#37319;&#29992;&#20102;&#19968;&#31181;&#36890;&#29992;&#31574;&#30053;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#20010;&#20307;&#31574;&#30053;&#26041;&#27861;&#30740;&#31350;&#20102;2&#36742;&#36710;(F1TENTH)&#30340;&#23545;&#25239;&#24615;&#33258;&#20027;&#36187;&#36710;&#38382;&#39064;&#12290;&#22312;&#20219;&#20309;&#19968;&#32452;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#26550;&#26500;&#65292;&#36825;&#20801;&#35768;&#23545;&#31574;&#30053;&#36827;&#34892;&#26377;&#21147;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10996v1 Announce Type: cross  Abstract: This work presents a sustainable multi-agent deep reinforcement learning framework capable of selectively scaling parallelized training workloads on-demand, and transferring the trained policies from simulation to reality using minimal hardware resources. We introduce AutoDRIVE Ecosystem as an enabling digital twin framework to train, deploy, and transfer cooperative as well as competitive multi-agent reinforcement learning policies from simulation to reality. Particularly, we first investigate an intersection traversal problem of 4 cooperative vehicles (Nigel) that share limited state information in single as well as multi-agent learning settings using a common policy approach. We then investigate an adversarial autonomous racing problem of 2 vehicles (F1TENTH) using an individual policy approach. In either set of experiments, a decentralized learning architecture was adopted, which allowed robust training and testing of the policies 
&lt;/p&gt;</description></item><item><title>&#36229;&#21442;&#25968;&#23545;&#20110;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#34987;&#24378;&#35843;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28041;&#21450;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#35780;&#20272;&#38454;&#27573;&#30340;&#35780;&#20272;&#21327;&#35758;&#12290;</title><link>https://arxiv.org/abs/2403.09066</link><description>&lt;p&gt;
Continual Learning&#20013;&#30340;&#36229;&#21442;&#25968;&#65306;&#29616;&#23454;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Hyperparameters in Continual Learning: a Reality Check
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09066
&lt;/p&gt;
&lt;p&gt;
&#36229;&#21442;&#25968;&#23545;&#20110;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#34987;&#24378;&#35843;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28041;&#21450;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#35780;&#20272;&#38454;&#27573;&#30340;&#35780;&#20272;&#21327;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#36830;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#31639;&#27861;&#26088;&#22312;&#22312;CL&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#32531;&#35299;&#31283;&#23450;&#24615;&#21644;&#21487;&#22609;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#35843;&#25972;&#27599;&#31181;&#31639;&#27861;&#30340;&#36866;&#24403;&#36229;&#21442;&#25968;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#12290;&#26412;&#25991;&#20027;&#24352;&#29616;&#34892;&#30340;&#35780;&#20272;&#21327;&#35758;&#26082;&#19981;&#20999;&#23454;&#38469;&#65292;&#20063;&#26080;&#27861;&#26377;&#25928;&#35780;&#20272;&#36830;&#32493;&#23398;&#20064;&#31639;&#27861;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09066v1 Announce Type: new  Abstract: Various algorithms for continual learning (CL) have been designed with the goal of effectively alleviating the trade-off between stability and plasticity during the CL process. To achieve this goal, tuning appropriate hyperparameters for each algorithm is essential. As an evaluation protocol, it has been common practice to train a CL algorithm using diverse hyperparameter values on a CL scenario constructed with a benchmark dataset. Subsequently, the best performance attained with the optimal hyperparameter value serves as the criterion for evaluating the CL algorithm. In this paper, we contend that this evaluation protocol is not only impractical but also incapable of effectively assessing the CL capability of a CL algorithm. Returning to the fundamental principles of model evaluation in machine learning, we propose an evaluation protocol that involves Hyperparameter Tuning and Evaluation phases. Those phases consist of different datase
&lt;/p&gt;</description></item><item><title>FogGuard&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38654;&#22825;&#27668;&#26465;&#20214;&#25361;&#25112;&#30340;&#26032;&#22411;&#38654;&#24863;&#30693;&#30446;&#26631;&#26816;&#27979;&#32593;&#32476;&#65292;&#36890;&#36807;&#24494;&#35843;&#25968;&#25454;&#25910;&#38598;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#30446;&#26631;&#26816;&#27979;&#31639;&#27861;&#22312;&#24694;&#21155;&#22825;&#27668;&#26465;&#20214;&#19979;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.08939</link><description>&lt;p&gt;
FogGuard: &#20351;&#29992;&#24863;&#30693;&#25439;&#22833;&#20445;&#25252;YOLO&#20813;&#21463;&#38654;&#38718;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
FogGuard: guarding YOLO against fog using perceptual loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08939
&lt;/p&gt;
&lt;p&gt;
FogGuard&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38654;&#22825;&#27668;&#26465;&#20214;&#25361;&#25112;&#30340;&#26032;&#22411;&#38654;&#24863;&#30693;&#30446;&#26631;&#26816;&#27979;&#32593;&#32476;&#65292;&#36890;&#36807;&#24494;&#35843;&#25968;&#25454;&#25910;&#38598;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#30446;&#26631;&#26816;&#27979;&#31639;&#27861;&#22312;&#24694;&#21155;&#22825;&#27668;&#26465;&#20214;&#19979;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38654;&#24863;&#30693;&#30446;&#26631;&#26816;&#27979;&#32593;&#32476;&#65292;&#31216;&#20026;FogGuard&#65292;&#26088;&#22312;&#35299;&#20915;&#38654;&#22825;&#27668;&#26465;&#20214;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20005;&#37325;&#20381;&#36182;&#20934;&#30830;&#30340;&#30446;&#26631;&#26816;&#27979;&#31639;&#27861;&#65292;&#20294;&#24694;&#21155;&#30340;&#22825;&#27668;&#26465;&#20214;&#20250;&#26174;&#33879;&#24433;&#21709;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#21487;&#38752;&#24615;&#12290;&#29616;&#26377;&#26041;&#27861;&#21487;&#20998;&#20026;&#20004;&#31867;&#65292;1&#65289;&#22270;&#20687;&#22686;&#24378;&#65288;&#22914;IA-YOLO&#65289;&#21644;2&#65289;&#22522;&#20110;&#39046;&#22495;&#36866;&#24212;&#30340;&#26041;&#27861;&#12290;&#22270;&#20687;&#22686;&#24378;&#25216;&#26415;&#35797;&#22270;&#29983;&#25104;&#26080;&#38654;&#22270;&#20687;&#65292;&#28982;&#32780;&#65292;&#20174;&#26377;&#38654;&#22270;&#20687;&#20013;&#24674;&#22797;&#26080;&#38654;&#22270;&#20687;&#27604;&#22312;&#26377;&#38654;&#22270;&#20687;&#20013;&#26816;&#27979;&#23545;&#35937;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22522;&#20110;&#39046;&#22495;&#36866;&#24212;&#30340;&#26041;&#27861;&#27809;&#26377;&#21033;&#29992;&#30446;&#26631;&#39046;&#22495;&#20013;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#12290;&#36825;&#20004;&#31867;&#26041;&#27861;&#37117;&#22312;&#23581;&#35797;&#35299;&#20915;&#38382;&#39064;&#30340;&#26356;&#38590;&#29256;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#22312;&#23545;&#21407;&#22987;&#26631;&#27880;&#25968;&#25454;&#30340;&#24494;&#35843;&#20043;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08939v1 Announce Type: cross  Abstract: In this paper, we present a novel fog-aware object detection network called FogGuard, designed to address the challenges posed by foggy weather conditions. Autonomous driving systems heavily rely on accurate object detection algorithms, but adverse weather conditions can significantly impact the reliability of deep neural networks (DNNs).   Existing approaches fall into two main categories, 1) image enhancement such as IA-YOLO 2) domain adaptation based approaches. Image enhancement based techniques attempt to generate fog-free image. However, retrieving a fogless image from a foggy image is a much harder problem than detecting objects in a foggy image. Domain-adaptation based approaches, on the other hand, do not make use of labelled datasets in the target domain. Both categories of approaches are attempting to solve a harder version of the problem. Our approach builds over fine-tuning on the   Our framework is specifically designed t
&lt;/p&gt;</description></item><item><title>HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;</title><link>https://arxiv.org/abs/2403.07735</link><description>&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;
&lt;/p&gt;
&lt;p&gt;
The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07735
&lt;/p&gt;
&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kernel&#25216;&#26415;&#26159;&#25968;&#25454;&#31185;&#23398;&#21644;&#32479;&#35745;&#23398;&#20013;&#26368;&#26377;&#24433;&#21709;&#21147;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#19982;&#26680;&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33021;&#22815;&#32534;&#30721;$M\ge 2$&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#12290;&#22312;&#26680;&#19978;&#20381;&#36182;&#30340;&#26368;&#26222;&#36941;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#21487;&#33021;&#26159;&#25152;&#35859;&#30340;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;(HSIC; &#22312;&#32479;&#35745;&#25991;&#29486;&#20013;&#20063;&#31216;&#20026;&#36317;&#31163;&#21327;&#26041;&#24046;)&#12290;&#23613;&#31649;&#33258;&#36817;&#20108;&#21313;&#24180;&#21069;&#24341;&#20837;&#20197;&#26469;&#24050;&#32463;&#26377;&#21508;&#31181;&#29616;&#26377;&#30340;&#35774;&#35745;&#30340;HSIC&#20272;&#35745;&#37327;&#65292;HSIC&#21487;&#20197;&#34987;&#20272;&#35745;&#30340;&#36895;&#24230;&#30340;&#22522;&#26412;&#38382;&#39064;&#20173;&#28982;&#26159;&#24320;&#25918;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#21253;&#21547;&#20855;&#26377;&#36830;&#32493;&#26377;&#30028;&#24179;&#31227;&#19981;&#21464;&#29305;&#24449;&#26680;&#30340;&#39640;&#26031;Borel&#27979;&#24230;&#22312;$\mathbb R^d$&#19978;&#30340;HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#26368;&#20248;&#36895;&#29575;&#26159;$\mathcal O\!\left(n^{-1/2}\right)$&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#35768;&#22810;&#26041;&#38754;&#22312;&#26497;&#23567;&#21270;&#24847;&#20041;&#19978;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07735v1 Announce Type: cross  Abstract: Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the optimality in the minimax sense of many 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20004;&#31181;&#26681;&#26893;&#20110;&#27531;&#24046;&#36830;&#25509;&#21644;&#23494;&#38598;&#36830;&#25509;&#30340;&#28151;&#21512;&#37327;&#23376;&#21551;&#21457;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;&#20110;&#26356;&#20840;&#38754;&#22320;&#25913;&#36827;&#21644;&#35780;&#20272;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#22797;&#26434;&#21644;&#19981;&#21487;&#39044;&#27979;&#29615;&#22659;&#20013;&#30340;&#34920;&#29616;</title><link>https://arxiv.org/abs/2403.05754</link><description>&lt;p&gt;
&#27169;&#24335;&#35782;&#21035;&#30340;&#28151;&#21512;&#37327;&#23376;&#21551;&#21457;&#24335;ResNet&#21644;DenseNet&#21450;&#20854;&#23436;&#25972;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Hybrid Quantum-inspired Resnet and Densenet for Pattern Recognition with Completeness Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05754
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20004;&#31181;&#26681;&#26893;&#20110;&#27531;&#24046;&#36830;&#25509;&#21644;&#23494;&#38598;&#36830;&#25509;&#30340;&#28151;&#21512;&#37327;&#23376;&#21551;&#21457;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;&#20110;&#26356;&#20840;&#38754;&#22320;&#25913;&#36827;&#21644;&#35780;&#20272;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#22797;&#26434;&#21644;&#19981;&#21487;&#39044;&#27979;&#29615;&#22659;&#20013;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#24403;&#20170;&#25968;&#23383;&#25216;&#26415;&#30340;&#25509;&#36817;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27491;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#32321;&#33635;&#30340;&#22522;&#30784;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#19981;&#26029;&#21457;&#23637;&#30340;&#31038;&#20250;&#38656;&#27714;&#27491;&#22312;&#24378;&#35843;&#26367;&#20195;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#30340;&#24517;&#35201;&#24615;&#12290;&#21516;&#26102;&#65292;&#21518;&#25705;&#23572;&#26102;&#20195;&#30340;&#26469;&#20020;&#25512;&#21160;&#20102;&#20855;&#26377;&#21331;&#36234;&#28508;&#21147;&#30340;&#37327;&#23376;&#21551;&#21457;&#24335;&#31070;&#32463;&#32593;&#32476;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#30446;&#21069;&#26032;&#26087;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20043;&#38388;&#27604;&#36739;&#20013;&#23384;&#22312;&#21547;&#31946;&#25351;&#26631;&#65292;&#22240;&#27492;&#19968;&#22871;&#26126;&#30830;&#30340;&#35780;&#20272;&#31995;&#32479;&#19982;&#35814;&#32454;&#30340;&#25351;&#26631;&#26159;&#38750;&#24120;&#37325;&#35201;&#21644;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#26356;&#20840;&#38754;&#22320;&#25913;&#36827;&#21644;&#35780;&#20272;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#22797;&#26434;&#21644;&#19981;&#21487;&#39044;&#27979;&#29615;&#22659;&#20013;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26681;&#26893;&#20110;&#27531;&#24046;&#36830;&#25509;&#21644;&#23494;&#38598;&#36830;&#25509;&#30340;&#28151;&#21512;&#37327;&#23376;&#21551;&#21457;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;&#20110;&#27169;&#24335;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05754v1 Announce Type: new  Abstract: With the contemporary digital technology approaching, deep neural networks are emerging as the foundational algorithm of the artificial intelligence boom. Whereas, the evolving social demands have been emphasizing the necessity of novel methodologies to substitute traditional neural networks. Concurrently, the advent of the post-Moore era has spurred the development of quantum-inspired neural networks with outstanding potentials at certain circumstances. Nonetheless, a definitive evaluating system with detailed metrics is tremendously vital and indispensable owing to the vague indicators in comparison between the novel and traditional deep learning models at present. Hence, to improve and evaluate the performances of the novel neural networks more comprehensively in complex and unpredictable environments, we propose two hybrid quantum-inspired neural networks which are rooted in residual and dense connections respectively for pattern rec
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#32467;&#21512;&#20223;&#30495;&#21040;&#30495;&#23454;&#19990;&#30028;&#30340;&#36716;&#31227;&#20026;&#35299;&#20915;&#29289;&#20307;&#25805;&#32437;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#21147;&#25903;&#25345;</title><link>https://arxiv.org/abs/2403.02338</link><description>&lt;p&gt;
&#29992;&#21452;&#25163;&#25197;&#24320;&#30422;&#23376;
&lt;/p&gt;
&lt;p&gt;
Twisting Lids Off with Two Hands
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02338
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#32467;&#21512;&#20223;&#30495;&#21040;&#30495;&#23454;&#19990;&#30028;&#30340;&#36716;&#31227;&#20026;&#35299;&#20915;&#29289;&#20307;&#25805;&#32437;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#21147;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#20004;&#21482;&#22810;&#25351;&#25163;&#33218;&#25805;&#32437;&#29289;&#20307;&#19968;&#30452;&#26159;&#26426;&#22120;&#20154;&#39046;&#22495;&#30340;&#19968;&#39033;&#38271;&#26399;&#25361;&#25112;&#65292;&#21407;&#22240;&#22312;&#20110;&#35768;&#22810;&#25805;&#32437;&#20219;&#21153;&#30340;&#20016;&#23500;&#25509;&#35302;&#24615;&#36136;&#20197;&#21450;&#21327;&#35843;&#39640;&#32500;&#24230;&#21452;&#25163;&#31995;&#32479;&#22266;&#26377;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20351;&#29992;&#20004;&#21482;&#25163;&#25197;&#24320;&#21508;&#31181;&#29942;&#23376;&#30422;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20986;&#20351;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#20223;&#30495;&#20013;&#35757;&#32451;&#30340;&#31574;&#30053;&#21487;&#20197;&#26377;&#25928;&#22320;&#36716;&#31227;&#21040;&#29616;&#23454;&#19990;&#30028;&#12290;&#36890;&#36807;&#23545;&#29289;&#29702;&#24314;&#27169;&#12289;&#23454;&#26102;&#24863;&#30693;&#21644;&#22870;&#21169;&#35774;&#35745;&#30340;&#26032;&#24037;&#31243;&#35265;&#35299;&#65292;&#35813;&#31574;&#30053;&#23637;&#31034;&#20102;&#19968;&#33324;&#21270;&#33021;&#21147;&#65292;&#33021;&#22815;&#36143;&#31359;&#21508;&#31181;&#30475;&#19981;&#35265;&#30340;&#29289;&#20307;&#65292;&#23637;&#31034;&#20986;&#21160;&#24577;&#21644;&#28789;&#24039;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#35777;&#26126;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#32467;&#21512;&#20223;&#30495;&#21040;&#30495;&#23454;&#19990;&#30028;&#30340;&#36716;&#31227;&#20173;&#28982;&#26159;&#35299;&#20915;&#21069;&#25152;&#26410;&#26377;&#22797;&#26434;&#38382;&#39064;&#30340;&#25805;&#32437;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02338v1 Announce Type: cross  Abstract: Manipulating objects with two multi-fingered hands has been a long-standing challenge in robotics, attributed to the contact-rich nature of many manipulation tasks and the complexity inherent in coordinating a high-dimensional bimanual system. In this work, we consider the problem of twisting lids of various bottle-like objects with two hands, and demonstrate that policies trained in simulation using deep reinforcement learning can be effectively transferred to the real world. With novel engineering insights into physical modeling, real-time perception, and reward design, the policy demonstrates generalization capabilities across a diverse set of unseen objects, showcasing dynamic and dexterous behaviors. Our findings serve as compelling evidence that deep reinforcement learning combined with sim-to-real transfer remains a promising approach for addressing manipulation problems of unprecedented complexity.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01371</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21464;&#20998;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large-scale variational Gaussian state-space models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01371
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#23884;&#22871;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#21464;&#20998;&#36924;&#36817;&#26041;&#27861;&#65292;&#20854;&#20013;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30001;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20801;&#35768;&#22312;&#27809;&#26377;&#37319;&#29992;&#23545;&#35282;&#39640;&#26031;&#36924;&#36817;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#35780;&#20272;ELBO&#21644;&#20302;&#26041;&#24046;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#65288;i&#65289;&#36890;&#36807;&#21160;&#21147;&#23398;&#23545;&#38544;&#29366;&#24577;&#36827;&#34892;&#36793;&#32536;&#21270;&#30340;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#30340;&#20302;&#31209;&#32467;&#26500;&#65292;&#65288;ii&#65289;&#19968;&#20010;&#25512;&#26029;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#36890;&#36807;&#20302;&#31209;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#26469;&#36817;&#20284;&#26356;&#26032;&#27493;&#39588;&#65292;&#65288;iii&#65289;&#23558;&#24403;&#21069;&#21644;&#26410;&#26469;&#35266;&#27979;&#32534;&#30721;&#20026;&#20266;&#35266;&#27979;--&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#25442;&#20026;&#65288;&#26356;&#31616;&#21333;&#30340;&#65289;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;&#25972;&#20307;&#32780;&#35328;&#65292;&#24517;&#35201;&#30340;&#32479;&#35745;&#20449;&#24687;&#21644;ELBO&#21487;&#20197;&#22312;$O&#65288;TL&#65288;Sr+S^2+r^2&#65289;&#65289;$&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#20854;&#20013;$T$&#26159;&#31995;&#21015;&#38271;&#24230;&#65292;$L$&#26159;&#29366;&#24577;&#31354;&#38388;&#32500;&#25968;&#65292;$S$&#26159;&#29992;&#20110;&#36924;&#36817;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01371v1 Announce Type: cross  Abstract: We introduce an amortized variational inference algorithm and structured variational approximation for state-space models with nonlinear dynamics driven by Gaussian noise. Importantly, the proposed framework allows for efficient evaluation of the ELBO and low-variance stochastic gradient estimates without resorting to diagonal Gaussian approximations by exploiting (i) the low-rank structure of Monte-Carlo approximations to marginalize the latent state through the dynamics (ii) an inference network that approximates the update step with low-rank precision matrix updates (iii) encoding current and future observations into pseudo observations -- transforming the approximate smoothing problem into an (easier) approximate filtering problem. Overall, the necessary statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$ is the series length, $L$ is the state-space dimensionality, $S$ are the number of samples used to app
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;</title><link>https://arxiv.org/abs/2402.18477</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#31614;&#21517;&#26680;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#29992;&#20110;&#38543;&#26426;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18477
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25512;&#26029;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#22312;&#31185;&#23398;&#12289;&#20581;&#24247;&#21644;&#37329;&#34701;&#31561;&#39046;&#22495;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#31614;&#21517;&#26680;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#8220;&#36335;&#24452;&#31354;&#38388;&#8221;&#19978;&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#27979;&#35797;&#65292;&#29992;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#36335;&#24452;&#31354;&#38388;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;CI&#27979;&#35797;&#34920;&#29616;&#20986;&#20005;&#26684;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;&#38750;&#24490;&#29615;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#24320;&#21457;&#20102;&#22522;&#20110;&#32422;&#26463;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#65292;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#26469;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;&#22312;&#20551;&#35774;&#24544;&#23454;&#24615;&#21644;CI&#39044;&#35328;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23436;&#22791;&#19988;&#27491;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18477v1 Announce Type: cross  Abstract: Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via "which variables enter the differential of which other variables". In this paper, we develop a kernel-based test of conditional independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirical
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#23558;&#23567;&#21442;&#25968;&#32435;&#20837;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#65292;&#20174;&#32780;&#31616;&#21270;&#35299;&#20915;&#36807;&#31243;&#65292;&#24182;&#33021;&#22815;&#21512;&#29702;&#20934;&#30830;&#22320;&#25429;&#25417;&#30001;&#23567;&#21442;&#25968;&#24341;&#36215;&#30340;&#35299;&#20013;&#22823;&#23548;&#25968;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2402.17232</link><description>&lt;p&gt;
&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Two-scale Neural Networks for Partial Differential Equations with Small Parameters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17232
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#23558;&#23567;&#21442;&#25968;&#32435;&#20837;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#65292;&#20174;&#32780;&#31616;&#21270;&#35299;&#20915;&#36807;&#31243;&#65292;&#24182;&#33021;&#22815;&#21512;&#29702;&#20934;&#30830;&#22320;&#25429;&#25417;&#30001;&#23567;&#21442;&#25968;&#24341;&#36215;&#30340;&#35299;&#20013;&#22823;&#23548;&#25968;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#12290;&#25105;&#20204;&#30452;&#25509;&#23558;&#23567;&#21442;&#25968;&#32435;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#20013;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#24471;&#20197;&#31616;&#21333;&#26041;&#24335;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;PDE&#25104;&#20026;&#21487;&#33021;&#65292;&#32780;&#26080;&#38656;&#28155;&#21152;&#20613;&#37324;&#21494;&#29305;&#24449;&#25110;&#20854;&#20182;&#35745;&#31639;&#32321;&#29712;&#30340;&#25130;&#26029;&#21442;&#25968;&#25628;&#32034;&#12290;&#22810;&#20010;&#25968;&#20540;&#20363;&#23376;&#23637;&#31034;&#20102;&#22312;&#35299;&#20915;&#30001;&#23567;&#21442;&#25968;&#24341;&#36215;&#30340;&#35299;&#20013;&#22823;&#23548;&#25968;&#29305;&#24449;&#26102;&#30340;&#21512;&#29702;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17232v1 Announce Type: cross  Abstract: We propose a two-scale neural network method for solving partial differential equations (PDEs) with small parameters using physics-informed neural networks (PINNs). We directly incorporate the small parameters into the architecture of neural networks. The proposed method enables solving PDEs with small parameters in a simple fashion, without adding Fourier features or other computationally taxing searches of truncation parameters. Various numerical examples demonstrate reasonable accuracy in capturing features of large derivatives in the solutions caused by small parameters.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#21487;&#23398;&#20064;&#30340;&#27010;&#29575;&#31163;&#25955;&#28508;&#21464;&#37327;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30524;&#37096;&#30142;&#30149;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#26469;&#23398;&#20064;&#30524;&#24213;&#22270;&#20687;&#20013;&#30524;&#37096;&#30142;&#30149;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.16865</link><description>&lt;p&gt;
&#36890;&#36807;&#23558;&#21487;&#23398;&#20064;&#30340;&#27010;&#29575;&#31163;&#25955;&#28508;&#21464;&#37327;&#24341;&#20837;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#25552;&#39640;&#30524;&#37096;&#30142;&#30149;&#26816;&#27979;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improve Robustness of Eye Disease Detection by including Learnable Probabilistic Discrete Latent Variables into Machine Learning Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16865
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#21487;&#23398;&#20064;&#30340;&#27010;&#29575;&#31163;&#25955;&#28508;&#21464;&#37327;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30524;&#37096;&#30142;&#30149;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#26469;&#23398;&#20064;&#30524;&#24213;&#22270;&#20687;&#20013;&#30524;&#37096;&#30142;&#30149;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30524;&#37096;&#30142;&#30149;&#20174;&#31958;&#23615;&#30149;&#24615;&#35270;&#32593;&#33180;&#30149;&#21464;&#21040;&#38738;&#20809;&#30524;&#31561;&#65292;&#30001;&#20110;&#20854;&#39640;&#21457;&#30149;&#29575;&#21644;&#21487;&#33021;&#23548;&#33268;&#35270;&#21147;&#25439;&#23475;&#65292;&#26500;&#25104;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#20844;&#20849;&#21355;&#29983;&#25361;&#25112;&#12290;&#21450;&#26089;&#21644;&#20934;&#30830;&#30340;&#35786;&#26029;&#23545;&#20110;&#26377;&#25928;&#27835;&#30103;&#21644;&#31649;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#20998;&#26512;&#21307;&#23398;&#22270;&#20687;&#65288;&#21253;&#25324;&#30524;&#37096;&#22270;&#20687;&#65289;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#20173;&#28982;&#23384;&#22312;&#25361;&#25112;&#65292;&#36825;&#23545;&#20020;&#24202;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;GFlowOut&#30340;&#26032;&#39062;&#24212;&#29992;&#65292;&#21033;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#30340;&#27010;&#29575;&#26694;&#26550;&#26469;&#23398;&#20064;&#20851;&#20110;&#36749;&#23398;&#25513;&#30721;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#29992;&#20110;&#20351;&#29992;&#30524;&#24213;&#22270;&#20687;&#23545;&#30524;&#37096;&#30142;&#30149;&#36827;&#34892;&#20998;&#31867;&#21644;&#20998;&#26512;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31283;&#20581;&#19988;&#20855;&#26377;&#26222;&#36866;&#24615;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20197;ResNet18&#21644;ViT&#27169;&#22411;&#20026;&#20027;&#24178;&#30340;GFlowOut&#26469;&#35782;&#21035;&#21508;&#31181;&#30524;&#37096;&#29366;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16865v1 Announce Type: cross  Abstract: Ocular diseases, ranging from diabetic retinopathy to glaucoma, present a significant public health challenge due to their prevalence and potential for causing vision impairment. Early and accurate diagnosis is crucial for effective treatment and management.In recent years, deep learning models have emerged as powerful tools for analysing medical images, including ocular imaging . However, challenges persist in model interpretability and uncertainty estimation, which are critical for clinical decision-making. This study introduces a novel application of GFlowOut, leveraging the probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over dropout masks, for the classification and analysis of ocular diseases using eye fundus images. We develop a robust and generalizable method that utilizes GFlowOut integrated with ResNet18 and ViT models as backbone in identifying various ocular conditions. Th
&lt;/p&gt;</description></item><item><title>OmniArch&#36890;&#36807;&#22810;&#29289;&#29702;&#23398;&#26102;&#31354;&#25968;&#25454;&#22788;&#29702;&#12289;&#21487;&#25193;&#23637;&#30340;&#33258;&#22238;&#24402;&#20219;&#21153;&#21644;&#29289;&#29702;&#20449;&#24687;&#22686;&#24378;&#23398;&#20064;&#25216;&#26415;&#65292;&#22312;&#31185;&#23398;&#35745;&#31639;&#39046;&#22495;&#26500;&#24314;&#28789;&#27963;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#24182;&#22312;&#24615;&#33021;&#12289;&#36866;&#24212;&#24615;&#21644;&#36870;&#38382;&#39064;&#27714;&#35299;&#26041;&#38754;&#21462;&#24471;&#31361;&#30772;&#65292;&#23637;&#29616;&#20102;AI&#23545;&#31185;&#23398;&#35745;&#31639;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.16014</link><description>&lt;p&gt;
&#22312;&#31185;&#23398;&#35745;&#31639;&#35268;&#27169;&#19978;&#26500;&#24314;&#28789;&#27963;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Building Flexible Machine Learning Models for Scientific Computing at Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16014
&lt;/p&gt;
&lt;p&gt;
OmniArch&#36890;&#36807;&#22810;&#29289;&#29702;&#23398;&#26102;&#31354;&#25968;&#25454;&#22788;&#29702;&#12289;&#21487;&#25193;&#23637;&#30340;&#33258;&#22238;&#24402;&#20219;&#21153;&#21644;&#29289;&#29702;&#20449;&#24687;&#22686;&#24378;&#23398;&#20064;&#25216;&#26415;&#65292;&#22312;&#31185;&#23398;&#35745;&#31639;&#39046;&#22495;&#26500;&#24314;&#28789;&#27963;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#24182;&#22312;&#24615;&#33021;&#12289;&#36866;&#24212;&#24615;&#21644;&#36870;&#38382;&#39064;&#27714;&#35299;&#26041;&#38754;&#21462;&#24471;&#31361;&#30772;&#65292;&#23637;&#29616;&#20102;AI&#23545;&#31185;&#23398;&#35745;&#31639;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16014v1
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16014v1 Announce Type: cross  Abstract: Foundation models have revolutionized knowledge acquisition across domains, and our study introduces OmniArch, a paradigm-shifting approach designed for building foundation models in multi-physics scientific computing. OmniArch's pre-training involves a versatile pipeline that processes multi-physics spatio-temporal data, casting forward problem learning into scalable auto-regressive tasks, while our novel Physics-Informed Reinforcement Learning (PIRL) technique during fine-tuning ensures alignment with physical laws. Pre-trained on the comprehensive PDEBench dataset, OmniArch not only sets new performance benchmarks for 1D, 2D and 3D PDEs but also demonstrates exceptional adaptability to new physics via few-shot and zero-shot learning approaches. The model's representations further extend to inverse problem-solving, highlighting the transformative potential of AI-enabled Scientific Computing(AI4SC) foundation models for engineering ap
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22635;&#34917;&#20102;&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#22312;&#21508;&#24322;&#25968;&#25454;&#19978;&#25910;&#25947;&#20998;&#26512;&#30340;&#31354;&#30333;&#65292;&#25552;&#20379;&#20102;&#38024;&#23545;&#24378;&#20984;&#21644;&#19968;&#33324;&#20984;&#30446;&#26631;&#30340;SFL&#25910;&#25947;&#20998;&#26512;&#65292;&#25910;&#25947;&#36895;&#29575;&#20998;&#21035;&#20026;$O(1/T)$&#21644;$O(1/\sqrt[3]{T})&#12290;</title><link>https://arxiv.org/abs/2402.15166</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24322;&#26500;&#25968;&#25454;&#19978;&#30340;&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Split Federated Learning on Heterogeneous Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22635;&#34917;&#20102;&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#22312;&#21508;&#24322;&#25968;&#25454;&#19978;&#25910;&#25947;&#20998;&#26512;&#30340;&#31354;&#30333;&#65292;&#25552;&#20379;&#20102;&#38024;&#23545;&#24378;&#20984;&#21644;&#19968;&#33324;&#20984;&#30446;&#26631;&#30340;SFL&#25910;&#25947;&#20998;&#26512;&#65292;&#25910;&#25947;&#36895;&#29575;&#20998;&#21035;&#20026;$O(1/T)$&#21644;$O(1/\sqrt[3]{T})&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#65288;SFL&#65289;&#26159;&#19968;&#31181;&#26368;&#36817;&#30340;&#20998;&#24067;&#24335;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#20010;&#23458;&#25143;&#31471;&#20043;&#38388;&#36827;&#34892;&#21327;&#20316;&#27169;&#22411;&#35757;&#32451;&#12290;&#22312;SFL&#20013;&#65292;&#20840;&#23616;&#27169;&#22411;&#36890;&#24120;&#34987;&#20998;&#20026;&#20004;&#37096;&#20998;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#20197;&#24182;&#34892;&#32852;&#37030;&#26041;&#24335;&#35757;&#32451;&#19968;&#37096;&#20998;&#65292;&#20027;&#26381;&#21153;&#22120;&#35757;&#32451;&#21478;&#19968;&#37096;&#20998;&#12290;&#23613;&#31649;&#26368;&#36817;&#20851;&#20110;SFL&#31639;&#27861;&#21457;&#23637;&#30340;&#30740;&#31350;&#24456;&#22810;&#65292;&#20294;SFL&#30340;&#25910;&#25947;&#20998;&#26512;&#22312;&#25991;&#29486;&#20013;&#36824;&#26410;&#26377;&#25552;&#21450;&#65292;&#26412;&#25991;&#26088;&#22312;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#23545;SFL&#36827;&#34892;&#20998;&#26512;&#21487;&#33021;&#27604;&#23545;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#20998;&#26512;&#26356;&#20855;&#25361;&#25112;&#24615;&#65292;&#36825;&#26159;&#30001;&#20110;&#23458;&#25143;&#31471;&#21644;&#20027;&#26381;&#21153;&#22120;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#21452;&#36895;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#38024;&#23545;&#24322;&#26500;&#25968;&#25454;&#19978;&#24378;&#20984;&#21644;&#19968;&#33324;&#20984;&#30446;&#26631;&#30340;SFL&#25910;&#25947;&#20998;&#26512;&#12290;&#25910;&#25947;&#36895;&#29575;&#20998;&#21035;&#20026;$O(1/T)$&#21644;$O(1/\sqrt[3]{T})$&#65292;&#20854;&#20013;$T$&#34920;&#31034;SFL&#35757;&#32451;&#30340;&#24635;&#36718;&#25968;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#20998;&#26512;&#25193;&#23637;&#21040;&#38750;&#20984;&#30446;&#26631;&#21644;&#19968;&#20123;&#23458;&#25143;&#31471;&#21487;&#33021;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#19981;&#21487;&#29992;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15166v1 Announce Type: cross  Abstract: Split federated learning (SFL) is a recent distributed approach for collaborative model training among multiple clients. In SFL, a global model is typically split into two parts, where clients train one part in a parallel federated manner, and a main server trains the other. Despite the recent research on SFL algorithm development, the convergence analysis of SFL is missing in the literature, and this paper aims to fill this gap. The analysis of SFL can be more challenging than that of federated learning (FL), due to the potential dual-paced updates at the clients and the main server. We provide convergence analysis of SFL for strongly convex and general convex objectives on heterogeneous data. The convergence rates are $O(1/T)$ and $O(1/\sqrt[3]{T})$, respectively, where $T$ denotes the total number of rounds for SFL training. We further extend the analysis to non-convex objectives and where some clients may be unavailable during trai
&lt;/p&gt;</description></item><item><title>GINNs&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#20309;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#33539;&#24335;&#65292;&#21487;&#20197;&#22312;&#20960;&#20309;&#20219;&#21153;&#20013;&#29983;&#25104;&#22810;&#26679;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26080;&#38656;&#35757;&#32451;&#25968;&#25454;&#65292;&#37319;&#29992;&#26174;&#24335;&#22810;&#26679;&#24615;&#25439;&#22833;&#20197;&#21450;&#21487;&#24494;&#25439;&#22833;&#26469;&#20943;&#36731;&#27169;&#24577;&#22349;&#32553;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#22312;&#21508;&#31181;&#22797;&#26434;&#24615;&#22330;&#26223;&#20013;&#30340;&#39640;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14009</link><description>&lt;p&gt;
&#20960;&#20309;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Geometry-Informed Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14009
&lt;/p&gt;
&lt;p&gt;
GINNs&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#20309;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#33539;&#24335;&#65292;&#21487;&#20197;&#22312;&#20960;&#20309;&#20219;&#21153;&#20013;&#29983;&#25104;&#22810;&#26679;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26080;&#38656;&#35757;&#32451;&#25968;&#25454;&#65292;&#37319;&#29992;&#26174;&#24335;&#22810;&#26679;&#24615;&#25439;&#22833;&#20197;&#21450;&#21487;&#24494;&#25439;&#22833;&#26469;&#20943;&#36731;&#27169;&#24577;&#22349;&#32553;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#22312;&#21508;&#31181;&#22797;&#26434;&#24615;&#22330;&#26223;&#20013;&#30340;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#20960;&#20309;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;GINNs&#65289;&#30340;&#27010;&#24565;&#65292;&#28085;&#30422;&#20102;&#65288;i&#65289;&#22312;&#20960;&#20309;&#32422;&#26463;&#19979;&#23398;&#20064;&#65292;&#65288;ii&#65289;&#31070;&#32463;&#22330;&#20316;&#20026;&#21512;&#36866;&#30340;&#34920;&#31034;&#65292;&#65288;iii&#65289;&#29983;&#25104;&#22312;&#20960;&#20309;&#20219;&#21153;&#20013;&#32463;&#24120;&#36935;&#21040;&#30340;&#27424;&#23450;&#31995;&#32479;&#30340;&#22810;&#26679;&#35299;&#20915;&#26041;&#26696;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;GINN&#30340;&#26500;&#24314;&#19981;&#38656;&#35201;&#35757;&#32451;&#25968;&#25454;&#65292;&#22240;&#27492;&#21487;&#20197;&#34987;&#32431;&#32422;&#26463;&#39537;&#21160;&#22320;&#35270;&#20026;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#22686;&#21152;&#20102;&#26174;&#24335;&#30340;&#22810;&#26679;&#24615;&#25439;&#22833;&#26469;&#20943;&#36731;&#27169;&#24577;&#22349;&#32553;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20960;&#31181;&#32422;&#26463;&#65292;&#29305;&#21035;&#26159;&#32452;&#20214;&#30340;&#36830;&#36890;&#24615;&#65292;&#25105;&#20204;&#36890;&#36807;&#33707;&#23572;&#26031;&#29702;&#35770;&#23558;&#20854;&#36716;&#21270;&#20026;&#21487;&#24494;&#25439;&#22833;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19981;&#26029;&#22686;&#21152;&#22797;&#26434;&#24615;&#30340;&#20108;&#32500;&#21644;&#19977;&#32500;&#22330;&#26223;&#20013;&#65292;GINN&#23398;&#20064;&#33539;&#24335;&#30340;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14009v1 Announce Type: new  Abstract: We introduce the concept of geometry-informed neural networks (GINNs), which encompass (i) learning under geometric constraints, (ii) neural fields as a suitable representation, and (iii) generating diverse solutions to under-determined systems often encountered in geometric tasks. Notably, the GINN formulation does not require training data, and as such can be considered generative modeling driven purely by constraints. We add an explicit diversity loss to mitigate mode collapse. We consider several constraints, in particular, the connectedness of components which we convert to a differentiable loss through Morse theory. Experimentally, we demonstrate the efficacy of the GINN learning paradigm across a range of two and three-dimensional scenarios with increasing levels of complexity.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;CodaMal&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#20302;&#25104;&#26412;&#26174;&#24494;&#38236;&#19979;&#30111;&#30142;&#26816;&#27979;&#30340;&#23545;&#27604;&#22495;&#33258;&#36866;&#24212;&#65292;&#35299;&#20915;&#20102;HCM&#21644;LCM&#22270;&#20687;&#20043;&#38388;&#30340;&#22495;&#24046;&#24322;&#38382;&#39064;</title><link>https://arxiv.org/abs/2402.10478</link><description>&lt;p&gt;
CodaMal&#65306;&#20302;&#25104;&#26412;&#26174;&#24494;&#38236;&#19979;&#30340;&#30111;&#30142;&#26816;&#27979;&#30340;&#23545;&#27604;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
CodaMal: Contrastive Domain Adaptation for Malaria Detection in Low-Cost Microscopes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10478
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;CodaMal&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#20302;&#25104;&#26412;&#26174;&#24494;&#38236;&#19979;&#30111;&#30142;&#26816;&#27979;&#30340;&#23545;&#27604;&#22495;&#33258;&#36866;&#24212;&#65292;&#35299;&#20915;&#20102;HCM&#21644;LCM&#22270;&#20687;&#20043;&#38388;&#30340;&#22495;&#24046;&#24322;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30111;&#30142;&#26159;&#20840;&#29699;&#37325;&#22823;&#20581;&#24247;&#38382;&#39064;&#65292;&#20854;&#35786;&#26029;&#38656;&#35201;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#20302;&#25104;&#26412;&#26174;&#24494;&#38236;(LCM)&#19979;&#30340;&#26174;&#24494;&#22270;&#20687;&#12290;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#22312;&#20174;&#26174;&#24494;&#22270;&#20687;&#20013;&#36827;&#34892;&#35745;&#31639;&#26426;&#36741;&#21161;&#35786;&#26029;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#38656;&#35201;&#26631;&#27880;&#30340;&#26174;&#29616;&#20986;&#21463;&#30111;&#30142;&#23492;&#29983;&#34411;&#24433;&#21709;&#30340;&#32454;&#32990;&#21450;&#20854;&#29983;&#21629;&#21608;&#26399;&#38454;&#27573;&#30340;&#22270;&#20687;&#12290;&#19982;&#20174;&#39640;&#25104;&#26412;&#26174;&#24494;&#38236;(HCM)&#20013;&#26631;&#27880;&#22270;&#20687;&#30456;&#27604;&#65292;&#20174;LCM&#20013;&#26631;&#27880;&#22270;&#20687;&#26174;&#33879;&#22686;&#21152;&#20102;&#21307;&#23398;&#19987;&#23478;&#30340;&#36127;&#25285;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#23454;&#38469;&#30340;&#35299;&#20915;&#26041;&#26696;&#24212;&#35813;&#22312;HCM&#22270;&#20687;&#19978;&#35757;&#32451;&#65292;&#33021;&#22815;&#22312;LCM&#22270;&#20687;&#19978;&#27979;&#35797;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#26412;&#20316;&#21697;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CodaMal&#65288;&#23545;&#27604;&#22495;&#33258;&#36866;&#24212;&#29992;&#20110;&#30111;&#30142;&#26816;&#27979;&#65289;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10478v1 Announce Type: cross  Abstract: Malaria is a major health issue worldwide, and its diagnosis requires scalable solutions that can work effectively with low-cost microscopes (LCM). Deep learning-based methods have shown success in computer-aided diagnosis from microscopic images. However, these methods need annotated images that show cells affected by malaria parasites and their life stages. Annotating images from LCM significantly increases the burden on medical experts compared to annotating images from high-cost microscopes (HCM). For this reason, a practical solution would be trained on HCM images which should generalize well on LCM images during testing. While earlier methods adopted a multi-stage learning process, they did not offer an end-to-end approach. In this work, we present an end-to-end learning framework, named CodaMal (Contrastive Domain Adpation for Malaria). In order to bridge the gap between HCM (training) and LCM (testing), we propose a domain adap
&lt;/p&gt;</description></item><item><title>BitDelta&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#20449;&#24687;&#20887;&#20313;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BitDelta&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#28155;&#21152;&#30340;&#20449;&#24687;&#37327;&#21270;&#20026;&#19968;&#20010;&#27604;&#29305;&#65292;&#21516;&#26102;&#20445;&#25345;&#24615;&#33021;&#12290;&#36825;&#19968;&#21457;&#29616;&#23545;&#20110;&#22810;&#31199;&#25143;&#27169;&#22411;&#30340;&#26381;&#21153;&#21644;&#23384;&#20648;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;GPU&#20869;&#23384;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.10193</link><description>&lt;p&gt;
BitDelta&#65306;&#20320;&#30340;&#24494;&#35843;&#21487;&#33021;&#21482;&#26377;&#19968;&#20010;&#27604;&#29305;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
BitDelta: Your Fine-Tune May Only Be Worth One Bit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10193
&lt;/p&gt;
&lt;p&gt;
BitDelta&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#20449;&#24687;&#20887;&#20313;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BitDelta&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#28155;&#21152;&#30340;&#20449;&#24687;&#37327;&#21270;&#20026;&#19968;&#20010;&#27604;&#29305;&#65292;&#21516;&#26102;&#20445;&#25345;&#24615;&#33021;&#12290;&#36825;&#19968;&#21457;&#29616;&#23545;&#20110;&#22810;&#31199;&#25143;&#27169;&#22411;&#30340;&#26381;&#21153;&#21644;&#23384;&#20648;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;GPU&#20869;&#23384;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#24120;&#22312;&#20004;&#20010;&#38454;&#27573;&#36827;&#34892;&#35757;&#32451;&#65306;&#22312;&#22823;&#35268;&#27169;&#20114;&#32852;&#32593;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#30340;&#39640;&#35745;&#31639;&#38656;&#27714;&#65292;&#30452;&#35273;&#19978;&#35748;&#20026;&#24494;&#35843;&#23545;&#27169;&#22411;&#30340;&#20449;&#24687;&#28155;&#21152;&#36739;&#23569;&#65292;&#22240;&#27492;&#26356;&#20855;&#26377;&#21487;&#21387;&#32553;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#24494;&#35843;&#27169;&#22411;&#30340;&#26435;&#37325;&#20998;&#35299;&#20026;&#39044;&#35757;&#32451;&#32452;&#20214;&#21644;&#39069;&#22806;&#30340;&#22686;&#37327;&#26469;&#25506;&#31350;&#36825;&#19968;&#20551;&#35774;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#8212;&#8212;BitDelta&#65292;&#25104;&#21151;&#22320;&#23558;&#36825;&#20010;&#22686;&#37327;&#37327;&#21270;&#20026;1&#27604;&#29305;&#32780;&#19981;&#24433;&#21709;&#24615;&#33021;&#12290;&#36825;&#19968;&#26377;&#36259;&#30340;&#21457;&#29616;&#19981;&#20165;&#31361;&#26174;&#20102;&#24494;&#35843;&#36807;&#31243;&#20013;&#28155;&#21152;&#30340;&#20449;&#24687;&#30340;&#28508;&#22312;&#20887;&#20313;&#24615;&#65292;&#32780;&#19988;&#23545;&#20110;&#22810;&#31199;&#25143;&#27169;&#22411;&#30340;&#26381;&#21153;&#21644;&#23384;&#20648;&#20063;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#39640;&#31934;&#24230;&#30340;&#22522;&#30784;&#27169;&#22411;&#20197;&#21450;&#22810;&#20010;1&#27604;&#29305;&#30340;&#22686;&#37327;&#65292;BitDelta&#22823;&#22823;&#38477;&#20302;&#20102;GPU&#20869;&#23384;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10193v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are typically trained in two phases: pre-training on large internet-scale datasets, and fine-tuning for downstream tasks. Given the higher computational demand of pre-training, it's intuitive to assume that fine-tuning adds less new information to the model, and is thus more compressible. We explore this assumption by decomposing the weights of fine-tuned models into their pre-trained components and an additional delta. We introduce a simple method, BitDelta, which successfully quantizes this delta down to 1 bit without compromising performance. This interesting finding not only highlights the potential redundancy of information added during fine-tuning, but also has significant implications for the multi-tenant serving and multi-tenant storage of fine-tuned models. By enabling the use of a single high-precision base model accompanied by multiple 1-bit deltas, BitDelta dramatically reduces GPU memory requir
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#38024;&#23545;&#30701;&#35270;&#39057;&#23545;&#35266;&#20247;&#24515;&#29702;&#20581;&#24247;&#30340;&#25233;&#37057;&#24433;&#21709;&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#21307;&#23398;&#30693;&#35782;&#30340;&#22810;&#27169;&#24577;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#65292;&#20197;&#39044;&#27979;&#20854;&#24433;&#21709;&#24182;&#37319;&#21462;&#30456;&#24212;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;</title><link>https://arxiv.org/abs/2402.10045</link><description>&lt;p&gt;
&#30701;&#35270;&#39057;&#21644;&#24515;&#29702;&#20581;&#24247;&#65306;&#22522;&#20110;&#30693;&#35782;&#23548;&#21521;&#30340;&#22810;&#27169;&#24577;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Short-Form Videos and Mental Health: A Knowledge-Guided Multimodal Neural Topic Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10045
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#38024;&#23545;&#30701;&#35270;&#39057;&#23545;&#35266;&#20247;&#24515;&#29702;&#20581;&#24247;&#30340;&#25233;&#37057;&#24433;&#21709;&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#21307;&#23398;&#30693;&#35782;&#30340;&#22810;&#27169;&#24577;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#65292;&#20197;&#39044;&#27979;&#20854;&#24433;&#21709;&#24182;&#37319;&#21462;&#30456;&#24212;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#35270;&#39057;&#27491;&#35797;&#22270;&#37325;&#26032;&#22609;&#36896;&#25972;&#20010;&#31038;&#20132;&#23186;&#20307;&#26223;&#35266;&#65292;&#28982;&#32780;&#19987;&#23478;&#20204;&#23545;&#20854;&#23545;&#35266;&#20247;&#30340;&#25233;&#37057;&#24433;&#21709;&#24863;&#21040;&#26497;&#24230;&#25285;&#24551;&#65292;&#36825;&#19968;&#28857;&#24050;&#30001;&#21307;&#23398;&#30740;&#31350;&#35777;&#26126;&#12290;&#20026;&#20102;&#38450;&#27490;&#24191;&#27867;&#24433;&#21709;&#65292;&#21508;&#24179;&#21488;&#28212;&#26395;&#39044;&#27979;&#36825;&#20123;&#35270;&#39057;&#23545;&#35266;&#20247;&#24515;&#29702;&#20581;&#24247;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#37319;&#21462;&#24178;&#39044;&#25514;&#26045;&#65292;&#27604;&#22914;&#20462;&#35746;&#25512;&#33616;&#31639;&#27861;&#21644;&#26174;&#31034;&#35266;&#20247;&#24910;&#37325;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#26041;&#27861;&#32570;&#20047;&#19982;&#25233;&#37057;&#30151;&#30340;&#20020;&#24202;&#35777;&#23454;&#30340;&#22806;&#37096;&#29615;&#22659;&#22240;&#32032;&#30456;&#20851;&#30340;&#21307;&#23398;&#30693;&#35782;&#12290;&#20026;&#20102;&#32771;&#34385;&#36825;&#26679;&#30340;&#21307;&#23398;&#30693;&#35782;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#26041;&#27861;&#35770;&#23398;&#31185;&#8212;&#8212;&#31181;&#23376;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#65288;NTMs&#65289;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#31181;&#23376;NTMs&#23384;&#22312;&#21333;&#19968;&#26469;&#28304;&#20027;&#39064;&#12289;&#26410;&#30693;&#20027;&#39064;&#26469;&#28304;&#12289;&#27169;&#31946;&#30340;&#31181;&#23376;&#30417;&#30563;&#21644;&#27425;&#20248;&#30340;&#25910;&#25947;&#31561;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#30693;&#35782;&#25351;&#23548;&#30340;&#22810;&#27169;&#24577;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#65288;Knowledg...&#65288;&#24453;&#34917;&#20805;&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10045v1 Announce Type: cross  Abstract: While short-form videos head to reshape the entire social media landscape, experts are exceedingly worried about their depressive impacts on viewers, as evidenced by medical studies. To prevent widespread consequences, platforms are eager to predict these videos' impact on viewers' mental health. Subsequently, they can take intervention measures, such as revising recommendation algorithms and displaying viewer discretion. Nevertheless, applicable predictive methods lack relevance to well-established medical knowledge, which outlines clinically proven external and environmental factors of depression. To account for such medical knowledge, we resort to an emergent methodological discipline, seeded Neural Topic Models (NTMs). However, existing seeded NTMs suffer from the limitations of single-origin topics, unknown topic sources, unclear seed supervision, and suboptimal convergence. To address those challenges, we develop a novel Knowledg
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20391;&#20449;&#24687;&#20013;&#30340;Stackelberg&#21338;&#24328;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#29616;&#23454;&#20013;&#29609;&#23478;&#20043;&#38388;&#20449;&#24687;&#20132;&#27969;&#19981;&#20805;&#20998;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#21518;&#24724;&#26368;&#23567;&#21270;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.08576</link><description>&lt;p&gt;
&#20391;&#20449;&#24687;&#20013;&#30340;Stackelberg&#21338;&#24328;&#20013;&#30340;&#21518;&#24724;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Regret Minimization in Stackelberg Games with Side Information
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08576
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20391;&#20449;&#24687;&#20013;&#30340;Stackelberg&#21338;&#24328;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#29616;&#23454;&#20013;&#29609;&#23478;&#20043;&#38388;&#20449;&#24687;&#20132;&#27969;&#19981;&#20805;&#20998;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#21518;&#24724;&#26368;&#23567;&#21270;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#22522;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;Stackelberg&#21338;&#24328;&#26159;&#19968;&#20010;&#21452;&#20154;&#21338;&#24328;&#65292;&#20854;&#20013;&#39046;&#23548;&#32773;&#25215;&#35834;&#19968;&#31181;&#65288;&#28151;&#21512;&#65289;&#31574;&#30053;&#65292;&#36861;&#38543;&#32773;&#20570;&#20986;&#26368;&#20339;&#21453;&#24212;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;Stackelberg&#21338;&#24328;&#31639;&#27861;&#26159;&#31639;&#27861;&#21338;&#24328;&#35770;&#30340;&#26368;&#22823;&#25104;&#21151;&#20043;&#19968;&#65292;&#22240;&#20026;Stackelberg&#21338;&#24328;&#30340;&#31639;&#27861;&#24050;&#32463;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#39046;&#22495;&#20013;&#34987;&#24212;&#29992;&#65292;&#21253;&#25324;&#26426;&#22330;&#23433;&#20840;&#12289;&#21453;&#30423;&#29454;&#21644;&#32593;&#32476;&#29359;&#32618;&#39044;&#38450;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#26410;&#33021;&#32771;&#34385;&#21040;&#27599;&#20010;&#29609;&#23478;&#21487;&#29992;&#30340;&#39069;&#22806;&#20449;&#24687;&#65288;&#20363;&#22914;&#20132;&#36890;&#27169;&#24335;&#65292;&#22825;&#27668;&#26465;&#20214;&#65292;&#32593;&#32476;&#25317;&#22622;&#65289;&#65292;&#36825;&#26159;&#29616;&#23454;&#30340;&#26174;&#33879;&#29305;&#24449;&#65292;&#21487;&#33021;&#20250;&#26174;&#33879;&#24433;&#21709;&#21040;&#20004;&#20010;&#29609;&#23478;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#23558;&#36825;&#26679;&#30340;&#24773;&#20917;&#24418;&#24335;&#21270;&#20026;&#24102;&#26377;&#20391;&#20449;&#24687;&#30340;Stackelberg&#21338;&#24328;&#65292;&#20854;&#20013;&#20004;&#20010;&#29609;&#23478;&#22312;&#36827;&#34892;&#28216;&#25103;&#20043;&#21069;&#37117;&#35266;&#23519;&#21040;&#19968;&#20010;&#22806;&#37096;&#29615;&#22659;&#12290;&#28982;&#21518;&#65292;&#39046;&#23548;&#32773;&#25215;&#35834;&#19968;&#31181;&#65288;&#21487;&#33021;&#20381;&#36182;&#20110;&#19978;&#19979;&#25991;&#30340;&#65289;&#31574;&#30053;&#65292;&#36861;&#38543;&#32773;&#23545;&#39046;&#23548;&#32773;&#30340;&#31574;&#30053;&#21644;&#19978;&#19979;&#25991;&#37117;&#20570;&#20986;&#26368;&#20339;&#21453;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
In its most basic form, a Stackelberg game is a two-player game in which a leader commits to a (mixed) strategy, and a follower best-responds. Stackelberg games are perhaps one of the biggest success stories of algorithmic game theory over the last decade, as algorithms for playing in Stackelberg games have been deployed in many real-world domains including airport security, anti-poaching efforts, and cyber-crime prevention. However, these algorithms often fail to take into consideration the additional information available to each player (e.g. traffic patterns, weather conditions, network congestion), a salient feature of reality which may significantly affect both players' optimal strategies. We formalize such settings as Stackelberg games with side information, in which both players observe an external context before playing. The leader then commits to a (possibly context-dependent) strategy, and the follower best-responds to both the leader's strategy and the context. We focus on t
&lt;/p&gt;</description></item><item><title>Shadowcast&#26159;&#19968;&#31181;&#38544;&#31192;&#30340;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#20266;&#35013;&#25104;&#33391;&#24615;&#22270;&#20687;&#21644;&#21305;&#37197;&#25991;&#26412;&#26469;&#25805;&#32437;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#21709;&#24212;&#12290;&#23427;&#21253;&#25324;&#26631;&#31614;&#25915;&#20987;&#21644;&#35828;&#26381;&#25915;&#20987;&#65292;&#21487;&#20197;&#28151;&#28102;&#31867;&#21035;&#26631;&#31614;&#24182;&#32534;&#20889;&#26377;&#35828;&#26381;&#21147;&#30340;&#25551;&#36848;&#12290;&#20351;&#29992;&#20165;50&#20010;&#27602;&#26679;&#26412;&#65292;Shadowcast&#33021;&#22815;&#39640;&#25928;&#23454;&#29616;&#25915;&#20987;&#32773;&#30340;&#24847;&#22270;&#12290;</title><link>https://arxiv.org/abs/2402.06659</link><description>&lt;p&gt;
Shadowcast: &#38544;&#31192;&#30340;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#23545;&#25239;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06659
&lt;/p&gt;
&lt;p&gt;
Shadowcast&#26159;&#19968;&#31181;&#38544;&#31192;&#30340;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#20266;&#35013;&#25104;&#33391;&#24615;&#22270;&#20687;&#21644;&#21305;&#37197;&#25991;&#26412;&#26469;&#25805;&#32437;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#21709;&#24212;&#12290;&#23427;&#21253;&#25324;&#26631;&#31614;&#25915;&#20987;&#21644;&#35828;&#26381;&#25915;&#20987;&#65292;&#21487;&#20197;&#28151;&#28102;&#31867;&#21035;&#26631;&#31614;&#24182;&#32534;&#20889;&#26377;&#35828;&#26381;&#21147;&#30340;&#25551;&#36848;&#12290;&#20351;&#29992;&#20165;50&#20010;&#27602;&#26679;&#26412;&#65292;Shadowcast&#33021;&#22815;&#39640;&#25928;&#23454;&#29616;&#25915;&#20987;&#32773;&#30340;&#24847;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLM&#65289;&#33021;&#22815;&#20174;&#35270;&#35273;&#36755;&#20837;&#20013;&#29983;&#25104;&#25991;&#26412;&#21709;&#24212;&#65292;&#28982;&#32780;&#23427;&#20204;&#30340;&#22810;&#21151;&#33021;&#24615;&#24102;&#26469;&#20102;&#37325;&#22823;&#30340;&#23433;&#20840;&#38544;&#24739;&#12290;&#26412;&#30740;&#31350;&#39318;&#27425;&#25581;&#31034;&#20102;VLM&#23545;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#30340;&#26131;&#21463;&#24615;&#65292;&#36825;&#20123;&#25915;&#20987;&#21487;&#20197;&#25805;&#32437;&#23545;&#26080;&#23475;&#30340;&#26085;&#24120;&#25552;&#31034;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;Shadowcast&#30340;&#38544;&#31192;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#26041;&#27861;&#65292;&#20854;&#20013;&#27602;&#26679;&#26412;&#22312;&#35270;&#35273;&#19978;&#19982;&#20855;&#26377;&#21305;&#37197;&#25991;&#26412;&#30340;&#33391;&#24615;&#22270;&#20687;&#38590;&#20197;&#21306;&#20998;&#12290;Shadowcast&#22312;&#20004;&#31181;&#25915;&#20987;&#31867;&#22411;&#20013;&#23637;&#31034;&#20986;&#20102;&#26377;&#25928;&#24615;&#12290;&#31532;&#19968;&#31181;&#26159;&#26631;&#31614;&#25915;&#20987;&#65292;&#20351;VLM&#35823;&#35782;&#21035;&#31867;&#21035;&#26631;&#31614;&#65292;&#20363;&#22914;&#28151;&#28102;&#21776;&#32435;&#24503;&#183;&#29305;&#26391;&#26222;&#21644;&#20052;&#183;&#25308;&#30331;&#31561;&#20154;&#12290;&#31532;&#20108;&#31181;&#26159;&#35828;&#26381;&#25915;&#20987;&#65292;&#21033;&#29992;VLM&#30340;&#25991;&#26412;&#29983;&#25104;&#33021;&#21147;&#26469;&#32534;&#20889;&#25925;&#20107;&#65292;&#20363;&#22914;&#36890;&#36807;&#26377;&#35828;&#26381;&#21147;&#21644;&#30475;&#20284;&#21512;&#29702;&#30340;&#25551;&#36848;&#23558;&#22403;&#22334;&#39135;&#21697;&#25551;&#32472;&#25104;&#20581;&#24247;&#39135;&#21697;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;Shadowcast&#20351;&#29992;&#20165;50&#20010;&#27602;&#26679;&#26412;&#23601;&#33021;&#39640;&#24230;&#26377;&#25928;&#22320;&#23454;&#29616;&#25915;&#20987;&#32773;&#30340;&#24847;&#22270;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#27602;&#26679;&#26412;&#20173;&#28982;&#20445;&#25345;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vision-Language Models (VLMs) excel in generating textual responses from visual inputs, yet their versatility raises significant security concerns. This study takes the first step in exposing VLMs' susceptibility to data poisoning attacks that can manipulate responses to innocuous, everyday prompts. We introduce Shadowcast, a stealthy data poisoning attack method where poison samples are visually indistinguishable from benign images with matching texts. Shadowcast demonstrates effectiveness in two attack types. The first is Label Attack, tricking VLMs into misidentifying class labels, such as confusing Donald Trump for Joe Biden. The second is Persuasion Attack, which leverages VLMs' text generation capabilities to craft narratives, such as portraying junk food as health food, through persuasive and seemingly rational descriptions. We show that Shadowcast are highly effective in achieving attacker's intentions using as few as 50 poison samples. Moreover, these poison samples remain eff
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28176;&#36827;&#23376;&#32593;&#32476;&#35757;&#32451;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#20998;&#38454;&#27573;&#39044;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;&#26089;&#26399;&#38454;&#27573;&#26080;&#27861;&#35780;&#20272;&#23436;&#25972;&#27169;&#22411;&#21644;&#27169;&#22411;&#36136;&#37327;&#19979;&#38477;&#31561;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.05913</link><description>&lt;p&gt;
&#36890;&#36807;&#28176;&#36827;&#23376;&#32593;&#32476;&#23454;&#29616;&#39640;&#25928;&#30340;&#20998;&#38454;&#27573;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Efficient Stagewise Pretraining via Progressive Subnetworks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05913
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28176;&#36827;&#23376;&#32593;&#32476;&#35757;&#32451;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#20998;&#38454;&#27573;&#39044;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;&#26089;&#26399;&#38454;&#27573;&#26080;&#27861;&#35780;&#20272;&#23436;&#25972;&#27169;&#22411;&#21644;&#27169;&#22411;&#36136;&#37327;&#19979;&#38477;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21457;&#23637;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#39640;&#25928;&#39044;&#35757;&#32451;&#26041;&#27861;&#30340;&#20851;&#27880;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#26377;&#25928;&#33539;&#20363;&#26159;&#36827;&#34892;&#20998;&#38454;&#27573;&#35757;&#32451;&#65292;&#21363;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#30340;&#22823;&#23567;&#65288;&#20363;&#22914;&#36880;&#28176;&#21472;&#21152;&#65288;Reddi&#31561;&#20154;&#65292;2023&#24180;&#65289;&#65289;&#12290;&#34429;&#28982;&#36164;&#28304;&#21644;&#22681;&#38047;&#26102;&#38388;&#30340;&#33410;&#30465;&#24456;&#21560;&#24341;&#20154;&#65292;&#20294;&#23427;&#20063;&#26377;&#23616;&#38480;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#26089;&#26399;&#38454;&#27573;&#26080;&#27861;&#35780;&#20272;&#23436;&#25972;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#30001;&#20110;&#21021;&#22987;&#38454;&#27573;&#27169;&#22411;&#23481;&#37327;&#36739;&#23567;&#32780;&#23548;&#33268;&#27169;&#22411;&#36136;&#37327;&#19979;&#38477;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#24615;&#26694;&#26550;&#65292;&#21363;&#28176;&#36827;&#23376;&#32593;&#32476;&#35757;&#32451;&#65292;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#23436;&#25972;&#30340;&#27169;&#22411;&#65292;&#20294;&#27599;&#20010;&#27493;&#39588;&#21482;&#35757;&#32451;&#27169;&#22411;&#20013;&#30340;&#23376;&#32593;&#32476;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#36825;&#20010;&#26694;&#26550;&#30340;&#19968;&#20010;&#31616;&#21333;&#23454;&#20363;&#65292;&#21363;&#38543;&#26426;&#36335;&#24452;&#35757;&#32451;&#65288;RaPTr&#65289;&#65292;&#23427;&#22312;&#27599;&#20010;&#27493;&#39588;&#20013;&#21482;&#35757;&#32451;&#19968;&#26465;&#23376;&#36335;&#24452;&#65292;&#36880;&#28176;&#22686;&#21152;&#36335;&#24452;&#38271;&#24230;&#12290;RaPTr&#22312;BERT&#21644;UL2&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#25439;&#22833;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#21482;&#38656;&#35201;2
&lt;/p&gt;
&lt;p&gt;
Recent developments in large language models have sparked interest in efficient pretraining methods. A recent effective paradigm is to perform stage-wise training, where the size of the model is gradually increased over the course of training (e.g. gradual stacking (Reddi et al., 2023)). While the resource and wall-time savings are appealing, it has limitations, particularly the inability to evaluate the full model during earlier stages, and degradation in model quality due to smaller model capacity in the initial stages. In this work, we propose an alternative framework, progressive subnetwork training, that maintains the full model throughout training, but only trains subnetworks within the model in each step. We focus on a simple instantiation of this framework, Random Path Training (RaPTr) that only trains a sub-path of layers in each step, progressively increasing the path lengths in stages. RaPTr achieves better pre-training loss for BERT and UL2 language models while requiring 2
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20256;&#25773;&#35270;&#35282;&#20998;&#26512;&#20102;&#24369;&#30417;&#30563;&#30340;&#23454;&#20307;&#23545;&#40784;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#28508;&#22312;&#21516;&#26500;&#20256;&#25773;&#25805;&#20316;&#31526;&#26469;&#22686;&#24378;&#30693;&#35782;&#22270;&#35889;&#20043;&#38388;&#30340;&#37051;&#22495;&#20449;&#24687;&#20256;&#25773;&#12290;&#36890;&#36807;&#39564;&#35777;&#65292;&#21457;&#29616;&#22522;&#20110;&#32858;&#21512;&#30340;&#23454;&#20307;&#23545;&#40784;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#23545;&#40784;&#23454;&#20307;&#20855;&#26377;&#21516;&#26500;&#23376;&#22270;&#12290;</title><link>https://arxiv.org/abs/2402.03025</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#21516;&#26500;&#20256;&#25773;&#29702;&#35299;&#21644;&#24341;&#23548;&#24369;&#30417;&#30563;&#30340;&#23454;&#20307;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Understanding and Guiding Weakly Supervised Entity Alignment with Potential Isomorphism Propagation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20256;&#25773;&#35270;&#35282;&#20998;&#26512;&#20102;&#24369;&#30417;&#30563;&#30340;&#23454;&#20307;&#23545;&#40784;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#28508;&#22312;&#21516;&#26500;&#20256;&#25773;&#25805;&#20316;&#31526;&#26469;&#22686;&#24378;&#30693;&#35782;&#22270;&#35889;&#20043;&#38388;&#30340;&#37051;&#22495;&#20449;&#24687;&#20256;&#25773;&#12290;&#36890;&#36807;&#39564;&#35777;&#65292;&#21457;&#29616;&#22522;&#20110;&#32858;&#21512;&#30340;&#23454;&#20307;&#23545;&#40784;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#23545;&#40784;&#23454;&#20307;&#20855;&#26377;&#21516;&#26500;&#23376;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24369;&#30417;&#30563;&#30340;&#23454;&#20307;&#23545;&#40784;&#26159;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#31181;&#23376;&#23545;&#40784;&#65292;&#22312;&#19981;&#21516;&#30693;&#35782;&#22270;&#35889;&#20043;&#38388;&#35782;&#21035;&#31561;&#20215;&#23454;&#20307;&#30340;&#20219;&#21153;&#12290;&#23613;&#31649;&#22312;&#22522;&#20110;&#32858;&#21512;&#30340;&#24369;&#30417;&#30563;&#23454;&#20307;&#23545;&#40784;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#30340;&#22522;&#26412;&#26426;&#21046;&#20173;&#26410;&#34987;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20256;&#25773;&#35270;&#35282;&#26469;&#20998;&#26512;&#24369;&#30417;&#30563;&#23454;&#20307;&#23545;&#40784;&#65292;&#24182;&#35299;&#37322;&#20102;&#29616;&#26377;&#30340;&#22522;&#20110;&#32858;&#21512;&#30340;&#23454;&#20307;&#23545;&#40784;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#23454;&#36136;&#19978;&#26159;&#23547;&#25214;&#29992;&#20110;&#23545;&#23454;&#20307;&#30456;&#20284;&#24230;&#36827;&#34892;&#20256;&#25773;&#30340;&#25805;&#20316;&#31526;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#23613;&#31649;&#19981;&#21516;&#30693;&#35782;&#22270;&#35889;&#20043;&#38388;&#23384;&#22312;&#32467;&#26500;&#24322;&#36136;&#24615;&#65292;&#22522;&#20110;&#32858;&#21512;&#30340;&#23454;&#20307;&#23545;&#40784;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#23545;&#40784;&#23454;&#20307;&#20855;&#26377;&#21516;&#26500;&#23376;&#22270;&#65292;&#36825;&#26159;&#23454;&#20307;&#23545;&#40784;&#30340;&#26680;&#24515;&#21069;&#25552;&#65292;&#20294;&#23578;&#26410;&#34987;&#30740;&#31350;&#12290;&#21033;&#29992;&#36825;&#19968;&#27934;&#35265;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#28508;&#22312;&#21516;&#26500;&#20256;&#25773;&#25805;&#20316;&#31526;&#26469;&#22686;&#24378;&#36328;&#30693;&#35782;&#22270;&#35889;&#30340;&#37051;&#22495;&#20449;&#24687;&#20256;&#25773;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#23454;&#20307;&#23545;&#40784;&#26694;&#26550;PipEA&#65292;&#23454;&#29616;&#20102;&#25928;&#26524;&#26174;&#33879;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Weakly Supervised Entity Alignment (EA) is the task of identifying equivalent entities across diverse knowledge graphs (KGs) using only a limited number of seed alignments. Despite substantial advances in aggregation-based weakly supervised EA, the underlying mechanisms in this setting remain unexplored. In this paper, we present a propagation perspective to analyze weakly supervised EA and explain the existing aggregation-based EA models. Our theoretical analysis reveals that these models essentially seek propagation operators for pairwise entity similarities. We further prove that, despite the structural heterogeneity of different KGs, the potentially aligned entities within aggregation-based EA models have isomorphic subgraphs, which is the core premise of EA but has not been investigated. Leveraging this insight, we introduce a potential isomorphism propagation operator to enhance the propagation of neighborhood information across KGs. We develop a general EA framework, PipEA, inco
&lt;/p&gt;</description></item><item><title>AutoTimes&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#36716;&#25442;&#33021;&#21147;&#26469;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#19982;&#20808;&#21069;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02370</link><description>&lt;p&gt;
AutoTimes: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
AutoTimes: Autoregressive Time Series Forecasters via Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02370
&lt;/p&gt;
&lt;p&gt;
AutoTimes&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#36716;&#25442;&#33021;&#21147;&#26469;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#19982;&#20808;&#21069;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#30340;&#26377;&#38480;&#21487;&#29992;&#24615;&#21644;&#21487;&#25193;&#23637;&#39044;&#35757;&#32451;&#30340;&#19981;&#20805;&#20998;&#25506;&#32034;&#65292;&#26102;&#38388;&#24207;&#21015;&#30340;&#22522;&#30784;&#27169;&#22411;&#23578;&#26410;&#23436;&#20840;&#21457;&#23637;&#12290;&#22522;&#20110;&#26102;&#38388;&#24207;&#21015;&#21644;&#33258;&#28982;&#35821;&#35328;&#30340;&#30456;&#20284;&#39034;&#24207;&#32467;&#26500;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#35777;&#26126;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#30340;&#21487;&#34892;&#24615;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#26041;&#27861;&#21487;&#33021;&#24573;&#35270;&#20102;&#26102;&#38388;&#24207;&#21015;&#21644;&#33258;&#28982;&#35821;&#35328;&#23545;&#40784;&#30340;&#19968;&#33268;&#24615;&#65292;&#23548;&#33268;&#23545;LLM&#28508;&#21147;&#30340;&#21033;&#29992;&#19981;&#36275;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#20174;&#35821;&#35328;&#24314;&#27169;&#20013;&#23398;&#21040;&#30340;&#36890;&#29992;&#20196;&#29260;&#36716;&#25442;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AutoTimes&#65292;&#23558;LLM&#37325;&#26032;&#29992;&#20316;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;&#65292;&#36825;&#19982;LLM&#30340;&#33719;&#21462;&#21644;&#21033;&#29992;&#19968;&#33268;&#65292;&#32780;&#26080;&#38656;&#26356;&#26032;&#21442;&#25968;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#39044;&#27979;&#22120;&#21487;&#20197;&#22788;&#29702;&#28789;&#27963;&#30340;&#31995;&#21015;&#38271;&#24230;&#65292;&#24182;&#23454;&#29616;&#19982;&#27969;&#34892;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20196;&#29260;&#30340;&#25552;&#31034;&#26041;&#27861;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#26102;&#38388;&#25139;&#26469;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation models of time series have not been fully developed due to the limited availability of large-scale time series and the underexploration of scalable pre-training. Based on the similar sequential structure of time series and natural language, increasing research demonstrates the feasibility of leveraging large language models (LLM) for time series. Nevertheless, prior methods may overlook the consistency in aligning time series and natural language, resulting in insufficient utilization of the LLM potentials. To fully exploit the general-purpose token transitions learned from language modeling, we propose AutoTimes to repurpose LLMs as Autoregressive Time series forecasters, which is consistent with the acquisition and utilization of LLMs without updating the parameters. The consequent forecasters can handle flexible series lengths and achieve competitive performance as prevalent models. Further, we present token-wise prompting that utilizes corresponding timestamps to make ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#30697;&#38453;&#29109;&#65292;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#21644;&#20960;&#20309;&#21407;&#29702;&#30340;&#26032;&#22411;&#25351;&#26631;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25968;&#25454;&#21387;&#32553;&#33021;&#21147;&#12290;&#35813;&#25351;&#26631;&#21453;&#26144;&#20102;&#27169;&#22411;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#21644;&#28040;&#38500;&#19981;&#24517;&#35201;&#20803;&#32032;&#30340;&#33021;&#21147;&#65292;&#20026;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#30340;&#22266;&#26377;&#33021;&#21147;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;&#22312;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#35774;&#32622;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17139</link><description>&lt;p&gt;
&#36890;&#36807;&#30697;&#38453;&#29109;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Evaluation via Matrix Entropy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#30697;&#38453;&#29109;&#65292;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#21644;&#20960;&#20309;&#21407;&#29702;&#30340;&#26032;&#22411;&#25351;&#26631;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25968;&#25454;&#21387;&#32553;&#33021;&#21147;&#12290;&#35813;&#25351;&#26631;&#21453;&#26144;&#20102;&#27169;&#22411;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#21644;&#28040;&#38500;&#19981;&#24517;&#35201;&#20803;&#32032;&#30340;&#33021;&#21147;&#65292;&#20026;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#30340;&#22266;&#26377;&#33021;&#21147;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;&#22312;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#35774;&#32622;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#23558;&#24378;&#22823;&#30340;&#33021;&#21147;&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#39046;&#22495;&#65292;&#20351;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#21457;&#29983;&#20102;&#38761;&#21629;&#12290;&#22240;&#27492;&#65292;&#20026;LLMs&#23450;&#20041;&#36866;&#24403;&#19988;&#22810;&#26679;&#21270;&#30340;&#35780;&#20272;&#25351;&#26631;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30697;&#38453;&#29109;&#65292;&#19968;&#31181;&#26681;&#26893;&#20110;&#20449;&#24687;&#35770;&#21644;&#20960;&#20309;&#21407;&#29702;&#30340;&#26032;&#22411;&#25351;&#26631;&#65292;&#29992;&#20110;&#37327;&#21270;LLMs&#20013;&#30340;&#25968;&#25454;&#21387;&#32553;&#33021;&#21147;&#12290;&#23427;&#21453;&#26144;&#20102;&#27169;&#22411;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#21644;&#28040;&#38500;&#19981;&#24517;&#35201;&#20803;&#32032;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#23545;&#35821;&#35328;&#27169;&#22411;&#22266;&#26377;&#33021;&#21147;&#30340;&#27934;&#23519;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#21333;&#27169;&#24577;&#65288;&#35821;&#35328;&#65289;&#21644;&#22810;&#27169;&#24577;&#35774;&#32622;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#23545;&#20110;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20986;&#34920;&#31034;&#30340;&#30697;&#38453;&#29109;&#22312;&#27169;&#22411;&#25193;&#22823;&#26102;&#36981;&#24490;&#19968;&#20010;&#32553;&#25918;&#23450;&#24459;&#31867;&#22411;&#30340;&#38477;&#20302;&#65292;&#36825;&#20316;&#20026;&#20256;&#32479;&#25439;&#22833;&#32553;&#25918;&#23450;&#24459;&#30340;&#34917;&#20805;&#12290;&#23545;&#20110;&#22810;&#27169;&#24577;&#35774;&#32622;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#29109;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#19968;&#20010;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have revolutionized the field of natural language processing, extending their strong capabilities into multi-modal domains. Thus, it is vital to define proper and diversified metrics for the evaluation of LLMs.   In this paper, we introduce matrix entropy, a novel metric rooted in information theory and geometry principles to quantify the data compression proficiency in LLMs. It reflects the model's ability to extract relevant information and eliminate unnecessary elements, thereby providing insight into the language model's intrinsic capability. Specifically, we demonstrate its applicability in both single-modal (language) and multi-modal settings. For language models, our findings reveal that the matrix entropy of representations follows a scaling law type reduction when the model scales up, serving as a complement to the traditional loss scaling law. For the multi-modal setting, we also propose an evaluation method based on matrix entropy for assessing a
&lt;/p&gt;</description></item><item><title>LLM&#25351;&#20196;&#24494;&#35843;&#20013;&#65292;&#23545;&#20110;&#30701;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#65292;&#25552;&#31034;&#35789;&#26631;&#35760;&#20998;&#31867;&#25439;&#22833;&#21152;&#26435;&#65288;PLW&#65289;&#19982;&#24615;&#33021;&#21576;&#36127;&#20108;&#27425;&#20851;&#31995;&#65292;&#32780;&#38271;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#21017;&#19981;&#21463;PLW&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.13586</link><description>&lt;p&gt;
LLM&#25351;&#20196;&#24494;&#35843;&#20013;&#30340;&#25552;&#31034;&#26435;&#37325;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Prompt Weight Experiments for LLM Instruction Fine-Tuning. (arXiv:2401.13586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13586
&lt;/p&gt;
&lt;p&gt;
LLM&#25351;&#20196;&#24494;&#35843;&#20013;&#65292;&#23545;&#20110;&#30701;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#65292;&#25552;&#31034;&#35789;&#26631;&#35760;&#20998;&#31867;&#25439;&#22833;&#21152;&#26435;&#65288;PLW&#65289;&#19982;&#24615;&#33021;&#21576;&#36127;&#20108;&#27425;&#20851;&#31995;&#65292;&#32780;&#38271;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#21017;&#19981;&#21463;PLW&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#23567;&#22411;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;&#25552;&#31034;&#35789;&#26631;&#35760;&#20998;&#31867;&#25439;&#22833;&#21152;&#26435;&#65288;PLW&#65289;&#22914;&#20309;&#24433;&#21709;&#22312;&#25351;&#20196;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;7B&#22823;&#23567;&#30340;LLaMA&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20351;&#29992;&#22810;&#20010;&#25351;&#20196;&#25968;&#25454;&#38598;&#37325;&#29616;&#20102;&#26031;&#22374;&#31119;&#22823;&#23398;&#30340;Alpaca&#23454;&#39564;&#65292;&#20854;&#20013;&#21253;&#25324;LLaMA 1&#21644;LLaMA 2&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#25105;&#20204;&#30340;&#30701;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#30340;&#27169;&#22411;&#19982;PLW&#20043;&#38388;&#23384;&#22312;&#36127;&#20108;&#27425;&#20851;&#31995;&#65292;&#32780;&#22312;&#38271;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#30340;&#27169;&#22411;&#19981;&#21463;PLW&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets. We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW.
&lt;/p&gt;</description></item><item><title>&#25910;&#32553;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;CDPMs&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#25910;&#32553;&#21518;&#21521;&#37319;&#26679;&#24182;&#20811;&#26381;&#20998;&#25968;&#21305;&#37197;&#35823;&#24046;&#21644;&#31163;&#25955;&#21270;&#35823;&#24046;&#30340;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#25910;&#32553;&#23376;&#26041;&#24046;&#20445;&#25345;&#65288;sub-VP&#65289;&#26159;&#34920;&#29616;&#26368;&#20339;&#30340;&#19968;&#31181;CDPMs&#12290;</title><link>http://arxiv.org/abs/2401.13115</link><description>&lt;p&gt;
&#25910;&#32553;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Contractive Diffusion Probabilistic Models. (arXiv:2401.13115v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13115
&lt;/p&gt;
&lt;p&gt;
&#25910;&#32553;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;CDPMs&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#25910;&#32553;&#21518;&#21521;&#37319;&#26679;&#24182;&#20811;&#26381;&#20998;&#25968;&#21305;&#37197;&#35823;&#24046;&#21644;&#31163;&#25955;&#21270;&#35823;&#24046;&#30340;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#25910;&#32553;&#23376;&#26041;&#24046;&#20445;&#25345;&#65288;sub-VP&#65289;&#26159;&#34920;&#29616;&#26368;&#20339;&#30340;&#19968;&#31181;CDPMs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#32553;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPMs&#65289;&#24050;&#32463;&#25104;&#20026;&#29983;&#25104;&#24314;&#27169;&#20013;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;DPMs&#30340;&#25104;&#21151;&#20381;&#36182;&#20110;&#20004;&#20010;&#35201;&#32032;&#65306;&#39532;&#23572;&#31185;&#22827;&#25193;&#25955;&#36807;&#31243;&#30340;&#26102;&#38388;&#21453;&#28436;&#21644;&#20998;&#25968;&#21305;&#37197;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24037;&#20316;&#38544;&#21547;&#22320;&#20551;&#35774;&#20998;&#25968;&#21305;&#37197;&#26159;&#25509;&#36817;&#23436;&#32654;&#30340;&#65292;&#32780;&#36825;&#20010;&#20551;&#35774;&#26159;&#20540;&#24471;&#24576;&#30097;&#30340;&#12290;&#37492;&#20110;&#21487;&#33021;&#26080;&#27861;&#20445;&#35777;&#30340;&#20998;&#25968;&#21305;&#37197;&#65292;&#25105;&#20204;&#22312;DPMs&#30340;&#35774;&#35745;&#20013;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20934;&#21017;&#8212;&#8212;&#25910;&#32553;&#21518;&#21521;&#37319;&#26679;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#26032;&#30340;&#25910;&#32553;DPMs&#65288;CDPMs&#65289;&#31867;&#65292;&#21253;&#25324;&#25910;&#32553;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#65288;OU&#65289;&#36807;&#31243;&#21644;&#25910;&#32553;&#23376;&#26041;&#24046;&#20445;&#25345;&#65288;sub-VP&#65289;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDEs&#65289;&#12290;&#20851;&#38190;&#27934;&#23519;&#21147;&#26159;&#21518;&#21521;&#36807;&#31243;&#30340;&#25910;&#32553;&#33021;&#22815;&#32553;&#23567;&#20998;&#25968;&#21305;&#37197;&#35823;&#24046;&#21644;&#31163;&#25955;&#21270;&#35823;&#24046;&#12290;&#22240;&#27492;&#65292;&#25152;&#25552;&#20986;&#30340;CDPMs&#23545;&#20110;&#36825;&#20004;&#31181;&#35823;&#24046;&#37117;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#24471;&#21040;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#25903;&#25345;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25910;&#32553;&#23376;&#26041;&#24046;&#20445;&#25345;&#22312;&#34920;&#29616;&#19978;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion probabilistic models (DPMs) have emerged as a promising technology in generative modeling. The success of DPMs relies on two ingredients: time reversal of Markov diffusion processes and score matching. Most existing work implicitly assumes that score matching is close to perfect, while this assumption is questionable. In view of possibly unguaranteed score matching, we propose a new criterion -- the contraction of backward sampling in the design of DPMs. This leads to a novel class of contractive DPMs (CDPMs), including contractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variance preserving (sub-VP) stochastic differential equations (SDEs). The key insight is that the contraction in the backward process narrows score matching errors, as well as discretization error. Thus, the proposed CDPMs are robust to both sources of error. Our proposal is supported by theoretical results, and is corroborated by experiments. Notably, contractive sub-VP shows the best performa
&lt;/p&gt;</description></item><item><title>Langevin&#36951;&#24536;&#26159;&#19968;&#31181;&#22522;&#20110;&#22122;&#22768;&#26799;&#24230;&#19979;&#38477;&#30340;&#36951;&#24536;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#36817;&#20284;&#36951;&#24536;&#38382;&#39064;&#20013;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#24182;&#19988;&#20855;&#26377;&#31639;&#27861;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.10371</link><description>&lt;p&gt;
Langevin&#36951;&#24536;&#65306;&#22122;&#22768;&#26799;&#24230;&#19979;&#38477;&#30340;&#26426;&#22120;&#36951;&#24536;&#26032;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning. (arXiv:2401.10371v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10371
&lt;/p&gt;
&lt;p&gt;
Langevin&#36951;&#24536;&#26159;&#19968;&#31181;&#22522;&#20110;&#22122;&#22768;&#26799;&#24230;&#19979;&#38477;&#30340;&#36951;&#24536;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#36817;&#20284;&#36951;&#24536;&#38382;&#39064;&#20013;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#24182;&#19988;&#20855;&#26377;&#31639;&#27861;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#37319;&#29992;&#30830;&#20445;&#8220;&#34987;&#36951;&#24536;&#26435;&#8221;&#30340;&#27861;&#24459;&#65292;&#26426;&#22120;&#36951;&#24536;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20010;&#27010;&#29575;&#24615;&#30340;&#36817;&#20284;&#36951;&#24536;&#23450;&#20041;&#65292;&#31867;&#20284;&#20110;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#30340;&#23450;&#20041;&#65292;&#20854;&#20013;&#38544;&#31169;&#34987;&#23450;&#20041;&#20026;&#23545;&#37325;&#26032;&#35757;&#32451;&#30340;&#32479;&#35745;&#19981;&#21487;&#21306;&#20998;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Langevin&#36951;&#24536;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#22122;&#22768;&#26799;&#24230;&#19979;&#38477;&#30340;&#36817;&#20284;&#36951;&#24536;&#38382;&#39064;&#30340;&#38544;&#31169;&#20445;&#35777;&#30340;&#36951;&#24536;&#26694;&#26550;&#12290;Langevin&#36951;&#24536;&#22312;&#31639;&#27861;&#19978;&#32479;&#19968;&#20102;DP&#23398;&#20064;&#36807;&#31243;&#21644;&#38544;&#31169;&#35748;&#35777;&#30340;&#36951;&#24536;&#36807;&#31243;&#12290;&#20854;&#20013;&#21253;&#25324;&#38750;&#20984;&#38382;&#39064;&#30340;&#36817;&#20284;&#35748;&#35777;&#36951;&#24536;&#65292;&#30456;&#23545;&#20110;&#37325;&#26032;&#35757;&#32451;&#30340;&#22797;&#26434;&#24230;&#33410;&#30465;&#65292;&#20197;&#21450;&#29992;&#20110;&#22810;&#20010;&#36951;&#24536;&#35831;&#27714;&#30340;&#39034;&#24207;&#21644;&#25209;&#37327;&#36951;&#24536;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;Langevin&#36951;&#24536;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#23545;&#26799;&#24230;&#19979;&#38477;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine unlearning has raised significant interest with the adoption of laws ensuring the ``right to be forgotten''. Researchers have provided a probabilistic notion of approximate unlearning under a similar definition of Differential Privacy (DP), where privacy is defined as statistical indistinguishability to retraining from scratch. We propose Langevin unlearning, an unlearning framework based on noisy gradient descent with privacy guarantees for approximate unlearning problems. Langevin unlearning unifies the DP learning process and the privacy-certified unlearning process with many algorithmic benefits. These include approximate certified unlearning for non-convex problems, complexity saving compared to retraining, sequential and batch unlearning for multiple unlearning requests. We verify the practicality of Langevin unlearning by studying its privacy-utility-complexity trade-off via experiments on benchmark datasets, and also demonstrate its superiority against gradient-decent-p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#23884;&#20837;&#32500;&#24230;&#20248;&#21270;&#26041;&#27861;&#65288;FIITED&#65289;&#65292;&#33021;&#22815;&#22312;&#25512;&#33616;&#31995;&#32479;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#26681;&#25454;&#23884;&#20837;&#21521;&#37327;&#30340;&#37325;&#35201;&#24615;&#19981;&#26029;&#35843;&#25972;&#20854;&#32500;&#24230;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#34394;&#25311;&#21704;&#24076;&#32034;&#24341;&#21704;&#24076;&#34920;&#30340;&#23884;&#20837;&#23384;&#20648;&#31995;&#32479;&#20197;&#26377;&#25928;&#33410;&#30465;&#20869;&#23384;&#12290;</title><link>http://arxiv.org/abs/2401.04408</link><description>&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#20248;&#21270;&#32454;&#31890;&#24230;&#23884;&#20837;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems. (arXiv:2401.04408v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#23884;&#20837;&#32500;&#24230;&#20248;&#21270;&#26041;&#27861;&#65288;FIITED&#65289;&#65292;&#33021;&#22815;&#22312;&#25512;&#33616;&#31995;&#32479;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#26681;&#25454;&#23884;&#20837;&#21521;&#37327;&#30340;&#37325;&#35201;&#24615;&#19981;&#26029;&#35843;&#25972;&#20854;&#32500;&#24230;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#34394;&#25311;&#21704;&#24076;&#32034;&#24341;&#21704;&#24076;&#34920;&#30340;&#23884;&#20837;&#23384;&#20648;&#31995;&#32479;&#20197;&#26377;&#25928;&#33410;&#30465;&#20869;&#23384;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#25512;&#33616;&#27169;&#22411;&#20013;&#30340;&#22823;&#22411;&#23884;&#20837;&#34920;&#22312;&#35757;&#32451;&#21644;&#25512;&#26029;&#36807;&#31243;&#20013;&#38656;&#35201;&#36807;&#22823;&#30340;&#20869;&#23384;&#12290;&#20026;&#20102;&#20943;&#23567;&#35757;&#32451;&#26102;&#30340;&#20869;&#23384;&#21344;&#29992;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#23884;&#20837;&#32500;&#24230;&#20248;&#21270;&#26041;&#27861; (FIITED)&#12290;&#26681;&#25454;&#23884;&#20837;&#21521;&#37327;&#30340;&#37325;&#35201;&#24615;&#19981;&#21516;&#65292;FIITED&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36830;&#32493;&#35843;&#25972;&#27599;&#20010;&#23884;&#20837;&#21521;&#37327;&#30340;&#32500;&#24230;&#65292;&#23558;&#26356;&#37325;&#35201;&#30340;&#23884;&#20837;&#21521;&#37327;&#20998;&#37197;&#26356;&#38271;&#30340;&#32500;&#24230;&#65292;&#24182;&#33021;&#22815;&#36866;&#24212;&#25968;&#25454;&#30340;&#21160;&#24577;&#21464;&#21270;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#34394;&#25311;&#21704;&#24076;&#30340;&#29289;&#29702;&#32034;&#24341;&#21704;&#24076;&#34920;&#30340;&#23884;&#20837;&#23384;&#20648;&#31995;&#32479;&#65292;&#20197;&#23454;&#29616;&#23884;&#20837;&#32500;&#24230;&#30340;&#35843;&#25972;&#24182;&#26377;&#25928;&#22320;&#33410;&#30465;&#20869;&#23384;&#12290;&#23545;&#20004;&#20010;&#34892;&#19994;&#27169;&#22411;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;FIITED&#33021;&#22815;&#23558;&#23884;&#20837;&#30340;&#22823;&#23567;&#20943;&#23567;&#36229;&#36807;65%&#65292;&#21516;&#26102;&#20445;&#25345;&#35757;&#32451;&#27169;&#22411;&#30340;&#36136;&#37327;&#65292;&#27604;&#29616;&#26377;&#30340;&#19968;&#31181;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36827;&#34892;&#23884;&#20837;&#20462;&#21098;&#30340;&#26041;&#27861;&#33410;&#30465;&#26356;&#22810;&#20869;&#23384;&#12290;
&lt;/p&gt;
&lt;p&gt;
Huge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On p
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27169;&#22411;&#37096;&#32626;&#21644;&#24182;&#34892;&#26694;&#26550;&#65292;&#29992;&#20110;&#21152;&#36895;RLHF&#35757;&#32451;&#12290;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#20004;&#31181;&#28789;&#27963;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#65292;&#20854;&#20013;&#20132;&#26367;&#31574;&#30053;&#26377;&#21161;&#20110;&#20943;&#23569;&#20869;&#23384;&#20887;&#20313;&#21644;&#36890;&#20449;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2312.11819</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#21152;&#36895;RLHF&#35757;&#32451;&#30340;&#33258;&#36866;&#24212;&#37096;&#32626;&#21644;&#24182;&#34892;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training. (arXiv:2312.11819v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.11819
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27169;&#22411;&#37096;&#32626;&#21644;&#24182;&#34892;&#26694;&#26550;&#65292;&#29992;&#20110;&#21152;&#36895;RLHF&#35757;&#32451;&#12290;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#20004;&#31181;&#28789;&#27963;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#65292;&#20854;&#20013;&#20132;&#26367;&#31574;&#30053;&#26377;&#21161;&#20110;&#20943;&#23569;&#20869;&#23384;&#20887;&#20313;&#21644;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20687;ChatGPT&#25110;InstructGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20135;&#29983;&#20102;&#37325;&#22823;&#24433;&#21709;&#12290;&#35768;&#22810;&#30740;&#31350;&#23581;&#35797;&#22797;&#29616;&#22797;&#26434;&#30340;InstructGPT&#30340;&#35757;&#32451;&#27969;&#31243;&#65292;&#21363;&#22522;&#20110;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#12290;&#28982;&#32780;&#65292;&#20027;&#27969;&#30340;&#20998;&#24067;&#24335;RLHF&#35757;&#32451;&#26041;&#27861;&#36890;&#24120;&#37319;&#29992;&#22266;&#23450;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#65292;&#31216;&#20026;Flattening&#31574;&#30053;&#12290;&#35813;&#31574;&#30053;&#23558;RLHF&#20013;&#28041;&#21450;&#30340;&#22235;&#20010;&#30456;&#20114;&#20381;&#36182;&#30340;&#27169;&#22411;&#35270;&#20026;&#21333;&#20010;&#23454;&#20307;&#65292;&#23558;&#23427;&#20204;&#20998;&#37197;&#21040;&#25152;&#26377;&#35774;&#22791;&#19978;&#65292;&#24182;&#24212;&#29992;&#20110;&#21333;&#20010;&#27169;&#22411;&#35774;&#35745;&#30340;&#24182;&#34892;&#25216;&#26415;&#65292;&#32780;&#19981;&#32771;&#34385;&#27599;&#20010;&#27169;&#22411;&#22266;&#26377;&#30340;&#19981;&#21516;&#24037;&#20316;&#36127;&#36733;&#12290;&#32467;&#26524;&#65292;&#35813;&#31574;&#30053;&#21152;&#21095;&#20102;RLHF&#35757;&#32451;&#20013;&#30340;&#29983;&#25104;&#29942;&#39048;&#65292;&#24182;&#38477;&#20302;&#20102;&#25972;&#20307;&#35757;&#32451;&#25928;&#29575;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27169;&#22411;&#37096;&#32626;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#20004;&#31181;&#28789;&#27963;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#12290;&#20132;&#26367;&#31574;&#30053;&#26377;&#21161;&#20110;&#20943;&#23569;&#20869;&#23384;&#20887;&#20313;&#21644;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, ChatGPT or InstructGPT like large language models (LLM) has made a significant impact in the AI world. Many works have attempted to reproduce the complex InstructGPT's training pipeline, namely Reinforcement Learning with Human Feedback (RLHF). However, the mainstream distributed RLHF training methods typically adopt a fixed model placement strategy, referred to as the Flattening strategy. This strategy treats all four interdependent models involved in RLHF as a single entity, distributing them across all devices and applying parallelism techniques designed for a single model, regardless of the different workloads inherent to each model. As a result, this strategy exacerbates the generation bottlenecks in the RLHF training and degrades the overall training efficiency. To address these issues, we propose an adaptive model placement framework that offers two flexible model placement strategies. The Interleaving strategy helps reduce memory redundancy and communication costs of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25193;&#23637;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#33539;&#22260;&#65292;&#20174;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#36716;&#21270;&#20026;&#22810;&#39033;&#24335;&#27169;&#22411;&#65292;&#24182;&#30740;&#31350;&#20102;&#37096;&#20998;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#26102;&#30340;&#37096;&#20998;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.15580</link><description>&lt;p&gt;
&#36879;&#36807;&#21464;&#21270;&#30340;&#35270;&#35282;&#65292;&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Identifiable Latent Polynomial Causal Models Through the Lens of Change. (arXiv:2310.15580v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25193;&#23637;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#33539;&#22260;&#65292;&#20174;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#36716;&#21270;&#20026;&#22810;&#39033;&#24335;&#27169;&#22411;&#65292;&#24182;&#30740;&#31350;&#20102;&#37096;&#20998;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#26102;&#30340;&#37096;&#20998;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26088;&#22312;&#20174;&#35266;&#23519;&#21040;&#30340;&#20302;&#32423;&#25968;&#25454;&#20013;&#25581;&#31034;&#28508;&#22312;&#30340;&#39640;&#32423;&#22240;&#26524;&#34920;&#31034;&#12290;&#20854;&#20013;&#19968;&#20010;&#20027;&#35201;&#20219;&#21153;&#26159;&#25552;&#20379;&#21487;&#38752;&#30340;&#20445;&#35777;&#65292;&#20197;&#30830;&#20445;&#35782;&#21035;&#20986;&#36825;&#20123;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#21363;&#21487;&#35782;&#21035;&#24615;&#12290;&#26368;&#36817;&#30340;&#19968;&#39033;&#31361;&#30772;&#24615;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20043;&#38388;&#22312;&#22810;&#20010;&#29615;&#22659;&#19979;&#30340;&#22240;&#26524;&#24433;&#21709;&#30340;&#21464;&#21270;&#26469;&#25506;&#32034;&#21487;&#35782;&#21035;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#36827;&#23637;&#24314;&#31435;&#22312;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#20005;&#26684;&#36981;&#24490;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#30340;&#20551;&#35774;&#22522;&#30784;&#19978;&#12290;&#26412;&#25991;&#23558;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#33539;&#22260;&#25193;&#23637;&#21040;&#28041;&#21450;&#38750;&#32447;&#24615;&#22240;&#26524;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#36825;&#20123;&#20851;&#31995;&#30001;&#22810;&#39033;&#24335;&#27169;&#22411;&#34920;&#31034;&#65292;&#24182;&#19988;&#22122;&#22768;&#20998;&#24067;&#31526;&#21512;&#25351;&#25968;&#20998;&#24067;&#26063;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#25152;&#26377;&#22240;&#26524;&#21442;&#25968;&#26045;&#21152;&#21464;&#21270;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#22312;&#37096;&#20998;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32463;&#39564;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal representation learning aims to unveil latent high-level causal representations from observed low-level data. One of its primary tasks is to provide reliable assurance of identifying these latent causal models, known as identifiability. A recent breakthrough explores identifiability by leveraging the change of causal influences among latent causal variables across multiple environments \citep{liu2022identifying}. However, this progress rests on the assumption that the causal relationships among latent causal variables adhere strictly to linear Gaussian models. In this paper, we extend the scope of latent causal models to involve nonlinear causal relationships, represented by polynomial models, and general noise distributions conforming to the exponential family. Additionally, we investigate the necessity of imposing changes on all causal parameters and present partial identifiability results when part of them remains unchanged. Further, we propose a novel empirical estimation me
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#30340;&#20248;&#21183;&#65292;&#25512;&#23548;&#20102;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#65292;&#21021;&#22987;&#21270;&#26465;&#20214;&#28385;&#36275;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.12680</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#20248;&#21270;&#19982;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#30340;&#20248;&#21183;&#65292;&#25512;&#23548;&#20102;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#65292;&#21021;&#22987;&#21270;&#26465;&#20214;&#28385;&#36275;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26680;&#24515;&#26426;&#21046;&#8212;&#8212;Attention&#26426;&#21046;&#30340;&#35757;&#32451;&#21644;&#27867;&#21270;&#21160;&#24577;&#20173;&#26410;&#28145;&#20837;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#20998;&#26512;&#20027;&#35201;&#38598;&#20013;&#22312;&#21333;&#22836;&#27880;&#24847;&#21147;&#19978;&#12290;&#21463;&#21040;&#20840;&#36830;&#25509;&#32593;&#32476;&#35757;&#32451;&#26102;&#36807;&#21442;&#25968;&#21270;&#30340;&#30410;&#22788;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#28508;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#20248;&#21183;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#25968;&#25454;&#30340;&#36866;&#24403;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#19979;&#65292;&#25512;&#23548;&#20986;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#36215;&#21021;&#22987;&#21270;&#26102;&#30830;&#20445;&#21487;&#23454;&#29616;&#24615;&#24471;&#21040;&#28385;&#36275;&#30340;&#22522;&#26412;&#26465;&#20214;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#26465;&#20214;&#36866;&#29992;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#26399;&#26395;&#36825;&#20010;&#20998;&#26512;&#21487;&#20197;&#25193;&#23637;&#21040;&#21508;&#31181;&#25968;&#25454;&#27169;&#22411;&#21644;&#26550;&#26500;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
The training and generalization dynamics of the Transformer's core mechanism, namely the Attention mechanism, remain under-explored. Besides, existing analyses primarily focus on single-head attention. Inspired by the demonstrated benefits of overparameterization when training fully-connected networks, we investigate the potential optimization and generalization advantages of using multiple attention heads. Towards this goal, we derive convergence and generalization guarantees for gradient-descent training of a single-layer multi-head self-attention model, under a suitable realizability condition on the data. We then establish primitive conditions on the initialization that ensure realizability holds. Finally, we demonstrate that these conditions are satisfied for a simple tokenized-mixture model. We expect the analysis can be extended to various data-model and architecture variations.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#65288;TOA&#65289;&#30340;&#27010;&#24565;&#21644;&#26694;&#26550;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#23545;&#25512;&#29702;&#20219;&#21153;&#26377;&#29992;&#31572;&#26696;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#23454;&#32423;&#36974;&#34109;&#65288;FLM&#65289;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#33258;&#25105;&#30417;&#30563;&#30340;TOA&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2310.11571</link><description>&lt;p&gt;
&#20160;&#20040;&#26159;&#19968;&#20010;&#22909;&#38382;&#39064;&#65311;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#19982;&#20107;&#23454;&#32423;&#36974;&#34109;&#12290;
&lt;/p&gt;
&lt;p&gt;
What is a good question? Task-oriented asking with fact-level masking. (arXiv:2310.11571v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#65288;TOA&#65289;&#30340;&#27010;&#24565;&#21644;&#26694;&#26550;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#23545;&#25512;&#29702;&#20219;&#21153;&#26377;&#29992;&#31572;&#26696;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#23454;&#32423;&#36974;&#34109;&#65288;FLM&#65289;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#33258;&#25105;&#30417;&#30563;&#30340;TOA&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#38382;&#26159;&#29616;&#23454;&#29983;&#27963;&#20013;&#21512;&#20316;&#25512;&#29702;&#20219;&#21153;&#65288;&#22914;&#38382;&#31572;&#65289;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#20363;&#22914;&#65292;&#19968;&#20010;&#27861;&#24459;&#21161;&#25163;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#27809;&#26377;&#29992;&#25143;&#24773;&#20917;&#30340;&#20855;&#20307;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#26080;&#27861;&#25552;&#20379;&#20934;&#30830;&#30340;&#24314;&#35758;&#12290;&#28982;&#32780;&#65292;&#36890;&#24120;&#20250;&#30452;&#25509;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#25512;&#29702;&#20219;&#21153;&#65292;&#32780;&#19981;&#20250;&#21521;&#29992;&#25143;&#25110;&#31532;&#19977;&#26041;&#25552;&#20986;&#21518;&#32493;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31216;&#20026;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#65288;TOA&#65289;&#12290;&#38646;-shot&#32842;&#22825;&#27169;&#22411;&#21487;&#20197;&#25191;&#34892;TOA&#65292;&#20294;&#23427;&#20204;&#30340;&#35757;&#32451;&#20027;&#35201;&#22522;&#20110;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#65292;&#32780;&#19981;&#26159;&#38382;&#39064;&#26159;&#21542;&#23545;&#25104;&#21151;&#30340;&#21512;&#20316;&#26377;&#24110;&#21161;&#12290;&#20026;&#20102;&#33021;&#22815;&#35757;&#32451;&#21644;&#35780;&#20272;TOA&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#23548;&#21521;&#35810;&#38382;&#30340;&#23450;&#20041;&#21644;&#26694;&#26550;&#65292;&#21363;&#29983;&#25104;&#33021;&#22815;&#20026;&#25512;&#29702;&#20219;&#21153;&#25552;&#20379;&#26377;&#29992;&#31572;&#26696;&#30340;&#38382;&#39064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20107;&#23454;&#32423;&#36974;&#34109;&#65288;FLM&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30465;&#30053;&#29305;&#23450;&#30340;&#37096;&#20998;&#23558;&#33258;&#28982;&#35821;&#35328;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#33258;&#25105;&#30417;&#30563;&#30340;TOA&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Asking questions is an important element of real-life collaboration on reasoning tasks like question answering. For example, a legal assistant chatbot may be unable to make accurate recommendations without specific information on the user's circumstances. However, large language models are usually deployed to solve reasoning tasks directly without asking follow-up questions to the user or third parties. We term this problem task-oriented asking (TOA). Zero-shot chat models can perform TOA, but their training is primarily based on next-token prediction rather than whether questions contribute to successful collaboration. To enable the training and evaluation of TOA models, we present a definition and framework for natural language task-oriented asking, the problem of generating questions that result in answers useful for a reasoning task. We also present fact-level masking (FLM), a procedure for converting natural language datasets into self-supervised TOA datasets by omitting particula
&lt;/p&gt;</description></item><item><title>EHI&#26159;&#19968;&#31181;&#31471;&#21040;&#31471;&#23398;&#20064;&#30340;&#23618;&#27425;&#32034;&#24341;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#23494;&#38598;&#26816;&#32034;&#12290;&#23427;&#21516;&#26102;&#23398;&#20064;&#23884;&#20837;&#21644;ANNS&#32467;&#26500;&#65292;&#36890;&#36807;&#20351;&#29992;&#23494;&#38598;&#36335;&#24452;&#23884;&#20837;&#26469;&#25429;&#33719;&#32034;&#24341;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#20197;&#20248;&#21270;&#26816;&#32034;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.08891</link><description>&lt;p&gt;
EHI: &#39640;&#25928;&#23494;&#38598;&#26816;&#32034;&#30340;&#23618;&#27425;&#32034;&#24341;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
EHI: End-to-end Learning of Hierarchical Index for Efficient Dense Retrieval. (arXiv:2310.08891v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08891
&lt;/p&gt;
&lt;p&gt;
EHI&#26159;&#19968;&#31181;&#31471;&#21040;&#31471;&#23398;&#20064;&#30340;&#23618;&#27425;&#32034;&#24341;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#23494;&#38598;&#26816;&#32034;&#12290;&#23427;&#21516;&#26102;&#23398;&#20064;&#23884;&#20837;&#21644;ANNS&#32467;&#26500;&#65292;&#36890;&#36807;&#20351;&#29992;&#23494;&#38598;&#36335;&#24452;&#23884;&#20837;&#26469;&#25429;&#33719;&#32034;&#24341;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#20197;&#20248;&#21270;&#26816;&#32034;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#23884;&#20837;&#24335;&#26816;&#32034;&#29616;&#24050;&#25104;&#20026;&#35821;&#20041;&#25628;&#32034;&#21644;&#25490;&#21517;&#38382;&#39064;&#30340;&#34892;&#19994;&#26631;&#20934;&#65292;&#22914;&#33719;&#21462;&#32473;&#23450;&#26597;&#35810;&#30340;&#30456;&#20851;&#32593;&#32476;&#25991;&#26723;&#12290;&#36825;&#20123;&#25216;&#26415;&#20351;&#29992;&#20102;&#20004;&#20010;&#38454;&#27573;&#30340;&#36807;&#31243;&#65306;(a)&#23545;&#27604;&#23398;&#20064;&#26469;&#35757;&#32451;&#21452;&#32534;&#30721;&#22120;&#20197;&#23884;&#20837;&#26597;&#35810;&#21644;&#25991;&#26723;&#65292;&#20197;&#21450;(b)&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;(ANNS)&#20197;&#26597;&#25214;&#32473;&#23450;&#26597;&#35810;&#30340;&#30456;&#20284;&#25991;&#26723;&#12290;&#36825;&#20004;&#20010;&#38454;&#27573;&#26159;&#19981;&#30456;&#20132;&#30340;&#65307;&#23398;&#24471;&#30340;&#23884;&#20837;&#21487;&#33021;&#19981;&#36866;&#21512;ANNS&#26041;&#27861;&#65292;&#21453;&#20043;&#20134;&#28982;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31471;&#21040;&#31471;&#23618;&#27425;&#32034;&#24341;(EHI)&#30340;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#23398;&#20064;&#23884;&#20837;&#21644;ANNS&#32467;&#26500;&#20197;&#20248;&#21270;&#26816;&#32034;&#24615;&#33021;&#12290;EHI&#20351;&#29992;&#26631;&#20934;&#30340;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#26469;&#23884;&#20837;&#26597;&#35810;&#21644;&#25991;&#26723;&#65292;&#21516;&#26102;&#23398;&#20064;&#19968;&#20010;&#20498;&#25490;&#25991;&#20214;&#32034;&#24341;(IVF)&#39118;&#26684;&#30340;&#26641;&#29366;&#32467;&#26500;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;ANNS&#12290;&#20026;&#20102;&#30830;&#20445;&#31163;&#25955;&#22522;&#20110;&#26641;&#30340;ANNS&#32467;&#26500;&#30340;&#31283;&#23450;&#21644;&#39640;&#25928;&#23398;&#20064;&#65292;EHI&#24341;&#20837;&#20102;&#23494;&#38598;&#36335;&#24452;&#23884;&#20837;&#30340;&#27010;&#24565;&#65292;&#29992;&#26469;&#25429;&#33719;&#32034;&#24341;&#30340;&#35821;&#20041;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dense embedding-based retrieval is now the industry standard for semantic search and ranking problems, like obtaining relevant web documents for a given query. Such techniques use a two-stage process: (a) contrastive learning to train a dual encoder to embed both the query and documents and (b) approximate nearest neighbor search (ANNS) for finding similar documents for a given query. These two stages are disjoint; the learned embeddings might be ill-suited for the ANNS method and vice-versa, leading to suboptimal performance. In this work, we propose End-to-end Hierarchical Indexing -- EHI -- that jointly learns both the embeddings and the ANNS structure to optimize retrieval performance. EHI uses a standard dual encoder model for embedding queries and documents while learning an inverted file index (IVF) style tree structure for efficient ANNS. To ensure stable and efficient learning of discrete tree-based ANNS structure, EHI introduces the notion of dense path embedding that capture
&lt;/p&gt;</description></item><item><title>&#20013;&#22269;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#30740;&#31350;&#21457;&#29616;&#22312;&#32852;&#21512;&#23398;&#20064;&#20013;&#65292;&#38598;&#20013;&#21270;&#30340;&#26041;&#27861;&#24635;&#26159;&#27604;&#20998;&#25955;&#21270;&#30340;&#26041;&#27861;&#26356;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#65292;&#21516;&#26102;&#65292;&#37096;&#20998;&#21442;&#19982;&#22312;&#38598;&#20013;&#21270;&#26041;&#27861;&#20013;&#34920;&#29616;&#26356;&#22909;&#65292;&#32780;&#22312;&#20998;&#25955;&#21270;&#26041;&#27861;&#20013;&#65292;&#25299;&#25169;&#32467;&#26500;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#21313;&#20998;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2310.03461</link><description>&lt;p&gt;
&#21738;&#31181;&#27169;&#24335;&#26356;&#36866;&#21512;&#32852;&#21512;&#23398;&#20064;&#65311;&#20013;&#22830;&#21270;&#36824;&#26159;&#20998;&#25955;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Which mode is better for federated learning? Centralized or Decentralized. (arXiv:2310.03461v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03461
&lt;/p&gt;
&lt;p&gt;
&#20013;&#22269;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#30740;&#31350;&#21457;&#29616;&#22312;&#32852;&#21512;&#23398;&#20064;&#20013;&#65292;&#38598;&#20013;&#21270;&#30340;&#26041;&#27861;&#24635;&#26159;&#27604;&#20998;&#25955;&#21270;&#30340;&#26041;&#27861;&#26356;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#65292;&#21516;&#26102;&#65292;&#37096;&#20998;&#21442;&#19982;&#22312;&#38598;&#20013;&#21270;&#26041;&#27861;&#20013;&#34920;&#29616;&#26356;&#22909;&#65292;&#32780;&#22312;&#20998;&#25955;&#21270;&#26041;&#27861;&#20013;&#65292;&#25299;&#25169;&#32467;&#26500;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#21313;&#20998;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#65292;&#38598;&#20013;&#21270;&#21644;&#20998;&#25955;&#21270;&#26041;&#27861;&#37117;&#34920;&#29616;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#21644;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#30740;&#31350;&#24182;&#27809;&#26377;&#25552;&#20379;&#36275;&#22815;&#30340;&#35777;&#25454;&#26469;&#34920;&#26126;&#21738;&#31181;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#34429;&#28982;&#20174;&#20248;&#21270;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#20998;&#25955;&#21270;&#30340;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#36739;&#23569;&#30340;&#36890;&#20449;&#23454;&#29616;&#19982;&#38598;&#20013;&#21270;&#26041;&#27861;&#30456;&#27604;&#36739;&#30340;&#25910;&#25947;&#24615;&#65292;&#20294;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#23427;&#30340;&#27979;&#35797;&#24615;&#33021;&#22987;&#32456;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#20840;&#38754;&#25506;&#32034;&#23427;&#20204;&#22312;&#32852;&#21512;&#23398;&#20064;&#20013;&#30340;&#34892;&#20026;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#36807;&#24230;&#39118;&#38505;&#65292;&#21253;&#25324;&#20248;&#21270;&#21644;&#27867;&#21270;&#30340;&#32852;&#21512;&#20998;&#26512;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20809;&#28369;&#38750;&#20984;&#30446;&#26631;&#19978;&#65292;1&#65289;&#38598;&#20013;&#21270;&#30340;FL&#65288;CFL&#65289;&#24635;&#26159;&#27604;&#20998;&#25955;&#21270;&#30340;FL&#65288;DFL&#65289;&#26356;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#65307;2&#65289;&#20174;CFL&#30340;&#36807;&#24230;&#39118;&#38505;&#21644;&#27979;&#35797;&#35823;&#24046;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#37096;&#20998;&#21442;&#19982;&#27604;&#20840;&#21442;&#19982;&#26356;&#22909;&#65307;3&#65289;&#22312;DFL&#20013;&#65292;&#20026;&#20102;&#36991;&#20813;&#38543;&#30528;&#35757;&#32451;&#35268;&#27169;&#22686;&#21152;&#32780;&#24615;&#33021;&#23849;&#28291;&#65292;&#25299;&#25169;&#32467;&#26500;&#26377;&#24517;&#35201;&#28385;&#36275;&#19968;&#23450;&#30340;&#35201;&#27714;&#12290;&#22522;&#20110;&#19968;&#20123;&#23454;&#35777;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Both centralized and decentralized approaches have shown excellent performance and great application value in federated learning (FL). However, current studies do not provide sufficient evidence to show which one performs better. Although from the optimization perspective, decentralized methods can approach the comparable convergence of centralized methods with less communication, its test performance has always been inefficient in empirical studies. To comprehensively explore their behaviors in FL, we study their excess risks, including the joint analysis of both optimization and generalization. We prove that on smooth non-convex objectives, 1) centralized FL (CFL) always generalizes better than decentralized FL (DFL); 2) from perspectives of the excess risk and test error in CFL, adopting partial participation is superior to full participation; and, 3) there is a necessary requirement for the topology in DFL to avoid performance collapse as the training scale increases. Based on some
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#20998;&#20301;&#25968;&#21098;&#20999;&#30340;&#40065;&#26834;&#24615;&#38543;&#26426;&#20248;&#21270;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#20809;&#28369;&#30446;&#26631;&#19988;&#33021;&#23481;&#24525;&#24322;&#24120;&#20540;&#21644;&#23614;&#37325;&#26679;&#26412;&#12290;&#23545;&#20110;&#24378;&#20984;&#30446;&#26631;&#65292;&#36845;&#20195;&#25910;&#25947;&#21040;&#38598;&#20013;&#20998;&#24067;&#24182;&#23548;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#27010;&#29575;&#30028;&#12290;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#65292;&#26497;&#38480;&#20998;&#24067;&#23616;&#37096;&#21270;&#22312;&#20302;&#26799;&#24230;&#37051;&#22495;&#19978;&#12290;&#20351;&#29992;&#28378;&#21160;&#20998;&#20301;&#25968;&#23454;&#29616;&#30340;&#31639;&#27861;&#20855;&#26377;&#24456;&#24378;&#30340;&#40065;&#26834;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.17316</link><description>&lt;p&gt;
&#36890;&#36807;&#26799;&#24230;&#20998;&#20301;&#25968;&#21098;&#20999;&#23454;&#29616;&#40065;&#26834;&#24615;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust Stochastic Optimization via Gradient Quantile Clipping. (arXiv:2309.17316v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17316
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#20998;&#20301;&#25968;&#21098;&#20999;&#30340;&#40065;&#26834;&#24615;&#38543;&#26426;&#20248;&#21270;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#20809;&#28369;&#30446;&#26631;&#19988;&#33021;&#23481;&#24525;&#24322;&#24120;&#20540;&#21644;&#23614;&#37325;&#26679;&#26412;&#12290;&#23545;&#20110;&#24378;&#20984;&#30446;&#26631;&#65292;&#36845;&#20195;&#25910;&#25947;&#21040;&#38598;&#20013;&#20998;&#24067;&#24182;&#23548;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#27010;&#29575;&#30028;&#12290;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#65292;&#26497;&#38480;&#20998;&#24067;&#23616;&#37096;&#21270;&#22312;&#20302;&#26799;&#24230;&#37051;&#22495;&#19978;&#12290;&#20351;&#29992;&#28378;&#21160;&#20998;&#20301;&#25968;&#23454;&#29616;&#30340;&#31639;&#27861;&#20855;&#26377;&#24456;&#24378;&#30340;&#40065;&#26834;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#33539;&#25968;&#20998;&#20301;&#25968;&#20316;&#20026;&#21098;&#20999;&#38408;&#20540;&#30340;&#31574;&#30053;&#65292;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477; (SGD)&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#31574;&#30053;&#22312;&#20809;&#28369;&#30446;&#26631;&#65288;&#20984;&#25110;&#38750;&#20984;&#65289;&#19979;&#25552;&#20379;&#20102;&#19968;&#31181;&#40065;&#26834;&#19988;&#39640;&#25928;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#23481;&#24525;&#23614;&#37325;&#26679;&#26412;&#65288;&#21253;&#25324;&#26080;&#38480;&#26041;&#24046;&#65289;&#21644;&#25968;&#25454;&#27969;&#20013;&#30340;&#24322;&#24120;&#20540;&#65292;&#31867;&#20284;&#20110; Huber &#27745;&#26579;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#25968;&#23398;&#20998;&#26512;&#21033;&#29992;&#20102;&#24658;&#23450;&#27493;&#38271;&#30340; SGD &#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#20197;&#29420;&#29305;&#30340;&#26041;&#24335;&#22788;&#29702;&#21098;&#20999;&#24341;&#20837;&#30340;&#20559;&#24046;&#12290;&#23545;&#20110;&#24378;&#20984;&#30446;&#26631;&#65292;&#25105;&#20204;&#35777;&#26126;&#36845;&#20195;&#25910;&#25947;&#21040;&#19968;&#20010;&#38598;&#20013;&#20998;&#24067;&#65292;&#24182;&#23548;&#20986;&#20102;&#26368;&#32456;&#20272;&#35745;&#35823;&#24046;&#30340;&#39640;&#27010;&#29575;&#30028;&#12290;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#26497;&#38480;&#20998;&#24067;&#23616;&#37096;&#21270;&#22312;&#20302;&#26799;&#24230;&#37051;&#22495;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28378;&#21160;&#20998;&#20301;&#25968;&#23454;&#29616;&#27492;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20248;&#21270;&#36807;&#31243;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a clipping strategy for Stochastic Gradient Descent (SGD) which uses quantiles of the gradient norm as clipping thresholds. We prove that this new strategy provides a robust and efficient optimization algorithm for smooth objectives (convex or non-convex), that tolerates heavy-tailed samples (including infinite variance) and a fraction of outliers in the data stream akin to Huber contamination. Our mathematical analysis leverages the connection between constant step size SGD and Markov chains and handles the bias introduced by clipping in an original way. For strongly convex objectives, we prove that the iteration converges to a concentrated distribution and derive high probability bounds on the final estimation error. In the non-convex case, we prove that the limit distribution is localized on a neighborhood with low gradient. We propose an implementation of this algorithm using rolling quantiles which leads to a highly efficient optimization procedure with strong robustn
&lt;/p&gt;</description></item><item><title>AR-TTA&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#36830;&#32493;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#12290;&#36890;&#36807;&#23558;&#20869;&#23384;&#32531;&#20914;&#21306;&#32435;&#20837;&#33258;&#35757;&#32451;&#26694;&#26550;&#65292;&#24182;&#26681;&#25454;&#25968;&#25454;&#27969;&#30340;&#24378;&#24230;&#36827;&#34892;&#21160;&#24577;&#36866;&#24212;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.10109</link><description>&lt;p&gt;
AR-TTA: &#19968;&#31181;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#36830;&#32493;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#30340;&#31616;&#21333;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
AR-TTA: A Simple Method for Real-World Continual Test-Time Adaptation. (arXiv:2309.10109v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10109
&lt;/p&gt;
&lt;p&gt;
AR-TTA&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#36830;&#32493;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#12290;&#36890;&#36807;&#23558;&#20869;&#23384;&#32531;&#20914;&#21306;&#32435;&#20837;&#33258;&#35757;&#32451;&#26694;&#26550;&#65292;&#24182;&#26681;&#25454;&#25968;&#25454;&#27969;&#30340;&#24378;&#24230;&#36827;&#34892;&#21160;&#24577;&#36866;&#24212;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#23427;&#20801;&#35768;&#28304;&#27169;&#22411;&#22312;&#27809;&#26377;&#20219;&#20309;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#36866;&#24212;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#22312;&#21482;&#26159;&#23454;&#38469;&#22330;&#26223;&#31616;&#21270;&#29256;&#26412;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#36827;&#34892;&#35780;&#20272;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#26368;&#36817;&#25512;&#20986;&#30340;&#33258;&#21160;&#39550;&#39542;&#25968;&#25454;&#38598;CLAD-C&#21644;SHIFT&#26469;&#39564;&#35777;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#26041;&#27861;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#24403;&#21069;&#30340;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#26041;&#27861;&#24448;&#24448;&#38590;&#20197;&#26377;&#25928;&#22788;&#29702;&#19981;&#21516;&#31243;&#24230;&#30340;&#22495;&#20559;&#31227;&#65292;&#24120;&#24120;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#65292;&#20302;&#20110;&#28304;&#27169;&#22411;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#38382;&#39064;&#30340;&#26681;&#28304;&#22312;&#20110;&#26080;&#27861;&#20445;&#30041;&#28304;&#27169;&#22411;&#30340;&#30693;&#35782;&#65292;&#24182;&#19988;&#26080;&#27861;&#36866;&#24212;&#21160;&#24577;&#21464;&#21270;&#12289;&#26102;&#38388;&#30456;&#20851;&#30340;&#25968;&#25454;&#27969;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#19968;&#20010;&#23567;&#30340;&#20869;&#23384;&#32531;&#20914;&#21306;&#32435;&#20837;&#21040;&#25104;&#29087;&#30340;&#33258;&#35757;&#32451;&#26694;&#26550;&#20013;&#65292;&#22686;&#21152;&#27169;&#22411;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#21516;&#26102;&#26681;&#25454;&#25968;&#25454;&#27969;&#30340;&#24378;&#24230;&#36827;&#34892;&#21160;&#24577;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Test-time adaptation is a promising research direction that allows the source model to adapt itself to changes in data distribution without any supervision. Yet, current methods are usually evaluated on benchmarks that are only a simplification of real-world scenarios. Hence, we propose to validate test-time adaptation methods using the recently introduced datasets for autonomous driving, namely CLAD-C and SHIFT. We observe that current test-time adaptation methods struggle to effectively handle varying degrees of domain shift, often resulting in degraded performance that falls below that of the source model. We noticed that the root of the problem lies in the inability to preserve the knowledge of the source model and adapt to dynamically changing, temporally correlated data streams. Therefore, we enhance well-established self-training framework by incorporating a small memory buffer to increase model stability and at the same time perform dynamic adaptation based on the intensity of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.07261</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21516;&#26102;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#20013;&#65292;&#24120;&#24120;&#36827;&#34892;&#25104;&#21315;&#19978;&#19975;&#20010;&#21516;&#26102;&#20551;&#35774;&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#24046;&#24322;&#34920;&#36798;&#30340;&#22522;&#22240;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#65292;&#35768;&#22810;&#26631;&#20934;&#32479;&#35745;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#22810;&#20803;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#12290;&#22312;&#20219;&#24847;&#28151;&#28102;&#26426;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#24182;&#23558;&#32447;&#24615;&#25237;&#24433;&#25972;&#21512;&#21040;&#19977;&#20010;&#20851;&#38190;&#38454;&#27573;&#20013;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#22810;&#20803;&#21709;&#24212;&#21464;&#37327;&#20998;&#31163;&#36793;&#38469;&#21644;&#19981;&#30456;&#20851;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#24674;&#22797;&#28151;&#28102;&#31995;&#25968;&#30340;&#21015;&#31354;&#38388;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;$\ell_1$&#27491;&#21017;&#21270;&#36827;&#34892;&#31232;&#30095;&#24615;&#20272;&#35745;&#65292;&#24182;&#24378;&#21152;&#27491;&#20132;&#24615;&#38480;&#21046;&#20110;&#28151;&#28102;&#31995;&#25968;&#65292;&#32852;&#21512;&#20272;&#35745;&#28508;&#22312;&#22240;&#23376;&#21644;&#20027;&#35201;&#25928;&#24212;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32467;&#21512;&#25237;&#24433;&#21644;&#21152;&#26435;&#20559;&#24046;&#26657;&#27491;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23454;&#35777;&#20102;&#22522;&#30784;&#27169;&#22411;&#24494;&#35843;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#29616;&#35937;&#65292;&#24494;&#35843;&#36807;&#31243;&#20013;&#36861;&#27714;&#19987;&#19994;&#24615;&#20250;&#23548;&#33268;&#27169;&#22411;&#30340;&#24191;&#27867;&#24615;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2309.06256</link><description>&lt;p&gt;
&#19987;&#19994;&#24615;&#19982;&#24191;&#27867;&#24615;&#65306;&#20851;&#20110;&#22522;&#30784;&#27169;&#22411;&#24494;&#35843;&#20013;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Speciality vs Generality: An Empirical Study on Catastrophic Forgetting in Fine-tuning Foundation Models. (arXiv:2309.06256v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23454;&#35777;&#20102;&#22522;&#30784;&#27169;&#22411;&#24494;&#35843;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#29616;&#35937;&#65292;&#24494;&#35843;&#36807;&#31243;&#20013;&#36861;&#27714;&#19987;&#19994;&#24615;&#20250;&#23548;&#33268;&#27169;&#22411;&#30340;&#24191;&#27867;&#24615;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#30784;&#27169;&#22411;&#65292;&#21253;&#25324;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;(VLMs)&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#20855;&#26377;&#22788;&#29702;&#22810;&#26679;&#20998;&#24067;&#21644;&#20219;&#21153;&#30340;&#24191;&#27867;&#24615;&#65292;&#36825;&#28304;&#20110;&#23427;&#20204;&#24191;&#27867;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#23545;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#26159;&#25552;&#39640;&#20219;&#21153;&#24615;&#33021;&#25110;&#35843;&#25972;&#27169;&#22411;&#34892;&#20026;&#19982;&#20154;&#31867;&#26399;&#26395;&#19968;&#33268;&#30340;&#24120;&#35265;&#20570;&#27861;&#65292;&#20351;&#20854;&#33719;&#24471;&#19987;&#19994;&#24615;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#24494;&#35843;&#30340;&#23567;&#22411;&#25968;&#25454;&#38598;&#21487;&#33021;&#26080;&#27861;&#20805;&#20998;&#35206;&#30422;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#36935;&#21040;&#30340;&#22810;&#26679;&#20998;&#24067;&#21644;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#36861;&#27714;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#19987;&#19994;&#24615;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#30340;&#24191;&#27867;&#24615;&#25439;&#22833;&#65292;&#36825;&#19982;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;(Catastrophic Forgetting, CF)&#30456;&#20851;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#22312;VLMs&#21644;LLMs&#20013;&#30340;&#23384;&#22312;&#12290;&#20363;&#22914;&#65292;&#23545;&#20687;CLIP&#36825;&#26679;&#30340;VLM&#36827;&#34892;&#22312;ImageNet&#19978;&#30340;&#24494;&#35843;&#20250;&#23548;&#33268;&#22788;&#29702;&#22810;&#26679;&#20998;&#24067;&#30340;&#24191;&#27867;&#24615;&#25439;&#22833;&#65292;&#23545;&#21307;&#23398;&#39046;&#22495;&#30340;Galactica&#36827;&#34892;&#24494;&#35843;&#21017;&#20250;&#23548;&#33268;&#36981;&#24490;&#25351;&#20196;&#30340;&#33021;&#21147;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation models, including Vision Language Models (VLMs) and Large Language Models (LLMs), possess the $generality$ to handle diverse distributions and tasks, which stems from their extensive pre-training datasets. The fine-tuning of foundation models is a common practice to enhance task performance or align the model's behavior with human expectations, allowing them to gain $speciality$. However, the small datasets used for fine-tuning may not adequately cover the diverse distributions and tasks encountered during pre-training. Consequently, the pursuit of speciality during fine-tuning can lead to a loss of {generality} in the model, which is related to catastrophic forgetting (CF) in deep learning. In this study, we demonstrate this phenomenon in both VLMs and LLMs. For instance, fine-tuning VLMs like CLIP on ImageNet results in a loss of generality in handling diverse distributions, and fine-tuning LLMs like Galactica in the medical domain leads to a loss in following instructions
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32431;&#31929;&#30340;&#28040;&#24687;&#20256;&#36882;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#20849;&#21516;&#37051;&#23621;&#36827;&#34892;&#38142;&#36335;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#36755;&#20837;&#21521;&#37327;&#30340;&#27491;&#20132;&#24615;&#26469;&#25429;&#25417;&#32852;&#21512;&#32467;&#26500;&#29305;&#24449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38142;&#36335;&#39044;&#27979;&#27169;&#22411;MPLP&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#20934;&#27491;&#20132;&#21521;&#37327;&#20272;&#35745;&#38142;&#36335;&#32423;&#32467;&#26500;&#29305;&#24449;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#33410;&#28857;&#32423;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.00976</link><description>&lt;p&gt;
&#32431;&#31929;&#30340;&#28040;&#24687;&#20256;&#36882;&#21487;&#20197;&#20272;&#35745;&#20849;&#21516;&#37051;&#23621;&#36827;&#34892;&#38142;&#36335;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Pure Message Passing Can Estimate Common Neighbor for Link Prediction. (arXiv:2309.00976v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00976
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32431;&#31929;&#30340;&#28040;&#24687;&#20256;&#36882;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#20849;&#21516;&#37051;&#23621;&#36827;&#34892;&#38142;&#36335;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#36755;&#20837;&#21521;&#37327;&#30340;&#27491;&#20132;&#24615;&#26469;&#25429;&#25417;&#32852;&#21512;&#32467;&#26500;&#29305;&#24449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38142;&#36335;&#39044;&#27979;&#27169;&#22411;MPLP&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#20934;&#27491;&#20132;&#21521;&#37327;&#20272;&#35745;&#38142;&#36335;&#32423;&#32467;&#26500;&#29305;&#24449;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#33410;&#28857;&#32423;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#24050;&#25104;&#20026;&#22270;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#20107;&#23454;&#26631;&#20934;&#12290;&#28982;&#32780;&#65292;&#22312;&#38142;&#36335;&#39044;&#27979;&#26041;&#38754;&#65292;&#23427;&#20204;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#65292;&#34987;&#31616;&#21333;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#22914;&#20849;&#21516;&#37051;&#23621;&#65288;CN&#65289;&#25152;&#36229;&#36234;&#12290;&#36825;&#31181;&#24046;&#24322;&#28304;&#20110;&#19968;&#20010;&#26681;&#26412;&#38480;&#21046;&#65306;&#23613;&#31649;MPNN&#22312;&#33410;&#28857;&#32423;&#34920;&#31034;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#32534;&#30721;&#38142;&#36335;&#39044;&#27979;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#32852;&#21512;&#32467;&#26500;&#29305;&#24449;&#65288;&#22914;CN&#65289;&#26041;&#38754;&#21017;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#35748;&#20026;&#36890;&#36807;&#21033;&#29992;&#36755;&#20837;&#21521;&#37327;&#30340;&#27491;&#20132;&#24615;&#65292;&#32431;&#31929;&#30340;&#28040;&#24687;&#20256;&#36882;&#30830;&#23454;&#21487;&#20197;&#25429;&#25417;&#21040;&#32852;&#21512;&#32467;&#26500;&#29305;&#24449;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;MPNN&#22312;&#36817;&#20284;CN&#21551;&#21457;&#24335;&#31639;&#27861;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38142;&#36335;&#39044;&#27979;&#27169;&#22411;&#8212;&#8212;&#28040;&#24687;&#20256;&#36882;&#38142;&#36335;&#39044;&#27979;&#22120;&#65288;MPLP&#65289;&#12290;MPLP&#21033;&#29992;&#20934;&#27491;&#20132;&#21521;&#37327;&#20272;&#35745;&#38142;&#36335;&#32423;&#32467;&#26500;&#29305;&#24449;&#65292;&#21516;&#26102;&#20445;&#30041;&#33410;&#28857;&#32423;&#22797;&#26434;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#26126;&#21033;&#29992;&#28040;&#24687;&#20256;&#36882;&#25429;&#25417;&#32467;&#26500;&#29305;&#24449;&#33021;&#22815;&#25913;&#21892;&#38142;&#36335;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto} standard in graph representation learning. However, when it comes to link prediction, they often struggle, surpassed by simple heuristics such as Common Neighbor (CN). This discrepancy stems from a fundamental limitation: while MPNNs excel in node-level representation, they stumble with encoding the joint structural features essential to link prediction, like CN. To bridge this gap, we posit that, by harnessing the orthogonality of input vectors, pure message-passing can indeed capture joint structural features. Specifically, we study the proficiency of MPNNs in approximating CN heuristics. Based on our findings, we introduce the Message Passing Link Predictor (MPLP), a novel link prediction model. MPLP taps into quasi-orthogonal vectors to estimate link-level structural features, all while preserving the node-level complexities. Moreover, our approach demonstrates that leveraging message-passing to capture stru
&lt;/p&gt;</description></item><item><title>Flamingo&#26159;&#19968;&#20010;&#29992;&#20110;&#23454;&#29616;&#36328;&#22823;&#37327;&#23458;&#25143;&#31471;&#23433;&#20840;&#32858;&#21512;&#30340;&#31995;&#32479;&#65292;&#22312;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#20013;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#28040;&#38500;&#27599;&#36718;&#35774;&#32622;&#21644;&#24341;&#20837;&#36731;&#37327;&#32423;&#30340;&#20002;&#22833;&#23481;&#24525;&#21327;&#35758;&#65292;Flamingo&#35299;&#20915;&#20102;&#20197;&#24448;&#21327;&#35758;&#22312;&#22810;&#36718;&#35774;&#32622;&#19979;&#30340;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#26412;&#22320;&#36873;&#25321;&#23458;&#25143;&#31471;&#37051;&#22495;&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2308.09883</link><description>&lt;p&gt;
Flamingo: &#22810;&#36718;&#21333;&#26381;&#21153;&#22120;&#23433;&#20840;&#32858;&#21512;&#21450;&#20854;&#22312;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning. (arXiv:2308.09883v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09883
&lt;/p&gt;
&lt;p&gt;
Flamingo&#26159;&#19968;&#20010;&#29992;&#20110;&#23454;&#29616;&#36328;&#22823;&#37327;&#23458;&#25143;&#31471;&#23433;&#20840;&#32858;&#21512;&#30340;&#31995;&#32479;&#65292;&#22312;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#20013;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#28040;&#38500;&#27599;&#36718;&#35774;&#32622;&#21644;&#24341;&#20837;&#36731;&#37327;&#32423;&#30340;&#20002;&#22833;&#23481;&#24525;&#21327;&#35758;&#65292;Flamingo&#35299;&#20915;&#20102;&#20197;&#24448;&#21327;&#35758;&#22312;&#22810;&#36718;&#35774;&#32622;&#19979;&#30340;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#26412;&#22320;&#36873;&#25321;&#23458;&#25143;&#31471;&#37051;&#22495;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Flamingo&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#36328;&#22823;&#37327;&#23458;&#25143;&#31471;&#23433;&#20840;&#32858;&#21512;&#25968;&#25454;&#30340;&#31995;&#32479;&#12290;&#22312;&#23433;&#20840;&#32858;&#21512;&#20013;&#65292;&#26381;&#21153;&#22120;&#23545;&#23458;&#25143;&#31471;&#30340;&#31169;&#26377;&#36755;&#20837;&#36827;&#34892;&#27714;&#21644;&#65292;&#24182;&#22312;&#19981;&#20102;&#35299;&#20010;&#20307;&#36755;&#20837;&#30340;&#24773;&#20917;&#19979;&#24471;&#21040;&#32467;&#26524;&#65292;&#20165;&#33021;&#25512;&#26029;&#20986;&#26368;&#32456;&#24635;&#21644;&#12290;Flamingo&#19987;&#27880;&#20110;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#22810;&#36718;&#35774;&#32622;&#65292;&#20854;&#20013;&#25191;&#34892;&#22810;&#20010;&#36830;&#32493;&#30340;&#27169;&#22411;&#26435;&#37325;&#27714;&#21644;&#65288;&#24179;&#22343;&#65289;&#65292;&#20197;&#24471;&#21040;&#19968;&#20010;&#33391;&#22909;&#30340;&#27169;&#22411;&#12290;&#20043;&#21069;&#30340;&#21327;&#35758;&#65288;&#20363;&#22914;Bell&#31561;&#20154;&#30340;CCS '20&#65289;&#20165;&#36866;&#29992;&#20110;&#21333;&#36718;&#65292;&#24182;&#36890;&#36807;&#22810;&#27425;&#37325;&#22797;&#35813;&#21327;&#35758;&#26469;&#36866;&#24212;&#32852;&#37030;&#23398;&#20064;&#30340;&#35774;&#32622;&#12290;Flamingo&#28040;&#38500;&#20102;&#20043;&#21069;&#21327;&#35758;&#27599;&#36718;&#35774;&#32622;&#30340;&#38656;&#27714;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#36731;&#37327;&#32423;&#30340;&#20002;&#22833;&#23481;&#24525;&#21327;&#35758;&#65292;&#20197;&#30830;&#20445;&#22914;&#26524;&#23458;&#25143;&#31471;&#22312;&#27714;&#21644;&#36807;&#31243;&#20013;&#31163;&#24320;&#65292;&#26381;&#21153;&#22120;&#20173;&#28982;&#21487;&#20197;&#33719;&#24471;&#26377;&#24847;&#20041;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;Flamingo&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26412;&#22320;&#36873;&#25321;&#25152;&#35859;&#30340;&#23458;&#25143;&#31471;&#37051;&#22495;&#30340;&#26041;&#24335;&#65292;&#27492;&#27010;&#24565;&#30001;Bell&#31561;&#20154;&#25552;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces Flamingo, a system for secure aggregation of data across a large set of clients. In secure aggregation, a server sums up the private inputs of clients and obtains the result without learning anything about the individual inputs beyond what is implied by the final sum. Flamingo focuses on the multi-round setting found in federated learning in which many consecutive summations (averages) of model weights are performed to derive a good model. Previous protocols, such as Bell et al. (CCS '20), have been designed for a single round and are adapted to the federated learning setting by repeating the protocol multiple times. Flamingo eliminates the need for the per-round setup of previous protocols, and has a new lightweight dropout resilience protocol to ensure that if clients leave in the middle of a sum the server can still obtain a meaningful result. Furthermore, Flamingo introduces a new way to locally choose the so-called client neighborhood introduced by Bell et al
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;Stackelberg&#21338;&#24328;&#20013;&#30340;&#20027;&#21160;&#36870;&#21521;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27963;&#36291;&#22320;&#26368;&#22823;&#21270;&#36319;&#38543;&#32773;&#22312;&#19981;&#21516;&#20551;&#35774;&#19979;&#30340;&#36712;&#36857;&#24046;&#24322;&#26469;&#21152;&#36895;&#39046;&#23548;&#32773;&#30340;&#25512;&#26029;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2308.08017</link><description>&lt;p&gt;
Stackelberg&#36712;&#36857;&#21338;&#24328;&#20013;&#30340;&#20027;&#21160;&#36870;&#21521;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active Inverse Learning in Stackelberg Trajectory Games. (arXiv:2308.08017v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08017
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;Stackelberg&#21338;&#24328;&#20013;&#30340;&#20027;&#21160;&#36870;&#21521;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27963;&#36291;&#22320;&#26368;&#22823;&#21270;&#36319;&#38543;&#32773;&#22312;&#19981;&#21516;&#20551;&#35774;&#19979;&#30340;&#36712;&#36857;&#24046;&#24322;&#26469;&#21152;&#36895;&#39046;&#23548;&#32773;&#30340;&#25512;&#26029;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21338;&#24328;&#35770;&#30340;&#36870;&#21521;&#23398;&#20064;&#26159;&#20174;&#29609;&#23478;&#30340;&#34892;&#20026;&#20013;&#25512;&#26029;&#20986;&#20182;&#20204;&#30340;&#30446;&#26631;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;Stackelberg&#21338;&#24328;&#20013;&#65292;&#36890;&#36807;&#27599;&#20010;&#29609;&#23478;&#30340;&#21160;&#24577;&#31995;&#32479;&#36712;&#36857;&#26469;&#23450;&#20041;&#19968;&#20010;&#36870;&#21521;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#39046;&#23548;&#32773;&#21644;&#19968;&#20010;&#36319;&#38543;&#32773;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#21160;&#36870;&#21521;&#23398;&#20064;&#26041;&#27861;&#65292;&#35753;&#39046;&#23548;&#32773;&#25512;&#26029;&#20986;&#19968;&#20010;&#26377;&#38480;&#20505;&#36873;&#38598;&#20013;&#25551;&#36848;&#36319;&#38543;&#32773;&#30446;&#26631;&#20989;&#25968;&#30340;&#20551;&#35774;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#34987;&#21160;&#35266;&#23519;&#21040;&#30340;&#36712;&#36857;&#19981;&#21516;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20027;&#21160;&#22320;&#26368;&#22823;&#21270;&#19981;&#21516;&#20551;&#35774;&#19979;&#36319;&#38543;&#32773;&#36712;&#36857;&#30340;&#24046;&#24322;&#65292;&#21152;&#36895;&#39046;&#23548;&#32773;&#30340;&#25512;&#26029;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#36882;&#36827;&#30340;&#37325;&#22797;&#36712;&#36857;&#21338;&#24328;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;&#19982;&#22343;&#21248;&#38543;&#26426;&#36755;&#20837;&#30456;&#27604;&#65292;&#25152;&#25552;&#20379;&#30340;&#26041;&#27861;&#21152;&#36895;&#20102;&#27010;&#29575;&#25910;&#25947;&#21040;&#26465;&#20214;&#20110;&#36319;&#38543;&#32773;&#36712;&#36857;&#30340;&#19981;&#21516;&#20551;&#35774;&#19978;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Game-theoretic inverse learning is the problem of inferring the players' objectives from their actions. We formulate an inverse learning problem in a Stackelberg game between a leader and a follower, where each player's action is the trajectory of a dynamical system. We propose an active inverse learning method for the leader to infer which hypothesis among a finite set of candidates describes the follower's objective function. Instead of using passively observed trajectories like existing methods, the proposed method actively maximizes the differences in the follower's trajectories under different hypotheses to accelerate the leader's inference. We demonstrate the proposed method in a receding-horizon repeated trajectory game. Compared with uniformly random inputs, the leader inputs provided by the proposed method accelerate the convergence of the probability of different hypotheses conditioned on the follower's trajectory by orders of magnitude.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.04428</link><description>&lt;p&gt;
&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#20803;&#23398;&#20064;&#25805;&#20316;&#31526;&#21040;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#36817;&#21462;&#24471;&#36827;&#23637;&#30340;&#19968;&#20010;&#24378;&#22823;&#27010;&#24565;&#26159;&#20174;&#24322;&#26500;&#26469;&#28304;&#25110;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20849;&#21516;&#29305;&#24449;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#23558;&#25152;&#26377;&#25968;&#25454;&#29992;&#20110;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#20989;&#25968;&#65292;&#26082;&#26377;&#21161;&#20110;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#26377;&#21161;&#20110;&#32479;&#35745;&#27867;&#21270;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20943;&#23569;&#35201;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20026;&#20102;&#22312;&#29702;&#35770;&#19978;&#20570;&#20986;&#36825;&#20123;&#20248;&#28857;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#22122;&#22768;&#21521;&#37327;&#27979;&#37327;$y = Mx + w$&#20013;&#22238;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;$M$&#30340;&#19968;&#33324;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21464;&#37327;$x$&#26082;&#21487;&#20197;&#26159;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20063;&#21487;&#20197;&#26159;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#36825;&#23548;&#33268;&#22122;&#22768;&#39033;&#30340;&#32553;&#25918;&#19981;&#20877;&#26377;&#21033;&#20110;&#28304;&#20219;&#21153;&#25968;&#37327;&#12290;&#36825;&#21453;&#36807;&#26469;&#20250;&#23548;&#33268;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21463;&#21040;&#21333;&#20219;&#21153;&#25968;&#25454;&#35268;&#27169;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp; Feature-Whiten}
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20998;&#21306;&#25193;&#25955;&#27169;&#22411;&#65288;CDM&#65289;&#35757;&#32451;&#19981;&#21516;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#22312;&#25512;&#26029;&#26102;&#20219;&#24847;&#32452;&#21512;&#23427;&#20204;&#65292;&#23454;&#29616;&#20102;&#35757;&#32451;&#25968;&#25454;&#20445;&#25252;&#21644;&#36873;&#25321;&#24615;&#36951;&#24536;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#35775;&#38382;&#26435;&#38480;&#25552;&#20379;&#23450;&#21046;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.01937</link><description>&lt;p&gt;
&#20351;&#29992;&#32452;&#21512;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#35757;&#32451;&#25968;&#25454;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
Training Data Protection with Compositional Diffusion Models. (arXiv:2308.01937v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01937
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20998;&#21306;&#25193;&#25955;&#27169;&#22411;&#65288;CDM&#65289;&#35757;&#32451;&#19981;&#21516;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#22312;&#25512;&#26029;&#26102;&#20219;&#24847;&#32452;&#21512;&#23427;&#20204;&#65292;&#23454;&#29616;&#20102;&#35757;&#32451;&#25968;&#25454;&#20445;&#25252;&#21644;&#36873;&#25321;&#24615;&#36951;&#24536;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#35775;&#38382;&#26435;&#38480;&#25552;&#20379;&#23450;&#21046;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#21306;&#25193;&#25955;&#27169;&#22411;&#65288;CDM&#65289;&#65292;&#19968;&#31181;&#22312;&#19981;&#21516;&#25968;&#25454;&#28304;&#19978;&#35757;&#32451;&#19981;&#21516;&#25193;&#25955;&#27169;&#22411;&#65288;&#25110;&#25552;&#31034;&#65289;&#24182;&#22312;&#25512;&#26029;&#26102;&#20219;&#24847;&#32452;&#21512;&#23427;&#20204;&#30340;&#26041;&#27861;&#12290;&#36825;&#20123;&#21333;&#29420;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#23396;&#31435;&#29366;&#24577;&#19979;&#12289;&#22312;&#19981;&#21516;&#26102;&#38388;&#12289;&#22312;&#19981;&#21516;&#20998;&#24067;&#21644;&#39046;&#22495;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#21487;&#20197;&#21518;&#32493;&#32452;&#21512;&#20197;&#36798;&#21040;&#19982;&#21516;&#26102;&#35757;&#32451;&#25152;&#26377;&#25968;&#25454;&#30340;&#29702;&#24819;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#27599;&#20010;&#27169;&#22411;&#21482;&#21253;&#21547;&#20854;&#22312;&#35757;&#32451;&#26399;&#38388;&#25509;&#35302;&#21040;&#30340;&#25968;&#25454;&#23376;&#38598;&#30340;&#20449;&#24687;&#65292;&#21487;&#20197;&#23454;&#29616;&#22810;&#31181;&#24418;&#24335;&#30340;&#35757;&#32451;&#25968;&#25454;&#20445;&#25252;&#12290;&#29305;&#21035;&#26159;&#65292;CDM&#26159;&#31532;&#19968;&#31181;&#21487;&#20197;&#23454;&#29616;&#22823;&#35268;&#27169;&#25193;&#25955;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#36951;&#24536;&#21644;&#25345;&#32493;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#20801;&#35768;&#26681;&#25454;&#29992;&#25143;&#35775;&#38382;&#26435;&#38480;&#25552;&#20379;&#23450;&#21046;&#27169;&#22411;&#12290;CDM&#36824;&#21487;&#20197;&#30830;&#23450;&#29983;&#25104;&#29305;&#23450;&#26679;&#26412;&#30340;&#25968;&#25454;&#23376;&#38598;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2307.15772</link><description>&lt;p&gt;
&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#19982;&#27973;&#23618;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Weighted variation spaces and approximation by shallow ReLU networks. (arXiv:2307.15772v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#937;&#8834;Rd&#19978;&#65292;&#36890;&#36807;&#23485;&#24230;&#20026;n&#30340;&#21333;&#38544;&#34255;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#26469;&#36924;&#36817;&#20989;&#25968;f&#30340;&#24773;&#20917;&#12290;&#36825;&#31181;&#38750;&#32447;&#24615;&#30340;n&#39033;&#23383;&#20856;&#36924;&#36817;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#22240;&#20026;&#23427;&#26159;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;(NNA)&#30340;&#26368;&#31616;&#21333;&#24773;&#20917;&#12290;&#23545;&#20110;&#36825;&#31181;NNA&#24418;&#24335;&#65292;&#26377;&#20960;&#20010;&#33879;&#21517;&#30340;&#36924;&#36817;&#32467;&#26524;&#65292;&#24341;&#20837;&#20102;&#22312;&#937;&#19978;&#30340;&#20989;&#25968;&#30340;&#26032;&#22411;&#27169;&#22411;&#31867;&#65292;&#20854;&#36924;&#36817;&#36895;&#29575;&#36991;&#20813;&#20102;&#32500;&#25968;&#28798;&#38590;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#21253;&#25324;Barron&#31867;&#21644;&#22522;&#20110;&#31232;&#30095;&#24615;&#25110;&#21464;&#24046;&#30340;&#31867;&#65292;&#20363;&#22914;Radon&#22495;BV&#31867;&#12290;&#26412;&#25991;&#20851;&#27880;&#20110;&#22312;&#22495;&#937;&#19978;&#23450;&#20041;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#12290;&#24403;&#21069;&#36825;&#20123;&#27169;&#22411;&#31867;&#30340;&#23450;&#20041;&#19981;&#20381;&#36182;&#20110;&#22495;&#937;&#12290;&#36890;&#36807;&#24341;&#20837;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#30340;&#27010;&#24565;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#22495;&#30340;&#26356;&#24688;&#24403;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the approximation of functions $f$ on a bounded domain $\Omega\subset \mathbb{R}^d$ by the outputs of single-hidden-layer ReLU neural networks of width $n$. This form of nonlinear $n$-term dictionary approximation has been intensely studied since it is the simplest case of neural network approximation (NNA). There are several celebrated approximation results for this form of NNA that introduce novel model classes of functions on $\Omega$ whose approximation rates avoid the curse of dimensionality. These novel classes include Barron classes, and classes based on sparsity or variation such as the Radon-domain BV classes.  The present paper is concerned with the definition of these novel model classes on domains $\Omega$. The current definition of these model classes does not depend on the domain $\Omega$. A new and more proper definition of model classes on domains is given by introducing the concept of weighted variation spaces. These new model classes are intrinsic to th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.10053</link><description>&lt;p&gt;
&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#21450;&#20854;&#21464;&#31181;&#22312;&#35757;&#32451;&#30001;&#38750;&#24179;&#28369;&#28608;&#27963;&#20989;&#25968;&#26500;&#24314;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20026;&#26356;&#26032;&#21160;&#37327;&#39033;&#21644;&#21464;&#37327;&#30340;&#27493;&#38271;&#20998;&#37197;&#20102;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#12290;&#22312;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#24456;&#22810;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#65292;&#21253;&#25324;heavy-ball SGD&#12289;SignSGD&#12289;Lion&#12289;normalized SGD&#21644;clipped SGD&#12290;&#27492;&#22806;&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#37319;&#29992;&#26377;&#38480;&#21644;&#24418;&#24335;&#26102;&#65292;&#25105;&#20204;&#22522;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#33021;&#22815;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26368;&#24120;&#35265;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#24615;&#33021;&#27979;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#24110;&#21161;&#20174;&#19994;&#32773;&#36873;&#25321;&#26368;&#36866;&#21512;&#20854;&#29305;&#23450;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.02694</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#24230;&#37327;&#26041;&#27861;&#65306;&#19968;&#39033;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Loss Functions and Metrics in Deep Learning. A Review. (arXiv:2307.02694v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26368;&#24120;&#35265;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#24615;&#33021;&#27979;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#24110;&#21161;&#20174;&#19994;&#32773;&#36873;&#25321;&#26368;&#36866;&#21512;&#20854;&#29305;&#23450;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#19968;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#26159;&#36873;&#25321;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#27169;&#22411;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#24615;&#33021;&#24230;&#37327;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26368;&#24120;&#35265;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#24615;&#33021;&#27979;&#37327;&#26041;&#27861;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#27599;&#31181;&#25216;&#26415;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#24182;&#20030;&#20363;&#35828;&#26126;&#23427;&#20204;&#22312;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#38382;&#39064;&#19978;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#30340;&#35780;&#35770;&#26088;&#22312;&#20840;&#38754;&#20102;&#35299;&#26368;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#30340;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#21644;&#24615;&#33021;&#25351;&#26631;&#65292;&#24182;&#24110;&#21161;&#20174;&#19994;&#32773;&#36873;&#25321;&#26368;&#36866;&#21512;&#20854;&#29305;&#23450;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#37319;&#26679;&#22120;&#30340;&#20219;&#21153;&#21644;&#21160;&#20316;&#35268;&#21010;&#26041;&#27861;&#65292;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#19979;&#33021;&#22815;&#23454;&#29616;&#38271;&#21608;&#26399;&#21463;&#32422;&#26463;&#30340;&#25805;&#20316;&#35745;&#21010;&#12290;</title><link>http://arxiv.org/abs/2306.13196</link><description>&lt;p&gt;
DiMSam:&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#37096;&#20998;&#21487;&#35266;&#27979;&#20219;&#21153;&#19982;&#21160;&#20316;&#35268;&#21010;&#20013;&#30340;&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability. (arXiv:2306.13196v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#37319;&#26679;&#22120;&#30340;&#20219;&#21153;&#21644;&#21160;&#20316;&#35268;&#21010;&#26041;&#27861;&#65292;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#19979;&#33021;&#22815;&#23454;&#29616;&#38271;&#21608;&#26399;&#21463;&#32422;&#26463;&#30340;&#25805;&#20316;&#35745;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20219;&#21153;&#21644;&#21160;&#20316;&#35268;&#21010;&#65288;TAMP&#65289;&#26041;&#27861;&#38750;&#24120;&#26377;&#25928;&#22320;&#35745;&#21010;&#38271;&#21608;&#26399;&#33258;&#20027;&#26426;&#22120;&#20154;&#25805;&#20316;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#23427;&#20204;&#38656;&#35201;&#19968;&#20010;&#35268;&#21010;&#27169;&#22411;&#65292;&#22240;&#27492;&#22312;&#29615;&#22659;&#21644;&#20854;&#21160;&#24577;&#19981;&#23436;&#20840;&#20102;&#35299;&#30340;&#39046;&#22495;&#20013;&#24212;&#29992;&#23427;&#20204;&#21487;&#33021;&#38750;&#24120;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#65292;&#29305;&#21035;&#26159;&#25193;&#25955;&#27169;&#22411;&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#23398;&#20064;&#25429;&#33719;&#35268;&#21010;&#27169;&#22411;&#20013;&#38590;&#20197;&#35774;&#35745;&#30340;&#32422;&#26463;&#21644;&#37319;&#26679;&#22120;&#12290;&#36825;&#20123;&#23398;&#20064;&#37319;&#26679;&#22120;&#22312;TAMP&#27714;&#35299;&#22120;&#20013;&#32452;&#21512;&#21644;&#21512;&#24182;&#65292;&#20197;&#32852;&#21512;&#25214;&#21040;&#28385;&#36275;&#35268;&#21010;&#20013;&#32422;&#26463;&#30340;&#34892;&#21160;&#21442;&#25968;&#20540;&#12290;&#20026;&#20102;&#20415;&#20110;&#23545;&#29615;&#22659;&#20013;&#26410;&#30693;&#23545;&#35937;&#36827;&#34892;&#39044;&#27979;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#37319;&#26679;&#22120;&#23450;&#20041;&#20026;&#23398;&#20064;&#30340;&#20302;&#32500;&#28508;&#21464;&#37327;&#23884;&#20837;&#30340;&#21487;&#21464;&#23545;&#35937;&#29366;&#24577;&#12290;&#25105;&#20204;&#22312;&#20851;&#33410;&#24335;&#29289;&#20307;&#25805;&#20316;&#39046;&#22495;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#32463;&#20856;TAMP&#12289;&#29983;&#25104;&#23398;&#20064;&#21644;&#28508;&#22312;&#23884;&#20837;&#30340;&#32452;&#21512;&#22914;&#20309;&#20351;&#24471;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#19979;&#36827;&#34892;&#38271;&#21608;&#26399;&#21463;&#32422;&#26463;&#30340;&#25805;&#20316;&#35745;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Task and Motion Planning (TAMP) approaches are effective at planning long-horizon autonomous robot manipulation. However, because they require a planning model, it can be difficult to apply them to domains where the environment and its dynamics are not fully known. We propose to overcome these limitations by leveraging deep generative modeling, specifically diffusion models, to learn constraints and samplers that capture these difficult-to-engineer aspects of the planning model. These learned samplers are composed and combined within a TAMP solver in order to find action parameter values jointly that satisfy the constraints along a plan. To tractably make predictions for unseen objects in the environment, we define these samplers on low-dimensional learned latent embeddings of changing object state. We evaluate our approach in an articulated object manipulation domain and show how the combination of classical TAMP, generative learning, and latent embeddings enables long-horizon constra
&lt;/p&gt;</description></item><item><title>DynaQuant&#36890;&#36807;&#21160;&#24577;&#37327;&#21270;&#23454;&#29616;&#23545;&#21508;&#31181;&#26368;&#20808;&#36827;&#27169;&#22411;&#30340;&#26174;&#30528;&#21387;&#32553;&#65292;&#20960;&#20046;&#19981;&#24433;&#21709;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11800</link><description>&lt;p&gt;
DynaQuant: &#36890;&#36807;&#21160;&#24577;&#37327;&#21270;&#21387;&#32553;&#28145;&#24230;&#23398;&#20064;&#35757;&#32451;&#26816;&#26597;&#28857;
&lt;/p&gt;
&lt;p&gt;
DynaQuant: Compressing Deep Learning Training Checkpoints via Dynamic Quantization. (arXiv:2306.11800v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11800
&lt;/p&gt;
&lt;p&gt;
DynaQuant&#36890;&#36807;&#21160;&#24577;&#37327;&#21270;&#23454;&#29616;&#23545;&#21508;&#31181;&#26368;&#20808;&#36827;&#27169;&#22411;&#30340;&#26174;&#30528;&#21387;&#32553;&#65292;&#20960;&#20046;&#19981;&#24433;&#21709;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#35757;&#32451;&#24037;&#20316;&#37327;&#22312;&#35745;&#31639;&#36164;&#28304;&#21644;&#26102;&#38388;&#28040;&#32791;&#26041;&#38754;&#30340;&#22686;&#21152;&#65292;&#36935;&#21040;&#35757;&#32451;&#22833;&#36133;&#30340;&#21487;&#33021;&#24615;&#26174;&#33879;&#22686;&#21152;&#65292;&#23548;&#33268;&#24037;&#20316;&#20002;&#22833;&#21644;&#36164;&#28304;&#28010;&#36153;&#12290;&#26368;&#26032;&#30340;&#26041;&#27861;&#28041;&#21450;&#26377;&#25439;&#27169;&#22411;&#21387;&#32553;&#26426;&#21046;&#65292;&#36825;&#20250;&#22312;&#27169;&#22411;&#36136;&#37327;&#65288;&#20934;&#30830;&#24615;&#65289;&#21644;&#21387;&#32553;&#27604;&#20043;&#38388;&#20135;&#29983;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#21160;&#24577;&#37327;&#21270;&#26694;&#26550;&#65292;&#31216;&#20026;DynaQuant&#65292;&#23427;&#21487;&#20197;&#26681;&#25454;&#35757;&#32451;&#26399;&#38388;&#27169;&#22411;&#26435;&#37325;&#30340;&#28789;&#25935;&#24230;&#21464;&#21270;&#26469;&#26356;&#26032;&#37327;&#21270;&#32423;&#21035;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#21508;&#31181;&#26368;&#20808;&#36827;&#27169;&#22411;&#30340;&#26174;&#30528;&#21387;&#32553;&#65292;&#24182;&#19988;&#20960;&#20046;&#19981;&#24433;&#21709;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increase in the scale of Deep Learning (DL) training workloads in terms of compute resources and time consumption, the likelihood of encountering in-training failures rises substantially, leading to lost work and resource wastage. Such failures are typically offset by a checkpointing mechanism, which comes at the cost of storage and network bandwidth overhead. State-of-the-art approaches involve lossy model compression mechanisms, which induce a tradeoff between the resulting model quality (accuracy) and compression ratio. Delta compression is then also used to further reduce the overhead by only storing the difference between consecutive checkpoints. We make a key enabling observation that the sensitivity of model weights to compression varies during training, and different weights benefit from different quantization levels (ranging from retaining full precision to pruning). We propose (1) a non-uniform quantization scheme that leverages this variation, (2) an efficient searc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24490;&#29615;&#35760;&#24518;&#20915;&#31574;&#21464;&#21387;&#22120;&#65288;RMDT&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38271;&#24207;&#21015;&#38382;&#39064;&#12290;&#22312;Atari&#28216;&#25103;&#21644;MoJoCo&#25511;&#21046;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#37319;&#29992;&#24490;&#29615;&#35760;&#24518;&#26426;&#21046;&#30340;RMDT&#27169;&#22411;&#26174;&#30528;&#20248;&#20110;&#20854;&#27809;&#26377;&#24490;&#29615;&#35760;&#24518;&#26426;&#21046;&#30340;&#23545;&#24212;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.09459</link><description>&lt;p&gt;
&#24490;&#29615;&#35760;&#24518;&#20915;&#31574;&#21464;&#21387;&#22120;
&lt;/p&gt;
&lt;p&gt;
Recurrent Memory Decision Transformer. (arXiv:2306.09459v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24490;&#29615;&#35760;&#24518;&#20915;&#31574;&#21464;&#21387;&#22120;&#65288;RMDT&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38271;&#24207;&#21015;&#38382;&#39064;&#12290;&#22312;Atari&#28216;&#25103;&#21644;MoJoCo&#25511;&#21046;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#37319;&#29992;&#24490;&#29615;&#35760;&#24518;&#26426;&#21046;&#30340;RMDT&#27169;&#22411;&#26174;&#30528;&#20248;&#20110;&#20854;&#27809;&#26377;&#24490;&#29615;&#35760;&#24518;&#26426;&#21046;&#30340;&#23545;&#24212;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#38761;&#24615;&#27169;&#22411;&#26368;&#21021;&#26159;&#20026;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#32780;&#24320;&#21457;&#30340;&#65292;&#26368;&#36817;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#36825;&#26159;&#22240;&#20026;&#20195;&#29702;&#30340;&#21382;&#21490;&#21487;&#20197;&#34920;&#31034;&#20026;&#24207;&#21015;&#65292;&#24182;&#19988;&#25972;&#20010;&#20219;&#21153;&#21487;&#20197;&#32553;&#20943;&#20026;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#21464;&#21387;&#22120;&#25805;&#20316;&#30340;&#20108;&#27425;&#22797;&#26434;&#24615;&#38480;&#21046;&#20102;&#19978;&#19979;&#25991;&#30340;&#28508;&#22312;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#20013;&#22788;&#29702;&#38271;&#24207;&#21015;&#65292;&#20351;&#29992;&#20102;&#19981;&#21516;&#29256;&#26412;&#30340;&#35760;&#24518;&#26426;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24490;&#29615;&#35760;&#24518;&#20915;&#31574;&#21464;&#21387;&#22120;&#65288;RMDT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#20013;&#20351;&#29992;&#24490;&#29615;&#35760;&#24518;&#26426;&#21046;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;Atari&#28216;&#25103;&#21644;MoJoCo&#25511;&#21046;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#23454;&#39564;&#65292;&#24182;&#34920;&#26126;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;Atari&#28216;&#25103;&#19978;&#26174;&#30528;&#20248;&#20110;&#27809;&#26377;&#24490;&#29615;&#35760;&#24518;&#26426;&#21046;&#30340;&#23545;&#24212;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#20180;&#32454;&#30740;&#31350;&#20102;&#35760;&#24518;&#23545;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#32489;&#25928;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#24320;&#21457;&#26356;&#39640;&#25928;&#21644;&#26356;&#26377;&#25928;&#30340;&#22788;&#29702;&#38271;&#24207;&#21015;&#30340;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformative models, originally developed for natural language problems, have recently been widely used in offline reinforcement learning tasks. This is due to the fact that the agent's history can be represented as a sequence, and the whole task can be reduced to the sequence modeling task. However, the quadratic complexity of the transformer operation limits the potential increase in context. Therefore, to work with long sequences in a natural language, different versions of the memory mechanism are used. In this paper, we propose the Recurrent Memory Decision Transformer (RMDT), a model that uses a recurrent memory mechanism for reinforcement learning problems. We conduct thorough experiments on Atari games and MoJoCo control problems, and show that our proposed model is significantly superior to its counterparts without the recurrent memory mechanism on Atari games. We also carefully study the effect of memory on the performance of the proposed model. These findings shed light on
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#36890;&#36807;&#20998;&#24067;&#20581;&#22766;&#20248;&#21270;&#21644;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#26799;&#24230;&#19979;&#38477;&#25216;&#26415;&#25552;&#21319;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.09222</link><description>&lt;p&gt;
&#38543;&#26426;&#21152;&#26435;&#26799;&#24230;&#19979;&#38477;&#36890;&#36807;&#20998;&#24067;&#20581;&#22766;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization. (arXiv:2306.09222v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09222
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20998;&#24067;&#20581;&#22766;&#20248;&#21270;&#21644;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#26799;&#24230;&#19979;&#38477;&#25216;&#26415;&#25552;&#21319;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#22312;&#27599;&#19968;&#27425;&#20248;&#21270;&#27493;&#39588;&#20013;&#23545;&#25968;&#25454;&#28857;&#36827;&#34892;&#37325;&#35201;&#24615;&#21152;&#26435;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#30340;&#21152;&#26435;&#26799;&#24230;&#19979;&#38477;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21463;&#21040;&#20998;&#24067;&#20581;&#22766;&#20248;&#21270;&#21644;f-&#25955;&#24230;&#30340;&#21551;&#21457;&#65292;&#24050;&#30693;&#21487;&#20197;&#24471;&#21040;&#20855;&#26377;&#25913;&#36827;&#30340;&#27867;&#21270;&#20445;&#35777;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#21152;&#26435;&#26041;&#26696;&#31616;&#21333;&#12289;&#35745;&#31639;&#39640;&#25928;&#65292;&#21487;&#20197;&#19982;&#35768;&#22810;&#27969;&#34892;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;SGD&#21644;Adam&#65289;&#32467;&#21512;&#20351;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#37117;&#34920;&#29616;&#20986;&#20102;&#20248;&#36234;&#24615;&#33021;&#65292;&#21253;&#25324;&#30417;&#30563;&#23398;&#20064;&#21644;&#39046;&#22495;&#36866;&#24212;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;DomainBed&#21644;Tabular&#20998;&#31867;&#22522;&#20934;&#19978;&#20998;&#21035;&#27604;&#29616;&#26377;&#26368;&#20339;&#32467;&#26524;&#25552;&#21319;&#20102;0.7%&#21644;1.44%&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#23558;BERT&#22312;GLUE&#22522;&#20934;&#19978;&#30340;&#24615;&#33021;&#25552;&#21319;&#20102;1.94%&#65292;&#23558;ViT&#22312;ImageNet-1K&#19978;&#30340;&#24615;&#33021;&#25552;&#21319;&#20102;1.01%&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#39044;&#31034;&#30528;&#23427;&#22312;&#25913;&#21892;&#24615;&#33021;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a re-weighted gradient descent technique for boosting the performance of deep neural networks, which involves importance weighting of data points during each optimization step. Our approach is inspired by distributionally robust optimization with f-divergences, which has been known to result in models with improved generalization guarantees. Our re-weighting scheme is simple, computationally efficient, and can be combined with many popular optimization algorithms such as SGD and Adam. Empirically, we demonstrate the superiority of our approach on various tasks, including supervised learning, domain adaptation. Notably, we obtain improvements of +0.7% and +1.44% over SOTA on DomainBed and Tabular classification benchmarks, respectively. Moreover, our algorithm boosts the performance of BERT on GLUE benchmarks by +1.94%, and ViT on ImageNet-1K by +1.01%. These results demonstrate the effectiveness of the proposed approach, indicating its potential for improving performance in 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28145;&#24230;Q&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21098;&#26525;&#21160;&#20316;&#38598;&#26469;&#23454;&#29616;&#23558;&#20013;&#38388;&#29983;&#29289;&#26631;&#24535;&#29289;&#20449;&#21495;&#25972;&#21512;&#21040;&#22870;&#21169;&#35268;&#33539;&#20013;&#65292;&#25552;&#39640;&#20102;&#37325;&#30151;&#25252;&#29702;&#31574;&#30053;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08044</link><description>&lt;p&gt;
&#21098;&#26525;&#26041;&#24335;&#25552;&#39640;&#21487;&#38752;&#31574;&#30053;&#65306;&#19968;&#31181;&#22810;&#30446;&#26631;&#28145;&#24230;Q&#23398;&#20064;&#26041;&#27861;&#24212;&#29992;&#20110;&#37325;&#30151;&#25252;&#29702;
&lt;/p&gt;
&lt;p&gt;
Pruning the Way to Reliable Policies: A Multi-Objective Deep Q-Learning Approach to Critical Care. (arXiv:2306.08044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08044
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28145;&#24230;Q&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21098;&#26525;&#21160;&#20316;&#38598;&#26469;&#23454;&#29616;&#23558;&#20013;&#38388;&#29983;&#29289;&#26631;&#24535;&#29289;&#20449;&#21495;&#25972;&#21512;&#21040;&#22870;&#21169;&#35268;&#33539;&#20013;&#65292;&#25552;&#39640;&#20102;&#37325;&#30151;&#25252;&#29702;&#31574;&#30053;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#21307;&#30103;&#20915;&#31574;&#20855;&#26377;&#36830;&#32493;&#24615;&#65292;&#22240;&#27492;&#65292;&#24378;&#21270;&#23398;&#20064;&#21487;&#33021;&#26377;&#26395;&#21046;&#23450;&#31934;&#30830;&#30340;&#25968;&#25454;&#39537;&#21160;&#27835;&#30103;&#35745;&#21010;&#12290;&#28982;&#32780;&#65292;&#35813;&#39046;&#22495;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#20027;&#35201;&#22522;&#20110;&#27515;&#20129;&#29575;&#30340;&#22870;&#21169;&#20989;&#25968;&#30340;&#31232;&#30095;&#24615;&#65292;&#23548;&#33268;&#31163;&#32447;&#20272;&#35745;&#30340;&#31283;&#23450;&#24615;&#38477;&#20302;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#28145;&#24230;Q&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#33719;&#24471;&#26356;&#21487;&#38752;&#30340;&#37325;&#30151;&#25252;&#29702;&#31574;&#30053;&#12290;&#35813;&#26041;&#27861;&#23558;&#30456;&#20851;&#20294;&#22024;&#26434;&#30340;&#20013;&#38388;&#29983;&#29289;&#26631;&#24535;&#29289;&#20449;&#21495;&#25972;&#21512;&#21040;&#22870;&#21169;&#35268;&#33539;&#20013;&#65292;&#21516;&#26102;&#19981;&#20250;&#25439;&#23475;&#24863;&#20852;&#36259;&#30340;&#20027;&#35201;&#32467;&#26524;&#65288;&#20363;&#22914;&#24739;&#32773;&#29983;&#23384;&#29575;&#65289;&#30340;&#20248;&#21270;&#12290;&#36890;&#36807;&#26681;&#25454;&#25152;&#26377;&#21487;&#29992;&#22870;&#21169;&#23545;&#21160;&#20316;&#38598;&#36827;&#34892;&#21098;&#26525;&#65292;&#28982;&#21518;&#22522;&#20110;&#31232;&#30095;&#20027;&#35201;&#22870;&#21169;&#65292;&#20351;&#29992;&#21463;&#38480;&#21160;&#20316;&#38598;&#36827;&#34892;&#26368;&#32456;&#27169;&#22411;&#35757;&#32451;&#65292;&#36890;&#36807;&#35299;&#31163;&#20934;&#30830;&#21644;&#36817;&#20284;&#22870;&#21169;&#26469;&#26368;&#23567;&#21270;&#20027;&#35201;&#30446;&#26631;&#30340;&#28508;&#22312;&#25197;&#26354;&#65292;&#23454;&#29616;&#20102;&#19978;&#36848;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most medical treatment decisions are sequential in nature. Hence, there is substantial hope that reinforcement learning may make it possible to formulate precise data-driven treatment plans. However, a key challenge for most applications in this field is the sparse nature of primarily mortality-based reward functions, leading to decreased stability of offline estimates. In this work, we introduce a deep Q-learning approach able to obtain more reliable critical care policies. This method integrates relevant but noisy intermediate biomarker signals into the reward specification, without compromising the optimization of the main outcome of interest (e.g. patient survival). We achieve this by first pruning the action set based on all available rewards, and second training a final model based on the sparse main reward but with a restricted action set. By disentangling accurate and approximated rewards through action pruning, potential distortions of the main objective are minimized, all whi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;MuZero&#31639;&#27861;&#65292;&#21457;&#29616;&#23427;&#23398;&#20064;&#21040;&#30340;&#27169;&#22411;&#26080;&#27861;&#26377;&#25928;&#25512;&#24191;&#21040;&#35780;&#20272;&#26410;&#35265;&#31574;&#30053;&#65292;&#38480;&#21046;&#20102;&#20854;&#23545;&#24403;&#21069;&#31574;&#30053;&#30340;&#36827;&#19968;&#27493;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2306.00840</link><description>&lt;p&gt;
MuZero&#23398;&#21040;&#20102;&#20160;&#20040;&#27169;&#22411;&#65311;
&lt;/p&gt;
&lt;p&gt;
What model does MuZero learn?. (arXiv:2306.00840v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00840
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;MuZero&#31639;&#27861;&#65292;&#21457;&#29616;&#23427;&#23398;&#20064;&#21040;&#30340;&#27169;&#22411;&#26080;&#27861;&#26377;&#25928;&#25512;&#24191;&#21040;&#35780;&#20272;&#26410;&#35265;&#31574;&#30053;&#65292;&#38480;&#21046;&#20102;&#20854;&#23545;&#24403;&#21069;&#31574;&#30053;&#30340;&#36827;&#19968;&#27493;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#26377;&#26395;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#24403;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26102;&#65292;&#26377;&#21487;&#33021;&#20174;&#22797;&#26434;&#30340;&#20256;&#24863;&#22120;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#32039;&#20945;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#23398;&#20064;&#21040;&#30340;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#65292;&#29305;&#21035;&#26159;&#23427;&#20204;&#35268;&#21010;&#33021;&#21147;&#30340;&#25552;&#21319;&#24403;&#21069;&#31574;&#30053;&#30340;&#33021;&#21147;&#65292;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;MuZero&#36825;&#20010;&#33879;&#21517;&#30340;&#22522;&#20110;&#28145;&#24230;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#22312;&#23454;&#29616;&#20540;&#31561;&#20215;&#27169;&#22411;&#30340;&#23398;&#20064;&#30446;&#26631;&#19978;&#30340;&#25104;&#23601;&#20197;&#21450;&#23398;&#20064;&#21040;&#30340;&#27169;&#22411;&#23545;&#31574;&#30053;&#25913;&#36827;&#30340;&#23454;&#29992;&#24615;&#12290;&#22312;&#35832;&#22810;&#20854;&#20182;&#35266;&#28857;&#20013;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65306;MuZero&#23398;&#21040;&#30340;&#27169;&#22411;&#26080;&#27861;&#26377;&#25928;&#22320;&#25512;&#24191;&#21040;&#35780;&#20272;&#26410;&#35265;&#31574;&#30053;&#65292;&#36825;&#38480;&#21046;&#20102;&#25105;&#20204;&#36890;&#36807;&#27169;&#22411;&#35268;&#21010;&#26469;&#36827;&#19968;&#27493;&#25913;&#36827;&#24403;&#21069;&#31574;&#30053;&#30340;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based reinforcement learning has drawn considerable interest in recent years, given its promise to improve sample efficiency. Moreover, when using deep-learned models, it is potentially possible to learn compact models from complex sensor data. However, the effectiveness of these learned models, particularly their capacity to plan, i.e., to improve the current policy, remains unclear. In this work, we study MuZero, a well-known deep model-based reinforcement learning algorithm, and explore how far it achieves its learning objective of a value-equivalent model and how useful the learned models are for policy improvement. Amongst various other insights, we conclude that the model learned by MuZero cannot effectively generalize to evaluate unseen policies, which limits the extent to which we can additionally improve the current policy by planning with the model.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2305.19059</link><description>&lt;p&gt;
&#35757;&#32451;&#26399;&#38388;&#30340;&#33258;&#36866;&#24212;&#31209;&#35889;&#21098;&#26525;&#21367;&#31215;&#23618;
&lt;/p&gt;
&lt;p&gt;
Rank-adaptive spectral pruning of convolutional layers during training. (arXiv:2305.19059v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#26041;&#38754;&#22686;&#38271;&#36805;&#36895;&#65292;&#22240;&#27492;&#24050;&#32463;&#21457;&#23637;&#20102;&#21508;&#31181;&#21098;&#26525;&#25216;&#26415;&#20197;&#20943;&#23569;&#27169;&#22411;&#21442;&#25968;&#12290;&#22823;&#22810;&#25968;&#25216;&#26415;&#20391;&#37325;&#20110;&#36890;&#36807;&#22312;&#23436;&#25972;&#35757;&#32451;&#21518;&#23545;&#32593;&#32476;&#36827;&#34892;&#20462;&#21098;&#20197;&#20943;&#23569;&#25512;&#29702;&#25104;&#26412;&#12290;&#23569;&#37327;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#20943;&#23569;&#35757;&#32451;&#25104;&#26412;&#30340;&#38382;&#39064;&#65292;&#20027;&#35201;&#26159;&#36890;&#36807;&#20302;&#31209;&#23618;&#20998;&#35299;&#26469;&#21387;&#32553;&#32593;&#32476;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#32447;&#24615;&#23618;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#26159;&#23427;&#20204;&#26080;&#27861;&#26377;&#25928;&#22788;&#29702;&#21367;&#31215;&#28388;&#27874;&#22120;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#12290;&#21033;&#29992;&#24494;&#20998;&#26041;&#31243;&#22312;&#24352;&#37327;&#27969;&#24418;&#19978;&#30340;&#20960;&#20309;&#31215;&#20998;&#29702;&#35770;&#30340;&#22522;&#26412;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#35777;&#26126;&#33021;&#22815;&#36924;&#36817;&#23436;&#25972;&#30340;&#22522;&#32447;&#24615;&#33021;&#24182;&#20445;&#35777;&#25439;&#22833;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
The computing cost and memory demand of deep learning pipelines have grown fast in recent years and thus a variety of pruning techniques have been developed to reduce model parameters. The majority of these techniques focus on reducing inference costs by pruning the network after a pass of full training. A smaller number of methods address the reduction of training costs, mostly based on compressing the network via low-rank layer factorizations. Despite their efficiency for linear layers, these methods fail to effectively handle convolutional filters. In this work, we propose a low-parametric training method that factorizes the convolutions into tensor Tucker format and adaptively prunes the Tucker ranks of the convolutional kernel during training. Leveraging fundamental results from geometric integration theory of differential equations on tensor manifolds, we obtain a robust training algorithm that provably approximates the full baseline performance and guarantees loss descent. A var
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21333;&#38454;&#27573;&#29305;&#26435;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65288;HIB&#65289;&#65292;&#36890;&#36807;&#25429;&#25417;&#21382;&#21490;&#36712;&#36857;&#30340;&#29305;&#26435;&#30693;&#35782;&#34920;&#31034;&#26469;&#23398;&#20064;&#65292;&#32553;&#23567;&#27169;&#25311;&#21644;&#30495;&#23454;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2305.18464</link><description>&lt;p&gt;
&#29305;&#26435;&#30693;&#35782;&#33976;&#39311;&#29992;&#20110; Sim-to-Real &#31574;&#30053;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Privileged Knowledge Distillation for Sim-to-Real Policy Generalization. (arXiv:2305.18464v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18464
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21333;&#38454;&#27573;&#29305;&#26435;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65288;HIB&#65289;&#65292;&#36890;&#36807;&#25429;&#25417;&#21382;&#21490;&#36712;&#36857;&#30340;&#29305;&#26435;&#30693;&#35782;&#34920;&#31034;&#26469;&#23398;&#20064;&#65292;&#32553;&#23567;&#27169;&#25311;&#21644;&#30495;&#23454;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#26368;&#36817;&#22312;&#26426;&#22120;&#20154;&#25511;&#21046;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#22810;&#25968;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#27169;&#25311;&#29615;&#22659;&#20013;&#36816;&#34892;&#65292;&#37027;&#37324;&#30340;&#29305;&#26435;&#30693;&#35782;&#65288;&#20363;&#22914;&#21160;&#21147;&#23398;&#65292;&#29615;&#22659;&#65292;&#22320;&#24418;&#65289;&#26159;&#36731;&#26494;&#33719;&#21462;&#30340;&#12290;&#30456;&#21453;&#65292;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#65292;&#26426;&#22120;&#20154;&#20195;&#29702;&#36890;&#24120;&#20165;&#20381;&#36182;&#20110;&#26412;&#22320;&#29366;&#24577;&#65288;&#20363;&#22914;&#26426;&#22120;&#20154;&#20851;&#33410;&#30340;&#26412;&#20307;&#24863;&#21453;&#39304;&#65289;&#26469;&#36873;&#25321;&#21160;&#20316;&#65292;&#23548;&#33268;&#26174;&#33879;&#30340;&#27169;&#25311;&#21040;&#30495;&#23454;&#30340;&#24046;&#36317;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#36880;&#28176;&#20943;&#23569;&#23545;&#29305;&#26435;&#30693;&#35782;&#30340;&#20381;&#36182;&#25110;&#25191;&#34892;&#20004;&#38454;&#27573;&#31574;&#30053;&#27169;&#20223;&#26469;&#35299;&#20915;&#36825;&#20010;&#24046;&#36317;&#12290;&#20294;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20805;&#20998;&#21033;&#29992;&#29305;&#26435;&#30693;&#35782;&#30340;&#33021;&#21147;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#23548;&#33268;&#24615;&#33021;&#27425;&#20248;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21382;&#21490;&#20449;&#24687;&#29942;&#39048;&#65288;HIB&#65289;&#30340;&#26032;&#22411;&#21333;&#38454;&#27573;&#29305;&#26435;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65292;&#20197;&#32553;&#23567;&#27169;&#25311;&#21040;&#30495;&#23454;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;HIB&#36890;&#36807;&#25429;&#25417;&#21382;&#21490;&#36712;&#36857;&#30340;&#29305;&#26435;&#30693;&#35782;&#34920;&#31034;&#26469;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning (RL) has recently achieved remarkable success in robotic control. However, most RL methods operate in simulated environments where privileged knowledge (e.g., dynamics, surroundings, terrains) is readily available. Conversely, in real-world scenarios, robot agents usually rely solely on local states (e.g., proprioceptive feedback of robot joints) to select actions, leading to a significant sim-to-real gap. Existing methods address this gap by either gradually reducing the reliance on privileged knowledge or performing a two-stage policy imitation. However, we argue that these methods are limited in their ability to fully leverage the privileged knowledge, resulting in suboptimal performance. In this paper, we propose a novel single-stage privileged knowledge distillation method called the Historical Information Bottleneck (HIB) to narrow the sim-to-real gap. In particular, HIB learns a privileged knowledge representation from historical trajectories by capturing 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15912</link><description>&lt;p&gt;
&#25913;&#36827;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#30340;&#31070;&#32463;&#29305;&#24449;&#28608;&#27963;&#20540;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning. (arXiv:2305.15912v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#21333;&#20010;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#12290;&#25105;&#20204;&#23558;ReLU&#21333;&#20803;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#23545;&#24212;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#31216;&#20026;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#38598;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#29305;&#24449;&#28608;&#27963;&#38598;&#19982;ReLU&#32593;&#32476;&#20013;&#23398;&#20064;&#29305;&#24449;&#20043;&#38388;&#30340;&#26126;&#30830;&#32852;&#31995;&#65292;&#24182;&#25581;&#31034;&#20102;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#20351;&#29992;&#30340;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#35268;&#33539;&#21270;&#25216;&#26415;&#22914;&#20309;&#35268;&#33539;&#21270;&#21644;&#31283;&#23450;SGD&#20248;&#21270;&#12290;&#21033;&#29992;&#36825;&#20123;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20960;&#20309;&#26041;&#27861;&#26469;&#21442;&#25968;&#21270;ReLU&#32593;&#32476;&#20197;&#25913;&#36827;&#29305;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#20102;&#20854;&#26377;&#29992;&#24615;&#65292;&#20351;&#29992;&#20102;&#19981;&#37027;&#20040;&#31934;&#24515;&#36873;&#25321;&#30340;&#21021;&#22987;&#21270;&#26041;&#26696;&#21644;&#26356;&#22823;&#30340;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#26356;&#22909;&#30340;&#20248;&#21270;&#31283;&#23450;&#24615;&#65292;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the characteristic activation values of individual ReLU units in neural networks. We refer to the corresponding set for such characteristic activation values in the input space as the characteristic activation set of a ReLU unit. We draw an explicit connection between the characteristic activation set and learned features in ReLU networks. This connection leads to new insights into why various neural network normalization techniques used in modern deep learning architectures regularize and stabilize SGD optimization. Utilizing these insights, we propose a geometric approach to parameterize ReLU networks for improved feature learning. We empirically verify its usefulness with less carefully chosen initialization schemes and larger learning rates. We report improved optimization stability, faster convergence speed, and better generalization performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#35299;&#20915;&#35299;&#32806;&#24335;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#30340;&#23545;&#31216;&#24615;&#38480;&#21046;&#21644;&#24341;&#20837;&#20840;&#23616;&#20449;&#24687;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#22312;CIFAR-10/100&#21644;ImageNet&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#22312;&#23545;&#25239;&#35757;&#32451;&#21644;&#30693;&#35782;&#33976;&#39311;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.13948</link><description>&lt;p&gt;
&#35299;&#32806;&#24335;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Decoupled Kullback-Leibler Divergence Loss. (arXiv:2305.13948v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#35299;&#20915;&#35299;&#32806;&#24335;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#30340;&#23545;&#31216;&#24615;&#38480;&#21046;&#21644;&#24341;&#20837;&#20840;&#23616;&#20449;&#24687;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#22312;CIFAR-10/100&#21644;ImageNet&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#22312;&#23545;&#25239;&#35757;&#32451;&#21644;&#30693;&#35782;&#33976;&#39311;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26356;&#28145;&#20837;&#22320;&#25506;&#31350;&#20102;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#21457;&#29616;&#23427;&#19982;&#35299;&#32806;&#24335;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#31561;&#20215;&#65292;&#21518;&#32773;&#30001;&#21152;&#26435;&#22343;&#26041;&#24046;&#25439;&#22833;&#21644;&#21253;&#21547;&#36719;&#26631;&#31614;&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#32452;&#25104;&#12290;&#36890;&#36807;&#23545;&#35299;&#32806;&#24335;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#30340;&#20998;&#26512;&#65292;&#26412;&#25991;&#30830;&#23450;&#20102;&#20004;&#20010;&#25913;&#36827;&#26041;&#21521;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#30693;&#35782;&#33976;&#39311;&#31561;&#22330;&#26223;&#19979;&#35299;&#32806;&#24335;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#30340;&#23545;&#31216;&#24615;&#38480;&#21046;&#38382;&#39064;&#12290;&#36825;&#20010;&#25913;&#36827;&#20445;&#35777;&#20102;&#22312;&#35757;&#32451;&#26399;&#38388;wMSE&#32452;&#20214;&#22987;&#32456;&#26377;&#25928;&#65292;&#25552;&#20379;&#39069;&#22806;&#30340;&#26500;&#36896;&#24615;&#26263;&#31034;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23558;&#20840;&#23616;&#20449;&#24687;&#24341;&#20837;&#35299;&#32806;&#24335;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#20013;&#65292;&#29992;&#20110;&#31867;&#20869;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#12290;&#36890;&#36807;&#36825;&#20004;&#20010;&#25913;&#36827;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#25913;&#36827;&#30340;KL&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#22312;CIFAR-10/100&#21644;ImageNet&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#26469;&#35780;&#20272;&#20854;&#26377;&#25928;&#24615;&#65292;&#37325;&#28857;&#26159;&#23545;&#25239;&#35757;&#32451;&#21644;&#30693;&#35782;&#33976;&#39311;&#20219;&#21153;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#20102;&#27604;&#20854;&#20182;&#26368;&#20808;&#36827;&#27169;&#22411;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we delve deeper into the Kullback-Leibler (KL) Divergence loss and observe that it is equivalent to the Doupled Kullback-Leibler (DKL) Divergence loss that consists of 1) a weighted Mean Square Error (wMSE) loss and 2) a Cross-Entropy loss incorporating soft labels. From our analysis of the DKL loss, we have identified two areas for improvement. Firstly, we address the limitation of DKL in scenarios like knowledge distillation by breaking its asymmetry property in training optimization. This modification ensures that the wMSE component is always effective during training, providing extra constructive cues. Secondly, we introduce global information into DKL for intra-class consistency regularization. With these two enhancements, we derive the Improved Kullback-Leibler (IKL) Divergence loss and evaluate its effectiveness by conducting experiments on CIFAR-10/100 and ImageNet datasets, focusing on adversarial training and knowledge distillation tasks. The proposed approach 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.05642</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A duality framework for generalization analysis of random feature models and two-layer neural networks. (arXiv:2305.05642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#39640;&#32500;&#20998;&#26512;&#20013;&#20986;&#29616;&#30340;&#33258;&#28982;&#20989;&#25968;&#31354;&#38388; $\mathcal{F}_{p,\pi}$ &#21644; Barron &#31354;&#38388;&#20013;&#23398;&#20064;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23545;&#20598;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20123;&#31354;&#38388;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#21487;&#20197;&#22312;&#26576;&#31181;&#24847;&#20041;&#19979;&#34987;&#35270;&#20026;&#31561;&#20215;&#30340;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#22312;&#30740;&#31350;&#36825;&#20004;&#31181;&#27169;&#22411;&#30340;&#27867;&#21270;&#26102;&#26356;&#19987;&#27880;&#20110;&#26356;&#23481;&#26131;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#30340;&#22797;&#26434;&#24230;&#26469;&#26377;&#25928;&#22320;&#25511;&#21046;&#20272;&#35745;&#35823;&#24046;&#65292;&#24314;&#31435;&#20102;&#23545;&#20598;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#20004;&#20010;&#20855;&#20307;&#24212;&#29992;&#36827;&#34892;&#32508;&#21512;&#20998;&#26512;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#12290;&#31532;&#19968;&#20010;&#24212;&#29992;&#26159;&#30740;&#31350;&#20351;&#29992; RFMs &#23398;&#20064; $\mathcal{F}_{p,\pi}$ &#20013;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#21482;&#35201; $p&gt;1$&#65292;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#36825;&#24847;&#21619;&#30528; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning functions in the $\mathcal{F}_{p,\pi}$ and Barron spaces, which are natural function spaces that arise in the high-dimensional analysis of random feature models (RFMs) and two-layer neural networks. Through a duality analysis, we reveal that the approximation and estimation of these spaces can be considered equivalent in a certain sense. This enables us to focus on the easier problem of approximation and estimation when studying the generalization of both models. The dual equivalence is established by defining an information-based complexity that can effectively control estimation errors. Additionally, we demonstrate the flexibility of our duality framework through comprehensive analyses of two concrete applications.  The first application is to study learning functions in $\mathcal{F}_{p,\pi}$ with RFMs. We prove that the learning does not suffer from the curse of dimensionality as long as $p&gt;1$, implying RFMs can work beyond the kernel regime. Our 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#38754;&#37096;&#35782;&#21035;&#25216;&#26415;&#65292;&#36890;&#36807;&#29305;&#23450;&#30340;&#38754;&#37096;&#29305;&#24449;&#21457;&#29616;&#20102;&#20154;&#20204;&#30340;&#25919;&#27835;&#21462;&#21521;&#65292;&#29978;&#33267;&#21487;&#20197;&#20174;&#33258;&#28982;&#22270;&#20687;&#20013;&#25512;&#24191;&#12290;&#36825;&#31181;&#39044;&#27979;&#30340;&#31934;&#24230;&#27604;&#20154;&#31867;&#35780;&#20998;&#32773;&#39640;&#65292;&#30456;&#24403;&#20110;&#19968;&#20123;&#24037;&#20316;&#38754;&#35797;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.16343</link><description>&lt;p&gt;
&#38754;&#37096;&#35782;&#21035;&#25216;&#26415;&#21487;&#20197;&#20174;&#38754;&#37096;&#22270;&#20687;&#20013;&#26174;&#31034;&#25919;&#27835;&#21462;&#21521;&#65292;&#21363;&#20351;&#25511;&#21046;&#31038;&#20250;&#20154;&#21475;&#32479;&#35745;&#21644;&#33258;&#25105;&#34920;&#29616;&#12290;(arXiv: 2303.16343v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
Facial recognition technology can expose political orientation from facial images even when controlling for demographics and self-presentation. (arXiv:2303.16343v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#38754;&#37096;&#35782;&#21035;&#25216;&#26415;&#65292;&#36890;&#36807;&#29305;&#23450;&#30340;&#38754;&#37096;&#29305;&#24449;&#21457;&#29616;&#20102;&#20154;&#20204;&#30340;&#25919;&#27835;&#21462;&#21521;&#65292;&#29978;&#33267;&#21487;&#20197;&#20174;&#33258;&#28982;&#22270;&#20687;&#20013;&#25512;&#24191;&#12290;&#36825;&#31181;&#39044;&#27979;&#30340;&#31934;&#24230;&#27604;&#20154;&#31867;&#35780;&#20998;&#32773;&#39640;&#65292;&#30456;&#24403;&#20110;&#19968;&#20123;&#24037;&#20316;&#38754;&#35797;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36816;&#29992;&#38754;&#37096;&#35782;&#21035;&#31639;&#27861;&#65292;&#20174;&#23454;&#39564;&#23460;&#35774;&#32622;&#19979;&#25293;&#25668;&#30340;591&#24352;&#20013;&#24615;&#38754;&#37096;&#22270;&#20687;&#20013;&#25552;&#21462;&#38754;&#37096;&#25551;&#36848;&#31526;&#12290;&#22312;&#25511;&#21046;&#24180;&#40836;&#12289;&#24615;&#21035;&#21644;&#31181;&#26063;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20132;&#21449;&#39564;&#35777;&#30340;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#39044;&#27979;&#21442;&#19982;&#32773;&#22312;&#25919;&#27835;&#21462;&#21521;&#37327;&#34920;&#19978;&#30340;&#24471;&#20998;(Cronbach&#30340;&#945;=0.94)&#12290;&#27169;&#22411;&#30340;&#24615;&#33021;&#36229;&#36807;&#20102;r = 0.20&#65292;&#36828;&#20248;&#20110;&#20154;&#31867;&#35780;&#20998;&#32773;&#65292;&#19982;&#24037;&#20316;&#38754;&#35797;&#39044;&#27979;&#24037;&#20316;&#25104;&#21151;&#12289;&#37202;&#31934;&#39537;&#21160;&#25915;&#20987;&#24615;&#25110;&#24515;&#29702;&#27835;&#30103;&#25913;&#21892;&#24515;&#29702;&#20581;&#24247;&#30340;&#25928;&#26524;&#30456;&#24403;&#12290;&#27492;&#22806;&#65292;&#20174;&#26631;&#20934;&#21270;&#22270;&#20687;&#34893;&#29983;&#20986;&#30340;&#27169;&#22411;&#22312;3,401&#21517;&#26469;&#33258;&#32654;&#22269;&#12289;&#33521;&#22269;&#21644;&#21152;&#25343;&#22823;&#30340;&#25919;&#27835;&#20154;&#29289;&#30340;&#33258;&#28982;&#22270;&#20687;&#26679;&#26412;&#20013;&#34920;&#29616;&#33391;&#22909;(r = 0.12)&#65292;&#34920;&#26126;&#38754;&#37096;&#22806;&#35980;&#21644;&#25919;&#27835;&#21462;&#21521;&#20043;&#38388;&#30340;&#20851;&#32852;&#21487;&#25512;&#24191;&#21040;&#25105;&#20204;&#20043;&#22806;&#30340;&#20154;&#32676;&#12290;&#38754;&#37096;&#29305;&#24449;&#19982;&#25919;&#27835;&#21462;&#21521;&#30456;&#20851;&#30340;&#20998;&#26512;&#21457;&#29616;&#65292;&#20445;&#23432;&#27966;&#30340;&#19979;&#21322;&#33080;&#37096;&#20998;&#26356;&#22823;&#65292;&#34429;&#28982;&#25919;&#27835;&#21462;&#21521;&#19981;&#33021;&#20934;&#30830;&#22320;&#39044;&#27979;&#20010;&#20307;&#38754;&#37096;&#29305;&#24449;&#30340;&#25152;&#26377;&#21464;&#21270;&#65292;&#20294;&#26159;&#36825;&#31181;&#21457;&#29616;&#36824;&#26159;&#23500;&#26377;&#21551;&#21457;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
A facial recognition algorithm was used to extract face descriptors from carefully standardized images of 591 neutral faces taken in the laboratory setting. Face descriptors were entered into a cross-validated linear regression to predict participants' scores on a political orientation scale (Cronbach's alpha=.94) while controlling for age, gender, and ethnicity. The model's performance exceeded r=.20: much better than that of human raters and on par with how well job interviews predict job success, alcohol drives aggressiveness, or psychological therapy improves mental health. Moreover, the model derived from standardized images performed well (r=.12) in a sample of naturalistic images of 3,401 politicians from the U.S., UK, and Canada, suggesting that the associations between facial appearance and political orientation generalize beyond our sample. The analysis of facial features associated with political orientation revealed that conservatives had larger lower faces, although politi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.06198</link><description>&lt;p&gt;
&#20811;&#26381;&#24322;&#26041;&#24046;PCA&#20013;&#30149;&#24577;&#38382;&#39064;&#30340;&#32553;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA. (arXiv:2303.06198v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel algorithm, called Deflated-HeteroPCA, that overcomes the curse of ill-conditioning in heteroskedastic PCA while achieving near-optimal and condition-number-free theoretical guarantees.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#20174;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;X*&#30340;&#21015;&#23376;&#31354;&#38388;&#12290;&#24403;&#23384;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#21644;&#19981;&#24179;&#34913;&#30340;&#32500;&#24230;&#65288;&#21363;n2 &gt;&gt; n1&#65289;&#26102;&#65292;&#22914;&#20309;&#22312;&#23481;&#32435;&#26368;&#24191;&#27867;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#30340;&#21516;&#26102;&#33719;&#24471;&#26368;&#20339;&#30340;&#32479;&#35745;&#31934;&#24230;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;HeteroPCA&#25104;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24378;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#36973;&#21463;&#20102;&#8220;&#30149;&#24577;&#38382;&#39064;&#30340;&#35781;&#21650;&#8221;&#65292;&#21363;&#38543;&#30528;X*&#30340;&#26465;&#20214;&#25968;&#22686;&#38271;&#65292;&#20854;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#32780;&#19981;&#24433;&#21709;&#20801;&#35768;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;$\ell_2$&#21644;$\ell_{2,\infty}$&#32479;&#35745;&#31934;&#24230;&#26041;&#38754;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23558;&#35889;&#20998;&#25104;&#20004;&#37096;&#20998;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26377;&#38480;&#26102;&#22495;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22266;&#23450;&#26102;&#38388;&#21518;&#32456;&#27490;&#65292;&#36890;&#36807;&#20989;&#25968;&#36924;&#36817;&#21644;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2210.04527</link><description>&lt;p&gt;
&#26377;&#38480;&#26102;&#22495;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A policy gradient approach for Finite Horizon Constrained Markov Decision Processes. (arXiv:2210.04527v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26377;&#38480;&#26102;&#22495;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22266;&#23450;&#26102;&#38388;&#21518;&#32456;&#27490;&#65292;&#36890;&#36807;&#20989;&#25968;&#36924;&#36817;&#21644;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38480;&#26102;&#22495;&#35774;&#32622;&#36890;&#24120;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#23548;&#33268;&#20135;&#29983;&#26368;&#20248;&#30340;&#22266;&#23450;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#26377;&#38480;&#26102;&#22495;&#25511;&#21046;&#38382;&#39064;&#26356;&#20855;&#26377;&#23454;&#38469;&#24847;&#20041;&#65292;&#24182;&#19988;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#36890;&#24120;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#26368;&#36817;&#65292;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#35774;&#32622;&#20063;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#65292;&#20854;&#20013;&#20195;&#29702;&#21516;&#26102;&#22312;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#21516;&#26102;&#28385;&#36275;&#26576;&#20123;&#32473;&#23450;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#35774;&#32622;&#20165;&#22312;&#26080;&#38480;&#26102;&#22495;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#32972;&#26223;&#19979;&#24471;&#21040;&#20102;&#30740;&#31350;&#65292;&#20854;&#20013;&#22266;&#23450;&#31574;&#30053;&#26159;&#26368;&#20248;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26377;&#38480;&#26102;&#22495;&#35774;&#32622;&#19979;&#36827;&#34892;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#22312;&#19968;&#20010;&#22266;&#23450;&#30340;&#26102;&#38388;&#21518;&#32456;&#27490;&#12290;&#25105;&#20204;&#22312;&#31639;&#27861;&#20013;&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#65292;&#36825;&#22312;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#36739;&#22823;&#25110;&#36830;&#32493;&#30340;&#24773;&#20917;&#19979;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#24182;&#20351;&#29992;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#24471;&#21040;&#30340;&#26368;&#20248;&#31574;&#30053;&#21462;&#20915;&#20110;&#26102;&#38388;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
The infinite horizon setting is widely adopted for problems of reinforcement learning (RL). These invariably result in stationary policies that are optimal. In many situations, finite horizon control problems are of interest and for such problems, the optimal policies are time-varying in general. Another setting that has become popular in recent times is of Constrained Reinforcement Learning, where the agent maximizes its rewards while it also aims to satisfy some given constraint criteria. However, this setting has only been studied in the context of infinite horizon MDPs where stationary policies are optimal. We present an algorithm for constrained RL in the Finite Horizon Setting where the horizon terminates after a fixed (finite) time. We use function approximation in our algorithm which is essential when the state and action spaces are large or continuous and use the policy gradient method to find the optimal policy. The optimal policy that we obtain depends on the stage and so is
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.13714</link><description>&lt;p&gt;
&#24102;&#29702;&#35770;&#25903;&#25345;&#30340;&#26679;&#26412;&#37325;&#29992;&#30340;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse. (arXiv:2206.13714v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13714
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#23398;&#20064;&#25511;&#21046;&#26041;&#27861;&#20855;&#26377;&#25913;&#21892;&#22797;&#26434;&#31995;&#32479;&#36816;&#34892;&#30340;&#28508;&#21147;&#65292;&#32780;&#22522;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#34920;&#20102;&#19968;&#31181;&#27969;&#34892;&#30340;&#25968;&#25454;&#39537;&#21160;&#25511;&#21046;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#31639;&#27861;&#31867;&#21035;&#22312;&#23454;&#38469;&#25511;&#21046;&#37096;&#32626;&#30340;&#20004;&#20010;&#37325;&#35201;&#35201;&#27714;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#65306;&#65288;i&#65289;&#23454;&#38469;&#24615;&#33021;&#20445;&#35777;&#21644;&#65288;ii&#65289;&#25968;&#25454;&#25928;&#29575;&#12290;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#65292;&#20294;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#22312;&#32447;&#31574;&#30053;&#31639;&#27861;&#20445;&#35777;&#20102;&#35757;&#32451;&#26399;&#38388;&#30340;&#36817;&#20284;&#31574;&#30053;&#25913;&#36827;&#65292;&#20294;&#21463;&#21040;&#39640;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#24179;&#34913;&#36825;&#20123;&#31454;&#20105;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31867;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#26679;&#26412;&#37325;&#29992;&#30340;&#25928;&#29575;&#12290;&#36890;&#36807;&#23545;&#26469;&#33258;DeepMind C&#30340;&#22810;&#31181;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#36827;&#34892; extensive &#30340;&#23454;&#39564;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#31867;&#31639;&#27861;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven, learning-based control methods offer the potential to improve operations in complex systems, and model-free deep reinforcement learning represents a popular approach to data-driven control. However, existing classes of algorithms present a trade-off between two important deployment requirements for real-world control: (i) practical performance guarantees and (ii) data efficiency. Off-policy algorithms make efficient use of data through sample reuse but lack theoretical guarantees, while on-policy algorithms guarantee approximate policy improvement throughout training but suffer from high sample complexity. In order to balance these competing goals, we develop a class of Generalized Policy Improvement algorithms that combines the policy improvement guarantees of on-policy methods with the efficiency of sample reuse. We demonstrate the benefits of this new class of algorithms through extensive experimental analysis on a variety of continuous control tasks from the DeepMind C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22996;&#25176;&#20154;&#23545;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#37096;&#20998;&#20102;&#35299;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#30340;&#35774;&#35745;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#22823;&#26368;&#23567;&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#26469;&#26368;&#22823;&#21270;&#22312;&#20195;&#29702;&#20154;&#20449;&#21495;&#20998;&#24067;&#30340;&#38598;&#21512;&#20013;&#26368;&#22351;&#24773;&#20917;&#19979;&#22238;&#25253;&#30340;&#22686;&#21152;&#12290;&#23545;&#20110;&#26377;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65307;&#23545;&#20110;&#26080;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#36924;&#36817;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2107.07420</link><description>&lt;p&gt;
&#37096;&#20998;&#30693;&#35782;&#19979;&#30340;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Scoring Rule Design under Partial Knowledge. (arXiv:2107.07420v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.07420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22996;&#25176;&#20154;&#23545;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#37096;&#20998;&#20102;&#35299;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#30340;&#35774;&#35745;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#22823;&#26368;&#23567;&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#26469;&#26368;&#22823;&#21270;&#22312;&#20195;&#29702;&#20154;&#20449;&#21495;&#20998;&#24067;&#30340;&#38598;&#21512;&#20013;&#26368;&#22351;&#24773;&#20917;&#19979;&#22238;&#25253;&#30340;&#22686;&#21152;&#12290;&#23545;&#20110;&#26377;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65307;&#23545;&#20110;&#26080;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#36924;&#36817;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#22996;&#25176;&#20154;&#23545;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#37096;&#20998;&#20102;&#35299;&#26102;&#65292;&#26368;&#20248;&#36866;&#24403;&#25171;&#20998;&#35268;&#21017;&#30340;&#35774;&#35745;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#22312;&#22996;&#25176;&#20154;&#23436;&#20840;&#20102;&#35299;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#21487;&#20197;&#30830;&#23450;&#22686;&#21152;&#20195;&#29702;&#20154;&#22238;&#25253;&#30340;&#26368;&#22823;&#36866;&#24403;&#25171;&#20998;&#35268;&#21017;&#65292;&#24403;&#20195;&#29702;&#20154;&#36873;&#25321;&#35775;&#38382;&#26114;&#36149;&#20449;&#21495;&#20197;&#23436;&#21892;&#20854;&#20808;&#39564;&#39044;&#27979;&#30340;&#21518;&#39564;&#20449;&#24565;&#26102;&#12290;&#22312;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;&#65292;&#22996;&#25176;&#20154;&#21482;&#30693;&#36947;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#23646;&#20110;&#19968;&#32452;&#20998;&#24067;&#20013;&#30340;&#26576;&#20010;&#12290;&#25105;&#20204;&#23558;&#25171;&#20998;&#35268;&#21017;&#35774;&#35745;&#38382;&#39064;&#21046;&#23450;&#20026;&#26368;&#22823;&#26368;&#23567;&#20248;&#21270;&#38382;&#39064;&#65292;&#26368;&#22823;&#21270;&#20998;&#24067;&#38598;&#21512;&#20013;&#26368;&#22351;&#24773;&#20917;&#19979;&#22238;&#25253;&#30340;&#22686;&#21152;&#12290;&#24403;&#20998;&#24067;&#38598;&#21512;&#26377;&#38480;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#36924;&#36817;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#26080;&#38480;&#38598;&#21512;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25351;&#20986;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;&#25171;&#20998;&#35268;&#21017;&#65292;&#22914;&#20108;&#27425;&#26041;&#25171;&#20998;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the design of optimal proper scoring rules when the principal has partial knowledge of an agent's signal distribution. Recent work characterizes the proper scoring rules that maximize the increase of an agent's payoff when the agent chooses to access a costly signal to refine a posterior belief from her prior prediction, under the assumption that the agent's signal distribution is fully known to the principal. In our setting, the principal only knows about a set of distributions where the agent's signal distribution belongs. We formulate the scoring rule design problem as a max-min optimization that maximizes the worst-case increase in payoff across the set of distributions.  We propose an efficient algorithm to compute an optimal scoring rule when the set of distributions is finite, and devise a fully polynomial-time approximation scheme that accommodates various infinite sets of distributions. We further remark that widely used scoring rules, such as the quadratic 
&lt;/p&gt;</description></item></channel></rss>