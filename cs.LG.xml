<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>Videoshop&#26159;&#19968;&#20010;&#26080;&#38656;&#35757;&#32451;&#30340;&#35270;&#39057;&#32534;&#36753;&#31639;&#27861;&#65292;&#36890;&#36807;&#22270;&#20687;&#20026;&#22522;&#30784;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#26412;&#22320;&#21270;&#35821;&#20041;&#32534;&#36753;&#65292;&#20174;&#32780;&#20801;&#35768;&#29992;&#25143;&#23545;&#35270;&#39057;&#36827;&#34892;&#31934;&#32454;&#25511;&#21046;&#65292;&#21462;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#32534;&#36753;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.14617</link><description>&lt;p&gt;
Videoshop&#65306;&#20855;&#26377;&#22122;&#22768;&#22806;&#25512;&#25193;&#25955;&#21453;&#28436;&#30340;&#26412;&#22320;&#21270;&#35821;&#20041;&#35270;&#39057;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14617
&lt;/p&gt;
&lt;p&gt;
Videoshop&#26159;&#19968;&#20010;&#26080;&#38656;&#35757;&#32451;&#30340;&#35270;&#39057;&#32534;&#36753;&#31639;&#27861;&#65292;&#36890;&#36807;&#22270;&#20687;&#20026;&#22522;&#30784;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#26412;&#22320;&#21270;&#35821;&#20041;&#32534;&#36753;&#65292;&#20174;&#32780;&#20801;&#35768;&#29992;&#25143;&#23545;&#35270;&#39057;&#36827;&#34892;&#31934;&#32454;&#25511;&#21046;&#65292;&#21462;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#32534;&#36753;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;Videoshop&#65292;&#36825;&#26159;&#19968;&#20010;&#26080;&#38656;&#35757;&#32451;&#30340;&#29992;&#20110;&#26412;&#22320;&#21270;&#35821;&#20041;&#32534;&#36753;&#30340;&#35270;&#39057;&#32534;&#36753;&#31639;&#27861;&#12290;Videoshop&#20801;&#35768;&#29992;&#25143;&#20351;&#29992;&#20219;&#20309;&#32534;&#36753;&#36719;&#20214;&#65292;&#21253;&#25324;Photoshop&#21644;&#29983;&#25104;&#22635;&#20805;&#65292;&#20462;&#25913;&#31532;&#19968;&#24103;&#65307;&#23427;&#20250;&#33258;&#21160;&#23558;&#36825;&#20123;&#26356;&#25913;&#20256;&#25773;&#21040;&#20854;&#20313;&#24103;&#65292;&#20445;&#25345;&#35821;&#20041;&#12289;&#31354;&#38388;&#21644;&#26102;&#38388;&#19978;&#30340;&#19968;&#33268;&#36816;&#21160;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#21482;&#33021;&#36890;&#36807;&#19981;&#31934;&#30830;&#30340;&#25991;&#26412;&#25351;&#20196;&#36827;&#34892;&#32534;&#36753;&#19981;&#21516;&#65292;Videoshop&#20801;&#35768;&#29992;&#25143;&#28155;&#21152;&#25110;&#21024;&#38500;&#23545;&#35937;&#65292;&#35821;&#20041;&#19978;&#26356;&#25913;&#23545;&#35937;&#65292;&#23558;&#32032;&#26448;&#29031;&#29255;&#25554;&#20837;&#35270;&#39057;&#31561;&#65292;&#24182;&#23545;&#20301;&#32622;&#21644;&#22806;&#35266;&#36827;&#34892;&#32454;&#31890;&#24230;&#25511;&#21046;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#28508;&#22312;&#20540;&#36827;&#34892;&#22122;&#22768;&#22806;&#25512;&#21453;&#28436;&#30340;&#22270;&#20687;&#20026;&#22522;&#30784;&#30340;&#35270;&#39057;&#32534;&#36753;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20174;&#20013;&#25105;&#20204;&#29983;&#25104;&#26681;&#25454;&#32534;&#36753;&#22270;&#20687;&#35843;&#25972;&#30340;&#35270;&#39057;&#12290;Videoshop&#22312;2&#20010;&#32534;&#36753;&#22522;&#20934;&#27979;&#35797;&#20013;&#20351;&#29992;10&#20010;&#35780;&#20272;&#25351;&#26631;&#23545;6&#20010;&#22522;&#32447;&#21462;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#32534;&#36753;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14617v1 Announce Type: cross  Abstract: We introduce Videoshop, a training-free video editing algorithm for localized semantic edits. Videoshop allows users to use any editing software, including Photoshop and generative inpainting, to modify the first frame; it automatically propagates those changes, with semantic, spatial, and temporally consistent motion, to the remaining frames. Unlike existing methods that enable edits only through imprecise textual instructions, Videoshop allows users to add or remove objects, semantically change objects, insert stock photos into videos, etc. with fine-grained control over locations and appearance. We achieve this through image-based video editing by inverting latents with noise extrapolation, from which we generate videos conditioned on the edited image. Videoshop produces higher quality edits against 6 baselines on 2 editing benchmarks using 10 evaluation metrics.
&lt;/p&gt;</description></item><item><title>&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#20013;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#20811;&#26381;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#38454;&#27573;&#30340;&#26041;&#27861;&#36827;&#34892;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;</title><link>https://arxiv.org/abs/2403.12203</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#20223;&#30340;&#22686;&#24378;&#23398;&#20064;&#20026;&#22522;&#20110;&#35270;&#35273;&#30340;&#25935;&#25463;&#39134;&#34892;&#24341;&#23548;&#24341;&#23548;
&lt;/p&gt;
&lt;p&gt;
Bootstrapping Reinforcement Learning with Imitation for Vision-Based Agile Flight
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12203
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#20013;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#20811;&#26381;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#38454;&#27573;&#30340;&#26041;&#27861;&#36827;&#34892;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#30340;&#32972;&#26223;&#19979;&#65292;&#23558;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#26377;&#25928;&#24615;&#21644;&#27169;&#20223;&#23398;&#20064;&#65288;IL&#65289;&#30340;&#25928;&#29575;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#30452;&#25509;&#22788;&#29702;&#35270;&#35273;&#36755;&#20837;&#65292;&#32780;&#26080;&#38656;&#26126;&#30830;&#30340;&#29366;&#24577;&#20272;&#35745;&#12290;&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#35797;&#38169;&#25552;&#20379;&#20102;&#19968;&#20010;&#23398;&#20064;&#22797;&#26434;&#25511;&#21046;&#22120;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#20294;&#38754;&#20020;&#30528;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#35270;&#35273;&#36755;&#20837;&#30340;&#32500;&#24230;&#36739;&#39640;&#12290;&#30456;&#21453;&#65292;IL&#22312;&#20174;&#35270;&#35273;&#28436;&#31034;&#20013;&#23398;&#20064;&#26041;&#38754;&#34920;&#29616;&#20986;&#25928;&#29575;&#65292;&#20294;&#21463;&#21040;&#28436;&#31034;&#36136;&#37327;&#30340;&#38480;&#21046;&#65292;&#24182;&#38754;&#20020;&#35832;&#22914;&#21327;&#21464;&#37327;&#28418;&#31227;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#21512;RL&#21644;IL&#20248;&#21183;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#20351;&#29992;&#29305;&#26435;&#29366;&#24577;&#20449;&#24687;&#30340;&#24072;&#20613;&#31574;&#30053;&#30340;&#21021;&#22987;&#35757;&#32451;&#65292;&#20351;&#29992;IL&#23558;&#27492;&#31574;&#30053;&#33976;&#39311;&#20026;&#23398;&#29983;&#31574;&#30053;&#65292;&#20197;&#21450;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12203v1 Announce Type: cross  Abstract: We combine the effectiveness of Reinforcement Learning (RL) and the efficiency of Imitation Learning (IL) in the context of vision-based, autonomous drone racing. We focus on directly processing visual input without explicit state estimation. While RL offers a general framework for learning complex controllers through trial and error, it faces challenges regarding sample efficiency and computational demands due to the high dimensionality of visual inputs. Conversely, IL demonstrates efficiency in learning from visual demonstrations but is limited by the quality of those demonstrations and faces issues like covariate shift. To overcome these limitations, we propose a novel training framework combining RL and IL's advantages. Our framework involves three stages: initial training of a teacher policy using privileged state information, distilling this policy into a student policy using IL, and performance-constrained adaptive RL fine-tunin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#20844;&#24320;&#25968;&#25454;&#38598;&#26500;&#24314;&#29983;&#29289;&#20998;&#31867;&#32676;&#25968;&#25454;&#38598;&#20197;&#21450;&#21033;&#29992;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#25512;&#23548;&#27169;&#22411;&#30340;&#31616;&#21270;&#26041;&#27861;&#65292;&#24182;&#20197;&#33889;&#33796;&#29273;&#26412;&#22320;&#26893;&#29289;&#20026;&#26696;&#20363;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.12072</link><description>&lt;p&gt;
Floralens&#65306;&#19968;&#31181;&#29992;&#20110;&#33889;&#33796;&#29273;&#26412;&#22320;&#26893;&#29289;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Floralens: a Deep Learning Model for the Portuguese Native Flora
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#20844;&#24320;&#25968;&#25454;&#38598;&#26500;&#24314;&#29983;&#29289;&#20998;&#31867;&#32676;&#25968;&#25454;&#38598;&#20197;&#21450;&#21033;&#29992;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#25512;&#23548;&#27169;&#22411;&#30340;&#31616;&#21270;&#26041;&#27861;&#65292;&#24182;&#20197;&#33889;&#33796;&#29273;&#26412;&#22320;&#26893;&#29289;&#20026;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#29305;&#21035;&#26159;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#35768;&#22810;&#20844;&#27665;&#31185;&#23398;&#24179;&#21488;&#20013;&#23545;&#29983;&#29289;&#29289;&#31181;&#36827;&#34892;&#22522;&#20110;&#22270;&#20687;&#30340;&#35782;&#21035;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#26500;&#24314;&#36275;&#22815;&#22823;&#23567;&#21644;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;&#32593;&#32476;&#20197;&#21450;&#32593;&#32476;&#26550;&#26500;&#30340;&#36873;&#25321;&#26412;&#36523;&#20173;&#28982;&#24456;&#23569;&#26377;&#25991;&#29486;&#35760;&#24405;&#65292;&#22240;&#27492;&#19981;&#23481;&#26131;&#34987;&#22797;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#20844;&#24320;&#21487;&#29992;&#30340;&#30740;&#31350;&#32423;&#25968;&#25454;&#38598;&#26500;&#24314;&#29983;&#29289;&#20998;&#31867;&#32676;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#38598;&#20351;&#29992;&#35895;&#27468;&#30340;AutoML Vision&#20113;&#26381;&#21153;&#25552;&#20379;&#30340;&#29616;&#25104;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26469;&#25512;&#23548;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26696;&#20363;&#30740;&#31350;&#26159;&#33889;&#33796;&#29273;&#26412;&#22320;&#26893;&#29289;&#65292;&#22522;&#20110;&#30001;&#33889;&#33796;&#29273;&#26893;&#29289;&#23398;&#20250;&#25552;&#20379;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#28155;&#21152;&#26469;&#33258;iNaturalist&#12289;Pl@ntNet&#21644;Observation.org&#30340;&#37319;&#38598;&#25968;&#25454;&#36827;&#34892;&#25193;&#23637;&#12290;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;&#35880;&#24910;&#22320;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12072v1 Announce Type: cross  Abstract: Machine-learning techniques, namely deep convolutional neural networks, are pivotal for image-based identification of biological species in many Citizen Science platforms. However, the construction of critically sized and sampled datasets to train the networks and the choice of the network architectures itself remains little documented and, therefore, does not lend itself to be easily replicated. In this paper, we develop a streamlined methodology for building datasets for biological taxa from publicly available research-grade datasets and for deriving models from these datasets using off-the-shelf deep convolutional neural networks such as those provided by Google's AutoML Vision cloud service. Our case study is the Portuguese native flora, anchored in a high-quality dataset, provided by the Sociedade Portuguesa de Bot\^anica, scaled up by adding sampled data from iNaturalist, Pl@ntNet, and Observation.org. We find that with a careful
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#24207;&#21015;&#20219;&#21153;&#35774;&#32622;&#19979;&#26368;&#23567;&#21270;&#23616;&#37096;&#36951;&#25022;&#30340;&#35884;&#35823;&#65292;&#25581;&#31034;&#20102;&#36817;&#35270;&#22320;&#26368;&#23567;&#21270;&#36951;&#25022;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10946</link><description>&lt;p&gt;
&#22312;&#24207;&#21015;&#20219;&#21153;&#35774;&#32622;&#20013;&#26368;&#23567;&#21270;&#23616;&#37096;&#36951;&#25022;&#30340;&#35884;&#35823;
&lt;/p&gt;
&lt;p&gt;
The Fallacy of Minimizing Local Regret in the Sequential Task Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10946
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#24207;&#21015;&#20219;&#21153;&#35774;&#32622;&#19979;&#26368;&#23567;&#21270;&#23616;&#37096;&#36951;&#25022;&#30340;&#35884;&#35823;&#65292;&#25581;&#31034;&#20102;&#36817;&#35270;&#22320;&#26368;&#23567;&#21270;&#36951;&#25022;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#32463;&#24120;&#34987;&#27010;&#24565;&#21270;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#31639;&#27861;&#19982;&#26410;&#30693;&#29615;&#22659;&#20132;&#20114;&#20197;&#26368;&#23567;&#21270;&#32047;&#31215;&#36951;&#25022;&#12290;&#22312;&#38745;&#24577;&#35774;&#32622;&#20013;&#65292;&#21487;&#20197;&#33719;&#24471;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#22914;&#27425;&#32447;&#24615;&#65288;$\sqrt{T}$&#65289;&#36951;&#25022;&#30028;&#38480;&#65292;&#36890;&#24120;&#24847;&#21619;&#30528;&#25910;&#25947;&#21040;&#26368;&#20248;&#31574;&#30053;&#24182;&#20572;&#27490;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29702;&#35770;&#35774;&#32622;&#36890;&#24120;&#36807;&#20998;&#31616;&#21270;&#20102;&#30495;&#23454;&#19990;&#30028;&#24378;&#21270;&#23398;&#20064;&#23454;&#29616;&#20013;&#36935;&#21040;&#30340;&#22797;&#26434;&#24615;&#65292;&#20854;&#20013;&#20219;&#21153;&#25353;&#39034;&#24207;&#21040;&#36798;&#65292;&#20219;&#21153;&#20043;&#38388;&#26377;&#37325;&#22823;&#21464;&#21270;&#65292;&#24182;&#19988;&#31639;&#27861;&#21487;&#33021;&#19981;&#20801;&#35768;&#22312;&#26576;&#20123;&#20219;&#21153;&#20013;&#36827;&#34892;&#33258;&#36866;&#24212;&#23398;&#20064;&#12290;&#25105;&#20204;&#30740;&#31350;&#36229;&#20986;&#32467;&#26524;&#20998;&#24067;&#30340;&#21464;&#21270;&#65292;&#28085;&#30422;&#22870;&#21169;&#35774;&#35745;&#65288;&#20174;&#32467;&#26524;&#21040;&#22870;&#21169;&#30340;&#26144;&#23556;&#65289;&#21644;&#20801;&#35768;&#30340;&#31574;&#30053;&#31354;&#38388;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#22312;&#27599;&#20010;&#20219;&#21153;&#20013;&#36817;&#35270;&#22320;&#26368;&#23567;&#21270;&#36951;&#25022;&#30340;&#35884;&#35823;&#65306;&#33719;&#24471;&#26368;&#20248;&#36951;&#25022;r
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10946v1 Announce Type: cross  Abstract: In the realm of Reinforcement Learning (RL), online RL is often conceptualized as an optimization problem, where an algorithm interacts with an unknown environment to minimize cumulative regret. In a stationary setting, strong theoretical guarantees, like a sublinear ($\sqrt{T}$) regret bound, can be obtained, which typically implies the convergence to an optimal policy and the cessation of exploration. However, these theoretical setups often oversimplify the complexities encountered in real-world RL implementations, where tasks arrive sequentially with substantial changes between tasks and the algorithm may not be allowed to adaptively learn within certain tasks. We study the changes beyond the outcome distributions, encompassing changes in the reward designs (mappings from outcomes to rewards) and the permissible policy spaces. Our results reveal the fallacy of myopically minimizing regret within each task: obtaining optimal regret r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;LoReKT&#30340;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#26694;&#26550;&#65292;&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#37325;&#35201;&#24615;&#26426;&#21046;&#65292;&#26088;&#22312;&#20174;&#20016;&#23500;&#36164;&#28304;&#30340;KT&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#21644;&#34920;&#31034;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2403.06725</link><description>&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#37325;&#35201;&#24615;&#26426;&#21046;&#24494;&#35843;&#25913;&#36827;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06725
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;LoReKT&#30340;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#26694;&#26550;&#65292;&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#37325;&#35201;&#24615;&#26426;&#21046;&#65292;&#26088;&#22312;&#20174;&#20016;&#23500;&#36164;&#28304;&#30340;KT&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#21644;&#34920;&#31034;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#36861;&#36394;&#65288;KT&#65289;&#26088;&#22312;&#22522;&#20110;&#23398;&#29983;&#30340;&#21382;&#21490;&#20114;&#21160;&#26469;&#20272;&#35745;&#20182;&#20204;&#30340;&#30693;&#35782;&#25484;&#25569;&#31243;&#24230;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;KT&#65288;DLKT&#65289;&#26041;&#27861;&#22312;KT&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#21407;&#22240;&#65292;&#22914;&#39044;&#31639;&#38480;&#21046;&#21644;&#38544;&#31169;&#38382;&#39064;&#65292;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#35266;&#23519;&#21040;&#30340;&#20114;&#21160;&#38750;&#24120;&#26377;&#38480;&#65292;&#21363;&#20302;&#36164;&#28304;KT&#25968;&#25454;&#38598;&#12290;&#30452;&#25509;&#22312;&#20302;&#36164;&#28304;KT&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;DLKT&#27169;&#22411;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#65292;&#24182;&#19988;&#24456;&#38590;&#36873;&#25321;&#36866;&#24403;&#30340;&#28145;&#24230;&#31070;&#32463;&#26550;&#26500;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LoReKT&#30340;&#20302;&#36164;&#28304;KT&#26694;&#26550;&#26469;&#24212;&#23545;&#19978;&#36848;&#25361;&#25112;&#12290;&#21463;&#30427;&#34892;&#30340;&#8220;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#8221;&#33539;&#24335;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#26088;&#22312;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#20174;&#20016;&#23500;&#36164;&#28304;&#30340;KT&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#21644;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06725v1 Announce Type: cross  Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subseque
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#38382;&#31572;&#20219;&#21153;&#65292;GPT&#33021;&#22815;&#39564;&#35777;&#21307;&#30103;&#39046;&#22495;&#24739;&#32773;&#30340;PA&#35831;&#27714;&#65292;&#24110;&#21161;&#21355;&#29983;&#35745;&#21010;&#26356;&#24555;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2402.18419</link><description>&lt;p&gt;
&#33021;&#21542;&#36890;&#36807;&#22522;&#20110;&#25351;&#21335;&#30340;&#33258;&#21160;&#38382;&#31572;&#26469;&#25913;&#21892;GPT&#30340;&#20808;&#21069;&#25480;&#26435;&#29366;&#24577;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can GPT Improve the State of Prior Authorization via Guideline Based Automated Question Answering?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18419
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38382;&#31572;&#20219;&#21153;&#65292;GPT&#33021;&#22815;&#39564;&#35777;&#21307;&#30103;&#39046;&#22495;&#24739;&#32773;&#30340;PA&#35831;&#27714;&#65292;&#24110;&#21161;&#21355;&#29983;&#35745;&#21010;&#26356;&#24555;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21355;&#29983;&#20445;&#38505;&#20844;&#21496;&#26377;&#19968;&#20010;&#34987;&#31216;&#20026;&#20808;&#21069;&#25480;&#26435;&#65288;PA&#65289;&#30340;&#27969;&#31243;&#65292;&#36825;&#26159;&#19968;&#31181;&#21355;&#29983;&#35745;&#21010;&#25104;&#26412;&#25511;&#21046;&#27969;&#31243;&#65292;&#35201;&#27714;&#21307;&#29983;&#21644;&#20854;&#20182;&#21307;&#30103;&#19987;&#19994;&#20154;&#21592;&#22312;&#23545;&#24739;&#32773;&#25191;&#34892;&#29305;&#23450;&#31243;&#24207;&#20043;&#21069;&#24517;&#39035;&#20107;&#20808;&#33719;&#24471;&#21355;&#29983;&#35745;&#21010;&#30340;&#25209;&#20934;&#65292;&#20197;&#20415;&#26377;&#36164;&#26684;&#33719;&#24471;&#25903;&#20184;&#35206;&#30422;&#12290;&#23545;&#21355;&#29983;&#20445;&#38505;&#20844;&#21496;&#26469;&#35828;&#65292;&#25209;&#20934;&#21307;&#30103;&#39046;&#22495;&#24739;&#32773;&#30340;PA&#35831;&#27714;&#26159;&#19968;&#39033;&#32791;&#26102;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20854;&#20013;&#30340;&#19968;&#39033;&#20851;&#38190;&#25361;&#25112;&#26159;&#39564;&#35777;&#35831;&#27714;&#26159;&#21542;&#31526;&#21512;&#26576;&#20123;&#26631;&#20934;&#65292;&#22914;&#24180;&#40836;&#12289;&#24615;&#21035;&#31561;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;GPT&#26159;&#21542;&#33021;&#39564;&#35777;&#22823;&#37327;&#20851;&#38190;&#22240;&#32032;&#65292;&#20174;&#32780;&#24110;&#21161;&#21355;&#29983;&#35745;&#21010;&#26356;&#24555;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#23558;&#20854;&#26500;&#24314;&#20026;&#19968;&#20010;&#38382;&#31572;&#20219;&#21153;&#65292;&#20419;&#20351;GPT&#20174;&#24739;&#32773;&#30340;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#22238;&#31572;&#38382;&#39064;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#19981;&#21516;&#30340;&#20256;&#32479;&#25552;&#31034;&#25216;&#26415;&#65292;&#21516;&#26102;&#36824;&#24341;&#20837;&#20102;&#25105;&#20204;&#33258;&#24049;&#30340;&#26032;&#39062;&#25552;&#31034;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18419v1 Announce Type: cross  Abstract: Health insurance companies have a defined process called prior authorization (PA) which is a health plan cost-control process that requires doctors and other healthcare professionals to get clearance in advance from a health plan before performing a particular procedure on a patient in order to be eligible for payment coverage. For health insurance companies, approving PA requests for patients in the medical domain is a time-consuming and challenging task. One of those key challenges is validating if a request matches up to certain criteria such as age, gender, etc. In this work, we evaluate whether GPT can validate numerous key factors, in turn helping health plans reach a decision drastically faster. We frame it as a question answering task, prompting GPT to answer a question from patient electronic health record. We experiment with different conventional prompting techniques as well as introduce our own novel prompting technique. Mo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#21644;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#25968;&#25454;&#38598;&#26465;&#20214;&#30340;&#39044;&#35757;&#32451;&#26435;&#37325;&#37319;&#26679;&#31574;&#30053;&#65292;&#29992;&#20110;&#25913;&#21892;&#36801;&#31227;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.18153</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#30340;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Diffusion-based Neural Network Weights Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18153
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#21644;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#25968;&#25454;&#38598;&#26465;&#20214;&#30340;&#39044;&#35757;&#32451;&#26435;&#37325;&#37319;&#26679;&#31574;&#30053;&#65292;&#29992;&#20110;&#25913;&#21892;&#36801;&#31227;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36801;&#31227;&#23398;&#20064;&#26159;&#36817;&#26399;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#20013;&#20855;&#26377;&#26174;&#33879;&#20852;&#36259;&#30340;&#35805;&#39064;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#23454;&#29616;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#22312;&#26032;&#20219;&#21153;&#19978;&#25913;&#21892;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36801;&#31227;&#23398;&#20064;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#28304;&#25968;&#25454;&#19982;&#30446;&#26631;&#25968;&#25454;&#30340;&#30456;&#20284;&#24615;&#65292;&#20294;&#22312;&#22823;&#37327;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#27169;&#22411;&#25104;&#26412;&#39640;&#26114;&#12290;&#22240;&#27492;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#36890;&#24120;&#26159;&#30450;&#30446;&#36873;&#25321;&#65292;&#24182;&#24076;&#26395;&#23427;&#20204;&#33021;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#20026;&#20102;&#35299;&#20915;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#27425;&#20248;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#25968;&#25454;&#38598;&#26465;&#20214;&#30340;&#39044;&#35757;&#32451;&#26435;&#37325;&#37319;&#26679;&#23454;&#29616;&#39640;&#25928;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#32467;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#21487;&#20197;&#37325;&#24314;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#65292;&#20197;&#23398;&#20064;&#27599;&#20010;&#25968;&#25454;&#38598;&#26465;&#20214;&#19979;&#19968;&#32452;&#39044;&#35757;&#32451;&#26435;&#37325;&#30340;&#20998;&#24067;&#65292;&#20174;&#32780;&#22312;&#26410;&#35265;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#36890;&#36807;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#20998;&#24067;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18153v1 Announce Type: cross  Abstract: Transfer learning is a topic of significant interest in recent deep learning research because it enables faster convergence and improved performance on new tasks. While the performance of transfer learning depends on the similarity of the source data to the target data, it is costly to train a model on a large number of datasets. Therefore, pretrained models are generally blindly selected with the hope that they will achieve good performance on the given task. To tackle such suboptimality of the pretrained models, we propose an efficient and adaptive transfer learning scheme through dataset-conditioned pretrained weights sampling. Specifically, we use a latent diffusion model with a variational autoencoder that can reconstruct the neural network weights, to learn the distribution of a set of pretrained weights conditioned on each dataset for transfer learning on unseen datasets. By learning the distribution of a neural network on a var
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;&#26041;&#27861;&#65292;&#26377;&#25928;&#24212;&#23545;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#31163;&#25955;&#20998;&#24067;&#65292;&#21253;&#25324;&#24490;&#29615;&#27493;&#38271;&#35843;&#24230;&#12289;&#24490;&#29615;&#24179;&#34913;&#35843;&#24230;&#21644;&#33258;&#21160;&#35843;&#25972;&#36229;&#21442;&#25968;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.17699</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Gradient-based Discrete Sampling with Automatic Cyclical Scheduling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17699
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;&#26041;&#27861;&#65292;&#26377;&#25928;&#24212;&#23545;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#31163;&#25955;&#20998;&#24067;&#65292;&#21253;&#25324;&#24490;&#29615;&#27493;&#38271;&#35843;&#24230;&#12289;&#24490;&#29615;&#24179;&#34913;&#35843;&#24230;&#21644;&#33258;&#21160;&#35843;&#25972;&#36229;&#21442;&#25968;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#20998;&#24067;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#32500;&#28145;&#24230;&#27169;&#22411;&#20013;&#65292;&#36890;&#24120;&#30001;&#20110;&#22266;&#26377;&#30340;&#19981;&#36830;&#32493;&#24615;&#32780;&#21576;&#29616;&#39640;&#24230;&#22810;&#27169;&#24577;&#12290;&#34429;&#28982;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#30001;&#20110;&#26799;&#24230;&#20449;&#24687;&#65292;&#23427;&#23481;&#26131;&#38519;&#20837;&#23616;&#37096;&#27169;&#24335;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;&#22810;&#27169;&#24577;&#31163;&#25955;&#20998;&#24067;&#36827;&#34892;&#39640;&#25928;&#20934;&#30830;&#30340;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#37096;&#20998;&#65306;&#65288;1&#65289;&#24490;&#29615;&#27493;&#38271;&#35843;&#24230;&#65292;&#20854;&#20013;&#22823;&#27493;&#38271;&#21457;&#29616;&#26032;&#27169;&#24335;&#65292;&#23567;&#27493;&#38271;&#21033;&#29992;&#27599;&#20010;&#27169;&#24335;&#65307;&#65288;2&#65289;&#24490;&#29615;&#24179;&#34913;&#35843;&#24230;&#65292;&#30830;&#20445;&#32473;&#23450;&#27493;&#38271;&#30340;&#8220;&#24179;&#34913;&#8221;&#25552;&#26696;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#39640;&#25928;&#29575;&#65307;&#20197;&#21450;&#65288;3&#65289;&#33258;&#21160;&#35843;&#25972;&#26041;&#26696;&#65292;&#29992;&#20110;&#35843;&#25972;&#24490;&#29615;&#35843;&#24230;&#20013;&#30340;&#36229;&#21442;&#25968;&#65292;&#23454;&#29616;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#33258;&#36866;&#24212;&#24615;&#19988;&#38656;&#26368;&#23567;&#35843;&#25972;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#21644;&#25512;&#26029;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17699v1 Announce Type: new  Abstract: Discrete distributions, particularly in high-dimensional deep models, are often highly multimodal due to inherent discontinuities. While gradient-based discrete sampling has proven effective, it is susceptible to becoming trapped in local modes due to the gradient information. To tackle this challenge, we propose an automatic cyclical scheduling, designed for efficient and accurate sampling in multimodal discrete distributions. Our method contains three key components: (1) a cyclical step size schedule where large steps discover new modes and small steps exploit each mode; (2) a cyclical balancing schedule, ensuring ``balanced" proposals for given step sizes and high efficiency of the Markov chain; and (3) an automatic tuning scheme for adjusting the hyperparameters in the cyclical schedules, allowing adaptability across diverse datasets with minimal tuning. We prove the non-asymptotic convergence and inference guarantee for our method i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#22270;&#25193;&#25955;&#31574;&#30053;&#20248;&#21270;&#65288;GDPO&#65289;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#20026;&#20219;&#24847;&#30446;&#26631;&#20248;&#21270;&#22270;&#25193;&#25955;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#21508;&#31181;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.16302</link><description>&lt;p&gt;
&#22270;&#25193;&#25955;&#31574;&#30053;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Graph Diffusion Policy Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#22270;&#25193;&#25955;&#31574;&#30053;&#20248;&#21270;&#65288;GDPO&#65289;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#20026;&#20219;&#24847;&#30446;&#26631;&#20248;&#21270;&#22270;&#25193;&#25955;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#21508;&#31181;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#22312;&#20248;&#21270;&#25193;&#25955;&#27169;&#22411;&#20197;&#23454;&#29616;&#29305;&#23450;&#19979;&#28216;&#30446;&#26631;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#36825;&#23545;&#20110;&#39046;&#22495;&#22914;&#33647;&#29289;&#35774;&#35745;&#20013;&#30340;&#22270;&#29983;&#25104;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#36861;&#27714;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22270;&#25193;&#25955;&#23384;&#22312;&#25361;&#25112;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#25193;&#25955;&#31574;&#30053;&#20248;&#21270;&#65288;GDPO&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#20026;&#20219;&#24847;&#65288;&#22914;&#38750;&#21487;&#24494;&#20998;&#65289;&#30446;&#26631;&#20248;&#21270;&#22270;&#25193;&#25955;&#27169;&#22411;&#12290;GDPO&#22522;&#20110;&#38024;&#23545;&#22270;&#25193;&#25955;&#27169;&#22411;&#37327;&#36523;&#23450;&#21046;&#30340;&#24613;&#20999;&#31574;&#30053;&#26799;&#24230;&#65292;&#36890;&#36807;&#35748;&#30495;&#20998;&#26512;&#24320;&#21457;&#65292;&#26377;&#26395;&#25552;&#39640;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;GDPO&#22312;&#20855;&#26377;&#22797;&#26434;&#21644;&#22810;&#26679;&#21270;&#30446;&#26631;&#30340;&#21508;&#31181;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/sail-sg/GDPO&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16302v1 Announce Type: cross  Abstract: Recent research has made significant progress in optimizing diffusion models for specific downstream objectives, which is an important pursuit in fields such as graph generation for drug design. However, directly applying these models to graph diffusion presents challenges, resulting in suboptimal performance. This paper introduces graph diffusion policy optimization (GDPO), a novel approach to optimize graph diffusion models for arbitrary (e.g., non-differentiable) objectives using reinforcement learning. GDPO is based on an eager policy gradient tailored for graph diffusion models, developed through meticulous analysis and promising improved performance. Experimental results show that GDPO achieves state-of-the-art performance in various graph generation tasks with complex and diverse objectives. Code is available at https://github.com/sail-sg/GDPO.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20915;&#31574;&#35821;&#35328;&#27169;&#22411;DLM&#65292;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;LLMs&#20316;&#20026;&#33258;&#21160;&#35268;&#21010;&#22120;&#65292;&#21160;&#24577;&#24494;&#35843;RMAB&#31574;&#30053;&#65292;&#20197;&#24212;&#23545;&#20844;&#20849;&#21355;&#29983;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#22659;&#12290;</title><link>https://arxiv.org/abs/2402.14807</link><description>&lt;p&gt;
&#29992;&#20110;&#20844;&#20849;&#21355;&#29983;&#20013;&#21160;&#24577;&#19981;&#23433;&#38745;&#22810;&#33218;&#32769;&#34382;&#26426;&#20219;&#21153;&#30340;&#20915;&#31574;&#35821;&#35328;&#27169;&#22411;&#65288;DLM&#65289;
&lt;/p&gt;
&lt;p&gt;
A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14807
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20915;&#31574;&#35821;&#35328;&#27169;&#22411;DLM&#65292;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;LLMs&#20316;&#20026;&#33258;&#21160;&#35268;&#21010;&#22120;&#65292;&#21160;&#24577;&#24494;&#35843;RMAB&#31574;&#30053;&#65292;&#20197;&#24212;&#23545;&#20844;&#20849;&#21355;&#29983;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26088;&#22312;&#38477;&#20302;&#23381;&#20135;&#22919;&#27515;&#20129;&#29575;&#30340;&#21162;&#21147;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#39044;&#38450;&#20445;&#20581;&#35745;&#21010;&#65292;&#21521;&#39640;&#39118;&#38505;&#20154;&#32676;&#20256;&#25773;&#37325;&#35201;&#30340;&#20581;&#24247;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;DLM&#65306;&#19968;&#31181;&#29992;&#20110;RMAB&#30340;&#20915;&#31574;&#35821;&#35328;&#27169;&#22411;&#65292;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;LLMs&#20316;&#20026;&#33258;&#21160;&#35268;&#21010;&#22120;&#65292;&#21160;&#24577;&#24494;&#35843;RMAB&#31574;&#30053;&#65292;&#20197;&#24212;&#23545;&#20844;&#20849;&#21355;&#29983;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14807v1 Announce Type: cross  Abstract: Efforts to reduce maternal mortality rate, a key UN Sustainable Development target (SDG Target 3.1), rely largely on preventative care programs to spread critical health information to high-risk populations. These programs face two important challenges: efficiently allocating limited health resources to large beneficiary populations, and adapting to evolving policy priorities. While prior works in restless multi-armed bandit (RMAB) demonstrated success in public health allocation tasks, they lack flexibility to adapt to evolving policy priorities. Concurrently, Large Language Models (LLMs) have emerged as adept, automated planners in various domains, including robotic control and navigation. In this paper, we propose DLM: a Decision Language Model for RMABs. To enable dynamic fine-tuning of RMAB policies for challenging public health settings using human-language commands, we propose using LLMs as automated planners to (1) interpret hu
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ACE&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22240;&#26524;&#24863;&#30693;&#29109;&#27491;&#21017;&#21270;&#65292;&#26377;&#25928;&#35780;&#20272;&#19981;&#21516;&#34892;&#20026;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#20998;&#26512;&#26799;&#24230;&#20241;&#30496;&#29616;&#35937;&#65292;&#24341;&#20837;&#20241;&#30496;&#24341;&#23548;&#22797;&#20301;&#26426;&#21046;&#65292;&#22312;&#22810;&#20010;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#24615;&#33021;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.14528</link><description>&lt;p&gt;
ACE&#65306;&#20855;&#26377;&#22240;&#26524;&#24863;&#30693;&#29109;&#27491;&#21017;&#21270;&#30340;&#31163;&#31574;&#30053;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
ACE : Off-Policy Actor-Critic with Causality-Aware Entropy Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14528
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ACE&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22240;&#26524;&#24863;&#30693;&#29109;&#27491;&#21017;&#21270;&#65292;&#26377;&#25928;&#35780;&#20272;&#19981;&#21516;&#34892;&#20026;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#20998;&#26512;&#26799;&#24230;&#20241;&#30496;&#29616;&#35937;&#65292;&#24341;&#20837;&#20241;&#30496;&#24341;&#23548;&#22797;&#20301;&#26426;&#21046;&#65292;&#22312;&#22810;&#20010;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#24573;&#35270;&#20102;&#31574;&#30053;&#23398;&#20064;&#36807;&#31243;&#20013;&#19981;&#21516;&#21407;&#22987;&#34892;&#20026;&#30340;&#21464;&#21270;&#37325;&#35201;&#24615;&#12290;&#21033;&#29992;&#36825;&#19968;&#35266;&#28857;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#19981;&#21516;&#21160;&#20316;&#32500;&#24230;&#21644;&#22870;&#21169;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20197;&#35780;&#20272;&#35757;&#32451;&#36807;&#31243;&#20013;&#21508;&#31181;&#21407;&#22987;&#34892;&#20026;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22240;&#26524;&#24863;&#30693;&#29109;&#39033;&#65292;&#26377;&#25928;&#22320;&#35782;&#21035;&#24182;&#20248;&#20808;&#22788;&#29702;&#20855;&#26377;&#39640;&#28508;&#22312;&#24433;&#21709;&#30340;&#34892;&#21160;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#38450;&#27490;&#23545;&#29305;&#23450;&#21407;&#22987;&#34892;&#20026;&#36807;&#24230;&#20851;&#27880;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#26799;&#24230;&#20241;&#30496;&#29616;&#35937;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#20241;&#30496;&#24341;&#23548;&#22797;&#20301;&#26426;&#21046;&#65292;&#36827;&#19968;&#27493;&#22686;&#24378;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;ACE&#65306;&#20855;&#26377;&#22240;&#26524;&#24863;&#30693;&#29109;&#27491;&#21017;&#21270;&#30340;&#31163;&#31574;&#28436;&#21592;-&#35780;&#35770;&#23478;&#65292;&#22312;&#36328;7&#20010;&#39046;&#22495;&#30340;29&#20010;&#19981;&#21516;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#20013;&#65292;&#30456;&#36739;&#20110;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#22522;&#32447;&#65292;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14528v1 Announce Type: cross  Abstract: The varying significance of distinct primitive behaviors during the policy learning process has been overlooked by prior model-free RL algorithms. Leveraging this insight, we explore the causal relationship between different action dimensions and rewards to evaluate the significance of various primitive behaviors during training. We introduce a causality-aware entropy term that effectively identifies and prioritizes actions with high potential impacts for efficient exploration. Furthermore, to prevent excessive focus on specific primitive behaviors, we analyze the gradient dormancy phenomenon and introduce a dormancy-guided reset mechanism to further enhance the efficacy of our method. Our proposed algorithm, ACE: Off-policy Actor-critic with Causality-aware Entropy regularization, demonstrates a substantial performance advantage across 29 diverse continuous control tasks spanning 7 domains compared to model-free RL baselines, which un
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#27010;&#29575;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20998;&#24067;&#20540;&#26469;&#35299;&#20915;&#24403;&#21069;&#26041;&#27861;&#22312;&#35299;&#37322;&#27169;&#22411;&#36755;&#20986;&#26102;&#30340;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#25552;&#20379;&#30340;&#35814;&#32454;&#21644;&#26377;&#27934;&#23519;&#21147;&#30340;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2402.09947</link><description>&lt;p&gt;
&#29992;&#20998;&#24067;&#20540;&#35299;&#37322;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Explaining Probabilistic Models with Distributional Values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#27010;&#29575;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20998;&#24067;&#20540;&#26469;&#35299;&#20915;&#24403;&#21069;&#26041;&#27861;&#22312;&#35299;&#37322;&#27169;&#22411;&#36755;&#20986;&#26102;&#30340;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#25552;&#20379;&#30340;&#35814;&#32454;&#21644;&#26377;&#27934;&#23519;&#21147;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#37325;&#35201;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20998;&#25903;&#22522;&#20110;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#12290;&#28982;&#32780;&#65292;&#30740;&#31350;&#34920;&#26126;&#21338;&#24328;&#29702;&#35770;&#35299;&#37322;&#21487;&#33021;&#20250;&#35823;&#23548;&#25110;&#38590;&#20197;&#35299;&#37322;&#12290;&#25105;&#20204;&#35748;&#20026;&#36890;&#24120;&#23384;&#22312;&#30528;&#19968;&#20010;&#37325;&#35201;&#30340;&#19981;&#21305;&#37197;&#65292;&#21363;&#20154;&#20204;&#24076;&#26395;&#35299;&#37322;&#30340;&#20869;&#23481;&#65288;&#20363;&#22914;&#20998;&#31867;&#22120;&#30340;&#36755;&#20986;&#65289;&#19982;&#24403;&#21069;&#30340;&#26041;&#27861;&#65288;&#20363;&#22914;SHAP&#65289;&#25152;&#35299;&#37322;&#30340;&#20869;&#23481;&#65288;&#20363;&#22914;&#31867;&#21035;&#30340;&#27010;&#29575;&#65289;&#20043;&#38388;&#12290;&#26412;&#25991;&#36890;&#36807;&#25512;&#24191;&#21512;&#20316;&#21338;&#24328;&#21644;&#20215;&#20540;&#31639;&#23376;&#65292;&#26469;&#35299;&#20915;&#27010;&#29575;&#27169;&#22411;&#30340;&#36825;&#31181;&#24046;&#36317;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#24067;&#20540;&#65292;&#36825;&#26159;&#19968;&#31181;&#38543;&#26426;&#21464;&#37327;&#65292;&#29992;&#20110;&#36861;&#36394;&#27169;&#22411;&#36755;&#20986;&#30340;&#21464;&#21270;&#65288;&#20363;&#22914;&#39044;&#27979;&#31867;&#21035;&#30340;&#21453;&#36716;&#65289;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#22312;&#20855;&#26377;&#39640;&#26031;&#12289;&#20271;&#21162;&#21033;&#21644;&#20998;&#31867;&#25903;&#20184;&#30340;&#21338;&#24328;&#20013;&#30340;&#20998;&#24067;&#20540;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24314;&#31435;&#20102;&#20960;&#20010;&#29305;&#24615;&#65292;&#24182;&#36890;&#36807;&#23545;&#35270;&#35273;&#21644;&#35821;&#35328;&#27169;&#22411;&#30340;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#32454;&#31890;&#24230;&#21644;&#26377;&#27934;&#23519;&#21147;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09947v1 Announce Type: new  Abstract: A large branch of explainable machine learning is grounded in cooperative game theory. However, research indicates that game-theoretic explanations may mislead or be hard to interpret. We argue that often there is a critical mismatch between what one wishes to explain (e.g. the output of a classifier) and what current methods such as SHAP explain (e.g. the scalar probability of a class). This paper addresses such gap for probabilistic models by generalising cooperative games and value operators. We introduce the distributional values, random variables that track changes in the model output (e.g. flipping of the predicted class) and derive their analytic expressions for games with Gaussian, Bernoulli and Categorical payoffs. We further establish several characterising properties, and show that our framework provides fine-grained and insightful explanations with case studies on vision and language models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.05162</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#35780;&#20272;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20854;&#23433;&#20840;&#26426;&#21046;&#26041;&#38754;&#34920;&#29616;&#20986;&#22266;&#26377;&#30340;&#26131;&#30862;&#24615;&#65292;&#36825;&#21487;&#20174;&#23427;&#20204;&#26131;&#21463;&#36234;&#29425;&#21644;&#21363;&#20351;&#26159;&#38750;&#24694;&#24847;&#24494;&#35843;&#20063;&#26131;&#21463;&#24433;&#21709;&#26469;&#35828;&#26126;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#25506;&#35752;&#20102;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#23545;&#20110;&#23433;&#20840;&#38450;&#25252;&#33267;&#20851;&#37325;&#35201;&#65292;&#19988;&#22312;&#31070;&#32463;&#20803;&#21644;&#31209;&#32423;&#21035;&#19978;&#19982;&#25928;&#29992;&#30456;&#20851;&#30340;&#21306;&#22495;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#30340;&#23396;&#31435;&#21306;&#22495;&#26159;&#31232;&#30095;&#30340;&#65292;&#32422;&#21344;&#21442;&#25968;&#32423;&#21035;&#30340;$3\%$&#21644;&#25490;&#21517;&#32423;&#21035;&#30340;$2.5\%$&#12290;&#21435;&#38500;&#36825;&#20123;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#32780;&#23545;&#25928;&#29992;&#30340;&#24433;&#21709;&#19981;&#22823;&#65292;&#20174;&#32780;&#35777;&#23454;&#20102;&#35813;&#27169;&#22411;&#23433;&#20840;&#26426;&#21046;&#30340;&#22266;&#26377;&#26131;&#30862;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#21363;&#20351;&#38480;&#21046;&#23545;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#36827;&#34892;&#20462;&#25913;&#65292;LLMs&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#20302;&#25104;&#26412;&#30340;&#24494;&#35843;&#25915;&#20987;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;LLMs&#20013;&#26356;&#24378;&#22823;&#30340;&#23433;&#20840;&#31574;&#30053;&#30340;&#32039;&#36843;&#24615;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3\%$ at the parameter level and $2.5\%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model's safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#22635;&#20805;&#32570;&#22833;&#25968;&#25454;&#26102;&#23558;&#26631;&#31614;&#19982;&#36755;&#20837;&#22534;&#21472;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22635;&#20805;&#25928;&#26524;&#65292;&#24182;&#21516;&#26102;&#22635;&#20805;&#26631;&#31614;&#21644;&#36755;&#20837;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20855;&#26377;&#26377;&#24076;&#26395;&#30340;&#20934;&#30830;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.16877</link><description>&lt;p&gt;
&#20351;&#29992;&#35757;&#32451;&#26631;&#31614;&#36827;&#34892;&#22635;&#20805;&#21644;&#36890;&#36807;&#26631;&#31614;&#22635;&#20805;&#36827;&#34892;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Imputation using training labels and classification via label imputation. (arXiv:2311.16877v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.16877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#22635;&#20805;&#32570;&#22833;&#25968;&#25454;&#26102;&#23558;&#26631;&#31614;&#19982;&#36755;&#20837;&#22534;&#21472;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22635;&#20805;&#25928;&#26524;&#65292;&#24182;&#21516;&#26102;&#22635;&#20805;&#26631;&#31614;&#21644;&#36755;&#20837;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20855;&#26377;&#26377;&#24076;&#26395;&#30340;&#20934;&#30830;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#32570;&#22833;&#25968;&#25454;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#22635;&#20805;&#26041;&#27861;&#26469;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35757;&#32451;&#25968;&#25454;&#36890;&#24120;&#37117;&#26377;&#26631;&#31614;&#65292;&#20294;&#24120;&#35265;&#30340;&#22635;&#20805;&#26041;&#27861;&#36890;&#24120;&#21482;&#20381;&#36182;&#20110;&#36755;&#20837;&#32780;&#24573;&#30053;&#26631;&#31614;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;&#23558;&#26631;&#31614;&#22534;&#21472;&#21040;&#36755;&#20837;&#20013;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#36755;&#20837;&#30340;&#22635;&#20805;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#23558;&#39044;&#27979;&#30340;&#27979;&#35797;&#26631;&#31614;&#21021;&#22987;&#21270;&#20026;&#32570;&#22833;&#20540;&#65292;&#24182;&#23558;&#26631;&#31614;&#19982;&#36755;&#20837;&#22534;&#21472;&#22312;&#19968;&#36215;&#36827;&#34892;&#22635;&#20805;&#12290;&#36825;&#26679;&#21487;&#20197;&#21516;&#26102;&#22635;&#20805;&#26631;&#31614;&#21644;&#36755;&#20837;&#12290;&#32780;&#19988;&#65292;&#35813;&#25216;&#26415;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#32570;&#22833;&#26631;&#31614;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#26080;&#38656;&#20219;&#20309;&#20808;&#21069;&#30340;&#22635;&#20805;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#36830;&#32493;&#22411;&#12289;&#20998;&#31867;&#22411;&#25110;&#28151;&#21512;&#22411;&#25968;&#25454;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing data is a common problem in practical settings. Various imputation methods have been developed to deal with missing data. However, even though the label is usually available in the training data, the common practice of imputation usually only relies on the input and ignores the label. In this work, we illustrate how stacking the label into the input can significantly improve the imputation of the input. In addition, we propose a classification strategy that initializes the predicted test label with missing values and stacks the label with the input for imputation. This allows imputing the label and the input at the same time. Also, the technique is capable of handling data training with missing labels without any prior imputation and is applicable to continuous, categorical, or mixed-type data. Experiments show promising results in terms of accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#20223;&#30495;&#22120;&#22312;&#32447;&#35757;&#32451;&#20122;&#32593;&#26684;&#21442;&#25968;&#21270;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21518;&#39564;&#25439;&#22833;&#20989;&#25968;&#36866;&#24212;&#38750;&#21487;&#24494;&#20998;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#24182;&#36890;&#36807;&#26102;&#38388;&#31215;&#20998;&#27493;&#39588;&#20801;&#35768;&#26799;&#24230;&#20256;&#25773;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#23558;&#31070;&#32463;&#20223;&#30495;&#22120;&#21644;&#21442;&#25968;&#21270;&#32452;&#20214;&#20998;&#21035;&#29992;&#30456;&#24212;&#30340;&#25439;&#22833;&#37327;&#36827;&#34892;&#35757;&#32451;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#26368;&#23567;&#21270;&#26576;&#20123;&#36817;&#20284;&#20559;&#24046;&#30340;&#20256;&#25773;&#12290;</title><link>http://arxiv.org/abs/2310.19385</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#20223;&#30495;&#22120;&#30340;&#26080;&#26799;&#24230;&#22312;&#32447;&#23398;&#20064;&#20122;&#32593;&#26684;&#23610;&#24230;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Gradient-free online learning of subgrid-scale dynamics with neural emulators. (arXiv:2310.19385v2 [physics.comp-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19385
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#20223;&#30495;&#22120;&#22312;&#32447;&#35757;&#32451;&#20122;&#32593;&#26684;&#21442;&#25968;&#21270;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21518;&#39564;&#25439;&#22833;&#20989;&#25968;&#36866;&#24212;&#38750;&#21487;&#24494;&#20998;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#24182;&#36890;&#36807;&#26102;&#38388;&#31215;&#20998;&#27493;&#39588;&#20801;&#35768;&#26799;&#24230;&#20256;&#25773;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#23558;&#31070;&#32463;&#20223;&#30495;&#22120;&#21644;&#21442;&#25968;&#21270;&#32452;&#20214;&#20998;&#21035;&#29992;&#30456;&#24212;&#30340;&#25439;&#22833;&#37327;&#36827;&#34892;&#35757;&#32451;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#26368;&#23567;&#21270;&#26576;&#20123;&#36817;&#20284;&#20559;&#24046;&#30340;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#35757;&#32451;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20122;&#32593;&#26684;&#21442;&#25968;&#21270;&#65292;&#24182;&#36890;&#36807;&#21518;&#39564;&#25439;&#22833;&#20989;&#25968;&#36866;&#24212;&#38750;&#21487;&#24494;&#20998;&#25968;&#20540;&#27714;&#35299;&#22120;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#31070;&#32463;&#20223;&#30495;&#22120;&#35757;&#32451;&#31616;&#21270;&#29366;&#24577;&#31354;&#38388;&#27714;&#35299;&#22120;&#30340;&#36817;&#20284;&#20540;&#65292;&#28982;&#21518;&#36890;&#36807;&#26102;&#38388;&#31215;&#20998;&#27493;&#39588;&#20801;&#35768;&#26799;&#24230;&#20256;&#25773;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#19981;&#35745;&#31639;&#21407;&#22987;&#27714;&#35299;&#22120;&#26799;&#24230;&#30340;&#24773;&#20917;&#19979;&#24674;&#22797;&#22823;&#37096;&#20998;&#22312;&#32447;&#31574;&#30053;&#30340;&#22909;&#22788;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#23558;&#31070;&#32463;&#20223;&#30495;&#22120;&#21644;&#21442;&#25968;&#21270;&#32452;&#20214;&#20998;&#21035;&#29992;&#30456;&#24212;&#30340;&#25439;&#22833;&#37327;&#36827;&#34892;&#35757;&#32451;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#26368;&#23567;&#21270;&#26576;&#20123;&#36817;&#20284;&#20559;&#24046;&#30340;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a generic algorithm to train machine learning-based subgrid parametrizations online, i.e., with $\textit{a posteriori}$ loss functions for non-differentiable numerical solvers. The proposed approach leverage neural emulators to train an approximation of the reduced state-space solver, which is then used to allows gradient propagation through temporal integration steps. The algorithm is able to recover most of the benefit of online strategies without having to compute the gradient of the original solver. It is demonstrated that training the neural emulator and parametrization components separately with respective loss quantities is necessary in order to minimize the propagation of some approximation bias.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38598;&#20013;&#24335;&#35757;&#32451;&#21644;&#20998;&#24067;&#24335;&#25191;&#34892;&#26041;&#27861;&#65292;&#20197;&#22312;&#32447;&#35299;&#20915;&#21160;&#24577;&#38556;&#30861;&#29289;&#36991;&#38556;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16659</link><description>&lt;p&gt;
&#26080;&#20154;&#26426;&#22312;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21160;&#24577;&#36991;&#38556;&#36335;&#24452;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
UAV Pathfinding in Dynamic Obstacle Avoidance with Multi-agent Reinforcement Learning. (arXiv:2310.16659v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38598;&#20013;&#24335;&#35757;&#32451;&#21644;&#20998;&#24067;&#24335;&#25191;&#34892;&#26041;&#27861;&#65292;&#20197;&#22312;&#32447;&#35299;&#20915;&#21160;&#24577;&#38556;&#30861;&#29289;&#36991;&#38556;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#21160;&#24577;&#21644;&#19981;&#30830;&#23450;&#30340;&#22330;&#26223;&#20013;&#22312;&#32447;&#35268;&#21010;&#26234;&#33021;&#20307;&#30340;&#21487;&#34892;&#19988;&#23433;&#20840;&#30340;&#36335;&#24452;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38598;&#20013;&#24335;&#35757;&#32451;&#21644;&#20998;&#24067;&#24335;&#25191;&#34892;&#26041;&#27861;&#65292;&#20197;&#22312;&#32447;&#35299;&#20915;&#21160;&#24577;&#38556;&#30861;&#29289;&#36991;&#38556;&#38382;&#39064;&#12290;&#22312;&#35813;&#26041;&#27861;&#20013;&#65292;&#27599;&#20010;&#26234;&#33021;&#20307;&#20165;&#19982;&#20013;&#22830;&#35268;&#21010;&#32773;&#25110;&#20854;&#37051;&#23621;&#36827;&#34892;&#36890;&#20449;&#65292;&#20197;&#22312;&#32447;&#35268;&#21010;&#21487;&#34892;&#19988;&#23433;&#20840;&#30340;&#36335;&#24452;&#12290;&#25105;&#20204;&#22522;&#20110;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#30340;&#24605;&#24819;&#25913;&#36827;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#26234;&#33021;&#20307;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#37319;&#26679;&#21033;&#29992;&#29575;&#12290;&#22312;&#27169;&#25311;&#12289;&#23460;&#20869;&#21644;&#23460;&#22806;&#29615;&#22659;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-agent reinforcement learning based methods are significant for online planning of feasible and safe paths for agents in dynamic and uncertain scenarios. Although some methods like fully centralized and fully decentralized methods achieve a certain measure of success, they also encounter problems such as dimension explosion and poor convergence, respectively. In this paper, we propose a novel centralized training with decentralized execution method based on multi-agent reinforcement learning to solve the dynamic obstacle avoidance problem online. In this approach, each agent communicates only with the central planner or only with its neighbors, respectively, to plan feasible and safe paths online. We improve our methods based on the idea of model predictive control to increase the training efficiency and sample utilization of agents. The experimental results in both simulation, indoor, and outdoor environments validate the effectiveness of our method. The video is available at htt
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#35821;&#35328;&#27169;&#22411;&#65288;PPLM&#65289;&#30340;&#26032;&#33539;&#24335;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#26377;&#25928;&#27880;&#20837;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#35774;&#35745;&#30340;&#29702;&#35770;&#20998;&#26512;&#21644;&#19981;&#21516;&#25216;&#26415;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#20351;&#29992;&#27491;&#21521;&#21644;&#36127;&#21521;&#31034;&#20363;&#36827;&#34892;&#25351;&#20196;&#24494;&#35843;&#30340;&#26041;&#27861;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.02469</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25104;&#20026;&#33391;&#22909;&#30340;&#38544;&#31169;&#20445;&#25252;&#23398;&#20064;&#32773;
&lt;/p&gt;
&lt;p&gt;
Large Language Models Can Be Good Privacy Protection Learners. (arXiv:2310.02469v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#35821;&#35328;&#27169;&#22411;&#65288;PPLM&#65289;&#30340;&#26032;&#33539;&#24335;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#26377;&#25928;&#27880;&#20837;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#35774;&#35745;&#30340;&#29702;&#35770;&#20998;&#26512;&#21644;&#19981;&#21516;&#25216;&#26415;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#20351;&#29992;&#27491;&#21521;&#21644;&#36127;&#21521;&#31034;&#20363;&#36827;&#34892;&#25351;&#20196;&#24494;&#35843;&#30340;&#26041;&#27861;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26222;&#21450;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#20351;&#29992;&#29305;&#23450;&#39046;&#22495;&#25968;&#25454;&#23545;&#20854;&#36827;&#34892;&#24494;&#35843;&#65292;&#21019;&#24314;&#19987;&#38376;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#29305;&#23450;&#39046;&#22495;&#30340;&#24494;&#35843;&#25968;&#25454;&#36890;&#24120;&#21253;&#21547;&#25935;&#24863;&#30340;&#20010;&#20154;&#36523;&#20221;&#20449;&#24687;&#65288;PII&#65289;&#12290;&#22312;&#27809;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;&#24773;&#20917;&#19979;&#30452;&#25509;&#24494;&#35843; LLMs &#20250;&#23384;&#22312;&#20449;&#24687;&#27844;&#38706;&#30340;&#39118;&#38505;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#38544;&#31169;&#20445;&#25252;&#35821;&#35328;&#27169;&#22411;&#65288;PPLM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#26377;&#25928;&#27880;&#20837;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#30340;&#21516;&#26102;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#26032;&#33539;&#24335;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20379;&#20102;&#27169;&#22411;&#35774;&#35745;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#28145;&#20837;&#30740;&#31350;&#20102;&#21508;&#31181;&#25216;&#26415;&#65292;&#27604;&#22914;&#35821;&#26009;&#24211;&#31574;&#23637;&#12289;&#22522;&#20110;&#24809;&#32602;&#30340;&#38750;&#27010;&#28982;&#24615;&#35757;&#32451;&#25439;&#22833;&#20197;&#21450;&#22522;&#20110;&#25351;&#20196;&#30340;&#24494;&#35843;&#31561;&#31561;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#21644;&#22330;&#26223;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#20351;&#29992;&#27491;&#21521;&#21644;&#36127;&#21521;&#31034;&#20363;&#36827;&#34892;&#25351;&#20196;&#24494;&#35843;&#65292;&#26174;&#31034;&#20986;&#24456;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The proliferation of Large Language Models (LLMs) has driven considerable interest in fine-tuning them with domain-specific data to create specialized language models. Nevertheless, such domain-specific fine-tuning data often contains sensitive personally identifiable information (PII). Direct fine-tuning LLMs on this data without privacy protection poses a risk of leakage. To address this challenge, we introduce Privacy Protection Language Models (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects domain-specific knowledge while safeguarding data privacy. Our work offers a theoretical analysis for model design and delves into various techniques such as corpus curation, penalty-based unlikelihood in training loss, and instruction-based tuning, etc. Extensive experiments across diverse datasets and scenarios demonstrate the effectiveness of our approaches. In particular, instruction tuning with both positive and negative examples, stands out as a promising method, eff
&lt;/p&gt;</description></item><item><title>&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#26159;&#19968;&#31181;&#20851;&#31995;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23478;&#26063;&#65292;&#29992;&#20110;&#22312;&#20851;&#31995;&#39046;&#22495;&#25552;&#20379;&#21487;&#35299;&#37322;&#30340;&#20219;&#21153;&#39044;&#27979;&#65292;&#30456;&#27604;&#38750;&#20851;&#31995;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#27169;&#22411;&#65292;&#23427;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#19982;&#29616;&#26377;&#30340;&#20851;&#31995;&#27169;&#22411;&#30456;&#21305;&#37197;&#65292;&#24182;&#25903;&#25345;&#29983;&#25104;&#37327;&#21270;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#65292;&#21516;&#26102;&#22312;&#27979;&#35797;&#26102;&#24178;&#39044;&#12289;&#36229;&#20986;&#20998;&#24067;&#24773;&#26223;&#12289;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#33539;&#22260;&#21644;&#31232;&#32570;&#30340;&#27010;&#24565;&#30417;&#30563;&#31561;&#33499;&#21051;&#26465;&#20214;&#19979;&#20063;&#33021;&#26377;&#25928;&#24212;&#23545;&#12290;</title><link>http://arxiv.org/abs/2308.11991</link><description>&lt;p&gt;
&#20851;&#20110;&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Relational Concept Based Models. (arXiv:2308.11991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11991
&lt;/p&gt;
&lt;p&gt;
&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#26159;&#19968;&#31181;&#20851;&#31995;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23478;&#26063;&#65292;&#29992;&#20110;&#22312;&#20851;&#31995;&#39046;&#22495;&#25552;&#20379;&#21487;&#35299;&#37322;&#30340;&#20219;&#21153;&#39044;&#27979;&#65292;&#30456;&#27604;&#38750;&#20851;&#31995;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#27169;&#22411;&#65292;&#23427;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#19982;&#29616;&#26377;&#30340;&#20851;&#31995;&#27169;&#22411;&#30456;&#21305;&#37197;&#65292;&#24182;&#25903;&#25345;&#29983;&#25104;&#37327;&#21270;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#65292;&#21516;&#26102;&#22312;&#27979;&#35797;&#26102;&#24178;&#39044;&#12289;&#36229;&#20986;&#20998;&#24067;&#24773;&#26223;&#12289;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#33539;&#22260;&#21644;&#31232;&#32570;&#30340;&#27010;&#24565;&#30417;&#30563;&#31561;&#33499;&#21051;&#26465;&#20214;&#19979;&#20063;&#33021;&#26377;&#25928;&#24212;&#23545;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20851;&#31995;&#39046;&#22495;&#20013;&#35774;&#35745;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#25361;&#25112;&#65306;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#22522;&#20110;&#27010;&#24565;&#30340;&#27169;&#22411;&#65288;CBMs&#65289;&#65292;&#24182;&#27809;&#26377;&#35774;&#35745;&#26469;&#35299;&#20915;&#20851;&#31995;&#38382;&#39064;&#65292;&#32780;&#20851;&#31995;&#27169;&#22411;&#20063;&#27809;&#26377;&#20687;CBMs&#37027;&#26679;&#21487;&#35299;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#31181;&#25552;&#20379;&#21487;&#35299;&#37322;&#20219;&#21153;&#39044;&#27979;&#30340;&#20851;&#31995;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23478;&#26063;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20174;&#22270;&#20687;&#20998;&#31867;&#21040;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#38142;&#25509;&#39044;&#27979;&#65292;&#34920;&#26126;&#20851;&#31995;CBMs&#65306;&#65288;i&#65289;&#19982;&#29616;&#26377;&#30340;&#20851;&#31995;&#40657;&#30418;&#30340;&#27867;&#21270;&#24615;&#33021;&#30456;&#21305;&#37197;&#65288;&#19981;&#21516;&#20110;&#38750;&#20851;&#31995;&#30340;CBMs&#65289;&#65292;&#65288;ii&#65289;&#25903;&#25345;&#29983;&#25104;&#37327;&#21270;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#65292;&#65288;iii&#65289;&#26377;&#25928;&#24212;&#23545;&#27979;&#35797;&#26102;&#30340;&#24178;&#39044;&#65292;&#20197;&#21450;&#65288;iv&#65289;&#32463;&#21463;&#20303;&#21253;&#25324;&#36229;&#20986;&#20998;&#24067;&#24773;&#26223;&#12289;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#33539;&#22260;&#21644;&#31232;&#32570;&#30340;&#27010;&#24565;&#30417;&#30563;&#31561;&#33499;&#21051;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
The design of interpretable deep learning models working in relational domains poses an open challenge: interpretable deep learning methods, such as Concept-Based Models (CBMs), are not designed to solve relational problems, while relational models are not as interpretable as CBMs. To address this problem, we propose Relational Concept-Based Models, a family of relational deep learning methods providing interpretable task predictions. Our experiments, ranging from image classification to link prediction in knowledge graphs, show that relational CBMs (i) match generalization performance of existing relational black-boxes (as opposed to non-relational CBMs), (ii) support the generation of quantified concept-based explanations, (iii) effectively respond to test-time interventions, and (iv) withstand demanding settings including out-of-distribution scenarios, limited training data regimes, and scarce concept supervisions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;L2 Init&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;L2&#27491;&#21017;&#21270;&#24212;&#29992;&#20110;&#21021;&#22987;&#21442;&#25968;&#65292;&#26469;&#32500;&#25345;&#31070;&#32463;&#32593;&#32476;&#22312;&#22788;&#29702;&#38750;&#24179;&#31283;&#25968;&#25454;&#27969;&#26102;&#30340;&#21487;&#22609;&#24615;&#19988;&#26131;&#20110;&#23454;&#26045;&#12290;&#35813;&#26041;&#27861;&#20351;&#24471;&#21442;&#25968;&#33021;&#22815;&#36805;&#36895;&#36866;&#24212;&#26032;&#20219;&#21153;&#24182;&#20943;&#36731;&#21487;&#22609;&#24615;&#30340;&#20002;&#22833;&#12290;</title><link>http://arxiv.org/abs/2308.11958</link><description>&lt;p&gt;
&#36890;&#36807;&#20877;&#29983;&#24615;&#27491;&#21017;&#21270;&#32500;&#25345;&#21487;&#22609;&#24615;
&lt;/p&gt;
&lt;p&gt;
Maintaining Plasticity via Regenerative Regularization. (arXiv:2308.11958v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;L2 Init&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;L2&#27491;&#21017;&#21270;&#24212;&#29992;&#20110;&#21021;&#22987;&#21442;&#25968;&#65292;&#26469;&#32500;&#25345;&#31070;&#32463;&#32593;&#32476;&#22312;&#22788;&#29702;&#38750;&#24179;&#31283;&#25968;&#25454;&#27969;&#26102;&#30340;&#21487;&#22609;&#24615;&#19988;&#26131;&#20110;&#23454;&#26045;&#12290;&#35813;&#26041;&#27861;&#20351;&#24471;&#21442;&#25968;&#33021;&#22815;&#36805;&#36895;&#36866;&#24212;&#26032;&#20219;&#21153;&#24182;&#20943;&#36731;&#21487;&#22609;&#24615;&#30340;&#20002;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#65292;&#21487;&#22609;&#24615;&#25351;&#30340;&#26159;&#20195;&#29702;&#24555;&#36895;&#36866;&#24212;&#26032;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;&#24050;&#30693;&#31070;&#32463;&#32593;&#32476;&#22312;&#22788;&#29702;&#38750;&#24179;&#31283;&#25968;&#25454;&#27969;&#26102;&#20250;&#22833;&#21435;&#21487;&#22609;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;L2 Init&#30340;&#38750;&#24120;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;L2&#27491;&#21017;&#21270;&#24212;&#29992;&#20110;&#21021;&#22987;&#21442;&#25968;&#65292;&#26469;&#32500;&#25345;&#21487;&#22609;&#24615;&#12290;&#36825;&#19982;&#26631;&#20934;&#30340;L2&#27491;&#21017;&#21270;&#38750;&#24120;&#30456;&#20284;&#65292;&#21807;&#19968;&#30340;&#21306;&#21035;&#22312;&#20110;L2 Init&#27491;&#21017;&#21270;&#26397;&#21521;&#21407;&#28857;&#12290;L2 Init&#26131;&#20110;&#23454;&#26045;&#65292;&#21482;&#38656;&#35201;&#36873;&#25321;&#19968;&#20010;&#36229;&#21442;&#25968;&#12290;&#36825;&#20010;&#26041;&#27861;&#30340;&#21160;&#26426;&#19982;&#37325;&#32622;&#31070;&#32463;&#20803;&#25110;&#21442;&#25968;&#20540;&#30340;&#26041;&#27861;&#30456;&#21516;&#12290;&#30452;&#35266;&#19978;&#35762;&#65292;&#24403;&#26368;&#36817;&#30340;&#25439;&#22833;&#23545;&#29305;&#23450;&#21442;&#25968;&#19981;&#25935;&#24863;&#26102;&#65292;&#36825;&#20123;&#21442;&#25968;&#20250;&#21521;&#23427;&#20204;&#30340;&#21021;&#22987;&#20540;&#28418;&#31227;&#12290;&#36825;&#20351;&#24471;&#21442;&#25968;&#33021;&#22815;&#36805;&#36895;&#36866;&#24212;&#26032;&#20219;&#21153;&#12290;&#22312;&#20195;&#34920;&#36830;&#32493;&#23398;&#20064;&#20013;&#19981;&#21516;&#31867;&#22411;&#38750;&#24179;&#31283;&#24615;&#30340;&#31616;&#21333;&#38382;&#39064;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;L2 Init&#33021;&#22815;&#19968;&#33268;&#22320;&#20943;&#36731;&#21487;&#22609;&#24615;&#30340;&#20002;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
In continual learning, plasticity refers to the ability of an agent to quickly adapt to new information. Neural networks are known to lose plasticity when processing non-stationary data streams. In this paper, we propose L2 Init, a very simple approach for maintaining plasticity by incorporating in the loss function L2 regularization toward initial parameters. This is very similar to standard L2 regularization (L2), the only difference being that L2 regularizes toward the origin. L2 Init is simple to implement and requires selecting only a single hyper-parameter. The motivation for this method is the same as that of methods that reset neurons or parameter values. Intuitively, when recent losses are insensitive to particular parameters, these parameters drift toward their initial values. This prepares parameters to adapt quickly to new tasks. On simple problems representative of different types of nonstationarity in continual learning, we demonstrate that L2 Init consistently mitigates 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#25252;&#30340;&#20998;&#25955;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#21512;&#20316;&#20998;&#25955;&#28145;&#24230;&#23398;&#20064;&#65292;&#38450;&#27490;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#26102;&#27844;&#38706;&#31169;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2306.13892</link><description>&lt;p&gt;
&#20855;&#26377;&#20849;&#35782;&#31639;&#27861;&#30340;&#24046;&#20998;&#38544;&#31169;&#20998;&#25955;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Decentralized Deep Learning with Consensus Algorithms. (arXiv:2306.13892v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#25252;&#30340;&#20998;&#25955;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#21512;&#20316;&#20998;&#25955;&#28145;&#24230;&#23398;&#20064;&#65292;&#38450;&#27490;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#26102;&#27844;&#38706;&#31169;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#20316;&#20998;&#25955;&#28145;&#24230;&#23398;&#20064;&#20381;&#36182;&#20110;&#36890;&#20449;&#20195;&#29702;&#20043;&#38388;&#30340;&#30452;&#25509;&#20449;&#24687;&#20132;&#25442;&#65292;&#27599;&#20010;&#20195;&#29702;&#37117;&#21487;&#20197;&#35775;&#38382;&#24212;&#35813;&#20445;&#25345;&#31169;&#26377;&#30340;&#26412;&#22320;&#25968;&#25454;&#38598;&#12290;&#30446;&#26631;&#26159;&#22312;&#35757;&#32451;&#21518;&#20351;&#24471;&#25152;&#26377;&#20195;&#29702;&#22312;&#27169;&#22411;&#21442;&#25968;&#19978;&#36798;&#25104;&#20849;&#35782;&#12290;&#28982;&#32780;&#65292;&#19982;&#19981;&#21487;&#20449;&#30340;&#37051;&#23621;&#20195;&#29702;&#20849;&#20139;&#21442;&#25968;&#21487;&#33021;&#20250;&#27844;&#38706;&#26377;&#20851;&#26412;&#22320;&#25968;&#25454;&#38598;&#30340;&#21487;&#21033;&#29992;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#20998;&#25955;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#22312;&#21512;&#20316;&#35757;&#32451;&#26399;&#38388;&#21644;&#20043;&#21518;&#20445;&#25252;&#27599;&#20010;&#20195;&#29702;&#30340;&#26412;&#22320;&#25968;&#25454;&#38598;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#23558;&#24120;&#29992;&#20110;&#38598;&#20013;&#24335;&#28145;&#24230;&#23398;&#20064;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#27867;&#21270;&#21040;&#23454;&#29992;&#30340;&#22522;&#20110;&#23376;&#26799;&#24230;&#21644;ADMM&#30340;&#20998;&#25955;&#23398;&#20064;&#26041;&#27861;&#20013;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#36866;&#29992;&#20110;&#20219;&#24847;&#28145;&#24230;&#23398;&#20064;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#20998;&#26512;&#20102;&#24378;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#19982;&#20854;&#20182;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cooperative decentralized deep learning relies on direct information exchange between communicating agents, each with access to a local dataset which should be kept private. The goal is for all agents to achieve consensus on model parameters after training. However, sharing parameters with untrustworthy neighboring agents could leak exploitable information about local datasets. To combat this, we introduce differentially private decentralized learning that secures each agent's local dataset during and after cooperative training. In our approach, we generalize Differentially Private Stochastic Gradient Descent (DP-SGD) -- a popular differentially private training method for centralized deep learning -- to practical subgradient- and ADMM-based decentralized learning methods. Our algorithms' differential privacy guarantee holds for arbitrary deep learning objective functions, and we analyze the convergence properties for strongly convex objective functions. We compare our algorithms again
&lt;/p&gt;</description></item><item><title>&#24425;&#34425;&#32593;&#32476;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#36890;&#36807;&#23618;&#20869;&#31070;&#32463;&#20803;&#26435;&#37325;&#20114;&#30456;&#29420;&#31435;&#30340;&#23545;&#40784;&#21644;&#38543;&#26426;&#29305;&#24449;&#26144;&#23556;&#26469;&#36827;&#34892;&#32447;&#24615;&#38477;&#32500;&#21644;&#38750;&#32447;&#24615;&#39640;&#32500;&#23884;&#20837;&#65292;&#22312;ImageNet&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.18512</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#40657;&#30418;&#20013;&#30340;&#24425;&#34425;
&lt;/p&gt;
&lt;p&gt;
A Rainbow in Deep Network Black Boxes. (arXiv:2305.18512v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18512
&lt;/p&gt;
&lt;p&gt;
&#24425;&#34425;&#32593;&#32476;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#36890;&#36807;&#23618;&#20869;&#31070;&#32463;&#20803;&#26435;&#37325;&#20114;&#30456;&#29420;&#31435;&#30340;&#23545;&#40784;&#21644;&#38543;&#26426;&#29305;&#24449;&#26144;&#23556;&#26469;&#36827;&#34892;&#32447;&#24615;&#38477;&#32500;&#21644;&#38750;&#32447;&#24615;&#39640;&#32500;&#23884;&#20837;&#65292;&#22312;ImageNet&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#24425;&#34425;&#32593;&#32476;&#20316;&#20026;&#35757;&#32451;&#22909;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27010;&#29575;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#32423;&#32852;&#38543;&#26426;&#29305;&#24449;&#26144;&#23556;&#65292;&#20854;&#26435;&#37325;&#20998;&#24067;&#26159;&#21487;&#20197;&#23398;&#20064;&#30340;&#12290;&#23427;&#20551;&#35774;&#19981;&#21516;&#23618;&#20043;&#38388;&#30340;&#26435;&#37325;&#20381;&#36182;&#24615;&#34987;&#20943;&#23569;&#21040;&#23558;&#36755;&#20837;&#28608;&#27963;&#23545;&#20934;&#30340;&#26059;&#36716;&#12290;&#23618;&#20869;&#30340;&#31070;&#32463;&#20803;&#26435;&#37325;&#22312;&#36825;&#31181;&#23545;&#40784;&#21518;&#26159;&#30456;&#20114;&#29420;&#31435;&#30340;&#12290;&#23427;&#20204;&#30340;&#28608;&#27963;&#23450;&#20041;&#20102;&#22312;&#26080;&#31351;&#23485;&#24230;&#26497;&#38480;&#19979;&#21464;&#24471;&#30830;&#23450;&#30340;&#20869;&#26680;&#12290;&#36825;&#22312;ImageNet&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;ResNets&#20013;&#36890;&#36807;&#25968;&#23383;&#39564;&#35777;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#20998;&#24067;&#20855;&#26377;&#20302;&#31209;&#21327;&#26041;&#24046;&#12290;&#22240;&#27492;&#65292;&#24425;&#34425;&#32593;&#32476;&#22312;&#32447;&#24615;&#38477;&#32500;&#21644;&#38750;&#32447;&#24615;&#39640;&#32500;&#23884;&#20837;&#19982;&#30333;&#33394;&#38543;&#26426;&#29305;&#24449;&#20043;&#38388;&#20132;&#26367;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20855;&#26377;&#39640;&#26031;&#26435;&#37325;&#20998;&#24067;&#30340;&#39640;&#26031;&#24425;&#34425;&#32593;&#32476;&#23450;&#20041;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#20351;&#29992;&#23567;&#27874;&#25955;&#23556;&#32593;&#32476;&#36827;&#34892;CIFAR-10&#22270;&#20687;&#20998;&#31867;&#26041;&#38754;&#36827;&#34892;&#20102;&#25968;&#23383;&#39564;&#35777;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#65292;&#22312;&#35757;&#32451;&#26399;&#38388;&#65292;SGD&#26356;&#26032;&#26435;&#37325;&#30340;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce rainbow networks as a probabilistic model of trained deep neural networks. The model cascades random feature maps whose weight distributions are learned. It assumes that dependencies between weights at different layers are reduced to rotations which align the input activations. Neuron weights within a layer are independent after this alignment. Their activations define kernels which become deterministic in the infinite-width limit. This is verified numerically for ResNets trained on the ImageNet dataset. We also show that the learned weight distributions have low-rank covariances. Rainbow networks thus alternate between linear dimension reductions and non-linear high-dimensional embeddings with white random features. Gaussian rainbow networks are defined with Gaussian weight distributions. These models are validated numerically on image classification on the CIFAR-10 dataset, with wavelet scattering networks. We further show that during training, SGD updates the weight cov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#23725;&#27491;&#21017;&#21270;&#30340;&#21435;&#22122;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20250;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2305.14689</link><description>&lt;p&gt;
&#22522;&#20110;&#23725;&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#21435;&#22122;&#38382;&#39064;&#30340;&#27424;&#21442;&#25968;&#21270;&#21452;&#35895;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Under-Parameterized Double Descent for Ridge Regularized Least Squares Denoising of Data on a Line. (arXiv:2305.14689v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#23725;&#27491;&#21017;&#21270;&#30340;&#21435;&#22122;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20250;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#35757;&#32451;&#25968;&#25454;&#28857;&#25968;&#12289;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#25968;&#21644;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#24050;&#26377;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21487;&#33021;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#65292;&#32780;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21017;&#26222;&#36941;&#23384;&#22312;&#26631;&#20934;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20363;&#23376;&#65292;&#21487;&#20197;&#35777;&#26126;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21487;&#20197;&#21457;&#29983;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;&#32771;&#34385;&#23884;&#20837;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#21435;&#22122;&#38382;&#39064;&#20013;&#30340;&#23725;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#19968;&#31181;&#28176;&#36817;&#20934;&#30830;&#30340;&#24191;&#20041;&#35823;&#24046;&#20844;&#24335;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#26679;&#26412;&#21644;&#21442;&#25968;&#30340;&#21452;&#35895;&#25928;&#24212;&#65292;&#21452;&#23792;&#35895;&#20301;&#20110;&#25554;&#20540;&#28857;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#21306;&#22495;&#20043;&#38388;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#21452;&#35895;&#26354;&#32447;&#30340;&#39640;&#23792;&#23545;&#24212;&#20110;&#20272;&#35745;&#37327;&#30340;&#33539;&#25968;&#26354;&#32447;&#30340;&#39640;&#23792;&#12290;
&lt;/p&gt;
&lt;p&gt;
The relationship between the number of training data points, the number of parameters in a statistical model, and the generalization capabilities of the model has been widely studied. Previous work has shown that double descent can occur in the over-parameterized regime, and believe that the standard bias-variance trade-off holds in the under-parameterized regime. In this paper, we present a simple example that provably exhibits double descent in the under-parameterized regime. For simplicity, we look at the ridge regularized least squares denoising problem with data on a line embedded in high-dimension space. By deriving an asymptotically accurate formula for the generalization error, we observe sample-wise and parameter-wise double descent with the peak in the under-parameterized regime rather than at the interpolation point or in the over-parameterized regime.  Further, the peak of the sample-wise double descent curve corresponds to a peak in the curve for the norm of the estimator,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;-&#21069;&#21521;&#21644;&#39044;&#27979;&#24335;&#21069;&#21521;-&#21069;&#21521;&#23398;&#20064;&#36807;&#31243;&#30340;&#36890;&#29992;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#36882;&#24402;&#30005;&#36335;&#35745;&#31639;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#33180;&#30005;&#20301;&#12290;&#19982;&#20381;&#36182;&#21453;&#39304;&#31361;&#35302;&#35843;&#25972;&#31070;&#32463;&#30005;&#27963;&#21160;&#30340;&#23574;&#23792;&#31070;&#32463;&#32534;&#30721;&#19981;&#21516;&#65292;&#35813;&#27169;&#22411;&#32431;&#22312;&#32447;&#24182;&#19988;&#26102;&#38388;&#21521;&#21069;&#65292;&#26159;&#23398;&#20064;&#24102;&#26377;&#26102;&#38388;&#23574;&#23792;&#20449;&#21495;&#30340;&#24863;&#35273;&#25968;&#25454;&#27169;&#24335;&#20998;&#24067;&#34920;&#31034;&#30340;&#26377;&#21069;&#36884;&#30340;&#19968;&#31181;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2303.18187</link><description>&lt;p&gt;
&#21033;&#29992;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;&#21069;&#21521;&#36807;&#31243;&#23398;&#20064;&#23574;&#23792;&#31070;&#32463;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning Spiking Neural Systems with the Event-Driven Forward-Forward Process. (arXiv:2303.18187v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.18187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;-&#21069;&#21521;&#21644;&#39044;&#27979;&#24335;&#21069;&#21521;-&#21069;&#21521;&#23398;&#20064;&#36807;&#31243;&#30340;&#36890;&#29992;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#36882;&#24402;&#30005;&#36335;&#35745;&#31639;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#33180;&#30005;&#20301;&#12290;&#19982;&#20381;&#36182;&#21453;&#39304;&#31361;&#35302;&#35843;&#25972;&#31070;&#32463;&#30005;&#27963;&#21160;&#30340;&#23574;&#23792;&#31070;&#32463;&#32534;&#30721;&#19981;&#21516;&#65292;&#35813;&#27169;&#22411;&#32431;&#22312;&#32447;&#24182;&#19988;&#26102;&#38388;&#21521;&#21069;&#65292;&#26159;&#23398;&#20064;&#24102;&#26377;&#26102;&#38388;&#23574;&#23792;&#20449;&#21495;&#30340;&#24863;&#35273;&#25968;&#25454;&#27169;&#24335;&#20998;&#24067;&#34920;&#31034;&#30340;&#26377;&#21069;&#36884;&#30340;&#19968;&#31181;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#20351;&#29992;&#23574;&#23792;&#31070;&#32463;&#20803;&#36827;&#34892;&#20449;&#24687;&#22788;&#29702;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20998;&#20998;&#37197;&#31639;&#27861;&#65292;&#26080;&#38656;&#21453;&#39304;&#31361;&#35302;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;-&#21069;&#21521;&#21644;&#39044;&#27979;&#24335;&#21069;&#21521;-&#21069;&#21521;&#23398;&#20064;&#36807;&#31243;&#30340;&#36890;&#29992;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#36845;&#20195;&#22788;&#29702;&#24863;&#35273;&#36755;&#20837;&#12290;&#22240;&#27492;&#65292;&#36882;&#24402;&#30005;&#36335;&#20250;&#26681;&#25454;&#23616;&#37096;&#33258;&#19979;&#21521;&#19978;&#12289;&#33258;&#19978;&#32780;&#19979;&#21644;&#20391;&#38754;&#30340;&#20449;&#21495;&#35745;&#31639;&#27599;&#23618;&#20013;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#33180;&#30005;&#20301;&#65292;&#20419;&#36827;&#19968;&#31181;&#21160;&#24577;&#30340;&#12289;&#36880;&#23618;&#24182;&#34892;&#30340;&#31070;&#32463;&#35745;&#31639;&#24418;&#24335;&#12290;&#19982;&#20381;&#36182;&#21453;&#39304;&#31361;&#35302;&#35843;&#25972;&#31070;&#32463;&#30005;&#27963;&#21160;&#30340;&#23574;&#23792;&#31070;&#32463;&#32534;&#30721;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#32431;&#22312;&#32447;&#24182;&#19988;&#26102;&#38388;&#21521;&#21069;&#65292;&#36825;&#26679;&#23601;&#33021;&#22815;&#23398;&#20064;&#24102;&#26377;&#26102;&#38388;&#23574;&#23792;&#20449;&#21495;&#30340;&#24863;&#35273;&#25968;&#25454;&#27169;&#24335;&#30340;&#20998;&#24067;&#34920;&#31034;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#27169;&#24335;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;&#21069;&#21521;&#65288;ED-FF&#65289;&#26694;&#26550;&#24037;&#20316;&#27491;&#24120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel credit assignment algorithm for information processing with spiking neurons without requiring feedback synapses. Specifically, we propose an event-driven generalization of the forward-forward and the predictive forward-forward learning processes for a spiking neural system that iteratively processes sensory input over a stimulus window. As a result, the recurrent circuit computes the membrane potential of each neuron in each layer as a function of local bottom-up, top-down, and lateral signals, facilitating a dynamic, layer-wise parallel form of neural computation. Unlike spiking neural coding, which relies on feedback synapses to adjust neural electrical activity, our model operates purely online and forward in time, offering a promising way to learn distributed representations of sensory data patterns with temporal spike signals. Notably, our experimental results on several pattern datasets demonstrate that the even-driven forward-forward (ED-FF) framework works we
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bayan&#30340;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#25110;&#36817;&#20284;&#20248;&#21270;&#27169;&#22359;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#36820;&#22238;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#30340;&#20998;&#21306;&#65292;&#24182;&#19988;&#27604;&#20854;&#20182;&#31639;&#27861;&#24555;&#25968;&#20493;&#65292;&#24182;&#33021;&#22815;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#20934;&#30830;&#22320;&#25214;&#21040;&#22320;&#38754;&#30495;&#23454;&#31038;&#21306;&#12290;</title><link>http://arxiv.org/abs/2209.04562</link><description>&lt;p&gt;
Bayan&#31639;&#27861;&#65306;&#36890;&#36807;&#23545;&#27169;&#22359;&#24230;&#30340;&#31934;&#30830;&#21644;&#36817;&#20284;&#20248;&#21270;&#26469;&#26816;&#27979;&#32593;&#32476;&#20013;&#30340;&#31038;&#21306;
&lt;/p&gt;
&lt;p&gt;
The Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity. (arXiv:2209.04562v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04562
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bayan&#30340;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#25110;&#36817;&#20284;&#20248;&#21270;&#27169;&#22359;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#36820;&#22238;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#30340;&#20998;&#21306;&#65292;&#24182;&#19988;&#27604;&#20854;&#20182;&#31639;&#27861;&#24555;&#25968;&#20493;&#65292;&#24182;&#33021;&#22815;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#20934;&#30830;&#22320;&#25214;&#21040;&#22320;&#38754;&#30495;&#23454;&#31038;&#21306;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#32593;&#32476;&#31185;&#23398;&#20013;&#30340;&#32463;&#20856;&#38382;&#39064;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#22312;&#20247;&#22810;&#26041;&#27861;&#20013;&#65292;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#26368;&#22823;&#21270;&#27169;&#22359;&#24230;&#12290;&#23613;&#31649;&#21551;&#21457;&#24335;&#27169;&#22359;&#24230;&#26368;&#22823;&#21270;&#31639;&#27861;&#35774;&#35745;&#29702;&#24565;&#21644;&#24191;&#27867;&#37319;&#29992;&#65292;&#20294;&#24456;&#23569;&#36820;&#22238;&#26368;&#20339;&#20998;&#21306;&#25110;&#31867;&#20284;&#20998;&#21306;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#38376;&#30340;&#31639;&#27861;Bayan&#65292;&#23427;&#36820;&#22238;&#20855;&#26377;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#20998;&#21306;&#20445;&#35777;&#30340;&#20998;&#21306;&#12290;Bayan&#31639;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#20998;&#25903;&#38480;&#30028;&#26041;&#26696;&#65292;&#23427;&#35299;&#20915;&#20102;&#38382;&#39064;&#30340;&#25972;&#25968;&#35268;&#21010;&#20844;&#24335;&#20197;&#36798;&#21040;&#26368;&#20248;&#25110;&#36817;&#20284;&#26368;&#20248;&#30340;&#30446;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;Bayan&#22312;&#21512;&#25104;&#22522;&#20934;&#21644;&#30495;&#23454;&#32593;&#32476;&#33410;&#28857;&#26631;&#31614;&#30340;&#26816;&#32034;&#22320;&#38754;&#30495;&#23454;&#31038;&#21306;&#26041;&#38754;&#20855;&#26377;&#29420;&#29305;&#30340;&#20934;&#30830;&#24615;&#21644;&#31283;&#23450;&#24615;&#65292;&#27604;&#20854;&#20182;21&#31181;&#31639;&#27861;&#24555;&#25968;&#20493;&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#20248;&#20998;&#21306;&#30340;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is a classic problem in network science with extensive applications in various fields. Among numerous approaches, the most common method is modularity maximization. Despite their design philosophy and wide adoption, heuristic modularity maximization algorithms rarely return an optimal partition or anything similar. We propose a specialized algorithm, Bayan, which returns partitions with a guarantee of either optimality or proximity to an optimal partition. At the core of the Bayan algorithm is a branch-and-cut scheme that solves an integer programming formulation of the problem to optimality or approximate it within a factor. We demonstrate Bayan's distinctive accuracy and stability over 21 other algorithms in retrieving ground-truth communities in synthetic benchmarks and node labels in real networks. Bayan is several times faster than open-source and commercial solvers for modularity maximization making it capable of finding optimal partitions for instances that c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#20250;&#21512;&#65292;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#23548;&#33322;&#21644;&#25511;&#21046;&#26694;&#26550;&#65292;&#29992;&#20110;&#21487;&#38752;&#12289;&#20934;&#30830;&#21644;&#33258;&#20027;&#22320;&#36973;&#36935;&#24555;&#36895;&#31227;&#21160;&#30340;&#26143;&#38469;&#29289;&#20307;&#12290;&#23427;&#36890;&#36807;&#28857;&#26368;&#23567;&#33539;&#25968;&#36861;&#36394;&#25511;&#21046;&#21644;&#35889;&#24402;&#19968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24341;&#23548;&#31574;&#30053;&#26469;&#25552;&#20379;&#39640;&#27010;&#29575;&#25351;&#25968;&#19978;&#30028;&#30340;&#39134;&#34892;&#22120;&#20132;&#20184;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2208.04883</link><description>&lt;p&gt;
&#31070;&#32463;&#20250;&#21512;&#65306;&#38754;&#21521;&#26143;&#38469;&#29289;&#20307;&#30340;&#21487;&#38752;&#23548;&#33322;&#21644;&#25511;&#21046;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects. (arXiv:2208.04883v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.04883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#20250;&#21512;&#65292;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#23548;&#33322;&#21644;&#25511;&#21046;&#26694;&#26550;&#65292;&#29992;&#20110;&#21487;&#38752;&#12289;&#20934;&#30830;&#21644;&#33258;&#20027;&#22320;&#36973;&#36935;&#24555;&#36895;&#31227;&#21160;&#30340;&#26143;&#38469;&#29289;&#20307;&#12290;&#23427;&#36890;&#36807;&#28857;&#26368;&#23567;&#33539;&#25968;&#36861;&#36394;&#25511;&#21046;&#21644;&#35889;&#24402;&#19968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24341;&#23548;&#31574;&#30053;&#26469;&#25552;&#20379;&#39640;&#27010;&#29575;&#25351;&#25968;&#19978;&#30028;&#30340;&#39134;&#34892;&#22120;&#20132;&#20184;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26143;&#38469;&#29289;&#20307;&#65288;ISOs&#65289;&#24456;&#21487;&#33021;&#26159;&#19981;&#21487;&#26367;&#20195;&#30340;&#21407;&#22987;&#26448;&#26009;&#65292;&#22312;&#29702;&#35299;&#31995;&#22806;&#34892;&#26143;&#26143;&#31995;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#36816;&#34892;&#36712;&#36947;&#38590;&#20197;&#32422;&#26463;&#65292;&#36890;&#24120;&#20855;&#26377;&#36739;&#39640;&#30340;&#20542;&#35282;&#21644;&#30456;&#23545;&#36895;&#24230;&#65292;&#20351;&#29992;&#20256;&#32479;&#30340;&#20154;&#22312;&#29615;&#36335;&#26041;&#27861;&#25506;&#32034;ISOs&#20855;&#26377;&#30456;&#24403;&#22823;&#30340;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#20250;&#21512;&#30340;&#28145;&#24230;&#23398;&#20064;&#23548;&#33322;&#21644;&#25511;&#21046;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#23454;&#26102;&#20013;&#20197;&#21487;&#38752;&#12289;&#20934;&#30830;&#21644;&#33258;&#20027;&#30340;&#26041;&#24335;&#36973;&#36935;&#24555;&#36895;&#31227;&#21160;&#30340;&#29289;&#20307;&#65292;&#21253;&#25324;ISOs&#12290;&#23427;&#22312;&#22522;&#20110;&#35889;&#24402;&#19968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24341;&#23548;&#31574;&#30053;&#20043;&#19978;&#20351;&#29992;&#28857;&#26368;&#23567;&#33539;&#25968;&#36861;&#36394;&#25511;&#21046;&#65292;&#20854;&#20013;&#21442;&#25968;&#36890;&#36807;&#30452;&#25509;&#24809;&#32602;MPC&#29366;&#24577;&#36712;&#36857;&#36319;&#36394;&#35823;&#24046;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35843;&#20248;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31070;&#32463;&#20250;&#21512;&#22312;&#39044;&#26399;&#30340;&#39134;&#34892;&#22120;&#20132;&#20184;&#35823;&#24046;&#19978;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#25351;&#25968;&#19978;&#30028;&#65292;&#20854;&#35777;&#26126;&#21033;&#29992;&#20102;&#38543;&#26426;&#36882;&#22686;&#31283;&#23450;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interstellar objects (ISOs) are likely representatives of primitive materials invaluable in understanding exoplanetary star systems. Due to their poorly constrained orbits with generally high inclinations and relative velocities, however, exploring ISOs with conventional human-in-the-loop approaches is significantly challenging. This paper presents Neural-Rendezvous, a deep learning-based guidance and control framework for encountering fast-moving objects, including ISOs, robustly, accurately, and autonomously in real time. It uses pointwise minimum norm tracking control on top of a guidance policy modeled by a spectrally-normalized deep neural network, where its hyperparameters are tuned with a loss function directly penalizing the MPC state trajectory tracking error. We show that Neural-Rendezvous provides a high probability exponential bound on the expected spacecraft delivery error, the proof of which leverages stochastic incremental stability analysis. In particular, it is used to
&lt;/p&gt;</description></item><item><title>EVOTER&#20351;&#29992;&#31616;&#21333;&#30340;&#36923;&#36753;&#34920;&#36798;&#24335;&#28436;&#21270;&#20986;&#36879;&#26126;&#21487;&#35299;&#37322;&#30340;&#35268;&#21017;&#38598;&#65292;&#19982;&#40657;&#30418;&#27169;&#22411;&#24615;&#33021;&#30456;&#20284;&#65292;&#21487;&#20197;&#25581;&#31034;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#24182;&#20026;&#26410;&#26469;&#26500;&#24314;&#21487;&#38752;&#30340;AI&#31995;&#32479;&#25552;&#20379;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2204.10438</link><description>&lt;p&gt;
EVOTER&#65306;&#36879;&#26126;&#21487;&#35299;&#37322;&#35268;&#21017;&#38598;&#30340;&#36827;&#21270;
&lt;/p&gt;
&lt;p&gt;
EVOTER: Evolution of Transparent Explainable Rule-sets. (arXiv:2204.10438v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10438
&lt;/p&gt;
&lt;p&gt;
EVOTER&#20351;&#29992;&#31616;&#21333;&#30340;&#36923;&#36753;&#34920;&#36798;&#24335;&#28436;&#21270;&#20986;&#36879;&#26126;&#21487;&#35299;&#37322;&#30340;&#35268;&#21017;&#38598;&#65292;&#19982;&#40657;&#30418;&#27169;&#22411;&#24615;&#33021;&#30456;&#20284;&#65292;&#21487;&#20197;&#25581;&#31034;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#24182;&#20026;&#26410;&#26469;&#26500;&#24314;&#21487;&#38752;&#30340;AI&#31995;&#32479;&#25552;&#20379;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;AI&#31995;&#32479;&#26159;&#40657;&#30418;&#23376;&#65292;&#20026;&#32473;&#23450;&#30340;&#36755;&#20837;&#29983;&#25104;&#21512;&#29702;&#30340;&#36755;&#20986;&#12290;&#28982;&#32780;&#65292;&#26576;&#20123;&#39046;&#22495;&#20855;&#26377;&#35299;&#37322;&#33021;&#21147;&#21644;&#20449;&#20219;&#24230;&#35201;&#27714;&#65292;&#36825;&#20123;&#35201;&#27714;&#19981;&#33021;&#30452;&#25509;&#28385;&#36275;&#36825;&#20123;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#21363;&#24320;&#22987;&#26102;&#27169;&#22411;&#23601;&#26159;&#36879;&#26126;&#30340;&#21644;&#21487;&#35299;&#37322;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#31616;&#21333;&#30340;&#36923;&#36753;&#34920;&#36798;&#24335;&#28436;&#21270;&#20986;&#35268;&#21017;&#38598;&#65292;&#31216;&#20026;EVOTER&#12290;EVOTER&#22312;&#22810;&#20010;&#39044;&#27979;/&#20998;&#31867;&#21644;&#22788;&#26041;/&#25919;&#31574;&#25628;&#32034;&#39046;&#22495;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#26377;&#21644;&#27809;&#26377;&#20195;&#29702;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#23427;&#33021;&#22815;&#21457;&#29616;&#21644;&#40657;&#30418;&#27169;&#22411;&#30456;&#20284;&#30340;&#26377;&#24847;&#20041;&#30340;&#35268;&#21017;&#38598;&#12290;&#36825;&#20123;&#35268;&#21017;&#21487;&#20197;&#25552;&#20379;&#39046;&#22495;&#30340;&#35265;&#35299;&#65292;&#24182;&#20351;&#25968;&#25454;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#26174;&#24615;&#21270;&#12290;&#20063;&#21487;&#20197;&#30452;&#25509;&#23545;&#23427;&#20204;&#36827;&#34892;&#32534;&#36753;&#65292;&#20197;&#28040;&#38500;&#20559;&#35265;&#24182;&#28155;&#21152;&#32422;&#26463;&#12290;&#22240;&#27492;&#65292;EVOTER&#20026;&#26410;&#26469;&#26500;&#24314;&#20540;&#24471;&#20449;&#36182;&#30340;AI&#31995;&#32479;&#30340;&#21487;&#38752;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most AI systems are black boxes generating reasonable outputs for given inputs. Some domains, however, have explainability and trustworthiness requirements that cannot be directly met by these approaches. Various methods have therefore been developed to interpret black-box models after training. This paper advocates an alternative approach where the models are transparent and explainable to begin with. This approach, EVOTER, evolves rule-sets based on simple logical expressions. The approach is evaluated in several prediction/classification and prescription/policy search domains with and without a surrogate. It is shown to discover meaningful rule sets that perform similarly to black-box models. The rules can provide insight into the domain, and make biases hidden in the data explicit. It may also be possible to edit them directly to remove biases and add constraints. EVOTER thus forms a promising foundation for building trustworthy AI systems for real-world applications in the future.
&lt;/p&gt;</description></item></channel></rss>