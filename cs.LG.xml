<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01000</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#19982;&#30456;&#20851;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Multivariate Probabilistic Time Series Forecasting with Correlated Errors
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#35823;&#24046;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#19982;&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#37327;&#21270;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#26368;&#36817;&#30340;&#22810;&#20803;&#27169;&#22411;&#22312;&#32771;&#34385;&#35823;&#24046;&#20043;&#38388;&#30340;&#21516;&#26102;&#30456;&#20851;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#23545;&#20110;&#32479;&#35745;&#31616;&#21270;&#30340;&#30446;&#30340;&#65292;&#23545;&#36825;&#20123;&#35823;&#24046;&#30340;&#24120;&#35265;&#20551;&#35774;&#26159;&#23427;&#20204;&#22312;&#26102;&#38388;&#19978;&#26159;&#29420;&#31435;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#35266;&#27979;&#24448;&#24448;&#20559;&#31163;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#22240;&#20026;&#35823;&#24046;&#36890;&#24120;&#30001;&#20110;&#21508;&#31181;&#22240;&#32032;&#65288;&#22914;&#25490;&#38500;&#26102;&#38388;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65289;&#32780;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#21487;&#21462;&#30340;&#29305;&#24615;&#65306;&#22797;&#26434;&#24230;&#19981;&#38543;&#26102;&#38388;&#24207;&#21015;&#25968;&#30446;&#22686;&#21152;&#65292;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#21487;&#20197;&#29992;&#20110;&#26657;&#20934;&#39044;&#27979;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling the correlations among errors is closely associated with how accurately the model can quantify predictive uncertainty in probabilistic time series forecasting. Recent multivariate models have made significant progress in accounting for contemporaneous correlations among errors, while a common assumption on these errors is that they are temporally independent for the sake of statistical simplicity. However, real-world observations often deviate from this assumption, since errors usually exhibit substantial autocorrelation due to various factors such as the exclusion of temporally correlated covariates. In this work, we propose an efficient method, based on a low-rank-plus-diagonal parameterization of the covariance matrix, which can effectively characterize the autocorrelation of errors. The proposed method possesses several desirable properties: the complexity does not scale with the number of time series, the resulting covariance can be used for calibrating predictions, and i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#30005;&#21160;&#24494;&#31227;&#21160;&#24037;&#20855;&#22312;&#37117;&#26575;&#26519;&#25910;&#38598;&#30340;&#24320;&#25918;&#25968;&#25454;&#38598;&#65292;&#20026;&#35299;&#20915;&#23454;&#38469;&#22330;&#26223;&#20013;&#33021;&#32791;&#24314;&#27169;&#30340;&#22256;&#38590;&#25552;&#20379;&#20102;&#37325;&#35201;&#36164;&#28304;</title><link>https://arxiv.org/abs/2403.17632</link><description>&lt;p&gt;
&#20351;&#29992;&#24320;&#25918;&#25968;&#25454;&#38598;&#23545;&#30005;&#21160;&#24494;&#31227;&#21160;&#33021;&#32791;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Data-driven Energy Consumption Modelling for Electric Micromobility using an Open Dataset
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17632
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#30005;&#21160;&#24494;&#31227;&#21160;&#24037;&#20855;&#22312;&#37117;&#26575;&#26519;&#25910;&#38598;&#30340;&#24320;&#25918;&#25968;&#25454;&#38598;&#65292;&#20026;&#35299;&#20915;&#23454;&#38469;&#22330;&#26223;&#20013;&#33021;&#32791;&#24314;&#27169;&#30340;&#22256;&#38590;&#25552;&#20379;&#20102;&#37325;&#35201;&#36164;&#28304;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36710;&#36742;&#25317;&#22581;&#21644;&#29615;&#22659;&#24694;&#21270;&#24102;&#26469;&#30340;&#25361;&#25112;&#26085;&#30410;&#21152;&#21095;&#65292;&#20984;&#26174;&#20102;&#22312;&#22478;&#24066;&#31354;&#38388;&#25512;&#34892;E-Mobility&#35299;&#20915;&#26041;&#26696;&#30340;&#37325;&#35201;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;E-&#28369;&#26495;&#36710;&#21644;E-&#33258;&#34892;&#36710;&#31561;&#24494;&#22411;E-Mobility&#24037;&#20855;&#22312;&#36825;&#19968;&#36716;&#21464;&#20013;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#20026;&#22478;&#24066;&#36890;&#21220;&#32773;&#25552;&#20379;&#21487;&#25345;&#32493;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24037;&#20855;&#30340;&#33021;&#32791;&#27169;&#24335;&#26159;&#24433;&#21709;&#20854;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#26377;&#25928;&#24615;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#23545;&#20110;&#20986;&#34892;&#35268;&#21010;&#20197;&#21450;&#22686;&#24378;&#29992;&#25143;&#22312;&#20351;&#29992;&#36825;&#20123;&#24037;&#20855;&#26102;&#30340;&#20449;&#24515;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21033;&#29992;&#38024;&#23545;&#29305;&#23450;&#31227;&#21160;&#24037;&#20855;&#21644;&#26465;&#20214;&#23450;&#21046;&#30340;&#29289;&#29702;&#27169;&#22411;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26377;&#25928;&#24615;&#23384;&#22312;&#22256;&#38590;&#65292;&#36825;&#26159;&#22240;&#20026;&#32570;&#20047;&#29992;&#20110;&#24443;&#24213;&#27169;&#22411;&#35780;&#20272;&#21644;&#39564;&#35777;&#30340;&#24320;&#25918;&#25968;&#25454;&#38598;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#29233;&#23572;&#20848;&#37117;&#26575;&#26519;&#25910;&#38598;&#30340;&#24320;&#25918;&#25968;&#25454;&#38598;&#65292;&#19987;&#38376;&#29992;&#20110;&#33021;&#32791;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17632v1 Announce Type: new  Abstract: The escalating challenges of traffic congestion and environmental degradation underscore the critical importance of embracing E-Mobility solutions in urban spaces. In particular, micro E-Mobility tools such as E-scooters and E-bikes, play a pivotal role in this transition, offering sustainable alternatives for urban commuters. However, the energy consumption patterns for these tools are a critical aspect that impacts their effectiveness in real-world scenarios and is essential for trip planning and boosting user confidence in using these. To this effect, recent studies have utilised physical models customised for specific mobility tools and conditions, but these models struggle with generalization and effectiveness in real-world scenarios due to a notable absence of open datasets for thorough model evaluation and verification. To fill this gap, our work presents an open dataset, collected in Dublin, Ireland, specifically designed for ene
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#27969;&#21305;&#37197;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#27493;&#20013;&#23398;&#20064;&#23454;&#29616;&#20108;&#27425;&#25104;&#26412;&#19979;&#30340;&#30452;&#32447; OT &#20301;&#31227;&#12290;</title><link>https://arxiv.org/abs/2403.13117</link><description>&lt;p&gt;
&#26368;&#20248;&#27969;&#21305;&#37197;&#65306;&#22312;&#19968;&#27493;&#20013;&#23398;&#20064;&#30452;&#32447;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Optimal Flow Matching: Learning Straight Trajectories in Just One Step
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13117
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#27969;&#21305;&#37197;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#27493;&#20013;&#23398;&#20064;&#23454;&#29616;&#20108;&#27425;&#25104;&#26412;&#19979;&#30340;&#30452;&#32447; OT &#20301;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#27969;&#21305;&#37197;&#26041;&#27861;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#24471;&#21040;&#20102;&#34028;&#21187;&#21457;&#23637;&#12290;&#31038;&#21306;&#36861;&#27714;&#30340;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#23646;&#24615;&#26159;&#33021;&#22815;&#23398;&#20064;&#20855;&#26377;&#30452;&#32447;&#36712;&#36857;&#30340;&#27969;&#65292;&#36825;&#20123;&#36712;&#36857;&#23454;&#29616;&#20102;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#32622;&#25442;&#12290;&#30452;&#32447;&#24615;&#23545;&#20110;&#24555;&#36895;&#38598;&#25104;&#23398;&#20064;&#27969;&#30340;&#36335;&#24452;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27969;&#30452;&#32447;&#21270;&#26041;&#27861;&#37117;&#22522;&#20110;&#38750;&#24179;&#20961;&#30340;&#36845;&#20195;&#36807;&#31243;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#31215;&#32047;&#35823;&#24046;&#25110;&#21033;&#29992;&#21551;&#21457;&#24335;&#23567;&#25209;&#37327;OT&#36817;&#20284;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#27969;&#21305;&#37197;&#26041;&#27861;&#65292;&#20165;&#36890;&#36807;&#19968;&#27425;&#27969;&#21305;&#37197;&#27493;&#39588;&#21363;&#21487;&#20026;&#20108;&#27425;&#25104;&#26412;&#24674;&#22797;&#30452;&#32447;OT&#32622;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13117v1 Announce Type: cross  Abstract: Over the several recent years, there has been a boom in development of flow matching methods for generative modeling. One intriguing property pursued by the community is the ability to learn flows with straight trajectories which realize the optimal transport (OT) displacements. Straightness is crucial for fast integration of the learned flow's paths. Unfortunately, most existing flow straightening methods are based on non-trivial iterative procedures which accumulate the error during training or exploit heuristic minibatch OT approximations. To address this issue, we develop a novel optimal flow matching approach which recovers the straight OT displacement for the quadratic cost in just one flow matching step.
&lt;/p&gt;</description></item><item><title>&#22823;&#22810;&#25968;&#29616;&#20195;LLM&#21463;&#21040;softmax&#29942;&#39048;&#24433;&#21709;&#65292;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#33719;&#21462;API&#20445;&#25252;&#30340;LLM&#30340;&#38750;&#20844;&#24320;&#20449;&#24687;&#21644;&#35299;&#38145;&#22810;&#31181;&#21151;&#33021;</title><link>https://arxiv.org/abs/2403.09539</link><description>&lt;p&gt;
API&#20445;&#25252;&#30340;LLMs&#30340;&#26631;&#24535;&#27844;&#38706;&#19987;&#26377;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Logits of API-Protected LLMs Leak Proprietary Information
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09539
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#20195;LLM&#21463;&#21040;softmax&#29942;&#39048;&#24433;&#21709;&#65292;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#33719;&#21462;API&#20445;&#25252;&#30340;LLM&#30340;&#38750;&#20844;&#24320;&#20449;&#24687;&#21644;&#35299;&#38145;&#22810;&#31181;&#21151;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21830;&#19994;&#21270;&#23548;&#33268;&#20102;&#39640;&#32423;API-only&#25509;&#20837;&#19987;&#26377;&#27169;&#22411;&#30340;&#24120;&#35265;&#23454;&#36341;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#23545;&#20110;&#27169;&#22411;&#26550;&#26500;&#26377;&#20445;&#23432;&#30340;&#20551;&#35774;&#65292;&#20063;&#21487;&#20197;&#20174;&#30456;&#23545;&#36739;&#23569;&#30340;API&#26597;&#35810;&#20013;&#23398;&#20064;&#20851;&#20110;API&#20445;&#25252;&#30340;LLM&#30340;&#22823;&#37327;&#38750;&#20844;&#24320;&#20449;&#24687;&#65288;&#20363;&#22914;&#65292;&#20351;&#29992;OpenAI&#30340;gpt-3.5-turbo&#20165;&#33457;&#36153;&#19981;&#21040;1000&#32654;&#20803;&#65289;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#38598;&#20013;&#22312;&#19968;&#20010;&#20851;&#38190;&#35266;&#23519;&#19978;&#65306;&#22823;&#22810;&#25968;&#29616;&#20195;LLM&#21463;&#21040;&#20102;softmax&#29942;&#39048;&#30340;&#24433;&#21709;&#65292;&#36825;&#38480;&#21046;&#20102;&#27169;&#22411;&#36755;&#20986;&#21040;&#23436;&#25972;&#36755;&#20986;&#31354;&#38388;&#30340;&#32447;&#24615;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#27169;&#22411;&#22270;&#20687;&#25110;&#27169;&#22411;&#31614;&#21517;&#65292;&#20174;&#32780;&#20197;&#36739;&#20302;&#30340;&#25104;&#26412;&#35299;&#38145;&#20102;&#20960;&#31181;&#21151;&#33021;&#65306;&#26377;&#25928;&#21457;&#29616;LLM&#30340;&#38544;&#34255;&#22823;&#23567;&#65292;&#33719;&#21462;&#23436;&#25972;&#35789;&#27719;&#36755;&#20986;&#65292;&#26816;&#27979;&#21644;&#28040;&#38500;&#19981;&#21516;&#27169;&#22411;&#26356;&#26032;&#65292;&#35782;&#21035;&#32473;&#23450;&#21333;&#20010;&#23436;&#25972;LLM&#36755;&#20986;&#30340;&#28304;LLM&#65292;&#20197;&#21450;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09539v1 Announce Type: cross  Abstract: The commercialization of large language models (LLMs) has led to the common practice of high-level API-only access to proprietary models. In this work, we show that even with a conservative assumption about the model architecture, it is possible to learn a surprisingly large amount of non-public information about an API-protected LLM from a relatively small number of API queries (e.g., costing under $1,000 for OpenAI's gpt-3.5-turbo). Our findings are centered on one key observation: most modern LLMs suffer from a softmax bottleneck, which restricts the model outputs to a linear subspace of the full output space. We show that this lends itself to a model image or a model signature which unlocks several capabilities with affordable cost: efficiently discovering the LLM's hidden size, obtaining full-vocabulary outputs, detecting and disambiguating different model updates, identifying the source LLM given a single full LLM output, and eve
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Curry-DPO&#30340;&#26041;&#27861;&#65292;&#22312;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#20013;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#20559;&#22909;&#23545;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#21333;&#19968;&#23545;DPO&#35774;&#32622;&#26377;&#30528;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2403.07230</link><description>&lt;p&gt;
Curry-DPO&#65306;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#21644;&#25490;&#21517;&#20559;&#22909;&#22686;&#24378;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Curry-DPO: Enhancing Alignment using Curriculum Learning &amp; Ranked Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07230
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Curry-DPO&#30340;&#26041;&#27861;&#65292;&#22312;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#20013;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#20559;&#22909;&#23545;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#21333;&#19968;&#23545;DPO&#35774;&#32622;&#26377;&#30528;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#25104;&#23545;&#20559;&#22909;&#25968;&#25454;(&#36890;&#24120;&#26159;&#27599;&#20010;&#29992;&#25143;&#25552;&#31034;&#36873;&#25321;&#21644;&#25298;&#32477;&#30340;&#21709;&#24212;&#23545;)&#23558;LLMs&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#23545;&#20110;&#32473;&#23450;&#25552;&#31034;&#21487;&#33021;&#20250;&#23384;&#22312;&#22810;&#20010;&#21709;&#24212;&#65292;&#36825;&#20123;&#21709;&#24212;&#30340;&#36136;&#37327;&#30456;&#23545;&#20110;&#24444;&#27492;&#32780;&#35328;&#26377;&#25152;&#19981;&#21516;&#12290;&#26377;&#20102;&#36825;&#20123;&#22810;&#20010;&#21709;&#24212;&#30340;&#36136;&#37327;&#35780;&#32423;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#36825;&#20123;&#21709;&#24212;&#20026;&#32473;&#23450;&#25552;&#31034;&#21019;&#24314;&#22810;&#20010;&#20559;&#22909;&#23545;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20391;&#37325;&#20110;&#36890;&#36807;&#35838;&#31243;&#23398;&#20064;&#26041;&#27861;&#31995;&#32479;&#22320;&#21033;&#29992;&#26500;&#24314;&#30340;&#22810;&#20010;&#20559;&#22909;&#23545;&#26469;&#36827;&#34892;DPO&#35757;&#32451;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#26681;&#25454;&#19981;&#21516;&#30340;&#26631;&#20934;&#23558;&#36825;&#20123;&#22810;&#20010;&#20559;&#22909;&#25968;&#25454;&#23545;&#20174;&#26131;&#21040;&#38590;(&#27169;&#25311;&#35838;&#31243;&#35757;&#32451;)&#25490;&#24207;&#12290;&#25105;&#20204;&#35814;&#32454;&#27604;&#36739;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#26631;&#20934;&#21333;&#19968;&#23545;DPO&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;Curry-DPO&#65292;&#22312;MTbench&#12289;Vicuna&#12289;Wiz&#19978;&#22987;&#32456;&#34920;&#29616;&#20986;&#22686;&#24378;&#30340;&#24615;&#33021;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07230v1 Announce Type: cross  Abstract: Direct Preference Optimization (DPO) is an effective technique that leverages pairwise preference data (usually one chosen and rejected response pair per user prompt) to align LLMs to human preferences. In practice, multiple responses can exist for a given prompt with varying quality relative to each other. With availability of such quality ratings for multiple responses, we propose utilizing these responses to create multiple preference pairs for a given prompt. Our work focuses on systematically using the constructed multiple preference pair in DPO training via curriculum learning methodology. In particular, we order these multiple pairs of preference data from easy to hard (emulating curriculum training) according to various criteria. We show detailed comparisons of our proposed approach to the standard single-pair DPO setting. Our method, which we call Curry-DPO consistently shows increased performance gains on MTbench, Vicuna, Wiz
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#34920;&#26126;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#23558;&#28176;&#36817;&#20110;&#19968;&#20010;&#24120;&#25968;&#20989;&#25968;&#65292;&#24182;&#38480;&#21046;&#20102;&#36825;&#20123;&#20998;&#31867;&#22120;&#30340;&#32479;&#19968;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.03880</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#20960;&#20046;&#32943;&#23450;&#26159;&#28176;&#36817;&#24120;&#25968;
&lt;/p&gt;
&lt;p&gt;
Graph neural network outputs are almost surely asymptotically constant
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03880
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#23558;&#28176;&#36817;&#20110;&#19968;&#20010;&#24120;&#25968;&#20989;&#25968;&#65292;&#24182;&#38480;&#21046;&#20102;&#36825;&#20123;&#20998;&#31867;&#22120;&#30340;&#32479;&#19968;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#26159;&#21508;&#31181;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20027;&#35201;&#30340;&#26550;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;GNN&#30340;&#27010;&#29575;&#20998;&#31867;&#22120;&#22312;&#20174;&#26576;&#20010;&#38543;&#26426;&#22270;&#27169;&#22411;&#20013;&#32472;&#21046;&#30340;&#26356;&#22823;&#22270;&#19978;&#24212;&#29992;&#26102;&#39044;&#27979;&#22914;&#20309;&#28436;&#21464;&#65292;&#25552;&#20986;&#20102;GNN&#34920;&#36798;&#33021;&#21147;&#30340;&#26032;&#35282;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36755;&#20986;&#25910;&#25947;&#21040;&#19968;&#20010;&#24120;&#25968;&#20989;&#25968;&#65292;&#36825;&#20010;&#20989;&#25968;&#19978;&#38480;&#20102;&#36825;&#20123;&#20998;&#31867;&#22120;&#21487;&#20197;&#32479;&#19968;&#34920;&#36798;&#30340;&#20869;&#23481;&#12290;&#36825;&#31181;&#25910;&#25947;&#29616;&#35937;&#36866;&#29992;&#20110;&#38750;&#24120;&#24191;&#27867;&#30340;GNN&#31867;&#21035;&#65292;&#21253;&#25324;&#20808;&#36827;&#27169;&#22411;&#65292;&#20854;&#20013;&#30340;&#32858;&#21512;&#21253;&#25324;&#24179;&#22343;&#20540;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#36716;&#25442;&#22120;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#21508;&#31181;&#38543;&#26426;&#22270;&#27169;&#22411;&#65292;&#21253;&#25324;&#65288;&#31232;&#30095;&#30340;&#65289;Erd\H{o}s-R\'enyi&#27169;&#22411;&#21644;&#38543;&#26426;&#22359;&#27169;&#22411;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#36825;&#20123;&#21457;&#29616;&#65292;&#35266;&#23519;&#21040;&#25910;&#25947;&#29616;&#35937;&#24050;&#32463;&#22312;&#30456;&#23545;&#36866;&#20013;&#35268;&#27169;&#30340;&#22270;&#20013;&#26174;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03880v1 Announce Type: new  Abstract: Graph neural networks (GNNs) are the predominant architectures for a variety of learning tasks on graphs. We present a new angle on the expressive power of GNNs by studying how the predictions of a GNN probabilistic classifier evolve as we apply it on larger graphs drawn from some random graph model. We show that the output converges to a constant function, which upper-bounds what these classifiers can express uniformly. This convergence phenomenon applies to a very wide class of GNNs, including state of the art models, with aggregates including mean and the attention-based mechanism of graph transformers. Our results apply to a broad class of random graph models, including the (sparse) Erd\H{o}s-R\'enyi model and the stochastic block model. We empirically validate these findings, observing that the convergence phenomenon already manifests itself on graphs of relatively modest size.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#36328;&#35821;&#35328;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#22312;&#20302;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#20013;&#23454;&#29616;&#24773;&#24863;&#20998;&#31867;&#65292;&#23637;&#31034;&#20102;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.18424</link><description>&lt;p&gt;
&#20302;&#36164;&#28304;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#20013;&#30340;&#24773;&#24863;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Emotion Classification in Low and Moderate Resource Languages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18424
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36328;&#35821;&#35328;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#22312;&#20302;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#20013;&#23454;&#29616;&#24773;&#24863;&#20998;&#31867;&#65292;&#23637;&#31034;&#20102;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#20998;&#26512;&#20840;&#29699;&#33539;&#22260;&#20869;&#20154;&#20204;&#24773;&#32490;&#29366;&#24577;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#20840;&#29699;&#26377;7100&#22810;&#31181;&#27963;&#36291;&#35821;&#35328;&#65292;&#20026;&#27599;&#31181;&#35821;&#35328;&#26500;&#24314;&#24773;&#24863;&#20998;&#31867;&#26159;&#19968;&#39033;&#21171;&#21160;&#23494;&#38598;&#22411;&#24037;&#20316;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;&#20302;&#36164;&#28304;&#21644;&#28626;&#21361;&#35821;&#35328;&#65292;&#24314;&#31435;&#24773;&#24863;&#20998;&#31867;&#21487;&#33021;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#25105;&#20204;&#22312;&#36164;&#28304;&#20016;&#23500;&#30340;&#35821;&#35328;&#65288;&#20363;&#22914;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#30340;&#33521;&#35821;&#65289;&#19978;&#35757;&#32451;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#24182;&#23558;&#23398;&#20064;&#36801;&#31227;&#21040;&#20302;&#36164;&#28304;&#21644;&#20013;&#31561;&#36164;&#28304;&#30340;&#35821;&#35328;&#12290;&#25105;&#20204;&#27604;&#36739;&#24182;&#23545;&#27604;&#20102;&#20174;&#39640;&#36164;&#28304;&#35821;&#35328;&#21040;&#20302;&#36164;&#28304;&#25110;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#30340;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#12290;&#19968;&#31181;&#26041;&#27861;&#23558;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#26631;&#27880;&#25237;&#24433;&#21040;&#20302;&#36164;&#28304;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#30340;&#24179;&#34892;&#35821;&#26009;&#24211;&#20013;&#65292;&#21478;&#19968;&#31181;&#26041;&#27861;&#30452;&#25509;&#23558;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#23398;&#20064;&#36801;&#31227;&#21040;&#20854;&#20182;&#35821;&#35328;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;6&#31181;&#35821;&#35328;&#19978;&#30340;&#26377;&#25928;&#24615;&#65306;Fa
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18424v1 Announce Type: cross  Abstract: It is important to be able to analyze the emotional state of people around the globe. There are 7100+ active languages spoken around the world and building emotion classification for each language is labor intensive. Particularly for low-resource and endangered languages, building emotion classification can be quite challenging. We present a cross-lingual emotion classifier, where we train an emotion classifier with resource-rich languages (i.e. \textit{English} in our work) and transfer the learning to low and moderate resource languages. We compare and contrast two approaches of transfer learning from a high-resource language to a low or moderate-resource language. One approach projects the annotation from a high-resource language to low and moderate-resource language in parallel corpora and the other one uses direct transfer from high-resource language to the other languages. We show the efficacy of our approaches on 6 languages: Fa
&lt;/p&gt;</description></item><item><title>DeepDRK&#26159;&#19968;&#31181;&#20998;&#24067;&#26080;&#20851;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#29983;&#25104;&#27169;&#22411;&#20197;&#23454;&#29616;&#8220;&#20132;&#25442;&#23646;&#24615;&#8221;&#65292;&#24182;&#25552;&#20986;&#26032;&#39062;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#21462;&#24471;&#20102;&#22312;FDR&#21644;&#33021;&#21147;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.17176</link><description>&lt;p&gt;
DeepDRK:&#28145;&#24230;&#20381;&#36182;&#27491;&#21017;&#21270; Knockoff &#29992;&#20110;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17176
&lt;/p&gt;
&lt;p&gt;
DeepDRK&#26159;&#19968;&#31181;&#20998;&#24067;&#26080;&#20851;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#29983;&#25104;&#27169;&#22411;&#20197;&#23454;&#29616;&#8220;&#20132;&#25442;&#23646;&#24615;&#8221;&#65292;&#24182;&#25552;&#20986;&#26032;&#39062;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#21462;&#24471;&#20102;&#22312;FDR&#21644;&#33021;&#21147;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17176v1 &#20844;&#21578;&#31867;&#22411;:&#26032; &#25688;&#35201;: Model-X knockoff&#65292;&#22312;&#21508;&#31181;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#20013;&#65292;&#30001;&#20110;&#20854;&#23545;&#20551;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#25511;&#21046;&#30340;&#20445;&#35777;&#32780;&#26368;&#36817;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;&#21442;&#25968;&#35774;&#35745;&#20013;&#24341;&#20837;&#21518;&#65292;knockoff&#34987;&#21457;&#23637;&#20026;&#20351;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#29983;&#25104;&#24314;&#27169;&#26469;&#22788;&#29702;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#30446;&#21069;&#28145;&#24230;Model-X knockoff&#26694;&#26550;&#30340;&#23454;&#29616;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;knockoffs&#25152;&#38656;&#30340;&#8220;&#20132;&#25442;&#23646;&#24615;&#8221;&#32463;&#24120;&#22312;&#26679;&#26412;&#32423;&#21035;&#36935;&#21040;&#25361;&#25112;&#65292;&#23548;&#33268;&#36873;&#25321;&#33021;&#21147;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#8220;&#28145;&#24230;&#20381;&#36182;&#27491;&#21017;&#21270;Knockoff&#65288;DeepDRK&#65289;&#8221;&#65292;&#36825;&#26159;&#19968;&#31181;&#19981;&#20381;&#36182;&#20998;&#24067;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;FDR&#21644;&#33021;&#21147;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;&#22312;DeepDRK&#20013;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#26356;&#22909;&#22320;&#23454;&#29616;&#8220;&#20132;&#25442;&#23646;&#24615;&#8221;&#12290;&#36824;&#25552;&#20986;&#20102;&#26032;&#39062;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#20197;&#33719;&#24471;&#26356;&#39640;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17176v1 Announce Type: new  Abstract: Model-X knockoff, among various feature selection methods, received much attention recently due to its guarantee on false discovery rate (FDR) control. Subsequent to its introduction in parametric design, knockoff is advanced to handle arbitrary data distributions using deep learning-based generative modeling. However, we observed that current implementations of the deep Model-X knockoff framework exhibit limitations. Notably, the "swap property" that knockoffs necessitate frequently encounter challenges on sample level, leading to a diminished selection power. To overcome, we develop "Deep Dependency Regularized Knockoff (DeepDRK)", a distribution-free deep learning method that strikes a balance between FDR and power. In DeepDRK, a generative model grounded in a transformer architecture is introduced to better achieve the "swap property". Novel efficient regularization techniques are also proposed to reach higher power. Our model outper
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#23384;&#22312;&#22823;&#37327;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#30340;&#38598;&#21512;&#19981;&#23494;&#38598;&#65292;&#20855;&#26377;&#19968;&#23450;&#25299;&#25169;&#24615;&#36136;&#30340;&#23376;&#38598;&#20013;&#20063;&#23384;&#22312;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#32456;&#65292;&#21457;&#29616;&#20351;&#29992;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#20027;&#35201;&#23450;&#29702;&#27169;&#22411;&#22312;&#25968;&#23398;&#34920;&#36798;&#19978;&#24182;&#38750;&#30001;&#21333;&#19968;&#21021;&#31561;&#20989;&#25968;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.17089</link><description>&lt;p&gt;
&#36890;&#36807;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Learning high-dimensional targets by two-parameter models and gradient flow
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17089
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#23384;&#22312;&#22823;&#37327;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#30340;&#38598;&#21512;&#19981;&#23494;&#38598;&#65292;&#20855;&#26377;&#19968;&#23450;&#25299;&#25169;&#24615;&#36136;&#30340;&#23376;&#38598;&#20013;&#20063;&#23384;&#22312;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#32456;&#65292;&#21457;&#29616;&#20351;&#29992;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#20027;&#35201;&#23450;&#29702;&#27169;&#22411;&#22312;&#25968;&#23398;&#34920;&#36798;&#19978;&#24182;&#38750;&#30001;&#21333;&#19968;&#21021;&#31561;&#20989;&#25968;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#24403;$W&lt;d$&#26102;&#65292;&#36890;&#36807;&#26799;&#24230;&#27969;&#65288;GF&#65289;&#20197;$W$&#21442;&#25968;&#27169;&#22411;&#23398;&#20064;$d$&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#24517;&#28982;&#23384;&#22312;GF-&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#30340;&#22823;&#23376;&#38598;&#12290;&#29305;&#21035;&#26159;&#65292;&#21487;&#23398;&#20064;&#30446;&#26631;&#30340;&#38598;&#21512;&#22312;$\mathbb R^d$&#20013;&#19981;&#26159;&#23494;&#38598;&#30340;&#65292;&#20219;&#20309;&#24418;&#21516;$W$&#32500;&#29699;&#38754;&#30340;$\mathbb R^d$&#23376;&#38598;&#21253;&#21547;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#20960;&#20046;&#20445;&#35777;&#20108;&#21442;&#25968;&#23398;&#20064;&#30340;&#20027;&#35201;&#23450;&#29702;&#20013;&#65292;&#25152;&#36848;&#27169;&#22411;&#26159;&#36890;&#36807;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#65292;&#22240;&#27492;&#19981;&#33021;&#29992;&#21333;&#20010;&#21021;&#31561;&#20989;&#25968;&#34920;&#36798;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#38480;&#21046;&#22312;&#26412;&#36136;&#19978;&#26159;&#24517;&#35201;&#30340;&#65292;&#22240;&#20026;&#36825;&#31181;&#21487;&#23398;&#20064;&#24615;&#23545;&#20110;&#35768;&#22810;&#21021;&#31561;&#20989;&#25968;&#31867;&#30340;&#21487;&#23398;&#20064;&#24615;&#26159;&#34987;&#25490;&#38500;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17089v1 Announce Type: cross  Abstract: We explore the theoretical possibility of learning $d$-dimensional targets with $W$-parameter models by gradient flow (GF) when $W&lt;d$ there is necessarily a large subset of GF-non-learnable targets. In particular, the set of learnable targets is not dense in $\mathbb R^d$, and any subset of $\mathbb R^d$ homeomorphic to the $W$-dimensional sphere contains non-learnable targets. Finally, we observe that the model in our main theorem on almost guaranteed two-parameter learning is constructed using a hierarchical procedure and as a result is not expressible by a single elementary function. We show that this limitation is essential in the sense that such learnability can be ruled out for a large class of elementary functions.
&lt;/p&gt;</description></item><item><title>&#22312;&#19981;&#23454;&#26045;&#20844;&#24179;&#35757;&#32451;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20844;&#24179;&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#25277;&#26679;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#25968;&#25454;&#26469;&#36880;&#27493;&#36716;&#31227;&#21407;&#22987;&#35757;&#32451;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12789</link><description>&lt;p&gt;
&#26080;&#38656;&#20844;&#24179;&#35757;&#32451;&#30340;&#20844;&#24179;&#20998;&#31867;&#22120;&#65306;&#19968;&#31181;&#21463;&#24433;&#21709;&#25968;&#25454;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fair Classifiers Without Fair Training: An Influence-Guided Data Sampling Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12789
&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#23454;&#26045;&#20844;&#24179;&#35757;&#32451;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20844;&#24179;&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#25277;&#26679;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#25968;&#25454;&#26469;&#36880;&#27493;&#36716;&#31227;&#21407;&#22987;&#35757;&#32451;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#20844;&#24179;&#30340;&#20998;&#31867;&#22120;&#24212;&#35813;&#30830;&#20445;&#26469;&#33258;&#19981;&#21516;&#32676;&#20307;&#30340;&#20154;&#20204;&#21463;&#30410;&#65292;&#32780;&#32676;&#20307;&#20449;&#24687;&#24448;&#24448;&#26159;&#25935;&#24863;&#30340;&#65292;&#19981;&#36866;&#21512;&#27169;&#22411;&#35757;&#32451;&#12290;&#22240;&#27492;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#19968;&#20010;&#20844;&#24179;&#30340;&#20998;&#31867;&#22120;&#20294;&#25490;&#38500;&#25935;&#24863;&#23646;&#24615;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20844;&#24179;&#20998;&#31867;&#22120;&#32780;&#19981;&#23454;&#29616;&#20844;&#24179;&#35757;&#32451;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#36991;&#20813;&#21487;&#33021;&#27844;&#38706;&#25935;&#24863;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#39564;&#35777;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#21487;&#33021;&#24615;&#65292;&#21363;&#22312;&#20855;&#26377;&#36866;&#24403;&#20998;&#24067;&#20559;&#31227;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20256;&#32479;&#35757;&#32451;&#21487;&#20197;&#21516;&#26102;&#20943;&#23569;&#20844;&#24179;&#24046;&#36317;&#30340;&#19978;&#38480;&#21644;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#65292;&#34920;&#26126;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#21487;&#20197;&#21516;&#27493;&#25552;&#39640;&#65292;&#21482;&#38656;&#31616;&#21333;&#22320;&#36827;&#34892;&#20256;&#32479;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#25277;&#26679;&#26377;&#24433;&#21709;&#21147;&#30340;&#25968;&#25454;&#36880;&#27493;&#36716;&#31227;&#21407;&#22987;&#35757;&#32451;&#25968;&#25454;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#19981;&#35775;&#38382;&#26032;&#25968;&#25454;&#30340;&#25935;&#24863;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12789v1 Announce Type: cross  Abstract: A fair classifier should ensure the benefit of people from different groups, while the group information is often sensitive and unsuitable for model training. Therefore, learning a fair classifier but excluding sensitive attributes in the training dataset is important. In this paper, we study learning fair classifiers without implementing fair training algorithms to avoid possible leakage of sensitive information. Our theoretical analyses validate the possibility of this approach, that traditional training on a dataset with an appropriate distribution shift can reduce both the upper bound for fairness disparity and model generalization error, indicating that fairness and accuracy can be improved simultaneously with simply traditional training. We then propose a tractable solution to progressively shift the original training data during training by sampling influential data, where the sensitive attribute of new data is not accessed in s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#32544;&#32455;&#28151;&#21512;&#31163;&#25955;&#26356;&#26032;Markov&#38142;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#24809;&#32602;&#20284;&#28982;&#20998;&#25968;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#31526;&#21495;&#20998;&#32452;&#65292;&#24182;&#22312;&#30005;&#23376;&#25903;&#25588;&#25514;&#26045;&#20013;&#30340;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09166</link><description>&lt;p&gt;
&#28151;&#21512;&#31163;&#25955;&#26356;&#26032;&#36807;&#31243;&#30340;&#35299;&#32544;&#32455;&#26041;&#27861;&#21450;&#20854;&#22312;&#30005;&#23376;&#25903;&#25588;&#25514;&#26045;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deinterleaving of Discrete Renewal Process Mixtures with Application to Electronic Support Measures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#32544;&#32455;&#28151;&#21512;&#31163;&#25955;&#26356;&#26032;Markov&#38142;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#24809;&#32602;&#20284;&#28982;&#20998;&#25968;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#31526;&#21495;&#20998;&#32452;&#65292;&#24182;&#22312;&#30005;&#23376;&#25903;&#25588;&#25514;&#26045;&#20013;&#30340;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28151;&#21512;&#31163;&#25955;&#26356;&#26032;Markov&#38142;&#30340;&#26032;&#30340;&#35299;&#32544;&#32455;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#23545;&#24809;&#32602;&#20284;&#28982;&#20998;&#25968;&#30340;&#26368;&#22823;&#21270;&#12290;&#23427;&#21033;&#29992;&#20102;&#26377;&#20851;&#19981;&#21516;&#31526;&#21495;&#24207;&#21015;&#21450;&#20854;&#21040;&#36798;&#26102;&#38388;&#30340;&#25152;&#26377;&#21487;&#29992;&#20449;&#24687;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#65292;&#22312;&#32452;&#25104;&#36807;&#31243;&#19978;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#23567;&#21270;&#35813;&#20998;&#25968;&#33021;&#22815;&#22312;&#22823;&#26679;&#26412;&#38480;&#21046;&#19979;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#31526;&#21495;&#20998;&#32452;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#29702;&#35770;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#20174;RESM&#65288;&#38647;&#36798;&#30005;&#23376;&#25903;&#25588;&#27979;&#37327;&#65289;&#29615;&#22659;&#20013;&#25509;&#25910;&#21040;&#30340;&#19981;&#21516;&#21457;&#23556;&#26426;&#30340;&#33033;&#20914;&#20018;&#35299;&#32544;&#32455;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25112;&#25968;&#25454;&#38598;&#19978;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09166v1 Announce Type: new Abstract: In this paper, we propose a new deinterleaving method for mixtures of discrete renewal Markov chains. This method relies on the maximization of a penalized likelihood score. It exploits all available information about both the sequence of the different symbols and their arrival times. A theoretical analysis is carried out to prove that minimizing this score allows to recover the true partition of symbols in the large sample limit, under mild conditions on the component processes. This theoretical analysis is then validated by experiments on synthetic data. Finally, the method is applied to deinterleave pulse trains received from different emitters in a RESM (Radar Electronic Support Measurements) context and we show that the proposed method competes favorably with state-of-the-art methods on simulated warfare datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29109;&#27491;&#21017;&#21270;&#30340;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#30456;&#32467;&#21512;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#19968;&#20010;&#22797;&#26434;&#30340;&#21160;&#20316;&#20998;&#24067;&#36716;&#21270;&#20026;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#20351;&#29992;&#36870;&#26102;&#38388;SDE&#37319;&#26679;&#21160;&#20316;&#65292;&#20197;&#25913;&#21892;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#25506;&#32034;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;Q-&#38598;&#21512;&#30340;&#19979;&#20449;&#24515;&#30028;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#22312;D4RL&#22522;&#20934;&#20219;&#21153;&#30340;&#22823;&#22810;&#25968;&#20219;&#21153;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04080</link><description>&lt;p&gt;
&#29109;&#27491;&#21017;&#21270;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Entropy-regularized Diffusion Policy with Q-Ensembles for Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04080
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29109;&#27491;&#21017;&#21270;&#30340;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#30456;&#32467;&#21512;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#19968;&#20010;&#22797;&#26434;&#30340;&#21160;&#20316;&#20998;&#24067;&#36716;&#21270;&#20026;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#20351;&#29992;&#36870;&#26102;&#38388;SDE&#37319;&#26679;&#21160;&#20316;&#65292;&#20197;&#25913;&#21892;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#25506;&#32034;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;Q-&#38598;&#21512;&#30340;&#19979;&#20449;&#24515;&#30028;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#22312;D4RL&#22522;&#20934;&#20219;&#21153;&#30340;&#22823;&#22810;&#25968;&#20219;&#21153;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#35757;&#32451;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#25193;&#25955;&#31574;&#30053;&#30340;&#20808;&#36827;&#25216;&#26415;&#12290;&#26680;&#24515;&#26159;&#19968;&#20010;&#22343;&#20540;&#22238;&#24402;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#65292;&#23427;&#23558;&#22797;&#26434;&#30340;&#21160;&#20316;&#20998;&#24067;&#36716;&#21270;&#20026;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#22312;&#29615;&#22659;&#29366;&#24577;&#26465;&#20214;&#19979;&#20351;&#29992;&#30456;&#24212;&#30340;&#36870;&#26102;&#38388;SDE&#37319;&#26679;&#21160;&#20316;&#65292;&#31867;&#20284;&#20110;&#20856;&#22411;&#30340;&#25193;&#25955;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#19968;&#20010;SDE&#26377;&#35299;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#23427;&#26469;&#35745;&#31639;&#31574;&#30053;&#30340;&#23545;&#25968;&#27010;&#29575;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#29109;&#27491;&#21017;&#39033;&#65292;&#25913;&#36827;&#20102;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#25506;&#32034;&#33021;&#21147;&#12290;&#20026;&#20102;&#20943;&#36731;&#26469;&#33258;&#20998;&#24067;&#22806;&#25968;&#25454;&#28857;&#30340;&#19981;&#20934;&#30830;&#20540;&#20989;&#25968;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#23398;&#20064;Q-&#38598;&#21512;&#30340;&#19979;&#20449;&#24515;&#30028;&#20197;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#36890;&#36807;&#23558;&#29109;&#27491;&#21017;&#21270;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#32467;&#21512;&#24212;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;D4RL&#22522;&#20934;&#20219;&#21153;&#30340;&#22823;&#22810;&#25968;&#20219;&#21153;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20195;&#30721;&#21487;&#22312;\href{https://github.com/ruoqizzz/Entro}{https://github.com/ruoqizzz/Entro}&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents advanced techniques of training diffusion policies for offline reinforcement learning (RL). At the core is a mean-reverting stochastic differential equation (SDE) that transfers a complex action distribution into a standard Gaussian and then samples actions conditioned on the environment state with a corresponding reverse-time SDE, like a typical diffusion policy. We show that such an SDE has a solution that we can use to calculate the log probability of the policy, yielding an entropy regularizer that improves the exploration of offline datasets. To mitigate the impact of inaccurate value functions from out-of-distribution data points, we further propose to learn the lower confidence bound of Q-ensembles for more robust policy improvement. By combining the entropy-regularized diffusion policy with Q-ensembles in offline RL, our method achieves state-of-the-art performance on most tasks in D4RL benchmarks. Code is available at \href{https://github.com/ruoqizzz/Entro
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#31639;&#27861;&#65288;RPO&#65289;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#65292;&#24182;&#25104;&#21151;&#38477;&#20302;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2401.17263</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17263
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#31639;&#27861;&#65288;RPO&#65289;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#65292;&#24182;&#25104;&#21151;&#38477;&#20302;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#25110;&#30772;&#35299;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#20854;&#20013;&#23545;&#25163;&#20462;&#25913;&#36755;&#20837;&#25552;&#31034;&#20197;&#35825;&#23548;&#26377;&#23475;&#34892;&#20026;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#38450;&#24481;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#20165;&#20851;&#27880;&#29421;&#31364;&#30340;&#23041;&#32961;&#27169;&#22411;&#65292;&#24182;&#19981;&#33021;&#25552;&#20379;&#24378;&#22823;&#30340;&#38450;&#24481;&#12290;&#20026;&#20102;&#23454;&#29616;&#24378;&#22823;&#30340;&#38450;&#24481;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#29992;&#20110;&#23545;&#25239;&#30772;&#35299;&#25915;&#20987;&#30340;&#23545;&#25239;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#40065;&#26834;&#25552;&#31034;&#20248;&#21270;&#65288;RPO&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20196;&#29260;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#26131;&#20110;&#35775;&#38382;&#30340;&#21518;&#32512;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#23545;&#30772;&#35299;&#25915;&#20987;&#30340;&#24378;&#38887;&#24615;&#65292;&#21253;&#25324;&#20248;&#21270;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#30772;&#35299;&#25915;&#20987;&#20197;&#21450;&#26410;&#30693;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#20174;84%&#38477;&#20302;&#21040;8.66%&#65292;&#22312;20&#20010;&#30772;&#35299;&#25915;&#20987;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;RPO&#23545;&#27491;&#24120;LM&#20351;&#29992;&#30340;&#24433;&#21709;&#36739;&#23567;&#65292;&#22312;&#36866;&#24212;&#24615;&#25915;&#20987;&#19979;&#20173;&#28982;&#26377;&#25928;&#65292;&#24182;&#19988;&#21487;&#20197;&#36801;&#31227;&#21040;&#40657;&#30418;&#27169;&#22411;&#20013;&#65292;&#38477;&#20302;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite advances in AI alignment, language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior. While some defenses have been proposed, they focus on narrow threat models and fall short of a strong defense, which we posit should be effective, universal, and practical. To achieve this, we propose the first adversarial objective for defending LMs against jailbreaking attacks and an algorithm, robust prompt optimization (RPO), that uses gradient-based token optimization to enforce harmless outputs. This results in an easily accessible suffix that significantly improves robustness to both jailbreaks seen during optimization and unknown, held-out jailbreaks, reducing the attack success rate on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find that RPO has a minor effect on normal LM use, is successful under adaptive attacks, and can transfer to black-box models, reducing the success
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23398;&#20064;&#31867;&#20154;&#30340;&#34920;&#31034;&#65292;&#21487;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#31526;&#21512;&#20154;&#31867;&#20215;&#20540;&#35266;&#65292;&#25903;&#25345;&#20262;&#29702;&#31561;&#22810;&#26041;&#38754;&#30340;&#20215;&#20540;&#23545;&#40784;&#12290;</title><link>https://arxiv.org/abs/2312.14106</link><description>&lt;p&gt;
&#23398;&#20064;&#31867;&#20154;&#34920;&#31034;&#20197;&#23454;&#29616;&#23398;&#20064;&#31867;&#20154;&#20215;&#20540;&#35266;
&lt;/p&gt;
&lt;p&gt;
Learning Human-like Representations to Enable Learning Human Values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14106
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#31867;&#20154;&#30340;&#34920;&#31034;&#65292;&#21487;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#31526;&#21512;&#20154;&#31867;&#20215;&#20540;&#35266;&#65292;&#25903;&#25345;&#20262;&#29702;&#31561;&#22810;&#26041;&#38754;&#30340;&#20215;&#20540;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#26500;&#24314;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#30456;&#19968;&#33268;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#20197;&#36991;&#20813;&#36896;&#25104;&#20260;&#23475;&#25110;&#36829;&#21453;&#31038;&#20250;&#23545;&#21487;&#25509;&#21463;&#34892;&#20026;&#30340;&#26631;&#20934;&#65311;&#25105;&#20204;&#35748;&#20026;&#65292;&#20154;&#31867;&#19982;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#20043;&#38388;&#30340;&#34920;&#24449;&#23545;&#40784;&#26377;&#21161;&#20110;&#20215;&#20540;&#35266;&#30340;&#23545;&#40784;&#12290;&#20351;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23398;&#20064;&#31867;&#20154;&#31867;&#23545;&#19990;&#30028;&#30340;&#34920;&#31034;&#20855;&#26377;&#35768;&#22810;&#24050;&#30693;&#22909;&#22788;&#65292;&#21253;&#25324;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12289;&#22686;&#24378;&#23545;&#39046;&#22495;&#36716;&#31227;&#30340;&#31283;&#20581;&#24615;&#21644;&#25552;&#39640;&#23569;&#26679;&#26412;&#23398;&#20064;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#65292;&#36825;&#31181;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#34920;&#31034;&#23545;&#40784;&#20063;&#21487;&#20197;&#25903;&#25345;&#20215;&#20540;&#23545;&#40784;&#65292;&#20351;ML&#31995;&#32479;&#36981;&#24490;&#20154;&#31867;&#20215;&#20540;&#35266;&#21644;&#31038;&#20250;&#35268;&#33539;&#12290;&#25105;&#20204;&#20851;&#27880;&#20262;&#29702;&#23398;&#20316;&#20026;&#20215;&#20540;&#23545;&#40784;&#30340;&#19968;&#20010;&#26041;&#38754;&#65292;&#24182;&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#35774;&#32622;&#20013;&#20351;&#29992;&#21508;&#31181;&#26041;&#27861;&#35757;&#32451;ML&#20195;&#29702;&#65292;&#20854;&#20013;&#22870;&#21169;&#21453;&#26144;&#25152;&#36873;&#34892;&#21160;&#30340;&#36947;&#24503;&#21487;&#25509;&#21463;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21512;&#25104;&#23454;&#39564;&#26469;&#35777;&#26126;&#20195;&#29702;&#19982;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14106v2 Announce Type: replace  Abstract: How can we build AI systems that are aligned with human values to avoid causing harm or violating societal standards for acceptable behavior? We argue that representational alignment between humans and AI agents facilitates value alignment. Making AI systems learn human-like representations of the world has many known benefits, including improving generalization, robustness to domain shifts, and few-shot learning performance. We propose that this kind of representational alignment between machine learning (ML) models and humans can also support value alignment, allowing ML systems to conform to human values and societal norms. We focus on ethics as one aspect of value alignment and train ML agents using a variety of methods in a multi-armed bandit setting, where rewards reflect the moral acceptability of the chosen action. We use a synthetic experiment to demonstrate that agents' representational alignment with the environment bounds
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#24230;&#21322;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#65288;DeepSAD&#65289;&#26041;&#27861;&#36827;&#34892;&#20581;&#24247;&#25351;&#25968;&#26500;&#24314;&#65292;&#24182;&#25552;&#20986;&#20102;&#22810;&#26679;&#24615;&#25439;&#22833;&#26469;&#20016;&#23500;&#26465;&#20214;&#25351;&#26631;&#12290;</title><link>https://arxiv.org/abs/2312.02867</link><description>&lt;p&gt;
&#20351;&#29992;&#29305;&#24449;&#29983;&#25104;&#21644;&#34701;&#21512;&#30340;&#21322;&#30417;&#30563;&#20581;&#24247;&#25351;&#25968;&#30417;&#27979;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Health Index Monitoring with Feature Generation and Fusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02867
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#21322;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#65288;DeepSAD&#65289;&#26041;&#27861;&#36827;&#34892;&#20581;&#24247;&#25351;&#25968;&#26500;&#24314;&#65292;&#24182;&#25552;&#20986;&#20102;&#22810;&#26679;&#24615;&#25439;&#22833;&#26469;&#20016;&#23500;&#26465;&#20214;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20581;&#24247;&#25351;&#25968;&#65288;HI&#65289;&#23545;&#20110;&#35780;&#20272;&#31995;&#32479;&#20581;&#24247;&#29366;&#24577;&#33267;&#20851;&#37325;&#35201;&#65292;&#26377;&#21161;&#20110;&#35782;&#21035;&#24322;&#24120;&#65292;&#24182;&#39044;&#27979;&#23545;&#39640;&#23433;&#20840;&#24615;&#21644;&#21487;&#38752;&#24615;&#35201;&#27714;&#39640;&#30340;&#31995;&#32479;&#30340;&#21097;&#20313;&#20351;&#29992;&#23551;&#21629;&#12290;&#22312;&#23454;&#29616;&#39640;&#31934;&#24230;&#30340;&#21516;&#26102;&#38477;&#20302;&#25104;&#26412;&#65292;&#32039;&#23494;&#30417;&#27979;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#33719;&#21462;HI&#26631;&#31614;&#24448;&#24448;&#25104;&#26412;&#39640;&#26114;&#65292;&#38656;&#35201;&#36830;&#32493;&#12289;&#31934;&#30830;&#30340;&#20581;&#24247;&#27979;&#37327;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#21487;&#33021;&#25552;&#20379;&#28508;&#22312;&#26426;&#22120;&#30952;&#25439;&#29366;&#24577;&#25351;&#31034;&#30340;&#8220;&#36816;&#34892;&#33267;&#25925;&#38556;&#8221;&#25968;&#25454;&#38598;&#65292;&#26356;&#26041;&#20415;&#37319;&#29992;&#21322;&#30417;&#30563;&#24037;&#20855;&#26500;&#24314;HI&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02867v2 Announce Type: replace  Abstract: The Health Index (HI) is crucial for evaluating system health, aiding tasks like anomaly detection and predicting remaining useful life for systems demanding high safety and reliability. Tight monitoring is crucial for achieving high precision at a lower cost. Obtaining HI labels in real-world applications is often cost-prohibitive, requiring continuous, precise health measurements. Therefore, it is more convenient to leverage run-to failure datasets that may provide potential indications of machine wear condition, making it necessary to apply semi-supervised tools for HI construction. In this study, we adapt the Deep Semi-supervised Anomaly Detection (DeepSAD) method for HI construction. We use the DeepSAD embedding as a condition indicators to address interpretability challenges and sensitivity to system-specific factors. Then, we introduce a diversity loss to enrich condition indicators. We employ an alternating projection algorit
&lt;/p&gt;</description></item><item><title>SINCERE&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#21512;&#29702;&#30340;&#30417;&#30563;&#25193;&#23637;&#65292;&#36991;&#20813;&#20102;&#21516;&#19968;&#31867;&#21035;&#30340;&#22270;&#20687;&#30456;&#20114;&#25490;&#26021;&#65292;&#36890;&#36807;&#26356;&#22909;&#22320;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#30340;&#23884;&#20837;&#65292;&#22312;&#20445;&#25345;&#31454;&#20105;&#24615;&#20998;&#31867;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2309.14277</link><description>&lt;p&gt;
SINCERE: &#30417;&#30563;&#20449;&#24687;&#22122;&#22768;-&#23545;&#27604;&#20272;&#35745;&#20877;&#23457;
&lt;/p&gt;
&lt;p&gt;
SINCERE: Supervised Information Noise-Contrastive Estimation REvisited
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.14277
&lt;/p&gt;
&lt;p&gt;
SINCERE&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#21512;&#29702;&#30340;&#30417;&#30563;&#25193;&#23637;&#65292;&#36991;&#20813;&#20102;&#21516;&#19968;&#31867;&#21035;&#30340;&#22270;&#20687;&#30456;&#20114;&#25490;&#26021;&#65292;&#36890;&#36807;&#26356;&#22909;&#22320;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#30340;&#23884;&#20837;&#65292;&#22312;&#20445;&#25345;&#31454;&#20105;&#24615;&#20998;&#31867;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#65288;InfoNCE&#65289;&#25439;&#22833;&#20989;&#25968;&#30001;&#20110;&#20854;&#24378;&#22823;&#30340;&#23454;&#35777;&#32467;&#26524;&#21644;&#29702;&#35770;&#21160;&#26426;&#65292;&#20026;&#35768;&#22810;&#33258;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#30417;&#30563;&#23545;&#27604;&#65288;SupCon&#65289;&#25439;&#22833;&#21487;&#25193;&#23637;InfoNCE&#20197;&#20174;&#21487;&#29992;&#31867;&#26631;&#31614;&#20013;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20808;&#21069;&#30340;SupCon&#25439;&#22833;&#20844;&#24335;&#23384;&#22312;&#30097;&#38382;&#30340;&#29702;&#30001;&#65292;&#22240;&#20026;&#23427;&#21487;&#33021;&#20250;&#20419;&#20351;&#26469;&#33258;&#21516;&#19968;&#31867;&#21035;&#30340;&#26576;&#20123;&#22270;&#20687;&#22312;&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#30456;&#20114;&#25490;&#26021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#30417;&#30563;&#20449;&#24687;&#22122;&#22768;-&#23545;&#27604;&#20272;&#35745;&#20877;&#23457;&#65288;SINCERE&#65289;&#25439;&#22833;&#65292;&#20316;&#20026;&#20449;&#24687;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#29702;&#35770;&#19978;&#21512;&#29702;&#30340;&#30417;&#30563;&#25193;&#23637;&#65292;&#23427;&#27704;&#36828;&#19981;&#20250;&#23548;&#33268;&#26469;&#33258;&#21516;&#19968;&#31867;&#21035;&#30340;&#22270;&#20687;&#30456;&#20114;&#25490;&#26021;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;SINCERE&#23548;&#33268;&#19981;&#21516;&#31867;&#21035;&#30340;&#23884;&#20837;&#26356;&#22909;&#22320;&#20998;&#31163;&#65292;&#21516;&#26102;&#23545;&#20110;&#30417;&#30563;&#21644;&#36801;&#31227;&#23398;&#20064;&#25552;&#20379;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#19968;&#20010;&#20449;&#24687;&#35770;&#19978;&#30340;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.14277v2 Announce Type: replace-cross  Abstract: The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation. Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels. However, in this work we find that the prior SupCon loss formulation has questionable justification because it can encourage some images from the same class to repel one another in the learned embedding space. We propose the Supervised InfoNCE REvisited (SINCERE) loss as a theoretically-justified supervised extension of InfoNCE that never causes images from the same class to repel one another. Experiments show that SINCERE leads to better separation of embeddings from different classes while delivering competitive classification accuracy for supervised and transfer learning. We further show an information-theoretic boun
&lt;/p&gt;</description></item><item><title>K&#25240;&#20132;&#21449;&#39564;&#35777;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#24120;&#29992;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#22312;&#22788;&#29702;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#24322;&#36136;&#25968;&#25454;&#28304;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2401.16407</link><description>&lt;p&gt;
K&#25240;&#20132;&#21449;&#39564;&#35777;&#26159;&#21542;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#22909;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is K-fold cross validation the best model selection method for Machine Learning?. (arXiv:2401.16407v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16407
&lt;/p&gt;
&lt;p&gt;
K&#25240;&#20132;&#21449;&#39564;&#35777;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#24120;&#29992;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#22312;&#22788;&#29702;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#24322;&#36136;&#25968;&#25454;&#28304;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#33021;&#22815;&#32039;&#20945;&#34920;&#31034;&#22797;&#26434;&#27169;&#24335;&#30340;&#25216;&#26415;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#39044;&#27979;&#25512;&#29702;&#28508;&#21147;&#12290;K&#25240;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#26159;&#30830;&#23450;&#26426;&#22120;&#23398;&#20064;&#32467;&#26524;&#26159;&#21542;&#26159;&#38543;&#26426;&#29983;&#25104;&#30340;&#26368;&#24120;&#29992;&#26041;&#27861;&#65292;&#24182;&#32463;&#24120;&#20248;&#20110;&#20256;&#32479;&#30340;&#20551;&#35774;&#26816;&#39564;&#12290;&#36825;&#31181;&#25913;&#36827;&#21033;&#29992;&#20102;&#30452;&#25509;&#20174;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#20013;&#33719;&#24471;&#30340;&#24230;&#37327;&#65292;&#27604;&#22914;&#20934;&#30830;&#24615;&#65292;&#36825;&#20123;&#24230;&#37327;&#27809;&#26377;&#21442;&#25968;&#25551;&#36848;&#12290;&#20026;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#36827;&#34892;&#39057;&#29575;&#20998;&#26512;&#65292;&#21487;&#20197;&#28155;&#21152;&#25490;&#21015;&#27979;&#35797;&#25110;&#26469;&#33258;&#25968;&#25454;&#20998;&#21306;&#65288;&#21363;&#25240;&#21472;&#65289;&#30340;&#31616;&#21333;&#32479;&#35745;&#37327;&#26469;&#20272;&#35745;&#32622;&#20449;&#21306;&#38388;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#26080;&#35770;&#26159;&#21442;&#25968;&#21270;&#36824;&#26159;&#38750;&#21442;&#25968;&#21270;&#27979;&#35797;&#37117;&#26080;&#27861;&#35299;&#20915;&#22260;&#32469;&#20998;&#21106;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#26469;&#33258;&#24322;&#36136;&#25968;&#25454;&#28304;&#30340;&#23398;&#20064;&#22266;&#26377;&#38382;&#39064;&#12290;&#26426;&#22120;&#23398;&#20064;&#20005;&#37325;&#20381;&#36182;&#23398;&#20064;&#21442;&#25968;&#21644;&#25968;&#25454;&#22312;&#25240;&#21472;&#20013;&#30340;&#20998;&#24067;&#65292;&#36825;&#37325;&#26032;&#27010;&#25324;&#20102;&#29087;&#24713;&#30340;&#22256;&#38590;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a technique that can compactly represent complex patterns, machine learning has significant potential for predictive inference. K-fold cross-validation (CV) is the most common approach to ascertaining the likelihood that a machine learning outcome is generated by chance and frequently outperforms conventional hypothesis testing. This improvement uses measures directly obtained from machine learning classifications, such as accuracy, that do not have a parametric description. To approach a frequentist analysis within machine learning pipelines, a permutation test or simple statistics from data partitions (i.e. folds) can be added to estimate confidence intervals. Unfortunately, neither parametric nor non-parametric tests solve the inherent problems around partitioning small sample-size datasets and learning from heterogeneous data sources. The fact that machine learning strongly depends on the learning parameters and the distribution of data across folds recapitulates familiar diffic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15771</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#25968;&#25454;&#39537;&#21160;&#40065;&#26834;&#20248;&#21270;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#36890;&#24120;&#28041;&#21450;&#20248;&#21270;&#25968;&#25454;&#39537;&#21160;&#30340;&#39118;&#38505;&#20934;&#21017;&#12290;&#39118;&#38505;&#36890;&#24120;&#26159;&#26681;&#25454;&#32463;&#39564;&#25968;&#25454;&#20998;&#24067;&#35745;&#31639;&#30340;&#65292;&#20294;&#30001;&#20110;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#31283;&#23450;&#21644;&#19981;&#22909;&#30340;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#40065;&#26834;&#20934;&#21017;&#65292;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#65288;&#21363;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65289;&#29702;&#35770;&#21644;&#26368;&#36817;&#30340;&#24179;&#28369;&#27169;&#31946;&#35268;&#36991;&#20559;&#22909;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30340;&#35265;&#35299;&#30456;&#32467;&#21512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#30340;&#26032;&#36830;&#25509;&#65292;&#20854;&#20013;&#21253;&#25324;&#23725;&#22238;&#24402;&#21644;&#22871;&#32034;&#22238;&#24402;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#40065;&#26834;&#20248;&#21270;&#36807;&#31243;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#32479;&#35745;&#20445;&#35777;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#23384;&#22312;&#12290;&#23545;&#20110;&#23454;&#38469;&#23454;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#34920;&#31034;&#30340;&#21487;&#34892;&#36817;&#20284;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
&lt;/p&gt;</description></item><item><title>&#36793;&#32536;&#21464;&#25442;&#22120;&#26159;&#19968;&#20010;&#20840;&#23616;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#33267;&#23569;3-WL&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#36229;&#36807;&#20854;&#20182;&#26550;&#26500;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#12290;</title><link>http://arxiv.org/abs/2401.10119</link><description>&lt;p&gt;
&#36208;&#21521;&#22522;&#20110;&#21407;&#21017;&#30340;&#22270;&#24418;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Towards Principled Graph Transformers. (arXiv:2401.10119v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10119
&lt;/p&gt;
&lt;p&gt;
&#36793;&#32536;&#21464;&#25442;&#22120;&#26159;&#19968;&#20010;&#20840;&#23616;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#33267;&#23569;3-WL&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#36229;&#36807;&#20854;&#20182;&#26550;&#26500;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;k&#32500;Weisfeiler-Leman&#65288;k-WL&#65289;&#23618;&#27425;&#32467;&#26500;&#30340;&#22270;&#24418;&#23398;&#20064;&#26550;&#26500;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#24456;&#22909;&#29702;&#35299;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#26550;&#26500;&#22312;&#30495;&#23454;&#20219;&#21153;&#20013;&#24448;&#24448;&#26080;&#27861;&#25552;&#20379;&#21487;&#38752;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24433;&#21709;&#21147;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#22522;&#20110;&#20840;&#23616;&#27880;&#24847;&#21147;&#30340;&#27169;&#22411;&#22914;&#22270;&#24418;&#21464;&#25442;&#22120;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#20294;&#26159;&#23558;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#19982;k-WL&#23618;&#27425;&#32467;&#26500;&#36827;&#34892;&#27604;&#36739;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#23588;&#20854;&#26159;&#22240;&#20026;&#36825;&#20123;&#26550;&#26500;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#26469;&#23454;&#29616;&#20854;&#34920;&#36798;&#33021;&#21147;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#36793;&#32536;&#21464;&#25442;&#22120;&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;&#33410;&#28857;&#23545;&#32780;&#19981;&#26159;&#33410;&#28857;&#19978;&#36827;&#34892;&#25805;&#20316;&#30340;&#20840;&#23616;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#20855;&#26377;&#33267;&#23569;3-WL&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36793;&#32536;&#21464;&#25442;&#22120;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20854;&#20182;&#29702;&#35770;&#23545;&#40784;&#30340;&#26550;&#26500;&#65292;&#21516;&#26102;&#19981;&#20381;&#36182;&#20110;&#20301;&#32622;&#25110;&#32467;&#26500;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph learning architectures based on the k-dimensional Weisfeiler-Leman (k-WL) hierarchy offer a theoretically well-understood expressive power. However, such architectures often fail to deliver solid predictive performance on real-world tasks, limiting their practical impact. In contrast, global attention-based models such as graph transformers demonstrate strong performance in practice, but comparing their expressive power with the k-WL hierarchy remains challenging, particularly since these architectures rely on positional or structural encodings for their expressivity and predictive performance. To address this, we show that the recently proposed Edge Transformer, a global attention model operating on node pairs instead of nodes, has at least 3-WL expressive power. Empirically, we demonstrate that the Edge Transformer surpasses other theoretically aligned architectures regarding predictive performance while not relying on positional or structural encodings.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01981</link><description>&lt;p&gt;
&#36229;&#36234;&#36951;&#25022;&#65306;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#20960;&#20309;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Beyond Regrets: Geometric Metrics for Bayesian Optimization. (arXiv:2401.01981v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#38024;&#23545;&#40657;&#30418;&#23376;&#30446;&#26631;&#20989;&#25968;&#30340;&#21407;&#21017;&#24615;&#20248;&#21270;&#31574;&#30053;&#12290;&#23427;&#22312;&#31185;&#23398;&#21457;&#29616;&#21644;&#23454;&#39564;&#35774;&#35745;&#31561;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#25928;&#26524;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#36890;&#24120;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#22522;&#20110;&#36951;&#25022;&#30340;&#24230;&#37327;&#26469;&#35780;&#20272;&#30340;&#65292;&#22914;&#30636;&#26102;&#36951;&#25022;&#12289;&#31616;&#21333;&#36951;&#25022;&#21644;&#32047;&#31215;&#36951;&#25022;&#12290;&#36825;&#20123;&#24230;&#37327;&#20165;&#20381;&#36182;&#20110;&#20989;&#25968;&#35780;&#20272;&#65292;&#22240;&#27492;&#23427;&#20204;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#35299;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#65292;&#20063;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#26412;&#36523;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#20204;&#19981;&#33021;&#21306;&#20998;&#26159;&#21542;&#25104;&#21151;&#25214;&#21040;&#20102;&#22810;&#20010;&#20840;&#23616;&#35299;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#20063;&#19981;&#33021;&#35780;&#20272;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#32473;&#23450;&#25628;&#32034;&#31354;&#38388;&#20013;&#21033;&#29992;&#21644;&#25506;&#32034;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21363;&#31934;&#30830;&#24230;&#12289;&#21484;&#22238;&#29575;&#12289;&#24179;&#22343;&#24230;&#21644;&#24179;&#22343;&#36317;&#31163;&#12290;&#36825;&#20123;&#24230;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a principled optimization strategy for a black-box objective function. It shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. In general, the performance of Bayesian optimization is assessed by regret-based metrics such as instantaneous, simple, and cumulative regrets. These metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. Notably, they cannot discriminate if multiple global solutions are successfully found. Moreover, they do not evaluate Bayesian optimization's abilities to exploit and explore a search space given. To tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. These metrics allow us to compare Bayesian optimization algorithms considering the geometry of both query points and global optima, or que
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#22312;&#32447;&#36716;&#25442;&#21450;&#20854;&#24102;&#26377;&#20999;&#25442;&#25104;&#26412;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#38408;&#20540;&#31639;&#27861;&#20197;&#21450;&#23398;&#20064;&#22686;&#24378;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#26368;&#23567;&#21270;&#21644;&#26368;&#22823;&#21270;&#21464;&#20307;&#20013;&#37117;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.20598</link><description>&lt;p&gt;
&#22312;&#32447;&#36716;&#25442;&#21450;&#20854;&#24102;&#26377;&#20999;&#25442;&#25104;&#26412;&#65306;&#31283;&#20581;&#21644;&#23398;&#20064;&#22686;&#24378;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Conversion with Switching Costs: Robust and Learning-Augmented Algorithms. (arXiv:2310.20598v2 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#22312;&#32447;&#36716;&#25442;&#21450;&#20854;&#24102;&#26377;&#20999;&#25442;&#25104;&#26412;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#38408;&#20540;&#31639;&#27861;&#20197;&#21450;&#23398;&#20064;&#22686;&#24378;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#26368;&#23567;&#21270;&#21644;&#26368;&#22823;&#21270;&#21464;&#20307;&#20013;&#37117;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#24182;&#30740;&#31350;&#22312;&#32447;&#36716;&#25442;&#21450;&#20854;&#24102;&#26377;&#20999;&#25442;&#25104;&#26412;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#28085;&#30422;&#20102;&#33021;&#28304;&#21644;&#21487;&#25345;&#32493;&#24615;&#20132;&#21449;&#39046;&#22495;&#20013;&#20986;&#29616;&#30340;&#19968;&#31995;&#21015;&#26032;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#22312;&#32447;&#29609;&#23478;&#35797;&#22270;&#22312;&#22266;&#23450;&#30340;&#26102;&#38388;&#27573;&#20869;&#36141;&#20080;&#65288;&#25110;&#38144;&#21806;&#65289;&#36164;&#20135;&#30340;&#20998;&#25968;&#20221;&#39069;&#65292;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#37117;&#20250;&#20844;&#24067;&#25104;&#26412;&#65288;&#25110;&#20215;&#26684;&#65289;&#20989;&#25968;&#65292;&#24182;&#19988;&#29609;&#23478;&#24517;&#39035;&#20570;&#20986;&#19981;&#21487;&#25764;&#28040;&#30340;&#20915;&#31574;&#65292;&#20915;&#23450;&#36716;&#25442;&#30340;&#36164;&#20135;&#25968;&#37327;&#12290;&#24403;&#29609;&#23478;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#20013;&#25913;&#21464;&#20915;&#31574;&#26102;&#65292;&#20063;&#20250;&#20135;&#29983;&#20999;&#25442;&#25104;&#26412;&#65292;&#21363;&#22312;&#36141;&#20080;&#37327;&#22686;&#21152;&#25110;&#20943;&#23569;&#26102;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#22312;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#23567;&#21270;&#21644;&#26368;&#22823;&#21270;&#21464;&#20307;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#65288;&#31283;&#20581;&#65289;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#31639;&#27861;&#65292;&#24182;&#19988;&#35777;&#26126;&#23427;&#20204;&#26159;&#30830;&#23450;&#24615;&#22312;&#32447;&#31639;&#27861;&#20013;&#30340;&#26368;&#20248;&#31639;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#22686;&#24378;&#31639;&#27861;&#65292;&#21033;&#29992;&#19981;&#21487;&#20449;&#30340;&#40657;&#30418;&#24314;&#35758;&#65288;&#20363;&#22914;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#65289;&#26469;&#26174;&#33879;&#25913;&#21892;&#31639;&#27861;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce and study online conversion with switching costs, a family of online problems that capture emerging problems at the intersection of energy and sustainability. In this problem, an online player attempts to purchase (alternatively, sell) fractional shares of an asset during a fixed time horizon with length $T$. At each time step, a cost function (alternatively, price function) is revealed, and the player must irrevocably decide an amount of asset to convert. The player also incurs a switching cost whenever their decision changes in consecutive time steps, i.e., when they increase or decrease their purchasing amount. We introduce competitive (robust) threshold-based algorithms for both the minimization and maximization variants of this problem, and show they are optimal among deterministic online algorithms. We then propose learning-augmented algorithms that take advantage of untrusted black-box advice (such as predictions from a machine learning model) to achieve significant
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#30001;&#35821;&#20041;&#36890;&#20449;&#22686;&#24378;&#30340;&#26080;&#32447;AI&#29983;&#25104;&#20869;&#23481;&#65288;AIGC&#65289;&#20379;&#24212;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#35821;&#20041;&#20449;&#24687;&#32780;&#19981;&#26159;&#25152;&#26377;&#30340;&#20108;&#36827;&#21046;&#20301;&#25552;&#21462;&#21644;&#20256;&#36755;&#20869;&#23481;&#65292;&#20197;&#35299;&#20915;&#22312;&#26080;&#32447;&#32593;&#32476;&#20013;&#25552;&#20379;&#26368;&#20248;AIGC&#26381;&#21153;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.17705</link><description>&lt;p&gt;
&#19968;&#31181;&#30001;&#35821;&#20041;&#36890;&#20449;&#22686;&#24378;&#30340;&#26080;&#32447;AI&#29983;&#25104;&#20869;&#23481;&#65288;AIGC&#65289;&#20379;&#24212;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered by Semantic Communication. (arXiv:2310.17705v1 [cs.NI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17705
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#30001;&#35821;&#20041;&#36890;&#20449;&#22686;&#24378;&#30340;&#26080;&#32447;AI&#29983;&#25104;&#20869;&#23481;&#65288;AIGC&#65289;&#20379;&#24212;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#35821;&#20041;&#20449;&#24687;&#32780;&#19981;&#26159;&#25152;&#26377;&#30340;&#20108;&#36827;&#21046;&#20301;&#25552;&#21462;&#21644;&#20256;&#36755;&#20869;&#23481;&#65292;&#20197;&#35299;&#20915;&#22312;&#26080;&#32447;&#32593;&#32476;&#20013;&#25552;&#20379;&#26368;&#20248;AIGC&#26381;&#21153;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#29983;&#25104;&#24335;AI&#24212;&#29992;&#36890;&#36807;&#21019;&#24314;&#22810;&#26679;&#21270;&#19988;&#39640;&#36136;&#37327;&#30340;AI&#29983;&#25104;&#20869;&#23481;&#65288;AIGC&#65289;&#26469;&#28385;&#36275;&#24191;&#22823;&#29992;&#25143;&#32676;&#20307;&#30340;&#38656;&#27714;&#12290;&#38543;&#30528;&#31227;&#21160;&#35774;&#22791;&#30340;&#26222;&#21450;&#21644;&#31227;&#21160;&#27969;&#37327;&#30340;&#24555;&#36895;&#22686;&#38271;&#65292;&#36890;&#36807;&#26080;&#32447;&#36890;&#20449;&#32593;&#32476;&#25552;&#20379;&#23545;&#39640;&#36136;&#37327;AIGC&#26381;&#21153;&#30340;&#26080;&#22788;&#19981;&#22312;&#30340;&#35775;&#38382;&#24050;&#25104;&#20026;AIGC&#20135;&#21697;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;&#28982;&#32780;&#65292;&#22312;&#19981;&#31283;&#23450;&#30340;&#20449;&#36947;&#12289;&#26377;&#38480;&#30340;&#24102;&#23485;&#36164;&#28304;&#21644;&#20998;&#24067;&#19981;&#22343;&#21248;&#30340;&#35745;&#31639;&#36164;&#28304;&#30340;&#26080;&#32447;&#32593;&#32476;&#20013;&#25552;&#20379;&#26368;&#20248;&#30340;AIGC&#26381;&#21153;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#30001;&#35821;&#20041;&#36890;&#20449;&#65288;SemCom&#65289;&#22686;&#24378;&#30340;AIGC&#65288;SemAIGC&#65289;&#29983;&#25104;&#21644;&#20256;&#36755;&#26694;&#26550;&#65292;&#20854;&#20013;&#21482;&#38656;&#25552;&#21462;&#21644;&#20256;&#36755;&#20869;&#23481;&#30340;&#35821;&#20041;&#20449;&#24687;&#32780;&#19981;&#26159;&#25152;&#26377;&#30340;&#20108;&#36827;&#21046;&#20301;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SemAIGC&#22312;&#35821;&#20041;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#20013;&#38598;&#25104;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#27169;&#22411;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#20869;&#23481;&#29983;&#25104;&#21644;&#28789;&#27963;&#35843;&#25972;&#35745;&#31639;&#24037;&#20316;&#36127;&#36733;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI applications are recently catering to a vast user base by creating diverse and high-quality AI-generated content (AIGC). With the proliferation of mobile devices and rapid growth of mobile traffic, providing ubiquitous access to high-quality AIGC services via wireless communication networks is becoming the future direction for AIGC products. However, it is challenging to provide optimal AIGC services in wireless networks with unstable channels, limited bandwidth resources, and unevenly distributed computational resources. To tackle these challenges, we propose a semantic communication (SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where only semantic information of the content rather than all the binary bits should be extracted and transmitted by using SemCom. Specifically, SemAIGC integrates diffusion-based models within the semantic encoder and decoder for efficient content generation and flexible adjustment of the computing workload of both tr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22240;&#26524;&#24863;&#30693;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#21160;&#24577;&#22270;&#20013;&#30340;&#26102;&#38388;&#20013;&#24515;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;13&#20010;&#26102;&#38388;&#22270;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26174;&#33879;&#25913;&#21892;&#20102;&#20171;&#25968;&#21644;&#25509;&#36817;&#24230;&#20013;&#24515;&#24615;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.15865</link><description>&lt;p&gt;
&#20351;&#29992;&#22240;&#26524;&#24863;&#30693;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#21160;&#24577;&#22270;&#20013;&#39044;&#27979;&#26102;&#38388;&#20013;&#24515;&#24615;
&lt;/p&gt;
&lt;p&gt;
Using Causality-Aware Graph Neural Networks to Predict Temporal Centralities in Dynamic Graphs. (arXiv:2310.15865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22240;&#26524;&#24863;&#30693;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#21160;&#24577;&#22270;&#20013;&#30340;&#26102;&#38388;&#20013;&#24515;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;13&#20010;&#26102;&#38388;&#22270;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26174;&#33879;&#25913;&#21892;&#20102;&#20171;&#25968;&#21644;&#25509;&#36817;&#24230;&#20013;&#24515;&#24615;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33410;&#28857;&#20013;&#24515;&#24615;&#22312;&#32593;&#32476;&#31185;&#23398;&#12289;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#26102;&#38388;&#25968;&#25454;&#20013;&#65292;&#38745;&#24577;&#22522;&#20110;&#36335;&#24452;&#30340;&#20013;&#24515;&#24615;&#22914;&#25509;&#36817;&#24230;&#25110;&#20171;&#25968;&#21487;&#33021;&#20250;&#23545;&#33410;&#28857;&#22312;&#26102;&#38388;&#22270;&#20013;&#30340;&#30495;&#23454;&#37325;&#35201;&#24615;&#20135;&#29983;&#35823;&#23548;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24050;&#32463;&#23450;&#20041;&#20102;&#22522;&#20110;&#33410;&#28857;&#23545;&#20043;&#38388;&#26368;&#30701;&#26102;&#38388;&#36335;&#24452;&#30340;&#26102;&#38388;&#19968;&#33324;&#21270;&#20171;&#25968;&#21644;&#25509;&#36817;&#24230;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#19968;&#33324;&#21270;&#30340;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#26159;&#35745;&#31639;&#36825;&#26679;&#30340;&#36335;&#24452;&#30340;&#35745;&#31639;&#25104;&#26412;&#36739;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;De Bruijn&#22270;&#31070;&#32463;&#32593;&#32476;(DBGNN)&#65292;&#19968;&#31181;&#22240;&#26524;&#24863;&#30693;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#22312;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#39044;&#27979;&#22522;&#20110;&#36335;&#24452;&#30340;&#26102;&#38388;&#20013;&#24515;&#24615;&#12290;&#25105;&#20204;&#22312;13&#20010;&#29983;&#29289;&#21644;&#31038;&#20132;&#31995;&#32479;&#30340;&#26102;&#38388;&#22270;&#20013;&#23454;&#39564;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#26174;&#31034;&#23427;&#30456;&#27604;&#38745;&#24577;&#22270;&#21367;&#31215;&#26041;&#27861;&#26174;&#33879;&#25913;&#21892;&#20102;&#20171;&#25968;&#21644;&#25509;&#36817;&#24230;&#20013;&#24515;&#24615;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Node centralities play a pivotal role in network science, social network analysis, and recommender systems. In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph. To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes. However, a major issue of those generalizations is that the calculation of such paths is computationally expensive. Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data. We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolut
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;R2SL&#30340;&#22522;&#20110;&#21306;&#22495;&#30340;&#21452;&#28508;&#22312;&#29366;&#24577;&#23398;&#20064;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#36890;&#36807;&#27719;&#24635;&#25968;&#25454;&#26469;&#25429;&#25417;&#21306;&#22495;&#32593;&#32476;&#34892;&#20026;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#24182;&#37319;&#29992;&#22686;&#24378;&#30340;Huber&#25439;&#22833;&#20989;&#25968;&#26469;&#25552;&#39640;QoS&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.05988</link><description>&lt;p&gt;
&#19968;&#31181;&#21452;&#28508;&#22312;&#29366;&#24577;&#23398;&#20064;&#26041;&#27861;&#65306;&#21033;&#29992;&#21306;&#22495;&#32593;&#32476;&#30456;&#20284;&#24615;&#36827;&#34892;QoS&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Dual Latent State Learning Approach: Exploiting Regional Network Similarities for QoS Prediction. (arXiv:2310.05988v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;R2SL&#30340;&#22522;&#20110;&#21306;&#22495;&#30340;&#21452;&#28508;&#22312;&#29366;&#24577;&#23398;&#20064;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#36890;&#36807;&#27719;&#24635;&#25968;&#25454;&#26469;&#25429;&#25417;&#21306;&#22495;&#32593;&#32476;&#34892;&#20026;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#24182;&#37319;&#29992;&#22686;&#24378;&#30340;Huber&#25439;&#22833;&#20989;&#25968;&#26469;&#25552;&#39640;QoS&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#23450;&#21306;&#22495;&#20869;&#30340;&#20010;&#20307;&#23545;&#35937;&#65292;&#26080;&#35770;&#26159;&#29992;&#25143;&#36824;&#26159;&#26381;&#21153;&#65292;&#36890;&#24120;&#30001;&#20110;&#23427;&#20204;&#26469;&#33258;&#21516;&#19968;&#22478;&#24066;&#25110;&#33258;&#27835;&#31995;&#32479;&#65288;AS&#65289;&#65292;&#23637;&#29616;&#20986;&#30456;&#20284;&#30340;&#32593;&#32476;&#29366;&#24577;&#12290;&#23613;&#31649;&#23384;&#22312;&#21306;&#22495;&#32593;&#32476;&#30456;&#20284;&#24615;&#65292;&#20294;&#35768;&#22810;&#29616;&#26377;&#25216;&#26415;&#24573;&#35270;&#20102;&#20854;&#28508;&#21147;&#65292;&#23548;&#33268;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#26631;&#31614;&#19981;&#24179;&#34913;&#31561;&#25361;&#25112;&#32780;&#20135;&#29983;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#22522;&#20110;&#21306;&#22495;&#30340;&#21452;&#28508;&#22312;&#29366;&#24577;&#23398;&#20064;&#32593;&#32476;&#65288;R2SL&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#20811;&#26381;&#20256;&#32479;&#22522;&#20110;&#20010;&#20307;&#23545;&#35937;&#30340;QoS&#39044;&#27979;&#25216;&#26415;&#30340;&#32570;&#28857;&#12290;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;R2SL&#36890;&#36807;&#20174;&#20844;&#20849;&#21306;&#22495;&#27719;&#24635;&#30340;&#25968;&#25454;&#26500;&#24314;&#20102;&#20004;&#20010;&#19981;&#21516;&#30340;&#21306;&#22495;&#32593;&#32476;&#28508;&#22312;&#29366;&#24577;&#65306;&#22478;&#24066;&#32593;&#32476;&#28508;&#22312;&#29366;&#24577;&#21644;AS&#32593;&#32476;&#28508;&#22312;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;R2SL&#37319;&#29992;&#20102;&#22686;&#24378;&#30340;Huber&#25439;&#22833;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individual objects, whether users or services, within a specific region often exhibit similar network states due to their shared origin from the same city or autonomous system (AS). Despite this regional network similarity, many existing techniques overlook its potential, resulting in subpar performance arising from challenges such as data sparsity and label imbalance. In this paper, we introduce the regional-based dual latent state learning network(R2SL), a novel deep learning framework designed to overcome the pitfalls of traditional individual object-based prediction techniques in Quality of Service (QoS) prediction. Unlike its predecessors, R2SL captures the nuances of regional network behavior by deriving two distinct regional network latent states: the city-network latent state and the AS-network latent state. These states are constructed utilizing aggregated data from common regions rather than individual object data. Furthermore, R2SL adopts an enhanced Huber loss function that
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RO2O&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#21644;&#24179;&#28369;&#24615;&#22686;&#24378;&#31163;&#32447;&#35757;&#32451;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#22312;&#31163;&#32447;&#21040;&#22312;&#32447;&#23398;&#20064;&#20013;&#32531;&#35299;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.16973</link><description>&lt;p&gt;
&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#21644;&#24179;&#28369;&#24615;&#23454;&#29616;&#24378;&#21270;&#23398;&#20064;&#30340;&#40065;&#26834;&#31163;&#32447;&#21040;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Robust Offline-to-Online Reinforcement Learning via Uncertainty and Smoothness. (arXiv:2309.16973v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16973
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RO2O&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#21644;&#24179;&#28369;&#24615;&#22686;&#24378;&#31163;&#32447;&#35757;&#32451;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#22312;&#31163;&#32447;&#21040;&#22312;&#32447;&#23398;&#20064;&#20013;&#32531;&#35299;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20197;&#36739;&#23569;&#30340;&#20114;&#21160;&#27425;&#25968;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#31574;&#30053;&#65292;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#26159;&#23558;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;&#36890;&#36807;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65289;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;&#36890;&#36807;&#19982;&#29615;&#22659;&#20114;&#21160;&#25506;&#32034;&#20449;&#24687;&#20016;&#23500;&#30340;&#36716;&#25442;&#65289;&#30456;&#32467;&#21512;&#12290;&#31163;&#32447;&#21040;&#22312;&#32447;&#65288;O2O&#65289;&#24378;&#21270;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#25913;&#36827;&#31163;&#32447;&#35757;&#32451;&#20195;&#29702;&#30340;&#33539;&#20363;&#65292;&#20294;&#30001;&#20110;&#22312;&#32447;&#32463;&#39564;&#19982;&#31163;&#32447;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#20998;&#24067;&#20559;&#24046;&#65292;&#22823;&#22810;&#25968;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22312;O2O&#36866;&#24212;&#20013;&#24615;&#33021;&#19979;&#38477;&#24182;&#26080;&#27861;&#23454;&#29616;&#31283;&#23450;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Robust Offline-to-Online&#65288;RO2O&#65289;&#31639;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#21644;&#24179;&#28369;&#24615;&#22686;&#24378;&#31163;&#32447;&#31574;&#30053;&#65292;&#24182;&#20943;&#23569;&#22312;&#32447;&#36866;&#24212;&#20013;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;RO2O&#31639;&#27861;&#36890;&#36807;Q-ensemble&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#24809;&#32602;&#65292;&#24182;&#36890;&#36807;&#23545;&#25239;&#26679;&#26412;&#23454;&#29616;&#31574;&#30053;&#21644;&#20215;&#20540;&#30340;&#24179;&#28369;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;RO2O&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
To obtain a near-optimal policy with fewer interactions in Reinforcement Learning (RL), a promising approach involves the combination of offline RL, which enhances sample efficiency by leveraging offline datasets, and online RL, which explores informative transitions by interacting with the environment. Offline-to-Online (O2O) RL provides a paradigm for improving an offline trained agent within limited online interactions. However, due to the significant distribution shift between online experiences and offline data, most offline RL algorithms suffer from performance drops and fail to achieve stable policy improvement in O2O adaptation. To address this problem, we propose the Robust Offline-to-Online (RO2O) algorithm, designed to enhance offline policies through uncertainty and smoothness, and to mitigate the performance drop in online adaptation. Specifically, RO2O incorporates Q-ensemble for uncertainty penalty and adversarial samples for policy and value smoothness, which enable RO2
&lt;/p&gt;</description></item><item><title>PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function.</title><link>http://arxiv.org/abs/2308.02580</link><description>&lt;p&gt;
Probabilistic Deep Supervision Network: &#19968;&#31181;&#25239;&#22122;&#22768;&#30340;QoS&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction. (arXiv:2308.02580v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02580
&lt;/p&gt;
&lt;p&gt;
PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;QoS&#65288;&#26381;&#21153;&#36136;&#37327;&#65289;&#30340;&#39044;&#27979;&#26159;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#20934;&#30830;&#39044;&#27979;&#26410;&#30693;&#30340;QoS&#20540;&#21487;&#20197;&#25552;&#39640;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;QoS&#39044;&#27979;&#25216;&#26415;&#22312;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#65288;&#22914;&#34394;&#20551;&#20301;&#32622;&#20449;&#24687;&#25110;&#34394;&#25311;&#32593;&#20851;&#65289;&#26102;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;QoS&#39044;&#27979;&#26694;&#26550;&#8212;&#8212;&#27010;&#29575;&#28145;&#24230;&#30417;&#30563;&#32593;&#32476;&#65288;PDS-Net&#65289;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;PDS-Net&#21033;&#29992;&#22522;&#20110;&#39640;&#26031;&#30340;&#27010;&#29575;&#31354;&#38388;&#30417;&#30563;&#20013;&#38388;&#23618;&#65292;&#24182;&#23398;&#20064;&#24050;&#30693;&#29305;&#24449;&#21644;&#30495;&#23454;&#26631;&#31614;&#30340;&#27010;&#29575;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;PDS-Net&#37319;&#29992;&#22522;&#20110;&#26465;&#20214;&#30340;&#22810;&#20219;&#21153;&#25439;&#22833;&#20989;&#25968;&#26469;&#35782;&#21035;&#20855;&#26377;&#22122;&#22768;&#25968;&#25454;&#30340;&#23545;&#35937;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#36825;&#20123;&#23545;&#35937;&#30340;&#27010;&#29575;&#31354;&#38388;&#19982;&#30495;&#23454;&#26631;&#31614;&#27010;&#29575;&#31354;&#38388;&#20043;&#38388;&#30340;Kullback-Leibler&#36317;&#31163;&#65292;&#30452;&#25509;&#23545;&#20174;&#27010;&#29575;&#31354;&#38388;&#20013;&#37319;&#26679;&#30340;&#28145;&#24230;&#29305;&#24449;&#36827;&#34892;&#30417;&#30563;&#12290;&#22240;&#27492;&#65292;PDS-Net&#26377;&#25928;&#20943;&#23569;&#20102;&#22240;&#20256;&#25773;&#24341;&#36215;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quality of Service (QoS) prediction is an essential task in recommendation systems, where accurately predicting unknown QoS values can improve user satisfaction. However, existing QoS prediction techniques may perform poorly in the presence of noise data, such as fake location information or virtual gateways. In this paper, we propose the Probabilistic Deep Supervision Network (PDS-Net), a novel framework for QoS prediction that addresses this issue. PDS-Net utilizes a Gaussian-based probabilistic space to supervise intermediate layers and learns probability spaces for both known features and true labels. Moreover, PDS-Net employs a condition-based multitasking loss function to identify objects with noise data and applies supervision directly to deep features sampled from the probability space by optimizing the Kullback-Leibler distance between the probability space of these objects and the real-label probability space. Thus, PDS-Net effectively reduces errors resulting from the propag
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09254</link><description>&lt;p&gt;
&#29992;&#20110;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#22686;&#24378;&#27169;&#22411;&#21487;&#20449;&#24230;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#30001;&#20110;&#23545;&#29983;&#25104;&#34394;&#26500;&#20107;&#23454;&#30340;&#25285;&#24551;&#65292;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;GLM&#65289;&#29305;&#21035;&#24378;&#35843;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31070;&#32463;&#39044;&#27979;&#38598;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#26041;&#24335;&#37327;&#21270;GLM&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#39044;&#27979;&#38598;&#27169;&#22411;&#36890;&#36807;&#26631;&#37327;&#20540;&#21442;&#25968;&#21270;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#39044;&#27979;&#38598;&#65292;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20173;&#28385;&#36275;PAC&#20445;&#35777;&#12290;&#36890;&#36807;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#20845;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#22810;&#32423;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#32676;&#20307;&#25968;&#25454;&#35270;&#20026;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#24182;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#65292;&#20197;&#23454;&#29616;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;</title><link>http://arxiv.org/abs/2305.08657</link><description>&lt;p&gt;
&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#32534;&#30721;&#21040;&#22810;&#32423;&#27169;&#22411;&#20013;&#29992;&#20110;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;
Encoding Domain Expertise into Multilevel Models for Source Location. (arXiv:2305.08657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#22810;&#32423;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#32676;&#20307;&#25968;&#25454;&#35270;&#20026;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#24182;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#65292;&#20197;&#23454;&#29616;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#32676;&#20307;&#25968;&#25454;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;&#26426;&#22120;&#21644;&#22522;&#30784;&#35774;&#26045;&#36234;&#26469;&#36234;&#22810;&#22320;&#37197;&#22791;&#20102;&#20256;&#24863;&#31995;&#32479;&#65292;&#21457;&#20986;&#20855;&#26377;&#22797;&#26434;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#30340;&#36965;&#27979;&#25968;&#25454;&#27969;&#12290;&#23454;&#38469;&#19978;&#65292;&#25968;&#25454;&#20013;&#24515;&#30340;&#30417;&#27979;&#31243;&#24207;&#20542;&#21521;&#20110;&#23558;&#36825;&#20123;&#36164;&#20135;&#65288;&#20197;&#21450;&#21508;&#33258;&#30340;&#27169;&#22411;&#65289;&#35270;&#20026;&#19981;&#21516;&#30340;&#23454;&#20307; - &#29420;&#31435;&#36816;&#34892;&#24182;&#19982;&#29420;&#31435;&#25968;&#25454;&#30456;&#20851;&#32852;&#12290;&#30456;&#21453;&#65292;&#36825;&#39033;&#24037;&#20316;&#25429;&#25417;&#20102;&#19968;&#32452;&#31995;&#32479;&#27169;&#22411;&#20043;&#38388;&#30340;&#32479;&#35745;&#30456;&#20851;&#24615;&#21644;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#12290;&#21033;&#29992;&#36125;&#21494;&#26031;&#22810;&#32423;&#26041;&#27861;&#65292;&#25968;&#25454;&#30340;&#20215;&#20540;&#21487;&#20197;&#24471;&#21040;&#25193;&#23637;&#65292;&#22240;&#20026;&#21487;&#20197;&#23558;&#20154;&#32676;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#32780;&#19981;&#26159;&#20316;&#20026;&#32452;&#25104;&#37096;&#20998;&#12290;&#26368;&#26377;&#36259;&#30340;&#26159;&#65292;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#22522;&#30784;&#29289;&#29702;&#30693;&#35782;&#21487;&#20197;&#22312;&#31995;&#32479;&#12289;&#23376;&#32452;&#25110;&#20154;&#32676;&#27700;&#24179;&#19978;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22768;&#21457;&#23556;&#65288;&#21040;&#36798;&#26102;&#38388;&#65289;&#26144;&#23556;&#28304;&#20301;&#32622;&#30340;&#31034;&#20363;&#65292;&#20197;&#35828;&#26126;&#22810;&#32423;&#27169;&#22411;&#22914;&#20309;&#33258;&#28982;&#22320;&#36866;&#29992;&#20110;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data from populations of systems are prevalent in many industrial applications. Machines and infrastructure are increasingly instrumented with sensing systems, emitting streams of telemetry data with complex interdependencies. In practice, data-centric monitoring procedures tend to consider these assets (and respective models) as distinct -- operating in isolation and associated with independent data. In contrast, this work captures the statistical correlations and interdependencies between models of a group of systems. Utilising a Bayesian multilevel approach, the value of data can be extended, since the population can be considered as a whole, rather than constituent parts. Most interestingly, domain expertise and knowledge of the underlying physics can be encoded in the model at the system, subgroup, or population level. We present an example of acoustic emission (time-of-arrival) mapping for source location, to illustrate how multilevel models naturally lend themselves to represent
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#20197;&#21450;&#30456;&#20851;&#24212;&#29992;&#65292;&#24635;&#32467;&#20102;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2303.07909</link><description>&lt;p&gt;
&#29983;&#25104;AI&#20013;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Text-to-image Diffusion Model in Generative AI: A Survey. (arXiv:2303.07909v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07909
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#20197;&#21450;&#30456;&#20851;&#24212;&#29992;&#65292;&#24635;&#32467;&#20102;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#22810;&#31181;&#29983;&#25104;&#20219;&#21153;&#20013;&#27969;&#34892;&#30340;&#27169;&#22411;&#12290;&#20316;&#20026;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#24037;&#20316;&#65292;&#26412;&#35843;&#26597;&#20174;&#31616;&#21333;&#20171;&#32461;&#22522;&#26412;&#25193;&#25955;&#27169;&#22411;&#22914;&#20309;&#29992;&#20110;&#22270;&#20687;&#21512;&#25104;&#24320;&#22987;&#65292;&#25509;&#30528;&#26159;&#26465;&#20214;&#25110;&#24341;&#23548;&#22914;&#20309;&#25913;&#36827;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#24635;&#32467;&#20102;&#25991;&#26412;&#26465;&#20214;&#19979;&#30340;&#26368;&#20808;&#36827;&#30340;&#22270;&#20687;&#21512;&#25104;&#26041;&#27861;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#24635;&#32467;&#20102;&#25991;&#26412;&#24341;&#23548;&#21019;&#24847;&#29983;&#25104;&#21644;&#22270;&#20687;&#32534;&#36753;&#30340;&#24212;&#29992;&#12290;&#38500;&#20102;&#36804;&#20170;&#20026;&#27490;&#25152;&#21462;&#24471;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#29616;&#26377;&#25361;&#25112;&#21644;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This survey reviews text-to-image diffusion models in the context that diffusion models have emerged to be popular for a wide range of generative tasks. As a self-contained work, this survey starts with a brief introduction of how a basic diffusion model works for image synthesis, followed by how condition or guidance improves learning. Based on that, we present a review of state-of-the-art methods on text-conditioned image synthesis, i.e., text-to-image. We further summarize applications beyond text-to-image generation: text-guided creative generation and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2302.10160</link><description>&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#19979;&#20266;&#26631;&#31614;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift. (arXiv:2302.10160v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10160
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#30446;&#26631;&#20998;&#24067;&#19978;&#23398;&#20064;&#19968;&#20010;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#22522;&#20110;&#20174;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#21644;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#30340;&#24050;&#26631;&#35760;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#24050;&#26631;&#35760;&#25968;&#25454;&#20998;&#25104;&#20004;&#20010;&#23376;&#38598;&#65292;&#24182;&#20998;&#21035;&#36827;&#34892;&#26680;&#23725;&#22238;&#24402;&#65292;&#20197;&#33719;&#24471;&#20505;&#36873;&#27169;&#22411;&#38598;&#21512;&#21644;&#19968;&#20010;&#22635;&#20805;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#21518;&#32773;&#22635;&#20805;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#28982;&#21518;&#30456;&#24212;&#22320;&#36873;&#25321;&#26368;&#20339;&#30340;&#20505;&#36873;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36817;&#24615;&#36807;&#37327;&#39118;&#38505;&#30028;&#34920;&#26126;&#65292;&#22312;&#30456;&#24403;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#20998;&#24067;&#20197;&#21450;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#32467;&#26500;&#12290;&#23427;&#33021;&#22815;&#23454;&#29616;&#28176;&#36817;&#27491;&#24577;&#35823;&#24046;&#29575;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#30340;&#26368;&#23567;&#26497;&#38480;&#20248;&#21270;&#12290;&#22312;&#27169;&#22411;&#36873;&#25321;&#20013;&#20351;&#29992;&#20266;&#26631;&#31614;&#19981;&#20250;&#20135;&#29983;&#20027;&#35201;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate model accordingly. Our non-asymptotic excess risk bounds show that in quite general scenarios, our estimator adapts to the structure of the target distribution as well as the covariate shift. It achieves the minimax optimal error rate up to a logarithmic factor. The use of pseudo-labels in model selection does not have major negative impacts.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23618;&#32423;&#32465;&#23450;&#21644;&#32852;&#24819;&#26816;&#32034;&#21464;&#20026;&#30701;&#26399;&#21644;&#38271;&#26399;&#22768;&#26126;&#24615;&#35760;&#24518;&#30340;&#22312;&#32447;&#39044;&#27979;&#22788;&#29702;&#31995;&#32479;&#21487;&#33021;&#20250;&#24863;&#30693;&#21040;&#33258;&#24049;&#20855;&#26377;&#24847;&#35782;&#12290;</title><link>http://arxiv.org/abs/2301.07016</link><description>&lt;p&gt;
&#24847;&#35782;&#26159;&#23398;&#20064;&#30340;&#36807;&#31243;&#65306;&#36890;&#36807;&#32465;&#23450;&#23398;&#20064;&#30340;&#39044;&#27979;&#22788;&#29702;&#31995;&#32479;&#21487;&#33021;&#20250;&#23558;&#33258;&#24049;&#24863;&#30693;&#20026;&#26377;&#24847;&#35782;&#30340;
&lt;/p&gt;
&lt;p&gt;
Consciousness is learning: predictive processing systems that learn by binding may perceive themselves as conscious. (arXiv:2301.07016v2 [q-bio.NC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07016
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23618;&#32423;&#32465;&#23450;&#21644;&#32852;&#24819;&#26816;&#32034;&#21464;&#20026;&#30701;&#26399;&#21644;&#38271;&#26399;&#22768;&#26126;&#24615;&#35760;&#24518;&#30340;&#22312;&#32447;&#39044;&#27979;&#22788;&#29702;&#31995;&#32479;&#21487;&#33021;&#20250;&#24863;&#30693;&#21040;&#33258;&#24049;&#20855;&#26377;&#24847;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#29305;&#23450;&#22797;&#26434;&#39046;&#22495;&#23454;&#29616;&#20102;&#36229;&#36234;&#20154;&#31867;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#20174;&#23569;&#37327;&#31034;&#20363;&#20013;&#36827;&#34892;&#22312;&#32447;&#23398;&#20064;&#65292;&#24182;&#22312;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#39640;&#25928;&#22320;&#27867;&#21270;&#20173;&#28982;&#26159;&#38590;&#20197;&#23454;&#29616;&#30340;&#12290;&#22312;&#20154;&#31867;&#36523;&#19978;&#65292;&#36825;&#31181;&#23398;&#20064;&#36890;&#36807;&#22768;&#26126;&#24615;&#23384;&#20648;&#36807;&#31243;&#36827;&#34892;&#65292;&#24182;&#19988;&#19982;&#24847;&#35782;&#23494;&#20999;&#30456;&#20851;&#12290;&#39044;&#27979;&#22788;&#29702;&#34987;&#25512;&#24191;&#20026;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#26694;&#26550;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#29702;&#35299;&#30382;&#36136;&#22914;&#20309;&#23454;&#29616;&#28145;&#24230;&#29983;&#25104;&#24863;&#30693;&#27169;&#22411;&#65292;&#29992;&#20110;&#24863;&#23448;&#25968;&#25454;&#21644;&#34892;&#20026;&#25511;&#21046;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#22788;&#29702;&#23545;&#20110;&#24555;&#36895;&#32452;&#25104;&#24335;&#23398;&#20064;&#25110;&#24847;&#35782;&#20043;&#35868;&#25552;&#20379;&#20102;&#24456;&#23569;&#30340;&#30452;&#25509;&#35265;&#35299;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#65292;&#36890;&#36807;&#36890;&#36807;&#32465;&#23450;&#39044;&#27979;&#20013;&#30340;&#23618;&#27425;&#27169;&#22411;&#26469;&#23454;&#29616;&#22312;&#32447;&#23398;&#20064;&#65292;&#39044;&#27979;&#22788;&#29702;&#31995;&#32479;&#21487;&#20197;&#36890;&#36807;&#20174;&#21333;&#20010;&#31034;&#20363;&#20013;&#20026;&#24863;&#30693;&#21644;&#34892;&#21160;&#24418;&#25104;&#24037;&#20316;&#35760;&#24518;&#65292;&#22312;&#26032;&#24773;&#20917;&#19979;&#28789;&#27963;&#27867;&#21270;&#65292;&#36825;&#21487;&#36890;&#36807;&#32852;&#24819;&#26816;&#32034;&#21464;&#20026;&#30701;&#26399;&#21644;&#38271;&#26399;&#30340;&#22768;&#26126;&#24615;&#35760;&#24518;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#20010;&#36807;&#31243;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#22312;&#32447;&#23618;&#32423;&#39044;&#27979;&#32465;&#23450;&#8221;&#65292;&#20063;&#21487;&#33021;&#26159;&#31995;&#32479;&#24863;&#30693;&#33258;&#24049;&#20855;&#26377;&#24847;&#35782;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#20851;&#20110;&#24863;&#30693;&#30340;&#12289;&#36816;&#21160;&#30340;&#12289;&#35748;&#30693;&#30340;&#21644;&#24773;&#24863;&#30340;&#24847;&#35782;&#30340;&#32479;&#19968;&#35299;&#37322;&#65292;&#24182;&#20855;&#26377;&#36827;&#21270;&#21644;&#21457;&#32946;&#29983;&#29289;&#23398;&#30340;&#28145;&#21051;&#26681;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms have achieved superhuman performance in specific complex domains. Yet learning online from few examples and efficiently generalizing across domains remains elusive. In humans such learning proceeds via declarative memory formation and is closely associated with consciousness. Predictive processing has been advanced as a principled Bayesian inference framework for understanding the cortex as implementing deep generative perceptual models for both sensory data and action control. However, predictive processing offers little direct insight into fast compositional learning or the mystery of consciousness. Here we propose that through implementing online learning by hierarchical binding of unpredicted inferences, a predictive processing system may flexibly generalize in novel situations by forming working memories for perceptions and actions from single examples, which can become short- and long-term declarative memories retrievable by associative recall. We argu
&lt;/p&gt;</description></item></channel></rss>