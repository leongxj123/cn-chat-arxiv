<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#38543;&#26426;&#25311;&#29275;&#39039;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#38750;&#22343;&#21248;&#24179;&#28369;&#24230;&#30340;&#24773;&#20917;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#24341;&#20837;&#20102;$(L_0, L_1)$-&#24179;&#28369;&#24230;&#65292;&#30456;&#27604;&#20256;&#32479;&#30340;$L$-&#24179;&#28369;&#24230;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#24179;&#28369;&#24230;&#19982;&#26799;&#24230;&#33539;&#25968;&#20043;&#38388;&#30340;&#27491;&#30456;&#20851;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.15244</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#30340;&#38543;&#26426;&#25311;&#29275;&#39039;&#26041;&#27861;&#19982;&#38750;&#22343;&#21248;&#24179;&#28369;&#24230;
&lt;/p&gt;
&lt;p&gt;
A Stochastic Quasi-Newton Method for Non-convex Optimization with Non-uniform Smoothness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15244
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#38543;&#26426;&#25311;&#29275;&#39039;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#38750;&#22343;&#21248;&#24179;&#28369;&#24230;&#30340;&#24773;&#20917;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#24341;&#20837;&#20102;$(L_0, L_1)$-&#24179;&#28369;&#24230;&#65292;&#30456;&#27604;&#20256;&#32479;&#30340;$L$-&#24179;&#28369;&#24230;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#24179;&#28369;&#24230;&#19982;&#26799;&#24230;&#33539;&#25968;&#20043;&#38388;&#30340;&#27491;&#30456;&#20851;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#20248;&#21270;&#31639;&#27861;&#30340;&#32463;&#20856;&#25910;&#25947;&#20998;&#26512;&#20381;&#36182;&#20110;&#24191;&#27867;&#37319;&#29992;&#30340;&#22343;&#21248;&#24179;&#28369;&#24230;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#34920;&#29616;&#20986;&#38750;&#22343;&#21248;&#24179;&#28369;&#24230;&#65292;&#36825;&#24847;&#21619;&#30528;&#24179;&#28369;&#24230;&#22240;&#23376;&#26159;&#27169;&#22411;&#21442;&#25968;&#30340;&#20989;&#25968;&#65292;&#32780;&#19981;&#26159;&#19968;&#20010;&#26222;&#36941;&#24120;&#25968;&#12290;&#23588;&#20854;&#26159;&#35266;&#23519;&#21040;&#65292;&#24179;&#28369;&#24230;&#38543;&#30528;&#35757;&#32451;&#36712;&#36857;&#20013;&#30340;&#26799;&#24230;&#33539;&#25968;&#22686;&#38271;&#12290;&#21463;&#36825;&#19968;&#29616;&#35937;&#30340;&#21551;&#21457;&#65292;&#26368;&#36817;&#24341;&#20837;&#30340;$(L_0, L_1)$-&#24179;&#28369;&#24230;&#26159;&#19968;&#20010;&#27604;&#20256;&#32479;&#30340;$L$-&#24179;&#28369;&#24230;&#26356;&#19968;&#33324;&#30340;&#27010;&#24565;&#65292;&#23427;&#25429;&#25417;&#20102;&#24179;&#28369;&#24230;&#19982;&#26799;&#24230;&#33539;&#25968;&#20043;&#38388;&#30340;&#36825;&#31181;&#27491;&#30456;&#20851;&#20851;&#31995;&#12290;&#22312;&#36825;&#31181;&#38750;&#22343;&#21248;&#24179;&#28369;&#24230;&#19979;&#65292;&#29616;&#26377;&#25991;&#29486;&#36890;&#36807;&#21033;&#29992;&#26799;&#24230;&#35009;&#21098;&#25216;&#26415;&#35774;&#35745;&#20102;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#65292;&#20197;&#33719;&#24471;&#25214;&#21040;$\epsilon$-&#36817;&#20284;&#35299;&#30340;$\mathcal{O}(\epsilon^{-3})$&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15244v1 Announce Type: new  Abstract: Classical convergence analyses for optimization algorithms rely on the widely-adopted uniform smoothness assumption. However, recent experimental studies have demonstrated that many machine learning problems exhibit non-uniform smoothness, meaning the smoothness factor is a function of the model parameter instead of a universal constant. In particular, it has been observed that the smoothness grows with respect to the gradient norm along the training trajectory. Motivated by this phenomenon, the recently introduced $(L_0, L_1)$-smoothness is a more general notion, compared to traditional $L$-smoothness, that captures such positive relationship between smoothness and gradient norm. Under this type of non-uniform smoothness, existing literature has designed stochastic first-order algorithms by utilizing gradient clipping techniques to obtain the optimal $\mathcal{O}(\epsilon^{-3})$ sample complexity for finding an $\epsilon$-approximate fi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28909;&#25193;&#25955;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#25628;&#32034;&#20840;&#23616;&#26368;&#20248;&#26102;&#25928;&#29575;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.08757</link><description>&lt;p&gt;
&#36890;&#36807;&#28909;&#25193;&#25955;&#23454;&#29616;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Efficient Combinatorial Optimization via Heat Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08757
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28909;&#25193;&#25955;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#25628;&#32034;&#20840;&#23616;&#26368;&#20248;&#26102;&#25928;&#29575;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#28909;&#25193;&#25955;&#26469;&#23454;&#29616;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;&#12290;&#38024;&#23545;&#29616;&#26377;&#26041;&#27861;&#21482;&#33021;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#35775;&#38382;&#35299;&#31354;&#38388;&#30340;&#19968;&#23567;&#37096;&#20998;&#36825;&#19968;&#38480;&#21046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#26469;&#35299;&#20915;&#19968;&#33324;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#19968;&#31995;&#21015;&#26368;&#20855;&#25361;&#25112;&#24615;&#21644;&#24191;&#27867;&#36935;&#21040;&#30340;&#32452;&#21512;&#20248;&#21270;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08757v1 Announce Type: cross  Abstract: Combinatorial optimization problems are widespread but inherently challenging due to their discrete nature.The primary limitation of existing methods is that they can only access a small fraction of the solution space at each iteration, resulting in limited efficiency for searching the global optimal. To overcome this challenge, diverging from conventional efforts of expanding the solver's search scope, we focus on enabling information to actively propagate to the solver through heat diffusion. By transforming the target function while preserving its optima, heat diffusion facilitates information flow from distant regions to the solver, providing more efficient navigation. Utilizing heat diffusion, we propose a framework for solving general combinatorial optimization problems. The proposed methodology demonstrates superior performance across a range of the most challenging and widely encountered combinatorial optimizations. Echoing rec
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#19987;&#27880;&#20110;&#20248;&#21270;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#27969;&#20307;&#21147;&#23398;&#20013;&#20027;&#21160;&#27969;&#25511;&#21046;&#20013;&#30340;&#24182;&#34892;&#35774;&#32622;&#65292;&#36890;&#36807;&#25286;&#35299;DRL&#26694;&#26550;&#12289;&#36827;&#34892;&#25193;&#23637;&#24615;&#22522;&#20934;&#27979;&#35797;&#12289;&#25552;&#20986;&#28151;&#21512;&#24182;&#34892;&#21270;&#37197;&#32622;&#24182;&#20248;&#21270;&#22810;&#29615;&#22659;DRL&#35757;&#32451;&#20013;&#30340;I/O&#25805;&#20316;&#65292;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#24182;&#34892;&#21270;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.11515</link><description>&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#27969;&#20307;&#21147;&#23398;&#20013;&#20027;&#21160;&#27969;&#25511;&#21046;&#20013;&#30340;&#26368;&#20339;&#24182;&#34892;&#21270;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Optimal Parallelization Strategies for Active Flow Control in Deep Reinforcement Learning-Based Computational Fluid Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11515
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#19987;&#27880;&#20110;&#20248;&#21270;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#27969;&#20307;&#21147;&#23398;&#20013;&#20027;&#21160;&#27969;&#25511;&#21046;&#20013;&#30340;&#24182;&#34892;&#35774;&#32622;&#65292;&#36890;&#36807;&#25286;&#35299;DRL&#26694;&#26550;&#12289;&#36827;&#34892;&#25193;&#23637;&#24615;&#22522;&#20934;&#27979;&#35797;&#12289;&#25552;&#20986;&#28151;&#21512;&#24182;&#34892;&#21270;&#37197;&#32622;&#24182;&#20248;&#21270;&#22810;&#29615;&#22659;DRL&#35757;&#32451;&#20013;&#30340;I/O&#25805;&#20316;&#65292;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#24182;&#34892;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#22788;&#29702;&#39640;&#21160;&#24577;&#21644;&#38750;&#32447;&#24615;&#20027;&#21160;&#27969;&#25511;&#21046;&#65288;AFC&#65289;&#38382;&#39064;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#19982;&#35757;&#32451;DRL&#27169;&#22411;&#30456;&#20851;&#30340;&#35745;&#31639;&#25104;&#26412;&#26500;&#25104;&#20102;&#37325;&#35201;&#30340;&#24615;&#33021;&#29942;&#39048;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#24182;&#22312;&#39640;&#24615;&#33021;&#35745;&#31639;&#26550;&#26500;&#19978;&#23454;&#29616;&#26377;&#25928;&#30340;&#25193;&#23637;&#65292;&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#20248;&#21270;&#24182;&#34892;&#35774;&#32622;&#20013;&#30340;&#22522;&#20110;DRL&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#29992;&#20110;AFC&#38382;&#39064;&#30340;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;DRL&#26694;&#26550;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#25928;&#29575;&#29942;&#39048;&#12290;&#38543;&#21518;&#65292;&#36890;&#36807;&#25286;&#35299;&#25972;&#20307;&#26694;&#26550;&#65292;&#24182;&#20026;&#21508;&#20010;&#32452;&#20214;&#36827;&#34892;&#24191;&#27867;&#30340;&#21487;&#25193;&#23637;&#24615;&#22522;&#20934;&#27979;&#35797;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#28151;&#21512;&#24182;&#34892;&#21270;&#37197;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#24182;&#34892;&#21270;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20248;&#21270;&#20102;&#22810;&#29615;&#22659;DRL&#35757;&#32451;&#20013;&#30340;&#36755;&#20837;/&#36755;&#20986;&#65288;I/O&#65289;&#25805;&#20316;&#65292;&#20197;&#35299;&#20915;&#19982;&#25968;&#25454;&#31227;&#21160;&#30456;&#20851;&#30340;&#20851;&#38190;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11515v1 Announce Type: new  Abstract: Deep Reinforcement Learning (DRL) has emerged as a promising approach for handling highly dynamic and nonlinear Active Flow Control (AFC) problems. However, the computational cost associated with training DRL models presents a significant performance bottleneck. To address this challenge and enable efficient scaling on high-performance computing architectures, this study focuses on optimizing DRL-based algorithms in parallel settings. We validate an existing state-of-the-art DRL framework used for AFC problems and discuss its efficiency bottlenecks. Subsequently, by deconstructing the overall framework and conducting extensive scalability benchmarks for individual components, we investigate various hybrid parallelization configurations and propose efficient parallelization strategies. Moreover, we refine input/output (I/O) operations in multi-environment DRL training to tackle critical overhead associated with data movement. Finally, we 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#29983;&#25104;&#23545;&#25239;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;GABO&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#28304;&#25209;&#35780;&#23478;&#27491;&#21017;&#21270;&#65292;&#23558;&#20248;&#21270;&#36712;&#36857;&#38480;&#21046;&#22312;&#20195;&#29702;&#20989;&#25968;&#21487;&#38752;&#30340;&#21306;&#22495;&#20869;&#65292;&#35299;&#20915;&#20102;&#31163;&#32447;&#27169;&#22411;&#22522;&#20110;&#31574;&#30053;&#20248;&#21270;&#20013;&#20195;&#29702;&#27169;&#22411;&#39044;&#27979;&#19981;&#20934;&#30830;&#30340;&#38382;&#39064;&#12290;&#22312;&#22810;&#20010;&#31163;&#32447;&#20248;&#21270;&#20219;&#21153;&#20013;&#65292;GABO&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#22522;&#20934;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.06532</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#36125;&#21494;&#26031;&#20248;&#21270;&#29992;&#20110;&#20195;&#29702;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Bayesian Optimization for Surrogate Objectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06532
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#29983;&#25104;&#23545;&#25239;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;GABO&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#28304;&#25209;&#35780;&#23478;&#27491;&#21017;&#21270;&#65292;&#23558;&#20248;&#21270;&#36712;&#36857;&#38480;&#21046;&#22312;&#20195;&#29702;&#20989;&#25968;&#21487;&#38752;&#30340;&#21306;&#22495;&#20869;&#65292;&#35299;&#20915;&#20102;&#31163;&#32447;&#27169;&#22411;&#22522;&#20110;&#31574;&#30053;&#20248;&#21270;&#20013;&#20195;&#29702;&#27169;&#22411;&#39044;&#27979;&#19981;&#20934;&#30830;&#30340;&#38382;&#39064;&#12290;&#22312;&#22810;&#20010;&#31163;&#32447;&#20248;&#21270;&#20219;&#21153;&#20013;&#65292;GABO&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#20248;&#21270;&#36890;&#36807;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#19981;&#26597;&#35810;&#30495;&#23454;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#20248;&#21270;&#23398;&#20064;&#21040;&#30340;&#20195;&#29702;&#30446;&#26631;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#32463;&#24120;&#36935;&#21040;&#20195;&#29702;&#27169;&#22411;&#39044;&#27979;&#19981;&#20934;&#30830;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#33258;&#36866;&#24212;&#28304;&#25209;&#35780;&#23478;&#27491;&#21017;&#21270;&#30340;&#29983;&#25104;&#23545;&#25239;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;GABO&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#20219;&#21153;&#19981;&#21487;&#30693;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#37319;&#29992;&#20102;Lipschitz&#26377;&#30028;&#28304;&#25209;&#35780;&#23478;&#27169;&#22411;&#26469;&#32422;&#26463;&#20248;&#21270;&#36712;&#36857;&#65292;&#20351;&#20854;&#22312;&#20195;&#29702;&#20989;&#25968;&#21487;&#38752;&#30340;&#21306;&#22495;&#20869;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36830;&#32493;&#36755;&#20837;&#31354;&#38388;&#20808;&#39564;&#30340;&#19968;&#23450;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21160;&#24577;&#35843;&#25972;&#28304;&#25209;&#35780;&#23478;&#27491;&#21017;&#21270;&#30340;&#24378;&#24230;&#12290;&#22312;&#21508;&#31181;&#31185;&#23398;&#39046;&#22495;&#30340;&#22810;&#20010;&#31163;&#32447;&#20248;&#21270;&#20219;&#21153;&#20013;&#65292;GABO&#20248;&#20110;&#29616;&#26377;&#22522;&#20934;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/michael-s-yao/gabo &#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline model-based policy optimization seeks to optimize a learned surrogate objective function without querying the true oracle objective during optimization. However, inaccurate surrogate model predictions are frequently encountered along the optimization trajectory. To address this limitation, we propose generative adversarial Bayesian optimization (GABO) using adaptive source critic regularization, a task-agnostic framework for Bayesian optimization that employs a Lipschitz-bounded source critic model to constrain the optimization trajectory to regions where the surrogate function is reliable. We show that under certain assumptions for the continuous input space prior, our algorithm dynamically adjusts the strength of the source critic regularization. GABO outperforms existing baselines on a number of different offline optimization tasks across a variety of scientific domains. Our code is available at https://github.com/michael-s-yao/gabo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#30340;&#26032;&#30340;&#39640;&#25928;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03664</link><description>&lt;p&gt;
&#39640;&#25928;&#27714;&#35299;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Efficient Solvers for Partial Gromov-Wasserstein
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#30340;&#26032;&#30340;&#39640;&#25928;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#24046;Gromov-Wasserstein&#65288;PGW&#65289;&#38382;&#39064;&#21487;&#20197;&#27604;&#36739;&#20855;&#26377;&#19981;&#22343;&#21248;&#36136;&#37327;&#30340;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#65292;&#20174;&#32780;&#23454;&#29616;&#36825;&#20123;&#31354;&#38388;&#20043;&#38388;&#30340;&#19981;&#24179;&#34913;&#21644;&#37096;&#20998;&#21305;&#37197;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#21487;&#20197;&#36716;&#21270;&#20026;Gromov-Wasserstein&#38382;&#39064;&#30340;&#19968;&#20010;&#21464;&#31181;&#65292;&#31867;&#20284;&#20110;&#25226;&#20559;&#24046;&#26368;&#20248;&#36816;&#36755;&#38382;&#39064;&#36716;&#21270;&#20026;&#26368;&#20248;&#36816;&#36755;&#38382;&#39064;&#12290;&#36825;&#20010;&#36716;&#21270;&#23548;&#33268;&#20102;&#20004;&#20010;&#26032;&#30340;&#27714;&#35299;&#22120;&#65292;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#65292;&#25968;&#23398;&#21644;&#35745;&#31639;&#19978;&#31561;&#20215;&#65292;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;PGW&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19982;&#29616;&#26377;&#22522;&#32447;&#26041;&#27861;&#22312;&#24418;&#29366;&#21305;&#37197;&#21644;&#27491;&#26679;&#26412;&#26410;&#26631;&#35760;&#23398;&#20064;&#38382;&#39064;&#19978;&#30340;&#35745;&#31639;&#26102;&#38388;&#21644;&#24615;&#33021;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#27714;&#35299;&#22120;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The partial Gromov-Wasserstein (PGW) problem facilitates the comparison of measures with unequal masses residing in potentially distinct metric spaces, thereby enabling unbalanced and partial matching across these spaces. In this paper, we demonstrate that the PGW problem can be transformed into a variant of the Gromov-Wasserstein problem, akin to the conversion of the partial optimal transport problem into an optimal transport problem. This transformation leads to two new solvers, mathematically and computationally equivalent, based on the Frank-Wolfe algorithm, that provide efficient solutions to the PGW problem. We further establish that the PGW problem constitutes a metric for metric measure spaces. Finally, we validate the effectiveness of our proposed solvers in terms of computation time and performance on shape-matching and positive-unlabeled learning problems, comparing them against existing baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20154;&#31867;&#32534;&#20889;&#30340;&#25351;&#20196;&#26469;&#25351;&#23548;&#22270;&#20687;&#24674;&#22797;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#24674;&#22797;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#20026;&#22522;&#20110;&#25991;&#26412;&#25351;&#23548;&#30340;&#22270;&#20687;&#24674;&#22797;&#21644;&#22686;&#24378;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#12290;</title><link>http://arxiv.org/abs/2401.16468</link><description>&lt;p&gt;
&#36981;&#24490;&#20154;&#31867;&#25351;&#20196;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
High-Quality Image Restoration Following Human Instructions. (arXiv:2401.16468v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20154;&#31867;&#32534;&#20889;&#30340;&#25351;&#20196;&#26469;&#25351;&#23548;&#22270;&#20687;&#24674;&#22797;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#24674;&#22797;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#20026;&#22522;&#20110;&#25991;&#26412;&#25351;&#23548;&#30340;&#22270;&#20687;&#24674;&#22797;&#21644;&#22686;&#24378;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#20687;&#24674;&#22797;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#28041;&#21450;&#20174;&#36864;&#21270;&#35266;&#27979;&#20013;&#24674;&#22797;&#20986;&#39640;&#36136;&#37327;&#30340;&#24178;&#20928;&#22270;&#20687;&#12290;&#20840;&#33021;&#22270;&#20687;&#24674;&#22797;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#29305;&#23450;&#20110;&#36864;&#21270;&#31867;&#22411;&#30340;&#20449;&#24687;&#20316;&#20026;&#25552;&#31034;&#26469;&#26377;&#25928;&#22320;&#24674;&#22797;&#21508;&#31181;&#31867;&#22411;&#21644;&#32423;&#21035;&#30340;&#36864;&#21270;&#22270;&#20687;&#65292;&#24182;&#24341;&#23548;&#24674;&#22797;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20154;&#31867;&#32534;&#20889;&#30340;&#25351;&#20196;&#26469;&#25351;&#23548;&#22270;&#20687;&#24674;&#22797;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#22312;&#32473;&#23450;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#20174;&#36864;&#21270;&#22270;&#20687;&#20013;&#24674;&#22797;&#20986;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#65292;&#24182;&#32771;&#34385;&#22810;&#31181;&#36864;&#21270;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;InstructIR&#22312;&#22270;&#20687;&#21435;&#22122;&#12289;&#38632;&#27700;&#21435;&#38500;&#12289;&#21435;&#27169;&#31946;&#12289;&#21435;&#38654;&#21644;(&#20302;&#20809;)&#22270;&#20687;&#22686;&#24378;&#31561;&#22810;&#20010;&#24674;&#22797;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;InstructIR&#22312;&#20043;&#21069;&#30340;&#20840;&#33021;&#24674;&#22797;&#26041;&#27861;&#19978;&#25552;&#39640;&#20102;1dB&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#21644;&#32467;&#26524;&#20026;&#22522;&#20110;&#25991;&#26412;&#25351;&#23548;&#30340;&#22270;&#20687;&#24674;&#22797;&#21644;&#22686;&#24378;&#30340;&#26032;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20195;&#30721;&#12289;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Image restoration is a fundamental problem that involves recovering a high-quality clean image from its degraded observation. All-In-One image restoration models can effectively restore images from various types and levels of degradation using degradation-specific information as prompts to guide the restoration model. In this work, we present the first approach that uses human-written instructions to guide the image restoration model. Given natural language prompts, our model can recover high-quality images from their degraded counterparts, considering multiple degradation types. Our method, InstructIR, achieves state-of-the-art results on several restoration tasks including image denoising, deraining, deblurring, dehazing, and (low-light) image enhancement. InstructIR improves +1dB over previous all-in-one restoration methods. Moreover, our dataset and results represent a novel benchmark for new research on text-guided image restoration and enhancement. Our code, datasets and models a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#20998;&#24067;&#23545;&#40784;&#26041;&#27861;&#20197;&#35299;&#20915;&#21518;&#35757;&#32451;&#37327;&#21270;&#23545;&#20110;&#24357;&#25955;&#27169;&#22411;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#24310;&#36831;&#24212;&#29992;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#28508;&#21147;&#65292;&#24182;&#19988;&#33021;&#26377;&#25928;&#25552;&#21319;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.04585</link><description>&lt;p&gt;
&#25193;&#23637;&#20998;&#24067;&#23545;&#40784;&#26469;&#23454;&#29616;&#24357;&#25955;&#27169;&#22411;&#30340;&#21518;&#35757;&#32451;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Enhanced Distribution Alignment for Post-Training Quantization of Diffusion Models. (arXiv:2401.04585v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#20998;&#24067;&#23545;&#40784;&#26041;&#27861;&#20197;&#35299;&#20915;&#21518;&#35757;&#32451;&#37327;&#21270;&#23545;&#20110;&#24357;&#25955;&#27169;&#22411;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#24310;&#36831;&#24212;&#29992;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#28508;&#21147;&#65292;&#24182;&#19988;&#33021;&#26377;&#25928;&#25552;&#21319;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36845;&#20195;&#22122;&#22768;&#20272;&#35745;&#65292;&#25193;&#25955;&#27169;&#22411;&#22312;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#32321;&#37325;&#30340;&#21435;&#22122;&#36807;&#31243;&#21644;&#22797;&#26434;&#30340;&#31070;&#32463;&#32593;&#32476;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#20302;&#24310;&#36831;&#24212;&#29992;&#12290;&#37327;&#21270;&#21487;&#20197;&#26377;&#25928;&#38477;&#20302;&#27169;&#22411;&#22797;&#26434;&#24230;&#65292;&#32780;&#21518;&#35757;&#32451;&#37327;&#21270;(PTQ)&#22312;&#21152;&#36895;&#21435;&#22122;&#36807;&#31243;&#26041;&#38754;&#20855;&#26377;&#24456;&#39640;&#30340;&#28508;&#21147;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#24494;&#35843;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#30001;&#20110;&#19981;&#21516;&#21435;&#22122;&#27493;&#39588;&#20013;&#28608;&#27963;&#30340;&#39640;&#24230;&#21160;&#24577;&#20998;&#24067;&#65292;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;PTQ&#26041;&#27861;&#22312;&#26657;&#20934;&#26679;&#26412;&#21644;&#37325;&#26500;&#36755;&#20986;&#20004;&#20010;&#23618;&#38754;&#19978;&#37117;&#23384;&#22312;&#20998;&#24067;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#65292;&#23548;&#33268;&#24615;&#33021;&#36828;&#20302;&#20110;&#20196;&#20154;&#28385;&#24847;&#30340;&#27700;&#24179;&#65292;&#29305;&#21035;&#26159;&#22312;&#20302;&#20301;&#24773;&#20917;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22686;&#24378;&#30340;&#20998;&#24067;&#23545;&#40784;&#29992;&#20110;&#24357;&#25955;&#27169;&#22411;&#30340;&#21518;&#35757;&#32451;&#37327;&#21270;(EDA-DM)&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22312;&#26657;&#20934;&#26679;&#26412;&#23618;&#38754;&#65292;&#25105;&#20204;&#22522;&#20110;...[&#32570;&#30465;]
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved great success in image generation tasks through iterative noise estimation. However, the heavy denoising process and complex neural networks hinder their low-latency applications in real-world scenarios. Quantization can effectively reduce model complexity, and post-training quantization (PTQ), which does not require fine-tuning, is highly promising in accelerating the denoising process. Unfortunately, we find that due to the highly dynamic distribution of activations in different denoising steps, existing PTQ methods for diffusion models suffer from distribution mismatch issues at both calibration sample level and reconstruction output level, which makes the performance far from satisfactory, especially in low-bit cases. In this paper, we propose Enhanced Distribution Alignment for Post-Training Quantization of Diffusion Models (EDA-DM) to address the above issues. Specifically, at the calibration sample level, we select calibration samples based on the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#19981;&#21516;&#32972;&#26223;&#26465;&#20214;&#19979;&#23545;&#26368;&#36817;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#22312;&#35266;&#23519;&#24615;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#23454;&#38469;&#24615;&#33021;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#21457;&#29616;&#22522;&#20110;score matching&#30340;&#26041;&#27861;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.13387</link><description>&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#20551;&#35774;&#36829;&#35268;&#21644;score matching&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assumption violations in causal discovery and the robustness of score matching. (arXiv:2310.13387v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13387
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#19981;&#21516;&#32972;&#26223;&#26465;&#20214;&#19979;&#23545;&#26368;&#36817;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#22312;&#35266;&#23519;&#24615;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#23454;&#38469;&#24615;&#33021;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#21457;&#29616;&#22522;&#20110;score matching&#30340;&#26041;&#27861;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#39046;&#22495;&#30693;&#35782;&#26377;&#38480;&#19988;&#23454;&#39564;&#21463;&#21040;&#36947;&#24503;&#12289;&#36130;&#21153;&#25110;&#26102;&#38388;&#38480;&#21046;&#26102;&#65292;&#20174;&#19994;&#32773;&#20250;&#36716;&#21521;&#35266;&#23519;&#24615;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#26469;&#24674;&#22797;&#22240;&#26524;&#32467;&#26500;&#65292;&#21033;&#29992;&#20854;&#25968;&#25454;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;&#30001;&#20110;&#27809;&#26377;&#36827;&#19968;&#27493;&#30340;&#20551;&#35774;&#65292;&#22240;&#26524;&#21457;&#29616;&#26159;&#19968;&#20010;&#19981;&#36866;&#23450;&#30340;&#38382;&#39064;&#65292;&#27599;&#20010;&#31639;&#27861;&#37117;&#26377;&#20854;&#33258;&#24049;&#30340;&#19968;&#22871;&#36890;&#24120;&#26080;&#27861;&#39564;&#35777;&#30340;&#20551;&#35774;&#65292;&#20854;&#20013;&#19968;&#20123;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#24456;&#38590;&#28385;&#36275;&#12290;&#37492;&#20110;&#36825;&#20123;&#32771;&#34385;&#65292;&#26412;&#25991;&#22312;&#19981;&#21516;&#32972;&#26223;&#26465;&#20214;&#19979;&#23545;&#26368;&#36817;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#22312;&#35266;&#23519;&#24615;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#23454;&#38469;&#24615;&#33021;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#20801;&#35768;&#36829;&#21453;&#27599;&#20010;&#36873;&#23450;&#26041;&#27861;&#25152;&#38656;&#30340;&#20851;&#38190;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#36825;&#20123;&#20855;&#26377;&#25361;&#25112;&#24615;&#22330;&#26223;&#20013;&#65292;&#22522;&#20110;score matching&#30340;&#26041;&#27861;&#22312;&#25512;&#26029;&#30340;&#22270;&#30340;&#35823;&#25253;&#19982;&#28431;&#25253;&#29575;&#26041;&#38754;&#34920;&#29616;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20854;&#30340;&#29702;&#35770;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
When domain knowledge is limited and experimentation is restricted by ethical, financial, or time constraints, practitioners turn to observational causal discovery methods to recover the causal structure, exploiting the statistical properties of their data. Because causal discovery without further assumptions is an ill-posed problem, each algorithm comes with its own set of usually untestable assumptions, some of which are hard to meet in real datasets. Motivated by these considerations, this paper extensively benchmarks the empirical performance of recent causal discovery methods on observational i.i.d. data generated under different background conditions, allowing for violations of the critical assumptions required by each selected approach. Our experimental findings show that score matching-based methods demonstrate surprising performance in the false positive and false negative rate of the inferred graph in these challenging scenarios, and we provide theoretical insights into their
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Fourier&#31070;&#32463;&#25805;&#20316;&#31526;(FNO)&#30340;&#21021;&#22987;&#21270;&#20559;&#24046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;FNO&#29256;&#26412;&#30340;He&#21021;&#22987;&#21270;&#26041;&#26696;&#65292;&#36890;&#36807;&#27169;&#24335;&#25130;&#26029;&#21644;&#23494;&#38598;&#36830;&#25509;&#32593;&#32476;&#30456;&#20284;&#30340;&#29305;&#28857;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#36127;&#21021;&#22987;&#21270;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.06379</link><description>&lt;p&gt;
Fourier&#31070;&#32463;&#25805;&#20316;&#31526;&#30340;&#21021;&#22987;&#21270;&#20559;&#24046;&#65306;&#37325;&#26032;&#23457;&#35270;&#28151;&#27788;&#36793;&#32536;
&lt;/p&gt;
&lt;p&gt;
Initialization Bias of Fourier Neural Operator: Revisiting the Edge of Chaos. (arXiv:2310.06379v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Fourier&#31070;&#32463;&#25805;&#20316;&#31526;(FNO)&#30340;&#21021;&#22987;&#21270;&#20559;&#24046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;FNO&#29256;&#26412;&#30340;He&#21021;&#22987;&#21270;&#26041;&#26696;&#65292;&#36890;&#36807;&#27169;&#24335;&#25130;&#26029;&#21644;&#23494;&#38598;&#36830;&#25509;&#32593;&#32476;&#30456;&#20284;&#30340;&#29305;&#28857;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#36127;&#21021;&#22987;&#21270;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Fourier&#31070;&#32463;&#25805;&#20316;&#31526;(FNO)&#30340;&#21021;&#22987;&#21270;&#20559;&#24046;&#12290;&#24314;&#31435;&#20102;&#19968;&#20010;&#38024;&#23545;FNO&#30340;&#24179;&#22343;&#22330;&#29702;&#35770;&#65292;&#20174;&#8220;&#28151;&#27788;&#36793;&#32536;&#8221;&#30340;&#35270;&#35282;&#20998;&#26512;&#20102;&#38543;&#26426;FNO&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#25581;&#31034;&#20102;&#21069;&#21521;&#21644;&#21453;&#21521;&#20256;&#25773;&#34892;&#20026;&#34920;&#29616;&#20986;&#19982;FNO&#29420;&#29305;&#30340;&#29305;&#24449;&#65292;&#36825;&#26159;&#30001;&#27169;&#24335;&#25130;&#26029;&#24341;&#36215;&#30340;&#65292;&#21516;&#26102;&#20063;&#23637;&#31034;&#20102;&#19982;&#23494;&#38598;&#36830;&#25509;&#32593;&#32476;&#30456;&#20284;&#30340;&#29305;&#28857;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;FNO&#29256;&#26412;&#30340;He&#21021;&#22987;&#21270;&#26041;&#26696;&#65292;&#20197;&#20943;&#36731;&#23548;&#33268;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#36127;&#21021;&#22987;&#21270;&#20559;&#24046;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;&#25105;&#20204;&#21021;&#22987;&#21270;&#26041;&#26696;&#30340;&#26377;&#25928;&#24615;&#65292;&#20351;&#24471;32&#23618;FNO&#30340;&#35757;&#32451;&#31283;&#23450;&#65292;&#26080;&#38656;&#39069;&#22806;&#25216;&#26415;&#25110;&#26174;&#33879;&#24615;&#33021;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the initialization bias of the Fourier neural operator (FNO). A mean-field theory for FNO is established, analyzing the behavior of the random FNO from an ``edge of chaos'' perspective. We uncover that the forward and backward propagation behaviors exhibit characteristics unique to FNO, induced by mode truncation, while also showcasing similarities to those of densely connected networks. Building upon this observation, we also propose a FNO version of the He initialization scheme to mitigate the negative initialization bias leading to training instability. Experimental results demonstrate the effectiveness of our initialization scheme, enabling stable training of a 32-layer FNO without the need for additional techniques or significant performance degradation.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#27169;&#25311;&#21560;&#24341;&#23376;&#21160;&#21147;&#23398;&#26469;&#26356;&#21152;&#31070;&#32463;&#21487;&#34892;&#22320;&#23454;&#29616;&#31163;&#25955;&#21270;&#65292;&#20174;&#32780;&#23558;&#36830;&#32493;&#30340;&#34920;&#31034;&#31354;&#38388;&#21010;&#20998;&#20026;&#23545;&#24212;&#20110;&#31526;&#21495;&#24207;&#21015;&#30340;&#20998;&#21306;&#12290;&#36890;&#36807;&#24341;&#20837;&#31526;&#21495;&#31354;&#38388;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#20016;&#23500;&#30340;&#24863;&#30693;&#36755;&#20837;&#30340;&#21560;&#24341;&#23376;&#25903;&#25345;&#34920;&#31034;&#31354;&#38388;&#20013;&#23454;&#29616;&#32452;&#21512;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.01807</link><description>&lt;p&gt;
&#36890;&#36807;&#21560;&#24341;&#23376;&#21160;&#21147;&#23398;&#23454;&#29616;&#31163;&#25955;&#12289;&#32452;&#21512;&#21644;&#31526;&#21495;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Discrete, compositional, and symbolic representations through attractor dynamics. (arXiv:2310.01807v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01807
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#27169;&#25311;&#21560;&#24341;&#23376;&#21160;&#21147;&#23398;&#26469;&#26356;&#21152;&#31070;&#32463;&#21487;&#34892;&#22320;&#23454;&#29616;&#31163;&#25955;&#21270;&#65292;&#20174;&#32780;&#23558;&#36830;&#32493;&#30340;&#34920;&#31034;&#31354;&#38388;&#21010;&#20998;&#20026;&#23545;&#24212;&#20110;&#31526;&#21495;&#24207;&#21015;&#30340;&#20998;&#21306;&#12290;&#36890;&#36807;&#24341;&#20837;&#31526;&#21495;&#31354;&#38388;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#20016;&#23500;&#30340;&#24863;&#30693;&#36755;&#20837;&#30340;&#21560;&#24341;&#23376;&#25903;&#25345;&#34920;&#31034;&#31354;&#38388;&#20013;&#23454;&#29616;&#32452;&#21512;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452;&#21512;&#24615;&#26159;&#31163;&#25955;&#31526;&#21495;&#31995;&#32479;&#65288;&#22914;&#35821;&#35328;&#21644;&#31243;&#24207;&#65289;&#30340;&#37325;&#35201;&#29305;&#24449;&#65292;&#23427;&#20351;&#24471;&#36825;&#20123;&#31995;&#32479;&#23613;&#31649;&#20351;&#29992;&#26377;&#38480;&#30340;&#31526;&#21495;&#38598;&#21512;&#65292;&#20294;&#20173;&#20855;&#26377;&#26080;&#38480;&#30340;&#23481;&#37327;&#12290;&#23427;&#22312;&#35748;&#30693;&#31185;&#23398;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#25512;&#29702;&#20013;&#37117;&#20855;&#26377;&#24456;&#22909;&#30340;&#25277;&#35937;&#24615;&#12290;&#28982;&#32780;&#65292;&#36830;&#32493;&#21644;&#31526;&#21495;&#22788;&#29702;&#20043;&#38388;&#30340;&#30028;&#38754;&#36890;&#24120;&#26159;&#36890;&#36807;&#31639;&#27861;&#32423;&#21035;&#19978;&#30340;&#37327;&#21270;&#25110;softmax&#37319;&#26679;&#27493;&#39588;&#26469;&#23454;&#29616;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#21560;&#24341;&#23376;&#21160;&#21147;&#23398;&#23558;&#31163;&#25955;&#21270;&#23454;&#29616;&#24471;&#26356;&#21152;&#31070;&#32463;&#21487;&#34892;&#65292;&#36825;&#31181;&#26041;&#27861;&#23558;&#36830;&#32493;&#30340;&#34920;&#31034;&#31354;&#38388;&#21010;&#20998;&#20026;&#23545;&#24212;&#20110;&#31526;&#21495;&#24207;&#21015;&#30340;&#20998;&#21306;&#12290;&#22312;&#21560;&#24341;&#23376;&#32593;&#32476;&#30340;&#22522;&#30784;&#19978;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20016;&#23500;&#30340;&#24863;&#30693;&#36755;&#20837;&#30340;&#21560;&#24341;&#23376;&#25903;&#25345;&#34920;&#31034;&#31354;&#38388;&#20013;&#24341;&#20837;&#31526;&#21495;&#31354;&#38388;&#32467;&#26500;&#21487;&#20197;&#20135;&#29983;&#32452;&#21512;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#30340;&#27169;&#22411;&#23637;&#31034;&#20102;&#19968;&#31181;&#20449;&#24687;&#22686;&#38271;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compositionality is an important feature of discrete symbolic systems, such as language and programs, as it enables them to have infinite capacity despite a finite symbol set. It serves as a useful abstraction for reasoning in both cognitive science and in AI, yet the interface between continuous and symbolic processing is often imposed by fiat at the algorithmic level, such as by means of quantization or a softmax sampling step. In this work, we explore how discretization could be implemented in a more neurally plausible manner through the modeling of attractor dynamics that partition the continuous representation space into basins that correspond to sequences of symbols. Building on established work in attractor networks and introducing novel training methods, we show that imposing structure in the symbolic space can produce compositionality in the attractor-supported representation space of rich sensory inputs. Lastly, we argue that our model exhibits the process of an information b
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24178;&#39044;&#24863;&#30693;&#30340;&#27010;&#24565;&#23884;&#20837;&#27169;&#22411;&#65292;&#29992;&#20110;&#25552;&#39640;&#31070;&#32463;&#26550;&#26500;&#23545;&#27010;&#24565;&#24178;&#39044;&#30340;&#21709;&#24212;&#24615;&#65292;&#24182;&#35299;&#20915;&#20102;&#27010;&#24565;&#24178;&#39044;&#39034;&#24207;&#21644;&#27169;&#22411;&#26550;&#26500;&#30340;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.16928</link><description>&lt;p&gt;
&#23398;&#20064;&#25509;&#21463;&#24110;&#21161;&#65306;&#24178;&#39044;&#24863;&#30693;&#30340;&#27010;&#24565;&#23884;&#20837;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning to Receive Help: Intervention-Aware Concept Embedding Models. (arXiv:2309.16928v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16928
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24178;&#39044;&#24863;&#30693;&#30340;&#27010;&#24565;&#23884;&#20837;&#27169;&#22411;&#65292;&#29992;&#20110;&#25552;&#39640;&#31070;&#32463;&#26550;&#26500;&#23545;&#27010;&#24565;&#24178;&#39044;&#30340;&#21709;&#24212;&#24615;&#65292;&#24182;&#35299;&#20915;&#20102;&#27010;&#24565;&#24178;&#39044;&#39034;&#24207;&#21644;&#27169;&#22411;&#26550;&#26500;&#30340;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBMs&#65289;&#36890;&#36807;&#20351;&#29992;&#19968;&#32452;&#39640;&#32423;&#27010;&#24565;&#26500;&#24314;&#21644;&#35299;&#37322;&#31070;&#32463;&#26550;&#26500;&#30340;&#39044;&#27979;&#65292;&#20197;&#35299;&#20915;&#20854;&#19981;&#36879;&#26126;&#24615;&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#27169;&#22411;&#30340;&#19968;&#20010;&#29305;&#27530;&#23646;&#24615;&#26159;&#23427;&#20204;&#20801;&#35768;&#27010;&#24565;&#24178;&#39044;&#65292;&#29992;&#25143;&#21487;&#20197;&#32416;&#27491;&#34987;&#38169;&#35823;&#39044;&#27979;&#30340;&#27010;&#24565;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24178;&#39044;&#26377;&#25928;&#24615;&#21487;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#24178;&#39044;&#27010;&#24565;&#30340;&#39034;&#24207;&#20197;&#21450;&#27169;&#22411;&#30340;&#26550;&#26500;&#21644;&#35757;&#32451;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#28304;&#20110;CBM&#22312;&#35757;&#32451;&#26102;&#32570;&#20047;&#27169;&#22411;&#36866;&#24212;&#27010;&#24565;&#24178;&#39044;&#30340;&#28608;&#21169;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24178;&#39044;&#24863;&#30693;&#30340;&#27010;&#24565;&#23884;&#20837;&#27169;&#22411;&#65288;IntCEMs&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;CBM&#30340;&#26032;&#22411;&#26550;&#26500;&#21644;&#35757;&#32451;&#33539;&#24335;&#65292;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#23545;&#27979;&#35797;&#26102;&#24178;&#39044;&#30340;&#21709;&#24212;&#24615;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#23398;&#20064;&#20102;&#19968;&#20010;&#27010;&#24565;&#24178;&#39044;&#31574;&#30053;&#65292;&#20174;&#20013;&#21487;&#20197;&#37319;&#26679;&#26377;&#24847;&#20041;&#30340;&#24178;&#39044;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Concept Bottleneck Models (CBMs) tackle the opacity of neural architectures by constructing and explaining their predictions using a set of high-level concepts. A special property of these models is that they permit concept interventions, wherein users can correct mispredicted concepts and thus improve the model's performance. Recent work, however, has shown that intervention efficacy can be highly dependent on the order in which concepts are intervened on and on the model's architecture and training hyperparameters. We argue that this is rooted in a CBM's lack of train-time incentives for the model to be appropriately receptive to concept interventions. To address this, we propose Intervention-aware Concept Embedding models (IntCEMs), a novel CBM-based architecture and training paradigm that improves a model's receptiveness to test-time interventions. Our model learns a concept intervention policy in an end-to-end fashion from where it can sample meaningful intervention trajectories a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EPTQ&#30340;&#22686;&#24378;&#21518;&#35757;&#32451;&#37327;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#33258;&#36866;&#24212;&#21152;&#26435;&#23618;&#21644;&#26080;&#26631;&#31614;Hessian&#36817;&#20284;&#25216;&#26415;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.11531</link><description>&lt;p&gt;
EPTQ:&#36890;&#36807;&#26080;&#26631;&#31614;Hessian&#22686;&#24378;&#30340;&#21518;&#35757;&#32451;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
EPTQ: Enhanced Post-Training Quantization via Label-Free Hessian. (arXiv:2309.11531v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EPTQ&#30340;&#22686;&#24378;&#21518;&#35757;&#32451;&#37327;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#33258;&#36866;&#24212;&#21152;&#26435;&#23618;&#21644;&#26080;&#26631;&#31614;Hessian&#36817;&#20284;&#25216;&#26415;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#37327;&#21270;&#24050;&#25104;&#20026;&#23558;&#36825;&#20123;&#32593;&#32476;&#23884;&#20837;&#21040;&#26368;&#32456;&#29992;&#25143;&#35774;&#22791;&#19978;&#30340;&#20851;&#38190;&#35201;&#32032;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#37327;&#21270;&#26041;&#27861;&#36890;&#24120;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#20005;&#37325;&#19979;&#38477;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EPTQ&#30340;&#22686;&#24378;&#21518;&#35757;&#32451;&#37327;&#21270;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#30693;&#35782;&#33976;&#39311;&#65292;&#24182;&#37319;&#29992;&#33258;&#36866;&#24212;&#21152;&#26435;&#23618;&#30340;&#26041;&#24335;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#26631;&#31614;Hessian&#36817;&#20284;&#25216;&#26415;&#65292;&#21517;&#20026;Label-Free Hessian&#12290;&#36825;&#31181;&#25216;&#26415;&#28040;&#38500;&#20102;&#35745;&#31639;Hessian&#25152;&#38656;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#30340;&#35201;&#27714;&#12290;&#33258;&#36866;&#24212;&#30693;&#35782;&#33976;&#39311;&#21033;&#29992;Label-Free Hessian&#25216;&#26415;&#65292;&#22312;&#36827;&#34892;&#20248;&#21270;&#26102;&#26356;&#21152;&#20851;&#27880;&#27169;&#22411;&#30340;&#25935;&#24863;&#37096;&#20998;&#12290;&#36890;&#36807;&#20351;&#29992;EPTQ&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#21253;&#25324;ImageNet&#20998;&#31867;&#12289;COCO&#30446;&#26631;&#26816;&#27979;&#21644;&#29992;&#20110;&#35821;&#20041;&#20998;&#21106;&#30340;Pascal-VOC&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantization of deep neural networks (DNN) has become a key element in the efforts of embedding such networks on end-user devices. However, current quantization methods usually suffer from costly accuracy degradation. In this paper, we propose a new method for Enhanced Post Training Quantization named EPTQ. The method is based on knowledge distillation with an adaptive weighting of layers. In addition, we introduce a new label-free technique for approximating the Hessian trace of the task loss, named Label-Free Hessian. This technique removes the requirement of a labeled dataset for computing the Hessian. The adaptive knowledge distillation uses the Label-Free Hessian technique to give greater attention to the sensitive parts of the model while performing the optimization. Empirically, by employing EPTQ we achieve state-of-the-art results on a wide variety of models, tasks, and datasets, including ImageNet classification, COCO object detection, and Pascal-VOC for semantic segmentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2307.08038</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields. (arXiv:2307.08038v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08038
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#39118;&#22330;&#25968;&#25454;&#23545;&#20110;&#27668;&#20505;&#12289;&#28023;&#27915;&#21644;&#27668;&#35937;&#30740;&#31350;&#20013;&#30340;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#20110;&#39118;&#25968;&#25454;&#24448;&#24448;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#39640;&#31354;&#38388;&#21464;&#24322;&#24615;&#21644;&#24322;&#36136;&#24615;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#20004;&#20010;&#32500;&#24230;&#36895;&#24230;&#30340;&#21452;&#21464;&#37327;&#39118;&#22330;&#36827;&#34892;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#25110;&#19979;&#32553;&#25918;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#31354;&#38388;&#32479;&#35745;&#23398;&#20013;&#65292;&#24120;&#29992;cokriging&#26469;&#39044;&#27979;&#21452;&#21464;&#37327;&#31354;&#38388;&#22330;&#12290;&#28982;&#32780;&#65292;cokriging&#39044;&#27979;&#22120;&#38500;&#20102;&#23545;&#39640;&#26031;&#36807;&#31243;&#26377;&#25928;&#22806;&#65292;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;cokriging&#35745;&#31639;&#37327;&#24040;&#22823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#20010;&#30001;&#31354;&#38388;&#24452;&#21521;&#22522;&#20989;&#25968;&#26500;&#24314;&#30340;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#65292;&#29992;&#20110;&#21452;&#21464;&#37327;&#31354;&#38388;&#25968;&#25454;&#39044;&#27979;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;cokriging&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
High spatial resolution wind data are essential for a wide range of applications in climate, oceanographic and meteorological studies. Large-scale spatial interpolation or downscaling of bivariate wind fields having velocity in two dimensions is a challenging task because wind data tend to be non-Gaussian with high spatial variability and heterogeneity. In spatial statistics, cokriging is commonly used for predicting bivariate spatial fields. However, the cokriging predictor is not optimal except for Gaussian processes. Additionally, cokriging is computationally prohibitive for large datasets. In this paper, we propose a method, called bivariate DeepKriging, which is a spatially dependent deep neural network (DNN) with an embedding layer constructed by spatial radial basis functions for bivariate spatial data prediction. We then develop a distribution-free uncertainty quantification method based on bootstrap and ensemble DNN. Our proposed approach outperforms the traditional cokriging 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#35299;&#20915;&#24191;&#20041;&#33258;&#30001;&#33021;&#65288;FE&#65289;&#30446;&#26631;&#30340;&#21512;&#25104;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#21464;&#20998;&#20449;&#24687;&#26356;&#26032;&#21644;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;T&#24418;&#36855;&#23467;&#23548;&#33322;&#20219;&#21153;&#30340;&#27169;&#25311;&#27604;&#36739;&#65292;&#34920;&#26126;AIF&#21487;&#24341;&#36215;&#35748;&#30693;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.02733</link><description>&lt;p&gt;
&#23454;&#29616;&#21512;&#25104;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#65292;&#31532;&#20108;&#37096;&#20998;&#65306;&#21464;&#20998;&#20449;&#24687;&#26356;&#26032;
&lt;/p&gt;
&lt;p&gt;
Realising Synthetic Active Inference Agents, Part II: Variational Message Updates. (arXiv:2306.02733v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#35299;&#20915;&#24191;&#20041;&#33258;&#30001;&#33021;&#65288;FE&#65289;&#30446;&#26631;&#30340;&#21512;&#25104;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#21464;&#20998;&#20449;&#24687;&#26356;&#26032;&#21644;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;T&#24418;&#36855;&#23467;&#23548;&#33322;&#20219;&#21153;&#30340;&#27169;&#25311;&#27604;&#36739;&#65292;&#34920;&#26126;AIF&#21487;&#24341;&#36215;&#35748;&#30693;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30001;&#33021;&#21407;&#29702;&#65288;FEP&#65289;&#25551;&#36848;&#29983;&#29289;&#20195;&#29702;&#36890;&#36807;&#30456;&#24212;&#29615;&#22659;&#30340;&#29983;&#25104;&#27169;&#22411;&#26368;&#23567;&#21270;&#21464;&#20998;&#33258;&#30001;&#33021;&#65288;FE&#65289;&#12290;&#20027;&#21160;&#25512;&#29702;&#65288;AIF&#65289;&#26159;FEP&#30340;&#25512;&#35770;&#65292;&#25551;&#36848;&#20102;&#20195;&#29702;&#20154;&#36890;&#36807;&#26368;&#23567;&#21270;&#26399;&#26395;&#30340;FE&#30446;&#26631;&#26469;&#25506;&#32034;&#21644;&#21033;&#29992;&#20854;&#29615;&#22659;&#12290;&#22312;&#20004;&#31687;&#30456;&#20851;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#33258;&#30001;&#24418;&#24335;Forney-style&#22240;&#23376;&#22270;&#65288;FFG&#65289;&#19978;&#30340;&#28040;&#24687;&#20256;&#36882;&#65292;&#25551;&#36848;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#21512;&#25104;AIF&#20195;&#29702;&#30340;&#35748;&#30693;&#26041;&#27861;&#12290;&#26412;&#25991;&#65288;&#31532;&#20108;&#37096;&#20998;&#65289;&#26681;&#25454;&#21464;&#20998;&#28436;&#31639;&#27861;&#65292;&#23548;&#20986;&#20102;&#26368;&#23567;&#21270;CFFG&#19978;&#65288;&#24191;&#20041;&#65289;FE&#30446;&#26631;&#30340;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#12290;&#27604;&#36739;&#20102;&#27169;&#25311;Bethe&#21644;&#24191;&#20041;FE&#20195;&#29702;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#35828;&#26126;&#20102;&#21512;&#25104;AIF&#22914;&#20309;&#22312;T&#24418;&#36855;&#23467;&#23548;&#33322;&#20219;&#21153;&#19978;&#24341;&#36215;&#35748;&#30693;&#34892;&#20026;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;AIF&#20195;&#29702;&#30340;&#23436;&#25972;&#28040;&#24687;&#20256;&#36882;&#25551;&#36848;&#65292;&#21487;&#20197;&#25512;&#23548;&#21644;&#37325;&#29992;&#35813;&#20195;&#29702;&#22312;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Free Energy Principle (FEP) describes (biological) agents as minimising a variational Free Energy (FE) with respect to a generative model of their environment. Active Inference (AIF) is a corollary of the FEP that describes how agents explore and exploit their environment by minimising an expected FE objective. In two related papers, we describe a scalable, epistemic approach to synthetic AIF agents, by message passing on free-form Forney-style Factor Graphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG) notation that visually represents (generalised) FE objectives for AIF. The current paper (part II) derives message passing algorithms that minimise (generalised) FE objectives on a CFFG by variational calculus. A comparison between simulated Bethe and generalised FE agents illustrates how synthetic AIF induces epistemic behaviour on a T-maze navigation task. With a full message passing account of synthetic AIF agents, it becomes possible to derive and reuse 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#27602;&#21270;&#25915;&#20987;&#31574;&#30053;&#65292;&#26082;&#21487;&#20197;&#23454;&#29616;&#25298;&#32477;&#26381;&#21153;(Dos)&#30446;&#26631;&#65292;&#20063;&#21487;&#20197;&#31934;&#30830;&#25511;&#21046;&#20840;&#23616;&#20934;&#30830;&#24615;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#38544;&#24418;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.10783</link><description>&lt;p&gt;
&#25298;&#32477;&#26381;&#21153;&#25110;&#32454;&#31890;&#24230;&#25511;&#21046;&#65306;&#38754;&#21521;&#32852;&#37030;&#23398;&#20064;&#30340;&#28789;&#27963;&#27169;&#22411;&#27602;&#21270;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Denial-of-Service or Fine-Grained Control: Towards Flexible Model Poisoning Attacks on Federated Learning. (arXiv:2304.10783v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#27602;&#21270;&#25915;&#20987;&#31574;&#30053;&#65292;&#26082;&#21487;&#20197;&#23454;&#29616;&#25298;&#32477;&#26381;&#21153;(Dos)&#30446;&#26631;&#65292;&#20063;&#21487;&#20197;&#31934;&#30830;&#25511;&#21046;&#20840;&#23616;&#20934;&#30830;&#24615;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#38544;&#24418;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#23481;&#26131;&#21463;&#21040;&#27602;&#21270;&#25915;&#20987;&#65292;&#25932;&#23545;&#26041;&#20250;&#30772;&#22351;&#20840;&#23616;&#32858;&#21512;&#32467;&#26524;&#24182;&#36896;&#25104;&#25298;&#32477;&#26381;&#21153;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#27169;&#22411;&#27602;&#21270;&#25915;&#20987;(FMPA)&#65292;&#26088;&#22312;&#23454;&#29616;&#22810;&#21151;&#33021;&#25915;&#20987;&#30446;&#26631;&#12290;&#26412;&#25991;&#32771;&#34385;&#22914;&#19979;&#23454;&#38469;&#24773;&#26223;&#65306;&#25932;&#23545;&#26041;&#27809;&#26377;&#20851;&#20110;FL&#31995;&#32479;&#30340;&#39069;&#22806;&#20449;&#24687;&#65288;&#20363;&#22914;&#65292;&#32858;&#21512;&#35268;&#21017;&#25110;&#33391;&#24615;&#35774;&#22791;&#19978;&#30340;&#26356;&#26032;&#65289;&#12290;FMPA&#21033;&#29992;&#20840;&#23616;&#21382;&#21490;&#20449;&#24687;&#26500;&#24314;&#20272;&#35745;&#22120;&#65292;&#23558;&#19979;&#19968;&#36718;&#20840;&#23616;&#27169;&#22411;&#39044;&#27979;&#20026;&#33391;&#24615;&#21442;&#32771;&#27169;&#22411;&#65292;&#24182;&#24494;&#35843;&#21442;&#32771;&#27169;&#22411;&#20197;&#33719;&#24471;&#25152;&#38656;&#30340;&#31934;&#24230;&#20302;&#21644;&#25200;&#21160;&#23567;&#30340;&#27602;&#21270;&#27169;&#22411;&#12290;FMPA&#19981;&#20165;&#21487;&#20197;&#36798;&#21040;DoS&#30340;&#30446;&#26631;&#65292;&#36824;&#21487;&#20197;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#21551;&#21160;&#32454;&#31890;&#24230;&#21487;&#25511;&#25915;&#20987;&#65292;&#20174;&#32780;&#31934;&#30830;&#38477;&#20302;&#20840;&#23616;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#36827;&#19968;&#27493;&#25506;&#32034;&#20102;FMPA&#22312;&#20960;&#31181;FL&#22330;&#26223;&#19979;&#30340;&#25915;&#20987;&#24615;&#33021;&#65292;&#21253;&#25324;&#20108;&#20803;&#20998;&#31867;&#21644;&#22270;&#20687;&#20998;&#31867;&#65292;&#22312;&#19981;&#21516;&#30340;&#25915;&#20987;&#30446;&#26631;&#21644;&#25915;&#20987;&#30693;&#35782;&#27700;&#24179;&#19979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;FMPA&#21487;&#20197;&#26377;&#25928;&#32780;&#39640;&#25928;&#22320;&#23454;&#29616;&#25152;&#38656;&#30340;&#25915;&#20987;&#30446;&#26631;&#65292;&#21516;&#26102;&#20445;&#25345;&#38544;&#24418;&#21644;&#19981;&#21487;&#24863;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) is vulnerable to poisoning attacks, where adversaries corrupt the global aggregation results and cause denial-of-service (DoS). Unlike recent model poisoning attacks that optimize the amplitude of malicious perturbations along certain prescribed directions to cause DoS, we propose a Flexible Model Poisoning Attack (FMPA) that can achieve versatile attack goals. We consider a practical threat scenario where no extra knowledge about the FL system (e.g., aggregation rules or updates on benign devices) is available to adversaries. FMPA exploits the global historical information to construct an estimator that predicts the next round of the global model as a benign reference. It then fine-tunes the reference model to obtain the desired poisoned model with low accuracy and small perturbations. Besides the goal of causing DoS, FMPA can be naturally extended to launch a fine-grained controllable attack, making it possible to precisely reduce the global accuracy. Armed wi
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#26088;&#22312;&#20171;&#32461;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#30340;&#27010;&#24565;&#21644;&#24037;&#20855;&#65292;&#24182;&#24635;&#32467;&#20102;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2302.11337</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Bayesian Matrix Decomposition and Applications. (arXiv:2302.11337v2 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#20171;&#32461;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#30340;&#27010;&#24565;&#21644;&#24037;&#20855;&#65292;&#24182;&#24635;&#32467;&#20102;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#30340;&#21807;&#19968;&#30446;&#30340;&#26159;&#20026;&#20102;&#32473;&#20986;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#27010;&#24565;&#21644;&#25968;&#23398;&#24037;&#20855;&#30340;&#33258;&#21253;&#21547;&#20171;&#32461;&#65292;&#20197;&#20415;&#22312;&#21518;&#32493;&#31456;&#33410;&#20013;&#26080;&#32541;&#24341;&#20837;&#30697;&#38453;&#20998;&#35299;&#25216;&#26415;&#21450;&#20854;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#28165;&#26970;&#22320;&#24847;&#35782;&#21040;&#25105;&#20204;&#26080;&#27861;&#35206;&#30422;&#20851;&#20110;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#30340;&#25152;&#26377;&#26377;&#29992;&#21644;&#26377;&#36259;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#30001;&#20110;&#35752;&#35770;&#30340;&#33539;&#22260;&#26377;&#38480;&#65292;&#20363;&#22914;&#20998;&#26512;&#21464;&#20998;&#25512;&#29702;&#20197;&#36827;&#34892;&#20248;&#21270;&#30340;&#20998;&#31163;&#20998;&#26512;&#12290;&#25105;&#20204;&#23558;&#35835;&#32773;&#24341;&#23548;&#21040;&#36125;&#21494;&#26031;&#20998;&#26512;&#39046;&#22495;&#30340;&#25991;&#29486;&#20013;&#65292;&#20197;&#20415;&#26356;&#35814;&#32454;&#22320;&#20171;&#32461;&#30456;&#20851;&#39046;&#22495;&#12290;&#26412;&#20070;&#20027;&#35201;&#24635;&#32467;&#20102;&#37325;&#35201;&#30340;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65288;&#20363;&#22914;&#23454;&#20540;&#20998;&#35299;&#12289;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#12289;&#36125;&#21494;&#26031;&#25554;&#20540;&#20998;&#35299;&#65289;&#30340;&#30446;&#30340;&#21644;&#24847;&#20041;&#65292;&#20197;&#21450;&#36825;&#20123;&#26041;&#27861;&#30340;&#36215;&#28304;&#21644;&#22797;&#26434;&#24615;&#23545;&#20854;&#24212;&#29992;&#25552;&#20379;&#30340;&#21551;&#31034;&#12290;&#25968;&#23398;&#20808;&#20915;&#26465;&#20214;&#26159;&#31532;&#19968;&#38376;&#35838;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
The sole aim of this book is to give a self-contained introduction to concepts and mathematical tools in Bayesian matrix decomposition in order to seamlessly introduce matrix decomposition techniques and their applications in subsequent sections. However, we clearly realize our inability to cover all the useful and interesting results concerning Bayesian matrix decomposition and given the paucity of scope to present this discussion, e.g., the separated analysis of variational inference for conducting the optimization. We refer the reader to literature in the field of Bayesian analysis for a more detailed introduction to the related fields.  This book is primarily a summary of purpose, significance of important Bayesian matrix decomposition methods, e.g., real-valued decomposition, nonnegative matrix factorization, Bayesian interpolative decomposition, and the origin and complexity of the methods which shed light on their applications. The mathematical prerequisite is a first course in 
&lt;/p&gt;</description></item></channel></rss>