<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22312;&#22810;&#29615;&#22659;&#39044;&#27979;&#38382;&#39064;&#20013;&#26500;&#24314;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#21644;&#32622;&#20449;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;&#35843;&#25972;&#26041;&#27861;&#20197;&#36866;&#24212;&#38382;&#39064;&#38590;&#24230;&#65292;&#20174;&#32780;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;&#65292;&#36825;&#22312;&#31070;&#32463;&#24863;&#24212;&#21644;&#29289;&#31181;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#23454;&#38469;&#34920;&#29616;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.16336</link><description>&lt;p&gt;
&#22810;&#29615;&#22659;&#22330;&#26223;&#20013;&#30340;&#39044;&#27979;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Predictive Inference in Multi-environment Scenarios
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16336
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22312;&#22810;&#29615;&#22659;&#39044;&#27979;&#38382;&#39064;&#20013;&#26500;&#24314;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#21644;&#32622;&#20449;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;&#35843;&#25972;&#26041;&#27861;&#20197;&#36866;&#24212;&#38382;&#39064;&#38590;&#24230;&#65292;&#20174;&#32780;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;&#65292;&#36825;&#22312;&#31070;&#32463;&#24863;&#24212;&#21644;&#29289;&#31181;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#23454;&#38469;&#34920;&#29616;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#36328;&#22810;&#20010;&#29615;&#22659;&#30340;&#39044;&#27979;&#38382;&#39064;&#20013;&#26500;&#24314;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#21644;&#32622;&#20449;&#38598;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36866;&#29992;&#20110;&#36825;&#20123;&#38382;&#39064;&#30340;&#20004;&#31181;&#35206;&#30422;&#31867;&#22411;&#65292;&#25193;&#23637;&#20102;Jackknife&#21644;&#20998;&#35010;&#19968;&#33268;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#36825;&#31181;&#38750;&#20256;&#32479;&#30340;&#23618;&#27425;&#25968;&#25454;&#29983;&#25104;&#22330;&#26223;&#20013;&#33719;&#24471;&#26080;&#20998;&#24067;&#35206;&#30422;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#36824;&#21253;&#25324;&#23545;&#38750;&#23454;&#20540;&#21709;&#24212;&#35774;&#32622;&#30340;&#25193;&#23637;&#65292;&#20197;&#21450;&#36825;&#20123;&#19968;&#33324;&#38382;&#39064;&#20013;&#39044;&#27979;&#25512;&#26029;&#30340;&#19968;&#33268;&#24615;&#29702;&#35770;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;&#35843;&#25972;&#26041;&#27861;&#65292;&#20197;&#36866;&#24212;&#38382;&#39064;&#38590;&#24230;&#65292;&#36825;&#36866;&#29992;&#20110;&#20855;&#26377;&#23618;&#27425;&#25968;&#25454;&#30340;&#39044;&#27979;&#25512;&#26029;&#30340;&#29616;&#26377;&#26041;&#27861;&#20197;&#21450;&#25105;&#20204;&#24320;&#21457;&#30340;&#26041;&#27861;&#65307;&#36825;&#36890;&#36807;&#31070;&#32463;&#21270;&#23398;&#24863;&#24212;&#21644;&#29289;&#31181;&#20998;&#31867;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16336v1 Announce Type: cross  Abstract: We address the challenge of constructing valid confidence intervals and sets in problems of prediction across multiple environments. We investigate two types of coverage suitable for these problems, extending the jackknife and split-conformal methods to show how to obtain distribution-free coverage in such non-traditional, hierarchical data-generating scenarios. Our contributions also include extensions for settings with non-real-valued responses and a theory of consistency for predictive inference in these general problems. We demonstrate a novel resizing method to adapt to problem difficulty, which applies both to existing approaches for predictive inference with hierarchical data and the methods we develop; this reduces prediction set sizes using limited information from the test environment, a key to the methods' practical performance, which we evaluate through neurochemical sensing and species classification datasets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#20013;&#24182;&#19982;&#31070;&#32463;&#32593;&#32476;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#20248;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13150</link><description>&lt;p&gt;
&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Training Survival Models using Scoring Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13150
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#20013;&#24182;&#19982;&#31070;&#32463;&#32593;&#32476;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#20248;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#20026;&#21508;&#20010;&#39046;&#22495;&#20013;&#37096;&#20998;&#19981;&#23436;&#25972;&#30340;&#20107;&#20214;&#21457;&#29983;&#26102;&#38388;&#25968;&#25454;&#25552;&#20379;&#20102;&#20851;&#38190;&#35265;&#35299;&#12290;&#23427;&#20063;&#26159;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#20010;&#37325;&#35201;&#31034;&#20363;&#12290;&#25105;&#20204;&#30340;&#25552;&#26696;&#20197;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#24335;&#21033;&#29992;&#20102;&#39044;&#27979;&#30340;&#27010;&#29575;&#24615;&#36136;&#65292;&#36890;&#36807;&#22312;&#27169;&#22411;&#25311;&#21512;&#36807;&#31243;&#20013;&#20351;&#29992;&#65288;&#21512;&#36866;&#30340;&#65289;&#35780;&#20998;&#35268;&#21017;&#32780;&#38750;&#22522;&#20110;&#20284;&#28982;&#24615;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19981;&#21516;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#23376;&#26694;&#26550;&#65292;&#20801;&#35768;&#19981;&#21516;&#31243;&#24230;&#30340;&#28789;&#27963;&#24615;&#12290;&#23558;&#20854;&#28151;&#20837;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#23548;&#33268;&#20102;&#19968;&#20010;&#35745;&#31639;&#26377;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#20135;&#29983;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#24674;&#22797;&#21508;&#31181;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#22312;&#19982;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#27604;&#36739;&#20013;&#65292;&#20248;&#21270;&#25928;&#26524;&#21516;&#26679;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13150v1 Announce Type: new  Abstract: Survival Analysis provides critical insights for partially incomplete time-to-event data in various domains. It is also an important example of probabilistic machine learning. The probabilistic nature of the predictions can be exploited by using (proper) scoring rules in the model fitting process instead of likelihood-based optimization. Our proposal does so in a generic manner and can be used for a variety of model classes. We establish different parametric and non-parametric sub-frameworks that allow different degrees of flexibility. Incorporated into neural networks, it leads to a computationally efficient and scalable optimization routine, yielding state-of-the-art predictive performance. Finally, we show that using our framework, we can recover various parametric models and demonstrate that optimization works equally well when compared to likelihood-based methods.
&lt;/p&gt;</description></item><item><title>PAPER-HILT&#26159;&#38024;&#23545;&#20154;&#26426;&#21327;&#21516;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;&#21019;&#26032;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#25552;&#21069;&#36864;&#20986;&#26041;&#27861;&#21160;&#24577;&#35843;&#25972;&#38544;&#31169;&#20445;&#25252;&#21644;&#31995;&#32479;&#25928;&#29992;&#65292;&#20197;&#36866;&#24212;&#20010;&#20307;&#34892;&#20026;&#27169;&#24335;&#21644;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2403.05864</link><description>&lt;p&gt;
PAPER-HILT&#65306;&#20010;&#24615;&#21270;&#21644;&#33258;&#36866;&#24212;&#38544;&#31169;&#24863;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;&#25552;&#21069;&#36864;&#20986;&#22312;&#20154;&#26426;&#21327;&#21516;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
PAPER-HILT: Personalized and Adaptive Privacy-Aware Early-Exit for Reinforcement Learning in Human-in-the-Loop Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05864
&lt;/p&gt;
&lt;p&gt;
PAPER-HILT&#26159;&#38024;&#23545;&#20154;&#26426;&#21327;&#21516;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;&#21019;&#26032;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#25552;&#21069;&#36864;&#20986;&#26041;&#27861;&#21160;&#24577;&#35843;&#25972;&#38544;&#31169;&#20445;&#25252;&#21644;&#31995;&#32479;&#25928;&#29992;&#65292;&#20197;&#36866;&#24212;&#20010;&#20307;&#34892;&#20026;&#27169;&#24335;&#21644;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26085;&#30410;&#25104;&#20026;&#20154;&#26426;&#21327;&#21516;&#65288;HITL&#65289;&#24212;&#29992;&#20013;&#30340;&#39318;&#36873;&#26041;&#27861;&#65292;&#22240;&#20854;&#36866;&#24212;&#20110;&#20154;&#31867;&#20132;&#20114;&#30340;&#21160;&#24577;&#29305;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#31181;&#29615;&#22659;&#20013;&#25972;&#21512;RL&#20250;&#24102;&#26469;&#37325;&#22823;&#30340;&#38544;&#31169;&#38382;&#39064;&#65292;&#21487;&#33021;&#20250;&#19981;&#32463;&#24847;&#22320;&#26292;&#38706;&#25935;&#24863;&#29992;&#25143;&#20449;&#24687;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#35770;&#25991;&#19987;&#27880;&#20110;&#24320;&#21457;PAPER-HILT&#65292;&#19968;&#31181;&#21019;&#26032;&#30340;&#33258;&#36866;&#24212;RL&#31574;&#30053;&#65292;&#36890;&#36807;&#21033;&#29992;&#19987;&#20026;HITL&#29615;&#22659;&#20013;&#38544;&#31169;&#20445;&#25252;&#35774;&#35745;&#30340;&#25552;&#21069;&#36864;&#20986;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21160;&#24577;&#35843;&#25972;&#38544;&#31169;&#20445;&#25252;&#21644;&#31995;&#32479;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#20351;&#20854;&#25805;&#20316;&#36866;&#24212;&#20010;&#20154;&#34892;&#20026;&#27169;&#24335;&#21644;&#20559;&#22909;&#12290;&#25105;&#20204;&#20027;&#35201;&#24378;&#35843;&#38754;&#20020;&#22788;&#29702;&#20154;&#31867;&#34892;&#20026;&#30340;&#21487;&#21464;&#21644;&#19981;&#26029;&#21457;&#23637;&#30340;&#25361;&#25112;&#65292;&#20351;&#24471;&#38745;&#24577;&#38544;&#31169;&#27169;&#22411;&#22833;&#25928;&#12290;&#36890;&#36807;&#20854;&#24212;&#29992;&#65292;&#35780;&#20272;&#20102;PAPER-HILT&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05864v1 Announce Type: new  Abstract: Reinforcement Learning (RL) has increasingly become a preferred method over traditional rule-based systems in diverse human-in-the-loop (HITL) applications due to its adaptability to the dynamic nature of human interactions. However, integrating RL in such settings raises significant privacy concerns, as it might inadvertently expose sensitive user information. Addressing this, our paper focuses on developing PAPER-HILT, an innovative, adaptive RL strategy through exploiting an early-exit approach designed explicitly for privacy preservation in HITL environments. This approach dynamically adjusts the tradeoff between privacy protection and system utility, tailoring its operation to individual behavioral patterns and preferences. We mainly highlight the challenge of dealing with the variable and evolving nature of human behavior, which renders static privacy models ineffective. PAPER-HILT's effectiveness is evaluated through its applicati
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#36895;&#29575;&#36801;&#31227;&#29616;&#35937;&#21487;&#20197;&#24402;&#22240;&#20110;&#22312;&#956;P&#21644;&#20854;&#28145;&#24230;&#24310;&#20280;&#19979;&#65292;&#35757;&#32451;&#25439;&#22833;Hessian&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65288;&#21363;&#38160;&#24230;&#65289;&#22312;&#36739;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#22522;&#26412;&#29420;&#31435;&#20110;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.17457</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#23398;&#20064;&#36895;&#29575;&#20855;&#26377;&#36801;&#31227;&#24615;&#65311;&#35843;&#21644;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#20248;&#21270;&#21644;&#23610;&#24230;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Why do Learning Rates Transfer? Reconciling Optimization and Scaling Limits for Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17457
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#36895;&#29575;&#36801;&#31227;&#29616;&#35937;&#21487;&#20197;&#24402;&#22240;&#20110;&#22312;&#956;P&#21644;&#20854;&#28145;&#24230;&#24310;&#20280;&#19979;&#65292;&#35757;&#32451;&#25439;&#22833;Hessian&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65288;&#21363;&#38160;&#24230;&#65289;&#22312;&#36739;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#22522;&#26412;&#29420;&#31435;&#20110;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#35777;&#25454;&#34920;&#26126;&#65292;&#22914;&#26524;&#31070;&#32463;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#26397;&#30528;&#25152;&#35859;&#30340;&#20016;&#23500;&#29305;&#24449;&#23398;&#20064;&#26497;&#38480;&#65288;&#956;P&#21450;&#20854;&#28145;&#24230;&#25193;&#23637;&#65289;&#36827;&#34892;&#32553;&#25918;&#65292;&#37027;&#20040;&#26576;&#20123;&#36229;&#21442;&#25968; - &#20363;&#22914;&#23398;&#20064;&#36895;&#29575; - &#23601;&#20250;&#20174;&#23567;&#27169;&#22411;&#36716;&#31227;&#21040;&#38750;&#24120;&#22823;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#25104;&#26412;&#12290;&#20174;&#20248;&#21270;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#29616;&#35937;&#20196;&#20154;&#22256;&#24785;&#65292;&#22240;&#20026;&#23427;&#24847;&#21619;&#30528;&#25439;&#22833;&#26223;&#35266;&#22312;&#38750;&#24120;&#19981;&#21516;&#30340;&#27169;&#22411;&#23610;&#23544;&#20043;&#38388;&#26159;&#38750;&#24120;&#19968;&#33268;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25214;&#21040;&#35777;&#25454;&#25903;&#25345;&#23398;&#20064;&#36895;&#29575;&#36801;&#31227;&#21487;&#20197;&#24402;&#22240;&#20110;&#20107;&#23454;&#65306;&#22312;&#956;P&#21450;&#20854;&#28145;&#24230;&#25193;&#23637;&#19979;&#65292;&#35757;&#32451;&#25439;&#22833;Hessian&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65288;&#21363;&#38160;&#24230;&#65289;&#22312;&#36739;&#38271;&#30340;&#35757;&#32451;&#26102;&#38388;&#20869;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#29420;&#31435;&#20110;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#23637;&#31034;&#22312;&#31070;&#32463;&#20999;&#32447;&#26680;&#65288;NTK&#65289;&#20307;&#31995;&#19979;&#65292;&#38160;&#24230;&#22312;&#19981;&#21516;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17457v1 Announce Type: new  Abstract: Recently, there has been growing evidence that if the width and depth of a neural network are scaled toward the so-called rich feature learning limit ($\mu$P and its depth extension), then some hyperparameters - such as the learning rate - exhibit transfer from small to very large models, thus reducing the cost of hyperparameter tuning. From an optimization perspective, this phenomenon is puzzling, as it implies that the loss landscape is remarkably consistent across very different model sizes. In this work, we find empirical evidence that learning rate transfer can be attributed to the fact that under $\mu$P and its depth extension, the largest eigenvalue of the training loss Hessian (i.e. the sharpness) is largely independent of the width and depth of the network for a sustained period of training time. On the other hand, we show that under the neural tangent kernel (NTK) regime, the sharpness exhibits very different dynamics at differ
&lt;/p&gt;</description></item><item><title>&#29616;&#26377;&#30340;LLM&#27700;&#21360;&#31995;&#32479;&#34429;&#28982;&#20855;&#26377;&#36136;&#37327;&#20445;&#30041;&#12289;&#40065;&#26834;&#24615;&#21644;&#20844;&#24320;&#26816;&#27979;API&#31561;&#20248;&#28857;&#65292;&#20294;&#20063;&#22240;&#27492;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#25915;&#20987;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#22871;&#23454;&#29992;&#25351;&#21335;&#20197;&#32531;&#35299;&#36825;&#20123;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2402.16187</link><description>&lt;p&gt;
&#21033;&#29992;&#20854;&#20248;&#21183;&#25915;&#20987;LLM&#27700;&#21360;
&lt;/p&gt;
&lt;p&gt;
Attacking LLM Watermarks by Exploiting Their Strengths
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16187
&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;LLM&#27700;&#21360;&#31995;&#32479;&#34429;&#28982;&#20855;&#26377;&#36136;&#37327;&#20445;&#30041;&#12289;&#40065;&#26834;&#24615;&#21644;&#20844;&#24320;&#26816;&#27979;API&#31561;&#20248;&#28857;&#65292;&#20294;&#20063;&#22240;&#27492;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#25915;&#20987;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#22871;&#23454;&#29992;&#25351;&#21335;&#20197;&#32531;&#35299;&#36825;&#20123;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#23637;&#20351;&#24471;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#25991;&#26412;&#12289;&#20195;&#30721;&#21644;&#22270;&#29255;&#33021;&#22815;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#27169;&#20223;&#20154;&#31867;&#29983;&#25104;&#30340;&#20869;&#23481;&#12290;&#27700;&#21360;&#25216;&#26415;&#26088;&#22312;&#23558;&#20449;&#24687;&#23884;&#20837;&#27169;&#22411;&#30340;&#36755;&#20986;&#20013;&#20197;&#39564;&#35777;&#20854;&#26469;&#28304;&#65292;&#23545;&#20110;&#20943;&#23569;&#23545;&#36825;&#20123;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#30340;&#28389;&#29992;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#27700;&#21360;&#26041;&#26696;&#20173;&#28982;&#20196;&#20154;&#24847;&#22806;&#22320;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;LLM&#27700;&#21360;&#31995;&#32479;&#20849;&#20139;&#30340;&#21487;&#21462;&#29305;&#24615;&#65292;&#20363;&#22914;&#36136;&#37327;&#20445;&#30041;&#12289;&#40065;&#26834;&#24615;&#21644;&#20844;&#24320;&#26816;&#27979;API&#65292;&#21453;&#36807;&#26469;&#21364;&#20351;&#36825;&#20123;&#31995;&#32479;&#23481;&#26131;&#36973;&#21463;&#21508;&#31181;&#25915;&#20987;&#12290;&#25105;&#20204;&#22312;&#24120;&#35265;&#27700;&#21360;&#35774;&#35745;&#36873;&#25321;&#26041;&#38754;&#20005;&#26684;&#30740;&#31350;&#28508;&#22312;&#25915;&#20987;&#65292;&#24182;&#25552;&#20986;&#20102;&#32531;&#35299;&#25915;&#20987;&#30340;&#26368;&#20339;&#23454;&#36341;&#21644;&#38450;&#24481;&#25514;&#26045;&#8212;&#8212;&#24314;&#31435;&#20102;&#19968;&#22871;&#23884;&#20837;&#21644;&#26816;&#27979;LLM&#27700;&#21360;&#30340;&#23454;&#29992;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16187v1 Announce Type: cross  Abstract: Advances in generative models have made it possible for AI-generated text, code, and images to mirror human-generated content in many applications. Watermarking, a technique that aims to embed information in the output of a model to verify its source, is useful for mitigating misuse of such AI-generated content. However, existing watermarking schemes remain surprisingly susceptible to attack. In particular, we show that desirable properties shared by existing LLM watermarking systems such as quality preservation, robustness, and public detection APIs can in turn make these systems vulnerable to various attacks. We rigorously study potential attacks in terms of common watermark design choices, and propose best practices and defenses for mitigation -- establishing a set of practical guidelines for embedding and detection of LLM watermarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;&#27169;&#22411;&#65292;&#36890;&#36807;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#21644;&#38543;&#26426;&#35268;&#21010;&#65292;&#35299;&#20915;&#20102;&#20805;&#30005;&#20250;&#35805;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#20248;&#21270;&#25104;&#26412;&#24182;&#25552;&#39640;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.13224</link><description>&lt;p&gt;
&#36890;&#36807;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#21644;&#38543;&#26426;&#35268;&#21010;&#25511;&#21046;&#22823;&#22411;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;
&lt;/p&gt;
&lt;p&gt;
Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;&#27169;&#22411;&#65292;&#36890;&#36807;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#21644;&#38543;&#26426;&#35268;&#21010;&#65292;&#35299;&#20915;&#20102;&#20805;&#30005;&#20250;&#35805;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#20248;&#21270;&#25104;&#26412;&#24182;&#25552;&#39640;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;&#65288;EVCS&#65289;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#34701;&#21512;&#20102;&#30495;&#23454;&#19990;&#30028;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#22914;&#25554;&#27133;&#21151;&#29575;&#38480;&#21046;&#12289;&#21512;&#21516;&#38408;&#20540;&#36229;&#38480;&#24809;&#32602;&#20197;&#21450;&#30005;&#21160;&#27773;&#36710;&#65288;EVs&#65289;&#30340;&#26089;&#26399;&#26029;&#24320;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#25511;&#21046;EVCS&#30340;&#38382;&#39064;&#24418;&#24335;&#65292;&#24182;&#23454;&#26045;&#20102;&#20004;&#31181;&#22810;&#38454;&#27573;&#38543;&#26426;&#35268;&#21010;&#26041;&#27861;&#65292;&#21033;&#29992;&#29992;&#25143;&#25552;&#20379;&#30340;&#20449;&#24687;&#65292;&#21363;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#21644;&#20108;&#38454;&#27573;&#38543;&#26426;&#35268;&#21010;&#12290;&#35813;&#27169;&#22411;&#35299;&#20915;&#20102;&#20805;&#30005;&#20250;&#35805;&#24320;&#22987;&#21644;&#32467;&#26463;&#26102;&#38388;&#20197;&#21450;&#33021;&#37327;&#38656;&#27714;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#39547;&#30041;&#26102;&#38388;&#20381;&#36182;&#38543;&#26426;&#36807;&#31243;&#30340;&#29992;&#25143;&#34892;&#20026;&#27169;&#22411;&#22686;&#24378;&#20102;&#25104;&#26412;&#38477;&#20302;&#30340;&#21516;&#26102;&#20445;&#25345;&#23458;&#25143;&#28385;&#24847;&#24230;&#12290;&#36890;&#36807;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;22&#22825;&#27169;&#25311;&#23637;&#31034;&#20102;&#20004;&#31181;&#25552;&#20986;&#26041;&#27861;&#30456;&#23545;&#20110;&#20004;&#20010;&#22522;&#32447;&#30340;&#20248;&#21183;&#12290;&#20004;&#38454;&#27573;&#26041;&#27861;&#35777;&#26126;&#20102;&#38024;&#23545;&#26089;&#26399;&#26029;&#24320;&#30340;&#40065;&#26834;&#24615;&#65292;&#32771;&#34385;&#20102;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13224v1 Announce Type: cross  Abstract: This paper introduces an Electric Vehicle Charging Station (EVCS) model that incorporates real-world constraints, such as slot power limitations, contract threshold overruns penalties, or early disconnections of electric vehicles (EVs). We propose a formulation of the problem of EVCS control under uncertainty, and implement two Multi-Stage Stochastic Programming approaches that leverage user-provided information, namely, Model Predictive Control and Two-Stage Stochastic Programming. The model addresses uncertainties in charging session start and end times, as well as in energy demand. A user's behavior model based on a sojourn-time-dependent stochastic process enhances cost reduction while maintaining customer satisfaction. The benefits of the two proposed methods are showcased against two baselines over a 22-day simulation using a real-world dataset. The two-stage approach proves robust against early disconnections, considering a more
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08621</link><description>&lt;p&gt;
&#19968;&#31181;&#24191;&#20041;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Generalized Approach to Online Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08621
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#29992;&#20110;&#20855;&#26377;&#23436;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#30340;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#30340;&#31639;&#27861;&#37117;&#26159;&#29992;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20219;&#20309;&#38656;&#35201;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#31639;&#27861;&#37117;&#21487;&#20197;&#36716;&#21270;&#20026;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#30340;&#21322;&#21305;&#37197;&#21453;&#39304;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20351;&#29992;&#30830;&#23450;&#24615;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#35774;&#35745;&#30340;&#31639;&#27861;&#22312;&#38754;&#23545;&#26080;&#30693;&#23545;&#25163;&#26102;&#21487;&#20197;&#20351;&#29992;&#21482;&#26377;&#38543;&#26426;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#31639;&#27861;&#33719;&#24471;&#30456;&#20284;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#25551;&#36848;&#20102;&#23558;&#19968;&#38454;&#31639;&#27861;&#36716;&#21270;&#20026;&#38646;&#38454;&#31639;&#27861;&#30340;&#36890;&#29992;&#20803;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#20998;&#26512;&#21508;&#31181;&#35774;&#32622;&#20013;&#30340;&#22312;&#32447;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#20840;&#20449;&#24687;&#21453;&#39304;&#12289;&#21322;&#21305;&#37197;&#21453;&#39304;&#12289;&#38543;&#26426;&#36951;&#25022;&#12289;&#23545;&#25239;&#36951;&#25022;&#21644;&#21508;&#31181;&#24418;&#24335;&#30340;&#38750;&#24179;&#31283;&#36951;&#25022;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#26524;&#65292;
&lt;/p&gt;
&lt;p&gt;
In this paper, we analyze the problem of online convex optimization in different settings. We show that any algorithm for online linear optimization with fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, such full-information feedback, bandit feedback, stochastic regret, adversarial regret and various forms of non-stationary regret. Using our analysis, we provide
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#65288;UoT&#65289;&#31639;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#27169;&#25311;&#26410;&#26469;&#22330;&#26223;&#12289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#21644;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20248;&#21270;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2402.03271</link><description>&lt;p&gt;
&#24819;&#27861;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24687;&#25628;&#32034;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03271
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#65288;UoT&#65289;&#31639;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#27169;&#25311;&#26410;&#26469;&#22330;&#26223;&#12289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#21644;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20248;&#21270;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#27604;&#22914;&#21307;&#23398;&#35786;&#26029;&#21644;&#25925;&#38556;&#25490;&#38500;&#65292;&#35299;&#20915;&#20219;&#21153;&#25152;&#38656;&#30340;&#20449;&#24687;&#19981;&#26159;&#21021;&#22987;&#32473;&#23450;&#30340;&#65292;&#32780;&#38656;&#35201;&#36890;&#36807;&#35810;&#38382;&#21518;&#32493;&#38382;&#39064;&#26469;&#20027;&#21160;&#23547;&#27714;&#65288;&#20363;&#22914;&#65292;&#21307;&#29983;&#21521;&#24739;&#32773;&#35810;&#38382;&#30151;&#29366;&#30340;&#26356;&#22810;&#32454;&#33410;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24605;&#24819;&#30340;&#19981;&#30830;&#23450;&#24615;&#65288;UoT&#65289;&#65292;&#19968;&#31181;&#31639;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#19982;&#20027;&#21160;&#25552;&#38382;&#20449;&#24687;&#30340;&#33021;&#21147;&#30456;&#32467;&#21512;&#12290;UoT&#32467;&#21512;&#20102;1&#65289;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#20223;&#30495;&#26041;&#27861;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#27169;&#25311;&#21487;&#33021;&#30340;&#26410;&#26469;&#22330;&#26223;&#65292;&#24182;&#20272;&#35745;&#20854;&#21457;&#29983;&#30340;&#21487;&#33021;&#24615;&#65307;2&#65289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#65292;&#28608;&#21169;&#27169;&#22411;&#23547;&#27714;&#20449;&#24687;&#65307;3&#65289;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20197;&#26368;&#22823;&#21270;&#39044;&#26399;&#22870;&#21169;&#30340;&#26041;&#24335;&#36873;&#25321;&#26368;&#20339;&#30340;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;&#22312;&#21307;&#23398;&#35786;&#26029;&#12289;&#25925;&#38556;&#25490;&#38500;&#21644;'20&#30340;&#23454;&#39564;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the face of uncertainty, the ability to seek information is of fundamental importance. In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms). In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions. UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertainty-based rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. In experiments on medical diagnosis, troubleshooting and the '20 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#21487;&#25509;&#21463;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.02549</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#36866;&#21512;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are Large Language Models Table-based Fact-Checkers?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#21487;&#25509;&#21463;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#39564;&#35777;&#65288;TFV&#65289;&#26088;&#22312;&#25552;&#21462;&#35821;&#21477;&#21644;&#32467;&#26500;&#21270;&#34920;&#26684;&#20043;&#38388;&#30340;&#34164;&#28085;&#20851;&#31995;&#12290;&#29616;&#26377;&#22522;&#20110;&#23567;&#35268;&#27169;&#27169;&#22411;&#30340;TFV&#26041;&#27861;&#22312;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#21644;&#38646;&#26679;&#26412;&#33021;&#21147;&#34180;&#24369;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#30740;&#31350;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#23427;&#20204;&#22312;&#20960;&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#38646;&#26679;&#26412;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;TFV&#39046;&#22495;&#30340;&#28508;&#21147;&#36824;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20851;&#20110;LLMs&#26159;&#21542;&#36866;&#21512;&#20316;&#20026;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#22120;&#30340;&#21021;&#27493;&#30740;&#31350;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22810;&#26679;&#21270;&#30340;&#25552;&#31034;&#35821;&#26469;&#25506;&#32034;&#19978;&#19979;&#25991;&#23398;&#20064;&#22914;&#20309;&#24110;&#21161;LLMs&#22312;TFV&#26041;&#38754;&#65292;&#21363;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;TFV&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#31934;&#24515;&#35774;&#35745;&#21644;&#26500;&#24314;&#20102;TFV&#25351;&#23548;&#20197;&#30740;&#31350;LLMs&#30340;&#25351;&#23548;&#35843;&#25972;&#24102;&#26469;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;LLMs&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;TFV&#26041;&#38754;&#21487;&#20197;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#32467;&#26524;&#65292;&#32780;&#25351;&#23548;&#35843;&#25972;&#21017;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Table-based Fact Verification (TFV) aims to extract the entailment relation between statements and structured tables. Existing TFV methods based on small-scaled models suffer from insufficient labeled data and weak zero-shot ability. Recently, the appearance of Large Language Models (LLMs) has gained lots of attraction in research fields. They have shown powerful zero-shot and in-context learning abilities on several NLP tasks, but their potential on TFV is still unknown. In this work, we implement a preliminary study about whether LLMs are table-based fact-checkers. In detail, we design diverse prompts to explore how the in-context learning can help LLMs in TFV, i.e., zero-shot and few-shot TFV capability. Besides, we carefully design and construct TFV instructions to study the performance gain brought by the instruction tuning of LLMs. Experimental results demonstrate that LLMs can achieve acceptable results on zero-shot and few-shot TFV with prompt engineering, while instruction-tun
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26500;&#24314;$\lambda$-&#20998;&#25968;&#20840;&#21516;&#32500;&#25968;&#65292;&#23454;&#29616;&#20102;&#26641;&#37325;&#26032;&#21152;&#26435;&#21644;&#20449;&#24565;&#20256;&#25773;&#31639;&#27861;&#20043;&#38388;&#30340;&#25554;&#20540;&#65292;&#30830;&#20445;&#22312;&#38081;&#30913;&#24615;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#8220;&#31934;&#30830;&#8221;$\lambda_*$&#20351;&#24471;&#35745;&#31639;&#30340;&#37197;&#20998;&#20989;&#25968;$Z=Z^{(\lambda_*)}$&#12290;</title><link>https://arxiv.org/abs/2301.10369</link><description>&lt;p&gt;
&#31934;&#30830;&#20998;&#25968;&#25512;&#26029;&#65306;&#37325;&#26032;&#21442;&#25968;&#21270;&#21450;&#26641;&#37325;&#26032;&#21152;&#26435;&#21644;&#20449;&#24565;&#20256;&#25773;&#31639;&#27861;&#20043;&#38388;&#30340;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Exact Fractional Inference via Re-Parametrization &amp; Interpolation between Tree-Re-Weighted- and Belief Propagation- Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.10369
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26500;&#24314;$\lambda$-&#20998;&#25968;&#20840;&#21516;&#32500;&#25968;&#65292;&#23454;&#29616;&#20102;&#26641;&#37325;&#26032;&#21152;&#26435;&#21644;&#20449;&#24565;&#20256;&#25773;&#31639;&#27861;&#20043;&#38388;&#30340;&#25554;&#20540;&#65292;&#30830;&#20445;&#22312;&#38081;&#30913;&#24615;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#8220;&#31934;&#30830;&#8221;$\lambda_*$&#20351;&#24471;&#35745;&#31639;&#30340;&#37197;&#20998;&#20989;&#25968;$Z=Z^{(\lambda_*)}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#26029;&#24037;&#20316;--&#35745;&#31639;Ising&#27169;&#22411;&#22312;N&#20010;&#8220;&#33258;&#26059;&#8221;&#32452;&#25104;&#30340;&#22270;&#19978;&#30340;&#37197;&#20998;&#20989;&#25968;$Z$&#25152;&#38656;&#30340;&#24037;&#20316;--&#24456;&#21487;&#33021;&#38543;&#30528;N&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#39640;&#25928;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#22914;&#20449;&#24565;&#20256;&#25773;&#65288;BP&#65289;&#21644;&#26641;&#37325;&#26032;&#21152;&#26435;&#65288;TRW&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#26368;&#23567;&#21270;&#21508;&#33258;&#65288;BP&#25110;TRW&#65289;&#33258;&#30001;&#33021;&#30340;$Z$&#26469;&#36817;&#20284;&#35745;&#31639;$Z$&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;$\lambda$-&#20998;&#25968;&#20840;&#21516;&#32500;&#25968;&#65292;$Z^{(\lambda)}$&#65292;&#20854;&#20013;$\lambda=0$&#21644;$\lambda=1$&#20998;&#21035;&#23545;&#24212;&#20110;TRW&#21644;BP&#30340;&#36817;&#20284;&#65292;&#19988;$Z^{(\lambda)}$&#38543;$\lambda$&#21333;&#35843;&#20943;&#23569;&#12290;&#27492;&#22806;&#65292;&#36825;&#31181;&#20998;&#25968;&#26041;&#26696;&#20445;&#35777;&#22312;&#21560;&#24341;&#21147;&#65288;&#38081;&#30913;&#24615;&#65289;&#24773;&#20917;&#19979;$Z^{(TRW)}\geq Z^{(\lambda)}\geq Z^{(BP)}$&#65292;&#24182;&#19988;&#23384;&#22312;&#19968;&#20010;&#21807;&#19968;&#30340;&#65288;&#8220;&#31934;&#30830;&#8221;&#65289;$\lambda_*$&#65292;&#20351;&#24471;$Z=Z^{(\lambda_*)}$&#12290;&#36890;&#36807;&#25512;&#24191;\citep {wainwright_tree-based_2002}&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#26041;&#27861;&#21644;\citep {chertkov_loop_2006}&#30340;&#29615;&#32423;&#25968;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36827;&#34892;e
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.10369v2 Announce Type: replace  Abstract: Inference efforts -- required to compute partition function, $Z$, of an Ising model over a graph of $N$ ``spins" -- are most likely exponential in $N$. Efficient variational methods, such as Belief Propagation (BP) and Tree Re-Weighted (TRW) algorithms, compute $Z$ approximately minimizing respective (BP- or TRW-) free energy. We generalize the variational scheme building a $\lambda$-fractional-homotopy, $Z^{(\lambda)}$, where $\lambda=0$ and $\lambda=1$ correspond to TRW- and BP-approximations, respectively, and $Z^{(\lambda)}$ decreases with $\lambda$ monotonically. Moreover, this fractional scheme guarantees that in the attractive (ferromagnetic) case $Z^{(TRW)}\geq Z^{(\lambda)}\geq Z^{(BP)}$, and there exists a unique (``exact") $\lambda_*$ such that, $Z=Z^{(\lambda_*)}$. Generalizing the re-parametrization approach of \citep{wainwright_tree-based_2002} and the loop series approach of \citep{chertkov_loop_2006}, we show how to e
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#27010;&#29575;&#22522;&#20934;&#65292;&#29992;&#20110;&#27604;&#36739;AI&#22825;&#27668;&#27169;&#22411;&#30340;&#27010;&#29575;&#25216;&#33021;&#12290;&#36890;&#36807;&#20351;&#29992;&#28382;&#21518;&#38598;&#21512;&#65292;&#21487;&#20197;&#23454;&#29616;&#23545;&#22810;&#20010;&#27169;&#22411;&#30340;&#27604;&#36739;&#65292;&#24182;&#19982;&#25805;&#20316;&#22522;&#20934;&#36827;&#34892;&#23545;&#27604;&#12290;</title><link>http://arxiv.org/abs/2401.15305</link><description>&lt;p&gt;
AI&#22825;&#27668;&#27169;&#22411;&#30340;&#23454;&#29992;&#27010;&#29575;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
A Practical Probabilistic Benchmark for AI Weather Models. (arXiv:2401.15305v1 [physics.ao-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15305
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#27010;&#29575;&#22522;&#20934;&#65292;&#29992;&#20110;&#27604;&#36739;AI&#22825;&#27668;&#27169;&#22411;&#30340;&#27010;&#29575;&#25216;&#33021;&#12290;&#36890;&#36807;&#20351;&#29992;&#28382;&#21518;&#38598;&#21512;&#65292;&#21487;&#20197;&#23454;&#29616;&#23545;&#22810;&#20010;&#27169;&#22411;&#30340;&#27604;&#36739;&#65292;&#24182;&#19982;&#25805;&#20316;&#22522;&#20934;&#36827;&#34892;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22825;&#27668;&#30340;&#28151;&#27788;&#24615;&#36136;&#65292;&#22825;&#27668;&#39044;&#25253;&#26088;&#22312;&#39044;&#27979;&#26410;&#26469;&#29366;&#24577;&#30340;&#20998;&#24067;&#32780;&#19981;&#26159;&#20570;&#20986;&#21333;&#20010;&#39044;&#27979;&#12290;&#26368;&#36817;&#65292;&#20986;&#29616;&#20102;&#22810;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#22825;&#27668;&#27169;&#22411;&#65292;&#22768;&#31216;&#22312;&#25216;&#26415;&#19978;&#21462;&#24471;&#20102;&#31361;&#30772;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22823;&#22810;&#20351;&#29992;&#30830;&#23450;&#24615;&#25216;&#33021;&#35780;&#20998;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#23545;&#23427;&#20204;&#30340;&#27010;&#29575;&#25216;&#33021;&#30693;&#20043;&#29978;&#23569;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22312;&#27010;&#29575;&#24847;&#20041;&#19978;&#20844;&#24179;&#27604;&#36739;AI&#22825;&#27668;&#27169;&#22411;&#26159;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#38598;&#21512;&#21021;&#22987;&#21270;&#30340;&#36873;&#25321;&#12289;&#29366;&#24577;&#23450;&#20041;&#21644;&#22122;&#22768;&#27880;&#20837;&#26041;&#27861;&#30340;&#21464;&#21270;&#20250;&#20135;&#29983;&#28151;&#28102;&#12290;&#27492;&#22806;&#65292;&#32771;&#34385;&#21040;&#25152;&#28041;&#21450;&#30340;&#25968;&#25454;&#37327;&#65292;&#21363;&#20351;&#26159;&#33719;&#24471;&#38598;&#21512;&#39044;&#25253;&#30340;&#22522;&#32447;&#20063;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#24037;&#31243;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#20960;&#21313;&#24180;&#21069;&#30340;&#27010;&#24565; - &#28382;&#21518;&#38598;&#21512;&#65292;&#36890;&#36807;&#19968;&#20010;&#36866;&#24230;&#35268;&#27169;&#30340;&#30830;&#23450;&#24615;&#39044;&#27979;&#24211;&#26500;&#24314;&#38598;&#21512;&#12290;&#36825;&#20801;&#35768;&#23545;&#39046;&#20808;&#30340;AI&#22825;&#27668;&#27169;&#22411;&#30340;&#27010;&#29575;&#25216;&#33021;&#36827;&#34892;&#31532;&#19968;&#20010;&#26080;&#21442;&#25968;&#27604;&#36739;&#65292;&#24182;&#19982;&#25805;&#20316;&#22522;&#20934;&#36827;&#34892;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since the weather is chaotic, forecasts aim to predict the distribution of future states rather than make a single prediction. Recently, multiple data driven weather models have emerged claiming breakthroughs in skill. However, these have mostly been benchmarked using deterministic skill scores, and little is known about their probabilistic skill. Unfortunately, it is hard to fairly compare AI weather models in a probabilistic sense, since variations in choice of ensemble initialization, definition of state, and noise injection methodology become confounding. Moreover, even obtaining ensemble forecast baselines is a substantial engineering challenge given the data volumes involved. We sidestep both problems by applying a decades-old idea -- lagged ensembles -- whereby an ensemble can be constructed from a moderately-sized library of deterministic forecasts. This allows the first parameter-free intercomparison of leading AI weather models' probabilistic skill against an operational base
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10545</link><description>&lt;p&gt;
&#20248;&#21270;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#19982;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;
&lt;/p&gt;
&lt;p&gt;
Optimal vintage factor analysis with deflation varimax. (arXiv:2310.10545v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#26088;&#22312;&#39318;&#20808;&#25214;&#21040;&#21407;&#22987;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#23547;&#27714;&#26059;&#36716;&#65292;&#20351;&#26059;&#36716;&#21518;&#30340;&#20302;&#32500;&#34920;&#31034;&#20855;&#26377;&#31185;&#23398;&#24847;&#20041;&#12290;&#23613;&#31649;Principal Component Analysis (PCA) followed by the varimax rotation&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#65292;&#20294;&#30001;&#20110;varimax rotation&#38656;&#35201;&#22312;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#19978;&#35299;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22240;&#27492;&#24456;&#38590;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#34892;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#30340;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#36807;&#31243;&#12290;&#38500;&#20102;&#22312;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#21644;&#28789;&#27963;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#33021;&#22312;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#23545;&#25152;&#25552;&#20986;&#30340;&#36807;&#31243;&#36827;&#34892;&#23436;&#20840;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;PCA&#20043;&#21518;&#37319;&#29992;&#36825;&#31181;&#26032;&#30340;varimax&#26041;&#27861;&#20316;&#20026;&#31532;&#20108;&#27493;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#36825;&#20010;&#20004;&#27493;&#36807;&#31243;&#22312;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#22240;&#23376;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. Perhaps the most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.  In this paper, we propose a deflation varimax procedure that solves each row of an orthogonal matrix sequentially. In addition to its net computational gain and flexibility, we are able to fully establish theoretical guarantees for the proposed procedure in a broad context.  Adopting this new varimax approach as the second step after PCA, we further analyze this two step procedure under a general class of factor models. Our resul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38750;Lipschitz&#20989;&#25968;&#20248;&#21270;&#38382;&#39064;&#30340;&#36817;&#31471;&#27425;&#26799;&#24230;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#36882;&#24402;&#20851;&#31995;&#29992;&#20110; Moreau&#21253;&#32476;&#30340;&#24314;&#31435;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#38543;&#26426;&#27425;&#26799;&#24230;&#19978;&#30028;&#26465;&#20214;&#65292;&#24182;&#20998;&#26512;&#20102;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.16362</link><description>&lt;p&gt;
&#35299;&#20915;&#22797;&#21512;&#38750;&#20984;&#38750;&#20809;&#28369;&#38750;Lipschitz&#20989;&#25968;&#30340;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#32479;&#19968;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Unified Analysis for the Subgradient Methods Minimizing Composite Nonconvex, Nonsmooth and Non-Lipschitz Functions. (arXiv:2308.16362v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38750;Lipschitz&#20989;&#25968;&#20248;&#21270;&#38382;&#39064;&#30340;&#36817;&#31471;&#27425;&#26799;&#24230;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#36882;&#24402;&#20851;&#31995;&#29992;&#20110; Moreau&#21253;&#32476;&#30340;&#24314;&#31435;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#38543;&#26426;&#27425;&#26799;&#24230;&#19978;&#30028;&#26465;&#20214;&#65292;&#24182;&#20998;&#26512;&#20102;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#30340;&#36817;&#31471;&#27425;&#26799;&#24230;&#26041;&#27861;(Prox-SubGrad)&#65292;&#32780;&#26080;&#38656;&#20551;&#35774;Lipschitz&#36830;&#32493;&#24615;&#26465;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#27425;&#26799;&#24230;&#19978;&#30028;&#21450;&#20854;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#36825;&#20123;&#19978;&#30028;&#26465;&#20214;&#24314;&#31435;&#20102;&#24369;&#20984;&#20248;&#21270;Moreau&#21253;&#32476;&#30340;&#19968;&#20123;&#32479;&#19968;&#36882;&#24402;&#20851;&#31995;&#12290;&#36825;&#31181;&#32479;&#19968;&#26041;&#26696;&#31616;&#21270;&#24182;&#32479;&#19968;&#20102;&#24314;&#31435;Prox-SubGrad&#25910;&#25947;&#36895;&#29575;&#30340;&#35777;&#26126;&#26041;&#26696;&#65292;&#32780;&#26080;&#38656;&#20551;&#35774;Lipschitz&#36830;&#32493;&#24615;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#38543;&#26426;&#27425;&#26799;&#24230;&#19978;&#30028;&#26465;&#20214;&#65292;&#24182;&#20026;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;(Sto-SubGrad)&#35299;&#20915;&#38750;Lipschitz&#38750;&#20809;&#28369;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#24314;&#31435;&#20102;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#30340;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#26080;&#38656;Lipschitz&#36830;&#32493;&#24615;&#30340;&#24369;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we propose a proximal subgradient method (Prox-SubGrad) for solving nonconvex and nonsmooth optimization problems without assuming Lipschitz continuity conditions. A number of subgradient upper bounds and their relationships are presented. By means of these upper bounding conditions, we establish some uniform recursive relations for the Moreau envelopes for weakly convex optimization. This uniform scheme simplifies and unifies the proof schemes to establish rate of convergence for Prox-SubGrad without assuming Lipschitz continuity. We present a novel convergence analysis in this context. Furthermore, we propose some new stochastic subgradient upper bounding conditions and establish convergence and iteration complexity rates for the stochastic subgradient method (Sto-SubGrad) to solve non-Lipschitz and nonsmooth stochastic optimization problems. In particular, for both deterministic and stochastic subgradient methods on weakly convex optimization problems without Lipschitz
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#25512;&#21160;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#31934;&#32454;&#35821;&#35328;&#65292;&#20316;&#32773;&#26500;&#24314;&#20102;WhyShift&#23454;&#39564;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;$Y|X$-&#20559;&#31227;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.05284</link><description>&lt;p&gt;
&#20851;&#20110;&#38656;&#35201;&#25551;&#36848;&#20998;&#24067;&#20559;&#31227;&#30340;&#35821;&#35328;&#65306;&#22522;&#20110;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#26696;&#20363;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets. (arXiv:2307.05284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05284
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#25512;&#21160;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#31934;&#32454;&#35821;&#35328;&#65292;&#20316;&#32773;&#26500;&#24314;&#20102;WhyShift&#23454;&#39564;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;$Y|X$-&#20559;&#31227;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#20998;&#24067;&#20559;&#31227;&#38656;&#35201;&#19981;&#21516;&#30340;&#31639;&#27861;&#21644;&#25805;&#20316;&#24178;&#39044;&#12290;&#26041;&#27861;&#30740;&#31350;&#24517;&#39035;&#20197;&#20854;&#25152;&#28041;&#21450;&#30340;&#20855;&#20307;&#20559;&#31227;&#20026;&#22522;&#30784;&#12290;&#23613;&#31649;&#26032;&#20852;&#30340;&#22522;&#20934;&#25968;&#25454;&#20026;&#23454;&#35777;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#22522;&#30784;&#65292;&#20294;&#23427;&#20204;&#38544;&#21547;&#22320;&#20851;&#27880;&#21327;&#21464;&#37327;&#20559;&#31227;&#65292;&#24182;&#19988;&#23454;&#35777;&#21457;&#29616;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20559;&#31227;&#31867;&#22411;&#65292;&#20363;&#22914;&#65292;&#24403;$Y|X$&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#20043;&#21069;&#20851;&#20110;&#31639;&#27861;&#24615;&#33021;&#30340;&#35266;&#23519;&#21487;&#33021;&#26080;&#25928;&#12290;&#25105;&#20204;&#23545;5&#20010;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#36890;&#36807;&#23545;86,000&#20010;&#27169;&#22411;&#37197;&#32622;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#40723;&#21169;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#19968;&#31181;&#31934;&#32454;&#30340;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#35821;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;WhyShift&#65292;&#19968;&#20010;&#30001;&#31574;&#21010;&#30340;&#30495;&#23454;&#19990;&#30028;&#20559;&#31227;&#27979;&#35797;&#24179;&#21488;&#65292;&#22312;&#20854;&#20013;&#25105;&#20204;&#23545;&#25105;&#20204;&#22522;&#20934;&#24615;&#33021;&#30340;&#20559;&#31227;&#31867;&#22411;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#30001;&#20110;$Y|X$-&#20559;&#31227;&#22312;&#34920;&#26684;&#35774;&#32622;&#20013;&#24456;&#24120;&#35265;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#21463;&#21040;&#26368;&#22823;$Y|X$-&#20559;&#31227;&#24433;&#21709;&#30340;&#21327;&#21464;&#37327;&#21306;&#22495;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithm
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32463;&#20856;&#23398;&#20064;&#32773;&#21644;&#37327;&#23376;&#23398;&#20064;&#32773;&#20043;&#38388;&#30340;&#25351;&#25968;&#21306;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#23398;&#20064;&#20998;&#31163;&#38382;&#39064;&#65292;&#20854;&#20013;&#32463;&#20856;&#22256;&#38590;&#20027;&#35201;&#22312;&#20110;&#35782;&#21035;&#29983;&#25104;&#25968;&#25454;&#30340;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.16028</link><description>&lt;p&gt;
&#32463;&#20856;&#23398;&#20064;&#32773;&#19982;&#37327;&#23376;&#23398;&#20064;&#32773;&#20043;&#38388;&#30340;&#25351;&#25968;&#21306;&#21035;
&lt;/p&gt;
&lt;p&gt;
Exponential separations between classical and quantum learners. (arXiv:2306.16028v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32463;&#20856;&#23398;&#20064;&#32773;&#21644;&#37327;&#23376;&#23398;&#20064;&#32773;&#20043;&#38388;&#30340;&#25351;&#25968;&#21306;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#23398;&#20064;&#20998;&#31163;&#38382;&#39064;&#65292;&#20854;&#20013;&#32463;&#20856;&#22256;&#38590;&#20027;&#35201;&#22312;&#20110;&#35782;&#21035;&#29983;&#25104;&#25968;&#25454;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#22312;&#22788;&#29702;&#32463;&#20856;&#25968;&#25454;&#26102;&#24050;&#32463;&#23637;&#31034;&#20102;&#37327;&#23376;&#23398;&#20064;&#20248;&#21183;&#65292;&#20294;&#22312;&#23547;&#25214;&#37327;&#23376;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#22312;&#32463;&#20856;&#23398;&#20064;&#31639;&#27861;&#19978;&#23454;&#29616;&#21487;&#35777;&#26126;&#25351;&#25968;&#21152;&#36895;&#30340;&#23398;&#20064;&#38382;&#39064;&#26041;&#38754;&#65292;&#20173;&#28982;&#23384;&#22312;&#25361;&#25112;&#12290;&#26412;&#25991;&#35752;&#35770;&#19982;&#27492;&#38382;&#39064;&#30456;&#20851;&#30340;&#35745;&#31639;&#23398;&#20064;&#29702;&#35770;&#27010;&#24565;&#65292;&#24182;&#35752;&#35770;&#23450;&#20041;&#19978;&#30340;&#24494;&#22937;&#24046;&#24322;&#21487;&#33021;&#23548;&#33268;&#23398;&#20064;&#32773;&#38656;&#35201;&#28385;&#36275;&#21644;&#35299;&#20915;&#26174;&#33879;&#19981;&#21516;&#30340;&#35201;&#27714;&#21644;&#20219;&#21153;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#24050;&#26377;&#30340;&#20855;&#26377;&#21487;&#35777;&#26126;&#37327;&#23376;&#21152;&#36895;&#24615;&#36136;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#20027;&#35201;&#20381;&#36182;&#20110;&#35745;&#31639;&#29983;&#25104;&#25968;&#25454;&#30340;&#20989;&#25968;&#30340;&#32463;&#20856;&#38590;&#24230;&#65292;&#32780;&#19981;&#26159;&#35782;&#21035;&#36825;&#20010;&#20989;&#25968;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#23398;&#20064;&#20998;&#31163;&#38382;&#39064;&#65292;&#20854;&#20013;&#32463;&#20856;&#22256;&#38590;&#20027;&#35201;&#22312;&#20110;&#35782;&#21035;&#29983;&#25104;&#25968;&#25454;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite significant effort, the quantum machine learning community has only demonstrated quantum learning advantages for artificial cryptography-inspired datasets when dealing with classical data. In this paper we address the challenge of finding learning problems where quantum learning algorithms can achieve a provable exponential speedup over classical learning algorithms. We reflect on computational learning theory concepts related to this question and discuss how subtle differences in definitions can result in significantly different requirements and tasks for the learner to meet and solve. We examine existing learning problems with provable quantum speedups and find that they largely rely on the classical hardness of evaluating the function that generates the data, rather than identifying it. To address this, we present two new learning separations where the classical difficulty primarily lies in identifying the function generating the data. Furthermore, we explore computational h
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#31639;&#27861;&#34917;&#20607;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#25968;&#25454;&#27969;&#24418;&#20013;&#25552;&#20379;&#29992;&#25143;&#21487;&#20197;&#37319;&#21462;&#30340;&#26041;&#21521;&#26469;&#25913;&#21464;&#20854;&#39044;&#27979;&#32467;&#26524;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#24615;&#12289;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#21644;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2306.15557</link><description>&lt;p&gt;
&#31616;&#21333;&#25104;&#21151;&#30340;&#27493;&#39588;&#65306;&#22522;&#20110;&#36317;&#31163;&#30340;&#31639;&#27861;&#34917;&#20607;&#30340;&#20844;&#29702;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Simple Steps to Success: Axiomatics of Distance-Based Algorithmic Recourse. (arXiv:2306.15557v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15557
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#31639;&#27861;&#34917;&#20607;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#25968;&#25454;&#27969;&#24418;&#20013;&#25552;&#20379;&#29992;&#25143;&#21487;&#20197;&#37319;&#21462;&#30340;&#26041;&#21521;&#26469;&#25913;&#21464;&#20854;&#39044;&#27979;&#32467;&#26524;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#24615;&#12289;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#21644;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25968;&#25454;&#39537;&#21160;&#26694;&#26550;&#65292;&#29992;&#20110;&#31639;&#27861;&#34917;&#20607;&#65292;&#25552;&#20379;&#32473;&#29992;&#25143;&#25913;&#21464;&#20854;&#39044;&#27979;&#32467;&#26524;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#29616;&#26377;&#30340;&#35745;&#31639;&#34917;&#20607;&#26041;&#27861;&#25214;&#21040;&#28385;&#36275;&#26576;&#20123;&#26399;&#26395;&#30340;&#28857;&#38598;&#65292;&#20363;&#22914;&#22312;&#22522;&#30784;&#22240;&#26524;&#22270;&#20013;&#30340;&#24178;&#39044;&#65292;&#25110;&#32773;&#26368;&#23567;&#21270;&#20195;&#20215;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#28385;&#36275;&#36825;&#20123;&#26631;&#20934;&#38656;&#35201;&#23545;&#22522;&#30784;&#27169;&#22411;&#32467;&#26500;&#26377;&#24191;&#27867;&#30340;&#20102;&#35299;&#65292;&#22312;&#20960;&#20010;&#39046;&#22495;&#20013;&#24448;&#24448;&#38656;&#35201;&#22823;&#37327;&#30340;&#19981;&#20999;&#23454;&#38469;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#12289;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#34917;&#20607;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#25968;&#25454;&#27969;&#24418;&#20013;&#25552;&#20379;&#29992;&#25143;&#21487;&#20197;&#37319;&#21462;&#30340;&#26041;&#21521;&#26469;&#25913;&#21464;&#20854;&#39044;&#27979;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#29702;&#21270;&#21512;&#29702;&#21270;&#30340;&#26041;&#27861;&#65292;Stepwise Explainable Paths (StEP)&#65292;&#29992;&#20110;&#35745;&#31639;&#22522;&#20110;&#26041;&#21521;&#30340;&#31639;&#27861;&#34917;&#20607;&#12290;&#25105;&#20204;&#23545;StEP&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#23454;&#35777;&#21644;&#29702;&#35770;&#30740;&#31350;&#12290;StEP&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#21644;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#24182;&#22312;&#20960;&#20010;&#24050;&#24314;&#31435;&#30340;&#34917;&#20607;&#26041;&#27861;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel data-driven framework for algorithmic recourse that offers users interventions to change their predicted outcome. Existing approaches to compute recourse find a set of points that satisfy some desiderata -- e.g. an intervention in the underlying causal graph, or minimizing a cost function. Satisfying these criteria, however, requires extensive knowledge of the underlying model structure, often an unrealistic amount of information in several domains. We propose a data-driven, computationally efficient approach to computing algorithmic recourse. We do so by suggesting directions in the data manifold that users can take to change their predicted outcome. We present Stepwise Explainable Paths (StEP), an axiomatically justified framework to compute direction-based algorithmic recourse. We offer a thorough empirical and theoretical investigation of StEP. StEP offers provable privacy and robustness guarantees, and outperforms the state-of-the-art on several established reco
&lt;/p&gt;</description></item><item><title>V-LoL&#26159;&#19968;&#20010;&#32467;&#21512;&#35270;&#35273;&#21644;&#36923;&#36753;&#25361;&#25112;&#30340;&#35786;&#26029;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;V-LoL-Trains&#65292;&#35813;&#25968;&#25454;&#38598;&#39318;&#27425;&#23558;&#22797;&#26434;&#30340;&#35270;&#35273;&#22330;&#26223;&#21644;&#28789;&#27963;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#32467;&#21512;&#36215;&#26469;&#65292;&#20026;&#30740;&#31350;&#24191;&#27867;&#30340;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25361;&#25112;&#25552;&#20379;&#20102;&#24179;&#21488;&#12290;</title><link>http://arxiv.org/abs/2306.07743</link><description>&lt;p&gt;
V-LoL: &#19968;&#31181;&#29992;&#20110;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#30340;&#35786;&#26029;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
V-LoL: A Diagnostic Dataset for Visual Logical Learning. (arXiv:2306.07743v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07743
&lt;/p&gt;
&lt;p&gt;
V-LoL&#26159;&#19968;&#20010;&#32467;&#21512;&#35270;&#35273;&#21644;&#36923;&#36753;&#25361;&#25112;&#30340;&#35786;&#26029;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;V-LoL-Trains&#65292;&#35813;&#25968;&#25454;&#38598;&#39318;&#27425;&#23558;&#22797;&#26434;&#30340;&#35270;&#35273;&#22330;&#26223;&#21644;&#28789;&#27963;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#32467;&#21512;&#36215;&#26469;&#65292;&#20026;&#30740;&#31350;&#24191;&#27867;&#30340;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25361;&#25112;&#25552;&#20379;&#20102;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36817;&#26399;&#22312;&#35270;&#35273;AI&#39046;&#22495;&#26377;&#20102;&#35768;&#22810;&#25104;&#21151;&#30340;&#36827;&#23637;&#65292;&#20294;&#20173;&#23384;&#22312;&#19981;&#21516;&#30340;&#32570;&#28857;&#65307;&#21253;&#25324;&#32570;&#23569;&#31934;&#30830;&#30340;&#36923;&#36753;&#25512;&#29702;&#12289;&#25277;&#35937;&#30340;&#27010;&#25324;&#33021;&#21147;&#20197;&#21450;&#29702;&#35299;&#22797;&#26434;&#21644;&#22024;&#26434;&#30340;&#22330;&#26223;&#31561;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#24182;&#19981;&#33021;&#25429;&#25417;&#21040;&#36825;&#20123;&#26041;&#38754;&#20013;&#30340;&#22810;&#25968;&#12290;&#28145;&#24230;&#23398;&#20064;&#25968;&#25454;&#38598;&#20851;&#27880;&#35270;&#35273;&#22797;&#26434;&#25968;&#25454;&#20294;&#21482;&#26377;&#31616;&#21333;&#30340;&#35270;&#35273;&#25512;&#29702;&#20219;&#21153;&#65292;&#24402;&#32435;&#36923;&#36753;&#25968;&#25454;&#38598;&#21253;&#25324;&#22797;&#26434;&#30340;&#36923;&#36753;&#23398;&#20064;&#20219;&#21153;&#65292;&#20294;&#26159;&#32570;&#20047;&#35270;&#35273;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25968;&#25454;&#38598;V-LoL&#65292;&#23427;&#26080;&#32541;&#22320;&#32467;&#21512;&#20102;&#35270;&#35273;&#21644;&#36923;&#36753;&#30340;&#25361;&#25112;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#39318;&#27425;&#25512;&#20986;&#20102;V-LoL&#30340;&#31532;&#19968;&#20010;&#23454;&#20363;&#65292;&#21517;&#20026;V-LoL-Trains&#65292;&#23427;&#26159;&#31526;&#21495;AI&#20013;&#19968;&#20010;&#32463;&#20856;&#22522;&#20934;&#27979;&#35797;&#30340;&#35270;&#35273;&#21576;&#29616;&#65292;&#21363;Michalski&#28779;&#36710;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#20869;&#32467;&#21512;&#22797;&#26434;&#30340;&#35270;&#35273;&#22330;&#26223;&#21644;&#28789;&#27963;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#65292;V-LoL-Trains&#20026;&#30740;&#31350;&#24191;&#27867;&#30340;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25361;&#25112;&#25552;&#20379;&#20102;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the successes of recent developments in visual AI, different shortcomings still exist; from missing exact logical reasoning, to abstract generalization abilities, to understanding complex and noisy scenes. Unfortunately, existing benchmarks, were not designed to capture more than a few of these aspects. Whereas deep learning datasets focus on visually complex data but simple visual reasoning tasks, inductive logic datasets involve complex logical learning tasks, however, lack the visual component. To address this, we propose the visual logical learning dataset, V-LoL, that seamlessly combines visual and logical challenges. Notably, we introduce the first instantiation of V-LoL, V-LoL-Trains, -- a visual rendition of a classic benchmark in symbolic AI, the Michalski train problem. By incorporating intricate visual scenes and flexible logical reasoning tasks within a versatile framework, V-LoL-Trains provides a platform for investigating a wide range of visual logical learning ch
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#23545;&#25239;&#24615;&#20027;&#23548;&#36755;&#20837;&#65288;ADIs&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#20856;&#22411;VFL&#31995;&#32479;&#20013;&#30340;&#23384;&#22312;&#12290;&#35813;&#30740;&#31350;&#20026;&#38450;&#27490;ADIs&#30340;&#20351;&#29992;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2201.02775</link><description>&lt;p&gt;
ADI: &#22312;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#23545;&#25239;&#24615;&#20027;&#23548;&#36755;&#20837;
&lt;/p&gt;
&lt;p&gt;
ADI: Adversarial Dominating Inputs in Vertical Federated Learning Systems. (arXiv:2201.02775v3 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#23545;&#25239;&#24615;&#20027;&#23548;&#36755;&#20837;&#65288;ADIs&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#20856;&#22411;VFL&#31995;&#32479;&#20013;&#30340;&#23384;&#22312;&#12290;&#35813;&#30740;&#31350;&#20026;&#38450;&#27490;ADIs&#30340;&#20351;&#29992;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#65288;VFL&#65289;&#31995;&#32479;&#20316;&#20026;&#22788;&#29702;&#20998;&#25955;&#22312;&#35768;&#22810;&#20010;&#20307;&#26469;&#28304;&#20013;&#30340;&#25968;&#25454;&#30340;&#27010;&#24565;&#32780;&#21464;&#24471;&#31361;&#20986;&#65292;&#26080;&#38656;&#23558;&#20854;&#38598;&#20013;&#21270;&#12290;&#22810;&#20010;&#21442;&#19982;&#32773;&#20197;&#38544;&#31169;&#24847;&#35782;&#30340;&#26041;&#24335;&#21327;&#20316;&#35757;&#32451;&#22522;&#20110;&#20854;&#26412;&#22320;&#25968;&#25454;&#30340;&#27169;&#22411;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;VFL&#24050;&#25104;&#20026;&#22312;&#32452;&#32455;&#20043;&#38388;&#23433;&#20840;&#23398;&#20064;&#27169;&#22411;&#30340;&#20107;&#23454;&#35299;&#20915;&#26041;&#26696;&#65292;&#20801;&#35768;&#20849;&#20139;&#30693;&#35782;&#32780;&#19981;&#24433;&#21709;&#20219;&#20309;&#20010;&#20154;&#30340;&#38544;&#31169;&#12290;&#23613;&#31649;VFL&#31995;&#32479;&#30340;&#21457;&#23637;&#26124;&#30427;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#26576;&#20123;&#21442;&#19982;&#32773;&#30340;&#36755;&#20837;&#65292;&#31216;&#20026;&#23545;&#25239;&#24615;&#20027;&#23548;&#36755;&#20837;&#65288;ADIs&#65289;&#65292;&#21487;&#20197;&#25903;&#37197;&#20849;&#21516;&#25512;&#26029;&#26397;&#30528;&#23545;&#25163;&#30340;&#24847;&#24895;&#26041;&#21521;&#24182;&#36843;&#20351;&#20854;&#20182;&#65288;&#21463;&#23475;&#32773;&#65289;&#21442;&#19982;&#32773;&#20570;&#20986;&#24494;&#19981;&#36275;&#36947;&#30340;&#36129;&#29486;&#65292;&#22833;&#21435;&#36890;&#24120;&#22312;&#32852;&#37030;&#23398;&#20064;&#22330;&#26223;&#20013;&#25552;&#20379;&#30340;&#23545;&#20854;&#36129;&#29486;&#37325;&#35201;&#24615;&#30340;&#22870;&#21169;&#12290;&#25105;&#20204;&#23545;ADIs&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#65292;&#39318;&#20808;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#20856;&#22411;&#30340;VFL&#31995;&#32479;&#20013;&#30340;&#23384;&#22312;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Vertical federated learning (VFL) system has recently become prominent as a concept to process data distributed across many individual sources without the need to centralize it. Multiple participants collaboratively train models based on their local data in a privacy-aware manner. To date, VFL has become a de facto solution to securely learn a model among organizations, allowing knowledge to be shared without compromising privacy of any individuals. Despite the prosperous development of VFL systems, we find that certain inputs of a participant, named adversarial dominating inputs (ADIs), can dominate the joint inference towards the direction of the adversary's will and force other (victim) participants to make negligible contributions, losing rewards that are usually offered regarding the importance of their contributions in federated learning scenarios. We conduct a systematic study on ADIs by first proving their existence in typical VFL systems. We then propose gradient-based methods
&lt;/p&gt;</description></item></channel></rss>