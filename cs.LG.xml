<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;</title><link>https://arxiv.org/abs/2404.01903</link><description>&lt;p&gt;
&#22312;CodeLLMs&#20013;&#23454;&#29616;&#31867;&#22411;&#39044;&#27979;&#30340;&#40065;&#26834;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Activation Steering for Robust Type Prediction in CodeLLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01903
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#22312;&#20195;&#30721;&#19978;&#30340;&#29616;&#20195;LLMs&#33021;&#22815;&#25104;&#21151;&#22320;&#23436;&#25104;&#21508;&#31181;&#32534;&#31243;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#23545;&#35821;&#27861;&#29305;&#24449;&#38750;&#24120;&#25935;&#24863;&#65292;&#20363;&#22914;&#21464;&#37327;&#21644;&#31867;&#22411;&#30340;&#21517;&#31216;&#12289;&#20195;&#30721;&#32467;&#26500;&#20197;&#21450;&#31867;&#22411;&#25552;&#31034;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25512;&#29702;&#26102;&#25216;&#26415;&#65292;&#20351;CodeLLMs&#26356;&#33021;&#25269;&#24481;&#35821;&#27861;&#24178;&#25200;&#22240;&#32032;&#65292;&#36825;&#20123;&#22240;&#32032;&#19982;&#35821;&#20041;&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#28608;&#27963;&#23548;&#21521;&#65292;&#28041;&#21450;&#32534;&#36753;&#20869;&#37096;&#27169;&#22411;&#28608;&#27963;&#20197;&#23558;&#27169;&#22411;&#24341;&#23548;&#21040;&#27491;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#20174;&#31361;&#21464;&#27979;&#35797;&#20013;&#27762;&#21462;&#28789;&#24863;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#26368;&#23567;&#30340;&#30772;&#22351;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#20174;&#20445;&#30041;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#20013;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#36880;&#28176;&#31867;&#22411;&#21270;&#35821;&#35328;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#20219;&#21153;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#32416;&#27491;&#39640;&#36798;90%&#30340;&#31867;&#22411;&#38169;&#35823;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01903v1 Announce Type: new  Abstract: Contemporary LLMs pretrained on code are capable of succeeding at a wide variety of programming tasks. However, their performance is very sensitive to syntactic features, such as the names of variables and types, the structure of code, and presence of type hints. We contribute an inference-time technique to make CodeLLMs more robust to syntactic distractors that are semantically irrelevant. Our methodology relies on activation steering, which involves editing internal model activations to steer the model towards the correct prediction. We contribute a novel way to construct steering vectors by taking inspiration from mutation testing, which constructs minimal semantics-breaking code edits. In contrast, we construct steering vectors from semantics-preserving code edits. We apply our approach to the task of type prediction for the gradually typed languages Python and TypeScript. This approach corrects up to 90% of type mispredictions. Fina
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;Shapley&#20540;&#26041;&#27861;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#25581;&#31034;&#20102;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#20915;&#31574;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#25552;&#31034;&#32452;&#20214;&#30340;&#24433;&#21709;</title><link>https://arxiv.org/abs/2404.01332</link><description>&lt;p&gt;
&#31561;&#31561;&#65292;&#36825;&#37117;&#26159;&#20196;&#29260;&#22122;&#38899;&#65311;&#19968;&#30452;&#23601;&#26159;&#21527;&#65306;&#21033;&#29992; Shapley &#20540;&#35299;&#37322; LLM &#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01332
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;Shapley&#20540;&#26041;&#27861;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#25581;&#31034;&#20102;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#20915;&#31574;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#25552;&#31034;&#32452;&#20214;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#20026;&#27169;&#25311;&#20154;&#31867;&#34892;&#20026;&#21644;&#35748;&#30693;&#36807;&#31243;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#65292;&#28508;&#22312;&#24212;&#29992;&#21253;&#25324;&#24066;&#22330;&#30740;&#31350;&#21644;&#28040;&#36153;&#32773;&#34892;&#20026;&#20998;&#26512;&#31561;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLMs&#30340;&#26174;&#33879;&#24046;&#24322;&#26263;&#31034;&#20102;&#19981;&#21516;&#30340;&#22522;&#30784;&#36807;&#31243;&#22312;&#36215;&#20316;&#29992;&#65292;&#20197;&#21450;LLMs&#23545;&#25552;&#31034;&#21464;&#21270;&#30340;&#25935;&#24863;&#24615;&#65292;&#21033;&#29992;LLMs&#20316;&#20026;&#20154;&#31867;&#20027;&#20307;&#30340;&#26367;&#20195;&#20173;&#28982;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#20013;Shapley&#20540;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#24182;&#37327;&#21270;&#27599;&#20010;&#25552;&#31034;&#32452;&#20214;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#30456;&#23545;&#36129;&#29486;&#12290;&#36890;&#36807;&#20004;&#20010;&#24212;&#29992;--&#19968;&#20010;&#31163;&#25955;&#36873;&#25321;&#23454;&#39564;&#21644;&#19968;&#20010;&#35748;&#30693;&#20559;&#35265;&#35843;&#26597;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Shapley&#20540;&#26041;&#27861;&#22914;&#20309;&#25581;&#31034;&#25105;&#20204;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#21363;LLM&#20915;&#31574;&#21463;&#21040;&#30340;&#24433;&#21709;&#20005;&#37325;&#20559;&#21521;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01332v1 Announce Type: cross  Abstract: The emergence of large language models (LLMs) has opened up exciting possibilities for simulating human behavior and cognitive processes, with potential applications in various domains, including marketing research and consumer behavior analysis. However, the validity of utilizing LLMs as stand-ins for human subjects remains uncertain due to glaring divergences that suggest fundamentally different underlying processes at play and the sensitivity of LLM responses to prompt variations. This paper presents a novel approach based on Shapley values from cooperative game theory to interpret LLM behavior and quantify the relative contribution of each prompt component to the model's output. Through two applications-a discrete choice experiment and an investigation of cognitive biases-we demonstrate how the Shapley value method can uncover what we term "token noise" effects, a phenomenon where LLM decisions are disproportionately influenced by 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#23545;&#19968;&#33324;&#21644;&#24635; $N$-agent &#28216;&#25103;&#30340;&#32435;&#20160;&#22343;&#34913;&#20135;&#29983;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;NE&#31526;&#21512;&#32447;&#24615;&#39640;&#26031;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#20102;&#25919;&#31574;&#20248;&#21270;&#31639;&#27861;&#20197;&#21450;&#22686;&#24378;&#25216;&#26415;&#26469;&#25214;&#21040;&#28216;&#25103;&#20869;&#30340;NE&#12290;</title><link>https://arxiv.org/abs/2404.00045</link><description>&lt;p&gt;
&#25919;&#31574;&#20248;&#21270;&#22312;&#27491;&#21017;&#21270;&#24191;&#20041;&#21644;&#24635; LQ &#28216;&#25103;&#20013;&#25214;&#21040;&#32435;&#20160;&#22343;&#34913;
&lt;/p&gt;
&lt;p&gt;
Policy Optimization finds Nash Equilibrium in Regularized General-Sum LQ Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00045
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#23545;&#19968;&#33324;&#21644;&#24635; $N$-agent &#28216;&#25103;&#30340;&#32435;&#20160;&#22343;&#34913;&#20135;&#29983;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;NE&#31526;&#21512;&#32447;&#24615;&#39640;&#26031;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#20102;&#25919;&#31574;&#20248;&#21270;&#31639;&#27861;&#20197;&#21450;&#22686;&#24378;&#25216;&#26415;&#26469;&#25214;&#21040;&#28216;&#25103;&#20869;&#30340;NE&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24341;&#20837;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#23545;&#19968;&#33324;&#21644;&#24635; $N$-agent &#28216;&#25103;&#30340;&#32435;&#20160;&#22343;&#34913; (NE) &#30340;&#24433;&#21709;&#65292;&#25581;&#31034;&#20102;&#36825;&#31867;&#28216;&#25103;&#30340;NE&#31526;&#21512;&#32447;&#24615;&#39640;&#26031;&#31574;&#30053;&#30340;&#20107;&#23454;&#12290;&#27492;&#22806;&#65292;&#23427;&#25551;&#32472;&#20102;&#22312;&#29109;&#27491;&#21017;&#21270;&#30340;&#36866;&#24403;&#24615;&#26041;&#38754;&#65292;&#23545;&#28216;&#25103;&#20869;NE&#29420;&#29305;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#30001;&#20110;&#25919;&#31574;&#20248;&#21270;&#26159;&#24378;&#21270;&#23398;&#20064; (RL) &#25216;&#26415;&#30340;&#22522;&#30784;&#26041;&#27861;&#65292;&#26088;&#22312;&#25214;&#21040; NE&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#25919;&#31574;&#20248;&#21270;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#35813;&#31639;&#27861; (&#22312;&#29109;&#27491;&#21017;&#21270;&#30340;&#36866;&#24403;&#24615;&#19979;) &#33021;&#22815;&#26126;&#26174;&#22320;&#23454;&#29616; NE&#12290;&#27492;&#22806;&#65292;&#22312;&#29109;&#27491;&#21017;&#21270;&#35777;&#26126;&#19981;&#36275;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010; $\delta$-&#22686;&#24378;&#25216;&#26415;&#65292;&#26377;&#21161;&#20110;&#23454;&#29616;&#28216;&#25103;&#20869;&#30340; $\epsilon$-NE&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00045v1 Announce Type: cross  Abstract: In this paper, we investigate the impact of introducing relative entropy regularization on the Nash Equilibria (NE) of General-Sum $N$-agent games, revealing the fact that the NE of such games conform to linear Gaussian policies. Moreover, it delineates sufficient conditions, contingent upon the adequacy of entropy regularization, for the uniqueness of the NE within the game. As Policy Optimization serves as a foundational approach for Reinforcement Learning (RL) techniques aimed at finding the NE, in this work we prove the linear convergence of a policy optimization algorithm which (subject to the adequacy of entropy regularization) is capable of provably attaining the NE. Furthermore, in scenarios where the entropy regularization proves insufficient, we present a $\delta$-augmentation technique, which facilitates the achievement of an $\epsilon$-NE within the game.
&lt;/p&gt;</description></item><item><title>CoverUp&#36890;&#36807;&#35206;&#30422;&#29575;&#20998;&#26512;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#65292;&#39537;&#21160;&#29983;&#25104;&#39640;&#35206;&#30422;&#29575;&#30340;Python&#22238;&#24402;&#27979;&#35797;&#65292;&#24182;&#22312;&#25913;&#36827;&#35206;&#30422;&#29575;&#26041;&#38754;&#21462;&#24471;&#26174;&#33879;&#25104;&#23601;&#12290;</title><link>https://arxiv.org/abs/2403.16218</link><description>&lt;p&gt;
CoverUp&#65306;&#22522;&#20110;&#35206;&#30422;&#29575;&#24341;&#23548;&#30340;LLM&#27979;&#35797;&#29983;&#25104;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
CoverUp: Coverage-Guided LLM-Based Test Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16218
&lt;/p&gt;
&lt;p&gt;
CoverUp&#36890;&#36807;&#35206;&#30422;&#29575;&#20998;&#26512;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#65292;&#39537;&#21160;&#29983;&#25104;&#39640;&#35206;&#30422;&#29575;&#30340;Python&#22238;&#24402;&#27979;&#35797;&#65292;&#24182;&#22312;&#25913;&#36827;&#35206;&#30422;&#29575;&#26041;&#38754;&#21462;&#24471;&#26174;&#33879;&#25104;&#23601;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;CoverUp&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#22411;&#31995;&#32479;&#65292;&#36890;&#36807;&#35206;&#30422;&#29575;&#20998;&#26512;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#32467;&#21512;&#39537;&#21160;&#29983;&#25104;&#39640;&#35206;&#30422;&#29575;&#30340;Python&#22238;&#24402;&#27979;&#35797;&#12290;CoverUp&#36890;&#36807;&#36845;&#20195;&#25913;&#21892;&#35206;&#30422;&#29575;&#65292;&#23558;&#35206;&#30422;&#29575;&#20998;&#26512;&#19982;LLM&#23545;&#35805;&#20132;&#26367;&#36827;&#34892;&#65292;&#20197;&#20415;&#23558;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#23578;&#26410;&#28085;&#30422;&#30340;&#20195;&#30721;&#34892;&#21644;&#20998;&#25903;&#19978;&#12290;&#26368;&#32456;&#30340;&#27979;&#35797;&#22871;&#20214;&#30456;&#27604;&#24403;&#21069;&#25216;&#26415;&#27700;&#24179;&#26174;&#33879;&#25552;&#39640;&#20102;&#35206;&#30422;&#29575;&#65306;&#19982;CodaMosa&#30456;&#27604;&#65292;&#19968;&#31181;&#28151;&#21512;LLM / &#22522;&#20110;&#25628;&#32034;&#30340;&#36719;&#20214;&#27979;&#35797;&#31995;&#32479;&#65292;CoverUp&#22312;&#21508;&#26041;&#38754;&#37117;&#22823;&#24133;&#25552;&#39640;&#20102;&#35206;&#30422;&#29575;&#12290;&#20197;&#27169;&#22359;&#20026;&#22522;&#30784;&#65292;CoverUp&#23454;&#29616;&#20102;81%&#30340;&#20013;&#20301;&#32447;&#35206;&#30422;&#29575;&#65288;&#23545;&#27604;62%&#65289;&#12289;53%&#30340;&#20998;&#25903;&#35206;&#30422;&#29575;&#65288;&#23545;&#27604;35%&#65289;&#21644;78%&#30340;&#32447;+&#20998;&#25903;&#35206;&#30422;&#29575;&#65288;&#23545;&#27604;55%&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;CoverUp&#30340;&#36845;&#20195;&#12289;&#35206;&#30422;&#29575;&#24341;&#23548;&#26041;&#27861;&#23545;&#20854;&#26377;&#25928;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#20026;&#20854;&#25104;&#21151;&#30340;&#36817;&#19968;&#21322;&#20316;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16218v1 Announce Type: cross  Abstract: This paper presents CoverUp, a novel system that drives the generation of high-coverage Python regression tests via a combination of coverage analysis and large-language models (LLMs). CoverUp iteratively improves coverage, interleaving coverage analysis with dialogs with the LLM to focus its attention on as yet uncovered lines and branches. The resulting test suites significantly improve coverage over the current state of the art: compared to CodaMosa, a hybrid LLM / search-based software testing system, CoverUp substantially improves coverage across the board. On a per-module basis, CoverUp achieves median line coverage of 81% (vs. 62%), branch coverage of 53% (vs. 35%) and line+branch coverage of 78% (vs. 55%). We show that CoverUp's iterative, coverage-guided approach is crucial to its effectiveness, contributing to nearly half of its successes.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;\carb &#30340;&#31471;&#21040;&#31471;&#24314;&#27169;&#24037;&#20855;&#65292;&#29992;&#20110;&#22312;&#29289;&#32852;&#32593;-&#21551;&#29992;&#28145;&#24230;&#23398;&#20064;&#20013;&#31934;&#30830;&#20272;&#31639;&#30899;&#36275;&#36857;&#65292;&#23637;&#31034;&#20102;&#19982;&#23454;&#38469;&#27979;&#37327;&#20540;&#30456;&#27604;&#26368;&#22823;$\pm21\%$&#30340;&#30899;&#36275;&#36857;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2403.10984</link><description>&lt;p&gt;
IoTCO2&#65306;&#35780;&#20272;&#29289;&#32852;&#32593;-&#21551;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471;&#30899;&#36275;&#36857;
&lt;/p&gt;
&lt;p&gt;
IoTCO2: Assessing the End-To-End Carbon Footprint of Internet-of-Things-Enabled Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10984
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;\carb &#30340;&#31471;&#21040;&#31471;&#24314;&#27169;&#24037;&#20855;&#65292;&#29992;&#20110;&#22312;&#29289;&#32852;&#32593;-&#21551;&#29992;&#28145;&#24230;&#23398;&#20064;&#20013;&#31934;&#30830;&#20272;&#31639;&#30899;&#36275;&#36857;&#65292;&#23637;&#31034;&#20102;&#19982;&#23454;&#38469;&#27979;&#37327;&#20540;&#30456;&#27604;&#26368;&#22823;$\pm21\%$&#30340;&#30899;&#36275;&#36857;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#38544;&#31169;&#24615;&#21644;&#30830;&#20445;&#26381;&#21153;&#36136;&#37327;&#65288;QoS&#65289;&#65292;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#27169;&#22411;&#36234;&#26469;&#36234;&#22810;&#22320;&#37096;&#32626;&#22312;&#29289;&#32852;&#32593;&#65288;IoT&#65289;&#35774;&#22791;&#19978;&#36827;&#34892;&#25968;&#25454;&#22788;&#29702;&#65292;&#26497;&#22823;&#22320;&#22686;&#21152;&#20102;&#19982;IoT&#19978;DL&#30456;&#20851;&#30340;&#30899;&#36275;&#36857;&#65292;&#28085;&#30422;&#20102;&#25805;&#20316;&#21644;&#23454;&#20307;&#26041;&#38754;&#12290;&#29616;&#26377;&#30340;&#25805;&#20316;&#33021;&#37327;&#39044;&#27979;&#22120;&#32463;&#24120;&#24573;&#30053;&#20102;&#37327;&#21270;&#30340;DL&#27169;&#22411;&#21644;&#26032;&#20852;&#30340;&#31070;&#32463;&#22788;&#29702;&#21333;&#20803;&#65288;NPUs&#65289;&#65292;&#32780;&#23454;&#20307;&#30899;&#36275;&#36857;&#24314;&#27169;&#24037;&#20855;&#24573;&#30053;&#20102;IoT&#35774;&#22791;&#20013;&#24120;&#35265;&#30340;&#38750;&#35745;&#31639;&#30828;&#20214;&#32452;&#20214;&#65292;&#23548;&#33268;&#20102;&#29289;&#32852;&#32593;DL&#20934;&#30830;&#30899;&#36275;&#36857;&#24314;&#27169;&#24037;&#20855;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;\textit{\carb}&#65292;&#19968;&#31181;&#29992;&#20110;&#31934;&#30830;&#20272;&#31639;&#29289;&#32852;&#32593;DL&#20013;&#30899;&#36275;&#36857;&#30340;&#31471;&#21040;&#31471;&#24314;&#27169;&#24037;&#20855;&#65292;&#23637;&#31034;&#20102;&#19982;&#21508;&#31181;DL&#27169;&#22411;&#30340;&#23454;&#38469;&#27979;&#37327;&#20540;&#30456;&#27604;&#26368;&#22823;$\pm21\%$&#30340;&#30899;&#36275;&#36857;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;\carb&#30340;&#23454;&#38469;&#24212;&#29992;&#36890;&#36807;&#22810;&#20010;&#29992;&#25143;&#26696;&#20363;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10984v1 Announce Type: cross  Abstract: To improve privacy and ensure quality-of-service (QoS), deep learning (DL) models are increasingly deployed on Internet of Things (IoT) devices for data processing, significantly increasing the carbon footprint associated with DL on IoT, covering both operational and embodied aspects. Existing operational energy predictors often overlook quantized DL models and emerging neural processing units (NPUs), while embodied carbon footprint modeling tools neglect non-computing hardware components common in IoT devices, creating a gap in accurate carbon footprint modeling tools for IoT-enabled DL. This paper introduces \textit{\carb}, an end-to-end modeling tool for precise carbon footprint estimation in IoT-enabled DL, demonstrating a maximum $\pm21\%$ deviation in carbon footprint values compared to actual measurements across various DL models. Additionally, practical applications of \carb are showcased through multiple user case studies.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#65288;PERL&#65289;&#65292;&#33021;&#22815;&#22312;&#19982;&#20256;&#32479;RLHF&#35774;&#32622;&#30456;&#24403;&#30340;&#24615;&#33021;&#19979;&#65292;&#23454;&#29616;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#26356;&#23569;&#30340;&#20869;&#23384;&#21344;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.10704</link><description>&lt;p&gt;
PERL: &#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#23454;&#29616;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PERL: Parameter Efficient Reinforcement Learning from Human Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10704
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#65288;PERL&#65289;&#65292;&#33021;&#22815;&#22312;&#19982;&#20256;&#32479;RLHF&#35774;&#32622;&#30456;&#24403;&#30340;&#24615;&#33021;&#19979;&#65292;&#23454;&#29616;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#26356;&#23569;&#30340;&#20869;&#23384;&#21344;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#23558;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;RLHF&#35757;&#32451;&#27169;&#22411;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#19988;&#25972;&#20010;&#36807;&#31243;&#22797;&#26434;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;RLHF&#65292;&#20854;&#20013;&#22522;&#30784;&#27169;&#22411;&#20351;&#29992;&#32993;&#31561;&#20154;&#25552;&#20986;&#30340;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#21442;&#25968;&#39640;&#25928;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#8220;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#8221;&#65288;PERL&#65289;&#30340;&#35774;&#32622;&#65292;&#22312;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;LoRA&#36827;&#34892;&#22870;&#21169;&#27169;&#22411;&#35757;&#32451;&#21644;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#23558;PERL&#19982;&#20256;&#32479;&#30340;&#24494;&#35843;&#65288;&#20840;&#35843;&#65289;&#22312;&#21253;&#25324;2&#20010;&#26032;&#25968;&#25454;&#38598;&#22312;&#20869;&#30340;7&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#22870;&#21169;&#24314;&#27169;&#21644;&#24378;&#21270;&#23398;&#20064;&#26041;&#38754;&#30340;&#21508;&#31181;&#37197;&#32622;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;PERL&#30340;&#24615;&#33021;&#19982;&#20256;&#32479;&#30340;RLHF&#35774;&#32622;&#30456;&#24403;&#65292;&#21516;&#26102;&#35757;&#32451;&#36895;&#24230;&#26356;&#24555;&#65292;&#20869;&#23384;&#21344;&#29992;&#26356;&#23569;&#12290;&#36825;&#20351;&#24471;RLHF&#20855;&#26377;&#24456;&#39640;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10704v1 Announce Type: cross  Abstract: Reinforcement Learning from Human Feedback (RLHF) has proven to be a strong method to align Pretrained Large Language Models (LLMs) with human preferences. But training models with RLHF is computationally expensive, and an overall complex process. In this work, we study RLHF where the underlying models are trained using the parameter efficient method of Low-Rank Adaptation (LoRA) introduced by Hu et al. [2021]. We investigate the setup of "Parameter Efficient Reinforcement Learning" (PERL), in which we perform reward model training and reinforcement learning using LoRA. We compare PERL to conventional fine-tuning (full-tuning) across various configurations for 7 benchmarks, including 2 novel datasets, of reward modeling and reinforcement learning. We find that PERL performs on par with the conventional RLHF setting, while training faster, and with less memory. This enables the high performance of RLHF, while reducing the computational 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22522;&#26412;&#24341;&#29702;&#30340;&#25512;&#24191;&#21644;&#26680;&#22238;&#24402;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#25193;&#23637;&#21644;&#21464;&#25442;&#65292;&#24471;&#21040;&#20102;&#31995;&#32479;&#36712;&#36857;&#30340;&#26032;&#26680;&#34920;&#31034;&#26041;&#27861;&#65292;&#23637;&#31034;&#20986;&#20102;&#19982;&#29305;&#23450;&#26680;&#22238;&#24402;&#38382;&#39064;&#30340;&#31561;&#25928;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;&#28508;&#22312;&#26680;&#30340;&#32467;&#26500;&#21450;&#20854;&#23545;&#24212;&#30340;&#31995;&#32479;&#31867;&#21035;&#12290;</title><link>https://arxiv.org/abs/2403.05368</link><description>&lt;p&gt;
&#25506;&#35752;&#22522;&#26412;&#24341;&#29702;&#19982;&#26680;&#22238;&#24402;&#20043;&#38388;&#30340;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
Exploring the Links between the Fundamental Lemma and Kernel Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22522;&#26412;&#24341;&#29702;&#30340;&#25512;&#24191;&#21644;&#26680;&#22238;&#24402;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#25193;&#23637;&#21644;&#21464;&#25442;&#65292;&#24471;&#21040;&#20102;&#31995;&#32479;&#36712;&#36857;&#30340;&#26032;&#26680;&#34920;&#31034;&#26041;&#27861;&#65292;&#23637;&#31034;&#20986;&#20102;&#19982;&#29305;&#23450;&#26680;&#22238;&#24402;&#38382;&#39064;&#30340;&#31561;&#25928;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;&#28508;&#22312;&#26680;&#30340;&#32467;&#26500;&#21450;&#20854;&#23545;&#24212;&#30340;&#31995;&#32479;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Willems&#31561;&#20154;&#20851;&#20110;&#22522;&#26412;&#24341;&#29702;&#30340;&#25512;&#24191;&#21644;&#21464;&#31181;&#26159;&#26368;&#36817;&#30740;&#31350;&#30340;&#28909;&#38376;&#35805;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#24182;&#24418;&#24335;&#21270;&#20102;&#26680;&#22238;&#24402;&#19982;&#24050;&#30693;&#38750;&#32447;&#24615;&#22522;&#26412;&#24341;&#29702;&#25193;&#23637;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#36890;&#36807;&#23545;Hankel&#30697;&#38453;&#20013;&#30340;&#20256;&#32479;&#32447;&#24615;&#26041;&#31243;&#36827;&#34892;&#21464;&#25442;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#31995;&#32479;&#36712;&#36857;&#30340;&#21478;&#19968;&#31181;&#38544;&#24335;&#26680;&#34920;&#31034;&#65292;&#21516;&#26102;&#20445;&#25345;&#23545;&#28608;&#21169;&#25345;&#20037;&#24615;&#30340;&#35201;&#27714;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#34920;&#31034;&#31561;&#21516;&#20110;&#29305;&#23450;&#26680;&#22238;&#24402;&#38382;&#39064;&#30340;&#35299;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#28508;&#22312;&#26680;&#30340;&#21487;&#33021;&#32467;&#26500;&#20197;&#21450;&#23427;&#20204;&#23545;&#24212;&#30340;&#31995;&#32479;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05368v1 Announce Type: cross  Abstract: Generalizations and variations of the fundamental lemma by Willems et al. are an active topic of recent research. In this note, we explore and formalize the links between kernel regression and known nonlinear extensions of the fundamental lemma. Applying a transformation to the usual linear equation in Hankel matrices, we arrive at an alternative implicit kernel representation of the system trajectories while keeping the requirements on persistency of excitation. We show that this representation is equivalent to the solution of a specific kernel regression problem. We explore the possible structures of the underlying kernel as well as the system classes to which they correspond.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#24067;&#26080;&#20851;&#20844;&#24179;&#23398;&#20064;&#30340;&#21518;&#22788;&#29702;&#31639;&#27861;FedFaiREE&#65292;&#36866;&#29992;&#20110;&#21435;&#20013;&#24515;&#21270;&#20855;&#26377;&#23567;&#26679;&#26412;&#30340;&#29615;&#22659;&#12290;</title><link>https://arxiv.org/abs/2402.16158</link><description>&lt;p&gt;
&#20998;&#24067;&#26080;&#20851;&#20844;&#24179;&#32852;&#37030;&#23398;&#20064;&#19982;&#23567;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Fair Federated Learning with Small Samples
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#24067;&#26080;&#20851;&#20844;&#24179;&#23398;&#20064;&#30340;&#21518;&#22788;&#29702;&#31639;&#27861;FedFaiREE&#65292;&#36866;&#29992;&#20110;&#21435;&#20013;&#24515;&#21270;&#20855;&#26377;&#23567;&#26679;&#26412;&#30340;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#32852;&#37030;&#23398;&#20064;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#21435;&#20013;&#24515;&#21270;&#25968;&#25454;&#35757;&#32451;&#30340;&#33021;&#21147;&#65292;&#35299;&#20915;&#36328;&#32676;&#20307;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#29992;&#20110;&#30830;&#20445;&#20844;&#24179;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26159;&#20026;&#38598;&#20013;&#21270;&#25968;&#25454;&#29615;&#22659;&#35774;&#35745;&#30340;&#65292;&#36890;&#24120;&#38656;&#35201;&#22823;&#26679;&#26412;&#21644;&#20998;&#24067;&#20551;&#35774;&#65292;&#24378;&#35843;&#20102;&#36843;&#20999;&#38656;&#35201;&#38024;&#23545;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#20998;&#24067;&#26080;&#20851;&#20445;&#35777;&#30340;&#21435;&#20013;&#24515;&#21270;&#21644;&#24322;&#26500;&#31995;&#32479;&#36827;&#34892;&#20844;&#24179;&#24615;&#25216;&#26415;&#30340;&#35843;&#25972;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;FedFaiREE&#65292;&#36825;&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#21435;&#20013;&#24515;&#21270;&#29615;&#22659;&#20013;&#23567;&#26679;&#26412;&#30340;&#20998;&#24067;&#26080;&#20851;&#20844;&#24179;&#23398;&#20064;&#30340;&#21518;&#22788;&#29702;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32771;&#34385;&#21040;&#20102;&#21435;&#20013;&#24515;&#21270;&#29615;&#22659;&#20013;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#20363;&#22914;&#23458;&#25143;&#24322;&#36136;&#24615;&#12289;&#36890;&#20449;&#25104;&#26412;&#21644;&#23567;&#26679;&#26412;&#22823;&#23567;&#12290;&#25105;&#20204;&#20026;bot&#25552;&#20379;&#20005;&#26684;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16158v1 Announce Type: cross  Abstract: As federated learning gains increasing importance in real-world applications due to its capacity for decentralized data training, addressing fairness concerns across demographic groups becomes critically important. However, most existing machine learning algorithms for ensuring fairness are designed for centralized data environments and generally require large-sample and distributional assumptions, underscoring the urgent need for fairness techniques adapted for decentralized and heterogeneous systems with finite-sample and distribution-free guarantees. To address this issue, this paper introduces FedFaiREE, a post-processing algorithm developed specifically for distribution-free fair learning in decentralized settings with small samples. Our approach accounts for unique challenges in decentralized environments, such as client heterogeneity, communication costs, and small sample sizes. We provide rigorous theoretical guarantees for bot
&lt;/p&gt;</description></item><item><title>SpanSeq &#26159;&#19968;&#31181;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#24207;&#21015;&#30340;&#25968;&#25454;&#24211;&#20998;&#21306;&#26041;&#27861;&#65292;&#33021;&#22815;&#36991;&#20813;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20043;&#38388;&#30340;&#25968;&#25454;&#27844;&#28431;&#12290;</title><link>https://arxiv.org/abs/2402.14482</link><description>&lt;p&gt;
SpanSeq&#65306;&#29992;&#20110;&#25913;&#36827;&#28145;&#24230;&#23398;&#20064;&#39033;&#30446;&#24320;&#21457;&#21644;&#35780;&#20272;&#30340;&#22522;&#20110;&#30456;&#20284;&#24230;&#30340;&#24207;&#21015;&#25968;&#25454;&#25286;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SpanSeq: Similarity-based sequence data splitting method for improved development and assessment of deep learning projects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14482
&lt;/p&gt;
&lt;p&gt;
SpanSeq &#26159;&#19968;&#31181;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#24207;&#21015;&#30340;&#25968;&#25454;&#24211;&#20998;&#21306;&#26041;&#27861;&#65292;&#33021;&#22815;&#36991;&#20813;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20043;&#38388;&#30340;&#25968;&#25454;&#27844;&#28431;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#22312;&#35745;&#31639;&#29983;&#29289;&#23398;&#20013;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#22686;&#21152;&#24456;&#22823;&#65292;&#24182;&#19988;&#38543;&#30528;&#35832;&#22914;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#39046;&#22495;&#30340;&#24403;&#21069;&#36827;&#23637;&#65292;&#39044;&#35745;&#23558;&#36827;&#19968;&#27493;&#22686;&#21152;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;SpanSeq&#65292;&#36825;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22823;&#22810;&#25968;&#29983;&#29289;&#24207;&#21015;&#65288;&#22522;&#22240;&#12289;&#34507;&#30333;&#36136;&#21644;&#22522;&#22240;&#32452;&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#25968;&#25454;&#24211;&#20998;&#21306;&#26041;&#27861;&#65292;&#26088;&#22312;&#36991;&#20813;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#25968;&#25454;&#27844;&#28431;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14482v1 Announce Type: new  Abstract: The use of deep learning models in computational biology has increased massively in recent years, and is expected to do so further with the current advances in fields like Natural Language Processing. These models, although able to draw complex relations between input and target, are also largely inclined to learn noisy deviations from the pool of data used during their development. In order to assess their performance on unseen data (their capacity to generalize), it is common to randomly split the available data in development (train/validation) and test sets. This procedure, although standard, has lately been shown to produce dubious assessments of generalization due to the existing similarity between samples in the databases used. In this work, we present SpanSeq, a database partition method for machine learning that can scale to most biological sequences (genes, proteins and genomes) in order to avoid data leakage between sets. We a
&lt;/p&gt;</description></item><item><title>&#37325;&#26032;&#23457;&#35270;&#20102;AdaGrad&#22312;&#38750;&#20984;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#22122;&#22768;&#27169;&#22411;&#65292;&#24471;&#20986;&#20102;&#27010;&#29575;&#25910;&#25947;&#36895;&#24230;&#65292;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#65292;&#19988;&#21487;&#20197;&#22312;&#22122;&#22768;&#21442;&#25968;&#36275;&#22815;&#23567;&#26102;&#21152;&#36895;&#33267;&#26356;&#24555;&#30340;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.13794</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;AdaGrad&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting Convergence of AdaGrad with Relaxed Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13794
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#20102;AdaGrad&#22312;&#38750;&#20984;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#22122;&#22768;&#27169;&#22411;&#65292;&#24471;&#20986;&#20102;&#27010;&#29575;&#25910;&#25947;&#36895;&#24230;&#65292;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#65292;&#19988;&#21487;&#20197;&#22312;&#22122;&#22768;&#21442;&#25968;&#36275;&#22815;&#23567;&#26102;&#21152;&#36895;&#33267;&#26356;&#24555;&#30340;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;AdaGrad&#22312;&#38750;&#20984;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;AdaGrad&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#20854;&#20013;&#22122;&#22768;&#30340;&#22823;&#23567;&#30001;&#20989;&#25968;&#20540;&#24046;&#21644;&#26799;&#24230;&#22823;&#23567;&#25511;&#21046;&#12290;&#36825;&#20010;&#27169;&#22411;&#28085;&#30422;&#20102;&#24191;&#27867;&#33539;&#22260;&#30340;&#22122;&#22768;&#65292;&#21253;&#25324;&#26377;&#30028;&#22122;&#22768;&#12289;&#27425;&#39640;&#26031;&#22122;&#22768;&#12289;&#20223;&#23556;&#26041;&#24046;&#22122;&#22768;&#21644;&#39044;&#26399;&#20809;&#28369;&#24230;&#65292;&#24182;&#19988;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#34987;&#35777;&#26126;&#26356;&#21152;&#29616;&#23454;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24471;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#25910;&#25947;&#36895;&#24230;&#65292;&#26681;&#25454;&#36890;&#29992;&#22122;&#22768;&#65292;&#21487;&#20197;&#36798;&#21040;( \tilde{\mathcal{O}}(1/\sqrt{T}))&#12290;&#36825;&#20010;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#20808;&#21069;&#23545;&#38382;&#39064;&#21442;&#25968;&#30340;&#20102;&#35299;&#65292;&#24403;&#19982;&#20989;&#25968;&#20540;&#24046;&#21644;&#22122;&#22768;&#27700;&#24179;&#30456;&#20851;&#30340;&#21442;&#25968;&#36275;&#22815;&#23567;&#26102;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#21040;(\tilde{\mathcal{O}}(1/T))&#65292;&#20854;&#20013;(T)&#34920;&#31034;&#24635;&#36845;&#20195;&#27425;&#25968;&#12290;&#25910;&#25947;&#36895;&#24230;&#22240;&#27492;&#21305;&#37197;&#20102;&#19979;&#38480;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13794v1 Announce Type: cross  Abstract: In this study, we revisit the convergence of AdaGrad with momentum (covering AdaGrad as a special case) on non-convex smooth optimization problems. We consider a general noise model where the noise magnitude is controlled by the function value gap together with the gradient magnitude. This model encompasses a broad range of noises including bounded noise, sub-Gaussian noise, affine variance noise and the expected smoothness, and it has been shown to be more realistic in many practical applications. Our analysis yields a probabilistic convergence rate which, under the general noise, could reach at (\tilde{\mathcal{O}}(1/\sqrt{T})). This rate does not rely on prior knowledge of problem-parameters and could accelerate to (\tilde{\mathcal{O}}(1/T)) where (T) denotes the total number iterations, when the noise parameters related to the function value gap and noise level are sufficiently small. The convergence rate thus matches the lower rat
&lt;/p&gt;</description></item><item><title>FRAC-Q-Learning&#26159;&#19968;&#31181;&#19987;&#20026;&#31038;&#20132;&#26426;&#22120;&#20154;&#35774;&#35745;&#65292;&#33021;&#36991;&#20813;&#29992;&#25143;&#21388;&#28902;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#27604;&#20256;&#32479;&#31639;&#27861;&#22312;&#20852;&#36259;&#21644;&#21388;&#28902;&#31243;&#24230;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#26377;&#21161;&#20110;&#24320;&#21457;&#19981;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;</title><link>https://arxiv.org/abs/2311.15327</link><description>&lt;p&gt;
FRAC-Q-Learning: &#19968;&#31181;&#20855;&#26377;&#36991;&#20813;&#21388;&#28902;&#36807;&#31243;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15327
&lt;/p&gt;
&lt;p&gt;
FRAC-Q-Learning&#26159;&#19968;&#31181;&#19987;&#20026;&#31038;&#20132;&#26426;&#22120;&#20154;&#35774;&#35745;&#65292;&#33021;&#36991;&#20813;&#29992;&#25143;&#21388;&#28902;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#27604;&#20256;&#32479;&#31639;&#27861;&#22312;&#20852;&#36259;&#21644;&#21388;&#28902;&#31243;&#24230;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#26377;&#21161;&#20110;&#24320;&#21457;&#19981;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#32463;&#24120;&#34987;&#24212;&#29992;&#20110;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#24182;&#26410;&#38024;&#23545;&#31038;&#20132;&#26426;&#22120;&#20154;&#36827;&#34892;&#20248;&#21270;&#65292;&#22240;&#27492;&#21487;&#33021;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#20026;&#31038;&#20132;&#26426;&#22120;&#20154;&#35774;&#35745;&#30340;&#26032;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;FRAC-Q-Learning&#65292;&#21487;&#20197;&#36991;&#20813;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#12290;&#35813;&#31639;&#27861;&#38500;&#20102;&#38543;&#26426;&#21270;&#21644;&#20998;&#31867;&#36807;&#31243;&#22806;&#65292;&#36824;&#21253;&#25324;&#19968;&#20010;&#36951;&#24536;&#36807;&#31243;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#19982;&#20256;&#32479;Q-Learning&#30340;&#27604;&#36739;&#35780;&#20272;&#20102;FRAC-Q-Learning&#30340;&#20852;&#36259;&#21644;&#21388;&#28902;&#31243;&#24230;&#20998;&#25968;&#12290;FRAC-Q-Learning&#26174;&#31034;&#20986;&#26126;&#26174;&#26356;&#39640;&#30340;&#20852;&#36259;&#20998;&#25968;&#36235;&#21183;&#65292;&#24182;&#19988;&#30456;&#36739;&#20110;&#20256;&#32479;Q-Learning&#26356;&#38590;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#12290;&#22240;&#27492;&#65292;FRAC-Q-Learning&#26377;&#21161;&#20110;&#24320;&#21457;&#19981;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;&#35813;&#31639;&#27861;&#36824;&#21487;&#20197;&#22312;&#22522;&#20110;Web&#30340;&#36890;&#20449;&#21644;&#25945;&#32946;&#20013;&#25214;&#21040;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15327v3 Announce Type: replace-cross  Abstract: The reinforcement learning algorithms have often been applied to social robots. However, most reinforcement learning algorithms were not optimized for the use of social robots, and consequently they may bore users. We proposed a new reinforcement learning method specialized for the social robot, the FRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists of a forgetting process in addition to randomizing and categorizing processes. This study evaluated interest and boredom hardness scores of the FRAC-Q-learning by a comparison with the traditional Q-learning. The FRAC-Q-learning showed significantly higher trend of interest score, and indicated significantly harder to bore users compared to the traditional Q-learning. Therefore, the FRAC-Q-learning can contribute to develop a social robot that will not bore users. The proposed algorithm can also find applications in Web-based communication and educational 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#65292;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#65292;&#24182;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;</title><link>http://arxiv.org/abs/2401.14483</link><description>&lt;p&gt;
&#39044;&#27979;&#30340;&#22235;&#20010;&#26041;&#38754;&#65306;&#26657;&#20934;&#12289;&#39044;&#27979;&#24615;&#12289;&#38543;&#26426;&#24615;&#21644;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret. (arXiv:2401.14483v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#65292;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#65292;&#24182;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26159;&#20851;&#20110;&#39044;&#27979;&#30340;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#21482;&#26377;&#32463;&#36807;&#35780;&#20272;&#21518;&#25165;&#20855;&#26377;&#20854;&#26377;&#29992;&#24615;&#12290;&#26426;&#22120;&#23398;&#20064;&#20256;&#32479;&#19978;&#20851;&#27880;&#25439;&#22833;&#31867;&#22411;&#21450;&#20854;&#30456;&#24212;&#30340;&#36951;&#25022;&#12290;&#30446;&#21069;&#65292;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#37325;&#26032;&#23545;&#26657;&#20934;&#20135;&#29983;&#20102;&#20852;&#36259;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#12290;&#25105;&#20204;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#12290;&#36890;&#36807;&#23545;&#36172;&#24466;&#21644;&#39044;&#27979;&#32773;&#26045;&#21152;&#30452;&#35266;&#30340;&#38480;&#21046;&#65292;&#26657;&#20934;&#21644;&#36951;&#25022;&#33258;&#28982;&#22320;&#25104;&#20026;&#20102;&#36825;&#20010;&#26694;&#26550;&#30340;&#19968;&#37096;&#20998;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#21338;&#24328;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;&#30456;&#23545;&#20110;&#39044;&#27979;&#32780;&#35328;&#65292;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#31561;&#21516;&#20110;&#20851;&#20110;&#32467;&#26524;&#30340;&#22909;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#31216;&#36825;&#20004;&#20010;&#26041;&#38754;&#20026;&#26657;&#20934;&#21644;&#36951;&#25022;&#12289;&#39044;&#27979;&#24615;&#21644;&#38543;&#26426;&#24615;&#65292;&#21363;&#39044;&#27979;&#30340;&#22235;&#20010;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning is about forecasting. Forecasts, however, obtain their usefulness only through their evaluation. Machine learning has traditionally focused on types of losses and their corresponding regret. Currently, the machine learning community regained interest in calibration. In this work, we show the conceptual equivalence of calibration and regret in evaluating forecasts. We frame the evaluation problem as a game between a forecaster, a gambler and nature. Putting intuitive restrictions on gambler and forecaster, calibration and regret naturally fall out of the framework. In addition, this game links evaluation of forecasts to randomness of outcomes. Random outcomes with respect to forecasts are equivalent to good forecasts with respect to outcomes. We call those dual aspects, calibration and regret, predictiveness and randomness, the four facets of forecast felicity.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#20844;&#24179;&#24615;&#30340;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#65288;MEDL&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#35299;&#20915;&#25968;&#25454;&#38598;&#31751;&#38388;&#20851;&#32852;&#21644;&#19981;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#65292;&#26469;&#25552;&#39640;&#23545;&#31751;&#20998;&#24067;&#25968;&#25454;&#30340;&#20844;&#24179;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.03146</link><description>&lt;p&gt;
&#22686;&#24378;&#20844;&#24179;&#24615;&#30340;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#22312;&#31751;&#65288;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#25968;&#25454;&#19978;&#25913;&#21892;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fairness-enhancing mixed effects deep learning improves fairness on in- and out-of-distribution clustered (non-iid) data. (arXiv:2310.03146v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03146
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#20844;&#24179;&#24615;&#30340;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#65288;MEDL&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#35299;&#20915;&#25968;&#25454;&#38598;&#31751;&#38388;&#20851;&#32852;&#21644;&#19981;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#65292;&#26469;&#25552;&#39640;&#23545;&#31751;&#20998;&#24067;&#25968;&#25454;&#30340;&#20844;&#24179;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#28145;&#24230;&#23398;&#20064;&#22312;&#20004;&#20010;&#26680;&#24515;&#38382;&#39064;&#19978;&#23384;&#22312;&#22256;&#25200;&#12290;&#39318;&#20808;&#65292;&#23427;&#20551;&#35774;&#35757;&#32451;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#28982;&#32780;&#65292;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#23558;&#26679;&#26412;&#25353;&#20849;&#20139;&#30340;&#27979;&#37327;&#20540;&#36827;&#34892;&#20998;&#32452;&#65288;&#20363;&#22914;&#65292;&#30740;&#31350;&#21442;&#19982;&#32773;&#25110;&#32454;&#32990;&#65289;&#65292;&#36829;&#21453;&#20102;&#36825;&#19968;&#20551;&#35774;&#12290;&#22312;&#36825;&#20123;&#22330;&#26223;&#20013;&#65292;&#28145;&#24230;&#23398;&#20064;&#21487;&#33021;&#26174;&#31034;&#20986;&#24615;&#33021;&#19979;&#38477;&#12289;&#27867;&#21270;&#33021;&#21147;&#26377;&#38480;&#21644;&#35299;&#37322;&#24615;&#38382;&#39064;&#65292;&#24182;&#20276;&#38543;&#30528;&#31751;&#28151;&#28102;&#24341;&#36215;&#30340;&#31532;&#19968;&#22411;&#21644;&#31532;&#20108;&#22411;&#38169;&#35823;&#12290;&#20854;&#27425;&#65292;&#27169;&#22411;&#36890;&#24120;&#34987;&#35757;&#32451;&#20197;&#23454;&#29616;&#25972;&#20307;&#20934;&#30830;&#24615;&#65292;&#24448;&#24448;&#24573;&#35270;&#20102;&#34987;&#20302;&#20272;&#30340;&#32676;&#20307;&#65292;&#22312;&#36151;&#27454;&#25209;&#20934;&#25110;&#30830;&#23450;&#20581;&#24247;&#20445;&#38505;&#36153;&#29575;&#31561;&#20851;&#38190;&#39046;&#22495;&#24341;&#20837;&#20559;&#35265;&#65292;&#36825;&#20123;&#20559;&#35265;&#21487;&#33021;&#20250;&#20005;&#37325;&#24433;&#21709;&#20010;&#20154;&#30340;&#29983;&#27963;&#36136;&#37327;&#12290;&#20026;&#20102;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#65288;MEDL&#65289;&#26694;&#26550;&#12290;MEDL&#36890;&#36807;&#24341;&#20837;&#20197;&#19979;&#20869;&#23481;&#20998;&#21035;&#37327;&#21270;&#31751;&#19981;&#21464;&#30340;&#22266;&#23450;&#25928;&#24212;&#21644;&#31751;&#29305;&#23450;&#30340;&#38543;&#26426;&#25928;&#24212;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#25361;&#25112;&#65306;1&#65289;&#19968;&#20010;&#31751;&#23545;&#25163;&#65292;&#40723;&#21169;&#31751;&#38388;&#24046;&#24322;&#30340;&#26368;&#23567;&#21270;&#65307;
&lt;/p&gt;
&lt;p&gt;
Traditional deep learning (DL) suffers from two core problems. Firstly, it assumes training samples are independent and identically distributed. However, numerous real-world datasets group samples by shared measurements (e.g., study participants or cells), violating this assumption. In these scenarios, DL can show compromised performance, limited generalization, and interpretability issues, coupled with cluster confounding causing Type 1 and 2 errors. Secondly, models are typically trained for overall accuracy, often neglecting underrepresented groups and introducing biases in crucial areas like loan approvals or determining health insurance rates, such biases can significantly impact one's quality of life. To address both of these challenges simultaneously, we present a mixed effects deep learning (MEDL) framework. MEDL separately quantifies cluster-invariant fixed effects (FE) and cluster-specific random effects (RE) through the introduction of: 1) a cluster adversary which encourage
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26631;&#20934;&#21270;&#19988;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#65292;&#29992;&#20110;&#22312;&#22810;&#20013;&#24515;&#25968;&#25454;&#24211;&#20013;&#39044;&#27979;&#21152;&#25252;&#30149;&#25151;&#24739;&#32773;&#30340;&#20877;&#20837;&#38498;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2309.13781</link><description>&lt;p&gt;
ICU &#37325;&#26032;&#20837;&#38498;&#39044;&#27979;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Explainable Machine Learning for ICU Readmission Prediction. (arXiv:2309.13781v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26631;&#20934;&#21270;&#19988;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#65292;&#29992;&#20110;&#22312;&#22810;&#20013;&#24515;&#25968;&#25454;&#24211;&#20013;&#39044;&#27979;&#21152;&#25252;&#30149;&#25151;&#24739;&#32773;&#30340;&#20877;&#20837;&#38498;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21152;&#25252;&#30149;&#25151;&#65288;ICU&#65289;&#26159;&#19968;&#20010;&#22797;&#26434;&#30340;&#21307;&#38498;&#29615;&#22659;&#65292;&#21307;&#29983;&#30340;&#20915;&#31574;&#23545;&#24739;&#32773;&#30340;&#29983;&#21629;&#26500;&#25104;&#39640;&#39118;&#38505;&#12290;&#24517;&#39035;&#36981;&#24490;&#19968;&#26465;&#20840;&#38754;&#30340;&#25252;&#29702;&#36335;&#24452;&#26469;&#20943;&#23569;&#24182;&#21457;&#30151;&#12290;&#22312;&#36825;&#31181;&#29615;&#22659;&#20013;&#65292;&#19981;&#30830;&#23450;&#24615;&#12289;&#31454;&#20105;&#24615;&#21644;&#38750;&#35745;&#21010;&#24615;&#30340;&#22240;&#32032;&#22686;&#21152;&#20102;&#32479;&#19968;&#23454;&#26045;&#25252;&#29702;&#36335;&#24452;&#30340;&#22256;&#38590;&#12290;&#20877;&#20837;&#38498;&#26159;&#35813;&#36335;&#24452;&#30340;&#22256;&#38590;&#20043;&#19968;&#65292;&#21363;&#24739;&#32773;&#22312;&#30701;&#26102;&#38388;&#20869;&#20877;&#27425;&#20837;&#20303;ICU&#65292;&#23548;&#33268;&#39640;&#27515;&#20129;&#29575;&#21644;&#39640;&#36164;&#28304;&#21033;&#29992;&#29575;&#12290;&#19968;&#20123;&#30740;&#31350;&#23581;&#35797;&#36890;&#36807;&#24739;&#32773;&#30340;&#21307;&#30103;&#20449;&#24687;&#26469;&#39044;&#27979;&#20877;&#20837;&#38498;&#24773;&#20917;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#39044;&#27979;&#20877;&#20837;&#38498;&#26102;&#26377;&#19968;&#23450;&#30340;&#25104;&#21151;&#65292;&#20294;&#36825;&#20123;&#30740;&#31350;&#24182;&#26410;&#23545;&#20877;&#20837;&#38498;&#39044;&#27979;&#36827;&#34892;&#36866;&#24403;&#30340;&#35780;&#20272;&#12289;&#25551;&#36848;&#21644;&#29702;&#35299;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26631;&#20934;&#21270;&#19988;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#65292;&#29992;&#20110;&#22312;&#22810;&#20013;&#24515;&#25968;&#25454;&#24211;&#65288;&#21363;&#21253;&#21547;166,355&#21517;&#24739;&#32773;&#30340;eICU&#38431;&#21015;&#65292;200,859&#21517;...&#65289;
&lt;/p&gt;
&lt;p&gt;
The intensive care unit (ICU) comprises a complex hospital environment, where decisions made by clinicians have a high level of risk for the patients' lives. A comprehensive care pathway must then be followed to reduce p complications. Uncertain, competing and unplanned aspects within this environment increase the difficulty in uniformly implementing the care pathway. Readmission contributes to this pathway's difficulty, occurring when patients are admitted again to the ICU in a short timeframe, resulting in high mortality rates and high resource utilisation. Several works have tried to predict readmission through patients' medical information. Although they have some level of success while predicting readmission, those works do not properly assess, characterise and understand readmission prediction. This work proposes a standardised and explainable machine learning pipeline to model patient readmission on a multicentric database (i.e., the eICU cohort with 166,355 patients, 200,859 ad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#38899;&#39057;&#20998;&#31867;&#20219;&#21153;&#20013;&#23398;&#20064;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#21253;&#25324;&#39046;&#22495;&#29305;&#23450;&#30340;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#65292;&#20197;&#21450;&#31471;&#21040;&#31471;&#26550;&#26500;&#65292;&#20026;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.08751</link><description>&lt;p&gt;
&#22810;&#26679;&#30340;&#31070;&#32463;&#38899;&#39057;&#23884;&#20837; - &#24674;&#22797;&#29305;&#24449;&#65281;
&lt;/p&gt;
&lt;p&gt;
Diverse Neural Audio Embeddings -- Bringing Features back !. (arXiv:2309.08751v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#38899;&#39057;&#20998;&#31867;&#20219;&#21153;&#20013;&#23398;&#20064;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#21253;&#25324;&#39046;&#22495;&#29305;&#23450;&#30340;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#65292;&#20197;&#21450;&#31471;&#21040;&#31471;&#26550;&#26500;&#65292;&#20026;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#20195;&#20154;&#24037;&#26234;&#33021;&#26550;&#26500;&#30340;&#20986;&#29616;&#65292;&#20174;&#31471;&#21040;&#31471;&#30340;&#26550;&#26500;&#24320;&#22987;&#27969;&#34892;&#12290;&#36825;&#31181;&#36716;&#21464;&#23548;&#33268;&#20102;&#31070;&#32463;&#26550;&#26500;&#22312;&#27809;&#26377;&#39046;&#22495;&#29305;&#23450;&#20559;&#35265;/&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35757;&#32451;&#65292;&#26681;&#25454;&#20219;&#21153;&#36827;&#34892;&#20248;&#21270;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22810;&#26679;&#30340;&#29305;&#24449;&#34920;&#31034;&#65288;&#22312;&#26412;&#20363;&#20013;&#26159;&#39046;&#22495;&#29305;&#23450;&#30340;&#65289;&#23398;&#20064;&#38899;&#39057;&#23884;&#20837;&#12290;&#23545;&#20110;&#28041;&#21450;&#25968;&#30334;&#31181;&#22768;&#38899;&#20998;&#31867;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#23398;&#20064;&#20998;&#21035;&#38024;&#23545;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#31561;&#22810;&#26679;&#30340;&#38899;&#39057;&#23646;&#24615;&#24314;&#31435;&#31283;&#20581;&#30340;&#23884;&#20837;&#65292;&#21516;&#26102;&#20063;&#36890;&#36807;&#31471;&#21040;&#31471;&#26550;&#26500;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#25163;&#24037;&#21046;&#20316;&#30340;&#23884;&#20837;&#65292;&#20363;&#22914;&#22522;&#20110;&#38899;&#39640;&#21644;&#38899;&#33394;&#30340;&#23884;&#20837;&#65292;&#34429;&#28982;&#21333;&#29420;&#20351;&#29992;&#26102;&#26080;&#27861;&#20987;&#36133;&#23436;&#20840;&#31471;&#21040;&#31471;&#30340;&#34920;&#31034;&#65292;&#20294;&#23558;&#36825;&#20123;&#23884;&#20837;&#19982;&#31471;&#21040;&#31471;&#23884;&#20837;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#36825;&#39033;&#24037;&#20316;&#23558;&#20026;&#22312;&#31471;&#21040;&#31471;&#27169;&#22411;&#20013;&#24341;&#20837;&#19968;&#20123;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#36947;&#36335;&#65292;&#24182;&#36229;&#36234;&#20165;&#35757;&#32451;&#31471;&#21040;&#31471;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the advent of modern AI architectures, a shift has happened towards end-to-end architectures. This pivot has led to neural architectures being trained without domain-specific biases/knowledge, optimized according to the task. We in this paper, learn audio embeddings via diverse feature representations, in this case, domain-specific. For the case of audio classification over hundreds of categories of sound, we learn robust separate embeddings for diverse audio properties such as pitch, timbre, and neural representation, along with also learning it via an end-to-end architecture. We observe handcrafted embeddings, e.g., pitch and timbre-based, although on their own, are not able to beat a fully end-to-end representation, yet adding these together with end-to-end embedding helps us, significantly improve performance. This work would pave the way to bring some domain expertise with end-to-end models to learn robust, diverse representations, surpassing the performance of just training 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;EPNS&#30340;&#31561;&#21464;&#27010;&#29575;&#31070;&#32463;&#27169;&#25311;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31995;&#32479;&#28436;&#21270;&#20013;&#29983;&#25104;&#31561;&#21464;&#20998;&#24067;&#65292;&#24182;&#22312;&#38543;&#26426;&#26102;&#31354;&#21160;&#24577;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2305.14286</link><description>&lt;p&gt;
&#31561;&#21464;&#31070;&#32463;&#27169;&#25311;&#22120;&#29992;&#20110;&#38543;&#26426;&#26102;&#31354;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Equivariant Neural Simulators for Stochastic Spatiotemporal Dynamics. (arXiv:2305.14286v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;EPNS&#30340;&#31561;&#21464;&#27010;&#29575;&#31070;&#32463;&#27169;&#25311;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31995;&#32479;&#28436;&#21270;&#20013;&#29983;&#25104;&#31561;&#21464;&#20998;&#24067;&#65292;&#24182;&#22312;&#38543;&#26426;&#26102;&#31354;&#21160;&#24577;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#27491;&#22312;&#25104;&#20026;&#21487;&#25193;&#23637;&#30340;&#25968;&#25454;&#39537;&#21160;&#39640;&#32500;&#21160;&#24577;&#31995;&#32479;&#27169;&#25311;&#24037;&#20855;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#20540;&#26041;&#27861;&#19981;&#21487;&#34892;&#25110;&#35745;&#31639;&#26114;&#36149;&#30340;&#24773;&#20917;&#19979;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#24050;&#32463;&#35777;&#26126;&#22312;&#30830;&#23450;&#24615;&#31070;&#32463;&#27169;&#25311;&#22120;&#20013;&#24341;&#20837;&#22495;&#23545;&#31216;&#24615;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#20854;&#31934;&#30830;&#24615;&#12289;&#26679;&#26412;&#25928;&#29575;&#21644;&#21442;&#25968;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#23558;&#23545;&#31216;&#24615;&#32435;&#20837;&#21487;&#20197;&#27169;&#25311;&#38543;&#26426;&#29616;&#35937;&#30340;&#27010;&#29575;&#31070;&#32463;&#27169;&#25311;&#22120;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#19968;&#20010;&#33021;&#22815;&#29983;&#25104;&#31561;&#21464;&#36712;&#36857;&#20998;&#24067;&#32780;&#19981;&#26159;&#31561;&#21464;&#20989;&#25968;&#36924;&#36817;&#30340;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31561;&#21464;&#27010;&#29575;&#31070;&#32463;&#27169;&#25311;&#65288;EPNS&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#31561;&#21464;&#20998;&#24067;&#31995;&#32479;&#28436;&#21270;&#30340;&#33258;&#22238;&#24402;&#27010;&#29575;&#24314;&#27169;&#26694;&#26550;&#12290;&#25105;&#20204;&#20351;&#29992;EPNS&#35774;&#35745;&#20102;&#19968;&#20010;&#29992;&#20110;&#38543;&#26426;N&#20307;&#31995;&#32479;&#21644;&#38543;&#26426;&#32454;&#32990;&#21160;&#21147;&#23398;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;EPNS&#22312;p&#26041;&#38754;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks are emerging as a tool for scalable data-driven simulation of high-dimensional dynamical systems, especially in settings where numerical methods are infeasible or computationally expensive. Notably, it has been shown that incorporating domain symmetries in deterministic neural simulators can substantially improve their accuracy, sample efficiency, and parameter efficiency. However, to incorporate symmetries in probabilistic neural simulators that can simulate stochastic phenomena, we need a model that produces equivariant distributions over trajectories, rather than equivariant function approximations. In this paper, we propose Equivariant Probabilistic Neural Simulation (EPNS), a framework for autoregressive probabilistic modeling of equivariant distributions over system evolutions. We use EPNS to design models for a stochastic n-body system and stochastic cellular dynamics. Our results show that EPNS considerably outperforms existing neural network-based methods for p
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#20102;&#23545;&#20110;&#35757;&#32451;&#33391;&#22909;&#30340;AI&#27169;&#22411;&#65292;&#22914;&#26524;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#65292;&#23558;&#20986;&#29616;&#31232;&#30095;&#20132;&#20114;&#27010;&#24565;&#65292;&#36825;&#20123;&#27010;&#24565;&#33021;&#22815;&#25551;&#36848;&#36755;&#20837;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#23545;&#27169;&#22411;&#25512;&#29702;&#20998;&#25968;&#20135;&#29983;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.01939</link><description>&lt;p&gt;
&#35777;&#26126;AI&#27169;&#22411;&#20013;&#31232;&#30095;&#31526;&#21495;&#27010;&#24565;&#30340;&#20986;&#29616;
&lt;/p&gt;
&lt;p&gt;
Where We Have Arrived in Proving the Emergence of Sparse Symbolic Concepts in AI Models. (arXiv:2305.01939v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01939
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#20102;&#23545;&#20110;&#35757;&#32451;&#33391;&#22909;&#30340;AI&#27169;&#22411;&#65292;&#22914;&#26524;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#65292;&#23558;&#20986;&#29616;&#31232;&#30095;&#20132;&#20114;&#27010;&#24565;&#65292;&#36825;&#20123;&#27010;&#24565;&#33021;&#22815;&#25551;&#36848;&#36755;&#20837;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#23545;&#27169;&#22411;&#25512;&#29702;&#20998;&#25968;&#20135;&#29983;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35777;&#26126;&#35757;&#32451;&#33391;&#22909;&#30340;AI&#27169;&#22411;&#20013;&#20986;&#29616;&#31526;&#21495;&#27010;&#24565;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#65288;1&#65289;&#27169;&#22411;&#36755;&#20986;&#30456;&#23545;&#20110;&#36755;&#20837;&#21464;&#37327;&#30340;&#39640;&#38454;&#23548;&#25968;&#22343;&#20026;&#38646;&#65292;&#65288;2&#65289;AI&#27169;&#22411;&#21487;&#29992;&#20110;&#36974;&#25377;&#26679;&#26412;&#19988;&#36755;&#20837;&#26679;&#26412;&#36739;&#23569;&#36974;&#25377;&#26102;&#20250;&#20135;&#29983;&#26356;&#39640;&#30340;&#32622;&#20449;&#24230;&#65292;&#65288;3&#65289;AI&#27169;&#22411;&#22312;&#36974;&#25377;&#26679;&#26412;&#19978;&#30340;&#32622;&#20449;&#24230;&#24182;&#19981;&#20250;&#26174;&#33879;&#38477;&#20302;&#65292;&#21017;AI&#27169;&#22411;&#23558;&#32534;&#30721;&#31232;&#30095;&#20132;&#20114;&#27010;&#24565;&#12290;&#27599;&#20010;&#20132;&#20114;&#27010;&#24565;&#34920;&#31034;&#29305;&#23450;&#19968;&#32452;&#36755;&#20837;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#23545;&#27169;&#22411;&#25512;&#29702;&#20998;&#25968;&#20135;&#29983;&#19968;&#23450;&#30340;&#25968;&#20540;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#27169;&#22411;&#30340;&#25512;&#29702;&#20998;&#25968;&#24635;&#26159;&#21487;&#20197;&#34920;&#31034;&#20026;&#25152;&#26377;&#20132;&#20114;&#27010;&#24565;&#30340;&#20132;&#20114;&#25928;&#24212;&#20043;&#21644;&#12290;&#20107;&#23454;&#19978;&#65292;&#25105;&#20204;&#24076;&#26395;&#35777;&#26126;&#20986;&#29616;&#31526;&#21495;&#27010;&#24565;&#30340;&#26465;&#20214;&#38750;&#24120;&#26222;&#36941;&#12290;&#36825;&#24847;&#21619;&#30528;&#23545;&#20110;&#22823;&#22810;&#25968;AI&#27169;&#22411;&#65292;&#25105;&#20204;&#36890;&#24120;&#21487;&#20197;&#20351;&#29992;&#23569;&#37327;&#30340;&#20132;&#20114;&#27010;&#24565;&#26469;&#27169;&#25311;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper aims to prove the emergence of symbolic concepts in well-trained AI models. We prove that if (1) the high-order derivatives of the model output w.r.t. the input variables are all zero, (2) the AI model can be used on occluded samples and will yield higher confidence when the input sample is less occluded, and (3) the confidence of the AI model does not significantly degrade on occluded samples, then the AI model will encode sparse interactive concepts. Each interactive concept represents an interaction between a specific set of input variables, and has a certain numerical effect on the inference score of the model. Specifically, it is proved that the inference score of the model can always be represented as the sum of the interaction effects of all interactive concepts. In fact, we hope to prove that conditions for the emergence of symbolic concepts are quite common. It means that for most AI models, we can usually use a small number of interactive concepts to mimic the mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#26500;&#24314;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#33021;&#22815;&#23545;&#23450;&#20041;&#22312;&#36825;&#20123;&#31354;&#38388;&#19978;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#23454;&#38469;&#37319;&#26679;&#21644;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#12290;</title><link>http://arxiv.org/abs/2301.13088</link><description>&lt;p&gt;
Lie &#32676;&#21644;&#23427;&#20204;&#30340;&#40784;&#27425;&#31354;&#38388;&#19978;&#30340;&#38745;&#27490;&#26680;&#21644;&#39640;&#26031;&#36807;&#31243; II&#65306;&#38750;&#32039;&#23545;&#31216;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces II: non-compact symmetric spaces. (arXiv:2301.13088v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#26500;&#24314;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#33021;&#22815;&#23545;&#23450;&#20041;&#22312;&#36825;&#20123;&#31354;&#38388;&#19978;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#23454;&#38469;&#37319;&#26679;&#21644;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26102;&#31354;&#27169;&#22411;&#20043;&#19968;&#65292;&#23427;&#21487;&#20197;&#32534;&#30721;&#26377;&#20851;&#24314;&#27169;&#20989;&#25968;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#24182;&#21487;&#29992;&#20110;&#31934;&#30830;&#25110;&#36817;&#20284;&#36125;&#21494;&#26031;&#23398;&#20064;&#12290;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#29289;&#29702;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#65292;&#20197;&#21450;&#22320;&#36136;&#32479;&#35745;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#65292;&#23545;&#23545;&#31216;&#24615;&#30340;&#19981;&#21464;&#24615;&#26159;&#21487;&#20197;&#32771;&#34385;&#30340;&#26368;&#22522;&#26412;&#24418;&#24335;&#20043;&#19968;&#12290;&#39640;&#26031;&#36807;&#31243;&#21327;&#26041;&#24046;&#23545;&#36825;&#20123;&#23545;&#31216;&#24615;&#30340;&#19981;&#21464;&#24615;&#24341;&#21457;&#20102;&#23545;&#36825;&#20123;&#31354;&#38388;&#30340;&#24179;&#31283;&#24615;&#27010;&#24565;&#30340;&#26368;&#33258;&#28982;&#30340;&#25512;&#24191;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#24314;&#31435;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#26500;&#36896;&#24615;&#21644;&#23454;&#29992;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23545;&#31216;&#24615;&#32972;&#26223;&#19979;&#20986;&#29616;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#38750;&#24120;&#22823;&#30340;&#31867;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#20351;&#24471;&#33021;&#22815;&#65288;i&#65289;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#21644;&#65288;ii&#65289;&#20174;&#36825;&#20123;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#20013;&#23454;&#38469;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are arguably the most important class of spatiotemporal models within machine learning. They encode prior information about the modeled function and can be used for exact or approximate Bayesian learning. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process' covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is 
&lt;/p&gt;</description></item></channel></rss>