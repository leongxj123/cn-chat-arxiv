<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36229;&#21442;&#25968;&#23545;&#20110;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#34987;&#24378;&#35843;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28041;&#21450;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#35780;&#20272;&#38454;&#27573;&#30340;&#35780;&#20272;&#21327;&#35758;&#12290;</title><link>https://arxiv.org/abs/2403.09066</link><description>&lt;p&gt;
Continual Learning&#20013;&#30340;&#36229;&#21442;&#25968;&#65306;&#29616;&#23454;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Hyperparameters in Continual Learning: a Reality Check
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09066
&lt;/p&gt;
&lt;p&gt;
&#36229;&#21442;&#25968;&#23545;&#20110;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#34987;&#24378;&#35843;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28041;&#21450;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#35780;&#20272;&#38454;&#27573;&#30340;&#35780;&#20272;&#21327;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#36830;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#31639;&#27861;&#26088;&#22312;&#22312;CL&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#32531;&#35299;&#31283;&#23450;&#24615;&#21644;&#21487;&#22609;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#35843;&#25972;&#27599;&#31181;&#31639;&#27861;&#30340;&#36866;&#24403;&#36229;&#21442;&#25968;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#12290;&#26412;&#25991;&#20027;&#24352;&#29616;&#34892;&#30340;&#35780;&#20272;&#21327;&#35758;&#26082;&#19981;&#20999;&#23454;&#38469;&#65292;&#20063;&#26080;&#27861;&#26377;&#25928;&#35780;&#20272;&#36830;&#32493;&#23398;&#20064;&#31639;&#27861;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09066v1 Announce Type: new  Abstract: Various algorithms for continual learning (CL) have been designed with the goal of effectively alleviating the trade-off between stability and plasticity during the CL process. To achieve this goal, tuning appropriate hyperparameters for each algorithm is essential. As an evaluation protocol, it has been common practice to train a CL algorithm using diverse hyperparameter values on a CL scenario constructed with a benchmark dataset. Subsequently, the best performance attained with the optimal hyperparameter value serves as the criterion for evaluating the CL algorithm. In this paper, we contend that this evaluation protocol is not only impractical but also incapable of effectively assessing the CL capability of a CL algorithm. Returning to the fundamental principles of model evaluation in machine learning, we propose an evaluation protocol that involves Hyperparameter Tuning and Evaluation phases. Those phases consist of different datase
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#20540;&#20272;&#35745;&#30340;&#31283;&#20581;&#26799;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#38024;&#23545;&#21253;&#25324;&#37325;&#23614;&#22122;&#22768;&#22312;&#20869;&#30340;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#36827;&#34892;&#20102;&#25506;&#35752;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#24418;&#24335;&#30340;&#21098;&#20999;&#26041;&#27861;&#23454;&#38469;&#19978;&#26159;&#35813;&#26041;&#27861;&#30340;&#29305;&#20363;&#12290;</title><link>https://arxiv.org/abs/2402.12828</link><description>&lt;p&gt;
SGD&#26799;&#24230;&#21098;&#20999;&#26041;&#27861;&#26263;&#20013;&#20272;&#35745;&#20013;&#20540;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
SGD with Clipping is Secretly Estimating the Median Gradient
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#20540;&#20272;&#35745;&#30340;&#31283;&#20581;&#26799;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#38024;&#23545;&#21253;&#25324;&#37325;&#23614;&#22122;&#22768;&#22312;&#20869;&#30340;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#36827;&#34892;&#20102;&#25506;&#35752;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#24418;&#24335;&#30340;&#21098;&#20999;&#26041;&#27861;&#23454;&#38469;&#19978;&#26159;&#35813;&#26041;&#27861;&#30340;&#29305;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#20960;&#31181;&#38543;&#26426;&#20248;&#21270;&#30340;&#24212;&#29992;&#22330;&#26223;&#21487;&#20197;&#21463;&#30410;&#20110;&#23545;&#26799;&#24230;&#30340;&#31283;&#20581;&#20272;&#35745;&#12290;&#20363;&#22914;&#65292;&#22312;&#20855;&#26377;&#25439;&#22351;&#33410;&#28857;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#39046;&#22495;&#12289;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#22823;&#30340;&#24322;&#24120;&#20540;&#12289;&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#23398;&#20064;&#65292;&#29978;&#33267;&#30001;&#20110;&#31639;&#27861;&#21160;&#24577;&#26412;&#36523;&#30340;&#37325;&#23614;&#22122;&#22768;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20013;&#20540;&#20272;&#35745;&#30340;&#31283;&#20581;&#26799;&#24230;&#20272;&#35745;&#30340;SGD&#12290;&#39318;&#20808;&#32771;&#34385;&#36328;&#26679;&#26412;&#35745;&#31639;&#20013;&#20540;&#26799;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126;&#21363;&#20351;&#22312;&#37325;&#23614;&#12289;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#19979;&#65292;&#35813;&#26041;&#27861;&#20063;&#33021;&#25910;&#25947;&#12290;&#28982;&#21518;&#25105;&#20204;&#25512;&#23548;&#20102;&#22522;&#20110;&#38543;&#26426;&#36817;&#31471;&#28857;&#26041;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#20960;&#20309;&#20013;&#20540;&#21644;&#20854;&#25512;&#24191;&#24418;&#24335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#36845;&#20195;&#38388;&#30340;&#20013;&#20540;&#26799;&#24230;&#65292;&#24182;&#21457;&#29616;&#20960;&#31181;&#20247;&#25152;&#21608;&#30693;&#30340;&#26041;&#27861; - &#29305;&#21035;&#26159;&#19981;&#21516;&#24418;&#24335;&#30340;&#21098;&#20999; - &#26159;&#36825;&#19968;&#26694;&#26550;&#30340;&#29305;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12828v1 Announce Type: cross  Abstract: There are several applications of stochastic optimization where one can benefit from a robust estimate of the gradient. For example, domains such as distributed learning with corrupted nodes, the presence of large outliers in the training data, learning under privacy constraints, or even heavy-tailed noise due to the dynamics of the algorithm itself. Here we study SGD with robust gradient estimators based on estimating the median. We first consider computing the median gradient across samples, and show that the resulting method can converge even under heavy-tailed, state-dependent noise. We then derive iterative methods based on the stochastic proximal point method for computing the geometric median and generalizations thereof. Finally we propose an algorithm estimating the median gradient across iterations, and find that several well known methods - in particular different forms of clipping - are particular cases of this framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.13966</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26368;&#20248;&#26497;&#23567;&#21270;&#20256;&#36882;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Transfer Learning for Kernel-based Nonparametric Regression. (arXiv:2310.13966v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20256;&#36882;&#23398;&#20064;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#21463;&#21040;&#20102;&#24456;&#22823;&#20851;&#27880;&#12290;&#23427;&#33021;&#22815;&#21033;&#29992;&#30456;&#20851;&#30740;&#31350;&#30340;&#30693;&#35782;&#26469;&#25552;&#39640;&#30446;&#26631;&#30740;&#31350;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20351;&#20854;&#20855;&#26377;&#24456;&#39640;&#30340;&#21560;&#24341;&#21147;&#12290;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#30446;&#30340;&#26159;&#32553;&#23567;&#23454;&#38469;&#25928;&#26524;&#19982;&#29702;&#35770;&#20445;&#35777;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32771;&#34385;&#20102;&#20004;&#31181;&#24773;&#20917;&#65306;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#21644;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#26680;&#20272;&#35745;&#22120;&#65292;&#20165;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#12290;&#23545;&#20110;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#25928;&#32858;&#21512;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26816;&#27979;&#24182;&#20943;&#36731;&#36127;&#38754;&#26469;&#28304;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25152;&#38656;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#65292;&#24182;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, transfer learning has garnered significant attention in the machine learning community. Its ability to leverage knowledge from related studies to improve generalization performance in a target study has made it highly appealing. This paper focuses on investigating the transfer learning problem within the context of nonparametric regression over a reproducing kernel Hilbert space. The aim is to bridge the gap between practical effectiveness and theoretical guarantees. We specifically consider two scenarios: one where the transferable sources are known and another where they are unknown. For the known transferable source case, we propose a two-step kernel-based estimator by solely using kernel ridge regression. For the unknown case, we develop a novel method based on an efficient aggregation algorithm, which can automatically detect and alleviate the effects of negative sources. This paper provides the statistical properties of the desired estimators and establishes the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;Richards&#26041;&#31243;&#25968;&#20540;&#35299;&#27861;&#65292;&#31216;&#20026;D-GRW&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#33258;&#36866;&#24212;&#32447;&#24615;&#21270;&#26041;&#26696;&#12289;&#31070;&#32463;&#32593;&#32476;&#21644;&#20840;&#23616;&#38543;&#26426;&#28216;&#36208;&#65292;&#22312;&#26377;&#38480;&#20307;&#31215;&#31163;&#25955;&#21270;&#26694;&#26550;&#19979;&#65292;&#33021;&#22815;&#20135;&#29983;&#20855;&#26377;&#25910;&#25947;&#24615;&#20445;&#35777;&#30340;Richards&#26041;&#31243;&#25968;&#20540;&#35299;&#65292;&#24182;&#22312;&#31934;&#24230;&#21644;&#36136;&#37327;&#23432;&#24658;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#21331;&#36234;&#12290;</title><link>http://arxiv.org/abs/2310.02806</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;Richards&#26041;&#31243;&#25968;&#20540;&#35299;&#27861;&#65292;&#29992;&#20110;&#27169;&#25311;&#22303;&#22756;&#20013;&#30340;&#27700;&#27969;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
A Data-facilitated Numerical Method for Richards Equation to Model Water Flow Dynamics in Soil. (arXiv:2310.02806v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;Richards&#26041;&#31243;&#25968;&#20540;&#35299;&#27861;&#65292;&#31216;&#20026;D-GRW&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#33258;&#36866;&#24212;&#32447;&#24615;&#21270;&#26041;&#26696;&#12289;&#31070;&#32463;&#32593;&#32476;&#21644;&#20840;&#23616;&#38543;&#26426;&#28216;&#36208;&#65292;&#22312;&#26377;&#38480;&#20307;&#31215;&#31163;&#25955;&#21270;&#26694;&#26550;&#19979;&#65292;&#33021;&#22815;&#20135;&#29983;&#20855;&#26377;&#25910;&#25947;&#24615;&#20445;&#35777;&#30340;Richards&#26041;&#31243;&#25968;&#20540;&#35299;&#65292;&#24182;&#22312;&#31934;&#24230;&#21644;&#36136;&#37327;&#23432;&#24658;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#21331;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26681;&#21306;&#22303;&#22756;&#28287;&#24230;&#30340;&#30417;&#27979;&#23545;&#20110;&#31934;&#23494;&#20892;&#19994;&#12289;&#26234;&#33021;&#28748;&#28297;&#21644;&#24178;&#26097;&#39044;&#38450;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#24120;&#36890;&#36807;&#27714;&#35299;Richards&#26041;&#31243;&#36825;&#26679;&#30340;&#27700;&#25991;&#27169;&#22411;&#26469;&#27169;&#25311;&#22303;&#22756;&#30340;&#26102;&#31354;&#27700;&#27969;&#21160;&#21147;&#23398;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;&#25968;&#25454;&#30340;Richards&#26041;&#31243;&#25968;&#20540;&#35299;&#27861;&#12290;&#36825;&#31181;&#25968;&#20540;&#35299;&#27861;&#34987;&#31216;&#20026;D-GRW&#65288;Data-facilitated global Random Walk&#65289;&#26041;&#27861;&#65292;&#23427;&#22312;&#26377;&#38480;&#20307;&#31215;&#31163;&#25955;&#21270;&#26694;&#26550;&#20013;&#21327;&#21516;&#22320;&#25972;&#21512;&#20102;&#33258;&#36866;&#24212;&#32447;&#24615;&#21270;&#26041;&#26696;&#12289;&#31070;&#32463;&#32593;&#32476;&#21644;&#20840;&#23616;&#38543;&#26426;&#28216;&#36208;&#65292;&#21487;&#20197;&#22312;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#20135;&#29983;&#31934;&#30830;&#30340;Richards&#26041;&#31243;&#25968;&#20540;&#35299;&#65292;&#24182;&#19988;&#20855;&#26377;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#36890;&#36807;&#19977;&#20010;&#31034;&#20363;&#65292;&#25105;&#20204;&#23637;&#31034;&#21644;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;D-GRW&#26041;&#27861;&#22312;&#31934;&#24230;&#21644;&#36136;&#37327;&#23432;&#24658;&#24615;&#33021;&#26041;&#38754;&#30340;&#21331;&#36234;&#34920;&#29616;&#65292;&#24182;&#23558;&#20854;&#19982;&#22522;&#20934;&#25968;&#20540;&#35299;&#27861;&#21644;&#21830;&#29992;&#36719;&#20214;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Root-zone soil moisture monitoring is essential for precision agriculture, smart irrigation, and drought prevention. Modeling the spatiotemporal water flow dynamics in soil is typically achieved by solving a hydrological model, such as the Richards equation which is a highly nonlinear partial differential equation (PDE). In this paper, we present a novel data-facilitated numerical method for solving the mixed-form Richards equation. This numerical method, which we call the D-GRW (Data-facilitated global Random Walk) method, synergistically integrates adaptive linearization scheme, neural networks, and global random walk in a finite volume discretization framework to produce accurate numerical solutions of the Richards equation with guaranteed convergence under reasonable assumptions. Through three illustrative examples, we demonstrate and discuss the superior accuracy and mass conservation performance of our D-GRW method and compare it with benchmark numerical methods and commercial so
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37096;&#20998;&#21487;&#35266;&#27979;&#38543;&#26426;&#21338;&#24328;&#30340;&#21487;&#35777;&#26126;&#22810;Agent&#24378;&#21270;&#23398;&#20064;&#12290;&#36890;&#36807;&#20449;&#24687;&#20849;&#20139;&#21644;&#35266;&#27979;&#21487;&#33021;&#24615;&#20551;&#35774;&#65292;&#25552;&#20986;&#20102;&#26500;&#24314;&#36817;&#20284;&#27169;&#22411;&#20197;&#23454;&#29616;&#20934;&#25928;&#29575;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.08705</link><description>&lt;p&gt;
&#37096;&#20998;&#21487;&#35266;&#27979;&#30340;&#22810;Agent&#24378;&#21270;&#23398;&#20064;&#19982;&#65288;&#20934;&#65289;&#25928;&#29575;&#65306;&#20449;&#24687;&#20849;&#20139;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing. (arXiv:2308.08705v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37096;&#20998;&#21487;&#35266;&#27979;&#38543;&#26426;&#21338;&#24328;&#30340;&#21487;&#35777;&#26126;&#22810;Agent&#24378;&#21270;&#23398;&#20064;&#12290;&#36890;&#36807;&#20449;&#24687;&#20849;&#20139;&#21644;&#35266;&#27979;&#21487;&#33021;&#24615;&#20551;&#35774;&#65292;&#25552;&#20986;&#20102;&#26500;&#24314;&#36817;&#20284;&#27169;&#22411;&#20197;&#23454;&#29616;&#20934;&#25928;&#29575;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37096;&#20998;&#21487;&#35266;&#27979;&#38543;&#26426;&#21338;&#24328;&#65288;POSGs&#65289;&#30340;&#21487;&#35777;&#26126;&#22810;Agent&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#12290;&#20026;&#20102;&#35268;&#36991;&#24050;&#30693;&#30340;&#38590;&#24230;&#38382;&#39064;&#21644;&#20351;&#29992;&#35745;&#31639;&#19981;&#21487;&#34892;&#30340;&#39044;&#35328;&#26426;&#65292;&#25105;&#20204;&#20513;&#23548;&#21033;&#29992;Agent&#20043;&#38388;&#30340;&#28508;&#22312;&#8220;&#20449;&#24687;&#20849;&#20139;&#8221;&#65292;&#36825;&#26159;&#23454;&#35777;MARL&#20013;&#30340;&#24120;&#35265;&#20570;&#27861;&#65292;&#20063;&#26159;&#20855;&#22791;&#36890;&#20449;&#21151;&#33021;&#30340;&#22810;Agent&#25511;&#21046;&#31995;&#32479;&#30340;&#26631;&#20934;&#27169;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#33509;&#24178;&#35745;&#31639;&#22797;&#26434;&#24615;&#32467;&#26524;&#65292;&#26469;&#35777;&#26126;&#20449;&#24687;&#20849;&#20139;&#30340;&#24517;&#35201;&#24615;&#65292;&#20197;&#21450;&#35266;&#27979;&#21487;&#33021;&#24615;&#20551;&#35774;&#20026;&#20102;&#27714;&#35299;POSGs&#20013;&#30340;&#35745;&#31639;&#25928;&#29575;&#24050;&#32463;&#20351;&#24471;&#37096;&#20998;&#21487;&#35266;&#27979;&#30340;&#21333;Agent&#24378;&#21270;&#23398;&#20064;&#20855;&#26377;&#20934;&#25928;&#29575;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#36827;&#19968;&#27493;&#8220;&#36817;&#20284;&#8221;&#20849;&#20139;&#30340;&#20844;&#20849;&#20449;&#24687;&#26500;&#24314;POSG&#30340;&#8220;&#36817;&#20284;&#27169;&#22411;&#8221;&#65292;&#22312;&#35813;&#27169;&#22411;&#20013;&#35745;&#21010;&#19968;&#20010;&#36817;&#20284;&#22343;&#34913;&#65288;&#20174;&#35299;&#20915;&#21407;&#22987;POSG&#30340;&#35282;&#24230;&#65289;&#21487;&#20197;&#23454;&#29616;&#20934;&#25928;&#29575;&#65292;&#21363;&#20934;&#22810;&#39033;&#24335;&#26102;&#38388;&#65292;&#21069;&#25552;&#26159;&#19978;&#36848;&#20551;&#35774;&#28385;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermo
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#39044;&#27979;&#32534;&#30721;&#30340;&#33041;&#21551;&#21457;&#24335;&#35745;&#31639;&#26234;&#33021;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#30340;&#19968;&#20123;&#37325;&#35201;&#38480;&#21046;&#65292;&#24182;&#20855;&#26377;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#26377;&#24076;&#26395;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.07870</link><description>&lt;p&gt;
&#36890;&#36807;&#39044;&#27979;&#32534;&#30721;&#23454;&#29616;&#33041;&#21551;&#21457;&#24335;&#35745;&#31639;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
Brain-Inspired Computational Intelligence via Predictive Coding. (arXiv:2308.07870v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07870
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#39044;&#27979;&#32534;&#30721;&#30340;&#33041;&#21551;&#21457;&#24335;&#35745;&#31639;&#26234;&#33021;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#30340;&#19968;&#20123;&#37325;&#35201;&#38480;&#21046;&#65292;&#24182;&#20855;&#26377;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#26377;&#24076;&#26395;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27491;&#22312;&#36805;&#36895;&#25104;&#20026;&#26412;&#19990;&#32426;&#30340;&#20851;&#38190;&#25216;&#26415;&#20043;&#19968;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#22312;AI&#39046;&#22495;&#21462;&#24471;&#30340;&#22823;&#37096;&#20998;&#25104;&#26524;&#37117;&#26159;&#20351;&#29992;&#35823;&#24046;&#21453;&#21521;&#20256;&#25773;&#23398;&#20064;&#31639;&#27861;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25152;&#23454;&#29616;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#26222;&#21450;&#24212;&#29992;&#24050;&#32463;&#20984;&#26174;&#20986;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#35745;&#31639;&#25104;&#26412;&#39640;&#12289;&#38590;&#20197;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12289;&#32570;&#20047;&#40065;&#26834;&#24615;&#12289;&#19981;&#21487;&#38752;&#24615;&#21644;&#29983;&#29289;&#23398;&#19978;&#30340;&#19981;&#21512;&#29702;&#24615;&#12290;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#21487;&#33021;&#38656;&#35201;&#21463;&#21040;&#31070;&#32463;&#31185;&#23398;&#29702;&#35770;&#30340;&#21551;&#21457;&#21644;&#25351;&#23548;&#30340;&#26041;&#26696;&#12290;&#20854;&#20013;&#19968;&#31181;&#29702;&#35770;&#31216;&#20026;&#39044;&#27979;&#32534;&#30721;&#65288;PC&#65289;&#65292;&#22312;&#26426;&#22120;&#26234;&#33021;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#65292;&#20855;&#26377;&#20196;&#20154;&#20852;&#22859;&#30340;&#29305;&#24615;&#65292;&#20351;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#20215;&#20540;&#65306;PC&#21487;&#20197;&#27169;&#25311;&#19981;&#21516;&#33041;&#21306;&#30340;&#20449;&#24687;&#22788;&#29702;&#65292;&#21487;&#20197;&#29992;&#20110;&#35748;&#30693;&#25511;&#21046;&#21644;&#26426;&#22120;&#20154;&#25216;&#26415;&#65292;&#24182;&#22312;&#21464;&#20998;&#25512;&#29702;&#26041;&#38754;&#20855;&#26377;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence (AI) is rapidly becoming one of the key technologies of this century. The majority of results in AI thus far have been achieved using deep neural networks trained with the error backpropagation learning algorithm. However, the ubiquitous adoption of this approach has highlighted some important limitations such as substantial computational cost, difficulty in quantifying uncertainty, lack of robustness, unreliability, and biological implausibility. It is possible that addressing these limitations may require schemes that are inspired and guided by neuroscience theories. One such theory, called predictive coding (PC), has shown promising performance in machine intelligence tasks, exhibiting exciting properties that make it potentially valuable for the machine learning community: PC can model information processing in different brain areas, can be used in cognitive control and robotics, and has a solid mathematical grounding in variational inference, offering a pow
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;&#30340;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#20132;&#21270;&#30340;&#24378;&#20581;Fitted-Q&#36845;&#20195;&#65292;&#24182;&#28155;&#21152;&#20102;&#20998;&#20301;&#25968;&#20272;&#35745;&#30340;&#20559;&#24046;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2302.00662</link><description>&lt;p&gt;
&#24378;&#20581;&#30340;Fitted-Q&#35780;&#20272;&#21644;&#36845;&#20195;&#22312;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;
&lt;/p&gt;
&lt;p&gt;
Robust Fitted-Q-Evaluation and Iteration under Sequentially Exogenous Unobserved Confounders. (arXiv:2302.00662v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00662
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;&#30340;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#20132;&#21270;&#30340;&#24378;&#20581;Fitted-Q&#36845;&#20195;&#65292;&#24182;&#28155;&#21152;&#20102;&#20998;&#20301;&#25968;&#20272;&#35745;&#30340;&#20559;&#24046;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#12289;&#32463;&#27982;&#21644;&#30005;&#23376;&#21830;&#21153;&#31561;&#39046;&#22495;&#65292;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#22312;&#32447;&#23454;&#39564;&#21487;&#33021;&#25104;&#26412;&#39640;&#26114;&#12289;&#21361;&#38505;&#25110;&#19981;&#36947;&#24503;&#65292;&#24182;&#19988;&#30495;&#23454;&#27169;&#22411;&#26410;&#30693;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#20551;&#35774;&#34892;&#20026;&#31574;&#30053;&#30340;&#25152;&#26377;&#21327;&#21464;&#37327;&#37117;&#26159;&#24050;&#35266;&#23519;&#21040;&#30340;&#12290;&#23613;&#31649;&#36825;&#20010;&#20551;&#35774;"&#39034;&#24207;&#21487;&#24573;&#30053;&#24615;"&#22312;&#35266;&#23519;&#25968;&#25454;&#20013;&#19981;&#22826;&#21487;&#33021;&#25104;&#31435;&#65292;&#20294;&#22823;&#37096;&#20998;&#32771;&#34385;&#36827;&#20837;&#27835;&#30103;&#22240;&#32032;&#30340;&#25968;&#25454;&#21487;&#33021;&#26159;&#35266;&#23519;&#21040;&#30340;&#65292;&#36825;&#28608;&#21169;&#20102;&#25935;&#24863;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25935;&#24863;&#24615;&#27169;&#22411;&#19979;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;&#30340;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#27491;&#20132;&#21270;&#30340;&#24378;&#20581;Fitted-Q&#36845;&#20195;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#24378;&#20581;&#36125;&#23572;&#26364;&#31639;&#23376;&#30340;&#23553;&#38381;&#24418;&#24335;&#35299;&#26469;&#23548;&#20986;&#24378;&#20581;Q&#20989;&#25968;&#30340;&#25439;&#22833;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#23545;&#20998;&#20301;&#25968;&#20272;&#35745;&#21152;&#20837;&#20559;&#24046;&#26657;&#27491;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20860;&#20855;Fitted-Q&#36845;&#20195;&#30340;&#35745;&#31639;&#31616;&#20415;&#24615;&#21644;&#32479;&#35745;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning is important in domains such as medicine, economics, and e-commerce where online experimentation is costly, dangerous or unethical, and where the true model is unknown. However, most methods assume all covariates used in the behavior policy's action decisions are observed. Though this assumption, sequential ignorability/unconfoundedness, likely does not hold in observational data, most of the data that accounts for selection into treatment may be observed, motivating sensitivity analysis. We study robust policy evaluation and policy optimization in the presence of sequentially-exogenous unobserved confounders under a sensitivity model. We propose and analyze orthogonalized robust fitted-Q-iteration that uses closed-form solutions of the robust Bellman operator to derive a loss minimization problem for the robust Q function, and adds a bias-correction to quantile estimation. Our algorithm enjoys the computational ease of fitted-Q-iteration and statistical 
&lt;/p&gt;</description></item></channel></rss>