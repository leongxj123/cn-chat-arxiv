<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;SAMMO&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#32534;&#35793;&#26102;&#20248;&#21270;&#20803;&#25552;&#31034;&#31243;&#24207;&#65292;&#25552;&#39640;&#20102;&#22797;&#26434;&#25552;&#31034;&#22312;&#22810;&#31181;&#19981;&#21516;LLM&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.02319</link><description>&lt;p&gt;
Prompt&#20316;&#20026;&#31243;&#24207;&#65306;&#19968;&#31181;&#32467;&#26500;&#24863;&#30693;&#30340;&#39640;&#25928;&#32534;&#35793;&#26102;Prompt&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02319
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;SAMMO&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#32534;&#35793;&#26102;&#20248;&#21270;&#20803;&#25552;&#31034;&#31243;&#24207;&#65292;&#25552;&#39640;&#20102;&#22797;&#26434;&#25552;&#31034;&#22312;&#22810;&#31181;&#19981;&#21516;LLM&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#29616;&#22312;&#33021;&#22788;&#29702;&#26356;&#38271;&#26356;&#22797;&#26434;&#30340;&#36755;&#20837;&#65292;&#36825;&#20419;&#36827;&#20102;&#26356;&#22797;&#26434;&#25552;&#31034;&#30340;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#25552;&#31034;&#36890;&#24120;&#38656;&#35201;&#19968;&#20123;&#35843;&#25972;&#20197;&#25552;&#39640;&#37096;&#32626;&#24615;&#33021;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#33258;&#21160;&#25552;&#31034;&#20248;&#21270;&#26041;&#27861;&#65292;&#20294;&#38543;&#30528;&#25552;&#31034;&#22797;&#26434;&#24230;&#21644;LLM&#24378;&#24230;&#30340;&#22686;&#21152;&#65292;&#35768;&#22810;&#25552;&#31034;&#20248;&#21270;&#25216;&#26415;&#24050;&#19981;&#20877;&#36275;&#22815;&#65292;&#38656;&#35201;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#20248;&#21270;&#20803;&#25552;&#31034;&#31243;&#24207;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SAMMO&#65292;&#19968;&#20010;&#29992;&#20110;&#20803;&#25552;&#31034;&#31243;&#24207;&#30340;{\em &#32534;&#35793;&#26102;}&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#23427;&#23558;&#25552;&#31034;&#34920;&#31034;&#20026;&#32467;&#26500;&#21270;&#23545;&#35937;&#65292;&#20801;&#35768;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#25628;&#32034;&#19968;&#32452;&#20016;&#23500;&#30340;&#36716;&#25442;&#12290;&#25105;&#20204;&#23637;&#31034;SAMMO&#25512;&#24191;&#20102;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#22312;&#25351;&#20196;&#35843;&#25972;&#12289;RAG&#31649;&#32447;&#35843;&#25972;&#21644;&#25552;&#31034;&#21387;&#32553;&#26041;&#38754;&#25552;&#39640;&#20102;&#22797;&#26434;&#25552;&#31034;&#22312;&#22810;&#31181;&#19981;&#21516;LLM&#19978;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#24320;&#25918;&#25152;&#26377;&#20195;&#30721;&#20379;&#22823;&#23478;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02319v1 Announce Type: cross  Abstract: Large language models (LLMs) can now handle longer and more complex inputs, which facilitate the use of more elaborate prompts. However, prompts often require some tuning to improve performance for deployment. Recent work has proposed automatic prompt optimization methods, but as prompt complexity and LLM strength increase, many prompt optimization techniques are no longer sufficient and a new approach is needed to optimize {\em meta prompt programs}. To address this, we introduce SAMMO, a framework for {\em compile-time} optimizations of metaprompt programs, which represent prompts as structured objects that allows for a rich set of transformations that can be searched over during optimization. We show that SAMMO generalizes previous methods and improves the performance of complex prompts on (1) instruction tuning, (2) RAG pipeline tuning, and (3) prompt compression, across several different LLMs.   We make all code available open-sou
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#28151;&#21512;&#31574;&#30053;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#39118;&#38505;&#20013;&#24615;&#31574;&#30053;&#21644;&#21487;&#35843;&#25972;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;CVaR&#20248;&#21270;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.11062</link><description>&lt;p&gt;
&#29992;&#20110;&#25552;&#39640;CVaR&#20248;&#21270;&#26679;&#26412;&#25928;&#29575;&#30340;&#31616;&#21333;&#28151;&#21512;&#31574;&#30053;&#21442;&#25968;&#21270;
&lt;/p&gt;
&lt;p&gt;
A Simple Mixture Policy Parameterization for Improving Sample Efficiency of CVaR Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11062
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#28151;&#21512;&#31574;&#30053;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#39118;&#38505;&#20013;&#24615;&#31574;&#30053;&#21644;&#21487;&#35843;&#25972;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;CVaR&#20248;&#21270;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#31574;&#30053;&#26799;&#24230;(PG)&#20248;&#21270;&#26465;&#20214;&#20540;&#39118;&#38505;(CVaR)&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22312;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#26041;&#38754;&#38754;&#20020;&#30528;&#37325;&#22823;&#25361;&#25112;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#28151;&#21512;&#31574;&#30053;&#21442;&#25968;&#21270;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#23558;&#39118;&#38505;&#20013;&#24615;&#31574;&#30053;&#19982;&#21487;&#35843;&#25972;&#31574;&#30053;&#25972;&#21512;&#20026;&#19968;&#20010;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#12290;&#36890;&#36807;&#37319;&#29992;&#36825;&#31181;&#31574;&#30053;&#65292;&#25152;&#26377;&#25910;&#38598;&#21040;&#30340;&#36712;&#36857;&#37117;&#21487;&#20197;&#29992;&#20110;&#31574;&#30053;&#26356;&#26032;&#65292;&#24182;&#19988;&#36890;&#36807;&#39118;&#38505;&#20013;&#24615;&#32452;&#20214;&#21050;&#28608;&#26356;&#39640;&#30340;&#22238;&#25253;&#65292;&#20174;&#32780;&#25552;&#21319;&#23614;&#37096;&#24182;&#38450;&#27490;&#25153;&#24179;&#21270;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#28151;&#21512;&#21442;&#25968;&#21270;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11062v1 Announce Type: new  Abstract: Reinforcement learning algorithms utilizing policy gradients (PG) to optimize Conditional Value at Risk (CVaR) face significant challenges with sample inefficiency, hindering their practical applications. This inefficiency stems from two main facts: a focus on tail-end performance that overlooks many sampled trajectories, and the potential of gradient vanishing when the lower tail of the return distribution is overly flat. To address these challenges, we propose a simple mixture policy parameterization. This method integrates a risk-neutral policy with an adjustable policy to form a risk-averse policy. By employing this strategy, all collected trajectories can be utilized for policy updating, and the issue of vanishing gradients is counteracted by stimulating higher returns through the risk-neutral component, thus lifting the tail and preventing flatness. Our empirical study reveals that this mixture parameterization is uniquely effectiv
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#32487;&#32493;&#23398;&#20064;&#24212;&#29992;&#65292;&#26412;&#30740;&#31350;&#39318;&#27425;&#33719;&#24471;&#20102;&#22686;&#37327;&#26799;&#24230;&#21644;&#22686;&#37327;&#36817;&#31471;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#19988;&#20854;&#39044;&#26399;&#22797;&#26434;&#24230;&#30028;&#38480;&#20960;&#20046;&#19982;&#24050;&#30693;&#26368;&#20339;&#24179;&#22343;&#36845;&#20195;&#30340;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;</title><link>https://arxiv.org/abs/2403.06873</link><description>&lt;p&gt;
&#22686;&#37327;&#26041;&#27861;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#24615;&#21450;&#22312;&#32487;&#32493;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Last Iterate Convergence of Incremental Methods and Applications in Continual Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06873
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#32487;&#32493;&#23398;&#20064;&#24212;&#29992;&#65292;&#26412;&#30740;&#31350;&#39318;&#27425;&#33719;&#24471;&#20102;&#22686;&#37327;&#26799;&#24230;&#21644;&#22686;&#37327;&#36817;&#31471;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#19988;&#20854;&#39044;&#26399;&#22797;&#26434;&#24230;&#30028;&#38480;&#20960;&#20046;&#19982;&#24050;&#30693;&#26368;&#20339;&#24179;&#22343;&#36845;&#20195;&#30340;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22686;&#37327;&#26799;&#24230;&#26041;&#27861;&#21644;&#22686;&#37327;&#36817;&#31471;&#26041;&#27861;&#26159;&#19968;&#31867;&#22522;&#26412;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24191;&#27867;&#30740;&#31350;&#30340;&#26377;&#38480;&#21644;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#23601;&#25910;&#25947;&#24615;&#20445;&#35777;&#32780;&#35328;&#65292;&#38750;&#28176;&#36827;&#65288;&#19968;&#38454;&#25110;&#36817;&#31471;&#65289;&#30340;&#39044;&#26399;&#22797;&#26434;&#24615;&#30028;&#38480;&#26368;&#36817;&#25165;&#24471;&#21040;&#65292;&#24182;&#19988;&#20960;&#20046;&#20165;&#36866;&#29992;&#20110;&#24179;&#22343;&#36845;&#20195;&#12290;&#21463;&#32487;&#32493;&#23398;&#20064;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#23545;&#19968;&#33324;&#20984;&#24179;&#28369;&#65288;&#20004;&#32773;&#65289;&#21644;&#20984;Lipschitz&#65288;&#23545;&#20110;&#36817;&#31471;&#21464;&#31181;&#65289;&#35774;&#32622;&#20013;&#22686;&#37327;&#26799;&#24230;&#21644;&#22686;&#37327;&#36817;&#31471;&#26041;&#27861;&#30340;&#26368;&#21518;&#36845;&#20195;&#30340;&#39318;&#20010;&#25910;&#25947;&#20445;&#35777;&#12290;&#25105;&#20204;&#23545;&#26368;&#21518;&#36845;&#20195;&#30340;&#39044;&#26399;&#22797;&#26434;&#24615;&#30028;&#38480;&#20960;&#20046;&#19982;&#26368;&#20339;&#24050;&#30693;&#30340;&#24179;&#22343;&#36845;&#20195;&#30340;&#39044;&#26399;&#22797;&#26434;&#24615;&#30028;&#38480;&#30456;&#21305;&#37197;&#65288;&#21363;&#21305;&#37197;&#33267;&#24179;&#26041;&#26681;&#23545;&#25968;&#25110;&#23545;&#25968;&#22240;&#23376;&#65289;&#65292;&#23545;&#20004;&#31867;&#26041;&#27861;&#22343;&#36866;&#29992;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#21152;&#26435;&#24179;&#22343;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06873v1 Announce Type: cross  Abstract: Incremental gradient methods and incremental proximal methods are a fundamental class of optimization algorithms used for solving finite sum problems, broadly studied in the literature. Yet, when it comes to their convergence guarantees, nonasymptotic (first-order or proximal) oracle complexity bounds have been obtained fairly recently, almost exclusively applying to the average iterate. Motivated by applications in continual learning, we obtain the first convergence guarantees for the last iterate of both incremental gradient and incremental proximal methods, in general convex smooth (for both) and convex Lipschitz (for the proximal variants) settings. Our oracle complexity bounds for the last iterate nearly match (i.e., match up to a square-root-log or a log factor) the best known oracle complexity bounds for the average iterate, for both classes of methods. We further obtain generalizations of our results to weighted averaging of th
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wiener-Kallianpur&#21019;&#26032;&#34920;&#31034;&#30340;&#29983;&#25104;&#24335;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#21253;&#25324;&#33258;&#32534;&#30721;&#22120;&#21644;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#21644;&#32467;&#26500;&#25910;&#25947;&#24615;&#36136;&#65292;&#36866;&#29992;&#20110;&#23454;&#26102;&#24066;&#22330;&#36816;&#33829;&#20013;&#30340;&#39640;&#21160;&#24577;&#21644;&#27874;&#21160;&#26102;&#38388;&#24207;&#21015;&#12290;</title><link>https://arxiv.org/abs/2403.05743</link><description>&lt;p&gt;
&#20855;&#26377;&#24066;&#22330;&#36816;&#33829;&#24212;&#29992;&#30340;&#29983;&#25104;&#24335;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Generative Probabilistic Forecasting with Applications in Market Operations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05743
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wiener-Kallianpur&#21019;&#26032;&#34920;&#31034;&#30340;&#29983;&#25104;&#24335;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#21253;&#25324;&#33258;&#32534;&#30721;&#22120;&#21644;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#21644;&#32467;&#26500;&#25910;&#25947;&#24615;&#36136;&#65292;&#36866;&#29992;&#20110;&#23454;&#26102;&#24066;&#22330;&#36816;&#33829;&#20013;&#30340;&#39640;&#21160;&#24577;&#21644;&#27874;&#21160;&#26102;&#38388;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24335;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#28304;&#33258;&#20110;&#38750;&#21442;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;Wiener-Kallianpur&#21019;&#26032;&#34920;&#31034;&#12290;&#22312;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#30340;&#33539;&#24335;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#39044;&#27979;&#26550;&#26500;&#21253;&#25324;&#19968;&#20010;&#33258;&#32534;&#30721;&#22120;&#65292;&#23558;&#38750;&#21442;&#25968;&#22810;&#21464;&#37327;&#38543;&#26426;&#36807;&#31243;&#36716;&#21270;&#20026;&#35268;&#33539;&#30340;&#21019;&#26032;&#24207;&#21015;&#65292;&#20174;&#20013;&#26681;&#25454;&#36807;&#21435;&#26679;&#26412;&#29983;&#25104;&#26410;&#26469;&#26102;&#38388;&#24207;&#21015;&#26679;&#26412;&#65292;&#26465;&#20214;&#26159;&#23427;&#20204;&#30340;&#27010;&#29575;&#20998;&#24067;&#21462;&#20915;&#20110;&#36807;&#21435;&#26679;&#26412;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#28508;&#22312;&#36807;&#31243;&#38480;&#21046;&#20026;&#20855;&#26377;&#21305;&#37197;&#33258;&#32534;&#30721;&#22120;&#36755;&#20837;-&#36755;&#20986;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#24207;&#21015;&#12290;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#30340;&#29983;&#25104;&#24335;&#39044;&#27979;&#26041;&#27861;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#21644;&#32467;&#26500;&#25910;&#25947;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#22312;&#23454;&#26102;&#24066;&#22330;&#36816;&#33829;&#20013;&#28041;&#21450;&#39640;&#24230;&#21160;&#24577;&#21644;&#27874;&#21160;&#26102;&#38388;&#24207;&#21015;&#30340;&#19977;&#20010;&#24212;&#29992;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05743v1 Announce Type: cross  Abstract: This paper presents a novel generative probabilistic forecasting approach derived from the Wiener-Kallianpur innovation representation of nonparametric time series. Under the paradigm of generative artificial intelligence, the proposed forecasting architecture includes an autoencoder that transforms nonparametric multivariate random processes into canonical innovation sequences, from which future time series samples are generated according to their probability distributions conditioned on past samples. A novel deep-learning algorithm is proposed that constrains the latent process to be an independent and identically distributed sequence with matching autoencoder input-output conditional probability distributions. Asymptotic optimality and structural convergence properties of the proposed generative forecasting approach are established. Three applications involving highly dynamic and volatile time series in real-time market operations a
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#30690;&#37327;&#37327;&#21270;&#34892;&#20026;&#36716;&#25442;&#22120;&#65288;VQ-BeT&#65289;&#30340;&#22810;&#21151;&#33021;&#34892;&#20026;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#36830;&#32493;&#21160;&#20316;&#36827;&#34892;&#26631;&#35760;&#21270;&#22788;&#29702;&#22810;&#27169;&#24577;&#21160;&#20316;&#39044;&#27979;&#12289;&#26465;&#20214;&#29983;&#25104;&#21644;&#37096;&#20998;&#35266;&#23519;&#12290;</title><link>https://arxiv.org/abs/2403.03181</link><description>&lt;p&gt;
&#20855;&#26377;&#28508;&#22312;&#21160;&#20316;&#30340;&#34892;&#20026;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Behavior Generation with Latent Actions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03181
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#30690;&#37327;&#37327;&#21270;&#34892;&#20026;&#36716;&#25442;&#22120;&#65288;VQ-BeT&#65289;&#30340;&#22810;&#21151;&#33021;&#34892;&#20026;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#36830;&#32493;&#21160;&#20316;&#36827;&#34892;&#26631;&#35760;&#21270;&#22788;&#29702;&#22810;&#27169;&#24577;&#21160;&#20316;&#39044;&#27979;&#12289;&#26465;&#20214;&#29983;&#25104;&#21644;&#37096;&#20998;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#24102;&#26631;&#31614;&#30340;&#25968;&#25454;&#38598;&#20013;&#29983;&#25104;&#22797;&#26434;&#34892;&#20026;&#30340;&#29983;&#25104;&#24314;&#27169;&#19968;&#30452;&#26159;&#20915;&#31574;&#21046;&#23450;&#20013;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#19982;&#35821;&#35328;&#25110;&#22270;&#20687;&#29983;&#25104;&#19981;&#21516;&#65292;&#20915;&#31574;&#21046;&#23450;&#38656;&#35201;&#24314;&#27169;&#21160;&#20316; - &#36830;&#32493;&#20540;&#21521;&#37327;&#65292;&#20854;&#22312;&#20998;&#24067;&#19978;&#26159;&#22810;&#27169;&#24577;&#30340;&#65292;&#21487;&#33021;&#26469;&#33258;&#26410;&#32463;&#31579;&#36873;&#30340;&#26469;&#28304;&#65292;&#22312;&#39034;&#24207;&#39044;&#27979;&#20013;&#29983;&#25104;&#35823;&#24046;&#21487;&#33021;&#20250;&#30456;&#20114;&#32047;&#31215;&#12290;&#26368;&#36817;&#19968;&#31867;&#31216;&#20026;&#34892;&#20026;&#36716;&#25442;&#22120;&#65288;BeT&#65289;&#30340;&#27169;&#22411;&#36890;&#36807;&#20351;&#29992;k-means&#32858;&#31867;&#23545;&#21160;&#20316;&#36827;&#34892;&#31163;&#25955;&#21270;&#20197;&#25429;&#25417;&#19981;&#21516;&#27169;&#24335;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;k-means&#22312;&#22788;&#29702;&#39640;&#32500;&#21160;&#20316;&#31354;&#38388;&#25110;&#38271;&#24207;&#21015;&#26102;&#23384;&#22312;&#22256;&#38590;&#65292;&#24182;&#19988;&#32570;&#20047;&#26799;&#24230;&#20449;&#24687;&#65292;&#22240;&#27492;BeT&#22312;&#24314;&#27169;&#38271;&#36317;&#31163;&#21160;&#20316;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#30690;&#37327;&#37327;&#21270;&#34892;&#20026;&#36716;&#25442;&#22120;&#65288;VQ-BeT&#65289;&#30340;&#22810;&#21151;&#33021;&#34892;&#20026;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#21160;&#20316;&#39044;&#27979;&#12289;&#26465;&#20214;&#29983;&#25104;&#21644;&#37096;&#20998;&#35266;&#23519;&#12290;VQ-BeT&#36890;&#36807;&#23545;&#36830;&#32493;&#21160;&#20316;&#36827;&#34892;&#26631;&#35760;&#21270;&#26469;&#22686;&#24378;BeT
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03181v1 Announce Type: cross  Abstract: Generative modeling of complex behaviors from labeled datasets has been a longstanding problem in decision making. Unlike language or image generation, decision making requires modeling actions - continuous-valued vectors that are multimodal in their distribution, potentially drawn from uncurated sources, where generation errors can compound in sequential prediction. A recent class of models called Behavior Transformers (BeT) addresses this by discretizing actions using k-means clustering to capture different modes. However, k-means struggles to scale for high-dimensional action spaces or long sequences, and lacks gradient information, and thus BeT suffers in modeling long-range actions. In this work, we present Vector-Quantized Behavior Transformer (VQ-BeT), a versatile model for behavior generation that handles multimodal action prediction, conditional generation, and partial observations. VQ-BeT augments BeT by tokenizing continuous
&lt;/p&gt;</description></item><item><title>XAI&#39046;&#22495;&#34987;&#21010;&#20998;&#20026;&#34013;&#33394;XAI&#21644;&#32418;&#33394;XAI&#20004;&#31181;&#35299;&#37322;&#25991;&#21270;&#65292;&#25351;&#20986;&#20102;&#32418;&#33394;XAI&#39046;&#22495;&#30340;&#37325;&#35201;&#24615;&#21644;&#30740;&#31350;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.13914</link><description>&lt;p&gt;
&#19981;&#26159;&#20026;&#20102;&#36777;&#35299;&#32780;&#26159;&#20026;&#20102;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Explain to Question not to Justify
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13914
&lt;/p&gt;
&lt;p&gt;
XAI&#39046;&#22495;&#34987;&#21010;&#20998;&#20026;&#34013;&#33394;XAI&#21644;&#32418;&#33394;XAI&#20004;&#31181;&#35299;&#37322;&#25991;&#21270;&#65292;&#25351;&#20986;&#20102;&#32418;&#33394;XAI&#39046;&#22495;&#30340;&#37325;&#35201;&#24615;&#21644;&#30740;&#31350;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26159;&#19968;&#20010;&#24180;&#36731;&#20294;&#38750;&#24120;&#26377;&#21069;&#36884;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#35813;&#39046;&#22495;&#30446;&#21069;&#30340;&#36827;&#23637;&#21463;&#21040;&#20102;&#19981;&#21516;&#21644;&#19981;&#20860;&#23481;&#30446;&#26631;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;XAI&#39046;&#22495;&#20869;&#32416;&#32544;&#22312;&#19968;&#36215;&#30340;&#21508;&#31181;&#32447;&#32034;&#20998;&#20026;&#20004;&#31181;&#20114;&#34917;&#30340;&#25991;&#21270;&#65292;&#21363;&#20154;&#31867;/&#20215;&#20540;&#21462;&#21521;&#35299;&#37322;&#65288;&#34013;&#33394;XAI&#65289;&#21644;&#27169;&#22411;/&#39564;&#35777;&#21462;&#21521;&#35299;&#37322;&#65288;&#32418;&#33394;XAI&#65289;&#12290;&#25105;&#20204;&#36824;&#35748;&#20026;&#65292;&#32418;&#33394;XAI&#39046;&#22495;&#30446;&#21069;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#65292;&#38544;&#34255;&#30528;&#24040;&#22823;&#30340;&#26426;&#36935;&#21644;&#37325;&#35201;&#30740;&#31350;&#30340;&#28508;&#21147;&#65292;&#20197;&#30830;&#20445;AI&#31995;&#32479;&#30340;&#23433;&#20840;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#36825;&#19968;&#39046;&#22495;&#30340;&#26377;&#21069;&#36884;&#30340;&#25361;&#25112;&#26469;&#24635;&#32467;&#26412;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13914v1 Announce Type: new  Abstract: Explainable Artificial Intelligence (XAI) is a young but very promising field of research. Unfortunately, the progress in this field is currently slowed down by divergent and incompatible goals. In this paper, we separate various threads tangled within the area of XAI into two complementary cultures of human/value-oriented explanations (BLUE XAI) and model/validation-oriented explanations (RED XAI). We also argue that the area of RED XAI is currently under-explored and hides great opportunities and potential for important research necessary to ensure the safety of AI systems. We conclude this paper by presenting promising challenges in this area.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#22312;&#21160;&#24577;&#35268;&#21010;&#39046;&#22495;&#20013;&#27169;&#25311;&#24037;&#20855;&#20351;&#29992;&#30340;&#30446;&#26631;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;&#65292;&#35813;&#39046;&#22495;&#32771;&#34385;&#21040;&#29983;&#29289;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;</title><link>https://arxiv.org/abs/2402.11658</link><description>&lt;p&gt;
&#20998;&#23618;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Dynamic planning in hierarchical active inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11658
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#22312;&#21160;&#24577;&#35268;&#21010;&#39046;&#22495;&#20013;&#27169;&#25311;&#24037;&#20855;&#20351;&#29992;&#30340;&#30446;&#26631;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;&#65292;&#35813;&#39046;&#22495;&#32771;&#34385;&#21040;&#29983;&#29289;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#65292;&#25105;&#20204;&#25351;&#30340;&#26159;&#20154;&#31867;&#22823;&#33041;&#25512;&#26029;&#21644;&#26045;&#21152;&#19982;&#35748;&#30693;&#20915;&#31574;&#30456;&#20851;&#30340;&#36816;&#21160;&#36712;&#36857;&#30340;&#33021;&#21147;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#33539;&#24335;&#65292;&#20027;&#21160;&#25512;&#26029;&#65292;&#20026;&#29983;&#29289;&#26377;&#26426;&#20307;&#36866;&#24212;&#24102;&#26469;&#20102;&#22522;&#26412;&#35265;&#35299;&#65292;&#19981;&#26029;&#21162;&#21147;&#26368;&#23567;&#21270;&#39044;&#27979;&#35823;&#24046;&#20197;&#23558;&#33258;&#24049;&#38480;&#21046;&#22312;&#19982;&#29983;&#21629;&#20860;&#23481;&#30340;&#29366;&#24577;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#37324;&#65292;&#35768;&#22810;&#30740;&#31350;&#34920;&#26126;&#20154;&#31867;&#21644;&#21160;&#29289;&#34892;&#20026;&#21487;&#20197;&#35299;&#37322;&#20026;&#20027;&#21160;&#25512;&#26029;&#36807;&#31243;&#65292;&#26080;&#35770;&#26159;&#20316;&#20026;&#31163;&#25955;&#20915;&#31574;&#36824;&#26159;&#36830;&#32493;&#36816;&#21160;&#25511;&#21046;&#65292;&#37117;&#28608;&#21457;&#20102;&#26426;&#22120;&#20154;&#25216;&#26415;&#21644;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#32570;&#20047;&#23545;&#22914;&#20309;&#26377;&#25928;&#22320;&#22312;&#21464;&#21270;&#29615;&#22659;&#20013;&#35268;&#21010;&#34892;&#21160;&#30340;&#20840;&#38754;&#23637;&#26395;&#12290;&#25105;&#20204;&#35774;&#23450;&#20102;&#23545;&#24037;&#20855;&#20351;&#29992;&#36827;&#34892;&#24314;&#27169;&#30340;&#30446;&#26631;&#65292;&#28145;&#20837;&#30740;&#31350;&#20102;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;&#20027;&#39064;&#65292;&#29282;&#35760;&#20004;&#20010;&#29983;&#29289;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#20851;&#38190;&#26041;&#38754;&#65306;&#29702;&#35299;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11658v1 Announce Type: new  Abstract: By dynamic planning, we refer to the ability of the human brain to infer and impose motor trajectories related to cognitive decisions. A recent paradigm, active inference, brings fundamental insights into the adaptation of biological organisms, constantly striving to minimize prediction errors to restrict themselves to life-compatible states. Over the past years, many studies have shown how human and animal behavior could be explained in terms of an active inferential process -- either as discrete decision-making or continuous motor control -- inspiring innovative solutions in robotics and artificial intelligence. Still, the literature lacks a comprehensive outlook on how to effectively plan actions in changing environments. Setting ourselves the goal of modeling tool use, we delve into the topic of dynamic planning in active inference, keeping in mind two crucial aspects of biological goal-directed behavior: the capacity to understand a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36923;&#36753;&#38381;&#29615;&#30340;&#26694;&#26550;&#65288;LogicCheckGPT&#65289;&#65292;&#21033;&#29992;&#22823;&#22411;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#23545;&#35937;&#24187;&#35273;&#12290;</title><link>https://arxiv.org/abs/2402.11622</link><description>&lt;p&gt;
&#36923;&#36753;&#38381;&#29615;&#65306;&#25581;&#31034;&#22823;&#22411;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23545;&#35937;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Logical Closed Loop: Uncovering Object Hallucinations in Large Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11622
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36923;&#36753;&#38381;&#29615;&#30340;&#26694;&#26550;&#65288;LogicCheckGPT&#65289;&#65292;&#21033;&#29992;&#22823;&#22411;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#23545;&#35937;&#24187;&#35273;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35937;&#24187;&#35273;&#19968;&#30452;&#26159;&#38459;&#30861;&#22823;&#22411;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#65288;LVLMs&#65289;&#26356;&#24191;&#27867;&#24212;&#29992;&#30340;&#36719;&#32907;&#12290;&#23545;&#35937;&#24187;&#35273;&#26159;&#25351;LVLMs&#22312;&#22270;&#20687;&#20013;&#22768;&#31216;&#19981;&#23384;&#22312;&#30340;&#23545;&#35937;&#30340;&#29616;&#35937;&#12290;&#20026;&#20102;&#20943;&#36731;&#23545;&#35937;&#24187;&#35273;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#25351;&#23548;&#35843;&#25972;&#21644;&#22522;&#20110;&#22806;&#37096;&#27169;&#22411;&#30340;&#26816;&#27979;&#26041;&#27861;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#22823;&#35268;&#27169;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#35201;&#20040;&#20381;&#36182;&#20110;&#22806;&#37096;&#27169;&#22411;&#30340;&#26816;&#27979;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#19968;&#20010;&#26410;&#28145;&#20837;&#25506;&#35752;&#30340;&#39046;&#22495;&#65292;&#21363;&#21033;&#29992;LVLM&#26412;&#36523;&#26469;&#20943;&#36731;&#23545;&#35937;&#24187;&#35273;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#36825;&#26679;&#30340;&#30452;&#35273;&#65292;&#21363;LVLM&#20542;&#21521;&#20110;&#23545;&#23384;&#22312;&#30340;&#23545;&#35937;&#20570;&#20986;&#36923;&#36753;&#19968;&#33268;&#30340;&#21453;&#24212;&#65292;&#20294;&#23545;&#24187;&#35273;&#23545;&#35937;&#20570;&#20986;&#19981;&#19968;&#33268;&#30340;&#21453;&#24212;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#36923;&#36753;&#38381;&#29615;&#30340;&#23545;&#35937;&#24187;&#35273;&#26816;&#27979;&#21644;&#20943;&#36731;&#26694;&#26550;&#65292;&#21363;LogicCheckGPT&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#36923;&#36753;&#19968;&#33268;&#24615;&#25506;&#27979;&#26469;&#25552;&#20986;&#20855;&#26377;&#36923;&#36753;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11622v1 Announce Type: cross  Abstract: Object hallucination has been an Achilles' heel which hinders the broader applications of large vision-language models (LVLMs). Object hallucination refers to the phenomenon that the LVLMs claim non-existent objects in the image. To mitigate the object hallucinations, instruction tuning and external model-based detection methods have been proposed, which either require large-scare computational resources or depend on the detection result of external models. However, there remains an under-explored field to utilize the LVLM itself to alleviate object hallucinations. In this work, we adopt the intuition that the LVLM tends to respond logically consistently for existent objects but inconsistently for hallucinated objects. Therefore, we propose a Logical Closed Loop-based framework for Object Hallucination Detection and Mitigation, namely LogicCheckGPT. In specific, we devise logical consistency probing to raise questions with logical corr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#20559;&#22909;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#26469;&#26356;&#22909;&#22320;&#21033;&#29992;&#20559;&#22909;&#26631;&#31614;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22522;&#20110;&#25104;&#23545;&#20559;&#22909;&#25968;&#25454;&#30340;&#24494;&#35843;&#30340;&#23398;&#20064;&#36895;&#24230;&#21644;&#26368;&#32456;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08114</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#20559;&#22909;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active Preference Learning for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08114
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#20559;&#22909;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#26469;&#26356;&#22909;&#22320;&#21033;&#29992;&#20559;&#22909;&#26631;&#31614;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22522;&#20110;&#25104;&#23545;&#20559;&#22909;&#25968;&#25454;&#30340;&#24494;&#35843;&#30340;&#23398;&#20064;&#36895;&#24230;&#21644;&#26368;&#32456;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#33021;&#21147;&#36234;&#26469;&#36234;&#24378;&#65292;&#19982;&#20154;&#31867;&#24847;&#22270;&#23545;&#40784;&#30340;&#24494;&#35843;&#25216;&#26415;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#23545;&#20110;&#23545;&#40784;&#36825;&#20123;&#27169;&#22411;&#26469;&#35828;&#65292;&#26368;&#20851;&#38190;&#30340;&#32771;&#34385;&#26159;&#22914;&#20309;&#26368;&#26377;&#25928;&#22320;&#21033;&#29992;&#20154;&#21147;&#36164;&#28304;&#65292;&#25110;&#32773;&#22312;LLM&#26412;&#36523;&#34987;&#29992;&#20316;oracle&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#26368;&#26377;&#25928;&#22320;&#21033;&#29992;&#27169;&#22411;&#36164;&#28304;&#12290;&#20174;&#20154;&#31867;&#25110;AI&#20559;&#22909;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF / RLAIF&#65289;&#26159;&#36825;&#31181;&#25216;&#26415;&#26368;&#31361;&#20986;&#30340;&#20363;&#23376;&#65292;&#20294;&#23427;&#24448;&#24448;&#22797;&#26434;&#19988;&#19981;&#31283;&#23450;&#12290;&#26368;&#36817;&#65292;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#20010;&#26356;&#31616;&#21333;&#21644;&#26356;&#31283;&#23450;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;DPO&#30340;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#20559;&#22909;&#26631;&#31614;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#27979;&#29109;&#21644;DPO&#20248;&#21270;&#30340;&#38544;&#24335;&#20559;&#22909;&#27169;&#22411;&#30340;&#30830;&#23450;&#24615;&#24230;&#37327;&#30340;&#23454;&#29992;&#37319;&#38598;&#20989;&#25968;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#25552;&#39640;&#22522;&#20110;&#25104;&#23545;&#20559;&#22909;&#25968;&#25454;&#30340;&#24494;&#35843;&#30340;&#23398;&#20064;&#36895;&#24230;&#21644;&#26368;&#32456;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models (LLMs) become more capable, fine-tuning techniques for aligning with human intent are increasingly important. A key consideration for aligning these models is how to most effectively use human resources, or model resources in the case where LLMs themselves are used as oracles. Reinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most prominent example of such a technique, but is complex and often unstable. Direct Preference Optimization (DPO) has recently been proposed as a simpler and more stable alternative. In this work, we develop an active learning strategy for DPO to make better use of preference labels. We propose a practical acquisition function for prompt/completion pairs based on the predictive entropy of the language model and a measure of certainty of the implicit preference model optimized by DPO. We demonstrate how our approach improves both the rate of learning and final performance of fine-tuning on pairwise preference data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#31995;&#32479;&#35843;&#26597;&#65292;&#21457;&#29616;&#25972;&#21512;&#39046;&#22495;&#30693;&#35782;&#21487;&#20197;&#25552;&#39640;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#21033;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#34701;&#21512;&#21487;&#20197;&#20135;&#29983;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.07249</link><description>&lt;p&gt;
&#39046;&#22495;&#30693;&#35782;&#21644;&#22810;&#27169;&#24577;&#23545;&#26234;&#33021;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#30340;&#24433;&#21709;&#65306;&#19968;&#39033;&#31995;&#32479;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
The Impact of Domain Knowledge and Multi-Modality on Intelligent Molecular Property Prediction: A Systematic Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#31995;&#32479;&#35843;&#26597;&#65292;&#21457;&#29616;&#25972;&#21512;&#39046;&#22495;&#30693;&#35782;&#21487;&#20197;&#25552;&#39640;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#21033;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#34701;&#21512;&#21487;&#20197;&#20135;&#29983;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#39044;&#27979;&#20998;&#23376;&#24615;&#36136;&#23545;&#20110;&#33647;&#29289;&#24320;&#21457;&#23588;&#20854;&#26159;&#34394;&#25311;&#31579;&#36873;&#21644;&#21270;&#21512;&#29289;&#20248;&#21270;&#30340;&#36827;&#23637;&#33267;&#20851;&#37325;&#35201;&#12290;&#36817;&#24180;&#26469;&#24341;&#20837;&#20102;&#35768;&#22810;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#22312;&#22686;&#24378;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#65288;MPP&#65289;&#26041;&#38754;&#26174;&#31034;&#20986;&#26174;&#33879;&#28508;&#21147;&#65292;&#29305;&#21035;&#26159;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#21644;&#23545;&#20998;&#23376;&#32467;&#26500;&#30340;&#27934;&#23519;&#21147;&#12290;&#28982;&#32780;&#65292;&#26377;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;&#39046;&#22495;&#30693;&#35782;&#30340;&#25972;&#21512;&#26159;&#21542;&#22686;&#24378;&#20102;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#34701;&#21512;&#26159;&#21542;&#27604;&#21333;&#19968;&#25968;&#25454;&#26469;&#28304;&#26041;&#27861;&#20135;&#29983;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#65311;&#20026;&#20102;&#25506;&#31350;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20840;&#38754;&#22238;&#39038;&#21644;&#23450;&#37327;&#20998;&#26512;&#20102;&#22522;&#20110;&#21508;&#31181;&#22522;&#20934;&#30340;&#26368;&#26032;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25972;&#21512;&#20998;&#23376;&#20449;&#24687;&#23558;&#20998;&#21035;&#25552;&#39640;MPP&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#65292;&#20998;&#21035;&#39640;&#36798;3.98&#65285;&#21644;1.72&#65285;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#20351;&#29992;&#19977;&#32500;&#20449;&#24687;&#19982;&#19968;&#32500;&#21644;&#20108;&#32500;&#20449;&#24687;&#30456;&#32467;&#21512;&#20250;&#20135;&#29983;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The precise prediction of molecular properties is essential for advancements in drug development, particularly in virtual screening and compound optimization. The recent introduction of numerous deep learning-based methods has shown remarkable potential in enhancing molecular property prediction (MPP), especially improving accuracy and insights into molecular structures. Yet, two critical questions arise: does the integration of domain knowledge augment the accuracy of molecular property prediction and does employing multi-modal data fusion yield more precise results than unique data source methods? To explore these matters, we comprehensively review and quantitatively analyze recent deep learning methods based on various benchmarks. We discover that integrating molecular information will improve both MPP regression and classification tasks by upto 3.98% and 1.72%, respectively. We also discover that the utilizing 3-dimensional information with 1-dimensional and 2-dimensional informati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#30028;&#38754;&#22312;&#36719;&#20214;&#39033;&#30446;&#20013;&#36827;&#34892;&#24037;&#20316;&#37327;&#21644;&#35268;&#27169;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#20256;&#32479;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#24378;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#38382;&#39064;&#35268;&#33539;&#26469;&#23454;&#29616;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20934;&#30830;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.07158</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#30028;&#38754;&#22312;&#36719;&#20214;&#39033;&#30446;&#20013;&#30340;&#24037;&#20316;&#37327;&#21644;&#35268;&#27169;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Effort and Size Estimation in Software Projects with Large Language Model-based Intelligent Interfaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#30028;&#38754;&#22312;&#36719;&#20214;&#39033;&#30446;&#20013;&#36827;&#34892;&#24037;&#20316;&#37327;&#21644;&#35268;&#27169;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#20256;&#32479;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#24378;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#38382;&#39064;&#35268;&#33539;&#26469;&#23454;&#29616;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20934;&#30830;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21457;&#23637;&#20063;&#23548;&#33268;&#20854;&#24212;&#29992;&#30340;&#24191;&#27867;&#22686;&#21152;&#12290;&#36719;&#20214;&#35774;&#35745;&#20316;&#20026;&#20854;&#20013;&#20043;&#19968;&#65292;&#22312;&#20351;&#29992;LLM&#20316;&#20026;&#25193;&#23637;&#22266;&#23450;&#29992;&#25143;&#25925;&#20107;&#30340;&#25509;&#21475;&#32452;&#20214;&#26041;&#38754;&#33719;&#24471;&#20102;&#24040;&#22823;&#30340;&#22909;&#22788;&#12290;&#28982;&#32780;&#65292;&#23558;&#22522;&#20110;LLM&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#21253;&#21547;&#22312;&#36719;&#20214;&#35774;&#35745;&#20013;&#24120;&#24120;&#24102;&#26469;&#24847;&#24819;&#19981;&#21040;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20272;&#35745;&#26041;&#38754;&#12290;&#36890;&#36807;&#22522;&#20110;&#29992;&#25143;&#30028;&#38754;&#30340;&#29992;&#25143;&#25925;&#20107;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23545;&#27604;&#20102;&#20256;&#32479;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#38382;&#39064;&#30340;&#35268;&#33539;&#65292;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#28304;&#12289;&#25509;&#21475;&#21644;&#31639;&#27861;&#26469;&#36827;&#34892;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advancement of Large Language Models (LLM) has also resulted in an equivalent proliferation in its applications. Software design, being one, has gained tremendous benefits in using LLMs as an interface component that extends fixed user stories. However, inclusion of LLM-based AI agents in software design often poses unexpected challenges, especially in the estimation of development efforts. Through the example of UI-based user stories, we provide a comparison against traditional methods and propose a new way to enhance specifications of natural language-based questions that allows for the estimation of development effort by taking into account data sources, interfaces and algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#26377;&#32467;&#26500;&#32570;&#22833;&#30340;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#25429;&#33719;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>https://arxiv.org/abs/2402.05758</link><description>&lt;p&gt;
&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#32467;&#26500;&#32570;&#22833;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Latent variable model for high-dimensional point process with structured missingness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#26377;&#32467;&#26500;&#32570;&#22833;&#30340;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#25429;&#33719;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#25968;&#25454;&#22312;&#21307;&#30103;&#20445;&#20581;&#12289;&#31038;&#20250;&#23398;&#21644;&#22320;&#38663;&#23398;&#31561;&#35768;&#22810;&#39046;&#22495;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#20294;&#26159;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#23545;&#20174;&#19994;&#20154;&#21592;&#26469;&#35828;&#23384;&#22312;&#26126;&#26174;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#33021;&#26159;&#39640;&#32500;&#30340;&#65292;&#21253;&#21547;&#26377;&#32467;&#26500;&#21270;&#30340;&#32570;&#22833;&#27169;&#24335;&#65292;&#24182;&#19988;&#27979;&#37327;&#26102;&#38388;&#28857;&#21487;&#33021;&#21463;&#21040;&#26410;&#30693;&#38543;&#26426;&#36807;&#31243;&#30340;&#25511;&#21046;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#20854;&#20013;&#22823;&#22810;&#25968;&#20165;&#32771;&#34385;&#20102;&#36825;&#20123;&#25361;&#25112;&#20013;&#30340;&#19968;&#20010;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#33021;&#22815;&#24212;&#23545;&#25152;&#26377;&#36825;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#25429;&#33719;&#26679;&#26412;&#19982;&#20854;&#20851;&#32852;&#30340;&#32570;&#22833;&#27169;&#24335;&#20043;&#38388;&#30340;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#20063;&#29992;&#20110;&#24314;&#27169;&#24213;&#23618;&#30340;&#28857;&#36807;&#31243;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#26500;&#24314;&#20026;&#19968;&#20010;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#21516;&#26102;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#26469;&#36827;&#34892;&#39640;&#25928;&#30340;&#27169;&#22411;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Longitudinal data are important in numerous fields, such as healthcare, sociology and seismology, but real-world datasets present notable challenges for practitioners because they can be high-dimensional, contain structured missingness patterns, and measurement time points can be governed by an unknown stochastic process. While various solutions have been suggested, the majority of them have been designed to account for only one of these challenges. In this work, we propose a flexible and efficient latent-variable model that is capable of addressing all these limitations. Our approach utilizes Gaussian processes to capture temporal correlations between samples and their associated missingness masks as well as to model the underlying point process. We construct our model as a variational autoencoder together with deep neural network parameterised encoder and decoder models, and develop a scalable amortised variational inference approach for efficient model training. We demonstrate compe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;</title><link>https://arxiv.org/abs/2402.04376</link><description>&lt;p&gt;
&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#30340;&#25193;&#23637;&#35268;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling laws for learning with real and surrogate data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#38598;&#22823;&#37327;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#25104;&#26412;&#26114;&#36149;&#25110;&#19981;&#20999;&#23454;&#38469;&#30340;&#33539;&#22260;&#20869;, &#36825;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29942;&#39048;&#12290;&#30456;&#21453;&#22320;, &#21487;&#20197;&#23558;&#26469;&#33258;&#30446;&#26631;&#20998;&#24067;&#30340;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19982;&#26469;&#33258;&#20844;&#20849;&#25968;&#25454;&#38598;&#12289;&#19981;&#21516;&#24773;&#20917;&#19979;&#25910;&#38598;&#30340;&#25968;&#25454;&#25110;&#30001;&#29983;&#25104;&#27169;&#22411;&#21512;&#25104;&#30340;&#25968;&#25454;&#30456;&#32467;&#21512;, &#20316;&#20026;&#26367;&#20195;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#26696;&#26469;&#23558;&#26367;&#20195;&#25968;&#25454;&#25972;&#21512;&#21040;&#35757;&#32451;&#20013;, &#24182;&#20351;&#29992;&#29702;&#35770;&#27169;&#22411;&#21644;&#23454;&#35777;&#30740;&#31350;&#25506;&#32034;&#20854;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#65306;(i) &#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#21407;&#22987;&#20998;&#24067;&#30340;&#27979;&#35797;&#35823;&#24046;&#65307;(ii) &#20026;&#20102;&#33719;&#24471;&#36825;&#31181;&#25928;&#30410;, &#20351;&#29992;&#26368;&#20248;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38750;&#24120;&#20851;&#38190;&#65307;(iii) &#22312;&#28151;&#21512;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#21487;&#20197;&#24456;&#22909;&#22320;&#29992;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#12290;&#36825;&#21487;&#20197;&#29992;&#26469;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collecting large quantities of high-quality data is often prohibitively expensive or impractical, and a crucial bottleneck in machine learning. One may instead augment a small set of $n$ data points from the target distribution with data from more accessible sources like public datasets, data collected under different circumstances, or synthesized by generative models. Blurring distinctions, we refer to such data as `surrogate data'.   We define a simple scheme for integrating surrogate data into training and use both theoretical models and empirical studies to explore its behavior. Our main findings are: $(i)$ Integrating surrogate data can significantly reduce the test error on the original distribution; $(ii)$ In order to reap this benefit, it is crucial to use optimally weighted empirical risk minimization; $(iii)$ The test error of models trained on mixtures of real and surrogate data is well described by a scaling law. This can be used to predict the optimal weighting and the gai
&lt;/p&gt;</description></item><item><title>BGE M3-&#23884;&#20837;&#26159;&#19968;&#31181;&#26032;&#30340;&#22810;&#35821;&#35328;&#12289;&#22810;&#21151;&#33021;&#21644;&#22810;&#31890;&#24230;&#30340;&#25991;&#26412;&#23884;&#20837;&#27169;&#22411;&#65292;&#25903;&#25345;&#36229;&#36807;100&#31181;&#24037;&#20316;&#35821;&#35328;&#65292;&#24182;&#22312;&#22810;&#35821;&#35328;&#21644;&#36328;&#35821;&#35328;&#26816;&#32034;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#23427;&#33021;&#22815;&#21516;&#26102;&#25191;&#34892;&#23494;&#38598;&#26816;&#32034;&#12289;&#22810;&#21521;&#37327;&#26816;&#32034;&#21644;&#31232;&#30095;&#26816;&#32034;&#65292;&#24182;&#33021;&#22788;&#29702;&#19981;&#21516;&#31890;&#24230;&#30340;&#36755;&#20837;&#12290;&#20854;&#26377;&#25928;&#35757;&#32451;&#21253;&#25324;&#20102;&#19968;&#31181;&#33258;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#21644;&#20248;&#21270;&#30340;&#25209;&#22788;&#29702;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.03216</link><description>&lt;p&gt;
BGE M3-&#23884;&#20837;&#65306;&#36890;&#36807;&#33258;&#30693;&#35782;&#33976;&#39311;&#23454;&#29616;&#22810;&#35821;&#35328;&#12289;&#22810;&#21151;&#33021;&#21644;&#22810;&#31890;&#24230;&#30340;&#25991;&#26412;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03216
&lt;/p&gt;
&lt;p&gt;
BGE M3-&#23884;&#20837;&#26159;&#19968;&#31181;&#26032;&#30340;&#22810;&#35821;&#35328;&#12289;&#22810;&#21151;&#33021;&#21644;&#22810;&#31890;&#24230;&#30340;&#25991;&#26412;&#23884;&#20837;&#27169;&#22411;&#65292;&#25903;&#25345;&#36229;&#36807;100&#31181;&#24037;&#20316;&#35821;&#35328;&#65292;&#24182;&#22312;&#22810;&#35821;&#35328;&#21644;&#36328;&#35821;&#35328;&#26816;&#32034;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#23427;&#33021;&#22815;&#21516;&#26102;&#25191;&#34892;&#23494;&#38598;&#26816;&#32034;&#12289;&#22810;&#21521;&#37327;&#26816;&#32034;&#21644;&#31232;&#30095;&#26816;&#32034;&#65292;&#24182;&#33021;&#22788;&#29702;&#19981;&#21516;&#31890;&#24230;&#30340;&#36755;&#20837;&#12290;&#20854;&#26377;&#25928;&#35757;&#32451;&#21253;&#25324;&#20102;&#19968;&#31181;&#33258;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#21644;&#20248;&#21270;&#30340;&#25209;&#22788;&#29702;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23884;&#20837;&#27169;&#22411;&#65292;&#31216;&#20026;M3-&#23884;&#20837;&#65292;&#20197;&#20854;&#22312;&#22810;&#35821;&#35328;&#12289;&#22810;&#21151;&#33021;&#21644;&#22810;&#31890;&#24230;&#26041;&#38754;&#30340;&#22810;&#26679;&#24615;&#32780;&#33879;&#31216;&#12290;&#23427;&#21487;&#20197;&#25903;&#25345;&#36229;&#36807;100&#31181;&#24037;&#20316;&#35821;&#35328;&#65292;&#22312;&#22810;&#35821;&#35328;&#21644;&#36328;&#35821;&#35328;&#26816;&#32034;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;&#23427;&#21487;&#20197;&#21516;&#26102;&#25191;&#34892;&#23884;&#20837;&#27169;&#22411;&#30340;&#19977;&#31181;&#24120;&#35265;&#26816;&#32034;&#21151;&#33021;&#65306;&#23494;&#38598;&#26816;&#32034;&#12289;&#22810;&#21521;&#37327;&#26816;&#32034;&#21644;&#31232;&#30095;&#26816;&#32034;&#65292;&#20026;&#29616;&#23454;&#19990;&#30028;&#30340;IR&#24212;&#29992;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#27169;&#22411;&#22522;&#30784;&#12290;&#23427;&#33021;&#22815;&#22788;&#29702;&#19981;&#21516;&#31890;&#24230;&#30340;&#36755;&#20837;&#65292;&#20174;&#30701;&#21477;&#21040;&#38271;&#36798;8192&#20010;&#26631;&#35760;&#30340;&#25991;&#26723;&#12290;M3-&#23884;&#20837;&#30340;&#26377;&#25928;&#35757;&#32451;&#21253;&#25324;&#20197;&#19979;&#25216;&#26415;&#36129;&#29486;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#26469;&#33258;&#19981;&#21516;&#26816;&#32034;&#21151;&#33021;&#30340;&#30456;&#20851;&#24615;&#20998;&#25968;&#25972;&#21512;&#20026;&#25945;&#24072;&#20449;&#21495;&#65292;&#20197;&#25552;&#39640;&#35757;&#32451;&#36136;&#37327;&#12290;&#25105;&#20204;&#36824;&#20248;&#21270;&#20102;&#25209;&#22788;&#29702;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a new embedding model, called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It can support more than 100 working languages, leading to new state-of-the-art performances on multi-lingual and cross-lingual retrieval tasks. It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval, which provides a unified model foundation for real-world IR applications. It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens. The effective training of M3-Embedding involves the following technical contributions. We propose a novel self-knowledge distillation approach, where the relevance scores from different retrieval functionalities can be integrated as the teacher signal to enhance the training quality. We also optimize the batching strat
&lt;/p&gt;</description></item><item><title>&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;: &#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#31561;&#21464;&#30340;&#23545;&#31216;&#30772;&#32570;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#23545;&#31216;&#30772;&#32570;&#38598;&#26469;&#30772;&#22351;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23545;&#31216;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#29992;&#19988;&#36866;&#29992;&#20110;&#20219;&#20309;&#32676;&#30340;&#31561;&#21464;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02681</link><description>&lt;p&gt;
&#31561;&#21464;&#23545;&#31216;&#30772;&#32570;&#38598;
&lt;/p&gt;
&lt;p&gt;
Equivariant Symmetry Breaking Sets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02681
&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;: &#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#31561;&#21464;&#30340;&#23545;&#31216;&#30772;&#32570;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#23545;&#31216;&#30772;&#32570;&#38598;&#26469;&#30772;&#22351;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23545;&#31216;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#29992;&#19988;&#36866;&#29992;&#20110;&#20219;&#20309;&#32676;&#30340;&#31561;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#65288;ENN&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#28041;&#21450;&#28508;&#22312;&#23545;&#31216;&#24615;&#30340;&#24212;&#29992;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#36890;&#36807;&#35774;&#35745;&#65292;ENN&#22312;&#32473;&#23450;&#26356;&#39640;&#23545;&#31216;&#24615;&#36755;&#20837;&#26102;&#26080;&#27861;&#20135;&#29983;&#36739;&#20302;&#23545;&#31216;&#24615;&#36755;&#20986;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#29289;&#29702;&#31995;&#32479;&#20013;&#20250;&#21457;&#29983;&#33258;&#21457;&#23545;&#31216;&#30772;&#32570;&#65292;&#25105;&#20204;&#21487;&#20197;&#20174;&#19968;&#20010;&#21021;&#22987;&#39640;&#24230;&#23545;&#31216;&#30340;&#29366;&#24577;&#33719;&#24471;&#19968;&#20010;&#36739;&#19981;&#23545;&#31216;&#30340;&#31283;&#23450;&#29366;&#24577;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24517;&#39035;&#20102;&#35299;&#22914;&#20309;&#31995;&#32479;&#22320;&#22312;ENN&#20013;&#30772;&#22351;&#23545;&#31216;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#31561;&#21464;&#30340;&#26032;&#22411;&#23545;&#31216;&#30772;&#32570;&#26694;&#26550;&#12290;&#25105;&#20204;&#24378;&#35843;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#36890;&#29992;&#30340;&#65292;&#24182;&#36866;&#29992;&#20110;&#20219;&#20309;&#32676;&#30340;&#31561;&#21464;&#24615;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#31216;&#30772;&#32570;&#38598;&#65288;SBS&#65289;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#19981;&#26159;&#37325;&#26032;&#35774;&#35745;&#29616;&#26377;&#30340;&#32593;&#32476;&#65292;&#32780;&#26159;&#35774;&#35745;&#20102;&#19968;&#32452;&#23545;&#31216;&#30772;&#32570;&#23545;&#35937;&#65292;&#26681;&#25454;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#23545;&#31216;&#24615;&#23558;&#20854;&#36755;&#20837;&#21040;&#25105;&#20204;&#30340;&#32593;&#32476;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#20123;&#38598;&#21512;&#19978;&#23450;&#20041;&#31561;&#21464;&#24615;&#30340;&#19968;&#31181;&#33258;&#28982;&#26041;&#24335;&#65292;&#23427;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#32422;&#26463;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;... (the abstract is incomplete and cut off)
&lt;/p&gt;
&lt;p&gt;
Equivariant neural networks (ENNs) have been shown to be extremely effective in applications involving underlying symmetries. By construction ENNs cannot produce lower symmetry outputs given a higher symmetry input. However, spontaneous symmetry breaking occurs in many physical systems and we may obtain a less symmetric stable state from an initial highly symmetric one. Hence, it is imperative that we understand how to systematically break symmetry in ENNs. In this work, we propose a novel symmetry breaking framework that is fully equivariant. We emphasize that our approach is general and applicable to equivariance under any group. To achieve this, we introduce the idea of symmetry breaking sets (SBS). Rather than redesign existing networks, we design sets of symmetry breaking objects which we feed into our network based on the symmetry of our inputs and outputs. We show there is a natural way to define equivariance on these sets, which gives an additional constraint. Minimizing the si
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#27969;&#27700;&#32447;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#35268;&#26684;&#29983;&#25104;&#33521;&#35821;&#12289;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#21644;SVA&#26029;&#35328;&#65292;&#24182;&#25104;&#21151;&#20943;&#23569;&#20102;&#26029;&#35328;&#38169;&#35823;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.00093</link><description>&lt;p&gt;
ChIRAAG: &#36890;&#36807;ChatGPT&#29983;&#25104;&#24555;&#36895;&#21644;&#33258;&#21160;&#26029;&#35328;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#27969;&#27700;&#32447;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#35268;&#26684;&#29983;&#25104;&#33521;&#35821;&#12289;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#21644;SVA&#26029;&#35328;&#65292;&#24182;&#25104;&#21151;&#20943;&#23569;&#20102;&#26029;&#35328;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
System Verilog Assertion (SVA)&#30340;&#24418;&#24335;&#21270;&#26159;Formal Property Verification (FPV)&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#20294;&#22797;&#26434;&#30340;&#20219;&#21153;&#12290;&#20256;&#32479;&#19978;&#65292;SVA&#30340;&#24418;&#24335;&#21270;&#38656;&#35201;&#32463;&#39564;&#20016;&#23500;&#30340;&#19987;&#23478;&#35299;&#37322;&#35268;&#26684;&#12290;&#36825;&#26159;&#32791;&#26102;&#19988;&#23481;&#26131;&#20986;&#38169;&#30340;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36827;&#23637;&#20351;&#24471;&#22522;&#20110;LLM&#30340;&#33258;&#21160;&#26029;&#35328;&#29983;&#25104;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;LLM&#30340;&#27969;&#27700;&#32447;&#65292;&#29992;&#20110;&#20174;&#33258;&#28982;&#35821;&#35328;&#35268;&#26684;&#20013;&#29983;&#25104;&#33521;&#35821;&#12289;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#21644;SVA&#30340;&#26029;&#35328;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;OpenAI GPT4&#30340;&#33258;&#23450;&#20041;LLM&#29992;&#20110;&#23454;&#39564;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#27979;&#35797;&#24179;&#21488;&#26469;&#39564;&#35777;LLM&#29983;&#25104;&#30340;&#26029;&#35328;&#12290;&#21482;&#26377;43%&#30340;LLM&#29983;&#25104;&#30340;&#21407;&#22987;&#26029;&#35328;&#23384;&#22312;&#38169;&#35823;&#65292;&#21253;&#25324;&#35821;&#27861;&#21644;&#36923;&#36753;&#38169;&#35823;&#12290;&#36890;&#36807;&#20351;&#29992;&#20174;&#27979;&#35797;&#26696;&#20363;&#22833;&#36133;&#20013;&#24471;&#20986;&#30340;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#65292;&#36845;&#20195;&#22320;&#20419;&#20351;LLM&#65292;&#35813;&#27969;&#27700;&#32447;&#22312;&#26368;&#22810;&#20061;&#27425;&#25552;&#31034;&#36845;&#20195;&#21518;&#21487;&#20197;&#29983;&#25104;&#27491;&#30830;&#30340;SVA&#12290;
&lt;/p&gt;
&lt;p&gt;
System Verilog Assertion (SVA) formulation, a critical yet complex task, is a pre-requisite in the Formal Property Verification (FPV) process. Traditionally, SVA formulation involves expert-driven interpretation of specifications. This is time consuming and prone to human error. However, recent advances in Large Language Models (LLM), LLM-informed automatic assertion generation is gaining interest. We designed a novel LLM-based pipeline to generate assertions in English Language, Linear Temporal Logic, and SVA from natural language specifications. We developed a custom LLM-based on OpenAI GPT4 for our experiments. Furthermore, we developed testbenches to verify/validate the LLM-generated assertions. Only 43% of LLM-generated raw assertions had errors, including syntax and logical errors. By iteratively prompting the LLMs using carefully crafted prompts derived from test case failures, the pipeline could generate correct SVAs after a maximum of nine iterations of prompting. Our results 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#23545;&#33322;&#29677;&#28369;&#34892;&#23433;&#20840;&#30340;&#36305;&#36947;&#29289;&#20307;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#35780;&#20272;&#65292;&#20351;&#29992;&#24418;&#24335;&#26041;&#27861;&#35780;&#20272;&#20102;&#35813;&#20998;&#31867;&#22120;&#23545;&#19977;&#31181;&#24120;&#35265;&#22270;&#20687;&#25200;&#21160;&#31867;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21333;&#35843;&#24615;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.00035</link><description>&lt;p&gt;
&#33322;&#29677;&#28369;&#34892;&#23433;&#20840;&#30340;&#36305;&#36947;&#29289;&#20307;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Robustness Assessment of a Runway Object Classifier for Safe Aircraft Taxiing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00035
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#23545;&#33322;&#29677;&#28369;&#34892;&#23433;&#20840;&#30340;&#36305;&#36947;&#29289;&#20307;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#35780;&#20272;&#65292;&#20351;&#29992;&#24418;&#24335;&#26041;&#27861;&#35780;&#20272;&#20102;&#35813;&#20998;&#31867;&#22120;&#23545;&#19977;&#31181;&#24120;&#35265;&#22270;&#20687;&#25200;&#21160;&#31867;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21333;&#35843;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#22312;&#35768;&#22810;&#35745;&#31639;&#38382;&#39064;&#19978;&#25104;&#20026;&#20027;&#35201;&#35299;&#20915;&#26041;&#26696;&#65292;&#33322;&#31354;&#19994;&#24076;&#26395;&#25506;&#32034;&#23427;&#20204;&#22312;&#20943;&#36731;&#39134;&#34892;&#21592;&#36127;&#25285;&#21644;&#25913;&#21892;&#36816;&#33829;&#23433;&#20840;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#31867;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#20351;&#29992;DNNs&#38656;&#35201;&#36827;&#34892;&#24443;&#24213;&#30340;&#35748;&#35777;&#36807;&#31243;&#12290;&#36825;&#19968;&#38656;&#27714;&#21487;&#20197;&#36890;&#36807;&#24418;&#24335;&#39564;&#35777;&#26469;&#35299;&#20915;&#65292;&#24418;&#24335;&#39564;&#35777;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20445;&#35777;&#65292;&#20363;&#22914;&#35777;&#26126;&#26576;&#20123;&#35823;&#21028;&#30340;&#19981;&#23384;&#22312;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;Airbus&#24403;&#21069;&#27491;&#22312;&#24320;&#21457;&#30340;&#22270;&#20687;&#20998;&#31867;&#22120;DNN&#20316;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#26088;&#22312;&#22312;&#39134;&#26426;&#28369;&#34892;&#38454;&#27573;&#20351;&#29992;&#12290;&#25105;&#20204;&#20351;&#29992;&#24418;&#24335;&#26041;&#27861;&#26469;&#35780;&#20272;&#36825;&#20010;DNN&#23545;&#19977;&#31181;&#24120;&#35265;&#22270;&#20687;&#25200;&#21160;&#31867;&#22411;&#30340;&#40065;&#26834;&#24615;&#65306;&#22122;&#22768;&#12289;&#20142;&#24230;&#21644;&#23545;&#27604;&#24230;&#65292;&#20197;&#21450;&#23427;&#20204;&#30340;&#37096;&#20998;&#32452;&#21512;&#12290;&#36825;&#20010;&#36807;&#31243;&#28041;&#21450;&#22810;&#27425;&#35843;&#29992;&#24213;&#23618;&#39564;&#35777;&#22120;&#65292;&#36825;&#21487;&#33021;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#65307;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21333;&#35843;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
As deep neural networks (DNNs) are becoming the prominent solution for many computational problems, the aviation industry seeks to explore their potential in alleviating pilot workload and in improving operational safety. However, the use of DNNs in this type of safety-critical applications requires a thorough certification process. This need can be addressed through formal verification, which provides rigorous assurances -- e.g.,~by proving the absence of certain mispredictions. In this case-study paper, we demonstrate this process using an image-classifier DNN currently under development at Airbus and intended for use during the aircraft taxiing phase. We use formal methods to assess this DNN's robustness to three common image perturbation types: noise, brightness and contrast, and some of their combinations. This process entails multiple invocations of the underlying verifier, which might be computationally expensive; and we therefore propose a method that leverages the monotonicity
&lt;/p&gt;</description></item><item><title>&#26354;&#29575;&#26041;&#21521;&#30340;&#20007;&#22833;&#34987;&#35748;&#20026;&#26159;&#23548;&#33268;&#31070;&#32463;&#32593;&#32476;&#21487;&#22609;&#24615;&#20007;&#22833;&#30340;&#19968;&#20010;&#37325;&#35201;&#21407;&#22240;&#65292;&#24182;&#19988;&#25105;&#20204;&#36890;&#36807;&#31995;&#32479;&#35843;&#26597;&#21644;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30340;&#30740;&#31350;&#32467;&#26524;&#25903;&#25345;&#20102;&#36825;&#19968;&#35266;&#28857;&#12290;</title><link>https://arxiv.org/abs/2312.00246</link><description>&lt;p&gt;
&#26354;&#29575;&#26041;&#21521;&#20316;&#20026;&#22833;&#21435;&#21487;&#22609;&#24615;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Directions of Curvature as an Explanation for Loss of Plasticity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.00246
&lt;/p&gt;
&lt;p&gt;
&#26354;&#29575;&#26041;&#21521;&#30340;&#20007;&#22833;&#34987;&#35748;&#20026;&#26159;&#23548;&#33268;&#31070;&#32463;&#32593;&#32476;&#21487;&#22609;&#24615;&#20007;&#22833;&#30340;&#19968;&#20010;&#37325;&#35201;&#21407;&#22240;&#65292;&#24182;&#19988;&#25105;&#20204;&#36890;&#36807;&#31995;&#32479;&#35843;&#26597;&#21644;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30340;&#30740;&#31350;&#32467;&#26524;&#25903;&#25345;&#20102;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#22609;&#24615;&#30340;&#20007;&#22833;&#26159;&#31070;&#32463;&#32593;&#32476;&#20007;&#22833;&#20174;&#26032;&#32463;&#39564;&#23398;&#20064;&#33021;&#21147;&#30340;&#29616;&#35937;&#12290;&#23613;&#31649;&#22312;&#20960;&#31181;&#38382;&#39064;&#35774;&#32622;&#20013;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#65292;&#20294;&#23545;&#23548;&#33268;&#21487;&#22609;&#24615;&#20007;&#22833;&#30340;&#26426;&#21046;&#20102;&#35299;&#29978;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#21487;&#22609;&#24615;&#20007;&#22833;&#30340;&#19968;&#33268;&#35299;&#37322;&#65306;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20007;&#22833;&#20102;&#26354;&#29575;&#26041;&#21521;&#65292;&#21487;&#23558;&#21487;&#22609;&#24615;&#30340;&#20007;&#22833;&#24402;&#22240;&#20110;&#36825;&#31181;&#26354;&#29575;&#20943;&#23569;&#12290;&#20026;&#20102;&#25903;&#25345;&#36825;&#26679;&#30340;&#35828;&#27861;&#65292;&#25105;&#20204;&#23545;&#22312;MNIST&#12289;CIFAR-10&#21644;ImageNet&#20013;&#20351;&#29992;&#30340;&#19981;&#26029;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#21487;&#22609;&#24615;&#20007;&#22833;&#36827;&#34892;&#20102;&#31995;&#32479;&#35843;&#26597;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#26354;&#29575;&#26041;&#21521;&#30340;&#20007;&#22833;&#19982;&#21487;&#22609;&#24615;&#30340;&#20007;&#22833;&#30456;&#21563;&#21512;&#65292;&#21516;&#26102;&#36824;&#34920;&#26126;&#20197;&#21069;&#30340;&#35299;&#37322;&#19981;&#36275;&#20197;&#35299;&#37322;&#25152;&#26377;&#24773;&#20917;&#19979;&#30340;&#21487;&#22609;&#24615;&#20007;&#22833;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32531;&#35299;&#21487;&#22609;&#24615;&#20007;&#22833;&#30340;&#27491;&#21017;&#21270;&#22120;&#20063;&#20250;&#20445;&#30041;&#26354;&#29575;&#65292;&#20419;&#20351;&#37319;&#29992;&#31616;&#21333;&#30340;&#20998;&#24067;&#24335;&#27491;&#21017;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.00246v2 Announce Type: replace  Abstract: Loss of plasticity is a phenomenon in which neural networks lose their ability to learn from new experience. Despite being empirically observed in several problem settings, little is understood about the mechanisms that lead to loss of plasticity. In this paper, we offer a consistent explanation for loss of plasticity: Neural networks lose directions of curvature during training and that loss of plasticity can be attributed to this reduction in curvature. To support such a claim, we provide a systematic investigation of loss of plasticity across continual learning tasks using MNIST, CIFAR-10 and ImageNet. Our findings illustrate that loss of curvature directions coincides with loss of plasticity, while also showing that previous explanations are insufficient to explain loss of plasticity in all settings. Lastly, we show that regularizers which mitigate loss of plasticity also preserve curvature, motivating a simple distributional reg
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#22312;&#29289;&#32852;&#32593;&#20581;&#24247;&#25252;&#29702;&#20013;&#21033;&#29992;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#30340;&#24212;&#29992;&#12290;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#20316;&#20026;&#22810;&#21151;&#33021;&#12289;&#29983;&#21160;&#30340;&#20154;&#31867;&#25968;&#23383;&#27979;&#35797;&#24179;&#21488;&#65292;&#21487;&#20197;&#27169;&#25311;&#32467;&#26524;&#24182;&#25351;&#23548;&#23454;&#38469;&#27835;&#30103;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#32852;&#32593;&#20581;&#24247;&#25252;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.13699</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#29289;&#32852;&#32593;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#65306;&#19968;&#39033;&#32508;&#21512;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Generative AI-Driven Human Digital Twin in IoT-Healthcare: A Comprehensive Survey. (arXiv:2401.13699v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13699
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#22312;&#29289;&#32852;&#32593;&#20581;&#24247;&#25252;&#29702;&#20013;&#21033;&#29992;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#30340;&#24212;&#29992;&#12290;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#20316;&#20026;&#22810;&#21151;&#33021;&#12289;&#29983;&#21160;&#30340;&#20154;&#31867;&#25968;&#23383;&#27979;&#35797;&#24179;&#21488;&#65292;&#21487;&#20197;&#27169;&#25311;&#32467;&#26524;&#24182;&#25351;&#23548;&#23454;&#38469;&#27835;&#30103;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#32852;&#32593;&#20581;&#24247;&#25252;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#32852;&#32593;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20154;&#31867;&#29983;&#27963;&#30340;&#36136;&#37327;&#65292;&#29305;&#21035;&#26159;&#22312;&#20581;&#24247;&#25252;&#29702;&#26041;&#38754;&#21560;&#24341;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#12290;&#21516;&#26102;&#65292;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#21019;&#26032;&#30340;&#33539;&#24335;&#65292;&#21487;&#20197;&#20840;&#38754;&#22320;&#25551;&#36848;&#20010;&#20307;&#20154;&#20307;&#22312;&#25968;&#23383;&#19990;&#30028;&#20013;&#30340;&#22797;&#21046;&#65292;&#24182;&#23454;&#26102;&#21453;&#26144;&#20854;&#29289;&#29702;&#29366;&#20917;&#12290;&#33258;&#28982;&#22320;&#65292;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#34987;&#35774;&#24819;&#20026;&#36890;&#36807;&#20805;&#24403;&#22810;&#21151;&#33021;&#12289;&#29983;&#21160;&#30340;&#20154;&#31867;&#25968;&#23383;&#27979;&#35797;&#24179;&#21488;&#26469;&#22686;&#24378;&#29289;&#32852;&#32593;&#20581;&#24247;&#25252;&#29702;&#30340;&#33021;&#21147;&#65292;&#27169;&#25311;&#32467;&#26524;&#24182;&#25351;&#23548;&#23454;&#38469;&#27835;&#30103;&#12290;&#28982;&#32780;&#65292;&#25104;&#21151;&#24314;&#31435;&#20154;&#31867;&#25968;&#23383;&#23402;&#29983;&#38656;&#35201;&#39640;&#20445;&#30495;&#24230;&#30340;&#34394;&#25311;&#24314;&#27169;&#21644;&#24378;&#22823;&#30340;&#20449;&#24687;&#20132;&#20114;&#65292;&#20294;&#21487;&#33021;&#23384;&#22312;&#31232;&#32570;&#12289;&#20559;&#20506;&#21644;&#22122;&#22768;&#25968;&#25454;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#26368;&#36817;&#27969;&#34892;&#30340;&#19968;&#31181;&#21517;&#20026;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GAI&#65289;&#30340;&#25216;&#26415;&#21487;&#33021;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#21033;&#29992;&#20808;&#36827;&#30340;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#33258;&#21160;&#29983;&#25104;&#12289;&#25805;&#20316;&#21644;&#20462;&#25913;&#28176;&#21464;&#35270;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Internet of things (IoT) can significantly enhance the quality of human life, specifically in healthcare, attracting extensive attentions to IoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as an innovative paradigm that can comprehensively characterize the replication of the individual human body in the digital world and reflect its physical status in real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the application of healthcare monitoring by acting as a versatile and vivid human digital testbed, simulating the outcomes and guiding the practical treatments. However, successfully establishing HDT requires high-fidelity virtual modeling and strong information interactions but possibly with scarce, biased and noisy data. Fortunately, a recent popular technology called generative artificial intelligence (GAI) may be a promising solution because it can leverage advanced AI algorithms to automatically create, manipulate, and modify val
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20934;&#30830;&#39044;&#27979;&#24739;&#32773;&#30340;&#38750;&#20381;&#20174;&#39118;&#38505;&#21644;&#30456;&#20851;&#30340;&#31995;&#32479;&#30151;&#29366;&#35780;&#20998;&#65292;&#20026;&#38271;&#26399;&#36807;&#25935;&#24615;&#40763;&#28814;&#20122;&#21345;&#28608;&#32032;&#30382;&#19979;&#20813;&#30123;&#27835;&#30103;&#30340;&#31649;&#29702;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.11447</link><description>&lt;p&gt;
&#39044;&#27979;&#36807;&#25935;&#24615;&#40763;&#28814;&#20122;&#21345;&#28608;&#32032;&#30382;&#19979;&#20813;&#30123;&#27835;&#30103;&#20013;&#24739;&#32773;&#20381;&#20174;&#24615;&#30340;&#24207;&#21015;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis. (arXiv:2401.11447v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11447
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20934;&#30830;&#39044;&#27979;&#24739;&#32773;&#30340;&#38750;&#20381;&#20174;&#39118;&#38505;&#21644;&#30456;&#20851;&#30340;&#31995;&#32479;&#30151;&#29366;&#35780;&#20998;&#65292;&#20026;&#38271;&#26399;&#36807;&#25935;&#24615;&#40763;&#28814;&#20122;&#21345;&#28608;&#32032;&#30382;&#19979;&#20813;&#30123;&#27835;&#30103;&#30340;&#31649;&#29702;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#30382;&#19979;&#20813;&#30123;&#27835;&#30103;(SCIT)&#26159;&#36807;&#25935;&#24615;&#40763;&#28814;&#30340;&#38271;&#25928;&#22240;&#26524;&#27835;&#30103;&#12290;&#22914;&#20309;&#25552;&#39640;&#24739;&#32773;&#23545;&#21464;&#24212;&#21407;&#20813;&#30123;&#27835;&#30103;(AIT)&#30340;&#20381;&#20174;&#24615;&#20197;&#26368;&#22823;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#22312;AIT&#31649;&#29702;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20934;&#30830;&#39044;&#27979;&#24739;&#32773;&#30340;&#38750;&#20381;&#20174;&#39118;&#38505;&#21644;&#30456;&#20851;&#30340;&#31995;&#32479;&#30151;&#29366;&#35780;&#20998;&#65292;&#20026;&#38271;&#26399;AIT&#30340;&#31649;&#29702;&#25552;&#20379;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;&#26041;&#27861;&#65306;&#26412;&#30740;&#31350;&#24320;&#21457;&#21644;&#20998;&#26512;&#20102;&#20004;&#31181;&#27169;&#22411;&#65292;&#24207;&#21015;&#28508;&#22312;&#34892;&#20026;&#32773;-&#35780;&#35770;&#23478;&#27169;&#22411;(SLAC)&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#27169;&#22411;(LSTM)&#65292;&#24182;&#22522;&#20110;&#35780;&#20998;&#21644;&#20381;&#20174;&#24615;&#39044;&#27979;&#33021;&#21147;&#36827;&#34892;&#35780;&#20272;&#12290;&#32467;&#26524;&#65306;&#22312;&#25490;&#38500;&#31532;&#19968;&#26102;&#38388;&#27493;&#30340;&#20559;&#20506;&#26679;&#26412;&#21518;&#65292;SLAC&#27169;&#22411;&#30340;&#39044;&#27979;&#20381;&#20174;&#20934;&#30830;&#29575;&#20026;60%-72%&#65292;&#32780;LSTM&#27169;&#22411;&#30340;&#20934;&#30830;&#29575;&#20026;66%-84%&#65292;&#26681;&#25454;&#26102;&#38388;&#27493;&#38271;&#30340;&#19981;&#21516;&#32780;&#21464;&#21270;&#12290;SLAC&#27169;&#22411;&#30340;&#22343;&#26041;&#26681;&#35823;&#24046;(RMSE)&#33539;&#22260;&#22312;0.93&#21040;2.22&#20043;&#38388;&#65292;&#32780;LSTM&#27169;&#22411;&#30340;RMSE&#33539;&#22260;&#22312;...
&lt;/p&gt;
&lt;p&gt;
Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis. How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of patients and related systematic symptom scores, to provide a novel approach in the management of long-term AIT.  Methods: The research develops and analyzes two models, Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on scoring and adherence prediction capabilities.  Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from $60\,\%$ to $72\%$, and for LSTM models, it is $66\,\%$ to $84\,\%$, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and $2.22$, while for L
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37329;&#34701;&#31185;&#25216;&#24212;&#29992;&#20013;&#23547;&#25214;&#39640;&#36136;&#37327;&#30340;&#21452;&#30446;&#26631; Pareto &#26368;&#20248;&#27450;&#35784;&#39044;&#38450;&#35268;&#21017;&#38598;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#37319;&#29992; Pareto &#26368;&#20248;&#24615;&#27010;&#24565;&#21644;&#21551;&#21457;&#24335;&#26694;&#26550; PORS&#65292;&#25105;&#20204;&#25104;&#21151;&#25552;&#20986;&#20102;&#19968;&#32452;&#38750;&#25903;&#37197;&#30340;&#35268;&#21017;&#23376;&#38598;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.00964</link><description>&lt;p&gt;
&#22312;&#37329;&#34701;&#31185;&#25216;&#24212;&#29992;&#20013;&#23547;&#25214;&#21452;&#30446;&#26631; Pareto &#26368;&#20248;&#27450;&#35784;&#39044;&#38450;&#35268;&#21017;&#38598;
&lt;/p&gt;
&lt;p&gt;
On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications. (arXiv:2311.00964v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00964
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37329;&#34701;&#31185;&#25216;&#24212;&#29992;&#20013;&#23547;&#25214;&#39640;&#36136;&#37327;&#30340;&#21452;&#30446;&#26631; Pareto &#26368;&#20248;&#27450;&#35784;&#39044;&#38450;&#35268;&#21017;&#38598;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#37319;&#29992; Pareto &#26368;&#20248;&#24615;&#27010;&#24565;&#21644;&#21551;&#21457;&#24335;&#26694;&#26550; PORS&#65292;&#25105;&#20204;&#25104;&#21151;&#25552;&#20986;&#20102;&#19968;&#32452;&#38750;&#25903;&#37197;&#30340;&#35268;&#21017;&#23376;&#38598;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35268;&#21017;&#22312;&#37329;&#34701;&#31185;&#25216;&#26426;&#26500;&#20013;&#34987;&#24191;&#27867;&#29992;&#20110;&#36827;&#34892;&#27450;&#35784;&#39044;&#38450;&#20915;&#31574;&#65292;&#22240;&#20026;&#35268;&#21017;&#20855;&#26377;&#30452;&#35266;&#30340; if-then &#32467;&#26500;&#65292;&#26131;&#20110;&#29702;&#35299;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#22823;&#22411;&#37329;&#34701;&#31185;&#25216;&#26426;&#26500;&#36890;&#24120;&#37319;&#29992;&#20004;&#38454;&#27573;&#27450;&#35784;&#39044;&#38450;&#20915;&#31574;&#35268;&#21017;&#38598;&#25366;&#25496;&#26694;&#26550;&#12290;&#26412;&#25991;&#20851;&#27880;&#20110;&#20174;&#21021;&#22987;&#35268;&#21017;&#38598;&#20013;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#35268;&#21017;&#23376;&#38598;&#65292;&#20197;&#21452;&#30446;&#26631;&#31354;&#38388;&#65288;&#22914;&#31934;&#30830;&#29575;&#21644;&#21484;&#22238;&#29575;&#65289;&#20026;&#22522;&#30784;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#37319;&#29992; Pareto &#26368;&#20248;&#24615;&#27010;&#24565;&#65292;&#26088;&#22312;&#25214;&#21040;&#19968;&#32452;&#38750;&#25903;&#37197;&#30340;&#35268;&#21017;&#23376;&#38598;&#65292;&#26500;&#25104;&#19968;&#20010; Pareto &#21069;&#27839;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21551;&#21457;&#24335;&#30340;&#26694;&#26550; PORS&#65292;&#24182;&#30830;&#23450;&#20102; PORS &#30340;&#26680;&#24515;&#38382;&#39064;&#26159;&#21069;&#27839;&#35299;&#20915;&#26041;&#26696;&#36873;&#25321;&#65288;SSF&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545; SSF &#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#20998;&#31867;&#65292;&#24182;&#22312;&#20844;&#24320;&#21644;&#19987;&#26377;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#35777;&#35780;&#20272;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026; SpectralRules &#30340;&#26032;&#39062;&#21464;&#20307;&#30340;&#39034;&#24207;&#35206;&#30422;&#31639;&#27861;&#65292;&#20197;&#40723;&#21169;&#35268;&#21017;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rules are widely used in Fintech institutions to make fraud prevention decisions, since rules are highly interpretable thanks to their intuitive if-then structure. In practice, a two-stage framework of fraud prevention decision rule set mining is usually employed in large Fintech institutions. This paper is concerned with finding high-quality rule subsets in a bi-objective space (such as precision and recall) from an initial pool of rules. To this end, we adopt the concept of Pareto optimality and aim to find a set of non-dominated rule subsets, which constitutes a Pareto front. We propose a heuristic-based framework called PORS and we identify that the core of PORS is the problem of solution selection on the front (SSF). We provide a systematic categorization of the SSF problem and a thorough empirical evaluation of various SSF methods on both public and proprietary datasets. We also introduce a novel variant of sequential covering algorithm called SpectralRules to encourage the diver
&lt;/p&gt;</description></item><item><title>Fishnets&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#20449;&#24687;&#26368;&#20248;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#35268;&#27169;&#19978;&#21487;&#20197;&#20248;&#21270;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#33021;&#22815;&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#21487;&#29992;&#20110;GNNs&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#12290;</title><link>http://arxiv.org/abs/2310.03812</link><description>&lt;p&gt;
&#40060;&#32593;&#65306;&#20449;&#24687;&#26368;&#20248;&#65292;&#21487;&#25193;&#23637;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs. (arXiv:2310.03812v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03812
&lt;/p&gt;
&lt;p&gt;
Fishnets&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#20449;&#24687;&#26368;&#20248;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#35268;&#27169;&#19978;&#21487;&#20197;&#20248;&#21270;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#33021;&#22815;&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#21487;&#29992;&#20110;GNNs&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#38598;&#21512;&#30340;&#23398;&#20064;&#26159;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#21644;&#32593;&#32476;&#31185;&#23398;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#21450;&#20854;&#19981;&#21547;&#36793;&#30340;&#23545;&#24212;&#29289;Deepsets&#22312;&#19981;&#35268;&#21017;&#21644;&#25299;&#25169;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#19978;&#34987;&#35777;&#26126;&#38750;&#24120;&#26377;&#29992;&#12290;&#20026;&#20102;&#23398;&#20064;&#38598;&#21512;&#25104;&#21592;&#30340;&#20449;&#24687;&#20016;&#23500;&#30340;&#23884;&#20837;&#65292;&#20851;&#38190;&#26159;&#25351;&#23450;&#19968;&#20010;&#32858;&#21512;&#20989;&#25968;&#65292;&#36890;&#24120;&#26159;&#27714;&#21644;&#12289;&#26368;&#22823;&#20540;&#25110;&#22343;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Fishnets&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38598;&#21512;&#25968;&#25454;&#21644;&#22270;&#32858;&#21512;&#30340;&#20449;&#24687;&#26368;&#20248;&#23884;&#20837;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65306;i&#65289;Fishnets&#31070;&#32463;&#25688;&#35201;&#21487;&#20197;&#26368;&#20248;&#22320;&#25193;&#23637;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65307;ii&#65289;Fishnets&#32858;&#21512;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#25913;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#32780;&#26631;&#20934;&#30340;Deepsets&#19981;&#20855;&#22791;&#36825;&#31181;&#29305;&#24615;&#65307;iii&#65289;Fishnets&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#25193;&#23637;&#21040;MCMC&#25216;&#26415;&#22833;&#36133;&#30340;&#39046;&#22495;&#65307;iv&#65289;Fishnets&#21487;&#20197;&#20316;&#20026;GNN&#20013;&#30340;&#19968;&#20010;&#25554;&#20837;&#24335;&#32858;&#21512;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#37319;&#29992;Fishnets&#32858;&#21512;&#26041;&#26696;&#36827;&#34892;&#28040;&#24687;&#20256;&#36882;&#65292;GNNs&#21487;&#20197;&#23454;&#29616; &#36798;&#21040;
&lt;/p&gt;
&lt;p&gt;
Set-based learning is an essential component of modern deep learning and network science. Graph Neural Networks (GNNs) and their edge-free counterparts Deepsets have proven remarkably useful on ragged and topologically challenging datasets. The key to learning informative embeddings for set members is a specified aggregation function, usually a sum, max, or mean. We propose Fishnets, an aggregation strategy for learning information-optimal embeddings for sets of data for both Bayesian inference and graph aggregation. We demonstrate that i) Fishnets neural summaries can be scaled optimally to an arbitrary number of data objects, ii) Fishnets aggregations are robust to changes in data distribution, unlike standard deepsets, iii) Fishnets saturate Bayesian information content and extend to regimes where MCMC techniques fail and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We show that by adopting a Fishnets aggregation scheme for message passing, GNNs can achieve 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#35299;&#35835;&#33258;&#32534;&#30721;&#22120;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#20026;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#25968;&#25454;&#28857;&#20998;&#37197;&#29420;&#29305;&#30340;&#38543;&#26426;&#20002;&#24323;&#27169;&#24335;&#26469;&#36827;&#34892;&#35757;&#32451;&#65292;&#21482;&#20381;&#38752;&#37325;&#26500;&#35823;&#24046;&#26469;&#25552;&#20379;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#24615;&#33021;&#65292;&#24182;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#19982;DCGAN&#30456;&#23218;&#32654;&#30340;&#37319;&#26679;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.01712</link><description>&lt;p&gt;
&#20002;&#24323;&#27169;&#24335;&#30340;&#29983;&#25104;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Generative Autoencoding of Dropout Patterns. (arXiv:2310.01712v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#35299;&#35835;&#33258;&#32534;&#30721;&#22120;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#20026;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#25968;&#25454;&#28857;&#20998;&#37197;&#29420;&#29305;&#30340;&#38543;&#26426;&#20002;&#24323;&#27169;&#24335;&#26469;&#36827;&#34892;&#35757;&#32451;&#65292;&#21482;&#20381;&#38752;&#37325;&#26500;&#35823;&#24046;&#26469;&#25552;&#20379;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#24615;&#33021;&#65292;&#24182;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#19982;DCGAN&#30456;&#23218;&#32654;&#30340;&#37319;&#26679;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#35299;&#35835;&#33258;&#32534;&#30721;&#22120;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#20026;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#25968;&#25454;&#28857;&#20998;&#37197;&#19968;&#20010;&#21807;&#19968;&#30340;&#38543;&#26426;&#20002;&#24323;&#27169;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#36825;&#20010;&#27169;&#24335;&#20316;&#20026;&#34987;&#32534;&#30721;&#30340;&#20449;&#24687;&#26469;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#26469;&#37325;&#26500;&#30456;&#24212;&#30340;&#25968;&#25454;&#28857;&#12290;&#30001;&#20110;&#35299;&#35835;&#33258;&#32534;&#30721;&#22120;&#30340;&#35757;&#32451;&#20165;&#20381;&#36182;&#20110;&#37325;&#26500;&#35823;&#24046;&#65292;&#25152;&#20197;&#30456;&#27604;&#20854;&#20182;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#24615;&#33021;&#12290;&#23613;&#31649;&#23427;&#24456;&#31616;&#21333;&#65292;&#20294;&#35299;&#35835;&#33258;&#32534;&#30721;&#22120;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20986;&#20102;&#19982;DCGAN&#30456;&#23218;&#32654;&#30340;&#37319;&#26679;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a generative model termed Deciphering Autoencoders. In this model, we assign a unique random dropout pattern to each data point in the training dataset and then train an autoencoder to reconstruct the corresponding data point using this pattern as information to be encoded. Since the training of Deciphering Autoencoders relies solely on reconstruction error, it offers more stable training than other generative models. Despite its simplicity, Deciphering Autoencoders show comparable sampling quality to DCGAN on the CIFAR-10 dataset.
&lt;/p&gt;</description></item><item><title>3D-Mol&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;3D&#32467;&#26500;&#30340;&#20998;&#23376;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#25552;&#39640;&#20102;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.17366</link><description>&lt;p&gt;
3D-Mol: &#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#26694;&#26550;&#65292;&#21033;&#29992;&#20102;3D&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
3D-Mol: A Novel Contrastive Learning Framework for Molecular Property Prediction with 3D Information. (arXiv:2309.17366v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17366
&lt;/p&gt;
&lt;p&gt;
3D-Mol&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;3D&#32467;&#26500;&#30340;&#20998;&#23376;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#25552;&#39640;&#20102;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#20026;&#33647;&#29289;&#20505;&#36873;&#29289;&#30340;&#26089;&#26399;&#31579;&#36873;&#21644;&#20248;&#21270;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#19988;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#23613;&#31649;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20173;&#26410;&#20805;&#20998;&#21033;&#29992;3D&#31354;&#38388;&#20449;&#24687;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#21333;&#20010;&#20998;&#23376;&#34920;&#31034;&#22810;&#20010;&#23454;&#38469;&#20998;&#23376;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;3D-Mol&#30340;&#26032;&#39062;&#30340;&#22522;&#20110;3D&#32467;&#26500;&#30340;&#20998;&#23376;&#24314;&#27169;&#26041;&#27861;&#12290;&#20026;&#20102;&#20934;&#30830;&#34920;&#31034;&#23436;&#25972;&#30340;&#31354;&#38388;&#32467;&#26500;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32534;&#30721;&#22120;&#65292;&#36890;&#36807;&#23558;&#20998;&#23376;&#20998;&#35299;&#25104;&#19977;&#20010;&#20960;&#20309;&#22270;&#24418;&#26469;&#25552;&#21462;3D&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;20M&#20010;&#26080;&#26631;&#31614;&#25968;&#25454;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23545;&#27169;&#22411;&#36827;&#34892;&#39044;&#35757;&#32451;&#12290;&#25105;&#20204;&#23558;&#20855;&#26377;&#30456;&#21516;&#25299;&#25169;&#32467;&#26500;&#30340;&#26500;&#35937;&#35270;&#20026;&#27491;&#26679;&#26412;&#23545;&#65292;&#23558;&#30456;&#21453;&#30340;&#26500;&#35937;&#35270;&#20026;&#36127;&#26679;&#26412;&#23545;&#65292;&#32780;&#26435;&#37325;&#21017;&#30001;&#26500;&#35937;&#20043;&#38388;&#30340;&#24046;&#24322;&#30830;&#23450;&#12290;&#25105;&#20204;&#22312;7&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23558;3D-Mol&#19982;&#21508;&#31181;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#27169;&#22411;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Molecular property prediction offers an effective and efficient approach for early screening and optimization of drug candidates. Although deep learning based methods have made notable progress, most existing works still do not fully utilize 3D spatial information. This can lead to a single molecular representation representing multiple actual molecules. To address these issues, we propose a novel 3D structure-based molecular modeling method named 3D-Mol. In order to accurately represent complete spatial structure, we design a novel encoder to extract 3D features by deconstructing the molecules into three geometric graphs. In addition, we use 20M unlabeled data to pretrain our model by contrastive learning. We consider conformations with the same topological structure as positive pairs and the opposites as negative pairs, while the weight is determined by the dissimilarity between the conformations. We compare 3D-Mol with various state-of-the-art (SOTA) baselines on 7 benchmarks and de
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MESc&#30340;&#20998;&#23618;&#31070;&#32463;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31867;&#21644;&#35299;&#37322;&#22823;&#22411;&#38750;&#32467;&#26500;&#21270;&#27861;&#24459;&#25991;&#20214;&#12290;&#36890;&#36807;&#23558;&#25991;&#20214;&#20998;&#25104;&#22810;&#20010;&#37096;&#20998;&#24182;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23884;&#20837;&#21644;&#26080;&#30417;&#30563;&#32858;&#31867;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#23454;&#29616;&#20174;&#38271;&#25991;&#26723;&#20013;&#39044;&#27979;&#21028;&#20915;&#24182;&#25552;&#21462;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2309.10563</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#20998;&#31867;&#21644;&#35299;&#37322;&#22823;&#22411;&#38750;&#32467;&#26500;&#21270;&#27861;&#24459;&#25991;&#20214;&#30340;&#20998;&#23618;&#31070;&#32463;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Hierarchical Neural Framework for Classification and its Explanation in Large Unstructured Legal Documents. (arXiv:2309.10563v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MESc&#30340;&#20998;&#23618;&#31070;&#32463;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31867;&#21644;&#35299;&#37322;&#22823;&#22411;&#38750;&#32467;&#26500;&#21270;&#27861;&#24459;&#25991;&#20214;&#12290;&#36890;&#36807;&#23558;&#25991;&#20214;&#20998;&#25104;&#22810;&#20010;&#37096;&#20998;&#24182;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23884;&#20837;&#21644;&#26080;&#30417;&#30563;&#32858;&#31867;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#23454;&#29616;&#20174;&#38271;&#25991;&#26723;&#20013;&#39044;&#27979;&#21028;&#20915;&#24182;&#25552;&#21462;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#21450;&#20854;&#35299;&#37322;&#24120;&#24120;&#38754;&#20020;&#38271;&#36798;&#25968;&#19975;&#23383;&#30340;&#26696;&#20363;&#25991;&#20214;&#21644;&#38750;&#32479;&#19968;&#32467;&#26500;&#30340;&#38382;&#39064;&#12290;&#22312;&#27809;&#26377;&#32467;&#26500;&#26631;&#27880;&#30340;&#25991;&#20214;&#19978;&#39044;&#27979;&#21028;&#20915;&#24182;&#25552;&#21462;&#35299;&#37322;&#21464;&#24471;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#26412;&#35770;&#25991;&#23558;&#36825;&#19968;&#38382;&#39064;&#23450;&#20041;&#20026;&#8220;&#31232;&#32570;&#26631;&#27880;&#27861;&#24459;&#25991;&#20214;&#8221;&#65292;&#24182;&#36890;&#36807;&#19968;&#31181;&#31216;&#20026;MESc&#65288;&#22522;&#20110;&#22810;&#38454;&#27573;&#32534;&#30721;&#22120;&#30340;&#24102;&#32858;&#31867;&#30340;&#30417;&#30563;&#65289;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#26694;&#26550;&#26469;&#25506;&#32034;&#32570;&#20047;&#32467;&#26500;&#20449;&#24687;&#21644;&#38271;&#25991;&#26723;&#30340;&#29305;&#28857;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#25991;&#26723;&#20998;&#25104;&#22810;&#20010;&#37096;&#20998;&#65292;&#20174;&#33258;&#23450;&#20041;&#24494;&#35843;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26368;&#21518;&#22235;&#20010;&#23618;&#20013;&#25552;&#21462;&#23427;&#20204;&#30340;&#23884;&#20837;&#65292;&#24182;&#35797;&#22270;&#36890;&#36807;&#26080;&#30417;&#30563;&#32858;&#31867;&#26469;&#36817;&#20284;&#23427;&#20204;&#30340;&#32467;&#26500;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#21478;&#19968;&#32452;Transformer&#32534;&#30721;&#22120;&#23618;&#23398;&#20064;&#37096;&#20998;&#20043;&#38388;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#22810;&#21313;&#20159;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic legal judgment prediction and its explanation suffer from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents and extracting their explanation becomes a challenging task, more so on documents with no structural annotation. We define this problem as "scarce annotated legal documents" and explore their lack of structural information and their long lengths with a deep learning-based classification framework which we call MESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgment prediction. Specifically, we divide a document into parts to extract their embeddings from the last four layers of a custom fine-tuned Large Language Model, and try to approximate their structure through unsupervised clustering. Which we use in another set of transformer encoder layers to learn the inter-chunk representations. We explore the adaptability of LLMs with multi-billion
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;Mendelson&#22797;&#26434;&#24615;&#21644;&#24230;&#37327;&#29109;&#26469;&#21051;&#30011;&#20854;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#26368;&#20248;&#27604;&#29575;&#38543;&#30528;&#32500;&#24230;&#19982;&#26679;&#26412;&#22823;&#23567;&#20851;&#31995;&#30340;&#21464;&#21270;&#21576;&#29616;&#20986;&#22810;&#27425;&#19979;&#38477;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2309.04268</link><description>&lt;p&gt;
&#22823;&#32500;&#24230;&#24773;&#20917;&#19979;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;
&lt;/p&gt;
&lt;p&gt;
Optimal Rate of Kernel Regression in Large Dimensions. (arXiv:2309.04268v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04268
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;Mendelson&#22797;&#26434;&#24615;&#21644;&#24230;&#37327;&#29109;&#26469;&#21051;&#30011;&#20854;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#26368;&#20248;&#27604;&#29575;&#38543;&#30528;&#32500;&#24230;&#19982;&#26679;&#26412;&#22823;&#23567;&#20851;&#31995;&#30340;&#21464;&#21270;&#21576;&#29616;&#20986;&#22810;&#27425;&#19979;&#38477;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#65288;&#26679;&#26412;&#22823;&#23567;$n$&#19982;&#26679;&#26412;&#32500;&#24230;$d$&#30340;&#20851;&#31995;&#20026;&#22810;&#39033;&#24335;&#65292;&#21363;$n\asymp d^{\gamma}$&#65292;&#20854;&#20013;$\gamma&gt;0$&#65289;&#30340;&#26680;&#22238;&#24402;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;Mendelson&#22797;&#26434;&#24615;$\varepsilon_{n}^{2}$&#21644;&#24230;&#37327;&#29109;$\bar{\varepsilon}_{n}^{2}$&#26469;&#24314;&#31435;&#19968;&#20010;&#36890;&#29992;&#24037;&#20855;&#65292;&#29992;&#20110;&#21051;&#30011;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#23646;&#20110;&#19982;$\mathbb{S}^{d}$&#19978;&#23450;&#20041;&#30340;&#65288;&#19968;&#33324;&#65289;&#20869;&#31215;&#27169;&#22411;&#30456;&#20851;&#32852;&#30340;RKHS&#26102;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#26032;&#24037;&#20855;&#26469;&#23637;&#31034;&#26680;&#22238;&#24402;&#30340;&#36807;&#37327;&#39118;&#38505;&#30340;&#26368;&#23567;&#21270;&#29575;&#26159;$n^{-1/2}$&#65292;&#24403;$n\asymp d^{\gamma}$&#65292;&#20854;&#20013;$\gamma=2, 4, 6, 8, \cdots$&#12290;&#28982;&#21518;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#23545;&#20110;&#25152;&#26377;$\gamma&gt;0$&#65292;&#26680;&#22238;&#24402;&#36807;&#37327;&#39118;&#38505;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#24182;&#21457;&#29616;&#38543;&#30528;$\gamma$&#30340;&#21464;&#21270;&#65292;&#26368;&#20248;&#27604;&#29575;&#30340;&#26354;&#32447;&#23637;&#29616;&#20986;&#20960;&#20010;&#26032;&#29616;&#35937;&#65292;&#21253;&#25324;&#22810;&#27425;&#19979;&#38477;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
We perform a study on kernel regression for large-dimensional data (where the sample size $n$ is polynomially depending on the dimension $d$ of the samples, i.e., $n\asymp d^{\gamma}$ for some $\gamma &gt;0$ ). We first build a general tool to characterize the upper bound and the minimax lower bound of kernel regression for large dimensional data through the Mendelson complexity $\varepsilon_{n}^{2}$ and the metric entropy $\bar{\varepsilon}_{n}^{2}$ respectively. When the target function falls into the RKHS associated with a (general) inner product model defined on $\mathbb{S}^{d}$, we utilize the new tool to show that the minimax rate of the excess risk of kernel regression is $n^{-1/2}$ when $n\asymp d^{\gamma}$ for $\gamma =2, 4, 6, 8, \cdots$. We then further determine the optimal rate of the excess risk of kernel regression for all the $\gamma&gt;0$ and find that the curve of optimal rate varying along $\gamma$ exhibits several new phenomena including the {\it multiple descent behavior
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Deep Maxout&#32593;&#32476;&#29305;&#24449;&#34701;&#21512;&#21644;Political Tangent Search&#20248;&#21270;&#22120;&#30340;&#36716;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#22320;&#20013;&#28023;&#36139;&#34880;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#23545;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#24182;&#21033;&#29992;Deep Maxout&#32593;&#32476;&#30340;&#29305;&#24449;&#34701;&#21512;&#21644;&#36807;&#37319;&#26679;&#26041;&#27861;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;&#26368;&#32456;&#36890;&#36807;&#36716;&#31227;&#23398;&#20064;&#36827;&#34892;&#22320;&#20013;&#28023;&#36139;&#34880;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.02029</link><description>&lt;p&gt;
&#22522;&#20110;Deep Maxout&#32593;&#32476;&#29305;&#24449;&#34701;&#21512;&#21644;Political Tangent Search&#20248;&#21270;&#22120;&#30340;&#36716;&#31227;&#23398;&#20064;&#22312;&#22320;&#20013;&#28023;&#36139;&#34880;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Maxout Network-based Feature Fusion and Political Tangent Search Optimizer enabled Transfer Learning for Thalassemia Detection. (arXiv:2308.02029v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02029
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Deep Maxout&#32593;&#32476;&#29305;&#24449;&#34701;&#21512;&#21644;Political Tangent Search&#20248;&#21270;&#22120;&#30340;&#36716;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#22320;&#20013;&#28023;&#36139;&#34880;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#23545;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#24182;&#21033;&#29992;Deep Maxout&#32593;&#32476;&#30340;&#29305;&#24449;&#34701;&#21512;&#21644;&#36807;&#37319;&#26679;&#26041;&#27861;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;&#26368;&#32456;&#36890;&#36807;&#36716;&#31227;&#23398;&#20064;&#36827;&#34892;&#22320;&#20013;&#28023;&#36139;&#34880;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#20013;&#28023;&#36139;&#34880;&#26159;&#19968;&#31181;&#36951;&#20256;&#24615;&#34880;&#28082;&#30149;&#65292;&#30001;&#36951;&#20256;&#32570;&#38519;&#23548;&#33268;&#34880;&#32418;&#34507;&#30333;&#22810;&#32957;&#38142;&#30340;&#20135;&#29983;&#19981;&#36275;&#12290;&#28982;&#32780;&#65292;&#23545;&#36825;&#20123;&#22320;&#21306;&#30340;&#21457;&#30149;&#39057;&#29575;&#21644;&#20849;&#20139;&#31243;&#24230;&#30340;&#20102;&#35299;&#36739;&#23569;&#12290;&#20102;&#35299;&#22320;&#20013;&#28023;&#36139;&#34880;&#21457;&#29983;&#30340;&#39057;&#29575;&#21644;&#21487;&#38752;&#31361;&#21464;&#26159;&#39044;&#38450;&#12289;&#25511;&#21046;&#21644;&#27835;&#30103;&#35745;&#21010;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;Political Tangent Search&#20248;&#21270;&#22120;&#30340;&#36716;&#31227;&#23398;&#20064;&#65288;PTSO_TL&#65289;&#22312;&#22320;&#20013;&#28023;&#36139;&#34880;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;&#12290;&#39318;&#20808;&#65292;&#20174;&#29305;&#23450;&#25968;&#25454;&#38598;&#33719;&#21462;&#30340;&#36755;&#20837;&#25968;&#25454;&#22312;&#25968;&#25454;&#24402;&#19968;&#21270;&#38454;&#27573;&#36827;&#34892;&#20102;&#35268;&#33539;&#21270;&#12290;&#25968;&#25454;&#24402;&#19968;&#21270;&#38454;&#27573;&#21033;&#29992;&#20998;&#20301;&#25968;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#28982;&#21518;&#23558;&#25968;&#25454;&#20256;&#36882;&#32473;&#29305;&#24449;&#34701;&#21512;&#38454;&#27573;&#65292;&#22312;&#35813;&#38454;&#27573;&#21033;&#29992;Deep Maxout&#32593;&#32476;&#30340;&#21152;&#26435;&#27431;&#27663;&#36317;&#31163;&#36827;&#34892;&#29305;&#24449;&#34701;&#21512;&#12290;&#28982;&#21518;&#65292;&#20351;&#29992;&#36807;&#37319;&#26679;&#26041;&#27861;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#20197;&#22686;&#21152;&#25968;&#25454;&#32500;&#24230;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#36716;&#31227;&#23398;&#20064;&#36827;&#34892;&#22320;&#20013;&#28023;&#36139;&#34880;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thalassemia is a heritable blood disorder which is the outcome of a genetic defect causing lack of production of hemoglobin polypeptide chains. However, there is less understanding of the precise frequency as well as sharing in these areas. Knowing about the frequency of thalassemia occurrence and dependable mutations is thus a significant step in preventing, controlling, and treatment planning. Here, Political Tangent Search Optimizer based Transfer Learning (PTSO_TL) is introduced for thalassemia detection. Initially, input data obtained from a particular dataset is normalized in the data normalization stage. Quantile normalization is utilized in the data normalization stage, and the data are then passed to the feature fusion phase, in which Weighted Euclidean Distance with Deep Maxout Network (DMN) is utilized. Thereafter, data augmentation is performed using the oversampling method to increase data dimensionality. Lastly, thalassemia detection is carried out by TL, wherein a convol
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;SciBench&#30340;&#22522;&#20934;&#22871;&#20214;&#65292;&#26088;&#22312;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22823;&#23398;&#27700;&#24179;&#31185;&#23398;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#36827;&#34892;&#35780;&#20272;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#20379;&#22797;&#26434;&#31185;&#23398;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#26041;&#38754;&#36824;&#26377;&#19981;&#36275;&#20043;&#22788;&#12290;</title><link>http://arxiv.org/abs/2307.10635</link><description>&lt;p&gt;
SciBench: &#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#22823;&#23398;&#27700;&#24179;&#30340;&#31185;&#23398;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models. (arXiv:2307.10635v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10635
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;SciBench&#30340;&#22522;&#20934;&#22871;&#20214;&#65292;&#26088;&#22312;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22823;&#23398;&#27700;&#24179;&#31185;&#23398;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#36827;&#34892;&#35780;&#20272;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#20379;&#22797;&#26434;&#31185;&#23398;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#26041;&#38754;&#36824;&#26377;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#36827;&#23637;&#22312;&#35768;&#22810;&#25968;&#23398;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#27493;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22522;&#20934;&#22823;&#22810;&#21482;&#21253;&#21547;&#21021;&#39640;&#20013;&#31185;&#30446;&#30340;&#38382;&#39064;&#65292;&#20165;&#21253;&#21547;&#22810;&#39033;&#36873;&#25321;&#39064;&#65292;&#24182;&#19988;&#20165;&#38480;&#20110;&#22522;&#26412;&#31639;&#26415;&#36816;&#31639;&#33539;&#22260;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#22522;&#20934;&#22871;&#20214;SciBench&#65292;&#26088;&#22312;&#31995;&#32479;&#22320;&#26816;&#27979;&#22797;&#26434;&#31185;&#23398;&#38382;&#39064;&#35299;&#20915;&#25152;&#38656;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;SciBench&#21253;&#21547;&#20004;&#20010;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#65306;&#19968;&#20010;&#24320;&#25918;&#38598;&#65292;&#21253;&#25324;&#20174;&#25968;&#23398;&#12289;&#21270;&#23398;&#21644;&#29289;&#29702;&#25945;&#31185;&#20070;&#20013;&#25688;&#24405;&#30340;&#22823;&#23398;&#27700;&#24179;&#30340;&#31185;&#23398;&#38382;&#39064;&#65292;&#20197;&#21450;&#19968;&#20010;&#23553;&#38381;&#38598;&#65292;&#21253;&#21547;&#26469;&#33258;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#25968;&#23398;&#26412;&#31185;&#32771;&#35797;&#30340;&#38382;&#39064;&#12290;&#22522;&#20110;&#36825;&#20004;&#20010;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23545;&#20004;&#20010;&#20195;&#34920;&#24615;&#30340;LLM&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#24182;&#37319;&#29992;&#19981;&#21516;&#30340;&#25552;&#31034;&#31574;&#30053;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21069;&#30340;LLMs&#22312;&#25552;&#20379;&#22797;&#26434;&#31185;&#23398;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#26041;&#38754;&#36824;&#23384;&#22312;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in large language models (LLMs) have demonstrated notable progress on many mathematical benchmarks. However, most of these benchmarks only feature problems grounded in junior and senior high school subjects, contain only multiple-choice questions, and are confined to a limited scope of elementary arithmetic operations. To address these issues, this paper introduces an expansive benchmark suite SciBench that aims to systematically examine the reasoning capabilities required for complex scientific problem solving. SciBench contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set comprising problems from undergraduate-level exams in computer science and mathematics. Based on the two datasets, we conduct an in-depth benchmark study of two representative LLMs with various prompting strategies. The results reveal that current LLMs fall short of deli
&lt;/p&gt;</description></item><item><title>MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.03565</link><description>&lt;p&gt;
MALIBO: &#20803;&#23398;&#20064;&#24212;&#29992;&#20110;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
MALIBO: Meta-learning for Likelihood-free Bayesian Optimization. (arXiv:2307.03565v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03565
&lt;/p&gt;
&lt;p&gt;
MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20250;&#20174;&#22836;&#24320;&#22987;&#20248;&#21270;&#27599;&#20010;&#26032;&#30340;&#30446;&#26631;&#20219;&#21153;&#65292;&#32780;&#20803;&#23398;&#20064;&#21017;&#26159;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#30340;&#30693;&#35782;&#26469;&#26356;&#24555;&#22320;&#20248;&#21270;&#26032;&#20219;&#21153;&#30340;&#19968;&#31181;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#20381;&#36182;&#20110;&#26631;&#20934;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#23384;&#22312;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#23545;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#35266;&#23519;&#25968;&#25454;&#30340;&#23610;&#24230;&#21644;&#22122;&#22768;&#31867;&#22411;&#38750;&#24120;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#24120;&#24120;&#24573;&#35270;&#19982;&#20219;&#21153;&#30456;&#20284;&#24615;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#23548;&#33268;&#22312;&#20165;&#26377;&#26377;&#38480;&#35266;&#23519;&#25968;&#25454;&#25110;&#26032;&#20219;&#21153;&#19982;&#30456;&#20851;&#20219;&#21153;&#24046;&#24322;&#26174;&#33879;&#26102;&#65292;&#20219;&#21153;&#36866;&#24212;&#24615;&#19981;&#21487;&#38752;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#32469;&#24320;&#26631;&#20934;&#27169;&#22411;&#65292;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#30830;&#24314;&#27169;&#20219;&#21153;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#23545;&#26032;&#20219;&#21153;&#36827;&#34892;&#31283;&#20581;&#36866;&#24212;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is a popular method to optimize costly black-box functions. While traditional BO optimizes each new target task from scratch, meta-learning has emerged as a way to leverage knowledge from related tasks to optimize new tasks faster. However, existing meta-learning BO methods rely on surrogate models that suffer from scalability issues and are sensitive to observations with different scales and noise types across tasks. Moreover, they often overlook the uncertainty associated with task similarity. This leads to unreliable task adaptation when only limited observations are obtained or when the new tasks differ significantly from the related tasks. To address these limitations, we propose a novel meta-learning BO approach that bypasses the surrogate model and directly learns the utility of queries across tasks. Our method explicitly models task uncertainty and includes an auxiliary model to enable robust adaptation to new tasks. Extensive experiments show that ou
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#24341;&#20837;&#32593;&#32476;&#36890;&#20449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#39640;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#23398;&#20064;&#25928;&#29575;&#30340;&#26041;&#26696;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#38469;&#23454;&#39564;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.02766</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#30340;&#32593;&#32476;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
Networked Communication for Decentralised Agents in Mean-Field Games. (arXiv:2306.02766v2 [cs.MA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#24341;&#20837;&#32593;&#32476;&#36890;&#20449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#39640;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#23398;&#20064;&#25928;&#29575;&#30340;&#26041;&#26696;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#38469;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#32593;&#32476;&#36890;&#20449;&#24341;&#20837;&#22343;&#22330;&#21338;&#24328;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#22312;&#26080;oracle&#30340;&#24773;&#20917;&#19979;&#65292;N&#20010;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#27839;&#30528;&#32463;&#36807;&#30340;&#32463;&#39564;&#31995;&#32479;&#30340;&#21333;&#19968;&#38750;&#21608;&#26399;&#28436;&#21270;&#36335;&#24452;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26550;&#26500;&#22312;&#21482;&#26377;&#19968;&#20123;&#20851;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#21512;&#29702;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#26679;&#26412;&#20445;&#35777;&#65292;&#22312;&#38598;&#20013;&#23398;&#20064;&#21644;&#29420;&#31435;&#23398;&#20064;&#24773;&#20917;&#20043;&#38388;&#26377;&#30028;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#19977;&#20010;&#29702;&#35770;&#31639;&#27861;&#30340;&#26679;&#26412;&#20445;&#35777;&#23454;&#38469;&#19978;&#24182;&#19981;&#20250;&#23548;&#33268;&#23454;&#38469;&#25910;&#25947;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#65292;&#24403;&#29702;&#35770;&#21442;&#25968;&#26410;&#34987;&#35266;&#23519;&#21040;&#65288;&#23548;&#33268;Q&#20989;&#25968;&#30340;&#20272;&#35745;&#19981;&#20934;&#30830;&#65289;&#26102;&#65292;&#25105;&#20204;&#30340;&#36890;&#20449;&#26041;&#26696;&#26174;&#33879;&#21152;&#36895;&#20102;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#26080;&#38656;&#20381;&#36182;&#20110;&#19968;&#20010;&#19981;&#21487;&#21462;&#30340;&#38598;&#20013;&#24335;&#25511;&#21046;&#22120;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#23545;&#19977;&#20010;&#29702;&#35770;&#31639;&#27861;&#36827;&#34892;&#20102;&#20960;&#31181;&#23454;&#38469;&#30340;&#25913;&#36827;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23637;&#31034;&#23427;&#20204;&#30340;&#31532;&#19968;&#20010;&#23454;&#35777;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce networked communication to the mean-field game framework, in particular to oracle-free settings where $N$ decentralised agents learn along a single, non-episodic evolution path of the empirical system. We prove that our architecture, with only a few reasonable assumptions about network structure, has sample guarantees bounded between those of the centralised- and independent-learning cases. We discuss how the sample guarantees of the three theoretical algorithms do not actually result in practical convergence. Accordingly, we show that in practical settings where the theoretical parameters are not observed (leading to poor estimation of the Q-function), our communication scheme significantly accelerates convergence over the independent case, without relying on the undesirable assumption of a centralised controller. We contribute several further practical enhancements to all three theoretical algorithms, allowing us to showcase their first empirical demonstrations. Our expe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32467;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#39564;&#35777;&#30340;&#26041;&#27861;&#26469;&#33258;&#21160;&#39564;&#35777;&#21644;&#20462;&#22797;&#36719;&#20214;&#28431;&#27934;&#65292;&#24182;&#36890;&#36807;ESBMC-AI&#20570;&#20986;&#20102;&#27010;&#24565;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.14752</link><description>&lt;p&gt;
&#36208;&#21521;&#36719;&#20214;&#33258;&#24840;&#65306;&#32467;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#39564;&#35777;&#35299;&#20915;&#36719;&#20214;&#23433;&#20840;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification. (arXiv:2305.14752v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14752
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32467;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#39564;&#35777;&#30340;&#26041;&#27861;&#26469;&#33258;&#21160;&#39564;&#35777;&#21644;&#20462;&#22797;&#36719;&#20214;&#28431;&#27934;&#65292;&#24182;&#36890;&#36807;ESBMC-AI&#20570;&#20986;&#20102;&#27010;&#24565;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#21270;&#39564;&#35777;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#20351;&#24471;&#36719;&#20214;&#28431;&#27934;&#21487;&#20197;&#24471;&#21040;&#39564;&#35777;&#21644;&#33258;&#21160;&#20462;&#22797;&#12290;&#39318;&#20808;&#21033;&#29992;&#26377;&#38480;&#27169;&#22411;&#26816;&#26597;&#65288;BMC&#65289;&#23450;&#20301;&#36719;&#20214;&#28431;&#27934;&#21644;&#27966;&#29983;&#21453;&#20363;&#12290;&#28982;&#21518;&#65292;&#23558;&#21453;&#20363;&#21644;&#28304;&#20195;&#30721;&#25552;&#20379;&#32473;&#22823;&#35821;&#35328;&#27169;&#22411;&#24341;&#25806;&#36827;&#34892;&#20195;&#30721;&#35843;&#35797;&#21644;&#29983;&#25104;&#65292;&#20174;&#32780;&#25214;&#21040;&#28431;&#27934;&#30340;&#26681;&#26412;&#21407;&#22240;&#24182;&#20462;&#22797;&#20195;&#30721;&#12290;&#26368;&#21518;&#65292;&#21017;&#20351;&#29992;BMC&#39564;&#35777;&#22823;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#20462;&#27491;&#29256;&#26412;&#30340;&#20195;&#30721;&#12290; &#20316;&#20026;&#27010;&#24565;&#35777;&#26126;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;ESBMC-AI&#65292;&#23427;&#22522;&#20110;&#39640;&#25928;&#30340;&#22522;&#20110;SMT&#30340;&#19978;&#19979;&#25991;&#26377;&#30028;&#27169;&#22411;&#26816;&#26597;&#22120;&#65288;ESBMC&#65289;&#21644;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;gpt-3.5-turbo&#26469;&#26816;&#27979;&#21644;&#20462;&#22797;C&#31243;&#24207;&#20013;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we present a novel solution that combines the capabilities of Large Language Models (LLMs) with Formal Verification strategies to verify and automatically repair software vulnerabilities. Initially, we employ Bounded Model Checking (BMC) to locate the software vulnerability and derive a counterexample. The counterexample provides evidence that the system behaves incorrectly or contains a vulnerability. The counterexample that has been detected, along with the source code, are provided to the LLM engine. Our approach involves establishing a specialized prompt language for conducting code debugging and generation to understand the vulnerability's root cause and repair the code. Finally, we use BMC to verify the corrected version of the code generated by the LLM. As a proof of concept, we create ESBMC-AI based on the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C program
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23646;&#24615;&#24341;&#23548;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;PGVAE&#65289;&#65292;&#36890;&#36807;&#23646;&#24615;&#20540;&#26126;&#30830;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#65292;&#20351;&#24471;MBO&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#19978;&#31283;&#20581;&#22320;&#23547;&#25214;&#20855;&#26377;&#25913;&#36827;&#23646;&#24615;&#30340;&#24207;&#21015;&#12290;</title><link>http://arxiv.org/abs/2305.13650</link><description>&lt;p&gt;
&#38754;&#21521;&#19981;&#22343;&#34913;&#25968;&#25454;&#30340;&#40065;&#26834;&#22522;&#20110;&#27169;&#22411;&#30340;&#35774;&#35745;&#30340;&#23646;&#24615;&#24341;&#23548;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Property-Guided Generative Modelling for Robust Model-Based Design with Imbalanced Data. (arXiv:2305.13650v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23646;&#24615;&#24341;&#23548;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;PGVAE&#65289;&#65292;&#36890;&#36807;&#23646;&#24615;&#20540;&#26126;&#30830;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#65292;&#20351;&#24471;MBO&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#19978;&#31283;&#20581;&#22320;&#23547;&#25214;&#20855;&#26377;&#25913;&#36827;&#23646;&#24615;&#30340;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20855;&#26377;&#29305;&#23450;&#23646;&#24615;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#36825;&#38656;&#35201;&#25506;&#32034;&#20855;&#26377;&#26497;&#24230;&#31232;&#30095;&#30340;&#26377;&#24847;&#20041;&#21306;&#22495;&#30340;&#39640;&#32500;&#34507;&#30333;&#36136;&#24207;&#21015;&#31354;&#38388;&#12290;&#36825;&#23548;&#33268;&#20102;&#27169;&#22411;&#20248;&#21270;&#65288;MBO&#65289;&#25216;&#26415;&#30340;&#21457;&#23637;&#65292;&#36890;&#36807;&#20351;&#29992;&#30001;&#24207;&#21015;&#31354;&#38388;&#20013;&#30340;&#23646;&#24615;&#24341;&#23548;&#30340;&#26377;&#25928;&#25628;&#32034;&#27169;&#22411;&#26469;&#36741;&#21161;&#35774;&#35745;&#12290;&#28982;&#32780;&#65292;&#23454;&#39564;&#33719;&#24471;&#30340;&#25968;&#25454;&#38598;&#30340;&#20869;&#22312;&#19981;&#24179;&#34913;&#24615;&#20351;&#24471;&#29616;&#26377;&#30340;MBO&#26041;&#27861;&#24456;&#38590;&#25110;&#26681;&#26412;&#26080;&#27861;&#22788;&#29702;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23646;&#24615;&#24341;&#23548;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;PGVAE&#65289;&#65292;&#20854;&#28508;&#22312;&#31354;&#38388;&#30001;&#23646;&#24615;&#20540;&#26126;&#30830;&#32467;&#26500;&#21270;&#65292;&#20351;&#24471;&#25353;&#29031;&#36825;&#20123;&#23646;&#24615;&#20540;&#20248;&#20808;&#32771;&#34385;&#26679;&#26412;&#12290;&#36890;&#36807;&#23545;&#30495;&#23454;&#21644;&#21322;&#21512;&#25104;&#34507;&#30333;&#36136;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#22522;&#20934;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MBO&#19982;PGVAE&#31283;&#20581;&#22320;&#21457;&#29616;&#20855;&#26377;&#25913;&#36827;&#23646;&#24615;&#30340;&#24207;&#21015;&#65292;&#23613;&#31649;&#25968;&#25454;&#38598;&#23384;&#22312;&#26174;&#33879;&#30340;&#19981;&#24179;&#34913;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#36830;&#32493;&#35774;&#35745;&#31354;&#38388;&#30340;&#26222;&#36866;&#24615;&#21450;&#20854;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of designing protein sequences with desired properties is challenging, as it requires to explore a high-dimensional protein sequence space with extremely sparse meaningful regions. This has led to the development of model-based optimization (MBO) techniques that aid in the design, by using effective search models guided by the properties over the sequence space. However, the intrinsic imbalanced nature of experimentally derived datasets causes existing MBO approaches to struggle or outright fail. We propose a property-guided variational auto-encoder (PGVAE) whose latent space is explicitly structured by the property values such that samples are prioritized according to these properties. Through extensive benchmarking on real and semi-synthetic protein datasets, we demonstrate that MBO with PGVAE robustly finds sequences with improved properties despite significant dataset imbalances. We further showcase the generality of our approach to continuous design spaces, and its rob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IsEM-Pro&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#32473;&#23450;&#36866;&#24212;&#24615;&#26631;&#20934;&#29983;&#25104;&#34507;&#30333;&#36136;&#24207;&#21015;&#12290;&#22312;&#25512;&#29702;&#26399;&#38388;&#65292;&#20174;&#20854;&#28508;&#22312;&#31354;&#38388;&#37319;&#26679;&#21487;&#20197;&#22686;&#21152;&#22810;&#26679;&#24615;&#65292;&#25351;&#23548;&#20102;&#25506;&#32034;&#39640;&#36866;&#24212;&#24615;&#21306;&#22495;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#30456;&#27604;&#20808;&#21069;&#26368;&#20339;&#26041;&#27861;&#65292;IsEM-Pro&#30340;&#24179;&#22343;&#36866;&#24212;&#24615;&#24471;&#20998;&#33267;&#23569;&#39640;&#20986;55&#65285;&#65292;&#24182;&#29983;&#25104;&#20102;&#26356;&#22810;&#26679;&#21270;&#21644;&#26032;&#39062;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;&#12290;</title><link>http://arxiv.org/abs/2305.00386</link><description>&lt;p&gt;
&#34507;&#30333;&#36136;&#24207;&#21015;&#35774;&#35745;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26399;&#26395;&#26368;&#22823;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Importance Weighted Expectation-Maximization for Protein Sequence Design. (arXiv:2305.00386v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IsEM-Pro&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#32473;&#23450;&#36866;&#24212;&#24615;&#26631;&#20934;&#29983;&#25104;&#34507;&#30333;&#36136;&#24207;&#21015;&#12290;&#22312;&#25512;&#29702;&#26399;&#38388;&#65292;&#20174;&#20854;&#28508;&#22312;&#31354;&#38388;&#37319;&#26679;&#21487;&#20197;&#22686;&#21152;&#22810;&#26679;&#24615;&#65292;&#25351;&#23548;&#20102;&#25506;&#32034;&#39640;&#36866;&#24212;&#24615;&#21306;&#22495;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#30456;&#27604;&#20808;&#21069;&#26368;&#20339;&#26041;&#27861;&#65292;IsEM-Pro&#30340;&#24179;&#22343;&#36866;&#24212;&#24615;&#24471;&#20998;&#33267;&#23569;&#39640;&#20986;55&#65285;&#65292;&#24182;&#29983;&#25104;&#20102;&#26356;&#22810;&#26679;&#21270;&#21644;&#26032;&#39062;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#29289;&#21644;&#21270;&#23398;&#39046;&#22495;&#65292;&#35774;&#35745;&#20855;&#26377;&#25152;&#38656;&#29983;&#29289;&#21151;&#33021;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;&#38750;&#24120;&#37325;&#35201;&#12290;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20351;&#29992;&#20195;&#29702;&#24207;&#21015;-&#21151;&#33021;&#27169;&#22411;&#26367;&#20195;&#26114;&#36149;&#30340;&#28287;&#23454;&#39564;&#39564;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IsEM-Pro&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#32473;&#23450;&#30340;&#36866;&#24212;&#24615;&#26631;&#20934;&#29983;&#25104;&#34507;&#30333;&#36136;&#24207;&#21015;&#12290;&#23427;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#21463;&#21040;&#21478;&#22806;&#19968;&#20010;&#23398;&#20064;&#30340;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#32467;&#26500;&#29305;&#24449;&#30340;&#22686;&#24378;&#12290;&#30740;&#31350;&#32773;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#26399;&#26395;&#26368;&#22823;&#21270;&#26041;&#27861;&#65288;MCEM&#65289;&#26469;&#23398;&#20064;&#36825;&#20010;&#27169;&#22411;&#12290;&#22312;&#25512;&#29702;&#26399;&#38388;&#65292;&#20174;&#20854;&#28508;&#22312;&#31354;&#38388;&#37319;&#26679;&#21487;&#20197;&#22686;&#21152;&#22810;&#26679;&#24615;&#65292;&#32780;&#20854;MRF&#29305;&#24449;&#21017;&#25351;&#23548;&#20102;&#25506;&#32034;&#39640;&#36866;&#24212;&#24615;&#21306;&#22495;&#12290;&#22312;&#20843;&#39033;&#34507;&#30333;&#36136;&#24207;&#21015;&#35774;&#35745;&#20219;&#21153;&#20013;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;IsEM-Pro&#30340;&#24179;&#22343;&#36866;&#24212;&#24615;&#24471;&#20998;&#33267;&#23569;&#27604;&#20808;&#21069;&#26368;&#20339;&#26041;&#27861;&#39640;55&#65285;&#65292;&#24182;&#19988;&#29983;&#25104;&#20102;&#26356;&#22810;&#26679;&#21270;&#21644;&#26032;&#39062;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
Designing protein sequences with desired biological function is crucial in biology and chemistry. Recent machine learning methods use a surrogate sequence-function model to replace the expensive wet-lab validation. How can we efficiently generate diverse and novel protein sequences with high fitness? In this paper, we propose IsEM-Pro, an approach to generate protein sequences towards a given fitness criterion. At its core, IsEM-Pro is a latent generative model, augmented by combinatorial structure features from a separately learned Markov random fields (MRFs). We develop an Monte Carlo Expectation-Maximization method (MCEM) to learn the model. During inference, sampling from its latent space enhances diversity while its MRFs features guide the exploration in high fitness regions. Experiments on eight protein sequence design tasks show that our IsEM-Pro outperforms the previous best methods by at least 55% on average fitness score and generates more diverse and novel protein sequences.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; G&#19981;&#21464;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376; &#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#38598;&#19981;&#20165;&#22312;&#27969;&#24418;&#19978;&#65292;&#32780;&#19988;&#22312;&#19968;&#20010;&#36830;&#32493;&#32676;&#30340;&#20316;&#29992;&#19979;&#20063;&#26159;&#23553;&#38381;&#30340;&#24773;&#24418;&#65292;&#30456;&#36739;&#20110;&#26631;&#20934;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#12290;</title><link>http://arxiv.org/abs/2303.17001</link><description>&lt;p&gt;
G&#19981;&#21464;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
The G-invariant graph Laplacian. (arXiv:2303.17001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; G&#19981;&#21464;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376; &#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#38598;&#19981;&#20165;&#22312;&#27969;&#24418;&#19978;&#65292;&#32780;&#19988;&#22312;&#19968;&#20010;&#36830;&#32493;&#32676;&#30340;&#20316;&#29992;&#19979;&#20063;&#26159;&#23553;&#38381;&#30340;&#24773;&#24418;&#65292;&#30456;&#36739;&#20110;&#26631;&#20934;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#31639;&#27861;&#24050;&#32463;&#34987;&#35777;&#26126;&#22312;&#38477;&#32500;&#12289;&#32858;&#31867;&#21644;&#21435;&#22122;&#31561;&#39046;&#22495;&#23545;&#27969;&#24418;&#25968;&#25454;&#38750;&#24120;&#26377;&#25928;&#12290;&#26412;&#25991;&#32771;&#34385;&#30340;&#25968;&#25454;&#38598;&#19981;&#20165;&#22312;&#27969;&#24418;&#19978;&#65292;&#32780;&#19988;&#22312;&#19968;&#20010;&#36830;&#32493;&#32676;&#30340;&#20316;&#29992;&#19979;&#20063;&#26159;&#23553;&#38381;&#30340;&#12290;&#36825;&#31867;&#25968;&#25454;&#38598;&#30340;&#19968;&#20010;&#20363;&#23376;&#26159;&#27839;&#30528;&#20302;&#32500;&#27969;&#24418;&#20256;&#25773;&#30340;&#20307;&#31215;&#65292;&#20854;&#20013;&#27599;&#20010;&#20307;&#31215;&#21487;&#20197;&#22312;&#19977;&#32500;&#31354;&#38388;&#20013;&#26059;&#36716;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;G&#19981;&#21464;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#65292;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#38598;&#19978;&#30340;&#32676;&#30340;&#20316;&#29992;&#26469;&#24191;&#20041;&#21270;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#12290;&#25105;&#20204;&#26174;&#31034;&#20102;&#19982;&#26631;&#20934;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#31867;&#20284;&#65292;G&#19981;&#21464;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#25910;&#25947;&#20110;&#25968;&#25454;&#27969;&#24418;&#19978;&#30340;Laplace-Beltrami&#31639;&#23376;&#65292;&#20294;&#25910;&#25947;&#36895;&#24230;&#26174;&#33879;&#25552;&#39640;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;G&#19981;&#21464;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#29305;&#24449;&#20989;&#25968;&#20855;&#26377;&#32676;&#20803;&#32032;&#21644;&#26576;&#20123;&#30697;&#38453;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#24352;&#37327;&#31215;&#24418;&#24335;&#65292;&#21487;&#20197;&#20351;&#29992;F&#39640;&#25928;&#22320;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Laplacian based algorithms for data lying on a manifold have been proven effective for tasks such as dimensionality reduction, clustering, and denoising. In this work, we consider data sets whose data point not only lie on a manifold, but are also closed under the action of a continuous group. An example of such data set is volumes that line on a low dimensional manifold, where each volume may be rotated in three-dimensional space. We introduce the G-invariant graph Laplacian that generalizes the graph Laplacian by accounting for the action of the group on the data set. We show that like the standard graph Laplacian, the G-invariant graph Laplacian converges to the Laplace-Beltrami operator on the data manifold, but with a significantly improved convergence rate. Furthermore, we show that the eigenfunctions of the G-invariant graph Laplacian admit the form of tensor products between the group elements and eigenvectors of certain matrices, which can be computed efficiently using F
&lt;/p&gt;</description></item></channel></rss>