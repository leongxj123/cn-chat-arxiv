# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees.](http://arxiv.org/abs/2209.07225) | MIXRTs是一种可解释的多智能体强化学习架构，通过混合循环软决策树的方式，能够表达明确的决策过程并展示每个智能体的贡献。 |

# 详细

[^1]: MIXRTs:通过混合循环软决策树实现可解释的多智能体强化学习

    MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees. (arXiv:2209.07225v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.07225](http://arxiv.org/abs/2209.07225)

    MIXRTs是一种可解释的多智能体强化学习架构，通过混合循环软决策树的方式，能够表达明确的决策过程并展示每个智能体的贡献。

    

    在各个领域取得巨大成功的同时，现有的具有黑盒神经网络结构的多智能体强化学习（MARL）以不透明的方式做出决策，阻碍了人们理解学习到的知识以及输入观测如何影响决策。与此相反，现有的可解释方法，如传统的线性模型和决策树，往往在表达能力和准确性方面存在问题。为了解决性能和解释性之间的明显二元对立，我们提出了一种新颖的可解释结构——混合循环软决策树（MIXRTs），它能够通过从根节点到叶节点的路径表示明确的决策过程，并反映每个智能体对团队的贡献。具体而言，我们构建了一种新颖的软决策树来解决局部可观察性问题，利用循环神经网络的进展，并通过基于树的模型展示哪些特征影响决策过程。

    While achieving tremendous success in various fields, existing multi-agent reinforcement learning (MARL) with a black-box neural network architecture makes decisions in an opaque manner that hinders humans from understanding the learned knowledge and how input observations influence decisions. Instead, existing interpretable approaches, such as traditional linear models and decision trees, usually suffer from weak expressivity and low accuracy. To address this apparent dichotomy between performance and interpretability, our solution, MIXing Recurrent soft decision Trees (MIXRTs), is a novel interpretable architecture that can represent explicit decision processes via the root-to-leaf path and reflect each agent's contribution to the team. Specifically, we construct a novel soft decision tree to address partial observability by leveraging the advances in recurrent neural networks, and demonstrate which features influence the decision-making process through the tree-based model. Then, ba
    

