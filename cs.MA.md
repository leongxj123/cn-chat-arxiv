# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Networked Multiagent Reinforcement Learning for Peer-to-Peer Energy Trading.](http://arxiv.org/abs/2401.13947) | 本文提出了一个利用多智能体强化学习框架来实现点对点能源交易的方法，该方法帮助自动化消费者的竞标和管理，并解决了可再生能源零边际成本和物理约束的问题。 |

# 详细

[^1]: 网络化多智能体强化学习用于点对点能源交易

    Networked Multiagent Reinforcement Learning for Peer-to-Peer Energy Trading. (arXiv:2401.13947v1 [eess.SY])

    [http://arxiv.org/abs/2401.13947](http://arxiv.org/abs/2401.13947)

    本文提出了一个利用多智能体强化学习框架来实现点对点能源交易的方法，该方法帮助自动化消费者的竞标和管理，并解决了可再生能源零边际成本和物理约束的问题。

    

    利用分布式可再生能源和能量储存资源进行点对点能源交易被长期认为是提高能源系统弹性和可持续性的解决方案。然而，消费者和自给自足者（具有能源发电资源的人）缺乏进行重复点对点交易的专业知识，并且可再生能源的零边际成本在确定公平市场价格方面存在挑战。为了解决这些问题，我们提出了多智能体强化学习（MARL）框架，以帮助自动化消费者对太阳能光伏和能量储存资源的竞标和管理，在一种利用供需比的点对点清算机制下。此外，我们展示了MARL框架如何整合物理网络约束以实现电压控制，从而确保点对点能源交易的物理可行性，并为真实世界的实施铺平了道路。

    Utilizing distributed renewable and energy storage resources in local distribution networks via peer-to-peer (P2P) energy trading has long been touted as a solution to improve energy systems' resilience and sustainability. Consumers and prosumers (those who have energy generation resources), however, do not have the expertise to engage in repeated P2P trading, and the zero-marginal costs of renewables present challenges in determining fair market prices. To address these issues, we propose multi-agent reinforcement learning (MARL) frameworks to help automate consumers' bidding and management of their solar PV and energy storage resources, under a specific P2P clearing mechanism that utilizes the so-called supply-demand ratio. In addition, we show how the MARL frameworks can integrate physical network constraints to realize voltage control, hence ensuring physical feasibility of the P2P energy trading and paving way for real-world implementations.
    

