# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multi-Agent Quantum Reinforcement Learning using Evolutionary Optimization.](http://arxiv.org/abs/2311.05546) | 本研究提出了三种基于变分量子线路的进化优化多智能体强化学习变体，并在Coin Game环境中证明了这些方法相比于经典方法表现显著更好。 |
| [^2] | [Detecting stealthy cyberattacks on adaptive cruise control vehicles: A machine learning approach.](http://arxiv.org/abs/2310.17091) | 本研究针对自适应巡航控制车辆可能遭受的网络攻击问题，提出了一个交通模型框架和基于GAN的异常检测模型，能够实时识别恶意操纵、虚假注入和拒绝服务攻击。 |
| [^3] | [Robust Auction Design with Support Information.](http://arxiv.org/abs/2305.09065) | 本文提出了一个新颖的带支持信息的拍卖设计，通过优化DSIC机制并将最坏情况与oracle进行比较，讲述了三种支持信息的区域，得出了最优机制的闭合形式。 |
| [^4] | [Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution.](http://arxiv.org/abs/2208.04957) | 本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。 |

# 详细

[^1]: 多智能体量子强化学习使用进化优化

    Multi-Agent Quantum Reinforcement Learning using Evolutionary Optimization. (arXiv:2311.05546v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2311.05546](http://arxiv.org/abs/2311.05546)

    本研究提出了三种基于变分量子线路的进化优化多智能体强化学习变体，并在Coin Game环境中证明了这些方法相比于经典方法表现显著更好。

    

    多智能体强化学习在自动驾驶和其他智能产业应用方面变得越来越重要。与此同时，利用量子力学的固有属性，采用新的有希望的强化学习方法，显著减少模型的可训练参数。然而，基于梯度的多智能体量子强化学习方法常常面临贫瘠平台问题，阻碍了它们与经典方法性能的匹配。我们在现有的无梯度量子强化学习方法基础上构建，并提出了三种基于变分量子线路的进化优化多智能体强化学习变体。我们在Coin Game环境中评估了我们的遗传变种，并与经典方法进行了比较。我们证明了我们的变分量子线路方法相比于具有类似参数数量的神经网络表现显著更好。

    Multi-Agent Reinforcement Learning is becoming increasingly more important in times of autonomous driving and other smart industrial applications. Simultaneously a promising new approach to Reinforcement Learning arises using the inherent properties of quantum mechanics, reducing the trainable parameters of a model significantly. However, gradient-based Multi-Agent Quantum Reinforcement Learning methods often have to struggle with barren plateaus, holding them back from matching the performance of classical approaches. We build upon an existing approach for gradient free Quantum Reinforcement Learning and propose three genetic variations with Variational Quantum Circuits for Multi-Agent Reinforcement Learning using evolutionary optimization. We evaluate our genetic variations in the Coin Game environment and also compare them to classical approaches. We showed that our Variational Quantum Circuit approaches perform significantly better compared to a neural network with a similar amount
    
[^2]: 对自适应巡航控制车辆的隐蔽网络攻击的检测：一种机器学习方法

    Detecting stealthy cyberattacks on adaptive cruise control vehicles: A machine learning approach. (arXiv:2310.17091v1 [cs.MA])

    [http://arxiv.org/abs/2310.17091](http://arxiv.org/abs/2310.17091)

    本研究针对自适应巡航控制车辆可能遭受的网络攻击问题，提出了一个交通模型框架和基于GAN的异常检测模型，能够实时识别恶意操纵、虚假注入和拒绝服务攻击。

    

    随着配备了自适应巡航控制（ACC）和其他自动驾驶功能的先进驾驶辅助系统的出现，针对这些自动驾驶车辆（AVs）的网络攻击潜在风险也出现了。虽然强制车辆发生碰撞的明显攻击容易被识别，但更隐蔽的攻击，只略微改变行驶行为，可能会导致网络范围内拥堵、燃油消耗增加，甚至增加碰撞风险，但很难被检测到。为了解决这种攻击的检测问题，我们首先提出了一个交通模型框架，用于描述可能的三种网络攻击类型：恶意操纵车辆控制命令、对传感器测量数据进行虚假注入攻击和拒绝服务（DoS）攻击。然后，我们研究了这些攻击对个体车辆（微观）和交通流（宏观）水平的影响。我们提出了一种基于生成对抗网络（GAN）的异常检测模型，用于实时识别。

    With the advent of vehicles equipped with advanced driver-assistance systems, such as adaptive cruise control (ACC) and other automated driving features, the potential for cyberattacks on these automated vehicles (AVs) has emerged. While overt attacks that force vehicles to collide may be easily identified, more insidious attacks, which only slightly alter driving behavior, can result in network-wide increases in congestion, fuel consumption, and even crash risk without being easily detected. To address the detection of such attacks, we first present a traffic model framework for three types of potential cyberattacks: malicious manipulation of vehicle control commands, false data injection attacks on sensor measurements, and denial-of-service (DoS) attacks. We then investigate the impacts of these attacks at both the individual vehicle (micro) and traffic flow (macro) levels. A novel generative adversarial network (GAN)-based anomaly detection model is proposed for real-time identifica
    
[^3]: 带支持信息的鲁棒拍卖设计

    Robust Auction Design with Support Information. (arXiv:2305.09065v1 [econ.TH])

    [http://arxiv.org/abs/2305.09065](http://arxiv.org/abs/2305.09065)

    本文提出了一个新颖的带支持信息的拍卖设计，通过优化DSIC机制并将最坏情况与oracle进行比较，讲述了三种支持信息的区域，得出了最优机制的闭合形式。

    

    一个卖家想要将商品卖给$n$个买家，买家的估值是独立同分布的，但是卖家并不知道这个分布。为了抵御环境和买家行为的不确定性，卖家在DSIC机制中进行优化，并将最坏情况的表现与具有完全买家估值知识的oracle进行比较。我们的分析包括遗憾和比率两个目标。对于这些目标，我们以支持和买家数$n$的函数形式导出了一个闭合的最优机制。我们的分析揭示了三个支持信息的区域和一个新的鲁棒机制类。

    A seller wants to sell an item to $n$ buyers. The buyer valuations are drawn i.i.d. from a distribution, but the seller does not know this distribution; the seller only knows the support $[a,b]$. To be robust against the lack of knowledge of the environment and buyers' behavior, the seller optimizes over DSIC mechanisms, and measures the worst-case performance relative to an oracle with complete knowledge of buyers' valuations. Our analysis encompasses both the regret and the ratio objectives.  For these objectives, we derive an optimal mechanism in closed form as a function of the support and the number of buyers $n$. Our analysis reveals three regimes of support information and a new class of robust mechanisms. i.) With "low" support information, the optimal mechanism is a second-price auction (SPA) with a random reserve, a focal class in the earlier literature. ii.) With "high" support information, we show that second-price auctions are strictly suboptimal, and an optimal mechanism 
    
[^4]: 异构多智能体零样本协同进化研究

    Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution. (arXiv:2208.04957v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2208.04957](http://arxiv.org/abs/2208.04957)

    本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。

    

    在合作多智能体强化学习领域，生成能够与未知合作伙伴零样本协同的智能体是一个新的挑战。最近的一些研究在零样本协同方面取得了进展，通过训练过程中向智能体暴露多样化的合作伙伴。然而，这些方法通常在训练伙伴时涉及自我对弈，隐式地假设任务是同质的。然而，许多真实世界的任务是异构的，因此先前的方法可能效率低下。本文首次研究了异构零样本协同的问题，并提出了一种基于协同进化的通用方法，通过三个子过程：配对、更新和选择，对两个智能体和合作伙伴进行协同进化。对不同异构任务的实验结果突出了考虑异构情况的必要性，并证明我们提出的方法是解决异构零样本协同任务的一种有前景的解决方案。

    Generating agents that can achieve zero-shot coordination (ZSC) with unseen partners is a new challenge in cooperative multi-agent reinforcement learning (MARL). Recently, some studies have made progress in ZSC by exposing the agents to diverse partners during the training process. They usually involve self-play when training the partners, implicitly assuming that the tasks are homogeneous. However, many real-world tasks are heterogeneous, and hence previous methods may be inefficient. In this paper, we study the heterogeneous ZSC problem for the first time and propose a general method based on coevolution, which coevolves two populations of agents and partners through three sub-processes: pairing, updating and selection. Experimental results on various heterogeneous tasks highlight the necessity of considering the heterogeneous setting and demonstrate that our proposed method is a promising solution for heterogeneous ZSC tasks.
    

