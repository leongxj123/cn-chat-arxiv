# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Unified Framework for Gradient-based Clustering of Distributed Data](https://rss.arxiv.org/abs/2402.01302) | 这是一篇关于梯度聚类分布式数据的统一框架的论文，作者提出了一族分布式聚类算法，可以在用户网络中工作。通过控制用户中心估计的接近程度和定义聚类损失函数，这些算法适用于不同的聚类任务。在提供了统一分析和几个强结果的基础上，这些算法都表现出了良好的收敛性和可行性。 |

# 详细

[^1]: 梯度聚类分布式数据的统一框架

    A Unified Framework for Gradient-based Clustering of Distributed Data

    [https://rss.arxiv.org/abs/2402.01302](https://rss.arxiv.org/abs/2402.01302)

    这是一篇关于梯度聚类分布式数据的统一框架的论文，作者提出了一族分布式聚类算法，可以在用户网络中工作。通过控制用户中心估计的接近程度和定义聚类损失函数，这些算法适用于不同的聚类任务。在提供了统一分析和几个强结果的基础上，这些算法都表现出了良好的收敛性和可行性。

    

    我们开发了一族分布式聚类算法，可以在用户网络中工作。在提出的场景中，用户包含一个本地数据集，并且只与其直接邻居进行通信，目标是寻找完整数据的聚类。所提出的家族称为分布式梯度聚类（DGC-$\mathcal{F}_\rho$），由参数化的$\rho\geq1$确定，控制用户中心估计的接近程度，而$\mathcal{F}$确定聚类损失。针对流行的聚类损失如$K$均值和Huber损失，DGC-$\mathcal{F}_\rho$产生了新的分布式聚类算法DGC-KM$_\rho$和DGC-HL$_\rho$，而基于逻辑函数的新型聚类损失导致了DGC-LL$_\rho$。我们提供了统一的分析并建立了几个强结果，在温和的假设下。首先，方法生成的中心序列在任何中心初始化和$...

    We develop a family of distributed clustering algorithms that work over networks of users. In the proposed scenario, users contain a local dataset and communicate only with their immediate neighbours, with the aim of finding a clustering of the full, joint data. The proposed family, termed Distributed Gradient Clustering (DGC-$\mathcal{F}_\rho$), is parametrized by $\rho \geq 1$, controling the proximity of users' center estimates, with $\mathcal{F}$ determining the clustering loss. Specialized to popular clustering losses like $K$-means and Huber loss, DGC-$\mathcal{F}_\rho$ gives rise to novel distributed clustering algorithms DGC-KM$_\rho$ and DGC-HL$_\rho$, while a novel clustering loss based on the logistic function leads to DGC-LL$_\rho$. We provide a unified analysis and establish several strong results, under mild assumptions. First, the sequence of centers generated by the methods converges to a well-defined notion of fixed point, under any center initialization and value of $
    

