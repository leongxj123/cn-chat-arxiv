# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Machine Learning Assisted Adjustment Boosts Inferential Efficiency of Randomized Controlled Trials](https://arxiv.org/abs/2403.03058) | 该研究提出了一种机器学习辅助调整的推断程序，可以提高随机对照试验的推断效率，并在样本量和成本方面有显著的优势。 |
| [^2] | [CoLoRA: Continuous low-rank adaptation for reduced implicit neural modeling of parameterized partial differential equations](https://arxiv.org/abs/2402.14646) | CoLoRA通过连续低秩自适应提供了一种快速预测参数化偏微分方程解演变的简化神经网络建模方法 |
| [^3] | [Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption](https://arxiv.org/abs/2402.08991) | 本研究通过引入对抗性健壮的乐观MLE（CR-OMLE）算法，解决了模型驱动强化学习中对抗性破坏的挑战，实现了对转移模型的健壮估计。 |
| [^4] | [Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past](https://arxiv.org/abs/2203.06056) | 本文考虑了在时间序列模型中进行 IV 回归的困难，提出了一种用于构建识别方程的方法，以实现对时间序列数据中因果效应的一致性参数估计。 |
| [^5] | [Dynamical System Identification, Model Selection and Model Uncertainty Quantification by Bayesian Inference.](http://arxiv.org/abs/2401.16943) | 本研究提出了一种基于贝叶斯推理的动力系统识别方法，可以估计模型系数，进行模型排序和模型不确定性量化，并展示了与其他算法的比较结果。 |
| [^6] | [Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling.](http://arxiv.org/abs/2401.12476) | 本文提出了一种用于学习非分离哈密顿系统的结构保持的贝叶斯方法，可以处理统计相关的加性和乘性噪声，并且通过将结构保持方法纳入框架中，提供了对高维系统的高效识别。 |
| [^7] | [Stochastic optimization with arbitrary recurrent data sampling.](http://arxiv.org/abs/2401.07694) | 这篇论文研究了一种随机优化算法，证明了对于非凸、可能不光滑的目标函数，在一般的经常性抽样方案下，可以以最佳速率收敛；同时指出了收敛速度与"经常性的速度"之间的关系。 |
| [^8] | [Simulation-Based Inference with Quantile Regression.](http://arxiv.org/abs/2401.02413) | 提出了一种基于模拟推断和分位数回归的新方法，通过学习个体化的分位数来估计后验样本，并使用局部累积密度函数定义贝叶斯可信区间，具有更快的评估速度。同时，还可以集成后处理扩展步骤以保证后验估计的无偏性，而计算成本几乎可以忽略不计。 |
| [^9] | [Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference.](http://arxiv.org/abs/2312.05910) | 这篇论文介绍了一种将集合卡尔曼滤波引入变分推理框架的方法，用于近似高斯过程状态空间模型的后验分布，并且有效地利用了潜在状态和动力学之间的依赖关系，减少了变分参数的数量。 |
| [^10] | [Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach.](http://arxiv.org/abs/2310.15411) | 这个论文研究了在结构化无标签数据分布下，对于具有Tsybakov噪声的$d$维半空间，计算和标签的高效PAC主动学习问题。通过设计一种基于非凸优化的算法，它能够在一定的噪声参数范围内达到较低的标签复杂度。 |
| [^11] | [Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression.](http://arxiv.org/abs/2309.07810) | 这项研究介绍了一种新的去偏方法框架，用于解决高维线性回归中现有技术对协变量分布的限制问题。研究者们发现，现有方法在处理非高斯分布、异质性设计矩阵和缺乏可靠特征协方差估计时遇到困难。为了解决这些问题，他们提出了一种新的策略，该策略利用缩放的梯度下降步骤进行去偏校正。 |
| [^12] | [Meta-Learning Operators to Optimality from Multi-Task Non-IID Data.](http://arxiv.org/abs/2308.04428) | 本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。 |
| [^13] | [VITS : Variational Inference Thomson Sampling for contextual bandits.](http://arxiv.org/abs/2307.10167) | VITS是一种基于高斯变分推理的新算法，用于情境背离问题的汤普森抽样。它提供了强大的后验近似，计算效率高，并且在线性情境背离问题中达到与传统TS相同阶数的次线性遗憾上界。 |
| [^14] | [High-Dimensional Bayesian Structure Learning in Gaussian Graphical Models using Marginal Pseudo-Likelihood.](http://arxiv.org/abs/2307.00127) | 该论文提出了两种创新的搜索算法，在高维图结构学习中使用边际伪似然函数解决计算复杂性问题，并且能够在短时间内生成可靠的估计。该方法提供了R软件包BDgraph的代码实现。 |
| [^15] | [Estimation of Ridge Using Nonlinear Transformation on Density Function.](http://arxiv.org/abs/2306.05722) | 本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。 |
| [^16] | [Distributed Gradient Descent for Functional Learning.](http://arxiv.org/abs/2305.07408) | 该论文提出了一种针对函数数据的分布式梯度下降函数学习算法，在再生核希尔伯特空间框架下通过积分算子方法得到了该算法的理论理解，并取得了不饱和边界的置信度最优学习率。 |

# 详细

[^1]: 机器学习辅助调整提升随机对照试验的推断效率

    Machine Learning Assisted Adjustment Boosts Inferential Efficiency of Randomized Controlled Trials

    [https://arxiv.org/abs/2403.03058](https://arxiv.org/abs/2403.03058)

    该研究提出了一种机器学习辅助调整的推断程序，可以提高随机对照试验的推断效率，并在样本量和成本方面有显著的优势。

    

    在这项工作中，我们提出了一种新的推断程序，该程序采用了基于机器学习的调整方法，用于随机对照试验。该方法是在罗森鲍姆的基于协变量调整的随机实验的确切检验框架下开发的。通过大量的模拟实验，我们展示了所提出的方法可以稳健地控制第一类错误，并可以提高随机对照试验(RCT)的推断效率。这一优势在一个真实案例中进一步得到了证明。所提出方法的简单性和稳健性使其成为一种竞争性候选作为RCT的常规推断程序，特别是当基线协变量的数量较多，且预计存在非线性关联或协变量之间的交互作用时。其应用可以显著降低RCT的所需样本量和成本，例如三期临床试验。

    arXiv:2403.03058v1 Announce Type: cross  Abstract: In this work, we proposed a novel inferential procedure assisted by machine learning based adjustment for randomized control trials. The method was developed under the Rosenbaum's framework of exact tests in randomized experiments with covariate adjustments. Through extensive simulation experiments, we showed the proposed method can robustly control the type I error and can boost the inference efficiency for a randomized controlled trial (RCT). This advantage was further demonstrated in a real world example. The simplicity and robustness of the proposed method makes it a competitive candidate as a routine inference procedure for RCTs, especially when the number of baseline covariates is large, and when nonlinear association or interaction among covariates is expected. Its application may remarkably reduce the required sample size and cost of RCTs, such as phase III clinical trials.
    
[^2]: CoLoRA:用于参数化偏微分方程简化隐式神经建模的连续低秩自适应

    CoLoRA: Continuous low-rank adaptation for reduced implicit neural modeling of parameterized partial differential equations

    [https://arxiv.org/abs/2402.14646](https://arxiv.org/abs/2402.14646)

    CoLoRA通过连续低秩自适应提供了一种快速预测参数化偏微分方程解演变的简化神经网络建模方法

    

    该工作介绍了一种基于连续低秩自适应（CoLoRA）的简化模型，它预先训练神经网络适用于给定的偏微分方程，然后在时间上连续地调整低秩权重，以快速预测新物理参数和新初始条件下解场的演变。自适应可以是纯粹数据驱动的，也可以通过一个方程驱动的变分方法，提供Galerkin最优的逼近。由于CoLoRA在时间上局部逼近解场，权重的秩可以保持较小，这意味着只需要离线训练几条轨迹，因此CoLoRA非常适用于数据稀缺的情况。与传统方法相比，CoLoRA的预测速度快上几个数量级，其准确度和参数效率也比其他神经网络方法更高。

    arXiv:2402.14646v1 Announce Type: new  Abstract: This work introduces reduced models based on Continuous Low Rank Adaptation (CoLoRA) that pre-train neural networks for a given partial differential equation and then continuously adapt low-rank weights in time to rapidly predict the evolution of solution fields at new physics parameters and new initial conditions. The adaptation can be either purely data-driven or via an equation-driven variational approach that provides Galerkin-optimal approximations. Because CoLoRA approximates solution fields locally in time, the rank of the weights can be kept small, which means that only few training trajectories are required offline so that CoLoRA is well suited for data-scarce regimes. Predictions with CoLoRA are orders of magnitude faster than with classical methods and their accuracy and parameter efficiency is higher compared to other neural network approaches.
    
[^3]: 面向对抗性破坏的健壮模型驱动强化学习

    Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption

    [https://arxiv.org/abs/2402.08991](https://arxiv.org/abs/2402.08991)

    本研究通过引入对抗性健壮的乐观MLE（CR-OMLE）算法，解决了模型驱动强化学习中对抗性破坏的挑战，实现了对转移模型的健壮估计。

    

    本研究解决了模型驱动强化学习中对抗性破坏的挑战，其中转移动力学可以被对手破坏。现有研究主要集中在模型无关强化学习的情景下，通常采用健壮的最小二乘回归来进行值函数估计。然而，这些技术不能直接应用于模型驱动的强化学习。在本文中，我们专注于模型驱动的强化学习，并采用最大似然估计（MLE）方法来学习转移模型。我们的工作涵盖了在线和离线两种情况。在在线情况下，我们引入了一种名为对抗性健壮的乐观MLE（CR-OMLE）的算法，它利用基于总变差（TV）的信息比率作为MLE的不确定权重。我们证明了CR-OMLE的遗憾度为$ \tilde {\mathcal {O}}（\sqrt {T} + C）$，其中$ C $表示经过$ T $个回合后的累计破坏水平。

    arXiv:2402.08991v1 Announce Type: cross Abstract: This study tackles the challenges of adversarial corruption in model-based reinforcement learning (RL), where the transition dynamics can be corrupted by an adversary. Existing studies on corruption-robust RL mostly focus on the setting of model-free RL, where robust least-square regression is often employed for value function estimation. However, these techniques cannot be directly applied to model-based RL. In this paper, we focus on model-based RL and take the maximum likelihood estimation (MLE) approach to learn transition model. Our work encompasses both online and offline settings. In the online setting, we introduce an algorithm called corruption-robust optimistic MLE (CR-OMLE), which leverages total-variation (TV)-based information ratios as uncertainty weights for MLE. We prove that CR-OMLE achieves a regret of $\tilde{\mathcal{O}}(\sqrt{T} + C)$, where $C$ denotes the cumulative corruption level after $T$ episodes. We also pro
    
[^4]: 使用工具时间序列识别因果效应：无关 IV 和纠正历史

    Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past

    [https://arxiv.org/abs/2203.06056](https://arxiv.org/abs/2203.06056)

    本文考虑了在时间序列模型中进行 IV 回归的困难，提出了一种用于构建识别方程的方法，以实现对时间序列数据中因果效应的一致性参数估计。

    

    仪器变量（IV）回归依赖于工具来推断观测数据中的因果效应，其中存在未观测的混淆因素。我们考虑在时间序列模型中进行 IV 回归，例如矢量自回归（VAR）过程。直接应用独立同分布技术通常不一致，因为它们不能正确调整过去的依赖关系。本文概述了由于时间结构而引起的困难，并提出了用于构建可用于时间序列数据中因果效应一致参数估计的确认方程的方法。一种方法使用额外的无关协变量来获得可识别性（即使在独立同分布情况下也是有趣的想法）。我们进一步提出了一个图边缘化框架，允许我们以原则性的方式对时间序列应用无关 IV 和其他 IV 方法。我们的方法利用了全局马尔可夫性质的一个版本。

    arXiv:2203.06056v2 Announce Type: replace-cross  Abstract: Instrumental variable (IV) regression relies on instruments to infer causal effects from observational data with unobserved confounding. We consider IV regression in time series models, such as vector auto-regressive (VAR) processes. Direct applications of i.i.d. techniques are generally inconsistent as they do not correctly adjust for dependencies in the past. In this paper, we outline the difficulties that arise due to time structure and propose methodology for constructing identifying equations that can be used for consistent parametric estimation of causal effects in time series data. One method uses extra nuisance covariates to obtain identifiability (an idea that can be of interest even in the i.i.d. case). We further propose a graph marginalization framework that allows us to apply nuisance IV and other IV methods in a principled way to time series. Our methods make use of a version of the global Markov property, which w
    
[^5]: 动力系统识别、模型选择和贝叶斯推理中的模型不确定性量化

    Dynamical System Identification, Model Selection and Model Uncertainty Quantification by Bayesian Inference. (arXiv:2401.16943v1 [stat.ME])

    [http://arxiv.org/abs/2401.16943](http://arxiv.org/abs/2401.16943)

    本研究提出了一种基于贝叶斯推理的动力系统识别方法，可以估计模型系数，进行模型排序和模型不确定性量化，并展示了与其他算法的比较结果。

    

    本研究提出了一种基于贝叶斯最大后验概率 (MAP) 框架的动力系统识别方法，用于从时间序列数据中恢复系统模型。实验证明这等价于广义的零阶 Tikhonov 正则化，通过负对数似然和先验分布来合理选择残差和正则化项。除了估计模型系数外，贝叶斯解释还提供了完整的贝叶斯推理工具，包括模型排序、模型不确定性量化和未知超参数的估计。通过应用于带有噪声的几个动力系统，比较了两种贝叶斯算法，即联合最大后验概率 (JMAP) 和变分贝叶斯近似 (VBA)，与流行的阈值最小二乘回归算法SINDy。对于多元高斯似然和先验分布，

    This study presents a Bayesian maximum \textit{a~posteriori} (MAP) framework for dynamical system identification from time-series data. This is shown to be equivalent to a generalized zeroth-order Tikhonov regularization, providing a rational justification for the choice of the residual and regularization terms, respectively, from the negative logarithms of the likelihood and prior distributions. In addition to the estimation of model coefficients, the Bayesian interpretation gives access to the full apparatus for Bayesian inference, including the ranking of models, the quantification of model uncertainties and the estimation of unknown (nuisance) hyperparameters. Two Bayesian algorithms, joint maximum \textit{a~posteriori} (JMAP) and variational Bayesian approximation (VBA), are compared to the popular SINDy algorithm for thresholded least-squares regression, by application to several dynamical systems with added noise. For multivariate Gaussian likelihood and prior distributions, the
    
[^6]: 用深度学习和降阶建模进行贝叶斯非分离哈密顿系统的识别和多项式噪声 (arXiv:2401.12476v1 [stat.ML])

    Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling. (arXiv:2401.12476v1 [stat.ML])

    [http://arxiv.org/abs/2401.12476](http://arxiv.org/abs/2401.12476)

    本文提出了一种用于学习非分离哈密顿系统的结构保持的贝叶斯方法，可以处理统计相关的加性和乘性噪声，并且通过将结构保持方法纳入框架中，提供了对高维系统的高效识别。

    

    本文提出了一种结构保持的贝叶斯方法，用于学习使用随机动力模型的非分离哈密顿系统，该系统允许统计相关的，矢量值的加性和乘性测量噪声。该方法由三个主要方面组成。首先，我们推导了一个用于评估贝叶斯后验中的似然函数所需的统计相关的，矢量值的加性和乘性噪声模型的高斯滤波器。其次，我们开发了一种新算法，用于对高维系统进行高效的贝叶斯系统识别。第三，我们演示了如何将结构保持方法纳入所提议的框架中，使用非分离哈密顿系统作为一个举例的系统类别。我们将贝叶斯方法与一种最先进的机器学习方法在一个典型的非分离哈密顿模型和带有小型噪声训练数据集的混沌双摆模型上进行了比较，实验结果表明

    This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that us
    
[^7]: 具有任意经常性数据抽样的随机优化

    Stochastic optimization with arbitrary recurrent data sampling. (arXiv:2401.07694v1 [math.OC])

    [http://arxiv.org/abs/2401.07694](http://arxiv.org/abs/2401.07694)

    这篇论文研究了一种随机优化算法，证明了对于非凸、可能不光滑的目标函数，在一般的经常性抽样方案下，可以以最佳速率收敛；同时指出了收敛速度与"经常性的速度"之间的关系。

    

    为了获得随机优化的最佳一阶收敛保证，需要使用一个经常性数据抽样算法，该算法以足够的频率对每个数据点进行抽样。大多数常用的数据抽样算法（如i.i.d.，MCMC，随机重排）在温和的假设下确实是经常性的。在这项工作中，我们表明对于一类特殊的随机优化算法，我们无需除了数据抽样算法中的经常性之外的任何其他属性（如独立性，指数混合和重排）来保证最佳的一阶收敛速率。也就是说，使用Minimization by Incremental Surrogate Optimization (MISO)的正则化版本，我们证明了对于非凸的、可能不光滑的目标函数，期望的最优性差异在一般的经常性抽样方案下收敛于最佳速率$O(n^{-1/2})$。此外，暗示的常数明确取决于"经常性的速度"，由指数测量。

    For obtaining optimal first-order convergence guarantee for stochastic optimization, it is necessary to use a recurrent data sampling algorithm that samples every data point with sufficient frequency. Most commonly used data sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed recurrent under mild assumptions. In this work, we show that for a particular class of stochastic optimization algorithms, we do not need any other property (e.g., independence, exponential mixing, and reshuffling) than recurrence in data sampling algorithms to guarantee the optimal rate of first-order convergence. Namely, using regularized versions of Minimization by Incremental Surrogate Optimization (MISO), we show that for non-convex and possibly non-smooth objective functions, the expected optimality gap converges at an optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes. Furthermore, the implied constant depends explicitly on the `speed of recurrence', measured by the expe
    
[^8]: 基于分位数回归的模拟推断方法

    Simulation-Based Inference with Quantile Regression. (arXiv:2401.02413v1 [stat.ML])

    [http://arxiv.org/abs/2401.02413](http://arxiv.org/abs/2401.02413)

    提出了一种基于模拟推断和分位数回归的新方法，通过学习个体化的分位数来估计后验样本，并使用局部累积密度函数定义贝叶斯可信区间，具有更快的评估速度。同时，还可以集成后处理扩展步骤以保证后验估计的无偏性，而计算成本几乎可以忽略不计。

    

    我们提出了一种基于条件分位数回归的新型模拟推断（Simulation-Based Inference，SBI）方法——神经分位数估计（Neural Quantile Estimation，NQE）。NQE通过自回归方式学习每个后验维度的单一维度分位数，以数据和之前的后验维度为条件。后验样本通过使用单调三次埃尔米特样条插值预测分位数进行获取，并对尾部行为和多模态分布进行了特殊处理。我们引入了一种使用局部累积密度函数（CDF）的贝叶斯可信区间的替代定义，其评估速度比传统的最高后验密度区域（HPDR）快得多。在模拟预算有限和/或已知模型错误规范的情况下，可以将后处理扩展步骤集成到NQE中，以确保后验估计的无偏性，且附加的计算成本可以忽略不计。我们证明了所提出的NQE方法达到了最新的研究水平。

    We present Neural Quantile Estimation (NQE), a novel Simulation-Based Inference (SBI) method based on conditional quantile regression. NQE autoregressively learns individual one dimensional quantiles for each posterior dimension, conditioned on the data and previous posterior dimensions. Posterior samples are obtained by interpolating the predicted quantiles using monotonic cubic Hermite spline, with specific treatment for the tail behavior and multi-modal distributions. We introduce an alternative definition for the Bayesian credible region using the local Cumulative Density Function (CDF), offering substantially faster evaluation than the traditional Highest Posterior Density Region (HPDR). In case of limited simulation budget and/or known model misspecification, a post-processing broadening step can be integrated into NQE to ensure the unbiasedness of the posterior estimation with negligible additional computational cost. We demonstrate that the proposed NQE method achieves state-of
    
[^9]: 集合卡尔曼滤波与高斯过程状态空间模型在非均场和在线推理中的应用

    Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference. (arXiv:2312.05910v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.05910](http://arxiv.org/abs/2312.05910)

    这篇论文介绍了一种将集合卡尔曼滤波引入变分推理框架的方法，用于近似高斯过程状态空间模型的后验分布，并且有效地利用了潜在状态和动力学之间的依赖关系，减少了变分参数的数量。

    

    高斯过程状态空间模型（GPSSMs）是一种多功能和原则性的非线性动态系统模型。然而，现有的GPSSMs变分学习和推理方法通常需要优化大量变分参数，导致性能和效率不足。为了解决这个问题，我们提出将集合卡尔曼滤波（EnKF），一种成熟的基于模型的滤波技术，纳入变分推理框架中，以近似潜在状态的后验分布。这种利用EnKF的方法可以有效地利用潜在状态和GP动力学之间的依赖关系，同时消除了对变分分布进行参数化的需求，从而显著减少了变分参数的数量。此外，我们还展示了我们提出的算法可以通过简单地对多个项进行求和来直接评估变分推理中的近似证据下界（ELBO）。

    Gaussian process state-space models (GPSSMs) are a versatile and principled family of nonlinear dynamical system models. However, existing variational learning and inference methods for GPSSMs often necessitate optimizing a substantial number of variational parameters, leading to inadequate performance and efficiency. To overcome this issue, we propose incorporating the ensemble Kalman filter (EnKF), a well-established model-based filtering technique, into the variational inference framework to approximate the posterior distribution of latent states. This utilization of EnKF can effectively exploit the dependencies between latent states and GP dynamics, while eliminating the need for parameterizing the variational distribution, thereby significantly reducing the number of variational parameters. Moreover, we show that our proposed algorithm allows straightforward evaluation of an approximated evidence lower bound (ELBO) in variational inference via simply summating multiple terms with 
    
[^10]: 高效的带有Tsybakov噪声的半空间主动学习：一种非凸优化方法

    Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach. (arXiv:2310.15411v1 [cs.LG])

    [http://arxiv.org/abs/2310.15411](http://arxiv.org/abs/2310.15411)

    这个论文研究了在结构化无标签数据分布下，对于具有Tsybakov噪声的$d$维半空间，计算和标签的高效PAC主动学习问题。通过设计一种基于非凸优化的算法，它能够在一定的噪声参数范围内达到较低的标签复杂度。

    

    我们研究了在结构化无标签数据分布下，对于具有Tsybakov噪声的$d$维半空间，计算和标签的高效PAC主动学习问题。受到\cite{diakonikolas2020learning}的启发，我们证明了平滑非凸损失函数的任何近似一阶稳定点都会产生一个具有低过量误差保证的半空间。根据上述结构性结果，我们设计了一种基于非凸优化的算法，其标签复杂度为$\tilde{O}(d (\frac{1}{\epsilon})^{\frac{8-6\alpha}{3\alpha-1}})$，在Tsybakov噪声参数$\alpha \in (\frac13, 1]$的假设下，这缩小了先前已知的高效被动或主动算法的标签复杂度间隔。

    We study the problem of computationally and label efficient PAC active learning $d$-dimensional halfspaces with Tsybakov Noise~\citep{tsybakov2004optimal} under structured unlabeled data distributions. Inspired by~\cite{diakonikolas2020learning}, we prove that any approximate first-order stationary point of a smooth nonconvex loss function yields a halfspace with a low excess error guarantee. In light of the above structural result, we design a nonconvex optimization-based algorithm with a label complexity of $\tilde{O}(d (\frac{1}{\epsilon})^{\frac{8-6\alpha}{3\alpha-1}})$\footnote{In the main body of this work, we use $\tilde{O}(\cdot), \tilde{\Theta}(\cdot)$ to hide factors of the form $\polylog(d, \frac{1}{\epsilon}, \frac{1}{\delta})$}, under the assumption that the Tsybakov noise parameter $\alpha \in (\frac13, 1]$, which narrows down the gap between the label complexities of the previously known efficient passive or active algorithms~\citep{diakonikolas2020polynomial,zhang2021im
    
[^11]: Spectrum-Aware Adjustment: 一种新的去偏方法框架及其在主成分回归中的应用

    Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])

    [http://arxiv.org/abs/2309.07810](http://arxiv.org/abs/2309.07810)

    这项研究介绍了一种新的去偏方法框架，用于解决高维线性回归中现有技术对协变量分布的限制问题。研究者们发现，现有方法在处理非高斯分布、异质性设计矩阵和缺乏可靠特征协方差估计时遇到困难。为了解决这些问题，他们提出了一种新的策略，该策略利用缩放的梯度下降步骤进行去偏校正。

    

    我们引入了一个新的去偏方法框架，用于解决高维线性回归中现代去偏技术对协变量分布的约束问题。我们研究了特征数和样本数都很大且相近的普遍情况。在这种情况下，现代去偏技术使用自由度校正来除去正则化估计量的收缩偏差并进行推断。然而，该方法要求观测样本是独立同分布的，协变量遵循均值为零的高斯分布，并且能够获得可靠的特征协方差矩阵估计。当（i）协变量具有非高斯分布、重尾或非对称分布，（ii）设计矩阵的行呈异质性或存在依赖性，以及（iii）缺乏可靠的特征协方差估计时，这种方法就会遇到困难。为了应对这些问题，我们提出了一种新的策略，其中去偏校正是一步缩放的梯度下降步骤（适当缩放）。

    We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
    
[^12]: 从多任务非独立同分布数据中元学习操作符到最优性

    Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])

    [http://arxiv.org/abs/2308.04428](http://arxiv.org/abs/2308.04428)

    本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。

    

    机器学习中最近取得进展的一个强大概念是从异构来源或任务的数据中提取共同特征。直观地说，将所有数据用于学习共同的表示函数，既有助于计算效率，又有助于统计泛化，因为它可以减少要在给定任务上进行微调的参数数量。为了在理论上做出这些优点的根源，我们提出了从噪声向量测量$y = Mx + w$中回复线性操作符$M$的一般模型。其中，协变量$x$既可以是非独立同分布的，也可以是非各向同性的。我们证明了现有的各向同性无关的元学习方法会对表示更新造成偏差，这导致噪声项的缩放不再有利于源任务数量。这反过来会导致表示学习的样本复杂性受到单任务数据规模的限制。我们引入了一种方法，称为去偏差和特征白化。

    A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias & Feature-Whiten}
    
[^13]: VITS: 基于变分推理的汤普森抽样用于情境背离问题的算法

    VITS : Variational Inference Thomson Sampling for contextual bandits. (arXiv:2307.10167v1 [stat.ML])

    [http://arxiv.org/abs/2307.10167](http://arxiv.org/abs/2307.10167)

    VITS是一种基于高斯变分推理的新算法，用于情境背离问题的汤普森抽样。它提供了强大的后验近似，计算效率高，并且在线性情境背离问题中达到与传统TS相同阶数的次线性遗憾上界。

    

    本文介绍并分析了一种用于情境背离问题的汤普森抽样（TS）算法的变体。传统的TS算法在每轮需要从当前的后验分布中抽样，而这通常是难以计算的。为了解决这个问题，可以使用近似推理技术并提供接近后验分布的样本。然而，当前的近似技术要么估计不准确（拉普拉斯近似），要么计算开销较大（MCMC方法，集成抽样...）。在本文中，我们提出了一种新的算法，基于高斯变分推理的变分推理汤普森抽样（VITS）。这种方法提供了强大的后验近似，并且容易从中抽样，而且计算效率高，是TS的理想选择。此外，我们还证明了在线性情境背离问题中，VITS实现了与传统TS相同阶数的次线性遗憾上界，与维度和回合数成正比。

    In this paper, we introduce and analyze a variant of the Thompson sampling (TS) algorithm for contextual bandits. At each round, traditional TS requires samples from the current posterior distribution, which is usually intractable. To circumvent this issue, approximate inference techniques can be used and provide samples with distribution close to the posteriors. However, current approximate techniques yield to either poor estimation (Laplace approximation) or can be computationally expensive (MCMC methods, Ensemble sampling...). In this paper, we propose a new algorithm, Varational Inference Thompson sampling VITS, based on Gaussian Variational Inference. This scheme provides powerful posterior approximations which are easy to sample from, and is computationally efficient, making it an ideal choice for TS. In addition, we show that VITS achieves a sub-linear regret bound of the same order in the dimension and number of round as traditional TS for linear contextual bandit. Finally, we 
    
[^14]: 高维贝叶斯高斯图模型中的结构学习方法——利用边际伪似然函数

    High-Dimensional Bayesian Structure Learning in Gaussian Graphical Models using Marginal Pseudo-Likelihood. (arXiv:2307.00127v1 [stat.ME])

    [http://arxiv.org/abs/2307.00127](http://arxiv.org/abs/2307.00127)

    该论文提出了两种创新的搜索算法，在高维图结构学习中使用边际伪似然函数解决计算复杂性问题，并且能够在短时间内生成可靠的估计。该方法提供了R软件包BDgraph的代码实现。

    

    高斯图模型以图形形式描绘了多元正态分布中变量之间的条件依赖关系。这篇论文介绍了两种创新的搜索算法，利用边际伪似然函数来应对高维图结构学习中的计算复杂性问题。这些方法可以在标准计算机上在几分钟内快速生成对包含1000个变量的问题的可靠估计。对于对实际应用感兴趣的人，支持这种新方法的代码通过R软件包BDgraph提供。

    Gaussian graphical models depict the conditional dependencies between variables within a multivariate normal distribution in a graphical format. The identification of these graph structures is an area known as structure learning. However, when utilizing Bayesian methodologies in structure learning, computational complexities can arise, especially with high-dimensional graphs surpassing 250 nodes. This paper introduces two innovative search algorithms that employ marginal pseudo-likelihood to address this computational challenge. These methods can swiftly generate reliable estimations for problems encompassing 1000 variables in just a few minutes on standard computers. For those interested in practical applications, the code supporting this new approach is made available through the R package BDgraph.
    
[^15]: 利用密度函数的非线性变换估计岭

    Estimation of Ridge Using Nonlinear Transformation on Density Function. (arXiv:2306.05722v1 [cs.LG])

    [http://arxiv.org/abs/2306.05722](http://arxiv.org/abs/2306.05722)

    本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。

    

    岭在准确近似流形的基础结构方面发挥着重要作用。本文通过将凹非线性变换应用于密度函数以探索岭的变化。通过对Hessian矩阵的推导和分析，我们发现非线性变换产生了Hessian矩阵的秩一修改。利用特征值问题的变分性质，我们建立了相应岭之间的偏序包含关系。我们直观地发现，通过Hessian矩阵的秩一修改，变换可以导致对切空间的估计改进。为验证我们的理论，我们在合成和真实世界数据集上进行了大量数值实验，证明了与其他流形拟合算法相比，我们的变换方法得到的岭在近似底层真实流形方面更加优越。

    Ridges play a vital role in accurately approximating the underlying structure of manifolds. In this paper, we explore the ridge's variation by applying a concave nonlinear transformation to the density function. Through the derivation of the Hessian matrix, we observe that nonlinear transformations yield a rank-one modification of the Hessian matrix. Leveraging the variational properties of eigenvalue problems, we establish a partial order inclusion relationship among the corresponding ridges. We intuitively discover that the transformation can lead to improved estimation of the tangent space via rank-one modification of the Hessian matrix. To validate our theories, we conduct extensive numerical experiments on synthetic and real-world datasets that demonstrate the superiority of the ridges obtained from our transformed approach in approximating the underlying truth manifold compared to other manifold fitting algorithms.
    
[^16]: 面向函数学习的分布式梯度下降算法

    Distributed Gradient Descent for Functional Learning. (arXiv:2305.07408v1 [stat.ML])

    [http://arxiv.org/abs/2305.07408](http://arxiv.org/abs/2305.07408)

    该论文提出了一种针对函数数据的分布式梯度下降函数学习算法，在再生核希尔伯特空间框架下通过积分算子方法得到了该算法的理论理解，并取得了不饱和边界的置信度最优学习率。

    

    近年来，不同类型的分布式学习方案因其在处理大规模数据信息方面的巨大优势而受到越来越多的关注。针对最近从函数数据分析中产生的大数据挑战，我们在再生核希尔伯特空间框架下提出了一种新颖的分布式梯度下降函数学习（DGDFL）算法，用于处理来自众多本地机器（处理器）的函数数据。基于积分算子方法，我们提供了DGDFL算法在文献中的许多方面的第一个理论理解。在理解DGDFL的过程中，首先，我们提出并全面研究了基于数据的渐进式下降函数学习（GDFL）算法与单机模型相关联。在温和的条件下，得到了DGDFL的置信度最优学习率，避免了先前在正则性索引上遭受的饱和边界。

    In recent years, different types of distributed learning schemes have received increasing attention for their strong advantages in handling large-scale data information. In the information era, to face the big data challenges which stem from functional data analysis very recently, we propose a novel distributed gradient descent functional learning (DGDFL) algorithm to tackle functional data across numerous local machines (processors) in the framework of reproducing kernel Hilbert space. Based on integral operator approaches, we provide the first theoretical understanding of the DGDFL algorithm in many different aspects in the literature. On the way of understanding DGDFL, firstly, a data-based gradient descent functional learning (GDFL) algorithm associated with a single-machine model is proposed and comprehensively studied. Under mild conditions, confidence-based optimal learning rates of DGDFL are obtained without the saturation boundary on the regularity index suffered in previous w
    

