# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multifidelity linear regression for scientific machine learning from scarce data](https://arxiv.org/abs/2403.08627) | 提出了一种新的多信度训练方法，用于处理科学机器学习中稀缺而昂贵的高保真数据，以提高模型的稳健性和泛化能力。 |
| [^2] | [Explaining Deep Learning for ECG Analysis: Building Blocks for Auditing and Knowledge Discovery.](http://arxiv.org/abs/2305.17043) | 本文介绍了可解释人工智能(XAI)方法在心电图(ECG)分析中的应用，提出了一套检查措施以确定合理的归因方法，并通过对患者亚组的数据分析，展示了这些XAI技术如何被用于知识发现，如识别心肌梗死亚型。 |
| [^3] | [On the Generalization Capacities of Neural Controlled Differential Equations.](http://arxiv.org/abs/2305.16791) | 本文研究了使用神经控制微分方程进行监督学习的泛化能力问题，通过量化离散化偏差和利普希茨函数逼近误差，得到了经验风险最小化器与贝叶斯最优风险的泛化差距上界。 |
| [^4] | [Homomorphism Autoencoder -- Learning Group Structured Representations from Observed Transitions.](http://arxiv.org/abs/2207.12067) | 本文提出了一种同态自编码器方法，使机器能够在行动中学习到与其行为相一致的感知信息的内部表示，并捕获环境中的转换结构。 |
| [^5] | [Logarithmic regret bounds for continuous-time average-reward Markov decision processes.](http://arxiv.org/abs/2205.11168) | 这项研究考虑了连续时间马尔可夫决策过程（MDPs）的平均奖励设置下的强化学习问题，并找到了实例相关的对数遗憾下界，并设计出了一个能够实现对数增长速率的学习算法。 |

# 详细

[^1]: 多信度线性回归用于科学机器学习中稀缺数据的研究

    Multifidelity linear regression for scientific machine learning from scarce data

    [https://arxiv.org/abs/2403.08627](https://arxiv.org/abs/2403.08627)

    提出了一种新的多信度训练方法，用于处理科学机器学习中稀缺而昂贵的高保真数据，以提高模型的稳健性和泛化能力。

    

    机器学习（ML）方法，通过拟合给定参数化模型类的参数来适应数据，作为学习复杂工程系统的代理模型的潜在方法已经引起了极大关注。然而，在许多科学和工程环境中，生成用于训练ML模型的高保真数据是昂贵的，并且用于生成训练数据的预算有限。我们提出了一种新的科学机器学习多信度训练方法，该方法利用了数据的各种保真度和成本可用的科学背景；例如，高保真数据可能由昂贵的全面解析的物理模拟生成，而低保真数据可能来自基于简化的更便宜的模型。

    arXiv:2403.08627v1 Announce Type: cross  Abstract: Machine learning (ML) methods, which fit to data the parameters of a given parameterized model class, have garnered significant interest as potential methods for learning surrogate models for complex engineering systems for which traditional simulation is expensive. However, in many scientific and engineering settings, generating high-fidelity data on which to train ML models is expensive, and the available budget for generating training data is limited. ML models trained on the resulting scarce high-fidelity data have high variance and are sensitive to vagaries of the training data set. We propose a new multifidelity training approach for scientific machine learning that exploits the scientific context where data of varying fidelities and costs are available; for example high-fidelity data may be generated by an expensive fully resolved physics simulation whereas lower-fidelity data may arise from a cheaper model based on simplifying 
    
[^2]: 解析心电图分析的深度学习：审计和知识发现的基石

    Explaining Deep Learning for ECG Analysis: Building Blocks for Auditing and Knowledge Discovery. (arXiv:2305.17043v1 [eess.SP])

    [http://arxiv.org/abs/2305.17043](http://arxiv.org/abs/2305.17043)

    本文介绍了可解释人工智能(XAI)方法在心电图(ECG)分析中的应用，提出了一套检查措施以确定合理的归因方法，并通过对患者亚组的数据分析，展示了这些XAI技术如何被用于知识发现，如识别心肌梗死亚型。

    

    由于深度神经网络能够准确识别心脏疾病和隐藏的临床因素，因此它们已经越来越受欢迎地用于分析心电图数据。然而，这些模型的黑匣子特性缺乏透明度，是一个常见的问题。为了解决这个问题，可以使用可解释的人工智能（XAI）方法。在本研究中，我们展示了一种后事解释(XAI)方法的全面分析，研究了局部(每个样本的贡献值)和全局(基于领域专家概念)的视角。我们建立了一套检查措施，以确定合理的归因方法，并提供符合专家规则的定量证据。这种数据集范围的分析超出了个案经验证据，通过汇总患者亚组的数据来实现。此外，我们展示了这些XAI技术如何被用于知识发现，如识别心肌梗死的亚型。我们相信，这些提出的方法可以作为审计和知识发现的基础。

    Deep neural networks have become increasingly popular for analyzing ECG data because of their ability to accurately identify cardiac conditions and hidden clinical factors. However, the lack of transparency due to the black box nature of these models is a common concern. To address this issue, explainable AI (XAI) methods can be employed. In this study, we present a comprehensive analysis of post-hoc XAI methods, investigating the local (attributions per sample) and global (based on domain expert concepts) perspectives. We have established a set of sanity checks to identify sensible attribution methods, and we provide quantitative evidence in accordance with expert rules. This dataset-wide analysis goes beyond anecdotal evidence by aggregating data across patient subgroups. Furthermore, we demonstrate how these XAI techniques can be utilized for knowledge discovery, such as identifying subtypes of myocardial infarction. We believe that these proposed methods can serve as building block
    
[^3]: 神经控制微分方程的泛化能力研究

    On the Generalization Capacities of Neural Controlled Differential Equations. (arXiv:2305.16791v1 [stat.ML])

    [http://arxiv.org/abs/2305.16791](http://arxiv.org/abs/2305.16791)

    本文研究了使用神经控制微分方程进行监督学习的泛化能力问题，通过量化离散化偏差和利普希茨函数逼近误差，得到了经验风险最小化器与贝叶斯最优风险的泛化差距上界。

    

    本文研究了使用神经控制微分方程（Kidger，Morrill等，2020）从不规则采样的时间序列样本中预测结果的监督学习设置。在我们的框架中，时间序列是一个未观察到的连续路径的离散化，结果通过一个具有未知向量场的控制微分方程依赖于这个路径。使用离散数据进行学习会引入离散偏差，我们精确地量化了这种偏差。通过使用关于控制微分方程流的连续性的理论结果，我们展示了逼近偏差直接与由浅层神经网络定义生成模型的利普希茨函数的逼近误差相关。通过结合最近的工作将神经网络的利普希茨常数与其泛化能力联系起来，我们上界了经验风险最小化器达到的期望损失与贝叶斯最优风险之间的泛化差距。

    We consider a supervised learning setup in which the goal is to predicts an outcome from a sample of irregularly sampled time series using Neural Controlled Differential Equations (Kidger, Morrill, et al. 2020). In our framework, the time series is a discretization of an unobserved continuous path, and the outcome depends on this path through a controlled differential equation with unknown vector field. Learning with discrete data thus induces a discretization bias, which we precisely quantify. Using theoretical results on the continuity of the flow of controlled differential equations, we show that the approximation bias is directly related to the approximation error of a Lipschitz function defining the generative model by a shallow neural network. By combining these result with recent work linking the Lipschitz constant of neural networks to their generalization capacities, we upper bound the generalization gap between the expected loss attained by the empirical risk minimizer and th
    
[^4]: 同态自编码器 - 从观察到转化学习群组结构表现

    Homomorphism Autoencoder -- Learning Group Structured Representations from Observed Transitions. (arXiv:2207.12067v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.12067](http://arxiv.org/abs/2207.12067)

    本文提出了一种同态自编码器方法，使机器能够在行动中学习到与其行为相一致的感知信息的内部表示，并捕获环境中的转换结构。

    

    如何让机器学习系统学习到准确表示其与真实世界交互的内在模型是一个尚待解决的问题。为了构建不仅包含观察性知识，也包含干预性知识的表现学习框架，我们使用了表示学习和群论的方法来研究该问题。我们提出一种方法，使机器能够在行动过程中学习到与之相一致的感知信息的内部表示，而这些行动实际上是变换这些信息的。我们使用一个自编码器并在其潜在空间上应用群组表示，通过利用等变损失强制实施适当的同态性质以完成训练。与现有方法不同的是，我们的方法不需要先验群组知识，并且不限制代理可执行的行动集合。理论上，我们证明了该方法的有效性，并通过实验证明了其能够学习到行动的群组表示，从而捕获了环境中的转换结构。

    How can agents learn internal models that veridically represent interactions with the real world is a largely open question. As machine learning is moving towards representations containing not just observational but also interventional knowledge, we study this problem using tools from representation learning and group theory. We propose methods enabling an agent acting upon the world to learn internal representations of sensory information that are consistent with actions that modify it. We use an autoencoder equipped with a group representation acting on its latent space, trained using an equivariance-derived loss in order to enforce a suitable homomorphism property on the group representation. In contrast to existing work, our approach does not require prior knowledge of the group and does not restrict the set of actions the agent can perform. We motivate our method theoretically, and show empirically that it can learn a group representation of the actions, thereby capturing the str
    
[^5]: 连续时间平均奖励马尔可夫决策过程的对数遗憾界限

    Logarithmic regret bounds for continuous-time average-reward Markov decision processes. (arXiv:2205.11168v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11168](http://arxiv.org/abs/2205.11168)

    这项研究考虑了连续时间马尔可夫决策过程（MDPs）的平均奖励设置下的强化学习问题，并找到了实例相关的对数遗憾下界，并设计出了一个能够实现对数增长速率的学习算法。

    

    我们考虑了在无限时间跨度、平均奖励设定下的连续时间马尔可夫决策过程（MDPs）的强化学习。与离散时间MDPs不同，连续时间过程在采取行动后会移动到一个状态并在此停留一个随机持续时间。在未知的转移概率和指数持续时间变化率下，我们得到了一个与时间跨度对数相关的实例相关遗憾下界。此外，我们设计了一个学习算法，并建立了一个有限时间的遗憾界限，能够实现对数增长速率。我们的分析建立在上限置信增强学习、均值持续时间的精细估计以及点过程的随机比较之上。

    We consider reinforcement learning for continuous-time Markov decision processes (MDPs) in the infinite-horizon, average-reward setting. In contrast to discrete-time MDPs, a continuous-time process moves to a state and stays there for a random holding time after an action is taken. With unknown transition probabilities and rates of exponential holding times, we derive instance-dependent regret lower bounds that are logarithmic in the time horizon. Moreover, we design a learning algorithm and establish a finite-time regret bound that achieves the logarithmic growth rate. Our analysis builds upon upper confidence reinforcement learning, a delicate estimation of the mean holding times, and stochastic comparison of point processes.
    

