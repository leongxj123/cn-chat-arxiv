# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning](https://arxiv.org/abs/2404.02545) | 提出了一种用于连续领域的新的计数方法，称为格点映射伪计数方法（GPC），以适应离线环境中的强化学习问题，并在惩罚Q值的同时减少计算成本。 |
| [^2] | [Long-form factuality in large language models](https://arxiv.org/abs/2403.18802) | 该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。 |
| [^3] | [Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning](https://arxiv.org/abs/2403.13749) | 引入了新的图同构测试层次结构$r$-$\ell{}$WL以及相应的GNN框架$r$-$\ell{}$MPNN，能够计数长度最多为$r + 2$的循环，具有强大的表达能力和计数能力，在真实数据集上表现出最先进的预测性能。 |
| [^4] | [Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains](https://arxiv.org/abs/2403.06672) | 本文研究了在隐私敏感领域中如何设计一种FL协议，既能保证隐私，又能提高模型准确性，并提供了设计出对所有参与者都有益处的协议。 |
| [^5] | [Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes](https://arxiv.org/abs/2403.00867) | 本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。 |
| [^6] | [Stochastic contextual bandits with graph feedback: from independence number to MAS number](https://arxiv.org/abs/2402.18591) | 本文研究了具有图反馈的上下文赌博问题，提出了一个刻画学习极限的图论量 $\beta_M(G)$，并建立了对应的遗憾下限。 |
| [^7] | [Depth Separations in Neural Networks: Separating the Dimension from the Accuracy](https://arxiv.org/abs/2402.07248) | 通过研究深度2和深度3神经网络在逼近Lipschitz目标函数时的分离性质，证明了维度诅咒也会在深度2逼近中存在，即使目标函数可以使用深度3高效表示。这为以前确定深度要求的下界提供了新的观点，并且适用于多种激活函数。 |
| [^8] | [The Implicit Bias of Gradient Noise: A Symmetry Perspective](https://arxiv.org/abs/2402.07193) | 本研究通过对对称性的存在进行分析，揭示了梯度噪声在随机梯度下降中的隐性偏见。我们发现不同类型的对称性会导致不同的学习动态，其中一类对称性可以自然收敛，而另一类对称性几乎总是发散。此外，我们的研究结果适用于没有对称性的损失函数，对于理解训练动态和解释相关实际问题具有普适性。 |
| [^9] | [Differentially Private Range Queries with Correlated Input Perturbation](https://arxiv.org/abs/2402.07066) | 本研究提出了一种具有相关输入扰动的差分隐私范围查询的局部机制，通过级联采样算法实现，实验表明在保障近乎最优的效用的同时，与输出扰动方法在实践中具有竞争力。 |
| [^10] | [CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract Patients](https://arxiv.org/abs/2402.04620) | CataractBot是一种基于LLM的白内障患者专家辅助聊天机器人，通过查询知识库提供即时的答案和专家验证的回复。在实地部署研究中证明了其价值所在。 |
| [^11] | [Hyper-Diffusion: Estimating Epistemic and Aleatoric Uncertainty with a Single Model](https://arxiv.org/abs/2402.03478) | 本研究引入了一种新的集合方法，超扩散，可以使用单一模型准确估计认识和偶然不确定性。 |
| [^12] | [GD doesn't make the cut: Three ways that non-differentiability affects neural network training](https://arxiv.org/abs/2401.08426) | 本文研究了非可微性对神经网络训练的影响，包括收敛性差异、$L_1$正则化问题的矛盾性质以及稳定边界现象的不适用性。 |
| [^13] | [Ventricular Segmentation: A Brief Comparison of U-Net Derivatives.](http://arxiv.org/abs/2401.09980) | 本文探讨了深度学习技术在心脏图像分割中的应用，实施了多个U-Net衍生模型以实现对心脏特定部位的全面解剖和功能分析。通过图像、图表和定量指标验证了模型的效果，并讨论了面临的挑战和未来改进策略。 |
| [^14] | [MeTA: Multi-source Test Time Adaptation.](http://arxiv.org/abs/2401.02561) | MeTA是第一个完全无监督的多源测试时适应框架，它可以在没有访问源数据的情况下，以最佳组合权重适应多个源模型到测试数据分布。 |
| [^15] | [Multi-Lattice Sampling of Quantum Field Theories via Neural Operator-based Flows.](http://arxiv.org/abs/2401.00828) | 本文提出了一种基于神经算子流的方法，通过近似时间相关算子，实现了在量子场论中从底层自由理论到目标理论的离散-连续归一化流。 |
| [^16] | [Latent Diffusion Model for Conditional Reservoir Facies Generation.](http://arxiv.org/abs/2311.01968) | 本研究提出了一种专门用于条件下储层相生成的潜在扩散模型，通过充分保留条件数据，生成了高保真度的储层相。它在性能上明显优于基于GANs的替代方法。 |
| [^17] | [Robust multimodal models have outlier features and encode more concepts.](http://arxiv.org/abs/2310.13040) | 健壮的多模态模型展示了异常特征和更多概念的编码方式。 |
| [^18] | [Generative Entropic Neural Optimal Transport To Map Within and Across Spaces.](http://arxiv.org/abs/2310.09254) | 该论文介绍了生成熵神经最优传输在测度到测度映射中的应用，解决了处理非平方欧氏距离成本、确定性蒙格映射、映射跨不可比较空间和质量守恒约束等实际挑战。 |
| [^19] | [Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance.](http://arxiv.org/abs/2310.03722) | 本文提出了两种新的“e-process”和置信序列方法，分别通过替换Lai的混合方法，并分析了所得结果的宽度。 |
| [^20] | [NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory.](http://arxiv.org/abs/2308.12970) | 本文提出了一种新的布料模拟方法 NeuralClothSim，使用薄壳理论和神经变形场进行表面演化，克服了现有布料模拟方法的局限性和挑战，为物理合理的布料模拟提供了一种全新的视角。 |
| [^21] | [Performance Issue Identification in Cloud Systems with Relational-Temporal Anomaly Detection.](http://arxiv.org/abs/2307.10869) | 云系统中的性能问题识别存在挑战，现有方法中的独立分析每个指标的异常无法解决问题，需要考虑指标之间的关联性。 |
| [^22] | [Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks.](http://arxiv.org/abs/2306.09377) | 语言对齐的视觉表示方式比纯视觉表示方式更有效地预测人类在自然学习任务中的行为。 |
| [^23] | [Learning to Communicate and Collaborate in a Competitive Multi-Agent Setup to Clean the Ocean from Macroplastics.](http://arxiv.org/abs/2304.05872) | 本文提出了一种基于图神经网络（GNN）的、用于多智能体交互式海洋废弃物清理的通信机制，使得不同代理之间可以协作竞争并实现收集废弃物的最大化。 |
| [^24] | [Evaluating explainability for machine learning predictions using model-agnostic metrics.](http://arxiv.org/abs/2302.12094) | 本文提出了一种使用模型无关的度量标准，用于评估机器学习模型的预测结果的可解释性。这些度量标准将各个解释能力方面总结成标量，提供全面的理解并促进决策者和利益相关者之间的沟通，从而提高整体的透明度。 |
| [^25] | [The ODE Method for Asymptotic Statistics in Stochastic Approximation and Reinforcement Learning.](http://arxiv.org/abs/2110.14427) | 本文提出了一种称为ODE方法的渐近统计方法解决$d$维随机逼近递归的问题，证明了其收敛性和中心极限定理，为强化学习等领域的应用提供了有力的理论支持。 |

# 详细

[^1]: 离线强化学习的格点映射伪计数约束

    Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning

    [https://arxiv.org/abs/2404.02545](https://arxiv.org/abs/2404.02545)

    提出了一种用于连续领域的新的计数方法，称为格点映射伪计数方法（GPC），以适应离线环境中的强化学习问题，并在惩罚Q值的同时减少计算成本。

    

    离线强化学习是从静态数据集中学习而不与环境进行交互的方法，这确保了安全性并因此具有良好的应用前景。然而，直接应用朴素的强化学习方法通常在离线环境中失败，因为由于超出分布（OOD）行为引起的函数逼近误差。为了解决这个问题，现有算法主要惩罚OOD行为的Q值，其约束的质量也很重要。不精确的约束可能导致次优解，而精确的约束则需要显著的计算成本。在本文中，我们提出了一种新颖的连续领域计数方法，称为格点映射伪计数方法（GPC），以适当地惩罚Q值并减少计算成本。所提出的方法将状态和动作空间映射到离散空间，并通过伪计数约束它们的Q值。这是一个理论性

    arXiv:2404.02545v1 Announce Type: cross  Abstract: Offline reinforcement learning learns from a static dataset without interacting with the environment, which ensures security and thus owns a good prospect of application. However, directly applying naive reinforcement learning methods usually fails in an offline environment due to function approximation errors caused by out-of-distribution(OOD) actions. To solve this problem, existing algorithms mainly penalize the Q-value of OOD actions, the quality of whose constraints also matter. Imprecise constraints may lead to suboptimal solutions, while precise constraints require significant computational costs. In this paper, we propose a novel count-based method for continuous domains, called Grid-Mapping Pseudo-Count method(GPC), to penalize the Q-value appropriately and reduce the computational cost. The proposed method maps the state and action space to discrete space and constrains their Q-values through the pseudo-count. It is theoretic
    
[^2]: 大型语言模型中的长篇事实性

    Long-form factuality in large language models

    [https://arxiv.org/abs/2403.18802](https://arxiv.org/abs/2403.18802)

    该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。

    

    大型语言模型（LLMs）在回答开放性主题的事实性提示时，经常生成包含事实错误的内容。为了在开放领域中对模型的长篇事实性进行基准测试，我们首先使用GPT-4生成了一个名为LongFact的提示集，其中包含数千个囊括38个主题的问题。然后，我们提出LLM代理可以通过一种名为Search-Augmented Factuality Evaluator（SAFE）的方法作为长篇事实性的自动评估器。SAFE利用LLM将长篇回应分解为一组单独的事实，并通过发送搜索查询到Google搜索以及确定一个事实是否得到搜索结果支持的多步推理过程来评估每个事实的准确性。此外，我们还提议将F1分数扩展为长篇事实性的聚合度量。为此，我们平衡了回应中支持事实的百分比（精度）与

    arXiv:2403.18802v1 Announce Type: cross  Abstract: Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the 
    
[^3]: Weisfeiler和Leman变得疯狂：一种新的图表示学习层次结构

    Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning

    [https://arxiv.org/abs/2403.13749](https://arxiv.org/abs/2403.13749)

    引入了新的图同构测试层次结构$r$-$\ell{}$WL以及相应的GNN框架$r$-$\ell{}$MPNN，能够计数长度最多为$r + 2$的循环，具有强大的表达能力和计数能力，在真实数据集上表现出最先进的预测性能。

    

    我们引入$r$-loopy Weisfeiler-Leman ($r$-$\ell{}$WL)，这是一种新颖的图同构测试层次结构以及相应的GNN框架$r$-$\ell{}$MPNN，该框架可以计数长度最多为$r + 2$的循环。最重要的是，我们展示了$r$-$\ell{}$WL可以计数仙人掌图的同态。这严格地扩展了经典的1-WL，后者只能计数树的同态，实际上与任意固定的$k$-WL是不可比的。我们在几个合成数据集上经验验证了所提出的$r$-$\ell{}$MPNN的表达和计数能力，并展示了在各种真实数据集上具有最先进的预测性能。代码可在https://github.com/RPaolino/loopy找到。

    arXiv:2403.13749v1 Announce Type: new  Abstract: We introduce $r$-loopy Weisfeiler-Leman ($r$-$\ell{}$WL), a novel hierarchy of graph isomorphism tests and a corresponding GNN framework, $r$-$\ell{}$MPNN, that can count cycles up to length $r + 2$. Most notably, we show that $r$-$\ell{}$WL can count homomorphisms of cactus graphs. This strictly extends classical 1-WL, which can only count homomorphisms of trees and, in fact, is incomparable to $k$-WL for any fixed $k$. We empirically validate the expressive and counting power of the proposed $r$-$\ell{}$MPNN on several synthetic datasets and present state-of-the-art predictive performance on various real-world datasets. The code is available at https://github.com/RPaolino/loopy
    
[^4]: 在隐私敏感领域中从联邦学习中有可证明的互惠益处

    Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains

    [https://arxiv.org/abs/2403.06672](https://arxiv.org/abs/2403.06672)

    本文研究了在隐私敏感领域中如何设计一种FL协议，既能保证隐私，又能提高模型准确性，并提供了设计出对所有参与者都有益处的协议。

    

    跨领域联邦学习（FL）允许数据所有者通过从彼此的私有数据集中获益来训练准确的机器学习模型。本文研究了在何时以及如何服务器可以设计一种对所有参与者都有利的FL协议的问题。我们提供了在均值估计和凸随机优化背景下存在相互有利协议的必要和充分条件。我们推导出了在对称隐私偏好下，最大化总客户效用的协议。最后，我们设计了最大化最终模型准确性的协议，并在合成实验中展示了它们的好处。

    arXiv:2403.06672v1 Announce Type: cross  Abstract: Cross-silo federated learning (FL) allows data owners to train accurate machine learning models by benefiting from each others private datasets. Unfortunately, the model accuracy benefits of collaboration are often undermined by privacy defenses. Therefore, to incentivize client participation in privacy-sensitive domains, a FL protocol should strike a delicate balance between privacy guarantees and end-model accuracy. In this paper, we study the question of when and how a server could design a FL protocol provably beneficial for all participants. First, we provide necessary and sufficient conditions for the existence of mutually beneficial protocols in the context of mean estimation and convex stochastic optimization. We also derive protocols that maximize the total clients' utility, given symmetric privacy preferences. Finally, we design protocols maximizing end-model accuracy and demonstrate their benefits in synthetic experiments.
    
[^5]: 梯度被罚：通过探索拒绝损失地形图来检测针对大语言模型的越狱攻击

    Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes

    [https://arxiv.org/abs/2403.00867](https://arxiv.org/abs/2403.00867)

    本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。

    

    大型语言模型（LLMs）正成为一种突出的生成式AI工具，用户输入查询，LLM生成答案。为了减少伤害和滥用，人们通过使用先进的训练技术如来自人类反馈的强化学习（RLHF）来将这些LLMs与人类价值观保持一致。然而，最近的研究突显了LLMs对于试图颠覆嵌入的安全防护措施的对抗性越狱尝试的脆弱性。为了解决这一挑战，本文定义并调查了LLMs的拒绝损失，然后提出了一种名为Gradient Cuff的方法来检测越狱尝试。Gradient Cuff利用拒绝损失地形图中观察到的独特特性，包括功能值及其光滑性，设计了一种有效的两步检测策略。

    arXiv:2403.00867v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN,
    
[^6]: 具有图反馈的随机上下文赌博：从独立数到MAS数

    Stochastic contextual bandits with graph feedback: from independence number to MAS number

    [https://arxiv.org/abs/2402.18591](https://arxiv.org/abs/2402.18591)

    本文研究了具有图反馈的上下文赌博问题，提出了一个刻画学习极限的图论量 $\beta_M(G)$，并建立了对应的遗憾下限。

    

    我们考虑具有图反馈的上下文赌博，在这类互动学习问题中，具有比普通上下文赌博更丰富结构，其中采取一个行动将在所有情境下揭示所有相邻行动的奖励。与多臂赌博设置不同，多文献已经对图反馈的理解进行了全面探讨，但在上下文赌博对应部分仍有许多未被探讨的地方。在本文中，我们通过建立一个遗憾下限 $\Omega(\sqrt{\beta_M(G) T})$ 探究了这个问题，其中 $M$ 是情境数，$G$ 是反馈图，$\beta_M(G)$ 是我们提出的表征该问题类的基础学习限制的图论量。有趣的是，$\beta_M(G)$ 在 $\alpha(G)$ (图的独立数) 和 $\mathsf{m}(G)$ (图的最大无环子图（MAS）数) 之间插值。

    arXiv:2402.18591v1 Announce Type: new  Abstract: We consider contextual bandits with graph feedback, a class of interactive learning problems with richer structures than vanilla contextual bandits, where taking an action reveals the rewards for all neighboring actions in the feedback graph under all contexts. Unlike the multi-armed bandits setting where a growing literature has painted a near-complete understanding of graph feedback, much remains unexplored in the contextual bandits counterpart. In this paper, we make inroads into this inquiry by establishing a regret lower bound $\Omega(\sqrt{\beta_M(G) T})$, where $M$ is the number of contexts, $G$ is the feedback graph, and $\beta_M(G)$ is our proposed graph-theoretical quantity that characterizes the fundamental learning limit for this class of problems. Interestingly, $\beta_M(G)$ interpolates between $\alpha(G)$ (the independence number of the graph) and $\mathsf{m}(G)$ (the maximum acyclic subgraph (MAS) number of the graph) as 
    
[^7]: 神经网络中的深度分离：将维度与准确度分离

    Depth Separations in Neural Networks: Separating the Dimension from the Accuracy

    [https://arxiv.org/abs/2402.07248](https://arxiv.org/abs/2402.07248)

    通过研究深度2和深度3神经网络在逼近Lipschitz目标函数时的分离性质，证明了维度诅咒也会在深度2逼近中存在，即使目标函数可以使用深度3高效表示。这为以前确定深度要求的下界提供了新的观点，并且适用于多种激活函数。

    

    我们证明了深度2和深度3神经网络在逼近一个$\mathcal{O}(1)$-Lipschitz目标函数至常数精度时的指数分离，对于支持在$[0,1]^{d}$上的分布，假设权重指数有界。这解决了在\citet{safran2019depth}中提出的一个问题，并证明了维度诅咒在深度2逼近中的存在，即使在目标函数可以使用深度3高效表示的情况下也是如此。以前，将深度2和深度3分离的下界要求至少有一个Lipschitz参数、目标准确度或逼近域的大小（某种度量）与输入维度多项式地缩放，而我们保持前两者不变，并将我们的域限制在单位超立方体上。我们的下界适用于各种激活函数，并基于一种新的平均情况到最坏情况的随机自约化论证的应用，以减少

    We prove an exponential separation between depth 2 and depth 3 neural networks, when approximating an $\mathcal{O}(1)$-Lipschitz target function to constant accuracy, with respect to a distribution with support in $[0,1]^{d}$, assuming exponentially bounded weights. This addresses an open problem posed in \citet{safran2019depth}, and proves that the curse of dimensionality manifests in depth 2 approximation, even in cases where the target function can be represented efficiently using depth 3. Previously, lower bounds that were used to separate depth 2 from depth 3 required that at least one of the Lipschitz parameter, target accuracy or (some measure of) the size of the domain of approximation scale polynomially with the input dimension, whereas we fix the former two and restrict our domain to the unit hypercube. Our lower bound holds for a wide variety of activation functions, and is based on a novel application of an average- to worst-case random self-reducibility argument, to reduce
    
[^8]: 梯度噪声的隐性偏见：从对称性角度来看

    The Implicit Bias of Gradient Noise: A Symmetry Perspective

    [https://arxiv.org/abs/2402.07193](https://arxiv.org/abs/2402.07193)

    本研究通过对对称性的存在进行分析，揭示了梯度噪声在随机梯度下降中的隐性偏见。我们发现不同类型的对称性会导致不同的学习动态，其中一类对称性可以自然收敛，而另一类对称性几乎总是发散。此外，我们的研究结果适用于没有对称性的损失函数，对于理解训练动态和解释相关实际问题具有普适性。

    

    我们对随机梯度下降（SGD）在损失函数存在连续对称性时的学习动态进行了表征，说明了SGD和梯度下降之间的分歧是多么巨大。我们展示了根据对称性对学习动态的影响方式，我们可以将一族对称性分为两类。对于一类对称性，SGD自然地收敛到具有平衡和对齐梯度噪声的解。对于另一类对称性，SGD几乎总是发散的。然后，我们展示了即使损失函数中没有对称性，我们的结果依然适用并可以帮助我们理解训练动态。我们的主要结果是普遍的，它只依赖于对称性的存在，而与损失函数的细节无关。我们证明了所提出的理论对于逐步变形和平坦化提供了解释，并可以应用于常见的实际问题，如表示正则化。

    We characterize the learning dynamics of stochastic gradient descent (SGD) when continuous symmetry exists in the loss function, where the divergence between SGD and gradient descent is dramatic. We show that depending on how the symmetry affects the learning dynamics, we can divide a family of symmetry into two classes. For one class of symmetry, SGD naturally converges to solutions that have a balanced and aligned gradient noise. For the other class of symmetry, SGD will almost always diverge. Then, we show that our result remains applicable and can help us understand the training dynamics even when the symmetry is not present in the loss function. Our main result is universal in the sense that it only depends on the existence of the symmetry and is independent of the details of the loss function. We demonstrate that the proposed theory offers an explanation of progressive sharpening and flattening and can be applied to common practical problems such as representation normalization, 
    
[^9]: 具有相关输入扰动的差分隐私范围查询

    Differentially Private Range Queries with Correlated Input Perturbation

    [https://arxiv.org/abs/2402.07066](https://arxiv.org/abs/2402.07066)

    本研究提出了一种具有相关输入扰动的差分隐私范围查询的局部机制，通过级联采样算法实现，实验表明在保障近乎最优的效用的同时，与输出扰动方法在实践中具有竞争力。

    

    本工作提出了一种用于线性查询的局部差分隐私机制，特别是范围查询，利用相关输入扰动同时实现无偏性、一致性、统计透明性和对精度目标的控制，无论是在某些查询边缘上还是在层次数据库结构所暗示的精度要求上。所提出的级联采样算法准确高效地实现了该机制。我们的界限表明，我们在保障近乎最优的效用的同时，与输出扰动方法在实践中具有竞争力。

    This work proposes a class of locally differentially private mechanisms for linear queries, in particular range queries, that leverages correlated input perturbation to simultaneously achieve unbiasedness, consistency, statistical transparency, and control over utility requirements in terms of accuracy targets expressed either in certain query margins or as implied by the hierarchical database structure. The proposed Cascade Sampling algorithm instantiates the mechanism exactly and efficiently. Our bounds show that we obtain near-optimal utility while being empirically competitive against output perturbation methods.
    
[^10]: CataractBot：一种基于LLM的白内障患者专家辅助聊天机器人

    CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract Patients

    [https://arxiv.org/abs/2402.04620](https://arxiv.org/abs/2402.04620)

    CataractBot是一种基于LLM的白内障患者专家辅助聊天机器人，通过查询知识库提供即时的答案和专家验证的回复。在实地部署研究中证明了其价值所在。

    

    随着医疗行业的发展，患者越来越追求更可靠的健康信息，包括他们的健康状况、治疗选择和潜在风险。虽然有很多信息来源，但数字时代却给人们带来了过多且错误的信息。患者主要信任医生和医院工作人员，突显了专家认可的健康信息的必要性。但是，专家面临的压力导致了沟通时间的减少，影响了信息的共享。为了填补这一空白，我们提出了CataractBot，一种由大型语言模型（LLMs）驱动的专家辅助聊天机器人。与印度一家三级眼科医院合作开发的CataractBot通过查询策划的知识库，即时回答白内障手术相关的问题，并异步提供专家验证的答复。CataractBot具备多模式支持和多语言能力。在与49名参与者的实地部署研究中，CataractBot证明了其价值所在。

    The healthcare landscape is evolving, with patients seeking more reliable information about their health conditions, treatment options, and potential risks. Despite the abundance of information sources, the digital age overwhelms individuals with excess, often inaccurate information. Patients primarily trust doctors and hospital staff, highlighting the need for expert-endorsed health information. However, the pressure on experts has led to reduced communication time, impacting information sharing. To address this gap, we propose CataractBot, an experts-in-the-loop chatbot powered by large language models (LLMs). Developed in collaboration with a tertiary eye hospital in India, CataractBot answers cataract surgery related questions instantly by querying a curated knowledge base, and provides expert-verified responses asynchronously. CataractBot features multimodal support and multilingual capabilities. In an in-the-wild deployment study with 49 participants, CataractBot proved valuable,
    
[^11]: 超扩散：使用单一模型估计认识和偶然不确定性

    Hyper-Diffusion: Estimating Epistemic and Aleatoric Uncertainty with a Single Model

    [https://arxiv.org/abs/2402.03478](https://arxiv.org/abs/2402.03478)

    本研究引入了一种新的集合方法，超扩散，可以使用单一模型准确估计认识和偶然不确定性。

    

    在将机器学习应用于高风险应用领域（如医学影像和天气预报）时，准确估计和区分认识不确定性（可以通过更多的训练数据降低的不确定性）和偶然不确定性（与当前任务固有的不确定性）至关重要。条件扩散模型具有准确有效地从数据集的后验分布中采样的突破性能力，现在使得不确定性估计从概念上变得简单明了：只需要训练和从一个大型扩散模型集合中采样即可。然而，随着模型架构的复杂性增加，训练这样一个集合变得难以计算。在本文中，我们介绍了一种新的集合方法，超扩散，它可以使用单一模型准确估计认识和偶然不确定性。

    Estimating and disentangling epistemic uncertainty (uncertainty that can be reduced with more training data) and aleatoric uncertainty (uncertainty that is inherent to the task at hand) is critically important when applying machine learning (ML) to high-stakes applications such as medical imaging and weather forecasting. Conditional diffusion models' breakthrough ability to accurately and efficiently sample from the posterior distribution of a dataset now makes uncertainty estimation conceptually straightforward: One need only train and sample from a large ensemble of diffusion models. Unfortunately, training such an ensemble becomes computationally intractable as the complexity of the model architecture grows.   In this work we introduce a new approach to ensembling, hyper-diffusion, which allows one to accurately estimate epistemic and aleatoric uncertainty with a single model. Unlike existing Monte Carlo dropout based single-model ensembling methods, hyper-diffusion offers the same 
    
[^12]: GD无法胜任：非可微性对神经网络训练的三种影响方式

    GD doesn't make the cut: Three ways that non-differentiability affects neural network training

    [https://arxiv.org/abs/2401.08426](https://arxiv.org/abs/2401.08426)

    本文研究了非可微性对神经网络训练的影响，包括收敛性差异、$L_1$正则化问题的矛盾性质以及稳定边界现象的不适用性。

    

    本文研究了应用于非可微函数（NGDMs）和应用于可微函数的传统梯度下降（GDs）之间的区别。首先，我们证明了NGDMs的收敛性质与GDs存在显著差异，挑战了基于$L$-光滑性的广泛神经网络收敛文献对非光滑神经网络的适用性。接下来，我们展示了NGDM解决$L_1$正则化问题的矛盾性质，表明增加正则化惩罚会导致NGDMs中最优解的$L_1$范数增加。因此，我们证明了广泛采用的基于$L_1$惩罚的网络修剪技术并未产生预期结果。最后，我们探索了稳定边界现象（Edge of Stability），指出即使对于Lipschitz连续凸可微函数，它也不适用于非凸非可微的神经网络。

    This paper investigates the distinctions between gradient methods applied to non-differentiable functions (NGDMs) and classical gradient descents (GDs) designed for differentiable functions. First, we demonstrate significant differences in the convergence properties of NGDMs compared to GDs, challenging the applicability of the extensive neural network convergence literature based on $L-smoothness$ to non-smooth neural networks. Next, we demonstrate the paradoxical nature of NGDM solutions for $L_{1}$-regularized problems, showing that increasing the regularization penalty leads to an increase in the $L_{1}$ norm of optimal solutions in NGDMs. Consequently, we show that widely adopted $L_{1}$ penalization-based techniques for network pruning do not yield expected results. Finally, we explore the Edge of Stability phenomenon, indicating its inapplicability even to Lipschitz continuous convex differentiable functions, leaving its relevance to non-convex non-differentiable neural networks
    
[^13]: 心室分割：U-Net衍生模型的简要比较

    Ventricular Segmentation: A Brief Comparison of U-Net Derivatives. (arXiv:2401.09980v1 [eess.IV])

    [http://arxiv.org/abs/2401.09980](http://arxiv.org/abs/2401.09980)

    本文探讨了深度学习技术在心脏图像分割中的应用，实施了多个U-Net衍生模型以实现对心脏特定部位的全面解剖和功能分析。通过图像、图表和定量指标验证了模型的效果，并讨论了面临的挑战和未来改进策略。

    

    医学影像是指用于观察人体及其内部的技术和方法，以诊断、监测甚至治疗医学疾病。本文旨在探讨深度学习技术在心脏短轴磁共振成像图像的语义分割中的应用，旨在提高与心脏相关的医学疾病的诊断、监测和治疗。重点是实施各种U-Net的衍生体系结构，以有效地分离心脏的特定部分，进行全面的解剖和功能分析。通过图像、图表和定量指标的组合展示了模型及其预测的效果。此外，本文还讨论了遇到的挑战，并概述了未来改进的策略。本摘要简要概述了利用深度学习进行心脏图像分割的工作，强调了模型的有效性。

    Medical imaging refers to the technologies and methods utilized to view the human body and its inside, in order to diagnose, monitor, or even treat medical disorders. This paper aims to explore the application of deep learning techniques in the semantic segmentation of Cardiac short-axis MRI (Magnetic Resonance Imaging) images, aiming to enhance the diagnosis, monitoring, and treatment of medical disorders related to the heart. The focus centers on implementing various architectures that are derivatives of U-Net, to effectively isolate specific parts of the heart for comprehensive anatomical and functional analysis. Through a combination of images, graphs, and quantitative metrics, the efficacy of the models and their predictions are showcased. Additionally, this paper addresses encountered challenges and outline strategies for future improvements. This abstract provides a concise overview of the efforts in utilizing deep learning for cardiac image segmentation, emphasizing both the ac
    
[^14]: MeTA: 多源测试时适应

    MeTA: Multi-source Test Time Adaptation. (arXiv:2401.02561v1 [cs.LG])

    [http://arxiv.org/abs/2401.02561](http://arxiv.org/abs/2401.02561)

    MeTA是第一个完全无监督的多源测试时适应框架，它可以在没有访问源数据的情况下，以最佳组合权重适应多个源模型到测试数据分布。

    

    测试时适应是一个无监督的过程，它将预训练的源模型适应到每个进入的测试数据批次中（即，无需大量的测试数据可用，就像传统领域适应中那样），并且没有访问源数据的权限。由于它与每个测试数据批次一起工作，因此非常适合需要在数据流入时进行决策的动态环境。当前的测试时适应方法主要集中在单个源模型上。我们提出了第一个完全无监督的多源测试时适应（MeTA）框架，它处理多个源模型并将它们最佳组合以适应测试数据。MeTA具有两个独特的特点。首先，它有效地获得最佳组合权重，以将源模型组合以适应测试数据分布。其次，它确定要更新哪个源模型参数，以便只更新与测试数据最相关的模型。

    Test time adaptation is the process of adapting, in an unsupervised manner, a pre-trained source model to each incoming batch of the test data (i.e., without requiring a substantial portion of the test data to be available, as in traditional domain adaptation) and without access to the source data. Since it works with each batch of test data, it is well-suited for dynamic environments where decisions need to be made as the data is streaming in. Current test time adaptation methods are primarily focused on a single source model. We propose the first completely unsupervised Multi-source Test Time Adaptation (MeTA) framework that handles multiple source models and optimally combines them to adapt to the test data. MeTA has two distinguishing features. First, it efficiently obtains the optimal combination weights to combine the source models to adapt to the test data distribution. Second, it identifies which of the source model parameters to update so that only the model which is most corr
    
[^15]: 基于神经算子流的量子场论多格采样方法

    Multi-Lattice Sampling of Quantum Field Theories via Neural Operator-based Flows. (arXiv:2401.00828v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.00828](http://arxiv.org/abs/2401.00828)

    本文提出了一种基于神经算子流的方法，通过近似时间相关算子，实现了在量子场论中从底层自由理论到目标理论的离散-连续归一化流。

    

    本文考虑从玻尔兹曼分布中采样离散场配置$\phi$的问题，其中$S$是某个量子场论连续欧几里得作用$\mathcal S$的格点离散化。我们将该密度近似视为底层函数密度$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$的学习算子实例。具体而言，我们提出了近似时间相关算子$\mathcal V_t$的方法，其时间积分提供了自由理论$[\mathcal D\phi(x)]\mathcal Z_0^{-1}e^{-\mathcal S_{0}[\phi(x)]}$的函数分布与目标理论$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$之间的映射。当选择特定的格点时，算子$\mathcal V_t$可以离散化为有限维的时间相关矢量场$V_t$，从而在离散格点上实现了连续的归一化流。

    We consider the problem of sampling discrete field configurations $\phi$ from the Boltzmann distribution $[d\phi] Z^{-1} e^{-S[\phi]}$, where $S$ is the lattice-discretization of the continuous Euclidean action $\mathcal S$ of some quantum field theory. Since such densities arise as the approximation of the underlying functional density $[\mathcal D\phi(x)] \mathcal Z^{-1} e^{-\mathcal S[\phi(x)]}$, we frame the task as an instance of operator learning. In particular, we propose to approximate a time-dependent operator $\mathcal V_t$ whose time integral provides a mapping between the functional distributions of the free theory $[\mathcal D\phi(x)] \mathcal Z_0^{-1} e^{-\mathcal S_{0}[\phi(x)]}$ and of the target theory $[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$. Whenever a particular lattice is chosen, the operator $\mathcal V_t$ can be discretized to a finite dimensional, time-dependent vector field $V_t$ which in turn induces a continuous normalizing flow between fi
    
[^16]: 条件储层相生成的潜在扩散模型

    Latent Diffusion Model for Conditional Reservoir Facies Generation. (arXiv:2311.01968v1 [physics.geo-ph])

    [http://arxiv.org/abs/2311.01968](http://arxiv.org/abs/2311.01968)

    本研究提出了一种专门用于条件下储层相生成的潜在扩散模型，通过充分保留条件数据，生成了高保真度的储层相。它在性能上明显优于基于GANs的替代方法。

    

    在油气领域的田地开发和储层管理中，基于有限测量数据创建准确且地质真实的储层相至关重要。传统的两点地质统计方法虽然基础，但往往难以捕捉复杂的地质模式。多点统计方法提供了更大的灵活性，但也面临着挑战。随着生成对抗网络（GANs）的兴起和它们在不同领域的成功，人们开始倾向于使用它们进行储层相生成。然而，计算机视觉领域的最新进展显示了扩散模型相较于GANs的卓越性能。受此启发，提出了一种新颖的潜在扩散模型，专门用于条件下的储层相生成。该模型产生了高保真度的储层相，严格保留了条件数据。它明显优于基于GANs的替代方法。

    Creating accurate and geologically realistic reservoir facies based on limited measurements is crucial for field development and reservoir management, especially in the oil and gas sector. Traditional two-point geostatistics, while foundational, often struggle to capture complex geological patterns. Multi-point statistics offers more flexibility, but comes with its own challenges. With the rise of Generative Adversarial Networks (GANs) and their success in various fields, there has been a shift towards using them for facies generation. However, recent advances in the computer vision domain have shown the superiority of diffusion models over GANs. Motivated by this, a novel Latent Diffusion Model is proposed, which is specifically designed for conditional generation of reservoir facies. The proposed model produces high-fidelity facies realizations that rigorously preserve conditioning data. It significantly outperforms a GAN-based alternative.
    
[^17]: 健壮的多模态模型具有异常特征并编码更多概念

    Robust multimodal models have outlier features and encode more concepts. (arXiv:2310.13040v1 [cs.LG])

    [http://arxiv.org/abs/2310.13040](http://arxiv.org/abs/2310.13040)

    健壮的多模态模型展示了异常特征和更多概念的编码方式。

    

    什么区分健壮模型与非健壮模型？随着大规模多模态模型（如CLIP）的出现，这个问题引起了人们的关注。这些模型在自然分布转变方面表现出了前所未有的健壮性。尽管已经证明了健壮性的差异可以追溯到训练数据上的差异，但迄今为止还不清楚这对于模型学习到了什么意味着。在这项工作中，我们通过探测12个具有不同骨干（ResNets和ViTs）和预训练集（OpenAI，LAION-400M，LAION-2B，YFCC15M，CC12M和DataComp）的健壮多模态模型的表示空间来填补这一空白。我们发现这些模型的表示空间中存在两个健壮性的特征：（1）健壮模型具有由其激活特征表征的异常特征，其中一些特征值比平均值高几个数量级。这些异常特征在模型的表示空间中引入了特权方向。我们证明了...

    What distinguishes robust models from non-robust ones? This question has gained traction with the appearance of large-scale multimodal models, such as CLIP. These models have demonstrated unprecedented robustness with respect to natural distribution shifts. While it has been shown that such differences in robustness can be traced back to differences in training data, so far it is not known what that translates to in terms of what the model has learned. In this work, we bridge this gap by probing the representation spaces of 12 robust multimodal models with various backbones (ResNets and ViTs) and pretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp). We find two signatures of robustness in the representation spaces of these models: (1) Robust models exhibit outlier features characterized by their activations, with some being several orders of magnitude above average. These outlier features induce privileged directions in the model's representation space. We demon
    
[^18]: 生成熵神经最优传输在空间内外映射中的应用

    Generative Entropic Neural Optimal Transport To Map Within and Across Spaces. (arXiv:2310.09254v1 [stat.ML])

    [http://arxiv.org/abs/2310.09254](http://arxiv.org/abs/2310.09254)

    该论文介绍了生成熵神经最优传输在测度到测度映射中的应用，解决了处理非平方欧氏距离成本、确定性蒙格映射、映射跨不可比较空间和质量守恒约束等实际挑战。

    

    学习测度到测度的映射是机器学习中的一个关键任务，尤其在生成建模中占据重要地位。近年来，受最优传输理论启发的技术不断涌现。结合神经网络模型，这些方法统称为"神经最优传输"，将最优传输作为归纳偏好：这些映射应该针对给定的成本函数是最优的，能以节约的方式（通过最小化位移）在空间内或空间间移动点。这一原则在直观上是合理的，但往往面临几个实际挑战，需要调整最优传输工具箱：处理其他非平方欧氏距离成本的挑战，确定性状况下的蒙格映射公式会限制灵活性，映射在不可比较的空间中会带来多个挑战，最优传输固有的质量守恒约束可能对异常数据给予过多的重视。

    Learning measure-to-measure mappings is a crucial task in machine learning, featured prominently in generative modeling. Recent years have witnessed a surge of techniques that draw inspiration from optimal transport (OT) theory. Combined with neural network models, these methods collectively known as \textit{Neural OT} use optimal transport as an inductive bias: such mappings should be optimal w.r.t. a given cost function, in the sense that they are able to move points in a thrifty way, within (by minimizing displacements) or across spaces (by being isometric). This principle, while intuitive, is often confronted with several practical challenges that require adapting the OT toolbox: cost functions other than the squared-Euclidean cost can be challenging to handle, the deterministic formulation of Monge maps leaves little flexibility, mapping across incomparable spaces raises multiple challenges, while the mass conservation constraint inherent to OT can provide too much credit to outli
    
[^19]: 未知方差下的高斯均值的任意有效T检验和置信序列

    Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])

    [http://arxiv.org/abs/2310.03722](http://arxiv.org/abs/2310.03722)

    本文提出了两种新的“e-process”和置信序列方法，分别通过替换Lai的混合方法，并分析了所得结果的宽度。

    

    在1976年，Lai构造了一个非平凡的均值$\mu$的高斯分布的置信序列，该分布的方差$\sigma$是未知的。他使用了关于$\sigma$的不适当（右Haar）混合和关于$\mu$的不适当（平坦）混合。在本文中，我们详细说明了他构建的细节，其中使用了广义的不可积分鞅和扩展的维尔不等式。尽管这确实产生了一个顺序T检验，但由于他的鞅不可积分，它并没有产生一个“e-process”。在本文中，我们为相同的设置开发了两个新的“e-process”和置信序列：一个是在缩减滤波器中的测试鞅，另一个是在规范数据滤波器中的“e-process”。这些分别是通过将Lai的平坦混合替换为高斯混合，并将对$\sigma$的右Haar混合替换为在零空间下的最大似然估计，就像在通用推断中一样。我们还分析了所得结果的宽度。

    In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an ``e-process'' (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting 
    
[^20]: NeuralClothSim: 神经变形场与Kirchhoff-Love薄壳理论相遇

    NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory. (arXiv:2308.12970v1 [cs.GR])

    [http://arxiv.org/abs/2308.12970](http://arxiv.org/abs/2308.12970)

    本文提出了一种新的布料模拟方法 NeuralClothSim，使用薄壳理论和神经变形场进行表面演化，克服了现有布料模拟方法的局限性和挑战，为物理合理的布料模拟提供了一种全新的视角。

    

    布料模拟是一个广泛研究的问题，在计算机图形学文献中有大量的解决方案。现有的布料模拟器产生符合不同类型边界条件的逼真布料变形。然而，它们的操作原理在几个方面仍然存在局限性：它们在具有固定空间分辨率的显式表面表示上进行操作，执行一系列离散化的更新（限制了它们的时间分辨率），并且需要相对较大的存储空间。此外，通过现有的求解器进行梯度反向传播通常并不直观，这在将其集成到现代神经架构中时造成了额外的挑战。针对上述限制，本文从根本上以一种根本不同的视角来考虑物理合理的布料模拟，并重新思考这个长期存在的问题：我们提出了NeuralClothSim，即一种使用薄壳的新布料模拟方法，其中表面演化通过神经变形场等进行。

    Cloth simulation is an extensively studied problem, with a plethora of solutions available in computer graphics literature. Existing cloth simulators produce realistic cloth deformations that obey different types of boundary conditions. Nevertheless, their operational principle remains limited in several ways: They operate on explicit surface representations with a fixed spatial resolution, perform a series of discretised updates (which bounds their temporal resolution), and require comparably large amounts of storage. Moreover, back-propagating gradients through the existing solvers is often not straightforward, which poses additional challenges when integrating them into modern neural architectures. In response to the limitations mentioned above, this paper takes a fundamentally different perspective on physically-plausible cloth simulation and re-thinks this long-standing problem: We propose NeuralClothSim, i.e., a new cloth simulation approach using thin shells, in which surface ev
    
[^21]: 云系统中的性能问题识别与关系-时间异常检测

    Performance Issue Identification in Cloud Systems with Relational-Temporal Anomaly Detection. (arXiv:2307.10869v1 [cs.LG])

    [http://arxiv.org/abs/2307.10869](http://arxiv.org/abs/2307.10869)

    云系统中的性能问题识别存在挑战，现有方法中的独立分析每个指标的异常无法解决问题，需要考虑指标之间的关联性。

    

    性能问题在大规模云服务系统中普遍存在，可能导致巨额收入损失。为了确保可靠的性能，使用服务监控指标准确地识别和定位这些问题是至关重要的。鉴于现代云系统的复杂性和规模，这项任务可能会具有挑战性，并且可能需要超出个人能力的广泛专业知识和资源。一些现有的方法通过分析每个指标独立地检测异常来解决这个问题。然而，这可能会导致难以由工程师手动诊断的压倒性警报风暴。为了追求更好的性能，不仅应考虑指标的时间模式，还应考虑指标之间的关联性模式，这可以被形式化为多变量指标异常检测问题。然而，大多数研究在明确提取这两种类型的特征方面存在不足。此外，存在一些未标记的异常。

    Performance issues permeate large-scale cloud service systems, which can lead to huge revenue losses. To ensure reliable performance, it's essential to accurately identify and localize these issues using service monitoring metrics. Given the complexity and scale of modern cloud systems, this task can be challenging and may require extensive expertise and resources beyond the capacity of individual humans. Some existing methods tackle this problem by analyzing each metric independently to detect anomalies. However, this could incur overwhelming alert storms that are difficult for engineers to diagnose manually. To pursue better performance, not only the temporal patterns of metrics but also the correlation between metrics (i.e., relational patterns) should be considered, which can be formulated as a multivariate metrics anomaly detection problem. However, most of the studies fall short of extracting these two types of features explicitly. Moreover, there exist some unlabeled anomalies m
    
[^22]: 对齐语言的视觉表示预测人类在自然学习任务中的行为

    Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks. (arXiv:2306.09377v1 [cs.LG])

    [http://arxiv.org/abs/2306.09377](http://arxiv.org/abs/2306.09377)

    语言对齐的视觉表示方式比纯视觉表示方式更有效地预测人类在自然学习任务中的行为。

    

    人类具备识别和概括自然物体相关特征的能力，在各种情境中有所帮助。为了研究这种现象并确定最有效的表示方式以预测人类行为，我们进行了两个涉及类别学习和奖励学习的实验。我们的实验使用逼真的图像作为刺激物，并要求参与者基于所有试验的新型刺激物作出准确的决策，因此需要泛化。在两个任务中，底层规则是使用人类相似性判断提取的刺激维度生成的简单线性函数。值得注意的是，参与者在几次试验内就成功地确定了相关的刺激特征，证明了有效的泛化。我们进行了广泛的模型比较，评估了各种深度学习模型的表示对人类选择的逐次预测准确性。有趣的是，自然语言处理任务（如语言建模和机器翻译）训练的模型表示优于视觉任务训练的模型表示，表明对齐语言的视觉表示可能更有效地预测人类在自然学习任务中的行为。

    Humans possess the ability to identify and generalize relevant features of natural objects, which aids them in various situations. To investigate this phenomenon and determine the most effective representations for predicting human behavior, we conducted two experiments involving category learning and reward learning. Our experiments used realistic images as stimuli, and participants were tasked with making accurate decisions based on novel stimuli for all trials, thereby necessitating generalization. In both tasks, the underlying rules were generated as simple linear functions using stimulus dimensions extracted from human similarity judgments. Notably, participants successfully identified the relevant stimulus features within a few trials, demonstrating effective generalization. We performed an extensive model comparison, evaluating the trial-by-trial predictive accuracy of diverse deep learning models' representations of human choices. Intriguingly, representations from models train
    
[^23]: 在竞争性多智能体环境中学习沟通和协作以清理海洋废弃塑料

    Learning to Communicate and Collaborate in a Competitive Multi-Agent Setup to Clean the Ocean from Macroplastics. (arXiv:2304.05872v1 [cs.AI])

    [http://arxiv.org/abs/2304.05872](http://arxiv.org/abs/2304.05872)

    本文提出了一种基于图神经网络（GNN）的、用于多智能体交互式海洋废弃物清理的通信机制，使得不同代理之间可以协作竞争并实现收集废弃物的最大化。

    

    在许多实际应用中，协作与竞争之间的平衡对于人工智能代理至关重要。本文使用多智能体强化学习（MARL）建立在一个高影响问题上，通过对海洋废弃塑料的收集实现了协作与竞争的平衡。我们提出了一种基于图神经网络（GNN）的通信机制，它增加了代理的观察空间。在我们自定义的环境中，代理控制着收集塑料的船只。这种通信机制使代理能够使用二进制信号来开发通信协议。虽然代理的集体目标是尽可能地清理海洋废弃塑料，但代理会因个人收集到的废弃塑料数量而获得奖励。因此，代理必须学会有效地沟通并保持竞争关系。

    Finding a balance between collaboration and competition is crucial for artificial agents in many real-world applications. We investigate this using a Multi-Agent Reinforcement Learning (MARL) setup on the back of a high-impact problem. The accumulation and yearly growth of plastic in the ocean cause irreparable damage to many aspects of oceanic health and the marina system. To prevent further damage, we need to find ways to reduce macroplastics from known plastic patches in the ocean. Here we propose a Graph Neural Network (GNN) based communication mechanism that increases the agents' observation space. In our custom environment, agents control a plastic collecting vessel. The communication mechanism enables agents to develop a communication protocol using a binary signal. While the goal of the agent collective is to clean up as much as possible, agents are rewarded for the individual amount of macroplastics collected. Hence agents have to learn to communicate effectively while maintai
    
[^24]: 评估使用模型无关的度量标准解释机器学习预测的可解释性

    Evaluating explainability for machine learning predictions using model-agnostic metrics. (arXiv:2302.12094v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12094](http://arxiv.org/abs/2302.12094)

    本文提出了一种使用模型无关的度量标准，用于评估机器学习模型的预测结果的可解释性。这些度量标准将各个解释能力方面总结成标量，提供全面的理解并促进决策者和利益相关者之间的沟通，从而提高整体的透明度。

    

    人工智能技术的快速发展带来了管理和监管方面的众多挑战。人工智能系统正在被整合到各个行业和领域，决策者需全面细致地了解这些系统的能力和限制。这个需求的一个关键方面是能够解释机器学习模型的结果，这对于提高透明度和信任度以及帮助模型在道德上进行训练至关重要。本文提出了新颖的度量标准，用于量化AI模型预测结果是否可以通过其特征进行易于解释。我们的度量标准将解释能力的不同方面总结为标量，提供对模型预测的更全面的理解，促进决策者和利益相关者之间的沟通，从而提高整体的透明度。

    Rapid advancements in artificial intelligence (AI) technology have brought about a plethora of new challenges in terms of governance and regulation. AI systems are being integrated into various industries and sectors, creating a demand from decision-makers to possess a comprehensive and nuanced understanding of the capabilities and limitations of these systems. One critical aspect of this demand is the ability to explain the results of machine learning models, which is crucial to promoting transparency and trust in AI systems, as well as fundamental in helping machine learning models to be trained ethically. In this paper, we present novel metrics to quantify the degree of which AI model predictions can be easily explainable by its features. Our metrics summarize different aspects of explainability into scalars, providing a more comprehensive understanding of model predictions and facilitating communication between decision-makers and stakeholders, thereby increasing the overall transp
    
[^25]: 随机逼近和强化学习中渐近统计的ODE方法

    The ODE Method for Asymptotic Statistics in Stochastic Approximation and Reinforcement Learning. (arXiv:2110.14427v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2110.14427](http://arxiv.org/abs/2110.14427)

    本文提出了一种称为ODE方法的渐近统计方法解决$d$维随机逼近递归的问题，证明了其收敛性和中心极限定理，为强化学习等领域的应用提供了有力的理论支持。

    

    本文研究了$d$维随机逼近递归$$\theta_{n+1}=\theta_n+\alpha_{n+1}f(\theta_n, \Phi_{n+1})$$其中$\Phi$是一个在一般状态空间$\textsf{X}$上具有平稳分布$\pi$的几何遍历马尔可夫链，$f：\Re^d\times\textsf{X}\to\Re^d$。在称为（DV3）的Donsker-Varadhan Lyapunov漂移条件的一种版本和对具有向量场$\bar{f}(\theta)=\textsf{E}[f(\theta,\Phi)]$以及$\Phi\sim\pi$的均值流的稳定性条件下，建立了主要结果。(i) $\{\theta_n\}$以概率1和$L_4$收敛于$\bar{f}(\theta)$的唯一根$\theta^*$。(ii) 建立了泛函中心极限定理，以及归一化误差一维中心极限定理。(iii) 对于归一化版本$z_n{=:} \sqrt{n} (\theta^{\text{PR}}_n -\theta^*)$的平均参数$\theta^{\text{PR}}_n {=:} n^{-1} \sum_{k=1}^n\theta_k$ ，在步长的标准假设下，建立了中心极限定理。

    The paper concerns the $d$-dimensional stochastic approximation recursion, $$ \theta_{n+1}= \theta_n + \alpha_{n + 1} f(\theta_n, \Phi_{n+1}) $$ in which $\Phi$ is a geometrically ergodic Markov chain on a general state space $\textsf{X}$ with stationary distribution $\pi$, and $f:\Re^d\times\textsf{X}\to\Re^d$.  The main results are established under a version of the Donsker-Varadhan Lyapunov drift condition known as (DV3), and a stability condition for the mean flow with vector field $\bar{f}(\theta)=\textsf{E}[f(\theta,\Phi)]$, with $\Phi\sim\pi$.  (i) $\{ \theta_n\}$ is convergent a.s. and in $L_4$ to the unique root $\theta^*$ of $\bar{f}(\theta)$.  (ii) A functional CLT is established, as well as the usual one-dimensional CLT for the normalized error.  (iii) The CLT holds for the normalized version, $z_n{=:} \sqrt{n} (\theta^{\text{PR}}_n -\theta^*)$, of the averaged parameters, $\theta^{\text{PR}}_n {=:} n^{-1} \sum_{k=1}^n\theta_k$, subject to standard assumptions on the step-s
    

