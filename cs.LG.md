# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Social Dynamics of Consumer Response: A Unified Framework Integrating Statistical Physics and Marketing Dynamics](https://arxiv.org/abs/2404.02175) | 使用统计物理学和市场营销动态的理论框架，本研究提出了一个创新的方程，准确捕捉了广告支出与消费者反应之间的复杂关系，并验证了其有效性。 |
| [^2] | [Multi-Conditional Ranking with Large Language Models](https://arxiv.org/abs/2404.00211) | 该论文提出了一种新颖的分解推理方法(MCRank)，用于解决大型语言模型在多条件排序任务中性能下降的问题。 |
| [^3] | [Keypoint Action Tokens Enable In-Context Imitation Learning in Robotics](https://arxiv.org/abs/2403.19578) | 使用关键动作令牌（KAT）框架，研究展示了文本预训练的变形器（GPT-4 Turbo）在机器人领域可实现视觉模仿学习，将视觉观测映射为模拟示范者行为的动作序列，表现优越于现有的模仿学习方法。 |
| [^4] | ['One size doesn't fit all': Learning how many Examples to use for In-Context Learning for Improved Text Classification](https://arxiv.org/abs/2403.06402) | 本文提出了自适应上下文学习（AICL）的工作流程，通过动态调整示例数量来提高文本分类的性能，类似于k最近邻（k-NN）中的可变大小邻域。 |
| [^5] | [WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](https://arxiv.org/abs/2403.04808) | WaterMax提出了一种新的水印方案，能够在保持生成文本质量的同时实现高检测性能，打破了水印技术中质量和稳健性之间的传统平衡。 |
| [^6] | [ENOT: Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport](https://arxiv.org/abs/2403.03777) | 通过期望回归正则化，本论文提出了一种新的神经优化传输（NOT）训练程序扩展，能够有效地估计最优输运方案，并使学习变得稳定。 |
| [^7] | [Boosting Graph Pooling with Persistent Homology](https://arxiv.org/abs/2402.16346) | 通过PH向池化层注入全局拓扑不变性的机制显著提升了图神经网络的性能。 |
| [^8] | [Average gradient outer product as a mechanism for deep neural collapse](https://arxiv.org/abs/2402.13728) | 本文通过提供证据表明，深度神经网络中的神经坍塌主要是通过平均梯度外积进行深度特征学习的，权重的奇异结构与AGOP高度相关，导致类内变异坍塌。 |
| [^9] | [Polyhedral Complex Derivation from Piecewise Trilinear Networks](https://arxiv.org/abs/2402.10403) | 本文以三线性插值方法作为位置编码，提出了理论见解和分析网格提取方法，将高维曲面转换为平面，并引入了一种近似交点的方法，拓展了更广泛的应用。 |
| [^10] | [Timer: Transformers for Time Series Analysis at Scale](https://arxiv.org/abs/2402.02368) | 本文旨在早期开发大规模时间序列模型（LTSM），通过预训练和GPT风格架构，克服深度模型在小样本场景中的性能瓶颈，并实现在时间序列分析中的大样本泛化能力、可扩展性和任务普适性。 |
| [^11] | [CPT: Competence-progressive Training Strategy for Few-shot Node Classification](https://arxiv.org/abs/2402.00450) | CPT是一种新颖的两阶段课程学习方法，弥补了传统元学习方法在少样本节点分类上的困难。它使用能力递进的训练策略来提高元学习器的效果和稳定性。 |
| [^12] | [Path-based Explanation for Knowledge Graph Completion.](http://arxiv.org/abs/2401.02290) | 基于路径的KGC解释器Power-Link通过引入图加权技术，实现了可解释的知识图谱补全，推动了模型透明度和可靠性的提升。 |
| [^13] | [FedSN: A General Federated Learning Framework over LEO Satellite Networks.](http://arxiv.org/abs/2311.01483) | FedSN是一个通用的联邦学习框架，用于解决在LEO卫星网络中的异构计算和存储能力、有限的上行速率以及模型陈旧等关键挑战。 |
| [^14] | [Entity Matching using Large Language Models.](http://arxiv.org/abs/2310.11244) | 这项研究探讨了使用大型语言模型（LLMs）作为实体匹配的替代方法，相较于预训练的语言模型（PLMs），LLMs对训练数据需求较少且更具鲁棒性。 |
| [^15] | [Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models.](http://arxiv.org/abs/2310.03546) | 本研究提出了一种插拔式后验采样算法（PnP-ULA），通过将物理测量模型与深度学习先验相结合，解决了成像逆问题。我们通过理论分析和数值验证，量化了PnP-ULA在不匹配后验分布下的误差界限，结果表明PnP-ULA对于测量模型和去噪器的不匹配非常敏感。 |
| [^16] | [Efficient Anatomical labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks.](http://arxiv.org/abs/2309.17329) | 本文介绍了一种通过隐式点图网络高效解剖标记肺部树状结构的方法，提供了SOTA准确度和可用的表面，同时还提供了一个用于评估该方法的数据集。 |
| [^17] | [Learning-Augmented Decentralized Online Convex Optimization in Networks.](http://arxiv.org/abs/2306.10158) | 本论文研究了网络中的分布式在线凸优化问题，并提出了一种新的学习增强的分布式在线优化算法（LADO），该算法使个体智能体能够基于本地信息选择行动。与现有的算法不同，LADO在分布式设置中实现了强鲁棒性保证，并通过考虑鲁棒性要求来训练机器学习策略。此外，我们还证明了LADO算法的平均成本界限，揭示了平均性能和最坏情况鲁棒性之间的折衷。 |
| [^18] | [The Power of Populations in Decentralized Learning Dynamics.](http://arxiv.org/abs/2306.08670) | 本文研究了分散式学习动力学中个体群体的力量。我们介绍了一种分散式的多臂赌博机设置，并分析了几个针对此任务的分散式动力学家族。我们展示了这些动力学与一类“零和”乘法权重更新算法的联系，并开发了一个通用框架来分析这些协议的群体级遗憾。在广泛的参数范围下，我们得到了次线性的遗憾界限。 |
| [^19] | [FLEdge: Benchmarking Federated Machine Learning Applications in Edge Computing Systems.](http://arxiv.org/abs/2306.05172) | FLEdge是一个面向边缘计算系统中FL工作量的基准测试，通过研究硬件异构性、能量效率和隐私级别对FL系统训练的影响，以及客户端退出对最新FL策略的影响，提供了训练最先进的FL工作负载的新见解。 |
| [^20] | [Bounded KRnet and its applications to density estimation and approximation.](http://arxiv.org/abs/2305.09063) | 本文介绍了一种新的可逆映射B-KRnet，并将其应用于数据或PDE的密度估计/近似，由于其定义在有界域上，因此比KRnet更有效。 |
| [^21] | [SIA-FTP: A Spoken Instruction Aware Flight Trajectory Prediction Framework.](http://arxiv.org/abs/2305.01661) | 提出一种语音指令感知的飞行轨迹预测框架，通过融合即时的语音指令和飞行轨迹表示，解决了语音指令和飞行轨迹的模态差距问题，在多个真实世界数据集上表现优异。 |
| [^22] | [Optimization Dynamics of Equivariant and Augmented Neural Networks.](http://arxiv.org/abs/2303.13458) | 本论文研究了在对称数据上优化多层感知机的方法，比较了等变和增强两种策略的优缺点，证明了在自然假设下等变稳定点的集合和等变层的集合具有不变性，但增强模型的稳定点可能是不稳定的。 |
| [^23] | [Simplifying Subgraph Representation Learning for Scalable Link Prediction.](http://arxiv.org/abs/2301.12562) | 提出了一种新的可扩展简化子图表示学习（S3GRL）框架，通过简化每个链接子图中的消息传递和聚合操作实现更快的训练和推理，并可适应各种子图采样策略和扩散操作符以模拟计算代价高的子图表示学习。大量实验证明了S3GRL模型可以扩展SGRL而不会显著降低性能。 |

# 详细

[^1]: 消费者反应的社会动态：融合统计物理学与营销动态的统一框架

    Social Dynamics of Consumer Response: A Unified Framework Integrating Statistical Physics and Marketing Dynamics

    [https://arxiv.org/abs/2404.02175](https://arxiv.org/abs/2404.02175)

    使用统计物理学和市场营销动态的理论框架，本研究提出了一个创新的方程，准确捕捉了广告支出与消费者反应之间的复杂关系，并验证了其有效性。

    

    理解消费者对广告输入的反应对于旨在优化广告策略并提高广告活动有效性的营销人员至关重要。本研究通过应用源自物理学和社会心理学的理论框架，研究消费者行为的复杂性。我们提出了一个创新的方程，捕捉了广告支出与消费者反应之间的关系，利用了诸如对称性、标度律和相变等概念。通过将我们的方程验证与Michaelis-Menten和Hill方程等著名模型相比较，我们证明了其在准确表示消费者反应动态复杂性方面的有效性。分析强调了关键模型参数（如营销效果、反应敏感度和行为敏感度）对影响消费者行为的重要性。该研究探讨了广告商和营销人员的实际影响。

    arXiv:2404.02175v1 Announce Type: cross  Abstract: Comprehending how consumers react to advertising inputs is essential for marketers aiming to optimize advertising strategies and improve campaign effectiveness. This study examines the complex nature of consumer behaviour by applying theoretical frameworks derived from physics and social psychology. We present an innovative equation that captures the relation between spending on advertising and consumer response, using concepts such as symmetries, scaling laws, and phase transitions. By validating our equation against well-known models such as the Michaelis-Menten and Hill equations, we prove its effectiveness in accurately representing the complexity of consumer response dynamics. The analysis emphasizes the importance of key model parameters, such as marketing effectiveness, response sensitivity, and behavioural sensitivity, in influencing consumer behaviour. The work explores the practical implications for advertisers and marketers,
    
[^2]: 大型语言模型下的多条件排序

    Multi-Conditional Ranking with Large Language Models

    [https://arxiv.org/abs/2404.00211](https://arxiv.org/abs/2404.00211)

    该论文提出了一种新颖的分解推理方法(MCRank)，用于解决大型语言模型在多条件排序任务中性能下降的问题。

    

    利用大型语言模型(LLMs)对一组项目进行排序已成为推荐和检索系统中的常见方法。在这篇论文中，我们定义并探讨了多条件排序的任务，引入了一个名为MCRank的基准，旨在评估跨不同项目类型和条件进行多条件排序。我们使用MCRank对LLMs进行分析表明，随着项目和条件数量以及复杂性的增长，性能显著下降。为了克服这一限制，我们提出了一种新颖的分解推理方法，包括提取和排序条件，然后迭代地对条件进行排序。

    arXiv:2404.00211v1 Announce Type: new  Abstract: Utilizing large language models (LLMs) to rank a set of items has become a common approach in recommendation and retrieval systems. Typically, these systems focus on ordering a substantial number of documents in a monotonic order based on a given query. However, real-world scenarios often present a different challenge: ranking a comparatively smaller set of items, but according to a variety of diverse and occasionally conflicting conditions. In this paper, we define and explore the task of multi-conditional ranking by introducing MCRank, a benchmark tailored for assessing multi-conditional ranking across various item types and conditions. Our analysis of LLMs using MCRank indicates a significant decrease in performance as the number and complexity of items and conditions grow. To overcome this limitation, we propose a novel decomposed reasoning method, consisting of EXtracting and Sorting the conditions, and then Iterativly Ranking the i
    
[^3]: 关键动作令牌在机器人学中实现上下文模仿学习

    Keypoint Action Tokens Enable In-Context Imitation Learning in Robotics

    [https://arxiv.org/abs/2403.19578](https://arxiv.org/abs/2403.19578)

    使用关键动作令牌（KAT）框架，研究展示了文本预训练的变形器（GPT-4 Turbo）在机器人领域可实现视觉模仿学习，将视觉观测映射为模拟示范者行为的动作序列，表现优越于现有的模仿学习方法。

    

    我们展示了现成的基于文本的变形器，无需额外训练，就可以执行少样本上下文内视觉模仿学习，将视觉观测映射为模拟示范者行为的动作序列。我们通过将视觉观测（输入）和动作轨迹（输出）转换为一系列令牌，这些令牌可以被文本预训练的变形器（GPT-4 Turbo）接收和生成，通过我们称之为关键动作令牌（KAT）的框架来实现这一点。尽管仅在语言上训练，我们展示这些变形器擅长将标记化的视觉关键点观察翻译为行为轨迹，在真实世界的日常任务套件中，在低数据情况下表现与优于最先进的模仿学习（扩散策略）。KAT不同于通常在语言领域操作，它利用基于文本的变形器在视觉和动作领域中学习。

    arXiv:2403.19578v1 Announce Type: cross  Abstract: We show that off-the-shelf text-based Transformers, with no additional training, can perform few-shot in-context visual imitation learning, mapping visual observations to action sequences that emulate the demonstrator's behaviour. We achieve this by transforming visual observations (inputs) and trajectories of actions (outputs) into sequences of tokens that a text-pretrained Transformer (GPT-4 Turbo) can ingest and generate, via a framework we call Keypoint Action Tokens (KAT). Despite being trained only on language, we show that these Transformers excel at translating tokenised visual keypoint observations into action trajectories, performing on par or better than state-of-the-art imitation learning (diffusion policies) in the low-data regime on a suite of real-world, everyday tasks. Rather than operating in the language domain as is typical, KAT leverages text-based Transformers to operate in the vision and action domains to learn ge
    
[^4]: 一刀切不适用：学习在文本分类中使用多少例为了改进上下文学习

    'One size doesn't fit all': Learning how many Examples to use for In-Context Learning for Improved Text Classification

    [https://arxiv.org/abs/2403.06402](https://arxiv.org/abs/2403.06402)

    本文提出了自适应上下文学习（AICL）的工作流程，通过动态调整示例数量来提高文本分类的性能，类似于k最近邻（k-NN）中的可变大小邻域。

    

    arXiv:2403.06402v1 发表类型：新 Abstract: 自然语言处理（NLP）中的预测模型已经从从头训练模型发展到使用标记数据微调预训练模型。这种微调的极端形式涉及到上下文学习（ICL），其中一个预先训练的生成模型的输出（冻结的解码器参数）只受到输入字符串的变化（称为指令或提示）的控制。ICL的一个重要组成部分是在提示中使用少量标记数据实例作为示例。尽管现有工作在推理过程中为每个数据实例使用静态数量的示例，但在本文中，我们提出了一种动态调整示例数量的新方法。这类似于k最近邻（k-NN）分类器中使用可变大小邻域的方法。在我们提出的自适应ICL（AICL）的工作流程中，对于特定数据实例进行推理时使用的演示数量是动态调整的。

    arXiv:2403.06402v1 Announce Type: new  Abstract: Predictive models in natural language processing (NLP) have evolved from training models from scratch to fine-tuning pre-trained models with labelled data. An extreme form of this fine-tuning involves in-context learning (ICL), where the output of a pre-trained generative model (frozen decoder parameters) is controlled only with variations in the input strings (called instructions or prompts). An important component of ICL is the use of a small number of labelled data instances as examples in the prompt. While existing work uses a static number of examples during inference for each data instance, in this paper we propose a novel methodology of dynamically adapting the number of examples as per the data. This is analogous to the use of a variable-sized neighborhood in k-nearest neighbors (k-NN) classifier. In our proposed workflow of adaptive ICL (AICL), the number of demonstrations to employ during the inference on a particular data inst
    
[^5]: WaterMax: 打破LLM水印可检测性-稳健性-质量的平衡

    WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off

    [https://arxiv.org/abs/2403.04808](https://arxiv.org/abs/2403.04808)

    WaterMax提出了一种新的水印方案，能够在保持生成文本质量的同时实现高检测性能，打破了水印技术中质量和稳健性之间的传统平衡。

    

    水印是阻止大型语言模型被恶意使用的技术手段。本文提出了一种称为WaterMax的新颖水印方案，具有高检测性能，同时保持原始LLM生成文本的质量。其新设计不会对LLM进行任何修改（不调整权重、对数、温度或采样技术）。WaterMax平衡了稳健性和复杂性，与文献中的水印技术相反，从根本上引发了质量和稳健性之间的平衡。其性能在理论上得到证明并经过实验证实。在最全面的基准测试套件下，它胜过所有的最先进技术。

    arXiv:2403.04808v1 Announce Type: cross  Abstract: Watermarking is a technical means to dissuade malfeasant usage of Large Language Models. This paper proposes a novel watermarking scheme, so-called WaterMax, that enjoys high detectability while sustaining the quality of the generated text of the original LLM. Its new design leaves the LLM untouched (no modification of the weights, logits, temperature, or sampling technique). WaterMax balances robustness and complexity contrary to the watermarking techniques of the literature inherently provoking a trade-off between quality and robustness. Its performance is both theoretically proven and experimentally validated. It outperforms all the SotA techniques under the most complete benchmark suite.
    
[^6]: ENOT：期望回归用于神经优化传输的快速和准确训练

    ENOT: Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport

    [https://arxiv.org/abs/2403.03777](https://arxiv.org/abs/2403.03777)

    通过期望回归正则化，本论文提出了一种新的神经优化传输（NOT）训练程序扩展，能够有效地估计最优输运方案，并使学习变得稳定。

    

    我们提出了一种新的神经优化传输（NOT）训练程序扩展，通过特定的共轭势正则化能够准确和高效地估计最优输运方案。现有NOT求解器的主要瓶颈在于找到共轭算子（即c-transform）的接近精确近似的过程，这要么通过优化最小-最大目标，要么通过计算密集型的对初始近似预测的精细调整来完成。我们通过提出一种新的、在期望回归形式上强制适应性条件于学习对偶势的理论上合理化损失来解决这两个问题。这样的正则化提供了可能共轭势分布的上限估计，并使学习变得稳定，消除了对额外广泛微调的需求。我们正式证明了我们的方法的效率。

    arXiv:2403.03777v1 Announce Type: cross  Abstract: We present a new extension for Neural Optimal Transport (NOT) training procedure, capable of accurately and efficiently estimating optimal transportation plan via specific regularisation on conjugate potentials. The main bottleneck of existing NOT solvers is associated with the procedure of finding a near-exact approximation of the conjugate operator (i.e., the c-transform), which is done either by optimizing over maximin objectives or by the computationally-intensive fine-tuning of the initial approximated prediction. We resolve both issues by proposing a new, theoretically justified loss in the form of expectile regularization that enforces binding conditions on the learning dual potentials. Such a regularization provides the upper bound estimation over the distribution of possible conjugate potentials and makes the learning stable, eliminating the need for additional extensive finetuning. We formally justify the efficiency of our me
    
[^7]: 用持久同调增强图池化

    Boosting Graph Pooling with Persistent Homology

    [https://arxiv.org/abs/2402.16346](https://arxiv.org/abs/2402.16346)

    通过PH向池化层注入全局拓扑不变性的机制显著提升了图神经网络的性能。

    

    最近，将持久同调（PH）纳入图神经网络（GNN）以丰富表达能力的趋势越来越明显。然而，简单地将PH特征插入GNN层总是带来较低可解释性的边际改进。本文研究了一种新颖的机制，通过PH向池化层注入全局拓扑不变性，灵感来自PH中的过滤操作自然地使图池化以截断方式对齐。这种方式下，粗化图中的消息传递沿着持久池化拓扑进行，从而提升性能。在实验中，我们将该机制应用于一系列图池化方法，并观察到在几个常见数据集上持续且显著的性能提升，展示了其广泛适用性和灵活性。

    arXiv:2402.16346v1 Announce Type: new  Abstract: Recently, there has been an emerging trend to integrate persistent homology (PH) into graph neural networks (GNNs) to enrich expressive power. However, naively plugging PH features into GNN layers always results in marginal improvement with low interpretability. In this paper, we investigate a novel mechanism for injecting global topological invariance into pooling layers using PH, motivated by the observation that filtration operation in PH naturally aligns graph pooling in a cut-off manner. In this fashion, message passing in the coarsened graph acts along persistent pooled topology, leading to improved performance. Experimentally, we apply our mechanism to a collection of graph pooling methods and observe consistent and substantial performance gain over several popular datasets, demonstrating its wide applicability and flexibility.
    
[^8]: 平均梯度外积作为深度神经坍塌机制的研究

    Average gradient outer product as a mechanism for deep neural collapse

    [https://arxiv.org/abs/2402.13728](https://arxiv.org/abs/2402.13728)

    本文通过提供证据表明，深度神经网络中的神经坍塌主要是通过平均梯度外积进行深度特征学习的，权重的奇异结构与AGOP高度相关，导致类内变异坍塌。

    

    Deep Neural Collapse (DNC)指的是深度神经网络(DNNs)最后几层数据表示的惊人刚性结构。尽管这种现象在各种情境中都得到了测量，但其出现只有部分被理解。本文提供了充分证据，表明DNC主要是通过平均梯度外积(AGOP)进行深度特征学习而发生的。相比于解释神经坍塌的特征不可知方法，如无约束特征模型，这一进展更进一步。我们继续提供证据表明，权重的右奇异向量和奇异值是DNN中类内变异坍塌的主要因素。正如最近的研究所示，这种奇异结构与AGOP的高度相关。然后我们在实验和理论上证明了AGOP在随机初始化的神经网络中引发神经坍塌。

    arXiv:2402.13728v1 Announce Type: new  Abstract: Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized ne
    
[^9]: 从分段三线性网络中导出多面体复合体

    Polyhedral Complex Derivation from Piecewise Trilinear Networks

    [https://arxiv.org/abs/2402.10403](https://arxiv.org/abs/2402.10403)

    本文以三线性插值方法作为位置编码，提出了理论见解和分析网格提取方法，将高维曲面转换为平面，并引入了一种近似交点的方法，拓展了更广泛的应用。

    

    最近关于深度神经网络可视化的进展揭示了它们结构的见解，并且可以从连续分段仿射（CPWA）函数中提取网格。与此同时，神经表面表示学习的发展包括非线性位置编码，解决了诸如谱偏差之类的问题；然而，这在应用基于CPWA函数的网格提取技术方面带来了挑战。我们聚焦于三线性插值方法作为位置编码，提供了理论见解和分析的网格提取，展示了在奇拿尔约束下将高维曲面转换为三线性区域内的平面的过程。此外，我们引入了一种方法来近似三个高维曲面之间的交点，从而扩展了更广泛的应用。通过汉明距离和效率以及角距离来经验性地验证正确性和简洁性，同时检查了t之间的相关性

    arXiv:2402.10403v1 Announce Type: cross  Abstract: Recent advancements in visualizing deep neural networks provide insights into their structures and mesh extraction from Continuous Piecewise Affine (CPWA) functions. Meanwhile, developments in neural surface representation learning incorporate non-linear positional encoding, addressing issues like spectral bias; however, this poses challenges in applying mesh extraction techniques based on CPWA functions. Focusing on trilinear interpolating methods as positional encoding, we present theoretical insights and an analytical mesh extraction, showing the transformation of hypersurfaces to flat planes within the trilinear region under the eikonal constraint. Moreover, we introduce a method for approximating intersecting points among three hypersurfaces contributing to broader applications. We empirically validate correctness and parsimony through chamfer distance and efficiency, and angular distance, while examining the correlation between t
    
[^10]: 计时器: 用于大规模时间序列分析的Transformer模型

    Timer: Transformers for Time Series Analysis at Scale

    [https://arxiv.org/abs/2402.02368](https://arxiv.org/abs/2402.02368)

    本文旨在早期开发大规模时间序列模型（LTSM），通过预训练和GPT风格架构，克服深度模型在小样本场景中的性能瓶颈，并实现在时间序列分析中的大样本泛化能力、可扩展性和任务普适性。

    

    深度学习在时间序列分析方面做出了显著贡献。然而，在现实世界的小样本场景中，深度模型可能遇到性能瓶颈，这可能由于当前基准测试中小模型的性能饱和而隐蔽。同时，通过大规模预训练，大模型在这些场景中展示了巨大的能力。随着大型语言模型的出现，取得了持续的进展，在少样本泛化能力、可扩展性和任务普适性方面展现了前所未有的能力，但这些能力在时间序列模型中不存在。为了改变目前在特定数据集上从头开始训练小模型的做法，本文旨在早期开发大规模时间序列模型（LTSM）。在预训练期间，我们策划了包含10亿个时间点的大规模数据集，将异构时间序列统一为单序列序列（S3）格式，并开发了面向LTSM的GPT风格架构。

    Deep learning has contributed remarkably to the advancement of time series analysis. Still, deep models can encounter performance bottlenecks in real-world small-sample scenarios, which can be concealed due to the performance saturation with small models on current benchmarks. Meanwhile, large models have demonstrated great powers in these scenarios through large-scale pre-training. Continuous progresses have been achieved as the emergence of large language models, exhibiting unprecedented ability in few-shot generalization, scalability, and task generality, which is however absent in time series models. To change the current practices of training small models on specific datasets from scratch, this paper aims at an early development of large time series models (LTSM). During pre-training, we curate large-scale datasets with up to 1 billion time points, unify heterogeneous time series into single-series sequence (S3) format, and develop the GPT-style architecture toward LTSMs. To meet 
    
[^11]: CPT: 应用于少样本节点分类的能 力递进式训练策略

    CPT: Competence-progressive Training Strategy for Few-shot Node Classification

    [https://arxiv.org/abs/2402.00450](https://arxiv.org/abs/2402.00450)

    CPT是一种新颖的两阶段课程学习方法，弥补了传统元学习方法在少样本节点分类上的困难。它使用能力递进的训练策略来提高元学习器的效果和稳定性。

    

    图神经网络（GNNs）在节点分类方面取得了显著的进展，但其成功仍然依赖于训练数据中每个类别有足够的标记节点。现实世界中的图数据通常呈现出长尾分布，标签稀疏，强调了GNN在少样本节点分类中的重要性，即使用有限的数据对节点进行分类。传统的情节元学习方法在这个领域显示出了潜力，但它们面临着固有的限制：随机和均匀任务分配可能导致模型收敛到次优解，忽视了任务的难度水平。这可能导致元学习器过早地面临复杂任务，阻碍了正常的学习。理想情况下，元学习器应该从简单概念开始，逐渐进入更复杂的概念，就像人类学习一样。因此，我们引入了CPT，一种新颖的两阶段课程学习方法，将任务难度与元学习器的递进能力相匹配，增强了元学习的效果和稳定性。

    Graph Neural Networks (GNNs) have made significant advancements in node classification, but their success relies on sufficient labeled nodes per class in the training data. Real-world graph data often exhibits a long-tail distribution with sparse labels, emphasizing the importance of GNNs' ability in few-shot node classification, which entails categorizing nodes with limited data. Traditional episodic meta-learning approaches have shown promise in this domain, but they face an inherent limitation: it might lead the model to converge to suboptimal solutions because of random and uniform task assignment, ignoring task difficulty levels. This could lead the meta-learner to face complex tasks too soon, hindering proper learning. Ideally, the meta-learner should start with simple concepts and advance to more complex ones, like human learning. So, we introduce CPT, a novel two-stage curriculum learning method that aligns task difficulty with the meta-learner's progressive competence, enhanci
    
[^12]: 基于路径的知识图谱补全的解释方法

    Path-based Explanation for Knowledge Graph Completion. (arXiv:2401.02290v1 [cs.LG])

    [http://arxiv.org/abs/2401.02290](http://arxiv.org/abs/2401.02290)

    基于路径的KGC解释器Power-Link通过引入图加权技术，实现了可解释的知识图谱补全，推动了模型透明度和可靠性的提升。

    

    近年来，图神经网络（GNNs）通过建模实体和关系的交互在知识图谱补全（KGC）任务中取得了巨大成功。然而，对预测结果的解释却没有得到必要的关注。对基于GNN的KGC模型结果进行适当解释，可以增加模型的透明度，并帮助研究人员开发更可靠的模型。现有的KGC解释方法主要依赖于实例/子图的方法，而在某些场景下，路径可以提供更友好和可解释的解释。然而，还没有对生成基于路径的知识图谱解释方法进行充分探索。为了填补这一空白，我们提出了Power-Link，这是第一个探索基于路径的KGC解释器。我们设计了一种新颖的图加权技术，使得可以以完全可并行化和内存高效的训练方案生成基于路径的解释。我们还引入了三个新的度量指标，用于评估解释的质量和有效性。

    Graph Neural Networks (GNNs) have achieved great success in Knowledge Graph Completion (KGC) by modelling how entities and relations interact in recent years. However, the explanation of the predicted facts has not caught the necessary attention. Proper explanations for the results of GNN-based KGC models increase model transparency and help researchers develop more reliable models. Existing practices for explaining KGC tasks rely on instance/subgraph-based approaches, while in some scenarios, paths can provide more user-friendly and interpretable explanations. Nonetheless, the methods for generating path-based explanations for KGs have not been well-explored. To address this gap, we propose Power-Link, the first path-based KGC explainer that explores GNN-based models. We design a novel simplified graph-powering technique, which enables the generation of path-based explanations with a fully parallelisable and memory-efficient training scheme. We further introduce three new metrics for 
    
[^13]: FedSN：一个适用于LEO卫星网络的通用联邦学习框架

    FedSN: A General Federated Learning Framework over LEO Satellite Networks. (arXiv:2311.01483v1 [cs.LG])

    [http://arxiv.org/abs/2311.01483](http://arxiv.org/abs/2311.01483)

    FedSN是一个通用的联邦学习框架，用于解决在LEO卫星网络中的异构计算和存储能力、有限的上行速率以及模型陈旧等关键挑战。

    

    最近，许多低地球轨道（LEO）卫星已经由商业公司成功地发射和部署到太空中，如SpaceX。由于LEO卫星配备了多模传感器，它们不仅用于通信，还用于各种机器学习应用，如空间调制识别、遥感图像分类等。然而，由于与LEO卫星的有限接触时间（例如5分钟），地面站（GS）可能无法下载如此大量的原始感测数据进行集中模型训练。因此，联邦学习（FL）已经成为解决这个问题的有希望的解决方案，通过在设备上进行训练。不幸的是，要在LEO卫星上使用FL，我们仍然面临三个关键挑战，即i）异构计算和存储能力，ii）有限的上行速率，以及iii）模型陈旧问题。为此，我们提出了一种名为FedSN的通用FL框架来解决上述挑战，一

    Recently, a large number of Low Earth Orbit (LEO) satellites have been launched and deployed successfully in space by commercial companies, such as SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve not only for communication but also for various machine learning applications, such as space modulation recognition, remote sensing image classification, etc. However, the ground station (GS) may be incapable of downloading such a large volume of raw sensing data for centralized model training due to the limited contact time with LEO satellites (e.g. 5 minutes). Therefore, federated learning (FL) has emerged as the promising solution to address this problem via on-device training. Unfortunately, to enable FL on LEO satellites, we still face three critical challenges that are i) heterogeneous computing and memory capabilities, ii) limited uplink rate, and iii) model staleness. To this end, we propose FedSN as a general FL framework to tackle the above challenges, an
    
[^14]: 使用大型语言模型进行实体匹配

    Entity Matching using Large Language Models. (arXiv:2310.11244v1 [cs.CL])

    [http://arxiv.org/abs/2310.11244](http://arxiv.org/abs/2310.11244)

    这项研究探讨了使用大型语言模型（LLMs）作为实体匹配的替代方法，相较于预训练的语言模型（PLMs），LLMs对训练数据需求较少且更具鲁棒性。

    

    实体匹配是判断两个实体描述是否指的是同一个真实世界实体的任务。实体匹配是大多数数据集成流程中的核心步骤，也是许多电子商务应用的重要组成部分，这些应用需要将来自不同供应商的产品匹配起来。目前最先进的实体匹配方法通常依赖于预训练的语言模型（PLMs），如BERT或RoBERTa。然而，这些模型在实体匹配中存在两个主要缺点：（i）模型需要大量特定任务的训练数据；（ii）微调后的模型对于超出分布范围的实体不够健壮。本文研究了使用大型语言模型（LLMs）作为基于PLMs的匹配器的备选方案，相比之下，LLMs对领域特定训练数据需求较少且更具鲁棒性。我们的研究涵盖了托管的LLMs，如GPT3.5和GPT4，以及基于Llama2的开源LLMs，可以在本地运行。我们在零样本场景和…

    Entity Matching is the task of deciding whether two entity descriptions refer to the same real-world entity. Entity Matching is a central step in most data integration pipelines and an enabler for many e-commerce applications which require to match products offers from different vendors. State-of-the-art entity matching methods often rely on pre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks of these models for entity matching are that (i) the models require significant amounts of task-specific training data and (ii) the fine-tuned models are not robust concerning out-of-distribution entities. In this paper, we investigate using large language models (LLMs) for entity matching as a less domain-specific training data reliant and more robust alternative to PLM-based matchers. Our study covers hosted LLMs, such as GPT3.5 and GPT4, as well as open source LLMs based on Llama2 which can be run locally. We evaluate these models in a zero-shot scenario as well as a
    
[^15]: 插拔式后验采样在不匹配测量和先验模型下的应用

    Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])

    [http://arxiv.org/abs/2310.03546](http://arxiv.org/abs/2310.03546)

    本研究提出了一种插拔式后验采样算法（PnP-ULA），通过将物理测量模型与深度学习先验相结合，解决了成像逆问题。我们通过理论分析和数值验证，量化了PnP-ULA在不匹配后验分布下的误差界限，结果表明PnP-ULA对于测量模型和去噪器的不匹配非常敏感。

    

    后验采样已被证明是解决成像逆问题的强大贝叶斯方法。最近发展起来的插拔式未调整朗之万算法（PnP-ULA）通过将物理测量模型与使用图像去噪器指定的深度学习先验相结合，成为一种有前景的蒙特卡洛采样和最小均方误差（MMSE）估计方法。然而，PnP-ULA的采样分布与不匹配的数据保真度和去噪器之间的复杂关系尚未经过理论分析。我们通过提出一种后验-L2拟度量并利用它来量化PnP-ULA在不匹配的后验分布下的显式误差界限来填补这一空白。我们在多个逆问题上对我们的理论进行了数值验证，如从高斯混合模型和图像去模糊中采样。我们的结果表明，PnP-ULA的采样分布对于测量模型和去噪器的不匹配非常敏感，并可以精确地描述其特征。

    Posterior sampling has been shown to be a powerful Bayesian approach for solving imaging inverse problems. The recent plug-and-play unadjusted Langevin algorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling and minimum mean squared error (MMSE) estimation by combining physical measurement models with deep-learning priors specified using image denoisers. However, the intricate relationship between the sampling distribution of PnP-ULA and the mismatched data-fidelity and denoiser has not been theoretically analyzed. We address this gap by proposing a posterior-L2 pseudometric and using it to quantify an explicit error bound for PnP-ULA under mismatched posterior distribution. We numerically validate our theory on several inverse problems such as sampling from Gaussian mixture models and image deblurring. Our results suggest that the sensitivity of the sampling distribution of PnP-ULA to a mismatch in the measurement model and the denoiser can be precisely characte
    
[^16]: 通过隐式点图网络高效解剖标记肺部树状结构

    Efficient Anatomical labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks. (arXiv:2309.17329v1 [cs.CV])

    [http://arxiv.org/abs/2309.17329](http://arxiv.org/abs/2309.17329)

    本文介绍了一种通过隐式点图网络高效解剖标记肺部树状结构的方法，提供了SOTA准确度和可用的表面，同时还提供了一个用于评估该方法的数据集。

    

    肺部疾病在全球范围内是导致死亡的主要原因之一。治愈肺部疾病需要更好地理解肺部系统内的许多复杂的3D树状结构，如气道、动脉和静脉。在理论上，它们可以通过高分辨率图像堆栈进行建模。然而，基于密集体素网格的标准CNN方法代价过高。为了解决这个问题，我们引入了一种基于点的方法，保留了树骨架的图连通性，并结合了隐式表面表示。它以较低的计算成本提供了SOTA准确度，生成的模型具有可用的表面。由于公开可访问的数据稀缺，我们还整理了一套广泛的数据集来评估我们的方法，并将其公开。

    Pulmonary diseases rank prominently among the principal causes of death worldwide. Curing them will require, among other things, a better understanding of the many complex 3D tree-shaped structures within the pulmonary system, such as airways, arteries, and veins. In theory, they can be modeled using high-resolution image stacks. Unfortunately, standard CNN approaches operating on dense voxel grids are prohibitively expensive. To remedy this, we introduce a point-based approach that preserves graph connectivity of tree skeleton and incorporates an implicit surface representation. It delivers SOTA accuracy at a low computational cost and the resulting models have usable surfaces. Due to the scarcity of publicly accessible data, we have also curated an extensive dataset to evaluate our approach and will make it public.
    
[^17]: 在网络中学习增强的分布式在线凸优化

    Learning-Augmented Decentralized Online Convex Optimization in Networks. (arXiv:2306.10158v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10158](http://arxiv.org/abs/2306.10158)

    本论文研究了网络中的分布式在线凸优化问题，并提出了一种新的学习增强的分布式在线优化算法（LADO），该算法使个体智能体能够基于本地信息选择行动。与现有的算法不同，LADO在分布式设置中实现了强鲁棒性保证，并通过考虑鲁棒性要求来训练机器学习策略。此外，我们还证明了LADO算法的平均成本界限，揭示了平均性能和最坏情况鲁棒性之间的折衷。

    

    本文研究了网络化多智能体系统中的分布式在线凸优化，并提出了一种新的算法，即学习增强的分布式在线优化（LADO），用于使个体智能体仅基于本地在线信息选择行动。LADO利用基线策略来保障最坏情况下的鲁棒性保证，同时保持接近于机器学习（ML）策略以提高平均性能。与现有的学习增强在线算法不同，这些算法关注的是集中式设置，LADO在分布式设置中实现了强鲁棒性保证。我们还证明了LADO的平均成本界限，揭示了平均性能和最坏情况鲁棒性之间的折衷，证明了通过明确考虑鲁棒性要求来训练ML策略的优势。

    This paper studies decentralized online convex optimization in a networked multi-agent system and proposes a novel algorithm, Learning-Augmented Decentralized Online optimization (LADO), for individual agents to select actions only based on local online information. LADO leverages a baseline policy to safeguard online actions for worst-case robustness guarantees, while staying close to the machine learning (ML) policy for average performance improvement. In stark contrast with the existing learning-augmented online algorithms that focus on centralized settings, LADO achieves strong robustness guarantees in a decentralized setting. We also prove the average cost bound for LADO, revealing the tradeoff between average performance and worst-case robustness and demonstrating the advantage of training the ML policy by explicitly considering the robustness requirement.
    
[^18]: 分散式学习动力学中个体群体的力量

    The Power of Populations in Decentralized Learning Dynamics. (arXiv:2306.08670v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.08670](http://arxiv.org/abs/2306.08670)

    本文研究了分散式学习动力学中个体群体的力量。我们介绍了一种分散式的多臂赌博机设置，并分析了几个针对此任务的分散式动力学家族。我们展示了这些动力学与一类“零和”乘法权重更新算法的联系，并开发了一个通用框架来分析这些协议的群体级遗憾。在广泛的参数范围下，我们得到了次线性的遗憾界限。

    

    我们研究了一种分散式多臂赌博机设置，在一个由$n$个受内存限制的节点组成的种群中，采用了谣言模型：每轮，每个节点本地采用$m$个臂之一，观察从臂的（对抗选择的）分布中抽取的奖励，然后与随机抽取的邻居进行通信，交换信息，以确定下一轮的策略。我们介绍并分析了几个针对此任务的分散式动力学家族：每个节点的决策完全是局部的，只依赖于其最新获得的奖励以及它抽样的邻居的奖励。我们展示了这些分散式动力学的全局演化与特定类型的“零和”乘法权重更新算法之间的联系，并且开发了一个分析这些自然协议的群体级遗憾的通用框架。利用这个框架，我们在广泛的参数范围（即，种群的大小和nu的大小）下推导了次线性遗憾界限。

    We study a distributed multi-armed bandit setting among a population of $n$ memory-constrained nodes in the gossip model: at each round, every node locally adopts one of $m$ arms, observes a reward drawn from the arm's (adversarially chosen) distribution, and then communicates with a randomly sampled neighbor, exchanging information to determine its policy in the next round. We introduce and analyze several families of dynamics for this task that are decentralized: each node's decision is entirely local and depends only on its most recently obtained reward and that of the neighbor it sampled. We show a connection between the global evolution of these decentralized dynamics with a certain class of "zero-sum" multiplicative weights update algorithms, and we develop a general framework for analyzing the population-level regret of these natural protocols. Using this framework, we derive sublinear regret bounds under a wide range of parameter regimes (i.e., the size of the population and nu
    
[^19]: FLEdge：边缘计算系统中联邦机器学习应用的基准测试

    FLEdge: Benchmarking Federated Machine Learning Applications in Edge Computing Systems. (arXiv:2306.05172v1 [cs.LG])

    [http://arxiv.org/abs/2306.05172](http://arxiv.org/abs/2306.05172)

    FLEdge是一个面向边缘计算系统中FL工作量的基准测试，通过研究硬件异构性、能量效率和隐私级别对FL系统训练的影响，以及客户端退出对最新FL策略的影响，提供了训练最先进的FL工作负载的新见解。

    

    近年来，联邦机器学习（FL）备受关注。 FL基准测试主要在模拟系统或数据中心环境中进行探索，忽略了与边缘计算密切相关的实际系统设置。 我们通过引入面向边缘计算系统中FL工作量的基准测试FLEdge来弥补这一研究差距。我们系统地研究了硬件异构性、训练过程中的能量效率以及各种不同隐私级别对FL系统训练的影响。为了使这个基准测试适用于实际场景，我们评估了客户端退出对具有高达50％失效率的最新FL策略的影响。 FLEdge提供了新的见解，例如，在旧GPU加速的嵌入式设备上训练最先进的FL工作负载比在现代服务器级GPU上训练高达3倍的能量效率。

    Federated Machine Learning (FL) has received considerable attention in recent years. FL benchmarks are predominantly explored in either simulated systems or data center environments, neglecting the setups of real-world systems, which are often closely linked to edge computing. We close this research gap by introducing FLEdge, a benchmark targeting FL workloads in edge computing systems. We systematically study hardware heterogeneity, energy efficiency during training, and the effect of various differential privacy levels on training in FL systems. To make this benchmark applicable to real-world scenarios, we evaluate the impact of client dropouts on state-of-the-art FL strategies with failure rates as high as 50%. FLEdge provides new insights, such as that training state-of-the-art FL workloads on older GPU-accelerated embedded devices is up to 3x more energy efficient than on modern server-grade GPUs.
    
[^20]: 有界KRnet及其在密度估计和近似中的应用

    Bounded KRnet and its applications to density estimation and approximation. (arXiv:2305.09063v1 [cs.LG])

    [http://arxiv.org/abs/2305.09063](http://arxiv.org/abs/2305.09063)

    本文介绍了一种新的可逆映射B-KRnet，并将其应用于数据或PDE的密度估计/近似，由于其定义在有界域上，因此比KRnet更有效。

    

    本文在有界域上开发了一种可逆映射，称为B-KRnet，并将其应用于数据或PDE（例如福克-普朗克方程和Keller-Segel方程）的密度估计/近似。与KRnet类似，B-KRnet的结构将Knothe-Rosenblatt重排的三角形形式转化为归一化流模型。B-KRnet和KRnet之间的主要区别是B-KRnet定义在超立方体上，而KRnet定义在整个空间上，换句话说，我们在B-KRnet中引入了一种新的机制来保持精确的可逆性。将B-KRnet用作传输映射，我们获得了一个明确的概率密度函数（PDF）模型，该模型对应于先验（均匀）分布在超立方体上的推移。为了近似计算域上定义的PDF，B-KRnet比KRnet更有效。通过耦合KRnet和B-KRnet，我们还可以在高维域上定义一个深度生成模型。

    In this paper, we develop an invertible mapping, called B-KRnet, on a bounded domain and apply it to density estimation/approximation for data or the solutions of PDEs such as the Fokker-Planck equation and the Keller-Segel equation. Similar to KRnet, the structure of B-KRnet adapts the triangular form of the Knothe-Rosenblatt rearrangement into a normalizing flow model. The main difference between B-KRnet and KRnet is that B-KRnet is defined on a hypercube while KRnet is defined on the whole space, in other words, we introduce a new mechanism in B-KRnet to maintain the exact invertibility. Using B-KRnet as a transport map, we obtain an explicit probability density function (PDF) model that corresponds to the pushforward of a prior (uniform) distribution on the hypercube. To approximate PDFs defined on a bounded computational domain, B-KRnet is more effective than KRnet. By coupling KRnet and B-KRnet, we can also define a deep generative model on a high-dimensional domain where some di
    
[^21]: SIA-FTP: 一种语音指令感知的飞行轨迹预测框架

    SIA-FTP: A Spoken Instruction Aware Flight Trajectory Prediction Framework. (arXiv:2305.01661v1 [cs.SD])

    [http://arxiv.org/abs/2305.01661](http://arxiv.org/abs/2305.01661)

    提出一种语音指令感知的飞行轨迹预测框架，通过融合即时的语音指令和飞行轨迹表示，解决了语音指令和飞行轨迹的模态差距问题，在多个真实世界数据集上表现优异。

    

    通过语音通讯进行地空协商是确保空中交通管制（ATC）操作安全和效率的重要前提。但是，随着交通流量的增加，由于人为因素导致的错误指令给ATC安全带来了巨大威胁。现有的飞行轨迹预测（FTP）方法主要依赖于历史轨迹的飞行状态，在实时机动指令的预测上会出现显著的延迟，这不利于冲突检测。本文提出了一种名为SIA-FTP的语音指令感知FTP框架，通过包含即时的语音指令来支持高机动FTP任务。为了解决模态差距并最小化数据需求，我们提出了一种联合注意机制来融合语音指令嵌入和飞行轨迹表示。在多个真实世界数据集上评估了所提出的SIA-FTP，与现有的FTP方法相比取得了显著的改进。

    Ground-air negotiation via speech communication is a vital prerequisite for ensuring safety and efficiency in air traffic control (ATC) operations. However, with the increase in traffic flow, incorrect instructions caused by human factors bring a great threat to ATC safety. Existing flight trajectory prediction (FTP) approaches primarily rely on the flight status of historical trajectory, leading to significant delays in the prediction of real-time maneuvering instruction, which is not conducive to conflict detection. A major reason is that spoken instructions and flight trajectories are presented in different modalities in the current air traffic control (ATC) system, bringing great challenges to considering the maneuvering instruction in the FTP tasks. In this paper, a spoken instruction-aware FTP framework, called SIA-FTP, is innovatively proposed to support high-maneuvering FTP tasks by incorporating instant spoken instruction. To address the modality gap and minimize the data requ
    
[^22]: 等变增强神经网络的优化动态

    Optimization Dynamics of Equivariant and Augmented Neural Networks. (arXiv:2303.13458v1 [cs.LG])

    [http://arxiv.org/abs/2303.13458](http://arxiv.org/abs/2303.13458)

    本论文研究了在对称数据上优化多层感知机的方法，比较了等变和增强两种策略的优缺点，证明了在自然假设下等变稳定点的集合和等变层的集合具有不变性，但增强模型的稳定点可能是不稳定的。

    

    我们研究了在对称数据上优化多层感知机的方法。我们比较了限制架构等变和使用增强的策略。我们证明，在对损失和非线性性进行自然假设的情况下，等变稳定点的集合对于这两种策略是相同的，并且等变层的集合在增强模型的梯度流下是不变的。最后，我们表明，尽管等变模型的稳定点是稳定的，增强训练的稳定点可能是不稳定的。

    We investigate the optimization of multilayer perceptrons on symmetric data. We compare the strategy of constraining the architecture to be equivariant to that of using augmentation. We show that, under natural assumptions on the loss and non-linearities, the sets of equivariant stationary points are identical for the two strategies, and that the set of equivariant layers is invariant under the gradient flow for augmented models. Finally, we show that stationary points may be unstable for augmented training although they are stable for the equivariant models
    
[^23]: 针对可扩展性的子图表示学习简化以进行可扩展的链接预测

    Simplifying Subgraph Representation Learning for Scalable Link Prediction. (arXiv:2301.12562v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12562](http://arxiv.org/abs/2301.12562)

    提出了一种新的可扩展简化子图表示学习（S3GRL）框架，通过简化每个链接子图中的消息传递和聚合操作实现更快的训练和推理，并可适应各种子图采样策略和扩散操作符以模拟计算代价高的子图表示学习。大量实验证明了S3GRL模型可以扩展SGRL而不会显著降低性能。

    

    图上的链接预测是一个基本问题。子图表示学习方法通过将链接预测转化为在链接周围子图上的图分类来实现了最先进的链接预测。然而，子图表示学习方法计算代价高，并且由于子图水平操作的代价而不适用于大规模图形。我们提出了一种新的子图表示学习类，称为可扩展简化子图表示学习（S3GRL），旨在实现更快的训练和推理。S3GRL简化了每个链接子图中的消息传递和聚合操作。作为可扩展性框架，S3GRL适应各种子图采样策略和扩散运算符来模拟计算代价高的子图表示学习方法。我们提出了多个S3GRL实例，并在小到大规模的图形上进行了实证研究。我们广泛的实验表明，所提出的S3GRL模型可以扩展SGRL而不会显著降低性能。

    Link prediction on graphs is a fundamental problem. Subgraph representation learning approaches (SGRLs), by transforming link prediction to graph classification on the subgraphs around the links, have achieved state-of-the-art performance in link prediction. However, SGRLs are computationally expensive, and not scalable to large-scale graphs due to expensive subgraph-level operations. To unlock the scalability of SGRLs, we propose a new class of SGRLs, that we call Scalable Simplified SGRL (S3GRL). Aimed at faster training and inference, S3GRL simplifies the message passing and aggregation operations in each link's subgraph. S3GRL, as a scalability framework, accommodates various subgraph sampling strategies and diffusion operators to emulate computationally-expensive SGRLs. We propose multiple instances of S3GRL and empirically study them on small to large-scale graphs. Our extensive experiments demonstrate that the proposed S3GRL models scale up SGRLs without significant performance 
    

