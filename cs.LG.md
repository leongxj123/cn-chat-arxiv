# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Deep Reinforcement Learning for Traveling Purchaser Problems](https://arxiv.org/abs/2404.02476) | 提出了一种基于深度强化学习的方法，该方法分别解决了旅行购买者问题中的路由构建和购买规划问题，并从全局角度评估和优化解决方案。 |
| [^2] | [Stochastic Gradient Langevin Unlearning](https://arxiv.org/abs/2403.17105) | 本工作提出了随机梯度 Langevin 反遗忘方法，为近似反遗忘问题提供了隐私保障，并展示了小批次梯度更新相较于全批次的优越性能。 |
| [^3] | [CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing](https://arxiv.org/abs/2403.13583) | CONLINE框架提出了通过在线搜索和正确性测试来增强复杂代码生成的方法，通过实验证明了其显著提高了代码生成质量。 |
| [^4] | [The Value of Reward Lookahead in Reinforcement Learning](https://arxiv.org/abs/2403.11637) | 分析了在强化学习中利用部分未来奖励先知的价值，通过竞争性分析得出了最坏情况下奖励期望的精确比率。 |
| [^5] | [A Scalable and Parallelizable Digital Twin Framework for Sustainable Sim2Real Transition of Multi-Agent Reinforcement Learning Systems](https://arxiv.org/abs/2403.10996) | 提出了一个可持续的多智能体深度强化学习框架，利用分散的学习架构，来解决交通路口穿越和自主赛车等问题 |
| [^6] | [Hyperparameters in Continual Learning: a Reality Check](https://arxiv.org/abs/2403.09066) | 超参数对于连续学习的重要性被强调，提出了一个涉及超参数调整和评估阶段的评估协议。 |
| [^7] | [FogGuard: guarding YOLO against fog using perceptual loss](https://arxiv.org/abs/2403.08939) | FogGuard提出了一种针对雾天气条件挑战的新型雾感知目标检测网络，通过微调数据收集的方法来提高目标检测算法在恶劣天气条件下的可靠性。 |
| [^8] | [The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels](https://arxiv.org/abs/2403.07735) | HSIC估计的极小化率对平移不变核的独立性度量具有重要意义 |
| [^9] | [Hybrid Quantum-inspired Resnet and Densenet for Pattern Recognition with Completeness Analysis](https://arxiv.org/abs/2403.05754) | 提出了两种根植于残差连接和密集连接的混合量子启发式神经网络，用于更全面地改进和评估新型神经网络在复杂和不可预测环境中的表现 |
| [^10] | [Twisting Lids Off with Two Hands](https://arxiv.org/abs/2403.02338) | 深度强化学习结合仿真到真实世界的转移为解决物体操纵问题提供了有力支持 |
| [^11] | [Large-scale variational Gaussian state-space models](https://arxiv.org/abs/2403.01371) | 该论文介绍了一种针对具有高斯噪声驱动非线性动力学的状态空间模型的大规模变分算法和结构化逼近方法，可以有效评估ELBO和获取低方差的随机梯度估计，通过利用低秩蒙特卡罗逼近和推断网络的精度矩阵更新，将近似平滑问题转化为近似滤波问题。 |
| [^12] | [Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes](https://arxiv.org/abs/2402.18477) | 本文在随机过程中开发了一种基于签名核的条件独立性测试，实现了对因果关系的推断，以及开发了约束条件的因果发现算法用于恢复整个有向图。 |
| [^13] | [Two-scale Neural Networks for Partial Differential Equations with Small Parameters](https://arxiv.org/abs/2402.17232) | 提出了一种用双尺度神经网络方法解决具有小参数的偏微分方程的方法，能够直接将小参数纳入神经网络架构中，从而简化解决过程，并能够合理准确地捕捉由小参数引起的解中大导数特征。 |
| [^14] | [Improve Robustness of Eye Disease Detection by including Learnable Probabilistic Discrete Latent Variables into Machine Learning Models](https://arxiv.org/abs/2402.16865) | 通过引入可学习的概率离散潜变量，该研究提出了一种新颖的眼部疾病检测方法，利用生成流网络来学习眼底图像中眼部疾病的后验分布，提高了鲁棒性和泛化能力。 |
| [^15] | [Building Flexible Machine Learning Models for Scientific Computing at Scale](https://arxiv.org/abs/2402.16014) | OmniArch通过多物理学时空数据处理、可扩展的自回归任务和物理信息增强学习技术，在科学计算领域构建灵活的基础模型，并在性能、适应性和逆问题求解方面取得突破，展现了AI对科学计算的潜力。 |
| [^16] | [Convergence Analysis of Split Federated Learning on Heterogeneous Data](https://arxiv.org/abs/2402.15166) | 本文填补了分裂联邦学习在各异数据上收敛分析的空白，提供了针对强凸和一般凸目标的SFL收敛分析，收敛速率分别为$O(1/T)$和$O(1/\sqrt[3]{T})。 |
| [^17] | [Geometry-Informed Neural Networks](https://arxiv.org/abs/2402.14009) | GINNs提出了一种新颖的几何信息神经网络范式，可以在几何任务中生成多样的解决方案，无需训练数据，采用显式多样性损失以及可微损失来减轻模态坍缩，并在实验中展示了其在各种复杂性场景中的高效性。 |
| [^18] | [CodaMal: Contrastive Domain Adaptation for Malaria Detection in Low-Cost Microscopes](https://arxiv.org/abs/2402.10478) | 提出了CodaMal框架，实现了低成本显微镜下疟疾检测的对比域自适应，解决了HCM和LCM图像之间的域差异问题 |
| [^19] | [BitDelta: Your Fine-Tune May Only Be Worth One Bit](https://arxiv.org/abs/2402.10193) | BitDelta研究探讨了大型语言模型在微调过程中的信息冗余性，并提出了一种名为BitDelta的方法，可以将微调过程中添加的信息量化为一个比特，同时保持性能。这一发现对于多租户模型的服务和存储有重要意义，并可以显著降低GPU内存需求。 |
| [^20] | [Short-Form Videos and Mental Health: A Knowledge-Guided Multimodal Neural Topic Model](https://arxiv.org/abs/2402.10045) | 这项研究针对短视频对观众心理健康的抑郁影响问题，开发了一种基于医学知识的多模态神经主题模型，以预测其影响并采取相应的干预措施。 |
| [^21] | [Regret Minimization in Stackelberg Games with Side Information](https://arxiv.org/abs/2402.08576) | 这篇论文研究了侧信息中的Stackelberg博弈，提出了一种方法来解决现实中玩家之间信息交流不充分的情况，并且证明了在这种情况下后悔最小化是有效的。 |
| [^22] | [Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models](https://arxiv.org/abs/2402.06659) | Shadowcast是一种隐秘的数据污染攻击方法，可以通过伪装成良性图像和匹配文本来操纵视觉语言模型的响应。它包括标签攻击和说服攻击，可以混淆类别标签并编写有说服力的描述。使用仅50个毒样本，Shadowcast能够高效实现攻击者的意图。 |
| [^23] | [Efficient Stagewise Pretraining via Progressive Subnetworks](https://arxiv.org/abs/2402.05913) | 通过渐进子网络训练，该方法实现了高效的分阶段预训练，避免了早期阶段无法评估完整模型和模型质量下降等问题。 |
| [^24] | [Understanding and Guiding Weakly Supervised Entity Alignment with Potential Isomorphism Propagation](https://arxiv.org/abs/2402.03025) | 本文通过传播视角分析了弱监督的实体对齐任务，并提出一种潜在同构传播操作符来增强知识图谱之间的邻域信息传播。通过验证，发现基于聚合的实体对齐模型中的潜在对齐实体具有同构子图。 |
| [^25] | [AutoTimes: Autoregressive Time Series Forecasters via Large Language Models](https://arxiv.org/abs/2402.02370) | AutoTimes是一种基于大型语言模型的自回归时间序列预测器，利用语言模型的转换能力来处理时间序列数据，实现了与先前模型相当的性能。 |
| [^26] | [Large Language Model Evaluation via Matrix Entropy](https://arxiv.org/abs/2401.17139) | 本文引入了矩阵熵，一种基于信息论和几何原理的新型指标，用于评估大型语言模型（LLMs）的数据压缩能力。该指标反映了模型提取相关信息和消除不必要元素的能力，为评估语言模型的固有能力提供了洞察。在单模态和多模态设置中都展示了其适用性。 |
| [^27] | [Prompt Weight Experiments for LLM Instruction Fine-Tuning.](http://arxiv.org/abs/2401.13586) | LLM指令微调中，对于短提示完成数据集，提示词标记分类损失加权（PLW）与性能呈负二次关系，而长提示完成数据集则不受PLW影响。 |
| [^28] | [Contractive Diffusion Probabilistic Models.](http://arxiv.org/abs/2401.13115) | 收缩扩散概率模型（CDPMs）是一种新颖的生成建模技术，通过收缩后向采样并克服分数匹配误差和离散化误差的问题，提高了模型的鲁棒性。实验证明收缩子方差保持（sub-VP）是表现最佳的一种CDPMs。 |
| [^29] | [Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning.](http://arxiv.org/abs/2401.10371) | Langevin遗忘是一种基于噪声梯度下降的遗忘框架，能够在近似遗忘问题中提供隐私保证，并且具有算法上的优势。 |
| [^30] | [Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems.](http://arxiv.org/abs/2401.04408) | 本文提出了一种细粒度嵌入维度优化方法（FIITED），能够在推荐系统的训练过程中根据嵌入向量的重要性不断调整其维度，并设计了一种虚拟哈希索引哈希表的嵌入存储系统以有效节省内存。 |
| [^31] | [An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training.](http://arxiv.org/abs/2312.11819) | 提出了一种自适应模型部署和并行框架，用于加速RLHF训练。该框架提供了两种灵活的模型部署策略，其中交替策略有助于减少内存冗余和通信成本。 |
| [^32] | [Identifiable Latent Polynomial Causal Models Through the Lens of Change.](http://arxiv.org/abs/2310.15580) | 本文通过扩展潜在因果模型的范围，从线性高斯模型转化为多项式模型，并研究了部分参数保持不变时的部分识别性结果。 |
| [^33] | [On the Optimization and Generalization of Multi-head Attention.](http://arxiv.org/abs/2310.12680) | 本论文研究了使用多头注意力在优化和泛化方面的优势，推导了单层多头自注意力模型的梯度下降训练的收敛性和泛化保证，并证明了对于一个简单的分词混合模型，初始化条件满足可实现性条件。 |
| [^34] | [What is a good question? Task-oriented asking with fact-level masking.](http://arxiv.org/abs/2310.11571) | 本论文提出了基于任务的询问（TOA）的概念和框架，介绍了一种用于生成对推理任务有用答案的问题的方法。同时还提出了一种事实级遮蔽（FLM）的技术，用于将自然语言数据集转换为自我监督的TOA数据集。 |
| [^35] | [EHI: End-to-end Learning of Hierarchical Index for Efficient Dense Retrieval.](http://arxiv.org/abs/2310.08891) | EHI是一种端到端学习的层次索引方法，用于高效密集检索。它同时学习嵌入和ANNS结构，通过使用密集路径嵌入来捕获索引的语义信息，以优化检索性能。 |
| [^36] | [Which mode is better for federated learning? Centralized or Decentralized.](http://arxiv.org/abs/2310.03461) | 中国总结出的一句话要点：研究发现在联合学习中，集中化的方法总是比分散化的方法更好地进行泛化，同时，部分参与在集中化方法中表现更好，而在分散化方法中，拓扑结构对性能的影响十分重要。 |
| [^37] | [Robust Stochastic Optimization via Gradient Quantile Clipping.](http://arxiv.org/abs/2309.17316) | 本文介绍了一种基于梯度分位数剪切的鲁棒性随机优化策略，适用于光滑目标且能容忍异常值和尾重样本。对于强凸目标，迭代收敛到集中分布并导出了估计误差的概率界。在非凸情况下，极限分布局部化在低梯度邻域上。使用滚动分位数实现的算法具有很强的鲁棒性和高效性。 |
| [^38] | [AR-TTA: A Simple Method for Real-World Continual Test-Time Adaptation.](http://arxiv.org/abs/2309.10109) | AR-TTA提出了一种简单的方法用于真实世界连续测试时间自适应。通过将内存缓冲区纳入自训练框架，并根据数据流的强度进行动态适应，提高了模型的稳定性。 |
| [^39] | [Simultaneous inference for generalized linear models with unmeasured confounders.](http://arxiv.org/abs/2309.07261) | 本文研究了存在混淆效应时的广义线性模型的大规模假设检验问题，并提出了一种利用正交结构和线性投影的统计估计和推断框架，解决了由于未测混淆因素引起的偏差问题。 |
| [^40] | [Speciality vs Generality: An Empirical Study on Catastrophic Forgetting in Fine-tuning Foundation Models.](http://arxiv.org/abs/2309.06256) | 本研究实证了基础模型微调中的灾难性遗忘现象，微调过程中追求专业性会导致模型的广泛性损失。 |
| [^41] | [Pure Message Passing Can Estimate Common Neighbor for Link Prediction.](http://arxiv.org/abs/2309.00976) | 这篇论文提出了一种纯粹的消息传递方法，用于估计共同邻居进行链路预测。该方法通过利用输入向量的正交性来捕捉联合结构特征，提出了一种新的链路预测模型MPLP，该模型利用准正交向量估计链路级结构特征，同时保留了节点级复杂性。 |
| [^42] | [Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning.](http://arxiv.org/abs/2308.09883) | Flamingo是一个用于实现跨大量客户端安全聚合的系统，在私有联邦学习中有广泛的应用。通过消除每轮设置和引入轻量级的丢失容忍协议，Flamingo解决了以往协议在多轮设置下的问题，并引入了新的本地选择客户端邻域的方式。 |
| [^43] | [Active Inverse Learning in Stackelberg Trajectory Games.](http://arxiv.org/abs/2308.08017) | 这项研究提出了一种在Stackelberg博弈中的主动逆向学习方法，通过活跃地最大化跟随者在不同假设下的轨迹差异来加速领导者的推断过程。 |
| [^44] | [Meta-Learning Operators to Optimality from Multi-Task Non-IID Data.](http://arxiv.org/abs/2308.04428) | 本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。 |
| [^45] | [Training Data Protection with Compositional Diffusion Models.](http://arxiv.org/abs/2308.01937) | 使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。 |
| [^46] | [Weighted variation spaces and approximation by shallow ReLU networks.](http://arxiv.org/abs/2307.15772) | 本文研究了在有界域上通过单隐藏层ReLU网络逼近函数的问题，介绍了新的模型类定义加权变差空间，该定义与域本身相关。 |
| [^47] | [Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization.](http://arxiv.org/abs/2307.10053) | 本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。 |
| [^48] | [Loss Functions and Metrics in Deep Learning. A Review.](http://arxiv.org/abs/2307.02694) | 本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。 |
| [^49] | [DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability.](http://arxiv.org/abs/2306.13196) | 本文提出了一种使用扩散模型作为采样器的任务和动作规划方法，在部分可观测下能够实现长周期受约束的操作计划。 |
| [^50] | [DynaQuant: Compressing Deep Learning Training Checkpoints via Dynamic Quantization.](http://arxiv.org/abs/2306.11800) | DynaQuant通过动态量化实现对各种最先进模型的显着压缩，几乎不影响模型准确性。 |
| [^51] | [Recurrent Memory Decision Transformer.](http://arxiv.org/abs/2306.09459) | 本文提出了循环记忆决策变压器（RMDT）模型，用于处理强化学习中的长序列问题。在Atari游戏和MoJoCo控制问题上的实验表明，采用循环记忆机制的RMDT模型显着优于其没有循环记忆机制的对应模型。 |
| [^52] | [Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization.](http://arxiv.org/abs/2306.09222) | 我们通过分布健壮优化和重要性加权的梯度下降技术提升了深度神经网络的性能，并在各种任务上取得了优越的结果。 |
| [^53] | [Pruning the Way to Reliable Policies: A Multi-Objective Deep Q-Learning Approach to Critical Care.](http://arxiv.org/abs/2306.08044) | 该论文介绍了一种深度Q学习方法，通过剪枝动作集来实现将中间生物标志物信号整合到奖励规范中，提高了重症护理策略的可靠性。 |
| [^54] | [What model does MuZero learn?.](http://arxiv.org/abs/2306.00840) | 本文研究了MuZero算法，发现它学习到的模型无法有效推广到评估未见策略，限制了其对当前策略的进一步改进。 |
| [^55] | [Rank-adaptive spectral pruning of convolutional layers during training.](http://arxiv.org/abs/2305.19059) | 本论文提出了一种新的低参数训练方法，该方法将卷积分解为张量Tucker格式，并在训练过程中自适应地修剪卷积核的Tucker秩，可以有效地降低训练成本。 |
| [^56] | [Privileged Knowledge Distillation for Sim-to-Real Policy Generalization.](http://arxiv.org/abs/2305.18464) | 论文提出了一种新的单阶段特权知识蒸馏方法（HIB），通过捕捉历史轨迹的特权知识表示来学习，缩小模拟和真实之间的差距。 |
| [^57] | [Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning.](http://arxiv.org/abs/2305.15912) | 本文提出了一种利用ReLU单元特征激活值集合进行参数化的几何方法，通过利用现代深度学习架构中的规范化技术，改进了ReLU网络特征学习，提高了优化稳定性和收敛速度，并获得更好的泛化性能。 |
| [^58] | [Decoupled Kullback-Leibler Divergence Loss.](http://arxiv.org/abs/2305.13948) | 本文提出了改进的KL散度损失函数，通过解决解耦式KL散度损失函数的对称性限制和引入全局信息来提升性能，在CIFAR-10/100和ImageNet数据集上展示了其在对抗训练和知识蒸馏任务中的优越表现。 |
| [^59] | [A duality framework for generalization analysis of random feature models and two-layer neural networks.](http://arxiv.org/abs/2305.05642) | 本文提出了一个针对随机特征模型和双层神经网络的泛化分析的对偶性框架，并证明了学习不会受到维数灾难的影响，使 RFMs 可以在核范围之外发挥作用。 |
| [^60] | [Facial recognition technology can expose political orientation from facial images even when controlling for demographics and self-presentation.](http://arxiv.org/abs/2303.16343) | 本研究使用面部识别技术，通过特定的面部特征发现了人们的政治取向，甚至可以从自然图像中推广。这种预测的精度比人类评分者高，相当于一些工作面试的预测效果。 |
| [^61] | [Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA.](http://arxiv.org/abs/2303.06198) | 本文提出了一种新的算法，称为缩减异方差PCA，它在克服病态问题的同时实现了近乎最优和无条件数的理论保证。 |
| [^62] | [A policy gradient approach for Finite Horizon Constrained Markov Decision Processes.](http://arxiv.org/abs/2210.04527) | 本文提出了一种针对有限时域受限马尔可夫决策过程的策略梯度方法，该方法能够在固定时间后终止，通过函数逼近和策略梯度方法找到最优策略。 |
| [^63] | [Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse.](http://arxiv.org/abs/2206.13714) | 研究提出了一种广义策略提升算法，结合了在线方法的策略提升保证和离线策略算法通过样本重用有效利用数据的效率。 |
| [^64] | [Optimal Scoring Rule Design under Partial Knowledge.](http://arxiv.org/abs/2107.07420) | 本文研究了在委托人对代理人的信号分布部分了解的情况下，最优打分规则的设计问题。作者提出了一个最大最小优化的框架，来最大化在代理人信号分布的集合中最坏情况下回报的增加。对于有限集合，提出了高效的算法；对于无限集合，提出了完全多项式时间逼近方案。 |

# 详细

[^1]: 用于旅行购买者问题的深度强化学习

    Deep Reinforcement Learning for Traveling Purchaser Problems

    [https://arxiv.org/abs/2404.02476](https://arxiv.org/abs/2404.02476)

    提出了一种基于深度强化学习的方法，该方法分别解决了旅行购买者问题中的路由构建和购买规划问题，并从全局角度评估和优化解决方案。

    

    旅行购买者问题（TPP）是一种具有广泛应用的重要组合优化问题。本文提出了一种基于深度强化学习（DRL）的新方法，该方法分别解决了路由构建和购买规划问题，同时从全局角度评估和优化解决方案。我们的方法的关键组成部分包括用于捕捉市场-产品关系的TPP的二部图表示，以及从二部图中提取信息并将其用于顺序构建路由的策略网络。

    arXiv:2404.02476v1 Announce Type: cross  Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently const
    
[^2]: 随机梯度 Langevin 反遗忘

    Stochastic Gradient Langevin Unlearning

    [https://arxiv.org/abs/2403.17105](https://arxiv.org/abs/2403.17105)

    本工作提出了随机梯度 Langevin 反遗忘方法，为近似反遗忘问题提供了隐私保障，并展示了小批次梯度更新相较于全批次的优越性能。

    

    “被遗忘的权利”是用户数据隐私的法律所确保的越来越重要。机器反遗忘旨在高效地消除已训练模型参数上某些数据点的影响，使其近似于从头开始重新训练模型。本研究提出了随机梯度 Langevin 反遗忘，这是第一个基于带有隐私保障的噪声随机梯度下降（SGD）的反遗忘框架，适用于凸性假设下的近似反遗忘问题。我们的结果表明，与全批次对应方法相比，小批次梯度更新在隐私复杂度权衡方面提供了更好的性能。我们的反遗忘方法具有诸多算法优势，包括与重新训练相比的复杂度节省，以及支持顺序和批量反遗忘。为了检验我们方法的隐私-效用-复杂度权衡，我们在基准数据集上进行了实验比较。

    arXiv:2403.17105v1 Announce Type: new  Abstract: ``The right to be forgotten'' ensured by laws for user data privacy becomes increasingly important. Machine unlearning aims to efficiently remove the effect of certain data points on the trained model parameters so that it can be approximately the same as if one retrains the model from scratch. This work proposes stochastic gradient Langevin unlearning, the first unlearning framework based on noisy stochastic gradient descent (SGD) with privacy guarantees for approximate unlearning problems under convexity assumption. Our results show that mini-batch gradient updates provide a superior privacy-complexity trade-off compared to the full-batch counterpart. There are numerous algorithmic benefits of our unlearning approach, including complexity saving compared to retraining, and supporting sequential and batch unlearning. To examine the privacy-utility-complexity trade-off of our method, we conduct experiments on benchmark datasets compared 
    
[^3]: CONLINE: 复杂代码生成与在线搜索和正确性测试的精炼

    CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing

    [https://arxiv.org/abs/2403.13583](https://arxiv.org/abs/2403.13583)

    CONLINE框架提出了通过在线搜索和正确性测试来增强复杂代码生成的方法，通过实验证明了其显著提高了代码生成质量。

    

    大型语言模型（LLMs）通过将自然语言描述转换为可执行代码，彻底改变了代码生成能力。然而，在真实场景下生成复杂代码仍然具有挑战性，原因在于复杂的结构、微妙的错误、对高级数据类型的理解以及缺少辅助内容。为了解决这些挑战，我们引入了CONLINE框架，通过计划的在线搜索信息检索和自动正确性测试来增强代码生成，进行迭代精炼。CONLINE还串行化了复杂的输入和输出，以改善理解，并生成测试用例，确保框架适用于现实应用。CONLINE通过对DS-1000和ClassEval数据集进行严格实验验证。结果表明，CONLINE显著提高了复杂代码生成的质量，突显了其提升实践应用潜力。

    arXiv:2403.13583v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement. CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications. CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets. It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the pra
    
[^4]: 强化学习中未来奖励先知的价值

    The Value of Reward Lookahead in Reinforcement Learning

    [https://arxiv.org/abs/2403.11637](https://arxiv.org/abs/2403.11637)

    分析了在强化学习中利用部分未来奖励先知的价值，通过竞争性分析得出了最坏情况下奖励期望的精确比率。

    

    在强化学习（RL）中，代理们与不断变化的环境进行顺序交互，旨在最大化获得的奖励。通常情况下，奖励仅在行动后被观察到，因此目标是最大化预期累积奖励。然而，在许多实际场景中，奖励信息是提前观察到的 -- 交易前观察到价格；了解部分附近交通信息；经常在互动之前为代理分配目标。在这项工作中，我们旨在通过竞争性分析的视角，定量分析这种未来奖励信息的价值。特别地，我们测量了标准RL代理的价值与具有部分未来奖励先知的代理之间的比率。我们刻画了最坏情况下的奖励分布，并推导出最坏情况下奖励期望的精确比率。令人惊讶的是，结果比率与离线RL和r中已知的数量有关。

    arXiv:2403.11637v1 Announce Type: new  Abstract: In reinforcement learning (RL), agents sequentially interact with changing environments while aiming to maximize the obtained rewards. Usually, rewards are observed only after acting, and so the goal is to maximize the expected cumulative reward. Yet, in many practical settings, reward information is observed in advance -- prices are observed before performing transactions; nearby traffic information is partially known; and goals are oftentimes given to agents prior to the interaction. In this work, we aim to quantifiably analyze the value of such future reward information through the lens of competitive analysis. In particular, we measure the ratio between the value of standard RL agents and that of agents with partial future-reward lookahead. We characterize the worst-case reward distribution and derive exact ratios for the worst-case reward expectations. Surprisingly, the resulting ratios relate to known quantities in offline RL and r
    
[^5]: 一个可扩展且可并行化的数字孪生框架，用于多智能体强化学习系统可持续Sim2Real转换

    A Scalable and Parallelizable Digital Twin Framework for Sustainable Sim2Real Transition of Multi-Agent Reinforcement Learning Systems

    [https://arxiv.org/abs/2403.10996](https://arxiv.org/abs/2403.10996)

    提出了一个可持续的多智能体深度强化学习框架，利用分散的学习架构，来解决交通路口穿越和自主赛车等问题

    

    本工作提出了一个可持续的多智能体深度强化学习框架，能够选择性地按需扩展并行化训练工作负载，并利用最少的硬件资源将训练好的策略从模拟环境转移到现实世界。我们引入了AutoDRIVE生态系统作为一个启动数字孪生框架，用于训练、部署和转移合作和竞争的多智能体强化学习策略从模拟环境到现实世界。具体来说，我们首先探究了4台合作车辆(Nigel)在单智能体和多智能体学习环境中共享有限状态信息的交叉遍历问题，采用了一种通用策略方法。然后，我们使用个体策略方法研究了2辆车(F1TENTH)的对抗性自主赛车问题。在任何一组实验中，我们采用了去中心化学习架构，这允许对策略进行有力的训练和测试。

    arXiv:2403.10996v1 Announce Type: cross  Abstract: This work presents a sustainable multi-agent deep reinforcement learning framework capable of selectively scaling parallelized training workloads on-demand, and transferring the trained policies from simulation to reality using minimal hardware resources. We introduce AutoDRIVE Ecosystem as an enabling digital twin framework to train, deploy, and transfer cooperative as well as competitive multi-agent reinforcement learning policies from simulation to reality. Particularly, we first investigate an intersection traversal problem of 4 cooperative vehicles (Nigel) that share limited state information in single as well as multi-agent learning settings using a common policy approach. We then investigate an adversarial autonomous racing problem of 2 vehicles (F1TENTH) using an individual policy approach. In either set of experiments, a decentralized learning architecture was adopted, which allowed robust training and testing of the policies 
    
[^6]: Continual Learning中的超参数：现实检验

    Hyperparameters in Continual Learning: a Reality Check

    [https://arxiv.org/abs/2403.09066](https://arxiv.org/abs/2403.09066)

    超参数对于连续学习的重要性被强调，提出了一个涉及超参数调整和评估阶段的评估协议。

    

    不同的连续学习（CL）算法旨在在CL过程中有效地缓解稳定性和可塑性之间的权衡，为了实现这一目标，调整每种算法的适当超参数是必不可少的。本文主张现行的评估协议既不切实际，也无法有效评估连续学习算法的能力。

    arXiv:2403.09066v1 Announce Type: new  Abstract: Various algorithms for continual learning (CL) have been designed with the goal of effectively alleviating the trade-off between stability and plasticity during the CL process. To achieve this goal, tuning appropriate hyperparameters for each algorithm is essential. As an evaluation protocol, it has been common practice to train a CL algorithm using diverse hyperparameter values on a CL scenario constructed with a benchmark dataset. Subsequently, the best performance attained with the optimal hyperparameter value serves as the criterion for evaluating the CL algorithm. In this paper, we contend that this evaluation protocol is not only impractical but also incapable of effectively assessing the CL capability of a CL algorithm. Returning to the fundamental principles of model evaluation in machine learning, we propose an evaluation protocol that involves Hyperparameter Tuning and Evaluation phases. Those phases consist of different datase
    
[^7]: FogGuard: 使用感知损失保护YOLO免受雾霾影响

    FogGuard: guarding YOLO against fog using perceptual loss

    [https://arxiv.org/abs/2403.08939](https://arxiv.org/abs/2403.08939)

    FogGuard提出了一种针对雾天气条件挑战的新型雾感知目标检测网络，通过微调数据收集的方法来提高目标检测算法在恶劣天气条件下的可靠性。

    

    在本文中，我们提出了一种新颖的雾感知目标检测网络，称为FogGuard，旨在解决雾天气条件带来的挑战。自动驾驶系统严重依赖准确的目标检测算法，但恶劣的天气条件会显著影响深度神经网络（DNN）的可靠性。现有方法可分为两类，1）图像增强（如IA-YOLO）和2）基于领域适应的方法。图像增强技术试图生成无雾图像，然而，从有雾图像中恢复无雾图像比在有雾图像中检测对象要困难得多。另一方面，基于领域适应的方法没有利用目标领域中的标记数据集。这两类方法都在尝试解决问题的更难版本。我们的方法建立在对原始标注数据的微调之上。

    arXiv:2403.08939v1 Announce Type: cross  Abstract: In this paper, we present a novel fog-aware object detection network called FogGuard, designed to address the challenges posed by foggy weather conditions. Autonomous driving systems heavily rely on accurate object detection algorithms, but adverse weather conditions can significantly impact the reliability of deep neural networks (DNNs).   Existing approaches fall into two main categories, 1) image enhancement such as IA-YOLO 2) domain adaptation based approaches. Image enhancement based techniques attempt to generate fog-free image. However, retrieving a fogless image from a foggy image is a much harder problem than detecting objects in a foggy image. Domain-adaptation based approaches, on the other hand, do not make use of labelled datasets in the target domain. Both categories of approaches are attempting to solve a harder version of the problem. Our approach builds over fine-tuning on the   Our framework is specifically designed t
    
[^8]: HSIC估计的极小化率对平移不变核

    The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels

    [https://arxiv.org/abs/2403.07735](https://arxiv.org/abs/2403.07735)

    HSIC估计的极小化率对平移不变核的独立性度量具有重要意义

    

    Kernel技术是数据科学和统计学中最有影响力的方法之一。在温和条件下，与核相关的再生核希尔伯特空间能够编码$M\ge 2$个随机变量的独立性。在核上依赖的最普遍的独立性度量可能是所谓的Hilbert-Schmidt独立性准则(HSIC; 在统计文献中也称为距离协方差)。尽管自近二十年前引入以来已经有各种现有的设计的HSIC估计量，HSIC可以被估计的速度的基本问题仍然是开放的。在这项工作中，我们证明了对于包含具有连续有界平移不变特征核的高斯Borel测度在$\mathbb R^d$上的HSIC估计的极小化最优速率是$\mathcal O\!\left(n^{-1/2}\right)$。具体地，我们的结果意味着许多方面在极小化意义上的最优性

    arXiv:2403.07735v1 Announce Type: cross  Abstract: Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the optimality in the minimax sense of many 
    
[^9]: 模式识别的混合量子启发式ResNet和DenseNet及其完整性分析

    Hybrid Quantum-inspired Resnet and Densenet for Pattern Recognition with Completeness Analysis

    [https://arxiv.org/abs/2403.05754](https://arxiv.org/abs/2403.05754)

    提出了两种根植于残差连接和密集连接的混合量子启发式神经网络，用于更全面地改进和评估新型神经网络在复杂和不可预测环境中的表现

    

    随着当今数字技术的接近，深度神经网络正成为人工智能繁荣的基础算法。然而，不断发展的社会需求正在强调替代传统神经网络的新方法的必要性。同时，后摩尔时代的来临推动了具有卓越潜力的量子启发式神经网络在某些情况下的发展。然而，由于目前新旧深度学习模型之间比较中存在含糊指标，因此一套明确的评估系统与详细的指标是非常重要和不可或缺的。因此，为了更全面地改进和评估新型神经网络在复杂和不可预测环境中的表现，我们提出了两种根植于残差连接和密集连接的混合量子启发式神经网络，用于模式识别。

    arXiv:2403.05754v1 Announce Type: new  Abstract: With the contemporary digital technology approaching, deep neural networks are emerging as the foundational algorithm of the artificial intelligence boom. Whereas, the evolving social demands have been emphasizing the necessity of novel methodologies to substitute traditional neural networks. Concurrently, the advent of the post-Moore era has spurred the development of quantum-inspired neural networks with outstanding potentials at certain circumstances. Nonetheless, a definitive evaluating system with detailed metrics is tremendously vital and indispensable owing to the vague indicators in comparison between the novel and traditional deep learning models at present. Hence, to improve and evaluate the performances of the novel neural networks more comprehensively in complex and unpredictable environments, we propose two hybrid quantum-inspired neural networks which are rooted in residual and dense connections respectively for pattern rec
    
[^10]: 用双手扭开盖子

    Twisting Lids Off with Two Hands

    [https://arxiv.org/abs/2403.02338](https://arxiv.org/abs/2403.02338)

    深度强化学习结合仿真到真实世界的转移为解决物体操纵问题提供了有力支持

    

    用两只多指手臂操纵物体一直是机器人领域的一项长期挑战，原因在于许多操纵任务的丰富接触性质以及协调高维度双手系统固有的复杂性。在这项工作中，我们考虑了使用两只手扭开各种瓶子盖的问题，并展示出使用深度强化学习在仿真中训练的策略可以有效地转移到现实世界。通过对物理建模、实时感知和奖励设计的新工程见解，该策略展示了一般化能力，能够贯穿各种看不见的物体，展示出动态和灵巧的行为。我们的发现证明了深度强化学习结合仿真到真实世界的转移仍然是解决前所未有复杂问题的操纵问题的一个有前途的方法。

    arXiv:2403.02338v1 Announce Type: cross  Abstract: Manipulating objects with two multi-fingered hands has been a long-standing challenge in robotics, attributed to the contact-rich nature of many manipulation tasks and the complexity inherent in coordinating a high-dimensional bimanual system. In this work, we consider the problem of twisting lids of various bottle-like objects with two hands, and demonstrate that policies trained in simulation using deep reinforcement learning can be effectively transferred to the real world. With novel engineering insights into physical modeling, real-time perception, and reward design, the policy demonstrates generalization capabilities across a diverse set of unseen objects, showcasing dynamic and dexterous behaviors. Our findings serve as compelling evidence that deep reinforcement learning combined with sim-to-real transfer remains a promising approach for addressing manipulation problems of unprecedented complexity.
    
[^11]: 大规模变分高斯状态空间模型

    Large-scale variational Gaussian state-space models

    [https://arxiv.org/abs/2403.01371](https://arxiv.org/abs/2403.01371)

    该论文介绍了一种针对具有高斯噪声驱动非线性动力学的状态空间模型的大规模变分算法和结构化逼近方法，可以有效评估ELBO和获取低方差的随机梯度估计，通过利用低秩蒙特卡罗逼近和推断网络的精度矩阵更新，将近似平滑问题转化为近似滤波问题。

    

    我们介绍了一种用于状态空间模型的嵌套变分推断算法和结构化变分逼近方法，其中非线性动力学由高斯噪声驱动。值得注意的是，所提出的框架允许在没有采用对角高斯逼近的情况下有效地评估ELBO和低方差随机梯度估计，通过利用（i）通过动力学对隐状态进行边缘化的蒙特卡罗逼近的低秩结构，（ii）一个推断网络，该网络通过低秩精度矩阵更新来近似更新步骤，（iii）将当前和未来观测编码为伪观测--将近似平滑问题转换为（更简单的）近似滤波问题。整体而言，必要的统计信息和ELBO可以在$O（TL（Sr+S^2+r^2））$时间内计算，其中$T$是系列长度，$L$是状态空间维数，$S$是用于逼近的样本数量。

    arXiv:2403.01371v1 Announce Type: cross  Abstract: We introduce an amortized variational inference algorithm and structured variational approximation for state-space models with nonlinear dynamics driven by Gaussian noise. Importantly, the proposed framework allows for efficient evaluation of the ELBO and low-variance stochastic gradient estimates without resorting to diagonal Gaussian approximations by exploiting (i) the low-rank structure of Monte-Carlo approximations to marginalize the latent state through the dynamics (ii) an inference network that approximates the update step with low-rank precision matrix updates (iii) encoding current and future observations into pseudo observations -- transforming the approximate smoothing problem into an (easier) approximate filtering problem. Overall, the necessary statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$ is the series length, $L$ is the state-space dimensionality, $S$ are the number of samples used to app
    
[^12]: 在因果发现中的签名核条件独立性测试用于随机过程

    Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes

    [https://arxiv.org/abs/2402.18477](https://arxiv.org/abs/2402.18477)

    本文在随机过程中开发了一种基于签名核的条件独立性测试，实现了对因果关系的推断，以及开发了约束条件的因果发现算法用于恢复整个有向图。

    

    从观测数据中推断随机动力系统背后的因果结构在科学、健康和金融等领域具有巨大潜力。本文通过利用最近签名核技术的进展，开发了一种基于内核的“路径空间”上条件独立性（CI）测试，用于随机微分方程的解。我们展示了相较于现有方法，在路径空间上，我们提出的CI测试表现出严格更好的性能。此外，我们还为非循环随机动力系统开发了基于约束的因果发现算法，利用时间信息来恢复整个有向图。在假设忠实性和CI预言机的情况下，我们的算法是完备且正确的。

    arXiv:2402.18477v1 Announce Type: cross  Abstract: Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via "which variables enter the differential of which other variables". In this paper, we develop a kernel-based test of conditional independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirical
    
[^13]: 具有小参数的偏微分方程的双尺度神经网络

    Two-scale Neural Networks for Partial Differential Equations with Small Parameters

    [https://arxiv.org/abs/2402.17232](https://arxiv.org/abs/2402.17232)

    提出了一种用双尺度神经网络方法解决具有小参数的偏微分方程的方法，能够直接将小参数纳入神经网络架构中，从而简化解决过程，并能够合理准确地捕捉由小参数引起的解中大导数特征。

    

    我们提出了一种用物理信息神经网络（PINNs）解决具有小参数的偏微分方程（PDEs）的双尺度神经网络方法。我们直接将小参数纳入神经网络的架构中。所提出的方法使得以简单方式解决具有小参数的PDE成为可能，而无需添加傅里叶特征或其他计算繁琐的截断参数搜索。多个数值例子展示了在解决由小参数引起的解中大导数特征时的合理准确性。

    arXiv:2402.17232v1 Announce Type: cross  Abstract: We propose a two-scale neural network method for solving partial differential equations (PDEs) with small parameters using physics-informed neural networks (PINNs). We directly incorporate the small parameters into the architecture of neural networks. The proposed method enables solving PDEs with small parameters in a simple fashion, without adding Fourier features or other computationally taxing searches of truncation parameters. Various numerical examples demonstrate reasonable accuracy in capturing features of large derivatives in the solutions caused by small parameters.
    
[^14]: 通过将可学习的概率离散潜变量引入机器学习模型来提高眼部疾病检测的鲁棒性

    Improve Robustness of Eye Disease Detection by including Learnable Probabilistic Discrete Latent Variables into Machine Learning Models

    [https://arxiv.org/abs/2402.16865](https://arxiv.org/abs/2402.16865)

    通过引入可学习的概率离散潜变量，该研究提出了一种新颖的眼部疾病检测方法，利用生成流网络来学习眼底图像中眼部疾病的后验分布，提高了鲁棒性和泛化能力。

    

    眼部疾病从糖尿病性视网膜病变到青光眼等，由于其高发病率和可能导致视力损害，构成了一个重要的公共卫生挑战。及早和准确的诊断对于有效治疗和管理至关重要。近年来，深度学习模型已经成为分析医学图像（包括眼部图像）的强大工具。然而，模型的解释性和不确定性估计方面仍然存在挑战，这对临床决策至关重要。本研究引入了GFlowOut的新颖应用，利用生成流网络（GFlowNets）的概率框架来学习关于辍学掩码的后验分布，用于使用眼底图像对眼部疾病进行分类和分析。我们开发了一种稳健且具有普适性的方法，利用以ResNet18和ViT模型为主干的GFlowOut来识别各种眼部状况。

    arXiv:2402.16865v1 Announce Type: cross  Abstract: Ocular diseases, ranging from diabetic retinopathy to glaucoma, present a significant public health challenge due to their prevalence and potential for causing vision impairment. Early and accurate diagnosis is crucial for effective treatment and management.In recent years, deep learning models have emerged as powerful tools for analysing medical images, including ocular imaging . However, challenges persist in model interpretability and uncertainty estimation, which are critical for clinical decision-making. This study introduces a novel application of GFlowOut, leveraging the probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over dropout masks, for the classification and analysis of ocular diseases using eye fundus images. We develop a robust and generalizable method that utilizes GFlowOut integrated with ResNet18 and ViT models as backbone in identifying various ocular conditions. Th
    
[^15]: 在科学计算规模上构建灵活的机器学习模型

    Building Flexible Machine Learning Models for Scientific Computing at Scale

    [https://arxiv.org/abs/2402.16014](https://arxiv.org/abs/2402.16014)

    OmniArch通过多物理学时空数据处理、可扩展的自回归任务和物理信息增强学习技术，在科学计算领域构建灵活的基础模型，并在性能、适应性和逆问题求解方面取得突破，展现了AI对科学计算的潜力。

    

    arXiv:2402.16014v1

    arXiv:2402.16014v1 Announce Type: cross  Abstract: Foundation models have revolutionized knowledge acquisition across domains, and our study introduces OmniArch, a paradigm-shifting approach designed for building foundation models in multi-physics scientific computing. OmniArch's pre-training involves a versatile pipeline that processes multi-physics spatio-temporal data, casting forward problem learning into scalable auto-regressive tasks, while our novel Physics-Informed Reinforcement Learning (PIRL) technique during fine-tuning ensures alignment with physical laws. Pre-trained on the comprehensive PDEBench dataset, OmniArch not only sets new performance benchmarks for 1D, 2D and 3D PDEs but also demonstrates exceptional adaptability to new physics via few-shot and zero-shot learning approaches. The model's representations further extend to inverse problem-solving, highlighting the transformative potential of AI-enabled Scientific Computing(AI4SC) foundation models for engineering ap
    
[^16]: 分布式异构数据上的分裂联邦学习的收敛分析

    Convergence Analysis of Split Federated Learning on Heterogeneous Data

    [https://arxiv.org/abs/2402.15166](https://arxiv.org/abs/2402.15166)

    本文填补了分裂联邦学习在各异数据上收敛分析的空白，提供了针对强凸和一般凸目标的SFL收敛分析，收敛速率分别为$O(1/T)$和$O(1/\sqrt[3]{T})。

    

    分裂联邦学习（SFL）是一种最近的分布式方法，用于在多个客户端之间进行协作模型训练。在SFL中，全局模型通常被分为两部分，其中客户端以并行联邦方式训练一部分，主服务器训练另一部分。尽管最近关于SFL算法发展的研究很多，但SFL的收敛分析在文献中还未有提及，本文旨在弥补这一空白。对SFL进行分析可能比对联邦学习（FL）的分析更具挑战性，这是由于客户端和主服务器之间可能存在双速更新。我们提供了针对异构数据上强凸和一般凸目标的SFL收敛分析。收敛速率分别为$O(1/T)$和$O(1/\sqrt[3]{T})$，其中$T$表示SFL训练的总轮数。我们进一步将分析扩展到非凸目标和一些客户端可能在训练过程中不可用的情况。

    arXiv:2402.15166v1 Announce Type: cross  Abstract: Split federated learning (SFL) is a recent distributed approach for collaborative model training among multiple clients. In SFL, a global model is typically split into two parts, where clients train one part in a parallel federated manner, and a main server trains the other. Despite the recent research on SFL algorithm development, the convergence analysis of SFL is missing in the literature, and this paper aims to fill this gap. The analysis of SFL can be more challenging than that of federated learning (FL), due to the potential dual-paced updates at the clients and the main server. We provide convergence analysis of SFL for strongly convex and general convex objectives on heterogeneous data. The convergence rates are $O(1/T)$ and $O(1/\sqrt[3]{T})$, respectively, where $T$ denotes the total number of rounds for SFL training. We further extend the analysis to non-convex objectives and where some clients may be unavailable during trai
    
[^17]: 几何信息神经网络

    Geometry-Informed Neural Networks

    [https://arxiv.org/abs/2402.14009](https://arxiv.org/abs/2402.14009)

    GINNs提出了一种新颖的几何信息神经网络范式，可以在几何任务中生成多样的解决方案，无需训练数据，采用显式多样性损失以及可微损失来减轻模态坍缩，并在实验中展示了其在各种复杂性场景中的高效性。

    

    我们引入了几何信息神经网络（GINNs）的概念，涵盖了（i）在几何约束下学习，（ii）神经场作为合适的表示，（iii）生成在几何任务中经常遇到的欠定系统的多样解决方案。值得注意的是，GINN的构建不需要训练数据，因此可以被纯约束驱动地视为生成建模。我们增加了显式的多样性损失来减轻模态坍缩。我们考虑了几种约束，特别是组件的连通性，我们通过莫尔斯理论将其转化为可微损失。在实验中，我们展示了在不断增加复杂性的二维和三维场景中，GINN学习范式的高效性。

    arXiv:2402.14009v1 Announce Type: new  Abstract: We introduce the concept of geometry-informed neural networks (GINNs), which encompass (i) learning under geometric constraints, (ii) neural fields as a suitable representation, and (iii) generating diverse solutions to under-determined systems often encountered in geometric tasks. Notably, the GINN formulation does not require training data, and as such can be considered generative modeling driven purely by constraints. We add an explicit diversity loss to mitigate mode collapse. We consider several constraints, in particular, the connectedness of components which we convert to a differentiable loss through Morse theory. Experimentally, we demonstrate the efficacy of the GINN learning paradigm across a range of two and three-dimensional scenarios with increasing levels of complexity.
    
[^18]: CodaMal：低成本显微镜下的疟疾检测的对比域自适应

    CodaMal: Contrastive Domain Adaptation for Malaria Detection in Low-Cost Microscopes

    [https://arxiv.org/abs/2402.10478](https://arxiv.org/abs/2402.10478)

    提出了CodaMal框架，实现了低成本显微镜下疟疾检测的对比域自适应，解决了HCM和LCM图像之间的域差异问题

    

    疟疾是全球重大健康问题，其诊断需要可扩展的解决方案，能够有效地处理低成本显微镜(LCM)下的显微图像。基于深度学习的方法在从显微图像中进行计算机辅助诊断方面取得了成功。然而，这些方法需要标注的显现出受疟疾寄生虫影响的细胞及其生命周期阶段的图像。与从高成本显微镜(HCM)中标注图像相比，从LCM中标注图像显著增加了医学专家的负担。因此，一个实际的解决方案应该在HCM图像上训练，能够在LCM图像上测试时具有良好的泛化能力。在本作品中，我们提出了一个名为CodaMal（对比域自适应用于疟疾检测）的端到端学习框架。

    arXiv:2402.10478v1 Announce Type: cross  Abstract: Malaria is a major health issue worldwide, and its diagnosis requires scalable solutions that can work effectively with low-cost microscopes (LCM). Deep learning-based methods have shown success in computer-aided diagnosis from microscopic images. However, these methods need annotated images that show cells affected by malaria parasites and their life stages. Annotating images from LCM significantly increases the burden on medical experts compared to annotating images from high-cost microscopes (HCM). For this reason, a practical solution would be trained on HCM images which should generalize well on LCM images during testing. While earlier methods adopted a multi-stage learning process, they did not offer an end-to-end approach. In this work, we present an end-to-end learning framework, named CodaMal (Contrastive Domain Adpation for Malaria). In order to bridge the gap between HCM (training) and LCM (testing), we propose a domain adap
    
[^19]: BitDelta：你的微调可能只有一个比特的价值

    BitDelta: Your Fine-Tune May Only Be Worth One Bit

    [https://arxiv.org/abs/2402.10193](https://arxiv.org/abs/2402.10193)

    BitDelta研究探讨了大型语言模型在微调过程中的信息冗余性，并提出了一种名为BitDelta的方法，可以将微调过程中添加的信息量化为一个比特，同时保持性能。这一发现对于多租户模型的服务和存储有重要意义，并可以显著降低GPU内存需求。

    

    大型语言模型（LLMs）通常在两个阶段进行训练：在大规模互联网数据集上进行预训练，然后在下游任务上进行微调。由于预训练的高计算需求，直觉上认为微调对模型的信息添加较少，因此更具有可压缩性。我们通过将微调模型的权重分解为预训练组件和额外的增量来探究这一假设。我们引入了一种简单的方法——BitDelta，成功地将这个增量量化为1比特而不影响性能。这一有趣的发现不仅突显了微调过程中添加的信息的潜在冗余性，而且对于多租户模型的服务和存储也具有重要影响。通过使用一个高精度的基础模型以及多个1比特的增量，BitDelta大大降低了GPU内存需求。

    arXiv:2402.10193v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are typically trained in two phases: pre-training on large internet-scale datasets, and fine-tuning for downstream tasks. Given the higher computational demand of pre-training, it's intuitive to assume that fine-tuning adds less new information to the model, and is thus more compressible. We explore this assumption by decomposing the weights of fine-tuned models into their pre-trained components and an additional delta. We introduce a simple method, BitDelta, which successfully quantizes this delta down to 1 bit without compromising performance. This interesting finding not only highlights the potential redundancy of information added during fine-tuning, but also has significant implications for the multi-tenant serving and multi-tenant storage of fine-tuned models. By enabling the use of a single high-precision base model accompanied by multiple 1-bit deltas, BitDelta dramatically reduces GPU memory requir
    
[^20]: 短视频和心理健康：基于知识导向的多模态神经主题模型

    Short-Form Videos and Mental Health: A Knowledge-Guided Multimodal Neural Topic Model

    [https://arxiv.org/abs/2402.10045](https://arxiv.org/abs/2402.10045)

    这项研究针对短视频对观众心理健康的抑郁影响问题，开发了一种基于医学知识的多模态神经主题模型，以预测其影响并采取相应的干预措施。

    

    短视频正试图重新塑造整个社交媒体景观，然而专家们对其对观众的抑郁影响感到极度担忧，这一点已由医学研究证明。为了防止广泛影响，各平台渴望预测这些视频对观众心理健康的影响，从而采取干预措施，比如修订推荐算法和显示观众慎重选择。然而，现有的预测方法缺乏与抑郁症的临床证实的外部环境因素相关的医学知识。为了考虑这样的医学知识，我们采用了一种新兴的方法论学科——种子神经主题模型（NTMs）。然而，现有的种子NTMs存在单一来源主题、未知主题来源、模糊的种子监督和次优的收敛等局限性。为了解决这些挑战，我们开发了一种新颖的基于知识指导的多模态神经主题模型（Knowledg...（待补充）

    arXiv:2402.10045v1 Announce Type: cross  Abstract: While short-form videos head to reshape the entire social media landscape, experts are exceedingly worried about their depressive impacts on viewers, as evidenced by medical studies. To prevent widespread consequences, platforms are eager to predict these videos' impact on viewers' mental health. Subsequently, they can take intervention measures, such as revising recommendation algorithms and displaying viewer discretion. Nevertheless, applicable predictive methods lack relevance to well-established medical knowledge, which outlines clinically proven external and environmental factors of depression. To account for such medical knowledge, we resort to an emergent methodological discipline, seeded Neural Topic Models (NTMs). However, existing seeded NTMs suffer from the limitations of single-origin topics, unknown topic sources, unclear seed supervision, and suboptimal convergence. To address those challenges, we develop a novel Knowledg
    
[^21]: 侧信息中的Stackelberg博弈中的后悔最小化

    Regret Minimization in Stackelberg Games with Side Information

    [https://arxiv.org/abs/2402.08576](https://arxiv.org/abs/2402.08576)

    这篇论文研究了侧信息中的Stackelberg博弈，提出了一种方法来解决现实中玩家之间信息交流不充分的情况，并且证明了在这种情况下后悔最小化是有效的。

    

    在最基本的情况下，Stackelberg博弈是一个双人博弈，其中领导者承诺一种（混合）策略，追随者做出最佳反应。在过去的十年中，Stackelberg博弈算法是算法博弈论的最大成功之一，因为Stackelberg博弈的算法已经在许多现实世界的领域中被应用，包括机场安全、反盗猎和网络犯罪预防。然而，这些算法通常未能考虑到每个玩家可用的额外信息（例如交通模式，天气条件，网络拥塞），这是现实的显著特征，可能会显著影响到两个玩家的最优策略。我们将这样的情况形式化为带有侧信息的Stackelberg博弈，其中两个玩家在进行游戏之前都观察到一个外部环境。然后，领导者承诺一种（可能依赖于上下文的）策略，追随者对领导者的策略和上下文都做出最佳反应。

    In its most basic form, a Stackelberg game is a two-player game in which a leader commits to a (mixed) strategy, and a follower best-responds. Stackelberg games are perhaps one of the biggest success stories of algorithmic game theory over the last decade, as algorithms for playing in Stackelberg games have been deployed in many real-world domains including airport security, anti-poaching efforts, and cyber-crime prevention. However, these algorithms often fail to take into consideration the additional information available to each player (e.g. traffic patterns, weather conditions, network congestion), a salient feature of reality which may significantly affect both players' optimal strategies. We formalize such settings as Stackelberg games with side information, in which both players observe an external context before playing. The leader then commits to a (possibly context-dependent) strategy, and the follower best-responds to both the leader's strategy and the context. We focus on t
    
[^22]: Shadowcast: 隐秘的数据污染攻击对抗视觉语言模型

    Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models

    [https://arxiv.org/abs/2402.06659](https://arxiv.org/abs/2402.06659)

    Shadowcast是一种隐秘的数据污染攻击方法，可以通过伪装成良性图像和匹配文本来操纵视觉语言模型的响应。它包括标签攻击和说服攻击，可以混淆类别标签并编写有说服力的描述。使用仅50个毒样本，Shadowcast能够高效实现攻击者的意图。

    

    视觉语言模型（VLM）能够从视觉输入中生成文本响应，然而它们的多功能性带来了重大的安全隐患。本研究首次揭示了VLM对数据污染攻击的易受性，这些攻击可以操纵对无害的日常提示的响应。我们引入了一种名为Shadowcast的隐秘数据污染攻击方法，其中毒样本在视觉上与具有匹配文本的良性图像难以区分。Shadowcast在两种攻击类型中展示出了有效性。第一种是标签攻击，使VLM误识别类别标签，例如混淆唐纳德·特朗普和乔·拜登等人。第二种是说服攻击，利用VLM的文本生成能力来编写故事，例如通过有说服力和看似合理的描述将垃圾食品描绘成健康食品。我们展示了Shadowcast使用仅50个毒样本就能高度有效地实现攻击者的意图。此外，这些毒样本仍然保持有效。

    Vision-Language Models (VLMs) excel in generating textual responses from visual inputs, yet their versatility raises significant security concerns. This study takes the first step in exposing VLMs' susceptibility to data poisoning attacks that can manipulate responses to innocuous, everyday prompts. We introduce Shadowcast, a stealthy data poisoning attack method where poison samples are visually indistinguishable from benign images with matching texts. Shadowcast demonstrates effectiveness in two attack types. The first is Label Attack, tricking VLMs into misidentifying class labels, such as confusing Donald Trump for Joe Biden. The second is Persuasion Attack, which leverages VLMs' text generation capabilities to craft narratives, such as portraying junk food as health food, through persuasive and seemingly rational descriptions. We show that Shadowcast are highly effective in achieving attacker's intentions using as few as 50 poison samples. Moreover, these poison samples remain eff
    
[^23]: 通过渐进子网络实现高效的分阶段预训练

    Efficient Stagewise Pretraining via Progressive Subnetworks

    [https://arxiv.org/abs/2402.05913](https://arxiv.org/abs/2402.05913)

    通过渐进子网络训练，该方法实现了高效的分阶段预训练，避免了早期阶段无法评估完整模型和模型质量下降等问题。

    

    最近大型语言模型的发展引起了人们对高效预训练方法的关注。最近的一个有效范例是进行分阶段训练，即在训练过程中逐渐增加模型的大小（例如逐渐叠加（Reddi等人，2023年））。虽然资源和墙钟时间的节省很吸引人，但它也有局限性，特别是在早期阶段无法评估完整的模型，并且由于初始阶段模型容量较小而导致模型质量下降。在这项工作中，我们提出了一种替代性框架，即渐进子网络训练，在整个训练过程中保持完整的模型，但每个步骤只训练模型中的子网络。我们专注于这个框架的一个简单实例，即随机路径训练（RaPTr），它在每个步骤中只训练一条子路径，逐渐增加路径长度。RaPTr在BERT和UL2语言模型的预训练损失方面取得了更好的效果，同时只需要2

    Recent developments in large language models have sparked interest in efficient pretraining methods. A recent effective paradigm is to perform stage-wise training, where the size of the model is gradually increased over the course of training (e.g. gradual stacking (Reddi et al., 2023)). While the resource and wall-time savings are appealing, it has limitations, particularly the inability to evaluate the full model during earlier stages, and degradation in model quality due to smaller model capacity in the initial stages. In this work, we propose an alternative framework, progressive subnetwork training, that maintains the full model throughout training, but only trains subnetworks within the model in each step. We focus on a simple instantiation of this framework, Random Path Training (RaPTr) that only trains a sub-path of layers in each step, progressively increasing the path lengths in stages. RaPTr achieves better pre-training loss for BERT and UL2 language models while requiring 2
    
[^24]: 通过潜在同构传播理解和引导弱监督的实体对齐

    Understanding and Guiding Weakly Supervised Entity Alignment with Potential Isomorphism Propagation

    [https://arxiv.org/abs/2402.03025](https://arxiv.org/abs/2402.03025)

    本文通过传播视角分析了弱监督的实体对齐任务，并提出一种潜在同构传播操作符来增强知识图谱之间的邻域信息传播。通过验证，发现基于聚合的实体对齐模型中的潜在对齐实体具有同构子图。

    

    弱监督的实体对齐是使用有限数量的种子对齐，在不同知识图谱之间识别等价实体的任务。尽管在基于聚合的弱监督实体对齐方面取得了重大进展，但在这种设置下的基本机制仍未被探索。在本文中，我们提出了一种传播视角来分析弱监督实体对齐，并解释了现有的基于聚合的实体对齐模型。我们的理论分析揭示了这些模型实质上是寻找用于对实体相似度进行传播的操作符。我们进一步证明，尽管不同知识图谱之间存在结构异质性，基于聚合的实体对齐模型中的潜在对齐实体具有同构子图，这是实体对齐的核心前提，但尚未被研究。利用这一洞见，我们引入了潜在同构传播操作符来增强跨知识图谱的邻域信息传播。我们开发了一个通用的实体对齐框架PipEA，实现了效果显著的实验结果。

    Weakly Supervised Entity Alignment (EA) is the task of identifying equivalent entities across diverse knowledge graphs (KGs) using only a limited number of seed alignments. Despite substantial advances in aggregation-based weakly supervised EA, the underlying mechanisms in this setting remain unexplored. In this paper, we present a propagation perspective to analyze weakly supervised EA and explain the existing aggregation-based EA models. Our theoretical analysis reveals that these models essentially seek propagation operators for pairwise entity similarities. We further prove that, despite the structural heterogeneity of different KGs, the potentially aligned entities within aggregation-based EA models have isomorphic subgraphs, which is the core premise of EA but has not been investigated. Leveraging this insight, we introduce a potential isomorphism propagation operator to enhance the propagation of neighborhood information across KGs. We develop a general EA framework, PipEA, inco
    
[^25]: AutoTimes: 基于大型语言模型的自回归时间序列预测器

    AutoTimes: Autoregressive Time Series Forecasters via Large Language Models

    [https://arxiv.org/abs/2402.02370](https://arxiv.org/abs/2402.02370)

    AutoTimes是一种基于大型语言模型的自回归时间序列预测器，利用语言模型的转换能力来处理时间序列数据，实现了与先前模型相当的性能。

    

    由于大规模时间序列的有限可用性和可扩展预训练的不充分探索，时间序列的基础模型尚未完全发展。基于时间序列和自然语言的相似顺序结构，越来越多的研究证明了利用大型语言模型(LLM)进行时间序列的可行性。然而，先前的方法可能忽视了时间序列和自然语言对齐的一致性，导致对LLM潜力的利用不足。为了充分利用从语言建模中学到的通用令牌转换，我们提出了AutoTimes，将LLM重新用作自回归时间序列预测器，这与LLM的获取和利用一致，而无需更新参数。由此产生的预测器可以处理灵活的系列长度，并实现与流行模型相当的性能。此外，我们提出了基于令牌的提示方法，利用相应的时间戳来进行预测。

    Foundation models of time series have not been fully developed due to the limited availability of large-scale time series and the underexploration of scalable pre-training. Based on the similar sequential structure of time series and natural language, increasing research demonstrates the feasibility of leveraging large language models (LLM) for time series. Nevertheless, prior methods may overlook the consistency in aligning time series and natural language, resulting in insufficient utilization of the LLM potentials. To fully exploit the general-purpose token transitions learned from language modeling, we propose AutoTimes to repurpose LLMs as Autoregressive Time series forecasters, which is consistent with the acquisition and utilization of LLMs without updating the parameters. The consequent forecasters can handle flexible series lengths and achieve competitive performance as prevalent models. Further, we present token-wise prompting that utilizes corresponding timestamps to make ou
    
[^26]: 通过矩阵熵评估大型语言模型

    Large Language Model Evaluation via Matrix Entropy

    [https://arxiv.org/abs/2401.17139](https://arxiv.org/abs/2401.17139)

    本文引入了矩阵熵，一种基于信息论和几何原理的新型指标，用于评估大型语言模型（LLMs）的数据压缩能力。该指标反映了模型提取相关信息和消除不必要元素的能力，为评估语言模型的固有能力提供了洞察。在单模态和多模态设置中都展示了其适用性。

    

    大型语言模型（LLMs）通过将强大的能力扩展到多模态领域，使自然语言处理领域发生了革命。因此，为LLMs定义适当且多样化的评估指标至关重要。在本文中，我们引入了矩阵熵，一种根植于信息论和几何原理的新型指标，用于量化LLMs中的数据压缩能力。它反映了模型提取相关信息和消除不必要元素的能力，从而提供了对语言模型固有能力的洞察。具体而言，我们展示了它在单模态（语言）和多模态设置中的适用性。对于语言模型，我们的发现揭示出表示的矩阵熵在模型扩大时遵循一个缩放定律类型的降低，这作为传统损失缩放定律的补充。对于多模态设置，我们还提出了一种基于矩阵熵的评估方法，用于评估一个模型的性能。

    Large language models (LLMs) have revolutionized the field of natural language processing, extending their strong capabilities into multi-modal domains. Thus, it is vital to define proper and diversified metrics for the evaluation of LLMs.   In this paper, we introduce matrix entropy, a novel metric rooted in information theory and geometry principles to quantify the data compression proficiency in LLMs. It reflects the model's ability to extract relevant information and eliminate unnecessary elements, thereby providing insight into the language model's intrinsic capability. Specifically, we demonstrate its applicability in both single-modal (language) and multi-modal settings. For language models, our findings reveal that the matrix entropy of representations follows a scaling law type reduction when the model scales up, serving as a complement to the traditional loss scaling law. For the multi-modal setting, we also propose an evaluation method based on matrix entropy for assessing a
    
[^27]: LLM指令微调中的提示权重实验

    Prompt Weight Experiments for LLM Instruction Fine-Tuning. (arXiv:2401.13586v1 [cs.LG])

    [http://arxiv.org/abs/2401.13586](http://arxiv.org/abs/2401.13586)

    LLM指令微调中，对于短提示完成数据集，提示词标记分类损失加权（PLW）与性能呈负二次关系，而长提示完成数据集则不受PLW影响。

    

    我们进行了一项小型研究，分析了提示词标记分类损失加权（PLW）如何影响在指令任务上进行微调的7B大小的LLaMA模型的性能。我们使用多个指令数据集重现了斯坦福大学的Alpaca实验，其中包括LLaMA 1和LLaMA 2。我们发现，在我们的短提示完成数据集上微调的模型与PLW之间存在负二次关系，而在长提示完成数据集上微调的模型不受PLW的影响。

    We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets. We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW.
    
[^28]: 收缩扩散概率模型

    Contractive Diffusion Probabilistic Models. (arXiv:2401.13115v1 [cs.LG])

    [http://arxiv.org/abs/2401.13115](http://arxiv.org/abs/2401.13115)

    收缩扩散概率模型（CDPMs）是一种新颖的生成建模技术，通过收缩后向采样并克服分数匹配误差和离散化误差的问题，提高了模型的鲁棒性。实验证明收缩子方差保持（sub-VP）是表现最佳的一种CDPMs。

    

    收缩扩散概率模型（DPMs）已经成为生成建模中一种有前途的技术。DPMs的成功依赖于两个要素：马尔科夫扩散过程的时间反演和分数匹配。大多数现有的工作隐含地假设分数匹配是接近完美的，而这个假设是值得怀疑的。鉴于可能无法保证的分数匹配，我们在DPMs的设计中提出了一个新的准则——收缩后向采样。这导致了一种新的收缩DPMs（CDPMs）类，包括收缩奥恩斯坦-乌伦贝克（OU）过程和收缩子方差保持（sub-VP）随机微分方程（SDEs）。关键洞察力是后向过程的收缩能够缩小分数匹配误差和离散化误差。因此，所提出的CDPMs对于这两种误差都具有鲁棒性。我们的提议得到了理论结果的支持，并且通过实验进行了验证。值得注意的是，收缩子方差保持在表现上最佳。

    Diffusion probabilistic models (DPMs) have emerged as a promising technology in generative modeling. The success of DPMs relies on two ingredients: time reversal of Markov diffusion processes and score matching. Most existing work implicitly assumes that score matching is close to perfect, while this assumption is questionable. In view of possibly unguaranteed score matching, we propose a new criterion -- the contraction of backward sampling in the design of DPMs. This leads to a novel class of contractive DPMs (CDPMs), including contractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variance preserving (sub-VP) stochastic differential equations (SDEs). The key insight is that the contraction in the backward process narrows score matching errors, as well as discretization error. Thus, the proposed CDPMs are robust to both sources of error. Our proposal is supported by theoretical results, and is corroborated by experiments. Notably, contractive sub-VP shows the best performa
    
[^29]: Langevin遗忘：噪声梯度下降的机器遗忘新视角

    Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning. (arXiv:2401.10371v1 [cs.LG])

    [http://arxiv.org/abs/2401.10371](http://arxiv.org/abs/2401.10371)

    Langevin遗忘是一种基于噪声梯度下降的遗忘框架，能够在近似遗忘问题中提供隐私保证，并且具有算法上的优势。

    

    随着采用确保“被遗忘权”的法律，机器遗忘引起了极大的兴趣。研究人员提供了一个概率性的近似遗忘定义，类似于差分隐私（DP）的定义，其中隐私被定义为对重新训练的统计不可区分性。我们提出了Langevin遗忘，这是一个基于噪声梯度下降的近似遗忘问题的隐私保证的遗忘框架。Langevin遗忘在算法上统一了DP学习过程和隐私认证的遗忘过程。其中包括非凸问题的近似认证遗忘，相对于重新训练的复杂度节省，以及用于多个遗忘请求的顺序和批量遗忘。我们通过在基准数据集上的实验验证了Langevin遗忘的实用性，并展示了它对梯度下降的优势。

    Machine unlearning has raised significant interest with the adoption of laws ensuring the ``right to be forgotten''. Researchers have provided a probabilistic notion of approximate unlearning under a similar definition of Differential Privacy (DP), where privacy is defined as statistical indistinguishability to retraining from scratch. We propose Langevin unlearning, an unlearning framework based on noisy gradient descent with privacy guarantees for approximate unlearning problems. Langevin unlearning unifies the DP learning process and the privacy-certified unlearning process with many algorithmic benefits. These include approximate certified unlearning for non-convex problems, complexity saving compared to retraining, sequential and batch unlearning for multiple unlearning requests. We verify the practicality of Langevin unlearning by studying its privacy-utility-complexity trade-off via experiments on benchmark datasets, and also demonstrate its superiority against gradient-decent-p
    
[^30]: 在推荐系统的训练过程中优化细粒度嵌入维度

    Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems. (arXiv:2401.04408v1 [cs.IR])

    [http://arxiv.org/abs/2401.04408](http://arxiv.org/abs/2401.04408)

    本文提出了一种细粒度嵌入维度优化方法（FIITED），能够在推荐系统的训练过程中根据嵌入向量的重要性不断调整其维度，并设计了一种虚拟哈希索引哈希表的嵌入存储系统以有效节省内存。

    

    现代深度学习推荐模型中的大型嵌入表在训练和推断过程中需要过大的内存。为了减小训练时的内存占用，本文提出了一种细粒度嵌入维度优化方法 (FIITED)。根据嵌入向量的重要性不同，FIITED在训练过程中连续调整每个嵌入向量的维度，将更重要的嵌入向量分配更长的维度，并能够适应数据的动态变化。同时，本文设计了一种基于虚拟哈希的物理索引哈希表的嵌入存储系统，以实现嵌入维度的调整并有效地节省内存。对两个行业模型的实验表明，FIITED能够将嵌入的大小减小超过65%，同时保持训练模型的质量，比现有的一种在训练过程中进行嵌入修剪的方法节省更多内存。

    Huge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On p
    
[^31]: 一种用于加速RLHF训练的自适应部署和并行框架

    An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training. (arXiv:2312.11819v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11819](http://arxiv.org/abs/2312.11819)

    提出了一种自适应模型部署和并行框架，用于加速RLHF训练。该框架提供了两种灵活的模型部署策略，其中交替策略有助于减少内存冗余和通信成本。

    

    最近，像ChatGPT或InstructGPT这样的大型语言模型（LLM）在人工智能领域产生了重大影响。许多研究尝试复现复杂的InstructGPT的训练流程，即基于人类反馈的强化学习（RLHF）。然而，主流的分布式RLHF训练方法通常采用固定的模型部署策略，称为Flattening策略。该策略将RLHF中涉及的四个相互依赖的模型视为单个实体，将它们分配到所有设备上，并应用于单个模型设计的并行技术，而不考虑每个模型固有的不同工作负载。结果，该策略加剧了RLHF训练中的生成瓶颈，并降低了整体训练效率。为了解决这些问题，我们提出了一种自适应模型部署框架，提供了两种灵活的模型部署策略。交替策略有助于减少内存冗余和通信成本。

    Recently, ChatGPT or InstructGPT like large language models (LLM) has made a significant impact in the AI world. Many works have attempted to reproduce the complex InstructGPT's training pipeline, namely Reinforcement Learning with Human Feedback (RLHF). However, the mainstream distributed RLHF training methods typically adopt a fixed model placement strategy, referred to as the Flattening strategy. This strategy treats all four interdependent models involved in RLHF as a single entity, distributing them across all devices and applying parallelism techniques designed for a single model, regardless of the different workloads inherent to each model. As a result, this strategy exacerbates the generation bottlenecks in the RLHF training and degrades the overall training efficiency. To address these issues, we propose an adaptive model placement framework that offers two flexible model placement strategies. The Interleaving strategy helps reduce memory redundancy and communication costs of 
    
[^32]: 透过变化的视角，可识别的潜在多项式因果模型

    Identifiable Latent Polynomial Causal Models Through the Lens of Change. (arXiv:2310.15580v1 [cs.LG])

    [http://arxiv.org/abs/2310.15580](http://arxiv.org/abs/2310.15580)

    本文通过扩展潜在因果模型的范围，从线性高斯模型转化为多项式模型，并研究了部分参数保持不变时的部分识别性结果。

    

    因果表示学习旨在从观察到的低级数据中揭示潜在的高级因果表示。其中一个主要任务是提供可靠的保证，以确保识别出这些潜在的因果模型，即可识别性。最近的一项突破性研究通过利用潜在因果变量之间在多个环境下的因果影响的变化来探索可识别性。然而，这一进展建立在潜在因果变量之间的因果关系严格遵循线性高斯模型的假设基础上。本文将潜在因果模型的范围扩展到涉及非线性因果关系的情况，这些关系由多项式模型表示，并且噪声分布符合指数分布族。此外，我们研究了对所有因果参数施加变化的必要性，并在部分参数保持不变的情况下提出了部分可识别性的结果。此外，我们提出了一种新颖的经验估计方法。

    Causal representation learning aims to unveil latent high-level causal representations from observed low-level data. One of its primary tasks is to provide reliable assurance of identifying these latent causal models, known as identifiability. A recent breakthrough explores identifiability by leveraging the change of causal influences among latent causal variables across multiple environments \citep{liu2022identifying}. However, this progress rests on the assumption that the causal relationships among latent causal variables adhere strictly to linear Gaussian models. In this paper, we extend the scope of latent causal models to involve nonlinear causal relationships, represented by polynomial models, and general noise distributions conforming to the exponential family. Additionally, we investigate the necessity of imposing changes on all causal parameters and present partial identifiability results when part of them remains unchanged. Further, we propose a novel empirical estimation me
    
[^33]: 关于多头注意力的优化与泛化

    On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])

    [http://arxiv.org/abs/2310.12680](http://arxiv.org/abs/2310.12680)

    本论文研究了使用多头注意力在优化和泛化方面的优势，推导了单层多头自注意力模型的梯度下降训练的收敛性和泛化保证，并证明了对于一个简单的分词混合模型，初始化条件满足可实现性条件。

    

    Transformer核心机制——Attention机制的训练和泛化动态仍未深入研究。此外，现有分析主要集中在单头注意力上。受到全连接网络训练时过参数化的益处启发，我们研究了使用多头注意力的潜在优化和泛化优势。为此，我们在数据的适当可实现性条件下，推导出单层多头自注意力模型的梯度下降训练的收敛性和泛化保证。然后，我们建立起初始化时确保可实现性得到满足的基本条件。最后，我们证明了这些条件适用于一个简单的分词混合模型。我们期望这个分析可以扩展到各种数据模型和架构变体。

    The training and generalization dynamics of the Transformer's core mechanism, namely the Attention mechanism, remain under-explored. Besides, existing analyses primarily focus on single-head attention. Inspired by the demonstrated benefits of overparameterization when training fully-connected networks, we investigate the potential optimization and generalization advantages of using multiple attention heads. Towards this goal, we derive convergence and generalization guarantees for gradient-descent training of a single-layer multi-head self-attention model, under a suitable realizability condition on the data. We then establish primitive conditions on the initialization that ensure realizability holds. Finally, we demonstrate that these conditions are satisfied for a simple tokenized-mixture model. We expect the analysis can be extended to various data-model and architecture variations.
    
[^34]: 什么是一个好问题？基于任务的询问与事实级遮蔽。

    What is a good question? Task-oriented asking with fact-level masking. (arXiv:2310.11571v1 [cs.CL])

    [http://arxiv.org/abs/2310.11571](http://arxiv.org/abs/2310.11571)

    本论文提出了基于任务的询问（TOA）的概念和框架，介绍了一种用于生成对推理任务有用答案的问题的方法。同时还提出了一种事实级遮蔽（FLM）的技术，用于将自然语言数据集转换为自我监督的TOA数据集。

    

    提问是现实生活中合作推理任务（如问答）的重要组成部分。例如，一个法律助手聊天机器人在没有用户情况的具体信息的情况下可能无法提供准确的建议。然而，通常会直接使用大型语言模型来解决推理任务，而不会向用户或第三方提出后续问题。我们将这个问题称为基于任务的询问（TOA）。零-shot聊天模型可以执行TOA，但它们的训练主要基于下一个词预测，而不是问题是否对成功的合作有帮助。为了能够训练和评估TOA模型，我们提出了自然语言任务导向询问的定义和框架，即生成能够为推理任务提供有用答案的问题的问题。我们还提出了事实级遮蔽（FLM）的方法，通过省略特定的部分将自然语言数据集转换为自我监督的TOA数据集。

    Asking questions is an important element of real-life collaboration on reasoning tasks like question answering. For example, a legal assistant chatbot may be unable to make accurate recommendations without specific information on the user's circumstances. However, large language models are usually deployed to solve reasoning tasks directly without asking follow-up questions to the user or third parties. We term this problem task-oriented asking (TOA). Zero-shot chat models can perform TOA, but their training is primarily based on next-token prediction rather than whether questions contribute to successful collaboration. To enable the training and evaluation of TOA models, we present a definition and framework for natural language task-oriented asking, the problem of generating questions that result in answers useful for a reasoning task. We also present fact-level masking (FLM), a procedure for converting natural language datasets into self-supervised TOA datasets by omitting particula
    
[^35]: EHI: 高效密集检索的层次索引的端到端学习

    EHI: End-to-end Learning of Hierarchical Index for Efficient Dense Retrieval. (arXiv:2310.08891v1 [cs.LG])

    [http://arxiv.org/abs/2310.08891](http://arxiv.org/abs/2310.08891)

    EHI是一种端到端学习的层次索引方法，用于高效密集检索。它同时学习嵌入和ANNS结构，通过使用密集路径嵌入来捕获索引的语义信息，以优化检索性能。

    

    密集嵌入式检索现已成为语义搜索和排名问题的行业标准，如获取给定查询的相关网络文档。这些技术使用了两个阶段的过程：(a)对比学习来训练双编码器以嵌入查询和文档，以及(b)近似最近邻搜索(ANNS)以查找给定查询的相似文档。这两个阶段是不相交的；学得的嵌入可能不适合ANNS方法，反之亦然，导致性能不佳。在这项工作中，我们提出了一种名为端到端层次索引(EHI)的方法，它同时学习嵌入和ANNS结构以优化检索性能。EHI使用标准的双编码器模型来嵌入查询和文档，同时学习一个倒排文件索引(IVF)风格的树状结构以实现高效的ANNS。为了确保离散基于树的ANNS结构的稳定和高效学习，EHI引入了密集路径嵌入的概念，用来捕获索引的语义信息。

    Dense embedding-based retrieval is now the industry standard for semantic search and ranking problems, like obtaining relevant web documents for a given query. Such techniques use a two-stage process: (a) contrastive learning to train a dual encoder to embed both the query and documents and (b) approximate nearest neighbor search (ANNS) for finding similar documents for a given query. These two stages are disjoint; the learned embeddings might be ill-suited for the ANNS method and vice-versa, leading to suboptimal performance. In this work, we propose End-to-end Hierarchical Indexing -- EHI -- that jointly learns both the embeddings and the ANNS structure to optimize retrieval performance. EHI uses a standard dual encoder model for embedding queries and documents while learning an inverted file index (IVF) style tree structure for efficient ANNS. To ensure stable and efficient learning of discrete tree-based ANNS structure, EHI introduces the notion of dense path embedding that capture
    
[^36]: 哪种模式更适合联合学习？中央化还是分散化。

    Which mode is better for federated learning? Centralized or Decentralized. (arXiv:2310.03461v1 [cs.LG])

    [http://arxiv.org/abs/2310.03461](http://arxiv.org/abs/2310.03461)

    中国总结出的一句话要点：研究发现在联合学习中，集中化的方法总是比分散化的方法更好地进行泛化，同时，部分参与在集中化方法中表现更好，而在分散化方法中，拓扑结构对性能的影响十分重要。

    

    在联合学习（FL）中，集中化和分散化方法都表现出了出色的性能和重要的应用价值。然而，目前的研究并没有提供足够的证据来表明哪种方法表现更好。虽然从优化的角度来看，分散化的方法可以通过较少的通信实现与集中化方法相比较的收敛性，但在实证研究中，它的测试性能始终效率低下。为了全面探索它们在联合学习中的行为，我们研究了它们的过度风险，包括优化和泛化的联合分析。我们证明了在光滑非凸目标上，1）集中化的FL（CFL）总是比分散化的FL（DFL）更好地进行泛化；2）从CFL的过度风险和测试误差的角度来看，部分参与比全参与更好；3）在DFL中，为了避免随着训练规模增加而性能崩溃，拓扑结构有必要满足一定的要求。基于一些实证结果

    Both centralized and decentralized approaches have shown excellent performance and great application value in federated learning (FL). However, current studies do not provide sufficient evidence to show which one performs better. Although from the optimization perspective, decentralized methods can approach the comparable convergence of centralized methods with less communication, its test performance has always been inefficient in empirical studies. To comprehensively explore their behaviors in FL, we study their excess risks, including the joint analysis of both optimization and generalization. We prove that on smooth non-convex objectives, 1) centralized FL (CFL) always generalizes better than decentralized FL (DFL); 2) from perspectives of the excess risk and test error in CFL, adopting partial participation is superior to full participation; and, 3) there is a necessary requirement for the topology in DFL to avoid performance collapse as the training scale increases. Based on some
    
[^37]: 通过梯度分位数剪切实现鲁棒性随机优化

    Robust Stochastic Optimization via Gradient Quantile Clipping. (arXiv:2309.17316v1 [stat.ML])

    [http://arxiv.org/abs/2309.17316](http://arxiv.org/abs/2309.17316)

    本文介绍了一种基于梯度分位数剪切的鲁棒性随机优化策略，适用于光滑目标且能容忍异常值和尾重样本。对于强凸目标，迭代收敛到集中分布并导出了估计误差的概率界。在非凸情况下，极限分布局部化在低梯度邻域上。使用滚动分位数实现的算法具有很强的鲁棒性和高效性。

    

    我们提出了一种基于梯度范数分位数作为剪切阈值的策略，用于随机梯度下降 (SGD)。我们证明了这种新策略在光滑目标（凸或非凸）下提供了一种鲁棒且高效的优化算法，能够容忍尾重样本（包括无限方差）和数据流中的异常值，类似于 Huber 污染模型。我们的数学分析利用了恒定步长的 SGD 和马尔可夫链之间的联系，并以独特的方式处理剪切引入的偏差。对于强凸目标，我们证明迭代收敛到一个集中分布，并导出了最终估计误差的高概率界。在非凸情况下，我们证明极限分布局部化在低梯度邻域上。我们提出了一种使用滚动分位数实现此算法的方法，从而得到了一种高效的优化过程，具有很强的鲁棒性。

    We introduce a clipping strategy for Stochastic Gradient Descent (SGD) which uses quantiles of the gradient norm as clipping thresholds. We prove that this new strategy provides a robust and efficient optimization algorithm for smooth objectives (convex or non-convex), that tolerates heavy-tailed samples (including infinite variance) and a fraction of outliers in the data stream akin to Huber contamination. Our mathematical analysis leverages the connection between constant step size SGD and Markov chains and handles the bias introduced by clipping in an original way. For strongly convex objectives, we prove that the iteration converges to a concentrated distribution and derive high probability bounds on the final estimation error. In the non-convex case, we prove that the limit distribution is localized on a neighborhood with low gradient. We propose an implementation of this algorithm using rolling quantiles which leads to a highly efficient optimization procedure with strong robustn
    
[^38]: AR-TTA: 一种用于真实世界连续测试时间自适应的简单方法

    AR-TTA: A Simple Method for Real-World Continual Test-Time Adaptation. (arXiv:2309.10109v1 [cs.CV])

    [http://arxiv.org/abs/2309.10109](http://arxiv.org/abs/2309.10109)

    AR-TTA提出了一种简单的方法用于真实世界连续测试时间自适应。通过将内存缓冲区纳入自训练框架，并根据数据流的强度进行动态适应，提高了模型的稳定性。

    

    测试时间自适应是一种有前景的研究方向，它允许源模型在没有任何监督的情况下适应数据分布的变化。然而，当前的方法通常在只是实际场景简化版本的基准测试中进行评估。因此，我们建议使用最近推出的自动驾驶数据集CLAD-C和SHIFT来验证测试时间自适应方法。我们观察到，当前的测试时间自适应方法往往难以有效处理不同程度的域偏移，常常导致性能下降，低于源模型。我们注意到问题的根源在于无法保留源模型的知识，并且无法适应动态变化、时间相关的数据流。因此，我们通过将一个小的内存缓冲区纳入到成熟的自训练框架中，增加模型的稳定性，并同时根据数据流的强度进行动态适应。

    Test-time adaptation is a promising research direction that allows the source model to adapt itself to changes in data distribution without any supervision. Yet, current methods are usually evaluated on benchmarks that are only a simplification of real-world scenarios. Hence, we propose to validate test-time adaptation methods using the recently introduced datasets for autonomous driving, namely CLAD-C and SHIFT. We observe that current test-time adaptation methods struggle to effectively handle varying degrees of domain shift, often resulting in degraded performance that falls below that of the source model. We noticed that the root of the problem lies in the inability to preserve the knowledge of the source model and adapt to dynamically changing, temporally correlated data streams. Therefore, we enhance well-established self-training framework by incorporating a small memory buffer to increase model stability and at the same time perform dynamic adaptation based on the intensity of 
    
[^39]: 具有未测混淆因素的广义线性模型的同时推断

    Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])

    [http://arxiv.org/abs/2309.07261](http://arxiv.org/abs/2309.07261)

    本文研究了存在混淆效应时的广义线性模型的大规模假设检验问题，并提出了一种利用正交结构和线性投影的统计估计和推断框架，解决了由于未测混淆因素引起的偏差问题。

    

    在基因组研究中，常常进行成千上万个同时假设检验，以确定差异表达的基因。然而，由于存在未测混淆因素，许多标准统计方法可能存在严重的偏差。本文研究了存在混淆效应时的多元广义线性模型的大规模假设检验问题。在任意混淆机制下，我们提出了一个统一的统计估计和推断方法，利用正交结构并将线性投影整合到三个关键阶段中。首先，利用多元响应变量分离边际和不相关的混淆效应，恢复混淆系数的列空间。随后，利用$\ell_1$正则化进行稀疏性估计，并强加正交性限制于混淆系数，联合估计潜在因子和主要效应。最后，我们结合投影和加权偏差校正步骤。

    Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
    
[^40]: 专业性与广泛性：关于基础模型微调中灾难性遗忘的实证研究

    Speciality vs Generality: An Empirical Study on Catastrophic Forgetting in Fine-tuning Foundation Models. (arXiv:2309.06256v1 [cs.LG])

    [http://arxiv.org/abs/2309.06256](http://arxiv.org/abs/2309.06256)

    本研究实证了基础模型微调中的灾难性遗忘现象，微调过程中追求专业性会导致模型的广泛性损失。

    

    基础模型，包括视觉语言模型(VLMs)和大型语言模型(LLMs)，具有处理多样分布和任务的广泛性，这源于它们广泛的预训练数据集。对基础模型进行微调是提高任务性能或调整模型行为与人类期望一致的常见做法，使其获得专业性。然而，用于微调的小型数据集可能无法充分覆盖预训练过程中遇到的多样分布和任务。因此，追求微调过程中的专业性可能导致模型的广泛性损失，这与深度学习中的灾难性遗忘(Catastrophic Forgetting, CF)相关。在本研究中，我们展示了这种现象在VLMs和LLMs中的存在。例如，对像CLIP这样的VLM进行在ImageNet上的微调会导致处理多样分布的广泛性损失，对医学领域的Galactica进行微调则会导致遵循指令的能力损失。

    Foundation models, including Vision Language Models (VLMs) and Large Language Models (LLMs), possess the $generality$ to handle diverse distributions and tasks, which stems from their extensive pre-training datasets. The fine-tuning of foundation models is a common practice to enhance task performance or align the model's behavior with human expectations, allowing them to gain $speciality$. However, the small datasets used for fine-tuning may not adequately cover the diverse distributions and tasks encountered during pre-training. Consequently, the pursuit of speciality during fine-tuning can lead to a loss of {generality} in the model, which is related to catastrophic forgetting (CF) in deep learning. In this study, we demonstrate this phenomenon in both VLMs and LLMs. For instance, fine-tuning VLMs like CLIP on ImageNet results in a loss of generality in handling diverse distributions, and fine-tuning LLMs like Galactica in the medical domain leads to a loss in following instructions
    
[^41]: 纯粹的消息传递可以估计共同邻居进行链路预测

    Pure Message Passing Can Estimate Common Neighbor for Link Prediction. (arXiv:2309.00976v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.00976](http://arxiv.org/abs/2309.00976)

    这篇论文提出了一种纯粹的消息传递方法，用于估计共同邻居进行链路预测。该方法通过利用输入向量的正交性来捕捉联合结构特征，提出了一种新的链路预测模型MPLP，该模型利用准正交向量估计链路级结构特征，同时保留了节点级复杂性。

    

    消息传递神经网络（MPNN）已成为图表示学习中的事实标准。然而，在链路预测方面，它们往往表现不佳，被简单的启发式算法如共同邻居（CN）所超越。这种差异源于一个根本限制：尽管MPNN在节点级表示方面表现出色，但在编码链路预测中至关重要的联合结构特征（如CN）方面则遇到困难。为了弥合这一差距，我们认为通过利用输入向量的正交性，纯粹的消息传递确实可以捕捉到联合结构特征。具体而言，我们研究了MPNN在近似CN启发式算法方面的能力。基于我们的发现，我们引入了一种新的链路预测模型——消息传递链路预测器（MPLP）。MPLP利用准正交向量估计链路级结构特征，同时保留节点级复杂性。此外，我们的方法表明利用消息传递捕捉结构特征能够改善链路预测性能。

    Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto} standard in graph representation learning. However, when it comes to link prediction, they often struggle, surpassed by simple heuristics such as Common Neighbor (CN). This discrepancy stems from a fundamental limitation: while MPNNs excel in node-level representation, they stumble with encoding the joint structural features essential to link prediction, like CN. To bridge this gap, we posit that, by harnessing the orthogonality of input vectors, pure message-passing can indeed capture joint structural features. Specifically, we study the proficiency of MPNNs in approximating CN heuristics. Based on our findings, we introduce the Message Passing Link Predictor (MPLP), a novel link prediction model. MPLP taps into quasi-orthogonal vectors to estimate link-level structural features, all while preserving the node-level complexities. Moreover, our approach demonstrates that leveraging message-passing to capture stru
    
[^42]: Flamingo: 多轮单服务器安全聚合及其在私有联邦学习中的应用

    Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning. (arXiv:2308.09883v1 [cs.CR])

    [http://arxiv.org/abs/2308.09883](http://arxiv.org/abs/2308.09883)

    Flamingo是一个用于实现跨大量客户端安全聚合的系统，在私有联邦学习中有广泛的应用。通过消除每轮设置和引入轻量级的丢失容忍协议，Flamingo解决了以往协议在多轮设置下的问题，并引入了新的本地选择客户端邻域的方式。

    

    本文介绍了Flamingo，这是一个用于跨大量客户端安全聚合数据的系统。在安全聚合中，服务器对客户端的私有输入进行求和，并在不了解个体输入的情况下得到结果，仅能推断出最终总和。Flamingo专注于联邦学习中的多轮设置，其中执行多个连续的模型权重求和（平均），以得到一个良好的模型。之前的协议（例如Bell等人的CCS '20）仅适用于单轮，并通过多次重复该协议来适应联邦学习的设置。Flamingo消除了之前协议每轮设置的需求，并引入了一种新的轻量级的丢失容忍协议，以确保如果客户端在求和过程中离开，服务器仍然可以获得有意义的结果。此外，Flamingo还引入了一种新的本地选择所谓的客户端邻域的方式，此概念由Bell等人提出。

    This paper introduces Flamingo, a system for secure aggregation of data across a large set of clients. In secure aggregation, a server sums up the private inputs of clients and obtains the result without learning anything about the individual inputs beyond what is implied by the final sum. Flamingo focuses on the multi-round setting found in federated learning in which many consecutive summations (averages) of model weights are performed to derive a good model. Previous protocols, such as Bell et al. (CCS '20), have been designed for a single round and are adapted to the federated learning setting by repeating the protocol multiple times. Flamingo eliminates the need for the per-round setup of previous protocols, and has a new lightweight dropout resilience protocol to ensure that if clients leave in the middle of a sum the server can still obtain a meaningful result. Furthermore, Flamingo introduces a new way to locally choose the so-called client neighborhood introduced by Bell et al
    
[^43]: Stackelberg轨迹博弈中的主动逆向学习

    Active Inverse Learning in Stackelberg Trajectory Games. (arXiv:2308.08017v1 [cs.GT])

    [http://arxiv.org/abs/2308.08017](http://arxiv.org/abs/2308.08017)

    这项研究提出了一种在Stackelberg博弈中的主动逆向学习方法，通过活跃地最大化跟随者在不同假设下的轨迹差异来加速领导者的推断过程。

    

    博弈论的逆向学习是从玩家的行为中推断出他们的目标的问题。我们在一个Stackelberg博弈中，通过每个玩家的动态系统轨迹来定义一个逆向学习问题，其中包括一个领导者和一个跟随者。我们提出了一种主动逆向学习方法，让领导者推断出一个有限候选集中描述跟随者目标函数的假设。与现有方法使用被动观察到的轨迹不同，所提出的方法主动地最大化不同假设下跟随者轨迹的差异，加速领导者的推断过程。我们在一个递进的重复轨迹博弈中展示了所提出的方法。与均匀随机输入相比，所提供的方法加速了概率收敛到条件于跟随者轨迹的不同假设上的收敛速度。

    Game-theoretic inverse learning is the problem of inferring the players' objectives from their actions. We formulate an inverse learning problem in a Stackelberg game between a leader and a follower, where each player's action is the trajectory of a dynamical system. We propose an active inverse learning method for the leader to infer which hypothesis among a finite set of candidates describes the follower's objective function. Instead of using passively observed trajectories like existing methods, the proposed method actively maximizes the differences in the follower's trajectories under different hypotheses to accelerate the leader's inference. We demonstrate the proposed method in a receding-horizon repeated trajectory game. Compared with uniformly random inputs, the leader inputs provided by the proposed method accelerate the convergence of the probability of different hypotheses conditioned on the follower's trajectory by orders of magnitude.
    
[^44]: 从多任务非独立同分布数据中元学习操作符到最优性

    Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])

    [http://arxiv.org/abs/2308.04428](http://arxiv.org/abs/2308.04428)

    本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。

    

    机器学习中最近取得进展的一个强大概念是从异构来源或任务的数据中提取共同特征。直观地说，将所有数据用于学习共同的表示函数，既有助于计算效率，又有助于统计泛化，因为它可以减少要在给定任务上进行微调的参数数量。为了在理论上做出这些优点的根源，我们提出了从噪声向量测量$y = Mx + w$中回复线性操作符$M$的一般模型。其中，协变量$x$既可以是非独立同分布的，也可以是非各向同性的。我们证明了现有的各向同性无关的元学习方法会对表示更新造成偏差，这导致噪声项的缩放不再有利于源任务数量。这反过来会导致表示学习的样本复杂性受到单任务数据规模的限制。我们引入了一种方法，称为去偏差和特征白化。

    A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias & Feature-Whiten}
    
[^45]: 使用组合扩散模型实现训练数据保护

    Training Data Protection with Compositional Diffusion Models. (arXiv:2308.01937v1 [cs.LG])

    [http://arxiv.org/abs/2308.01937](http://arxiv.org/abs/2308.01937)

    使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。

    

    我们引入了分区扩散模型（CDM），一种在不同数据源上训练不同扩散模型（或提示）并在推断时任意组合它们的方法。这些单独的模型可以在孤立状态下、在不同时间、在不同分布和领域上进行训练，并可以后续组合以达到与同时训练所有数据的理想模型相当的性能。此外，每个模型只包含其在训练期间接触到的数据子集的信息，可以实现多种形式的训练数据保护。特别是，CDM是第一种可以实现大规模扩散模型的选择性遗忘和持续学习的方法，并且允许根据用户访问权限提供定制模型。CDM还可以确定生成特定样本的数据子集的重要性。

    We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
    
[^46]: 加权变差空间与浅层ReLU网络的逼近

    Weighted variation spaces and approximation by shallow ReLU networks. (arXiv:2307.15772v1 [stat.ML])

    [http://arxiv.org/abs/2307.15772](http://arxiv.org/abs/2307.15772)

    本文研究了在有界域上通过单隐藏层ReLU网络逼近函数的问题，介绍了新的模型类定义加权变差空间，该定义与域本身相关。

    

    本文研究了在有界域Ω⊂Rd上，通过宽度为n的单隐藏层ReLU神经网络的输出来逼近函数f的情况。这种非线性的n项字典逼近已经得到广泛研究，因为它是神经网络逼近(NNA)的最简单情况。对于这种NNA形式，有几个著名的逼近结果，引入了在Ω上的函数的新型模型类，其逼近速率避免了维数灾难。这些新型模型类包括Barron类和基于稀疏性或变差的类，例如Radon域BV类。本文关注于在域Ω上定义这些新型模型类。当前这些模型类的定义不依赖于域Ω。通过引入加权变差空间的概念，给出了关于域的更恰当的模型类定义。这些新型模型类与域本身相关。

    We investigate the approximation of functions $f$ on a bounded domain $\Omega\subset \mathbb{R}^d$ by the outputs of single-hidden-layer ReLU neural networks of width $n$. This form of nonlinear $n$-term dictionary approximation has been intensely studied since it is the simplest case of neural network approximation (NNA). There are several celebrated approximation results for this form of NNA that introduce novel model classes of functions on $\Omega$ whose approximation rates avoid the curse of dimensionality. These novel classes include Barron classes, and classes based on sparsity or variation such as the Radon-domain BV classes.  The present paper is concerned with the definition of these novel model classes on domains $\Omega$. The current definition of these model classes does not depend on the domain $\Omega$. A new and more proper definition of model classes on domains is given by introducing the concept of weighted variation spaces. These new model classes are intrinsic to th
    
[^47]: 非平滑非凸优化中随机次梯度方法的收敛性保证

    Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])

    [http://arxiv.org/abs/2307.10053](http://arxiv.org/abs/2307.10053)

    本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。

    

    本文研究了随机梯度下降（SGD）方法及其变种在训练由非平滑激活函数构建的神经网络中的收敛性质。我们提出了一种新颖的框架，为更新动量项和变量的步长分配了不同的时间尺度。在一些温和的条件下，我们证明了我们提出的框架在单时间尺度和双时间尺度情况下的全局收敛性。我们还证明了我们提出的框架包含了很多已知的SGD类型方法，包括heavy-ball SGD、SignSGD、Lion、normalized SGD和clipped SGD。此外，当目标函数采用有限和形式时，我们基于我们提出的框架证明了这些SGD类型方法的收敛性质。特别地，在温和的假设下，我们证明了这些SGD类型方法在随机选择的步长和初始点上能够找到目标函数的Clarke稳定点。

    In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
    
[^48]: 深度学习中的损失函数和度量方法：一项评论

    Loss Functions and Metrics in Deep Learning. A Review. (arXiv:2307.02694v1 [cs.LG])

    [http://arxiv.org/abs/2307.02694](http://arxiv.org/abs/2307.02694)

    本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。

    

    深度学习的一个重要组成部分是选择用于训练和评估模型的损失函数和性能度量。本文回顾了深度学习中最常见的损失函数和性能测量方法。我们探讨了每种技术的优势和局限性，并举例说明它们在各种深度学习问题上的应用。我们的评论旨在全面了解最常见的深度学习任务中使用的不同损失函数和性能指标，并帮助从业者选择最适合其特定任务的方法。

    One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.
    
[^49]: DiMSam:扩散模型作为部分可观测任务与动作规划中的采样器。

    DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability. (arXiv:2306.13196v1 [cs.RO])

    [http://arxiv.org/abs/2306.13196](http://arxiv.org/abs/2306.13196)

    本文提出了一种使用扩散模型作为采样器的任务和动作规划方法，在部分可观测下能够实现长周期受约束的操作计划。

    

    任务和动作规划（TAMP）方法非常有效地计划长周期自主机器人操作。但是，由于它们需要一个规划模型，因此在环境和其动态不完全了解的领域中应用它们可能非常困难。我们提出通过利用深度生成建模，特别是扩散模型来克服这些限制，学习捕获规划模型中难以设计的约束和采样器。这些学习采样器在TAMP求解器中组合和合并，以联合找到满足规划中约束的行动参数值。为了便于对环境中未知对象进行预测，我们将这些采样器定义为学习的低维潜变量嵌入的可变对象状态。我们在关节式物体操作领域评估了我们的方法，并展示了经典TAMP、生成学习和潜在嵌入的组合如何使得在部分可观测下进行长周期受约束的操作计划。

    Task and Motion Planning (TAMP) approaches are effective at planning long-horizon autonomous robot manipulation. However, because they require a planning model, it can be difficult to apply them to domains where the environment and its dynamics are not fully known. We propose to overcome these limitations by leveraging deep generative modeling, specifically diffusion models, to learn constraints and samplers that capture these difficult-to-engineer aspects of the planning model. These learned samplers are composed and combined within a TAMP solver in order to find action parameter values jointly that satisfy the constraints along a plan. To tractably make predictions for unseen objects in the environment, we define these samplers on low-dimensional learned latent embeddings of changing object state. We evaluate our approach in an articulated object manipulation domain and show how the combination of classical TAMP, generative learning, and latent embeddings enables long-horizon constra
    
[^50]: DynaQuant: 通过动态量化压缩深度学习训练检查点

    DynaQuant: Compressing Deep Learning Training Checkpoints via Dynamic Quantization. (arXiv:2306.11800v1 [cs.LG])

    [http://arxiv.org/abs/2306.11800](http://arxiv.org/abs/2306.11800)

    DynaQuant通过动态量化实现对各种最先进模型的显着压缩，几乎不影响模型准确性。

    

    随着深度学习训练工作量在计算资源和时间消耗方面的增加，遇到训练失败的可能性显著增加，导致工作丢失和资源浪费。最新的方法涉及有损模型压缩机制，这会在模型质量（准确性）和压缩比之间产生权衡。我们提出了一个新颖的动态量化框架，称为DynaQuant，它可以根据训练期间模型权重的灵敏度变化来更新量化级别，从而实现对各种最先进模型的显着压缩，并且几乎不影响模型准确性。

    With the increase in the scale of Deep Learning (DL) training workloads in terms of compute resources and time consumption, the likelihood of encountering in-training failures rises substantially, leading to lost work and resource wastage. Such failures are typically offset by a checkpointing mechanism, which comes at the cost of storage and network bandwidth overhead. State-of-the-art approaches involve lossy model compression mechanisms, which induce a tradeoff between the resulting model quality (accuracy) and compression ratio. Delta compression is then also used to further reduce the overhead by only storing the difference between consecutive checkpoints. We make a key enabling observation that the sensitivity of model weights to compression varies during training, and different weights benefit from different quantization levels (ranging from retaining full precision to pruning). We propose (1) a non-uniform quantization scheme that leverages this variation, (2) an efficient searc
    
[^51]: 循环记忆决策变压器

    Recurrent Memory Decision Transformer. (arXiv:2306.09459v1 [cs.LG])

    [http://arxiv.org/abs/2306.09459](http://arxiv.org/abs/2306.09459)

    本文提出了循环记忆决策变压器（RMDT）模型，用于处理强化学习中的长序列问题。在Atari游戏和MoJoCo控制问题上的实验表明，采用循环记忆机制的RMDT模型显着优于其没有循环记忆机制的对应模型。

    

    变革性模型最初是为自然语言问题而开发的，最近在离线强化学习任务中得到广泛应用。这是因为代理的历史可以表示为序列，并且整个任务可以缩减为序列建模任务。然而，变压器操作的二次复杂性限制了上下文的潜在增加。因此，为了在自然语言中处理长序列，使用了不同版本的记忆机制。在本文中，我们提出了循环记忆决策变压器（RMDT），这是一种在强化学习问题中使用循环记忆机制的模型。我们在Atari游戏和MoJoCo控制问题上进行了彻底的实验，并表明我们提出的模型在Atari游戏上显着优于没有循环记忆机制的对应模型。我们还仔细研究了记忆对所提出的模型绩效的影响。这些发现为开发更高效和更有效的处理长序列的强化学习模型提供了启示。

    Transformative models, originally developed for natural language problems, have recently been widely used in offline reinforcement learning tasks. This is due to the fact that the agent's history can be represented as a sequence, and the whole task can be reduced to the sequence modeling task. However, the quadratic complexity of the transformer operation limits the potential increase in context. Therefore, to work with long sequences in a natural language, different versions of the memory mechanism are used. In this paper, we propose the Recurrent Memory Decision Transformer (RMDT), a model that uses a recurrent memory mechanism for reinforcement learning problems. We conduct thorough experiments on Atari games and MoJoCo control problems, and show that our proposed model is significantly superior to its counterparts without the recurrent memory mechanism on Atari games. We also carefully study the effect of memory on the performance of the proposed model. These findings shed light on
    
[^52]: 随机加权梯度下降通过分布健壮优化

    Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization. (arXiv:2306.09222v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09222](http://arxiv.org/abs/2306.09222)

    我们通过分布健壮优化和重要性加权的梯度下降技术提升了深度神经网络的性能，并在各种任务上取得了优越的结果。

    

    我们通过在每一次优化步骤中对数据点进行重要性加权，开发了一种提高深度神经网络性能的加权梯度下降技术。我们的方法受到分布健壮优化和f-散度的启发，已知可以得到具有改进的泛化保证的模型。我们的加权方案简单、计算高效，可以与许多流行的优化算法（如SGD和Adam）结合使用。实验证明，我们的方法在各种任务上都表现出了优越性能，包括监督学习和领域适应。值得注意的是，我们在DomainBed和Tabular分类基准上分别比现有最佳结果提升了0.7%和1.44%。此外，我们的算法将BERT在GLUE基准上的性能提升了1.94%，将ViT在ImageNet-1K上的性能提升了1.01%。这些结果表明了所提出方法的有效性，预示着它在改善性能方面的潜力。

    We develop a re-weighted gradient descent technique for boosting the performance of deep neural networks, which involves importance weighting of data points during each optimization step. Our approach is inspired by distributionally robust optimization with f-divergences, which has been known to result in models with improved generalization guarantees. Our re-weighting scheme is simple, computationally efficient, and can be combined with many popular optimization algorithms such as SGD and Adam. Empirically, we demonstrate the superiority of our approach on various tasks, including supervised learning, domain adaptation. Notably, we obtain improvements of +0.7% and +1.44% over SOTA on DomainBed and Tabular classification benchmarks, respectively. Moreover, our algorithm boosts the performance of BERT on GLUE benchmarks by +1.94%, and ViT on ImageNet-1K by +1.01%. These results demonstrate the effectiveness of the proposed approach, indicating its potential for improving performance in 
    
[^53]: 剪枝方式提高可靠策略：一种多目标深度Q学习方法应用于重症护理

    Pruning the Way to Reliable Policies: A Multi-Objective Deep Q-Learning Approach to Critical Care. (arXiv:2306.08044v1 [cs.LG])

    [http://arxiv.org/abs/2306.08044](http://arxiv.org/abs/2306.08044)

    该论文介绍了一种深度Q学习方法，通过剪枝动作集来实现将中间生物标志物信号整合到奖励规范中，提高了重症护理策略的可靠性。

    

    大多数医疗决策具有连续性，因此，强化学习可能有望制定精确的数据驱动治疗计划。然而，该领域的主要挑战之一是主要基于死亡率的奖励函数的稀疏性，导致离线估计的稳定性降低。本研究引入了一种深度Q学习方法，能够获得更可靠的重症护理策略。该方法将相关但嘈杂的中间生物标志物信号整合到奖励规范中，同时不会损害感兴趣的主要结果（例如患者生存率）的优化。通过根据所有可用奖励对动作集进行剪枝，然后基于稀疏主要奖励，使用受限动作集进行最终模型训练，通过解离准确和近似奖励来最小化主要目标的潜在扭曲，实现了上述目标。

    Most medical treatment decisions are sequential in nature. Hence, there is substantial hope that reinforcement learning may make it possible to formulate precise data-driven treatment plans. However, a key challenge for most applications in this field is the sparse nature of primarily mortality-based reward functions, leading to decreased stability of offline estimates. In this work, we introduce a deep Q-learning approach able to obtain more reliable critical care policies. This method integrates relevant but noisy intermediate biomarker signals into the reward specification, without compromising the optimization of the main outcome of interest (e.g. patient survival). We achieve this by first pruning the action set based on all available rewards, and second training a final model based on the sparse main reward but with a restricted action set. By disentangling accurate and approximated rewards through action pruning, potential distortions of the main objective are minimized, all whi
    
[^54]: MuZero学到了什么模型？

    What model does MuZero learn?. (arXiv:2306.00840v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.00840](http://arxiv.org/abs/2306.00840)

    本文研究了MuZero算法，发现它学习到的模型无法有效推广到评估未见策略，限制了其对当前策略的进一步改进。

    

    近年来，基于模型的强化学习引起了广泛关注，因为它有望提高样本效率。此外，当使用深度学习模型时，有可能从复杂的传感器数据中学习到紧凑的模型。然而，这些学习到的模型的有效性，特别是它们规划能力的提升当前策略的能力，仍然不清楚。在本研究中，我们研究了MuZero这个著名的基于深度模型的强化学习算法，并探讨了它在实现值等价模型的学习目标上的成就以及学习到的模型对策略改进的实用性。在诸多其他观点中，我们得出结论：MuZero学到的模型无法有效地推广到评估未见策略，这限制了我们通过模型规划来进一步改进当前策略的程度。

    Model-based reinforcement learning has drawn considerable interest in recent years, given its promise to improve sample efficiency. Moreover, when using deep-learned models, it is potentially possible to learn compact models from complex sensor data. However, the effectiveness of these learned models, particularly their capacity to plan, i.e., to improve the current policy, remains unclear. In this work, we study MuZero, a well-known deep model-based reinforcement learning algorithm, and explore how far it achieves its learning objective of a value-equivalent model and how useful the learned models are for policy improvement. Amongst various other insights, we conclude that the model learned by MuZero cannot effectively generalize to evaluate unseen policies, which limits the extent to which we can additionally improve the current policy by planning with the model.
    
[^55]: 训练期间的自适应秩谱剪枝卷积层

    Rank-adaptive spectral pruning of convolutional layers during training. (arXiv:2305.19059v1 [cs.LG])

    [http://arxiv.org/abs/2305.19059](http://arxiv.org/abs/2305.19059)

    本论文提出了一种新的低参数训练方法，该方法将卷积分解为张量Tucker格式，并在训练过程中自适应地修剪卷积核的Tucker秩，可以有效地降低训练成本。

    

    深度学习模型在计算成本和内存需求方面增长迅速，因此已经发展了各种剪枝技术以减少模型参数。大多数技术侧重于通过在完整训练后对网络进行修剪以减少推理成本。少量的方法解决了减少训练成本的问题，主要是通过低秩层分解来压缩网络。尽管这些方法对于线性层是有效的，但是它们无法有效处理卷积滤波器。在这项工作中，我们提出了一种低参数训练方法，将卷积分解为张量Tucker格式，并在训练过程中自适应地修剪卷积核的Tucker秩。利用微分方程在张量流形上的几何积分理论的基本结果，我们获得了一个鲁棒的训练算法，证明能够逼近完整的基线性能并保证损失下降。

    The computing cost and memory demand of deep learning pipelines have grown fast in recent years and thus a variety of pruning techniques have been developed to reduce model parameters. The majority of these techniques focus on reducing inference costs by pruning the network after a pass of full training. A smaller number of methods address the reduction of training costs, mostly based on compressing the network via low-rank layer factorizations. Despite their efficiency for linear layers, these methods fail to effectively handle convolutional filters. In this work, we propose a low-parametric training method that factorizes the convolutions into tensor Tucker format and adaptively prunes the Tucker ranks of the convolutional kernel during training. Leveraging fundamental results from geometric integration theory of differential equations on tensor manifolds, we obtain a robust training algorithm that provably approximates the full baseline performance and guarantees loss descent. A var
    
[^56]: 特权知识蒸馏用于 Sim-to-Real 策略泛化

    Privileged Knowledge Distillation for Sim-to-Real Policy Generalization. (arXiv:2305.18464v1 [cs.LG])

    [http://arxiv.org/abs/2305.18464](http://arxiv.org/abs/2305.18464)

    论文提出了一种新的单阶段特权知识蒸馏方法（HIB），通过捕捉历史轨迹的特权知识表示来学习，缩小模拟和真实之间的差距。

    

    强化学习最近在机器人控制方面取得了显著的成功。但是，多数强化学习方法在模拟环境中运行，那里的特权知识（例如动力学，环境，地形）是轻松获取的。相反，在真实场景中，机器人代理通常仅依赖于本地状态（例如机器人关节的本体感反馈）来选择动作，导致显著的模拟到真实的差距。现有方法通过逐渐减少对特权知识的依赖或执行两阶段策略模仿来解决这个差距。但我们认为，这些方法在充分利用特权知识的能力方面存在局限性，导致性能次优。本文提出了一种称为历史信息瓶颈（HIB）的新型单阶段特权知识蒸馏方法，以缩小模拟到真实的差距。具体而言，HIB通过捕捉历史轨迹的特权知识表示来学习。

    Reinforcement Learning (RL) has recently achieved remarkable success in robotic control. However, most RL methods operate in simulated environments where privileged knowledge (e.g., dynamics, surroundings, terrains) is readily available. Conversely, in real-world scenarios, robot agents usually rely solely on local states (e.g., proprioceptive feedback of robot joints) to select actions, leading to a significant sim-to-real gap. Existing methods address this gap by either gradually reducing the reliance on privileged knowledge or performing a two-stage policy imitation. However, we argue that these methods are limited in their ability to fully leverage the privileged knowledge, resulting in suboptimal performance. In this paper, we propose a novel single-stage privileged knowledge distillation method called the Historical Information Bottleneck (HIB) to narrow the sim-to-real gap. In particular, HIB learns a privileged knowledge representation from historical trajectories by capturing 
    
[^57]: 改进ReLU网络特征学习的神经特征激活值分析

    Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning. (arXiv:2305.15912v1 [cs.LG])

    [http://arxiv.org/abs/2305.15912](http://arxiv.org/abs/2305.15912)

    本文提出了一种利用ReLU单元特征激活值集合进行参数化的几何方法，通过利用现代深度学习架构中的规范化技术，改进了ReLU网络特征学习，提高了优化稳定性和收敛速度，并获得更好的泛化性能。

    

    本文研究了神经网络中单个ReLU单元的特征激活值。我们将ReLU单元在输入空间中对应的特征激活值集合称为ReLU单元的特征激活集。我们建立了特征激活集与ReLU网络中学习特征之间的明确联系，并揭示了现代深度学习架构中使用的各种神经网络规范化技术如何规范化和稳定SGD优化。利用这些洞见，我们提出了一种几何方法来参数化ReLU网络以改进特征学习。我们经验性地验证了其有用性，使用了不那么精心选择的初始化方案和更大的学习率。我们报告了更好的优化稳定性，更快的收敛速度和更好的泛化性能。

    We examine the characteristic activation values of individual ReLU units in neural networks. We refer to the corresponding set for such characteristic activation values in the input space as the characteristic activation set of a ReLU unit. We draw an explicit connection between the characteristic activation set and learned features in ReLU networks. This connection leads to new insights into why various neural network normalization techniques used in modern deep learning architectures regularize and stabilize SGD optimization. Utilizing these insights, we propose a geometric approach to parameterize ReLU networks for improved feature learning. We empirically verify its usefulness with less carefully chosen initialization schemes and larger learning rates. We report improved optimization stability, faster convergence speed, and better generalization performance.
    
[^58]: 解耦式KL散度损失函数

    Decoupled Kullback-Leibler Divergence Loss. (arXiv:2305.13948v1 [cs.CV])

    [http://arxiv.org/abs/2305.13948](http://arxiv.org/abs/2305.13948)

    本文提出了改进的KL散度损失函数，通过解决解耦式KL散度损失函数的对称性限制和引入全局信息来提升性能，在CIFAR-10/100和ImageNet数据集上展示了其在对抗训练和知识蒸馏任务中的优越表现。

    

    本文更深入地探究了KL散度损失函数，并发现它与解耦式KL散度损失函数等价，后者由加权均方差损失和包含软标签的交叉熵损失组成。通过对解耦式KL散度损失函数的分析，本文确定了两个改进方向。首先，我们解决了在知识蒸馏等场景下解耦式KL散度损失函数的对称性限制问题。这个改进保证了在训练期间wMSE组件始终有效，提供额外的构造性暗示。其次，我们将全局信息引入解耦式KL散度损失函数中，用于类内一致性正则化。通过这两个改进，我们得到了改进的KL散度损失函数，通过在CIFAR-10/100和ImageNet数据集上进行实验来评估其有效性，重点是对抗训练和知识蒸馏任务。所提出的方法表现出了比其他最先进模型更优越的性能，展示了其在各种实际应用中的潜力。

    In this paper, we delve deeper into the Kullback-Leibler (KL) Divergence loss and observe that it is equivalent to the Doupled Kullback-Leibler (DKL) Divergence loss that consists of 1) a weighted Mean Square Error (wMSE) loss and 2) a Cross-Entropy loss incorporating soft labels. From our analysis of the DKL loss, we have identified two areas for improvement. Firstly, we address the limitation of DKL in scenarios like knowledge distillation by breaking its asymmetry property in training optimization. This modification ensures that the wMSE component is always effective during training, providing extra constructive cues. Secondly, we introduce global information into DKL for intra-class consistency regularization. With these two enhancements, we derive the Improved Kullback-Leibler (IKL) Divergence loss and evaluate its effectiveness by conducting experiments on CIFAR-10/100 and ImageNet datasets, focusing on adversarial training and knowledge distillation tasks. The proposed approach 
    
[^59]: 随机特征模型和双层神经网络的泛化分析的对偶性框架

    A duality framework for generalization analysis of random feature models and two-layer neural networks. (arXiv:2305.05642v1 [stat.ML])

    [http://arxiv.org/abs/2305.05642](http://arxiv.org/abs/2305.05642)

    本文提出了一个针对随机特征模型和双层神经网络的泛化分析的对偶性框架，并证明了学习不会受到维数灾难的影响，使 RFMs 可以在核范围之外发挥作用。

    

    本文研究在高维分析中出现的自然函数空间 $\mathcal{F}_{p,\pi}$ 和 Barron 空间中学习函数的问题。通过对偶分析，我们揭示了这些空间的逼近和估计可以在某种意义下被视为等价的。这使得我们能够在研究这两种模型的泛化时更专注于更容易的逼近和估计问题。通过定义一种基于信息的复杂度来有效地控制估计误差，建立了对偶等价性。此外，我们通过对两个具体应用进行综合分析展示了我们的对偶性框架的灵活性。第一个应用是研究使用 RFMs 学习 $\mathcal{F}_{p,\pi}$ 中的函数。我们证明只要 $p>1$，学习不会受到维数灾难的影响，这意味着 RFMs 可以在核范围之外发挥作用。

    We consider the problem of learning functions in the $\mathcal{F}_{p,\pi}$ and Barron spaces, which are natural function spaces that arise in the high-dimensional analysis of random feature models (RFMs) and two-layer neural networks. Through a duality analysis, we reveal that the approximation and estimation of these spaces can be considered equivalent in a certain sense. This enables us to focus on the easier problem of approximation and estimation when studying the generalization of both models. The dual equivalence is established by defining an information-based complexity that can effectively control estimation errors. Additionally, we demonstrate the flexibility of our duality framework through comprehensive analyses of two concrete applications.  The first application is to study learning functions in $\mathcal{F}_{p,\pi}$ with RFMs. We prove that the learning does not suffer from the curse of dimensionality as long as $p>1$, implying RFMs can work beyond the kernel regime. Our 
    
[^60]: 面部识别技术可以从面部图像中显示政治取向，即使控制社会人口统计和自我表现。(arXiv: 2303.16343v1 [cs.CV])

    Facial recognition technology can expose political orientation from facial images even when controlling for demographics and self-presentation. (arXiv:2303.16343v1 [cs.CV])

    [http://arxiv.org/abs/2303.16343](http://arxiv.org/abs/2303.16343)

    本研究使用面部识别技术，通过特定的面部特征发现了人们的政治取向，甚至可以从自然图像中推广。这种预测的精度比人类评分者高，相当于一些工作面试的预测效果。

    

    本论文运用面部识别算法，从实验室设置下拍摄的591张中性面部图像中提取面部描述符。在控制年龄、性别和种族的情况下，通过交叉验证的线性回归模型来预测参与者在政治取向量表上的得分(Cronbach的α=0.94)。模型的性能超过了r = 0.20，远优于人类评分者，与工作面试预测工作成功、酒精驱动攻击性或心理治疗改善心理健康的效果相当。此外，从标准化图像衍生出的模型在3,401名来自美国、英国和加拿大的政治人物的自然图像样本中表现良好(r = 0.12)，表明面部外貌和政治取向之间的关联可推广到我们之外的人群。面部特征与政治取向相关的分析发现，保守派的下半脸部分更大，虽然政治取向不能准确地预测个体面部特征的所有变化，但是这种发现还是富有启发性的。

    A facial recognition algorithm was used to extract face descriptors from carefully standardized images of 591 neutral faces taken in the laboratory setting. Face descriptors were entered into a cross-validated linear regression to predict participants' scores on a political orientation scale (Cronbach's alpha=.94) while controlling for age, gender, and ethnicity. The model's performance exceeded r=.20: much better than that of human raters and on par with how well job interviews predict job success, alcohol drives aggressiveness, or psychological therapy improves mental health. Moreover, the model derived from standardized images performed well (r=.12) in a sample of naturalistic images of 3,401 politicians from the U.S., UK, and Canada, suggesting that the associations between facial appearance and political orientation generalize beyond our sample. The analysis of facial features associated with political orientation revealed that conservatives had larger lower faces, although politi
    
[^61]: 克服异方差PCA中病态问题的缩减算法

    Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA. (arXiv:2303.06198v1 [math.ST])

    [http://arxiv.org/abs/2303.06198](http://arxiv.org/abs/2303.06198)

    本文提出了一种新的算法，称为缩减异方差PCA，它在克服病态问题的同时实现了近乎最优和无条件数的理论保证。

    This paper proposes a novel algorithm, called Deflated-HeteroPCA, that overcomes the curse of ill-conditioning in heteroskedastic PCA while achieving near-optimal and condition-number-free theoretical guarantees.

    本文关注于从受污染的数据中估计低秩矩阵X*的列子空间。当存在异方差噪声和不平衡的维度（即n2 >> n1）时，如何在容纳最广泛的信噪比范围的同时获得最佳的统计精度变得特别具有挑战性。虽然最先进的算法HeteroPCA成为解决这个问题的强有力的解决方案，但它遭受了“病态问题的诅咒”，即随着X*的条件数增长，其性能会下降。为了克服这个关键问题而不影响允许的信噪比范围，我们提出了一种新的算法，称为缩减异方差PCA，它在$\ell_2$和$\ell_{2,\infty}$统计精度方面实现了近乎最优和无条件数的理论保证。所提出的算法将谱分成两部分

    This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum
    
[^62]: 有限时域受限马尔可夫决策过程的策略梯度方法

    A policy gradient approach for Finite Horizon Constrained Markov Decision Processes. (arXiv:2210.04527v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04527](http://arxiv.org/abs/2210.04527)

    本文提出了一种针对有限时域受限马尔可夫决策过程的策略梯度方法，该方法能够在固定时间后终止，通过函数逼近和策略梯度方法找到最优策略。

    

    无限时域设置通常用于强化学习问题，导致产生最优的固定策略。然而，在许多情况下，有限时域控制问题更具有实际意义，并且在这种情况下，最优策略通常随时间变化。最近，约束强化学习的设置也越来越受到关注，其中代理同时在最大化奖励的同时满足某些给定的约束条件。然而，这个设置仅在无限时域马尔可夫决策过程的背景下得到了研究，其中固定策略是最优的。本文提出了一种在有限时域设置下进行约束强化学习的算法，其中在一个固定的时间后终止。我们在算法中使用函数逼近，这在状态和动作空间较大或连续的情况下是必不可少的，并使用策略梯度方法来找到最优策略。我们得到的最优策略取决于时间段。

    The infinite horizon setting is widely adopted for problems of reinforcement learning (RL). These invariably result in stationary policies that are optimal. In many situations, finite horizon control problems are of interest and for such problems, the optimal policies are time-varying in general. Another setting that has become popular in recent times is of Constrained Reinforcement Learning, where the agent maximizes its rewards while it also aims to satisfy some given constraint criteria. However, this setting has only been studied in the context of infinite horizon MDPs where stationary policies are optimal. We present an algorithm for constrained RL in the Finite Horizon Setting where the horizon terminates after a fixed (finite) time. We use function approximation in our algorithm which is essential when the state and action spaces are large or continuous and use the policy gradient method to find the optimal policy. The optimal policy that we obtain depends on the stage and so is
    
[^63]: 带理论支持的样本重用的广义策略提升算法

    Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse. (arXiv:2206.13714v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.13714](http://arxiv.org/abs/2206.13714)

    研究提出了一种广义策略提升算法，结合了在线方法的策略提升保证和离线策略算法通过样本重用有效利用数据的效率。

    

    数据驱动的学习控制方法具有改善复杂系统运行的潜力，而基于模型的深度强化学习代表了一种流行的数据驱动控制方法。然而，现有的算法类别在实际控制部署的两个重要要求之间存在权衡：（i）实际性能保证和（ii）数据效率。离线策略算法通过样本重用有效利用数据，但缺乏理论保证，而在线策略算法保证了训练期间的近似策略改进，但受到高样本复杂度的影响。为了平衡这些竞争目标，我们开发了一类广义策略提升算法，它结合了在线方法的策略提升保证和样本重用的效率。通过对来自DeepMind C的多种连续控制任务进行 extensive 的实验分析，我们证明了这种新类算法的益处。

    Data-driven, learning-based control methods offer the potential to improve operations in complex systems, and model-free deep reinforcement learning represents a popular approach to data-driven control. However, existing classes of algorithms present a trade-off between two important deployment requirements for real-world control: (i) practical performance guarantees and (ii) data efficiency. Off-policy algorithms make efficient use of data through sample reuse but lack theoretical guarantees, while on-policy algorithms guarantee approximate policy improvement throughout training but suffer from high sample complexity. In order to balance these competing goals, we develop a class of Generalized Policy Improvement algorithms that combines the policy improvement guarantees of on-policy methods with the efficiency of sample reuse. We demonstrate the benefits of this new class of algorithms through extensive experimental analysis on a variety of continuous control tasks from the DeepMind C
    
[^64]: 部分知识下的最优打分规则设计

    Optimal Scoring Rule Design under Partial Knowledge. (arXiv:2107.07420v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2107.07420](http://arxiv.org/abs/2107.07420)

    本文研究了在委托人对代理人的信号分布部分了解的情况下，最优打分规则的设计问题。作者提出了一个最大最小优化的框架，来最大化在代理人信号分布的集合中最坏情况下回报的增加。对于有限集合，提出了高效的算法；对于无限集合，提出了完全多项式时间逼近方案。

    

    本文研究了当委托人对代理人的信号分布部分了解时，最优适当打分规则的设计。最近的工作表明，在委托人完全了解代理人的信号分布的假设下，可以确定增加代理人回报的最大适当打分规则，当代理人选择访问昂贵信号以完善其先验预测的后验信念时。在我们的设置中，委托人只知道代理人的信号分布属于一组分布中的某个。我们将打分规则设计问题制定为最大最小优化问题，最大化分布集合中最坏情况下回报的增加。当分布集合有限时，我们提出了一种高效的算法来计算最优打分规则，并设计了一种完全多项式时间逼近方案，适用于各种无限集合的分布。我们进一步指出，广泛使用的打分规则，如二次方打分规则。

    This paper studies the design of optimal proper scoring rules when the principal has partial knowledge of an agent's signal distribution. Recent work characterizes the proper scoring rules that maximize the increase of an agent's payoff when the agent chooses to access a costly signal to refine a posterior belief from her prior prediction, under the assumption that the agent's signal distribution is fully known to the principal. In our setting, the principal only knows about a set of distributions where the agent's signal distribution belongs. We formulate the scoring rule design problem as a max-min optimization that maximizes the worst-case increase in payoff across the set of distributions.  We propose an efficient algorithm to compute an optimal scoring rule when the set of distributions is finite, and devise a fully polynomial-time approximation scheme that accommodates various infinite sets of distributions. We further remark that widely used scoring rules, such as the quadratic 
    

