# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Vaccine: Perturbation-aware Alignment for Large Language Model](https://rss.arxiv.org/abs/2402.01109) | 疫苗是一种针对大规模语言模型的干扰感知对齐技术，通过逐渐添加扰动产生不变的隐藏嵌入，提高对抗有害提示引起的嵌入漂移的对齐鲁棒性，同时保留对良性提示的推理能力。 |
| [^2] | [Propensity Score Alignment of Unpaired Multimodal Data](https://arxiv.org/abs/2404.01595) | 本文提出了一种解决多模态表示学习中对齐不配对样本挑战的方法，通过估计倾向得分来定义样本之间的距离。 |
| [^3] | [QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs](https://arxiv.org/abs/2404.00456) | QuaRot是一种基于旋转的新量化方案，能够在LLMs中进行无异常值的4位推断，实现了端到端的量化，并保持了99%的零-shot表现。 |
| [^4] | [Benchmarking Counterfactual Image Generation](https://arxiv.org/abs/2403.20287) | 提出了一个针对对照图像生成方法的基准测试框架，包含评估对照多个方面的度量标准以及评估三种不同类型的条件图像生成模型性能。 |
| [^5] | [Do LLM Agents Have Regret? A Case Study in Online Learning and Games](https://arxiv.org/abs/2403.16843) | 通过研究在线学习和博弈论中的基准决策设置，评估LLM代理的交互行为和性能，以了解它们在多代理环境中的潜力和限制。 |
| [^6] | [Can large language models explore in-context?](https://arxiv.org/abs/2403.15371) | 研究发现，大型语言模型在没有实质干预的情况下很难有效进行探索，除了特定配置下的GPT-4具有满意的探索行为外，其他模型表现不稳定。 |
| [^7] | [Simplified Diffusion Schr\"odinger Bridge](https://arxiv.org/abs/2403.14623) | 介绍了简化后的扩散薛定谔桥（DSB），通过与基于得分的生成模型（SGM）的统一解决了复杂数据生成中的限制，提高了性能并加快了收敛速度。 |
| [^8] | [Forging the Forger: An Attempt to Improve Authorship Verification via Data Augmentation](https://arxiv.org/abs/2403.11265) | 通过引入合成示例的数据增强方法，可以改善在作者验证任务中对抗性攻击下的分类器预测。 |
| [^9] | [A Probabilistic Hadamard U-Net for MRI Bias Field Correction](https://arxiv.org/abs/2403.05024) | 提出了一种用于前列腺MRI偏置场校正的概率哈达玛U-Net，引入了哈达玛U-Net（HU-Net）通过哈达玛变换将输入图像从时域转换为频域，并使用可训练的滤波器和硬阈值层消除高频部分。 |
| [^10] | [Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation](https://arxiv.org/abs/2403.03949) | 该论文提出了一种名为RialTo的系统，通过在“数字孪生”模拟环境中进行强化学习来稳健化真实世界的模仿学习策略，以实现在不需要大量不安全真实世界数据采集或广泛人类监督的情况下学习性能优越、稳健的策略。 |
| [^11] | [Blue and Green-Mode Energy-Efficient Chemiresistive Sensor Array Realized by Rapid Ensemble Learning](https://arxiv.org/abs/2403.01642) | 该研究提出了一种通过快速集成学习优化化学传感器阵列的策略，引入了蓝色和绿色两种工作模式，通过选择性激活关键传感器显著降低能耗而不影响检测准确性。 |
| [^12] | [Pre-training Differentially Private Models with Limited Public Data](https://arxiv.org/abs/2402.18752) | 通过使用有限的公共数据，研究者提出了一种新颖的差分隐私持续预训练策略，以显著缓解优化器性能下降。 |
| [^13] | [C-GAIL: Stabilizing Generative Adversarial Imitation Learning with Control Theory](https://arxiv.org/abs/2402.16349) | 该论文利用控制理论改进了生成对抗模仿学习（GAIL），提出了一种名为“Controlled-GAIL”（C-GAIL）的算法，能够解决GAIL训练不稳定性的问题，并在MuJoCo任务中取得了较快的收敛速度。 |
| [^14] | [Information-based Transductive Active Learning](https://arxiv.org/abs/2402.15898) | ITL是一种基于信息的转导式学习方法，可以在现实世界设置中自适应采样，以最大化关于指定预测目标的信息获取，并在少样本微调和安全贝叶斯优化应用中显著优于最先进技术。 |
| [^15] | [Doubly Robust Inference in Causal Latent Factor Models](https://arxiv.org/abs/2402.11652) | 提出了一种双重稳健的估计量框架，可以在现代数据丰富的环境中估计存在未观察混杂因素下平均处理效应，具有良好的有限样本和渐近性质，并在参数速率下将其误差收敛为零均值高斯分布。 |
| [^16] | [OptEx: Expediting First-Order Optimization with Approximately Parallelized Iterations](https://arxiv.org/abs/2402.11427) | OptEx是第一个通过利用并行计算来减轻一阶优化的迭代瓶颈并增强效率的框架，使用核化梯度估计实现迭代的并行化，提供理论保证。 |
| [^17] | [CultureLLM: Incorporating Cultural Differences into Large Language Models](https://arxiv.org/abs/2402.10946) | 提出了一种名为CultureLLM的成本效益高的解决方案，通过使用世界价值调查（WVS）作为种子数据，并通过提出的语义数据增强来将文化差异纳入大型语言模型中，成功微调得到了涵盖富裕和低资源语言的9种文化特定LLMs以及一个统一模型（CultureLLM-One）。 |
| [^18] | [AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts](https://arxiv.org/abs/2402.07625) | 本论文介绍了一种自主数据选择策略，利用语言模型进行数学文本的自动评估和选择，并通过连续预训练显著提高了数学推理能力。主要创新包括利用元提示语言模型作为验证器，发布了高质量的AutoMathText数据集，并实现了预训练令牌效率的提升。 |
| [^19] | [EuLagNet: Eulerian Fluid Prediction with Lagrangian Dynamics](https://arxiv.org/abs/2402.02425) | EuLagNet提出了一种新的拉格朗日引导范式，通过跟踪多尺度关键粒子的运动来捕捉多尺度流体动力学。这种方法克服了由于欧拉观察而导致的流体动力学困难，为准确预测未来的流体提供了一种有效的方法。 |
| [^20] | [D\'ej\`a Vu Memorization in Vision-Language Models](https://arxiv.org/abs/2402.02103) | 这项研究提出了一种新方法来衡量视觉语言模型中的记忆现象，并发现对于使用图像-标题对进行训练的VLMs，模型确实会保留关于训练图像中的个别对象的信息，文本随机化可以在很大程度上减轻记忆现象而对模型的下游任务性能影响较小。 |
| [^21] | [Proximal Causal Inference With Text Data.](http://arxiv.org/abs/2401.06687) | 本论文提出了一种使用文本数据进行近因果推断的方法，通过将文本数据分割并使用零样本模型推断出代理变量，然后应用于近邻 g-formula，从而解决了混淆变量完全未观察到的情况。实验结果表明该方法产生了低偏差的估计值。 |
| [^22] | [Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents.](http://arxiv.org/abs/2401.05821) | SCoBots是一种可解释的概念瓶颈代理，能够透明化整个决策流程，帮助领域专家理解和规范强化学习代理的行为，从而可能实现更好的人类对齐强化学习。 |
| [^23] | [Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs.](http://arxiv.org/abs/2311.01404) | 本文以线性控制神经ODE的流动作为归一化流构造最优传输映射的近似。通过离散最优耦合问题和数值方案，实现了对最优传输映射的近似。最终结果有助于构建深度神经网络中的可逆传输映射。 |
| [^24] | [Externally Valid Policy Evaluation Combining Trial and Observational Data.](http://arxiv.org/abs/2310.14763) | 这项研究提出了一种结合试验和观察数据的外部有效策略评估方法，利用试验数据对目标人群上的政策结果进行有效推断，并给出了可验证的评估结果。 |
| [^25] | [Inverse Renormalization Group of Disordered Systems.](http://arxiv.org/abs/2310.12631) | 本文介绍了一种逆重整群的方法，通过机器学习算法构造了缩放的晶格配置，用于研究自旋玻璃。该方法可以实现在不使用超级计算机的情况下，探索不断增大的晶格体积下的精确配置。 |
| [^26] | [On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism.](http://arxiv.org/abs/2310.07852) | 本文研究了在高维稀疏线性回归模型中的差分隐私模型选择问题。我们使用指数机制进行模型选择，并提出了Metropolis-Hastings算法来克服指数搜索空间的计算复杂性。我们的算法在一定边界条件下能够实现强模型恢复性质，并具有多项式混合时间和近似差分隐私性质。 |
| [^27] | [A Neural Tangent Kernel View on Federated Averaging for Deep Linear Neural Network.](http://arxiv.org/abs/2310.05495) | 本论文介绍了一种基于神经切向核视角的联邦平均方法在深度线性神经网络上的应用，并探讨了该方法面临的挑战。 |
| [^28] | [Federated Deep Equilibrium Learning: A Compact Shared Representation for Edge Communication Efficiency.](http://arxiv.org/abs/2309.15659) | FeDEQ是一个联邦学习框架，采用深度平衡学习和共识优化，通过紧凑的共享数据表示在边缘节点之间共享模型，解决了深度联邦学习在边缘环境中的通信瓶颈和数据异构性问题。 |
| [^29] | [AI-Driven Patient Monitoring with Multi-Agent Deep Reinforcement Learning.](http://arxiv.org/abs/2309.10980) | 本研究提出了一种基于多智能体深度强化学习的AI驱动患者监测框架，通过部署多个学习智能体，针对不同的生理特征进行监测，并根据紧急程度预警医疗紧急团队。 |
| [^30] | [Out-of-Distribution Optimality of Invariant Risk Minimization.](http://arxiv.org/abs/2307.11972) | 本文旨在提供IRM的理论验证，严格证明了解决方案可以最小化区外风险。 |
| [^31] | [Federated Large Language Model: A Position Paper.](http://arxiv.org/abs/2307.08925) | 我们提出了联邦式大规模语言模型的概念，通过联邦学习实现分散数据的共同训练共享模型，以应对公共数据可用性的限制和私有数据的隐私保护需求。我们讨论了预训练、微调和提示工程这三个组件的优势，并提出了实施策略。同时，我们探讨了FL和LLM集成带来的新挑战，并分析了现有解决方案和潜在障碍。 |
| [^32] | [Absorbing Phase Transitions in Artificial Deep Neural Networks.](http://arxiv.org/abs/2307.02284) | 本文研究了在适当初始化的有限神经网络中的吸收相变及其普适性，证明了即使在有限网络中仍然存在着从有序状态到混沌状态的过渡，并且不同的网络架构会反映在过渡的普适类上。 |
| [^33] | [What Makes ImageNet Look Unlike LAION.](http://arxiv.org/abs/2306.15769) | 本研究通过重新搜索大规模的LAION数据集，尝试重新创建图像网，并发现与原始图像网相比，新建的LAIONet具有明显不同之处。这种差异的原因是，在基于图像描述进行搜索时，存在信息瓶颈，从而减轻了选择偏差。 |
| [^34] | [S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks.](http://arxiv.org/abs/2306.15220) | S-TLLR是一个受到STDP机制启发的时间局部学习规则，可以用于训练脉冲神经网络，同时考虑到了因果和非因果关系。 |
| [^35] | [Collaborative World Models: An Online-Offline Transfer RL Approach.](http://arxiv.org/abs/2305.15260) | 本论文提出了一种名为协作世界模型（CoWorld）的转移学习方法，以改善离线条件下视觉RL的性能。其核心想法是使用易于交互的模拟器来训练辅助RL模型作为离线策略的在线“测试床”，并执行域协作表示学习和域协作行为学习，缓解离线数据分布之外的价值函数过度估计问题。 |
| [^36] | [RHINO: Rotated DETR with Dynamic Denoising via Hungarian Matching for Oriented Object Detection.](http://arxiv.org/abs/2305.07598) | 本文提出了一种面向定向目标检测的DINO基线模型RHINO。并通过匈牙利匹配和查询对齐的方式实现动态降噪，解决了重复预测的问题，从而在公共基准测试中达到最先进的性能水平。 |
| [^37] | [Efficient Convex Algorithms for Universal Kernel Learning.](http://arxiv.org/abs/2304.07472) | 本文提出了一种基于SVD-QCQP原始对偶算法的高效内核学习实现，用于学习半分离核，大大降低了计算复杂度，并在几个基准数据集上展示了其准确性和速度。 |
| [^38] | [Empirical Design in Reinforcement Learning.](http://arxiv.org/abs/2304.01315) | 本文是一个关于如何进行良好实验的资源，旨在解决强化学习中实证设计的挑战，并弥补实证研究中可能导致的弱的统计证据。 |
| [^39] | [Het-node2vec: second order random walk sampling for heterogeneous multigraphs embedding.](http://arxiv.org/abs/2101.01425) | Het-node2vec是一个算法框架，通过在异构多图上进行二阶随机游走采样，能够捕获图的结构特征和不同类型节点边的语义，有效地提高对异构图的无监督和有监督学习性能。 |

# 详细

[^1]: 疫苗：针对大规模语言模型的干扰感知对齐技术

    Vaccine: Perturbation-aware Alignment for Large Language Model

    [https://rss.arxiv.org/abs/2402.01109](https://rss.arxiv.org/abs/2402.01109)

    疫苗是一种针对大规模语言模型的干扰感知对齐技术，通过逐渐添加扰动产生不变的隐藏嵌入，提高对抗有害提示引起的嵌入漂移的对齐鲁棒性，同时保留对良性提示的推理能力。

    

    作为一种新的微调即服务范 paradigm，大型语言模型 (LLM) 为用户上传的一小部分有害数据提供了新的攻击面，这些数据很容易欺骗微调过程从而产生对齐失效的模型。我们进行了实证分析，揭示了一种可能导致对齐失效的有害嵌入漂移现象。受到我们的发现启发，我们提出了疫苗 (Vaccine) ，一种针对干扰感知的对齐技术，以减轻用户微调的安全风险。疫苗的核心思想是通过在对齐阶段逐渐添加精心设计的扰动，产生不变的隐藏嵌入，从而使嵌入能够抵御来自未经消毒的用户数据的有害扰动。我们在开源主流LLM（如Llama2，Opt，Vicuna）上的实验结果表明，疫苗能够提高对抗有害提示引起的嵌入漂移的对齐鲁棒性，同时保留对良性提示的推理能力。

    The new paradigm of finetuning-as-a-service introduces a new attack surface for Large Language Models (LLMs): a few harmful data uploaded by users can easily trick the finetuning to produce an alignment-broken model. We conduct an empirical analysis and uncover a \textit{harmful embedding drift} phenomenon, showing a probable cause of the alignment-broken effect. Inspired by our findings, we propose Vaccine, a perturbation-aware alignment technique to mitigate the security risk of users finetuning. The core idea of Vaccine is to produce invariant hidden embeddings by progressively adding crafted perturbation to them in the alignment phase. This enables the embeddings to withstand harmful perturbation from un-sanitized user data in the finetuning phase. Our results on open source mainstream LLMs (e.g., Llama2, Opt, Vicuna) demonstrate that Vaccine can boost the robustness of alignment against harmful prompts induced embedding drift while reserving reasoning ability towards benign prompt
    
[^2]: 多模态数据无配对倾向得分对齐

    Propensity Score Alignment of Unpaired Multimodal Data

    [https://arxiv.org/abs/2404.01595](https://arxiv.org/abs/2404.01595)

    本文提出了一种解决多模态表示学习中对齐不配对样本挑战的方法，通过估计倾向得分来定义样本之间的距离。

    

    多模态表示学习技术通常依赖于配对样本来学习共同的表示，但在生物学等领域，往往难以收集配对样本，因为测量设备通常会破坏样本。本文介绍了一种解决多模态表示学习中对齐不配对样本的方法。我们将因果推断中的潜在结果与多模态观察中的潜在视图进行类比，这使我们能够使用Rubin的框架来估计一个共同的空间，以匹配样本。我们的方法假设我们收集了经过处理实验干扰的样本，并利用此来从每种模态中估计倾向得分，其中包括潜在状态和处理之间的所有共享信息，并可用于定义样本之间的距离。我们尝试了两种利用这一方法的对齐技术。

    arXiv:2404.01595v1 Announce Type: new  Abstract: Multimodal representation learning techniques typically rely on paired samples to learn common representations, but paired samples are challenging to collect in fields such as biology where measurement devices often destroy the samples. This paper presents an approach to address the challenge of aligning unpaired samples across disparate modalities in multimodal representation learning. We draw an analogy between potential outcomes in causal inference and potential views in multimodal observations, which allows us to use Rubin's framework to estimate a common space in which to match samples. Our approach assumes we collect samples that are experimentally perturbed by treatments, and uses this to estimate a propensity score from each modality, which encapsulates all shared information between a latent state and treatment and can be used to define a distance between samples. We experiment with two alignment techniques that leverage this di
    
[^3]: QuaRot：旋转LLMs中无异常值的4位推断

    QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs

    [https://arxiv.org/abs/2404.00456](https://arxiv.org/abs/2404.00456)

    QuaRot是一种基于旋转的新量化方案，能够在LLMs中进行无异常值的4位推断，实现了端到端的量化，并保持了99%的零-shot表现。

    

    我们介绍了QuaRot，一种基于旋转的新量化方案，能够端对端地将LLMs中的所有权重、激活和KV缓存量化为4位。QuaRot以一种能够去除隐藏状态中异常值但不改变输出的方式对LLMs进行旋转，使得量化变得更简单。这种计算不变性被应用于LLM的隐藏状态（残差），以及前馈组件的激活、注意机制的部分内容和KV缓存。结果是一个量化模型，其中所有矩阵乘法都以4位进行，无需识别需要以更高精度保留的通道。我们的量化LLaMa2-70B模型在最坏情况下仅损失0.29的WikiText-2困惑度，并保留了99%的零-shot表现。代码可在此处获得：https://github.com/spcl/QuaRot。

    arXiv:2404.00456v1 Announce Type: new  Abstract: We introduce QuaRot, a new Quantization scheme based on Rotations, which is able to quantize LLMs end-to-end, including all weights, activations, and KV cache in 4 bits. QuaRot rotates LLMs in a way that removes outliers from the hidden state without changing the output, making quantization easier. This computational invariance is applied to the hidden state (residual) of the LLM, as well as to the activations of the feed-forward components, aspects of the attention mechanism and to the KV cache. The result is a quantized model where all matrix multiplications are performed in 4-bits, without any channels identified for retention in higher precision. Our quantized LLaMa2-70B model has losses of at most 0.29 WikiText-2 perplexity and retains 99% of the zero-shot performance. Code is available at: https://github.com/spcl/QuaRot.
    
[^4]: 基准对照图像生成

    Benchmarking Counterfactual Image Generation

    [https://arxiv.org/abs/2403.20287](https://arxiv.org/abs/2403.20287)

    提出了一个针对对照图像生成方法的基准测试框架，包含评估对照多个方面的度量标准以及评估三种不同类型的条件图像生成模型性能。

    

    对照图像生成在理解变量因果关系方面具有关键作用，在解释性和生成无偏合成数据方面有应用。然而，评估图像生成本身就是一个长期存在的挑战。对于评估对照生成的需求进一步加剧了这一挑战，因为根据定义，对照情景是没有可观测基准事实的假设情况。本文提出了一个旨在对照图像生成方法进行基准测试的新颖综合框架。我们结合了侧重于评估对照的不同方面的度量标准，例如组成、有效性、干预的最小性和图像逼真度。我们评估了基于结构因果模型范式的三种不同条件图像生成模型类型的性能。我们的工作还配备了一个用户友好的Python软件包，可以进一步评估。

    arXiv:2403.20287v1 Announce Type: cross  Abstract: Counterfactual image generation is pivotal for understanding the causal relations of variables, with applications in interpretability and generation of unbiased synthetic data. However, evaluating image generation is a long-standing challenge in itself. The need to evaluate counterfactual generation compounds on this challenge, precisely because counterfactuals, by definition, are hypothetical scenarios without observable ground truths. In this paper, we present a novel comprehensive framework aimed at benchmarking counterfactual image generation methods. We incorporate metrics that focus on evaluating diverse aspects of counterfactuals, such as composition, effectiveness, minimality of interventions, and image realism. We assess the performance of three distinct conditional image generation model types, based on the Structural Causal Model paradigm. Our work is accompanied by a user-friendly Python package which allows to further eval
    
[^5]: LLM代理是否会感到后悔？在线学习和游戏案例研究

    Do LLM Agents Have Regret? A Case Study in Online Learning and Games

    [https://arxiv.org/abs/2403.16843](https://arxiv.org/abs/2403.16843)

    通过研究在线学习和博弈论中的基准决策设置，评估LLM代理的交互行为和性能，以了解它们在多代理环境中的潜力和限制。

    

    大型语言模型(LLMs)越来越多地被用于(交互式)决策制定，通过开发基于LLM的自主代理。尽管它们取得了不断的成功，但LLM代理在决策制定中的表现尚未通过定量指标进行充分调查，特别是在它们相互作用时的多代理设置中，这是实际应用中的典型场景。为了更好地理解LLM代理在这些交互环境中的限制，我们建议研究它们在在线学习和博弈论的基准决策设置中的相互作用，并通过\emph{后悔}性能指标进行评估。我们首先在经典(非平稳)在线学习问题中经验性地研究LLMs的无后悔行为，以及当LLM代理通过进行重复游戏进行交互时均衡的出现。然后我们对无后悔行为提供一些理论洞见。

    arXiv:2403.16843v1 Announce Type: cross  Abstract: Large language models (LLMs) have been increasingly employed for (interactive) decision-making, via the development of LLM-based autonomous agents. Despite their emerging successes, the performance of LLM agents in decision-making has not been fully investigated through quantitative metrics, especially in the multi-agent setting when they interact with each other, a typical scenario in real-world LLM-agent applications. To better understand the limits of LLM agents in these interactive environments, we propose to study their interactions in benchmark decision-making settings in online learning and game theory, through the performance metric of \emph{regret}. We first empirically study the {no-regret} behaviors of LLMs in canonical (non-stationary) online learning problems, as well as the emergence of equilibria when LLM agents interact through playing repeated games. We then provide some theoretical insights into the no-regret behavior
    
[^6]: 大型语言模型能够进行上下文中的探索吗？

    Can large language models explore in-context?

    [https://arxiv.org/abs/2403.15371](https://arxiv.org/abs/2403.15371)

    研究发现，大型语言模型在没有实质干预的情况下很难有效进行探索，除了特定配置下的GPT-4具有满意的探索行为外，其他模型表现不稳定。

    

    我们研究现代大型语言模型（LLMs）在进行探索方面的能力，这是强化学习和决策制定中的核心能力。我们关注现有LLMs的原生性能，没有进行训练干预。我们将LLMs部署为简单多臂老虎机环境中的代理，并完全在上下文中指定环境描述和交互历史，即在LLM提示内部进行。我们使用各种提示设计对GPT-3.5、GPT-4和Llama2进行实验，发现这些模型在没有实质干预的情况下并没有稳健地进行探索：i）在我们的所有实验中，只有一个配置导致了令人满意的探索行为：具有思维链推理和外部总结的交互历史的GPT-4，这些被呈现为充分统计的情况；ii）所有其他配置都没有产生稳健的探索行为，包括具有思维链推理的其他配置。

    arXiv:2403.15371v1 Announce Type: cross  Abstract: We investigate the extent to which contemporary Large Language Models (LLMs) can engage in exploration, a core capability in reinforcement learning and decision making. We focus on native performance of existing LLMs, without training interventions. We deploy LLMs as agents in simple multi-armed bandit environments, specifying the environment description and interaction history entirely in-context, i.e., within the LLM prompt. We experiment with GPT-3.5, GPT-4, and Llama2, using a variety of prompt designs, and find that the models do not robustly engage in exploration without substantial interventions: i) Across all of our experiments, only one configuration resulted in satisfactory exploratory behavior: GPT-4 with chain-of-thought reasoning and an externally summarized interaction history, presented as sufficient statistics; ii) All other configurations did not result in robust exploratory behavior, including those with chain-of-thou
    
[^7]: 简化扩散薛定谔桥

    Simplified Diffusion Schr\"odinger Bridge

    [https://arxiv.org/abs/2403.14623](https://arxiv.org/abs/2403.14623)

    介绍了简化后的扩散薛定谔桥（DSB），通过与基于得分的生成模型（SGM）的统一解决了复杂数据生成中的限制，提高了性能并加快了收敛速度。

    

    这篇论文介绍了一种新的理论简化扩散薛定谔桥（DSB），便于将其与基于得分的生成模型（SGM）统一起来，解决了DSB在复杂数据生成方面的局限性，实现更快的收敛速度和增强的性能。通过将SGM作为DSB的初始解决方案，我们的方法利用了这两个框架的优势，确保了更高效的训练过程，并改进了SGM的性能。我们还提出了一种重新参数化技术，尽管存在理论近似，但实际上提高了网络的拟合能力。我们进行了大量的实验证实，证实了简化的DSB的有效性，展示了其显著的改进。我们相信这项工作的贡献为先进的生成建模铺平了道路。

    arXiv:2403.14623v1 Announce Type: new  Abstract: This paper introduces a novel theoretical simplification of the Diffusion Schr\"odinger Bridge (DSB) that facilitates its unification with Score-based Generative Models (SGMs), addressing the limitations of DSB in complex data generation and enabling faster convergence and enhanced performance. By employing SGMs as an initial solution for DSB, our approach capitalizes on the strengths of both frameworks, ensuring a more efficient training process and improving the performance of SGM. We also propose a reparameterization technique that, despite theoretical approximations, practically improves the network's fitting capabilities. Our extensive experimental evaluations confirm the effectiveness of the simplified DSB, demonstrating its significant improvements. We believe the contributions of this work pave the way for advanced generative modeling. The code is available at https://github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge.
    
[^8]: 通过数据增强来改善作者验证的方法

    Forging the Forger: An Attempt to Improve Authorship Verification via Data Augmentation

    [https://arxiv.org/abs/2403.11265](https://arxiv.org/abs/2403.11265)

    通过引入合成示例的数据增强方法，可以改善在作者验证任务中对抗性攻击下的分类器预测。

    

    作者验证（AV）是一个文本分类任务，关注的是推断候选文本是由一个特定作者撰写还是由其他人撰写。已经显示许多AV系统容易受到敌对攻击的影响，其中恶意作者积极尝试欺骗分类器，方法是隐藏他们的写作风格，或者模仿另一位作者的风格。本文研究了将分类器训练集与（负面的）合成示例进行增强的潜在好处。这些合成示例是为了模仿感兴趣的作者的风格而生成的。我们分析了这种增强对在敌对环境下的AV任务中带来的分类器预测改进。具体来说，我们尝试了三种不同的生成器架构（一种基于循环神经网络，另一种基于小规模transformers，另一种基于流行的GPT模型）。

    arXiv:2403.11265v1 Announce Type: cross  Abstract: Authorship Verification (AV) is a text classification task concerned with inferring whether a candidate text has been written by one specific author or by someone else. It has been shown that many AV systems are vulnerable to adversarial attacks, where a malicious author actively tries to fool the classifier by either concealing their writing style, or by imitating the style of another author. In this paper, we investigate the potential benefits of augmenting the classifier training set with (negative) synthetic examples. These synthetic examples are generated to imitate the style of the author of interest. We analyze the improvements in classifier prediction that this augmentation brings to bear in the task of AV in an adversarial setting. In particular, we experiment with three different generator architectures (one based on Recurrent Neural Networks, another based on small-scale transformers, and another based on the popular GPT mod
    
[^9]: 一种用于MRI偏置场校正的概率哈达玛U-Net

    A Probabilistic Hadamard U-Net for MRI Bias Field Correction

    [https://arxiv.org/abs/2403.05024](https://arxiv.org/abs/2403.05024)

    提出了一种用于前列腺MRI偏置场校正的概率哈达玛U-Net，引入了哈达玛U-Net（HU-Net）通过哈达玛变换将输入图像从时域转换为频域，并使用可训练的滤波器和硬阈值层消除高频部分。

    

    磁场不均匀性校正在MRI分析中仍然是一个具有挑战性的任务。大多数已建立的技术是为脑MRI设计的，假设相同组织中的图像强度遵循均匀分布。这种假设不易适用于其他器官，特别是那些体积小，质地不均匀（强度变化大）的器官，比如前列腺。为了解决这个问题，本文提出了一种用于前列腺MRI偏置场校正的概率哈达玛U-Net（PHU-Net）。首先，引入了一种新颖的哈达玛U-Net（HU-Net）以提取低频标量场，将其乘以原始输入以获得原型校正图像。HU-Net通过哈达玛变换将输入图像从时域转换为频域。在频域中，使用可训练的滤波器（缩放层）、硬阈值层消除高频部分。

    arXiv:2403.05024v1 Announce Type: cross  Abstract: Magnetic field inhomogeneity correction remains a challenging task in MRI analysis. Most established techniques are designed for brain MRI by supposing that image intensities in the identical tissue follow a uniform distribution. Such an assumption cannot be easily applied to other organs, especially those that are small in size and heterogeneous in texture (large variations in intensity), such as the prostate. To address this problem, this paper proposes a probabilistic Hadamard U-Net (PHU-Net) for prostate MRI bias field correction. First, a novel Hadamard U-Net (HU-Net) is introduced to extract the low-frequency scalar field, multiplied by the original input to obtain the prototypical corrected image. HU-Net converts the input image from the time domain into the frequency domain via Hadamard transform. In the frequency domain, high-frequency components are eliminated using the trainable filter (scaling layer), hard-thresholding laye
    
[^10]: 通过模拟调和现实：一种用于稳健操作的实-模-实方法

    Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation

    [https://arxiv.org/abs/2403.03949](https://arxiv.org/abs/2403.03949)

    该论文提出了一种名为RialTo的系统，通过在“数字孪生”模拟环境中进行强化学习来稳健化真实世界的模仿学习策略，以实现在不需要大量不安全真实世界数据采集或广泛人类监督的情况下学习性能优越、稳健的策略。

    

    仿真学习方法需要大量人类监督来学习对物体姿势变化、物理干扰和视觉扰动鲁棒的策略。另一方面，强化学习可以自主探索环境以学习稳健行为，但可能需要大量不安全的真实世界数据采集。为了在没有不安全真实世界数据采集或广泛人类监督的负担下学习性能优越、稳健的策略，我们提出了RialTo，一个通过在即将从少量真实世界数据构建的“数字孪生”模拟环境中进行强化学习来稳健化真实世界的模仿学习策略的系统。为了实现这种实-模-实流水线，RialTo提出了一个易于使用的接口，用于快速扫描和构建真实世界环境的数字孪生。我们还引入了一种新颖的“反向提炼”过程，用于给真实世界演示带来

    arXiv:2403.03949v1 Announce Type: cross  Abstract: Imitation learning methods need significant human supervision to learn policies robust to changes in object poses, physical disturbances, and visual distractors. Reinforcement learning, on the other hand, can explore the environment autonomously to learn robust behaviors but may require impractical amounts of unsafe real-world data collection. To learn performant, robust policies without the burden of unsafe real-world data collection or extensive human supervision, we propose RialTo, a system for robustifying real-world imitation learning policies via reinforcement learning in "digital twin" simulation environments constructed on the fly from small amounts of real-world data. To enable this real-to-sim-to-real pipeline, RialTo proposes an easy-to-use interface for quickly scanning and constructing digital twins of real-world environments. We also introduce a novel "inverse distillation" procedure for bringing real-world demonstrations
    
[^11]: 通过快速集成学习实现的蓝绿模式高能效化化学传感器阵列

    Blue and Green-Mode Energy-Efficient Chemiresistive Sensor Array Realized by Rapid Ensemble Learning

    [https://arxiv.org/abs/2403.01642](https://arxiv.org/abs/2403.01642)

    该研究提出了一种通过快速集成学习优化化学传感器阵列的策略，引入了蓝色和绿色两种工作模式，通过选择性激活关键传感器显著降低能耗而不影响检测准确性。

    

    arXiv:2403.01642v1 公告类型: 新的 摘要: 物联网的快速发展需要开发既高效又能胜任的优化化学传感器阵列。本研究引入一种新颖的优化策略，采用快速集成学习模型委员会方法来实现这些目标。利用弹性网回归、随机森林、XGBoost等机器学习模型，该策略识别出在化学传感器阵列中对准确分类最具影响力的传感器：引入加权投票机制来聚合传感器选择中的模型意见，从而建立了两种不同的工作模式，称为“蓝色”和“绿色”。蓝色模式利用所有传感器进行最大检测能力，而绿色模式仅选择性激活关键传感器，从而显著降低能耗而不影响检测准确性。该策略通过理论验证。

    arXiv:2403.01642v1 Announce Type: new  Abstract: The rapid advancement of Internet of Things (IoT) necessitates the development of optimized Chemiresistive Sensor (CRS) arrays that are both energy-efficient and capable. This study introduces a novel optimization strategy that employs a rapid ensemble learning-based model committee approach to achieve these goals. Utilizing machine learning models such as Elastic Net Regression, Random Forests, and XGBoost, among others, the strategy identifies the most impactful sensors in a CRS array for accurate classification: A weighted voting mechanism is introduced to aggregate the models' opinions in sensor selection, thereby setting up wo distinct working modes, termed "Blue" and "Green". The Blue mode operates with all sensors for maximum detection capability, while the Green mode selectively activates only key sensors, significantly reducing energy consumption without compromising detection accuracy. The strategy is validated through theoreti
    
[^12]: 使用有限公共数据对有差异隐私的模型进行预训练

    Pre-training Differentially Private Models with Limited Public Data

    [https://arxiv.org/abs/2402.18752](https://arxiv.org/abs/2402.18752)

    通过使用有限的公共数据，研究者提出了一种新颖的差分隐私持续预训练策略，以显著缓解优化器性能下降。

    

    大型基础模型卓越的性能依赖于大量高质量数据的使用，然而这些数据通常包含需要正式保护的敏感、私人和受版权保护的信息。差分隐私是一种用于衡量模型提供的安全程度的重要方法，然而由于在预训练阶段应用差分隐私会导致性能下降，因此其应用通常仅限于模型微调阶段。因此，差分隐私目前尚不能保护初始预训练过程中使用的大部分数据。在这项工作中，我们首先通过分析每次迭代的损失改进，对差分隐私训练的有效性提供了理论理解。我们观察到，通过使用有限的公共数据，可以显著缓解差分隐私优化器的性能下降，从而引出一种新颖的差分隐私持续预训练策略。在实证方面，通过

    arXiv:2402.18752v1 Announce Type: new  Abstract: The superior performance of large foundation models relies on the use of massive amounts of high-quality data, which often contain sensitive, private and copyrighted material that requires formal protection. While differential privacy (DP) is a prominent method to gauge the degree of security provided to the models, its application is commonly limited to the model fine-tuning stage, due to the performance degradation when applying DP during the pre-training stage. Consequently, DP is yet not capable of protecting a substantial portion of the data used during the initial pre-training process.   In this work, we first provide a theoretical understanding of the efficacy of DP training by analyzing the per-iteration loss improvement. We make a key observation that DP optimizers' performance degradation can be significantly mitigated by the use of limited public data, which leads to a novel DP continual pre-training strategy. Empirically, usi
    
[^13]: C-GAIL: 利用控制理论稳定生成对抗模仿学习

    C-GAIL: Stabilizing Generative Adversarial Imitation Learning with Control Theory

    [https://arxiv.org/abs/2402.16349](https://arxiv.org/abs/2402.16349)

    该论文利用控制理论改进了生成对抗模仿学习（GAIL），提出了一种名为“Controlled-GAIL”（C-GAIL）的算法，能够解决GAIL训练不稳定性的问题，并在MuJoCo任务中取得了较快的收敛速度。

    

    生成对抗模仿学习（GAIL）训练一个生成策略来模仿一个演示者。它使用基于策略的强化学习（RL）来优化从类似GAN的鉴别器中导出的奖励信号。GAIL的一个主要缺点是其训练不稳定性 - 它继承了GAN的复杂训练动态，以及RL引入的分布转移。这可能导致训练过程中的振荡，从而影响其样本效率和最终策略性能。最近的工作表明，控制理论可以帮助GAN的训练收敛。本文延伸了这一线路的工作，对GAIL进行了控制理论分析，并导出了一种新颖的控制器，该控制器不仅将GAIL推向期望的均衡点，还在“单步”设置中实现了渐近稳定性。基于此，我们提出了一个实用算法“Controlled-GAIL”（C-GAIL）。在MuJoCo任务中，我们的受控变体能够加速收敛速度。

    arXiv:2402.16349v1 Announce Type: new  Abstract: Generative Adversarial Imitation Learning (GAIL) trains a generative policy to mimic a demonstrator. It uses on-policy Reinforcement Learning (RL) to optimize a reward signal derived from a GAN-like discriminator. A major drawback of GAIL is its training instability - it inherits the complex training dynamics of GANs, and the distribution shift introduced by RL. This can cause oscillations during training, harming its sample efficiency and final policy performance. Recent work has shown that control theory can help with the convergence of a GAN's training. This paper extends this line of work, conducting a control-theoretic analysis of GAIL and deriving a novel controller that not only pushes GAIL to the desired equilibrium but also achieves asymptotic stability in a 'one-step' setting. Based on this, we propose a practical algorithm 'Controlled-GAIL' (C-GAIL). On MuJoCo tasks, our controlled variant is able to speed up the rate of conve
    
[^14]: 基于信息的转导式主动学习

    Information-based Transductive Active Learning

    [https://arxiv.org/abs/2402.15898](https://arxiv.org/abs/2402.15898)

    ITL是一种基于信息的转导式学习方法，可以在现实世界设置中自适应采样，以最大化关于指定预测目标的信息获取，并在少样本微调和安全贝叶斯优化应用中显著优于最先进技术。

    

    我们将主动学习推广到解决现实世界中采样受限于可访问域的情况，而预测目标可能位于这个域之外。为此，我们提出了ITL，即基于信息的转导式学习，一种自适应采样的方法，旨在最大化关于指定预测目标的信息获取。在一般正则性假设下，我们展示了ITL收敛到可从可访问数据中获得的最小可能不确定性。我们在两个关键应用中展示了ITL：大型神经网络的少样本微调和安全贝叶斯优化，在两种情况下，ITL明显优于最先进技术。

    arXiv:2402.15898v1 Announce Type: cross  Abstract: We generalize active learning to address real-world settings where sampling is restricted to an accessible region of the domain, while prediction targets may lie outside this region. To this end, we propose ITL, short for information-based transductive learning, an approach which samples adaptively to maximize the information gained about specified prediction targets. We show, under general regularity assumptions, that ITL converges uniformly to the smallest possible uncertainty obtainable from the accessible data. We demonstrate ITL in two key applications: Few-shot fine-tuning of large neural networks and safe Bayesian optimization, and in both cases, ITL significantly outperforms the state-of-the-art.
    
[^15]: 因果潜在因子模型中的双重稳健推断

    Doubly Robust Inference in Causal Latent Factor Models

    [https://arxiv.org/abs/2402.11652](https://arxiv.org/abs/2402.11652)

    提出了一种双重稳健的估计量框架，可以在现代数据丰富的环境中估计存在未观察混杂因素下平均处理效应，具有良好的有限样本和渐近性质，并在参数速率下将其误差收敛为零均值高斯分布。

    

    本文介绍了一种在现代数据丰富环境中估计存在未观察混杂因素下的平均处理效应的新框架，该环境具有大量单位和结果。所提出的估计量是双重稳健的，结合了结果填补、倒数概率加权以及一种用于矩阵补全的新型交叉配对程序。我们推导了有限样本和渐近保证，并展示了新估计量的误差收敛到参数速率下的零均值高斯分布。模拟结果展示了本文分析的估计量的形式特性的实际相关性。

    arXiv:2402.11652v1 Announce Type: cross  Abstract: This article introduces a new framework for estimating average treatment effects under unobserved confounding in modern data-rich environments featuring large numbers of units and outcomes. The proposed estimator is doubly robust, combining outcome imputation, inverse probability weighting, and a novel cross-fitting procedure for matrix completion. We derive finite-sample and asymptotic guarantees, and show that the error of the new estimator converges to a mean-zero Gaussian distribution at a parametric rate. Simulation results demonstrate the practical relevance of the formal properties of the estimators analyzed in this article.
    
[^16]: OptEx: 利用近似并行化迭代加速一阶优化

    OptEx: Expediting First-Order Optimization with Approximately Parallelized Iterations

    [https://arxiv.org/abs/2402.11427](https://arxiv.org/abs/2402.11427)

    OptEx是第一个通过利用并行计算来减轻一阶优化的迭代瓶颈并增强效率的框架，使用核化梯度估计实现迭代的并行化，提供理论保证。

    

    第一阶优化（FOO）算法在诸如机器学习和信号去噪等众多计算领域中至关重要。然而，将它们应用于神经网络训练等复杂任务往往导致显著的低效，因为需要许多顺序迭代以实现收敛。为此，我们引入了第一阶优化加速近似并行迭代（OptEx），这是第一个通过利用并行计算来减轻其迭代瓶颈而增强FOO效率的框架。OptEx采用核化梯度估计来利用梯度历史进行未来梯度预测，实现了迭代的并行化 -- 这是一种曾经被认为由于FOO中固有的迭代依赖而不切实际的策略。我们为我们的核化梯度估计的可靠性和基于SGD的OptEx的迭代复杂度提供理论保证，并确认了其可靠性。

    arXiv:2402.11427v1 Announce Type: cross  Abstract: First-order optimization (FOO) algorithms are pivotal in numerous computational domains such as machine learning and signal denoising. However, their application to complex tasks like neural network training often entails significant inefficiencies due to the need for many sequential iterations for convergence. In response, we introduce first-order optimization expedited with approximately parallelized iterations (OptEx), the first framework that enhances the efficiency of FOO by leveraging parallel computing to mitigate its iterative bottleneck. OptEx employs kernelized gradient estimation to make use of gradient history for future gradient prediction, enabling parallelization of iterations -- a strategy once considered impractical because of the inherent iterative dependency in FOO. We provide theoretical guarantees for the reliability of our kernelized gradient estimation and the iteration complexity of SGD-based OptEx, confirming t
    
[^17]: 将文化差异纳入大型语言模型的研究

    CultureLLM: Incorporating Cultural Differences into Large Language Models

    [https://arxiv.org/abs/2402.10946](https://arxiv.org/abs/2402.10946)

    提出了一种名为CultureLLM的成本效益高的解决方案，通过使用世界价值调查（WVS）作为种子数据，并通过提出的语义数据增强来将文化差异纳入大型语言模型中，成功微调得到了涵盖富裕和低资源语言的9种文化特定LLMs以及一个统一模型（CultureLLM-One）。

    

    大型语言模型（LLMs）被报道偏向于某些文化，因为训练数据主要来自英语语料库。由于多语种文化数据通常较难收集，现有的工作通过提示工程或特定文化的预训练来处理这一问题。然而，它们可能忽视了低资源文化的知识缺乏，并需要大量的计算资源。本文提出了CultureLLM，这是一个成本效益高的解决方案，可将文化差异纳入LLMs中。CultureLLM采用世界价值调查（WVS）作为种子数据，并通过提出的语义数据增强生成语义等效的训练数据。仅使用来自WVS的50个种子样本和增强数据，我们对9种包括富裕和低资源语言的文化特定LLMs和一个统一模型（CultureLLM-One）进行了微调。对60个与文化相关的数据集进行的大量实验表明，CultureLLM在增强LLM的文化特性方面取得了显著的成果。

    arXiv:2402.10946v1 Announce Type: cross  Abstract: Large language models (LLMs) are reported to be partial to certain cultures owing to the training data dominance from the English corpora. Since multilingual cultural data are often expensive to collect, existing efforts handle this by prompt engineering or culture-specific pre-training. However, they might overlook the knowledge deficiency of low-resource culture and require extensive computing resources. In this paper, we propose CultureLLM, a cost-effective solution to incorporate cultural differences into LLMs. CultureLLM adopts World Value Survey (WVS) as seed data and generates semantically equivalent training data via the proposed semantic data augmentation. Using only 50 seed samples from WVS with augmented data, we fine-tune culture-specific LLMs and one unified model (CultureLLM-One) for 9 cultures covering rich and low-resource languages. Extensive experiments on 60 culture-related datasets demonstrate that CultureLLM signif
    
[^18]: AutoMathText：使用语言模型进行数学文本的自主数据选择

    AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts

    [https://arxiv.org/abs/2402.07625](https://arxiv.org/abs/2402.07625)

    本论文介绍了一种自主数据选择策略，利用语言模型进行数学文本的自动评估和选择，并通过连续预训练显著提高了数学推理能力。主要创新包括利用元提示语言模型作为验证器，发布了高质量的AutoMathText数据集，并实现了预训练令牌效率的提升。

    

    为了通过持续的预训练改善语言模型在数学推理方面的能力，我们引入了一种新颖的策略，利用基础语言模型进行自主数据选择。与传统的有人工标注数据的监督微调或训练过的分类器不同，我们的方法利用元提示语言模型作为零样本验证器，自主评估和选择高质量的数学内容，并发布了经过策划的开源AutoMathText数据集，其中包含超过200GB的数据。为了证明我们方法的有效性，我们对AutoMathText数据集进行了连续预训练，使得7B参数的Mistral语言模型在MATH数据集上的下游性能大幅提升，而令牌数量比之前的连续预训练工作减少了几个数量级。我们的方法展示了基准的预训练令牌效率提高了2倍，突显了我们方法在增强中的潜力。

    To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or trained classifiers with human-annotated data, our approach utilizes meta-prompted language models as zero-shot verifiers to autonomously evaluate and select high-quality mathematical content, and we release the curated open-source AutoMathText dataset encompassing over 200GB of data. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter Mistral language model on the AutoMathText dataset, achieving substantial improvements in downstream performance on the MATH dataset with a token amount reduced by orders of magnitude compared to previous continuous pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to baselines, underscoring the potential of our approach in enhancing
    
[^19]: EuLagNet: 拉格朗日动力学的欧拉预测

    EuLagNet: Eulerian Fluid Prediction with Lagrangian Dynamics

    [https://arxiv.org/abs/2402.02425](https://arxiv.org/abs/2402.02425)

    EuLagNet提出了一种新的拉格朗日引导范式，通过跟踪多尺度关键粒子的运动来捕捉多尺度流体动力学。这种方法克服了由于欧拉观察而导致的流体动力学困难，为准确预测未来的流体提供了一种有效的方法。

    

    准确预测未来的流体对气象学、海洋学和空气动力学等广泛领域至关重要。然而，由于流体通常从欧拉角度观察，其活跃和复杂的动力学在静止的网格中严重被掩盖和混淆，给预测带来了巨大挑战。本文引入了一种新的拉格朗日引导范式来解决复杂的流体动力学。我们提出了以拉格朗日动力学为导向的欧拉-拉格朗日双重递归网络（EuLagNet），通过跟踪自适应采样的多尺度关键粒子的运动并随时间积累动力学信息来捕捉多尺度流体动力学。具体地，我们提出了一个EuLag块，用于在每个时刻和尺度上传递学习到的欧拉和拉格朗日特征，其中跟踪粒子的运动是从欧拉观察中推断出来的，它们积累的动力学信息被纳入到预测模型中。

    Accurately predicting the future fluid is important to extensive areas, such as meteorology, oceanology and aerodynamics. However, since the fluid is usually observed from an Eulerian perspective, its active and intricate dynamics are seriously obscured and confounded in static grids, bringing horny challenges to the prediction. This paper introduces a new Lagrangian-guided paradigm to tackle the tanglesome fluid dynamics. Instead of solely predicting the future based on Eulerian observations, we propose the Eulerian-Lagrangian Dual Recurrent Network (EuLagNet), which captures multiscale fluid dynamics by tracking movements of adaptively sampled key particles on multiple scales and integrating dynamics information over time. Concretely, a EuLag Block is presented to communicate the learned Eulerian and Lagrangian features at each moment and scale, where the motion of tracked particles is inferred from Eulerian observations and their accumulated dynamics information is incorporated into
    
[^20]: 视觉语言模型中的心理现象记忆

    D\'ej\`a Vu Memorization in Vision-Language Models

    [https://arxiv.org/abs/2402.02103](https://arxiv.org/abs/2402.02103)

    这项研究提出了一种新方法来衡量视觉语言模型中的记忆现象，并发现对于使用图像-标题对进行训练的VLMs，模型确实会保留关于训练图像中的个别对象的信息，文本随机化可以在很大程度上减轻记忆现象而对模型的下游任务性能影响较小。

    

    视觉语言模型（VLM）作为最先进的表示学习解决方案出现，具有诸多下游应用，如图像分类、检索和生成。一个自然的问题是这些模型是否会记忆训练数据，这也对泛化有着影响。我们提出了一种衡量VLMs中记忆的新方法，称之为心理现象记忆。对于在图像-标题对上训练的VLMs，我们展示了该模型确实保留了关于训练图像中个别对象的信息，超出了从相关性或图像标题中可以推断出的范畴。我们在样本和总体水平上评估了心理现象记忆，并展示了OpenCLIP在多达5000万个图像-标题对上训练时的显著性。最后，我们展示了文本随机化在很大程度上减轻了记忆，同时对模型的下游任务性能产生了适度影响。

    Vision-Language Models (VLMs) have emerged as the state-of-the-art representation learning solution, with myriads of downstream applications such as image classification, retrieval and generation. A natural question is whether these models memorize their training data, which also has implications for generalization. We propose a new method for measuring memorization in VLMs, which we call d\'ej\`a vu memorization. For VLMs trained on image-caption pairs, we show that the model indeed retains information about individual objects in the training images beyond what can be inferred from correlations or the image caption. We evaluate d\'ej\`a vu memorization at both sample and population level, and show that it is significant for OpenCLIP trained on as many as 50M image-caption pairs. Finally, we show that text randomization considerably mitigates memorization while only moderately impacting the model's downstream task performance.
    
[^21]: 使用文本数据的近因果推断

    Proximal Causal Inference With Text Data. (arXiv:2401.06687v1 [cs.CL])

    [http://arxiv.org/abs/2401.06687](http://arxiv.org/abs/2401.06687)

    本论文提出了一种使用文本数据进行近因果推断的方法，通过将文本数据分割并使用零样本模型推断出代理变量，然后应用于近邻 g-formula，从而解决了混淆变量完全未观察到的情况。实验结果表明该方法产生了低偏差的估计值。

    

    最近的基于文本的因果方法试图通过将非结构化文本数据作为倾向于包含部分或不完全测量的混淆变量的代理来减轻混淆偏差。这些方法假设分析人员在一部分实例的文本中具有有监督的混淆变量标签，但由于数据隐私或成本，这种约束并不总是可行。在这里，我们解决了一个重要的混淆变量完全未观察到的情况。我们提出了一种新的因果推断方法，将处理前文本数据分割，并使用两个零样本模型从分割的两个部分推断出两个代理，并将这些代理应用于近邻 g-formula。我们证明了我们基于文本的代理方法满足近邻 g-formula所需的识别条件，而其他看似合理的提议则不满足。我们在合成和半合成环境中评估了我们的方法，并发现它产生了低偏差的估计值。

    Recent text-based causal methods attempt to mitigate confounding bias by including unstructured text data as proxies of confounding variables that are partially or imperfectly measured. These approaches assume analysts have supervised labels of the confounders given text for a subset of instances, a constraint that is not always feasible due to data privacy or cost. Here, we address settings in which an important confounding variable is completely unobserved. We propose a new causal inference method that splits pre-treatment text data, infers two proxies from two zero-shot models on the separate splits, and applies these proxies in the proximal g-formula. We prove that our text-based proxy method satisfies identification conditions required by the proximal g-formula while other seemingly reasonable proposals do not. We evaluate our method in synthetic and semi-synthetic settings and find that it produces estimates with low bias. This combination of proximal causal inference and zero-sh
    
[^22]: 可解释概念瓶颈用于对齐强化学习代理

    Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents. (arXiv:2401.05821v1 [cs.LG])

    [http://arxiv.org/abs/2401.05821](http://arxiv.org/abs/2401.05821)

    SCoBots是一种可解释的概念瓶颈代理，能够透明化整个决策流程，帮助领域专家理解和规范强化学习代理的行为，从而可能实现更好的人类对齐强化学习。

    

    奖励稀疏性、难以归因的问题以及不对齐等等都是深度强化学习代理学习最优策略困难甚至不可能的原因之一。不幸的是，深度网络的黑盒特性阻碍了领域专家的参与，这些专家可以解释模型并纠正错误行为。为此，我们引入了连续概念瓶颈代理（SCoBots），通过整合连续的概念瓶颈层，使整个决策流程透明化。SCoBots不仅利用相关的对象属性，还利用关系概念。实验结果强有力地证明，SCoBots使领域专家能够有效理解和规范他们的行为，从而可能实现更好的人类对齐强化学习。通过这种方式，SCoBots使我们能够识别最简单且具有代表性的视频游戏Pong中的不对齐问题，并加以解决。

    Reward sparsity, difficult credit assignment, and misalignment are only a few of the many issues that make it difficult, if not impossible, for deep reinforcement learning (RL) agents to learn optimal policies. Unfortunately, the black-box nature of deep networks impedes the inclusion of domain experts who could interpret the model and correct wrong behavior. To this end, we introduce Successive Concept Bottlenecks Agents (SCoBots), which make the whole decision pipeline transparent via the integration of consecutive concept bottleneck layers. SCoBots make use of not only relevant object properties but also of relational concepts. Our experimental results provide strong evidence that SCoBots allow domain experts to efficiently understand and regularize their behavior, resulting in potentially better human-aligned RL. In this way, SCoBots enabled us to identify a misalignment problem in the most simple and iconic video game, Pong, and resolve it.
    
[^23]: 使用线性控制神经ODE将归一化流作为最优传输映射的近似

    Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs. (arXiv:2311.01404v1 [math.OC])

    [http://arxiv.org/abs/2311.01404](http://arxiv.org/abs/2311.01404)

    本文以线性控制神经ODE的流动作为归一化流构造最优传输映射的近似。通过离散最优耦合问题和数值方案，实现了对最优传输映射的近似。最终结果有助于构建深度神经网络中的可逆传输映射。

    

    "归一化流"一词与通过深度神经网络构建概率测度之间的可逆传输映射相关。本文考虑将$W_2$-最优传输映射$T$恢复为线性控制神经ODE的流动的问题。我们首先展示了在合适的假设下，对于绝对连续测度$\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$和受控向量场，最优传输映射包含在系统产生的流动的$C^0_c$闭包中。假设原始测度$\mu,\nu$的离散近似$\mu_N,\nu_N$可用，我们使用离散最优耦合$\gamma_N$来定义最优控制问题。通过$\Gamma$-收敛论证，我们证明其解对应于近似最优传输映射$T$的流动。最后，利用Pontryagin最大原理，我们提出了一种迭代数值方案来解决问题。

    The term "Normalizing Flows" is related to the task of constructing invertible transport maps between probability measures by means of deep neural networks. In this paper, we consider the problem of recovering the $W_2$-optimal transport map $T$ between absolutely continuous measures $\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neural ODE. We first show that, under suitable assumptions on $\mu,\nu$ and on the controlled vector fields, the optimal transport map is contained in the $C^0_c$-closure of the flows generated by the system. Assuming that discrete approximations $\mu_N,\nu_N$ of the original measures $\mu,\nu$ are available, we use a discrete optimal coupling $\gamma_N$ to define an optimal control problem. With a $\Gamma$-convergence argument, we prove that its solutions correspond to flows that approximate the optimal transport map $T$. Finally, taking advantage of the Pontryagin Maximum Principle, we propose an iterative numerical scheme for the reso
    
[^24]: 外部验证策略评估结合试验和观察数据

    Externally Valid Policy Evaluation Combining Trial and Observational Data. (arXiv:2310.14763v1 [stat.ME])

    [http://arxiv.org/abs/2310.14763](http://arxiv.org/abs/2310.14763)

    这项研究提出了一种结合试验和观察数据的外部有效策略评估方法，利用试验数据对目标人群上的政策结果进行有效推断，并给出了可验证的评估结果。

    

    随机试验被广泛认为是评估决策策略影响的金 standard。然而，试验数据来自可能与目标人群不同的人群，这引发了外部效度（也称为泛化能力）的问题。在本文中，我们试图利用试验数据对目标人群上的政策结果进行有效推断。目标人群的额外协变量数据用于模拟试验研究中个体的抽样。我们开发了一种方法，在任何指定的模型未校准范围内产生可验证的基于试验的政策评估。该方法是非参数的，即使样本是有限的，有效性也得到保证。使用模拟和实际数据说明了认证的政策评估结果。

    Randomized trials are widely considered as the gold standard for evaluating the effects of decision policies. Trial data is, however, drawn from a population which may differ from the intended target population and this raises a problem of external validity (aka. generalizability). In this paper we seek to use trial data to draw valid inferences about the outcome of a policy on the target population. Additional covariate data from the target population is used to model the sampling of individuals in the trial study. We develop a method that yields certifiably valid trial-based policy evaluations under any specified range of model miscalibrations. The method is nonparametric and the validity is assured even with finite samples. The certified policy evaluations are illustrated using both simulated and real data.
    
[^25]: 不规则系统的逆重整群

    Inverse Renormalization Group of Disordered Systems. (arXiv:2310.12631v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2310.12631](http://arxiv.org/abs/2310.12631)

    本文介绍了一种逆重整群的方法，通过机器学习算法构造了缩放的晶格配置，用于研究自旋玻璃。该方法可以实现在不使用超级计算机的情况下，探索不断增大的晶格体积下的精确配置。

    

    我们提出了逆重整群变换，用于构建尚未被超级计算机或大规模模拟方法所访问的晶格体积的近似配置，以研究自旋玻璃。具体而言，在三维爱德华-安德森模型的情况下，从体积为$V=8^{3}$的晶格开始，我们采用机器学习算法构造了经过缩放的晶格，最大到$V'=128^{3}$，并提取了两个临界指数。最后，我们讨论了如何在逆重整群方法中融入数值精确性，从而为不断增大的晶格体积提供了探索可持续、节能的精确配置，而无需使用专用超级计算机。

    We propose inverse renormalization group transformations to construct approximate configurations for lattice volumes that have not yet been accessed by supercomputers or large-scale simulations in the study of spin glasses. Specifically, starting from lattices of volume $V=8^{3}$ in the case of the three-dimensional Edwards-Anderson model we employ machine learning algorithms to construct rescaled lattices up to $V'=128^{3}$, which we utilize to extract two critical exponents. We conclude by discussing how to incorporate numerical exactness within inverse renormalization group approaches of disordered systems, thus opening up the opportunity to explore a sustainable and energy-efficient generation of exact configurations for increasing lattice volumes without the use of dedicated supercomputers.
    
[^26]: 关于通过指数机制进行高维私有模型选择的计算复杂性

    On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])

    [http://arxiv.org/abs/2310.07852](http://arxiv.org/abs/2310.07852)

    本文研究了在高维稀疏线性回归模型中的差分隐私模型选择问题。我们使用指数机制进行模型选择，并提出了Metropolis-Hastings算法来克服指数搜索空间的计算复杂性。我们的算法在一定边界条件下能够实现强模型恢复性质，并具有多项式混合时间和近似差分隐私性质。

    

    在差分隐私框架下，我们考虑了高维稀疏线性回归模型中的模型选择问题。具体而言，我们考虑了差分隐私最佳子集选择的问题，并研究了其效用保证。我们采用了广为人知的指数机制来选择最佳模型，并在一定边界条件下，建立了其强模型恢复性质。然而，指数机制的指数搜索空间导致了严重的计算瓶颈。为了克服这个挑战，我们提出了Metropolis-Hastings算法来进行采样步骤，并在问题参数$n$、$p$和$s$中建立了其到稳态分布的多项式混合时间。此外，我们还利用其混合性质建立了Metropolis-Hastings随机行走的最终估计的近似差分隐私性质。最后，我们还进行了一些说明性模拟，印证了我们主要结果的理论发现。

    We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
    
[^27]: 基于神经切向核的联邦平均在深度线性神经网络上的视角

    A Neural Tangent Kernel View on Federated Averaging for Deep Linear Neural Network. (arXiv:2310.05495v1 [cs.LG])

    [http://arxiv.org/abs/2310.05495](http://arxiv.org/abs/2310.05495)

    本论文介绍了一种基于神经切向核视角的联邦平均方法在深度线性神经网络上的应用，并探讨了该方法面临的挑战。

    

    联邦平均（FedAvg）是一种广泛使用的范式，用于在不共享数据的情况下协同训练来自分布式客户端的模型。如今，由于其卓越性能，神经网络取得了显著的成功，这使得它成为FedAvg中的首选模型。然而，神经网络的优化问题通常是非凸的甚至是非光滑的。此外，FedAvg总是涉及多个客户端和本地更新，导致不准确的更新方向。这些属性给分析FedAvg在训练神经网络中的收敛性带来了困难。最近，神经切向核（NTK）理论已被提出，用于理解解决神经网络非凸问题中的一阶方法的收敛性。深度线性神经网络是理论学科中的经典模型，由于其简单的公式。然而，在训练深度线性神经网络上，对于FedAvg的收敛性目前还没有理论结果。

    Federated averaging (FedAvg) is a widely employed paradigm for collaboratively training models from distributed clients without sharing data. Nowadays, the neural network has achieved remarkable success due to its extraordinary performance, which makes it a preferred choice as the model in FedAvg. However, the optimization problem of the neural network is often non-convex even non-smooth. Furthermore, FedAvg always involves multiple clients and local updates, which results in an inaccurate updating direction. These properties bring difficulties in analyzing the convergence of FedAvg in training neural networks. Recently, neural tangent kernel (NTK) theory has been proposed towards understanding the convergence of first-order methods in tackling the non-convex problem of neural networks. The deep linear neural network is a classical model in theoretical subject due to its simple formulation. Nevertheless, there exists no theoretical result for the convergence of FedAvg in training the d
    
[^28]: 联邦深度平衡学习：边缘通信效率的紧凑共享表示

    Federated Deep Equilibrium Learning: A Compact Shared Representation for Edge Communication Efficiency. (arXiv:2309.15659v1 [cs.LG])

    [http://arxiv.org/abs/2309.15659](http://arxiv.org/abs/2309.15659)

    FeDEQ是一个联邦学习框架，采用深度平衡学习和共识优化，通过紧凑的共享数据表示在边缘节点之间共享模型，解决了深度联邦学习在边缘环境中的通信瓶颈和数据异构性问题。

    

    联邦学习是一种卓越的分布式学习范式，促进了边缘网络节点之间的协作，以在不集中数据的情况下共同训练全局模型。通过将计算转移到网络边缘，联邦学习提供了鲁棒和响应迅速的边缘人工智能解决方案，并增强了隐私保护。然而，在边缘环境中部署深度联邦学习模型通常受到通信瓶颈、数据异构性和内存限制的阻碍。为了共同解决这些挑战，我们引入了FeDEQ，这是一个开创性的联邦学习框架，它有效地采用深度平衡学习和共识优化，在边缘节点之间利用紧凑的共享数据表示，允许派生出针对每个节点特定的个性化模型。我们深入探讨了一个独特的模型结构，由一个平衡层和传统神经网络层组成。在这里，平衡层充当全局特征表示，边缘节点可以根据自己的需求进行个性化调整。

    Federated Learning (FL) is a prominent distributed learning paradigm facilitating collaboration among nodes within an edge network to co-train a global model without centralizing data. By shifting computation to the network edge, FL offers robust and responsive edge-AI solutions and enhance privacy-preservation. However, deploying deep FL models within edge environments is often hindered by communication bottlenecks, data heterogeneity, and memory limitations. To address these challenges jointly, we introduce FeDEQ, a pioneering FL framework that effectively employs deep equilibrium learning and consensus optimization to exploit a compact shared data representation across edge nodes, allowing the derivation of personalized models specific to each node. We delve into a unique model structure composed of an equilibrium layer followed by traditional neural network layers. Here, the equilibrium layer functions as a global feature representation that edge nodes can adapt to personalize thei
    
[^29]: 基于多智能体深度强化学习的AI驱动患者监测

    AI-Driven Patient Monitoring with Multi-Agent Deep Reinforcement Learning. (arXiv:2309.10980v1 [cs.LG])

    [http://arxiv.org/abs/2309.10980](http://arxiv.org/abs/2309.10980)

    本研究提出了一种基于多智能体深度强化学习的AI驱动患者监测框架，通过部署多个学习智能体，针对不同的生理特征进行监测，并根据紧急程度预警医疗紧急团队。

    

    有效的患者监测对及时干预和改善医疗结果至关重要。传统的监测系统往往难以处理复杂、动态的环境和波动的生命体征，导致延迟发现危急情况。为了应对这一挑战，我们提出了一种新颖的基于多智能体深度强化学习（DRL）的AI驱动患者监测框架。我们的方法部署了多个学习智能体，每个智能体专门负责监测特定的生理特征，如心率、呼吸和体温。这些智能体与通用的医疗监测环境进行交互，学习患者的行为模式，并根据估计的紧急程度做出通知相应医疗紧急团队（MET）的决策。在本研究中，我们使用来自两个数据集（PPG-DaLiA和WESAD）的真实生理和运动数据评估了提出的多智能体DRL框架的性能。

    Effective patient monitoring is vital for timely interventions and improved healthcare outcomes. Traditional monitoring systems often struggle to handle complex, dynamic environments with fluctuating vital signs, leading to delays in identifying critical conditions. To address this challenge, we propose a novel AI-driven patient monitoring framework using multi-agent deep reinforcement learning (DRL). Our approach deploys multiple learning agents, each dedicated to monitoring a specific physiological feature, such as heart rate, respiration, and temperature. These agents interact with a generic healthcare monitoring environment, learn the patients' behavior patterns, and make informed decisions to alert the corresponding Medical Emergency Teams (METs) based on the level of emergency estimated. In this study, we evaluate the performance of the proposed multi-agent DRL framework using real-world physiological and motion data from two datasets: PPG-DaLiA and WESAD. We compare the results 
    
[^30]: 不变风险最小化的区外优化性

    Out-of-Distribution Optimality of Invariant Risk Minimization. (arXiv:2307.11972v1 [stat.ML])

    [http://arxiv.org/abs/2307.11972](http://arxiv.org/abs/2307.11972)

    本文旨在提供IRM的理论验证，严格证明了解决方案可以最小化区外风险。

    

    深度神经网络经常继承训练数据中嵌入的虚假相关性，因此可能无法泛化到具有与提供训练数据的领域不同的未知域。M. Arjovsky等人（2019年）引入了区外（o.o.d.）风险的概念，即所有域中的最大风险，并将由虚假相关性引起的问题规定为最小化区外风险的问题。不变风险最小化（IRM）被认为是最小化区外风险的一种有前途的方法：IRM通过解决一个双层优化问题来估计最小化的区外风险。尽管IRM以实证成功吸引了相当多的关注，但它缺乏一些理论保证。特别是，还没有确立双层优化问题给出最小化区外风险的坚实理论保证。本文旨在提供IRM的理论验证，严格证明了解决方案可以通过在大仿真跟踪数据库中进行实时仿真，其包括对周围环境的直接感知，对潜在路线规划的策略认识，同时考虑到多车辆交互，以实现该问题的全局优化目标。

    Deep Neural Networks often inherit spurious correlations embedded in training data and hence may fail to generalize to unseen domains, which have different distributions from the domain to provide training data. M. Arjovsky et al. (2019) introduced the concept out-of-distribution (o.o.d.) risk, which is the maximum risk among all domains, and formulated the issue caused by spurious correlations as a minimization problem of the o.o.d. risk. Invariant Risk Minimization (IRM) is considered to be a promising approach to minimize the o.o.d. risk: IRM estimates a minimum of the o.o.d. risk by solving a bi-level optimization problem. While IRM has attracted considerable attention with empirical success, it comes with few theoretical guarantees. Especially, a solid theoretical guarantee that the bi-level optimization problem gives the minimum of the o.o.d. risk has not yet been established. Aiming at providing a theoretical justification for IRM, this paper rigorously proves that a solution to
    
[^31]: 联邦式大规模语言模型：一个立场论文

    Federated Large Language Model: A Position Paper. (arXiv:2307.08925v1 [cs.LG])

    [http://arxiv.org/abs/2307.08925](http://arxiv.org/abs/2307.08925)

    我们提出了联邦式大规模语言模型的概念，通过联邦学习实现分散数据的共同训练共享模型，以应对公共数据可用性的限制和私有数据的隐私保护需求。我们讨论了预训练、微调和提示工程这三个组件的优势，并提出了实施策略。同时，我们探讨了FL和LLM集成带来的新挑战，并分析了现有解决方案和潜在障碍。

    

    大规模语言模型（LLM）在各个领域获得了相当大的关注并找到了多样化的应用，但在真实场景中开发时面临挑战。这些挑战源于公共领域数据可用性的匮乏以及对私有领域数据的隐私保护需求。为了解决这些问题，联邦学习（FL）作为一项有前景的技术出现了，它能够在保持分散数据的同时实现共同训练共享模型。我们提出了联邦式LLM的概念，包括三个关键组成部分，即联邦式LLM预训练、联邦式LLM微调和联邦式LLM提示工程。对于每个组件，我们讨论了它相对于传统LLM训练方法的优势，并提出了具体的工程策略来实施。此外，我们探讨了FL和LLM集成带来的新挑战。我们分析现有的解决方案并确定可能的障碍

    Large scale language models (LLM) have received significant attention and found diverse applications across various domains, but their development encounters challenges in real-world scenarios. These challenges arise due to the scarcity of public domain data availability and the need to maintain privacy with respect to private domain data. To address these issues, federated learning (FL) has emerged as a promising technology that enables collaborative training of shared models while preserving decentralized data. We propose the concept of federated LLM, which comprises three key components, i.e., federated LLM pre-training, federated LLM fine-tuning, and federated LLM prompt engineering. For each component, we discuss its advantage over traditional LLM training methods and propose specific engineering strategies for implementation. Furthermore, we explore the novel challenges introduced by the integration of FL and LLM. We analyze existing solutions and identify potential obstacles fac
    
[^32]: 人工深度神经网络中的吸收相变

    Absorbing Phase Transitions in Artificial Deep Neural Networks. (arXiv:2307.02284v1 [stat.ML])

    [http://arxiv.org/abs/2307.02284](http://arxiv.org/abs/2307.02284)

    本文研究了在适当初始化的有限神经网络中的吸收相变及其普适性，证明了即使在有限网络中仍然存在着从有序状态到混沌状态的过渡，并且不同的网络架构会反映在过渡的普适类上。

    

    由于著名的平均场理论，对于各种体系的无限宽度神经网络的行为的理论理解已经迅速发展。然而，对于更实际和现实重要性更强的有限网络，缺乏清晰直观的框架来延伸我们的理解。在本文中，我们展示了适当初始化的神经网络的行为可以用吸收相变中的普遍临界现象来理解。具体而言，我们研究了全连接前馈神经网络和卷积神经网络中从有序状态到混沌状态的相变，并强调了体系架构的差异与相变的普适类之间的关系。值得注意的是，我们还成功地应用了有限尺度扩展的方法，这表明了直观的现象学。

    Theoretical understanding of the behavior of infinitely-wide neural networks has been rapidly developed for various architectures due to the celebrated mean-field theory. However, there is a lack of a clear, intuitive framework for extending our understanding to finite networks that are of more practical and realistic importance. In the present contribution, we demonstrate that the behavior of properly initialized neural networks can be understood in terms of universal critical phenomena in absorbing phase transitions. More specifically, we study the order-to-chaos transition in the fully-connected feedforward neural networks and the convolutional ones to show that (i) there is a well-defined transition from the ordered state to the chaotics state even for the finite networks, and (ii) difference in architecture is reflected in that of the universality class of the transition. Remarkably, the finite-size scaling can also be successfully applied, indicating that intuitive phenomenologic
    
[^33]: 图像网为何与LAION网络截然不同

    What Makes ImageNet Look Unlike LAION. (arXiv:2306.15769v1 [cs.LG])

    [http://arxiv.org/abs/2306.15769](http://arxiv.org/abs/2306.15769)

    本研究通过重新搜索大规模的LAION数据集，尝试重新创建图像网，并发现与原始图像网相比，新建的LAIONet具有明显不同之处。这种差异的原因是，在基于图像描述进行搜索时，存在信息瓶颈，从而减轻了选择偏差。

    

    图像网是通过Flickr图像搜索结果创建的。如果我们仅根据图像描述重新创建图像网，搜索大规模的LAION数据集会发生什么呢？本研究进行了这个反事实的调查。我们发现重新创建的图像网，我们称之为LAIONet，与原始图像网有明显不同之处。具体而言，原始图像网中图像的类内相似性远高于LAIONet。因此，在图像网上训练的模型在LAIONet上表现明显较差。我们提出了一个严格解释这种差异的观点，并通过系统性的实验予以支持。简而言之，仅基于图像描述进行搜索会产生信息瓶颈，从而减轻了基于图像过滤时存在的选择偏差。我们的解释形式化了一个长期的直觉。

    ImageNet was famously created from Flickr image search results. What if we recreated ImageNet instead by searching the massive LAION dataset based on image captions alone? In this work, we carry out this counterfactual investigation. We find that the resulting ImageNet recreation, which we call LAIONet, looks distinctly unlike the original. Specifically, the intra-class similarity of images in the original ImageNet is dramatically higher than it is for LAIONet. Consequently, models trained on ImageNet perform significantly worse on LAIONet. We propose a rigorous explanation for the discrepancy in terms of a subtle, yet important, difference in two plausible causal data-generating processes for the respective datasets, that we support with systematic experimentation. In a nutshell, searching based on an image caption alone creates an information bottleneck that mitigates the selection bias otherwise present in image-based filtering. Our explanation formalizes a long-held intuition in th
    
[^34]: S-TLLR: 受到时间局部学习规则的STDP启发的脉冲神经网络

    S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks. (arXiv:2306.15220v1 [cs.NE])

    [http://arxiv.org/abs/2306.15220](http://arxiv.org/abs/2306.15220)

    S-TLLR是一个受到STDP机制启发的时间局部学习规则，可以用于训练脉冲神经网络，同时考虑到了因果和非因果关系。

    

    脉冲神经网络（SNN）是可用于边缘智能的生物学合理模型，特别适用于顺序学习任务。然而，SNN的训练面临着精确的时间和空间信用分配的挑战。尽管BPTT算法是解决这些问题最常用的方法，但由于其时间依赖性，它产生了较高的计算成本。此外，BPTT及其近似仅利用从脉冲活动中导出的因果信息来计算突触更新，从而忽略了非因果关系。在这项工作中，我们提出了S-TLLR，这是一种受到Spike-Timing Dependent Plasticity（STDP）机制启发的新型三因素时间局部学习规则，旨在用于事件驱动学习任务的SNN训练。S-TLLR同时考虑了前后突触之间的因果和非因果关系。

    Spiking Neural Networks (SNNs) are biologically plausible models that have been identified as potentially apt for the deployment for energy-efficient intelligence at the edge, particularly for sequential learning tasks. However, training of SNNs poses a significant challenge due to the necessity for precise temporal and spatial credit assignment. Back-propagation through time (BPTT) algorithm, whilst being the most widely used method for addressing these issues, incurs a high computational cost due to its temporal dependency. Moreover, BPTT and its approximations solely utilize causal information derived from the spiking activity to compute the synaptic updates, thus neglecting non-causal relationships. In this work, we propose S-TLLR, a novel three-factor temporal local learning rule inspired by the Spike-Timing Dependent Plasticity (STDP) mechanism, aimed at training SNNs on event-based learning tasks. S-TLLR considers both causal and non-causal relationships between pre and post-syn
    
[^35]: 协作世界模型: 一种在线离线转移RL方法。

    Collaborative World Models: An Online-Offline Transfer RL Approach. (arXiv:2305.15260v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.15260](http://arxiv.org/abs/2305.15260)

    本论文提出了一种名为协作世界模型（CoWorld）的转移学习方法，以改善离线条件下视觉RL的性能。其核心想法是使用易于交互的模拟器来训练辅助RL模型作为离线策略的在线“测试床”，并执行域协作表示学习和域协作行为学习，缓解离线数据分布之外的价值函数过度估计问题。

    

    在离线数据集中训练视觉强化学习（RL）模型由于表征学习中的过度拟合问题和价值函数中的过度估计问题而具有挑战性。在本文中，我们提出了一种称为协作世界模型（CoWorld）的转移学习方法，以改善离线条件下视觉RL的性能。其核心想法是使用易于交互、现成的模拟器来训练辅助RL模型作为离线策略在目标域中学习的在线“测试床”，这为价值函数提供了灵活的约束——直观地说，我们想在不妨碍具有潜在优势的动作探索的情况下缓解离线数据分布之外的价值函数过度估计问题。具体而言，CoWorld执行域协作表示学习以弥合在线和离线隐藏状态分布之间的差距。此外，它执行域协作行为学习，使在离线数据集外的智能体能够学习在线行为策略。

    Training visual reinforcement learning (RL) models in offline datasets is challenging due to overfitting issues in representation learning and overestimation problems in value function. In this paper, we propose a transfer learning method called Collaborative World Models (CoWorld) to improve the performance of visual RL under offline conditions. The core idea is to use an easy-to-interact, off-the-shelf simulator to train an auxiliary RL model as the online "test bed" for the offline policy learned in the target domain, which provides a flexible constraint for the value function -- Intuitively, we want to mitigate the overestimation problem of value functions outside the offline data distribution without impeding the exploration of actions with potential advantages. Specifically, CoWorld performs domain-collaborative representation learning to bridge the gap between online and offline hidden state distributions. Furthermore, it performs domain-collaborative behavior learning that enab
    
[^36]: RHINO：通过匈牙利匹配实现动态降噪的旋转目标检测的旋转DETR

    RHINO: Rotated DETR with Dynamic Denoising via Hungarian Matching for Oriented Object Detection. (arXiv:2305.07598v1 [cs.CV])

    [http://arxiv.org/abs/2305.07598](http://arxiv.org/abs/2305.07598)

    本文提出了一种面向定向目标检测的DINO基线模型RHINO。并通过匈牙利匹配和查询对齐的方式实现动态降噪，解决了重复预测的问题，从而在公共基准测试中达到最先进的性能水平。

    

    随着DINO的发布，一种DETR的变体，检测变压器正在通过其端到端设计和可扩展性在目标检测基准中刷新记录。然而，虽然预计从其端到端架构中获得更多的好处，如消除NMS和与锚相关的成本，但尚未彻底研究DETR在定向目标检测方面的扩展。本文提出了首个面向定向目标检测的DINO基线。我们发现，直接使用DETR进行定向目标检测并不能保证不重复预测，并提出了一种简单的成本来减轻这种情况。此外，我们介绍了一种新的去噪策略，该策略使用匈牙利匹配来过滤冗余的带噪声的查询，并使用查询对齐来保持Transformer解码器层之间的匹配一致性。我们提出的模型在公共基准测试中优于以前的旋转DETR和其他对手，实现了最先进的性能。

    With the publication of DINO, a variant of the Detection Transformer (DETR), Detection Transformers are breaking the record in the object detection benchmark with the merits of their end-to-end design and scalability. However, the extension of DETR to oriented object detection has not been thoroughly studied although more benefits from its end-to-end architecture are expected such as removing NMS and anchor-related costs. In this paper, we propose a first strong DINO-based baseline for oriented object detection. We found that straightforward employment of DETRs for oriented object detection does not guarantee non-duplicate prediction, and propose a simple cost to mitigate this. Furthermore, we introduce a novel denoising strategy that uses Hungarian matching to filter redundant noised queries and query alignment to preserve matching consistency between Transformer decoder layers. Our proposed model outperforms previous rotated DETRs and other counterparts, achieving state-of-the-art pe
    
[^37]: 通用核学习的高效凸优化算法

    Efficient Convex Algorithms for Universal Kernel Learning. (arXiv:2304.07472v1 [stat.ML])

    [http://arxiv.org/abs/2304.07472](http://arxiv.org/abs/2304.07472)

    本文提出了一种基于SVD-QCQP原始对偶算法的高效内核学习实现，用于学习半分离核，大大降低了计算复杂度，并在几个基准数据集上展示了其准确性和速度。

    

    基于核优化的机器学习算法的准确性和复杂性取决于它们能够优化的核集。理想的核集应该：具有线性参数化（以便于可处理性）；在所有核集中密集（以便于鲁棒性）；是通用的（以便于准确性）。最近，提出了一种框架，使用正定矩阵来参数化一类正半分离核。尽管此类核能够满足所有三个标准，但之前用于优化此类核的算法仅限于分类，并且还依赖于计算复杂的半定规划（SDP）算法。在本文中，我们将学习半分离核的问题作为极小化极大化优化问题，并提出了一种SVD-QCQP原始对偶算法，其与之前基于SDP的方法相比，大大降低了计算复杂度。此外，我们提供了一种高效的内核学习实现，并在几个基准数据集上展示了其准确性和速度。

    The accuracy and complexity of machine learning algorithms based on kernel optimization are determined by the set of kernels over which they are able to optimize. An ideal set of kernels should: admit a linear parameterization (for tractability); be dense in the set of all kernels (for robustness); be universal (for accuracy). Recently, a framework was proposed for using positive matrices to parameterize a class of positive semi-separable kernels. Although this class can be shown to meet all three criteria, previous algorithms for optimization of such kernels were limited to classification and furthermore relied on computationally complex Semidefinite Programming (SDP) algorithms. In this paper, we pose the problem of learning semiseparable kernels as a minimax optimization problem and propose a SVD-QCQP primal-dual algorithm which dramatically reduces the computational complexity as compared with previous SDP-based approaches. Furthermore, we provide an efficient implementation of thi
    
[^38]: 强化学习中的实证设计

    Empirical Design in Reinforcement Learning. (arXiv:2304.01315v1 [cs.LG])

    [http://arxiv.org/abs/2304.01315](http://arxiv.org/abs/2304.01315)

    本文是一个关于如何进行良好实验的资源，旨在解决强化学习中实证设计的挑战，并弥补实证研究中可能导致的弱的统计证据。

    

    强化学习中的实证设计不是小任务。进行良好实验需要讲究细节，并且在某些时候需要大量计算资源。最近的研究表明，常用算法对超参数设置和实现细节敏感，并且常见的实证做法会导致弱的统计证据。本文不仅呼吁行动，而且是如何在强化学习中进行良好实验的全面资源。

    Empirical design in reinforcement learning is no small task. Running good experiments requires attention to detail and at times significant computational resources. While compute resources available per dollar have continued to grow rapidly, so have the scale of typical experiments in reinforcement learning. It is now common to benchmark agents with millions of parameters against dozens of tasks, each using the equivalent of 30 days of experience. The scale of these experiments often conflict with the need for proper statistical evidence, especially when comparing algorithms. Recent studies have highlighted how popular algorithms are sensitive to hyper-parameter settings and implementation details, and that common empirical practice leads to weak statistical evidence (Machado et al., 2018; Henderson et al., 2018). Here we take this one step further.  This manuscript represents both a call to action, and a comprehensive resource for how to do good experiments in reinforcement learning. 
    
[^39]: Het-node2vec：异构多图嵌入的二阶随机游走采样方法

    Het-node2vec: second order random walk sampling for heterogeneous multigraphs embedding. (arXiv:2101.01425v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2101.01425](http://arxiv.org/abs/2101.01425)

    Het-node2vec是一个算法框架，通过在异构多图上进行二阶随机游走采样，能够捕获图的结构特征和不同类型节点边的语义，有效地提高对异构图的无监督和有监督学习性能。

    

    在多个真实世界应用中，为异构图开发图表示学习方法是基础性的，因为在多个上下文中，图由不同类型的节点和边所特征化。我们引入了一个算法框架（Het-node2vec），将原始的node2vec节点邻域采样方法扩展到了异构多图上。所得到的随机游走样本捕获了图的结构特征以及不同类型的节点和边的语义。所提出的算法可以聚焦于特定的节点或边类型，为所研究的预测问题中有兴趣的少数节点/边类型提供准确的表示。这些丰富而有针对性的表示可以增强对异构图的无监督和有监督学习。

    The development of Graph Representation Learning methods for heterogeneous graphs is fundamental in several real-world applications, since in several contexts graphs are characterized by different types of nodes and edges. We introduce a an algorithmic framework (Het-node2vec) that extends the original node2vec node-neighborhood sampling method to heterogeneous multigraphs. The resulting random walk samples capture both the structural characteristics of the graph and the semantics of the different types of nodes and edges. The proposed algorithms can focus their attention on specific node or edge types, allowing accurate representations also for underrepresented types of nodes/edges that are of interest for the prediction problem under investigation. These rich and well-focused representations can boost unsupervised and supervised learning on heterogeneous graphs.
    

