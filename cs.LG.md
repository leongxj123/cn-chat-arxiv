# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness](https://rss.arxiv.org/abs/2401.15963) | 本论文提出了一个新的基准测试 NoFunEval，用于评估代码语言模型在非功能性要求和简单分类实例方面的表现。研究发现，目前的代码语言模型在处理这些要求时存在根本性的盲点。 |
| [^2] | [Federated Multi-Agent Mapping for Planetary Exploration](https://arxiv.org/abs/2404.02289) | 联邦学习在多智能体机器人探测中的应用，利用隐式神经映射和地球数据集上的元初始化，实现了对不同领域如火星地形和冰川的强泛化能力。 |
| [^3] | [Finding Decision Tree Splits in Streaming and Massively Parallel Models](https://arxiv.org/abs/2403.19867) | 提出了在数据流学习中计算决策树最佳分割点的算法，能够在流式计算和大规模并行模型中高效运行 |
| [^4] | [Bidirectional Consistency Models](https://arxiv.org/abs/2403.18035) | 提出了双向一致性模型（BCM），学习一个神经网络，能够实现沿着概率流常微分方程前向和后向遍历，从而有效地统一了生成和编辑图像等任务。 |
| [^5] | [Data Acquisition via Experimental Design for Decentralized Data Markets](https://arxiv.org/abs/2403.13893) | 我们提出了一个受线性实验设计启发的联邦方法，用于在数据市场中选择最有价值的数据点，并实现更低的预测误差，无需标记的验证数据，更适用于去中心化市场设置。 |
| [^6] | [Optimal and Adaptive Non-Stationary Dueling Bandits Under a Generalized Borda Criterion](https://arxiv.org/abs/2403.12950) | 该研究建立了首个在对抗性多臂老虎机中优化且自适应的波达动态遗憾上界，揭示了在Condorcet和Borda之间严重非平稳性可学习性的基本差异 |
| [^7] | [Contextualized Messages Boost Graph Representations](https://arxiv.org/abs/2403.12529) | 这篇论文提出了关于图神经网络在各个层次（节点级、邻域级和图级）的表示能力的新视角。 |
| [^8] | [LSKNet: A Foundation Lightweight Backbone for Remote Sensing](https://arxiv.org/abs/2403.11735) | LSKNet是一种轻量级的大型选择核网络骨干，能动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远程上下文。 |
| [^9] | [SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection](https://arxiv.org/abs/2403.06534) | SARDet-100K是第一个COCO级别的大规模多类别SAR物体检测数据集，为研究提供了大规模且多样化的数据集，揭示了SAR物体检测中预训练模型显著差异的关键挑战。 |
| [^10] | [Jet Discrimination with Quantum Complete Graph Neural Network](https://arxiv.org/abs/2403.04990) | QCGNN通过量子并行性实现了对喷注判别的多项式加速，为喷注判别问题带来新的解决方案 |
| [^11] | [WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](https://arxiv.org/abs/2403.04808) | WaterMax提出了一种新的水印方案，能够在保持生成文本质量的同时实现高检测性能，打破了水印技术中质量和稳健性之间的传统平衡。 |
| [^12] | [MedMamba: Vision Mamba for Medical Image Classification](https://arxiv.org/abs/2403.03849) | 提出了Vision Mamba用于医学图像分类，结合了卷积层的局部特征提取能力和SSM捕捉长距离依赖性的能力。 |
| [^13] | [Understanding random forests and overfitting: a visualization and simulation study](https://arxiv.org/abs/2402.18612) | 这项研究通过可视化和模拟研究探讨了随机森林的行为，发现在训练集存在过拟合的情况下，模型在测试数据上表现出了竞争力。 |
| [^14] | [Multilinear Mixture of Experts: Scalable Expert Specialization through Factorization](https://arxiv.org/abs/2402.12550) | 多线性专家混合（MMoE）层通过因式分解针对视觉模型提供了一种可扩展的专家特化解决方案，避免了离散专家路由和过高推理时间成本。 |
| [^15] | [Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code](https://arxiv.org/abs/2402.09299) | 这项研究关注如何在训练代码的语言模型中检测代码包含，以解决使用这些模型进行代码审计时的版权侵权问题。 |
| [^16] | [Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional Systems](https://arxiv.org/abs/2402.08193) | 高斯模型集成置信传播算法（GEnBP）是一种用于高维系统中高效推断的方法，通过集成卡尔曼滤波器和高斯置信传播等技术相结合，能有效处理高维状态、参数和复杂的依赖结构。 |
| [^17] | [Policy Improvement using Language Feedback Models](https://arxiv.org/abs/2402.07876) | 本文介绍了一种使用语言反馈模型（LFMs）改进政策的方法，通过识别期望的行为并进行模仿学习，我们在任务完成率、泛化性能和人类可解释性方面取得了显著改进。 |
| [^18] | [Tempered Calculus for ML: Application to Hyperbolic Model Embedding](https://arxiv.org/abs/2402.04163) | 本论文介绍了基于温和微积分的理论和工具，来改进目前在机器学习中使用的数学扭曲方法，特别强调与几何和机器学习相关的特性。 |
| [^19] | [Estimating the Local Learning Coefficient at Scale](https://arxiv.org/abs/2402.03698) | 本文提出了一种方法，可以在深度线性网络中准确地测量高达1亿参数的局部学习系数(LLC)，并证明了估计得到的LLC具有重缩放不变性。 |
| [^20] | [A Momentum Accelerated Algorithm for ReLU-based Nonlinear Matrix Decomposition](https://arxiv.org/abs/2402.02442) | 提出了一种针对基于ReLU的非线性矩阵分解问题的动量加速算法，解决了现有模型中过拟合的问题，并通过实验验证了算法的有效性。 |
| [^21] | [Data-Driven Discovery of PDEs via the Adjoint Method](https://arxiv.org/abs/2401.17177) | 本文提出了一种通过伴随方法从数据中发现潜在偏微分方程的方法，展示了在给定光滑数据集的情况下，该方法可以恢复真实的PDE，但在存在噪声的情况下，准确性与PDE-FIND方法相当。 |
| [^22] | [CEDAS: A Compressed Decentralized Stochastic Gradient Method with Improved Convergence](https://arxiv.org/abs/2301.05872) | CEDAS提出了一种压缩分布式随机梯度方法，在无偏压缩运算符下具有与集中式随机梯度下降相当的收敛速度，实现了最短的瞬态时间，对光滑强凸和非凸目标函数都适用。 |
| [^23] | [Text2Model: Text-based Model Induction for Zero-shot Image Classification](https://arxiv.org/abs/2210.15182) | 该论文提出了一种使用文本描述构建与任务无关的分类器的方法，通过生成针对查询分类任务定制的模型来解决零样本图像分类问题。 |
| [^24] | [Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations.](http://arxiv.org/abs/2401.14142) | 基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。 |
| [^25] | [Fast Semi-supervised Unmixing using Non-convex Optimization.](http://arxiv.org/abs/2401.12609) | 本文介绍了一种用于解混合的快速半监督非凸优化模型，该模型考虑了库不匹配和丰度约束，并提出了两种基于先验的半监督解混合方法。实验证明，实施凸性约束优于稀疏先验对于端元库的表现。 |
| [^26] | [Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities.](http://arxiv.org/abs/2401.11143) | 该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。 |
| [^27] | [Towards Learning from Graphs with Heterophily: Progress and Future.](http://arxiv.org/abs/2401.09769) | 本调查综合概述了关于从带有异质性的图中学习的现有研究，并根据学习策略、模型架构和实际应用等方面对方法进行了分类。同时讨论了现有研究的主要挑战，并提出了未来研究的潜在方向。 |
| [^28] | [An exploratory study on automatic identification of assumptions in the development of deep learning frameworks.](http://arxiv.org/abs/2401.03653) | 本研究以构建一个新的最大假设数据集为基础，针对深度学习框架开发中手动识别假设的问题进行了探索性研究。在该研究中，我们发现手动识别假设的成本高，因此探讨了使用传统机器学习模型和流行的深度学习模型来识别假设的性能。 |
| [^29] | [The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers.](http://arxiv.org/abs/2401.01537) | 这项研究介绍了一种使用动态触发器进行强健后门攻击的方法，通过巧妙设计的调整，使损坏的样本与干净的样本无法区分，实验证明这种方法可以成功地欺骗语音识别系统。 |
| [^30] | [Knowledge Enhanced Conditional Imputation for Healthcare Time-series.](http://arxiv.org/abs/2312.16713) | 本研究提出了一种知识增强的条件插补方法，针对医疗时间序列数据中的缺失数据问题。通过整合先进的知识嵌入和非均匀掩蔽策略，该方法能够灵活适应不同模式的电子健康记录中的缺失数据分布不平衡问题。 |
| [^31] | [Towards Unifying Diffusion Models for Probabilistic Spatio-Temporal Graph Learning.](http://arxiv.org/abs/2310.17360) | 本文提出了一种统一的时空图学习方法，即统一时空扩散模型（USTD），用于处理物联网时代的各种学习任务。USTD综合考虑了时空数据中的不确定性，并利用共享的时空模式进行预测。此方法具有通用性和灵活性。 |
| [^32] | [Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space.](http://arxiv.org/abs/2310.11256) | 本文介绍了两种在高斯混合模型空间中的Gromov-Wasserstein类型距离，分别用于评估分布之间的距离和推导最优的点分配方案。 |
| [^33] | [Pure Exploration in Asynchronous Federated Bandits.](http://arxiv.org/abs/2310.11015) | 该论文研究了异步联邦赌博机中的纯探索问题，并提出了首个在完全异步环境下实现近乎最优样本复杂性和高效通信成本的联邦异步多臂赌博机和线性赌博机纯探索算法。 |
| [^34] | [IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training.](http://arxiv.org/abs/2310.07355) | IMITATE是一种临床先验指导的分层视觉语言预训练模型。它利用医学报告的层级结构，从胸部X射线图像中提取多级视觉特征，并与分层医学报告中的描述性和结论性文本进行对齐。 |
| [^35] | [Suppressing Overestimation in Q-Learning through Adversarial Behaviors.](http://arxiv.org/abs/2310.06286) | 本文提出了一种新的Q学习算法，通过引入虚拟对抗性玩家，有效调节了标准Q学习中的过高估计偏差，提出的算法简单而有效，能够轻松应用于强化学习算法并提高性能。 |
| [^36] | [Improved prediction of ligand-protein binding affinities by meta-modeling.](http://arxiv.org/abs/2310.03946) | 通过整合基于结构的对接和基于序列的深度学习模型，开发了一个元模型框架，显著改善了配体-蛋白质结合亲和力预测的性能。 |
| [^37] | [Active Inverse Learning in Stackelberg Trajectory Games.](http://arxiv.org/abs/2308.08017) | 这项研究提出了一种在Stackelberg博弈中的主动逆向学习方法，通过活跃地最大化跟随者在不同假设下的轨迹差异来加速领导者的推断过程。 |
| [^38] | [Interpretable Stereotype Identification through Reasoning.](http://arxiv.org/abs/2308.00071) | 本研究通过使用推理方法，在零射击刻板印象识别中取得了重要的进展，并发现推理的性能增益远远超过模型规模扩展的增益。推理不仅提高了准确性，还提高了决策的可解释性。 |
| [^39] | [It begins with a boundary: A geometric view on probabilistically robust learning.](http://arxiv.org/abs/2305.18779) | 本文探讨了深度神经网络对于对抗生成的示例缺乏鲁棒性的问题，并提出了一种从几何角度出发的新颖视角，介绍一族概率非局部周长函数来优化概率鲁棒学习（PRL）的原始表述，以提高其鲁棒性。 |
| [^40] | [Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations.](http://arxiv.org/abs/2305.16326) | 本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。 |
| [^41] | [Achieving Minimax Optimal Sample Complexity of Offline Reinforcement Learning: A DRO-Based Approach.](http://arxiv.org/abs/2305.13289) | 本文提出了一种分布鲁棒优化 (DRO)的方法，用于解决离线强化学习中的数据有限性和分布转移问题。通过直接建模转移核的不确定性，并寻找在不确定性集合中最优化最坏情况下的性能的策略，实现了极小极大最优性。 |
| [^42] | [A benchmark for computational analysis of animal behavior, using animal-borne tags.](http://arxiv.org/abs/2305.10740) | 该论文介绍了一个名为BEBE的动物行为计算分析基准，其中包括了1654小时的动物生态生理学数据，这是迄今为止最大、最具分类多样性的公开可用的数据集合。在这个基准上，作者使用了十种机器学习方法并确定了未来工作中需要解决的关键问题。 |
| [^43] | [Logarithmic-Regret Quantum Learning Algorithms for Zero-Sum Games.](http://arxiv.org/abs/2304.14197) | 该论文提出了一个在线零和游戏的量子算法，可以在量子时间计算出$\varepsilon$-近似纳什均衡，是目前第一个实现基于量子计算的快速量子线性编程求解器。 |
| [^44] | [On the Effects of Data Heterogeneity on the Convergence Rates of Distributed Linear System Solvers.](http://arxiv.org/abs/2304.10640) | 本文比较了投影方法和优化方法求解分布式线性系统的收敛速度，提出了角异构性的几何概念，并对最有效的算法(APC和D-HBM)的收敛速度进行了约束和比较。 |
| [^45] | [Contrastive Learning and the Emergence of Attributes Associations.](http://arxiv.org/abs/2302.10763) | 对比学习方案通过对物体输入表示进行身份保持的变换，不仅有助于物体的分类，还可以提供关于属性的有无决策的有价值信息。 |
| [^46] | [Combinatorial Causal Bandits without Graph Skeleton.](http://arxiv.org/abs/2301.13392) | 本文研究了在二值一般因果模型和BGLMs上不考虑图骨架的组合因果赌博机问题，提出了可在BGLMs上实现的无需图骨架的遗憾最小化算法，达到了与依赖于图结构的最先进算法相同的渐进遗憾率$O(\sqrt{T}\ln T)$。 |
| [^47] | [Discriminative Entropy Clustering and its Relation to K-means and SVM.](http://arxiv.org/abs/2301.11405) | 该论文介绍了判别熵聚类的相关理论及其与K-means和SVM的区别和相似之处。同时提出了一种新的损失函数，用于改进深度聚类的性能。 |
| [^48] | [Policy Optimization over General State and Action Spaces.](http://arxiv.org/abs/2211.16715) | 本文提出了一种新方法并引入了函数近似来解决通用状态和动作空间上的强化学习问题，同时介绍了一种新的策略双平均法。 |
| [^49] | [Controlling Moments with Kernel Stein Discrepancies.](http://arxiv.org/abs/2211.05408) | 本研究分析了核斯坦离差（KSD）控制性质，发现标准KSD无法控制矩的收敛，提出了可控制矩和弱收敛的下游扩散KSD，并且发展了可以准确描述$q$-Wasserstein收敛的KSD。 |
| [^50] | [Approximate Cross-validated Mean Estimates for Bayesian Hierarchical Regression Models.](http://arxiv.org/abs/2011.14238) | 我们提出了一种用于贝叶斯层次回归模型的近似交叉验证均值估计的新方法，通过在方差-协方差参数上进行条件，将交叉验证问题转化为简单的优化问题，从而提高了大型BHRMs的可行性。 |

# 详细

[^1]: NoFunEval: 有趣的是，代码语言模型在超出功能正确性的要求上遇到困难

    NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness

    [https://rss.arxiv.org/abs/2401.15963](https://rss.arxiv.org/abs/2401.15963)

    本论文提出了一个新的基准测试 NoFunEval，用于评估代码语言模型在非功能性要求和简单分类实例方面的表现。研究发现，目前的代码语言模型在处理这些要求时存在根本性的盲点。

    

    现有的代码语言模型（code LMs）的评估基准几乎完全集中在LMs是否能够生成功能正确的代码上。在实际的软件工程中，开发人员会考虑超出功能正确性的要求。他们对于“如何”实现功能有着对整体系统设计目标（如效率、安全性和可维护性）的要求。如果LMs能够展示对要求和代码语义的强大理解能力，他们也会更加信任这些LMs。我们提出了一个新的基准测试NoFunEval来评估代码LMs在非功能性要求和简单分类实例方面的表现。我们提出了一个提示方法Coding Concepts (CoCo)，可以用于开发人员向LMs传达领域知识。我们对22个代码LMs进行了广泛评估，发现它们在我们的基准测试中普遍表现不佳，暗示着它们在处理这些问题时存在根本性的盲点。

    Existing evaluation benchmarks of language models of code (code LMs) focus almost exclusively on whether the LMs can generate functionally-correct code. In real-world software engineering, developers think beyond functional correctness. They have requirements on "how" a functionality should be implemented to meet overall system design objectives like efficiency, security, and maintainability. They would also trust the code LMs more if the LMs demonstrate robust understanding of requirements and code semantics.   We propose a new benchmark NoFunEval to evaluate code LMs on non-functional requirements and simple classification instances for both functional and non-functional requirements. We propose a prompting method, Coding Concepts (CoCo), as a way for a developer to communicate the domain knowledge to the LMs. We conduct an extensive evaluation of twenty-two code LMs. Our finding is that they generally falter when tested on our benchmark, hinting at fundamental blindspots in their tr
    
[^2]: 行星探测的联邦多智能体建图

    Federated Multi-Agent Mapping for Planetary Exploration

    [https://arxiv.org/abs/2404.02289](https://arxiv.org/abs/2404.02289)

    联邦学习在多智能体机器人探测中的应用，利用隐式神经映射和地球数据集上的元初始化，实现了对不同领域如火星地形和冰川的强泛化能力。

    

    在多智能体机器人探测中，管理和有效利用动态环境产生的大量异构数据构成了一个重要挑战。联邦学习（FL）是一种有前途的分布式映射方法，它解决了协作学习中去中心化数据的挑战。FL使多个智能体之间可以进行联合模型训练，而无需集中化或共享原始数据，克服了带宽和存储限制。我们的方法利用隐式神经映射，将地图表示为由神经网络学习的连续函数，以便实现紧凑和适应性的表示。我们进一步通过在地球数据集上进行元初始化来增强这一方法，预训练网络以快速学习新的地图结构。这种组合在诸如火星地形和冰川等不同领域展现了较强的泛化能力。我们对这一方法进行了严格评估，展示了其有效性。

    arXiv:2404.02289v1 Announce Type: cross  Abstract: In multi-agent robotic exploration, managing and effectively utilizing the vast, heterogeneous data generated from dynamic environments poses a significant challenge. Federated learning (FL) is a promising approach for distributed mapping, addressing the challenges of decentralized data in collaborative learning. FL enables joint model training across multiple agents without requiring the centralization or sharing of raw data, overcoming bandwidth and storage constraints. Our approach leverages implicit neural mapping, representing maps as continuous functions learned by neural networks, for compact and adaptable representations. We further enhance this approach with meta-initialization on Earth datasets, pre-training the network to quickly learn new map structures. This combination demonstrates strong generalization to diverse domains like Martian terrain and glaciers. We rigorously evaluate this approach, demonstrating its effectiven
    
[^3]: 在流式和大规模并行模型中找到决策树分割点

    Finding Decision Tree Splits in Streaming and Massively Parallel Models

    [https://arxiv.org/abs/2403.19867](https://arxiv.org/abs/2403.19867)

    提出了在数据流学习中计算决策树最佳分割点的算法，能够在流式计算和大规模并行模型中高效运行

    

    在这项工作中，我们提出了一种数据流算法，用于计算决策树学习中的最优分割点。具体而言，给定观测数据流$x_i$及其标签$y_i$，目标是找到将数据分为两组的最佳分割点$j$，使得均方误差（回归问题）或误分类率（分类问题）最小化。我们提供了多种快速的数据流算法，这些算法在这些问题中使用亚线性空间和少量次数的遍历。这些算法还可以扩展到大规模并行计算模型中。尽管不能直接比较，但我们的工作与Domingos和Hulten的开创性工作（KDD 2000）相互补充。

    arXiv:2403.19867v1 Announce Type: cross  Abstract: In this work, we provide data stream algorithms that compute optimal splits in decision tree learning. In particular, given a data stream of observations $x_i$ and their labels $y_i$, the goal is to find the optimal split point $j$ that divides the data into two sets such that the mean squared error (for regression) or misclassification rate (for classification) is minimized. We provide various fast streaming algorithms that use sublinear space and a small number of passes for these problems. These algorithms can also be extended to the massively parallel computation model. Our work, while not directly comparable, complements the seminal work of Domingos and Hulten (KDD 2000).
    
[^4]: 双向一致性模型

    Bidirectional Consistency Models

    [https://arxiv.org/abs/2403.18035](https://arxiv.org/abs/2403.18035)

    提出了双向一致性模型（BCM），学习一个神经网络，能够实现沿着概率流常微分方程前向和后向遍历，从而有效地统一了生成和编辑图像等任务。

    

    扩散模型（DMs）通过迭代去噪一个随机向量能够生成非常高质量的样本，这个过程对应于沿着概率流常微分方程（PF ODE）移动。有趣的是，DMs还可以通过沿着PF ODE向后移动将输入图像转换为噪声，这是下游任务（如插值和图像编辑）的关键操作。然而，这一过程的迭代性质限制了其速度，阻碍了其更广泛的应用。最近，一致性模型（CMs）已经出现，以解决这一挑战，通过近似PF ODE的积分，从而避免了需要迭代。然而，缺乏显式ODE求解器使得反演过程复杂化。为了解决这个问题，我们引入了双向一致性模型（BCM），学习单个神经网络，能够同时实现沿着PF ODE的前向和后向遍历，有效地统一生成和

    arXiv:2403.18035v1 Announce Type: new  Abstract: Diffusion models (DMs) are capable of generating remarkably high-quality samples by iteratively denoising a random vector, a process that corresponds to moving along the probability flow ordinary differential equation (PF ODE). Interestingly, DMs can also invert an input image to noise by moving backward along the PF ODE, a key operation for downstream tasks such as interpolation and image editing. However, the iterative nature of this process restricts its speed, hindering its broader application. Recently, Consistency Models (CMs) have emerged to address this challenge by approximating the integral of the PF ODE, thereby bypassing the need to iterate. Yet, the absence of an explicit ODE solver complicates the inversion process. To resolve this, we introduce the Bidirectional Consistency Model (BCM), which learns a single neural network that enables both forward and backward traversal along the PF ODE, efficiently unifying generation an
    
[^5]: 通过实验设计实现去中心化数据市场的数据采集

    Data Acquisition via Experimental Design for Decentralized Data Markets

    [https://arxiv.org/abs/2403.13893](https://arxiv.org/abs/2403.13893)

    我们提出了一个受线性实验设计启发的联邦方法，用于在数据市场中选择最有价值的数据点，并实现更低的预测误差，无需标记的验证数据，更适用于去中心化市场设置。

    

    获取高质量的训练数据对于当前的机器学习模型至关重要。数据市场通过激励潜在的数据卖家加入市场的方式来增加数据供应，特别是在数据稀缺的领域，如医疗保健领域。我们提出了一个受线性实验设计启发的去中心化数据选择问题的联邦方法，该方法不需要标记的验证数据即可实现更低的预测误差，并且可以在快速和联邦的过程中进行优化。我们的工作的关键见解是，一种直接估计获取数据对于测试集预测的好处的方法特别适用于去中心化市场设置。

    arXiv:2403.13893v1 Announce Type: new  Abstract: Acquiring high-quality training data is essential for current machine learning models. Data markets provide a way to increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data sellers to join the market. A major challenge for a data buyer in such a market is selecting the most valuable data points from a data seller. Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data selection problem that is inspired by linear experimental design. Our proposed data selection method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure. The key insight of our work is that a method that directly estimates the benefit of acquiring data for test set prediction is particularly compatible with a decentralized market setting.
    
[^6]: 优化的自适应非平稳对抗性多臂老虎机在广义波达准则下

    Optimal and Adaptive Non-Stationary Dueling Bandits Under a Generalized Borda Criterion

    [https://arxiv.org/abs/2403.12950](https://arxiv.org/abs/2403.12950)

    该研究建立了首个在对抗性多臂老虎机中优化且自适应的波达动态遗憾上界，揭示了在Condorcet和Borda之间严重非平稳性可学习性的基本差异

    

    在对抗性多臂老虎机中，学习者接收臂之间的偏好反馈，并将某个臂的遗憾定义为其相对于优胜臂的次优性。更具挑战性和实践动机的非平稳对抗性多臂老虎机变体，在这种变体中，偏好随时间变化，已经成为近期多项工作的焦点。目标是设计出算法，而无需提前了解变化量。已知结果的大部分研究了孔多塞优胜者设置，其中优先于其他任何臂的臂在任何时候都存在。然而，这样的优胜者可能并不存在，为了对比，此问题的波达版本（始终有明确定义）却受到了很少关注。在这项工作中，我们建立了第一个最优和自适应的波达动态遗憾上界，突显了在孔多塞和波达之间的严重非平稳性可学习性的基本差异。

    arXiv:2403.12950v1 Announce Type: new  Abstract: In dueling bandits, the learner receives preference feedback between arms, and the regret of an arm is defined in terms of its suboptimality to a winner arm. The more challenging and practically motivated non-stationary variant of dueling bandits, where preferences change over time, has been the focus of several recent works (Saha and Gupta, 2022; Buening and Saha, 2023; Suk and Agarwal, 2023). The goal is to design algorithms without foreknowledge of the amount of change.   The bulk of known results here studies the Condorcet winner setting, where an arm preferred over any other exists at all times. Yet, such a winner may not exist and, to contrast, the Borda version of this problem (which is always well-defined) has received little attention. In this work, we establish the first optimal and adaptive Borda dynamic regret upper bound, which highlights fundamental differences in the learnability of severe non-stationarity between Condorce
    
[^7]: 上下文化信息提升了图表示

    Contextualized Messages Boost Graph Representations

    [https://arxiv.org/abs/2403.12529](https://arxiv.org/abs/2403.12529)

    这篇论文提出了关于图神经网络在各个层次（节点级、邻域级和图级）的表示能力的新视角。

    

    近年来，图神经网络（GNN）因其处理以图表示的任意结构化数据的能力而引起了广泛关注。GNN通常遵循消息传递方案来本地更新节点特征表示。然后使用图读出函数创建整个图的表示。一些研究通过修改消息传递框架的聚合和组合策略提出了不同的GNN，常常受启发于启发式算法。然而，一些研究已经开始从基于图同构问题的理论角度探索GNN，该问题固有地假设可数的节点特征表示。然而，目前只有少数理论工作探索了具有不可数节点特征表示的GNN。本文提出了一个关于GNN在节点级、邻域级和图级的表示能力的新视角。

    arXiv:2403.12529v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have gained significant interest in recent years due to their ability to handle arbitrarily structured data represented as graphs. GNNs generally follow the message-passing scheme to locally update node feature representations. A graph readout function is then employed to create a representation for the entire graph. Several studies proposed different GNNs by modifying the aggregation and combination strategies of the message-passing framework, often inspired by heuristics. Nevertheless, several studies have begun exploring GNNs from a theoretical perspective based on the graph isomorphism problem which inherently assumes countable node feature representations. Yet, there are only a few theoretical works exploring GNNs with uncountable node feature representations. This paper presents a new perspective on the representational capabilities of GNNs across all levels - node-level, neighborhood-level, and graph-l
    
[^8]: LSKNet：一种用于遥感的轻量级基础架构

    LSKNet: A Foundation Lightweight Backbone for Remote Sensing

    [https://arxiv.org/abs/2403.11735](https://arxiv.org/abs/2403.11735)

    LSKNet是一种轻量级的大型选择核网络骨干，能动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远程上下文。

    

    遥感图像由于其固有的复杂性对下游任务提出了独特的挑战。尽管已经有大量研究致力于遥感分类、目标检测和语义分割，但其中大多数研究都忽视了嵌入在遥感场景中的宝贵先验知识。这些先验知识可能会很有用，因为在没有参考足够长程上下文的情况下，遥感对象可能会被错误识别，而这可以因不同对象而异。本文考虑了这些先验知识，并提出了一种轻量级的大型选择核网络（LSKNet）骨干网络。LSKNet可以动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远距离上下文。据我们所知，先前尚未在遥感图像中探索过大型和选择性核机制。我们的轻量级方法没有太多复杂性。

    arXiv:2403.11735v1 Announce Type: cross  Abstract: Remote sensing images pose distinct challenges for downstream tasks due to their inherent complexity. While a considerable amount of research has been dedicated to remote sensing classification, object detection and semantic segmentation, most of these studies have overlooked the valuable prior knowledge embedded within remote sensing scenarios. Such prior knowledge can be useful because remote sensing objects may be mistakenly recognized without referencing a sufficiently long-range context, which can vary for different objects. This paper considers these priors and proposes a lightweight Large Selective Kernel Network (LSKNet) backbone. LSKNet can dynamically adjust its large spatial receptive field to better model the ranging context of various objects in remote sensing scenarios. To our knowledge, large and selective kernel mechanisms have not been previously explored in remote sensing images. Without bells and whistles, our lightw
    
[^9]: SARDet-100K: 面向大规模合成孔径雷达 SAR 物体检测的开源基准和工具包

    SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection

    [https://arxiv.org/abs/2403.06534](https://arxiv.org/abs/2403.06534)

    SARDet-100K是第一个COCO级别的大规模多类别SAR物体检测数据集，为研究提供了大规模且多样化的数据集，揭示了SAR物体检测中预训练模型显著差异的关键挑战。

    

    面向合成孔径雷达（SAR）物体检测近来备受关注，因其不可替代的全天候成像能力。然而，这一研究领域面临着有限的公共数据集（主要包含 <2K 张图像，且仅包含单类别物体）和源代码不可访问的挑战。为解决这些问题，我们建立了一个新的基准数据集和一个针对大规模 SAR 物体检测的开源方法。我们的数据集 SARDet-100K 结果是对 10 个现有 SAR 检测数据集进行深入调研、收集和标准化的产物，为研究提供了一个大规模且多样化的数据集。据我们所知，SARDet-100K 是有史以来第一个达到 COCO 水平的大规模多类别 SAR 物体检测数据集。凭借这一高质量数据集，我们进行了全面实验，并揭示了 SAR 物体检测中一个关键挑战：预训练模型的显著差异。

    arXiv:2403.06534v1 Announce Type: cross  Abstract: Synthetic Aperture Radar (SAR) object detection has gained significant attention recently due to its irreplaceable all-weather imaging capabilities. However, this research field suffers from both limited public datasets (mostly comprising <2K images with only mono-category objects) and inaccessible source code. To tackle these challenges, we establish a new benchmark dataset and an open-source method for large-scale SAR object detection. Our dataset, SARDet-100K, is a result of intense surveying, collecting, and standardizing 10 existing SAR detection datasets, providing a large-scale and diverse dataset for research purposes. To the best of our knowledge, SARDet-100K is the first COCO-level large-scale multi-class SAR object detection dataset ever created. With this high-quality dataset, we conducted comprehensive experiments and uncovered a crucial challenge in SAR object detection: the substantial disparities between the pretraining
    
[^10]: 使用量子完全图神经网络进行喷注判别

    Jet Discrimination with Quantum Complete Graph Neural Network

    [https://arxiv.org/abs/2403.04990](https://arxiv.org/abs/2403.04990)

    QCGNN通过量子并行性实现了对喷注判别的多项式加速，为喷注判别问题带来新的解决方案

    

    机器学习，特别是深度神经网络，在高能物理中被广泛应用，并在各种应用中展现出显著的效果。此外，机器学习的概念已扩展到量子计算机，形成了一个被称为量子机器学习的新研究领域。在本文中，我们提出了一个新颖的变分量子电路模型，即量子完全图神经网络（QCGNN），旨在学习完全图。我们认为QCGNN由于量子并行性的特性，在速度上对其经典对应物具有多项式加速。本文研究了QCGNN在具有挑战性的喷注判别中的应用，其中喷注用完全图表示。随后，我们与经典图神经网络进行了比较分析，以建立基准。

    arXiv:2403.04990v1 Announce Type: cross  Abstract: Machine learning, particularly deep neural networks, has been widely utilized in high energy physics and has shown remarkable results in various applications. Moreover, the concept of machine learning has been extended to quantum computers, giving rise to a new research area known as quantum machine learning. In this paper, we propose a novel variational quantum circuit model, Quantum Complete Graph Neural Network (QCGNN), designed for learning complete graphs. We argue that QCGNN has a polynomial speedup against its classical counterpart, due to the property of quantum parallelism. In this paper, we study the application of QCGNN through the challenging jet discrimination, where the jets are represented with complete graphs. Subsequently, we conduct a comparative analysis with classical graph neural networks to establish a benchmark.
    
[^11]: WaterMax: 打破LLM水印可检测性-稳健性-质量的平衡

    WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off

    [https://arxiv.org/abs/2403.04808](https://arxiv.org/abs/2403.04808)

    WaterMax提出了一种新的水印方案，能够在保持生成文本质量的同时实现高检测性能，打破了水印技术中质量和稳健性之间的传统平衡。

    

    水印是阻止大型语言模型被恶意使用的技术手段。本文提出了一种称为WaterMax的新颖水印方案，具有高检测性能，同时保持原始LLM生成文本的质量。其新设计不会对LLM进行任何修改（不调整权重、对数、温度或采样技术）。WaterMax平衡了稳健性和复杂性，与文献中的水印技术相反，从根本上引发了质量和稳健性之间的平衡。其性能在理论上得到证明并经过实验证实。在最全面的基准测试套件下，它胜过所有的最先进技术。

    arXiv:2403.04808v1 Announce Type: cross  Abstract: Watermarking is a technical means to dissuade malfeasant usage of Large Language Models. This paper proposes a novel watermarking scheme, so-called WaterMax, that enjoys high detectability while sustaining the quality of the generated text of the original LLM. Its new design leaves the LLM untouched (no modification of the weights, logits, temperature, or sampling technique). WaterMax balances robustness and complexity contrary to the watermarking techniques of the literature inherently provoking a trade-off between quality and robustness. Its performance is both theoretically proven and experimentally validated. It outperforms all the SotA techniques under the most complete benchmark suite.
    
[^12]: MedMamba: 用于医学图像分类的Vision Mamba

    MedMamba: Vision Mamba for Medical Image Classification

    [https://arxiv.org/abs/2403.03849](https://arxiv.org/abs/2403.03849)

    提出了Vision Mamba用于医学图像分类，结合了卷积层的局部特征提取能力和SSM捕捉长距离依赖性的能力。

    

    医学图像分类是计算机视觉领域中非常基础和关键的任务。近年来，基于CNN和Transformer的模型被广泛应用于分类各种医学图像。不幸的是，CNN在长距离建模能力方面存在局限，无法有效提取医学图像中的细粒度特征，而Transformers受到二次计算复杂度的阻碍。最近的研究表明，由Mamba表示的状态空间模型（SSM）可以高效地建模长距离交互作用同时保持线性计算复杂度。受此启发，我们提出了用于医学图像分类的Vision Mamba（MedMamba）。更具体地，我们引入了一个新颖的Conv-SSM模块，将卷积层的局部特征提取能力与SSM捕捉长距离依赖性的能力结合在一起。为了展示MedMamba的潜力，我们进行了

    arXiv:2403.03849v1 Announce Type: cross  Abstract: Medical image classification is a very fundamental and crucial task in the field of computer vision. These years, CNN-based and Transformer-based models are widely used in classifying various medical images. Unfortunately, The limitation of CNNs in long-range modeling capabilities prevent them from effectively extracting fine-grained features in medical images , while Transformers are hampered by their quadratic computational complexity. Recent research has shown that the state space model (SSM) represented by Mamba can efficiently model long-range interactions while maintaining linear computational complexity. Inspired by this, we propose Vision Mamba for medical image classification (MedMamba). More specifically, we introduce a novel Conv-SSM module, which combines the local feature extraction ability of convolutional layers with the ability of SSM to capture long-range dependency. To demonstrate the potential of MedMamba, we conduct
    
[^13]: 理解随机森林和过拟合：一项可视化和模拟研究

    Understanding random forests and overfitting: a visualization and simulation study

    [https://arxiv.org/abs/2402.18612](https://arxiv.org/abs/2402.18612)

    这项研究通过可视化和模拟研究探讨了随机森林的行为，发现在训练集存在过拟合的情况下，模型在测试数据上表现出了竞争力。

    

    随机森林在临床风险预测建模中变得流行。在一项关于预测卵巢恶性的案例研究中，我们观察到训练集上的c-统计值接近1。尽管这表明存在过拟合，但在测试数据上表现竞争力。我们旨在通过（1）在三个真实案例研究中可视化数据空间和（2）进行模拟研究来理解随机森林的行为。在案例研究中，使用热力图在二维子空间中可视化风险估计。模拟研究包括48个逻辑数据生成机制（DGM），变化预测变量分布、预测变量数量、预测变量之间的相关性、真实c-统计值和真实预测变量的强度。对于每个DGM，模拟生成大小为200或4000的1000个训练数据集，并使用ranger包训练最小节点大小为2或20的随机森林模型，总共得到了192个场景。可视化结果表明，模型…

    arXiv:2402.18612v1 Announce Type: cross  Abstract: Random forests have become popular for clinical risk prediction modelling. In a case study on predicting ovarian malignancy, we observed training c-statistics close to 1. Although this suggests overfitting, performance was competitive on test data. We aimed to understand the behaviour of random forests by (1) visualizing data space in three real world case studies and (2) a simulation study. For the case studies, risk estimates were visualised using heatmaps in a 2-dimensional subspace. The simulation study included 48 logistic data generating mechanisms (DGM), varying the predictor distribution, the number of predictors, the correlation between predictors, the true c-statistic and the strength of true predictors. For each DGM, 1000 training datasets of size 200 or 4000 were simulated and RF models trained with minimum node size 2 or 20 using ranger package, resulting in 192 scenarios in total. The visualizations suggested that the mod
    
[^14]: 多线性专家混合：通过因式分解实现可扩展的专家特化

    Multilinear Mixture of Experts: Scalable Expert Specialization through Factorization

    [https://arxiv.org/abs/2402.12550](https://arxiv.org/abs/2402.12550)

    多线性专家混合（MMoE）层通过因式分解针对视觉模型提供了一种可扩展的专家特化解决方案，避免了离散专家路由和过高推理时间成本。

    

    专家混合（MoE）范式提供了一种强大的方法，将难以理解的密集层分解为更小、模块化的计算，通常更易于人类解释、调试和编辑。然而，一个主要问题在于扩展专家数量的计算成本，以实现足够精细的专业化。本文提出了多线性专家混合（MMoE）层来解决这个问题，重点放在视觉模型上。MMoE层完全以因式化形式对庞大的权重张量进行隐式计算。因此，MMoEs既避免了在流行的“稀疏”MoE模型中离散专家路由所造成的问题，又不会引起“软”MoE替代方案中过高的推理时间成本。我们通过可视化和反事实干预，提供了定性和定量证据，证明了扩展MMoE层的效果。

    arXiv:2402.12550v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) paradigm provides a powerful way to decompose inscrutable dense layers into smaller, modular computations often more amenable to human interpretation, debugging, and editability. A major problem however lies in the computational cost of scaling the number of experts to achieve sufficiently fine-grained specialization. In this paper, we propose the Multilinear Mixutre of Experts (MMoE) layer to address this, focusing on vision models. MMoE layers perform an implicit computation on prohibitively large weight tensors entirely in factorized form. Consequently, MMoEs both (1) avoid the issues incurred through the discrete expert routing in the popular 'sparse' MoE models, yet (2) do not incur the restrictively high inference-time costs of 'soft' MoE alternatives. We present both qualitative and quantitative evidence (through visualization and counterfactual interventions respectively) that scaling MMoE layers wh
    
[^15]: 未经本人同意的训练：在训练代码的语言模型中检测代码包含

    Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code

    [https://arxiv.org/abs/2402.09299](https://arxiv.org/abs/2402.09299)

    这项研究关注如何在训练代码的语言模型中检测代码包含，以解决使用这些模型进行代码审计时的版权侵权问题。

    

    代码审计通过验证开发的代码是否符合标准、法规和版权保护，确保其不包含来自受保护来源的代码。在软件开发过程中，大型语言模型(LLMs)作为编码助手的出现给代码审计带来了新的挑战。训练这些模型的数据集主要来自公开可用的来源。这引发了知识产权侵权问题，因为开发者的代码已包含在数据集中。因此，使用LLMs开发的代码审计具有挑战性，因为我们无法准确确定开发过程中使用的LLM是否已经在特定的受版权保护的代码上进行了训练，因为我们无法获得这些模型的训练数据集。鉴于训练数据集的保密性，传统的代码克隆检测等方法无法确保版权侵权。

    arXiv:2402.09299v1 Announce Type: cross Abstract: Code auditing ensures that the developed code adheres to standards, regulations, and copyright protection by verifying that it does not contain code from protected sources. The recent advent of Large Language Models (LLMs) as coding assistants in the software development process poses new challenges for code auditing. The dataset for training these models is mainly collected from publicly available sources. This raises the issue of intellectual property infringement as developers' codes are already included in the dataset. Therefore, auditing code developed using LLMs is challenging, as it is difficult to reliably assert if an LLM used during development has been trained on specific copyrighted codes, given that we do not have access to the training datasets of these models. Given the non-disclosure of the training datasets, traditional approaches such as code clone detection are insufficient for asserting copyright infringement. To add
    
[^16]: 高斯模型集成置信传播用于高维系统中的高效推断

    Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional Systems

    [https://arxiv.org/abs/2402.08193](https://arxiv.org/abs/2402.08193)

    高斯模型集成置信传播算法（GEnBP）是一种用于高维系统中高效推断的方法，通过集成卡尔曼滤波器和高斯置信传播等技术相结合，能有效处理高维状态、参数和复杂的依赖结构。

    

    高维模型中的高效推断仍然是机器学习中的一个核心挑战。本文介绍了一种名为高斯模型集成置信传播（GEnBP）算法的方法，该方法是集成卡尔曼滤波器和高斯置信传播（GaBP）方法的结合。GEnBP通过在图模型结构中传递低秩本地信息来更新集成模型。这种组合继承了每种方法的有利特性。集成技术使得GEnBP能够处理高维状态、参数和复杂的、嘈杂的黑箱生成过程。在图模型结构中使用本地信息确保了该方法适用于分布式计算，并能高效地处理复杂的依赖结构。当集成大小远小于推断维度时，GEnBP特别有优势。这种情况在空时建模、图像处理和物理模型反演等领域经常出现。GEnBP可以应用于一般性问题。

    Efficient inference in high-dimensional models remains a central challenge in machine learning. This paper introduces the Gaussian Ensemble Belief Propagation (GEnBP) algorithm, a fusion of the Ensemble Kalman filter and Gaussian belief propagation (GaBP) methods. GEnBP updates ensembles by passing low-rank local messages in a graphical model structure. This combination inherits favourable qualities from each method. Ensemble techniques allow GEnBP to handle high-dimensional states, parameters and intricate, noisy, black-box generation processes. The use of local messages in a graphical model structure ensures that the approach is suited to distributed computing and can efficiently handle complex dependence structures. GEnBP is particularly advantageous when the ensemble size is considerably smaller than the inference dimension. This scenario often arises in fields such as spatiotemporal modelling, image processing and physical model inversion. GEnBP can be applied to general problem s
    
[^17]: 使用语言反馈模型来改进政策

    Policy Improvement using Language Feedback Models

    [https://arxiv.org/abs/2402.07876](https://arxiv.org/abs/2402.07876)

    本文介绍了一种使用语言反馈模型（LFMs）改进政策的方法，通过识别期望的行为并进行模仿学习，我们在任务完成率、泛化性能和人类可解释性方面取得了显著改进。

    

    我们引入了语言反馈模型（LFMs），用于在指令遵循中识别期望的行为-有助于实现指令中指定任务的行动-以进行模仿学习。为了训练LFMs，我们从大型语言模型（LLMs）获取对视觉轨迹进行语言描述的反馈。首先，通过使用LFMs识别期望模仿的行为，我们在三种不同的语言基础环境（Touchdown，ScienceWorld和ALFWorld）上，在任务完成率上改善了强行为克隆的基线方法。其次，与LLMs直接预测行动相比，使用LFMs在LLM输出标记的数量相同的情况下表现更好。第三，LFMs适应未见环境，通过一轮适应使任务完成率提高了3.5-12.0％。最后，可以修改LFM以提供人类可解释的反馈，无需性能损失，从而允许人类验证模仿学习的期望行为。

    We introduce Language Feedback Models (LFMs) that identify desirable behaviour - actions that help achieve tasks specified in the instruction - for imitation learning in instruction following. To train LFMs, we obtain feedback from Large Language Models (LLMs) on visual trajectories verbalized to language descriptions. First, by using LFMs to identify desirable behaviour to imitate, we improve in task-completion rate over strong behavioural cloning baselines on three distinct language grounding environments (Touchdown, ScienceWorld, and ALFWorld). Second, LFMs outperform using LLMs as experts to directly predict actions, when controlling for the number of LLM output tokens. Third, LFMs generalize to unseen environments, improving task-completion rate by 3.5-12.0% through one round of adaptation. Finally, LFM can be modified to provide human-interpretable feedback without performance loss, allowing human verification of desirable behaviour for imitation learning.
    
[^18]: Tempered Calculus for ML: 应用于双曲模型嵌入的研究

    Tempered Calculus for ML: Application to Hyperbolic Model Embedding

    [https://arxiv.org/abs/2402.04163](https://arxiv.org/abs/2402.04163)

    本论文介绍了基于温和微积分的理论和工具，来改进目前在机器学习中使用的数学扭曲方法，特别强调与几何和机器学习相关的特性。

    

    大多数在机器学习中使用的数学扭曲本质上都是积分的：$f$-divergences, Bregman divergences, (regularized) optimal transport distances, integral probability metrics, geodesic distances等。在本文中，我们揭示了一个基于温和微积分的理论和工具，可以帮助改进这些扭曲以更好地满足机器学习的要求。我们从广义的黎曼积分开始，这种积分还包括不严格可加的函数，而是更一般地是$t$-可加的，就像非极限统计力学中的情况一样。特别地，这种方法将Volterra的乘积积分作为特例。然后，我们使用（欧几里得）导数的扩展来推广基本定理。这些推广以及一系列更具体的定理为结果提供了基础，展示了如何以简单的方式专门设计、改变或改变扭曲度量的基本特性，特别强调与几何和机器学习相关的特性。

    Most mathematical distortions used in ML are fundamentally integral in nature: $f$-divergences, Bregman divergences, (regularized) optimal transport distances, integral probability metrics, geodesic distances, etc. In this paper, we unveil a grounded theory and tools which can help improve these distortions to better cope with ML requirements. We start with a generalization of Riemann integration that also encapsulates functions that are not strictly additive but are, more generally, $t$-additive, as in nonextensive statistical mechanics. Notably, this recovers Volterra's product integral as a special case. We then generalize the Fundamental Theorem of calculus using an extension of the (Euclidean) derivative. This, along with a series of more specific Theorems, serves as a basis for results showing how one can specifically design, alter, or change fundamental properties of distortion measures in a simple way, with a special emphasis on geometric- and ML-related properties that are the
    
[^19]: 在大规模情况下估计局部学习系数

    Estimating the Local Learning Coefficient at Scale

    [https://arxiv.org/abs/2402.03698](https://arxiv.org/abs/2402.03698)

    本文提出了一种方法，可以在深度线性网络中准确地测量高达1亿参数的局部学习系数(LLC)，并证明了估计得到的LLC具有重缩放不变性。

    

    局部学习系数(LLC)是一种量化模型复杂性的原则性方法，最初是在贝叶斯统计中使用奇异学习理论(SLT)推导出来的。已知有几种数值估计局部学习系数的方法，但迄今为止这些方法尚未扩展到现代深度学习架构或数据集的规模。通过在arXiv:2308.12108 [stat.ML]中开发的一种方法，我们经验证明可以准确和自洽地测量深度线性网络(DLN)中高达1亿参数的局部学习系数(LLC)。我们还证明了估计得到的LLC具有理论数量所具备的重缩放不变性。

    The \textit{local learning coefficient} (LLC) is a principled way of quantifying model complexity, originally derived in the context of Bayesian statistics using singular learning theory (SLT). Several methods are known for numerically estimating the local learning coefficient, but so far these methods have not been extended to the scale of modern deep learning architectures or data sets. Using a method developed in {\tt arXiv:2308.12108 [stat.ML]} we empirically show how the LLC may be measured accurately and self-consistently for deep linear networks (DLNs) up to 100M parameters. We also show that the estimated LLC has the rescaling invariance that holds for the theoretical quantity.
    
[^20]: 一种用于基于ReLU的非线性矩阵分解的动量加速算法

    A Momentum Accelerated Algorithm for ReLU-based Nonlinear Matrix Decomposition

    [https://arxiv.org/abs/2402.02442](https://arxiv.org/abs/2402.02442)

    提出了一种针对基于ReLU的非线性矩阵分解问题的动量加速算法，解决了现有模型中过拟合的问题，并通过实验验证了算法的有效性。

    

    最近，由于与神经网络的密切联系，人们对非线性矩阵分解（NMD）的探索日益增多。NMD旨在从稀疏的非负矩阵中找到一个低秩矩阵，其中每个元素都经过非线性函数，典型的选择是ReLU激活函数。为了解决现有的ReLU-NMD模型中的过拟合问题，我们提出了一种Tikhonov正则化的ReLU-NMD模型，称为ReLU-NMD-T。随后，我们引入了一种用于处理ReLU-NMD-T模型的动量加速算法。与大多数现有研究工作的一个显著特点是，我们的算法同时结合了正动量和负动量参数。我们对实际数据集进行的数值实验表明了所提出模型和算法的有效性。此外，代码可在https://github.com/nothing2wang/NMD-TM找到。

    Recently, there has been a growing interest in the exploration of Nonlinear Matrix Decomposition (NMD) due to its close ties with neural networks. NMD aims to find a low-rank matrix from a sparse nonnegative matrix with a per-element nonlinear function. A typical choice is the Rectified Linear Unit (ReLU) activation function. To address over-fitting in the existing ReLU-based NMD model (ReLU-NMD), we propose a Tikhonov regularized ReLU-NMD model, referred to as ReLU-NMD-T. Subsequently, we introduce a momentum accelerated algorithm for handling the ReLU-NMD-T model. A distinctive feature, setting our work apart from most existing studies, is the incorporation of both positive and negative momentum parameters in our algorithm. Our numerical experiments on real-world datasets show the effectiveness of the proposed model and algorithm. Moreover, the code is available at https://github.com/nothing2wang/NMD-TM.
    
[^21]: 数据驱动的通过伴随方法发现偏微分方程

    Data-Driven Discovery of PDEs via the Adjoint Method

    [https://arxiv.org/abs/2401.17177](https://arxiv.org/abs/2401.17177)

    本文提出了一种通过伴随方法从数据中发现潜在偏微分方程的方法，展示了在给定光滑数据集的情况下，该方法可以恢复真实的PDE，但在存在噪声的情况下，准确性与PDE-FIND方法相当。

    

    在这项工作中，我们提出了一种通过伴随方法来发现给定数据的潜在偏微分方程（PDEs）的方法。我们的思路是以一般形式考虑参数化的PDE，并制定最小化PDE解与数据误差的优化问题。利用变分计算，我们得到了拉格朗日乘子（伴随方程）的演化方程，使我们能够直接计算出与PDE参数相关的目标函数的梯度。特别是对于一族参数化和非线性PDEs，我们展示了如何推导出相应的伴随方程。我们在这里展示了，在给定光滑数据集的情况下，所提出的伴随方法可以以机器精度恢复真实的PDE。然而，在存在噪声的情况下，伴随方法的准确性与著名的PDE-FIND（Rudy et al., 2017）方法相当。

    In this work, we present an adjoint-based method for discovering the underlying governing partial differential equations (PDEs) given data. The idea is to consider a parameterized PDE in a general form, and formulate the optimization problem that minimizes the error of PDE solution from data. Using variational calculus, we obtain an evolution equation for the Lagrange multipliers (adjoint equations) allowing us to compute the gradient of the objective function with respect to the parameters of PDEs given data in a straightforward manner. In particular, for a family of parameterized and nonlinear PDEs, we show how the corresponding adjoint equations can be derived. Here, we show that given smooth data set, the proposed adjoint method can recover the true PDE up to machine accuracy. However, in the presence of noise, the accuracy of the adjoint method becomes comparable to the famous PDE Functional Identification of Nonlinear Dynamics method known as PDE-FIND (Rudy et al., 2017). Even th
    
[^22]: CEDAS：一种具有改进收敛性的压缩分布式随机梯度法

    CEDAS: A Compressed Decentralized Stochastic Gradient Method with Improved Convergence

    [https://arxiv.org/abs/2301.05872](https://arxiv.org/abs/2301.05872)

    CEDAS提出了一种压缩分布式随机梯度方法，在无偏压缩运算符下具有与集中式随机梯度下降相当的收敛速度，实现了最短的瞬态时间，对光滑强凸和非凸目标函数都适用。

    

    在本文中，我们考虑在通信受限环境下解决多代理网络上的分布式优化问题。我们研究了一种称为“具有自适应步长的压缩精确扩散（CEDAS）”的压缩分布式随机梯度方法，并证明该方法在无偏压缩运算符下渐近地实现了与集中式随机梯度下降（SGD）相当的收敛速度，适用于光滑强凸目标函数和光滑非凸目标函数。特别地，据我们所知，CEDAS迄今为止以其最短的瞬态时间（关于图的特性）实现了与集中式SGD相同的收敛速度，其在光滑强凸目标函数下表现为$\mathcal{O}(n{C^3}/(1-\lambda_2)^{2})$，在光滑非凸目标函数下表现为$\mathcal{O}(n^3{C^6}/(1-\lambda_2)^4)$，其中$(1-\lambda_2)$表示谱...

    arXiv:2301.05872v2 Announce Type: replace-cross  Abstract: In this paper, we consider solving the distributed optimization problem over a multi-agent network under the communication restricted setting. We study a compressed decentralized stochastic gradient method, termed ``compressed exact diffusion with adaptive stepsizes (CEDAS)", and show the method asymptotically achieves comparable convergence rate as centralized { stochastic gradient descent (SGD)} for both smooth strongly convex objective functions and smooth nonconvex objective functions under unbiased compression operators. In particular, to our knowledge, CEDAS enjoys so far the shortest transient time (with respect to the graph specifics) for achieving the convergence rate of centralized SGD, which behaves as $\mathcal{O}(n{C^3}/(1-\lambda_2)^{2})$ under smooth strongly convex objective functions, and $\mathcal{O}(n^3{C^6}/(1-\lambda_2)^4)$ under smooth nonconvex objective functions, where $(1-\lambda_2)$ denotes the spectr
    
[^23]: Text2Model:基于文本的模型归纳用于零样本图像分类

    Text2Model: Text-based Model Induction for Zero-shot Image Classification

    [https://arxiv.org/abs/2210.15182](https://arxiv.org/abs/2210.15182)

    该论文提出了一种使用文本描述构建与任务无关的分类器的方法，通过生成针对查询分类任务定制的模型来解决零样本图像分类问题。

    

    我们解决了仅使用文本描述构建与任务无关的分类器的挑战，展示了一种统一的方法来进行图像分类、3D点云分类以及从场景中识别动作。与学习固定输出类别表示的方法不同，我们在推断时生成针对查询分类任务定制的模型。为了生成基于任务的零样本分类器，我们训练一个超网络，该网络接收类描述并输出一个多类模型。超网络设计为对描述集合和分类层具有等变性，因此符合问题的对称性并提高了泛化性能。我们的方法生成非线性分类器，并且可以处理丰富的文本描述。我们在一系列零样本分类任务中评估了这种方法，涵盖了图像、点云和动作识别，并使用一系列文本描述。

    arXiv:2210.15182v2 Announce Type: replace-cross  Abstract: We address the challenge of building task-agnostic classifiers using only text descriptions, demonstrating a unified approach to image classification, 3D point cloud classification, and action recognition from scenes. Unlike approaches that learn a fixed representation of the output classes, we generate at inference time a model tailored to a query classification task. To generate task-based zero-shot classifiers, we train a hypernetwork that receives class descriptions and outputs a multi-class model. The hypernetwork is designed to be equivariant with respect to the set of descriptions and the classification layer, thus obeying the symmetries of the problem and improving generalization. Our approach generates non-linear classifiers and can handle rich textual descriptions. We evaluate this approach in a series of zero-shot classification tasks, for image, point-cloud, and action recognition, using a range of text descriptions
    
[^24]: 基于能量的概念瓶颈模型：统一预测、概念干预和条件解释

    Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations. (arXiv:2401.14142v1 [cs.CV])

    [http://arxiv.org/abs/2401.14142](http://arxiv.org/abs/2401.14142)

    基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。

    

    现有方法，如概念瓶颈模型 (CBM)，在为黑盒深度学习模型提供基于概念的解释方面取得了成功。它们通常通过在给定输入的情况下预测概念，然后在给定预测的概念的情况下预测最终的类别标签。然而，它们经常无法捕捉到概念之间的高阶非线性相互作用，例如纠正一个预测的概念（例如“黄色胸部”）无法帮助纠正高度相关的概念（例如“黄色腹部”），导致最终准确率不理想；它们无法自然地量化不同概念和类别标签之间的复杂条件依赖关系（例如对于一个带有类别标签“Kentucky Warbler”和概念“黑色嘴巴”的图像，模型能够正确预测另一个概念“黑色冠”的概率是多少），因此无法提供关于黑盒模型工作原理更深层次的洞察。针对这些限制，我们提出了基于能量的概念瓶颈模型（Energy-based Concept Bottleneck Models）。

    Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final class label given the predicted concepts. However, (1) they often fail to capture the high-order, nonlinear interaction between concepts, e.g., correcting a predicted concept (e.g., "yellow breast") does not help correct highly correlated concepts (e.g., "yellow belly"), leading to suboptimal final accuracy; (2) they cannot naturally quantify the complex conditional dependencies between different concepts and class labels (e.g., for an image with the class label "Kentucky Warbler" and a concept "black bill", what is the probability that the model correctly predicts another concept "black crown"), therefore failing to provide deeper insight into how a black-box model works. In response to these limitations, we propose Energy-based Concept Bot
    
[^25]: 快速半监督非凸优化解混合

    Fast Semi-supervised Unmixing using Non-convex Optimization. (arXiv:2401.12609v1 [cs.CV])

    [http://arxiv.org/abs/2401.12609](http://arxiv.org/abs/2401.12609)

    本文介绍了一种用于解混合的快速半监督非凸优化模型，该模型考虑了库不匹配和丰度约束，并提出了两种基于先验的半监督解混合方法。实验证明，实施凸性约束优于稀疏先验对于端元库的表现。

    

    本文介绍了一种针对半监督/基于库的解混合设计的新型线性模型。我们的模型考虑了库不匹配，并能够实施丰度和等于一的约束。与传统的稀疏解混合方法不同，该模型涉及到非凸优化，具有重要的计算挑战。我们展示了交替乘法器方法（ADMM）在循环求解这些复杂问题中的效果。我们提出了两种半监督解混合方法，每种方法都依赖于应用于新模型的不同先验以及丰度和等于一的约束：稀疏先验和凸性约束。我们的实验证明，实施凸性约束优于稀疏先验对于端元库的表现。这些结果在三个模拟数据集（考虑了光谱变化和不同像素纯度水平）和Cuprite数据集上得到了证实。此外，我们与传统方法进行了比较。

    In this paper, we introduce a novel linear model tailored for semisupervised/library-based unmixing. Our model incorporates considerations for library mismatch while enabling the enforcement of the abundance sum-to-one constraint (ASC). Unlike conventional sparse unmixing methods, this model involves nonconvex optimization, presenting significant computational challenges. We demonstrate the efficacy of Alternating Methods of Multipliers (ADMM) in cyclically solving these intricate problems. We propose two semisupervised unmixing approaches, each relying on distinct priors applied to the new model in addition to the ASC: sparsity prior and convexity constraint. Our experimental results validate that enforcing the convexity constraint outperforms the sparsity prior for the endmember library. These results are corroborated across three simulated datasets (accounting for spectral variability and varying pixel purity levels) and the Cuprite dataset. Additionally, our comparison with convent
    
[^26]: 高斯自适应注意力是唯一所需的：跨多个模态的健壮上下文表示

    Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])

    [http://arxiv.org/abs/2401.11143](http://arxiv.org/abs/2401.11143)

    该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。

    

    我们提出了多头高斯自适应注意力机制（GAAM），一种新颖的概率注意力框架，并设计了高斯自适应变压器（GAT），旨在增强跨多个模态（包括语音、文本和视觉）的信息聚合。GAAM将可学习的均值和方差融入其注意力机制中，采用多头框架实现，使其能够集体建模任何概率分布，以动态重新调整特征重要性。该方法在处理高度非平稳数据时表现出显著改进，通过识别特征空间中的关键元素，超越了现有的注意力技术在模型性能上的状态（精度增加约20%）。GAAM与基于点积的注意力模型兼容，并具有相对较低的参数数量，展示了其适应性和提升现有注意力框架的潜力。在实证方面，GAAM表现出卓越的适应性和功效。

    We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy
    
[^27]: 走向异质图学习：进展与未来

    Towards Learning from Graphs with Heterophily: Progress and Future. (arXiv:2401.09769v1 [cs.SI])

    [http://arxiv.org/abs/2401.09769](http://arxiv.org/abs/2401.09769)

    本调查综合概述了关于从带有异质性的图中学习的现有研究，并根据学习策略、模型架构和实际应用等方面对方法进行了分类。同时讨论了现有研究的主要挑战，并提出了未来研究的潜在方向。

    

    图是用来模拟现实世界实体之间复杂关系的结构化数据。最近，异质图，其中连接的节点往往具有不同的标签或不同的特征，引起了广泛关注并找到了许多应用。与此同时，人们也在不断努力推进从异质图中学习。虽然有关该主题的调查存在，但它们只关注于异质图神经网络（GNNs），而忽略了异质图学习的其他子主题。在本调查中，我们全面回顾了关于从带有异质性的图中学习的现有研究。首先，我们收集了180多篇论文，介绍了该领域的发展。然后，我们根据层次分类法对现有方法进行了系统分类，包括学习策略、模型架构和实际应用。最后，我们讨论了现有研究的主要挑战，并突出了未来研究的潜在方向。

    Graphs are structured data that models complex relations between real-world entities. Heterophilous graphs, where linked nodes are prone to be with different labels or dissimilar features, have recently attracted significant attention and found many applications. Meanwhile, increasing efforts have been made to advance learning from heterophilous graphs. Although there exist surveys on the relevant topic, they focus on heterophilous GNNs, which are only sub-topics of heterophilous graph learning. In this survey, we comprehensively overview existing works on learning from graphs with heterophily.First, we collect over 180 publications and introduce the development of this field. Then, we systematically categorize existing methods based on a hierarchical taxonomy including learning strategies, model architectures and practical applications. Finally, we discuss the primary challenges of existing studies and highlight promising avenues for future research.More publication details and corres
    
[^28]: 关于深度学习框架开发中自动识别假设的探索性研究

    An exploratory study on automatic identification of assumptions in the development of deep learning frameworks. (arXiv:2401.03653v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2401.03653](http://arxiv.org/abs/2401.03653)

    本研究以构建一个新的最大假设数据集为基础，针对深度学习框架开发中手动识别假设的问题进行了探索性研究。在该研究中，我们发现手动识别假设的成本高，因此探讨了使用传统机器学习模型和流行的深度学习模型来识别假设的性能。

    

    利益相关方在深度学习框架开发中经常做出假设。这些假设涉及各种软件构件（例如需求、设计决策和技术债务），可能会被证明无效，从而导致系统故障。现有的假设管理方法和工具通常依赖于手动识别假设。然而，假设分散在深度学习框架开发的各种源头（例如代码注释、提交、拉取请求和问题）中，手动识别假设成本较高（例如时间和资源消耗）。为了解决深度学习框架开发中手动识别假设的问题，我们构建了一个新的并且最大的假设数据集（称为AssuEval），该数据集收集自GitHub上的TensorFlow和Keras代码库；我们探讨了七个传统的机器学习模型（例如支持向量机、分类回归树）和一个流行的深度学习模型的性能。

    Stakeholders constantly make assumptions in the development of deep learning (DL) frameworks. These assumptions are related to various types of software artifacts (e.g., requirements, design decisions, and technical debt) and can turn out to be invalid, leading to system failures. Existing approaches and tools for assumption management usually depend on manual identification of assumptions. However, assumptions are scattered in various sources (e.g., code comments, commits, pull requests, and issues) of DL framework development, and manually identifying assumptions has high costs (e.g., time and resources). To overcome the issues of manually identifying assumptions in DL framework development, we constructed a new and largest dataset (i.e., AssuEval) of assumptions collected from the TensorFlow and Keras repositories on GitHub; explored the performance of seven traditional machine learning models (e.g., Support Vector Machine, Classification and Regression Trees), a popular DL model (i
    
[^29]: 欺骗的艺术：使用动态触发器的强健后门攻击

    The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers. (arXiv:2401.01537v1 [cs.CR])

    [http://arxiv.org/abs/2401.01537](http://arxiv.org/abs/2401.01537)

    这项研究介绍了一种使用动态触发器进行强健后门攻击的方法，通过巧妙设计的调整，使损坏的样本与干净的样本无法区分，实验证明这种方法可以成功地欺骗语音识别系统。

    

    由于人工智能行业的最新进展，机器学习作为服务（MLaaS）领域正在经历增长的实施。然而，这种增长引发了对AI防御机制的担忧，特别是对于来自不完全可信的第三方提供商的潜在隐蔽攻击。最近的研究发现，听觉后门可能使用某些修改作为其启动机制。DynamicTrigger作为一种方法被引入，用于进行使用巧妙设计的调整来确保损坏的样本与干净的样本无法区分的动态后门攻击。通过利用波动的信号采样率，并通过动态声音触发器（比如拍手声）对说话者身份进行掩盖，可以欺骗语音识别系统（ASR）。我们的实证测试表明，DynamicTrigger在隐蔽攻击中既有效又隐蔽，并在攻击过程中取得了令人印象深刻的成功率。

    The area of Machine Learning as a Service (MLaaS) is experiencing increased implementation due to recent advancements in the AI (Artificial Intelligence) industry. However, this spike has prompted concerns regarding AI defense mechanisms, specifically regarding potential covert attacks from third-party providers that cannot be entirely trusted. Recent research has uncovered that auditory backdoors may use certain modifications as their initiating mechanism. DynamicTrigger is introduced as a methodology for carrying out dynamic backdoor attacks that use cleverly designed tweaks to ensure that corrupted samples are indistinguishable from clean. By utilizing fluctuating signal sampling rates and masking speaker identities through dynamic sound triggers (such as the clapping of hands), it is possible to deceive speech recognition systems (ASR). Our empirical testing demonstrates that DynamicTrigger is both potent and stealthy, achieving impressive success rates during covert attacks while 
    
[^30]: 知识增强的医疗时间序列条件插补方法

    Knowledge Enhanced Conditional Imputation for Healthcare Time-series. (arXiv:2312.16713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.16713](http://arxiv.org/abs/2312.16713)

    本研究提出了一种知识增强的条件插补方法，针对医疗时间序列数据中的缺失数据问题。通过整合先进的知识嵌入和非均匀掩蔽策略，该方法能够灵活适应不同模式的电子健康记录中的缺失数据分布不平衡问题。

    

    本研究提出了一种新颖的方法来解决多变量时间序列中的缺失数据问题，特别关注医疗数据的复杂性。我们的条件自注意力插补（CSAI）模型以基于Transformer的框架为基础，引入了一种针对医疗时间序列数据细节的条件隐藏状态初始化方式。该方法与传统的插补技术不同，它特别针对医疗数据集中缺失数据分布的不平衡问题，这一关键问题常常被忽视。通过整合先进的知识嵌入和非均匀掩蔽策略，CSAI能够灵活适应电子健康记录（EHR）中缺失数据的不同模式。

    This study presents a novel approach to addressing the challenge of missing data in multivariate time series, with a particular focus on the complexities of healthcare data. Our Conditional Self-Attention Imputation (CSAI) model, grounded in a transformer-based framework, introduces a conditional hidden state initialization tailored to the intricacies of medical time series data. This methodology diverges from traditional imputation techniques by specifically targeting the imbalance in missing data distribution, a crucial aspect often overlooked in healthcare datasets. By integrating advanced knowledge embedding and a non-uniform masking strategy, CSAI adeptly adjusts to the distinct patterns of missing data in Electronic Health Records (EHRs).
    
[^31]: 《面向概率时空图学习的扩散模型统一化》

    Towards Unifying Diffusion Models for Probabilistic Spatio-Temporal Graph Learning. (arXiv:2310.17360v1 [cs.LG])

    [http://arxiv.org/abs/2310.17360](http://arxiv.org/abs/2310.17360)

    本文提出了一种统一的时空图学习方法，即统一时空扩散模型（USTD），用于处理物联网时代的各种学习任务。USTD综合考虑了时空数据中的不确定性，并利用共享的时空模式进行预测。此方法具有通用性和灵活性。

    

    在物联网时代，时空图学习是一个基本问题，可以应用于智能城市、人类移动性和气候分析等众多网络应用。现有方法独立地解决不同的学习任务，并根据任务特点调整模型。然而，这些方法未能模拟时空数据中的固有不确定性。同时，它们专门设计的模型限制了其作为普适时空学习解决方案的通用性。在本文中，我们提出以统一视角建模学习任务，将其视为基于共享时空模式的条件信息预测。基于这一建议，我们引入了统一时空扩散模型（USTD），在考虑不确定性的扩散框架下统一处理任务。USTD的设计是全面的，包括一个共享时空编码器和基于注意力的去噪网络，针对不同任务进行。

    Spatio-temporal graph learning is a fundamental problem in the Web of Things era, which enables a plethora of Web applications such as smart cities, human mobility and climate analysis. Existing approaches tackle different learning tasks independently, tailoring their models to unique task characteristics. These methods, however, fall short of modeling intrinsic uncertainties in the spatio-temporal data. Meanwhile, their specialized designs limit their universality as general spatio-temporal learning solutions. In this paper, we propose to model the learning tasks in a unified perspective, viewing them as predictions based on conditional information with shared spatio-temporal patterns. Based on this proposal, we introduce Unified Spatio-Temporal Diffusion Models (USTD) to address the tasks uniformly within the uncertainty-aware diffusion framework. USTD is holistically designed, comprising a shared spatio-temporal encoder and attention-based denoising networks that are task-specific. 
    
[^32]: 在高斯混合模型空间中引入了类似于Gromov-Wassertein的距离

    Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space. (arXiv:2310.11256v1 [stat.ML])

    [http://arxiv.org/abs/2310.11256](http://arxiv.org/abs/2310.11256)

    本文介绍了两种在高斯混合模型空间中的Gromov-Wasserstein类型距离，分别用于评估分布之间的距离和推导最优的点分配方案。

    

    本文介绍了两种在高斯混合模型集合上的Gromov-Wasserstein类型距离。第一种距离是在高斯测度空间上两个离散分布的Gromov-Wasserstein距离。该距离可以作为Gromov-Wasserstein的替代，用于评估分布之间的距离，但不能直接推导出最优的运输方案。为了设计出这样的运输方案，我们引入了另一种在不可比较的空间中的测度之间的距离，该距离与Gromov-Wasserstein密切相关。当将允许的运输耦合限制为高斯混合模型时，这定义了另一种高斯混合模型之间的距离，可以作为Gromov-Wasserstein的另一种替代，并允许推导出最优的点分配方案。

    In this paper, we introduce two Gromov-Wasserstein-type distances on the set of Gaussian mixture models. The first one takes the form of a Gromov-Wasserstein distance between two discrete distributionson the space of Gaussian measures. This distance can be used as an alternative to Gromov-Wasserstein for applications which only require to evaluate how far the distributions are from each other but does not allow to derive directly an optimal transportation plan between clouds of points. To design a way to define such a transportation plan, we introduce another distance between measures living in incomparable spaces that turns out to be closely related to Gromov-Wasserstein. When restricting the set of admissible transportation couplings to be themselves Gaussian mixture models in this latter, this defines another distance between Gaussian mixture models that can be used as another alternative to Gromov-Wasserstein and which allows to derive an optimal assignment between points. Finally,
    
[^33]: 异步联邦赌博机中的纯探索研究

    Pure Exploration in Asynchronous Federated Bandits. (arXiv:2310.11015v1 [cs.LG])

    [http://arxiv.org/abs/2310.11015](http://arxiv.org/abs/2310.11015)

    该论文研究了异步联邦赌博机中的纯探索问题，并提出了首个在完全异步环境下实现近乎最优样本复杂性和高效通信成本的联邦异步多臂赌博机和线性赌博机纯探索算法。

    

    我们研究了联邦纯探索问题，包括多臂赌博机和线性赌博机，其中M个代理通过与中央服务器通信，合作地确定最佳抽臂。为了增强对延迟和代理不可用性的鲁棒性，我们提出了第一个联邦异步多臂赌博机和线性赌博机纯探索算法，用于固定置信度。我们的理论分析表明，所提出的算法在完全异步环境中实现了近乎最优的样本复杂性和高效的通信成本。此外，基于合成和真实数据的实验结果从经验上阐明了所提出算法的效力和通信成本效率。

    We study the federated pure exploration problem of multi-armed bandits and linear bandits, where $M$ agents cooperatively identify the best arm via communicating with the central server. To enhance the robustness against latency and unavailability of agents that are common in practice, we propose the first federated asynchronous multi-armed bandit and linear bandit algorithms for pure exploration with fixed confidence. Our theoretical analysis shows the proposed algorithms achieve near-optimal sample complexities and efficient communication costs in a fully asynchronous environment. Moreover, experimental results based on synthetic and real-world data empirically elucidate the effectiveness and communication cost-efficiency of the proposed algorithms.
    
[^34]: IMITATE: 临床先验指导的分层视觉语言预训练模型

    IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training. (arXiv:2310.07355v1 [cs.CV])

    [http://arxiv.org/abs/2310.07355](http://arxiv.org/abs/2310.07355)

    IMITATE是一种临床先验指导的分层视觉语言预训练模型。它利用医学报告的层级结构，从胸部X射线图像中提取多级视觉特征，并与分层医学报告中的描述性和结论性文本进行对齐。

    

    在医学视觉语言预训练（VLP）领域，人们致力于从临床报告和相关医学图像中提取文本和图像特征。然而，大多数现有的方法可能忽视了利用临床报告固有的层级结构的机会，这些报告通常被分为描述性内容的“发现”和结论性观察的“印象”。当前的医学VLP方法往往将报告简化为一个统一的实体或分散的标记，而没有利用这种丰富的、结构化的格式。在这项工作中，我们提出了一种新的临床先验指导的VLP框架，名为IMITATE，用于从医学报告中学习结构信息，并使用分层视觉语言对齐。该框架从胸部X射线（CXR）图像中提取多级视觉特征，并将这些特征与分层医学报告中的描述性和结论性文本分别对齐。

    In the field of medical Vision-Language Pre-training (VLP), significant efforts have been devoted to deriving text and image features from both clinical reports and associated medical images. However, most existing methods may have overlooked the opportunity in leveraging the inherent hierarchical structure of clinical reports, which are generally split into `findings' for descriptive content and `impressions' for conclusive observation. Instead of utilizing this rich, structured format, current medical VLP approaches often simplify the report into either a unified entity or fragmented tokens. In this work, we propose a novel clinical prior guided VLP framework named IMITATE to learn the structure information from medical reports with hierarchical vision-language alignment. The framework derives multi-level visual features from the chest X-ray (CXR) images and separately aligns these features with the descriptive and the conclusive text encoded in the hierarchical medical report. Furth
    
[^35]: 通过对抗行为抑制Q学习中的过高估计

    Suppressing Overestimation in Q-Learning through Adversarial Behaviors. (arXiv:2310.06286v1 [cs.LG])

    [http://arxiv.org/abs/2310.06286](http://arxiv.org/abs/2310.06286)

    本文提出了一种新的Q学习算法，通过引入虚拟对抗性玩家，有效调节了标准Q学习中的过高估计偏差，提出的算法简单而有效，能够轻松应用于强化学习算法并提高性能。

    

    本文旨在提出一种新的Q学习算法，使用一个虚拟对抗性玩家，称为虚拟对抗性Q学习（DAQ），以有效地调节标准Q学习中的过高估计偏差。通过虚拟玩家，学习可以被表述为一个双人零和博弈。所提出的DAQ将几种Q学习的变体统一到一个单一的框架中，以控制过高估计偏差，例如maxmin Q学习和minmax Q学习（本文提出）。通过虚拟对抗性行为，所提出的DAQ是一种简单而有效的方式，可以轻松应用于现成的强化学习算法，以提高性能。通过调整对抗性Q学习，从综合的角度分析了DAQ的有限时间收敛性。在各种基准环境下，实证验证了所提出DAQ的性能。

    The goal of this paper is to propose a new Q-learning algorithm with a dummy adversarial player, which is called dummy adversarial Q-learning (DAQ), that can effectively regulate the overestimation bias in standard Q-learning. With the dummy player, the learning can be formulated as a two-player zero-sum game. The proposed DAQ unifies several Q-learning variations to control overestimation biases, such as maxmin Q-learning and minmax Q-learning (proposed in this paper) in a single framework. The proposed DAQ is a simple but effective way to suppress the overestimation bias thourgh dummy adversarial behaviors and can be easily applied to off-the-shelf reinforcement learning algorithms to improve the performances. A finite-time convergence of DAQ is analyzed from an integrated perspective by adapting an adversarial Q-learning. The performance of the suggested DAQ is empirically demonstrated under various benchmark environments.
    
[^36]: 通过元模型改进了配体-蛋白质结合亲和力的预测

    Improved prediction of ligand-protein binding affinities by meta-modeling. (arXiv:2310.03946v1 [cs.LG])

    [http://arxiv.org/abs/2310.03946](http://arxiv.org/abs/2310.03946)

    通过整合基于结构的对接和基于序列的深度学习模型，开发了一个元模型框架，显著改善了配体-蛋白质结合亲和力预测的性能。

    

    通过计算方法准确筛选候选药物配体与靶蛋白的结合是药物开发的主要关注点，因为筛选潜在候选物能够节省找药物的时间和费用。这种虚拟筛选部分依赖于预测配体和蛋白质之间的结合亲和力的方法。鉴于存在许多计算模型对不同目标的结合亲和力预测结果不同，我们在这里开发了一个元模型框架，通过整合已发表的基于结构的对接和基于序列的深度学习模型来构建。在构建这个框架时，我们评估了许多组合的个别模型、训练数据库以及线性和非线性的元模型方法。我们显示出许多元模型在亲和力预测上显著改善了个别基础模型的性能。我们最好的元模型达到了与最先进的纯结构为基础的深度学习工具相当的性能。总体而言，我们证明了这个元模型框架可以显著改善配体-蛋白质结合亲和力预测的性能。

    The accurate screening of candidate drug ligands against target proteins through computational approaches is of prime interest to drug development efforts, as filtering potential candidates would save time and expenses for finding drugs. Such virtual screening depends in part on methods to predict the binding affinity between ligands and proteins. Given many computational models for binding affinity prediction with varying results across targets, we herein develop a meta-modeling framework by integrating published empirical structure-based docking and sequence-based deep learning models. In building this framework, we evaluate many combinations of individual models, training databases, and linear and nonlinear meta-modeling approaches. We show that many of our meta-models significantly improve affinity predictions over individual base models. Our best meta-models achieve comparable performance to state-of-the-art exclusively structure-based deep learning tools. Overall, we demonstrate 
    
[^37]: Stackelberg轨迹博弈中的主动逆向学习

    Active Inverse Learning in Stackelberg Trajectory Games. (arXiv:2308.08017v1 [cs.GT])

    [http://arxiv.org/abs/2308.08017](http://arxiv.org/abs/2308.08017)

    这项研究提出了一种在Stackelberg博弈中的主动逆向学习方法，通过活跃地最大化跟随者在不同假设下的轨迹差异来加速领导者的推断过程。

    

    博弈论的逆向学习是从玩家的行为中推断出他们的目标的问题。我们在一个Stackelberg博弈中，通过每个玩家的动态系统轨迹来定义一个逆向学习问题，其中包括一个领导者和一个跟随者。我们提出了一种主动逆向学习方法，让领导者推断出一个有限候选集中描述跟随者目标函数的假设。与现有方法使用被动观察到的轨迹不同，所提出的方法主动地最大化不同假设下跟随者轨迹的差异，加速领导者的推断过程。我们在一个递进的重复轨迹博弈中展示了所提出的方法。与均匀随机输入相比，所提供的方法加速了概率收敛到条件于跟随者轨迹的不同假设上的收敛速度。

    Game-theoretic inverse learning is the problem of inferring the players' objectives from their actions. We formulate an inverse learning problem in a Stackelberg game between a leader and a follower, where each player's action is the trajectory of a dynamical system. We propose an active inverse learning method for the leader to infer which hypothesis among a finite set of candidates describes the follower's objective function. Instead of using passively observed trajectories like existing methods, the proposed method actively maximizes the differences in the follower's trajectories under different hypotheses to accelerate the leader's inference. We demonstrate the proposed method in a receding-horizon repeated trajectory game. Compared with uniformly random inputs, the leader inputs provided by the proposed method accelerate the convergence of the probability of different hypotheses conditioned on the follower's trajectory by orders of magnitude.
    
[^38]: 可解释的推理方法用于刻板印象识别

    Interpretable Stereotype Identification through Reasoning. (arXiv:2308.00071v1 [cs.CL])

    [http://arxiv.org/abs/2308.00071](http://arxiv.org/abs/2308.00071)

    本研究通过使用推理方法，在零射击刻板印象识别中取得了重要的进展，并发现推理的性能增益远远超过模型规模扩展的增益。推理不仅提高了准确性，还提高了决策的可解释性。

    

    鉴于语言模型训练使用了包含固有偏见的大量数据集，可能会不经意地持续系统性歧视，因此，审查和解决语言模型中的偏见变得至关重要，将公平性整合到它们的发展中，以确保这些模型具有公正和无偏的特性。在这项工作中，我们展示了基于Vicuna-13B-v1.3的零射击刻板印象识别中推理的重要性。尽管我们观察到从13B到33B的规模扩展会提高准确性，但我们表明推理的性能增益远远超过规模扩展的增益。我们的研究结果表明，推理可能是使LLMs在刻板印象等领域任务上超越规模定律的关键因素。此外，通过对选定的推理追踪进行定性分析，我们突出显示了推理不仅提高了准确性，还提高了决策的可解释性。

    Given that language models are trained on vast datasets that may contain inherent biases, there is a potential danger of inadvertently perpetuating systemic discrimination. Consequently, it becomes essential to examine and address biases in language models, integrating fairness into their development to ensure these models are equitable and free from bias. In this work, we demonstrate the importance of reasoning in zero-shot stereotype identification based on Vicuna-13B-v1.3. While we do observe improved accuracy by scaling from 13B to 33B, we show that the performance gain from reasoning significantly exceeds the gain from scaling up. Our findings suggest that reasoning could be a key factor that enables LLMs to trescend the scaling law on out-of-domain tasks such as stereotype identification. Additionally, through a qualitative analysis of select reasoning traces, we highlight how reasoning enhances not just accuracy but also the interpretability of the decision.
    
[^39]: 从几何角度看待概率鲁棒学习中的边界问题

    It begins with a boundary: A geometric view on probabilistically robust learning. (arXiv:2305.18779v1 [cs.LG])

    [http://arxiv.org/abs/2305.18779](http://arxiv.org/abs/2305.18779)

    本文探讨了深度神经网络对于对抗生成的示例缺乏鲁棒性的问题，并提出了一种从几何角度出发的新颖视角，介绍一族概率非局部周长函数来优化概率鲁棒学习（PRL）的原始表述，以提高其鲁棒性。

    

    尽管深度神经网络在许多分类任务上已经实现了超人类的表现，但它们往往对于对抗生成的示例缺乏鲁棒性，因此需要将经验风险最小化（ERM）重构为对抗性鲁棒的框架。最近，关注点已经转向了介于对抗性训练提供的鲁棒性和ERM提供的更高干净准确性和更快训练时间之间的方法。本文从几何角度出发，对一种这样的方法——概率鲁棒学习（PRL）（Robey等人，ICML，2022）进行了新颖的几何视角的探讨。我们提出了一个几何框架来理解PRL，这使我们能够确定其原始表述中的微妙缺陷，并介绍了一族概率非局部周长函数来解决这一问题。我们使用新颖的松弛方法证明了解的存在，并研究了引入的非局部周长函数的特性以及局部极限。

    Although deep neural networks have achieved super-human performance on many classification tasks, they often exhibit a worrying lack of robustness towards adversarially generated examples. Thus, considerable effort has been invested into reformulating Empirical Risk Minimization (ERM) into an adversarially robust framework. Recently, attention has shifted towards approaches which interpolate between the robustness offered by adversarial training and the higher clean accuracy and faster training times of ERM. In this paper, we take a fresh and geometric view on one such method -- Probabilistically Robust Learning (PRL) (Robey et al., ICML, 2022). We propose a geometric framework for understanding PRL, which allows us to identify a subtle flaw in its original formulation and to introduce a family of probabilistic nonlocal perimeter functionals to address this. We prove existence of solutions using novel relaxation methods and study properties as well as local limits of the introduced per
    
[^40]: 生物医学自然语言处理中的大型语言模型: 基准、基线和建议

    Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])

    [http://arxiv.org/abs/2305.16326](http://arxiv.org/abs/2305.16326)

    本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。

    

    生物医学文献呈指数级增长，手动筛选和提取知识变得困难。自动从生物医学文献中提取信息的生物医学自然语言处理（BioNLP）技术有助于减轻这种负担。近年来，如GPT-3和GPT-4等大型语言模型（LLMs）因其卓越的性能而受到重视。但是，它们在BioNLP任务中的有效性以及对方法开发和下游用户的影响仍未得到研究。本研究（1）在四个应用程序中在八个BioNLP数据集中建立了GPT-3和GPT-4在零-shot和一-shot设置下的基准表现，包括命名实体识别，关系提取，多标签文档分类和语义相似性和推理；（2）审查了LLMs产生的错误，并将错误分为三种类型：缺失，不一致和不需要的人工内容；（3）提出了使用LLMs的建议。

    Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
    
[^41]: 实现离线强化学习的极小极大样本复杂性：一种基于DRO的方法。

    Achieving Minimax Optimal Sample Complexity of Offline Reinforcement Learning: A DRO-Based Approach. (arXiv:2305.13289v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.13289](http://arxiv.org/abs/2305.13289)

    本文提出了一种分布鲁棒优化 (DRO)的方法，用于解决离线强化学习中的数据有限性和分布转移问题。通过直接建模转移核的不确定性，并寻找在不确定性集合中最优化最坏情况下的性能的策略，实现了极小极大最优性。

    

    离线强化学习旨在从先前收集的数据集中学习，而无需主动探索。该问题面临着诸多挑战，包括有限的数据可用性和分布转移。现有方法采用一种悲观的态度对待不确定性，通过惩罚未充分探索的状态-行为对的奖励来保守估计值函数。在本文中，我们展示了分布鲁棒优化（DRO）基于方法也可以应对这些挑战，并且是极小极大最优的。具体而言，我们直接建模转移核的不确定性，并构建一个统计合理的转移核不确定性集合。然后我们寻找在该不确定性集合上最优化最坏情况下的性能的策略。我们首先设计了一种基于度量的霍夫丁风格不确定性集合，这样真实的转移核以高概率位于该集合中。我们证明了为了实现$\epsilon$的次最优性差距，样本复杂度为$\mat。

    Offline reinforcement learning aims to learn from pre-collected datasets without active exploration. This problem faces significant challenges, including limited data availability and distributional shifts. Existing approaches adopt a pessimistic stance towards uncertainty by penalizing rewards of under-explored state-action pairs to estimate value functions conservatively. In this paper, we show that the distributionally robust optimization (DRO) based approach can also address these challenges and is minimax optimal. Specifically, we directly model the uncertainty in the transition kernel and construct an uncertainty set of statistically plausible transition kernels. We then find the policy that optimizes the worst-case performance over this uncertainty set. We first design a metric-based Hoeffding-style uncertainty set such that with high probability the true transition kernel is in this set. We prove that to achieve a sub-optimality gap of $\epsilon$, the sample complexity is $\mat
    
[^42]: 一种动物行为计算分析的基准，使用动物携带的标签。

    A benchmark for computational analysis of animal behavior, using animal-borne tags. (arXiv:2305.10740v1 [cs.LG])

    [http://arxiv.org/abs/2305.10740](http://arxiv.org/abs/2305.10740)

    该论文介绍了一个名为BEBE的动物行为计算分析基准，其中包括了1654小时的动物生态生理学数据，这是迄今为止最大、最具分类多样性的公开可用的数据集合。在这个基准上，作者使用了十种机器学习方法并确定了未来工作中需要解决的关键问题。

    

    动物携带的传感器（“生物记录器”）可以记录一系列动力学和环境数据，揭示动物生态生理学并改善保护工作。机器学习技术对于解释生物记录器记录的大量数据非常有用，但在这个领域中没有标准来比较不同的机器学习技术。为了解决这个问题，我们提出了Bio-logger Ethogram Benchmark（BEBE），这是一个带有行为注释，标准化建模任务和评估指标的数据集合。BEBE是迄今为止最大、最具分类多样性和公开可用的这种基准，包括来自九个分类单元中149个个体收集的1654小时数据。我们在BEBE上评估了十种不同的机器学习方法的性能，并确定了未来工作中需要解决的关键问题。数据集、模型和评估代码已公开发布在https://github.com/earthspecies/BEBE，以便社区使用。

    Animal-borne sensors ('bio-loggers') can record a suite of kinematic and environmental data, which can elucidate animal ecophysiology and improve conservation efforts. Machine learning techniques are useful for interpreting the large amounts of data recorded by bio-loggers, but there exists no standard for comparing the different machine learning techniques in this domain. To address this, we present the Bio-logger Ethogram Benchmark (BEBE), a collection of datasets with behavioral annotations, standardized modeling tasks, and evaluation metrics. BEBE is to date the largest, most taxonomically diverse, publicly available benchmark of this type, and includes 1654 hours of data collected from 149 individuals across nine taxa. We evaluate the performance of ten different machine learning methods on BEBE, and identify key challenges to be addressed in future work. Datasets, models, and evaluation code are made publicly available at https://github.com/earthspecies/BEBE, to enable community 
    
[^43]: 零和游戏的对数遗憾量子学习算法

    Logarithmic-Regret Quantum Learning Algorithms for Zero-Sum Games. (arXiv:2304.14197v1 [quant-ph])

    [http://arxiv.org/abs/2304.14197](http://arxiv.org/abs/2304.14197)

    该论文提出了一个在线零和游戏的量子算法，可以在量子时间计算出$\varepsilon$-近似纳什均衡，是目前第一个实现基于量子计算的快速量子线性编程求解器。

    

    我们提出了第一个在线零和游戏的量子算法，并在游戏设置下实现了 $\tilde O(1)$ 的遗憾度。此外，我们的量子算法可以在量子时间$\tilde O(\sqrt{m+n}/\varepsilon^{2.5})$内计算$m\times n$矩阵零和游戏的$\varepsilon$-近似纳什均衡，相对于传统算法在$m, n$方面实现了二次改进。我们的算法使用标准的量子输入，并生成简明的描述性的经典输出，方便进行端到端应用。作为应用，我们获得了一个快速的量子线性规划求解器。在技术上，我们的在线量子算法基于乐观的乘法权重更新方法“量子化”了经典算法。我们算法的核心是一个快速量子多重采样过程，用于Gibbs采样问题，这可能是独立感兴趣的问题。

    We propose the first online quantum algorithm for zero-sum games with $\tilde O(1)$ regret under the game setting. Moreover, our quantum algorithm computes an $\varepsilon$-approximate Nash equilibrium of an $m \times n$ matrix zero-sum game in quantum time $\tilde O(\sqrt{m+n}/\varepsilon^{2.5})$, yielding a quadratic improvement over classical algorithms in terms of $m, n$. Our algorithm uses standard quantum inputs and generates classical outputs with succinct descriptions, facilitating end-to-end applications. As an application, we obtain a fast quantum linear programming solver. Technically, our online quantum algorithm "quantizes" classical algorithms based on the optimistic multiplicative weight update method. At the heart of our algorithm is a fast quantum multi-sampling procedure for the Gibbs sampling problem, which may be of independent interest.
    
[^44]: 论数据异构性对分布式线性系统求解器收敛速度的影响

    On the Effects of Data Heterogeneity on the Convergence Rates of Distributed Linear System Solvers. (arXiv:2304.10640v1 [cs.DC])

    [http://arxiv.org/abs/2304.10640](http://arxiv.org/abs/2304.10640)

    本文比较了投影方法和优化方法求解分布式线性系统的收敛速度，提出了角异构性的几何概念，并对最有效的算法(APC和D-HBM)的收敛速度进行了约束和比较。

    

    本文考虑了解决大规模线性方程组的基本问题。特别地，我们考虑任务负责人打算在一组具有一些方程组子集的机器的分布式/联合帮助下解决该系统的设置。虽然有几种方法用于解决这个问题，但缺少对投影方法和优化方法收敛速度的严格比较。在本文中，我们分析并比较这两类算法，特别关注每个类别中最有效的方法，即最近提出的加速投影一致性(APC)和分布式重球方法(D-HBM)。为此，我们首先提出了称为角异构性的几何概念，并讨论其普遍性。使用该概念，我们约束并比较所研究算法的收敛速度，并捕捉两种方法的异构数据的效应。

    We consider the fundamental problem of solving a large-scale system of linear equations. In particular, we consider the setting where a taskmaster intends to solve the system in a distributed/federated fashion with the help of a set of machines, who each have a subset of the equations. Although there exist several approaches for solving this problem, missing is a rigorous comparison between the convergence rates of the projection-based methods and those of the optimization-based ones. In this paper, we analyze and compare these two classes of algorithms with a particular focus on the most efficient method from each class, namely, the recently proposed Accelerated Projection-Based Consensus (APC) and the Distributed Heavy-Ball Method (D-HBM). To this end, we first propose a geometric notion of data heterogeneity called angular heterogeneity and discuss its generality. Using this notion, we bound and compare the convergence rates of the studied algorithms and capture the effects of both 
    
[^45]: 对比学习与属性关联的出现

    Contrastive Learning and the Emergence of Attributes Associations. (arXiv:2302.10763v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.10763](http://arxiv.org/abs/2302.10763)

    对比学习方案通过对物体输入表示进行身份保持的变换，不仅有助于物体的分类，还可以提供关于属性的有无决策的有价值信息。

    

    对于物体呈现，监督学习方案通常会给出一个简洁的标签。而人类在类似的呈现下，除了给出一个标签外，还会被大量的关联信息所淹没，其中包括了呈现物体的属性。对比学习是一种半监督学习方案，基于对物体输入表示进行保持身份的变换。本研究推测，这些变换不仅可以保持呈现物体的身份，还可以保持其语义上有意义的属性的身份。这意味着对比学习方案的输出表示不仅对于呈现物体的分类有价值，还对于任何感兴趣属性的有无决策有价值。通过模拟实验证明了这一观点的可行性。

    In response to an object presentation, supervised learning schemes generally respond with a parsimonious label. Upon a similar presentation we humans respond again with a label, but are flooded, in addition, by a myriad of associations. A significant portion of these consist of the presented object attributes. Contrastive learning is a semi-supervised learning scheme based on the application of identity preserving transformations on the object input representations. It is conjectured in this work that these same applied transformations preserve, in addition to the identity of the presented object, also the identity of its semantically meaningful attributes. The corollary of this is that the output representations of such a contrastive learning scheme contain valuable information not only for the classification of the presented object, but also for the presence or absence decision of any attribute of interest. Simulation results which demonstrate this idea and the feasibility of this co
    
[^46]: 不考虑图骨架的组合因果赌博机

    Combinatorial Causal Bandits without Graph Skeleton. (arXiv:2301.13392v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13392](http://arxiv.org/abs/2301.13392)

    本文研究了在二值一般因果模型和BGLMs上不考虑图骨架的组合因果赌博机问题，提出了可在BGLMs上实现的无需图骨架的遗憾最小化算法，达到了与依赖于图结构的最先进算法相同的渐进遗憾率$O(\sqrt{T}\ln T)$。

    

    在组合因果赌博机问题中，学习代理在每一轮选择一组变量进行干预，收集观测变量的反馈以最小化期望遗憾或样本复杂度。先前的工作研究了一般因果模型和二值广义线性模型（BGLMs）中的问题。但是，它们都需要先验知识来构建因果关系图。本文研究了在二值一般因果模型和BGLMs上不考虑图骨架的组合因果赌博机问题。我们首先在一般因果模型上提供了累积遗憾的指数下限。然后，我们设计了一种无需图骨架来实现BGLMs的遗憾最小化算法，表明它仍然达到$O(\sqrt{T}\ln T)$的期望遗憾。这个渐进的遗憾率与依赖于图结构的最先进算法相同。

    In combinatorial causal bandits (CCB), the learning agent chooses a subset of variables in each round to intervene and collects feedback from the observed variables to minimize expected regret or sample complexity. Previous works study this problem in both general causal models and binary generalized linear models (BGLMs). However, all of them require prior knowledge of causal graph structure. This paper studies the CCB problem without the graph structure on binary general causal models and BGLMs. We first provide an exponential lower bound of cumulative regrets for the CCB problem on general causal models. To overcome the exponentially large space of parameters, we then consider the CCB problem on BGLMs. We design a regret minimization algorithm for BGLMs even without the graph skeleton and show that it still achieves $O(\sqrt{T}\ln T)$ expected regret. This asymptotic regret is the same as the state-of-art algorithms relying on the graph structure. Moreover, we sacrifice the regret t
    
[^47]: 判别熵聚类及其与K-means和SVM的关系

    Discriminative Entropy Clustering and its Relation to K-means and SVM. (arXiv:2301.11405v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11405](http://arxiv.org/abs/2301.11405)

    该论文介绍了判别熵聚类的相关理论及其与K-means和SVM的区别和相似之处。同时提出了一种新的损失函数，用于改进深度聚类的性能。

    

    在判别模型中，最大化模型输入和输出之间的互信息形式上与 softmax 预测的“决策性”和“公平性”有关，从而激发了基于熵的无监督损失函数的使用。 最近，基于这样的损失函数的自我标记方法代表了深度聚类的最新研究方向。 首先，我们讨论了这种熵聚类方法的许多通用属性，包括它们与 K-means 和无监督 SVM 技术的关系。 我们证明与 K-均值有着根本的区别。另一方面，我们表明了与基于 SVM 的聚类的相似性，使我们能够将显式的边际最大化与熵聚类联系起来。最后，我们观察到交叉熵的常见形式对于伪标签错误不稳健。我们的新损失解决了这个问题，并导致了一种新的 EM 算法，在许多标准基准测试中改进了最新技术水平。

    Maximization of mutual information between the model's input and output is formally related to "decisiveness" and "fairness" of the softmax predictions, motivating such unsupervised entropy-based losses for discriminative models. Recent self-labeling methods based on such losses represent the state of the art in deep clustering. First, we discuss a number of general properties of such entropy clustering methods, including their relation to K-means and unsupervised SVM-based techniques. Disproving some earlier published claims, we point out fundamental differences with K-means. On the other hand, we show similarity with SVM-based clustering allowing us to link explicit margin maximization to entropy clustering. Finally, we observe that the common form of cross-entropy is not robust to pseudo-label errors. Our new loss addresses the problem and leads to a new EM algorithm improving the state of the art on many standard benchmarks.
    
[^48]: 通用状态和动作空间上的策略优化

    Policy Optimization over General State and Action Spaces. (arXiv:2211.16715v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16715](http://arxiv.org/abs/2211.16715)

    本文提出了一种新方法并引入了函数近似来解决通用状态和动作空间上的强化学习问题，同时介绍了一种新的策略双平均法。

    

    通用状态和动作空间上的强化学习问题异常困难。本文提出了一种新方法，并引入了函数近似来解决这个问题。同时，还提出了一种新的策略双平均法。这些方法都可以应用于不同类型的RL问题。

    Reinforcement learning (RL) problems over general state and action spaces are notoriously challenging. In contrast to the tableau setting, one can not enumerate all the states and then iteratively update the policies for each state. This prevents the application of many well-studied RL methods especially those with provable convergence guarantees. In this paper, we first present a substantial generalization of the recently developed policy mirror descent method to deal with general state and action spaces. We introduce new approaches to incorporate function approximation into this method, so that we do not need to use explicit policy parameterization at all. Moreover, we present a novel policy dual averaging method for which possibly simpler function approximation techniques can be applied. We establish linear convergence rate to global optimality or sublinear convergence to stationarity for these methods applied to solve different classes of RL problems under exact policy evaluation. 
    
[^49]: 用核斯坦离差控制矩

    Controlling Moments with Kernel Stein Discrepancies. (arXiv:2211.05408v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.05408](http://arxiv.org/abs/2211.05408)

    本研究分析了核斯坦离差（KSD）控制性质，发现标准KSD无法控制矩的收敛，提出了可控制矩和弱收敛的下游扩散KSD，并且发展了可以准确描述$q$-Wasserstein收敛的KSD。

    

    核斯坦离差（KSD）用于衡量分布逼近的质量，并且可以在目标密度具有不可计算的归一化常数时计算。显著的应用包括诊断近似MCMC采样器和非归一化统计模型的适配度检验。本文分析了KSD的收敛控制性质。我们首先证明了用于弱收敛控制的标准KSD无法控制矩的收敛。为了解决这个限制，我们提供了一组充分条件，下游扩散KSD可以同时控制矩和弱收敛。作为一个直接的结果，我们发展了对于每个$q>0$，第一组已知可以准确描述$q$-Wasserstein收敛的KSD。

    Kernel Stein discrepancies (KSDs) measure the quality of a distributional approximation and can be computed even when the target density has an intractable normalizing constant. Notable applications include the diagnosis of approximate MCMC samplers and goodness-of-fit tests for unnormalized statistical models. The present work analyzes the convergence control properties of KSDs. We first show that standard KSDs used for weak convergence control fail to control moment convergence. To address this limitation, we next provide sufficient conditions under which alternative diffusion KSDs control both moment and weak convergence. As an immediate consequence we develop, for each $q > 0$, the first KSDs known to exactly characterize $q$-Wasserstein convergence.
    
[^50]: Bayesian层次回归模型的近似交叉验证均值估计

    Approximate Cross-validated Mean Estimates for Bayesian Hierarchical Regression Models. (arXiv:2011.14238v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2011.14238](http://arxiv.org/abs/2011.14238)

    我们提出了一种用于贝叶斯层次回归模型的近似交叉验证均值估计的新方法，通过在方差-协方差参数上进行条件，将交叉验证问题转化为简单的优化问题，从而提高了大型BHRMs的可行性。

    

    我们引入了一种新的方法，用于获取贝叶斯层次回归模型(BHRMs)的交叉验证预测估计。贝叶斯层次模型以其能够建模复杂的依赖结构并提供概率不确定性估计而受到欢迎，但运行的计算开销很大。因此，交叉验证(CV)不是评估BHRMs预测性能的常见实践。我们的方法避免了为每个交叉验证折叠重新运行计算开销昂贵的估计方法的需要，使CV在大型BHRMs中更可行。通过在方差-协方差参数上进行条件，将CV问题从基于概率的抽样转化为简单熟悉的优化问题。在许多情况下，这产生的估计与完整的CV等效。我们提供理论结果，并在公开可用的数据和模拟中证明其有效性。

    We introduce a novel procedure for obtaining cross-validated predictive estimates for Bayesian hierarchical regression models (BHRMs). Bayesian hierarchical models are popular for their ability to model complex dependence structures and provide probabilistic uncertainty estimates, but can be computationally expensive to run. Cross-validation (CV) is therefore not a common practice to evaluate the predictive performance of BHRMs. Our method circumvents the need to re-run computationally costly estimation methods for each cross-validation fold and makes CV more feasible for large BHRMs. By conditioning on the variance-covariance parameters, we shift the CV problem from probability-based sampling to a simple and familiar optimization problem. In many cases, this produces estimates which are equivalent to full CV. We provide theoretical results and demonstrate its efficacy on publicly available data and in simulations.
    

