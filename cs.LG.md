# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Grappa -- A Machine Learned Molecular Mechanics Force Field](https://arxiv.org/abs/2404.00050) | 提出了一个用于预测分子力学参数的机器学习架构Grappa，通过图注意力神经网络和transformer提高了准确性，减少了计算开销，能在现有MD引擎中使用。 |
| [^2] | [The opportunities and risks of large language models in mental health](https://arxiv.org/abs/2403.14814) | 大型语言模型在心理健康领域有望提供新颖的解决方案，但应注意其应用可能带来的风险，并积极采取策略减轻这些风险。 |
| [^3] | [An Aligning and Training Framework for Multimodal Recommendations](https://arxiv.org/abs/2403.12384) | 提出了一种名为AlignRec的对齐和训练框架，用于解决多模态推荐中的不对齐问题，通过将推荐目标分解为三个对齐部分，实现内容内部对齐、内容与分类ID之间的对齐以及用户和项目之间的对齐。 |
| [^4] | [Attention-based Class-Conditioned Alignment for Multi-Source Domain Adaptive Object Detection](https://arxiv.org/abs/2403.09918) | 提出了一种基于注意力的类别条件对齐方案，用于多源领域自适应目标检测，在跨领域对齐每个对象类别的实例。 |
| [^5] | [Actor-Critic Physics-informed Neural Lyapunov Control](https://arxiv.org/abs/2403.08448) | 提出了一种新方法，通过使用祖博夫的偏微分方程（PDE）来训练神经网络控制器，以及对应的李雅普诺夫证书，以最大化区域吸引力，并尊重激励约束。 |
| [^6] | [Switching the Loss Reduces the Cost in Batch Reinforcement Learning](https://arxiv.org/abs/2403.05385) | 使用对数损失函数来训练适合的Q迭代的批强化学习方法，在实现目标时不产生成本的问题中，其样本数量需求与最优策略的累积成本成比例，能够提供与最优可达成本成比例的“小成本”界限，并在实验中验证在那些最优策略可靠实现目标的问题中，FQI-LOG比使用平方损失训练的FQI使用更少的样本。 |
| [^7] | [Informed Meta-Learning](https://arxiv.org/abs/2402.16105) | 该研究提出了通知元学习这一新范式，旨在通过人类和机器之间的跨任务知识共享，提高数据效率和抵御观测噪声。 |
| [^8] | [Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior](https://arxiv.org/abs/2402.15402) | 该论文提出了一种具有策略结构先验的高效未知物体重新排列系统，通过内外环的学习，实现了抓取、观察和放置在感知噪声中的优化。 |
| [^9] | [ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition](https://arxiv.org/abs/2402.15220) | ChunkAttention是一种前缀感知的自注意力模块，通过将键/值张量分解为较小的块并结构化到辅助前缀树中，实现了在运行时改善内存利用率的KV缓存，同时设计了两阶段分区算法以提高自注意力计算中的数据局部性。 |
| [^10] | [Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling](https://arxiv.org/abs/2402.10211) | 分层状态空间模型（HiSS）是一种针对连续序列到序列建模的技术，它利用堆叠的结构化状态空间模型来进行预测。 |
| [^11] | [DefInt: A Default-interventionist Framework for Efficient Reasoning with Hybrid Large Language Models](https://arxiv.org/abs/2402.02563) | DefInt提出了一种默认干预框架，通过默认使用较小规模的语言模型生成推理思路，然后通过反思推理干预解决复杂推理问题，从而提高混合大型语言模型的效率和准确性。 |
| [^12] | [KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM Does and Doesn't Know](https://arxiv.org/abs/2312.11539) | KGLens 是一个旨在衡量知识图与大型语言模型（LLMs）之间对齐程度的框架，帮助找出LLMs相对于知识图的知识不足之处。 |
| [^13] | [Revealing behavioral impact on mobility prediction networks through causal interventions](https://arxiv.org/abs/2311.11749) | 通过因果干预框架，评估移动因素对神经网络的影响，产生具有不同移动行为的位置序列，有助于理解和解释预测网络。 |
| [^14] | [Tiered Reward Functions: Specifying and Fast Learning of Desired Behavior](https://arxiv.org/abs/2212.03733) | 层级奖励函数提出了一种解决奖励设计问题的方法，能够保证诱导出根据偏好关系是帕累托最优的策略，并在多个环境中展示其快速学习的能力。 |
| [^15] | [MoE-Infinity: Activation-Aware Expert Offloading for Efficient MoE Serving.](http://arxiv.org/abs/2401.14361) | MoE-Infinity是一种成本高效的MoE服务系统，通过激活感知的专家卸载和缓存技术，显著降低了延迟，并提高了成本性能。 |
| [^16] | [Learning Backdoors for Mixed Integer Programs with Contrastive Learning.](http://arxiv.org/abs/2401.10467) | 本论文提出了使用对比学习方法来学习混合整数规划的后门，通过收集用于训练的后门并训练图注意力网络模型来预测后门，取得了比Gurobi和先前模型更好的性能改进。 |
| [^17] | [Modeling Latent Selection with Structural Causal Models.](http://arxiv.org/abs/2401.06925) | 本文介绍了一种在结构因果模型中对潜在选择进行建模的方法，并展示了它如何帮助进行因果推理任务，包括处理选择偏差。 |
| [^18] | [HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling for Long-Term Forecasting.](http://arxiv.org/abs/2401.05012) | HiMTM是一种面向长期预测的分层多尺度屏蔽时间序列建模方法，包括分层多尺度变压器，解耦的编码器-解码器，多尺度屏蔽重构和跨尺度注意微调等组成部分。 |
| [^19] | [SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image Classification.](http://arxiv.org/abs/2311.00048) | 本文提出了SC-MIL模型，通过利用稀疏字典学习来同时改进特征嵌入和实例相关性建模，从而提高全切片图像分类的性能。 |
| [^20] | [Temporally Disentangled Representation Learning under Unknown Nonstationarity.](http://arxiv.org/abs/2310.18615) | 本研究在非平稳情况下，探索了时间解缠表示学习的马尔可夫假设，并提出了一种无需辅助变量观测的方法来恢复独立的潜在分量。 |
| [^21] | [Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach.](http://arxiv.org/abs/2310.12428) | 这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。 |
| [^22] | [Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks.](http://arxiv.org/abs/2309.07716) | 本文介绍了向量值神经网络（V-nets）的广泛框架，并解释了它们与超复值神经网络以及传统神经网络的关系。 |
| [^23] | [End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC.](http://arxiv.org/abs/2308.01674) | 本论文提出了一种用于经济非线性MPC的Koopman模型的端到端强化学习方法，旨在实现控制性能和计算需求之间的平衡。 |
| [^24] | [Conformal prediction for frequency-severity modeling.](http://arxiv.org/abs/2307.13124) | 这个论文提出了一个非参数的模型无关框架，用于建立保险理赔的预测区间，并具有有限样本的统计保证，扩展了split conformal prediction技术到两阶段频率-严重性建模领域，并通过使用随机森林作为严重性模型，利用了袋外机制消除了校准集的需要，并实现了具有自适应宽度的预测区间的生成。 |
| [^25] | [Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image Segmentation with U-Net.](http://arxiv.org/abs/2307.09067) | 本论文评估了使用U-Net进行胎儿头超声图像分割的微调策略，通过使用轻量级的MobileNet作为编码器，并对有限的图像进行训练，可以获得与从头开始训练相媲美的分割性能，且优于其他策略。 |
| [^26] | [Technical Note: Defining and Quantifying AND-OR Interactions for Faithful and Concise Explanation of DNNs.](http://arxiv.org/abs/2304.13312) | 本文提出了一种通过量化输入变量之间的编码交互来准确且简明地解释深度神经网络(DNN)的推理逻辑的方法。针对此目的，作者提出了两种交互方式，即AND交互和OR交互，并利用它们设计出一系列技术来提高解释的简洁性，同时不会损害准确性。 |
| [^27] | [Application of Transformers for Nonlinear Channel Compensation in Optical Systems.](http://arxiv.org/abs/2304.13119) | 本文提出了一种利用Transformer进行光学系统非线性通道补偿的新方法，这种方法利用了Transformer的记忆关注能力和并行结构，实现了高效的非线性补偿。同时，作者还提出了一种物理学信息掩码，用于降低计算复杂度。 |
| [^28] | [Generalization in Neural Networks: A Broad Survey.](http://arxiv.org/abs/2209.01610) | 这篇论文总结了神经网络模型中不同抽象层次上的泛化问题及其方法，其中样本泛化已经取得了进展，但未来需要重点关注减少过拟合；分布泛化与领域泛化有相似之处，领域泛化方法可以应用于困难的样本或分布泛化。 |

# 详细

[^1]: Grappa--一个机器学习的分子力学势场

    Grappa -- A Machine Learned Molecular Mechanics Force Field

    [https://arxiv.org/abs/2404.00050](https://arxiv.org/abs/2404.00050)

    提出了一个用于预测分子力学参数的机器学习架构Grappa，通过图注意力神经网络和transformer提高了准确性，减少了计算开销，能在现有MD引擎中使用。

    

    模拟长时间尺度上的大分子系统需要既准确又高效的力场。近年来，E(3)等变神经网络解决了计算效率和力场准确性之间的张力，但其代价仍比传统的分子力学（MM）力场昂贵数个数量级。在这项研究中，我们提出了一种新颖的机器学习架构，利用图注意力神经网络和具有保持对称性的位置编码的transformer来预测分子图中的MM参数。由此产生的力场Grappa在准确性方面优于已建立的其他机器学习的MM力场，并且能以相同的计算效率在现有的分子动力学（MD）引擎如GROMACS和OpenMM中使用。它可以预测小分子、肽、RNA的能量和力--展示了其可扩展性到未知区域。

    arXiv:2404.00050v1 Announce Type: cross  Abstract: Simulating large molecular systems over long timescales requires force fields that are both accurate and efficient. In recent years, E(3) equivariant neural networks have lifted the tension between computational efficiency and accuracy of force fields, but they are still several orders of magnitude more expensive than classical molecular mechanics (MM) force fields.   Here, we propose a novel machine learning architecture to predict MM parameters from the molecular graph, employing a graph attentional neural network and a transformer with symmetry-preserving positional encoding. The resulting force field, Grappa, outperforms established and other machine-learned MM force fields in terms of accuracy at the same computational efficiency and can be used in existing Molecular Dynamics (MD) engines like GROMACS and OpenMM. It predicts energies and forces of small molecules, peptides, RNA and - showcasing its extensibility to uncharted regio
    
[^2]: 大型语言模型在心理健康领域的机会和风险

    The opportunities and risks of large language models in mental health

    [https://arxiv.org/abs/2403.14814](https://arxiv.org/abs/2403.14814)

    大型语言模型在心理健康领域有望提供新颖的解决方案，但应注意其应用可能带来的风险，并积极采取策略减轻这些风险。

    

    全球心理健康问题的发生率正在上升，人们越来越意识到现有的心理保健模式无法充分扩展以满足需求。随着大型语言模型（LLMs）的出现，人们对它们具有创造新颖、大规模解决方案以支持心理健康的承诺感到乐观。尽管它们还处于初期阶段，LLMs已被应用于与心理健康相关的任务。本综述总结了已有文献中关于利用LLMs提供心理健康教育、评估和干预的努力，并突出了每个领域中产生积极影响的关键机会。然后，我们强调了将LLMs应用于心理健康领域所伴随的风险，并鼓励采用策略来减轻这些风险。对于心理健康支持的迫切需求必须与负责任的心理健康LLMs的开发、测试和部署相平衡。特别关键的是确保心理健康...

    arXiv:2403.14814v1 Announce Type: cross  Abstract: Global rates of mental health concerns are rising and there is increasing realization that existing models of mental healthcare will not adequately expand to meet the demand. With the emergence of large language models (LLMs) has come great optimism regarding their promise to create novel, large-scale solutions to support mental health. Despite their nascence, LLMs have already been applied to mental health-related tasks. In this review, we summarize the extant literature on efforts to use LLMs to provide mental health education, assessment, and intervention and highlight key opportunities for positive impact in each area. We then highlight risks associated with LLMs application to mental health and encourage adoption of strategies to mitigate these risks. The urgent need for mental health support must be balanced with responsible development, testing, and deployment of mental health LLMs. Especially critical is ensuring that mental he
    
[^3]: 一种用于多模态推荐的对齐和训练框架

    An Aligning and Training Framework for Multimodal Recommendations

    [https://arxiv.org/abs/2403.12384](https://arxiv.org/abs/2403.12384)

    提出了一种名为AlignRec的对齐和训练框架，用于解决多模态推荐中的不对齐问题，通过将推荐目标分解为三个对齐部分，实现内容内部对齐、内容与分类ID之间的对齐以及用户和项目之间的对齐。

    

    随着多媒体应用的发展，多模态推荐正在发挥着重要作用，因为它们可以利用超越用户交互的丰富上下文。现有方法主要将多模态信息视为辅助，用于帮助学习ID特征；然而，多模态内容特征和ID特征之间存在语义差距，直接将多模态信息作为辅助使用会导致用户和项目表示的不对齐。本文首先系统地研究了多模态推荐中的不对齐问题，并提出了一种名为AlignRec的解决方案。在AlignRec中，推荐目标被分解为三个对齐部分，即内容内部对齐，内容与分类ID之间的对齐以及用户和项目之间的对齐。每个对齐部分都由特定的目标函数来表征，并整合到我们的多模态推荐中。

    arXiv:2403.12384v1 Announce Type: cross  Abstract: With the development of multimedia applications, multimodal recommendations are playing an essential role, as they can leverage rich contexts beyond user interactions. Existing methods mainly regard multimodal information as an auxiliary, using them to help learn ID features; however, there exist semantic gaps among multimodal content features and ID features, for which directly using multimodal information as an auxiliary would lead to misalignment in representations of users and items. In this paper, we first systematically investigate the misalignment issue in multimodal recommendations, and propose a solution named AlignRec. In AlignRec, the recommendation objective is decomposed into three alignments, namely alignment within contents, alignment between content and categorical ID, and alignment between users and items. Each alignment is characterized by a specific objective function and is integrated into our multimodal recommendat
    
[^4]: 基于注意力的多源领域自适应目标检测的类别条件对齐

    Attention-based Class-Conditioned Alignment for Multi-Source Domain Adaptive Object Detection

    [https://arxiv.org/abs/2403.09918](https://arxiv.org/abs/2403.09918)

    提出了一种基于注意力的类别条件对齐方案，用于多源领域自适应目标检测，在跨领域对齐每个对象类别的实例。

    

    目标检测（OD）的领域自适应方法致力于通过促进源域和目标域之间的特征对齐来缓解分布转移的影响。多源领域自适应（MSDA）允许利用多个带注释的源数据集和未标记的目标数据来提高检测模型的准确性和鲁棒性。大多数最先进的OD MSDA方法以一种与类别无关的方式执行特征对齐。最近提出的基于原型的方法提出了一种按类别对齐的方法，但由于嘈杂的伪标签而导致错误积累，这可能会对不平衡数据的自适应产生负面影响。为克服这些限制，我们提出了一种基于注意力的类别条件对齐方案，用于MSDA，该方案在跨领域对齐每个对象类别的实例。

    arXiv:2403.09918v1 Announce Type: cross  Abstract: Domain adaptation methods for object detection (OD) strive to mitigate the impact of distribution shifts by promoting feature alignment across source and target domains. Multi-source domain adaptation (MSDA) allows leveraging multiple annotated source datasets, and unlabeled target data to improve the accuracy and robustness of the detection model. Most state-of-the-art MSDA methods for OD perform feature alignment in a class-agnostic manner. This is challenging since the objects have unique modal information due to variations in object appearance across domains. A recent prototype-based approach proposed a class-wise alignment, yet it suffers from error accumulation due to noisy pseudo-labels which can negatively affect adaptation with imbalanced data. To overcome these limitations, we propose an attention-based class-conditioned alignment scheme for MSDA that aligns instances of each object category across domains. In particular, an 
    
[^5]: 《基于演员评论者物理信息神经李雅普诺夫控制》

    Actor-Critic Physics-informed Neural Lyapunov Control

    [https://arxiv.org/abs/2403.08448](https://arxiv.org/abs/2403.08448)

    提出了一种新方法，通过使用祖博夫的偏微分方程（PDE）来训练神经网络控制器，以及对应的李雅普诺夫证书，以最大化区域吸引力，并尊重激励约束。

    

    设计具有可证保证的稳定化任务控制策略是非线性控制中的一个长期问题。关键的性能指标是产生区域吸引力的大小，这基本上充当了封闭环系统对不确定性的弹性“边界”。本文提出了一种新方法，用于训练一个稳定的神经网络控制器以及其对应的李雅普诺夫证书，旨在最大化产生的区域吸引力，同时尊重激励约束。我们方法的关键之处在于使用祖博夫的偏微分方程（PDE），该方程精确地表征了给定控制策略的真实区域吸引力。我们的框架遵循演员评论者模式，我们在改进控制策略（演员）和学习祖博夫函数（评论者）之间交替进行。最后，我们通过调用SMT求解器计算出最大的可证区域吸引力。

    arXiv:2403.08448v1 Announce Type: new  Abstract: Designing control policies for stabilization tasks with provable guarantees is a long-standing problem in nonlinear control. A crucial performance metric is the size of the resulting region of attraction, which essentially serves as a robustness "margin" of the closed-loop system against uncertainties. In this paper, we propose a new method to train a stabilizing neural network controller along with its corresponding Lyapunov certificate, aiming to maximize the resulting region of attraction while respecting the actuation constraints. Crucial to our approach is the use of Zubov's Partial Differential Equation (PDE), which precisely characterizes the true region of attraction of a given control policy. Our framework follows an actor-critic pattern where we alternate between improving the control policy (actor) and learning a Zubov function (critic). Finally, we compute the largest certifiable region of attraction by invoking an SMT solver
    
[^6]: 在批强化学习中，通过切换损失函数来降低成本

    Switching the Loss Reduces the Cost in Batch Reinforcement Learning

    [https://arxiv.org/abs/2403.05385](https://arxiv.org/abs/2403.05385)

    使用对数损失函数来训练适合的Q迭代的批强化学习方法，在实现目标时不产生成本的问题中，其样本数量需求与最优策略的累积成本成比例，能够提供与最优可达成本成比例的“小成本”界限，并在实验中验证在那些最优策略可靠实现目标的问题中，FQI-LOG比使用平方损失训练的FQI使用更少的样本。

    

    我们提出了一种使用对数损失（FQI-LOG）来训练适合的Q迭代的批强化学习（RL）方法。我们展示了使用FQI-LOG学习接近最优策略所需的样本数量与最优策略的累积成本成比例，对于那些通过最优行为实现目标且不产生成本的问题，最优策略的累积成本为零。通过这种方式，我们提供了一种在批RL中证明具有与最优可达成本成比例的“小成本”界限的一般框架。此外，我们从经验上验证，FQI-LOG在那些最优策略可靠地实现目标的问题上使用的样本比使用平方损失训练的FQI要少。

    arXiv:2403.05385v1 Announce Type: new  Abstract: We propose training fitted Q-iteration with log-loss (FQI-LOG) for batch reinforcement learning (RL). We show that the number of samples needed to learn a near-optimal policy with FQI-LOG scales with the accumulated cost of the optimal policy, which is zero in problems where acting optimally achieves the goal and incurs no cost. In doing so, we provide a general framework for proving $\textit{small-cost}$ bounds, i.e. bounds that scale with the optimal achievable cost, in batch RL. Moreover, we empirically verify that FQI-LOG uses fewer samples than FQI trained with squared loss on problems where the optimal policy reliably achieves the goal.
    
[^7]: 通知元学习

    Informed Meta-Learning

    [https://arxiv.org/abs/2402.16105](https://arxiv.org/abs/2402.16105)

    该研究提出了通知元学习这一新范式，旨在通过人类和机器之间的跨任务知识共享，提高数据效率和抵御观测噪声。

    

    在真实应用中盛行的嘈杂和低数据情况下，机器学习中一个突出的挑战在于有效地融合促进数据效率和稳健性的归纳偏差。元学习和通知机器学习是两种将先验知识纳入机器学习流程的方法。前者依赖于一种纯数据驱动的先验来源，而后者受专家知识的形式化表示引导。本文介绍了一种新颖的混合范式，通知元学习，旨在实现人类和机器之间跨任务知识共享的互补性。我们建立了通知元学习的基本组成部分，并提出了这一框架的具体实例--通知神经过程。通过一系列说明性和更大规模的实验，我们展示了通知元学习在提高数据效率和抵御观测噪声方面的潜在优势。

    arXiv:2402.16105v1 Announce Type: new  Abstract: In noisy and low-data regimes prevalent in real-world applications, an outstanding challenge of machine learning lies in effectively incorporating inductive biases that promote data efficiency and robustness. Meta-learning and informed ML stand out as two approaches for incorporating prior knowledge into the ML pipeline. While the former relies on a purely data-driven source of priors, the latter is guided by a formal representation of expert knowledge. This paper introduces a novel hybrid paradigm, informed meta-learning, seeking complementarity in cross-task knowledge sharing of humans and machines. We establish the foundational components of informed meta-learning and present a concrete instantiation of this framework--the Informed Neural Process. Through a series of illustrative and larger-scale experiments, we demonstrate the potential benefits of informed meta-learning in improving data efficiency and robustness to observational no
    
[^8]: 抓取、观察和放置：具有策略结构先验的高效未知物体重新排列

    Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior

    [https://arxiv.org/abs/2402.15402](https://arxiv.org/abs/2402.15402)

    该论文提出了一种具有策略结构先验的高效未知物体重新排列系统，通过内外环的学习，实现了抓取、观察和放置在感知噪声中的优化。

    

    我们关注未知物体重新排列任务，即机器人应重新配置物体到由RGB-D图像指定的期望目标配置中。最近的研究通过整合基于学习的感知模块来探索未知物体重新排列系统。然而，它们对感知误差敏感，并且较少关注任务级性能。本文旨在开发一个有效的系统，用于在感知噪声中重新排列未知物体。我们在理论上揭示了噪声感知如何以分离的方式影响抓取和放置，并展示这样的分离结构不容易改善任务的最优性。我们提出了具有分离结构作为先验的GSP，一个双环系统。对于内环，我们学习主动观察策略以提高放置的感知。对于外环，我们学习一个抓取策略，意识到物体匹配和抓取能力。

    arXiv:2402.15402v1 Announce Type: cross  Abstract: We focus on the task of unknown object rearrangement, where a robot is supposed to re-configure the objects into a desired goal configuration specified by an RGB-D image. Recent works explore unknown object rearrangement systems by incorporating learning-based perception modules. However, they are sensitive to perception error, and pay less attention to task-level performance. In this paper, we aim to develop an effective system for unknown object rearrangement amidst perception noise. We theoretically reveal the noisy perception impacts grasp and place in a decoupled way, and show such a decoupled structure is non-trivial to improve task optimality. We propose GSP, a dual-loop system with the decoupled structure as prior. For the inner loop, we learn an active seeing policy for self-confident object matching to improve the perception of place. For the outer loop, we learn a grasp policy aware of object matching and grasp capability gu
    
[^9]: ChunkAttention: 具有前缀感知KV缓存和两阶段分区的高效自注意力

    ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition

    [https://arxiv.org/abs/2402.15220](https://arxiv.org/abs/2402.15220)

    ChunkAttention是一种前缀感知的自注意力模块，通过将键/值张量分解为较小的块并结构化到辅助前缀树中，实现了在运行时改善内存利用率的KV缓存，同时设计了两阶段分区算法以提高自注意力计算中的数据局部性。

    

    自注意力是大型语言模型（LLMs）的重要组成部分，但对于长序列来说是推理延迟的一个显著来源。在多租户LLMs服务场景中，通过利用多个LLM请求在前缀中共享系统提示的概率，可以优化自注意力的计算和内存操作成本。本文介绍了ChunkAttention，一种具有前缀感知的自注意力模块，可以在运行时检测多个请求之间匹配的提示前缀，并共享它们的键/值张量以改进KV缓存的内存利用率。这是通过将整体键/值张量分解为较小的块，并将它们结构化到辅助前缀树中来实现的。因此，在基于前缀树的KV缓存之上，我们设计了一个高效的自注意力内核，其中实现了两阶段分区算法，以改善自注意力计算中的数据局部性。

    arXiv:2402.15220v1 Announce Type: cross  Abstract: Self-attention is an essential component of large language models(LLMs) but a significant source of inference latency for long sequences. In multi-tenant LLMs serving scenarios, the compute and memory operation cost of self-attention can be optimized by using the probability that multiple LLM requests have shared system prompts in prefixes. In this paper, we introduce ChunkAttention, a prefix-aware self-attention module that can detect matching prompt prefixes across multiple requests and share their key/value tensors in memory at runtime to improve the memory utilization of KV cache. This is achieved by breaking monolithic key/value tensors into smaller chunks and structuring them into the auxiliary prefix tree. Consequently, on top of the prefix-tree based KV cache, we design an efficient self-attention kernel, where a two-phase partition algorithm is implemented to improve the data locality during self-attention computation in the p
    
[^10]: 针对连续序列到序列建模的分层状态空间模型

    Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling

    [https://arxiv.org/abs/2402.10211](https://arxiv.org/abs/2402.10211)

    分层状态空间模型（HiSS）是一种针对连续序列到序列建模的技术，它利用堆叠的结构化状态空间模型来进行预测。

    

    arXiv:2402.10211v1 公告类型：新的 摘要：从原始感知数据的序列推理是从医疗设备到机器人领域中普遍存在的问题。这些问题常常涉及使用长序列的原始传感器数据（例如磁力计，压阻器）来预测理想的物理量序列（例如力量，惯性测量）。虽然经典方法对于局部线性预测问题非常有效，但在使用实际传感器时往往表现不佳。这些传感器通常是非线性的，受到外界变量（例如振动）的影响，并且表现出数据相关漂移。对于许多问题来说，预测任务受到稀缺标记数据集的限制，因为获取地面真实标签需要昂贵的设备。在这项工作中，我们提出了分层状态空间模型（HiSS），这是一种概念上简单、全新的连续顺序预测技术。HiSS将结构化的状态空间模型堆叠在一起，以创建一个暂定的预测模型。

    arXiv:2402.10211v1 Announce Type: new  Abstract: Reasoning from sequences of raw sensory data is a ubiquitous problem across fields ranging from medical devices to robotics. These problems often involve using long sequences of raw sensor data (e.g. magnetometers, piezoresistors) to predict sequences of desirable physical quantities (e.g. force, inertial measurements). While classical approaches are powerful for locally-linear prediction problems, they often fall short when using real-world sensors. These sensors are typically non-linear, are affected by extraneous variables (e.g. vibration), and exhibit data-dependent drift. For many problems, the prediction task is exacerbated by small labeled datasets since obtaining ground-truth labels requires expensive equipment. In this work, we present Hierarchical State-Space Models (HiSS), a conceptually simple, new technique for continuous sequential prediction. HiSS stacks structured state-space models on top of each other to create a tempor
    
[^11]: DefInt：一种用于高效处理混合大型语言模型推理的默认干预框架

    DefInt: A Default-interventionist Framework for Efficient Reasoning with Hybrid Large Language Models

    [https://arxiv.org/abs/2402.02563](https://arxiv.org/abs/2402.02563)

    DefInt提出了一种默认干预框架，通过默认使用较小规模的语言模型生成推理思路，然后通过反思推理干预解决复杂推理问题，从而提高混合大型语言模型的效率和准确性。

    

    大型语言模型（LLMs）在各种任务中展示出令人印象深刻的新能力，但在处理复杂推理问题方面仍面临挑战。以往的研究如连锁推理（CoT）和思维树（ToT）主要关注提高准确性，但忽视了不断增加的标记成本，这对于具有巨大解空间的开放性实际任务来说可能特别问题。受人类认知的双过程理论的启发，我们提出了一种默认干预框架（DefInt），以释放混合LLMs的协同潜力。默认情况下，DefInt使用较小规模的语言模型生成低成本的推理思路，类似于“系统1”产生的快速直觉。如果这些直觉被认为低置信度，则DefInt将调用放大的语言模型的反思推理作为“系统2”的干预，可以覆盖默认思考并纠正推理过程。实验在五个实际数据集上展示了DefInt论文中的有效性。

    Large language models (LLMs) have shown impressive emergent abilities in a wide range of tasks, but still face challenges in handling complex reasoning problems. Previous works like chain-of-thought (CoT) and tree-of-thoughts(ToT) have predominately focused on enhancing accuracy, but overlook the rapidly increasing token cost, which could be particularly problematic for open-ended real-world tasks with huge solution spaces. Motivated by the dual process theory of human cognition, we propose a Default-Interventionist framework (DefInt) to unleash the synergistic potential of hybrid LLMs. By default, DefInt uses smaller-scale language models to generate low-cost reasoning thoughts, which resembles the fast intuitions produced by System 1. If the intuitions are considered with low confidence, DefInt will invoke the reflective reasoning of scaled-up language models as the intervention of System 2, which can override the default thoughts and rectify the reasoning process. Experiments on fiv
    
[^12]: KGLens：一个参数化知识图解决方案，用于评估LLM知道和不知道的内容

    KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM Does and Doesn't Know

    [https://arxiv.org/abs/2312.11539](https://arxiv.org/abs/2312.11539)

    KGLens 是一个旨在衡量知识图与大型语言模型（LLMs）之间对齐程度的框架，帮助找出LLMs相对于知识图的知识不足之处。

    

    衡量知识图（KG）与大型语言模型（LLMs）之间的对齐程度是评估事实性并识别LLMs的知识盲点的有效方法。然而，这种方法面临两个主要挑战，包括将KGs转化为自然语言和高效评估这些广泛且复杂的结构。在本文中，我们提出了KGLens--一个旨在衡量KGs和LLMs之间对齐程度，并找出LLMs相对于KGs的知识缺陷的新颖框架。KGLens具有一个图引导的问题生成器，用于将KGs转化为自然语言，以及一个基于参数化KG结构的精心设计的采样策略，以加快KG的遍历。我们使用来自Wikidata的三个领域特定KG进行实验，这些KG包括超过19,000条边，700个关系和21,000个实体。我们跨越8个LLMs的分析表明，KGLens不仅

    arXiv:2312.11539v2 Announce Type: replace  Abstract: Measuring the alignment between a Knowledge Graph (KG) and Large Language Models (LLMs) is an effective method to assess the factualness and identify the knowledge blind spots of LLMs. However, this approach encounters two primary challenges including the translation of KGs into natural language and the efficient evaluation of these extensive and complex structures. In this paper, we present KGLens--a novel framework aimed at measuring the alignment between KGs and LLMs, and pinpointing the LLMs' knowledge deficiencies relative to KGs. KGLens features a graph-guided question generator for converting KGs into natural language, along with a carefully designed sampling strategy based on parameterized KG structure to expedite KG traversal. We conducted experiments using three domain-specific KGs from Wikidata, which comprise over 19,000 edges, 700 relations, and 21,000 entities. Our analysis across eight LLMs reveals that KGLens not only
    
[^13]: 通过因果干预揭示行为对移动预测网络的影响

    Revealing behavioral impact on mobility prediction networks through causal interventions

    [https://arxiv.org/abs/2311.11749](https://arxiv.org/abs/2311.11749)

    通过因果干预框架，评估移动因素对神经网络的影响，产生具有不同移动行为的位置序列，有助于理解和解释预测网络。

    

    深度神经网络在移动性预测任务中被越来越广泛地使用，然而它们复杂的内部运作方式给可解释性带来挑战，特别是在理解各种移动行为如何影响预测方面。本研究引入了一个因果干预框架，评估与下一个位置预测相关的移动因素对神经网络的影响 -- 这是一项专注于预测个体即将到达位置的任务。为了实现这一目标，我们使用个体移动模型生成合成位置访问序列，并通过干预它们的数据生成过程来控制行为动态。我们使用移动指标评估干预位置序列，并将其输入到训练良好的网络中以分析性能变化。结果表明，产生具有不同移动行为的位置序列的有效性，从而促进了预测网络的理解和解释。

    arXiv:2311.11749v2 Announce Type: replace-cross  Abstract: Deep neural networks are increasingly utilized in mobility prediction tasks, yet their intricate internal workings pose challenges for interpretability, especially in comprehending how various aspects of mobility behavior affect predictions. This study introduces a causal intervention framework to assess the impact of mobility-related factors on neural networks designed for next location prediction -- a task focusing on predicting the immediate next location of an individual. To achieve this, we employ individual mobility models to generate synthetic location visit sequences and control behavior dynamics by intervening in their data generation process. We evaluate the interventional location sequences using mobility metrics and input them into well-trained networks to analyze performance variations. The results demonstrate the effectiveness in producing location sequences with distinct mobility behaviors, thereby facilitating t
    
[^14]: 层级奖励函数：规定和快速学习所需行为

    Tiered Reward Functions: Specifying and Fast Learning of Desired Behavior

    [https://arxiv.org/abs/2212.03733](https://arxiv.org/abs/2212.03733)

    层级奖励函数提出了一种解决奖励设计问题的方法，能够保证诱导出根据偏好关系是帕累托最优的策略，并在多个环境中展示其快速学习的能力。

    

    强化学习代理通过与环境的交互来最大化奖励信号。在学习过程中，我们作为人类的任务是设计奖励函数，以表达所期望的行为，并使代理能够迅速学习这种行为。在这项工作中，我们考虑了任务中达到良好状态和避免不良状态的奖励设计问题。首先，我们提出了一种严格的策略空间的部分排序，以解决行为偏好中的权衡。我们更倾向于能更快速地到达良好状态并以更高的概率到达，同时能更长时间地避免不良状态的策略。接下来，我们介绍了层级奖励，一类与环境无关的奖励函数，并表明它保证诱导出根据我们的偏好关系是帕累托最优的策略。最后，我们证明了层级奖励可以通过在多个环境上使用多个表格进行评估，从而实现快速学习。

    arXiv:2212.03733v2 Announce Type: replace-cross  Abstract: Reinforcement-learning agents seek to maximize a reward signal through environmental interactions. As humans, our job in the learning process is to design reward functions to express desired behavior and enable the agent to learn such behavior swiftly. In this work, we consider the reward-design problem in tasks formulated as reaching desirable states and avoiding undesirable states. To start, we propose a strict partial ordering of the policy space to resolve trade-offs in behavior preference. We prefer policies that reach the good states faster and with higher probability while avoiding the bad states longer. Next, we introduce Tiered Reward, a class of environment-independent reward functions and show it is guaranteed to induce policies that are Pareto-optimal according to our preference relation. Finally, we demonstrate that Tiered Reward can lead to fast learning by evaluating on several environments using multiple tabular
    
[^15]: MoE-Infinity：用于高效MoE服务的激活感知专家卸载系统

    MoE-Infinity: Activation-Aware Expert Offloading for Efficient MoE Serving. (arXiv:2401.14361v1 [cs.LG])

    [http://arxiv.org/abs/2401.14361](http://arxiv.org/abs/2401.14361)

    MoE-Infinity是一种成本高效的MoE服务系统，通过激活感知的专家卸载和缓存技术，显著降低了延迟，并提高了成本性能。

    

    本文介绍了MoE-Infinity，一种成本高效的专家混合(MoE)服务系统，实现了激活感知的专家卸载。MoE-Infinity具有序列级专家激活追踪的特点，这是一种擅长识别稀疏激活并捕捉MoE推理的时间局部性的新方法。通过分析这些追踪，MoE-Infinity执行了新颖的激活感知专家预取和缓存，大大降低了通常与卸载专家相关的延迟开销，提高了成本性能。在一个集群中进行的大量实验表明，MoE-Infinity优于许多现有的系统和方法，对于各种MoEs，将延迟降低了420倍，将部署成本降低了8倍以上。MoE-Infinity的源代码可在https://github.com/TorchMoE/MoE-Infinity公开获取。

    This paper presents MoE-Infinity, a cost-efficient mixture-of-expert (MoE) serving system that realizes activation-aware expert offloading. MoE-Infinity features sequence-level expert activation tracing, a new approach adept at identifying sparse activations and capturing the temporal locality of MoE inference. By analyzing these traces, MoE-Infinity performs novel activation-aware expert prefetching and caching, substantially reducing the latency overheads usually associated with offloading experts for improved cost performance. Extensive experiments in a cluster show that MoE-Infinity outperforms numerous existing systems and approaches, reducing latency by 4 20X and decreasing deployment costs by over 8X for various MoEs. MoE-Infinity's source code is publicly available at https://github.com/TorchMoE/MoE-Infinity
    
[^16]: 使用对比学习学习混合整数规划的后门

    Learning Backdoors for Mixed Integer Programs with Contrastive Learning. (arXiv:2401.10467v1 [cs.AI])

    [http://arxiv.org/abs/2401.10467](http://arxiv.org/abs/2401.10467)

    本论文提出了使用对比学习方法来学习混合整数规划的后门，通过收集用于训练的后门并训练图注意力网络模型来预测后门，取得了比Gurobi和先前模型更好的性能改进。

    

    许多现实世界中的问题可以有效地建模为混合整数规划（MIP）并使用分支定界方法进行求解。先前的研究表明存在MIP后门，即一小组变量，如果优先在可能的情况下在它们上进行分支，则可以加快运行时间。然而，寻找能提高运行时间的高质量后门仍是一个未解决的问题。先前的工作通过排名学习估计随机采样的后门相对求解器速度，然后决定是否使用。本文中，我们利用蒙特卡洛树搜索方法收集用于训练的后门，而不是依赖随机采样，并且采用对比学习框架训练图注意力网络模型来预测后门。我们的方法在四个常见的MIP问题领域上进行评估，表现出对比Gurobi和先前模型的性能改进。

    Many real-world problems can be efficiently modeled as Mixed Integer Programs (MIPs) and solved with the Branch-and-Bound method. Prior work has shown the existence of MIP backdoors, small sets of variables such that prioritizing branching on them when possible leads to faster running times. However, finding high-quality backdoors that improve running times remains an open question. Previous work learns to estimate the relative solver speed of randomly sampled backdoors through ranking and then decide whether to use it. In this paper, we utilize the Monte-Carlo tree search method to collect backdoors for training, rather than relying on random sampling, and adapt a contrastive learning framework to train a Graph Attention Network model to predict backdoors. Our method, evaluated on four common MIP problem domains, demonstrates performance improvements over both Gurobi and previous models.
    
[^17]: 用结构因果模型对潜在选择进行建模

    Modeling Latent Selection with Structural Causal Models. (arXiv:2401.06925v1 [cs.AI])

    [http://arxiv.org/abs/2401.06925](http://arxiv.org/abs/2401.06925)

    本文介绍了一种在结构因果模型中对潜在选择进行建模的方法，并展示了它如何帮助进行因果推理任务，包括处理选择偏差。

    

    选择偏倚在现实世界的数据中是普遍存在的，如果不正确处理可能导致误导性结果。我们引入了对结构因果模型（SCMs）进行条件操作的方法，以从因果的角度对潜在选择进行建模。我们展示了条件操作将具有明确潜在选择机制的SCM转换为没有此类选择机制的SCM，这在一定程度上编码了根据原始SCM选择的亚总体的因果语义。此外，我们还展示了该条件操作保持SCMs的简洁性，无环性和线性性，并与边际化操作相符合。由于这些特性与边际化和干预结合起来，条件操作为在潜在细节已经去除的因果模型中进行因果推理任务提供了一个有价值的工具。我们通过例子演示了如何将因果推断的经典结果推广以包括选择偏倚。

    Selection bias is ubiquitous in real-world data, and can lead to misleading results if not dealt with properly. We introduce a conditioning operation on Structural Causal Models (SCMs) to model latent selection from a causal perspective. We show that the conditioning operation transforms an SCM with the presence of an explicit latent selection mechanism into an SCM without such selection mechanism, which partially encodes the causal semantics of the selected subpopulation according to the original SCM. Furthermore, we show that this conditioning operation preserves the simplicity, acyclicity, and linearity of SCMs, and commutes with marginalization. Thanks to these properties, combined with marginalization and intervention, the conditioning operation offers a valuable tool for conducting causal reasoning tasks within causal models where latent details have been abstracted away. We demonstrate by example how classical results of causal inference can be generalized to include selection b
    
[^18]: HiMTM: 面向长期预测的分层多尺度屏蔽时间序列建模

    HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling for Long-Term Forecasting. (arXiv:2401.05012v1 [cs.LG])

    [http://arxiv.org/abs/2401.05012](http://arxiv.org/abs/2401.05012)

    HiMTM是一种面向长期预测的分层多尺度屏蔽时间序列建模方法，包括分层多尺度变压器，解耦的编码器-解码器，多尺度屏蔽重构和跨尺度注意微调等组成部分。

    

    在现实世界中，时间序列预测是至关重要且具有挑战性的。近期对于时间序列基础模型的兴趣激增，这些模型适应各种不同的下游任务，这是值得注意的。然而，现有方法往往忽视了时间序列的多尺度性质，这是进行精确预测所必需的。为了弥合这一差距，我们提出了HiMTM，一种专门针对长期预测设计的分层多尺度屏蔽时间序列建模方法。具体包括四个主要组成部分：（1）分层多尺度变压器（HMT）捕捉不同尺度的时间信息；（2）解耦的编码器-解码器（DED）让编码器专注于特征提取，而解码器专注于假设任务；（3）多尺度屏蔽重构（MMR）为预训练提供多阶段的监督信号；（4）跨尺度注意微调（CSA-FT）以捕捉不同尺度之间的依赖性进行预测。综上所述，这些部件共同构成了模型。

    Time series forecasting is crucial and challenging in the real world. The recent surge in interest regarding time series foundation models, which cater to a diverse array of downstream tasks, is noteworthy. However, existing methods often overlook the multi-scale nature of time series, an aspect crucial for precise forecasting. To bridge this gap, we propose HiMTM, a hierarchical multi-scale masked time series modeling method designed for long-term forecasting. Specifically, it comprises four integral components: (1) hierarchical multi-scale transformer (HMT) to capture temporal information at different scales; (2) decoupled encoder-decoder (DED) forces the encoder to focus on feature extraction, while the decoder to focus on pretext tasks; (3) multi-scale masked reconstruction (MMR) provides multi-stage supervision signals for pre-training; (4) cross-scale attention fine-tuning (CSA-FT) to capture dependencies between different scales for forecasting. Collectively, these components en
    
[^19]: SC-MIL: 用于全切片图像分类的稀疏编码多实例学习

    SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image Classification. (arXiv:2311.00048v1 [cs.CV])

    [http://arxiv.org/abs/2311.00048](http://arxiv.org/abs/2311.00048)

    本文提出了SC-MIL模型，通过利用稀疏字典学习来同时改进特征嵌入和实例相关性建模，从而提高全切片图像分类的性能。

    

    多实例学习（MIL）在弱监督的全切片图像（WSI）分类中被广泛使用。典型的MIL方法包括特征嵌入部分，通过预训练的特征提取器将实例嵌入到特征中，以及MIL聚合器，将实例嵌入组合成预测结果。目前的重点是通过自监督预训练来改进这些部分，并单独建模实例之间的相关性。在本文中，我们提出了一种稀疏编码的MIL（SC-MIL），同时通过利用稀疏字典学习来解决这两个方面。稀疏字典学习通过将实例表示为过完备字典中原子的稀疏线性组合来捕捉实例之间的相似性。此外，引入稀疏性可以通过抑制不相关的实例而保留最相关的实例，从而增强实例的特征嵌入。为了改善传统的特征嵌入和实例之间的相关性建模方法，we proposed a sparsely coded MIL.

    Multiple Instance Learning (MIL) has been widely used in weakly supervised whole slide image (WSI) classification. Typical MIL methods include a feature embedding part that embeds the instances into features via a pre-trained feature extractor and the MIL aggregator that combines instance embeddings into predictions. The current focus has been directed toward improving these parts by refining the feature embeddings through self-supervised pre-training and modeling the correlations between instances separately. In this paper, we proposed a sparsely coded MIL (SC-MIL) that addresses those two aspects at the same time by leveraging sparse dictionary learning. The sparse dictionary learning captures the similarities of instances by expressing them as a sparse linear combination of atoms in an over-complete dictionary. In addition, imposing sparsity help enhance the instance feature embeddings by suppressing irrelevant instances while retaining the most relevant ones. To make the convention
    
[^20]: 未知非平稳情况下的时间解缠表示学习

    Temporally Disentangled Representation Learning under Unknown Nonstationarity. (arXiv:2310.18615v1 [cs.LG])

    [http://arxiv.org/abs/2310.18615](http://arxiv.org/abs/2310.18615)

    本研究在非平稳情况下，探索了时间解缠表示学习的马尔可夫假设，并提出了一种无需辅助变量观测的方法来恢复独立的潜在分量。

    

    在具有时延潜在因果影响的时序数据的无监督因果表示学习中，通过利用时间结构在稳态情况下已经建立了有关因果相关潜在变量解缠的强可识别性结果。然而，在非平稳情况下，现有研究只部分解决了这个问题，要么利用观测到的辅助变量（如类别标签和/或域索引）作为辅助信息，要么假设简化的潜在因果动力学。这两者限制了方法的适用范围。在本研究中，我们进一步探索了非平稳环境中时间延迟相关过程的马尔可夫假设，并证明了在温和条件下，可以在不观察辅助变量的情况下从非线性混合中恢复独立的潜在分量，但可能存在排列和分量级转换。然后，我们引入了一个有原则的估计框架NCTRL来实现。

    In unsupervised causal representation learning for sequential data with time-delayed latent causal influences, strong identifiability results for the disentanglement of causally-related latent variables have been established in stationary settings by leveraging temporal structure. However, in nonstationary setting, existing work only partially addressed the problem by either utilizing observed auxiliary variables (e.g., class labels and/or domain indexes) as side information or assuming simplified latent causal dynamics. Both constrain the method to a limited range of scenarios. In this study, we further explored the Markov Assumption under time-delayed causally related process in nonstationary setting and showed that under mild conditions, the independent latent components can be recovered from their nonlinear mixture up to a permutation and a component-wise transformation, without the observation of auxiliary variables. We then introduce NCTRL, a principled estimation framework, to r
    
[^21]: 实现随机森林的局部可解释性增强：基于邻近性的方法

    Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])

    [http://arxiv.org/abs/2310.12428](http://arxiv.org/abs/2310.12428)

    这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。

    

    我们提出一种新的方法来解释随机森林（RF）模型的样本外性能，利用了任何RF都可以被表述为自适应加权K最近邻（KNN）模型的事实。具体而言，我们利用RF在特征空间中学到的点之间的邻近性，将随机森林的预测重写为训练数据点目标标签的加权平均值。这种线性性质有助于在训练集观测中为任何模型预测生成属性，从而为RF预测提供了局部的解释性，补充了SHAP等已有方法，这些方法则为特征空间维度上的模型预测生成属性。我们在训练于美国公司债券交易数据的债券定价模型中演示了这种方法，并将其与各种现有的模型解释方法进行了比较。

    We initiate a novel approach to explain the out of sample performance of random forest (RF) models by exploiting the fact that any RF can be formulated as an adaptive weighted K nearest-neighbors model. Specifically, we use the proximity between points in the feature space learned by the RF to re-write random forest predictions exactly as a weighted average of the target labels of training data points. This linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established methods like SHAP, which instead generates attributions for a model prediction across dimensions of the feature space. We demonstrate this approach in the context of a bond pricing model trained on US corporate bond trades, and compare our approach to various existing approaches to model explainability.
    
[^22]: 理解向量值神经网络及其与实数和超复值神经网络的关系

    Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks. (arXiv:2309.07716v1 [cs.LG])

    [http://arxiv.org/abs/2309.07716](http://arxiv.org/abs/2309.07716)

    本文介绍了向量值神经网络（V-nets）的广泛框架，并解释了它们与超复值神经网络以及传统神经网络的关系。

    

    尽管深度学习模型在多维信号和图像处理方面有许多成功的应用，但大多数传统神经网络处理由（多维）实数数组表示的数据。特征通道之间的互相关通常被期望从训练数据中学习，这需要大量的参数和仔细的训练。相反，向量值神经网络被设计成处理向量数组，并自然地考虑特征通道之间的互相关。因此，它们通常具有更少的参数，通常比传统神经网络具有更强的训练能力。本文旨在提出一个广泛的向量值神经网络框架，称为V-nets。在这个背景下，超复值神经网络被视为具有额外代数属性的向量值模型。此外，本文解释了向量值神经网络与传统神经网络之间的关系。

    Despite the many successful applications of deep learning models for multidimensional signal and image processing, most traditional neural networks process data represented by (multidimensional) arrays of real numbers. The intercorrelation between feature channels is usually expected to be learned from the training data, requiring numerous parameters and careful training. In contrast, vector-valued neural networks are conceived to process arrays of vectors and naturally consider the intercorrelation between feature channels. Consequently, they usually have fewer parameters and often undergo more robust training than traditional neural networks. This paper aims to present a broad framework for vector-valued neural networks, referred to as V-nets. In this context, hypercomplex-valued neural networks are regarded as vector-valued models with additional algebraic properties. Furthermore, this paper explains the relationship between vector-valued and traditional neural networks. Precisely, 
    
[^23]: 经济非线性MPC的Koopman模型的端到端强化学习

    End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC. (arXiv:2308.01674v1 [cs.LG])

    [http://arxiv.org/abs/2308.01674](http://arxiv.org/abs/2308.01674)

    本论文提出了一种用于经济非线性MPC的Koopman模型的端到端强化学习方法，旨在实现控制性能和计算需求之间的平衡。

    

    （经济）非线性模型预测控制（（e）NMPC）需要在所有相关状态空间区域都具有足够准确性的动态系统模型。这些模型还必须计算成本足够低以确保实时可行性。基于数据驱动的替代机制模型可以用来减少（e）NMPC的计算负担；但是，这些模型通常通过系统辨识以在模拟样本上获得最大平均预测准确性进行训练，并作为实际（e）NMPC的一部分表现不佳。我们提出了一种用于实现最佳（e）NMPC性能的动态替代模型的端到端强化学习方法，从而得到具有控制性能和计算需求之间良好平衡的预测控制器。我们通过两个基于已建立的非线性连续搅拌反应器模型的应用来验证我们的方法。

    (Economic) nonlinear model predictive control ((e)NMPC) requires dynamic system models that are sufficiently accurate in all relevant state-space regions. These models must also be computationally cheap enough to ensure real-time tractability. Data-driven surrogate models for mechanistic models can be used to reduce the computational burden of (e)NMPC; however, such models are typically trained by system identification for maximum average prediction accuracy on simulation samples and perform suboptimally as part of actual (e)NMPC. We present a method for end-to-end reinforcement learning of dynamic surrogate models for optimal performance in (e)NMPC applications, resulting in predictive controllers that strike a favorable balance between control performance and computational demand. We validate our method on two applications derived from an established nonlinear continuous stirred-tank reactor model. We compare the controller performance to that of MPCs utilizing models trained by the 
    
[^24]: 频率-严重性建模的符合性预测

    Conformal prediction for frequency-severity modeling. (arXiv:2307.13124v1 [stat.ME])

    [http://arxiv.org/abs/2307.13124](http://arxiv.org/abs/2307.13124)

    这个论文提出了一个非参数的模型无关框架，用于建立保险理赔的预测区间，并具有有限样本的统计保证，扩展了split conformal prediction技术到两阶段频率-严重性建模领域，并通过使用随机森林作为严重性模型，利用了袋外机制消除了校准集的需要，并实现了具有自适应宽度的预测区间的生成。

    

    我们提出了一个非参数的模型无关框架，用于建立保险理赔的预测区间，并具有有限样本的统计保证，将分割符合性预测技术扩展到两阶段频率-严重性建模领域。通过模拟和真实数据集展示了该框架的有效性。当基础严重性模型是随机森林时，我们扩展了两阶段分割符合性预测过程，展示了如何利用袋外机制消除校准集的需要，并实现具有自适应宽度的预测区间的生成。

    We present a nonparametric model-agnostic framework for building prediction intervals of insurance claims, with finite sample statistical guarantees, extending the technique of split conformal prediction to the domain of two-stage frequency-severity modeling. The effectiveness of the framework is showcased with simulated and real datasets. When the underlying severity model is a random forest, we extend the two-stage split conformal prediction procedure, showing how the out-of-bag mechanism can be leveraged to eliminate the need for a calibration set and to enable the production of prediction intervals with adaptive width.
    
[^25]: 评估使用U-Net进行胎儿头超声图像分割中的微调策略

    Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image Segmentation with U-Net. (arXiv:2307.09067v1 [eess.IV])

    [http://arxiv.org/abs/2307.09067](http://arxiv.org/abs/2307.09067)

    本论文评估了使用U-Net进行胎儿头超声图像分割的微调策略，通过使用轻量级的MobileNet作为编码器，并对有限的图像进行训练，可以获得与从头开始训练相媲美的分割性能，且优于其他策略。

    

    胎儿头分割是测量妊娠期间胎儿头围(HC)的关键步骤，是监测胎儿生长的重要生物测定学。然而，手动生成生物学测定是耗时且结果不一致的。为解决这个问题，我们提出了一种迁移学习（TL）方法，通过细调(U-Net网络和轻量级的MobileNet作为编码器)对一组有限的胎儿头超声图像进行分割。这种方法解决了从头开始训练CNN网络的挑战。研究表明，我们提出的细调策略在训练参数减少85.8%的情况下，能够获得可比较的分割性能。并且，我们的细调策略优于其他策略。

    Fetal head segmentation is a crucial step in measuring the fetal head circumference (HC) during gestation, an important biometric in obstetrics for monitoring fetal growth. However, manual biometry generation is time-consuming and results in inconsistent accuracy. To address this issue, convolutional neural network (CNN) models have been utilized to improve the efficiency of medical biometry. But training a CNN network from scratch is a challenging task, we proposed a Transfer Learning (TL) method. Our approach involves fine-tuning (FT) a U-Net network with a lightweight MobileNet as the encoder to perform segmentation on a set of fetal head ultrasound (US) images with limited effort. This method addresses the challenges associated with training a CNN network from scratch. It suggests that our proposed FT strategy yields segmentation performance that is comparable when trained with a reduced number of parameters by 85.8%. And our proposed FT strategy outperforms other strategies with s
    
[^26]: 技术笔记：定义和量化DNN的AND-OR交互以进行准确和简明的解释

    Technical Note: Defining and Quantifying AND-OR Interactions for Faithful and Concise Explanation of DNNs. (arXiv:2304.13312v1 [cs.LG])

    [http://arxiv.org/abs/2304.13312](http://arxiv.org/abs/2304.13312)

    本文提出了一种通过量化输入变量之间的编码交互来准确且简明地解释深度神经网络(DNN)的推理逻辑的方法。针对此目的，作者提出了两种交互方式，即AND交互和OR交互，并利用它们设计出一系列技术来提高解释的简洁性，同时不会损害准确性。

    

    本文旨在通过量化输入变量之间的编码交互来解释深度神经网络(DNN)的推理逻辑。具体而言，我们首先重新思考交互的定义，然后正式定义了基于交互的解释的准确性和简洁性。为此，我们提出了两种交互方式，即AND交互和OR交互。针对准确性，我们证明了AND（OR）交互在量化输入变量之间的AND（OR）关系效应方面的唯一性。此外，基于AND-OR交互，我们设计了技术来提高解释的简洁性，同时不会损害准确性。因此，DNN的推理逻辑可以通过一组符号概念准确而简明地解释。

    In this technical note, we aim to explain a deep neural network (DNN) by quantifying the encoded interactions between input variables, which reflects the DNN's inference logic. Specifically, we first rethink the definition of interactions, and then formally define faithfulness and conciseness for interaction-based explanation. To this end, we propose two kinds of interactions, i.e., the AND interaction and the OR interaction. For faithfulness, we prove the uniqueness of the AND (OR) interaction in quantifying the effect of the AND (OR) relationship between input variables. Besides, based on AND-OR interactions, we design techniques to boost the conciseness of the explanation, while not hurting the faithfulness. In this way, the inference logic of a DNN can be faithfully and concisely explained by a set of symbolic concepts.
    
[^27]: 利用Transformer进行光学系统非线性通道补偿的应用

    Application of Transformers for Nonlinear Channel Compensation in Optical Systems. (arXiv:2304.13119v1 [cs.IT])

    [http://arxiv.org/abs/2304.13119](http://arxiv.org/abs/2304.13119)

    本文提出了一种利用Transformer进行光学系统非线性通道补偿的新方法，这种方法利用了Transformer的记忆关注能力和并行结构，实现了高效的非线性补偿。同时，作者还提出了一种物理学信息掩码，用于降低计算复杂度。

    

    本文介绍了一种基于Transformer的新型非线性通道均衡方法，用于相干长距离传输。我们证明，由于其能够直接关注一系列符号之间的记忆，因此Transformer可以与并行结构有效地配合使用。我们展示了一个编码器部分的Transformer实现，用于非线性均衡，并分析了其在不同超参数范围内的性能。通过在每次迭代中处理符号块，并仔细选择要一起处理的编码器输出子集，可以实现高效的非线性补偿。我们还提出了一种基于非线性扰动理论的物理学信息掩码，用于降低Transformer非线性均衡的计算复杂度。

    In this paper, we introduce a new nonlinear channel equalization method for the coherent long-haul transmission based on Transformers. We show that due to their capability to attend directly to the memory across a sequence of symbols, Transformers can be used effectively with a parallelized structure. We present an implementation of encoder part of Transformer for nonlinear equalization and analyze its performance over a wide range of different hyper-parameters. It is shown that by processing blocks of symbols at each iteration and carefully selecting subsets of the encoder's output to be processed together, an efficient nonlinear compensation can be achieved. We also propose the use of a physic-informed mask inspired by nonlinear perturbation theory for reducing the computational complexity of Transformer nonlinear equalization.
    
[^28]: 神经网络中的泛化：综述与分析

    Generalization in Neural Networks: A Broad Survey. (arXiv:2209.01610v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.01610](http://arxiv.org/abs/2209.01610)

    这篇论文总结了神经网络模型中不同抽象层次上的泛化问题及其方法，其中样本泛化已经取得了进展，但未来需要重点关注减少过拟合；分布泛化与领域泛化有相似之处，领域泛化方法可以应用于困难的样本或分布泛化。

    

    本文综述了神经网络模型中不同抽象层次的概念、建模方法和最近的研究成果，包括样本、分布、领域、任务、模态和范围上的泛化。在样本泛化方面的研究结果显示，在ImageNet数据集的情况下，几乎所有的最新改进都减小了训练误差，而过拟合保持不变；随着几乎所有的训练误差被消除，未来的进展将需要集中关注减少过拟合。从统计学的角度来看，(2)分布泛化可以被看作是样本权重或输入输出关系的变化；因此，在领域泛化成功的技术有可能应用于困难的样本或分布泛化。本文总结了转移学习方法(3)领域泛化的应用，以及最近的进展和丰富的应用领域。

    This paper reviews concepts, modeling approaches, and recent findings along a spectrum of different levels of abstraction of neural network models including generalization across (1) Samples, (2) Distributions, (3) Domains, (4) Tasks, (5) Modalities, and (6) Scopes. Results on (1) sample generalization show that, in the case of ImageNet, nearly all the recent improvements reduced training error while overfitting stayed flat; with nearly all the training error eliminated, future progress will require a focus on reducing overfitting. Perspectives from statistics highlight how (2) distribution generalization can be viewed alternately as a change in sample weights or a change in the input-output relationship; thus, techniques that have been successful in domain generalization have the potential to be applied to difficult forms of sample or distribution generalization. Transfer learning approaches to (3) domain generalization are summarized, as are recent advances and the wealth of domain a
    

