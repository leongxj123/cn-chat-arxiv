# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [No Free Prune: Information-Theoretic Barriers to Pruning at Initialization](https://rss.arxiv.org/abs/2402.01089) | 本文解释了为什么在初始化时修剪神经网络困难，并提出了一个关于有效参数数量的理论解释。我们指出，在嘈杂数据中鲁棒地插值的稀疏神经网络需要严重依赖于数据的掩码。为此，我们怀疑在训练过程中和训练后修剪是必要的。 |
| [^2] | [A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide](https://arxiv.org/abs/2404.01039) | 该研究是第一份致力于超图神经网络的调查报告，深入介绍了HNN架构、训练策略和应用，为从事数据挖掘和机器学习的研究人员提供了重要的指导。 |
| [^3] | [The Larger the Better? Improved LLM Code-Generation via Budget Reallocation](https://arxiv.org/abs/2404.00725) | 较小的语言模型可以在相同预算下产生可靠的改进，但在无法进行单元测试的情况下，较小的模型选择排名次于较大模型的单个输出。 |
| [^4] | [Particle identification with machine learning from incomplete data in the ALICE experiment](https://arxiv.org/abs/2403.17436) | 在ALICE实验中，我们利用机器学习方法和多神经网络进行粒子识别，包括特征集嵌入和注意力机制，以在不完整数据样本上进行训练，并将ML项目与ALICE分析软件集成，讨论了域自适应技术。 |
| [^5] | [A Unified Framework for Model Editing](https://arxiv.org/abs/2403.14236) | 这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。 |
| [^6] | [Equivariant Ensembles and Regularization for Reinforcement Learning in Map-based Path Planning](https://arxiv.org/abs/2403.12856) | 本文提出了一种无需专门神经网络组件的等变策略和不变值函数构建方法，在基于地图的路径规划中展示了等变集合和正则化如何提高样本效率和性能 |
| [^7] | [Light Curve Classification with DistClassiPy: a new distance-based classifier](https://arxiv.org/abs/2403.12120) | 提出了一种新的基于距离度量的分类器DistClassiPy，通过比较不同类别对象之间的距离，实现了可变星的光变曲线分类，帮助增加分类结果的可解释性并减少计算成本。 |
| [^8] | [Optimal Block-Level Draft Verification for Accelerating Speculative Decoding](https://arxiv.org/abs/2403.10444) | 提出了一种更好的草稿验证算法，通过将验证步骤制定为块级最优传输问题，实现了额外的墙钟速度提升，而不增加额外的计算成本和草稿标记 |
| [^9] | [Efficient Combinatorial Optimization via Heat Diffusion](https://arxiv.org/abs/2403.08757) | 通过热扩散实现了高效的组合优化，克服了现有方法在搜索全局最优时效率有限的问题。 |
| [^10] | [Neural Fractional Differential Equations](https://arxiv.org/abs/2403.02737) | 提出了神经FDE，一种新型深度神经网络架构，可调整FDE以适应数据动态，可能优于神经OD。 |
| [^11] | [A Priori Uncertainty Quantification of Reacting Turbulence Closure Models using Bayesian Neural Networks](https://arxiv.org/abs/2402.18729) | 使用贝叶斯神经网络对反应流动模型中的不确定性进行量化，特别是在湍涡预混火焰动态中关键变量的建模方面取得重要进展 |
| [^12] | [DiCoM -- Diverse Concept Modeling towards Enhancing Generalizability in Chest X-Ray Studies](https://arxiv.org/abs/2402.15534) | DiCoM是一种新颖的自监督训练范式，通过学习多元概念，有效表示胸部X射线数据，以应对医学成像预训练中与自然图像不同的挑战。 |
| [^13] | [HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts](https://arxiv.org/abs/2402.12656) | HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。 |
| [^14] | [SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning](https://arxiv.org/abs/2402.11933) | SLADE通过自监督学习在边缘流中迅速检测动态异常，无需依赖标签，主要通过观察节点交互模式的偏差来检测节点状态转变。 |
| [^15] | [3D Diffuser Actor: Policy Diffusion with 3D Scene Representations](https://arxiv.org/abs/2402.10885) | 通过策略扩散和3D场景表示相结合，提出了3D Diffuser Actor，一个神经策略架构，可以根据语言指令构建3D视觉场景表示，并对机器人末端执行器的3D旋转和平移进行迭代去噪。 |
| [^16] | [Exploring the Impact of In-Browser Deep Learning Inference on Quality of User Experience and Performance](https://arxiv.org/abs/2402.05981) | 本研究通过全面性能评估，探索了浏览器内深度学习推理对用户体验质量和性能的影响。研究发现，浏览器内推理存在严重的延迟问题，平均比原生推理方法慢16.9倍。为了衡量这种影响，我们引入了新的指标：响应性，流畅度和推理准确性。 |
| [^17] | [KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache](https://arxiv.org/abs/2402.02750) | 该论文提出了一种无需调整的非对称2位量化KV缓存技术，以解决存储注意力键和值的内存需求增加和推断速度受限问题。 |
| [^18] | [Goodness-of-Fit and Clustering of Spherical Data: the QuadratiK package in R and Python](https://arxiv.org/abs/2402.02290) | QuadratiK软件包是一个在R和Python中实现的数据分析工具，它提供了一套全面的拟合度测试和基于核方法的聚类技术，特别适用于处理球形数据。 |
| [^19] | [Self-supervised learning of video representations from a child's perspective](https://arxiv.org/abs/2402.00300) | 本研究从儿童的视角进行自监督学习，通过长时间的头戴式摄像记录训练视频模型，结果表明这些模型在促进从少量样本中学习行动概念方面非常有效。 |
| [^20] | [Dr. Jekyll and Mr. Hyde: Two Faces of LLMs](https://arxiv.org/abs/2312.03853) | 本研究通过让ChatGPT和Bard冒充复杂人物角色，绕过了安全机制和专门训练程序，展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。 |
| [^21] | [ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models.](http://arxiv.org/abs/2401.14351) | ServerlessLLM是一种用于大型语言模型的增强本地化无服务器推理系统，通过优化检查点加载、本地化推理和服务器分配来实现高效且低延迟的推理过程。 |
| [^22] | [Detection of Correlated Random Vectors.](http://arxiv.org/abs/2401.13429) | 本文研究了判断两个标准正态随机向量是否相关的问题，提出了一种新的方法来评估似然比的二阶矩，并发现了与整数分割函数之间的联系。 |
| [^23] | [Predicting the structure of dynamic graphs.](http://arxiv.org/abs/2401.04280) | 本文提出了一种预测动态图结构的方法，利用时间序列方法预测未来时间点的节点度，并结合通量平衡分析方法获得未来图的结构，评估了该方法在合成和真实数据集上的实用性和适用性。 |
| [^24] | [Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures.](http://arxiv.org/abs/2401.00773) | 提出一种基于随机子空间和子抽样集合的Dirichlet过程高斯混合模型的无监督异常检测方法，提高了计算效率和检测器的鲁棒性。 |
| [^25] | [Generative Learning of Continuous Data by Tensor Networks.](http://arxiv.org/abs/2310.20498) | 张量网络生成模型一般适用于二进制或类别数据，这篇论文介绍了一种新型张量网络生成模型，它可以用于学习连续数据分布，并展示了该模型在合成和真实数据集上的性能表现。 |
| [^26] | [Lattice Approximations in Wasserstein Space.](http://arxiv.org/abs/2310.09149) | 本论文研究了在Wasserstein空间中通过离散和分段常数测度进行的结构逼近方法。结果表明，对于满秩的格点按比例缩放后得到的Voronoi分割逼近的测度误差是$O(h)$，逼近的$N$项误差为$O(N^{-\frac1d})$，并且可以推广到非紧支撑测度。 |
| [^27] | [Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials.](http://arxiv.org/abs/2309.16571) | 该论文综述了基于机器学习方法的功能梯度材料增材制造。功能梯度材料是一类具有平滑性质过渡的高级复合材料，机器学习技术被应用于优化加工参数、提高产品质量和检测制造缺陷。这些方法有望提高零件性能和性质。 |
| [^28] | [P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification.](http://arxiv.org/abs/2309.08499) | 本研究提出了一种名为P-ROCKET的方法，通过在特征选择的角度删除卷积核，从而实现对时间序列分类中的随机卷积核进行剪枝。 |
| [^29] | [Generalizable improvement of the Spalart-Allmaras model through assimilation of experimental data.](http://arxiv.org/abs/2309.06679) | 本研究通过实验数据同化改进了Spalart-Allmaras模型，实现了对分离流体的雷诺平均纳维-斯托克斯解的泛化，提高了计算模型的性能。 |
| [^30] | [The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants.](http://arxiv.org/abs/2308.16884) | Belebele是一个包含122种语言变体的多选机器阅读理解数据集，可用于评估文本模型在高、中和低资源语言中的性能。尽管英语为中心的大型语言模型在跨语言转移方面表现良好，但小型多语言遮蔽语言模型在其他语言上表现更佳。 |
| [^31] | [Generalized Continual Category Discovery.](http://arxiv.org/abs/2308.12112) | 本研究提出了一种广义持续类别发现（GCCD）的框架，用于在现实生活场景中同时处理新的和已知的类别，并且利用持续的无监督学习方法来发现它们。通过实验证明现有方法无法处理后续任务中的无标记样本。 |
| [^32] | [Amortized Variational Inference with Coverage Guarantees.](http://arxiv.org/abs/2305.14275) | 提出了一种称为CANVI的方法，通过构建一致化预测器并使用预测效率进行比较，来提供具有保证的后验近似结果。该方法可以快速计算，易于实现，并且对于候选近似器的设计决策无需关注。此外，CANVI能够在无似然的情况下使用。 |
| [^33] | [Clustering with minimum spanning trees: How good can it be?.](http://arxiv.org/abs/2303.05679) | 本文研究了使用最小生成树（MST）进行分区数据聚类任务的意义程度，并发现MST方法在总体上具有很强的竞争力。此外，通过回顾、研究、扩展和推广现有的MST-based划分方案，我们提出了一些新的和值得注意的方法。总体上，Genie和信息论方法往往优于其他非MST算法，在某些情况下MST方法可能不如其他算法。 |
| [^34] | [Hierarchical Classification of Research Fields in the "Web of Science" Using Deep Learning.](http://arxiv.org/abs/2302.00390) | 本文提出了一个使用深度学习进行层次分类的系统，可以自动将学术出版物通过抽象进行分类，实现了对研究活动在不同层次结构中的全面分类，并允许跨学科和跨领域的单标签和多标签分类。 |
| [^35] | [Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification.](http://arxiv.org/abs/2301.08403) | 本文探究了一种单次生成模型的多样性，主要聚焦于子序列相似性如何影响整个序列相似性，并通过生成子序列相似的序列来增强数据集。 |
| [^36] | [Normalised clustering accuracy: An asymmetric external cluster validity measure.](http://arxiv.org/abs/2209.02935) | 本文提出了一种非对称的外部聚类有效度量方法，旨在区分不同任务类型上表现良好和系统性表现不佳的聚类算法。与传统的内部度量不同，该方法利用参考真实分组进行评估，并弥补了现有方法在最坏情况下的误差。 |

# 详细

[^1]: 无免费修剪：初始化时剪枝的信息论障碍

    No Free Prune: Information-Theoretic Barriers to Pruning at Initialization

    [https://rss.arxiv.org/abs/2402.01089](https://rss.arxiv.org/abs/2402.01089)

    本文解释了为什么在初始化时修剪神经网络困难，并提出了一个关于有效参数数量的理论解释。我们指出，在嘈杂数据中鲁棒地插值的稀疏神经网络需要严重依赖于数据的掩码。为此，我们怀疑在训练过程中和训练后修剪是必要的。

    

    “抽奖中奖者”是否在初始化时存在，引发了一个令人着迷的问题：深度学习是否需要大型模型，或者可以在不训练包含它们的密集模型的情况下迅速识别和训练稀疏网络。然而，尝试在初始化时找到这些稀疏子网络（“初始化时修剪”）的努力在广泛上都没有成功。我们提出了一个理论解释，基于模型的有效参数数量$p_\text{eff}$，由最终网络中非零权重的数量和稀疏掩码与数据之间的相互信息的总和给出。我们展示了“鲁棒性定律”（arXiv:2105.12806）延伸到稀疏网络，其中常规参数数量被$p_\text{eff}$所取代，这意味着一个能够在嘈杂数据中鲁棒地插值的稀疏神经网络需要严重依赖于数据的掩码。我们假设在训练过程中和训练后修剪。

    The existence of "lottery tickets" arXiv:1803.03635 at or near initialization raises the tantalizing question of whether large models are necessary in deep learning, or whether sparse networks can be quickly identified and trained without ever training the dense models that contain them. However, efforts to find these sparse subnetworks without training the dense model ("pruning at initialization") have been broadly unsuccessful arXiv:2009.08576. We put forward a theoretical explanation for this, based on the model's effective parameter count, $p_\text{eff}$, given by the sum of the number of non-zero weights in the final network and the mutual information between the sparsity mask and the data. We show the Law of Robustness of arXiv:2105.12806 extends to sparse networks with the usual parameter count replaced by $p_\text{eff}$, meaning a sparse neural network which robustly interpolates noisy data requires a heavily data-dependent mask. We posit that pruning during and after training 
    
[^2]: 基于超图神经网络的调查：深入和分步指南

    A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide

    [https://arxiv.org/abs/2404.01039](https://arxiv.org/abs/2404.01039)

    该研究是第一份致力于超图神经网络的调查报告，深入介绍了HNN架构、训练策略和应用，为从事数据挖掘和机器学习的研究人员提供了重要的指导。

    

    高阶相互作用在现实世界中的复杂系统和应用中无处不在，因此，对于高阶相互作用的深度学习已成为数据挖掘和机器学习社区的一项重要议程。由于高阶相互作用网络在数学上被表达为超图，超图神经网络（HNNs）已成为在超图上进行表示学习的强大工具。鉴于这一新趋势，我们提出了首份致力于HNNs的调查报告，其中包含深入和分步指南。总体而言，本调查概述了HNN架构、训练策略和应用。首先，我们将现有的HNNs分解为四个设计组成部分：（i）输入特征，（ii）输入结构，（iii）消息传递方案，和（iv）训练策略。其次，我们考察HNNs如何通过各自的组成部分处理和学习高阶相互作用。第三，我们总结了HNNs在推荐、生物和医学中的最新应用。

    arXiv:2404.01039v1 Announce Type: new  Abstract: Higher-order interactions (HOIs) are ubiquitous in real-world complex systems and applications, and thus investigation of deep learning for HOIs has become a valuable agenda for the data mining and machine learning communities. As networks of HOIs are expressed mathematically as hypergraphs, hypergraph neural networks (HNNs) have emerged as a powerful tool for representation learning on hypergraphs. Given the emerging trend, we present the first survey dedicated to HNNs, with an in-depth and step-by-step guide. Broadly, the present survey overviews HNN architectures, training strategies, and applications. First, we break existing HNNs down into four design components: (i) input features, (ii) input structures, (iii) message-passing schemes, and (iv) training strategies. Second, we examine how HNNs address and learn HOIs with each of their components. Third, we overview the recent applications of HNNs in recommendation, biological and med
    
[^3]: 越大越好吗？通过预算重新分配改进LLM代码生成

    The Larger the Better? Improved LLM Code-Generation via Budget Reallocation

    [https://arxiv.org/abs/2404.00725](https://arxiv.org/abs/2404.00725)

    较小的语言模型可以在相同预算下产生可靠的改进，但在无法进行单元测试的情况下，较小的模型选择排名次于较大模型的单个输出。

    

    人们普遍认为，大型语言模型(LLMs)比较小的模型更好。然而，更大的模型在推断过程中也需要更多的时间和计算资源。这就引出了一个问题：当两个模型在相同的预算下运行时会发生什么？（例如，计算资源，运行时间）。为了解决这个问题，我们分析了各种大小的代码生成LLMs，并进行比较，例如运行一个70B模型一次与从13B模型生成五个输出并选择一个的情况。我们的研究结果表明，在标准单元测试设置中，反复使用较小的模型可以产生一致的改进，在五个任务中最高可达15%的增益。另一方面，在无法进行单元测试的情况下，从较小模型中基于排名的候选选择表现不及来自较大模型的单个输出。我们的结果突显了使用较小模型而非较大模型的潜力。

    arXiv:2404.00725v1 Announce Type: cross  Abstract: It is a common belief that large language models (LLMs) are better than smaller-sized ones. However, larger models also require significantly more time and compute during inference. This begs the question: what happens when both models operate under the same budget? (e.g., compute, run-time). To address this question, we analyze code generation LLMs of various sizes and make comparisons such as running a 70B model once vs. generating five outputs from a 13B model and selecting one. Our findings reveal that, in a standard unit-test setup, the repeated use of smaller models can yield consistent improvements, with gains of up to 15% across five tasks. On the other hand, in scenarios where unit-tests are unavailable, a ranking-based selection of candidates from the smaller model falls short of the performance of a single output from larger ones. Our results highlight the potential of using smaller models instead of larger ones, and the imp
    
[^4]: 在ALICE实验中利用机器学习从不完整数据中进行粒子识别

    Particle identification with machine learning from incomplete data in the ALICE experiment

    [https://arxiv.org/abs/2403.17436](https://arxiv.org/abs/2403.17436)

    在ALICE实验中，我们利用机器学习方法和多神经网络进行粒子识别，包括特征集嵌入和注意力机制，以在不完整数据样本上进行训练，并将ML项目与ALICE分析软件集成，讨论了域自适应技术。

    

    LHC的ALICE实验测量在超相对论重离子对撞中形成的强相互作用物质的性质。这些研究需要准确的粒子识别(PID)。ALICE通过几个探测器为动量从约100 MeV/c到20 GeV/c的粒子提供PID信息。传统上，粒子是通过矩形切割进行选择的。利用机器学习(ML)方法可以实现更好的性能。我们的解决方案使用多个神经网络(NN)作为二进制分类器。此外，我们通过特征集嵌入和关注扩展了粒子分类器，以便对包含不完整样本的数据进行训练。我们还介绍了ML项目与ALICE分析软件的集成，并讨论了域自适应，这是将知识从模拟数据转移到实际实验数据所需的ML技术。

    arXiv:2403.17436v1 Announce Type: cross  Abstract: The ALICE experiment at the LHC measures properties of the strongly interacting matter formed in ultrarelativistic heavy-ion collisions. Such studies require accurate particle identification (PID). ALICE provides PID information via several detectors for particles with momentum from about 100 MeV/c up to 20 GeV/c. Traditionally, particles are selected with rectangular cuts. Acmuch better performance can be achieved with machine learning (ML) methods. Our solution uses multiple neural networks (NN) serving as binary classifiers. Moreover, we extended our particle classifier with Feature Set Embedding and attention in order to train on data with incomplete samples. We also present the integration of the ML project with the ALICE analysis software, and we discuss domain adaptation, the ML technique needed to transfer the knowledge between simulated and real experimental data.
    
[^5]: 一个统一的模型编辑框架

    A Unified Framework for Model Editing

    [https://arxiv.org/abs/2403.14236](https://arxiv.org/abs/2403.14236)

    这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。

    

    模型编辑是一个不断发展的领域，专注于更新模型中嵌入的知识。在各种方法中，ROME和MEMIT作为主要的“定位和编辑”模型编辑技术脱颖而出。而MEMIT可以批量编辑记忆，ROME则一次只能改变一个事实。本文引入了一个统一的框架，将ROME和MEMIT纳入一个单一的概念框架，优化同一目标，我们称之为“保存-记忆”目标。该目标旨在在记忆新事实信息的同时保留某些选定向量的表示。具体来说，ROME使用等式约束优化此目标，而MEMIT采用更灵活的最小二乘约束。除了批量编辑外，MEMIT还可以在多个层面编辑模型。我们将编辑的分布从多个层面分开，区别于优化目标。

    arXiv:2403.14236v1 Announce Type: cross  Abstract: Model editing is a growing area focused on updating the knowledge embedded within models. Among the various methodologies, ROME and MEMIT stand out as leading "locate-and-edit" model editing techniques. While MEMIT enables batched editing of memories, ROME is limited to changing one fact at a time. This paper introduces a unifying framework that brings ROME and MEMIT under a single conceptual umbrella, optimizing for the same goal, which we call the "preservation-memorization" objective. This objective aims to preserve the representations of certain selected vectors while memorizing the representations of new factual information. Specifically, ROME optimizes this objective using an equality constraint, whereas MEMIT employs a more flexible least-square constraint. In addition to making batched edits, MEMIT also edits the model at multiple layers. We disentangle the distribution of edits to multiple layers from the optimization objectiv
    
[^6]: 基于地图的路径规划中的等变集合和正则化的强化学习

    Equivariant Ensembles and Regularization for Reinforcement Learning in Map-based Path Planning

    [https://arxiv.org/abs/2403.12856](https://arxiv.org/abs/2403.12856)

    本文提出了一种无需专门神经网络组件的等变策略和不变值函数构建方法，在基于地图的路径规划中展示了等变集合和正则化如何提高样本效率和性能

    

    在强化学习（RL）中，利用环境的对称性可以显著增强效率、鲁棒性和性能。然而，确保深度RL策略和值网络分别是等变和不变的以利用这些对称性是一个重大挑战。相关工作尝试通过构造具有等变性和不变性的网络来设计，这限制了它们只能使用非常受限的组件库，进而阻碍了网络的表现能力。本文提出了一种构建等变策略和不变值函数的方法，而无需专门的神经网络组件，我们将其称为等变集合。我们进一步添加了一个正则化项，用于在训练过程中增加归纳偏差。在基于地图的路径规划案例研究中，我们展示了等变集合和正则化如何有益于样本效率和性能。

    arXiv:2403.12856v1 Announce Type: new  Abstract: In reinforcement learning (RL), exploiting environmental symmetries can significantly enhance efficiency, robustness, and performance. However, ensuring that the deep RL policy and value networks are respectively equivariant and invariant to exploit these symmetries is a substantial challenge. Related works try to design networks that are equivariant and invariant by construction, limiting them to a very restricted library of components, which in turn hampers the expressiveness of the networks. This paper proposes a method to construct equivariant policies and invariant value functions without specialized neural network components, which we term equivariant ensembles. We further add a regularization term for adding inductive bias during training. In a map-based path planning case study, we show how equivariant ensembles and regularization benefit sample efficiency and performance.
    
[^7]: 使用DistClassiPy进行光变曲线分类：一种新的基于距离的分类器

    Light Curve Classification with DistClassiPy: a new distance-based classifier

    [https://arxiv.org/abs/2403.12120](https://arxiv.org/abs/2403.12120)

    提出了一种新的基于距离度量的分类器DistClassiPy，通过比较不同类别对象之间的距离，实现了可变星的光变曲线分类，帮助增加分类结果的可解释性并减少计算成本。

    

    天文学领域的巡天调查的兴起引领了时域天文学中大数据时代的到来，使得数据科学和机器学习成为研究天体对象的必备工具。我们探讨了使用不同距离度量来辅助对象分类的方法。为此，我们开发了一种基于距离度量的新分类器，称为DistClassiPy。直接使用距离度量是一种在时域天文学中尚未探索的方法，但基于距离的方法可以帮助增加分类结果的可解释性并减少计算成本。具体而言，我们通过比较不同类别对象之间的距离，对可变星的光变曲线进行分类。通过对10个类别中的6000颗可变星的目录应用18种距离度量，我们展示了分类和维度缩减。

    arXiv:2403.12120v1 Announce Type: cross  Abstract: The rise of synoptic sky surveys has ushered in an era of big data in time-domain astronomy, making data science and machine learning essential tools for studying celestial objects. Tree-based (e.g. Random Forests) and deep learning models represent the current standard in the field. We explore the use of different distance metrics to aid in the classification of objects. For this, we developed a new distance metric based classifier called DistClassiPy. The direct use of distance metrics is an approach that has not been explored in time-domain astronomy, but distance-based methods can aid in increasing the interpretability of the classification result and decrease the computational costs. In particular, we classify light curves of variable stars by comparing the distances between objects of different classes. Using 18 distance metrics applied to a catalog of 6,000 variable stars in 10 classes, we demonstrate classification and dimensio
    
[^8]: 用于加速推测解码的最佳块级草稿验证

    Optimal Block-Level Draft Verification for Accelerating Speculative Decoding

    [https://arxiv.org/abs/2403.10444](https://arxiv.org/abs/2403.10444)

    提出了一种更好的草稿验证算法，通过将验证步骤制定为块级最优传输问题，实现了额外的墙钟速度提升，而不增加额外的计算成本和草稿标记

    

    推测解码已被证明是在推理过程中加速大型语言模型（LLMs）无损加速的有效方法。 在每次迭代中，算法首先使用一个较小的模型起草一块标记。这些标记然后由大型模型并行验证，只有一部分标记将被保留，以确保最终输出遵循大型模型的分布。 在以往的所有推测解码工作中，起草验证是独立地逐个标记执行的。 在本工作中，我们提出了一个更好的起草验证算法，可提供额外的墙钟加速，而不需要额外的计算成本和起草标记。 我们首先将起草验证步骤制定为一个块级最优传输问题。 块级制定允许我们考虑更广泛的起草验证算法，并在一个起草中预期获得更多接受的标记数量

    arXiv:2403.10444v1 Announce Type: cross  Abstract: Speculative decoding has shown to be an effective method for lossless acceleration of large language models (LLMs) during inference. In each iteration, the algorithm first uses a smaller model to draft a block of tokens. The tokens are then verified by the large model in parallel and only a subset of tokens will be kept to guarantee that the final output follows the distribution of the large model. In all of the prior speculative decoding works, the draft verification is performed token-by-token independently. In this work, we propose a better draft verification algorithm that provides additional wall-clock speedup without incurring additional computation cost and draft tokens. We first formulate the draft verification step as a block-level optimal transport problem. The block-level formulation allows us to consider a wider range of draft verification algorithms and obtain a higher number of accepted tokens in expectation in one draft 
    
[^9]: 通过热扩散实现高效的组合优化

    Efficient Combinatorial Optimization via Heat Diffusion

    [https://arxiv.org/abs/2403.08757](https://arxiv.org/abs/2403.08757)

    通过热扩散实现了高效的组合优化，克服了现有方法在搜索全局最优时效率有限的问题。

    

    论文探讨了通过热扩散来实现高效的组合优化。针对现有方法只能在每次迭代中访问解空间的一小部分这一限制，提出了一种框架来解决一般的组合优化问题，并且在一系列最具挑战性和广泛遇到的组合优化中展现出卓越性能。

    arXiv:2403.08757v1 Announce Type: cross  Abstract: Combinatorial optimization problems are widespread but inherently challenging due to their discrete nature.The primary limitation of existing methods is that they can only access a small fraction of the solution space at each iteration, resulting in limited efficiency for searching the global optimal. To overcome this challenge, diverging from conventional efforts of expanding the solver's search scope, we focus on enabling information to actively propagate to the solver through heat diffusion. By transforming the target function while preserving its optima, heat diffusion facilitates information flow from distant regions to the solver, providing more efficient navigation. Utilizing heat diffusion, we propose a framework for solving general combinatorial optimization problems. The proposed methodology demonstrates superior performance across a range of the most challenging and widely encountered combinatorial optimizations. Echoing rec
    
[^10]: 神经分数阶微分方程

    Neural Fractional Differential Equations

    [https://arxiv.org/abs/2403.02737](https://arxiv.org/abs/2403.02737)

    提出了神经FDE，一种新型深度神经网络架构，可调整FDE以适应数据动态，可能优于神经OD。

    

    分数阶微分方程（FDEs）是科学和工程中建模复杂系统的基本工具。 它们将传统的微分和积分概念扩展到非整数阶，使得能够更精确地表示具有非局部和记忆依赖行为特征的过程。在这个背景下，受神经常微分方程（Neural ODEs）的启发，我们提出了神经FDE，这是一种调整FDE以适应数据动态的新型深度神经网络架构。这项工作全面概述了神经FDE中采用的数值方法和神经FDE架构。数值结果表明，尽管计算要求更高，神经FDE可能优于神经OD。

    arXiv:2403.02737v1 Announce Type: new  Abstract: Fractional Differential Equations (FDEs) are essential tools for modelling complex systems in science and engineering. They extend the traditional concepts of differentiation and integration to non-integer orders, enabling a more precise representation of processes characterised by non-local and memory-dependent behaviours.   This property is useful in systems where variables do not respond to changes instantaneously, but instead exhibit a strong memory of past interactions.   Having this in mind, and drawing inspiration from Neural Ordinary Differential Equations (Neural ODEs), we propose the Neural FDE, a novel deep neural network architecture that adjusts a FDE to the dynamics of data.   This work provides a comprehensive overview of the numerical method employed in Neural FDEs and the Neural FDE architecture. The numerical outcomes suggest that, despite being more computationally demanding, the Neural FDE may outperform the Neural OD
    
[^11]: 利用贝叶斯神经网络对反应湍流封闭模型进行先验不确定性量化

    A Priori Uncertainty Quantification of Reacting Turbulence Closure Models using Bayesian Neural Networks

    [https://arxiv.org/abs/2402.18729](https://arxiv.org/abs/2402.18729)

    使用贝叶斯神经网络对反应流动模型中的不确定性进行量化，特别是在湍涡预混火焰动态中关键变量的建模方面取得重要进展

    

    虽然为大涡模拟（LES）中的子滤波尺度（SFS）提出了许多基于物理的封闭模型形式，但直接数值模拟（DNS）提供的大量数据为利用数据驱动建模技术创造了机会。尽管灵活，数据驱动模型仍取决于选择的数据集和模型的函数形式。采用这种模型的增加需要可靠地估计数据驱动模型中数据知识和超出分布范围的不确定性。在本工作中，我们利用贝叶斯神经网络（BNNs）来捕捉反应流动模型中的逻辑不确定性和偶然不确定性。特别是，我们模拟了在湍涡预混火焰动态中起关键作用的滤波进展变量标量耗散率。我们展示了BNN模型可以提供关于数据驱动封闭模型的不确定性结构的独特见解。我们还提出了一种方法来进行...

    arXiv:2402.18729v1 Announce Type: cross  Abstract: While many physics-based closure model forms have been posited for the sub-filter scale (SFS) in large eddy simulation (LES), vast amounts of data available from direct numerical simulation (DNS) create opportunities to leverage data-driven modeling techniques. Albeit flexible, data-driven models still depend on the dataset and the functional form of the model chosen. Increased adoption of such models requires reliable uncertainty estimates both in the data-informed and out-of-distribution regimes. In this work, we employ Bayesian neural networks (BNNs) to capture both epistemic and aleatoric uncertainties in a reacting flow model. In particular, we model the filtered progress variable scalar dissipation rate which plays a key role in the dynamics of turbulent premixed flames. We demonstrate that BNN models can provide unique insights about the structure of uncertainty of the data-driven closure models. We also propose a method for the
    
[^12]: DiCoM -- 多元概念建模以增强胸部X射线研究的普适性

    DiCoM -- Diverse Concept Modeling towards Enhancing Generalizability in Chest X-Ray Studies

    [https://arxiv.org/abs/2402.15534](https://arxiv.org/abs/2402.15534)

    DiCoM是一种新颖的自监督训练范式，通过学习多元概念，有效表示胸部X射线数据，以应对医学成像预训练中与自然图像不同的挑战。

    

    胸部X线（CXR）是一种广泛应用的临床成像模态，在各种肺部和心脏相关疾病的诊断和预后中起着关键作用。传统的依赖放射学读片和监督学习的自动化临床诊断工具设计策略需要高质量注释训练数据，为了解决这一挑战，自监督预训练已被证明在许多下游视觉任务中胜过监督预训练，代表了该领域的重大突破。然而，医学成像预训练与自然图像（例如ImageNet）的预训练在很大程度上不同，因为临床图像具有独特属性。在这种背景下，我们介绍了多元概念建模（DiCoM），这是一种新颖的自监督训练范式，利用了学生教师框架来学习多元概念，从而有效表示CXR数据。

    arXiv:2402.15534v1 Announce Type: cross  Abstract: Chest X-Ray (CXR) is a widely used clinical imaging modality and has a pivotal role in the diagnosis and prognosis of various lung and heart related conditions. Conventional automated clinical diagnostic tool design strategies relying on radiology reads and supervised learning, entail the cumbersome requirement of high quality annotated training data. To address this challenge, self-supervised pre-training has proven to outperform supervised pre-training in numerous downstream vision tasks, representing a significant breakthrough in the field. However, medical imaging pre-training significantly differs from pre-training with natural images (e.g., ImageNet) due to unique attributes of clinical images. In this context, we introduce Diverse Concept Modeling (DiCoM), a novel self-supervised training paradigm that leverages a student teacher framework for learning diverse concepts and hence effective representation of the CXR data. Hence, e
    
[^13]: HyperMoE: 通过专家之间的知识传递实现更好的专家混合

    HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts

    [https://arxiv.org/abs/2402.12656](https://arxiv.org/abs/2402.12656)

    HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。

    

    混合专家(MoE)在语言模型中被证明有效地增强了模型的能力，通过动态地将每个输入标记路由到特定的专家子集进行处理。尽管取得了成功，但大多数现有方法在专家知识的稀疏性和可用性之间面临挑战：通过增加对专家知识的使用来增强性能，往往会导致在专家选择过程中稀疏度减少。为了缓解这一矛盾，我们提出了HyperMoE，这是一个建立在Hypernetworks之上的新颖MoE框架。该框架将MoE的计算过程与多任务学习中的知识传递概念进行了集成。基于未选择专家信息生成的特定模块作为补充信息，允许未被选中的专家的知识在保持选择稀疏性的同时被使用。

    arXiv:2402.12656v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) for language models has been proven effective in augmenting the capacity of models by dynamically routing each input token to a specific subset of experts for processing. Despite the success, most existing methods face a challenge for balance between sparsity and the availability of expert knowledge: enhancing performance through increased use of expert knowledge often results in diminishing sparsity during expert selection. To mitigate this contradiction, we propose HyperMoE, a novel MoE framework built upon Hypernetworks. This framework integrates the computational processes of MoE with the concept of knowledge transferring in multi-task learning. Specific modules generated based on the information of unselected experts serve as supplementary information, which allows the knowledge of experts not selected to be used while maintaining selection sparsity. Our comprehensive empirical evaluations across multi
    
[^14]: SLADE：通过自监督学习在边缘流中检测动态异常

    SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning

    [https://arxiv.org/abs/2402.11933](https://arxiv.org/abs/2402.11933)

    SLADE通过自监督学习在边缘流中迅速检测动态异常，无需依赖标签，主要通过观察节点交互模式的偏差来检测节点状态转变。

    

    为了检测真实世界图中的异常，如社交、电子邮件和金融网络，已经开发了各种方法。在大多数真实世界图随时间增长，自然地表示为边缘流的情况下，我们的目标是：(a)在异常发生时即时检测异常，(b)适应动态变化的状态，(c)处理动态异常标签的稀缺性。在本文中，我们提出了SLADE（边缘流异常检测的自监督学习），用于在边缘流中快速检测动态异常，而不依赖于标签。SLADE通过观察节点在时间上相互作用模式的偏差来检测节点进入异常状态的转变。为此，它训练一个深度神经网络执行两个自监督任务：(a)最小化节点表示中的漂移，(b)从短期生成长期交互模式。

    arXiv:2402.11933v1 Announce Type: new  Abstract: To detect anomalies in real-world graphs, such as social, email, and financial networks, various approaches have been developed. While they typically assume static input graphs, most real-world graphs grow over time, naturally represented as edge streams. In this context, we aim to achieve three goals: (a) instantly detecting anomalies as they occur, (b) adapting to dynamically changing states, and (c) handling the scarcity of dynamic anomaly labels. In this paper, we propose SLADE (Self-supervised Learning for Anomaly Detection in Edge Streams) for rapid detection of dynamic anomalies in edge streams, without relying on labels. SLADE detects the shifts of nodes into abnormal states by observing deviations in their interaction patterns over time. To this end, it trains a deep neural network to perform two self-supervised tasks: (a) minimizing drift in node representations and (b) generating long-term interaction patterns from short-term 
    
[^15]: 基于3D场景表示的3D扩散器Actor：通过策略扩散进行机器人操作

    3D Diffuser Actor: Policy Diffusion with 3D Scene Representations

    [https://arxiv.org/abs/2402.10885](https://arxiv.org/abs/2402.10885)

    通过策略扩散和3D场景表示相结合，提出了3D Diffuser Actor，一个神经策略架构，可以根据语言指令构建3D视觉场景表示，并对机器人末端执行器的3D旋转和平移进行迭代去噪。

    

    我们将扩散策略和3D场景表示相结合，用于机器人操作。扩散策略通过条件扩散模型学习基于机器人和环境状态的动作分布。最近，它们已经表现出优于确定性和其他基于状态的动作分布学习方法。3D机器人策略使用从单个或多个摄像头视角获取的感应深度聚合的3D场景特征表示。它们已经证明比其2D对应物在摄像机视角上具有更好的泛化能力。我们统一了这两条线路的工作，并提出了3D扩散器Actor，这是一个神经策略架构，它在给定语言指令的情况下，构建视觉场景的3D表示，并在其上进行条件迭代去噪机器人末端执行器的3D旋转和平移。在每个去噪迭代中，我们的模型将末端执行器姿态估计表示为3D场景令牌，并预测t

    arXiv:2402.10885v1 Announce Type: cross  Abstract: We marry diffusion policies and 3D scene representations for robot manipulation. Diffusion policies learn the action distribution conditioned on the robot and environment state using conditional diffusion models. They have recently shown to outperform both deterministic and alternative state-conditioned action distribution learning methods. 3D robot policies use 3D scene feature representations aggregated from a single or multiple camera views using sensed depth. They have shown to generalize better than their 2D counterparts across camera viewpoints. We unify these two lines of work and present 3D Diffuser Actor, a neural policy architecture that, given a language instruction, builds a 3D representation of the visual scene and conditions on it to iteratively denoise 3D rotations and translations for the robot's end-effector. At each denoising iteration, our model represents end-effector pose estimates as 3D scene tokens and predicts t
    
[^16]: 探索浏览器内深度学习推理对用户体验质量和性能的影响

    Exploring the Impact of In-Browser Deep Learning Inference on Quality of User Experience and Performance

    [https://arxiv.org/abs/2402.05981](https://arxiv.org/abs/2402.05981)

    本研究通过全面性能评估，探索了浏览器内深度学习推理对用户体验质量和性能的影响。研究发现，浏览器内推理存在严重的延迟问题，平均比原生推理方法慢16.9倍。为了衡量这种影响，我们引入了新的指标：响应性，流畅度和推理准确性。

    

    深度学习越来越多地通过“浏览器内推理”这种方法整合到Web应用程序中，其中DL处理直接在Web浏览器中进行。然而，这种方法的实际性能及其对用户体验质量（QoE）的影响尚不为人所知。这种知识的空白需要新形式的QoE测量，超越传统的指标，如页面加载时间。为了解决这个问题，我们进行了浏览器内推理的首次全面性能评估。我们引入了新的指标：响应性，流畅度和推理准确性。我们的全面研究包括9个广泛使用的DL模型，并在50个常用的PC Web浏览器上进行了测试。研究结果显示，浏览器内推理存在严重的延迟问题：在CPU上平均比原生推理方法慢16.9倍，在GPU上慢4.9倍。这种延迟有几个因素导致，包括未充分使用的硬件指令集，固有的延迟等。

    Deep Learning (DL) is increasingly being integrated into Web applications through a method known as "in-browser inference", where the DL processes occur directly within Web browsers. However, the actual performance of this method and its effect on user experience quality (QoE) is not well-understood. This gap in knowledge necessitates new forms of QoE measurement, going beyond traditional metrics such as page load time. To address this, we conducted the first extensive performance evaluation of in-browser inference. We introduced new metrics for this purpose: responsiveness, smoothness, and inference accuracy.   Our thorough study included 9 widely-used DL models and tested them across 50 popular PC Web browsers. The findings show a significant latency issue with in-browser inference: it's on average 16.9 times slower on CPU and 4.9 times slower on GPU than native inference methods. Several factors contribute to this latency, including underused hardware instruction sets, inherent dela
    
[^17]: KIVI：一种无需调整的非对称2位量化KV缓存技术

    KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache

    [https://arxiv.org/abs/2402.02750](https://arxiv.org/abs/2402.02750)

    该论文提出了一种无需调整的非对称2位量化KV缓存技术，以解决存储注意力键和值的内存需求增加和推断速度受限问题。

    

    高效地为大型语言模型（LLMs）提供服务需要将许多请求批量处理以减少每个请求的成本。然而，存储注意力键和值以避免重新计算的键值（KV）缓存显著增加了内存需求，并成为速度和内存使用的新瓶颈。这种内存需求随着批处理大小和上下文长度的增加而增加。此外，推断速度受到KV缓存大小的限制，因为GPU的SRAM必须从主GPU内存中加载整个KV缓存以生成每个标记，导致计算核心在此过程中处于空闲状态。减小KV缓存大小的一个直接而有效的解决方案是量化，通过减少KV缓存所需的总字节数来实现。然而，目前缺乏对KV缓存元素分布进行深入研究以了解KV缓存量化的难度和限制。为了弥补这一空白，我们开展了一项全面的元素分布研究。。。

    Efficiently serving large language models (LLMs) requires batching many requests together to reduce the cost per request. Yet, the key-value (KV) cache, which stores attention keys and values to avoid re-computations, significantly increases memory demands and becomes the new bottleneck in speed and memory usage. This memory demand increases with larger batch sizes and longer context lengths. Additionally, the inference speed is limited by the size of KV cache, as the GPU's SRAM must load the entire KV cache from the main GPU memory for each token generated, causing the computational core to be idle during this process. A straightforward and effective solution to reduce KV cache size is quantization, which decreases the total bytes taken by KV cache. However, there is a lack of in-depth studies that explore the element distribution of KV cache to understand the hardness and limitation of KV cache quantization. To fill the gap, we conducted a comprehensive study on the element distribut
    
[^18]: 球形数据的拟合度和聚类：R和Python中的QuadratiK软件包

    Goodness-of-Fit and Clustering of Spherical Data: the QuadratiK package in R and Python

    [https://arxiv.org/abs/2402.02290](https://arxiv.org/abs/2402.02290)

    QuadratiK软件包是一个在R和Python中实现的数据分析工具，它提供了一套全面的拟合度测试和基于核方法的聚类技术，特别适用于处理球形数据。

    

    我们介绍了QuadratiK软件包，该软件包包含了创新的数据分析方法。该软件包在R和Python中实现，提供了一套全面的适应度拟合测试和基于核方法的二次距离的聚类技术，从而弥合了统计学和机器学习文献之间的差距。我们的软件实现了单样本、双样本和k样本适应度拟合测试，提供了一种高效且数学上合理的方法来评估概率分布的拟合度。我们的软件扩展了功能，包括基于泊松核密度的$d$维球上均匀性测试，以及从泊松核密度中生成随机样本的算法。特别值得注意的是，我们的软件还包括一种针对球形数据而特别量身定制的独特聚类算法，该算法利用了球面上基于泊松核密度的混合模型。同时，我们的软件还包括其他图形功能。

    We introduce the QuadratiK package that incorporates innovative data analysis methodologies. The presented software, implemented in both R and Python, offers a comprehensive set of goodness-of-fit tests and clustering techniques using kernel-based quadratic distances, thereby bridging the gap between the statistical and machine learning literatures. Our software implements one, two and k-sample tests for goodness of fit, providing an efficient and mathematically sound way to assess the fit of probability distributions. Expanded capabilities of our software include supporting tests for uniformity on the $d$-dimensional Sphere based on Poisson kernel densities, and algorithms for generating random samples from Poisson kernel densities. Particularly noteworthy is the incorporation of a unique clustering algorithm specifically tailored for spherical data that leverages a mixture of Poisson-kernel-based densities on the sphere. Alongside this, our software includes additional graphical func
    
[^19]: 从儿童视角进行自监督学习的视频表示

    Self-supervised learning of video representations from a child's perspective

    [https://arxiv.org/abs/2402.00300](https://arxiv.org/abs/2402.00300)

    本研究从儿童的视角进行自监督学习，通过长时间的头戴式摄像记录训练视频模型，结果表明这些模型在促进从少量样本中学习行动概念方面非常有效。

    

    儿童通过几年的自我视觉经验学习到了强大的世界内部模型。这些内部模型能否通过儿童的视觉体验和通用的自监督学习算法来学习，还是需要强大的归纳偏差？最近，在收集大规模、纵向的发展现实视频数据集以及通用的自监督学习算法的进展使我们能够开始探讨这个本质与养育之间的问题。然而，现有的工作通常关注基于图像的自监督学习算法和可以从静态图像中学习的视觉能力（例如目标识别），从而忽略了世界的时间性质。为了弥合这一差距，我们在一个儿童早期发展阶段（6-31个月）从儿童的头戴式摄像记录中训练自监督视频模型。所得到的模型在促进从少量样本中学习行动概念方面非常有效。

    Children learn powerful internal models of the world around them from a few years of egocentric visual experience. Can such internal models be learned from a child's visual experience with highly generic learning algorithms or do they require strong inductive biases? Recent advances in collecting large-scale, longitudinal, developmentally realistic video datasets and generic self-supervised learning (SSL) algorithms are allowing us to begin to tackle this nature vs. nurture question. However, existing work typically focuses on image-based SSL algorithms and visual capabilities that can be learned from static images (e.g. object recognition), thus ignoring temporal aspects of the world. To close this gap, here we train self-supervised video models on longitudinal, egocentric headcam recordings collected from a child over a two year period in their early development (6-31 months). The resulting models are highly effective at facilitating the learning of action concepts from a small numbe
    
[^20]: LLMs的两面性：Jekyll博士与Hyde先生

    Dr. Jekyll and Mr. Hyde: Two Faces of LLMs

    [https://arxiv.org/abs/2312.03853](https://arxiv.org/abs/2312.03853)

    本研究通过让ChatGPT和Bard冒充复杂人物角色，绕过了安全机制和专门训练程序，展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。

    

    仅仅一年前，我们目睹了大型语言模型（LLMs）的使用增加，尤其是在结合像聊天机器人助手之类的应用时。为了防止这些助手产生不当回应，我们实施了安全机制和专门的训练程序。在这项工作中，我们通过让ChatGPT和Bard（以及在某种程度上是Bing chat）冒充复杂人物角色，绕过了这些措施，这些角色与它们本应成为的真实助手的特征相反。我们首先创造出这些人物角色的复杂传记，然后在同一聊天机器人中使用它们进行新的对话。我们的对话采用角色扮演风格，以获得助手不被允许提供的回应。通过使用人物角色，我们展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。这项工作表明，通过使用对抗性pe

    arXiv:2312.03853v2 Announce Type: replace-cross  Abstract: Only a year ago, we witnessed a rise in the use of Large Language Models (LLMs), especially when combined with applications like chatbot assistants. Safety mechanisms and specialized training procedures are implemented to prevent improper responses from these assistants. In this work, we bypass these measures for ChatGPT and Bard (and, to some extent, Bing chat) by making them impersonate complex personas with opposite characteristics as those of the truthful assistants they are supposed to be. We start by creating elaborate biographies of these personas, which we then use in a new session with the same chatbots. Our conversation followed a role-play style to get the response the assistant was not allowed to provide. By making use of personas, we show that the response that is prohibited is actually provided, making it possible to obtain unauthorized, illegal, or harmful information. This work shows that by using adversarial pe
    
[^21]: ServerlessLLM：增强本地化的用于大型语言模型的无服务器推理系统

    ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models. (arXiv:2401.14351v1 [cs.LG])

    [http://arxiv.org/abs/2401.14351](http://arxiv.org/abs/2401.14351)

    ServerlessLLM是一种用于大型语言模型的增强本地化无服务器推理系统，通过优化检查点加载、本地化推理和服务器分配来实现高效且低延迟的推理过程。

    

    本文介绍了ServerlessLLM，一种增强本地化的用于大型语言模型(LLM)的无服务器推理系统。ServerlessLLM利用GPU服务器上可用的存储和内存设备的大容量和带宽，从而减少昂贵的远程检查点下载并实现高效的检查点加载。ServerlessLLM通过三个主要贡献实现了这一目标：(i)通过一种新颖的加载优化检查点格式设计和高效的多级检查点加载系统实现快速LLM检查点加载；(ii)利用本地化推理和实时迁移，使ServerlessLLM能够在保持低延迟的同时有效地实现本地化驱动的服务器分配；(iii)本地化感知的服务器分配，使ServerlessLLM能够评估集群中每个服务器的状态，并有效地安排模型启动时间以充分利用本地检查点位置。我们进行了全面的实验，包括微基准测试和大规模语言模型评估，验证了ServerlessLLM的有效性和性能优势。

    This paper presents ServerlessLLM, a locality-enhanced serverless inference system for Large Language Models (LLMs). ServerlessLLM exploits the substantial capacity and bandwidth of storage and memory devices available on GPU servers, thereby reducing costly remote checkpoint downloads and achieving efficient checkpoint loading. ServerlessLLM achieves this through three main contributions: (i) fast LLM checkpoint loading via a novel loading-optimized checkpoint format design, coupled with an efficient multi-tier checkpoint loading system; (ii) locality-driven LLM inference with live migration, which allows ServerlessLLM to effectively achieve locality-driven server allocation while preserving the low latency of ongoing LLM inference; and (iii) locality-aware server allocation, enabling ServerlessLLM to evaluate the status of each server in a cluster and effectively schedule model startup time to capitalize on local checkpoint placement. Our comprehensive experiments, which include micr
    
[^22]: 相关随机向量的检测

    Detection of Correlated Random Vectors. (arXiv:2401.13429v1 [cs.IT])

    [http://arxiv.org/abs/2401.13429](http://arxiv.org/abs/2401.13429)

    本文研究了判断两个标准正态随机向量是否相关的问题，提出了一种新的方法来评估似然比的二阶矩，并发现了与整数分割函数之间的联系。

    

    在本文中，我们研究了判断两个标准正态随机向量$\mathsf{X}\in\mathbb{R}^{n}$和$\mathsf{Y}\in\mathbb{R}^{n}$是否相关的问题。这被表述为一个假设检验问题，在零假设下，这些向量是统计独立的，而在备择假设下，$\mathsf{X}$和随机均匀置换的$\mathsf{Y}$是具有相关系数$\rho$的。我们分析了信息论上不可能和可能的最优测试阈值，作为$n$和$\rho$的函数。为了得出我们的信息论下界，我们开发了一种利用正交多项式展开来评估似然比的二阶矩的新技术，该技术揭示了与整数分割函数之间的一个令人惊讶的联系。我们还研究了上述设置的多维泛化，其中我们观察到两个数据库/矩阵，而不是两个向量。

    In this paper, we investigate the problem of deciding whether two standard normal random vectors $\mathsf{X}\in\mathbb{R}^{n}$ and $\mathsf{Y}\in\mathbb{R}^{n}$ are correlated or not. This is formulated as a hypothesis testing problem, where under the null hypothesis, these vectors are statistically independent, while under the alternative, $\mathsf{X}$ and a randomly and uniformly permuted version of $\mathsf{Y}$, are correlated with correlation $\rho$. We analyze the thresholds at which optimal testing is information-theoretically impossible and possible, as a function of $n$ and $\rho$. To derive our information-theoretic lower bounds, we develop a novel technique for evaluating the second moment of the likelihood ratio using an orthogonal polynomials expansion, which among other things, reveals a surprising connection to integer partition functions. We also study a multi-dimensional generalization of the above setting, where rather than two vectors we observe two databases/matrices
    
[^23]: 预测动态图的结构

    Predicting the structure of dynamic graphs. (arXiv:2401.04280v1 [cs.LG])

    [http://arxiv.org/abs/2401.04280](http://arxiv.org/abs/2401.04280)

    本文提出了一种预测动态图结构的方法，利用时间序列方法预测未来时间点的节点度，并结合通量平衡分析方法获得未来图的结构，评估了该方法在合成和真实数据集上的实用性和适用性。

    

    动态图嵌入、归纳和增量学习有助于预测任务，如节点分类和链接预测。然而，从图的时间序列中预测未来时间步的图结构，允许有新节点，并没有受到太多关注。在本文中，我们提出了一种这样的方法。我们使用时间序列方法预测未来时间点的节点度，并将其与通量平衡分析（一种在生物化学中使用的线性规划方法）结合起来，以获得未来图的结构。此外，我们探索了不同参数值的预测图分布。我们使用合成和真实数据集评估了该方法，并展示了其实用性和适用性。

    Dynamic graph embeddings, inductive and incremental learning facilitate predictive tasks such as node classification and link prediction. However, predicting the structure of a graph at a future time step from a time series of graphs, allowing for new nodes has not gained much attention. In this paper, we present such an approach. We use time series methods to predict the node degree at future time points and combine it with flux balance analysis -- a linear programming method used in biochemistry -- to obtain the structure of future graphs. Furthermore, we explore the predictive graph distribution for different parameter values. We evaluate this method using synthetic and real datasets and demonstrate its utility and applicability.
    
[^24]: 使用随机子空间和Dirichlet过程混合模型的子抽样集合进行无监督异常检测

    Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures. (arXiv:2401.00773v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.00773](http://arxiv.org/abs/2401.00773)

    提出一种基于随机子空间和子抽样集合的Dirichlet过程高斯混合模型的无监督异常检测方法，提高了计算效率和检测器的鲁棒性。

    

    概率混合模型被认为是一种有价值的工具，用于无监督异常检测，因为它们具有解释性，并且在统计原理上有直观基础。在这个框架内，Dirichlet过程混合模型作为传统有限混合模型在聚类和异常检测任务中的一个引人注目的替代选择。然而，尽管它们明显具有优势，但在无监督异常检测中广泛采用Dirichlet过程混合模型受到与构建检测器过程中的计算效率和对异常值的敏感性有关的挑战的阻碍。为了解决这些挑战，我们提出了一种基于Dirichlet过程高斯混合模型集合的新型异常检测方法。所提出的方法是一种完全无监督的算法，利用了随机子空间和子抽样集合，不仅确保了高效计算，还增强了结果异常检测器的鲁棒性。

    Probabilistic mixture models are acknowledged as a valuable tool for unsupervised outlier detection owing to their interpretability and intuitive grounding in statistical principles. Within this framework, Dirichlet process mixture models emerge as a compelling alternative to conventional finite mixture models for both clustering and outlier detection tasks. However, despite their evident advantages, the widespread adoption of Dirichlet process mixture models in unsupervised outlier detection has been hampered by challenges related to computational inefficiency and sensitivity to outliers during the construction of detectors. To tackle these challenges, we propose a novel outlier detection method based on ensembles of Dirichlet process Gaussian mixtures. The proposed method is a fully unsupervised algorithm that capitalizes on random subspace and subsampling ensembles, not only ensuring efficient computation but also enhancing the robustness of the resulting outlier detector. Moreover,
    
[^25]: 通过张量网络生成连续数据的生成学习

    Generative Learning of Continuous Data by Tensor Networks. (arXiv:2310.20498v1 [cs.LG])

    [http://arxiv.org/abs/2310.20498](http://arxiv.org/abs/2310.20498)

    张量网络生成模型一般适用于二进制或类别数据，这篇论文介绍了一种新型张量网络生成模型，它可以用于学习连续数据分布，并展示了该模型在合成和真实数据集上的性能表现。

    

    张量网络除了用于建模多体量子系统外，还成为解决机器学习问题的一类有前景的模型，尤其是在无监督生成学习中。然而，以量子启发式为特点的张量网络生成模型之前主要局限于二进制或类别数据，限制了它们在现实世界建模问题中的效用。我们通过引入一种能够学习包含连续随机变量的分布的新型张量网络生成模型，克服了这一局限。我们首先在矩阵积态的设置下开发了我们的方法，证明了这个模型族能够以任意精度逼近任何相对平滑的概率密度函数的一般表达性定理。然后，我们在几个合成和真实世界数据集上评估了这个模型的性能，发现该模型具有较好的表现。

    Beyond their origin in modeling many-body quantum systems, tensor networks have emerged as a promising class of models for solving machine learning problems, notably in unsupervised generative learning. While possessing many desirable features arising from their quantum-inspired nature, tensor network generative models have previously been largely restricted to binary or categorical data, limiting their utility in real-world modeling problems. We overcome this by introducing a new family of tensor network generative models for continuous data, which are capable of learning from distributions containing continuous random variables. We develop our method in the setting of matrix product states, first deriving a universal expressivity theorem proving the ability of this model family to approximate any reasonably smooth probability density function with arbitrary precision. We then benchmark the performance of this model on several synthetic and real-world datasets, finding that the model 
    
[^26]: 微分水平空间中的格点逼近

    Lattice Approximations in Wasserstein Space. (arXiv:2310.09149v1 [stat.ML])

    [http://arxiv.org/abs/2310.09149](http://arxiv.org/abs/2310.09149)

    本论文研究了在Wasserstein空间中通过离散和分段常数测度进行的结构逼近方法。结果表明，对于满秩的格点按比例缩放后得到的Voronoi分割逼近的测度误差是$O(h)$，逼近的$N$项误差为$O(N^{-\frac1d})$，并且可以推广到非紧支撑测度。

    

    我们考虑在Wasserstein空间$W_p(\mathbb{R}^d)$中通过离散和分段常数测度来对测度进行结构逼近。我们证明，如果一个满秩的格点$\Lambda$按照$h\in(0,1]$的比例进行缩放，那么基于$h\Lambda$的Voronoi分割得到的测度逼近是$O(h)$，不论$d$或$p$的取值。之后，我们使用覆盖论证证明，对于紧支撑的测度的$N$项逼近是$O(N^{-\frac1d})$，这与最优量化器和经验测度逼近在大多数情况下已知的速率相匹配。最后，我们将这些结果推广到非紧支撑测度，要求其具有足够的衰减性质。

    We consider structured approximation of measures in Wasserstein space $W_p(\mathbb{R}^d)$ for $p\in[1,\infty)$ by discrete and piecewise constant measures based on a scaled Voronoi partition of $\mathbb{R}^d$. We show that if a full rank lattice $\Lambda$ is scaled by a factor of $h\in(0,1]$, then approximation of a measure based on the Voronoi partition of $h\Lambda$ is $O(h)$ regardless of $d$ or $p$. We then use a covering argument to show that $N$-term approximations of compactly supported measures is $O(N^{-\frac1d})$ which matches known rates for optimal quantizers and empirical measure approximation in most instances. Finally, we extend these results to noncompactly supported measures with sufficient decay.
    
[^27]: 基于机器学习方法的功能梯度材料增材制造的综述

    Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials. (arXiv:2309.16571v1 [cs.LG])

    [http://arxiv.org/abs/2309.16571](http://arxiv.org/abs/2309.16571)

    该论文综述了基于机器学习方法的功能梯度材料增材制造。功能梯度材料是一类具有平滑性质过渡的高级复合材料，机器学习技术被应用于优化加工参数、提高产品质量和检测制造缺陷。这些方法有望提高零件性能和性质。

    

    增材制造通过实现直接材料连接，革新了复杂零件的制造，并提供了成本效益高的复杂零件制造、减少制造废料以及为制造自动化开启新的可能性等多个优势。其中，功能梯度材料（FGMs）作为一类材料，在提高零件性能和性质方面具有巨大潜力。FGMs是高级复合材料，其性质呈平滑过渡，因此被航空、汽车、生物医学和国防等行业广泛应用。与传统复合材料不同，FGMs中的成分会逐渐变化，从而提高了材料的性能。最近，机器学习技术已经成为制造FGMs的有希望的手段，可以优化加工参数、提高产品质量并检测制造缺陷。

    Additive manufacturing has revolutionized the manufacturing of complex parts by enabling direct material joining and offers several advantages such as cost-effective manufacturing of complex parts, reducing manufacturing waste, and opening new possibilities for manufacturing automation. One group of materials for which additive manufacturing holds great potential for enhancing component performance and properties is Functionally Graded Materials (FGMs). FGMs are advanced composite materials that exhibit smoothly varying properties making them desirable for applications in aerospace, automobile, biomedical, and defense industries. Such composition differs from traditional composite materials, since the location-dependent composition changes gradually in FGMs, leading to enhanced properties. Recently, machine learning techniques have emerged as a promising means for fabrication of FGMs through optimizing processing parameters, improving product quality, and detecting manufacturing defect
    
[^28]: P-ROCKET: 针对时间序列分类的随机卷积核剪枝

    P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification. (arXiv:2309.08499v1 [cs.LG])

    [http://arxiv.org/abs/2309.08499](http://arxiv.org/abs/2309.08499)

    本研究提出了一种名为P-ROCKET的方法，通过在特征选择的角度删除卷积核，从而实现对时间序列分类中的随机卷积核进行剪枝。

    

    在最近几年，两个时间序列分类模型ROCKET和MINIROCKET因其低训练成本和最先进的准确性而受到广泛关注。ROCKET和MINIROCKET利用无需训练的随机一维卷积核，可以快速从时间序列数据中提取特征，从而实现线性分类器的高效拟合。然而，为了全面捕捉有用的特征，需要大量的随机卷积核，这对于资源受限的设备来说是不兼容的。因此，我们设计了一种启发式进化算法S-ROCKET，用于识别和剪枝冗余的卷积核。然而，进化算法本身的特性导致在S-ROCKET中评估卷积核是一个耗时的过程。本文中，与直接评估具有非显著差异的随机卷积核的S-ROCKET不同，我们从特征选择的角度删除卷积核，通过消除序列中的相关连接来实现。

    In recent years, two time series classification models, ROCKET and MINIROCKET, have attracted much attention for their low training cost and state-of-the-art accuracy. Utilizing random 1-D convolutional kernels without training, ROCKET and MINIROCKET can rapidly extract features from time series data, allowing for the efficient fitting of linear classifiers. However, to comprehensively capture useful features, a large number of random kernels are required, which is incompatible for resource-constrained devices. Therefore, a heuristic evolutionary algorithm named S-ROCKET is devised to recognize and prune redundant kernels. Nevertheless, the inherent nature of evolutionary algorithms renders the evaluation of kernels within S-ROCKET an unacceptable time-consuming process. In this paper, diverging from S-ROCKET, which directly evaluates random kernels with nonsignificant differences, we remove kernels from a feature selection perspective by eliminating associating connections in the sequ
    
[^29]: 通过实验数据同化实现对Spalart-Allmaras模型的可普适改进

    Generalizable improvement of the Spalart-Allmaras model through assimilation of experimental data. (arXiv:2309.06679v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2309.06679](http://arxiv.org/abs/2309.06679)

    本研究通过实验数据同化改进了Spalart-Allmaras模型，实现了对分离流体的雷诺平均纳维-斯托克斯解的泛化，提高了计算模型的性能。

    

    本研究旨在利用模型和数据融合改进分离流体的雷诺平均纳维-斯托克斯解的Spalart-Allmaras（SA）闭合模型。特别是，我们的目标是开发模型，不仅能将稀疏的实验数据同化以改善计算模型的性能，还能通过恢复经典的SA行为来推广到未见过的情况。我们使用数据同化，即集合卡尔曼滤波方法（EnKF），通过将SA模型的系数校准到分离流体中来实现我们的目标。通过参数化产生、扩散和破坏项，实现了一种全面的校准策略。该校准依赖于采集的分离流体速度剖面、壁擦力和压力系数的实验数据的同化。尽管仅使用了来自单一流动条件（环绕一个背面台阶）的观测数据，但重新校准的SA模型表现出泛化能力。

    This study focuses on the use of model and data fusion for improving the Spalart-Allmaras (SA) closure model for Reynolds-averaged Navier-Stokes solutions of separated flows. In particular, our goal is to develop of models that not-only assimilate sparse experimental data to improve performance in computational models, but also generalize to unseen cases by recovering classical SA behavior. We achieve our goals using data assimilation, namely the Ensemble Kalman Filtering approach (EnKF), to calibrate the coefficients of the SA model for separated flows. A holistic calibration strategy is implemented via a parameterization of the production, diffusion, and destruction terms. This calibration relies on the assimilation of experimental data collected velocity profiles, skin friction, and pressure coefficients for separated flows. Despite using of observational data from a single flow condition around a backward-facing step (BFS), the recalibrated SA model demonstrates generalization to o
    
[^30]: Belebele基准数据集：122种语言变体的并行阅读理解数据集

    The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants. (arXiv:2308.16884v1 [cs.CL])

    [http://arxiv.org/abs/2308.16884](http://arxiv.org/abs/2308.16884)

    Belebele是一个包含122种语言变体的多选机器阅读理解数据集，可用于评估文本模型在高、中和低资源语言中的性能。尽管英语为中心的大型语言模型在跨语言转移方面表现良好，但小型多语言遮蔽语言模型在其他语言上表现更佳。

    

    我们提出了Belebele，一个包含122种语言变体的多选机器阅读理解（MRC）数据集。该数据集极大地扩展了自然语言理解（NLU）基准的语言覆盖范围，使得可以评估文本模型在高、中和低资源语言中的性能。每个问题都基于Flores-200数据集中的一个短篇文章，并提供了四个多选答案。问题经过精心策划，以区分具有不同通用语言理解水平的模型。单独的英语数据集已经足够困难，可以挑战最先进的语言模型。由于完全并行，该数据集可以直接比较所有语言的模型性能。我们使用该数据集评估多语言遮蔽语言模型（MLMs）和大型语言模型（LLMs）的能力。我们展示了广泛的结果，并发现尽管英语为中心的LLMs之间存在显著的跨语言转移，但小型MLMs在其他语言上的表现相对较好。

    We present Belebele, a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. Significantly expanding the language coverage of natural language understanding (NLU) benchmarks, this dataset enables the evaluation of text models in high-, medium-, and low-resource languages. Each question is based on a short passage from the Flores-200 dataset and has four multiple-choice answers. The questions were carefully curated to discriminate between models with different levels of general language comprehension. The English dataset on its own proves difficult enough to challenge state-of-the-art language models. Being fully parallel, this dataset enables direct comparison of model performance across all languages. We use this dataset to evaluate the capabilities of multilingual masked language models (MLMs) and large language models (LLMs). We present extensive results and find that despite significant cross-lingual transfer in English-centric LLMs, much small
    
[^31]: 广义持续类别发现

    Generalized Continual Category Discovery. (arXiv:2308.12112v1 [cs.LG])

    [http://arxiv.org/abs/2308.12112](http://arxiv.org/abs/2308.12112)

    本研究提出了一种广义持续类别发现（GCCD）的框架，用于在现实生活场景中同时处理新的和已知的类别，并且利用持续的无监督学习方法来发现它们。通过实验证明现有方法无法处理后续任务中的无标记样本。

    

    大多数持续学习（CL）方法推动着监督学习设置的极限，其中一个智能体期望学习新的标记任务而不会忘记先前的知识。然而，这些设置与现实生活场景不太吻合，其中学习智能体可以访问大量的无标记数据，包括全新（完全无标记）类别和已知类别的示例。受到广义类别发现（GCD）的启发，我们引入了一个新的框架来放松这个假设。确切地说，在任何任务中，我们允许存在新的和已知的类别，并且必须使用持续版本的无监督学习方法来发现它们。我们称这种设置为广义持续类别发现（GCCD）。它统一了CL和GCD，弥合了合成基准和现实生活场景之间的差距。通过一系列实验，我们发现现有的方法无法从后续任务中积累知识，其中包含无标记样本。

    Most of Continual Learning (CL) methods push the limit of supervised learning settings, where an agent is expected to learn new labeled tasks and not forget previous knowledge. However, these settings are not well aligned with real-life scenarios, where a learning agent has access to a vast amount of unlabeled data encompassing both novel (entirely unlabeled) classes and examples from known classes. Drawing inspiration from Generalized Category Discovery (GCD), we introduce a novel framework that relaxes this assumption. Precisely, in any task, we allow for the existence of novel and known classes, and one must use continual version of unsupervised learning methods to discover them. We call this setting Generalized Continual Category Discovery (GCCD). It unifies CL and GCD, bridging the gap between synthetic benchmarks and real-life scenarios. With a series of experiments, we present that existing methods fail to accumulate knowledge from subsequent tasks in which unlabeled samples of 
    
[^32]: 具有覆盖保证的分摊变分推断

    Amortized Variational Inference with Coverage Guarantees. (arXiv:2305.14275v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2305.14275](http://arxiv.org/abs/2305.14275)

    提出了一种称为CANVI的方法，通过构建一致化预测器并使用预测效率进行比较，来提供具有保证的后验近似结果。该方法可以快速计算，易于实现，并且对于候选近似器的设计决策无需关注。此外，CANVI能够在无似然的情况下使用。

    

    分摊变分推断产生了一个后验近似，可以快速计算给定任何新观测。然而，对于这些近似后验的质量，很少有保证。我们提出了一种称为CANVI的一致化分摊神经变分推断的方法，该方法可扩展、易于实现，并提供了保证的边际覆盖。给定一系列候选的分摊后验近似器，CANVI基于每个候选构建一致化预测器，使用预测效率这个度量标准比较预测器，并返回最高效的预测器。CANVI确保所得到的预测器构建的区域以用户指定的概率水平包含真实值。CANVI对候选近似器的制定决策不关心，并且只需要访问前向模型的样本，可以在无似然的情况下使用。我们证明了预测效率的下界。

    Amortized variational inference produces a posterior approximation that can be rapidly computed given any new observation. Unfortunately, there are few guarantees about the quality of these approximate posteriors. We propose Conformalized Amortized Neural Variational Inference (CANVI), a procedure that is scalable, easily implemented, and provides guaranteed marginal coverage. Given a collection of candidate amortized posterior approximators, CANVI constructs conformalized predictors based on each candidate, compares the predictors using a metric known as predictive efficiency, and returns the most efficient predictor. CANVI ensures that the resulting predictor constructs regions that contain the truth with a user-specified level of probability. CANVI is agnostic to design decisions in formulating the candidate approximators and only requires access to samples from the forward model, permitting its use in likelihood-free settings. We prove lower bounds on the predictive efficiency of t
    
[^33]: 使用最小生成树进行聚类：能有多好？

    Clustering with minimum spanning trees: How good can it be?. (arXiv:2303.05679v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.05679](http://arxiv.org/abs/2303.05679)

    本文研究了使用最小生成树（MST）进行分区数据聚类任务的意义程度，并发现MST方法在总体上具有很强的竞争力。此外，通过回顾、研究、扩展和推广现有的MST-based划分方案，我们提出了一些新的和值得注意的方法。总体上，Genie和信息论方法往往优于其他非MST算法，在某些情况下MST方法可能不如其他算法。

    

    最小生成树（MST）在许多模式识别任务中可以提供方便的数据集表示，并且计算相对较快。本文中，我们量化了MST在低维空间的分区数据聚类任务中的意义程度。通过识别最佳（oracle）算法与大量基准数据的专家标签之间的一致性上限，我们发现MST方法在总体上具有很强的竞争力。接下来，我们不是提出另一个只在有限的示例上表现良好的算法，而是回顾、研究、扩展和推广现有的最新MST-based划分方案。这导致了一些新的和值得注意的方法。总体上，Genie和信息论方法往往优于非MST算法，如k-means，高斯混合，谱聚类，Birch，基于密度和经典层次聚类程序。尽管如此，我们还是发现MST方法在某些情况下可能不如其他算法。

    Minimum spanning trees (MSTs) provide a convenient representation of datasets in numerous pattern recognition activities. Moreover, they are relatively fast to compute. In this paper, we quantify the extent to which they can be meaningful in partitional data clustering tasks in low-dimensional spaces. By identifying the upper bounds for the agreement between the best (oracle) algorithm and the expert labels from a large battery of benchmark data, we discover that MST methods are overall very competitive. Next, instead of proposing yet another algorithm that performs well on a limited set of examples, we review, study, extend, and generalise existing, state-of-the-art MST-based partitioning schemes. This leads to a few new and noteworthy approaches. Overall, Genie and the information-theoretic methods often outperform the non-MST algorithms such as k-means, Gaussian mixtures, spectral clustering, Birch, density-based, and classical hierarchical agglomerative procedures. Nevertheless, we
    
[^34]: 使用深度学习在"Web of Science"中对研究领域进行层次分类

    Hierarchical Classification of Research Fields in the "Web of Science" Using Deep Learning. (arXiv:2302.00390v2 [cs.DL] UPDATED)

    [http://arxiv.org/abs/2302.00390](http://arxiv.org/abs/2302.00390)

    本文提出了一个使用深度学习进行层次分类的系统，可以自动将学术出版物通过抽象进行分类，实现了对研究活动在不同层次结构中的全面分类，并允许跨学科和跨领域的单标签和多标签分类。

    

    本文提出了一个层次分类系统，通过使用抽象将学术出版物自动分类到三级层次标签集（学科、领域、子领域）中，以多类别设置进行分类。该系统可以通过文章的知识生产和引用的影响，对研究活动在所述层次结构中进行全面的分类，并允许这些活动被归为多个类别。该分类系统在Microsoft Academic Graph (版本2018-05-17)的160 million份摘要片段中区分了44个学科、718个领域和1,485个子领域。我们以模块化和分布式方式进行批量训练，以解决和允许跨学科和跨领域的单标签和多标签分类。总共，我们在所有考虑的模型（卷积神经网络，循环神经网络，变形器）中进行了3,140次实验。分类准确率> 90％。

    This paper presents a hierarchical classification system that automatically categorizes a scholarly publication using its abstract into a three-tier hierarchical label set (discipline, field, subfield) in a multi-class setting. This system enables a holistic categorization of research activities in the mentioned hierarchy in terms of knowledge production through articles and impact through citations, permitting those activities to fall into multiple categories. The classification system distinguishes 44 disciplines, 718 fields and 1,485 subfields among 160 million abstract snippets in Microsoft Academic Graph (version 2018-05-17). We used batch training in a modularized and distributed fashion to address and allow for interdisciplinary and interfield classifications in single-label and multi-label settings. In total, we have conducted 3,140 experiments in all considered models (Convolutional Neural Networks, Recurrent Neural Networks, Transformers). The classification accuracy is > 90%
    
[^35]: 通过子序列相似性生成序列：理论及其在无人机识别中的应用

    Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification. (arXiv:2301.08403v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.08403](http://arxiv.org/abs/2301.08403)

    本文探究了一种单次生成模型的多样性，主要聚焦于子序列相似性如何影响整个序列相似性，并通过生成子序列相似的序列来增强数据集。

    

    生成人工合成序列的能力在广泛的应用中至关重要，而深度学习架构和生成框架的最新进展已经极大地促进了这一过程。本文使用一种单次生成模型来采样，通过相似性生成子序列，并证明了子序列相似性对整个序列相似性的影响，给出了相应的界限。我们使用一种一次性生成模型来从单个序列的范围内取样，并生成子序列相似的序列，证明了数据集增强方面的实用性。

    The ability to generate synthetic sequences is crucial for a wide range of applications, and recent advances in deep learning architectures and generative frameworks have greatly facilitated this process. Particularly, unconditional one-shot generative models constitute an attractive line of research that focuses on capturing the internal information of a single image or video to generate samples with similar contents. Since many of those one-shot models are shifting toward efficient non-deep and non-adversarial approaches, we examine the versatility of a one-shot generative model for augmenting whole datasets. In this work, we focus on how similarity at the subsequence level affects similarity at the sequence level, and derive bounds on the optimal transport of real and generated sequences based on that of corresponding subsequences. We use a one-shot generative model to sample from the vicinity of individual sequences and generate subsequence-similar ones and demonstrate the improvem
    
[^36]: 规范化聚类准确度：一种非对称的外部聚类有效度量

    Normalised clustering accuracy: An asymmetric external cluster validity measure. (arXiv:2209.02935v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.02935](http://arxiv.org/abs/2209.02935)

    本文提出了一种非对称的外部聚类有效度量方法，旨在区分不同任务类型上表现良好和系统性表现不佳的聚类算法。与传统的内部度量不同，该方法利用参考真实分组进行评估，并弥补了现有方法在最坏情况下的误差。

    

    没有一个最好的聚类算法，我们仍然希望能够区分出在某些任务类型上表现良好和系统性表现不佳的方法。传统上，聚类算法使用内部或外部有效度量进行评估。内部度量量化所得分区的不同方面，例如，簇紧密度的平均程度或点的可分离性。然而，它们的有效性是有问题的，因为它们促使的聚类有时可能是无意义的。另一方面，外部度量将算法的输出与由专家提供的参考真实分组进行比较。在本文中，我们认为常用的经典分区相似性评分，例如规范化互信息、Fowlkes-Mallows或调整兰德指数，缺少一些可取的属性，例如，它们不能正确识别最坏情况，也不易解释。

    There is no, nor will there ever be, single best clustering algorithm, but we would still like to be able to distinguish between methods which work well on certain task types and those that systematically underperform. Clustering algorithms are traditionally evaluated using either internal or external validity measures. Internal measures quantify different aspects of the obtained partitions, e.g., the average degree of cluster compactness or point separability. Yet, their validity is questionable, because the clusterings they promote can sometimes be meaningless. External measures, on the other hand, compare the algorithms' outputs to the reference, ground truth groupings that are provided by experts. In this paper, we argue that the commonly-used classical partition similarity scores, such as the normalised mutual information, Fowlkes-Mallows, or adjusted Rand index, miss some desirable properties, e.g., they do not identify worst-case scenarios correctly or are not easily interpretab
    

