# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models](https://arxiv.org/abs/2403.17933) | SLEDGE是第一个使用生成模型训练的车辆运动规划生成模拟器，引入了新颖的栅格到矢量自编码器（RVAE）以及Diffusion Transformer来生成智能体和车道图，从而实现更好的模拟控制。 |
| [^2] | [Automatic Outlier Rectification via Optimal Transport](https://arxiv.org/abs/2403.14067) | 提出了一种自动异常值矫正机制，通过将矫正和估计集成到联合优化框架中，利用最优输运和凹成本函数来检测和移除异常值，并选择最佳分布来执行估计任务 |
| [^3] | [Why Online Reinforcement Learning is Causal](https://arxiv.org/abs/2403.04221) | 强化学习和因果建模相互补充，论文主要指出在线学习环境下，条件概率具有因果性，离线RL是因果学习潜力最大的环境。 |
| [^4] | [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](https://arxiv.org/abs/2403.02178) | 引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果 |
| [^5] | [Resilience of Entropy Model in Distributed Neural Networks](https://arxiv.org/abs/2403.00942) | 本文研究了分布式神经网络中熵模型对有意干扰和无意干扰的韧性，通过实验证明了熵模型的韧性。 |
| [^6] | [Behavioral Refinement via Interpolant-based Policy Diffusion](https://arxiv.org/abs/2402.16075) | 使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。 |
| [^7] | [BeTAIL: Behavior Transformer Adversarial Imitation Learning from Human Racing Gameplay](https://arxiv.org/abs/2402.14194) | BeTAIL结合了行为转换器（BeT）策略和在线对抗性模仿学习（AIL），以学习从人类专家示范中学到的顺序决策过程，并纠正环境中的分布转移。 |
| [^8] | [Adjustment Identification Distance: A gadjid for Causal Structure Learning](https://arxiv.org/abs/2402.08616) | gadjid软件包提供了一种用于因果结构学习的调整识别距离，通过引入框架来计算因果距离，这些距离能够高效评估因果发现算法学习的图形，并且在处理大规模图形时具有较高的性能。 |
| [^9] | [Predictive representations: building blocks of intelligence](https://arxiv.org/abs/2402.06590) | 预测性表征可能是智能的多功能基石。 |
| [^10] | [The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise](https://arxiv.org/abs/2401.07844) | 本文通过使用ODE方法，将稳定性的Borkar-Meyn定理从鞅差异噪声设定拓展到马尔可夫噪声设定，提高了其在离策略强化学习中的适用性。 |
| [^11] | [Spectral State Space Models](https://arxiv.org/abs/2312.06837) | 本文提出了一种称为光谱状态空间模型的序列预测架构，通过学习具有光谱滤波算法的线性动态系统实现。这些模型具有可证明的鲁棒性和固定卷积滤波器，适用于需要非常长程记忆的预测任务。 |
| [^12] | [A Matter of Annotation: An Empirical Study on In Situ and Self-Recall Activity Annotations from Wearable Sensors](https://arxiv.org/abs/2305.08752) | 不同的标记方法对数据质量和深度学习分类器的性能有直接影响，原位方法产生的标签较少但更精确。 |
| [^13] | [Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models.](http://arxiv.org/abs/2401.13537) | 本文提出了一种称为遮蔽粒子建模（MPM）的自监督方法，用于学习高能物理科学数据中无序输入的通用表示。该方法通过预训练学习置换不变的函数，在构建适用于多种任务的高能物理基础模型方面具有潜力。 |
| [^14] | [Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge.](http://arxiv.org/abs/2401.13098) | 通过考虑航运通量密度、港口距离、贸易流量和交通枢纽的中心性指标等因素，本研究开发了一个受物理启发的模型来预测海事航运流量，并用于指导全球交通网络中入侵物种的风险评估和管理。 |
| [^15] | [Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach.](http://arxiv.org/abs/2401.10747) | 本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。 |
| [^16] | [Generalizable Sleep Staging via Multi-level Domain Alignment.](http://arxiv.org/abs/2401.05363) | 本文提出了一种通用的睡眠分期方法，通过引入域泛化概念，结合多级特征对齐的思想，提高了模型对未见过数据集的泛化能力。 |
| [^17] | [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning.](http://arxiv.org/abs/2401.01325) | 本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。 |
| [^18] | [Towards Foundation Models for Learning on Tabular Data.](http://arxiv.org/abs/2310.07338) | 本文提出了Tabular Foundation Models (TabFMs)，通过利用生成型表格学习的潜力，采用预训练的大规模语言模型作为基础模型，并在广泛的表格数据集上进行微调，赋予TabFMs深刻的理解和普遍的能力，从而克服了当前可转移的表格模型的限制。 |
| [^19] | [Are Large Language Models Post Hoc Explainers?.](http://arxiv.org/abs/2310.05797) | 这项工作提出了第一个研究大型语言模型（LLMs）解释其他预测模型有效性的框架，并且提出了多个提示策略，填补了当前对于LLMs在解释其他模型行为方面的缺失。 |
| [^20] | [A Long Way to Go: Investigating Length Correlations in RLHF.](http://arxiv.org/abs/2310.03716) | 这篇论文通过研究RLHF中奖励和长度的关系，发现优化响应长度是RLHF在提高模型性能方面的一个重要因素。 |
| [^21] | [Chunking: Forgetting Matters in Continual Learning even without Changing Tasks.](http://arxiv.org/abs/2310.02206) | 分块是连续学习的重要组成部分，占据实验中离线学习性能下降的约一半。当前的连续学习算法没有解决分块问题，只有在数据分布没有变化时表现与普通SGD训练相仿。 |
| [^22] | [Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP.](http://arxiv.org/abs/2310.00927) | 本文研究了CLIP中的可转移表示学习和零样本传递，提出了一个新的CLIP类型方法，在基准数据集上取得了更好的性能。 |
| [^23] | [Deep Learning Safety Concerns in Automated Driving Perception.](http://arxiv.org/abs/2309.03774) | 本研究旨在通过引入安全考虑作为结构元素，以系统综合的方式确保基于深度神经网络的自动驾驶系统的安全性。这一概念不仅与现有的安全标准相契合，还为AI安全相关的学术出版物和标准提供了新的启示。 |
| [^24] | [Generalized Continual Category Discovery.](http://arxiv.org/abs/2308.12112) | 本研究提出了一种广义持续类别发现（GCCD）的框架，用于在现实生活场景中同时处理新的和已知的类别，并且利用持续的无监督学习方法来发现它们。通过实验证明现有方法无法处理后续任务中的无标记样本。 |
| [^25] | [Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding.](http://arxiv.org/abs/2306.06094) | 本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。 |
| [^26] | [SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks.](http://arxiv.org/abs/2302.13939) | 本论文提出了一种称之为SpikeGPT的生成语言模型，使用二进制、事件驱动脉冲激活单元进行训练，克服了SNN训练中的挑战性。该模型可以用于大规模语言生成任务。 |
| [^27] | [Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding with Luhmann's Functional Theory of Communication.](http://arxiv.org/abs/2302.03460) | 本文提出了一个更对话式的解释模型，弥合可解释人工智能与人类理解之间的差距，以创建更有效和广泛应用的人工智能系统。 |
| [^28] | [Fairness-aware Vision Transformer via Debiased Self-Attention.](http://arxiv.org/abs/2301.13803) | 这篇论文提出了一种基于去偏自注意力的公平感知视觉变换器框架，通过消除与敏感属性相关的虚假特征来减轻偏见，并利用对抗性示例来定位和屏蔽这些特征。 |

# 详细

[^1]: SLEDGE: 使用生成模型合成驾驶智能体的模拟环境

    SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models

    [https://arxiv.org/abs/2403.17933](https://arxiv.org/abs/2403.17933)

    SLEDGE是第一个使用生成模型训练的车辆运动规划生成模拟器，引入了新颖的栅格到矢量自编码器（RVAE）以及Diffusion Transformer来生成智能体和车道图，从而实现更好的模拟控制。

    

    SLEDGE是第一个基于真实世界驾驶记录训练的车辆运动规划生成模拟器。其核心组件是一个学习模型，能够生成智能体边界框和车道图。该模型的输出作为交通模拟的初始状态。针对SLEDGE待生成的实体的独特特性，例如它们的连接性和每个场景的可变数量，使得大多数现代生成模型在这一任务上的朴素应用变得不简单。因此，我们除了对现有车道图表示进行系统研究外，还引入了一种新颖的栅格到矢量自编码器（RVAE）。它将智能体和车道图编码为栅格化潜在映射中的不同通道。这有助于车道条件下的智能体生成以及使用扩散变换器同时生成车道和智能体。在SLEDGE中使用生成的实体可以更好地控制模拟，例如上采样转弯。

    arXiv:2403.17933v1 Announce Type: cross  Abstract: SLEDGE is the first generative simulator for vehicle motion planning trained on real-world driving logs. Its core component is a learned model that is able to generate agent bounding boxes and lane graphs. The model's outputs serve as an initial state for traffic simulation. The unique properties of the entities to be generated for SLEDGE, such as their connectivity and variable count per scene, render the naive application of most modern generative models to this task non-trivial. Therefore, together with a systematic study of existing lane graph representations, we introduce a novel raster-to-vector autoencoder (RVAE). It encodes agents and the lane graph into distinct channels in a rasterized latent map. This facilitates both lane-conditioned agent generation and combined generation of lanes and agents with a Diffusion Transformer. Using generated entities in SLEDGE enables greater control over the simulation, e.g. upsampling turns 
    
[^2]: 通过最优输运的自动异常值矫正

    Automatic Outlier Rectification via Optimal Transport

    [https://arxiv.org/abs/2403.14067](https://arxiv.org/abs/2403.14067)

    提出了一种自动异常值矫正机制，通过将矫正和估计集成到联合优化框架中，利用最优输运和凹成本函数来检测和移除异常值，并选择最佳分布来执行估计任务

    

    在本文中，我们提出了一个新颖的概念框架，使用具有凹成本函数的最优输运来检测异常值。传统的异常值检测方法通常使用两阶段流程：首先检测并移除异常值，然后在清洁数据上执行估计。然而，这种方法并没有将异常值移除与估计任务联系起来，留下了改进的空间。为了解决这一局限性，我们提出了一种自动异常值矫正机制，将矫正和估计集成到一个联合优化框架中。我们首先利用具有凹成本函数的最优输运距离来构建概率分布空间中的矫正集合。然后，我们选择在矫正集合中的最佳分布来执行估计任务。值得注意的是，我们在本文中引入的凹成本函数是使我们的估计器具有关键性的因素。

    arXiv:2403.14067v1 Announce Type: cross  Abstract: In this paper, we propose a novel conceptual framework to detect outliers using optimal transport with a concave cost function. Conventional outlier detection approaches typically use a two-stage procedure: first, outliers are detected and removed, and then estimation is performed on the cleaned data. However, this approach does not inform outlier removal with the estimation task, leaving room for improvement. To address this limitation, we propose an automatic outlier rectification mechanism that integrates rectification and estimation within a joint optimization framework. We take the first step to utilize an optimal transport distance with a concave cost function to construct a rectification set in the space of probability distributions. Then, we select the best distribution within the rectification set to perform the estimation task. Notably, the concave cost function we introduced in this paper is the key to making our estimator e
    
[^3]: 在线强化学习为何具有因果性

    Why Online Reinforcement Learning is Causal

    [https://arxiv.org/abs/2403.04221](https://arxiv.org/abs/2403.04221)

    强化学习和因果建模相互补充，论文主要指出在线学习环境下，条件概率具有因果性，离线RL是因果学习潜力最大的环境。

    

    强化学习（RL）和因果建模自然互补。因果建模的目标是预测在环境中进行干预的效果，而强化学习的目标是选择最大化代理从环境中接收的奖励的干预。强化学习包括用于估计因果关系的两个最强大信息源：时间顺序和对环境进行操作的能力。本文研究了我们可以期望在哪些强化学习设置中从因果建模中受益，以及如何受益。在线学习中，代理有能力直接与环境进行交互，并从探索中学习。我们的主要论点是，在在线学习中，条件概率是因果的，因此离线RL是因果学习有潜力产生差异的环境。基本上，原因在于当代理与环境互动时，代理的行为是由其对环境的认识所推动的。

    arXiv:2403.04221v1 Announce Type: cross  Abstract: Reinforcement learning (RL) and causal modelling naturally complement each other. The goal of causal modelling is to predict the effects of interventions in an environment, while the goal of reinforcement learning is to select interventions that maximize the rewards the agent receives from the environment. Reinforcement learning includes the two most powerful sources of information for estimating causal relationships: temporal ordering and the ability to act on an environment. This paper examines which reinforcement learning settings we can expect to benefit from causal modelling, and how. In online learning, the agent has the ability to interact directly with their environment, and learn from exploring it. Our main argument is that in online learning, conditional probabilities are causal, and therefore offline RL is the setting where causal learning has the most potential to make a difference. Essentially, the reason is that when an a
    
[^4]: 掩面思想:简单地掩盖部分推理步骤可以提高语言模型对数学推理的学习

    Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models

    [https://arxiv.org/abs/2403.02178](https://arxiv.org/abs/2403.02178)

    引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果

    

    在推理任务中，即使是一个轻微的错误也可能导致不准确的结果，从而导致大型语言模型在这些领域的性能不佳。我们提出的方法避免了外部资源，而是依赖于引入对输入的扰动。我们的训练方法随机掩盖了链式思维中的某些标记，这种技术对推理任务特别有效。

    arXiv:2403.02178v1 Announce Type: cross  Abstract: In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain tokens within the chain of thought, a technique we found to be particularly effective for reasoning tasks. When applied to fine-tuning with GSM8K, this method achieved a 5% improvement in accuracy over standard supervised fine-tuning with a few codes modified and no additional labeling effort. Furthermore, it is complementary to existing methods. When integrated with related data augmentation methods, it leads to an average improvement of 3% im
    
[^5]: 分布式神经网络中熵模型的韧性

    Resilience of Entropy Model in Distributed Neural Networks

    [https://arxiv.org/abs/2403.00942](https://arxiv.org/abs/2403.00942)

    本文研究了分布式神经网络中熵模型对有意干扰和无意干扰的韧性，通过实验证明了熵模型的韧性。

    

    分布式深度神经网络（DNNs）已经成为边缘计算系统中减少通信开销而不降低性能的关键技术。最近，熵编码被引入以进一步减少通信开销。其关键思想是将分布式DNN与熵模型联合训练，该模型在推断时间用作边信息，以自适应地将潜在表示编码为具有可变长度的比特流。据我们所知，熵模型的韧性尚未得到研究。因此，在本文中，我们制定并调查了熵模型对有意干扰（例如，对抗性攻击）和无意干扰（例如，天气变化和运动模糊）的韧性。通过对3种不同DNN架构、2个熵模型和4个速率失真权衡因子进行广泛的实验，我们证明了熵模型的韧性

    arXiv:2403.00942v1 Announce Type: cross  Abstract: Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model, which is used as side information during inference time to adaptively encode latent representations into bit streams with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated. As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference (e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur). Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion trade-off factors, we demonstrate that the entropy attacks
    
[^6]: 基于插值的策略扩散的行为细化

    Behavioral Refinement via Interpolant-based Policy Diffusion

    [https://arxiv.org/abs/2402.16075](https://arxiv.org/abs/2402.16075)

    使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。

    

    模仿学习使人工智能代理通过从演示中学习来模仿行为。最近，拥有建模高维度和多模态分布能力的扩散模型在模仿学习任务上表现出色。这些模型通过将动作（或状态）从标准高斯噪声中扩散来塑造策略。然而，要学习的目标策略通常与高斯分布显著不同，这种不匹配可能导致在使用少量扩散步骤（以提高推理速度）和有限数据下性能不佳。这项工作的关键思想是，从比高斯更具信息量的源头开始，可以使扩散方法克服上述限制。我们提供了理论结果、一种新方法和实证发现，展示了使用信息量丰富的源策略的好处。我们的方法，称为BRIDGER，利用了随机性。

    arXiv:2402.16075v1 Announce Type: cross  Abstract: Imitation learning empowers artificial agents to mimic behavior by learning from demonstrations. Recently, diffusion models, which have the ability to model high-dimensional and multimodal distributions, have shown impressive performance on imitation learning tasks. These models learn to shape a policy by diffusing actions (or states) from standard Gaussian noise. However, the target policy to be learned is often significantly different from Gaussian and this mismatch can result in poor performance when using a small number of diffusion steps (to improve inference speed) and under limited data. The key idea in this work is that initiating from a more informative source than Gaussian enables diffusion methods to overcome the above limitations. We contribute both theoretical results, a new method, and empirical findings that show the benefits of using an informative source policy. Our method, which we call BRIDGER, leverages the stochast
    
[^7]: BeTAIL：从人类赛车游戏中学习的行为转换器对抗性模仿学习

    BeTAIL: Behavior Transformer Adversarial Imitation Learning from Human Racing Gameplay

    [https://arxiv.org/abs/2402.14194](https://arxiv.org/abs/2402.14194)

    BeTAIL结合了行为转换器（BeT）策略和在线对抗性模仿学习（AIL），以学习从人类专家示范中学到的顺序决策过程，并纠正环境中的分布转移。

    

    模仿学习是从示范中学习策略而无需手工设计奖励函数的方法。在许多机器人任务中，如自主赛车，被模仿的策略必须对复杂的环境动态和人类决策建模。序列建模非常有效地捕捉运动序列的复杂模式，但在适应新环境或分布转移方面却很难。相反，对抗性模仿学习（AIL）可以缓解这种效应，但在样本效率和处理复杂运动模式方面存在困难。因此，我们提出了BeTAIL：行为转换器对抗性模仿学习，它将来自人类示范的行为转换器（BeT）策略与在线AIL相结合。BeTAIL将一个AIL剩余策略添加到BeT策略中，以建模人类专家的顺序决策过程并纠正分布外状态或环境中的转移。

    arXiv:2402.14194v1 Announce Type: new  Abstract: Imitation learning learns a policy from demonstrations without requiring hand-designed reward functions. In many robotic tasks, such as autonomous racing, imitated policies must model complex environment dynamics and human decision-making. Sequence modeling is highly effective in capturing intricate patterns of motion sequences but struggles to adapt to new environments or distribution shifts that are common in real-world robotics tasks. In contrast, Adversarial Imitation Learning (AIL) can mitigate this effect, but struggles with sample inefficiency and handling complex motion patterns. Thus, we propose BeTAIL: Behavior Transformer Adversarial Imitation Learning, which combines a Behavior Transformer (BeT) policy from human demonstrations with online AIL. BeTAIL adds an AIL residual policy to the BeT policy to model the sequential decision-making process of human experts and correct for out-of-distribution states or shifts in environmen
    
[^8]: Adjustment Identification Distance: 一种用于因果结构学习的调整识别距离

    Adjustment Identification Distance: A gadjid for Causal Structure Learning

    [https://arxiv.org/abs/2402.08616](https://arxiv.org/abs/2402.08616)

    gadjid软件包提供了一种用于因果结构学习的调整识别距离，通过引入框架来计算因果距离，这些距离能够高效评估因果发现算法学习的图形，并且在处理大规模图形时具有较高的性能。

    

    通过因果发现算法学习的图形的评估是困难的：两个图形之间不同的边的数量不能反映出它们在建议因果效应的识别公式方面有何不同。我们引入了一个框架，用于开发图形之间的因果距离，其中包括有向无环图的结构干预距离作为一种特殊情况。我们利用这个框架开发了改进的基于调整的距离，以及对完成的部分有向无环图和因果序列的扩展。我们开发了多项式时间可达性算法来高效计算距离。在我们的gadjid软件包中（在https://github.com/CausalDisco/gadjid上开源），我们提供了我们的距离实现；它们的运行速度比结构干预距离快几个数量级，从而为以前无法扩展的图形尺寸提供了一个因果发现的成功指标。

    Evaluating graphs learned by causal discovery algorithms is difficult: The number of edges that differ between two graphs does not reflect how the graphs differ with respect to the identifying formulas they suggest for causal effects. We introduce a framework for developing causal distances between graphs which includes the structural intervention distance for directed acyclic graphs as a special case. We use this framework to develop improved adjustment-based distances as well as extensions to completed partially directed acyclic graphs and causal orders. We develop polynomial-time reachability algorithms to compute the distances efficiently. In our package gadjid (open source at https://github.com/CausalDisco/gadjid), we provide implementations of our distances; they are orders of magnitude faster than the structural intervention distance and thereby provide a success metric for causal discovery that scales to graph sizes that were previously prohibitive.
    
[^9]: 预测性表征：智能的基石

    Predictive representations: building blocks of intelligence

    [https://arxiv.org/abs/2402.06590](https://arxiv.org/abs/2402.06590)

    预测性表征可能是智能的多功能基石。

    

    适应性行为通常需要预测未来事件。强化学习理论规定了什么样的预测性表征是有用的以及如何计算它们。本文将这些理论观点与认知和神经科学的研究结合起来。我们特别关注继任者表征（SR）及其广义形式，它们不仅被广泛应用于工程工具，也作为大脑功能的模型。这种融合表明特定类型的预测性表征可能是智能的多功能基石。

    Adaptive behavior often requires predicting future events. The theory of reinforcement learning prescribes what kinds of predictive representations are useful and how to compute them. This paper integrates these theoretical ideas with work on cognition and neuroscience. We pay special attention to the successor representation (SR) and its generalizations, which have been widely applied both as engineering tools and models of brain function. This convergence suggests that particular kinds of predictive representations may function as versatile building blocks of intelligence.
    
[^10]: 使用ODE方法进行带有马尔可夫噪声的随机逼近和强化学习

    The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise

    [https://arxiv.org/abs/2401.07844](https://arxiv.org/abs/2401.07844)

    本文通过使用ODE方法，将稳定性的Borkar-Meyn定理从鞅差异噪声设定拓展到马尔可夫噪声设定，提高了其在离策略强化学习中的适用性。

    

    随机逼近是一类通过迭代、增量和随机更新向量的算法，包括随机梯度下降和时序差分学习。分析随机逼近算法的一个主要挑战是确保其稳定性，即证明随机向量迭代几乎必定有界。本文将稳定性的Borkar-Meyn定理从鞅差异噪声设定拓展到马尔可夫噪声设定，大大提高了其在强化学习中的适用性，特别是那些具有线性函数逼近和资格迹的离策略强化学习算法。我们的分析的核心在于少数函数的渐进变化速率下降，这一点由大数定律和常用的V4 Lyapunov漂移条件隐含，并在马尔可夫链是有限且不可约时显然成立。

    Stochastic approximation is a class of algorithms that update a vector iteratively, incrementally, and stochastically, including, e.g., stochastic gradient descent and temporal difference learning. One fundamental challenge in analyzing a stochastic approximation algorithm is to establish its stability, i.e., to show that the stochastic vector iterates are bounded almost surely. In this paper, we extend the celebrated Borkar-Meyn theorem for stability from the Martingale difference noise setting to the Markovian noise setting, which greatly improves its applicability in reinforcement learning, especially in those off-policy reinforcement learning algorithms with linear function approximation and eligibility traces. Central to our analysis is the diminishing asymptotic rate of change of a few functions, which is implied by both a form of strong law of large numbers and a commonly used V4 Lyapunov drift condition and trivially holds if the Markov chain is finite and irreducible.
    
[^11]: 光谱状态空间模型

    Spectral State Space Models

    [https://arxiv.org/abs/2312.06837](https://arxiv.org/abs/2312.06837)

    本文提出了一种称为光谱状态空间模型的序列预测架构，通过学习具有光谱滤波算法的线性动态系统实现。这些模型具有可证明的鲁棒性和固定卷积滤波器，适用于需要非常长程记忆的预测任务。

    

    本文研究了具有长程依赖关系的预测任务的序列建模。我们提出了一种基于学习具有光谱滤波算法的线性动态系统的新形式化状态空间模型（SSMs）。这导致了一种称为光谱状态空间模型的新颖序列预测架构。光谱状态空间模型具有两个主要优势。首先，它们具有可证明的鲁棒性属性，因为它们的性能既不依赖于底层动力学的频谱，也不依赖于问题的维度。其次，这些模型是通过固定的卷积滤波器构建的，不需要学习，同时在理论和实践中仍然优于SSMs。基于光谱过滤算法的Spectral state space models在合成动态系统和各种模态的长程预测任务上进行了评估。这些评估支持了光谱滤波在需要非常长程记忆的任务中的理论优势。

    This paper studies sequence modeling for prediction tasks with long range dependencies. We propose a new formulation for state space models (SSMs) based on learning linear dynamical systems with the spectral filtering algorithm (Hazan et al. (2017)). This gives rise to a novel sequence prediction architecture we call a spectral state space model.   Spectral state space models have two primary advantages. First, they have provable robustness properties as their performance depends on neither the spectrum of the underlying dynamics nor the dimensionality of the problem. Second, these models are constructed with fixed convolutional filters that do not require learning while still outperforming SSMs in both theory and practice.   The resulting models are evaluated on synthetic dynamical systems and long-range prediction tasks of various modalities. These evaluations support the theoretical benefits of spectral filtering for tasks requiring very long range memory.
    
[^12]: 注释问题：来自可穿戴传感器的原位和自我回忆活动注释的实证研究

    A Matter of Annotation: An Empirical Study on In Situ and Self-Recall Activity Annotations from Wearable Sensors

    [https://arxiv.org/abs/2305.08752](https://arxiv.org/abs/2305.08752)

    不同的标记方法对数据质量和深度学习分类器的性能有直接影响，原位方法产生的标签较少但更精确。

    

    人们对从可穿戴传感器中检测人类活动的研究是一个高度活跃的领域，使许多应用受益，从通过健康护理患者的步行监测到健身指导再到简化手工作业流程。我们提出了一项实证研究，比较了在野外数据用户研究中使用的4种不同常用的注释方法。这些方法可以分为用户驱动的、原位注释-即在记录活动之前或期间执行的注释-和回忆方法-参与者在当天结束时追溯地对其数据进行标注。我们的研究表明，不同的标记方法直接影响注释的质量，以及相应数据训练的深度学习分类器的能力。我们注意到，原位方法产生的标签较少，但更精确，而回忆方法产生的标签较多，但不够精确。此外，我们还结合了一本活动日记

    arXiv:2305.08752v2 Announce Type: replace-cross  Abstract: Research into the detection of human activities from wearable sensors is a highly active field, benefiting numerous applications, from ambulatory monitoring of healthcare patients via fitness coaching to streamlining manual work processes. We present an empirical study that compares 4 different commonly used annotation methods utilized in user studies that focus on in-the-wild data. These methods can be grouped in user-driven, in situ annotations - which are performed before or during the activity is recorded - and recall methods - where participants annotate their data in hindsight at the end of the day. Our study illustrates that different labeling methodologies directly impact the annotations' quality, as well as the capabilities of a deep learning classifier trained with the data respectively. We noticed that in situ methods produce less but more precise labels than recall methods. Furthermore, we combined an activity diary
    
[^13]: 基于集合的遮蔽粒子建模：走向自监督高能物理基础模型

    Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models. (arXiv:2401.13537v1 [hep-ph])

    [http://arxiv.org/abs/2401.13537](http://arxiv.org/abs/2401.13537)

    本文提出了一种称为遮蔽粒子建模（MPM）的自监督方法，用于学习高能物理科学数据中无序输入的通用表示。该方法通过预训练学习置换不变的函数，在构建适用于多种任务的高能物理基础模型方面具有潜力。

    

    本文提出了一种称为"遮蔽粒子建模"（MPM）的自监督方法，用于学习高能物理（HEP）科学数据中无序输入的通用、可转移和可重用表示。这项工作提供了一种新颖的方案，通过基于遮蔽建模的预训练来学习集合上的置换不变函数。更一般地，这项工作在构建可以通过自监督学习进行通用预训练并稍后精调用于各种下游任务的HEP大型基础模型方面迈出了一步。在MPM中，集合中的粒子被遮蔽，训练的目标是恢复它们的身份，身份由预训练的向量量化变分自动编码器的离散化标记表示定义。我们研究了该方法在对撞机物理实验中高能喷注样本上的有效性，包括离散化、置换不变性和排序的影响。

    We propose \textit{masked particle modeling} (MPM) as a self-supervised method for learning generic, transferable, and reusable representations on unordered sets of inputs for use in high energy physics (HEP) scientific data. This work provides a novel scheme to perform masked modeling based pre-training to learn permutation invariant functions on sets. More generally, this work provides a step towards building large foundation models for HEP that can be generically pre-trained with self-supervised learning and later fine-tuned for a variety of down-stream tasks. In MPM, particles in a set are masked and the training objective is to recover their identity, as defined by a discretized token representation of a pre-trained vector quantized variational autoencoder. We study the efficacy of the method in samples of high energy jets at collider physics experiments, including studies on the impact of discretization, permutation invariance, and ordering. We also study the fine-tuning capabili
    
[^14]: 通过重力信息驱动的深度学习框架预测非本地物种船舶交通流量和入侵风险

    Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge. (arXiv:2401.13098v1 [cs.LG])

    [http://arxiv.org/abs/2401.13098](http://arxiv.org/abs/2401.13098)

    通过考虑航运通量密度、港口距离、贸易流量和交通枢纽的中心性指标等因素，本研究开发了一个受物理启发的模型来预测海事航运流量，并用于指导全球交通网络中入侵物种的风险评估和管理。

    

    水体中的入侵物种对全球环境和生物多样性构成了重大威胁。由于交通和贸易增加，非本土物种已经引入了新的环境，导致生态系统破坏，并导致农业、林业和渔业方面的经济损失。因此，迫切需要风险评估和管理技术以减轻这些入侵的影响。本研究旨在开发一种新的受物理启发的模型，用于预测海事航运交通流量，并以此指导通过全球交通网络传播的入侵物种风险评估。受国际贸易重力模型的启发，我们的模型考虑了影响船舶活动可能性和影响的各种因素，如航运通量密度、港口之间的距离、贸易流量和交通枢纽的中心性指标。此外，通过分析入侵物种的风险网络，我们为评估和管理入侵提供了全面的框架。

    Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for as
    
[^15]: 缺失模态下的多模态情感分析:一种知识迁移方法

    Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])

    [http://arxiv.org/abs/2401.10747](http://arxiv.org/abs/2401.10747)

    本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。

    

    多模态情感分析旨在通过视觉、语言和声音线索来识别个体表达的情绪。然而，现有研究大多假设在训练和测试过程中所有模态都是可用的，这使得它们的算法容易受到缺失模态的影响。在本文中，我们提出了一种新颖的知识迁移网络，用于在不同模态之间进行翻译，以重构缺失的音频模态。此外，我们还开发了一种跨模态注意机制，以保留重构和观察到的模态的最大信息，用于情感预测。在三个公开数据集上进行的大量实验证明了相对于基线算法的显著改进，并实现了与具有完整多模态监督的先前方法相媲美的结果。

    Multimodal sentiment analysis aims to identify the emotions expressed by individuals through visual, language, and acoustic cues. However, most of the existing research efforts assume that all modalities are available during both training and testing, making their algorithms susceptible to the missing modality scenario. In this paper, we propose a novel knowledge-transfer network to translate between different modalities to reconstruct the missing audio modalities. Moreover, we develop a cross-modality attention mechanism to retain the maximal information of the reconstructed and observed modalities for sentiment prediction. Extensive experiments on three publicly available datasets demonstrate significant improvements over baselines and achieve comparable results to the previous methods with complete multi-modality supervision.
    
[^16]: 通过多级域对齐实现通用的睡眠分期

    Generalizable Sleep Staging via Multi-level Domain Alignment. (arXiv:2401.05363v1 [eess.SP])

    [http://arxiv.org/abs/2401.05363](http://arxiv.org/abs/2401.05363)

    本文提出了一种通用的睡眠分期方法，通过引入域泛化概念，结合多级特征对齐的思想，提高了模型对未见过数据集的泛化能力。

    

    自动睡眠分期对于睡眠评估和疾病诊断至关重要。现有的大多数方法依赖于特定数据集，并且仅适用于相同数据集的未见过的数据集。本文引入了域泛化概念到自动睡眠分期中，并提出了通用的睡眠分期任务，旨在提高模型对未见过的数据集的泛化能力。受到现有的域泛化方法的启发，我们采用特征对齐思想，提出了一种名为SleepDG的框架来解决该问题。考虑到局部显著特征和时序特征对于睡眠分期都很重要，我们提出了一种多级特征对齐，将时代级和序列级特征对齐来学习域不变特征表示。具体而言，我们设计了一种时代级特征对齐方法，对不同睡眠时代的特征分布进行对齐。

    Automatic sleep staging is essential for sleep assessment and disorder diagnosis. Most existing methods depend on one specific dataset and are limited to be generalized to other unseen datasets, for which the training data and testing data are from the same dataset. In this paper, we introduce domain generalization into automatic sleep staging and propose the task of generalizable sleep staging which aims to improve the model generalization ability to unseen datasets. Inspired by existing domain generalization methods, we adopt the feature alignment idea and propose a framework called SleepDG to solve it. Considering both of local salient features and sequential features are important for sleep staging, we propose a Multi-level Feature Alignment combining epoch-level and sequence-level feature alignment to learn domain-invariant feature representations. Specifically, we design an Epoch-level Feature Alignment to align the feature distribution of each single sleep epoch among different 
    
[^17]: 自扩展LLM:无需调整的LLM上下文窗口。

    LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning. (arXiv:2401.01325v1 [cs.CL])

    [http://arxiv.org/abs/2401.01325](http://arxiv.org/abs/2401.01325)

    本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。

    

    本研究揭示了LLM在处理长上下文时的固有能力，而无需进行精调。在训练过程中，训练序列的有限长度可能限制了大型语言模型（LLMs）在推理过程中对长输入序列的应用。在本研究中，我们认为现有的LLMs本身具有处理长上下文的固有能力。基于这一观点，我们建议通过自身扩展LLMs的上下文窗口，以充分利用其固有能力。我们提出了Self-Extend方法来激发LLMs的长上下文处理潜力。基本思想是构建双层注意信息：群组级和邻居级。这两个级别通过原始模型的自注意力计算，这意味着所提方法不需要任何训练。只需修改四行代码，所提方法就可以轻松扩展现有LLMs的上下文窗口，而无需进行任何精调。我们进行了全面的实验证明，结果表明所提方法可以+摘要减掉文章最后一句話

    This work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can 
    
[^18]: 面向基于表格数据的学习的基础模型研究

    Towards Foundation Models for Learning on Tabular Data. (arXiv:2310.07338v1 [cs.LG])

    [http://arxiv.org/abs/2310.07338](http://arxiv.org/abs/2310.07338)

    本文提出了Tabular Foundation Models (TabFMs)，通过利用生成型表格学习的潜力，采用预训练的大规模语言模型作为基础模型，并在广泛的表格数据集上进行微调，赋予TabFMs深刻的理解和普遍的能力，从而克服了当前可转移的表格模型的限制。

    

    基于表格数据的学习支撑着众多实际应用。尽管在开发针对表格数据的有效学习模型方面已经做出了相当大的努力，但目前可转移的表格模型仍然处于初级阶段，要么缺乏直接指令跟随新任务的支持，要么忽视从不同的表格数据集中获取基础知识和能力。在本文中，我们提出了Tabular Foundation Models (TabFMs)来克服这些限制。TabFMs利用生成型表格学习的潜力，采用预训练的大规模语言模型 (LLM) 作为基础模型，并使用经过专门设计的目标在大范围的表格数据集上进行微调。这种方法赋予TabFMs深刻的理解和普遍的能力，对于表格数据的学习至关重要。我们的评估强调了TabFM的有效性：它不仅在零样本和上下文推理等遵循指令的任务中明显出色，

    Learning on tabular data underpins numerous real-world applications. Despite considerable efforts in developing effective learning models for tabular data, current transferable tabular models remain in their infancy, limited by either the lack of support for direct instruction following in new tasks or the neglect of acquiring foundational knowledge and capabilities from diverse tabular datasets. In this paper, we propose Tabular Foundation Models (TabFMs) to overcome these limitations. TabFMs harness the potential of generative tabular learning, employing a pre-trained large language model (LLM) as the base model and fine-tuning it using purpose-designed objectives on an extensive range of tabular datasets. This approach endows TabFMs with a profound understanding and universal capabilities essential for learning on tabular data. Our evaluations underscore TabFM's effectiveness: not only does it significantly excel in instruction-following tasks like zero-shot and in-context inference
    
[^19]: 大型语言模型是事后解释器吗？

    Are Large Language Models Post Hoc Explainers?. (arXiv:2310.05797v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05797](http://arxiv.org/abs/2310.05797)

    这项工作提出了第一个研究大型语言模型（LLMs）解释其他预测模型有效性的框架，并且提出了多个提示策略，填补了当前对于LLMs在解释其他模型行为方面的缺失。

    

    大型语言模型（LLM）越来越被广泛应用于各种自然语言处理（NLP）应用中。最近的一项创新，即上下文学习（ICL），使得LLM能够在推理阶段通过在提示中提供少量示例来学习新任务，从而消除了模型微调的需要。虽然LLM已经被应用于多个领域，但其在解释其他模型行为方面的适用性仍相对未被探索。尽管存在越来越多的新解释技术，但很多技术要求对模型具有白盒访问权限和/或计算成本较高，凸显了下一代事后解释器的需求。在这项工作中，我们提出了第一个研究LLM解释其他预测模型有效性的框架。具体而言，我们提出了一个包含多种提示策略的新颖框架：i）基于扰动的ICL，ii）基于预测的ICL，iii）基于指令的ICL，和iv）基于解释的ICL。

    Large Language Models (LLMs) are increasingly used as powerful tools for a plethora of natural language processing (NLP) applications. A recent innovation, in-context learning (ICL), enables LLMs to learn new tasks by supplying a few examples in the prompt during inference time, thereby eliminating the need for model fine-tuning. While LLMs have been utilized in several applications, their applicability in explaining the behavior of other models remains relatively unexplored. Despite the growing number of new explanation techniques, many require white-box access to the model and/or are computationally expensive, highlighting a need for next-generation post hoc explainers. In this work, we present the first framework to study the effectiveness of LLMs in explaining other predictive models. More specifically, we propose a novel framework encompassing multiple prompting strategies: i) Perturbation-based ICL, ii) Prediction-based ICL, iii) Instruction-based ICL, and iv) Explanation-based I
    
[^20]: 一条漫长之路：探究RLHF中的长度相关性

    A Long Way to Go: Investigating Length Correlations in RLHF. (arXiv:2310.03716v1 [cs.CL])

    [http://arxiv.org/abs/2310.03716](http://arxiv.org/abs/2310.03716)

    这篇论文通过研究RLHF中奖励和长度的关系，发现优化响应长度是RLHF在提高模型性能方面的一个重要因素。

    

    在利用人类反馈进行强化学习（RLHF）来对齐大型语言模型方面取得了巨大成功。开源偏好数据集和奖励模型使得在通用聊天设置之外进行更广泛的实验成为可能，特别是为了使系统在网页问答、摘要和多轮对话等任务中更加“有用”。当优化有用性时，我们一直观察到RLHF会驱使模型产生更长的输出。本文证明了对响应长度进行优化是RLHF在这些设置中取得改进的一个重要因素。首先，我们研究了在针对有用性训练的三个开源偏好数据集上训练的奖励模型的奖励与长度之间的关系。在这里，长度与奖励强烈相关，奖励分数的提高在很大程度上是通过改变输出长度的分布来实现的。然后，我们在RL和奖励模型学习过程中进行干预，看是否能够达到...

    Great successes have been reported using Reinforcement Learning from Human Feedback (RLHF) to align large language models. Open-source preference datasets and reward models have enabled wider experimentation beyond generic chat settings, particularly to make systems more "helpful" for tasks like web question answering, summarization, and multi-turn dialogue. When optimizing for helpfulness, RLHF has been consistently observed to drive models to produce longer outputs. This paper demonstrates that optimizing for response length is a significant factor behind RLHF's reported improvements in these settings. First, we study the relationship between reward and length for reward models trained on three open-source preference datasets for helpfulness. Here, length correlates strongly with reward, and improvements in reward score are driven in large part by shifting the distribution over output lengths. We then explore interventions during both RL and reward model learning to see if we can ach
    
[^21]: 分块：即使在不改变任务的情况下在连续学习中遗忘也很重要

    Chunking: Forgetting Matters in Continual Learning even without Changing Tasks. (arXiv:2310.02206v1 [cs.LG])

    [http://arxiv.org/abs/2310.02206](http://arxiv.org/abs/2310.02206)

    分块是连续学习的重要组成部分，占据实验中离线学习性能下降的约一半。当前的连续学习算法没有解决分块问题，只有在数据分布没有变化时表现与普通SGD训练相仿。

    

    在连续学习（CL）的研究中，主要关注动态变化的数据分布所带来的问题。然而，CL可以分解为两个子问题：（a）数据分布的变化，以及（b）处理数据被分成块的事实，因此在任何时间点上只有一部分数据可用于训练。在这项工作中，我们关注后者的子问题--数据的分块--并注意到以前对CL文献中关于分块的分析很少。我们显示出分块是CL的重要组成部分，在我们的实验中占据了离线学习性能下降的约一半。此外，我们的结果显示，当前的CL算法没有解决分块子问题，只有在数据分布没有变化时才能表现出与普通SGD训练一样的水平。我们分析了为什么在数据块上进行学习时性能会下降，并发现遗忘是一个经常被看作是问题的原因。

    Work on continual learning (CL) has largely focused on the problems arising from the dynamically-changing data distribution. However, CL can be decomposed into two sub-problems: (a) shifts in the data distribution, and (b) dealing with the fact that the data is split into chunks and so only a part of the data is available to be trained on at any point in time. In this work, we look at the latter sub-problem -- the chunking of data -- and note that previous analysis of chunking in the CL literature is sparse. We show that chunking is an important part of CL, accounting for around half of the performance drop from offline learning in our experiments. Furthermore, our results reveal that current CL algorithms do not address the chunking sub-problem, only performing as well as plain SGD training when there is no shift in the data distribution. We analyse why performance drops when learning occurs on chunks of data, and find that forgetting, which is often seen to be a problem due to distri
    
[^22]: 理解CLIP中的可转移表示学习和零样本传递

    Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP. (arXiv:2310.00927v1 [cs.LG])

    [http://arxiv.org/abs/2310.00927](http://arxiv.org/abs/2310.00927)

    本文研究了CLIP中的可转移表示学习和零样本传递，提出了一个新的CLIP类型方法，在基准数据集上取得了更好的性能。

    

    多模态学习因其能够利用不同数据源（例如文本和图像）的信息来提高模型性能而日益受到关注。近年来，CLIP作为一种有效的方法，采用视觉-语言对比预训练来学习联合图像和文本表示，并在零样本学习和文本引导的自然图像生成方面表现出非凡的性能。尽管CLIP在实践中取得了巨大的成功，但其理论理解仍然困难。在本文中，我们正式研究了CLIP中的可转移表示学习，并展示了不同模态的特征如何对齐。我们还分析了其在下游任务中的零样本传递性能。受到我们分析的启发，我们提出了一种新的CLIP类型方法，在基准数据集上实现了比CLIP和其他最先进方法更好的性能。

    Multi-modal learning has become increasingly popular due to its ability to leverage information from different data sources (e.g., text and images) to improve the model performance. Recently, CLIP has emerged as an effective approach that employs vision-language contrastive pretraining to learn joint image and text representations and exhibits remarkable performance in zero-shot learning and text-guided natural image generation. Despite the huge practical success of CLIP, its theoretical understanding remains elusive. In this paper, we formally study transferrable representation learning underlying CLIP and demonstrate how features from different modalities get aligned. We also analyze its zero-shot transfer performance on the downstream tasks. Inspired by our analysis, we propose a new CLIP-type approach, which achieves better performance than CLIP and other state-of-the-art methods on benchmark datasets.
    
[^23]: 自动驾驶感知中的深度学习安全考虑

    Deep Learning Safety Concerns in Automated Driving Perception. (arXiv:2309.03774v1 [cs.LG])

    [http://arxiv.org/abs/2309.03774](http://arxiv.org/abs/2309.03774)

    本研究旨在通过引入安全考虑作为结构元素，以系统综合的方式确保基于深度神经网络的自动驾驶系统的安全性。这一概念不仅与现有的安全标准相契合，还为AI安全相关的学术出版物和标准提供了新的启示。

    

    深度学习领域的最新进展以及深度神经网络（DNNs）在感知方面的出色性能导致了对其在自动驾驶系统中应用的增加需求。这类系统的安全性至关重要，因此需要考虑DNNs的独特属性。为了以系统综合的方式确保基于DNNs的自动驾驶系统的安全性，引入了所谓的安全考虑作为适当的结构元素。一方面，安全考虑的概念设计与现有的与自动驾驶系统安全相关的标准如ISO 21448（SOTIF）非常契合。另一方面，它已经激发了几篇学术出版物和即将出台的关于AI安全的标准，如ISO PAS 8800。虽然安全考虑的概念以前已经被介绍过，但本文对其进行了扩展和优化，借鉴了各个领域和安全专家的反馈意见。

    Recent advances in the field of deep learning and impressive performance of deep neural networks (DNNs) for perception have resulted in an increased demand for their use in automated driving (AD) systems. The safety of such systems is of utmost importance and thus requires to consider the unique properties of DNNs.  In order to achieve safety of AD systems with DNN-based perception components in a systematic and comprehensive approach, so-called safety concerns have been introduced as a suitable structuring element. On the one hand, the concept of safety concerns is -- by design -- well aligned to existing standards relevant for safety of AD systems such as ISO 21448 (SOTIF). On the other hand, it has already inspired several academic publications and upcoming standards on AI safety such as ISO PAS 8800.  While the concept of safety concerns has been previously introduced, this paper extends and refines it, leveraging feedback from various domain and safety experts in the field. In par
    
[^24]: 广义持续类别发现

    Generalized Continual Category Discovery. (arXiv:2308.12112v1 [cs.LG])

    [http://arxiv.org/abs/2308.12112](http://arxiv.org/abs/2308.12112)

    本研究提出了一种广义持续类别发现（GCCD）的框架，用于在现实生活场景中同时处理新的和已知的类别，并且利用持续的无监督学习方法来发现它们。通过实验证明现有方法无法处理后续任务中的无标记样本。

    

    大多数持续学习（CL）方法推动着监督学习设置的极限，其中一个智能体期望学习新的标记任务而不会忘记先前的知识。然而，这些设置与现实生活场景不太吻合，其中学习智能体可以访问大量的无标记数据，包括全新（完全无标记）类别和已知类别的示例。受到广义类别发现（GCD）的启发，我们引入了一个新的框架来放松这个假设。确切地说，在任何任务中，我们允许存在新的和已知的类别，并且必须使用持续版本的无监督学习方法来发现它们。我们称这种设置为广义持续类别发现（GCCD）。它统一了CL和GCD，弥合了合成基准和现实生活场景之间的差距。通过一系列实验，我们发现现有的方法无法从后续任务中积累知识，其中包含无标记样本。

    Most of Continual Learning (CL) methods push the limit of supervised learning settings, where an agent is expected to learn new labeled tasks and not forget previous knowledge. However, these settings are not well aligned with real-life scenarios, where a learning agent has access to a vast amount of unlabeled data encompassing both novel (entirely unlabeled) classes and examples from known classes. Drawing inspiration from Generalized Category Discovery (GCD), we introduce a novel framework that relaxes this assumption. Precisely, in any task, we allow for the existence of novel and known classes, and one must use continual version of unsupervised learning methods to discover them. We call this setting Generalized Continual Category Discovery (GCCD). It unifies CL and GCD, bridging the gap between synthetic benchmarks and real-life scenarios. With a series of experiments, we present that existing methods fail to accumulate knowledge from subsequent tasks in which unlabeled samples of 
    
[^25]: 利用大型语言模型进行可伸缩矢量图驱动的图像理解

    Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding. (arXiv:2306.06094v1 [cs.CV])

    [http://arxiv.org/abs/2306.06094](http://arxiv.org/abs/2306.06094)

    本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。

    

    最近，大型语言模型(LLMs)在自然语言理解和生成方面取得了显著进展。然而，它们在计算机视觉领域的潜力仍然很大程度上没有被开发。本文介绍了一种新的探索性方法，使得LLMs能够使用可伸缩矢量图(SVG)格式处理图像。通过利用基于XML的SVG表述的文本描述而不是光栅图像，我们旨在弥合视觉和文本模态之间的差距，使LLMs能够直接理解和操作图像，而无需使用参数化的视觉组件。我们的方法仅利用LLMs的能力进行简单的图像分类、生成和上下文学习。我们展示了方法在判别和生成任务中的优异表现，重点介绍了它(i)对分布转移的鲁棒性，(ii)通过利用LLMs的上下文学习能力实现的显著改进，以及(iii)图像杂乱程度上的显著性能提高。

    Recently, large language models (LLMs) have made significant advancements in natural language understanding and generation. However, their potential in computer vision remains largely unexplored. In this paper, we introduce a new, exploratory approach that enables LLMs to process images using the Scalable Vector Graphics (SVG) format. By leveraging the XML-based textual descriptions of SVG representations instead of raster images, we aim to bridge the gap between the visual and textual modalities, allowing LLMs to directly understand and manipulate images without the need for parameterized visual components. Our method facilitates simple image classification, generation, and in-context learning using only LLM capabilities. We demonstrate the promise of our approach across discriminative and generative tasks, highlighting its (i) robustness against distribution shift, (ii) substantial improvements achieved by tapping into the in-context learning abilities of LLMs, and (iii) image unders
    
[^26]: SpikeGPT：带有脉冲神经网络的生成预训练语言模型

    SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks. (arXiv:2302.13939v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13939](http://arxiv.org/abs/2302.13939)

    本论文提出了一种称之为SpikeGPT的生成语言模型，使用二进制、事件驱动脉冲激活单元进行训练，克服了SNN训练中的挑战性。该模型可以用于大规模语言生成任务。

    

    随着大型语言模型的规模不断扩大，所需的计算资源也随之增加。脉冲神经网络（SNN）已成为一种能够利用稀疏和事件驱动激活减少模型推理计算开销的节能深度学习方法。虽然它们在许多计算机视觉任务上已经具有竞争力，但SNN的训练也被证明更具挑战性。因此，它们的性能落后于现代深度学习，我们尚未看到SNN在语言生成方面的有效性。在本文中，我们受到Receptance Weighted Key Value（RWKV）语言模型的启发，成功实现了“SpikeGPT”，它是一种具有二进制、事件驱动脉冲激活单元的生成语言模型。我们在两种模型变体上训练了所提出的模型：45M和216M参数。据我们所知，SpikeGPT是迄今最大的反向传播训练SNN模型，使其适用于非脉冲模型通常解决的大规模语言生成任务。

    As the size of large language models continue to scale, so does the computational resources required to run it. Spiking Neural Networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference. While they have become competitive with non-spiking models on many computer vision tasks, SNNs have also proven to be more challenging to train. As a result, their performance lags behind modern deep learning, and we are yet to see the effectiveness of SNNs in language generation. In this paper, inspired by the Receptance Weighted Key Value (RWKV) language model, we successfully implement `SpikeGPT', a generative language model with binary, event-driven spiking activation units. We train the proposed model on two model variants: 45M and 216M parameters. To the best of our knowledge, SpikeGPT is the largest backpropagation-trained SNN model to date, rendering it suita
    
[^27]: 注意留下空隙！用鲁曼功能理论构建可解释人工智能与人类理解之间的桥梁

    Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding with Luhmann's Functional Theory of Communication. (arXiv:2302.03460v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2302.03460](http://arxiv.org/abs/2302.03460)

    本文提出了一个更对话式的解释模型，弥合可解释人工智能与人类理解之间的差距，以创建更有效和广泛应用的人工智能系统。

    

    在过去的十年中，可解释人工智能已从一种主要的技术学科发展成与社会科学紧密相交的领域。人类偏好对比的解释，确切而言是反事实的解释，对于这种转变起到了重要的作用，启发和引领计算机科学的研究。然而，其他同样重要的观察却受到了很少的关注。人类解释者希望通过对话式的交互与人工智能解释者进行交流的愿望在社区中基本被忽视。这给这种技术的有效性和广泛应用带来了很多挑战，因为根据预定义的目标提供单一的优化解释可能会失败，并且不能满足其接收者的独特需求，鉴于人类知识和意图的多样性。本文利用尼克拉斯·鲁曼和其他交流学者阐述的见解，提出了向更对话式的解释模型的转变，其中解释者和被解释者之间的信息持续交流是核心。通过这种模型，我们可以建立更有效和广泛应用的人工智能系统，弥合可解释人工智能与人类理解之间的差距。

    Over the past decade explainable artificial intelligence has evolved from a predominantly technical discipline into a field that is deeply intertwined with social sciences. Insights such as human preference for contrastive -- more precisely, counterfactual -- explanations have played a major role in this transition, inspiring and guiding the research in computer science. Other observations, while equally important, have received much less attention. The desire of human explainees to communicate with artificial intelligence explainers through a dialogue-like interaction has been mostly neglected by the community. This poses many challenges for the effectiveness and widespread adoption of such technologies as delivering a single explanation optimised according to some predefined objectives may fail to engender understanding in its recipients and satisfy their unique needs given the diversity of human knowledge and intention. Using insights elaborated by Niklas Luhmann and, more recently,
    
[^28]: 基于去偏自注意力的公平感知视觉变换器

    Fairness-aware Vision Transformer via Debiased Self-Attention. (arXiv:2301.13803v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13803](http://arxiv.org/abs/2301.13803)

    这篇论文提出了一种基于去偏自注意力的公平感知视觉变换器框架，通过消除与敏感属性相关的虚假特征来减轻偏见，并利用对抗性示例来定位和屏蔽这些特征。

    

    最近，由于其提取信息特征和通过自我关注机制建模长距离依赖关系的能力，视觉变换器（ViT）在解决计算机视觉（CV）问题方面引起了广泛关注。为了充分发挥ViT在现实应用中的优势，最近的研究探索了ViT的可靠性和可解释性，包括其鲁棒性和可解释性。然而，另一个需求，公平性，在文献中尚未得到充分解决。我们证明了现有的公平感知算法（主要设计用于CNN）在ViT上表现不佳。这就需要我们通过去偏自注意（DSA）开发我们的新框架。DSA是一种通过盲目方法来强制ViT消除与敏感属性相关的虚假特征以减轻偏见的方法。值得注意的是，对抗性示例被用来定位和屏蔽输入图像块中的虚假特征。

    Vision Transformer (ViT) has recently gained significant interest in solving computer vision (CV) problems due to its capability of extracting informative features and modeling long-range dependencies through the self-attention mechanism. To fully realize the advantages of ViT in real-world applications, recent works have explored the trustworthiness of ViT, including its robustness and explainability. However, another desiderata, fairness has not yet been adequately addressed in the literature. We establish that the existing fairness-aware algorithms (primarily designed for CNNs) do not perform well on ViT. This necessitates the need for developing our novel framework via Debiased Self-Attention (DSA). DSA is a fairness-through-blindness approach that enforces ViT to eliminate spurious features correlated with the sensitive attributes for bias mitigation. Notably, adversarial examples are leveraged to locate and mask the spurious features in the input image patches. In addition, DSA u
    

