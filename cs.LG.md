# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Objective and subjective evaluation of speech enhancement methods in the UDASE task of the 7th CHiME challenge](https://rss.arxiv.org/abs/2402.01413) | 本文介绍了第七届CHiME挑战赛的UDASE任务中系统的客观和主观评估，并分析了结果 |
| [^2] | [Aardvark Weather: end-to-end data-driven weather forecasting](https://arxiv.org/abs/2404.00411) | Aardvark Weather是第一个端到端数据驱动的预报系统，能够取代传统数值天气预报系统，提供全球和本地精准预报。 |
| [^3] | [Compressed Multi-task embeddings for Data-Efficient Downstream training and inference in Earth Observation](https://arxiv.org/abs/2403.17886) | 基于神经嵌入压缩的多任务嵌入方法在地球观测中实现了数据高效的训练和推断，通过压缩率与嵌入效用之间的权衡，取得了数据量显著减少的准确性。 |
| [^4] | [Improving Medical Multi-modal Contrastive Learning with Expert Annotations](https://arxiv.org/abs/2403.10153) | eCLIP是一种改进的CLIP模型，通过集成专家注释和混合增强来应对医学影像分析中的数据稀缺和模态差距挑战，提高了模型学习效果 |
| [^5] | [GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery](https://arxiv.org/abs/2403.09974) | 本文提出了一种文本嵌入合成器（TES），用于为无标签数据生成伪文本嵌入，以解锁CLIP用于广义类别发现任务中的多模态潜力。 |
| [^6] | [Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding](https://arxiv.org/abs/2403.07559) | 提出了Ensembling Prioritized Hybrid Policies (EPH)方法，通过选择性通信模块和三种高级推理策略，提高了基于通信的多智能体路径规划解决方案的性能。 |
| [^7] | [Benign overfitting in leaky ReLU networks with moderate input dimension](https://arxiv.org/abs/2403.06903) | 研究了在泄漏ReLU网络上使用铰链损失进行训练的过程中，信噪比（SNR）条件对于良性和非良性过拟合的影响，并发现高SNR值会导致良性过拟合，低SNR值则会导致有害过拟合。 |
| [^8] | [Learning Agility Adaptation for Flight in Clutter](https://arxiv.org/abs/2403.04586) | 本文旨在使飞行器在未知且部分可观测的杂乱环境中具有敏捷性调整能力，提出了一种利用分层学习和规划框架的方法，通过在线无模型强化学习和预训练微调奖励方案获得可部署的策略，在仿真中显示出比恒定敏捷性基线和另一种替代方法更优越的飞行效率和安全性。 |
| [^9] | [Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents](https://arxiv.org/abs/2403.02502) | 提出了一种面向LLM代理的基于探索的轨迹优化方法，通过允许代理从探索失败中学习，实现了性能的改进。 |
| [^10] | [Diffusion Tempering Improves Parameter Estimation with Probabilistic Integrators for Ordinary Differential Equations](https://arxiv.org/abs/2402.12231) | 扩散回火是一种新颖的正则化技术，可改善概率数值方法在普通微分方程中的参数优化收敛性，实现对复杂动态系统中参数的可靠估计 |
| [^11] | [Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search](https://arxiv.org/abs/2402.11354) | 该论文提出了一种基于概率路由的方法，通过引入PEOs有效识别图中需要考虑进行精确距离计算的邻居，从而显著提高了基于图的近似最近邻搜索的效率。 |
| [^12] | [Agent Lumos: Unified and Modular Training for Open-Source Language Agents](https://arxiv.org/abs/2311.05657) | Agent Lumos提出了一种统一和模块化的框架，通过规划模块学习高级子目标生成，训练接地模块将其转化为动作，促进广泛互动任务应用。 |
| [^13] | [DistriBlock: Identifying adversarial audio samples by leveraging characteristics of the output distribution](https://arxiv.org/abs/2305.17000) | DistriBlock提出了一种能够识别对抗性音频样本的有效检测策略，通过利用输出分布的特征，包括中位数、最大值和最小值、熵以及与后续时间步骤的分布之间的散度，应用二元分类器进行预测。这项研究证明了DistriBlock在识别对抗性音频样本方面的有效性。 |
| [^14] | [Non-Coherent Over-the-Air Decentralized Gradient Descent](https://arxiv.org/abs/2211.10777) | 提出了一种适用于无线系统的DGD算法，通过无相干空中共识方案实现无需智能体协调、拓扑信息或信道状态信息的分布式优化。 |
| [^15] | [Left/Right Brain, human motor control and the implications for robotics.](http://arxiv.org/abs/2401.14057) | 本研究通过训练不同的损失函数，实现了类似于人类的左右半球专门化控制系统，该系统在不同的运动任务中展现出协调性、运动效率和位置稳定性的优势。 |
| [^16] | [A First-Order Multi-Gradient Algorithm for Multi-Objective Bi-Level Optimization.](http://arxiv.org/abs/2401.09257) | 本文提出了一种用于多目标双层优化的高效一阶多梯度算法FORUM，通过值函数方法将MOBLO问题重新形式化为约束多目标优化问题，并提出了一种新颖的多梯度聚合方法来解决挑战性的约束多目标优化问题。在理论和实证上的结果表明该方法的高效性和有效性。 |
| [^17] | [Manipulating Feature Visualizations with Gradient Slingshots.](http://arxiv.org/abs/2401.06122) | 本研究探究了激活最大化方法在对抗模型操作中的脆弱性，并提出了一种新的方法来操纵特征可视化，以隐藏特定神经元的功能。 |
| [^18] | [Lie Group Decompositions for Equivariant Neural Networks.](http://arxiv.org/abs/2310.11366) | 本论文提出了一种基于Lie群结构和几何特性的框架，可以处理非紧致非阿贝尔的Lie群，特别关注于$\text{GL}^{+}(n, \mathbb{R})$和$\text{SL}(n, \mathbb{R})$这两个Lie群。 |
| [^19] | [NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series Pretraining.](http://arxiv.org/abs/2310.07402) | 本研究通过采用Transformer架构和数值多尺度嵌入模块，使时间序列自监督模型能够扩展到大规模数据集，并在大规模数据集上进行预训练。 |
| [^20] | [Towards Foundation Models for Learning on Tabular Data.](http://arxiv.org/abs/2310.07338) | 本文提出了Tabular Foundation Models (TabFMs)，通过利用生成型表格学习的潜力，采用预训练的大规模语言模型作为基础模型，并在广泛的表格数据集上进行微调，赋予TabFMs深刻的理解和普遍的能力，从而克服了当前可转移的表格模型的限制。 |
| [^21] | [A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models.](http://arxiv.org/abs/2310.05833) | 该论文首次引入了生成模型的核评分的偏差-方差-协方差分解，并提出了相应的量的无偏和一致估计器。通过应用在扩散模型上发现少数群体的模式坍缩是一种与过拟合相反的现象，并证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。 |
| [^22] | [SyMOT-Flow: Learning optimal transport flow for two arbitrary distributions with maximum mean discrepancy.](http://arxiv.org/abs/2308.13815) | 本文介绍了一个名为SyMOT-Flow的新模型，它通过最小化两个未知分布样本之间的对称最大平均差异来训练可逆转换，并结合最优输运成本作为正则化，将未知分布转换为标准正态分布。实验证明这种转换可以实现更稳定准确的样本生成。 |
| [^23] | [MCMC-Correction of Score-Based Diffusion Models for Model Composition.](http://arxiv.org/abs/2307.14012) | 本文提出了一种修正基于得分的扩散模型的方法，使其能够与各种MCMC方法结合，从而实现模型组合和进行更好的采样。 |
| [^24] | [Abide by the Law and Follow the Flow: Conservation Laws for Gradient Flows.](http://arxiv.org/abs/2307.00144) | 本文通过定义和研究梯度流中的守恒定律，以及在模型的雅可比矩阵生成的李代数上进行有限维代数运算，揭示了超参数调节的模型保留了一些优化初始化的特性，这可能解释了训练模型具有良好泛化特性的原因。 |
| [^25] | [Neural Symbolic Regression using Control Variables.](http://arxiv.org/abs/2306.04718) | 提出了一种利用控制变量的神经符号回归方法，可以分解多变量符号回归为单变量回归，并从底部向上组合，解决了符号回归存在的精度和可扩展性问题。 |
| [^26] | [Fair Column Subset Selection.](http://arxiv.org/abs/2306.04489) | 解决了公平的列子集选择问题，通过已知方法基于确定性杠杆分数采样，提出了一种有效算法，可以在1.5倍的大小下实现与两倍相同的近似保证。 |
| [^27] | [Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise.](http://arxiv.org/abs/2305.13498) | 本文研究了带有测量噪声的Ornstein-Uhlenbeck过程参数估计，提出了算法和方法能够分离热噪声和乘性噪声，并改善数据分析的参数估计精度。 |
| [^28] | [Balancing Privacy and Security in Federated Learning with FedGT: A Group Testing Framework.](http://arxiv.org/abs/2305.05506) | 该论文提出了FedGT框架，通过群体测试的方法在联邦学习中识别并删除恶意客户，从而平衡了隐私和安全，保护数据隐私并提高了识别恶意客户的能力。 |
| [^29] | [A noise-robust acoustic method for recognition of foraging activities of grazing cattle.](http://arxiv.org/abs/2304.14824) | 本研究提出了一种抗噪声的声学方法，能够分析与吃草和反刍相关的鉴定下颚运动事件的固定长度段，用于识别牛的觅食活动，并在环境和自然噪声方面具有鲁棒性。 |
| [^30] | [CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X.](http://arxiv.org/abs/2303.17568) | CodeGeeX是一个多语言模型，具有130亿参数，用于代码生成。经过广泛的实验证明，CodeGeeX在HumanEval-X上的代码生成和翻译任务中表现优异。此外，CodeGeeX可以将程序员的生产力提高22%。 |
| [^31] | [Cross-model Fairness: Empirical Study of Fairness and Ethics Under Model Multiplicity.](http://arxiv.org/abs/2203.07139) | 本文提出了一种跨模型公平性的新定义，并进行了实证研究。该研究关注数据驱动预测模型在社会背景下的公平性问题，特别是在通过选择不同预测器进行模型多样性时可能导致个人受伤害的情况。 |
| [^32] | [Trade When Opportunity Comes: Price Movement Forecasting via Locality-Aware Attention and Iterative Refinement Labeling.](http://arxiv.org/abs/2107.11972) | 本论文提出了一种名为LARA的新型价格变动预测框架，包括两个主要部分：局部感知注意力和迭代细化标注。在真实世界的金融数据集上的实验结果表明，LARA在准确性和盈利能力方面优于现有的最先进方法。 |

# 详细

[^1]: 第七届CHiME挑战赛中UDASE任务中语音增强方法的客观和主观评估

    Objective and subjective evaluation of speech enhancement methods in the UDASE task of the 7th CHiME challenge

    [https://rss.arxiv.org/abs/2402.01413](https://rss.arxiv.org/abs/2402.01413)

    本文介绍了第七届CHiME挑战赛的UDASE任务中系统的客观和主观评估，并分析了结果

    

    基于监督模型的语音增强方法是通过人工合成的干净语音和噪声信号混合来训练的。然而，合成训练条件可能无法准确反映测试过程中遇到的真实世界条件。这种差异可能导致在测试域与合成训练域显著不同时性能不佳。为了解决这个问题，第七届CHiME挑战赛的UDASE任务旨在利用测试域的真实世界噪声语音录音来对语音增强模型进行无监督域适应。具体来说，这个测试域对应于CHiME-5数据集，该数据集由在嘈杂和混响的家庭环境中进行的真实多说话人对话录音组成，无法获得地面实况干净语音信号。在本文中，我们介绍了提交到CHiME-7 UDASE任务的系统的客观和主观评估，并对结果进行了分析

    Supervised models for speech enhancement are trained using artificially generated mixtures of clean speech and noise signals. However, the synthetic training conditions may not accurately reflect real-world conditions encountered during testing. This discrepancy can result in poor performance when the test domain significantly differs from the synthetic training domain. To tackle this issue, the UDASE task of the 7th CHiME challenge aimed to leverage real-world noisy speech recordings from the test domain for unsupervised domain adaptation of speech enhancement models. Specifically, this test domain corresponds to the CHiME-5 dataset, characterized by real multi-speaker and conversational speech recordings made in noisy and reverberant domestic environments, for which ground-truth clean speech signals are not available. In this paper, we present the objective and subjective evaluations of the systems that were submitted to the CHiME-7 UDASE task, and we provide an analysis of the resul
    
[^2]: Aardvark Weather:端对端数据驱动的天气预报

    Aardvark Weather: end-to-end data-driven weather forecasting

    [https://arxiv.org/abs/2404.00411](https://arxiv.org/abs/2404.00411)

    Aardvark Weather是第一个端到端数据驱动的预报系统，能够取代传统数值天气预报系统，提供全球和本地精准预报。

    

    机器学习正在彻底改变中程天气预测。然而，它仅被应用于天气预测管道的特定和单个组件。因此，这些数据驱动方法无法在没有来自传统操作数值天气预报系统的输入的情况下部署，这是计算成本高昂且不支持端到端优化。在这项工作中，我们采用了一种根本不同的方法，用机器学习模型取代整个数值天气预报管道。我们提出了Aardvark Weather，这是第一个端到端数据驱动的预报系统，它接受原始观测数据作为输入，并提供全球和本地预报。这些全球预报以一度空间分辨率，24小时时间分辨率为多个压力水平24个变量产生，并在五到七天的前期领先时段对每小时气候的预测能力。本地预报是...

    arXiv:2404.00411v1 Announce Type: cross  Abstract: Machine learning is revolutionising medium-range weather prediction. However it has only been applied to specific and individual components of the weather prediction pipeline. Consequently these data-driven approaches are unable to be deployed without input from conventional operational numerical weather prediction (NWP) systems, which is computationally costly and does not support end-to-end optimisation. In this work, we take a radically different approach and replace the entire NWP pipeline with a machine learning model. We present Aardvark Weather, the first end-to-end data-driven forecasting system which takes raw observations as input and provides both global and local forecasts. These global forecasts are produced for 24 variables at multiple pressure levels at one-degree spatial resolution and 24 hour temporal resolution, and are skillful with respect to hourly climatology at five to seven day lead times. Local forecasts are pr
    
[^3]: 压缩多任务嵌入用于地球观测中数据高效下游训练和推断

    Compressed Multi-task embeddings for Data-Efficient Downstream training and inference in Earth Observation

    [https://arxiv.org/abs/2403.17886](https://arxiv.org/abs/2403.17886)

    基于神经嵌入压缩的多任务嵌入方法在地球观测中实现了数据高效的训练和推断，通过压缩率与嵌入效用之间的权衡，取得了数据量显著减少的准确性。

    

    随着地球观测（EO）中大规模数据的存储库增长，模型训练和推断的转移和存储成本也在增加，消耗了大量资源。我们引入了基于神经嵌入压缩（NEC）的方法，该方法基于对数据使用者传输压缩的嵌入而不是原始数据。我们通过学习神经压缩来调整基础模型（FM），生成多任务嵌入，同时在压缩率和嵌入效用之间进行权衡。我们仅针对FM参数的一小部分（10%）进行更新，进行短时间训练（预训练迭代的1%）。我们在两个EO任务上评估了NEC：场景分类和语义分割。与将传统压缩应用于原始数据相比，NEC在减少数据量方面可实现类似的准确性，降低了75%到90%的数据量。即使在99.7%的压缩下，在场景分类任务上性能仅下降了5%。总体而言，NEC是一种数据高效

    arXiv:2403.17886v1 Announce Type: new  Abstract: As repositories of large scale data in earth observation (EO) have grown, so have transfer and storage costs for model training and inference, expending significant resources. We introduce Neural Embedding Compression (NEC), based on the transfer of compressed embeddings to data consumers instead of raw data. We adapt foundation models (FM) through learned neural compression to generate multi-task embeddings while navigating the tradeoff between compression rate and embedding utility. We update only a small fraction of the FM parameters (10%) for a short training period (1% of the iterations of pre-training). We evaluate NEC on two EO tasks: scene classification and semantic segmentation. Compared with applying traditional compression to the raw data, NEC achieves similar accuracy with a 75% to 90% reduction in data. Even at 99.7% compression, performance drops by only 5% on the scene classification task. Overall, NEC is a data-efficient
    
[^4]: 改进医学多模态对比学习与专家注释

    Improving Medical Multi-modal Contrastive Learning with Expert Annotations

    [https://arxiv.org/abs/2403.10153](https://arxiv.org/abs/2403.10153)

    eCLIP是一种改进的CLIP模型，通过集成专家注释和混合增强来应对医学影像分析中的数据稀缺和模态差距挑战，提高了模型学习效果

    

    我们介绍了一种增强版CLIP模型——eCLIP，它集成了放射科医生眼球注视热图形式的专家注释。它解决了对比多模态医学影像分析中的关键挑战，尤其是数据稀缺和“模态差距”——图像和文本嵌入之间存在的显著差异，降低了表示的质量并阻碍了跨模态互操作性。eCLIP集成了一个热图处理器，并利用混合增强来有效利用稀缺的专家注释，从而提高模型的学习效果。eCLIP设计为通用的，适用于任何形式的CLIP变体，无需修改核心架构。通过对多个任务的详细评估，包括零样本推断、线性探针、跨模态检索以及使用冻结的大型语言模型进行放射学报告的检索增强生成（RAG），eCLIP展示了其...

    arXiv:2403.10153v1 Announce Type: cross  Abstract: We introduce eCLIP, an enhanced version of the CLIP model that integrates expert annotations in the form of radiologist eye-gaze heatmaps. It tackles key challenges in contrastive multi-modal medical imaging analysis, notably data scarcity and the "modality gap" -- a significant disparity between image and text embeddings that diminishes the quality of representations and hampers cross-modal interoperability. eCLIP integrates a heatmap processor and leverages mixup augmentation to efficiently utilize the scarce expert annotations, thus boosting the model's learning effectiveness. eCLIP is designed to be generally applicable to any variant of CLIP without requiring any modifications of the core architecture. Through detailed evaluations across several tasks, including zero-shot inference, linear probing, cross-modal retrieval, and Retrieval Augmented Generation (RAG) of radiology reports using a frozen Large Language Model, eCLIP showca
    
[^5]: GET：解锁CLIP的多模态潜力，用于广义类别发现

    GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery

    [https://arxiv.org/abs/2403.09974](https://arxiv.org/abs/2403.09974)

    本文提出了一种文本嵌入合成器（TES），用于为无标签数据生成伪文本嵌入，以解锁CLIP用于广义类别发现任务中的多模态潜力。

    

    给定包含旧类别和新类别的无标签数据集，广义类别发现（GCD）旨在准确发现新类别，并正确分类旧类别，利用从有标签样本中学习的类别概念。当前的GCD方法只使用单一的视觉信息模态，导致在视觉上相似类别的分类效果不佳。虽然某些类别在视觉上容易混淆，但它们的文本信息可能是不同的，这促使我们将文本信息引入到GCD任务中。然而，无标签数据缺乏类别名称，使得利用文本信息变得不切实际。为了解决这一具有挑战性的问题，在本文中，我们提出了一种文本嵌入合成器（TES），用于为无标签样本生成伪文本嵌入。具体而言，我们的TES利用CLIP可以生成对齐的视觉-语言特征这一特性，将视觉嵌入转换为CLIP文本模型的标记。

    arXiv:2403.09974v1 Announce Type: cross  Abstract: Given unlabelled datasets containing both old and new categories, generalized category discovery (GCD) aims to accurately discover new classes while correctly classifying old classes, leveraging the class concepts learned from labeled samples. Current GCD methods only use a single visual modality of information, resulting in poor classification of visually similar classes. Though certain classes are visually confused, their text information might be distinct, motivating us to introduce text information into the GCD task. However, the lack of class names for unlabelled data makes it impractical to utilize text information. To tackle this challenging problem, in this paper, we propose a Text Embedding Synthesizer (TES) to generate pseudo text embeddings for unlabelled samples. Specifically, our TES leverages the property that CLIP can generate aligned vision-language features, converting visual embeddings into tokens of the CLIP's text e
    
[^6]: 为多智能体路径规划集成优先级混合策略

    Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding

    [https://arxiv.org/abs/2403.07559](https://arxiv.org/abs/2403.07559)

    提出了Ensembling Prioritized Hybrid Policies (EPH)方法，通过选择性通信模块和三种高级推理策略，提高了基于通信的多智能体路径规划解决方案的性能。

    

    基于多智能体强化学习（MARL）的多智能体路径规划（MAPF）近来因其高效性和可扩展性而受到关注。我们提出了一种新方法，Ensembling Prioritized Hybrid Policies (EPH)，以进一步提高基于通信的MARL-MAPF求解器的性能。我们首先提出了一个选择性通信模块，以在多智能体环境中收集更丰富的信息，从而实现更好的智能体协调，并使用基于Q-learning的算法对模型进行训练。

    arXiv:2403.07559v1 Announce Type: cross  Abstract: Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding (MAPF) has recently gained attention due to its efficiency and scalability. Several MARL-MAPF methods choose to use communication to enrich the information one agent can perceive. However, existing works still struggle in structured environments with high obstacle density and a high number of agents. To further improve the performance of the communication-based MARL-MAPF solvers, we propose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first propose a selective communication block to gather richer information for better agent coordination within multi-agent environments and train the model with a Q-learning-based algorithm. We further introduce three advanced inference strategies aimed at bolstering performance during the execution phase. First, we hybridize the neural policy with single-agent expert guidance for navigating conflict-free zones. Se
    
[^7]: 具有适度输入维度的泄漏ReLU网络中的良性过拟合问题

    Benign overfitting in leaky ReLU networks with moderate input dimension

    [https://arxiv.org/abs/2403.06903](https://arxiv.org/abs/2403.06903)

    研究了在泄漏ReLU网络上使用铰链损失进行训练的过程中，信噪比（SNR）条件对于良性和非良性过拟合的影响，并发现高SNR值会导致良性过拟合，低SNR值则会导致有害过拟合。

    

    良性过拟合问题探讨了一个模型是否能够完美地拟合嘈杂的训练数据，同时又能够很好地泛化。我们研究了在二层泄漏ReLU网络上使用铰链损失进行训练的良性过拟合问题，针对二分类任务。我们考虑输入数据，可以分解为一个共同信号和一个随机噪声成分的总和，这两者相互正交。我们表征了模型参数的信噪比（SNR）条件，导致了良性和非良性（有害）过拟合：特别是，如果SNR很高，则发生良性过拟合，相反，如果SNR很低，则发生有害过拟合。我们将良性和非良性过拟合归因于一个近似边界最大化性质，并展示了在铰链损失下使用梯度下降（GD）训练的泄漏ReLU网络满足这一性质。与以前的工作相比，我们不需要nea

    arXiv:2403.06903v1 Announce Type: new  Abstract: The problem of benign overfitting asks whether it is possible for a model to perfectly fit noisy training data and still generalize well. We study benign overfitting in two-layer leaky ReLU networks trained with the hinge loss on a binary classification task. We consider input data which can be decomposed into the sum of a common signal and a random noise component, which lie on subspaces orthogonal to one another. We characterize conditions on the signal to noise ratio (SNR) of the model parameters giving rise to benign versus non-benign, or harmful, overfitting: in particular, if the SNR is high then benign overfitting occurs, conversely if the SNR is low then harmful overfitting occurs. We attribute both benign and non-benign overfitting to an approximate margin maximization property and show that leaky ReLU networks trained on hinge loss with Gradient Descent (GD) satisfy this property. In contrast to prior work we do not require nea
    
[^8]: 在杂乱环境中学习飞行敏捷性调整

    Learning Agility Adaptation for Flight in Clutter

    [https://arxiv.org/abs/2403.04586](https://arxiv.org/abs/2403.04586)

    本文旨在使飞行器在未知且部分可观测的杂乱环境中具有敏捷性调整能力，提出了一种利用分层学习和规划框架的方法，通过在线无模型强化学习和预训练微调奖励方案获得可部署的策略，在仿真中显示出比恒定敏捷性基线和另一种替代方法更优越的飞行效率和安全性。

    

    动物学习适应其运动能力和操作环境的敏捷性。移动机器人也应展示这种能力，将敏捷性和安全性结合起来。本文旨在赋予飞行器在未知且部分可观测的杂乱环境中适应敏捷性的能力。我们提出了一种分层学习和规划框架，结合试错学习和基于模型的轨迹生成方法来全面学习敏捷性策略。我们使用在线无模型强化学习和预训练微调奖励方案来获得可部署的策略。在仿真中的统计结果显示，相较于恒定敏捷性基线和另一种替代方法，我们的方法在飞行效率和安全性方面具有优势。特别是，该策略导致

    arXiv:2403.04586v1 Announce Type: cross  Abstract: Animals learn to adapt agility of their movements to their capabilities and the environment they operate in. Mobile robots should also demonstrate this ability to combine agility and safety. The aim of this work is to endow flight vehicles with the ability of agility adaptation in prior unknown and partially observable cluttered environments. We propose a hierarchical learning and planning framework where we utilize both trial and error to comprehensively learn an agility policy with the vehicle's observation as the input, and well-established methods of model-based trajectory generation. Technically, we use online model-free reinforcement learning and a pre-training-fine-tuning reward scheme to obtain the deployable policy. The statistical results in simulation demonstrate the advantages of our method over the constant agility baselines and an alternative method in terms of flight efficiency and safety. In particular, the policy leads
    
[^9]: 试错法：面向LLM代理的基于探索的轨迹优化

    Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents

    [https://arxiv.org/abs/2403.02502](https://arxiv.org/abs/2403.02502)

    提出了一种面向LLM代理的基于探索的轨迹优化方法，通过允许代理从探索失败中学习，实现了性能的改进。

    

    大型语言模型（LLMs）已经成为各种自主代理系统中不可或缺的组成部分。在这项研究中，我们提出一种基于探索的轨迹优化方法，称为ETO。这种学习方法旨在提高开放LLM代理的性能。与先前专门训练成功专家轨迹的研究相反，我们的方法允许代理从其探索失败中学习。这通过迭代优化框架实现了性能的改进。在探索阶段，代理与环境互动，完成指定任务，收集失败轨迹以创建对比轨迹对。在随后的训练阶段，代理利用这些轨迹偏好对更新其策略，使用类似DPO的对比学习方法。这种探索和训练的迭代循环促进了代理的持续改进。

    arXiv:2403.02502v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have become integral components in various autonomous agent systems. In this study, we present an exploration-based trajectory optimization approach, referred to as ETO. This learning method is designed to enhance the performance of open LLM agents. Contrary to previous studies that exclusively train on successful expert trajectories, our method allows agents to learn from their exploration failures. This leads to improved performance through an iterative optimization framework. During the exploration phase, the agent interacts with the environment while completing given tasks, gathering failure trajectories to create contrastive trajectory pairs. In the subsequent training phase, the agent utilizes these trajectory preference pairs to update its policy using contrastive learning methods like DPO. This iterative cycle of exploration and training fosters continued improvement in the agents. Our experiments o
    
[^10]: 扩散回火改善概率积分器对普通微分方程参数估计的效果

    Diffusion Tempering Improves Parameter Estimation with Probabilistic Integrators for Ordinary Differential Equations

    [https://arxiv.org/abs/2402.12231](https://arxiv.org/abs/2402.12231)

    扩散回火是一种新颖的正则化技术，可改善概率数值方法在普通微分方程中的参数优化收敛性，实现对复杂动态系统中参数的可靠估计

    

    普通微分方程（ODEs）被广泛应用于描述科学中的动态系统，但确定解释实验测量结果的参数是具有挑战性的。我们提出了扩散回火这一新的正则化技术，它针对ODEs中的概率数值方法，改善了梯度优化参数估计的收敛性。通过迭代减少概率积分器的一个噪声参数，所提出的方法更可靠地收敛到真实参数。我们证明了我们的方法对于不同复杂性的动态系统是有效的，并展示它对于具有实际相关参数数量的Hodgkin-Huxley模型获得可靠的参数估计。

    arXiv:2402.12231v1 Announce Type: new  Abstract: Ordinary differential equations (ODEs) are widely used to describe dynamical systems in science, but identifying parameters that explain experimental measurements is challenging. In particular, although ODEs are differentiable and would allow for gradient-based parameter optimization, the nonlinear dynamics of ODEs often lead to many local minima and extreme sensitivity to initial conditions. We therefore propose diffusion tempering, a novel regularization technique for probabilistic numerical methods which improves convergence of gradient-based parameter optimization in ODEs. By iteratively reducing a noise parameter of the probabilistic integrator, the proposed method converges more reliably to the true parameters. We demonstrate that our method is effective for dynamical systems of different complexity and show that it obtains reliable parameter estimates for a Hodgkin-Huxley model with a practically relevant number of parameters.
    
[^11]: 基于概率路由的基于图的近似最近邻搜索

    Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search

    [https://arxiv.org/abs/2402.11354](https://arxiv.org/abs/2402.11354)

    该论文提出了一种基于概率路由的方法，通过引入PEOs有效识别图中需要考虑进行精确距离计算的邻居，从而显著提高了基于图的近似最近邻搜索的效率。

    

    arXiv：2402.11354v1 公告类型：交叉 摘要：在机器学习领域，高维空间中的近似最近邻搜索(ANNS)是一个重要挑战。近年来，基于图的方法已经成为ANNS的优越方法，建立了一种新的技术水平。尽管引入了各种基于图的ANNS优化方法，但它们主要依赖于缺乏正式理论支持的启发式方法。本文旨在通过引入一种方法来增强基于图的ANNS中的路由，该方法在探索图中节点的邻居时提供概率保证。我们将问题建模为概率路由，并通过结合局部敏感技术开发了两种基准策略。随后，我们介绍了PEOs，这是一种有效识别图中应考虑进行精确距离计算的邻居的新方法，从而在实践中显著提高了效率。我们的实验证明...

    arXiv:2402.11354v1 Announce Type: cross  Abstract: Approximate nearest neighbor search (ANNS) in high-dimensional spaces is a pivotal challenge in the field of machine learning. In recent years, graph-based methods have emerged as the superior approach to ANNS, establishing a new state of the art. Although various optimizations for graph-based ANNS have been introduced, they predominantly rely on heuristic methods that lack formal theoretical backing. This paper aims to enhance routing within graph-based ANNS by introducing a method that offers a probabilistic guarantee when exploring a node's neighbors in the graph. We formulate the problem as probabilistic routing and develop two baseline strategies by incorporating locality-sensitive techniques. Subsequently, we introduce PEOs, a novel approach that efficiently identifies which neighbors in the graph should be considered for exact distance computation, thus significantly improving efficiency in practice. Our experiments demonstrate 
    
[^12]: Agent Lumos: 统一和模块化训练开源语言代理

    Agent Lumos: Unified and Modular Training for Open-Source Language Agents

    [https://arxiv.org/abs/2311.05657](https://arxiv.org/abs/2311.05657)

    Agent Lumos提出了一种统一和模块化的框架，通过规划模块学习高级子目标生成，训练接地模块将其转化为动作，促进广泛互动任务应用。

    

    闭源代理存在诸多问题，如缺乏负担得起性、透明度和可重复性，特别是在复杂的互动任务中。这促使了开源替代方案的发展。我们介绍了 LUMOS，这是第一个为训练开源 LLM-based 代理而设计的框架之一。LUMOS具有可学习、统一和模块化的架构，其中包括一个学习高级子目标生成的规划模块，以及一个训练有素的接地模块，用于使用执行模块中的各种工具将这些转化为动作。这种设计允许模块化升级，并更广泛地适用于不同的互动任务。为了促进通用代理学习，我们收集了源自各种复杂互动任务中不同地面真实推理原理的大规模、统一和高质量的训练注释。在9个数据集上，LUMOS表现出了几个关键优势：（1）LUMOS在多个较大的开源a

    arXiv:2311.05657v2 Announce Type: replace  Abstract: Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce LUMOS, one of the first frameworks for training open-source LLM-based agents. LUMOS features a learnable, unified, and modular architecture with a planning module that learns high-level subgoal generation, and a grounding module trained to translate these into actions using various tools in the execution module. The design allows for modular upgrades and wider applicability to diverse interactive tasks. To foster generalizable agent learning, we collect large-scale, unified, and high-quality training annotations derived from diverse ground-truth reasoning rationales across various complex interactive tasks. On 9 datasets, LUMOS exhibits several key advantages: (1) LUMOS excels multiple larger open-source a
    
[^13]: DistriBlock: 通过利用输出分布的特征识别对抗性音频样本

    DistriBlock: Identifying adversarial audio samples by leveraging characteristics of the output distribution

    [https://arxiv.org/abs/2305.17000](https://arxiv.org/abs/2305.17000)

    DistriBlock提出了一种能够识别对抗性音频样本的有效检测策略，通过利用输出分布的特征，包括中位数、最大值和最小值、熵以及与后续时间步骤的分布之间的散度，应用二元分类器进行预测。这项研究证明了DistriBlock在识别对抗性音频样本方面的有效性。

    

    对抗性攻击可能误导自动语音识别（ASR）系统，使其预测任意目标文本，从而构成明显的安全威胁。为了防止这种攻击，我们提出了DistriBlock，一种适用于任何ASR系统的高效检测策略，该系统在每个时间步骤上预测输出标记的概率分布。我们对该分布的一组特征进行测量：输出概率的中位数、最大值和最小值，分布的熵，以及与后续时间步骤的分布之间的Kullback-Leibler和Jensen-Shannon散度。然后，通过利用对良性和对抗性数据观察到的特征，我们应用二元分类器，包括简单的基于阈值的分类、这种分类器的集合以及神经网络。通过对不同最先进的ASR系统和语言数据集进行广泛分析，我们证明了DistriBlock在识别对抗性音频样本方面的有效性。

    arXiv:2305.17000v2 Announce Type: replace-cross  Abstract: Adversarial attacks can mislead automatic speech recognition (ASR) systems into predicting an arbitrary target text, thus posing a clear security threat. To prevent such attacks, we propose DistriBlock, an efficient detection strategy applicable to any ASR system that predicts a probability distribution over output tokens in each time step. We measure a set of characteristics of this distribution: the median, maximum, and minimum over the output probabilities, the entropy of the distribution, as well as the Kullback-Leibler and the Jensen-Shannon divergence with respect to the distributions of the subsequent time step. Then, by leveraging the characteristics observed for both benign and adversarial data, we apply binary classifiers, including simple threshold-based classification, ensembles of such classifiers, and neural networks. Through extensive analysis across different state-of-the-art ASR systems and language data sets, 
    
[^14]: 无相干空中分布式梯度下降

    Non-Coherent Over-the-Air Decentralized Gradient Descent

    [https://arxiv.org/abs/2211.10777](https://arxiv.org/abs/2211.10777)

    提出了一种适用于无线系统的DGD算法，通过无相干空中共识方案实现无需智能体协调、拓扑信息或信道状态信息的分布式优化。

    

    分布式梯度下降（DGD）是一种流行的算法，用于解决诸如远程感知、分布式推断、多智能体协调和联邦学习等各种领域的分布式优化问题。然而，在受到噪声、衰落和带宽受限的无线系统上执行DGD会带来挑战，需要调度传输以减轻干扰，并获取拓扑和信道状态信息，这在无线分布式系统中是复杂的任务。本文提出了一种专为无线系统定制的DGD算法。与现有方法不同，它在无需进行智能体协调、拓扑信息或信道状态信息的情况下运行。其核心是一种无相干空中（NCOTA）共识方案，利用了无线信道的噪声能量叠加特性。通过随机化传输策略来适应半双工操作，发射机将位置映射到

    arXiv:2211.10777v2 Announce Type: replace-cross  Abstract: Decentralized Gradient Descent (DGD) is a popular algorithm used to solve decentralized optimization problems in diverse domains such as remote sensing, distributed inference, multi-agent coordination, and federated learning. Yet, executing DGD over wireless systems affected by noise, fading and limited bandwidth presents challenges, requiring scheduling of transmissions to mitigate interference and the acquisition of topology and channel state information -- complex tasks in wireless decentralized systems. This paper proposes a DGD algorithm tailored to wireless systems. Unlike existing approaches, it operates without inter-agent coordination, topology information, or channel state information. Its core is a Non-Coherent Over-The-Air (NCOTA) consensus scheme, exploiting a noisy energy superposition property of wireless channels. With a randomized transmission strategy to accommodate half-duplex operation, transmitters map loca
    
[^15]: 左/右脑、人类运动控制及对机器人的影响

    Left/Right Brain, human motor control and the implications for robotics. (arXiv:2401.14057v1 [cs.RO])

    [http://arxiv.org/abs/2401.14057](http://arxiv.org/abs/2401.14057)

    本研究通过训练不同的损失函数，实现了类似于人类的左右半球专门化控制系统，该系统在不同的运动任务中展现出协调性、运动效率和位置稳定性的优势。

    

    神经网络运动控制器相对传统控制方法具有各种优点，然而由于其无法产生可靠的精确运动，因此尚未得到广泛采用。本研究探讨了一种双侧神经网络架构作为运动任务的控制系统。我们旨在实现类似于人类在不同任务中观察到的半球专门化：优势系统（通常是右手、左半球）擅长协调和运动效率的任务，而非优势系统在需要位置稳定性的任务上表现更好。通过使用不同的损失函数对半球进行训练，实现了专门化。我们比较了具有专门化半球和无专门化半球、具有半球间连接（代表生物学脑桥）和无半球间连接、具有专门化和无专门化的单侧模型。

    Neural Network movement controllers promise a variety of advantages over conventional control methods however they are not widely adopted due to their inability to produce reliably precise movements. This research explores a bilateral neural network architecture as a control system for motor tasks. We aimed to achieve hemispheric specialisation similar to what is observed in humans across different tasks; the dominant system (usually the right hand, left hemisphere) excels at tasks involving coordination and efficiency of movement, and the non-dominant system performs better at tasks requiring positional stability. Specialisation was achieved by training the hemispheres with different loss functions tailored toward the expected behaviour of the respective hemispheres. We compared bilateral models with and without specialised hemispheres, with and without inter-hemispheric connectivity (representing the biological Corpus Callosum), and unilateral models with and without specialisation. 
    
[^16]: 一种用于多目标双层优化的一阶多梯度算法

    A First-Order Multi-Gradient Algorithm for Multi-Objective Bi-Level Optimization. (arXiv:2401.09257v1 [cs.LG])

    [http://arxiv.org/abs/2401.09257](http://arxiv.org/abs/2401.09257)

    本文提出了一种用于多目标双层优化的高效一阶多梯度算法FORUM，通过值函数方法将MOBLO问题重新形式化为约束多目标优化问题，并提出了一种新颖的多梯度聚合方法来解决挑战性的约束多目标优化问题。在理论和实证上的结果表明该方法的高效性和有效性。

    

    本文研究了多目标双层优化（MOBLO）问题，其中上层子问题是一个多目标优化问题，下层子问题是一个标量优化问题。现有基于梯度的MOBLO算法需要计算Hessian矩阵，从而导致计算效率低下的问题。为解决这个问题，我们提出了一种高效的一阶多梯度算法FORUM用于MOBLO。具体地，我们通过值函数方法将MOBLO问题重新形式化为约束多目标优化（MOO）问题。然后，我们提出了一种新颖的多梯度聚合方法来解决具有挑战性的约束MOO问题。从理论上讲，我们提供了复杂度分析，展示了所提方法的高效性和非渐进收敛结果。从实证上讲，广泛的实验验证了所提FORUM方法在不同学习问题中的有效性和高效性。尤其值得注意的是，在一些应用中，它达到了当前最先进的水平。

    In this paper, we study the Multi-Objective Bi-Level Optimization (MOBLO) problem, where the upper-level subproblem is a multi-objective optimization problem and the lower-level subproblem is for scalar optimization. Existing gradient-based MOBLO algorithms need to compute the Hessian matrix, causing the computational inefficient problem. To address this, we propose an efficient first-order multi-gradient method for MOBLO, called FORUM. Specifically, we reformulate MOBLO problems as a constrained multi-objective optimization (MOO) problem via the value-function approach. Then we propose a novel multi-gradient aggregation method to solve the challenging constrained MOO problem. Theoretically, we provide the complexity analysis to show the efficiency of the proposed method and a non-asymptotic convergence result. Empirically, extensive experiments demonstrate the effectiveness and efficiency of the proposed FORUM method in different learning problems. In particular, it achieves state-of-
    
[^17]: 用梯度弹射操纵特征可视化

    Manipulating Feature Visualizations with Gradient Slingshots. (arXiv:2401.06122v1 [cs.LG])

    [http://arxiv.org/abs/2401.06122](http://arxiv.org/abs/2401.06122)

    本研究探究了激活最大化方法在对抗模型操作中的脆弱性，并提出了一种新的方法来操纵特征可视化，以隐藏特定神经元的功能。

    

    深度神经网络(DNNs)能够学习复杂而多样化的表示，然而，学习到的概念的语义性质仍然未知。解释DNNs学习到的概念的常用方法是激活最大化(AM)，它生成一个合成的输入信号，最大化激活网络中的特定神经元。在本文中，我们研究了这种方法对于对抗模型操作的脆弱性，并引入了一种新的方法来操纵特征可视化，而不改变模型结构或对模型的决策过程产生显著影响。我们评估了我们的方法对几个神经网络模型的效果，并展示了它隐藏特定神经元功能的能力，在模型审核过程中使用选择的目标解释屏蔽了原始解释。作为一种补救措施，我们提出了一种防止这种操纵的防护措施，并提供了定量证据，证明了它的有效性。

    Deep Neural Networks (DNNs) are capable of learning complex and versatile representations, however, the semantic nature of the learned concepts remains unknown. A common method used to explain the concepts learned by DNNs is Activation Maximization (AM), which generates a synthetic input signal that maximally activates a particular neuron in the network. In this paper, we investigate the vulnerability of this approach to adversarial model manipulations and introduce a novel method for manipulating feature visualization without altering the model architecture or significantly impacting the model's decision-making process. We evaluate the effectiveness of our method on several neural network models and demonstrate its capabilities to hide the functionality of specific neurons by masking the original explanations of neurons with chosen target explanations during model auditing. As a remedy, we propose a protective measure against such manipulations and provide quantitative evidence which 
    
[^18]: Lie Group Decompositions for Equivariant Neural Networks. (arXiv:2310.11366v1 [cs.LG]) (等变神经网络的Lie群分解)

    Lie Group Decompositions for Equivariant Neural Networks. (arXiv:2310.11366v1 [cs.LG])

    [http://arxiv.org/abs/2310.11366](http://arxiv.org/abs/2310.11366)

    本论文提出了一种基于Lie群结构和几何特性的框架，可以处理非紧致非阿贝尔的Lie群，特别关注于$\text{GL}^{+}(n, \mathbb{R})$和$\text{SL}(n, \mathbb{R})$这两个Lie群。

    

    在训练（卷积）神经网络模型时，对几何变换的不变性和等变性被证明是非常有用的归纳偏差，特别是在低数据环境下。大部分研究集中在使用的对称群为紧致或阿贝尔群，或者两者都是。最近的研究拓展了使用的变换类别到Lie群的情况，主要通过使用其Lie代数以及群的指数和对数映射。然而，这样的方法在适用于更大的变换群时受到限制，因为根据所关心的群$G$的不同，指数映射可能不满射。当$G$既不是紧致群也不是阿贝尔群时，还会遇到进一步的限制。我们利用Lie群及其齐次空间的结构和几何特性，提出了一个可以处理这类群的框架，主要关注Lie群$G = \text{GL}^{+}(n, \mathbb{R})$和$G = \text{SL}(n, \mathbb{R}$。

    Invariance and equivariance to geometrical transformations have proven to be very useful inductive biases when training (convolutional) neural network models, especially in the low-data regime. Much work has focused on the case where the symmetry group employed is compact or abelian, or both. Recent work has explored enlarging the class of transformations used to the case of Lie groups, principally through the use of their Lie algebra, as well as the group exponential and logarithm maps. The applicability of such methods to larger transformation groups is limited by the fact that depending on the group of interest $G$, the exponential map may not be surjective. Further limitations are encountered when $G$ is neither compact nor abelian. Using the structure and geometry of Lie groups and their homogeneous spaces, we present a framework by which it is possible to work with such groups primarily focusing on the Lie groups $G = \text{GL}^{+}(n, \mathbb{R})$ and $G = \text{SL}(n, \mathbb{R}
    
[^19]: NuTime: 大规模时间序列预训练的数值多尺度嵌入

    NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series Pretraining. (arXiv:2310.07402v1 [cs.LG])

    [http://arxiv.org/abs/2310.07402](http://arxiv.org/abs/2310.07402)

    本研究通过采用Transformer架构和数值多尺度嵌入模块，使时间序列自监督模型能够扩展到大规模数据集，并在大规模数据集上进行预训练。

    

    最近关于时间序列自监督模型的研究显示出学习语义表示的巨大潜力，然而，这些研究仅限于小规模数据集，例如数千个时间序列。本文的关键技术贡献针对时间序列数据的数值特性，使模型能够扩展到大规模数据集，例如百万个时间序列。我们采用Transformer架构，首先将输入划分为非重叠窗口。然后，通过窗口的标准化形状和两个标量值表示每个窗口内的均值和标准差。为了将可能具有任意数值尺度的标量值嵌入到高维向量中，我们提出了一个数值多尺度嵌入模块，枚举所有可能的标量值尺度。该模型使用提出的数值多尺度嵌入在大规模数据集上进行预训练，采用简单的对比损失函数。

    Recent research on time-series self-supervised models shows great promise in learning semantic representations. However, it has been limited to small-scale datasets, e.g., thousands of temporal sequences. In this work, we make key technical contributions that are tailored to the numerical properties of time-series data and allow the model to scale to large datasets, e.g., millions of temporal sequences. We adopt the Transformer architecture by first partitioning the input into non-overlapping windows. Each window is then characterized by its normalized shape and two scalar values denoting the mean and standard deviation within each window. To embed scalar values that may possess arbitrary numerical scales to high-dimensional vectors, we propose a numerically multi-scaled embedding module enumerating all possible scales for the scalar values. The model undergoes pretraining using the proposed numerically multi-scaled embedding with a simple contrastive objective on a large-scale dataset
    
[^20]: 面向基于表格数据的学习的基础模型研究

    Towards Foundation Models for Learning on Tabular Data. (arXiv:2310.07338v1 [cs.LG])

    [http://arxiv.org/abs/2310.07338](http://arxiv.org/abs/2310.07338)

    本文提出了Tabular Foundation Models (TabFMs)，通过利用生成型表格学习的潜力，采用预训练的大规模语言模型作为基础模型，并在广泛的表格数据集上进行微调，赋予TabFMs深刻的理解和普遍的能力，从而克服了当前可转移的表格模型的限制。

    

    基于表格数据的学习支撑着众多实际应用。尽管在开发针对表格数据的有效学习模型方面已经做出了相当大的努力，但目前可转移的表格模型仍然处于初级阶段，要么缺乏直接指令跟随新任务的支持，要么忽视从不同的表格数据集中获取基础知识和能力。在本文中，我们提出了Tabular Foundation Models (TabFMs)来克服这些限制。TabFMs利用生成型表格学习的潜力，采用预训练的大规模语言模型 (LLM) 作为基础模型，并使用经过专门设计的目标在大范围的表格数据集上进行微调。这种方法赋予TabFMs深刻的理解和普遍的能力，对于表格数据的学习至关重要。我们的评估强调了TabFM的有效性：它不仅在零样本和上下文推理等遵循指令的任务中明显出色，

    Learning on tabular data underpins numerous real-world applications. Despite considerable efforts in developing effective learning models for tabular data, current transferable tabular models remain in their infancy, limited by either the lack of support for direct instruction following in new tasks or the neglect of acquiring foundational knowledge and capabilities from diverse tabular datasets. In this paper, we propose Tabular Foundation Models (TabFMs) to overcome these limitations. TabFMs harness the potential of generative tabular learning, employing a pre-trained large language model (LLM) as the base model and fine-tuning it using purpose-designed objectives on an extensive range of tabular datasets. This approach endows TabFMs with a profound understanding and universal capabilities essential for learning on tabular data. Our evaluations underscore TabFM's effectiveness: not only does it significantly excel in instruction-following tasks like zero-shot and in-context inference
    
[^21]: 生成模型的核评分的偏差-方差-协方差分解

    A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models. (arXiv:2310.05833v1 [cs.LG])

    [http://arxiv.org/abs/2310.05833](http://arxiv.org/abs/2310.05833)

    该论文首次引入了生成模型的核评分的偏差-方差-协方差分解，并提出了相应的量的无偏和一致估计器。通过应用在扩散模型上发现少数群体的模式坍缩是一种与过拟合相反的现象，并证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。

    

    生成模型在我们日常生活中变得越来越重要，然而，尚不存在一个理论框架来评估它们的泛化行为和不确定性。特别是，不确定性估计问题通常以一种特定任务的临时解决方案来解决。例如，自然语言方法不能应用于图像生成。在本文中，我们首次引入了用于核评分及其相关熵的偏差-方差-协方差分解。我们提出了每个量的无偏和一致估计器，只需要生成样本而不需要底层模型本身。作为应用，我们提供了扩散模型的泛化评估，并发现少数群体的模式坍缩是一种与过拟合相反的现象。此外，我们证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。具体来说，我们的方法使得可以通过样本生成评估生成模型的泛化性能，并且发现了不同模型类型下的不确定性现象。

    Generative models, like large language models, are becoming increasingly relevant in our daily lives, yet a theoretical framework to assess their generalization behavior and uncertainty does not exist. Particularly, the problem of uncertainty estimation is commonly solved in an ad-hoc manner and task dependent. For example, natural language approaches cannot be transferred to image generation. In this paper we introduce the first bias-variance-covariance decomposition for kernel scores and their associated entropy. We propose unbiased and consistent estimators for each quantity which only require generated samples but not the underlying model itself. As an application, we offer a generalization evaluation of diffusion models and discover how mode collapse of minority groups is a contrary phenomenon to overfitting. Further, we demonstrate that variance and predictive kernel entropy are viable measures of uncertainty for image, audio, and language generation. Specifically, our approach f
    
[^22]: SyMOT-Flow: 学习两个任意分布之间的最优输运流动及最大平均差异

    SyMOT-Flow: Learning optimal transport flow for two arbitrary distributions with maximum mean discrepancy. (arXiv:2308.13815v1 [cs.LG])

    [http://arxiv.org/abs/2308.13815](http://arxiv.org/abs/2308.13815)

    本文介绍了一个名为SyMOT-Flow的新模型，它通过最小化两个未知分布样本之间的对称最大平均差异来训练可逆转换，并结合最优输运成本作为正则化，将未知分布转换为标准正态分布。实验证明这种转换可以实现更稳定准确的样本生成。

    

    找到两个未知概率分布之间的转换对于建模复杂数据分布和执行密度估计、样本生成和统计推断等任务至关重要。本文引入了一个名为SyMOT-Flow的新模型，通过最小化两个未知分布样本之间的对称最大平均差异来训练一个可逆转换，并结合最优输运成本作为正则化以获得一个短距离和可解释的转换。得到的转换可以实现更稳定准确的样本生成。我们为所提出的模型建立了一些理论结果，并通过低维示例和高维生成样本展示了其有效性。

    Finding a transformation between two unknown probability distributions from samples is crucial for modeling complex data distributions and perform tasks such as density estimation, sample generation, and statistical inference. One powerful framework for such transformations is normalizing flow, which transforms an unknown distribution into a standard normal distribution using an invertible network. In this paper, we introduce a novel model called SyMOT-Flow that trains an invertible transformation by minimizing the symmetric maximum mean discrepancy between samples from two unknown distributions, and we incorporate an optimal transport cost as regularization to obtain a short-distance and interpretable transformation. The resulted transformation leads to more stable and accurate sample generation. We establish several theoretical results for the proposed model and demonstrate its effectiveness with low-dimensional illustrative examples as well as high-dimensional generative samples obt
    
[^23]: MCMC-修正基于得分的扩散模型用于模型组合

    MCMC-Correction of Score-Based Diffusion Models for Model Composition. (arXiv:2307.14012v1 [stat.ML])

    [http://arxiv.org/abs/2307.14012](http://arxiv.org/abs/2307.14012)

    本文提出了一种修正基于得分的扩散模型的方法，使其能够与各种MCMC方法结合，从而实现模型组合和进行更好的采样。

    

    扩散模型可以用得分或能量函数来参数化。能量参数化具有更好的理论特性，主要是它可以通过在提议样本中总能量的变化基于Metropolis-Hastings修正步骤来进行扩展采样过程。然而，它似乎产生了稍微较差的性能，更重要的是，由于基于得分的扩散模型的普遍流行，现有的预训练能量参数化模型的可用性受到限制。这种限制削弱了模型组合的目的，即将预训练模型组合起来从新分布中进行采样。然而，我们的提议建议保留得分参数化，而是通过对得分函数进行线积分来计算基于能量的接受概率。这使我们能够重用现有的扩散模型，并将反向过程与各种马尔可夫链蒙特卡罗（MCMC）方法组合起来。

    Diffusion models can be parameterised in terms of either a score or an energy function. The energy parameterisation has better theoretical properties, mainly that it enables an extended sampling procedure with a Metropolis--Hastings correction step, based on the change in total energy in the proposed samples. However, it seems to yield slightly worse performance, and more importantly, due to the widespread popularity of score-based diffusion, there are limited availability of off-the-shelf pre-trained energy-based ones. This limitation undermines the purpose of model composition, which aims to combine pre-trained models to sample from new distributions. Our proposal, however, suggests retaining the score parameterization and instead computing the energy-based acceptance probability through line integration of the score function. This allows us to re-use existing diffusion models and still combine the reverse process with various Markov-Chain Monte Carlo (MCMC) methods. We evaluate our 
    
[^24]: 遵守法律并遵循流程：梯度流的守恒定律

    Abide by the Law and Follow the Flow: Conservation Laws for Gradient Flows. (arXiv:2307.00144v1 [cs.LG])

    [http://arxiv.org/abs/2307.00144](http://arxiv.org/abs/2307.00144)

    本文通过定义和研究梯度流中的守恒定律，以及在模型的雅可比矩阵生成的李代数上进行有限维代数运算，揭示了超参数调节的模型保留了一些优化初始化的特性，这可能解释了训练模型具有良好泛化特性的原因。

    

    理解梯度下降动力学的几何特性是解密非常大的机器学习模型最近成功的关键因素。一个引人注目的观察是，超参数调节的模型保留了一些优化初始化的特性。这种“隐式偏差”被认为是训练模型具有有利特性并能解释其良好泛化特性的原因。本文的目的有三个。首先，我们严格介绍了“守恒定律”的定义和基本性质，这些守恒定律是在给定模型（例如具有给定架构的ReLU网络）的梯度流中独立保持的最大量。不论使用任何训练数据和任何损失函数。然后，我们解释如何通过对模型的雅可比矩阵生成的李代数进行有限维代数运算，找到这些数量的确切数量。最后，我们提供了在SageMath中实现的算法。

    Understanding the geometric properties of gradient descent dynamics is a key ingredient in deciphering the recent success of very large machine learning models. A striking observation is that trained over-parameterized models retain some properties of the optimization initialization. This "implicit bias" is believed to be responsible for some favorable properties of the trained models and could explain their good generalization properties. The purpose of this article is threefold. First, we rigorously expose the definition and basic properties of "conservation laws", which are maximal sets of independent quantities conserved during gradient flows of a given model (e.g. of a ReLU network with a given architecture) with any training data and any loss. Then we explain how to find the exact number of these quantities by performing finite-dimensional algebraic manipulations on the Lie algebra generated by the Jacobian of the model. Finally, we provide algorithms (implemented in SageMath) to
    
[^25]: 控制变量的神经符号回归

    Neural Symbolic Regression using Control Variables. (arXiv:2306.04718v1 [cs.LG])

    [http://arxiv.org/abs/2306.04718](http://arxiv.org/abs/2306.04718)

    提出了一种利用控制变量的神经符号回归方法，可以分解多变量符号回归为单变量回归，并从底部向上组合，解决了符号回归存在的精度和可扩展性问题。

    

    符号回归是一种从数据中发现分析数学表达式的强有力技术，由于其良好的结果可解释性，在自然科学中应用广泛。然而，现有的方法在处理涉及多个变量的复杂方程时面临可伸缩性问题。为了应对这一挑战，我们提出了 SRCV，一种新颖的神经符号回归方法，利用控制变量来增强精度和可扩展性。核心思想是将多变量符号回归分解为一组单变量 SR 问题，然后从底部向上组合。该方法包括四个步骤。首先，我们使用深度神经网络（DNN）从观察到的数据中学习数据生成器。其次，使用数据生成器通过控制输入变量来生成特定变量的样本。第三，应用单变量符号回归来估计相应的数学表达式。

    Symbolic regression (SR) is a powerful technique for discovering the analytical mathematical expression from data, finding various applications in natural sciences due to its good interpretability of results. However, existing methods face scalability issues when dealing with complex equations involving multiple variables. To address this challenge, we propose SRCV, a novel neural symbolic regression method that leverages control variables to enhance both accuracy and scalability. The core idea is to decompose multi-variable symbolic regression into a set of single-variable SR problems, which are then combined in a bottom-up manner. The proposed method involves a four-step process. First, we learn a data generator from observed data using deep neural networks (DNNs). Second, the data generator is used to generate samples for a certain variable by controlling the input variables. Thirdly, single-variable symbolic regression is applied to estimate the corresponding mathematical expressio
    
[^26]: 公平的列子集选择

    Fair Column Subset Selection. (arXiv:2306.04489v1 [cs.LG])

    [http://arxiv.org/abs/2306.04489](http://arxiv.org/abs/2306.04489)

    解决了公平的列子集选择问题，通过已知方法基于确定性杠杆分数采样，提出了一种有效算法，可以在1.5倍的大小下实现与两倍相同的近似保证。

    

    我们考虑公平的列子集选择问题。特别地，我们假设数据中存在两个群体，并且所选列子集必须相对于它们各自的最佳秩-k逼近提供良好的近似。我们证明了这种公平设置引入了重大挑战：为了扩展已知结果，人们不能做得比简单地选择原始方法的两倍列更好。我们采用了基于确定性杠杆分数采样的已知方法，并且在存在两个群体的情况下，仅仅采样适当大小的子集就变得NP难。而找到两倍于所需大小的子集则非常简单，我们提供了一种有效的算法，它可以在基本上1.5倍的大小的情况下实现相同的保证。我们通过对真实世界数据的广泛实验验证了我们的方法。

    We consider the problem of fair column subset selection. In particular, we assume that two groups are present in the data, and the chosen column subset must provide a good approximation for both, relative to their respective best rank-k approximations. We show that this fair setting introduces significant challenges: in order to extend known results, one cannot do better than the trivial solution of simply picking twice as many columns as the original methods. We adopt a known approach based on deterministic leverage-score sampling, and show that merely sampling a subset of appropriate size becomes NP-hard in the presence of two groups. Whereas finding a subset of two times the desired size is trivial, we provide an efficient algorithm that achieves the same guarantees with essentially 1.5 times that size. We validate our methods through an extensive set of experiments on real-world data.
    
[^27]: 用于带测量噪声的Ornstein-Uhlenbeck过程参数估计

    Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise. (arXiv:2305.13498v1 [stat.ML])

    [http://arxiv.org/abs/2305.13498](http://arxiv.org/abs/2305.13498)

    本文研究了带有测量噪声的Ornstein-Uhlenbeck过程参数估计，提出了算法和方法能够分离热噪声和乘性噪声，并改善数据分析的参数估计精度。

    

    本文旨在研究噪声对Ornstein-Uhlenbeck过程参数拟合的影响，重点考察了乘性噪声和热噪声对信号分离精度的影响。为了解决这些问题，我们提出了有效区分热噪声和乘性噪声、改善参数估计精度的算法和方法，探讨了乘性和热噪声对实际信号混淆的影响，并提出了解决方法。首先，我们提出了一种可以有效分离热噪声的算法，其性能可与Hamilton Monte Carlo (HMC)相媲美，但速度显著提高。随后，我们分析了乘性噪声，并证明了HMC无法隔离热噪声和乘性噪声。然而，我们展示了，在额外了解热噪声和乘性噪声之间比率的情况下，我们可以精确地估计参数和分离信号。

    This article aims to investigate the impact of noise on parameter fitting for an Ornstein-Uhlenbeck process, focusing on the effects of multiplicative and thermal noise on the accuracy of signal separation. To address these issues, we propose algorithms and methods that can effectively distinguish between thermal and multiplicative noise and improve the precision of parameter estimation for optimal data analysis. Specifically, we explore the impact of both multiplicative and thermal noise on the obfuscation of the actual signal and propose methods to resolve them. Firstly, we present an algorithm that can effectively separate thermal noise with comparable performance to Hamilton Monte Carlo (HMC) but with significantly improved speed. Subsequently, we analyze multiplicative noise and demonstrate that HMC is insufficient for isolating thermal and multiplicative noise. However, we show that, with additional knowledge of the ratio between thermal and multiplicative noise, we can accuratel
    
[^28]: 在联邦学习中平衡隐私与安全：FedGT的群体测试框架

    Balancing Privacy and Security in Federated Learning with FedGT: A Group Testing Framework. (arXiv:2305.05506v1 [cs.LG])

    [http://arxiv.org/abs/2305.05506](http://arxiv.org/abs/2305.05506)

    该论文提出了FedGT框架，通过群体测试的方法在联邦学习中识别并删除恶意客户，从而平衡了隐私和安全，保护数据隐私并提高了识别恶意客户的能力。

    

    我们提出FedGT，一个新颖的框架，用于在联邦学习中识别恶意客户并进行安全聚合。受到群体测试的启发，该框架利用重叠的客户组来检测恶意客户的存在，并通过译码操作识别它们。然后，将这些被识别的客户从模型的训练中删除，并在其余客户之间执行训练。FedGT在隐私和安全之间取得平衡，允许改进识别能力同时仍保护数据隐私。具体而言，服务器学习每个组中客户的聚合模型。通过对MNIST和CIFAR-10数据集进行大量实验，证明了FedGT的有效性，展示了其识别恶意客户的能力，具有低误检和虚警概率，产生高模型效用。

    We propose FedGT, a novel framework for identifying malicious clients in federated learning with secure aggregation. Inspired by group testing, the framework leverages overlapping groups of clients to detect the presence of malicious clients in the groups and to identify them via a decoding operation. The identified clients are then removed from the training of the model, which is performed over the remaining clients. FedGT strikes a balance between privacy and security, allowing for improved identification capabilities while still preserving data privacy. Specifically, the server learns the aggregated model of the clients in each group. The effectiveness of FedGT is demonstrated through extensive experiments on the MNIST and CIFAR-10 datasets, showing its ability to identify malicious clients with low misdetection and false alarm probabilities, resulting in high model utility.
    
[^29]: 一种抗噪声的声学方法用于识别牛的觅食活动

    A noise-robust acoustic method for recognition of foraging activities of grazing cattle. (arXiv:2304.14824v1 [cs.LG])

    [http://arxiv.org/abs/2304.14824](http://arxiv.org/abs/2304.14824)

    本研究提出了一种抗噪声的声学方法，能够分析与吃草和反刍相关的鉴定下颚运动事件的固定长度段，用于识别牛的觅食活动，并在环境和自然噪声方面具有鲁棒性。

    

    为了在不断增长的乳制品市场中保持竞争力，农民必须不断改进他们的畜牧生产系统。精确畜牧业技术提供了商业农场动物个体化监测，优化畜牧生产。连续的声学监测是一种广泛接受的感应技术，用于估计自由放牧牛的日反刍和吃草时间预算。然而，牧场上的典型环境和自然噪声明显影响当前声学方法的性能和泛化。在本研究中，我们提出了一种声学方法，称为抗噪声觅食活动识别器 (NRFAR)。该方法通过分析与吃草和反刍相关的鉴定下颚运动事件的固定长度段，确定觅食活动的突发。NRFAR 的加性噪声鲁棒性使用静态高斯白噪声和四种不同的非静态自然噪声进行评估。

    To stay competitive in the growing dairy market, farmers must continuously improve their livestock production systems. Precision livestock farming technologies provide individualised monitoring of animals on commercial farms, optimising livestock production. Continuous acoustic monitoring is a widely accepted sensing technique used to estimate the daily rumination and grazing time budget of free-ranging cattle. However, typical environmental and natural noises on pasture noticeably affect the performance and generalisation of current acoustic methods. In this study, we present an acoustic method called Noise-Robust Foraging Activity Recognizer (NRFAR). The proposed method determines foraging activity bouts by analysing fixed-length segments of identified jaw movement events associated with grazing and rumination. The additive noise robustness of NRFAR was evaluated for several signal-to-noise ratios, using stationary Gaussian white noise and four different non-stationary natural noise 
    
[^30]: CodeGeeX：多语言评估下的预训练代码生成模型

    CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X. (arXiv:2303.17568v1 [cs.LG])

    [http://arxiv.org/abs/2303.17568](http://arxiv.org/abs/2303.17568)

    CodeGeeX是一个多语言模型，具有130亿参数，用于代码生成。经过广泛的实验证明，CodeGeeX在HumanEval-X上的代码生成和翻译任务中表现优异。此外，CodeGeeX可以将程序员的生产力提高22%。

    

    大型预训练代码生成模型（如OpenAI Codex）可以生成正确语法和功能的代码，使程序员的编码更加高效，使我们对人工智能的追求更加贴近现实。本文介绍了CodeGeeX，一个具有130亿参数的多语言模型，用于代码生成。CodeGeeX在2022年6月时基于23种编程语言的8500亿令牌进行了预训练。我们的广泛实验表明，CodeGeeX在HumanEval-X上的代码生成和翻译任务中均优于规模相似的多语言代码模型。在HumanEval（仅限Python）的基础上，我们开发了HumanEval-X基准测试，通过手写C ++、Java、JavaScript和Go的解决方案来评估多语言模型。此外，我们在Visual Studio Code、JetBrains和Cloud Studio上构建了基于CodeGeeX的扩展，每周为数以万计的活跃用户生成47亿令牌。我们的用户研究表明，CodeGeeX可以将程序员的生产力提高22%。

    Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive and our pursuit of artificial general intelligence closer. In this paper, we introduce CodeGeeX, a multilingual model with 13 billion parameters for code generation. CodeGeeX is pre-trained on 850 billion tokens of 23 programming languages as of June 2022. Our extensive experiments suggest that CodeGeeX outperforms multilingual code models of similar scale for both the tasks of code generation and translation on HumanEval-X. Building upon HumanEval (Python only), we develop the HumanEval-X benchmark for evaluating multilingual models by hand-writing the solutions in C++, Java, JavaScript, and Go. In addition, we build CodeGeeX-based extensions on Visual Studio Code, JetBrains, and Cloud Studio, generating 4.7 billion tokens for tens of thousands of active users per week. Our user study demonstrates that CodeGeeX can help to inc
    
[^31]: 跨模型公平性：多模型情况下的公平性与伦理实证研究

    Cross-model Fairness: Empirical Study of Fairness and Ethics Under Model Multiplicity. (arXiv:2203.07139v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.07139](http://arxiv.org/abs/2203.07139)

    本文提出了一种跨模型公平性的新定义，并进行了实证研究。该研究关注数据驱动预测模型在社会背景下的公平性问题，特别是在通过选择不同预测器进行模型多样性时可能导致个人受伤害的情况。

    

    虽然基于数据驱动的预测模型是一个严格的技术构造，但它们可能在社会背景下运作，在这个背景下，善意的工程选择可能带来隐含的、间接的和意想不到的现实后果。在这个领域中，这些系统的公平性，涉及到个人和群体，是一个相关的考虑因素；它在数据捕捉可导致人们受到歧视的受保护特征时出现。迄今为止，这个概念主要针对固定模型进行研究，通常在不同的分类阈值下进行研究，力图识别和消除其运作中不希望的、具有歧视性和可能违法的方面。在本文中，我们回溯了这个固定模型的假设，提出并探索了一种新的跨模型公平性定义，即在从一组表现同样出色的模型中特定选择预测器的情况下，个人可能受到伤害，即在基于效用的模型多样性的视图下。由于一个人在不同的模型下可能被分类不同。

    While data-driven predictive models are a strictly technological construct, they may operate within a social context in which benign engineering choices entail implicit, indirect and unexpected real-life consequences. Fairness of such systems -- pertaining both to individuals and groups -- is one relevant consideration in this space; it arises when data capture protected characteristics upon which people may be discriminated. To date, this notion has predominantly been studied for a fixed model, often under different classification thresholds, striving to identify and eradicate undesirable, discriminative and possibly unlawful aspects of its operation. Here, we backtrack on this fixed model assumption to propose and explore a novel definition of cross-model fairness where individuals can be harmed when one predictor is chosen ad hoc from a group of equally-well performing models, i.e., in view of utility-based model multiplicity. Since a person may be classified differently across mode
    
[^32]: 当机会来临时进行交易：基于注意力机制和迭代细化标注的价格变动预测

    Trade When Opportunity Comes: Price Movement Forecasting via Locality-Aware Attention and Iterative Refinement Labeling. (arXiv:2107.11972v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.11972](http://arxiv.org/abs/2107.11972)

    本论文提出了一种名为LARA的新型价格变动预测框架，包括两个主要部分：局部感知注意力和迭代细化标注。在真实世界的金融数据集上的实验结果表明，LARA在准确性和盈利能力方面优于现有的最先进方法。

    

    价格变动预测旨在根据当前市场情况和其他相关信息预测金融资产的未来趋势。最近，机器学习（ML）方法在学术界和工业界中越来越受欢迎，并取得了令人满意的结果。然而，由于金融数据的低信噪比和随机性极强，好的交易机会极为稀少。因此，如果不仔细选择潜在的盈利样本，这些ML方法容易捕捉到噪声而不是真实信号的模式。为解决这个问题，本研究提出了一种名为LARA的新型价格变动预测框架，包括两个主要部分：局部感知注意力（LA-Attention）和迭代细化标注（IRL）。LA-Attention旨在有选择地关注金融数据中最具信息量的局部区域，而IRL则旨在迭代地细化标注过程，过滤掉噪声和无关样本。在真实世界的金融数据集上的实验结果表明，LARA在准确性和盈利能力方面优于现有的最先进方法。

    Price movement forecasting aims at predicting the future trends of financial assets based on the current market conditions and other relevant information. Recently, machine learning (ML) methods have become increasingly popular and achieved promising results for price movement forecasting in both academia and industry. Most existing ML solutions formulate the forecasting problem as a classification (to predict the direction) or a regression (to predict the return) problem over the entire set of training data. However, due to the extremely low signal-to-noise ratio and stochastic nature of financial data, good trading opportunities are extremely scarce. As a result, without careful selection of potentially profitable samples, such ML methods are prone to capture the patterns of noises instead of real signals. To address this issue, we propose a novel price movement forecasting framework named LARA consisting of two main components: Locality-Aware Attention (LA-Attention) and Iterative R
    

