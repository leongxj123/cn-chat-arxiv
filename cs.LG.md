# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Recent Advances in Predictive Modeling with Electronic Health Records](https://rss.arxiv.org/abs/2402.01077) | 这项调查总结了基于电子健康记录数据的深度学习预测模型的最新进展，包括背景介绍、数学定义、分类总结、基准和工具包，以及未来研究方向的讨论。 |
| [^2] | [SSHPool: The Separated Subgraph-based Hierarchical Pooling](https://arxiv.org/abs/2403.16133) | 提出了基于分隔子图的分层池化（SSHPool）方法，通过将节点分配到不同的簇并利用局部图卷积单元进行压缩，解决了现有图神经网络中的过度平滑问题，有效提取了原始图结构的分层全局特征。 |
| [^3] | [AKBR: Learning Adaptive Kernel-based Representations for Graph Classification](https://arxiv.org/abs/2403.16130) | 提出了一种用于图分类的自适应核表示学习模型，通过特征通道注意机制捕捉不同子结构之间的相互依赖关系，有效识别结构重要性，并计算与重要子结构相关的图对之间的R-卷积核。 |
| [^4] | [Simplified Diffusion Schr\"odinger Bridge](https://arxiv.org/abs/2403.14623) | 介绍了简化后的扩散薛定谔桥（DSB），通过与基于得分的生成模型（SGM）的统一解决了复杂数据生成中的限制，提高了性能并加快了收敛速度。 |
| [^5] | [Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting](https://arxiv.org/abs/2403.13369) | 使用预训练语言模型和提示技术，在少资源语言情境下，仅需少量样本训练即可提取临床信息，且表现优于传统方法。 |
| [^6] | [Two-scale Neural Networks for Partial Differential Equations with Small Parameters](https://arxiv.org/abs/2402.17232) | 提出了一种用双尺度神经网络方法解决具有小参数的偏微分方程的方法，能够直接将小参数纳入神经网络架构中，从而简化解决过程，并能够合理准确地捕捉由小参数引起的解中大导数特征。 |
| [^7] | [How Transformers Learn Causal Structure with Gradient Descent](https://arxiv.org/abs/2402.14735) | Transformers通过梯度下降学习因果结构的过程中，关键的证据是注意力矩阵的梯度编码了token之间的互信息 |
| [^8] | [Enhancing Real-World Complex Network Representations with Hyperedge Augmentation](https://arxiv.org/abs/2402.13033) | 提出了一种新颖的图增强方法Hyperedge Augmentation (HyperAug)，通过构建直接从原始数据形成的虚拟超边，以解决现实世界复杂网络表示中高阶节点关系的问题 |
| [^9] | [Maintaining Adversarial Robustness in Continuous Learning](https://arxiv.org/abs/2402.11196) | 提出了一种名为双梯度投影的方法，通过将梯度投影到两个关键子空间来实现持续鲁棒学习，有效地维持了神经网络对抗性鲁棒性。 |
| [^10] | [PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2402.07867) | 本论文提出了一种名为PoisonedRAG的知识污染攻击方法，用于对大型语言模型的检索增强生成进行攻击和破坏。 |
| [^11] | [Extending the Reach of First-Order Algorithms for Nonconvex Min-Max Problems with Cohypomonotonicity](https://arxiv.org/abs/2402.05071) | 本文研究了具有连带偏序特性的非凸极小极大问题，提出了一阶算法的适用范围，并在理论上证明了算法的复杂度保证。 |
| [^12] | [Continual Driving Policy Optimization with Closed-Loop Individualized Curricula](https://arxiv.org/abs/2309.14209) | 开发了连续驾驶政策优化框架，提出了闭环个性化课程（CLIC）概念，允许重复利用广泛场景来迭代改进自主驾驶车辆模型。 |
| [^13] | [EdgeOL: Efficient in-situ Online Learning on Edge Devices.](http://arxiv.org/abs/2401.16694) | 本文提出了EdgeOL，一种边缘在线学习框架，通过内部和外部调优来优化推理准确性、微调执行时间和能量效率，在边缘设备上实现了显著的性能提升。 |
| [^14] | [The Distributional Uncertainty of the SHAP score in Explainable Machine Learning.](http://arxiv.org/abs/2401.12731) | 本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。 |
| [^15] | [Operator Learning for Continuous Spatial-Temporal Model with Gradient-Based and Derivative-Free Optimization Methods.](http://arxiv.org/abs/2311.11798) | 本论文提出了一种基于梯度和无导数优化方法的连续时空模型的算子学习框架，具有空间和时间上的分辨率不变性，并能够在短期时间序列和长期统计数据上高效训练。 |
| [^16] | [Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of Text-To-Image Models.](http://arxiv.org/abs/2310.01929) | 本研究旨在探索和解锁文本到图像模型的文化视角，通过对TTI模型中嵌入的文化感知进行评估，揭示了这些模型的文化意识、文化区别和文化适应性。 |
| [^17] | [Latent Space Symmetry Discovery.](http://arxiv.org/abs/2310.00105) | 提出了一种新的生成模型——潜空间LieGAN（LaLiGAN），可以从数据中发现非线性对称性，并产生结构良好的潜空间，对其他下游任务非常有用。 |
| [^18] | [An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems.](http://arxiv.org/abs/2309.00983) | 我们提出了一种集成评分滤波器（EnSF），在处理高维非线性滤波问题时具有卓越的准确性。EnSF利用评分模型在伪时域中描述滤波密度的演化，并通过评分函数存储信息，相比于使用蒙特卡罗样本的粒子滤波器和集成卡尔曼滤波器具有更好的效果。 |
| [^19] | [Interpretable Graph Neural Networks for Tabular Data.](http://arxiv.org/abs/2308.08945) | 本论文提出了一种称为IGNNet的方法，可以在处理表格数据时使用图神经网络，该方法能够产生可解释的模型，从原始输入特征精确计算预测结果，并且在性能上与最先进的机器学习算法性能相当。 |
| [^20] | [Neural networks can detect model-free static arbitrage strategies.](http://arxiv.org/abs/2306.16422) | 本文证明了神经网络可以检测金融市场中的无模型静态套利机会，并可应用于交易证券数量较多的金融市场。我们的方法具有易处理性、有效性和稳健性，并使用真实金融数据进行了示例验证。 |
| [^21] | [Performative Prediction with Bandit Feedback: Learning through Reparameterization.](http://arxiv.org/abs/2305.01094) | 本文提出一种新的在线反馈的实现式预测框架，解决了在模型部署自身改变数据分布的情况下优化准确性的问题。 |
| [^22] | [Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs.](http://arxiv.org/abs/2304.11140) | 本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。 |

# 详细

[^1]: 电子健康记录预测建模的最新进展

    Recent Advances in Predictive Modeling with Electronic Health Records

    [https://rss.arxiv.org/abs/2402.01077](https://rss.arxiv.org/abs/2402.01077)

    这项调查总结了基于电子健康记录数据的深度学习预测模型的最新进展，包括背景介绍、数学定义、分类总结、基准和工具包，以及未来研究方向的讨论。

    

    电子健康记录（EHR）系统的发展使得大量的数字化患者数据得以收集。然而，由于其独特的特性，利用EHR数据进行预测建模面临着一些挑战。随着机器学习技术的进步，深度学习在包括医疗在内的各个领域展现出了卓越的优势。本调查系统地回顾了基于EHR数据的深度学习预测模型的最新进展。具体而言，我们首先介绍了EHR数据的背景，并提供了预测建模任务的数学定义。然后，我们从多个角度对预测深度模型进行分类和总结。此外，我们还介绍了与医疗预测建模相关的基准和工具包。最后，我们讨论了开放性挑战，并提出了未来研究的有希望的方向。

    The development of electronic health records (EHR) systems has enabled the collection of a vast amount of digitized patient data. However, utilizing EHR data for predictive modeling presents several challenges due to its unique characteristics. With the advancements in machine learning techniques, deep learning has demonstrated its superiority in various applications, including healthcare. This survey systematically reviews recent advances in deep learning-based predictive models using EHR data. Specifically, we begin by introducing the background of EHR data and providing a mathematical definition of the predictive modeling task. We then categorize and summarize predictive deep models from multiple perspectives. Furthermore, we present benchmarks and toolkits relevant to predictive modeling in healthcare. Finally, we conclude this survey by discussing open challenges and suggesting promising directions for future research.
    
[^2]: 基于分隔子图的分层池化SSHPool

    SSHPool: The Separated Subgraph-based Hierarchical Pooling

    [https://arxiv.org/abs/2403.16133](https://arxiv.org/abs/2403.16133)

    提出了基于分隔子图的分层池化（SSHPool）方法，通过将节点分配到不同的簇并利用局部图卷积单元进行压缩，解决了现有图神经网络中的过度平滑问题，有效提取了原始图结构的分层全局特征。

    

    在本文中，我们提出了一种新颖的本地图池化方法，称为基于分隔子图的分层池化（SSHPool），用于图分类。通过将一个样本图的节点分配到不同的簇中，从而产生一系列分隔的子图。我们分别使用本地图卷积单元作为局部结构，进一步将每个子图压缩成一个粗糙节点，将原始图转化为粗糙图。由于这些子图由不同的簇分隔开，结构信息无法在它们之间传播，局部卷积操作可以显著避免大多数现有图神经网络（GNNs）中出现的过度平滑问题。通过在结果粗糙图上层次地执行所提议的程序，SSHPool可以有效地提取原始图结构的分层全局特征。

    arXiv:2403.16133v1 Announce Type: new  Abstract: In this paper, we develop a novel local graph pooling method, namely the Separated Subgraph-based Hierarchical Pooling (SSHPool), for graph classification. To this end, we commence by assigning the nodes of a sample graph into different clusters, resulting in a family of separated subgraphs. We individually employ a local graph convolution units as the local structure to further compress each subgraph into a coarsened node, transforming the original graph into a coarsened graph. Since these subgraphs are separated by different clusters and the structural information cannot be propagated between them, the local convolution operation can significantly avoid the over-smoothing problem arising in most existing Graph Neural Networks (GNNs). By hierarchically performing the proposed procedures on the resulting coarsened graph, the proposed SSHPool can effectively extract the hierarchical global feature of the original graph structure, encapsul
    
[^3]: AKBR: 学习自适应基于核的图分类表示

    AKBR: Learning Adaptive Kernel-based Representations for Graph Classification

    [https://arxiv.org/abs/2403.16130](https://arxiv.org/abs/2403.16130)

    提出了一种用于图分类的自适应核表示学习模型，通过特征通道注意机制捕捉不同子结构之间的相互依赖关系，有效识别结构重要性，并计算与重要子结构相关的图对之间的R-卷积核。

    

    在本文中，我们提出了一种新模型，用于学习自适应基于核的图分类表示（AKBR）。与仅通过计算图之间同构子结构对的数量来定义的最先进的 R-卷积图核不同，无法为分类器提供端到端学习机制，所提出的AKBR方法旨在定义一个端到端表示学习模型，为图构建自适应核矩阵。为此，我们首先利用一种新颖的特征通道注意机制来捕捉原始图中不同子结构不变性之间的相互依赖关系。所提出的AKBR模型因此可以有效地确定不同子结构的结构重要性，并计算与由其结构注意力指定的更重要子结构相关的成对图之间的R-卷积核。由于结果核矩阵的每一行...（此处被截断）

    arXiv:2403.16130v1 Announce Type: cross  Abstract: In this paper, we propose a new model to learn Adaptive Kernel-based Representations (AKBR) for graph classification. Unlike state-of-the-art R-convolution graph kernels that are defined by merely counting any pair of isomorphic substructures between graphs and cannot provide an end-to-end learning mechanism for the classifier, the proposed AKBR approach aims to define an end-to-end representation learning model to construct an adaptive kernel matrix for graphs. To this end, we commence by leveraging a novel feature-channel attention mechanism to capture the interdependencies between different substructure invariants of original graphs. The proposed AKBR model can thus effectively identify the structural importance of different substructures, and compute the R-convolution kernel between pairwise graphs associated with the more significant substructures specified by their structural attentions. Since each row of the resulting kernel mat
    
[^4]: 简化扩散薛定谔桥

    Simplified Diffusion Schr\"odinger Bridge

    [https://arxiv.org/abs/2403.14623](https://arxiv.org/abs/2403.14623)

    介绍了简化后的扩散薛定谔桥（DSB），通过与基于得分的生成模型（SGM）的统一解决了复杂数据生成中的限制，提高了性能并加快了收敛速度。

    

    这篇论文介绍了一种新的理论简化扩散薛定谔桥（DSB），便于将其与基于得分的生成模型（SGM）统一起来，解决了DSB在复杂数据生成方面的局限性，实现更快的收敛速度和增强的性能。通过将SGM作为DSB的初始解决方案，我们的方法利用了这两个框架的优势，确保了更高效的训练过程，并改进了SGM的性能。我们还提出了一种重新参数化技术，尽管存在理论近似，但实际上提高了网络的拟合能力。我们进行了大量的实验证实，证实了简化的DSB的有效性，展示了其显著的改进。我们相信这项工作的贡献为先进的生成建模铺平了道路。

    arXiv:2403.14623v1 Announce Type: new  Abstract: This paper introduces a novel theoretical simplification of the Diffusion Schr\"odinger Bridge (DSB) that facilitates its unification with Score-based Generative Models (SGMs), addressing the limitations of DSB in complex data generation and enabling faster convergence and enhanced performance. By employing SGMs as an initial solution for DSB, our approach capitalizes on the strengths of both frameworks, ensuring a more efficient training process and improving the performance of SGM. We also propose a reparameterization technique that, despite theoretical approximations, practically improves the network's fitting capabilities. Our extensive experimental evaluations confirm the effectiveness of the simplified DSB, demonstrating its significant improvements. We believe the contributions of this work pave the way for advanced generative modeling. The code is available at https://github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge.
    
[^5]: 使用预训练语言模型和提示进行少资源语言的少样本学习的临床信息提取

    Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting

    [https://arxiv.org/abs/2403.13369](https://arxiv.org/abs/2403.13369)

    使用预训练语言模型和提示技术，在少资源语言情境下，仅需少量样本训练即可提取临床信息，且表现优于传统方法。

    

    从临床文件中自动提取医疗信息面临着几个挑战：所需临床专业知识的高成本、模型预测的有限可解释性、受限的计算资源以及隐私法规。最近在领域适应和提示方法上的进展显示，利用轻量级遮蔽语言模型在使用极少的训练数据时取得了令人期待的结果，这些模型适用于成熟的可解释性方法。我们首次在少资源环境中对这些方法进行了系统评估，通过在德国医生信件上进行多类别段分类来实现。我们进行了广泛的类别级评估，支持 Shapley 值，以验证我们的小型训练数据集的质量，并确保模型预测的可解释性。我们证明，一个轻量级、领域适应的预训练模型，在仅仅提示了 20 次的情况下，胜过了传统的分类

    arXiv:2403.13369v1 Announce Type: new  Abstract: Automatic extraction of medical information from clinical documents poses several challenges: high costs of required clinical expertise, limited interpretability of model predictions, restricted computational resources and privacy regulations. Recent advances in domain-adaptation and prompting methods showed promising results with minimal training data using lightweight masked language models, which are suited for well-established interpretability methods. We are first to present a systematic evaluation of these methods in a low-resource setting, by performing multi-class section classification on German doctor's letters. We conduct extensive class-wise evaluations supported by Shapley values, to validate the quality of our small training data set and to ensure the interpretability of model predictions. We demonstrate that a lightweight, domain-adapted pretrained model, prompted with just 20 shots, outperforms a traditional classificatio
    
[^6]: 具有小参数的偏微分方程的双尺度神经网络

    Two-scale Neural Networks for Partial Differential Equations with Small Parameters

    [https://arxiv.org/abs/2402.17232](https://arxiv.org/abs/2402.17232)

    提出了一种用双尺度神经网络方法解决具有小参数的偏微分方程的方法，能够直接将小参数纳入神经网络架构中，从而简化解决过程，并能够合理准确地捕捉由小参数引起的解中大导数特征。

    

    我们提出了一种用物理信息神经网络（PINNs）解决具有小参数的偏微分方程（PDEs）的双尺度神经网络方法。我们直接将小参数纳入神经网络的架构中。所提出的方法使得以简单方式解决具有小参数的PDE成为可能，而无需添加傅里叶特征或其他计算繁琐的截断参数搜索。多个数值例子展示了在解决由小参数引起的解中大导数特征时的合理准确性。

    arXiv:2402.17232v1 Announce Type: cross  Abstract: We propose a two-scale neural network method for solving partial differential equations (PDEs) with small parameters using physics-informed neural networks (PINNs). We directly incorporate the small parameters into the architecture of neural networks. The proposed method enables solving PDEs with small parameters in a simple fashion, without adding Fourier features or other computationally taxing searches of truncation parameters. Various numerical examples demonstrate reasonable accuracy in capturing features of large derivatives in the solutions caused by small parameters.
    
[^7]: Transformers如何通过梯度下降学习因果结构

    How Transformers Learn Causal Structure with Gradient Descent

    [https://arxiv.org/abs/2402.14735](https://arxiv.org/abs/2402.14735)

    Transformers通过梯度下降学习因果结构的过程中，关键的证据是注意力矩阵的梯度编码了token之间的互信息

    

    Transformers在序列建模任务上取得了令人难以置信的成功，这在很大程度上归功于自注意机制，它允许信息在序列的不同部分之间传递。自注意机制使得transformers能够编码因果结构，从而使其特别适合序列建模。然而，transformers通过梯度训练算法学习这种因果结构的过程仍然不太清楚。为了更好地理解这个过程，我们引入了一个需要学习潜在因果结构的上下文学习任务。我们证明了简化的两层transformer上的梯度下降可以学会解决这个任务，通过在第一层注意力中编码潜在因果图来完成。我们证明的关键洞察是注意力矩阵的梯度编码了token之间的互信息。由于数据处理不等式的结果，注意力矩阵中最大的条目...

    arXiv:2402.14735v1 Announce Type: new  Abstract: The incredible success of transformers on sequence modeling tasks can be largely attributed to the self-attention mechanism, which allows information to be transferred between different parts of a sequence. Self-attention allows transformers to encode causal structure which makes them particularly suitable for sequence modeling. However, the process by which transformers learn such causal structure via gradient-based training algorithms remains poorly understood. To better understand this process, we introduce an in-context learning task that requires learning latent causal structure. We prove that gradient descent on a simplified two-layer transformer learns to solve this task by encoding the latent causal graph in the first attention layer. The key insight of our proof is that the gradient of the attention matrix encodes the mutual information between tokens. As a consequence of the data processing inequality, the largest entries of th
    
[^8]: 用超边增强改进现实世界复杂网络表示

    Enhancing Real-World Complex Network Representations with Hyperedge Augmentation

    [https://arxiv.org/abs/2402.13033](https://arxiv.org/abs/2402.13033)

    提出了一种新颖的图增强方法Hyperedge Augmentation (HyperAug)，通过构建直接从原始数据形成的虚拟超边，以解决现实世界复杂网络表示中高阶节点关系的问题

    

    arXiv:2402.13033v1 公告类型: 新摘要: 图增强方法在改进图神经网络（GNNs）的性能和增强泛化能力中起着至关重要的作用。现有的图增强方法主要扰动图结构，通常限于成对节点关系。这些方法无法完全解决真实世界大规模网络的复杂性，这些网络通常涉及高阶节点关系，而不仅仅是成对关系。同时，由于缺乏可用于形成高阶边的数据，真实世界图数据集主要被建模为简单图。因此，将高阶边重新配置为图增强策略的一部分是一个有前途的研究路径，可解决前述问题。在本文中，我们提出了超边增强（HyperAug），一种新颖的图增强方法，直接从原始数据构建虚拟超边，并产生辅助节点。

    arXiv:2402.13033v1 Announce Type: new  Abstract: Graph augmentation methods play a crucial role in improving the performance and enhancing generalisation capabilities in Graph Neural Networks (GNNs). Existing graph augmentation methods mainly perturb the graph structures and are usually limited to pairwise node relations. These methods cannot fully address the complexities of real-world large-scale networks that often involve higher-order node relations beyond only being pairwise. Meanwhile, real-world graph datasets are predominantly modelled as simple graphs, due to the scarcity of data that can be used to form higher-order edges. Therefore, reconfiguring the higher-order edges as an integration into graph augmentation strategies lights up a promising research path to address the aforementioned issues. In this paper, we present Hyperedge Augmentation (HyperAug), a novel graph augmentation method that constructs virtual hyperedges directly form the raw data, and produces auxiliary nod
    
[^9]: 在连续学习中保持对抗性鲁棒性

    Maintaining Adversarial Robustness in Continuous Learning

    [https://arxiv.org/abs/2402.11196](https://arxiv.org/abs/2402.11196)

    提出了一种名为双梯度投影的方法，通过将梯度投影到两个关键子空间来实现持续鲁棒学习，有效地维持了神经网络对抗性鲁棒性。

    

    对抗性鲁棒性对于机器学习系统的安全性和可靠性至关重要。然而，通过复杂的防御算法获得的对抗性鲁棒性在神经网络不断演化以学习新任务时很容易被抹去。这种脆弱性可以通过培养一种新颖的神经网络能力来解决，称为持续鲁棒学习，它在连续学习过程中关注前期任务的(分类)性能和对抗性鲁棒性。为了实现持续鲁棒学习，我们提出了一种称为双梯度投影的方法，将用于权重更新的梯度正交投影到两个关键子空间上 -- 一个用于稳定平滑样本梯度，另一个用于稳定神经网络的最终输出。在四个基准测试上的实验结果表明，所提出的方法有效地维持了对强对抗性的持续鲁棒性。

    arXiv:2402.11196v1 Announce Type: cross  Abstract: Adversarial robustness is essential for security and reliability of machine learning systems. However, the adversarial robustness gained by sophisticated defense algorithms is easily erased as the neural network evolves to learn new tasks. This vulnerability can be addressed by fostering a novel capability for neural networks, termed continual robust learning, which focuses on both the (classification) performance and adversarial robustness on previous tasks during continuous learning. To achieve continuous robust learning, we propose an approach called Double Gradient Projection that projects the gradients for weight updates orthogonally onto two crucial subspaces -- one for stabilizing the smoothed sample gradients and another for stabilizing the final outputs of the neural network. The experimental results on four benchmarks demonstrate that the proposed approach effectively maintains continuous robustness against strong adversarial
    
[^10]: PoisonedRAG: 知识污染攻击对大型语言模型的检索增强生成

    PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models

    [https://arxiv.org/abs/2402.07867](https://arxiv.org/abs/2402.07867)

    本论文提出了一种名为PoisonedRAG的知识污染攻击方法，用于对大型语言模型的检索增强生成进行攻击和破坏。

    

    大型语言模型（LLM）由于其卓越的生成能力而取得了显著的成功。尽管如此，它们也存在固有的局限性，如缺乏最新的知识和虚构。检索增强生成（RAG）是一种最先进的技术，以减轻这些限制。具体而言，对于给定的问题，RAG从知识数据库中检索相关知识，以增强LLM的输入。例如，当知识数据库中包含从维基百科收集的数百万个文本时，检索到的知识可以是与给定问题在语义上最相似的前K个文本集。因此，LLM可以利用检索到的知识作为上下文为给定问题生成答案。现有研究主要集中在改善RAG的准确性或效率，而对其安全性的探索较少。我们旨在填补这一空白。

    Large language models (LLMs) have achieved remarkable success due to their exceptional generative capabilities. Despite their success, they also have inherent limitations such as a lack of up-to-date knowledge and hallucination. Retrieval-Augmented Generation (RAG) is a state-of-the-art technique to mitigate those limitations. In particular, given a question, RAG retrieves relevant knowledge from a knowledge database to augment the input of the LLM. For instance, the retrieved knowledge could be a set of top-k texts that are most semantically similar to the given question when the knowledge database contains millions of texts collected from Wikipedia. As a result, the LLM could utilize the retrieved knowledge as the context to generate an answer for the given question. Existing studies mainly focus on improving the accuracy or efficiency of RAG, leaving its security largely unexplored. We aim to bridge the gap in this work. Particularly, we propose PoisonedRAG , a set of knowledge pois
    
[^11]: 扩展具有连带偏序特性的非凸极小极大问题的一阶算法的适用范围

    Extending the Reach of First-Order Algorithms for Nonconvex Min-Max Problems with Cohypomonotonicity

    [https://arxiv.org/abs/2402.05071](https://arxiv.org/abs/2402.05071)

    本文研究了具有连带偏序特性的非凸极小极大问题，提出了一阶算法的适用范围，并在理论上证明了算法的复杂度保证。

    

    本文关注满足rho-连带偏序特性或在rho-弱Minty变分不等式（MVI）中存在解的约束，L-光滑的非凸非凹极小极大问题，其中参数rho>0的较大值对应更高的非凸性程度。这些问题类包括两个玩家强化学习，交互主导的极小极大问题以及某些经典极小极大算法无法解决的合成测试问题。已有猜想认为一阶方法可容忍最大rho为1/L，但现有文献中的结果已停滞在更严格的要求rho<1/2L。通过简单的论证，我们获得了具有连带偏序特性或弱MVI条件下，rho<1/L的最优或最佳已知复杂度保证。我们分析的算法是Halpern和Krasnosel'skiĭ-Mann (KM)迭代的非精确变种。我们还提供了算法和复杂度g...

    We focus on constrained, $L$-smooth, nonconvex-nonconcave min-max problems either satisfying $\rho$-cohypomonotonicity or admitting a solution to the $\rho$-weakly Minty Variational Inequality (MVI), where larger values of the parameter $\rho>0$ correspond to a greater degree of nonconvexity. These problem classes include examples in two player reinforcement learning, interaction dominant min-max problems, and certain synthetic test problems on which classical min-max algorithms fail. It has been conjectured that first-order methods can tolerate value of $\rho$ no larger than $\frac{1}{L}$, but existing results in the literature have stagnated at the tighter requirement $\rho < \frac{1}{2L}$. With a simple argument, we obtain optimal or best-known complexity guarantees with cohypomonotonicity or weak MVI conditions for $\rho < \frac{1}{L}$. The algorithms we analyze are inexact variants of Halpern and Krasnosel'ski\u{\i}-Mann (KM) iterations. We also provide algorithms and complexity g
    
[^12]: 具有闭环个性化课程的连续驾驶政策优化

    Continual Driving Policy Optimization with Closed-Loop Individualized Curricula

    [https://arxiv.org/abs/2309.14209](https://arxiv.org/abs/2309.14209)

    开发了连续驾驶政策优化框架，提出了闭环个性化课程（CLIC）概念，允许重复利用广泛场景来迭代改进自主驾驶车辆模型。

    

    自主驾驶车辆（AV）的安全一直是一个长期的头等关注点，根源于长尾自然驾驶分布中罕见的安全关键场景的缺失。为了解决这一挑战，出现了大量基于场景的自动驾驶研究，重点是生成高风险驾驶场景并将它们应用于对AV模型进行安全关键测试。然而，有限的工作探讨了重复利用这些广泛场景来迭代改进AV模型。此外，从具有不同行为的其他AV模型收集的巨大场景库中滤出可传递信息以改进当前AV仍然是难以解决的且具有挑战性。因此，我们开发了一个具有闭环个性化课程（CLIC）特点的连续驾驶政策优化框架，我们将其分解为一组标准化的子模块。

    arXiv:2309.14209v3 Announce Type: replace-cross  Abstract: The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution. To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models. However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models. Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement. Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for
    
[^13]: EdgeOL: 边缘设备上高效的原位在线学习

    EdgeOL: Efficient in-situ Online Learning on Edge Devices. (arXiv:2401.16694v1 [cs.LG])

    [http://arxiv.org/abs/2401.16694](http://arxiv.org/abs/2401.16694)

    本文提出了EdgeOL，一种边缘在线学习框架，通过内部和外部调优来优化推理准确性、微调执行时间和能量效率，在边缘设备上实现了显著的性能提升。

    

    新兴应用，如机器人辅助养老和物体识别，通常采用深度学习神经网络模型，并且自然需要：i) 处理实时推理请求和ii) 适应可能的部署场景变化。在线模型微调被广泛采用以满足这些需求。然而，微调会导致显著的能量消耗，使其难以部署在边缘设备上。在本文中，我们提出了EdgeOL，一种边缘在线学习框架，通过内部和外部调优来优化推理准确性、微调执行时间和能量效率。实验结果显示，EdgeOL平均减少了82%的微调执行时间，74%的能量消耗，并提高了平均推理准确率1.70%，相对于即时在线学习策略。

    Emerging applications, such as robot-assisted eldercare and object recognition, generally employ deep learning neural networks (DNNs) models and naturally require: i) handling streaming-in inference requests and ii) adapting to possible deployment scenario changes. Online model fine-tuning is widely adopted to satisfy these needs. However, fine-tuning involves significant energy consumption, making it challenging to deploy on edge devices. In this paper, we propose EdgeOL, an edge online learning framework that optimizes inference accuracy, fine-tuning execution time, and energy efficiency through both inter-tuning and intra-tuning optimizations. Experimental results show that, on average, EdgeOL reduces overall fine-tuning execution time by 82%, energy consumption by 74%, and improves average inference accuracy by 1.70% over the immediate online learning strategy.
    
[^14]: SHAP评分在可解释机器学习中的分布不确定性

    The Distributional Uncertainty of the SHAP score in Explainable Machine Learning. (arXiv:2401.12731v1 [cs.AI])

    [http://arxiv.org/abs/2401.12731](http://arxiv.org/abs/2401.12731)

    本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。

    

    归属分数反映了输入实体中的特征值对机器学习模型输出的重要性。其中最受欢迎的评分之一是SHAP评分，它是合作博弈理论中Shapley值的具体实例。该评分的定义依赖于实体群体的概率分布。由于通常不知道精确的分布，因此需要主观地进行分配或从数据中进行估计，这可能会导致误导性的特征评分。在本文中，我们提出了一个基于不知道实体群体分布的SHAP评分推理的原则性框架。在我们的框架中，我们考虑一个包含潜在分布的不确定性区域，而特征的SHAP评分成为在该区域上定义的一个函数。我们研究了找到该函数的最大值和最小值的基本问题，这使我们能够确定所有特征的SHAP评分的紧束范围。

    Attribution scores reflect how important the feature values in an input entity are for the output of a machine learning model. One of the most popular attribution scores is the SHAP score, which is an instantiation of the general Shapley value used in coalition game theory. The definition of this score relies on a probability distribution on the entity population. Since the exact distribution is generally unknown, it needs to be assigned subjectively or be estimated from data, which may lead to misleading feature scores. In this paper, we propose a principled framework for reasoning on SHAP scores under unknown entity population distributions. In our framework, we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region. We study the basic problems of finding maxima and minima of this function, which allows us to determine tight ranges for the SHAP scores of all features. In particular, we pinp
    
[^15]: 连续时空模型的基于梯度和无导数优化方法的算子学习

    Operator Learning for Continuous Spatial-Temporal Model with Gradient-Based and Derivative-Free Optimization Methods. (arXiv:2311.11798v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.11798](http://arxiv.org/abs/2311.11798)

    本论文提出了一种基于梯度和无导数优化方法的连续时空模型的算子学习框架，具有空间和时间上的分辨率不变性，并能够在短期时间序列和长期统计数据上高效训练。

    

    在许多工程应用中，常常使用偏微分方程对复杂动态系统进行时空建模。在这项工作中，我们借鉴了算子学习的最新进展，并提出了一种连续的数据驱动建模框架。所提出模型的一个关键特点是对于空间和时间离散化的分辨率不变性，而不需要大量的不同时间分辨率下的训练数据。为了改善校准模型的长期性能，我们进一步提出了一种混合优化方案，利用了基于梯度和无导数的优化方法，能够在短期时间序列和长期统计数据上高效训练。我们通过三个数值实例，包括粘性Burgers方程、Navier-Stokes方程和Kuramoto-Sivashinsky方程，来研究空间连续学习框架的性能。

    Partial differential equations are often used in the spatial-temporal modeling of complex dynamical systems in many engineering applications. In this work, we build on the recent progress of operator learning and present a data-driven modeling framework that is continuous in both space and time. A key feature of the proposed model is the resolution-invariance with respect to both spatial and temporal discretizations, without demanding abundant training data in different temporal resolutions. To improve the long-term performance of the calibrated model, we further propose a hybrid optimization scheme that leverages both gradient-based and derivative-free optimization methods and efficiently trains on both short-term time series and long-term statistics. We investigate the performance of the spatial-temporal continuous learning framework with three numerical examples, including the viscous Burgers' equation, the Navier-Stokes equations, and the Kuramoto-Sivashinsky equation. The results 
    
[^16]: 穿越文化鸿沟：探索和解锁文本到图像模型的文化视角

    Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of Text-To-Image Models. (arXiv:2310.01929v1 [cs.CL])

    [http://arxiv.org/abs/2310.01929](http://arxiv.org/abs/2310.01929)

    本研究旨在探索和解锁文本到图像模型的文化视角，通过对TTI模型中嵌入的文化感知进行评估，揭示了这些模型的文化意识、文化区别和文化适应性。

    

    文本到图像（TTI）模型，例如DALL-E和StableDiffusion，在通过文本提示生成图像的零射模式方面具有卓越的能力，近来备受关注。作为文化的媒介，语言在这些模型的多语言能力中起着关键作用，从而塑造了它们的文化机制。在本研究中，我们通过描述文化维度，文化领域和文化概念的三个层次来探索TTI模型中嵌入的文化感知。我们提出了一套全面的评估技术，包括使用CLIP空间进行内在评估，使用视觉问答（VQA）模型进行外在评估以及人类评估，以识别TTI文化感知。为了促进我们的研究，我们引入了CulText2I数据集，该数据集来自四个不同的TTI模型，涵盖了十种语言。我们的实验揭示了这些模型的文化意识、文化区别和

    Text-To-Image (TTI) models, exemplified by DALL-E and StableDiffusion, have recently gained prominence for their remarkable zero-shot capabilities in generating images guided by textual prompts. Language, as a conduit of culture, plays a pivotal role in these models' multilingual capabilities, which in turn shape their cultural agency. In this study, we explore the cultural perception embedded in TTI models by characterizing culture across three hierarchical tiers: cultural dimensions, cultural domains, and cultural concepts. We propose a comprehensive suite of evaluation techniques, including intrinsic evaluations using the CLIP space, extrinsic evaluations with a Visual-Question-Answer (VQA) model, and human assessments, to discern TTI cultural perceptions. To facilitate our research, we introduce the CulText2I dataset, derived from four diverse TTI models and spanning ten languages. Our experiments reveal insights into these models' cultural awareness, cultural distinctions, and the
    
[^17]: 潜空间的对称性发现

    Latent Space Symmetry Discovery. (arXiv:2310.00105v1 [cs.LG])

    [http://arxiv.org/abs/2310.00105](http://arxiv.org/abs/2310.00105)

    提出了一种新的生成模型——潜空间LieGAN（LaLiGAN），可以从数据中发现非线性对称性，并产生结构良好的潜空间，对其他下游任务非常有用。

    

    等变神经网络需要明确知道对称群。自动对称性发现方法旨在放宽这个约束，并从数据中学习不变性和等变性。然而，现有的对称性发现方法在搜索空间中仅限于线性对称性，无法处理实际世界中的对称性复杂性，尤其是高维数据。我们提出了一种新颖的生成模型，潜空间LieGAN（LaLiGAN），可以从数据中发现非线性对称性。它学习了一种从数据到潜空间的映射，在其中对称性变得线性，并同时发现潜空间中的对称性。理论上，我们证明了在一定条件下我们的方法可以表示任何非线性对称性。实验上，我们的方法可以捕捉高维观测中的内在对称性，从而产生一个结构良好的潜空间，对其他下游任务非常有用。我们演示了LaLiGAN在改进方程发现方面的应用案例。

    Equivariant neural networks require explicit knowledge of the symmetry group. Automatic symmetry discovery methods aim to relax this constraint and learn invariance and equivariance from data. However, existing symmetry discovery methods are limited to linear symmetries in their search space and cannot handle the complexity of symmetries in real-world, often high-dimensional data. We propose a novel generative model, Latent LieGAN (LaLiGAN), which can discover nonlinear symmetries from data. It learns a mapping from data to a latent space where the symmetries become linear and simultaneously discovers symmetries in the latent space. Theoretically, we show that our method can express any nonlinear symmetry under certain conditions. Experimentally, our method can capture the intrinsic symmetry in high-dimensional observations, which results in a well-structured latent space that is useful for other downstream tasks. We demonstrate the use cases for LaLiGAN in improving equation discovery
    
[^18]: 用于跟踪高维非线性动力系统的集成评分滤波器

    An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems. (arXiv:2309.00983v1 [stat.ML])

    [http://arxiv.org/abs/2309.00983](http://arxiv.org/abs/2309.00983)

    我们提出了一种集成评分滤波器（EnSF），在处理高维非线性滤波问题时具有卓越的准确性。EnSF利用评分模型在伪时域中描述滤波密度的演化，并通过评分函数存储信息，相比于使用蒙特卡罗样本的粒子滤波器和集成卡尔曼滤波器具有更好的效果。

    

    我们提出了一种集成评分滤波器（EnSF）来解决高维非线性滤波问题，并具有卓越的准确性。现有的滤波方法（如粒子滤波器或集成卡尔曼滤波器）在处理高维和高度非线性问题时存在低准确性的主要缺陷。EnSF通过利用基于评分的扩散模型，在伪时域中定义，来描述滤波密度的演化，从而攻克了这一挑战。EnSF在评分函数中存储了递归更新的滤波密度函数的信息，而不是在一组有限的蒙特卡罗样本中存储信息（用于粒子滤波器和集成卡尔曼滤波器）。与训练神经网络来近似评分函数的现有扩散模型不同，我们开发了一种无需训练的评分估计方法，使用基于小批量的蒙特卡罗估计器来直接近似任何伪空间-时间位置处的评分函数，从而提供了足够准确的估计。

    We propose an ensemble score filter (EnSF) for solving high-dimensional nonlinear filtering problems with superior accuracy. A major drawback of existing filtering methods, e.g., particle filters or ensemble Kalman filters, is the low accuracy in handling high-dimensional and highly nonlinear problems. EnSF attacks this challenge by exploiting the score-based diffusion model, defined in a pseudo-temporal domain, to characterizing the evolution of the filtering density. EnSF stores the information of the recursively updated filtering density function in the score function, in stead of storing the information in a set of finite Monte Carlo samples (used in particle filters and ensemble Kalman filters). Unlike existing diffusion models that train neural networks to approximate the score function, we develop a training-free score estimation that uses mini-batch-based Monte Carlo estimator to directly approximate the score function at any pseudo-spatial-temporal location, which provides suf
    
[^19]: 可解释的基于图神经网络的表格数据处理方法

    Interpretable Graph Neural Networks for Tabular Data. (arXiv:2308.08945v1 [cs.LG])

    [http://arxiv.org/abs/2308.08945](http://arxiv.org/abs/2308.08945)

    本论文提出了一种称为IGNNet的方法，可以在处理表格数据时使用图神经网络，该方法能够产生可解释的模型，从原始输入特征精确计算预测结果，并且在性能上与最先进的机器学习算法性能相当。

    

    在现实世界的应用中，表格格式的数据经常出现。图神经网络（GNNs）近期被扩展以有效处理此类数据，通过表示学习捕捉特征之间的相互作用。然而，这些方法本质上产生了黑盒模型，以深度神经网络的形式存在，使得用户无法理解模型预测的逻辑。我们提出了一种称为IGNNet（基于图神经网络的可解释表格数据处理方法）的方法，它限制学习算法以产生可解释的模型，该模型展示了如何从原始输入特征准确计算预测结果。通过大规模实证研究，我们展示了IGNNet与面向表格数据的最先进机器学习算法（包括XGBoost，Random Forests和TabNet）性能相当。同时，结果显示从IGNNet获得的解释与真实情况一致。

    Data in tabular format is frequently occurring in real-world applications. Graph Neural Networks (GNNs) have recently been extended to effectively handle such data, allowing feature interactions to be captured through representation learning. However, these approaches essentially produce black-box models, in the form of deep neural networks, precluding users from following the logic behind the model predictions. We propose an approach, called IGNNet (Interpretable Graph Neural Network for tabular data), which constrains the learning algorithm to produce an interpretable model, where the model shows how the predictions are exactly computed from the original input features. A large-scale empirical investigation is presented, showing that IGNNet is performing on par with state-of-the-art machine-learning algorithms that target tabular data, including XGBoost, Random Forests, and TabNet. At the same time, the results show that the explanations obtained from IGNNet are aligned with the true
    
[^20]: 神经网络可以检测无模型静态套利策略

    Neural networks can detect model-free static arbitrage strategies. (arXiv:2306.16422v1 [q-fin.CP])

    [http://arxiv.org/abs/2306.16422](http://arxiv.org/abs/2306.16422)

    本文证明了神经网络可以检测金融市场中的无模型静态套利机会，并可应用于交易证券数量较多的金融市场。我们的方法具有易处理性、有效性和稳健性，并使用真实金融数据进行了示例验证。

    

    本文利用理论和数值方法证明了神经网络可以在市场存在套利机会时检测出无模型静态套利机会。由于使用了神经网络，我们的方法可以应用于交易证券数量较多的金融市场，并确保相应交易策略的几乎即时执行。为了证明其易处理性、有效性和稳健性，我们提供了使用真实金融数据的示例。从技术角度来看，我们证明了单个神经网络可以近似解决一类凸半无限规划问题，这是推导出我们的理论结果的关键。

    In this paper we demonstrate both theoretically as well as numerically that neural networks can detect model-free static arbitrage opportunities whenever the market admits some. Due to the use of neural networks, our method can be applied to financial markets with a high number of traded securities and ensures almost immediate execution of the corresponding trading strategies. To demonstrate its tractability, effectiveness, and robustness we provide examples using real financial data. From a technical point of view, we prove that a single neural network can approximately solve a class of convex semi-infinite programs, which is the key result in order to derive our theoretical results that neural networks can detect model-free static arbitrage strategies whenever the financial market admits such opportunities.
    
[^21]: 通过重新参数化学习实现在线反馈的实现式预测

    Performative Prediction with Bandit Feedback: Learning through Reparameterization. (arXiv:2305.01094v1 [cs.LG])

    [http://arxiv.org/abs/2305.01094](http://arxiv.org/abs/2305.01094)

    本文提出一种新的在线反馈的实现式预测框架，解决了在模型部署自身改变数据分布的情况下优化准确性的问题。

    

    本文提出了在数据分布由模型部署自身改变的情形下预测的一个框架——实现式预测。现有研究的重点在于优化准确性，但是其假设往往难以在实践中得到满足。本文针对这类问题，提出了一种两层零阶优化算法，通过重新参数化实现式预测目标，从而将非凸的目标转化为凸的目标。

    Performative prediction, as introduced by Perdomo et al. (2020), is a framework for studying social prediction in which the data distribution itself changes in response to the deployment of a model. Existing work on optimizing accuracy in this setting hinges on two assumptions that are easily violated in practice: that the performative risk is convex over the deployed model, and that the mapping from the model to the data distribution is known to the model designer in advance. In this paper, we initiate the study of tractable performative prediction problems that do not require these assumptions. To tackle this more challenging setting, we develop a two-level zeroth-order optimization algorithm, where one level aims to compute the distribution map, and the other level reparameterizes the performative prediction objective as a function of the induced data distribution. Under mild conditions, this reparameterization allows us to transform the non-convex objective into a convex one and ac
    
[^22]: 基于消息传递的图神经网络在大规模随机图上的通用聚合收敛性研究

    Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])

    [http://arxiv.org/abs/2304.11140](http://arxiv.org/abs/2304.11140)

    本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。

    

    本文研究了消息传递图神经网络在随机图模型上的收敛性，当节点数量趋近于无限时，该网络模型能收敛于其连续模型。迄今为止，该收敛性结果只适用于聚合函数采用度规范化平均值形式的网络结构。我们将此结果扩展到包含所有传统消息传递图神经网络的大类聚合函数上，例如基于注意力和最大卷积的网络。在一定假设下，我们给出了高概率的非渐进上限来量化这种收敛性。我们的主要结果基于McDiarmid不等式。有趣的是，我们特别处理了聚合函数采用逐个坐标最大值的情况，因为它需要非常不同的证明技巧，并产生了定性不同的收敛率。

    We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
    

