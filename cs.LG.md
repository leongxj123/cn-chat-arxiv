# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast](https://rss.arxiv.org/abs/2402.01295) | ExtremeCast提出了一种新的损失函数Exloss，实现了针对极值的准确预测，同时引入了无需训练的极值增强策略ExEnsemble，提高了预报的稳健性 |
| [^2] | [A PPO-based DRL Auto-Tuning Nonlinear PID Drone Controller for Robust Autonomous Flights](https://arxiv.org/abs/2404.00204) | 该项目将非线性深度强化学习（DRL）代理引入无人机控制中，取代传统线性PID控制器，实现了无缝过渡、提高响应速度和稳定性，同时结合PPO策略训练DRL代理，并利用高精度跟踪系统提高自主飞行精度。 |
| [^3] | [Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble](https://arxiv.org/abs/2403.16260) | 通过引入新颖的定性和定量模型集成评估方法，作者揭示了现有集成方法的关键缺陷，提出了提高传统模型集成维度的方法，以克服特征表示中的多样性限制。 |
| [^4] | [Space Group Informed Transformer for Crystalline Materials Generation](https://arxiv.org/abs/2403.15734) | CrystalFormer是一种基于变压器的自回归模型，专门设计用于受空间群控制的晶体材料生成，它通过预测单位胞中对称不等价原子的种类和位置来生成晶体，并在有效性、新颖性和稳定性等方面达到了与最先进性能相匹配的水平。 |
| [^5] | [Improving Sampling Methods for Fine-tuning SentenceBERT in Text Streams](https://arxiv.org/abs/2403.15455) | 本研究旨在解决概念漂移问题，通过探索七种文本采样方法的有效性，精细调整语言模型，从而减轻性能下降。 |
| [^6] | [Analyzing the Impact of Partial Sharing on the Resilience of Online Federated Learning Against Model Poisoning Attacks](https://arxiv.org/abs/2403.13108) | PSO-Fed算法的部分共享机制不仅可以降低通信负载，还能增强算法对模型投毒攻击的抵抗力，并且在面对拜占庭客户端的情况下依然能保持收敛。 |
| [^7] | [Automated Contrastive Learning Strategy Search for Time Series](https://arxiv.org/abs/2403.12641) | 本文介绍了微软开展的自动机器学习实践，用于自动对比学习各种时间序列数据集和任务的表示。 |
| [^8] | [CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation](https://arxiv.org/abs/2403.11960) | CASPER提出了一种因果关系感知的方法来处理时空时间序列数据插补问题，避免过度利用非因果关系，提高数据分析的准确性。 |
| [^9] | [Hyperparameters in Continual Learning: a Reality Check](https://arxiv.org/abs/2403.09066) | 超参数对于连续学习的重要性被强调，提出了一个涉及超参数调整和评估阶段的评估协议。 |
| [^10] | [Rethinking of Encoder-based Warm-start Methods in Hyperparameter Optimization](https://arxiv.org/abs/2403.04720) | 提出了一种新的基于编码器的表格数据集表示方法，与现有方法不同，能够自动提取重要的元特征，同时在两个常见的元任务上进行了评估 |
| [^11] | [Indirectly Parameterized Concrete Autoencoders](https://arxiv.org/abs/2403.00563) | 本文提出了间接参数化CAEs（IP-CAEs）来解决具体自编码器（CAEs）在稳定联合优化方面的问题，IP-CAEs在多个数据集上表现出显著且一致的改进。 |
| [^12] | [CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI](https://arxiv.org/abs/2402.19105) | CollaFuse是一个受拆分学习启发的框架，通过共享服务器训练和推理，在协作使用去噪扩散概率模型时减轻客户端的计算负担，从而提高隐私保护能力。 |
| [^13] | [Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach](https://arxiv.org/abs/2402.17987) | 提出了一种完全贝叶斯雷达自动目标识别的框架，采用最优贝叶斯融合来有效地汇总多个雷达的分类概率向量，以改进无人机雷达截面识别效果。 |
| [^14] | [What Do Language Models Hear? Probing for Auditory Representations in Language Models](https://arxiv.org/abs/2402.16998) | 通过训练一个线性探针，将语言模型中的文本表示和预训练音频模型中的声音表示联系在一起，研究发现尽管仅在原始文本上进行训练，语言模型对于一些对象的声音知识有着基于实质的编码。 |
| [^15] | [Graph Out-of-Distribution Generalization via Causal Intervention](https://arxiv.org/abs/2402.11494) | GNN在离群分布泛化中的失败关键在于来自环境的潜在混杂偏差，因此引入了一个简单而原则性的方法来训练稳健GNN。 |
| [^16] | [Disentanglement in Implicit Causal Models via Switch Variable](https://arxiv.org/abs/2402.11124) | 该论文通过软干预处理隐式潜在因果表征学习，在 Variational Autoencoder (VAE) 框架中引入了因果机制开关变量。 |
| [^17] | [Harm Amplification in Text-to-Image Models](https://arxiv.org/abs/2402.01787) | 我们的研究提出了危害放大现象并发展了量化危害放大的方法，考虑模型输出的危害与用户输入的情境。我们还实证地研究了不同的方法在真实场景中的应用，并量化了由危害放大引起的性别之间的影响差异。 |
| [^18] | [Data-Effective Learning: A Comprehensive Medical Benchmark](https://arxiv.org/abs/2401.17542) | 这项研究引入了一个综合基准，用于评估医学领域的数据有效学习。该基准包括大量的医疗数据样本、基准方法和新的评估指标，能够准确评估数据有效学习的性能。 |
| [^19] | [Spectral Clustering for Discrete Distributions.](http://arxiv.org/abs/2401.13913) | 本文提出了一种基于谱聚类和分布相似度度量的框架来解决离散分布聚类问题。通过使用线性最优传输构建相似度矩阵，我们在聚类准确性和计算效率方面取得了显著的改进。 |
| [^20] | [Fair Sampling in Diffusion Models through Switching Mechanism.](http://arxiv.org/abs/2401.03140) | 本论文提出了一种称为“属性切换”的公平抽样机制，用于解决扩散模型中公平性的问题。通过在生成的数据中混淆敏感属性，该方法能够实现生成公平数据和保持数据效用的目标。 |
| [^21] | [Personalized Predictions of Glioblastoma Infiltration: Mathematical Models, Physics-Informed Neural Networks and Multimodal Scans.](http://arxiv.org/abs/2311.16536) | 本研究利用物理信息神经网络（PINNs）从单个三维结构MRI快照中估计胶质母细胞瘤（GBM）生长模型的患者特异性参数，并通过整合理论和数据进行个性化预测，为胶质母细胞瘤的治疗设计提供了关键创新。 |
| [^22] | [Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent.](http://arxiv.org/abs/2311.01205) | 我们设计了Injectivity Bit Flip Attack来针对图神经网络，成功地降低了其对图结构的识别能力和表达能力，从而增加了其对位反转攻击的易受攻击性。 |
| [^23] | [Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning.](http://arxiv.org/abs/2311.00201) | 本研究提出了一种多任务强化学习的联邦自然策略梯度方法，在分布式环境中，通过优化全局策略以最大化所有智能体的总奖励，实现协作决策。这些方法不受信息共享不完备的影响，且具有非渐近全局收敛保证。 |
| [^24] | [Isometric Motion Manifold Primitives.](http://arxiv.org/abs/2310.17072) | Isometric Motion Manifold Primitives (IMMP) is proposed to address the degradation of Motion Manifold Primitive (MMP) performance due to geometric distortion in the latent space. IMMP preserves the geometry of the manifold in the latent coordinate space using a Riemannian metric, and experimental results show that IMMP significantly outperforms existing MMP methods. |
| [^25] | [Fast and Reliable Generation of EHR Time Series via Diffusion Models.](http://arxiv.org/abs/2310.15290) | 本研究通过使用扩散模型提出了一种快速可靠生成EHR时间序列数据的新方法，该方法在数据效用方面明显优于现有方法，并且对训练工作的需求更少。同时，该方法还提供了多样化和真实的合成EHR数据，增强了下游医疗数据分析。 |
| [^26] | [Model-agnostic variable importance for predictive uncertainty: an entropy-based approach.](http://arxiv.org/abs/2310.12842) | 本文提出了一种基于熵的方法，通过扩展现有的解释性方法，可以理解不确定性感知模型中的预测来源和置信度，并利用改编后的特征重要性、部分依赖图和个体条件期望图等方法来测量特征对预测分布的熵和基于真实标签的对数似然的影响。 |
| [^27] | [Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation.](http://arxiv.org/abs/2310.02304) | 本文提出了一种自学优化器（STOP），通过递归自我改进的代码生成，使用融合了语言模型的脚手架程序来改进自身，从而生成性能更好的程序。 |
| [^28] | [S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees.](http://arxiv.org/abs/2309.12041) | S-GBDT是一种节俭的差分隐私梯度提升决策树学习器，利用了四种技术来改善效用和隐私权之间的平衡，包括对隐私泄露的更紧密计算和整合个体Rényi滤波器以学习未充分利用的数据点。 |
| [^29] | [Identifying contributors to supply chain outcomes in a multi-echelon setting: a decentralised approach.](http://arxiv.org/abs/2307.12157) | 研究介绍了一种去中心化方法，利用可解释的人工智能对多层级供应链中感兴趣指标的估计贡献进行计算，无需数据共享。经验证实，该方法在检测质量变化的原因方面有效。 |
| [^30] | [Simplifying and Empowering Transformers for Large-Graph Representations.](http://arxiv.org/abs/2306.10759) | 本文通过实验证明，在大型图上使用一层注意力即可获得令人惊讶的竞争性能，挑战了在语言和视觉任务中复杂模型的应用。这促使我们重新思考在大型图上设计Transformer的理念，以提高可扩展性。 |
| [^31] | [Self-Supervised Multimodal Learning: A Survey.](http://arxiv.org/abs/2304.01008) | 自监督多模态学习是一项旨在解决多模态数据中的自监督学习挑战的研究方向。它通过学习来自原始多模态数据中的表示，并解决了没有标签的多模态数据学习、不同模态的融合和不对齐数据学习等问题。 |
| [^32] | [Large Language Models for Code: Security Hardening and Adversarial Testing.](http://arxiv.org/abs/2302.05319) | 本研究针对大型语言模型在生成代码时缺乏安全意识，从安全加固和对抗测试的角度入手，提出了一项新的安全任务——受控代码生成，通过一种新型基于学习的方法SVEN，实现生成既安全又功能正确的代码，并对当前的LM进行对抗测试，强调了在LM的培训和评估中考虑安全因素的必要性。 |
| [^33] | [Active Learning with Weak Supervision for Gaussian Processes.](http://arxiv.org/abs/2204.08335) | 本文提出了一种基于弱监督的主动学习算法，不仅选择要注释的观测结果，还选择要获得的注释精度，并在高斯过程中进行了实验验证。 |

# 详细

[^1]: ExtremeCast: 提升全球天气预报的极值预测能力

    ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast

    [https://rss.arxiv.org/abs/2402.01295](https://rss.arxiv.org/abs/2402.01295)

    ExtremeCast提出了一种新的损失函数Exloss，实现了针对极值的准确预测，同时引入了无需训练的极值增强策略ExEnsemble，提高了预报的稳健性

    

    基于机器学习的数据驱动天气预报在全球中期预报中已经得到了快速发展，并且相较于传统的基于物理的动力学模型表现出更好的性能。然而，大多数这些机器学习模型在准确预测极端天气方面存在困难，而极端值预测与此密切相关。通过数学分析，我们证明使用对称损失，如均方误差（MSE），会导致预测有偏差并低估极值。为了解决这个问题，我们引入了Exloss，一种新的损失函数，通过非对称优化突出极值，以获得准确的极端天气预报。此外，我们还引入了一种无需训练的极值增强策略ExEnsemble，它增加了像素值的方差，并提高了预报的稳健性。结合先进的全球天气预报模型，广泛的实验证明了我们的方法

    Data-driven weather forecast based on machine learning (ML) has experienced rapid development and demonstrated superior performance in the global medium-range forecast compared to traditional physics-based dynamical models. However, most of these ML models struggle with accurately predicting extreme weather, which is closely related to the extreme value prediction. Through mathematical analysis, we prove that the use of symmetric losses, such as the Mean Squared Error (MSE), leads to biased predictions and underestimation of extreme values. To address this issue, we introduce Exloss, a novel loss function that performs asymmetric optimization and highlights extreme values to obtain accurate extreme weather forecast. Furthermore, we introduce a training-free extreme value enhancement strategy named ExEnsemble, which increases the variance of pixel values and improves the forecast robustness. Combined with an advanced global weather forecast model, extensive experiments show that our sol
    
[^2]: 基于PPO的DRL自调PID非线性无人机控制器用于稳健自主飞行

    A PPO-based DRL Auto-Tuning Nonlinear PID Drone Controller for Robust Autonomous Flights

    [https://arxiv.org/abs/2404.00204](https://arxiv.org/abs/2404.00204)

    该项目将非线性深度强化学习（DRL）代理引入无人机控制中，取代传统线性PID控制器，实现了无缝过渡、提高响应速度和稳定性，同时结合PPO策略训练DRL代理，并利用高精度跟踪系统提高自主飞行精度。

    

    该项目旨在通过将非线性深度强化学习（DRL）代理作为传统线性比例积分微分（PID）控制器的替代品，从而彻底改变无人机飞行控制。主要目标是在手动和自主模式之间实现无缝过渡，提高响应速度和稳定性。我们在Gazebo模拟器中利用近端策略优化（PPO）强化学习策略来训练DRL代理。添加20000美元的室内Vicon跟踪系统提供<1mm的定位精度，显着提高了自主飞行精度。为了在最短的无碰撞轨迹中导航无人机，我们还建立了一个三维A*路径规划器并成功地将其实施到实际飞行中。

    arXiv:2404.00204v1 Announce Type: cross  Abstract: This project aims to revolutionize drone flight control by implementing a nonlinear Deep Reinforcement Learning (DRL) agent as a replacement for traditional linear Proportional Integral Derivative (PID) controllers. The primary objective is to seamlessly transition drones between manual and autonomous modes, enhancing responsiveness and stability. We utilize the Proximal Policy Optimization (PPO) reinforcement learning strategy within the Gazebo simulator to train the DRL agent. Adding a $20,000 indoor Vicon tracking system offers <1mm positioning accuracy, which significantly improves autonomous flight precision. To navigate the drone in the shortest collision-free trajectory, we also build a 3 dimensional A* path planner and implement it into the real flight successfully.
    
[^3]: 通过深度多理解集成实现越界检测

    Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble

    [https://arxiv.org/abs/2403.16260](https://arxiv.org/abs/2403.16260)

    通过引入新颖的定性和定量模型集成评估方法，作者揭示了现有集成方法的关键缺陷，提出了提高传统模型集成维度的方法，以克服特征表示中的多样性限制。

    

    最近的研究强调了越界（OOD）特征表示领域规模对模型在OOD检测中效果的重要作用。因此，采用模型集成作为增强这一特征表示领域的突出策略已经成为一种突出的策略，利用预期的模型多样性。然而，我们引入了新颖的定性和定量模型集成评估方法，特别是损失盆/障碍可视化和自耦合指数，揭示了现有集成方法的一个关键缺陷。我们发现这些方法包含可进行仿射变换的权重，表现出有限的可变性，从而未能实现特征表示中所需的多样性。

    arXiv:2403.16260v1 Announce Type: cross  Abstract: Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity.   However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation.   To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into di
    
[^4]: 基于空间群信息的晶体材料生成变压器

    Space Group Informed Transformer for Crystalline Materials Generation

    [https://arxiv.org/abs/2403.15734](https://arxiv.org/abs/2403.15734)

    CrystalFormer是一种基于变压器的自回归模型，专门设计用于受空间群控制的晶体材料生成，它通过预测单位胞中对称不等价原子的种类和位置来生成晶体，并在有效性、新颖性和稳定性等方面达到了与最先进性能相匹配的水平。

    

    我们引入了CrystalFormer，这是一种基于变压器的自回归模型，专门设计用于受空间群控制的晶体材料生成。空间群对称性显著简化了晶体空间，这对于数据和计算有效的晶体材料生成建模至关重要。通过利用Wyckoff位置的显著离散和顺序特性，CrystalFormer学会了通过直接预测单位胞中对称不等价原子的种类和位置来生成晶体。我们的结果表明，CrystalFormer在生成的晶体材料的有效性、新颖性和稳定性方面与标准基准上的最新性能相匹配。我们的分析还表明，CrystalFormer从数据中吸收了合理的固体化学信息用于生成建模。CrystalFormer统一了基于对称性的结构搜索和生成性预训练。

    arXiv:2403.15734v1 Announce Type: cross  Abstract: We introduce CrystalFormer, a transformer-based autoregressive model specifically designed for space group-controlled generation of crystalline materials. The space group symmetry significantly simplifies the crystal space, which is crucial for data and compute efficient generative modeling of crystalline materials. Leveraging the prominent discrete and sequential nature of the Wyckoff positions, CrystalFormer learns to generate crystals by directly predicting the species and locations of symmetry-inequivalent atoms in the unit cell. Our results demonstrate that CrystalFormer matches state-of-the-art performance on standard benchmarks for both validity, novelty, and stability of the generated crystalline materials. Our analysis also shows that CrystalFormer ingests sensible solid-state chemistry information from data for generative modeling. The CrystalFormer unifies symmetry-based structure search and generative pre-training in the re
    
[^5]: 改进文本流中用于微调SentenceBERT的采样方法

    Improving Sampling Methods for Fine-tuning SentenceBERT in Text Streams

    [https://arxiv.org/abs/2403.15455](https://arxiv.org/abs/2403.15455)

    本研究旨在解决概念漂移问题，通过探索七种文本采样方法的有效性，精细调整语言模型，从而减轻性能下降。

    

    互联网上文本数据的激增为机构和公司提供了一个独特的机会，可以监测公众对其服务和产品的意见。考虑到这些数据的快速生成，处理依次到达、潜在无限的文本流的文本流挖掘设置通常比传统的批量学习更合适。虽然预训练语言模型通常因其在流式内容中高质量的文本向量化能力而被广泛采用，但它们在适应概念漂移（数据分布随时间发生变化，从而对模型性能产生负面影响的现象）方面面临挑战。本研究解决了概念漂移问题，探讨了七种文本采样方法对精心微调语言模型的效果，从而减轻性能下降。我们准确评估了这些方法对使用四种不同方式进行微调的SBERT模型的影响。

    arXiv:2403.15455v1 Announce Type: new  Abstract: The proliferation of textual data on the Internet presents a unique opportunity for institutions and companies to monitor public opinion about their services and products. Given the rapid generation of such data, the text stream mining setting, which handles sequentially arriving, potentially infinite text streams, is often more suitable than traditional batch learning. While pre-trained language models are commonly employed for their high-quality text vectorization capabilities in streaming contexts, they face challenges adapting to concept drift - the phenomenon where the data distribution changes over time, adversely affecting model performance. Addressing the issue of concept drift, this study explores the efficacy of seven text sampling methods designed to selectively fine-tune language models, thereby mitigating performance degradation. We precisely assess the impact of these methods on fine-tuning the SBERT model using four differ
    
[^6]: 分析部分共享对在线联邦学习抵抗模型投毒攻击的影响

    Analyzing the Impact of Partial Sharing on the Resilience of Online Federated Learning Against Model Poisoning Attacks

    [https://arxiv.org/abs/2403.13108](https://arxiv.org/abs/2403.13108)

    PSO-Fed算法的部分共享机制不仅可以降低通信负载，还能增强算法对模型投毒攻击的抵抗力，并且在面对拜占庭客户端的情况下依然能保持收敛。

    

    我们审查了部分共享的在线联邦学习（PSO-Fed）算法对抵抗模型投毒攻击的韧性。 PSO-Fed通过使客户端在每个更新轮次仅与服务器交换部分模型估计来减少通信负载。模型估计的部分共享还增强了算法对模型投毒攻击的强度。为了更好地理解这一现象，我们分析了PSO-Fed算法在存在拜占庭客户端的情况下的性能，这些客户端可能会在与服务器共享之前通过添加噪声轻微篡改其本地模型。通过我们的分析，我们证明了PSO-Fed在均值和均方意义上都能保持收敛，即使在模型投毒攻击的压力下也是如此。我们进一步推导了PSO-Fed的理论均方误差（MSE），将其与步长、攻击概率、数字等各种参数联系起来。

    arXiv:2403.13108v1 Announce Type: new  Abstract: We scrutinize the resilience of the partial-sharing online federated learning (PSO-Fed) algorithm against model-poisoning attacks. PSO-Fed reduces the communication load by enabling clients to exchange only a fraction of their model estimates with the server at each update round. Partial sharing of model estimates also enhances the robustness of the algorithm against model-poisoning attacks. To gain better insights into this phenomenon, we analyze the performance of the PSO-Fed algorithm in the presence of Byzantine clients, malicious actors who may subtly tamper with their local models by adding noise before sharing them with the server. Through our analysis, we demonstrate that PSO-Fed maintains convergence in both mean and mean-square senses, even under the strain of model-poisoning attacks. We further derive the theoretical mean square error (MSE) of PSO-Fed, linking it to various parameters such as stepsize, attack probability, numb
    
[^7]: 用于时间序列的自动对比学习策略搜索

    Automated Contrastive Learning Strategy Search for Time Series

    [https://arxiv.org/abs/2403.12641](https://arxiv.org/abs/2403.12641)

    本文介绍了微软开展的自动机器学习实践，用于自动对比学习各种时间序列数据集和任务的表示。

    

    近年来，对比学习（CL）已成为时间序列的主要表示学习范式。现有文献中大多数方法侧重于通过人类启发式方法手动构建特定的对比学习策略（CLS）以应用于特定数据集和任务。然而，手动开发CLS通常需要对数据集和任务有过多的先验知识，例如在医疗保健领域对医学时间序列的专业认知，以及大量的人力和大量实验来确定详细的学习配置。本文介绍了微软的自动机器学习（AutoML）实践，该实践自动学习对比学习各种时间序列数据集和任务的表示，即自动化对比学习（AutoCL）。

    arXiv:2403.12641v1 Announce Type: new  Abstract: In recent years, Contrastive Learning (CL) has become a predominant representation learning paradigm for time series. Most existing methods in the literature focus on manually building specific Contrastive Learning Strategies (CLS) by human heuristics for certain datasets and tasks. However, manually developing CLS usually require excessive prior knowledge about the datasets and tasks, e.g., professional cognition of the medical time series in healthcare, as well as huge human labor and massive experiments to determine the detailed learning configurations. In this paper, we present an Automated Machine Learning (AutoML) practice at Microsoft, which automatically learns to contrastively learn representations for various time series datasets and tasks, namely Automated Contrastive Learning (AutoCL). We first construct a principled universal search space of size over 3x1012, covering data augmentation, embedding transformation, contrastive 
    
[^8]: CASPER：因果关系感知时空图神经网络用于时空时间序列插补

    CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation

    [https://arxiv.org/abs/2403.11960](https://arxiv.org/abs/2403.11960)

    CASPER提出了一种因果关系感知的方法来处理时空时间序列数据插补问题，避免过度利用非因果关系，提高数据分析的准确性。

    

    arXiv:2403.11960v1 公告类型：新 提要：时空时间序列是理解人类活动及其影响的基础，通常通过放置在不同位置的监测传感器收集。收集到的数据通常包含由于各种故障而导致的缺失值，这对数据分析有重要影响。为了填补缺失值，已经提出了许多方法。在恢复特定数据点时，大多数现有方法倾向于考虑与该点相关的所有信息，无论它们是否具有因果关系。在数据收集过程中，包括一些未知混杂因素是不可避免的，例如时间序列中的背景噪声和构建的传感器网络中的非因果快捷边。这些混杂因素可能在输入和输出之间开辟反向路径，换句话说，它们建立了输入和输出之间的非因果相关性。

    arXiv:2403.11960v1 Announce Type: new  Abstract: Spatiotemporal time series is the foundation of understanding human activities and their impacts, which is usually collected via monitoring sensors placed at different locations. The collected data usually contains missing values due to various failures, which have significant impact on data analysis. To impute the missing values, a lot of methods have been introduced. When recovering a specific data point, most existing methods tend to take into consideration all the information relevant to that point regardless of whether they have a cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths between the input and output, in other words, they establish non-causal correlations between the input and output. Over-exploiting these non-causa
    
[^9]: Continual Learning中的超参数：现实检验

    Hyperparameters in Continual Learning: a Reality Check

    [https://arxiv.org/abs/2403.09066](https://arxiv.org/abs/2403.09066)

    超参数对于连续学习的重要性被强调，提出了一个涉及超参数调整和评估阶段的评估协议。

    

    不同的连续学习（CL）算法旨在在CL过程中有效地缓解稳定性和可塑性之间的权衡，为了实现这一目标，调整每种算法的适当超参数是必不可少的。本文主张现行的评估协议既不切实际，也无法有效评估连续学习算法的能力。

    arXiv:2403.09066v1 Announce Type: new  Abstract: Various algorithms for continual learning (CL) have been designed with the goal of effectively alleviating the trade-off between stability and plasticity during the CL process. To achieve this goal, tuning appropriate hyperparameters for each algorithm is essential. As an evaluation protocol, it has been common practice to train a CL algorithm using diverse hyperparameter values on a CL scenario constructed with a benchmark dataset. Subsequently, the best performance attained with the optimal hyperparameter value serves as the criterion for evaluating the CL algorithm. In this paper, we contend that this evaluation protocol is not only impractical but also incapable of effectively assessing the CL capability of a CL algorithm. Returning to the fundamental principles of model evaluation in machine learning, we propose an evaluation protocol that involves Hyperparameter Tuning and Evaluation phases. Those phases consist of different datase
    
[^10]: 在超参数优化中重新思考基于编码器的热启动方法

    Rethinking of Encoder-based Warm-start Methods in Hyperparameter Optimization

    [https://arxiv.org/abs/2403.04720](https://arxiv.org/abs/2403.04720)

    提出了一种新的基于编码器的表格数据集表示方法，与现有方法不同，能够自动提取重要的元特征，同时在两个常见的元任务上进行了评估

    

    有效地表示异质性表格数据集以用于元学习仍然是一个未解决的问题。以往的方法依赖于预定义的元特征，例如，统计量或标志点。基于编码器的模型，如Dataset2Vec，使我们能够在无人干预的情况下自动提取重要的元特征。本研究介绍了一个新颖的基于编码器的表格数据集表示，实现在liltab包中，该包可在GitHub上找到https://github.com/azoz01/liltab。我们的包基于[Iwata and Kumagai, 2020]提出的一个用于异质表格数据的已建立模型。所提出的方法采用一种不同于现有方法如Dataset2Vec 的编码特征关系的模型，生成与现有方法不同的替代表示。它们都利用了数据集相似性学习的基本假设。在这项工作中，我们在两个常见的元任务上评价了Dataset2Vec和liltab

    arXiv:2403.04720v1 Announce Type: new  Abstract: Effectively representing heterogeneous tabular datasets for meta-learning remains an open problem. Previous approaches rely on predefined meta-features, for example, statistical measures or landmarkers. Encoder-based models, such as Dataset2Vec, allow us to extract significant meta-features automatically without human intervention. This research introduces a novel encoder-based representation of tabular datasets implemented within the liltab package available on GitHub https://github.com/azoz01/liltab. Our package is based on an established model for heterogeneous tabular data proposed in [Iwata and Kumagai, 2020]. The proposed approach employs a different model for encoding feature relationships, generating alternative representations compared to existing methods like Dataset2Vec. Both of them leverage the fundamental assumption of dataset similarity learning. In this work, we evaluate Dataset2Vec and liltab on two common meta-tasks - r
    
[^11]: 间接参数化具体自编码器

    Indirectly Parameterized Concrete Autoencoders

    [https://arxiv.org/abs/2403.00563](https://arxiv.org/abs/2403.00563)

    本文提出了间接参数化CAEs（IP-CAEs）来解决具体自编码器（CAEs）在稳定联合优化方面的问题，IP-CAEs在多个数据集上表现出显著且一致的改进。

    

    特征选择在数据高维或获取完整特征集成本高昂的情况下至关重要。最近基于神经网络的嵌入式特征选择的发展在广泛应用中表现出有希望的结果。具体自编码器（CAEs）被认为是嵌入式特征选择中的最先进技术，但可能难以实现稳定的联合优化，从而影响其训练时间和泛化能力。本文发现这种不稳定性与CAE学习重复选择有关。为了解决这个问题，我们提出了一种简单有效的改进：间接参数化CAEs（IP-CAEs）。IP-CAEs学习一个嵌入和从它到Gumbel-Softmax分布参数的映射。尽管实现简单，IP-CAE在多个数据集上的重构和分类任务中均表现出显著且一致的改进，无论是在泛化还是训练时间上。

    arXiv:2403.00563v1 Announce Type: new  Abstract: Feature selection is a crucial task in settings where data is high-dimensional or acquiring the full set of features is costly. Recent developments in neural network-based embedded feature selection show promising results across a wide range of applications. Concrete Autoencoders (CAEs), considered state-of-the-art in embedded feature selection, may struggle to achieve stable joint optimization, hurting their training time and generalization. In this work, we identify that this instability is correlated with the CAE learning duplicate selections. To remedy this, we propose a simple and effective improvement: Indirectly Parameterized CAEs (IP-CAEs). IP-CAEs learn an embedding and a mapping from it to the Gumbel-Softmax distributions' parameters. Despite being simple to implement, IP-CAE exhibits significant and consistent improvements over CAE in both generalization and training time across several datasets for reconstruction and classifi
    
[^12]: CollaFuse：在协作生成人工智能中导航有限资源和隐私

    CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI

    [https://arxiv.org/abs/2402.19105](https://arxiv.org/abs/2402.19105)

    CollaFuse是一个受拆分学习启发的框架，通过共享服务器训练和推理，在协作使用去噪扩散概率模型时减轻客户端的计算负担，从而提高隐私保护能力。

    

    在生成人工智能领域，扩散式模型在数据需求和隐私方面给社会技术系统带来挑战。传统方法如联邦学习分发学习过程，但会给个别客户带来压力，尤其是在资源受限情况下（例如边缘设备）。为了解决这些挑战，我们引入了CollaFuse，这是一个受拆分学习启发的新框架。为了有效协作使用去噪扩散概率模型，CollaFuse实现了共享服务器训练和推理，减轻了客户端的计算负担。这通过在每个客户端本地保留数据和计算成本低廉的GPU进程，同时将计算成本高昂的进程外包给共享服务器来实现。在医疗环境中展示，CollaFuse通过大大减少对敏感信息共享的需求来增强隐私保护能力。

    arXiv:2402.19105v1 Announce Type: cross  Abstract: In the landscape of generative artificial intelligence, diffusion-based models present challenges for socio-technical systems in data requirements and privacy. Traditional approaches like federated learning distribute the learning process but strain individual clients, especially with constrained resources (e.g., edge devices). In response to these challenges, we introduce CollaFuse, a novel framework inspired by split learning. Tailored for efficient and collaborative use of denoising diffusion probabilistic models, CollaFuse enables shared server training and inference, alleviating client computational burdens. This is achieved by retaining data and computationally inexpensive GPU processes locally at each client while outsourcing the computationally expensive processes to the shared server. Demonstrated in a healthcare context, CollaFuse enhances privacy by highly reducing the need for sensitive information sharing. These capabiliti
    
[^13]: 多态雷达对空中飞行器雷达截面识别：一种贝叶斯融合方法

    Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach

    [https://arxiv.org/abs/2402.17987](https://arxiv.org/abs/2402.17987)

    提出了一种完全贝叶斯雷达自动目标识别的框架，采用最优贝叶斯融合来有效地汇总多个雷达的分类概率向量，以改进无人机雷达截面识别效果。

    

    arXiv:2402.17987v1 公告类型：跨领域 摘要：无人机的雷达自动目标识别（RATR）涉及发射电磁波并对接收到的雷达回波执行目标类型识别，对国防和航空航天应用至关重要。先前的研究突出了多态雷达配置在RATR中优于单态雷达的优势。然而，多态雷达配置中的融合方法通常以概率方式次优地组合来自各个雷达的分类向量。为了解决这个问题，我们提出了一个完全贝叶斯RATR框架，采用最优贝叶斯融合（OBF）来聚合来自多个雷达的分类概率向量。OBF基于期望0-1损失，根据多个时间步骤的历史观测更新目标无人机类型的递归贝叶斯分类（RBC）后验分布。我们使用模拟的随机行走轨迹评估了这种方法，共涉及七种机动目标。

    arXiv:2402.17987v1 Announce Type: cross  Abstract: Radar Automated Target Recognition (RATR) for Unmanned Aerial Vehicles (UAVs) involves transmitting Electromagnetic Waves (EMWs) and performing target type recognition on the received radar echo, crucial for defense and aerospace applications. Previous studies highlighted the advantages of multistatic radar configurations over monostatic ones in RATR. However, fusion methods in multistatic radar configurations often suboptimally combine classification vectors from individual radars probabilistically. To address this, we propose a fully Bayesian RATR framework employing Optimal Bayesian Fusion (OBF) to aggregate classification probability vectors from multiple radars. OBF, based on expected 0-1 loss, updates a Recursive Bayesian Classification (RBC) posterior distribution for target UAV type, conditioned on historical observations across multiple time steps. We evaluate the approach using simulated random walk trajectories for seven dro
    
[^14]: 语言模型听到了什么？探究语言模型中的听觉表征

    What Do Language Models Hear? Probing for Auditory Representations in Language Models

    [https://arxiv.org/abs/2402.16998](https://arxiv.org/abs/2402.16998)

    通过训练一个线性探针，将语言模型中的文本表示和预训练音频模型中的声音表示联系在一起，研究发现尽管仅在原始文本上进行训练，语言模型对于一些对象的声音知识有着基于实质的编码。

    

    这项工作探讨了语言模型是否对物体的声音具有含义深刻且基于实质的表征。我们学习了一个线性探针，通过一个预训练的音频模型给出一个对象的声音表示，从而在给定与该对象相关的音频片段的情况下检索出该对象的正确文本表示。这个探针是通过对比损失进行训练的，推动对象的语言表示和声音表示彼此接近。在训练之后，我们测试了探针对于一些在训练中没有见过的对象的泛化能力。在不同的语言模型和音频模型中，我们发现在许多情况下探针的泛化能力超过了随机猜测的水平，这表明尽管仅在原始文本上进行训练，语言模型对于一些对象的声音知识具有基于实质的编码。

    arXiv:2402.16998v1 Announce Type: cross  Abstract: This work explores whether language models encode meaningfully grounded representations of sounds of objects. We learn a linear probe that retrieves the correct text representation of an object given a snippet of audio related to that object, where the sound representation is given by a pretrained audio model. This probe is trained via a contrastive loss that pushes the language representations and sound representations of an object to be close to one another. After training, the probe is tested on its ability to generalize to objects that were not seen during training. Across different language models and audio models, we find that the probe generalization is above chance in many cases, indicating that despite being trained only on raw text, language models encode grounded knowledge of sounds for some objects.
    
[^15]: 通过因果干预实现图形的离群分布泛化

    Graph Out-of-Distribution Generalization via Causal Intervention

    [https://arxiv.org/abs/2402.11494](https://arxiv.org/abs/2402.11494)

    GNN在离群分布泛化中的失败关键在于来自环境的潜在混杂偏差，因此引入了一个简单而原则性的方法来训练稳健GNN。

    

    离群分布（OOD）泛化在图形学习中引起了越来越多的关注，因为图神经网络（GNN）在分布转移时通常会表现出性能下降。本文从自下而上的数据生成角度出发，通过因果分析揭示了一个关键观察：GNN在OOD泛化中失败的关键在于来自环境的潜在混杂偏差。后者误导模型利用自我图特征和目标节点标签之间的环境敏感相关性，导致在新的未见节点上不良泛化。基于这一分析，我们引入了一个在节点级别分布转移下训练稳健GNN的概念简单而又原则性的方法，而不需要环境的先验知识。

    arXiv:2402.11494v1 Announce Type: new  Abstract: Out-of-distribution (OOD) generalization has gained increasing attentions for learning on graphs, as graph neural networks (GNNs) often exhibit performance degradation with distribution shifts. The challenge is that distribution shifts on graphs involve intricate interconnections between nodes, and the environment labels are often absent in data. In this paper, we adopt a bottom-up data-generative perspective and reveal a key observation through causal analysis: the crux of GNNs' failure in OOD generalization lies in the latent confounding bias from the environment. The latter misguides the model to leverage environment-sensitive correlations between ego-graph features and target nodes' labels, resulting in undesirable generalization on new unseen nodes. Built upon this analysis, we introduce a conceptually simple yet principled approach for training robust GNNs under node-level distribution shifts, without prior knowledge of environment
    
[^16]: 通过开关变量在隐式因果模型中解开纠缠

    Disentanglement in Implicit Causal Models via Switch Variable

    [https://arxiv.org/abs/2402.11124](https://arxiv.org/abs/2402.11124)

    该论文通过软干预处理隐式潜在因果表征学习，在 Variational Autoencoder (VAE) 框架中引入了因果机制开关变量。

    

    从观测和干预数据中学习因果表征，在没有已知的地面真实图结构的情况下，需要隐式潜在因果表征学习。隐式学习因果机制通常涉及两类干预数据：硬干预和软干预。在现实世界场景中，软干预通常比硬干预更现实，因为后者需要完全受控的环境。与直接强制改变因果变量的硬干预不同，软干预通过影响因果机制间接地产生影响。本文通过软干预在变分自动编码器（VAE）框架中处理隐式潜在因果表征学习。我们的方法通过使用一个旨在在不同因果机制之间切换的因果机制开关变量来建模软干预效果。在我们的实验中，我们始终保持

    arXiv:2402.11124v1 Announce Type: new  Abstract: Learning causal representations from observational and interventional data in the absence of known ground-truth graph structures necessitates implicit latent causal representation learning. Implicitly learning causal mechanisms typically involves two categories of interventional data: hard and soft interventions. In real-world scenarios, soft interventions are often more realistic than hard interventions, as the latter require fully controlled environments. Unlike hard interventions, which directly force changes in a causal variable, soft interventions exert influence indirectly by affecting the causal mechanism. In this paper, we tackle implicit latent causal representation learning in a Variational Autoencoder (VAE) framework through soft interventions. Our approach models soft interventions effects by employing a causal mechanism switch variable designed to toggle between different causal mechanisms. In our experiments, we consistentl
    
[^17]: 在文本到图像模型中的危害放大

    Harm Amplification in Text-to-Image Models

    [https://arxiv.org/abs/2402.01787](https://arxiv.org/abs/2402.01787)

    我们的研究提出了危害放大现象并发展了量化危害放大的方法，考虑模型输出的危害与用户输入的情境。我们还实证地研究了不同的方法在真实场景中的应用，并量化了由危害放大引起的性别之间的影响差异。

    

    文本到图像 (T2I) 模型已成为生成式人工智能的重要进展，然而，存在安全问题，即使用户输入看似安全的提示，这些模型也可能生成有害图像。这种现象称为危害放大，它比对抗提示更具潜在风险，使用户无意间遭受伤害。本文首先提出了危害放大的形式定义，并进一步贡献于开发用于量化危害放大的方法，考虑模型输出的危害与用户输入的情境。我们还经验性地研究了如何应用这些方法模拟真实世界的部署场景，包括量化由危害放大引起的不同性别之间的影响差异。我们的工作旨在为研究者提供工具去解决这个问题。

    Text-to-image (T2I) models have emerged as a significant advancement in generative AI; however, there exist safety concerns regarding their potential to produce harmful image outputs even when users input seemingly safe prompts. This phenomenon, where T2I models generate harmful representations that were not explicit in the input, poses a potentially greater risk than adversarial prompts, leaving users unintentionally exposed to harms. Our paper addresses this issue by first introducing a formal definition for this phenomenon, termed harm amplification. We further contribute to the field by developing methodologies to quantify harm amplification in which we consider the harm of the model output in the context of user input. We then empirically examine how to apply these different methodologies to simulate real-world deployment scenarios including a quantification of disparate impacts across genders resulting from harm amplification. Together, our work aims to offer researchers tools to
    
[^18]: 数据有效学习：一项综合医学基准研究

    Data-Effective Learning: A Comprehensive Medical Benchmark

    [https://arxiv.org/abs/2401.17542](https://arxiv.org/abs/2401.17542)

    这项研究引入了一个综合基准，用于评估医学领域的数据有效学习。该基准包括大量的医疗数据样本、基准方法和新的评估指标，能够准确评估数据有效学习的性能。

    

    数据有效学习旨在以最有效的方式利用数据来训练AI模型，其涉及关注数据质量而非数量的策略，确保用于训练的数据具有高信息价值。数据有效学习在加快AI训练、减少计算成本和节省数据存储方面发挥着重要作用，这在近年来医学数据的数量超出了许多人的预期时尤为重要。然而，由于缺乏标准和综合的基准研究，医学领域的数据有效学习研究还不够深入。为了填补这一空白，本文引入了一个专门用于评估医学领域数据有效学习的综合基准。该基准包括来自31个医疗中心数百万个数据样本的数据集(DataDEL)，用于比较的基准方法(MedDEL)，以及一个用于客观衡量数据有效学习性能的新评估指标(NormDEL)。我们进行了广泛的实证实验和比较，证明了我们的基准在评估数据有效学习方面的有效性和适用性。

    Data-effective learning aims to use data in the most impactful way to train AI models, which involves strategies that focus on data quality rather than quantity, ensuring the data used for training has high informational value. Data-effective learning plays a profound role in accelerating AI training, reducing computational costs, and saving data storage, which is very important as the volume of medical data in recent years has grown beyond many people's expectations. However, due to the lack of standards and comprehensive benchmark, research on medical data-effective learning is poorly studied. To address this gap, our paper introduces a comprehensive benchmark specifically for evaluating data-effective learning in the medical field. This benchmark includes a dataset with millions of data samples from 31 medical centers (DataDEL), a baseline method for comparison (MedDEL), and a new evaluation metric (NormDEL) to objectively measure data-effective learning performance. Our extensive e
    
[^19]: 离散分布的谱聚类

    Spectral Clustering for Discrete Distributions. (arXiv:2401.13913v1 [cs.LG])

    [http://arxiv.org/abs/2401.13913](http://arxiv.org/abs/2401.13913)

    本文提出了一种基于谱聚类和分布相似度度量的框架来解决离散分布聚类问题。通过使用线性最优传输构建相似度矩阵，我们在聚类准确性和计算效率方面取得了显著的改进。

    

    离散分布聚类（D2C）通常通过Wasserstein质心方法来解决。这些方法在一个共同的假设下工作，即聚类可以通过质心很好地表示，但在许多实际应用中可能不成立。在本文中，我们提出了一个简单而有效的基于谱聚类和分布相似度度量（例如最大均值差异和Wasserstein距离）的框架来解决D2C问题。为了提高可扩展性，我们提出使用线性最优传输在大型数据集上高效地构建相似度矩阵。我们提供了理论保证，保证了所提方法在聚类分布方面的成功。在合成数据和真实数据上的实验证明，我们的方法在聚类准确性和计算效率方面大大优于基准方法。

    Discrete distribution clustering (D2C) was often solved by Wasserstein barycenter methods. These methods are under a common assumption that clusters can be well represented by barycenters, which may not hold in many real applications. In this work, we propose a simple yet effective framework based on spectral clustering and distribution affinity measures (e.g., maximum mean discrepancy and Wasserstein distance) for D2C. To improve the scalability, we propose to use linear optimal transport to construct affinity matrices efficiently on large datasets. We provide theoretical guarantees for the success of the proposed methods in clustering distributions. Experiments on synthetic and real data show that our methods outperform the baselines largely in terms of both clustering accuracy and computational efficiency.
    
[^20]: 通过切换机制，在扩散模型中实现公平抽样

    Fair Sampling in Diffusion Models through Switching Mechanism. (arXiv:2401.03140v1 [cs.LG])

    [http://arxiv.org/abs/2401.03140](http://arxiv.org/abs/2401.03140)

    本论文提出了一种称为“属性切换”的公平抽样机制，用于解决扩散模型中公平性的问题。通过在生成的数据中混淆敏感属性，该方法能够实现生成公平数据和保持数据效用的目标。

    

    扩散模型通过良好逼近潜在概率分布，在生成任务中展现了高效性。然而，扩散模型在公平性方面受到训练数据的内在偏差的放大。尽管扩散模型的抽样过程可以通过条件引导来控制，但之前的研究试图找到实证引导来实现定量公平性。为了解决这个限制，我们提出了一种称为“属性切换”机制的具有公平意识的抽样方法，用于扩散模型。在不需要额外训练的情况下，所提出的抽样方法可以在生成的数据中混淆敏感属性，而不依赖分类器。我们在两个关键方面从数学上证明了和实验证明了所提方法的有效性：(i)生成公平数据和(ii)保持生成数据的效用。

    Diffusion models have shown their effectiveness in generation tasks by well-approximating the underlying probability distribution. However, diffusion models are known to suffer from an amplified inherent bias from the training data in terms of fairness. While the sampling process of diffusion models can be controlled by conditional guidance, previous works have attempted to find empirical guidance to achieve quantitative fairness. To address this limitation, we propose a fairness-aware sampling method called \textit{attribute switching} mechanism for diffusion models. Without additional training, the proposed sampling can obfuscate sensitive attributes in generated data without relying on classifiers. We mathematically prove and experimentally demonstrate the effectiveness of the proposed method on two key aspects: (i) the generation of fair data and (ii) the preservation of the utility of the generated data.
    
[^21]: 个性化预测胶质母细胞瘤浸润:数学模型、物理信息神经网络和多模态扫描

    Personalized Predictions of Glioblastoma Infiltration: Mathematical Models, Physics-Informed Neural Networks and Multimodal Scans. (arXiv:2311.16536v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.16536](http://arxiv.org/abs/2311.16536)

    本研究利用物理信息神经网络（PINNs）从单个三维结构MRI快照中估计胶质母细胞瘤（GBM）生长模型的患者特异性参数，并通过整合理论和数据进行个性化预测，为胶质母细胞瘤的治疗设计提供了关键创新。

    

    预测胶质母细胞瘤（GBM）从医学MRI扫描中的浸润对于理解肿瘤生长动力学和设计个体化放射治疗计划至关重要。GBM生长的数学模型可以在预测肿瘤细胞的空间分布中补充数据。然而，这需要从临床数据中估计模型的患者特异性参数，由于时间数据有限且成像和诊断之间的时间有限，这是一个具有挑战性的反问题。本研究提出了一种使用物理信息神经网络（PINNs）从单个三维结构MRI快照中估计GBM生长反应扩散偏微分方程模型的患者特异性参数的方法。PINNs将数据和PDE嵌入到损失函数中，从而整合了理论和数据。关键创新包括特征无量纲参数的识别和估计，利用无量纲参数的预训练步骤以及微调步骤。

    Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is crucial for understanding tumor growth dynamics and designing personalized radiotherapy treatment plans.Mathematical models of GBM growth can complement the data in the prediction of spatial distributions of tumor cells. However, this requires estimating patient-specific parameters of the model from clinical data, which is a challenging inverse problem due to limited temporal data and the limited time between imaging and diagnosis. This work proposes a method that uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific parameters of a reaction-diffusion PDE model of GBM growth from a single 3D structural MRI snapshot. PINNs embed both the data and the PDE into a loss function, thus integrating theory and data. Key innovations include the identification and estimation of characteristic non-dimensional parameters, a pre-training step that utilizes the non-dimensional parameters and a fine-tunin
    
[^22]: 使用位反转攻击图神经网络：Weisfeiler和Lehman变得冷漠了

    Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent. (arXiv:2311.01205v1 [cs.LG])

    [http://arxiv.org/abs/2311.01205](http://arxiv.org/abs/2311.01205)

    我们设计了Injectivity Bit Flip Attack来针对图神经网络，成功地降低了其对图结构的识别能力和表达能力，从而增加了其对位反转攻击的易受攻击性。

    

    先前对图神经网络的攻击主要集中在图毒化和规避上，忽略了网络的权重和偏置。传统的基于权重的故障注入攻击，如用于卷积神经网络的位反转攻击，没有考虑到图神经网络的独特属性。我们提出了注入率位反转攻击（Injectivity Bit Flip Attack），这是第一个专门针对图神经网络设计的位反转攻击。我们的攻击针对量化消息传递神经网络中的可学习邻域聚合函数，降低了其区分图结构的能力，失去了Weisfeiler-Lehman测试的表达能力。我们的发现表明，利用特定于某些图神经网络架构的数学属性可能会显著增加其对位反转攻击的易受攻击性。注入率位反转攻击可以将各种图属性预测数据集上训练的最大表达性同构网络降级为随机输出。

    Prior attacks on graph neural networks have mostly focused on graph poisoning and evasion, neglecting the network's weights and biases. Traditional weight-based fault injection attacks, such as bit flip attacks used for convolutional neural networks, do not consider the unique properties of graph neural networks. We propose the Injectivity Bit Flip Attack, the first bit flip attack designed specifically for graph neural networks. Our attack targets the learnable neighborhood aggregation functions in quantized message passing neural networks, degrading their ability to distinguish graph structures and losing the expressivity of the Weisfeiler-Lehman test. Our findings suggest that exploiting mathematical properties specific to certain graph neural network architectures can significantly increase their vulnerability to bit flip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive Graph Isomorphism Networks trained on various graph property prediction datasets to rando
    
[^23]: 多任务强化学习的联邦自然策略梯度方法

    Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning. (arXiv:2311.00201v1 [cs.LG])

    [http://arxiv.org/abs/2311.00201](http://arxiv.org/abs/2311.00201)

    本研究提出了一种多任务强化学习的联邦自然策略梯度方法，在分布式环境中，通过优化全局策略以最大化所有智能体的总奖励，实现协作决策。这些方法不受信息共享不完备的影响，且具有非渐近全局收敛保证。

    

    联邦强化学习使得多个分布式智能体可以在不共享本地数据轨迹的情况下进行协作决策。本文考虑了多任务设置，其中每个智能体都有自己的私有奖励函数对应不同的任务，同时共享环境的相同转移核。针对无限时间步标记马尔可夫决策过程，目标是学习出一种全局最优策略，在分散的方式下，最大化所有智能体的折扣总奖励之和，其中每个智能体仅与其在给定图拓扑中的邻居进行通信。我们在 softmax 参数化下开展了联邦纯粹和熵正则化的自然策略梯度（NPG）方法，其中将梯度跟踪应用于全局 Q 函数，以减轻信息共享不完备的影响。我们在精确策略评估下建立了非渐近全局收敛保证，这些保证几乎是独立的。

    Federated reinforcement learning (RL) enables collaborative decision making of multiple distributed agents without sharing local data trajectories. In this work, we consider a multi-task setting, in which each agent has its own private reward function corresponding to different tasks, while sharing the same transition kernel of the environment. Focusing on infinite-horizon tabular Markov decision processes, the goal is to learn a globally optimal policy that maximizes the sum of the discounted total rewards of all the agents in a decentralized manner, where each agent only communicates with its neighbors over some prescribed graph topology. We develop federated vanilla and entropy-regularized natural policy gradient (NPG) methods under softmax parameterization, where gradient tracking is applied to the global Q-function to mitigate the impact of imperfect information sharing. We establish non-asymptotic global convergence guarantees under exact policy evaluation, which are nearly indep
    
[^24]: 等距运动流形基元

    Isometric Motion Manifold Primitives. (arXiv:2310.17072v1 [cs.AI])

    [http://arxiv.org/abs/2310.17072](http://arxiv.org/abs/2310.17072)

    Isometric Motion Manifold Primitives (IMMP) is proposed to address the degradation of Motion Manifold Primitive (MMP) performance due to geometric distortion in the latent space. IMMP preserves the geometry of the manifold in the latent coordinate space using a Riemannian metric, and experimental results show that IMMP significantly outperforms existing MMP methods.

    

    运动流形基元（MMP）为给定任务生成一系列连续轨迹流形，每一个轨迹流形都能成功完成任务。它由对流形进行参数化的解码函数以及潜在坐标空间中的概率密度组成。本文首先展示了由于潜在空间中的几何扭曲，MMP的性能可能会显著降低--通过变形，我们指的是相似的运动在潜在空间中无法相邻。然后，我们提出了等距运动流形基元（IMMP），其潜在坐标空间保持了流形的几何结构。为此，我们建立和使用了一个Riemannian度量，用于运动空间（即，参数化曲线空间），我们称之为CurveGeom Riemannian度量。对于平面障碍避让运动和推动操纵任务的实验表明，IMMP明显优于现有的MMP方法。代码可在https://github.com/Gabe-YHLee/IMMP找到。

    The Motion Manifold Primitive (MMP) produces, for a given task, a continuous manifold of trajectories each of which can successfully complete the task. It consists of the decoder function that parametrizes the manifold and the probability density in the latent coordinate space. In this paper, we first show that the MMP performance can significantly degrade due to the geometric distortion in the latent space -- by distortion, we mean that similar motions are not located nearby in the latent space. We then propose {\it Isometric Motion Manifold Primitives (IMMP)} whose latent coordinate space preserves the geometry of the manifold. For this purpose, we formulate and use a Riemannian metric for the motion space (i.e., parametric curve space), which we call a {\it CurveGeom Riemannian metric}. Experiments with planar obstacle-avoiding motions and pushing manipulation tasks show that IMMP significantly outperforms existing MMP methods. Code is available at https://github.com/Gabe-YHLee/IMMP
    
[^25]: 通过扩散模型快速可靠地生成电子健康记录时间序列

    Fast and Reliable Generation of EHR Time Series via Diffusion Models. (arXiv:2310.15290v1 [cs.LG])

    [http://arxiv.org/abs/2310.15290](http://arxiv.org/abs/2310.15290)

    本研究通过使用扩散模型提出了一种快速可靠生成EHR时间序列数据的新方法，该方法在数据效用方面明显优于现有方法，并且对训练工作的需求更少。同时，该方法还提供了多样化和真实的合成EHR数据，增强了下游医疗数据分析。

    

    电子健康记录（EHR）是丰富的患者级数据来源，包括实验室检验、药物和诊断，为医疗数据分析提供了宝贵资源。然而，对隐私的担忧常常限制了对EHR的访问，阻碍了下游分析。研究人员已经探索了各种方法来生成保护隐私的EHR数据。在本研究中，我们引入了一种使用去噪扩散概率模型（DDPM）生成多样化和真实的合成EHR时间序列数据的新方法。我们对六个数据集进行了实验证明，我们的方法在数据效用方面明显优于七种现有方法，并且需要更少的训练工作。我们的方法还通过提供多样化和真实的合成EHR数据来增强下游医疗数据分析。

    Electronic Health Records (EHRs) are rich sources of patient-level data, including laboratory tests, medications, and diagnoses, offering valuable resources for medical data analysis. However, concerns about privacy often restrict access to EHRs, hindering downstream analysis. Researchers have explored various methods for generating privacy-preserving EHR data. In this study, we introduce a new method for generating diverse and realistic synthetic EHR time series data using Denoising Diffusion Probabilistic Models (DDPM). We conducted experiments on six datasets, comparing our proposed method with seven existing methods. Our results demonstrate that our approach significantly outperforms all existing methods in terms of data utility while requiring less training effort. Our approach also enhances downstream medical data analysis by providing diverse and realistic synthetic EHR data.
    
[^26]: 针对预测不确定性的模型无关变量重要性：一种基于熵的方法

    Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])

    [http://arxiv.org/abs/2310.12842](http://arxiv.org/abs/2310.12842)

    本文提出了一种基于熵的方法，通过扩展现有的解释性方法，可以理解不确定性感知模型中的预测来源和置信度，并利用改编后的特征重要性、部分依赖图和个体条件期望图等方法来测量特征对预测分布的熵和基于真实标签的对数似然的影响。

    

    为了相信机器学习算法的预测结果，必须理解导致这些预测的因素。对于概率和不确定性感知的模型来说，不仅需要理解预测本身的原因，还要理解模型对这些预测的置信度。本文展示了如何将现有的解释性方法扩展到不确定性感知的模型，并如何利用这些扩展来理解模型预测分布中的不确定性来源。特别是通过改编排列特征重要性、部分依赖图和个体条件期望图，我们证明可以获得对模型行为的新见解，并且可以使用这些方法来衡量特征对预测分布的熵和基于该分布的真实标签的对数似然的影响。通过使用两个数据集的实验，我们验证了所提方法的有效性。

    In order to trust the predictions of a machine learning algorithm, it is necessary to understand the factors that contribute to those predictions. In the case of probabilistic and uncertainty-aware models, it is necessary to understand not only the reasons for the predictions themselves, but also the model's level of confidence in those predictions. In this paper, we show how existing methods in explainability can be extended to uncertainty-aware models and how such extensions can be used to understand the sources of uncertainty in a model's predictive distribution. In particular, by adapting permutation feature importance, partial dependence plots, and individual conditional expectation plots, we demonstrate that novel insights into model behaviour may be obtained and that these methods can be used to measure the impact of features on both the entropy of the predictive distribution and the log-likelihood of the ground truth labels under that distribution. With experiments using both s
    
[^27]: 自学优化器（STOP）：递归自我改进的代码生成

    Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation. (arXiv:2310.02304v1 [cs.CL])

    [http://arxiv.org/abs/2310.02304](http://arxiv.org/abs/2310.02304)

    本文提出了一种自学优化器（STOP），通过递归自我改进的代码生成，使用融合了语言模型的脚手架程序来改进自身，从而生成性能更好的程序。

    

    最近几年的人工智能系统（例如思维树和程序辅助语言模型）取得了一些重要进展，通过提供一个“脚手架”程序来解决问题，该程序构建了多次调用语言模型以生成更好的输出。脚手架程序通常使用Python等编程语言编写。在这项工作中，我们使用了一个融合了语言模型的脚手架程序来改进自身。我们从一个种子“改进器”开始，通过多次查询语言模型并返回最佳解决方案，根据给定的效用函数来改进输入程序。然后，我们运行这个种子改进器来改进自身。在一系列细分任务中，得到的改进改进器生成的程序在性能上明显优于种子改进器。随后，我们对语言模型提出的各种自我改进策略进行了分析，包括波束搜索、遗传算法和模拟退火。由于语言模型本身没有改变，这并不是一种增长领域。

    Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a "scaffolding" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed "improver" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. Afterward, we analyze the variety of self-improvement strategies proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not fu
    
[^28]: S-GBDT: 节俭的差分隐私梯度提升决策树

    S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees. (arXiv:2309.12041v1 [cs.CR])

    [http://arxiv.org/abs/2309.12041](http://arxiv.org/abs/2309.12041)

    S-GBDT是一种节俭的差分隐私梯度提升决策树学习器，利用了四种技术来改善效用和隐私权之间的平衡，包括对隐私泄露的更紧密计算和整合个体Rényi滤波器以学习未充分利用的数据点。

    

    差分隐私学习梯度提升决策树(GBDT)在表格数据(如人口普查数据或医疗元数据)中具有很强的效用和隐私权之间的平衡潜力：经典的GBDT学习器可以从小规模数据集中提取非线性模式。可证明具有隐私性质的当前方法是差分隐私，该方法要求单个数据点的影响有限且可否认。我们引入了一种新的差分隐私GBDT学习器，并利用四种主要技术来改善效用和隐私权之间的平衡。(1)我们使用了一种改进的噪声缩放方法，更紧密地计算了与先前工作相比决策树叶子的隐私泄露，从而导致噪声的期望与数据点数量n的比例为$O(1/n)$，其中n为数据点数量。(2)我们将个体Rényi滤波器整合到我们的方法中，以从在迭代训练过程中未充分利用的数据点中学习，这可能是独立于兴趣的结果。

    Privacy-preserving learning of gradient boosting decision trees (GBDT) has the potential for strong utility-privacy tradeoffs for tabular data, such as census data or medical meta data: classical GBDT learners can extract non-linear patterns from small sized datasets. The state-of-the-art notion for provable privacy-properties is differential privacy, which requires that the impact of single data points is limited and deniable. We introduce a novel differentially private GBDT learner and utilize four main techniques to improve the utility-privacy tradeoff. (1) We use an improved noise scaling approach with tighter accounting of privacy leakage of a decision tree leaf compared to prior work, resulting in noise that in expectation scales with $O(1/n)$, for $n$ data points. (2) We integrate individual R\'enyi filters to our method to learn from data points that have been underutilized during an iterative training process, which -- potentially of independent interest -- results in a natura
    
[^29]: 在多层级环境中识别供应链结果的贡献者：一种去中心化方法

    Identifying contributors to supply chain outcomes in a multi-echelon setting: a decentralised approach. (arXiv:2307.12157v1 [cs.LG])

    [http://arxiv.org/abs/2307.12157](http://arxiv.org/abs/2307.12157)

    研究介绍了一种去中心化方法，利用可解释的人工智能对多层级供应链中感兴趣指标的估计贡献进行计算，无需数据共享。经验证实，该方法在检测质量变化的原因方面有效。

    

    组织经常难以确定产品质量和交货时间等指标变化的原因。当原因位于公司边界之外，处于部分可观察的多层级供应链中时，这项任务变得越来越具有挑战性。尽管传统的供应链管理主张通过数据共享获得更好的洞察力，但由于数据隐私问题，这在实践中并不常见。我们提出使用可解释的人工智能来实现对多阶段生产过程中感兴趣指标的估计贡献的去中心化计算。这种方法减轻了说服供应链参与者共享数据的需求，因为所有计算都是以去中心化的方式进行的。我们的方法是通过对真实多阶段制造过程进行数据收集进行经验证实的。结果显示，与使用集中化方法相比，我们的方法在检测质量变化的原因方面具有有效性。

    Organisations often struggle to identify the causes of change in metrics such as product quality and delivery duration. This task becomes increasingly challenging when the cause lies outside of company borders in multi-echelon supply chains that are only partially observable. Although traditional supply chain management has advocated for data sharing to gain better insights, this does not take place in practice due to data privacy concerns. We propose the use of explainable artificial intelligence for decentralised computing of estimated contributions to a metric of interest in a multi-stage production process. This approach mitigates the need to convince supply chain actors to share data, as all computations occur in a decentralised manner. Our method is empirically validated using data collected from a real multi-stage manufacturing process. The results demonstrate the effectiveness of our approach in detecting the source of quality variations compared to a centralised approach using
    
[^30]: 为大型图表示简化和增强Transformer

    Simplifying and Empowering Transformers for Large-Graph Representations. (arXiv:2306.10759v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10759](http://arxiv.org/abs/2306.10759)

    本文通过实验证明，在大型图上使用一层注意力即可获得令人惊讶的竞争性能，挑战了在语言和视觉任务中复杂模型的应用。这促使我们重新思考在大型图上设计Transformer的理念，以提高可扩展性。

    

    在大型图上学习表示是一个长期存在的挑战，因为其中涉及了大量数据点之间的相互依赖关系。Transformer作为一种新兴的用于图结构数据的基本编码器类别，由于其全局注意力可以捕捉到邻节点之外的所有对影响，因此在小型图上表现出了有希望的性能。尽管如此，现有方法往往继承了Transformer在语言和视觉任务中的思想，并通过堆叠深层多头注意力来采用复杂的模型。本文通过关于节点属性预测基准的实验证明，即使只使用一层注意力也能在节点数量从千级到十亿级的范围内带来令人惊讶的竞争性能。这鼓励我们重新思考在大型图上设计Transformer的理念，其中全局注意力是一个阻碍可扩展性的计算开销。我们将提出的方案称为简化图Transformer。

    Learning representations on large-sized graphs is a long-standing challenge due to the inter-dependence nature involved in massive data points. Transformers, as an emerging class of foundation encoders for graph-structured data, have shown promising performance on small graphs due to its global attention capable of capturing all-pair influence beyond neighboring nodes. Even so, existing approaches tend to inherit the spirit of Transformers in language and vision tasks, and embrace complicated models by stacking deep multi-head attentions. In this paper, we critically demonstrate that even using a one-layer attention can bring up surprisingly competitive performance across node property prediction benchmarks where node numbers range from thousand-level to billion-level. This encourages us to rethink the design philosophy for Transformers on large graphs, where the global attention is a computation overhead hindering the scalability. We frame the proposed scheme as Simplified Graph Trans
    
[^31]: 自监督多模态学习：一项综述

    Self-Supervised Multimodal Learning: A Survey. (arXiv:2304.01008v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.01008](http://arxiv.org/abs/2304.01008)

    自监督多模态学习是一项旨在解决多模态数据中的自监督学习挑战的研究方向。它通过学习来自原始多模态数据中的表示，并解决了没有标签的多模态数据学习、不同模态的融合和不对齐数据学习等问题。

    

    多模态学习旨在理解和分析来自多种模态的信息，在监督学习范式下取得了重大进展。然而，由于依赖于配对数据和昂贵的人工注释，模型的扩展性受到了限制。与此同时，鉴于野外有大规模未注释的数据可用，自监督学习成为缓解注释瓶颈的一种有吸引力的策略。自监督多模态学习（SSML）建立在这两个方向的基础上，提供了从原始多模态数据中学习的方法。在本综述中，我们全面回顾了SSML的最新进展，阐述了自监督学习在多模态数据中面临的三个主要挑战：（1）在没有标签的多模态数据中学习表示，（2）不同模态的融合，以及（3）与不对齐数据的学习。然后，我们详细介绍了这些挑战的现有解决方案。具体而言，我们考虑了（1）目标

    Multimodal learning, which aims to understand and analyze information from multiple modalities, has achieved substantial progress in the supervised regime in recent years. However, the heavy dependence on data paired with expensive human annotations impedes scaling up models. Meanwhile, given the availability of large-scale unannotated data in the wild, self-supervised learning has become an attractive strategy to alleviate the annotation bottleneck. Building on these two directions, self-supervised multimodal learning (SSML) provides ways to learn from raw multimodal data. In this survey, we provide a comprehensive review of the state-of-the-art in SSML, in which we elucidate three major challenges intrinsic to self-supervised learning with multimodal data: (1) learning representations from multimodal data without labels, (2) fusion of different modalities, and (3) learning with unaligned data. We then detail existing solutions to these challenges. Specifically, we consider (1) object
    
[^32]: 用于编码的大型语言模型：安全加固和对抗测试

    Large Language Models for Code: Security Hardening and Adversarial Testing. (arXiv:2302.05319v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.05319](http://arxiv.org/abs/2302.05319)

    本研究针对大型语言模型在生成代码时缺乏安全意识，从安全加固和对抗测试的角度入手，提出了一项新的安全任务——受控代码生成，通过一种新型基于学习的方法SVEN，实现生成既安全又功能正确的代码，并对当前的LM进行对抗测试，强调了在LM的培训和评估中考虑安全因素的必要性。

    

    大型语言模型(LMs)越来越多地预先在大规模代码库上进行预处理，用于生成代码。然而，LM缺乏安全意识，并经常生成不安全的代码。本研究沿着两个重要方向研究了LM的安全性:(i)安全加固，旨在增强LM在生成安全代码方面的可靠性;(ii)对抗测试，旨在在对抗性立场评估LM的安全性。我们通过制定一项称为受控代码生成的新安全任务来同时解决这两个问题。该任务是参数化的，将一个二进制属性作为输入，以指导LM生成安全或不安全的代码，同时保留LM生成功能正确代码的能力。我们提出了一种称为SVEN的新型基于学习的方法来解决这个任务。SVEN利用属性特定的连续向量来引导程序生成达到给定的属性，而不修改LM的权重。我们的训练过程通过可微分的投影损失来优化这些连续向量，实现端到端的训练。此外，我们使用SVEN进行对抗测试，并表明当前的LM容易受到攻击，在测试时修改它们的输入而保留功能。我们的工作强调需要在LM的培训和评估中考虑安全因素。

    Large language models (LMs) are increasingly pretrained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous ve
    
[^33]: 基于弱监督的高斯过程主动学习

    Active Learning with Weak Supervision for Gaussian Processes. (arXiv:2204.08335v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.08335](http://arxiv.org/abs/2204.08335)

    本文提出了一种基于弱监督的主动学习算法，不仅选择要注释的观测结果，还选择要获得的注释精度，并在高斯过程中进行了实验验证。

    

    对于监督学习，进行数据注释需要耗费大量成本。当注释预算有限时，可以使用主动学习来选择和注释那些可能在模型性能上获得最大收益的观测结果。我们提出了一种主动学习算法，除了选择要注释的观测结果外，还选择要获得的注释精度。假定具有低精度的注释比具有高精度的注释更便宜，这使得模型能够在相同的注释预算下探索输入空间的更大部分。我们在先前针对高斯过程提出的BALD目标基础上构建了我们的获取函数，并在实验中展示了能够调整主动学习循环中的注释精度的优势。

    Annotating data for supervised learning can be costly. When the annotation budget is limited, active learning can be used to select and annotate those observations that are likely to give the most gain in model performance. We propose an active learning algorithm that, in addition to selecting which observation to annotate, selects the precision of the annotation that is acquired. Assuming that annotations with low precision are cheaper to obtain, this allows the model to explore a larger part of the input space, with the same annotation budget. We build our acquisition function on the previously proposed BALD objective for Gaussian Processes, and empirically demonstrate the gains of being able to adjust the annotation precision in the active learning loop.
    

