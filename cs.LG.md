# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning](https://arxiv.org/abs/2404.00027) | 探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。 |
| [^2] | [Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs](https://arxiv.org/abs/2404.00026) | 研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。 |
| [^3] | [Uncertainty-Aware Deployment of Pre-trained Language-Conditioned Imitation Learning Policies](https://arxiv.org/abs/2403.18222) | 提出一种不确定性感知的预训练语言条件模仿学习代理的部署方法，通过温度缩放和本地信息聚合做出不确定性感知决策，显著提升任务完成率。 |
| [^4] | [A Wasserstein perspective of Vanilla GANs](https://arxiv.org/abs/2403.15312) | 将普通GANs与水斯坦距离联系起来，扩展现有水斯坦GANs结果到普通GANs，获得了普通GANs的神谕不等式。 |
| [^5] | [Extracting Emotion Phrases from Tweets using BART](https://arxiv.org/abs/2403.14050) | 本文提出了一种基于BART的情感分析方法，利用问答框架从文本中提取特定情绪短语，并通过分类器预测答案跨度位置，实现对情绪短语的精确提取。 |
| [^6] | [SportsNGEN: Sustained Generation of Multi-player Sports Gameplay](https://arxiv.org/abs/2403.12977) | SportsNGEN是一种基于Transformer解码器的模型，经过训练能持续生成逼真的多人体育游戏，包括模拟整个网球比赛和为教练和广播员提供洞察力的能力。 |
| [^7] | [N2F2: Hierarchical Scene Understanding with Nested Neural Feature Fields](https://arxiv.org/abs/2403.10997) | 利用Nested Neural Feature Fields (N2F2) 实现了层次化监督学习，提供了对物理维度或语义维度等不同粒度的场景属性全面和细致的理解。 |
| [^8] | [Towards Fair Graph Anomaly Detection: Problem, New Datasets, and Evaluation](https://arxiv.org/abs/2402.15988) | 这项研究提出了公平图异常检测（FairGAD）问题，介绍了来自Reddit和Twitter的两个新图数据集，填补了当前文献在此问题上的空白。 |
| [^9] | [Automated Design and Optimization of Distributed Filtering Circuits via Reinforcement Learning](https://arxiv.org/abs/2402.14236) | 提出一种通过强化学习算法实现的自动化设计方法，显著提高了分布式滤波电路设计的效率和质量。 |
| [^10] | [On the Conflict of Robustness and Learning in Collaborative Machine Learning](https://arxiv.org/abs/2402.13700) | 在协作机器学习中，研究人员正式规范了稳健聚合器的领域，并发现现有的稳健聚合器无法实现其目标，要么无法准确识别有针对性的恶意更新，要么方法成功率不够。 |
| [^11] | [Statistical Test for Generated Hypotheses by Diffusion Models](https://arxiv.org/abs/2402.11789) | 本研究提出了一种统计检验方法，通过选择性推断框架，在考虑生成图像是由训练的扩散模型产生的条件下，量化医学图像诊断结果的可靠性。 |
| [^12] | [Privacy-preserving data release leveraging optimal transport and particle gradient descent](https://arxiv.org/abs/2401.17823) | 该研究提出了一种基于边际的保护隐私数据合成方法PrivPGD，利用了最优输运和粒子梯度下降的工具。该方法在不同领域的数据集上表现出色，具有高度的可扩展性和灵活性，并可以满足特定的领域约束条件。 |
| [^13] | [Weighted Ensemble Models Are Strong Continual Learners](https://arxiv.org/abs/2312.08977) | 通过加权集成模型实现了高准确性的持续学习，兼顾可塑性和稳定性。 |
| [^14] | [Weight fluctuations in (deep) linear neural networks and a derivation of the inverse-variance flatness relation](https://arxiv.org/abs/2311.14120) | 该研究探讨了单层和双层线性神经网络在随机梯度下降中的稳定训练规则，并发现了权重波动在各种情况下的各向异性特征，其中双层网络中的权重波动受到层间耦合的影响，并呈现出各向异性损失。 |
| [^15] | [Fast multiplication by two's complement addition of numbers represented as a set of polynomial radix 2 indexes, stored as an integer list for massively parallel computation](https://arxiv.org/abs/2311.09922) | 本论文介绍了一种基于多项式基数2指数集合的快速乘法方法，在特定位数范围内比传统方法更快。该方法把数字表示为整数索引列表，并实现了分布式计算。 |
| [^16] | [Learning in Mean Field Games: A Survey](https://arxiv.org/abs/2205.12944) | 强化学习和均场博弈的结合有望在很大规模上解决游戏的均衡和社会最优问题。 |
| [^17] | [Memory-Efficient Sequential Pattern Mining with Hybrid Tries](https://arxiv.org/abs/2202.06834) | 提出了一种基于混合trie的内存高效序列模式挖掘方法，在内存消耗和计算时间方面相比现有技术有显著改善，且是唯一一个能够处理256GB系统内存下大数据集的方法。 |
| [^18] | [Finetuning Large Language Models for Vulnerability Detection.](http://arxiv.org/abs/2401.17010) | 本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。 |
| [^19] | [Towards Interpretable Physical-Conceptual Catchment-Scale Hydrological Modeling using the Mass-Conserving-Perceptron.](http://arxiv.org/abs/2401.14521) | 本研究通过利用质量守恒感知器构建基于有向图结构的水文模型，实现了对集水区尺度水文过程的解释能力，在保持简洁性的同时能够准确地模拟各种流量动力学行为，并通过引入输入旁路机制进一步优化了模型的表现。 |
| [^20] | [Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation.](http://arxiv.org/abs/2401.09031) | 本文研究了数据归因方法对扩散模型的影响，发现对于在引发大范数时间步骤上训练的样本，其损失梯度范数高度依赖于时间步骤，导致在影响估计中存在显著的偏差。为了解决这个问题，提出了Diffusion-ReTr方法。 |
| [^21] | [Dynamic Spiking Graph Neural Networks.](http://arxiv.org/abs/2401.05373) | 本文提出了一个名为"动态尖峰图神经网络"（DSGNN）的框架，它将尖峰神经网络（SNNs）与图神经网络（GNNs）结合起来，以解决动态图表示学习中的复杂性和内存开销问题。DSGNN通过动态调整尖峰神经元的状态和连接权重，在传播过程中保持图结构信息的完整性。 |
| [^22] | [Setting the Record Straight on Transformer Oversmoothing.](http://arxiv.org/abs/2401.04301) | Transformers are not inherently low-pass filters as previously thought and whether they oversmooth or not depends on the eigenspectrum of their update equations. Based on the analysis, a simple way to parameterize the weights of the Transformer update equations is derived, allowing for control over its spectrum and preventing oversmoothing. |
| [^23] | [Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems.](http://arxiv.org/abs/2401.01192) | 本文提出了Deep-ELA方法，通过使用自监督预训练的变换器，对单目标和多目标连续优化问题进行深度探索性景观分析，解决了传统ELA特征存在的强相关性和在多目标优化问题中的局限性问题。 |
| [^24] | [Adaptive maximization of social welfare.](http://arxiv.org/abs/2310.09597) | 论文研究了通过适应性策略选择最大化社会福利的问题，并提供了关于遗憾的下界和算法的匹配上界。研究发现福利最大化比多臂老虎机问题更困难，但该算法达到了最优增长速率。 |
| [^25] | [Robust Losses for Decision-Focused Learning.](http://arxiv.org/abs/2310.04328) | 这篇论文提出了一种改进的损失函数来处理决策导向学习中的不确定性问题，并对经验遗憾作为替代的准确性进行了分析。 |
| [^26] | [Robust Multimodal Learning with Missing Modalities via Parameter-Efficient Adaptation.](http://arxiv.org/abs/2310.03986) | 通过低秩适应和中间特征的调制，我们提出了针对预训练多模态网络的参数高效适应程序，以实现对缺失模态的鲁棒性，并在某些情况下胜过独立的专门网络。 |
| [^27] | [FLAIM: AIM-based Synthetic Data Generation in the Federated Setting.](http://arxiv.org/abs/2310.03447) | FLAIM是一个在联邦设置中基于AIM的合成数据生成方法，该方法解决了差分隐私方向的技术在联邦场景下的适用问题，并提出了FLAIM方法来维持较高的效用和处理异构性。 |
| [^28] | [Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks.](http://arxiv.org/abs/2310.00115) | 本研究引入了第一个MoleculAR Conformer Ensemble Learning（MARCEL）基准测试，以全面评估在构象集合上学习的潜力，并提出有前途的研究方向。 |
| [^29] | [Revealing the Power of Spatial-Temporal Masked Autoencoders in Multivariate Time Series Forecasting.](http://arxiv.org/abs/2309.15169) | 提出了一个利用空间-时间掩蔽自动编码器（STMAE）来提高多元时间序列（MTS）预测性能的框架，通过新颖的双掩蔽策略处理部分可见的MTS数据，包括空间掩蔽和时间掩蔽。 |
| [^30] | [LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins.](http://arxiv.org/abs/2309.10254) | 本文提出了一个框架，用于分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性。在应用框架于OpenAI的插件生态系统时，我们发现了一些具体证明了潜在问题的插件。 |
| [^31] | [Non-Clashing Teaching Maps for Balls in Graphs.](http://arxiv.org/abs/2309.02876) | 本文研究了在图中球的概念类中的非冲突教学图，并证明了相关决策问题{\sc B-NCTD$^+$}是NP完全的。 |
| [^32] | [GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields.](http://arxiv.org/abs/2308.16891) | GNFactor是一个用于多任务机器人操作的代理方法，它利用可泛化神经特征场和Perceiver Transformer模块，以及深度三维体素表示来实现对真实世界环境中的操作任务的执行。它通过将视觉和语义信息纳入三维表示来提高场景的理解能力，并在多个任务上进行了验证。 |
| [^33] | [Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes.](http://arxiv.org/abs/2308.11247) | 本文在化学过程的交叉领域故障诊断中，对单源和多源无监督领域适应算法进行了广泛比较。研究结果表明，即使没有进行适应，使用多个领域进行训练也具有积极影响。 |
| [^34] | [Proprioceptive Learning with Soft Polyhedral Networks.](http://arxiv.org/abs/2308.08538) | 本文提出了一种使用软多面体网络的本体感知学习方法，通过学习动力学特性和引入嵌入式视觉，实现了在物理交互中的自适应和粘弹性感觉，可以实时推断6维力和扭矩的作用。 |
| [^35] | [Meta-Learning Operators to Optimality from Multi-Task Non-IID Data.](http://arxiv.org/abs/2308.04428) | 本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。 |
| [^36] | [Optimized Network Architectures for Large Language Model Training with Billions of Parameters.](http://arxiv.org/abs/2307.12169) | 本文提出了一种优化的网络架构，用于训练拥有数十亿参数的大型语言模型。这个架构根据语言模型的通信需求，将集群分割成一组通过非阻塞高带宽互连的GPU集合，并通过轨道连接仅连接具有通信需求的GPU，从而降低网络成本高达75％，同时不影响训练性能。 |
| [^37] | [Robust Fully-Asynchronous Methods for Distributed Training over General Architecture.](http://arxiv.org/abs/2307.11617) | 该论文提出了一种强健的全异步方法（R-FAST），在分布式机器学习中解决了完美同步的低效性和不可能性问题，通过采用鲁棒的梯度跟踪策略和灵活的通信架构，消除了数据异构性和数据包丢失的影响，并实现了期望的邻域收敛。 |
| [^38] | [Instruction Mining: High-Quality Instruction Data Selection for Large Language Models.](http://arxiv.org/abs/2307.06290) | 本文提出了InstructMining，一种用于选择高质量指令数据的线性规则，以增强大语言模型的解释和响应指令能力。通过特定的自然语言指标建模，研究结果表明，即使只有少量高质量的指令跟随数据，语言模型也可以进行良好的微调。 |
| [^39] | [Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding.](http://arxiv.org/abs/2307.05908) | 本论文提出了一种预测性流水线解码（PPD）方法，通过并行启动后续令牌解码来加速大型语言模型（LLMs）中的贪婪解码过程，同时保持完全相同的输出。该方法在减少解码延迟方面具有潜力，提供了新的LLM解码策略权衡理解。 |
| [^40] | [Scaling Laws Do Not Scale.](http://arxiv.org/abs/2307.03201) | 本文讨论了缩放定律与人工智能模型性能之间的关系，并指出数据集规模的增加会引发不同社群的价值观和偏见风险。 |
| [^41] | [GIO: Gradient Information Optimization for Training Dataset Selection.](http://arxiv.org/abs/2306.11670) | GIO是一种可伸缩且任务不可知的方法，通过对目标的简单放松和高效实现，可以在非常小的训练集上产生出色的结果。 |
| [^42] | [How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?.](http://arxiv.org/abs/2306.06048) | 本研究旨在探究微调对少样本下游任务的外分布检测的影响，发现适当选择外分布分数对于CLIP-based 微调至关重要。最大概念匹配（MCM）分数提供了一个有前途的解决方案。 |
| [^43] | [CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification.](http://arxiv.org/abs/2306.04979) | CoCo是一种耦合对比图表示学习框架，其中包含一个图卷积网络和一个分层图内核网络，通过耦合对比学习减少领域差异，用于无监督领域自适应图分类。 |
| [^44] | [SAPI: Surroundings-Aware Vehicle Trajectory Prediction at Intersections.](http://arxiv.org/abs/2306.01812) | 本文提出了一种称为SAPI的深度学习模型，用于在路口预测车辆轨迹，通过实时地图、优先权和周围交通信息来表示和编码周围环境。SAPI能够在预测车辆轨迹时表现出有希望的性能，且优于基准方法。 |
| [^45] | [InstructIE: A Chinese Instruction-based Information Extraction Dataset.](http://arxiv.org/abs/2305.11527) | 介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。 |
| [^46] | [On Consistency of Signatures Using Lasso.](http://arxiv.org/abs/2305.10413) | 本文重新审视了Lasso回归对于签名变换的一致性问题，并发现对于不同的过程和时间序列，选择适当的签名定义和随机模型可以提高Lasso回归的一致性。 |
| [^47] | [Dropout Regularization in Extended Generalized Linear Models based on Double Exponential Families.](http://arxiv.org/abs/2305.06625) | 本论文研究了基于双指数族的扩展广义线性模型中的dropout正则化，dropout正则化偏好罕见但重要的特征，在均值和离散度方面都具有普适性。 |
| [^48] | [ContactArt: Learning 3D Interaction Priors for Category-level Articulated Object and Hand Poses Estimation.](http://arxiv.org/abs/2305.01618) | 本研究提出了一种基于视觉遥操作的数据收集方法以及学习手物互动先验的新方法，从而能够在联结目标和手部姿态估计中实现更好的关键点定位性能。 |
| [^49] | [Exact Characterization of the Convex Hulls of Reachable Sets.](http://arxiv.org/abs/2303.17674) | 本文精确地刻画了具有有界扰动的非线性系统的可达集的凸包为一阶常微分方程的解的凸包，提出了一种低成本、高精度的估计算法，可用于过逼近可达集。 |
| [^50] | [Generalization with quantum geometry for learning unitaries.](http://arxiv.org/abs/2303.13462) | 本文研究了量子机器学习模型的泛化能力，使用数据的量子费舍尔信息度量来评估成功训练和泛化所需的电路参数和训练数据的数量，并展示通过去除对称性来提高泛化能力，同时发现超出分布泛化能力可以比使用相同分布更优。 |
| [^51] | [The ADMM-PINNs Algorithmic Framework for Nonsmooth PDE-Constrained Optimization: A Deep Learning Approach.](http://arxiv.org/abs/2302.08309) | 本论文提出了采用ADMM-PINNs算法框架解决非光滑PDE约束优化问题的方法，在迭代中采用ADMM将PDE约束和非光滑正则化项分离，使得可以高效地解决 PDE-constrained optimization problems。 |
| [^52] | [Hierarchical Policy Blending as Inference for Reactive Robot Control.](http://arxiv.org/abs/2210.07890) | 该论文提出了一种分层运动生成的方法，结合了反应式策略和规划的优点，在多目标决策问题中提供了可行的路径。 |
| [^53] | [Multitask Learning and Bandits via Robust Statistics.](http://arxiv.org/abs/2112.14233) | 本研究探讨了多任务学习以及Bandits方法的健壮统计学实现，提出了一种新颖的两阶段多任务学习估计器，该估计器以一种样本高效的方式利用共享全局参数和稀疏实例特定术语的结构。 |
| [^54] | [Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models.](http://arxiv.org/abs/2112.03860) | 该论文提出了一种使用可微数据相关层进行重新参数化和高斯化潜在张量的方法，以约束逆问题为获得高保真度的分布内解决方案，有效解决深度生成模型逆问题中潜在张量偏离期望高斯分布的问题。 |

# 详细

[^1]: LLM作为写作助手：探讨所有权感和推理的视角

    LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning

    [https://arxiv.org/abs/2404.00027](https://arxiv.org/abs/2404.00027)

    探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。

    

    写作中的所有权感限制了我们对思想、时间和贡献的投入，导致对产出物的依恋。然而，使用写作助手引入了一种心理困境，因为一些内容并非直接我们的创作。我们往往更倾向于在创造性任务中更多地归功于大型语言模型（LLMs），尽管它们对所有任务都是平等的。此外，虽然我们可能不会完全声称对由LLM生成的内容拥有所有权，但却自由地声称作者身份。我们进行了一项简短调查来研究这些问题，并了解潜在的认知过程，以更好地了解人机交互在写作中的应用并改进写作辅助系统。

    arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
    
[^2]: 墨水与个性：在LLMs时代塑造个性化叙事

    Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs

    [https://arxiv.org/abs/2404.00026](https://arxiv.org/abs/2404.00026)

    研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。

    

    个性和个性化构成了使每个作家独特并影响其文字以有效吸引读者同时传达真实性的独特特征。然而，我们日益依赖基于LLM的写作助手可能会危及我们的创造力和个性。我们经常忽视这一趋势对我们的创造力和独特性的负面影响，尽管可能会造成后果。本研究通过进行简要调查探索不同的观点和概念，以及尝试理解人们的观点，结合以往在该领域的研究，来研究这些问题。解决这些问题对于改进人机交互系统和增强个性化和个性化写作助手至关重要。

    arXiv:2404.00026v1 Announce Type: cross  Abstract: Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality.
    
[^3]: 预训练语言条件模仿学习策略的不确定性感知部署

    Uncertainty-Aware Deployment of Pre-trained Language-Conditioned Imitation Learning Policies

    [https://arxiv.org/abs/2403.18222](https://arxiv.org/abs/2403.18222)

    提出一种不确定性感知的预训练语言条件模仿学习代理的部署方法，通过温度缩放和本地信息聚合做出不确定性感知决策，显著提升任务完成率。

    

    大规模机器人策略在来自不同任务和机器人平台的数据上训练，为实现通用机器人带来很大希望；然而，可靠地泛化到新的环境条件仍然是一个主要挑战。为解决这一挑战，我们提出了一种新颖的方法，用于不确定性感知的预训练语言条件模仿学习代理的部署。具体来说，我们使用温度缩放来校准这些模型，并利用校准的模型通过聚合候选动作的本地信息来做出不确定性感知决策。我们在仿真环境中使用三个这样的预训练模型来实现我们的方法，并展示其潜力显著提升任务完成率。附带的代码可以在以下链接找到：https://github.com/BobWu1998/uncertainty_quant_all.git

    arXiv:2403.18222v1 Announce Type: cross  Abstract: Large-scale robotic policies trained on data from diverse tasks and robotic platforms hold great promise for enabling general-purpose robots; however, reliable generalization to new environment conditions remains a major challenge. Toward addressing this challenge, we propose a novel approach for uncertainty-aware deployment of pre-trained language-conditioned imitation learning agents. Specifically, we use temperature scaling to calibrate these models and exploit the calibrated model to make uncertainty-aware decisions by aggregating the local information of candidate actions. We implement our approach in simulation using three such pre-trained models, and showcase its potential to significantly enhance task completion rates. The accompanying code is accessible at the link: https://github.com/BobWu1998/uncertainty_quant_all.git
    
[^4]: 水斯坦视角下的普通 GANs

    A Wasserstein perspective of Vanilla GANs

    [https://arxiv.org/abs/2403.15312](https://arxiv.org/abs/2403.15312)

    将普通GANs与水斯坦距离联系起来，扩展现有水斯坦GANs结果到普通GANs，获得了普通GANs的神谕不等式。

    

    生成对抗网络(GANs)的实证成功引起了对理论研究日益增长的兴趣。统计文献主要集中在水斯坦GANs及其扩展上，特别是允许具有良好的降维特性。对于普通GANs，即原始优化问题，统计结果仍然相当有限，需要假设平滑激活函数和潜空间与周围空间的维度相等。为了弥合这一差距，我们将普通GANs与水斯坦距离联系起来。通过这样做，现有的水斯坦GANs结果可以扩展到普通GANs。特别是，在水斯坦距离中获得了普通GANs的神谕不等式。这个神谕不等式的假设旨在由实践中常用的网络架构满足，如前馈ReLU网络。

    arXiv:2403.15312v1 Announce Type: cross  Abstract: The empirical success of Generative Adversarial Networks (GANs) caused an increasing interest in theoretical research. The statistical literature is mainly focused on Wasserstein GANs and generalizations thereof, which especially allow for good dimension reduction properties. Statistical results for Vanilla GANs, the original optimization problem, are still rather limited and require assumptions such as smooth activation functions and equal dimensions of the latent space and the ambient space. To bridge this gap, we draw a connection from Vanilla GANs to the Wasserstein distance. By doing so, existing results for Wasserstein GANs can be extended to Vanilla GANs. In particular, we obtain an oracle inequality for Vanilla GANs in Wasserstein distance. The assumptions of this oracle inequality are designed to be satisfied by network architectures commonly used in practice, such as feedforward ReLU networks. By providing a quantitative resu
    
[^5]: 使用BART从推文中提取情绪短语

    Extracting Emotion Phrases from Tweets using BART

    [https://arxiv.org/abs/2403.14050](https://arxiv.org/abs/2403.14050)

    本文提出了一种基于BART的情感分析方法，利用问答框架从文本中提取特定情绪短语，并通过分类器预测答案跨度位置，实现对情绪短语的精确提取。

    

    情感分析是一项旨在识别和提取文本中情绪方面的自然语言处理任务。然而，许多现有的情感分析方法主要是对文本的整体极性进行分类，忽略了传达情绪的具体短语。在本文中，我们应用了一种基于问答框架的情感分析方法。我们利用双向自回归变换器（BART），一个预训练的序列到序列模型，从给定文本中提取放大给定情感极性的短语。我们创建一个自然语言问题，确定要提取的特定情绪，然后引导BART专注于文本中相关的情感线索。我们在BART中使用一个分类器来预测文本中答案跨度的开始和结束位置，从而帮助确定提取的情绪短语的精确边界。

    arXiv:2403.14050v2 Announce Type: replace  Abstract: Sentiment analysis is a natural language processing task that aims to identify and extract the emotional aspects of a text. However, many existing sentiment analysis methods primarily classify the overall polarity of a text, overlooking the specific phrases that convey sentiment. In this paper, we applied an approach to sentiment analysis based on a question-answering framework. Our approach leverages the power of Bidirectional Autoregressive Transformer (BART), a pre-trained sequence-to-sequence model, to extract a phrase from a given text that amplifies a given sentiment polarity. We create a natural language question that identifies the specific emotion to extract and then guide BART to pay attention to the relevant emotional cues in the text. We use a classifier within BART to predict the start and end positions of the answer span within the text, which helps to identify the precise boundaries of the extracted emotion phrase. Our
    
[^6]: SportsNGEN: 持续生成多人体育游戏

    SportsNGEN: Sustained Generation of Multi-player Sports Gameplay

    [https://arxiv.org/abs/2403.12977](https://arxiv.org/abs/2403.12977)

    SportsNGEN是一种基于Transformer解码器的模型，经过训练能持续生成逼真的多人体育游戏，包括模拟整个网球比赛和为教练和广播员提供洞察力的能力。

    

    我们提出了一种基于Transformer解码器的模型SportsNGEN，该模型经过训练使用运动员和球追踪序列，能够生成逼真且持续的游戏场景。我们在大量专业网球追踪数据上训练和评估SportsNGEN，并展示通过将生成的模拟与射击分类器和逻辑相结合来开始和结束球赛，系统能够模拟整个网球比赛。此外，SportsNGEN的通用版本可以通过在包含该球员的比赛数据上微调来定制特定球员。我们展示了我们的模型经过良好校准，可以通过评估反事实或假设选项为教练和广播员提供洞察力。最后，我们展示了质量结果表明相同的方法适用于足球。

    arXiv:2403.12977v1 Announce Type: cross  Abstract: We present a transformer decoder based model, SportsNGEN, that is trained on sports player and ball tracking sequences that is capable of generating realistic and sustained gameplay. We train and evaluate SportsNGEN on a large database of professional tennis tracking data and demonstrate that by combining the generated simulations with a shot classifier and logic to start and end rallies, the system is capable of simulating an entire tennis match. In addition, a generic version of SportsNGEN can be customized to a specific player by fine-tuning on match data that includes that player. We show that our model is well calibrated and can be used to derive insights for coaches and broadcasters by evaluating counterfactual or what if options. Finally, we show qualitative results indicating the same approach works for football.
    
[^7]: 嵌套神经特征场的层次场景理解

    N2F2: Hierarchical Scene Understanding with Nested Neural Feature Fields

    [https://arxiv.org/abs/2403.10997](https://arxiv.org/abs/2403.10997)

    利用Nested Neural Feature Fields (N2F2) 实现了层次化监督学习，提供了对物理维度或语义维度等不同粒度的场景属性全面和细致的理解。

    

    在计算机视觉中，理解多层抽象的复杂场景仍然是一个巨大挑战。为了解决这个问题，我们引入了嵌套神经特征场 (N2F2)，这是一种新颖的方法，利用分层监督来学习单个特征场，在同一高维特征中的不同维度编码不同粒度的场景属性。我们的方法允许灵活定义层次，可以根据物理维度、语义维度或两者均匹配，从而实现对场景的全面和细致理解。我们利用2D类别无关分割模型在图像空间的任意尺度提供语义有意义的像素分组，并查询CLIP视觉编码器，为这些段落中的每个部分获得与语言对齐的嵌入。我们提出的分层监督方法将不同的嵌套特征场维度分配给提取C

    arXiv:2403.10997v1 Announce Type: cross  Abstract: Understanding complex scenes at multiple levels of abstraction remains a formidable challenge in computer vision. To address this, we introduce Nested Neural Feature Fields (N2F2), a novel approach that employs hierarchical supervision to learn a single feature field, wherein different dimensions within the same high-dimensional feature encode scene properties at varying granularities. Our method allows for a flexible definition of hierarchies, tailored to either the physical dimensions or semantics or both, thereby enabling a comprehensive and nuanced understanding of scenes. We leverage a 2D class-agnostic segmentation model to provide semantically meaningful pixel groupings at arbitrary scales in the image space, and query the CLIP vision-encoder to obtain language-aligned embeddings for each of these segments. Our proposed hierarchical supervision method then assigns different nested dimensions of the feature field to distill the C
    
[^8]: 朝向公平的图异常检测：问题、新数据集和评估

    Towards Fair Graph Anomaly Detection: Problem, New Datasets, and Evaluation

    [https://arxiv.org/abs/2402.15988](https://arxiv.org/abs/2402.15988)

    这项研究提出了公平图异常检测（FairGAD）问题，介绍了来自Reddit和Twitter的两个新图数据集，填补了当前文献在此问题上的空白。

    

    公平图异常检测（FairGAD）问题旨在在输入图中准确检测异常节点，同时确保公平性，避免针对来自敏感亚组如性别或政治倾向的个体的偏见预测。图中的公平性在异常检测领域尤为关键，比如在搜索/排名系统中进行的误信息检测，决策结果可能会极大地影响个人。然而，当前文献没有全面讨论这个问题，也没有提供贴近实际图结构、异常标签和敏感属性的数据集，以用于FairGAD研究。为弥补这一不足，我们介绍了FairGAD问题的正式定义，并提出了两个新颖的图数据集，这些数据集来自于全球知名社交媒体平台Reddit和Twitter。

    arXiv:2402.15988v1 Announce Type: cross  Abstract: The Fair Graph Anomaly Detection (FairGAD) problem aims to accurately detect anomalous nodes in an input graph while ensuring fairness and avoiding biased predictions against individuals from sensitive subgroups such as gender or political leanings. Fairness in graphs is particularly crucial in anomaly detection areas such as misinformation detection in search/ranking systems, where decision outcomes can significantly affect individuals. However, the current literature does not comprehensively discuss this problem, nor does it provide realistic datasets that encompass actual graph structures, anomaly labels, and sensitive attributes for research in FairGAD. To bridge this gap, we introduce a formal definition of the FairGAD problem and present two novel graph datasets constructed from the globally prominent social media platforms Reddit and Twitter. These datasets comprise 1.2 million and 400,000 edges associated with 9,000 and 47,000 
    
[^9]: 分布式滤波电路的自动设计与优化通过强化学习

    Automated Design and Optimization of Distributed Filtering Circuits via Reinforcement Learning

    [https://arxiv.org/abs/2402.14236](https://arxiv.org/abs/2402.14236)

    提出一种通过强化学习算法实现的自动化设计方法，显著提高了分布式滤波电路设计的效率和质量。

    

    设计分布式滤波电路(DFC)复杂且耗时，电路性能严重依赖电子工程师的专业知识和经验。然而，手动设计方法效率低下。本研究提出一种新的端到端自动化方法，利用强化学习算法来改进DFC的设计。所提出的方法消除了对工程师设计经验的依赖，显著降低了与电路设计相关的主观性和约束。实验结果表明，在与传统的工程师驱动方法进行比较时，所提出的方法在设计效率和质量上都有明显改善。特别是，在设计复杂或快速发展的DFC时，所提出的方法表现出卓越的性能。

    arXiv:2402.14236v1 Announce Type: cross  Abstract: Designing distributed filtering circuits (DFCs) is complex and time-consuming, with the circuit performance relying heavily on the expertise and experience of electronics engineers. However, manual design methods tend to have exceedingly low-efficiency. This study proposes a novel end-to-end automated method for fabricating circuits to improve the design of DFCs. The proposed method harnesses reinforcement learning (RL) algorithms, eliminating the dependence on the design experience of engineers. Thus, it significantly reduces the subjectivity and constraints associated with circuit design. The experimental findings demonstrate clear improvements in both design efficiency and quality when comparing the proposed method with traditional engineer-driven methods. In particular, the proposed method achieves superior performance when designing complex or rapidly evolving DFCs. Furthermore, compared to existing circuit automation design techn
    
[^10]: 在协作机器学习中稳健性和学习的冲突

    On the Conflict of Robustness and Learning in Collaborative Machine Learning

    [https://arxiv.org/abs/2402.13700](https://arxiv.org/abs/2402.13700)

    在协作机器学习中，研究人员正式规范了稳健聚合器的领域，并发现现有的稳健聚合器无法实现其目标，要么无法准确识别有针对性的恶意更新，要么方法成功率不够。

    

    协作机器学习（CML）允许参与者共同训练机器学习模型，同时保持他们的训练数据私密。在隐私是一个强烈要求的情况下，比如健康相关应用中，安全也是首要关注的问题。这意味着保护隐私的CML流程必须产生能够输出正确可靠决策的模型，甚至在可能不受信任参与者的情况下也是如此。为了解决这个问题，研究人员提出使用依赖于帮助过滤可能危及训练过程的恶意贡献的度量的“稳健聚合器”。在这项工作中，我们在文献中规范化了稳健聚合器的进展。我们的规范化能够表明现有的稳健聚合器无法实现其目标：无论是它们使用无法准确识别有针对性的恶意更新的基于距离的度量；还是提出的方法成功率不够。

    arXiv:2402.13700v1 Announce Type: new  Abstract: Collaborative Machine Learning (CML) allows participants to jointly train a machine learning model while keeping their training data private. In scenarios where privacy is a strong requirement, such as health-related applications, safety is also a primary concern. This means that privacy-preserving CML processes must produce models that output correct and reliable decisions \emph{even in the presence of potentially untrusted participants}. In response to this issue, researchers propose to use \textit{robust aggregators} that rely on metrics which help filter out malicious contributions that could compromise the training process. In this work, we formalize the landscape of robust aggregators in the literature. Our formalization allows us to show that existing robust aggregators cannot fulfill their goal: either they use distance-based metrics that cannot accurately identify targeted malicious updates; or propose methods whose success is i
    
[^11]: 通过扩散模型生成的假设的统计检验

    Statistical Test for Generated Hypotheses by Diffusion Models

    [https://arxiv.org/abs/2402.11789](https://arxiv.org/abs/2402.11789)

    本研究提出了一种统计检验方法，通过选择性推断框架，在考虑生成图像是由训练的扩散模型产生的条件下，量化医学图像诊断结果的可靠性。

    

    AI的增强性能加速了其融入科学研究。特别是，利用生成式AI创建科学假设是很有前途的，并且正在越来越多地应用于各个领域。然而，当使用AI生成的假设进行关键决策（如医学诊断）时，验证它们的可靠性至关重要。在本研究中，我们考虑使用扩散模型生成的图像进行医学诊断任务，并提出了一种统计检验来量化其可靠性。所提出的统计检验的基本思想是使用选择性推断框架，我们考虑在生成的图像是由经过训练的扩散模型产生的这一事实条件下的统计检验。利用所提出的方法，医学图像诊断结果的统计可靠性可以以p值的形式量化，从而实现在控制错误率的情况下进行决策。

    arXiv:2402.11789v1 Announce Type: cross  Abstract: The enhanced performance of AI has accelerated its integration into scientific research. In particular, the use of generative AI to create scientific hypotheses is promising and is increasingly being applied across various fields. However, when employing AI-generated hypotheses for critical decisions, such as medical diagnoses, verifying their reliability is crucial. In this study, we consider a medical diagnostic task using generated images by diffusion models, and propose a statistical test to quantify its reliability. The basic idea behind the proposed statistical test is to employ a selective inference framework, where we consider a statistical test conditional on the fact that the generated images are produced by a trained diffusion model. Using the proposed method, the statistical reliability of medical image diagnostic results can be quantified in the form of a p-value, allowing for decision-making with a controlled error rate. 
    
[^12]: 采用最优输运和粒子梯度下降的保护隐私数据发布方法

    Privacy-preserving data release leveraging optimal transport and particle gradient descent

    [https://arxiv.org/abs/2401.17823](https://arxiv.org/abs/2401.17823)

    该研究提出了一种基于边际的保护隐私数据合成方法PrivPGD，利用了最优输运和粒子梯度下降的工具。该方法在不同领域的数据集上表现出色，具有高度的可扩展性和灵活性，并可以满足特定的领域约束条件。

    

    我们提出了一种新颖的方法，用于保护关键领域（如医疗保健和政府）中隐私的表格数据差分私有数据合成的任务。目前的最先进方法主要使用基于边际的方法，从私有边际估计生成数据集。在本文中，我们引入了PrivPGD，一种基于边际的私有数据合成的新一代方法，利用了最优输运和粒子梯度下降的工具。我们的算法在大范围数据集上优于现有方法，并具有高度可扩展性和灵活性，可以结合其他领域特定的约束条件。

    We present a novel approach for differentially private data synthesis of protected tabular datasets, a relevant task in highly sensitive domains such as healthcare and government. Current state-of-the-art methods predominantly use marginal-based approaches, where a dataset is generated from private estimates of the marginals. In this paper, we introduce PrivPGD, a new generation method for marginal-based private data synthesis, leveraging tools from optimal transport and particle gradient descent. Our algorithm outperforms existing methods on a large range of datasets while being highly scalable and offering the flexibility to incorporate additional domain-specific constraints.
    
[^13]: 加权集成模型是强大的持续学习者

    Weighted Ensemble Models Are Strong Continual Learners

    [https://arxiv.org/abs/2312.08977](https://arxiv.org/abs/2312.08977)

    通过加权集成模型实现了高准确性的持续学习，兼顾可塑性和稳定性。

    

    在本文中，我们研究持续学习（CL）的问题，其中目标是从一系列任务中学习模型，使得以前任务的数据在学习当前任务数据时不可用。CL本质上是在能够学习新任务（即可塑性）和保持先前学习概念的性能（即稳定性）之间取得平衡的过程。为了解决稳定性-可塑性的权衡问题，我们建议对先前和当前任务的模型参数进行加权集成。这种加权集成模型，我们称之为持续模型平均（或CoMA），通过利用可塑性在当前任务上获得高准确性，同时不会偏离太远的先前权重配置，从而确保稳定性。我们还提出了CoMA的改进型变体，名为持续费舍尔加权模型平均（或CoFiMA），该模型对每一个参数进行选择性加权。

    arXiv:2312.08977v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of continual learning (CL) where the goal is to learn a model on a sequence of tasks, such that the data from the previous tasks becomes unavailable while learning on the current task data. CL is essentially a balancing act between being able to learn on the new task (i.e., plasticity) and maintaining the performance on the previously learned concepts (i.e., stability). Intending to address the stability-plasticity trade-off, we propose to perform weight-ensembling of the model parameters of the previous and current tasks. This weighted-ensembled model, which we call Continual Model Averaging (or CoMA), attains high accuracy on the current task by leveraging plasticity, while not deviating too far from the previous weight configuration, ensuring stability. We also propose an improved variant of CoMA, named Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively weighs each para
    
[^14]: (深)线性神经网络中的权重波动和逆方差平直关系的推导

    Weight fluctuations in (deep) linear neural networks and a derivation of the inverse-variance flatness relation

    [https://arxiv.org/abs/2311.14120](https://arxiv.org/abs/2311.14120)

    该研究探讨了单层和双层线性神经网络在随机梯度下降中的稳定训练规则，并发现了权重波动在各种情况下的各向异性特征，其中双层网络中的权重波动受到层间耦合的影响，并呈现出各向异性损失。

    

    我们在合成高斯数据的随机梯度下降（SGD）的连续极限内，研究了单层和双层线性欠参数化神经网络的稳定（末态）训练规则。对于 schwach欠参数化区域中的单层网络，噪声协方差矩阵的谱明显偏离Hessian，可以归因于SGD动态的破坏详细平衡。在这种情况下，权重波动通常是各向异性的，但受各向同性损失限制。对于双层网络，我们获得了每层权重的随机动力学，并分析了相关的稳定协方差。我们确定了层间耦合作为权重波动的各向异性的新来源。与单层情况相反，权重波动经历各向异性损失，其平直度与波动的方差成反比。

    arXiv:2311.14120v2 Announce Type: replace  Abstract: We investigate the stationary (late-time) training regime of single- and two-layer linear underparameterized neural networks within the continuum limit of stochastic gradient descent (SGD) for synthetic Gaussian data. In the case of a single-layer network in the weakly underparameterized regime, the spectrum of the noise covariance matrix deviates notably from the Hessian, which can be attributed to the broken detailed balance of SGD dynamics. The weight fluctuations are in this case generally anisotropic, but are subject to an isotropic loss. For a two-layer network, we obtain the stochastic dynamics of the weights in each layer and analyze the associated stationary covariances. We identify the inter-layer coupling as a new source of anisotropy for the weight fluctuations. In contrast to the single-layer case, the weight fluctuations experience an anisotropic loss, the flatness of which is inversely related to the fluctuation varian
    
[^15]: 通过采用整数列表作为多项式基数2指数的集合来实现快速乘法

    Fast multiplication by two's complement addition of numbers represented as a set of polynomial radix 2 indexes, stored as an integer list for massively parallel computation

    [https://arxiv.org/abs/2311.09922](https://arxiv.org/abs/2311.09922)

    本论文介绍了一种基于多项式基数2指数集合的快速乘法方法，在特定位数范围内比传统方法更快。该方法把数字表示为整数索引列表，并实现了分布式计算。

    

    我们演示了一种基于用整数列表表示的多项式基数2指数集合的乘法方法。该方法采用python代码实现了一组算法。我们展示了该方法在某一位数范围内比数论变换(NTT)和卡拉茨巴(Karatsuba)乘法更快。我们还实现了用python代码进行比较，与多项式基数2整数方法进行比较。我们展示了任何整数或实数都可以表示为整数索引列表，表示二进制中的有限级数。该数字的整数索引有限级数可以存储和分布在多个CPU / GPU上。我们展示了加法和乘法运算可以应用于作为索引整数表示的两个补码加法，并可以完全分布在给定的CPU / GPU架构上。我们展示了完全的分布性能。

    We demonstrate a multiplication method based on numbers represented as set of polynomial radix 2 indices stored as an integer list. The 'polynomial integer index multiplication' method is a set of algorithms implemented in python code. We demonstrate the method to be faster than both the Number Theoretic Transform (NTT) and Karatsuba for multiplication within a certain bit range. Also implemented in python code for comparison purposes with the polynomial radix 2 integer method. We demonstrate that it is possible to express any integer or real number as a list of integer indices, representing a finite series in base two. The finite series of integer index representation of a number can then be stored and distributed across multiple CPUs / GPUs. We show that operations of addition and multiplication can be applied as two's complement additions operating on the index integer representations and can be fully distributed across a given CPU / GPU architecture. We demonstrate fully distribute
    
[^16]: 在均场博弈中的学习：一项调查

    Learning in Mean Field Games: A Survey

    [https://arxiv.org/abs/2205.12944](https://arxiv.org/abs/2205.12944)

    强化学习和均场博弈的结合有望在很大规模上解决游戏的均衡和社会最优问题。

    

    非合作和合作游戏在拥有大量玩家时有许多应用，但随着玩家数量的增加，通常变得难以解决。均场博弈(Mean Field Games, MFGs)由Lasry和Lions以及Huang，Caines和Malham\'e引入，依靠均场近似允许玩家数量增长到无穷大。传统解决这些游戏的方法通常依赖于解决带有对模型的完全了解的偏微分方程或随机微分方程。最近，强化学习(Reinforcement Learning, RL)出现在解决规模复杂问题上表现出了很大的潜力。RL和MFGs的结合有望解决在人口规模和环境复杂性方面非常庞大的游戏。在这项调查中，我们回顾了最近迅速增长的关于RL方法在MFGs中学习均衡和社交最优的文献。我们首先确定了M中最常见的设置(静态、稳态和进化的)。

    arXiv:2205.12944v3 Announce Type: replace-cross  Abstract: Non-cooperative and cooperative games with a very large number of players have many applications but remain generally intractable when the number of players increases. Introduced by Lasry and Lions, and Huang, Caines and Malham\'e, Mean Field Games (MFGs) rely on a mean-field approximation to allow the number of players to grow to infinity. Traditional methods for solving these games generally rely on solving partial or stochastic differential equations with a full knowledge of the model. Recently, Reinforcement Learning (RL) has appeared promising to solve complex problems at scale. The combination of RL and MFGs is promising to solve games at a very large scale both in terms of population size and environment complexity. In this survey, we review the quickly growing recent literature on RL methods to learn equilibria and social optima in MFGs. We first identify the most common settings (static, stationary, and evolutive) of M
    
[^17]: 基于混合Tries的内存高效序列模式挖掘

    Memory-Efficient Sequential Pattern Mining with Hybrid Tries

    [https://arxiv.org/abs/2202.06834](https://arxiv.org/abs/2202.06834)

    提出了一种基于混合trie的内存高效序列模式挖掘方法，在内存消耗和计算时间方面相比现有技术有显著改善，且是唯一一个能够处理256GB系统内存下大数据集的方法。

    

    随着现代数据集的指数级增长，对于能够处理如此庞大数据集的高效挖掘算法的需求变得日益迫切。本文提出了一种内存高效的方法用于序列模式挖掘（SPM），这是知识发现中的一个基本主题，面临着针对大数据集的已知内存瓶颈。我们的方法涉及一种新颖的混合trie数据结构，利用重复模式紧凑地存储内存中的数据集; 以及一个相应的挖掘算法，旨在有效地从此紧凑表示中提取模式。对真实测试实例的数值结果显示，与最先进技术相比，对于小到中等大小的数据集，内存消耗平均提高了88％，计算时间提高了41％。此外，我们的算法是唯一一个在系统内存为256GB的情况下能够处理大数据集的SPM方法。

    arXiv:2202.06834v2 Announce Type: replace-cross  Abstract: As modern data sets continue to grow exponentially in size, the demand for efficient mining algorithms capable of handling such large data sets becomes increasingly imperative. This paper develops a memory-efficient approach for Sequential Pattern Mining (SPM), a fundamental topic in knowledge discovery that faces a well-known memory bottleneck for large data sets. Our methodology involves a novel hybrid trie data structure that exploits recurring patterns to compactly store the data set in memory; and a corresponding mining algorithm designed to effectively extract patterns from this compact representation. Numerical results on real-life test instances show an average improvement of 88% in memory consumption and 41% in computation time for small to medium-sized data sets compared to the state of the art. Furthermore, our algorithm stands out as the only capable SPM approach for large data sets within 256GB of system memory.
    
[^18]: 优化大规模语言模型用于漏洞检测

    Finetuning Large Language Models for Vulnerability Detection. (arXiv:2401.17010v1 [cs.CR])

    [http://arxiv.org/abs/2401.17010](http://arxiv.org/abs/2401.17010)

    本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。

    

    本文介绍了对大规模语言模型进行微调，并将其用于源代码中的漏洞检测的结果。我们利用最先进的语言模型StarCoder的改进版本WizardCoder，并通过进一步微调将其适应于漏洞检测任务。为了加速训练，我们修改了WizardCoder的训练过程，并探究了最佳的训练策略。针对负样本远多于正样本的不平衡数据集，我们还尝试了不同的技术来提高分类性能。微调后的WizardCoder模型在平衡和不平衡的漏洞数据集上在ROC AUC和F1度量上实现了改进，证明了将预训练的语言模型用于源代码中的漏洞检测的有效性。主要贡献包括对最先进的代码语言模型WizardCoder进行微调，提高其训练速度而不影响性能，并对训练过程和策略进行了优化。

    This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, 
    
[^19]: 以质量守恒感知器为基础，实现可解释的物理-概念集水区尺度水文建模

    Towards Interpretable Physical-Conceptual Catchment-Scale Hydrological Modeling using the Mass-Conserving-Perceptron. (arXiv:2401.14521v1 [cs.LG])

    [http://arxiv.org/abs/2401.14521](http://arxiv.org/abs/2401.14521)

    本研究通过利用质量守恒感知器构建基于有向图结构的水文模型，实现了对集水区尺度水文过程的解释能力，在保持简洁性的同时能够准确地模拟各种流量动力学行为，并通过引入输入旁路机制进一步优化了模型的表现。

    

    本研究探讨了利用机器学习技术开发简洁可解释的集水区尺度水文模型的可行性，采用基于质量守恒感知器（MCP）的有向图结构作为基本计算单元。我们关注的是单个位置的结构复杂性（深度），而不是对大样本集水区具有普适性的广度。目标是发现一个最小的表示（单元状态数和流量路径数），用于表示能够解释给定集水区输入状态和输出行为的主要过程，特别强调模拟全范围（高、中、低）的流量动力学。我们发现，在我们的研究区域，采用类似HyMod的架构，具有3个单元状态和2个主要流动路径，能够实现这样的表示，但引入输入旁路机制可以显著改善水文图的时间和形状。

    We investigate the applicability of machine learning technologies to the development of parsimonious, interpretable, catchment-scale hydrologic models using directed-graph architectures based on the mass-conserving perceptron (MCP) as the fundamental computational unit. Here, we focus on architectural complexity (depth) at a single location, rather than universal applicability (breadth) across large samples of catchments. The goal is to discover a minimal representation (numbers of cell-states and flow paths) that represents the dominant processes that can explain the input-state-output behaviors of a given catchment, with particular emphasis given to simulating the full range (high, medium, and low) of flow dynamics. We find that a HyMod-like architecture with three cell-states and two major flow pathways achieves such a representation at our study location, but that the additional incorporation of an input-bypass mechanism significantly improves the timing and shape of the hydrograph
    
[^20]: 数据归因对扩散模型的影响：时间步引起的对影响估计的偏差

    Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation. (arXiv:2401.09031v1 [cs.LG])

    [http://arxiv.org/abs/2401.09031](http://arxiv.org/abs/2401.09031)

    本文研究了数据归因方法对扩散模型的影响，发现对于在引发大范数时间步骤上训练的样本，其损失梯度范数高度依赖于时间步骤，导致在影响估计中存在显著的偏差。为了解决这个问题，提出了Diffusion-ReTr方法。

    

    数据归因方法可以将模型行为追溯到其训练数据集，为理解“黑箱”神经网络提供了一种有效的方法。虽然先前的研究已经在各种情况下建立了模型输出与训练数据之间的可量化联系，但在与训练样本相关的扩散模型输出的解释方面仍然未被充分探索。特别是，扩散模型通过一系列时间步骤而不是之前的瞬时输入输出关系操作，对直接将现有框架扩展到扩散模型构成了重大挑战。值得注意的是，我们提出了Diffusion-TracIn，它包含了这种时间动力学，并观察到样本的损失梯度范数高度依赖于时间步骤。这种趋势导致影响估计中存在显著的偏差，对于在引发大范数时间步骤上训练的样本尤为明显，导致它们通常具有影响力。为了减轻这种影响，我们引入了Diffusion-ReTr方法。

    Data attribution methods trace model behavior back to its training dataset, offering an effective approach to better understand ``black-box'' neural networks. While prior research has established quantifiable links between model output and training data in diverse settings, interpreting diffusion model outputs in relation to training samples remains underexplored. In particular, diffusion models operate over a sequence of timesteps instead of instantaneous input-output relationships in previous contexts, posing a significant challenge to extend existing frameworks to diffusion models directly. Notably, we present Diffusion-TracIn that incorporates this temporal dynamics and observe that samples' loss gradient norms are highly dependent on timestep. This trend leads to a prominent bias in influence estimation, and is particularly noticeable for samples trained on large-norm-inducing timesteps, causing them to be generally influential. To mitigate this effect, we introduce Diffusion-ReTr
    
[^21]: 动态尖峰图神经网络

    Dynamic Spiking Graph Neural Networks. (arXiv:2401.05373v1 [cs.NE])

    [http://arxiv.org/abs/2401.05373](http://arxiv.org/abs/2401.05373)

    本文提出了一个名为"动态尖峰图神经网络"（DSGNN）的框架，它将尖峰神经网络（SNNs）与图神经网络（GNNs）结合起来，以解决动态图表示学习中的复杂性和内存开销问题。DSGNN通过动态调整尖峰神经元的状态和连接权重，在传播过程中保持图结构信息的完整性。

    

    将尖峰神经网络（SNNs）和图神经网络（GNNs）相结合渐渐引起了人们的关注，这是因为它在处理由图表示的非欧几里得数据时具有低功耗和高效率。然而，作为一个常见的问题，动态图表示学习面临着高复杂性和大内存开销的挑战。目前的工作通常通过使用二进制特征而不是连续特征的SNNs来替代循环神经网络（RNNs）进行高效训练，这会忽视图结构信息并在传播过程中导致细节的丢失。此外，优化动态尖峰模型通常需要在时间步之间传播信息，这增加了内存需求。为了解决这些挑战，我们提出了一个名为"动态尖峰图神经网络"（\method{}）的框架。为了减轻信息丢失问题，\method{} 在传播过程中引入了一种新的机制，它在每个时间步骤中动态地调整尖峰神经元的状态和连接权重，以保持图结构信息的完整性。

    The integration of Spiking Neural Networks (SNNs) and Graph Neural Networks (GNNs) is gradually attracting attention due to the low power consumption and high efficiency in processing the non-Euclidean data represented by graphs. However, as a common problem, dynamic graph representation learning faces challenges such as high complexity and large memory overheads. Current work often uses SNNs instead of Recurrent Neural Networks (RNNs) by using binary features instead of continuous ones for efficient training, which would overlooks graph structure information and leads to the loss of details during propagation. Additionally, optimizing dynamic spiking models typically requires propagation of information across time steps, which increases memory requirements. To address these challenges, we present a framework named \underline{Dy}namic \underline{S}p\underline{i}king \underline{G}raph \underline{N}eural Networks (\method{}). To mitigate the information loss problem, \method{} propagates
    
[^22]: 《关于Transformer过度平滑的真相》

    Setting the Record Straight on Transformer Oversmoothing. (arXiv:2401.04301v1 [cs.LG])

    [http://arxiv.org/abs/2401.04301](http://arxiv.org/abs/2401.04301)

    Transformers are not inherently low-pass filters as previously thought and whether they oversmooth or not depends on the eigenspectrum of their update equations. Based on the analysis, a simple way to parameterize the weights of the Transformer update equations is derived, allowing for control over its spectrum and preventing oversmoothing.

    

    最近，基于Transformer的模型在各个领域取得了巨大成功。与此同时，最新的研究表明，Transformer本质上是一种低通滤波器，会逐渐过度平滑输入数据，降低其表示能力。一个自然的问题是：在存在这个缺陷的情况下，Transformer是如何取得这些成功的？在这项研究中，我们展示了事实上Transformer并不本质上是一种低通滤波器。相反，Transformer是否过度平滑取决于其更新方程的特征谱。我们的分析扩展了之前关于过度平滑和相关现象的研究。我们表明，许多成功的Transformer模型具有满足避免过度平滑条件的注意力和权重。基于这个分析，我们提出了一种简单的方法，对Transformer更新方程的权重进行参数化，使其可以控制其谱特性，确保不会发生过度平滑。与传统的方法相比，我们的方法可以更好地控制过度平滑问题。

    Transformer-based models have recently become wildly successful across a diverse set of domains. At the same time, recent work has shown that Transformers are inherently low-pass filters that gradually oversmooth the inputs, reducing the expressivity of their representations. A natural question is: How can Transformers achieve these successes given this shortcoming? In this work we show that in fact Transformers are not inherently low-pass filters. Instead, whether Transformers oversmooth or not depends on the eigenspectrum of their update equations. Our analysis extends prior work in oversmoothing and in the closely-related phenomenon of rank collapse. We show that many successful Transformer models have attention and weights which satisfy conditions that avoid oversmoothing. Based on this analysis, we derive a simple way to parameterize the weights of the Transformer update equations that allows for control over its spectrum, ensuring that oversmoothing does not occur. Compared to a 
    
[^23]: Deep-ELA: 使用自监督预训练的变换器进行单目标和多目标连续优化问题的深度探索性景观分析

    Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems. (arXiv:2401.01192v1 [cs.LG])

    [http://arxiv.org/abs/2401.01192](http://arxiv.org/abs/2401.01192)

    本文提出了Deep-ELA方法，通过使用自监督预训练的变换器，对单目标和多目标连续优化问题进行深度探索性景观分析，解决了传统ELA特征存在的强相关性和在多目标优化问题中的局限性问题。

    

    在许多最近的研究中，探索性景观分析（ELA）特征的潜力已经被证明可以对特定的单目标连续优化问题进行数值表征。这些数值特征为连续优化问题的各种机器学习任务提供输入，包括高级属性预测、自动算法选择和自动算法配置等。没有ELA特征，分析和理解单目标连续优化问题的特性将是不可能的。然而，尽管它们的实用性无可争议，ELA特征仍然存在一些缺点。其中包括（1.）多个特征之间的强相关性，以及（2.）其在多目标连续优化问题中的适用性非常有限。为解决这个问题，最近的研究提出了以深度学习为基础的方法作为ELA的替代方案。在这些研究中，例如，点云变换器被提出作为改进方法。

    In many recent works, the potential of Exploratory Landscape Analysis (ELA) features to numerically characterize, in particular, single-objective continuous optimization problems has been demonstrated. These numerical features provide the input for all kinds of machine learning tasks on continuous optimization problems, ranging, i.a., from High-level Property Prediction to Automated Algorithm Selection and Automated Algorithm Configuration. Without ELA features, analyzing and understanding the characteristics of single-objective continuous optimization problems would be impossible.  Yet, despite their undisputed usefulness, ELA features suffer from several drawbacks. These include, in particular, (1.) a strong correlation between multiple features, as well as (2.) its very limited applicability to multi-objective continuous optimization problems. As a remedy, recent works proposed deep learning-based approaches as alternatives to ELA. In these works, e.g., point-cloud transformers were
    
[^24]: 自适应最大化社会福利

    Adaptive maximization of social welfare. (arXiv:2310.09597v1 [econ.EM])

    [http://arxiv.org/abs/2310.09597](http://arxiv.org/abs/2310.09597)

    论文研究了通过适应性策略选择最大化社会福利的问题，并提供了关于遗憾的下界和算法的匹配上界。研究发现福利最大化比多臂老虎机问题更困难，但该算法达到了最优增长速率。

    

    我们考虑了重复选择政策以最大化社会福利的问题。福利是个人效用和公共收入的加权和。早期的结果影响后续的政策选择。效用不可观测，但可以间接推断。响应函数通过实验学习获得。我们推导出了一个关于遗憾的下界，并且对于一种Exp3算法的匹配对策对立上界。累积遗憾以$T^{2/3}$的速率增长。这意味着(i)福利最大化比多臂老虎机问题更困难（对于有限的政策集来说，增长速率为$T^{1/2}$），和(ii)我们的算法实现了最优增长速率。对于随机设置，如果社会福利是凹的，我们可以使用二分搜索算法在连续政策集上实现$T^{1/2}$的速率。我们分析了非线性收入税扩展，并概述了商品税扩展。我们将我们的设置与垄断定价（更容易）和双边交易的定价进行了比较。

    We consider the problem of repeatedly choosing policies to maximize social welfare. Welfare is a weighted sum of private utility and public revenue. Earlier outcomes inform later policies. Utility is not observed, but indirectly inferred. Response functions are learned through experimentation.  We derive a lower bound on regret, and a matching adversarial upper bound for a variant of the Exp3 algorithm. Cumulative regret grows at a rate of $T^{2/3}$. This implies that (i) welfare maximization is harder than the multi-armed bandit problem (with a rate of $T^{1/2}$ for finite policy sets), and (ii) our algorithm achieves the optimal rate. For the stochastic setting, if social welfare is concave, we can achieve a rate of $T^{1/2}$ (for continuous policy sets), using a dyadic search algorithm.  We analyze an extension to nonlinear income taxation, and sketch an extension to commodity taxation. We compare our setting to monopoly pricing (which is easier), and price setting for bilateral tra
    
[^25]: 决策导向学习的鲁棒损失函数

    Robust Losses for Decision-Focused Learning. (arXiv:2310.04328v1 [cs.LG])

    [http://arxiv.org/abs/2310.04328](http://arxiv.org/abs/2310.04328)

    这篇论文提出了一种改进的损失函数来处理决策导向学习中的不确定性问题，并对经验遗憾作为替代的准确性进行了分析。

    

    用于进行离散决策的优化模型通常包含基于预测估计的上下文相关且不确定的参数。为了考虑基于预测的决策质量，决策导向学习（端到端预测-优化）旨在训练预测模型以最小化遗憾，即通过进行次优决策而产生的损失。尽管这个损失函数可能是非凸和一般不可导的，但已经提出了有效的基于梯度的学习方法来最小化期望损失，使用经验损失作为替代。然而，经验遗憾可能不是一个有效的替代，因为优化模型中的不确定性导致经验遗憾与期望遗憾在期望上不相等。为了说明这种不等式的影响，我们评估了机会性和认知性不确定性对经验遗憾作为替代的准确性的影响。接下来，我们提出了一种改进的损失函数，该函数能够更好地近似期望遗憾，从而更好地指导决策导向学习的训练过程。

    Optimization models used to make discrete decisions often contain uncertain parameters that are context-dependent and are estimated through prediction. To account for the quality of the decision made based on the prediction, decision-focused learning (end-to-end predict-then-optimize) aims at training the predictive model to minimize regret, i.e., the loss incurred by making a suboptimal decision. Despite the challenge of this loss function being possibly non-convex and in general non-differentiable, effective gradient-based learning approaches have been proposed to minimize the expected loss, using the empirical loss as a surrogate. However, empirical regret can be an ineffective surrogate because the uncertainty in the optimization model makes the empirical regret unequal to the expected regret in expectation. To illustrate the impact of this inequality, we evaluate the effect of aleatoric and epistemic uncertainty on the accuracy of empirical regret as a surrogate. Next, we propose 
    
[^26]: 通过参数高效适应，实现对缺失模态的鲁棒多模态学习

    Robust Multimodal Learning with Missing Modalities via Parameter-Efficient Adaptation. (arXiv:2310.03986v1 [cs.CV])

    [http://arxiv.org/abs/2310.03986](http://arxiv.org/abs/2310.03986)

    通过低秩适应和中间特征的调制，我们提出了针对预训练多模态网络的参数高效适应程序，以实现对缺失模态的鲁棒性，并在某些情况下胜过独立的专门网络。

    

    多模态学习旨在利用多个数据源来提高下游任务的整体性能。在一些相关的模态中观察到，如果在测试时间缺少一个或多个模态，现有的多模态网络的性能会显著下降。为了实现对缺失模态的鲁棒性，我们提出了预训练的多模态网络的简单和参数高效的适应程序。特别地，我们利用低秩适应和中间特征的调制来补偿缺失的模态。我们证明，这种适应可以部分弥补由于缺失模态而导致的性能下降，并在某些情况下胜过针对可用模态组合进行训练的独立的、专门的网络。所提出的适应所需的参数非常少（例如，少于）

    Multimodal learning seeks to utilize data from multiple sources to improve the overall performance of downstream tasks. It is desirable for redundancies in the data to make multimodal systems robust to missing or corrupted observations in some correlated modalities. However, we observe that the performance of several existing multimodal networks significantly deteriorates if one or multiple modalities are absent at test time. To enable robustness to missing modalities, we propose simple and parameter-efficient adaptation procedures for pretrained multimodal networks. In particular, we exploit low-rank adaptation and modulation of intermediate features to compensate for the missing modalities. We demonstrate that such adaptation can partially bridge performance drop due to missing modalities and outperform independent, dedicated networks trained for the available modality combinations in some cases. The proposed adaptation requires extremely small number of parameters (e.g., fewer than 
    
[^27]: FLAIM: 在联邦设置中基于AIM的合成数据生成

    FLAIM: AIM-based Synthetic Data Generation in the Federated Setting. (arXiv:2310.03447v1 [cs.CR])

    [http://arxiv.org/abs/2310.03447](http://arxiv.org/abs/2310.03447)

    FLAIM是一个在联邦设置中基于AIM的合成数据生成方法，该方法解决了差分隐私方向的技术在联邦场景下的适用问题，并提出了FLAIM方法来维持较高的效用和处理异构性。

    

    保护个人隐私同时实现协同数据共享对组织至关重要。合成数据生成是一种解决方案，它产生与私有数据的统计特性相似的人工数据。虽然在差分隐私下已经设计出了许多技术，但它们主要假设数据是集中的。然而，数据往往以联邦方式分布在多个客户端上。在这项工作中，我们开始研究联邦合成表数据生成。在AIM这个先进的中心方法的基础上，我们提出了DistAIM和FLAIM。我们展示了分发AIM是简单的，扩展了基于安全多方计算的最新方法，但需要额外的开销，使其在联邦场景中不太适用。然后，我们证明了简单地联邦AIM可能导致在异构性存在的情况下效用严重下降。为了解决这两个问题，我们提出了一种增强的FLAIM方法，该方法可以维持较高的效用，并且可以处理联邦设置中的异构性。

    Preserving individual privacy while enabling collaborative data sharing is crucial for organizations. Synthetic data generation is one solution, producing artificial data that mirrors the statistical properties of private data. While numerous techniques have been devised under differential privacy, they predominantly assume data is centralized. However, data is often distributed across multiple clients in a federated manner. In this work, we initiate the study of federated synthetic tabular data generation. Building upon a SOTA central method known as AIM, we present DistAIM and FLAIM. We show it is straightforward to distribute AIM, extending a recent approach based on secure multi-party computation which necessitates additional overhead, making it less suited to federated scenarios. We then demonstrate that naively federating AIM can lead to substantial degradation in utility under the presence of heterogeneity. To mitigate both issues, we propose an augmented FLAIM approach that mai
    
[^28]: 学习分子构象集合：数据集和基准测试

    Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks. (arXiv:2310.00115v1 [cs.LG])

    [http://arxiv.org/abs/2310.00115](http://arxiv.org/abs/2310.00115)

    本研究引入了第一个MoleculAR Conformer Ensemble Learning（MARCEL）基准测试，以全面评估在构象集合上学习的潜力，并提出有前途的研究方向。

    

    分子表示学习在药物发现和酶设计等众多生物化学应用中已经证明具有重要影响力。然而，现有的工作往往忽略了分子的灵活性，分子通过化学键旋转和微小振动扰动不断在构象之间相互转化。为了更好地考虑分子的灵活性，最近的一些工作将分子表示学习定义为一个集合学习问题，专注于从一组构象结构中明确学习。然而，大多数研究在数据集、任务和模型方面存在局限性。在本研究中，我们引入了第一个MoleculAR Conformer Ensemble Learning（MARCEL）基准测试，以全面评估在构象集合上学习的潜力，并提出有前途的研究方向。MARCEL包括四个数据集，涵盖了多样的分子和反应水平信息。

    Molecular Representation Learning (MRL) has proven impactful in numerous biochemical applications such as drug discovery and enzyme design. While Graph Neural Networks (GNNs) are effective at learning molecular representations from a 2D molecular graph or a single 3D structure, existing works often overlook the flexible nature of molecules, which continuously interconvert across conformations via chemical bond rotations and minor vibrational perturbations. To better account for molecular flexibility, some recent works formulate MRL as an ensemble learning problem, focusing on explicitly learning from a set of conformer structures. However, most of these studies have limited datasets, tasks, and models. In this work, we introduce the first MoleculAR Conformer Ensemble Learning (MARCEL) benchmark to thoroughly evaluate the potential of learning on conformer ensembles and suggest promising research directions. MARCEL includes four datasets covering diverse molecule- and reaction-level pro
    
[^29]: 揭示空间-时间掩蔽自动编码器在多元时间序列预测中的力量

    Revealing the Power of Spatial-Temporal Masked Autoencoders in Multivariate Time Series Forecasting. (arXiv:2309.15169v1 [cs.LG])

    [http://arxiv.org/abs/2309.15169](http://arxiv.org/abs/2309.15169)

    提出了一个利用空间-时间掩蔽自动编码器（STMAE）来提高多元时间序列（MTS）预测性能的框架，通过新颖的双掩蔽策略处理部分可见的MTS数据，包括空间掩蔽和时间掩蔽。

    

    多元时间序列（MTS）预测涉及基于历史观测来预测未来时间序列数据。现有研究主要强调开发能够明确捕捉时间序列变量之间的空间依赖性和时间相关性的复杂空间-时间模型。然而，最近的进展受到了数据稀缺性和模型鲁棒性的挑战。为了解决这些问题，我们提出了空间-时间掩蔽自动编码器（STMAE），这是一个MTS预测框架，利用掩蔽自动编码器来提高空间-时间基线模型的性能。STMAE包括两个学习阶段。在预训练阶段，采用编码器-解码器架构。编码器通过一种新颖的双掩蔽策略处理部分可见的MTS数据，包括基于偏置随机游走的空间掩蔽和基于补丁的时间掩蔽。随后，解码器旨在重构两个掩蔽对应物。

    Multivariate time series (MTS) forecasting involves predicting future time series data based on historical observations. Existing research primarily emphasizes the development of complex spatial-temporal models that capture spatial dependencies and temporal correlations among time series variables explicitly. However, recent advances have been impeded by challenges relating to data scarcity and model robustness. To address these issues, we propose Spatial-Temporal Masked Autoencoders (STMAE), an MTS forecasting framework that leverages masked autoencoders to enhance the performance of spatial-temporal baseline models. STMAE consists of two learning stages. In the pretraining stage, an encoder-decoder architecture is employed. The encoder processes the partially visible MTS data produced by a novel dual-masking strategy, including biased random walk-based spatial masking and patch-based temporal masking. Subsequently, the decoders aim to reconstruct the masked counterparts from both spa
    
[^30]: LLM平台安全：将系统评估框架应用于OpenAI的ChatGPT插件

    LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins. (arXiv:2309.10254v1 [cs.CR])

    [http://arxiv.org/abs/2309.10254](http://arxiv.org/abs/2309.10254)

    本文提出了一个框架，用于分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性。在应用框架于OpenAI的插件生态系统时，我们发现了一些具体证明了潜在问题的插件。

    

    近期，如ChatGPT等大型语言模型（LLM）平台开始提供插件生态系统，以与互联网上的第三方服务进行交互。虽然这些插件扩展了LLM平台的功能，但它们是由任意的第三方开发的，因此不能隐式信任。插件还使用自然语言与LLM平台和用户进行交互，这可能导致模糊的解释。本文提出了一个框架，为LLM平台设计者分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性奠定了基础。我们的框架是一个攻击分类法的表述，通过迭代地探索LLM平台相关方如何利用他们的能力和责任对彼此进行攻击来开发的。作为我们迭代过程的一部分，我们将我们的框架应用于OpenAI的插件生态系统。我们揭示了一些具体证明了潜在问题的插件。

    Large language model (LLM) platforms, such as ChatGPT, have recently begun offering a plugin ecosystem to interface with third-party services on the internet. While these plugins extend the capabilities of LLM platforms, they are developed by arbitrary third parties and thus cannot be implicitly trusted. Plugins also interface with LLM platforms and users using natural language, which can have imprecise interpretations. In this paper, we propose a framework that lays a foundation for LLM platform designers to analyze and improve the security, privacy, and safety of current and future plugin-integrated LLM platforms. Our framework is a formulation of an attack taxonomy that is developed by iteratively exploring how LLM platform stakeholders could leverage their capabilities and responsibilities to mount attacks against each other. As part of our iterative process, we apply our framework in the context of OpenAI's plugin ecosystem. We uncover plugins that concretely demonstrate the poten
    
[^31]: 非冲突教学图在图中球的应用研究

    Non-Clashing Teaching Maps for Balls in Graphs. (arXiv:2309.02876v1 [cs.CC])

    [http://arxiv.org/abs/2309.02876](http://arxiv.org/abs/2309.02876)

    本文研究了在图中球的概念类中的非冲突教学图，并证明了相关决策问题{\sc B-NCTD$^+$}是NP完全的。

    

    最近，Kirkpatrick等人[ALT 2019]和Fallat等人[JMLR 2023]引入了非冲突教学，并表明它是满足Goldman和Mathias提出的防止勾结基准的最高效的机器教学模型。对于一个概念类$\cal{C}$来说，教学图$T$将一个（教学）集合$T(C)$分配给每个概念$C \in \cal{C}$。如果没有一对概念与它们的教学集合的并一致，则教学图是非冲突的。非冲突教学图（NCTM）$T$的大小是$T(C)$中的最大大小，其中$C \in \cal{C}$。概念类$\mathcal{B}(G)$的非冲突教学维度NCTD$(\cal{C})$是$\cal{C}$的一个NCTM的最小大小。类似地，NCTM$^+$和NCTD$^+(\cal{C})$的定义是类似的，只是教师只能使用正例。我们研究了由图$G$的所有球组成的概念类$\mathcal{B}(G)$的NCTMs和NCTM$^+$s。我们证明了与NCTD$^+$的相关决策问题{\sc B-NCTD$^+$}是NP完全的。

    Recently, Kirkpatrick et al. [ALT 2019] and Fallat et al. [JMLR 2023] introduced non-clashing teaching and showed it to be the most efficient machine teaching model satisfying the benchmark for collusion-avoidance set by Goldman and Mathias. A teaching map $T$ for a concept class $\cal{C}$ assigns a (teaching) set $T(C)$ of examples to each concept $C \in \cal{C}$. A teaching map is non-clashing if no pair of concepts are consistent with the union of their teaching sets. The size of a non-clashing teaching map (NCTM) $T$ is the maximum size of a $T(C)$, $C \in \cal{C}$. The non-clashing teaching dimension NCTD$(\cal{C})$ of $\cal{C}$ is the minimum size of an NCTM for $\cal{C}$. NCTM$^+$ and NCTD$^+(\cal{C})$ are defined analogously, except the teacher may only use positive examples.  We study NCTMs and NCTM$^+$s for the concept class $\mathcal{B}(G)$ consisting of all balls of a graph $G$. We show that the associated decision problem {\sc B-NCTD$^+$} for NCTD$^+$ is NP-complete in spl
    
[^32]: GNFactor：具有可泛化神经特征场的多任务真实机器人学习

    GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields. (arXiv:2308.16891v1 [cs.RO])

    [http://arxiv.org/abs/2308.16891](http://arxiv.org/abs/2308.16891)

    GNFactor是一个用于多任务机器人操作的代理方法，它利用可泛化神经特征场和Perceiver Transformer模块，以及深度三维体素表示来实现对真实世界环境中的操作任务的执行。它通过将视觉和语义信息纳入三维表示来提高场景的理解能力，并在多个任务上进行了验证。

    

    在无结构的现实世界环境中，从视觉观察中开发能够执行多样化操作任务的代理机器人一直是机器人学中的一个长期问题。为了实现这个目标，机器人需要全面理解场景的三维结构和语义。在这项工作中，我们提出了GNFactor，一种用于多任务机器人操作的可视行为克隆代理，它利用可泛化神经特征场（GNF）作为重建模块，Perceiver Transformer作为决策模块，共享深度三维体素表示。为了将语义纳入三维表示，重建模块利用视觉语言基础模型（例如，稳定扩散）将丰富的语义信息提取到深度三维体素中。我们在3个真实机器人任务上评估了GNFactor，并对10个RLBench任务进行了详细的消融实验，只使用了有限数量的数据。

    It is a long-standing problem in robotics to develop agents capable of executing diverse manipulation tasks from visual observations in unstructured real-world environments. To achieve this goal, the robot needs to have a comprehensive understanding of the 3D structure and semantics of the scene. In this work, we present $\textbf{GNFactor}$, a visual behavior cloning agent for multi-task robotic manipulation with $\textbf{G}$eneralizable $\textbf{N}$eural feature $\textbf{F}$ields. GNFactor jointly optimizes a generalizable neural field (GNF) as a reconstruction module and a Perceiver Transformer as a decision-making module, leveraging a shared deep 3D voxel representation. To incorporate semantics in 3D, the reconstruction module utilizes a vision-language foundation model ($\textit{e.g.}$, Stable Diffusion) to distill rich semantic information into the deep 3D voxel. We evaluate GNFactor on 3 real robot tasks and perform detailed ablations on 10 RLBench tasks with a limited number of
    
[^33]: 多源领域适应用于化学过程交叉领域故障诊断

    Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes. (arXiv:2308.11247v1 [cs.LG])

    [http://arxiv.org/abs/2308.11247](http://arxiv.org/abs/2308.11247)

    本文在化学过程的交叉领域故障诊断中，对单源和多源无监督领域适应算法进行了广泛比较。研究结果表明，即使没有进行适应，使用多个领域进行训练也具有积极影响。

    

    故障诊断是过程监视中的重要组成部分。机器学习的故障诊断系统基于传感器数据预测故障类型。然而，这些模型对数据分布的变化敏感，这些变化可能由于监测过程中的变化，如操作模式的改变，导致跨领域故障诊断的情况。本文在化学工业中广泛使用的田纳西-伊斯曼过程的背景下，提供了单源和多源无监督领域适应算法在交叉领域故障诊断中的广泛比较。研究结果表明，即使没有进行适应，使用多个领域进行训练也具有积极影响。因此，多源无监督领域适应的基准模型相对于单源无监督领域适应的基准模型有所改进。

    Fault diagnosis is an essential component in process supervision. Indeed, it determines which kind of fault has occurred, given that it has been previously detected, allowing for appropriate intervention. Automatic fault diagnosis systems use machine learning for predicting the fault type from sensor readings. Nonetheless, these models are sensible to changes in the data distributions, which may be caused by changes in the monitored process, such as changes in the mode of operation. This scenario is known as Cross-Domain Fault Diagnosis (CDFD). We provide an extensive comparison of single and multi-source unsupervised domain adaptation (SSDA and MSDA respectively) algorithms for CDFD. We study these methods in the context of the Tennessee-Eastmann Process, a widely used benchmark in the chemical industry. We show that using multiple domains during training has a positive effect, even when no adaptation is employed. As such, the MSDA baseline improves over the SSDA baseline classificati
    
[^34]: 使用软多面体网络的本体感知学习

    Proprioceptive Learning with Soft Polyhedral Networks. (arXiv:2308.08538v1 [cs.RO])

    [http://arxiv.org/abs/2308.08538](http://arxiv.org/abs/2308.08538)

    本文提出了一种使用软多面体网络的本体感知学习方法，通过学习动力学特性和引入嵌入式视觉，实现了在物理交互中的自适应和粘弹性感觉，可以实时推断6维力和扭矩的作用。

    

    本文提出了一种具备嵌入式视觉的软多面体网络，用于在物理交互中实现自适应的本体感知和粘弹性感觉。该设计通过学习动力学特性，实现了对全向交互的被动适应，并通过内嵌的微型高速运动跟踪系统以视觉方式捕获本体感知的数据。实验结果表明，软多面体网络能够以0.25/0.24/0.35 N和0.025/0.034/0.006 Nm的精度实时推断6维力和扭矩在动态交互中的作用。此外，我们还通过添加粘弹性感受性来在静态适应中增加本体感知，从而进一步提高预测结果的精度。

    Proprioception is the "sixth sense" that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed 
    
[^35]: 从多任务非独立同分布数据中元学习操作符到最优性

    Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])

    [http://arxiv.org/abs/2308.04428](http://arxiv.org/abs/2308.04428)

    本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。

    

    机器学习中最近取得进展的一个强大概念是从异构来源或任务的数据中提取共同特征。直观地说，将所有数据用于学习共同的表示函数，既有助于计算效率，又有助于统计泛化，因为它可以减少要在给定任务上进行微调的参数数量。为了在理论上做出这些优点的根源，我们提出了从噪声向量测量$y = Mx + w$中回复线性操作符$M$的一般模型。其中，协变量$x$既可以是非独立同分布的，也可以是非各向同性的。我们证明了现有的各向同性无关的元学习方法会对表示更新造成偏差，这导致噪声项的缩放不再有利于源任务数量。这反过来会导致表示学习的样本复杂性受到单任务数据规模的限制。我们引入了一种方法，称为去偏差和特征白化。

    A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias & Feature-Whiten}
    
[^36]: 用于训练拥有数十亿参数的大型语言模型的优化网络架构

    Optimized Network Architectures for Large Language Model Training with Billions of Parameters. (arXiv:2307.12169v1 [cs.NI])

    [http://arxiv.org/abs/2307.12169](http://arxiv.org/abs/2307.12169)

    本文提出了一种优化的网络架构，用于训练拥有数十亿参数的大型语言模型。这个架构根据语言模型的通信需求，将集群分割成一组通过非阻塞高带宽互连的GPU集合，并通过轨道连接仅连接具有通信需求的GPU，从而降低网络成本高达75％，同时不影响训练性能。

    

    本文挑战了为训练大型语言模型（LLMs）构建任意到任意网络的传统范式。我们展示了LLMs呈现出一种独特的通信模式，在其中，只有小组的GPU需要高带宽的任意到任意通信，以实现接近最优的训练性能。在这些GPU小组之间，通信非常微不足道、稀疏且均匀。我们提出了一个新的网络架构，紧密匹配LLMs的通信需求。我们的架构将集群分割为一组通过非阻塞任意到任意高带宽互连的GPU集合，我们称之为HB域。在HB域之间，网络只连接具有通信需求的GPU。我们将这种网络连接称为“仅轨道连接”，并展示了我们的架构相对于最先进的任意到任意Clos网络可以将网络成本降低高达75％，同时不损害LLM训练的性能。

    This paper challenges the well-established paradigm for building any-to-any networks for training Large Language Models (LLMs). We show that LLMs exhibit a unique communication pattern where only small groups of GPUs require high-bandwidth any-to-any communication within them, to achieve near-optimal training performance. Across these groups of GPUs, the communication is insignificant, sparse, and homogeneous. We propose a new network architecture that closely resembles the communication requirement of LLMs. Our architecture partitions the cluster into sets of GPUs interconnected with non-blocking any-to-any high-bandwidth interconnects that we call HB domains. Across the HB domains, the network only connects GPUs with communication demands. We call this network a "rail-only" connection, and show that our proposed architecture reduces the network cost by up to 75% compared to the state-of-the-art any-to-any Clos networks without compromising the performance of LLM training.
    
[^37]: 强健的全异步方法用于通用架构上的分布式训练

    Robust Fully-Asynchronous Methods for Distributed Training over General Architecture. (arXiv:2307.11617v1 [cs.DC])

    [http://arxiv.org/abs/2307.11617](http://arxiv.org/abs/2307.11617)

    该论文提出了一种强健的全异步方法（R-FAST），在分布式机器学习中解决了完美同步的低效性和不可能性问题，通过采用鲁棒的梯度跟踪策略和灵活的通信架构，消除了数据异构性和数据包丢失的影响，并实现了期望的邻域收敛。

    

    分布式机器学习问题中完美的同步是低效甚至不可能的，由于延迟、数据丢失和延迟较大的设备。我们提出了一种强健的全异步随机梯度跟踪方法（R-FAST），其中每个设备以自己的速度进行本地计算和通信，而无需任何形式的同步。与现有的异步分布式算法不同，R-FAST可以通过采用基于设计良好的辅助变量来跟踪和缓冲整体梯度向量的鲁棒梯度跟踪策略，消除设备间数据异构性的影响，并允许数据包丢失。更重要的是，所提出的方法利用两个生成树图进行通信，只要两者共享至少一个共同的根节点，就能实现灵活的通信架构设计。我们证明了R-FAST对于平滑和强凸问题，收敛到最优解的期望邻域，并具有几何收敛率。

    Perfect synchronization in distributed machine learning problems is inefficient and even impossible due to the existence of latency, package losses and stragglers. We propose a Robust Fully-Asynchronous Stochastic Gradient Tracking method (R-FAST), where each device performs local computation and communication at its own pace without any form of synchronization. Different from existing asynchronous distributed algorithms, R-FAST can eliminate the impact of data heterogeneity across devices and allow for packet losses by employing a robust gradient tracking strategy that relies on properly designed auxiliary variables for tracking and buffering the overall gradient vector. More importantly, the proposed method utilizes two spanning-tree graphs for communication so long as both share at least one common root, enabling flexible designs in communication architectures. We show that R-FAST converges in expectation to a neighborhood of the optimum with a geometric rate for smooth and strongly
    
[^38]: 指令挖掘：大语言模型的高质量指令数据选择

    Instruction Mining: High-Quality Instruction Data Selection for Large Language Models. (arXiv:2307.06290v1 [cs.CL])

    [http://arxiv.org/abs/2307.06290](http://arxiv.org/abs/2307.06290)

    本文提出了InstructMining，一种用于选择高质量指令数据的线性规则，以增强大语言模型的解释和响应指令能力。通过特定的自然语言指标建模，研究结果表明，即使只有少量高质量的指令跟随数据，语言模型也可以进行良好的微调。

    

    大型语言模型通常经历预训练和微调两个训练阶段。尽管大规模预训练赋予模型强大的生成自然语言回应的能力，但这些预训练模型有时仍然无法理解人类指令。为了增强语言模型解释和响应指令的能力，指令微调已成为该领域的关键方法。最近的研究发现，即使只有少量高质量的指令跟随数据，大型语言模型也可以进行良好的微调。然而，选择用于微调语言模型的高质量数据集仍缺乏明确的指导方针。在本文中，我们提出了InstructMining，一个用于评估指令跟随数据质量的线性规则。我们使用具体的自然语言指标来进行InstructMining的建模。为了研究数据质量与这些指标之间的关系，我们还进行了广泛的细致研究。

    Large language models typically undergo two training stages, pretraining and finetuning. Despite that large-scale pretraining endows the model with strong capabilities to generate natural language responses, these pretrained models can still fail to understand human instructions at times. To enhance language models' ability of interpreting and responding to instructions, instruction finetuning has emerged as a critical method in this area. Recent studies found that large language models can be finetuned to perform well even with a small amount of high-quality instruction-following data. However, the selection of high-quality datasets for finetuning language models still lacks clear guidelines to follow. In this paper, we propose InstructMining, a linear rule for evaluating instruction-following data quality. We formulate InstructMining using specific natural language indicators. To investigate the relationship between data quality and these indicators, we further conduct extensive fine
    
[^39]: 预测性流水线解码：准确LLM解码中的计算延迟权衡

    Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding. (arXiv:2307.05908v1 [cs.CL])

    [http://arxiv.org/abs/2307.05908](http://arxiv.org/abs/2307.05908)

    本论文提出了一种预测性流水线解码（PPD）方法，通过并行启动后续令牌解码来加速大型语言模型（LLMs）中的贪婪解码过程，同时保持完全相同的输出。该方法在减少解码延迟方面具有潜力，提供了新的LLM解码策略权衡理解。

    

    本论文提出了一种名为"预测性流水线解码（PPD）"的方法，该方法可以加速大型语言模型（LLMs）中的贪婪解码，同时保持与原始解码完全相同的输出。与传统策略不同，PPD利用额外的计算资源在当前令牌解码期间并行启动后续令牌解码。这种创新方法减少了解码延迟，并重新塑造了LLM解码策略中的权衡理解。我们开发了一个理论框架，可以分析计算和延迟之间的权衡关系。使用这个框架，我们可以通过评估匹配率（表示为p_correct）来对我们提出的方法可能的延迟减少进行分析估计。结果表明，使用额外的计算资源有潜力加速LLM的贪婪解码过程。

    This paper presents "Predictive Pipelined Decoding (PPD)," an approach that speeds up greedy decoding in Large Language Models (LLMs) while maintaining the exact same output as the original decoding. Unlike conventional strategies, PPD employs additional compute resources to parallelize the initiation of subsequent token decoding during the current token decoding. This innovative method reduces decoding latency and reshapes the understanding of trade-offs in LLM decoding strategies. We have developed a theoretical framework that allows us to analyze the trade-off between computation and latency. Using this framework, we can analytically estimate the potential reduction in latency associated with our proposed method, achieved through the assessment of the match rate, represented as p_correct. The results demonstrate that the use of extra computational resources has the potential to accelerate LLM greedy decoding.
    
[^40]: 缩放定律不具备可扩展性

    Scaling Laws Do Not Scale. (arXiv:2307.03201v1 [cs.LG])

    [http://arxiv.org/abs/2307.03201](http://arxiv.org/abs/2307.03201)

    本文讨论了缩放定律与人工智能模型性能之间的关系，并指出数据集规模的增加会引发不同社群的价值观和偏见风险。

    

    最近的研究提出了一种称为“缩放定律”的幂律关系，它描述了人工智能（AI）模型的性能与模型设计的各个方面（如数据集大小）之间的关系。换句话说，随着数据集（或模型参数等）的增加，基于该数据集训练的模型的性能将相应增加。然而，在总体上具有吸引力的同时，这种缩放定律关系忽视了用于衡量性能的指标可能是不稳定和有争议的，或者可能不符合不同人群对模型输出质量的感知。本文提出，随着用于训练大型AI模型的数据集规模增长，数据集中包含的不同社群（包括人口统计学群体）的数量可能会增加，每个社群可能具有不同的价值观。因此，数据集中所代表的社群可能存在价值观或偏见的风险。

    Recent work has proposed a power law relationship, referred to as ``scaling laws,'' between the performance of artificial intelligence (AI) models and aspects of those models' design (e.g., dataset size). In other words, as the size of a dataset (or model parameters, etc) increases, the performance of a given model trained on that dataset will correspondingly increase. However, while compelling in the aggregate, this scaling law relationship overlooks the ways that metrics used to measure performance may be precarious and contested, or may not correspond with how different groups of people may perceive the quality of models' output. In this paper, we argue that as the size of datasets used to train large AI models grows, the number of distinct communities (including demographic groups) whose data is included in a given dataset is likely to grow, each of whom may have different values. As a result, there is an increased risk that communities represented in a dataset may have values or p
    
[^41]: GIO：用于训练数据集选择的梯度信息优化

    GIO: Gradient Information Optimization for Training Dataset Selection. (arXiv:2306.11670v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11670](http://arxiv.org/abs/2306.11670)

    GIO是一种可伸缩且任务不可知的方法，通过对目标的简单放松和高效实现，可以在非常小的训练集上产生出色的结果。

    

    在训练模型时，通常有利于在可用训练样本的子集上进行训练，因为这些样本具有不同的质量，或者希望在不影响性能的情况下使用更少的样本进行训练。我们提出了梯度信息优化（GIO），这是一种可伸缩且任务不可知的方法，用于解决这个数据选择问题，它只需要一小组（未标记的）样本来代表目标分布。GIO从一个实践中难以处理的自然的信息理论目标开始。我们的贡献在于展示出通过对目标进行简单的放松和高效的实现，它可以被高度扩展。在机器翻译、拼写纠正和图像识别等实验中，我们证明了GIO在非常小的训练集上产生了出色的结果。这些发现对于GIO本身的不同表示模型和超参数是稳健的。GIO是任务和领域无关的，可以直接应用于新领域。

    It is often advantageous to train models on a subset of the available train examples, because the examples are of variable quality or because one would like to train with fewer examples, without sacrificing performance. We present Gradient Information Optimization (GIO), a scalable, task-agnostic approach to this data selection problem that requires only a small set of (unlabeled) examples representing a target distribution. GIO begins from a natural, information-theoretic objective that is intractable in practice. Our contribution is in showing that it can be made highly scalable through a simple relaxation of the objective and a highly efficient implementation. In experiments with machine translation, spelling correction, and image recognition, we show that GIO delivers outstanding results with very small train sets. These findings are robust to different representation models and hyperparameters for GIO itself. GIO is task- and domain-agnostic and can be applied out-of-the-box to ne
    
[^42]: 微调对于视觉语言模型外分布检测的影响是怎样的？

    How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?. (arXiv:2306.06048v1 [cs.CV])

    [http://arxiv.org/abs/2306.06048](http://arxiv.org/abs/2306.06048)

    本研究旨在探究微调对少样本下游任务的外分布检测的影响，发现适当选择外分布分数对于CLIP-based 微调至关重要。最大概念匹配（MCM）分数提供了一个有前途的解决方案。

    

    最近的大型视觉语言模型，如CLIP，在外分布检测和泛化性能方面表现出色。然而，它们的零样本内分布准确性往往在下游数据集中受到限制。最近的基于CLIP的微调方法，如提示学习，已经在存在外分布标签的情况下显著改进了内分布分类和外分布泛化。然而，模型对于没有外分布标签的语义转移是否可靠仍然不清楚。为了填补这一空白，本文旨在对微调对于少样本下游任务的外分布检测的影响进行全面研究。通过将外分布检测框架化为多模式概念匹配，我们建立了微调方法和各种外分布分数之间的联系。我们的结果表明，选择适当的外分布分数对于基于CLIP的微调至关重要。特别是，最大概念匹配（MCM）分数提供了一个有前途的解决方案。

    Recent large vision-language models such as CLIP have shown remarkable out-of-distribution (OOD) detection and generalization performance. However, their zero-shot in-distribution (ID) accuracy is often limited for downstream datasets. Recent CLIP-based fine-tuning methods such as prompt learning have demonstrated significant improvements in ID classification and OOD generalization where OOD labels are available. Nonetheless, it remains unclear whether the model is reliable to semantic shifts without OOD labels. In this paper, we aim to bridge the gap and present a comprehensive study to understand how fine-tuning impact OOD detection for few-shot downstream tasks. By framing OOD detection as multi-modal concept matching, we establish a connection between fine-tuning methods and various OOD scores. Our results suggest that a proper choice of OOD scores is essential for CLIP-based fine-tuning. In particular, the maximum concept matching (MCM) score provides a promising solution consiste
    
[^43]: CoCo: 一种用于无监督领域自适应图分类的耦合对比框架

    CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification. (arXiv:2306.04979v1 [cs.LG])

    [http://arxiv.org/abs/2306.04979](http://arxiv.org/abs/2306.04979)

    CoCo是一种耦合对比图表示学习框架，其中包含一个图卷积网络和一个分层图内核网络，通过耦合对比学习减少领域差异，用于无监督领域自适应图分类。

    

    虽然图神经网络在图分类中取得了显著成果，但它们通常需要大量特定任务的标签，这可能需要极大的代价来获得。一种可靠的解决方案是探索其他标注图以增强目标域的无监督学习，但如何将图神经网络应用到领域适应中仍未解决，因为对图拓扑的不充分探索以及相当大的领域偏差。本文提出了一种称为CoCo（Coupled Contrastive Graph Representation Learning）方案，该方案从耦合学习分支中提取拓扑信息，并通过耦合对比学习减少领域差异。CoCo包含一个图卷积网络分支和分层图内核网络分支，分别用隐式和显式方式探索图拓扑。此外，我们将耦合分支结合到一个全面的多视角对比学习框架中，

    Although graph neural networks (GNNs) have achieved impressive achievements in graph classification, they often need abundant task-specific labels, which could be extensively costly to acquire. A credible solution is to explore additional labeled graphs to enhance unsupervised learning on the target domain. However, how to apply GNNs to domain adaptation remains unsolved owing to the insufficient exploration of graph topology and the significant domain discrepancy. In this paper, we propose \underline{Co}upled \underline{Co}ntrastive Graph Representation Learning (\method{}), which extracts the topological information from coupled learning branches and reduces the domain discrepancy with coupled contrastive learning. \method{} contains a graph convolutional network branch and a hierarchical graph kernel network branch, which explore graph topology in implicit and explicit manners. Besides, we incorporate coupled branches into a holistic multi-view contrastive learning framework, which 
    
[^44]: SAPI:环境感知车辆在路口的轨迹预测

    SAPI: Surroundings-Aware Vehicle Trajectory Prediction at Intersections. (arXiv:2306.01812v1 [cs.LG])

    [http://arxiv.org/abs/2306.01812](http://arxiv.org/abs/2306.01812)

    本文提出了一种称为SAPI的深度学习模型，用于在路口预测车辆轨迹，通过实时地图、优先权和周围交通信息来表示和编码周围环境。SAPI能够在预测车辆轨迹时表现出有希望的性能，且优于基准方法。

    

    本文提出了一种深度学习模型，即SAPI，用于在路口预测车辆轨迹。SAPI使用抽象的方式来表示和编码周围环境，通过利用实时地图、优先权和周围交通信息。提出的模型包括两个卷积网络(CNN)和一个基于循环神经网络(RNN)的编码器以及一个解码器。为了充分利用原始历史轨迹信息，在模型中提出了一个细化器来进行回溯操作。我们使用自主车辆在实际路口采集的专有数据集评估了SAPI。结果表明，在预测路口车辆轨迹时，SAPI表现出有希望的性能，并且优于基准方法。6秒预测的平均位移误差(ADE)和最终位移误差(FDE)分别为1.84米和4.32米。我们还展示了该模型能够准确预测车辆轨迹。

    In this work we propose a deep learning model, i.e., SAPI, to predict vehicle trajectories at intersections. SAPI uses an abstract way to represent and encode surrounding environment by utilizing information from real-time map, right-of-way, and surrounding traffic. The proposed model consists of two convolutional network (CNN) and recurrent neural network (RNN)-based encoders and one decoder. A refiner is proposed to conduct a look-back operation inside the model, in order to make full use of raw history trajectory information. We evaluate SAPI on a proprietary dataset collected in real-world intersections through autonomous vehicles. It is demonstrated that SAPI shows promising performance when predicting vehicle trajectories at intersection, and outperforms benchmark methods. The average displacement error(ADE) and final displacement error(FDE) for 6-second prediction are 1.84m and 4.32m respectively. We also show that the proposed model can accurately predict vehicle trajectories i
    
[^45]: InstructIE: 一份基于指令的中文信息提取数据集

    InstructIE: A Chinese Instruction-based Information Extraction Dataset. (arXiv:2305.11527v1 [cs.CL])

    [http://arxiv.org/abs/2305.11527](http://arxiv.org/abs/2305.11527)

    介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。

    

    我们引入了一项新的信息提取任务，称为基于指令的信息提取 (Instruction-based IE)，它旨在要求系统遵循特定的指令或指南来提取信息。为了促进该领域的研究，我们构建了一个数据集，称为InstructIE，其中包括来自中文维基百科的 270,000 个弱监督数据和 1,000 个高质量众包注释实例。我们进一步评估了各种基线模型在InstructIE数据集上的表现。结果表明，尽管当前的模型表现很有希望，但仍有改进的空间。此外，我们进行了全面的案例研究分析，强调了基于指令的信息提取任务中固有的挑战。代码和数据集可在 https://github.com/zjunlp/DeepKE/tree/main/example/llm 找到。

    We introduce a new Information Extraction (IE) task dubbed Instruction-based IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task. Code and dataset are available at https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^46]: 使用Lasso的签名一致性研究

    On Consistency of Signatures Using Lasso. (arXiv:2305.10413v1 [stat.ML])

    [http://arxiv.org/abs/2305.10413](http://arxiv.org/abs/2305.10413)

    本文重新审视了Lasso回归对于签名变换的一致性问题，并发现对于不同的过程和时间序列，选择适当的签名定义和随机模型可以提高Lasso回归的一致性。

    

    签名变换是连续和离散时间序列数据的迭代路径积分，它们的普遍非线性通过线性化特征选择问题。本文在理论和数值上重新审视了Lasso回归对于签名变换的一致性问题。我们的研究表明，对于更接近布朗运动或具有较弱跨维度相关性的过程和时间序列，签名定义为It\^o积分的Lasso回归更具一致性；对于均值回归过程和时间序列，其签名定义为Stratonovich积分在Lasso回归中具有更高的一致性。我们的发现强调了在统计推断和机器学习中选择适当的签名和随机模型的重要性。

    Signature transforms are iterated path integrals of continuous and discrete-time time series data, and their universal nonlinearity linearizes the problem of feature selection. This paper revisits the consistency issue of Lasso regression for the signature transform, both theoretically and numerically. Our study shows that, for processes and time series that are closer to Brownian motion or random walk with weaker inter-dimensional correlations, the Lasso regression is more consistent for their signatures defined by It\^o integrals; for mean reverting processes and time series, their signatures defined by Stratonovich integrals have more consistency in the Lasso regression. Our findings highlight the importance of choosing appropriate definitions of signatures and stochastic models in statistical inference and machine learning.
    
[^47]: 基于双指数族的扩展广义线性模型中的Dropout正则化

    Dropout Regularization in Extended Generalized Linear Models based on Double Exponential Families. (arXiv:2305.06625v1 [stat.ML])

    [http://arxiv.org/abs/2305.06625](http://arxiv.org/abs/2305.06625)

    本论文研究了基于双指数族的扩展广义线性模型中的dropout正则化，dropout正则化偏好罕见但重要的特征，在均值和离散度方面都具有普适性。

    

    尽管dropout是一种流行的正则化技术，但其理论性质尚未被充分理解。本文研究了基于双指数族的扩展广义线性模型中的dropout正则化，其中离散参数可以随特征变化。理论分析表明，dropout正则化偏好罕见但重要的特征，在均值和离散度方面都具有普适性，这扩展了之前针对传统广义线性模型的结果 。采用自适应学习率的随机梯度下降进行训练。为了说明这一点，我们将dropout应用于自适应B样条平滑，其中均值和离散度参数都被灵活地建模。重要的B样条基础函数可以被认为是罕见的特征，我们在实验中证实，dropout是一种改善了罚最大似然方法的显式平滑性的均值和离散度参数的有效正则化形式。

    Even though dropout is a popular regularization technique, its theoretical properties are not fully understood. In this paper we study dropout regularization in extended generalized linear models based on double exponential families, for which the dispersion parameter can vary with the features. A theoretical analysis shows that dropout regularization prefers rare but important features in both the mean and dispersion, generalizing an earlier result for conventional generalized linear models. Training is performed using stochastic gradient descent with adaptive learning rate. To illustrate, we apply dropout to adaptive smoothing with B-splines, where both the mean and dispersion parameters are modelled flexibly. The important B-spline basis functions can be thought of as rare features, and we confirm in experiments that dropout is an effective form of regularization for mean and dispersion parameters that improves on a penalized maximum likelihood approach with an explicit smoothness p
    
[^48]: ContactArt：学习类别级联结物体和手部姿态估计的三维交互先验

    ContactArt: Learning 3D Interaction Priors for Category-level Articulated Object and Hand Poses Estimation. (arXiv:2305.01618v1 [cs.CV])

    [http://arxiv.org/abs/2305.01618](http://arxiv.org/abs/2305.01618)

    本研究提出了一种基于视觉遥操作的数据收集方法以及学习手物互动先验的新方法，从而能够在联结目标和手部姿态估计中实现更好的关键点定位性能。

    

    我们提出了一个新的数据集和一种新方法，用于学习手部和联结目标姿态估计中的手物互动先验。我们首先使用视觉遥操作收集了一个数据集，其中人类操作员可以直接在物理模拟器中游戏来操纵联结对象。 我们记录数据并从模拟器获得有关目标姿态和接触信息的免费和准确注释。 我们的系统仅需要使用iPhone来记录人手运动，可以轻松扩展并大大降低数据和注释收集的成本。使用这些数据，我们学习了三维交互先验，包括捕获对象部件排列分布的鉴别器（在GAN中），以及生成联结对象上接触区域的扩散模型，以指导手势估计。这些结构和接触先验可以很容易地转移到现实世界数据，几乎没有任何领域差距。通过使用我们的数据和学习的先验，我们的方法显著提高了关键点定位性能。

    We propose a new dataset and a novel approach to learning hand-object interaction priors for hand and articulated object pose estimation. We first collect a dataset using visual teleoperation, where the human operator can directly play within a physical simulator to manipulate the articulated objects. We record the data and obtain free and accurate annotations on object poses and contact information from the simulator. Our system only requires an iPhone to record human hand motion, which can be easily scaled up and largely lower the costs of data and annotation collection. With this data, we learn 3D interaction priors including a discriminator (in a GAN) capturing the distribution of how object parts are arranged, and a diffusion model which generates the contact regions on articulated objects, guiding the hand pose estimation. Such structural and contact priors can easily transfer to real-world data with barely any domain gap. By using our data and learned priors, our method signific
    
[^49]: 可达集的凸包的精确刻画

    Exact Characterization of the Convex Hulls of Reachable Sets. (arXiv:2303.17674v1 [math.OC])

    [http://arxiv.org/abs/2303.17674](http://arxiv.org/abs/2303.17674)

    本文精确地刻画了具有有界扰动的非线性系统的可达集的凸包为一阶常微分方程的解的凸包，提出了一种低成本、高精度的估计算法，可用于过逼近可达集。

    

    本文研究了具有有界扰动的非线性系统的可达集的凸包。可达集在控制中起着至关重要的作用，但计算起来仍然非常具有挑战性，现有的过逼近工具往往过于保守或计算代价高昂。本文精确地刻画了可达集的凸包，将其表示成一阶常微分方程的解的凸包，这个有限维的刻画开启了一种紧密的估计算法，可用于过逼近可达集，且成本比现有方法更低、更精准。本文还提出了神经反馈环分析和鲁棒模型预测控制的应用。

    We study the convex hulls of reachable sets of nonlinear systems with bounded disturbances. Reachable sets play a critical role in control, but remain notoriously challenging to compute, and existing over-approximation tools tend to be conservative or computationally expensive. In this work, we exactly characterize the convex hulls of reachable sets as the convex hulls of solutions of an ordinary differential equation from all possible initial values of the disturbances. This finite-dimensional characterization unlocks a tight estimation algorithm to over-approximate reachable sets that is significantly faster and more accurate than existing methods. We present applications to neural feedback loop analysis and robust model predictive control.
    
[^50]: 利用量子几何进行学习幺正变换的泛化

    Generalization with quantum geometry for learning unitaries. (arXiv:2303.13462v1 [quant-ph])

    [http://arxiv.org/abs/2303.13462](http://arxiv.org/abs/2303.13462)

    本文研究了量子机器学习模型的泛化能力，使用数据的量子费舍尔信息度量来评估成功训练和泛化所需的电路参数和训练数据的数量，并展示通过去除对称性来提高泛化能力，同时发现超出分布泛化能力可以比使用相同分布更优。

    

    泛化是量子机器学习模型从训练数据学习准确预测新数据的能力。在这里，我们引入数据的量子费舍尔信息度量(DQFIM)来确定模型何时能够泛化。对于幺正变换的可变学习，DQFIM量化了成功训练和泛化所需的电路参数和训练数据的数量。我们应用DQFIM来解释何时恒定数量的训练状态和多项式数量的参数足以实现泛化。此外，通过从训练数据中删除对称性，可以提高泛化能力。最后，我们显示，使用不同数据分布进行训练和测试的超出分布泛化能力可以比使用相同分布的能力更优。我们的研究为提高量子机器学习中的泛化能力开辟了新的方法。

    Generalization is the ability of quantum machine learning models to make accurate predictions on new data by learning from training data. Here, we introduce the data quantum Fisher information metric (DQFIM) to determine when a model can generalize. For variational learning of unitaries, the DQFIM quantifies the amount of circuit parameters and training data needed to successfully train and generalize. We apply the DQFIM to explain when a constant number of training states and polynomial number of parameters are sufficient for generalization. Further, we can improve generalization by removing symmetries from training data. Finally, we show that out-of-distribution generalization, where training and testing data are drawn from different data distributions, can be better than using the same distribution. Our work opens up new approaches to improve generalization in quantum machine learning.
    
[^51]: 针对非光滑偏微分方程约束的优化问题，使用ADMM-PINNs算法框架进行深度学习处理

    The ADMM-PINNs Algorithmic Framework for Nonsmooth PDE-Constrained Optimization: A Deep Learning Approach. (arXiv:2302.08309v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2302.08309](http://arxiv.org/abs/2302.08309)

    本论文提出了采用ADMM-PINNs算法框架解决非光滑PDE约束优化问题的方法，在迭代中采用ADMM将PDE约束和非光滑正则化项分离，使得可以高效地解决 PDE-constrained optimization problems。

    

    本文研究了使用多重乘数交替方向法(ADMM)和物理信息神经网络(PINNs)的组合来解决一般类别的非光滑偏微分方程(PDE)约束优化问题。当需要对控制或设计变量进行限制时，可以采用附加正则化方法。所得到的ADMM-PINNs算法框架极大地扩展了PINNs的适用范围，可以应用于非光滑的PDE约束的优化问题。采用ADMM可以将PDE约束和非光滑正则化项分离出来，使迭代更加高效。在每次迭代中，其中的一个子问题是平滑的PDE受约束优化问题，可以通过PINNs有效地解决，而另一个是简单的非光滑优化问题，通常有封闭形式解或可以通过多种标准优化算法或预训练的神经网络有效地解决。通过两个数值实验证明了ADMM-PINNs算法框架在解决PDE约束的非光滑约束优化问题方面的有效性和鲁棒性。

    We study the combination of the alternating direction method of multipliers (ADMM) with physics-informed neural networks (PINNs) for a general class of nonsmooth partial differential equation (PDE)-constrained optimization problems, where additional regularization can be employed for constraints on the control or design variables. The resulting ADMM-PINNs algorithmic framework substantially enlarges the applicable range of PINNs to nonsmooth cases of PDE-constrained optimization problems. The application of the ADMM makes it possible to untie the PDE constraints and the nonsmooth regularization terms for iterations. Accordingly, at each iteration, one of the resulting subproblems is a smooth PDE-constrained optimization which can be efficiently solved by PINNs, and the other is a simple nonsmooth optimization problem which usually has a closed-form solution or can be efficiently solved by various standard optimization algorithms or pre-trained neural networks. The ADMM-PINNs algorithmi
    
[^52]: 分层策略混合作为反应式机器人控制的推理

    Hierarchical Policy Blending as Inference for Reactive Robot Control. (arXiv:2210.07890v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.07890](http://arxiv.org/abs/2210.07890)

    该论文提出了一种分层运动生成的方法，结合了反应式策略和规划的优点，在多目标决策问题中提供了可行的路径。

    

    在杂乱、密集和动态的环境中进行运动生成是机器人领域的一个核心问题，被视为一个多目标决策问题。当前的方法在安全和性能之间进行权衡。一方面，反应式策略保证了对环境变化的快速响应，但以次优的行为作为代价。另一方面，基于规划的运动生成提供可行的轨迹，但高计算成本可能会限制控制频率，从而牺牲安全性。为了结合反应式策略和规划的优点，我们提出了一种分层运动生成方法。此外，我们采用概率推理方法来正式化分层模型和随机优化。我们将这种方法实现为随机反应式专家策略的加权乘积，其中规划被用于自适应计算任务周期内的最优权重。这种随机优化避免了局部最优，并提出了可行的反应式计划，找到路径。

    Motion generation in cluttered, dense, and dynamic environments is a central topic in robotics, rendered as a multi-objective decision-making problem. Current approaches trade-off between safety and performance. On the one hand, reactive policies guarantee fast response to environmental changes at the risk of suboptimal behavior. On the other hand, planning-based motion generation provides feasible trajectories, but the high computational cost may limit the control frequency and thus safety. To combine the benefits of reactive policies and planning, we propose a hierarchical motion generation method. Moreover, we adopt probabilistic inference methods to formalize the hierarchical model and stochastic optimization. We realize this approach as a weighted product of stochastic, reactive expert policies, where planning is used to adaptively compute the optimal weights over the task horizon. This stochastic optimization avoids local optima and proposes feasible reactive plans that find path
    
[^53]: 多任务学习和Bandits通过健壮统计学

    Multitask Learning and Bandits via Robust Statistics. (arXiv:2112.14233v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.14233](http://arxiv.org/abs/2112.14233)

    本研究探讨了多任务学习以及Bandits方法的健壮统计学实现，提出了一种新颖的两阶段多任务学习估计器，该估计器以一种样本高效的方式利用共享全局参数和稀疏实例特定术语的结构。

    

    决策者经常同时面对许多相关但异质的学习问题。在此工作中，我们研究了一种自然的设置，其中每个学习实例中的未知参数可以分解为共享全局参数加上稀疏的实例特定术语。我们提出了一种新颖的两阶段多任务学习估计器，以一种样本高效的方式利用这种结构，使用健壮统计学（在相似实例上学习）和LASSO回归（去偏差结果）的独特组合。我们的估计器提供了改进的样本复杂度界限。

    Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bound
    
[^54]: 可微分高斯化层用于深度生成模型正则化的逆问题

    Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models. (arXiv:2112.03860v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.03860](http://arxiv.org/abs/2112.03860)

    该论文提出了一种使用可微数据相关层进行重新参数化和高斯化潜在张量的方法，以约束逆问题为获得高保真度的分布内解决方案，有效解决深度生成模型逆问题中潜在张量偏离期望高斯分布的问题。

    

    深度生成模型如GAN、标准化流和扩散模型是逆问题的强大正则化器，可以帮助减小不适定性并获得高质量的结果。然而，在逆推过程中，这些模型的潜在张量可能会从期望的高维标准高斯分布中脱离，特别是在数据噪声和不准确的正向模型存在的情况下，会导致低保真度的解决方案。为解决这个问题，我们提出使用新颖的可微数据相关层重新参数化和高斯化潜在张量，其中使用自定义操作符解决优化问题。这些拟议的层将逆问题约束为获得高保真度的分布内解决方案。我们在三个反演任务（压缩感知MRI、图像去模糊和准确度受限的非线性偏微分方程反演问题“eikonal tomography”）上使用两种典型的深度生成模型进行了验证。

    Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the desired high-dimensional standard Gaussian distribution during inversion, particularly in the presence of data noise and inaccurate forward models, leading to low-fidelity solutions. To address this issue, we propose to reparameterize and Gaussianize the latent tensors using novel differentiable data-dependent layers wherein custom operators are defined by solving optimization problems. These proposed layers constrain inverse problems to obtain high-fidelity in-distribution solutions. We validate our technique on three inversion tasks: compressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear PDE-constrained inverse problem) using two representative deep generative models
    

