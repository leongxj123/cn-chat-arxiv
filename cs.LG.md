# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs](https://rss.arxiv.org/abs/2312.05356) | 这项工作介绍了一种神经元层面的模型编辑方法，能够在编码任务中修补LLM模型，并且在API序列推荐、代码生成和伪代码到代码转换等任务中得到了验证和评估。 |
| [^2] | [Diffusion Posterior Proximal Sampling for Image Restoration](https://arxiv.org/abs/2402.16907) | 本文提出了一种改进的基于扩散的图像恢复范式，通过选择与测量标识一致的样本，以及从与测量信号相结合的初始化开始恢复过程，实现输出稳定性和增强。 |
| [^3] | [Explainable Classification Techniques for Quantum Dot Device Measurements](https://arxiv.org/abs/2402.13699) | 提出了一种基于合成数据的的可解释特征技术，利用可解释性提升机（EBMs）实现了在量子点调谐中较高的可解释性和准确性。 |
| [^4] | [Distilling Large Language Models for Text-Attributed Graph Learning](https://arxiv.org/abs/2402.12022) | 本研究旨在将大型语言模型和图模型的优势相结合，通过将LLMs的能力压缩到 TAG 学习的本地图模型中，解决它们之间的固有差距。 |
| [^5] | [ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks](https://arxiv.org/abs/2402.09146) | 本文介绍了一种增强量子卷积神经网络性能的新框架ResQuNNs，在quanvolutional层中引入可训练性，通过残差学习的概念解决了跨层梯度访问的问题。 |
| [^6] | [Position Paper: Challenges and Opportunities in Topological Deep Learning](https://arxiv.org/abs/2402.08871) | 拓扑深度学习将拓扑特征引入深度学习模型，可作为图表示学习和几何深度学习的补充，给各种机器学习环境提供了自然选择。本文讨论了拓扑深度学习中的开放问题，并提出了未来的研究机会。 |
| [^7] | [Large Language Model Adaptation for Networking](https://arxiv.org/abs/2402.02338) | 本文首次研究了使用大型语言模型（LLM）适应网络问题的方法，通过利用LLM的预训练知识和强大推理能力，实现了“一模型适用于所有”的目标，并取得了更好的性能和更强的泛化能力。 |
| [^8] | [Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI](https://arxiv.org/abs/2402.00809) | 《在大规模人工智能时代的贝叶斯深度学习》这篇立场论文探讨了贝叶斯深度学习在各种不同设置下的优势，并指出了与之相关的挑战和有趣的研究方向。未来的研究重点将放在如何将大规模基础模型与贝叶斯深度学习相结合，以发挥它们的全部潜力。 |
| [^9] | [Robustness Assessment of a Runway Object Classifier for Safe Aircraft Taxiing](https://arxiv.org/abs/2402.00035) | 本文介绍了对航班滑行安全的跑道物体分类器的鲁棒性评估，使用形式方法评估了该分类器对三种常见图像扰动类型的鲁棒性，并提出了一种利用单调性的方法。 |
| [^10] | [PBSCSR: The Piano Bootleg Score Composer Style Recognition Dataset.](http://arxiv.org/abs/2401.16803) | 本研究介绍了PBSCSR数据集，用于研究钢琴乐谱作曲家风格识别。数据集包含了盗版乐谱图像和相关元数据，可以进行多个研究任务。 |
| [^11] | [The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making.](http://arxiv.org/abs/2401.11044) | 本文研究了机器学习分类过程中数据抽象方法的重要性，提出了Small and Incomplete Dataset Analyser (SaNDA)采用ROC曲线方法开发的数据抽象协议，该方法在缺少值很少的情况下可以成为随机森林的可行替代品，始终保持高准确性。 |
| [^12] | [Comparison analysis between standard polysomnographic data and in-ear-EEG signals: A preliminary study.](http://arxiv.org/abs/2401.10107) | 本研究通过比较标准多导睡眠图（PSG）和耳内脑电信号的相似性，旨在探索一种更少侵入、成本效益高和便携的替代方法。研究确定了评估方法，并通过提取特征进行分析。 |
| [^13] | [Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach.](http://arxiv.org/abs/2310.12428) | 这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。 |
| [^14] | [On the Over-Memorization During Natural, Robust and Catastrophic Overfitting.](http://arxiv.org/abs/2310.08847) | 本论文研究了深度神经网络中的过度记忆问题，发现其会损害泛化能力，并提出了方法综合性地减轻不同类型的过拟合。 |
| [^15] | [Imitation Learning from Purified Demonstration.](http://arxiv.org/abs/2310.07143) | 本文提出了一种从纯净演示中进行模仿学习的方法，通过引入扩散过程对不完美演示中的潜在扰动进行净化。通过这种方法，可以改善模仿学习在真实场景中的应用挑战。 |
| [^16] | [HeaP: Hierarchical Policies for Web Actions using LLMs.](http://arxiv.org/abs/2310.03720) | 这篇论文介绍了一个名为HeaP的框架，利用大型语言模型（LLMs）来解决Web任务的挑战。该框架将Web任务分解为子任务，并通过一系列低级的策略来执行，相比其他基准方法，该框架在不同的Web任务上表现出更好的性能。 |
| [^17] | [Local Differential Privacy in Graph Neural Networks: a Reconstruction Approach.](http://arxiv.org/abs/2309.08569) | 本研究提出了一种学习框架，旨在为用户提供节点隐私保护，并通过在节点级别对特征和标签数据进行随机化扰动来实现。通过频率估计和重构方法，实现了对扰动数据中特征和标签的恢复。 |
| [^18] | [Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems.](http://arxiv.org/abs/2307.15325) | 本文解决了在大规模动态系统中部分观测或粗粒化的情况下，经典的EDMD算法不能准确提供Koopman算子近似的问题，并展示了将系统动态的对称性转移到Koopman算子可以显著提高模型效率。 |
| [^19] | [Probabilistic Forecasting with Coherent Aggregation.](http://arxiv.org/abs/2307.09797) | 该论文提出了一种新的模型，利用因子模型结构来产生遵守层次结构的概率预测。模型利用卷积神经网络生成参数，并通过优化样本损失函数实现预测优化。 |
| [^20] | [SIMGA: A Simple and Effective Heterophilous Graph Neural Network with Efficient Global Aggregation.](http://arxiv.org/abs/2305.09958) | 本文章提出了一种简单有效的异质图神经网络模型SIMGA，它通过SimRank全局聚合来解决异质性节点聚合的问题，具有接近于线性的传播效率，同时具有良好的有效性和可扩展性。 |
| [^21] | [Tool Learning with Foundation Models.](http://arxiv.org/abs/2304.08354) | 基于基础模型的工具学习结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。本文对工具学习进行了系统研究，提出了涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。 |
| [^22] | [Deep-learning assisted detection and quantification of (oo)cysts of Giardia and Cryptosporidium on smartphone microscopy images.](http://arxiv.org/abs/2304.05339) | 本研究采用基于深度学习的RetinaNet模型针对采用智能手机显微系统检测贾第虫和隐孢子进行检测和计数，并在速度和准确度方面表现出最佳效果，为在资源有限的环境下解决这一问题提供了潜在解决方案。 |
| [^23] | [Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States.](http://arxiv.org/abs/2303.17963) | 本文提出了一种面向未知具有潜在状态系统的学习优化控制方法，并给出了概率性能保证，同时提出了一种验证任意控制律性能的方法。 |
| [^24] | [Attribute Graph Clustering via Learnable Augmentation.](http://arxiv.org/abs/2212.03559) | 本研究提出了一种通过可学习增强技术进行属性图聚类的方法，该方法利用可学习的增强器为深度图聚类提供高质量和适合的增强样本，通过改进矩阵提高了聚类性能的可靠性。 |
| [^25] | [Closing the gap between SVRG and TD-SVRG with Gradient Splitting.](http://arxiv.org/abs/2211.16237) | 本论文通过将TD学习视为适当选择函数的梯度分割，将TD和SVRG相结合，实现了具有几何收敛速度的策略评估方法，并在理论和实验上得到了支持。 |

# 详细

[^1]: Neuron Patching: 神经元层面的模型编辑与代码生成

    Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs

    [https://rss.arxiv.org/abs/2312.05356](https://rss.arxiv.org/abs/2312.05356)

    这项工作介绍了一种神经元层面的模型编辑方法，能够在编码任务中修补LLM模型，并且在API序列推荐、代码生成和伪代码到代码转换等任务中得到了验证和评估。

    

    大型语言模型在软件工程中得到了成功应用，特别是在代码生成方面。更新这些模型的新知识非常昂贵，通常需要全面实现其价值。在本文中，我们提出了一种新颖有效的模型编辑方法MENT，用于在编码任务中修补LLM模型。基于生成式LLM的机制，MENT可以在预测下一个令牌时进行模型编辑，并进一步支持常见的编码任务。MENT具有高效、有效和可靠的特点。它可以通过修补1或2个神经元来纠正神经模型。作为神经元层面上生成模型编辑的先驱工作，我们规范了编辑过程并介绍了相关概念。此外，我们还引入了新的衡量方法来评估其泛化能力，并建立了一个用于进一步研究的基准。我们的方法在三个编码任务上进行了评估，包括API序列推荐、行级代码生成和伪代码到代码转换。

    Large Language Models are successfully adopted in software engineering, especially in code generation. Updating these models with new knowledge is very expensive, and is often required to fully realize their value. In this paper, we propose a novel and effective model editing approach, \textsc{MENT}, to patch LLMs in coding tasks. Based on the mechanism of generative LLMs, \textsc{MENT} enables model editing in next-token predictions, and further supports common coding tasks. \textsc{MENT} is effective, efficient, and reliable. It can correct a neural model by patching 1 or 2 neurons. As the pioneer work on neuron-level model editing of generative models, we formalize the editing process and introduce the involved concepts. Besides, we also introduce new measures to evaluate its generalization ability, and build a benchmark for further study. Our approach is evaluated on three coding tasks, including API-seq recommendation, line-level code generation, and pseudocode-to-code transaction
    
[^2]: 用于图像恢复的扩散后验近似采样

    Diffusion Posterior Proximal Sampling for Image Restoration

    [https://arxiv.org/abs/2402.16907](https://arxiv.org/abs/2402.16907)

    本文提出了一种改进的基于扩散的图像恢复范式，通过选择与测量标识一致的样本，以及从与测量信号相结合的初始化开始恢复过程，实现输出稳定性和增强。

    

    扩散模型在生成高质量样本方面表现出卓越的功效。现有基于扩散的图像恢复算法利用预先训练的扩散模型来利用数据先验，但仍保留了继承自无条件生成范式的元素。本文介绍了一种改进的基于扩散的图像恢复范式。具体来说，我们选择在每个生成步骤中与测量标识一致的样本，利用采样选择作为输出稳定性和增强的途径。此外，我们从一个与测量信号相结合的初始化开始恢复过程，提供了附加信息以更好地对齐生成过程。

    arXiv:2402.16907v1 Announce Type: cross  Abstract: Diffusion models have demonstrated remarkable efficacy in generating high-quality samples. Existing diffusion-based image restoration algorithms exploit pre-trained diffusion models to leverage data priors, yet they still preserve elements inherited from the unconditional generation paradigm. These strategies initiate the denoising process with pure white noise and incorporate random noise at each generative step, leading to over-smoothed results. In this paper, we introduce a refined paradigm for diffusion-based image restoration. Specifically, we opt for a sample consistent with the measurement identity at each generative step, exploiting the sampling selection as an avenue for output stability and enhancement. Besides, we start the restoration process with an initialization combined with the measurement signal, providing supplementary information to better align the generative process. Extensive experimental results and analyses val
    
[^3]: 可解释的量子点器件测量分类技术

    Explainable Classification Techniques for Quantum Dot Device Measurements

    [https://arxiv.org/abs/2402.13699](https://arxiv.org/abs/2402.13699)

    提出了一种基于合成数据的的可解释特征技术，利用可解释性提升机（EBMs）实现了在量子点调谐中较高的可解释性和准确性。

    

    在物理科学中，对图像数据的稳健特征表示需求增加：图像采集，在广义上指二维数据，现在在许多领域广泛应用，包括我们在此考虑的量子信息科学。虽然在这些情况下广泛使用传统图像特征，但它们的使用正在迅速被神经网络技术所取代，后者往往以牺牲可解释性为代价换取高准确性。为了弥合这种权衡，我们提出了一种基于合成数据的技术，可以产生可解释的特征。我们利用可解释性提升机（EBMs）展示，这种方法提供了卓越的可解释性，并且不会降低准确性。具体而言，我们展示了在量子点调谐的背景下，这种技术带来了实质性的益处，当前发展阶段需要人类干预。

    arXiv:2402.13699v1 Announce Type: cross  Abstract: In the physical sciences, there is an increased need for robust feature representations of image data: image acquisition, in the generalized sense of two-dimensional data, is now widespread across a large number of fields, including quantum information science, which we consider here. While traditional image features are widely utilized in such cases, their use is rapidly being supplanted by Neural Network-based techniques that often sacrifice explainability in exchange for high accuracy. To ameliorate this trade-off, we propose a synthetic data-based technique that results in explainable features. We show, using Explainable Boosting Machines (EBMs), that this method offers superior explainability without sacrificing accuracy. Specifically, we show that there is a meaningful benefit to this technique in the context of quantum dot tuning, where human intervention is necessary at the current stage of development.
    
[^4]: 将大型语言模型压缩用于文本属性图学习

    Distilling Large Language Models for Text-Attributed Graph Learning

    [https://arxiv.org/abs/2402.12022](https://arxiv.org/abs/2402.12022)

    本研究旨在将大型语言模型和图模型的优势相结合，通过将LLMs的能力压缩到 TAG 学习的本地图模型中，解决它们之间的固有差距。

    

    文本属性图（TAGs）是连接的文本文档图。图模型可以有效学习TAGs，但它们的训练严重依赖于人工标注的标签，在许多应用中这些标签很少或甚至不可用。大型语言模型（LLMs）最近在少样本和零样本TAG学习中展示了显著能力，但它们存在可伸缩性、成本和隐私问题。因此，在这项工作中，我们专注于通过将LLMs的能力传授给TAG学习中的本地图模型，从而协同LLMs和图模型的互补优势。

    arXiv:2402.12022v1 Announce Type: new  Abstract: Text-Attributed Graphs (TAGs) are graphs of connected textual documents. Graph models can efficiently learn TAGs, but their training heavily relies on human-annotated labels, which are scarce or even unavailable in many applications. Large language models (LLMs) have recently demonstrated remarkable capabilities in few-shot and zero-shot TAG learning, but they suffer from scalability, cost, and privacy issues. Therefore, in this work, we focus on synergizing LLMs and graph models with their complementary strengths by distilling the power of LLMs to a local graph model on TAG learning. To address the inherent gaps between LLMs (generative models for texts) and graph models (discriminative models for graphs), we propose first to let LLMs teach an interpreter with rich textual rationale and then let a student model mimic the interpreter's reasoning without LLMs' textual rationale. Extensive experiments validate the efficacy of our proposed 
    
[^5]: ResQuNNs: 实现量子卷积神经网络中深度学习的新框架

    ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks

    [https://arxiv.org/abs/2402.09146](https://arxiv.org/abs/2402.09146)

    本文介绍了一种增强量子卷积神经网络性能的新框架ResQuNNs，在quanvolutional层中引入可训练性，通过残差学习的概念解决了跨层梯度访问的问题。

    

    本文提出了一种增强量子卷积神经网络（QuNNs）性能的新框架，通过引入可训练的quanvolutional层并解决与其相关的关键挑战。传统的quanvolutional层虽然有助于特征提取，但往往是静态的，适应性有限。与最先进的研究不同，我们的研究通过在这些层内部进行训练，显著提高了QuNNs的灵活性和潜力。然而，多个可训练的quanvolutional层的引入给基于梯度的优化带来了复杂性，主要是由于难以在这些层之间访问梯度。为了解决这个问题，我们提出了一种新的架构，Residual Quanvolutional Neural Networks (ResQuNNs)，利用残差学习的概念，在这些层之间添加跳过连接以促进梯度的流动。

    arXiv:2402.09146v1 Announce Type: new Abstract: In this paper, we present a novel framework for enhancing the performance of Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional layers and addressing the critical challenges associated with them. Traditional quanvolutional layers, although beneficial for feature extraction, have largely been static, offering limited adaptability. Unlike state-of-the-art, our research overcomes this limitation by enabling training within these layers, significantly increasing the flexibility and potential of QuNNs. However, the introduction of multiple trainable quanvolutional layers induces complexities in gradient-based optimization, primarily due to the difficulty in accessing gradients across these layers. To resolve this, we propose a novel architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging the concept of residual learning, which facilitates the flow of gradients by adding skip connections between 
    
[^6]: 位置论文：拓扑深度学习中的挑战与机遇

    Position Paper: Challenges and Opportunities in Topological Deep Learning

    [https://arxiv.org/abs/2402.08871](https://arxiv.org/abs/2402.08871)

    拓扑深度学习将拓扑特征引入深度学习模型，可作为图表示学习和几何深度学习的补充，给各种机器学习环境提供了自然选择。本文讨论了拓扑深度学习中的开放问题，并提出了未来的研究机会。

    

    拓扑深度学习是一个快速发展的领域，它利用拓扑特征来理解和设计深度学习模型。本文认为，通过融入拓扑概念，拓扑深度学习可以补充图表示学习和几何深度学习，并成为各种机器学习环境下的自然选择。为此，本文讨论了拓扑深度学习中的开放问题，涵盖了从实用益处到理论基础的各个方面。针对每个问题，它概述了潜在的解决方案和未来的研究机会。同时，本文也是对科学界的邀请，希望积极参与拓扑深度学习研究，开发这个新兴领域的潜力。

    arXiv:2402.08871v1 Announce Type: new Abstract: Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.
    
[^7]: 大型语言模型用于网络的适应性

    Large Language Model Adaptation for Networking

    [https://arxiv.org/abs/2402.02338](https://arxiv.org/abs/2402.02338)

    本文首次研究了使用大型语言模型（LLM）适应网络问题的方法，通过利用LLM的预训练知识和强大推理能力，实现了“一模型适用于所有”的目标，并取得了更好的性能和更强的泛化能力。

    

    现在许多网络任务都使用深度学习（DL）来解决复杂的预测和系统优化问题。然而，目前基于DL的算法的设计哲学需要进行大量的工程开销，因为需要为不同的网络任务手动设计深度神经网络（DNN）。此外，DNN在未见过的数据分布/环境上的泛化性能较差。在大型语言模型（LLM）的最新成功的推动下，本文首次研究了LLM用于网络的适应性，以探索更可持续的设计哲学。凭借海量的预训练知识和强大的推理能力，LLM可以作为基础模型，并且有望在各种任务中实现“一模型适用于所有”，并具有更好的性能和更强的泛化能力。在本文中，我们提出了NetLLM，这是第一个有效地将LLM应用于解决网络问题的适应性框架。NetLLM解决了许多实际挑战。

    Many networking tasks now employ deep learning (DL) to solve complex prediction and system optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.   Motivated by the recent success of large language models (LLMs), for the first time, this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the massive pre-trained knowledge and powerful inference ability, LLM can serve as the foundation model, and is expected to achieve "one model for all" with even better performance and stronger generalization for various tasks. In this paper, we present NetLLM, the first LLM adaptation framework that efficiently adapts LLMs to solve networking problems. NetLLM addresses many practical challenges in L
    
[^8]: 《在大规模人工智能时代的贝叶斯深度学习》的立场论文

    Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI

    [https://arxiv.org/abs/2402.00809](https://arxiv.org/abs/2402.00809)

    《在大规模人工智能时代的贝叶斯深度学习》这篇立场论文探讨了贝叶斯深度学习在各种不同设置下的优势，并指出了与之相关的挑战和有趣的研究方向。未来的研究重点将放在如何将大规模基础模型与贝叶斯深度学习相结合，以发挥它们的全部潜力。

    

    在当前的深度学习研究领域中，人们主要关注在涉及大规模图像和语言数据集的监督任务中实现高预测准确性。然而，更广泛的视角揭示了许多被忽视的度量标准、任务和数据类型，如不确定性、主动和持续学习以及科学数据，这些方面需要关注。贝叶斯深度学习（BDL）是一条有前景的道路，可以在这些不同的设置中提供优势。本文认为BDL可以提升深度学习的能力。它重新审视了BDL的优势、承认了现有的挑战，并重点介绍了一些旨在解决这些障碍的有趣的研究方向。展望未来，讨论集中在可能的方式上，将大规模基础模型与BDL相结合，以充分发挥它们的潜力。

    In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.
    
[^9]: 航班滑行安全的跑道物体分类器的鲁棒性评估

    Robustness Assessment of a Runway Object Classifier for Safe Aircraft Taxiing

    [https://arxiv.org/abs/2402.00035](https://arxiv.org/abs/2402.00035)

    本文介绍了对航班滑行安全的跑道物体分类器的鲁棒性评估，使用形式方法评估了该分类器对三种常见图像扰动类型的鲁棒性，并提出了一种利用单调性的方法。

    

    随着深度神经网络(DNNs)在许多计算问题上成为主要解决方案，航空业希望探索它们在减轻飞行员负担和改善运营安全方面的潜力。然而，在这类安全关键应用中使用DNNs需要进行彻底的认证过程。这一需求可以通过形式验证来解决，形式验证提供了严格的保证，例如证明某些误判的不存在。在本文中，我们使用Airbus当前正在开发的图像分类器DNN作为案例研究，旨在在飞机滑行阶段使用。我们使用形式方法来评估这个DNN对三种常见图像扰动类型的鲁棒性：噪声、亮度和对比度，以及它们的部分组合。这个过程涉及多次调用底层验证器，这可能在计算上是昂贵的；因此，我们提出了一种利用单调性的方法。

    As deep neural networks (DNNs) are becoming the prominent solution for many computational problems, the aviation industry seeks to explore their potential in alleviating pilot workload and in improving operational safety. However, the use of DNNs in this type of safety-critical applications requires a thorough certification process. This need can be addressed through formal verification, which provides rigorous assurances -- e.g.,~by proving the absence of certain mispredictions. In this case-study paper, we demonstrate this process using an image-classifier DNN currently under development at Airbus and intended for use during the aircraft taxiing phase. We use formal methods to assess this DNN's robustness to three common image perturbation types: noise, brightness and contrast, and some of their combinations. This process entails multiple invocations of the underlying verifier, which might be computationally expensive; and we therefore propose a method that leverages the monotonicity
    
[^10]: PBSCSR：钢琴黑市乐谱作曲家风格识别数据集

    PBSCSR: The Piano Bootleg Score Composer Style Recognition Dataset. (arXiv:2401.16803v1 [cs.SD])

    [http://arxiv.org/abs/2401.16803](http://arxiv.org/abs/2401.16803)

    本研究介绍了PBSCSR数据集，用于研究钢琴乐谱作曲家风格识别。数据集包含了盗版乐谱图像和相关元数据，可以进行多个研究任务。

    

    本文介绍了PBSCSR数据集，用于研究钢琴乐谱作曲家风格识别。我们的目标是创建一个研究作曲家风格识别的数据集，它既像MNIST一样易于获取，又像ImageNet一样具有挑战性。为了实现这个目标，我们从IMSLP的钢琴乐谱图像中采样固定长度的盗版乐谱片段。数据集本身包含40,000个62x64的盗版乐谱图像，用于进行9分类任务，以及100,000个62x64的盗版乐谱图像，用于进行100分类任务，还有29,310个无标签的可变长度的盗版乐谱图像，用于预训练。标记数据以与MNIST图像类似的形式呈现，以便极其方便地可视化、操作和训练模型。此外，我们还包括相关的元数据，以允许访问IMSLP上的原始乐谱图像和其他相关数据。我们描述了几个可以使用该数据进行研究的任务。

    This article motivates, describes, and presents the PBSCSR dataset for studying composer style recognition of piano sheet music. Our overarching goal was to create a dataset for studying composer style recognition that is "as accessible as MNIST and as challenging as ImageNet." To achieve this goal, we sample fixed-length bootleg score fragments from piano sheet music images on IMSLP. The dataset itself contains 40,000 62x64 bootleg score images for a 9-way classification task, 100,000 62x64 bootleg score images for a 100-way classification task, and 29,310 unlabeled variable-length bootleg score images for pretraining. The labeled data is presented in a form that mirrors MNIST images, in order to make it extremely easy to visualize, manipulate, and train models in an efficient manner. Additionally, we include relevant metadata to allow access to the underlying raw sheet music images and other related data on IMSLP. We describe several research tasks that could be studied with the data
    
[^11]: 机器学习分类过程中数据抽象方法在关键决策中的重要性

    The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making. (arXiv:2401.11044v1 [cs.LG])

    [http://arxiv.org/abs/2401.11044](http://arxiv.org/abs/2401.11044)

    本文研究了机器学习分类过程中数据抽象方法的重要性，提出了Small and Incomplete Dataset Analyser (SaNDA)采用ROC曲线方法开发的数据抽象协议，该方法在缺少值很少的情况下可以成为随机森林的可行替代品，始终保持高准确性。

    

    广泛采用的机器学习(ML)方法在分类方面的适用性受到了解释能力和不确定性的限制，特别是在医疗保健、行为科学和金融等领域，其中责任问题至关重要。最近，提出了Small and Incomplete Dataset Analyser (SaNDA)，通过使用基于ROC曲线的方法开发数据抽象协议，以增强在这些领域中执行分类的能力。本文关注于列间数据转换，即抽象，这对SaNDA的分类过程非常关键，并探讨了替代的抽象协议，如常量分箱和分位数。将最佳的方法与可解释方法的基准模型随机森林进行了比较。结果表明，即使数据不完整，SaNDA在缺少值很少的情况下仍然可以成为随机森林的可行替代品，并且始终保持高准确性。

    The applicability of widely adopted machine learning (ML) methods to classification is circumscribed by the imperatives of explicability and uncertainty, particularly evident in domains such as healthcare, behavioural sciences, and finances, wherein accountability assumes priority. Recently, Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the ability to perform classification in such domains, by developing a data abstraction protocol using a ROC curve-based method. This paper focuses on column-wise data transformations called abstractions, which are crucial for SaNDA's classification process and explores alternative abstractions protocols, such as constant binning and quantiles. The best-performing methods have been compared against Random Forest as a baseline for explainable methods. The results suggests that SaNDA can be a viable substitute for Random Forest when data is incomplete, even with minimal missing values. It consistently maintains high accuracy e
    
[^12]: 标准多导睡眠图与耳内脑电信号的比较分析：初步研究

    Comparison analysis between standard polysomnographic data and in-ear-EEG signals: A preliminary study. (arXiv:2401.10107v1 [eess.SP])

    [http://arxiv.org/abs/2401.10107](http://arxiv.org/abs/2401.10107)

    本研究通过比较标准多导睡眠图（PSG）和耳内脑电信号的相似性，旨在探索一种更少侵入、成本效益高和便携的替代方法。研究确定了评估方法，并通过提取特征进行分析。

    

    研究目的：多导睡眠图（PSG）目前被用作评估睡眠障碍的基准。其不舒适、不适合家庭使用以及在睡眠质量评估中引入偏差的问题需要探索更少侵入性、成本效益高和便携性的替代方法。一种有前景的候选方法是耳内脑电传感器，它在舒适性、固定电极位置、抗电磁干扰性和易于使用性方面均具有优势。本研究旨在建立一种评估耳内脑电信号与标准PSG之间相似性的方法。方法：我们评估PSG和耳内脑电推导的睡眠图之间的一致性。我们从PSG和耳内脑电信号的30秒时域和频域提取特征。我们只考虑在PSG评分员和耳内脑电评分员达成一致时的时段。我们引入一种方法来量化PSG推导和单通道耳内脑电之间的相似性。该方法包括...

    Study Objectives: Polysomnography (PSG) currently serves as the benchmark for evaluating sleep disorders. Its discomfort, impracticality for home-use, and introduction of bias in sleep quality assessment necessitate the exploration of less invasive, cost-effective, and portable alternatives. One promising contender is the in-ear-EEG sensor, which offers advantages in terms of comfort, fixed electrode positions, resistance to electromagnetic interference, and user-friendliness. This study aims to establish a methodology to assess the similarity between the in-ear-EEG signal and standard PSG.  Methods: We assess the agreement between the PSG and in-ear-EEG derived hypnograms. We extract features in the time- and frequency- domain from PSG and in-ear-EEG 30-second epochs. We only consider the epochs where the PSG-scorers and the in-ear-EEG-scorers were in agreement. We introduce a methodology to quantify the similarity between PSG derivations and the single-channel in-ear-EEG. The approac
    
[^13]: 实现随机森林的局部可解释性增强：基于邻近性的方法

    Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])

    [http://arxiv.org/abs/2310.12428](http://arxiv.org/abs/2310.12428)

    这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。

    

    我们提出一种新的方法来解释随机森林（RF）模型的样本外性能，利用了任何RF都可以被表述为自适应加权K最近邻（KNN）模型的事实。具体而言，我们利用RF在特征空间中学到的点之间的邻近性，将随机森林的预测重写为训练数据点目标标签的加权平均值。这种线性性质有助于在训练集观测中为任何模型预测生成属性，从而为RF预测提供了局部的解释性，补充了SHAP等已有方法，这些方法则为特征空间维度上的模型预测生成属性。我们在训练于美国公司债券交易数据的债券定价模型中演示了这种方法，并将其与各种现有的模型解释方法进行了比较。

    We initiate a novel approach to explain the out of sample performance of random forest (RF) models by exploiting the fact that any RF can be formulated as an adaptive weighted K nearest-neighbors model. Specifically, we use the proximity between points in the feature space learned by the RF to re-write random forest predictions exactly as a weighted average of the target labels of training data points. This linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established methods like SHAP, which instead generates attributions for a model prediction across dimensions of the feature space. We demonstrate this approach in the context of a bond pricing model trained on US corporate bond trades, and compare our approach to various existing approaches to model explainability.
    
[^14]: 关于自然、鲁棒和灾难性过拟合中的过度记忆问题

    On the Over-Memorization During Natural, Robust and Catastrophic Overfitting. (arXiv:2310.08847v1 [cs.LG])

    [http://arxiv.org/abs/2310.08847](http://arxiv.org/abs/2310.08847)

    本论文研究了深度神经网络中的过度记忆问题，发现其会损害泛化能力，并提出了方法综合性地减轻不同类型的过拟合。

    

    过拟合对深度神经网络（DNN）的泛化能力产生了负面影响，无论是在自然训练还是对抗性训练中。现有的方法难以一致地解决不同类型的过拟合，通常设计了针对自然模式或对抗模式的策略。在本工作中，我们采用统一的视角，仅关注自然模式，去探索不同类型的过拟合。具体而言，我们研究了DNN中的记忆效应，并揭示了一种称为过度记忆的共同行为，这会损害它们的泛化能力。这种行为表现为DNN突然对某些训练模式产生高置信度的预测，并对其保持持久记忆。此外，当DNN过度记忆一种对抗模式时，它们往往同时展现出对应自然模式的高置信度预测。这些发现激励我们综合性地减轻不同类型的过拟合，阻碍过度记忆行为的发生。

    Overfitting negatively impacts the generalization ability of deep neural networks (DNNs) in both natural and adversarial training. Existing methods struggle to consistently address different types of overfitting, typically designing strategies that focus separately on either natural or adversarial patterns. In this work, we adopt a unified perspective by solely focusing on natural patterns to explore different types of overfitting. Specifically, we examine the memorization effect in DNNs and reveal a shared behaviour termed over-memorization, which impairs their generalization capacity. This behaviour manifests as DNNs suddenly becoming high-confidence in predicting certain training patterns and retaining a persistent memory for them. Furthermore, when DNNs over-memorize an adversarial pattern, they tend to simultaneously exhibit high-confidence prediction for the corresponding natural pattern. These findings motivate us to holistically mitigate different types of overfitting by hinder
    
[^15]: 从纯净演示中进行模仿学习

    Imitation Learning from Purified Demonstration. (arXiv:2310.07143v1 [cs.LG])

    [http://arxiv.org/abs/2310.07143](http://arxiv.org/abs/2310.07143)

    本文提出了一种从纯净演示中进行模仿学习的方法，通过引入扩散过程对不完美演示中的潜在扰动进行净化。通过这种方法，可以改善模仿学习在真实场景中的应用挑战。

    

    模仿学习已经成为解决顺序决策问题的一种有希望的方法，假设专家演示是最优的。然而，在现实世界中，专家演示通常是不完美的，导致在有效应用模仿学习时面临挑战。尽管现有研究已经着眼于优化不完美演示，但通常需要一定比例的最优演示来保证性能。为了解决这些问题，我们提出了在不完美演示中净化潜在扰动并随后从纯净演示中进行模仿学习的方法。受扩散模型的成功启发，我们引入了一个通过扩散过程进行的两步净化。在第一步中，我们应用正向扩散过程通过引入额外的噪声来有效地平滑不完美演示中的潜在扰动。随后，进行逆向生成过程。

    Imitation learning has emerged as a promising approach for addressing sequential decision-making problems, with the assumption that expert demonstrations are optimal. However, in real-world scenarios, expert demonstrations are often imperfect, leading to challenges in effectively applying imitation learning. While existing research has focused on optimizing with imperfect demonstrations, the training typically requires a certain proportion of optimal demonstrations to guarantee performance. To tackle these problems, we propose to purify the potential perturbations in imperfect demonstrations and subsequently conduct imitation learning from purified demonstrations. Motivated by the success of diffusion models, we introduce a two-step purification via the diffusion process. In the first step, we apply a forward diffusion process to effectively smooth out the potential perturbations in imperfect demonstrations by introducing additional noise. Subsequently, a reverse generative process is 
    
[^16]: HeaP: 使用LLMs进行层次化Web动作策略

    HeaP: Hierarchical Policies for Web Actions using LLMs. (arXiv:2310.03720v1 [cs.LG])

    [http://arxiv.org/abs/2310.03720](http://arxiv.org/abs/2310.03720)

    这篇论文介绍了一个名为HeaP的框架，利用大型语言模型（LLMs）来解决Web任务的挑战。该框架将Web任务分解为子任务，并通过一系列低级的策略来执行，相比其他基准方法，该框架在不同的Web任务上表现出更好的性能。

    

    大型语言模型（LLMs）在少量数据和零-shot设置中展示了出色的指令跟随任务能力。然而，教授LLMs在Web上执行任务面临着基本挑战 - 组合性大的开放世界任务和Web接口之间的差异。我们通过利用LLMs将Web任务分解为一系列子任务来应对这些挑战，每个子任务可以通过一个低级的闭环策略来解决。这些策略构成了任务之间的共享语法，即新的Web任务可以作为这些策略的组合来表达。我们提出了一种新的框架，即基于LLMs的Hierarchical Policies for Web Actions（HeaP），该框架通过从示范中学习一组层次化的LLM提示来规划高级任务并通过一系列低级策略执行它们。我们通过一套Web任务，包括MiniWoB++，WebArena，模拟航空CRM以及实际网站来评估HeaP与一系列基准方法的性能。

    Large language models (LLMs) have demonstrated remarkable capabilities in performing a range of instruction following tasks in few and zero-shot settings. However, teaching LLMs to perform tasks on the web presents fundamental challenges -- combinatorially large open-world tasks and variations across web interfaces. We tackle these challenges by leveraging LLMs to decompose web tasks into a collection of sub-tasks, each of which can be solved by a low-level, closed-loop policy. These policies constitute a shared grammar across tasks, i.e., new web tasks can be expressed as a composition of these policies. We propose a novel framework, Hierarchical Policies for Web Actions using LLMs (HeaP), that learns a set of hierarchical LLM prompts from demonstrations for planning high-level tasks and executing them via a sequence of low-level policies. We evaluate HeaP against a range of baselines on a suite of web tasks, including MiniWoB++, WebArena, a mock airline CRM, as well as live website i
    
[^17]: 图神经网络中的局部差分隐私：一种重构方法

    Local Differential Privacy in Graph Neural Networks: a Reconstruction Approach. (arXiv:2309.08569v1 [cs.LG])

    [http://arxiv.org/abs/2309.08569](http://arxiv.org/abs/2309.08569)

    本研究提出了一种学习框架，旨在为用户提供节点隐私保护，并通过在节点级别对特征和标签数据进行随机化扰动来实现。通过频率估计和重构方法，实现了对扰动数据中特征和标签的恢复。

    

    图神经网络在各种应用中对建模复杂图数据取得了巨大成功。然而，有关GNN的隐私保护的研究还很有限。在本文中，我们提出了一个学习框架，可以在不丧失太多效用的情况下为用户提供节点隐私保护。我们关注一种去中心化的差分隐私概念，即局部差分隐私，并在数据被集中服务器进行模型训练之前，对节点级别的特征和标签数据应用随机化机制进行扰动。具体而言，我们研究了在高维特征设置中应用随机化机制的方法，并提出了具有严格隐私保证的LDP协议。基于随机化数据的统计分析中的频率估计，我们开发了重构方法来近似从扰动数据中恢复特征和标签。我们还制定了这个学习框架，利用了图聚类中的频率估计。

    Graph Neural Networks have achieved tremendous success in modeling complex graph data in a variety of applications. However, there are limited studies investigating privacy protection in GNNs. In this work, we propose a learning framework that can provide node privacy at the user level, while incurring low utility loss. We focus on a decentralized notion of Differential Privacy, namely Local Differential Privacy, and apply randomization mechanisms to perturb both feature and label data at the node level before the data is collected by a central server for model training. Specifically, we investigate the application of randomization mechanisms in high-dimensional feature settings and propose an LDP protocol with strict privacy guarantees. Based on frequency estimation in statistical analysis of randomized data, we develop reconstruction methods to approximate features and labels from perturbed data. We also formulate this learning framework to utilize frequency estimates of graph cluste
    
[^18]: 大规模动态系统中的观测部分、粗粒化和等变性在Koopman算子理论中的应用

    Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems. (arXiv:2307.15325v1 [math.DS])

    [http://arxiv.org/abs/2307.15325](http://arxiv.org/abs/2307.15325)

    本文解决了在大规模动态系统中部分观测或粗粒化的情况下，经典的EDMD算法不能准确提供Koopman算子近似的问题，并展示了将系统动态的对称性转移到Koopman算子可以显著提高模型效率。

    

    Koopman算子已经成为数据驱动分析、预测和控制复杂系统的重要工具，其主要原因是从测量中识别非线性动力学的线性函数空间表示的巨大潜力。然而，对于大规模系统，我们只能访问部分观测（如实验数据中非常常见的测量）或者出于效率原因刻意进行粗粒化的情况尚未得到充分研究。本文中，我们解决了这种情况中的困扰，即如果我们不仔细选择可观测数量，经典的EDMD算法不能自动提供潜在系统的Koopman算子近似。此外，我们还展示了系统动态中的对称性可以转移到Koopman算子中，从而大大提高模型的效率。我们还简要讨论了与域分解的联系。

    The Koopman operator has become an essential tool for data-driven analysis, prediction and control of complex systems, the main reason being the enormous potential of identifying linear function space representations of nonlinear dynamics from measurements. Until now, the situation where for large-scale systems, we (i) only have access to partial observations (i.e., measurements, as is very common for experimental data) or (ii) deliberately perform coarse graining (for efficiency reasons) has not been treated to its full extent. In this paper, we address the pitfall associated with this situation, that the classical EDMD algorithm does not automatically provide a Koopman operator approximation for the underlying system if we do not carefully select the number of observables. Moreover, we show that symmetries in the system dynamics can be carried over to the Koopman operator, which allows us to massively increase the model efficiency. We also briefly draw a connection to domain decompos
    
[^19]: 具有一致聚合的概率预测

    Probabilistic Forecasting with Coherent Aggregation. (arXiv:2307.09797v1 [cs.LG])

    [http://arxiv.org/abs/2307.09797](http://arxiv.org/abs/2307.09797)

    该论文提出了一种新的模型，利用因子模型结构来产生遵守层次结构的概率预测。模型利用卷积神经网络生成参数，并通过优化样本损失函数实现预测优化。

    

    在许多应用中，准确获得遵守层次结构的概率预测是一项重要的运营挑战，特别是在能源管理、供应链规划和资源配置等领域。对于多变量预测，基本挑战在于预测通常需要与层次结构保持一致。在本文中，我们提出了一种新的模型，利用因子模型结构通过构建来产生一致的预测。这是一个简单的观察结果（可交换性）：置换层次结构中的基本级别序列不会改变它们的聚合。我们的模型使用卷积神经网络来生成因子、它们的加载和基本级别分布的参数；它产生可以根据模型参数进行微分的样本；因此它可以对任何基于样本的损失函数进行优化，包括连续排名概率损失函数。

    Obtaining accurate probabilistic forecasts while respecting hierarchical information is an important operational challenge in many applications, perhaps most obviously in energy management, supply chain planning, and resource allocation. The basic challenge, especially for multivariate forecasting, is that forecasts are often required to be coherent with respect to the hierarchical structure. In this paper, we propose a new model which leverages a factor model structure to produce coherent forecasts by construction. This is a consequence of a simple (exchangeability) observation: permuting \textit{}base-level series in the hierarchy does not change their aggregates. Our model uses a convolutional neural network to produce parameters for the factors, their loadings and base-level distributions; it produces samples which can be differentiated with respect to the model's parameters; and it can therefore optimize for any sample-based loss function, including the Continuous Ranked Probabili
    
[^20]: SIMGA：一种简单有效的异质图神经网络结构与高效的全局聚合

    SIMGA: A Simple and Effective Heterophilous Graph Neural Network with Efficient Global Aggregation. (arXiv:2305.09958v1 [cs.LG])

    [http://arxiv.org/abs/2305.09958](http://arxiv.org/abs/2305.09958)

    本文章提出了一种简单有效的异质图神经网络模型SIMGA，它通过SimRank全局聚合来解决异质性节点聚合的问题，具有接近于线性的传播效率，同时具有良好的有效性和可扩展性。

    

    图神经网络在图学习领域取得了巨大成功，但遇到异质性时会出现性能下降，即因为局部和统一聚合而导致的相邻节点不相似。现有的异质性图神经网络中，试图整合全局聚合的尝试通常需要迭代地维护和更新全图信息，对于一个具有 $n$ 个节点的图，这需要 $\mathcal{O}(n^2)$ 的计算效率，从而导致对大型图的扩展性较差。在本文中，我们提出了 SIMGA，一种将 SimRank 结构相似度测量作为全局聚合的 GNN 结构。 SIMGA 的设计简单，且在效率和有效性方面都有着有 promising 的结果。SIMGA 的简单性使其成为第一个可以实现接近于线性的 $n$ 传播效率的异质性 GNN 模型。我们从理论上证明了它的有效性，将 SimRank 视为 GNN 的一种新解释，并证明了汇聚节点表示的有效性。

    Graph neural networks (GNNs) realize great success in graph learning but suffer from performance loss when meeting heterophily, i.e. neighboring nodes are dissimilar, due to their local and uniform aggregation. Existing attempts in incoorporating global aggregation for heterophilous GNNs usually require iteratively maintaining and updating full-graph information, which entails $\mathcal{O}(n^2)$ computation efficiency for a graph with $n$ nodes, leading to weak scalability to large graphs. In this paper, we propose SIMGA, a GNN structure integrating SimRank structural similarity measurement as global aggregation. The design of SIMGA is simple, yet it leads to promising results in both efficiency and effectiveness. The simplicity of SIMGA makes it the first heterophilous GNN model that can achieve a propagation efficiency near-linear to $n$. We theoretically demonstrate its effectiveness by treating SimRank as a new interpretation of GNN and prove that the aggregated node representation
    
[^21]: 基于基础模型的工具学习

    Tool Learning with Foundation Models. (arXiv:2304.08354v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08354](http://arxiv.org/abs/2304.08354)

    基于基础模型的工具学习结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。本文对工具学习进行了系统研究，提出了涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。

    

    人类拥有非凡的创造和利用工具的能力，使得他们能够克服物理限制并探索新的领域。随着基础模型的出现，AI系统有望像人类一样熟练地使用工具。这种范式即基于基础模型的工具学习，结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。尽管具有巨大潜力，但该领域仍缺乏对关键挑战、机会和未来发展的全面理解。针对这一问题，本文对工具学习进行了系统研究。首先介绍了工具学习的背景，包括其认知起源、基础模型的范式转换和工具和模型的互补作用。然后，我们回顾了现有的工具学习研究，包括基于工具和面向工具的学习。我们制定了一个涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。我们预计这种系统的探索将为未来开发具有复杂工具学习能力的AI系统提供一个跳板。

    Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of foundation models, AI systems have the potential to be equally adept in tool use as humans. This paradigm, i.e., tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool l
    
[^22]: 基于深度学习的智能手机显微镜图像中贾第虫和隐孢子的检测与计数

    Deep-learning assisted detection and quantification of (oo)cysts of Giardia and Cryptosporidium on smartphone microscopy images. (arXiv:2304.05339v1 [eess.IV])

    [http://arxiv.org/abs/2304.05339](http://arxiv.org/abs/2304.05339)

    本研究采用基于深度学习的RetinaNet模型针对采用智能手机显微系统检测贾第虫和隐孢子进行检测和计数，并在速度和准确度方面表现出最佳效果，为在资源有限的环境下解决这一问题提供了潜在解决方案。

    

    食用受微生物污染的食物和水每年造成数百万人死亡。基于智能手机的显微系统是一种便携、低成本和比传统的亮场显微镜更易接近的方法用于检测贾第虫和隐孢子。然而，智能手机显微镜的图像有很多噪声，需要培训有素的技术人员进行手动囊泡识别，而这通常在资源有限的环境中是不可用的。采用基于深度学习的对象检测自动检测卵/梭状体可能为此限制提供解决方案。我们评估了三种最先进的物体检测器在自定义数据集上检测贾第虫和隐孢子的效果，数据集包括从蔬菜样品中获取的智能手机和亮场显微镜图像。Faster RCNN、RetinaNet和You Only Look Once（YOLOv8s）深度学习模型被用来探索它们的有效性和限制。我们的结果表明，虽然深度学习模型能够准确地检测卵/梭状体，但RetinaNet在速度和准确度方面优于其他两种模型。本研究提供了一种潜在的解决方案，利用基于智能手机的显微系统在资源有限的环境中自动检测和计数贾第虫和隐孢子。

    The consumption of microbial-contaminated food and water is responsible for the deaths of millions of people annually. Smartphone-based microscopy systems are portable, low-cost, and more accessible alternatives for the detection of Giardia and Cryptosporidium than traditional brightfield microscopes. However, the images from smartphone microscopes are noisier and require manual cyst identification by trained technicians, usually unavailable in resource-limited settings. Automatic detection of (oo)cysts using deep-learning-based object detection could offer a solution for this limitation. We evaluate the performance of three state-of-the-art object detectors to detect (oo)cysts of Giardia and Cryptosporidium on a custom dataset that includes both smartphone and brightfield microscopic images from vegetable samples. Faster RCNN, RetinaNet, and you only look once (YOLOv8s) deep-learning models were employed to explore their efficacy and limitations. Our results show that while the deep-l
    
[^23]: 面向未知具有潜在状态系统的学习优化控制方法

    Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States. (arXiv:2303.17963v1 [eess.SY])

    [http://arxiv.org/abs/2303.17963](http://arxiv.org/abs/2303.17963)

    本文提出了一种面向未知具有潜在状态系统的学习优化控制方法，并给出了概率性能保证，同时提出了一种验证任意控制律性能的方法。

    

    随着控制工程方法应用于越来越复杂的系统，数据驱动的系统辨识方法成为物理建模的有希望的替代方法。然而，许多这些方法依赖于状态测量的可用性，而复杂系统的状态通常不是直接可测量的。因此，可能需要同时估计动力学和潜在状态，从而更加具有挑战性地设计具有性能保证的控制器。本文提出了一种新方法，用于计算具有潜在状态的未知非线性系统的最优输入轨迹。对结果输入轨迹进行了概率性能保证，并提出了一种验证任意控制律性能的方法。本文在数值模拟中展示了所提出方法的有效性。

    As control engineering methods are applied to increasingly complex systems, data-driven approaches for system identification appear as a promising alternative to physics-based modeling. While many of these approaches rely on the availability of state measurements, the states of a complex system are often not directly measurable. It may then be necessary to jointly estimate the dynamics and a latent state, making it considerably more challenging to design controllers with performance guarantees. This paper proposes a novel method for the computation of an optimal input trajectory for unknown nonlinear systems with latent states. Probabilistic performance guarantees are derived for the resulting input trajectory, and an approach to validate the performance of arbitrary control laws is presented. The effectiveness of the proposed method is demonstrated in a numerical simulation.
    
[^24]: 通过可学习的增强技术进行属性图聚类

    Attribute Graph Clustering via Learnable Augmentation. (arXiv:2212.03559v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03559](http://arxiv.org/abs/2212.03559)

    本研究提出了一种通过可学习增强技术进行属性图聚类的方法，该方法利用可学习的增强器为深度图聚类提供高质量和适合的增强样本，通过改进矩阵提高了聚类性能的可靠性。

    

    对比深度图聚类（CDGC）利用对比学习将节点分组到不同的簇中。更好的增强技术有助于提高对比样本的质量，因此成为改善性能的关键因素之一。然而，现有方法中的增强样本始终由人类经验预定义，并且与下游任务聚类无关，从而导致人力资源成本高和性能差。为此，我们提出了一种通过可学习增强技术进行属性图聚类的方法（AGCLA），为CDGC引入可学习的增强器，以获得高质量且适合的增强样本。具体而言，我们设计了两种可学习的增强器分别用于属性和结构信息。此外，生成了两个改进矩阵，包括高置信度伪标签矩阵和跨视图样本相似度矩阵，以提高学习的亲和矩阵的可靠性。在训练过程中，我们不断调整这些增强器和改进矩阵，以最大程度地提高聚类性能。

    Contrastive deep graph clustering (CDGC) utilizes contrastive learning to group nodes into different clusters. Better augmentation techniques benefit the quality of the contrastive samples, thus being one of key factors to improve performance. However, the augmentation samples in existing methods are always predefined by human experiences, and agnostic from the downstream task clustering, thus leading to high human resource costs and poor performance. To this end, we propose an Attribute Graph Clustering method via Learnable Augmentation (\textbf{AGCLA}), which introduces learnable augmentors for high-quality and suitable augmented samples for CDGC. Specifically, we design two learnable augmentors for attribute and structure information, respectively. Besides, two refinement matrices, including the high-confidence pseudo-label matrix and the cross-view sample similarity matrix, are generated to improve the reliability of the learned affinity matrix. During the training procedure, we no
    
[^25]: 用梯度分割方法缩小SVRG与TD-SVRG之间的差距

    Closing the gap between SVRG and TD-SVRG with Gradient Splitting. (arXiv:2211.16237v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16237](http://arxiv.org/abs/2211.16237)

    本论文通过将TD学习视为适当选择函数的梯度分割，将TD和SVRG相结合，实现了具有几何收敛速度的策略评估方法，并在理论和实验上得到了支持。

    

    TD（时序差分）学习是一种增强学习中的策略评估方法，其性能可以通过方差缩减技术进行增强。最近，多个工作尝试将TD学习与SVRG相结合，以获得一种具有几何收敛速度的策略评估方法。然而，在凸优化设置下，所得到的收敛速度明显不及SVRG。本研究利用最近对TD学习的解释，将其视为一个适当选择函数的梯度的分割，从而简化了算法，并将TD与SVRG相结合。我们的主要结果是一个具有预定学习速率为1/8的几何收敛界限，与凸设置下SVRG的收敛界限相同。我们的理论发现得到了一系列实验证明。

    Temporal difference (TD) learning is a policy evaluation in reinforcement learning whose performance can be enhanced by variance reduction techniques. Recently, multiple works have sought to fuse TD learning with SVRG to obtain a policy evaluation method with a geometric rate of convergence. However, the resulting convergence rate is significantly weaker than what is achieved by SVRG in the setting of convex optimization. In this work we utilize a recent interpretation of TD-learning as the splitting of the gradient of an appropriately chosen function, thus simplifying the algorithm and fusing TD with SVRG. Our main result is a geometric convergence bound with predetermined learning rate of $1/8$, which is identical to the convergence bound available for SVRG in the convex setting. Our theoretical findings are supported by a set of experiments.
    

