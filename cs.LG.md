# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](https://arxiv.org/abs/2404.02151) | 展示了对齐的LLM对简单自适应越狱攻击不具有鲁棒性，并成功实现了在多个模型上几乎100%的攻击成功率，同时还介绍了对于不公开logprobs的模型如何进行越狱以及如何在受污染的模型中查找木马字符串的方法。 |
| [^2] | [Contrastive Learning with Orthonormal Anchors (CLOA)](https://arxiv.org/abs/2403.18699) | 该研究提出了一种新的损失函数称为正交锚点回归损失，用于解开嵌入聚类，显著增强嵌入的独特性 |
| [^3] | [TransFusion: Contrastive Learning with Transformers](https://arxiv.org/abs/2403.18681) | TransFusion的主要创新在于定义了对比学习领域中的两个基本问题的理论极限，并成功实现了从复杂的现实世界数据中提取特征以改善分类精度。 |
| [^4] | [A Moreau Envelope Approach for LQR Meta-Policy Estimation](https://arxiv.org/abs/2403.17364) | 提出了一种基于Moreau包络的替代LQR成本，可有效调整到新实现的元策略，并设计了找到近似一阶稳定点的算法。 |
| [^5] | [An Analysis of Switchback Designs in Reinforcement Learning](https://arxiv.org/abs/2403.17285) | 本文通过提出“弱信号分析”框架，研究了强化学习中往返设计对平均处理效应估计准确性的影响，发现在大部分奖励误差为正相关时，往返设计比每日切换策略更有效，增加政策切换频率可以降低平均处理效应估计器的均方误差。 |
| [^6] | [VL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning](https://arxiv.org/abs/2403.13164) | 大型语言模型的视觉变种在识别、推理和基准确定等领域取得了显著进展，但多模态上下文学习的广泛能力和限制仍未得到充分探讨。 |
| [^7] | [Generalized Consistency Trajectory Models for Image Manipulation](https://arxiv.org/abs/2403.12510) | 本研究提出了广义一致性轨迹模型（GCTMs），能够在任何噪声分布和数据分布之间实现转换。 |
| [^8] | [A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models](https://arxiv.org/abs/2403.12025) | 提出了用于揭示大型语言模型中健康公平危害和偏见的资源和方法，进行了实证案例研究，并提出了用于人类评估LLM生成答案偏见的多因子框架以及EquityMedQA数据集。 |
| [^9] | [A Neural-Evolutionary Algorithm for Autonomous Transit Network Design](https://arxiv.org/abs/2403.07917) | 提出了一种神经进化算法用于自动公交网络设计，该算法通过训练图神经网络模型作为策略，并将其用作进化算法中的变异操作符，在公交网络设计基准集上优于单独学习策略和简单进化算法方法。 |
| [^10] | [Editing Conceptual Knowledge for Large Language Models](https://arxiv.org/abs/2403.06259) | 该论文首次研究了为大型语言模型编辑概念知识，通过构建基准数据集和建立新评估指标，发现现有方法虽然能一定程度上修改概念定义，但也可能造成LLMs中相关实例知识的扭曲，导致性能下降。 |
| [^11] | [Matrix Completion with Convex Optimization and Column Subset Selection](https://arxiv.org/abs/2403.01919) | 该方法结合了列子集选择和低秩矩阵完成问题的理论基础，提出使用凸优化解决矩阵恢复问题，同时通过实验验证了算法的正确性和性能。 |
| [^12] | [High-Dimensional Tail Index Regression: with An Application to Text Analyses of Viral Posts in Social Media](https://arxiv.org/abs/2403.01318) | 提出了高维尾指数回归方法，利用正则化估计和去偏方法进行推断，支持理论的仿真研究，并在社交媒体病毒帖子文本分析中应用。 |
| [^13] | [SELFI: Autonomous Self-Improvement with Reinforcement Learning for Social Navigation](https://arxiv.org/abs/2403.00991) | SELFI提出了一种在线学习方法，通过将在线无模型强化学习与离线基于模型的学习相结合，实现了机器人行为的快速改进，并在避撞和社交遵从行为方面取得了显著进展。 |
| [^14] | [Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2402.17840) | 研究揭示了检索增强生成系统中的数据泄露风险，指出对手可以利用LMs的指示遵循能力轻松地从数据存储中直接提取文本数据，并设计了攻击对生产RAG模型GPTs造成数据存储泄漏。 |
| [^15] | [Spectrum Extraction and Clipping for Implicitly Linear Layers](https://arxiv.org/abs/2402.16017) | 展示自动微分在计算和控制隐式线性算子频谱中的有效性；提供第一个适用于一般卷积层的裁剪方法；研究了批归一化层与卷积层组合的效果；通过比较算法与最先进方法的精度和性能表明更精确和高效。 |
| [^16] | [QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs](https://arxiv.org/abs/2402.15929) | 本文提出了一种新颖的认证框架QuaCer-C，用于正式认证大型语言模型中知识理解的能力，证书定量化且包含高置信度的概率界限，研究发现，随着参数数量的增加，知识理解能力提高，Mistral模型在这一评估中表现不如其他模型。 |
| [^17] | [On Minimal Depth in Neural Networks](https://arxiv.org/abs/2402.15315) | 本研究研究了神经网络中关于最小深度的问题，特别关注了ReLU神经网络的表达能力和最小深度与CPWL函数的关系。 |
| [^18] | [Linear Dynamics-embedded Neural Network for Long-Sequence Modeling](https://arxiv.org/abs/2402.15290) | 提出了一种名为嵌入线性动力学的神经网络（LDNN），通过引入连续状态空间模型的属性和优化策略，实现了在长序列任务中具有少量参数、灵活推断和高效训练，最终在长距离竞技场上取得了有效且领先的性能。 |
| [^19] | [Large-Scale Actionless Video Pre-Training via Discrete Diffusion for Efficient Policy Learning](https://arxiv.org/abs/2402.14407) | 利用离散扩散结合生成式预训练和少量机器人视频微调，实现从人类视频到机器人策略学习的知识迁移。 |
| [^20] | [Numerical Claim Detection in Finance: A New Financial Dataset, Weak-Supervision Model, and Market Analysis](https://arxiv.org/abs/2402.11728) | 本研究探讨了分析师报告和盈利电话中的索赔对金融市场回报的影响，并构建了一个新的金融数据集用于索赔检测任务。提出了一种融入主题专家知识的新型弱监督模型，通过构建一种新的度量“乐观主义”展示了模型的实际效用。 |
| [^21] | [An Elementary Predictor Obtaining $2\sqrt{T}$ Distance to Calibration](https://arxiv.org/abs/2402.11410) | 给出了一种简单、高效、确定性的算法，该算法的校准距离误差最多为$2\sqrt{T}$ |
| [^22] | [Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models](https://arxiv.org/abs/2402.10353) | 本研究提出了一种空输入提示方法，用于校准预训练语言模型中的固有偏差，从而提升零/少样本学习的性能。 |
| [^23] | [Switch EMA: A Free Lunch for Better Flatness and Sharpness](https://arxiv.org/abs/2402.09240) | 本研究提出了一种称为Switch EMA（SEMA）的方法，通过简单的修改指数移动平均（EMA）参数，可以帮助深度神经网络（DNN）达到更好的平坦性和锐度的概括最优解。通过在多个任务和数据集上进行实验证明了SEMA的有效性。 |
| [^24] | [IR-Aware ECO Timing Optimization Using Reinforcement Learning](https://arxiv.org/abs/2402.07781) | 本文提出了一种使用强化学习进行IR感知的ECO时序优化的方法，该方法通过门尺寸调整纠正由IR降低引起的时序退化，并且相较于传统方法在性能和运行时间上都具有优势。 |
| [^25] | [The SpongeNet Attack: Sponge Weight Poisoning of Deep Neural Networks](https://arxiv.org/abs/2402.06357) | 本文提出了一种名为 SpongeNet 的新型海绵攻击，通过直接作用于预训练模型参数，成功增加了视觉模型的能耗，而且所需的样本数量更少。 |
| [^26] | [Learning Contrastive Feature Representations for Facial Action Unit Detection](https://arxiv.org/abs/2402.06165) | 这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。 |
| [^27] | [Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding](https://arxiv.org/abs/2402.05109) | Hydra heads是一种循序依赖的草稿头部，取代了标准草稿头部，显著提高了推测准确性，在Medusa解码中具有更高的吞吐量。 |
| [^28] | [Preference-free Alignment Learning with Regularized Relevance Reward](https://arxiv.org/abs/2402.03469) | 无偏好对齐学习使用正则化相关奖励作为关键目标，在提供稳健奖励信号的同时，显著提高了偏好基准测试的性能。 |
| [^29] | [Conversation Reconstruction Attack Against GPT Models](https://arxiv.org/abs/2402.02987) | 本文介绍了一种针对 GPT 模型的对话重构攻击，该攻击具有劫持会话和重构对话的两个步骤。通过对该攻击对 GPT 模型的隐私风险进行评估，发现 GPT-4 对该攻击具有一定的鲁棒性。 |
| [^30] | [Large Language Models are Geographically Biased](https://arxiv.org/abs/2402.02680) | 本文研究了大型语言模型的地理偏见，并展示了其对地理空间预测的系统错误，通过零射击地理空间预测来评估其对世界的认知。 |
| [^31] | [Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics](https://arxiv.org/abs/2312.11834) | 通过使用回声状态网络将行人实现为MARL代理，研究了他们学习避让其他代理向前移动的能力，在密度不太高的情况下取得成功。 |
| [^32] | [Dr. Jekyll and Mr. Hyde: Two Faces of LLMs](https://arxiv.org/abs/2312.03853) | 本研究通过让ChatGPT和Bard冒充复杂人物角色，绕过了安全机制和专门训练程序，展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。 |
| [^33] | [Directions of Curvature as an Explanation for Loss of Plasticity](https://arxiv.org/abs/2312.00246) | 曲率方向的丧失被认为是导致神经网络可塑性丧失的一个重要原因，并且我们通过系统调查和在多个任务中的研究结果支持了这一观点。 |
| [^34] | [Compelling ReLU Network Initialization and Training to Leverage Exponential Scaling with Depth](https://arxiv.org/abs/2311.18022) | 该论文提出了一种新的训练策略，通过重新参数化网络权重，使得神经网络的指数数量的激活模式得以展现，从而得到远远超过随机初始化的结果。 |
| [^35] | [Multiply Robust Causal Mediation Analysis with Continuous Treatments](https://arxiv.org/abs/2105.09254) | 本文提出了一种适用于连续治疗环境的多重稳健因果中介分析估计器，采用了核平滑方法，并具有多重稳健性和渐近正态性。 |
| [^36] | [On the Convergence of Hermitian Dynamic Mode Decomposition.](http://arxiv.org/abs/2401.03192) | 研究了Hermitian动态模态分解(DMD)对自伴随Koopman算子的谱性质的收敛性，通过建立了关于谱测度收敛性的一般定理，证明了HDMD的特征值和特征函数在适当条件下收敛到基础Koopman算子的谱性质。 |
| [^37] | [Data-Centric Foundation Models in Computational Healthcare: A Survey.](http://arxiv.org/abs/2401.02458) | 计算医疗中的数据中心基础模型是一项调查研究，为医疗工作流程的改进提供了基于数据的人工智能方法，并讨论了安全性、评估和与人类价值观的一致性。基于FM的分析有望提高患者结果和临床工作流程表现。 |
| [^38] | [The Power of Training: How Different Neural Network Setups Influence the Energy Demand.](http://arxiv.org/abs/2401.01851) | 本文研究了机器学习训练方案和学习范式对能源消耗的影响，并探讨了预训练和多任务训练在可持续机器学习方面的潜力。 |
| [^39] | [Speak Like a Native: Prompting Large Language Models in a Native Style.](http://arxiv.org/abs/2311.13538) | 本文提出了一种名为AlignedCoT的新颖有效方法，通过将上下文示例与大型语言模型（LLMs）的母语风格对齐，提高了LLMs的推理能力和性能。 |
| [^40] | [Hierarchical Ensemble-Based Feature Selection for Time Series Forecasting.](http://arxiv.org/abs/2310.17544) | 这项研究提出了一种基于层次集成的特征选择方法，能够克服传统方法和最先进方法在非平稳和特征数目庞大且样本有限的情况下的局限性，并在合成和实际数据集上展示了更好的性能。 |
| [^41] | [Learning Successor Representations with Distributed Hebbian Temporal Memory.](http://arxiv.org/abs/2310.13391) | 本文提出了一种名为DHTM的算法，它基于因子图形式和多组成神经元模型，利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则来解决在线隐藏表示学习的挑战。实验结果表明，DHTM在变化的环境中比经典的LSTM效果更好，并与更先进的类似RNN的算法性能相当，可以加速继任者表示的时间差异学习。 |
| [^42] | [Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark.](http://arxiv.org/abs/2310.12567) | 本文介绍了一个名为Safety-Gymnasium的环境套件，其中包括单个和多个Agent场景中的安全关键任务，并提供了一个包含16种最先进的SafeRL算法的算法库。这个基准旨在促进对安全性能的评估和比较，推动强化学习在安全性能上的发展。 |
| [^43] | [Advancing Test-Time Adaptation for Acoustic Foundation Models in Open-World Shifts.](http://arxiv.org/abs/2310.09505) | 本文提出了一种针对声学基础模型的测试时间自适应方法，以解决开放世界数据转换中的分布变化问题。研究发现，噪声较大的语音帧包含重要的语义内容。 |
| [^44] | [Prosody Analysis of Audiobooks.](http://arxiv.org/abs/2310.06930) | 本研究通过使用一个含有93个书籍和对应有声书的数据集，提出了改进的模型来预测有声书文本中的韵律属性。结果显示，我们的预测韵律与人类朗读比商业级TTS系统更相关，并且人们更喜欢韵律增强的有声书朗读。 |
| [^45] | [Uncertainty-Aware Decision Transformer for Stochastic Driving Environments.](http://arxiv.org/abs/2309.16397) | 本论文提出了一种针对随机驾驶环境的不确定性感知决策Transformer（UNREST），通过估计状态的不确定性并相应地分割序列，取代了全局回报。这项工作通过解决在不确定性环境中过于乐观的问题，为离线强化学习在自主驾驶任务中的应用提供了一种有效的解决方案。 |
| [^46] | [NoSENSE: Learned unrolled cardiac MRI reconstruction without explicit sensitivity maps.](http://arxiv.org/abs/2309.15608) | 本文提出了一种无需显式灵敏度图的展开心脏MRI重建方法，使用深度卷积神经网络和算法展开，通过学习图像之间的接收线圈关系来实现加速心脏MRI重建，在实验中取得了较好的性能。 |
| [^47] | [Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer ReLU Neural Networks.](http://arxiv.org/abs/2309.15244) | 本文提出了一种名为同伦松弛训练算法（HRTA）的新的训练方法，它通过构建无缝连接线性激活函数和ReLU激活函数的同伦激活函数，并松弛同伦参数以增强训练精细化过程，加速了训练过程，在神经切线核（NTK）的背景下，实现了显著改进的收敛速度，并展示了对其他激活函数和深度神经网络的潜力。 |
| [^48] | [Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation.](http://arxiv.org/abs/2309.01860) | 本文提出了一种注意力驱动的多模态融合机制，通过将光流信息与RGB图像相结合，丰富了连续手语识别和翻译流程中的特征。该方法在手语识别任务中降低了WER 0.9，在翻译任务中提高了测试集上大多数BLEU分数约0.6。 |
| [^49] | [An engine to simulate insurance fraud network data.](http://arxiv.org/abs/2308.11659) | 本论文介绍了一种模拟保险欺诈网络数据的引擎，利用索赔涉及方的社交网络特征进行学习方法，旨在开发高效准确的欺诈检测模型。但面临类别不平衡、大量未标记数据和缺乏公开数据等挑战。 |
| [^50] | [Classification of Blood Cells Using Deep Learning Models.](http://arxiv.org/abs/2308.06300) | 这项研究使用深度学习模型通过图像分类对人类血细胞进行了分类和识别，为诊断疾病提供了重要的帮助。 |
| [^51] | [Context-Conditional Navigation with a Learning-Based Terrain- and Robot-Aware Dynamics Model.](http://arxiv.org/abs/2307.09206) | 本文提出了一种名为TRADYN的概率地形和机器人感知前向动力学模型，能够适应在自主导航环境中的地形和机器人的变化，通过在模拟的二维导航环境中的实验证明，该模型在长视程轨迹预测任务中表现出较低的预测误差。 |
| [^52] | [Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation.](http://arxiv.org/abs/2307.05385) | 本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。 |
| [^53] | [Representation Learning on Hyper-Relational and Numeric Knowledge Graphs with Transformers.](http://arxiv.org/abs/2305.18256) | 本文提出了一个名为HyNT的框架，用于学习超关系型知识图的表示，包括数值文字。该框架使用上下文Transformer和预测Transformer，通过学习三元组和其限定词之间的相关性以及数值信息来获得模型。 |
| [^54] | [Loss Spike in Training Neural Networks.](http://arxiv.org/abs/2305.12133) | 本文研究神经网络训练过程中损失值峰值现象的机制，并发现最大特征值的第一个特征向量的偏差主要受低频成分占据。低频成分可以被训练数据和测试数据很好地捕获，所以导致具有良好和劣质泛化能力的解决方案都可以很好地学习低频成分，但劣质泛化能力的解决方案可能会过度拟合高频成分，良好泛化能力的解决方案具有更平滑的损失函数。 |
| [^55] | [SREL: Severity Rating Ensemble Learning for Non-Destructive Fault Diagnosis of Cu Interconnects using S-parameter Patterns.](http://arxiv.org/abs/2304.10207) | 本研究利用S参数模式成功实现对Cu互连缺陷的非破坏性检测和诊断，在同时分析根本原因和严重性方面具有先进性，具备早期检测、高诊断准确度和噪声鲁棒性等优点。 |
| [^56] | [PI-FL: Personalized and Incentivized Federated Learning.](http://arxiv.org/abs/2304.07514) | PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。 |
| [^57] | [Latent-Conditioned Policy Gradient for Multi-Objective Deep Reinforcement Learning.](http://arxiv.org/abs/2303.08909) | 该论文提出了一种新的多目标深度强化学习算法，通过策略梯度训练单个神经网络，以在单次训练运行中近似获取整个帕累托集，而不依赖于目标的线性标量化。 |
| [^58] | [An active learning method for solving competitive multi-agent decision-making and control problems.](http://arxiv.org/abs/2212.12561) | 我们提出了一个基于主动学习的方法，用于解决竞争性多智能体决策和控制问题。通过重构私有策略和预测稳态行动配置文件，外部观察者可以成功进行预测和优化策略。 |

# 详细

[^1]: 用简单自适应攻击越狱功能对齐的LLM

    Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks

    [https://arxiv.org/abs/2404.02151](https://arxiv.org/abs/2404.02151)

    展示了对齐的LLM对简单自适应越狱攻击不具有鲁棒性，并成功实现了在多个模型上几乎100%的攻击成功率，同时还介绍了对于不公开logprobs的模型如何进行越狱以及如何在受污染的模型中查找木马字符串的方法。

    

    我们展示了即使是最新的安全对齐的LLM也不具有抵抗简单自适应越狱攻击的稳健性。首先，我们展示了如何成功利用对logprobs的访问进行越狱：我们最初设计了一个对抗性提示模板（有时会适应目标LLM），然后我们在后缀上应用随机搜索以最大化目标logprob（例如token“Sure”），可能会进行多次重启。通过这种方式，我们实现了对GPT-3.5/4、Llama-2-Chat-7B/13B/70B、Gemma-7B和针对GCG攻击进行对抗训练的HarmBench上的R2D2等几乎100%的攻击成功率--根据GPT-4的评判。我们还展示了如何通过转移或预填充攻击以100%的成功率对所有不暴露logprobs的Claude模型进行越狱。此外，我们展示了如何在受污染的模型中使用对一组受限制的token执行随机搜索以查找木马字符串的方法--这项任务与许多其他任务共享相同的属性。

    arXiv:2404.02151v1 Announce Type: cross  Abstract: We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks. First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize the target logprob (e.g., of the token "Sure"), potentially with multiple restarts. In this way, we achieve nearly 100\% attack success rate -- according to GPT-4 as a judge -- on GPT-3.5/4, Llama-2-Chat-7B/13B/70B, Gemma-7B, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with 100\% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many s
    
[^2]: 具有正交锚点的对比学习（CLOA）

    Contrastive Learning with Orthonormal Anchors (CLOA)

    [https://arxiv.org/abs/2403.18699](https://arxiv.org/abs/2403.18699)

    该研究提出了一种新的损失函数称为正交锚点回归损失，用于解开嵌入聚类，显著增强嵌入的独特性

    

    本研究关注解决对比学习中普遍存在的不稳定性问题，特别是检查InfoNCE损失函数及其导数。我们揭示了一个关键观察，即这些损失函数表现出限制性行为，导致嵌入趋于融合为一个奇异点的收敛现象。这种“过度融合”效应对后续监督学习任务中的分类准确性产生不利影响。通过理论分析，我们证明了嵌入在等于或局限于秩-1线性子空间时表示InfoNCE的局部最小值。针对这一挑战，我们的研究提出了一种创新策略，利用与微调阶段典型使用的相同或更少的标记数据。我们提出的损失函数，即正交锚点回归损失，旨在解开嵌入聚类，显著增强每个嵌入的独特性。

    arXiv:2403.18699v1 Announce Type: cross  Abstract: This study focuses on addressing the instability issues prevalent in contrastive learning, specifically examining the InfoNCE loss function and its derivatives. We reveal a critical observation that these loss functions exhibit a restrictive behavior, leading to a convergence phenomenon where embeddings tend to merge into a singular point. This "over-fusion" effect detrimentally affects classification accuracy in subsequent supervised-learning tasks. Through theoretical analysis, we demonstrate that embeddings, when equalized or confined to a rank-1 linear subspace, represent a local minimum for InfoNCE. In response to this challenge, our research introduces an innovative strategy that leverages the same or fewer labeled data than typically used in the fine-tuning phase. The loss we proposed, Orthonormal Anchor Regression Loss, is designed to disentangle embedding clusters, significantly enhancing the distinctiveness of each embedding 
    
[^3]: TransFusion：具有变压器的对比学习

    TransFusion: Contrastive Learning with Transformers

    [https://arxiv.org/abs/2403.18681](https://arxiv.org/abs/2403.18681)

    TransFusion的主要创新在于定义了对比学习领域中的两个基本问题的理论极限，并成功实现了从复杂的现实世界数据中提取特征以改善分类精度。

    

    这篇论文提出了一个新的框架，TransFusion，旨在使对比学习的过程更具分析性和可解释性。 TransFusion由注意力块组成，其中的softmax被替换为ReLU，并且其最终块的加权和操作被截断，以使邻接矩阵成为输出。该模型通过最小化其输出与目标关联矩阵之间的Jensen-Shannon散度来进行训练，该矩阵指示每对样本是否属于相同类别或不同类别。 TransFusion的主要贡献在于定义了回答该领域两个基本问题的理论极限：数据增强的最大级别和有效对比学习所需的最小批量大小。 此外，实验结果表明，TransFusion成功地提取出能够从复杂的现实世界数据中分离集群的特征，从而提高了分类精度。

    arXiv:2403.18681v1 Announce Type: cross  Abstract: This paper proposes a novel framework, TransFusion, designed to make the process of contrastive learning more analytical and explainable. TransFusion consists of attention blocks whose softmax being replaced by ReLU, and its final block's weighted-sum operation is truncated to leave the adjacency matrix as the output. The model is trained by minimizing the Jensen-Shannon Divergence between its output and the target affinity matrix, which indicates whether each pair of samples belongs to the same or different classes. The main contribution of TransFusion lies in defining a theoretical limit for answering two fundamental questions in the field: the maximum level of data augmentation and the minimum batch size required for effective contrastive learning. Furthermore, experimental results indicate that TransFusion successfully extracts features that isolate clusters from complex real-world data, leading to improved classification accuracy 
    
[^4]: 一种适用于LQR元策略估计的Moreau包络方法

    A Moreau Envelope Approach for LQR Meta-Policy Estimation

    [https://arxiv.org/abs/2403.17364](https://arxiv.org/abs/2403.17364)

    提出了一种基于Moreau包络的替代LQR成本，可有效调整到新实现的元策略，并设计了找到近似一阶稳定点的算法。

    

    我们研究了在线性时不变离散时间不确定动态系统中的线性二次型调节器（LQR）策略估计问题。我们提出了一种基于Moreau包络的替代LQR成本，由不确定系统的有限实现构建，以定义一个对新实现有效调整的元策略。此外，我们设计了一个算法来找到元LQR成本函数的近似一阶稳定点。数值结果表明，所提出的方法在新实现的线性系统上胜过了控制器的朴素平均。我们还提供了实证证据表明，我们的方法比模型不可知元学习（MAML）方法具有更好的样本复杂性。

    arXiv:2403.17364v1 Announce Type: cross  Abstract: We study the problem of policy estimation for the Linear Quadratic Regulator (LQR) in discrete-time linear time-invariant uncertain dynamical systems. We propose a Moreau Envelope-based surrogate LQR cost, built from a finite set of realizations of the uncertain system, to define a meta-policy efficiently adjustable to new realizations. Moreover, we design an algorithm to find an approximate first-order stationary point of the meta-LQR cost function. Numerical results show that the proposed approach outperforms naive averaging of controllers on new realizations of the linear system. We also provide empirical evidence that our method has better sample complexity than Model-Agnostic Meta-Learning (MAML) approaches.
    
[^5]: 对强化学习中的往返设计进行的分析

    An Analysis of Switchback Designs in Reinforcement Learning

    [https://arxiv.org/abs/2403.17285](https://arxiv.org/abs/2403.17285)

    本文通过提出“弱信号分析”框架，研究了强化学习中往返设计对平均处理效应估计准确性的影响，发现在大部分奖励误差为正相关时，往返设计比每日切换策略更有效，增加政策切换频率可以降低平均处理效应估计器的均方误差。

    

    本文提供了对A/B测试中往返设计的详细研究，这些设计随时间在基准和新策略之间交替。我们的目标是全面评估这些设计对其产生的平均处理效应（ATE）估计器准确性的影响。我们提出了一个新颖的“弱信号分析”框架，大大简化了这些ATE的均方误差（MSE）在马尔科夫决策过程环境中的计算。我们的研究结果表明：(i) 当大部分奖励误差呈正相关时，往返设计比每日切换策略的交替设计更有效。此外，增加政策切换的频率往往会降低ATE估计器的MSE。(ii) 然而，当误差不相关时，所有这些设计变得渐近等效。(iii) 在大多数误差为负相关时

    arXiv:2403.17285v1 Announce Type: cross  Abstract: This paper offers a detailed investigation of switchback designs in A/B testing, which alternate between baseline and new policies over time. Our aim is to thoroughly evaluate the effects of these designs on the accuracy of their resulting average treatment effect (ATE) estimators. We propose a novel "weak signal analysis" framework, which substantially simplifies the calculations of the mean squared errors (MSEs) of these ATEs in Markov decision process environments. Our findings suggest that (i) when the majority of reward errors are positively correlated, the switchback design is more efficient than the alternating-day design which switches policies in a daily basis. Additionally, increasing the frequency of policy switches tends to reduce the MSE of the ATE estimator. (ii) When the errors are uncorrelated, however, all these designs become asymptotically equivalent. (iii) In cases where the majority of errors are negative correlate
    
[^6]: VL-ICL Bench: 基于细节的多模态上下文学习基准测试中的细节之魔

    VL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning

    [https://arxiv.org/abs/2403.13164](https://arxiv.org/abs/2403.13164)

    大型语言模型的视觉变种在识别、推理和基准确定等领域取得了显著进展，但多模态上下文学习的广泛能力和限制仍未得到充分探讨。

    

    大型语言模型（LLMs）以其著名的出现式上下文学习（ICL）而闻名——即在仅提供几个示例作为提示的情况下，快速适应新任务的能力，而无需更新模型的权重。构建在LLMs之上的视觉大型语言模型（VLLMs）在识别、推理和基准确定等领域取得了显著进展。然而，对于\emph{多模态ICL}的研究主要集中在少样本视觉问题回答（VQA）和图像字幕上，我们将展示二者既没有充分利用ICL的优势，也没有测试其限制。对多模态ICL的更广泛能力和局限性尚未得到充分探讨。在本研究中，我们引入了一个全面的多模态上下文学习基准测试 VL-ICL Bench，涵盖了涉及图像和文本作为输入和输出的广泛任务范围，并涵盖了从{感知到推理和长期上下文长度}的不同类型挑战。

    arXiv:2403.13164v1 Announce Type: new  Abstract: Large language models (LLMs) famously exhibit emergent in-context learning (ICL) -- the ability to rapidly adapt to new tasks using few-shot examples provided as a prompt, without updating the model's weights. Built on top of LLMs, vision large language models (VLLMs) have advanced significantly in areas such as recognition, reasoning, and grounding. However, investigations into \emph{multimodal ICL} have predominantly focused on few-shot visual question answering (VQA), and image captioning, which we will show neither exploit the strengths of ICL, nor test its limitations. The broader capabilities and limitations of multimodal ICL remain under-explored. In this study, we introduce a comprehensive benchmark VL-ICL Bench for multimodal in-context learning, encompassing a broad spectrum of tasks that involve both images and text as inputs and outputs, and different types of challenges, from {perception to reasoning and long context length}
    
[^7]: 图像操作的广义一致性轨迹模型

    Generalized Consistency Trajectory Models for Image Manipulation

    [https://arxiv.org/abs/2403.12510](https://arxiv.org/abs/2403.12510)

    本研究提出了广义一致性轨迹模型（GCTMs），能够在任何噪声分布和数据分布之间实现转换。

    

    基于扩散的生成模型在无条件生成以及图像编辑和恢复等应用任务中表现出色。扩散模型的成功在于扩散的迭代性质：扩散将将噪声到数据的复杂映射过程分解为一系列简单的去噪任务。此外，通过在每个去噪步骤中注入引导项，我们能够对生成过程进行精细控制。然而，迭代过程也常常计算密集，通常需要进行数十次甚至数千次函数评估。虽然一致性轨迹模型（CTMs）可以在概率流ODE（PFODE）上任意时间点之间进行遍历，并且通过单次函数评估进行得分推导，但CTMs仅允许从高斯噪声转换为数据。因此，本文旨在通过提出广义CTMs（GCTMs）来发挥CTMs的全部潜力，实现在任何噪声分布和数据分布之间进行转换。

    arXiv:2403.12510v1 Announce Type: cross  Abstract: Diffusion-based generative models excel in unconditional generation, as well as on applied tasks such as image editing and restoration. The success of diffusion models lies in the iterative nature of diffusion: diffusion breaks down the complex process of mapping noise to data into a sequence of simple denoising tasks. Moreover, we are able to exert fine-grained control over the generation process by injecting guidance terms into each denoising step. However, the iterative process is also computationally intensive, often taking from tens up to thousands of function evaluations. Although consistency trajectory models (CTMs) enable traversal between any time points along the probability flow ODE (PFODE) and score inference with a single function evaluation, CTMs only allow translation from Gaussian noise to data. Thus, this work aims to unlock the full potential of CTMs by proposing generalized CTMs (GCTMs), which translate between arbit
    
[^8]: 一个用于揭示大型语言模型中健康公平危害和偏见的工具箱

    A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models

    [https://arxiv.org/abs/2403.12025](https://arxiv.org/abs/2403.12025)

    提出了用于揭示大型语言模型中健康公平危害和偏见的资源和方法，进行了实证案例研究，并提出了用于人类评估LLM生成答案偏见的多因子框架以及EquityMedQA数据集。

    

    大型语言模型（LLMs）有着为复杂的健康信息需求提供服务的巨大潜力，但同时也有可能引入危害并加剧健康不平等。可靠地评估与公平相关的模型失灵是发展促进健康公平系统的关键步骤。在这项工作中，我们提出了用于揭示可能导致LLM生成的长篇答案中的公平相关危害的偏见的资源和方法，并使用Med-PaLM 2进行了一项实证案例研究，这是迄今为止在该领域进行的最大规模的人类评估研究。我们的贡献包括用于人类评估LLM生成答案偏见的多因子框架，以及EquityMedQA，一个包含七个新发布数据集的收集，其中既包括手动策划又包括LLM生成的问题，丰富了对抗性查询。我们的人类评估框架和数据集设计过程都根植于实际

    arXiv:2403.12025v1 Announce Type: cross  Abstract: Large language models (LLMs) hold immense promise to serve complex health information needs but also have the potential to introduce harm and exacerbate health disparities. Reliably evaluating equity-related model failures is a critical step toward developing systems that promote health equity. In this work, we present resources and methodologies for surfacing biases with potential to precipitate equity-related harms in long-form, LLM-generated answers to medical questions and then conduct an empirical case study with Med-PaLM 2, resulting in the largest human evaluation study in this area to date. Our contributions include a multifactorial framework for human assessment of LLM-generated answers for biases, and EquityMedQA, a collection of seven newly-released datasets comprising both manually-curated and LLM-generated questions enriched for adversarial queries. Both our human assessment framework and dataset design process are grounde
    
[^9]: 用于自主公交网络设计的神经进化算法

    A Neural-Evolutionary Algorithm for Autonomous Transit Network Design

    [https://arxiv.org/abs/2403.07917](https://arxiv.org/abs/2403.07917)

    提出了一种神经进化算法用于自动公交网络设计，该算法通过训练图神经网络模型作为策略，并将其用作进化算法中的变异操作符，在公交网络设计基准集上优于单独学习策略和简单进化算法方法。

    

    规划公共交通网络是一个具有挑战性的优化问题，但是为了实现自动驾驶公交车的好处是至关重要的。我们提出了一种新颖的算法，用于规划自动驾驶公交车的路线网络。我们首先训练一个图神经网络模型作为构建路线网络的策略，然后将该策略用作进化算法中的多个变异操作符之一。我们在标准的公交网络设计基准集上评估这种算法，并发现它在现实基准实例上的表现比单独学习的策略高出高达20\%，比简单的进化算法方法高出高达53%。

    arXiv:2403.07917v1 Announce Type: cross  Abstract: Planning a public transit network is a challenging optimization problem, but essential in order to realize the benefits of autonomous buses. We propose a novel algorithm for planning networks of routes for autonomous buses. We first train a graph neural net model as a policy for constructing route networks, and then use the policy as one of several mutation operators in a evolutionary algorithm. We evaluate this algorithm on a standard set of benchmarks for transit network design, and find that it outperforms the learned policy alone by up to 20\% and a plain evolutionary algorithm approach by up to 53\% on realistic benchmark instances.
    
[^10]: 大型语言模型的概念知识编辑

    Editing Conceptual Knowledge for Large Language Models

    [https://arxiv.org/abs/2403.06259](https://arxiv.org/abs/2403.06259)

    该论文首次研究了为大型语言模型编辑概念知识，通过构建基准数据集和建立新评估指标，发现现有方法虽然能一定程度上修改概念定义，但也可能造成LLMs中相关实例知识的扭曲，导致性能下降。

    

    最近，对于大型语言模型（LLMs）的知识编辑引起了越来越多的关注。当前的方法和评估仅探讨了实例级别的编辑，然而LLMs是否具有修改概念的能力仍不清楚。本文首次研究了为LLMs编辑概念知识，通过构建一个新颖的基准数据集ConceptEdit并建立了一套新的评估指标。实验结果表明，尽管现有的编辑方法可以有效地在一定程度上修改概念级别的定义，但它们也有潜力扭曲LLMs中相关的实例知识，导致性能不佳。我们期望这可以激发对更好理解LLMs的进一步进展。我们的项目主页位于https://zjunlp.github.io/project/ConceptEdit。

    arXiv:2403.06259v1 Announce Type: cross  Abstract: Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs). Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear. This paper pioneers the investigation of editing conceptual knowledge for LLMs, by constructing a novel benchmark dataset ConceptEdit and establishing a suite of new metrics for evaluation. The experimental results reveal that, although existing editing methods can efficiently modify concept-level definition to some extent, they also have the potential to distort the related instantial knowledge in LLMs, leading to poor performance. We anticipate this can inspire further progress in better understanding LLMs. Our project homepage is available at https://zjunlp.github.io/project/ConceptEdit.
    
[^11]: 使用凸优化和列子集选择的矩阵完成

    Matrix Completion with Convex Optimization and Column Subset Selection

    [https://arxiv.org/abs/2403.01919](https://arxiv.org/abs/2403.01919)

    该方法结合了列子集选择和低秩矩阵完成问题的理论基础，提出使用凸优化解决矩阵恢复问题，同时通过实验验证了算法的正确性和性能。

    

    我们介绍了一种用于矩阵恢复问题的两步方法。我们的方法结合了列子集选择和低秩矩阵完成问题的理论基础。提出的方法在每一步中解决一个凸优化任务。我们提出了两种实现我们的列选择矩阵完成（CSMC）方法的算法，每种算法针对不同规模的问题。我们对所提出的方法进行了正式分析，在分析中我们阐明了必要的假设和找到正确解的概率。在论文的第二部分，我们展示了实验工作的结果。数值实验验证了算法的正确性和性能。为了研究矩阵大小、秩和缺失元素比例对解的质量和计算时间的影响，我们在合成数据上进行了实验。所提出的方法被应用于两个真实世界的例子。

    arXiv:2403.01919v1 Announce Type: new  Abstract: We introduce a two-step method for the matrix recovery problem. Our approach combines the theoretical foundations of the Column Subset Selection and Low-rank Matrix Completion problems. The proposed method, in each step, solves a convex optimization task. We present two algorithms that implement our Columns Selected Matrix Completion (CSMC) method, each dedicated to a different size problem. We performed a formal analysis of the presented method, in which we formulated the necessary assumptions and the probability of finding a correct solution. In the second part of the paper, we present the results of the experimental work. Numerical experiments verified the correctness and performance of the algorithms. To study the influence of the matrix size, rank, and the proportion of missing elements on the quality of the solution and the computation time, we performed experiments on synthetic data. The presented method was applied to two real-li
    
[^12]: 高维尾指数回归：以社交媒体病毒帖子文本分析为例

    High-Dimensional Tail Index Regression: with An Application to Text Analyses of Viral Posts in Social Media

    [https://arxiv.org/abs/2403.01318](https://arxiv.org/abs/2403.01318)

    提出了高维尾指数回归方法，利用正则化估计和去偏方法进行推断，支持理论的仿真研究，并在社交媒体病毒帖子文本分析中应用。

    

    受社交媒体病毒帖子的点赞分布（如点赞数量）经验性幂律的启发，我们引入了高维尾指数回归及其参数的估计和推断方法。我们提出了一种正则化估计量，证明了它的一致性，并推导了其收敛速度。为了进行推断，我们提出了去偏正则化估计，证明了去偏估计量的渐近正态性。仿真研究支持了我们的理论。这些方法被应用于对涉及 LGBTQ+ 话题的 X（原 Twitter）病毒帖子的文本分析。

    arXiv:2403.01318v1 Announce Type: cross  Abstract: Motivated by the empirical power law of the distributions of credits (e.g., the number of "likes") of viral posts in social media, we introduce the high-dimensional tail index regression and methods of estimation and inference for its parameters. We propose a regularized estimator, establish its consistency, and derive its convergence rate. To conduct inference, we propose to debias the regularized estimate, and establish the asymptotic normality of the debiased estimator. Simulation studies support our theory. These methods are applied to text analyses of viral posts in X (formerly Twitter) concerning LGBTQ+.
    
[^13]: SELFI: 利用强化学习实现自主自我改进以进行社交导航

    SELFI: Autonomous Self-Improvement with Reinforcement Learning for Social Navigation

    [https://arxiv.org/abs/2403.00991](https://arxiv.org/abs/2403.00991)

    SELFI提出了一种在线学习方法，通过将在线无模型强化学习与离线基于模型的学习相结合，实现了机器人行为的快速改进，并在避撞和社交遵从行为方面取得了显著进展。

    

    自主自我改进的机器人通过与环境互动和经验积累来实现将是机器人系统在现实世界中投入使用的关键。本文提出了一种在线学习方法SELFI，利用在线机器人经验来快速高效地微调预训练的控制策略。SELFI将在线无模型强化学习应用于离线基于模型的学习之上，以发挥这两种学习范式的优点。具体来说，SELFI通过将离线预训练的模型学习目标与在线无模型强化学习中学习到的Q值相结合，稳定了在线学习过程。我们在多个现实环境中评估了SELFI，并报告了在避撞方面的改善，以及通过人类用户研究测量的更具社交遵从行为。SELFI使我们能够快速学习有用的机器人行为，减少了预先干预的人员干预。

    arXiv:2403.00991v1 Announce Type: cross  Abstract: Autonomous self-improving robots that interact and improve with experience are key to the real-world deployment of robotic systems. In this paper, we propose an online learning method, SELFI, that leverages online robot experience to rapidly fine-tune pre-trained control policies efficiently. SELFI applies online model-free reinforcement learning on top of offline model-based learning to bring out the best parts of both learning paradigms. Specifically, SELFI stabilizes the online learning process by incorporating the same model-based learning objective from offline pre-training into the Q-values learned with online model-free reinforcement learning. We evaluate SELFI in multiple real-world environments and report improvements in terms of collision avoidance, as well as more socially compliant behavior, measured by a human user study. SELFI enables us to quickly learn useful robotic behaviors with less human interventions such as pre-e
    
[^14]: 遵循我的指示并说出真相：来自检索增强生成系统的可扩展数据提取

    Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems

    [https://arxiv.org/abs/2402.17840](https://arxiv.org/abs/2402.17840)

    研究揭示了检索增强生成系统中的数据泄露风险，指出对手可以利用LMs的指示遵循能力轻松地从数据存储中直接提取文本数据，并设计了攻击对生产RAG模型GPTs造成数据存储泄漏。

    

    检索增强生成（RAG）通过在测试时将外部知识纳入预训练模型，从而实现定制适应，提升了模型性能。本研究探讨了Retrieval-In-Context RAG语言模型（LMs）中的数据泄露风险。我们展示了当对使用指令调整的LMs构建的RAG系统进行提示注入时，对手可以利用LMs的指示遵循能力轻松地从数据存储中直接提取文本数据。这种漏洞存在于覆盖Llama2、Mistral/Mixtral、Vicuna、SOLAR、WizardLM、Qwen1.5和Platypus2等多种现代LMs的广泛范围内，并且随着模型规模的扩大，利用能力加剧。将研究扩展到生产RAG模型GPTs，我们设计了一种攻击，可以在对25个随机选择的定制GPTs施加最多2个查询时以100%成功率导致数据存储泄漏，并且我们能够以77,000字的书籍中的文本数据的提取率为41%，以及在含有1,569,00词的语料库中的文本数据的提取率为3%。

    arXiv:2402.17840v1 Announce Type: cross  Abstract: Retrieval-Augmented Generation (RAG) improves pre-trained models by incorporating external knowledge at test time to enable customized adaptation. We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection. The vulnerability exists for a wide range of modern LMs that span Llama2, Mistral/Mixtral, Vicuna, SOLAR, WizardLM, Qwen1.5, and Platypus2, and the exploitability exacerbates as the model size scales up. Extending our study to production RAG models GPTs, we design an attack that can cause datastore leakage with a 100% success rate on 25 randomly selected customized GPTs with at most 2 queries, and we extract text data verbatim at a rate of 41% from a book of 77,000 words and 3% from a corpus of 1,569,00
    
[^15]: 隐式线性层的频谱提取和裁剪

    Spectrum Extraction and Clipping for Implicitly Linear Layers

    [https://arxiv.org/abs/2402.16017](https://arxiv.org/abs/2402.16017)

    展示自动微分在计算和控制隐式线性算子频谱中的有效性；提供第一个适用于一般卷积层的裁剪方法；研究了批归一化层与卷积层组合的效果；通过比较算法与最先进方法的精度和性能表明更精确和高效。

    

    我们展示了自动微分在高效准确计算和控制隐式线性算子的频谱上的有效性，这是一类包括所有标准卷积和全连接层的丰富层类型。我们提供了第一个适用于一般卷积层的裁剪方法，并阐明了导致之前工作中正确性问题的表示限制。我们研究了批归一化层与卷积层串联时的效果，并展示了我们的裁剪方法如何应用于它们的组合。通过对我们的算法与最先进方法的精度和性能进行比较，我们使用各种实验表明它们更精确和高效，能够实现更好的泛化和对抗鲁棒性。我们提供了使用我们方法的代码链接https://github.com/Ali-E/FastClip。

    arXiv:2402.16017v1 Announce Type: new  Abstract: We show the effectiveness of automatic differentiation in efficiently and correctly computing and controlling the spectrum of implicitly linear operators, a rich family of layer types including all standard convolutional and dense layers. We provide the first clipping method which is correct for general convolution layers, and illuminate the representational limitation that caused correctness issues in prior work. We study the effect of the batch normalization layers when concatenated with convolutional layers and show how our clipping method can be applied to their composition. By comparing the accuracy and performance of our algorithms to the state-of-the-art methods, using various experiments, we show they are more precise and efficient and lead to better generalization and adversarial robustness. We provide the code for using our methods at https://github.com/Ali-E/FastClip.
    
[^16]: QuaCer-C：大型语言模型中知识理解的定量认证

    QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs

    [https://arxiv.org/abs/2402.15929](https://arxiv.org/abs/2402.15929)

    本文提出了一种新颖的认证框架QuaCer-C，用于正式认证大型语言模型中知识理解的能力，证书定量化且包含高置信度的概率界限，研究发现，随着参数数量的增加，知识理解能力提高，Mistral模型在这一评估中表现不如其他模型。

    

    大型语言模型（LLMs）在多个基准测试中展现出令人印象深刻的表现。然而，传统研究并未对LLMs的表现提供正式的保证。本文提出了一种新颖的LLM认证框架QuaCer-C，我们在此对知名LLMs的知识理解能力进行正式认证。我们的证书是定量的 - 它们包括对目标LLM在任何相关知识理解提示上给出正确答案的概率的高置信度紧密界限。我们针对Llama、Vicuna和Mistral LLMs的证书表明，知识理解能力随参数数量的增加而提高，并且Mistral模型在这一评估中表现不如其他模型。

    arXiv:2402.15929v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive performance on several benchmarks. However, traditional studies do not provide formal guarantees on the performance of LLMs. In this work, we propose a novel certification framework for LLM, QuaCer-C, wherein we formally certify the knowledge-comprehension capabilities of popular LLMs. Our certificates are quantitative - they consist of high-confidence, tight bounds on the probability that the target LLM gives the correct answer on any relevant knowledge comprehension prompt. Our certificates for the Llama, Vicuna, and Mistral LLMs indicate that the knowledge comprehension capability improves with an increase in the number of parameters and that the Mistral model is less performant than the rest in this evaluation.
    
[^17]: 关于神经网络中的最小深度

    On Minimal Depth in Neural Networks

    [https://arxiv.org/abs/2402.15315](https://arxiv.org/abs/2402.15315)

    本研究研究了神经网络中关于最小深度的问题，特别关注了ReLU神经网络的表达能力和最小深度与CPWL函数的关系。

    

    通过对ReLU神经网络表达能力以及与表示任何连续分段线性函数（CPWL）所需的最小深度相关的猜想的关系进行研究，本研究探讨了神经网络的表达能力特性。研究重点包括对求和和最大运算的最小深度表示，以及对多面体神经网络的探索。实验结果表明，对于求和运算，我们建立了关于操作数最小深度的充分条件以找到运算的最小深度。相反，关于最大运算，我们提供了全面的例子，证明仅依赖于操作数深度的充分条件，并不会暗示运算的最小深度。研究还考察了凸CPWL函数之间的最小深度关系。

    arXiv:2402.15315v1 Announce Type: new  Abstract: A characterization of the representability of neural networks is relevant to comprehend their success in artificial intelligence. This study investigate two topics on ReLU neural network expressivity and their connection with a conjecture related to the minimum depth required for representing any continuous piecewise linear function (CPWL). The topics are the minimal depth representation of the sum and max operations, as well as the exploration of polytope neural networks. For the sum operation, we establish a sufficient condition on the minimal depth of the operands to find the minimal depth of the operation. In contrast, regarding the max operation, a comprehensive set of examples is presented, demonstrating that no sufficient conditions, depending solely on the depth of the operands, would imply a minimal depth for the operation. The study also examine the minimal depth relationship between convex CPWL functions. On polytope neural ne
    
[^18]: 嵌入线性动力学的神经网络用于长序列建模

    Linear Dynamics-embedded Neural Network for Long-Sequence Modeling

    [https://arxiv.org/abs/2402.15290](https://arxiv.org/abs/2402.15290)

    提出了一种名为嵌入线性动力学的神经网络（LDNN），通过引入连续状态空间模型的属性和优化策略，实现了在长序列任务中具有少量参数、灵活推断和高效训练，最终在长距离竞技场上取得了有效且领先的性能。

    

    由于现有模型在长序列建模中性能和计算效率之间的权衡成为瓶颈，受到控制理论中具有多输入多输出的连续状态空间模型（SSMs）启发，我们提出了一种名为嵌入线性动力学的神经网络（LDNN）的新型神经网络。 SSM的连续、离散和卷积属性使LDNN具有少量参数、灵活的推断和在长序列任务中高效训练的特点。 我们开发了两种有效策略，对角化和“解耦然后快速傅立叶变换（FFT）”，以将卷积的时间复杂度从$O(LNH\max\{L, N\})$降低到$O(LN\max\{H, \log L\})$。 我们通过双向非因果和多头设置进一步改进了LDNN，以适应更广泛的应用范围。 对长距离竞技场（LRA）的大量实验表明了LDNN的有效性和最先进的性能。

    arXiv:2402.15290v1 Announce Type: cross  Abstract: The trade-off between performance and computational efficiency in long-sequence modeling becomes a bottleneck for existing models. Inspired by the continuous state space models (SSMs) with multi-input and multi-output in control theory, we propose a new neural network called Linear Dynamics-embedded Neural Network (LDNN). SSMs' continuous, discrete, and convolutional properties enable LDNN to have few parameters, flexible inference, and efficient training in long-sequence tasks. Two efficient strategies, diagonalization and $'\text{Disentanglement then Fast Fourier Transform (FFT)}'$, are developed to reduce the time complexity of convolution from $O(LNH\max\{L, N\})$ to $O(LN\max \{H, \log L\})$. We further improve LDNN through bidirectional noncausal and multi-head settings to accommodate a broader range of applications. Extensive experiments on the Long Range Arena (LRA) demonstrate the effectiveness and state-of-the-art performance
    
[^19]: 通过离散扩散进行大规模无动作视频预训练，以实现高效策略学习

    Large-Scale Actionless Video Pre-Training via Discrete Diffusion for Efficient Policy Learning

    [https://arxiv.org/abs/2402.14407](https://arxiv.org/abs/2402.14407)

    利用离散扩散结合生成式预训练和少量机器人视频微调，实现从人类视频到机器人策略学习的知识迁移。

    

    学习一个能够完成多个任务的通用实体代理面临挑战，主要源自缺乏有标记动作的机器人数据集。相比之下，存在大量捕捉复杂任务和与物理世界互动的人类视频。本文介绍了一种新颖框架，利用统一的离散扩散将人类视频上的生成式预训练与少量有标记机器人视频上的策略微调结合起来。我们首先将人类和机器人视频压缩成统一的视频标记。在预训练阶段，我们使用一个带有蒙版替换扩散策略的离散扩散模型来预测潜空间中的未来视频标记。在微调阶段，我们 h

    arXiv:2402.14407v1 Announce Type: new  Abstract: Learning a generalist embodied agent capable of completing multiple tasks poses challenges, primarily stemming from the scarcity of action-labeled robotic datasets. In contrast, a vast amount of human videos exist, capturing intricate tasks and interactions with the physical world. Promising prospects arise for utilizing actionless human videos for pre-training and transferring the knowledge to facilitate robot policy learning through limited robot demonstrations. In this paper, we introduce a novel framework that leverages a unified discrete diffusion to combine generative pre-training on human videos and policy fine-tuning on a small number of action-labeled robot videos. We start by compressing both human and robot videos into unified video tokens. In the pre-training stage, we employ a discrete diffusion model with a mask-and-replace diffusion strategy to predict future video tokens in the latent space. In the fine-tuning stage, we h
    
[^20]: 金融领域的数字化索赔检测：一个新的金融数据集、弱监督模型和市场分析

    Numerical Claim Detection in Finance: A New Financial Dataset, Weak-Supervision Model, and Market Analysis

    [https://arxiv.org/abs/2402.11728](https://arxiv.org/abs/2402.11728)

    本研究探讨了分析师报告和盈利电话中的索赔对金融市场回报的影响，并构建了一个新的金融数据集用于索赔检测任务。提出了一种融入主题专家知识的新型弱监督模型，通过构建一种新的度量“乐观主义”展示了模型的实际效用。

    

    在本文中，我们研究了分析师报告和盈利电话中的索赔对金融市场回报的影响，将它们视为上市公司重要的季度事件。为了进行全面的分析，我们构建了一个新的金融数据集，用于金融领域的索赔检测任务。我们在该数据集上对各种语言模型进行了基准测试，并提出了一种融入主题专家（SMEs）知识的新型弱监督模型，在聚合函数中超越了现有方法。此外，我们通过构建一种新的度量“乐观主义”展示了我们提出的模型的实际效用。我们还观察到盈利惊喜和回报对我们的乐观主义度量的依赖。我们的数据集、模型和代码将在GitHub和Hugging Face上公开（遵循CC BY 4.0许可）。

    arXiv:2402.11728v1 Announce Type: new  Abstract: In this paper, we investigate the influence of claims in analyst reports and earnings calls on financial market returns, considering them as significant quarterly events for publicly traded companies. To facilitate a comprehensive analysis, we construct a new financial dataset for the claim detection task in the financial domain. We benchmark various language models on this dataset and propose a novel weak-supervision model that incorporates the knowledge of subject matter experts (SMEs) in the aggregation function, outperforming existing approaches. Furthermore, we demonstrate the practical utility of our proposed model by constructing a novel measure ``optimism". Furthermore, we observed the dependence of earnings surprise and return on our optimism measure. Our dataset, models, and code will be made publicly (under CC BY 4.0 license) available on GitHub and Hugging Face.
    
[^21]: 获得$2\sqrt{T}$到校准的基本预测器

    An Elementary Predictor Obtaining $2\sqrt{T}$ Distance to Calibration

    [https://arxiv.org/abs/2402.11410](https://arxiv.org/abs/2402.11410)

    给出了一种简单、高效、确定性的算法，该算法的校准距离误差最多为$2\sqrt{T}$

    

    Blasiok等人[2023]提出了校准距离作为一种自然的校准误差度量，与预期的校准误差(ECE)不同，它是连续的。最近，Qiao和Zheng [2024]给出了一个非构造性的论证，建立了一种在线预测器的存在，该预测器可以在对抗设置中获得$O(\sqrt{T})$的校准距离，而对于ECE来说是不可能的。他们将找到一种明确的、高效的算法作为一个需要解决的问题。我们解决了这个问题，并给出了一个非常简单、高效、确定性的算法，该算法的校准距离误差最多为$2\sqrt{T}$。

    arXiv:2402.11410v1 Announce Type: new  Abstract: Blasiok et al. [2023] proposed distance to calibration as a natural measure of calibration error that unlike expected calibration error (ECE) is continuous. Recently, Qiao and Zheng [2024] gave a non-constructive argument establishing the existence of an online predictor that can obtain $O(\sqrt{T})$ distance to calibration in the adversarial setting, which is known to be impossible for ECE. They leave as an open problem finding an explicit, efficient algorithm. We resolve this problem and give an extremely simple, efficient, deterministic algorithm that obtains distance to calibration error at most $2\sqrt{T}$.
    
[^22]: 提升基于提示的语言模型零/少样本学习的偏差校准策略

    Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models

    [https://arxiv.org/abs/2402.10353](https://arxiv.org/abs/2402.10353)

    本研究提出了一种空输入提示方法，用于校准预训练语言模型中的固有偏差，从而提升零/少样本学习的性能。

    

    提示学习容易受到预训练语言模型中固有偏差的影响，导致基于提示的零/少样本学习性能不佳。本文提出了一种空输入提示方法，用于校准预训练语言模型中编码的固有偏差。与以往主要致力于社会公平的固有偏差修正方法不同，我们的目标是在增强语言模型在下游零/少样本学习任务中的性能的同时，强调固有偏差校准的效率。具体来说，我们利用从GPT-4生成的一组自动选取的无意义输入来提示预训练语言模型以探测固有偏差。利用偏差反映的概率分布，我们提出了一个分布差异损失用于偏差校准，其中我们仅更新语言模型的偏差参数（总参数的0.1%）以朝向相等的概率分布。

    arXiv:2402.10353v1 Announce Type: new  Abstract: Prompt learning is susceptible to intrinsic bias present in pre-trained language models (LMs), resulting in sub-optimal performance of prompt-based zero/few-shot learning. In this work, we propose a null-input prompting method to calibrate intrinsic bias encoded in pre-trained LMs. Different from prior efforts that address intrinsic bias primarily for social fairness and often involve excessive computational cost, our objective is to explore enhancing LMs' performance in downstream zero/few-shot learning while emphasizing the efficiency of intrinsic bias calibration. Specifically, we leverage a diverse set of auto-selected null-meaning inputs generated from GPT-4 to prompt pre-trained LMs for intrinsic bias probing. Utilizing the bias-reflected probability distribution, we formulate a distribution disparity loss for bias calibration, where we exclusively update bias parameters ($0.1\%$ of total parameters) of LMs towards equal probabilit
    
[^23]: Switch EMA: 更好的平坦性和锐度的免费午餐

    Switch EMA: A Free Lunch for Better Flatness and Sharpness

    [https://arxiv.org/abs/2402.09240](https://arxiv.org/abs/2402.09240)

    本研究提出了一种称为Switch EMA（SEMA）的方法，通过简单的修改指数移动平均（EMA）参数，可以帮助深度神经网络（DNN）达到更好的平坦性和锐度的概括最优解。通过在多个任务和数据集上进行实验证明了SEMA的有效性。

    

    指数移动平均（EMA）是一种广泛使用的权重平均正则化方法，在深度神经网络（DNN）优化中学习平坦的最优解，以获得更好的概括能力而不增加额外的成本。尽管可以获得更好的平坦性，但现有的平均方法可能陷入更差的最终性能或需要额外的测试时间计算。本文通过一个简单的修改，即在每个周期后将EMA参数切换回原始模型，揭示了EMA的充分潜力，被称为Switch EMA（SEMA）。从理论和实证方面都证明了SEMA可以帮助DNNs达到更好的平坦性和锐度之间平衡的概括最优解。为了验证SEMA的效果，我们在视觉和语言数据集上进行了辨别性、生成性和回归任务的比较实验，包括图像分类、自监督学习、目标检测和分割、图像生成等。

    arXiv:2402.09240v1 Announce Type: new Abstract: Exponential Moving Average (EMA) is a widely used weight averaging (WA) regularization to learn flat optima for better generalizations without extra cost in deep neural network (DNN) optimization. Despite achieving better flatness, existing WA methods might fall into worse final performances or require extra test-time computations. This work unveils the full potential of EMA with a single line of modification, i.e., switching the EMA parameters to the original model after each epoch, dubbed as Switch EMA (SEMA). From both theoretical and empirical aspects, we demonstrate that SEMA can help DNNs to reach generalization optima that better trade-off between flatness and sharpness. To verify the effectiveness of SEMA, we conduct comparison experiments with discriminative, generative, and regression tasks on vision and language datasets, including image classification, self-supervised learning, object detection and segmentation, image generati
    
[^24]: 使用强化学习进行IR感知的ECO时序优化

    IR-Aware ECO Timing Optimization Using Reinforcement Learning

    [https://arxiv.org/abs/2402.07781](https://arxiv.org/abs/2402.07781)

    本文提出了一种使用强化学习进行IR感知的ECO时序优化的方法，该方法通过门尺寸调整纠正由IR降低引起的时序退化，并且相较于传统方法在性能和运行时间上都具有优势。

    

    在晚期阶段的工程变更订单（ECOs）通过最小的设计修复来从过多的IR降低导致的时序偏移中恢复。本文将IR感知的时序分析和使用强化学习（RL）进行ECO时序优化相结合。该方法在物理设计和功耗网格综合之后运行，并通过门尺寸调整纠正由IR降低引起的时序退化。它将拉格朗日松弛（LR）技术融入一种新颖的RL框架中，该框架训练一个关系图卷积网络（R-GCN）代理，按顺序调整门尺寸以修复时序违规。R-GCN代理优于传统的仅使用LR的算法：在开放式45nm工艺中，它将延迟-面积权衡曲线的帕累托前沿向左移动，并通过在等质量时使用训练模型进行快速推理，节省运行时间。RL模型可在时序规范间转移，并可通过零样本学习或微调在未见设计上转移。

    Engineering change orders (ECOs) in late stages make minimal design fixes to recover from timing shifts due to excessive IR drops. This paper integrates IR-drop-aware timing analysis and ECO timing optimization using reinforcement learning (RL). The method operates after physical design and power grid synthesis, and rectifies IR-drop-induced timing degradation through gate sizing. It incorporates the Lagrangian relaxation (LR) technique into a novel RL framework, which trains a relational graph convolutional network (R-GCN) agent to sequentially size gates to fix timing violations. The R-GCN agent outperforms a classical LR-only algorithm: in an open 45nm technology, it (a) moves the Pareto front of the delay-area tradeoff curve to the left and (b) saves runtime over the classical method by running fast inference using trained models at iso-quality. The RL model is transferable across timing specifications, and transferable to unseen designs with zero-shot learning or fine tuning.
    
[^25]: SpongeNet 攻击：深度神经网络的海绵权重中毒

    The SpongeNet Attack: Sponge Weight Poisoning of Deep Neural Networks

    [https://arxiv.org/abs/2402.06357](https://arxiv.org/abs/2402.06357)

    本文提出了一种名为 SpongeNet 的新型海绵攻击，通过直接作用于预训练模型参数，成功增加了视觉模型的能耗，而且所需的样本数量更少。

    

    海绵攻击旨在增加在硬件加速器上部署的神经网络的能耗和计算时间。现有的海绵攻击可以通过海绵示例进行推理，也可以通过海绵中毒在训练过程中进行。海绵示例利用添加到模型输入的扰动来增加能量和延迟，而海绵中毒则改变模型的目标函数来引发推理时的能量/延迟效应。在这项工作中，我们提出了一种新颖的海绵攻击，称为 SpongeNet。SpongeNet 是第一个直接作用于预训练模型参数的海绵攻击。我们的实验表明，相比于海绵中毒，SpongeNet 可以成功增加视觉模型的能耗，并且所需的样本数量更少。我们的实验结果表明，如果不专门针对海绵中毒进行调整（即减小批归一化偏差值），则毒害防御会失效。我们的工作显示出海绵攻击的影响。

    Sponge attacks aim to increase the energy consumption and computation time of neural networks deployed on hardware accelerators. Existing sponge attacks can be performed during inference via sponge examples or during training via Sponge Poisoning. Sponge examples leverage perturbations added to the model's input to increase energy and latency, while Sponge Poisoning alters the objective function of a model to induce inference-time energy/latency effects.   In this work, we propose a novel sponge attack called SpongeNet. SpongeNet is the first sponge attack that is performed directly on the parameters of a pre-trained model. Our experiments show that SpongeNet can successfully increase the energy consumption of vision models with fewer samples required than Sponge Poisoning. Our experiments indicate that poisoning defenses are ineffective if not adjusted specifically for the defense against Sponge Poisoning (i.e., they decrease batch normalization bias values). Our work shows that Spong
    
[^26]: 学习对比特征表示来进行面部动作单元检测

    Learning Contrastive Feature Representations for Facial Action Unit Detection

    [https://arxiv.org/abs/2402.06165](https://arxiv.org/abs/2402.06165)

    这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。

    

    面部动作单元（AU）检测的主要方法涉及监督的多标签二进制分类问题。现有的方法常常对AU的像素级信息进行编码，从而对模型的复杂性和表达能力提出了很大的要求。此外，由于存在噪声AU标签，这种做法增加了过拟合的风险。在本研究中，我们引入了一个对比学习框架，通过监督和自监督信号增强。目标是在AU检测领域中摆脱传统的像素级学习范式，获得判别特征。为了应对噪声AU标签带来的挑战，我们通过引入自监督信号来增强监督信号。这种增强是通过正样本抽样实现的，包括三种不同类型的正样本对。另外，为了减轻每个AU类型的分布不平衡问题，我们采用了一种权衡重要性的损失函数。

    The predominant approach to facial action unit (AU) detection revolves around a supervised multi-label binary classification problem. Existing methodologies often encode pixel-level information of AUs, thereby imposing substantial demands on model complexity and expressiveness. Moreover, this practice elevates the susceptibility to overfitting due to the presence of noisy AU labels. In the present study, we introduce a contrastive learning framework enhanced by both supervised and self-supervised signals. The objective is to acquire discriminative features, deviating from the conventional pixel-level learning paradigm within the domain of AU detection. To address the challenge posed by noisy AU labels, we augment the supervised signal through the introduction of a self-supervised signal. This augmentation is achieved through positive sample sampling, encompassing three distinct types of positive sample pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we empl
    
[^27]: Hydra: 循序依赖的草稿头部用于Medusa解码

    Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding

    [https://arxiv.org/abs/2402.05109](https://arxiv.org/abs/2402.05109)

    Hydra heads是一种循序依赖的草稿头部，取代了标准草稿头部，显著提高了推测准确性，在Medusa解码中具有更高的吞吐量。

    

    为了解决自回归LLM推理的内存带宽限制问题，先前的研究提出了推测解码框架。为了执行推测解码，一个小的草稿模型提出了输入序列的候选延续，然后由基础模型并行验证。在最近的Medusa解码框架中，一种指定草稿模型的方法是将其作为一组称为草稿头部的轻量级头部，这些头部对基础模型的隐藏状态进行操作。迄今为止，所有现有的草稿头部都是顺序独立的，这意味着它们在候选延续中的令牌推测与候选延续中的任何前面的令牌无关。在这项工作中，我们提出了循序依赖的Hydra heads，它们是标准草稿头部的可替换组件，显著提高了推测准确性。使用Hydra heads进行解码比使用标准草稿头部的Medusa解码具有更高的吞吐量。我们进一步研究了设计空间。

    To combat the memory bandwidth-bound nature of autoregressive LLM inference, previous research has proposed the speculative decoding framework. To perform speculative decoding, a small draft model proposes candidate continuations of the input sequence, that are then verified in parallel by the base model. One way to specify the draft model, as used in the recent Medusa decoding framework, is as a collection of light-weight heads, called draft heads, that operate on the base model's hidden states. To date, all existing draft heads have been sequentially independent, meaning that they speculate tokens in the candidate continuation independently of any preceding tokens in the candidate continuation. In this work, we propose Hydra heads, a sequentially dependent, drop-in replacement for standard draft heads that significantly improves speculation accuracy. Decoding with Hydra heads improves throughput compared to Medusa decoding with standard draft heads. We further explore the design spac
    
[^28]: 无偏好对齐学习与正则化相关奖励

    Preference-free Alignment Learning with Regularized Relevance Reward

    [https://arxiv.org/abs/2402.03469](https://arxiv.org/abs/2402.03469)

    无偏好对齐学习使用正则化相关奖励作为关键目标，在提供稳健奖励信号的同时，显著提高了偏好基准测试的性能。

    

    从人类偏好中学习被认为是将大规模语言模型（LLMs）与人类价值观对齐的关键。然而，与普遍的观点相反，我们的初步研究发现，基于人类偏好数据集训练的奖励模型倾向于给长的与主题无关的回复更高的分数，而给短的与主题相关的回复较低分。在这一观察的驱动下，我们探索了一种无偏好的方法，利用“相关性”作为对齐的一个关键目标。在我们的第一次尝试中，我们发现仅仅通过检索得到的相关性得分容易受到奖励欺骗的影响，即过度优化到不期望的捷径上，当我们将该得分作为奖励用于强化学习。为了缓解这个问题，我们将有效的归纳偏差整合到常规的相关性中，互相正则化，形成了一种混合奖励函数：正则化相关奖励（$R^3$）。$R^3$通过提供稳健的奖励信号，显著提高了在偏好基准测试中的性能。值得注意的是，$R^3$不需要

    Learning from human preference has been considered key to aligning Large Language Models (LLMs) with human values. However, contrary to popular belief, our preliminary study reveals that reward models trained on human preference datasets tend to give higher scores to long off-topic responses than short on-topic ones. Motivated by this observation, we explore a preference-free approach utilizing `relevance' as a key objective for alignment. On our first attempt, we find that the relevance score obtained by a retriever alone is vulnerable to reward hacking, i.e., overoptimizing to undesired shortcuts, when we utilize the score as a reward for reinforcement learning. To mitigate it, we integrate effective inductive biases into the vanilla relevance to regularize each other, resulting in a mixture of reward functions: Regularized Relevance Reward ($R^3$). $R^3$ significantly improves performance on preference benchmarks by providing a robust reward signal. Notably, $R^3$ does not require a
    
[^29]: GPT 模型的对话重构攻击

    Conversation Reconstruction Attack Against GPT Models

    [https://arxiv.org/abs/2402.02987](https://arxiv.org/abs/2402.02987)

    本文介绍了一种针对 GPT 模型的对话重构攻击，该攻击具有劫持会话和重构对话的两个步骤。通过对该攻击对 GPT 模型的隐私风险进行评估，发现 GPT-4 对该攻击具有一定的鲁棒性。

    

    最近，在大型语言模型（LLM）领域取得了重要进展，其中 GPT 系列模型代表着最具代表性的成果。为了优化任务执行，用户经常与托管在云环境中的 GPT 模型进行多轮对话。这些多轮对话往往包含私人信息，需要在云中进行传输和存储。然而，这种操作模式引入了额外的攻击面。本文首先介绍了一种针对 GPT 模型的特定对话重构攻击。我们提出的对话重构攻击由两个步骤组成：劫持会话和重构对话。随后，我们对当 GPT 模型遭受该攻击时对话中固有的隐私风险进行了详尽评估。然而，GPT-4 对于该攻击具有一定的鲁棒性。接着，我们引入了两种高级攻击，旨在更好地重构以前的对话。

    In recent times, significant advancements have been made in the field of large language models (LLMs), represented by GPT series models. To optimize task execution, users often engage in multi-round conversations with GPT models hosted in cloud environments. These multi-round conversations, potentially replete with private information, require transmission and storage within the cloud. However, this operational paradigm introduces additional attack surfaces. In this paper, we first introduce a specific Conversation Reconstruction Attack targeting GPT models. Our introduced Conversation Reconstruction Attack is composed of two steps: hijacking a session and reconstructing the conversations. Subsequently, we offer an exhaustive evaluation of the privacy risks inherent in conversations when GPT models are subjected to the proposed attack. However, GPT-4 demonstrates certain robustness to the proposed attacks. We then introduce two advanced attacks aimed at better reconstructing previous c
    
[^30]: 大型语言模型存在地理偏见

    Large Language Models are Geographically Biased

    [https://arxiv.org/abs/2402.02680](https://arxiv.org/abs/2402.02680)

    本文研究了大型语言模型的地理偏见，并展示了其对地理空间预测的系统错误，通过零射击地理空间预测来评估其对世界的认知。

    

    大型语言模型（LLMs）内在地含有其训练语料库中的偏见，这可能导致社会伤害的持续存在。随着这些基础模型的影响力不断增长，理解和评估它们的偏见对于实现公正和准确性至关重要。本文提出通过地理视角研究LLMs对我们所生活的世界的认知。这种方法特别强大，因为对人类生活中诸多与地理空间相关的方面（如文化、种族、语言、政治和宗教）有着明显的真实性。我们展示了各种问题地理偏见，我们将其定义为地理空间预测中的系统错误。首先，我们证明LLMs能够进行精确的零射击地理空间预测，以评级的形式呈现，其与真实情况之间呈现出强烈的单调相关性（Spearman's ρ最高可达0.89）。然后，我们展示了LLMs在多个客观和子领域上表现出共同的偏见。

    Large Language Models (LLMs) inherently carry the biases contained in their training corpora, which can lead to the perpetuation of societal harm. As the impact of these foundation models grows, understanding and evaluating their biases becomes crucial to achieving fairness and accuracy. We propose to study what LLMs know about the world we live in through the lens of geography. This approach is particularly powerful as there is ground truth for the numerous aspects of human life that are meaningfully projected onto geographic space such as culture, race, language, politics, and religion. We show various problematic geographic biases, which we define as systemic errors in geospatial predictions. Initially, we demonstrate that LLMs are capable of making accurate zero-shot geospatial predictions in the form of ratings that show strong monotonic correlation with ground truth (Spearman's $\rho$ of up to 0.89). We then show that LLMs exhibit common biases across a range of objective and sub
    
[^31]: 使用回声状态网络的多智能体强化学习及其在行人动态中的应用

    Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics

    [https://arxiv.org/abs/2312.11834](https://arxiv.org/abs/2312.11834)

    通过使用回声状态网络将行人实现为MARL代理，研究了他们学习避让其他代理向前移动的能力，在密度不太高的情况下取得成功。

    

    近年来，研究使用多智能体强化学习（MARL）模拟行人。本研究考虑了网格世界环境中的道路，并将行人实现为使用回声状态网络和最小二乘策略迭代方法的MARL代理。在这个环境下，研究了这些代理学习避开其他代理向前移动的能力。具体而言，我们考虑了两种任务：窄直接路径和宽绕道之间的选择，以及走廊中的双向行人流。模拟结果表明，当代理密度不太高时，学习是成功的。

    arXiv:2312.11834v2 Announce Type: replace-cross  Abstract: In recent years, simulations of pedestrians using the multi-agent reinforcement learning (MARL) have been studied. This study considered the roads on a grid-world environment, and implemented pedestrians as MARL agents using an echo-state network and the least squares policy iteration method. Under this environment, the ability of these agents to learn to move forward by avoiding other agents was investigated. Specifically, we considered two types of tasks: the choice between a narrow direct route and a broad detour, and the bidirectional pedestrian flow in a corridor. The simulations results indicated that the learning was successful when the density of the agents was not that high.
    
[^32]: LLMs的两面性：Jekyll博士与Hyde先生

    Dr. Jekyll and Mr. Hyde: Two Faces of LLMs

    [https://arxiv.org/abs/2312.03853](https://arxiv.org/abs/2312.03853)

    本研究通过让ChatGPT和Bard冒充复杂人物角色，绕过了安全机制和专门训练程序，展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。

    

    仅仅一年前，我们目睹了大型语言模型（LLMs）的使用增加，尤其是在结合像聊天机器人助手之类的应用时。为了防止这些助手产生不当回应，我们实施了安全机制和专门的训练程序。在这项工作中，我们通过让ChatGPT和Bard（以及在某种程度上是Bing chat）冒充复杂人物角色，绕过了这些措施，这些角色与它们本应成为的真实助手的特征相反。我们首先创造出这些人物角色的复杂传记，然后在同一聊天机器人中使用它们进行新的对话。我们的对话采用角色扮演风格，以获得助手不被允许提供的回应。通过使用人物角色，我们展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。这项工作表明，通过使用对抗性pe

    arXiv:2312.03853v2 Announce Type: replace-cross  Abstract: Only a year ago, we witnessed a rise in the use of Large Language Models (LLMs), especially when combined with applications like chatbot assistants. Safety mechanisms and specialized training procedures are implemented to prevent improper responses from these assistants. In this work, we bypass these measures for ChatGPT and Bard (and, to some extent, Bing chat) by making them impersonate complex personas with opposite characteristics as those of the truthful assistants they are supposed to be. We start by creating elaborate biographies of these personas, which we then use in a new session with the same chatbots. Our conversation followed a role-play style to get the response the assistant was not allowed to provide. By making use of personas, we show that the response that is prohibited is actually provided, making it possible to obtain unauthorized, illegal, or harmful information. This work shows that by using adversarial pe
    
[^33]: 曲率方向作为失去可塑性的解释

    Directions of Curvature as an Explanation for Loss of Plasticity

    [https://arxiv.org/abs/2312.00246](https://arxiv.org/abs/2312.00246)

    曲率方向的丧失被认为是导致神经网络可塑性丧失的一个重要原因，并且我们通过系统调查和在多个任务中的研究结果支持了这一观点。

    

    可塑性的丧失是神经网络丧失从新经验学习能力的现象。尽管在几种问题设置中经验上观察到，但对导致可塑性丧失的机制了解甚少。在本文中，我们提供了对可塑性丧失的一致解释：神经网络在训练过程中丧失了曲率方向，可将可塑性的丧失归因于这种曲率减少。为了支持这样的说法，我们对在MNIST、CIFAR-10和ImageNet中使用的不断学习任务中的可塑性丧失进行了系统调查。我们的研究结果表明，曲率方向的丧失与可塑性的丧失相吻合，同时还表明以前的解释不足以解释所有情况下的可塑性丧失。最后，我们展示了缓解可塑性丧失的正则化器也会保留曲率，促使采用简单的分布式正则化器。

    arXiv:2312.00246v2 Announce Type: replace  Abstract: Loss of plasticity is a phenomenon in which neural networks lose their ability to learn from new experience. Despite being empirically observed in several problem settings, little is understood about the mechanisms that lead to loss of plasticity. In this paper, we offer a consistent explanation for loss of plasticity: Neural networks lose directions of curvature during training and that loss of plasticity can be attributed to this reduction in curvature. To support such a claim, we provide a systematic investigation of loss of plasticity across continual learning tasks using MNIST, CIFAR-10 and ImageNet. Our findings illustrate that loss of curvature directions coincides with loss of plasticity, while also showing that previous explanations are insufficient to explain loss of plasticity in all settings. Lastly, we show that regularizers which mitigate loss of plasticity also preserve curvature, motivating a simple distributional reg
    
[^34]: 利用指数尺度的深度强化ReLU网络初始化和训练

    Compelling ReLU Network Initialization and Training to Leverage Exponential Scaling with Depth

    [https://arxiv.org/abs/2311.18022](https://arxiv.org/abs/2311.18022)

    该论文提出了一种新的训练策略，通过重新参数化网络权重，使得神经网络的指数数量的激活模式得以展现，从而得到远远超过随机初始化的结果。

    

    ReLU激活的神经网络可以看作是分段线性函数的组合。对于这样的网络，随着深度的增加，表达在输入域上的不同线性区域的数量有可能以指数级增长，但当初始参数选择随机时，不太可能出现这种情况。这种不良的尺度能够导致即使是简单函数也需要使用过大的模型来近似。为了解决这个问题，我们引入了一种新的训练策略：首先以一种方式重新参数化网络权重，使得指数数量的激活模式得以展现。在这些新参数上进行训练可以得到一个初始解，稍后通过更新底层模型权重来改进。这种方法使我们能够产生比随机初始化对应的函数逼近好几个数量级的结果。

    A neural network with ReLU activations may be viewed as a composition of piecewise linear functions. For such networks, the number of distinct linear regions expressed over the input domain has the potential to scale exponentially with depth, but it is not expected to do so when the initial parameters are chosen randomly. This poor scaling can necessitate the use of overly large models to approximate even simple functions. To address this issue, we introduce a novel training strategy: we first reparameterize the network weights in a manner that forces an exponential number of activation patterns to manifest. Training first on these new parameters provides an initial solution that can later be refined by updating the underlying model weights. This approach allows us to produce function approximations that are several orders of magnitude better than their randomly initialized counterparts.
    
[^35]: 在连续治疗下的多重稳健因果中介分析

    Multiply Robust Causal Mediation Analysis with Continuous Treatments

    [https://arxiv.org/abs/2105.09254](https://arxiv.org/abs/2105.09254)

    本文提出了一种适用于连续治疗环境的多重稳健因果中介分析估计器，采用了核平滑方法，并具有多重稳健性和渐近正态性。

    

    在许多应用中，研究人员对治疗或暴露对感兴趣的结果的直接和间接的因果效应。中介分析为鉴定和估计这些因果效应提供了一个严谨的框架。对于二元治疗，Tchetgen Tchetgen和Shpitser (2012)提出了直接和间接效应的高效估计器，基于参数的影响函数。这些估计器具有良好的性质，如多重稳健性和渐近正态性，同时允许对干扰参数进行低于根号n的收敛速度。然而，在涉及连续治疗的情况下，这些基于影响函数的估计器没有准备好应用，除非进行强参数假设。在这项工作中，我们利用核平滑方法提出了一种适用于连续治疗环境的估计器，受到Tchetgen Tchetgen的影响函数估计器的启发。

    In many applications, researchers are interested in the direct and indirect causal effects of a treatment or exposure on an outcome of interest. Mediation analysis offers a rigorous framework for identifying and estimating these causal effects. For binary treatments, efficient estimators for the direct and indirect effects are presented in Tchetgen Tchetgen and Shpitser (2012) based on the influence function of the parameter of interest. These estimators possess desirable properties, such as multiple-robustness and asymptotic normality, while allowing for slower than root-n rates of convergence for the nuisance parameters. However, in settings involving continuous treatments, these influence function-based estimators are not readily applicable without making strong parametric assumptions. In this work, utilizing a kernel-smoothing approach, we propose an estimator suitable for settings with continuous treatments inspired by the influence function-based estimator of Tchetgen Tchetgen an
    
[^36]: 关于Hermitian动态模态分解的收敛性研究

    On the Convergence of Hermitian Dynamic Mode Decomposition. (arXiv:2401.03192v1 [math.NA])

    [http://arxiv.org/abs/2401.03192](http://arxiv.org/abs/2401.03192)

    研究了Hermitian动态模态分解(DMD)对自伴随Koopman算子的谱性质的收敛性，通过建立了关于谱测度收敛性的一般定理，证明了HDMD的特征值和特征函数在适当条件下收敛到基础Koopman算子的谱性质。

    

    本文研究了Hermitian动态模态分解(DMD)对自伴随Koopman算子的谱性质的收敛性。Hermitian DMD是一种基于数据的方法，用于从离散时间快照近似表示与未知非线性动力系统相关的Koopman算子，同时在其有限维近似中保持算子的自伴性。我们证明，在适当的条件下，HDMD的特征值和特征函数收敛到基础Koopman算子的谱性质。在此过程中，我们建立了关于谱测度收敛性的一般定理，并在二维薛定谔方程上通过数值结果验证了我们的结论。

    In this work, we study the convergence of Hermitian Dynamic Mode Decomposition (DMD) to the spectral properties of self-adjoint Koopman operators. Hermitian DMD is a data-driven method for approximating the Koopman operator associated with an unknown nonlinear dynamical system from discrete-time snapshots, while preserving the self-adjointness of the operator on its finite-dimensional approximations. We show that, under suitable conditions, the eigenvalues and eigenfunctions of HDMD converge to the spectral properties of the underlying Koopman operator. Along the way, we establish a general theorem on the convergence of spectral measures, and demonstrate our results numerically on the two-dimensional Schr\"odinger equation.
    
[^37]: 计算医疗中的数据中心基础模型：一项调查

    Data-Centric Foundation Models in Computational Healthcare: A Survey. (arXiv:2401.02458v1 [cs.LG])

    [http://arxiv.org/abs/2401.02458](http://arxiv.org/abs/2401.02458)

    计算医疗中的数据中心基础模型是一项调查研究，为医疗工作流程的改进提供了基于数据的人工智能方法，并讨论了安全性、评估和与人类价值观的一致性。基于FM的分析有望提高患者结果和临床工作流程表现。

    

    作为一套新兴的人工智能技术，基础模型（FMs）的出现为计算医疗带来了一系列机遇。这些模型的交互性由预训练数据和人类指令引导，引发了一个数据中心的人工智能范式，强调更好的数据表征、质量和规模。在医疗人工智能领域，获取和处理高质量的临床数据记录一直是一个长期存在的挑战，涉及数据数量、注释、患者隐私和伦理等方面。在这项调查中，我们研究了FM时代的广泛数据中心方法（从模型预训练到推理），以改进医疗工作流程。我们讨论了人工智能安全性、评估以及与人类价值观的一致性的关键观点。最后，我们展望了基于FM的分析在医疗和医药领域不断发展的格局中提高患者结果和临床工作流程表现的前景。我们提供了一个最新的医疗清单。

    The advent of foundation models (FMs) as an emerging suite of AI techniques has struck a wave of opportunities in computational healthcare. The interactive nature of these models, guided by pre-training data and human instructions, has ignited a data-centric AI paradigm that emphasizes better data characterization, quality, and scale. In healthcare AI, obtaining and processing high-quality clinical data records has been a longstanding challenge, ranging from data quantity, annotation, patient privacy, and ethics. In this survey, we investigate a wide range of data-centric approaches in the FM era (from model pre-training to inference) towards improving the healthcare workflow. We discuss key perspectives in AI security, assessment, and alignment with human values. Finally, we offer a promising outlook of FM-based analytics to enhance the performance of patient outcome and clinical workflow in the evolving landscape of healthcare and medicine. We provide an up-to-date list of healthcare
    
[^38]: 训练的力量：不同的神经网络设置对能源需求的影响

    The Power of Training: How Different Neural Network Setups Influence the Energy Demand. (arXiv:2401.01851v1 [cs.LG])

    [http://arxiv.org/abs/2401.01851](http://arxiv.org/abs/2401.01851)

    本文研究了机器学习训练方案和学习范式对能源消耗的影响，并探讨了预训练和多任务训练在可持续机器学习方面的潜力。

    

    本研究探讨机器学习训练方案和学习范式的变化对相应能源消耗的影响。虽然数据的可用性提高和高性能硬件的创新推动了复杂模型的训练，但也支持了能源消耗和碳排放的消隐。因此，本研究的目标是增加人们对一般训练参数和过程（从学习率到批量大小再到知识传输）的能源影响的认识。使用不同的超参数初始化在两种不同的硬件配置上评估多种设置，以获得有意义的结果。在基准结果上进行了预训练和多任务训练实验，以确定它们对可持续机器学习的潜力。

    This work examines the effects of variations in machine learning training regimes and learning paradigms on the corresponding energy consumption. While increasing data availability and innovation in high-performance hardware fuels the training of sophisticated models, it also supports the fading perception of energy consumption and carbon emission. Therefore, the goal of this work is to create awareness about the energy impact of general training parameters and processes, from learning rate over batch size to knowledge transfer. Multiple setups with different hyperparameter initializations are evaluated on two different hardware configurations to obtain meaningful results. Experiments on pretraining and multitask training are conducted on top of the baseline results to determine their potential towards sustainable machine learning.
    
[^39]: 学会说母语：以母语风格激发大型语言模型的能力

    Speak Like a Native: Prompting Large Language Models in a Native Style. (arXiv:2311.13538v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.13538](http://arxiv.org/abs/2311.13538)

    本文提出了一种名为AlignedCoT的新颖有效方法，通过将上下文示例与大型语言模型（LLMs）的母语风格对齐，提高了LLMs的推理能力和性能。

    

    大型语言模型（LLMs）与上下文学习（ICL）已成为许多自然语言处理任务的现代工具选择。然而，上下文示例的文本风格如何影响LLMs的性能仍然不足。本文提出了一种名为AlignedCoT的新颖有效的方法，通过将上下文示例与LLMs的母语风格对齐来提高LLMs的推理能力。 "母语"是指LLMs的固有特征，可以通过零-shot场景探测。 AlignedCoT广泛适用于ICL方法，可以轻松与最先进的技术结合，进一步提高LLMs的性能。我们在数学问答、常识推理和文本理解等多个基准测试上进行了广泛而全面的实验。实证结果表明，我们的AlignedCoT相比精心手工制作的演示文稿显著提高了性能。

    In-context learning (ICL) with large language models (LLMs) has become the modern tools of choice for many natural language processing tasks. However, how the text style of in-context examples influences the performance of LLMs still remains under-explored. This paper presents a novel and effective approach, named \textbf{AlignedCoT}, to improve the reasoning capability of LLMs by aligning the in-context examples with the native style of LLMs.''Native'' refers to the inherent characteristic of LLMs which can be probed by zero-shot scenarios.AlignedCoT is widely applicable to ICL methods, making it easy to combine with state-of-the-art techniques to further improve the LLMs' performance. We conduct extensive and comprehensive experiments on several benchmarks on mathematical question-answering, common-sense reasoning, and text understanding. The empirical results demonstrate that our AlignedCoT significantly improves performance over the carefully handcrafted demonstrations. Specificall
    
[^40]: 基于层次集成的时间序列预测特征选择研究

    Hierarchical Ensemble-Based Feature Selection for Time Series Forecasting. (arXiv:2310.17544v1 [cs.LG])

    [http://arxiv.org/abs/2310.17544](http://arxiv.org/abs/2310.17544)

    这项研究提出了一种基于层次集成的特征选择方法，能够克服传统方法和最先进方法在非平稳和特征数目庞大且样本有限的情况下的局限性，并在合成和实际数据集上展示了更好的性能。

    

    我们研究了一种针对非平稳和样本有限的大量特征情况下的特征选择新的集成方法。我们的方法利用层次结构来利用特征之间的相互依赖关系。首先，使用特征子集训练机器学习模型，然后使用另一种算法更新模型的输出，以最小化目标损失。这种层次结构允许灵活的深度和特征选择。通过层次地利用特征之间的依赖关系，我们的方法克服了传统特征选择方法和特征重要性评分的局限性。该方法在合成和现实数据集上展示了其有效性，与传统方法和最先进的方法相比，性能具有可扩展性和稳定性。

    We study a novel ensemble approach for feature selection based on hierarchical stacking in cases of non-stationarity and limited number of samples with large number of features. Our approach exploits the co-dependency between features using a hierarchical structure. Initially, a machine learning model is trained using a subset of features, and then the model's output is updated using another algorithm with the remaining features to minimize the target loss. This hierarchical structure allows for flexible depth and feature selection. By exploiting feature co-dependency hierarchically, our proposed approach overcomes the limitations of traditional feature selection methods and feature importance scores. The effectiveness of the approach is demonstrated on synthetic and real-life datasets, indicating improved performance with scalability and stability compared to the traditional methods and state-of-the-art approaches.
    
[^41]: 使用分布式Hebbian Temporal Memory学习继任者表示法

    Learning Successor Representations with Distributed Hebbian Temporal Memory. (arXiv:2310.13391v1 [cs.LG])

    [http://arxiv.org/abs/2310.13391](http://arxiv.org/abs/2310.13391)

    本文提出了一种名为DHTM的算法，它基于因子图形式和多组成神经元模型，利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则来解决在线隐藏表示学习的挑战。实验结果表明，DHTM在变化的环境中比经典的LSTM效果更好，并与更先进的类似RNN的算法性能相当，可以加速继任者表示的时间差异学习。

    

    本文提出了一种新颖的方法来解决在线隐藏表示学习的挑战，该方法用于在不稳定的、部分可观测的环境中进行决策。所提出的算法，分布式Hebbian Temporal Memory (DHTM)，基于因子图形式和多组成神经元模型。DHTM旨在捕捉顺序数据关系并对未来观察作出累积预测，形成继任者表示。受新皮层的神经生理学模型启发，该算法利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则克服了传统时间记忆算法（如RNN和HMM）的不稳定性和慢速学习过程。实验结果表明，DHTM优于经典的LSTM，并与更先进的类似RNN的算法性能相当，在变化的环境中加速了继任者表示的时间差异学习。此外，我们还进行了比较。

    This paper presents a novel approach to address the challenge of online hidden representation learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Representation (SR). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms classical LSTM and performs comparably to more advanced RNN-like algorithms, speeding up Temporal Difference learning for SR in changing environments. Additionally, we compare
    
[^42]: Safety-Gymnasion：一个统一的安全强化学习基准

    Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark. (arXiv:2310.12567v1 [cs.AI])

    [http://arxiv.org/abs/2310.12567](http://arxiv.org/abs/2310.12567)

    本文介绍了一个名为Safety-Gymnasium的环境套件，其中包括单个和多个Agent场景中的安全关键任务，并提供了一个包含16种最先进的SafeRL算法的算法库。这个基准旨在促进对安全性能的评估和比较，推动强化学习在安全性能上的发展。

    

    人工智能系统拥有推动社会进步的巨大潜力。然而，它们的部署经常面临严重的安全问题。安全强化学习(SafeRL)作为一种解决方案出现，可以在同时遵守多个约束的情况下优化策略，从而解决集成强化学习在安全关键场景中的挑战。本文介绍了一个名为Safety-Gymnasium的环境套件，包括单个和多个Agent场景中的安全关键任务，并接受向量和仅视觉输入。此外，我们提供了一个名为Safe Policy Optimization（SafePO）的算法库，包含16种最先进的SafeRL算法。这个综合性库可以作为研究社区的验证工具。通过引入这个基准，我们旨在促进对安全性能的评估和比较，从而推动强化学习在安全性能上的发展。

    Artificial intelligence (AI) systems possess significant potential to drive societal progress. However, their deployment often faces obstacles due to substantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a solution to optimize policies while simultaneously adhering to multiple constraints, thereby addressing the challenge of integrating reinforcement learning in safety-critical scenarios. In this paper, we present an environment suite called Safety-Gymnasium, which encompasses safety-critical tasks in both single and multi-agent scenarios, accepting vector and vision-only input. Additionally, we offer a library of algorithms named Safe Policy Optimization (SafePO), comprising 16 state-of-the-art SafeRL algorithms. This comprehensive library can serve as a validation tool for the research community. By introducing this benchmark, we aim to facilitate the evaluation and comparison of safety performance, thus fostering the development of reinforcement learning for s
    
[^43]: 在开放世界转换中推进声学基础模型的测试时间自适应

    Advancing Test-Time Adaptation for Acoustic Foundation Models in Open-World Shifts. (arXiv:2310.09505v1 [cs.SD])

    [http://arxiv.org/abs/2310.09505](http://arxiv.org/abs/2310.09505)

    本文提出了一种针对声学基础模型的测试时间自适应方法，以解决开放世界数据转换中的分布变化问题。研究发现，噪声较大的语音帧包含重要的语义内容。

    

    测试时间自适应（TTA）是在推理过程中解决分布转换问题的关键方法，特别是在视觉识别任务中。然而，虽然声学模型在测试时间的语音分布转换中面临相似的挑战，但针对声学建模在开放世界数据转换环境下的TTA技术仍然很少见。考虑到声学基础模型的特点：1）它们主要是基于具有层归一化的变压器架构构建的；2）它们以一种非静态的方式处理长度不同的测试时间语音数据。这些因素使得在视觉聚焦的TTA方法的直接应用变得不可行，这些方法大多依赖于批归一化并假设独立样本。在本文中，我们深入研究了面临开放世界数据转换的预训练声学模型的TTA方法。我们发现，噪声较大、熵较高的语音帧通常带有关键的语义内容。传统的视觉TTA方法的直接应用在声学建模中并不可行。

    Test-Time Adaptation (TTA) is a critical paradigm for tackling distribution shifts during inference, especially in visual recognition tasks. However, while acoustic models face similar challenges due to distribution shifts in test-time speech, TTA techniques specifically designed for acoustic modeling in the context of open-world data shifts remain scarce. This gap is further exacerbated when considering the unique characteristics of acoustic foundation models: 1) they are primarily built on transformer architectures with layer normalization and 2) they deal with test-time speech data of varying lengths in a non-stationary manner. These aspects make the direct application of vision-focused TTA methods, which are mostly reliant on batch normalization and assume independent samples, infeasible. In this paper, we delve into TTA for pre-trained acoustic models facing open-world data shifts. We find that noisy, high-entropy speech frames, often non-silent, carry key semantic content. Tradit
    
[^44]: 《有声书的韵律分析》

    Prosody Analysis of Audiobooks. (arXiv:2310.06930v1 [cs.SD])

    [http://arxiv.org/abs/2310.06930](http://arxiv.org/abs/2310.06930)

    本研究通过使用一个含有93个书籍和对应有声书的数据集，提出了改进的模型来预测有声书文本中的韵律属性。结果显示，我们的预测韵律与人类朗读比商业级TTS系统更相关，并且人们更喜欢韵律增强的有声书朗读。

    

    最近在文本转语音方面取得了一些进展，使得从文本中生成自然音效的音频成为可能。然而，有声书朗读涉及到读者的戏剧性声音和语调，更多地依赖情感、对话和叙述。使用我们的数据集，包括93本书与其对应的有声书，我们提出了改进的模型，用于从叙述文本中预测韵律属性（音高、音量和语速），并使用语言建模。我们预测的韵律属性与人类朗读的相关性要远高于商业级TTS系统的结果：在24本书中，我们预测的音高对22本书的人类阅读更具相关性，而我们预测的音量属性对23本书的人类阅读更加相似。最后，我们进行了一项人类评估研究，以量化人们更喜欢韵律增强的有声书朗读还是商业级文本转语音系统。

    Recent advances in text-to-speech have made it possible to generate natural-sounding audio from text. However, audiobook narrations involve dramatic vocalizations and intonations by the reader, with greater reliance on emotions, dialogues, and descriptions in the narrative. Using our dataset of 93 aligned book-audiobook pairs, we present improved models for prosody prediction properties (pitch, volume, and rate of speech) from narrative text using language modeling. Our predicted prosody attributes correlate much better with human audiobook readings than results from a state-of-the-art commercial TTS system: our predicted pitch shows a higher correlation with human reading for 22 out of the 24 books, while our predicted volume attribute proves more similar to human reading for 23 out of the 24 books. Finally, we present a human evaluation study to quantify the extent that people prefer prosody-enhanced audiobook readings over commercial text-to-speech systems.
    
[^45]: 针对随机驾驶环境的不确定性感知决策Transformer

    Uncertainty-Aware Decision Transformer for Stochastic Driving Environments. (arXiv:2309.16397v1 [cs.LG])

    [http://arxiv.org/abs/2309.16397](http://arxiv.org/abs/2309.16397)

    本论文提出了一种针对随机驾驶环境的不确定性感知决策Transformer（UNREST），通过估计状态的不确定性并相应地分割序列，取代了全局回报。这项工作通过解决在不确定性环境中过于乐观的问题，为离线强化学习在自主驾驶任务中的应用提供了一种有效的解决方案。

    

    离线强化学习（RL）已经成为一种无需主动交互的学习策略的有希望框架，因此在自主驾驶任务中尤其吸引人。最近Transformers的成功启发了将离线RL视为序列建模，这在长期任务中表现出色。然而，在具有不确定性的环境中，它们过于乐观，错误地假设相同的目标可以通过相同的动作一致实现。在本文中，我们引入了一种针对随机驾驶环境的不确定性感知决策Transformer（UNREST），不引入额外的转换模型或复杂的生成模型来进行规划。具体而言，UNREST通过转换与回报之间的条件互信息来估计状态的不确定性，并相应地分割序列。通过发现驾驶环境的“不确定性累积”和“时间局部性”特性，UNREST将决策Transformer中的全局回报替换为较少的部分回报。

    Offline Reinforcement Learning (RL) has emerged as a promising framework for learning policies without active interactions, making it especially appealing for autonomous driving tasks. Recent successes of Transformers inspire casting offline RL as sequence modeling, which performs well in long-horizon tasks. However, they are overly optimistic in stochastic environments with incorrect assumptions that the same goal can be consistently achieved by identical actions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in stochastic driving environments without introducing additional transition or complex generative models. Specifically, UNREST estimates state uncertainties by the conditional mutual information between transitions and returns, and segments sequences accordingly. Discovering the `uncertainty accumulation' and `temporal locality' properties of driving environments, UNREST replaces the global returns in decision transformers with less 
    
[^46]: NoSENSE：学习无需显式灵敏度图的展开心脏MRI重建方法

    NoSENSE: Learned unrolled cardiac MRI reconstruction without explicit sensitivity maps. (arXiv:2309.15608v1 [eess.IV])

    [http://arxiv.org/abs/2309.15608](http://arxiv.org/abs/2309.15608)

    本文提出了一种无需显式灵敏度图的展开心脏MRI重建方法，使用深度卷积神经网络和算法展开，通过学习图像之间的接收线圈关系来实现加速心脏MRI重建，在实验中取得了较好的性能。

    

    本文提出了一种新颖的学习图像重建方法，适用于基于多个接收线圈的加速心脏MRI。该方法基于深度卷积神经网络（CNN）和算法展开。与许多现有的学习MR图像重建技术不同，需要将灵敏度映射（CSM）估计作为一个独立的网络组件，我们提出的方法避免了显式的CSM估计。相反，它隐含地捕捉并学习利用图像之间的接收线圈关系。我们的方法由一系列新颖的学习图像块和k空间块组成，共享潜在信息，并通过特征调节和接收线圈数据一致性实现对采集参数的适应性。在MICCAI STACOM CMRxRecon挑战赛的影片追踪和映射追踪验证排行榜中，我们的方法分别在PSNR值上达到了34.89和35.56，SSIM值分别为0.920和0.942，在撰写本文时位列不同小组第4位。

    We present a novel learned image reconstruction method for accelerated cardiac MRI with multiple receiver coils based on deep convolutional neural networks (CNNs) and algorithm unrolling. In contrast to many existing learned MR image reconstruction techniques that necessitate coil-sensitivity map (CSM) estimation as a distinct network component, our proposed approach avoids explicit CSM estimation. Instead, it implicitly captures and learns to exploit the inter-coil relationships of the images. Our method consists of a series of novel learned image and k-space blocks with shared latent information and adaptation to the acquisition parameters by feature-wise modulation (FiLM), as well as coil-wise data-consistency (DC) blocks.  Our method achieved PSNR values of 34.89 and 35.56 and SSIM values of 0.920 and 0.942 in the cine track and mapping track validation leaderboard of the MICCAI STACOM CMRxRecon Challenge, respectively, ranking 4th among different teams at the time of writing.  Cod
    
[^47]: 无穷宽度两层ReLU神经网络的同伦松弛训练算法

    Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer ReLU Neural Networks. (arXiv:2309.15244v1 [cs.LG])

    [http://arxiv.org/abs/2309.15244](http://arxiv.org/abs/2309.15244)

    本文提出了一种名为同伦松弛训练算法（HRTA）的新的训练方法，它通过构建无缝连接线性激活函数和ReLU激活函数的同伦激活函数，并松弛同伦参数以增强训练精细化过程，加速了训练过程，在神经切线核（NTK）的背景下，实现了显著改进的收敛速度，并展示了对其他激活函数和深度神经网络的潜力。

    

    本文提出了一种新的训练方法，称为同伦松弛训练算法（HRTA），旨在加速训练过程，与传统方法相比。我们的算法结合了两个关键机制：一个是构建无缝连接线性激活函数和ReLU激活函数的同伦激活函数；另一个技术是松弛同伦参数以增强训练精细化过程。我们在神经切线核（NTK）的背景下对这种新方法进行了深入分析，揭示了显著改进的收敛速度。我们的实验结果，尤其是在考虑更大宽度的网络时，验证了理论结论。这种提议的HRTA展示了对其他激活函数和深度神经网络的潜力。

    In this paper, we present a novel training approach called the Homotopy Relaxation Training Algorithm (HRTA), aimed at accelerating the training process in contrast to traditional methods. Our algorithm incorporates two key mechanisms: one involves building a homotopy activation function that seamlessly connects the linear activation function with the ReLU activation function; the other technique entails relaxing the homotopy parameter to enhance the training refinement process. We have conducted an in-depth analysis of this novel method within the context of the neural tangent kernel (NTK), revealing significantly improved convergence rates. Our experimental results, especially when considering networks with larger widths, validate the theoretical conclusions. This proposed HRTA exhibits the potential for other activation functions and deep neural networks.
    
[^48]: 基于注意力驱动的多模态融合：增强手语识别和翻译

    Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation. (arXiv:2309.01860v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.01860](http://arxiv.org/abs/2309.01860)

    本文提出了一种注意力驱动的多模态融合机制，通过将光流信息与RGB图像相结合，丰富了连续手语识别和翻译流程中的特征。该方法在手语识别任务中降低了WER 0.9，在翻译任务中提高了测试集上大多数BLEU分数约0.6。

    

    本文中，我们设计了一种机制，用于将多模态信息与现有的连续手语识别和翻译流程相结合。在我们的过程中，我们将光流信息与RGB图像结合，以丰富具有与运动相关信息的特征。该工作通过使用跨模态编码器研究了这种模态包含的可行性。我们使用的插件非常轻量级，并且不需要以端到端的方式为新模态包括一个单独的特征提取器。我们在手语识别和翻译中应用了这些改变，改善了每个任务的结果。我们在RWTH-PHOENIX-2014数据集上评估了性能，用于手语识别，并在RWTH-PHOENIX-2014T数据集上评估了翻译任务。在识别任务上，我们的方法将WER降低了0.9，在翻译任务上，我们的方法将大部分BLEU分数在测试集上提高了约0.6。

    In this paper, we devise a mechanism for the addition of multi-modal information with an existing pipeline for continuous sign language recognition and translation. In our procedure, we have incorporated optical flow information with RGB images to enrich the features with movement-related information. This work studies the feasibility of such modality inclusion using a cross-modal encoder. The plugin we have used is very lightweight and doesn't need to include a separate feature extractor for the new modality in an end-to-end manner. We have applied the changes in both sign language recognition and translation, improving the result in each case. We have evaluated the performance on the RWTH-PHOENIX-2014 dataset for sign language recognition and the RWTH-PHOENIX-2014T dataset for translation. On the recognition task, our approach reduced the WER by 0.9, and on the translation task, our approach increased most of the BLEU scores by ~0.6 on the test set.
    
[^49]: 一种模拟保险欺诈网络数据的引擎

    An engine to simulate insurance fraud network data. (arXiv:2308.11659v1 [cs.LG])

    [http://arxiv.org/abs/2308.11659](http://arxiv.org/abs/2308.11659)

    本论文介绍了一种模拟保险欺诈网络数据的引擎，利用索赔涉及方的社交网络特征进行学习方法，旨在开发高效准确的欺诈检测模型。但面临类别不平衡、大量未标记数据和缺乏公开数据等挑战。

    

    传统上，检测保险欺诈索赔依赖于业务规则和专家判断，这使得这一过程耗时且昂贵。因此，研究人员一直在探索开发高效准确的分析策略来标记可疑索赔。从索赔涉及方的社交网络中提取特征并将其馈送给学习方法是一种特别有潜力的策略。然而，在开发欺诈检测模型时，我们面临着几个挑战。例如，欺诈的非常规性质导致了高度的类别不平衡，这增加了开发性能良好的分析分类模型的难度。此外，只有少数索赔得到调查和标签，从而产生了大量未标记的数据。另一个挑战是缺乏公开可用的数据，这妨碍了研究和模型验证。

    Traditionally, the detection of fraudulent insurance claims relies on business rules and expert judgement which makes it a time-consuming and expensive process (\'Oskarsd\'ottir et al., 2022). Consequently, researchers have been examining ways to develop efficient and accurate analytic strategies to flag suspicious claims. Feeding learning methods with features engineered from the social network of parties involved in a claim is a particularly promising strategy (see for example Van Vlasselaer et al. (2016); Tumminello et al. (2023)). When developing a fraud detection model, however, we are confronted with several challenges. The uncommon nature of fraud, for example, creates a high class imbalance which complicates the development of well performing analytic classification models. In addition, only a small number of claims are investigated and get a label, which results in a large corpus of unlabeled data. Yet another challenge is the lack of publicly available data. This hinders not 
    
[^50]: 使用深度学习模型进行血细胞分类

    Classification of Blood Cells Using Deep Learning Models. (arXiv:2308.06300v1 [eess.IV])

    [http://arxiv.org/abs/2308.06300](http://arxiv.org/abs/2308.06300)

    这项研究使用深度学习模型通过图像分类对人类血细胞进行了分类和识别，为诊断疾病提供了重要的帮助。

    

    人类血液主要包括血浆、红细胞、白细胞和血小板。血细胞为身体细胞提供氧气，滋养它们，保护它们免受感染，增强免疫力并促进凝血。人的健康状况可以从血细胞中反映出来。一个人被诊断出某种疾病的机会很大程度上受其血细胞类型和计数的影响。因此，血细胞分类非常重要，它可以帮助识别疾病，包括癌症、骨髓损伤、良性肿瘤和它们的生长。这种分类可以帮助血液学家区分不同的血细胞片段，以便确定疾病的原因。卷积神经网络是一种深度学习技术，它将人类血细胞（红细胞、白细胞和血小板）的图像分类为它们的亚型。在这项研究中，使用迁移学习将不同的CNN预训练模型应用于血细胞分类。

    Human blood mainly comprises plasma, red blood cells, white blood cells, and platelets. The blood cells provide the body's cells oxygen to nourish them, shield them from infections, boost immunity, and aid in clotting. Human health is reflected in blood cells. The chances that a human being can be diagnosed with a disease are significantly influenced by their blood cell type and count. Therefore, blood cell classification is crucial because it helps identify diseases, including cancer, damaged bone marrow, benign tumors, and their growth. This classification allows hematologists to distinguish between different blood cell fragments so that the cause of diseases can be identified. Convolution neural networks are a deep learning technique that classifies images of human blood cells (RBCs, WBCs, and platelets) into their subtypes. For this study, transfer learning is used to apply different CNN pre-trained models, including VGG16, VGG19, ResNet-50, ResNet-101, ResNet-152, InceptionV3 Mobi
    
[^51]: 带有基于学习的地形和机器人感知动力模型的上下文条件导航

    Context-Conditional Navigation with a Learning-Based Terrain- and Robot-Aware Dynamics Model. (arXiv:2307.09206v1 [cs.RO])

    [http://arxiv.org/abs/2307.09206](http://arxiv.org/abs/2307.09206)

    本文提出了一种名为TRADYN的概率地形和机器人感知前向动力学模型，能够适应在自主导航环境中的地形和机器人的变化，通过在模拟的二维导航环境中的实验证明，该模型在长视程轨迹预测任务中表现出较低的预测误差。

    

    在自主导航环境中，多个参数可能会发生变化。地形特性如摩擦系数可能会根据机器人的位置而随时间变化。此外，机器人的动力学可能会因不同负载、系统质量变化、磨损等原因而发生变化，从而改变执行器增益或关节摩擦力。自主代理应该能够适应这些变化。在本文中，我们开发了一种新颖的概率地形和机器人感知前向动力学模型，称为TRADYN，它能够适应上述变化。它基于基于神经过程的元学习前向动力学模型的最新进展。我们在模拟的二维导航环境中评估了我们的方法，使用了一个类似自行车的机器人和具有空间变化摩擦系数的不同地形布局。在我们的实验中，与非自适应方法相比，所提出的模型在长视程轨迹预测任务中表现出较低的预测误差。

    In autonomous navigation settings, several quantities can be subject to variations. Terrain properties such as friction coefficients may vary over time depending on the location of the robot. Also, the dynamics of the robot may change due to, e.g., different payloads, changing the system's mass, or wear and tear, changing actuator gains or joint friction. An autonomous agent should thus be able to adapt to such variations. In this paper, we develop a novel probabilistic, terrain- and robot-aware forward dynamics model, termed TRADYN, which is able to adapt to the above-mentioned variations. It builds on recent advances in meta-learning forward dynamics models based on Neural Processes. We evaluate our method in a simulated 2D navigation setting with a unicycle-like robot and different terrain layouts with spatially varying friction coefficients. In our experiments, the proposed model exhibits lower prediction error for the task of long-horizon trajectory prediction, compared to non-ada
    
[^52]: 学习核技术用于可解释和高效的PPG信号质量评估和伪影分割

    Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation. (arXiv:2307.05385v1 [eess.SP])

    [http://arxiv.org/abs/2307.05385](http://arxiv.org/abs/2307.05385)

    本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。

    

    光电容抗(PPG)提供了一种低成本、非侵入性的方法来持续监测各种心血管参数。PPG信号由可穿戴设备产生，常常包含由外部因素(如人体运动)引起的大型伪影。为了确保对生理参数进行稳健和准确的提取，信号的损坏区域需要被正确地识别和处理。之前的方法依靠手工特征检测器或信号度量，结果性能不佳，或依靠深度神经网络(DNN)等机器学习技术，缺乏可解释性，计算和内存密集。在这项工作中，我们提出了一种新的方法，学习一小组可解释的卷积核，其性能与现有技术DNN方法相似，甚至更好，而参数数量比DNN方法少几个数量级。这项工作实现了高效、稳健和可解释的PPG信号质量评估和伪影分割。

    Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and int
    
[^53]: 用Transformer学习超关系型和数值知识图中的表征学习

    Representation Learning on Hyper-Relational and Numeric Knowledge Graphs with Transformers. (arXiv:2305.18256v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.18256](http://arxiv.org/abs/2305.18256)

    本文提出了一个名为HyNT的框架，用于学习超关系型知识图的表示，包括数值文字。该框架使用上下文Transformer和预测Transformer，通过学习三元组和其限定词之间的相关性以及数值信息来获得模型。

    

    近期研究了一个超关系型知识图谱，其中三元组与限定词集合相关联; 一个限定词由关系和实体组成，为三元组提供辅助信息。现有的超关系型知识图嵌入方法假定实体是离散对象，但有些信息应使用数值表示，例如(J.R.R.，出生于，1892)。同时，三元组(J.R.R.，就读于，牛津大学)可以与限定词(开始时间，1911)相关联。在本文中，我们提出了一个名为HyNT的统一框架，用于学习包含三元组或限定词中数值文字的超关系型知识图的表示。我们定义了一个上下文Transformer和一个预测Transformer，来学习表示，不仅基于三元组和其限定词之间的相关性，还基于数值信息。通过学习三元组和限定词的紧凑表示，并将它们馈送给Transformer来获得模型

    A hyper-relational knowledge graph has been recently studied where a triplet is associated with a set of qualifiers; a qualifier is composed of a relation and an entity, providing auxiliary information for a triplet. While existing hyper-relational knowledge graph embedding methods assume that the entities are discrete objects, some information should be represented using numeric values, e.g., (J.R.R., was born in, 1892). Also, a triplet (J.R.R., educated at, Oxford Univ.) can be associated with a qualifier such as (start time, 1911). In this paper, we propose a unified framework named HyNT that learns representations of a hyper-relational knowledge graph containing numeric literals in either triplets or qualifiers. We define a context transformer and a prediction transformer to learn the representations based not only on the correlations between a triplet and its qualifiers but also on the numeric information. By learning compact representations of triplets and qualifiers and feeding 
    
[^54]: 神经网络训练中的损失峰值研究

    Loss Spike in Training Neural Networks. (arXiv:2305.12133v1 [cs.LG])

    [http://arxiv.org/abs/2305.12133](http://arxiv.org/abs/2305.12133)

    本文研究神经网络训练过程中损失值峰值现象的机制，并发现最大特征值的第一个特征向量的偏差主要受低频成分占据。低频成分可以被训练数据和测试数据很好地捕获，所以导致具有良好和劣质泛化能力的解决方案都可以很好地学习低频成分，但劣质泛化能力的解决方案可能会过度拟合高频成分，良好泛化能力的解决方案具有更平滑的损失函数。

    

    本文研究了神经网络训练过程中出现的损失值峰值现象所背后的机制。研究发现，在具有较小损失的区域，一旦训练进入该区域，训练就会变得不稳定，损失值呈指数式增长，即出现损失峰值现象。当训练进入平坦区域时，训练会变得稳定。本研究发现，损失Hessian矩阵的最大特征值（$\lambda_{\mathrm{max}}$）的第一个特征向量的偏差主要由低频成分占据。由于低频成分可以非常快速地被捕获（频率原理），因此会出现急剧下降的现象。在分析损失峰值的基础上，我们重新审视了$\lambda_{\mathrm{max}}$平坦性和泛化能力之间的关系。对于实际数据集，低频往往占据主导地位，并且可以被训练数据和测试数据所很好地捕获。因此，具有良好泛化能力和具有劣质泛化能力的解决方案都可以很好地学习低频成分，因此它们在损失函数上的性质相似。但是，劣质泛化能力的解决方案可能会过度拟合高频成分，而良好泛化能力的解决方案具有更平滑的损失函数。

    In this work, we study the mechanism underlying loss spikes observed during neural network training. When the training enters a region, which has a smaller-loss-as-sharper (SLAS) structure, the training becomes unstable and loss exponentially increases once it is too sharp, i.e., the rapid ascent of the loss spike. The training becomes stable when it finds a flat region. The deviation in the first eigen direction (with maximum eigenvalue of the loss Hessian ($\lambda_{\mathrm{max}}$) is found to be dominated by low-frequency. Since low-frequency is captured very fast (frequency principle), the rapid descent is then observed. Inspired by our analysis of loss spikes, we revisit the link between $\lambda_{\mathrm{max}}$ flatness and generalization. For real datasets, low-frequency is often dominant and well-captured by both the training data and the test data. Then, a solution with good generalization and a solution with bad generalization can both learn low-frequency well, thus, they hav
    
[^55]: SREL：基于S参数模式的铜互连非破坏故障诊断的严重性评级集成学习

    SREL: Severity Rating Ensemble Learning for Non-Destructive Fault Diagnosis of Cu Interconnects using S-parameter Patterns. (arXiv:2304.10207v1 [cs.LG])

    [http://arxiv.org/abs/2304.10207](http://arxiv.org/abs/2304.10207)

    本研究利用S参数模式成功实现对Cu互连缺陷的非破坏性检测和诊断，在同时分析根本原因和严重性方面具有先进性，具备早期检测、高诊断准确度和噪声鲁棒性等优点。

    

    随着处理器的工作频率和时钟速度逐年提高，互连对整个电子系统的可靠性和性能都产生了影响。检测和诊断互连故障对电子健康管理至关重要。然而，利用电信号作为预测因子的现有研究存在局限性，例如无法区分缺陷的根本原因，最终需要进行额外的破坏性评估，并容易受到噪声的干扰而导致误警。本文实现了对Cu互连缺陷的非破坏性检测和诊断，实现了早期检测、高诊断准确度和噪声鲁棒性。据我们所知，本研究首次利用电信号模式同时分析根本原因和严重性。在本文中，我们实验性地展示了S参数模式具有故障诊断能力。

    As operating frequencies and clock speeds in processors have increased over the years, interconnects affect both the reliability and performance of entire electronic systems. Fault detection and diagnosis of the interconnects are crucial for prognostics and health management (PHM) of electronics. However, existing research works utilizing electrical signals as prognostic factors have limitations, such as the inability to distinguish the root cause of defects, which eventually requires additional destructive evaluation, and vulnerability to noise that results in a false alarm. Herein, we realize the non-destructive detection and diagnosis of defects in Cu interconnects, achieving early detection, high diagnostic accuracy, and noise robustness. To the best of our knowledge, this study first simultaneously analyzes the root cause and severity using electrical signal patterns. In this paper, we experimentally show that S-parameter patterns have the ability for fault diagnosis and they are 
    
[^56]: PI-FL：个性化和激励联邦学习

    PI-FL: Personalized and Incentivized Federated Learning. (arXiv:2304.07514v1 [cs.LG])

    [http://arxiv.org/abs/2304.07514](http://arxiv.org/abs/2304.07514)

    PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。

    

    个性化联邦学习已被广泛应用于应对非独立同分布数据异质性的挑战。主要问题是考虑来自客户端的个性化过程以保护其自治权。允许客户端参与个性化联邦学习决策变得重要，因为存在隐私和安全问题，客户端可能无法自由共享生成良好质量个性化模型所必需的私人信息。此外，具有高质量数据和资源的客户端不愿意在没有合理激励的情况下参与联邦学习过程。在本文中，我们提出了PI-FL，这是一个一次性个性化解决方案，配合一个基于令牌的激励机制，奖励个性化训练。PI-FL优于其他最先进的方法，并且可以在尊重客户端隐私的同时生成高质量的个性化模型。

    Personalized FL has been widely used to cater to heterogeneity challenges with non-IID data. A primary obstacle is considering the personalization process from the client's perspective to preserve their autonomy. Allowing the clients to participate in personalized FL decisions becomes significant due to privacy and security concerns, where the clients may not be at liberty to share private information necessary for producing good quality personalized models. Moreover, clients with high-quality data and resources are reluctant to participate in the FL process without reasonable incentive. In this paper, we propose PI-FL, a one-shot personalization solution complemented by a token-based incentive mechanism that rewards personalized training. PI-FL outperforms other state-of-the-art approaches and can generate good-quality personalized models while respecting clients' privacy.
    
[^57]: 多目标深度强化学习中的潜在条件策略梯度

    Latent-Conditioned Policy Gradient for Multi-Objective Deep Reinforcement Learning. (arXiv:2303.08909v1 [cs.LG])

    [http://arxiv.org/abs/2303.08909](http://arxiv.org/abs/2303.08909)

    该论文提出了一种新的多目标深度强化学习算法，通过策略梯度训练单个神经网络，以在单次训练运行中近似获取整个帕累托集，而不依赖于目标的线性标量化。

    

    在现实世界中进行序列决策通常需要找到平衡相互矛盾的目标的良好平衡点。一般来说，存在大量的帕累托最优策略，它们体现了不同的目标权衡模式，并且使用深度神经网络全面获得它们具有技术挑战性。在本文中，我们提出了一种新的多目标强化学习（MORL）算法，通过策略梯度训练单个神经网络，以在单次训练运行中近似获取整个帕累托集，而不依赖于目标的线性标量化。该方法适用于连续和离散的行动空间，并且不需要修改策略网络的设计。在基准环境中的数字实验证明了我们的方法与标准MORL基线相比的实用性和有效性。

    Sequential decision making in the real world often requires finding a good balance of conflicting objectives. In general, there exist a plethora of Pareto-optimal policies that embody different patterns of compromises between objectives, and it is technically challenging to obtain them exhaustively using deep neural networks. In this work, we propose a novel multi-objective reinforcement learning (MORL) algorithm that trains a single neural network via policy gradient to approximately obtain the entire Pareto set in a single run of training, without relying on linear scalarization of objectives. The proposed method works in both continuous and discrete action spaces with no design change of the policy network. Numerical experiments in benchmark environments demonstrate the practicality and efficacy of our approach in comparison to standard MORL baselines.
    
[^58]: 解决竞争性多智能体决策和控制问题的主动学习方法

    An active learning method for solving competitive multi-agent decision-making and control problems. (arXiv:2212.12561v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2212.12561](http://arxiv.org/abs/2212.12561)

    我们提出了一个基于主动学习的方法，用于解决竞争性多智能体决策和控制问题。通过重构私有策略和预测稳态行动配置文件，外部观察者可以成功进行预测和优化策略。

    

    我们提出了一种基于主动学习的方案，用于重构由相互作用代理人群体执行的私有策略，并预测底层多智能体交互过程的确切结果，这里被认为是一个稳定的行动配置文件。我们设想了一个场景，在这个场景中，一个具有学习程序的外部观察者可以通过私有的行动-反应映射进行查询和观察代理人的反应，集体的不动点对应于一个稳态配置文件。通过迭代地收集有意义的数据和更新行动-反应映射的参数估计，我们建立了评估所提出的主动学习方法的渐近性质的充分条件，以便如果收敛发生，它只能朝向一个稳态行动配置文件。这一事实导致了两个主要结果：i）学习局部精确的行动-反应映射替代物使得外部观察者能够成功完成其预测任务，ii）与代理人的互动提供了一种方法来优化策略以达到最佳效果。

    We propose a scheme based on active learning to reconstruct private strategies executed by a population of interacting agents and predict an exact outcome of the underlying multi-agent interaction process, here identified as a stationary action profile. We envision a scenario where an external observer, endowed with a learning procedure, can make queries and observe the agents' reactions through private action-reaction mappings, whose collective fixed point corresponds to a stationary profile. By iteratively collecting sensible data and updating parametric estimates of the action-reaction mappings, we establish sufficient conditions to assess the asymptotic properties of the proposed active learning methodology so that, if convergence happens, it can only be towards a stationary action profile. This fact yields two main consequences: i) learning locally-exact surrogates of the action-reaction mappings allows the external observer to succeed in its prediction task, and ii) working with 
    

