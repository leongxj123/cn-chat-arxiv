# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SeisFusion: Constrained Diffusion Model with Input Guidance for 3D Seismic Data Interpolation and Reconstruction](https://arxiv.org/abs/2403.11482) | 提出了一种适用于3D地震数据的新型扩散模型重建框架，可以在处理复杂缺失模式时提高重建性能 |
| [^2] | [FedQNN: Federated Learning using Quantum Neural Networks](https://arxiv.org/abs/2403.10861) | FedQNN框架融合了量子机器学习与经典联邦学习原则，在保护数据隐私的分布式环境中实现了合作学习，具有高准确率。 |
| [^3] | [Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective](https://arxiv.org/abs/2402.18607) | 本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。 |
| [^4] | [MMSR: Symbolic Regression is a Multimodal Task](https://arxiv.org/abs/2402.18603) | 符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。 |
| [^5] | [Avoiding Catastrophic Forgetting in Visual Classification Using Human Concept Formation](https://arxiv.org/abs/2402.16933) | 提出了一种名为Cobweb4V的新颖视觉分类方法，利用人类类似学习系统，避免了灾难性遗忘效应，与传统方法相比，需要更少的数据来实现有效学习成果，并保持稳定性能。 |
| [^6] | [Learning by Watching: A Review of Video-based Learning Approaches for Robot Manipulation](https://arxiv.org/abs/2402.07127) |  |
| [^7] | [Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation](https://arxiv.org/abs/2402.03990) | 通过研究差分隐私随机梯度下降（DP-SGD）中的总梯度方差，我们发现大批次大小有助于减小則采樣引起的方差，从而提高优化效果。 |
| [^8] | [Hybrid quantum cycle generative adversarial network for small molecule generation](https://arxiv.org/abs/2402.00014) | 本文介绍了一种基于参数化量子电路的新型生成对抗网络模型，通过引入强化学习原理的多参数奖励函数，成功优化了小分子生成的药物样性估计，最高提升了30%。 |
| [^9] | [On Measuring Faithfulness or Self-consistency of Natural Language Explanations](https://arxiv.org/abs/2311.07466) | 本文论述了衡量自然语言解释的忠诚度或自一致性的问题。我们提出了自一致性测试来评估解释的输出级别的一致性。我们通过构建比较一致性测试库，并引入了新的自一致性度量CC-SHAP来支持我们的观点。 |
| [^10] | [Customizing Graph Neural Networks using Path Reweighting](https://arxiv.org/abs/2106.10866) | 使用路径重加权的定制图神经网络CustomGNN可以自动学习特定下游任务的高层语义，突出与语义相关的路径，并过滤掉任务无关的噪音，避免传统GNN中的过度平滑、鲁棒性差和过拟合问题。 |
| [^11] | [Ethical Artificial Intelligence Principles and Guidelines for the Governance and Utilization of Highly Advanced Large Language Models.](http://arxiv.org/abs/2401.10745) | 本文探讨了如何利用道德人工智能原则和指南来解决高级大型语言模型的治理和利用问题。 |
| [^12] | [Towards Model-Free LQR Control over Rate-Limited Channels.](http://arxiv.org/abs/2401.01258) | 这篇论文研究了在速率限制通道上实现模型无关的LQR控制的问题。通过引入自适应量化梯度下降（AQGD）算法，作者证明了在噪声电路中可以实现控制问题的解决。 |
| [^13] | [A Survey on Graph Neural Networks in Intelligent Transportation Systems.](http://arxiv.org/abs/2401.00713) | 本研究调查了智能交通系统中图神经网络的应用。图神经网络通过其强大的图建模能力，在交通领域表现出优秀性能。然而，目前研究主要集中在交通预测方面，其他领域仍需更多关注。 |
| [^14] | [Estimation and Inference in Distributional Reinforcement Learning.](http://arxiv.org/abs/2309.17262) | 本文研究了分布式强化学习中的估计和推断问题，通过使用等价确定法，在提供生成模型的情况下以高效的方式解决了分布式策略评估问题。 |
| [^15] | [Targeting Relative Risk Heterogeneity with Causal Forests.](http://arxiv.org/abs/2309.15793) | 本研究提出了一种通过修改因果森林方法，以相对风险为目标，从而捕捉到治疗效应异质性的潜在来源。 |
| [^16] | [Dynamic control of self-assembly of quasicrystalline structures through reinforcement learning.](http://arxiv.org/abs/2309.06869) | 本研究提出使用强化学习来控制具有多边形单元颗粒的动态自组装过程，形成十二边准晶体。我们通过估计最佳的温度控制策略，成功地生成了几乎没有缺陷的结构。强化学习获得的温度调度比传统的预设温度调度更有效地重现了期望的结构。 |
| [^17] | [Designing an attack-defense game: how to increase robustness of financial transaction models via a competition.](http://arxiv.org/abs/2308.11406) | 通过设计一款攻防游戏，我们研究了使用序列金融数据的神经网络模型的对抗攻击和防御的现状和动态，并且通过分析比赛动态，回答了隐藏模型免受恶意用户攻击的重要性以及需要多长时间才能破解模型的问题。 |
| [^18] | [Explanation-Guided Fair Federated Learning for Transparent 6G RAN Slicing.](http://arxiv.org/abs/2307.09494) | 这篇论文提出了一个解释引导的联邦学习方案，通过利用可解释的人工智能策略产生透明和无偏的深度神经网络，从而确保可靠的预测。 |
| [^19] | [Forecasting the steam mass flow in a powerplant using the parallel hybrid network.](http://arxiv.org/abs/2307.09483) | 这项研究使用并行混合神经网络结构来预测发电厂中的蒸汽质量流量，相比纯经典和纯量子模型，该混合模型在测试集上取得了更好的性能，平均平方误差降低了5.7倍和4.9倍，并且相对误差较小，最多提升了2倍。 |
| [^20] | [Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem.](http://arxiv.org/abs/2307.03515) | 本文提出了一种基于破产问题的方法来解决垂直联邦学习中激励分配的挑战，以确保公平性和稳定性。 |
| [^21] | [Optimal Heterogeneous Collaborative Linear Regression and Contextual Bandits.](http://arxiv.org/abs/2306.06291) | 本文提出了一种新的估计器MOLAR，它利用协同线性回归和上下文臂问题中的稀疏异质性来提高估计精度，并且相比独立方法具有更好的表现。 |
| [^22] | [Self-attention Dual Embedding for Graphs with Heterophily.](http://arxiv.org/abs/2305.18385) | 本研究提出了一种新颖的图神经网络，采用自注意力机制，适用于异质性图和同质性图，并在许多标准数据集上展示出最先进的性能。 |
| [^23] | [Node Feature Augmentation Vitaminizes Network Alignment.](http://arxiv.org/abs/2304.12751) | 本研究提出了Grad-Align+方法，通过增强节点特征来执行NA任务，并最大限度地利用增强的节点特征来设计NA方法，解决了NA方法缺乏额外信息的问题。 |
| [^24] | [NN-Copula-CD: A Copula-Guided Interpretable Neural Network for Change Detection in Heterogeneous Remote Sensing Images.](http://arxiv.org/abs/2303.17448) | 该论文提出了一种可解释的神经网络方法，结合Copula理论来解决异构遥感图像中的变化检测问题。 |
| [^25] | [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention.](http://arxiv.org/abs/2303.16199) | 本文提出了一种基于适应提示和零初始化注意力机制的轻量级语言模型调整方法，可高效微调LLaMA为指令跟随模型，具有比Alpaca更短的微调时间并具有近似的响应质量。 |
| [^26] | [repliclust: Synthetic Data for Cluster Analysis.](http://arxiv.org/abs/2303.14301) | repliclust 是一个 Python 包，用于生成具有聚类的合成数据集，基于数据集的原型，提供了放置集群中心、采样集群形状、选择每个集群的数据点数量以及为集群分配概率分布的算法。 |
| [^27] | [Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation.](http://arxiv.org/abs/2210.05918) | 本研究通过引入尾平均和正则化技术，对时序差异(TD)学习算法进行了有限时间行为的研究。我们得出结论，尾平均TD能以最优速率 $O(1/t)$ 收敛，并且初始误差衰减速率更快。此外，正则化的TD版本在具有病态特征的问题上很有用。 |

# 详细

[^1]: SeisFusion: 带有输入指导的受限扩散模型用于3D地震数据插值和重构

    SeisFusion: Constrained Diffusion Model with Input Guidance for 3D Seismic Data Interpolation and Reconstruction

    [https://arxiv.org/abs/2403.11482](https://arxiv.org/abs/2403.11482)

    提出了一种适用于3D地震数据的新型扩散模型重建框架，可以在处理复杂缺失模式时提高重建性能

    

    地理、物理或经济约束通常导致地震数据中存在缺失的痕迹，使得重建完整的地震数据成为地震数据处理中的关键步骤。传统的地震数据重建方法需要选择多个经验参数，并且难以处理大规模连续缺失数据。随着深度学习的发展，各种神经网络展示出强大的重建能力。然而，这些卷积神经网络代表了一种点对点的重建方法，可能无法覆盖整个数据集的分布。因此，当处理具有复杂缺失模式的地震数据时，这些网络可能会经历不同程度的性能下降。针对这一挑战，我们提出了一种针对3D地震数据量身定制的新颖扩散模型重建框架。

    arXiv:2403.11482v1 Announce Type: new  Abstract: Geographical, physical, or economic constraints often result in missing traces within seismic data, making the reconstruction of complete seismic data a crucial step in seismic data processing. Traditional methods for seismic data reconstruction require the selection of multiple empirical parameters and struggle to handle large-scale continuous missing data. With the development of deep learning, various neural networks have demonstrated powerful reconstruction capabilities. However, these convolutional neural networks represent a point-to-point reconstruction approach that may not cover the entire distribution of the dataset. Consequently, when dealing with seismic data featuring complex missing patterns, such networks may experience varying degrees of performance degradation. In response to this challenge, we propose a novel diffusion model reconstruction framework tailored for 3D seismic data. To constrain the results generated by the
    
[^2]: FedQNN: 使用量子神经网络的联邦学习

    FedQNN: Federated Learning using Quantum Neural Networks

    [https://arxiv.org/abs/2403.10861](https://arxiv.org/abs/2403.10861)

    FedQNN框架融合了量子机器学习与经典联邦学习原则，在保护数据隐私的分布式环境中实现了合作学习，具有高准确率。

    

    在这项研究中，我们探索了量子联邦学习（QFL）的创新领域，作为通过分布式网络训练量子机器学习（QML）模型的框架。我们提出的联邦量子神经网络（FedQNN）框架是一种尖端解决方案，将QML的独特特征与经典联邦学习的原则相结合。这项工作彻底调查了QFL，在分布式环境中保护数据处理的能力，并促进合作学习而无需直接共享数据。我们的研究通过在不同数据集（包括基因组学和医疗保健）上进行实验证实了这一概念，从而验证了我们的FedQNN框架的多功能性和高效性。结果在三个不同数据集上始终保持在86%以上的准确率。

    arXiv:2403.10861v1 Announce Type: cross  Abstract: In this study, we explore the innovative domain of Quantum Federated Learning (QFL) as a framework for training Quantum Machine Learning (QML) models via distributed networks. Conventional machine learning models frequently grapple with issues about data privacy and the exposure of sensitive information. Our proposed Federated Quantum Neural Network (FedQNN) framework emerges as a cutting-edge solution, integrating the singular characteristics of QML with the principles of classical federated learning. This work thoroughly investigates QFL, underscoring its capability to secure data handling in a distributed environment and facilitate cooperative learning without direct data sharing. Our research corroborates the concept through experiments across varied datasets, including genomics and healthcare, thereby validating the versatility and efficacy of our FedQNN framework. The results consistently exceed 86% accuracy across three distinct
    
[^3]: 在分享扩散模型中探讨隐私和公平风险：一种对抗性视角

    Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective

    [https://arxiv.org/abs/2402.18607](https://arxiv.org/abs/2402.18607)

    本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。

    

    扩散模型近年来在学术界和工业界引起了广泛关注，因为其在采样质量和分布覆盖方面表现出色。因此，提出了跨不同组织分享预训练扩散模型的建议，以提高数据利用率同时通过避免直接分享私人数据来增强隐私保护。然而，与这种方法相关的潜在风险尚未得到全面调查。本文从对抗性的角度探讨了与分享扩散模型相关的潜在隐私和公平风险。具体而言，我们调查了一方（分享者）使用私人数据训练扩散模型并向另一方（接收者）提供预训练模型的黑盒访问权限用于下游任务的情况。我们展示了分享者可以实行的行动

    arXiv:2402.18607v1 Announce Type: cross  Abstract: Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined.   In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execut
    
[^4]: MMSR：符号回归是一个多模态任务

    MMSR: Symbolic Regression is a Multimodal Task

    [https://arxiv.org/abs/2402.18603](https://arxiv.org/abs/2402.18603)

    符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。

    

    数学公式是探索自然规律几千年来人类智慧的结晶。用简洁的数学公式描述复杂的自然规律是科学家不断追求的目标，也是人工智能面临的重大挑战。这一领域被称为符号回归。在本文中，研究人员将从数据到表达式的映射视为翻译问题，并引入了相应的大规模预训练模型。

    arXiv:2402.18603v1 Announce Type: cross  Abstract: Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, w
    
[^5]: 使用人类概念形成避免视觉分类中的灾难性遗忘

    Avoiding Catastrophic Forgetting in Visual Classification Using Human Concept Formation

    [https://arxiv.org/abs/2402.16933](https://arxiv.org/abs/2402.16933)

    提出了一种名为Cobweb4V的新颖视觉分类方法，利用人类类似学习系统，避免了灾难性遗忘效应，与传统方法相比，需要更少的数据来实现有效学习成果，并保持稳定性能。

    

    深度神经网络在机器学习中表现出色，特别是在视觉任务中，然而，当按顺序学习新任务时，它们经常面临灾难性遗忘。本研究提出了Cobweb4V，这是一种新颖的视觉分类方法，它基于Cobweb，这是一种人类类似的学习系统，受到人类随时间逐渐学习新概念的启发。我们进行了全面评估，展示了Cobweb4V在学习视觉概念方面的熟练程度，相较于传统方法，需要更少的数据来实现有效的学习成果，随时间保持稳定的性能，并实现了令人称赞的渐近行为，避免了灾难性遗忘效应。这些特征与人类认知中的学习策略一致，将Cobweb4V定位为神经网络方法的一个有前途的替代方案。

    arXiv:2402.16933v1 Announce Type: cross  Abstract: Deep neural networks have excelled in machine learning, particularly in vision tasks, however, they often suffer from catastrophic forgetting when learning new tasks sequentially. In this work, we propose Cobweb4V, a novel visual classification approach that builds on Cobweb, a human like learning system that is inspired by the way humans incrementally learn new concepts over time. In this research, we conduct a comprehensive evaluation, showcasing the proficiency of Cobweb4V in learning visual concepts, requiring less data to achieve effective learning outcomes compared to traditional methods, maintaining stable performance over time, and achieving commendable asymptotic behavior, without catastrophic forgetting effects. These characteristics align with learning strategies in human cognition, positioning Cobweb4V as a promising alternative to neural network approaches.
    
[^6]: 观察学习：基于视频的机器人操作学习方法综述

    Learning by Watching: A Review of Video-based Learning Approaches for Robot Manipulation

    [https://arxiv.org/abs/2402.07127](https://arxiv.org/abs/2402.07127)

    

    

    机器人学习操作技能受到多样化、无偏的数据集的稀缺性的影响。尽管策划的数据集可以帮助解决问题，但在泛化性和现实世界的转移方面仍然存在挑战。与此同时，“野外”视频数据集的大规模存在通过自监督技术推动了计算机视觉的进展。将这一点应用到机器人领域，最近的研究探索了通过被动观察来学习丰富的在线视频中的操作技能。这种基于视频的学习范式显示出了有希望的结果，它提供了可扩展的监督方法，同时降低了数据集的偏见。本综述回顾了视频特征表示学习技术、物体可行性理解、三维手部/身体建模和大规模机器人资源等基础知识，以及从不受控制的视频演示中获取机器人操作技能的新兴技术。我们讨论了仅从观察大规模人类视频中学习如何增强机器人的泛化性和样本效率。

    Robot learning of manipulation skills is hindered by the scarcity of diverse, unbiased datasets. While curated datasets can help, challenges remain in generalizability and real-world transfer. Meanwhile, large-scale "in-the-wild" video datasets have driven progress in computer vision through self-supervised techniques. Translating this to robotics, recent works have explored learning manipulation skills by passively watching abundant videos sourced online. Showing promising results, such video-based learning paradigms provide scalable supervision while reducing dataset bias. This survey reviews foundations such as video feature representation learning techniques, object affordance understanding, 3D hand/body modeling, and large-scale robot resources, as well as emerging techniques for acquiring robot manipulation skills from uncontrolled video demonstrations. We discuss how learning only from observing large-scale human videos can enhance generalization and sample efficiency for roboti
    
[^7]: 則采樣并不是魔法: 大批量大小為什麼適用於差分隱私隨機優化

    Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation

    [https://arxiv.org/abs/2402.03990](https://arxiv.org/abs/2402.03990)

    通过研究差分隐私随机梯度下降（DP-SGD）中的总梯度方差，我们发现大批次大小有助于减小則采樣引起的方差，从而提高优化效果。

    

    我們研究了批次大小對差分隱私隨機梯度下降（DP-SGD）中總梯度方差的影響，尋求對大批次大小有用性的理論解釋。由於DP-SGD是現代差分隱私深度學習的基礎，其性質已被廣泛研究，最近的工作在實踐中發現大批次大小有益。然而，對於這種好處的理論解釋目前最多只能說是啟發式的。我們首先觀察到，在DP-SGD中，總梯度方差可以分解為由則采樣和噪聲引起的方差。然後，我們證明在無限次迭代的極限情況下，有效的噪聲引起的方差對批次大小是不變的。剩下的則采樣引起的方差隨著批次大小的增大而減小，因此大批次大小減小了有效的總梯度方差。我們在數值上確認這種漸進的情況在實際環境中是相關的，當批次大小不小的時候會起作用，並且發現

    We study the effect of the batch size to the total gradient variance in differentially private stochastic gradient descent (DP-SGD), seeking a theoretical explanation for the usefulness of large batch sizes. As DP-SGD is the basis of modern DP deep learning, its properties have been widely studied, and recent works have empirically found large batch sizes to be beneficial. However, theoretical explanations of this benefit are currently heuristic at best. We first observe that the total gradient variance in DP-SGD can be decomposed into subsampling-induced and noise-induced variances. We then prove that in the limit of an infinite number of iterations, the effective noise-induced variance is invariant to the batch size. The remaining subsampling-induced variance decreases with larger batch sizes, so large batches reduce the effective total gradient variance. We confirm numerically that the asymptotic regime is relevant in practical settings when the batch size is not small, and find tha
    
[^8]: 混合量子循环生成对抗网络用于小分子生成

    Hybrid quantum cycle generative adversarial network for small molecule generation

    [https://arxiv.org/abs/2402.00014](https://arxiv.org/abs/2402.00014)

    本文介绍了一种基于参数化量子电路的新型生成对抗网络模型，通过引入强化学习原理的多参数奖励函数，成功优化了小分子生成的药物样性估计，最高提升了30%。

    

    当代药物设计过程需要大量的时间和资源来开发首次进入市场的每个新化合物。生成小分子是药物发现的一个关键方面，对于开发创新的制药产品至关重要。然而，尚未充分发挥独特性、有效性、多样性、药物样性、可合成性和溶解度分子药代动力学性质。本文介绍了几种基于参数化量子电路工程整合到已知分子生成对抗网络中的新型生成对抗网络模型。引入的机器学习模型结合了以强化学习原理为基础的新型多参数奖励函数。通过在基准药物设计数据集QM9和PC9上进行广泛的实验，显示出引入的模型优于以前的评分。最重要的是，新的评分表明药物样性定量估计增加了最多30%。

    The contemporary drug design process demands considerable time and resources to develop each new compound entering the market. Generating small molecules is a pivotal aspect of drug discovery, essential for developing innovative pharmaceuticals. Uniqueness, validity, diversity, druglikeliness, synthesizability, and solubility molecular pharmacokinetic properties, however, are yet to be maximized. This work introduces several new generative adversarial network models based on engineering integration of parametrized quantum circuits into known molecular generative adversarial networks. The introduced machine learning models incorporate a new multi-parameter reward function grounded in reinforcement learning principles. Through extensive experimentation on benchmark drug design datasets, QM9 and PC9, the introduced models are shown to outperform scores achieved previously. Most prominently, the new scores indicate an increase of up to 30% in the druglikeness quantitative estimation. The n
    
[^9]: 关于衡量自然语言解释的忠诚度或自一致性

    On Measuring Faithfulness or Self-consistency of Natural Language Explanations

    [https://arxiv.org/abs/2311.07466](https://arxiv.org/abs/2311.07466)

    本文论述了衡量自然语言解释的忠诚度或自一致性的问题。我们提出了自一致性测试来评估解释的输出级别的一致性。我们通过构建比较一致性测试库，并引入了新的自一致性度量CC-SHAP来支持我们的观点。

    

    大型语言模型（LLMs）可以通过事后或思维链（CoT）解释其预测。但是，LLM可能会编造听起来合理但不忠实于其基本推理的解释。最近的工作设计了旨在判断事后或CoT解释忠实度的测试。在这项工作中，我们认为这些忠实度测试不是衡量模型内部工作的忠实度，而是衡量其输出级别的自一致性。我们的贡献有三个方面：i）我们在模型可解释性的背景下澄清了忠实度测试的地位，将其描述为自一致性测试。我们通过ii）构建了一个比较一致性的测试库，首次在11个开放式LLMs和5个任务的通用套件上比较了现有测试，包括iii）我们的新的自一致性度量CC-SHAP。CC-SHAP是LLM自一致性的细粒度度量（而不是测试）。它进行比较。

    Large language models (LLMs) can explain their predictions through post-hoc or Chain-of-Thought (CoT) explanations. But an LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning. Recent work has designed tests that aim to judge the faithfulness of post-hoc or CoT explanations. In this work we argue that these faithfulness tests do not measure faithfulness to the models' inner workings -- but rather their self-consistency at output level. Our contributions are three-fold: i) We clarify the status of faithfulness tests in view of model explainability, characterising them as self-consistency tests instead. This assessment we underline by ii) constructing a Comparative Consistency Bank for self-consistency tests that for the first time compares existing tests on a common suite of 11 open LLMs and 5 tasks -- including iii) our new self-consistency measure CC-SHAP. CC-SHAP is a fine-grained measure (not a test) of LLM self-consistency. It compares 
    
[^10]: 使用路径重加权定制图神经网络

    Customizing Graph Neural Networks using Path Reweighting

    [https://arxiv.org/abs/2106.10866](https://arxiv.org/abs/2106.10866)

    使用路径重加权的定制图神经网络CustomGNN可以自动学习特定下游任务的高层语义，突出与语义相关的路径，并过滤掉任务无关的噪音，避免传统GNN中的过度平滑、鲁棒性差和过拟合问题。

    

    图神经网络（GNNs）已广泛用于挖掘图结构数据，表现出卓越的性能。然而，传统GNNs并未区分不同下游任务，因此它们嵌入的嵌入向量并非总是有效。本文以图中的路径为灵感，设计了一种新颖的GNN解决方案，即带有路径重加权的定制图神经网络（简称CustomGNN）。具体而言，所提出的CustomGNN可以自动学习特定下游任务的高层语义，突出与语义相关的路径，并过滤掉图中与任务无关的噪音。此外，我们通过实验证明了CustomGNN学习的语义以及其避免传统GNN中存在的过度平滑、鲁棒性差和过拟合等三个固有问题的能力。

    arXiv:2106.10866v3 Announce Type: replace  Abstract: Graph Neural Networks (GNNs) have been extensively used for mining graph-structured data with impressive performance. However, because these traditional GNNs do not distinguish among various downstream tasks, embeddings embedded by them are not always effective. Intuitively, paths in a graph imply different semantics for different downstream tasks. Inspired by this, we design a novel GNN solution, namely Customized Graph Neural Network with Path Reweighting (CustomGNN for short). Specifically, the proposed CustomGNN can automatically learn the high-level semantics for specific downstream tasks to highlight semantically relevant paths as well to filter out task-irrelevant noises in a graph. Furthermore, we empirically analyze the semantics learned by CustomGNN and demonstrate its ability to avoid the three inherent problems in traditional GNNs, i.e., over-smoothing, poor robustness, and overfitting. In experiments with the node classi
    
[^11]: 对高级大型语言模型的治理和利用的道德人工智能原则和指南

    Ethical Artificial Intelligence Principles and Guidelines for the Governance and Utilization of Highly Advanced Large Language Models. (arXiv:2401.10745v1 [cs.CY])

    [http://arxiv.org/abs/2401.10745](http://arxiv.org/abs/2401.10745)

    本文探讨了如何利用道德人工智能原则和指南来解决高级大型语言模型的治理和利用问题。

    

    鉴于ChatGPT、LaMDA和其他大型语言模型（LLMs）的成功，技术行业和其他行业对LLMs的开发和使用有所增加。虽然LLMs的水平尚未超过人类智能，但总有一天会达到这一点。这种LLMs可以称为高级LLMs。目前，由于尚未达到这一点，使用道德人工智能（AI）原则和指南来解决高级LLMs的问题还受到限制。然而，这是一个问题，因为一旦达到这一点，我们将无法充分准备好以道德和最佳方式处理其产生的后果，这将导致不可预期的后果。本文讨论了如何利用道德人工智能原则和指南来解决高级LLMs的问题。

    Given the success of ChatGPT, LaMDA and other large language models (LLMs), there has been an increase in development and usage of LLMs within the technology sector and other sectors. While the level in which LLMs has not reached a level where it has surpassed human intelligence, there will be a time when it will. Such LLMs can be referred to as advanced LLMs. Currently, there are limited usage of ethical artificial intelligence (AI) principles and guidelines addressing advanced LLMs due to the fact that we have not reached that point yet. However, this is a problem as once we do reach that point, we will not be adequately prepared to deal with the aftermath of it in an ethical and optimal way, which will lead to undesired and unexpected consequences. This paper addresses this issue by discussing what ethical AI principles and guidelines can be used to address highly advanced LLMs.
    
[^12]: 实现模型无关的通过速率限制通道的LQR控制

    Towards Model-Free LQR Control over Rate-Limited Channels. (arXiv:2401.01258v1 [math.OC])

    [http://arxiv.org/abs/2401.01258](http://arxiv.org/abs/2401.01258)

    这篇论文研究了在速率限制通道上实现模型无关的LQR控制的问题。通过引入自适应量化梯度下降（AQGD）算法，作者证明了在噪声电路中可以实现控制问题的解决。

    

    鉴于模型无关方法在许多问题设置中的控制设计方面取得的成功，自然而然地会问，如果利用实际的通信通道来传输梯度或策略，情况会如何改变。尽管由此产生的问题与网络控制系统中研究的公式有类似之处，但那个领域的丰富文献通常假定系统的模型是已知的。为了在模型无关控制设计和网络控制系统领域之间建立联系，我们提出了一个问题：\textit{是否可以通过速率限制的通道以模型无关的方式解决基本的控制问题-例如线性二次调节器（LQR）问题？}为了回答这个问题，我们研究了一个设置，其中一个工作代理通过一个无噪声信道以有限的位速率传输量化策略梯度（LQR成本）到一个服务器。我们提出了一种名为自适应量化梯度下降（AQGD）的新算法，并证明了

    Given the success of model-free methods for control design in many problem settings, it is natural to ask how things will change if realistic communication channels are utilized for the transmission of gradients or policies. While the resulting problem has analogies with the formulations studied under the rubric of networked control systems, the rich literature in that area has typically assumed that the model of the system is known. As a step towards bridging the fields of model-free control design and networked control systems, we ask: \textit{Is it possible to solve basic control problems - such as the linear quadratic regulator (LQR) problem - in a model-free manner over a rate-limited channel?} Toward answering this question, we study a setting where a worker agent transmits quantized policy gradients (of the LQR cost) to a server over a noiseless channel with a finite bit-rate. We propose a new algorithm titled Adaptively Quantized Gradient Descent (\texttt{AQGD}), and prove that
    
[^13]: 智能交通系统中图神经网络的调查

    A Survey on Graph Neural Networks in Intelligent Transportation Systems. (arXiv:2401.00713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.00713](http://arxiv.org/abs/2401.00713)

    本研究调查了智能交通系统中图神经网络的应用。图神经网络通过其强大的图建模能力，在交通领域表现出优秀性能。然而，目前研究主要集中在交通预测方面，其他领域仍需更多关注。

    

    智能交通系统（ITS）对于改善交通拥堵、减少交通事故、优化城市规划等方面至关重要。然而，由于交通网络的复杂性，传统的机器学习和统计方法变得不受重视。随着人工智能时代的到来，许多深度学习框架在各个领域取得了显著进展，并且被认为是许多领域中有效的方法。作为一种深度学习方法，图神经网络（GNNs）由于其在建模与图相关的问题方面的强大能力，自2019年以来已经在ITS领域中崭露头角。因此，越来越多的学者关注GNN在交通领域的应用，表现出优秀的性能。然而，目前该领域的大部分研究仍集中在交通预测方面，而其他ITS领域，如自动驾驶车辆和城市规划，仍需要更多关注。

    Intelligent Transportation System (ITS) is vital in improving traffic congestion, reducing traffic accidents, optimizing urban planning, etc. However, due to the complexity of the traffic network, traditional machine learning and statistical methods are relegated to the background. With the advent of the artificial intelligence era, many deep learning frameworks have made remarkable progress in various fields and are now considered effective methods in many areas. As a deep learning method, Graph Neural Networks (GNNs) have emerged as a highly competitive method in the ITS field since 2019 due to their strong ability to model graph-related problems. As a result, more and more scholars pay attention to the applications of GNNs in transportation domains, which have shown excellent performance. However, most of the research in this area is still concentrated on traffic forecasting, while other ITS domains, such as autonomous vehicles and urban planning, still require more attention. This 
    
[^14]: 分布式强化学习中的估计和推断

    Estimation and Inference in Distributional Reinforcement Learning. (arXiv:2309.17262v1 [stat.ML])

    [http://arxiv.org/abs/2309.17262](http://arxiv.org/abs/2309.17262)

    本文研究了分布式强化学习中的估计和推断问题，通过使用等价确定法，在提供生成模型的情况下以高效的方式解决了分布式策略评估问题。

    

    本文从统计效率的角度研究了分布式强化学习。我们研究了分布式策略评估，旨在估计由给定策略π获得的随机回报的完整分布（表示为η^π）。在提供生成模型的情况下，我们使用等价确定法构造了估计器η^π。我们证明，在这种情况下，通过具有大小为O(|S||A|/(ε^(2p)(1-γ)^(2p+2)))的数据集可以保证估计器η^π和真实分布η^π之间的p-Wasserstein距离小于ε的概率很高。这意味着分布式策略评估问题可以以高效利用样本的方式解决。此外，我们还证明，在不同的温和假设下，通过具有大小为O(|S||A|/(ε^2(1-γ)^4))的数据集就足以确保Kolmogorov距离和总变差。

    In this paper, we study distributional reinforcement learning from the perspective of statistical efficiency.  We investigate distributional policy evaluation, aiming to estimate the complete distribution of the random return (denoted $\eta^\pi$) attained by a given policy $\pi$.  We use the certainty-equivalence method to construct our estimator $\hat\eta^\pi$, given a generative model is available.  We show that in this circumstance we need a dataset of size $\widetilde O\left(\frac{|\mathcal{S}||\mathcal{A}|}{\epsilon^{2p}(1-\gamma)^{2p+2}}\right)$ to guarantee a $p$-Wasserstein metric between $\hat\eta^\pi$ and $\eta^\pi$ is less than $\epsilon$ with high probability.  This implies the distributional policy evaluation problem can be solved with sample efficiency.  Also, we show that under different mild assumptions a dataset of size $\widetilde O\left(\frac{|\mathcal{S}||\mathcal{A}|}{\epsilon^{2}(1-\gamma)^{4}}\right)$ suffices to ensure the Kolmogorov metric and total variation m
    
[^15]: 用因果森林针对相对风险异质性进行目标化

    Targeting Relative Risk Heterogeneity with Causal Forests. (arXiv:2309.15793v1 [stat.ME])

    [http://arxiv.org/abs/2309.15793](http://arxiv.org/abs/2309.15793)

    本研究提出了一种通过修改因果森林方法，以相对风险为目标，从而捕捉到治疗效应异质性的潜在来源。

    

    在临床试验分析中，治疗效应异质性（TEH）即种群中不同亚群的治疗效应的变异性是非常重要的。因果森林（Wager和Athey，2018）是解决这个问题的一种非常流行的方法，但像许多其他发现TEH的方法一样，它用于分离亚群的标准侧重于绝对风险的差异。这可能会削弱统计功效，掩盖了相对风险中的细微差别，而相对风险通常是临床关注的更合适的数量。在这项工作中，我们提出并实现了一种修改因果森林以针对相对风险的方法，使用基于广义线性模型（GLM）比较的新颖节点分割过程。我们在模拟和真实数据上展示了结果，表明相对风险的因果森林可以捕捉到其他未观察到的异质性源。

    Treatment effect heterogeneity (TEH), or variability in treatment effect for different subgroups within a population, is of significant interest in clinical trial analysis. Causal forests (Wager and Athey, 2018) is a highly popular method for this problem, but like many other methods for detecting TEH, its criterion for separating subgroups focuses on differences in absolute risk. This can dilute statistical power by masking nuance in the relative risk, which is often a more appropriate quantity of clinical interest. In this work, we propose and implement a methodology for modifying causal forests to target relative risk using a novel node-splitting procedure based on generalized linear model (GLM) comparison. We present results on simulated and real-world data that suggest relative risk causal forests can capture otherwise unobserved sources of heterogeneity.
    
[^16]: 通过强化学习动态控制拟晶结构的自组装

    Dynamic control of self-assembly of quasicrystalline structures through reinforcement learning. (arXiv:2309.06869v1 [cond-mat.soft])

    [http://arxiv.org/abs/2309.06869](http://arxiv.org/abs/2309.06869)

    本研究提出使用强化学习来控制具有多边形单元颗粒的动态自组装过程，形成十二边准晶体。我们通过估计最佳的温度控制策略，成功地生成了几乎没有缺陷的结构。强化学习获得的温度调度比传统的预设温度调度更有效地重现了期望的结构。

    

    我们提出使用强化学习来控制具有多边形单元的颗粒的动态自组装过程，形成十二边准晶体（DDQC）。这些具有多边形单元的颗粒与其他颗粒具有各向异性相互作用，从而形成DDQC。然而，它们在稳态下的结构受其结构形成的动力学路径的显著影响。我们通过Q学习方法估计了最佳的温度控制策略，并证明我们可以使用估计的策略生成几乎没有缺陷的DDQC。通过强化学习获得的温度调度比传统的预设温度调度（如退火）更有效地重现了期望的结构。为了阐明学习的成功，我们还分析了一个描述结构变化动力学的简单模型，其中的运动是在三井势能中进行的。我们发现强化学习能够自主地发现增强结构波动的临界温度。

    We propose reinforcement learning to control the dynamical self-assembly of the dodecagonal quasicrystal (DDQC) from patchy particles. The patchy particles have anisotropic interactions with other particles and form DDQC. However, their structures at steady states are significantly influenced by the kinetic pathways of their structural formation. We estimate the best policy of temperature control trained by the Q-learning method and demonstrate that we can generate DDQC with few defects using the estimated policy. The temperature schedule obtained by reinforcement learning can reproduce the desired structure more efficiently than the conventional pre-fixed temperature schedule, such as annealing. To clarify the success of the learning, we also analyse a simple model describing the kinetics of structural changes through the motion in a triple-well potential. We have found that reinforcement learning autonomously discovers the critical temperature at which structural fluctuations enhance
    
[^17]: 设计一款攻防游戏：通过竞争来增加金融交易模型的鲁棒性

    Designing an attack-defense game: how to increase robustness of financial transaction models via a competition. (arXiv:2308.11406v1 [cs.LG])

    [http://arxiv.org/abs/2308.11406](http://arxiv.org/abs/2308.11406)

    通过设计一款攻防游戏，我们研究了使用序列金融数据的神经网络模型的对抗攻击和防御的现状和动态，并且通过分析比赛动态，回答了隐藏模型免受恶意用户攻击的重要性以及需要多长时间才能破解模型的问题。

    

    鉴于金融领域恶意攻击风险不断升级和由此引发的严重损害，对机器学习模型的对抗策略和鲁棒的防御机制有深入的理解至关重要。随着银行日益广泛采用更精确但潜在脆弱的神经网络，这一威胁变得更加严重。我们旨在调查使用序列金融数据作为输入的神经网络模型的对抗攻击和防御的当前状态和动态。为了实现这一目标，我们设计了一个比赛，允许对现代金融交易数据中的问题进行逼真而详细的研究。参与者直接竞争，因此可能的攻击和防御在接近真实条件下进行了检验。我们的主要贡献是分析比赛动态，回答了隐藏模型免受恶意用户攻击的重要性以及需要多长时间才能破解模型的问题。

    Given the escalating risks of malicious attacks in the finance sector and the consequential severe damage, a thorough understanding of adversarial strategies and robust defense mechanisms for machine learning models is critical. The threat becomes even more severe with the increased adoption in banks more accurate, but potentially fragile neural networks. We aim to investigate the current state and dynamics of adversarial attacks and defenses for neural network models that use sequential financial data as the input.  To achieve this goal, we have designed a competition that allows realistic and detailed investigation of problems in modern financial transaction data. The participants compete directly against each other, so possible attacks and defenses are examined in close-to-real-life conditions. Our main contributions are the analysis of the competition dynamics that answers the questions on how important it is to conceal a model from malicious users, how long does it take to break i
    
[^18]: 透明的6G RAN切片中基于解释的公平联邦学习

    Explanation-Guided Fair Federated Learning for Transparent 6G RAN Slicing. (arXiv:2307.09494v1 [cs.NI])

    [http://arxiv.org/abs/2307.09494](http://arxiv.org/abs/2307.09494)

    这篇论文提出了一个解释引导的联邦学习方案，通过利用可解释的人工智能策略产生透明和无偏的深度神经网络，从而确保可靠的预测。

    

    未来的零触摸人工智能驱动的6G网络自动化需要通过可解释的人工智能建立对AI黑盒子的信任，预计AI的可信度将与通信关键性能指标一起作为可量化的服务级别协议指标。这需要利用可解释人工智能输出来生成透明和无偏的深度神经网络。我们设计了一个基于解释的联邦学习方案(EGFL)来确保在训练运行时通过Jensen-Shannon (JS)散度利用XAI策略的模型解释以确保可靠的预测。具体而言，我们通过将回忆度指标作为优化任务的约束条件，预测每个切片RAN的丢包概率来说明所提出的概念。

    Future zero-touch artificial intelligence (AI)-driven 6G network automation requires building trust in the AI black boxes via explainable artificial intelligence (XAI), where it is expected that AI faithfulness would be a quantifiable service-level agreement (SLA) metric along with telecommunications key performance indicators (KPIs). This entails exploiting the XAI outputs to generate transparent and unbiased deep neural networks (DNNs). Motivated by closed-loop (CL) automation and explanation-guided learning (EGL), we design an explanation-guided federated learning (EGFL) scheme to ensure trustworthy predictions by exploiting the model explanation emanating from XAI strategies during the training run time via Jensen-Shannon (JS) divergence. Specifically, we predict per-slice RAN dropped traffic probability to exemplify the proposed concept while respecting fairness goals formulated in terms of the recall metric which is included as a constraint in the optimization task. Finally, the 
    
[^19]: 使用并行混合网络预测发电厂中的蒸汽质量流量

    Forecasting the steam mass flow in a powerplant using the parallel hybrid network. (arXiv:2307.09483v1 [cs.LG])

    [http://arxiv.org/abs/2307.09483](http://arxiv.org/abs/2307.09483)

    这项研究使用并行混合神经网络结构来预测发电厂中的蒸汽质量流量，相比纯经典和纯量子模型，该混合模型在测试集上取得了更好的性能，平均平方误差降低了5.7倍和4.9倍，并且相对误差较小，最多提升了2倍。

    

    高效可持续的发电是能源领域的一个关键问题。尤其是热电厂在准确预测蒸汽质量流量方面面临困难，这对于运营效率和成本降低至关重要。在本研究中，我们使用一个并行混合神经网络结构，该结构将参数化量子电路和传统的前馈神经网络相结合，特别设计用于工业环境中的时间序列预测，以提高对未来15分钟内蒸汽质量流量的预测能力。我们的结果表明，并行混合模型优于独立的经典和量子模型，在训练后的测试集上相对于纯经典模型和纯量子网络，平均平方误差（MSE）损失分别降低了5.7倍和4.9倍。此外，该混合模型在测试集上表现出相对误差较小，比纯经典模型更好，最多提升了2倍。

    Efficient and sustainable power generation is a crucial concern in the energy sector. In particular, thermal power plants grapple with accurately predicting steam mass flow, which is crucial for operational efficiency and cost reduction. In this study, we use a parallel hybrid neural network architecture that combines a parametrized quantum circuit and a conventional feed-forward neural network specifically designed for time-series prediction in industrial settings to enhance predictions of steam mass flow 15 minutes into the future. Our results show that the parallel hybrid model outperforms standalone classical and quantum models, achieving more than 5.7 and 4.9 times lower mean squared error (MSE) loss on the test set after training compared to pure classical and pure quantum networks, respectively. Furthermore, the hybrid model demonstrates smaller relative errors between the ground truth and the model predictions on the test set, up to 2 times better than the pure classical model.
    
[^20]: 基于破产问题的垂直联邦学习中的激励分配

    Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem. (arXiv:2307.03515v1 [cs.LG])

    [http://arxiv.org/abs/2307.03515](http://arxiv.org/abs/2307.03515)

    本文提出了一种基于破产问题的方法来解决垂直联邦学习中激励分配的挑战，以确保公平性和稳定性。

    

    垂直联邦学习（VFL）是一种有前景的方法，用于合作训练在不同参与方之间垂直划分的私有数据的机器学习模型。在VFL设置中，理想情况下，主动方（拥有带标签样本特征的参与方）通过与某些被动方（拥有相同样本但没有标签的额外特征的参与方）合作，在保护隐私的情况下改进其机器学习模型。然而，激励被动方参与VFL可能具有挑战性。本文重点研究了基于被动方在VFL过程中的贡献来为他们分配激励的问题。我们将这个问题定义为核心游戏论概念的一种变体——破产问题，并使用塔木德划分规则来解决它。我们在合成和真实数据集上评估了我们提出的方法，并展示它确保了激励的公平性和稳定性。

    Vertical federated learning (VFL) is a promising approach for collaboratively training machine learning models using private data partitioned vertically across different parties. Ideally in a VFL setting, the active party (party possessing features of samples with labels) benefits by improving its machine learning model through collaboration with some passive parties (parties possessing additional features of the same samples without labels) in a privacy preserving manner. However, motivating passive parties to participate in VFL can be challenging. In this paper, we focus on the problem of allocating incentives to the passive parties by the active party based on their contributions to the VFL process. We formulate this problem as a variant of the Nucleolus game theory concept, known as the Bankruptcy Problem, and solve it using the Talmud's division rule. We evaluate our proposed method on synthetic and real-world datasets and show that it ensures fairness and stability in incentive a
    
[^21]: 最优异构协同线性回归和上下文臂研究

    Optimal Heterogeneous Collaborative Linear Regression and Contextual Bandits. (arXiv:2306.06291v1 [stat.ML])

    [http://arxiv.org/abs/2306.06291](http://arxiv.org/abs/2306.06291)

    本文提出了一种新的估计器MOLAR，它利用协同线性回归和上下文臂问题中的稀疏异质性来提高估计精度，并且相比独立方法具有更好的表现。

    

    大型和复杂的数据集往往来自于几个可能是异构的来源。协同学习方法通过利用数据集之间的共性提高效率，同时考虑可能出现的差异。在这里，我们研究协同线性回归和上下文臂问题，其中每个实例的相关参数等于全局参数加上一个稀疏的实例特定术语。我们提出了一种名为MOLAR的新型二阶段估计器，它通过首先构建实例线性回归估计的逐项中位数，然后将实例特定估计值收缩到中位数附近来利用这种结构。与独立最小二乘估计相比，MOLAR提高了估计误差对数据维度的依赖性。然后，我们将MOLAR应用于开发用于稀疏异构协同上下文臂的方法，这些方法相比独立臂模型具有更好的遗憾保证。我们进一步证明了我们的贡献优于先前在文献中报道的算法。

    Large and complex datasets are often collected from several, possibly heterogeneous sources. Collaborative learning methods improve efficiency by leveraging commonalities across datasets while accounting for possible differences among them. Here we study collaborative linear regression and contextual bandits, where each instance's associated parameters are equal to a global parameter plus a sparse instance-specific term. We propose a novel two-stage estimator called MOLAR that leverages this structure by first constructing an entry-wise median of the instances' linear regression estimates, and then shrinking the instance-specific estimates towards the median. MOLAR improves the dependence of the estimation error on the data dimension, compared to independent least squares estimates. We then apply MOLAR to develop methods for sparsely heterogeneous collaborative contextual bandits, which lead to improved regret guarantees compared to independent bandit methods. We further show that our 
    
[^22]: 自注意力双重嵌入：适用于异质性图的图神经网络

    Self-attention Dual Embedding for Graphs with Heterophily. (arXiv:2305.18385v1 [cs.LG])

    [http://arxiv.org/abs/2305.18385](http://arxiv.org/abs/2305.18385)

    本研究提出了一种新颖的图神经网络，采用自注意力机制，适用于异质性图和同质性图，并在许多标准数据集上展示出最先进的性能。

    

    图神经网络（GNNs）在节点分类任务中取得了重大成功。GNNs通常假设图是同质的，即相邻节点很可能属于相同的类别。然而，许多真实世界的图都是异质的，这导致使用标准的GNNs时分类精度要低得多。在本文中，我们设计了一种新颖的GNN，它对异质性和同质性图都有效。我们的工作基于三个主要观察结果。首先，我们展示了在不同的图中，节点特征和图拓扑提供不同数量的信息，因此应该独立编码并以自适应方式优先级化。其次，我们展示了当传播图拓扑信息时允许负的注意权重可以提高精度。最后，我们展示了节点之间不对称的注意权重是有帮助的。我们设计了一种GNN，利用这些观察结果通过新颖的自注意力机制。我们评估了我们的算法在一些标准的节点分类数据集上，并展示了在同质性和异质性图上的最新性能。

    Graph Neural Networks (GNNs) have been highly successful for the node classification task. GNNs typically assume graphs are homophilic, i.e. neighboring nodes are likely to belong to the same class. However, a number of real-world graphs are heterophilic, and this leads to much lower classification accuracy using standard GNNs. In this work, we design a novel GNN which is effective for both heterophilic and homophilic graphs. Our work is based on three main observations. First, we show that node features and graph topology provide different amounts of informativeness in different graphs, and therefore they should be encoded independently and prioritized in an adaptive manner. Second, we show that allowing negative attention weights when propagating graph topology information improves accuracy. Finally, we show that asymmetric attention weights between nodes are helpful. We design a GNN which makes use of these observations through a novel self-attention mechanism. We evaluate our algor
    
[^23]: 节点特征增强改进网络对齐

    Node Feature Augmentation Vitaminizes Network Alignment. (arXiv:2304.12751v1 [cs.SI])

    [http://arxiv.org/abs/2304.12751](http://arxiv.org/abs/2304.12751)

    本研究提出了Grad-Align+方法，通过增强节点特征来执行NA任务，并最大限度地利用增强的节点特征来设计NA方法，解决了NA方法缺乏额外信息的问题。

    

    网络对齐（NA）是通过给定网络的拓扑和/或特征信息来发现多个网络之间的节点对应关系的任务。虽然NA方法在各种场景下取得了显著的成功，但其有效性并不总是有额外信息，如先前的锚点链接和/或节点特征。为了解决这个实际的挑战，我们提出了Grad-Align+，这是一种新颖的NA方法，建立在最近一种最先进的NA方法Grad-Align之上，Grad-Align+仅逐步发现部分节点对，直到找到所有节点对。在设计Grad-Align+时，我们考虑如何通过增强节点特征来执行NA任务，并最大限度地利用增强的节点特征来设计NA方法。为了实现这个目标，我们开发了由三个关键组成部分组成的Grad-Align+：基于中心性的节点特征增强（CNFA）、图切片生成和优化节点嵌入特征（ONIFE）。

    Network alignment (NA) is the task of discovering node correspondences across multiple networks using topological and/or feature information of given networks. Although NA methods have achieved remarkable success in a myriad of scenarios, their effectiveness is not without additional information such as prior anchor links and/or node features, which may not always be available due to privacy concerns or access restrictions. To tackle this practical challenge, we propose Grad-Align+, a novel NA method built upon a recent state-of-the-art NA method, the so-called Grad-Align, that gradually discovers only a part of node pairs until all node pairs are found. In designing Grad-Align+, we account for how to augment node features in the sense of performing the NA task and how to design our NA method by maximally exploiting the augmented node features. To achieve this goal, we develop Grad-Align+ consisting of three key components: 1) centrality-based node feature augmentation (CNFA), 2) graph
    
[^24]: NN-Copula-CD：一种基于Copula的可解释神经网络用于异构遥感图像变化检测

    NN-Copula-CD: A Copula-Guided Interpretable Neural Network for Change Detection in Heterogeneous Remote Sensing Images. (arXiv:2303.17448v1 [cs.CV])

    [http://arxiv.org/abs/2303.17448](http://arxiv.org/abs/2303.17448)

    该论文提出了一种可解释的神经网络方法，结合Copula理论来解决异构遥感图像中的变化检测问题。

    

    异构遥感图像中的变化检测是一个实际而具有挑战性的问题。过去十年来，深度神经网络(DNN)的发展让异构变化检测问题受益匪浅。然而，数据驱动的DNN始终像黑匣子一样，缺乏可解释性，这限制了DNN在大多数实际变化检测应用中的可靠性和可控性。为了解决这些问题，我们提出了一种基于Copula的可解释神经网络异构变化检测方法(NN-Copula-CD)。在NN-Copula-CD中，Copula的数学特征被设计为损失函数，用于监督一个简单的全连接神经网络学习变量之间的相关性。

    Change detection (CD) in heterogeneous remote sensing images is a practical and challenging issue for real-life emergencies. In the past decade, the heterogeneous CD problem has significantly benefited from the development of deep neural networks (DNN). However, the data-driven DNNs always perform like a black box where the lack of interpretability limits the trustworthiness and controllability of DNNs in most practical CD applications. As a strong knowledge-driven tool to measure correlation between random variables, Copula theory has been introduced into CD, yet it suffers from non-robust CD performance without manual prior selection for Copula functions. To address the above issues, we propose a knowledge-data-driven heterogeneous CD method (NN-Copula-CD) based on the Copula-guided interpretable neural network. In our NN-Copula-CD, the mathematical characteristics of Copula are designed as the losses to supervise a simple fully connected neural network to learn the correlation betwe
    
[^25]: LLaMA-Adapter: 零初始化注意力下的语言模型精细调整的高效方法

    LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention. (arXiv:2303.16199v1 [cs.CV])

    [http://arxiv.org/abs/2303.16199](http://arxiv.org/abs/2303.16199)

    本文提出了一种基于适应提示和零初始化注意力机制的轻量级语言模型调整方法，可高效微调LLaMA为指令跟随模型，具有比Alpaca更短的微调时间并具有近似的响应质量。

    

    本文提出了LLaMA-Adapter这一轻量级适应方法，用于将LLaMA高效地微调为一个指令跟随模型。利用52K个自我指导示范，LLaMA-Adapter仅在冻结的LLaMA 7B模型上引入了1.2M个可学习参数，并且在8个A100 GPU上仅耗时不到一个小时进行微调。具体而言，我们采用一组可学习的适应提示，并在较高的变压器层中将它们预置于输入文本令牌之前。然后，提出了一种零初始化注意力机制和零门控机制，该机制可以自适应地将新的指令提示注入LLaMA，并有效地保留了其预先训练的知识。通过高效训练，LLaMA-Adapter能够产生高质量的响应，与完全微调的7B参数的Alpaca相似。此外，我们的方法还可以简单地扩展到多模态输入，例如图像，用于图像相关的LLaMA，在ScienceQA上实现了更强的推理能力。我们在https://github.com/ZrrSkywalker/LLaMA-Adapt发布了我们的代码。

    We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model. Using 52K self-instruct demonstrations, LLaMA-Adapter only introduces 1.2M learnable parameters upon the frozen LLaMA 7B model, and costs less than one hour for fine-tuning on 8 A100 GPUs. Specifically, we adopt a set of learnable adaption prompts, and prepend them to the input text tokens at higher transformer layers. Then, a zero-init attention mechanism with zero gating is proposed, which adaptively injects the new instructional cues into LLaMA, while effectively preserves its pre-trained knowledge. With efficient training, LLaMA-Adapter generates high-quality responses, comparable to Alpaca with fully fine-tuned 7B parameters. Furthermore, our approach can be simply extended to multi-modal input, e.g., images, for image-conditioned LLaMA, which achieves superior reasoning capacity on ScienceQA. We release our code at https://github.com/ZrrSkywalker/LLaMA-Adapt
    
[^26]: repliclust：聚类分析的合成数据

    repliclust: Synthetic Data for Cluster Analysis. (arXiv:2303.14301v1 [cs.LG])

    [http://arxiv.org/abs/2303.14301](http://arxiv.org/abs/2303.14301)

    repliclust 是一个 Python 包，用于生成具有聚类的合成数据集，基于数据集的原型，提供了放置集群中心、采样集群形状、选择每个集群的数据点数量以及为集群分配概率分布的算法。

    

    我们介绍了 repliclust（来自于 repli-cate 和 clust-er），这是一个用于生成具有聚类的合成数据集的 Python 包。我们的方法基于数据集的原型，即高级几何描述，用户可以从中创建许多不同的数据集，并具有所需的几何特性。我们软件的架构是模块化和面向对象的，将数据生成分解成放置集群中心的算法、采样集群形状的算法、选择每个集群的数据点数量的算法以及为集群分配概率分布的算法。repliclust.org 项目网页提供了简明的用户指南和全面的文档。

    We present repliclust (from repli-cate and clust-er), a Python package for generating synthetic data sets with clusters. Our approach is based on data set archetypes, high-level geometric descriptions from which the user can create many different data sets, each possessing the desired geometric characteristics. The architecture of our software is modular and object-oriented, decomposing data generation into algorithms for placing cluster centers, sampling cluster shapes, selecting the number of data points for each cluster, and assigning probability distributions to clusters. The project webpage, repliclust.org, provides a concise user guide and thorough documentation.
    
[^27]: 有限时间内使用线性函数逼近进行时序差异学习的分析：尾平均和正则化

    Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation. (arXiv:2210.05918v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05918](http://arxiv.org/abs/2210.05918)

    本研究通过引入尾平均和正则化技术，对时序差异(TD)学习算法进行了有限时间行为的研究。我们得出结论，尾平均TD能以最优速率 $O(1/t)$ 收敛，并且初始误差衰减速率更快。此外，正则化的TD版本在具有病态特征的问题上很有用。

    

    本文研究了将流行的时序差异(TD)学习算法与尾平均相结合时的有限时间行为。我们在不需要关于底层投影TD不动点矩阵的特征值信息的步长选择下，推导了尾平均TD迭代的参数误差的有限时间界。我们的分析表明，尾平均TD以期望速率和高概率收敛于最优的 $O(1/t)$ 速率。此外，我们的界限展示了初始误差(偏差)的更快衰减速率，这是对所有迭代的平均值的改进。我们还提出并分析了一种结合正则化的TD变体。通过分析，我们得出结论认为正则化的TD版本在具有病态特征的问题上是有用的。

    We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal $O\left(1/t\right)$ rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation. From analysis, we conclude that the regularised version of TD is useful for problems with ill-conditioned features.
    

