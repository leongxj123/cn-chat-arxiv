# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Credal Learning Theory](https://rss.arxiv.org/abs/2402.00957) | 本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。 |
| [^2] | [Generalizable, Fast, and Accurate DeepQSPR with fastprop Part 1: Framework and Benchmarks](https://arxiv.org/abs/2404.02058) | fastprop是一种DeepQSPR框架，通过使用分子级描述符，在极大缩短时间内，在多样数据集上达到并超越了学习表示的性能。 |
| [^3] | [Predicting the Performance of Foundation Models via Agreement-on-the-Line](https://arxiv.org/abs/2404.01542) | 本研究发现，通过对来自单个基础模型的多次运行进行轻微微调，可以通过训练期间的随机性选择来显著影响最终集合中的一致性。 |
| [^4] | [Iterated $Q$-Network: Beyond the One-Step Bellman Operator](https://arxiv.org/abs/2403.02107) | 引入了迭代$Q$-网络（iQN）方法，通过一次考虑多次迭代的贝尔曼算子来改进值基强化学习方法，在理论上可行，并在实验中展示其在游戏和控制环境中的优势。 |
| [^5] | [TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2402.19072) | 本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。 |
| [^6] | [Accelerating Graph Neural Networks on Real Processing-In-Memory Systems](https://arxiv.org/abs/2402.16731) | 在实际处理内存系统上加速图神经网络，并提出了针对实际PIM系统的智能并行化技术和混合式执行方法。 |
| [^7] | [Provably Safe Neural Network Controllers via Differential Dynamic Logic](https://arxiv.org/abs/2402.10998) | 通过差分动态逻辑与神经网络验证相结合的VerSAILLE方法，实现了对神经网络控制系统在无限时间范围上的安全性证明。 |
| [^8] | [Reward Poisoning Attack Against Offline Reinforcement Learning](https://arxiv.org/abs/2402.09695) | 这项研究针对深度神经网络函数逼近的一般离线强化学习中的奖励污染攻击问题，提出了一种名为“策略对比攻击”的攻击策略。通过使低性能策略看起来像是高性能的，同时使高性能策略看起来像是低性能的，我们证明了这种攻击有效性。 |
| [^9] | [Gradient Sketches for Training Data Attribution and Studying the Loss Landscape](https://arxiv.org/abs/2402.03994) | 本论文提出了一种可扩展的渐变草图算法，用于训练数据归因和损失地貌研究。作者在三个应用中展示了该方法的有效性。 |
| [^10] | [Equivalence of the Empirical Risk Minimization to Regularization on the Family of f-Divergences](https://arxiv.org/abs/2402.00501) | 经验风险最小化与f-分布族的正则化的解决方案在特定条件下是唯一的，并且可以通过使用不同的f-分布正则化等效地表示。 |
| [^11] | [Interpretable Fine-Tuning for Graph Neural Network Surrogate Models](https://arxiv.org/abs/2311.07548) | 本论文引入了一种可解释的微调策略，通过应用于非结构网格化流体动力学建模的GNNs，增强了模型的预测能力，并通过识别可解释的物理空间区域及其对应的子图，帮助理解模型架构、优化目标和已知物理之间的关系。 |
| [^12] | [Pointer Networks with Q-Learning for OP Combinatorial Optimization](https://arxiv.org/abs/2311.02629) | 提出了Pointer Q-Network (PQN)方法，将Ptr-Nets和Q-learning相结合，利用其批评者性质，出色地捕获了嵌入图中的关系，从而有效解决了OP组合优化中的具体挑战 |
| [^13] | [An Unobtrusive and Lightweight Ear-worn System for Continuous Epileptic Seizure Detection.](http://arxiv.org/abs/2401.05425) | 本文提出了一种无干扰且轻量级的耳戴系统EarSD，通过测量用户耳后部位的生理信号，实现了对癫痫发作的连续检测。这种系统相比传统的基于头皮的脑电图测试具有成本低、便携性好、使用舒适的优点。 |
| [^14] | [FairWASP: Fast and Optimal Fair Wasserstein Pre-processing.](http://arxiv.org/abs/2311.00109) | FairWASP是一种快速和最优的公平Wasserstein预处理方法，通过重新加权数据集来减少分类数据集中的不平等性，同时满足人口平等性准则。这种方法可以用于构建可以输入任何分类方法的数据集。 |
| [^15] | [RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network for Non-stationary Signal Decomposition.](http://arxiv.org/abs/2309.04782) | RRCNN$^{+}$是一种增强的残差递归卷积神经网络，用于非平稳信号分解。它能更稳定地分解信号并具有较低的计算成本，深度学习为非平稳信号分解提供了新的视角。 |
| [^16] | [Unified Concept Editing in Diffusion Models.](http://arxiv.org/abs/2308.14761) | 本文提出了一种称为统一概念编辑（UCE）的方法，通过使用一个闭合解决方案对模型进行编辑，同时解决文本到图像模型中的偏见、版权和冒犯性内容等问题。实验证明了该方法的改进和可扩展性。 |
| [^17] | [RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task.](http://arxiv.org/abs/2307.07840) | 这项工作提出了一种新的解释方法（XAIG-R），用于解释图回归模型，通过引入信息瓶颈理论的新目标和混合框架来解决回归任务中的挑战，同时还使用对比学习策略来处理连续有序标签。 |
| [^18] | [Convolutions Through the Lens of Tensor Networks.](http://arxiv.org/abs/2307.02275) | 该论文提供了一种通过张量网络理解和演化卷积的新视角，可以通过绘制和操作张量网络来进行函数转换、子张量访问和融合。研究人员还演示了卷积图表的导出以及各种自动微分操作和二阶信息逼近图表的生成，同时还提供了特定于卷积的图表转换，以优化计算性能。 |
| [^19] | [Approximation theory of transformer networks for sequence modeling.](http://arxiv.org/abs/2305.18475) | 本文证明了变压器假设空间的普遍逼近定理，并提出了一种新的规律概念用于精确逼近速率估计，揭示了变压器适用于逼近哪些类型的序列关系，并讨论了其与传统序列建模方法之间的结构偏差。 |
| [^20] | [A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU.](http://arxiv.org/abs/2305.17473) | 本文全面概括了深度学习模型的类型和应用，比较分析了各个模型的结构、优点和局限性，有助于选择和设计深度学习模型。 |
| [^21] | [The Representation Jensen-Shannon Divergence.](http://arxiv.org/abs/2305.16446) | 本文提出了一种基于表示的新型散度——表示Jensen-Shannon散度，通过将数据分布嵌入到RKHS中，并利用表示的协方差算子的频谱，实现对数据分布的估计，并提供了具有灵活性，可扩展性，可微分性的经验协方差矩阵估计函数和基于核矩阵的估计函数。 |
| [^22] | [Neural incomplete factorization: learning preconditioners for the conjugate gradient method.](http://arxiv.org/abs/2305.16368) | 本文提出了一种名为神经不完全分解的新方法，利用自监督训练的图神经网络生成适用于特定问题域的有效预处理器。其通过替换传统手工预处理器显着提高了收敛和计算效率，在合成和真实问题上进行的实验均表现出竞争力。 |
| [^23] | [Fed-GLOSS-DP: Federated, Global Learning using Synthetic Sets with Record Level Differential Privacy.](http://arxiv.org/abs/2302.01068) | 本文通过利用合成样本实现全局优化，加入记录级差分隐私以保护隐私，验证了该方法的数据集有效性。 |
| [^24] | [Investigating Labeler Bias in Face Annotation for Machine Learning.](http://arxiv.org/abs/2301.09902) | 面部注释标注者的刻板印象和个人特征会影响其数据标注的公正性，强调需要对整个人工智能培训过程保持高度透明以尽早识别和纠正偏见。 |
| [^25] | [Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects.](http://arxiv.org/abs/2208.04883) | 本文提出了神经会合，一种深度学习导航和控制框架，用于可靠、准确和自主地遭遇快速移动的星际物体。它通过点最小范数追踪控制和谱归一化深度神经网络引导策略来提供高概率指数上界的飞行器交付误差。 |
| [^26] | [Output-sensitive ERM-based techniques for data-driven algorithm design.](http://arxiv.org/abs/2204.03569) | 本研究通过列举问题实例总损失函数的部分来提出了基于输出感知ERM的数据驱动算法设计技术，解决了多参数组合算法族的计算效率问题。 |

# 详细

[^1]: 信任学习理论

    Credal Learning Theory

    [https://rss.arxiv.org/abs/2402.00957](https://rss.arxiv.org/abs/2402.00957)

    本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。

    

    统计学习理论是机器学习的基础，为从未知概率分布中学习到的模型的风险提供理论边界。然而，在实际部署中，数据分布可能会变化，导致领域适应/泛化问题。在本文中，我们建立了一个“信任”学习理论的基础，使用概率的凸集（信任集）来建模数据生成分布的变异性。我们认为，这样的信任集可以从有限样本的训练集中推断出来。对于有限假设空间（无论是否可实现）和无限模型空间，推导出界限，这直接推广了经典结果。

    Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.
    
[^2]: 具有快速prop的可推广、快速和准确的DeepQSPR Part 1: 框架和基准测试

    Generalizable, Fast, and Accurate DeepQSPR with fastprop Part 1: Framework and Benchmarks

    [https://arxiv.org/abs/2404.02058](https://arxiv.org/abs/2404.02058)

    fastprop是一种DeepQSPR框架，通过使用分子级描述符，在极大缩短时间内，在多样数据集上达到并超越了学习表示的性能。

    

    量化结构-性质关系研究旨在定义分子结构与任意感兴趣的数量之间的映射。历史上，这是通过开发描述符来实现的，这需要显著的领域专业知识，并且难以泛化。因此，该领域已经演变为分子属性预测，并转为使用高度可推广的学习表示。该论文介绍了fastprop，一种DeepQSPR框架，使用一组明智的分子级描述符，在极大缩短的时间内满足并超越了多样数据集上学习表示的性能。fastprop可以在github上免费获取，网址为github.com/JacksonBurns/fastprop。

    arXiv:2404.02058v1 Announce Type: new  Abstract: Quantitative Structure Property Relationship studies aim to define a mapping between molecular structure and arbitrary quantities of interest. This was historically accomplished via the development of descriptors which requires significant domain expertise and struggles to generalize. Thus the field has morphed into Molecular Property Prediction and been given over to learned representations which are highly generalizable. The paper introduces fastprop, a DeepQSPR framework which uses a cogent set of molecular level descriptors to meet and exceed the performance of learned representations on diverse datasets in dramatically less time. fastprop is freely available on github at github.com/JacksonBurns/fastprop.
    
[^3]: 通过线上的一致性预测基础模型的性能

    Predicting the Performance of Foundation Models via Agreement-on-the-Line

    [https://arxiv.org/abs/2404.01542](https://arxiv.org/abs/2404.01542)

    本研究发现，通过对来自单个基础模型的多次运行进行轻微微调，可以通过训练期间的随机性选择来显著影响最终集合中的一致性。

    

    估计标签稀缺情况下的外部分布性能对于安全部署基础模型至关重要。最近，人们发现神经网络集合观察到“线上一致性”现象，可以利用它可靠地预测无标签的外部分布性能。然而，与在分布数据上从头开始训练多次轮数的传统神经网络相比，基础模型经历了从预训练权重中进行最小微调，这可能会减少观察到线上一致性所需的集合多样性。在我们的工作中，我们展示出当轻微微调整来自$\textit{单个}$基础模型的多次运行时，训练期间的随机性选择（线性头初始化、数据排序和数据子集）可能导致不同程度的线上一致性的最终集合。令人惊讶的是，只有随机头初始化就能极大程度地影响集合中的一致性。ên初化就能使产生的集合中的一致性水平产生巨大差异。

    arXiv:2404.01542v1 Announce Type: new  Abstract: Estimating the out-of-distribution performance in regimes where labels are scarce is critical to safely deploy foundation models. Recently, it was shown that ensembles of neural networks observe the phenomena ``agreement-on-the-line'', which can be leveraged to reliably predict OOD performance without labels. However, in contrast to classical neural networks that are trained on in-distribution data from scratch for numerous epochs, foundation models undergo minimal finetuning from heavily pretrained weights, which may reduce the ensemble diversity needed to observe agreement-on-the-line. In our work, we demonstrate that when lightly finetuning multiple runs from a $\textit{single}$ foundation model, the choice of randomness during training (linear head initialization, data ordering, and data subsetting) can lead to drastically different levels of agreement-on-the-line in the resulting ensemble. Surprisingly, only random head initializati
    
[^4]: 迭代$Q$-网络：超越单步贝尔曼算子

    Iterated $Q$-Network: Beyond the One-Step Bellman Operator

    [https://arxiv.org/abs/2403.02107](https://arxiv.org/abs/2403.02107)

    引入了迭代$Q$-网络（iQN）方法，通过一次考虑多次迭代的贝尔曼算子来改进值基强化学习方法，在理论上可行，并在实验中展示其在游戏和控制环境中的优势。

    

    值基强化学习（RL）方法依赖于贝尔曼算子的应用，该算子需要从样本中进行近似。大多数方法包括交替应用贝尔曼算子和随后投影步骤到考虑的函数空间的迭代方案。然而，我们观察到这些算法可以通过一次考虑多次迭代的贝尔曼算子来改进。因此，我们引入了迭代$Q$-网络（iQN），这是一种新颖的方法，它学习一系列$Q$函数逼近，其中每个$Q$函数都作为下一个函数链中的目标。我们证明了iQN在理论上是可行的，并展示了它如何可以无缝地用于值基和演员-评论方法。我们在Atari$2600$游戏和连续控制MuJoCo环境中在实验上展示了它的优势。

    arXiv:2403.02107v1 Announce Type: cross  Abstract: Value-based Reinforcement Learning (RL) methods rely on the application of the Bellman operator, which needs to be approximated from samples. Most approaches consist of an iterative scheme alternating the application of the Bellman operator and a subsequent projection step onto a considered function space. However, we observe that these algorithms can be improved by considering multiple iterations of the Bellman operator at once. Thus, we introduce iterated $Q$-Networks (iQN), a novel approach that learns a sequence of $Q$-function approximations where each $Q$-function serves as the target for the next one in a chain of consecutive Bellman iterations. We demonstrate that iQN is theoretically sound and show how it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate its advantages on Atari $2600$ games and in continuous-control MuJoCo environments.
    
[^5]: TimeXer：利用外生变量增强变压器进行时间序列预测

    TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables

    [https://arxiv.org/abs/2402.19072](https://arxiv.org/abs/2402.19072)

    本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。

    

    最近的研究表明，在时间序列预测方面取得了显著的性能。然而，由于现实应用的部分观测性质，仅专注于感兴趣的目标，也就是所谓的内生变量，通常是不足以保证准确预测的。值得注意的是，系统通常记录为多个变量，其中外生序列可以为内生变量提供有价值的外部信息。因此，与先前确立的多变量或单变量预测不同，它们要么将所有变量等同对待，要么忽视外生信息，本文关注的是一种实际设置，即具有外生变量的时间序列预测。我们提出了一个新颖的框架TimeXer，利用外部信息增强内生变量的预测。通过巧妙设计的嵌入层，TimeXer使传统的Transformer架构具有重新

    arXiv:2402.19072v1 Announce Type: cross  Abstract: Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical Transformer architecture with the ability to reco
    
[^6]: 在实际处理内存系统上加速图神经网络

    Accelerating Graph Neural Networks on Real Processing-In-Memory Systems

    [https://arxiv.org/abs/2402.16731](https://arxiv.org/abs/2402.16731)

    在实际处理内存系统上加速图神经网络，并提出了针对实际PIM系统的智能并行化技术和混合式执行方法。

    

    图神经网络（GNNs）是新兴的机器学习模型，用于分析图结构数据。图神经网络（GNN）的执行涉及计算密集型和内存密集型核心，后者在总时间中占主导地位，受数据在内存和处理器之间移动的严重瓶颈所限制。处理内存（PIM）系统可以通过在内存阵列附近或内部放置简单处理器来缓解这种数据移动瓶颈。在这项工作中，我们介绍了PyGim，一个有效的机器学习框架，可以在实际PIM系统上加速GNNs。我们为针对实际PIM系统定制的GNN内存密集型核心提出智能并行化技术，并为它们开发了方便的Python API。我们提供混合式GNN执行，其中计算密集型和内存密集型核心分别在以处理器为中心和以内存为中心的计算系统中执行，以匹配它们的算法特性。我们进行了大量评估。

    arXiv:2402.16731v2 Announce Type: replace-cross  Abstract: Graph Neural Networks (GNNs) are emerging ML models to analyze graph-structure data. Graph Neural Network (GNN) execution involves both compute-intensive and memory-intensive kernels, the latter dominates the total time, being significantly bottlenecked by data movement between memory and processors. Processing-In-Memory (PIM) systems can alleviate this data movement bottleneck by placing simple processors near or inside to memory arrays. In this work, we introduce PyGim, an efficient ML framework that accelerates GNNs on real PIM systems. We propose intelligent parallelization techniques for memory-intensive kernels of GNNs tailored for real PIM systems, and develop handy Python API for them. We provide hybrid GNN execution, in which the compute-intensive and memory-intensive kernels are executed in processor-centric and memory-centric computing systems, respectively, to match their algorithmic nature. We extensively evaluate 
    
[^7]: 通过差分动态逻辑确保神经网络控制器的安全性

    Provably Safe Neural Network Controllers via Differential Dynamic Logic

    [https://arxiv.org/abs/2402.10998](https://arxiv.org/abs/2402.10998)

    通过差分动态逻辑与神经网络验证相结合的VerSAILLE方法，实现了对神经网络控制系统在无限时间范围上的安全性证明。

    

    虽然神经网络（NN）作为面向目标的控制器在网络物理系统中具有巨大潜力，但验证基于神经网络的控制系统（NNCS）的安全性对于实际应用NN来说面临着重大挑战，特别是当需要对无界时间范围进行安全性验证时。我们引入了VerSAILLE（通过逻辑链接包验证的可验证安全人工智能）：这是差分动态逻辑（dL）和NN验证组合的第一种方法。通过合作，我们可以利用NN验证工具的效率，同时保留dL的严谨性。我们提出了一个控制器信封的安全性证明，以证明无限时间范围上具体NNCS的安全性。VerSAILLE导致的NN验证属性通常需要非线性算术，而高效的NN验证工具仅支持线性算术。

    arXiv:2402.10998v1 Announce Type: cross  Abstract: While neural networks (NNs) have a large potential as goal-oriented controllers for Cyber-Physical Systems, verifying the safety of neural network based control systems (NNCSs) poses significant challenges for the practical use of NNs -- especially when safety is needed for unbounded time horizons. One reason for this is the intractability of NN and hybrid system analysis. We introduce VerSAILLE (Verifiably Safe AI via Logically Linked Envelopes): The first approach for the combination of differential dynamic logic (dL) and NN verification. By joining forces, we can exploit the efficiency of NN verification tools while retaining the rigor of dL. We reflect a safety proof for a controller envelope in an NN to prove the safety of concrete NNCS on an infinite-time horizon. The NN verification properties resulting from VerSAILLE typically require nonlinear arithmetic while efficient NN verification tools merely support linear arithmetic. T
    
[^8]: 对离线强化学习中的奖励污染攻击的研究

    Reward Poisoning Attack Against Offline Reinforcement Learning

    [https://arxiv.org/abs/2402.09695](https://arxiv.org/abs/2402.09695)

    这项研究针对深度神经网络函数逼近的一般离线强化学习中的奖励污染攻击问题，提出了一种名为“策略对比攻击”的攻击策略。通过使低性能策略看起来像是高性能的，同时使高性能策略看起来像是低性能的，我们证明了这种攻击有效性。

    

    我们研究了针对深度神经网络函数逼近的一般离线强化学习中的奖励污染攻击问题。我们考虑了一个黑盒威胁模型，攻击者对学习算法完全不了解，并且其预算受到限制，限制了每个数据点的污染量以及总扰动。我们提出了一种名为“策略对比攻击”的攻击策略。其高层思想是使一些低性能策略看起来像是高性能的，同时使高性能策略看起来像是低性能的。据我们所知，我们首次提出了一种适用于一般离线强化学习场景的黑盒奖励污染攻击。我们提供了关于攻击设计的理论洞察，并在不同类型的学习数据集上经验证明我们的攻击对当前最先进的离线强化学习算法是有效的。

    arXiv:2402.09695v1 Announce Type: cross  Abstract: We study the problem of reward poisoning attacks against general offline reinforcement learning with deep neural networks for function approximation. We consider a black-box threat model where the attacker is completely oblivious to the learning algorithm and its budget is limited by constraining both the amount of corruption at each data point, and the total perturbation. We propose an attack strategy called `policy contrast attack'. The high-level idea is to make some low-performing policies appear as high-performing while making high-performing policies appear as low-performing. To the best of our knowledge, we propose the first black-box reward poisoning attack in the general offline RL setting. We provide theoretical insights on the attack design and empirically show that our attack is efficient against current state-of-the-art offline RL algorithms in different kinds of learning datasets.
    
[^9]: 使用渐变草图进行训练数据归因和损失地貌研究

    Gradient Sketches for Training Data Attribution and Studying the Loss Landscape

    [https://arxiv.org/abs/2402.03994](https://arxiv.org/abs/2402.03994)

    本论文提出了一种可扩展的渐变草图算法，用于训练数据归因和损失地貌研究。作者在三个应用中展示了该方法的有效性。

    

    随机投影或渐变和Hessian向量乘积的草图在需要存储许多这些向量并保留关于它们的相对几何信息的应用中起着重要作用。两个重要场景是训练数据归因（跟踪模型对训练数据的行为），其中需要存储每个训练示例的渐变，以及Hessian的频谱研究（分析训练动态），其中需要存储多个Hessian向量乘积。虽然使用密集矩阵的草图易于实现，但它们受存储限制，不能扩展到现代神经网络。在神经网络内在维度的研究工作的推动下，我们提出并研究了可伸缩草图算法的设计空间。我们在三个应用中展示了我们方法的有效性：训练数据归因，Hessian谱分析和微调预先训练时的内在维度计算。

    Random projections or sketches of gradients and Hessian vector products play an essential role in applications where one needs to store many such vectors while retaining accurate information about their relative geometry. Two important scenarios are training data attribution (tracing a model's behavior to the training data), where one needs to store a gradient for each training example, and the study of the spectrum of the Hessian (to analyze the training dynamics), where one needs to store multiple Hessian vector products. While sketches that use dense matrices are easy to implement, they are memory bound and cannot be scaled to modern neural networks. Motivated by work on the intrinsic dimension of neural networks, we propose and study a design space for scalable sketching algorithms. We demonstrate the efficacy of our approach in three applications: training data attribution, the analysis of the Hessian spectrum and the computation of the intrinsic dimension when fine-tuning pre-tra
    
[^10]: 经验风险最小化与f-分布族正则化的等价性

    Equivalence of the Empirical Risk Minimization to Regularization on the Family of f-Divergences

    [https://arxiv.org/abs/2402.00501](https://arxiv.org/abs/2402.00501)

    经验风险最小化与f-分布族的正则化的解决方案在特定条件下是唯一的，并且可以通过使用不同的f-分布正则化等效地表示。

    

    在对f中的温和条件下，给出了经验风险最小化与f-分布的正则化（ERM-$f$DR）的解法。在这些条件下，最优测度被证明是唯一的。并给出了特定选择函数f的解决方案的示例。通过利用f-分布族的灵活性，获得了先前对常见正则化选择的已知解决方案，包括相对熵正则化的唯一解（Type-I和Type-II）。对解的分析揭示了在ERM-$f$DR问题中使用f-分布时的以下属性：$i)$ f-分布正则化强制将解的支持与参考测度的支持重合，引入了在训练数据提供的证据中占主导地位的强归纳偏差；$ii)$ 任何f-分布的正则化都等价于另一种f-分布的正则化。

    The solution to empirical risk minimization with $f$-divergence regularization (ERM-$f$DR) is presented under mild conditions on $f$. Under such conditions, the optimal measure is shown to be unique. Examples of the solution for particular choices of the function $f$ are presented. Previously known solutions to common regularization choices are obtained by leveraging the flexibility of the family of $f$-divergences. These include the unique solutions to empirical risk minimization with relative entropy regularization (Type-I and Type-II). The analysis of the solution unveils the following properties of $f$-divergences when used in the ERM-$f$DR problem: $i\bigl)$ $f$-divergence regularization forces the support of the solution to coincide with the support of the reference measure, which introduces a strong inductive bias that dominates the evidence provided by the training data; and $ii\bigl)$ any $f$-divergence regularization is equivalent to a different $f$-divergence regularization 
    
[^11]: 可解释的图神经网络替代模型微调

    Interpretable Fine-Tuning for Graph Neural Network Surrogate Models

    [https://arxiv.org/abs/2311.07548](https://arxiv.org/abs/2311.07548)

    本论文引入了一种可解释的微调策略，通过应用于非结构网格化流体动力学建模的GNNs，增强了模型的预测能力，并通过识别可解释的物理空间区域及其对应的子图，帮助理解模型架构、优化目标和已知物理之间的关系。

    

    数据驱动的替代建模随着图神经网络（GNNs）的出现在最近几年内蓬勃发展，GNNs可以直接在基于网格的数据表示上运行。这项工作的目标是为GNN引入一种可解释的微调策略，应用于非结构网格化流体动力学建模。最终结果是一个增强的微调模型，它隔离了与预测任务密切相关的物理空间区域，相应于子图，同时保留了基线的预测能力。这些由微调的GNN识别出的结构在前向传递中是自适应生成的，并作为可解释的链接存在于基线模型架构、优化目标和已知问题特定物理之间。此外，通过正则化程序，微调的GNNs还可以在推断期间用于识别对应的图节点。

    arXiv:2311.07548v2 Announce Type: replace  Abstract: Data-driven surrogate modeling has surged in capability in recent years with the emergence of graph neural networks (GNNs), which can operate directly on mesh-based representations of data. The goal of this work is to introduce an interpretable fine-tuning strategy for GNNs, with application to unstructured mesh-based fluid dynamics modeling. The end result is an enhanced fine-tuned model that isolates regions in physical space, corresponding to sub-graphs, that are intrinsically linked to the forecasting task while retaining the predictive capability of the baseline. These structures, identified by the fine-tuned GNNs, are adaptively produced in the forward pass and serve as explainable links between the baseline model architecture, the optimization goal, and known problem-specific physics. Additionally, through a regularization procedure, the fine-tuned GNNs can also be used to identify, during inference, graph nodes that correspon
    
[^12]: 带有Q-Learning的指针网络用于OP组合优化

    Pointer Networks with Q-Learning for OP Combinatorial Optimization

    [https://arxiv.org/abs/2311.02629](https://arxiv.org/abs/2311.02629)

    提出了Pointer Q-Network (PQN)方法，将Ptr-Nets和Q-learning相结合，利用其批评者性质，出色地捕获了嵌入图中的关系，从而有效解决了OP组合优化中的具体挑战

    

    Orienteering Problem（OP）在组合优化（CO）中提出了独特挑战，突显了其在物流、交付和运输规划中的广泛应用。由于OP的NP-hard性质，获得最优解本质上是复杂的。尽管指针网络（Ptr-Nets）在各种组合任务中表现出色，但它们在OP上的表现以及需要专注于未来回报或探索的任务方面仍有改进空间。认识到将强化学习（RL）方法与序列-序列模型相结合的潜能，本研究揭示了指针Q网络（PQN）。该方法结合了Ptr-Nets和Q-learning，由于其仅具批评者性质，它在捕获嵌入图中的关系方面表现出色，这是有效应对OP提出的具体挑战的基本要求。我们探讨了架构和功能

    arXiv:2311.02629v2 Announce Type: replace  Abstract: The Orienteering Problem (OP) presents a unique challenge in Combinatorial Optimization (CO), emphasized by its widespread use in logistics, delivery, and transportation planning. Given the NP-hard nature of OP, obtaining optimal solutions is inherently complex. While Pointer Networks (Ptr-Nets) have exhibited prowess in various combinatorial tasks, their performance in the context of OP, and duties requiring focus on future return or exploration, leaves room for improvement. Recognizing the potency combining Reinforcement Learning (RL) methods with sequence-to-sequence models, this research unveils the Pointer Q-Network (PQN). This method combines Ptr-Nets and Q-learning, which, thanks to its critic only nature, outstands in its capability of capturing relationships within an embedded graph, a fundamental requirement in order to effectively address the specific challenges presented by OP. We explore the architecture and functionalit
    
[^13]: 一种无干扰且轻量级的耳戴系统用于连续癫痫发作检测

    An Unobtrusive and Lightweight Ear-worn System for Continuous Epileptic Seizure Detection. (arXiv:2401.05425v1 [eess.SP])

    [http://arxiv.org/abs/2401.05425](http://arxiv.org/abs/2401.05425)

    本文提出了一种无干扰且轻量级的耳戴系统EarSD，通过测量用户耳后部位的生理信号，实现了对癫痫发作的连续检测。这种系统相比传统的基于头皮的脑电图测试具有成本低、便携性好、使用舒适的优点。

    

    癫痫是全球最常见的神经疾病之一，影响着全球约5000万人。幸运的是，如果能得到正确的诊断和治疗，高达70%的癫痫患者可以无癫痫发作地生活，而一种可靠的监测癫痫发作的技术可以提高那些不断面临随机发作恐惧的患者的生活质量。尽管基于头皮的脑电图（EEG）测试是诊断癫痫的黄金标准，但该方法成本高、需要住院治疗、需要熟练的操作人员，并且对用户来说不舒适。在本文中，我们提出了EarSD，一种新颖的轻量级、无干扰和社会接受度高的耳戴系统，通过测量用户耳后部位的生理信号来检测癫痫发作的开始。EarSD包括一个集成的自定义传感、计算和通信电路板，用于收集和放大感兴趣的信号，去除运动伪影和环境噪声。

    Epilepsy is one of the most common neurological diseases globally, affecting around 50 million people worldwide. Fortunately, up to 70 percent of people with epilepsy could live seizure-free if properly diagnosed and treated, and a reliable technique to monitor the onset of seizures could improve the quality of life of patients who are constantly facing the fear of random seizure attacks. The scalp-based EEG test, despite being the gold standard for diagnosing epilepsy, is costly, necessitates hospitalization, demands skilled professionals for operation, and is discomforting for users. In this paper, we propose EarSD, a novel lightweight, unobtrusive, and socially acceptable ear-worn system to detect epileptic seizure onsets by measuring the physiological signals from behind the user's ears. EarSD includes an integrated custom-built sensing, computing, and communication PCB to collect and amplify the signals of interest, remove the noises caused by motion artifacts and environmental im
    
[^14]: FairWASP：快速和最优的公平Wasserstein预处理

    FairWASP: Fast and Optimal Fair Wasserstein Pre-processing. (arXiv:2311.00109v1 [cs.LG])

    [http://arxiv.org/abs/2311.00109](http://arxiv.org/abs/2311.00109)

    FairWASP是一种快速和最优的公平Wasserstein预处理方法，通过重新加权数据集来减少分类数据集中的不平等性，同时满足人口平等性准则。这种方法可以用于构建可以输入任何分类方法的数据集。

    

    近年来，机器学习方法的快速发展旨在减少不同子群体之间模型输出的不平等性。在许多情况下，训练数据可能会被不同用户在多个下游应用中使用，这意味着对训练数据本身进行干预可能是最有效的。在这项工作中，我们提出了一种新的预处理方法FairWASP，旨在减少分类数据集中的不平等性，而不会修改原始数据。FairWASP返回样本级权重，使重新加权的数据集最小化与原始数据集的Wasserstein距离，同时满足（经验版本的）人口平等性，这是一种常用的公平性准则。我们从理论上证明了整数权重的最优性，这意味着我们的方法可以等同地理解为复制或删除样本。因此，FairWASP可用于构建可以输入任何分类方法的数据集，而不仅仅是接受样本权重的方法。

    Recent years have seen a surge of machine learning approaches aimed at reducing disparities in model outputs across different subgroups. In many settings, training data may be used in multiple downstream applications by different users, which means it may be most effective to intervene on the training data itself. In this work, we present FairWASP, a novel pre-processing approach designed to reduce disparities in classification datasets without modifying the original data. FairWASP returns sample-level weights such that the reweighted dataset minimizes the Wasserstein distance to the original dataset while satisfying (an empirical version of) demographic parity, a popular fairness criterion. We show theoretically that integer weights are optimal, which means our method can be equivalently understood as duplicating or eliminating samples. FairWASP can therefore be used to construct datasets which can be fed into any classification method, not just methods which accept sample weights. Ou
    
[^15]: RRCNN$^{+}$：一种增强的用于非平稳信号分解的残差递归卷积神经网络

    RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network for Non-stationary Signal Decomposition. (arXiv:2309.04782v1 [cs.LG])

    [http://arxiv.org/abs/2309.04782](http://arxiv.org/abs/2309.04782)

    RRCNN$^{+}$是一种增强的残差递归卷积神经网络，用于非平稳信号分解。它能更稳定地分解信号并具有较低的计算成本，深度学习为非平稳信号分解提供了新的视角。

    

    时间频率分析是许多应用中的一个重要且具有挑战性的任务。傅里叶变换和小波分析是两种经典方法，在许多领域取得了显著的成功。然而，这些方法在处理非线性和非平稳信号时存在一定的局限性。为了应对这一挑战，研究人员提出了一系列非线性和自适应的方法，其中以经验模态分解方法为先驱。它们的目标是将非平稳信号分解为准平稳分量，以在时间频率分析中揭示更好的特征。最近，受深度学习的启发，我们提出了一种新颖的方法，称为残差递归卷积神经网络（RRCNN）。RRCNN不仅可以在对大规模信号进行批处理时实现更稳定的分解，而且还为非平稳信号分解提供了独特的视角。在本研究中，我们旨在借助服务器的帮助进一步改进RRCNN。

    Time-frequency analysis is an important and challenging task in many applications. Fourier and wavelet analysis are two classic methods that have achieved remarkable success in many fields. They also exhibit limitations when applied to nonlinear and non-stationary signals. To address this challenge, a series of nonlinear and adaptive methods, pioneered by the empirical mode decomposition method have been proposed. Their aim is to decompose a non-stationary signal into quasi-stationary components which reveal better features in the time-frequency analysis. Recently, inspired by deep learning, we proposed a novel method called residual recursive convolutional neural network (RRCNN). Not only RRCNN can achieve more stable decomposition than existing methods while batch processing large-scale signals with low computational cost, but also deep learning provides a unique perspective for non-stationary signal decomposition. In this study, we aim to further improve RRCNN with the help of sever
    
[^16]: 扩散模型中的统一概念编辑

    Unified Concept Editing in Diffusion Models. (arXiv:2308.14761v1 [cs.CV])

    [http://arxiv.org/abs/2308.14761](http://arxiv.org/abs/2308.14761)

    本文提出了一种称为统一概念编辑（UCE）的方法，通过使用一个闭合解决方案对模型进行编辑，同时解决文本到图像模型中的偏见、版权和冒犯性内容等问题。实验证明了该方法的改进和可扩展性。

    

    文本到图像模型存在各种安全问题，可能限制其适用性。先前的方法分别解决了文本到图像模型中的偏见、版权和冒犯性内容等各个问题。然而，在真实世界中，所有这些问题都同时出现在同一个模型中。我们提出了一种使用单一方法解决所有问题的方法，名为统一概念编辑（UCE）。我们的方法在不经过训练的情况下通过闭合解决方案对模型进行编辑，并可无缝地扩展到文本条件下的扩散模型上进行并行编辑。我们通过编辑文本到图像的投影来展示可扩展的同时去偏见、消除风格和内容调节，我们进行了大量实验证明了相对于先前方法的改进效果和可扩展性。我们的代码可以在https://unified.baulab.info上找到。

    Text-to-image models suffer from various safety issues that may limit their suitability for deployment. Previous methods have separately addressed individual issues of bias, copyright, and offensive content in text-to-image models. However, in the real world, all of these issues appear simultaneously in the same model. We present a method that tackles all issues with a single approach. Our method, Unified Concept Editing (UCE), edits the model without training using a closed-form solution, and scales seamlessly to concurrent edits on text-conditional diffusion models. We demonstrate scalable simultaneous debiasing, style erasure, and content moderation by editing text-to-image projections, and we present extensive experiments demonstrating improved efficacy and scalability over prior work. Our code is available at https://unified.baulab.info
    
[^17]: RegExplainer: 在回归任务中生成图神经网络的解释

    RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task. (arXiv:2307.07840v1 [cs.LG])

    [http://arxiv.org/abs/2307.07840](http://arxiv.org/abs/2307.07840)

    这项工作提出了一种新的解释方法（XAIG-R），用于解释图回归模型，通过引入信息瓶颈理论的新目标和混合框架来解决回归任务中的挑战，同时还使用对比学习策略来处理连续有序标签。

    

    图回归是一项基础任务，在各种图学习任务中受到越来越多的关注。然而，推理过程通常是不可解释的。现有的解释技术大多限于理解分类任务中图神经网络的行为。在这项工作中，我们寻求解释来解释图回归模型（XAIG-R）。我们展示了现有方法忽视了分布偏移和连续有序的决策边界，这阻碍了它们在回归任务中的应用。为了解决这些挑战，我们提出了一种基于信息瓶颈理论的新目标，并引入了一种新的混合框架，可以以模型无关的方式支持各种图神经网络。我们进一步提出了一种对比学习策略来应对回归任务中的连续有序标签。为了从经验上验证所提出的方法的有效性，我们引入了三个基准数据集和一个真实数据集进行评估。

    Graph regression is a fundamental task and has received increasing attention in a wide range of graph learning tasks. However, the inference process is often not interpretable. Most existing explanation techniques are limited to understanding GNN behaviors in classification tasks. In this work, we seek an explanation to interpret the graph regression models (XAIG-R). We show that existing methods overlook the distribution shifting and continuously ordered decision boundary, which hinders them away from being applied in the regression tasks. To address these challenges, we propose a novel objective based on the information bottleneck theory and introduce a new mix-up framework, which could support various GNNs in a model-agnostic manner. We further present a contrastive learning strategy to tackle the continuously ordered labels in regression task. To empirically verify the effectiveness of the proposed method, we introduce three benchmark datasets and a real-life dataset for evaluation
    
[^18]: 透过张量网络的视角解析卷积

    Convolutions Through the Lens of Tensor Networks. (arXiv:2307.02275v1 [cs.LG])

    [http://arxiv.org/abs/2307.02275](http://arxiv.org/abs/2307.02275)

    该论文提供了一种通过张量网络理解和演化卷积的新视角，可以通过绘制和操作张量网络来进行函数转换、子张量访问和融合。研究人员还演示了卷积图表的导出以及各种自动微分操作和二阶信息逼近图表的生成，同时还提供了特定于卷积的图表转换，以优化计算性能。

    

    尽管卷积的直观概念简单，但其分析比稠密层更加复杂，这使得理论和算法的推广变得困难。我们通过张量网络（TN）提供了对卷积的新视角，通过绘制图表、操作图表进行函数转换、子张量访问和融合来推理底层张量乘法。我们通过推导各种自动微分操作的图表以及具有完整超参数支持、批处理、通道组和任意卷积维度泛化的流行的二阶信息逼近的图表来展示这种表达能力。此外，我们基于连接模式提供了特定于卷积的转换，允许在评估之前重新连接和简化图表。最后，我们通过依赖于高效TN缩并的已建立机制来探究计算性能。我们的TN实现加速了最近提出的

    Despite their simple intuition, convolutions are more tedious to analyze than dense layers, which complicates the generalization of theoretical and algorithmic ideas. We provide a new perspective onto convolutions through tensor networks (TNs) which allow reasoning about the underlying tensor multiplications by drawing diagrams, and manipulating them to perform function transformations, sub-tensor access, and fusion. We demonstrate this expressive power by deriving the diagrams of various autodiff operations and popular approximations of second-order information with full hyper-parameter support, batching, channel groups, and generalization to arbitrary convolution dimensions. Further, we provide convolution-specific transformations based on the connectivity pattern which allow to re-wire and simplify diagrams before evaluation. Finally, we probe computational performance, relying on established machinery for efficient TN contraction. Our TN implementation speeds up a recently-proposed
    
[^19]: 序列建模的变压器网络的逼近理论

    Approximation theory of transformer networks for sequence modeling. (arXiv:2305.18475v1 [cs.LG])

    [http://arxiv.org/abs/2305.18475](http://arxiv.org/abs/2305.18475)

    本文证明了变压器假设空间的普遍逼近定理，并提出了一种新的规律概念用于精确逼近速率估计，揭示了变压器适用于逼近哪些类型的序列关系，并讨论了其与传统序列建模方法之间的结构偏差。

    

    变压器是序列建模应用中广泛应用的架构，但其工作原理的理论理解有限。在本文中，我们研究了变压器逼近序列关系的能力。我们首先证明了变压器假设空间的普遍逼近定理。通过推导，我们确定了一种新的规律概念，在此概念下，我们可以证明一个明确的逼近速率估计。这个估计揭示了变压器的关键结构特性，并暗示了变压器适用于逼近哪些类型的序列关系。特别地，它使我们能够具体地讨论变压器与传统序列建模方法（如循环神经网络）之间的结构偏差。我们的研究结果得到了数字实验的支持。

    The transformer is a widely applied architecture in sequence modeling applications, but the theoretical understanding of its working principles is limited. In this work, we investigate the ability of transformers to approximate sequential relationships. We first prove a universal approximation theorem for the transformer hypothesis space. From its derivation, we identify a novel notion of regularity under which we can prove an explicit approximation rate estimate. This estimate reveals key structural properties of the transformer and suggests the types of sequence relationships that the transformer is adapted to approximating. In particular, it allows us to concretely discuss the structural bias between the transformer and classical sequence modeling methods, such as recurrent neural networks. Our findings are supported by numerical experiments.
    
[^20]: 深度学习模型概述与比较分析：CNN、RNN、LSTM、GRU。

    A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU. (arXiv:2305.17473v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.17473](http://arxiv.org/abs/2305.17473)

    本文全面概括了深度学习模型的类型和应用，比较分析了各个模型的结构、优点和局限性，有助于选择和设计深度学习模型。

    

    深度学习（DL）是机器学习（ML）和人工智能（AI）的强大子集，特别在处理非结构化和大型数据集方面优于传统的ML方法。其影响跨越各个领域，包括语音识别、医疗保健、自动驾驶汽车、网络安全、预测分析等。然而，实际问题的复杂性和动态性给设计有效的深度学习模型带来了挑战。因此，人们开发出了几种不同的深度学习模型来解决不同的问题和应用。在本文中，我们对各种深度学习模型进行了全面调查，包括卷积神经网络（CNN）、循环神经网络（RNN）、生成模型、深度强化学习（DRL）和深度迁移学习。我们考察了每个模型的结构、应用、好处和局限性。此外，我们使用了三个公开可用的数据集进行了分析。

    Deep learning (DL) has emerged as a powerful subset of machine learning (ML) and artificial intelligence (AI), outperforming traditional ML methods, especially in handling unstructured and large datasets. Its impact spans across various domains, including speech recognition, healthcare, autonomous vehicles, cybersecurity, predictive analytics, and more. However, the complexity and dynamic nature of real-world problems present challenges in designing effective deep learning models. Consequently, several deep learning models have been developed to address different problems and applications. In this article, we conduct a comprehensive survey of various deep learning models, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Generative Models, Deep Reinforcement Learning (DRL), and Deep Transfer Learning. We examine the structure, applications, benefits, and limitations of each model. Furthermore, we perform an analysis using three publicly available dataset
    
[^21]: 基于表示的Jensen-Shannon散度

    The Representation Jensen-Shannon Divergence. (arXiv:2305.16446v1 [cs.LG])

    [http://arxiv.org/abs/2305.16446](http://arxiv.org/abs/2305.16446)

    本文提出了一种基于表示的新型散度——表示Jensen-Shannon散度，通过将数据分布嵌入到RKHS中，并利用表示的协方差算子的频谱，实现对数据分布的估计，并提供了具有灵活性，可扩展性，可微分性的经验协方差矩阵估计函数和基于核矩阵的估计函数。

    

    统计散度量化概率分布之间的差异，是机器学习中的一种重要方法。但是，由于数据的底层分布通常未知，从经验样本中估计散度是一个基本难题。本文提出了一种基于再生核希尔伯特空间(RKHS)中协方差算子的新型散度——表示Jensen-Shannon散度。我们的方法将数据分布嵌入到RKHS中，并利用表示的协方差算子的频谱。我们提供了一个从经验协方差矩阵估计的估计函数，它通过使用Fourier特征将数据映射到RKHS中。此估计函数是灵活、可扩展、可微分的，并且适用于小批量优化问题。此外，我们还提供了一种基于核矩阵的估计函数，而不需要对RKHS进行显式映射。我们证明这个量是Jensen-Shannon散度的一个下界。

    Statistical divergences quantify the difference between probability distributions finding multiple uses in machine-learning. However, a fundamental challenge is to estimate divergence from empirical samples since the underlying distributions of the data are usually unknown. In this work, we propose the representation Jensen-Shannon Divergence, a novel divergence based on covariance operators in reproducing kernel Hilbert spaces (RKHS). Our approach embeds the data distributions in an RKHS and exploits the spectrum of the covariance operators of the representations. We provide an estimator from empirical covariance matrices by explicitly mapping the data to an RKHS using Fourier features. This estimator is flexible, scalable, differentiable, and suitable for minibatch-based optimization problems. Additionally, we provide an estimator based on kernel matrices without having an explicit mapping to the RKHS. We show that this quantity is a lower bound on the Jensen-Shannon divergence, and 
    
[^22]: 神经不完全分解：学习共轭梯度法的预处理器

    Neural incomplete factorization: learning preconditioners for the conjugate gradient method. (arXiv:2305.16368v1 [math.OC])

    [http://arxiv.org/abs/2305.16368](http://arxiv.org/abs/2305.16368)

    本文提出了一种名为神经不完全分解的新方法，利用自监督训练的图神经网络生成适用于特定问题域的有效预处理器。其通过替换传统手工预处理器显着提高了收敛和计算效率，在合成和真实问题上进行的实验均表现出竞争力。

    

    本文提出了一种新型的数据驱动方法，用于加速科学计算和优化中遇到的大规模线性方程组求解。我们的方法利用自监督训练图神经网络，生成适用于特定问题域的有效预处理器。通过替换与共轭梯度法一起使用的传统手工预处理器，我们的方法（称为神经不完全分解）显着加速了收敛和计算效率。我们的方法的核心是一种受稀疏矩阵理论启发的新型消息传递块，它与寻找矩阵的稀疏分解的目标相一致。我们在合成问题和来自科学计算的真实问题上评估了我们的方法。我们的结果表明，神经不完全分解始终优于最常见的通用预处理器，包括不完全的Cholesky方法，在收敛速度和计算效率方面表现出竞争力。

    In this paper, we develop a novel data-driven approach to accelerate solving large-scale linear equation systems encountered in scientific computing and optimization. Our method utilizes self-supervised training of a graph neural network to generate an effective preconditioner tailored to the specific problem domain. By replacing conventional hand-crafted preconditioners used with the conjugate gradient method, our approach, named neural incomplete factorization (NeuralIF), significantly speeds-up convergence and computational efficiency. At the core of our method is a novel message-passing block, inspired by sparse matrix theory, that aligns with the objective to find a sparse factorization of the matrix. We evaluate our proposed method on both a synthetic and a real-world problem arising from scientific computing. Our results demonstrate that NeuralIF consistently outperforms the most common general-purpose preconditioners, including the incomplete Cholesky method, achieving competit
    
[^23]: Fed-GLOSS-DP: 利用具有记录级差分隐私的合成集进行联邦全局学习

    Fed-GLOSS-DP: Federated, Global Learning using Synthetic Sets with Record Level Differential Privacy. (arXiv:2302.01068v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01068](http://arxiv.org/abs/2302.01068)

    本文通过利用合成样本实现全局优化，加入记录级差分隐私以保护隐私，验证了该方法的数据集有效性。

    

    本文提出了Fed-GLOSS-DP，一种新颖的保护隐私的联邦学习方法。与以前的线性逐点梯度分享方案（如FedAvg）不同，我们的公式利用从客户端接收到的合成样本实现了一种全局优化。这些合成样本作为损失替代物，通过模拟本地区域内真实图像的实用性来近似本地损失地形。我们还引入了一种衡量有效逼近区域的方法，反映了近似的质量。因此，服务器可以恢复全局损失地形并全面优化模型。此外，受日益严重的隐私问题的启发，我们演示了我们的方法与记录级差分隐私（DP）无缝配合，为客户端上的每个数据记录提供理论上的隐私保证。广泛的结果验证了我们的公式在具有高度倾斜分布的各种数据集上的有效性。

    This work proposes Fed-GLOSS-DP, a novel privacy-preserving approach for federated learning. Unlike previous linear point-wise gradient-sharing schemes, such as FedAvg, our formulation enables a type of global optimization by leveraging synthetic samples received from clients. These synthetic samples, serving as loss surrogates, approximate local loss landscapes by simulating the utility of real images within a local region. We additionally introduce an approach to measure effective approximation regions reflecting the quality of the approximation. Therefore, the server can recover the global loss landscape and comprehensively optimize the model. Moreover, motivated by the emerging privacy concerns, we demonstrate that our approach seamlessly works with record-level differential privacy (DP), granting theoretical privacy guarantees for every data record on the clients. Extensive results validate the efficacy of our formulation on various datasets with highly skewed distributions. Our m
    
[^24]: 探究面部注释在机器学习中的标注者偏见

    Investigating Labeler Bias in Face Annotation for Machine Learning. (arXiv:2301.09902v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.09902](http://arxiv.org/abs/2301.09902)

    面部注释标注者的刻板印象和个人特征会影响其数据标注的公正性，强调需要对整个人工智能培训过程保持高度透明以尽早识别和纠正偏见。

    

    在一个越来越依赖人工智能的世界中，考虑人工智能对人类的伦理影响变得比以往任何时候都更加重要。一个尚未充分探讨的关键挑战是标注者偏见，这可能会为训练创建本质上带有偏见的数据集，并随后导致在医疗保健、就业、教育和执法等领域中出现不准确或不公平的决策。因此，我们进行了一项研究，使用来自不同种族和性别的人的图像进行标记任务，以调查和衡量标注者偏见的存在。我们的结果表明，参与者拥有影响其决策过程的刻板印象，并且标注者人口统计数据对所分配的注释标签产生影响。我们还讨论了标注者偏见如何影响数据集，随后影响所训练的模型。总体而言，在整个人工智能培训过程中必须保持高度透明，尽早识别和纠正数据中的偏见。

    In a world increasingly reliant on artificial intelligence, it is more important than ever to consider the ethical implications of artificial intelligence on humanity. One key under-explored challenge is labeler bias, which can create inherently biased datasets for training and subsequently lead to inaccurate or unfair decisions in healthcare, employment, education, and law enforcement. Hence, we conducted a study to investigate and measure the existence of labeler bias using images of people from different ethnicities and sexes in a labeling task. Our results show that participants possess stereotypes that influence their decision-making process and that labeler demographics impact assigned labels. We also discuss how labeler bias influences datasets and, subsequently, the models trained on them. Overall, a high degree of transparency must be maintained throughout the entire artificial intelligence training process to identify and correct biases in the data as early as possible.
    
[^25]: 神经会合：面向星际物体的可靠导航和控制的证明

    Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects. (arXiv:2208.04883v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2208.04883](http://arxiv.org/abs/2208.04883)

    本文提出了神经会合，一种深度学习导航和控制框架，用于可靠、准确和自主地遭遇快速移动的星际物体。它通过点最小范数追踪控制和谱归一化深度神经网络引导策略来提供高概率指数上界的飞行器交付误差。

    

    星际物体（ISOs）很可能是不可替代的原始材料，在理解系外行星星系方面具有重要价值。然而，由于其运行轨道难以约束，通常具有较高的倾角和相对速度，使用传统的人在环路方法探索ISOs具有相当大的挑战性。本文提出了一种名为神经会合的深度学习导航和控制框架，用于在实时中以可靠、准确和自主的方式遭遇快速移动的物体，包括ISOs。它在基于谱归一化的深度神经网络的引导策略之上使用点最小范数追踪控制，其中参数通过直接惩罚MPC状态轨迹跟踪误差的损失函数进行调优。我们展示了神经会合在预期的飞行器交付误差上提供了高概率指数上界，其证明利用了随机递增稳定性分析。

    Interstellar objects (ISOs) are likely representatives of primitive materials invaluable in understanding exoplanetary star systems. Due to their poorly constrained orbits with generally high inclinations and relative velocities, however, exploring ISOs with conventional human-in-the-loop approaches is significantly challenging. This paper presents Neural-Rendezvous, a deep learning-based guidance and control framework for encountering fast-moving objects, including ISOs, robustly, accurately, and autonomously in real time. It uses pointwise minimum norm tracking control on top of a guidance policy modeled by a spectrally-normalized deep neural network, where its hyperparameters are tuned with a loss function directly penalizing the MPC state trajectory tracking error. We show that Neural-Rendezvous provides a high probability exponential bound on the expected spacecraft delivery error, the proof of which leverages stochastic incremental stability analysis. In particular, it is used to
    
[^26]: 基于输出感知ERM的数据驱动算法设计技术

    Output-sensitive ERM-based techniques for data-driven algorithm design. (arXiv:2204.03569v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2204.03569](http://arxiv.org/abs/2204.03569)

    本研究通过列举问题实例总损失函数的部分来提出了基于输出感知ERM的数据驱动算法设计技术，解决了多参数组合算法族的计算效率问题。

    

    数据驱动算法设计是一种有潜力的基于学习的方法，用于超出最坏情况分析具有可调参数的算法。一个重要的开放问题是为具有多个参数的组合算法族设计计算效率高的数据驱动算法。当固定问题实例并变化参数时，"对偶"损失函数通常具有分段可分解的结构，即除了某些尖锐的转换边界外都表现良好。在本工作中，我们通过列举一组问题实例的总损失函数的部分来开展技术研究，以开发用于数据驱动算法设计的高效ERM学习算法。我们的方法的运行时间与实际出现的部分数目成比例，而不是基于部分数目的最坏情况上界。我们的方法涉及两个新颖的要素 - 一种用于枚举由一组超平面诱导的多面体的输出感知算法。

    Data-driven algorithm design is a promising, learning-based approach for beyond worst-case analysis of algorithms with tunable parameters. An important open problem is the design of computationally efficient data-driven algorithms for combinatorial algorithm families with multiple parameters. As one fixes the problem instance and varies the parameters, the "dual" loss function typically has a piecewise-decomposable structure, i.e. is well-behaved except at certain sharp transition boundaries. In this work we initiate the study of techniques to develop efficient ERM learning algorithms for data-driven algorithm design by enumerating the pieces of the sum dual loss functions for a collection of problem instances. The running time of our approach scales with the actual number of pieces that appear as opposed to worst case upper bounds on the number of pieces. Our approach involves two novel ingredients -- an output-sensitive algorithm for enumerating polytopes induced by a set of hyperpla
    

