# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value](https://arxiv.org/abs/2404.01332) | 使用Shapley值方法解释LLM行为，揭示了所谓的“令牌噪音”效应，揭示了LLMs的决策在很大程度上受到提示组件的影响 |
| [^2] | [Securing GNNs: Explanation-Based Identification of Backdoored Training Graphs](https://arxiv.org/abs/2403.18136) | 提出了一种基于解释的方法来识别GNN中的后门训练图，设计了七种新的度量指标以更有效地检测后门攻击，并且通过自适应攻击进行了方法评估。 |
| [^3] | [Learn from Heterophily: Heterophilous Information-enhanced Graph Neural Network](https://arxiv.org/abs/2403.17351) | 本文提出了HiGNN，一种创新方法，通过调查节点的邻居分布来有效利用异质信息，从而增强图神经网络的学习效果。 |
| [^4] | [Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists](https://arxiv.org/abs/2403.13848) | 通过建立Gini不纯度的平滑敏感度并将其应用于提出DP贪婪规则列表算法，本文改善了差异保护模型的准确性问题。 |
| [^5] | [Bootstrapping Reinforcement Learning with Imitation for Vision-Based Agile Flight](https://arxiv.org/abs/2403.12203) | 在基于视觉的自主无人机竞速中，本研究提出了将强化学习和模仿学习相结合的新型训练框架，以克服样本效率和计算需求方面的挑战，并通过三个阶段的方法进行性能受限的自适应RL微调 |
| [^6] | [RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks](https://arxiv.org/abs/2403.00043) | RiNALMo是迄今为止最大的RNA语言模型，具有650亿个参数，能够在多个下游任务上取得最先进结果，并展示了其泛化能力。 |
| [^7] | [Bandits with Abstention under Expert Advice](https://arxiv.org/abs/2402.14585) | 我们提出了CBA算法，其利用放弃参与游戏的假设获得了可以显著改进经典Exp4算法的奖励界限，成为首个对一般置信评级预测器的预期累积奖励实现界限的研究者，并在专家案例中实现了一种新颖的奖励界限。 |
| [^8] | [Dynamic planning in hierarchical active inference](https://arxiv.org/abs/2402.11658) | 通过研究在动态规划领域中模拟工具使用的目标，我们深入探讨了主动推断中的动态规划，该领域考虑到生物目标导向行为的两个关键方面 |
| [^9] | [A Theoretical Analysis of Nash Learning from Human Feedback under General KL-Regularized Preference](https://arxiv.org/abs/2402.07314) | 本论文从理论层面分析了一种关于一般偏好下纳什学习从人类反馈中的方法，通过对两个竞争的LLM进行博弈来找到一种一致生成响应的策略。 |
| [^10] | [Solution-Set Geometry and Regularization Path of a Nonconvexly Regularized Convex Sparse Model](https://arxiv.org/abs/2311.18438) | sGMC模型作为LASSO的非凸正则化替代品，在保留LASSO模型优势的同时，其解集几何、解唯一性和稀疏性与LASSO模型具有相似且优雅的特性。 |
| [^11] | [Explainable Identification of Hate Speech towards Islam using Graph Neural Networks](https://arxiv.org/abs/2311.04916) | 使用图神经网络解释和识别伊斯兰教仇恨言论，模型在保持出色性能的同时能够解释相关性和因果关系。 |
| [^12] | [Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation.](http://arxiv.org/abs/2401.12275) | 本文提出了一种多Agent动态关系推理方法，通过明确推断关系结构的演化，来实现在社交机器人导航中的有效性。方法包括推断超边缘以实现群体推理和轨迹预测器生成未来状态。 |
| [^13] | [CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder.](http://arxiv.org/abs/2401.08897) | CFASL是一种用于解缠学习的新方法，它将对称性学习与VAE集成，无需任何数据集因子信息的先验知识，具有三个新特征：对齐潜在向量维度到可学习对称代码簿中的对称性，学习复合对称性来表达未知因素的变化，以及引入群等变编码器和解码器来训练VAE。 |
| [^14] | [Stochastic Super-resolution of Cosmological Simulations with Denoising Diffusion Models.](http://arxiv.org/abs/2310.06929) | 本文提出了使用去噪扩散模型进行宇宙学超分辨率的方法，通过重新分配不同尺度的重要性来实现准确的结果，该方法能够产生令人信服的超分辨率图像，并且与小尺度特征多样性一致。 |
| [^15] | [Exploiting Transformer Activation Sparsity with Dynamic Inference.](http://arxiv.org/abs/2310.04361) | 本文提出了一种名为DSTI的方法，通过强制激活稀疏性并将Transformer模型转换为稀疏的专家混合版本来极大地降低推理成本。此方法可以应用于任何Transformer模型，并对准确性影响微乎其微。 |
| [^16] | [Fast and Functional Structured Data Generators Rooted in Out-of-Equilibrium Physics.](http://arxiv.org/abs/2307.06797) | 这项研究提出了一种基于非平衡物理学的训练算法，用于解决使用能量模型生成高质量结构化数据的挑战。该方法通过改善模型的分类能力和生成速度，在多个领域取得了成功应用。 |
| [^17] | [Levin Tree Search with Context Models.](http://arxiv.org/abs/2305.16945) | 本文提出了一种新的具有上下文模型的Levin树搜索算法，通过将神经网络替换为上下文模型，实现了LTS损失的凸优化，并在多个基准测试中取得了明显优于LTS+NN的结果。 |
| [^18] | [A Block Coordinate Descent Method for Nonsmooth Composite Optimization under Orthogonality Constraints.](http://arxiv.org/abs/2304.03641) | 本文提出了一种新的块坐标下降方法OBCD，用于解决具有正交约束的一般非光滑组合问题。 OBCD是一种可行的方法，具有低的计算复杂性，并且获得严格的收敛保证。 |
| [^19] | [A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk.](http://arxiv.org/abs/2304.03247) | 论文提出了一种贝叶斯框架，针对错位处理问题，将其视为治疗切换问题，并通过概率模型解决了复增和末事件偏差的问题。 |
| [^20] | [SimTS: Rethinking Contrastive Representation Learning for Time Series Forecasting.](http://arxiv.org/abs/2303.18205) | 本文提出了一种不依赖于负对或特定时间序列特征假设的简单表示学习方法SimTS，通过学习在潜在空间中从过去预测未来来改进时间序列预测，并在多个数据集上表现出具有竞争力的性能。 |

# 详细

[^1]: 等等，这都是令牌噪音？一直就是吗：利用 Shapley 值解释 LLM 行为

    Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value

    [https://arxiv.org/abs/2404.01332](https://arxiv.org/abs/2404.01332)

    使用Shapley值方法解释LLM行为，揭示了所谓的“令牌噪音”效应，揭示了LLMs的决策在很大程度上受到提示组件的影响

    

    大型语言模型（LLMs）的出现为模拟人类行为和认知过程开辟了新的可能性，潜在应用包括市场研究和消费者行为分析等各个领域。然而，由于LLMs的显著差异暗示了不同的基础过程在起作用，以及LLMs对提示变化的敏感性，利用LLMs作为人类主体的替代仍然存在不确定性。本文提出了一种基于合作博弈理论中Shapley值的新方法来解释LLM行为，并量化每个提示组件对模型输出的相对贡献。通过两个应用--一个离散选择实验和一个认知偏见调查，我们展示了Shapley值方法如何揭示我们所谓的“令牌噪音”效应，即LLM决策受到的影响严重偏向于

    arXiv:2404.01332v1 Announce Type: cross  Abstract: The emergence of large language models (LLMs) has opened up exciting possibilities for simulating human behavior and cognitive processes, with potential applications in various domains, including marketing research and consumer behavior analysis. However, the validity of utilizing LLMs as stand-ins for human subjects remains uncertain due to glaring divergences that suggest fundamentally different underlying processes at play and the sensitivity of LLM responses to prompt variations. This paper presents a novel approach based on Shapley values from cooperative game theory to interpret LLM behavior and quantify the relative contribution of each prompt component to the model's output. Through two applications-a discrete choice experiment and an investigation of cognitive biases-we demonstrate how the Shapley value method can uncover what we term "token noise" effects, a phenomenon where LLM decisions are disproportionately influenced by 
    
[^2]: 保护GNN：基于解释的后门训练图识别

    Securing GNNs: Explanation-Based Identification of Backdoored Training Graphs

    [https://arxiv.org/abs/2403.18136](https://arxiv.org/abs/2403.18136)

    提出了一种基于解释的方法来识别GNN中的后门训练图，设计了七种新的度量指标以更有效地检测后门攻击，并且通过自适应攻击进行了方法评估。

    

    Graph Neural Networks (GNNs)已经在许多领域流行起来，但它们容易受到后门攻击，这可能会损害它们的性能和道德应用。检测这些攻击对于保持GNN分类任务的可靠性和安全性至关重要，但有效的检测技术并不多见。我们观察到，尽管图级解释能够提供一些有限的见解，但它们在检测后门触发器方面的有效性是不一致且不完整的。为弥补这一差距，我们提取并转换GNN解释机制的次要输出，设计了七种更有效地检测后门攻击的新度量。此外，我们还开发了一种自适应攻击来严格评估我们的方法。我们在多个基准数据集上测试了我们的方法，并检查其对各种攻击模型的有效性。我们的结果表明，我们的方法可以取得较高的效果。

    arXiv:2403.18136v1 Announce Type: cross  Abstract: Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet they are vulnerable to backdoor attacks that can compromise their performance and ethical application. The detection of these attacks is crucial for maintaining the reliability and security of GNN classification tasks, but effective detection techniques are lacking. Following an initial investigation, we observed that while graph-level explanations can offer limited insights, their effectiveness in detecting backdoor triggers is inconsistent and incomplete. To bridge this gap, we extract and transform secondary outputs of GNN explanation mechanisms, designing seven novel metrics that more effectively detect backdoor attacks. Additionally, we develop an adaptive attack to rigorously evaluate our approach. We test our method on multiple benchmark datasets and examine its efficacy against various attack models. Our results show that our method can achieve high de
    
[^3]: 从异质性学习：异质信息增强图神经网络

    Learn from Heterophily: Heterophilous Information-enhanced Graph Neural Network

    [https://arxiv.org/abs/2403.17351](https://arxiv.org/abs/2403.17351)

    本文提出了HiGNN，一种创新方法，通过调查节点的邻居分布来有效利用异质信息，从而增强图神经网络的学习效果。

    

    在异质性环境中，Graph Neural Networks (GNNs)通常表现出次优性能，因为不同标签的节点倾向于基于语义含义相连。目前关于图异质性的研究主要集中在聚合校准或邻居扩展上，通过利用节点特征或结构信息来改善GNN表示以解决异质性问题。本文提出并证明了异质性中内在的宝贵语义信息可以通过调查图中每个单独节点的邻居分布来有效地利用在图学习中。通过理论分析，论证了这一理念在增强图学习中的有效性。基于此分析，提出了HiGNN，一种创新方法，构建了一个额外的新图结构，通过利用节点分布整合异质信息来增强图学习。

    arXiv:2403.17351v1 Announce Type: new  Abstract: Under circumstances of heterophily, where nodes with different labels tend to be connected based on semantic meanings, Graph Neural Networks (GNNs) often exhibit suboptimal performance. Current studies on graph heterophily mainly focus on aggregation calibration or neighbor extension and address the heterophily issue by utilizing node features or structural information to improve GNN representations. In this paper, we propose and demonstrate that the valuable semantic information inherent in heterophily can be utilized effectively in graph learning by investigating the distribution of neighbors for each individual node within the graph. The theoretical analysis is carried out to demonstrate the efficacy of the idea in enhancing graph learning. Based on this analysis, we propose HiGNN, an innovative approach that constructs an additional new graph structure, that integrates heterophilous information by leveraging node distribution to enha
    
[^4]: 用于学习差异保护但准确规则列表的平滑敏感度

    Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists

    [https://arxiv.org/abs/2403.13848](https://arxiv.org/abs/2403.13848)

    通过建立Gini不纯度的平滑敏感度并将其应用于提出DP贪婪规则列表算法，本文改善了差异保护模型的准确性问题。

    

    差异保护（DP）机制可以嵌入到机器学习算法的设计中，以保护所得模型免受隐私泄露的影响，尽管这通常伴随着明显的准确性损失。本文旨在通过建立Gini不纯度的平滑敏感度并利用这一特性来提出一个DP贪婪规则列表算法，以改善这种权衡。我们的理论分析和实验结果表明，集成平滑敏感度的DP规则列表模型具有比使用全局敏感度的其他DP框架更高的准确性。

    arXiv:2403.13848v1 Announce Type: cross  Abstract: Differentially-private (DP) mechanisms can be embedded into the design of a machine learningalgorithm to protect the resulting model against privacy leakage, although this often comes with asignificant loss of accuracy. In this paper, we aim at improving this trade-off for rule lists modelsby establishing the smooth sensitivity of the Gini impurity and leveraging it to propose a DP greedyrule list algorithm. In particular, our theoretical analysis and experimental results demonstrate thatthe DP rule lists models integrating smooth sensitivity have higher accuracy that those using otherDP frameworks based on global sensitivity.
    
[^5]: 基于模仿的增强学习为基于视觉的敏捷飞行引导引导

    Bootstrapping Reinforcement Learning with Imitation for Vision-Based Agile Flight

    [https://arxiv.org/abs/2403.12203](https://arxiv.org/abs/2403.12203)

    在基于视觉的自主无人机竞速中，本研究提出了将强化学习和模仿学习相结合的新型训练框架，以克服样本效率和计算需求方面的挑战，并通过三个阶段的方法进行性能受限的自适应RL微调

    

    我们在基于视觉的自主无人机竞速的背景下，将强化学习（RL）的有效性和模仿学习（IL）的效率结合在一起。我们专注于直接处理视觉输入，而无需明确的状态估计。虽然强化学习通过试错提供了一个学习复杂控制器的通用框架，但面临着样本效率和计算需求的挑战，因为视觉输入的维度较高。相反，IL在从视觉演示中学习方面表现出效率，但受到演示质量的限制，并面临诸如协变量漂移的问题。为了克服这些限制，我们提出了一个结合RL和IL优势的新型训练框架。我们的框架包括三个阶段：使用特权状态信息的师傅策略的初始训练，使用IL将此策略蒸馏为学生策略，以及性能受限的自适应RL微调

    arXiv:2403.12203v1 Announce Type: cross  Abstract: We combine the effectiveness of Reinforcement Learning (RL) and the efficiency of Imitation Learning (IL) in the context of vision-based, autonomous drone racing. We focus on directly processing visual input without explicit state estimation. While RL offers a general framework for learning complex controllers through trial and error, it faces challenges regarding sample efficiency and computational demands due to the high dimensionality of visual inputs. Conversely, IL demonstrates efficiency in learning from visual demonstrations but is limited by the quality of those demonstrations and faces issues like covariate shift. To overcome these limitations, we propose a novel training framework combining RL and IL's advantages. Our framework involves three stages: initial training of a teacher policy using privileged state information, distilling this policy into a student policy using IL, and performance-constrained adaptive RL fine-tunin
    
[^6]: RiNALMo: 通用RNA语言模型在结构预测任务上具有良好的泛化能力

    RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks

    [https://arxiv.org/abs/2403.00043](https://arxiv.org/abs/2403.00043)

    RiNALMo是迄今为止最大的RNA语言模型，具有650亿个参数，能够在多个下游任务上取得最先进结果，并展示了其泛化能力。

    

    arXiv:2403.00043v1 通告类型: 跨领域 摘要: 核糖核酸（RNA）在基础生物过程中扮演着各种至关重要的角色。最近，RNA已成为一个有趣的药物靶点，强调了提高我们对其结构和功能的理解的必要性。多年来，测序技术已产生了大量未标记的RNA数据，其中隐藏着重要的知识和潜力。受蛋白质语言模型成功的启发，我们引入了核糖核酸语言模型（RiNALMo）以帮助揭示RNA的隐藏密码。RiNALMo是迄今为止最大的RNA语言模型，具有650亿个参数，预先训练了来自几个可用数据库的3600万个非编码RNA序列。RiNALMo能够提取隐藏知识并隐含地捕捉RNA序列中内嵌的基本结构信息。RiNALMo在多个下游任务上实现了最先进的结果。值得注意的是，我们展示了其泛化能力

    arXiv:2403.00043v1 Announce Type: cross  Abstract: Ribonucleic acid (RNA) plays a variety of crucial roles in fundamental biological processes. Recently, RNA has become an interesting drug target, emphasizing the need to improve our understanding of its structures and functions. Over the years, sequencing technologies have produced an enormous amount of unlabeled RNA data, which hides important knowledge and potential. Motivated by the successes of protein language models, we introduce RiboNucleic Acid Language Model (RiNALMo) to help unveil the hidden code of RNA. RiNALMo is the largest RNA language model to date with $650$ million parameters pre-trained on $36$ million non-coding RNA sequences from several available databases. RiNALMo is able to extract hidden knowledge and capture the underlying structure information implicitly embedded within the RNA sequences. RiNALMo achieves state-of-the-art results on several downstream tasks. Notably, we show that its generalization capabiliti
    
[^7]: 具有弃权选项的专家建议下的赌徒问题

    Bandits with Abstention under Expert Advice

    [https://arxiv.org/abs/2402.14585](https://arxiv.org/abs/2402.14585)

    我们提出了CBA算法，其利用放弃参与游戏的假设获得了可以显著改进经典Exp4算法的奖励界限，成为首个对一般置信评级预测器的预期累积奖励实现界限的研究者，并在专家案例中实现了一种新颖的奖励界限。

    

    我们研究了在赌徒反馈下利用专家建议进行预测的经典问题。我们的模型假设一种行动，即学习者放弃参与游戏，在每次试验中都没有奖励或损失。我们提出了CBA算法，利用这一假设获得了可以显著改进经典Exp4算法的奖励界限。我们可以将我们的问题视为在学习者有放弃参与游戏选项时对置信评级预测器进行聚合。重要的是，我们是第一个对一般置信评级预测器的预期累积奖励实现界限的研究者。在专家案例中，我们实现了一种新颖的奖励界限，显著改进了之前在专家Exp（将弃权视为另一种行动）的边界。作为一个示例应用，我们讨论了在有限度量空间中学习球的并集。在这个上下文设置中，我们设计了CBA的有效实现，re

    arXiv:2402.14585v1 Announce Type: new  Abstract: We study the classic problem of prediction with expert advice under bandit feedback. Our model assumes that one action, corresponding to the learner's abstention from play, has no reward or loss on every trial. We propose the CBA algorithm, which exploits this assumption to obtain reward bounds that can significantly improve those of the classical Exp4 algorithm. We can view our problem as the aggregation of confidence-rated predictors when the learner has the option of abstention from play. Importantly, we are the first to achieve bounds on the expected cumulative reward for general confidence-rated predictors. In the special case of specialists we achieve a novel reward bound, significantly improving previous bounds of SpecialistExp (treating abstention as another action). As an example application, we discuss learning unions of balls in a finite metric space. In this contextual setting, we devise an efficient implementation of CBA, re
    
[^8]: 分层主动推断中的动态规划

    Dynamic planning in hierarchical active inference

    [https://arxiv.org/abs/2402.11658](https://arxiv.org/abs/2402.11658)

    通过研究在动态规划领域中模拟工具使用的目标，我们深入探讨了主动推断中的动态规划，该领域考虑到生物目标导向行为的两个关键方面

    

    通过动态规划，我们指的是人类大脑推断和施加与认知决策相关的运动轨迹的能力。最近的一个范式，主动推断，为生物有机体适应带来了基本见解，不断努力最小化预测误差以将自己限制在与生命兼容的状态。在过去的几年里，许多研究表明人类和动物行为可以解释为主动推断过程，无论是作为离散决策还是连续运动控制，都激发了机器人技术和人工智能中的创新解决方案。然而，文献缺乏对如何有效地在变化环境中规划行动的全面展望。我们设定了对工具使用进行建模的目标，深入研究了主动推断中的动态规划主题，牢记两个生物目标导向行为的关键方面：理解……

    arXiv:2402.11658v1 Announce Type: new  Abstract: By dynamic planning, we refer to the ability of the human brain to infer and impose motor trajectories related to cognitive decisions. A recent paradigm, active inference, brings fundamental insights into the adaptation of biological organisms, constantly striving to minimize prediction errors to restrict themselves to life-compatible states. Over the past years, many studies have shown how human and animal behavior could be explained in terms of an active inferential process -- either as discrete decision-making or continuous motor control -- inspiring innovative solutions in robotics and artificial intelligence. Still, the literature lacks a comprehensive outlook on how to effectively plan actions in changing environments. Setting ourselves the goal of modeling tool use, we delve into the topic of dynamic planning in active inference, keeping in mind two crucial aspects of biological goal-directed behavior: the capacity to understand a
    
[^9]: 一种关于一般KL正则化偏好下纳什学习从人类反馈中的理论分析

    A Theoretical Analysis of Nash Learning from Human Feedback under General KL-Regularized Preference

    [https://arxiv.org/abs/2402.07314](https://arxiv.org/abs/2402.07314)

    本论文从理论层面分析了一种关于一般偏好下纳什学习从人类反馈中的方法，通过对两个竞争的LLM进行博弈来找到一种一致生成响应的策略。

    

    来自人类反馈的强化学习（RLHF）从一个概率偏好模型提供的偏好信号中学习，该模型以一个提示和两个响应作为输入，并产生一个分数，表示对一个响应相对于另一个响应的偏好程度。迄今为止，最流行的RLHF范式是基于奖励的，它从奖励建模的初始步骤开始，然后使用构建的奖励为后续的奖励优化阶段提供奖励信号。然而，奖励函数的存在是一个强假设，基于奖励的RLHF在表达能力上有局限性，不能捕捉到真实世界中复杂的人类偏好。在这项工作中，我们为最近提出的学习范式Nash学习从人类反馈（NLHF）提供了理论洞察力，该学习范式考虑了一个一般的偏好模型，并将对齐过程定义为两个竞争的LLM之间的博弈。学习目标是找到一个一致生成响应的策略。

    Reinforcement Learning from Human Feedback (RLHF) learns from the preference signal provided by a probabilistic preference model, which takes a prompt and two responses as input, and produces a score indicating the preference of one response against another. So far, the most popular RLHF paradigm is reward-based, which starts with an initial step of reward modeling, and the constructed reward is then used to provide a reward signal for the subsequent reward optimization stage. However, the existence of a reward function is a strong assumption and the reward-based RLHF is limited in expressivity and cannot capture the real-world complicated human preference.   In this work, we provide theoretical insights for a recently proposed learning paradigm, Nash learning from human feedback (NLHF), which considered a general preference model and formulated the alignment process as a game between two competitive LLMs. The learning objective is to find a policy that consistently generates responses
    
[^10]: 一个非凸正则化凸稀疏模型的解集几何与正则化路径

    Solution-Set Geometry and Regularization Path of a Nonconvexly Regularized Convex Sparse Model

    [https://arxiv.org/abs/2311.18438](https://arxiv.org/abs/2311.18438)

    sGMC模型作为LASSO的非凸正则化替代品，在保留LASSO模型优势的同时，其解集几何、解唯一性和稀疏性与LASSO模型具有相似且优雅的特性。

    

    广义极小极大凹（GMC）惩罚是一种非凸稀疏正则化器，可以保持正则化最小二乘问题的整体凸性。本文关注GMC模型的一个重要实例，称为缩放GMC（sGMC），并就其解集几何和正则化路径提出各种显著发现。我们的研究表明，虽然sGMC惩罚是LASSO惩罚的非凸扩展（即$\ell_1$范数），但sGMC模型保留了LASSO模型的许多著名特性，因此可以作为LASSO的一个偏差较小的替代品而不会失去其优势。具体而言，对于固定的正则化参数$\lambda$，我们展示了sGMC模型的解集几何、解唯一性和稀疏性可以以一种类似优雅的方式刻画为LASSO模型（参见，例如，Osborne等人2000年，R. J. Tibshirani 2013年）。对于变化的$\lambda$，我们证明了...

    arXiv:2311.18438v2 Announce Type: cross  Abstract: The generalized minimax concave (GMC) penalty is a nonconvex sparse regularizer which can preserve the overall-convexity of the regularized least-squares problem. In this paper, we focus on a significant instance of the GMC model termed scaled GMC (sGMC), and present various notable findings on its solution-set geometry and regularization path. Our investigation indicates that while the sGMC penalty is a nonconvex extension of the LASSO penalty (i.e., the $\ell_1$-norm), the sGMC model preserves many celebrated properties of the LASSO model, hence can serve as a less biased surrogate of LASSO without losing its advantages. Specifically, for a fixed regularization parameter $\lambda$, we show that the solution-set geometry, solution uniqueness and sparseness of the sGMC model can be characterized in a similar elegant way to the LASSO model (see, e.g., Osborne et al. 2000, R. J. Tibshirani 2013). For a varying $\lambda$, we prove that th
    
[^11]: 使用图神经网络解释伊斯兰教仇恨言论的研究

    Explainable Identification of Hate Speech towards Islam using Graph Neural Networks

    [https://arxiv.org/abs/2311.04916](https://arxiv.org/abs/2311.04916)

    使用图神经网络解释和识别伊斯兰教仇恨言论，模型在保持出色性能的同时能够解释相关性和因果关系。

    

    伊斯兰教仇恨言论在在线社交互动平台上是一个普遍存在的挑战。识别和消除这种仇恨是迈向和谐与和平未来的关键一步。本研究提出了一种新的范例，利用图神经网络来识别和解释针对伊斯兰教的仇恨言论。利用图神经网络发现、提取并利用不同数据点之间的关系的内在能力，我们的模型始终能够在保持出色性能的同时提供对潜在相关性和因果关系的解释。

    arXiv:2311.04916v2 Announce Type: cross  Abstract: Islamophobic language is a prevalent challenge on online social interaction platforms. Identifying and eliminating such hatred is a crucial step towards a future of harmony and peace. This study presents a novel paradigm for identifying and explaining hate speech towards Islam using graph neural networks. Utilizing the intrinsic ability of graph neural networks to find, extract, and use relationships across disparate data points, our model consistently achieves outstanding performance while offering explanations for the underlying correlations and causation.
    
[^12]: 多Agent动态关系推理用于社交机器人导航

    Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation. (arXiv:2401.12275v1 [cs.RO])

    [http://arxiv.org/abs/2401.12275](http://arxiv.org/abs/2401.12275)

    本文提出了一种多Agent动态关系推理方法，通过明确推断关系结构的演化，来实现在社交机器人导航中的有效性。方法包括推断超边缘以实现群体推理和轨迹预测器生成未来状态。

    

    社交机器人导航在日常生活的各种情景下可以提供帮助，但需要安全的人机交互和高效的轨迹规划。在多Agent交互系统中，建模成对的关系已经被广泛研究，但是捕捉更大规模的群体活动的能力有限。在本文中，我们提出了一种系统的关系推理方法，通过明确推断正在演变的关系结构，展示了其在多Agent轨迹预测和社交机器人导航中的有效性。除了节点对之间的边缘（即Agent），我们还提出了推断超边缘的方法，以自适应地连接多个节点，以便进行群体推理。我们的方法推断动态演化的关系图和超图，以捕捉关系的演化，轨迹预测器利用这些图来生成未来状态。同时，我们提出了对锐度和逻辑稀疏性进行正则化的方法。

    Social robot navigation can be helpful in various contexts of daily life but requires safe human-robot interactions and efficient trajectory planning. While modeling pairwise relations has been widely studied in multi-agent interacting systems, the ability to capture larger-scale group-wise activities is limited. In this paper, we propose a systematic relational reasoning approach with explicit inference of the underlying dynamically evolving relational structures, and we demonstrate its effectiveness for multi-agent trajectory prediction and social robot navigation. In addition to the edges between pairs of nodes (i.e., agents), we propose to infer hyperedges that adaptively connect multiple nodes to enable group-wise reasoning in an unsupervised manner. Our approach infers dynamically evolving relation graphs and hypergraphs to capture the evolution of relations, which the trajectory predictor employs to generate future states. Meanwhile, we propose to regularize the sharpness and sp
    
[^13]: CFASL：用于变分自编码器中的解缠学习的复合因子对齐对称学习

    CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder. (arXiv:2401.08897v1 [cs.LG])

    [http://arxiv.org/abs/2401.08897](http://arxiv.org/abs/2401.08897)

    CFASL是一种用于解缠学习的新方法，它将对称性学习与VAE集成，无需任何数据集因子信息的先验知识，具有三个新特征：对齐潜在向量维度到可学习对称代码簿中的对称性，学习复合对称性来表达未知因素的变化，以及引入群等变编码器和解码器来训练VAE。

    

    输入和潜在向量的对称性为VAE中的解缠学习提供了宝贵的见解。然而，只有少数几篇论文提出了一种无监督方法，甚至这些方法在训练数据中也需要已知的因子信息。我们提出了一种新的方法，Composite Factor-Aligned Symmetry Learning (CFASL)，将其集成到VAE中，用于学习基于对称性的解缠，无监督学习中不需要任何数据集因子信息的知识。CFASL包括三个用于学习基于对称性的解缠的新特征：1)注入归纳偏置，将潜在向量维度对齐到明确可学习的对称代码簿中的因子对齐对称性；2)学习一个复合对称性，通过学习代码簿中的因子对齐对称性，来表达两个随机样本之间的未知因素的变化；3)在训练VAE时，引入具有群等变编码器和解码器的两个条件。此外，我们提出了一种扩展的评估指标。

    Symmetries of input and latent vectors have provided valuable insights for disentanglement learning in VAEs.However, only a few works were proposed as an unsupervised method, and even these works require known factor information in training data. We propose a novel method, Composite Factor-Aligned Symmetry Learning (CFASL), which is integrated into VAEs for learning symmetry-based disentanglement in unsupervised learning without any knowledge of the dataset factor information.CFASL incorporates three novel features for learning symmetry-based disentanglement: 1) Injecting inductive bias to align latent vector dimensions to factor-aligned symmetries within an explicit learnable symmetry codebook 2) Learning a composite symmetry to express unknown factors change between two random samples by learning factor-aligned symmetries within the codebook 3) Inducing group equivariant encoder and decoder in training VAEs with the two conditions. In addition, we propose an extended evaluation metri
    
[^14]: 用去噪扩散模型的随机超分辨率方法在宇宙学模拟中实现的摘要

    Stochastic Super-resolution of Cosmological Simulations with Denoising Diffusion Models. (arXiv:2310.06929v1 [astro-ph.CO])

    [http://arxiv.org/abs/2310.06929](http://arxiv.org/abs/2310.06929)

    本文提出了使用去噪扩散模型进行宇宙学超分辨率的方法，通过重新分配不同尺度的重要性来实现准确的结果，该方法能够产生令人信服的超分辨率图像，并且与小尺度特征多样性一致。

    

    最近几年，深度学习模型已成功应用于增强低分辨率的宇宙学模拟的小尺度信息，这被称为“超分辨率”任务。迄今为止，这些宇宙学超分辨率模型依赖于生成对抗网络（GANs），这些网络可以实现高度逼真的结果，但存在各种缺点（例如低样本多样性）。我们使用去噪扩散模型作为一种强大的生成模型，来实现超分辨率的宇宙大尺度结构预测（作为二维的首个概念证明）。为了获得准确的小尺度结果，我们开发了一种新的“滤波增强”训练方法，重新分配了像素级训练目标中不同尺度的重要性。我们证明了我们的模型不仅能够产生令人信服的超分辨率图像和百分之一水平一致的功率谱，并且能够重现与小尺度特征多样性一致的结果。

    In recent years, deep learning models have been successfully employed for augmenting low-resolution cosmological simulations with small-scale information, a task known as "super-resolution". So far, these cosmological super-resolution models have relied on generative adversarial networks (GANs), which can achieve highly realistic results, but suffer from various shortcomings (e.g. low sample diversity). We introduce denoising diffusion models as a powerful generative model for super-resolving cosmic large-scale structure predictions (as a first proof-of-concept in two dimensions). To obtain accurate results down to small scales, we develop a new "filter-boosted" training approach that redistributes the importance of different scales in the pixel-wise training objective. We demonstrate that our model not only produces convincing super-resolution images and power spectra consistent at the percent level, but is also able to reproduce the diversity of small-scale features consistent with a
    
[^15]: 利用动态推理来利用Transformer激活稀疏性

    Exploiting Transformer Activation Sparsity with Dynamic Inference. (arXiv:2310.04361v1 [cs.LG])

    [http://arxiv.org/abs/2310.04361](http://arxiv.org/abs/2310.04361)

    本文提出了一种名为DSTI的方法，通过强制激活稀疏性并将Transformer模型转换为稀疏的专家混合版本来极大地降低推理成本。此方法可以应用于任何Transformer模型，并对准确性影响微乎其微。

    

    Transformer模型尽管表现出色，但由于其高计算需求，常面临实际限制。与此同时，先前的研究揭示了这些模型中的显著激活稀疏性，表明存在冗余计算。本文提出了一种称为动态稀疏化Transformer推理（DSTI）的方法，通过强制激活稀疏性并将密集模型转换为其稀疏的专家混合（MoE）版本，从而极大地降低Transformer模型的推理成本。我们证明，在推理过程中可以训练出成功预测每个专家相对贡献的小型门控网络。此外，我们引入了一种动态确定每个令牌执行的专家数量的机制。DSTI可以应用于任何基于Transformer的体系结构，并对准确性影响微乎其微。针对BERT-base分类模型，我们降低了推理成本。

    Transformer models, despite their impressive performance, often face practical limitations due to their high computational requirements. At the same time, previous studies have revealed significant activation sparsity in these models, indicating the presence of redundant computations. In this paper, we propose Dynamic Sparsified Transformer Inference (DSTI), a method that radically reduces the inference cost of Transformer models by enforcing activation sparsity and subsequently transforming a dense model into its sparse Mixture of Experts (MoE) version. We demonstrate that it is possible to train small gating networks that successfully predict the relative contribution of each expert during inference. Furthermore, we introduce a mechanism that dynamically determines the number of executed experts individually for each token. DSTI can be applied to any Transformer-based architecture and has negligible impact on the accuracy. For the BERT-base classification model, we reduce inference c
    
[^16]: 基于非平衡物理学的快速且功能性结构化数据生成器

    Fast and Functional Structured Data Generators Rooted in Out-of-Equilibrium Physics. (arXiv:2307.06797v1 [cs.LG])

    [http://arxiv.org/abs/2307.06797](http://arxiv.org/abs/2307.06797)

    这项研究提出了一种基于非平衡物理学的训练算法，用于解决使用能量模型生成高质量结构化数据的挑战。该方法通过改善模型的分类能力和生成速度，在多个领域取得了成功应用。

    

    在这项研究中，我们解决了使用基于能量的模型在复杂结构化数据集（如人口基因组学、RNA或蛋白质序列数据）中生成高质量、标签特定数据的挑战。传统的训练方法由于马尔可夫链蒙特卡洛混合效率低下而遇到困难，这影响了合成数据的多样性并增加了生成时间。为了解决这些问题，我们使用了一种利用非平衡效应的新型训练算法。这种方法应用于受限玻尔兹曼机，提高了模型对样本的正确分类能力，并只需少数几个采样步骤即可生成高质量的合成数据。该方法的有效性通过其成功应用于四种不同类型的数据得到证明：手写数字，按大陆起源分类的人类基因组突变，酶蛋白家族的功能序列，以及特定分类法的同源RNA序列。

    In this study, we address the challenge of using energy-based models to produce high-quality, label-specific data in complex structured datasets, such as population genetics, RNA or protein sequences data. Traditional training methods encounter difficulties due to inefficient Markov chain Monte Carlo mixing, which affects the diversity of synthetic data and increases generation times. To address these issues, we use a novel training algorithm that exploits non-equilibrium effects. This approach, applied on the Restricted Boltzmann Machine, improves the model's ability to correctly classify samples and generate high-quality synthetic data in only a few sampling steps. The effectiveness of this method is demonstrated by its successful application to four different types of data: handwritten digits, mutations of human genomes classified by continental origin, functionally characterized sequences of an enzyme protein family, and homologous RNA sequences from specific taxonomies.
    
[^17]: 具有上下文模型的Levin树搜索

    Levin Tree Search with Context Models. (arXiv:2305.16945v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.16945](http://arxiv.org/abs/2305.16945)

    本文提出了一种新的具有上下文模型的Levin树搜索算法，通过将神经网络替换为上下文模型，实现了LTS损失的凸优化，并在多个基准测试中取得了明显优于LTS+NN的结果。

    

    Levin Tree Search（LTS）是一种利用策略（动作的概率分布）的搜索算法，并具有关于达到目标节点之前扩展次数的理论保证，这取决于策略的质量。我们将这个保证称为LTS损失，可以将其作为优化表示策略的神经网络（LTS+NN）的损失函数。在这项工作中，我们展示了神经网络可以用在线压缩文献中的参数化上下文模型来替代（LTS+CM）。我们证明了在这种新模型下LTS损失是凸的，从而可以使用标准凸优化工具，并且对于给定的解轨迹集合，在在线设置中可以获得到最优参数的收敛保证——而神经网络无法提供这样的保证。新的LTS+CM算法在几个基准测试中与LTS+NN相比表现出明显优势：Sokoban（Boxoban）、The Witness和24-Sliding Tile Puzzle（STP）。

    Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a probability distribution over actions) and comes with a theoretical guarantee on the number of expansions before reaching a goal node, depending on the quality of the policy. This guarantee can be used as a loss function, which we call the LTS loss, to optimize neural networks representing the policy (LTS+NN). In this work we show that the neural network can be substituted with parameterized context models originating from the online compression literature (LTS+CM). We show that the LTS loss is convex under this new model, which allows for using standard convex optimization tools, and obtain convergence guarantees to the optimal parameters in an online setting for a given set of solution trajectories -- guarantees that cannot be provided for neural networks. The new LTS+CM algorithm compares favorably against LTS+NN on several benchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle (STP). The
    
[^18]: 一种用于正交约束下的非光滑组合优化的块坐标下降方法

    A Block Coordinate Descent Method for Nonsmooth Composite Optimization under Orthogonality Constraints. (arXiv:2304.03641v1 [math.OC])

    [http://arxiv.org/abs/2304.03641](http://arxiv.org/abs/2304.03641)

    本文提出了一种新的块坐标下降方法OBCD，用于解决具有正交约束的一般非光滑组合问题。 OBCD是一种可行的方法，具有低的计算复杂性，并且获得严格的收敛保证。

    

    具有正交约束的非光滑组合优化在统计学习和数据科学中有广泛的应用。由于其非凸性和非光滑性质，该问题通常很难求解。现有的解决方案受到以下一个或多个限制的限制：（i）它们是需要每次迭代高计算成本的全梯度方法；（ii）它们无法解决一般的非光滑组合问题；（iii）它们是不可行方法，并且只能在极限点处实现解的可行性；（iv）它们缺乏严格的收敛保证；（v）它们只能获得关键点的弱最优性。在本文中，我们提出了一种新的块坐标下降方法OBCD，用于解决正交约束下的一般非光滑组合问题。OBCD是一种可行的方法，具有低的计算复杂性。在每次迭代中，我们的算法会更新...

    Nonsmooth composite optimization with orthogonality constraints has a broad spectrum of applications in statistical learning and data science. However, this problem is generally challenging to solve due to its non-convex and non-smooth nature. Existing solutions are limited by one or more of the following restrictions: (i) they are full gradient methods that require high computational costs in each iteration; (ii) they are not capable of solving general nonsmooth composite problems; (iii) they are infeasible methods and can only achieve the feasibility of the solution at the limit point; (iv) they lack rigorous convergence guarantees; (v) they only obtain weak optimality of critical points. In this paper, we propose \textit{\textbf{OBCD}}, a new Block Coordinate Descent method for solving general nonsmooth composite problems under Orthogonality constraints. \textit{\textbf{OBCD}} is a feasible method with low computation complexity footprints. In each iteration, our algorithm updates $
    
[^19]: 一种在不可避免风险存在下进行复发事件因果分析的贝叶斯框架

    A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk. (arXiv:2304.03247v1 [stat.ME])

    [http://arxiv.org/abs/2304.03247](http://arxiv.org/abs/2304.03247)

    论文提出了一种贝叶斯框架，针对错位处理问题，将其视为治疗切换问题，并通过概率模型解决了复增和末事件偏差的问题。

    

    生物医学统计学中对复发事件率的观测研究很常见。通常的目标是在规定的随访时间窗口内，估计在一个明确定义的目标人群中两种治疗方法的事件率差异。使用观测性索赔数据进行估计是具有挑战性的，因为在目标人群的成员资格方面定义时，很少在资格确认时准确分配治疗方式。目前的解决方案通常是错位处理，比如基于后续分配，在资格确认时分配治疗方式，这会将先前的事件率错误地归因于治疗-从而产生不可避免的风险偏差。即使资格和治疗已经对齐，终止事件过程（例如死亡）也经常停止感兴趣的复发事件过程。同样，这两个过程也受到审查的影响，因此在整个随访时间窗口内不能观察到事件。我们的方法将错位处理转化为治疗切换问题：一些患者在整个随访时间窗口内坚持一个特定的治疗策略，另一些患者在这个时间窗口内经历治疗策略的切换。我们提出了一个概率模型，其中包括两个基本元素：通过一个合理的时刻切换模型，正确地建模治疗之间的切换和不可避免风险，通过将非观察事件模型化为复发事件模型，解决了复增和末事件偏差的问题。

    Observational studies of recurrent event rates are common in biomedical statistics. Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window. Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility. Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias. Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest. Both processes are also censored so that events are not observed over the entire followup window. Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on
    
[^20]: SimTS:重新思考时间序列预测的对比表示学习

    SimTS: Rethinking Contrastive Representation Learning for Time Series Forecasting. (arXiv:2303.18205v1 [cs.LG])

    [http://arxiv.org/abs/2303.18205](http://arxiv.org/abs/2303.18205)

    本文提出了一种不依赖于负对或特定时间序列特征假设的简单表示学习方法SimTS，通过学习在潜在空间中从过去预测未来来改进时间序列预测，并在多个数据集上表现出具有竞争力的性能。

    

    对比学习方法在图像或时间序列分类中展现出了强大的学习意义的表现。但是，这些方法对于时间序列预测的效果不够明显，因为对实例鉴别的优化不能直接应用于从历史上下文中预测未来状态。此外，目前技术中正负示例对的构建强烈依赖于特定的时间序列特征，限制了其在各种类型的时间序列数据中的普适性。为解决这些局限性，我们提出了SimTS，这是一种简单的表示学习方法，通过学习在潜在空间中从过去预测未来来改进时间序列预测。SimTS不依赖于负对或特定时间序列特征的假设。我们在几个基准时间序列预测数据集上进行了大量实验，结果表明SimTS取得了竞争性的性能。

    Contrastive learning methods have shown an impressive ability to learn meaningful representations for image or time series classification. However, these methods are less effective for time series forecasting, as optimization of instance discrimination is not directly applicable to predicting the future state from the history context. Moreover, the construction of positive and negative pairs in current technologies strongly relies on specific time series characteristics, restricting their generalization across diverse types of time series data. To address these limitations, we propose SimTS, a simple representation learning approach for improving time series forecasting by learning to predict the future from the past in the latent space. SimTS does not rely on negative pairs or specific assumptions about the characteristics of the particular time series. Our extensive experiments on several benchmark time series forecasting datasets show that SimTS achieves competitive performance comp
    

