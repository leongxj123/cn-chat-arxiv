# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ChatDBG: An AI-Powered Debugging Assistant](https://arxiv.org/abs/2403.16354) | ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。 |
| [^2] | [A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services](https://arxiv.org/abs/2403.15780) | 本研究介绍了一种在共享微移动服务运营与控制中实现性能优化和算法公平性平衡的前沿调查，利用Q-Learning算法确保方法稳健，能够实现各种站点类别之间的公平结果。 |
| [^3] | [Protein Conformation Generation via Force-Guided SE(3) Diffusion Models](https://arxiv.org/abs/2403.14088) | 本文提出了一种力引导SE(3)扩散模型ConfDiff，用于蛋白质构象生成，通过结合力引导网络与基于数据的分数模型，实现了对蛋白质构象的准确生成。 |
| [^4] | [NTK-Guided Few-Shot Class Incremental Learning](https://arxiv.org/abs/2403.12486) | 本文通过NTK对FSCIL模型的指导，致力于在增量学习中实现卓越泛化，通过优化NTK收敛和降低泛化误差来确保最佳性能。 |
| [^5] | [MicroT: Low-Energy and Adaptive Models for MCUs](https://arxiv.org/abs/2403.08040) | MicroT是一个低能耗、多任务自适应模型框架，通过特征提取器和分类器的分离、模型优化和本地任务训练，在MCUs上实现了模型性能的提升和能耗的降低。 |
| [^6] | [Advantage-Aware Policy Optimization for Offline Reinforcement Learning](https://arxiv.org/abs/2403.07262) | 介绍了一种新的适应优势的策略优化（A2PO）方法，用于离线学习，能够解决多行为策略收集的约束冲突问题，有效避免过拟合问题。 |
| [^7] | [Generative Probabilistic Forecasting with Applications in Market Operations](https://arxiv.org/abs/2403.05743) | 提出了一种基于Wiener-Kallianpur创新表示的生成式概率预测方法，包括自编码器和新颖的深度学习算法，具有渐近最优性和结构收敛性质，适用于实时市场运营中的高动态和波动时间序列。 |
| [^8] | [OpenGraph: Towards Open Graph Foundation Models](https://arxiv.org/abs/2403.01121) | 该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。 |
| [^9] | [The Matrix: A Bayesian learning model for LLMs](https://arxiv.org/abs/2402.03175) | 本文介绍了一个贝叶斯学习模型，用于理解大型语言模型（LLMs）的行为。研究探索了LLMs的优化指标，并开发了一个新的基于预测下一个标记的模型。实验结果表明，LLMs的行为与贝叶斯学习一致，为上下文学习提供了新的见解。 |
| [^10] | [HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents QA](https://arxiv.org/abs/2402.01767) | HiQA是一个先进的多文档问答框架，使用分层的上下文增强和多路径检索机制，解决了大规模文档问答中的检索准确性问题，并在多文档环境中展示了最先进的性能。 |
| [^11] | [IGCN: Integrative Graph Convolutional Networks for Multi-modal Data](https://arxiv.org/abs/2401.17612) | IGCN是用于多模态数据的综合神经网络，通过综合分析多模态数据来获得更好的学习表示，并提高模型的可解释性。 |
| [^12] | [PICL: Physics Informed Contrastive Learning for Partial Differential Equations](https://arxiv.org/abs/2401.16327) | 这项工作开发了一种使用广义对比损失的对比预训练框架，通过利用物理信息改善了神经算子在多个偏微分方程中的泛化能力。 |
| [^13] | [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://arxiv.org/abs/2401.09340) | 本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。 |
| [^14] | [Incentivizing Exploration with Linear Contexts and Combinatorial Actions](https://arxiv.org/abs/2306.01990) | 研究在激励式赌博机探索中通过线性赌博机模型替代先验独立性条件，提高了高维动作空间下的激励探索效率和最优遗憾，同时改进了半赌博模型中关于初始数据收集的样本复杂度。 |
| [^15] | [Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction.](http://arxiv.org/abs/2401.11798) | 本论文研究了在交通预测中应用空间-时间图卷积网络和知识蒸馏的方法。知识蒸馏的思想能够实现在减少参数和保持准确性的同时提高执行效率。通过引入教师网络的空间-时间相关性，我们的方法能够使学生网络学习到复杂的交通模式。 |
| [^16] | [Audio Editing with Non-Rigid Text Prompts.](http://arxiv.org/abs/2310.12858) | 本文研究了使用非刚性文本编辑进行音频编辑的方法，并展示了其在保持输入音频一致性方面的优势。 |
| [^17] | [Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models.](http://arxiv.org/abs/2310.12000) | 这篇文章介绍了用于潜在高斯过程模型中的Vecchia-Laplace近似法的迭代方法，相比于传统的Cholesky分解方法，可以显著加快计算速度。 |
| [^18] | [Representation Learning for Sequential Volumetric Design Tasks.](http://arxiv.org/abs/2309.02583) | 本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。 |
| [^19] | [Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds.](http://arxiv.org/abs/2309.00380) | 本文提出了一种用于多模态数据的深度潜变量模型，并开发了更灵活的编码特征聚合方案，能够紧密地下界数据对数似然。 |
| [^20] | [Triggering Dark Showers with Conditional Dual Auto-Encoders.](http://arxiv.org/abs/2306.12955) | 该论文通过使用条件双自编码器，对探测器图像进行暗版强力信号新物理搜索，实现了对撞机新物理搜索的有效和通用工具，证明了AE具有出色的判别能力。 |
| [^21] | [OpenOOD v1.5: Enhanced Benchmark for Out-of-Distribution Detection.](http://arxiv.org/abs/2306.09301) | OpenOOD v1.5 是对前身的重大改进，将OCC检测方法的评估能力扩展到大规模数据集，调查了全光谱OCC检测，引入了在线排行榜和易于使用的评估器等新功能，并提供了深入的分析和实验结果的见解。 |
| [^22] | [On Computing Optimal Tree Ensembles.](http://arxiv.org/abs/2306.04423) | 该论文提出了两种新算法以计算旨在各种度量方面最优的决策树集合，并且引入了“证明树技术”来大大改进可处理性结果。 |
| [^23] | [GUARD: A Safe Reinforcement Learning Benchmark.](http://arxiv.org/abs/2305.13681) | GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。 |
| [^24] | [A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion.](http://arxiv.org/abs/2304.13940) | 本文提出了一种基于主导-最小化原则，通过低秩矩阵补全解决1比特矩阵补全问题的新方法，称为MMGN。通过应用高斯-牛顿方法，MMGN具有更快的速度和更准确的结果，同时还不太受到潜在矩阵尖锐度的影响。 |
| [^25] | [Interpretable statistical representations of neural population dynamics and geometry.](http://arxiv.org/abs/2304.03376) | 该论文提出了一种基于统计分布的几何深度学习框架，用于表示非线性动态系统的几何感知或几何无感知表示，以对已测量轨迹进行无偏比较。利用该方法，能够解释神经动力学的嵌入，在灵长类似任务中取得了最先进的准确性。 |
| [^26] | [Subsampling Suffices for Adaptive Data Analysis.](http://arxiv.org/abs/2302.08661) | 子采样是自适应数据分析中的关键方法，仅需基于随机子样本和少量比特输出的查询，即可保证代表性和泛化性。 |
| [^27] | [Structure-based Drug Design with Equivariant Diffusion Models.](http://arxiv.org/abs/2210.13695) | 该论文提出了一个基于结构的药物设计方法，使用了等变扩散模型DiffSBDD来生成具有亲和力和特异性的新型药物配体。实验结果表明DiffSBDD在生成具有竞争性对接得分的多样化药物样配体方面具有高效和有效的性能。 |
| [^28] | [Adaptive joint distribution learning.](http://arxiv.org/abs/2110.04829) | 该论文提出了一种自适应联合分布学习的框架，可以从大量数据点中估计低维、归一化和正的Radon-Nikodym导数模型，并在不同学习问题上取得了良好的结果。 |

# 详细

[^1]: ChatDBG: 一种基于人工智能的调试助手

    ChatDBG: An AI-Powered Debugging Assistant

    [https://arxiv.org/abs/2403.16354](https://arxiv.org/abs/2403.16354)

    ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。

    

    本文介绍了ChatDBG，这是第一个基于人工智能的调试助手。ChatDBG集成了大型语言模型(LLMs)，显著增强了传统调试器的功能和用户友好性。ChatDBG允许程序员与调试器进行协作对话，使他们能够提出关于程序状态的复杂问题，对崩溃或断言失败进行根本原因分析，并探索诸如“为什么x为空？”之类的开放性查询。为了处理这些查询，ChatDBG授予LLM自主权，通过发出命令来浏览堆栈和检查程序状态进行调试；然后报告其发现并将控制权交还给程序员。我们的ChatDBG原型与标准调试器集成，包括LLDB、GDB和WinDBG用于本地代码以及用于Python的Pdb。我们在各种代码集合上进行了评估，包括具有已知错误的C/C++代码和一套Python代码。

    arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
    
[^2]: 面向公平性的共享微移动服务运营与控制的强化学习方法

    A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services

    [https://arxiv.org/abs/2403.15780](https://arxiv.org/abs/2403.15780)

    本研究介绍了一种在共享微移动服务运营与控制中实现性能优化和算法公平性平衡的前沿调查，利用Q-Learning算法确保方法稳健，能够实现各种站点类别之间的公平结果。

    

    随着机器学习系统在各种应用领域变得日益普遍，包括那些直接涉及人类的领域，平等和算法公平性的必要性在人工智能界愈发突出。另一方面，在共享微移动系统的背景下，公平性导向方法的探索仍然有限。为填补这一空白，我们引入了一项探讨性研究，探讨了共享微移动服务运营与控制中性能优化与算法公平性之间的平衡。我们的研究运用强化学习中的Q-Learning算法，利用其收敛保证来确保我们提出的方法的稳健性。值得注意的是，我们的方法在不同站点类别（中心、边缘和远程）之间能够实现公平的结果，这是通过基尼系数来衡量的。

    arXiv:2403.15780v1 Announce Type: cross  Abstract: As Machine Learning systems become increasingly popular across diverse application domains, including those with direct human implications, the imperative of equity and algorithmic fairness has risen to prominence in the Artificial Intelligence community. On the other hand, in the context of Shared Micromobility Systems, the exploration of fairness-oriented approaches remains limited. Addressing this gap, we introduce a pioneering investigation into the balance between performance optimization and algorithmic fairness in the operation and control of Shared Micromobility Services. Our study leverages the Q-Learning algorithm in Reinforcement Learning, benefiting from its convergence guarantees to ensure the robustness of our proposed approach. Notably, our methodology stands out for its ability to achieve equitable outcomes, as measured by the Gini index, across different station categories--central, peripheral, and remote. Through stra
    
[^3]: 基于力引导SE(3)扩散模型的蛋白质构象生成

    Protein Conformation Generation via Force-Guided SE(3) Diffusion Models

    [https://arxiv.org/abs/2403.14088](https://arxiv.org/abs/2403.14088)

    本文提出了一种力引导SE(3)扩散模型ConfDiff，用于蛋白质构象生成，通过结合力引导网络与基于数据的分数模型，实现了对蛋白质构象的准确生成。

    

    蛋白质的构象景观对于理解复杂生物过程中的功能至关重要。传统基于物理的计算方法，如分子动力学（MD）模拟，存在稀有事件采样和长时间平衡问题，限制了它们在一般蛋白质系统中的应用。最近，深度生成建模技术，特别是扩散模型，已被应用于生成新颖的蛋白质构象。然而，现有的基于分数的扩散方法无法很好地结合重要的物理先验知识来指导生成过程，导致采样蛋白质构象与平衡分布之间存在较大偏差。本文提出了一种用于蛋白质构象生成的力引导SE(3)扩散模型ConfDiff，以克服这些限制。通过将力引导网络与一系列基于数据的分数模型相结合，ConfDiff能够实现对蛋白质构象的准确生成。

    arXiv:2403.14088v1 Announce Type: cross  Abstract: The conformational landscape of proteins is crucial to understanding their functionality in complex biological processes. Traditional physics-based computational methods, such as molecular dynamics (MD) simulations, suffer from rare event sampling and long equilibration time problems, hindering their applications in general protein systems. Recently, deep generative modeling techniques, especially diffusion models, have been employed to generate novel protein conformations. However, existing score-based diffusion methods cannot properly incorporate important physical prior knowledge to guide the generation process, causing large deviations in the sampled protein conformations from the equilibrium distribution. In this paper, to overcome these limitations, we propose a force-guided SE(3) diffusion model, ConfDiff, for protein conformation generation. By incorporating a force-guided network with a mixture of data-based score models, Conf
    
[^4]: 基于NTK引导的少样本类增量学习

    NTK-Guided Few-Shot Class Incremental Learning

    [https://arxiv.org/abs/2403.12486](https://arxiv.org/abs/2403.12486)

    本文通过NTK对FSCIL模型的指导，致力于在增量学习中实现卓越泛化，通过优化NTK收敛和降低泛化误差来确保最佳性能。

    

    尽管反遗忘FSCIL学习者在增量会话中表现出色，但他们往往更注重减少知识流失，而忽视了模型潜在获取知识的能力。本文通过神经切向核（NTK）的视角深入探讨了FSCIL模型泛化的基础。我们主要的设计重点在于确保最优NTK收敛和NTK相关的泛化误差，作为卓越泛化的理论基础。为了达到全局最优的NTK收敛，我们采用了一个植根于数学原理的元学习机制，指导扩展网络内的优化过程。此外，为了减少NTK相关的泛化误差，我们从基础层面开始，优化构成其泛化损失的相关因素。具体地，我们通过在基础会话上启动自监督预训练来塑造初始ne

    arXiv:2403.12486v1 Announce Type: cross  Abstract: While anti-amnesia FSCIL learners often excel in incremental sessions, they tend to prioritize mitigating knowledge attrition over harnessing the model's potential for knowledge acquisition. In this paper, we delve into the foundations of model generalization in FSCIL through the lens of the Neural Tangent Kernel (NTK). Our primary design focus revolves around ensuring optimal NTK convergence and NTK-related generalization error, serving as the theoretical bedrock for exceptional generalization. To attain globally optimal NTK convergence, we employ a meta-learning mechanism grounded in mathematical principles to guide the optimization process within an expanded network. Furthermore, to reduce the NTK-related generalization error, we commence from the foundational level, optimizing the relevant factors constituting its generalization loss. Specifically, we initiate self-supervised pre-training on the base session to shape the initial ne
    
[^5]: MicroT：用于MCUs的低能耗和自适应模型

    MicroT: Low-Energy and Adaptive Models for MCUs

    [https://arxiv.org/abs/2403.08040](https://arxiv.org/abs/2403.08040)

    MicroT是一个低能耗、多任务自适应模型框架，通过特征提取器和分类器的分离、模型优化和本地任务训练，在MCUs上实现了模型性能的提升和能耗的降低。

    

    我们提出了MicroT，这是一个面向资源受限的MCUs的低能耗、多任务自适应模型框架。我们将原始模型划分为特征提取器和分类器。特征提取器通过自监督知识蒸馏获得，并通过模型分割和联合训练进一步优化为部分模型和完整模型。然后将这些模型部署在MCUs上，增加并在本地任务上训练分类器，最终执行关节推理的阶段决策。在这个过程中，部分模型最初处理样本，如果置信度得分低于设定的阈值，完整模型将恢复并继续推理。我们在两个模型、三个数据集和两个MCU板上评估了MicroT。我们的实验评估表明，在处理多个本地任务时，MicroT有效地提高了模型性能并降低了能耗。与未经优化的特征提取器相比，MicroT

    arXiv:2403.08040v1 Announce Type: new  Abstract: We propose MicroT, a low-energy, multi-task adaptive model framework for resource-constrained MCUs. We divide the original model into a feature extractor and a classifier. The feature extractor is obtained through self-supervised knowledge distillation and further optimized into part and full models through model splitting and joint training. These models are then deployed on MCUs, with classifiers added and trained on local tasks, ultimately performing stage-decision for joint inference. In this process, the part model initially processes the sample, and if the confidence score falls below the set threshold, the full model will resume and continue the inference. We evaluate MicroT on two models, three datasets, and two MCU boards. Our experimental evaluation shows that MicroT effectively improves model performance and reduces energy consumption when dealing with multiple local tasks. Compared to the unoptimized feature extractor, MicroT
    
[^6]: 适应优势的策略优化用于离线强化学习

    Advantage-Aware Policy Optimization for Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.07262](https://arxiv.org/abs/2403.07262)

    介绍了一种新的适应优势的策略优化（A2PO）方法，用于离线学习，能够解决多行为策略收集的约束冲突问题，有效避免过拟合问题。

    

    离线强化学习致力于利用离线数据集来制定有效的智能体策略，而无需在线交互，通过在行为策略的支持下施加适当的保守约束来解决分布外问题。本文引入了一种新的适应优势的策略优化（A2PO）方法，以明确构建针对混合质量数据集的离线学习优势感知策略约束。

    arXiv:2403.07262v1 Announce Type: cross  Abstract: Offline Reinforcement Learning (RL) endeavors to leverage offline datasets to craft effective agent policy without online interaction, which imposes proper conservative constraints with the support of behavior policies to tackle the Out-Of-Distribution (OOD) problem. However, existing works often suffer from the constraint conflict issue when offline datasets are collected from multiple behavior policies, i.e., different behavior policies may exhibit inconsistent actions with distinct returns across the state space. To remedy this issue, recent Advantage-Weighted (AW) methods prioritize samples with high advantage values for agent training while inevitably leading to overfitting on these samples. In this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO) method to explicitly construct advantage-aware policy constraints for offline learning under mixed-quality datasets. Specifically, A2PO employs a Conditional Variat
    
[^7]: 具有市场运营应用的生成式概率预测

    Generative Probabilistic Forecasting with Applications in Market Operations

    [https://arxiv.org/abs/2403.05743](https://arxiv.org/abs/2403.05743)

    提出了一种基于Wiener-Kallianpur创新表示的生成式概率预测方法，包括自编码器和新颖的深度学习算法，具有渐近最优性和结构收敛性质，适用于实时市场运营中的高动态和波动时间序列。

    

    本文提出了一种新颖的生成式概率预测方法，该方法源自于非参数时间序列的Wiener-Kallianpur创新表示。在生成人工智能的范式下，所提出的预测架构包括一个自编码器，将非参数多变量随机过程转化为规范的创新序列，从中根据过去样本生成未来时间序列样本，条件是它们的概率分布取决于过去样本。提出了一种新的深度学习算法，将潜在过程限制为具有匹配自编码器输入-输出条件概率分布的独立同分布序列。建立了所提出的生成式预测方法的渐近最优性和结构收敛性质。该方法在实时市场运营中涉及高度动态和波动时间序列的三个应用方面。

    arXiv:2403.05743v1 Announce Type: cross  Abstract: This paper presents a novel generative probabilistic forecasting approach derived from the Wiener-Kallianpur innovation representation of nonparametric time series. Under the paradigm of generative artificial intelligence, the proposed forecasting architecture includes an autoencoder that transforms nonparametric multivariate random processes into canonical innovation sequences, from which future time series samples are generated according to their probability distributions conditioned on past samples. A novel deep-learning algorithm is proposed that constrains the latent process to be an independent and identically distributed sequence with matching autoencoder input-output conditional probability distributions. Asymptotic optimality and structural convergence properties of the proposed generative forecasting approach are established. Three applications involving highly dynamic and volatile time series in real-time market operations a
    
[^8]: OpenGraph: 迈向开放图基础模型

    OpenGraph: Towards Open Graph Foundation Models

    [https://arxiv.org/abs/2403.01121](https://arxiv.org/abs/2403.01121)

    该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。

    

    arXiv:2403.01121v1 公告类型: 跨交互   摘要: 图学习已成为解释和利用各领域的关系数据的不可或缺部分，从推荐系统到社交网络分析。在这种背景下，各种GNN已经成为编码图的结构信息的有希望的方法论，通过有效地捕捉图的潜在结构，这些GNN已经展示出在增强图学习任务性能方面的巨大潜力，例如链接预测和节点分类。然而，尽管取得了成功，一个显著的挑战仍然存在: 这些先进方法通常在将显著不同于训练实例的未见图数据泛化时遇到困难。在这项工作中，我们的目标是通过开发一个通用图基础模型来推进图学习范式。该模型旨在理解多样图数据中存在的复杂拓扑模式，使其在零-shot情况下表现出色。

    arXiv:2403.01121v1 Announce Type: cross  Abstract: Graph learning has become indispensable for interpreting and harnessing relational data in diverse fields, ranging from recommendation systems to social network analysis. In this context, a variety of GNNs have emerged as promising methodologies for encoding the structural information of graphs. By effectively capturing the graph's underlying structure, these GNNs have shown great potential in enhancing performance in graph learning tasks, such as link prediction and node classification. However, despite their successes, a significant challenge persists: these advanced methods often face difficulties in generalizing to unseen graph data that significantly differs from the training instances. In this work, our aim is to advance the graph learning paradigm by developing a general graph foundation model. This model is designed to understand the complex topological patterns present in diverse graph data, enabling it to excel in zero-shot g
    
[^9]: The Matrix: 一个用于LLMs的贝叶斯学习模型

    The Matrix: A Bayesian learning model for LLMs

    [https://arxiv.org/abs/2402.03175](https://arxiv.org/abs/2402.03175)

    本文介绍了一个贝叶斯学习模型，用于理解大型语言模型（LLMs）的行为。研究探索了LLMs的优化指标，并开发了一个新的基于预测下一个标记的模型。实验结果表明，LLMs的行为与贝叶斯学习一致，为上下文学习提供了新的见解。

    

    本文介绍了一个用于理解大型语言模型（LLMs）行为的贝叶斯学习模型。我们探索了基于预测下一个标记的LLM的优化指标，并开发了一个以此原则为基础的新型模型。我们的方法涉及构建一个由先验和多项式转移概率矩阵表示的理想生成文本模型，并研究LLMs如何逼近该矩阵。我们讨论了嵌入和多项式分布之间的映射的连续性，并提出了Dirichlet逼近定理来逼近任何先验。此外，我们演示了LLMs的文本生成如何与贝叶斯学习原理一致，并深入探讨了其在上下文学习中的影响，具体解释了为什么在更大的模型中出现了上下文学习，其中提示被视为需要更新的样本。我们的发现表明，LLMs的行为与贝叶斯学习一致，提供了新的见解。

    In this paper, we introduce a Bayesian learning model to understand the behavior of Large Language Models (LLMs). We explore the optimization metric of LLMs, which is based on predicting the next token, and develop a novel model grounded in this principle. Our approach involves constructing an ideal generative text model represented by a multinomial transition probability matrix with a prior, and we examine how LLMs approximate this matrix. We discuss the continuity of the mapping between embeddings and multinomial distributions, and present the Dirichlet approximation theorem to approximate any prior. Additionally, we demonstrate how text generation by LLMs aligns with Bayesian learning principles and delve into the implications for in-context learning, specifically explaining why in-context learning emerges in larger models where prompts are considered as samples to be updated. Our findings indicate that the behavior of LLMs is consistent with Bayesian Learning, offering new insights
    
[^10]: HiQA：一种用于大规模文档问答的分层上下文增强的RAG模型

    HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents QA

    [https://arxiv.org/abs/2402.01767](https://arxiv.org/abs/2402.01767)

    HiQA是一个先进的多文档问答框架，使用分层的上下文增强和多路径检索机制，解决了大规模文档问答中的检索准确性问题，并在多文档环境中展示了最先进的性能。

    

    随着利用外部工具的语言模型代理迅速发展，使用补充文档和检索增强生成（RAG）方法的问答（QA）方法学取得了重要进展。这种进步提高了语言模型的回答质量，并减轻了幻觉的出现。然而，当面临大量无法区分的文档时，这些方法在检索准确性方面表现有限，给实际应用带来了显著挑战。针对这些新兴的挑战，我们提出了HiQA，这是一个先进的多文档问答（MDQA）框架，将级联的元数据整合到内容中，同时具备多路径检索机制。我们还发布了一个名为MasQA的基准来评估和研究MDQA。最后，HiQA在多文档环境中展示了最先进的性能。

    As language model agents leveraging external tools rapidly evolve, significant progress has been made in question-answering(QA) methodologies utilizing supplementary documents and the Retrieval-Augmented Generation (RAG) approach. This advancement has improved the response quality of language models and alleviates the appearance of hallucination. However, these methods exhibit limited retrieval accuracy when faced with massive indistinguishable documents, presenting notable challenges in their practical application. In response to these emerging challenges, we present HiQA, an advanced framework for multi-document question-answering (MDQA) that integrates cascading metadata into content as well as a multi-route retrieval mechanism. We also release a benchmark called MasQA to evaluate and research in MDQA. Finally, HiQA demonstrates the state-of-the-art performance in multi-document environments.
    
[^11]: IGCN：用于多模态数据的综合图卷积网络

    IGCN: Integrative Graph Convolutional Networks for Multi-modal Data

    [https://arxiv.org/abs/2401.17612](https://arxiv.org/abs/2401.17612)

    IGCN是用于多模态数据的综合神经网络，通过综合分析多模态数据来获得更好的学习表示，并提高模型的可解释性。

    

    最近图神经网络（GNN）的进展已经导致了图数据建模的显著增长，用于包含各种类型节点和边的多模态数据。尽管最近已经开发了一些用于网络结构化数据的综合预测解决方案，但这些方法存在一些限制。对于涉及多模态数据的节点分类任务，某些数据模态在预测一个类时表现更好，而其他数据模态可能在预测不同类别时表现出色。因此，为了获得更好的学习表示，需要先进的计算方法来进行多模态数据的综合分析。此外，现有的综合工具缺乏对其特定预测背后原理的全面和连贯理解，使其无法用于提高模型的可解释性。为了解决这些限制，我们引入了一种新的用于多模态数据网络的综合神经网络方法，名为综合图卷积网络（IGCN）。

    Recent advances in Graph Neural Networks (GNN) have led to a considerable growth in graph data modeling for multi-modal data which contains various types of nodes and edges. Although some integrative prediction solutions have been developed recently for network-structured data, these methods have some restrictions. For a node classification task involving multi-modal data, certain data modalities may perform better when predicting one class, while others might excel in predicting a different class. Thus, to obtain a better learning representation, advanced computational methodologies are required for the integrative analysis of multi-modal data. Moreover, existing integrative tools lack a comprehensive and cohesive understanding of the rationale behind their specific predictions, making them unsuitable for enhancing model interpretability. Addressing these restrictions, we introduce a novel integrative neural network approach for multi-modal data networks, named Integrative Graph Convo
    
[^12]: PICL: 物理信息对比学习用于偏微分方程

    PICL: Physics Informed Contrastive Learning for Partial Differential Equations

    [https://arxiv.org/abs/2401.16327](https://arxiv.org/abs/2401.16327)

    这项工作开发了一种使用广义对比损失的对比预训练框架，通过利用物理信息改善了神经算子在多个偏微分方程中的泛化能力。

    

    最近，神经算子作为偏微分方程（PDE）替代模型逐渐受到关注。学习解决方案函数而不是函数本身已被证明是一种强大的方法，可快速准确地求解复杂的PDE。尽管在广泛的代理建模任务中对神经算子的性能进行了许多研究，但这些工作通常是逐个方程评估性能。在本研究中，我们开发了一种新颖的对比预训练框架，利用广义对比损失，可以同时改善神经算子在多个控制方程中的泛化能力。控制方程系数用于衡量系统之间的真实相似性。物理信息系统演化和潜在空间模型输出的结合被锚定到输入数据中，并用于我们的距离函数。我们发现，物理信息对比预训练可以提高傅立叶神经算子的准确性和泛化能力。

    Neural operators have recently grown in popularity as Partial Differential Equation (PDEs) surrogate models. Learning solution functionals, rather than functions, has proven to be a powerful approach to calculate fast, accurate solutions to complex PDEs. While much work has been done evaluating neural operator performance on a wide variety of surrogate modeling tasks, these works normally evaluate performance on a single equation at a time. In this work, we develop a novel contrastive pretraining framework utilizing Generalized Contrastive Loss that improves neural operator generalization across multiple governing equations simultaneously. Governing equation coefficients are used to measure ground-truth similarity between systems. A combination of physics-informed system evolution and latent-space model output are anchored to input data and used in our distance function. We find that physics-informed contrastive pretraining improves both accuracy and generalization for the Fourier Neur
    
[^13]: SceneVerse：为基于场景的场景理解扩展3D视觉-语言学习

    SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding

    [https://arxiv.org/abs/2401.09340](https://arxiv.org/abs/2401.09340)

    本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。

    

    3D视觉-语言对齐，即将语言与3D物理环境对齐，是发展具身体能力的智能体的基石。与2D领域最近的进展相比，将语言与3D场景对齐面临着几个重要挑战：（i）3D场景固有复杂性，由于多样的物体配置、丰富的属性和错综复杂的关系；（ii）支持基于场景学习的配对3D视觉-语言数据的稀缺性；以及（iii）缺乏从基于场景的3D数据中提炼知识的统一学习框架。在这项工作中，我们旨在通过系统地扩展室内环境中的3D视觉-语言学习，从而解决3D视觉-语言领域中的这三大挑战。我们介绍首个百万规模的3D视觉-语言数据集SceneVerse，包含约68K个3D室内场景，包括250万个视觉语言

    arXiv:2401.09340v2 Announce Type: replace-cross  Abstract: 3D vision-language grounding, which focuses on aligning language with the 3D physical environment, stands as a cornerstone in the development of embodied agents. In comparison to recent advancements in the 2D domain, grounding language in 3D scenes faces several significant challenges: (i) the inherent complexity of 3D scenes due to the diverse object configurations, their rich attributes, and intricate relationships; (ii) the scarcity of paired 3D vision-language data to support grounded learning; and (iii) the absence of a unified learning framework to distill knowledge from grounded 3D data. In this work, we aim to address these three major challenges in 3D vision-language by examining the potential of systematically upscaling 3D vision-language learning in indoor environments. We introduce the first million-scale 3D vision-language dataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising 2.5M vision-langu
    
[^14]: 通过线性上下文和组合动作激励探索

    Incentivizing Exploration with Linear Contexts and Combinatorial Actions

    [https://arxiv.org/abs/2306.01990](https://arxiv.org/abs/2306.01990)

    研究在激励式赌博机探索中通过线性赌博机模型替代先验独立性条件，提高了高维动作空间下的激励探索效率和最优遗憾，同时改进了半赌博模型中关于初始数据收集的样本复杂度。

    

    我们推进了激励式赌博机探索的研究，其中手臂选择被视为推荐，并且要求是贝叶斯激励兼容的。最近的工作表明，在满足一定独立性假设后，经过足够的初始样本收集，流行的汤普森抽样算法变得激励兼容。我们为线性赌博机提供了这个结果的类比，其中先验的独立性被自然的凸性条件取代。这打开了在高维动作空间中高效和遗憾最优的激励探索的可能性。在半赌博模型中，我们还改进了用于初始数据收集的前汤普森抽样阶段的样本复杂度。

    arXiv:2306.01990v2 Announce Type: replace-cross  Abstract: We advance the study of incentivized bandit exploration, in which arm choices are viewed as recommendations and are required to be Bayesian incentive compatible. Recent work has shown under certain independence assumptions that after collecting enough initial samples, the popular Thompson sampling algorithm becomes incentive compatible. We give an analog of this result for linear bandits, where the independence of the prior is replaced by a natural convexity condition. This opens up the possibility of efficient and regret-optimal incentivized exploration in high-dimensional action spaces. In the semibandit model, we also improve the sample complexity for the pre-Thompson sampling phase of initial data collection.
    
[^15]: 空间-时间图卷积网络在交通预测上的知识蒸馏

    Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction. (arXiv:2401.11798v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11798](http://arxiv.org/abs/2401.11798)

    本论文研究了在交通预测中应用空间-时间图卷积网络和知识蒸馏的方法。知识蒸馏的思想能够实现在减少参数和保持准确性的同时提高执行效率。通过引入教师网络的空间-时间相关性，我们的方法能够使学生网络学习到复杂的交通模式。

    

    高效实时交通预测对减少交通时间至关重要。为了预测交通状况，我们采用了空间-时间图神经网络（ST-GNN）将实时交通数据建模为时间图。尽管ST-GNN具有强大的能力，但在为实际交通数据进行高效实时预测时经常面临挑战。鉴于实时数据动态性的重要性，我们采用知识蒸馏（KD）作为解决方案，以提高ST-GNN在交通预测中的执行时间。本文介绍了一个成本函数，旨在使用复杂网络（教师）的蒸馏数据来训练具有较少参数的网络（学生），同时保持其准确性接近教师的准确性。我们使用知识蒸馏，将教师网络的空间-时间相关性融入学生网络，使学生能够学习到教师感知的复杂模式。然而，面临一个挑战。

    Efficient real-time traffic prediction is crucial for reducing transportation time. To predict traffic conditions, we employ a spatio-temporal graph neural network (ST-GNN) to model our real-time traffic data as temporal graphs. Despite its capabilities, it often encounters challenges in delivering efficient real-time predictions for real-world traffic data. Recognizing the significance of timely prediction due to the dynamic nature of real-time data, we employ knowledge distillation (KD) as a solution to enhance the execution time of ST-GNNs for traffic prediction. In this paper, We introduce a cost function designed to train a network with fewer parameters (the student) using distilled data from a complex network (the teacher) while maintaining its accuracy close to that of the teacher. We use knowledge distillation, incorporating spatial-temporal correlations from the teacher network to enable the student to learn the complex patterns perceived by the teacher. However, a challenge a
    
[^16]: 非刚性文本提示的音频编辑

    Audio Editing with Non-Rigid Text Prompts. (arXiv:2310.12858v1 [cs.SD])

    [http://arxiv.org/abs/2310.12858](http://arxiv.org/abs/2310.12858)

    本文研究了使用非刚性文本编辑进行音频编辑的方法，并展示了其在保持输入音频一致性方面的优势。

    

    本文探讨了使用非刚性文本编辑进行音频编辑。我们展示了所提出的编辑流程能够创建与输入音频保持一致的音频编辑结果。我们探索了能够进行添加、风格转换和修复的文本提示。我们定量和定性地证明了这些编辑能够优于最近发布的文本提示音频生成模型Audio-LDM的结果。对结果的定性检查表明，我们的方法给出了更加保持输入音频原始起始和结束的编辑结果。

    In this paper, we explore audio-editing with non-rigid text edits. We show that the proposed editing pipeline is able to create audio edits that remain faithful to the input audio. We explore text prompts that perform addition, style transfer, and in-painting. We quantitatively and qualitatively show that the edits are able to obtain results which outperform Audio-LDM, a recently released text-prompted audio generation model. Qualitative inspection of the results points out that the edits given by our approach remain more faithful to the input audio in terms of keeping the original onsets and offsets of the audio events.
    
[^17]: Vecchia-Laplace近似法在潜在高斯过程模型中的迭代方法

    Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models. (arXiv:2310.12000v1 [stat.ME])

    [http://arxiv.org/abs/2310.12000](http://arxiv.org/abs/2310.12000)

    这篇文章介绍了用于潜在高斯过程模型中的Vecchia-Laplace近似法的迭代方法，相比于传统的Cholesky分解方法，可以显著加快计算速度。

    

    潜在高斯过程（GP）模型是灵活的概率非参数函数模型。Vecchia近似是用于克服大数据计算瓶颈的准确近似方法，Laplace近似是一种快速方法，可以近似非高斯似然函数的边缘似然和后验预测分布，并具有渐近收敛保证。然而，当与直接求解方法（如Cholesky分解）结合使用时，Vecchia-Laplace近似的计算复杂度增长超线性地随样本大小增加。因此，与Vecchia-Laplace近似计算相关的运算在通常情况下是最准确的大型数据集时会变得非常缓慢。在本文中，我们提出了几种用于Vecchia-Laplace近似推断的迭代方法，相比于基于Cholesky的计算，可以大大加快计算速度。我们对我们的方法进行了分析。

    Latent Gaussian process (GP) models are flexible probabilistic non-parametric function models. Vecchia approximations are accurate approximations for GPs to overcome computational bottlenecks for large data, and the Laplace approximation is a fast method with asymptotic convergence guarantees to approximate marginal likelihoods and posterior predictive distributions for non-Gaussian likelihoods. Unfortunately, the computational complexity of combined Vecchia-Laplace approximations grows faster than linearly in the sample size when used in combination with direct solver methods such as the Cholesky decomposition. Computations with Vecchia-Laplace approximations thus become prohibitively slow precisely when the approximations are usually the most accurate, i.e., on large data sets. In this article, we present several iterative methods for inference with Vecchia-Laplace approximations which make computations considerably faster compared to Cholesky-based calculations. We analyze our propo
    
[^18]: 顺序体积设计任务的表示学习

    Representation Learning for Sequential Volumetric Design Tasks. (arXiv:2309.02583v1 [cs.LG])

    [http://arxiv.org/abs/2309.02583](http://arxiv.org/abs/2309.02583)

    本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。

    

    体积设计，也称为质量设计，是专业建筑设计中的第一步关键性任务，具有顺序性。由于体积设计过程复杂，顺序化设计过程中包含了对设计师有价值的信息。许多努力已经被投入到自动生成合理的体积设计上，但生成的设计解决方案的质量存在差异，并且评估一个设计解决方案要么需要一套过于全面的度量标准，要么需要昂贵的人力专业知识。而之前的方法主要关注学习最终设计，而不是顺序设计任务，我们提出利用专家或高性能设计序列的设计知识，并使用基于transformer的模型提取有用的表示。然后，我们提出利用所学的表示在关键的下游应用中，如设计偏好评估和程序化设计生成。我们开发了prefer

    Volumetric design, also called massing design, is the first and critical step in professional building design which is sequential in nature. As the volumetric design process is complex, the underlying sequential design process encodes valuable information for designers. Many efforts have been made to automatically generate reasonable volumetric designs, but the quality of the generated design solutions varies, and evaluating a design solution requires either a prohibitively comprehensive set of metrics or expensive human expertise. While previous approaches focused on learning only the final design instead of sequential design tasks, we propose to encode the design knowledge from a collection of expert or high-performing design sequences and extract useful representations using transformer-based models. Later we propose to utilize the learned representations for crucial downstream applications such as design preference evaluation and procedural design generation. We develop the prefere
    
[^19]: 用排序不变的编码器和更紧的变分边界学习多模态生成模型

    Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds. (arXiv:2309.00380v1 [stat.ML])

    [http://arxiv.org/abs/2309.00380](http://arxiv.org/abs/2309.00380)

    本文提出了一种用于多模态数据的深度潜变量模型，并开发了更灵活的编码特征聚合方案，能够紧密地下界数据对数似然。

    

    设计用于多模态数据的深度潜变量模型一直是机器学习研究中的一个重要主题。多模态变分自编码器 (VAE) 是一种常用的生成模型类别，它学习能够共同解释多种模态的潜在表示。各种客观函数已被提出用于这样的模型，往往以多模态数据对数似然的下界以及信息论方面的考虑为动机。为了对不同模态子集进行编码，我们经常使用并展示了产品型专家 (PoE) 或者混合型专家 (MoE) 聚合方案，这些方案在生成质量或者多模态一致性等方面具有不同的权衡。在本研究中，我们考虑了一个能够紧密地下界数据对数似然的变分边界。我们通过将不同模态的编码特征组合起来，开发了更灵活的聚合方案，这些方案推广了 PoE 或者 MoE 方法。

    Devising deep latent variable models for multi-modal data has been a long-standing theme in machine learning research. Multi-modal Variational Autoencoders (VAEs) have been a popular generative model class that learns latent representations which jointly explain multiple modalities. Various objective functions for such models have been suggested, often motivated as lower bounds on the multi-modal data log-likelihood or from information-theoretic considerations. In order to encode latent variables from different modality subsets, Product-of-Experts (PoE) or Mixture-of-Experts (MoE) aggregation schemes have been routinely used and shown to yield different trade-offs, for instance, regarding their generative quality or consistency across multiple modalities. In this work, we consider a variational bound that can tightly lower bound the data log-likelihood. We develop more flexible aggregation schemes that generalise PoE or MoE approaches by combining encoded features from different modali
    
[^20]: 条件双自编码器触发暗淋浴

    Triggering Dark Showers with Conditional Dual Auto-Encoders. (arXiv:2306.12955v1 [hep-ex])

    [http://arxiv.org/abs/2306.12955](http://arxiv.org/abs/2306.12955)

    该论文通过使用条件双自编码器，对探测器图像进行暗版强力信号新物理搜索，实现了对撞机新物理搜索的有效和通用工具，证明了AE具有出色的判别能力。

    

    自编码器(AEs)有潜力成为对撞机新物理搜索的有效和通用工具，需要很少或不需要模型依赖的假设。新的理论物理信号可以作为与通常期望用来描述整个数据集的已知背景过程偏离的异常值来考虑。本文提出了一种用AE定义判定事件物理本质的准则的异常检测(AD)方法。在这项工作中，我们使用原始探测器图像进行AD搜索，对于无法利用任何基于物理的预处理或对信号的假设的大而稀疏的数据，进行暗版强力的表现形式的搜索。我们提出了一种可通过条件学习紧凑潜在空间的双编码器设计。在多个AD指标的背景下，我们提出了相比竞争基线和先前方法的明显改进。这是第一次展示AE具有出色的判别能力。

    Auto-encoders (AEs) have the potential to be effective and generic tools for new physics searches at colliders, requiring little to no model-dependent assumptions. New hypothetical physics signals can be considered anomalies that deviate from the well-known background processes generally expected to describe the whole dataset. We present a search formulated as an anomaly detection (AD) problem, using an AE to define a criterion to decide about the physics nature of an event. In this work, we perform an AD search for manifestations of a dark version of strong force using raw detector images, which are large and very sparse, without leveraging any physics-based pre-processing or assumption on the signals. We propose a dual-encoder design which can learn a compact latent space through conditioning. In the context of multiple AD metrics, we present a clear improvement over competitive baselines and prior approaches. It is the first time that an AE is shown to exhibit excellent discriminati
    
[^21]: OpenOOD v1.5：增强的OCC（Out-of-Distribution Detection）基准测试

    OpenOOD v1.5: Enhanced Benchmark for Out-of-Distribution Detection. (arXiv:2306.09301v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09301](http://arxiv.org/abs/2306.09301)

    OpenOOD v1.5 是对前身的重大改进，将OCC检测方法的评估能力扩展到大规模数据集，调查了全光谱OCC检测，引入了在线排行榜和易于使用的评估器等新功能，并提供了深入的分析和实验结果的见解。

    

    OCC检测对于开放世界智能系统的可靠运行至关重要。虽然出现了越来越多的OCC检测方法，但评估不一致性仍然存在挑战，难以跟踪该领域的进展。本文介绍了OpenOOD v1.5，这是对前身的重大改进，确保OCC检测方法的准确、标准化和用户友好的评估。值得注意的是，OpenOOD v1.5将其评估能力扩展到大规模数据集，如ImageNet。此外，它还调查了全光谱OCC检测，引入了在线排行榜和易于使用的评估器等新功能。该工作还提供了深入的分析和综合实验结果的见解，从而丰富了知识库。

    Out-of-Distribution (OOD) detection is critical for the reliable operation of open-world intelligent systems. Despite the emergence of an increasing number of OOD detection methods, the evaluation inconsistencies present challenges for tracking the progress in this field. OpenOOD v1 initiated the unification of the OOD detection evaluation but faced limitations in scalability and usability. In response, this paper presents OpenOOD v1.5, a significant improvement from its predecessor that ensures accurate, standardized, and user-friendly evaluation of OOD detection methodologies. Notably, OpenOOD v1.5 extends its evaluation capabilities to large-scale datasets such as ImageNet, investigates full-spectrum OOD detection which is important yet underexplored, and introduces new features including an online leaderboard and an easy-to-use evaluator. This work also contributes in-depth analysis and insights derived from comprehensive experimental results, thereby enriching the knowledge pool o
    
[^22]: 计算最优树集的方法

    On Computing Optimal Tree Ensembles. (arXiv:2306.04423v1 [cs.LG])

    [http://arxiv.org/abs/2306.04423](http://arxiv.org/abs/2306.04423)

    该论文提出了两种新算法以计算旨在各种度量方面最优的决策树集合，并且引入了“证明树技术”来大大改进可处理性结果。

    

    随机森林和决策树集合是分类和回归的广泛应用方法。最近的算法进展允许计算旨在各种度量方面（如大小或深度）最优的决策树。我们不知道有关树集合的此类研究，并旨在为该领域做出贡献。主要的是，我们提供了两种新算法和相应的下限。首先，我们能够转移和大大改进决策树的可处理性结果，获得一个 $(6\delta D S)^S \cdot poly$-time 算法，其中 $S$ 是树集合中割数，$D$ 是最大域大小，$\delta$ 是两个示例之间存在不同特征的最大数量。为了达到这个目的，我们引入了证明树技术，这似乎对实践也很有前途。其次，我们表明，动态规划对于决策树已经取得了成功，而对于树集合也可能是可行的，提供了一个 $\ell^n \cdot poly$-t。

    Random forests and, more generally, (decision\nobreakdash-)tree ensembles are widely used methods for classification and regression. Recent algorithmic advances allow to compute decision trees that are optimal for various measures such as their size or depth. We are not aware of such research for tree ensembles and aim to contribute to this area. Mainly, we provide two novel algorithms and corresponding lower bounds. First, we are able to carry over and substantially improve on tractability results for decision trees, obtaining a $(6\delta D S)^S \cdot poly$-time algorithm, where $S$ is the number of cuts in the tree ensemble, $D$ the largest domain size, and $\delta$ is the largest number of features in which two examples differ. To achieve this, we introduce the witness-tree technique which also seems promising for practice. Second, we show that dynamic programming, which has been successful for decision trees, may also be viable for tree ensembles, providing an $\ell^n \cdot poly$-t
    
[^23]: GUARD: 一个安全强化学习基准测试平台

    GUARD: A Safe Reinforcement Learning Benchmark. (arXiv:2305.13681v1 [cs.LG])

    [http://arxiv.org/abs/2305.13681](http://arxiv.org/abs/2305.13681)

    GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。

    

    由于试错的性质，将RL算法应用于安全关键的现实应用（例如自动驾驶、人机交互、机器人操作等）通常是具有挑战性的，因为这些错误是不可容忍的。最近，安全RL（即约束RL）已经在文献中迅速出现，其中代理在满足约束条件的同时，探索环境。由于算法和任务的多样性，比较现有的安全RL算法仍然很困难。为了填补这一空白，我们介绍了GUARD，一个广义统一安全强化学习开发基准测试平台。与现有基准相比，GUARD具有几个优点。首先，GUARD是一个广义基准测试平台，具有各种RL代理、任务和安全约束规范。其次，GUARD全面涵盖了最先进的安全RL算法，并具有自包含的实现。第三，GUARD在任务和算法方面具有高度的可自定义性。我们提供了状态下现有方法在GUARD上的基准测试结果。

    Due to the trial-and-error nature, it is typically challenging to apply RL algorithms to safety-critical real-world applications, such as autonomous driving, human-robot interaction, robot manipulation, etc, where such errors are not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly in the literature, in which the agents explore the environment while satisfying constraints. Due to the diversity of algorithms and tasks, it remains difficult to compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a Generalized Unified SAfe Reinforcement Learning Development Benchmark. GUARD has several advantages compared to existing benchmarks. First, GUARD is a generalized benchmark with a wide variety of RL agents, tasks, and safety constraint specifications. Second, GUARD comprehensively covers state-of-the-art safe RL algorithms with self-contained implementations. Third, GUARD is highly customizable in tasks and algorithms. We present a comparison of state
    
[^24]: 1比特矩阵补全的主导-最小化高斯牛顿方法

    A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion. (arXiv:2304.13940v1 [stat.ML])

    [http://arxiv.org/abs/2304.13940](http://arxiv.org/abs/2304.13940)

    本文提出了一种基于主导-最小化原则，通过低秩矩阵补全解决1比特矩阵补全问题的新方法，称为MMGN。通过应用高斯-牛顿方法，MMGN具有更快的速度和更准确的结果，同时还不太受到潜在矩阵尖锐度的影响。

    

    在1比特矩阵补全中，旨在从部分二进制观测值中估计潜在的低秩矩阵。我们提出了一种称为MMGN的1比特矩阵补全新方法。我们的方法基于主导-最小化（MM）原则，在我们的设置中产生一系列标准低秩矩阵补全问题。我们通过明确强制假定的低秩结构的分解方法解决这些子问题，然后应用高斯-牛顿方法。我们的数值研究和对实际数据的应用表明，MMGN输出的估计结果与现有方法相比较具有可比性且更准确、速度通常更快，并且对潜在矩阵的尖锐度不太敏感。

    In 1-bit matrix completion, the aim is to estimate an underlying low-rank matrix from a partial set of binary observations. We propose a novel method for 1-bit matrix completion called MMGN. Our method is based on the majorization-minimization (MM) principle, which yields a sequence of standard low-rank matrix completion problems in our setting. We solve each of these sub-problems by a factorization approach that explicitly enforces the assumed low-rank structure and then apply a Gauss-Newton method. Our numerical studies and application to a real-data example illustrate that MMGN outputs comparable if not more accurate estimates, is often significantly faster, and is less sensitive to the spikiness of the underlying matrix than existing methods.
    
[^25]: 神经群体动态和几何的可解释统计表示

    Interpretable statistical representations of neural population dynamics and geometry. (arXiv:2304.03376v1 [cs.LG])

    [http://arxiv.org/abs/2304.03376](http://arxiv.org/abs/2304.03376)

    该论文提出了一种基于统计分布的几何深度学习框架，用于表示非线性动态系统的几何感知或几何无感知表示，以对已测量轨迹进行无偏比较。利用该方法，能够解释神经动力学的嵌入，在灵长类似任务中取得了最先进的准确性。

    

    在各种任务中，神经元群体的动态通常在低维流形上演化。然而，区分几何和动态对编码相关行为变量的贡献仍然具有挑战性。在这里，我们引入了一种基于局部相轨特征的统计分布的非线性动态系统的几何深度学习框架，用于表示。我们的方法提供了对几何感知或几何无感知表示，以对已测量轨迹进行无偏比较。我们证明，我们的统计表示可以横跨神经网络实例进行推广，以区分计算机制，在具有几何对应的灵长类似任务中解释嵌入神经动力学，并开发具有最先进准确性的解码算法。我们的结果强调了使用内在流形结构优于时间信息的重要性。

    The dynamics of neuron populations during diverse tasks often evolve on low-dimensional manifolds. However, it remains challenging to discern the contributions of geometry and dynamics for encoding relevant behavioural variables. Here, we introduce an unsupervised geometric deep learning framework for representing non-linear dynamical systems based on statistical distributions of local phase portrait features. Our method provides robust geometry-aware or geometry-agnostic representations for the unbiased comparison of dynamics based on measured trajectories. We demonstrate that our statistical representation can generalise across neural network instances to discriminate computational mechanisms, obtain interpretable embeddings of neural dynamics in a primate reaching task with geometric correspondence to hand kinematics, and develop a decoding algorithm with state-of-the-art accuracy. Our results highlight the importance of using the intrinsic manifold structure over temporal informati
    
[^26]: 自适应数据分析中的子采样足够

    Subsampling Suffices for Adaptive Data Analysis. (arXiv:2302.08661v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08661](http://arxiv.org/abs/2302.08661)

    子采样是自适应数据分析中的关键方法，仅需基于随机子样本和少量比特输出的查询，即可保证代表性和泛化性。

    

    确保对数据集的分析代表整个样本总体是统计学中的核心问题之一。大多数经典技术假设数据集与分析师的查询无关，并在多次、自适应选择的查询中失效。这个“自适应数据分析”问题在Dwork等人（STOC，2015）和Hardt和Ullman（FOCS，2014）的开创性工作中得到了形式化。我们确定了一个非常简单的假设集，使得即使在自适应选择的情况下，查询仍然具有代表性：唯一的要求是每个查询采用随机子样本作为输入并输出少量比特。这个结果表明，子采样中固有的噪音足以保证查询的响应具有泛化性。这种基于子采样的框架的简单性使其能够模拟之前研究所未涵盖的各种实际情境。

    Ensuring that analyses performed on a dataset are representative of the entire population is one of the central problems in statistics. Most classical techniques assume that the dataset is independent of the analyst's query and break down in the common setting where a dataset is reused for multiple, adaptively chosen, queries. This problem of \emph{adaptive data analysis} was formalized in the seminal works of Dwork et al. (STOC, 2015) and Hardt and Ullman (FOCS, 2014).  We identify a remarkably simple set of assumptions under which the queries will continue to be representative even when chosen adaptively: The only requirements are that each query takes as input a random subsample and outputs few bits. This result shows that the noise inherent in subsampling is sufficient to guarantee that query responses generalize. The simplicity of this subsampling-based framework allows it to model a variety of real-world scenarios not covered by prior work.  In addition to its simplicity, we demo
    
[^27]: 基于结构的药物设计与等变扩散模型

    Structure-based Drug Design with Equivariant Diffusion Models. (arXiv:2210.13695v2 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2210.13695](http://arxiv.org/abs/2210.13695)

    该论文提出了一个基于结构的药物设计方法，使用了等变扩散模型DiffSBDD来生成具有亲和力和特异性的新型药物配体。实验结果表明DiffSBDD在生成具有竞争性对接得分的多样化药物样配体方面具有高效和有效的性能。

    

    基于结构的药物设计（SBDD）旨在设计与预定的蛋白靶点具有高亲和力和特异性的小分子配体。本文将SBDD表述为一个三维条件生成问题，并提出了DiffSBDD，这是一个SE(3)-等变的三维条件扩散模型，可以在蛋白口袋的条件下生成新型配体。全面的基于计算机模拟的实验证明了DiffSBDD在生成具有具有竞争性对接得分的新颖和多样的药物样配体方面的效率和有效性。我们进一步探索了扩散框架在药物设计活动中更广泛任务的灵活性，例如即插即用的性质优化和从局部分子设计带有修补的任务。

    Structure-based drug design (SBDD) aims to design small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets. In this paper, we formulate SBDD as a 3D-conditional generation problem and present DiffSBDD, an SE(3)-equivariant 3D-conditional diffusion model that generates novel ligands conditioned on protein pockets. Comprehensive in silico experiments demonstrate the efficiency and effectiveness of DiffSBDD in generating novel and diverse drug-like ligands with competitive docking scores. We further explore the flexibility of the diffusion framework for a broader range of tasks in drug design campaigns, such as off-the-shelf property optimization and partial molecular design with inpainting.
    
[^28]: 自适应联合分布学习

    Adaptive joint distribution learning. (arXiv:2110.04829v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.04829](http://arxiv.org/abs/2110.04829)

    该论文提出了一种自适应联合分布学习的框架，可以从大量数据点中估计低维、归一化和正的Radon-Nikodym导数模型，并在不同学习问题上取得了良好的结果。

    

    我们开发了一个新的框架，用于将联合概率分布嵌入张量积再生核希尔伯特空间（RKHS）中。我们的框架可以容纳一个低维、归一化和正的Radon-Nikodym导数模型，该模型可以从多达数百万个数据点的样本大小中进行估计，减轻了RKHS建模的固有限制。我们的方法自然产生了定义良好的归一化和正的条件分布。嵌入计算速度快且适用于从预测到分类的各种学习问题。我们的理论结果得到了有益的数值结果的支持。

    We develop a new framework for embedding joint probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). Our framework accommodates a low-dimensional, normalized and positive model of a Radon-Nikodym derivative, which we estimate from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and accommodates learning problems ranging from prediction to classification. Our theoretical findings are supplemented by favorable numerical results.
    

