# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Conditioning non-linear and infinite-dimensional diffusion processes](https://rss.arxiv.org/abs/2402.01434) | 本文探索了在无穷维空间中对非线性过程进行条件约束的方法，并应用于进化生物学中的生物形态时间序列分析。 |
| [^2] | [Social Dynamics of Consumer Response: A Unified Framework Integrating Statistical Physics and Marketing Dynamics](https://arxiv.org/abs/2404.02175) | 使用统计物理学和市场营销动态的理论框架，本研究提出了一个创新的方程，准确捕捉了广告支出与消费者反应之间的复杂关系，并验证了其有效性。 |
| [^3] | [Synthetic Data for Robust Stroke Segmentation](https://arxiv.org/abs/2404.01946) | 提出一种用于中风分割的合成框架，使用病变特定增强策略扩展了SynthSeg方法，通过训练深度学习模型实现对健康组织和病理病变的分割，无需特定序列的训练数据，在领域内和领域外数据集的评估中表现出鲁棒性能。 |
| [^4] | [Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Graph Variational Autoencoder with Contrastive Learning](https://arxiv.org/abs/2404.00785) | 本研究利用图变分自动编码器和对比学习解开神经系统疾病中海马形状变异的关键潜变量，超越了其他先进方法在解开能力上的表现。 |
| [^5] | [Tighter Confidence Bounds for Sequential Kernel Regression](https://arxiv.org/abs/2403.12732) | 通过使用鞅尾巴界限和无限维凸规划的有限维重构，建立了序贯核回归的新置信区间，证明其始终比现有的置信区间更紧凑，并将其应用于核赌博问题，提高了算法的性能表现。 |
| [^6] | [Stochastic Halpern iteration in normed spaces and applications to reinforcement learning](https://arxiv.org/abs/2403.12338) | 该论文分析了随机Halpern迭代在赋范空间中的Oracle复杂度，提出了改进的算法复杂度，进而在强化学习中提出了新的同步算法应用。 |
| [^7] | [Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors](https://arxiv.org/abs/2403.11407) | 通过利用去噪扩散模型先验结构，提出了一种分布式分隔后验采样方法，相比先前的方法具有更低的逼近误差。 |
| [^8] | [MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling](https://arxiv.org/abs/2403.10691) | MYTE是一种基于形态学的字节编码范式，通过使用具有一致大小的片段来实现跨不同语言的信息编码，为99种语言提供了更短的编码，特别是对非欧洲语言和非拉丁文字的改进最为显著。 |
| [^9] | [Advantage-Aware Policy Optimization for Offline Reinforcement Learning](https://arxiv.org/abs/2403.07262) | 介绍了一种新的适应优势的策略优化（A2PO）方法，用于离线学习，能够解决多行为策略收集的约束冲突问题，有效避免过拟合问题。 |
| [^10] | [Preserving correlations: A statistical method for generating synthetic data](https://arxiv.org/abs/2403.01471) | 提出了一种方法来生成具有统计代表性的合成数据，能够在合成数据集中保持原始数据集中特征之间的相关性，并提供可调整的隐私级别。 |
| [^11] | [Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction](https://arxiv.org/abs/2402.19197) | FSS是一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案，通过主动适应表面的厚度和复杂性，以及利用样本点的法线来改善结果，同时引入网格厚度损失信号来进一步改进训练过程。 |
| [^12] | [TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2402.19072) | 本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。 |
| [^13] | [Dataset Fairness: Achievable Fairness on Your Data With Utility Guarantees](https://arxiv.org/abs/2402.17106) | 该论文提出了一种针对数据集特性量身定制的近似公平性-准确性权衡曲线计算方法，能够有效减轻训练多个模型的计算负担并提供了严格的统计保证 |
| [^14] | [AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning](https://arxiv.org/abs/2402.15506) | AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。 |
| [^15] | [Statistical Agnostic Regression: a machine learning method to validate regression models](https://arxiv.org/abs/2402.15213) | 本文提出了一种新的方法，统计无关地评估了线性回归模型，并评估了ML估计在检测方面的表现。 |
| [^16] | [Covariance-Adaptive Least-Squares Algorithm for Stochastic Combinatorial Semi-Bandits](https://arxiv.org/abs/2402.15171) | 提出了一种协方差自适应的最小二乘算法，利用在线估计协方差结构，相对于基于代理方差的算法获得改进的遗憾上界，特别在协方差系数全为非负时，能有效地利用半臂反馈，并在各种参数设置下表现优异。 |
| [^17] | [Do Efficient Transformers Really Save Computation?](https://arxiv.org/abs/2402.13934) | 本研究旨在理解高效Transformer（例如稀疏Transformer和线性Transformer）的能力和限制，发现它们适合解决一般DP任务，但不同于标准Transformer。 |
| [^18] | [Diffusion Models for Audio Restoration](https://arxiv.org/abs/2402.09821) | 本文介绍了基于扩散模型的音频恢复算法，重点关注语音增强和音乐恢复任务。 |
| [^19] | [NeuRes: Learning Proofs of Propositional Satisfiability](https://arxiv.org/abs/2402.08365) | NeuRes是一种神经符号证明为基础的SAT解析器，能够证明不可满足性并加速找到可满足真值分配的过程。 |
| [^20] | [Data Distribution-based Curriculum Learning](https://arxiv.org/abs/2402.07352) | 本文提出了一种基于数据分布的课程学习方法（DDCL），通过利用数据集的数据分布和两种评分方法（DDCL（密度）和DDCL（点）），根据样本的顺序来提高分类器的性能。 |
| [^21] | [Thresholded Oja does Sparse PCA?](https://arxiv.org/abs/2402.07240) | 阈值和重新归一化Oja算法的输出可获得一个接近最优的错误率，与未经阈值处理的Oja向量相比，这大大减小了误差。 |
| [^22] | [On Provable Length and Compositional Generalization](https://arxiv.org/abs/2402.04875) | 本研究针对包括深度集合、变压器、状态空间模型和简单递归神经网络等多种架构，探索了可证明的长度和组合泛化，认为对于长度和组合泛化，不同架构需要不同程度的表示识别。 |
| [^23] | [Improved Generalization of Weight Space Networks via Augmentations](https://arxiv.org/abs/2402.04081) | 通过扩充权重空间的数据集，采用MixUp方法，我们改进了权重空间网络的泛化能力和性能。 |
| [^24] | [A Framework for Partially Observed Reward-States in RLHF](https://arxiv.org/abs/2402.03282) | 这篇论文提出了一个针对RLHF的框架，在其中考虑了部分观察到的奖励状态，并通过将基数反馈和决斗反馈缩减为PORRL形式进行了建模和算法开发。 |
| [^25] | [Positional Encoding Helps Recurrent Neural Networks Handle a Large Vocabulary](https://arxiv.org/abs/2402.00236) | 本研究探讨了位置编码在循环神经网络中的作用，发现即使与RNN结合使用，位置编码仍然有效，尤其是在处理大词汇量和多样观察结果时。这为使用输入驱动和自主时间表示的组合研究提供了新的方向，同时研究结果也对神经元振荡的生物学意义提供了讨论。 |
| [^26] | [Data Diversity Matters for Robust Instruction Tuning](https://arxiv.org/abs/2311.14736) | 数据多样性对鲁棒指令调整非常重要，我们提出了一种新算法(QDIT)，通过同时控制数据集的多样性和质量，我们深入研究了多样性和质量对指令调整性能的影响，并得出了两个关键观点。 |
| [^27] | [Deep Augmentation: Self-Supervised Learning with Transformations in Activation Space](https://arxiv.org/abs/2303.14537) | 深度增强是一种利用dropout或PCA在神经网络中转换目标层的方法，有效改善性能和泛化能力。在对比学习任务中，在Transformers、ResNets和图神经网络等基础模型上，通过深度增强实现了显著的性能提升，但在监督问题上效果相反。 |
| [^28] | [Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning.](http://arxiv.org/abs/2401.15043) | 该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。 |
| [^29] | [Learning Dynamics from Multicellular Graphs with Deep Neural Networks.](http://arxiv.org/abs/2401.12196) | 本研究提出了使用基于图的深度神经网络来预测多细胞集合体的运动能力。实验结果表明，这种方法能够准确地识别多细胞生物系统中的复杂图特征，并超越传统机械模型的能力。同时，研究者建议通过合作努力来构建一个多细胞数据库，以进一步推动多细胞动力学研究的发展。 |
| [^30] | [A survey on recent advances in named entity recognition.](http://arxiv.org/abs/2401.10825) | 这篇综述调查了最近的命名实体识别研究进展，并提供了对不同算法性能的深度比较，还探讨了数据集特征对方法行为的影响。 |
| [^31] | [Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products.](http://arxiv.org/abs/2401.10216) | 该论文提出了一种加速计算不可约表示张量积的方法，通过将等变操作基础从球形谐波改变为2D傅立叶基础，实现了对E(3)群的等变神经网络的高效建模。 |
| [^32] | [E3x: $\mathrm{E}(3)$-Equivariant Deep Learning Made Easy.](http://arxiv.org/abs/2401.07595) | E3x是一种简化了$\mathrm{E}(3)$等变深度学习的软件包，通过内置等变性实现更高的数据效率和准确性。 |
| [^33] | [Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel.](http://arxiv.org/abs/2311.01762) | 本文研究了使用梯度下降法解决非常数核的核岭回归。通过在训练过程中逐渐减小带宽，避免了超参数选择的需求，并提出了一种带宽更新方案，证明了其优于使用常数带宽的方法。 |
| [^34] | [Hierarchical Randomized Smoothing.](http://arxiv.org/abs/2310.16221) | 分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。 |
| [^35] | [Equivariant Deep Weight Space Alignment.](http://arxiv.org/abs/2310.13397) | 本论文提出了一个名为Deep-Align的新框架，用于学习解决权重对齐问题，以加速对齐过程并提高其质量。 |
| [^36] | [Accelerating optimization over the space of probability measures.](http://arxiv.org/abs/2310.04006) | 本研究研究了在概率测度空间中加速优化的问题，提出了一种类似于欧几里得空间中基于矩方法的哈密顿流方法，并证明了其可以达到任意高阶的收敛速度。 |
| [^37] | [Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood.](http://arxiv.org/abs/2309.05153) | 本文通过协同扩散恢复似然（CDRL）提出了一种方法，用于学习和采样一系列基于能量的模型（EBMs），通过在不断嘈杂化的数据集版本上定义不同噪声水平的EBMs，并与初始化模型配对协同训练。这种方法旨在关闭EBMs和其他生成框架之间的样本质量差距。 |
| [^38] | [Computing excited states of molecules using normalizing flows.](http://arxiv.org/abs/2308.16468) | 使用规范化流计算分子的激发态，通过逼近波函数并优化基函数的线性空间内的近似。该方法在计算量子系统中取得了准确和有效的结果，并在能量预测准确性和基组收敛速度方面进行了显著改善。 |
| [^39] | [A Parameter-Free Two-Bit Covariance Estimator with Improved Operator Norm Error Rate.](http://arxiv.org/abs/2308.16059) | 提出了一种无需参数的二位协方差估计器，通过使用变化的抖动尺度，解决了在协方差矩阵对角线主导情况下估计器与样本协方差之间的算子范数误差差距以及依赖未知参数的抖动尺度问题。 |
| [^40] | [Hessian-Aware Bayesian Optimization for Decision Making Systems.](http://arxiv.org/abs/2308.00629) | 本文介绍了一种感知海森贝叶斯优化算法，旨在解决决策系统优化中梯度反馈稀缺或无效的问题。通过引入紧凑的多层架构和角色概念，并利用感知海森贝叶斯优化方法对参数进行优化，作者实现了对复杂决策系统的高效优化。 |
| [^41] | [Learning in Repeated Multi-Unit Pay-As-Bid Auctions.](http://arxiv.org/abs/2307.15193) | 本论文研究了在重复的多单位付费拍卖中学习如何出价的问题。通过在离线设置中优化出价向量，并利用多项式时间动态规划方案，设计了具有多项式时间和空间复杂度的在线学习算法。 |
| [^42] | [Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via Optimization and Data-driven Approach for Dynamic Systems.](http://arxiv.org/abs/2306.12361) | 本文提出了一种不需要假设未知输入为线性的方法，结合非线性优化和数据驱动方法可以实现对未知输入的估计，并通过联合 sigma-point 变换方案将状态和未知输入的不确定性纳入估计中，确保其稳定性。这个方法适用于许多智能自主系统。 |
| [^43] | [Deep graph kernel point processes.](http://arxiv.org/abs/2306.11313) | 本文提出了一种基于潜在图拓扑的图点过程方法，并开发了一种新颖的深度图核来描述事件之间的触发和抑制效应，该方法在合成和实际数据集上具有优越性。 |
| [^44] | [On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models.](http://arxiv.org/abs/2305.17583) | 本文提出了一种创新方法，通过构建与神经网络完全对应的无限树状PGMs来解决深度神经网络(DNNs)缺乏PGMs的精确语义和明确定义的概率解释的问题。研究发现DNNs在前向传播时确实执行PGM推断的近似，这与现有研究不同，它阐明了DNNs对PGMs中的精确推理的更直接近似，潜在的好处包括改进DNNs的教学和解释，以及能够合并PGMs和DNNs的算法。 |
| [^45] | [Cross-domain Transfer Learning and State Inference for Soft Robots via a Semi-supervised Sequential Variational Bayes Framework.](http://arxiv.org/abs/2303.01693) | 本文提出了一个半监督顺序变分贝叶斯框架，用于解决软机器人领域的跨域迁移学习和状态推断问题。该框架可以处理某些机器人配置下存在缺失状态标签的情况，同时引入了特征空间迁移策略，提高了在多个配置下的潜在特征的适应性。 |
| [^46] | [Waveflow: Enforcing boundary conditions in smooth normalizing flows with application to fermionic wave functions.](http://arxiv.org/abs/2211.14839) | 本文介绍了一种新的处理归一化流拓扑问题、将边界条件应用于归一化流的技术、引入了可以被制作成任意次可微的 I-Spline 双射，并将这些技术用于创建一种基于归一化流的费米波函数 Ansatz，从而实现高效训练。 |
| [^47] | [MixMask: Revisiting Masking Strategy for Siamese ConvNets.](http://arxiv.org/abs/2210.11456) | 本文提出了一种新的填充式遮盖策略MixMask，在Siamese ConvNets中实现遮盖和对比学习目标的匹配，提高了Siamese ConvNets的性能并在多个基准测试中实现了最先进的结果。 |

# 详细

[^1]: 随机非线性与无穷维扩散过程的条件约束

    Conditioning non-linear and infinite-dimensional diffusion processes

    [https://rss.arxiv.org/abs/2402.01434](https://rss.arxiv.org/abs/2402.01434)

    本文探索了在无穷维空间中对非线性过程进行条件约束的方法，并应用于进化生物学中的生物形态时间序列分析。

    

    生成性扩散模型和许多科学和工程中的随机模型在离散化之前自然地存在于无穷维空间中。为了将观测数据纳入统计和学习任务中，需要对观测值进行条件约束。近期的研究已经处理了在无穷维空间中对线性过程进行条件约束的问题，但尚未探索在无穷维空间中对非线性过程进行条件约束的方法。本文提出了一种在无先验离散化的情况下对函数值随机过程进行条件约束的方法。为此，我们使用了Girsanov定理的无穷维版本来对函数值随机过程进行条件约束，从而得到了涉及得分的条件过程的随机微分方程(SDE)。我们将这种技术应用于进化生物学中的生物形态时间序列分析中，通过Fourier基函数离散化，然后利用得分匹配方法学习得分函数的系数。

    Generative diffusion models and many stochastic models in science and engineering naturally live in infinite dimensions before discretisation. To incorporate observed data for statistical and learning tasks, one needs to condition on observations. While recent work has treated conditioning linear processes in infinite dimensions, conditioning non-linear processes in infinite dimensions has not been explored. This paper conditions function valued stochastic processes without prior discretisation. To do so, we use an infinite-dimensional version of Girsanov's theorem to condition a function-valued stochastic process, leading to a stochastic differential equation (SDE) for the conditioned process involving the score. We apply this technique to do time series analysis for shapes of organisms in evolutionary biology, where we discretise via the Fourier basis and then learn the coefficients of the score function with score matching methods.
    
[^2]: 消费者反应的社会动态：融合统计物理学与营销动态的统一框架

    Social Dynamics of Consumer Response: A Unified Framework Integrating Statistical Physics and Marketing Dynamics

    [https://arxiv.org/abs/2404.02175](https://arxiv.org/abs/2404.02175)

    使用统计物理学和市场营销动态的理论框架，本研究提出了一个创新的方程，准确捕捉了广告支出与消费者反应之间的复杂关系，并验证了其有效性。

    

    理解消费者对广告输入的反应对于旨在优化广告策略并提高广告活动有效性的营销人员至关重要。本研究通过应用源自物理学和社会心理学的理论框架，研究消费者行为的复杂性。我们提出了一个创新的方程，捕捉了广告支出与消费者反应之间的关系，利用了诸如对称性、标度律和相变等概念。通过将我们的方程验证与Michaelis-Menten和Hill方程等著名模型相比较，我们证明了其在准确表示消费者反应动态复杂性方面的有效性。分析强调了关键模型参数（如营销效果、反应敏感度和行为敏感度）对影响消费者行为的重要性。该研究探讨了广告商和营销人员的实际影响。

    arXiv:2404.02175v1 Announce Type: cross  Abstract: Comprehending how consumers react to advertising inputs is essential for marketers aiming to optimize advertising strategies and improve campaign effectiveness. This study examines the complex nature of consumer behaviour by applying theoretical frameworks derived from physics and social psychology. We present an innovative equation that captures the relation between spending on advertising and consumer response, using concepts such as symmetries, scaling laws, and phase transitions. By validating our equation against well-known models such as the Michaelis-Menten and Hill equations, we prove its effectiveness in accurately representing the complexity of consumer response dynamics. The analysis emphasizes the importance of key model parameters, such as marketing effectiveness, response sensitivity, and behavioural sensitivity, in influencing consumer behaviour. The work explores the practical implications for advertisers and marketers,
    
[^3]: 用于鲁棒性中风分割的合成数据

    Synthetic Data for Robust Stroke Segmentation

    [https://arxiv.org/abs/2404.01946](https://arxiv.org/abs/2404.01946)

    提出一种用于中风分割的合成框架，使用病变特定增强策略扩展了SynthSeg方法，通过训练深度学习模型实现对健康组织和病理病变的分割，无需特定序列的训练数据，在领域内和领域外数据集的评估中表现出鲁棒性能。

    

    arXiv:2404.01946v1 公告类型：交叉 摘要：目前基于深度学习的神经影像语义分割需要高分辨率扫描和大量注释数据集，这给临床适用性带来了显著障碍。我们提出了一种新颖的合成框架，用于病变分割任务，扩展了已建立的SynthSeg方法的能力，以适应具有病变特定增强策略的大型异质病变。我们的方法使用从健康和中风数据集派生的标签映射训练深度学习模型，在这里演示了UNet架构，促进了健康组织和病理病变的分割，而无需特定于序列的训练数据。针对领域内和领域外（OOD）数据集进行评估，我们的框架表现出鲁棒性能，与训练领域内的当前方法相媲美，并在OOD数据上显着优于它们。这一贡献有望推动医学...

    arXiv:2404.01946v1 Announce Type: cross  Abstract: Deep learning-based semantic segmentation in neuroimaging currently requires high-resolution scans and extensive annotated datasets, posing significant barriers to clinical applicability. We present a novel synthetic framework for the task of lesion segmentation, extending the capabilities of the established SynthSeg approach to accommodate large heterogeneous pathologies with lesion-specific augmentation strategies. Our method trains deep learning models, demonstrated here with the UNet architecture, using label maps derived from healthy and stroke datasets, facilitating the segmentation of both healthy tissue and pathological lesions without sequence-specific training data. Evaluated against in-domain and out-of-domain (OOD) datasets, our framework demonstrates robust performance, rivaling current methods within the training domain and significantly outperforming them on OOD data. This contribution holds promise for advancing medical
    
[^4]: 解开海马形状变异之谜：利用对比学习的图变分自动编码器研究神经系统疾病

    Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Graph Variational Autoencoder with Contrastive Learning

    [https://arxiv.org/abs/2404.00785](https://arxiv.org/abs/2404.00785)

    本研究利用图变分自动编码器和对比学习解开神经系统疾病中海马形状变异的关键潜变量，超越了其他先进方法在解开能力上的表现。

    

    本文提出了一项综合研究，专注于在神经系统疾病背景下从扩散张量成像（DTI）数据集中解开海马形状变异。借助增强的监督对比学习图变分自动编码器（VAE），我们的方法旨在通过区分代表年龄和是否患病的两个不同潜变量来提高解释性。在我们的消融研究中，我们调查了一系列VAE架构和对比损失函数，展示了我们方法增强的解开能力。这个评估使用了来自DTI海马数据集的合成3D环形网格数据和真实的3D海马网格数据集。我们的监督解开模型在解开分数方面优于几种最先进的方法，如属性和引导VAE。我们的模型可以区分不同年龄组和疾病状况。

    arXiv:2404.00785v1 Announce Type: cross  Abstract: This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Graph Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in pa
    
[^5]: 对于序贯核回归的更紧凑置信区间

    Tighter Confidence Bounds for Sequential Kernel Regression

    [https://arxiv.org/abs/2403.12732](https://arxiv.org/abs/2403.12732)

    通过使用鞅尾巴界限和无限维凸规划的有限维重构，建立了序贯核回归的新置信区间，证明其始终比现有的置信区间更紧凑，并将其应用于核赌博问题，提高了算法的性能表现。

    

    置信区间是严格量化预测不确定性的重要工具。它们可以指导探索与开发的权衡，并构成许多序贯学习和决策算法的核心组成部分。更紧凑的置信区间带来了具有更好经验性能和更好性能保证的算法。在这项工作中，我们使用鞅尾巴界限和无限维凸规划的有限维重构来建立序贯核回归的新置信区间。我们证明在这一设置中，我们的新置信区间始终比现有的更紧凑。我们将我们的置信区间应用于核赌博问题，其中未来的行动取决于先前的历史。当我们的置信区间取代现有的置信区间时，KernelUCB（GP-UCB）算法具有更好的经验性能，匹配的最坏情况性能保证和可比性。

    arXiv:2403.12732v1 Announce Type: cross  Abstract: Confidence bounds are an essential tool for rigorously quantifying the uncertainty of predictions. In this capacity, they can inform the exploration-exploitation trade-off and form a core component in many sequential learning and decision-making algorithms. Tighter confidence bounds give rise to algorithms with better empirical performance and better performance guarantees. In this work, we use martingale tail bounds and finite-dimensional reformulations of infinite-dimensional convex programs to establish new confidence bounds for sequential kernel regression. We prove that our new confidence bounds are always tighter than existing ones in this setting. We apply our confidence bounds to the kernel bandit problem, where future actions depend on the previous history. When our confidence bounds replace existing ones, the KernelUCB (GP-UCB) algorithm has better empirical performance, a matching worst-case performance guarantee and compara
    
[^6]: 随机Halpern迭代在赋范空间中的应用及其在强化学习中的应用

    Stochastic Halpern iteration in normed spaces and applications to reinforcement learning

    [https://arxiv.org/abs/2403.12338](https://arxiv.org/abs/2403.12338)

    该论文分析了随机Halpern迭代在赋范空间中的Oracle复杂度，提出了改进的算法复杂度，进而在强化学习中提出了新的同步算法应用。

    

    我们分析了具有方差减少的随机Halpern迭代的Oracle复杂度，旨在近似有界和收缩算子的不动点在一个有限维赋范空间中。我们表明，如果底层的随机Oracle具有一致有界的方差，则我们的方法展现出总的Oracle复杂度为$ \tilde{O} (\varepsilon^{-5})$，改进了最近为随机Krasnoselskii-Mann迭代建立的速率。此外，我们建立了 $\Omega (\varepsilon^{-3})$的下界，适用于广泛范围的算法，包括所有带有小批处理的平均迭代。通过适当修改我们的方法，我们推导出了在算子为 $\gamma$-收缩的情况下一个 $O(\varepsilon^{-2}(1-\gamma)^{-3})$复杂度上界。作为一个应用，我们提出了新的用于平均奖励和折扣奖励马尔可夫决策过程的同步算法。

    arXiv:2403.12338v1 Announce Type: cross  Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, f
    
[^7]: 分布式分隔后验采样用于去噪扩散先验

    Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors

    [https://arxiv.org/abs/2403.11407](https://arxiv.org/abs/2403.11407)

    通过利用去噪扩散模型先验结构，提出了一种分布式分隔后验采样方法，相比先前的方法具有更低的逼近误差。

    

    近年来，对于使用去噪扩散模型（DDM）作为逆贝叶斯问题求解的先验引起了极大的兴趣。然而，从结果后验分布中抽样是一个挑战。为了解决这个问题，先前的研究提出了近似方法来偏置扩散的漂移项。在本工作中，我们采取了一种不同的方法，并利用DDM先验的特定结构来定义一组中间和更简单的后验抽样问题，相比先前的方法，这些方法具有更低的逼近误差。我们通过使用合成例子和各种图像恢复任务来实证地展示我们方法对于一般线性逆问题的重构能力。

    arXiv:2403.11407v1 Announce Type: cross  Abstract: Interest in the use of Denoising Diffusion Models (DDM) as priors for solving inverse Bayesian problems has recently increased significantly. However, sampling from the resulting posterior distribution poses a challenge. To solve this problem, previous works have proposed approximations to bias the drift term of the diffusion. In this work, we take a different approach and utilize the specific structure of the DDM prior to define a set of intermediate and simpler posterior sampling problems, resulting in a lower approximation error compared to previous methods. We empirically demonstrate the reconstruction capability of our method for general linear inverse problems using synthetic examples and various image restoration tasks.
    
[^8]: MYTE：形态学驱动的字节编码，用于更好、更公平的多语言语言建模

    MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling

    [https://arxiv.org/abs/2403.10691](https://arxiv.org/abs/2403.10691)

    MYTE是一种基于形态学的字节编码范式，通过使用具有一致大小的片段来实现跨不同语言的信息编码，为99种语言提供了更短的编码，特别是对非欧洲语言和非拉丁文字的改进最为显著。

    

    多语言语言建模中的一个主要考虑因素是如何最好地表示具有不同词汇和文字的语言。尽管当代文本编码方法涵盖了大多数世界文字系统，但它们存在偏向于全球西方高资源语言的问题。因此，少数语言的文本往往被分割为一长串在语言学上毫无意义的单元。为了解决这种不平等，我们引入了一种新的范式，用跨不同语言具有一致大小的片段来编码相同的信息。我们的编码约定（MYTE）基于形态素，因为它们的库存在各种语言中比字符更平衡，而以前的方法使用字符。我们展示MYTE为所有99种分析语言产生了更短的编码，其中非欧洲语言和非拉丁文字的改进最为显著。这进而改善了多语言语言建模的性能。

    arXiv:2403.10691v1 Announce Type: cross  Abstract: A major consideration in multilingual language modeling is how to best represent languages with diverse vocabularies and scripts. Although contemporary text encoding methods cover most of the world's writing systems, they exhibit bias towards the high-resource languages of the Global West. As a result, texts of underrepresented languages tend to be segmented into long sequences of linguistically meaningless units. To address the disparities, we introduce a new paradigm that encodes the same information with segments of consistent size across diverse languages. Our encoding convention (MYTE) is based on morphemes, as their inventories are more balanced across languages than characters, which are used in previous methods. We show that MYTE produces shorter encodings for all 99 analyzed languages, with the most notable improvements for non-European languages and non-Latin scripts. This, in turn, improves multilingual LM performance and di
    
[^9]: 适应优势的策略优化用于离线强化学习

    Advantage-Aware Policy Optimization for Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.07262](https://arxiv.org/abs/2403.07262)

    介绍了一种新的适应优势的策略优化（A2PO）方法，用于离线学习，能够解决多行为策略收集的约束冲突问题，有效避免过拟合问题。

    

    离线强化学习致力于利用离线数据集来制定有效的智能体策略，而无需在线交互，通过在行为策略的支持下施加适当的保守约束来解决分布外问题。本文引入了一种新的适应优势的策略优化（A2PO）方法，以明确构建针对混合质量数据集的离线学习优势感知策略约束。

    arXiv:2403.07262v1 Announce Type: cross  Abstract: Offline Reinforcement Learning (RL) endeavors to leverage offline datasets to craft effective agent policy without online interaction, which imposes proper conservative constraints with the support of behavior policies to tackle the Out-Of-Distribution (OOD) problem. However, existing works often suffer from the constraint conflict issue when offline datasets are collected from multiple behavior policies, i.e., different behavior policies may exhibit inconsistent actions with distinct returns across the state space. To remedy this issue, recent Advantage-Weighted (AW) methods prioritize samples with high advantage values for agent training while inevitably leading to overfitting on these samples. In this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO) method to explicitly construct advantage-aware policy constraints for offline learning under mixed-quality datasets. Specifically, A2PO employs a Conditional Variat
    
[^10]: 保持相关性：一种用于生成合成数据的统计方法

    Preserving correlations: A statistical method for generating synthetic data

    [https://arxiv.org/abs/2403.01471](https://arxiv.org/abs/2403.01471)

    提出了一种方法来生成具有统计代表性的合成数据，能够在合成数据集中保持原始数据集中特征之间的相关性，并提供可调整的隐私级别。

    

    我们提出了一种方法来生成具有统计代表性的合成数据。主要目标是在合成数据集中保持原始数据集中存在的特征之间的相关性，同时提供一个舒适的隐私级别，可以根据特定客户需求进行调整。我们详细描述了我们用于分析原始数据集和生成合成数据点的算法。我们使用了一个大型能源相关数据集进行了测试。我们在定性（例如通过可视化相关性图）和定量（以适当的$\ell^1$类型误差范数作为评估指标）方面获得了良好的结果。所提出的方法论是一般的，不依赖于使用的测试数据集。我们期望它可适用于比此处指示的更广泛的情境。

    arXiv:2403.01471v1 Announce Type: new  Abstract: We propose a method to generate statistically representative synthetic data. The main goal is to be able to maintain in the synthetic dataset the correlations of the features present in the original one, while offering a comfortable privacy level that can be eventually tailored on specific customer demands.   We describe in detail our algorithm used both for the analysis of the original dataset and for the generation of the synthetic data points. The approach is tested using a large energy-related dataset. We obtain good results both qualitatively (e.g. via vizualizing correlation maps) and quantitatively (in terms of suitable $\ell^1$-type error norms used as evaluation metrics).   The proposed methodology is general in the sense that it does not rely on the used test dataset. We expect it to be applicable in a much broader context than indicated here.
    
[^11]: 细结构感知采样: 一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案

    Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction

    [https://arxiv.org/abs/2402.19197](https://arxiv.org/abs/2402.19197)

    FSS是一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案，通过主动适应表面的厚度和复杂性，以及利用样本点的法线来改善结果，同时引入网格厚度损失信号来进一步改进训练过程。

    

    像素对齐的隐式模型，如PIFu、PIFuHD和ICON，用于单视图着装人体重建。这些模型需要使用采样训练方案进行训练。现有的采样训练方案要么无法捕捉薄表面（如耳朵、手指），要么会导致重建网格中的噪声伪影。为解决这些问题，我们引入了细结构感知采样（FSS），这是一种新的用于单视图人体重建中训练像素对齐隐式模型的采样训练方案。FSS通过主动适应表面的厚度和复杂性来解决前述问题。此外，与现有的采样训练方案不同，FSS显示了如何利用样本点的法线在训练过程中提高结果。最后，为进一步改进训练过程，FSS提出了一个用于像素对齐隐式模型的网格厚度损失信号。这使得在训练过程中利用法线变得计算上可行。

    arXiv:2402.19197v1 Announce Type: cross  Abstract: Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for single-view clothed human reconstruction. These models need to be trained using a sampling training scheme. Existing sampling training schemes either fail to capture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in reconstructed meshes. To address these problems, we introduce Fine Structured-Aware Sampling (FSS), a new sampling training scheme to train pixel-aligned implicit models for single-view human reconstruction. FSS resolves the aforementioned problems by proactively adapting to the thickness and complexity of surfaces. In addition, unlike existing sampling training schemes, FSS shows how normals of sample points can be capitalized in the training process to improve results. Lastly, to further improve the training process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit models. It becomes computationally feasible to int
    
[^12]: TimeXer：利用外生变量增强变压器进行时间序列预测

    TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables

    [https://arxiv.org/abs/2402.19072](https://arxiv.org/abs/2402.19072)

    本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。

    

    最近的研究表明，在时间序列预测方面取得了显著的性能。然而，由于现实应用的部分观测性质，仅专注于感兴趣的目标，也就是所谓的内生变量，通常是不足以保证准确预测的。值得注意的是，系统通常记录为多个变量，其中外生序列可以为内生变量提供有价值的外部信息。因此，与先前确立的多变量或单变量预测不同，它们要么将所有变量等同对待，要么忽视外生信息，本文关注的是一种实际设置，即具有外生变量的时间序列预测。我们提出了一个新颖的框架TimeXer，利用外部信息增强内生变量的预测。通过巧妙设计的嵌入层，TimeXer使传统的Transformer架构具有重新

    arXiv:2402.19072v1 Announce Type: cross  Abstract: Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical Transformer architecture with the ability to reco
    
[^13]: 数据集公平性：在您的数据上实现具有效用保证的公平性

    Dataset Fairness: Achievable Fairness on Your Data With Utility Guarantees

    [https://arxiv.org/abs/2402.17106](https://arxiv.org/abs/2402.17106)

    该论文提出了一种针对数据集特性量身定制的近似公平性-准确性权衡曲线计算方法，能够有效减轻训练多个模型的计算负担并提供了严格的统计保证

    

    在机器学习公平性中，训练能够最小化不同敏感群体之间差异的模型通常会导致准确性下降，这种现象被称为公平性-准确性权衡。这种权衡的严重程度基本取决于数据集的特性，如数据集的不均衡或偏见。因此，在数据集之间使用统一的公平性要求仍然值得怀疑，并且往往会导致效用极低的模型。为了解决这个问题，我们提出了一种针对单个数据集量身定制的近似公平性-准确性权衡曲线的计算效率高的方法，该方法支持严格的统计保证。通过利用You-Only-Train-Once（YOTO）框架，我们的方法减轻了在逼近权衡曲线时需要训练多个模型的计算负担。此外，我们通过在该曲线周围引入置信区间来量化我们近似值的不确定性，

    arXiv:2402.17106v1 Announce Type: cross  Abstract: In machine learning fairness, training models which minimize disparity across different sensitive groups often leads to diminished accuracy, a phenomenon known as the fairness-accuracy trade-off. The severity of this trade-off fundamentally depends on dataset characteristics such as dataset imbalances or biases. Therefore using a uniform fairness requirement across datasets remains questionable and can often lead to models with substantially low utility. To address this, we present a computationally efficient approach to approximate the fairness-accuracy trade-off curve tailored to individual datasets, backed by rigorous statistical guarantees. By utilizing the You-Only-Train-Once (YOTO) framework, our approach mitigates the computational burden of having to train multiple models when approximating the trade-off curve. Moreover, we quantify the uncertainty in our approximation by introducing confidence intervals around this curve, offe
    
[^14]: AgentOhana：为有效智能体学习设计统一数据和训练流水线

    AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning

    [https://arxiv.org/abs/2402.15506](https://arxiv.org/abs/2402.15506)

    AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。

    

    由大型语言模型（LLMs）提供支持的自主智能体引起了重大研究关注。然而，充分利用LLMs的潜力进行基于智能体的任务面临困难，这是由于具有多轮轨迹的多样化数据源的异构性。在本文中，我们介绍AgentOhana作为解决这些挑战的综合解决方案。AgentOhana从不同环境中聚合智能体轨迹，涵盖了各种情景。它精心地将这些轨迹标准化和统一到一致的格式中，简化了为智能体训练优化的通用数据加载器的创建。通过数据统一，我们的训练流水线在不同数据源之间保持平衡，并在数据集划分和模型训练过程中保持设备之间的独立随机性。此外，我们还介绍了xLAM-v0.1，一个大动作模式

    arXiv:2402.15506v1 Announce Type: new  Abstract: Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce \textbf{AgentOhana} as a comprehensive solution to address these challenges. \textit{AgentOhana} aggregates agent trajectories from distinct environments, spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format, streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification, our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally, we present \textbf{xLAM-v0.1}, a large action mode
    
[^15]: 统计无偏回归：一种用于验证回归模型的机器学习方法

    Statistical Agnostic Regression: a machine learning method to validate regression models

    [https://arxiv.org/abs/2402.15213](https://arxiv.org/abs/2402.15213)

    本文提出了一种新的方法，统计无关地评估了线性回归模型，并评估了ML估计在检测方面的表现。

    

    回归分析是统计建模中的一个核心主题，旨在估计因变量（通常称为响应变量）与一个或多个自变量（即解释变量）之间的关系。线性回归是迄今为止在预测、预测或因果推断等多个研究领域执行此任务的最流行方法。除了解决线性回归问题的各种传统方法外，如普通最小二乘法、岭回归或套索回归——这些方法往往是更高级机器学习（ML）技术的基础——后者已成功地应用在这种场景中，但没有对统计显著性进行正式定义。最多，基于经验测量（如残差或准确度）进行置换或基于经典分析，以反映ML估计对检测的更高能力。本文介绍了一种新的方法，该方法统计无关地评估了线性回归模型，并对ML估计在检测方面的表现进行了评估。

    arXiv:2402.15213v1 Announce Type: cross  Abstract: Regression analysis is a central topic in statistical modeling, aiming to estimate the relationships between a dependent variable, commonly referred to as the response variable, and one or more independent variables, i.e., explanatory variables. Linear regression is by far the most popular method for performing this task in several fields of research, such as prediction, forecasting, or causal inference. Beyond various classical methods to solve linear regression problems, such as Ordinary Least Squares, Ridge, or Lasso regressions - which are often the foundation for more advanced machine learning (ML) techniques - the latter have been successfully applied in this scenario without a formal definition of statistical significance. At most, permutation or classical analyses based on empirical measures (e.g., residuals or accuracy) have been conducted to reflect the greater ability of ML estimations for detection. In this paper, we introd
    
[^16]: 用于随机组合半臂老虎机的协方差自适应最小二乘算法

    Covariance-Adaptive Least-Squares Algorithm for Stochastic Combinatorial Semi-Bandits

    [https://arxiv.org/abs/2402.15171](https://arxiv.org/abs/2402.15171)

    提出了一种协方差自适应的最小二乘算法，利用在线估计协方差结构，相对于基于代理方差的算法获得改进的遗憾上界，特别在协方差系数全为非负时，能有效地利用半臂反馈，并在各种参数设置下表现优异。

    

    我们解决了随机组合半臂老虎机问题，其中玩家可以从包含d个基本项的P个子集中进行选择。大多数现有算法（如CUCB、ESCB、OLS-UCB）需要对奖励分布有先验知识，比如子高斯代理-方差的上界，这很难准确估计。在这项工作中，我们设计了OLS-UCB的方差自适应版本，依赖于协方差结构的在线估计。在实际设置中，估计协方差矩阵的系数要容易得多，并且相对于基于代理方差的算法，导致改进的遗憾上界。当协方差系数全为非负时，我们展示了我们的方法有效地利用了半臂反馈，并且可以明显优于老虎机反馈方法，在指数级别P≫d以及P≤d的情况下，这一点并不来自大多数现有分析。

    arXiv:2402.15171v1 Announce Type: new  Abstract: We address the problem of stochastic combinatorial semi-bandits, where a player can select from P subsets of a set containing d base items. Most existing algorithms (e.g. CUCB, ESCB, OLS-UCB) require prior knowledge on the reward distribution, like an upper bound on a sub-Gaussian proxy-variance, which is hard to estimate tightly. In this work, we design a variance-adaptive version of OLS-UCB, relying on an online estimation of the covariance structure. Estimating the coefficients of a covariance matrix is much more manageable in practical settings and results in improved regret upper bounds compared to proxy variance-based algorithms. When covariance coefficients are all non-negative, we show that our approach efficiently leverages the semi-bandit feedback and provably outperforms bandit feedback approaches, not only in exponential regimes where P $\gg$ d but also when P $\le$ d, which is not straightforward from most existing analyses.
    
[^17]: 确实高效的Transformer能够节约计算吗？

    Do Efficient Transformers Really Save Computation?

    [https://arxiv.org/abs/2402.13934](https://arxiv.org/abs/2402.13934)

    本研究旨在理解高效Transformer（例如稀疏Transformer和线性Transformer）的能力和限制，发现它们适合解决一般DP任务，但不同于标准Transformer。

    

    随着基于Transformer的语言模型在越来越大的数据集上训练，并拥有大量参数，找到更高效的替代标准Transformer变得非常有价值。虽然已经提出了许多高效的Transformer和Transformer的替代方案，但没有一个能够提供它们适合替代标准Transformer的理论保证。这使得很难确定何时使用特定模型以及进一步研究的重点。在本文中，我们旨在理解高效Transformer的能力和局限性，特别是稀疏Transformer和线性Transformer。我们专注于它们在Chain-of-Thought (CoT)提示中展示的推理能力，并遵循先前的研究将它们建模为动态规划（DP）问题。我们的结果表明，虽然这些模型足够表达解决一般DP任务的能力，但与标准Transformer不同

    arXiv:2402.13934v1 Announce Type: cross  Abstract: As transformer-based language models are trained on increasingly large datasets and with vast numbers of parameters, finding more efficient alternatives to the standard Transformer has become very valuable. While many efficient Transformers and Transformer alternatives have been proposed, none provide theoretical guarantees that they are a suitable replacement for the standard Transformer. This makes it challenging to identify when to use a specific model and what directions to prioritize for further investigation. In this paper, we aim to understand the capabilities and limitations of efficient Transformers, specifically the Sparse Transformer and the Linear Transformer. We focus on their reasoning capability as exhibited by Chain-of-Thought (CoT) prompts and follow previous works to model them as Dynamic Programming (DP) problems. Our results show that while these models are expressive enough to solve general DP tasks, contrary to ex
    
[^18]: 音频恢复的扩散模型

    Diffusion Models for Audio Restoration

    [https://arxiv.org/abs/2402.09821](https://arxiv.org/abs/2402.09821)

    本文介绍了基于扩散模型的音频恢复算法，重点关注语音增强和音乐恢复任务。

    

    随着音频播放设备和快速数据传输的发展，对高音质的需求在娱乐和通信领域不断增长。然而，由于录制过程中的失真和干扰，或者由于不完善的传输管道，音频质量面临许多挑战。为了解决这个问题，音频恢复方法旨在从损坏的输入数据中恢复出清晰的音频信号。本文介绍了基于扩散模型的音频恢复算法，重点关注语音增强和音乐恢复任务。传统方法通常基于手工规则和统计启发法，从而建立了我们对音频信号的认识。近几十年来，越来越多的人转向利用深度神经网络（DNNs）的建模能力的数据驱动方法。深度生成模型中的扩散模型成为一种新兴方法。

    arXiv:2402.09821v1 Announce Type: cross  Abstract: With the development of audio playback devices and fast data transmission, the demand for high sound quality is rising, for both entertainment and communications. In this quest for better sound quality, challenges emerge from distortions and interferences originating at the recording side or caused by an imperfect transmission pipeline. To address this problem, audio restoration methods aim to recover clean sound signals from the corrupted input data. We present here audio restoration algorithms based on diffusion models, with a focus on speech enhancement and music restoration tasks. Traditional approaches, often grounded in handcrafted rules and statistical heuristics, have shaped our understanding of audio signals. In the past decades, there has been a notable shift towards data-driven methods that exploit the modeling capabilities of deep neural networks (DNNs). Deep generative models, and among them diffusion models, have emerged 
    
[^19]: NeuRes: 学习命题可满足性的证明

    NeuRes: Learning Proofs of Propositional Satisfiability

    [https://arxiv.org/abs/2402.08365](https://arxiv.org/abs/2402.08365)

    NeuRes是一种神经符号证明为基础的SAT解析器，能够证明不可满足性并加速找到可满足真值分配的过程。

    

    我们介绍了一种神经符号证明为基础的SAT解析器NeuRes。与其他神经SAT解算法不同，NeuRes能够证明不可满足性，而不仅仅是预测它。NeuRes通过采用命题推理来证明不可满足性并加速在不可满足和可满足公式中找到满足真值分配的过程。为了实现这一点，我们提出了一种新颖的架构，它结合了图神经网络和指针网络的元素，从动态图结构中自动选择节点对，这对于生成解析证明是至关重要的。我们使用与NeuroSAT相同的随机公式分布编制了一个包含教师证明和真值分配的数据集，对我们的模型进行训练和评估。在实验证明中，我们展示了NeuRes在不同分布上比NeuroSAT解决更多的测试公式，并且需要更少的数据。

    We introduce NeuRes, a neuro-symbolic proof-based SAT solver. Unlike other neural SAT solving methods, NeuRes is capable of proving unsatisfiability as opposed to merely predicting it. By design, NeuRes operates in a certificate-driven fashion by employing propositional resolution to prove unsatisfiability and to accelerate the process of finding satisfying truth assignments in case of unsat and sat formulas, respectively. To realize this, we propose a novel architecture that adapts elements from Graph Neural Networks and Pointer Networks to autoregressively select pairs of nodes from a dynamic graph structure, which is essential to the generation of resolution proofs. Our model is trained and evaluated on a dataset of teacher proofs and truth assignments that we compiled with the same random formula distribution used by NeuroSAT. In our experiments, we show that NeuRes solves more test formulas than NeuroSAT by a rather wide margin on different distributions while being much more data
    
[^20]: 基于数据分布的课程学习

    Data Distribution-based Curriculum Learning

    [https://arxiv.org/abs/2402.07352](https://arxiv.org/abs/2402.07352)

    本文提出了一种基于数据分布的课程学习方法（DDCL），通过利用数据集的数据分布和两种评分方法（DDCL（密度）和DDCL（点）），根据样本的顺序来提高分类器的性能。

    

    训练样本的顺序对分类器的性能有着重要影响。课程学习是一种将训练样本从简单到困难排序的方法。本文提出了一种称为基于数据分布的课程学习（DDCL）的创新方法。DDCL利用数据集的数据分布以及两种评分方法（DDCL（密度）和DDCL（点））来决定训练样本的顺序。DDCL（密度）利用样本密度分配评分，而DDCL（点）利用欧氏距离进行评分。我们通过在多个数据集上使用神经网络、支持向量机和随机森林分类器进行实验来评估所提出的DDCL方法。评估结果显示，与没有任何课程的标准评估相比，应用DDCL方法可以提高所有数据集的平均分类准确率。

    The order of training samples can have a significant impact on the performance of a classifier. Curriculum learning is a method of ordering training samples from easy to hard. This paper proposes the novel idea of a curriculum learning approach called Data Distribution-based Curriculum Learning (DDCL). DDCL uses the data distribution of a dataset to build a curriculum based on the order of samples. Two types of scoring methods known as DDCL (Density) and DDCL (Point) are used to score training samples thus determining their training order. DDCL (Density) uses the sample density to assign scores while DDCL (Point) utilises the Euclidean distance for scoring. We evaluate the proposed DDCL approach by conducting experiments on multiple datasets using a neural network, support vector machine and random forest classifier. Evaluation results show that the application of DDCL improves the average classification accuracy for all datasets compared to standard evaluation without any curriculum. 
    
[^21]: 阈值Oja是否适用于稀疏PCA？

    Thresholded Oja does Sparse PCA?

    [https://arxiv.org/abs/2402.07240](https://arxiv.org/abs/2402.07240)

    阈值和重新归一化Oja算法的输出可获得一个接近最优的错误率，与未经阈值处理的Oja向量相比，这大大减小了误差。

    

    我们考虑了当比值$d/n \rightarrow c > 0$时稀疏主成分分析（PCA）的问题。在离线设置下，关于稀疏PCA的最优率已经有很多研究，其中所有数据都可以用于多次传递。相比之下，当人口特征向量是$s$-稀疏时，具有$O(d)$存储和$O(nd)$时间复杂度的流算法通常要求强初始化条件，否则会有次优错误。我们展示了一种简单的算法，对Oja算法的输出（Oja向量）进行阈值和重新归一化，从而获得接近最优的错误率。这非常令人惊讶，因为没有阈值，Oja向量的误差很大。我们的分析集中在限制未归一化的Oja向量的项上，这涉及将一组独立随机矩阵的乘积在随机初始向量上的投影。 这是非平凡且新颖的，因为以前的Oja算法分析没有考虑这一点。

    arXiv:2402.07240v2 Announce Type: cross  Abstract: We consider the problem of Sparse Principal Component Analysis (PCA) when the ratio $d/n \rightarrow c > 0$. There has been a lot of work on optimal rates on sparse PCA in the offline setting, where all the data is available for multiple passes. In contrast, when the population eigenvector is $s$-sparse, streaming algorithms that have $O(d)$ storage and $O(nd)$ time complexity either typically require strong initialization conditions or have a suboptimal error. We show that a simple algorithm that thresholds and renormalizes the output of Oja's algorithm (the Oja vector) obtains a near-optimal error rate. This is very surprising because, without thresholding, the Oja vector has a large error. Our analysis centers around bounding the entries of the unnormalized Oja vector, which involves the projection of a product of independent random matrices on a random initial vector. This is nontrivial and novel since previous analyses of Oja's al
    
[^22]: 关于可证明的长度和组合泛化

    On Provable Length and Compositional Generalization

    [https://arxiv.org/abs/2402.04875](https://arxiv.org/abs/2402.04875)

    本研究针对包括深度集合、变压器、状态空间模型和简单递归神经网络等多种架构，探索了可证明的长度和组合泛化，认为对于长度和组合泛化，不同架构需要不同程度的表示识别。

    

    长度泛化——对训练时未见到的更长序列的泛化能力，以及组合泛化——对训练时未见到的令牌组合的泛化能力，在序列到序列模型中是重要的非分布化泛化形式。在这项工作中，我们在包括深度集合、变压器、状态空间模型和简单递归神经网络在内的一系列架构中，朝着可证明的长度和组合泛化迈出了第一步。根据架构的不同，我们证明了不同程度的表示识别的必要性，例如与真实表示具有线性或排列关系。

    Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization.
    
[^23]: 通过扩充改进权重空间网络的泛化能力

    Improved Generalization of Weight Space Networks via Augmentations

    [https://arxiv.org/abs/2402.04081](https://arxiv.org/abs/2402.04081)

    通过扩充权重空间的数据集，采用MixUp方法，我们改进了权重空间网络的泛化能力和性能。

    

    深度权重空间（DWS）中的学习是一个新兴的研究方向，神经网络通过处理其他神经网络的权重来进行学习，它在2D和3D神经场（INRs，NeRFs）以及对其他类型神经网络进行推理方面有广泛应用。然而，权重空间模型往往容易受到过拟合的影响。我们通过实证分析了过拟合的原因，并发现一个关键原因是DWS数据集的缺乏多样性。虽然一个给定的对象可以被许多不同的权重配置所表示，但典型的INR训练集未能捕捉到表示同一对象的不同INR之间的变异性。为了解决这个问题，我们探索了权重空间中的数据扩充策略，并提出了适用于权重空间的MixUp方法。我们在两个设置中证明了这些方法的有效性。在分类任务中，它们的性能提升类似于拥有多达10倍的数据量。在自监督对比学习中，它们产生了实质性的改进。

    Learning in deep weight spaces (DWS), where neural networks process the weights of other neural networks, is an emerging research direction, with applications to 2D and 3D neural fields (INRs, NeRFs), as well as making inferences about other types of neural networks. Unfortunately, weight space models tend to suffer from substantial overfitting. We empirically analyze the reasons for this overfitting and find that a key reason is the lack of diversity in DWS datasets. While a given object can be represented by many different weight configurations, typical INR training sets fail to capture variability across INRs that represent the same object. To address this, we explore strategies for data augmentation in weight spaces and propose a MixUp method adapted for weight spaces. We demonstrate the effectiveness of these methods in two setups. In classification, they improve performance similarly to having up to 10 times more data. In self-supervised contrastive learning, they yield substanti
    
[^24]: 一个部分观察到的奖励状态在RLHF中的框架

    A Framework for Partially Observed Reward-States in RLHF

    [https://arxiv.org/abs/2402.03282](https://arxiv.org/abs/2402.03282)

    这篇论文提出了一个针对RLHF的框架，在其中考虑了部分观察到的奖励状态，并通过将基数反馈和决斗反馈缩减为PORRL形式进行了建模和算法开发。

    

    最近几年来，强化学习从人类反馈（RLHF）的研究因其在LLMs的发展中起到的作用而变得重要。神经科学研究表明，人类对刺激的反应已知依赖于部分观察到的“内部状态”。不幸的是，当前的RLHF模型没有考虑到这一点。此外，大多数RLHF模型没有考虑到中间反馈，在实证研究中变得越来越重要，可以帮助提高样本复杂性和对齐性。为了解决这些局限性，我们将RLHF建模为部分观察到的奖励状态的强化学习（PORRL）。我们展示了从RLHF中两种主要形式的人类反馈 - 基数反馈和决斗反馈到PORRL的缩减。对于基数反馈，我们开发了通用的统计高效算法，并将它们实例化为POR-UCRL和POR-UCBVI。对于决斗反馈，我们表明，简单的基数反馈缩减不能达到亚线性的决斗回归。

    The study of reinforcement learning from human feedback (RLHF) has gained prominence in recent years due to its role in the development of LLMs. Neuroscience research shows that human responses to stimuli are known to depend on partially-observed "internal states." Unfortunately current models of RLHF do not take take this into consideration. Moreover most RLHF models do not account for intermediate feedback, which is gaining importance in empirical work and can help improve both sample complexity and alignment. To address these limitations, we model RLHF as reinforcement learning with partially observed reward-states (PORRL). We show reductions from the the two dominant forms of human feedback in RLHF - cardinal and dueling feedback to PORRL. For cardinal feedback, we develop generic statistically efficient algorithms and instantiate them to present POR-UCRL and POR-UCBVI. For dueling feedback, we show that a naive reduction to cardinal feedback fails to achieve sublinear dueling regr
    
[^25]: 位置编码有助于循环神经网络处理大词汇量

    Positional Encoding Helps Recurrent Neural Networks Handle a Large Vocabulary

    [https://arxiv.org/abs/2402.00236](https://arxiv.org/abs/2402.00236)

    本研究探讨了位置编码在循环神经网络中的作用，发现即使与RNN结合使用，位置编码仍然有效，尤其是在处理大词汇量和多样观察结果时。这为使用输入驱动和自主时间表示的组合研究提供了新的方向，同时研究结果也对神经元振荡的生物学意义提供了讨论。

    

    本研究讨论了位置编码在利用合成基准测试的循环神经网络（RNN）中的影响。位置编码将时间序列中的数据点“时间戳化”，并补充了Transformer神经网络的能力，后者缺乏表示数据顺序的内在机制。相反，RNN可以自己对数据点进行时间编码，使得它们对位置编码的使用似乎是“冗余”的。然而，经验研究表明，即使与RNN结合使用，位置编码的有效性仍然很高，特别是用于处理产生多样观察结果的大词汇量。这些发现为循环神经网络上的新的研究方向铺平了道路，涉及输入驱动和自主时间表示的组合。此外，本研究还讨论了计算/模拟结果的生物学意义，考虑到位置编码的正弦实现与神经元振荡之间的关联。

    This study discusses the effects of positional encoding on recurrent neural networks (RNNs) utilizing synthetic benchmarks. Positional encoding "time-stamps" data points in time series and complements the capabilities of Transformer neural networks, which lack an inherent mechanism for representing the data order. By contrast, RNNs can encode the temporal information of data points on their own, rendering their use of positional encoding seemingly "redundant". Nonetheless, empirical investigations reveal the effectiveness of positional encoding even when coupled with RNNs, specifically for handling a large vocabulary that yields diverse observations. These findings pave the way for a new line of research on RNNs, concerning the combination of input-driven and autonomous time representation. Additionally, biological implications of the computational/simulational results are discussed, in the light of the affinity between the sinusoidal implementation of positional encoding and neural os
    
[^26]: 数据多样性对鲁棒指令调整至关重要

    Data Diversity Matters for Robust Instruction Tuning

    [https://arxiv.org/abs/2311.14736](https://arxiv.org/abs/2311.14736)

    数据多样性对鲁棒指令调整非常重要，我们提出了一种新算法(QDIT)，通过同时控制数据集的多样性和质量，我们深入研究了多样性和质量对指令调整性能的影响，并得出了两个关键观点。

    

    最近的研究表明，通过精选高质量且多样化的指令调整数据集，我们可以显著提高指令跟随能力。然而，创建这样的数据集非常困难，大多数研究依赖于手动精选或专有语言模型。自动数据精选很困难，因为仍不清楚如何为指令调整定义多样性，多样性和质量如何相互关联，以及如何优化数据集的质量和多样性。为解决这些问题，我们提出了一种新算法，质量-多样性指令调整(QDIT)。QDIT提供了一种简单的方法来同时控制数据集的多样性和质量，使我们能够深入研究多样性和质量对指令调整性能的影响。从这项研究中，我们得出了两个关键观点：(1)数据多样性和质量之间存在自然的权衡关系，(2)增加数据多样性显著提高最坏情况下的指令跟随性能。

    Recent works have shown that by curating high quality and diverse instruction tuning datasets, we can significantly improve instruction-following capabilities. However, creating such datasets is difficult and most works rely on manual curation or proprietary language models. Automatic data curation is difficult as it is still not clear how we can define diversity for instruction tuning, how diversity and quality depend on one other, and how we can optimize dataset quality and diversity. To resolve these issue, we propose a new algorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT provides a simple method to simultaneously control dataset diversity and quality, allowing us to conduct an in-depth study on the effect of diversity and quality on instruction tuning performance. From this study we draw two key insights (1) there is a natural tradeoff between data diversity and quality and (2) increasing data diversity significantly improves the worst case instruction following perform
    
[^27]: 深度增强：在激活空间中使用自监督学习进行数据增强

    Deep Augmentation: Self-Supervised Learning with Transformations in Activation Space

    [https://arxiv.org/abs/2303.14537](https://arxiv.org/abs/2303.14537)

    深度增强是一种利用dropout或PCA在神经网络中转换目标层的方法，有效改善性能和泛化能力。在对比学习任务中，在Transformers、ResNets和图神经网络等基础模型上，通过深度增强实现了显著的性能提升，但在监督问题上效果相反。

    

    我们提出了一种称为深度增强的方法，通过使用辍学或PCA来转换神经网络中的目标层，以提高性能和泛化能力。我们通过在自然语言处理、计算机视觉和图学习中的对比学习任务上进行大量实验来展示深度增强。 我们观察到在对比学习的基础模型中，如Transformers、ResNets和图神经网络上深度增强能够带来显著的性能提升，但在相应的监督问题上观察到相反的效果。 我们的分析表明，深度增强减轻了层之间的相互适应，即"崩溃"形式的问题。 我们利用这一观察结果制定了一种选择目标层的方法；特别是，我们的实验表明，用深度增强定位更深层次的层要优于增强输入数据。 这种方法的简单网络和模态无关性使其

    arXiv:2303.14537v2 Announce Type: replace-cross  Abstract: We introduce Deep Augmentation, an approach to implicit data augmentation using dropout or PCA to transform a targeted layer within a neural network to improve performance and generalization. We demonstrate Deep Augmentation through extensive experiments on contrastive learning tasks in NLP, computer vision, and graph learning. We observe substantial performance gains with Transformers, ResNets, and Graph Neural Networks as the underlying models in contrastive learning, but observe inverse effects on the corresponding supervised problems. Our analysis suggests that Deep Augmentation alleviates co-adaption between layers, a form of "collapse." We use this observation to formulate a method for selecting which layer to target; in particular, our experimentation reveals that targeting deeper layers with Deep Augmentation outperforms augmenting the input data. The simple network- and modality-agnostic nature of this approach enables
    
[^28]: 健康文本简化：消化癌症教育的注释语料库和增强学习的新策略

    Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning. (arXiv:2401.15043v1 [cs.CL])

    [http://arxiv.org/abs/2401.15043](http://arxiv.org/abs/2401.15043)

    该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。

    

    目标：健康教育材料的阅读水平显著影响信息的可理解性和可接触性，特别是对于少数族裔人群。许多患者教育资源超过了广泛接受的标准的阅读水平和复杂性。在健康信息中，急需高性能的文本简化模型以增强传播和识字能力。这种需要在癌症教育中尤为迫切，有效的预防和筛查教育可以大大减少发病率和死亡率。方法：我们引入了简化的消化癌症（SimpleDC）并行语料库，用于健康文本简化研究。利用SimpleDC和现有的Med-EASi语料库，我们探索了基于大型语言模型（LLM）的简化方法，包括微调、增强学习（RL）、增强学习与人类反馈（RLHF）、领域自适应和基于提示的应用。

    Objective: The reading level of health educational materials significantly influences information understandability and accessibility, particularly for minoritized populations. Many patient educational resources surpass the reading level and complexity of widely accepted standards. There is a critical need for high-performing text simplification models in health information to enhance dissemination and literacy. This need is particularly acute in cancer education, where effective prevention and screening education can substantially reduce morbidity and mortality.  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel corpus of cancer education materials tailored for health text simplification research. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore Large Language Model (LLM)-based simplification methods, including fine-tuning, reinforcement learning (RL), reinforcement learning with human feedback (RLHF), domain adaptation, and prompt-based app
    
[^29]: 使用深度神经网络从多细胞图中学习动力学

    Learning Dynamics from Multicellular Graphs with Deep Neural Networks. (arXiv:2401.12196v1 [physics.bio-ph] CROSS LISTED)

    [http://arxiv.org/abs/2401.12196](http://arxiv.org/abs/2401.12196)

    本研究提出了使用基于图的深度神经网络来预测多细胞集合体的运动能力。实验结果表明，这种方法能够准确地识别多细胞生物系统中的复杂图特征，并超越传统机械模型的能力。同时，研究者建议通过合作努力来构建一个多细胞数据库，以进一步推动多细胞动力学研究的发展。

    

    多细胞自组装的推断是理解形态发生的核心问题，包括胚胎、器官结构、肿瘤等。然而，很难找到能够指示多细胞动力学的结构特征。在这里，我们提出利用基于图的深度神经网络（GNN）的预测能力来发现可以预测动力学的重要图特征。为了证明，我们应用了一个物理学启发的 GNN（piGNN）来预测多细胞集合体的运动能力，从它们在实验和模拟中的位置快照中。我们证明了 piGNN 能够在多细胞生物系统的复杂图特征中导航，这是经典机械模型无法实现的。随着越来越多的多细胞数据的积累，我们提出可以进行合作努力，创建一个多细胞数据库（MDB），从中可以构建一个大型的多细胞图模型。

    The inference of multicellular self-assembly is the central quest of understanding morphogenesis, including embryos, organoids, tumors, and many others. However, it has been tremendously difficult to identify structural features that can indicate multicellular dynamics. Here we propose to harness the predictive power of graph-based deep neural networks (GNN) to discover important graph features that can predict dynamics. To demonstrate, we apply a physically informed GNN (piGNN) to predict the motility of multicellular collectives from a snapshot of their positions both in experiments and simulations. We demonstrate that piGNN is capable of navigating through complex graph features of multicellular living systems, which otherwise can not be achieved by classical mechanistic models. With increasing amounts of multicellular data, we propose that collaborative efforts can be made to create a multicellular data bank (MDB) from which it is possible to construct a large multicellular graph m
    
[^30]: 最新进展的命名实体识别综述

    A survey on recent advances in named entity recognition. (arXiv:2401.10825v1 [cs.CL])

    [http://arxiv.org/abs/2401.10825](http://arxiv.org/abs/2401.10825)

    这篇综述调查了最近的命名实体识别研究进展，并提供了对不同算法性能的深度比较，还探讨了数据集特征对方法行为的影响。

    

    命名实体识别旨在从文本中提取出命名真实世界对象的子字符串，并确定其类型（例如，是否指人物或组织）。在本综述中，我们首先概述了最近流行的方法，同时还关注了基于图和变换器的方法，包括很少在其他综述中涉及的大型语言模型（LLMs）。其次，我们重点介绍了针对稀缺注释数据集设计的方法。第三，我们评估了主要命名实体识别实现在各种具有不同特征（领域、规模和类别数）的数据集上的性能。因此，我们提供了一种从未同时考虑的算法的深度比较。我们的实验揭示了数据集特征如何影响我们比较的方法的行为。

    Named Entity Recognition seeks to extract substrings within a text that name real-world objects and to determine their type (for example, whether they refer to persons or organizations). In this survey, we first present an overview of recent popular approaches, but we also look at graph- and transformer- based methods including Large Language Models (LLMs) that have not had much coverage in other surveys. Second, we focus on methods designed for datasets with scarce annotations. Third, we evaluate the performance of the main NER implementations on a variety of datasets with differing characteristics (as regards their domain, their size, and their number of classes). We thus provide a deep comparison of algorithms that are never considered together. Our experiments shed some light on how the characteristics of datasets affect the behavior of the methods that we compare.
    
[^31]: 通过Gaunt张量积在傅里叶基础上实现高效的等变操作

    Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products. (arXiv:2401.10216v1 [cs.LG])

    [http://arxiv.org/abs/2401.10216](http://arxiv.org/abs/2401.10216)

    该论文提出了一种加速计算不可约表示张量积的方法，通过将等变操作基础从球形谐波改变为2D傅立叶基础，实现了对E(3)群的等变神经网络的高效建模。

    

    在建模现实世界应用中的3D数据时，发展E(3)群的等变神经网络起着重要作用。实现这种等变性主要涉及到不可约表示（irreps）的张量积。然而，随着使用高阶张量，这些操作的计算复杂性显著增加。在这项工作中，我们提出了一种系统的方法来大大加速不可约表示的张量积的计算。我们将常用的Clebsch-Gordan系数与Gaunt系数进行了数学上的连接，Gaunt系数是三个球形谐波乘积的积分。通过Gaunt系数，不可约表示的张量积等价于由球形谐波表示的球形函数之间的乘法。这种观点进一步使我们能够将等变操作的基础从球形谐波改变为2D傅立叶基础。因此，球形函数之间的乘法可以在傅立叶基础上进行。

    Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions 
    
[^32]: E3x：简化的$\mathrm{E}(3)$等变深度学习

    E3x: $\mathrm{E}(3)$-Equivariant Deep Learning Made Easy. (arXiv:2401.07595v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.07595](http://arxiv.org/abs/2401.07595)

    E3x是一种简化了$\mathrm{E}(3)$等变深度学习的软件包，通过内置等变性实现更高的数据效率和准确性。

    

    本文介绍了E3x，一种用于构建神经网络的软件包，该网络在三维空间的平移、旋转和反射方面等变。与普通神经网络相比，$\mathrm{E}(3)$-等变模型在输入和/或输出数据是与三维对象相关的数量时具有优势。这是因为此类数量（例如位置）的数值通常取决于所选择的坐标系统。在参考系的变换下，这些值会可预测地发生变化，但对于普通的机器学习模型来说，学习其潜在规则可能很困难。使用内置的$\mathrm{E}(3)$-等变性，神经网络可以保证完全满足相关的变换规则，从而实现更高的数据效率和准确性。E3x的代码可从https://github.com/google-research/e3x获得，还提供了详细的文档和使用示例。

    This work introduces E3x, a software package for building neural networks that are equivariant with respect to the Euclidean group $\mathrm{E}(3)$, consisting of translations, rotations, and reflections of three-dimensional space. Compared to ordinary neural networks, $\mathrm{E}(3)$-equivariant models promise benefits whenever input and/or output data are quantities associated with three-dimensional objects. This is because the numeric values of such quantities (e.g. positions) typically depend on the chosen coordinate system. Under transformations of the reference frame, the values change predictably, but the underlying rules can be difficult to learn for ordinary machine learning models. With built-in $\mathrm{E}(3)$-equivariance, neural networks are guaranteed to satisfy the relevant transformation rules exactly, resulting in superior data efficiency and accuracy. The code for E3x is available from https://github.com/google-research/e3x, detailed documentation and usage examples ca
    
[^33]: 使用梯度下降法解决非常数核的核岭回归

    Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])

    [http://arxiv.org/abs/2311.01762](http://arxiv.org/abs/2311.01762)

    本文研究了使用梯度下降法解决非常数核的核岭回归。通过在训练过程中逐渐减小带宽，避免了超参数选择的需求，并提出了一种带宽更新方案，证明了其优于使用常数带宽的方法。

    

    核岭回归（KRR）是线性岭回归的推广，它在数据中是非线性的，但在参数中是线性的。解决方案可以通过闭式解获得，其中包括矩阵求逆，也可以通过梯度下降迭代获得。本文研究了在训练过程中改变核函数的方法。我们从理论上探讨了这对模型复杂性和泛化性能的影响。基于我们的发现，我们提出了一种用于平移不变核的带宽更新方案，其中带宽在训练过程中逐渐减小至零，从而避免了超参数选择的需要。我们在真实和合成数据上展示了在训练过程中逐渐减小带宽的优于使用常数带宽，通过交叉验证和边缘似然最大化选择的带宽。我们还从理论和实证上证明了使用逐渐减小的带宽时，我们能够...

    Kernel ridge regression, KRR, is a generalization of linear ridge regression that is non-linear in the data, but linear in the parameters. The solution can be obtained either as a closed-form solution, which includes a matrix inversion, or iteratively through gradient descent. Using the iterative approach opens up for changing the kernel during training, something that is investigated in this paper. We theoretically address the effects this has on model complexity and generalization. Based on our findings, we propose an update scheme for the bandwidth of translational-invariant kernels, where we let the bandwidth decrease to zero during training, thus circumventing the need for hyper-parameter selection. We demonstrate on real and synthetic data how decreasing the bandwidth during training outperforms using a constant bandwidth, selected by cross-validation and marginal likelihood maximization. We also show theoretically and empirically that using a decreasing bandwidth, we are able to
    
[^34]: 分层随机平滑

    Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])

    [http://arxiv.org/abs/2310.16221](http://arxiv.org/abs/2310.16221)

    分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。

    

    真实世界的数据是复杂的，通常由可分解为多个实体的对象组成（例如，将图像分解为像素，将图形分解为相互连接的节点）。随机平滑是一种强大的框架，可以使模型在其输入的微小变化上具有证明的鲁棒性-通过在分类之前随机添加噪声来保证多数投票的鲁棒性。然而，当对手不是任意干扰整个对象（例如图像），而是对象的某个实体的子集（例如像素）时，通过随机平滑对这种复杂数据进行鲁棒性认证是具有挑战性的。作为解决方案，我们引入了分层随机平滑：我们通过仅在随机选择的实体子集上添加随机噪声来部分平滑对象。通过以比现有方法更有针对性的方式添加噪声，我们获得更强的鲁棒性保证，同时保持高准确性。我们使用不同的噪声分布初始化分层平滑，得到了新的鲁棒性保证。

    Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
    
[^35]: 等变深度权重空间对齐

    Equivariant Deep Weight Space Alignment. (arXiv:2310.13397v1 [cs.LG])

    [http://arxiv.org/abs/2310.13397](http://arxiv.org/abs/2310.13397)

    本论文提出了一个名为Deep-Align的新框架，用于学习解决权重对齐问题，以加速对齐过程并提高其质量。

    

    深度网络的排列对称性使得简单操作如模型平均和相似度估计变得困难。在许多情况下，对齐网络的权重，即找到它们之间最优排列，是必要的。更一般地说，权重对齐对于广泛的应用非常重要，从模型合并，通过探索深度神经网络的优化空间，到定义神经网络之间有意义的距离函数。不幸的是，权重对齐是一个NP-hard问题。先前的研究主要集中在解决对齐问题的松弛版本，导致方法耗时或者次优解。为了加速对齐过程并提高其质量，我们提出了一个名为Deep-Align的新框架，旨在学习解决权重对齐问题。为此，我们首先证明了权重对齐遵循两个基本对称性，然后提出了一个深度架构。

    Permutation symmetries of deep networks make simple operations like model averaging and similarity estimation challenging. In many cases, aligning the weights of the networks, i.e., finding optimal permutations between their weights, is necessary. More generally, weight alignment is essential for a wide range of applications, from model merging, through exploring the optimization landscape of deep neural networks, to defining meaningful distance functions between neural networks. Unfortunately, weight alignment is an NP-hard problem. Prior research has mainly focused on solving relaxed versions of the alignment problem, leading to either time-consuming methods or sub-optimal solutions. To accelerate the alignment process and improve its quality, we propose a novel framework aimed at learning to solve the weight alignment problem, which we name Deep-Align. To that end, we first demonstrate that weight alignment adheres to two fundamental symmetries and then, propose a deep architecture 
    
[^36]: 在概率测度空间中加速优化

    Accelerating optimization over the space of probability measures. (arXiv:2310.04006v1 [math.OC])

    [http://arxiv.org/abs/2310.04006](http://arxiv.org/abs/2310.04006)

    本研究研究了在概率测度空间中加速优化的问题，提出了一种类似于欧几里得空间中基于矩方法的哈密顿流方法，并证明了其可以达到任意高阶的收敛速度。

    

    梯度优化方法的加速是一个非常实用和理论上有意义的问题，特别是在机器学习应用中。大多数研究都集中在欧几里得空间的优化上，但考虑到在许多机器学习问题中需要在概率测度空间上进行优化，研究这种情况下的加速梯度方法是很有意义的。为此，我们引入了一种类似于欧几里得空间中基于矩方法的哈密顿流方法。我们证明了基于这种方法的算法可以达到任意高阶的收敛速度。数值实例证明了我们的论断。

    Acceleration of gradient-based optimization methods is an issue of significant practical and theoretical interest, particularly in machine learning applications. Most research has focused on optimization over Euclidean spaces, but given the need to optimize over spaces of probability measures in many machine learning problems, it is of interest to investigate accelerated gradient methods in this context too. To this end, we introduce a Hamiltonian-flow approach that is analogous to moment-based approaches in Euclidean space. We demonstrate that algorithms based on this approach can achieve convergence rates of arbitrarily high order. Numerical examples illustrate our claim.
    
[^37]: 通过协同扩散恢复似然学习基于能量的模型

    Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood. (arXiv:2309.05153v1 [stat.ML])

    [http://arxiv.org/abs/2309.05153](http://arxiv.org/abs/2309.05153)

    本文通过协同扩散恢复似然（CDRL）提出了一种方法，用于学习和采样一系列基于能量的模型（EBMs），通过在不断嘈杂化的数据集版本上定义不同噪声水平的EBMs，并与初始化模型配对协同训练。这种方法旨在关闭EBMs和其他生成框架之间的样本质量差距。

    

    在高维数据上使用最大似然估计训练能量基准模型（EBMs）可能具有挑战性且耗时较长。因此，EBMs和其他生成框架（如GANs和扩散模型）之间存在明显的样本质量差距。为了弥补这一差距，受最近通过最大化扩散恢复似然（DRL）来学习EBMs的努力的启发，我们提出了协同扩散恢复似然（CDRL），一种有效的方法来可行地学习和从一系列EBMs中进行采样，这些EBMs定义在越来越嘈杂的数据集版本上，并与每个EBM的初始化模型配对。在每个噪声水平上，初始化模型学习在EBM的采样过程中分摊，而两个模型在协同训练框架内共同估计。初始化模型生成的样本作为起始点，经过EBM的几个采样步骤进行改进。通过改进后的样本，通过最大化恢复似然来优化EBM。

    Training energy-based models (EBMs) with maximum likelihood estimation on high-dimensional data can be both challenging and time-consuming. As a result, there a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximimizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versons of a dataset, paired with an initializer model for each EBM. At each noise level, the initializer model learns to amortize the sampling process of the EBM, and the two models are jointly estimated within a cooperative training framework. Samples from the initializer serve as starting points that are refined by a few sampling steps from the EBM. With the refined samples, the EBM is optimized by maximizing recovery likelihood, while t
    
[^38]: 使用规范化流计算分子的激发态

    Computing excited states of molecules using normalizing flows. (arXiv:2308.16468v1 [physics.chem-ph])

    [http://arxiv.org/abs/2308.16468](http://arxiv.org/abs/2308.16468)

    使用规范化流计算分子的激发态，通过逼近波函数并优化基函数的线性空间内的近似。该方法在计算量子系统中取得了准确和有效的结果，并在能量预测准确性和基组收敛速度方面进行了显著改善。

    

    我们提出了一种新的非线性变分框架，可以同时计算量子系统的基态和激发态。我们的方法基于通过与规范化流的组合来逼近波函数，这些波函数位于基函数的线性空间中，并对其进行优化。我们通过计算三原子H$_2$S分子的大量振动态以及典型的单电子系统（包括氢原子、分子氢离子和碳原子在单激发电子近似下的基态和多个激发态）来证明我们方法的准确性和效率。结果表明，即使使用参数较少的规范化流，能量预测的准确性和基组收敛速度也有显著改善。该方法也可以被看作是对最佳捕捉底层物理的一组内禀坐标进行优化的过程。

    We present a new nonlinear variational framework for simultaneously computing ground and excited states of quantum systems. Our approach is based on approximating wavefunctions in the linear span of basis functions that are augmented and optimized \emph{via} composition with normalizing flows. The accuracy and efficiency of our approach are demonstrated in the calculations of a large number of vibrational states of the triatomic H$_2$S molecule as well as ground and several excited electronic states of prototypical one-electron systems including the hydrogen atom, the molecular hydrogen ion, and a carbon atom in a single-active-electron approximation. The results demonstrate significant improvements in the accuracy of energy predictions and accelerated basis-set convergence even when using normalizing flows with a small number of parameters. The present approach can be also seen as the optimization of a set of intrinsic coordinates that best capture the underlying physics within the gi
    
[^39]: 一种无需参数的改进二位协方差估计器

    A Parameter-Free Two-Bit Covariance Estimator with Improved Operator Norm Error Rate. (arXiv:2308.16059v1 [stat.ML])

    [http://arxiv.org/abs/2308.16059](http://arxiv.org/abs/2308.16059)

    提出了一种无需参数的二位协方差估计器，通过使用变化的抖动尺度，解决了在协方差矩阵对角线主导情况下估计器与样本协方差之间的算子范数误差差距以及依赖未知参数的抖动尺度问题。

    

    最近Dirksen, Maly and Rauhut在《Annals of Statistics》上开发了一种使用每个条目两位的协方差矩阵估计器。该估计器在一般亚高斯分布下达到了近似极小化速率，但也存在两个问题：理论上，在协方差矩阵的对角线由少数条目主导时，其估计器与样本协方差之间存在本质上的算子范数误差差距；实际上，其性能严重依赖于需要根据一些未知参数进行调整的抖动尺度。在这项工作中，我们提出了一种同时解决这两个问题的新型二位协方差矩阵估计器。与Dirksen等人采用的均匀抖动相关的符号量化器不同，我们采用了受多位均匀量化器启发的三角抖动器之后再进行二位量化。通过使用各个条目之间变化的抖动尺度，我们的估计器获得了改进的算子范数误差率，该误差率取决于...

    A covariance matrix estimator using two bits per entry was recently developed by Dirksen, Maly and Rauhut [Annals of Statistics, 50(6), pp. 3538-3562]. The estimator achieves near minimax rate for general sub-Gaussian distributions, but also suffers from two downsides: theoretically, there is an essential gap on operator norm error between their estimator and sample covariance when the diagonal of the covariance matrix is dominated by only a few entries; practically, its performance heavily relies on the dithering scale, which needs to be tuned according to some unknown parameters. In this work, we propose a new 2-bit covariance matrix estimator that simultaneously addresses both issues. Unlike the sign quantizer associated with uniform dither in Dirksen et al., we adopt a triangular dither prior to a 2-bit quantizer inspired by the multi-bit uniform quantizer. By employing dithering scales varying across entries, our estimator enjoys an improved operator norm error rate that depends o
    
[^40]: Hessian-Aware Bayesian Optimization for Decision Making Systems - 感知海森贝叶斯优化在决策系统中的应用

    Hessian-Aware Bayesian Optimization for Decision Making Systems. (arXiv:2308.00629v1 [cs.LG])

    [http://arxiv.org/abs/2308.00629](http://arxiv.org/abs/2308.00629)

    本文介绍了一种感知海森贝叶斯优化算法，旨在解决决策系统优化中梯度反馈稀缺或无效的问题。通过引入紧凑的多层架构和角色概念，并利用感知海森贝叶斯优化方法对参数进行优化，作者实现了对复杂决策系统的高效优化。

    

    许多优化决策系统的方法依赖于梯度方法，需要从环境中获取有信息量的反馈。然而，当反馈稀缺或者无信息时，这些方法可能导致性能较差。贝叶斯优化等无导数方法可以减少对梯度反馈质量的依赖，但在复杂决策系统的高维环境中往往难以扩展。如果系统需要多个参与者之间的互动来实现共同目标，这个问题就加剧了。为了解决维度问题，我们提出了一种紧凑的多层架构，通过角色的概念来建模参与者之间的动态。此外，我们还引入了感知海森贝叶斯优化来高效地优化由大量参数参数化的多层架构。实验结果表明，我们的方法(HA-GP-UCB)在效果上是有效的。

    Many approaches for optimizing decision making systems rely on gradient based methods requiring informative feedback from the environment. However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance. Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making systems. This problem is exacerbated if the system requires interactions between several actors cooperating to accomplish a shared goal. To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of actor interactions through the concept of role. Additionally, we introduce Hessian-aware Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters. Experimental results demonstrate that our method (HA-GP-UCB) works effectiv
    
[^41]: 在重复的多单位付费拍卖中学习

    Learning in Repeated Multi-Unit Pay-As-Bid Auctions. (arXiv:2307.15193v1 [cs.GT])

    [http://arxiv.org/abs/2307.15193](http://arxiv.org/abs/2307.15193)

    本论文研究了在重复的多单位付费拍卖中学习如何出价的问题。通过在离线设置中优化出价向量，并利用多项式时间动态规划方案，设计了具有多项式时间和空间复杂度的在线学习算法。

    

    受碳排放交易方案、国债拍卖和采购拍卖的启发，这些都涉及拍卖同质的多个单位，我们考虑了如何在重复的多单位付费拍卖中学习如何出价的问题。在每个拍卖中，大量（相同的）物品将被分配给最高的出价，每个中标价等于出价本身。由于行动空间的组合性质，学习如何在付费拍卖中出价是具有挑战性的。为了克服这个挑战，我们关注离线设置，其中投标人通过只能访问其他投标人过去提交的出价来优化他们的出价向量。我们证明了离线问题的最优解可以使用多项式时间动态规划（DP）方案来获得。我们利用DP方案的结构，设计了具有多项式时间和空间复杂度的在线学习算法。

    Motivated by Carbon Emissions Trading Schemes, Treasury Auctions, and Procurement Auctions, which all involve the auctioning of homogeneous multiple units, we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each of the winning bids is equal to the bid itself. The problem of learning how to bid in pay-as-bid auctions is challenging due to the combinatorial nature of the action space. We overcome this challenge by focusing on the offline setting, where the bidder optimizes their vector of bids while only having access to the past submitted bids by other bidders. We show that the optimal solution to the offline problem can be obtained using a polynomial time dynamic programming (DP) scheme. We leverage the structure of the DP scheme to design online learning algorithms with polynomial time and space complexity under fu
    
[^42]: 基于优化和数据驱动的 sigma-point 卡尔曼滤波器与非线性未知输入估计器

    Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via Optimization and Data-driven Approach for Dynamic Systems. (arXiv:2306.12361v1 [eess.SY])

    [http://arxiv.org/abs/2306.12361](http://arxiv.org/abs/2306.12361)

    本文提出了一种不需要假设未知输入为线性的方法，结合非线性优化和数据驱动方法可以实现对未知输入的估计，并通过联合 sigma-point 变换方案将状态和未知输入的不确定性纳入估计中，确保其稳定性。这个方法适用于许多智能自主系统。

    

    多数关于状态和未知输入(UI)估计的文献都要求UI是线性的，这个限制可能太严格了，因为它并不适用于许多智能自主系统。为了克服这一限制，我们提出了一种无导数未知输入 Sigma-point 卡尔曼滤波器(SPKE-nUI)，其中 SPKF 与普通非线性 UI 估计器相互连接，可以通过非线性优化和数据驱动方法实现。非线性 UI 估计器使用后验状态估计，这对状态预测误差不太敏感。此外，我们引入了联合 sigma-point 变换方案，将状态和 UI 的不确定性纳入 SPKF-nUI 的估计中。深入的随机稳定性分析证明了在合理的假设下，所提出的 SPKF-nUI 可以产生指数级收敛的估计误差界限。最后，我们在基于模拟的路面车辆控制问题上进行了两个案例研究。

    Most works on joint state and unknown input (UI) estimation require the assumption that the UIs are linear; this is potentially restrictive as it does not hold in many intelligent autonomous systems. To overcome this restriction and circumvent the need to linearize the system, we propose a derivative-free Unknown Input Sigma-point Kalman Filter (SPKF-nUI) where the SPKF is interconnected with a general nonlinear UI estimator that can be implemented via nonlinear optimization and data-driven approaches. The nonlinear UI estimator uses the posterior state estimate which is less susceptible to state prediction error. In addition, we introduce a joint sigma-point transformation scheme to incorporate both the state and UI uncertainties in the estimation of SPKF-nUI. An in-depth stochastic stability analysis proves that the proposed SPKF-nUI yields exponentially converging estimation error bounds under reasonable assumptions. Finally, two case studies are carried out on a simulation-based ri
    
[^43]: 深度图核点过程

    Deep graph kernel point processes. (arXiv:2306.11313v1 [stat.ML])

    [http://arxiv.org/abs/2306.11313](http://arxiv.org/abs/2306.11313)

    本文提出了一种基于潜在图拓扑的图点过程方法，并开发了一种新颖的深度图核来描述事件之间的触发和抑制效应，该方法在合成和实际数据集上具有优越性。

    

    点过程模型广泛用于分析图中异步事件，反映不同类型事件之间的相互影响。预测未来事件的时间和类型是一项关键任务，并且图的大小和拓扑结构增加了问题的难度。最近的神经点过程模型揭示了捕捉复杂的事件类别之间依赖关系的可能性。然而，这些方法在每个目标事件类型的强度计算中使用了包括所有事件类别在内的未经滤波的事件记录。在本文中，我们提出了一种基于潜在图拓扑的图点过程方法。对应的无向图具有代表事件类别的节点和表示潜在贡献关系的边。然后，我们开发了一种新颖的深度图核来描述事件之间的触发和抑制效应。本质影响结构通过图神经网络-based的局部邻域信息聚合进行了融合。我们在合成和实际数据集上展示了我们提出的方法比最先进的模型更具优越性。

    Point process models are widely used to analyze asynchronous events occurring within a graph that reflect how different types of events influence one another. Predicting future events' times and types is a crucial task, and the size and topology of the graph add to the challenge of the problem. Recent neural point process models unveil the possibility of capturing intricate inter-event-category dependencies. However, such methods utilize an unfiltered history of events, including all event categories in the intensity computation for each target event type. In this work, we propose a graph point process method where event interactions occur based on a latent graph topology. The corresponding undirected graph has nodes representing event categories and edges indicating potential contribution relationships. We then develop a novel deep graph kernel to characterize the triggering and inhibiting effects between events. The intrinsic influence structures are incorporated via the graph neural
    
[^44]: 关于神经网络作为无限树状概率图模型的论文研究

    On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models. (arXiv:2305.17583v1 [stat.ML])

    [http://arxiv.org/abs/2305.17583](http://arxiv.org/abs/2305.17583)

    本文提出了一种创新方法，通过构建与神经网络完全对应的无限树状PGMs来解决深度神经网络(DNNs)缺乏PGMs的精确语义和明确定义的概率解释的问题。研究发现DNNs在前向传播时确实执行PGM推断的近似，这与现有研究不同，它阐明了DNNs对PGMs中的精确推理的更直接近似，潜在的好处包括改进DNNs的教学和解释，以及能够合并PGMs和DNNs的算法。

    

    深度神经网络(DNNs)缺乏概率图模型(PGMs)的精确语义和明确定义的概率解释。本文提出了一种创新方法，通过构建与神经网络完全对应的无限树状PGMs来解决这个问题。我们的研究揭示了DNNs在前向传播期间确实执行PGM推断的近似，这与曾经的神经网络描述为核机器或无限大小的高斯过程的现有研究不同，它阐明了DNNs对PGMs中的精确推理的更直接近似。潜在的好处包括改进DNNs的教学和解释，以及能够合并PGMs和DNNs的算法。

    Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs.
    
[^45]: 通过半监督顺序变分贝叶斯框架实现软机器人的跨域迁移学习和状态推断

    Cross-domain Transfer Learning and State Inference for Soft Robots via a Semi-supervised Sequential Variational Bayes Framework. (arXiv:2303.01693v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.01693](http://arxiv.org/abs/2303.01693)

    本文提出了一个半监督顺序变分贝叶斯框架，用于解决软机器人领域的跨域迁移学习和状态推断问题。该框架可以处理某些机器人配置下存在缺失状态标签的情况，同时引入了特征空间迁移策略，提高了在多个配置下的潜在特征的适应性。

    

    最近，基于数据驱动模型（如深度神经网络）的软机器人建模和状态推断显示出了很大的潜力。然而，深度模型需要大量的数据才能有效地运行，这需要进行详尽和质量良好的数据采集，尤其是状态标签的采集。因此，由于软机器人的传感器化困难和在非结构化环境中收集数据的不便等原因，获取标注的软机器人系统状态数据存在挑战。为了解决这个挑战，本文提出了一个半监督顺序变分贝叶斯（DSVB）框架，用于处理某些机器人配置中存在缺失状态标签的软机器人的迁移学习和状态推断。考虑到软机器人在不同的机器人配置下可能展现出不同的动力学特性，我们还引入了特征空间迁移策略，以促进在多个配置下的潜在特征的适应。

    Recently, data-driven models such as deep neural networks have shown to be promising tools for modelling and state inference in soft robots. However, voluminous amounts of data are necessary for deep models to perform effectively, which requires exhaustive and quality data collection, particularly of state labels. Consequently, obtaining labelled state data for soft robotic systems is challenged for various reasons, including difficulty in the sensorization of soft robots and the inconvenience of collecting data in unstructured environments. To address this challenge, in this paper, we propose a semi-supervised sequential variational Bayes (DSVB) framework for transfer learning and state inference in soft robots with missing state labels on certain robot configurations. Considering that soft robots may exhibit distinct dynamics under different robot configurations, a feature space transfer strategy is also incorporated to promote the adaptation of latent features across multiple config
    
[^46]: Waveflow：将边界条件应用于平滑归一化流的新方法，并以费米波函数为例

    Waveflow: Enforcing boundary conditions in smooth normalizing flows with application to fermionic wave functions. (arXiv:2211.14839v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14839](http://arxiv.org/abs/2211.14839)

    本文介绍了一种新的处理归一化流拓扑问题、将边界条件应用于归一化流的技术、引入了可以被制作成任意次可微的 I-Spline 双射，并将这些技术用于创建一种基于归一化流的费米波函数 Ansatz，从而实现高效训练。

    

    本文提出了四个主要的创新点。首先，我们介绍了一种处理归一化流拓扑问题的新方法。其次，我们描述了一种在归一化流上强制施加特定类别边界条件的技术。第三，我们引入了 I-Spline 双射，它像之前的工作一样利用了样条曲线，但与这些工作不同的是，它可以被制作成任意次可微的。最后，我们使用这些技术创建了 Waveflow，一种基于归一化流的一维多粒子费米波函数的 Ansatz，它可以通过变分量子蒙特卡罗高效地训练，无需 MCMC 或估计归一化常数。为了强制费米波函数所需的反对称性，我们仅在排列群的基本域上训练归一化流，这有效地将其减少为一个边界值问题。

    In this paper, we introduce four main novelties: First, we present a new way of handling the topology problem of normalizing flows. Second, we describe a technique to enforce certain classes of boundary conditions onto normalizing flows. Third, we introduce the I-Spline bijection, which, similar to previous work, leverages splines but, in contrast to those works, can be made arbitrarily often differentiable. And finally, we use these techniques to create Waveflow, an Ansatz for the one-space-dimensional multi-particle fermionic wave functions in real space based on normalizing flows, that can be efficiently trained with Variational Quantum Monte Carlo without the need for MCMC nor estimation of a normalization constant. To enforce the necessary anti-symmetry of fermionic wave functions, we train the normalizing flow only on the fundamental domain of the permutation group, which effectively reduces it to a boundary value problem.
    
[^47]: MixMask: 重新审视Siamese ConvNets的遮盖策略

    MixMask: Revisiting Masking Strategy for Siamese ConvNets. (arXiv:2210.11456v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.11456](http://arxiv.org/abs/2210.11456)

    本文提出了一种新的填充式遮盖策略MixMask，在Siamese ConvNets中实现遮盖和对比学习目标的匹配，提高了Siamese ConvNets的性能并在多个基准测试中实现了最先进的结果。

    

    最近自监督学习的进展将Masked Image Modeling（MIM）和Siamese网络整合成一个统一的框架，利用了两种技术的优点。然而，在Siamese ConvNets中应用传统的基于擦除的遮盖策略时，存在一些未解决的问题，包括（I）在连续处理数据时不能放弃不相关的遮盖区域，导致训练效率低于ViT模型;（II）基于擦除的遮盖与Siamese ConvNets中的对比学习目标不匹配，与MIM方法不同。本文提出了一种称为MixMask的填充式遮盖策略，以防止香草遮盖方法中图像中的随机遮盖区域导致信息不完整。此外，我们引入了一种灵活的损失函数设计，考虑两个不同混合视图之间的语义距离变化，以适应集成架构并防止遮盖和对比学习目标之间的不匹配。实验表明，MixMask显着提高了Siamese ConvNets的性能，并在几个基准测试中实现了最先进的结果。

    Recent advances in self-supervised learning have integrated Masked Image Modeling (MIM) and Siamese Networks into a unified framework that leverages the benefits of both techniques. However, several issues remain unaddressed when applying conventional erase-based masking with Siamese ConvNets. These include (I) the inability to drop uninformative masked regions in ConvNets as they process data continuously, resulting in low training efficiency compared to ViT models; and (II) the mismatch between erase-based masking and the contrastive-based objective in Siamese ConvNets, which differs from the MIM approach. In this paper, we propose a filling-based masking strategy called MixMask to prevent information incompleteness caused by the randomly erased regions in an image in the vanilla masking method. Furthermore, we introduce a flexible loss function design that considers the semantic distance change between two different mixed views to adapt the integrated architecture and prevent mismat
    

