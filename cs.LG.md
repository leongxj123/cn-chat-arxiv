# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Heat Death of Generative Models in Closed-Loop Learning](https://arxiv.org/abs/2404.02325) | 生成模型的闭环训练过程容易产生退化现象，模型可能开始生成无意义的数据或仅从所需数据分布的一小部分中采样。 |
| [^2] | [Communication Optimization for Distributed Training: Architecture, Advances, and Opportunities](https://arxiv.org/abs/2403.07585) | 本文介绍了分布式深度神经网络训练的通信优化架构，并对并行化策略、集体通信库和网络关系进行了分析，总结了当前的研究进展。 |
| [^3] | [GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM](https://arxiv.org/abs/2403.05527) | GEAR提出了一种高效的KV缓存压缩框架，实现几乎无损的高比率压缩，用于解决大型语言模型推断中因缓存需求增长而导致的记忆绑定问题和性能下降。 |
| [^4] | [FRRI: a novel algorithm for fuzzy-rough rule induction](https://arxiv.org/abs/2403.04447) | 结合模糊与粗糙集理论，提出一种新颖的模糊-粗糙规则归纳算法 FRRI。 |
| [^5] | [Mitigating Label Noise on Graph via Topological Sample Selection](https://arxiv.org/abs/2403.01942) | 提出了一种通过利用图数据的拓扑信息来增强信息选择过程的$“\textit{拓扑样本选择}$”（TSS）方法。 |
| [^6] | [Multi-Constraint Safe RL with Objective Suppression for Safety-Critical Applications](https://arxiv.org/abs/2402.15650) | 提出了一种目标抑制的新方法，可以在多约束安全领域中改进安全强化学习任务表现，实验证明此方法结合现有算法能够在减少约束违规的情况下实现与基准线相当的任务奖励水平。 |
| [^7] | [LLM Agents for Psychology: A Study on Gamified Assessments](https://arxiv.org/abs/2402.12326) | 本研究提出了PsychoGAT（心理游戏代理）以实现心理评估的通用游戏化，通过将强大的LLM代理纳入角色，将标准量表转化为个性化且具有吸引力的互动小说游戏。 |
| [^8] | [Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given Enough Time](https://arxiv.org/abs/2402.03973) | 人类在识别不寻常姿势中的物体上表现优于深度网络，当给予足够时间时。然而，随着图像曝光时间的限制，人类的表现降至深度网络的水平，这暗示人类在识别不寻常姿势中的物体时需要额外的心理过程。此外，人类与网络之间的错误模式也存在不同。因此，我们需要进一步研究，以提高计算机视觉系统的鲁棒性水平。 |
| [^9] | [DiffiT: Diffusion Vision Transformers for Image Generation](https://arxiv.org/abs/2312.02139) | DiffiT是一种新的模型，结合了Vision Transformer和扩散模型的优势，在图像生成中表现出色，特别是通过引入细粒度去噪控制和时间依赖的多头自注意力机制，实现了高保真图像的生成。 |
| [^10] | [Domain Adaptation based Interpretable Image Emotion Recognition using Facial Expression Recognition](https://arxiv.org/abs/2011.08388) | 本论文提出了一种基于领域自适应的图像情绪识别方法，通过提出面部情绪识别系统并将其适应为图像情绪识别系统，解决了预训练模型和数据集不足的挑战。同时提出了一种新颖的解释性方法，用于解释情绪识别中关键的视觉特征。 |
| [^11] | [Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges.](http://arxiv.org/abs/2310.15274) | 本论文讨论了面临能源、对齐和从狭义人工智能到AGI的三大挑战的系统化人工智能方法。现有的人工智能方法在能源消耗、系统设计和对齐问题上存在不足，而系统设计在解决对齐、能源和AGI大挑战中是至关重要的。 |
| [^12] | [Gradient Descent Fails to Learn High-frequency Functions and Modular Arithmetic.](http://arxiv.org/abs/2310.12660) | 梯度下降无法学习高频函数和模运算，该研究为使用基于梯度的学习技术训练高频周期函数和模乘法提供了数学分析。 |
| [^13] | [Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models.](http://arxiv.org/abs/2310.12000) | 这篇文章介绍了用于潜在高斯过程模型中的Vecchia-Laplace近似法的迭代方法，相比于传统的Cholesky分解方法，可以显著加快计算速度。 |
| [^14] | [CAST: Cluster-Aware Self-Training for Tabular Data.](http://arxiv.org/abs/2310.06380) | 本文提出了一种面向表格数据的群集感知自训练方法（CAST），通过规范伪标签的置信度，弥补了自训练算法中的一些弱点，具有普适性和适应性。 |
| [^15] | [Dual Prompt Tuning for Domain-Aware Federated Learning.](http://arxiv.org/abs/2310.03103) | 本文提出了一种面向领域感知的联邦学习方法，通过双提示调优实现领域适应。实验结果表明，该方法在联邦学习中具有显著的效果。 |
| [^16] | [Interpretable Distribution-Invariant Fairness Measures for Continuous Scores.](http://arxiv.org/abs/2308.11375) | 对于连续评分，我们提出了一种基于Wasserstein距离的分布不变公平性度量方法，能够解释度量结果并适用于比较不同模型、数据集或时间点之间的偏差。 |
| [^17] | [Learning from Heterogeneity: A Dynamic Learning Framework for Hypergraphs.](http://arxiv.org/abs/2307.03411) | 本文提出了一个名为LFH的超图学习框架，能够动态构建超边并利用异质属性进行嵌入更新。实验结果表明，该框架在多个数据集上取得了良好的效果。 |
| [^18] | [Understanding how Differentially Private Generative Models Spend their Privacy Budget.](http://arxiv.org/abs/2305.10994) | 本文分析了采用差分隐私训练的生成模型如何分配隐私预算，以及影响分配的因素。使用不同的模型适合于不同的任务和设置。 |
| [^19] | [A Best-of-Both-Worlds Algorithm for Constrained MDPs with Long-Term Constraints.](http://arxiv.org/abs/2304.14326) | 本文提出了一种针对约束MDPs的双赢算法，能够处理奖励和约束随机或敌对的情况。 |
| [^20] | [Adaptive Riemannian Metrics on SPD Manifolds.](http://arxiv.org/abs/2303.15477) | 本文提出了自适应黎曼度量来改进SPD神经网络的次优性能，实验结果表明该度量能使网络表现更好。 |
| [^21] | [Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods.](http://arxiv.org/abs/2302.11962) | 该论文提出了一个名为辅助框架的新框架，通过统一的视角，提供了具有全局复杂性保证的随机和方差减少的二阶算法。该框架在构建和分析随机三次牛顿方法时具有高度灵活性，使用了任意大小的批量，以及有噪声和可能有偏差的梯度和Hessian的估计，结合了方差减少和惰性Hessian更新。在噪声的弱假设下，恢复了已知的随机和方差减少的三次牛顿的最佳复杂性。 |
| [^22] | [Convergence and sample complexity of natural policy gradient primal-dual methods for constrained MDPs.](http://arxiv.org/abs/2206.02346) | 本文研究了约束马尔可夫决策过程中优化问题的自然策略梯度原始-对偶方法。通过自然策略梯度上升和投影次梯度下降更新变量，我们的方法在全局收敛中实现了次线性速率，而且不受状态-动作空间大小限制。 |
| [^23] | [How to avoid machine learning pitfalls: a guide for academic researchers.](http://arxiv.org/abs/2108.02497) | 该论文总结了在机器学习中常见的错误，并提供了避免这些错误的方法和指南。其中包括在模型构建之前的准备工作、可靠地构建模型、稳健地评估模型、公平比较模型以及报告结果等五个关键阶段。 |

# 详细

[^1]: 闭环学习中生成模型的热力学死亡

    Heat Death of Generative Models in Closed-Loop Learning

    [https://arxiv.org/abs/2404.02325](https://arxiv.org/abs/2404.02325)

    生成模型的闭环训练过程容易产生退化现象，模型可能开始生成无意义的数据或仅从所需数据分布的一小部分中采样。

    

    生成式机器学习模型的改进和采纳正在迅速加速，例如文本中LLM（大型语言模型）的流行以及图像生成中的扩散模型。随着生成模型的普及，它们生成的数据被整合到公共网络中的共享内容中。这引发了一个问题：当模型生成的数据被送回到模型进行后续训练时会发生什么。这是一个关于训练过程稳定性的问题，即公共可访问内容的分布（我们称之为“知识”）是否保持稳定还是崩溃。文献中报道的小规模实证实验显示，这种闭环训练过程容易退化。模型可能开始生成无意义的数据，或者仅从所需数据分布的一小部分中采样（称为模式崩溃现象）。

    arXiv:2404.02325v1 Announce Type: new  Abstract: Improvement and adoption of generative machine learning models is rapidly accelerating, as exemplified by the popularity of LLMs (Large Language Models) for text, and diffusion models for image generation.As generative models become widespread, data they generate is incorporated into shared content through the public web. This opens the question of what happens when data generated by a model is fed back to the model in subsequent training campaigns. This is a question about the stability of the training process, whether the distribution of publicly accessible content, which we refer to as "knowledge", remains stable or collapses.   Small scale empirical experiments reported in the literature show that this closed-loop training process is prone to degenerating. Models may start producing gibberish data, or sample from only a small subset of the desired data distribution (a phenomenon referred to as mode collapse). So far there has been on
    
[^2]: 分布式训练的通信优化：架构、进展和机遇

    Communication Optimization for Distributed Training: Architecture, Advances, and Opportunities

    [https://arxiv.org/abs/2403.07585](https://arxiv.org/abs/2403.07585)

    本文介绍了分布式深度神经网络训练的通信优化架构，并对并行化策略、集体通信库和网络关系进行了分析，总结了当前的研究进展。

    

    近年来，大规模深度神经网络模型的蓬勃发展，参数量不断增长。训练这些大规模模型通常需要庞大的内存和计算资源，超出了单个GPU的范围，需要进行分布式训练。由于近年来GPU性能迅速发展，计算时间缩短，因此通信在整体训练时间中的比例增加。因此，优化分布式训练的通信已经成为一个紧迫问题。本文简要介绍了分布式深度神经网络训练的总体架构，并从通信优化的角度分析了并行化策略、集体通信库和网络之间的关系，形成了一个三层范式。然后，我们回顾了当前具有代表性的研究进展与这个三层范式。我们发现lay

    arXiv:2403.07585v1 Announce Type: cross  Abstract: The past few years have witnessed the flourishing of large-scale deep neural network models with ever-growing parameter numbers. Training such large-scale models typically requires massive memory and computing resources that exceed those of a single GPU, necessitating distributed training. As GPU performance has rapidly evolved in recent years, computation time has shrunk, thereby increasing the proportion of communication in the overall training time. Therefore, optimizing communication for distributed training has become an urgent issue. In this article, we briefly introduce the general architecture of distributed deep neural network training and analyze relationships among Parallelization Strategy, Collective Communication Library, and Network from the perspective of communication optimization, which forms a three-layer paradigm. We then review current representative research advances with this three-layer paradigm. We find that lay
    
[^3]: GEAR: 一种用于几乎无损生成推断大型语言模型的高效KV缓存压缩方案

    GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM

    [https://arxiv.org/abs/2403.05527](https://arxiv.org/abs/2403.05527)

    GEAR提出了一种高效的KV缓存压缩框架，实现几乎无损的高比率压缩，用于解决大型语言模型推断中因缓存需求增长而导致的记忆绑定问题和性能下降。

    

    关键-值（KV）缓存已成为加快大型语言模型（LLMs）推断生成速度的事实标准。然而，随着序列长度增加而增长的缓存需求已将LLM推断转变为一个记忆绑定问题，显著地限制了系统吞吐量。现有方法依赖于丢弃不重要的标记或均匀量化所有条目。然而，这种方法往往会产生较高的近似误差来表示压缩后的矩阵。自回归解码过程进一步增加了每个步骤的误差，导致模型生成中的重大偏差和性能恶化。为了解决这一挑战，我们提出了GEAR，一种高效的KV缓存压缩框架，实现几乎无损的高压缩比。

    arXiv:2403.05527v1 Announce Type: cross  Abstract: Key-value (KV) caching has become the de-facto to accelerate generation speed for large language models (LLMs) inference. However, the growing cache demand with increasing sequence length has transformed LLM inference to be a memory bound problem, significantly constraining the system throughput. Existing methods rely on dropping unimportant tokens or quantizing all entries uniformly. Such methods, however, often incur high approximation errors to represent the compressed matrices. The autoregressive decoding process further compounds the error of each step, resulting in critical deviation in model generation and deterioration of performance. To tackle this challenge, we propose GEAR, an efficient KV cache compression framework that achieves near-lossless high-ratio compression. GEAR first applies quantization to majority of entries of similar magnitudes to ultra-low precision. It then employs a low rank matrix to approximate the quant
    
[^4]: FRRI：一种新颖的模糊-粗糙规则归纳算法

    FRRI: a novel algorithm for fuzzy-rough rule induction

    [https://arxiv.org/abs/2403.04447](https://arxiv.org/abs/2403.04447)

    结合模糊与粗糙集理论，提出一种新颖的模糊-粗糙规则归纳算法 FRRI。

    

    可解释性是机器学习研究的下一个前沿。在寻找白盒模型的过程中-与随机森林或神经网络等黑盒模型相对应，规则归纳算法是一个合乎逻辑且有希望的选择，因为规则可以被人类轻松理解。模糊和粗糙集理论已成功应用于这种原型，几乎总是分开应用。由于规则归纳的两种方法均涉及基于等价类概念的粒计算，将它们结合是自然的选择。QuickRules算法是利用模糊粗糙集理论进行规则归纳的第一次尝试。它基于QuickReduct，这是一个用于构建决策约简的贪婪算法。QuickRules 已经展示了相比其他规则归纳方法的改进。然而，要评估模糊-粗糙规则归纳算法的全部潜力，就需要从基础开始。在本文中，

    arXiv:2403.04447v1 Announce Type: cross  Abstract: Interpretability is the next frontier in machine learning research. In the search for white box models - as opposed to black box models, like random forests or neural networks - rule induction algorithms are a logical and promising option, since the rules can easily be understood by humans. Fuzzy and rough set theory have been successfully applied to this archetype, almost always separately. As both approaches to rule induction involve granular computing based on the concept of equivalence classes, it is natural to combine them. The QuickRules\cite{JensenCornelis2009} algorithm was a first attempt at using fuzzy rough set theory for rule induction. It is based on QuickReduct, a greedy algorithm for building decision reducts. QuickRules already showed an improvement over other rule induction methods. However, to evaluate the full potential of a fuzzy rough rule induction algorithm, one needs to start from the foundations. In this paper,
    
[^5]: 通过拓扑样本选择减轻图中的标签噪音

    Mitigating Label Noise on Graph via Topological Sample Selection

    [https://arxiv.org/abs/2403.01942](https://arxiv.org/abs/2403.01942)

    提出了一种通过利用图数据的拓扑信息来增强信息选择过程的$“\textit{拓扑样本选择}$”（TSS）方法。

    

    尽管精心注释的基准测试取得了成功，但当现实世界的图数据带有噪声标签时，现有图神经网络（GNNs）的有效性在实践中可能会受到相当大的影响。以往在样本选择方面的探索已被证明是一种有效的应对噪声标签的鲁棒学习方法，然而，传统研究侧重于i.i.d数据，当转向非独立同分布的图数据和GNNs时，仍然存在两个值得关注的挑战：(1) 位于拓扑类边界附近的节点对分类非常有信息量，但无法通过启发式样本选择成功区分。(2) 没有可用的衡量标准考虑图的拓扑信息以促进图中的样本选择。为了解决这一困境，我们提出了一种$“\textit{拓扑样本选择}$（TSS）”方法，通过利用拓扑信息来提升图中信息丰富的样本选择过程。

    arXiv:2403.01942v1 Announce Type: new  Abstract: Despite the success of the carefully-annotated benchmarks, the effectiveness of existing graph neural networks (GNNs) can be considerably impaired in practice when the real-world graph data is noisily labeled. Previous explorations in sample selection have been demonstrated as an effective way for robust learning with noisy labels, however, the conventional studies focus on i.i.d data, and when moving to non-iid graph data and GNNs, two notable challenges remain: (1) nodes located near topological class boundaries are very informative for classification but cannot be successfully distinguished by the heuristic sample selection. (2) there is no available measure that considers the graph topological information to promote sample selection in a graph. To address this dilemma, we propose a $\textit{Topological Sample Selection}$ (TSS) method that boosts the informative sample selection process in a graph by utilising topological information.
    
[^6]: 具有目标抑制的多约束安全强化学习用于安全关键应用

    Multi-Constraint Safe RL with Objective Suppression for Safety-Critical Applications

    [https://arxiv.org/abs/2402.15650](https://arxiv.org/abs/2402.15650)

    提出了一种目标抑制的新方法，可以在多约束安全领域中改进安全强化学习任务表现，实验证明此方法结合现有算法能够在减少约束违规的情况下实现与基准线相当的任务奖励水平。

    

    尽管在现实世界中非常常见，但具有多个约束条件的安全强化学习任务仍然是一个具有挑战性的领域。为了解决这一挑战，我们提出了一种新方法，即目标抑制，根据安全评判器自适应地抑制任务奖励最大化目标。我们在两个多约束安全领域中对目标抑制进行了基准测试，包括一个自动驾驶领域，在这个领域中任何错误的行为都可能导致灾难性后果。实证结果表明，我们提出的方法与现有的安全强化学习算法相结合，可以在显著减少约束违规的情况下匹配我们的基准线所达到的任务奖励。

    arXiv:2402.15650v1 Announce Type: cross  Abstract: Safe reinforcement learning tasks with multiple constraints are a challenging domain despite being very common in the real world. To address this challenge, we propose Objective Suppression, a novel method that adaptively suppresses the task reward maximizing objectives according to a safety critic. We benchmark Objective Suppression in two multi-constraint safety domains, including an autonomous driving domain where any incorrect behavior can lead to disastrous consequences. Empirically, we demonstrate that our proposed method, when combined with existing safe RL algorithms, can match the task reward achieved by our baselines with significantly fewer constraint violations.
    
[^7]: 基于LLM的心理学智能代理：一项关于游戏化评估的研究

    LLM Agents for Psychology: A Study on Gamified Assessments

    [https://arxiv.org/abs/2402.12326](https://arxiv.org/abs/2402.12326)

    本研究提出了PsychoGAT（心理游戏代理）以实现心理评估的通用游戏化，通过将强大的LLM代理纳入角色，将标准量表转化为个性化且具有吸引力的互动小说游戏。

    

    心理测量对于精神健康、自我理解和个人发展至关重要。传统方法，如自我报告量表和心理学家访谈，常常面临参与度和可获得性方面的挑战。虽然已经探讨了基于游戏和LLM的工具来提高用户兴趣并自动化评估，但它们难以平衡参与度和普适性。在这项工作中，我们提出了PsychoGAT（心理游戏代理），以实现心理评估的通用游戏化。主要洞察是强大的LLM既可以充当熟练的心理学家，也可以是创新的游戏设计师。通过将LLM代理纳入指定角色并精心管理它们的互动，PsychoGAT可以将任何标准量表转化为个性化且具有吸引力的互动小说游戏。为验证所提出的方法，我们进行心理度量评估以评估其有效性，并使用人类

    arXiv:2402.12326v1 Announce Type: new  Abstract: Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to improve user interest and automate assessment, they struggle to balance engagement with generalizability. In this work, we propose PsychoGAT (Psychological Game AgenTs) to achieve a generic gamification of psychological assessment. The main insight is that powerful LLMs can function both as adept psychologists and innovative game designers. By incorporating LLM agents into designated roles and carefully managing their interactions, PsychoGAT can transform any standardized scales into personalized and engaging interactive fiction games. To validate the proposed method, we conduct psychometric evaluations to assess its effectiveness and employ huma
    
[^8]: 给予足够时间，人类在识别不寻常姿势中的物体上击败了深度网络

    Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given Enough Time

    [https://arxiv.org/abs/2402.03973](https://arxiv.org/abs/2402.03973)

    人类在识别不寻常姿势中的物体上表现优于深度网络，当给予足够时间时。然而，随着图像曝光时间的限制，人类的表现降至深度网络的水平，这暗示人类在识别不寻常姿势中的物体时需要额外的心理过程。此外，人类与网络之间的错误模式也存在不同。因此，我们需要进一步研究，以提高计算机视觉系统的鲁棒性水平。

    

    深度学习在几个物体识别基准上正在缩小与人类的差距。本文在涉及从不寻常视角观察物体的挑战性图像中对这一差距进行了研究。我们发现人类在识别不寻常姿势中的物体时表现出色，与先进的预训练网络（EfficientNet、SWAG、ViT、SWIN、BEiT、ConvNext）相比，这些网络在此情况下普遍脆弱。值得注意的是，随着我们限制图像曝光时间，人类的表现下降到深度网络的水平，这表明人类在识别不寻常姿势中的物体时需要额外的心理过程（需要额外的时间）。最后，我们分析了人类与网络的错误模式，发现即使在限制时间的情况下，人类与前馈深度网络也有不同。我们得出结论，需要更多的工作将计算机视觉系统带到人类视觉系统的鲁棒性水平。理解在外部情况下发生的心理过程的本质是必要的。

    Deep learning is closing the gap with humans on several object recognition benchmarks. Here we investigate this gap in the context of challenging images where objects are seen from unusual viewpoints. We find that humans excel at recognizing objects in unusual poses, in contrast with state-of-the-art pretrained networks (EfficientNet, SWAG, ViT, SWIN, BEiT, ConvNext) which are systematically brittle in this condition. Remarkably, as we limit image exposure time, human performance degrades to the level of deep networks, suggesting that additional mental processes (requiring additional time) take place when humans identify objects in unusual poses. Finally, our analysis of error patterns of humans vs. networks reveals that even time-limited humans are dissimilar to feed-forward deep networks. We conclude that more work is needed to bring computer vision systems to the level of robustness of the human visual system. Understanding the nature of the mental processes taking place during extr
    
[^9]: DiffiT: 用于图像生成的扩散视觉Transformer模型

    DiffiT: Diffusion Vision Transformers for Image Generation

    [https://arxiv.org/abs/2312.02139](https://arxiv.org/abs/2312.02139)

    DiffiT是一种新的模型，结合了Vision Transformer和扩散模型的优势，在图像生成中表现出色，特别是通过引入细粒度去噪控制和时间依赖的多头自注意力机制，实现了高保真图像的生成。

    

    具有强大表现力和高样本质量的扩散模型在生成领域取得了最先进的性能。开创性的视觉Transformer（ViT）展现了强大的建模能力和可扩展性，特别适用于识别任务。本文研究了ViTs在基于扩散的生成学习中的有效性，并提出了一个新模型，称为Diffusion Vision Transformers（DiffiT）。具体地，我们提出了一种用于对去噪过程进行细粒度控制的方法，并引入了时间依赖的多头自注意力（TMSA）机制。DiffiT在生成高保真图像方面非常有效，参数效率也显著提高。我们还提出了基于潜空间和图像空间的DiffiT模型，并在不同分辨率的各种类别条件和非条件综合任务上展现了最先进的性能。潜空间DiffiT模型达到

    arXiv:2312.02139v2 Announce Type: replace-cross  Abstract: Diffusion models with their powerful expressivity and high sample quality have achieved State-Of-The-Art (SOTA) performance in the generative domain. The pioneering Vision Transformer (ViT) has also demonstrated strong modeling capabilities and scalability, especially for recognition tasks. In this paper, we study the effectiveness of ViTs in diffusion-based generative learning and propose a new model denoted as Diffusion Vision Transformers (DiffiT). Specifically, we propose a methodology for finegrained control of the denoising process and introduce the Time-dependant Multihead Self Attention (TMSA) mechanism. DiffiT is surprisingly effective in generating high-fidelity images with significantly better parameter efficiency. We also propose latent and image space DiffiT models and show SOTA performance on a variety of class-conditional and unconditional synthesis tasks at different resolutions. The Latent DiffiT model achieves
    
[^10]: 基于领域自适应的可解释图像情绪识别，并利用面部表情识别

    Domain Adaptation based Interpretable Image Emotion Recognition using Facial Expression Recognition

    [https://arxiv.org/abs/2011.08388](https://arxiv.org/abs/2011.08388)

    本论文提出了一种基于领域自适应的图像情绪识别方法，通过提出面部情绪识别系统并将其适应为图像情绪识别系统，解决了预训练模型和数据集不足的挑战。同时提出了一种新颖的解释性方法，用于解释情绪识别中关键的视觉特征。

    

    本文提出了一种领域自适应技术，用于识别包含面部和非面部物体以及非人类组件的通用图像中的情绪。它解决了图像情绪识别（IER）中预训练模型和良好注释数据集的不足挑战。首先，提出了一种基于深度学习的面部情绪识别（FER）系统，将给定的面部图像分类为离散情绪类别。然后，提出了一种图像识别系统，将提出的FER系统适应于利用领域自适应识别图像所传达的情绪。它将通用图像分类为“快乐”，“悲伤”，“仇恨”和“愤怒”类别。还提出了一种新颖的解释性方法，称为分而治之的Shap（DnCShap），用于解释情绪识别中高度相关的视觉特征。

    A domain adaptation technique has been proposed in this paper to identify the emotions in generic images containing facial & non-facial objects and non-human components. It addresses the challenge of the insufficient availability of pre-trained models and well-annotated datasets for image emotion recognition (IER). It starts with proposing a facial emotion recognition (FER) system and then moves on to adapting it for image emotion recognition. First, a deep-learning-based FER system has been proposed that classifies a given facial image into discrete emotion classes. Further, an image recognition system has been proposed that adapts the proposed FER system to recognize the emotions portrayed by images using domain adaptation. It classifies the generic images into 'happy,' 'sad,' 'hate,' and 'anger' classes. A novel interpretability approach, Divide and Conquer based Shap (DnCShap), has also been proposed to interpret the highly relevant visual features for emotion recognition. The prop
    
[^11]: 系统化的人工智能方法用于AGI：解决对齐、能源和AGI大挑战

    Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges. (arXiv:2310.15274v1 [cs.AI])

    [http://arxiv.org/abs/2310.15274](http://arxiv.org/abs/2310.15274)

    本论文讨论了面临能源、对齐和从狭义人工智能到AGI的三大挑战的系统化人工智能方法。现有的人工智能方法在能源消耗、系统设计和对齐问题上存在不足，而系统设计在解决对齐、能源和AGI大挑战中是至关重要的。

    

    人工智能面临着三大挑战：能源壁垒、对齐问题和从狭义人工智能到AGI的飞跃。当代人工智能解决方案在模型训练和日常运行过程中消耗着不可持续的能源。更糟糕的是，自2020年以来，每个新的人工智能模型所需的计算量每两个月就翻倍，直接导致能源消耗的增加。从人工智能到AGI的飞跃需要多个功能子系统以平衡的方式运作，这需要一个系统架构。然而，当前的人工智能方法缺乏系统设计；即使系统特征在人脑中扮演着重要角色，从它处理信息的方式到它做出决策的方式。同样，当前的对齐和人工智能伦理方法在很大程度上忽视了系统设计，然而研究表明，大脑的系统架构在健康的道德决策中起着关键作用。在本文中，我们认为系统设计在解决对齐、能源和AGI大挑战中至关重要。

    AI faces a trifecta of grand challenges the Energy Wall, the Alignment Problem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume unsustainable amounts of energy during model training and daily operations.Making things worse, the amount of computation required to train each new AI model has been doubling every 2 months since 2020, directly translating to increases in energy consumption.The leap from AI to AGI requires multiple functional subsystems operating in a balanced manner, which requires a system architecture. However, the current approach to artificial intelligence lacks system design; even though system characteristics play a key role in the human brain from the way it processes information to how it makes decisions. Similarly, current alignment and AI ethics approaches largely ignore system design, yet studies show that the brains system architecture plays a critical role in healthy moral decisions.In this paper, we argue that system design is critically im
    
[^12]: 梯度下降无法学习高频函数和模运算

    Gradient Descent Fails to Learn High-frequency Functions and Modular Arithmetic. (arXiv:2310.12660v1 [cs.LG])

    [http://arxiv.org/abs/2310.12660](http://arxiv.org/abs/2310.12660)

    梯度下降无法学习高频函数和模运算，该研究为使用基于梯度的学习技术训练高频周期函数和模乘法提供了数学分析。

    

    已知一些包含大量近似正交元素的目标函数类别难以被统计查询算法学习到。最近，这一经典事实再次出现在神经网络梯度优化的理论中。在这个新的框架中，一个类的难度通常由梯度对随机选择的目标函数的方差来衡量。最近，一个形式为$x \to ax \bmod p$的函数集合，其中$a$取自${\mathbb Z}_p$，引起了深度学习理论家和密码学家的关注。这个类可以被理解为${\mathbb Z}$上的$p$-周期函数的子集，并且与实数线上的高频周期函数类紧密相关。我们对使用基于梯度的学习技术从示例中训练高频周期函数或模乘法进行了数学分析，并强调了相关的限制和挑战。

    Classes of target functions containing a large number of approximately orthogonal elements are known to be hard to learn by the Statistical Query algorithms. Recently this classical fact re-emerged in a theory of gradient-based optimization of neural networks. In the novel framework, the hardness of a class is usually quantified by the variance of the gradient with respect to a random choice of a target function.  A set of functions of the form $x\to ax \bmod p$, where $a$ is taken from ${\mathbb Z}_p$, has attracted some attention from deep learning theorists and cryptographers recently. This class can be understood as a subset of $p$-periodic functions on ${\mathbb Z}$ and is tightly connected with a class of high-frequency periodic functions on the real line.  We present a mathematical analysis of limitations and challenges associated with using gradient-based learning techniques to train a high-frequency periodic function or modular multiplication from examples. We highlight that t
    
[^13]: Vecchia-Laplace近似法在潜在高斯过程模型中的迭代方法

    Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models. (arXiv:2310.12000v1 [stat.ME])

    [http://arxiv.org/abs/2310.12000](http://arxiv.org/abs/2310.12000)

    这篇文章介绍了用于潜在高斯过程模型中的Vecchia-Laplace近似法的迭代方法，相比于传统的Cholesky分解方法，可以显著加快计算速度。

    

    潜在高斯过程（GP）模型是灵活的概率非参数函数模型。Vecchia近似是用于克服大数据计算瓶颈的准确近似方法，Laplace近似是一种快速方法，可以近似非高斯似然函数的边缘似然和后验预测分布，并具有渐近收敛保证。然而，当与直接求解方法（如Cholesky分解）结合使用时，Vecchia-Laplace近似的计算复杂度增长超线性地随样本大小增加。因此，与Vecchia-Laplace近似计算相关的运算在通常情况下是最准确的大型数据集时会变得非常缓慢。在本文中，我们提出了几种用于Vecchia-Laplace近似推断的迭代方法，相比于基于Cholesky的计算，可以大大加快计算速度。我们对我们的方法进行了分析。

    Latent Gaussian process (GP) models are flexible probabilistic non-parametric function models. Vecchia approximations are accurate approximations for GPs to overcome computational bottlenecks for large data, and the Laplace approximation is a fast method with asymptotic convergence guarantees to approximate marginal likelihoods and posterior predictive distributions for non-Gaussian likelihoods. Unfortunately, the computational complexity of combined Vecchia-Laplace approximations grows faster than linearly in the sample size when used in combination with direct solver methods such as the Cholesky decomposition. Computations with Vecchia-Laplace approximations thus become prohibitively slow precisely when the approximations are usually the most accurate, i.e., on large data sets. In this article, we present several iterative methods for inference with Vecchia-Laplace approximations which make computations considerably faster compared to Cholesky-based calculations. We analyze our propo
    
[^14]: CAST：面向表格数据的群集感知自训练

    CAST: Cluster-Aware Self-Training for Tabular Data. (arXiv:2310.06380v1 [cs.LG])

    [http://arxiv.org/abs/2310.06380](http://arxiv.org/abs/2310.06380)

    本文提出了一种面向表格数据的群集感知自训练方法（CAST），通过规范伪标签的置信度，弥补了自训练算法中的一些弱点，具有普适性和适应性。

    

    自训练由于其简单和多功能性而受到吸引，然而它容易受到有噪音的伪标签的影响。几项研究提出了成功解决这个问题的方法，但它们削弱了自训练的优势，因为它们需要对自训练算法或模型架构进行特定的修改。此外，大多数方法与在表格领域中占主导地位的梯度提升决策树不兼容。为了解决这个问题，我们重新考虑了群集假设，即相互接近的数据样本往往属于同一类。在此假设的启发下，我们提出了一种针对表格数据的群集感知自训练（CAST）方法。CAST是一种简单且普遍适应的方法，可以改进现有的自训练算法而无需进行大幅修改。具体而言，我们的方法规范了分类器的置信度，即伪标签的值，强制在低密度区域对伪标签进行限制。

    Self-training has gained attraction because of its simplicity and versatility, yet it is vulnerable to noisy pseudo-labels. Several studies have proposed successful approaches to tackle this issue, but they have diminished the advantages of self-training because they require specific modifications in self-training algorithms or model architectures. Furthermore, most of them are incompatible with gradient boosting decision trees, which dominate the tabular domain. To address this, we revisit the cluster assumption, which states that data samples that are close to each other tend to belong to the same class. Inspired by the assumption, we propose Cluster-Aware Self-Training (CAST) for tabular data. CAST is a simple and universally adaptable approach for enhancing existing self-training algorithms without significant modifications. Concretely, our method regularizes the confidence of the classifier, which represents the value of the pseudo-label, forcing the pseudo-labels in low-density r
    
[^15]: 面向领域感知的联邦学习的双提示调优

    Dual Prompt Tuning for Domain-Aware Federated Learning. (arXiv:2310.03103v1 [cs.LG])

    [http://arxiv.org/abs/2310.03103](http://arxiv.org/abs/2310.03103)

    本文提出了一种面向领域感知的联邦学习方法，通过双提示调优实现领域适应。实验结果表明，该方法在联邦学习中具有显著的效果。

    

    联邦学习是一种分布式机器学习范 paradigm，它允许多个客户端使用本地数据共同训练一个共享模型。然而，由于客户之间普遍存在领域变化，传统的联邦学习算法往往难以很好地泛化。在这项工作中，我们考虑了一个具有挑战性但现实的联邦学习场景，其中每个客户端的训练数据来自不同的领域。我们通过利用提示学习技术来解决领域变化的挑战，并提出了一种名为联邦双提示调优（Fed-DPT）的新方法。具体而言，Fed-DPT采用了一个预训练的视觉语言模型，然后应用了视觉和文本提示调优来促进分布式数据上的领域适应。大量的Fed-DPT实验结果表明，它在领域感知的联邦学习中具有显著的效果。

    Federated learning is a distributed machine learning paradigm that allows multiple clients to collaboratively train a shared model with their local data. Nonetheless, conventional federated learning algorithms often struggle to generalize well due to the ubiquitous domain shift across clients. In this work, we consider a challenging yet realistic federated learning scenario where the training data of each client originates from different domains. We address the challenges of domain shift by leveraging the technique of prompt learning, and propose a novel method called Federated Dual Prompt Tuning (Fed-DPT). Specifically, Fed-DPT employs a pre-trained vision-language model and then applies both visual and textual prompt tuning to facilitate domain adaptation over decentralized data. Extensive experiments of Fed-DPT demonstrate its significant effectiveness in domain-aware federated learning. With a pre-trained CLIP model (ViT-Base as image encoder), the proposed Fed-DPT attains 68.4% av
    
[^16]: 可解释的分布不变公平性度量方法对于连续评分

    Interpretable Distribution-Invariant Fairness Measures for Continuous Scores. (arXiv:2308.11375v1 [stat.ML])

    [http://arxiv.org/abs/2308.11375](http://arxiv.org/abs/2308.11375)

    对于连续评分，我们提出了一种基于Wasserstein距离的分布不变公平性度量方法，能够解释度量结果并适用于比较不同模型、数据集或时间点之间的偏差。

    

    算法公平性度量通常在二元决策的背景下进行讨论。我们将这种方法扩展到连续评分。到目前为止，基于ROC的度量方法主要用于此目的。其他现有方法主要依赖于评分的分布，不适用于排名任务，或者它们的效果大小不可解释。在这里，我们提出了一种基于Wasserstein距离的连续评分的分布不变公平性度量方法，具有合理的解释。我们的度量方法易于计算，并适用于量化和解释群体差异的强度，以及比较不同模型、数据集或时间点之间的偏差。我们建立了现有评分公平性度量方法的不同族之间的联系，并表明所提出的分布不变公平性度量方法表现更好，因为它们更明确，并且可以量化显著的偏差，而ROC-based不能。

    Measures of algorithmic fairness are usually discussed in the context of binary decisions. We extend the approach to continuous scores. So far, ROC-based measures have mainly been suggested for this purpose. Other existing methods depend heavily on the distribution of scores, are unsuitable for ranking tasks, or their effect sizes are not interpretable. Here, we propose a distributionally invariant version of fairness measures for continuous scores with a reasonable interpretation based on the Wasserstein distance. Our measures are easily computable and well suited for quantifying and interpreting the strength of group disparities as well as for comparing biases across different models, datasets, or time points. We derive a link between the different families of existing fairness measures for scores and show that the proposed distributionally invariant fairness measures outperform ROC-based fairness measures because they are more explicit and can quantify significant biases that ROC-ba
    
[^17]: 从异质性中学习：用于超图的动态学习框架

    Learning from Heterogeneity: A Dynamic Learning Framework for Hypergraphs. (arXiv:2307.03411v1 [cs.LG])

    [http://arxiv.org/abs/2307.03411](http://arxiv.org/abs/2307.03411)

    本文提出了一个名为LFH的超图学习框架，能够动态构建超边并利用异质属性进行嵌入更新。实验结果表明，该框架在多个数据集上取得了良好的效果。

    

    图神经网络（GNN）因其在建模复杂图结构数据方面的能力和灵活性而在近年来日益受到关注。在所有图学习方法中，超图学习是一种在训练图的嵌入空间时探索隐含的高阶关联的技术。在本文中，我们提出了一个名为LFH的超图学习框架，能够利用图的异质属性进行动态超边构建和关注性嵌入更新。具体来说，在我们的框架中，首先通过利用显式的图结构信息生成高质量的特征向量。然后通过隐式超边的动态分组来构建超图，并进行类型特定的超图学习过程。为了评估我们提出的框架的有效性，我们在几个流行的数据集上进行了全面的实验。

    Graph neural network (GNN) has gained increasing popularity in recent years owing to its capability and flexibility in modeling complex graph structure data. Among all graph learning methods, hypergraph learning is a technique for exploring the implicit higher-order correlations when training the embedding space of the graph. In this paper, we propose a hypergraph learning framework named LFH that is capable of dynamic hyperedge construction and attentive embedding update utilizing the heterogeneity attributes of the graph. Specifically, in our framework, the high-quality features are first generated by the pairwise fusion strategy that utilizes explicit graph structure information when generating initial node embedding. Afterwards, a hypergraph is constructed through the dynamic grouping of implicit hyperedges, followed by the type-specific hypergraph learning process. To evaluate the effectiveness of our proposed framework, we conduct comprehensive experiments on several popular data
    
[^18]: 理解差分隐私生成模型如何使用隐私预算

    Understanding how Differentially Private Generative Models Spend their Privacy Budget. (arXiv:2305.10994v1 [cs.LG])

    [http://arxiv.org/abs/2305.10994](http://arxiv.org/abs/2305.10994)

    本文分析了采用差分隐私训练的生成模型如何分配隐私预算，以及影响分配的因素。使用不同的模型适合于不同的任务和设置。

    

    采用差分隐私训练的生成模型被广泛应用于产生合成数据，同时减少隐私风险。但是在不同的应用场景中找到最适合的模型，需要权衡它们之间的隐私-效用关系。本文针对表格数据，分析了DP生成模型如何分配隐私预算，并探讨了影响隐私预算分配的主要因素。我们对图形和深度生成模型进行了广泛的评估，揭示了不同模型适用于不同设置和任务的独特特征。

    Generative models trained with Differential Privacy (DP) are increasingly used to produce synthetic data while reducing privacy risks. Navigating their specific privacy-utility tradeoffs makes it challenging to determine which models would work best for specific settings/tasks. In this paper, we fill this gap in the context of tabular data by analyzing how DP generative models distribute privacy budgets across rows and columns, arguably the main source of utility degradation. We examine the main factors contributing to how privacy budgets are spent, including underlying modeling techniques, DP mechanisms, and data dimensionality.  Our extensive evaluation of both graphical and deep generative models sheds light on the distinctive features that render them suitable for different settings and tasks. We show that graphical models distribute the privacy budget horizontally and thus cannot handle relatively wide datasets while the performance on the task they were optimized for monotonicall
    
[^19]: 一种针对带长期约束的约束MDPs的双赢算法

    A Best-of-Both-Worlds Algorithm for Constrained MDPs with Long-Term Constraints. (arXiv:2304.14326v1 [cs.LG])

    [http://arxiv.org/abs/2304.14326](http://arxiv.org/abs/2304.14326)

    本文提出了一种针对约束MDPs的双赢算法，能够处理奖励和约束随机或敌对的情况。

    

    本文研究了环形约束马尔科夫决策过程（CMDPs）的在线学习，其中学习者的目标是在收集尽可能多的奖励的同时，在学习过程中保证满足一些长期约束。奖励和约束可以随机或敌对地选择，并且转移函数对学习者是未知的。虽然在经典的无约束MDPs中的在线学习在过去几年中受到了大量关注，但CMDP的设置仍然大部分未被探索。这一点令人惊讶，因为在实际应用中，例如自动驾驶、自动投标和推荐系统中，通常存在额外的约束和规范，代理必须在学习过程中遵守这些规定。本文提出了一种面向长期约束的CMDPs的双赢算法。我们的算法能够处理奖励和约束随机或敌对的情况。

    We study online learning in episodic constrained Markov decision processes (CMDPs), where the goal of the learner is to collect as much reward as possible over the episodes, while guaranteeing that some long-term constraints are satisfied during the learning process. Rewards and constraints can be selected either stochastically or adversarially, and the transition function is not known to the learner. While online learning in classical unconstrained MDPs has received considerable attention over the last years, the setting of CMDPs is still largely unexplored. This is surprising, since in real-world applications, such as, e.g., autonomous driving, automated bidding, and recommender systems, there are usually additional constraints and specifications that an agent has to obey during the learning process. In this paper, we provide the first best-of-both-worlds algorithm for CMDPs with long-term constraints. Our algorithm is capable of handling settings in which rewards and constraints are
    
[^20]: 对称正定矩阵上的自适应黎曼度量

    Adaptive Riemannian Metrics on SPD Manifolds. (arXiv:2303.15477v1 [cs.LG])

    [http://arxiv.org/abs/2303.15477](http://arxiv.org/abs/2303.15477)

    本文提出了自适应黎曼度量来改进SPD神经网络的次优性能，实验结果表明该度量能使网络表现更好。

    

    由于其内在能够编码数据中的潜在结构相关性，对称正定（SPD）矩阵在机器学习中受到广泛关注。为了反映SPD流形的非欧几里得几何，已经提出了许多成功的黎曼度量。然而，现有的固定度量张量可能会导致SPD矩阵学习的次优性能，特别是对于SPD神经网络。为了解决这个限制，我们利用拉回的思想，提出了自适应SPD流形的黎曼度量。此外，我们还对我们的度量提出了全面的理论。三个数据集上的实验表明，配备了我们提出的度量的SPD网络可以展现出优越的性能。

    Symmetric Positive Definite (SPD) matrices have received wide attention in machine learning due to their intrinsic capacity of encoding underlying structural correlation in data. To reflect the non-Euclidean geometry of SPD manifolds, many successful Riemannian metrics have been proposed. However, existing fixed metric tensors might lead to sub-optimal performance for SPD matrices learning, especially for SPD neural networks. To remedy this limitation, we leverage the idea of pullback and propose adaptive Riemannian metrics for SPD manifolds. Moreover, we present comprehensive theories for our metrics. Experiments on three datasets demonstrate that equipped with the proposed metrics, SPD networks can exhibit superior performance.
    
[^21]: 随机和方差减少的三次牛顿方法的统一收敛理论

    Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods. (arXiv:2302.11962v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2302.11962](http://arxiv.org/abs/2302.11962)

    该论文提出了一个名为辅助框架的新框架，通过统一的视角，提供了具有全局复杂性保证的随机和方差减少的二阶算法。该框架在构建和分析随机三次牛顿方法时具有高度灵活性，使用了任意大小的批量，以及有噪声和可能有偏差的梯度和Hessian的估计，结合了方差减少和惰性Hessian更新。在噪声的弱假设下，恢复了已知的随机和方差减少的三次牛顿的最佳复杂性。

    

    我们研究用于解决一般可能非凸最小化问题的随机三次牛顿方法。我们提出了一个新的框架，称之为辅助框架，它提供了具有全局复杂性保证的随机和方差减少的二阶算法的统一视角。它还可以应用于带有辅助信息的学习。我们的辅助框架为算法设计者提供了构建和分析随机三次牛顿方法的高度灵活性，允许任意大小的批量，并且使用有噪声和可能有偏差的梯度和Hessian的估计，将方差减少和惰性Hessian更新结合起来。在噪声的弱假设下，我们恢复了已知的随机和方差减少的三次牛顿的最佳复杂性。我们理论的一个直接结果是新的惰性随机二阶方法，它显著改进了大维问题的算术复杂性。

    We study stochastic Cubic Newton methods for solving general possibly non-convex minimization problems. We propose a new framework, which we call the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees. It can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing the stochastic Cubic Newton methods, allowing arbitrary size batches, and the use of noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton, under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also esta
    
[^22]: 自然策略梯度原始-对偶方法在约束MDP中的收敛性和样本复杂度研究

    Convergence and sample complexity of natural policy gradient primal-dual methods for constrained MDPs. (arXiv:2206.02346v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2206.02346](http://arxiv.org/abs/2206.02346)

    本文研究了约束马尔可夫决策过程中优化问题的自然策略梯度原始-对偶方法。通过自然策略梯度上升和投影次梯度下降更新变量，我们的方法在全局收敛中实现了次线性速率，而且不受状态-动作空间大小限制。

    

    我们研究了顺序决策问题，旨在最大化预期总奖励，同时满足对预期总效用的约束。我们使用自然策略梯度方法来解决约束马尔可夫决策过程（约束MDP）的折扣无限时序优化控制问题。具体地，我们提出了一种新的自然策略梯度原始-对偶（NPG-PD）方法，该方法通过自然策略梯度上升更新原始变量，通过投影次梯度下降更新对偶变量。尽管底层最大化涉及非凸目标函数和非凸约束集，但在softmax策略参数化下，我们证明了我们的方法在优化间隙和约束违规方面实现全局收敛，并具有次线性速率。此类收敛与状态-动作空间的大小无关，即无维度限制。此外，对于对数线性和一般平滑策略参数化，我们确立了收敛性和样本复杂度界限。

    We study sequential decision making problems aimed at maximizing the expected total reward while satisfying a constraint on the expected total utility. We employ the natural policy gradient method to solve the discounted infinite-horizon optimal control problem for Constrained Markov Decision Processes (constrained MDPs). Specifically, we propose a new Natural Policy Gradient Primal-Dual (NPG-PD) method that updates the primal variable via natural policy gradient ascent and the dual variable via projected sub-gradient descent. Although the underlying maximization involves a nonconcave objective function and a nonconvex constraint set, under the softmax policy parametrization we prove that our method achieves global convergence with sublinear rates regarding both the optimality gap and the constraint violation. Such convergence is independent of the size of the state-action space, i.e., it is~dimension-free. Furthermore, for log-linear and general smooth policy parametrizations, we esta
    
[^23]: 如何避免机器学习陷阱：学术研究人员指南

    How to avoid machine learning pitfalls: a guide for academic researchers. (arXiv:2108.02497v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.02497](http://arxiv.org/abs/2108.02497)

    该论文总结了在机器学习中常见的错误，并提供了避免这些错误的方法和指南。其中包括在模型构建之前的准备工作、可靠地构建模型、稳健地评估模型、公平比较模型以及报告结果等五个关键阶段。

    

    本文概述了使用机器学习时常见的一些错误，以及如何避免它们。虽然对于具有基本机器学习技术理解的任何人都应该易于理解，但它最初是为研究生撰写的，并关注学术研究中特别关注的问题，例如进行严格比较和得出有效结论的需求。它涵盖了机器学习过程的五个阶段：如何在模型构建之前进行准备，如何可靠地构建模型，如何稳健地评估模型，如何公平比较模型，以及如何报告结果。

    This document outlines some of the common mistakes that occur when using machine learning, and what can be done to avoid them. Whilst it should be accessible to anyone with a basic understanding of machine learning techniques, it was originally written for research students, and focuses on issues that are of particular concern within academic research, such as the need to do rigorous comparisons and reach valid conclusions. It covers five stages of the machine learning process: what to do before model building, how to reliably build models, how to robustly evaluate models, how to compare models fairly, and how to report results.
    

