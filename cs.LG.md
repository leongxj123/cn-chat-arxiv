# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [D'OH: Decoder-Only random Hypernetworks for Implicit Neural Representations](https://arxiv.org/abs/2403.19163) | 本文提出使用仅运行时解码器的超网络，不依赖离线数据训练，以更好地模拟跨层参数冗余。 |
| [^2] | [skscope: Fast Sparsity-Constrained Optimization in Python](https://arxiv.org/abs/2403.18540) | skscope是一个Python库，通过只需编写目标函数，就能快速实现稀疏约束优化问题的解决，并且在高维参数空间下，其高效实现使得求解器能够迅速获得稀疏解，速度比基准凸求解器快80倍。 |
| [^3] | [Guided Decoding for Robot Motion Generation and Adaption](https://arxiv.org/abs/2403.15239) | 通过将演示学习集成到运动生成中，使机器人能够实时生成适应复杂环境的运动 |
| [^4] | [Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It](https://arxiv.org/abs/2403.14715) | LS方法在深度神经网络分类器训练中的标签平滑效果被发现会负面影响选择性分类，通过影响模型预测不确定性，此研究阐明了这一现象。 |
| [^5] | [Task-optimal data-driven surrogate models for eNMPC via differentiable simulation and optimization](https://arxiv.org/abs/2403.14425) | 提出了一种基于可微分模拟和优化的任务最优数据驱动替代模型方法，在eNMPC中表现出优越性能，为实现更具能力的控制器提供了有前途的途径。 |
| [^6] | [Ant Colony Sampling with GFlowNets for Combinatorial Optimization](https://arxiv.org/abs/2403.07041) | 本文提出了生成流蚁群采样器（GFACS），一种结合生成流网络与蚁群优化方法的神经引导元启发式算法，在组合优化任务中表现优于基线ACO算法并与特定问题启发式方法具有竞争力。 |
| [^7] | [Training Machine Learning models at the Edge: A Survey](https://arxiv.org/abs/2403.02619) | 这项调研深入探讨了边缘学习(EL)中优化机器学习模型训练的各种方法和方法论，旨在综合现有知识，识别挑战，并突出未来趋势。 |
| [^8] | [SubIQ: Inverse Soft-Q Learning for Offline Imitation with Suboptimal Demonstrations](https://arxiv.org/abs/2402.13147) | 逆向软 Q 学习用于获得次优演示的离线模仿挑战了离线 IL 中有限支持专家演示的问题，并提出了一种解决方案以匹配次优演示集合的占用分布 |
| [^9] | [Machine Learning based Prediction of Ditching Loads](https://arxiv.org/abs/2402.10724) | 该研究提出了使用机器学习来预测飞机机身动态水降载荷的方法，通过结合卷积自编码器和长短期记忆网络或Koopman算子方法，取得了令人满意的预测结果。 |
| [^10] | [One-Bit Quantization and Sparsification for Multiclass Linear Classification via Regularized Regression](https://arxiv.org/abs/2402.10474) | 通过正则化回归，在超参数化范围内，根据特定选择的凸函数并适当增加一个正则化项，可以实现稀疏和一位解决方案，其性能几乎与最佳分类性能相同。 |
| [^11] | [Exploiting Estimation Bias in Deep Double Q-Learning for Actor-Critic Methods](https://arxiv.org/abs/2402.09078) | 本文提出了两种创新方法，ExpD3 和 BE-TD3，用于解决和利用 Actor-Critic 方法中的估计偏差问题。实验证明这些算法在连续控制任务中比现有方法更高效。 |
| [^12] | [More Agents Is All You Need](https://arxiv.org/abs/2402.05120) | 大型语言模型的性能与代理数量成比例，通过简单的采样和投票方法可以进一步增强性能，这种方法与现有的复杂方法正交。 |
| [^13] | [Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies](https://arxiv.org/abs/2402.03819) | SMOTE是一种处理不平衡数据集的常用重新平衡策略，它通过复制原始少数样本来重新生成原始分布。本研究证明了SMOTE的密度在少数样本分布的边界附近逐渐减小，从而验证了BorderLine SMOTE策略的合理性。此外，研究还提出了两种新的SMOTE相关策略，并与其他重新平衡方法进行了比较。最终发现，在数据集极度不平衡的情况下，SMOTE、提出的方法或欠采样程序是最佳的策略。 |
| [^14] | [DeLLMa: A Framework for Decision Making Under Uncertainty with Large Language Models](https://arxiv.org/abs/2402.02392) | DeLLMa是一个旨在提高不确定环境下决策精度的框架，通过多步骤的脚手架程序，借鉴决策理论和效用理论的原则，可以显著提高大型语言模型的决策性能。 |
| [^15] | [The Selected-completely-at-random Complementary Label is a Practical Weak Supervision for Multi-class Classification](https://arxiv.org/abs/2311.15502) | 提出了一种不依赖于均匀分布假设的互补标签学习方法，基于完全随机选择假设的无偏风险估计器，以及风险校正方法来解决过拟合问题。 |
| [^16] | [Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter Paradigm for Performance Estimation in Online and Static Settings.](http://arxiv.org/abs/2401.09376) | 该论文通过适应Hui-Walter范式，将传统应用于流行病学和医学的方法引入机器学习领域，解决了训练和评估时无法获得标签数据的问题。通过将数据划分为潜在类别，并在多个测试中独立训练模型，能够在没有真实值的情况下估计关键性能指标，并在处理在线数据时提供了新的可能性。 |
| [^17] | [Deep Neural Decision Forest: A Novel Approach for Predicting Recovery or Decease of COVID-19 Patients with Clinical and RT-PCR.](http://arxiv.org/abs/2311.13925) | 该研究介绍了一种利用临床和RT-PCR数据结合深度学习算法来预测COVID-19患者康复或死亡风险的新方法。 |
| [^18] | [Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification.](http://arxiv.org/abs/2310.10379) | 本文重新审视和重新设计了逻辑-softmax似然，通过温度参数控制先验置信水平，从而改善了贝叶斯元学习中的少样本分类问题。同时证明softmax是逻辑-softmax的一种特殊情况，逻辑-softmax能够引导更大的数据分布家族。 |
| [^19] | [Explainable Attention for Few-shot Learning and Beyond.](http://arxiv.org/abs/2310.07800) | 本研究介绍了一种用于少样本学习的解释性注意力框架，旨在通过识别输入数据的关键部分来提高模型性能。 |
| [^20] | [PostRainBench: A comprehensive benchmark and a new model for precipitation forecasting.](http://arxiv.org/abs/2310.02676) | PostRainBench是一个全面的降水预测基准，结合AI后处理技术和传统的数值天气预报方法，能够增强准确性并解决复杂的降水预测挑战。 |
| [^21] | [Foundation Reinforcement Learning: towards Embodied Generalist Agents with Foundation Prior Assistance.](http://arxiv.org/abs/2310.02635) | 本研究提出了一种基于具身基础先验的基础强化学习框架，通过加速训练过程来提高样本效率。 |
| [^22] | [GPSINDy: Data-Driven Discovery of Equations of Motion.](http://arxiv.org/abs/2309.11076) | GPSINDy是一种数据驱动的方法，通过将高斯过程回归与SINDy相结合，能够从噪声数据中发现非线性动力学系统模型，并在实验证明了其在系统动态和预测未来轨迹方面的改进性能。 |
| [^23] | [CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement.](http://arxiv.org/abs/2308.12902) | 本研究提出了一种名为CDAN的卷积稠密注意力引导网络，用于低光图像增强。该网络结合了自编码器架构、卷积和稠密块、注意力机制和跳跃连接，通过专门的后处理阶段进一步改善色彩平衡和对比度。与现有方法相比，在低光图像增强方面取得了显著的进展，展示了在各种具有挑战性的场景中的稳健性。 |
| [^24] | [Continuous Sweep: an improved, binary quantifier.](http://arxiv.org/abs/2308.08387) | Continuous Sweep是一种改进的二元量化器，通过使用参数化类别分布、优化决策边界以及计算均值等方法，它在量化学习中取得了更好的性能。 |
| [^25] | [Certified Multi-Fidelity Zeroth-Order Optimization.](http://arxiv.org/abs/2308.00978) | 本文研究了认证的多流程零阶优化问题，提出了MFDOO算法的认证变体，并证明了其具有近似最优的代价复杂度。同时，还考虑了有噪声评估的特殊情况。 |
| [^26] | [Mercer Large-Scale Kernel Machines from Ridge Function Perspective.](http://arxiv.org/abs/2307.11925) | 本文从岭函数的角度介绍了Mercer大规模核机器，通过研究哪些核函数可以被余弦函数乘积逼近，解决了大规模核机器中的难题。这些结果对深度学习，特别是图像处理有潜在应用。 |
| [^27] | [Discovering How Agents Learn Using Few Data.](http://arxiv.org/abs/2307.06640) | 本研究提出了一个在少量数据上识别智能体学习动力学的算法框架。通过使用多项式回归和引入捕捉智能体行为的侧信息约束，该方法可以在使用单个轨迹的短暂运行中仅仅5个样本的情况下准确恢复真实动力学。 |
| [^28] | [Kernel Metric Learning for Clustering Mixed-type Data.](http://arxiv.org/abs/2306.01890) | 提出了一种使用混合核测量不相似性的度量方法，并通过交叉验证找到最佳核带宽。该方法可为现有的基于距离的聚类算法提高聚类准确度，适用于包含混合类型数据的模拟和实际数据集。 |
| [^29] | [Why Clean Generalization and Robust Overfitting Both Happen in Adversarial Training.](http://arxiv.org/abs/2306.01271) | 对抗训练是训练深度神经网络抗击对抗扰动的标准方法, 其学习机制导致干净泛化和强健过拟合现象同时发生。 |
| [^30] | [Federated Offline Policy Learning with Heterogeneous Observational Data.](http://arxiv.org/abs/2305.12407) | 本文提出了一种基于异构数据源的联邦政策学习算法，该算法基于本地策略聚合的方法，使用双重稳健线下策略评估和学习策略进行训练，可以在不交换原始数据的情况下学习个性化决策政策。我们建立了全局和局部后悔上限的理论模型，并用实验结果支持了理论发现。 |
| [^31] | [In Defense of Pure 16-bit Floating-Point Neural Networks.](http://arxiv.org/abs/2305.10947) | 本文探讨了纯16位浮点神经网络的被忽视的效率，提供了理论分析来探讨16位和32位模型的差异，并可以定量解释16位模型与其32位对应物之间的条件。 |
| [^32] | [PI-FL: Personalized and Incentivized Federated Learning.](http://arxiv.org/abs/2304.07514) | PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。 |
| [^33] | [BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with Graph Information Bottleneck.](http://arxiv.org/abs/2205.03612) | BrainIB是一种基于图信息瓶颈原理开发的图神经网络框架，在分析fMRI图像中的功能连接时能够识别最具信息量的边缘，具有良好的泛化能力和可解释性，适用于未见样本的场景。 |
| [^34] | [Learning Interpretable Characteristic Kernels via Decision Forests.](http://arxiv.org/abs/1812.00029) | 本论文介绍了一种通过决策森林构建可解释的特征核的方法，我们构建了基于叶节点相似性的核平均嵌入随机森林（KMERF），并证明其在离散和连续数据上都表现出渐进特征。实验证明KMERF在多种高维数据测试中优于目前的最先进的基于核的方法。 |

# 详细

[^1]: D'OH: 仅解码器随机超网络用于隐式神经表示

    D'OH: Decoder-Only random Hypernetworks for Implicit Neural Representations

    [https://arxiv.org/abs/2403.19163](https://arxiv.org/abs/2403.19163)

    本文提出使用仅运行时解码器的超网络，不依赖离线数据训练，以更好地模拟跨层参数冗余。

    

    深度隐式函数被发现是一种有效的工具，可以高效地编码各种自然信号。它们的吸引力在于能够紧凑地表示信号，几乎不需要离线训练数据。相反，它们利用深度网络的隐式偏差来解耦信号中的隐藏冗余。在本文中，我们探讨了这样一个假设：通过利用层之间存在的冗余可以实现更好的压缩。我们提出使用一种新颖的仅运行时解码器的超网络 - 它不使用离线训练数据 - 来更好地建模跨层参数冗余。先前在深度隐式函数中应用超网络的应用都采用了依赖大量离线数据集的前馈编码器/解码器框架，这些数据集无法泛化到训练信号之外。相反，我们提出一种用于初始化运行时深度隐式函数的策略

    arXiv:2403.19163v1 Announce Type: new  Abstract: Deep implicit functions have been found to be an effective tool for efficiently encoding all manner of natural signals. Their attractiveness stems from their ability to compactly represent signals with little to no off-line training data. Instead, they leverage the implicit bias of deep networks to decouple hidden redundancies within the signal. In this paper, we explore the hypothesis that additional compression can be achieved by leveraging the redundancies that exist between layers. We propose to use a novel run-time decoder-only hypernetwork - that uses no offline training data - to better model this cross-layer parameter redundancy. Previous applications of hyper-networks with deep implicit functions have applied feed-forward encoder/decoder frameworks that rely on large offline datasets that do not generalize beyond the signals they were trained on. We instead present a strategy for the initialization of run-time deep implicit func
    
[^2]: skscope：Python中的快速稀疏约束优化

    skscope: Fast Sparsity-Constrained Optimization in Python

    [https://arxiv.org/abs/2403.18540](https://arxiv.org/abs/2403.18540)

    skscope是一个Python库，通过只需编写目标函数，就能快速实现稀疏约束优化问题的解决，并且在高维参数空间下，其高效实现使得求解器能够迅速获得稀疏解，速度比基准凸求解器快80倍。

    

    在稀疏约束优化（SCO）上应用迭代求解器需要繁琐的数学推导和仔细的编程/调试，这限制了这些求解器的广泛影响。本文介绍了库skscope，以克服此障碍。借助skscope，用户只需编写目标函数即可解决SCO问题。本文通过两个例子演示了skscope的方便之处，其中只需四行代码就可以解决稀疏线性回归和趋势过滤。更重要的是，skscope的高效实现使得最先进的求解器可以快速获得稀疏解，而无需考虑参数空间的高维度。数值实验显示，skscope中的可用求解器可以实现比基准凸求解器获得的竞争松弛解高达80倍的加速度。skscope已经发布在Python软件包索引（PyPI）和Conda上。

    arXiv:2403.18540v1 Announce Type: cross  Abstract: Applying iterative solvers on sparsity-constrained optimization (SCO) requires tedious mathematical deduction and careful programming/debugging that hinders these solvers' broad impact. In the paper, the library skscope is introduced to overcome such an obstacle. With skscope, users can solve the SCO by just programming the objective function. The convenience of skscope is demonstrated through two examples in the paper, where sparse linear regression and trend filtering are addressed with just four lines of code. More importantly, skscope's efficient implementation allows state-of-the-art solvers to quickly attain the sparse solution regardless of the high dimensionality of parameter space. Numerical experiments reveal the available solvers in skscope can achieve up to 80x speedup on the competing relaxation solutions obtained via the benchmarked convex solver. skscope is published on the Python Package Index (PyPI) and Conda, and its 
    
[^3]: 引导解码用于机器人运动生成和适应

    Guided Decoding for Robot Motion Generation and Adaption

    [https://arxiv.org/abs/2403.15239](https://arxiv.org/abs/2403.15239)

    通过将演示学习集成到运动生成中，使机器人能够实时生成适应复杂环境的运动

    

    我们针对具有障碍物、通过点等复杂环境下的高自由度机器人臂运动生成问题进行了探讨。通过将演示学习（LfD）集成到运动生成过程中，取得了该领域的重大进展。这种集成支持机器人快速适应新任务，并通过允许机器人从演示轨迹中学习和泛化来优化积累的经验利用。我们在大量模拟轨迹数据集上训练了一个变分自动编码器变换器的transformer架构。这种基于条件变分自动编码器变换器的架构学习了基本的运动生成技能，并将其调整以满足辅助任务和约束条件。我们的自回归方法实现了物理系统反馈的实时集成，增强了运动生成的适应性和效率。我们展示了我们的模型能够从初始点和目标点生成运动，同时

    arXiv:2403.15239v1 Announce Type: cross  Abstract: We address motion generation for high-DoF robot arms in complex settings with obstacles, via points, etc. A significant advancement in this domain is achieved by integrating Learning from Demonstration (LfD) into the motion generation process. This integration facilitates rapid adaptation to new tasks and optimizes the utilization of accumulated expertise by allowing robots to learn and generalize from demonstrated trajectories.   We train a transformer architecture on a large dataset of simulated trajectories. This architecture, based on a conditional variational autoencoder transformer, learns essential motion generation skills and adapts these to meet auxiliary tasks and constraints. Our auto-regressive approach enables real-time integration of feedback from the physical system, enhancing the adaptability and efficiency of motion generation. We show that our model can generate motion from initial and target points, but also that it 
    
[^4]: 理解为何标签平滑会降低选择性分类的效果以及如何解决这个问题

    Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It

    [https://arxiv.org/abs/2403.14715](https://arxiv.org/abs/2403.14715)

    LS方法在深度神经网络分类器训练中的标签平滑效果被发现会负面影响选择性分类，通过影响模型预测不确定性，此研究阐明了这一现象。

    

    标签平滑（LS）是一种流行的深度神经网络分类器训练的正则化方法，因为它在提高测试准确性方面效果显著，并且实现简单。"硬"的one-hot标签通过将概率质量均匀分配给其他类别来进行"平滑化"，从而减少过度拟合。在这项工作中，我们揭示了LS如何负面影响选择性分类（SC）- 其目标是利用模型的预测不确定性来拒绝错误分类。我们首先在一系列任务和架构中从经验上证明LS会导致SC的一致性降级。然后，我们通过分析logit级别的梯度来解释这一点，表明LS通过在错误概率低时更加正则化最大logit，而在错误概率高时更少正则化，加剧了过度自信和低自信。这阐明了以前报道的强分类器在SC中性能不佳的实验结果。

    arXiv:2403.14715v1 Announce Type: cross  Abstract: Label smoothing (LS) is a popular regularisation method for training deep neural network classifiers due to its effectiveness in improving test accuracy and its simplicity in implementation. "Hard" one-hot labels are "smoothed" by uniformly distributing probability mass to other classes, reducing overfitting. In this work, we reveal that LS negatively affects selective classification (SC) - where the aim is to reject misclassifications using a model's predictive uncertainty. We first demonstrate empirically across a range of tasks and architectures that LS leads to a consistent degradation in SC. We then explain this by analysing logit-level gradients, showing that LS exacerbates overconfidence and underconfidence by regularising the max logit more when the probability of error is low, and less when the probability of error is high. This elucidates previously reported experimental results where strong classifiers underperform in SC. We
    
[^5]: 基于可微分模拟和优化的任务最优数据驱动替代模型用于eNMPC

    Task-optimal data-driven surrogate models for eNMPC via differentiable simulation and optimization

    [https://arxiv.org/abs/2403.14425](https://arxiv.org/abs/2403.14425)

    提出了一种基于可微分模拟和优化的任务最优数据驱动替代模型方法，在eNMPC中表现出优越性能，为实现更具能力的控制器提供了有前途的途径。

    

    我们提出了一种用于控制中优化性能的Koopman替代模型端到端学习方法。与之前采用标准强化学习（RL）算法的贡献相反，我们使用一种训练算法，利用基于机械模拟模型的环境的潜在可微性。通过将我们的方法与文献已知的eNMPC案例研究中其他控制器类型和训练算法组合的性能进行比较，我们评估了我们方法的性能。我们的方法在这个问题上表现出优越的性能，因此在使用动态替代模型的更有能力的控制器方面构成了一个有前途的途径。

    arXiv:2403.14425v1 Announce Type: new  Abstract: We present a method for end-to-end learning of Koopman surrogate models for optimal performance in control. In contrast to previous contributions that employ standard reinforcement learning (RL) algorithms, we use a training algorithm that exploits the potential differentiability of environments based on mechanistic simulation models. We evaluate the performance of our method by comparing it to that of other controller type and training algorithm combinations on a literature known eNMPC case study. Our method exhibits superior performance on this problem, thereby constituting a promising avenue towards more capable controllers that employ dynamic surrogate models.
    
[^6]: 使用GFlowNets的蚁群采样用于组合优化

    Ant Colony Sampling with GFlowNets for Combinatorial Optimization

    [https://arxiv.org/abs/2403.07041](https://arxiv.org/abs/2403.07041)

    本文提出了生成流蚁群采样器（GFACS），一种结合生成流网络与蚁群优化方法的神经引导元启发式算法，在组合优化任务中表现优于基线ACO算法并与特定问题启发式方法具有竞争力。

    

    本文介绍了生成流蚁群采样器（GFACS），这是一种新颖的用于组合优化的神经引导元启发式算法。GFACS 将生成流网络（GFlowNets）与蚁群优化（ACO）方法相结合。GFlowNets 是一种生成模型，它在组合空间中学习构造性策略，通过在输入图实例上提供决策变量的知情先验分布来增强 ACO。此外，我们引入了一种新颖的训练技巧组合，包括搜索引导的局部探索、能量归一化和能量塑形，以提高 GFACS 的性能。我们的实验结果表明，GFACS 在七个组合优化任务中优于基线 ACO 算法，并且在车辆路径问题的问题特定启发式方法中具有竞争力。源代码可在 \url{https://github.com/ai4co/gfacs} 获取。

    arXiv:2403.07041v1 Announce Type: new  Abstract: This paper introduces the Generative Flow Ant Colony Sampler (GFACS), a novel neural-guided meta-heuristic algorithm for combinatorial optimization. GFACS integrates generative flow networks (GFlowNets) with the ant colony optimization (ACO) methodology. GFlowNets, a generative model that learns a constructive policy in combinatorial spaces, enhance ACO by providing an informed prior distribution of decision variables conditioned on input graph instances. Furthermore, we introduce a novel combination of training tricks, including search-guided local exploration, energy normalization, and energy shaping to improve GFACS. Our experimental results demonstrate that GFACS outperforms baseline ACO algorithms in seven CO tasks and is competitive with problem-specific heuristics for vehicle routing problems. The source code is available at \url{https://github.com/ai4co/gfacs}.
    
[^7]: 在边缘进行机器学习模型训练：一项调研

    Training Machine Learning models at the Edge: A Survey

    [https://arxiv.org/abs/2403.02619](https://arxiv.org/abs/2403.02619)

    这项调研深入探讨了边缘学习(EL)中优化机器学习模型训练的各种方法和方法论，旨在综合现有知识，识别挑战，并突出未来趋势。

    

    边缘计算(EC)近年来获得了显著关注，通过在边缘集成人工智能(AI)能力，承诺提高效率。虽然主要关注点在边缘部署和推断机器学习(ML)模型，但训练方面仍然较少被探讨。这项调研深入探讨了边缘学习(EL)，特别是在边缘优化ML模型训练的方面。其目标是全面探讨EL中的不同方法和方法论，综合现有知识，识别挑战，并突出未来趋势。利用Scopus的高级搜索，确定了关于EL的相关文献，显示了研究工作在分布式学习方法方面的聚焦，特别是联邦学习(FL)。此调研还提供了一个比较用于优化边缘学习的ML的技术的指南，以及对不同框架的探索。

    arXiv:2403.02619v1 Announce Type: new  Abstract: Edge Computing (EC) has gained significant traction in recent years, promising enhanced efficiency by integrating Artificial Intelligence (AI) capabilities at the edge. While the focus has primarily been on the deployment and inference of Machine Learning (ML) models at the edge, the training aspect remains less explored. This survey delves into Edge Learning (EL), specifically the optimization of ML model training at the edge. The objective is to comprehensively explore diverse approaches and methodologies in EL, synthesize existing knowledge, identify challenges, and highlight future trends. Utilizing Scopus' advanced search, relevant literature on EL was identified, revealing a concentration of research efforts in distributed learning methods, particularly Federated Learning (FL). This survey further provides a guideline for comparing techniques used to optimize ML for edge learning, along with an exploration of different frameworks, 
    
[^8]: SubIQ: 逆向软 Q 学习用于获得次优演示的离线模仿

    SubIQ: Inverse Soft-Q Learning for Offline Imitation with Suboptimal Demonstrations

    [https://arxiv.org/abs/2402.13147](https://arxiv.org/abs/2402.13147)

    逆向软 Q 学习用于获得次优演示的离线模仿挑战了离线 IL 中有限支持专家演示的问题，并提出了一种解决方案以匹配次优演示集合的占用分布

    

    我们考虑了离线模仿学习（IL），旨在从专家演示中模仿专家的行为，而无需与环境进行进一步交互。在离线 IL 中的一个主要挑战是处理仅涵盖状态-动作空间的一小部分的专家演示的有限支持。我们考虑离线 IL，其中专家演示受到限制，但是由更大规模的次优演示集合补充。大部分现有的用于此设置的离线 IL 方法基于行为克隆或分布匹配，其目的是将模仿策略的占用分布与专家策略的占用分布匹配。这种方法往往存在过拟合问题，因为专家演示有限，无法准确表示任何占用分布。另一方面，由于次优演示集合规模更大，有很高的可能性

    arXiv:2402.13147v1 Announce Type: cross  Abstract: We consider offline imitation learning (IL), which aims to mimic the expert's behavior from its demonstration without further interaction with the environment. One of the main challenges in offline IL is dealing with the limited support of expert demonstrations that cover only a small fraction of the state-action spaces. In this work, we consider offline IL, where expert demonstrations are limited but complemented by a larger set of sub-optimal demonstrations of lower expertise levels. Most of the existing offline IL methods developed for this setting are based on behavior cloning or distribution matching, where the aim is to match the occupancy distribution of the imitation policy with that of the expert policy. Such an approach often suffers from over-fitting, as expert demonstrations are limited to accurately represent any occupancy distribution. On the other hand, since sub-optimal sets are much larger, there is a high chance that 
    
[^9]: 基于机器学习的水降载荷预测

    Machine Learning based Prediction of Ditching Loads

    [https://arxiv.org/abs/2402.10724](https://arxiv.org/abs/2402.10724)

    该研究提出了使用机器学习来预测飞机机身动态水降载荷的方法，通过结合卷积自编码器和长短期记忆网络或Koopman算子方法，取得了令人满意的预测结果。

    

    我们提出了使用机器学习来预测飞机机身动态水降载荷的方法。所采用的学习过程分为两部分，即使用卷积自编码器（CAE）重构空间载荷，以及在随后的部分中这些载荷的瞬时演化。评估了不同的CAE策略，并将其与长短期记忆（LSTM）网络或基于Koopman算子的方法相结合，以预测瞬时行为。训练数据是通过von-Karman和Wagner的动量方法的扩展编制的，训练方法的基本原理被简要总结。所涉及的应用是指DLR-D150飞机的全尺寸机身，包括一系列水平和垂直进场速度，入射角为6°。结果表明，对于所有四个研究的代理模型，采用LSTM结合...（内容缺失）

    arXiv:2402.10724v1 Announce Type: new  Abstract: We present approaches to predict dynamic ditching loads on aircraft fuselages using machine learning. The employed learning procedure is structured into two parts, the reconstruction of the spatial loads using a convolutional autoencoder (CAE) and the transient evolution of these loads in a subsequent part. Different CAE strategies are assessed and combined with either long short-term memory (LSTM) networks or Koopman-operator based methods to predict the transient behaviour. The training data is compiled by an extension of the momentum method of von-Karman and Wagner and the rationale of the training approach is briefly summarised. The application included refers to a full-scale fuselage of a DLR-D150 aircraft for a range of horizontal and vertical approach velocities at 6{\deg} incidence. Results indicate a satisfactory level of predictive agreement for all four investigated surrogate models examined, with the combination of an LSTM an
    
[^10]: 一位量化和稀疏化用于多类线性分类的正则化回归

    One-Bit Quantization and Sparsification for Multiclass Linear Classification via Regularized Regression

    [https://arxiv.org/abs/2402.10474](https://arxiv.org/abs/2402.10474)

    通过正则化回归，在超参数化范围内，根据特定选择的凸函数并适当增加一个正则化项，可以实现稀疏和一位解决方案，其性能几乎与最佳分类性能相同。

    

    我们研究了在线性回归中用于多类分类的问题，这些问题在超参数化范围内，训练数据中一些标记错误。在这种情况下，为了避免过度拟合错误标记的数据，需要添加一个显式的正则化项，$\lambda f(w)$，其中$f(\cdot)$是某个凸函数。在我们的分析中，我们假设数据是从一个具有相等类大小的高斯混合模型中采样的，并且每个类别的训练标签中有一部分比例为$c$是错误的。在这些假设下，我们证明了当$f(\cdot) = \|\cdot\|^2_2$且$\lambda \to \infty$时，可以获得最佳的分类性能。然后我们继续分析了在大$\lambda$范围内$f(\cdot) = \|\cdot\|_1$和$f(\cdot) = \|\cdot\|_\infty$的分类错误，并且注意到通常可以找到稀疏和一位解决方案，分别表现几乎与$f(\cdot) = \|\cdot\|^2_2$相同。

    arXiv:2402.10474v1 Announce Type: new  Abstract: We study the use of linear regression for multiclass classification in the over-parametrized regime where some of the training data is mislabeled. In such scenarios it is necessary to add an explicit regularization term, $\lambda f(w)$, for some convex function $f(\cdot)$, to avoid overfitting the mislabeled data. In our analysis, we assume that the data is sampled from a Gaussian Mixture Model with equal class sizes, and that a proportion $c$ of the training labels is corrupted for each class. Under these assumptions, we prove that the best classification performance is achieved when $f(\cdot) = \|\cdot\|^2_2$ and $\lambda \to \infty$. We then proceed to analyze the classification errors for $f(\cdot) = \|\cdot\|_1$ and $f(\cdot) = \|\cdot\|_\infty$ in the large $\lambda$ regime and notice that it is often possible to find sparse and one-bit solutions, respectively, that perform almost as well as the one corresponding to $f(\cdot) = \|\
    
[^11]: 在 Actor-Critic 方法中利用估计偏差的深度双 Q-Learning 的探索

    Exploiting Estimation Bias in Deep Double Q-Learning for Actor-Critic Methods

    [https://arxiv.org/abs/2402.09078](https://arxiv.org/abs/2402.09078)

    本文提出了两种创新方法，ExpD3 和 BE-TD3，用于解决和利用 Actor-Critic 方法中的估计偏差问题。实验证明这些算法在连续控制任务中比现有方法更高效。

    

    本文介绍了在强化学习领域中创新的方法，重点是解决和利用连续控制任务中 Actor-Critic 方法中的估计偏差问题，使用了深度双 Q-Learning。我们提出了两种新的算法：Expectile Delayed Deep Deterministic Policy Gradient (ExpD3) 和 Bias Exploiting - Twin Delayed Deep Deterministic Policy Gradient (BE-TD3)。ExpD3 旨在通过单一的 Q 估计来减少过度估计偏差，并在计算效率和性能之间提供平衡，而 BE-TD3 则旨在在训练过程中动态选择最有利的估计偏差。我们进行了大量的实验，在各种连续控制任务中展示了我们方法的有效性。我们展示了这些算法在与 TD3 等现有方法相比，尤其是在估计偏差显著影响学习的环境中，可以匹敌或超越它们。这些结果凸显了估计偏差对学习的重要性。

    arXiv:2402.09078v1 Announce Type: cross Abstract: This paper introduces innovative methods in Reinforcement Learning (RL), focusing on addressing and exploiting estimation biases in Actor-Critic methods for continuous control tasks, using Deep Double Q-Learning. We propose two novel algorithms: Expectile Delayed Deep Deterministic Policy Gradient (ExpD3) and Bias Exploiting - Twin Delayed Deep Deterministic Policy Gradient (BE-TD3). ExpD3 aims to reduce overestimation bias with a single $Q$ estimate, offering a balance between computational efficiency and performance, while BE-TD3 is designed to dynamically select the most advantageous estimation bias during training. Our extensive experiments across various continuous control tasks demonstrate the effectiveness of our approaches. We show that these algorithms can either match or surpass existing methods like TD3, particularly in environments where estimation biases significantly impact learning. The results underline the importance of
    
[^12]: 更多的代理就是你所需要的

    More Agents Is All You Need

    [https://arxiv.org/abs/2402.05120](https://arxiv.org/abs/2402.05120)

    大型语言模型的性能与代理数量成比例，通过简单的采样和投票方法可以进一步增强性能，这种方法与现有的复杂方法正交。

    

    我们发现，仅通过一种采样和投票的方法，大型语言模型(Large Language Models, LLMs)的性能与实例化的代理数量成比例。此外，这种方法对已有的复杂方法进一步增强LLMs是正交的，而增强的程度与任务的困难程度相关。我们进行了广泛的实验，验证了我们的发现，并研究了能够促进其发生的属性。我们的代码公开在以下网址: \url{https://anonymous.4open.science/r/more_agent_is_all_you_need}

    We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: \url{https://anonymous.4open.science/r/more_agent_is_all_you_need}.
    
[^13]: SMOTE的理论和实验研究：关于重新平衡策略的限制和比较

    Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies

    [https://arxiv.org/abs/2402.03819](https://arxiv.org/abs/2402.03819)

    SMOTE是一种处理不平衡数据集的常用重新平衡策略，它通过复制原始少数样本来重新生成原始分布。本研究证明了SMOTE的密度在少数样本分布的边界附近逐渐减小，从而验证了BorderLine SMOTE策略的合理性。此外，研究还提出了两种新的SMOTE相关策略，并与其他重新平衡方法进行了比较。最终发现，在数据集极度不平衡的情况下，SMOTE、提出的方法或欠采样程序是最佳的策略。

    

    SMOTE（Synthetic Minority Oversampling Technique）是处理不平衡数据集常用的重新平衡策略。我们证明了在渐进情况下，SMOTE（默认参数）通过简单复制原始少数样本来重新生成原始分布。我们还证明了在少数样本分布的支持边界附近，SMOTE的密度会减小，从而验证了常见的BorderLine SMOTE策略。随后，我们提出了两种新的SMOTE相关策略，并将它们与现有的重新平衡方法进行了比较。我们发现，只有当数据集极度不平衡时才需要重新平衡策略。对于这种数据集，SMOTE、我们提出的方法或欠采样程序是最佳的策略。

    Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.
    
[^14]: DeLLMa:一个用于大型语言模型下决策的框架

    DeLLMa: A Framework for Decision Making Under Uncertainty with Large Language Models

    [https://arxiv.org/abs/2402.02392](https://arxiv.org/abs/2402.02392)

    DeLLMa是一个旨在提高不确定环境下决策精度的框架，通过多步骤的脚手架程序，借鉴决策理论和效用理论的原则，可以显著提高大型语言模型的决策性能。

    

    大型语言模型（LLMs）在商业、工程和医学等领域被广泛应用，这些领域往往面临决策不确定性的问题，这是一个关键但具有挑战性的任务。本文表明，在决策问题上直接使用LLMs往往效果较差，尤其是在问题复杂性增加时。为了克服这个限制，我们提出了DeLLMa（Decision-making Large Language Model assistant）框架，旨在提高不确定环境下的决策精度。DeLLMa包括一个多步骤的脚手架程序，借鉴了决策理论和效用理论的原则，提供了一个最优的、可审计的决策过程。我们在涉及真实农业和金融数据的决策环境中验证了我们的框架。结果表明，DeLLMa可以显著提高LLMs的决策性能，准确性可提高高达40%以上。

    Large language models (LLMs) are increasingly used across society, including in domains like business, engineering, and medicine. These fields often grapple with decision-making under uncertainty, a critical yet challenging task. In this paper, we show that directly prompting LLMs on these types of decision-making problems yields poor results, especially as the problem complexity increases. To overcome this limitation, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments. DeLLMa involves a multi-step scaffolding procedure, drawing upon principles from decision theory and utility theory, to provide an optimal and human-auditable decision-making process. We validate our framework on decision-making environments involving real agriculture and finance data. Our results show that DeLLMa can significantly improve LLM decision-making performance, achieving up to a 40% increase in accuracy over co
    
[^15]: 选取完全随机的互补标签是多类别分类的实用弱监督方法

    The Selected-completely-at-random Complementary Label is a Practical Weak Supervision for Multi-class Classification

    [https://arxiv.org/abs/2311.15502](https://arxiv.org/abs/2311.15502)

    提出了一种不依赖于均匀分布假设的互补标签学习方法，基于完全随机选择假设的无偏风险估计器，以及风险校正方法来解决过拟合问题。

    

    互补标签学习是一个弱监督学习问题，每个训练样本关联着一个或多个互补标签，指示其不属于的类别。现有的一致方法依赖于均匀分布假设来模拟互补标签的生成，或者依赖于一个普通标签的训练集来估计非均匀情况下的转移矩阵。然而，实际情况下这两个条件可能不会被满足。在本文中，我们提出了一种新颖的一致方法，不依赖于这些条件。受到PU学习文献的启发，我们提出了基于完全随机选择假设的无偏风险估计器，用于互补标签学习。然后，我们引入了一种风险校正方法来解决过拟合问题。此外，我们发现互补标签学习可以被表达为一组...

    arXiv:2311.15502v2 Announce Type: replace  Abstract: Complementary-label learning is a weakly supervised learning problem in which each training example is associated with one or multiple complementary labels indicating the classes to which it does not belong. Existing consistent approaches have relied on the uniform distribution assumption to model the generation of complementary labels, or on an ordinary-label training set to estimate the transition matrix in non-uniform cases. However, either condition may not be satisfied in real-world scenarios. In this paper, we propose a novel consistent approach that does not rely on these conditions. Inspired by the positive-unlabeled (PU) learning literature, we propose an unbiased risk estimator based on the Selected Completely At Random assumption for complementary-label learning. We then introduce a risk-correction approach to address overfitting problems. Furthermore, we find that complementary-label learning can be expressed as a set of 
    
[^16]: 解锁无标签数据: Hui-Walter范式在在线和静态环境中的性能评估中的集成学习

    Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter Paradigm for Performance Estimation in Online and Static Settings. (arXiv:2401.09376v1 [cs.LG])

    [http://arxiv.org/abs/2401.09376](http://arxiv.org/abs/2401.09376)

    该论文通过适应Hui-Walter范式，将传统应用于流行病学和医学的方法引入机器学习领域，解决了训练和评估时无法获得标签数据的问题。通过将数据划分为潜在类别，并在多个测试中独立训练模型，能够在没有真实值的情况下估计关键性能指标，并在处理在线数据时提供了新的可能性。

    

    在机器学习和统计建模领域，从业人员常常在可评估和训练的假设下工作，即可访问的、静态的、带有标签的数据。然而，这个假设往往偏离了现实，其中的数据可能是私有的、加密的、难以测量的或者没有标签。本文通过将传统应用于流行病学和医学的Hui-Walter范式调整到机器学习领域来弥合这个差距。这种方法使我们能够在没有真实值可用的情况下估计关键性能指标，如假阳性率、假阴性率和先验概率。我们进一步扩展了这种范式来处理在线数据，开辟了动态数据环境的新可能性。我们的方法涉及将数据划分为潜在类别，以模拟多个数据群体（如果没有自然群体可用），并独立训练模型来复制多次测试。通过在不同数据子集之间交叉制表，我们能够比较二元结果。

    In the realm of machine learning and statistical modeling, practitioners often work under the assumption of accessible, static, labeled data for evaluation and training. However, this assumption often deviates from reality where data may be private, encrypted, difficult- to-measure, or unlabeled. In this paper, we bridge this gap by adapting the Hui-Walter paradigm, a method traditionally applied in epidemiology and medicine, to the field of machine learning. This approach enables us to estimate key performance metrics such as false positive rate, false negative rate, and priors in scenarios where no ground truth is available. We further extend this paradigm for handling online data, opening up new possibilities for dynamic data environments. Our methodology involves partitioning data into latent classes to simulate multiple data populations (if natural populations are unavailable) and independently training models to replicate multiple tests. By cross-tabulating binary outcomes across
    
[^17]: 深度神经决策森林：一种用于预测COVID-19患者康复或死亡的新方法，结合临床和RT-PCR数据

    Deep Neural Decision Forest: A Novel Approach for Predicting Recovery or Decease of COVID-19 Patients with Clinical and RT-PCR. (arXiv:2311.13925v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2311.13925](http://arxiv.org/abs/2311.13925)

    该研究介绍了一种利用临床和RT-PCR数据结合深度学习算法来预测COVID-19患者康复或死亡风险的新方法。

    

    尽管世界卫生组织宣布大流行已经结束，但COVID-19仍然被视为一种地方性疾病。这次大流行以前所未有的方式打乱了人们的生活并导致广泛的发病率和死亡率。因此，紧急医生有必要确定高风险死亡患者，以便优先考虑医院设备的分配，尤其是在医疗资源有限的地区。尽管存在哪种数据最准确的预测的问题，但患者收集到的数据对于预测COVID-19病例的结果是有益的。因此，本研究旨在实现两个主要目标。首先，我们想要检查深度学习算法是否能够预测患者的死亡率。其次，我们研究了临床和RT-PCR对预测的影响，以确定哪个更可靠。我们定义了四个不同特征集的阶段，并使用可解释的深度学习方法构建了相应的模型。

    COVID-19 continues to be considered an endemic disease in spite of the World Health Organization's declaration that the pandemic is over. This pandemic has disrupted people's lives in unprecedented ways and caused widespread morbidity and mortality. As a result, it is important for emergency physicians to identify patients with a higher mortality risk in order to prioritize hospital equipment, especially in areas with limited medical services. The collected data from patients is beneficial to predict the outcome of COVID-19 cases, although there is a question about which data makes the most accurate predictions. Therefore, this study aims to accomplish two main objectives. First, we want to examine whether deep learning algorithms can predict a patient's morality. Second, we investigated the impact of Clinical and RT-PCR on prediction to determine which one is more reliable. We defined four stages with different feature sets and used interpretable deep learning methods to build appropr
    
[^18]: 重新审视贝叶斯元学习中逻辑-softmax似然用于少样本分类

    Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification. (arXiv:2310.10379v1 [cs.LG])

    [http://arxiv.org/abs/2310.10379](http://arxiv.org/abs/2310.10379)

    本文重新审视和重新设计了逻辑-softmax似然，通过温度参数控制先验置信水平，从而改善了贝叶斯元学习中的少样本分类问题。同时证明softmax是逻辑-softmax的一种特殊情况，逻辑-softmax能够引导更大的数据分布家族。

    

    元学习通过学习使用先前的知识解决新问题，在少样本分类中取得了有希望的结果。贝叶斯方法能够有效地表征少样本分类中的不确定性，这在高风险领域至关重要。然而，在多类别高斯过程分类中，逻辑-softmax似然一直被用作softmax似然的替代方法，因为其具有条件共轭性质。然而，逻辑-softmax的理论特性不清楚，以前的研究表明逻辑-softmax的固有不确定性导致了次优的性能。为了解决这些问题，我们重新审视和重新设计了逻辑-softmax似然，通过一个温度参数实现对先验置信水平的控制。此外，我们从理论和实践的角度证明了softmax可以被视为逻辑-softmax的一种特殊情况，并且逻辑-softmax引导了比softmax更大的数据分布家族。

    Meta-learning has demonstrated promising results in few-shot classification (FSC) by learning to solve new problems using prior knowledge. Bayesian methods are effective at characterizing uncertainty in FSC, which is crucial in high-risk fields. In this context, the logistic-softmax likelihood is often employed as an alternative to the softmax likelihood in multi-class Gaussian process classification due to its conditional conjugacy property. However, the theoretical property of logistic-softmax is not clear and previous research indicated that the inherent uncertainty of logistic-softmax leads to suboptimal performance. To mitigate these issues, we revisit and redesign the logistic-softmax likelihood, which enables control of the \textit{a priori} confidence level through a temperature parameter. Furthermore, we theoretically and empirically show that softmax can be viewed as a special case of logistic-softmax and logistic-softmax induces a larger family of data distribution than soft
    
[^19]: 解释性注意力用于少样本学习及其它领域

    Explainable Attention for Few-shot Learning and Beyond. (arXiv:2310.07800v1 [cs.AI])

    [http://arxiv.org/abs/2310.07800](http://arxiv.org/abs/2310.07800)

    本研究介绍了一种用于少样本学习的解释性注意力框架，旨在通过识别输入数据的关键部分来提高模型性能。

    

    注意力机制在增强学习模型中显示出了有希望的潜力，它可以通过识别输入数据中显著的部分来提高模型的性能。这在数据收集和标记方面存在挑战，导致训练样本有限的情况下尤其有价值。受人类认知过程启发，我们认为，如果将AI基线暴露于原始数据的关键部分而不是整个输入数据集，类似于人类的感知，那么它的性能可能会更准确、更可靠。然而，选择这些信息性数据部分的任务，即硬注意力寻找，是一个巨大的挑战。在少量训练样本的情况下，现有的研究很难找到这些信息性区域，原因是大量的训练参数无法从有限的样本中有效学习。在本研究中，我们介绍了一种实用的框架，用于实现可解释的硬注意力寻找。

    Attention mechanisms have exhibited promising potential in enhancing learning models by identifying salient portions of input data. This is particularly valuable in scenarios where limited training samples are accessible due to challenges in data collection and labeling. Drawing inspiration from human recognition processes, we posit that an AI baseline's performance could be more accurate and dependable if it is exposed to essential segments of raw data rather than the entire input dataset, akin to human perception. However, the task of selecting these informative data segments, referred to as hard attention finding, presents a formidable challenge. In situations with few training samples, existing studies struggle to locate such informative regions due to the large number of training parameters that cannot be effectively learned from the available limited samples. In this study, we introduce a novel and practical framework for achieving explainable hard attention finding, specifically
    
[^20]: PostRainBench: 一种全面的降水预测基准和新模型

    PostRainBench: A comprehensive benchmark and a new model for precipitation forecasting. (arXiv:2310.02676v1 [cs.LG])

    [http://arxiv.org/abs/2310.02676](http://arxiv.org/abs/2310.02676)

    PostRainBench是一个全面的降水预测基准，结合AI后处理技术和传统的数值天气预报方法，能够增强准确性并解决复杂的降水预测挑战。

    

    准确的降水预测是一项具有科学和社会重要性的重大挑战。数据驱动方法已经成为解决这个挑战的广泛采用的解决方案。然而，仅依赖数据驱动方法在模拟基础物理过程方面有限，使得准确预测困难。将基于人工智能的后处理技术与传统的数值天气预报（NWP）方法相结合，为提高预测准确性提供了更有效的解决方案。尽管之前进行过后处理的尝试，但由于不同位置的降水数据失衡和多个气象变量之间的复杂关系，准确预测大雨仍然具有挑战性。为了解决这些限制，我们提出了PostRainBench，这是一个全面的多变量NWP后处理基准，包括三个用于NWP后处理降水预测的数据集。我们提出了一种简单而有效的渠道注意力模型CAMT。

    Accurate precipitation forecasting is a vital challenge of both scientific and societal importance. Data-driven approaches have emerged as a widely used solution for addressing this challenge. However, solely relying on data-driven approaches has limitations in modeling the underlying physics, making accurate predictions difficult. Coupling AI-based post-processing techniques with traditional Numerical Weather Prediction (NWP) methods offers a more effective solution for improving forecasting accuracy. Despite previous post-processing efforts, accurately predicting heavy rainfall remains challenging due to the imbalanced precipitation data across locations and complex relationships between multiple meteorological variables. To address these limitations, we introduce the PostRainBench, a comprehensive multi-variable NWP post-processing benchmark consisting of three datasets for NWP post-processing-based precipitation forecasting. We propose CAMT, a simple yet effective Channel Attention
    
[^21]: 强化学习基础：朝向具有基础先验辅助的具身通用智能体

    Foundation Reinforcement Learning: towards Embodied Generalist Agents with Foundation Prior Assistance. (arXiv:2310.02635v1 [cs.RO])

    [http://arxiv.org/abs/2310.02635](http://arxiv.org/abs/2310.02635)

    本研究提出了一种基于具身基础先验的基础强化学习框架，通过加速训练过程来提高样本效率。

    

    最近人们已经表明，从互联网规模的数据中进行大规模预训练是构建通用模型的关键，正如在NLP中所见。为了构建具身通用智能体，我们和许多其他研究者假设这种基础先验也是不可或缺的组成部分。然而，目前尚不清楚如何以适当的具体形式表示这些具身基础先验，以及它们应该如何在下游任务中使用。在本文中，我们提出了一组直观有效的具身先验，包括基础策略、价值和成功奖励。所提出的先验是基于目标条件的MDP。为了验证其有效性，我们实例化了一个由这些先验辅助的演员-评论家方法，称之为基础演员-评论家（FAC）。我们将我们的框架命名为基础强化学习（FRL），因为它完全依赖于具身基础先验来进行探索、学习和强化。FRL的好处有三个。(1)样本效率高。通过基础先验加速训练过程，减少样本使用量。

    Recently, people have shown that large-scale pre-training from internet-scale data is the key to building generalist models, as witnessed in NLP. To build embodied generalist agents, we and many other researchers hypothesize that such foundation prior is also an indispensable component. However, it is unclear what is the proper concrete form to represent those embodied foundation priors and how they should be used in the downstream task. In this paper, we propose an intuitive and effective set of embodied priors that consist of foundation policy, value, and success reward. The proposed priors are based on the goal-conditioned MDP. To verify their effectiveness, we instantiate an actor-critic method assisted by the priors, called Foundation Actor-Critic (FAC). We name our framework as Foundation Reinforcement Learning (FRL), since it completely relies on embodied foundation priors to explore, learn and reinforce. The benefits of FRL are threefold. (1) Sample efficient. With foundation p
    
[^22]: GPSINDy: 数据驱动的动力学系统方程发现

    GPSINDy: Data-Driven Discovery of Equations of Motion. (arXiv:2309.11076v1 [cs.LG])

    [http://arxiv.org/abs/2309.11076](http://arxiv.org/abs/2309.11076)

    GPSINDy是一种数据驱动的方法，通过将高斯过程回归与SINDy相结合，能够从噪声数据中发现非线性动力学系统模型，并在实验证明了其在系统动态和预测未来轨迹方面的改进性能。

    

    本论文考虑从有噪声数据中发现动力学系统模型的问题。已知噪声存在对符号回归算法来说是一个重要问题。我们将高斯过程回归（一种非参数学习方法）与SINDy（一种参数学习方法）相结合，从数据中识别非线性动力学系统。我们的方法具有简单性和与SINDy相比在有噪声数据上表现出更好的鲁棒性的优点。我们在Lotka-Volterra模型和仿真中的单轮车动态模型上以及在使用硬件数据的NVIDIA JetRacer系统上展示了我们的方法。我们展示了相较于SINDy，我们的方法在发现系统动态和预测未来轨迹方面的改进性能。

    In this paper, we consider the problem of discovering dynamical system models from noisy data. The presence of noise is known to be a significant problem for symbolic regression algorithms. We combine Gaussian process regression, a nonparametric learning method, with SINDy, a parametric learning approach, to identify nonlinear dynamical systems from data. The key advantages of our proposed approach are its simplicity coupled with the fact that it demonstrates improved robustness properties with noisy data over SINDy. We demonstrate our proposed approach on a Lotka-Volterra model and a unicycle dynamic model in simulation and on an NVIDIA JetRacer system using hardware data. We demonstrate improved performance over SINDy for discovering the system dynamics and predicting future trajectories.
    
[^23]: CDAN: 用于低光图像增强的卷积稠密注意力引导网络

    CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement. (arXiv:2308.12902v1 [cs.CV])

    [http://arxiv.org/abs/2308.12902](http://arxiv.org/abs/2308.12902)

    本研究提出了一种名为CDAN的卷积稠密注意力引导网络，用于低光图像增强。该网络结合了自编码器架构、卷积和稠密块、注意力机制和跳跃连接，通过专门的后处理阶段进一步改善色彩平衡和对比度。与现有方法相比，在低光图像增强方面取得了显著的进展，展示了在各种具有挑战性的场景中的稳健性。

    

    低光图像以不足的照明为特征，面临清晰度减弱、颜色暗淡和细节减少的挑战。低光图像增强是计算机视觉中的一个重要任务，旨在通过改善亮度、对比度和整体感知质量来纠正这些问题，从而促进准确的分析和解释。本文介绍了一种新颖的解决方案：卷积稠密注意力引导网络（CDAN），用于增强低光图像。CDAN将自编码器架构与卷积和稠密块相结合，配合注意力机制和跳跃连接。该架构确保了有效的信息传递和特征学习。此外，专门的后处理阶段可以进一步改善色彩平衡和对比度。与低光图像增强领域的最新成果相比，我们的方法取得了显著的进展，并展示了在各种具有挑战性的场景中的稳健性。

    Low-light images, characterized by inadequate illumination, pose challenges of diminished clarity, muted colors, and reduced details. Low-light image enhancement, an essential task in computer vision, aims to rectify these issues by improving brightness, contrast, and overall perceptual quality, thereby facilitating accurate analysis and interpretation. This paper introduces the Convolutional Dense Attention-guided Network (CDAN), a novel solution for enhancing low-light images. CDAN integrates an autoencoder-based architecture with convolutional and dense blocks, complemented by an attention mechanism and skip connections. This architecture ensures efficient information propagation and feature learning. Furthermore, a dedicated post-processing phase refines color balance and contrast. Our approach demonstrates notable progress compared to state-of-the-art results in low-light image enhancement, showcasing its robustness across a wide range of challenging scenarios. Our model performs 
    
[^24]: Continuous Sweep: 一种改进的二元量化器

    Continuous Sweep: an improved, binary quantifier. (arXiv:2308.08387v1 [stat.ML])

    [http://arxiv.org/abs/2308.08387](http://arxiv.org/abs/2308.08387)

    Continuous Sweep是一种改进的二元量化器，通过使用参数化类别分布、优化决策边界以及计算均值等方法，它在量化学习中取得了更好的性能。

    

    量化是一种监督式机器学习任务，其关注的是估计数据集中类别的普遍性，而不是标记其个体观测。我们引入了Continuous Sweep，这是一种新的参数化二元量化器，受到表现良好的Median Sweep的启发。Median Sweep目前是最好的二元量化器之一，但我们在三个方面改变了这个量化器，即1）使用参数化的类别分布而不是经验分布，2）优化决策边界而不是应用离散的决策规则，3）计算均值而不是中位数。在一般模型假设下，我们推导了Continuous Sweep的偏差和方差的解析表达式。这是量化学习领域中的首次理论贡献之一。此外，这些推导使我们能够找到最优的决策边界。最后，我们的模拟研究表明，在广泛的情况下，Continuous Sweep优于Median Sweep。

    Quantification is a supervised machine learning task, focused on estimating the class prevalence of a dataset rather than labeling its individual observations. We introduce Continuous Sweep, a new parametric binary quantifier inspired by the well-performing Median Sweep. Median Sweep is currently one of the best binary quantifiers, but we have changed this quantifier on three points, namely 1) using parametric class distributions instead of empirical distributions, 2) optimizing decision boundaries instead of applying discrete decision rules, and 3) calculating the mean instead of the median. We derive analytic expressions for the bias and variance of Continuous Sweep under general model assumptions. This is one of the first theoretical contributions in the field of quantification learning. Moreover, these derivations enable us to find the optimal decision boundaries. Finally, our simulation study shows that Continuous Sweep outperforms Median Sweep in a wide range of situations.
    
[^25]: 认证的多流程零阶优化

    Certified Multi-Fidelity Zeroth-Order Optimization. (arXiv:2308.00978v1 [cs.LG])

    [http://arxiv.org/abs/2308.00978](http://arxiv.org/abs/2308.00978)

    本文研究了认证的多流程零阶优化问题，提出了MFDOO算法的认证变体，并证明了其具有近似最优的代价复杂度。同时，还考虑了有噪声评估的特殊情况。

    

    我们考虑多流程零阶优化的问题，在这个问题中，可以在不同的近似水平（代价不同）上评估函数$f$，目标是以尽可能低的代价优化$f$。在本文中，我们研究了\emph{认证}算法，它们额外要求输出一个对优化误差的数据驱动上界。我们首先以算法和评估环境之间的极小极大博弈形式来形式化问题。然后，我们提出了MFDOO算法的认证变体，并推导出其在任意Lipschitz函数$f$上的代价复杂度上界。我们还证明了一个依赖于$f$的下界，表明该算法具有近似最优的代价复杂度。最后，我们通过直接示例解决了有噪声（随机）评估的特殊情况。

    We consider the problem of multi-fidelity zeroth-order optimization, where one can evaluate a function $f$ at various approximation levels (of varying costs), and the goal is to optimize $f$ with the cheapest evaluations possible. In this paper, we study \emph{certified} algorithms, which are additionally required to output a data-driven upper bound on the optimization error. We first formalize the problem in terms of a min-max game between an algorithm and an evaluation environment. We then propose a certified variant of the MFDOO algorithm and derive a bound on its cost complexity for any Lipschitz function $f$. We also prove an $f$-dependent lower bound showing that this algorithm has a near-optimal cost complexity. We close the paper by addressing the special case of noisy (stochastic) evaluations as a direct example.
    
[^26]: 基于岭函数角度的Mercer大规模核机器

    Mercer Large-Scale Kernel Machines from Ridge Function Perspective. (arXiv:2307.11925v1 [cs.LG])

    [http://arxiv.org/abs/2307.11925](http://arxiv.org/abs/2307.11925)

    本文从岭函数的角度介绍了Mercer大规模核机器，通过研究哪些核函数可以被余弦函数乘积逼近，解决了大规模核机器中的难题。这些结果对深度学习，特别是图像处理有潜在应用。

    

    为了从岭函数的角度介绍Mercer大规模核机器，我们回顾了Lin和Pinkus在岭函数的基本性上的结果。我们考虑了Rachimi和Recht在近似理论中的最近一篇论文的主要定理，即大规模核机器的随机特征。我们研究了哪些核函数可以被$x$和$y$的余弦函数乘积的和逼近，并提出了这种方法的障碍。本文的结果可能在深度学习中有各种应用，尤其是与图像处理相关的问题。

    To present Mercer large-scale kernel machines from a ridge function perspective, we recall the results by Lin and Pinkus from Fundamentality of ridge functions. We consider the main theorem of the recent paper by Rachimi and Recht, 2008, Random features for large-scale kernel machines in terms of the Approximation Theory. We study which kernels can be approximated by a sum of cosine function products with arguments depending on $x$ and $y$ and present the obstacles of such an approach. The results of this article may have various applications in Deep Learning, especially in problems related to Image Processing.
    
[^27]: 发现智能体在少量数据上的学习方式

    Discovering How Agents Learn Using Few Data. (arXiv:2307.06640v1 [cs.GT])

    [http://arxiv.org/abs/2307.06640](http://arxiv.org/abs/2307.06640)

    本研究提出了一个在少量数据上识别智能体学习动力学的算法框架。通过使用多项式回归和引入捕捉智能体行为的侧信息约束，该方法可以在使用单个轨迹的短暂运行中仅仅5个样本的情况下准确恢复真实动力学。

    

    分散式学习算法是设计多智能体系统的重要工具，它们使得智能体能够从经验和过去的交互中自主学习。本研究提出了一个理论和算法框架，用于实时识别规定智能体行为的学习动力学，只需使用单个系统轨迹的短暂突发。我们的方法通过多项式回归识别智能体动力学，在有限的数据上通过引入捕捉智能体行为的基本假设或期望的侧信息约束来补偿，并且通过使用和优化约束的平方和计算来实施这些约束，从而得到越来越准确的智能体动力学近似层次。广泛的实验证明，我们的方法只使用单个轨迹的短暂运行中的5个样本，就可以准确恢复各种基准测试中的真实动力学，包括均衡选择和预测。

    Decentralized learning algorithms are an essential tool for designing multi-agent systems, as they enable agents to autonomously learn from their experience and past interactions. In this work, we propose a theoretical and algorithmic framework for real-time identification of the learning dynamics that govern agent behavior using a short burst of a single system trajectory. Our method identifies agent dynamics through polynomial regression, where we compensate for limited data by incorporating side-information constraints that capture fundamental assumptions or expectations about agent behavior. These constraints are enforced computationally using sum-of-squares optimization, leading to a hierarchy of increasingly better approximations of the true agent dynamics. Extensive experiments demonstrated that our approach, using only 5 samples from a short run of a single trajectory, accurately recovers the true dynamics across various benchmarks, including equilibrium selection and predictio
    
[^28]: 混合类型数据的核度量学习

    Kernel Metric Learning for Clustering Mixed-type Data. (arXiv:2306.01890v1 [cs.LG])

    [http://arxiv.org/abs/2306.01890](http://arxiv.org/abs/2306.01890)

    提出了一种使用混合核测量不相似性的度量方法，并通过交叉验证找到最佳核带宽。该方法可为现有的基于距离的聚类算法提高聚类准确度，适用于包含混合类型数据的模拟和实际数据集。

    

    基于距离的聚类和分类广泛应用于各个领域，以将混合数值和分类数据分组。预定义的距离测量用于根据它们的不相似性来聚类数据点。虽然存在许多适用于具有纯数字属性和几个有序和无序分类指标的数据的基于距离的度量方法，但混合型数据的最佳距离是一个尚未解决的问题。许多度量将数字属性转换为分类属性或反之亦然。他们将数据点处理为单个属性类型，或者分别计算每个属性之间的距离并将它们相加。我们提出了一种度量方法，使用混合核测量不相似性，并进行交叉验证来寻找最佳核带宽。我们的方法对包含纯连续，分类和混合类型数据的模拟和实际数据集应用于现有的基于距离的聚类算法时，提高了聚类准确度。

    Distance-based clustering and classification are widely used in various fields to group mixed numeric and categorical data. A predefined distance measurement is used to cluster data points based on their dissimilarity. While there exist numerous distance-based measures for data with pure numerical attributes and several ordered and unordered categorical metrics, an optimal distance for mixed-type data is an open problem. Many metrics convert numerical attributes to categorical ones or vice versa. They handle the data points as a single attribute type or calculate a distance between each attribute separately and add them up. We propose a metric that uses mixed kernels to measure dissimilarity, with cross-validated optimal kernel bandwidths. Our approach improves clustering accuracy when utilized for existing distance-based clustering algorithms on simulated and real-world datasets containing pure continuous, categorical, and mixed-type data.
    
[^29]: 为什么在对抗训练中会同时出现干净泛化和强健过拟合现象？

    Why Clean Generalization and Robust Overfitting Both Happen in Adversarial Training. (arXiv:2306.01271v1 [cs.LG])

    [http://arxiv.org/abs/2306.01271](http://arxiv.org/abs/2306.01271)

    对抗训练是训练深度神经网络抗击对抗扰动的标准方法, 其学习机制导致干净泛化和强健过拟合现象同时发生。

    

    对抗训练是训练深度神经网络抗击对抗扰动的标准方法。与在标准深度学习环境中出现惊人的干净泛化能力类似，通过对抗训练训练的神经网络也能很好地泛化到未见过的干净数据。然而，与干净泛化不同的是，尽管对抗训练能够实现低鲁棒训练误差，仍存在显著的鲁棒泛化距离，这促使我们探索在学习过程中导致干净泛化和强健过拟合现象同时发生的机制。本文提供了对抗训练中这种现象的理论理解。首先，我们提出了对抗训练的理论框架，分析了特征学习过程，解释了对抗训练如何导致网络学习者进入到干净泛化和强健过拟合状态。具体来说，我们证明了，通过迫使学习器成为强预测网络，对抗训练将导致干净泛化和鲁棒过拟合现象同时发生。

    Adversarial training is a standard method to train deep neural networks to be robust to adversarial perturbation. Similar to surprising $\textit{clean generalization}$ ability in the standard deep learning setting, neural networks trained by adversarial training also generalize well for $\textit{unseen clean data}$. However, in constrast with clean generalization, while adversarial training method is able to achieve low $\textit{robust training error}$, there still exists a significant $\textit{robust generalization gap}$, which promotes us exploring what mechanism leads to both $\textit{clean generalization and robust overfitting (CGRO)}$ during learning process. In this paper, we provide a theoretical understanding of this CGRO phenomenon in adversarial training. First, we propose a theoretical framework of adversarial training, where we analyze $\textit{feature learning process}$ to explain how adversarial training leads network learner to CGRO regime. Specifically, we prove that, u
    
[^30]: 异构观测数据下的联邦弱化政策学习

    Federated Offline Policy Learning with Heterogeneous Observational Data. (arXiv:2305.12407v1 [cs.LG])

    [http://arxiv.org/abs/2305.12407](http://arxiv.org/abs/2305.12407)

    本文提出了一种基于异构数据源的联邦政策学习算法，该算法基于本地策略聚合的方法，使用双重稳健线下策略评估和学习策略进行训练，可以在不交换原始数据的情况下学习个性化决策政策。我们建立了全局和局部后悔上限的理论模型，并用实验结果支持了理论发现。

    

    本文考虑了基于异构数据源的观测数据学习个性化决策政策的问题。此外，我们在联邦设置中研究了这个问题，其中中央服务器旨在在分布在异构源上的数据上学习一个政策，而不交换它们的原始数据。我们提出了一个联邦政策学习算法，它基于使用双重稳健线下策略评估和学习策略训练的本地策略聚合的方法。我们提供了一种新的后悔分析方法来确立对全局后悔概念的有限样本上界，这个全局后悔概念跨越了客户端的分布。此外，我们针对每个单独的客户端建立了相应的局部后悔上界，该上界由相对于所有其他客户端的分布变化特征性地描述。我们用实验结果支持我们的理论发现。我们的分析和实验提供了异构客户端参与联邦学习的价值洞察。

    We consider the problem of learning personalized decision policies on observational data from heterogeneous data sources. Moreover, we examine this problem in the federated setting where a central server aims to learn a policy on the data distributed across the heterogeneous sources without exchanging their raw data. We present a federated policy learning algorithm based on aggregation of local policies trained with doubly robust offline policy evaluation and learning strategies. We provide a novel regret analysis for our approach that establishes a finite-sample upper bound on a notion of global regret across a distribution of clients. In addition, for any individual client, we establish a corresponding local regret upper bound characterized by the presence of distribution shift relative to all other clients. We support our theoretical findings with experimental results. Our analysis and experiments provide insights into the value of heterogeneous client participation in federation fo
    
[^31]: 关于纯16位浮点神经网络的辩护

    In Defense of Pure 16-bit Floating-Point Neural Networks. (arXiv:2305.10947v1 [cs.LG])

    [http://arxiv.org/abs/2305.10947](http://arxiv.org/abs/2305.10947)

    本文探讨了纯16位浮点神经网络的被忽视的效率，提供了理论分析来探讨16位和32位模型的差异，并可以定量解释16位模型与其32位对应物之间的条件。

    

    减少编码神经网络权重和激活所需的位数是非常可取的，因为它可以加快神经网络的训练和推理时间，同时减少内存消耗。因此，这一领域的研究引起了广泛关注，以开发利用更低精度计算的神经网络，比如混合精度训练。有趣的是，目前不存在纯16位浮点设置的方法。本文揭示了纯16位浮点神经网络被忽视的效率。我们通过提供全面的理论分析来探讨造成16位和32位模型的差异的因素。我们规范化了浮点误差和容忍度的概念，从而可以定量解释16位模型与其32位对应物之间密切逼近结果的条件。这种理论探索提供了新的视角。

    Reducing the number of bits needed to encode the weights and activations of neural networks is highly desirable as it speeds up their training and inference time while reducing memory consumption. For these reasons, research in this area has attracted significant attention toward developing neural networks that leverage lower-precision computing, such as mixed-precision training. Interestingly, none of the existing approaches has investigated pure 16-bit floating-point settings. In this paper, we shed light on the overlooked efficiency of pure 16-bit floating-point neural networks. As such, we provide a comprehensive theoretical analysis to investigate the factors contributing to the differences observed between 16-bit and 32-bit models. We formalize the concepts of floating-point error and tolerance, enabling us to quantitatively explain the conditions under which a 16-bit model can closely approximate the results of its 32-bit counterpart. This theoretical exploration offers perspect
    
[^32]: PI-FL：个性化和激励联邦学习

    PI-FL: Personalized and Incentivized Federated Learning. (arXiv:2304.07514v1 [cs.LG])

    [http://arxiv.org/abs/2304.07514](http://arxiv.org/abs/2304.07514)

    PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。

    

    个性化联邦学习已被广泛应用于应对非独立同分布数据异质性的挑战。主要问题是考虑来自客户端的个性化过程以保护其自治权。允许客户端参与个性化联邦学习决策变得重要，因为存在隐私和安全问题，客户端可能无法自由共享生成良好质量个性化模型所必需的私人信息。此外，具有高质量数据和资源的客户端不愿意在没有合理激励的情况下参与联邦学习过程。在本文中，我们提出了PI-FL，这是一个一次性个性化解决方案，配合一个基于令牌的激励机制，奖励个性化训练。PI-FL优于其他最先进的方法，并且可以在尊重客户端隐私的同时生成高质量的个性化模型。

    Personalized FL has been widely used to cater to heterogeneity challenges with non-IID data. A primary obstacle is considering the personalization process from the client's perspective to preserve their autonomy. Allowing the clients to participate in personalized FL decisions becomes significant due to privacy and security concerns, where the clients may not be at liberty to share private information necessary for producing good quality personalized models. Moreover, clients with high-quality data and resources are reluctant to participate in the FL process without reasonable incentive. In this paper, we propose PI-FL, a one-shot personalization solution complemented by a token-based incentive mechanism that rewards personalized training. PI-FL outperforms other state-of-the-art approaches and can generate good-quality personalized models while respecting clients' privacy.
    
[^33]: BrainIB：基于图信息瓶颈的可解释性脑网络精神疾病诊断

    BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with Graph Information Bottleneck. (arXiv:2205.03612v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2205.03612](http://arxiv.org/abs/2205.03612)

    BrainIB是一种基于图信息瓶颈原理开发的图神经网络框架，在分析fMRI图像中的功能连接时能够识别最具信息量的边缘，具有良好的泛化能力和可解释性，适用于未见样本的场景。

    

    发展一种基于潜在生物机制而非主观症状对精神障碍进行诊断的新模型已成为一种新的共识。最近，使用功能连接（FC）进行精神障碍和健康对照的机器学习分类器被开发出来，用于确定大脑标记物。然而，现有的基于机器学习的诊断模型容易出现过拟合的情况（由于训练样本不足），在新的测试环境中表现差。此外，难以获得可解释的、可靠的大脑生物标记物来解释潜在的诊断决策。这些问题阻碍了其可能的临床应用。在本研究中，我们提出了BrainIB，一种新的图神经网络（GNN）框架，通过利用著名的信息瓶颈（IB）原理来分析功能磁共振图像（fMRI）。BrainIB能够识别大脑中最具信息量的边缘（即子图）并具有良好的泛化能力，适用于未见样本的场景。

    Developing a new diagnostic models based on the underlying biological mechanisms rather than subjective symptoms for psychiatric disorders is an emerging consensus. Recently, machine learning-based classifiers using functional connectivity (FC) for psychiatric disorders and healthy controls are developed to identify brain markers. However, existing machine learningbased diagnostic models are prone to over-fitting (due to insufficient training samples) and perform poorly in new test environment. Furthermore, it is difficult to obtain explainable and reliable brain biomarkers elucidating the underlying diagnostic decisions. These issues hinder their possible clinical applications. In this work, we propose BrainIB, a new graph neural network (GNN) framework to analyze functional magnetic resonance images (fMRI), by leveraging the famed Information Bottleneck (IB) principle. BrainIB is able to identify the most informative edges in the brain (i.e., subgraph) and generalizes well to unseen 
    
[^34]: 通过决策森林学习可解释的特征核

    Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1812.00029](http://arxiv.org/abs/1812.00029)

    本论文介绍了一种通过决策森林构建可解释的特征核的方法，我们构建了基于叶节点相似性的核平均嵌入随机森林（KMERF），并证明其在离散和连续数据上都表现出渐进特征。实验证明KMERF在多种高维数据测试中优于目前的最先进的基于核的方法。

    

    决策森林被广泛用于分类和回归任务。树方法的一个较少被知晓的特性是可以从树构建相似性矩阵，并且这些相似性矩阵是由核诱导的。尽管对于核的应用和性质进行了广泛研究，但对于由决策森林诱导的核的研究相对较少。我们构建了基于叶节点相似性的核平均嵌入随机森林（KMERF），它可以从随机树或森林中诱导核。我们引入了渐进特征核的概念，并证明KMERF核对于离散和连续数据都是渐进特征的。由于KMERF是数据自适应的，我们怀疑它将在有限样本数据上胜过预先选择的核。我们展示了KMERF在各种高维两样本和独立性测试场景中几乎占据了目前的最先进的基于核的测试方法。

    Decision forests are widely used for classification and regression tasks. A lesser known property of tree-based methods is that one can construct a proximity matrix from the tree(s), and these proximity matrices are induced kernels. While there has been extensive research on the applications and properties of kernels, there is relatively little research on kernels induced by decision forests. We construct Kernel Mean Embedding Random Forests (KMERF), which induce kernels from random trees and/or forests using leaf-node proximity. We introduce the notion of an asymptotically characteristic kernel, and prove that KMERF kernels are asymptotically characteristic for both discrete and continuous data. Because KMERF is data-adaptive, we suspected it would outperform kernels selected a priori on finite sample data. We illustrate that KMERF nearly dominates current state-of-the-art kernel-based tests across a diverse range of high-dimensional two-sample and independence testing settings. Furth
    

