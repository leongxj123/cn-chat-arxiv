# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Dynamical Model of Neural Scaling Laws](https://rss.arxiv.org/abs/2402.01092) | 这篇论文提出了一个动力学模型来解释神经缩放定律。通过分析梯度下降训练的随机特征模型，研究发现训练时间和模型大小的缩放具有不同的幂律指数，而计算最优缩放规则要求增加训练步数快于增加模型参数，与实证观察相一致。 |
| [^2] | [LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages](https://arxiv.org/abs/2404.02261) | 在低资源语言中，通过将LLMs集成到主动学习循环中进行数据注释，有效减少所需数据量，并取得接近最先进性能的结果。 |
| [^3] | [EGTR: Extracting Graph from Transformer for Scene Graph Generation](https://arxiv.org/abs/2404.02072) | 提出了一种从Transformer中提取图形以用于场景图生成的轻量级单阶段模型，有效地提取了关系图。 |
| [^4] | [Human-compatible driving partners through data-regularized self-play reinforcement learning](https://arxiv.org/abs/2403.19648) | 提出了Human-Regularized PPO (HR-PPO)算法，通过自我博弈训练代理，实现在封闭环境中逼真且有效的驾驶伙伴 |
| [^5] | [Make Large Language Model a Better Ranker](https://arxiv.org/abs/2403.19181) | 本文介绍了一种具有对齐列表排名目标的语言模型框架（ALRO），旨在弥合大型语言模型的能力与推荐系统排名任务的要求之间的差距。 |
| [^6] | [Learning Action-based Representations Using Invariance](https://arxiv.org/abs/2403.16369) | 提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量 |
| [^7] | [Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach](https://arxiv.org/abs/2403.15250) | 评估大规模LLM中因素对性能的影响通过全面的统计分析，有助于更好地理解和推动这些模型的发展 |
| [^8] | [Jailbreaking is Best Solved by Definition](https://arxiv.org/abs/2403.14725) | 语言模型中"越狱"攻击的关键是通过定义好的不安全响应来进行防御，而不是依赖于执行策略。 |
| [^9] | [LSKNet: A Foundation Lightweight Backbone for Remote Sensing](https://arxiv.org/abs/2403.11735) | LSKNet是一种轻量级的大型选择核网络骨干，能动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远程上下文。 |
| [^10] | [ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs](https://arxiv.org/abs/2403.09724) | ClaimVer是一个人为中心的框架，通过知识图谱实现可解释的声明级验证和证据归因，致力于提高用户对文本验证方法的信任并强调细粒度证据的重要性。 |
| [^11] | [Mixture of Mixups for Multi-label Classification of Rare Anuran Sounds](https://arxiv.org/abs/2403.09598) | 该论文提出了利用混合Mixup方法来解决稀有无尾蛙声多标签分类中的挑战，实验证明这种方法在处理类别不平衡和多标签示例方面具有有效性。 |
| [^12] | [Unleashing the Power of Meta-tuning for Few-shot Generalization Through Sparse Interpolated Experts](https://arxiv.org/abs/2403.08477) | 本文提出了一种名为Sparse MetA-Tuning（SMAT）的方法，通过灵感来自稀疏专家混合方法，成功克服了域外任务敏感性，实现了增强视觉基础模型转移能力的目标。 |
| [^13] | [Knowledge Conflicts for LLMs: A Survey](https://arxiv.org/abs/2403.08319) | 这项调查深入分析了LLMs在融合上下文和参数化知识时所面临的知识冲突，探讨了三类知识冲突对其可信度和性能的重要影响，并提出改进LLMs稳健性策略的策略。 |
| [^14] | [Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings](https://arxiv.org/abs/2403.07454) | 使用结构混合概率分布提供了准确的后验推断，同时具有更小的计算占用量，相较于现有的基于神经网络的SBI方法。 |
| [^15] | [Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends](https://arxiv.org/abs/2403.07379) | 分析神经网络和LLMs中优化轨迹的复杂性，揭示了优化过程中的关键特征，包括方向探索和方向正则化。 |
| [^16] | [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](https://arxiv.org/abs/2403.06265) | 本文研究了文本压缩在分词过程中的重要性，证明了压缩与预训练语言模型后续成功之间的实证重要性，并表明分词器的压缩与模型的性能存在相关性。 |
| [^17] | [Deep Prompt Multi-task Network for Abuse Language Detection](https://arxiv.org/abs/2403.05268) | 提出了一种新颖的Deep Prompt Multi-task Network (DPMN)用于滥用语言检测，通过设计深度提示调整和轻提示调整来激发预训练语言模型的一般知识，并利用多任务学习来提高检测度量标准 |
| [^18] | [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](https://arxiv.org/abs/2403.04814) | 该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。 |
| [^19] | [SWAP-NAS: Sample-Wise Activation Patterns For Ultra-Fast NAS](https://arxiv.org/abs/2403.04161) | 提出了一种新颖的高性能无需训练的度量SWAP-Score，能够在不同搜索空间和任务中测量网络在一批输入样本上的表现能力，并通过正则化进一步提高相关性，实现模型大小的控制。 |
| [^20] | [Validation of ML-UQ calibration statistics using simulated reference values: a sensitivity analysis](https://arxiv.org/abs/2403.00423) | 本研究探讨了ML-UQ校准统计量的使用问题，发现一些统计量对于生成分布的选择过于敏感，可能影响校准诊断。 |
| [^21] | [Watermark Stealing in Large Language Models](https://arxiv.org/abs/2402.19361) | LLM水印技术可能存在水印窃取漏洞，我们提出了自动WS算法并展示了攻击者可以在不到50美元的成本下通过欺骗和擦除攻击破解之前认为安全的最先进方案，成功率超过80%。 |
| [^22] | [Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling](https://arxiv.org/abs/2402.18846) | 提出了一种多保真度残差神经过程（MFRNP）框架，旨在优化低保真度解码器，通过聚合准确的信息共享来解决不同保真度之间的共享信息不准确的问题。 |
| [^23] | [Automated Statistical Model Discovery with Language Models](https://arxiv.org/abs/2402.17879) | 利用大型语言模型，提出了一种基于语言模型驱动的自动统计模型发现方法，不再需要定义特定领域模型语言或设计手工搜索程序。 |
| [^24] | [Federated Learning for Estimating Heterogeneous Treatment Effects](https://arxiv.org/abs/2402.17705) | 提出了一种通过联邦学习在机构之间协作学习HTE估计量的新框架，实现了即使在客户之间存在多样干预和受试者群体情况下共同学习特征表示并私下学习特定的预测函数。 |
| [^25] | [Pandora's White-Box: Increased Training Data Leakage in Open LLMs](https://arxiv.org/abs/2402.17012) | 本文对开源大型语言模型（LLMs）进行了隐私攻击研究，提出了首个能同时实现高真正率和低误分类率的预训练LLMs会员推理攻击（MIAs），以及展示了在自然环境中可以从微调LLM中提取超过50%的微调数据集。 |
| [^26] | [Classification Under Strategic Self-Selection](https://arxiv.org/abs/2402.15274) | 用户在学习分类器后决定是否参与的战略自我选择对学习效果和自我选择人口构成产生了影响，我们提出了一种可优化的可微分框架。 |
| [^27] | [Content Conditional Debiasing for Fair Text Embedding](https://arxiv.org/abs/2402.14208) | 通过在内容条件下确保敏感属性与文本嵌入之间的条件独立性，我们提出了一种可以改善公平性的新方法，在保持效用的同时，解决了缺乏适当训练数据的问题。 |
| [^28] | [Best of Many in Both Worlds: Online Resource Allocation with Predictions under Unknown Arrival Model](https://arxiv.org/abs/2402.13530) | 本文提出了一种算法，能够在未知预测质量的情况下，以预测作为输入准确执行在线资源分配，解决了在线决策中预测质量未知的问题。 |
| [^29] | [PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning](https://arxiv.org/abs/2402.12842) | 提出了PromptKD方法，通过提示调整实现了生成语言模型提取学生友好知识的蒸馏，无需微调整整个教师模型。 |
| [^30] | [UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction](https://arxiv.org/abs/2402.11838) | UniST是一种为城市时空预测设计的通用模型，通过灵活性、有效的生成式预训练以及丰富的掩码策略成功捕捉复杂的时空关系。 |
| [^31] | [Towards Theoretical Understandings of Self-Consuming Generative Models](https://arxiv.org/abs/2402.11778) | 通过构建理论框架，我们探讨了在自消耗循环中训练生成模型对数据分布学习的影响，证明了在足够大的训练数据集大小或真实数据比例条件下，合成数据分布与原始真实数据分布之间的总变差距离能够被有效控制。 |
| [^32] | [Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network](https://arxiv.org/abs/2402.11518) | 提出了一种利用大型语言模型驱动的元结构搜索框架，解决了手工设计元结构不易扩展以及忽视可解释性的问题 |
| [^33] | [ZeroG: Investigating Cross-dataset Zero-shot Transferability in Graphs](https://arxiv.org/abs/2402.11235) | ZeroG是一个新框架，旨在实现图中跨数据集零射击迁移，解决了特征不对齐、标签空间不匹配和负迁移等挑战 |
| [^34] | [Fixed Confidence Best Arm Identification in the Bayesian Setting](https://arxiv.org/abs/2402.10429) | 该研究在贝叶斯设置中探讨了固定置信度最佳臂识别问题，证明了传统频率设定下的算法在此设置下表现次优，并引入了一种性能与理论下限相匹配的连续排除变种。 |
| [^35] | [All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining](https://arxiv.org/abs/2402.09834) | 本研究提出了一种简单而有效的跨领域图预训练方法，通过一体化和多功能性，使得大型语言模型在各个领域具备了超强的泛化能力。 |
| [^36] | [Nearly Optimal Regret for Decentralized Online Convex Optimization](https://arxiv.org/abs/2402.09173) | 本论文研究了分布式在线凸优化，开发了新的算法来分别降低凸函数和强凸函数的后悔边界，并填补了现有下界之间的差距。 |
| [^37] | [Improved Regret for Bandit Convex Optimization with Delayed Feedback](https://arxiv.org/abs/2402.09152) | 本文针对具有延迟反馈的强化学习问题提出了一种改进后悔率的算法，通过精确利用延迟的强化学习反馈，成功将后悔界限从$O(T^{3/4}+d^{1/3}T^{2/3})$改进为$O(T^{3/4}+\sqrt{dT})$，并在更大的延迟量$d=O(\sqrt{T})$情况下与非延迟设置下的强化学习梯度下降算法相匹配。 |
| [^38] | [Two Tales of Single-Phase Contrastive Hebbian Learning](https://arxiv.org/abs/2402.08573) | 两种单相对比海比安学习的故事探索了学习算法的生物合理性，并提出了一种全局学习算法，能够消除与反向传播之间的性能差距，并解决了同步和无限小扰动带来的问题。 |
| [^39] | [Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial](https://arxiv.org/abs/2402.07487) | 本文是基于分数的扩散模型的技术教程，重点讲解了通过随机微分方程进行公式化的方法，包括采样和分数匹配。适合初学者了解该领域，并且从业人员在设计新模型或算法时也可能会有所帮助。 |
| [^40] | [Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving](https://arxiv.org/abs/2402.05359) | 该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。 |
| [^41] | [Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks](https://arxiv.org/abs/2402.05271) | 了解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。前人的研究表明，在训练过程中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这被称为神经特征分析（NFA）。本研究解释了这种相关性的出现，并发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。在早期训练阶段，可以通过解析的方式预测NFA的发展速度。 |
| [^42] | [On Parameter Estimation in Deviated Gaussian Mixture of Experts](https://arxiv.org/abs/2402.05220) | 在偏离高斯混合专家模型中，本文通过构造Voronoi-based损失函数来解决参数估计问题。 |
| [^43] | [Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation](https://arxiv.org/abs/2402.04929) | 本文提出了一种无源域自适应的新方法，利用扩散模型生成上下文相关的领域特定图像，通过微调预训练模型和无监督领域自适应技术实现了显著的性能改进。 |
| [^44] | [Large Language Models As Faithful Explainers](https://arxiv.org/abs/2402.04678) | 本论文提出了一个生成解释框架（xLLM），用于提高大型语言模型（LLMs）自然语言格式解释的可信度。通过一个评估器来量化解释的可信度，并通过迭代优化过程来提高可信度。 |
| [^45] | [Positive concave deep equilibrium models](https://arxiv.org/abs/2402.04029) | 引入了一种新颖的正凹深度均衡（pcDEQ）模型，通过引入非负权重和凹函数的激活函数，确保了模型的存在性和唯一性。 |
| [^46] | [Skill Set Optimization: Reinforcing Language Model Behavior via Transferable Skills](https://arxiv.org/abs/2402.03244) | 本论文提出了一种技能集优化（SSO）方法，通过构建和完善可转移的技能集来提高大型语言模型（LLM）的性能。该方法通过提取高奖励的共同子轨迹，生成子目标和说明，并在上下文中提供给LLM演员，以强化行为。实验结果显示，SSO在不同环境中能够优化技能集，并实现上下文策略改进。 |
| [^47] | [EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models](https://arxiv.org/abs/2402.03049) | EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。 |
| [^48] | [AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a Single High-Resolution Image](https://arxiv.org/abs/2402.02956) | AdaTreeFormer是一种从源领域学习并适应只有有限数量标注树木的目标领域的框架，利用一个共享的编码器和分层特征提取方案，实现了树木计数的少样本领域自适应。 |
| [^49] | [On Least Squares Estimation in Softmax Gating Mixture of Experts](https://arxiv.org/abs/2402.02952) | 本研究探讨了在确定性MoE模型下使用最小二乘估计器的性能，并建立了强可识别性条件来描述不同类型专家函数的收敛行为。 |
| [^50] | [Shortened LLaMA: A Simple Depth Pruning for Large Language Models](https://arxiv.org/abs/2402.02834) | 使用简单的深度修剪方法可以提高大规模语言模型的推理速度，在内存受限的条件下表现良好，对部署在本地和边缘设备上的LLMs有帮助。 |
| [^51] | [A practical existence theorem for reduced order models based on convolutional autoencoders](https://arxiv.org/abs/2402.00435) | 本论文提出了基于卷积自编码器的降阶模型的实用存在定理，解决了在处理复杂非线性问题方面传统方法的不足，并讨论了如何学习潜在特征的挑战。 |
| [^52] | [Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey](https://arxiv.org/abs/2401.11963) | 通过整合进化算法与强化学习，进化强化学习（ERL）展现出卓越的性能提升，本综述呈现了ERL领域的各个研究分支，突出了EA辅助RL的优化、RL辅助EA的优化以及EA和RL的协同优化这三个主要研究方向。 |
| [^53] | [Diffusion Models, Image Super-Resolution And Everything: A Survey](https://arxiv.org/abs/2401.00736) | 扩散模型（DMs）在图像超分辨率（SR）领域产生了颠覆性的影响，缩小了图像质量与人类感知偏好之间的差距。该研究调查了DM的理论基础，分析了其独特特点和方法，探索了替代输入领域等当前的研究方向。 |
| [^54] | [Faster Rates for Switchback Experiments](https://arxiv.org/abs/2312.15574) | 本研究提出了一种更快速的Switchback实验方法，通过使用整个时间块，以 $\sqrt{\log T/T}$ 的速率估计全局平均处理效应。 |
| [^55] | [Prompt Optimization via Adversarial In-Context Learning](https://arxiv.org/abs/2312.02614) | 提出了Adversarial In-Context Learning (adv-ICL)方法，通过生成器、鉴别器和提示修改器之间的对抗学习优化提示，在上下文学习中取得显着改进。 |
| [^56] | [Weight fluctuations in (deep) linear neural networks and a derivation of the inverse-variance flatness relation](https://arxiv.org/abs/2311.14120) | 该研究探讨了单层和双层线性神经网络在随机梯度下降中的稳定训练规则，并发现了权重波动在各种情况下的各向异性特征，其中双层网络中的权重波动受到层间耦合的影响，并呈现出各向异性损失。 |
| [^57] | [Neural Koopman prior for data assimilation](https://arxiv.org/abs/2309.05317) | 本文介绍了一种利用神经Koopman先验进行数据同化的方法，将动态系统嵌入到潜在空间，使得对其动态进行线性描述，并展示了长期连续重构和自监督学习的潜力。 |
| [^58] | [EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models](https://arxiv.org/abs/2308.07269) | EasyEdit提出了一种易于使用的知识编辑框架，针对大型语言模型的知识截断或谬误问题，支持各种最新的知识编辑方法，并可应用于多个知名的LLMs。 |
| [^59] | [Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting](https://arxiv.org/abs/2304.00933) | 揭示了持续学习表示中的知识积累和特征遗忘问题，表明即使特征遗忘的绝对程度可能较小，新学习的信息在表示层面也面临着严重遗忘。 |
| [^60] | [OMPGPT: A Generative Pre-trained Transformer Model for OpenMP.](http://arxiv.org/abs/2401.16445) | OMPGPT是一种为了OpenMP pragma生成而设计的生成式预训练Transformer模型，采用了来自NLP领域的提示工程技术，并创建了一种创新的策略chain-of-OMP。 |
| [^61] | [Expert with Clustering: Hierarchical Online Preference Learning Framework.](http://arxiv.org/abs/2401.15062) | 本研究提出了一种名为Expert with Clustering (EWC)的分层在线偏好学习框架，它利用聚类技术和专家建议的预测来加速用户偏好学习，并通过一种新颖的损失引导距离度量生成更具代表性的聚类中心。 |
| [^62] | [Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?.](http://arxiv.org/abs/2401.13875) | 本文研究了温度对Softmax高斯混合专家的采样效率的影响，证明了由于温度和其他模型参数之间的相互作用，参数估计的收敛速度较慢，并且可能很慢。 |
| [^63] | [Revisiting Silhouette: From Micro to Macro Aggregation.](http://arxiv.org/abs/2401.05831) | 本文提出了一种新的聚合策略，用于评估聚类质量。通过对聚类级别的轮廓得分进行平均，并在此基础上对所有聚类的得分进行宏观平均，我们提出的宏观平均轮廓得分对于聚类不均衡和背景噪声是稳健的。 |
| [^64] | [AST-T5: Structure-Aware Pretraining for Code Generation and Understanding.](http://arxiv.org/abs/2401.03003) | AST-T5是一种结构感知的预训练模型，通过利用抽象语法树（AST）来增强代码生成、转换和理解的能力。它优于其他同等大小的语言模型，并在代码到代码任务中表现出色。 |
| [^65] | [Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving.](http://arxiv.org/abs/2401.02949) | 本文提出了一种名为Graph2Tac的图神经网络模型，用于在定理证明中学习数学概念的分层表示。该模型能够动态地将新的数学概念纳入到知识库中，并在Coq证明助手中进行训练和应用。 |
| [^66] | [Generative Fractional Diffusion Models.](http://arxiv.org/abs/2310.17638) | 该论文提出了一种基于分数阶扩散模型的生成模型，其中通过将分数布朗运动表示为奥恩斯坦-乌伦贝克过程的随机积分，实现了驱动噪声收敛到非马尔可夫过程的效果。这是第一个在具有无限二次变差的随机过程上构建生成模型的尝试。 |
| [^67] | [A General Theory for Softmax Gating Multinomial Logistic Mixture of Experts.](http://arxiv.org/abs/2310.14188) | 该论文提出了一种通用理论，用于研究Softmax Gating Multinomial Logistic Mixture of Experts模型。通过建立模型的收敛速度，揭示了softmax gating和专家函数之间存在的互作用，同时提出了一种修改后的softmax gating函数。 |
| [^68] | [Optimal Best Arm Identification with Fixed Confidence in Restless Bandits.](http://arxiv.org/abs/2310.13393) | 在多臂赌博机中，我们研究了以固定置信度进行最优臂识别。我们提出了一种新的策略来识别具有最大平均值的臂，同时限制了决策错误的概率，并建立了停止时间增长率的下界。 |
| [^69] | [Discovering Mixtures of Structural Causal Models from Time Series Data.](http://arxiv.org/abs/2310.06312) | 这项研究提出了一种从时间序列数据中发现混合结构因果模型的方法，通过推断潜在因果模型以及每个样本属于特定混合成分的概率，通过实验证明了该方法在因果发现任务中的优越性。 |
| [^70] | [Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers.](http://arxiv.org/abs/2310.02905) | 该论文提出了一种使用神经探测器和转换器优化指令的方法，以提高大型语言模型的性能。 |
| [^71] | [A Recipe for Improved Certifiable Robustness: Capacity and Data.](http://arxiv.org/abs/2310.02513) | 在本研究中，我们通过使用一系列新技术、设计优化和综合以前的研究，更全面地评估了基于Lipschitz的认证方法的潜力，并显著提高了状... |
| [^72] | [Graph-level Representation Learning with Joint-Embedding Predictive Architectures.](http://arxiv.org/abs/2309.16014) | 本文提出了一种用于图级表示学习的联合嵌入预测架构（JEPA），通过预测输入图的不同子图的潜在表示在2维单位双曲线上的坐标，实现了对图级表示的有效建模。 |
| [^73] | [Detach-ROCKET: Sequential feature selection for time series classification with random convolutional kernels.](http://arxiv.org/abs/2309.14518) | 本文提出了一种名为Detach-ROCKET的方法，用于时间序列分类中的顺序特征选择。通过利用随机卷积核模型中的大量特征，并使用顺序特征分离方法剪枝非主要特征，提高了模型的可扩展性和泛化能力。 |
| [^74] | [GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior.](http://arxiv.org/abs/2309.13160) | 本文提出了一种基于高斯混合后验的VAE方法，重新定义了ELBO，引入正则化项和PatchGAN鉴别器，能够生成逼真的人脸。 |
| [^75] | [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.](http://arxiv.org/abs/2309.13007) | ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。 |
| [^76] | [LMDX: Language Model-based Document Information Extraction and Localization.](http://arxiv.org/abs/2309.10952) | LMDX是一种基于语言模型的文档信息提取与定位方法，克服了布局编码和答案虚构的困难，能够在半结构化文档中提取关键实体。 |
| [^77] | [An Explainable Deep-learning Model of Proton Auroras on Mars.](http://arxiv.org/abs/2309.08195) | 这项研究开发了一个纯数据驱动模型，使用火星大气和挥发物演化 (MAVEN) 的观测资料，来解释火星质子极光。通过训练人工神经网络，可以准确重现每个Ly alpha辐射的强度，并对观测结果进行忠实重构。 |
| [^78] | [Improving physics-informed DeepONets with hard constraints.](http://arxiv.org/abs/2309.07899) | 本研究提出了一种改进的物理信息深度学习策略，消除了对初始条件的学习需求，并确保在多次应用时得到的函数是连续的。 |
| [^79] | [Identifying Constitutive Parameters for Complex Hyperelastic Solids using Physics-Informed Neural Networks.](http://arxiv.org/abs/2308.15640) | 本文介绍了一种基于物理信息神经网络（PINNs）的新框架，用于识别软材料在大变形平面应力条件下具有复杂组分行为的材料的组分参数。通过使用多模态的时间相关实验数据训练，我们的模型能够稳健地准确识别不可压缩Arruda-Boyce模型的组分参数。 |
| [^80] | [Hyperbolic Random Forests.](http://arxiv.org/abs/2308.13279) | 该论文提出了一种在非欧几里得空间中将随机森林推广的方法，并使用水平球重新定义了分割的概念。为了处理多类数据和不平衡实验，论文还提出了一种新的类组合方法。 |
| [^81] | [Manipulating Embeddings of Stable Diffusion Prompts.](http://arxiv.org/abs/2308.12059) | 本论文提出了一种直接改变提示嵌入的方法，促进了用户对生成图像细粒度和目标化的控制。这种方法将生成模型视为连续函数，并在图像空间和提示嵌入空间之间传递梯度。 |
| [^82] | [Causal Fair Machine Learning via Rank-Preserving Interventional Distributions.](http://arxiv.org/abs/2307.12797) | 通过保持排序的干预分布，我们提出了一种因果公平的机器学习方法，通过在一个理想的世界中消除受保护属性对目标的因果影响来减少不公平。 |
| [^83] | [On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets.](http://arxiv.org/abs/2307.05284) | 该论文通过对表格数据集中的自然偏移进行研究，发现$Y|X$-偏移最为普遍。为了推动研究人员开发描述数据分布偏移的精细语言，作者构建了WhyShift实验平台，并讨论了$Y|X$-偏移对算法的影响。 |
| [^84] | [Local primordial non-Gaussianity from the large-scale clustering of photometric DESI luminous red galaxies.](http://arxiv.org/abs/2307.01753) | 本研究利用DESI成像调查的亮红星系的角聚类信息限制了局部原初非高斯性参数fNL，发现在假设宇宙规律性关系的情况下，fNL为47^{+14(+29)}_{-11(-22)}，使用更积极的处理方法后，最大似然值略微偏离fNL≈5。 |
| [^85] | [Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via Optimization and Data-driven Approach for Dynamic Systems.](http://arxiv.org/abs/2306.12361) | 本文提出了一种不需要假设未知输入为线性的方法，结合非线性优化和数据驱动方法可以实现对未知输入的估计，并通过联合 sigma-point 变换方案将状态和未知输入的不确定性纳入估计中，确保其稳定性。这个方法适用于许多智能自主系统。 |
| [^86] | [Of Mice and Mates: Automated Classification and Modelling of Mouse Behaviour in Groups using a Single Model across Cages.](http://arxiv.org/abs/2306.03066) | 本文提供了自动分类和模拟群体老鼠行为的工具，通过单一模型跨笼使用置换矩阵匹配老鼠身份，在家鼠环境下研究老鼠可以捕捉到个体行为的时间因素，而且无需人为干预。 |
| [^87] | [A Slingshot Approach to Learning in Monotone Games.](http://arxiv.org/abs/2305.16610) | 本文提出了一种新的框架, 通过正则化游戏的支付或效用和更新投石索策略，无论是否存在噪声都能够实现在单调博弈中计算均衡。 |
| [^88] | [Non-stationary Online Convex Optimization with Arbitrary Delays.](http://arxiv.org/abs/2305.12131) | 本文研究了任意时延的非稳态在线凸优化，提出了一种简单的算法DOGD，并证明它能在最坏情况下获得$O(\sqrt{dT}(P_T+1))$的动态遗憾界，同时当延迟不改变梯度到达顺序时，自动将动态遗憾减少到$O(\sqrt{S}(1+P_T))$。 |
| [^89] | [State Representation Learning Using an Unbalanced Atlas.](http://arxiv.org/abs/2305.10267) | 本文介绍了一种使用不平衡图册（UA）方法的状态表示学习，该方法可以超越最先进的自监督学习方法。 |
| [^90] | [CLCIFAR: CIFAR-Derived Benchmark Datasets with Human Annotated Complementary Labels.](http://arxiv.org/abs/2305.08295) | 本研究开发了由人类标注的互补标签，创造了两个真实世界的CLL数据集，进一步揭示了现实表现下CLL算法的性能，为这一领域的研究提供了更实际的评估标准。 |
| [^91] | [FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework.](http://arxiv.org/abs/2305.01658) | FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。 |
| [^92] | [Jacobian-Scaled K-means Clustering for Physics-Informed Segmentation of Reacting Flows.](http://arxiv.org/abs/2305.01539) | 本研究提出了一种受物理学影响的聚类策略，名为Jacobian-Scaled K-means聚类方法，能够不修改输入数据集即生成能够捕获动力学相似性区域的聚类。本方法具有一定的应用前景和实用价值。 |
| [^93] | [In-situ surface porosity prediction in DED (directed energy deposition) printed SS316L parts using multimodal sensor fusion.](http://arxiv.org/abs/2304.08658) | 本研究利用多模式传感器融合技术和AI方法预测DED打印部件中的原位表面孔隙率的潜力，可以实时预测每个沃克塞尔中的气孔存在，是一个重大飞跃。 |
| [^94] | [Comparison of High-Dimensional Bayesian Optimization Algorithms on BBOB.](http://arxiv.org/abs/2303.00890) | 本研究比较了BBOB上五种高维贝叶斯优化算法与传统方法以及CMA-ES算法的性能，结果表明... (根据论文的具体内容进行总结) |
| [^95] | [Deep Reinforcement Learning with Swin Transformers.](http://arxiv.org/abs/2206.15269) | 本文介绍了基于 Swin Transformer 的在线强化学习方案 Swin DQN，通过将组合的图像像素分成小的补丁并在局部应用自我注意力操作，实现了在 Atari 基准测试上超越现有基于 CNN 的强化学习方法的最先进性能。 |
| [^96] | [A policy gradient approach for optimization of smooth risk measures.](http://arxiv.org/abs/2202.11046) | 本文介绍了一种应用于on-policy和off-policy RL情况下的策略梯度算法，用于最小化广义平滑风险度量，能够收敛到平滑风险度量的稳态点，并适用于均值-方差和畸变风险度量的优化。 |
| [^97] | [Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness.](http://arxiv.org/abs/2111.01996) | 本文提出了Pareto Adversarial Robustness策略，通过整合空间鲁棒性方法和基于敏感性的鲁棒性，实现了通用对抗鲁棒性。同时，从鲁棒表示的角度提供了自然准确性、敏感性鲁棒性和空间鲁棒性之间的关系。 |

# 详细

[^1]: 神经缩放定律的动力学模型

    A Dynamical Model of Neural Scaling Laws

    [https://rss.arxiv.org/abs/2402.01092](https://rss.arxiv.org/abs/2402.01092)

    这篇论文提出了一个动力学模型来解释神经缩放定律。通过分析梯度下降训练的随机特征模型，研究发现训练时间和模型大小的缩放具有不同的幂律指数，而计算最优缩放规则要求增加训练步数快于增加模型参数，与实证观察相一致。

    

    在各种任务中，神经网络的性能随着训练时间、数据集大小和模型大小的增加而预测性地提高，跨多个数量级。这种现象被称为神经缩放定律。最重要的是计算最优缩放定律，它报告了在选择最佳模型大小时性能与计算数量的关系。我们分析了一个通过梯度下降进行训练和泛化的随机特征模型作为网络训练和泛化的可解模型。这个模型复现了关于神经缩放定律的许多观察结果。首先，我们的模型对于为什么训练时间和模型大小的缩放具有不同的幂律指数提出了一个预测。因此，理论预测了一种不对称的计算最优缩放规则，其中训练步数的增加速度快于模型参数的增加速度，与最近的实证观察一致。其次，观察到在训练的早期，网络会收敛到无限宽度情况下的结果。

    On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-wi
    
[^2]: 在LLMs中循环：利用大型语言模型注释进行低资源语言的主动学习

    LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages

    [https://arxiv.org/abs/2404.02261](https://arxiv.org/abs/2404.02261)

    在低资源语言中，通过将LLMs集成到主动学习循环中进行数据注释，有效减少所需数据量，并取得接近最先进性能的结果。

    

    由于语言资源和数据标注专业知识有限，低资源语言在人工智能开发中面临着重大障碍，使它们变得罕见且成本高昂。为了解决这一不足，我们提出利用LLMs的潜力在主动学习环节中进行数据注释。我们首先进行评估以评估注释者之间的一致性，从而选择适当的LLM注释者。然后，选择的注释者被集成到一个分类器的训练循环中，使用主动学习范式，最小化所需的查询数据量。实证评估，特别是使用GPT-4-Turbo，展示了几乎达到最先进性能的结果，同时大大减少了数据需求，由估算的潜在性能指示。

    arXiv:2404.02261v1 Announce Type: cross  Abstract: Low-resource languages face significant barriers in AI development due to limited linguistic resources and expertise for data labeling, rendering them rare and costly. The scarcity of data and the absence of preexisting tools exacerbate these challenges, especially since these languages may not be adequately represented in various NLP datasets. To address this gap, we propose leveraging the potential of LLMs in the active learning loop for data annotation. Initially, we conduct evaluations to assess inter-annotator agreement and consistency, facilitating the selection of a suitable LLM annotator. The chosen annotator is then integrated into a training loop for a classifier using an active learning paradigm, minimizing the amount of queried data required. Empirical evaluations, notably employing GPT-4-Turbo, demonstrate near-state-of-the-art performance with significantly reduced data requirements, as indicated by estimated potential co
    
[^3]: 从Transformer中提取图形用于场景图生成

    EGTR: Extracting Graph from Transformer for Scene Graph Generation

    [https://arxiv.org/abs/2404.02072](https://arxiv.org/abs/2404.02072)

    提出了一种从Transformer中提取图形以用于场景图生成的轻量级单阶段模型，有效地提取了关系图。

    

    场景图生成（SGG）是一项具有挑战性的任务，涉及检测对象并预测对象之间的关系。提出了一个轻量级的单阶段SGG模型，它从DETR解码器的多头自注意力层中学习的各种关系中提取关系图。

    arXiv:2404.02072v1 Announce Type: cross  Abstract: Scene Graph Generation (SGG) is a challenging task of detecting objects and predicting relationships between objects. After DETR was developed, one-stage SGG models based on a one-stage object detector have been actively studied. However, complex modeling is used to predict the relationship between objects, and the inherent relationship between object queries learned in the multi-head self-attention of the object detector has been neglected. We propose a lightweight one-stage SGG model that extracts the relation graph from the various relationships learned in the multi-head self-attention layers of the DETR decoder. By fully utilizing the self-attention by-products, the relation graph can be extracted effectively with a shallow relation extraction head. Considering the dependency of the relation extraction task on the object detection task, we propose a novel relation smoothing technique that adjusts the relation label adaptively accor
    
[^4]: 通过数据正则化的自我博弈强化学习实现与人类兼容的驾驶伙伴

    Human-compatible driving partners through data-regularized self-play reinforcement learning

    [https://arxiv.org/abs/2403.19648](https://arxiv.org/abs/2403.19648)

    提出了Human-Regularized PPO (HR-PPO)算法，通过自我博弈训练代理，实现在封闭环境中逼真且有效的驾驶伙伴

    

    自主驾驶汽车面临的一个核心挑战是与人类进行协调。因此，在模拟环境中，将逼真的人类代理纳入自动驾驶系统的可扩展训练和评估是至关重要的。我们提出了一种名为Human-Regularized PPO (HR-PPO)的多智能体算法，其中代理通过自我博弈进行训练，对偏离人类参考策略的行为进行小幅惩罚，以构建在封闭环境中既逼真又有效的代理。

    arXiv:2403.19648v1 Announce Type: cross  Abstract: A central challenge for autonomous vehicles is coordinating with humans. Therefore, incorporating realistic human agents is essential for scalable training and evaluation of autonomous driving systems in simulation. Simulation agents are typically developed by imitating large-scale, high-quality datasets of human driving. However, pure imitation learning agents empirically have high collision rates when executed in a multi-agent closed-loop setting. To build agents that are realistic and effective in closed-loop settings, we propose Human-Regularized PPO (HR-PPO), a multi-agent algorithm where agents are trained through self-play with a small penalty for deviating from a human reference policy. In contrast to prior work, our approach is RL-first and only uses 30 minutes of imperfect human demonstrations. We evaluate agents in a large set of multi-agent traffic scenes. Results show our HR-PPO agents are highly effective in achieving goa
    
[^5]: 让大型语言模型成为更好的排名器

    Make Large Language Model a Better Ranker

    [https://arxiv.org/abs/2403.19181](https://arxiv.org/abs/2403.19181)

    本文介绍了一种具有对齐列表排名目标的语言模型框架（ALRO），旨在弥合大型语言模型的能力与推荐系统排名任务的要求之间的差距。

    

    大型语言模型（LLMs）的发展显著增强了各个领域的能力，导致推荐系统（RSs）概念和开发方式发生了转变。然而，现有研究主要集中在点对点和成对推荐范式上。这些方法在基于LLM的推荐器中效率低下，因为利用大型语言模型的计算成本很高。一些研究虽然深入研究了列表型方法，但在排名任务中表现不佳。这一不足归因于排名和语言生成目标之间的不匹配。为此，本文介绍了具有对齐列表排名目标的语言模型框架（ALRO）。ALRO旨在弥合LLMs的能力与推荐系统排名任务的微妙要求之间的差距。ALRO的一个关键特性是引入了软lambda值lo

    arXiv:2403.19181v1 Announce Type: cross  Abstract: The evolution of Large Language Models (LLMs) has significantly enhanced capabilities across various fields, leading to a paradigm shift in how Recommender Systems (RSs) are conceptualized and developed. However, existing research primarily focuses on point-wise and pair-wise recommendation paradigms. These approaches prove inefficient in LLM-based recommenders due to the high computational cost of utilizing Large Language Models. While some studies have delved into list-wise approaches, they fall short in ranking tasks. This shortfall is attributed to the misalignment between the objectives of ranking and language generation. To this end, this paper introduces the Language Model Framework with Aligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap between the capabilities of LLMs and the nuanced requirements of ranking tasks within recommender systems. A key feature of ALRO is the introduction of soft lambda lo
    
[^6]: 使用不变性学习基于动作的表示

    Learning Action-based Representations Using Invariance

    [https://arxiv.org/abs/2403.16369](https://arxiv.org/abs/2403.16369)

    提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量

    

    强化学习代理使用高维度观测必须能够在许多外源性干扰中识别相关状态特征。一个能够捕捉可控性的表示通过确定影响代理控制的因素来识别这些状态元素。虽然诸如逆动力学和互信息等方法可以捕捉有限数量的时间步的可控性，但捕获长时间元素仍然是一个具有挑战性的问题。短视的可控性可以捕捉代理即将撞向墙壁的瞬间，但不能在代理还有一定距离之时捕捉墙壁的控制相关性。为解决这个问题，我们提出了动作双模拟编码，这是一种受到双模拟不变量假度量启发的方法，它通过递归不变性约束扩展了单步控制性。通过这种方式，动作双模拟学习了一个平滑折扣远期元素的多步控制度量。

    arXiv:2403.16369v1 Announce Type: cross  Abstract: Robust reinforcement learning agents using high-dimensional observations must be able to identify relevant state features amidst many exogeneous distractors. A representation that captures controllability identifies these state elements by determining what affects agent control. While methods such as inverse dynamics and mutual information capture controllability for a limited number of timesteps, capturing long-horizon elements remains a challenging problem. Myopic controllability can capture the moment right before an agent crashes into a wall, but not the control-relevance of the wall while the agent is still some distance away. To address this we introduce action-bisimulation encoding, a method inspired by the bisimulation invariance pseudometric, that extends single-step controllability with a recursive invariance constraint. By doing this, action-bisimulation learns a multi-step controllability metric that smoothly discounts dist
    
[^7]: 大规模评估结果在LLM中的全面重新评估：一种多方位统计方法

    Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach

    [https://arxiv.org/abs/2403.15250](https://arxiv.org/abs/2403.15250)

    评估大规模LLM中因素对性能的影响通过全面的统计分析，有助于更好地理解和推动这些模型的发展

    

    在LLM快速发展的背景下，评估在理解和推动这些模型前进中的重要性日益凸显。评估揭示了缩放、训练类型、架构等因素深刻影响LLM的性能。然而，这些因素对性能评分的影响程度和性质仍然存在争议，因为大多数评估局限于有限数量的模型和数据点。通过统计视角更有效地澄清这些因素对性能得分的影响可以更有效地实现。我们的研究对这些LLM进行了彻底的重新检查，针对当前评估方法的不足之处。随着一个统一的评估框架的出现，我们的研究利用了广泛的评估结果数据集，引入了一种全面的统计方法论。其中包括ANOVA、Tukey HSD检验、GAMM的应用

    arXiv:2403.15250v1 Announce Type: cross  Abstract: Amidst the rapid evolution of LLMs, the significance of evaluation in comprehending and propelling these models forward is increasingly paramount. Evaluations have revealed that factors such as scaling, training types, architectures and other factors profoundly impact the performance of LLMs. However, the extent and nature of these impacts continue to be subjects of debate because most assessments have been restricted to a limited number of models and data points. Clarifying the effects of these factors on performance scores can be more effectively achieved through a statistical lens. Our study embarks on a thorough re-examination of these LLMs, targeting the inadequacies in current evaluation methods. With the advent of a uniform evaluation framework, our research leverages an expansive dataset of evaluation results, introducing a comprehensive statistical methodology. This includes the application of ANOVA, Tukey HSD tests, GAMM, and
    
[^8]: Jailbreaking的最佳解决方案是通过定义

    Jailbreaking is Best Solved by Definition

    [https://arxiv.org/abs/2403.14725](https://arxiv.org/abs/2403.14725)

    语言模型中"越狱"攻击的关键是通过定义好的不安全响应来进行防御，而不是依赖于执行策略。

    

    语言模型上"越狱"攻击的增多引发了大量防御工作，旨在防止产生不良回应。在这项工作中，我们批判性地审视了防御管道的两个阶段：（i）定义何为不安全输出，和（ii）通过输入处理或微调等方法来执行该定义。我们严重怀疑现有的执行机制的有效性，通过展示它们即使对于简单的不安全输出定义--包含单词"purple"的输出也无法防御。相比之下，对输出进行后处理对于这样的定义是完全健壮的。基于我们的结果，我们提出我们的观点，即在防御越狱攻击中真正的挑战在于得到一个良好的不安全响应定义：没有良好的定义，任何执行策略都无法成功，但有了良好的定义，输出处理已经作为一个强大的基线。

    arXiv:2403.14725v1 Announce Type: cross  Abstract: The rise of "jailbreak" attacks on language models has led to a flurry of defenses aimed at preventing the output of undesirable responses. In this work, we critically examine the two stages of the defense pipeline: (i) the definition of what constitutes unsafe outputs, and (ii) the enforcement of the definition via methods such as input processing or fine-tuning. We cast severe doubt on the efficacy of existing enforcement mechanisms by showing that they fail to defend even for a simple definition of unsafe outputs--outputs that contain the word "purple". In contrast, post-processing outputs is perfectly robust for such a definition. Drawing on our results, we present our position that the real challenge in defending jailbreaks lies in obtaining a good definition of unsafe responses: without a good definition, no enforcement strategy can succeed, but with a good definition, output processing already serves as a robust baseline albeit 
    
[^9]: LSKNet：一种用于遥感的轻量级基础架构

    LSKNet: A Foundation Lightweight Backbone for Remote Sensing

    [https://arxiv.org/abs/2403.11735](https://arxiv.org/abs/2403.11735)

    LSKNet是一种轻量级的大型选择核网络骨干，能动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远程上下文。

    

    遥感图像由于其固有的复杂性对下游任务提出了独特的挑战。尽管已经有大量研究致力于遥感分类、目标检测和语义分割，但其中大多数研究都忽视了嵌入在遥感场景中的宝贵先验知识。这些先验知识可能会很有用，因为在没有参考足够长程上下文的情况下，遥感对象可能会被错误识别，而这可以因不同对象而异。本文考虑了这些先验知识，并提出了一种轻量级的大型选择核网络（LSKNet）骨干网络。LSKNet可以动态调整其较大的空间感受野，以更好地模拟遥感场景中各种对象的远距离上下文。据我们所知，先前尚未在遥感图像中探索过大型和选择性核机制。我们的轻量级方法没有太多复杂性。

    arXiv:2403.11735v1 Announce Type: cross  Abstract: Remote sensing images pose distinct challenges for downstream tasks due to their inherent complexity. While a considerable amount of research has been dedicated to remote sensing classification, object detection and semantic segmentation, most of these studies have overlooked the valuable prior knowledge embedded within remote sensing scenarios. Such prior knowledge can be useful because remote sensing objects may be mistakenly recognized without referencing a sufficiently long-range context, which can vary for different objects. This paper considers these priors and proposes a lightweight Large Selective Kernel Network (LSKNet) backbone. LSKNet can dynamically adjust its large spatial receptive field to better model the ranging context of various objects in remote sensing scenarios. To our knowledge, large and selective kernel mechanisms have not been previously explored in remote sensing images. Without bells and whistles, our lightw
    
[^10]: ClaimVer：通过知识图谱实现可解释的声明级验证和证据归因

    ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs

    [https://arxiv.org/abs/2403.09724](https://arxiv.org/abs/2403.09724)

    ClaimVer是一个人为中心的框架，通过知识图谱实现可解释的声明级验证和证据归因，致力于提高用户对文本验证方法的信任并强调细粒度证据的重要性。

    

    在广泛传播的信息误导和社交媒体以及人工智能生成的文本的激增中，验证和信任所遇到的信息变得日益困难。许多事实核查方法和工具已被开发，但它们往往缺乏适当的可解释性或细粒度，无法在各种情境中发挥作用。一种易于使用、可访问且能够执行细粒度证据归因的文本验证方法变得至关重要。更重要的是，建立用户对这种方法的信任需要呈现每个预测背后的理由，因为研究表明这显著影响人们对自动化系统的信任。将用户关注重点放在具体的问题内容上，而不是提供简单的笼统标签也非常重要。在本文中，我们提出了$\textit{ClaimVer，一个以人为中心的框架}$，旨在满足用户的信息需求。

    arXiv:2403.09724v1 Announce Type: new  Abstract: In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people's belief in automated systems. It is also paramount to localize and bring users' attention to the specific problematic content, instead of providing simple blanket labels. In this paper, we present $\textit{ClaimVer, a human-centric framework}$ tailored to meet users' info
    
[^11]: 混合Mixup用于稀有无尾蛙声多标签分类

    Mixture of Mixups for Multi-label Classification of Rare Anuran Sounds

    [https://arxiv.org/abs/2403.09598](https://arxiv.org/abs/2403.09598)

    该论文提出了利用混合Mixup方法来解决稀有无尾蛙声多标签分类中的挑战，实验证明这种方法在处理类别不平衡和多标签示例方面具有有效性。

    

    多标签不平衡分类在机器学习中是一个重要挑战，特别在生物声学中尤为明显，动物声音经常同时出现，而某些声音比其他声音要少得多。本文针对使用包含类别不平衡和多标签示例的数据集AnuraSet，专注于分类无尾目物种声音的特定情况。为了解决这些挑战，我们引入了Mixture of Mixups (Mix2)，这是一个利用混合正则化方法Mixup、Manifold Mixup和MultiMix的框架。实验结果表明，这些方法单独使用可能导致次优结果；然而，当随机应用它们时，每次训练迭代选取一个方法，它们在解决提到的挑战方面表现出有效性，特别是对于发生次数较少的稀有类别。进一步分析表明，Mix2在跨各种类别同时出现水平上也能有效分类声音。

    arXiv:2403.09598v1 Announce Type: cross  Abstract: Multi-label imbalanced classification poses a significant challenge in machine learning, particularly evident in bioacoustics where animal sounds often co-occur, and certain sounds are much less frequent than others. This paper focuses on the specific case of classifying anuran species sounds using the dataset AnuraSet, that contains both class imbalance and multi-label examples. To address these challenges, we introduce Mixture of Mixups (Mix2), a framework that leverages mixing regularization methods Mixup, Manifold Mixup, and MultiMix. Experimental results show that these methods, individually, may lead to suboptimal results; however, when applied randomly, with one selected at each training iteration, they prove effective in addressing the mentioned challenges, particularly for rare classes with few occurrences. Further analysis reveals that Mix2 is also proficient in classifying sounds across various levels of class co-occurrences
    
[^12]: 通过稀疏插值专家释放元调整的力量，用于少样本泛化

    Unleashing the Power of Meta-tuning for Few-shot Generalization Through Sparse Interpolated Experts

    [https://arxiv.org/abs/2403.08477](https://arxiv.org/abs/2403.08477)

    本文提出了一种名为Sparse MetA-Tuning（SMAT）的方法，通过灵感来自稀疏专家混合方法，成功克服了域外任务敏感性，实现了增强视觉基础模型转移能力的目标。

    

    传统智慧建议参数高效的微调基础模型，是视觉迁移学习的最先进方法，取代了诸如元学习之类的丰富文献。为了兼顾两者的利益，元调整引入了基础模型的随后优化阶段，但迄今只展现了有限的成功，关键地在域外（OOD）任务上表现不佳。本文介绍了一种灵感来自稀疏专家混合方法的 Sparse MetA-Tuning（SMAT）方法，它经过训练以自动地为每个任务隔离预训练参数子集以进行元调整。SMAT成功克服了OOD敏感性，并实现了增强视觉基础模型转移能力的承诺。我们在Meta-Dataset与额外的OO挑战组合上建立了新的最先进结果。

    arXiv:2403.08477v1 Announce Type: cross  Abstract: Conventional wisdom suggests parameter-efficient fine-tuning of foundation models as the state-of-the-art method for transfer learning in vision, replacing the rich literature of alternatives such as meta-learning. In trying to harness the best of both worlds, meta-tuning introduces a subsequent optimization stage of foundation models but has so far only shown limited success and crucially tends to underperform on out-of-domain (OOD) tasks. In this paper, we introduce Sparse MetA-Tuning (SMAT), a method inspired by sparse mixture-of-experts approaches and trained to isolate subsets of pre-trained parameters automatically for meta-tuning on each task. SMAT successfully overcomes OOD sensitivity and delivers on the promise of enhancing the transfer abilities of vision foundation models beyond parameter-efficient finetuning. We establish new state-of-the-art results on a challenging combination of Meta-Dataset augmented with additional OO
    
[^13]: LLMs的知识冲突：一项调查

    Knowledge Conflicts for LLMs: A Survey

    [https://arxiv.org/abs/2403.08319](https://arxiv.org/abs/2403.08319)

    这项调查深入分析了LLMs在融合上下文和参数化知识时所面临的知识冲突，探讨了三类知识冲突对其可信度和性能的重要影响，并提出改进LLMs稳健性策略的策略。

    

    这项调查对大型语言模型（LLMs）的知识冲突进行了深入分析，突出了当它们融合上下文和参数化知识时所遇到的复杂挑战。我们关注三类知识冲突：上下文-记忆冲突、跨上下文冲突和内部记忆冲突。这些冲突可能会显著影响LLMs的可信度和性能，特别是在现实世界应用中，噪音和错误信息很常见。通过对这些冲突进行分类，探讨其原因，研究LLMs在这些冲突下的行为，并回顾可用的解决方案，本调查旨在为改进LLMs的稳健性策略提供启示，从而成为推动这一不断发展领域研究的宝贵资源。

    arXiv:2403.08319v1 Announce Type: cross  Abstract: This survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge. Our focus is on three categories of knowledge conflicts: context-memory, inter-context, and intra-memory conflict. These conflicts can significantly impact the trustworthiness and performance of LLMs, especially in real-world applications where noise and misinformation are common. By categorizing these conflicts, exploring the causes, examining the behaviors of LLMs under such conflicts, and reviewing available solutions, this survey aims to shed light on strategies for improving the robustness of LLMs, thereby serving as a valuable resource for advancing research in this evolving area.
    
[^14]: 使用高斯局部线性映射进行快速、准确和轻量级的顺序仿真推断

    Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings

    [https://arxiv.org/abs/2403.07454](https://arxiv.org/abs/2403.07454)

    使用结构混合概率分布提供了准确的后验推断，同时具有更小的计算占用量，相较于现有的基于神经网络的SBI方法。

    

    arXiv:2403.07454v1 公告类型: 跨领域 摘要: 针对具有难以处理的似然函数的复杂模型的贝叶斯推断可以使用多次调用计算模拟器的算法来解决。 这些方法被统称为“基于仿真的推断”（SBI）。 最近的SBI方法利用神经网络（NN）提供近似但表达丰富的构造，用于不可用的似然函数和后验分布。 然而，它们通常无法实现准确性和计算需求之间的最佳折衷。 在这项工作中，我们提出了一种提供似然函数和后验分布近似的替代方法，使用结构化的概率分布混合物。 相对于最先进的基于NN的SBI方法，我们的方法在产生准确的后验推断的同时，具有更小的计算占用量。 我们在SBI文献中的几个基准模型上展示了我们的结果。

    arXiv:2403.07454v1 Announce Type: cross  Abstract: Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as "simulation-based inference" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, they do not generally achieve an optimal trade-off between accuracy and computational demand. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature.
    
[^15]: 神经网络和LLMs中优化轨迹的特征：长度、拐点和死胡同

    Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends

    [https://arxiv.org/abs/2403.07379](https://arxiv.org/abs/2403.07379)

    分析神经网络和LLMs中优化轨迹的复杂性，揭示了优化过程中的关键特征，包括方向探索和方向正则化。

    

    我们提出了一种全新的方法来理解神经网络的机制，通过分析其优化轨迹中包含的丰富参数结构。为此，我们引入了一些关于优化轨迹复杂性的自然概念，既定性又定量地揭示了各种优化选择（如动量、权重衰减和批大小）之间所涉及的内在微妙和相互作用。我们利用这些概念来提供关于深度神经网络优化本质的关键特征：何时顺利进行，何时陷入死胡同。此外，基于我们的轨迹视角，我们揭示了动量和权重衰减之间促进方向探索的交织行为，以及其他一些行为的方向正则化行为。我们在大规模视觉和语言设置中进行实验，包括具有最多120亿个参数的大型语言模型（LLMs）。

    arXiv:2403.07379v1 Announce Type: cross  Abstract: We propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. Towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. We use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. Further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. We perform experiments over large-scale vision and language settings, including large language models (LLMs) with up to 12 billio
    
[^16]: 拆解分词：评估文本压缩及其与模型性能的相关性

    Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance

    [https://arxiv.org/abs/2403.06265](https://arxiv.org/abs/2403.06265)

    本文研究了文本压缩在分词过程中的重要性，证明了压缩与预训练语言模型后续成功之间的实证重要性，并表明分词器的压缩与模型的性能存在相关性。

    

    尽管压缩是BPE最常见的分词算法的重要基础，但分词过程中的压缩重要性仍不清楚。本文论述了压缩的理论重要性，可以被看作是0-gram语言建模，即为所有标记分配相等的概率。我们还展示了压缩对预训练语言模型后续成功的实证重要性。我们通过改变训练过程中可用文档的数量来控制多个BPE分词器的压缩能力：从100万个文档到相当于没有训练数据的基于字符的分词器。然后，我们基于这些分词器预训练英语语言模型，并在多个任务上进行微调。我们展示了分词器的压缩与模型的后续性能之间存在相关性，表明压缩是分词的可靠内在指标

    arXiv:2403.06265v1 Announce Type: cross  Abstract: Despite it being the cornerstone of BPE, the most common tokenization algorithm, the importance of compression in the tokenization process is still unclear. In this paper, we argue for the theoretical importance of compression, that can be viewed as 0-gram language modeling where equal probability is assigned to all tokens. We also demonstrate the empirical importance of compression for downstream success of pre-trained language models. We control the compression ability of several BPE tokenizers by varying the amount of documents available during their training: from 1 million documents to a character-based tokenizer equivalent to no training data at all. We then pre-train English language models based on those tokenizers and fine-tune them over several tasks. We show that there is a correlation between tokenizers' compression and models' downstream performance, suggesting that compression is a reliable intrinsic indicator of tokeniza
    
[^17]: 深度提示多任务网络用于辱骂语言检测

    Deep Prompt Multi-task Network for Abuse Language Detection

    [https://arxiv.org/abs/2403.05268](https://arxiv.org/abs/2403.05268)

    提出了一种新颖的Deep Prompt Multi-task Network (DPMN)用于滥用语言检测，通过设计深度提示调整和轻提示调整来激发预训练语言模型的一般知识，并利用多任务学习来提高检测度量标准

    

    滥用语言的检测仍然是社交网络广泛使用中存在的一项长期挑战。滥用语言检测任务存在着准确性有限的问题。我们认为现有的检测方法利用了预训练语言模型（PLMs）的微调技术来处理下游任务。因此，这些方法未能激发PLMs的一般知识。为了解决这个问题，我们提出了一种新颖的用于滥用语言检测的深度提示多任务网络（DPMN）。具体而言，DPMN首先尝试为PLMs设计两种形式的深度提示调整和轻提示调整。研究了不同提示长度、调整策略和提示初始化方法对于检测滥用语言的影响。此外，我们提出了基于Bi-LSTM和FFN的任务头，可用作短文本分类器。最终，DPMN利用多任务学习来提高检测度量标准。

    arXiv:2403.05268v1 Announce Type: cross  Abstract: The detection of abusive language remains a long-standing challenge with the extensive use of social networks. The detection task of abusive language suffers from limited accuracy. We argue that the existing detection methods utilize the fine-tuning technique of the pre-trained language models (PLMs) to handle downstream tasks. Hence, these methods fail to stimulate the general knowledge of the PLMs. To address the problem, we propose a novel Deep Prompt Multi-task Network (DPMN) for abuse language detection. Specifically, DPMN first attempts to design two forms of deep prompt tuning and light prompt tuning for the PLMs. The effects of different prompt lengths, tuning strategies, and prompt initialization methods on detecting abusive language are studied. In addition, we propose a Task Head based on Bi-LSTM and FFN, which can be used as a short text classifier. Eventually, DPMN utilizes multi-task learning to improve detection metrics 
    
[^18]: 在句法感知代码填空任务上评估LLMs

    Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks

    [https://arxiv.org/abs/2403.04814](https://arxiv.org/abs/2403.04814)

    该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。

    

    我们介绍了一种名为Syntax-Aware Fill-In-the-Middle（SAFIM）的新基准，用于评估大型语言模型（LLMs）在代码填空（FIM）任务上的表现。该基准侧重于程序结构的句法感知完成，如代码块和条件表达式，并包括来自多种编程语言的17,720个示例，来源于2022年4月之后的最新代码提交，以最小化数据污染。 SAFIM提供了一个强大的框架，具有各种提示设计和新颖的句法感知后处理技术，有助于在LLMs之间进行准确和公平的比较。我们对15个LLMs进行了全面评估，结果表明FIM预训练不仅提升了FIM的熟练程度，还改进了LLMs的左到右（L2R）推理。我们的发现挑战了传统观念，并表明预训练方法和数据质量对模型性能的影响大于模型大小。因此，SAFIM为未来构建

    arXiv:2403.04814v1 Announce Type: cross  Abstract: We introduce Syntax-Aware Fill-In-the-Middle (SAFIM), a new benchmark for evaluating Large Language Models (LLMs) on the code Fill-in-the-Middle (FIM) task. This benchmark focuses on syntax-aware completions of program structures such as code blocks and conditional expressions, and includes 17,720 examples from multiple programming languages, sourced from recent code submissions after April 2022 to minimize data contamination. SAFIM provides a robust framework with various prompt designs and novel syntax-aware post-processing techniques, facilitating accurate and fair comparisons across LLMs. Our comprehensive evaluation of 15 LLMs shows that FIM pretraining not only enhances FIM proficiency but also improves Left-to-Right (L2R) inference using LLMs. Our findings challenge conventional beliefs and suggest that pretraining methods and data quality have more impact than model size. SAFIM thus serves as a foundational platform for future 
    
[^19]: SWAP-NAS: 适用于超快速NAS的样本级激活模式

    SWAP-NAS: Sample-Wise Activation Patterns For Ultra-Fast NAS

    [https://arxiv.org/abs/2403.04161](https://arxiv.org/abs/2403.04161)

    提出了一种新颖的高性能无需训练的度量SWAP-Score，能够在不同搜索空间和任务中测量网络在一批输入样本上的表现能力，并通过正则化进一步提高相关性，实现模型大小的控制。

    

    无需训练的度量（即零成本代理）被广泛用于避免资源密集型的神经网络训练，尤其是在神经结构搜索（NAS）中。最近的研究表明，现有的无需训练的度量存在一些局限，比如在不同搜索空间和任务之间存在有限的关联性和差劲的泛化能力。因此，我们提出了样本级激活模式及其衍生物SWAP-Score，这是一种新颖的高性能无需训练的度量。它测量了网络在一批输入样本上的表现能力。SWAP-Score与不同搜索空间和任务中的真实性能强相关，在NAS-Bench-101/201/301和TransNAS-Bench-101上胜过了15种现有的无需训练的度量。SWAP-Score可以通过正则化进一步增强，这在基于单元的搜索空间中可以实现更高的相关性，并且在搜索过程中实现模型大小控制。例如，Spearman的排序

    arXiv:2403.04161v1 Announce Type: new  Abstract: Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid resource-intensive neural network training, especially in Neural Architecture Search (NAS). Recent studies show that existing training-free metrics have several limitations, such as limited correlation and poor generalisation across different search spaces and tasks. Hence, we propose Sample-Wise Activation Patterns and its derivative, SWAP-Score, a novel high-performance training-free metric. It measures the expressivity of networks over a batch of input samples. The SWAP-Score is strongly correlated with ground-truth performance across various search spaces and tasks, outperforming 15 existing training-free metrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be further enhanced by regularisation, which leads to even higher correlations in cell-based search space and enables model size control during the search. For example, Spearman's rank
    
[^20]: 使用模拟参考值验证ML-UQ校准统计量：一项敏感性分析

    Validation of ML-UQ calibration statistics using simulated reference values: a sensitivity analysis

    [https://arxiv.org/abs/2403.00423](https://arxiv.org/abs/2403.00423)

    本研究探讨了ML-UQ校准统计量的使用问题，发现一些统计量对于生成分布的选择过于敏感，可能影响校准诊断。

    

    一些流行的机器学习不确定性量化（ML-UQ）校准统计量没有预定义的参考值，主要用于比较研究。因此，校准几乎从不被验证，诊断留给读者的判断。提出了基于实际不确定性导出的合成校准数据集的模拟参考值，以弥补这一问题。由于用于模拟合成误差的生成概率分布通常没有约束，所以模拟参考值对生成分布选择的敏感性可能会成为问题，对校准诊断产生怀疑。本研究探讨了这一问题的各个方面，并显示一些统计量对于用于验证时生成分布的选择过于敏感，当生成分布未知时。例如，

    arXiv:2403.00423v1 Announce Type: cross  Abstract: Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration statistics do not have predefined reference values and are mostly used in comparative studies. In consequence, calibration is almost never validated and the diagnostic is left to the appreciation of the reader. Simulated reference values, based on synthetic calibrated datasets derived from actual uncertainties, have been proposed to palliate this problem. As the generative probability distribution for the simulation of synthetic errors is often not constrained, the sensitivity of simulated reference values to the choice of generative distribution might be problematic, shedding a doubt on the calibration diagnostic. This study explores various facets of this problem, and shows that some statistics are excessively sensitive to the choice of generative distribution to be used for validation when the generative distribution is unknown. This is the case, for instan
    
[^21]: 大型语言模型中的水印窃取

    Watermark Stealing in Large Language Models

    [https://arxiv.org/abs/2402.19361](https://arxiv.org/abs/2402.19361)

    LLM水印技术可能存在水印窃取漏洞，我们提出了自动WS算法并展示了攻击者可以在不到50美元的成本下通过欺骗和擦除攻击破解之前认为安全的最先进方案，成功率超过80%。

    

    LLM水印技术作为一种检测AI生成内容的有效方式，受到了关注。然而，我们在这项研究中争辩称当前方案可能已经可以部署，我们认为水印窃取（WS）是这些方案的一个根本性漏洞。我们展示了通过查询带有水印的LLM的API来近似逆向水印，从而实现实用的欺骗攻击，同时大幅增加了之前未被注意到的擦除攻击。我们是第一个提出自动WS算法并将其用于在现实环境中进行欺骗和擦除的全面研究。我们展示了仅需不到50美元的成本，攻击者就能够欺骗并擦除之前被认为是安全的最先进方案，平均成功率超过80%。我们的研究挑战了关于LLM水印技术的常见信念，强调了更加健壮方案的必要性。

    arXiv:2402.19361v1 Announce Type: cross  Abstract: LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment. In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes. We mak
    
[^22]: 多保真度残差神经过程用于可扩展的替代建模

    Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling

    [https://arxiv.org/abs/2402.18846](https://arxiv.org/abs/2402.18846)

    提出了一种多保真度残差神经过程（MFRNP）框架，旨在优化低保真度解码器，通过聚合准确的信息共享来解决不同保真度之间的共享信息不准确的问题。

    

    多保真度替代建模旨在通过结合来自多个来源的数据，在最高保真度水平学习准确的替代模型。传统方法依赖于高斯过程，很难扩展到高维数据。深度学习方法利用基于神经网络的编码器和解码器来提高可扩展性。这些方法在不包括对应解码器参数的情况下在不同保真度之间共享编码表示。在最高保真度时，用不同参数解码表示，使共享信息固有不准确。这限制了推断性能，特别是在最高保真度数据的域覆盖有限的情况下。为了解决这些限制，我们提出了一种新颖的多保真度替代建模框架——多保真度残差神经过程（MFRNP）。

    arXiv:2402.18846v1 Announce Type: new  Abstract: Multi-fidelity surrogate modeling aims to learn an accurate surrogate at the highest fidelity level by combining data from multiple sources. Traditional methods relying on Gaussian processes can hardly scale to high-dimensional data. Deep learning approaches utilize neural network based encoders and decoders to improve scalability. These approaches share encoded representations across fidelities without including corresponding decoder parameters. At the highest fidelity, the representations are decoded with different parameters, making the shared information inherently inaccurate. This hinders inference performance, especially in out-of-distribution scenarios when the highest fidelity data has limited domain coverage. To address these limitations, we propose Multi-fidelity Residual Neural Processes (MFRNP), a novel multi-fidelity surrogate modeling framework. MFRNP optimizes lower fidelity decoders for accurate information sharing by agg
    
[^23]: 使用语言模型进行自动统计模型发现

    Automated Statistical Model Discovery with Language Models

    [https://arxiv.org/abs/2402.17879](https://arxiv.org/abs/2402.17879)

    利用大型语言模型，提出了一种基于语言模型驱动的自动统计模型发现方法，不再需要定义特定领域模型语言或设计手工搜索程序。

    

    统计模型发现涉及在受领域特定建模约束的广泛模型空间上进行具有挑战性的搜索。高效搜索这一空间需要具有建模和问题域人类专长的专业知识。受大型语言模型（LMs）领域知识和编程能力的启发，我们介绍了一种基于语言模型驱动的自动统计模型发现方法。我们将自动化流程置于Box的循环框架之内：LM在提出表示为概率程序的统计模型（充当建模者）之间迭代，并批判这些模型（充当领域专家）。通过利用LMs，我们不必定义一个领域特定的模型语言或设计手工搜索程序，这是先前系统的重要限制。我们在概率建模的三种常见设置中评估了我们的方法：在受限模型空间内搜索，搜索

    arXiv:2402.17879v1 Announce Type: cross  Abstract: Statistical model discovery involves a challenging search over a vast space of models subject to domain-specific modeling constraints. Efficiently searching over this space requires human expertise in modeling and the problem domain. Motivated by the domain knowledge and programming capabilities of large language models (LMs), we introduce a method for language model driven automated statistical model discovery. We cast our automated procedure within the framework of Box's Loop: the LM iterates between proposing statistical models represented as probabilistic programs, acting as a modeler, and critiquing those models, acting as a domain expert. By leveraging LMs, we do not have to define a domain-specific language of models or design a handcrafted search procedure, key restrictions of previous systems. We evaluate our method in three common settings in probabilistic modeling: searching within a restricted space of models, searching ove
    
[^24]: 用于估计异质治疗效果的联邦学习

    Federated Learning for Estimating Heterogeneous Treatment Effects

    [https://arxiv.org/abs/2402.17705](https://arxiv.org/abs/2402.17705)

    提出了一种通过联邦学习在机构之间协作学习HTE估计量的新框架，实现了即使在客户之间存在多样干预和受试者群体情况下共同学习特征表示并私下学习特定的预测函数。

    

    用于估计异质治疗效果（HTE）的机器学习方法促进了跨各种领域（如医疗保健、政策制定、教育等）的大规模个性化决策。现有的用于HTE的机器学习方法需要每种处理方法大量数据的访问，而干预的高成本使得为每种干预集中收集这么多数据成为一个艰巨的挑战。为了克服这一障碍，在这项工作中，我们提出了一个通过联邦学习在机构之间协作学习HTE估计量的新框架。我们展示了，即使在客户之间存在多样的干预和受试者群体，也可以共同学习一个共同的特征表示，同时在各个机构之间同时并私下学习关于不同干预情况下结果的特定预测功能。我们的框架和相关算法基于

    arXiv:2402.17705v1 Announce Type: new  Abstract: Machine learning methods for estimating heterogeneous treatment effects (HTE) facilitate large-scale personalized decision-making across various domains such as healthcare, policy making, education, and more. Current machine learning approaches for HTE require access to substantial amounts of data per treatment, and the high costs associated with interventions makes centrally collecting so much data for each intervention a formidable challenge. To overcome this obstacle, in this work, we propose a novel framework for collaborative learning of HTE estimators across institutions via Federated Learning. We show that even under a diversity of interventions and subject populations across clients, one can jointly learn a common feature representation, while concurrently and privately learning the specific predictive functions for outcomes under distinct interventions across institutions. Our framework and the associated algorithm are based on 
    
[^25]: Pandora's White-Box：开放LLMs中训练数据泄漏的增加

    Pandora's White-Box: Increased Training Data Leakage in Open LLMs

    [https://arxiv.org/abs/2402.17012](https://arxiv.org/abs/2402.17012)

    本文对开源大型语言模型（LLMs）进行了隐私攻击研究，提出了首个能同时实现高真正率和低误分类率的预训练LLMs会员推理攻击（MIAs），以及展示了在自然环境中可以从微调LLM中提取超过50%的微调数据集。

    

    在本文中，我们对开源的大型语言模型（LLMs）遭受的隐私攻击进行了系统研究，其中对手可以访问模型权重、梯度或损失，试图利用它们来了解底层训练数据。我们的主要结果是针对预训练LLMs的第一个会员推理攻击（MIAs），能够同时实现高TPR和低FPR，并展示了在自然环境中可以从微调LLM中提取超过50%的微调数据集。我们考虑了对底层模型的不同访问程度、语言模型的定制化以及攻击者可以使用的资源。在预训练设置中，我们提出了三种新的白盒MIAs：基于梯度范数的攻击、监督神经网络分类器和单步损失比攻击。所有这些都优于现有的黑盒基线，并且我们的.....

    arXiv:2402.17012v1 Announce Type: cross  Abstract: In this paper we undertake a systematic study of privacy attacks against open source Large Language Models (LLMs), where an adversary has access to either the model weights, gradients, or losses, and tries to exploit them to learn something about the underlying training data. Our headline results are the first membership inference attacks (MIAs) against pre-trained LLMs that are able to simultaneously achieve high TPRs and low FPRs, and a pipeline showing that over $50\%$ (!) of the fine-tuning dataset can be extracted from a fine-tuned LLM in natural settings. We consider varying degrees of access to the underlying model, customization of the language model, and resources available to the attacker. In the pre-trained setting, we propose three new white-box MIAs: an attack based on the gradient norm, a supervised neural network classifier, and a single step loss ratio attack. All outperform existing black-box baselines, and our supervi
    
[^26]: 在战略自我选择下的分类

    Classification Under Strategic Self-Selection

    [https://arxiv.org/abs/2402.15274](https://arxiv.org/abs/2402.15274)

    用户在学习分类器后决定是否参与的战略自我选择对学习效果和自我选择人口构成产生了影响，我们提出了一种可优化的可微分框架。

    

    当用户可以从某些预测中获益时，他们往往会采取战略行动以获得有利的预测结果。大多数关于战略分类的研究都考虑用户行为表现为特征修改，而我们研究了一种新颖的情况，在这种情况下，用户在学习分类器的情况下决定是否参与（或不参与）。为了学习增加战略意识的方法，我们研究了自我选择对学习的影响，以及学习对自我选择人口构成的影响。然后，我们提出了一个可在自我选择行为下学习的可微分框架，可以有效优化。我们最后通过对真实数据和模拟行为进行实验，这些实验既可以补充我们的分析，又可以展示我们方法的实用性。

    arXiv:2402.15274v1 Announce Type: new  Abstract: When users stand to gain from certain predictions, they are prone to act strategically to obtain favorable predictive outcomes. Whereas most works on strategic classification consider user actions that manifest as feature modifications, we study a novel setting in which users decide -- in response to the learned classifier -- whether to at all participate (or not). For learning approaches of increasing strategic awareness, we study the effects of self-selection on learning, and the implications of learning on the composition of the self-selected population. We then propose a differentiable framework for learning under self-selective behavior, which can be optimized effectively. We conclude with experiments on real data and simulated behavior that both complement our analysis and demonstrate the utility of our approach.
    
[^27]: 面向公平文本嵌入的内容条件去偏方法

    Content Conditional Debiasing for Fair Text Embedding

    [https://arxiv.org/abs/2402.14208](https://arxiv.org/abs/2402.14208)

    通过在内容条件下确保敏感属性与文本嵌入之间的条件独立性，我们提出了一种可以改善公平性的新方法，在保持效用的同时，解决了缺乏适当训练数据的问题。

    

    在自然语言处理（NLP）中，减轻机器学习模型中的偏见引起了越来越多的关注。然而，只有少数研究集中在公平的文本嵌入上，这对实际应用至关重要且具有挑战性。本文提出了一种学习公平文本嵌入的新方法。我们通过确保在内容条件下敏感属性与文本嵌入之间的条件独立性来实现公平性，同时保持效用权衡。具体来说，我们强制要求具有不同敏感属性但相同内容的文本的嵌入与其对应中立文本的嵌入保持相同的距离。此外，我们通过使用大型语言模型（LLMs）将文本增强为不同的敏感组，来解决缺乏适当训练数据的问题。我们广泛的评估表明，我们的方法有效地提高了公平性同时保持了嵌入的效用。

    arXiv:2402.14208v1 Announce Type: cross  Abstract: Mitigating biases in machine learning models has gained increasing attention in Natural Language Processing (NLP). Yet, only a few studies focus on fair text embeddings, which are crucial yet challenging for real-world applications. In this paper, we propose a novel method for learning fair text embeddings. We achieve fairness while maintaining utility trade-off by ensuring conditional independence between sensitive attributes and text embeddings conditioned on the content. Specifically, we enforce that embeddings of texts with different sensitive attributes but identical content maintain the same distance toward the embedding of their corresponding neutral text. Furthermore, we address the issue of lacking proper training data by using Large Language Models (LLMs) to augment texts into different sensitive groups. Our extensive evaluations demonstrate that our approach effectively improves fairness while preserving the utility of embed
    
[^28]: 两个世界中的最佳之选：在未知到达模型下带预测的在线资源分配

    Best of Many in Both Worlds: Online Resource Allocation with Predictions under Unknown Arrival Model

    [https://arxiv.org/abs/2402.13530](https://arxiv.org/abs/2402.13530)

    本文提出了一种算法，能够在未知预测质量的情况下，以预测作为输入准确执行在线资源分配，解决了在线决策中预测质量未知的问题。

    

    arXiv:2402.13530v1 公告类型: 跨领域 摘要: 当今的在线决策者通常可以获得关于未来变量的预测，如到达、需求、库存等。这些预测可以由简单的单变量时间序列预测算法生成，一直到利用多个时间序列和附加特征信息的最先进的机器学习模型。然而，预测质量通常对决策者来说是未知的，因此盲目地遵循预测可能是有害的。本文通过给出将预测作为输入并针对未知预测质量进行稳健执行的算法来解决这个问题。我们考虑在线资源分配问题，这是收益管理和在线决策制定中最通用的模型之一。在这个问题中，决策者拥有有限数量的资源，并且请求是顺序到来的。对于每个请求，决策者需要决定采取何种行动。

    arXiv:2402.13530v1 Announce Type: cross  Abstract: Online decision-makers today can often obtain predictions on future variables, such as arrivals, demands, inventories, and so on. These predictions can be generated from simple forecasting algorithms for univariate time-series, all the way to state-of-the-art machine learning models that leverage multiple time-series and additional feature information. However, the prediction quality is often unknown to decisions-makers a priori, hence blindly following the predictions can be harmful. In this paper, we address this problem by giving algorithms that take predictions as inputs and perform robustly against the unknown prediction quality.   We consider the online resource allocation problem, one of the most generic models in revenue management and online decision-making. In this problem, a decision maker has a limited amount of resources, and requests arrive sequentially. For each request, the decision-maker needs to decide on an action, w
    
[^29]: PromptKD：通过提示调整为生成语言模型提取学生友好知识的蒸馏方法

    PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning

    [https://arxiv.org/abs/2402.12842](https://arxiv.org/abs/2402.12842)

    提出了PromptKD方法，通过提示调整实现了生成语言模型提取学生友好知识的蒸馏，无需微调整整个教师模型。

    

    近期大型语言模型（LLMs）的发展引起了对推理成本的担忧，进一步增加了对模型压缩研究的需求。尽管知识蒸馏（KD）是一种突出的方法，但是针对LLMs这样的生成语言模型的KD研究相对较少，而提取适合学生的知识的方法，在分类模型的KD中表现出了良好性能，在生成语言模型中尚未被探索。为了探索这种方法，我们提出了PromptKD，一种简单而有效的方法，它利用提示调整 - 在KD中首次出现 - 使生成语言模型能够传递适合学生的知识。与先前分类工作不同，先前那些需要微调整整个教师模型以提取适合学生的知识，PromptKD通过添加少量提示标记，并仅通过学生指导调整提示来达到类似效果。

    arXiv:2402.12842v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have raised concerns about inference costs, increasing the need for research into model compression. While knowledge distillation (KD) is a prominent method for this, research on KD for generative language models like LLMs is relatively sparse, and the approach of distilling student-friendly knowledge, which has shown promising performance in KD for classification models, remains unexplored in generative language models. To explore this approach, we propose PromptKD, a simple yet effective method that utilizes prompt tuning - for the first time in KD - to enable generative language models to transfer student-friendly knowledge. Unlike previous works in classification that require fine-tuning the entire teacher model for extracting student-friendly knowledge, PromptKD achieves similar effects by adding a small number of prompt tokens and tuning only the prompt with student guidance. Ex
    
[^30]: UniST：一种为城市时空预测设计的提示增强型通用模型

    UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction

    [https://arxiv.org/abs/2402.11838](https://arxiv.org/abs/2402.11838)

    UniST是一种为城市时空预测设计的通用模型，通过灵活性、有效的生成式预训练以及丰富的掩码策略成功捕捉复杂的时空关系。

    

    arXiv:2402.11838v1 公告类型：新的 摘要：城市时空预测对于决策至关重要，例如交通管理、资源优化和城市规划。尽管自然语言的预训练基础模型取得了显著突破，其中一个通用模型可以处理跨多个领域的多个任务，但城市时空建模落后。现有的城市预测方法通常针对特定的时空场景进行定制，需要特定任务的模型设计和大量域内训练数据。在这项工作中，我们提出了一种用于城市时空预测的通用模型UniST。借鉴自大型语言模型，UniST通过以下方式取得成功：(i) 对不同空间时间数据特征的灵活性，(ii) 有效的生成式预训练，采用精心设计的掩码策略来捕捉复杂的空间时间关系，(iii) 时空知识。

    arXiv:2402.11838v1 Announce Type: new  Abstract: Urban spatio-temporal prediction is crucial for informed decision-making, such as transportation management, resource optimization, and urban planning. Although pretrained foundation models for natural languages have experienced remarkable breakthroughs, wherein one general-purpose model can tackle multiple tasks across various domains, urban spatio-temporal modeling lags behind. Existing approaches for urban prediction are usually tailored for specific spatio-temporal scenarios, requiring task-specific model designs and extensive in-domain training data. In this work, we propose a universal model, UniST, for urban spatio-temporal prediction. Drawing inspiration from large language models, UniST achieves success through: (i) flexibility towards diverse spatio-temporal data characteristics, (ii) effective generative pre-training with elaborated masking strategies to capture complex spatio-temporal relationships, (iii) spatio-temporal know
    
[^31]: 朝向自消耗生成模型的理论理解

    Towards Theoretical Understandings of Self-Consuming Generative Models

    [https://arxiv.org/abs/2402.11778](https://arxiv.org/abs/2402.11778)

    通过构建理论框架，我们探讨了在自消耗循环中训练生成模型对数据分布学习的影响，证明了在足够大的训练数据集大小或真实数据比例条件下，合成数据分布与原始真实数据分布之间的总变差距离能够被有效控制。

    

    这篇论文探讨了训练生成模型的新挑战，即在一个自消耗循环中训练模型，其中连续的模型世代通过混合之前世代的真实数据和合成数据来进行递归训练。我们构建了一个理论框架，以严格评估这种训练方案对未来模型学习的数据分布产生的影响。具体来说，我们推导了在不同混合训练场景下，未来模型产生的合成数据分布与原始真实数据分布之间的总变差（TV）距离的界限。我们的分析表明，在混合训练数据集的大小或真实数据比例足够大的条件下，这种距离可以被有效控制。有趣的是，我们进一步揭示了由扩大合成数据量引起的相变，理论上证明了虽然TV距离表现出初始上升，但却逐渐下降。

    arXiv:2402.11778v1 Announce Type: cross  Abstract: This paper tackles the emerging challenge of training generative models within a self-consuming loop, wherein successive generations of models are recursively trained on mixtures of real and synthetic data from previous generations. We construct a theoretical framework to rigorously evaluate how this training regimen impacts the data distributions learned by future models. Specifically, we derive bounds on the total variation (TV) distance between the synthetic data distributions produced by future models and the original real data distribution under various mixed training scenarios. Our analysis demonstrates that this distance can be effectively controlled under the condition that mixed training dataset sizes or proportions of real data are large enough. Interestingly, we further unveil a phase transition induced by expanding synthetic data amounts, proving theoretically that while the TV distance exhibits an initial ascent, it declin
    
[^32]: 大型语言模型驱动的异质信息网络中元结构的发现

    Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network

    [https://arxiv.org/abs/2402.11518](https://arxiv.org/abs/2402.11518)

    提出了一种利用大型语言模型驱动的元结构搜索框架，解决了手工设计元结构不易扩展以及忽视可解释性的问题

    

    异质信息网络（HIN）因能够捕捉不同类型节点之间复杂关系而日益受到青睐。元结构被提出用于识别HIN上的重要关系模式，已证明在提取丰富语义信息和促进图神经网络学习表达力表示方面有效。然而，手工设计的元结构在扩展性方面存在挑战，这引起了广泛关注，以发展自动元结构搜索算法。先前的研究集中于寻找具有良好经验预测性能的元结构，而忽视了可解释性。因此，他们往往产生易于过度拟合和人类难以理解的元结构。为了解决这个问题，我们从大型语言模型（LLM）新兴的推理能力中获取启示。我们提出了一种新颖的REasoning meta-STRUCTure search（ReStruct）框架

    arXiv:2402.11518v1 Announce Type: new  Abstract: Heterogeneous information networks (HIN) have gained increasing popularity for being able to capture complex relations between nodes of diverse types. Meta-structure was proposed to identify important patterns of relations on HIN, which has been proven effective for extracting rich semantic information and facilitating graph neural networks to learn expressive representations. However, hand-crafted meta-structures pose challenges for scaling up, which draws wide research attention for developing automatic meta-structure search algorithms. Previous efforts concentrate on searching for meta-structures with good empirical prediction performance, overlooking explainability. Thus, they often produce meta-structures prone to overfitting and incomprehensible to humans. To address this, we draw inspiration from the emergent reasoning abilities of large language models (LLMs). We propose a novel REasoning meta-STRUCTure search (ReStruct) framewor
    
[^33]: ZeroG：探究图中跨数据集零射击可迁移性

    ZeroG: Investigating Cross-dataset Zero-shot Transferability in Graphs

    [https://arxiv.org/abs/2402.11235](https://arxiv.org/abs/2402.11235)

    ZeroG是一个新框架，旨在实现图中跨数据集零射击迁移，解决了特征不对齐、标签空间不匹配和负迁移等挑战

    

    随着如GPT-4这样的大型语言模型的发展，零射击迁移学习变得越来越重要。NLP模型的生成能力和CV模型的基于检索的方法突显了这一点，二者有效地弥合了已见数据和未见数据之间的差距。在图学习领域，新图的不断涌现和人类标注的挑战也加剧了零射击迁移学习的必要性，推动了探索能够在不需要特定数据集和标签特定微调的情况下泛化跨多样图数据的方法。在本研究中，我们通过引入ZeroG，一个旨在实现跨数据集泛化的新框架，将这样的范例扩展到了图中的零射击迁移性。解决诸如特征不对齐、不匹配的标签空间和负迁移等固有挑战。

    arXiv:2402.11235v1 Announce Type: new  Abstract: With the development of foundation models such as large language models, zero-shot transfer learning has become increasingly significant. This is highlighted by the generative capabilities of NLP models like GPT-4, and the retrieval-based approaches of CV models like CLIP, both of which effectively bridge the gap between seen and unseen data. In the realm of graph learning, the continuous emergence of new graphs and the challenges of human labeling also amplify the necessity for zero-shot transfer learning, driving the exploration of approaches that can generalize across diverse graph data without necessitating dataset-specific and label-specific fine-tuning. In this study, we extend such paradigms to zero-shot transferability in graphs by introducing ZeroG, a new framework tailored to enable cross-dataset generalization. Addressing the inherent challenges such as feature misalignment, mismatched label spaces, and negative transfer, we l
    
[^34]: 在贝叶斯设置中的固定置信度最佳臂识别问题

    Fixed Confidence Best Arm Identification in the Bayesian Setting

    [https://arxiv.org/abs/2402.10429](https://arxiv.org/abs/2402.10429)

    该研究在贝叶斯设置中探讨了固定置信度最佳臂识别问题，证明了传统频率设定下的算法在此设置下表现次优，并引入了一种性能与理论下限相匹配的连续排除变种。

    

    我们考虑了贝叶斯设置中的固定置信度最佳臂识别（FC-BAI）问题。该问题旨在在已知先验采样的情况下以固定置信水平找到均值最大的臂。大多数关于FC-BAI问题的研究都是在频率设定中进行的，在该设定下，游戏开始前即确定了赌博模型。我们证明了在贝叶斯设置中，传统的在频率设定中研究的FC-BAI算法（如track-and-stop和top-two算法）会导致任意次优的表现。我们同时证明了在贝叶斯设置下预期样本数的下限，并引入了一种连续排除的变种，其性能与下限相匹配，最多差一个对数因子。仿真验证了理论结果。

    arXiv:2402.10429v1 Announce Type: cross  Abstract: We consider the fixed-confidence best arm identification (FC-BAI) problem in the Bayesian Setting. This problem aims to find the arm of the largest mean with a fixed confidence level when the bandit model has been sampled from the known prior. Most studies on the FC-BAI problem have been conducted in the frequentist setting, where the bandit model is predetermined before the game starts. We show that the traditional FC-BAI algorithms studied in the frequentist setting, such as track-and-stop and top-two algorithms, result in arbitrary suboptimal performances in the Bayesian setting. We also prove a lower bound of the expected number of samples in the Bayesian setting and introduce a variant of successive elimination that has a matching performance with the lower bound up to a logarithmic factor. Simulations verify the theoretical results.
    
[^35]: 一体化与多功能性：一种简单而有效的跨领域图预训练方法

    All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining

    [https://arxiv.org/abs/2402.09834](https://arxiv.org/abs/2402.09834)

    本研究提出了一种简单而有效的跨领域图预训练方法，通过一体化和多功能性，使得大型语言模型在各个领域具备了超强的泛化能力。

    

    大型语言模型（LLMs）已经在计算机视觉（CV）和自然语言处理（NLP）领域取得了重大突破。LLMs最显著的进展之一是，在广泛且多样化的数据集上训练了单一模型，这些数据跨越多个领域，这种范式被称为“一体化”。这种方法使LLMs具备了超强的泛化能力，有助于理解各种数据分布。借助这些能力，单一的LLM在各种领域展现出了出色的多功能性，这种范式被称为“多功能一体化”。然而，将这个想法应用于图领域仍然面临着巨大的挑战，跨领域预训练经常导致负迁移。这个问题在少样本学习场景中尤为重要，因为训练数据的匮乏需要引入外部知识源。为了应对这个挑战，我们提出了一种新颖的方法。

    arXiv:2402.09834v1 Announce Type: new  Abstract: Large Language Models (LLMs) have revolutionized the fields of computer vision (CV) and natural language processing (NLP). One of the most notable advancements of LLMs is that a single model is trained on vast and diverse datasets spanning multiple domains -- a paradigm we term `All in One'. This methodology empowers LLMs with super generalization capabilities, facilitating an encompassing comprehension of varied data distributions. Leveraging these capabilities, a single LLM demonstrates remarkable versatility across a variety of domains -- a paradigm we term `One for All'. However, applying this idea to the graph field remains a formidable challenge, with cross-domain pretraining often resulting in negative transfer. This issue is particularly important in few-shot learning scenarios, where the paucity of training data necessitates the incorporation of external knowledge sources. In response to this challenge, we propose a novel approa
    
[^36]: 基于分布式在线凸优化的近似最优后悔算法

    Nearly Optimal Regret for Decentralized Online Convex Optimization

    [https://arxiv.org/abs/2402.09173](https://arxiv.org/abs/2402.09173)

    本论文研究了分布式在线凸优化，开发了新的算法来分别降低凸函数和强凸函数的后悔边界，并填补了现有下界之间的差距。

    

    我们研究了分布式在线凸优化(D-OCO)，其中一组本地学习器需要使用仅限于本地计算和通信的方法来最小化一系列全局损失函数。以前的研究已经确定了针对凸函数和强凸函数的后悔界限分别为$O(n^{5/4}\rho^{-1/2}\sqrt{T})$和${O}(n^{3/2}\rho^{-1}\log T)$，其中$n$是本地学习器的数量，$\rho<1$是通信矩阵的谱间隙，$T$是时间段。然而，对于凸函数存在着较大的间隙，即凸函数的下界为$\Omega(n\sqrt{T})$，强凸函数的下界为$\Omega(n)$。为了填补这些间隙，本文首先开发了新的D-OCO算法，将凸函数和强凸函数的后悔边界分别降低到$\tilde{O}(n\rho^{-1/4}\sqrt{T})$和$\tilde{O}(n\rho^{-1/2}\log T)$。主要技术是设计一种在线可进取的算法。

    arXiv:2402.09173v1 Announce Type: new Abstract: We investigate decentralized online convex optimization (D-OCO), in which a set of local learners are required to minimize a sequence of global loss functions using only local computations and communications. Previous studies have established $O(n^{5/4}\rho^{-1/2}\sqrt{T})$ and ${O}(n^{3/2}\rho^{-1}\log T)$ regret bounds for convex and strongly convex functions respectively, where $n$ is the number of local learners, $\rho<1$ is the spectral gap of the communication matrix, and $T$ is the time horizon. However, there exist large gaps from the existing lower bounds, i.e., $\Omega(n\sqrt{T})$ for convex functions and $\Omega(n)$ for strongly convex functions. To fill these gaps, in this paper, we first develop novel D-OCO algorithms that can respectively reduce the regret bounds for convex and strongly convex functions to $\tilde{O}(n\rho^{-1/4}\sqrt{T})$ and $\tilde{O}(n\rho^{-1/2}\log T)$. The primary technique is to design an online acce
    
[^37]: 改进了具有延迟反馈的强化学习问题的后悔率

    Improved Regret for Bandit Convex Optimization with Delayed Feedback

    [https://arxiv.org/abs/2402.09152](https://arxiv.org/abs/2402.09152)

    本文针对具有延迟反馈的强化学习问题提出了一种改进后悔率的算法，通过精确利用延迟的强化学习反馈，成功将后悔界限从$O(T^{3/4}+d^{1/3}T^{2/3})$改进为$O(T^{3/4}+\sqrt{dT})$，并在更大的延迟量$d=O(\sqrt{T})$情况下与非延迟设置下的强化学习梯度下降算法相匹配。

    

    我们研究了具有延迟反馈的强化学习问题，其中只有在任意延迟下才会显示动作的损失值。先前的研究通过简单地将延迟的损失值输入到经典的强化学习梯度下降算法，建立了该问题的后悔界限为$O(T^{3/4}+d^{1/3}T^{2/3})$。在本文中，我们开发了一种新的算法来提高后悔率，通过一个阻塞更新机制精确利用延迟的强化学习反馈。我们的分析首先揭示了所提出的算法可以分离延迟和强化学习反馈对后悔率的联合影响，并将凸函数的后悔界限改进为$O(T^{3/4}+\sqrt{dT})$。与先前的结果相比，在更大的延迟量$d=O(\sqrt{T})$，而不是$d=O(T^{1/4})$的情况下，我们的后悔与非延迟设置下强化学习梯度下降算法的$O(T^{3/4})$后悔相匹配。

    arXiv:2402.09152v1 Announce Type: new Abstract: We investigate bandit convex optimization (BCO) with delayed feedback, where only the loss value of the action is revealed under an arbitrary delay. Previous studies have established a regret bound of $O(T^{3/4}+d^{1/3}T^{2/3})$ for this problem, where $d$ is the maximum delay, by simply feeding delayed loss values to the classical bandit gradient descent (BGD) algorithm. In this paper, we develop a novel algorithm to enhance the regret, which carefully exploits the delayed bandit feedback via a blocking update mechanism. Our analysis first reveals that the proposed algorithm can decouple the joint effect of the delays and bandit feedback on the regret, and improve the regret bound to $O(T^{3/4}+\sqrt{dT})$ for convex functions. Compared with the previous result, our regret matches the $O(T^{3/4})$ regret of BGD in the non-delayed setting for a larger amount of delay, i.e., $d=O(\sqrt{T})$, instead of $d=O(T^{1/4})$. Furthermore, we consi
    
[^38]: 两种单相对比海比安学习的故事

    Two Tales of Single-Phase Contrastive Hebbian Learning

    [https://arxiv.org/abs/2402.08573](https://arxiv.org/abs/2402.08573)

    两种单相对比海比安学习的故事探索了学习算法的生物合理性，并提出了一种全局学习算法，能够消除与反向传播之间的性能差距，并解决了同步和无限小扰动带来的问题。

    

    对于“生物学上合理”的学习算法的探索已经收敛于将梯度表示为活动差异的想法。然而，大多数方法需要较高程度的同步（学习期间的不同阶段）并引入大量的计算开销，这对于它们的生物学合理性以及其在神经形态计算中的潜在效用产生了疑问。此外，它们通常依赖于对输出单元施加无限小扰动（nudges），这在嘈杂环境中是不切实际的。最近研究发现，通过将人工神经元建模为两个相反扰动的组件，名为“双向传播”的全局学习算法能够弥合到反向传播的性能差距，而不需要分别的学习阶段或无限小扰动。然而，该算法的数值稳定性依赖于对称扰动，这可能在生物学上受到限制。

    The search for "biologically plausible" learning algorithms has converged on the idea of representing gradients as activity differences. However, most approaches require a high degree of synchronization (distinct phases during learning) and introduce substantial computational overhead, which raises doubts regarding their biological plausibility as well as their potential utility for neuromorphic computing. Furthermore, they commonly rely on applying infinitesimal perturbations (nudges) to output units, which is impractical in noisy environments. Recently it has been shown that by modelling artificial neurons as dyads with two oppositely nudged compartments, it is possible for a fully local learning algorithm named ``dual propagation'' to bridge the performance gap to backpropagation, without requiring separate learning phases or infinitesimal nudging. However, the algorithm has the drawback that its numerical stability relies on symmetric nudging, which may be restrictive in biological
    
[^39]: 基于分数的扩散模型：随机微分方程的技术教程

    Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial

    [https://arxiv.org/abs/2402.07487](https://arxiv.org/abs/2402.07487)

    本文是基于分数的扩散模型的技术教程，重点讲解了通过随机微分方程进行公式化的方法，包括采样和分数匹配。适合初学者了解该领域，并且从业人员在设计新模型或算法时也可能会有所帮助。

    

    本文是关于基于分数的扩散模型的阐释性文章，重点介绍了通过随机微分方程(SDE)进行公式化的方法。在温和的介绍之后，我们讨论了扩散建模的两个关键点--采样和分数匹配，其中包括SDE/ODE采样，分数匹配效率，一致性模型和强化学习。我们提供了简短的证明来说明所述结果的主要思想。本文主要是为了向初学者介绍这个领域，同时从业人员在设计新模型或算法时也可能会发现一些分析有用。

    This is an expository article on the score-based diffusion models, with a particular focus on the formulation via stochastic differential equations (SDE). After a gentle introduction, we discuss the two pillars in the diffusion modeling -- sampling and score matching, which encompass the SDE/ODE sampling, score matching efficiency, the consistency model, and reinforcement learning. Short proofs are given to illustrate the main idea of the stated results. The article is primarily for introducing the beginners to the field, and practitioners may also find some analysis useful in designing new models or algorithms.
    
[^40]: 利用分治程序指导大型语言模型对问题求解进行引导

    Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving

    [https://arxiv.org/abs/2402.05359](https://arxiv.org/abs/2402.05359)

    该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。

    

    基础模型，如大型语言模型（LLMs），因其广泛的应用而引起了广泛的关注。现有的研究表明，适当的提示设计，如思维链，可以释放LLM在不同领域的强大能力。然而，对于处理涉及重复子任务和/或具有欺骗性内容的任务（如算术计算和文章级虚假新闻检测），现有的提示策略要么表现出表达能力不足，要么由幻觉引发中间错误。为了使LLM对这些中间错误更具辨别力，我们提出了一种以分治程序引导LLM的方法，同时确保优越的表达能力和任务分解、子任务解决和解决组装过程的分离。理论分析表明，我们的策略可以引导LLM扩展固定深度Transformer的表达能力。实验表明，我们提出的方法可以实现

    Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM's powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentangles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Transformer. Experiments indicate that our proposed method can achiev
    
[^41]: 梯度下降引发了深度非线性网络权重与经验NTK之间的对齐

    Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks

    [https://arxiv.org/abs/2402.05271](https://arxiv.org/abs/2402.05271)

    了解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。前人的研究表明，在训练过程中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这被称为神经特征分析（NFA）。本研究解释了这种相关性的出现，并发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。在早期训练阶段，可以通过解析的方式预测NFA的发展速度。

    

    理解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。先前的研究已经确定，在一般结构的训练神经网络中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这个说法被称为神经特征分析（NFA）。然而，这些数量在训练过程中如何相关尚不清楚。在这项工作中，我们解释了这种相关性的出现。我们发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。我们证明了先前研究中引入的NFA是由隔离这种对齐的中心化NFA驱动的。我们还展示了在早期训练阶段，可以通过解析的方式预测NFA的发展速度。

    Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of sim
    
[^42]: 关于偏离高斯混合专家模型参数估计的研究

    On Parameter Estimation in Deviated Gaussian Mixture of Experts

    [https://arxiv.org/abs/2402.05220](https://arxiv.org/abs/2402.05220)

    在偏离高斯混合专家模型中，本文通过构造Voronoi-based损失函数来解决参数估计问题。

    

    本文考虑了在偏离高斯混合专家模型中的参数估计问题，其中数据由$(1 - \lambda^{\ast}) g_0(Y| X)+ \lambda^{\ast} \sum_{i = 1}^{k_{\ast}} p_{i}^{\ast} f(Y|(a_{i}^{\ast})^{\top}X+b_i^{\ast},\sigma_{i}^{\ast})$生成，其中$X, Y$分别是协变量向量和响应变量，$g_{0}(Y|X)$是已知函数，$\lambda^{\ast} \in [0, 1]$是真实但未知的混合比例，$(p_{i}^{\ast}, a_{i}^{\ast}, b_{i}^{\ast}, \sigma_{i}^{\ast})$对于$1 \leq i \leq k^{\ast}$是高斯混合专家模型的未知参数。该问题源自于拟合优度检验，当我们希望检验数据是否由$g_{0}(Y|X)$（零假设）生成，还是由整个混合（备择假设）生成。基于专家函数的代数结构和$g_0$与混合部分的可区分性，我们构造了新的基于Voronoi的损失函数来捕捉c

    We consider the parameter estimation problem in the deviated Gaussian mixture of experts in which the data are generated from $(1 - \lambda^{\ast}) g_0(Y| X)+ \lambda^{\ast} \sum_{i = 1}^{k_{\ast}} p_{i}^{\ast} f(Y|(a_{i}^{\ast})^{\top}X+b_i^{\ast},\sigma_{i}^{\ast})$, where $X, Y$ are respectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a known function, $\lambda^{\ast} \in [0, 1]$ is true but unknown mixing proportion, and $(p_{i}^{\ast}, a_{i}^{\ast}, b_{i}^{\ast}, \sigma_{i}^{\ast})$ for $1 \leq i \leq k^{\ast}$ are unknown parameters of the Gaussian mixture of experts. This problem arises from the goodness-of-fit test when we would like to test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or they are generated from the whole mixture (alternative hypothesis). Based on the algebraic structure of the expert functions and the distinguishability between $g_0$ and the mixture part, we construct novel Voronoi-based loss functions to capture the c
    
[^43]: 无源域自适应的扩散引导源数据生成

    Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation

    [https://arxiv.org/abs/2402.04929](https://arxiv.org/abs/2402.04929)

    本文提出了一种无源域自适应的新方法，利用扩散模型生成上下文相关的领域特定图像，通过微调预训练模型和无监督领域自适应技术实现了显著的性能改进。

    

    本文引入了一种利用扩散模型的泛化能力进行无源域自适应（DM-SFDA）的新方法。我们提出的DM-SFDA方法包括对预训练的文本到图像扩散模型进行微调，并使用目标图像的特征来指导扩散过程生成源域图像。具体而言，预训练的扩散模型被微调以生成最小化熵并最大化预训练源模型置信度的源样本。然后，我们应用已建立的无监督领域自适应技术将生成的源图像与目标域数据进行对齐。我们通过在一系列数据集上进行全面实验验证了我们的方法，包括Office-31、Office-Home和VisDA。结果显示，在无源域自适应的性能方面取得了显著的改进，展示了扩散模型在生成上下文相关的、领域特定的图像方面的潜力。

    This paper introduces a novel approach to leverage the generalizability capability of Diffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed DM-SFDA method involves fine-tuning a pre-trained text-to-image diffusion model to generate source domain images using features from the target images to guide the diffusion process. Specifically, the pre-trained diffusion model is fine-tuned to generate source samples that minimize entropy and maximize confidence for the pre-trained source model. We then apply established unsupervised domain adaptation techniques to align the generated source images with target domain data. We validate our approach through comprehensive experiments across a range of datasets, including Office-31, Office-Home, and VisDA. The results highlight significant improvements in SFDA performance, showcasing the potential of diffusion models in generating contextually relevant, domain-specific images.
    
[^44]: 大型语言模型作为可信的解释器

    Large Language Models As Faithful Explainers

    [https://arxiv.org/abs/2402.04678](https://arxiv.org/abs/2402.04678)

    本论文提出了一个生成解释框架（xLLM），用于提高大型语言模型（LLMs）自然语言格式解释的可信度。通过一个评估器来量化解释的可信度，并通过迭代优化过程来提高可信度。

    

    近年来，大型语言模型(LLMs)通过利用其丰富的内部知识和推理能力，已经能够熟练解决复杂的任务。然而，这种复杂性阻碍了传统的以输入为重点的解释算法来解释LLMs的复杂决策过程。为了解决这个问题，最近出现了一种自我解释机制，通过自然语言的形式进行单向推理，从而实现对LLMs预测的解释。然而，这种自然语言解释经常因为缺乏可信度而受到批评，因为这些解释可能不准确地反映LLMs的决策行为。在这项工作中，我们引入了一个生成解释框架xLLM，以提高LLMs自然语言格式的解释的可信度。具体而言，我们提出了一个评估器来量化自然语言解释的可信度，并通过xLLM的迭代优化过程来提高可信度，目标是最大程度地提高可信度。

    Large Language Models (LLMs) have recently become proficient in addressing complex tasks by utilizing their rich internal knowledge and reasoning ability. Consequently, this complexity hinders traditional input-focused explanation algorithms for explaining the complex decision-making processes of LLMs. Recent advancements have thus emerged for self-explaining their predictions through a single feed-forward inference in a natural language format. However, natural language explanations are often criticized for lack of faithfulness since these explanations may not accurately reflect the decision-making behaviors of the LLMs. In this work, we introduce a generative explanation framework, xLLM, to improve the faithfulness of the explanations provided in natural language formats for LLMs. Specifically, we propose an evaluator to quantify the faithfulness of natural language explanation and enhance the faithfulness by an iterative optimization process of xLLM, with the goal of maximizing the 
    
[^45]: 正凹深度均衡模型

    Positive concave deep equilibrium models

    [https://arxiv.org/abs/2402.04029](https://arxiv.org/abs/2402.04029)

    引入了一种新颖的正凹深度均衡（pcDEQ）模型，通过引入非负权重和凹函数的激活函数，确保了模型的存在性和唯一性。

    

    深度均衡（DEQ）模型被广泛认为是标准神经网络的一种内存效率高的替代方案，在语言建模和计算机视觉任务中实现了最先进的性能。这些模型通过求解一个固定点方程而不是显式地计算输出，使它们与标准神经网络有所不同。然而，现有的DEQ模型往往缺乏对固定点存在性和唯一性的形式保证，并且计算固定点的数值方案的收敛性也没有得到形式上的证明。因此，在实践中DEQ模型可能是不稳定的。为了解决这些缺点，我们引入了一种新颖的DEQ模型类，称为正凹深度均衡（pcDEQ）模型。我们的方法基于非线性Perron-Frobenius理论，强制施加非负权重和在正半轴上是凹函数的激活函数。通过引入这些约束，我们可以轻松地确保固定点的存在性和唯一性。

    Deep equilibrium (DEQ) models are widely recognized as a memory efficient alternative to standard neural networks, achieving state-of-the-art performance in language modeling and computer vision tasks. These models solve a fixed point equation instead of explicitly computing the output, which sets them apart from standard neural networks. However, existing DEQ models often lack formal guarantees of the existence and uniqueness of the fixed point, and the convergence of the numerical scheme used for computing the fixed point is not formally established. As a result, DEQ models are potentially unstable in practice. To address these drawbacks, we introduce a novel class of DEQ models called positive concave deep equilibrium (pcDEQ) models. Our approach, which is based on nonlinear Perron-Frobenius theory, enforces nonnegative weights and activation functions that are concave on the positive orthant. By imposing these constraints, we can easily ensure the existence and uniqueness of the fi
    
[^46]: 技能集优化：通过可转移技能增强语言模型行为

    Skill Set Optimization: Reinforcing Language Model Behavior via Transferable Skills

    [https://arxiv.org/abs/2402.03244](https://arxiv.org/abs/2402.03244)

    本论文提出了一种技能集优化（SSO）方法，通过构建和完善可转移的技能集来提高大型语言模型（LLM）的性能。该方法通过提取高奖励的共同子轨迹，生成子目标和说明，并在上下文中提供给LLM演员，以强化行为。实验结果显示，SSO在不同环境中能够优化技能集，并实现上下文策略改进。

    

    近期，大型语言模型（LLMs）已被用于交互环境中的顺序决策。然而，利用环境奖励信号来不断改进LLM演员的表现并不简单。我们提出了技能集优化（SSO）来通过构建和完善可转移技能集来提高LLM演员的性能。SSO通过提取具有高奖励的共同子轨迹并生成子目标和说明来构建技能。这些技能在上下文中提供给LLM演员，以强化具有高奖励的行为。然后，SSO通过修剪不再产生高奖励的技能来进一步完善技能集。我们在经典视频游戏NetHack和文本环境ScienceWorld中评估了我们的方法，以展示SSO优化技能集并进行上下文策略改进的能力。在我们的自定义NetHack任务中，SSO的性能超过基准方法40%，并超过了先前的最新状态。

    Large language models (LLMs) have recently been used for sequential decision making in interactive environments. However, leveraging environment reward signals for continual LLM actor improvement is not straightforward. We propose Skill Set Optimization (SSO) for improving LLM actor performance through constructing and refining sets of transferable skills. SSO constructs skills by extracting common subtrajectories with high rewards and generating subgoals and instructions to represent each skill. These skills are provided to the LLM actor in-context to reinforce behaviors with high rewards. Then, SSO further refines the skill set by pruning skills that do not continue to result in high rewards. We evaluate our method in the classic videogame NetHack and the text environment ScienceWorld to demonstrate SSO's ability to optimize a set of skills and perform in-context policy improvement. SSO outperforms baselines by 40% in our custom NetHack task and outperforms the previous state-of-the-
    
[^47]: EasyInstruct：一个易于使用的用于大型语言模型的指令处理框架

    EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models

    [https://arxiv.org/abs/2402.03049](https://arxiv.org/abs/2402.03049)

    EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。

    

    近年来，指令调整已经引起了越来越多的关注，并成为增强大型语言模型（LLMs）能力的一种关键技术。为了构建高质量的指令数据集，已经提出了许多指令处理方法，旨在在数据数量和数据质量之间达到精巧的平衡。然而，由于各种指令处理方法之间仍然存在不一致，目前没有标准的开源指令处理实现框架可供社区使用，这使得从业者无法进一步开发和推进。为了促进指令处理的研究和开发，我们提出了EasyInstruct，一个易于使用的用于LLMs的指令处理框架，它将指令生成、选择和提示模块化，并考虑它们的组合和交互。EasyInstruct已经在https://github.com/zjunlp/EasyInstruct上公开发布，并得到了积极维护。

    In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
    
[^48]: AdaTreeFormer: 从一张高分辨率图像中进行树木计数的少样本领域自适应

    AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a Single High-Resolution Image

    [https://arxiv.org/abs/2402.02956](https://arxiv.org/abs/2402.02956)

    AdaTreeFormer是一种从源领域学习并适应只有有限数量标注树木的目标领域的框架，利用一个共享的编码器和分层特征提取方案，实现了树木计数的少样本领域自适应。

    

    仅使用一张航空或卫星图像来估计和计数树木密度是摄影测量和遥感领域中一项困难的任务。然而，它在森林管理中起着至关重要的作用。不同地形上各种各样的树木种类严重阻碍了树木计数模型的良好表现。本文旨在提出一个从具有足够标注树木的源领域学习并适应只有有限数量标注树木的目标领域的框架。我们的方法称为AdaTreeFormer，包含一个共享的编码器和一个分层特征提取方案，用于从源领域和目标领域中提取稳健的特征。它还包括三个子网络：两个用于分别从源领域和目标领域提取自注意力图，并一个用于提取跨领域注意力图。对于后者，引入了一种注意力适应机制，用于从不同领域中提取相关信息。

    The process of estimating and counting tree density using only a single aerial or satellite image is a difficult task in the fields of photogrammetry and remote sensing. However, it plays a crucial role in the management of forests. The huge variety of trees in varied topography severely hinders tree counting models to perform well. The purpose of this paper is to propose a framework that is learnt from the source domain with sufficient labeled trees and is adapted to the target domain with only a limited number of labeled trees. Our method, termed as AdaTreeFormer, contains one shared encoder with a hierarchical feature extraction scheme to extract robust features from the source and target domains. It also consists of three subnets: two for extracting self-domain attention maps from source and target domains respectively and one for extracting cross-domain attention maps. For the latter, an attention-to-adapt mechanism is introduced to distill relevant information from different doma
    
[^49]: 关于Softmax Gating混合专家模型中最小二乘估计的研究

    On Least Squares Estimation in Softmax Gating Mixture of Experts

    [https://arxiv.org/abs/2402.02952](https://arxiv.org/abs/2402.02952)

    本研究探讨了在确定性MoE模型下使用最小二乘估计器的性能，并建立了强可识别性条件来描述不同类型专家函数的收敛行为。

    

    专家模型是一种统计机器学习设计，使用Softmax Gating函数聚合多个专家网络，以形成一个更复杂和表达力更强的模型。尽管由于可扩展性而在多个应用领域中广泛使用，但MoE模型的数学和统计性质复杂且难以分析。因此，以前的理论工作主要集中在概率MoE模型上，这些模型假设数据是由高斯MoE模型生成的，这在实践中是不切实际的。在这项工作中，我们研究了在确定性MoE模型下最小二乘估计器（LSE）的性能，在该模型中，数据根据回归模型进行采样，这是一个尚未被充分探索的设置。我们建立了一个称为强可识别性的条件，以表征不同类型专家函数的收敛行为。我们证明了对于强可识别专家的估计速度，即

    Mixture of experts (MoE) model is a statistical machine learning design that aggregates multiple expert networks using a softmax gating function in order to form a more intricate and expressive model. Despite being commonly used in several applications owing to their scalability, the mathematical and statistical properties of MoE models are complex and difficult to analyze. As a result, previous theoretical works have primarily focused on probabilistic MoE models by imposing the impractical assumption that the data are generated from a Gaussian MoE model. In this work, we investigate the performance of the least squares estimators (LSE) under a deterministic MoE model where the data are sampled according to a regression model, a setting that has remained largely unexplored. We establish a condition called strong identifiability to characterize the convergence behavior of various types of expert functions. We demonstrate that the rates for estimating strongly identifiable experts, namel
    
[^50]: 简化的LLaMA: 大规模语言模型的简单深度修剪

    Shortened LLaMA: A Simple Depth Pruning for Large Language Models

    [https://arxiv.org/abs/2402.02834](https://arxiv.org/abs/2402.02834)

    使用简单的深度修剪方法可以提高大规模语言模型的推理速度，在内存受限的条件下表现良好，对部署在本地和边缘设备上的LLMs有帮助。

    

    现代大规模语言模型 (LLMs) 的结构化修剪已成为降低其高计算需求的一种方法。宽度修剪减小投影权重矩阵的大小 (例如通过删除注意力头)，同时保持层数不变。与此相反，深度修剪则删除整个层或块，同时保持剩余权重的大小不变。目前的大多数研究集中在宽度修剪或宽度和深度修剪的混合上，很少对两者 (宽度与深度) 在对LLM推理效率的影响方面进行比较分析。在这项工作中，我们展示了一种简单的深度修剪方法可以与最新的宽度修剪方法在零-shot任务性能方面竞争。我们的修剪方法提高了推理速度，特别是在内存受限的情况下，需要对运行LLMs进行有限批次大小的条件，此时宽度修剪无效。我们希望这项工作能够帮助将LLMs部署在本地和边缘设备上。

    Structured pruning of modern large language models (LLMs) has emerged as a way of decreasing their high computational needs. Width pruning reduces the size of projection weight matrices (e.g., by removing attention heads) while maintaining the number of layers. Depth pruning, in contrast, removes entire layers or blocks, while keeping the size of the remaining weights unchanged. Most current research focuses on either width-only or a blend of width and depth pruning, with little comparative analysis between the two units (width vs. depth) concerning their impact on LLM inference efficiency. In this work, we show that a simple depth pruning approach can compete with recent width pruning methods in terms of zero-shot task performance. Our pruning method boosts inference speeds, especially under memory-constrained conditions that require limited batch sizes for running LLMs, where width pruning is ineffective. We hope this work can help deploy LLMs on local and edge devices.
    
[^51]: 基于卷积自编码器的降阶模型的实用存在定理

    A practical existence theorem for reduced order models based on convolutional autoencoders

    [https://arxiv.org/abs/2402.00435](https://arxiv.org/abs/2402.00435)

    本论文提出了基于卷积自编码器的降阶模型的实用存在定理，解决了在处理复杂非线性问题方面传统方法的不足，并讨论了如何学习潜在特征的挑战。

    

    近年来，深度学习在偏微分方程和降阶建模领域越发受欢迎，提供了基于物理知识的神经网络、神经算子、深度算子网络和深度学习降阶模型等强大的数据驱动技术。在这种情况下，基于卷积神经网络的深度自编码器表现出极高的效果，在处理复杂的非线性问题时，优于传统的降阶方法。然而，尽管基于CNN的自编码器在实践中取得了成功，但目前只有少数理论结果支持这些架构，通常以万能逼近定理的形式陈述。尤其是，尽管现有文献为设计卷积自编码器提供了指导方针，但学习潜在特征的后续挑战几乎没有被探究。

    In recent years, deep learning has gained increasing popularity in the fields of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM), providing domain practitioners with new powerful data-driven techniques such as Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context, deep autoencoders based on Convolutional Neural Networks (CNNs) have proven extremely effective, outperforming established techniques, such as the reduced basis method, when dealing with complex nonlinear problems. However, despite the empirical success of CNN-based autoencoders, there are only a few theoretical results supporting these architectures, usually stated in the form of universal approximation theorems. In particular, although the existing literature provides users with guidelines for designing convolutional autoencoders, the subsequent challenge of learning the latent features has been barely inv
    
[^52]: 跨越进化算法和强化学习：一项全面调查

    Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey

    [https://arxiv.org/abs/2401.11963](https://arxiv.org/abs/2401.11963)

    通过整合进化算法与强化学习，进化强化学习（ERL）展现出卓越的性能提升，本综述呈现了ERL领域的各个研究分支，突出了EA辅助RL的优化、RL辅助EA的优化以及EA和RL的协同优化这三个主要研究方向。

    

    进化强化学习（ERL）将进化算法（EAs）和强化学习（RL）相结合进行优化，表现出卓越的性能提升。通过融合两种方法的优势，ERL已经成为一个有前景的研究方向。本调查综述了ERL中不同研究分支的全面概述。具体而言，我们系统总结了相关算法的最新进展，并确定了三个主要研究方向：EA辅助RL的优化，RL辅助EA的优化，以及EA和RL的协同优化。随后，我们深入分析了每个研究方向，组织了多个研究分支。我们阐明了每个分支致力于解决的问题，以及EA和RL的整合如何应对这些挑战。最后，我们讨论了潜在的挑战和未来的研究方向。

    arXiv:2401.11963v2 Announce Type: replace-cross  Abstract: Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary Algorithms (EAs) and Reinforcement Learning (RL) for optimization, has demonstrated remarkable performance advancements. By fusing the strengths of both approaches, ERL has emerged as a promising research direction. This survey offers a comprehensive overview of the diverse research branches in ERL. Specifically, we systematically summarize recent advancements in relevant algorithms and identify three primary research directions: EA-assisted optimization of RL, RL-assisted optimization of EA, and synergistic optimization of EA and RL. Following that, we conduct an in-depth analysis of each research direction, organizing multiple research branches. We elucidate the problems that each branch aims to tackle and how the integration of EA and RL addresses these challenges. In conclusion, we discuss potential challenges and prospective future research directions
    
[^53]: 扩散模型、图像超分辨率和一切：一项调查研究

    Diffusion Models, Image Super-Resolution And Everything: A Survey

    [https://arxiv.org/abs/2401.00736](https://arxiv.org/abs/2401.00736)

    扩散模型（DMs）在图像超分辨率（SR）领域产生了颠覆性的影响，缩小了图像质量与人类感知偏好之间的差距。该研究调查了DM的理论基础，分析了其独特特点和方法，探索了替代输入领域等当前的研究方向。

    

    扩散模型（DMs）在图像超分辨率（SR）领域中产生了颠覆性的影响，进一步缩小了图像质量与人类感知偏好之间的差距。它们易于训练，并能生成比以前的生成方法产生的样本更高质量的图像。尽管取得了有希望的结果，但它们也带来了新的挑战，需要进一步的研究：高计算需求、可比性、缺乏可解释性、色彩偏移等。不幸的是，由于大量的出版物，进入这个领域令人难以应对。为了解决这个问题，我们提供了一个统一的叙述，阐明了应用于图像超分辨率的DM的理论基础，并提供了一份详细的分析，突出了该领域内与其他综述文章不同的独特特点和方法。这项调查研究对DM的原则进行了一个连贯的理解，并探索了当前的研究方向，包括替代输入领域等。

    Diffusion Models (DMs) have disrupted the image Super-Resolution (SR) field and further closed the gap between image quality and human perceptual preferences. They are easy to train and can produce very high-quality samples that exceed the realism of those produced by previous generative methods. Despite their promising results, they also come with new challenges that need further research: high computational demands, comparability, lack of explainability, color shifts, and more. Unfortunately, entry into this field is overwhelming because of the abundance of publications. To address this, we provide a unified recount of the theoretical foundations underlying DMs applied to image SR and offer a detailed analysis that underscores the unique characteristics and methodologies within this domain, distinct from broader existing reviews in the field. This survey articulates a cohesive understanding of DM principles and explores current research avenues, including alternative input domains, c
    
[^54]: 更快速的Switchback实验方法

    Faster Rates for Switchback Experiments

    [https://arxiv.org/abs/2312.15574](https://arxiv.org/abs/2312.15574)

    本研究提出了一种更快速的Switchback实验方法，通过使用整个时间块，以 $\sqrt{\log T/T}$ 的速率估计全局平均处理效应。

    

    Switchback实验设计中，一个单独的单元（例如整个系统）在交替的时间块中暴露于一个随机处理，处理并行处理了跨单元和时间干扰问题。Hu和Wager（2022）最近提出了一种截断块起始的处理效应估计器，并在Markov条件下证明了用于估计全局平均处理效应（GATE）的$T^{-1/3}$速率，他们声称这个速率是最优的，并建议将注意力转向不同（且依赖设计）的估计量，以获得更快的速率。对于相同的设计，我们提出了一种替代估计器，使用整个块，并惊人地证明，在相同的假设下，它实际上达到了原始的设计独立GATE估计量的$\sqrt{\log T/T}$的估计速率。

    Switchback experimental design, wherein a single unit (e.g., a whole system) is exposed to a single random treatment for interspersed blocks of time, tackles both cross-unit and temporal interference. Hu and Wager (2022) recently proposed a treatment-effect estimator that truncates the beginnings of blocks and established a $T^{-1/3}$ rate for estimating the global average treatment effect (GATE) in a Markov setting with rapid mixing. They claim this rate is optimal and suggest focusing instead on a different (and design-dependent) estimand so as to enjoy a faster rate. For the same design we propose an alternative estimator that uses the whole block and surprisingly show that it in fact achieves an estimation rate of $\sqrt{\log T/T}$ for the original design-independent GATE estimand under the same assumptions.
    
[^55]: 通过对抗性上下文学习优化提示

    Prompt Optimization via Adversarial In-Context Learning

    [https://arxiv.org/abs/2312.02614](https://arxiv.org/abs/2312.02614)

    提出了Adversarial In-Context Learning (adv-ICL)方法，通过生成器、鉴别器和提示修改器之间的对抗学习优化提示，在上下文学习中取得显着改进。

    

    我们提出了一种新方法，Adversarial In-Context Learning（adv-ICL），通过利用一个LLM作为生成器，另一个作为鉴别器，第三个作为提示修改器，来优化上下文学习（ICL）的提示。类似于传统的对抗性学习，adv-ICL被实现为生成器和鉴别器之间的双人博弈，其中生成器试图生成足够逼真的输出以欺骗鉴别器。 在每一轮中，给定由任务说明前缀和几个示例组成的输入，生成器产生一个输出。然后，鉴别器负责将生成器的输入-输出对分类为模型生成的还是真实数据。根据鉴别器损失，提示修改器提出了可能对生成器和鉴别器提示进行的编辑，并选择最大程度改善对抗损失的编辑。我们展示了adv-ICL相对于最先进的提示优化有显着改进。

    arXiv:2312.02614v2 Announce Type: replace-cross  Abstract: We propose a new method, Adversarial In-Context Learning (adv-ICL), to optimize prompt for in-context learning (ICL) by employing one LLM as a generator, another as a discriminator, and a third as a prompt modifier. As in traditional adversarial learning, adv-ICL is implemented as a two-player game between the generator and discriminator, where the generator tries to generate realistic enough output to fool the discriminator. In each round, given an input prefixed by task instructions and several exemplars, the generator produces an output. The discriminator is then tasked with classifying the generator input-output pair as model-generated or real data. Based on the discriminator loss, the prompt modifier proposes possible edits to the generator and discriminator prompts, and the edits that most improve the adversarial loss are selected. We show that adv-ICL results in significant improvements over state-of-the-art prompt optim
    
[^56]: (深)线性神经网络中的权重波动和逆方差平直关系的推导

    Weight fluctuations in (deep) linear neural networks and a derivation of the inverse-variance flatness relation

    [https://arxiv.org/abs/2311.14120](https://arxiv.org/abs/2311.14120)

    该研究探讨了单层和双层线性神经网络在随机梯度下降中的稳定训练规则，并发现了权重波动在各种情况下的各向异性特征，其中双层网络中的权重波动受到层间耦合的影响，并呈现出各向异性损失。

    

    我们在合成高斯数据的随机梯度下降（SGD）的连续极限内，研究了单层和双层线性欠参数化神经网络的稳定（末态）训练规则。对于 schwach欠参数化区域中的单层网络，噪声协方差矩阵的谱明显偏离Hessian，可以归因于SGD动态的破坏详细平衡。在这种情况下，权重波动通常是各向异性的，但受各向同性损失限制。对于双层网络，我们获得了每层权重的随机动力学，并分析了相关的稳定协方差。我们确定了层间耦合作为权重波动的各向异性的新来源。与单层情况相反，权重波动经历各向异性损失，其平直度与波动的方差成反比。

    arXiv:2311.14120v2 Announce Type: replace  Abstract: We investigate the stationary (late-time) training regime of single- and two-layer linear underparameterized neural networks within the continuum limit of stochastic gradient descent (SGD) for synthetic Gaussian data. In the case of a single-layer network in the weakly underparameterized regime, the spectrum of the noise covariance matrix deviates notably from the Hessian, which can be attributed to the broken detailed balance of SGD dynamics. The weight fluctuations are in this case generally anisotropic, but are subject to an isotropic loss. For a two-layer network, we obtain the stochastic dynamics of the weights in each layer and analyze the associated stationary covariances. We identify the inter-layer coupling as a new source of anisotropy for the weight fluctuations. In contrast to the single-layer case, the weight fluctuations experience an anisotropic loss, the flatness of which is inversely related to the fluctuation varian
    
[^57]: 数据同化的神经Koopman先验

    Neural Koopman prior for data assimilation

    [https://arxiv.org/abs/2309.05317](https://arxiv.org/abs/2309.05317)

    本文介绍了一种利用神经Koopman先验进行数据同化的方法，将动态系统嵌入到潜在空间，使得对其动态进行线性描述，并展示了长期连续重构和自监督学习的潜力。

    

    随着大规模数据集、计算能力和诸如自动微分和表达能力强的神经网络架构等工具的日益普及，序贯数据现在经常以数据驱动的方式处理，通过从观测数据训练动力学模型。尽管神经网络经常被视为不可解释的黑盒架构，但它们仍然可以受益于数据的物理先验和数学知识。在本文中，我们使用了一种神经网络架构，该架构利用长期以来已知的Koopman算子理论，将动力系统嵌入到潜在空间中，其中它们的动态可以被线性描述，从而呈现出许多吸引人的特性。我们引入了使该模型能够进行长期连续重构的方法，即使在数据呈不规则采样时间序列的困难情境中也可以顺利进行。我们还展示了自监督学习的潜力，因为我们展示

    arXiv:2309.05317v2 Announce Type: replace  Abstract: With the increasing availability of large scale datasets, computational power and tools like automatic differentiation and expressive neural network architectures, sequential data are now often treated in a data-driven way, with a dynamical model trained from the observation data. While neural networks are often seen as uninterpretable black-box architectures, they can still benefit from physical priors on the data and from mathematical knowledge. In this paper, we use a neural network architecture which leverages the long-known Koopman operator theory to embed dynamical systems in latent spaces where their dynamics can be described linearly, enabling a number of appealing features. We introduce methods that enable to train such a model for long-term continuous reconstruction, even in difficult contexts where the data comes in irregularly-sampled time series. The potential for self-supervised learning is also demonstrated, as we show
    
[^58]: EasyEdit：一种易于使用的大型语言模型知识编辑框架

    EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models

    [https://arxiv.org/abs/2308.07269](https://arxiv.org/abs/2308.07269)

    EasyEdit提出了一种易于使用的知识编辑框架，针对大型语言模型的知识截断或谬误问题，支持各种最新的知识编辑方法，并可应用于多个知名的LLMs。

    

    大型语言模型（LLMs）通常遭受知识截断或谬误问题，这意味着它们对未见事件不知情或生成具有不正确事实的文本，原因是数据过时/嘈杂。为此，出现了许多针对LLMs的知识编辑方法，旨在微妙地注入/编辑更新的知识或调整不良行为，同时将对不相关输入的影响最小化。然而，由于各种知识编辑方法之间存在显著差异，以及任务设置中的变化，社区中没有可用于知识编辑的标准实施框架，这妨碍了从业者将知识编辑应用于应用程序。为解决这些问题，我们提出了EasyEdit，一种易于使用的LLMs知识编辑框架。它支持各种尖端的知识编辑方法，并可以轻松应用于许多著名的LLMs，如T5、GPT-J、LlaMA等。从经验上来看，我们报告了kno

    arXiv:2308.07269v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy issues, which means they are unaware of unseen events or generate text with incorrect facts owing to outdated/noisy data. To this end, many knowledge editing approaches for LLMs have emerged -- aiming to subtly inject/edit updated knowledge or adjust undesired behavior while minimizing the impact on unrelated inputs. Nevertheless, due to significant differences among various knowledge editing methods and the variations in task setups, there is no standard implementation framework available for the community, which hinders practitioners from applying knowledge editing to applications. To address these issues, we propose EasyEdit, an easy-to-use knowledge editing framework for LLMs. It supports various cutting-edge knowledge editing approaches and can be readily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc. Empirically, we report the kno
    
[^59]: 在不断学习的表示中的知识积累与特征遗忘问题

    Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting

    [https://arxiv.org/abs/2304.00933](https://arxiv.org/abs/2304.00933)

    揭示了持续学习表示中的知识积累和特征遗忘问题，表明即使特征遗忘的绝对程度可能较小，新学习的信息在表示层面也面临着严重遗忘。

    

    连续学习研究表明，神经网络在“输出级别”遭受灾难性遗忘，但有争议的是是否在学习的表示级别也存在这种情况。多个最近的研究将表示归因为具有一定程度的固有抗遗忘性 - 仅会最小程度忘记且不会遗失关键信息。我们重新审视并扩展了揭示这种遗忘差异的实验，说明了影响持续学习表示质量的两种现象共存：知识积累和特征遗忘。我们谨慎考虑了这两个方面，表明尽管绝对值上特征遗忘可能较小，新学习的信息在表示层面与输出层面一样面临灾难性遗忘。接下来，我们展示了这种特征遗忘问题

    arXiv:2304.00933v3 Announce Type: replace  Abstract: Continual learning research has shown that neural networks suffer from catastrophic forgetting "at the output level", but it is debated whether this is also the case at the level of learned representations. Multiple recent studies ascribe representations a certain level of innate robustness against forgetting - that they only forget minimally and no critical information. We revisit and expand upon the experiments that revealed this difference in forgetting and illustrate the coexistence of two phenomena that affect the quality of continually learned representations: knowledge accumulation and feature forgetting. Carefully taking both aspects into account, we show that, even though it is true that feature forgetting can be small in absolute terms, newly learned information tends to be forgotten just as catastrophically at the level of the representation as it is at the output level. Next we show that this feature forgetting is problem
    
[^60]: OMPGPT: 一种用于OpenMP的生成式预训练Transformer模型

    OMPGPT: A Generative Pre-trained Transformer Model for OpenMP. (arXiv:2401.16445v1 [cs.SE])

    [http://arxiv.org/abs/2401.16445](http://arxiv.org/abs/2401.16445)

    OMPGPT是一种为了OpenMP pragma生成而设计的生成式预训练Transformer模型，采用了来自NLP领域的提示工程技术，并创建了一种创新的策略chain-of-OMP。

    

    大型语言模型（LLMs），如ChatGPT等模型，已经在自然语言处理领域引起了革命。随着这一趋势，基于代码的大型语言模型，如StarCoder、WizardCoder和CodeLlama等，已经涌现出来，在大量的代码数据库上进行了广泛的训练。然而，由于设计固有的原因，这些模型主要关注代码生成、代码完成和注释生成等生成任务，以及对多种编程语言的一般支持。虽然代码LLMs的通用能力对许多程序员来说很有用，但高性能计算（HPC）领域具有更窄的需求集，使得更小、更具领域特定的LM成为一个更明智的选择。本文介绍了OMPGPT，这是一种精心设计的新型模型，旨在充分利用语言模型在OpenMP pragma生成方面的固有优势。此外，我们采用并改进了来自NLP领域的提示工程技术，创建了链式OMP（chain-of-OMP），这是一种创新策略。

    Large language models (LLMs), as epitomized by models like ChatGPT, have revolutionized the field of natural language processing (NLP). Along with this trend, code-based large language models such as StarCoder, WizardCoder, and CodeLlama have emerged, trained extensively on vast repositories of code data. Yet, inherent in their design, these models primarily focus on generative tasks like code generation, code completion, and comment generation, and general support for multiple programming languages. While the generic abilities of code LLMs are useful for many programmers, the area of high-performance computing (HPC) has a narrower set of requirements that make a smaller and more domain-specific LM a smarter choice. This paper introduces OMPGPT, a novel model meticulously designed to harness the inherent strengths of language models for OpenMP pragma generation. Furthermore, we adopt and adapt prompt engineering techniques from the NLP domain to create chain-of-OMP, an innovative strat
    
[^61]: 专家与聚类：分层在线偏好学习框架

    Expert with Clustering: Hierarchical Online Preference Learning Framework. (arXiv:2401.15062v1 [cs.LG])

    [http://arxiv.org/abs/2401.15062](http://arxiv.org/abs/2401.15062)

    本研究提出了一种名为Expert with Clustering (EWC)的分层在线偏好学习框架，它利用聚类技术和专家建议的预测来加速用户偏好学习，并通过一种新颖的损失引导距离度量生成更具代表性的聚类中心。

    

    新兴的移动系统越来越能够向移动用户推荐选项，以引导他们朝向个性化但可持续的系统结果。与典型的推荐系统相比，最小化后悔是至关重要的，因为1）移动选项直接影响用户的生活，2）系统的可持续性依赖于足够的用户参与。在本研究中，我们考虑通过利用捕捉用户移动偏好的低维潜在空间来加速用户偏好学习。我们引入了一种名为Expert with Clustering (EWC)的分层上下文Bandit框架，它集成了聚类技术和专家建议的预测。EWC有效地利用分层用户信息，并结合了一种新颖的损失引导距离度量。该度量在生成更具代表性的聚类中心方面起着关键作用。在每个用户$T$轮，$N$用户和$K$选项的推荐场景中，我们的算法根据用户的实时反馈来在线学习和改进推荐。

    Emerging mobility systems are increasingly capable of recommending options to mobility users, to guide them towards personalized yet sustainable system outcomes. Even more so than the typical recommendation system, it is crucial to minimize regret, because 1) the mobility options directly affect the lives of the users, and 2) the system sustainability relies on sufficient user participation. In this study, we consider accelerating user preference learning by exploiting a low-dimensional latent space that captures the mobility preferences of users. We introduce a hierarchical contextual bandit framework named Expert with Clustering (EWC), which integrates clustering techniques and prediction with expert advice. EWC efficiently utilizes hierarchical user information and incorporates a novel Loss-guided Distance metric. This metric is instrumental in generating more representative cluster centroids. In a recommendation scenario with $N$ users, $T$ rounds per user, and $K$ options, our alg
    
[^62]: 温度对Softmax高斯混合专家是否具有采样效率？

    Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?. (arXiv:2401.13875v1 [stat.ML])

    [http://arxiv.org/abs/2401.13875](http://arxiv.org/abs/2401.13875)

    本文研究了温度对Softmax高斯混合专家的采样效率的影响，证明了由于温度和其他模型参数之间的相互作用，参数估计的收敛速度较慢，并且可能很慢。

    

    最近，密集-稀疏门控专家混合模型（MoE）已成为广为使用的稀疏MoE的有效替代方案。与后者模型中固定激活的专家数量不同，前者模型利用温度来控制softmax权重分布和MoE的稀疏性，在训练过程中稳定专家的专业化。然而，尽管以前有尝试从理论上理解稀疏MoE的方法，对于密集到稀疏门控MoE的全面分析仍然困难重重。因此，本文旨在探讨密集到稀疏门控对Gaussian MoE下的最大似然估计的影响。我们证明由于温度和其他模型参数之间通过一些偏微分方程的相互作用，参数估计的收敛速度比任何多项式速率都要慢，并且可能慢到$\mathcal{

    Dense-to-sparse gating mixture of experts (MoE) has recently become an effective alternative to a well-known sparse MoE. Rather than fixing the number of activated experts as in the latter model, which could limit the investigation of potential experts, the former model utilizes the temperature to control the softmax weight distribution and the sparsity of the MoE during training in order to stabilize the expert specialization. Nevertheless, while there are previous attempts to theoretically comprehend the sparse MoE, a comprehensive analysis of the dense-to-sparse gating MoE has remained elusive. Therefore, we aim to explore the impacts of the dense-to-sparse gate on the maximum likelihood estimation under the Gaussian MoE in this paper. We demonstrate that due to interactions between the temperature and other model parameters via some partial differential equations, the convergence rates of parameter estimations are slower than any polynomial rates, and could be as slow as $\mathcal{
    
[^63]: 重新审视轮廓系数：从微观到宏观聚合。

    Revisiting Silhouette: From Micro to Macro Aggregation. (arXiv:2401.05831v1 [cs.LG])

    [http://arxiv.org/abs/2401.05831](http://arxiv.org/abs/2401.05831)

    本文提出了一种新的聚合策略，用于评估聚类质量。通过对聚类级别的轮廓得分进行平均，并在此基础上对所有聚类的得分进行宏观平均，我们提出的宏观平均轮廓得分对于聚类不均衡和背景噪声是稳健的。

    

    轮廓系数是一种常用的内部聚类评估指标，它会为每个数据点产生一个得分，用于评估其聚类分配的质量。目前，为了评估整个数据集的聚类质量，通常会将数据集中所有点的得分平均成一个单一值，这个策略被称为微观平均。然而我们在本文中通过使用一个合成例子展示了，该微观平均策略对于聚类不均衡和异常值（背景噪声）非常敏感。为了解决这些问题，我们提出了一种替代聚合策略，该策略首先对聚类级别的轮廓得分进行平均，然后再对所有聚类的得分进行宏观平均。基于相同的合成例子，我们展示了提出的宏观平均轮廓得分对于聚类不均衡和背景噪声是稳健的。我们进行了实验研究，结果表明我们提出的宏观平均变体可以更好地估计真实的聚类数量。

    Silhouette coefficient is an established internal clustering evaluation measure that produces a score per data point, assessing the quality of its clustering assignment. To assess the quality of the clustering of the whole dataset, the scores of all the points in the dataset are typically averaged into a single value, a strategy which we call as micro-averaging. As we illustrate in this work, by using a synthetic example, this micro-averaging strategy is sensitive both to cluster imbalance and outliers (background noise). To address these issues, we propose an alternative aggregation strategy, which first averages the silhouette scores at a cluster level and then (macro) averages the scores across the clusters. Based on the same synthetic example, we show that the proposed macro-averaged silhouette score is robust to cluster imbalance and background noise. We have conducted an experimental study showing that our macro-averaged variant provides better estimates of the ground truth numbe
    
[^64]: AST-T5：面向代码生成和理解的结构感知预训练模型

    AST-T5: Structure-Aware Pretraining for Code Generation and Understanding. (arXiv:2401.03003v1 [cs.SE])

    [http://arxiv.org/abs/2401.03003](http://arxiv.org/abs/2401.03003)

    AST-T5是一种结构感知的预训练模型，通过利用抽象语法树（AST）来增强代码生成、转换和理解的能力。它优于其他同等大小的语言模型，并在代码到代码任务中表现出色。

    

    大型语言模型在代码相关任务中取得了显著进展，然而许多模型将代码视为简单序列，忽略了其结构化特性。我们引入了AST-T5，一种新颖的预训练范式，利用抽象语法树（AST）增强了代码生成、转换和理解。通过动态规划，我们的AST感知分割保留了代码结构，而AST感知跨度破坏目标使模型能够重建各种代码结构。与其他模型不同，AST-T5避免了复杂的程序分析或架构更改，因此可以与任何编码器-解码器Transformer无缝集成。评估结果显示，AST-T5在各种代码相关任务中始终优于同等大小的语言模型。结构感知使得AST-T5在代码到代码任务中特别强大，在Bugs2Fix任务的精确匹配得分上超过CodeT5 2个点，并在CodeXGLUE中的Java-C#转换任务的精确匹配得分上超过CodeT5 3个点。

    Large language models (LLMs) have made significant advancements in code-related tasks, yet many LLMs treat code as simple sequences, neglecting its structured nature. We introduce AST-T5, a novel pretraining paradigm that leverages the Abstract Syntax Tree (AST) for enhanced code generation, transpilation, and understanding. Using dynamic programming, our AST-Aware Segmentation retains code structure, while our AST-Aware Span Corruption objective equips the model to reconstruct various code structures. Unlike other models, AST-T5 avoids intricate program analyses or architectural changes, so it integrates seamlessly with any encoder-decoder Transformer. Evaluations show that AST-T5 consistently outperforms similar-sized LMs across various code-related tasks. Structure-awareness makes AST-T5 particularly powerful in code-to-code tasks, surpassing CodeT5 by 2 points in exact match score for the Bugs2Fix task and by 3 points in exact match score for Java-C# Transpilation in CodeXGLUE. Our
    
[^65]: Graph2Tac: 在定理证明中学习数学概念的分层表示

    Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving. (arXiv:2401.02949v1 [cs.LG])

    [http://arxiv.org/abs/2401.02949](http://arxiv.org/abs/2401.02949)

    本文提出了一种名为Graph2Tac的图神经网络模型，用于在定理证明中学习数学概念的分层表示。该模型能够动态地将新的数学概念纳入到知识库中，并在Coq证明助手中进行训练和应用。

    

    数学及其应用中存在大量的概念。它们在不同的学科领域中有很大的变化，并且每篇数学论文或应用中都会引入新的概念。形式化理论建立了一个层次结构，其中包括了定义、定理和相互引用的证明。当一个AI代理人证明一个新的定理时，大多数与该定理相关的数学概念和引理在训练过程中可能从未被见过。这在Coq证明助手中尤为明显，该助手拥有各种各样的Coq项目，每个项目都有自己的定义、引理，甚至用于证明这些引理的自定义策略过程。将这样的新信息即时地融入到代理人的知识库中对于代理人至关重要。我们通过利用一个新的、大规模的、基于图的数据集，在Coq中进行机器学习。我们利用Coq术语的忠实图表示，创建了一种新颖的图神经网络Graph2Tac，该网络通过定义之间的依赖关系创建了一个有向图。

    Concepts abound in mathematics and its applications. They vary greatly between subject areas, and new ones are introduced in each mathematical paper or application. A formal theory builds a hierarchy of definitions, theorems and proofs that reference each other. When an AI agent is proving a new theorem, most of the mathematical concepts and lemmas relevant to that theorem may have never been seen during training. This is especially true in the Coq proof assistant, which has a diverse library of Coq projects, each with its own definitions, lemmas, and even custom tactic procedures used to prove those lemmas. It is essential for agents to incorporate such new information into their knowledge base on the fly. We work towards this goal by utilizing a new, large-scale, graph-based dataset for machine learning in Coq. We leverage a faithful graph-representation of Coq terms that induces a directed graph of dependencies between definitions to create a novel graph neural network, Graph2Tac (G
    
[^66]: 生成分数阶扩散模型

    Generative Fractional Diffusion Models. (arXiv:2310.17638v1 [cs.LG])

    [http://arxiv.org/abs/2310.17638](http://arxiv.org/abs/2310.17638)

    该论文提出了一种基于分数阶扩散模型的生成模型，其中通过将分数布朗运动表示为奥恩斯坦-乌伦贝克过程的随机积分，实现了驱动噪声收敛到非马尔可夫过程的效果。这是第一个在具有无限二次变差的随机过程上构建生成模型的尝试。

    

    我们将基于分数布朗运动（FBM）的连续时间框架推广到基于分数布朗运动的近似形式。我们通过将FBM表示为家族奥恩斯坦-乌伦贝克过程的随机积分，推导出连续再参数化技巧和逆时模型，定义了具有驱动噪声收敛到无限二次变差的非马尔可夫过程的生成分数阶扩散模型（GFDM）。FBM的赫斯特指数$H \in (0,1)$ 可以控制路径变换分布的粗糙度。据我们所知，这是第一次尝试在具有无限二次变差的随机过程上建立生成模型。

    We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM) to an approximation of fractional Brownian motion (FBM). We derive a continuous reparameterization trick and the reverse time model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation. The Hurst index $H\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path. To the best of our knowledge, this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.
    
[^67]: 一种Softmax Gating Multinomial Logistic Mixture of Experts的通用理论

    A General Theory for Softmax Gating Multinomial Logistic Mixture of Experts. (arXiv:2310.14188v1 [stat.ML])

    [http://arxiv.org/abs/2310.14188](http://arxiv.org/abs/2310.14188)

    该论文提出了一种通用理论，用于研究Softmax Gating Multinomial Logistic Mixture of Experts模型。通过建立模型的收敛速度，揭示了softmax gating和专家函数之间存在的互作用，同时提出了一种修改后的softmax gating函数。

    

    Mixture-of-experts（MoE）模型通过门控函数将多个子模型的能力结合起来，在许多回归和分类应用中实现更好的性能。从理论上讲，虽然之前已经尝试通过高斯MoE模型中最大似然估计的收敛性分析来理解该模型在回归设置下的行为，但在分类问题的设置下缺乏相关分析。我们通过建立softmax gating multinomial logistic MoE模型的密度估计和参数估计的收敛速度来弥补这一空白。值得注意的是，当部分专家参数消失时，由于softmax gating和专家函数之间存在固有的偏微分方程互作用，这些收敛速度比多项式速度更慢。为了解决这个问题，我们提出使用一种新颖的修改softmax gating函数。

    Mixture-of-experts (MoE) model incorporates the power of multiple submodels via gating functions to achieve greater performance in numerous regression and classification applications. From a theoretical perspective, while there have been previous attempts to comprehend the behavior of that model under the regression settings through the convergence analysis of maximum likelihood estimation in the Gaussian MoE model, such analysis under the setting of a classification problem has remained missing in the literature. We close this gap by establishing the convergence rates of density estimation and parameter estimation in the softmax gating multinomial logistic MoE model. Notably, when part of the expert parameters vanish, these rates are shown to be slower than polynomial rates owing to an inherent interaction between the softmax gating and expert functions via partial differential equations. To address this issue, we propose using a novel class of modified softmax gating functions which 
    
[^68]: 在多臂赌博机中以固定置信度进行最优臂识别

    Optimal Best Arm Identification with Fixed Confidence in Restless Bandits. (arXiv:2310.13393v1 [stat.ML])

    [http://arxiv.org/abs/2310.13393](http://arxiv.org/abs/2310.13393)

    在多臂赌博机中，我们研究了以固定置信度进行最优臂识别。我们提出了一种新的策略来识别具有最大平均值的臂，同时限制了决策错误的概率，并建立了停止时间增长率的下界。

    

    我们研究了在具有有限数目臂的多臂赌博机中以不断变化的形式进行最优臂识别。每个臂产生的离散时间数据形成了一个取值在共同、有限状态空间中的同质马尔可夫链。每个臂的状态转移由一个遵循单参数指数族的转移概率矩阵（TPM）捕获。每个臂的TPM的实值参数是未知的，属于给定空间。给定在臂的共同状态空间上定义的函数f，目标是在样本数最少的情况下识别最优臂，即在该臂的稳态分布下评估f的平均值最大的臂，同时满足对决策错误概率（即固定置信度区间）的上界。在渐进性的误差概率趋于零的情况下，建立了期望停止时间增长率的下界。此外，我们提出了一种最优臂识别策略。

    We study best arm identification in a restless multi-armed bandit setting with finitely many arms. The discrete-time data generated by each arm forms a homogeneous Markov chain taking values in a common, finite state space. The state transitions in each arm are captured by an ergodic transition probability matrix (TPM) that is a member of a single-parameter exponential family of TPMs. The real-valued parameters of the arm TPMs are unknown and belong to a given space. Given a function $f$ defined on the common state space of the arms, the goal is to identify the best arm -- the arm with the largest average value of $f$ evaluated under the arm's stationary distribution -- with the fewest number of samples, subject to an upper bound on the decision's error probability (i.e., the fixed-confidence regime). A lower bound on the growth rate of the expected stopping time is established in the asymptote of a vanishing error probability. Furthermore, a policy for best arm identification is propo
    
[^69]: 从时间序列数据中发现混合结构因果模型

    Discovering Mixtures of Structural Causal Models from Time Series Data. (arXiv:2310.06312v1 [cs.LG])

    [http://arxiv.org/abs/2310.06312](http://arxiv.org/abs/2310.06312)

    这项研究提出了一种从时间序列数据中发现混合结构因果模型的方法，通过推断潜在因果模型以及每个样本属于特定混合成分的概率，通过实验证明了该方法在因果发现任务中的优越性。

    

    在金融、气候科学和神经科学等领域，从时间序列数据中推断因果关系是一个巨大的挑战。尽管现代技术可以处理变量之间的非线性关系和灵活的噪声分布，但它们依赖于简化假设，即数据来自相同的潜在因果模型。在这项工作中，我们放松了这个假设，从来源于不同因果模型混合的时间序列数据中进行因果发现。我们推断了潜在的结构性因果模型，以及每个样本属于特定混合成分的后验概率。我们的方法采用了一个端对端的训练过程，最大化了数据似然的证据下界。通过对合成和真实世界数据集的广泛实验，我们证明了我们的方法在因果发现任务中超越了最先进的基准方法，尤其是当数据来自不同的潜在因果模型时。

    In fields such as finance, climate science, and neuroscience, inferring causal relationships from time series data poses a formidable challenge. While contemporary techniques can handle nonlinear relationships between variables and flexible noise distributions, they rely on the simplifying assumption that data originates from the same underlying causal model. In this work, we relax this assumption and perform causal discovery from time series data originating from mixtures of different causal models. We infer both the underlying structural causal models and the posterior probability for each sample belonging to a specific mixture component. Our approach employs an end-to-end training process that maximizes an evidence-lower bound for data likelihood. Through extensive experimentation on both synthetic and real-world datasets, we demonstrate that our method surpasses state-of-the-art benchmarks in causal discovery tasks, particularly when the data emanates from diverse underlying causal
    
[^70]: 使用您的本能：使用神经探测器与转换器进行指令优化

    Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers. (arXiv:2310.02905v1 [cs.LG])

    [http://arxiv.org/abs/2310.02905](http://arxiv.org/abs/2310.02905)

    该论文提出了一种使用神经探测器和转换器优化指令的方法，以提高大型语言模型的性能。

    

    大型语言模型(LLMs)在各种应用中展示了出色的指令跟随能力，并取得了令人瞩目的表现。然而，LLMs的性能严重依赖于给予它们的指令，这些指令通常需要大量人力进行手动调整。最近的研究使用了高效的贝叶斯优化（BO）算法来自动优化给予黑盒LLMs的指令。然而，在优化高度复杂（例如高维）的目标函数时，如将指令映射到LLM性能的函数，BO通常表现不佳。这主要是由于BO使用的高斯过程（GP）模型的表达能力有限，该模型被用作BO的代理来建模目标函数。与此同时，已经多次证明神经网络（NNs），尤其是预训练的转换器，具有很强的表达能力，可以建模高度复杂的函数。因此，我们采用了一种神经探测器算法。

    Large language models (LLMs) have shown remarkable instruction-following capabilities and achieved impressive performances in various applications. However, the performances of LLMs depend heavily on the instructions given to them, which are typically manually tuned with substantial human efforts. Recent work has used the query-efficient Bayesian optimization (BO) algorithm to automatically optimize the instructions given to black-box LLMs. However, BO usually falls short when optimizing highly sophisticated (e.g., high-dimensional) objective functions, such as the functions mapping an instruction to the performance of an LLM. This is mainly due to the limited expressive power of the Gaussian process (GP) model which is used by BO as a surrogate to model the objective function. Meanwhile, it has been repeatedly shown that neural networks (NNs), especially pre-trained transformers, possess strong expressive power and can model highly complex functions. So, we adopt a neural bandit algor
    
[^71]: 改进可验证稳健性的方法：容量和数据的配方

    A Recipe for Improved Certifiable Robustness: Capacity and Data. (arXiv:2310.02513v1 [cs.LG])

    [http://arxiv.org/abs/2310.02513](http://arxiv.org/abs/2310.02513)

    在本研究中，我们通过使用一系列新技术、设计优化和综合以前的研究，更全面地评估了基于Lipschitz的认证方法的潜力，并显著提高了状...

    

    理论和实践都支持一个关键挑战，即稳健性要求比标准训练更大的网络容量和更多的数据。然而，在严格的Lipschitz约束下有效地增加容量比看起来更困难，这表明现有的方法更倾向于低拟合而不是过拟合。此外，我们主张对基于Lipshitz的方法的设计空间进行仔细探索不足，这会导致潜在的性能提升被忽视。在这项工作中，我们通过使用一系列新技术、设计优化和综合以前的研究，更全面地评估Lipschitz-based认证方法的潜力。我们能够显著提高确定性认证在各种基准数据集上的“验证稳健准确性”（VRA），并覆盖一系列扰动大小。特别值得注意的是，我们发现...

    A key challenge, supported both theoretically and empirically, is that robustness demands greater network capacity and more data than standard training. However, effectively adding capacity under stringent Lipschitz constraints has proven more difficult than it may seem, evident by the fact that state-of-the-art approach tend more towards \emph{underfitting} than overfitting. Moreover, we posit that a lack of careful exploration of the design space for Lipshitz-based approaches has left potential performance gains on the table. In this work, we provide a more comprehensive evaluation to better uncover the potential of Lipschitz-based certification methods. Using a combination of novel techniques, design optimizations, and synthesis of prior work, we are able to significantly improve the state-of-the-art \emph{verified robust accuracy} (VRA) for deterministic certification on a variety of benchmark datasets, and over a range of perturbation sizes. Of particular note, we discover that th
    
[^72]: 用联合嵌入预测架构进行图级表示学习

    Graph-level Representation Learning with Joint-Embedding Predictive Architectures. (arXiv:2309.16014v1 [cs.LG])

    [http://arxiv.org/abs/2309.16014](http://arxiv.org/abs/2309.16014)

    本文提出了一种用于图级表示学习的联合嵌入预测架构（JEPA），通过预测输入图的不同子图的潜在表示在2维单位双曲线上的坐标，实现了对图级表示的有效建模。

    

    联合嵌入预测架构（JEPAs）作为一种新颖而强大的自监督表示学习技术最近出现。它们旨在通过从上下文信号x中预测目标信号y的潜在表示来学习基于能量的模型。JEPAs绕过了对数据增强和负样本的需求，这通常是对比学习所要求的，同时避免了与生成式预训练相关的过拟合问题。在本文中，我们展示了该范式可以有效地对图级表示进行建模，并提出了Graph-JEPA，这是图领域的第一个JEPA。特别是，我们采用掩码建模的方式来学习输入图的不同子图的嵌入。为了赋予表示隐含的层次结构，我们设计了一种替代性的训练目标，该目标是预测编码子图在2维单位双曲线上的坐标。

    Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a novel and powerful technique for self-supervised representation learning. They aim to learn an energy-based model by predicting the latent representation of a target signal $y$ from a context signal $x$. JEPAs bypass the need for data augmentation and negative samples, which are typically required by contrastive learning, while avoiding the overfitting issues associated with generative-based pretraining. In this paper, we show that graph-level representations can be effectively modeled using this paradigm and propose Graph-JEPA, the first JEPA for the graph domain. In particular, we employ masked modeling to learn embeddings for different subgraphs of the input graph. To endow the representations with the implicit hierarchy that is often present in graph-level concepts, we devise an alternative training objective that consists of predicting the coordinates of the encoded subgraphs on the unit hyperbola in the 2
    
[^73]: Detach-ROCKET: 基于随机卷积核的时间序列分类中的顺序特征选择

    Detach-ROCKET: Sequential feature selection for time series classification with random convolutional kernels. (arXiv:2309.14518v1 [cs.LG])

    [http://arxiv.org/abs/2309.14518](http://arxiv.org/abs/2309.14518)

    本文提出了一种名为Detach-ROCKET的方法，用于时间序列分类中的顺序特征选择。通过利用随机卷积核模型中的大量特征，并使用顺序特征分离方法剪枝非主要特征，提高了模型的可扩展性和泛化能力。

    

    时间序列分类在许多领域中都是必不可少的，如医学、金融、环境科学和制造业，可以实现疾病诊断、异常检测和股价预测等任务。尽管循环神经网络和InceptionTime等机器学习模型在许多应用中取得了成功，但由于训练需求的繁重，可能会面临可扩展性限制。为了解决这个问题，出现了Rocket及其衍生模型等随机卷积核模型，通过利用从时间序列数据中随机生成的大量特征，简化训练并实现最先进的性能。然而，由于其随机性质，生成的大部分特征是冗余或非信息性的，增加了不必要的计算负载并损害了泛化能力。在这里，我们引入了顺序特征分离（SFD）作为一种识别和修剪这些非主要特征的方法。SFD利用模型系数来估计特征的重要性。

    Time series classification is essential in many fields, such as medicine, finance, environmental science, and manufacturing, enabling tasks like disease diagnosis, anomaly detection, and stock price prediction. Machine learning models like Recurrent Neural Networks and InceptionTime, while successful in numerous applications, can face scalability limitations due to intensive training requirements. To address this, random convolutional kernel models such as Rocket and its derivatives have emerged, simplifying training and achieving state-of-the-art performance by utilizing a large number of randomly generated features from time series data. However, due to their random nature, most of the generated features are redundant or non-informative, adding unnecessary computational load and compromising generalization. Here, we introduce Sequential Feature Detachment (SFD) as a method to identify and prune these non-essential features. SFD uses model coefficients to estimate feature importance a
    
[^74]: GAMIX-VAE: 一种基于高斯混合后验的VAE

    GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior. (arXiv:2309.13160v1 [cs.LG])

    [http://arxiv.org/abs/2309.13160](http://arxiv.org/abs/2309.13160)

    本文提出了一种基于高斯混合后验的VAE方法，重新定义了ELBO，引入正则化项和PatchGAN鉴别器，能够生成逼真的人脸。

    

    变分自动编码器（VAEs）已成为机器学习中生成建模和表示学习的基石。本文探讨了VAEs的一个细微方面，重点是解释KL Divergence，这是Evidence Lower Bound（ELBO）中的关键组成部分，它控制了重构准确性和正则化之间的权衡。虽然KL Divergence让潜变量分布与先验分布对齐，给整个潜空间加上结构约束，但却不限制各个变量分布。所提出的方法重新定义了带有高斯混合的后验概率的ELBO，引入了正则化项以防止方差崩溃，并使用PatchGAN鉴别器来增强纹理逼真度。实现细节涉及Encoder和Decoder的ResNetV2架构。实验证明了生成逼真的人脸的能力，为提供了一个有希望的解决方案。

    Variational Autoencoders (VAEs) have become a cornerstone in generative modeling and representation learning within machine learning. This paper explores a nuanced aspect of VAEs, focusing on interpreting the Kullback Leibler (KL) Divergence, a critical component within the Evidence Lower Bound (ELBO) that governs the trade-off between reconstruction accuracy and regularization. While the KL Divergence enforces alignment between latent variable distributions and a prior imposing a structure on the overall latent space but leaves individual variable distributions unconstrained. The proposed method redefines the ELBO with a mixture of Gaussians for the posterior probability, introduces a regularization term to prevent variance collapse, and employs a PatchGAN discriminator to enhance texture realism. Implementation details involve ResNetV2 architectures for both the Encoder and Decoder. The experiments demonstrate the ability to generate realistic faces, offering a promising solution for
    
[^75]: ReConcile：圆桌会议通过多元LLM的共识改进推理能力

    ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs. (arXiv:2309.13007v1 [cs.CL])

    [http://arxiv.org/abs/2309.13007](http://arxiv.org/abs/2309.13007)

    ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。

    

    大型语言模型（LLM）仍然在复杂的推理任务上遇到困难。受到心智社会理论（Minsky, 1988）的启发，我们提出了ReConcile，这是一个多模型多代理的框架，旨在通过多样的LLM代理人之间的圆桌会议来促进多样的思想和讨论，从而改进一致性。ReConcile通过进行多轮讨论、学习说服其他代理人改进答案以及采用置信度加权投票机制来增强LLM的推理能力。在每一轮中，ReConcile通过“讨论提示”来启动代理人间的讨论，其中包括上一轮每个代理人生成的答案和解释的分组、它们的不确定性以及用于说服其他代理人的答案修正人类解释的演示。这个讨论提示使每个代理人能够根据其他代理人的见解修订自己的回答。一旦达成一致并结束讨论，ReConcile执行一次全体投票以确定最终答案。

    Large Language Models (LLMs) still struggle with complex reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents to foster diverse thoughts and discussion for improved consensus. ReConcile enhances the reasoning capabilities of LLMs by holding multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their uncertainties, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. This discussion prompt enables each agent to revise their responses in light of insights from other agents. Once a consensus is reached and the discussion ends, ReConcil
    
[^76]: LMDX：基于语言模型的文档信息提取与定位

    LMDX: Language Model-based Document Information Extraction and Localization. (arXiv:2309.10952v1 [cs.CL])

    [http://arxiv.org/abs/2309.10952](http://arxiv.org/abs/2309.10952)

    LMDX是一种基于语言模型的文档信息提取与定位方法，克服了布局编码和答案虚构的困难，能够在半结构化文档中提取关键实体。

    

    大规模语言模型（LLM）在自然语言处理（NLP）中取得了革命性的进展，改进了许多现有任务的最新技术，并展示了新兴的能力。然而，LLM尚未成功应用于半结构化文档信息提取，这是许多文档处理工作流的核心，包括从视觉丰富的文档（VRD）中提取关键实体，给定预定义的目标模式。LLM在这个任务中的主要障碍是LLM中缺乏布局编码，这对于高质量的提取至关重要，以及缺乏一个基于理论的机制，确保答案不是虚构的。在本文中，我们介绍了一种基于语言模型的文档信息提取与定位（LMDX）的方法，用于将任意LLM适应文档信息提取。LMDX可以提取单一、重复和层次结构实体，无论是否有训练数据，并提供基于理论的保证。

    Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art on many existing tasks and exhibiting emergent capabilities. However, LLMs have not yet been successfully applied on semi-structured document information extraction, which is at the core of many document processing workflows and consists of extracting key entities from a visually rich document (VRD) given a predefined target schema. The main obstacles to LLM adoption in that task have been the absence of layout encoding within LLMs, critical for a high quality extraction, and the lack of a grounding mechanism ensuring the answer is not hallucinated. In this paper, we introduce Language Model-based Document Information Extraction and Localization (LMDX), a methodology to adapt arbitrary LLMs for document information extraction. LMDX can do extraction of singular, repeated, and hierarchical entities, both with and without training data, while providing grounding guarantees and lo
    
[^77]: 火星质子极光的可解释深度学习模型

    An Explainable Deep-learning Model of Proton Auroras on Mars. (arXiv:2309.08195v1 [astro-ph.EP])

    [http://arxiv.org/abs/2309.08195](http://arxiv.org/abs/2309.08195)

    这项研究开发了一个纯数据驱动模型，使用火星大气和挥发物演化 (MAVEN) 的观测资料，来解释火星质子极光。通过训练人工神经网络，可以准确重现每个Ly alpha辐射的强度，并对观测结果进行忠实重构。

    

    火星白天侧广泛观察到质子极光，被认为是氢 Ly alpha (121.6 nm) 辐射在120至150公里高度之间的显著增强。太阳风质子作为高能中性原子穿过火星热层进入大气层，被认为是质子极光的原因。因此，理解质子极光对于描绘太阳风与火星大气相互作用至关重要。最近观测到局部"斑块状"质子极光，暗示在不稳定的太阳风条件下，质子可能直接沉积到火星大气中。在这里，我们利用火星大气和挥发物演化 (MAVEN) 非现场观测和边缘扫描的 Ly alpha 辐射资料开发了一个纯数据驱动模型来模拟质子极光。我们训练了一个人工神经网络，可以以0.95的Pearson相关性重现每个Ly alpha辐射的强度，并对观测结果进行忠实重构。

    Proton auroras are widely observed on the day side of Mars, identified as a significant intensity enhancement in the hydrogen Ly alpha (121.6 nm) emission between 120 and 150~km altitudes. Solar wind protons penetrating as energetic neutral atoms into the Martian thermosphere are thought to be responsible for these auroras. Understanding proton auroras is therefore important for characterizing the solar wind interaction with the atmosphere of Mars. Recent observations of spatially localized "patchy" proton auroras suggest a possible direct deposition of protons into the atmosphere of Mars during unstable solar wind conditions. Here, we develop a purely data-driven model of proton auroras using Mars Atmosphere and Volatile EvolutioN (MAVEN) in situ observations and limb scans of Ly alpha emissions between 2014 and 2022. We train an artificial neural network that reproduces individual Ly alpha intensities with a Pearson correlation of 0.95 along with a faithful reconstruction of the obse
    
[^78]: 改进具有硬约束的物理信息DeepONets

    Improving physics-informed DeepONets with hard constraints. (arXiv:2309.07899v1 [cs.LG])

    [http://arxiv.org/abs/2309.07899](http://arxiv.org/abs/2309.07899)

    本研究提出了一种改进的物理信息深度学习策略，消除了对初始条件的学习需求，并确保在多次应用时得到的函数是连续的。

    

    当前的物理信息神经网络（标准或操作符）仍然依赖于准确地学习所解决系统的初始条件。相比之下，标准的数值方法在不需要学习这些条件的情况下演化这些初始条件。在这项研究中，我们提出改进当前的物理信息深度学习策略，使得不需要学习初始条件，并且将其准确地表示在预测的解中。此外，该方法保证当将DeepONet多次应用于时间步长解上时，得到的函数是连续的。

    Current physics-informed (standard or operator) neural networks still rely on accurately learning the initial conditions of the system they are solving. In contrast, standard numerical methods evolve such initial conditions without needing to learn these. In this study, we propose to improve current physics-informed deep learning strategies such that initial conditions do not need to be learned and are represented exactly in the predicted solution. Moreover, this method guarantees that when a DeepONet is applied multiple times to time step a solution, the resulting function is continuous.
    
[^79]: 使用物理信息神经网络识别复杂超弹性固体的组分参数

    Identifying Constitutive Parameters for Complex Hyperelastic Solids using Physics-Informed Neural Networks. (arXiv:2308.15640v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2308.15640](http://arxiv.org/abs/2308.15640)

    本文介绍了一种基于物理信息神经网络（PINNs）的新框架，用于识别软材料在大变形平面应力条件下具有复杂组分行为的材料的组分参数。通过使用多模态的时间相关实验数据训练，我们的模型能够稳健地准确识别不可压缩Arruda-Boyce模型的组分参数。

    

    在工程和生物材料中，特别是那些具有复杂几何和机械行为的材料中，识别组分参数仍然是一个长期存在的挑战。最近出现的物理信息神经网络（PINNs）为此提供了有希望的解决方案，但当前的框架通常仅限于基本的组分定律，并在与实验数据相结合时遇到实际约束。本文引入了一种新的基于PINN的框架，旨在识别软材料的材料参数，特别是那些在平面应力条件下呈现复杂组分行为的材料。该模型强调用多模态的时间相关实验数据训练PINN，其中包括全场变形和加载历史，以确保算法在嘈杂数据中仍然稳健。我们的结果表明，我们的框架可以准确识别不可压缩Arruda-Boyce模型的组分参数。

    Identifying constitutive parameters in engineering and biological materials, particularly those with intricate geometries and mechanical behaviors, remains a longstanding challenge. The recent advent of Physics-Informed Neural Networks (PINNs) offers promising solutions, but current frameworks are often limited to basic constitutive laws and encounter practical constraints when combined with experimental data. In this paper, we introduce a new PINN-based framework designed to identify material parameters for soft materials, specifically those exhibiting complex constitutive behaviors, under large deformation in plane stress conditions. Distinctively, our model emphasizes training PINNs with multi-modal time-dependent experimental datasets consisting of full-field deformation and loading history, ensuring algorithm robustness even amidst noisy data. Our results reveal that our framework can accurately identify constitutive parameters of the incompressible Arruda-Boyce model for samples 
    
[^80]: 非欧几里得随机森林

    Hyperbolic Random Forests. (arXiv:2308.13279v1 [cs.LG])

    [http://arxiv.org/abs/2308.13279](http://arxiv.org/abs/2308.13279)

    该论文提出了一种在非欧几里得空间中将随机森林推广的方法，并使用水平球重新定义了分割的概念。为了处理多类数据和不平衡实验，论文还提出了一种新的类组合方法。

    

    非欧几里得空间由于许多现实世界数据集的分层结构（无论是隐式还是显式）而成为表示数据的流行选择。随之而来的是需要能够在非欧几里得空间中解决分类等基本任务的算法。最近，有多篇论文研究了非欧几里得空间中基于超平面的分类器（如逻辑回归和支持向量机）的替代方法。虽然有效，但这些方法在处理更复杂的分层数据时存在困难。因此，我们提出将众所周知的随机森林推广到非欧几里得空间。我们通过使用水平球重新定义了分割的概念来实现这一点。由于找到全局最优分割是计算上难以处理的，我们通过一个大边界分类器找到候选的水平球。为了使非欧几里得随机森林适用于多类数据和不平衡实验，我们还概述了一种基于它们的最低公共祖先和类平衡的类组合方法。

    Hyperbolic space is becoming a popular choice for representing data due to the hierarchical structure - whether implicit or explicit - of many real-world datasets. Along with it comes a need for algorithms capable of solving fundamental tasks, such as classification, in hyperbolic space. Recently, multiple papers have investigated hyperbolic alternatives to hyperplane-based classifiers, such as logistic regression and SVMs. While effective, these approaches struggle with more complex hierarchical data. We, therefore, propose to generalize the well-known random forests to hyperbolic space. We do this by redefining the notion of a split using horospheres. Since finding the globally optimal split is computationally intractable, we find candidate horospheres through a large-margin classifier. To make hyperbolic random forests work on multi-class data and imbalanced experiments, we furthermore outline a new method for combining classes based on their lowest common ancestor and a class-balan
    
[^81]: 操作稳定扩散提示的嵌入

    Manipulating Embeddings of Stable Diffusion Prompts. (arXiv:2308.12059v1 [cs.CV])

    [http://arxiv.org/abs/2308.12059](http://arxiv.org/abs/2308.12059)

    本论文提出了一种直接改变提示嵌入的方法，促进了用户对生成图像细粒度和目标化的控制。这种方法将生成模型视为连续函数，并在图像空间和提示嵌入空间之间传递梯度。

    

    生成文本到图像的模型，如稳定扩散，允许用户根据文本描述生成图像。改变提示仍然是用户想要改变生成图像的主要方式。然而，通过重新构思提示来改变图像仍然是一个困难的试错过程，这导致了提示工程作为一个新的研究领域的出现。我们提出并分析了直接改变提示嵌入的方法，而不是提示文本。它允许更精细和有针对性的控制，考虑到用户的意图。我们的方法将生成的文本到图像模型视为一个连续函数，并在图像空间和提示嵌入空间之间传递梯度。通过解决不同的用户交互问题，我们可以在三个场景中应用这个想法：（1）优化图像空间中定义的度量，可以测量图像风格等。（2）帮助用户进行创造性的图像编辑。

    Generative text-to-image models such as Stable Diffusion allow users to generate images based on a textual description, the prompt. Changing the prompt is still the primary means for the user to change a generated image as desired. However, changing the image by reformulating the prompt remains a difficult process of trial and error, which has led to the emergence of prompt engineering as a new field of research. We propose and analyze methods to change the embedding of a prompt directly instead of the prompt text. It allows for more fine-grained and targeted control that takes into account user intentions. Our approach treats the generative text-to-image model as a continuous function and passes gradients between the image space and the prompt embedding space. By addressing different user interaction problems, we can apply this idea in three scenarios: (1) Optimization of a metric defined in image space that could measure, for example, image style. (2) Assistance of users in creative 
    
[^82]: 通过保持排序的干预分布实现因果公平的机器学习

    Causal Fair Machine Learning via Rank-Preserving Interventional Distributions. (arXiv:2307.12797v1 [cs.LG])

    [http://arxiv.org/abs/2307.12797](http://arxiv.org/abs/2307.12797)

    通过保持排序的干预分布，我们提出了一种因果公平的机器学习方法，通过在一个理想的世界中消除受保护属性对目标的因果影响来减少不公平。

    

    如果相同的个体得到相同的对待，而不同的个体得到不同的对待，那么一个决策被定义为公平的。根据这个定义，在设计机器学习模型以减少自动决策系统中的不公平时，必须引入因果思考来引入受保护属性。根据最近的提议，我们将个体定义为在一个假设的、理想的（FiND）世界中是规范上相等的，这个世界中受保护属性对目标没有（直接或间接）的因果影响。我们提出保持排序的干预分布来定义这个FiND世界的估计目标，并提出了一个估计方法。通过模拟和实证数据的验证，我们提供了对方法和生成模型的评价标准。通过这些，我们展示了我们的干预方法有效地识别出最受歧视的个体并减少不公平。

    A decision can be defined as fair if equal individuals are treated equally and unequals unequally. Adopting this definition, the task of designing machine learning models that mitigate unfairness in automated decision-making systems must include causal thinking when introducing protected attributes. Following a recent proposal, we define individuals as being normatively equal if they are equal in a fictitious, normatively desired (FiND) world, where the protected attribute has no (direct or indirect) causal effect on the target. We propose rank-preserving interventional distributions to define an estimand of this FiND world and a warping method for estimation. Evaluation criteria for both the method and resulting model are presented and validated through simulations and empirical data. With this, we show that our warping approach effectively identifies the most discriminated individuals and mitigates unfairness.
    
[^83]: 关于需要描述分布偏移的语言：基于表格数据集的案例分析

    On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets. (arXiv:2307.05284v1 [cs.LG])

    [http://arxiv.org/abs/2307.05284](http://arxiv.org/abs/2307.05284)

    该论文通过对表格数据集中的自然偏移进行研究，发现$Y|X$-偏移最为普遍。为了推动研究人员开发描述数据分布偏移的精细语言，作者构建了WhyShift实验平台，并讨论了$Y|X$-偏移对算法的影响。

    

    不同的分布偏移需要不同的算法和操作干预。方法研究必须以其所涉及的具体偏移为基础。尽管新兴的基准数据为实证研究提供了有希望的基础，但它们隐含地关注协变量偏移，并且实证发现的有效性取决于偏移类型，例如，当$Y|X$分布发生变化时，之前关于算法性能的观察可能无效。我们对5个表格数据集中的自然偏移进行了深入研究，通过对86,000个模型配置进行实验，发现$Y|X$-偏移最为普遍。为了鼓励研究人员开发一种精细的描述数据分布偏移的语言，我们构建了WhyShift，一个由策划的真实世界偏移测试平台，在其中我们对我们基准性能的偏移类型进行了表征。由于$Y|X$-偏移在表格设置中很常见，我们确定了受到最大$Y|X$-偏移影响的协变量区域，并讨论了对算法的影响。

    Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithm
    
[^84]: 来自DESI亮红星系大尺度聚类的局部原初非高斯性翻译标题

    Local primordial non-Gaussianity from the large-scale clustering of photometric DESI luminous red galaxies. (arXiv:2307.01753v1 [astro-ph.CO])

    [http://arxiv.org/abs/2307.01753](http://arxiv.org/abs/2307.01753)

    本研究利用DESI成像调查的亮红星系的角聚类信息限制了局部原初非高斯性参数fNL，发现在假设宇宙规律性关系的情况下，fNL为47^{+14(+29)}_{-11(-22)}，使用更积极的处理方法后，最大似然值略微偏离fNL≈5。

    

    我们使用来自Dark Energy Spectroscopic Instrument (DESI)成像调查的亮红星系的角聚类信息来限制局部原初非高斯性参数fNL。我们的样本包括超过1200万个目标，覆盖了14000平方度的天空区域，红移范围为0.2 < z < 1.35。我们确定了银河消光、调查深度和观测条件是系统误差的主要来源，并采用线性回归和人工神经网络来减轻大尺度上的非宇宙学过度聚类。我们的方法经过了包含和不包含fNL和系统误差的对数正态模拟的测试，结果显示了神经网络处理在减小剩余系统误差方面的卓越性能。在假设宇宙规律性关系的情况下，我们发现fNL的68\%（95\%）置信区间为fNL = 47^{+14(+29)}_{-11(-22)}。通过更积极的处理方法，包括对所有成像图集进行回归，我们的最大似然值略微偏离fNL≈5。

    We use angular clustering of luminous red galaxies from the Dark Energy Spectroscopic Instrument (DESI) imaging surveys to constrain the local primordial non-Gaussianity parameter fNL. Our sample comprises over 12 million targets, covering 14,000 square degrees of the sky, with redshifts in the range 0.2< z < 1.35. We identify Galactic extinction, survey depth, and astronomical seeing as the primary sources of systematic error, and employ linear regression and artificial neural networks to alleviate non-cosmological excess clustering on large scales. Our methods are tested against log-normal simulations with and without fNL and systematics, showing superior performance of the neural network treatment in reducing remaining systematics. Assuming the universality relation, we find fNL $= 47^{+14(+29)}_{-11(-22)}$ at 68\%(95\%) confidence. With a more aggressive treatment, including regression against the full set of imaging maps, our maximum likelihood value shifts slightly to fNL$ \sim 5
    
[^85]: 基于优化和数据驱动的 sigma-point 卡尔曼滤波器与非线性未知输入估计器

    Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via Optimization and Data-driven Approach for Dynamic Systems. (arXiv:2306.12361v1 [eess.SY])

    [http://arxiv.org/abs/2306.12361](http://arxiv.org/abs/2306.12361)

    本文提出了一种不需要假设未知输入为线性的方法，结合非线性优化和数据驱动方法可以实现对未知输入的估计，并通过联合 sigma-point 变换方案将状态和未知输入的不确定性纳入估计中，确保其稳定性。这个方法适用于许多智能自主系统。

    

    多数关于状态和未知输入(UI)估计的文献都要求UI是线性的，这个限制可能太严格了，因为它并不适用于许多智能自主系统。为了克服这一限制，我们提出了一种无导数未知输入 Sigma-point 卡尔曼滤波器(SPKE-nUI)，其中 SPKF 与普通非线性 UI 估计器相互连接，可以通过非线性优化和数据驱动方法实现。非线性 UI 估计器使用后验状态估计，这对状态预测误差不太敏感。此外，我们引入了联合 sigma-point 变换方案，将状态和 UI 的不确定性纳入 SPKF-nUI 的估计中。深入的随机稳定性分析证明了在合理的假设下，所提出的 SPKF-nUI 可以产生指数级收敛的估计误差界限。最后，我们在基于模拟的路面车辆控制问题上进行了两个案例研究。

    Most works on joint state and unknown input (UI) estimation require the assumption that the UIs are linear; this is potentially restrictive as it does not hold in many intelligent autonomous systems. To overcome this restriction and circumvent the need to linearize the system, we propose a derivative-free Unknown Input Sigma-point Kalman Filter (SPKF-nUI) where the SPKF is interconnected with a general nonlinear UI estimator that can be implemented via nonlinear optimization and data-driven approaches. The nonlinear UI estimator uses the posterior state estimate which is less susceptible to state prediction error. In addition, we introduce a joint sigma-point transformation scheme to incorporate both the state and UI uncertainties in the estimation of SPKF-nUI. An in-depth stochastic stability analysis proves that the proposed SPKF-nUI yields exponentially converging estimation error bounds under reasonable assumptions. Finally, two case studies are carried out on a simulation-based ri
    
[^86]: 《鼠类与配偶：单一模型自动对群体中的老鼠行为进行分类和建模跨笼》

    Of Mice and Mates: Automated Classification and Modelling of Mouse Behaviour in Groups using a Single Model across Cages. (arXiv:2306.03066v1 [cs.CV])

    [http://arxiv.org/abs/2306.03066](http://arxiv.org/abs/2306.03066)

    本文提供了自动分类和模拟群体老鼠行为的工具，通过单一模型跨笼使用置换矩阵匹配老鼠身份，在家鼠环境下研究老鼠可以捕捉到个体行为的时间因素，而且无需人为干预。

    

    行为实验通常在专门的竞技场中进行，但这可能会混淆分析。为了解决这个问题，我们提供了工具来研究家鼠环境中的老鼠，为生物学家提供了捕捉个体行为的时间因素和模拟最小人为干预下笼友之间互动和相互依赖的可能性。我们开发了“活动标签模块”（ALM）来自动对老鼠行为进行分类，并开发了一种新的“群体行为模型”（GBM）来概括他们在笼子中的联合行为，使用置换矩阵将每个笼子中的老鼠身份与模型匹配。我们还发布了两个数据集，用于训练行为分类器（ABODe）和行为建模（IMADGE）。

    Behavioural experiments often happen in specialised arenas, but this may confound the analysis. To address this issue, we provide tools to study mice in the homecage environment, equipping biologists with the possibility to capture the temporal aspect of the individual's behaviour and model the interaction and interdependence between cage-mates with minimal human intervention. We develop the Activity Labelling Module (ALM) to automatically classify mouse behaviour from video, and a novel Group Behaviour Model (GBM) for summarising their joint behaviour across cages, using a permutation matrix to match the mouse identities in each cage to the model. We also release two datasets, ABODe for training behaviour classifiers and IMADGE for modelling behaviour.
    
[^87]: 学习单调博弈的投石索方法

    A Slingshot Approach to Learning in Monotone Games. (arXiv:2305.16610v1 [cs.GT])

    [http://arxiv.org/abs/2305.16610](http://arxiv.org/abs/2305.16610)

    本文提出了一种新的框架, 通过正则化游戏的支付或效用和更新投石索策略，无论是否存在噪声都能够实现在单调博弈中计算均衡。

    

    本文解决了在单调博弈中计算均衡的问题。传统的遵循正则化领导者算法即使在双人零和游戏中也无法收敛到均衡。虽然已经提出了这些算法的乐观版本并具有最后迭代的收敛保证，但它们需要无噪声的梯度反馈。为了克服这个限制，我们提出了一个新的框架，即使在存在噪声的情况下也能实现最后一次迭代的收敛。我们的关键思想是扰动或正则化游戏的支付或效用。这种扰动有助于将当前策略拉向一个锚定策略，我们称之为“投石索”策略。首先，我们建立了框架的收敛速度，从而获得靠近均衡点的稳定点，无论是否存在噪声。接下来，我们介绍了一种方法，定期更新投石索策略和当前策略。我们将这种方法解释为近端p

    In this paper, we address the problem of computing equilibria in monotone games. The traditional Follow the Regularized Leader algorithms fail to converge to an equilibrium even in two-player zero-sum games. Although optimistic versions of these algorithms have been proposed with last-iterate convergence guarantees, they require noiseless gradient feedback. To overcome this limitation, we present a novel framework that achieves last-iterate convergence even in the presence of noise. Our key idea involves perturbing or regularizing the payoffs or utilities of the games. This perturbation serves to pull the current strategy to an anchored strategy, which we refer to as a {\it slingshot} strategy. First, we establish the convergence rates of our framework to a stationary point near an equilibrium, regardless of the presence or absence of noise. Next, we introduce an approach to periodically update the slingshot strategy with the current strategy. We interpret this approach as a proximal p
    
[^88]: 任意时延的非稳态在线凸优化

    Non-stationary Online Convex Optimization with Arbitrary Delays. (arXiv:2305.12131v1 [cs.LG])

    [http://arxiv.org/abs/2305.12131](http://arxiv.org/abs/2305.12131)

    本文研究了任意时延的非稳态在线凸优化，提出了一种简单的算法DOGD，并证明它能在最坏情况下获得$O(\sqrt{dT}(P_T+1))$的动态遗憾界，同时当延迟不改变梯度到达顺序时，自动将动态遗憾减少到$O(\sqrt{S}(1+P_T))$。

    

    最近，以梯度或其他函数信息可以任意延迟为特点的在线凸优化（OCO）引起了越来越多的关注。与之前研究稳态环境的研究不同，本文研究了非稳态环境下的延迟OCO，并旨在最小化与任何比较器序列相关的动态遗憾。为此，我们首先提出了一个简单的算法，即DOGD，该算法根据其到达顺序为每个延迟梯度执行渐变下降步骤。尽管它很简单，但我们的新型分析表明，DOGD可以在最坏情况下获得$O(\sqrt{dT}(P_T+1))$的动态遗憾界，其中$d$是最大延迟，$T$是时间跨度，$P_T$是比较器的路径长度。更重要的是，在延迟不改变渐变的到达顺序的情况下，它可以自动将动态遗憾减少到$O(\sqrt{S}(1+P_T))$，其中$S$是延迟之和。此外，我们将DOGD扩展为更通用的算法，并证明它实现了与DOGD相同的遗憾界。广泛的模拟表明了所提出算法的有效性和效率。

    Online convex optimization (OCO) with arbitrary delays, in which gradients or other information of functions could be arbitrarily delayed, has received increasing attention recently. Different from previous studies that focus on stationary environments, this paper investigates the delayed OCO in non-stationary environments, and aims to minimize the dynamic regret with respect to any sequence of comparators. To this end, we first propose a simple algorithm, namely DOGD, which performs a gradient descent step for each delayed gradient according to their arrival order. Despite its simplicity, our novel analysis shows that DOGD can attain an $O(\sqrt{dT}(P_T+1)$ dynamic regret bound in the worst case, where $d$ is the maximum delay, $T$ is the time horizon, and $P_T$ is the path length of comparators. More importantly, in case delays do not change the arrival order of gradients, it can automatically reduce the dynamic regret to $O(\sqrt{S}(1+P_T))$, where $S$ is the sum of delays. Furtherm
    
[^89]: 使用不平衡图册的状态表示学习

    State Representation Learning Using an Unbalanced Atlas. (arXiv:2305.10267v1 [cs.LG])

    [http://arxiv.org/abs/2305.10267](http://arxiv.org/abs/2305.10267)

    本文介绍了一种使用不平衡图册（UA）方法的状态表示学习，该方法可以超越最先进的自监督学习方法。

    

    流形假说认为，高维数据通常位于较低维的流形上，并且利用该流形作为目标空间可以产生更有效的表示。虽然存在许多传统的基于流形的技术用于降维，但它们在自监督学习中的应用进展缓慢。最近的MSIMCLR方法将流形编码与SimCLR相结合，但需要极低的目标编码维度才能胜过SimCLR，从而限制了其适用性。本文介绍了一种使用不平衡图册（UA）的新型学习方法，能够超越最先进的自监督学习方法。我们通过系统地调整时空DeepInfomax（ST-DIM）框架以与我们提议的UA模式保持一致，并在整个过程中采用严谨的科学方法来精心研究和设计了使用UA的DeepInfomax（DIM-UA）方法。

    The manifold hypothesis posits that high-dimensional data often lies on a lower-dimensional manifold and that utilizing this manifold as the target space yields more efficient representations. While numerous traditional manifold-based techniques exist for dimensionality reduction, their application in self-supervised learning has witnessed slow progress. The recent MSIMCLR method combines manifold encoding with SimCLR but requires extremely low target encoding dimensions to outperform SimCLR, limiting its applicability. This paper introduces a novel learning paradigm using an unbalanced atlas (UA), capable of surpassing state-of-the-art self-supervised learning approaches. We meticulously investigated and engineered the DeepInfomax with an unbalanced atlas (DIM-UA) method by systematically adapting the Spatiotemporal DeepInfomax (ST-DIM) framework to align with our proposed UA paradigm, employing rigorous scientific methodologies throughout the process. The efficacy of DIM-UA is demons
    
[^90]: CLCIFAR：带人类标注互补标签的CIFAR派生基准数据集

    CLCIFAR: CIFAR-Derived Benchmark Datasets with Human Annotated Complementary Labels. (arXiv:2305.08295v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.08295](http://arxiv.org/abs/2305.08295)

    本研究开发了由人类标注的互补标签，创造了两个真实世界的CLL数据集，进一步揭示了现实表现下CLL算法的性能，为这一领域的研究提供了更实际的评估标准。

    

    互补标签学习（CLL）是一种弱监督学习范式，旨在仅使用互补标签（标示实例不属于哪些类别）来训练多类分类器。尽管已经提出了多种CLL算法，但由于两个原因，它们的实际表现仍不清楚。首先，这些算法通常依赖于对互补标签生成的假设。其次，它们的评估仅限于合成数据集。为了获取有关CLL算法的真实世界表现的见解，我们开发了一种协议来收集由人类注释者注释的互补标签。这一努力导致创建了两个数据集，CLCIFAR10和CLCIFAR20，分别由CIFAR10和CIFAR100派生而来。这些数据集在https://github.com/ntucllab/complementary_cifar上公开发布，代表了第一个真实世界的CLL数据集。通过广泛的基准实验，我们发现相较于合成数据集，当使用人类注释的互补标签时，性能有明显下降。但是，我们也观察到，真实世界的CLL数据集使得在更接近实际应用条件下评估算法成为可能，从而更真实地评估其性能。

    Complementary-label learning (CLL) is a weakly-supervised learning paradigm that aims to train a multi-class classifier using only complementary labels, which indicate classes to which an instance does not belong. Despite numerous algorithmic proposals for CLL, their practical performance remains unclear for two reasons. Firstly, these algorithms often rely on assumptions about the generation of complementary labels. Secondly, their evaluation has been limited to synthetic datasets. To gain insights into the real-world performance of CLL algorithms, we developed a protocol to collect complementary labels annotated by human annotators. This effort resulted in the creation of two datasets, CLCIFAR10 and CLCIFAR20, derived from CIFAR10 and CIFAR100, respectively. These datasets, publicly released at https://github.com/ntucllab/complementary_cifar, represent the very first real-world CLL datasets. Through extensive benchmark experiments, we discovered a notable decline in performance when 
    
[^91]: FlightBERT++：一种非自回归多时域飞行轨迹预测框架

    FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework. (arXiv:2305.01658v1 [cs.LG])

    [http://arxiv.org/abs/2305.01658](http://arxiv.org/abs/2305.01658)

    FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。

    

    飞行轨迹预测是空中交通管制中的重要任务，可以帮助空管员更安全高效地管理空域。现有方法通常采用自回归方式执行多时域飞行轨迹预测任务，容易出现误差累积和低效率问题。本文提出了一种新的框架，称为FlightBERT++，以i）直接以非自回归方式预测多时域飞行轨迹，和ii）改善FlightBERT框架中二进制编码（BE）表示的限制。具体而言，所提出的框架通过通用的编码器-解码器架构实现，其中编码器从历史观测中学习时空模式，而解码器预测未来时间步的飞行状态。与传统架构相比，额外的时域感知上下文生成器（HACG）专门设计考虑先前的时域。

    Flight Trajectory Prediction (FTP) is an essential task in Air Traffic Control (ATC), which can assist air traffic controllers to manage airspace more safely and efficiently. Existing approaches generally perform multi-horizon FTP tasks in an autoregressive manner, which is prone to suffer from error accumulation and low-efficiency problems. In this paper, a novel framework, called FlightBERT++, is proposed to i) forecast multi-horizon flight trajectories directly in a non-autoregressive way, and ii) improved the limitation of the binary encoding (BE) representation in the FlightBERT framework. Specifically, the proposed framework is implemented by a generalized Encoder-Decoder architecture, in which the encoder learns the temporal-spatial patterns from historical observations and the decoder predicts the flight status for the future time steps. Compared to conventional architecture, an extra horizon-aware contexts generator (HACG) is dedicatedly designed to consider the prior horizon 
    
[^92]: Jacobian-Scaled K-means聚类用于受物理学影响的反应流分割

    Jacobian-Scaled K-means Clustering for Physics-Informed Segmentation of Reacting Flows. (arXiv:2305.01539v1 [physics.comp-ph])

    [http://arxiv.org/abs/2305.01539](http://arxiv.org/abs/2305.01539)

    本研究提出了一种受物理学影响的聚类策略，名为Jacobian-Scaled K-means聚类方法，能够不修改输入数据集即生成能够捕获动力学相似性区域的聚类。本方法具有一定的应用前景和实用价值。

    

    本文介绍了Jacobian-Scaled K-means (JSK-means)聚类方法，该方法是基于K-means框架的受物理学影响的聚类策略。该方法通过距离函数的修改将潜在的物理知识注入到聚类过程中：JSK-means聚类过程不使用传统的欧氏距离向量，而是使用从集群质心处求得的动态系统Jacobian矩阵缩放的距离向量。本文的目标是展示如何通过JSK-means算法--而不是修改输入数据集--生成能够捕获动力学相似性区域的聚类，即聚类是向高敏感区域在相空间中重新分布并由样本的源项的相似性描述而非样本本身。该算法在复杂的反应流模拟数据集(通道爆轰配置)上进行演示，其中动态性质是

    This work introduces Jacobian-scaled K-means (JSK-means) clustering, which is a physics-informed clustering strategy centered on the K-means framework. The method allows for the injection of underlying physical knowledge into the clustering procedure through a distance function modification: instead of leveraging conventional Euclidean distance vectors, the JSK-means procedure operates on distance vectors scaled by matrices obtained from dynamical system Jacobians evaluated at the cluster centroids. The goal of this work is to show how the JSK-means algorithm -- without modifying the input dataset -- produces clusters that capture regions of dynamical similarity, in that the clusters are redistributed towards high-sensitivity regions in phase space and are described by similarity in the source terms of samples instead of the samples themselves. The algorithm is demonstrated on a complex reacting flow simulation dataset (a channel detonation configuration), where the dynamics in the the
    
[^93]: 多模式传感器融合技术在DED打印SS316L部件中的原位表面孔隙率预测

    In-situ surface porosity prediction in DED (directed energy deposition) printed SS316L parts using multimodal sensor fusion. (arXiv:2304.08658v1 [physics.app-ph])

    [http://arxiv.org/abs/2304.08658](http://arxiv.org/abs/2304.08658)

    本研究利用多模式传感器融合技术和AI方法预测DED打印部件中的原位表面孔隙率的潜力，可以实时预测每个沃克塞尔中的气孔存在，是一个重大飞跃。

    

    本研究旨在将声发射（AE）等多模式传感器数据中的时频模式与DED过程中的孔隙率形成进行高空间（0.5mm）和时间（<1ms）的关联。通过采用可解释的AI方法中的LIME（局部可解释性非特定性解释），将AE中的某些高频波形特征归因于DED过程中的两个主要孔隙形成途径：飞溅事件和低热量输入下相邻打印轨迹的不充分熔合。该方法为实时预测每个沃克塞尔（0.5mm）中的气孔存在提供了令人兴奋的可能性，这是与先前努力相比的一个重大飞跃。在打印并随后加工SS316L材料样品时，同步采集了包括力，AE，振动和温度在内的多模式传感器数据。深度卷积神经网络分类器用于识别两种孔隙形成途径的AE特征，然后使用可解释AI方法进一步分析这些特征。结果表明，利用多模式传感器融合技术和AI方法预测DED打印部件中的原位表面孔隙率的潜力。

    This study aims to relate the time-frequency patterns of acoustic emission (AE) and other multi-modal sensor data collected in a hybrid directed energy deposition (DED) process to the pore formations at high spatial (0.5 mm) and time (< 1ms) resolutions. Adapting an explainable AI method in LIME (Local Interpretable Model-Agnostic Explanations), certain high-frequency waveform signatures of AE are to be attributed to two major pathways for pore formation in a DED process, namely, spatter events and insufficient fusion between adjacent printing tracks from low heat input. This approach opens an exciting possibility to predict, in real-time, the presence of a pore in every voxel (0.5 mm in size) as they are printed, a major leap forward compared to prior efforts. Synchronized multimodal sensor data including force, AE, vibration and temperature were gathered while an SS316L material sample was printed and subsequently machined. A deep convolution neural network classifier was used to ide
    
[^94]: BBOB上高维贝叶斯优化算法的比较

    Comparison of High-Dimensional Bayesian Optimization Algorithms on BBOB. (arXiv:2303.00890v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00890](http://arxiv.org/abs/2303.00890)

    本研究比较了BBOB上五种高维贝叶斯优化算法与传统方法以及CMA-ES算法的性能，结果表明... (根据论文的具体内容进行总结)

    

    贝叶斯优化是一类基于黑盒、基于代理的启发式算法，可以有效地优化评估成本高、只能拥有有限的评估预算的问题。贝叶斯优化在解决工业界的数值优化问题中尤为受欢迎，因为目标函数的评估通常依赖耗时的模拟或物理实验。然而，许多工业问题涉及大量参数，这给贝叶斯优化算法带来了挑战，其性能在维度超过15个变量时常常下降。虽然已经提出了许多新算法来解决这个问题，但目前还不清楚哪种算法在哪种优化场景中表现最好。本研究比较了5种最新的高维贝叶斯优化算法与传统贝叶斯优化和CMA-ES算法在COCA环境下24个BBOB函数上的性能，在维度从10到60个变量不断增加的情况下进行了对比。我们的结果证实了...

    Bayesian Optimization (BO) is a class of black-box, surrogate-based heuristics that can efficiently optimize problems that are expensive to evaluate, and hence admit only small evaluation budgets. BO is particularly popular for solving numerical optimization problems in industry, where the evaluation of objective functions often relies on time-consuming simulations or physical experiments. However, many industrial problems depend on a large number of parameters. This poses a challenge for BO algorithms, whose performance is often reported to suffer when the dimension grows beyond 15 variables. Although many new algorithms have been proposed to address this problem, it is not well understood which one is the best for which optimization scenario.  In this work, we compare five state-of-the-art high-dimensional BO algorithms, with vanilla BO and CMA-ES on the 24 BBOB functions of the COCO environment at increasing dimensionality, ranging from 10 to 60 variables. Our results confirm the su
    
[^95]: Swin Transformer 深度强化学习

    Deep Reinforcement Learning with Swin Transformers. (arXiv:2206.15269v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.15269](http://arxiv.org/abs/2206.15269)

    本文介绍了基于 Swin Transformer 的在线强化学习方案 Swin DQN，通过将组合的图像像素分成小的补丁并在局部应用自我注意力操作，实现了在 Atari 基准测试上超越现有基于 CNN 的强化学习方法的最先进性能。

    

    Transformer 是神经网络模型，利用多层自我注意力头，并在自然语言处理任务中展示了巨大的潜力。同时，有人努力将 Transformer 适应于机器学习的视觉任务，包括 Vision Transformer 和 Swin Transformer。虽然一些研究人员将 Vision Transformer 用于强化学习任务，但由于高计算成本，实验仍停留在小规模。另一方面，大规模的实验必须依赖于技术来减少 Vision Transformer 的成本，这也会产生较差的结果。为了解决这一挑战，本文提出了基于 Swin Transformer 的第一个在线强化学习方案：Swin DQN。Swin Transformer 可作为神经网络中的主干骨干，将图像像素的组合分成小的补丁，并在固定大小的窗口内应用局部自我注意力操作。它们在 ImageNet 分类任务中表现卓越。Swin DQN 在 Atari 基准测试中实现了最先进的性能，优于现有的基于 CNN 的强化学习方法。

    Transformers are neural network models that utilize multiple layers of self-attention heads and have exhibited enormous potential in natural language processing tasks. Meanwhile, there have been efforts to adapt transformers to visual tasks of machine learning, including Vision Transformers and Swin Transformers. Although some researchers use Vision Transformers for reinforcement learning tasks, their experiments remain at a small scale due to the high computational cost. Experiments conducted at a large scale, on the other hand, have to rely on techniques to cut the costs of Vision Transformers, which also yield inferior results.  To address this challenge, this article presents the first online reinforcement learning scheme that is based on Swin Transformers: Swin DQN. Swin Transformers are promising as a backbone in neural networks by splitting groups of image pixels into small patches and applying local self-attention operations inside the (shifted) windows of fixed sizes. They hav
    
[^96]: 平滑风险度量的策略梯度优化方法

    A policy gradient approach for optimization of smooth risk measures. (arXiv:2202.11046v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.11046](http://arxiv.org/abs/2202.11046)

    本文介绍了一种应用于on-policy和off-policy RL情况下的策略梯度算法，用于最小化广义平滑风险度量，能够收敛到平滑风险度量的稳态点，并适用于均值-方差和畸变风险度量的优化。

    

    我们提出了一种策略梯度算法，用于解决风险敏感的强化学习问题，包括on-policy和off-policy情况。我们考虑时间段马尔可夫决策过程，并利用累积折扣奖励的广义平滑风险度量来建模风险。我们提出了两个模板策略梯度算法，分别在on-policy和off-policy RL情况下优化平滑风险度量。我们推导出非渐进性界，量化了我们提出的算法收敛到平滑风险度量的稳态点的速率。作为特例，我们确定了我们的算法分别应用于均值-方差和畸变风险度量的优化。

    We propose policy gradient algorithms for solving a risk-sensitive reinforcement learning problem in on-policy as well as off-policy settings. We consider episodic Markov decision processes, and model the risk using the broad class of smooth risk measures of the cumulative discounted reward. We propose two template policy gradient algorithms that optimize a smooth risk measure in on-policy and off-policy RL settings, respectively. We derive non-asymptotic bounds that quantify the rate of convergence to our proposed algorithms to a stationary point of the smooth risk measure. As special cases, we establish that our algorithms apply to the optimization of mean-variance and distortion risk measures, respectively.
    
[^97]: Pareto对抗鲁棒性：平衡空间鲁棒性和基于敏感性的鲁棒性

    Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness. (arXiv:2111.01996v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.01996](http://arxiv.org/abs/2111.01996)

    本文提出了Pareto Adversarial Robustness策略，通过整合空间鲁棒性方法和基于敏感性的鲁棒性，实现了通用对抗鲁棒性。同时，从鲁棒表示的角度提供了自然准确性、敏感性鲁棒性和空间鲁棒性之间的关系。

    

    对抗鲁棒性主要包括基于敏感性的鲁棒性和空间鲁棒性，在实现鲁棒泛化方面起着重要作用。本文旨在设计实现通用对抗鲁棒性的策略。为了实现这一目标，我们首先研究了相对较少探索的空间鲁棒性领域。然后，我们将现有的空间鲁棒性方法整合起来，将局部和全局空间的脆弱性结合到一个统一的空间攻击和对抗训练方法中。此外，我们从鲁棒表示的角度提供了自然准确性、基于敏感性的鲁棒性和空间鲁棒性之间的全面关系，并且提供了强有力的证据支持。关键是，为了将各种鲁棒性组成部分之间的相互影响纳入一个统一的框架中，我们将帕累托准则引入到对抗鲁棒性分析中，提出了一种名为Pareto Adversarial Robustness的新策略。

    Adversarial robustness, which primarily comprises sensitivity-based robustness and spatial robustness, plays an integral part in achieving robust generalization. In this paper, we endeavor to design strategies to achieve universal adversarial robustness. To achieve this, we first investigate the relatively less-explored realm of spatial robustness. Then, we integrate the existing spatial robustness methods by incorporating both local and global spatial vulnerability into a unified spatial attack and adversarial training approach. Furthermore, we present a comprehensive relationship between natural accuracy, sensitivity-based robustness, and spatial robustness, supported by strong evidence from the perspective of robust representation. Crucially, to reconcile the interplay between the mutual impacts of various robustness components into one unified framework, we incorporate the \textit{Pareto criterion} into the adversarial robustness analysis, yielding a novel strategy called Pareto Ad
    

