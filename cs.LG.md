# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Graph Neural Networks in EEG-based Emotion Recognition: A Survey](https://rss.arxiv.org/abs/2402.01138) | 基于脑电图的情绪识别中的图神经网络是一个有重要意义的领域。本综述分类和分析了已有方法，并提供了构建基于脑电图的GNNs的明确指导。 |
| [^2] | [Evaluating Named Entity Recognition: Comparative Analysis of Mono- and Multilingual Transformer Models on Brazilian Corporate Earnings Call Transcriptions](https://arxiv.org/abs/2403.12212) | 本研究通过引入新方法，将标记分类任务重新构建为文本生成问题，评估了在巴西银行财报电话转录中使用的单语和多语言Transformer模型的性能。 |
| [^3] | [Learning the irreversible progression trajectory of Alzheimer's disease](https://arxiv.org/abs/2403.06087) | 提出了一种正则化方法来预测阿尔茨海默病的不可逆进展轨迹 |
| [^4] | [Advancing Biomedical Text Mining with Community Challenges](https://arxiv.org/abs/2403.04261) | 社区挑战评估竞赛在促进生物医学文本挖掘研究中的技术创新和跨学科合作方面起着重要作用。 |
| [^5] | [A Deep-Learning Technique to Locate Cryptographic Operations in Side-Channel Traces](https://arxiv.org/abs/2402.19037) | 通过深度学习技术，成功实现了在侧信道跟踪中定位目标加密操作的时间瞬间，即使存在跟踪变形。 |
| [^6] | [Quantum Distance Approximation for Persistence Diagrams](https://arxiv.org/abs/2402.17295) | 探索了量子计算机在估计持久图之间距离方面的潜力，提出了用于Wasserstein距离和$d^{c}_{p}$距离的变分量子算法 |
| [^7] | [Transformers are Expressive, But Are They Expressive Enough for Regression?](https://arxiv.org/abs/2402.15478) | Transformer在逼近连续函数方面存在困难，是否真正是通用函数逼近器仍有待考证 |
| [^8] | [Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model.](http://arxiv.org/abs/2401.13192) | 本研究提出了一种基于点云和扩散模型的晶体结构生成设计框架，并通过重建输入结构和生成全新材料的实验证明了其有效性和潜力。 |
| [^9] | [Empowering Aggregators with Practical Data-Driven Tools: Harnessing Aggregated and Disaggregated Flexibility for Demand Response.](http://arxiv.org/abs/2401.10726) | 本研究通过优化聚合灵活性提供策略和评估HVAC系统的分散灵活性提供，为聚合器在可再生能源不确定性下实现需求响应提供了实用工具，从而实现了稳健的脱碳和增强能源系统的韧性。 |
| [^10] | [Object-Centric Diffusion for Efficient Video Editing.](http://arxiv.org/abs/2401.05735) | 本论文提出了一种面向对象的扩散技术，通过分配更多的计算资源给前景编辑区域来实现视频编辑的高效率，从而大大提高了速度，同时保持了质量。 |
| [^11] | [Invariant Causal Prediction with Locally Linear Models.](http://arxiv.org/abs/2401.05218) | 本文扩展了ICP原则，考虑了在不同环境下具有局部线性模型的不变因果预测任务。通过提供因果父节点的可辨识性条件和引入LoLICaP方法，实现了在观察数据中识别目标变量的因果父节点。 |
| [^12] | [Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm.](http://arxiv.org/abs/2310.13019) | 本文提出了一种增强版DeepFool算法，名为Targeted DeepFool，可以针对特定类别进行错误分类，并引入了最小置信度分数要求超参数来提高灵活性。 |
| [^13] | [Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing.](http://arxiv.org/abs/2310.12404) | Loop Copilot是一种新型的AI音乐合奏系统，能够通过交互式多轮对话界面生成和迭代改进音乐，通过选择适当的AI模型执行任务，并在一个集中的表中保持关键属性以确保音乐的连贯性。 |
| [^14] | [Learning adjacency matrix for dynamic graph neural network.](http://arxiv.org/abs/2310.02606) | 该论文介绍了一种用于动态图神经网络的学习邻接矩阵的方法。通过引入一个特殊设计的编码器块来学习缺失的时空连接，将其丰富后的块邻接矩阵输入到图神经网络中，以捕捉网络的复杂时空拓扑。 |
| [^15] | [DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model.](http://arxiv.org/abs/2306.01001) | 本文提出了一种扩散模型中的负荷预测不确定性量化方法，采用Seq2Seq网络结构来分离两种类型的不确定性并处理异常情况，不仅着眼于预测条件期望值。 |
| [^16] | [EEGMatch: Learning with Incomplete Labels for Semi-Supervised EEG-based Cross-Subject Emotion Recognition.](http://arxiv.org/abs/2304.06496) | EEGMatch是一种半监督学习框架，可用于脑电情绪识别。通过基于EEG-Mixup的数据增强方法和半监督多域自适应方法，可以有效提高情绪识别准确性和稳定性。 |
| [^17] | [Incorporating Unlabelled Data into Bayesian Neural Networks.](http://arxiv.org/abs/2304.01762) | 该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。 |
| [^18] | [Fast Convergence Federated Learning with Aggregated Gradients.](http://arxiv.org/abs/2303.15799) | 该论文提出了一种带有聚合梯度的快速收敛联邦学习方法，通过引入均值场方法来完成参数和梯度的聚合步骤，该方法在收敛速度和通信成本方面优于传统方法。 |
| [^19] | [Lamarr: LHCb ultra-fast simulation based on machine learning models deployed within Gauss.](http://arxiv.org/abs/2303.11428) | LHCb实验中的90%计算资源用于生产模拟数据样本，而Lamarr是一个基于机器学习模型的系统，通过对LHCb实验的探测器响应和重建算法进行参数化，加快了模拟产出。 |
| [^20] | [Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers.](http://arxiv.org/abs/2212.11498) | 该论文提出了一种可扩展的多智能体强化学习方法，用于仓库物流中的机器人和人类同事合作。他们通过分层的MARL算法，让经理和工人代理根据全局目标进行协同训练，以最大化拣货速率。 |
| [^21] | [MelHuBERT: A simplified HuBERT on Mel spectrograms.](http://arxiv.org/abs/2211.09944) | MelHuBERT是基于Mel频谱图的简化版HuBERT模型，通过改进损失函数、输入表示和多阶段训练，在语音识别方面取得了有利表现，节省了31.2%的预训练时间和33.5%的计算资源。 |
| [^22] | [Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning.](http://arxiv.org/abs/2207.05442) | 本文提出了一种新的自回归模型，用于分析多元分布时间序列。并且在Wasserstein空间中建模了随机对象，提供了该模型的解的存在性和一致估计器。此方法可以应用于年龄分布和自行车共享网络的观察数据。 |

# 详细

[^1]: 基于脑电图的情绪识别中的图神经网络：一个综述

    Graph Neural Networks in EEG-based Emotion Recognition: A Survey

    [https://rss.arxiv.org/abs/2402.01138](https://rss.arxiv.org/abs/2402.01138)

    基于脑电图的情绪识别中的图神经网络是一个有重要意义的领域。本综述分类和分析了已有方法，并提供了构建基于脑电图的GNNs的明确指导。

    

    相对于其他模式，基于脑电图的情绪识别可以直观地响应人脑中的情绪模式，因此成为脑-计算机接口领域最关注的任务之一。由于大脑区域之间的依赖与情绪密切相关，因此发展基于图神经网络（GNNs）进行基于脑电图的情绪识别成为一个重要趋势。然而，情绪性脑电图中的大脑区域依赖具有生理基础，使得在这一领域中的GNNs与其他时间序列领域的GNNs有所区别。此外，在基于脑电图的情绪识别中既没有全面的综述，也没有构建GNNs的指导。在这项综述中，我们对已有方法在图构造的统一框架下进行了分类，揭示出其共同点和差异。我们从框架的三个阶段分析和分类方法，为构建基于脑电图的GNNs提供了清晰的指导。此外，我们还讨论了一些...

    Compared to other modalities, EEG-based emotion recognition can intuitively respond to the emotional patterns in the human brain and, therefore, has become one of the most concerning tasks in the brain-computer interfaces field. Since dependencies within brain regions are closely related to emotion, a significant trend is to develop Graph Neural Networks (GNNs) for EEG-based emotion recognition. However, brain region dependencies in emotional EEG have physiological bases that distinguish GNNs in this field from those in other time series fields. Besides, there is neither a comprehensive review nor guidance for constructing GNNs in EEG-based emotion recognition. In the survey, our categorization reveals the commonalities and differences of existing approaches under a unified framework of graph construction. We analyze and categorize methods from three stages in the framework to provide clear guidance on constructing GNNs in EEG-based emotion recognition. In addition, we discuss several 
    
[^2]: 评估命名实体识别：比较分析巴西公司财报电话转录上的单语和多语言Transformer模型

    Evaluating Named Entity Recognition: Comparative Analysis of Mono- and Multilingual Transformer Models on Brazilian Corporate Earnings Call Transcriptions

    [https://arxiv.org/abs/2403.12212](https://arxiv.org/abs/2403.12212)

    本研究通过引入新方法，将标记分类任务重新构建为文本生成问题，评估了在巴西银行财报电话转录中使用的单语和多语言Transformer模型的性能。

    

    命名实体识别（NER）是一种从文本文档中提取信息的自然语言处理技术。然而，现有关于NER的大部分研究都集中在英语文档上，导致缺乏专门针对葡萄牙语财务领域的数据集。本研究解决了金融领域内NER需求，并侧重于从巴西银行财报电话转录中提取的葡萄牙语文本。通过整理包括384个转录的综合数据集，并利用弱监督技术进行注释，我们评估了在葡萄牙语（BERTimbau和PTT5）训练的单语模型以及多语言模型（mBERT和mT5）的性能。值得注意的是，我们引入了一种新方法，将标记分类任务重新构建为文本生成问题，从而实现T5模型的微调和评估。在模型微调之后，

    arXiv:2403.12212v1 Announce Type: cross  Abstract: Named Entity Recognition (NER) is a Natural Language Processing technique for extracting information from textual documents. However, much of the existing research on NER has been centered around English-language documents, leaving a gap in the availability of datasets tailored to the financial domain in Portuguese. This study addresses the need for NER within the financial domain, focusing on Portuguese-language texts extracted from earnings call transcriptions of Brazilian banks. By curating a comprehensive dataset comprising 384 transcriptions and leveraging weak supervision techniques for annotation, we evaluate the performance of monolingual models trained on Portuguese (BERTimbau and PTT5) and multilingual models (mBERT and mT5). Notably, we introduce a novel approach that reframes the token classification task as a text generation problem, enabling fine-tuning and evaluation of T5 models. Following the fine-tuning of the models,
    
[^3]: 学习阿尔茨海默病的不可逆进展轨迹

    Learning the irreversible progression trajectory of Alzheimer's disease

    [https://arxiv.org/abs/2403.06087](https://arxiv.org/abs/2403.06087)

    提出了一种正则化方法来预测阿尔茨海默病的不可逆进展轨迹

    

    阿尔茨海默病（AD）是一种随着30年时间逐渐展开的进行性不可逆脑部疾病。因此，关键是在早期捕获疾病的进展，以便在症状出现之前可以施加干预。机器学习（ML）模型已被证明在预测AD的发作方面有效。然而，对于有随访的受试者，现有的AD分类技术只针对准确的组分配，通常忽略了在随访过程中递增风险的单调增加。在随访间出现的波动风险评分违背了AD的不可逆性，影响了模型的可信度，也对理解疾病的进展提供了很少的价值。为了解决这个问题，我们提出了一种新的正则化方法来预测AD的纵向发展。我们的技术旨在在病情进展期间保持预期的单调增加疾病风险。

    arXiv:2403.06087v1 Announce Type: new  Abstract: Alzheimer's disease (AD) is a progressive and irreversible brain disorder that unfolds over the course of 30 years. Therefore, it is critical to capture the disease progression in an early stage such that intervention can be applied before the onset of symptoms. Machine learning (ML) models have been shown effective in predicting the onset of AD. Yet for subjects with follow-up visits, existing techniques for AD classification only aim for accurate group assignment, where the monotonically increasing risk across follow-up visits is usually ignored. Resulted fluctuating risk scores across visits violate the irreversibility of AD, hampering the trustworthiness of models and also providing little value to understanding the disease progression. To address this issue, we propose a novel regularization approach to predict AD longitudinally. Our technique aims to maintain the expected monotonicity of increasing disease risk during progression w
    
[^4]: 通过社区挑战推动生物医学文本挖掘的发展

    Advancing Biomedical Text Mining with Community Challenges

    [https://arxiv.org/abs/2403.04261](https://arxiv.org/abs/2403.04261)

    社区挑战评估竞赛在促进生物医学文本挖掘研究中的技术创新和跨学科合作方面起着重要作用。

    

    生物医学研究领域积累了大量来自科学文献、电子病历、临床试验报告和社交媒体等各方面的文本数据，然而手动处理和分析这些庞大且复杂的资源是耗时且低效的。为了解决这一挑战，生物医学文本挖掘，也称为生物医学自然语言处理，备受关注。社区挑战评估竞赛在促进生物医学文本挖掘研究中的技术创新和跨学科合作方面发挥了重要作用。这些挑战为研究人员提供了开发生物医学研究中数据挖掘和信息处理的最新解决方案的平台。在本文中，我们回顾了与中文生物医学文本挖掘有关的最新社区挑战的进展。

    arXiv:2403.04261v1 Announce Type: new  Abstract: The field of biomedical research has witnessed a significant increase in the accumulation of vast amounts of textual data from various sources such as scientific literatures, electronic health records, clinical trial reports, and social media. However, manually processing and analyzing these extensive and complex resources is time-consuming and inefficient. To address this challenge, biomedical text mining, also known as biomedical natural language processing, has garnered great attention. Community challenge evaluation competitions have played an important role in promoting technology innovation and interdisciplinary collaboration in biomedical text mining research. These challenges provide platforms for researchers to develop state-of-the-art solutions for data mining and information processing in biomedical research. In this article, we review the recent advances in community challenges specific to Chinese biomedical text mining. Firs
    
[^5]: 一种用于定位侧信道跟踪中密码操作的深度学习技术

    A Deep-Learning Technique to Locate Cryptographic Operations in Side-Channel Traces

    [https://arxiv.org/abs/2402.19037](https://arxiv.org/abs/2402.19037)

    通过深度学习技术，成功实现了在侧信道跟踪中定位目标加密操作的时间瞬间，即使存在跟踪变形。

    

    侧信道攻击通过相关部分已知计算数据和已测量的侧信道信号，允许从加密原语的执行中提取秘密信息。本文提出了一种新颖的深度学习技术，用于定位侧信道追踪中执行的目标计算密码操作的时间瞬间。与现有解决方案相比，所提出的方法甚至在通过随机延迟插入技术获得的跟踪变形的情况下也能工作。

    arXiv:2402.19037v1 Announce Type: cross  Abstract: Side-channel attacks allow extracting secret information from the execution of cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. However, to set up a successful side-channel attack, the attacker has to perform i) the challenging task of locating the time instant in which the target cryptographic primitive is executed inside a side-channel trace and then ii)the time-alignment of the measured data on that time instant. This paper presents a novel deep-learning technique to locate the time instant in which the target computed cryptographic operations are executed in the side-channel trace. In contrast to state-of-the-art solutions, the proposed methodology works even in the presence of trace deformations obtained through random delay insertion techniques. We validated our proposal through a successful attack against a variety of unprotected and protected cryptographic primitive
    
[^6]: 持久图的量子距离逼近

    Quantum Distance Approximation for Persistence Diagrams

    [https://arxiv.org/abs/2402.17295](https://arxiv.org/abs/2402.17295)

    探索了量子计算机在估计持久图之间距离方面的潜力，提出了用于Wasserstein距离和$d^{c}_{p}$距离的变分量子算法

    

    拓扑数据分析方法对于在许多不同领域中的分类和聚类任务可能会很有用，因为它们能够提供总结关于潜在复杂和高维数据集形状的重要信息的二维持久图。持久图的空间可以赋予各种度量，比如Wasserstein距离，其具有统计结构，并允许将这些总结用于机器学习算法。然而，计算两个持久图之间的距离涉及找到两个图的点之间的最佳匹配方式，对于传统计算机来说可能并不总是一项容易的任务。在这项工作中，我们探讨了量子计算机评估持久图之间距离的潜力，特别是我们提出了用于Wasserstein距离和$d^{c}_{p}$距离的变分量子算法。

    arXiv:2402.17295v1 Announce Type: cross  Abstract: Topological Data Analysis methods can be useful for classification and clustering tasks in many different fields as they can provide two dimensional persistence diagrams that summarize important information about the shape of potentially complex and high dimensional data sets. The space of persistence diagrams can be endowed with various metrics such as the Wasserstein distance which admit a statistical structure and allow to use these summaries for machine learning algorithms. However, computing the distance between two persistence diagrams involves finding an optimal way to match the points of the two diagrams and may not always be an easy task for classical computers. In this work we explore the potential of quantum computers to estimate the distance between persistence diagrams, in particular we propose variational quantum algorithms for the Wasserstein distance as well as the $d^{c}_{p}$ distance. Our implementation is a weighted 
    
[^7]: Transformer是表现力强大的，但是对于回归任务来说表现力足够吗？

    Transformers are Expressive, But Are They Expressive Enough for Regression?

    [https://arxiv.org/abs/2402.15478](https://arxiv.org/abs/2402.15478)

    Transformer在逼近连续函数方面存在困难，是否真正是通用函数逼近器仍有待考证

    

    Transformer已成为自然语言处理中至关重要的技术，在机器翻译和摘要等应用中表现出色。随着它们的广泛应用，一些研究尝试分析Transformer的表现力。神经网络的表现力指的是它能够逼近的函数类。一个神经网络是完全表现力的，如果它可以充当通用函数逼近器。我们尝试分析Transformer的表现力。与现有观点相反，我们的研究结果表明，Transformer在可靠逼近连续函数方面存在困难，依赖于具有可观区间的分段常数逼近。关键问题是：“Transformer是否真正是通用函数逼近器？”为了解决这个问题，我们进行了彻底的调查，通过实验提供理论见解和支持证据。我们的贡献包括了一个理论分析……（摘要未完整）

    arXiv:2402.15478v1 Announce Type: new  Abstract: Transformers have become pivotal in Natural Language Processing, demonstrating remarkable success in applications like Machine Translation and Summarization. Given their widespread adoption, several works have attempted to analyze the expressivity of Transformers. Expressivity of a neural network is the class of functions it can approximate. A neural network is fully expressive if it can act as a universal function approximator. We attempt to analyze the same for Transformers. Contrary to existing claims, our findings reveal that Transformers struggle to reliably approximate continuous functions, relying on piecewise constant approximations with sizable intervals. The central question emerges as: "\textit{Are Transformers truly Universal Function Approximators}?" To address this, we conduct a thorough investigation, providing theoretical insights and supporting evidence through experiments. Our contributions include a theoretical analysi
    
[^8]: 基于点云表示和扩散模型的晶体结构生成设计

    Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model. (arXiv:2401.13192v1 [cs.AI])

    [http://arxiv.org/abs/2401.13192](http://arxiv.org/abs/2401.13192)

    本研究提出了一种基于点云和扩散模型的晶体结构生成设计框架，并通过重建输入结构和生成全新材料的实验证明了其有效性和潜力。

    

    在材料设计中，高效地生成能量稳定的晶体结构一直是个挑战，主要是因为晶格中原子的巨大排列。为了促进稳定材料的发现，我们提出了一个用于生成可合成材料的框架，利用点云表示来编码复杂的结构信息。在这个框架的核心是引入扩散模型作为基础支柱。为了评估我们方法的有效性，我们使用它来重建训练数据集中的输入结构，并严格验证其高重建性能。此外，我们通过生成全新的材料，重点强调了基于点云的晶体扩散(PCCD)的巨大潜力，并展示了其可合成性。我们的研究在材料设计和合成的推进中，通过先进的生成设计方法，做出了显著贡献。

    Efficiently generating energetically stable crystal structures has long been a challenge in material design, primarily due to the immense arrangement of atoms in a crystal lattice. To facilitate the discovery of stable material, we present a framework for the generation of synthesizable materials, leveraging a point cloud representation to encode intricate structural information. At the heart of this framework lies the introduction of a diffusion model as its foundational pillar. To gauge the efficacy of our approach, we employ it to reconstruct input structures from our training datasets, rigorously validating its high reconstruction performance. Furthermore, we demonstrate the profound potential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirely new materials, emphasizing their synthesizability. Our research stands as a noteworthy contribution to the advancement of materials design and synthesis through the cutting-edge avenue of generative design instead of the con
    
[^9]: 用基于数据驱动的实用工具增强聚合器能力：利用聚合与分散的灵活性实现需求响应

    Empowering Aggregators with Practical Data-Driven Tools: Harnessing Aggregated and Disaggregated Flexibility for Demand Response. (arXiv:2401.10726v1 [eess.SY])

    [http://arxiv.org/abs/2401.10726](http://arxiv.org/abs/2401.10726)

    本研究通过优化聚合灵活性提供策略和评估HVAC系统的分散灵活性提供，为聚合器在可再生能源不确定性下实现需求响应提供了实用工具，从而实现了稳健的脱碳和增强能源系统的韧性。

    

    本研究探讨了在可再生能源带来不确定性的情况下，聚合器和建筑物居住者通过需求响应（DR）方案激活灵活性的关键相互作用，着重于实现稳健的脱碳和增强能源系统的韧性。首先，引入了一种在数据有限的环境中优化聚合灵活性提供策略的方法，利用离散傅里叶变换（DFT）和聚类技术识别建筑物居民的活动模式。其次，研究评估了DR事件期间供热通风空调（HVAC）系统的分散灵活性提供，采用机器学习和优化技术进行精确的设备级分析。第一种方法为聚合器在整个建筑物消费仅有一个智能电表的环境中提供灵活性服务提供了一条非侵入性途径。

    This study explores the crucial interplay between aggregators and building occupants in activating flexibility through Demand Response (DR) programs, with a keen focus on achieving robust decarbonization and fortifying the resilience of the energy system amidst the uncertainties presented by Renewable Energy Sources (RES). Firstly, it introduces a methodology of optimizing aggregated flexibility provision strategies in environments with limited data, utilizing Discrete Fourier Transformation (DFT) and clustering techniques to identify building occupant's activity patterns. Secondly, the study assesses the disaggregated flexibility provision of Heating Ventilation and Air Conditioning (HVAC) systems during DR events, employing machine learning and optimization techniques for precise, device-level analysis. The first approach offers a non-intrusive pathway for aggregators to provide flexibility services in environments of a single smart meter for the whole building's consumption, while t
    
[^10]: 面向对象的扩散技术实现高效视频编辑

    Object-Centric Diffusion for Efficient Video Editing. (arXiv:2401.05735v1 [cs.CV])

    [http://arxiv.org/abs/2401.05735](http://arxiv.org/abs/2401.05735)

    本论文提出了一种面向对象的扩散技术，通过分配更多的计算资源给前景编辑区域来实现视频编辑的高效率，从而大大提高了速度，同时保持了质量。

    

    基于扩散的视频编辑已经达到了令人印象深刻的质量，并且可以根据编辑提示来转换视频的全局风格、局部结构和属性。然而，这些解决方案通常需要使用大量的内存和计算资源来生成具有时序一致性的帧，可能涉及扩散反演和/或跨帧注意力。在本文中，我们对这种低效性进行了分析，并提出了简单而有效的修改，可以显著提高速度同时保持质量。此外，我们引入了面向对象的扩散技术（OCD），通过将计算资源更多地分配给对感知质量更重要的前景编辑区域，进一步降低延迟。我们通过两个新的提案来实现这一点：i）面向对象的采样，将用于显著区域或背景的扩散步骤与用于前景的扩散步骤分离开来，将大部分模型容量分配给前者；ii）面向对象的3D令牌合并，用于改善前景和背景之间的混合。

    Diffusion-based video editing have reached impressive quality and can transform either the global style, local structure, and attributes of given video inputs, following textual edit prompts. However, such solutions typically incur heavy memory and computational costs to generate temporally-coherent frames, either in the form of diffusion inversion and/or cross-frame attention. In this paper, we conduct an analysis of such inefficiencies, and suggest simple yet effective modifications that allow significant speed-ups whilst maintaining quality. Moreover, we introduce Object-Centric Diffusion, coined as OCD, to further reduce latency by allocating computations more towards foreground edited regions that are arguably more important for perceptual quality. We achieve this by two novel proposals: i) Object-Centric Sampling, decoupling the diffusion steps spent on salient regions or background, allocating most of the model capacity to the former, and ii) Object-Centric 3D Token Merging, whi
    
[^11]: 具有局部线性模型的不变因果预测

    Invariant Causal Prediction with Locally Linear Models. (arXiv:2401.05218v1 [cs.LG])

    [http://arxiv.org/abs/2401.05218](http://arxiv.org/abs/2401.05218)

    本文扩展了ICP原则，考虑了在不同环境下具有局部线性模型的不变因果预测任务。通过提供因果父节点的可辨识性条件和引入LoLICaP方法，实现了在观察数据中识别目标变量的因果父节点。

    

    本文考虑通过观察数据，从一组候选变量中识别出目标变量的因果父节点的任务。我们的主要假设是候选变量在不同的环境中被观察到，这些环境可以对应于机器的不同设置或者动态过程中的不同时间间隔等。在一定的假设条件下，不同的环境可以被视为对观察系统的干预。我们假设目标变量和协变量之间存在线性关系，在每个环境下可能不同，但因果结构在不同环境中是不变的。这是Peters等人[2016]提出的ICP（不变因果预测）原则的扩展，后者假设所有环境下存在一个固定的线性关系。在我们提出的设置下，我们给出了因果父节点可辨识性的充分条件，并引入了一个名为LoLICaP的实用方法。

    We consider the task of identifying the causal parents of a target variable among a set of candidate variables from observational data. Our main assumption is that the candidate variables are observed in different environments which may, for example, correspond to different settings of a machine or different time intervals in a dynamical process. Under certain assumptions different environments can be regarded as interventions on the observed system. We assume a linear relationship between target and covariates, which can be different in each environment with the only restriction that the causal structure is invariant across environments. This is an extension of the ICP ($\textbf{I}$nvariant $\textbf{C}$ausal $\textbf{P}$rediction) principle by Peters et al. [2016], who assumed a fixed linear relationship across all environments. Within our proposed setting we provide sufficient conditions for identifiability of the causal parents and introduce a practical method called LoLICaP ($\text
    
[^12]: 通过DeepFool算法对深度神经网络进行有针对性的类别操纵的对抗攻击定制

    Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm. (arXiv:2310.13019v1 [cs.CV])

    [http://arxiv.org/abs/2310.13019](http://arxiv.org/abs/2310.13019)

    本文提出了一种增强版DeepFool算法，名为Targeted DeepFool，可以针对特定类别进行错误分类，并引入了最小置信度分数要求超参数来提高灵活性。

    

    深度神经网络（DNNs）在各个领域都取得了显著的进展，但对抗攻击的易受攻击性引起了严重关注。了解这些易受攻击性并开发有效的防御机制至关重要。DeepFool是Moosavi-Dezfooli等人（2016年）提出的一种算法，用于找到将输入图像错误分类的最小扰动。然而，DeepFool缺乏有针对性的方法，使其在特定攻击场景中的有效性较低。此外，在先前的相关工作中，研究人员主要关注的是成功率，而没有考虑图像被扭曲的程度、图像质量的完整性以及错误分类的置信度水平。因此，在本文中，我们提出了Targeted DeepFool，这是DeepFool的增强版，可以针对特定类别进行错误分类。我们还引入了一个最小置信度分数要求超参数来增强灵活性。我们的实验证明了所提方法在不同情况下的有效性和效率。

    Deep neural networks (DNNs) have significantly advanced various domains, but their vulnerability to adversarial attacks poses serious concerns. Understanding these vulnerabilities and developing effective defense mechanisms is crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016), finds minimal perturbations to misclassify input images. However, DeepFool lacks a targeted approach, making it less effective in specific attack scenarios. Also, in previous related works, researchers primarily focus on success, not considering how much an image is getting distorted; the integrity of the image quality, and the confidence level to misclassifying. So, in this paper, we propose Targeted DeepFool, an augmented version of DeepFool that allows targeting specific classes for misclassification. We also introduce a minimum confidence score requirement hyperparameter to enhance flexibility. Our experiments demonstrate the effectiveness and efficiency of the proposed method across 
    
[^13]: Loop Copilot: 用于音乐生成和迭代编辑的AI合奏系统

    Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing. (arXiv:2310.12404v1 [cs.SD])

    [http://arxiv.org/abs/2310.12404](http://arxiv.org/abs/2310.12404)

    Loop Copilot是一种新型的AI音乐合奏系统，能够通过交互式多轮对话界面生成和迭代改进音乐，通过选择适当的AI模型执行任务，并在一个集中的表中保持关键属性以确保音乐的连贯性。

    

    创建音乐是一个迭代过程，每个阶段都需要不同的方法。然而，现有的AI音乐系统在组织多个子系统以满足不同需求方面存在不足。为了解决这个问题，我们引入了Loop Copilot，这是一个能够通过交互式、多轮对话界面生成和迭代改进音乐的新型系统。该系统使用一种大型语言模型来解释用户意图，并选择适当的AI模型进行任务执行。每个后端模型都专门针对特定任务，并将它们的输出聚合起来以满足用户的要求。为了确保音乐的连贯性，关键属性被保留在一个集中的表中。我们通过半结构化的访谈和问卷调查评估了所提出的系统的有效性，突出了它在促进音乐创作方面的实用性，以及它在更广泛应用中的潜力。

    Creating music is iterative, requiring varied methods at each stage. However, existing AI music systems fall short in orchestrating multiple subsystems for diverse needs. To address this gap, we introduce Loop Copilot, a novel system that enables users to generate and iteratively refine music through an interactive, multi-round dialogue interface. The system uses a large language model to interpret user intentions and select appropriate AI models for task execution. Each backend model is specialized for a specific task, and their outputs are aggregated to meet the user's requirements. To ensure musical coherence, essential attributes are maintained in a centralized table. We evaluate the effectiveness of the proposed system through semi-structured interviews and questionnaires, highlighting its utility not only in facilitating music creation but also its potential for broader applications.
    
[^14]: 动态图神经网络中学习邻接矩阵

    Learning adjacency matrix for dynamic graph neural network. (arXiv:2310.02606v1 [cs.LG])

    [http://arxiv.org/abs/2310.02606](http://arxiv.org/abs/2310.02606)

    该论文介绍了一种用于动态图神经网络的学习邻接矩阵的方法。通过引入一个特殊设计的编码器块来学习缺失的时空连接，将其丰富后的块邻接矩阵输入到图神经网络中，以捕捉网络的复杂时空拓扑。

    

    在最近的研究中，[1] 引入了使用块邻接矩阵（BA）来表示时空数据的概念。虽然他们的方法成功地串联了邻接矩阵，以封装单个图中的时空关系，但它形成了一个不连通的图。这个限制妨碍了图卷积网络（GCN）在属于不同时间步的节点之间进行消息传递的能力，因为没有时间链接存在。为了克服这个挑战，我们引入了一个专门设计用于学习这些缺失的时间链接的编码器块。编码器块处理BA并预测之前未连接的子图之间的连接，从而产生一个富化的时空块邻接矩阵（STBAM）。然后，将这个富化的矩阵输入到图神经网络（GNN）中，以捕捉网络的复杂时空拓扑。我们对基准数据集surgVisDom和C2D2进行评估，结果证明我们的方法稍高一些。

    In recent work, [1] introduced the concept of using a Block Adjacency Matrix (BA) for the representation of spatio-temporal data. While their method successfully concatenated adjacency matrices to encapsulate spatio-temporal relationships in a single graph, it formed a disconnected graph. This limitation hampered the ability of Graph Convolutional Networks (GCNs) to perform message passing across nodes belonging to different time steps, as no temporal links were present. To overcome this challenge, we introduce an encoder block specifically designed to learn these missing temporal links. The encoder block processes the BA and predicts connections between previously unconnected subgraphs, resulting in a Spatio-Temporal Block Adjacency Matrix (STBAM). This enriched matrix is then fed into a Graph Neural Network (GNN) to capture the complex spatio-temporal topology of the network. Our evaluations on benchmark datasets, surgVisDom and C2D2, demonstrate that our method, with slightly higher
    
[^15]: DiffLoad:扩散模型中的负荷预测不确定性量化

    DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model. (arXiv:2306.01001v1 [cs.LG])

    [http://arxiv.org/abs/2306.01001](http://arxiv.org/abs/2306.01001)

    本文提出了一种扩散模型中的负荷预测不确定性量化方法，采用Seq2Seq网络结构来分离两种类型的不确定性并处理异常情况，不仅着眼于预测条件期望值。

    

    电力负荷预测对电力系统的决策制定，如机组投入和能源管理等具有重要意义。近年来，各种基于自监督神经网络的方法已经被应用于电力负荷预测，以提高预测准确性和捕捉不确定性。然而，大多数现有的方法是基于高斯似然方法的，它旨在在给定的协变量下准确估计分布期望值。这种方法很难适应存在分布偏移和异常值的时间数据。在本文中，我们提出了一种基于扩散的Seq2seq结构来估计本体不确定性，并使用鲁棒的加性柯西分布来估计物象不确定性。我们展示了我们的方法能够分离两种类型的不确定性并处理突变情况，而不是准确预测条件期望。

    Electrical load forecasting is of great significance for the decision makings in power systems, such as unit commitment and energy management. In recent years, various self-supervised neural network-based methods have been applied to electrical load forecasting to improve forecasting accuracy and capture uncertainties. However, most current methods are based on Gaussian likelihood methods, which aim to accurately estimate the distribution expectation under a given covariate. This kind of approach is difficult to adapt to situations where temporal data has a distribution shift and outliers. In this paper, we propose a diffusion-based Seq2seq structure to estimate epistemic uncertainty and use the robust additive Cauchy distribution to estimate aleatoric uncertainty. Rather than accurately forecasting conditional expectations, we demonstrate our method's ability in separating two types of uncertainties and dealing with the mutant scenarios.
    
[^16]: EEGMatch: 学习不完整标记的半监督脑电情绪识别

    EEGMatch: Learning with Incomplete Labels for Semi-Supervised EEG-based Cross-Subject Emotion Recognition. (arXiv:2304.06496v1 [eess.SP])

    [http://arxiv.org/abs/2304.06496](http://arxiv.org/abs/2304.06496)

    EEGMatch是一种半监督学习框架，可用于脑电情绪识别。通过基于EEG-Mixup的数据增强方法和半监督多域自适应方法，可以有效提高情绪识别准确性和稳定性。

    

    脑电图（EEG）是情绪识别的客观工具，并显示出良好的性能。然而，标签稀缺问题是该领域的主要挑战，限制了基于EEG的情绪识别的广泛应用。本文提出了一种新的半监督学习框架（EEGMatch），以利用标记和未标记的EEG数据。首先，开发了一种基于EEG-Mixup数据增强方法，以生成更多用于模型学习的有效样本。其次，提出了一种半监督的两步成对学习方法，将原型式和实例化式成对学习连接起来，其中原型式成对学习衡量EEG数据与每个情感类别的原型表示之间的全局关系，而实例化式成对学习捕捉EEG数据之间的局部内在关系。第三，引入了一种半监督的多域自适应，以对齐多个域（标记的和未标记的数据集）之间的数据表示。实验结果表明，EEGMatch在情绪识别任务中表现出比现有的半监督方法更高的准确性和稳定性。

    Electroencephalography (EEG) is an objective tool for emotion recognition and shows promising performance. However, the label scarcity problem is a main challenge in this field, which limits the wide application of EEG-based emotion recognition. In this paper, we propose a novel semi-supervised learning framework (EEGMatch) to leverage both labeled and unlabeled EEG data. First, an EEG-Mixup based data augmentation method is developed to generate more valid samples for model learning. Second, a semi-supervised two-step pairwise learning method is proposed to bridge prototype-wise and instance-wise pairwise learning, where the prototype-wise pairwise learning measures the global relationship between EEG data and the prototypical representation of each emotion class and the instance-wise pairwise learning captures the local intrinsic relationship among EEG data. Third, a semi-supervised multi-domain adaptation is introduced to align the data representation among multiple domains (labeled
    
[^17]: 将未标记数据纳入贝叶斯神经网络中

    Incorporating Unlabelled Data into Bayesian Neural Networks. (arXiv:2304.01762v1 [cs.LG])

    [http://arxiv.org/abs/2304.01762](http://arxiv.org/abs/2304.01762)

    该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。

    

    我们提出了一个对贝叶斯神经网络（BNNs）中先验分布进行学习的对比框架，利用未标记数据来优化。基于该框架，我们提出了一种实用的BNN算法，同时具备自监督学习的标签效率和贝叶斯方法中的根据原则的不确定性估计。最后，我们展示了我们的方法在半监督和低预算主动学习问题中的数据高效学习优势。

    We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.
    
[^18]: 带有聚合梯度的快速收敛联邦学习

    Fast Convergence Federated Learning with Aggregated Gradients. (arXiv:2303.15799v1 [cs.LG])

    [http://arxiv.org/abs/2303.15799](http://arxiv.org/abs/2303.15799)

    该论文提出了一种带有聚合梯度的快速收敛联邦学习方法，通过引入均值场方法来完成参数和梯度的聚合步骤，该方法在收敛速度和通信成本方面优于传统方法。

    

    联邦学习（FL）是一种新的机器学习框架，它使多个分布式设备在保护本地数据的同时，通过中央服务器协同训练共享模型。然而，非独立和同分布（Non-IID）的数据样本以及参与者之间频繁的通信将减缓收敛速率并增加通信成本。为了实现快速收敛，我们通过在常规本地更新规则中引入聚合梯度来改善本地梯度下降方法，并提出一种自适应学习率算法，在每次迭代中进一步考虑本地参数和全局参数的偏差。以上策略要求在每个本地迭代中收集所有客户端的本地参数和梯度，由于本地更新期间没有通信，这是具有挑战性的。因此，我们利用均值场方法，引入称为全局均值场和本地均值场的两个均值场术语来完成聚合步骤。实验结果表明，我们提出的方法在收敛速度和通信成本方面优于传统方法。

    Federated Learning (FL) is a novel machine learning framework, which enables multiple distributed devices cooperatively training a shared model scheduled by a central server while protecting private data locally. However, the non-independent-and-identically-distributed (Non-IID) data samples and frequent communication among participants will slow down the convergent rate and increase communication costs. To achieve fast convergence, we ameliorate the local gradient descend approach in conventional local update rule by introducing the aggregated gradients at each local update epoch, and propose an adaptive learning rate algorithm that further takes the deviation of local parameter and global parameter into consideration at each iteration. The above strategy requires all clients' local parameters and gradients at each local iteration, which is challenging as there is no communication during local update epochs. Accordingly, we utilize mean field approach by introducing two mean field ter
    
[^19]: 基于机器学习模型的LHCb超快速模拟系统Lamarr在Gauss中的应用

    Lamarr: LHCb ultra-fast simulation based on machine learning models deployed within Gauss. (arXiv:2303.11428v1 [hep-ex])

    [http://arxiv.org/abs/2303.11428](http://arxiv.org/abs/2303.11428)

    LHCb实验中的90%计算资源用于生产模拟数据样本，而Lamarr是一个基于机器学习模型的系统，通过对LHCb实验的探测器响应和重建算法进行参数化，加快了模拟产出。

    

    LHCb实验可用的计算资源的约90%用于生产Large Hadron Collider（LHC）运行2的模拟数据样本。升级后的LHCb探测器将能够收集更多的数据样本，需要更多的模拟事件来分析将在运行3中收集的数据。模拟是分析的关键需求，以解释信号与背景并测量效率。这种需要的模拟将远远超出已承诺的资源，需要技术和技巧的演变来生产这些模拟数据样本。在这项贡献中，我们讨论了Lamarr，这是一种基于Gaudi框架的系统，该系统通过对LHCb实验的探测器响应和重建算法进行参数化，加快了模拟产出。使用基于多种算法和策略的深度生成模型，有效地参数化了LHCb探测器单个组件的高级响应，在神经网络中编码。

    About 90% of the computing resources available to the LHCb experiment has been spent to produce simulated data samples for Run 2 of the Large Hadron Collider at CERN. The upgraded LHCb detector will be able to collect larger data samples, requiring many more simulated events to analyze the data to be collected in Run 3. Simulation is a key necessity of analysis to interpret signal vs background and measure efficiencies. The needed simulation will far exceed the pledged resources, requiring an evolution in technologies and techniques to produce these simulated data samples. In this contribution, we discuss Lamarr, a Gaudi-based framework to speed-up the simulation production parametrizing both the detector response and the reconstruction algorithms of the LHCb experiment. Deep Generative Models powered by several algorithms and strategies are employed to effectively parametrize the high-level response of the single components of the LHCb detector, encoding within neural networks the exp
    
[^20]: 可扩展的多智能体强化学习在仓库物流中与机器人和人类同事合作

    Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers. (arXiv:2212.11498v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.11498](http://arxiv.org/abs/2212.11498)

    该论文提出了一种可扩展的多智能体强化学习方法，用于仓库物流中的机器人和人类同事合作。他们通过分层的MARL算法，让经理和工人代理根据全局目标进行协同训练，以最大化拣货速率。

    

    我们设想一个仓库里有数十个移动机器人和人类分拣员一起工作，收集和交付仓库内的物品。我们要解决的基本问题是称为拣货问题，即这些工作代理人如何在仓库中协调他们的移动和行为以最大化性能（例如订单吞吐量）。传统的行业方法使用启发式方法需要大量的工程努力来为固有可变的仓库配置进行优化。相比之下，多智能体强化学习（MARL）可以灵活地应用于不同的仓库配置（例如大小，布局，工人数量/类型，物品补充频率），因为代理人通过经验学习如何最优地相互合作。我们开发了分层MARL算法，其中一个管理者为工人代理分配目标，并且管理者和工人的策略被共同训练以最大化全局目标（例如拣货速率）。

    We envision a warehouse in which dozens of mobile robots and human pickers work together to collect and deliver items within the warehouse. The fundamental problem we tackle, called the order-picking problem, is how these worker agents must coordinate their movement and actions in the warehouse to maximise performance (e.g. order throughput). Established industry methods using heuristic approaches require large engineering efforts to optimise for innately variable warehouse configurations. In contrast, multi-agent reinforcement learning (MARL) can be flexibly applied to diverse warehouse configurations (e.g. size, layout, number/types of workers, item replenishment frequency), as the agents learn through experience how to optimally cooperate with one another. We develop hierarchical MARL algorithms in which a manager assigns goals to worker agents, and the policies of the manager and workers are co-trained toward maximising a global objective (e.g. pick rate). Our hierarchical algorith
    
[^21]: MelHuBERT: 一种基于Mel频谱图的简化HuBERT模型

    MelHuBERT: A simplified HuBERT on Mel spectrograms. (arXiv:2211.09944v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.09944](http://arxiv.org/abs/2211.09944)

    MelHuBERT是基于Mel频谱图的简化版HuBERT模型，通过改进损失函数、输入表示和多阶段训练，在语音识别方面取得了有利表现，节省了31.2%的预训练时间和33.5%的计算资源。

    

    自监督模型在学习语音表示方面取得了巨大的成功，可以推广到各种下游任务。然而，大多数自监督模型需要大量的计算资源和多个GPU来进行训练，从而严重限制了自监督学习的发展。为了减少训练的计算量，我们重新审视了HuBERT的训练方法，这是一个非常成功的自监督模型。我们改进并简化了几个关键组成部分，包括损失函数、输入表示和多阶段训练。我们的模型MelHuBERT在音素识别、说话人识别和自动语音识别方面均能取得较好的性能，同时节省了31.2%的预训练时间，或等效地每秒语音节省了33.5%的MACs。代码和预训练模型可在https://github.com/nervjack2/MelHuBERT中获得。

    Self-supervised models have had great success in learning speech representations that can generalize to various downstream tasks. However, most self-supervised models require a large amount of compute and multiple GPUs to train, significantly hampering the development of self-supervised learning. In an attempt to reduce the computation of training, we revisit the training of HuBERT, a highly successful self-supervised model. We improve and simplify several key components, including the loss function, input representation, and training in multiple stages. Our model, MelHuBERT, is able to achieve favorable performance on phone recognition, speaker identification, and automatic speech recognition against HuBERT, while saving 31.2% of the pre-training time, or equivalently 33.5% MACs per one second speech. The code and pre-trained models are available in https://github.com/nervjack2/MelHuBERT.
    
[^22]: Wasserstein多元自回归模型用于建模分布时间序列及其在图形学习中的应用

    Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning. (arXiv:2207.05442v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.05442](http://arxiv.org/abs/2207.05442)

    本文提出了一种新的自回归模型，用于分析多元分布时间序列。并且在Wasserstein空间中建模了随机对象，提供了该模型的解的存在性和一致估计器。此方法可以应用于年龄分布和自行车共享网络的观察数据。

    

    我们提出了一种新的自回归模型，用于统计分析多元分布时间序列。感兴趣的数据包括一组在实线有界间隔上支持的概率测度的多个系列，并且被不同时间瞬间所索引。概率测度被建模为Wasserstein空间中的随机对象。我们通过在Lebesgue测度的切空间中建立自回归模型，首先对所有原始测度进行居中处理，以便它们的Fréchet平均值成为Lebesgue测度。利用迭代随机函数系统的理论，提供了这样一个模型的解的存在性、唯一性和平稳性的结果。我们还提出了模型系数的一致估计器。除了对模拟数据的分析，我们还使用两个实际数据集进行了模型演示：一个是不同国家年龄分布的观察数据集，另一个是巴黎自行车共享网络的观察数据集。

    We propose a new auto-regressive model for the statistical analysis of multivariate distributional time series. The data of interest consist of a collection of multiple series of probability measures supported over a bounded interval of the real line, and that are indexed by distinct time instants. The probability measures are modelled as random objects in the Wasserstein space. We establish the auto-regressive model in the tangent space at the Lebesgue measure by first centering all the raw measures so that their Fr\'echet means turn to be the Lebesgue measure. Using the theory of iterated random function systems, results on the existence, uniqueness and stationarity of the solution of such a model are provided. We also propose a consistent estimator for the model coefficient. In addition to the analysis of simulated data, the proposed model is illustrated with two real data sets made of observations from age distribution in different countries and bike sharing network in Paris. Final
    

