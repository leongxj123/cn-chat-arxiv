# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning Collective Variables for Protein Folding with Labeled Data Augmentation through Geodesic Interpolation](https://rss.arxiv.org/abs/2402.01542) | 本实验提出了一种使用标记数据增强和测地插值方法学习蛋白质折叠的集体变量的策略，有效提高了采样效率，并在过渡态数据有限且嘈杂时表现优于基于分类器的方法。 |
| [^2] | [Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection](https://arxiv.org/abs/2403.14270) | 提出了一种简单高效的无解码器架构，用于开放词汇的视觉关系检测，通过Transformer-based图像编码器隐式建模对象之间的关系，使用注意力机制提取关系信息，在混合数据上进行端到端训练，实现了最先进的关系检测性能。 |
| [^3] | [Debiasing surgeon: fantastic weights and how to find them](https://arxiv.org/abs/2403.14200) | 证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。 |
| [^4] | [VFusion3D: Learning Scalable 3D Generative Models from Video Diffusion Models](https://arxiv.org/abs/2403.12034) | 利用预训练的视频扩散模型，本文提出了一个可生成大规模3D数据集的VFusion3D模型。 |
| [^5] | [Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery](https://arxiv.org/abs/2403.07955) | 本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化，并通过两种策略缓解利用快捷方式来组成理性化的问题，以及通过数据增强方法来补充已注释理性化数量的差距。 |
| [^6] | [Truly No-Regret Learning in Constrained MDPs](https://arxiv.org/abs/2402.15776) | 本文首次肯定回答了一个开放问题，即是否可以在不允许错误抵消的情况下，通过将一种常见的安全约束模型扩展到具有多个约束的CMDPs，提出了一种可以实现次线性后悔的新方法。 |
| [^7] | [Diffusion Tempering Improves Parameter Estimation with Probabilistic Integrators for Ordinary Differential Equations](https://arxiv.org/abs/2402.12231) | 扩散回火是一种新颖的正则化技术，可改善概率数值方法在普通微分方程中的参数优化收敛性，实现对复杂动态系统中参数的可靠估计 |
| [^8] | [Simple, unified analysis of Johnson-Lindenstrauss with applications](https://arxiv.org/abs/2402.10232) | 这项工作提出了Johnson-Lindenstrauss（JL）引理的简单统一分析，简化和统一了各种构造，包括球形、高斯、二进制硬币和次高斯模型，通过创新性地将Hanson-Wright不等式拓展到高维度，标志着对数据固有几何的保持取得重大进展。 |
| [^9] | [Layerwise Proximal Replay: A Proximal Point Method for Online Continual Learning](https://arxiv.org/abs/2402.09542) | 这项工作针对在线连续学习中经验回放造成的优化不稳定问题进行了改进，提出了一种逐层近端回放（LPR）方法，通过优化几何的修改来平衡新数据和回放数据的学习，从而改善了回放式在线连续学习方法的准确性。 |
| [^10] | [SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks](https://arxiv.org/abs/2402.09025) | SLEB是一种通过消除冗余的Transformer块来优化LLM流程的新方法，它成功加速了LLM的推理过程。 |
| [^11] | [Global optimality under amenable symmetry constraints](https://arxiv.org/abs/2402.07613) | 该论文研究了在可接受的对称约束条件下的全局最优性问题，提出了一种满足对称性质的函数或度量，并通过引入轨道凸体和coycle等工具解决了这一问题。具体应用包括不变核均值嵌入和基于对称约束的运输方案最优性。这些结果与不变性检验的Hunt-Stein定理相关。 |
| [^12] | [Bounding the Excess Risk for Linear Models Trained on Marginal-Preserving, Differentially-Private, Synthetic Data](https://arxiv.org/abs/2402.04375) | 本文提出了在保持边缘一致的差分隐私合成数据上训练线性模型的过量风险的新界限，为连续和Lipschitz损失函数提供了上界和下界。 |
| [^13] | [Multi-View Symbolic Regression](https://arxiv.org/abs/2402.04298) | 多视角符号回归(MvSR)是一种同时考虑多个数据集的符号回归方法，能够找到一个参数化解来准确拟合所有数据集，解决了传统方法无法处理不同实验设置的问题。 |
| [^14] | [Learning from Teaching Regularization: Generalizable Correlations Should be Easy to Imitate](https://arxiv.org/abs/2402.02769) | 通过从教学中学习（LoT）技术，我们提出了一种深度神经网络正则化技术，能够通过引入辅助学生模型来提升主模型的泛化性能。实验证明，LoT能有效识别具有泛化和可教授关系的信息。 |
| [^15] | [Robust Multi-Task Learning with Excess Risks](https://arxiv.org/abs/2402.02009) | 提出了一种具有过多风险的多任务学习（ExcessMTL）方法，根据任务到收敛的距离来更新任务权重，以克服存在标签噪声时现有方法的限制。 |
| [^16] | [Layerwise complexity-matched learning yields an improved model of cortical area V2](https://arxiv.org/abs/2312.11436) | 通过分层复杂度匹配学习，我们开发了一种自下而上的自监督训练方法，最大化了特征相似性同时在不同位置的补丁上解除特征相关性。 |
| [^17] | [SparQ Attention: Bandwidth-Efficient LLM Inference](https://arxiv.org/abs/2312.04985) | SparQ Attention通过减少注意力块内存带宽需求的技术，从而增加LLMs推理的吞吐量，同时保持模型准确性。 |
| [^18] | [Algorithms for Non-Negative Matrix Factorization on Noisy Data With Negative Values](https://arxiv.org/abs/2311.04855) | 本文提出了两种算法，Shift-NMF和Nearly-NMF，可以处理带有负值的嘈杂数据，在不引入正的偏移量的情况下正确恢复非负信号。 |
| [^19] | [Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?.](http://arxiv.org/abs/2401.12492) | 本研究比较了以群体属性、个体用户和组合方法来模拟人的上下文。合并群体和个体特征显著提高了用户级回归任务的性能，而模拟个体用户则显著提高了单个文档级分类任务的性能。 |
| [^20] | [Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis.](http://arxiv.org/abs/2401.11447) | 本研究利用新颖的机器学习模型，准确预测患者的非依从风险和相关的系统症状评分，为长期过敏性鼻炎亚卡激素皮下免疫治疗的管理提供了一种新的方法。 |
| [^21] | [Improved motif-scaffolding with SE(3) flow matching.](http://arxiv.org/abs/2401.04082) | 本文提出了一种使用SE(3)流匹配的图案支架方法，通过图案摊销和图案引导两种方法，可以生成结构上多样性更高的支架，与之前的最先进方法相比，成功率相当甚至更高。 |
| [^22] | [Locating Cross-Task Sequence Continuation Circuits in Transformers.](http://arxiv.org/abs/2311.04131) | 通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。 |
| [^23] | [Adversarial Examples in the Physical World: A Survey.](http://arxiv.org/abs/2311.01473) | 本综述系统地研究了物理世界中的对抗样本（PAEs）的特点，并提出了基于其特征的全面分析和分类框架，涵盖了100多个研究，以填补对PAEs独特特征的现有研究不足。 |
| [^24] | [Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference.](http://arxiv.org/abs/2310.16975) | 提出了两种神经网络方法来逼近静态和动态条件最优传输问题的解，实现了对条件概率分布的采样和密度估计，适用于贝叶斯推断。算法利用神经网络参数化传输映射以提高可扩展性。 |
| [^25] | [Jailbreaking Black Box Large Language Models in Twenty Queries.](http://arxiv.org/abs/2310.08419) | 这项研究提出了一个名为PAIR的算法，可以在只能黑盒访问大语言模型的情况下生成破解，无需人工干预。实证表明，PAIR通常只需要少于二十个查询来生成破解，是现有算法的数个数量级更高效。 |
| [^26] | [Leveraging Hierarchical Feature Sharing for Efficient Dataset Condensation.](http://arxiv.org/abs/2310.07506) | 本文提出了一种利用分层特征共享的数据参数化架构（HMN），旨在更高效地压缩数据。通过将数据存储在三层结构中，HMN能够捕捉到数据集级别、类别级别和样本级别的特征。 |
| [^27] | [Data Augmentation through Pseudolabels in Automatic Region Based Coronary Artery Segmentation for Disease Diagnosis.](http://arxiv.org/abs/2310.05990) | 这项研究引入了伪标签作为数据增强技术，通过改善基准Yolo模型的性能，提高了冠状动脉分割的效果。 |
| [^28] | [DeepHGCN: Toward Deeper Hyperbolic Graph Convolutional Networks.](http://arxiv.org/abs/2310.02027) | DeepHGCN是一个具有深层架构的双曲图卷积网络，通过引入新的双曲特征转换层和正则化技术，实现了计算效率的极大改进和过度平滑问题的显著减轻。 |
| [^29] | [Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection.](http://arxiv.org/abs/2310.00161) | 这项研究提出了一种面向检测的图像-文本预训练方法，旨在弥合图像级预训练和开放词汇目标检测之间的差距。通过检测器架构和对比损失，该方法能够从噪声图像-文本对中学习到新出现的物体-语义线索，并提出了一种平移窗口学习方法来改进主干网络的表示。在LVIS开放词汇检测基准上，该方法取得了显著优于其他方法的40.4的掩码AP$_r$结果。 |
| [^30] | [Discovering environments with XRM.](http://arxiv.org/abs/2309.16748) | 本文提出了一种用于发现环境的算法 XRM，它通过训练两个孪生网络，每个网络从训练数据的一半中学习，并模仿其兄弟网络的错误分类，解决了现有方法需要依赖人工注释环境信息的问题。 |
| [^31] | [Samplable Anonymous Aggregation for Private Federated Data Analysis.](http://arxiv.org/abs/2307.15017) | 本论文在解决每个设备持有私有数据情况下的私有统计和私有联邦学习设计中，提出了一个简单的原语，以实现高效的算法，并在不需要强信任假设的情况下保护隐私。 |
| [^32] | [Cross-Validation Is All You Need: A Statistical Approach To Label Noise Estimation.](http://arxiv.org/abs/2306.13990) | 本论文提出了一种重复交叉验证(Repeated Cross-Validation)方法，通过构建噪声直方图并提出三种基于该直方图的方法来检测标签噪声并清理数据，解决了结果预测分析中的数据清洗问题。 |
| [^33] | [Addressing the Rank Degeneration in Sequential Recommendation via Singular Spectrum Smoothing.](http://arxiv.org/abs/2306.11986) | 本文提出了一种通过奇异谱平滑算法缓解顺序推荐中序列与项目排名退化问题的方法，并提出了SSA指标来评估该问题的严重性。 |
| [^34] | [Differentially Private Latent Diffusion Models.](http://arxiv.org/abs/2305.15759) | 本文提出使用差分隐私训练潜在扩散模型(LDMs)，通过预训练自编码器将高维像素空间转变为低维潜在空间实现更高效快速的DMs训练，并且通过只微调注意力模块减少了可训练参数的数量。 |
| [^35] | [DF2M: An Explainable Deep Bayesian Nonparametric Model for High-Dimensional Functional Time Series.](http://arxiv.org/abs/2305.14543) | 本文提出一种名为DF2M的模型，用于分析高维函数时间序列。该模型采用印度自助餐过程和深度核函数的多任务高斯过程捕捉时间动态，与传统的深度学习模型相比，DF2M提供了更好的可解释性和卓越的预测准确性。 |
| [^36] | [Conditional Generative Models are Provably Robust: Pointwise Guarantees for Bayesian Inverse Problems.](http://arxiv.org/abs/2303.15845) | 本文证明了条件生成模型对单个观测结果有健壮性 |
| [^37] | [Waveflow: Enforcing boundary conditions in smooth normalizing flows with application to fermionic wave functions.](http://arxiv.org/abs/2211.14839) | 本文介绍了一种新的处理归一化流拓扑问题、将边界条件应用于归一化流的技术、引入了可以被制作成任意次可微的 I-Spline 双射，并将这些技术用于创建一种基于归一化流的费米波函数 Ansatz，从而实现高效训练。 |
| [^38] | [Introduction to Online Nonstochastic Control.](http://arxiv.org/abs/2211.09619) | 介绍了一种新兴的在线非随机控制方法，通过在一组策略中寻找低后悔，获得对最优策略的近似。 |

# 详细

[^1]: 使用标记数据增强的测地插值方法学习蛋白质折叠的集体变量

    Learning Collective Variables for Protein Folding with Labeled Data Augmentation through Geodesic Interpolation

    [https://rss.arxiv.org/abs/2402.01542](https://rss.arxiv.org/abs/2402.01542)

    本实验提出了一种使用标记数据增强和测地插值方法学习蛋白质折叠的集体变量的策略，有效提高了采样效率，并在过渡态数据有限且嘈杂时表现优于基于分类器的方法。

    

    在分子动力学（MD）模拟中，通常通过增强采样技术来研究蛋白质折叠等罕见事件，其中大部分依赖于沿着加速发生的集体变量（CV）的定义。获得富有表达力的CV至关重要，但往往受到关于特定事件的信息不足的阻碍，例如从未折叠到折叠构象的转变。我们提出了一种模拟无关的数据增强策略，利用受物理启发的度量来生成类似蛋白质折叠转变的测地插值，从而提高采样效率，而无需真实的过渡态样本。通过利用插值进度参数，我们引入了基于回归的学习方案来构建CV模型，当过渡态数据有限且嘈杂时，该方法表现优于基于分类器的方法。

    In molecular dynamics (MD) simulations, rare events, such as protein folding, are typically studied by means of enhanced sampling techniques, most of which rely on the definition of a collective variable (CV) along which the acceleration occurs. Obtaining an expressive CV is crucial, but often hindered by the lack of information about the particular event, e.g., the transition from unfolded to folded conformation. We propose a simulation-free data augmentation strategy using physics-inspired metrics to generate geodesic interpolations resembling protein folding transitions, thereby improving sampling efficiency without true transition state samples. Leveraging interpolation progress parameters, we introduce a regression-based learning scheme for CV models, which outperforms classifier-based methods when transition state data is limited and noisy
    
[^2]: 场景图ViT：端到端的开放词汇视觉关系检测

    Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection

    [https://arxiv.org/abs/2403.14270](https://arxiv.org/abs/2403.14270)

    提出了一种简单高效的无解码器架构，用于开放词汇的视觉关系检测，通过Transformer-based图像编码器隐式建模对象之间的关系，使用注意力机制提取关系信息，在混合数据上进行端到端训练，实现了最先进的关系检测性能。

    

    视觉关系检测旨在识别图像中的对象及其关系。以往的方法通过在现有目标检测架构中添加单独的关系模块或解码器来处理此任务。这种分离增加了复杂性，阻碍了端到端训练，限制了性能。我们提出了一种简单且高效的无解码器架构，用于开放词汇的视觉关系检测。我们的模型由基于Transformer的图像编码器组成，将对象表示为标记，并隐含地建模它们的关系。为了提取关系信息，我们引入了一个注意力机制，选择可能形成关系的对象对。我们提供了一个单阶段的训练方法，可以在混合对象和关系检测数据上训练此模型。我们的方法在Visual Genome和大词汇GQA基准测试上实现了最先进的关系检测性能，可实现实时性。

    arXiv:2403.14270v1 Announce Type: cross  Abstract: Visual relationship detection aims to identify objects and their relationships in images. Prior methods approach this task by adding separate relationship modules or decoders to existing object detection architectures. This separation increases complexity and hinders end-to-end training, which limits performance. We propose a simple and highly efficient decoder-free architecture for open-vocabulary visual relationship detection. Our model consists of a Transformer-based image encoder that represents objects as tokens and models their relationships implicitly. To extract relationship information, we introduce an attention mechanism that selects object pairs likely to form a relationship. We provide a single-stage recipe to train this model on a mixture of object and relationship detection data. Our approach achieves state-of-the-art relationship detection performance on Visual Genome and on the large-vocabulary GQA benchmark at real-tim
    
[^3]: 手术员去偏见：神奇的权重及如何找到它们

    Debiasing surgeon: fantastic weights and how to find them

    [https://arxiv.org/abs/2403.14200](https://arxiv.org/abs/2403.14200)

    证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。

    

    现今一个日益关注的现象是算法偏见的出现，它可能导致不公平的模型。在深度学习领域，已经提出了几种去偏见的方法，采用更或多或少复杂的方法来阻止这些模型大规模地使用这些偏见。然而，一个问题出现了：这种额外的复杂性真的有必要吗？一个普通训练的模型是否已经包含了一些可以独立使用的“无偏子网络”，并且可以提出一个解决方案而不依赖于算法偏见？在这项工作中，我们展示了这样的子网络通常存在，并且可以从一个普通训练的模型中提取出来，而无需额外的训练。我们进一步验证了这种特定的架构无法学习特定的偏见，表明在深度神经网络中有可能通过架构上的对策来解决偏见问题。

    arXiv:2403.14200v1 Announce Type: cross  Abstract: Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic biases that can lead to unfair models, emerges. Several debiasing approaches have been proposed in the realm of deep learning, employing more or less sophisticated approaches to discourage these models from massively employing these biases. However, a question emerges: is this extra complexity really necessary? Is a vanilla-trained model already embodying some ``unbiased sub-networks'' that can be used in isolation and propose a solution without relying on the algorithmic biases? In this work, we show that such a sub-network typically exists, and can be extracted from a vanilla-trained model without requiring additional training. We further validate that such specific architecture is incapable of learning a specific bias, suggesting that there are possible architectural countermeasures to the problem of biases in deep neural networks.
    
[^4]: VFusion3D: 从视频扩散模型中学习可扩展的3D生成模型

    VFusion3D: Learning Scalable 3D Generative Models from Video Diffusion Models

    [https://arxiv.org/abs/2403.12034](https://arxiv.org/abs/2403.12034)

    利用预训练的视频扩散模型，本文提出了一个可生成大规模3D数据集的VFusion3D模型。

    

    本文提出了一种新颖的范式，利用预训练的视频扩散模型构建可扩展的3D生成模型。构建基础3D生成模型的主要障碍是3D数据的有限可用性。与图像、文本或视频不同，3D数据不容易获取且难以获得，这导致与其他类型数据的数量相比存在显着的规模差异。为了解决这个问题，我们提出使用一个通过大量文本、图像和视频训练的视频扩散模型作为3D数据的知识源。通过微调解锁其多视角生成能力，我们生成一个大规模的合成多视角数据集来训练前馈3D生成模型。

    arXiv:2403.12034v1 Announce Type: cross  Abstract: This paper presents a novel paradigm for building scalable 3D generative models utilizing pre-trained video diffusion models. The primary obstacle in developing foundation 3D generative models is the limited availability of 3D data. Unlike images, texts, or videos, 3D data are not readily accessible and are difficult to acquire. This results in a significant disparity in scale compared to the vast quantities of other types of data. To address this issue, we propose using a video diffusion model, trained with extensive volumes of text, images, and videos, as a knowledge source for 3D data. By unlocking its multi-view generative capabilities through fine-tuning, we generate a large-scale synthetic multi-view dataset to train a feed-forward 3D generative model. The proposed model, VFusion3D, trained on nearly 3M synthetic multi-view data, can generate a 3D asset from a single image in seconds and achieves superior performance when compare
    
[^5]: 朝着忠实解释：利用快捷方式发现来增强理性化

    Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery

    [https://arxiv.org/abs/2403.07955](https://arxiv.org/abs/2403.07955)

    本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化，并通过两种策略缓解利用快捷方式来组成理性化的问题，以及通过数据增强方法来补充已注释理性化数量的差距。

    

    人工智能领域神经网络的显著成功引发了有选择性的理性化。本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化。具体而言，SSR首先设计了一种快捷方式发现方法来检测几个潜在的快捷方式。然后，通过引入识别出的快捷方式，我们提出了两种策略来缓解利用快捷方式来组成理性化的问题。最后，我们开发了两种数据增强方法来弥补已注释理性化数量的差距。对真实世界数据集的广泛实验结果清楚地验证了这一方法的有效性。

    arXiv:2403.07955v1 Announce Type: cross  Abstract: The remarkable success in neural networks provokes the selective rationalization. It explains the prediction results by identifying a small subset of the inputs sufficient to support them. Since existing methods still suffer from adopting the shortcuts in data to compose rationales and limited large-scale annotated rationales by human, in this paper, we propose a Shortcuts-fused Selective Rationalization (SSR) method, which boosts the rationalization by discovering and exploiting potential shortcuts. Specifically, SSR first designs a shortcuts discovery approach to detect several potential shortcuts. Then, by introducing the identified shortcuts, we propose two strategies to mitigate the problem of utilizing shortcuts to compose rationales. Finally, we develop two data augmentations methods to close the gap in the number of annotated rationales. Extensive experimental results on real-world datasets clearly validate the effectiveness of
    
[^6]: 受限制MDP中的真正无悔学习

    Truly No-Regret Learning in Constrained MDPs

    [https://arxiv.org/abs/2402.15776](https://arxiv.org/abs/2402.15776)

    本文首次肯定回答了一个开放问题，即是否可以在不允许错误抵消的情况下，通过将一种常见的安全约束模型扩展到具有多个约束的CMDPs，提出了一种可以实现次线性后悔的新方法。

    

    受约束的马尔可夫决策过程（CMDPs）是在强化学习中建模安全约束的常见方式。目前用于高效解决CMDPs的最先进方法基于原始-对偶算法。对于这些算法，所有当前已知的后悔界都允许错误抵消——可以通过在一个回合中的约束违反来用严格的约束满足在另一个回合中。这使得在线学习过程不安全，因为它仅保证最终（混合）策略的安全性，而在学习过程中不保证安全。正如Efroni等人（2020年）指出的，原始-对偶算法是否可以在不允许错误抵消的情况下可证明地实现次线性后悔是一个开放问题。在本文中，我们给出了第一个肯定的答案。我们首先将关于正则化原始-对偶方案的最后迭代收敛性通用化到具有多个约束的CMDPs上。基于这一见解，我们提出了一种基于模型的原始

    arXiv:2402.15776v1 Announce Type: new  Abstract: Constrained Markov decision processes (CMDPs) are a common way to model safety constraints in reinforcement learning. State-of-the-art methods for efficiently solving CMDPs are based on primal-dual algorithms. For these algorithms, all currently known regret bounds allow for error cancellations -- one can compensate for a constraint violation in one round with a strict constraint satisfaction in another. This makes the online learning process unsafe since it only guarantees safety for the final (mixture) policy but not during learning. As Efroni et al. (2020) pointed out, it is an open question whether primal-dual algorithms can provably achieve sublinear regret if we do not allow error cancellations. In this paper, we give the first affirmative answer. We first generalize a result on last-iterate convergence of regularized primal-dual schemes to CMDPs with multiple constraints. Building upon this insight, we propose a model-based primal
    
[^7]: 扩散回火改善概率积分器对普通微分方程参数估计的效果

    Diffusion Tempering Improves Parameter Estimation with Probabilistic Integrators for Ordinary Differential Equations

    [https://arxiv.org/abs/2402.12231](https://arxiv.org/abs/2402.12231)

    扩散回火是一种新颖的正则化技术，可改善概率数值方法在普通微分方程中的参数优化收敛性，实现对复杂动态系统中参数的可靠估计

    

    普通微分方程（ODEs）被广泛应用于描述科学中的动态系统，但确定解释实验测量结果的参数是具有挑战性的。我们提出了扩散回火这一新的正则化技术，它针对ODEs中的概率数值方法，改善了梯度优化参数估计的收敛性。通过迭代减少概率积分器的一个噪声参数，所提出的方法更可靠地收敛到真实参数。我们证明了我们的方法对于不同复杂性的动态系统是有效的，并展示它对于具有实际相关参数数量的Hodgkin-Huxley模型获得可靠的参数估计。

    arXiv:2402.12231v1 Announce Type: new  Abstract: Ordinary differential equations (ODEs) are widely used to describe dynamical systems in science, but identifying parameters that explain experimental measurements is challenging. In particular, although ODEs are differentiable and would allow for gradient-based parameter optimization, the nonlinear dynamics of ODEs often lead to many local minima and extreme sensitivity to initial conditions. We therefore propose diffusion tempering, a novel regularization technique for probabilistic numerical methods which improves convergence of gradient-based parameter optimization in ODEs. By iteratively reducing a noise parameter of the probabilistic integrator, the proposed method converges more reliably to the true parameters. We demonstrate that our method is effective for dynamical systems of different complexity and show that it obtains reliable parameter estimates for a Hodgkin-Huxley model with a practically relevant number of parameters.
    
[^8]: Johnson-Lindenstrauss的简单统一分析及其应用

    Simple, unified analysis of Johnson-Lindenstrauss with applications

    [https://arxiv.org/abs/2402.10232](https://arxiv.org/abs/2402.10232)

    这项工作提出了Johnson-Lindenstrauss（JL）引理的简单统一分析，简化和统一了各种构造，包括球形、高斯、二进制硬币和次高斯模型，通过创新性地将Hanson-Wright不等式拓展到高维度，标志着对数据固有几何的保持取得重大进展。

    

    在这项工作中，我们提出了Johnson-Lindenstrauss（JL）引理的简单统一分析，这是处理高维数据至关重要的降维领域中的基石。我们的方法不仅简化了理解，还将各种构造统一到JL框架下，包括球形、高斯、二进制硬币和次高斯模型。这种简化和统一在保持数据固有几何的重要性方面取得了重大进展，对从流算法到强化学习等各种应用至关重要。值得注意的是，我们在这个简化框架内提出了球形构造有效性的第一个严格证明。我们贡献的核心是将Hanson-Wright不等式拓展到高维度，具有明确的常数，这标志着文献中质的飞跃。通过运用简单而强大的概率工具

    arXiv:2402.10232v1 Announce Type: new  Abstract: In this work, we present a simple and unified analysis of the Johnson-Lindenstrauss (JL) lemma, a cornerstone in the field of dimensionality reduction critical for managing high-dimensional data. Our approach not only simplifies the understanding but also unifies various constructions under the JL framework, including spherical, Gaussian, binary coin, and sub-Gaussian models. This simplification and unification make significant strides in preserving the intrinsic geometry of data, essential across diverse applications from streaming algorithms to reinforcement learning. Notably, we deliver the first rigorous proof of the spherical construction's effectiveness within this simplified framework. At the heart of our contribution is an innovative extension of the Hanson-Wright inequality to high dimensions, complete with explicit constants, marking a substantial leap in the literature. By employing simple yet powerful probabilistic tools and 
    
[^9]: 逐层近端回放：一种在线连续学习的近端点方法

    Layerwise Proximal Replay: A Proximal Point Method for Online Continual Learning

    [https://arxiv.org/abs/2402.09542](https://arxiv.org/abs/2402.09542)

    这项工作针对在线连续学习中经验回放造成的优化不稳定问题进行了改进，提出了一种逐层近端回放（LPR）方法，通过优化几何的修改来平衡新数据和回放数据的学习，从而改善了回放式在线连续学习方法的准确性。

    

    在在线连续学习中，神经网络逐步从非独立同分布的数据流中学习。几乎所有的在线连续学习方法都使用经验回放来同时防止灾难性遗忘和过度拟合先前的数据。我们的工作展示了这种方法的一个局限性：使用经验回放训练的网络往往具有不稳定的优化轨迹，影响其整体准确度。令人惊讶的是，即使回放缓冲区存储了所有先前的训练样本，这些不稳定性仍然存在，这表明这个问题与灾难性遗忘是无关的。我们通过对优化几何的简单修改来最小化这些不稳定性。我们的解决方案，逐层近端回放（LPR），在只允许逐渐改变过去数据的隐藏激活的同时，平衡了从新数据和回放数据中的学习。我们证明了LPR在基于回放的在线连续学习方法中持续改进。

    arXiv:2402.09542v1 Announce Type: new  Abstract: In online continual learning, a neural network incrementally learns from a non-i.i.d. data stream. Nearly all online continual learning methods employ experience replay to simultaneously prevent catastrophic forgetting and underfitting on past data. Our work demonstrates a limitation of this approach: networks trained with experience replay tend to have unstable optimization trajectories, impeding their overall accuracy. Surprisingly, these instabilities persist even when the replay buffer stores all previous training examples, suggesting that this issue is orthogonal to catastrophic forgetting. We minimize these instabilities through a simple modification of the optimization geometry. Our solution, Layerwise Proximal Replay (LPR), balances learning from new and replay data while only allowing for gradual changes in the hidden activation of past data. We demonstrate that LPR consistently improves replay-based online continual learning me
    
[^10]: SLEB: 通过冗余验证和消除Transformer块优化LLM的流程

    SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks

    [https://arxiv.org/abs/2402.09025](https://arxiv.org/abs/2402.09025)

    SLEB是一种通过消除冗余的Transformer块来优化LLM流程的新方法，它成功加速了LLM的推理过程。

    

    大型语言模型（LLM）在各种自然语言处理任务中证明了其高效性。然而，它们庞大的参数数量给实际部署带来了重大挑战。精简，一种旨在减小LLM大小和复杂度的技术，通过从网络中删除冗余组件提供了潜在解决方案。尽管精简有希望，但现有方法往往难以实现显著的端到端LLM推理加速。本文中，我们引入了SLEB，一种通过消除冗余的Transformer块来优化LLM流程的新方法。我们选择Transformer块作为精简的基本单位，因为LLM在相邻块的输出之间具有块级别的冗余和高相似性。这个选择使我们能够有效地增强LLM的处理速度。我们的实验证明，SLEB成功加速了LLM的推理过程。

    arXiv:2402.09025v1 Announce Type: new Abstract: Large language models (LLMs) have proven to be highly effective across various natural language processing tasks. However, their large number of parameters poses significant challenges for practical deployment. Pruning, a technique aimed at reducing the size and complexity of LLMs, offers a potential solution by removing redundant components from the network. Despite the promise of pruning, existing methods often struggle to achieve substantial end-to-end LLM inference speedup. In this paper, we introduce SLEB, a novel approach designed to streamline LLMs by eliminating redundant transformer blocks. We choose the transformer block as the fundamental unit for pruning, because LLMs exhibit block-level redundancy with high similarity between the outputs of neighboring blocks. This choice allows us to effectively enhance the processing speed of LLMs. Our experimental results demonstrate that SLEB successfully accelerates LLM inference without
    
[^11]: 在可接受的对称约束条件下的全局最优性

    Global optimality under amenable symmetry constraints

    [https://arxiv.org/abs/2402.07613](https://arxiv.org/abs/2402.07613)

    该论文研究了在可接受的对称约束条件下的全局最优性问题，提出了一种满足对称性质的函数或度量，并通过引入轨道凸体和coycle等工具解决了这一问题。具体应用包括不变核均值嵌入和基于对称约束的运输方案最优性。这些结果与不变性检验的Hunt-Stein定理相关。

    

    我们研究是否存在一种满足可接受变换群指定的对称性质的函数或度量，即同时满足以下两个条件：（1）最小化给定的凸性泛函或风险，（2）满足可容忍对称约束。这种对称性质的例子包括不变性、可变性或准不变性。我们的结果依赖于Stein和Le Cam的老思想，以及在可接受群的遍历定理中出现的近似群平均值。在凸分析中，一类称为轨道凸体的凸集显得至关重要，我们在非参数设置中确定了这类轨道凸体的性质。我们还展示了一个称为coycle的简单装置如何将不同形式的对称性转化为一个问题。作为应用，我们得出了关于不变核均值嵌入和在对称约束下运输方案最优性的Monge-Kantorovich定理的结果。我们还解释了与不变性检验的Hunt-Stein定理的联系。

    We ask whether there exists a function or measure that (1) minimizes a given convex functional or risk and (2) satisfies a symmetry property specified by an amenable group of transformations. Examples of such symmetry properties are invariance, equivariance, or quasi-invariance. Our results draw on old ideas of Stein and Le Cam and on approximate group averages that appear in ergodic theorems for amenable groups. A class of convex sets known as orbitopes in convex analysis emerges as crucial, and we establish properties of such orbitopes in nonparametric settings. We also show how a simple device called a cocycle can be used to reduce different forms of symmetry to a single problem. As applications, we obtain results on invariant kernel mean embeddings and a Monge-Kantorovich theorem on optimality of transport plans under symmetry constraints. We also explain connections to the Hunt-Stein theorem on invariant tests.
    
[^12]: 在保持边缘一致的差分隐私合成数据上训练线性模型的过量风险界限

    Bounding the Excess Risk for Linear Models Trained on Marginal-Preserving, Differentially-Private, Synthetic Data

    [https://arxiv.org/abs/2402.04375](https://arxiv.org/abs/2402.04375)

    本文提出了在保持边缘一致的差分隐私合成数据上训练线性模型的过量风险的新界限，为连续和Lipschitz损失函数提供了上界和下界。

    

    机器学习的广泛应用引发了人们对于模型可能揭示训练数据中个体的私密信息的担忧。为了防止敏感数据的泄露，我们考虑使用差分隐私的合成训练数据而不是真实训练数据来训练机器学习模型。合成数据的一个关键优点是能够保持原始分布的低阶边缘特征。我们的主要贡献是针对在这种合成数据上训练的线性模型，针对连续和Lipschitz损失函数提出了新的过量经验风险的上界和下界。我们在理论结果之外进行了大量实验。

    The growing use of machine learning (ML) has raised concerns that an ML model may reveal private information about an individual who has contributed to the training dataset. To prevent leakage of sensitive data, we consider using differentially-private (DP), synthetic training data instead of real training data to train an ML model. A key desirable property of synthetic data is its ability to preserve the low-order marginals of the original distribution. Our main contribution comprises novel upper and lower bounds on the excess empirical risk of linear models trained on such synthetic data, for continuous and Lipschitz loss functions. We perform extensive experimentation alongside our theoretical results.
    
[^13]: 多视角符号回归

    Multi-View Symbolic Regression

    [https://arxiv.org/abs/2402.04298](https://arxiv.org/abs/2402.04298)

    多视角符号回归(MvSR)是一种同时考虑多个数据集的符号回归方法，能够找到一个参数化解来准确拟合所有数据集，解决了传统方法无法处理不同实验设置的问题。

    

    符号回归(SR)搜索表示解释变量和响应变量之间关系的分析表达式。目前的SR方法假设从单个实验中提取的单个数据集。然而，研究人员经常面临来自不同设置的多个实验结果集。传统的SR方法可能无法找到潜在的表达式，因为每个实验的参数可能不同。在这项工作中，我们提出了多视角符号回归(MvSR)，它同时考虑多个数据集，模拟实验环境，并输出一个通用的参数化解。这种方法将评估的表达式适应每个独立数据集，并同时返回能够准确拟合所有数据集的参数函数族f(x; \theta)。我们使用从已知表达式生成的数据以及来自实际世界的数据来展示MvSR的有效性。

    Symbolic regression (SR) searches for analytical expressions representing the relationship between a set of explanatory and response variables. Current SR methods assume a single dataset extracted from a single experiment. Nevertheless, frequently, the researcher is confronted with multiple sets of results obtained from experiments conducted with different setups. Traditional SR methods may fail to find the underlying expression since the parameters of each experiment can be different. In this work we present Multi-View Symbolic Regression (MvSR), which takes into account multiple datasets simultaneously, mimicking experimental environments, and outputs a general parametric solution. This approach fits the evaluated expression to each independent dataset and returns a parametric family of functions f(x; \theta) simultaneously capable of accurately fitting all datasets. We demonstrate the effectiveness of MvSR using data generated from known expressions, as well as real-world data from 
    
[^14]: 从教学中学习正则化: 易于模仿的可推广关系

    Learning from Teaching Regularization: Generalizable Correlations Should be Easy to Imitate

    [https://arxiv.org/abs/2402.02769](https://arxiv.org/abs/2402.02769)

    通过从教学中学习（LoT）技术，我们提出了一种深度神经网络正则化技术，能够通过引入辅助学生模型来提升主模型的泛化性能。实验证明，LoT能有效识别具有泛化和可教授关系的信息。

    

    泛化仍然是机器学习中的一个核心挑战。在这项工作中，我们提出了一种新颖的深度神经网络正则化技术，即从教学中学习（Learning from Teaching，简称LoT），以增强泛化性能。受到人类捕捉简明抽象模式的能力的启发，我们假设可推广的关系更容易教授。LoT通过辅助学生模型来实现这个概念，通过提供反馈来训练主模型和改进主模型，以捕捉更多具有泛化和可教授关系的信息。我们在计算机视觉、自然语言处理和强化学习等多个领域进行的实验结果表明，引入LoT相比仅在原始训练数据上训练模型带来了显著的好处。这表明了LoT在识别可推广信息方面的有效性。

    Generalization remains a central challenge in machine learning. In this work, we propose Learning from Teaching (LoT), a novel regularization technique for deep neural networks to enhance generalization. Inspired by the human ability to capture concise and abstract patterns, we hypothesize that generalizable correlations are expected to be easier to teach. LoT operationalizes this concept to improve the generalization of the main model with auxiliary student learners. The student learners are trained by the main model and improve the main model to capture more generalizable and teachable correlations by providing feedback. Our experimental results across several domains, including Computer Vision, Natural Language Processing, and Reinforcement Learning, demonstrate that the introduction of LoT brings significant benefits compared to merely training models on the original training data. It suggests the effectiveness of LoT in identifying generalizable information without falling into th
    
[^15]: 具有过多风险的鲁棒多任务学习

    Robust Multi-Task Learning with Excess Risks

    [https://arxiv.org/abs/2402.02009](https://arxiv.org/abs/2402.02009)

    提出了一种具有过多风险的多任务学习（ExcessMTL）方法，根据任务到收敛的距离来更新任务权重，以克服存在标签噪声时现有方法的限制。

    

    多任务学习（MTL）通过优化所有任务损失的凸组合来考虑为多个任务学习一个联合模型。为了解决优化问题，现有方法使用自适应权重更新方案，根据各自的损失动态调整任务权重，以优先考虑困难任务。然而，在存在标签噪声的情况下，这些算法会面临巨大挑战，因为过多的权重往往被分配给具有相对较大贝叶斯最优误差的噪声任务，从而掩盖其他任务并导致整体性能下降。为了克服这个限制，我们提出了具有过多风险的多任务学习（ExcessMTL），这是一种基于过多风险的任务平衡方法，通过任务到收敛的距离来更新任务权重。直观来说，ExcessMTL将更高的权重分配给较差训练的距离收敛较远的任务。为了估计过多风险，我们开发了一种高效而准确的方法。

    Multi-task learning (MTL) considers learning a joint model for multiple tasks by optimizing a convex combination of all task losses. To solve the optimization problem, existing methods use an adaptive weight updating scheme, where task weights are dynamically adjusted based on their respective losses to prioritize difficult tasks. However, these algorithms face a great challenge whenever label noise is present, in which case excessive weights tend to be assigned to noisy tasks that have relatively large Bayes optimal errors, thereby overshadowing other tasks and causing performance to drop across the board. To overcome this limitation, we propose Multi-Task Learning with Excess Risks (ExcessMTL), an excess risk-based task balancing method that updates the task weights by their distances to convergence instead. Intuitively, ExcessMTL assigns higher weights to worse-trained tasks that are further from convergence. To estimate the excess risks, we develop an efficient and accurate method 
    
[^16]: 分层复杂度匹配学习产生了改进的大脑皮层V2区模型

    Layerwise complexity-matched learning yields an improved model of cortical area V2

    [https://arxiv.org/abs/2312.11436](https://arxiv.org/abs/2312.11436)

    通过分层复杂度匹配学习，我们开发了一种自下而上的自监督训练方法，最大化了特征相似性同时在不同位置的补丁上解除特征相关性。

    

    人类识别复杂视觉模式的能力是通过顺次区域在腹侧视觉皮层中执行的变换所形成的。最近的端到端训练的深度神经网络逼近了人类的能力，并且提供了迄今为止对层次结构的后期神经反应的最佳描述。然而，与传统的手工设计模型相比，或者与优化编码效率或预测的模型相比，这些网络对前期阶段提供了较差的描述。此外，用于端到端学习的梯度反向传播通常被认为在生物上是不切实际的。在这里，我们通过开发一种自下而上的自监督训练方法，独立地作用于连续层，从而克服了这两个限制。具体地，我们最大化了对局部变形自然图像补丁对之间的特征相似性，并在采样自其他位置的补丁时使特征去相关。

    arXiv:2312.11436v2 Announce Type: replace-cross  Abstract: Human ability to recognize complex visual patterns arises through transformations performed by successive areas in the ventral visual cortex. Deep neural networks trained end-to-end for object recognition approach human capabilities, and offer the best descriptions to date of neural responses in the late stages of the hierarchy. But these networks provide a poor account of the early stages, compared to traditional hand-engineered models, or models optimized for coding efficiency or prediction. Moreover, the gradient backpropagation used in end-to-end learning is generally considered to be biologically implausible. Here, we overcome both of these limitations by developing a bottom-up self-supervised training methodology that operates independently on successive layers. Specifically, we maximize feature similarity between pairs of locally-deformed natural image patches, while decorrelating features across patches sampled from oth
    
[^17]: SparQ注意力：高效带宽的LLM推理

    SparQ Attention: Bandwidth-Efficient LLM Inference

    [https://arxiv.org/abs/2312.04985](https://arxiv.org/abs/2312.04985)

    SparQ Attention通过减少注意力块内存带宽需求的技术，从而增加LLMs推理的吞吐量，同时保持模型准确性。

    

    生成式大语言模型（LLMs）开创了许多新可能性，但由于其巨大的计算需求，它们的普遍使用仍然具有挑战性。我们引入了SparQ注意力，一种通过选择性获取缓存历史来减少注意力块内存带宽需求的技术，从而增加了LLMs的推理吞吐量。

    arXiv:2312.04985v2 Announce Type: replace  Abstract: Generative large language models (LLMs) have opened up numerous novel possibilities, but due to their significant computational requirements their ubiquitous use remains challenging. Some of the most useful applications require processing large numbers of samples at a time and using long contexts, both significantly increasing the memory communication load of the models. We introduce SparQ Attention, a technique for increasing the inference throughput of LLMs by reducing the memory bandwidth requirements within the attention blocks through selective fetching of the cached history. Our proposed technique can be applied directly to off-the-shelf LLMs during inference, without requiring any modification to the pre-training setup or additional fine-tuning. We show how SparQ Attention can decrease the attention memory bandwidth requirements up to eight times without any loss in accuracy by evaluating Llama 2 and Pythia models on a wide ra
    
[^18]: 用于处理带有负值的嘈杂数据的非负矩阵分解算法

    Algorithms for Non-Negative Matrix Factorization on Noisy Data With Negative Values

    [https://arxiv.org/abs/2311.04855](https://arxiv.org/abs/2311.04855)

    本文提出了两种算法，Shift-NMF和Nearly-NMF，可以处理带有负值的嘈杂数据，在不引入正的偏移量的情况下正确恢复非负信号。

    

    非负矩阵分解（NMF）是一种降维技术，在分析嘈杂数据，特别是天文数据方面表现出了潜力。在这些数据集中，由于噪声，观测数据可能包含负值，即使真实的物理信号严格为正。以往的NMF工作未以统计一致的方式处理负数据，这在低信噪比数据中出现许多负值时会变得棘手。在本文中，我们提出了两种算法，Shift-NMF和Nearly-NMF，可以处理输入数据的嘈杂性，并消除任何引入的负值。这两种算法都使用负数据空间而不进行截取，并且在消除负数据时不会引入正的偏移量。我们在简单和更现实的示例上进行了数值演示，并证明了这两种算法具有单调性。

    arXiv:2311.04855v2 Announce Type: replace-cross  Abstract: Non-negative matrix factorization (NMF) is a dimensionality reduction technique that has shown promise for analyzing noisy data, especially astronomical data. For these datasets, the observed data may contain negative values due to noise even when the true underlying physical signal is strictly positive. Prior NMF work has not treated negative data in a statistically consistent manner, which becomes problematic for low signal-to-noise data with many negative values. In this paper we present two algorithms, Shift-NMF and Nearly-NMF, that can handle both the noisiness of the input data and also any introduced negativity. Both of these algorithms use the negative data space without clipping, and correctly recover non-negative signals without any introduced positive offset that occurs when clipping negative data. We demonstrate this numerically on both simple and more realistic examples, and prove that both algorithms have monotoni
    
[^19]: 比较以人为中心的语言建模：模拟群体、个体特点还是两者兼顾？

    Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?. (arXiv:2401.12492v1 [cs.CL])

    [http://arxiv.org/abs/2401.12492](http://arxiv.org/abs/2401.12492)

    本研究比较了以群体属性、个体用户和组合方法来模拟人的上下文。合并群体和个体特征显著提高了用户级回归任务的性能，而模拟个体用户则显著提高了单个文档级分类任务的性能。

    

    自然语言处理在将人的上下文纳入其模型中取得了进展，但使用群体属性（如45岁以上的人群）还是模拟个体人物更有效的问题尚未确定。群体属性在技术上更容易实现，但是过于粗糙：并非所有45岁以上的人都以相同的方式书写。相反，模拟个体人物能够捕捉每个人身份的复杂性，允许更个性化的表示，但我们可能需要模拟无限数量的用户并且需要可能无法获取的数据。我们比较了通过群体属性、个体用户和组合方法来模拟人的上下文。将群体和个体特征结合起来，显著提高了基于用户文档的用户级回归任务（如年龄估计或个性评估）的性能。模拟个体用户显著提高了单个文档级分类任务（如立场和主题检测）的性能。

    Natural language processing has made progress in incorporating human context into its models, but whether it is more effective to use group-wise attributes (e.g., over-45-year-olds) or model individuals remains open. Group attributes are technically easier but coarse: not all 45-year-olds write the same way. In contrast, modeling individuals captures the complexity of each person's identity. It allows for a more personalized representation, but we may have to model an infinite number of users and require data that may be impossible to get. We compare modeling human context via group attributes, individual users, and combined approaches. Combining group and individual features significantly benefits user-level regression tasks like age estimation or personality assessment from a user's documents. Modeling individual users significantly improves the performance of single document-level classification tasks like stance and topic detection. We also find that individual-user modeling does w
    
[^20]: 预测过敏性鼻炎亚卡激素皮下免疫治疗中患者依从性的序列模型

    Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis. (arXiv:2401.11447v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11447](http://arxiv.org/abs/2401.11447)

    本研究利用新颖的机器学习模型，准确预测患者的非依从风险和相关的系统症状评分，为长期过敏性鼻炎亚卡激素皮下免疫治疗的管理提供了一种新的方法。

    

    目标：皮下免疫治疗(SCIT)是过敏性鼻炎的长效因果治疗。如何提高患者对变应原免疫治疗(AIT)的依从性以最大化治疗效果，在AIT管理中起着至关重要的作用。本研究旨在利用新颖的机器学习模型，准确预测患者的非依从风险和相关的系统症状评分，为长期AIT的管理提供一种新的方法。方法：本研究开发和分析了两种模型，序列潜在行为者-评论家模型(SLAC)和长短期记忆模型(LSTM)，并基于评分和依从性预测能力进行评估。结果：在排除第一时间步的偏倚样本后，SLAC模型的预测依从准确率为60%-72%，而LSTM模型的准确率为66%-84%，根据时间步长的不同而变化。SLAC模型的均方根误差(RMSE)范围在0.93到2.22之间，而LSTM模型的RMSE范围在...

    Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis. How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of patients and related systematic symptom scores, to provide a novel approach in the management of long-term AIT.  Methods: The research develops and analyzes two models, Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on scoring and adherence prediction capabilities.  Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from $60\,\%$ to $72\%$, and for LSTM models, it is $66\,\%$ to $84\,\%$, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and $2.22$, while for L
    
[^21]: 使用SE(3)流匹配改进了图案支架技术

    Improved motif-scaffolding with SE(3) flow matching. (arXiv:2401.04082v1 [q-bio.QM])

    [http://arxiv.org/abs/2401.04082](http://arxiv.org/abs/2401.04082)

    本文提出了一种使用SE(3)流匹配的图案支架方法，通过图案摊销和图案引导两种方法，可以生成结构上多样性更高的支架，与之前的最先进方法相比，成功率相当甚至更高。

    

    蛋白质设计通常从一个图案的期望功能开始，图案支架旨在构建一个功能性蛋白质。最近，生成模型在设计各种图案的支架方面取得了突破性的成功。然而，生成的支架往往缺乏结构多样性，这可能会影响湿实验验证的成功。在这项工作中，我们将FrameFlow，一种用于蛋白质主链生成的SE(3)流匹配模型扩展到使用两种互补的方法进行图案支架。第一种方法是图案摊销，即使用数据增强策略，将FrameFlow训练为以图案为输入。第二种方法是图案引导，它使用FrameFlow的条件分数估计进行支架构建，并且不需要额外的训练。这两种方法的成功率与之前的最先进方法相当或更高，并且可以产生结构上多样性更高2.5倍的支架。

    Protein design often begins with knowledge of a desired function from a motif which motif-scaffolding aims to construct a functional protein around. Recently, generative models have achieved breakthrough success in designing scaffolds for a diverse range of motifs. However, the generated scaffolds tend to lack structural diversity, which can hinder success in wet-lab validation. In this work, we extend FrameFlow, an SE(3) flow matching model for protein backbone generation, to perform motif-scaffolding with two complementary approaches. The first is motif amortization, in which FrameFlow is trained with the motif as input using a data augmentation strategy. The second is motif guidance, which performs scaffolding using an estimate of the conditional score from FrameFlow, and requires no additional training. Both approaches achieve an equivalent or higher success rate than previous state-of-the-art methods, with 2.5 times more structurally diverse scaffolds. Code: https://github.com/ mi
    
[^22]: 在Transformer中定位跨任务序列继续电路

    Locating Cross-Task Sequence Continuation Circuits in Transformers. (arXiv:2311.04131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04131](http://arxiv.org/abs/2311.04131)

    通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。

    

    虽然Transformer模型在语言任务上展现出强大的能力，但其复杂的架构使其难以解释。最近的研究旨在将Transformer模型还原为可读的电路表示，用于实现算法功能。我们通过分析和比较类似的序列继续任务的电路来扩展这项研究，其中包括数字、数字词和月份的递增序列。通过应用电路分析技术，我们确定了负责检测序列成员和预测序列中下一个成员的关键子电路。我们的分析揭示了语义相关序列依赖于具有类似作用的共享电路子图。总体而言，记录共享的计算结构能够更好地预测模型行为，识别错误，并进行更安全的编辑过程。这种对Transformer的机械理解是构建更健壮、调试和编辑更安全的模型的关键一步。

    While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust,
    
[^23]: 物理世界中的对抗样本：一项综述

    Adversarial Examples in the Physical World: A Survey. (arXiv:2311.01473v1 [cs.CV])

    [http://arxiv.org/abs/2311.01473](http://arxiv.org/abs/2311.01473)

    本综述系统地研究了物理世界中的对抗样本（PAEs）的特点，并提出了基于其特征的全面分析和分类框架，涵盖了100多个研究，以填补对PAEs独特特征的现有研究不足。

    

    深度神经网络（DNNs）对对抗样本表现出高度的脆弱性。除了在数字世界中的攻击外，对抗样本在物理世界中的实际影响提出了重大挑战和安全性问题。然而，当前对物理对抗样本（PAEs）的研究缺乏对其独特特征的全面理解，导致其重要性和理解的局限性。本文通过在训练、制造和重采样过程中全面考察PAEs的特点来弥补这一差距。通过分析物理对抗攻击之间的联系，我们确定制造和重采样是PAEs中独特属性和特殊性的主要来源。利用这一知识，我们基于其特定特征开发了一个全面的PAEs分析和分类框架，涵盖了100多个物理对抗世界研究的研究。

    Deep neural networks (DNNs) have demonstrated high vulnerability to adversarial examples. Besides the attacks in the digital world, the practical implications of adversarial examples in the physical world present significant challenges and safety concerns. However, current research on physical adversarial examples (PAEs) lacks a comprehensive understanding of their unique characteristics, leading to limited significance and understanding. In this paper, we address this gap by thoroughly examining the characteristics of PAEs within a practical workflow encompassing training, manufacturing, and re-sampling processes. By analyzing the links between physical adversarial attacks, we identify manufacturing and re-sampling as the primary sources of distinct attributes and particularities in PAEs. Leveraging this knowledge, we develop a comprehensive analysis and classification framework for PAEs based on their specific characteristics, covering over 100 studies on physical-world adversarial e
    
[^24]: 条件最优传输的高效神经网络方法及贝叶斯推断中的应用

    Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference. (arXiv:2310.16975v1 [stat.ML])

    [http://arxiv.org/abs/2310.16975](http://arxiv.org/abs/2310.16975)

    提出了两种神经网络方法来逼近静态和动态条件最优传输问题的解，实现了对条件概率分布的采样和密度估计，适用于贝叶斯推断。算法利用神经网络参数化传输映射以提高可扩展性。

    

    我们提出了两种神经网络方法，分别逼近静态和动态条件最优传输问题的解。这两种方法可以对条件概率分布进行采样和密度估计，这是贝叶斯推断中的核心任务。我们的方法将目标条件分布表示为可处理的参考分布的转换，因此属于测度传输的框架。在该框架中，COT映射是一个典型的选择，具有唯一性和单调性等可取的属性。然而，相关的COT问题在中等维度下计算具有挑战性。为了提高可扩展性，我们的数值算法利用神经网络对COT映射进行参数化。我们的方法充分利用了COT问题的静态和动态表达形式的结构。PCP-Map将条件传输映射建模为部分输入凸神经网络（PICNN）的梯度。

    We present two neural network approaches that approximate the solutions of static and dynamic conditional optimal transport (COT) problems, respectively. Both approaches enable sampling and density estimation of conditional probability distributions, which are core tasks in Bayesian inference. Our methods represent the target conditional distributions as transformations of a tractable reference distribution and, therefore, fall into the framework of measure transport. COT maps are a canonical choice within this framework, with desirable properties such as uniqueness and monotonicity. However, the associated COT problems are computationally challenging, even in moderate dimensions. To improve the scalability, our numerical algorithms leverage neural networks to parameterize COT maps. Our methods exploit the structure of the static and dynamic formulations of the COT problem. PCP-Map models conditional transport maps as the gradient of a partially input convex neural network (PICNN) and 
    
[^25]: 在二十个查询中破解黑盒大语言模型

    Jailbreaking Black Box Large Language Models in Twenty Queries. (arXiv:2310.08419v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.08419](http://arxiv.org/abs/2310.08419)

    这项研究提出了一个名为PAIR的算法，可以在只能黑盒访问大语言模型的情况下生成破解，无需人工干预。实证表明，PAIR通常只需要少于二十个查询来生成破解，是现有算法的数个数量级更高效。

    

    大语言模型（LLMs）与人类价值的一致性越来越受关注。然而，这类模型的一致性容易受到对抗性破解的影响，从而迫使LLMs超越其安全防护措施。因此，识别这些漏洞对于理解固有弱点并防止未来的不当使用至关重要。为此，我们提出了Prompt Automatic Iterative Refinement（PAIR），这是一种仅通过对LLM进行黑盒访问的算法生成语义破解。PAIR受到社会工程攻击的启发，使用攻击者LLM自动生成针对目标LLM的破解，无需人工干预。攻击者LLM通过迭代查询目标LLM来更新和改进候选破解。在实证上，PAIR通常只需要少于二十个查询来生成破解，这比现有算法高效数个数量级。PAIR还实现了有竞争力的破解效果。

    There is growing interest in ensuring that large language models (LLMs) align with human values. However, the alignment of such models is vulnerable to adversarial jailbreaks, which coax LLMs into overriding their safety guardrails. The identification of these vulnerabilities is therefore instrumental in understanding inherent weaknesses and preventing future misuse. To this end, we propose Prompt Automatic Iterative Refinement (PAIR), an algorithm that generates semantic jailbreaks with only black-box access to an LLM. PAIR -- which is inspired by social engineering attacks -- uses an attacker LLM to automatically generate jailbreaks for a separate targeted LLM without human intervention. In this way, the attacker LLM iteratively queries the target LLM to update and refine a candidate jailbreak. Empirically, PAIR often requires fewer than twenty queries to produce a jailbreak, which is orders of magnitude more efficient than existing algorithms. PAIR also achieves competitive jailbrea
    
[^26]: 利用分层特征共享进行高效数据集压缩

    Leveraging Hierarchical Feature Sharing for Efficient Dataset Condensation. (arXiv:2310.07506v1 [cs.CV])

    [http://arxiv.org/abs/2310.07506](http://arxiv.org/abs/2310.07506)

    本文提出了一种利用分层特征共享的数据参数化架构（HMN），旨在更高效地压缩数据。通过将数据存储在三层结构中，HMN能够捕捉到数据集级别、类别级别和样本级别的特征。

    

    在真实世界数据集中，数据压缩（DC）旨在合成一个显著较小的数据集，以高性能进行模型训练。最近的研究提出使用数据参数化增强DC，将数据压缩为参数化的数据容器而不是像素空间。数据参数化的直觉是编码图像的共享特征，以避免额外的存储成本。本文认识到由于分类系统的内在分层结构，图像以分层方式共享共同的特征，这是当前数据参数化方法所忽视的。为了更好地使DC与这种分层性质对齐，并在数据容器内部鼓励更高效的信息共享，我们提出了一种新颖的数据参数化架构，分层记忆网络（HMN）。HMN将压缩数据存储在三层结构中，表示数据集级别、类别级别和样本级别的特征。

    Given a real-world dataset, data condensation (DC) aims to synthesize a significantly smaller dataset that captures the knowledge of this dataset for model training with high performance. Recent works propose to enhance DC with data parameterization, which condenses data into parameterized data containers rather than pixel space. The intuition behind data parameterization is to encode shared features of images to avoid additional storage costs. In this paper, we recognize that images share common features in a hierarchical way due to the inherent hierarchical structure of the classification system, which is overlooked by current data parameterization methods. To better align DC with this hierarchical nature and encourage more efficient information sharing inside data containers, we propose a novel data parameterization architecture, Hierarchical Memory Network (HMN). HMN stores condensed data in a three-tier structure, representing the dataset-level, class-level, and instance-level fea
    
[^27]: 数据增强在自动区域性冠状动脉分割中的应用：伪标签法用于疾病诊断

    Data Augmentation through Pseudolabels in Automatic Region Based Coronary Artery Segmentation for Disease Diagnosis. (arXiv:2310.05990v1 [eess.IV])

    [http://arxiv.org/abs/2310.05990](http://arxiv.org/abs/2310.05990)

    这项研究引入了伪标签作为数据增强技术，通过改善基准Yolo模型的性能，提高了冠状动脉分割的效果。

    

    冠状动脉疾病（CAD）是可预防的主要死亡和残疾原因之一。这些疾病的诊断通常困难且资源密集。血管造影图像中的动脉分割已经演变成为一种辅助工具，可以帮助临床医生进行准确的诊断。然而，由于数据量有限且构建数据集的困难，分割任务一直很具挑战性。在本研究中，我们引入了使用伪标签作为数据增强技术来改善基准Yolo模型性能的思想。该方法在验证数据集中将基线的F1分数提高了9％，在测试数据集中提高了3％。

    Coronary Artery Diseases(CADs) though preventable are one of the leading causes of death and disability. Diagnosis of these diseases is often difficult and resource intensive. Segmentation of arteries in angiographic images has evolved as a tool for assistance, helping clinicians in making accurate diagnosis. However, due to the limited amount of data and the difficulty in curating a dataset, the task of segmentation has proven challenging. In this study, we introduce the idea of using pseudolabels as a data augmentation technique to improve the performance of the baseline Yolo model. This method increases the F1 score of the baseline by 9% in the validation dataset and by 3% in the test dataset.
    
[^28]: DeepHGCN：朝着更深的双曲图卷积网络

    DeepHGCN: Toward Deeper Hyperbolic Graph Convolutional Networks. (arXiv:2310.02027v1 [cs.LG])

    [http://arxiv.org/abs/2310.02027](http://arxiv.org/abs/2310.02027)

    DeepHGCN是一个具有深层架构的双曲图卷积网络，通过引入新的双曲特征转换层和正则化技术，实现了计算效率的极大改进和过度平滑问题的显著减轻。

    

    双曲图卷积网络（HGCN）在提取分层图信息方面展示了巨大潜力。然而，由于昂贵的双曲操作和随着深度增加的过度平滑问题，现有的HGCN受限于浅层架构。尽管在GCNs中已经应用了一些方法来减轻过度平滑问题，但是开发双曲治疗方法面临着不同的挑战，因为操作必须经过精心设计以适应双曲性质。解决以上挑战，本文提出了DeepHGCN，这是第一个具有显著提高计算效率和大大减轻过度平滑效果的深层多层HGCN架构。DeepHGCN具有两个深层HGCN的关键因素：（1）一种新颖的双曲特征转换层，能够实现快速而准确的线性映射；（2）通过有效的双曲残差连接和权重和特征的正则化技术来促进。

    Hyperbolic graph convolutional networks (HGCN) have demonstrated significant potential in extracting information from hierarchical graphs. However, existing HGCNs are limited to shallow architectures, due to the expensive hyperbolic operations and the over-smoothing issue as depth increases. Although in GCNs, treatments have been applied to alleviate over-smoothing, developing a hyperbolic therapy presents distinct challenges since operations should be carefully designed to fit the hyperbolic nature. Addressing the above challenges, in this work, we propose DeepHGCN, the first deep multi-layer HGCN architecture with dramatically improved computational efficiency and substantially alleviated over-smoothing effect. DeepHGCN presents two key enablers of deep HGCNs: (1) a novel hyperbolic feature transformation layer that enables fast and accurate linear maps; and (2) Techniques such as hyperbolic residual connections and regularization for both weights and features facilitated by an effic
    
[^29]: 面向检测的图像-文本预训练方法用于开放词汇检测

    Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection. (arXiv:2310.00161v1 [cs.CV])

    [http://arxiv.org/abs/2310.00161](http://arxiv.org/abs/2310.00161)

    这项研究提出了一种面向检测的图像-文本预训练方法，旨在弥合图像级预训练和开放词汇目标检测之间的差距。通过检测器架构和对比损失，该方法能够从噪声图像-文本对中学习到新出现的物体-语义线索，并提出了一种平移窗口学习方法来改进主干网络的表示。在LVIS开放词汇检测基准上，该方法取得了显著优于其他方法的40.4的掩码AP$_r$结果。

    

    我们提出了一种基于面向检测的图像-文本预训练的新的开放词汇检测方法，以填补图像级预训练和开放词汇目标检测之间的差距。在预训练阶段，我们用检测器架构替代常用的分类架构，通过使检测器头部能够从噪声图像-文本对中学习，更好地满足检测的区域级识别需求。我们的方法只使用标准的对比损失而不使用伪标签，是对对比学习方法的简单而有效的扩展，可以学习到新出现的物体-语义线索。此外，我们提出了一种基于窗口注意力的平移窗口学习方法，使主干网络的表示更加鲁棒、平移不变，并且不受窗口模式的偏差影响。在流行的LVIS开放词汇检测基准上，我们的方法使用常见的ViT-L主干网络取得了40.4的掩码AP$_r$新的最优结果，明显优于其他方法。

    We present a new open-vocabulary detection approach based on detection-oriented image-text pretraining to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we replace the commonly used classification architecture with the detector architecture, which better serves the region-level recognition needs of detection by enabling the detector heads to learn from noisy image-text pairs. Using only standard contrastive loss and no pseudo-labeling, our approach is a simple yet effective extension of the contrastive learning method to learn emergent object-semantic cues. In addition, we propose a shifted-window learning approach upon window attention to make the backbone representation more robust, translation-invariant, and less biased by the window pattern. On the popular LVIS open-vocabulary detection benchmark, our approach sets a new state of the art of 40.4 mask AP$_r$ using the common ViT-L backbone, significantly outperforming t
    
[^30]: 用XRM发现环境

    Discovering environments with XRM. (arXiv:2309.16748v1 [cs.LG])

    [http://arxiv.org/abs/2309.16748](http://arxiv.org/abs/2309.16748)

    本文提出了一种用于发现环境的算法 XRM，它通过训练两个孪生网络，每个网络从训练数据的一半中学习，并模仿其兄弟网络的错误分类，解决了现有方法需要依赖人工注释环境信息的问题。

    

    成功的跨领域泛化需要环境注释。然而，这些注释的获取是资源密集型的，并且它们对模型性能的影响受人类注释者的期望和感知偏差的限制。因此，为了实现应用领域全面泛化的鲁棒性AI系统，我们必须开发一种算法来自动发现引发广泛泛化的环境。目前的提案根据训练误差将示例划分为不同的类，但存在一个根本问题。这些方法添加了超参数和早停策略，而这些参数是无法在没有人类注释环境的验证集的情况下进行调整的，而这些信息正是要发现的信息。在本文中，我们提出了 Cross-Risk-Minimization (XRM) 来解决这个问题。XRM 训练两个孪生网络，每个网络从训练数据的一个随机一半中学习，同时模仿其兄弟网络所做的自信的错误分类。XRM 提供了超参数调整的方法，并且不需要依赖人工注释的环境信息。

    Successful out-of-distribution generalization requires environment annotations. Unfortunately, these are resource-intensive to obtain, and their relevance to model performance is limited by the expectations and perceptual biases of human annotators. Therefore, to enable robust AI systems across applications, we must develop algorithms to automatically discover environments inducing broad generalization. Current proposals, which divide examples based on their training error, suffer from one fundamental problem. These methods add hyper-parameters and early-stopping criteria that are impossible to tune without a validation set with human-annotated environments, the very information subject to discovery. In this paper, we propose Cross-Risk-Minimization (XRM) to address this issue. XRM trains two twin networks, each learning from one random half of the training data, while imitating confident held-out mistakes made by its sibling. XRM provides a recipe for hyper-parameter tuning, does not 
    
[^31]: 私有联邦数据分析的可采样匿名聚合

    Samplable Anonymous Aggregation for Private Federated Data Analysis. (arXiv:2307.15017v1 [cs.CR])

    [http://arxiv.org/abs/2307.15017](http://arxiv.org/abs/2307.15017)

    本论文在解决每个设备持有私有数据情况下的私有统计和私有联邦学习设计中，提出了一个简单的原语，以实现高效的算法，并在不需要强信任假设的情况下保护隐私。

    

    在每个设备持有私有数据的情况下，我们重新审视设计可扩展的私有统计协议和私有联邦学习的问题。我们的第一个贡献是提出了一个简单的原语，可以有效地实现几种常用算法，并且可以在不需要强信任假设的情况下进行隐私账务，接近于集中设置中的隐私保护。其次，我们提出了一个实现该原语的系统架构，并对该系统进行了安全性分析。

    We revisit the problem of designing scalable protocols for private statistics and private federated learning when each device holds its private data. Our first contribution is to propose a simple primitive that allows for efficient implementation of several commonly used algorithms, and allows for privacy accounting that is close to that in the central setting without requiring the strong trust assumptions it entails. Second, we propose a system architecture that implements this primitive and perform a security analysis of the proposed system.
    
[^32]: 交叉验证就是你所需的：一种统计方法来估计标签噪声。

    Cross-Validation Is All You Need: A Statistical Approach To Label Noise Estimation. (arXiv:2306.13990v1 [cs.LG])

    [http://arxiv.org/abs/2306.13990](http://arxiv.org/abs/2306.13990)

    本论文提出了一种重复交叉验证(Repeated Cross-Validation)方法，通过构建噪声直方图并提出三种基于该直方图的方法来检测标签噪声并清理数据，解决了结果预测分析中的数据清洗问题。

    

    标签噪声在机器学习数据集中普遍存在。鉴定和消除标签噪声至关重要，因为在噪声数据上训练的模型会大幅降低准确性和泛化性。大多数现有的标签噪声检测方法都是为分类任务设计的，而基于结果预测分析的数据清理相对未被探索。受到交叉验证中不同折的性能波动的启发，我们提出了用于标签噪声估计的重复交叉验证（ReCoV）来填补这一空白。ReCoV通过记录每个最差表现折中的样本ID来构建一个噪声直方图，以此来排名样本的噪声水平。我们进一步提出了三种基于噪声直方图来鉴别嘈杂样本的方法，以解决越来越复杂的噪声分布。我们展示了ReCoV在分类任务基准中的优越表现，优于现有最先进标签清理算法。更重要的是，

    Label noise is prevalent in machine learning datasets. It is crucial to identify and remove label noise because models trained on noisy data can have substantially reduced accuracy and generalizability. Most existing label noise detection approaches are designed for classification tasks, and data cleaning for outcome prediction analysis is relatively unexplored. Inspired by the fluctuations in performance across different folds in cross-validation, we propose Repeated Cross-Validations for label noise estimation (ReCoV) to address this gap. ReCoV constructs a noise histogram that ranks the noise level of samples based on a large number of cross-validations by recording sample IDs in each worst-performing fold. We further propose three approaches for identifying noisy samples based on noise histograms to address increasingly complex noise distributions. We show that ReCoV outperforms state-of-the-art algorithms for label cleaning in a classification task benchmark. More importantly, we 
    
[^33]: 通过奇异谱平滑解决顺序推荐中的排名退化问题

    Addressing the Rank Degeneration in Sequential Recommendation via Singular Spectrum Smoothing. (arXiv:2306.11986v1 [cs.IR])

    [http://arxiv.org/abs/2306.11986](http://arxiv.org/abs/2306.11986)

    本文提出了一种通过奇异谱平滑算法缓解顺序推荐中序列与项目排名退化问题的方法，并提出了SSA指标来评估该问题的严重性。

    

    顺序推荐研究动态用户偏好建模并生成下一个项目预测。下一个项目的偏好通常是通过序列和项目表示之间的亲和度生成的。然而，由于数据稀疏问题，序列和项目表示都会遭受排名降级问题。排名退化问题严重损害了顺序推荐的表示。因此我们提出了通过理论连接序列表示降级问题与项目排名退化问题的方法。我们还发现了快速奇异值衰减现象与转换器序列输出和项目嵌入中的排名折叠问题之间的联系。我们提出了奇异值曲线下面积（SSA）评估指标，同时缓解顺序推荐中的序列和项目表示排名退化问题。

    Sequential recommendation (SR) investigates the dynamic user preferences modeling and generates the next-item prediction. The next item preference is typically generated by the affinity between the sequence and item representations. However, both sequence and item representations suffer from the rank degeneration issue due to the data sparsity problem. The rank degeneration issue significantly impairs the representations for SR. This motivates us to measure how severe is the rank degeneration issue and alleviate the sequence and item representation rank degeneration issues simultaneously for SR.  In this work, we theoretically connect the sequence representation degeneration issue with the item rank degeneration, particularly for short sequences and cold items. We also identify the connection between the fast singular value decay phenomenon and the rank collapse issue in transformer sequence output and item embeddings. We propose the area under the singular value curve metric to evalua
    
[^34]: 差分隐私潜在扩散模型

    Differentially Private Latent Diffusion Models. (arXiv:2305.15759v1 [stat.ML])

    [http://arxiv.org/abs/2305.15759](http://arxiv.org/abs/2305.15759)

    本文提出使用差分隐私训练潜在扩散模型(LDMs)，通过预训练自编码器将高维像素空间转变为低维潜在空间实现更高效快速的DMs训练，并且通过只微调注意力模块减少了可训练参数的数量。

    

    扩散模型(DMs)被广泛用于生成高质量图像数据集。然而，由于它们直接在高维像素空间中运行，DMs的优化计算成本高，需要长时间的训练。这导致由于差分隐私的可组合性属性，大量噪音注入到差分隐私学习过程中。为了解决这个挑战，我们提出使用差分隐私训练潜在扩散模型(LDMs)。LDMs使用强大的预训练自编码器将高维像素空间减少到更低维的潜在空间，使训练DMs更加高效和快速。与[Ghalebikesabi等人，2023]预先用公共数据预训练DMs，然后再用隐私数据进行微调不同，我们仅微调LDMs中不同层的注意力模块以获得隐私敏感数据，相对于整个DM微调，可减少大约96%的可训练参数数量。

    Diffusion models (DMs) are widely used for generating high-quality image datasets. However, since they operate directly in the high-dimensional pixel space, optimization of DMs is computationally expensive, requiring long training times. This contributes to large amounts of noise being injected into the differentially private learning process, due to the composability property of differential privacy. To address this challenge, we propose training Latent Diffusion Models (LDMs) with differential privacy. LDMs use powerful pre-trained autoencoders to reduce the high-dimensional pixel space to a much lower-dimensional latent space, making training DMs more efficient and fast. Unlike [Ghalebikesabi et al., 2023] that pre-trains DMs with public data then fine-tunes them with private data, we fine-tune only the attention modules of LDMs at varying layers with privacy-sensitive data, reducing the number of trainable parameters by approximately 96% compared to fine-tuning the entire DM. We te
    
[^35]: DF2M：一种可解释的用于高维函数时间序列分析的深度贝叶斯非参数模型

    DF2M: An Explainable Deep Bayesian Nonparametric Model for High-Dimensional Functional Time Series. (arXiv:2305.14543v1 [stat.ML])

    [http://arxiv.org/abs/2305.14543](http://arxiv.org/abs/2305.14543)

    本文提出一种名为DF2M的模型，用于分析高维函数时间序列。该模型采用印度自助餐过程和深度核函数的多任务高斯过程捕捉时间动态，与传统的深度学习模型相比，DF2M提供了更好的可解释性和卓越的预测准确性。

    

    本文提出Deep Functional Factor Model(DF2M)，一种用于分析高维函数时间序列的贝叶斯非参数模型。DF2M利用印度自助餐过程和深度核函数的多任务高斯过程来捕捉非马尔科夫和非线性时间动态。与许多黑匣子深度学习模型不同，DF2M通过构建因子模型并将深度神经网络融入核函数中，提供了一种可解释的使用神经网络的方法。此外，我们还开发了一种计算高效的变分推理算法来推断DF2M。四个真实数据集的实证结果表明，与传统的深度学习模型相比，DF2M提供了更好的可解释性和卓越的预测准确性。

    In this paper, we present Deep Functional Factor Model (DF2M), a Bayesian nonparametric model for analyzing high-dimensional functional time series. The DF2M makes use of the Indian Buffet Process and the multi-task Gaussian Process with a deep kernel function to capture non-Markovian and nonlinear temporal dynamics. Unlike many black-box deep learning models, the DF2M provides an explainable way to use neural networks by constructing a factor model and incorporating deep neural networks within the kernel function. Additionally, we develop a computationally efficient variational inference algorithm for inferring the DF2M. Empirical results from four real-world datasets demonstrate that the DF2M offers better explainability and superior predictive accuracy compared to conventional deep learning models for high-dimensional functional time series.
    
[^36]: 条件生成模型可证明具有健壮性:银湖反问题的逐点保证

    Conditional Generative Models are Provably Robust: Pointwise Guarantees for Bayesian Inverse Problems. (arXiv:2303.15845v1 [cs.LG])

    [http://arxiv.org/abs/2303.15845](http://arxiv.org/abs/2303.15845)

    本文证明了条件生成模型对单个观测结果有健壮性

    

    条件生成模型成为采样银湖反问题后验概率的强大工具. 经典的贝叶斯文献已经知道后验测度对先前测度和负对数似然函数(包括观察的扰动)非常 robust. 但是, 就我们所知, 条件生成模型的健壮性还没被研究过. 在本文中, 我们首次证明了适当学习的条件生成模型在单个观测值方面提供了健壮的结果.

    Conditional generative models became a very powerful tool to sample from Bayesian inverse problem posteriors. It is well-known in classical Bayesian literature that posterior measures are quite robust with respect to perturbations of both the prior measure and the negative log-likelihood, which includes perturbations of the observations. However, to the best of our knowledge, the robustness of conditional generative models with respect to perturbations of the observations has not been investigated yet. In this paper, we prove for the first time that appropriately learned conditional generative models provide robust results for single observations.
    
[^37]: Waveflow：将边界条件应用于平滑归一化流的新方法，并以费米波函数为例

    Waveflow: Enforcing boundary conditions in smooth normalizing flows with application to fermionic wave functions. (arXiv:2211.14839v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14839](http://arxiv.org/abs/2211.14839)

    本文介绍了一种新的处理归一化流拓扑问题、将边界条件应用于归一化流的技术、引入了可以被制作成任意次可微的 I-Spline 双射，并将这些技术用于创建一种基于归一化流的费米波函数 Ansatz，从而实现高效训练。

    

    本文提出了四个主要的创新点。首先，我们介绍了一种处理归一化流拓扑问题的新方法。其次，我们描述了一种在归一化流上强制施加特定类别边界条件的技术。第三，我们引入了 I-Spline 双射，它像之前的工作一样利用了样条曲线，但与这些工作不同的是，它可以被制作成任意次可微的。最后，我们使用这些技术创建了 Waveflow，一种基于归一化流的一维多粒子费米波函数的 Ansatz，它可以通过变分量子蒙特卡罗高效地训练，无需 MCMC 或估计归一化常数。为了强制费米波函数所需的反对称性，我们仅在排列群的基本域上训练归一化流，这有效地将其减少为一个边界值问题。

    In this paper, we introduce four main novelties: First, we present a new way of handling the topology problem of normalizing flows. Second, we describe a technique to enforce certain classes of boundary conditions onto normalizing flows. Third, we introduce the I-Spline bijection, which, similar to previous work, leverages splines but, in contrast to those works, can be made arbitrarily often differentiable. And finally, we use these techniques to create Waveflow, an Ansatz for the one-space-dimensional multi-particle fermionic wave functions in real space based on normalizing flows, that can be efficiently trained with Variational Quantum Monte Carlo without the need for MCMC nor estimation of a normalization constant. To enforce the necessary anti-symmetry of fermionic wave functions, we train the normalizing flow only on the fundamental domain of the permutation group, which effectively reduces it to a boundary value problem.
    
[^38]: 在线非随机控制简介

    Introduction to Online Nonstochastic Control. (arXiv:2211.09619v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09619](http://arxiv.org/abs/2211.09619)

    介绍了一种新兴的在线非随机控制方法，通过在一组策略中寻找低后悔，获得对最优策略的近似。

    

    本文介绍了一种新兴的动态系统控制与可微强化学习范式——在线非随机控制，并应用在线凸优化和凸松弛技术得到了具有可证明保证的新方法，在最佳和鲁棒控制方面取得了显著成果。与其他框架不同，该方法的目标是对抗性攻击，在无法预测扰动模型的情况下，通过在一组策略中寻找低后悔，获得对最优策略的近似。

    This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.  This objective suggests the use of the decision making frame
    

