# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multivariate Probabilistic Time Series Forecasting with Correlated Errors](https://rss.arxiv.org/abs/2402.01000) | 本文提出了一种方法，基于低秩加对角线参数化协方差矩阵，可以有效地刻画时间序列预测中误差的自相关性，并具有复杂度低、校准预测准确性高等优点。 |
| [^2] | [Data-driven Energy Consumption Modelling for Electric Micromobility using an Open Dataset](https://arxiv.org/abs/2403.17632) | 提出了一个专门针对电动微移动工具在都柏林收集的开放数据集，为解决实际场景中能耗建模的困难提供了重要资源 |
| [^3] | [Optimal Flow Matching: Learning Straight Trajectories in Just One Step](https://arxiv.org/abs/2403.13117) | 该论文提出了一种新颖的最优流匹配方法，能够在一步中学习实现二次成本下的直线 OT 位移。 |
| [^4] | [Logits of API-Protected LLMs Leak Proprietary Information](https://arxiv.org/abs/2403.09539) | 大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能 |
| [^5] | [Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked Preferences](https://arxiv.org/abs/2403.07230) | 提出了一种名为Curry-DPO的方法，在直接偏好优化(DPO)中利用课程学习方法，通过构建多个偏好对来训练模型，相比于标准单一对DPO设置有着更好的性能表现。 |
| [^6] | [Graph neural network outputs are almost surely asymptotically constant](https://arxiv.org/abs/2403.03880) | 研究表明，图神经网络的输出将渐近于一个常数函数，并限制了这些分类器的统一表达能力。 |
| [^7] | [Emotion Classification in Low and Moderate Resource Languages](https://arxiv.org/abs/2402.18424) | 通过跨语言情感分类器，在低和中等资源语言中实现情感分类，展示了两种迁移学习方法的有效性。 |
| [^8] | [DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection](https://arxiv.org/abs/2402.17176) | DeepDRK是一种分布无关的深度学习方法，通过引入基于Transformer架构的生成模型以实现“交换属性”，并提出新颖有效的正则化技术，取得了在FDR和能力之间取得平衡。 |
| [^9] | [Learning high-dimensional targets by two-parameter models and gradient flow](https://arxiv.org/abs/2402.17089) | 通过提出两参数模型和梯度流学习高维目标的理论可能性，研究发现在特定条件下存在大量不可学习目标，并且这些目标的集合不密集，具有一定拓扑性质的子集中也存在不可学习目标。最终，发现使用层次过程构建的主要定理模型在数学表达上并非由单一初等函数表示。 |
| [^10] | [Fair Classifiers Without Fair Training: An Influence-Guided Data Sampling Approach](https://arxiv.org/abs/2402.12789) | 在不实施公平训练算法的情况下学习公平分类器，通过抽样具有影响力的数据来逐步转移原始训练数据，从而提高公平性和准确性。 |
| [^11] | [Deinterleaving of Discrete Renewal Process Mixtures with Application to Electronic Support Measures](https://arxiv.org/abs/2402.09166) | 本文提出了一种用于解缠织混合离散更新Markov链的新方法，通过最大化惩罚似然分数来恢复真实的符号分组，并在电子支援措施中的应用中展示了较好的性能。 |
| [^12] | [Entropy-regularized Diffusion Policy with Q-Ensembles for Offline Reinforcement Learning](https://arxiv.org/abs/2402.04080) | 本文介绍了一种熵正则化的扩散策略与Q-集合相结合的离线强化学习方法，该方法通过将一个复杂的动作分布转化为标准高斯分布，然后使用逆时间SDE采样动作，以改善离线数据集的探索能力，并通过学习Q-集合的下信心界实现更强健的策略改进。在D4RL基准任务的大多数任务上达到了最先进的性能。 |
| [^13] | [Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks](https://arxiv.org/abs/2401.17263) | 该论文提出了一种鲁棒的提示优化算法（RPO）用于对抗语言模型的破解攻击，通过梯度优化来确保输出的无害性，并成功降低了攻击成功率。 |
| [^14] | [Learning Human-like Representations to Enable Learning Human Values](https://arxiv.org/abs/2312.14106) | 通过学习类人的表示，可以实现机器学习系统符合人类价值观，支持伦理等多方面的价值对齐。 |
| [^15] | [Semi-Supervised Health Index Monitoring with Feature Generation and Fusion](https://arxiv.org/abs/2312.02867) | 通过深度半监督异常检测（DeepSAD）方法进行健康指数构建，并提出了多样性损失来丰富条件指标。 |
| [^16] | [SINCERE: Supervised Information Noise-Contrastive Estimation REvisited](https://arxiv.org/abs/2309.14277) | SINCERE提出了一个理论上合理的监督扩展，避免了同一类别的图像相互排斥，通过更好地分离不同类别的嵌入，在保持竞争性分类准确性的同时实现了更好的效果。 |
| [^17] | [Is K-fold cross validation the best model selection method for Machine Learning?.](http://arxiv.org/abs/2401.16407) | K折交叉验证在机器学习中是常用的模型选择方法，但在处理小样本数据集和异质数据源时存在困难。 |
| [^18] | [Bayesian Nonparametrics meets Data-Driven Robust Optimization.](http://arxiv.org/abs/2401.15771) | 本文提出了一种将贝叶斯非参数方法与最新的决策理论模型相结合的鲁棒优化准则，通过这种方法，可以在线性回归问题中获得有稳定性和优越性能的结果。 |
| [^19] | [Towards Principled Graph Transformers.](http://arxiv.org/abs/2401.10119) | 边缘变换器是一个全局注意力模型，它具有至少3-WL的表达能力，能够在预测性能上超过其他架构，而不依赖于位置或结构编码。 |
| [^20] | [Beyond Regrets: Geometric Metrics for Bayesian Optimization.](http://arxiv.org/abs/2401.01981) | 本论文提出了四个新的几何度量，可以比较贝叶斯优化算法在考虑查询点和全局最优解的几何特性时的性能。 |
| [^21] | [Online Conversion with Switching Costs: Robust and Learning-Augmented Algorithms.](http://arxiv.org/abs/2310.20598) | 本论文介绍并研究了在线转换及其带有切换成本的问题，并提出了具有竞争力的阈值算法以及学习增强算法，这些算法在最小化和最大化变体中都表现出优越性能。 |
| [^22] | [A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered by Semantic Communication.](http://arxiv.org/abs/2310.17705) | 一种由语义通信增强的无线AI生成内容（AIGC）供应框架，通过使用语义信息而不是所有的二进制位提取和传输内容，以解决在无线网络中提供最优AIGC服务的挑战。 |
| [^23] | [Using Causality-Aware Graph Neural Networks to Predict Temporal Centralities in Dynamic Graphs.](http://arxiv.org/abs/2310.15865) | 本研究提出了一种使用因果感知图神经网络预测动态图中的时间中心性的方法，并在不同领域的13个时间图上进行了实验验证，结果显示该方法显著改善了介数和接近度中心性的预测能力。 |
| [^24] | [A Dual Latent State Learning Approach: Exploiting Regional Network Similarities for QoS Prediction.](http://arxiv.org/abs/2310.05988) | 本文介绍了一种名为R2SL的基于区域的双潜在状态学习网络，该网络通过汇总数据来捕捉区域网络行为的细微差别，并采用增强的Huber损失函数来提高QoS预测性能。 |
| [^25] | [Towards Robust Offline-to-Online Reinforcement Learning via Uncertainty and Smoothness.](http://arxiv.org/abs/2309.16973) | 该论文提出了一种名为RO2O的算法，通过不确定性和平滑性增强离线训练的强化学习代理，在离线到在线学习中缓解性能下降问题。 |
| [^26] | [Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction.](http://arxiv.org/abs/2308.02580) | PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function. |
| [^27] | [PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models.](http://arxiv.org/abs/2307.09254) | 本文提出了一种使用神经网络来量化生成式语言模型不确定性的PAC神经预测集学习方法，通过在多种语言数据集和模型上的实验证明，相比于标准基准方法，我们的方法平均提高了63％的量化不确定性。 |
| [^28] | [Encoding Domain Expertise into Multilevel Models for Source Location.](http://arxiv.org/abs/2305.08657) | 本文提出了一种基于贝叶斯多级模型的方法，可以将群体数据视为整体来考虑，并将领域专业知识和物理知识编码到模型中，以实现源位置的定位。 |
| [^29] | [Text-to-image Diffusion Model in Generative AI: A Survey.](http://arxiv.org/abs/2303.07909) | 本文调查了文本到图像扩散模型以及相关应用，总结了最先进的方法，并探讨了挑战和未来方向。 |
| [^30] | [Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift.](http://arxiv.org/abs/2302.10160) | 该论文提出了一种关于核岭回归的协变量转移策略，通过使用伪标签进行模型选择，能够适应不同特征分布下的学习，实现均方误差最小化。 |
| [^31] | [Consciousness is learning: predictive processing systems that learn by binding may perceive themselves as conscious.](http://arxiv.org/abs/2301.07016) | 通过层级绑定和联想检索变为短期和长期声明性记忆的在线预测处理系统可能会感知到自己具有意识。 |

# 详细

[^1]: 多元概率时间序列预测与相关误差

    Multivariate Probabilistic Time Series Forecasting with Correlated Errors

    [https://rss.arxiv.org/abs/2402.01000](https://rss.arxiv.org/abs/2402.01000)

    本文提出了一种方法，基于低秩加对角线参数化协方差矩阵，可以有效地刻画时间序列预测中误差的自相关性，并具有复杂度低、校准预测准确性高等优点。

    

    建模误差之间的相关性与模型能够准确量化概率时间序列预测中的预测不确定性密切相关。最近的多元模型在考虑误差之间的同时相关性方面取得了显著进展，然而，对于统计简化的目的，对这些误差的常见假设是它们在时间上是独立的。然而，实际观测往往偏离了这个假设，因为误差通常由于各种因素（如排除时间相关的协变量）而表现出显著的自相关性。在这项工作中，我们提出了一种基于低秩加对角线参数化协方差矩阵的高效方法，可以有效地刻画误差的自相关性。所提出的方法具有几个可取的特性：复杂度不随时间序列数目增加，得到的协方差可以用于校准预测，且具有较好的性能。

    Modeling the correlations among errors is closely associated with how accurately the model can quantify predictive uncertainty in probabilistic time series forecasting. Recent multivariate models have made significant progress in accounting for contemporaneous correlations among errors, while a common assumption on these errors is that they are temporally independent for the sake of statistical simplicity. However, real-world observations often deviate from this assumption, since errors usually exhibit substantial autocorrelation due to various factors such as the exclusion of temporally correlated covariates. In this work, we propose an efficient method, based on a low-rank-plus-diagonal parameterization of the covariance matrix, which can effectively characterize the autocorrelation of errors. The proposed method possesses several desirable properties: the complexity does not scale with the number of time series, the resulting covariance can be used for calibrating predictions, and i
    
[^2]: 使用开放数据集对电动微移动能耗建模

    Data-driven Energy Consumption Modelling for Electric Micromobility using an Open Dataset

    [https://arxiv.org/abs/2403.17632](https://arxiv.org/abs/2403.17632)

    提出了一个专门针对电动微移动工具在都柏林收集的开放数据集，为解决实际场景中能耗建模的困难提供了重要资源

    

    车辆拥堵和环境恶化带来的挑战日益加剧，凸显了在城市空间推行E-Mobility解决方案的重要性。特别是，E-滑板车和E-自行车等微型E-Mobility工具在这一转变中发挥着关键作用，为城市通勤者提供可持续的替代方案。然而，这些工具的能耗模式是影响其在现实场景中有效性的关键因素，对于出行规划以及增强用户在使用这些工具时的信心至关重要。为此，最近的研究利用针对特定移动工具和条件定制的物理模型，但这些模型在现实场景中的泛化能力和有效性存在困难，这是因为缺乏用于彻底模型评估和验证的开放数据集。为填补这一空白，我们的工作提出了一个在爱尔兰都柏林收集的开放数据集，专门用于能耗建模。

    arXiv:2403.17632v1 Announce Type: new  Abstract: The escalating challenges of traffic congestion and environmental degradation underscore the critical importance of embracing E-Mobility solutions in urban spaces. In particular, micro E-Mobility tools such as E-scooters and E-bikes, play a pivotal role in this transition, offering sustainable alternatives for urban commuters. However, the energy consumption patterns for these tools are a critical aspect that impacts their effectiveness in real-world scenarios and is essential for trip planning and boosting user confidence in using these. To this effect, recent studies have utilised physical models customised for specific mobility tools and conditions, but these models struggle with generalization and effectiveness in real-world scenarios due to a notable absence of open datasets for thorough model evaluation and verification. To fill this gap, our work presents an open dataset, collected in Dublin, Ireland, specifically designed for ene
    
[^3]: 最优流匹配：在一步中学习直线轨迹

    Optimal Flow Matching: Learning Straight Trajectories in Just One Step

    [https://arxiv.org/abs/2403.13117](https://arxiv.org/abs/2403.13117)

    该论文提出了一种新颖的最优流匹配方法，能够在一步中学习实现二次成本下的直线 OT 位移。

    

    在过去几年中，流匹配方法在生成建模中得到了蓬勃发展。社区追求的一个引人注目的属性是能够学习具有直线轨迹的流，这些轨迹实现了最优输运（OT）置换。直线性对于快速集成学习流的路径至关重要。不幸的是，大多数现有的流直线化方法都基于非平凡的迭代过程，在训练过程中积累误差或利用启发式小批量OT近似。为解决这一问题，我们开发了一种新颖的最优流匹配方法，仅通过一次流匹配步骤即可为二次成本恢复直线OT置换。

    arXiv:2403.13117v1 Announce Type: cross  Abstract: Over the several recent years, there has been a boom in development of flow matching methods for generative modeling. One intriguing property pursued by the community is the ability to learn flows with straight trajectories which realize the optimal transport (OT) displacements. Straightness is crucial for fast integration of the learned flow's paths. Unfortunately, most existing flow straightening methods are based on non-trivial iterative procedures which accumulate the error during training or exploit heuristic minibatch OT approximations. To address this issue, we develop a novel optimal flow matching approach which recovers the straight OT displacement for the quadratic cost in just one flow matching step.
    
[^4]: API保护的LLMs的标志泄露专有信息

    Logits of API-Protected LLMs Leak Proprietary Information

    [https://arxiv.org/abs/2403.09539](https://arxiv.org/abs/2403.09539)

    大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能

    

    大型语言模型（LLMs）的商业化导致了高级API-only接入专有模型的常见实践。在这项工作中，我们展示了即使对于模型架构有保守的假设，也可以从相对较少的API查询中学习关于API保护的LLM的大量非公开信息（例如，使用OpenAI的gpt-3.5-turbo仅花费不到1000美元）。我们的发现集中在一个关键观察上：大多数现代LLM受到了softmax瓶颈的影响，这限制了模型输出到完整输出空间的线性子空间。我们表明，这导致了一个模型图像或模型签名，从而以较低的成本解锁了几种功能：有效发现LLM的隐藏大小，获取完整词汇输出，检测和消除不同模型更新，识别给定单个完整LLM输出的源LLM，以及...

    arXiv:2403.09539v1 Announce Type: cross  Abstract: The commercialization of large language models (LLMs) has led to the common practice of high-level API-only access to proprietary models. In this work, we show that even with a conservative assumption about the model architecture, it is possible to learn a surprisingly large amount of non-public information about an API-protected LLM from a relatively small number of API queries (e.g., costing under $1,000 for OpenAI's gpt-3.5-turbo). Our findings are centered on one key observation: most modern LLMs suffer from a softmax bottleneck, which restricts the model outputs to a linear subspace of the full output space. We show that this lends itself to a model image or a model signature which unlocks several capabilities with affordable cost: efficiently discovering the LLM's hidden size, obtaining full-vocabulary outputs, detecting and disambiguating different model updates, identifying the source LLM given a single full LLM output, and eve
    
[^5]: Curry-DPO：利用课程学习和排名偏好增强对齐

    Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked Preferences

    [https://arxiv.org/abs/2403.07230](https://arxiv.org/abs/2403.07230)

    提出了一种名为Curry-DPO的方法，在直接偏好优化(DPO)中利用课程学习方法，通过构建多个偏好对来训练模型，相比于标准单一对DPO设置有着更好的性能表现。

    

    直接偏好优化(DPO)是一种有效的技术，利用成对偏好数据(通常是每个用户提示选择和拒绝的响应对)将LLMs与人类偏好对齐。在实践中，对于给定提示可能会存在多个响应，这些响应的质量相对于彼此而言有所不同。有了这些多个响应的质量评级，我们提出利用这些响应为给定提示创建多个偏好对。我们的工作侧重于通过课程学习方法系统地利用构建的多个偏好对来进行DPO训练。特别是，我们根据不同的标准将这些多个偏好数据对从易到难(模拟课程训练)排序。我们详细比较了我们提出的方法与标准单一对DPO设置。我们的方法，我们称之为Curry-DPO，在MTbench、Vicuna、Wiz上始终表现出增强的性能收益。

    arXiv:2403.07230v1 Announce Type: cross  Abstract: Direct Preference Optimization (DPO) is an effective technique that leverages pairwise preference data (usually one chosen and rejected response pair per user prompt) to align LLMs to human preferences. In practice, multiple responses can exist for a given prompt with varying quality relative to each other. With availability of such quality ratings for multiple responses, we propose utilizing these responses to create multiple preference pairs for a given prompt. Our work focuses on systematically using the constructed multiple preference pair in DPO training via curriculum learning methodology. In particular, we order these multiple pairs of preference data from easy to hard (emulating curriculum training) according to various criteria. We show detailed comparisons of our proposed approach to the standard single-pair DPO setting. Our method, which we call Curry-DPO consistently shows increased performance gains on MTbench, Vicuna, Wiz
    
[^6]: 图神经网络的输出几乎肯定是渐近常数

    Graph neural network outputs are almost surely asymptotically constant

    [https://arxiv.org/abs/2403.03880](https://arxiv.org/abs/2403.03880)

    研究表明，图神经网络的输出将渐近于一个常数函数，并限制了这些分类器的统一表达能力。

    

    图神经网络（GNNs）是各种图学习任务中主要的架构。我们通过研究GNN的概率分类器在从某个随机图模型中绘制的更大图上应用时预测如何演变，提出了GNN表达能力的新角度。我们展示了输出收敛到一个常数函数，这个函数上限了这些分类器可以统一表达的内容。这种收敛现象适用于非常广泛的GNN类别，包括先进模型，其中的聚合包括平均值和基于注意力的图转换器机制。我们的结果适用于各种随机图模型，包括（稀疏的）Erd\H{o}s-R\'enyi模型和随机块模型。我们通过实证验证这些发现，观察到收敛现象已经在相对适中规模的图中显现。

    arXiv:2403.03880v1 Announce Type: new  Abstract: Graph neural networks (GNNs) are the predominant architectures for a variety of learning tasks on graphs. We present a new angle on the expressive power of GNNs by studying how the predictions of a GNN probabilistic classifier evolve as we apply it on larger graphs drawn from some random graph model. We show that the output converges to a constant function, which upper-bounds what these classifiers can express uniformly. This convergence phenomenon applies to a very wide class of GNNs, including state of the art models, with aggregates including mean and the attention-based mechanism of graph transformers. Our results apply to a broad class of random graph models, including the (sparse) Erd\H{o}s-R\'enyi model and the stochastic block model. We empirically validate these findings, observing that the convergence phenomenon already manifests itself on graphs of relatively modest size.
    
[^7]: 低资源和中等资源语言中的情感分类

    Emotion Classification in Low and Moderate Resource Languages

    [https://arxiv.org/abs/2402.18424](https://arxiv.org/abs/2402.18424)

    通过跨语言情感分类器，在低和中等资源语言中实现情感分类，展示了两种迁移学习方法的有效性。

    

    能够分析全球范围内人们情绪状态是很重要的。全球有7100多种活跃语言，为每种语言构建情感分类是一项劳动密集型工作。特别是对于低资源和濒危语言，建立情感分类可能非常具有挑战性。我们提出了一种跨语言情感分类器，我们在资源丰富的语言（例如我们的工作中的英语）上训练情感分类器，并将学习迁移到低资源和中等资源的语言。我们比较并对比了从高资源语言到低资源或中等资源语言的两种迁移学习方法。一种方法将高资源语言的标注投影到低资源和中等资源语言的平行语料库中，另一种方法直接将高资源语言的学习迁移到其他语言。我们展示了我们的方法在6种语言上的有效性：Fa

    arXiv:2402.18424v1 Announce Type: cross  Abstract: It is important to be able to analyze the emotional state of people around the globe. There are 7100+ active languages spoken around the world and building emotion classification for each language is labor intensive. Particularly for low-resource and endangered languages, building emotion classification can be quite challenging. We present a cross-lingual emotion classifier, where we train an emotion classifier with resource-rich languages (i.e. \textit{English} in our work) and transfer the learning to low and moderate resource languages. We compare and contrast two approaches of transfer learning from a high-resource language to a low or moderate-resource language. One approach projects the annotation from a high-resource language to low and moderate-resource language in parallel corpora and the other one uses direct transfer from high-resource language to the other languages. We show the efficacy of our approaches on 6 languages: Fa
    
[^8]: DeepDRK:深度依赖正则化 Knockoff 用于特征选择

    DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection

    [https://arxiv.org/abs/2402.17176](https://arxiv.org/abs/2402.17176)

    DeepDRK是一种分布无关的深度学习方法，通过引入基于Transformer架构的生成模型以实现“交换属性”，并提出新颖有效的正则化技术，取得了在FDR和能力之间取得平衡。

    

    arXiv:2402.17176v1 公告类型:新 摘要: Model-X knockoff，在各种特征选择方法中，由于其对假发现率（FDR）控制的保证而最近受到广泛关注。在参数设计中引入后，knockoff被发展为使用基于深度学习的生成建模来处理任意数据分布。然而，我们观察到目前深度Model-X knockoff框架的实现存在局限性。值得注意的是，knockoffs所需的“交换属性”经常在样本级别遇到挑战，导致选择能力下降。为了克服这一问题，我们开发了“深度依赖正则化Knockoff（DeepDRK）”，这是一种不依赖分布的深度学习方法，可以在FDR和能力之间取得平衡。在DeepDRK中，引入了一种基于Transformer架构的生成模型，以更好地实现“交换属性”。还提出了新颖有效的正则化技术，以获得更高的能力。

    arXiv:2402.17176v1 Announce Type: new  Abstract: Model-X knockoff, among various feature selection methods, received much attention recently due to its guarantee on false discovery rate (FDR) control. Subsequent to its introduction in parametric design, knockoff is advanced to handle arbitrary data distributions using deep learning-based generative modeling. However, we observed that current implementations of the deep Model-X knockoff framework exhibit limitations. Notably, the "swap property" that knockoffs necessitate frequently encounter challenges on sample level, leading to a diminished selection power. To overcome, we develop "Deep Dependency Regularized Knockoff (DeepDRK)", a distribution-free deep learning method that strikes a balance between FDR and power. In DeepDRK, a generative model grounded in a transformer architecture is introduced to better achieve the "swap property". Novel efficient regularization techniques are also proposed to reach higher power. Our model outper
    
[^9]: 通过两参数模型和梯度流学习高维目标

    Learning high-dimensional targets by two-parameter models and gradient flow

    [https://arxiv.org/abs/2402.17089](https://arxiv.org/abs/2402.17089)

    通过提出两参数模型和梯度流学习高维目标的理论可能性，研究发现在特定条件下存在大量不可学习目标，并且这些目标的集合不密集，具有一定拓扑性质的子集中也存在不可学习目标。最终，发现使用层次过程构建的主要定理模型在数学表达上并非由单一初等函数表示。

    

    我们探讨了当$W<d$时，通过梯度流（GF）以$W$参数模型学习$d$维目标的理论可能性，必然存在GF-不可学习目标的大子集。特别是，可学习目标的集合在$\mathbb R^d$中不是密集的，任何形同$W$维球面的$\mathbb R^d$子集包含不可学习目标。最后，我们观察到在几乎保证二参数学习的主要定理中，所述模型是通过层次过程构建的，因此不能用单个初等函数表达。我们展示了这种限制在本质上是必要的，因为这种可学习性对于许多初等函数类的可学习性是被排除的。

    arXiv:2402.17089v1 Announce Type: cross  Abstract: We explore the theoretical possibility of learning $d$-dimensional targets with $W$-parameter models by gradient flow (GF) when $W<d$ there is necessarily a large subset of GF-non-learnable targets. In particular, the set of learnable targets is not dense in $\mathbb R^d$, and any subset of $\mathbb R^d$ homeomorphic to the $W$-dimensional sphere contains non-learnable targets. Finally, we observe that the model in our main theorem on almost guaranteed two-parameter learning is constructed using a hierarchical procedure and as a result is not expressible by a single elementary function. We show that this limitation is essential in the sense that such learnability can be ruled out for a large class of elementary functions.
    
[^10]: 无需公平训练的公平分类器：一种受影响数据抽样方法

    Fair Classifiers Without Fair Training: An Influence-Guided Data Sampling Approach

    [https://arxiv.org/abs/2402.12789](https://arxiv.org/abs/2402.12789)

    在不实施公平训练算法的情况下学习公平分类器，通过抽样具有影响力的数据来逐步转移原始训练数据，从而提高公平性和准确性。

    

    一个公平的分类器应该确保来自不同群体的人们受益，而群体信息往往是敏感的，不适合模型训练。因此，在训练数据集中学习一个公平的分类器但排除敏感属性是很重要的。本文研究了学习公平分类器而不实现公平训练算法的方法，以避免可能泄露敏感信息。我们的理论分析验证了这种方法的可能性，即在具有适当分布偏移的数据集上进行传统训练可以同时减少公平差距的上限和模型泛化误差，表明公平性和准确性可以同步提高，只需简单地进行传统训练。然后，我们提出了一个可行的解决方案，通过抽样有影响力的数据逐步转移原始训练数据，在训练过程中不访问新数据的敏感属性。

    arXiv:2402.12789v1 Announce Type: cross  Abstract: A fair classifier should ensure the benefit of people from different groups, while the group information is often sensitive and unsuitable for model training. Therefore, learning a fair classifier but excluding sensitive attributes in the training dataset is important. In this paper, we study learning fair classifiers without implementing fair training algorithms to avoid possible leakage of sensitive information. Our theoretical analyses validate the possibility of this approach, that traditional training on a dataset with an appropriate distribution shift can reduce both the upper bound for fairness disparity and model generalization error, indicating that fairness and accuracy can be improved simultaneously with simply traditional training. We then propose a tractable solution to progressively shift the original training data during training by sampling influential data, where the sensitive attribute of new data is not accessed in s
    
[^11]: 混合离散更新过程的解缠织方法及其在电子支援措施中的应用

    Deinterleaving of Discrete Renewal Process Mixtures with Application to Electronic Support Measures

    [https://arxiv.org/abs/2402.09166](https://arxiv.org/abs/2402.09166)

    本文提出了一种用于解缠织混合离散更新Markov链的新方法，通过最大化惩罚似然分数来恢复真实的符号分组，并在电子支援措施中的应用中展示了较好的性能。

    

    在本文中，我们提出了一种用于混合离散更新Markov链的新的解缠织方法。该方法依赖于对惩罚似然分数的最大化。它利用了有关不同符号序列及其到达时间的所有可用信息。通过理论分析证明，在组成过程上满足一定条件的情况下，最小化该分数能够在大样本限制下恢复出真实的符号分组。然后，通过对合成数据的实验验证了该理论分析。最后，将该方法应用于从RESM（雷达电子支援测量）环境中接收到的不同发射机的脉冲串解缠织，并且我们展示了该方法在模拟战数据集上与最先进的方法相比具有竞争优势。

    arXiv:2402.09166v1 Announce Type: new Abstract: In this paper, we propose a new deinterleaving method for mixtures of discrete renewal Markov chains. This method relies on the maximization of a penalized likelihood score. It exploits all available information about both the sequence of the different symbols and their arrival times. A theoretical analysis is carried out to prove that minimizing this score allows to recover the true partition of symbols in the large sample limit, under mild conditions on the component processes. This theoretical analysis is then validated by experiments on synthetic data. Finally, the method is applied to deinterleave pulse trains received from different emitters in a RESM (Radar Electronic Support Measurements) context and we show that the proposed method competes favorably with state-of-the-art methods on simulated warfare datasets.
    
[^12]: 熵正则化扩散策略与Q-集合用于离线强化学习

    Entropy-regularized Diffusion Policy with Q-Ensembles for Offline Reinforcement Learning

    [https://arxiv.org/abs/2402.04080](https://arxiv.org/abs/2402.04080)

    本文介绍了一种熵正则化的扩散策略与Q-集合相结合的离线强化学习方法，该方法通过将一个复杂的动作分布转化为标准高斯分布，然后使用逆时间SDE采样动作，以改善离线数据集的探索能力，并通过学习Q-集合的下信心界实现更强健的策略改进。在D4RL基准任务的大多数任务上达到了最先进的性能。

    

    本文提出了训练用于离线强化学习的扩散策略的先进技术。核心是一个均值回归随机微分方程（SDE），它将复杂的动作分布转化为标准高斯分布，然后在环境状态条件下使用相应的逆时间SDE采样动作，类似于典型的扩散策略。我们展示了这样一个SDE有解，我们可以用它来计算策略的对数概率，从而得到一个熵正则项，改进了离线数据集的探索能力。为了减轻来自分布外数据点的不准确值函数的影响，我们进一步提出了学习Q-集合的下信心界以实现更强健的策略改进。通过将熵正则化扩散策略与Q-集合结合应用于离线强化学习，我们的方法在D4RL基准任务的大多数任务上达到了最先进的性能。代码可在\href{https://github.com/ruoqizzz/Entro}{https://github.com/ruoqizzz/Entro}找到。

    This paper presents advanced techniques of training diffusion policies for offline reinforcement learning (RL). At the core is a mean-reverting stochastic differential equation (SDE) that transfers a complex action distribution into a standard Gaussian and then samples actions conditioned on the environment state with a corresponding reverse-time SDE, like a typical diffusion policy. We show that such an SDE has a solution that we can use to calculate the log probability of the policy, yielding an entropy regularizer that improves the exploration of offline datasets. To mitigate the impact of inaccurate value functions from out-of-distribution data points, we further propose to learn the lower confidence bound of Q-ensembles for more robust policy improvement. By combining the entropy-regularized diffusion policy with Q-ensembles in offline RL, our method achieves state-of-the-art performance on most tasks in D4RL benchmarks. Code is available at \href{https://github.com/ruoqizzz/Entro
    
[^13]: 鲁棒的提示优化用于对抗语言模型的破解攻击

    Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks

    [https://arxiv.org/abs/2401.17263](https://arxiv.org/abs/2401.17263)

    该论文提出了一种鲁棒的提示优化算法（RPO）用于对抗语言模型的破解攻击，通过梯度优化来确保输出的无害性，并成功降低了攻击成功率。

    

    尽管在人工智能对齐方面取得了一些进展，但语言模型（LM）仍然容易受到对抗性攻击或破解攻击的影响，其中对手修改输入提示以诱导有害行为。虽然已经提出了一些防御方法，但它们仅关注狭窄的威胁模型，并不能提供强大的防御。为了实现强大的防御，我们首次提出了用于对抗破解攻击的对抗目标，并提出了一种名为鲁棒提示优化（RPO）的算法，该算法利用基于梯度的令牌优化来确保输出的无害性。通过这种方法，我们得到了一个易于访问的后缀，显著改善了对破解攻击的强韧性，包括优化过程中出现的破解攻击以及未知的破解攻击，将攻击成功率从84%降低到8.66%，在20个破解攻击中。此外，我们还发现RPO对正常LM使用的影响较小，在适应性攻击下仍然有效，并且可以迁移到黑盒模型中，降低攻击成功率。

    Despite advances in AI alignment, language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior. While some defenses have been proposed, they focus on narrow threat models and fall short of a strong defense, which we posit should be effective, universal, and practical. To achieve this, we propose the first adversarial objective for defending LMs against jailbreaking attacks and an algorithm, robust prompt optimization (RPO), that uses gradient-based token optimization to enforce harmless outputs. This results in an easily accessible suffix that significantly improves robustness to both jailbreaks seen during optimization and unknown, held-out jailbreaks, reducing the attack success rate on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find that RPO has a minor effect on normal LM use, is successful under adaptive attacks, and can transfer to black-box models, reducing the success
    
[^14]: 学习类人表示以实现学习类人价值观

    Learning Human-like Representations to Enable Learning Human Values

    [https://arxiv.org/abs/2312.14106](https://arxiv.org/abs/2312.14106)

    通过学习类人的表示，可以实现机器学习系统符合人类价值观，支持伦理等多方面的价值对齐。

    

    如何构建与人类价值观相一致的人工智能系统，以避免造成伤害或违反社会对可接受行为的标准？我们认为，人类与人工智能代理之间的表征对齐有助于价值观的对齐。使人工智能系统学习类人类对世界的表示具有许多已知好处，包括提高泛化能力、增强对领域转移的稳健性和提高少样本学习性能。我们提出，这种机器学习（ML）模型与人类之间的表示对齐也可以支持价值对齐，使ML系统遵循人类价值观和社会规范。我们关注伦理学作为价值对齐的一个方面，并在多臂老虎机设置中使用各种方法训练ML代理，其中奖励反映所选行动的道德可接受性。我们使用一个合成实验来证明代理与环境之间的表示对齐

    arXiv:2312.14106v2 Announce Type: replace  Abstract: How can we build AI systems that are aligned with human values to avoid causing harm or violating societal standards for acceptable behavior? We argue that representational alignment between humans and AI agents facilitates value alignment. Making AI systems learn human-like representations of the world has many known benefits, including improving generalization, robustness to domain shifts, and few-shot learning performance. We propose that this kind of representational alignment between machine learning (ML) models and humans can also support value alignment, allowing ML systems to conform to human values and societal norms. We focus on ethics as one aspect of value alignment and train ML agents using a variety of methods in a multi-armed bandit setting, where rewards reflect the moral acceptability of the chosen action. We use a synthetic experiment to demonstrate that agents' representational alignment with the environment bounds
    
[^15]: 使用特征生成和融合的半监督健康指数监测

    Semi-Supervised Health Index Monitoring with Feature Generation and Fusion

    [https://arxiv.org/abs/2312.02867](https://arxiv.org/abs/2312.02867)

    通过深度半监督异常检测（DeepSAD）方法进行健康指数构建，并提出了多样性损失来丰富条件指标。

    

    健康指数（HI）对于评估系统健康状态至关重要，有助于识别异常，并预测对高安全性和可靠性要求高的系统的剩余使用寿命。在实现高精度的同时降低成本，紧密监测至关重要。在现实应用中获取HI标签往往成本高昂，需要连续、精确的健康测量。因此，利用可能提供潜在机器磨损状态指示的“运行至故障”数据集，更方便采用半监督工具构建HI。

    arXiv:2312.02867v2 Announce Type: replace  Abstract: The Health Index (HI) is crucial for evaluating system health, aiding tasks like anomaly detection and predicting remaining useful life for systems demanding high safety and reliability. Tight monitoring is crucial for achieving high precision at a lower cost. Obtaining HI labels in real-world applications is often cost-prohibitive, requiring continuous, precise health measurements. Therefore, it is more convenient to leverage run-to failure datasets that may provide potential indications of machine wear condition, making it necessary to apply semi-supervised tools for HI construction. In this study, we adapt the Deep Semi-supervised Anomaly Detection (DeepSAD) method for HI construction. We use the DeepSAD embedding as a condition indicators to address interpretability challenges and sensitivity to system-specific factors. Then, we introduce a diversity loss to enrich condition indicators. We employ an alternating projection algorit
    
[^16]: SINCERE: 监督信息噪声-对比估计再审

    SINCERE: Supervised Information Noise-Contrastive Estimation REvisited

    [https://arxiv.org/abs/2309.14277](https://arxiv.org/abs/2309.14277)

    SINCERE提出了一个理论上合理的监督扩展，避免了同一类别的图像相互排斥，通过更好地分离不同类别的嵌入，在保持竞争性分类准确性的同时实现了更好的效果。

    

    信息噪声对比估计（InfoNCE）损失函数由于其强大的实证结果和理论动机，为许多自监督深度学习方法提供了基础。先前的工作表明，监督对比（SupCon）损失可扩展InfoNCE以从可用类标签中学习。然而，在这项工作中，我们发现先前的SupCon损失公式存在疑问的理由，因为它可能会促使来自同一类别的某些图像在学习到的嵌入空间中相互排斥。我们提出了监督信息噪声-对比估计再审（SINCERE）损失，作为信息噪声对比估计的理论上合理的监督扩展，它永远不会导致来自同一类别的图像相互排斥。实验表明，SINCERE导致不同类别的嵌入更好地分离，同时对于监督和迁移学习提供具有竞争力的分类准确性。我们进一步展示了一个信息论上的下界

    arXiv:2309.14277v2 Announce Type: replace-cross  Abstract: The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation. Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels. However, in this work we find that the prior SupCon loss formulation has questionable justification because it can encourage some images from the same class to repel one another in the learned embedding space. We propose the Supervised InfoNCE REvisited (SINCERE) loss as a theoretically-justified supervised extension of InfoNCE that never causes images from the same class to repel one another. Experiments show that SINCERE leads to better separation of embeddings from different classes while delivering competitive classification accuracy for supervised and transfer learning. We further show an information-theoretic boun
    
[^17]: K折交叉验证是否是机器学习中最好的模型选择方法？

    Is K-fold cross validation the best model selection method for Machine Learning?. (arXiv:2401.16407v1 [stat.ML])

    [http://arxiv.org/abs/2401.16407](http://arxiv.org/abs/2401.16407)

    K折交叉验证在机器学习中是常用的模型选择方法，但在处理小样本数据集和异质数据源时存在困难。

    

    机器学习作为一种能够紧凑表示复杂模式的技术，具有显著的预测推理潜力。K折交叉验证（CV）是确定机器学习结果是否是随机生成的最常用方法，并经常优于传统的假设检验。这种改进利用了直接从机器学习分类中获得的度量，比如准确性，这些度量没有参数描述。为了在机器学习流程中进行频率分析，可以添加排列测试或来自数据分区（即折叠）的简单统计量来估计置信区间。不幸的是，无论是参数化还是非参数化测试都无法解决围绕分割小样本数据集和来自异质数据源的学习固有问题。机器学习严重依赖学习参数和数据在折叠中的分布，这重新概括了熟悉的困难情况。

    As a technique that can compactly represent complex patterns, machine learning has significant potential for predictive inference. K-fold cross-validation (CV) is the most common approach to ascertaining the likelihood that a machine learning outcome is generated by chance and frequently outperforms conventional hypothesis testing. This improvement uses measures directly obtained from machine learning classifications, such as accuracy, that do not have a parametric description. To approach a frequentist analysis within machine learning pipelines, a permutation test or simple statistics from data partitions (i.e. folds) can be added to estimate confidence intervals. Unfortunately, neither parametric nor non-parametric tests solve the inherent problems around partitioning small sample-size datasets and learning from heterogeneous data sources. The fact that machine learning strongly depends on the learning parameters and the distribution of data across folds recapitulates familiar diffic
    
[^18]: 贝叶斯非参数方法与数据驱动鲁棒优化的结合

    Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])

    [http://arxiv.org/abs/2401.15771](http://arxiv.org/abs/2401.15771)

    本文提出了一种将贝叶斯非参数方法与最新的决策理论模型相结合的鲁棒优化准则，通过这种方法，可以在线性回归问题中获得有稳定性和优越性能的结果。

    

    训练机器学习和统计模型通常涉及优化数据驱动的风险准则。风险通常是根据经验数据分布计算的，但由于分布不确定性，这可能导致性能不稳定和不好的样本外表现。在分布鲁棒优化的精神下，我们提出了一个新颖的鲁棒准则，将贝叶斯非参数（即狄利克雷过程）理论和最近的平滑模糊规避偏好的决策理论模型的见解相结合。首先，我们强调了与标准正则化经验风险最小化技术的新连接，其中包括岭回归和套索回归。然后，我们从理论上证明了鲁棒优化过程在有限样本和渐近统计保证方面的有利性存在。对于实际实施，我们提出并研究了基于众所周知的狄利克雷过程表示的可行近似准则。

    Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
    
[^19]: 走向基于原则的图形变换器

    Towards Principled Graph Transformers. (arXiv:2401.10119v1 [cs.LG])

    [http://arxiv.org/abs/2401.10119](http://arxiv.org/abs/2401.10119)

    边缘变换器是一个全局注意力模型，它具有至少3-WL的表达能力，能够在预测性能上超过其他架构，而不依赖于位置或结构编码。

    

    基于k维Weisfeiler-Leman（k-WL）层次结构的图形学习架构提供了理论上很好理解的表达能力。然而，这样的架构在真实任务中往往无法提供可靠的预测性能，从而限制了它们的实际影响力。相比之下，基于全局注意力的模型如图形变换器在实践中表现出了强大的性能，但是将它们的表达能力与k-WL层次结构进行比较仍然具有挑战性，尤其是因为这些架构依赖于位置或结构编码来实现其表达能力和预测性能。为了解决这个问题，我们展示了最近提出的边缘变换器，这是一个在节点对而不是节点上进行操作的全局注意力模型，具有至少3-WL的表达能力。经验上，我们证明了边缘变换器在预测性能上超过了其他理论对齐的架构，同时不依赖于位置或结构编码。

    Graph learning architectures based on the k-dimensional Weisfeiler-Leman (k-WL) hierarchy offer a theoretically well-understood expressive power. However, such architectures often fail to deliver solid predictive performance on real-world tasks, limiting their practical impact. In contrast, global attention-based models such as graph transformers demonstrate strong performance in practice, but comparing their expressive power with the k-WL hierarchy remains challenging, particularly since these architectures rely on positional or structural encodings for their expressivity and predictive performance. To address this, we show that the recently proposed Edge Transformer, a global attention model operating on node pairs instead of nodes, has at least 3-WL expressive power. Empirically, we demonstrate that the Edge Transformer surpasses other theoretically aligned architectures regarding predictive performance while not relying on positional or structural encodings.
    
[^20]: 超越遗憾：贝叶斯优化的几何度量

    Beyond Regrets: Geometric Metrics for Bayesian Optimization. (arXiv:2401.01981v1 [cs.LG])

    [http://arxiv.org/abs/2401.01981](http://arxiv.org/abs/2401.01981)

    本论文提出了四个新的几何度量，可以比较贝叶斯优化算法在考虑查询点和全局最优解的几何特性时的性能。

    

    贝叶斯优化是一种针对黑盒子目标函数的原则性优化策略。它在科学发现和实验设计等各种实际应用中的效果得到了证明。通常，贝叶斯优化的性能是通过基于遗憾的度量来评估的，如瞬时遗憾、简单遗憾和累积遗憾。这些度量仅依赖于函数评估，因此它们不考虑查询点和全局解之间的几何关系，也不考虑查询点本身。值得注意的是，它们不能区分是否成功找到了多个全局解。此外，它们也不能评估贝叶斯优化在给定搜索空间中利用和探索的能力。为了解决这些问题，我们提出了四个新的几何度量，即精确度、召回率、平均度和平均距离。这些度量使我们能够比较考虑查询点和全局最优解的几何特性的贝叶斯优化算法。

    Bayesian optimization is a principled optimization strategy for a black-box objective function. It shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. In general, the performance of Bayesian optimization is assessed by regret-based metrics such as instantaneous, simple, and cumulative regrets. These metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. Notably, they cannot discriminate if multiple global solutions are successfully found. Moreover, they do not evaluate Bayesian optimization's abilities to exploit and explore a search space given. To tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. These metrics allow us to compare Bayesian optimization algorithms considering the geometry of both query points and global optima, or que
    
[^21]: 在线转换及其带有切换成本：稳健和学习增强算法

    Online Conversion with Switching Costs: Robust and Learning-Augmented Algorithms. (arXiv:2310.20598v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2310.20598](http://arxiv.org/abs/2310.20598)

    本论文介绍并研究了在线转换及其带有切换成本的问题，并提出了具有竞争力的阈值算法以及学习增强算法，这些算法在最小化和最大化变体中都表现出优越性能。

    

    我们介绍并研究在线转换及其带有切换成本的问题。这个问题涵盖了能源和可持续性交叉领域中出现的一系列新问题。在这个问题中，在线玩家试图在固定的时间段内购买（或销售）资产的分数份额，每个时间步骤都会公布成本（或价格）函数，并且玩家必须做出不可撤消的决策，决定转换的资产数量。当玩家连续时间步骤中改变决策时，也会产生切换成本，即在购买量增加或减少时。我们介绍了在这个问题的最小化和最大化变体中具有竞争力（稳健）的基于阈值的算法，并且证明它们是确定性在线算法中的最优算法。然后，我们提出了学习增强算法，利用不可信的黑盒建议（例如机器学习模型的预测）来显著改善算法性能。

    We introduce and study online conversion with switching costs, a family of online problems that capture emerging problems at the intersection of energy and sustainability. In this problem, an online player attempts to purchase (alternatively, sell) fractional shares of an asset during a fixed time horizon with length $T$. At each time step, a cost function (alternatively, price function) is revealed, and the player must irrevocably decide an amount of asset to convert. The player also incurs a switching cost whenever their decision changes in consecutive time steps, i.e., when they increase or decrease their purchasing amount. We introduce competitive (robust) threshold-based algorithms for both the minimization and maximization variants of this problem, and show they are optimal among deterministic online algorithms. We then propose learning-augmented algorithms that take advantage of untrusted black-box advice (such as predictions from a machine learning model) to achieve significant
    
[^22]: 一种由语义通信增强的无线AI生成内容（AIGC）供应框架

    A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered by Semantic Communication. (arXiv:2310.17705v1 [cs.NI])

    [http://arxiv.org/abs/2310.17705](http://arxiv.org/abs/2310.17705)

    一种由语义通信增强的无线AI生成内容（AIGC）供应框架，通过使用语义信息而不是所有的二进制位提取和传输内容，以解决在无线网络中提供最优AIGC服务的挑战。

    

    近期，生成式AI应用通过创建多样化且高质量的AI生成内容（AIGC）来满足广大用户群体的需求。随着移动设备的普及和移动流量的快速增长，通过无线通信网络提供对高质量AIGC服务的无处不在的访问已成为AIGC产品的未来方向。然而，在不稳定的信道、有限的带宽资源和分布不均匀的计算资源的无线网络中提供最优的AIGC服务是具有挑战性的。为了解决这些挑战，我们提出了一个由语义通信（SemCom）增强的AIGC（SemAIGC）生成和传输框架，其中只需提取和传输内容的语义信息而不是所有的二进制位。具体而言，SemAIGC在语义编码器和解码器中集成了基于扩散的模型，以实现高效的内容生成和灵活调整计算工作负载的目的。

    Generative AI applications are recently catering to a vast user base by creating diverse and high-quality AI-generated content (AIGC). With the proliferation of mobile devices and rapid growth of mobile traffic, providing ubiquitous access to high-quality AIGC services via wireless communication networks is becoming the future direction for AIGC products. However, it is challenging to provide optimal AIGC services in wireless networks with unstable channels, limited bandwidth resources, and unevenly distributed computational resources. To tackle these challenges, we propose a semantic communication (SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where only semantic information of the content rather than all the binary bits should be extracted and transmitted by using SemCom. Specifically, SemAIGC integrates diffusion-based models within the semantic encoder and decoder for efficient content generation and flexible adjustment of the computing workload of both tr
    
[^23]: 使用因果感知图神经网络在动态图中预测时间中心性

    Using Causality-Aware Graph Neural Networks to Predict Temporal Centralities in Dynamic Graphs. (arXiv:2310.15865v1 [cs.LG])

    [http://arxiv.org/abs/2310.15865](http://arxiv.org/abs/2310.15865)

    本研究提出了一种使用因果感知图神经网络预测动态图中的时间中心性的方法，并在不同领域的13个时间图上进行了实验验证，结果显示该方法显著改善了介数和接近度中心性的预测能力。

    

    节点中心性在网络科学、社交网络分析和推荐系统中起着重要作用。在时间数据中，静态基于路径的中心性如接近度或介数可能会对节点在时间图中的真实重要性产生误导。为了解决这个问题，已经定义了基于节点对之间最短时间路径的时间一般化介数和接近度。然而，这些一般化的一个主要问题是计算这样的路径的计算成本较高。为了解决这个问题，我们研究了De Bruijn图神经网络(DBGNN)，一种因果感知的图神经网络架构，在时间序列数据中预测基于路径的时间中心性。我们在13个生物和社交系统的时间图中实验评估了我们的方法，并显示它相比静态图卷积方法显著改善了介数和接近度中心性的预测能力。

    Node centralities play a pivotal role in network science, social network analysis, and recommender systems. In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph. To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes. However, a major issue of those generalizations is that the calculation of such paths is computationally expensive. Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data. We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolut
    
[^24]: 一种双潜在状态学习方法：利用区域网络相似性进行QoS预测

    A Dual Latent State Learning Approach: Exploiting Regional Network Similarities for QoS Prediction. (arXiv:2310.05988v1 [cs.LG])

    [http://arxiv.org/abs/2310.05988](http://arxiv.org/abs/2310.05988)

    本文介绍了一种名为R2SL的基于区域的双潜在状态学习网络，该网络通过汇总数据来捕捉区域网络行为的细微差别，并采用增强的Huber损失函数来提高QoS预测性能。

    

    特定区域内的个体对象，无论是用户还是服务，通常由于它们来自同一城市或自治系统（AS），展现出相似的网络状态。尽管存在区域网络相似性，但许多现有技术忽视了其潜力，导致由于数据稀疏性和标签不平衡等挑战而产生表现不佳。本文引入了基于区域的双潜在状态学习网络（R2SL），这是一个新颖的深度学习框架，旨在克服传统基于个体对象的QoS预测技术的缺点。与之前的方法不同，R2SL通过从公共区域汇总的数据构建了两个不同的区域网络潜在状态：城市网络潜在状态和AS网络潜在状态。此外，R2SL采用了增强的Huber损失函数。

    Individual objects, whether users or services, within a specific region often exhibit similar network states due to their shared origin from the same city or autonomous system (AS). Despite this regional network similarity, many existing techniques overlook its potential, resulting in subpar performance arising from challenges such as data sparsity and label imbalance. In this paper, we introduce the regional-based dual latent state learning network(R2SL), a novel deep learning framework designed to overcome the pitfalls of traditional individual object-based prediction techniques in Quality of Service (QoS) prediction. Unlike its predecessors, R2SL captures the nuances of regional network behavior by deriving two distinct regional network latent states: the city-network latent state and the AS-network latent state. These states are constructed utilizing aggregated data from common regions rather than individual object data. Furthermore, R2SL adopts an enhanced Huber loss function that
    
[^25]: 通过不确定性和平滑性实现强化学习的鲁棒离线到在线学习

    Towards Robust Offline-to-Online Reinforcement Learning via Uncertainty and Smoothness. (arXiv:2309.16973v1 [cs.LG])

    [http://arxiv.org/abs/2309.16973](http://arxiv.org/abs/2309.16973)

    该论文提出了一种名为RO2O的算法，通过不确定性和平滑性增强离线训练的强化学习代理，在离线到在线学习中缓解性能下降问题。

    

    为了在强化学习中以较少的互动次数获得接近最优策略，一种有前途的方法是将离线强化学习（通过利用离线数据集提高样本效率）和在线强化学习（通过与环境互动探索信息丰富的转换）相结合。离线到在线（O2O）强化学习提供了一种改进离线训练代理的范例，但由于在线经验与离线数据之间存在显著的分布偏差，大多数离线强化学习算法在O2O适应中性能下降并无法实现稳定的策略改进。为了解决这个问题，我们提出了Robust Offline-to-Online（RO2O）算法，旨在通过不确定性和平滑性增强离线策略，并减少在线适应中的性能下降。具体而言，RO2O算法通过Q-ensemble实现不确定性惩罚，并通过对抗样本实现策略和价值的平滑性，从而实现RO2O的目标。

    To obtain a near-optimal policy with fewer interactions in Reinforcement Learning (RL), a promising approach involves the combination of offline RL, which enhances sample efficiency by leveraging offline datasets, and online RL, which explores informative transitions by interacting with the environment. Offline-to-Online (O2O) RL provides a paradigm for improving an offline trained agent within limited online interactions. However, due to the significant distribution shift between online experiences and offline data, most offline RL algorithms suffer from performance drops and fail to achieve stable policy improvement in O2O adaptation. To address this problem, we propose the Robust Offline-to-Online (RO2O) algorithm, designed to enhance offline policies through uncertainty and smoothness, and to mitigate the performance drop in online adaptation. Specifically, RO2O incorporates Q-ensemble for uncertainty penalty and adversarial samples for policy and value smoothness, which enable RO2
    
[^26]: Probabilistic Deep Supervision Network: 一种抗噪声的QoS预测方法

    Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction. (arXiv:2308.02580v1 [cs.SE])

    [http://arxiv.org/abs/2308.02580](http://arxiv.org/abs/2308.02580)

    PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function.

    

    在推荐系统中，QoS（服务质量）的预测是一项重要任务，准确预测未知的QoS值可以提高用户满意度。然而，现有的QoS预测技术在存在噪声数据（如虚假位置信息或虚拟网关）时可能表现不佳。在本文中，我们提出了一种新颖的QoS预测框架——概率深度监督网络（PDS-Net），以解决这个问题。PDS-Net利用基于高斯的概率空间监督中间层，并学习已知特征和真实标签的概率空间。此外，PDS-Net采用基于条件的多任务损失函数来识别具有噪声数据的对象，并通过优化这些对象的概率空间与真实标签概率空间之间的Kullback-Leibler距离，直接对从概率空间中采样的深度特征进行监督。因此，PDS-Net有效减少了因传播引起的错误。

    Quality of Service (QoS) prediction is an essential task in recommendation systems, where accurately predicting unknown QoS values can improve user satisfaction. However, existing QoS prediction techniques may perform poorly in the presence of noise data, such as fake location information or virtual gateways. In this paper, we propose the Probabilistic Deep Supervision Network (PDS-Net), a novel framework for QoS prediction that addresses this issue. PDS-Net utilizes a Gaussian-based probabilistic space to supervise intermediate layers and learns probability spaces for both known features and true labels. Moreover, PDS-Net employs a condition-based multitasking loss function to identify objects with noise data and applies supervision directly to deep features sampled from the probability space by optimizing the Kullback-Leibler distance between the probability space of these objects and the real-label probability space. Thus, PDS-Net effectively reduces errors resulting from the propag
    
[^27]: 用于量化生成式语言模型不确定性的PAC神经预测集学习

    PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])

    [http://arxiv.org/abs/2307.09254](http://arxiv.org/abs/2307.09254)

    本文提出了一种使用神经网络来量化生成式语言模型不确定性的PAC神经预测集学习方法，通过在多种语言数据集和模型上的实验证明，相比于标准基准方法，我们的方法平均提高了63％的量化不确定性。

    

    学习和量化模型的不确定性是增强模型可信度的关键任务。由于对生成虚构事实的担忧，最近兴起的生成式语言模型（GLM）特别强调可靠的不确定性量化的需求。本文提出了一种学习神经预测集模型的方法，该方法能够以可能近似正确（PAC）的方式量化GLM的不确定性。与现有的预测集模型通过标量值参数化不同，我们提出通过神经网络参数化预测集，实现更精确的不确定性量化，但仍满足PAC保证。通过在四种类型的语言数据集和六种类型的模型上展示，我们的方法相比标准基准方法平均提高了63％的量化不确定性。

    Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
    
[^28]: 将领域专业知识编码到多级模型中用于源位置的定位。

    Encoding Domain Expertise into Multilevel Models for Source Location. (arXiv:2305.08657v1 [stat.ML])

    [http://arxiv.org/abs/2305.08657](http://arxiv.org/abs/2305.08657)

    本文提出了一种基于贝叶斯多级模型的方法，可以将群体数据视为整体来考虑，并将领域专业知识和物理知识编码到模型中，以实现源位置的定位。

    

    在许多工业应用中，群体数据是普遍存在的。机器和基础设施越来越多地配备了传感系统，发出具有复杂相互依赖关系的遥测数据流。实际上，数据中心的监测程序倾向于将这些资产（以及各自的模型）视为不同的实体 - 独立运行并与独立数据相关联。相反，这项工作捕捉了一组系统模型之间的统计相关性和相互依赖关系。利用贝叶斯多级方法，数据的价值可以得到扩展，因为可以将人群作为一个整体来考虑，而不是作为组成部分。最有趣的是，领域专业知识和基础物理知识可以在系统、子组或人群水平上编码到模型中。我们提供了一个声发射（到达时间）映射源位置的示例，以说明多级模型如何自然地适用于表示。

    Data from populations of systems are prevalent in many industrial applications. Machines and infrastructure are increasingly instrumented with sensing systems, emitting streams of telemetry data with complex interdependencies. In practice, data-centric monitoring procedures tend to consider these assets (and respective models) as distinct -- operating in isolation and associated with independent data. In contrast, this work captures the statistical correlations and interdependencies between models of a group of systems. Utilising a Bayesian multilevel approach, the value of data can be extended, since the population can be considered as a whole, rather than constituent parts. Most interestingly, domain expertise and knowledge of the underlying physics can be encoded in the model at the system, subgroup, or population level. We present an example of acoustic emission (time-of-arrival) mapping for source location, to illustrate how multilevel models naturally lend themselves to represent
    
[^29]: 生成AI中的文本到图像扩散模型：一项调查

    Text-to-image Diffusion Model in Generative AI: A Survey. (arXiv:2303.07909v1 [cs.CV])

    [http://arxiv.org/abs/2303.07909](http://arxiv.org/abs/2303.07909)

    本文调查了文本到图像扩散模型以及相关应用，总结了最先进的方法，并探讨了挑战和未来方向。

    

    本文调查了文本到图像扩散模型，这些模型已经成为多种生成任务中流行的模型。作为一个自包含的工作，本调查从简单介绍基本扩散模型如何用于图像合成开始，接着是条件或引导如何改进学习。我们还总结了文本条件下的最先进的图像合成方法，并且进一步总结了文本引导创意生成和图像编辑的应用。除了迄今为止所取得的进展，我们还讨论了现有挑战和有前途的未来方向。

    This survey reviews text-to-image diffusion models in the context that diffusion models have emerged to be popular for a wide range of generative tasks. As a self-contained work, this survey starts with a brief introduction of how a basic diffusion model works for image synthesis, followed by how condition or guidance improves learning. Based on that, we present a review of state-of-the-art methods on text-conditioned image synthesis, i.e., text-to-image. We further summarize applications beyond text-to-image generation: text-guided creative generation and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.
    
[^30]: 核岭回归下伪标签的协变量转移策略

    Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift. (arXiv:2302.10160v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2302.10160](http://arxiv.org/abs/2302.10160)

    该论文提出了一种关于核岭回归的协变量转移策略，通过使用伪标签进行模型选择，能够适应不同特征分布下的学习，实现均方误差最小化。

    

    我们提出并分析了一种基于协变量转移的核岭回归方法。我们的目标是在目标分布上学习一个均方误差最小的回归函数，基于从目标分布采样的未标记数据和可能具有不同特征分布的已标记数据。我们将已标记数据分成两个子集，并分别进行核岭回归，以获得候选模型集合和一个填充模型。我们使用后者填充缺失的标签，然后相应地选择最佳的候选模型。我们的非渐近性过量风险界表明，在相当一般的情况下，我们的估计器能够适应目标分布以及协变量转移的结构。它能够实现渐近正态误差率直到对数因子的最小极限优化。在模型选择中使用伪标签不会产生主要负面影响。

    We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate model accordingly. Our non-asymptotic excess risk bounds show that in quite general scenarios, our estimator adapts to the structure of the target distribution as well as the covariate shift. It achieves the minimax optimal error rate up to a logarithmic factor. The use of pseudo-labels in model selection does not have major negative impacts.
    
[^31]: 意识是学习的过程：通过绑定学习的预测处理系统可能会将自己感知为有意识的

    Consciousness is learning: predictive processing systems that learn by binding may perceive themselves as conscious. (arXiv:2301.07016v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2301.07016](http://arxiv.org/abs/2301.07016)

    通过层级绑定和联想检索变为短期和长期声明性记忆的在线预测处理系统可能会感知到自己具有意识。

    

    机器学习算法在特定复杂领域实现了超越人类的表现。然而，从少量示例中进行在线学习，并在不同领域之间高效地泛化仍然是难以实现的。在人类身上，这种学习通过声明性存储过程进行，并且与意识密切相关。预测处理被推广为一种基于贝叶斯推理框架的原则性方法，用于理解皮质如何实现深度生成感知模型，用于感官数据和行为控制。然而，预测处理对于快速组成式学习或意识之谜提供了很少的直接见解。在这里，我们提出，通过通过绑定预测中的层次模型来实现在线学习，预测处理系统可以通过从单个示例中为感知和行动形成工作记忆，在新情况下灵活泛化，这可通过联想检索变为短期和长期的声明性记忆。我们认为，这个过程，我们称之为“在线层级预测绑定”，也可能是系统感知自己具有意识的必要条件。由此产生的模型提供了一种关于感知的、运动的、认知的和情感的意识的统一解释，并具有进化和发育生物学的深刻根源。

    Machine learning algorithms have achieved superhuman performance in specific complex domains. Yet learning online from few examples and efficiently generalizing across domains remains elusive. In humans such learning proceeds via declarative memory formation and is closely associated with consciousness. Predictive processing has been advanced as a principled Bayesian inference framework for understanding the cortex as implementing deep generative perceptual models for both sensory data and action control. However, predictive processing offers little direct insight into fast compositional learning or the mystery of consciousness. Here we propose that through implementing online learning by hierarchical binding of unpredicted inferences, a predictive processing system may flexibly generalize in novel situations by forming working memories for perceptions and actions from single examples, which can become short- and long-term declarative memories retrievable by associative recall. We argu
    

