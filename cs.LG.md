# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide](https://arxiv.org/abs/2404.01039) | 该研究是第一份致力于超图神经网络的调查报告，深入介绍了HNN架构、训练策略和应用，为从事数据挖掘和机器学习的研究人员提供了重要的指导。 |
| [^2] | [MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection](https://arxiv.org/abs/2403.19888) | MambaMixer是一种新的架构，提出了具有数据依赖权重的双重选择机制，称为选择性标记和通道混合器，对长序列建模具有潜在优势。 |
| [^3] | [The Elements of Differentiable Programming](https://arxiv.org/abs/2403.14606) | 可微分编程是一个新的编程范式，使得复杂程序能够端对端地进行微分，实现基于梯度的参数优化。 |
| [^4] | [A Unified Framework for Model Editing](https://arxiv.org/abs/2403.14236) | 这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。 |
| [^5] | [RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content](https://arxiv.org/abs/2403.13031) | RigorLLM提出了一种新颖的框架，旨在高效有效地调节LLMs的有害和不安全输入和输出，包括能量数据增强、最小-最大优化安全输入后缀，以及基于数据增强的鲁棒KNN与LLMs融合模型。 |
| [^6] | [MELTing point: Mobile Evaluation of Language Transformers](https://arxiv.org/abs/2403.12844) | 该研究对移动设备上大型语言模型（LLMs）的执行进行了首次系统性研究，并创建了自动化基础架构MELT来支持其评估和性能测试。 |
| [^7] | [Dissecting Language Models: Machine Unlearning via Selective Pruning](https://arxiv.org/abs/2403.01267) | 介绍了一种针对大型语言模型的机器去学习方法，通过选择性修剪神经元来实现去学习，发现LLMs中的神经元在特定任务中具有不同的重要性。 |
| [^8] | [A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features](https://arxiv.org/abs/2403.01046) | 证明在1-D数据上训练神经网络等价于解决一个具有固定特征字典矩阵的凸Lasso问题，为全局最优网络和解空间提供了洞察。 |
| [^9] | [Supervised machine learning for microbiomics: bridging the gap between current and best practices](https://arxiv.org/abs/2402.17621) | 该研究通过分析大量期刊文章，总结了监督机器学习在微生物组学中的现有实践，探讨了实验设计方法的优缺点，并提出了如何避免常见实验设计缺陷的指导。 |
| [^10] | [Efficient Unbiased Sparsification](https://arxiv.org/abs/2402.14925) | 该论文描述了对于排列不变或者可加可分的分裂函数，高效的无偏稀疏化特征。 |
| [^11] | [SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning](https://arxiv.org/abs/2402.11933) | SLADE通过自监督学习在边缘流中迅速检测动态异常，无需依赖标签，主要通过观察节点交互模式的偏差来检测节点状态转变。 |
| [^12] | [World Model on Million-Length Video And Language With RingAttention](https://arxiv.org/abs/2402.08268) | 该论文介绍了一个使用百万长度的视频和语言序列进行联合建模的环形注意力世界模型。该模型通过利用视频序列中的时间信息和语言的文本知识以及逐渐增加上下文大小的方法提高了AI辅助人类的能力。 |
| [^13] | [Solving Deep Reinforcement Learning Benchmarks with Linear Policy Networks](https://arxiv.org/abs/2402.06912) | 本研究通过使用进化策略(ES)来优化神经网络的权重，以通过直接策略搜索解决深度强化学习(DRL)基准问题。研究结果显示，ES可以在许多基准任务中找到有效的线性策略，与当前使用更大网络的DRL方法相比，这表明当前的基准问题比以往认为的更容易解决。 |
| [^14] | [SAE: Single Architecture Ensemble Neural Networks](https://arxiv.org/abs/2402.06580) | SAE是一种单一架构集合神经网络方法，通过学习集合输入的最佳退出数量和深度，在任务上显示出优越的准确性和置信度校准。它能够根据特定架构或应用程序灵活地定制其配置。 |
| [^15] | [Heterophily-Aware Fair Recommendation using Graph Convolutional Networks](https://arxiv.org/abs/2402.03365) | 本文提出了一种利用图卷积网络的公平推荐系统，名为HetroFair，旨在提高项目侧的公平性。HetroFair使用公平注意力和异质性特征加权两个组件来生成具有公平性意识的嵌入。 |
| [^16] | [Learning Best-in-Class Policies for the Predict-then-Optimize Framework](https://arxiv.org/abs/2402.03256) | 我们提出了一种新颖的决策感知替代损失函数家族，用于predict-then-optimize框架，并且通过数值证据证实了其在误设置下的优越性。 |
| [^17] | [Copyright Protection in Generative AI: A Technical Perspective](https://arxiv.org/abs/2402.02333) | 本文从技术角度全面概述了在生成型人工智能中的版权保护问题，包括数据版权和模型版权两个方面，并提出了一些创新的方法和技术。 |
| [^18] | [Arrows of Time for Large Language Models](https://arxiv.org/abs/2401.17505) | 这篇论文通过研究自回归大型语言模型的时间方向性，发现了模型在建模自然语言能力上存在时间上的不对称性。从信息理论的角度来看，这种差异理论上是不应该存在的。通过稀疏性和计算复杂性的考虑，提供了一个理论框架来解释这种不对称性的出现。 |
| [^19] | [Towards Learning from Graphs with Heterophily: Progress and Future.](http://arxiv.org/abs/2401.09769) | 本调查综合概述了关于从带有异质性的图中学习的现有研究，并根据学习策略、模型架构和实际应用等方面对方法进行了分类。同时讨论了现有研究的主要挑战，并提出了未来研究的潜在方向。 |
| [^20] | [High-Probability Convergence for Composite and Distributed Stochastic Minimization and Variational Inequalities with Heavy-Tailed Noise.](http://arxiv.org/abs/2310.01860) | 提出了一种针对复合式和分布式优化问题的新的随机方法，通过剪裁梯度差值实现了紧致的高概率收敛性分析。 |
| [^21] | [On the Trade-offs between Adversarial Robustness and Actionable Explanations.](http://arxiv.org/abs/2309.16452) | 本论文研究了对抗鲁棒模型对可操作解释的影响，并通过理论和实证分析比较了对抗性鲁棒和非鲁棒模型生成的追索结果的成本和有效性之间的差异。 |
| [^22] | [Towards Robust Continual Learning with Bayesian Adaptive Moment Regularization.](http://arxiv.org/abs/2309.08546) | 基于贝叶斯自适应时刻正则化的鲁棒性持续学习方法能够在机器人应用中有效地解决灾难性遗忘问题，并具有轻量级和任务实验室等优势。 |
| [^23] | [Symplectic Structure-Aware Hamiltonian (Graph) Embeddings.](http://arxiv.org/abs/2309.04885) | 本文提出了SAH-GNN，一种在图神经网络中应用结构感知的辛系统哈密顿嵌入方法。与传统方法不同，SAH-GNN通过在训练过程中自适应学习辛结构，避免了依赖预定义标准辛结构形式的限制，并能够适应不同的图数据集，同时保持物理意义上的能量守恒。 |
| [^24] | [Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates.](http://arxiv.org/abs/2309.03227) | 本研究提出了一种使用药物专利和生物医学数据库相结合的方法，识别具有技术潜力和科学证据的药物再定位候选物。通过构建科学的生物医学知识图谱和基于专利的生物医学知识图谱，我们可以综合分析多种信息源，为药物再定位研究提供新的视角。 |
| [^25] | [Detecting Throat Cancer from Speech Signals Using Machine Learning: A Reproducible Literature Review.](http://arxiv.org/abs/2307.09230) | 本研究对使用机器学习和人工智能从语音记录中检测喉癌的文献进行了综述，发现了22篇相关论文，讨论了它们的方法和结果。研究使用了神经网络和梅尔频率倒谱系数提取音频特征，并通过迁移学习实现了分类，取得了一定的准确率。 |
| [^26] | [Optimizer's Information Criterion: Dissecting and Correcting Bias in Data-Driven Optimization.](http://arxiv.org/abs/2306.10081) | 这项研究提出了一个称为优化器的信息准则(OIC)的通用偏差校正方法，帮助解决数据驱动优化中的乐观偏差问题。该方法直接近似一阶偏差，并且不需要解决额外的优化问题，是在决策选择方面的一个创新。 |
| [^27] | [When Does Bottom-up Beat Top-down in Hierarchical Community Detection?.](http://arxiv.org/abs/2306.00833) | 本文研究了使用自下而上算法恢复Hierarchical Stochastic Block Model的树形结构和社区结构的理论保证，并确定了其在中间层次上达到了确切恢复信息理论阈值。 |
| [^28] | [Vector-Valued Variation Spaces and Width Bounds for DNNs: Insights on Weight Decay Regularization.](http://arxiv.org/abs/2305.16534) | 该论文提供了关于通过加权衰减训练的多输出ReLU神经网络的函数类型和相应的解决方案的新见解。 |
| [^29] | [Retrieving Texts based on Abstract Descriptions.](http://arxiv.org/abs/2305.12517) | 本研究针对语义检索问题，提出了一种基于摘要描述的文本检索模型，通过改进当前的文本嵌入方法，在标准最近邻搜索中取得了显著性能提升。 |
| [^30] | [Euler Characteristic Tools For Topological Data Analysis.](http://arxiv.org/abs/2303.14040) | 本文研究了欧拉特征技术在拓扑数据分析中的应用，利用点运算欧拉特征得到欧拉特征轮廓，在监督和无监督任务中实现了最先进性能，并提供了欧拉轮廓及其混合变换捕捉信息的启发式方法。 |
| [^31] | [Label-efficient Time Series Representation Learning: A Review.](http://arxiv.org/abs/2302.06433) | 这篇综述介绍了针对时间序列数据中标记数据稀缺性问题的现有方法，并提供了一个新颖的分类系统来归纳这些方法。该综述总结了每种方法的最新进展并提出了未来的研究方向。 |
| [^32] | [Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification.](http://arxiv.org/abs/2301.07609) | 该论文扩展了信息场理论(IFT)到物理信息场理论(PIFT)，将描述场的物理定律的信息编码为函数先验。从这个PIFT得出的后验与任何数值方案无关，并且可以捕捉多种模式。 |
| [^33] | [$\Phi$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation.](http://arxiv.org/abs/2209.15609) | 本文提出了一种物理指导的动态变分自编码器 ($\Phi$-DVAE) 用于将非结构化数据同化到物理模型中，解决了传统方法在未知映射情况下无法实现一致模型与数据综合的问题。 |
| [^34] | [Targeted Adaptive Design.](http://arxiv.org/abs/2205.14208) | TAD是一种新的目标自适应设计算法，可以通过高斯过程代理模型在指定公差中确定产生期望设计特征的最佳控制设置，相比其他自适应设计算法，具有更高的精度和效率。 |
| [^35] | [EXACT: How to Train Your Accuracy.](http://arxiv.org/abs/2205.09615) | 本文提出了一种新的分类任务优化框架，通过引入随机性，优化期望准确率，取得了强有力的替代分类损失的结果。 |
| [^36] | [Privacy-preserving machine learning with tensor networks.](http://arxiv.org/abs/2202.12319) | 本文展示了张量网络架构在保护隐私的机器学习中具有潜在优势，并提出了确保鲁棒性的明确条件。 |

# 详细

[^1]: 基于超图神经网络的调查：深入和分步指南

    A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide

    [https://arxiv.org/abs/2404.01039](https://arxiv.org/abs/2404.01039)

    该研究是第一份致力于超图神经网络的调查报告，深入介绍了HNN架构、训练策略和应用，为从事数据挖掘和机器学习的研究人员提供了重要的指导。

    

    高阶相互作用在现实世界中的复杂系统和应用中无处不在，因此，对于高阶相互作用的深度学习已成为数据挖掘和机器学习社区的一项重要议程。由于高阶相互作用网络在数学上被表达为超图，超图神经网络（HNNs）已成为在超图上进行表示学习的强大工具。鉴于这一新趋势，我们提出了首份致力于HNNs的调查报告，其中包含深入和分步指南。总体而言，本调查概述了HNN架构、训练策略和应用。首先，我们将现有的HNNs分解为四个设计组成部分：（i）输入特征，（ii）输入结构，（iii）消息传递方案，和（iv）训练策略。其次，我们考察HNNs如何通过各自的组成部分处理和学习高阶相互作用。第三，我们总结了HNNs在推荐、生物和医学中的最新应用。

    arXiv:2404.01039v1 Announce Type: new  Abstract: Higher-order interactions (HOIs) are ubiquitous in real-world complex systems and applications, and thus investigation of deep learning for HOIs has become a valuable agenda for the data mining and machine learning communities. As networks of HOIs are expressed mathematically as hypergraphs, hypergraph neural networks (HNNs) have emerged as a powerful tool for representation learning on hypergraphs. Given the emerging trend, we present the first survey dedicated to HNNs, with an in-depth and step-by-step guide. Broadly, the present survey overviews HNN architectures, training strategies, and applications. First, we break existing HNNs down into four design components: (i) input features, (ii) input structures, (iii) message-passing schemes, and (iv) training strategies. Second, we examine how HNNs address and learn HOIs with each of their components. Third, we overview the recent applications of HNNs in recommendation, biological and med
    
[^2]: MambaMixer：具有双重标记和通道选择的高效选择性状态空间模型

    MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection

    [https://arxiv.org/abs/2403.19888](https://arxiv.org/abs/2403.19888)

    MambaMixer是一种新的架构，提出了具有数据依赖权重的双重选择机制，称为选择性标记和通道混合器，对长序列建模具有潜在优势。

    

    深度学习的最新进展主要依赖于Transformers，因为它们具有数据依赖性并且能够实现大规模学习。然而，这些架构中的注意力模块展现出输入大小的二次时间和空间，限制了它们用于长序列建模的可扩展性。尽管最近有尝试为多维数据设计高效有效的架构主干，例如图像和多变量时间序列，但现有模型要么是数据独立的，要么无法允许跨维度和内部维度之间的通信。最近，状态空间模型（SSMs），尤其是具有高效硬件感知实现的选择性状态空间模型，展现出了用于长序列建模的潜在优势。受到SSMs成功的启发，我们提出了MambaMixer，一种新的具有数据依赖权重的架构，使用跨标记和通道的双重选择机制，称为选择性标记和通道混合器。

    arXiv:2403.19888v1 Announce Type: cross  Abstract: Recent advances in deep learning have mainly relied on Transformers due to their data dependency and ability to learn at scale. The attention module in these architectures, however, exhibits quadratic time and space in input size, limiting their scalability for long-sequence modeling. Despite recent attempts to design efficient and effective architecture backbone for multi-dimensional data, such as images and multivariate time series, existing models are either data independent, or fail to allow inter- and intra-dimension communication. Recently, State Space Models (SSMs), and more specifically Selective State Space Models, with efficient hardware-aware implementation, have shown promising potential for long sequence modeling. Motivated by the success of SSMs, we present MambaMixer, a new architecture with data-dependent weights that uses a dual selection mechanism across tokens and channels, called Selective Token and Channel Mixer. M
    
[^3]: 可微分编程的要素

    The Elements of Differentiable Programming

    [https://arxiv.org/abs/2403.14606](https://arxiv.org/abs/2403.14606)

    可微分编程是一个新的编程范式，使得复杂程序能够端对端地进行微分，实现基于梯度的参数优化。

    

    人工智能最近取得了显著进展，这得益于大型模型、庞大数据集、加速硬件，以及可微分编程的变革性力量。这种新的编程范式使复杂计算机程序（包括具有控制流和数据结构的程序）能够进行端对端的微分，从而实现对程序参数的基于梯度的优化。不仅仅是程序的微分，可微分编程也包括了程序优化、概率等多个领域的概念。本书介绍了可微分编程所需的基本概念，并采用了优化和概率两个主要视角进行阐述。

    arXiv:2403.14606v1 Announce Type: new  Abstract: Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the t
    
[^4]: 一个统一的模型编辑框架

    A Unified Framework for Model Editing

    [https://arxiv.org/abs/2403.14236](https://arxiv.org/abs/2403.14236)

    这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。

    

    模型编辑是一个不断发展的领域，专注于更新模型中嵌入的知识。在各种方法中，ROME和MEMIT作为主要的“定位和编辑”模型编辑技术脱颖而出。而MEMIT可以批量编辑记忆，ROME则一次只能改变一个事实。本文引入了一个统一的框架，将ROME和MEMIT纳入一个单一的概念框架，优化同一目标，我们称之为“保存-记忆”目标。该目标旨在在记忆新事实信息的同时保留某些选定向量的表示。具体来说，ROME使用等式约束优化此目标，而MEMIT采用更灵活的最小二乘约束。除了批量编辑外，MEMIT还可以在多个层面编辑模型。我们将编辑的分布从多个层面分开，区别于优化目标。

    arXiv:2403.14236v1 Announce Type: cross  Abstract: Model editing is a growing area focused on updating the knowledge embedded within models. Among the various methodologies, ROME and MEMIT stand out as leading "locate-and-edit" model editing techniques. While MEMIT enables batched editing of memories, ROME is limited to changing one fact at a time. This paper introduces a unifying framework that brings ROME and MEMIT under a single conceptual umbrella, optimizing for the same goal, which we call the "preservation-memorization" objective. This objective aims to preserve the representations of certain selected vectors while memorizing the representations of new factual information. Specifically, ROME optimizes this objective using an equality constraint, whereas MEMIT employs a more flexible least-square constraint. In addition to making batched edits, MEMIT also edits the model at multiple layers. We disentangle the distribution of edits to multiple layers from the optimization objectiv
    
[^5]: RigorLLM：针对大型语言模型抵御不良内容的鲁棒防护栏

    RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content

    [https://arxiv.org/abs/2403.13031](https://arxiv.org/abs/2403.13031)

    RigorLLM提出了一种新颖的框架，旨在高效有效地调节LLMs的有害和不安全输入和输出，包括能量数据增强、最小-最大优化安全输入后缀，以及基于数据增强的鲁棒KNN与LLMs融合模型。

    

    大语言模型（LLMs）的最新进展展示了其在不同领域的各种任务中的显著能力。然而，LLMs中出现的偏见以及在恶意输入下产生有害内容的潜力，尤其是对抗性攻击下，都带来了重大挑战。本文提出了面向大型语言模型的鲁棒防护栏（RigorLLM），这是一个新颖的框架，旨在高效有效地调节LLMs的有害和不安全输入和输出。通过采用多方面的方法，包括通过朗之万动力学进行基于能量的训练数据增强、通过极小极大优化针对输入优化安全后缀，以及基于我们的数据增强将鲁棒KNN与LLMs融合的基于融合的模型，RigorLLM为有害内容的调节提供了强大的解决方案。我们的实验评估

    arXiv:2403.13031v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs) have showcased remarkable capabilities across various tasks in different domains. However, the emergence of biases and the potential for generating harmful content in LLMs, particularly under malicious inputs, pose significant challenges. Current mitigation strategies, while effective, are not resilient under adversarial attacks. This paper introduces Resilient Guardrails for Large Language Models (RigorLLM), a novel framework designed to efficiently and effectively moderate harmful and unsafe inputs and outputs for LLMs. By employing a multi-faceted approach that includes energy-based training data augmentation through Langevin dynamics, optimizing a safe suffix for inputs via minimax optimization, and integrating a fusion-based model combining robust KNN with LLMs based on our data augmentation, RigorLLM offers a robust solution to harmful content moderation. Our experimental evalua
    
[^6]: MELTing point: 移动语言转换器的评估

    MELTing point: Mobile Evaluation of Language Transformers

    [https://arxiv.org/abs/2403.12844](https://arxiv.org/abs/2403.12844)

    该研究对移动设备上大型语言模型（LLMs）的执行进行了首次系统性研究，并创建了自动化基础架构MELT来支持其评估和性能测试。

    

    Transformers已经彻底改变了机器学习领域，逐渐应用于日常任务，赋予我们的计算机“智能的火花”。然而，它们的运行时需求阻碍了它们在移动设备上的广泛部署。在个人设备变得越来越强大，以及迅速隐私问题变得更加紧迫的情况下，我们探讨了大型语言模型（LLMs）在移动设备上执行的现状。为了实现这一目标，我们创建了自己的自动化基础架构MELT，支持在设备上无界面执行和评估LLMs，并支持不同的模型、设备和框架，包括Android、iOS和Nvidia Jetson设备。我们评估了流行的指令微调的LLMs，并利用不同的框架来测量它们的端到端和细粒度性能，跟踪它们的内存和能耗需求。

    arXiv:2403.12844v1 Announce Type: new  Abstract: Transformers have revolutionized the machine learning landscape, gradually making their way into everyday tasks and equipping our computers with ``sparks of intelligence''. However, their runtime requirements have prevented them from being broadly deployed on mobile. As personal devices become increasingly powerful and prompt privacy becomes an ever more pressing issue, we explore the current state of mobile execution of Large Language Models (LLMs). To achieve this, we have created our own automation infrastructure, MELT, which supports the headless execution and benchmarking of LLMs on device, supporting different models, devices and frameworks, including Android, iOS and Nvidia Jetson devices. We evaluate popular instruction fine-tuned LLMs and leverage different frameworks to measure their end-to-end and granular performance, tracing their memory and energy requirements along the way.   Our analysis is the first systematic study of o
    
[^7]: 解剖语言模型：通过选择性修剪实现机器去学习

    Dissecting Language Models: Machine Unlearning via Selective Pruning

    [https://arxiv.org/abs/2403.01267](https://arxiv.org/abs/2403.01267)

    介绍了一种针对大型语言模型的机器去学习方法，通过选择性修剪神经元来实现去学习，发现LLMs中的神经元在特定任务中具有不同的重要性。

    

    本文引入了一种专门为大型语言模型（LLMs）设计的机器去学习方法。我们提出了一种针对LLMs的选择性修剪方法，根据神经元对特定能力的相对重要性来移除神经元，而非整体网络性能。该方法是一种高效的计算和数据方法，用于识别和删除能够实现特定行为的神经元。我们的研究发现，LLMs中的前馈神经元和注意力神经元是专门化的；也就是说，对于特定任务，某些神经元比其他神经元更为关键。

    arXiv:2403.01267v1 Announce Type: cross  Abstract: Understanding and shaping the behaviour of Large Language Models (LLMs) is increasingly important as applications become more powerful and more frequently adopted. This paper introduces a machine unlearning method specifically designed for LLMs. We introduce a selective pruning method for LLMs that removes neurons based on their relative importance on a targeted capability compared to overall network performance. This approach is a compute- and data-efficient method for identifying and removing neurons that enable specific behaviours. Our findings reveal that both feed-forward and attention neurons in LLMs are specialized; that is, for specific tasks, certain neurons are more crucial than others.
    
[^8]: 一个镜子的库：低维深度神经网络是具有反射特征的凸Lasso模型

    A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features

    [https://arxiv.org/abs/2403.01046](https://arxiv.org/abs/2403.01046)

    证明在1-D数据上训练神经网络等价于解决一个具有固定特征字典矩阵的凸Lasso问题，为全局最优网络和解空间提供了洞察。

    

    我们证明在1-D数据上训练神经网络等价于解决一个带有固定、明确定义的特征字典矩阵的凸Lasso问题。具体的字典取决于激活函数和深度。我们考虑具有分段线性激活函数的两层网络，深窄的ReLU网络最多有4层，以及具有符号激活和任意深度的矩形和树网络。有趣的是，在ReLU网络中，第四层创建代表训练数据关于自身的反射的特征。Lasso表示法揭示了全局最优网络和解空间的洞察。

    arXiv:2403.01046v1 Announce Type: cross  Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.
    
[^9]: 用于微生物组学的监督机器学习：弥合当前和最佳实践之间的差距

    Supervised machine learning for microbiomics: bridging the gap between current and best practices

    [https://arxiv.org/abs/2402.17621](https://arxiv.org/abs/2402.17621)

    该研究通过分析大量期刊文章，总结了监督机器学习在微生物组学中的现有实践，探讨了实验设计方法的优缺点，并提出了如何避免常见实验设计缺陷的指导。

    

    机器学习（ML）将加速临床微生物组学创新，如疾病诊断和预后。这将需要高质量、可重现、可解释的工作流程，其预测能力达到或超过监管机构对临床工具设定的高门槛。我们通过深入分析2021-2022年发表的100篇同行评议的期刊文章，捕捉了当前将监督ML应用于微生物组学数据的实践的一个快照。我们采用数据驱动方法，引导讨论各种实验设计方法的优点，包括关键考虑因素，如如何减轻小数据集大小的影响同时避免数据泄漏。我们进一步提供关于如何避免可能损害模型性能、可信度和可重复性的常见实验设计缺陷的指南。讨论附有一个互动在线教程。

    arXiv:2402.17621v1 Announce Type: cross  Abstract: Machine learning (ML) is set to accelerate innovations in clinical microbiomics, such as in disease diagnostics and prognostics. This will require high-quality, reproducible, interpretable workflows whose predictive capabilities meet or exceed the high thresholds set for clinical tools by regulatory agencies. Here, we capture a snapshot of current practices in the application of supervised ML to microbiomics data, through an in-depth analysis of 100 peer-reviewed journal articles published in 2021-2022. We apply a data-driven approach to steer discussion of the merits of varied approaches to experimental design, including key considerations such as how to mitigate the effects of small dataset size while avoiding data leakage. We further provide guidance on how to avoid common experimental design pitfalls that can hurt model performance, trustworthiness, and reproducibility. Discussion is accompanied by an interactive online tutorial th
    
[^10]: 高效无偏稀疏化

    Efficient Unbiased Sparsification

    [https://arxiv.org/abs/2402.14925](https://arxiv.org/abs/2402.14925)

    该论文描述了对于排列不变或者可加可分的分裂函数，高效的无偏稀疏化特征。

    

    一个向量$p\in \mathbb{R}^n$的无偏$m$-稀疏化是一个具有平均值为$p$，最多有$m<n$个非零坐标的随机向量$Q\in \mathbb{R}^n。 无偏稀疏化可以压缩原始向量而不引入偏差；它出现在各种情境中，比如联邦学习和采样稀疏概率分布。 理想情况下，无偏稀疏化还应该最小化一个度量$Q$与原始$p$之间距离有多远的分裂函数$\mathsf{Div}(Q,p)$的期望值。 如果$Q$在这个意义上是最优的，那么我们称之为高效。 我们的主要结果描述了对于既是排列不变又是可加可分的分裂函数的高效无偏稀疏化。 令人惊讶的是，排列不变分裂函数的表征对于分裂函数的选择是健壮的，也就是说，我们针对平方欧氏距离的最优$Q$的类与我们的类重合了op

    arXiv:2402.14925v1 Announce Type: cross  Abstract: An unbiased $m$-sparsification of a vector $p\in \mathbb{R}^n$ is a random vector $Q\in \mathbb{R}^n$ with mean $p$ that has at most $m<n$ nonzero coordinates. Unbiased sparsification compresses the original vector without introducing bias; it arises in various contexts, such as in federated learning and sampling sparse probability distributions. Ideally, unbiased sparsification should also minimize the expected value of a divergence function $\mathsf{Div}(Q,p)$ that measures how far away $Q$ is from the original $p$. If $Q$ is optimal in this sense, then we call it efficient. Our main results describe efficient unbiased sparsifications for divergences that are either permutation-invariant or additively separable. Surprisingly, the characterization for permutation-invariant divergences is robust to the choice of divergence function, in the sense that our class of optimal $Q$ for squared Euclidean distance coincides with our class of op
    
[^11]: SLADE：通过自监督学习在边缘流中检测动态异常

    SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning

    [https://arxiv.org/abs/2402.11933](https://arxiv.org/abs/2402.11933)

    SLADE通过自监督学习在边缘流中迅速检测动态异常，无需依赖标签，主要通过观察节点交互模式的偏差来检测节点状态转变。

    

    为了检测真实世界图中的异常，如社交、电子邮件和金融网络，已经开发了各种方法。在大多数真实世界图随时间增长，自然地表示为边缘流的情况下，我们的目标是：(a)在异常发生时即时检测异常，(b)适应动态变化的状态，(c)处理动态异常标签的稀缺性。在本文中，我们提出了SLADE（边缘流异常检测的自监督学习），用于在边缘流中快速检测动态异常，而不依赖于标签。SLADE通过观察节点在时间上相互作用模式的偏差来检测节点进入异常状态的转变。为此，它训练一个深度神经网络执行两个自监督任务：(a)最小化节点表示中的漂移，(b)从短期生成长期交互模式。

    arXiv:2402.11933v1 Announce Type: new  Abstract: To detect anomalies in real-world graphs, such as social, email, and financial networks, various approaches have been developed. While they typically assume static input graphs, most real-world graphs grow over time, naturally represented as edge streams. In this context, we aim to achieve three goals: (a) instantly detecting anomalies as they occur, (b) adapting to dynamically changing states, and (c) handling the scarcity of dynamic anomaly labels. In this paper, we propose SLADE (Self-supervised Learning for Anomaly Detection in Edge Streams) for rapid detection of dynamic anomalies in edge streams, without relying on labels. SLADE detects the shifts of nodes into abnormal states by observing deviations in their interaction patterns over time. To this end, it trains a deep neural network to perform two self-supervised tasks: (a) minimizing drift in node representations and (b) generating long-term interaction patterns from short-term 
    
[^12]: 百万长度视频和语言的环形注意力世界模型

    World Model on Million-Length Video And Language With RingAttention

    [https://arxiv.org/abs/2402.08268](https://arxiv.org/abs/2402.08268)

    该论文介绍了一个使用百万长度的视频和语言序列进行联合建模的环形注意力世界模型。该模型通过利用视频序列中的时间信息和语言的文本知识以及逐渐增加上下文大小的方法提高了AI辅助人类的能力。

    

    当前的语言模型在理解难以用文字描述的世界方面表现不佳，并且在处理复杂的长篇任务时遇到困难。视频序列提供了只有语言和静态图像所不具备的宝贵时间信息，因此它们在与语言进行联合建模时具有吸引力。这种模型可以对人类的文本知识和物理世界进行理解，为辅助人类提供更广泛的人工智能能力。然而，从百万个标记的视频和语言序列中学习面临着记忆约束、计算复杂性和数据有限性的挑战。为了应对这些挑战，我们策划了一个包含多样化视频和书籍的大型数据集，利用环形注意力技术对长序列进行可扩展的训练，逐渐增加上下文大小从4K到1M个标记。本文的贡献如下：

    Current language models fall short in understanding aspects of the world not easily described in words, and struggle with complex, long-form tasks. Video sequences offer valuable temporal information absent in language and static images, making them attractive for joint modeling with language. Such models could develop a understanding of both human textual knowledge and the physical world, enabling broader AI capabilities for assisting humans. However, learning from millions of tokens of video and language sequences poses challenges due to memory constraints, computational complexity, and limited datasets. To address these challenges, we curate a large dataset of diverse videos and books, utilize the RingAttention technique to scalably train on long sequences, and gradually increase context size from 4K to 1M tokens. This paper makes the following contributions: (a) Largest context size neural network: We train one of the largest context size transformers on long video and language seq
    
[^13]: 用线性策略网络解决深度强化学习基准问题

    Solving Deep Reinforcement Learning Benchmarks with Linear Policy Networks

    [https://arxiv.org/abs/2402.06912](https://arxiv.org/abs/2402.06912)

    本研究通过使用进化策略(ES)来优化神经网络的权重，以通过直接策略搜索解决深度强化学习(DRL)基准问题。研究结果显示，ES可以在许多基准任务中找到有效的线性策略，与当前使用更大网络的DRL方法相比，这表明当前的基准问题比以往认为的更容易解决。

    

    尽管深度强化学习(DRL)算法能够学习有效的策略来解决像Atari游戏和机器人任务这样的挑战性问题，但算法复杂，训练时间往往较长。本研究探讨了进化策略(ES)与基于梯度的深度强化学习方法之间的表现差异。我们使用ES通过神经进化优化神经网络的权重，通过直接策略搜索来完成。我们对常规网络和由一个从观测到动作的单一线性层组成的策略网络进行基准测试；对于三种经典的ES方法和三种基于梯度的方法，如PPO。我们的结果表明，ES可以在许多RL基准任务中找到有效的线性策略，而DRL方法只能使用更大的网络找到成功的策略，这表明当前的基准问题比以前认为的更容易解决。有趣的是，即使对于更复杂的任务，ES的结果也与基于梯度的方法相当。

    Although Deep Reinforcement Learning (DRL) methods can learn effective policies for challenging problems such as Atari games and robotics tasks, algorithms are complex and training times are often long. This study investigates how evolution strategies (ES) perform compared to gradient-based deep reinforcement learning methods. We use ES to optimize the weights of a neural network via neuroevolution, performing direct policy search. We benchmark both regular networks and policy networks consisting of a single linear layer from observations to actions; for three classical ES methods and for three gradient-based methods such as PPO. Our results reveal that ES can find effective linear policies for many RL benchmark tasks, in contrast to DRL methods that can only find successful policies using much larger networks, suggesting that current benchmarks are easier to solve than previously assumed. Interestingly, also for higher complexity tasks, ES achieves results comparable to gradient-based
    
[^14]: SAE: 单一架构集合神经网络

    SAE: Single Architecture Ensemble Neural Networks

    [https://arxiv.org/abs/2402.06580](https://arxiv.org/abs/2402.06580)

    SAE是一种单一架构集合神经网络方法，通过学习集合输入的最佳退出数量和深度，在任务上显示出优越的准确性和置信度校准。它能够根据特定架构或应用程序灵活地定制其配置。

    

    单一神经网络架构的集合能够在任务上显示出优越的准确性和置信度校准。最近的方法通过提前退出或多输入多输出框架将集合压缩到单一网络中。然而，这些方法的景观迄今为止是零散的，因此很难选择适合特定任务的方法。此外，这些方法的算法性能落后于独立神经网络的集合，并需要广泛的架构调整。我们提出了一种新的方法，将这些方法统一到单一架构集合中。我们的方法在单一神经网络中学习集合输入的最佳退出数量和深度。这使得SAE框架可以根据特定架构或应用程序灵活地定制其配置。我们评估了在各种网络架构类型和大小上进行图像分类和回归的SAE。我们展示了与基线相当的准确性或置信度校准。

    Ensembles of separate neural networks (NNs) have shown superior accuracy and confidence calibration over single NN across tasks. Recent methods compress ensembles within a single network via early exits or multi-input multi-output frameworks. However, the landscape of these methods is fragmented thus far, making it difficult to choose the right approach for a given task. Furthermore, the algorithmic performance of these methods is behind the ensemble of separate NNs and requires extensive architecture tuning. We propose a novel methodology unifying these approaches into a Single Architecture Ensemble (SAE). Our method learns the optimal number and depth of exits per ensemble input in a single NN. This enables the SAE framework to flexibly tailor its configuration for a given architecture or application. We evaluate SAEs on image classification and regression across various network architecture types and sizes. We demonstrate competitive accuracy or confidence calibration to baselines w
    
[^15]: 利用图卷积网络的異质友善推荐方法

    Heterophily-Aware Fair Recommendation using Graph Convolutional Networks

    [https://arxiv.org/abs/2402.03365](https://arxiv.org/abs/2402.03365)

    本文提出了一种利用图卷积网络的公平推荐系统，名为HetroFair，旨在提高项目侧的公平性。HetroFair使用公平注意力和异质性特征加权两个组件来生成具有公平性意识的嵌入。

    

    近年来，图神经网络（GNNs）已成为提高推荐系统准确性和性能的流行工具。现代推荐系统不仅设计为为最终用户服务，还要让其他参与者（如项目和项目供应商）从中受益。这些参与者可能具有不同或冲突的目标和利益，这引发了对公平性和流行度偏差考虑的需求。基于GNN的推荐方法也面临不公平性和流行度偏差的挑战，其归一化和聚合过程受到这些挑战的影响。在本文中，我们提出了一种公平的基于GNN的推荐系统，称为HetroFair，旨在提高项目侧的公平性。HetroFair使用两个独立的组件生成具有公平性意识的嵌入：i）公平注意力，它在GNN的归一化过程中结合了点积，以减少节点度数的影响；ii）异质性特征加权，为不同的特征分配不同的权重。

    In recent years, graph neural networks (GNNs) have become a popular tool to improve the accuracy and performance of recommender systems. Modern recommender systems are not only designed to serve the end users, but also to benefit other participants, such as items and items providers. These participants may have different or conflicting goals and interests, which raise the need for fairness and popularity bias considerations. GNN-based recommendation methods also face the challenges of unfairness and popularity bias and their normalization and aggregation processes suffer from these challenges. In this paper, we propose a fair GNN-based recommender system, called HetroFair, to improve items' side fairness. HetroFair uses two separate components to generate fairness-aware embeddings: i) fairness-aware attention which incorporates dot product in the normalization process of GNNs, to decrease the effect of nodes' degrees, and ii) heterophily feature weighting to assign distinct weights to 
    
[^16]: 学习Predict-then-Optimize框架中的最优策略

    Learning Best-in-Class Policies for the Predict-then-Optimize Framework

    [https://arxiv.org/abs/2402.03256](https://arxiv.org/abs/2402.03256)

    我们提出了一种新颖的决策感知替代损失函数家族，用于predict-then-optimize框架，并且通过数值证据证实了其在误设置下的优越性。

    

    我们提出了一种新颖的决策感知替代损失函数家族，称为Perturbation Gradient（PG）损失，用于predict-then-optimize框架。这些损失直接近似了下游决策损失，并可以使用现成的基于梯度的方法进行优化。重要的是，与现有的替代损失不同，我们的PG损失的近似误差随着样本数量的增加而消失。这意味着优化我们的替代损失可以在渐近意义下得到最佳策略，即使在误设置下也是如此。这是第一个在误设置下的这样的结果，我们提供了数值证据证实了当基础模型误设置且噪声不是中心对称时，我们的PG损失在实践中显著优于现有的提案。鉴于在实践中误设置很常见--特别是当我们可能更喜欢一个更简单、更可解释的模型时--PG损失提供了一种新颖的、理论上有依据的、可计算的决策感知方法。

    We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. These losses directly approximate the downstream decision loss and can be optimized using off-the-shelf gradient-based methods. Importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. This implies that optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified and the noise is not centrally symmetric. Insofar as misspecification is commonplace in practice -- especially when we might prefer a simpler, more interpretable model -- PG losses offer a novel, theoretically justified, method for computationally tractable decision-aware 
    
[^17]: 生成型人工智能中的版权保护：技术视角

    Copyright Protection in Generative AI: A Technical Perspective

    [https://arxiv.org/abs/2402.02333](https://arxiv.org/abs/2402.02333)

    本文从技术角度全面概述了在生成型人工智能中的版权保护问题，包括数据版权和模型版权两个方面，并提出了一些创新的方法和技术。

    

    近年来，生成型人工智能（Generative AI）取得了快速发展，扩展了其创建文本、图像、音频和代码等合成内容的能力。这些深度生成模型（Deep Generative Models，DGMs）生成的内容高保真度和真实性引发了重大的版权问题。关于如何有效保护DGMs中的版权问题，已经进行了各种法律辩论。本文从技术角度提供了版权保护的全面概述。我们从两个不同的视角来进行研究：一是与数据所有者所持有的源数据相关的版权，二是与模型构建者所维护的生成模型相关的版权。对于数据版权，我们深入探讨了数据所有者如何保护其内容，并在不侵犯这些权利的情况下使用DGMs。对于模型版权，我们的讨论延伸到防止模型盗窃和识别特定模型生成的输出的策略。最后，我们强调了一些创新的方法和技术来处理这些版权问题。

    Generative AI has witnessed rapid advancement in recent years, expanding their capabilities to create synthesized content such as text, images, audio, and code. The high fidelity and authenticity of contents generated by these Deep Generative Models (DGMs) have sparked significant copyright concerns. There have been various legal debates on how to effectively safeguard copyrights in DGMs. This work delves into this issue by providing a comprehensive overview of copyright protection from a technical perspective. We examine from two distinct viewpoints: the copyrights pertaining to the source data held by the data owners and those of the generative models maintained by the model builders. For data copyright, we delve into methods data owners can protect their content and DGMs can be utilized without infringing upon these rights. For model copyright, our discussion extends to strategies for preventing model theft and identifying outputs generated by specific models. Finally, we highlight 
    
[^18]: 大型语言模型中的时间箭头

    Arrows of Time for Large Language Models

    [https://arxiv.org/abs/2401.17505](https://arxiv.org/abs/2401.17505)

    这篇论文通过研究自回归大型语言模型的时间方向性，发现了模型在建模自然语言能力上存在时间上的不对称性。从信息理论的角度来看，这种差异理论上是不应该存在的。通过稀疏性和计算复杂性的考虑，提供了一个理论框架来解释这种不对称性的出现。

    

    我们通过时间方向性的视角研究了自回归大型语言模型的概率建模。我们在实证上发现这类模型在建模自然语言能力上存在时间上的不对称性：预测下一个记号和预测前一个记号时的平均对数困惑度存在差异。这种差异既微妙又在不同的模态（语言、模型大小、训练时间等）下非常一致。从信息理论的角度来看，这在理论上是令人惊讶的，不应该存在这样的差异。我们提供了一个理论框架，解释了这种不对称性如何出现在稀疏性和计算复杂性考虑中，并概述了我们的结果带来的一些展望。

    We study the probabilistic modeling performed by Autoregressive Large Language Models through the angle of time directionality. We empirically find a time asymmetry exhibited by such models in their ability to model natural language: a difference in the average log-perplexity when trying to predict the next token versus when trying to predict the previous one. This difference is at the same time subtle and very consistent across various modalities (language, model size, training time, ...). Theoretically, this is surprising: from an information-theoretic point of view, there should be no such difference. We provide a theoretical framework to explain how such an asymmetry can appear from sparsity and computational complexity considerations, and outline a number of perspectives opened by our results.
    
[^19]: 走向异质图学习：进展与未来

    Towards Learning from Graphs with Heterophily: Progress and Future. (arXiv:2401.09769v1 [cs.SI])

    [http://arxiv.org/abs/2401.09769](http://arxiv.org/abs/2401.09769)

    本调查综合概述了关于从带有异质性的图中学习的现有研究，并根据学习策略、模型架构和实际应用等方面对方法进行了分类。同时讨论了现有研究的主要挑战，并提出了未来研究的潜在方向。

    

    图是用来模拟现实世界实体之间复杂关系的结构化数据。最近，异质图，其中连接的节点往往具有不同的标签或不同的特征，引起了广泛关注并找到了许多应用。与此同时，人们也在不断努力推进从异质图中学习。虽然有关该主题的调查存在，但它们只关注于异质图神经网络（GNNs），而忽略了异质图学习的其他子主题。在本调查中，我们全面回顾了关于从带有异质性的图中学习的现有研究。首先，我们收集了180多篇论文，介绍了该领域的发展。然后，我们根据层次分类法对现有方法进行了系统分类，包括学习策略、模型架构和实际应用。最后，我们讨论了现有研究的主要挑战，并突出了未来研究的潜在方向。

    Graphs are structured data that models complex relations between real-world entities. Heterophilous graphs, where linked nodes are prone to be with different labels or dissimilar features, have recently attracted significant attention and found many applications. Meanwhile, increasing efforts have been made to advance learning from heterophilous graphs. Although there exist surveys on the relevant topic, they focus on heterophilous GNNs, which are only sub-topics of heterophilous graph learning. In this survey, we comprehensively overview existing works on learning from graphs with heterophily.First, we collect over 180 publications and introduce the development of this field. Then, we systematically categorize existing methods based on a hierarchical taxonomy including learning strategies, model architectures and practical applications. Finally, we discuss the primary challenges of existing studies and highlight promising avenues for future research.More publication details and corres
    
[^20]: 高概率下具有重尾噪声的复合式和分布式随机最小化和变分不等式收敛性分析

    High-Probability Convergence for Composite and Distributed Stochastic Minimization and Variational Inequalities with Heavy-Tailed Noise. (arXiv:2310.01860v1 [math.OC])

    [http://arxiv.org/abs/2310.01860](http://arxiv.org/abs/2310.01860)

    提出了一种针对复合式和分布式优化问题的新的随机方法，通过剪裁梯度差值实现了紧致的高概率收敛性分析。

    

    近年来，对于具有轻微噪声假设的随机一阶优化方法的高概率分析受到了广泛关注。通常情况下，当噪声是重尾的时候，梯度剪裁是推导出良好的高概率保证的关键算法要素之一。然而，如果不加以处理地实现，剪裁操作会破坏常用的复合式和分布式优化方法（如Prox-SGD/Parallel SGD）的收敛性，即使在没有任何噪声的情况下也是如此。因此，许多高概率分析的工作仅考虑无约束的非分布式问题，现有的复合式/分布式问题的收敛性结果并不包括一些重要的特殊情况（如强凸问题），也不是最优的。为了解决这个问题，我们提出了基于梯度差值剪裁的复合式和分布式优化的新的随机方法，并证明了紧致的高概率收敛性结果（包括几乎所有的场景）。

    High-probability analysis of stochastic first-order optimization methods under mild assumptions on the noise has been gaining a lot of attention in recent years. Typically, gradient clipping is one of the key algorithmic ingredients to derive good high-probability guarantees when the noise is heavy-tailed. However, if implemented na\"ively, clipping can spoil the convergence of the popular methods for composite and distributed optimization (Prox-SGD/Parallel SGD) even in the absence of any noise. Due to this reason, many works on high-probability analysis consider only unconstrained non-distributed problems, and the existing results for composite/distributed problems do not include some important special cases (like strongly convex problems) and are not optimal. To address this issue, we propose new stochastic methods for composite and distributed optimization based on the clipping of stochastic gradient differences and prove tight high-probability convergence results (including nearly
    
[^21]: 关于对抗鲁棒性和可操作解释之间的权衡

    On the Trade-offs between Adversarial Robustness and Actionable Explanations. (arXiv:2309.16452v1 [cs.LG])

    [http://arxiv.org/abs/2309.16452](http://arxiv.org/abs/2309.16452)

    本论文研究了对抗鲁棒模型对可操作解释的影响，并通过理论和实证分析比较了对抗性鲁棒和非鲁棒模型生成的追索结果的成本和有效性之间的差异。

    

    随着机器学习模型在各种高风险环境中的应用越来越广泛，确保这些模型的预测不仅具有对抗性鲁棒性，而且还能向相关利益相关者提供可解释性变得越来越重要。然而，目前尚不清楚是否可以同时实现这两个概念，或者它们之间是否存在权衡。在这项工作中，我们首次尝试研究对抗性鲁棒模型对可操作解释的影响，这些解释为最终用户提供了追索权利。我们在理论和实证层面上分析了先进算法生成的追索结果的成本（实施的容易程度）和有效性（获得正向模型预测的概率），并比较了对抗性鲁棒和非鲁棒模型生成的追索结果之间的差异。具体而言，我们推导出对抗性鲁棒和非鲁棒模型生成的追索结果的成本和有效性之间的理论界限。

    As machine learning models are increasingly being employed in various high-stakes settings, it becomes important to ensure that predictions of these models are not only adversarially robust, but also readily explainable to relevant stakeholders. However, it is unclear if these two notions can be simultaneously achieved or if there exist trade-offs between them. In this work, we make one of the first attempts at studying the impact of adversarially robust models on actionable explanations which provide end users with a means for recourse. We theoretically and empirically analyze the cost (ease of implementation) and validity (probability of obtaining a positive model prediction) of recourses output by state-of-the-art algorithms when the underlying models are adversarially robust vs. non-robust. More specifically, we derive theoretical bounds on the differences between the cost and the validity of the recourses generated by state-of-the-art algorithms for adversarially robust vs. non-ro
    
[^22]: 基于贝叶斯自适应时刻正则化的鲁棒性持续学习

    Towards Robust Continual Learning with Bayesian Adaptive Moment Regularization. (arXiv:2309.08546v1 [cs.LG])

    [http://arxiv.org/abs/2309.08546](http://arxiv.org/abs/2309.08546)

    基于贝叶斯自适应时刻正则化的鲁棒性持续学习方法能够在机器人应用中有效地解决灾难性遗忘问题，并具有轻量级和任务实验室等优势。

    

    为了追求长期自主性，机器人代理必须不断适应不断变化的环境并学习解决新任务。持续学习试图克服灾难性遗忘的挑战，即学习解决新任务导致模型忘记先前学到的信息。基于先验的持续学习方法对于机器人应用具有吸引力，因为它们在空间效率上很高，并且通常不会随着任务数量的增加而增加计算复杂性。尽管具有这些理想的特性，但基于先验的方法通常在重要的基准测试中失败，因此与基于记忆的方法相比，在潜在应用方面有限。我们引入了贝叶斯自适应时刻正则化（BAdam），一种新的基于先验的方法，它更好地约束参数增长，降低灾难性遗忘。我们的方法在机器人应用中具有一系列理想的特性，例如轻量级和任务实验室。

    The pursuit of long-term autonomy mandates that robotic agents must continuously adapt to their changing environments and learn to solve new tasks. Continual learning seeks to overcome the challenge of catastrophic forgetting, where learning to solve new tasks causes a model to forget previously learnt information. Prior-based continual learning methods are appealing for robotic applications as they are space efficient and typically do not increase in computational complexity as the number of tasks grows. Despite these desirable properties, prior-based approaches typically fail on important benchmarks and consequently are limited in their potential applications compared to their memory-based counterparts. We introduce Bayesian adaptive moment regularization (BAdam), a novel prior-based method that better constrains parameter growth, leading to lower catastrophic forgetting. Our method boasts a range of desirable properties for robotic applications such as being lightweight and task lab
    
[^23]: 结构感知的辛系统哈密顿（图）嵌入

    Symplectic Structure-Aware Hamiltonian (Graph) Embeddings. (arXiv:2309.04885v1 [cs.LG])

    [http://arxiv.org/abs/2309.04885](http://arxiv.org/abs/2309.04885)

    本文提出了SAH-GNN，一种在图神经网络中应用结构感知的辛系统哈密顿嵌入方法。与传统方法不同，SAH-GNN通过在训练过程中自适应学习辛结构，避免了依赖预定义标准辛结构形式的限制，并能够适应不同的图数据集，同时保持物理意义上的能量守恒。

    

    在传统的图神经网络（GNNs）中，固定嵌入流形的假设常常限制了其对不同图几何结构的适应性。最近，提出了基于哈密顿系统的GNNs，通过将物理定律纳入节点特征更新中，来解决这类嵌入的动态特性。在这项工作中，我们提出了SAH-GNN，一种新颖的方法，将哈密顿动力学推广到更灵活的节点特征更新中。与现有的受哈密顿启发的GNNs不同，SAH-GNN在训练过程中采用辛斯蒂费尔流形上的黎曼优化，自适应地学习潜在的辛结构，从而规避了现有依赖预定义标准辛结构形式的哈密顿GNNs的局限性。这一创新使得SAH-GNN能够在没有大量超参数调整的情况下自动适应各种图数据集。此外，它在训练过程中保持能量守恒，使得隐式哈密顿系统具有物理意义。

    In traditional Graph Neural Networks (GNNs), the assumption of a fixed embedding manifold often limits their adaptability to diverse graph geometries. Recently, Hamiltonian system-inspired GNNs are proposed to address the dynamic nature of such embeddings by incorporating physical laws into node feature updates. In this work, we present SAH-GNN, a novel approach that generalizes Hamiltonian dynamics for more flexible node feature updates. Unlike existing Hamiltonian-inspired GNNs, SAH-GNN employs Riemannian optimization on the symplectic Stiefel manifold to adaptively learn the underlying symplectic structure during training, circumventing the limitations of existing Hamiltonian GNNs that rely on a pre-defined form of standard symplectic structure. This innovation allows SAH-GNN to automatically adapt to various graph datasets without extensive hyperparameter tuning. Moreover, it conserves energy during training such that the implicit Hamiltonian system is physically meaningful. To thi
    
[^24]: 学习基于专利的生物医学知识图谱揭示药物再定位候选物的技术潜力

    Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates. (arXiv:2309.03227v1 [cs.AI])

    [http://arxiv.org/abs/2309.03227](http://arxiv.org/abs/2309.03227)

    本研究提出了一种使用药物专利和生物医学数据库相结合的方法，识别具有技术潜力和科学证据的药物再定位候选物。通过构建科学的生物医学知识图谱和基于专利的生物医学知识图谱，我们可以综合分析多种信息源，为药物再定位研究提供新的视角。

    

    药物再定位是一种发现现有药物新治疗用途的有前途的策略，近年来在计算科学文献中使用生物医学数据库进行了广泛探索。然而，药物再定位候选物的技术潜力经常被忽视。本研究提出了一种新的方法，综合分析药物专利和生物医学数据库等多种信息源，识别具有技术潜力和科学证据的药物再定位候选物。首先，我们构建了一个科学的生物医学知识图谱（s-BKG），包括来自生物医学数据库的药物、疾病和基因之间的关系。我们的方法涉及识别在s-BKG中与目标疾病关联有限但在空间上紧密相邻的药物作为潜在的药物候选物。然后，我们通过添加药物专利信息构建了一个基于专利的生物医学知识图谱（p-BKG）。

    Drug repositioning-a promising strategy for discovering new therapeutic uses for existing drugs-has been increasingly explored in the computational science literature using biomedical databases. However, the technological potential of drug repositioning candidates has often been overlooked. This study presents a novel protocol to comprehensively analyse various sources such as pharmaceutical patents and biomedical databases, and identify drug repositioning candidates with both technological potential and scientific evidence. To this end, first, we constructed a scientific biomedical knowledge graph (s-BKG) comprising relationships between drugs, diseases, and genes derived from biomedical databases. Our protocol involves identifying drugs that exhibit limited association with the target disease but are closely located in the s-BKG, as potential drug candidates. We constructed a patent-informed biomedical knowledge graph (p-BKG) by adding pharmaceutical patent information. Finally, we d
    
[^25]: 使用机器学习从语音信号中检测喉癌：可复现的文献综述

    Detecting Throat Cancer from Speech Signals Using Machine Learning: A Reproducible Literature Review. (arXiv:2307.09230v1 [cs.LG])

    [http://arxiv.org/abs/2307.09230](http://arxiv.org/abs/2307.09230)

    本研究对使用机器学习和人工智能从语音记录中检测喉癌的文献进行了综述，发现了22篇相关论文，讨论了它们的方法和结果。研究使用了神经网络和梅尔频率倒谱系数提取音频特征，并通过迁移学习实现了分类，取得了一定的准确率。

    

    本文对使用机器学习和人工智能从语音记录中检测喉癌的当前文献进行了范围评估。我们找到了22篇相关论文，并讨论了它们的方法和结果。我们将这些论文分为两组 - 九篇进行二分类，13篇进行多类别分类。这些论文提出了一系列方法，其中最常见的是使用神经网络。在分类之前还从音频中提取了许多特征，其中最常见的是梅尔频率倒谱系数。在这次搜索中未找到任何带有代码库的论文，因此无法复现。因此，我们创建了一个公开可用的代码库来训练自己的分类器。我们在一个多类别问题上使用迁移学习，将三种病理和健康对照进行分类。使用这种技术，我们取得了53.54%的加权平均召回率、83.14%的敏感性和特异性。

    In this work we perform a scoping review of the current literature on the detection of throat cancer from speech recordings using machine learning and artificial intelligence. We find 22 papers within this area and discuss their methods and results. We split these papers into two groups - nine performing binary classification, and 13 performing multi-class classification. The papers present a range of methods with neural networks being most commonly implemented. Many features are also extracted from the audio before classification, with the most common bring mel-frequency cepstral coefficients. None of the papers found in this search have associated code repositories and as such are not reproducible. Therefore, we create a publicly available code repository of our own classifiers. We use transfer learning on a multi-class problem, classifying three pathologies and healthy controls. Using this technique we achieve an unweighted average recall of 53.54%, sensitivity of 83.14%, and specif
    
[^26]: 优化器的信息准则：剖析和纠正数据驱动优化中的偏差

    Optimizer's Information Criterion: Dissecting and Correcting Bias in Data-Driven Optimization. (arXiv:2306.10081v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10081](http://arxiv.org/abs/2306.10081)

    这项研究提出了一个称为优化器的信息准则(OIC)的通用偏差校正方法，帮助解决数据驱动优化中的乐观偏差问题。该方法直接近似一阶偏差，并且不需要解决额外的优化问题，是在决策选择方面的一个创新。

    

    在数据驱动的优化中，所得决策的样本表现通常存在着对真实表现的乐观偏差，这种现象通常被称为优化器的诅咒，与机器学习中的过拟合密切相关。传统的纠正这种偏差的技术，如交叉验证，需要反复解决额外的优化问题，因此计算代价很高。我们开发了一种通用的偏差校正方法，建立在我们称之为优化器的信息准则（OIC）的基础上，直接近似一阶偏差，不需要解决任何额外的优化问题。我们的OIC将著名的赤池信息准则推广到数据驱动优化中，关键是评估客观表现，不仅涉及模型拟合，还涉及其与下游优化的相互作用。因此，它可以用于决策选择而不仅仅是模型选择。我们将我们的方法应用于一系列问题的数据驱动优化。

    In data-driven optimization, the sample performance of the obtained decision typically incurs an optimistic bias against the true performance, a phenomenon commonly known as the Optimizer's Curse and intimately related to overfitting in machine learning. Common techniques to correct this bias, such as cross-validation, require repeatedly solving additional optimization problems and are therefore computationally expensive. We develop a general bias correction approach, building on what we call Optimizer's Information Criterion (OIC), that directly approximates the first-order bias and does not require solving any additional optimization problems. Our OIC generalizes the celebrated Akaike Information Criterion to evaluate the objective performance in data-driven optimization, which crucially involves not only model fitting but also its interplay with the downstream optimization. As such it can be used for decision selection instead of only model selection. We apply our approach to a rang
    
[^27]: 自下而上何时击败自上而下进行分层社区检测？

    When Does Bottom-up Beat Top-down in Hierarchical Community Detection?. (arXiv:2306.00833v1 [cs.SI])

    [http://arxiv.org/abs/2306.00833](http://arxiv.org/abs/2306.00833)

    本文研究了使用自下而上算法恢复Hierarchical Stochastic Block Model的树形结构和社区结构的理论保证，并确定了其在中间层次上达到了确切恢复信息理论阈值。

    

    网络的分层聚类是指查找一组社区的树形结构，其中层次结构的较低级别显示更细粒度的社区结构。解决这一问题的算法有两个主要类别：自上而下的算法和自下而上的算法。本文研究了使用自下而上算法恢复分层随机块模型的树形结构和社区结构的理论保证。我们还确定了这种自下而上算法在层次结构的中间层次上达到了确切恢复信息理论阈值。值得注意的是，这些恢复条件相对于现有的自上而下算法的条件来说，限制更少。

    Hierarchical clustering of networks consists in finding a tree of communities, such that lower levels of the hierarchy reveal finer-grained community structures. There are two main classes of algorithms tackling this problem. Divisive ($\textit{top-down}$) algorithms recursively partition the nodes into two communities, until a stopping rule indicates that no further split is needed. In contrast, agglomerative ($\textit{bottom-up}$) algorithms first identify the smallest community structure and then repeatedly merge the communities using a $\textit{linkage}$ method. In this article, we establish theoretical guarantees for the recovery of the hierarchical tree and community structure of a Hierarchical Stochastic Block Model by a bottom-up algorithm. We also establish that this bottom-up algorithm attains the information-theoretic threshold for exact recovery at intermediate levels of the hierarchy. Notably, these recovery conditions are less restrictive compared to those existing for to
    
[^28]: 向量值变分空间和DNN的宽度界：关于权重衰减正则化的见解。

    Vector-Valued Variation Spaces and Width Bounds for DNNs: Insights on Weight Decay Regularization. (arXiv:2305.16534v1 [stat.ML])

    [http://arxiv.org/abs/2305.16534](http://arxiv.org/abs/2305.16534)

    该论文提供了关于通过加权衰减训练的多输出ReLU神经网络的函数类型和相应的解决方案的新见解。

    

    深度神经网络(DNNs)通过梯度下降最小化损失项和平方权重和相应，对应于训练加权衰减的常见方法。本文提供了有关这种常见学习框架的新见解。我们表征了训练加权衰减以获得多输出(向量值)ReLU神经网络学习的函数类型。这扩展了先前限于单输出(标量值)网络的表征。这种表征需要定义我们称之为向量值变分(VV)空间的新类神经函数空间。我们通过一种新的表征定理证明，神经网络(NNs)是通过VV空间中提出学习问题的最优解。这个新的表征定理表明，这些学习问题的解存在于宽度受训练数据数限制的向量值神经网络中。接下来，通过与多任务lasso问题的新联系，我们导出了

    Deep neural networks (DNNs) trained to minimize a loss term plus the sum of squared weights via gradient descent corresponds to the common approach of training with weight decay. This paper provides new insights into this common learning framework. We characterize the kinds of functions learned by training with weight decay for multi-output (vector-valued) ReLU neural networks. This extends previous characterizations that were limited to single-output (scalar-valued) networks. This characterization requires the definition of a new class of neural function spaces that we call vector-valued variation (VV) spaces. We prove that neural networks (NNs) are optimal solutions to learning problems posed over VV spaces via a novel representer theorem. This new representer theorem shows that solutions to these learning problems exist as vector-valued neural networks with widths bounded in terms of the number of training data. Next, via a novel connection to the multi-task lasso problem, we derive
    
[^29]: 基于摘要描述的文本检索

    Retrieving Texts based on Abstract Descriptions. (arXiv:2305.12517v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12517](http://arxiv.org/abs/2305.12517)

    本研究针对语义检索问题，提出了一种基于摘要描述的文本检索模型，通过改进当前的文本嵌入方法，在标准最近邻搜索中取得了显著性能提升。

    

    虽然针对文本的信息提取，指令优化的大型语言模型表现优异，但对于在大规模文档集合中定位符合给定描述的文本（语义检索）并不适用。基于嵌入向量的相似度搜索可以通过查询执行检索，但嵌入中的相似度定义不明确且不一致，并且对于许多用例来说都是次优的。那么，什么是有效检索的好的查询表示？我们确定了根据内容的摘要描述检索句子的明确定义且一致的任务。我们展示了当前文本嵌入的不足，并提出了一种替代模型，在标准最近邻搜索中的表现显著提升。该模型使用通过提示LLM获得的正负样本对进行训练。虽然很容易从LLM中获得训练材料，但LLM无法直接执行检索任务。

    While instruction-tuned Large Language Models (LLMs) excel at extracting information from text, they are not suitable for locating texts conforming to a given description in a large document collection (semantic retrieval). Similarity search over embedding vectors does allow to perform retrieval by query, but the similarity reflected in the embedding is ill-defined and non-consistent, and is sub-optimal for many use cases. What, then, is a good query representation for effective retrieval?  We identify the well defined and consistent task of retrieving sentences based on abstract descriptions of their content. We demonstrate the inadequacy of current text embeddings and propose an alternative model that significantly improves when used in standard nearest neighbor search. The model is trained using positive and negative pairs sourced through prompting a LLM. While it is easy to source the training material from an LLM, the retrieval task cannot be performed by the LLM directly. This de
    
[^30]: 拓扑数据分析中的欧拉特征工具

    Euler Characteristic Tools For Topological Data Analysis. (arXiv:2303.14040v1 [cs.LG])

    [http://arxiv.org/abs/2303.14040](http://arxiv.org/abs/2303.14040)

    本文研究了欧拉特征技术在拓扑数据分析中的应用，利用点运算欧拉特征得到欧拉特征轮廓，在监督和无监督任务中实现了最先进性能，并提供了欧拉轮廓及其混合变换捕捉信息的启发式方法。

    

    本文研究了拓扑数据分析中的欧拉特征技术。从数据构建的一族单纯复合体的点运算欧拉特征，得到所谓的欧拉特征轮廓。我们展示了这个简单描述符以极低的计算成本在监督任务中实现了最先进性能。受信号分析的启发，我们计算欧拉特征轮廓的混合变换。这些积分变换将欧拉特征技术与勒贝格积分混合，提供高效压缩拓扑信号。因此，它们在无监督设置中表现出卓越的性能。在定性方面，我们提供了关于欧拉轮廓及其混合变换所捕捉的拓扑和几何信息的众多启发式方法。最后，我们证明了这些描述符的稳定性结果以及在随机设置下的渐近保证。

    In this article, we study Euler characteristic techniques in topological data analysis. Pointwise computing the Euler characteristic of a family of simplicial complexes built from data gives rise to the so-called Euler characteristic profile. We show that this simple descriptor achieve state-of-the-art performance in supervised tasks at a very low computational cost. Inspired by signal analysis, we compute hybrid transforms of Euler characteristic profiles. These integral transforms mix Euler characteristic techniques with Lebesgue integration to provide highly efficient compressors of topological signals. As a consequence, they show remarkable performances in unsupervised settings. On the qualitative side, we provide numerous heuristics on the topological and geometric information captured by Euler profiles and their hybrid transforms. Finally, we prove stability results for these descriptors as well as asymptotic guarantees in random settings.
    
[^31]: 标签效率的时间序列表示学习：一项综述

    Label-efficient Time Series Representation Learning: A Review. (arXiv:2302.06433v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06433](http://arxiv.org/abs/2302.06433)

    这篇综述介绍了针对时间序列数据中标记数据稀缺性问题的现有方法，并提供了一个新颖的分类系统来归纳这些方法。该综述总结了每种方法的最新进展并提出了未来的研究方向。

    

    标记数据的稀缺性是在现实世界中应用深度学习模型于时间序列数据时的主要挑战之一。因此，最近已经开发了几种方法，例如迁移学习，自监督学习和半监督学习，以促进深度学习模型从有限的时间序列标签中获取学习能力。在本综述中，我们首次提供了一个新颖的分类系统，用来根据它们对外部数据源的依赖，对解决时间序列数据中标记数据稀缺性问题的现有方法进行分类。此外，我们对每种方法的最新进展进行了审查，并总结了当前工作的局限性，并提供了可能在这一领域取得更好进展的未来方向。

    The scarcity of labeled data is one of the main challenges of applying deep learning models on time series data in the real world. Therefore, several approaches, e.g., transfer learning, self-supervised learning, and semi-supervised learning, have been recently developed to promote the learning capability of deep learning models from the limited time series labels. In this survey, for the first time, we provide a novel taxonomy to categorize existing approaches that address the scarcity of labeled data problem in time series data based on their dependency on external data sources. Moreover, we present a review of the recent advances in each approach and conclude the limitations of the current works and provide future directions that could yield better progress in the field.
    
[^32]: 物理学知识作为不确定性量化模型的信息场理论

    Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification. (arXiv:2301.07609v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.07609](http://arxiv.org/abs/2301.07609)

    该论文扩展了信息场理论(IFT)到物理信息场理论(PIFT)，将描述场的物理定律的信息编码为函数先验。从这个PIFT得出的后验与任何数值方案无关，并且可以捕捉多种模式。

    

    数据驱动的方法结合物理学知识是建模系统的强有力技术。此类模型的目标是通过将测量结果与已知物理定律相结合，高效地求解基本场。由于许多系统包含未知元素，如缺失参数、嘈杂数据或不完整的物理定律，因此这通常被视为一种不确定性量化问题。处理所有变量的常见技术通常取决于用于近似后验的数值方案，并且希望有一种不依赖于任何离散化的方法。信息场理论（IFT）提供了对不一定是高斯场的场进行统计学的工具。我们通过将描述场的物理定律的信息编码为函数先验来扩展IFT到物理信息场理论（PIFT）。从这个PIFT得出的后验与任何数值方案无关，并且可以捕捉多种模式。

    Data-driven approaches coupled with physical knowledge are powerful techniques to model systems. The goal of such models is to efficiently solve for the underlying field by combining measurements with known physical laws. As many systems contain unknown elements, such as missing parameters, noisy data, or incomplete physical laws, this is widely approached as an uncertainty quantification problem. The common techniques to handle all the variables typically depend on the numerical scheme used to approximate the posterior, and it is desirable to have a method which is independent of any such discretization. Information field theory (IFT) provides the tools necessary to perform statistics over fields that are not necessarily Gaussian. We extend IFT to physics-informed IFT (PIFT) by encoding the functional priors with information about the physical laws which describe the field. The posteriors derived from this PIFT remain independent of any numerical scheme and can capture multiple modes,
    
[^33]: $\Phi$-DVAE: 物理指导的动态变分自编码器用于非结构化数据同化

    $\Phi$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation. (arXiv:2209.15609v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.15609](http://arxiv.org/abs/2209.15609)

    本文提出了一种物理指导的动态变分自编码器 ($\Phi$-DVAE) 用于将非结构化数据同化到物理模型中，解决了传统方法在未知映射情况下无法实现一致模型与数据综合的问题。

    

    在数据同化中，将非结构化数据纳入物理模型是一个具有挑战性的问题。传统方法通常关注具有明确定义观测算子的情况，其函数形式通常被假定为已知。这阻止了这些方法在从数据空间到模型空间的映射未知的配置中实现一致的模型与数据综合。为了解决这些问题，在本文中我们开发了一种物理指导的动态变分自编码器($\Phi$-DVAE)，将多样化的数据流嵌入到由微分方程描述的时变物理系统中。我们的方法结合了一个标准的、可能是非线性的潜在状态空间模型滤波器和一个变分自编码器，将非结构化数据同化到潜在的动态系统中。在我们的示例系统中，非结构化数据采用视频数据和速度场测量的形式，但该方法的适用性足够通用，可以允许任意未知的观测算子。

    Incorporating unstructured data into physical models is a challenging problem that is emerging in data assimilation. Traditional approaches focus on well-defined observation operators whose functional forms are typically assumed to be known. This prevents these methods from achieving a consistent model-data synthesis in configurations where the mapping from data-space to model-space is unknown. To address these shortcomings, in this paper we develop a physics-informed dynamical variational autoencoder ($\Phi$-DVAE) to embed diverse data streams into time-evolving physical systems described by differential equations. Our approach combines a standard, possibly nonlinear, filter for the latent state-space model and a VAE, to assimilate the unstructured data into the latent dynamical system. Unstructured data, in our example systems, comes in the form of video data and velocity field measurements, however the methodology is suitably generic to allow for arbitrary unknown observation operat
    
[^34]: 目标自适应设计

    Targeted Adaptive Design. (arXiv:2205.14208v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14208](http://arxiv.org/abs/2205.14208)

    TAD是一种新的目标自适应设计算法，可以通过高斯过程代理模型在指定公差中确定产生期望设计特征的最佳控制设置，相比其他自适应设计算法，具有更高的精度和效率。

    

    现代先进制造和高级材料设计往往需要在较高维度的过程控制参数空间中搜索最佳结构、性能和性能参数的设置。从前者到后者的映射必须通过嘈杂的实验或昂贵的模拟来确定。我们把这个问题抽象成一个数学框架，其中必须通过昂贵的嘈杂测量来确定从控制空间到设计空间的未知函数，该函数在指定的公差范围内定位产生期望设计特征的最佳控制设置，并量化不确定性。我们描述了目标自适应设计 (TAD)，这是一种有效执行这个采样任务的新算法。TAD 在每个迭代阶段创建一个未知映射的高斯过程代理模型，建议一批新的控制设置进行实验采样，并优化更新的目标设计特征的对数预测似然。

    Modern advanced manufacturing and advanced materials design often require searches of relatively high-dimensional process control parameter spaces for settings that result in optimal structure, property, and performance parameters. The mapping from the former to the latter must be determined from noisy experiments or from expensive simulations. We abstract this problem to a mathematical framework in which an unknown function from a control space to a design space must be ascertained by means of expensive noisy measurements, which locate optimal control settings generating desired design features within specified tolerances, with quantified uncertainty. We describe targeted adaptive design (TAD), a new algorithm that performs this sampling task efficiently. TAD creates a Gaussian process surrogate model of the unknown mapping at each iterative stage, proposing a new batch of control settings to sample experimentally and optimizing the updated log-predictive likelihood of the target desi
    
[^35]: EXACT: 如何提高准确率的训练方法。

    EXACT: How to Train Your Accuracy. (arXiv:2205.09615v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09615](http://arxiv.org/abs/2205.09615)

    本文提出了一种新的分类任务优化框架，通过引入随机性，优化期望准确率，取得了强有力的替代分类损失的结果。

    

    分类任务通常会以准确率作为评估标准。然而，准确率是不连续的，无法直接使用梯度上升进行优化。流行的方法是通过最小化交叉熵、铰链损失或其他替代损失来优化，但这可能导致次优结果。本文提出了一种新的优化框架，通过向模型的输出引入随机性并优化期望准确率，即随机模型的准确率。对线性模型和深度图像分类进行了广泛的实验，结果表明所提出的优化方法是广泛使用的分类损失的强有力替代方案。

    Classification tasks are usually evaluated in terms of accuracy. However, accuracy is discontinuous and cannot be directly optimized using gradient ascent. Popular methods minimize cross-entropy, hinge loss, or other surrogate losses, which can lead to suboptimal results. In this paper, we propose a new optimization framework by introducing stochasticity to a model's output and optimizing expected accuracy, i.e. accuracy of the stochastic model. Extensive experiments on linear models and deep image classification show that the proposed optimization method is a powerful alternative to widely used classification losses.
    
[^36]: 保护隐私的张量网络机器学习

    Privacy-preserving machine learning with tensor networks. (arXiv:2202.12319v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2202.12319](http://arxiv.org/abs/2202.12319)

    本文展示了张量网络架构在保护隐私的机器学习中具有潜在优势，并提出了确保鲁棒性的明确条件。

    

    张量网络被广泛用于提供低能量态的高效表示，最近被提出作为机器学习架构的一种新方法。本文展示了张量网络架构在保护隐私的机器学习中具有潜在优势，这对于处理医疗记录等任务非常重要。首先，我们描述了前馈神经网络中存在的新隐私漏洞，并在合成和真实数据集中进行了说明。然后，我们提出了确保对这种漏洞具有鲁棒性的明确条件，这涉及到在规范对称性下等价的模型的刻画。我们严格证明了张量网络架构满足这些条件。在此过程中，我们定义了一种新型的矩阵乘积态的规范形式，具有高度的规律性并修正了残余规范问题。

    Tensor networks, widely used for providing efficient representations of low-energy states of local quantum many-body systems, have been recently proposed as machine learning architectures which could present advantages with respect to traditional ones. In this work we show that tensor network architectures have especially prospective properties for privacy-preserving machine learning, which is important in tasks such as the processing of medical records. First, we describe a new privacy vulnerability that is present in feedforward neural networks, illustrating it in synthetic and real-world datasets. Then, we develop well-defined conditions to guarantee robustness to such vulnerability, which involve the characterization of models equivalent under gauge symmetry. We rigorously prove that such conditions are satisfied by tensor-network architectures. In doing so, we define a novel canonical form for matrix product states, which has a high degree of regularity and fixes the residual gaug
    

