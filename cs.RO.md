# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior](https://arxiv.org/abs/2403.08828) | 人们会给自主车辆的行为赋予目的属性，并在生成解释和评估这些解释时表现出对目的论解释的倾向。 |

# 详细

[^1]: 当解释自主车辆的行为时，人们会给予其属性目的

    People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior

    [https://arxiv.org/abs/2403.08828](https://arxiv.org/abs/2403.08828)

    人们会给自主车辆的行为赋予目的属性，并在生成解释和评估这些解释时表现出对目的论解释的倾向。

    

    一款优秀的可解释人工智能系统的标志是用户可以理解并采取行动的解释。许多情况下，这需要系统提供可理解的因果或反事实解释。认知科学可以帮助我们理解用户可能期望的解释类型，以及在哪种格式下呈现这些解释。本文简要回顾了认知科学解释方面的相关文献，特别关注目的论，即以达到目的为解释决策的倾向。然后，我们报告了人们如何为自主车辆的行为产生解释以及他们如何评估这些解释的经验数据。在第一项调查中，参与者（n = 54）观看了道路场景的视频，并被要求为车辆的行为生成机械的、反事实的或目的论的言语解释。在第二项调查中，另一组参与者（n = 356）对这些进行评分。

    arXiv:2403.08828v1 Announce Type: cross  Abstract: A hallmark of a good XAI system is explanations that users can understand and act on. In many cases, this requires a system to offer causal or counterfactual explanations that are intelligible. Cognitive science can help us understand what kinds of explanations users might expect, and in which format to frame these explanations. We briefly review relevant literature from the cognitive science of explanation, particularly as it concerns teleology, the tendency to explain a decision in terms of the purpose it was meant to achieve. We then report empirical data on how people generate explanations for the behavior of autonomous vehicles, and how they evaluate these explanations. In a first survey, participants (n=54) were shown videos of a road scene and asked to generate either mechanistic, counterfactual, or teleological verbal explanations for a vehicle's actions. In the second survey, a different set of participants (n=356) rated these
    

