# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots](https://arxiv.org/abs/2311.15327) | FRAC-Q-Learning是一种专为社交机器人设计，能避免用户厌烦的强化学习方法，比传统算法在兴趣和厌烦程度上表现更好，有助于开发不会让用户感到无聊的社交机器人。 |

# 详细

[^1]: FRAC-Q-Learning: 一种具有避免厌烦过程的社交机器人强化学习方法

    FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots

    [https://arxiv.org/abs/2311.15327](https://arxiv.org/abs/2311.15327)

    FRAC-Q-Learning是一种专为社交机器人设计，能避免用户厌烦的强化学习方法，比传统算法在兴趣和厌烦程度上表现更好，有助于开发不会让用户感到无聊的社交机器人。

    

    强化学习算法经常被应用于社交机器人。然而，大多数强化学习算法并未针对社交机器人进行优化，因此可能会让用户感到无聊。我们提出了一种专为社交机器人设计的新强化学习方法，FRAC-Q-Learning，可以避免用户感到无聊。该算法除了随机化和分类过程外，还包括一个遗忘过程。本研究通过与传统Q-Learning的比较评估了FRAC-Q-Learning的兴趣和厌烦程度分数。FRAC-Q-Learning显示出明显更高的兴趣分数趋势，并且相较于传统Q-Learning更难让用户感到无聊。因此，FRAC-Q-Learning有助于开发不会让用户感到无聊的社交机器人。该算法还可以在基于Web的通信和教育中找到应用。

    arXiv:2311.15327v3 Announce Type: replace-cross  Abstract: The reinforcement learning algorithms have often been applied to social robots. However, most reinforcement learning algorithms were not optimized for the use of social robots, and consequently they may bore users. We proposed a new reinforcement learning method specialized for the social robot, the FRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists of a forgetting process in addition to randomizing and categorizing processes. This study evaluated interest and boredom hardness scores of the FRAC-Q-learning by a comparison with the traditional Q-learning. The FRAC-Q-learning showed significantly higher trend of interest score, and indicated significantly harder to bore users compared to the traditional Q-learning. Therefore, the FRAC-Q-learning can contribute to develop a social robot that will not bore users. The proposed algorithm can also find applications in Web-based communication and educational 
    

