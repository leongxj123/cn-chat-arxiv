# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?](https://arxiv.org/abs/2402.09546) | 本文首次研究了基于大型语言模型的导航系统在城市环境中的安全漏洞，并提出了一种新颖的NPS Attack方法，该方法通过添加后缀来操纵导航模型，导致不正确的行为。该研究对自动驾驶、物流和紧急服务等领域具有重要意义。 |

# 详细

[^1]: 大型语言模型（LLMs）在城市环境中导航时有多安全？

    How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?

    [https://arxiv.org/abs/2402.09546](https://arxiv.org/abs/2402.09546)

    本文首次研究了基于大型语言模型的导航系统在城市环境中的安全漏洞，并提出了一种新颖的NPS Attack方法，该方法通过添加后缀来操纵导航模型，导致不正确的行为。该研究对自动驾驶、物流和紧急服务等领域具有重要意义。

    

    在机器人和自动化领域，基于大型语言模型（LLMs）的导航系统最近展示了令人印象深刻的性能。然而，这些系统的安全性方面受到的关注相对较少。本文在城市户外环境中首次探索了LLM-based导航模型的漏洞，这是一个关键领域，因为该技术广泛应用于自动驾驶、物流和紧急服务。具体地，我们引入了一种新颖的Navigational Prompt Suffix (NPS) Attack，通过将梯度导出的后缀添加到原始导航提示，操纵LLM-based导航模型，从而导致不正确的行为。我们对基于LLMs的导航模型进行了全面的实验，该模型采用各种LLMs进行推理。我们的结果来自Touchdown和Map2Seq街景数据集，在few-shot学习和fine-tuning配置下进行实验，结果证明了NPS Attack的有效性。

    arXiv:2402.09546v1 Announce Type: cross  Abstract: In the field of robotics and automation, navigation systems based on Large Language Models (LLMs) have recently shown impressive performance. However, the security aspects of these systems have received relatively less attention. This paper pioneers the exploration of vulnerabilities in LLM-based navigation models in urban outdoor environments, a critical area given the technology's widespread application in autonomous driving, logistics, and emergency services. Specifically, we introduce a novel Navigational Prompt Suffix (NPS) Attack that manipulates LLM-based navigation models by appending gradient-derived suffixes to the original navigational prompt, leading to incorrect actions. We conducted comprehensive experiments on an LLMs-based navigation model that employs various LLMs for reasoning. Our results, derived from the Touchdown and Map2Seq street-view datasets under both few-shot learning and fine-tuning configurations, demonstr
    

