<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#36890;&#36807;&#36164;&#28304;&#24863;&#30693;&#30340;&#20998;&#23618;&#32852;&#37030;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#39044;&#27979;&#29992;&#25143;&#26410;&#26469;&#30340;&#20869;&#23481;&#35831;&#27714;&#65292;&#24182;&#20943;&#36731;&#26080;&#32447;&#35270;&#39057;&#32531;&#23384;&#32593;&#32476;&#20013;&#22238;&#31243;&#27969;&#37327;&#25317;&#22622;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04216</link><description>&lt;p&gt;
&#26080;&#32447;&#35270;&#39057;&#32531;&#23384;&#32593;&#32476;&#20013;&#30340;&#36164;&#28304;&#24863;&#30693;&#20998;&#23618;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Resource-Aware Hierarchical Federated Learning in Wireless Video Caching Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04216
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36164;&#28304;&#24863;&#30693;&#30340;&#20998;&#23618;&#32852;&#37030;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#39044;&#27979;&#29992;&#25143;&#26410;&#26469;&#30340;&#20869;&#23481;&#35831;&#27714;&#65292;&#24182;&#20943;&#36731;&#26080;&#32447;&#35270;&#39057;&#32531;&#23384;&#32593;&#32476;&#20013;&#22238;&#31243;&#27969;&#37327;&#25317;&#22622;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#32447;&#35270;&#39057;&#32531;&#23384;&#32593;&#32476;&#20013;&#65292;&#36890;&#36807;&#23558;&#24453;&#35831;&#27714;&#20869;&#23481;&#23384;&#20648;&#22312;&#19981;&#21516;&#32423;&#21035;&#19978;&#65292;&#21487;&#20197;&#20943;&#36731;&#30001;&#23569;&#25968;&#28909;&#38376;&#25991;&#20214;&#30340;&#35270;&#39057;&#27969;&#37327;&#36896;&#25104;&#30340;&#22238;&#31243;&#25317;&#22622;&#12290;&#36890;&#24120;&#65292;&#20869;&#23481;&#26381;&#21153;&#25552;&#20379;&#21830;&#65288;CSP&#65289;&#25317;&#26377;&#20869;&#23481;&#65292;&#29992;&#25143;&#20351;&#29992;&#20854;&#65288;&#26080;&#32447;&#65289;&#20114;&#32852;&#32593;&#26381;&#21153;&#25552;&#20379;&#21830;&#65288;ISP&#65289;&#20174;CSP&#35831;&#27714;&#20854;&#39318;&#36873;&#20869;&#23481;&#12290;&#30001;&#20110;&#36825;&#20123;&#21442;&#19982;&#26041;&#19981;&#20250;&#36879;&#38706;&#20854;&#31169;&#23494;&#20449;&#24687;&#21644;&#21830;&#19994;&#26426;&#23494;&#65292;&#20256;&#32479;&#25216;&#26415;&#21487;&#33021;&#26080;&#27861;&#29992;&#20110;&#39044;&#27979;&#29992;&#25143;&#26410;&#26469;&#38656;&#27714;&#30340;&#21160;&#24577;&#21464;&#21270;&#12290;&#20986;&#20110;&#36825;&#20010;&#21407;&#22240;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36164;&#28304;&#24863;&#30693;&#20998;&#23618;&#32852;&#37030;&#23398;&#20064;&#65288;RawHFL&#65289;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#39044;&#27979;&#29992;&#25143;&#26410;&#26469;&#30340;&#20869;&#23481;&#35831;&#27714;&#12290;&#37319;&#29992;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#25968;&#25454;&#33719;&#21462;&#25216;&#26415;&#65292;&#20801;&#35768;&#29992;&#25143;&#26681;&#25454;&#20854;&#35831;&#27714;&#30340;&#20869;&#23481;&#26356;&#26032;&#20854;&#26412;&#22320;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#32593;&#32476;&#21644;&#20854;&#20182;&#35745;&#31639;&#36164;&#28304;&#26377;&#38480;&#65292;&#32771;&#34385;&#21040;&#21482;&#26377;&#19968;&#37096;&#20998;&#29992;&#25143;&#21442;&#19982;&#27169;&#22411;&#35757;&#32451;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;
&lt;/p&gt;
&lt;p&gt;
Backhaul traffic congestion caused by the video traffic of a few popular files can be alleviated by storing the to-be-requested content at various levels in wireless video caching networks. Typically, content service providers (CSPs) own the content, and the users request their preferred content from the CSPs using their (wireless) internet service providers (ISPs). As these parties do not reveal their private information and business secrets, traditional techniques may not be readily used to predict the dynamic changes in users' future demands. Motivated by this, we propose a novel resource-aware hierarchical federated learning (RawHFL) solution for predicting user's future content requests. A practical data acquisition technique is used that allows the user to update its local training dataset based on its requested content. Besides, since networking and other computational resources are limited, considering that only a subset of the users participate in the model training, we derive
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#37096;&#20998;&#21487;&#35266;&#23519;&#21644;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26368;&#20248;&#25511;&#21046;&#29702;&#35770;&#65292;&#33021;&#22815;&#20351;&#29992;&#26102;&#38388;&#36923;&#36753;&#35268;&#33539;&#34920;&#36798;&#32422;&#26463;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#30340;&#26041;&#27861;&#26469;&#21512;&#25104;&#31574;&#30053;&#20197;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#24182;&#20445;&#35777;&#32422;&#26463;&#26465;&#20214;&#30340;&#27010;&#29575;&#36275;&#22815;&#39640;&#12290;&#21516;&#26102;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23545;&#20449;&#24687;&#19981;&#23545;&#31216;&#30340;&#22810;&#26234;&#33021;&#20307;&#35774;&#32622;&#36827;&#34892;&#26368;&#20248;&#25511;&#21046;&#30340;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2305.14736</link><description>&lt;p&gt;
&#36923;&#36753;&#32422;&#26463;&#19979;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#21644;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26368;&#20248;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Optimal Control of Logically Constrained Partially Observable and Multi-Agent Markov Decision Processes. (arXiv:2305.14736v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#37096;&#20998;&#21487;&#35266;&#23519;&#21644;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26368;&#20248;&#25511;&#21046;&#29702;&#35770;&#65292;&#33021;&#22815;&#20351;&#29992;&#26102;&#38388;&#36923;&#36753;&#35268;&#33539;&#34920;&#36798;&#32422;&#26463;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#30340;&#26041;&#27861;&#26469;&#21512;&#25104;&#31574;&#30053;&#20197;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#24182;&#20445;&#35777;&#32422;&#26463;&#26465;&#20214;&#30340;&#27010;&#29575;&#36275;&#22815;&#39640;&#12290;&#21516;&#26102;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23545;&#20449;&#24687;&#19981;&#23545;&#31216;&#30340;&#22810;&#26234;&#33021;&#20307;&#35774;&#32622;&#36827;&#34892;&#26368;&#20248;&#25511;&#21046;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#31995;&#32479;&#36890;&#24120;&#20250;&#20135;&#29983;&#36923;&#36753;&#32422;&#26463;&#65292;&#20363;&#22914;&#26469;&#33258;&#23433;&#20840;&#12289;&#25805;&#20316;&#25110;&#27861;&#35268;&#35201;&#27714;&#65292;&#21487;&#20197;&#29992;&#26102;&#38388;&#36923;&#36753;&#35268;&#33539;&#34920;&#36798;&#36825;&#20123;&#32422;&#26463;&#12290;&#31995;&#32479;&#29366;&#24577;&#36890;&#24120;&#26159;&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#65292;&#21487;&#33021;&#21253;&#21547;&#20855;&#26377;&#20849;&#21516;&#30446;&#26631;&#20294;&#19981;&#21516;&#20449;&#24687;&#32467;&#26500;&#21644;&#32422;&#26463;&#30340;&#22810;&#20010;&#26234;&#33021;&#20307;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#20010;&#26368;&#20248;&#25511;&#21046;&#29702;&#35770;&#65292;&#29992;&#20110;&#20855;&#26377;&#26377;&#38480;&#32447;&#24615;&#26102;&#38388;&#36923;&#36753;&#32422;&#26463;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#21512;&#25104;&#31574;&#30053;&#65292;&#21516;&#26102;&#30830;&#20445;&#28385;&#36275;&#26102;&#38388;&#36923;&#36753;&#32422;&#26463;&#30340;&#27010;&#29575;&#36275;&#22815;&#39640;&#26102;&#26368;&#22823;&#21270;&#32047;&#31215;&#22238;&#25253;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20851;&#20110;&#36817;&#20284;&#22870;&#21169;&#26368;&#20248;&#24615;&#21644;&#32422;&#26463;&#28385;&#36275;&#30340;&#20445;&#35777;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#27492;&#22522;&#30784;&#19978;&#26500;&#24314;&#20102;&#19968;&#20010;&#23545;&#20449;&#24687;&#19981;&#23545;&#31216;&#30340;&#20855;&#26377;&#36923;&#36753;&#32422;&#26463;&#30340;&#22810;&#26234;&#33021;&#20307;&#35774;&#32622;&#36827;&#34892;&#26368;&#20248;&#25511;&#21046;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#38416;&#36848;&#20102;&#35813;&#26041;&#27861;&#24182;&#32473;&#20986;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autonomous systems often have logical constraints arising, for example, from safety, operational, or regulatory requirements. Such constraints can be expressed using temporal logic specifications. The system state is often partially observable. Moreover, it could encompass a team of multiple agents with a common objective but disparate information structures and constraints. In this paper, we first introduce an optimal control theory for partially observable Markov decision processes (POMDPs) with finite linear temporal logic constraints. We provide a structured methodology for synthesizing policies that maximize a cumulative reward while ensuring that the probability of satisfying a temporal logic constraint is sufficiently high. Our approach comes with guarantees on approximate reward optimality and constraint satisfaction. We then build on this approach to design an optimal control framework for logically constrained multi-agent settings with information asymmetry. We illustrate the
&lt;/p&gt;</description></item></channel></rss>