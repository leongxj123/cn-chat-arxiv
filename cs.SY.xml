<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#31232;&#30095;&#22238;&#24402;&#20648;&#23618;&#35745;&#31639;&#26426;&#26469;&#35782;&#21035;&#21160;&#24577;&#37329;&#34701;&#36807;&#31243;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#26500;&#21270;&#30697;&#38453;&#36924;&#36817;&#21644;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#26041;&#27861;&#30830;&#23450;&#36755;&#20986;&#32806;&#21512;&#30697;&#38453;&#30340;&#36817;&#20284;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#34920;&#31034;&#24314;&#31435;&#23545;&#24212;&#20110;&#32473;&#23450;&#37329;&#34701;&#31995;&#32479;&#20013;&#36882;&#24402;&#32467;&#26500;&#30340;&#22238;&#24402;&#27169;&#22411;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#21160;&#24577;&#37329;&#34701;&#21644;&#32463;&#27982;&#36807;&#31243;&#30340;&#36817;&#20284;&#35782;&#21035;&#21644;&#39044;&#27979;&#27169;&#25311;&#65292;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12144</link><description>&lt;p&gt;
&#20351;&#29992;&#31232;&#30095;&#22238;&#24402;&#20648;&#23618;&#35745;&#31639;&#26426;&#35782;&#21035;&#21160;&#24577;&#37329;&#34701;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Dynamic financial processes identification using sparse regressive reservoir computers. (arXiv:2310.12144v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#31232;&#30095;&#22238;&#24402;&#20648;&#23618;&#35745;&#31639;&#26426;&#26469;&#35782;&#21035;&#21160;&#24577;&#37329;&#34701;&#36807;&#31243;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#26500;&#21270;&#30697;&#38453;&#36924;&#36817;&#21644;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#26041;&#27861;&#30830;&#23450;&#36755;&#20986;&#32806;&#21512;&#30697;&#38453;&#30340;&#36817;&#20284;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#34920;&#31034;&#24314;&#31435;&#23545;&#24212;&#20110;&#32473;&#23450;&#37329;&#34701;&#31995;&#32479;&#20013;&#36882;&#24402;&#32467;&#26500;&#30340;&#22238;&#24402;&#27169;&#22411;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#21160;&#24577;&#37329;&#34701;&#21644;&#32463;&#27982;&#36807;&#31243;&#30340;&#36817;&#20284;&#35782;&#21035;&#21644;&#39044;&#27979;&#27169;&#25311;&#65292;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#32467;&#26500;&#21270;&#30697;&#38453;&#36924;&#36817;&#29702;&#35770;&#30340;&#20851;&#38190;&#21457;&#29616;&#65292;&#20197;&#21450;&#20854;&#22312;&#21160;&#24577;&#37329;&#34701;&#36807;&#31243;&#30340;&#22238;&#24402;&#34920;&#31034;&#20013;&#30340;&#24212;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#28041;&#21450;&#20174;&#37329;&#34701;&#25110;&#32463;&#27982;&#31995;&#32479;&#20013;&#25552;&#21462;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#36890;&#29992;&#38750;&#32447;&#24615;&#26102;&#24310;&#23884;&#20837;&#30340;&#20840;&#38754;&#26041;&#27861;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#21644;&#32467;&#26500;&#21270;&#30697;&#38453;&#36924;&#36817;&#26041;&#27861;&#65292;&#26469;&#35782;&#21035;&#36755;&#20986;&#32806;&#21512;&#30697;&#38453;&#30340;&#36817;&#20284;&#34920;&#31034;&#12290;&#36825;&#20123;&#34920;&#31034;&#22312;&#24314;&#31435;&#23545;&#24212;&#20110;&#32473;&#23450;&#37329;&#34701;&#31995;&#32479;&#20013;&#36882;&#24402;&#32467;&#26500;&#30340;&#22238;&#24402;&#27169;&#22411;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26412;&#25991;&#36824;&#20171;&#32461;&#20102;&#21033;&#29992;&#19978;&#36848;&#25216;&#26415;&#30340;&#21407;&#22411;&#31639;&#27861;&#12290;&#36890;&#36807;&#22312;&#21160;&#24577;&#37329;&#34701;&#21644;&#32463;&#27982;&#36807;&#31243;&#30340;&#36817;&#20284;&#35782;&#21035;&#21644;&#39044;&#27979;&#27169;&#25311;&#20013;&#30340;&#24212;&#29992;&#65292;&#23637;&#31034;&#20102;&#36825;&#20123;&#31639;&#27861;&#65292;&#21253;&#25324;&#21487;&#33021;&#34920;&#29616;&#20986;&#28151;&#27788;&#34892;&#20026;&#30340;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this document, we present key findings in structured matrix approximation theory, with applications to the regressive representation of dynamic financial processes. Initially, we explore a comprehensive approach involving generic nonlinear time delay embedding for time series data extracted from a financial or economic system under examination. Subsequently, we employ sparse least-squares and structured matrix approximation methods to discern approximate representations of the output coupling matrices. These representations play a pivotal role in establishing the regressive models corresponding to the recursive structures inherent in a given financial system. The document further introduces prototypical algorithms that leverage the aforementioned techniques. These algorithms are demonstrated through applications in approximate identification and predictive simulation of dynamic financial and economic processes, encompassing scenarios that may or may not exhibit chaotic behavior.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#34892;&#20026;&#65292;&#21253;&#25324;&#36867;&#31163;&#38797;&#28857;&#21644;&#25910;&#25947;&#21040;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;&#30340;&#20998;&#26512;&#12290;&#30740;&#31350;&#22312;&#28176;&#36827;&#21644;&#38750;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31867;&#26032;&#30340;Nesterov&#31867;&#22411;&#30340;&#21152;&#36895;&#26041;&#27861;&#65292;&#24182;&#22238;&#31572;&#20102;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#26159;&#21542;&#36991;&#20813;&#20102;&#20005;&#26684;&#38797;&#28857;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07030</link><description>&lt;p&gt;
&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#29992;&#20110;&#38750;&#20984;&#20248;&#21270;&#65306;&#36867;&#36920;&#36712;&#36857;&#21644;&#25910;&#25947;&#21040;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;
&lt;/p&gt;
&lt;p&gt;
Accelerated gradient methods for nonconvex optimization: Escape trajectories from strict saddle points and convergence to local minima. (arXiv:2307.07030v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#34892;&#20026;&#65292;&#21253;&#25324;&#36867;&#31163;&#38797;&#28857;&#21644;&#25910;&#25947;&#21040;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;&#30340;&#20998;&#26512;&#12290;&#30740;&#31350;&#22312;&#28176;&#36827;&#21644;&#38750;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31867;&#26032;&#30340;Nesterov&#31867;&#22411;&#30340;&#21152;&#36895;&#26041;&#27861;&#65292;&#24182;&#22238;&#31572;&#20102;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#26159;&#21542;&#36991;&#20813;&#20102;&#20005;&#26684;&#38797;&#28857;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#20041;&#30340;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#22312;&#20809;&#28369;&#38750;&#20984;&#20989;&#25968;&#19978;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#23545;Polyak&#30340;&#37325;&#29699;&#26041;&#27861;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#36827;&#34892;&#25913;&#36827;&#65292;&#20197;&#23454;&#29616;&#23545;&#38750;&#20984;&#20989;&#25968;&#23616;&#37096;&#26497;&#23567;&#20540;&#30340;&#25910;&#25947;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;Nesterov&#31867;&#22411;&#30340;&#21152;&#36895;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#28176;&#36827;&#20998;&#26512;&#21644;&#38750;&#28176;&#36827;&#20998;&#26512;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20102;&#20005;&#26684;&#30740;&#31350;&#65292;&#21253;&#25324;&#36867;&#31163;&#38797;&#28857;&#21644;&#25910;&#25947;&#21040;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;&#12290;&#22312;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#22238;&#31572;&#20102;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#21363;&#24102;&#26377;&#21487;&#21464;&#21160;&#37327;&#21442;&#25968;&#30340;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#65288;NAG&#65289;&#26159;&#21542;&#20960;&#20046;&#24517;&#23450;&#36991;&#20813;&#20102;&#20005;&#26684;&#38797;&#28857;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#28176;&#36827;&#25910;&#25947;&#21644;&#21457;&#25955;&#30340;&#24230;&#37327;&#26041;&#24335;&#65292;&#24182;&#23545;&#20960;&#31181;&#24120;&#29992;&#30340;&#26631;&#20934;&#21152;&#36895;&#26041;&#27861;&#65288;&#22914;NAG&#21644;Ne&#65289;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the problem of understanding the behavior of a general class of accelerated gradient methods on smooth nonconvex functions. Motivated by some recent works that have proposed effective algorithms, based on Polyak's heavy ball method and the Nesterov accelerated gradient method, to achieve convergence to a local minimum of nonconvex functions, this work proposes a broad class of Nesterov-type accelerated methods and puts forth a rigorous study of these methods encompassing the escape from saddle-points and convergence to local minima through a both asymptotic and a non-asymptotic analysis. In the asymptotic regime, this paper answers an open question of whether Nesterov's accelerated gradient method (NAG) with variable momentum parameter avoids strict saddle points almost surely. This work also develops two metrics of asymptotic rate of convergence and divergence, and evaluates these two metrics for several popular standard accelerated methods such as the NAG, and Ne
&lt;/p&gt;</description></item></channel></rss>