<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35774;&#35745;&#20986;&#30340;&#28151;&#21512;&#31995;&#32479;&#27169;&#22411;&#20855;&#26377;&#20998;&#27573;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#21487;&#20197;&#29992;&#20110;&#20248;&#21270;&#25511;&#21046;&#35774;&#35745;&#65292;&#24182;&#19988;&#22312;&#26377;&#38480;&#35270;&#37326;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#20013;&#35745;&#31639;&#20986;&#20855;&#26377;&#24378;&#23616;&#37096;&#26368;&#20248;&#24615;&#20445;&#35777;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>https://arxiv.org/abs/2404.01814</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#28151;&#21512;&#31995;&#32479;&#35782;&#21035;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A neural network-based approach to hybrid systems identification for control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01814
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35774;&#35745;&#20986;&#30340;&#28151;&#21512;&#31995;&#32479;&#27169;&#22411;&#20855;&#26377;&#20998;&#27573;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#21487;&#20197;&#29992;&#20110;&#20248;&#21270;&#25511;&#21046;&#35774;&#35745;&#65292;&#24182;&#19988;&#22312;&#26377;&#38480;&#35270;&#37326;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#20013;&#35745;&#31639;&#20986;&#20855;&#26377;&#24378;&#23616;&#37096;&#26368;&#20248;&#24615;&#20445;&#35777;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20174;&#26377;&#38480;&#25968;&#37327;&#30340;(&#29366;&#24577;-&#36755;&#20837;)-&#21518;&#32487;&#29366;&#24577;&#25968;&#25454;&#28857;&#20013;&#35782;&#21035;&#26410;&#30693;&#21160;&#24577;&#31995;&#32479;&#65292;&#24182;&#19988;&#35813;&#27169;&#22411;&#36866;&#29992;&#20110;&#20248;&#21270;&#25511;&#21046;&#35774;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#31070;&#32463;&#32593;&#32476;(NN)&#26550;&#26500;&#65292;&#35813;&#26550;&#26500;&#20135;&#29983;&#20855;&#26377;&#20998;&#27573;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#28151;&#21512;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#23545;&#32593;&#32476;&#21442;&#25968;&#20855;&#26377;&#21487;&#24494;&#24615;&#65292;&#20174;&#32780;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992;&#22522;&#20110;&#23548;&#25968;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;NN&#26435;&#37325;&#30340;&#31934;&#24515;&#36873;&#25321;&#21487;&#20197;&#20135;&#29983;&#20855;&#26377;&#38750;&#24120;&#26377;&#21033;&#32467;&#26500;&#23646;&#24615;&#30340;&#28151;&#21512;&#31995;&#32479;&#27169;&#22411;&#65292;&#24403;&#20316;&#20026;&#26377;&#38480;&#35270;&#37326;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;(OCP)&#30340;&#19968;&#37096;&#20998;&#20351;&#29992;&#26102;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#23616;&#37096;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#38750;&#32447;&#24615;&#35268;&#21010;&#35745;&#31639;&#20855;&#26377;&#24378;&#23616;&#37096;&#26368;&#20248;&#24615;&#20445;&#35777;&#30340;&#26368;&#20248;&#35299;&#65292;&#19982;&#36890;&#24120;&#38656;&#35201;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#30340;&#19968;&#33324;&#28151;&#21512;&#31995;&#32479;&#30340;&#32463;&#20856;OCP&#30456;&#27604;&#12290;&#21478;&#22806;&#65292;&#36825;&#20123;&#27169;&#22411;&#36824;&#21487;&#20197;&#34987;&#29992;&#20110;&#25925;&#38556;&#26816;&#27979;&#21644;&#25925;&#38556;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01814v1 Announce Type: cross  Abstract: We consider the problem of designing a machine learning-based model of an unknown dynamical system from a finite number of (state-input)-successor state data points, such that the model obtained is also suitable for optimal control design. We propose a specific neural network (NN) architecture that yields a hybrid system with piecewise-affine dynamics that is differentiable with respect to the network's parameters, thereby enabling the use of derivative-based training procedures. We show that a careful choice of our NN's weights produces a hybrid system model with structural properties that are highly favourable when used as part of a finite horizon optimal control problem (OCP). Specifically, we show that optimal solutions with strong local optimality guarantees can be computed via nonlinear programming, in contrast to classical OCPs for general hybrid systems which typically require mixed-integer optimization. In addition to being we
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#26469;&#23454;&#29616;&#28857;&#23545;&#28857;&#33021;&#28304;&#20132;&#26131;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24110;&#21161;&#33258;&#21160;&#21270;&#28040;&#36153;&#32773;&#30340;&#31454;&#26631;&#21644;&#31649;&#29702;&#65292;&#24182;&#35299;&#20915;&#20102;&#21487;&#20877;&#29983;&#33021;&#28304;&#38646;&#36793;&#38469;&#25104;&#26412;&#21644;&#29289;&#29702;&#32422;&#26463;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.13947</link><description>&lt;p&gt;
&#32593;&#32476;&#21270;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#28857;&#23545;&#28857;&#33021;&#28304;&#20132;&#26131;
&lt;/p&gt;
&lt;p&gt;
Networked Multiagent Reinforcement Learning for Peer-to-Peer Energy Trading. (arXiv:2401.13947v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#26469;&#23454;&#29616;&#28857;&#23545;&#28857;&#33021;&#28304;&#20132;&#26131;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24110;&#21161;&#33258;&#21160;&#21270;&#28040;&#36153;&#32773;&#30340;&#31454;&#26631;&#21644;&#31649;&#29702;&#65292;&#24182;&#35299;&#20915;&#20102;&#21487;&#20877;&#29983;&#33021;&#28304;&#38646;&#36793;&#38469;&#25104;&#26412;&#21644;&#29289;&#29702;&#32422;&#26463;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#20998;&#24067;&#24335;&#21487;&#20877;&#29983;&#33021;&#28304;&#21644;&#33021;&#37327;&#20648;&#23384;&#36164;&#28304;&#36827;&#34892;&#28857;&#23545;&#28857;&#33021;&#28304;&#20132;&#26131;&#34987;&#38271;&#26399;&#35748;&#20026;&#26159;&#25552;&#39640;&#33021;&#28304;&#31995;&#32479;&#24377;&#24615;&#21644;&#21487;&#25345;&#32493;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#28040;&#36153;&#32773;&#21644;&#33258;&#32473;&#33258;&#36275;&#32773;&#65288;&#20855;&#26377;&#33021;&#28304;&#21457;&#30005;&#36164;&#28304;&#30340;&#20154;&#65289;&#32570;&#20047;&#36827;&#34892;&#37325;&#22797;&#28857;&#23545;&#28857;&#20132;&#26131;&#30340;&#19987;&#19994;&#30693;&#35782;&#65292;&#24182;&#19988;&#21487;&#20877;&#29983;&#33021;&#28304;&#30340;&#38646;&#36793;&#38469;&#25104;&#26412;&#22312;&#30830;&#23450;&#20844;&#24179;&#24066;&#22330;&#20215;&#26684;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#26694;&#26550;&#65292;&#20197;&#24110;&#21161;&#33258;&#21160;&#21270;&#28040;&#36153;&#32773;&#23545;&#22826;&#38451;&#33021;&#20809;&#20239;&#21644;&#33021;&#37327;&#20648;&#23384;&#36164;&#28304;&#30340;&#31454;&#26631;&#21644;&#31649;&#29702;&#65292;&#22312;&#19968;&#31181;&#21033;&#29992;&#20379;&#38656;&#27604;&#30340;&#28857;&#23545;&#28857;&#28165;&#31639;&#26426;&#21046;&#19979;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MARL&#26694;&#26550;&#22914;&#20309;&#25972;&#21512;&#29289;&#29702;&#32593;&#32476;&#32422;&#26463;&#20197;&#23454;&#29616;&#30005;&#21387;&#25511;&#21046;&#65292;&#20174;&#32780;&#30830;&#20445;&#28857;&#23545;&#28857;&#33021;&#28304;&#20132;&#26131;&#30340;&#29289;&#29702;&#21487;&#34892;&#24615;&#65292;&#24182;&#20026;&#30495;&#23454;&#19990;&#30028;&#30340;&#23454;&#26045;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Utilizing distributed renewable and energy storage resources in local distribution networks via peer-to-peer (P2P) energy trading has long been touted as a solution to improve energy systems' resilience and sustainability. Consumers and prosumers (those who have energy generation resources), however, do not have the expertise to engage in repeated P2P trading, and the zero-marginal costs of renewables present challenges in determining fair market prices. To address these issues, we propose multi-agent reinforcement learning (MARL) frameworks to help automate consumers' bidding and management of their solar PV and energy storage resources, under a specific P2P clearing mechanism that utilizes the so-called supply-demand ratio. In addition, we show how the MARL frameworks can integrate physical network constraints to realize voltage control, hence ensuring physical feasibility of the P2P energy trading and paving way for real-world implementations.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#36890;&#36807;&#35745;&#31639;&#20195;&#29702;&#20851;&#38190;&#24615;&#25351;&#26631;&#26469;&#29983;&#25104;&#23433;&#20840;&#36793;&#30028;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23558;&#21487;&#33021;&#30340;&#38169;&#35823;&#34892;&#20026;&#30340;&#21518;&#26524;&#19982;&#25972;&#20307;&#24615;&#33021;&#30340;&#39044;&#26399;&#25439;&#22833;&#32852;&#31995;&#36215;&#26469;&#12290;&#22312;Atari&#29615;&#22659;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#20195;&#29702;&#25509;&#36817;&#22833;&#36133;&#29366;&#24577;&#65292;&#23433;&#20840;&#36793;&#30028;&#20943;&#23567;&#12290;</title><link>http://arxiv.org/abs/2307.13642</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#30340;&#23433;&#20840;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Safety Margins for Reinforcement Learning. (arXiv:2307.13642v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#36890;&#36807;&#35745;&#31639;&#20195;&#29702;&#20851;&#38190;&#24615;&#25351;&#26631;&#26469;&#29983;&#25104;&#23433;&#20840;&#36793;&#30028;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23558;&#21487;&#33021;&#30340;&#38169;&#35823;&#34892;&#20026;&#30340;&#21518;&#26524;&#19982;&#25972;&#20307;&#24615;&#33021;&#30340;&#39044;&#26399;&#25439;&#22833;&#32852;&#31995;&#36215;&#26469;&#12290;&#22312;Atari&#29615;&#22659;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#20195;&#29702;&#25509;&#36817;&#22833;&#36133;&#29366;&#24577;&#65292;&#23433;&#20840;&#36793;&#30028;&#20943;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20219;&#20309;&#33258;&#20027;&#25511;&#21046;&#22120;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#37117;&#21487;&#33021;&#19981;&#23433;&#20840;&#12290;&#33021;&#22815;&#23450;&#37327;&#22320;&#30830;&#23450;&#20309;&#26102;&#20250;&#21457;&#29983;&#36825;&#20123;&#19981;&#23433;&#20840;&#24773;&#20917;&#23545;&#20110;&#21450;&#26102;&#24341;&#20837;&#20154;&#31867;&#30417;&#30563;&#33267;&#20851;&#37325;&#35201;&#65292;&#20363;&#22914;&#36135;&#36816;&#24212;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#20195;&#29702;&#30340;&#24773;&#20917;&#30340;&#30495;&#27491;&#20851;&#38190;&#24615;&#21487;&#20197;&#34987;&#31283;&#20581;&#22320;&#23450;&#20041;&#20026;&#22312;&#19968;&#20123;&#38543;&#26426;&#21160;&#20316;&#19979;&#22870;&#21169;&#30340;&#24179;&#22343;&#20943;&#23569;&#12290;&#21487;&#20197;&#23558;&#23454;&#26102;&#21487;&#35745;&#31639;&#30340;&#20195;&#29702;&#20851;&#38190;&#24615;&#25351;&#26631;&#65288;&#21363;&#65292;&#26080;&#38656;&#23454;&#38469;&#27169;&#25311;&#38543;&#26426;&#21160;&#20316;&#30340;&#24433;&#21709;&#65289;&#19982;&#30495;&#27491;&#30340;&#20851;&#38190;&#24615;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#20195;&#29702;&#25351;&#26631;&#29983;&#25104;&#23433;&#20840;&#36793;&#30028;&#65292;&#23558;&#28508;&#22312;&#38169;&#35823;&#34892;&#20026;&#30340;&#21518;&#26524;&#30452;&#25509;&#19982;&#25972;&#20307;&#24615;&#33021;&#30340;&#39044;&#26399;&#25439;&#22833;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#22312;Atari&#29615;&#22659;&#20013;&#36890;&#36807;APE-X&#21644;A3C&#30340;&#23398;&#20064;&#31574;&#30053;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#38543;&#30528;&#20195;&#29702;&#25509;&#36817;&#22833;&#36133;&#29366;&#24577;&#65292;&#23433;&#20840;&#36793;&#30028;&#30340;&#20943;&#23567;&#12290;&#23558;&#23433;&#20840;&#36793;&#30028;&#25972;&#21512;&#21040;&#30417;&#25511;&#31243;&#24207;&#20013;&#30340;&#21019;&#26032;&#28857;&#22312;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Any autonomous controller will be unsafe in some situations. The ability to quantitatively identify when these unsafe situations are about to occur is crucial for drawing timely human oversight in, e.g., freight transportation applications. In this work, we demonstrate that the true criticality of an agent's situation can be robustly defined as the mean reduction in reward given some number of random actions. Proxy criticality metrics that are computable in real-time (i.e., without actually simulating the effects of random actions) can be compared to the true criticality, and we show how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance. We evaluate our approach on learned policies from APE-X and A3C within an Atari environment, and demonstrate how safety margins decrease as agents approach failure states. The integration of safety margins into programs for monit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;(NNs)&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#30340;&#36817;&#20284;&#26041;&#27861;&#65292;&#31216;&#20026;&#23433;&#20840;&#22686;&#24378;&#65292;&#21487;&#20197;&#20351;&#35299;&#20915;&#26041;&#26696;&#22312;&#32447;&#21487;&#34892;&#24182;&#20855;&#26377;&#25910;&#25947;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#30830;&#23450;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.09575</link><description>&lt;p&gt;
&#22522;&#20110;&#23433;&#20840;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#32447;&#24615;&#36817;&#20284;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Approximate non-linear model predictive control with safety-augmented neural networks. (arXiv:2304.09575v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;(NNs)&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#30340;&#36817;&#20284;&#26041;&#27861;&#65292;&#31216;&#20026;&#23433;&#20840;&#22686;&#24378;&#65292;&#21487;&#20197;&#20351;&#35299;&#20915;&#26041;&#26696;&#22312;&#32447;&#21487;&#34892;&#24182;&#20855;&#26377;&#25910;&#25947;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#30830;&#23450;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#21487;&#20197;&#23454;&#29616;&#23545;&#20110;&#19968;&#33324;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#28385;&#36275;&#65292;&#20294;&#38656;&#35201;&#36827;&#34892;&#35745;&#31639;&#24320;&#38144;&#24456;&#22823;&#30340;&#22312;&#32447;&#20248;&#21270;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;(NNs)&#23545;&#36825;&#31181;MPC&#25511;&#21046;&#22120;&#30340;&#36817;&#20284;&#65292;&#20197;&#23454;&#29616;&#24555;&#36895;&#30340;&#22312;&#32447;&#35780;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23433;&#20840;&#22686;&#24378;&#65292;&#23613;&#31649;&#23384;&#22312;&#36817;&#20284;&#19981;&#20934;&#30830;&#24615;&#65292;&#20294;&#21487;&#20197;&#33719;&#24471;&#25910;&#25947;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#30830;&#23450;&#20445;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;NN&#36817;&#20284;MPC&#30340;&#25972;&#20010;&#36755;&#20837;&#24207;&#21015;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#22312;&#32447;&#39564;&#35777;&#23427;&#26159;&#21542;&#26159;MPC&#38382;&#39064;&#30340;&#21487;&#34892;&#35299;&#12290;&#24403;&#35813;&#35299;&#20915;&#26041;&#26696;&#19981;&#21487;&#34892;&#25110;&#25104;&#26412;&#26356;&#39640;&#26102;&#65292;&#25105;&#20204;&#22522;&#20110;&#26631;&#20934;MPC&#25216;&#26415;&#23558;NN&#35299;&#20915;&#26041;&#26696;&#26367;&#25442;&#20026;&#23433;&#20840;&#20505;&#36873;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20165;&#38656;&#35201;&#23545;NN&#36827;&#34892;&#19968;&#27425;&#35780;&#20272;&#21644;&#23545;&#36755;&#20837;&#24207;&#21015;&#36827;&#34892;&#22312;&#32447;&#21069;&#21521;&#31215;&#20998;&#65292;&#36825;&#22312;&#36164;&#28304;&#21463;&#38480;&#31995;&#32479;&#19978;&#30340;&#35745;&#31639;&#36895;&#24230;&#24456;&#24555;&#12290;&#25152;&#25552;&#20986;&#30340;&#25511;&#21046;&#26694;&#26550;&#22312;&#19977;&#20010;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#38750;&#32447;&#24615;MPC&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#23637;&#31034;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model predictive control (MPC) achieves stability and constraint satisfaction for general nonlinear systems, but requires computationally expensive online optimization. This paper studies approximations of such MPC controllers via neural networks (NNs) to achieve fast online evaluation. We propose safety augmentation that yields deterministic guarantees for convergence and constraint satisfaction despite approximation inaccuracies. We approximate the entire input sequence of the MPC with NNs, which allows us to verify online if it is a feasible solution to the MPC problem. We replace the NN solution by a safe candidate based on standard MPC techniques whenever it is infeasible or has worse cost. Our method requires a single evaluation of the NN and forward integration of the input sequence online, which is fast to compute on resource-constrained systems. The proposed control framework is illustrated on three non-linear MPC benchmarks of different complexity, demonstrating computational
&lt;/p&gt;</description></item></channel></rss>