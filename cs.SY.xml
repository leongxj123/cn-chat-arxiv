<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#20013;&#24615;&#33021;&#21644;&#21487;&#34892;&#24615;&#21463;&#24433;&#21709;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.17338</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#30340;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning-based Receding Horizon Control using Adaptive Control Barrier Functions for Safety-Critical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17338
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#20013;&#24615;&#33021;&#21644;&#21487;&#34892;&#24615;&#21463;&#24433;&#21709;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#25511;&#21046;&#26041;&#27861;&#20026;&#23433;&#20840;&#20851;&#38190;&#38382;&#39064;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#24456;&#23481;&#26131;&#21464;&#24471;&#26840;&#25163;&#12290;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;(CBFs)&#20316;&#20026;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#20986;&#29616;&#65292;&#36890;&#36807;&#20854;&#21069;&#21521;&#19981;&#21464;&#24615;&#23646;&#24615;&#65292;&#26377;&#21033;&#20110;&#36890;&#36807;&#22312;&#25439;&#22833;&#19968;&#20123;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#24335;&#22320;&#20445;&#35777;&#23433;&#20840;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#23450;&#20041;&#24615;&#33021;&#30446;&#26631;&#20197;&#21450;&#24517;&#39035;&#22987;&#32456;&#25191;&#34892;&#30340;&#22522;&#20110;CBF&#30340;&#23433;&#20840;&#32422;&#26463;&#12290;&#36951;&#25022;&#30340;&#26159;&#65292;&#20004;&#20010;&#20851;&#38190;&#22240;&#32032;&#21487;&#33021;&#20250;&#23545;&#24615;&#33021;&#21644;&#35299;&#20915;&#26041;&#26696;&#30340;&#21487;&#34892;&#24615;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65306;(i)&#25104;&#26412;&#20989;&#25968;&#21450;&#20854;&#30456;&#20851;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#20197;&#21450;(ii)&#22312;CBF&#32422;&#26463;&#20869;&#36827;&#34892;&#21442;&#25968;&#26657;&#20934;&#65292;&#25429;&#25417;&#24615;&#33021;&#21644;&#20445;&#23432;&#24615;&#20043;&#38388;&#30340;&#25240;&#34935;&#65292;&#20197;&#21450;&#19981;&#21487;&#34892;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#30340;&#24378;&#21270;&#23398;&#20064;(RL)&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;(RHC)&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17338v1 Announce Type: cross  Abstract: Optimal control methods provide solutions to safety-critical problems but easily become intractable. Control Barrier Functions (CBFs) have emerged as a popular technique that facilitates their solution by provably guaranteeing safety, through their forward invariance property, at the expense of some performance loss. This approach involves defining a performance objective alongside CBF-based safety constraints that must always be enforced. Unfortunately, both performance and solution feasibility can be significantly impacted by two key factors: (i) the selection of the cost function and associated parameters, and (ii) the calibration of parameters within the CBF-based constraints, which capture the trade-off between performance and conservativeness. %as well as infeasibility. To address these challenges, we propose a Reinforcement Learning (RL)-based Receding Horizon Control (RHC) approach leveraging Model Predictive Control (MPC) with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#20551;&#35774;&#26410;&#30693;&#36755;&#20837;&#20026;&#32447;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#38750;&#32447;&#24615;&#20248;&#21270;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#23545;&#26410;&#30693;&#36755;&#20837;&#30340;&#20272;&#35745;&#65292;&#24182;&#36890;&#36807;&#32852;&#21512; sigma-point &#21464;&#25442;&#26041;&#26696;&#23558;&#29366;&#24577;&#21644;&#26410;&#30693;&#36755;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#20272;&#35745;&#20013;&#65292;&#30830;&#20445;&#20854;&#31283;&#23450;&#24615;&#12290;&#36825;&#20010;&#26041;&#27861;&#36866;&#29992;&#20110;&#35768;&#22810;&#26234;&#33021;&#33258;&#20027;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2306.12361</link><description>&lt;p&gt;
&#22522;&#20110;&#20248;&#21270;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340; sigma-point &#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#19982;&#38750;&#32447;&#24615;&#26410;&#30693;&#36755;&#20837;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via Optimization and Data-driven Approach for Dynamic Systems. (arXiv:2306.12361v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#20551;&#35774;&#26410;&#30693;&#36755;&#20837;&#20026;&#32447;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#38750;&#32447;&#24615;&#20248;&#21270;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#23545;&#26410;&#30693;&#36755;&#20837;&#30340;&#20272;&#35745;&#65292;&#24182;&#36890;&#36807;&#32852;&#21512; sigma-point &#21464;&#25442;&#26041;&#26696;&#23558;&#29366;&#24577;&#21644;&#26410;&#30693;&#36755;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#20272;&#35745;&#20013;&#65292;&#30830;&#20445;&#20854;&#31283;&#23450;&#24615;&#12290;&#36825;&#20010;&#26041;&#27861;&#36866;&#29992;&#20110;&#35768;&#22810;&#26234;&#33021;&#33258;&#20027;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#25968;&#20851;&#20110;&#29366;&#24577;&#21644;&#26410;&#30693;&#36755;&#20837;(UI)&#20272;&#35745;&#30340;&#25991;&#29486;&#37117;&#35201;&#27714;UI&#26159;&#32447;&#24615;&#30340;&#65292;&#36825;&#20010;&#38480;&#21046;&#21487;&#33021;&#22826;&#20005;&#26684;&#20102;&#65292;&#22240;&#20026;&#23427;&#24182;&#19981;&#36866;&#29992;&#20110;&#35768;&#22810;&#26234;&#33021;&#33258;&#20027;&#31995;&#32479;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#23548;&#25968;&#26410;&#30693;&#36755;&#20837; Sigma-point &#21345;&#23572;&#26364;&#28388;&#27874;&#22120;(SPKE-nUI)&#65292;&#20854;&#20013; SPKF &#19982;&#26222;&#36890;&#38750;&#32447;&#24615; UI &#20272;&#35745;&#22120;&#30456;&#20114;&#36830;&#25509;&#65292;&#21487;&#20197;&#36890;&#36807;&#38750;&#32447;&#24615;&#20248;&#21270;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#23454;&#29616;&#12290;&#38750;&#32447;&#24615; UI &#20272;&#35745;&#22120;&#20351;&#29992;&#21518;&#39564;&#29366;&#24577;&#20272;&#35745;&#65292;&#36825;&#23545;&#29366;&#24577;&#39044;&#27979;&#35823;&#24046;&#19981;&#22826;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32852;&#21512; sigma-point &#21464;&#25442;&#26041;&#26696;&#65292;&#23558;&#29366;&#24577;&#21644; UI &#30340;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837; SPKF-nUI &#30340;&#20272;&#35745;&#20013;&#12290;&#28145;&#20837;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#20998;&#26512;&#35777;&#26126;&#20102;&#22312;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340; SPKF-nUI &#21487;&#20197;&#20135;&#29983;&#25351;&#25968;&#32423;&#25910;&#25947;&#30340;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#22522;&#20110;&#27169;&#25311;&#30340;&#36335;&#38754;&#36710;&#36742;&#25511;&#21046;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most works on joint state and unknown input (UI) estimation require the assumption that the UIs are linear; this is potentially restrictive as it does not hold in many intelligent autonomous systems. To overcome this restriction and circumvent the need to linearize the system, we propose a derivative-free Unknown Input Sigma-point Kalman Filter (SPKF-nUI) where the SPKF is interconnected with a general nonlinear UI estimator that can be implemented via nonlinear optimization and data-driven approaches. The nonlinear UI estimator uses the posterior state estimate which is less susceptible to state prediction error. In addition, we introduce a joint sigma-point transformation scheme to incorporate both the state and UI uncertainties in the estimation of SPKF-nUI. An in-depth stochastic stability analysis proves that the proposed SPKF-nUI yields exponentially converging estimation error bounds under reasonable assumptions. Finally, two case studies are carried out on a simulation-based ri
&lt;/p&gt;</description></item></channel></rss>