<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;DNN&#30340;&#25511;&#21046;&#22120;&#65292;&#36890;&#36807;&#35774;&#35745;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30830;&#20445;&#38381;&#29615;&#31283;&#23450;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#20248;&#21270;&#21442;&#25968;&#20197;&#23454;&#29616;&#25913;&#36827;&#30340;&#25511;&#21046;&#24615;&#33021;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20851;&#20110;&#36319;&#36394;&#35823;&#24046;&#30340;&#26126;&#30830;&#19978;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.00381</link><description>&lt;p&gt;
&#22522;&#20110;&#32467;&#26500;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#25289;&#26684;&#26391;&#26085;&#31995;&#32479;&#21453;&#27493;&#36712;&#36857;&#36319;&#36394;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Structured Deep Neural Networks-Based Backstepping Trajectory Tracking Control for Lagrangian Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00381
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;DNN&#30340;&#25511;&#21046;&#22120;&#65292;&#36890;&#36807;&#35774;&#35745;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30830;&#20445;&#38381;&#29615;&#31283;&#23450;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#20248;&#21270;&#21442;&#25968;&#20197;&#23454;&#29616;&#25913;&#36827;&#30340;&#25511;&#21046;&#24615;&#33021;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20851;&#20110;&#36319;&#36394;&#35823;&#24046;&#30340;&#26126;&#30830;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#20110;&#23398;&#20064;&#25511;&#21046;&#22120;&#65292;&#22240;&#20026;&#20854;&#20986;&#33394;&#30340;&#36924;&#36817;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#40657;&#30418;&#29305;&#24615;&#23545;&#38381;&#29615;&#31283;&#23450;&#24615;&#20445;&#35777;&#21644;&#24615;&#33021;&#20998;&#26512;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;DNN&#30340;&#25511;&#21046;&#22120;&#65292;&#29992;&#20110;&#37319;&#29992;&#21453;&#25512;&#25216;&#26415;&#23454;&#29616;&#25289;&#26684;&#26391;&#26085;&#31995;&#32479;&#30340;&#36712;&#36857;&#36319;&#36394;&#25511;&#21046;&#12290;&#36890;&#36807;&#36866;&#24403;&#35774;&#35745;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#25152;&#25552;&#20986;&#30340;&#25511;&#21046;&#22120;&#21487;&#20197;&#30830;&#20445;&#20219;&#20309;&#20860;&#23481;&#30340;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#23454;&#29616;&#38381;&#29615;&#31283;&#23450;&#24615;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#36827;&#19968;&#27493;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#25511;&#21046;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36319;&#36394;&#35823;&#24046;&#30340;&#26126;&#30830;&#19978;&#38480;&#65292;&#36825;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#25511;&#21046;&#21442;&#25968;&#26469;&#23454;&#29616;&#25152;&#38656;&#30340;&#36319;&#36394;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#24403;&#31995;&#32479;&#27169;&#22411;&#26410;&#30693;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#25289;&#26684;&#26391;&#26085;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00381v1 Announce Type: cross  Abstract: Deep neural networks (DNN) are increasingly being used to learn controllers due to their excellent approximation capabilities. However, their black-box nature poses significant challenges to closed-loop stability guarantees and performance analysis. In this paper, we introduce a structured DNN-based controller for the trajectory tracking control of Lagrangian systems using backing techniques. By properly designing neural network structures, the proposed controller can ensure closed-loop stability for any compatible neural network parameters. In addition, improved control performance can be achieved by further optimizing neural network parameters. Besides, we provide explicit upper bounds on tracking errors in terms of controller parameters, which allows us to achieve the desired tracking performance by properly selecting the controller parameters. Furthermore, when system models are unknown, we propose an improved Lagrangian neural net
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CNN-SAEDN-Res&#30340;&#30701;&#26399;&#21151;&#29575;&#36127;&#33655;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12289;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#21644;&#27531;&#24046;&#20462;&#27491;&#25216;&#26415;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#24102;&#26377;&#38750;&#26102;&#24207;&#22240;&#32032;&#30340;&#36127;&#33655;&#25968;&#25454;&#24182;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.07140</link><description>&lt;p&gt;
&#22522;&#20110;CNN-SAEDN-Res&#30340;&#30701;&#26399;&#21151;&#29575;&#36127;&#33655;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Short-term power load forecasting method based on CNN-SAEDN-Res. (arXiv:2309.07140v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07140
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CNN-SAEDN-Res&#30340;&#30701;&#26399;&#21151;&#29575;&#36127;&#33655;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12289;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#21644;&#27531;&#24046;&#20462;&#27491;&#25216;&#26415;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#24102;&#26377;&#38750;&#26102;&#24207;&#22240;&#32032;&#30340;&#36127;&#33655;&#25968;&#25454;&#24182;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#24102;&#26377;&#38750;&#26102;&#24207;&#22240;&#32032;&#30340;&#36127;&#33655;&#25968;&#25454;&#38590;&#20197;&#36890;&#36807;&#24207;&#21015;&#27169;&#22411;&#36827;&#34892;&#22788;&#29702;&#12290;&#36825;&#20010;&#38382;&#39064;&#23548;&#33268;&#20102;&#39044;&#27979;&#30340;&#31934;&#24230;&#19981;&#36275;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#12289;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#65288;SAEDN&#65289;&#21644;&#27531;&#24046;&#20462;&#27491;&#65288;Res&#65289;&#30340;&#30701;&#26399;&#36127;&#33655;&#39044;&#27979;&#26041;&#27861;&#12290;&#22312;&#35813;&#26041;&#27861;&#20013;&#65292;&#29305;&#24449;&#25552;&#21462;&#27169;&#22359;&#30001;&#19968;&#20010;&#20108;&#32500;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#32452;&#25104;&#65292;&#29992;&#20110;&#25366;&#25496;&#25968;&#25454;&#20043;&#38388;&#30340;&#23616;&#37096;&#30456;&#20851;&#24615;&#24182;&#33719;&#21462;&#39640;&#32500;&#25968;&#25454;&#29305;&#24449;&#12290;&#21021;&#22987;&#36127;&#33655;&#39044;&#27979;&#27169;&#22359;&#30001;&#19968;&#20010;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#21644;&#19968;&#20010;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFN&#65289;&#32452;&#25104;&#12290;&#35813;&#27169;&#22359;&#21033;&#29992;&#33258;&#27880;&#24847;&#26426;&#21046;&#23545;&#39640;&#32500;&#29305;&#24449;&#36827;&#34892;&#32534;&#30721;&#12290;&#36825;&#20010;&#25805;&#20316;&#21487;&#20197;&#33719;&#21462;&#25968;&#25454;&#20043;&#38388;&#30340;&#20840;&#23616;&#30456;&#20851;&#24615;&#12290;&#22240;&#27492;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#22522;&#20110;&#28151;&#21512;&#20102;&#38750;&#26102;&#24207;&#22240;&#32032;&#30340;&#25968;&#25454;&#20013;&#30340;&#32806;&#21512;&#20851;&#31995;&#20445;&#30041;&#37325;&#35201;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
In deep learning, the load data with non-temporal factors are difficult to process by sequence models. This problem results in insufficient precision of the prediction. Therefore, a short-term load forecasting method based on convolutional neural network (CNN), self-attention encoder-decoder network (SAEDN) and residual-refinement (Res) is proposed. In this method, feature extraction module is composed of a two-dimensional convolutional neural network, which is used to mine the local correlation between data and obtain high-dimensional data features. The initial load fore-casting module consists of a self-attention encoder-decoder network and a feedforward neural network (FFN). The module utilizes self-attention mechanisms to encode high-dimensional features. This operation can obtain the global correlation between data. Therefore, the model is able to retain important information based on the coupling relationship between the data in data mixed with non-time series factors. Then, self
&lt;/p&gt;</description></item></channel></rss>