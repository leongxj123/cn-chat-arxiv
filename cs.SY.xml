<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#26412;&#25991;&#22312;&#21270;&#23398;&#36807;&#31243;&#30340;&#20132;&#21449;&#39046;&#22495;&#25925;&#38556;&#35786;&#26029;&#20013;&#65292;&#23545;&#21333;&#28304;&#21644;&#22810;&#28304;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#31639;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#27604;&#36739;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#27809;&#26377;&#36827;&#34892;&#36866;&#24212;&#65292;&#20351;&#29992;&#22810;&#20010;&#39046;&#22495;&#36827;&#34892;&#35757;&#32451;&#20063;&#20855;&#26377;&#31215;&#26497;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.11247</link><description>&lt;p&gt;
&#22810;&#28304;&#39046;&#22495;&#36866;&#24212;&#29992;&#20110;&#21270;&#23398;&#36807;&#31243;&#20132;&#21449;&#39046;&#22495;&#25925;&#38556;&#35786;&#26029;
&lt;/p&gt;
&lt;p&gt;
Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes. (arXiv:2308.11247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#21270;&#23398;&#36807;&#31243;&#30340;&#20132;&#21449;&#39046;&#22495;&#25925;&#38556;&#35786;&#26029;&#20013;&#65292;&#23545;&#21333;&#28304;&#21644;&#22810;&#28304;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#31639;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#27604;&#36739;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#27809;&#26377;&#36827;&#34892;&#36866;&#24212;&#65292;&#20351;&#29992;&#22810;&#20010;&#39046;&#22495;&#36827;&#34892;&#35757;&#32451;&#20063;&#20855;&#26377;&#31215;&#26497;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25925;&#38556;&#35786;&#26029;&#26159;&#36807;&#31243;&#30417;&#35270;&#20013;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#26426;&#22120;&#23398;&#20064;&#30340;&#25925;&#38556;&#35786;&#26029;&#31995;&#32479;&#22522;&#20110;&#20256;&#24863;&#22120;&#25968;&#25454;&#39044;&#27979;&#25925;&#38556;&#31867;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#25935;&#24863;&#65292;&#36825;&#20123;&#21464;&#21270;&#21487;&#33021;&#30001;&#20110;&#30417;&#27979;&#36807;&#31243;&#20013;&#30340;&#21464;&#21270;&#65292;&#22914;&#25805;&#20316;&#27169;&#24335;&#30340;&#25913;&#21464;&#65292;&#23548;&#33268;&#36328;&#39046;&#22495;&#25925;&#38556;&#35786;&#26029;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#22312;&#21270;&#23398;&#24037;&#19994;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#30000;&#32435;&#35199;-&#20234;&#26031;&#26364;&#36807;&#31243;&#30340;&#32972;&#26223;&#19979;&#65292;&#25552;&#20379;&#20102;&#21333;&#28304;&#21644;&#22810;&#28304;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#31639;&#27861;&#22312;&#20132;&#21449;&#39046;&#22495;&#25925;&#38556;&#35786;&#26029;&#20013;&#30340;&#24191;&#27867;&#27604;&#36739;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#27809;&#26377;&#36827;&#34892;&#36866;&#24212;&#65292;&#20351;&#29992;&#22810;&#20010;&#39046;&#22495;&#36827;&#34892;&#35757;&#32451;&#20063;&#20855;&#26377;&#31215;&#26497;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#22810;&#28304;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#30340;&#22522;&#20934;&#27169;&#22411;&#30456;&#23545;&#20110;&#21333;&#28304;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#30340;&#22522;&#20934;&#27169;&#22411;&#26377;&#25152;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fault diagnosis is an essential component in process supervision. Indeed, it determines which kind of fault has occurred, given that it has been previously detected, allowing for appropriate intervention. Automatic fault diagnosis systems use machine learning for predicting the fault type from sensor readings. Nonetheless, these models are sensible to changes in the data distributions, which may be caused by changes in the monitored process, such as changes in the mode of operation. This scenario is known as Cross-Domain Fault Diagnosis (CDFD). We provide an extensive comparison of single and multi-source unsupervised domain adaptation (SSDA and MSDA respectively) algorithms for CDFD. We study these methods in the context of the Tennessee-Eastmann Process, a widely used benchmark in the chemical industry. We show that using multiple domains during training has a positive effect, even when no adaptation is employed. As such, the MSDA baseline improves over the SSDA baseline classificati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.04428</link><description>&lt;p&gt;
&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#20803;&#23398;&#20064;&#25805;&#20316;&#31526;&#21040;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#36817;&#21462;&#24471;&#36827;&#23637;&#30340;&#19968;&#20010;&#24378;&#22823;&#27010;&#24565;&#26159;&#20174;&#24322;&#26500;&#26469;&#28304;&#25110;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20849;&#21516;&#29305;&#24449;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#23558;&#25152;&#26377;&#25968;&#25454;&#29992;&#20110;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#20989;&#25968;&#65292;&#26082;&#26377;&#21161;&#20110;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#26377;&#21161;&#20110;&#32479;&#35745;&#27867;&#21270;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20943;&#23569;&#35201;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20026;&#20102;&#22312;&#29702;&#35770;&#19978;&#20570;&#20986;&#36825;&#20123;&#20248;&#28857;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#22122;&#22768;&#21521;&#37327;&#27979;&#37327;$y = Mx + w$&#20013;&#22238;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;$M$&#30340;&#19968;&#33324;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21464;&#37327;$x$&#26082;&#21487;&#20197;&#26159;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20063;&#21487;&#20197;&#26159;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#36825;&#23548;&#33268;&#22122;&#22768;&#39033;&#30340;&#32553;&#25918;&#19981;&#20877;&#26377;&#21033;&#20110;&#28304;&#20219;&#21153;&#25968;&#37327;&#12290;&#36825;&#21453;&#36807;&#26469;&#20250;&#23548;&#33268;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21463;&#21040;&#21333;&#20219;&#21153;&#25968;&#25454;&#35268;&#27169;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp; Feature-Whiten}
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#20855;&#26377;&#26377;&#30028;&#25200;&#21160;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#21487;&#36798;&#38598;&#30340;&#20984;&#21253;&#20026;&#19968;&#38454;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#30340;&#20984;&#21253;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#25104;&#26412;&#12289;&#39640;&#31934;&#24230;&#30340;&#20272;&#35745;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#36807;&#36924;&#36817;&#21487;&#36798;&#38598;&#12290;</title><link>http://arxiv.org/abs/2303.17674</link><description>&lt;p&gt;
&#21487;&#36798;&#38598;&#30340;&#20984;&#21253;&#30340;&#31934;&#30830;&#21051;&#30011;
&lt;/p&gt;
&lt;p&gt;
Exact Characterization of the Convex Hulls of Reachable Sets. (arXiv:2303.17674v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#20855;&#26377;&#26377;&#30028;&#25200;&#21160;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#21487;&#36798;&#38598;&#30340;&#20984;&#21253;&#20026;&#19968;&#38454;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#30340;&#20984;&#21253;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#25104;&#26412;&#12289;&#39640;&#31934;&#24230;&#30340;&#20272;&#35745;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#36807;&#36924;&#36817;&#21487;&#36798;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#25200;&#21160;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#21487;&#36798;&#38598;&#30340;&#20984;&#21253;&#12290;&#21487;&#36798;&#38598;&#22312;&#25511;&#21046;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#20294;&#35745;&#31639;&#36215;&#26469;&#20173;&#28982;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#29616;&#26377;&#30340;&#36807;&#36924;&#36817;&#24037;&#20855;&#24448;&#24448;&#36807;&#20110;&#20445;&#23432;&#25110;&#35745;&#31639;&#20195;&#20215;&#39640;&#26114;&#12290;&#26412;&#25991;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#21487;&#36798;&#38598;&#30340;&#20984;&#21253;&#65292;&#23558;&#20854;&#34920;&#31034;&#25104;&#19968;&#38454;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#30340;&#20984;&#21253;&#65292;&#36825;&#20010;&#26377;&#38480;&#32500;&#30340;&#21051;&#30011;&#24320;&#21551;&#20102;&#19968;&#31181;&#32039;&#23494;&#30340;&#20272;&#35745;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#36807;&#36924;&#36817;&#21487;&#36798;&#38598;&#65292;&#19988;&#25104;&#26412;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#20302;&#12289;&#26356;&#31934;&#20934;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#31070;&#32463;&#21453;&#39304;&#29615;&#20998;&#26512;&#21644;&#40065;&#26834;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the convex hulls of reachable sets of nonlinear systems with bounded disturbances. Reachable sets play a critical role in control, but remain notoriously challenging to compute, and existing over-approximation tools tend to be conservative or computationally expensive. In this work, we exactly characterize the convex hulls of reachable sets as the convex hulls of solutions of an ordinary differential equation from all possible initial values of the disturbances. This finite-dimensional characterization unlocks a tight estimation algorithm to over-approximate reachable sets that is significantly faster and more accurate than existing methods. We present applications to neural feedback loop analysis and robust model predictive control.
&lt;/p&gt;</description></item></channel></rss>