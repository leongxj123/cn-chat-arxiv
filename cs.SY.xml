<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#23558;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#25511;&#21046;&#29702;&#35770;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35774;&#23450;&#28857;&#26356;&#26032;&#31639;&#27861;&#65292;&#20197;&#30830;&#20445;&#23433;&#20840;&#26465;&#20214;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#20219;&#21153;&#30446;&#26631;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.01551</link><description>&lt;p&gt;
&#20855;&#26377;&#25511;&#21046;&#29702;&#35770;&#23433;&#20840;&#20445;&#35777;&#30340;&#21160;&#24577;&#32593;&#32476;&#26725;&#25509;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Reinforcement Learning with Control-Theoretic Safety Guarantees for Dynamic Network Bridging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01551
&lt;/p&gt;
&lt;p&gt;
&#23558;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#25511;&#21046;&#29702;&#35770;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35774;&#23450;&#28857;&#26356;&#26032;&#31639;&#27861;&#65292;&#20197;&#30830;&#20445;&#23433;&#20840;&#26465;&#20214;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#20219;&#21153;&#30446;&#26631;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23433;&#20840;&#20851;&#38190;&#29615;&#22659;&#19979;&#35299;&#20915;&#22797;&#26434;&#30340;&#21512;&#20316;&#20219;&#21153;&#23545;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#25552;&#20986;&#20102;&#37325;&#22823;&#25361;&#25112;&#65292;&#23588;&#20854;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#26465;&#20214;&#19979;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#65292;&#23558;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#25511;&#21046;&#29702;&#35770;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#30830;&#20445;&#23433;&#20840;&#21644;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#19968;&#31181;&#26032;&#39062;&#30340;&#35774;&#23450;&#28857;&#26356;&#26032;&#31639;&#27861;&#65292;&#21160;&#24577;&#35843;&#25972;&#26234;&#33021;&#20307;&#20301;&#32622;&#65292;&#20197;&#20445;&#25345;&#23433;&#20840;&#26465;&#20214;&#32780;&#19981;&#24433;&#21709;&#20219;&#21153;&#30446;&#26631;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#25105;&#20204;&#35777;&#26126;&#30456;&#27604;&#20256;&#32479;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#65292;&#23454;&#29616;&#20102;&#19982;&#38646;&#23433;&#20840;&#36829;&#35268;&#30456;&#27604;&#21487;&#27604;&#30340;&#20219;&#21153;&#24615;&#33021;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#23433;&#20840;&#25511;&#21046;&#19982;&#23398;&#20064;&#26041;&#27861;&#30456;&#32467;&#21512;&#19981;&#20165;&#22686;&#24378;&#20102;&#23433;&#20840;&#21512;&#35268;&#24615;&#65292;&#36824;&#23454;&#29616;&#20102;&#33391;&#22909;&#30340;&#20219;&#21153;&#30446;&#26631;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01551v1 Announce Type: cross  Abstract: Addressing complex cooperative tasks in safety-critical environments poses significant challenges for Multi-Agent Systems, especially under conditions of partial observability. This work introduces a hybrid approach that integrates Multi-Agent Reinforcement Learning with control-theoretic methods to ensure safe and efficient distributed strategies. Our contributions include a novel setpoint update algorithm that dynamically adjusts agents' positions to preserve safety conditions without compromising the mission's objectives. Through experimental validation, we demonstrate significant advantages over conventional MARL strategies, achieving comparable task performance with zero safety violations. Our findings indicate that integrating safe control with learning approaches not only enhances safety compliance but also achieves good performance in mission objectives.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25506;&#35752;&#20102;&#20010;&#20307;&#26234;&#33021;&#26159;&#21542;&#23545;&#20110;&#38598;&#20307;&#26234;&#33021;&#30340;&#20135;&#29983;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#21450;&#24590;&#26679;&#30340;&#20010;&#20307;&#26234;&#33021;&#26377;&#21033;&#20110;&#26356;&#22823;&#30340;&#38598;&#20307;&#26234;&#33021;&#12290;&#22312;Lotka-Volterra&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20123;&#20010;&#20307;&#34892;&#20026;&#65292;&#29305;&#21035;&#26159;&#25504;&#39135;&#32773;&#30340;&#34892;&#20026;&#65292;&#26377;&#21033;&#20110;&#19982;&#20854;&#20182;&#31181;&#32676;&#20849;&#23384;&#65292;&#20294;&#22914;&#26524;&#29454;&#29289;&#21644;&#25504;&#39135;&#32773;&#37117;&#36275;&#22815;&#26234;&#33021;&#20197;&#25512;&#26029;&#24444;&#27492;&#30340;&#34892;&#20026;&#65292;&#20849;&#23384;&#23558;&#20276;&#38543;&#30528;&#20004;&#20010;&#31181;&#32676;&#30340;&#26080;&#38480;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2012.12689</link><description>&lt;p&gt;
&#20803;&#32032;&#36234;&#31528;&#65292;&#25972;&#20307;&#36234;&#32874;&#26126;&#12290;&#25110;&#32773;&#65292;&#21487;&#33021;&#24182;&#38750;&#22914;&#27492;&#65311;
&lt;/p&gt;
&lt;p&gt;
The Less Intelligent the Elements, the More Intelligent the Whole. Or, Possibly Not?. (arXiv:2012.12689v2 [eess.SY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.12689
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#20010;&#20307;&#26234;&#33021;&#26159;&#21542;&#23545;&#20110;&#38598;&#20307;&#26234;&#33021;&#30340;&#20135;&#29983;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#21450;&#24590;&#26679;&#30340;&#20010;&#20307;&#26234;&#33021;&#26377;&#21033;&#20110;&#26356;&#22823;&#30340;&#38598;&#20307;&#26234;&#33021;&#12290;&#22312;Lotka-Volterra&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20123;&#20010;&#20307;&#34892;&#20026;&#65292;&#29305;&#21035;&#26159;&#25504;&#39135;&#32773;&#30340;&#34892;&#20026;&#65292;&#26377;&#21033;&#20110;&#19982;&#20854;&#20182;&#31181;&#32676;&#20849;&#23384;&#65292;&#20294;&#22914;&#26524;&#29454;&#29289;&#21644;&#25504;&#39135;&#32773;&#37117;&#36275;&#22815;&#26234;&#33021;&#20197;&#25512;&#26029;&#24444;&#27492;&#30340;&#34892;&#20026;&#65292;&#20849;&#23384;&#23558;&#20276;&#38543;&#30528;&#20004;&#20010;&#31181;&#32676;&#30340;&#26080;&#38480;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#22823;&#33041;&#20013;&#30340;&#31070;&#32463;&#20803;&#19982;&#31038;&#20250;&#20013;&#30340;&#20154;&#31867;&#20043;&#38388;&#30340;&#21033;&#32500;&#22374;&#31867;&#27604;&#65292;&#38382;&#33258;&#24049;&#26159;&#21542;&#20010;&#20307;&#26234;&#33021;&#23545;&#20110;&#38598;&#20307;&#26234;&#33021;&#30340;&#20135;&#29983;&#26159;&#24517;&#35201;&#30340;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#24590;&#26679;&#30340;&#20010;&#20307;&#26234;&#33021;&#26377;&#21033;&#20110;&#26356;&#22823;&#30340;&#38598;&#20307;&#26234;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#36830;&#25509;&#20027;&#20041;&#35748;&#30693;&#31185;&#23398;&#12289;&#22522;&#20110;&#20195;&#29702;&#30340;&#24314;&#27169;&#12289;&#32676;&#20307;&#24515;&#29702;&#23398;&#12289;&#32463;&#27982;&#23398;&#21644;&#29289;&#29702;&#23398;&#30340;&#19981;&#21516;&#27934;&#35265;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#27934;&#35265;&#24212;&#29992;&#20110;Lotka-Volterra&#27169;&#22411;&#20013;&#23548;&#33268;&#25504;&#39135;&#32773;&#21644;&#29454;&#29289;&#35201;&#20040;&#20849;&#23384;&#35201;&#20040;&#20840;&#29699;&#28781;&#32477;&#30340;&#26234;&#33021;&#31867;&#22411;&#21644;&#31243;&#24230;&#12290;&#25105;&#20204;&#21457;&#29616;&#20960;&#20010;&#20010;&#20307;&#34892;&#20026; - &#23588;&#20854;&#26159;&#25504;&#39135;&#32773;&#30340;&#34892;&#20026; - &#26377;&#21033;&#20110;&#20849;&#23384;&#65292;&#26368;&#32456;&#22312;&#19968;&#20010;&#24179;&#34913;&#28857;&#21608;&#22260;&#20135;&#29983;&#38663;&#33633;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#21457;&#29616;&#65292;&#22914;&#26524;&#29454;&#29289;&#21644;&#25504;&#39135;&#32773;&#37117;&#36275;&#22815;&#26234;&#33021;&#20197;&#25512;&#26029;&#24444;&#27492;&#30340;&#34892;&#20026;&#65292;&#20849;&#23384;&#23601;&#20250;&#20276;&#38543;&#30528;&#20004;&#20010;&#31181;&#32676;&#30340;&#26080;&#38480;&#22686;&#38271;&#12290;&#30001;&#20110;Lotka-Volterra&#27169;&#22411;&#26159;&#19981;&#31283;&#23450;&#30340;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore a Leviathan analogy between neurons in a brain and human beings in society, asking ourselves whether individual intelligence is necessary for collective intelligence to emerge and, most importantly, what sort of individual intelligence is conducive of greater collective intelligence. We first review disparate insights from connectionist cognitive science, agent-based modeling, group psychology, economics and physics. Subsequently, we apply these insights to the sort and degrees of intelligence that in the Lotka-Volterra model lead to either co-existence or global extinction of predators and preys.  We find several individual behaviors -- particularly of predators -- that are conducive to co-existence, eventually with oscillations around an equilibrium. However, we also find that if both preys and predators are sufficiently intelligent to extrapolate one other's behavior, co-existence comes along with indefinite growth of both populations. Since the Lotka-Volterra model is al
&lt;/p&gt;</description></item></channel></rss>