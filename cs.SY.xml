<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#65292;&#36890;&#36807;&#39030;&#28857;&#24230;&#26680;&#21644;&#32593;&#32476;&#25195;&#25551;&#20027;&#21160;&#23398;&#20064;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#30340;&#23398;&#20064;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;</title><link>http://arxiv.org/abs/2308.07867</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#30340;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Graph-Structured Kernel Design for Power Flow Learning using Gaussian Processes. (arXiv:2308.07867v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#65292;&#36890;&#36807;&#39030;&#28857;&#24230;&#26680;&#21644;&#32593;&#32476;&#25195;&#25551;&#20027;&#21160;&#23398;&#20064;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#30340;&#23398;&#20064;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#21551;&#21457;&#30340;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#12290;&#35813;&#26680;&#34987;&#21629;&#21517;&#20026;&#39030;&#28857;&#24230;&#26680;&#65288;VDK&#65289;&#65292;&#23427;&#20381;&#36182;&#20110;&#22522;&#20110;&#32593;&#32476;&#22270;&#25110;&#25299;&#25169;&#30340;&#30005;&#21387;&#27880;&#20837;&#20851;&#31995;&#30340;&#28508;&#22312;&#20998;&#35299;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;VDK&#35774;&#35745;&#36991;&#20813;&#20102;&#38656;&#35201;&#35299;&#20915;&#26680;&#25628;&#32034;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#20026;&#20102;&#25552;&#39640;&#25928;&#29575;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#19968;&#31181;&#22270;&#32553;&#20943;&#26041;&#27861;&#65292;&#20197;&#33719;&#24471;&#20855;&#26377;&#36739;&#23569;&#39033;&#30340;VDK&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32593;&#32476;&#25195;&#25551;&#20027;&#21160;&#23398;&#20064;&#26041;&#26696;&#65292;&#23427;&#26234;&#33021;&#22320;&#36873;&#25321;&#39034;&#24207;&#35757;&#32451;&#36755;&#20837;&#65292;&#21152;&#36895;VDK&#30340;&#23398;&#20064;&#12290;&#21033;&#29992;VDK&#30340;&#21487;&#21152;&#24615;&#32467;&#26500;&#65292;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#23545;GP&#30340;&#39044;&#27979;&#26041;&#24046;&#36827;&#34892;&#20102;&#22359;&#19979;&#38477;&#31867;&#22411;&#30340;&#36807;&#31243;&#65292;&#20316;&#20026;&#20449;&#24687;&#22686;&#30410;&#30340;&#20195;&#29702;&#12290;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;VDK-GP&#19982;&#20013;&#31561;&#35268;&#27169;500&#20010;&#33410;&#28857;&#21644;&#22823;&#35268;&#27169;1354&#20010;&#33410;&#28857;&#30340;&#23436;&#25972;GP&#30456;&#27604;&#65292;&#23454;&#29616;&#20102;&#36229;&#36807;&#20004;&#20493;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a physics-inspired graph-structured kernel designed for power flow learning using Gaussian Process (GP). The kernel, named the vertex-degree kernel (VDK), relies on latent decomposition of voltage-injection relationship based on the network graph or topology. Notably, VDK design avoids the need to solve optimization problems for kernel search. To enhance efficiency, we also explore a graph-reduction approach to obtain a VDK representation with lesser terms. Additionally, we propose a novel network-swipe active learning scheme, which intelligently selects sequential training inputs to accelerate the learning of VDK. Leveraging the additive structure of VDK, the active learning algorithm performs a block-descent type procedure on GP's predictive variance, serving as a proxy for information gain. Simulations demonstrate that the proposed VDK-GP achieves more than two fold sample complexity reduction, compared to full GP on medium scale 500-Bus and large scale 1354-Bus 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20248;&#21270;&#38382;&#39064;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#12290;&#36890;&#36807;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#19978;&#21319;&#21644;&#25237;&#24433;&#27425;&#26799;&#24230;&#19979;&#38477;&#26356;&#26032;&#21464;&#37327;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20840;&#23616;&#25910;&#25947;&#20013;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#36895;&#29575;&#65292;&#32780;&#19988;&#19981;&#21463;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#22823;&#23567;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2206.02346</link><description>&lt;p&gt;
&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#22312;&#32422;&#26463;MDP&#20013;&#30340;&#25910;&#25947;&#24615;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence and sample complexity of natural policy gradient primal-dual methods for constrained MDPs. (arXiv:2206.02346v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02346
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20248;&#21270;&#38382;&#39064;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#12290;&#36890;&#36807;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#19978;&#21319;&#21644;&#25237;&#24433;&#27425;&#26799;&#24230;&#19979;&#38477;&#26356;&#26032;&#21464;&#37327;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20840;&#23616;&#25910;&#25947;&#20013;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#36895;&#29575;&#65292;&#32780;&#19988;&#19981;&#21463;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#22823;&#23567;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#39044;&#26399;&#24635;&#22870;&#21169;&#65292;&#21516;&#26102;&#28385;&#36275;&#23545;&#39044;&#26399;&#24635;&#25928;&#29992;&#30340;&#32422;&#26463;&#12290;&#25105;&#20204;&#20351;&#29992;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#20915;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;&#32422;&#26463;MDP&#65289;&#30340;&#25240;&#25187;&#26080;&#38480;&#26102;&#24207;&#20248;&#21270;&#25511;&#21046;&#38382;&#39064;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#65288;NPG-PD&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#19978;&#21319;&#26356;&#26032;&#21407;&#22987;&#21464;&#37327;&#65292;&#36890;&#36807;&#25237;&#24433;&#27425;&#26799;&#24230;&#19979;&#38477;&#26356;&#26032;&#23545;&#20598;&#21464;&#37327;&#12290;&#23613;&#31649;&#24213;&#23618;&#26368;&#22823;&#21270;&#28041;&#21450;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#21644;&#38750;&#20984;&#32422;&#26463;&#38598;&#65292;&#20294;&#22312;softmax&#31574;&#30053;&#21442;&#25968;&#21270;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#38388;&#38553;&#21644;&#32422;&#26463;&#36829;&#35268;&#26041;&#38754;&#23454;&#29616;&#20840;&#23616;&#25910;&#25947;&#65292;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#36895;&#29575;&#12290;&#27492;&#31867;&#25910;&#25947;&#19982;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#30340;&#22823;&#23567;&#26080;&#20851;&#65292;&#21363;&#26080;&#32500;&#24230;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#23545;&#25968;&#32447;&#24615;&#21644;&#19968;&#33324;&#24179;&#28369;&#31574;&#30053;&#21442;&#25968;&#21270;&#65292;&#25105;&#20204;&#30830;&#31435;&#20102;&#25910;&#25947;&#24615;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study sequential decision making problems aimed at maximizing the expected total reward while satisfying a constraint on the expected total utility. We employ the natural policy gradient method to solve the discounted infinite-horizon optimal control problem for Constrained Markov Decision Processes (constrained MDPs). Specifically, we propose a new Natural Policy Gradient Primal-Dual (NPG-PD) method that updates the primal variable via natural policy gradient ascent and the dual variable via projected sub-gradient descent. Although the underlying maximization involves a nonconcave objective function and a nonconvex constraint set, under the softmax policy parametrization we prove that our method achieves global convergence with sublinear rates regarding both the optimality gap and the constraint violation. Such convergence is independent of the size of the state-action space, i.e., it is~dimension-free. Furthermore, for log-linear and general smooth policy parametrizations, we esta
&lt;/p&gt;</description></item></channel></rss>