<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36895;&#29575;&#38480;&#21046;&#36890;&#36947;&#19978;&#23454;&#29616;&#27169;&#22411;&#26080;&#20851;&#30340;LQR&#25511;&#21046;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#33258;&#36866;&#24212;&#37327;&#21270;&#26799;&#24230;&#19979;&#38477;&#65288;AQGD&#65289;&#31639;&#27861;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#22312;&#22122;&#22768;&#30005;&#36335;&#20013;&#21487;&#20197;&#23454;&#29616;&#25511;&#21046;&#38382;&#39064;&#30340;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2401.01258</link><description>&lt;p&gt;
&#23454;&#29616;&#27169;&#22411;&#26080;&#20851;&#30340;&#36890;&#36807;&#36895;&#29575;&#38480;&#21046;&#36890;&#36947;&#30340;LQR&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Towards Model-Free LQR Control over Rate-Limited Channels. (arXiv:2401.01258v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01258
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36895;&#29575;&#38480;&#21046;&#36890;&#36947;&#19978;&#23454;&#29616;&#27169;&#22411;&#26080;&#20851;&#30340;LQR&#25511;&#21046;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#33258;&#36866;&#24212;&#37327;&#21270;&#26799;&#24230;&#19979;&#38477;&#65288;AQGD&#65289;&#31639;&#27861;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#22312;&#22122;&#22768;&#30005;&#36335;&#20013;&#21487;&#20197;&#23454;&#29616;&#25511;&#21046;&#38382;&#39064;&#30340;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#27169;&#22411;&#26080;&#20851;&#26041;&#27861;&#22312;&#35768;&#22810;&#38382;&#39064;&#35774;&#32622;&#20013;&#30340;&#25511;&#21046;&#35774;&#35745;&#26041;&#38754;&#21462;&#24471;&#30340;&#25104;&#21151;&#65292;&#33258;&#28982;&#32780;&#28982;&#22320;&#20250;&#38382;&#65292;&#22914;&#26524;&#21033;&#29992;&#23454;&#38469;&#30340;&#36890;&#20449;&#36890;&#36947;&#26469;&#20256;&#36755;&#26799;&#24230;&#25110;&#31574;&#30053;&#65292;&#24773;&#20917;&#20250;&#22914;&#20309;&#25913;&#21464;&#12290;&#23613;&#31649;&#30001;&#27492;&#20135;&#29983;&#30340;&#38382;&#39064;&#19982;&#32593;&#32476;&#25511;&#21046;&#31995;&#32479;&#20013;&#30740;&#31350;&#30340;&#20844;&#24335;&#26377;&#31867;&#20284;&#20043;&#22788;&#65292;&#20294;&#37027;&#20010;&#39046;&#22495;&#30340;&#20016;&#23500;&#25991;&#29486;&#36890;&#24120;&#20551;&#23450;&#31995;&#32479;&#30340;&#27169;&#22411;&#26159;&#24050;&#30693;&#30340;&#12290;&#20026;&#20102;&#22312;&#27169;&#22411;&#26080;&#20851;&#25511;&#21046;&#35774;&#35745;&#21644;&#32593;&#32476;&#25511;&#21046;&#31995;&#32479;&#39046;&#22495;&#20043;&#38388;&#24314;&#31435;&#32852;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;\textit{&#26159;&#21542;&#21487;&#20197;&#36890;&#36807;&#36895;&#29575;&#38480;&#21046;&#30340;&#36890;&#36947;&#20197;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#24335;&#35299;&#20915;&#22522;&#26412;&#30340;&#25511;&#21046;&#38382;&#39064;-&#20363;&#22914;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#65288;LQR&#65289;&#38382;&#39064;&#65311;}&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#35774;&#32622;&#65292;&#20854;&#20013;&#19968;&#20010;&#24037;&#20316;&#20195;&#29702;&#36890;&#36807;&#19968;&#20010;&#26080;&#22122;&#22768;&#20449;&#36947;&#20197;&#26377;&#38480;&#30340;&#20301;&#36895;&#29575;&#20256;&#36755;&#37327;&#21270;&#31574;&#30053;&#26799;&#24230;&#65288;LQR&#25104;&#26412;&#65289;&#21040;&#19968;&#20010;&#26381;&#21153;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#36866;&#24212;&#37327;&#21270;&#26799;&#24230;&#19979;&#38477;&#65288;AQGD&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
Given the success of model-free methods for control design in many problem settings, it is natural to ask how things will change if realistic communication channels are utilized for the transmission of gradients or policies. While the resulting problem has analogies with the formulations studied under the rubric of networked control systems, the rich literature in that area has typically assumed that the model of the system is known. As a step towards bridging the fields of model-free control design and networked control systems, we ask: \textit{Is it possible to solve basic control problems - such as the linear quadratic regulator (LQR) problem - in a model-free manner over a rate-limited channel?} Toward answering this question, we study a setting where a worker agent transmits quantized policy gradients (of the LQR cost) to a server over a noiseless channel with a finite bit-rate. We propose a new algorithm titled Adaptively Quantized Gradient Descent (\texttt{AQGD}), and prove that
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#23545;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#23614;&#24179;&#22343;TD&#33021;&#20197;&#26368;&#20248;&#36895;&#29575; $O(1/t)$ &#25910;&#25947;&#65292;&#24182;&#19988;&#21021;&#22987;&#35823;&#24046;&#34928;&#20943;&#36895;&#29575;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#24456;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2210.05918</link><description>&lt;p&gt;
&#26377;&#38480;&#26102;&#38388;&#20869;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;&#30340;&#20998;&#26512;&#65306;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation. (arXiv:2210.05918v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#23545;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#23614;&#24179;&#22343;TD&#33021;&#20197;&#26368;&#20248;&#36895;&#29575; $O(1/t)$ &#25910;&#25947;&#65292;&#24182;&#19988;&#21021;&#22987;&#35823;&#24046;&#34928;&#20943;&#36895;&#29575;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#24456;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#27969;&#34892;&#30340;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#19982;&#23614;&#24179;&#22343;&#30456;&#32467;&#21512;&#26102;&#30340;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#12290;&#25105;&#20204;&#22312;&#19981;&#38656;&#35201;&#20851;&#20110;&#24213;&#23618;&#25237;&#24433;TD&#19981;&#21160;&#28857;&#30697;&#38453;&#30340;&#29305;&#24449;&#20540;&#20449;&#24687;&#30340;&#27493;&#38271;&#36873;&#25321;&#19979;&#65292;&#25512;&#23548;&#20102;&#23614;&#24179;&#22343;TD&#36845;&#20195;&#30340;&#21442;&#25968;&#35823;&#24046;&#30340;&#26377;&#38480;&#26102;&#38388;&#30028;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#23614;&#24179;&#22343;TD&#20197;&#26399;&#26395;&#36895;&#29575;&#21644;&#39640;&#27010;&#29575;&#25910;&#25947;&#20110;&#26368;&#20248;&#30340; $O(1/t)$ &#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#23637;&#31034;&#20102;&#21021;&#22987;&#35823;&#24046;(&#20559;&#24046;)&#30340;&#26356;&#24555;&#34928;&#20943;&#36895;&#29575;&#65292;&#36825;&#26159;&#23545;&#25152;&#26377;&#36845;&#20195;&#30340;&#24179;&#22343;&#20540;&#30340;&#25913;&#36827;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#32467;&#21512;&#27491;&#21017;&#21270;&#30340;TD&#21464;&#20307;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#35748;&#20026;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#26159;&#26377;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal $O\left(1/t\right)$ rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation. From analysis, we conclude that the regularised version of TD is useful for problems with ill-conditioned features.
&lt;/p&gt;</description></item></channel></rss>