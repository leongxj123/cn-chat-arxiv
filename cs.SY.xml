<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#21464;&#21387;&#22120;&#32593;&#32476;&#30340; QST &#26041;&#27861;&#65292;&#21487;&#25429;&#25417;&#19981;&#21516;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#26816;&#32034;&#37327;&#23376;&#24577;&#30340;&#23494;&#24230;&#30697;&#38453;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21463;&#38480;&#27979;&#37327;&#25968;&#25454;&#30340;&#24773;&#20917;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.05433</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21464;&#21387;&#22120;&#32593;&#32476;&#29992;&#20110;&#37327;&#23376;&#24577;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Attention-Based Transformer Networks for Quantum State Tomography. (arXiv:2305.05433v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05433
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#21464;&#21387;&#22120;&#32593;&#32476;&#30340; QST &#26041;&#27861;&#65292;&#21487;&#25429;&#25417;&#19981;&#21516;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#26816;&#32034;&#37327;&#23376;&#24577;&#30340;&#23494;&#24230;&#30697;&#38453;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21463;&#38480;&#27979;&#37327;&#25968;&#25454;&#30340;&#24773;&#20917;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#33391;&#22909;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#31070;&#32463;&#32593;&#32476;&#19968;&#30452;&#34987;&#29992;&#20110;&#37327;&#23376;&#24577;&#37325;&#26500;&#65288;QST&#65289;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25552;&#39640;&#37325;&#26500;&#37327;&#23376;&#24577;&#30340;&#25928;&#29575;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#35821;&#35328;&#24314;&#27169;&#19982;&#37327;&#23376;&#24577;&#37325;&#26500;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#21464;&#21387;&#22120;&#32593;&#32476;&#30340; QST &#26041;&#27861;&#65292;&#29992;&#20110;&#25429;&#25417;&#19981;&#21516;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30452;&#25509;&#20174;&#27979;&#37327;&#32479;&#35745;&#25968;&#25454;&#20013;&#26816;&#32034;&#37327;&#23376;&#24577;&#30340;&#23494;&#24230;&#30697;&#38453;&#65292;&#24182;&#36741;&#21161;&#20351;&#29992;&#32508;&#21512;&#25439;&#22833;&#20989;&#25968;&#26469;&#24110;&#21161;&#26368;&#23567;&#21270;&#23454;&#38469;&#24577;&#19982;&#26816;&#32034;&#24577;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#36319;&#36394;&#20102;&#28041;&#21450;&#21508;&#31181;&#21442;&#25968;&#35843;&#25972;&#30340;&#24120;&#35265;&#35757;&#32451;&#31574;&#30053;&#23545;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340; QST &#26041;&#27861;&#30340;&#19981;&#21516;&#24433;&#21709;&#12290;&#32467;&#21512;&#36825;&#20123;&#25216;&#26415;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#31283;&#20581;&#30340;&#22522;&#20934;&#32447;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#37325;&#26500;&#32431;&#24577;&#21644;&#28151;&#21512;&#24577;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#27604;&#36739;&#19977;&#31181;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26041;&#27861;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21463;&#38480;&#27979;&#37327;&#25968;&#25454;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have been actively explored for quantum state tomography (QST) due to their favorable expressibility. To further enhance the efficiency of reconstructing quantum states, we explore the similarity between language modeling and quantum state tomography and propose an attention-based QST method that utilizes the Transformer network to capture the correlations between measured results from different measurements. Our method directly retrieves the density matrices of quantum states from measured statistics, with the assistance of an integrated loss function that helps minimize the difference between the actual states and the retrieved states. Then, we systematically trace different impacts within a bag of common training strategies involving various parameter adjustments on the attention-based QST method. Combining these techniques, we establish a robust baseline that can efficiently reconstruct pure and mixed quantum states. Furthermore, by comparing the performance of thre
&lt;/p&gt;</description></item></channel></rss>