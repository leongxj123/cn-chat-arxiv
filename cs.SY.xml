<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#23558;&#23398;&#20064;&#31639;&#27861;&#21644;&#21551;&#21457;&#24335;&#24341;&#23548;&#24212;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#30340;&#39564;&#35777;&#65292;&#26088;&#22312;&#25552;&#39640;&#24615;&#33021;&#65292;&#36991;&#20813;&#23545;&#29366;&#24577;&#31354;&#38388;&#36827;&#34892;&#31351;&#23613;&#25506;&#32034;&#12290;</title><link>https://arxiv.org/abs/2403.09184</link><description>&lt;p&gt;
&#23398;&#20064;&#31639;&#27861;&#29992;&#20110;&#39564;&#35777;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning Algorithms for Verification of Markov Decision Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09184
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#23558;&#23398;&#20064;&#31639;&#27861;&#21644;&#21551;&#21457;&#24335;&#24341;&#23548;&#24212;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#30340;&#39564;&#35777;&#65292;&#26088;&#22312;&#25552;&#39640;&#24615;&#33021;&#65292;&#36991;&#20813;&#23545;&#29366;&#24577;&#31354;&#38388;&#36827;&#34892;&#31351;&#23613;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#23558;&#23398;&#20064;&#31639;&#27861;&#21644;&#21551;&#21457;&#24335;&#24341;&#23548;&#24212;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#30340;&#39564;&#35777;&#65292;&#22522;&#20110;Br\'azdil, T.&#31561;&#20154;&#65288;2014&#65289;&#30340;&#24819;&#27861;&#12290;&#35813;&#26694;&#26550;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#36890;&#36807;&#36991;&#20813;&#23545;&#29366;&#24577;&#31354;&#38388;&#36827;&#34892;&#31351;&#23613;&#25506;&#32034;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#32780;&#26159;&#20381;&#38752;&#21551;&#21457;&#24335;&#12290;&#26412;&#30740;&#31350;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#25193;&#23637;&#20102;&#36825;&#31181;&#26041;&#27861;&#12290;&#23545;&#22522;&#30784;&#29702;&#35770;&#30340;&#20960;&#20010;&#32454;&#33410;&#36827;&#34892;&#20102;&#25913;&#36827;&#21644;&#38169;&#35823;&#20462;&#27491;&#12290;&#31532;1.3&#33410;&#25552;&#20379;&#20102;&#25152;&#26377;&#24046;&#24322;&#30340;&#27010;&#36848;&#12290;&#35813;&#26694;&#26550;&#19987;&#27880;&#20110;&#27010;&#29575;&#21487;&#36798;&#24615;&#65292;&#36825;&#26159;&#39564;&#35777;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#65292;&#24182;&#20855;&#20307;&#21270;&#20026;&#20004;&#31181;&#19981;&#21516;&#30340;&#22330;&#26223;&#12290;&#31532;&#19968;&#20010;&#20551;&#35774;&#23436;&#20840;&#20102;&#35299;MDP&#65292;&#23588;&#20854;&#26159;&#31934;&#30830;&#30340;&#36716;&#31227;&#27010;&#29575;&#12290;&#23427;&#25191;&#34892;&#22522;&#20110;&#21551;&#21457;&#24335;&#30340;&#27169;&#22411;&#37096;&#20998;&#25506;&#32034;&#65292;&#20135;&#29983;&#31934;&#20934;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09184v1 Announce Type: cross  Abstract: We present a general framework for applying learning algorithms and heuristical guidance to the verification of Markov decision processes (MDPs), based on the ideas of Br\'azdil, T. et al. (2014). Verification of Markov Decision Processes Using Learning Algorithms. The primary goal of the techniques presented in that work is to improve performance by avoiding an exhaustive exploration of the state space, guided by heuristics. This approach is significantly extended in this work. Several details of the base theory are refined and errors are fixed. Section 1.3 provides an overview of all differences.   The presented framework focuses on probabilistic reachability, which is a core problem in verification, and is instantiated in two distinct scenarios. The first assumes that full knowledge of the MDP is available, in particular precise transition probabilities. It performs a heuristic-driven partial exploration of the model, yielding preci
&lt;/p&gt;</description></item></channel></rss>