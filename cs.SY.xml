<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PA-RL&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29109;&#29575;&#26469;&#24341;&#23548;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#23454;&#29616;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#20540;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2311.18703</link><description>&lt;p&gt;
&#36890;&#36807;&#29109;&#29575;&#26368;&#23567;&#21270;&#23454;&#29616;&#21487;&#39044;&#27979;&#30340;&#24378;&#21270;&#23398;&#20064;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.18703
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PA-RL&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29109;&#29575;&#26469;&#24341;&#23548;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#23454;&#29616;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#26234;&#33021;&#20307;&#27809;&#26377;&#21160;&#26426;&#23637;&#31034;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#65292;&#36890;&#24120;&#36890;&#36807;&#31574;&#30053;&#29109;&#27491;&#21017;&#21270;&#25512;&#21160;&#26234;&#33021;&#20307;&#22312;&#25506;&#32034;&#19978;&#38543;&#26426;&#21270;&#20854;&#34892;&#20026;&#12290;&#20174;&#20154;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#20351;&#24471;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#24456;&#38590;&#35299;&#37322;&#21644;&#39044;&#27979;&#65307;&#20174;&#23433;&#20840;&#35282;&#24230;&#26469;&#30475;&#65292;&#26356;&#38590;&#20197;&#36827;&#34892;&#24418;&#24335;&#21270;&#39564;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#21487;&#39044;&#27979;&#24615;&#24863;&#30693;&#24378;&#21270;&#23398;&#20064;&#65288;PA-RL&#65289;&#65292;&#29992;&#20110;&#24341;&#23548;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#65292;&#20854;&#21033;&#29992;&#29366;&#24577;&#24207;&#21015;&#29109;&#29575;&#20316;&#20026;&#21487;&#39044;&#27979;&#24615;&#24230;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29109;&#29575;&#21046;&#23450;&#20026;&#24179;&#22343;&#22870;&#21169;&#30446;&#26631;&#65292;&#24182;&#19988;&#30001;&#20110;&#20854;&#29109;&#22870;&#21169;&#20989;&#25968;&#20381;&#36182;&#20110;&#31574;&#30053;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21160;&#20316;&#30456;&#20851;&#30340;&#26367;&#20195;&#29109;&#65292;&#20197;&#21033;&#29992;PG&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26368;&#23567;&#21270;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#30340;&#30830;&#23450;&#24615;&#31574;&#30053;&#23384;&#22312;&#65292;&#24182;&#19988;&#26368;&#23567;&#21270;&#20102;&#23454;&#38469;&#29109;&#29575;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#23398;&#20064;&#21040;&#30340;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#19982;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Reinforcement Learning (RL), agents have no incentive to exhibit predictable behaviors, and are often pushed (through e.g. policy entropy regularization) to randomize their actions in favor of exploration. From a human perspective, this makes RL agents hard to interpret and predict, and from a safety perspective, even harder to formally verify. We propose a novel method to induce predictable behavior in RL agents, referred to as Predictability-Aware RL (PA-RL), which employs the state sequence entropy rate as a predictability measure. We show how the entropy rate can be formulated as an average reward objective, and since its entropy reward function is policy-dependent, we introduce an action-dependent surrogate entropy enabling the use of PG methods. We prove that deterministic policies minimizing the average surrogate reward exist and also minimize the actual entropy rate, and show how, given a learned dynamical model, we are able to approximate the value function associated to th
&lt;/p&gt;</description></item></channel></rss>