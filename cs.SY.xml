<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#20449;&#21495;&#26102;&#24207;&#36923;&#36753;&#65288;STL&#65289;&#25512;&#26029;&#21644;&#25511;&#21046;&#21512;&#25104;&#30340;&#26032;&#39062;&#20223;&#30495;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26126;&#30830;&#34920;&#31034;&#20219;&#21153;&#20026;STL&#20844;&#24335;&#65292;&#21516;&#26102;&#36890;&#36807;&#20154;&#20026;&#35843;&#25972;STL&#20844;&#24335;&#23454;&#29616;&#23545;&#20154;&#31867;&#30693;&#35782;&#30340;&#32435;&#20837;&#21644;&#26032;&#22330;&#26223;&#30340;&#36866;&#24212;&#65292;&#36824;&#37319;&#29992;&#20102;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#21551;&#21457;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#26377;&#25928;&#32553;&#23567;&#20102;&#19987;&#23478;&#31574;&#30053;&#21644;&#23398;&#20064;&#31574;&#30053;&#20043;&#38388;&#30340;&#24046;&#36317;</title><link>https://arxiv.org/abs/2402.10310</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#20223;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Interpretable Generative Adversarial Imitation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10310
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#20449;&#21495;&#26102;&#24207;&#36923;&#36753;&#65288;STL&#65289;&#25512;&#26029;&#21644;&#25511;&#21046;&#21512;&#25104;&#30340;&#26032;&#39062;&#20223;&#30495;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26126;&#30830;&#34920;&#31034;&#20219;&#21153;&#20026;STL&#20844;&#24335;&#65292;&#21516;&#26102;&#36890;&#36807;&#20154;&#20026;&#35843;&#25972;STL&#20844;&#24335;&#23454;&#29616;&#23545;&#20154;&#31867;&#30693;&#35782;&#30340;&#32435;&#20837;&#21644;&#26032;&#22330;&#26223;&#30340;&#36866;&#24212;&#65292;&#36824;&#37319;&#29992;&#20102;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#21551;&#21457;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#26377;&#25928;&#32553;&#23567;&#20102;&#19987;&#23478;&#31574;&#30053;&#21644;&#23398;&#20064;&#31574;&#30053;&#20043;&#38388;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20223;&#30495;&#23398;&#20064;&#26041;&#27861;&#24050;&#32463;&#36890;&#36807;&#19987;&#23478;&#28436;&#31034;&#22312;&#25945;&#25480;&#33258;&#20027;&#31995;&#32479;&#22797;&#26434;&#20219;&#21153;&#26041;&#38754;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#22312;&#20110;&#23427;&#20204;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#29702;&#35299;&#23398;&#20064;&#20195;&#29702;&#35797;&#22270;&#23436;&#25104;&#30340;&#20855;&#20307;&#20219;&#21153;&#26041;&#38754;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#20449;&#21495;&#26102;&#24207;&#36923;&#36753;&#65288;STL&#65289;&#25512;&#26029;&#21644;&#25511;&#21046;&#21512;&#25104;&#30340;&#26032;&#39062;&#20223;&#30495;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#20219;&#21153;&#21487;&#20197;&#26126;&#30830;&#34920;&#31034;&#20026;STL&#20844;&#24335;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#28165;&#26224;&#22320;&#29702;&#35299;&#20219;&#21153;&#65292;&#36824;&#21487;&#20197;&#36890;&#36807;&#25163;&#21160;&#35843;&#25972;STL&#20844;&#24335;&#26469;&#23558;&#20154;&#31867;&#30693;&#35782;&#32435;&#20837;&#24182;&#36866;&#24212;&#26032;&#22330;&#26223;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21463;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#21551;&#21457;&#30340;&#35757;&#32451;&#26041;&#27861;&#36827;&#34892;&#25512;&#26029;&#21644;&#25511;&#21046;&#31574;&#30053;&#65292;&#26377;&#25928;&#22320;&#32553;&#23567;&#20102;&#19987;&#23478;&#31574;&#30053;&#21644;&#23398;&#20064;&#31574;&#30053;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10310v1 Announce Type: new  Abstract: Imitation learning methods have demonstrated considerable success in teaching autonomous systems complex tasks through expert demonstrations. However, a limitation of these methods is their lack of interpretability, particularly in understanding the specific task the learning agent aims to accomplish. In this paper, we propose a novel imitation learning method that combines Signal Temporal Logic (STL) inference and control synthesis, enabling the explicit representation of the task as an STL formula. This approach not only provides a clear understanding of the task but also allows for the incorporation of human knowledge and adaptation to new scenarios through manual adjustments of the STL formulae. Additionally, we employ a Generative Adversarial Network (GAN)-inspired training approach for both the inference and the control policy, effectively narrowing the gap between the expert and learned policies. The effectiveness of our algorithm
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25511;&#21046;&#22120;&#36716;&#25442;&#20026;&#31561;&#25928;&#36719;&#20915;&#31574;&#26641;&#25511;&#21046;&#22120;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#19988;&#33410;&#32422;&#25104;&#26412;&#30340;&#36716;&#25442;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21253;&#25324;ReLU&#28608;&#27963;&#20989;&#25968;&#22312;&#20869;&#30340;&#31163;&#25955;&#36755;&#20986;NN&#25511;&#21046;&#22120;&#65292;&#24182;&#33021;&#22815;&#25552;&#39640;&#24418;&#24335;&#39564;&#35777;&#30340;&#36816;&#34892;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.06049</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#22120;&#21040;&#20915;&#31574;&#26641;&#25511;&#21046;&#22120;&#30340;&#31934;&#30830;&#19988;&#33410;&#32422;&#25104;&#26412;&#30340;&#33258;&#21160;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
Exact and Cost-Effective Automated Transformation of Neural Network Controllers to Decision Tree Controllers. (arXiv:2304.06049v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25511;&#21046;&#22120;&#36716;&#25442;&#20026;&#31561;&#25928;&#36719;&#20915;&#31574;&#26641;&#25511;&#21046;&#22120;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#19988;&#33410;&#32422;&#25104;&#26412;&#30340;&#36716;&#25442;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21253;&#25324;ReLU&#28608;&#27963;&#20989;&#25968;&#22312;&#20869;&#30340;&#31163;&#25955;&#36755;&#20986;NN&#25511;&#21046;&#22120;&#65292;&#24182;&#33021;&#22815;&#25552;&#39640;&#24418;&#24335;&#39564;&#35777;&#30340;&#36816;&#34892;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#30340;&#25511;&#21046;&#22120;&#22312;&#21508;&#31181;&#20915;&#31574;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#30528;&#30340;&#21151;&#25928;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#40657;&#30418;&#29305;&#24615;&#21644;&#24847;&#22806;&#34892;&#20026;&#21644;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#30340;&#39118;&#38505;&#23545;&#20110;&#22312;&#20855;&#26377;&#27491;&#30830;&#24615;&#21644;&#23433;&#20840;&#24615;&#24378;&#20445;&#35777;&#30340;&#30495;&#23454;&#19990;&#30028;&#31995;&#32479;&#20013;&#30340;&#37096;&#32626;&#26500;&#25104;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#35843;&#26597;&#23558;&#22522;&#20110;NN&#30340;&#25511;&#21046;&#22120;&#36716;&#25442;&#20026;&#31561;&#25928;&#30340;&#36719;&#20915;&#31574;&#26641;&#65288;SDT&#65289;&#25511;&#21046;&#22120;&#21450;&#20854;&#23545;&#21487;&#39564;&#35777;&#24615;&#30340;&#24433;&#21709;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#12290;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#31163;&#25955;&#36755;&#20986;NN&#25511;&#21046;&#22120;&#65292;&#21253;&#25324;&#25972;&#27969;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#28608;&#27963;&#20989;&#25968;&#20197;&#21450;argmax&#25805;&#20316;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#31934;&#30830;&#20294;&#33410;&#30465;&#25104;&#26412;&#30340;&#36716;&#25442;&#31639;&#27861;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#33258;&#21160;&#21024;&#38500;&#22810;&#20313;&#30340;&#20998;&#25903;&#12290;&#25105;&#20204;&#20351;&#29992;OpenAI Gym&#29615;&#22659;&#30340;&#20004;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;SDT&#36716;&#25442;&#21487;&#20197;&#20351;&#24418;&#24335;&#39564;&#35777;&#21463;&#30410;&#65292;&#26174;&#31034;&#36816;&#34892;&#26102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past decade, neural network (NN)-based controllers have demonstrated remarkable efficacy in a variety of decision-making tasks. However, their black-box nature and the risk of unexpected behaviors and surprising results pose a challenge to their deployment in real-world systems with strong guarantees of correctness and safety. We address these limitations by investigating the transformation of NN-based controllers into equivalent soft decision tree (SDT)-based controllers and its impact on verifiability. Differently from previous approaches, we focus on discrete-output NN controllers including rectified linear unit (ReLU) activation functions as well as argmax operations. We then devise an exact but cost-effective transformation algorithm, in that it can automatically prune redundant branches. We evaluate our approach using two benchmarks from the OpenAI Gym environment. Our results indicate that the SDT transformation can benefit formal verification, showing runtime improveme
&lt;/p&gt;</description></item></channel></rss>