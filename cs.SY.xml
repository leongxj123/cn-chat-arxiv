<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36755;&#20837;&#20984;LSTM&#30340;&#22522;&#20110;Lyapunov&#30340;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#25910;&#25947;&#26102;&#38388;&#21644;&#32531;&#35299;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#26469;&#25913;&#21892;MPC&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.07202</link><description>&lt;p&gt;
&#36755;&#20837;&#20984;LSTM&#65306;&#19968;&#31181;&#24555;&#36895;&#22522;&#20110;Lyapunov&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#30340;&#20984;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control. (arXiv:2311.07202v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.07202
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36755;&#20837;&#20984;LSTM&#30340;&#22522;&#20110;Lyapunov&#30340;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#25910;&#25947;&#26102;&#38388;&#21644;&#32531;&#35299;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#26469;&#25913;&#21892;MPC&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#65288;ICNN&#65289;&#65292;&#22522;&#20110;ICNN&#30340;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#65288;MPC&#65289;&#36890;&#36807;&#22312;MPC&#26694;&#26550;&#20013;&#20445;&#25345;&#20984;&#24615;&#25104;&#21151;&#23454;&#29616;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;ICNN&#26550;&#26500;&#23384;&#22312;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#20316;&#20026;&#22797;&#26434;&#20219;&#21153;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;MPC&#65292;&#21253;&#25324;&#20256;&#32479;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;MPC&#21644;&#22522;&#20110;ICNN&#30340;MPC&#65292;&#19982;&#22522;&#20110;&#31532;&#19968;&#21407;&#29702;&#27169;&#22411;&#30340;MPC&#30456;&#27604;&#38754;&#20020;&#36739;&#24930;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;ICNN&#30340;&#21407;&#29702;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36755;&#20837;&#20984;LSTM&#30340;&#22522;&#20110;Lyapunov&#30340;MPC&#65292;&#26088;&#22312;&#20943;&#23569;&#25910;&#25947;&#26102;&#38388;&#12289;&#32531;&#35299;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#24182;&#30830;&#20445;&#38381;&#29615;&#31283;&#23450;&#24615;&#12290;&#36890;&#36807;&#23545;&#38750;&#32447;&#24615;&#21270;&#23398;&#21453;&#24212;&#22120;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#30340;&#32531;&#35299;&#21644;&#25910;&#25947;&#26102;&#38388;&#30340;&#20943;&#23569;&#65292;&#25910;&#25947;&#26102;&#38388;&#24179;&#22343;&#38477;&#20302;&#20102;&#19968;&#23450;&#30340;&#30334;&#20998;&#20043;&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive Control (MPC) successfully attains globally optimal solutions by upholding convexity within the MPC framework. However, current ICNN architectures encounter the issue of vanishing/exploding gradients, which limits their ability to serve as deep neural networks for complex tasks. Additionally, the current neural network-based MPC, including conventional neural network-based MPC and ICNN-based MPC, faces slower convergence speed when compared to MPC based on first-principles models. In this study, we leverage the principles of ICNNs to propose a novel Input Convex LSTM for Lyapunov-based MPC, with the specific goal of reducing convergence time and mitigating the vanishing/exploding gradient problem while ensuring closed-loop stability. From a simulation study of a nonlinear chemical reactor, we observed a mitigation of vanishing/exploding gradient problem and a reduction in convergence time, with a percentage de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#36830;&#32493;&#26102;&#38388;&#19979;&#35266;&#27979;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;Kalman&#28388;&#27874;&#22120;&#30340;&#31995;&#32479;&#35782;&#21035;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#36830;&#32493;&#26102;&#38388;Ito&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#25512;&#24191;Kalman&#28388;&#27874;&#22120;&#30340;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#28388;&#27874;&#22120;&#30340;&#21518;&#39564;&#35745;&#31639;&#26041;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#27966;&#29983;&#33719;&#24471;&#30340;&#35299;&#26512;&#24418;&#24335;&#30340;&#21518;&#39564;&#35745;&#31639;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#20272;&#35745;SDE&#30340;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2308.11933</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31995;&#32479;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
System Identification for Continuous-time Linear Dynamical Systems. (arXiv:2308.11933v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#36830;&#32493;&#26102;&#38388;&#19979;&#35266;&#27979;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;Kalman&#28388;&#27874;&#22120;&#30340;&#31995;&#32479;&#35782;&#21035;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#36830;&#32493;&#26102;&#38388;Ito&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#25512;&#24191;Kalman&#28388;&#27874;&#22120;&#30340;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#28388;&#27874;&#22120;&#30340;&#21518;&#39564;&#35745;&#31639;&#26041;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#27966;&#29983;&#33719;&#24471;&#30340;&#35299;&#26512;&#24418;&#24335;&#30340;&#21518;&#39564;&#35745;&#31639;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#20272;&#35745;SDE&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kalman&#28388;&#27874;&#22120;&#30340;&#31995;&#32479;&#35782;&#21035;&#38382;&#39064;&#22312;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#30340;&#22522;&#30784;&#21442;&#25968;&#26102;&#65292;&#36890;&#24120;&#20551;&#35774;&#35266;&#27979;&#20540;&#22312;&#31561;&#38388;&#38548;&#30340;&#26102;&#38388;&#28857;&#37319;&#26679;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#36825;&#20010;&#20551;&#35774;&#26159;&#26377;&#38480;&#21046;&#21644;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#26412;&#25991;&#38024;&#23545;&#36830;&#32493;&#31163;&#25955;&#28388;&#27874;&#22120;&#30340;&#31995;&#32479;&#35782;&#21035;&#38382;&#39064;&#65292;&#36890;&#36807;&#27714;&#35299;&#36830;&#32493;&#26102;&#38388;Ito&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#26469;&#25512;&#24191;Kalman&#28388;&#27874;&#22120;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#28388;&#27874;&#22120;&#65292;&#20855;&#26377;&#36125;&#21494;&#26031;&#27966;&#29983;&#30340;&#35299;&#26512;&#24418;&#24335;&#30340;&#21518;&#39564;&#65292;&#36825;&#26679;&#21487;&#20197;&#24471;&#21040;&#19981;&#38656;&#35201;&#39044;&#20808;&#35745;&#31639;&#30340;&#27491;&#21521;&#20256;&#36882;&#30340;&#35299;&#26512;&#26356;&#26032;&#12290;&#21033;&#29992;&#36825;&#31181;&#35299;&#26512;&#30340;&#39640;&#25928;&#35745;&#31639;&#21518;&#39564;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;EM&#36807;&#31243;&#65292;&#29992;&#20110;&#20272;&#35745;SDE&#30340;&#21442;&#25968;&#65292;&#33258;&#28982;&#22320;&#32435;&#20837;&#20102;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of system identification for the Kalman filter, relying on the expectation-maximization (EM) procedure to learn the underlying parameters of a dynamical system, has largely been studied assuming that observations are sampled at equally-spaced time points. However, in many applications this is a restrictive and unrealistic assumption. This paper addresses system identification for the continuous-discrete filter, with the aim of generalizing learning for the Kalman filter by relying on a solution to a continuous-time It\^o stochastic differential equation (SDE) for the latent state and covariance dynamics. We introduce a novel two-filter, analytical form for the posterior with a Bayesian derivation, which yields analytical updates which do not require the forward-pass to be pre-computed. Using this analytical and efficient computation of the posterior, we provide an EM procedure which estimates the parameters of the SDE, naturally incorporating irregularly sampled measurement
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#31995;&#32479;&#21306;&#38388;&#21487;&#36798;&#24615;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21253;&#21547;&#20989;&#25968;&#21644;&#26500;&#24314;&#23884;&#20837;&#31995;&#32479;&#26469;&#25429;&#25417;&#31995;&#32479;&#21644;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#22120;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.14938</link><description>&lt;p&gt;
&#39640;&#25928;&#20114;&#21160;&#24863;&#30693;&#31070;&#32463;&#32593;&#32476;&#21453;&#39304;&#29615;&#30340;&#21306;&#38388;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops. (arXiv:2307.14938v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#31995;&#32479;&#21306;&#38388;&#21487;&#36798;&#24615;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21253;&#21547;&#20989;&#25968;&#21644;&#26500;&#24314;&#23884;&#20837;&#31995;&#32479;&#26469;&#25429;&#25417;&#31995;&#32479;&#21644;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#22120;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#31995;&#32479;&#21306;&#38388;&#21487;&#36798;&#24615;&#20998;&#26512;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#22120;&#21644;&#24320;&#29615;&#31995;&#32479;&#30340;&#21253;&#21547;&#20989;&#25968;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#22120;&#21487;&#20197;&#20026;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#21253;&#21547;&#20989;&#25968;&#12290;&#25105;&#20204;&#20171;&#32461;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#38597;&#21487;&#27604;&#36793;&#30028;&#30340;&#24320;&#29615;&#21160;&#21147;&#23398;&#21253;&#21547;&#20989;&#25968;&#30340;&#26032;&#31867;&#21035;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#25429;&#25417;&#31995;&#32479;&#21644;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#22120;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#25509;&#19979;&#26469;&#65292;&#23545;&#20110;&#20219;&#24847;&#21160;&#21147;&#31995;&#32479;&#65292;&#25105;&#20204;&#20351;&#29992;&#21253;&#21547;&#20989;&#25968;&#26500;&#24314;&#19968;&#20010;&#29366;&#24577;&#25968;&#26159;&#21407;&#31995;&#32479;&#20004;&#20493;&#30340;&#23884;&#20837;&#31995;&#32479;&#12290;&#25105;&#20204;&#35777;&#26126;&#23884;&#20837;&#31995;&#32479;&#30340;&#21333;&#20010;&#36712;&#36857;&#21487;&#20197;&#25552;&#20379;&#21487;&#36798;&#38598;&#30340;&#36229;&#30697;&#24418;&#36817;&#20284;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#21160;&#21147;&#31995;&#32479;&#30340;&#38381;&#29615;&#23884;&#20837;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#32771;&#34385;&#31995;&#32479;&#20043;&#38388;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a computationally efficient framework for interval reachability of neural network controlled systems. Our approach builds upon inclusion functions for the neural network controller and the open-loop system. We observe that many state-of-the-art neural network verifiers can produce inclusion functions for neural networks. We introduce and analyze a new class of inclusion functions for the open-loop dynamics based on bounds of the function Jacobian that is particularly suitable for capturing the interactions between systems and neural network controllers. Next, for any dynamical system, we use inclusion functions to construct an embedding system with twice the number of states as the original system. We show that a single trajectory of this embedding system provides hyper-rectangular over-approximations of reachable sets. We then propose two approaches for constructing a closed-loop embedding system for a neural network controlled dynamical system that accounts 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#27431;&#20960;&#37324;&#24503;&#26053;&#34892;&#21830;&#38382;&#39064;&#30340;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#35299;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#32500;&#32553;&#25918;&#23558;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#30340;&#28857;&#36817;&#20284;&#21040;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#29983;&#25104;&#20102;&#21021;&#22987;&#21270;&#31639;&#27861;&#30340;&#20984;&#21253;&#12290;&#22312;&#35780;&#20272;&#20013;&#21457;&#29616;&#65292;&#35813;&#31639;&#27861;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20248;&#20110;&#26368;&#37051;&#36817;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.06582</link><description>&lt;p&gt;
&#38750;&#27431;&#20960;&#37324;&#24503;&#26053;&#34892;&#21830;&#38382;&#39064;&#30340;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#35299;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Convex Hull Cheapest Insertion Heuristic for the Non-Euclidean TSP. (arXiv:2302.06582v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#27431;&#20960;&#37324;&#24503;&#26053;&#34892;&#21830;&#38382;&#39064;&#30340;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#35299;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#32500;&#32553;&#25918;&#23558;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#30340;&#28857;&#36817;&#20284;&#21040;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#29983;&#25104;&#20102;&#21021;&#22987;&#21270;&#31639;&#27861;&#30340;&#20984;&#21253;&#12290;&#22312;&#35780;&#20272;&#20013;&#21457;&#29616;&#65292;&#35813;&#31639;&#27861;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20248;&#20110;&#26368;&#37051;&#36817;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#31639;&#27861;&#21487;&#20197;&#22312;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20135;&#29983;&#33391;&#22909;&#30340;&#26053;&#34892;&#21830;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#36824;&#26410;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#24773;&#20917;&#19979;&#36827;&#34892;&#25193;&#23637;&#12290;&#20026;&#20102;&#35299;&#20915;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#22788;&#29702;&#38556;&#30861;&#29289;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#30340;&#25913;&#36827;&#26041;&#27861;&#20351;&#29992;&#22810;&#32500;&#32553;&#25918;&#23558;&#36825;&#20123;&#28857;&#39318;&#20808;&#36817;&#20284;&#21040;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#20174;&#32780;&#21487;&#20197;&#29983;&#25104;&#21021;&#22987;&#21270;&#31639;&#27861;&#30340;&#20984;&#21253;&#12290;&#36890;&#36807;&#20462;&#25913;TSPLIB&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#21521;&#20854;&#20013;&#28155;&#21152;&#19981;&#21487;&#36890;&#36807;&#30340;&#20998;&#21106;&#22120;&#26469;&#20135;&#29983;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;&#22312;&#25152;&#30740;&#31350;&#30340;&#26696;&#20363;&#20013;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20986;&#20248;&#20110;&#24120;&#29992;&#30340;&#26368;&#37051;&#36817;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;96%&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convex hull cheapest insertion heuristic is known to generate good solutions to the Traveling Salesperson Problem in Euclidean spaces, but it has not been extended to the non-Euclidean case. To address the difficulty of dealing with obstacles in the non-Euclidean space, the proposed adaptation uses multidimensional scaling to first approximate these points in a Euclidean space, thereby enabling the generation of the convex hull that initializes the algorithm. To evaluate the proposed algorithm, the TSPLIB benchmark data-set is modified by adding impassable separators that produce non-Euclidean spaces. The algorithm is demonstrated to outperform the commonly used Nearest Neighbor algorithm in 96% of the cases studied.
&lt;/p&gt;</description></item></channel></rss>