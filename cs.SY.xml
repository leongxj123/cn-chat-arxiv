<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#33258;&#36866;&#24212;&#29468;&#24819;&#30340;&#22312;&#32447;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;IT&#22522;&#30784;&#35774;&#26045;&#30340;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;&#26041;&#27861;&#65292;&#20854;&#20013;&#28216;&#25103;&#21442;&#19982;&#32773;&#36890;&#36807;Bayesian&#23398;&#20064;&#35843;&#25972;&#29468;&#24819;&#65292;&#24182;&#36890;&#36807;&#25512;&#28436;&#26356;&#26032;&#31574;&#30053;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#26368;&#20339;&#25311;&#21512;&#65292;&#25552;&#39640;&#20102;&#25512;&#28436;&#22312;&#29468;&#24819;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.12499</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#36866;&#24212;&#29468;&#24819;&#30340;&#22312;&#32447;&#23398;&#20064;&#23454;&#29616;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
Automated Security Response through Online Learning with Adaptive Conjectures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12499
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#33258;&#36866;&#24212;&#29468;&#24819;&#30340;&#22312;&#32447;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;IT&#22522;&#30784;&#35774;&#26045;&#30340;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;&#26041;&#27861;&#65292;&#20854;&#20013;&#28216;&#25103;&#21442;&#19982;&#32773;&#36890;&#36807;Bayesian&#23398;&#20064;&#35843;&#25972;&#29468;&#24819;&#65292;&#24182;&#36890;&#36807;&#25512;&#28436;&#26356;&#26032;&#31574;&#30053;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#26368;&#20339;&#25311;&#21512;&#65292;&#25552;&#39640;&#20102;&#25512;&#28436;&#22312;&#29468;&#24819;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;IT&#22522;&#30784;&#35774;&#26045;&#30340;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;&#65292;&#24182;&#23558;&#25915;&#20987;&#32773;&#21644;&#38450;&#24481;&#32773;&#20043;&#38388;&#30340;&#20114;&#21160;&#24418;&#24335;&#34920;&#36848;&#20026;&#19968;&#20010;&#37096;&#20998;&#35266;&#27979;&#12289;&#38750;&#24179;&#31283;&#21338;&#24328;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#28216;&#25103;&#27169;&#22411;&#27491;&#30830;&#35268;&#23450;&#30340;&#26631;&#20934;&#20551;&#35774;&#65292;&#24182;&#32771;&#34385;&#27599;&#20010;&#21442;&#19982;&#32773;&#23545;&#27169;&#22411;&#26377;&#19968;&#20010;&#27010;&#29575;&#24615;&#29468;&#24819;&#65292;&#21487;&#33021;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#38169;&#35823;&#35268;&#23450;&#65292;&#21363;&#30495;&#23454;&#27169;&#22411;&#30340;&#27010;&#29575;&#20026;0&#12290;&#36825;&#31181;&#24418;&#24335;&#20801;&#35768;&#25105;&#20204;&#25429;&#25417;&#20851;&#20110;&#22522;&#30784;&#35774;&#26045;&#21644;&#21442;&#19982;&#32773;&#24847;&#22270;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#22312;&#32447;&#23398;&#20064;&#26377;&#25928;&#30340;&#28216;&#25103;&#31574;&#30053;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20010;&#21442;&#19982;&#32773;&#36890;&#36807;&#36125;&#21494;&#26031;&#23398;&#20064;&#36845;&#20195;&#22320;&#35843;&#25972;&#20854;&#29468;&#24819;&#65292;&#24182;&#36890;&#36807;&#25512;&#28436;&#26356;&#26032;&#20854;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29468;&#24819;&#20250;&#25910;&#25947;&#21040;&#26368;&#20339;&#25311;&#21512;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20855;&#26377;&#29468;&#27979;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#25512;&#28436;&#23454;&#29616;&#24615;&#33021;&#25913;&#36827;&#30340;&#19978;&#38480;&#12290;&#20026;&#20102;&#21051;&#30011;&#28216;&#25103;&#30340;&#31283;&#23450;&#29366;&#24577;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Berk-Nash&#24179;&#34913;&#30340;&#19968;&#20010;&#21464;&#31181;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12499v1 Announce Type: cross  Abstract: We study automated security response for an IT infrastructure and formulate the interaction between an attacker and a defender as a partially observed, non-stationary game. We relax the standard assumption that the game model is correctly specified and consider that each player has a probabilistic conjecture about the model, which may be misspecified in the sense that the true model has probability 0. This formulation allows us to capture uncertainty about the infrastructure and the intents of the players. To learn effective game strategies online, we design a novel method where a player iteratively adapts its conjecture using Bayesian learning and updates its strategy through rollout. We prove that the conjectures converge to best fits, and we provide a bound on the performance improvement that rollout enables with a conjectured model. To characterize the steady state of the game, we propose a variant of the Berk-Nash equilibrium. We 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#36793;&#32536;&#35745;&#31639;&#36801;&#31227;&#30340;&#25925;&#38556;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550; FIRE&#65292;&#24341;&#20837;ImRE&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36793;&#32536;&#35745;&#31639;&#25968;&#23383;&#23402;&#29983;&#29615;&#22659;&#20013;&#35757;&#32451;RL&#31574;&#30053;&#26469;&#36866;&#24212;&#32597;&#35265;&#20107;&#20214;&#65292;&#35299;&#20915;&#20102;RL&#26694;&#26550;&#22312;&#22788;&#29702;&#20598;&#21457;&#26381;&#21153;&#22120;&#25925;&#38556;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2209.14399</link><description>&lt;p&gt;
FIRE&#65306;&#38754;&#21521;&#36793;&#32536;&#35745;&#31639;&#36801;&#31227;&#30340;&#25925;&#38556;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FIRE: A Failure-Adaptive Reinforcement Learning Framework for Edge Computing Migrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.14399
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#36793;&#32536;&#35745;&#31639;&#36801;&#31227;&#30340;&#25925;&#38556;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550; FIRE&#65292;&#24341;&#20837;ImRE&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36793;&#32536;&#35745;&#31639;&#25968;&#23383;&#23402;&#29983;&#29615;&#22659;&#20013;&#35757;&#32451;RL&#31574;&#30053;&#26469;&#36866;&#24212;&#32597;&#35265;&#20107;&#20214;&#65292;&#35299;&#20915;&#20102;RL&#26694;&#26550;&#22312;&#22788;&#29702;&#20598;&#21457;&#26381;&#21153;&#22120;&#25925;&#38556;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36793;&#32536;&#35745;&#31639;&#20013;&#65292;&#29992;&#25143;&#26381;&#21153;&#37197;&#32622;&#25991;&#20214;&#30001;&#20110;&#29992;&#25143;&#31227;&#21160;&#32780;&#36827;&#34892;&#36801;&#31227;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26694;&#26550;&#26469;&#36827;&#34892;&#36801;&#31227;&#65292;&#36890;&#24120;&#26159;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;RL&#26694;&#26550;&#24573;&#35270;&#20102;&#20598;&#21457;&#30340;&#26381;&#21153;&#22120;&#25925;&#38556;&#65292;&#23613;&#31649;&#32597;&#35265;&#65292;&#20294;&#20250;&#24433;&#21709;&#21040;&#20687;&#33258;&#21160;&#39550;&#39542;&#21644;&#23454;&#26102;&#38556;&#30861;&#26816;&#27979;&#31561;&#23545;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#65288;&#32597;&#35265;&#20107;&#20214;&#65289;&#25925;&#38556;&#34429;&#28982;&#22312;&#21382;&#21490;&#35757;&#32451;&#25968;&#25454;&#20013;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#20195;&#34920;&#65292;&#21364;&#23545;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;RL&#31639;&#27861;&#26500;&#25104;&#25361;&#25112;&#12290;&#30001;&#20110;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#35843;&#25972;&#25925;&#38556;&#39057;&#29575;&#36827;&#34892;&#35757;&#32451;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;FIRE&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#36807;&#22312;&#36793;&#32536;&#35745;&#31639;&#25968;&#23383;&#23402;&#29983;&#29615;&#22659;&#20013;&#35757;&#32451;RL&#31574;&#30053;&#26469;&#36866;&#24212;&#32597;&#35265;&#20107;&#20214;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ImRE&#65292;&#19968;&#31181;&#22522;&#20110;&#37325;&#35201;&#24615;&#25277;&#26679;&#30340;Q-learning&#31639;&#27861;&#65292;&#23427;&#26681;&#25454;&#32597;&#35265;&#20107;&#20214;&#23545;&#20540;&#20989;&#25968;&#30340;&#24433;&#21709;&#36827;&#34892;&#27604;&#20363;&#25277;&#26679;&#12290;FIRE&#32771;&#34385;&#20102;&#24310;&#36831;&#12289;&#36801;&#31227;&#12289;&#25925;&#38556;&#21644;&#22791;&#20221;pl
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.14399v2 Announce Type: replace-cross  Abstract: In edge computing, users' service profiles are migrated due to user mobility. Reinforcement learning (RL) frameworks have been proposed to do so, often trained on simulated data. However, existing RL frameworks overlook occasional server failures, which although rare, impact latency-sensitive applications like autonomous driving and real-time obstacle detection. Nevertheless, these failures (rare events), being not adequately represented in historical training data, pose a challenge for data-driven RL algorithms. As it is impractical to adjust failure frequency in real-world applications for training, we introduce FIRE, a framework that adapts to rare events by training a RL policy in an edge computing digital twin environment. We propose ImRE, an importance sampling-based Q-learning algorithm, which samples rare events proportionally to their impact on the value function. FIRE considers delay, migration, failure, and backup pl
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25317;&#22581;&#23450;&#20215;&#26041;&#26696;&#65292;&#26088;&#22312;&#21516;&#26102;&#20943;&#23569;&#20132;&#36890;&#25317;&#22581;&#27700;&#24179;&#21644;&#32553;&#23567;&#19981;&#21516;&#26053;&#34892;&#32773;&#20043;&#38388;&#30340;&#25104;&#26412;&#24046;&#24322;&#65292;&#20174;&#32780;&#25552;&#39640;&#25928;&#29575;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.16844</link><description>&lt;p&gt;
&#29992;&#20110;&#25928;&#29575;&#21644;&#20844;&#24179;&#24615;&#30340;&#25317;&#22581;&#23450;&#20215;&#65306;&#29702;&#35770;&#21450;&#20854;&#22312;&#26087;&#37329;&#23665;&#28286;&#21306;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Congestion Pricing for Efficiency and Equity: Theory and Applications to the San Francisco Bay Area. (arXiv:2401.16844v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16844
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25317;&#22581;&#23450;&#20215;&#26041;&#26696;&#65292;&#26088;&#22312;&#21516;&#26102;&#20943;&#23569;&#20132;&#36890;&#25317;&#22581;&#27700;&#24179;&#21644;&#32553;&#23567;&#19981;&#21516;&#26053;&#34892;&#32773;&#20043;&#38388;&#30340;&#25104;&#26412;&#24046;&#24322;&#65292;&#20174;&#32780;&#25552;&#39640;&#25928;&#29575;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25317;&#22581;&#23450;&#20215;&#34987;&#35768;&#22810;&#22478;&#24066;&#29992;&#20110;&#32531;&#35299;&#20132;&#36890;&#25317;&#22581;&#65292;&#20294;&#30001;&#20110;&#23545;&#20302;&#25910;&#20837;&#26053;&#34892;&#32773;&#24433;&#21709;&#36739;&#22823;&#65292;&#24341;&#21457;&#20102;&#20851;&#20110;&#31038;&#20250;&#32463;&#27982;&#24046;&#36317;&#25193;&#22823;&#30340;&#25285;&#24551;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25317;&#22581;&#23450;&#20215;&#26041;&#26696;&#65292;&#19981;&#20165;&#21487;&#20197;&#26368;&#22823;&#38480;&#24230;&#22320;&#20943;&#23569;&#20132;&#36890;&#25317;&#22581;&#65292;&#36824;&#21487;&#20197;&#23558;&#20844;&#24179;&#24615;&#30446;&#26631;&#32435;&#20837;&#20854;&#20013;&#65292;&#20197;&#20943;&#23569;&#19981;&#21516;&#25903;&#20184;&#24847;&#24895;&#30340;&#26053;&#34892;&#32773;&#20043;&#38388;&#30340;&#25104;&#26412;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#19968;&#20010;&#20855;&#26377;&#24322;&#36136;&#26053;&#34892;&#32773;&#32676;&#20307;&#30340;&#25317;&#22581;&#21338;&#24328;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#31181;&#32771;&#34385;&#23454;&#38469;&#22240;&#32032;&#30340;&#23450;&#20215;&#26041;&#26696;&#65292;&#20363;&#22914;&#23545;&#19981;&#21516;&#26053;&#34892;&#32773;&#32676;&#20307;&#25910;&#21462;&#24046;&#24322;&#21270;&#30340;&#36890;&#34892;&#36153;&#20197;&#21450;&#24449;&#25910;&#25972;&#20010;&#36335;&#32593;&#20013;&#30340;&#25152;&#26377;&#36793;&#25110;&#21482;&#24449;&#25910;&#20854;&#20013;&#19968;&#37096;&#20998;&#36793;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#22312;&#26087;&#37329;&#23665;&#28286;&#21306;&#30340;&#26657;&#20934;&#39640;&#36895;&#20844;&#36335;&#32593;&#32476;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#23450;&#20215;&#26041;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25317;&#22581;&#23450;&#20215;&#26041;&#26696;&#21487;&#20197;&#25552;&#39640;&#25928;&#29575;&#65288;&#21363;&#20943;&#23569;&#24179;&#22343;&#26053;&#34892;&#26102;&#38388;&#65289;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Congestion pricing, while adopted by many cities to alleviate traffic congestion, raises concerns about widening socioeconomic disparities due to its disproportionate impact on low-income travelers. In this study, we address this concern by proposing a new class of congestion pricing schemes that not only minimize congestion levels but also incorporate an equity objective to reduce cost disparities among travelers with different willingness-to-pay. Our analysis builds on a congestion game model with heterogeneous traveler populations. We present four pricing schemes that account for practical considerations, such as the ability to charge differentiated tolls to various traveler populations and the option to toll all or only a subset of edges in the network. We evaluate our pricing schemes in the calibrated freeway network of the San Francisco Bay Area. We demonstrate that the proposed congestion pricing schemes improve both efficiency (in terms of reduced average travel time) and equit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#65292;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#30340;&#31354;&#30333;&#65292;&#24182;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2401.14498</link><description>&lt;p&gt;
&#20248;&#21270;&#28207;&#21475;&#36816;&#33829;&#30340;&#39044;&#27979;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Predictive Analysis for Optimizing Port Operations. (arXiv:2401.14498v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#65292;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#30340;&#31354;&#30333;&#65292;&#24182;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28023;&#36816;&#26159;&#36828;&#36317;&#31163;&#21644;&#22823;&#23447;&#36135;&#29289;&#36816;&#36755;&#30340;&#37325;&#35201;&#29289;&#27969;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36816;&#36755;&#27169;&#24335;&#20013;&#22797;&#26434;&#30340;&#35268;&#21010;&#32463;&#24120;&#21463;&#21040;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#22825;&#27668;&#26465;&#20214;&#12289;&#36135;&#29289;&#22810;&#26679;&#24615;&#21644;&#28207;&#21475;&#21160;&#24577;&#65292;&#23548;&#33268;&#25104;&#26412;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#20572;&#30041;&#30340;&#24635;&#26102;&#38388;&#21644;&#28508;&#22312;&#24310;&#36831;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#20415;&#22312;&#28207;&#21475;&#36816;&#33829;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#35268;&#21010;&#21644;&#23433;&#25490;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24320;&#21457;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20272;&#35745;&#33337;&#33334;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#12290;&#35813;&#30740;&#31350;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#33337;&#33334;&#20572;&#30041;&#21644;&#24310;&#36831;&#26102;&#38388;&#26041;&#38754;&#30340;&#37325;&#35201;&#31354;&#30333;&#65292;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;&#25152;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#26088;&#22312;&#21327;&#21161;&#28207;&#21475;&#29615;&#22659;&#19979;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#24182;&#39044;&#27979;&#26381;&#21153;&#24310;&#36831;&#12290;&#36890;&#36807;&#23545;&#24052;&#35199;&#28207;&#21475;&#30340;&#26696;&#20363;&#30740;&#31350;&#36827;&#34892;&#39564;&#35777;&#65292;&#21516;&#26102;&#20351;&#29992;&#29305;&#24449;&#20998;&#26512;&#26469;&#29702;&#35299;...
&lt;/p&gt;
&lt;p&gt;
Maritime transport is a pivotal logistics mode for the long-distance and bulk transportation of goods. However, the intricate planning involved in this mode is often hindered by uncertainties, including weather conditions, cargo diversity, and port dynamics, leading to increased costs. Consequently, accurately estimating vessel total (stay) time at port and potential delays becomes imperative for effective planning and scheduling in port operations. This study aims to develop a port operation solution with competitive prediction and classification capabilities for estimating vessel Total and Delay times. This research addresses a significant gap in port analysis models for vessel Stay and Delay times, offering a valuable contribution to the field of maritime logistics. The proposed solution is designed to assist decision-making in port environments and predict service delays. This is demonstrated through a case study on Brazil ports. Additionally, feature analysis is used to understand
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;MDP&#20013;&#22522;&#20110;&#27010;&#29575;&#20195;&#29702;&#25481;&#32447;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#33021;&#22815;&#28040;&#38500;&#25481;&#32447;&#24773;&#20917;&#38656;&#35201;&#26522;&#20030;&#35745;&#31639;&#30340;&#38480;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#35745;&#31639;&#21518;&#25481;&#32447;&#31995;&#32479;&#30340;&#26368;&#20248;&#31574;&#30053;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.12458</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;MDP&#20013;&#22522;&#20110;&#27010;&#29575;&#20195;&#29702;&#25481;&#32447;&#30340;&#26080;&#27169;&#22411;&#23398;&#20064;&#21644;&#26368;&#20248;&#31574;&#30053;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Model-Free Learning and Optimal Policy Design in Multi-Agent MDPs Under Probabilistic Agent Dropout. (arXiv:2304.12458v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12458
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;MDP&#20013;&#22522;&#20110;&#27010;&#29575;&#20195;&#29702;&#25481;&#32447;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#33021;&#22815;&#28040;&#38500;&#25481;&#32447;&#24773;&#20917;&#38656;&#35201;&#26522;&#20030;&#35745;&#31639;&#30340;&#38480;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#35745;&#31639;&#21518;&#25481;&#32447;&#31995;&#32479;&#30340;&#26368;&#20248;&#31574;&#30053;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#65292;&#35813;&#36807;&#31243;&#21487;&#20197;&#32463;&#21382;&#20195;&#29702;&#25481;&#32447;&#65292;&#24182;&#22522;&#20110;&#23545;&#20110;&#31574;&#30053;&#30340;&#25511;&#21046;&#21644;&#39044;&#20195;&#29702;&#36807;&#31243;&#30340;&#37319;&#26679;&#26469;&#35745;&#31639;&#21518;&#25481;&#32447;&#31995;&#32479;&#30340;&#31574;&#30053;&#12290;&#25511;&#21046;&#22120;&#30340;&#30446;&#26631;&#26159;&#23547;&#25214;&#19968;&#20010;&#26368;&#20248;&#31574;&#30053;&#65292;&#20351;&#24471;&#22312;&#24050;&#30693;&#20195;&#29702;&#25481;&#20986;&#27010;&#29575;&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#26399;&#26395;&#31995;&#32479;&#30340;&#20215;&#20540;&#26368;&#22823;&#21270;&#12290;&#23545;&#20110;&#20219;&#20309;&#29305;&#23450;&#30340;&#25481;&#32447;&#24773;&#20917;&#19979;&#30340;&#26368;&#20248;&#31574;&#30053;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#29305;&#20363;&#12290;&#23545;&#20110;&#20855;&#26377;&#29305;&#23450;&#36716;&#25442;&#29420;&#31435;&#24615;&#21644;&#22870;&#21169;&#21487;&#20998;&#24615;&#32467;&#26500;&#30340;MDPs&#65292;&#25105;&#20204;&#20551;&#35774;&#20174;&#31995;&#32479;&#20013;&#31227;&#38500;&#20195;&#29702;&#32452;&#25104;&#20102;&#19968;&#20010;&#26032;&#30340;MDP&#65292;&#30001;&#21097;&#20313;&#20195;&#29702;&#32452;&#25104;&#20855;&#26377;&#26032;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;MDP&#65292;&#36716;&#25442;&#21160;&#24577;&#28040;&#38500;&#24050;&#21024;&#38500;&#30340;&#20195;&#29702;&#65292;&#22870;&#21169;&#19982;&#24050;&#21024;&#38500;&#30340;&#20195;&#29702;&#26080;&#20851;&#12290;&#39318;&#20808;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#20123;&#20551;&#35774;&#19979;&#65292;&#23545;&#20110;&#39044;&#25481;&#20986;&#31995;&#32479;&#26399;&#26395;&#20540;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#21333;&#19968;&#30340;MDP&#26469;&#34920;&#31034;&#65307;&#36825;&#20010;&#8220;&#40065;&#26834;MDP&#8221;&#33021;&#22815;&#28040;&#38500;&#22312;&#35745;&#31639;&#26368;&#20248;&#31574;&#30053;&#26102;&#35201;&#35780;&#20272;&#25152;&#26377;$2^N$&#31181;&#20195;&#29702;&#25481;&#32447;&#24773;&#20917;&#30340;&#38656;&#35201;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#21644;&#37325;&#35201;&#24615;&#37319;&#26679;&#26469;&#23398;&#20064;&#40065;&#26834;MDP&#65292;&#20174;&#32780;&#33021;&#22815;&#35745;&#31639;&#21518;&#25481;&#32447;&#31995;&#32479;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#20223;&#30495;&#32467;&#26524;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies a multi-agent Markov decision process (MDP) that can undergo agent dropout and the computation of policies for the post-dropout system based on control and sampling of the pre-dropout system. The controller's objective is to find an optimal policy that maximizes the value of the expected system given a priori knowledge of the agents' dropout probabilities. Finding an optimal policy for any specific dropout realization is a special case of this problem. For MDPs with a certain transition independence and reward separability structure, we assume that removing agents from the system forms a new MDP comprised of the remaining agents with new state and action spaces, transition dynamics that marginalize the removed agents, and rewards that are independent of the removed agents. We first show that under these assumptions, the value of the expected post-dropout system can be represented by a single MDP; this "robust MDP" eliminates the need to evaluate all $2^N$ realizations
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;D3G&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#28436;&#31034;&#20013;&#23398;&#20064;&#22810;&#26426;&#22120;&#20154;&#21327;&#35843;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;&#36712;&#36857;&#19982;&#28436;&#31034;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#65292;&#27599;&#20010;&#26426;&#22120;&#20154;&#21487;&#20197;&#33258;&#21160;&#35843;&#25972;&#20854;&#20010;&#20307;&#21160;&#24577;&#21644;&#30446;&#26631;&#65292;&#25552;&#39640;&#20102;&#23398;&#20064;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2207.08892</link><description>&lt;p&gt;
D3G: &#20174;&#28436;&#31034;&#20013;&#23398;&#20064;&#22810;&#26426;&#22120;&#20154;&#21327;&#35843;
&lt;/p&gt;
&lt;p&gt;
D3G: Learning Multi-robot Coordination from Demonstrations. (arXiv:2207.08892v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;D3G&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#28436;&#31034;&#20013;&#23398;&#20064;&#22810;&#26426;&#22120;&#20154;&#21327;&#35843;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;&#36712;&#36857;&#19982;&#28436;&#31034;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#65292;&#27599;&#20010;&#26426;&#22120;&#20154;&#21487;&#20197;&#33258;&#21160;&#35843;&#25972;&#20854;&#20010;&#20307;&#21160;&#24577;&#21644;&#30446;&#26631;&#65292;&#25552;&#39640;&#20102;&#23398;&#20064;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#21487;&#24494;&#21160;&#24577;&#28216;&#25103;&#65288;D3G&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#23454;&#29616;&#20174;&#28436;&#31034;&#20013;&#23398;&#20064;&#22810;&#26426;&#22120;&#20154;&#21327;&#35843;&#12290;&#25105;&#20204;&#23558;&#22810;&#26426;&#22120;&#20154;&#21327;&#35843;&#34920;&#31034;&#20026;&#19968;&#20010;&#21160;&#24577;&#28216;&#25103;&#65292;&#20854;&#20013;&#19968;&#20010;&#26426;&#22120;&#20154;&#30340;&#34892;&#20026;&#21463;&#20854;&#33258;&#36523;&#21160;&#24577;&#21644;&#30446;&#26631;&#30340;&#25511;&#21046;&#65292;&#21516;&#26102;&#20063;&#21462;&#20915;&#20110;&#20854;&#20182;&#26426;&#22120;&#20154;&#30340;&#34892;&#20026;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#35843;&#25972;&#27599;&#20010;&#26426;&#22120;&#20154;&#30340;&#30446;&#26631;&#21644;&#21160;&#24577;&#65292;&#21487;&#20197;&#36866;&#24212;&#21327;&#35843;&#12290;&#25152;&#25552;&#20986;&#30340;D3G&#20351;&#27599;&#20010;&#26426;&#22120;&#20154;&#36890;&#36807;&#26368;&#23567;&#21270;&#20854;&#36712;&#36857;&#19982;&#28436;&#31034;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#65292;&#22312;&#20998;&#24067;&#24335;&#26041;&#24335;&#19979;&#33258;&#21160;&#35843;&#25972;&#20854;&#20010;&#20307;&#21160;&#24577;&#21644;&#30446;&#26631;&#12290;&#35813;&#23398;&#20064;&#26694;&#26550;&#20855;&#26377;&#26032;&#30340;&#35774;&#35745;&#65292;&#21253;&#25324;&#19968;&#20010;&#21069;&#21521;&#20256;&#36882;&#65292;&#25152;&#26377;&#26426;&#22120;&#20154;&#21512;&#20316;&#23547;&#25214;&#28216;&#25103;&#30340;&#32435;&#20160;&#22343;&#34913;&#65292;&#20197;&#21450;&#19968;&#20010;&#21453;&#21521;&#20256;&#36882;&#65292;&#22312;&#36890;&#20449;&#22270;&#20013;&#20256;&#25773;&#26799;&#24230;&#12290;&#25105;&#20204;&#22312;&#20223;&#30495;&#20013;&#27979;&#35797;&#20102;D3G&#65292;&#24182;&#32473;&#20986;&#20102;&#19981;&#21516;&#20219;&#21153;&#37197;&#32622;&#30340;&#20004;&#31181;&#26426;&#22120;&#20154;&#12290;&#32467;&#26524;&#35777;&#26126;&#20102;D3G&#23398;&#20064;&#22810;&#26426;&#22120;&#20154;&#21327;&#35843;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops a Distributed Differentiable Dynamic Game (D3G) framework, which enables learning multi-robot coordination from demonstrations. We represent multi-robot coordination as a dynamic game, where the behavior of a robot is dictated by its own dynamics and objective that also depends on others' behavior. The coordination thus can be adapted by tuning the objective and dynamics of each robot. The proposed D3G enables each robot to automatically tune its individual dynamics and objectives in a distributed manner by minimizing the mismatch between its trajectory and demonstrations. This learning framework features a new design, including a forward-pass, where all robots collaboratively seek Nash equilibrium of a game, and a backward-pass, where gradients are propagated via the communication graph. We test the D3G in simulation with two types of robots given different task configurations. The results validate the capability of D3G for learning multi-robot coordination from de
&lt;/p&gt;</description></item></channel></rss>