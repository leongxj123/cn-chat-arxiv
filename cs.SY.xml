<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#20840;&#23616;&#25910;&#25947;&#20445;&#35777;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#31574;&#30053;&#26799;&#24230;&#26694;&#26550;&#65292;&#24182;&#24341;&#20837;&#23616;&#37096;&#26368;&#20248;&#25511;&#21046;&#20989;&#25968;&#30340;&#27010;&#24565;&#26469;&#34920;&#24449;&#36845;&#20195;&#30340;&#23616;&#37096;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.05816</link><description>&lt;p&gt;
&#24102;&#26377;&#20840;&#23616;&#25910;&#25947;&#20445;&#35777;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#31574;&#30053;&#26799;&#24230;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Policy Gradient Framework for Stochastic Optimal Control Problems with Global Convergence Guarantee. (arXiv:2302.05816v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05816
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#20840;&#23616;&#25910;&#25947;&#20445;&#35777;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#31574;&#30053;&#26799;&#24230;&#26694;&#26550;&#65292;&#24182;&#24341;&#20837;&#23616;&#37096;&#26368;&#20248;&#25511;&#21046;&#20989;&#25968;&#30340;&#27010;&#24565;&#26469;&#34920;&#24449;&#36845;&#20195;&#30340;&#23616;&#37096;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#36830;&#32493;&#26102;&#38388;&#20013;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20998;&#26512;&#25511;&#21046;&#30340;&#26799;&#24230;&#27969;&#65292;&#23558;&#20854;&#35270;&#20026;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#19968;&#20123;&#27491;&#21017;&#24615;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#20998;&#26512;&#20013;&#30340;&#20027;&#35201;&#21019;&#26032;&#26159;&#24341;&#20837;&#20102;&#23616;&#37096;&#26368;&#20248;&#25511;&#21046;&#20989;&#25968;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#34920;&#24449;&#36845;&#20195;&#30340;&#23616;&#37096;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider policy gradient methods for stochastic optimal control problem in continuous time. In particular, we analyze the gradient flow for the control, viewed as a continuous time limit of the policy gradient method. We prove the global convergence of the gradient flow and establish a convergence rate under some regularity assumptions. The main novelty in the analysis is the notion of local optimal control function, which is introduced to characterize the local optimality of the iterate.
&lt;/p&gt;</description></item></channel></rss>