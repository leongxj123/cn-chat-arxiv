<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#20013;&#24615;&#33021;&#21644;&#21487;&#34892;&#24615;&#21463;&#24433;&#21709;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.17338</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#30340;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning-based Receding Horizon Control using Adaptive Control Barrier Functions for Safety-Critical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17338
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#20013;&#24615;&#33021;&#21644;&#21487;&#34892;&#24615;&#21463;&#24433;&#21709;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#25511;&#21046;&#26041;&#27861;&#20026;&#23433;&#20840;&#20851;&#38190;&#38382;&#39064;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#24456;&#23481;&#26131;&#21464;&#24471;&#26840;&#25163;&#12290;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;(CBFs)&#20316;&#20026;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#20986;&#29616;&#65292;&#36890;&#36807;&#20854;&#21069;&#21521;&#19981;&#21464;&#24615;&#23646;&#24615;&#65292;&#26377;&#21033;&#20110;&#36890;&#36807;&#22312;&#25439;&#22833;&#19968;&#20123;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#24335;&#22320;&#20445;&#35777;&#23433;&#20840;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#23450;&#20041;&#24615;&#33021;&#30446;&#26631;&#20197;&#21450;&#24517;&#39035;&#22987;&#32456;&#25191;&#34892;&#30340;&#22522;&#20110;CBF&#30340;&#23433;&#20840;&#32422;&#26463;&#12290;&#36951;&#25022;&#30340;&#26159;&#65292;&#20004;&#20010;&#20851;&#38190;&#22240;&#32032;&#21487;&#33021;&#20250;&#23545;&#24615;&#33021;&#21644;&#35299;&#20915;&#26041;&#26696;&#30340;&#21487;&#34892;&#24615;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65306;(i)&#25104;&#26412;&#20989;&#25968;&#21450;&#20854;&#30456;&#20851;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#20197;&#21450;(ii)&#22312;CBF&#32422;&#26463;&#20869;&#36827;&#34892;&#21442;&#25968;&#26657;&#20934;&#65292;&#25429;&#25417;&#24615;&#33021;&#21644;&#20445;&#23432;&#24615;&#20043;&#38388;&#30340;&#25240;&#34935;&#65292;&#20197;&#21450;&#19981;&#21487;&#34892;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#30340;&#24378;&#21270;&#23398;&#20064;(RL)&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;(RHC)&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17338v1 Announce Type: cross  Abstract: Optimal control methods provide solutions to safety-critical problems but easily become intractable. Control Barrier Functions (CBFs) have emerged as a popular technique that facilitates their solution by provably guaranteeing safety, through their forward invariance property, at the expense of some performance loss. This approach involves defining a performance objective alongside CBF-based safety constraints that must always be enforced. Unfortunately, both performance and solution feasibility can be significantly impacted by two key factors: (i) the selection of the cost function and associated parameters, and (ii) the calibration of parameters within the CBF-based constraints, which capture the trade-off between performance and conservativeness. %as well as infeasibility. To address these challenges, we propose a Reinforcement Learning (RL)-based Receding Horizon Control (RHC) approach leveraging Model Predictive Control (MPC) with
&lt;/p&gt;</description></item></channel></rss>