<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#25511;&#21046;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#29366;&#24577;&#34920;&#31034;&#20989;&#25968;&#21644;&#25511;&#21046;&#22120;&#12290;</title><link>https://arxiv.org/abs/2212.14511</link><description>&lt;p&gt;
&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#33021;&#22815;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#25511;&#21046;&#38382;&#39064;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Direct Latent Model Learning Solve Linear Quadratic Gaussian Control?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.14511
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#25511;&#21046;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#29366;&#24577;&#34920;&#31034;&#20989;&#25968;&#21644;&#25511;&#21046;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#28508;&#22312;&#39640;&#32500;&#35266;&#27979;&#20013;&#23398;&#20064;&#29366;&#24577;&#34920;&#31034;&#30340;&#20219;&#21153;&#65292;&#30446;&#26631;&#26159;&#25511;&#21046;&#26410;&#30693;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#31995;&#32479;&#12290;&#25105;&#20204;&#37319;&#29992;&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#19982;&#35268;&#21010;&#30452;&#25509;&#30456;&#20851;&#30340;&#25968;&#37327;&#65288;&#20363;&#22914;&#25104;&#26412;&#65289;&#26469;&#23398;&#20064;&#28508;&#22312;&#29366;&#24577;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#37325;&#24314;&#35266;&#27979;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#19968;&#31181;&#30452;&#35266;&#30340;&#22522;&#20110;&#25104;&#26412;&#39537;&#21160;&#30340;&#29366;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#65288;LQG&#65289;&#25511;&#21046;&#38382;&#39064;&#65292;&#36825;&#26159;&#26368;&#22522;&#26412;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#25511;&#21046;&#38382;&#39064;&#20043;&#19968;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#29366;&#24577;&#34920;&#31034;&#20989;&#25968;&#21644;&#20351;&#29992;&#30452;&#25509;&#23398;&#20064;&#30340;&#28508;&#22312;&#27169;&#22411;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#25511;&#21046;&#22120;&#30340;&#20445;&#35777;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23613;&#31649;&#20197;&#21069;&#30340;&#30456;&#20851;&#24037;&#20316;&#21462;&#24471;&#20102;&#21508;&#31181;&#32463;&#39564;&#25104;&#21151;&#65292;&#20294;&#22312;&#36825;&#39033;&#24037;&#20316;&#20043;&#21069;&#65292;&#23578;&#19981;&#28165;&#26970;&#36825;&#31181;&#22522;&#20110;&#25104;&#26412;&#39537;&#21160;&#30340;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#26041;&#27861;&#26159;&#21542;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2212.14511v2 Announce Type: replace  Abstract: We study the task of learning state representations from potentially high-dimensional observations, with the goal of controlling an unknown partially observable system. We pursue a direct latent model learning approach, where a dynamic model in some latent state space is learned by predicting quantities directly related to planning (e.g., costs) without reconstructing the observations. In particular, we focus on an intuitive cost-driven state representation learning method for solving Linear Quadratic Gaussian (LQG) control, one of the most fundamental partially observable control problems. As our main results, we establish finite-sample guarantees of finding a near-optimal state representation function and a near-optimal controller using the directly learned latent model. To the best of our knowledge, despite various empirical successes, prior to this work it was unclear if such a cost-driven latent model learner enjoys finite-sampl
&lt;/p&gt;</description></item></channel></rss>