<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#24378;&#21270;&#23398;&#20064;&#21644;&#25511;&#21046;&#29702;&#35770;&#20013;&#23545;&#31216;&#25216;&#26415;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#24577;&#23545;&#31216;&#24615;&#23398;&#20064;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#32780;&#19981;&#35201;&#27714;&#22870;&#21169;&#20855;&#26377;&#30456;&#21516;&#30340;&#23545;&#31216;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.19024</link><description>&lt;p&gt;
&#21033;&#29992;&#21160;&#24577;&#23545;&#31216;&#24615;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#38750;&#23545;&#31216;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with Asymmetric Rewards
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19024
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#24378;&#21270;&#23398;&#20064;&#21644;&#25511;&#21046;&#29702;&#35770;&#20013;&#23545;&#31216;&#25216;&#26415;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#24577;&#23545;&#31216;&#24615;&#23398;&#20064;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#32780;&#19981;&#35201;&#27714;&#22870;&#21169;&#20855;&#26377;&#30456;&#21516;&#30340;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#26368;&#36817;&#30340;&#24037;&#20316;&#21033;&#29992;&#27169;&#22411;&#20013;&#30340;&#23545;&#31216;&#24615;&#26469;&#25552;&#39640;&#31574;&#30053;&#35757;&#32451;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;&#19968;&#20010;&#24120;&#29992;&#30340;&#31616;&#21270;&#20551;&#35774;&#26159;&#21160;&#21147;&#23398;&#21644;&#22870;&#21169;&#37117;&#34920;&#29616;&#20986;&#30456;&#21516;&#30340;&#23545;&#31216;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#30495;&#23454;&#29615;&#22659;&#20013;&#65292;&#21160;&#21147;&#23398;&#27169;&#22411;&#34920;&#29616;&#20986;&#19982;&#22870;&#21169;&#27169;&#22411;&#29420;&#31435;&#30340;&#23545;&#31216;&#24615;&#65306;&#22870;&#21169;&#21487;&#33021;&#19981;&#28385;&#36275;&#19982;&#21160;&#21147;&#23398;&#30456;&#21516;&#30340;&#23545;&#31216;&#24615;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#21482;&#20551;&#23450;&#21160;&#21147;&#23398;&#34920;&#29616;&#20986;&#23545;&#31216;&#24615;&#30340;&#24773;&#20917;&#65292;&#25193;&#23637;&#20102;&#24378;&#21270;&#23398;&#20064;&#21644;&#25511;&#21046;&#29702;&#35770;&#23398;&#20064;&#20013;&#21487;&#24212;&#29992;&#23545;&#31216;&#25216;&#26415;&#30340;&#38382;&#39064;&#33539;&#22260;&#12290;&#25105;&#20204;&#21033;&#29992;&#21345;&#22612;&#24681;&#31227;&#21160;&#26694;&#26550;&#26041;&#27861;&#24341;&#20837;&#19968;&#31181;&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#26500;&#36896;&#65292;&#36825;&#31181;&#21160;&#21147;&#23398;&#34920;&#29616;&#20986;&#25351;&#23450;&#30340;&#23545;&#31216;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23398;&#21040;&#20102;&#26356;&#20934;&#30830;&#30340;&#21160;&#24577;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19024v1 Announce Type: cross  Abstract: Recent work in reinforcement learning has leveraged symmetries in the model to improve sample efficiency in training a policy. A commonly used simplifying assumption is that the dynamics and reward both exhibit the same symmetry. However, in many real-world environments, the dynamical model exhibits symmetry independent of the reward model: the reward may not satisfy the same symmetries as the dynamics. In this paper, we investigate scenarios where only the dynamics are assumed to exhibit symmetry, extending the scope of problems in reinforcement learning and learning in control theory where symmetry techniques can be applied. We use Cartan's moving frame method to introduce a technique for learning dynamics which, by construction, exhibit specified symmetries. We demonstrate through numerical experiments that the proposed method learns a more accurate dynamical model.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20551;&#35774;&#22312;&#32447;&#23398;&#20064;&#65288;COL&#65289;&#30340;&#23398;&#20064;&#26041;&#26696;&#65292;&#38024;&#23545;&#36890;&#29992;AISG&#65292;&#32467;&#26500;&#21270;&#20026;&#19968;&#20010;&#20808;&#39564;&#39044;&#27979;&#32773;-&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;FAC&#65289;&#26550;&#26500;&#65292;&#21033;&#29992;&#19968;&#32423;&#20449;&#24565;&#21644;&#23545;&#25163;&#31574;&#30053;&#30340;&#20027;&#35266;&#39044;&#27979;&#65292;&#36890;&#36807;&#22312;&#32447;&#23637;&#24320;&#26356;&#26032;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#23398;&#20064;&#26657;&#20934;&#20551;&#35774;&#12290;</title><link>https://arxiv.org/abs/2402.18781</link><description>&lt;p&gt;
&#20855;&#26377;&#19968;&#32423;&#20449;&#24565;&#30340;&#20551;&#35774;&#22312;&#32447;&#23398;&#20064;&#22312;&#19981;&#23545;&#31216;&#20449;&#24687;&#38543;&#26426;&#21338;&#24328;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Conjectural Online Learning with First-order Beliefs in Asymmetric Information Stochastic Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18781
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20551;&#35774;&#22312;&#32447;&#23398;&#20064;&#65288;COL&#65289;&#30340;&#23398;&#20064;&#26041;&#26696;&#65292;&#38024;&#23545;&#36890;&#29992;AISG&#65292;&#32467;&#26500;&#21270;&#20026;&#19968;&#20010;&#20808;&#39564;&#39044;&#27979;&#32773;-&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;FAC&#65289;&#26550;&#26500;&#65292;&#21033;&#29992;&#19968;&#32423;&#20449;&#24565;&#21644;&#23545;&#25163;&#31574;&#30053;&#30340;&#20027;&#35266;&#39044;&#27979;&#65292;&#36890;&#36807;&#22312;&#32447;&#23637;&#24320;&#26356;&#26032;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#23398;&#20064;&#26657;&#20934;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21338;&#24328;&#20986;&#29616;&#22312;&#35768;&#22810;&#22797;&#26434;&#30340;&#31038;&#20250;&#25216;&#26415;&#31995;&#32479;&#20013;&#65292;&#22914;&#32593;&#32476;&#29289;&#29702;&#31995;&#32479;&#21644;IT&#22522;&#30784;&#35774;&#26045;&#65292;&#20449;&#24687;&#19981;&#23545;&#31216;&#20026;&#20915;&#31574;&#23454;&#20307;&#65288;&#29609;&#23478;&#65289;&#30340;&#20915;&#31574;&#24102;&#26469;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#19981;&#23545;&#31216;&#20449;&#24687;&#38543;&#26426;&#21338;&#24328;&#65288;AISG&#65289;&#30340;&#35745;&#31639;&#26041;&#27861;&#20027;&#35201;&#26159;&#31163;&#32447;&#30340;&#65292;&#38024;&#23545;&#29305;&#27530;&#31867;&#21035;&#30340;AISG&#65292;&#20197;&#36991;&#20813;&#20449;&#24565;&#23618;&#27425;&#65292;&#24182;&#19988;&#32570;&#20047;&#36866;&#24212;&#22343;&#34913;&#20559;&#24046;&#30340;&#22312;&#32447;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20551;&#35774;&#22312;&#32447;&#23398;&#20064;&#65288;COL&#65289;&#30340;&#23398;&#20064;&#26041;&#26696;&#65292;&#19987;&#38376;&#38024;&#23545;&#36890;&#29992;AISG&#12290;COL&#32467;&#26500;&#21270;&#20026;&#19968;&#20010;&#20808;&#39564;&#39044;&#27979;&#32773;-&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;FAC&#65289;&#26550;&#26500;&#65292;&#21033;&#29992;&#23545;&#38544;&#34255;&#29366;&#24577;&#30340;&#19968;&#32423;&#20449;&#24565;&#21644;&#23545;&#23545;&#25163;&#31574;&#30053;&#30340;&#20027;&#35266;&#39044;&#27979;&#12290;&#38024;&#23545;&#20551;&#35774;&#30340;&#23545;&#25163;&#65292;COL&#36890;&#36807;&#22312;&#32447;&#23637;&#24320;&#26356;&#26032;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#23398;&#20064;&#26657;&#20934;&#20551;&#35774;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;COL&#20013;&#30340;&#20551;&#35774;&#19982;t&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18781v1 Announce Type: cross  Abstract: Stochastic games arise in many complex socio-technical systems, such as cyber-physical systems and IT infrastructures, where information asymmetry presents challenges for decision-making entities (players). Existing computational methods for asymmetric information stochastic games (AISG) are primarily offline, targeting special classes of AISGs to avoid belief hierarchies, and lack online adaptability to deviations from equilibrium. To address this limitation, we propose a conjectural online learning (COL), a learning scheme for generic AISGs. COL, structured as a forecaster-actor-critic (FAC) architecture, utilizes first-order beliefs over the hidden states and subjective forecasts of the opponent's strategies. Against the conjectured opponent, COL updates strategies in an actor-critic approach using online rollout and calibrates conjectures through Bayesian learning. We prove that conjecture in COL is asymptotically consistent with t
&lt;/p&gt;</description></item><item><title>PowerGraph&#26159;&#19968;&#20010;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30005;&#32593;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23454;&#29616;&#30005;&#21147;&#32593;&#26684;&#26029;&#30005;&#30340;&#22312;&#32447;&#26816;&#27979;&#12290;</title><link>https://arxiv.org/abs/2402.02827</link><description>&lt;p&gt;
PowerGraph: &#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30005;&#32593;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
PowerGraph: A power grid benchmark dataset for graph neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02827
&lt;/p&gt;
&lt;p&gt;
PowerGraph&#26159;&#19968;&#20010;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30005;&#32593;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23454;&#29616;&#30005;&#21147;&#32593;&#26684;&#26029;&#30005;&#30340;&#22312;&#32447;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#20849;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22522;&#20934;&#25968;&#25454;&#38598;&#26377;&#21161;&#20110;&#20351;&#29992;GNN&#65292;&#24182;&#22686;&#24378;GNN&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#30446;&#21069;&#65292;&#31038;&#21306;&#20013;&#32570;&#20047;&#29992;&#20110;GNN&#24212;&#29992;&#30340;&#30005;&#21147;&#32593;&#26684;&#20844;&#20849;&#25968;&#25454;&#38598;&#12290;&#20107;&#23454;&#19978;&#65292;&#19982;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30456;&#27604;&#65292;GNN&#21487;&#20197;&#28508;&#22312;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#30005;&#21147;&#32593;&#26684;&#29616;&#35937;&#12290;&#30005;&#21147;&#32593;&#26684;&#26159;&#22797;&#26434;&#30340;&#24037;&#31243;&#32593;&#32476;&#65292;&#22825;&#28982;&#36866;&#21512;&#20110;&#22270;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;GNN&#26377;&#28508;&#21147;&#25429;&#25417;&#21040;&#30005;&#21147;&#32593;&#26684;&#30340;&#34892;&#20026;&#65292;&#32780;&#19981;&#29992;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#20110;&#32423;&#32852;&#25925;&#38556;&#20107;&#20214;&#30340;&#22270;&#25968;&#25454;&#38598;&#65292;&#36825;&#26159;&#23548;&#33268;&#30005;&#21147;&#32593;&#26684;&#26029;&#30005;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#21382;&#21490;&#26029;&#30005;&#25968;&#25454;&#38598;&#31232;&#32570;&#19988;&#19981;&#23436;&#25972;&#12290;&#36890;&#24120;&#36890;&#36807;&#35745;&#31639;&#26114;&#36149;&#30340;&#31163;&#32447;&#32423;&#32852;&#25925;&#38556;&#27169;&#25311;&#26469;&#35780;&#20272;&#33030;&#24369;&#24615;&#21644;&#35782;&#21035;&#20851;&#38190;&#32452;&#20214;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#22312;&#32447;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Public Graph Neural Networks (GNN) benchmark datasets facilitate the use of GNN and enhance GNN applicability to diverse disciplines. The community currently lacks public datasets of electrical power grids for GNN applications. Indeed, GNNs can potentially capture complex power grid phenomena over alternative machine learning techniques. Power grids are complex engineered networks that are naturally amenable to graph representations. Therefore, GNN have the potential for capturing the behavior of power grids over alternative machine learning techniques. To this aim, we develop a graph dataset for cascading failure events, which are the major cause of blackouts in electric power grids. Historical blackout datasets are scarce and incomplete. The assessment of vulnerability and the identification of critical components are usually conducted via computationally expensive offline simulations of cascading failures. Instead, we propose using machine learning models for the online detection of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#23398;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;MC&#26041;&#27861;&#19982;&#22522;&#20110;&#29289;&#29702;&#23398;&#30340;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#26377;&#25928;&#35780;&#20272;&#38271;&#26399;&#39118;&#38505;&#27010;&#29575;&#21450;&#20854;&#26799;&#24230;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#33021;&#22815;&#36866;&#24212;&#31995;&#32479;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.06432</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#39118;&#38505;&#27010;&#29575;&#20272;&#35745;&#30340;&#21487;&#25512;&#24191;&#12289;&#29289;&#29702;&#23398;&#22522;&#30784;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Generalizable Physics-informed Learning Framework for Risk Probability Estimation. (arXiv:2305.06432v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#23398;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;MC&#26041;&#27861;&#19982;&#22522;&#20110;&#29289;&#29702;&#23398;&#30340;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#26377;&#25928;&#35780;&#20272;&#38271;&#26399;&#39118;&#38505;&#27010;&#29575;&#21450;&#20854;&#26799;&#24230;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#33021;&#22815;&#36866;&#24212;&#31995;&#32479;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#35780;&#20272;&#38271;&#26399;&#39118;&#38505;&#27010;&#29575;&#21450;&#20854;&#26799;&#24230;&#23545;&#20110;&#35768;&#22810;&#38543;&#26426;&#23433;&#20840;&#25511;&#21046;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#26102;&#21644;&#26410;&#30693;&#25110;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#35745;&#31639;&#36825;&#20123;&#39118;&#38505;&#27010;&#29575;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#38271;&#26399;&#39118;&#38505;&#27010;&#29575;&#21450;&#20854;&#26799;&#24230;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#38271;&#26399;&#39118;&#38505;&#27010;&#29575;&#28385;&#36275;&#26576;&#20123;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#30340;&#20107;&#23454;&#65292;&#35813;&#26041;&#31243;&#34920;&#24449;&#20102;&#27010;&#29575;&#20043;&#38388;&#30340;&#37051;&#36817;&#20851;&#31995;&#65292;&#20197;&#23558;MC&#26041;&#27861;&#21644;&#22522;&#20110;&#29289;&#29702;&#23398;&#30340;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#29305;&#23450;&#35757;&#32451;&#37197;&#32622;&#19979;&#32473;&#20986;&#20272;&#35745;&#35823;&#24046;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#25512;&#24191;&#21040;&#26410;&#30693;&#21306;&#22495;&#65292;&#24182;&#33021;&#22815;&#36866;&#24212;&#31995;&#32479;&#21464;&#21270;&#65292;&#30456;&#27604;MC&#26041;&#27861;&#21644;&#29616;&#26377;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#23427;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate estimates of long-term risk probabilities and their gradients are critical for many stochastic safe control methods. However, computing such risk probabilities in real-time and in unseen or changing environments is challenging. Monte Carlo (MC) methods cannot accurately evaluate the probabilities and their gradients as an infinitesimal devisor can amplify the sampling noise. In this paper, we develop an efficient method to evaluate the probabilities of long-term risk and their gradients. The proposed method exploits the fact that long-term risk probability satisfies certain partial differential equations (PDEs), which characterize the neighboring relations between the probabilities, to integrate MC methods and physics-informed neural networks. We provide theoretical guarantees of the estimation error given certain choices of training configurations. Numerical results show the proposed method has better sample efficiency, generalizes well to unseen regions, and can adapt to sys
&lt;/p&gt;</description></item></channel></rss>