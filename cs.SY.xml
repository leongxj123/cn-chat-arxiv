<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31038;&#20250;&#25972;&#21512;&#23548;&#33322;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#20154;&#30340;&#20114;&#21160;&#20351;&#26426;&#22120;&#20154;&#30340;&#31038;&#20132;&#34892;&#20026;&#33258;&#36866;&#24212;&#65292;&#24182;&#20174;&#20854;&#20182;&#22522;&#20110;DRL&#30340;&#23548;&#33322;&#26041;&#27861;&#20013;&#21306;&#20998;&#20986;&#20855;&#26377;&#26126;&#30830;&#39044;&#23450;&#20041;&#31038;&#20132;&#34892;&#20026;&#30340;&#31038;&#20250;&#24847;&#35782;&#26041;&#27861;&#21644;&#32570;&#20047;&#31038;&#20132;&#34892;&#20026;&#30340;&#31038;&#20250;&#30896;&#25758;&#22238;&#36991;&#12290;</title><link>https://arxiv.org/abs/2403.09793</link><description>&lt;p&gt;
&#31038;&#20250;&#25972;&#21512;&#23548;&#33322;&#65306;&#20855;&#26377;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#31038;&#20132;&#34892;&#21160;&#26426;&#22120;&#20154;
&lt;/p&gt;
&lt;p&gt;
Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09793
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31038;&#20250;&#25972;&#21512;&#23548;&#33322;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#20154;&#30340;&#20114;&#21160;&#20351;&#26426;&#22120;&#20154;&#30340;&#31038;&#20132;&#34892;&#20026;&#33258;&#36866;&#24212;&#65292;&#24182;&#20174;&#20854;&#20182;&#22522;&#20110;DRL&#30340;&#23548;&#33322;&#26041;&#27861;&#20013;&#21306;&#20998;&#20986;&#20855;&#26377;&#26126;&#30830;&#39044;&#23450;&#20041;&#31038;&#20132;&#34892;&#20026;&#30340;&#31038;&#20250;&#24847;&#35782;&#26041;&#27861;&#21644;&#32570;&#20047;&#31038;&#20132;&#34892;&#20026;&#30340;&#31038;&#20250;&#30896;&#25758;&#22238;&#36991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31227;&#21160;&#26426;&#22120;&#20154;&#27491;&#22312;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#25317;&#25380;&#22330;&#26223;&#65292;&#24182;&#25104;&#20026;&#25105;&#20204;&#31038;&#20250;&#30340;&#19968;&#37096;&#20998;&#12290;&#19968;&#20010;&#20855;&#26377;&#20010;&#20307;&#20154;&#31867;&#32771;&#34385;&#30340;&#31038;&#20250;&#21487;&#25509;&#21463;&#30340;&#23548;&#33322;&#34892;&#20026;&#23545;&#20110;&#21487;&#25193;&#23637;&#30340;&#24212;&#29992;&#21644;&#20154;&#31867;&#25509;&#21463;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#20351;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#26041;&#27861;&#26469;&#23398;&#20064;&#26426;&#22120;&#20154;&#30340;&#23548;&#33322;&#31574;&#30053;&#65292;&#24182;&#23545;&#26426;&#22120;&#20154;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#22797;&#26434;&#20132;&#20114;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#24314;&#35758;&#26681;&#25454;&#26426;&#22120;&#20154;&#23637;&#31034;&#30340;&#31038;&#20132;&#34892;&#20026;&#23558;&#29616;&#26377;&#22522;&#20110;DRL&#30340;&#23548;&#33322;&#26041;&#27861;&#20998;&#20026;&#20855;&#26377;&#32570;&#20047;&#31038;&#20132;&#34892;&#20026;&#30340;&#31038;&#20250;&#30896;&#25758;&#22238;&#36991;&#21644;&#20855;&#26377;&#26126;&#30830;&#39044;&#23450;&#20041;&#31038;&#20132;&#34892;&#20026;&#30340;&#31038;&#20250;&#24847;&#35782;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31038;&#20250;&#25972;&#21512;&#23548;&#33322;&#26041;&#27861;&#65292;&#20854;&#20013;&#26426;&#22120;&#20154;&#30340;&#31038;&#20132;&#34892;&#20026;&#26159;&#33258;&#36866;&#24212;&#30340;&#65292;&#24182;&#19988;&#26159;&#36890;&#36807;&#19982;&#20154;&#31867;&#30340;&#20114;&#21160;&#32780;&#20135;&#29983;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26500;&#24335;&#28304;&#33258;&#31038;&#20250;&#23398;&#23450;&#20041;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09793v1 Announce Type: cross  Abstract: Mobile robots are being used on a large scale in various crowded situations and become part of our society. The socially acceptable navigation behavior of a mobile robot with individual human consideration is an essential requirement for scalable applications and human acceptance. Deep Reinforcement Learning (DRL) approaches are recently used to learn a robot's navigation policy and to model the complex interactions between robots and humans. We propose to divide existing DRL-based navigation approaches based on the robot's exhibited social behavior and distinguish between social collision avoidance with a lack of social behavior and socially aware approaches with explicit predefined social behavior. In addition, we propose a novel socially integrated navigation approach where the robot's social behavior is adaptive and emerges from the interaction with humans. The formulation of our approach is derived from a sociological definition, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#65292;&#36890;&#36807;&#39030;&#28857;&#24230;&#26680;&#21644;&#32593;&#32476;&#25195;&#25551;&#20027;&#21160;&#23398;&#20064;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#30340;&#23398;&#20064;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;</title><link>http://arxiv.org/abs/2308.07867</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#30340;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Graph-Structured Kernel Design for Power Flow Learning using Gaussian Processes. (arXiv:2308.07867v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#65292;&#36890;&#36807;&#39030;&#28857;&#24230;&#26680;&#21644;&#32593;&#32476;&#25195;&#25551;&#20027;&#21160;&#23398;&#20064;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#30340;&#23398;&#20064;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#21551;&#21457;&#30340;&#22270;&#32467;&#26500;&#26680;&#35774;&#35745;&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#21151;&#29575;&#27969;&#23398;&#20064;&#12290;&#35813;&#26680;&#34987;&#21629;&#21517;&#20026;&#39030;&#28857;&#24230;&#26680;&#65288;VDK&#65289;&#65292;&#23427;&#20381;&#36182;&#20110;&#22522;&#20110;&#32593;&#32476;&#22270;&#25110;&#25299;&#25169;&#30340;&#30005;&#21387;&#27880;&#20837;&#20851;&#31995;&#30340;&#28508;&#22312;&#20998;&#35299;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;VDK&#35774;&#35745;&#36991;&#20813;&#20102;&#38656;&#35201;&#35299;&#20915;&#26680;&#25628;&#32034;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#20026;&#20102;&#25552;&#39640;&#25928;&#29575;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#19968;&#31181;&#22270;&#32553;&#20943;&#26041;&#27861;&#65292;&#20197;&#33719;&#24471;&#20855;&#26377;&#36739;&#23569;&#39033;&#30340;VDK&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32593;&#32476;&#25195;&#25551;&#20027;&#21160;&#23398;&#20064;&#26041;&#26696;&#65292;&#23427;&#26234;&#33021;&#22320;&#36873;&#25321;&#39034;&#24207;&#35757;&#32451;&#36755;&#20837;&#65292;&#21152;&#36895;VDK&#30340;&#23398;&#20064;&#12290;&#21033;&#29992;VDK&#30340;&#21487;&#21152;&#24615;&#32467;&#26500;&#65292;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#23545;GP&#30340;&#39044;&#27979;&#26041;&#24046;&#36827;&#34892;&#20102;&#22359;&#19979;&#38477;&#31867;&#22411;&#30340;&#36807;&#31243;&#65292;&#20316;&#20026;&#20449;&#24687;&#22686;&#30410;&#30340;&#20195;&#29702;&#12290;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;VDK-GP&#19982;&#20013;&#31561;&#35268;&#27169;500&#20010;&#33410;&#28857;&#21644;&#22823;&#35268;&#27169;1354&#20010;&#33410;&#28857;&#30340;&#23436;&#25972;GP&#30456;&#27604;&#65292;&#23454;&#29616;&#20102;&#36229;&#36807;&#20004;&#20493;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a physics-inspired graph-structured kernel designed for power flow learning using Gaussian Process (GP). The kernel, named the vertex-degree kernel (VDK), relies on latent decomposition of voltage-injection relationship based on the network graph or topology. Notably, VDK design avoids the need to solve optimization problems for kernel search. To enhance efficiency, we also explore a graph-reduction approach to obtain a VDK representation with lesser terms. Additionally, we propose a novel network-swipe active learning scheme, which intelligently selects sequential training inputs to accelerate the learning of VDK. Leveraging the additive structure of VDK, the active learning algorithm performs a block-descent type procedure on GP's predictive variance, serving as a proxy for information gain. Simulations demonstrate that the proposed VDK-GP achieves more than two fold sample complexity reduction, compared to full GP on medium scale 500-Bus and large scale 1354-Bus 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.04428</link><description>&lt;p&gt;
&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#20803;&#23398;&#20064;&#25805;&#20316;&#31526;&#21040;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#36817;&#21462;&#24471;&#36827;&#23637;&#30340;&#19968;&#20010;&#24378;&#22823;&#27010;&#24565;&#26159;&#20174;&#24322;&#26500;&#26469;&#28304;&#25110;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20849;&#21516;&#29305;&#24449;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#23558;&#25152;&#26377;&#25968;&#25454;&#29992;&#20110;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#20989;&#25968;&#65292;&#26082;&#26377;&#21161;&#20110;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#26377;&#21161;&#20110;&#32479;&#35745;&#27867;&#21270;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20943;&#23569;&#35201;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20026;&#20102;&#22312;&#29702;&#35770;&#19978;&#20570;&#20986;&#36825;&#20123;&#20248;&#28857;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#22122;&#22768;&#21521;&#37327;&#27979;&#37327;$y = Mx + w$&#20013;&#22238;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;$M$&#30340;&#19968;&#33324;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21464;&#37327;$x$&#26082;&#21487;&#20197;&#26159;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20063;&#21487;&#20197;&#26159;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#36825;&#23548;&#33268;&#22122;&#22768;&#39033;&#30340;&#32553;&#25918;&#19981;&#20877;&#26377;&#21033;&#20110;&#28304;&#20219;&#21153;&#25968;&#37327;&#12290;&#36825;&#21453;&#36807;&#26469;&#20250;&#23548;&#33268;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21463;&#21040;&#21333;&#20219;&#21153;&#25968;&#25454;&#35268;&#27169;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp; Feature-Whiten}
&lt;/p&gt;</description></item></channel></rss>