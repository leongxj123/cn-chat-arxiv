<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>Constraint-Generation Policy Optimization (CGPO)&#26159;&#19968;&#31181;&#38024;&#23545;&#28151;&#21512;&#31163;&#25955;&#36830;&#32493;MDPs&#30340;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#25552;&#20379;&#26377;&#30028;&#30340;&#31574;&#30053;&#35823;&#24046;&#20445;&#35777;&#65292;&#25512;&#23548;&#20986;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#29983;&#25104;&#26368;&#22351;&#24773;&#20917;&#30340;&#29366;&#24577;&#36712;&#36857;&#26469;&#35786;&#26029;&#31574;&#30053;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2401.12243</link><description>&lt;p&gt;
Constraint-Generation Policy Optimization (CGPO): &#38024;&#23545;&#28151;&#21512;&#31163;&#25955;&#36830;&#32493;MDPs&#20013;&#30340;&#31574;&#30053;&#20248;&#21270;&#30340;&#38750;&#32447;&#24615;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Constraint-Generation Policy Optimization (CGPO): Nonlinear Programming for Policy Optimization in Mixed Discrete-Continuous MDPs. (arXiv:2401.12243v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12243
&lt;/p&gt;
&lt;p&gt;
Constraint-Generation Policy Optimization (CGPO)&#26159;&#19968;&#31181;&#38024;&#23545;&#28151;&#21512;&#31163;&#25955;&#36830;&#32493;MDPs&#30340;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#25552;&#20379;&#26377;&#30028;&#30340;&#31574;&#30053;&#35823;&#24046;&#20445;&#35777;&#65292;&#25512;&#23548;&#20986;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#29983;&#25104;&#26368;&#22351;&#24773;&#20917;&#30340;&#29366;&#24577;&#36712;&#36857;&#26469;&#35786;&#26029;&#31574;&#30053;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;Constraint-Generation Policy Optimization (CGPO)&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28151;&#21512;&#31163;&#25955;&#36830;&#32493;Markov Decision Processes (DC-MDPs)&#20013;&#20248;&#21270;&#31574;&#30053;&#21442;&#25968;&#12290;CGPO&#19981;&#20165;&#33021;&#22815;&#25552;&#20379;&#26377;&#30028;&#30340;&#31574;&#30053;&#35823;&#24046;&#20445;&#35777;&#65292;&#35206;&#30422;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#26080;&#25968;&#21021;&#22987;&#29366;&#24577;&#33539;&#22260;&#30340;DC-MDPs&#65292;&#32780;&#19988;&#22312;&#32467;&#26463;&#26102;&#21487;&#20197;&#26126;&#30830;&#22320;&#25512;&#23548;&#20986;&#26368;&#20248;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;CGPO&#36824;&#33021;&#22815;&#29983;&#25104;&#26368;&#22351;&#24773;&#20917;&#30340;&#29366;&#24577;&#36712;&#36857;&#26469;&#35786;&#26029;&#31574;&#30053;&#32570;&#38519;&#65292;&#24182;&#25552;&#20379;&#26368;&#20248;&#34892;&#21160;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20123;&#32467;&#26524;&#65292;CGPO&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#30340;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#20248;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#23450;&#20041;&#30340;&#34920;&#36798;&#33021;&#21147;&#31867;&#21035;&#65288;&#21363;&#20998;&#27573;(&#38750;)&#32447;&#24615;&#65289;&#20869;&#20248;&#21270;&#31574;&#30053;&#65292;&#24182;&#23558;&#20854;&#36716;&#21270;&#20026;&#19968;&#20010;&#26368;&#20248;&#30340;&#32422;&#26463;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25239;&#24615;&#29983;&#25104;&#26368;&#22351;&#24773;&#20917;&#30340;&#29366;&#24577;&#36712;&#36857;&#12290;&#27492;&#22806;&#65292;&#20511;&#21161;&#29616;&#20195;&#38750;&#32447;&#24615;&#20248;&#21270;&#22120;&#65292;CGPO&#21487;&#20197;&#33719;&#24471;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Constraint-Generation Policy Optimization (CGPO) for optimizing policy parameters within compact and interpretable policy classes for mixed discrete-continuous Markov Decision Processes (DC-MDPs). CGPO is not only able to provide bounded policy error guarantees over an infinite range of initial states for many DC-MDPs with expressive nonlinear dynamics, but it can also provably derive optimal policies in cases where it terminates with zero error. Furthermore, CGPO can generate worst-case state trajectories to diagnose policy deficiencies and provide counterfactual explanations of optimal actions. To achieve such results, CGPO proposes a bi-level mixed-integer nonlinear optimization framework for optimizing policies within defined expressivity classes (i.e. piecewise (non)-linear) and reduces it to an optimal constraint generation methodology that adversarially generates worst-case state trajectories. Furthermore, leveraging modern nonlinear optimizers, CGPO can obtain soluti
&lt;/p&gt;</description></item><item><title>MutateNN&#26159;&#19968;&#31181;&#29992;&#20110;&#25506;&#32034;&#30828;&#20214;&#21152;&#36895;&#22120;&#19978;&#28145;&#24230;&#23398;&#20064;&#22270;&#20687;&#35782;&#21035;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#24037;&#20855;&#65292;&#25552;&#20379;&#31361;&#21464;&#27979;&#35797;&#21644;&#20998;&#26512;&#33021;&#21147;&#65292;&#19988;&#26377;&#25928;&#24615;&#24050;&#22312;&#22810;&#31181;&#39044;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.01697</link><description>&lt;p&gt;
MutateNN&#65306;&#29992;&#20110;&#30828;&#20214;&#21152;&#36895;&#22120;&#19978;&#22270;&#20687;&#35782;&#21035;&#27169;&#22411;&#30340;&#31361;&#21464;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
MutateNN: Mutation Testing of Image Recognition Models Deployed on Hardware Accelerators. (arXiv:2306.01697v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01697
&lt;/p&gt;
&lt;p&gt;
MutateNN&#26159;&#19968;&#31181;&#29992;&#20110;&#25506;&#32034;&#30828;&#20214;&#21152;&#36895;&#22120;&#19978;&#28145;&#24230;&#23398;&#20064;&#22270;&#20687;&#35782;&#21035;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#24037;&#20855;&#65292;&#25552;&#20379;&#31361;&#21464;&#27979;&#35797;&#21644;&#20998;&#26512;&#33021;&#21147;&#65292;&#19988;&#26377;&#25928;&#24615;&#24050;&#22312;&#22810;&#31181;&#39044;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#38382;&#39064;&#24182;&#25512;&#21160;&#25216;&#26415;&#21457;&#23637;&#30340;&#26032;&#26426;&#36935;&#24212;&#36816;&#32780;&#29983;&#12290;&#22270;&#20687;&#35782;&#21035;&#27169;&#22411;&#29305;&#21035;&#26159;&#34987;&#20998;&#37197;&#20102;&#24863;&#30693;&#20219;&#21153;&#65292;&#20197;&#35299;&#20915;&#22797;&#26434;&#30340;&#29616;&#23454;&#19990;&#30028;&#25361;&#25112;&#24182;&#23548;&#33268;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#36825;&#31867;&#27169;&#22411;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#36164;&#28304;&#38656;&#27714;&#20063;&#26377;&#25152;&#22686;&#21152;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#27169;&#22411;&#20248;&#21270;&#21644;&#30828;&#20214;&#21152;&#36895;&#24050;&#25104;&#20026;&#20851;&#38190;&#25216;&#26415;&#65292;&#20294;&#26377;&#25928;&#25972;&#21512;&#36825;&#20123;&#27010;&#24565;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#21644;&#23481;&#26131;&#20986;&#38169;&#30340;&#36807;&#31243;&#12290;&#20026;&#20102;&#35753;&#24320;&#21457;&#20154;&#21592;&#21644;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#25506;&#32034;&#22312;&#19981;&#21516;&#30828;&#20214;&#21152;&#36895;&#35774;&#22791;&#19978;&#37096;&#32626;&#30340;&#28145;&#24230;&#23398;&#20064;&#22270;&#20687;&#35782;&#21035;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MutateNN&#65292;&#36825;&#26159;&#19968;&#20010;&#20026;&#27492;&#30446;&#30340;&#25552;&#20379;&#31361;&#21464;&#27979;&#35797;&#21644;&#20998;&#26512;&#33021;&#21147;&#30340;&#24037;&#20855;&#12290;&#20026;&#20102;&#23637;&#31034;&#20854;&#21151;&#33021;&#65292;&#25105;&#20204;&#23545;7&#20010;&#24191;&#20026;&#20154;&#30693;&#30340;&#39044;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#20102;21&#31181;&#21464;&#24322;&#12290;&#25105;&#20204;&#22312;4&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#30828;&#20214;&#21152;&#36895;&#22120;&#19978;&#37096;&#32626;&#20102;&#25105;&#20204;&#30340;&#21464;&#24322;&#20307;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#34892;&#20026;&#65292;&#24182;&#35780;&#20272;&#20102;MutateNN&#22312;&#26816;&#27979;&#20986;&#19981;&#27491;&#30830;&#25110;&#19981;&#31934;&#30830;&#30340;&#27169;&#22411;&#34892;&#20026;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the research advancement of Artificial Intelligence in the last years, there are new opportunities to mitigate real-world problems and advance technologically. Image recognition models in particular, are assigned with perception tasks to mitigate complex real-world challenges and lead to new solutions. Furthermore, the computational complexity and demand for resources of such models has also increased. To mitigate this, model optimization and hardware acceleration has come into play, but effectively integrating such concepts is a challenging and error-prone process.  In order to allow developers and researchers to explore the robustness of deep learning image recognition models deployed on different hardware acceleration devices, we propose MutateNN, a tool that provides mutation testing and analysis capabilities for that purpose. To showcase its capabilities, we utilized 21 mutations for 7 widely-known pre-trained deep neural network models. We deployed our mutants on 4 different
&lt;/p&gt;</description></item></channel></rss>