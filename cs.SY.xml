<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21551;&#29992;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26500;&#24314;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#20445;&#35777;&#24191;&#27867;&#31867;&#21035;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#12290;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#65292;&#23545;&#21442;&#32771;&#25511;&#21046;&#22120;&#30340;&#24178;&#39044;&#26368;&#23567;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#21644;&#27604;&#36739;&#26696;&#20363;&#23637;&#31034;&#20102;&#20854;&#21151;&#25928;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14907</link><description>&lt;p&gt;
&#23398;&#20064;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#20197;&#23454;&#29616;&#28151;&#21512;&#31995;&#32479;&#30340;&#23433;&#20840;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Learning Local Control Barrier Functions for Safety Control of Hybrid Systems. (arXiv:2401.14907v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14907
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21551;&#29992;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26500;&#24314;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#20445;&#35777;&#24191;&#27867;&#31867;&#21035;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#12290;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#65292;&#23545;&#21442;&#32771;&#25511;&#21046;&#22120;&#30340;&#24178;&#39044;&#26368;&#23567;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#21644;&#27604;&#36739;&#26696;&#20363;&#23637;&#31034;&#20102;&#20854;&#21151;&#25928;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#22312;&#23454;&#38469;&#30340;&#26426;&#22120;&#20154;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#24120;&#28041;&#21450;&#36830;&#32493;&#29366;&#24577;&#21644;&#31163;&#25955;&#29366;&#24577;&#20999;&#25442;&#12290;&#23433;&#20840;&#24615;&#26159;&#28151;&#21512;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#39318;&#35201;&#20851;&#27880;&#28857;&#12290;&#29616;&#26377;&#30340;&#28151;&#21512;&#31995;&#32479;&#30340;&#23433;&#20840;&#20851;&#38190;&#25511;&#21046;&#26041;&#27861;&#35201;&#20040;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#65292;&#23545;&#31995;&#32479;&#24615;&#33021;&#26377;&#25439;&#65292;&#35201;&#20040;&#20165;&#36866;&#29992;&#20110;&#23567;&#35268;&#27169;&#31995;&#32479;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21551;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65288;CBFs&#65289;&#65292;&#20197;&#20445;&#35777;&#24191;&#27867;&#31867;&#21035;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#12290;&#26368;&#32456;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#23433;&#20840;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;CBF&#20999;&#25442;&#25511;&#21046;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#65292;&#23545;&#20219;&#20309;&#21442;&#32771;&#25511;&#21046;&#22120;&#30340;&#24178;&#39044;&#26368;&#23567;&#65292;&#24182;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#31995;&#32479;&#12290;&#36890;&#36807;&#20004;&#20010;&#26426;&#22120;&#20154;&#31034;&#20363;&#65288;&#21253;&#25324;&#39640;&#32500;&#33258;&#20027;&#36187;&#36710;&#26696;&#20363;&#65289;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26694;&#26550;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#24182;&#19982;&#20854;&#20182;&#22522;&#20110;CBF&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#23637;&#31034;&#20102;&#20854;&#21151;&#25928;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hybrid dynamical systems are ubiquitous as practical robotic applications often involve both continuous states and discrete switchings. Safety is a primary concern for hybrid robotic systems. Existing safety-critical control approaches for hybrid systems are either computationally inefficient, detrimental to system performance, or limited to small-scale systems. To amend these drawbacks, in this paper, we propose a learningenabled approach to construct local Control Barrier Functions (CBFs) to guarantee the safety of a wide class of nonlinear hybrid dynamical systems. The end result is a safe neural CBFbased switching controller. Our approach is computationally efficient, minimally invasive to any reference controller, and applicable to large-scale systems. We empirically evaluate our framework and demonstrate its efficacy and flexibility through two robotic examples including a high-dimensional autonomous racing case, against other CBF-based approaches and model predictive control.
&lt;/p&gt;</description></item><item><title>Powerformer&#26159;&#19968;&#31181;&#36866;&#24212;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#65292;&#29992;&#20110;&#23398;&#20064;&#31283;&#20581;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#34920;&#31034;&#12290;&#23427;&#36890;&#36807;&#24320;&#21457;&#19987;&#29992;&#30340;&#21306;&#27573;&#33258;&#36866;&#24212;&#27880;&#24847;&#26426;&#21046;&#65292;&#24182;&#24341;&#20837;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#21644;&#22810;&#22240;&#32032;&#27880;&#24847;&#26426;&#21046;&#26469;&#25552;&#20379;&#26356;&#21152;&#31283;&#20581;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#30005;&#21147;&#31995;&#32479;&#22330;&#26223;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2401.02771</link><description>&lt;p&gt;
Powerformer&#65306;&#36866;&#24212;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#29992;&#20110;&#30005;&#21147;&#27969;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Powerformer: A Section-adaptive Transformer for Power Flow Adjustment. (arXiv:2401.02771v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02771
&lt;/p&gt;
&lt;p&gt;
Powerformer&#26159;&#19968;&#31181;&#36866;&#24212;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#65292;&#29992;&#20110;&#23398;&#20064;&#31283;&#20581;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#34920;&#31034;&#12290;&#23427;&#36890;&#36807;&#24320;&#21457;&#19987;&#29992;&#30340;&#21306;&#27573;&#33258;&#36866;&#24212;&#27880;&#24847;&#26426;&#21046;&#65292;&#24182;&#24341;&#20837;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#21644;&#22810;&#22240;&#32032;&#27880;&#24847;&#26426;&#21046;&#26469;&#25552;&#20379;&#26356;&#21152;&#31283;&#20581;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#30005;&#21147;&#31995;&#32479;&#22330;&#26223;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#20026;&#23398;&#20064;&#31283;&#20581;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#34920;&#31034;&#32780;&#37327;&#36523;&#23450;&#21046;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#65292;&#26088;&#22312;&#20248;&#21270;&#36328;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#30005;&#21147;&#35843;&#24230;&#20197;&#36827;&#34892;&#30005;&#21147;&#27969;&#35843;&#25972;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#26041;&#27861;&#21517;&#20026;Powerformer&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#19987;&#29992;&#30340;&#21306;&#27573;&#33258;&#36866;&#24212;&#27880;&#24847;&#26426;&#21046;&#65292;&#19982;&#20256;&#32479;&#21464;&#21387;&#22120;&#20013;&#20351;&#29992;&#30340;&#33258;&#27880;&#24847;&#20998;&#31163;&#24320;&#26469;&#12290;&#35813;&#26426;&#21046;&#26377;&#25928;&#22320;&#23558;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#19982;&#20256;&#36755;&#21306;&#27573;&#20449;&#24687;&#25972;&#21512;&#22312;&#19968;&#36215;&#65292;&#26377;&#21161;&#20110;&#24320;&#21457;&#31283;&#20581;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#32771;&#34385;&#30005;&#21147;&#31995;&#32479;&#30340;&#22270;&#25299;&#25169;&#21644;&#27597;&#32447;&#33410;&#28857;&#30340;&#30005;&#27668;&#23646;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#23450;&#21046;&#31574;&#30053;&#26469;&#36827;&#19968;&#27493;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#65306;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#21644;&#22810;&#22240;&#32032;&#27880;&#24847;&#26426;&#21046;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#30005;&#21147;&#31995;&#32479;&#22330;&#26223;&#65288;&#21253;&#25324;IEEE 118&#33410;&#28857;&#31995;&#32479;&#12289;&#20013;&#22269;&#23454;&#38469;300&#33410;&#28857;&#31995;&#32479;&#21644;&#19968;&#20010;&#22823;&#22411;&#31995;&#32479;&#65289;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a novel transformer architecture tailored for learning robust power system state representations, which strives to optimize power dispatch for the power flow adjustment across different transmission sections. Specifically, our proposed approach, named Powerformer, develops a dedicated section-adaptive attention mechanism, separating itself from the self-attention used in conventional transformers. This mechanism effectively integrates power system states with transmission section information, which facilitates the development of robust state representations. Furthermore, by considering the graph topology of power system and the electrical attributes of bus nodes, we introduce two customized strategies to further enhance the expressiveness: graph neural network propagation and multi-factor attention mechanism. Extensive evaluations are conducted on three power system scenarios, including the IEEE 118-bus system, a realistic 300-bus system in China, and a large-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#21452;&#26354;&#21644;&#25243;&#29289;&#22411;PDE&#30340;&#31227;&#21160;&#26102;&#22495;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;PDE&#21453;&#27493;&#27861;&#23558;&#38590;&#20197;&#35299;&#20915;&#30340;&#35266;&#27979;&#22120;PDE&#36716;&#21270;&#20026;&#21487;&#20197;&#26126;&#30830;&#35299;&#20915;&#30340;&#30446;&#26631;&#35266;&#27979;&#22120;PDE&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#23454;&#26102;&#29615;&#22659;&#19979;&#28040;&#38500;&#25968;&#20540;&#35299;&#35266;&#27979;&#22120;PDE&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.02516</link><description>&lt;p&gt;
&#22312;&#19968;&#32500;&#20013;&#20026;&#21452;&#26354;&#21644;&#25243;&#29289;&#22411;PDE&#24341;&#20837;&#31227;&#21160;&#26102;&#22495;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Moving-Horizon Estimators for Hyperbolic and Parabolic PDEs in 1-D. (arXiv:2401.02516v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#21452;&#26354;&#21644;&#25243;&#29289;&#22411;PDE&#30340;&#31227;&#21160;&#26102;&#22495;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;PDE&#21453;&#27493;&#27861;&#23558;&#38590;&#20197;&#35299;&#20915;&#30340;&#35266;&#27979;&#22120;PDE&#36716;&#21270;&#20026;&#21487;&#20197;&#26126;&#30830;&#35299;&#20915;&#30340;&#30446;&#26631;&#35266;&#27979;&#22120;PDE&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#23454;&#26102;&#29615;&#22659;&#19979;&#28040;&#38500;&#25968;&#20540;&#35299;&#35266;&#27979;&#22120;PDE&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;PDE&#30340;&#35266;&#27979;&#22120;&#26412;&#36523;&#20063;&#26159;PDE&#12290;&#22240;&#27492;&#65292;&#20351;&#29992;&#36825;&#26679;&#30340;&#35266;&#27979;&#22120;&#20135;&#29983;&#23454;&#26102;&#20272;&#35745;&#26159;&#35745;&#31639;&#36127;&#25285;&#24456;&#37325;&#30340;&#12290;&#23545;&#20110;&#26377;&#38480;&#32500;&#21644;ODE&#31995;&#32479;&#65292;&#31227;&#21160;&#26102;&#22495;&#20272;&#35745;&#22120;&#65288;MHE&#65289;&#26159;&#19968;&#31181;&#25805;&#20316;&#31526;&#65292;&#20854;&#36755;&#20986;&#26159;&#29366;&#24577;&#20272;&#35745;&#65292;&#32780;&#36755;&#20837;&#26159;&#26102;&#22495;&#36215;&#22987;&#22788;&#30340;&#21021;&#22987;&#29366;&#24577;&#20272;&#35745;&#20197;&#21450;&#31227;&#21160;&#26102;&#38388;&#22495;&#20869;&#30340;&#27979;&#37327;&#36755;&#20986;&#21644;&#36755;&#20837;&#20449;&#21495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#29992;&#20110;&#35299;&#20915;PDE&#30340;MHE&#65292;&#20197;&#28040;&#38500;&#23454;&#26102;&#25968;&#20540;&#35299;&#35266;&#27979;&#22120;PDE&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#20351;&#29992;PDE&#21453;&#27493;&#27861;&#23454;&#29616;&#20102;&#36825;&#19968;&#28857;&#65292;&#23545;&#20110;&#26576;&#20123;&#29305;&#23450;&#31867;&#21035;&#30340;&#21452;&#26354;&#21644;&#25243;&#29289;&#22411;PDE&#65292;&#23427;&#33021;&#22815;&#26126;&#30830;&#22320;&#20135;&#29983;&#31227;&#21160;&#26102;&#22495;&#29366;&#24577;&#20272;&#35745;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20026;&#20102;&#26126;&#30830;&#22320;&#20135;&#29983;&#29366;&#24577;&#20272;&#35745;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#38590;&#20197;&#35299;&#20915;&#30340;&#35266;&#27979;&#22120;PDE&#30340;&#21453;&#27493;&#21464;&#25442;&#65292;&#23558;&#20854;&#36716;&#21270;&#20026;&#19968;&#20010;&#21487;&#20197;&#26126;&#30830;&#35299;&#20915;&#30340;&#30446;&#26631;&#35266;&#27979;&#22120;PDE&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;MHE&#24182;&#19981;&#26159;&#26032;&#30340;&#35266;&#27979;&#22120;&#35774;&#35745;&#65292;&#32780;&#21482;&#26159;&#26126;&#30830;&#30340;MHE&#23454;&#29616;&#65292;&#23427;&#33021;&#22815;&#22312;&#31227;&#21160;&#26102;&#22495;&#20869;&#20135;&#29983;&#29366;&#24577;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Observers for PDEs are themselves PDEs. Therefore, producing real time estimates with such observers is computationally burdensome. For both finite-dimensional and ODE systems, moving-horizon estimators (MHE) are operators whose output is the state estimate, while their inputs are the initial state estimate at the beginning of the horizon as well as the measured output and input signals over the moving time horizon. In this paper we introduce MHEs for PDEs which remove the need for a numerical solution of an observer PDE in real time. We accomplish this using the PDE backstepping method which, for certain classes of both hyperbolic and parabolic PDEs, produces moving-horizon state estimates explicitly. Precisely, to explicitly produce the state estimates, we employ a backstepping transformation of a hard-to-solve observer PDE into a target observer PDE, which is explicitly solvable. The MHEs we propose are not new observer designs but simply the explicit MHE realizations, over a moving
&lt;/p&gt;</description></item></channel></rss>