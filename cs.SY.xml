<rss version="2.0"><channel><title>Chat Arxiv cs.SY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SY</description><item><title>&#36890;&#36807;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#27493;&#35770;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19981;&#23454;&#38469;&#25191;&#34892;&#25237;&#24433;&#27493;&#39588;&#30340;&#24773;&#20917;&#19979;&#20445;&#30041;&#25237;&#24433;&#22522;&#30784;&#20998;&#26512;&#30340;&#31616;&#21333;&#24615;&#26159;&#21487;&#33021;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.02476</link><description>&lt;p&gt;
&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;TD&#23398;&#20064;&#30340;&#31616;&#21333;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Simple Finite-Time Analysis of TD Learning with Linear Function Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02476
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#27493;&#35770;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19981;&#23454;&#38469;&#25191;&#34892;&#25237;&#24433;&#27493;&#39588;&#30340;&#24773;&#20917;&#19979;&#20445;&#30041;&#25237;&#24433;&#22522;&#30784;&#20998;&#26512;&#30340;&#31616;&#21333;&#24615;&#26159;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39532;&#23572;&#21487;&#22827;&#37319;&#26679;&#19979;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;TD&#23398;&#20064;&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#24615;&#12290;&#27492;&#35774;&#32622;&#19979;&#29616;&#26377;&#30340;&#35777;&#26126;&#35201;&#20040;&#20551;&#23450;&#31639;&#27861;&#20013;&#23384;&#22312;&#25237;&#24433;&#27493;&#39588;&#20197;&#31616;&#21270;&#20998;&#26512;&#65292;&#35201;&#20040;&#38656;&#35201;&#19968;&#20010;&#30456;&#24403;&#22797;&#26434;&#30340;&#35770;&#35777;&#26469;&#30830;&#20445;&#36845;&#20195;&#30340;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#65306;\textit{&#22312;&#19981;&#23454;&#38469;&#25191;&#34892;&#25237;&#24433;&#27493;&#39588;&#30340;&#24773;&#20917;&#19979;&#20445;&#30041;&#25237;&#24433;&#22522;&#30784;&#20998;&#26512;&#30340;&#31616;&#21333;&#24615;&#26159;&#21542;&#21487;&#33021;&#65311;}&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#36890;&#36807;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#27493;&#35770;&#35777;&#26469;&#23637;&#31034;&#36825;&#26159;&#21487;&#33021;&#30340;&#12290;&#22312;&#31532;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#24402;&#32435;&#35777;&#26126;&#65292;&#22312;&#26631;&#20934;&#36873;&#25321;&#24120;&#37327;&#27493;&#38271;$\alpha$&#19979;&#65292;&#30001;TD&#23398;&#20064;&#29983;&#25104;&#30340;&#36845;&#20195;&#20445;&#25345;&#26399;&#26395;&#19978;&#30340;&#19968;&#33268;&#26377;&#30028;&#24615;&#12290;&#22312;&#31532;&#20108;&#27493;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#36882;&#24402;&#65292;&#27169;&#25311;&#20102;TD&#23398;&#20064;&#30340;&#31283;&#24577;&#21160;&#24577;&#65292;&#21463;&#39532;&#23572;&#21487;&#22827;&#37319;&#26679;&#25928;&#26524;&#30340;$O(\alpha^2)$&#25968;&#37327;&#32423;&#19978;&#30340;&#26377;&#30028;&#25668;&#21160;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02476v1 Announce Type: new  Abstract: We study the finite-time convergence of TD learning with linear function approximation under Markovian sampling. Existing proofs for this setting either assume a projection step in the algorithm to simplify the analysis, or require a fairly intricate argument to ensure stability of the iterates. We ask: \textit{Is it possible to retain the simplicity of a projection-based analysis without actually performing a projection step in the algorithm?} Our main contribution is to show this is possible via a novel two-step argument. In the first step, we use induction to prove that under a standard choice of a constant step-size $\alpha$, the iterates generated by TD learning remain uniformly bounded in expectation. In the second step, we establish a recursion that mimics the steady-state dynamics of TD learning up to a bounded perturbation on the order of $O(\alpha^2)$ that captures the effect of Markovian sampling. Combining these pieces leads 
&lt;/p&gt;</description></item></channel></rss>