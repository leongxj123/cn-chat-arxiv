<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#24433;&#21709;&#65292;&#24182;&#21019;&#24314;&#20102;&#19987;&#38376;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;</title><link>https://arxiv.org/abs/2404.01461</link><description>&lt;p&gt;
&#35831;&#30495;&#27491;&#30340;&#29747;&#36798;&#31449;&#20986;&#26469;...&#38754;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#65311;&#22312;LLMs&#20013;&#23457;&#35270;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;
&lt;/p&gt;
&lt;p&gt;
Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01461
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#24433;&#21709;&#65292;&#24182;&#21019;&#24314;&#20102;&#19987;&#38376;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29702;&#35299;&#25991;&#26412;&#21644;&#29983;&#25104;&#31867;&#20284;&#20154;&#31867;&#25991;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#20250;&#23637;&#29616;&#20986;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#33719;&#24471;&#30340;&#20559;&#35265;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;LLMs&#21487;&#33021;&#20250;&#23481;&#26131;&#21463;&#21040;&#20154;&#31867;&#20915;&#31574;&#20013;&#30340;&#19968;&#31181;&#24120;&#35265;&#35748;&#30693;&#38519;&#38449;&#24433;&#21709;&#65292;&#21363;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#12290;&#36825;&#26159;&#24515;&#29702;&#23398;&#20013;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#25351;&#30340;&#26159;&#26681;&#25454;&#20107;&#20214;&#19982;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#21407;&#22411;&#25110;&#20856;&#22411;&#20363;&#23376;&#30340;&#30456;&#20284;&#31243;&#24230;&#26469;&#21028;&#26029;&#20107;&#20214;&#21457;&#29983;&#30340;&#21487;&#33021;&#24615;&#65292;&#32780;&#19981;&#32771;&#34385;&#26356;&#24191;&#27867;&#30340;&#20107;&#23454;&#25110;&#32479;&#35745;&#35777;&#25454;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#23545;LLM&#25512;&#29702;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;REHEAT&#65288;Representativeness Heuristic AI Testing&#65289;&#65292;&#19968;&#20010;&#21253;&#21547;&#28085;&#30422;&#20845;&#31181;&#24120;&#35265;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#31867;&#22411;&#38382;&#39064;&#30340;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#26174;&#31034;&#65292;&#24212;&#29992;&#20110;REHEAT&#30340;&#22235;&#20010;LLMs&#37117;&#34920;&#29616;&#20986;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#27169;&#22411;&#30340;&#25512;&#29702;&#27493;&#39588;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01461v1 Announce Type: new  Abstract: Although large language models (LLMs) have demonstrated remarkable proficiency in understanding text and generating human-like text, they may exhibit biases acquired from training data in doing so. Specifically, LLMs may be susceptible to a common cognitive trap in human decision-making called the representativeness heuristic. This is a concept in psychology that refers to judging the likelihood of an event based on how closely it resembles a well-known prototype or typical example versus considering broader facts or statistical evidence. This work investigates the impact of the representativeness heuristic on LLM reasoning. We created REHEAT (Representativeness Heuristic AI Testing), a dataset containing a series of problems spanning six common types of representativeness heuristics. Experiments reveal that four LLMs applied to REHEAT all exhibited representativeness heuristic biases. We further identify that the model's reasoning steps
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#39537;&#21160;&#21464;&#21387;&#22120;&#30340;&#35270;&#39057; HMR &#26694;&#26550;&#65288;DDT&#65289;&#65292;&#23427;&#26088;&#22312;&#20174;&#36755;&#20837;&#24207;&#21015;&#20013;&#35299;&#30721;&#29305;&#23450;&#30340;&#36816;&#21160;&#27169;&#24335;&#65292;&#22686;&#24378;&#36816;&#21160;&#24179;&#28369;&#24615;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#24182;&#36755;&#20986;&#25152;&#26377;&#24103;&#30340;&#20154;&#20307;&#32593;&#26684;&#65292;&#20351;&#24471; DDT &#26356;&#36866;&#29992;&#20110;&#26102;&#38388;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2303.13397</link><description>&lt;p&gt;
DDT&#65306;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#39537;&#21160;&#21464;&#21387;&#22120;&#30340;&#20174;&#35270;&#39057;&#20013;&#24674;&#22797;&#20154;&#20307;&#32593;&#26684;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
DDT: A Diffusion-Driven Transformer-based Framework for Human Mesh Recovery from a Video. (arXiv:2303.13397v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13397
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#39537;&#21160;&#21464;&#21387;&#22120;&#30340;&#35270;&#39057; HMR &#26694;&#26550;&#65288;DDT&#65289;&#65292;&#23427;&#26088;&#22312;&#20174;&#36755;&#20837;&#24207;&#21015;&#20013;&#35299;&#30721;&#29305;&#23450;&#30340;&#36816;&#21160;&#27169;&#24335;&#65292;&#22686;&#24378;&#36816;&#21160;&#24179;&#28369;&#24615;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#24182;&#36755;&#20986;&#25152;&#26377;&#24103;&#30340;&#20154;&#20307;&#32593;&#26684;&#65292;&#20351;&#24471; DDT &#26356;&#36866;&#29992;&#20110;&#26102;&#38388;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#20307;&#32593;&#26684;&#24674;&#22797;&#65288;HMR&#65289;&#20026;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#20154;&#20307;&#20449;&#24687;&#65292;&#20363;&#22914;&#28216;&#25103;&#12289;&#20154;&#26426;&#20132;&#20114;&#21644;&#34394;&#25311;&#29616;&#23454;&#12290;&#19982;&#21333;&#19968;&#22270;&#20687;&#26041;&#27861;&#30456;&#27604;&#65292;&#22522;&#20110;&#35270;&#39057;&#30340;&#26041;&#27861;&#21487;&#20197;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#36890;&#36807;&#34701;&#21512;&#20154;&#20307;&#36816;&#21160;&#20808;&#39564;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20687; VIBE &#36825;&#26679;&#30340;&#22810;&#23545;&#22810;&#26041;&#27861;&#23384;&#22312;&#36816;&#21160;&#24179;&#28369;&#24615;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#30340;&#25361;&#25112;&#12290;&#32780;&#20687; TCMR &#21644; MPS-Net &#36825;&#26679;&#30340;&#22810;&#23545;&#19968;&#26041;&#27861;&#21017;&#20381;&#36182;&#20110;&#26410;&#26469;&#24103;&#65292;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#26159;&#38750;&#22240;&#26524;&#21644;&#26102;&#38388;&#25928;&#29575;&#20302;&#19979;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#25193;&#25955;&#39537;&#21160;&#21464;&#21387;&#22120;&#30340;&#35270;&#39057; HMR &#26694;&#26550;&#65288;DDT&#65289;&#12290;DDT &#26088;&#22312;&#20174;&#36755;&#20837;&#24207;&#21015;&#20013;&#35299;&#30721;&#29305;&#23450;&#30340;&#36816;&#21160;&#27169;&#24335;&#65292;&#22686;&#24378;&#36816;&#21160;&#24179;&#28369;&#24615;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;&#20316;&#20026;&#19968;&#31181;&#22810;&#23545;&#22810;&#26041;&#27861;&#65292;DDT &#30340;&#35299;&#30721;&#22120;&#36755;&#20986;&#25152;&#26377;&#24103;&#30340;&#20154;&#20307;&#32593;&#26684;&#65292;&#20351; DDT &#26356;&#36866;&#29992;&#20110;&#26102;&#38388;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Human mesh recovery (HMR) provides rich human body information for various real-world applications such as gaming, human-computer interaction, and virtual reality. Compared to single image-based methods, video-based methods can utilize temporal information to further improve performance by incorporating human body motion priors. However, many-to-many approaches such as VIBE suffer from motion smoothness and temporal inconsistency. While many-to-one approaches such as TCMR and MPS-Net rely on the future frames, which is non-causal and time inefficient during inference. To address these challenges, a novel Diffusion-Driven Transformer-based framework (DDT) for video-based HMR is presented. DDT is designed to decode specific motion patterns from the input sequence, enhancing motion smoothness and temporal consistency. As a many-to-many approach, the decoder of our DDT outputs the human mesh of all the frames, making DDT more viable for real-world applications where time efficiency is cruc
&lt;/p&gt;</description></item></channel></rss>