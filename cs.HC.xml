<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#22240;&#26524;&#24863;&#30693;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#12290;&#24863;&#30693;&#23545;&#20915;&#31574;&#30340;&#20844;&#24179;&#24615;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#22240;&#20026;&#20844;&#24179;&#24615;&#26159;&#19982;&#32972;&#26223;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#20854;&#35299;&#37322;&#21462;&#20915;&#20110;&#35780;&#21028;&#20154;&#26159;&#35841;&#12290;</title><link>http://arxiv.org/abs/2401.13408</link><description>&lt;p&gt;
&#22240;&#26524;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Causal Perception. (arXiv:2401.13408v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13408
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#22240;&#26524;&#24863;&#30693;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#12290;&#24863;&#30693;&#23545;&#20915;&#31574;&#30340;&#20844;&#24179;&#24615;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#22240;&#20026;&#20844;&#24179;&#24615;&#26159;&#19982;&#32972;&#26223;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#20854;&#35299;&#37322;&#21462;&#20915;&#20110;&#35780;&#21028;&#20154;&#26159;&#35841;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20004;&#20010;&#20010;&#20307;&#23545;&#30456;&#21516;&#30340;&#20449;&#24687;&#36827;&#34892;&#19981;&#21516;&#35299;&#35835;&#26102;&#65292;&#24863;&#30693;&#20250;&#21457;&#29983;&#12290;&#23613;&#31649;&#36825;&#26159;&#19968;&#20010;&#24050;&#30693;&#29616;&#35937;&#65292;&#23545;&#20915;&#31574;&#20013;&#20559;&#35265;&#26377;&#24433;&#21709;&#65292;&#20294;&#26159;&#24863;&#30693;&#22312;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#20173;&#28982;&#34987;&#24573;&#35270;&#12290;&#24863;&#30693;&#23545;&#20110;ADM&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#25110;&#20844;&#24179;&#20351;&#29992;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#22240;&#20026;&#20844;&#24179;&#26412;&#36523;&#26159;&#19982;&#32972;&#26223;&#30456;&#20851;&#30340;&#65292;&#20854;&#35299;&#37322;&#21462;&#20915;&#20110;&#35780;&#21028;&#20154;&#26159;&#35841;&#12290;&#26412;&#25991;&#23558;&#24863;&#30693;&#22312;&#22240;&#26524;&#25512;&#29702;&#20013;&#24418;&#24335;&#21270;&#65292;&#20197;&#25429;&#25417;&#20010;&#20307;&#30340;&#35299;&#37322;&#34892;&#20026;&#12290;&#25105;&#20204;&#36824;&#23558;&#20010;&#20307;&#32463;&#39564;&#24418;&#24335;&#21270;&#20026;&#39069;&#22806;&#30340;&#22240;&#26524;&#30693;&#35782;&#65292;&#20010;&#20307;&#20250;&#20351;&#29992;&#36825;&#20123;&#30693;&#35782;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23450;&#20041;&#21644;&#35752;&#35770;&#20102;&#26131;&#24341;&#21457;&#24863;&#30693;&#30340;&#23646;&#24615;&#65292;&#21363;&#26131;&#24341;&#21457;&#24863;&#30693;&#30340;&#23646;&#24615;&#12290;&#25935;&#24863;&#23646;&#24615;&#65292;&#22914;&#24615;&#21035;&#21644;&#31181;&#26063;&#65292;&#23601;&#26159;&#26131;&#24341;&#21457;&#24863;&#30693;&#30340;&#26126;&#30830;&#31034;&#20363;&#12290;&#25105;&#20204;&#26681;&#25454;&#22240;&#26524;&#21407;&#21017;&#23450;&#20041;&#20102;&#20004;&#31181;&#24863;&#30693;&#65292;&#21363;&#19981;&#24544;&#23454;&#24863;&#30693;&#21644;&#19981;&#19968;&#33268;&#24863;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;
Perception occurs when two individuals interpret the same information differently. Despite being a known phenomenon with implications for bias in decision-making, as individuals' experience determines interpretation, perception remains largely overlooked in automated decision-making (ADM) systems. In particular, it can have considerable effects on the fairness or fair usage of an ADM system, as fairness itself is context-specific and its interpretation dependent on who is judging. In this work, we formalize perception under causal reasoning to capture the act of interpretation by an individual. We also formalize individual experience as additional causal knowledge that comes with and is used by an individual. Further, we define and discuss loaded attributes, which are attributes prone to evoke perception. Sensitive attributes, such as gender and race, are clear examples of loaded attributes. We define two kinds of causal perception, unfaithful and inconsistent, based on the causal prop
&lt;/p&gt;</description></item></channel></rss>