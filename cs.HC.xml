<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#35745;&#31639;&#35748;&#30693;&#31185;&#23398;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#36890;&#36807;&#35843;&#35797;&#24515;&#26234;&#27169;&#22411;&#35299;&#37322;&#20196;&#20154;&#22256;&#24785;&#31243;&#24207;&#34892;&#20026;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.05334</link><description>&lt;p&gt;
WatChat&#65306;&#36890;&#36807;&#35843;&#35797;&#24515;&#26234;&#27169;&#22411;&#35299;&#37322;&#20196;&#20154;&#22256;&#24785;&#30340;&#31243;&#24207;
&lt;/p&gt;
&lt;p&gt;
WatChat: Explaining perplexing programs by debugging mental models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05334
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#35745;&#31639;&#35748;&#30693;&#31185;&#23398;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#36890;&#36807;&#35843;&#35797;&#24515;&#26234;&#27169;&#22411;&#35299;&#37322;&#20196;&#20154;&#22256;&#24785;&#31243;&#24207;&#34892;&#20026;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#24120;&#65292;&#35299;&#37322;&#31243;&#24207;&#24847;&#22806;&#34892;&#20026;&#30340;&#19968;&#20010;&#22909;&#26041;&#27861;&#26159;&#31243;&#24207;&#21592;&#20195;&#30721;&#20013;&#30340;&#38169;&#35823;&#12290;&#20294;&#26377;&#26102;&#65292;&#19968;&#20010;&#26356;&#22909;&#30340;&#35299;&#37322;&#26159;&#31243;&#24207;&#21592;&#23545;&#25152;&#20351;&#29992;&#35821;&#35328;&#30340;&#24515;&#26234;&#27169;&#22411;&#20013;&#23384;&#22312;&#38169;&#35823;&#12290;&#25105;&#20204;&#19981;&#20165;&#20165;&#35843;&#35797;&#24403;&#21069;&#20195;&#30721;&#65288;&#8220;&#32473;&#31243;&#24207;&#21592;&#19968;&#26465;&#40060;&#8221;&#65289;&#65292;&#32780;&#26159;&#24076;&#26395;&#25105;&#20204;&#30340;&#24037;&#20855;&#33021;&#30452;&#25509;&#35843;&#35797;&#25105;&#20204;&#30340;&#24515;&#26234;&#27169;&#22411;&#65288;&#8220;&#25945;&#20250;&#31243;&#24207;&#21592;&#22914;&#20309;&#25429;&#40060;&#8221;&#65289;&#12290;&#26412;&#25991;&#23558;&#35745;&#31639;&#35748;&#30693;&#31185;&#23398;&#30340;&#24605;&#24819;&#24212;&#29992;&#21040;&#20854;&#20013;&#65292;&#23545;&#20196;&#20154;&#22256;&#24785;&#30340;&#31243;&#24207;&#65292;&#25105;&#20204;&#20351;&#29992;&#31243;&#24207;&#32508;&#21512;&#25216;&#26415;&#33258;&#21160;&#25512;&#26029;&#21487;&#33021;&#23548;&#33268;&#29992;&#25143;&#23545;&#31243;&#24207;&#34892;&#20026;&#24863;&#21040;&#24778;&#35766;&#30340;&#35823;&#35299;&#12290;&#36890;&#36807;&#20998;&#26512;&#36825;&#20123;&#35823;&#35299;&#65292;&#25105;&#20204;&#25552;&#20379;&#31616;&#26126;&#12289;&#26377;&#29992;&#30340;&#31243;&#24207;&#34892;&#20026;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#29978;&#33267;&#21487;&#20197;&#34987;&#21453;&#36716;&#65292;&#20197;&#32508;&#21512;&#25945;&#23398;&#31034;&#33539;&#31243;&#24207;&#26469;&#35786;&#26029;&#21644;&#32416;&#27491;&#23398;&#29983;&#30340;&#35823;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05334v1 Announce Type: cross  Abstract: Often, a good explanation for a program's unexpected behavior is a bug in the programmer's code. But sometimes, an even better explanation is a bug in the programmer's mental model of the language they are using. Instead of merely debugging our current code ("giving the programmer a fish"), what if our tools could directly debug our mental models ("teaching the programmer to fish")? In this paper, we apply ideas from computational cognitive science to do exactly that. Given a perplexing program, we use program synthesis techniques to automatically infer potential misconceptions that might cause the user to be surprised by the program's behavior. By analyzing these misconceptions, we provide succinct, useful explanations of the program's behavior. Our methods can even be inverted to synthesize pedagogical example programs for diagnosing and correcting misconceptions in students.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#21450;&#20854;&#35282;&#33394;&#65292;&#25351;&#20986;&#20102;&#26410;&#24320;&#21457;&#39046;&#22495;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.18659</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#28216;&#25103;&#65306;&#35843;&#30740;&#19982;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
Large Language Models and Games: A Survey and Roadmap
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18659
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#21450;&#20854;&#35282;&#33394;&#65292;&#25351;&#20986;&#20102;&#26410;&#24320;&#21457;&#39046;&#22495;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#30740;&#31350;&#24613;&#21095;&#22686;&#21152;&#65292;&#24182;&#20276;&#38543;&#30528;&#20844;&#20247;&#23545;&#35813;&#20027;&#39064;&#30340;&#21442;&#19982;&#12290;&#23613;&#31649;&#36215;&#21021;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#19968;&#23567;&#37096;&#20998;&#65292;LLMs&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#21644;&#39046;&#22495;&#20013;&#23637;&#29616;&#20986;&#26174;&#33879;&#28508;&#21147;&#65292;&#21253;&#25324;&#28216;&#25103;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;LLMs&#22312;&#28216;&#25103;&#20013;&#21450;&#20026;&#28216;&#25103;&#25552;&#20379;&#25903;&#25345;&#30340;&#21508;&#31181;&#24212;&#29992;&#30340;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#65292;&#24182;&#26126;&#30830;&#20102;LLMs&#22312;&#28216;&#25103;&#20013;&#21487;&#20197;&#25198;&#28436;&#30340;&#19981;&#21516;&#35282;&#33394;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23578;&#26410;&#24320;&#21457;&#30340;&#39046;&#22495;&#21644;LLMs&#22312;&#28216;&#25103;&#20013;&#26410;&#26469;&#24212;&#29992;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#65292;&#20197;&#21450;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;LLMs&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;&#20316;&#20026;LLMs&#21644;&#28216;&#25103;&#20132;&#21449;&#39046;&#22495;&#30340;&#31532;&#19968;&#20221;&#32508;&#21512;&#35843;&#26597;&#21644;&#36335;&#32447;&#22270;&#65292;&#25105;&#20204;&#24076;&#26395;&#26412;&#25991;&#33021;&#22815;&#25104;&#20026;&#36825;&#19968;&#28608;&#21160;&#20154;&#24515;&#30340;&#26032;&#39046;&#22495;&#30340;&#24320;&#21019;&#24615;&#30740;&#31350;&#21644;&#21019;&#26032;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18659v1 Announce Type: cross  Abstract: Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.
&lt;/p&gt;</description></item></channel></rss>