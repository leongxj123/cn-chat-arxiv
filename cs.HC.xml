<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#20154;&#26426;&#20915;&#31574;&#30340;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#31639;&#27861;&#25512;&#33616;&#23545;&#36873;&#25321;&#30340;&#24433;&#21709;&#21644;&#35774;&#35745;&#65292;&#29305;&#21035;&#20851;&#27880;&#31639;&#27861;&#23545;&#20559;&#22909;&#30340;&#25913;&#21464;&#65292;&#20197;&#35299;&#20915;&#31639;&#27861;&#36741;&#21161;&#21487;&#33021;&#24102;&#26469;&#30340;&#24847;&#22806;&#21518;&#26524;&#12290;</title><link>http://arxiv.org/abs/2208.07626</link><description>&lt;p&gt;
&#31639;&#27861;&#36741;&#21161;&#19979;&#30340;&#25512;&#33616;&#30456;&#20851;&#20559;&#22909;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Assistance with Recommendation-Dependent Preferences. (arXiv:2208.07626v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.07626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#20154;&#26426;&#20915;&#31574;&#30340;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#31639;&#27861;&#25512;&#33616;&#23545;&#36873;&#25321;&#30340;&#24433;&#21709;&#21644;&#35774;&#35745;&#65292;&#29305;&#21035;&#20851;&#27880;&#31639;&#27861;&#23545;&#20559;&#22909;&#30340;&#25913;&#21464;&#65292;&#20197;&#35299;&#20915;&#31639;&#27861;&#36741;&#21161;&#21487;&#33021;&#24102;&#26469;&#30340;&#24847;&#22806;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#31639;&#27861;&#25552;&#20379;&#39118;&#38505;&#35780;&#20272;&#26102;&#65292;&#25105;&#20204;&#36890;&#24120;&#23558;&#20854;&#35270;&#20026;&#23545;&#20154;&#31867;&#20915;&#31574;&#30340;&#26377;&#30410;&#36755;&#20837;&#65292;&#20363;&#22914;&#23558;&#39118;&#38505;&#35780;&#20998;&#21576;&#29616;&#32473;&#27861;&#23448;&#25110;&#21307;&#29983;&#12290;&#28982;&#32780;&#65292;&#20915;&#31574;&#32773;&#21487;&#33021;&#19981;&#20165;&#20165;&#21482;&#38024;&#23545;&#31639;&#27861;&#25552;&#20379;&#30340;&#20449;&#24687;&#20570;&#20986;&#21453;&#24212;&#12290;&#20915;&#31574;&#32773;&#36824;&#21487;&#33021;&#23558;&#31639;&#27861;&#25512;&#33616;&#35270;&#20026;&#40664;&#35748;&#25805;&#20316;&#65292;&#20351;&#20854;&#38590;&#20197;&#20559;&#31163;&#65292;&#20363;&#22914;&#27861;&#23448;&#22312;&#23545;&#34987;&#21578;&#36827;&#34892;&#39640;&#39118;&#38505;&#35780;&#20272;&#30340;&#26102;&#20505;&#19981;&#24895;&#24847;&#25512;&#32763;&#65292;&#25110;&#21307;&#29983;&#25285;&#24515;&#20559;&#31163;&#25512;&#33616;&#30340;&#31243;&#24207;&#20250;&#24102;&#26469;&#21518;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#31639;&#27861;&#36741;&#21161;&#30340;&#36825;&#31181;&#24847;&#22806;&#21518;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#20154;&#26426;&#20915;&#31574;&#30340;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#31639;&#27861;&#25512;&#33616;&#23545;&#36873;&#25321;&#30340;&#24433;&#21709;&#21644;&#35774;&#35745;&#65292;&#36825;&#31181;&#24433;&#21709;&#19981;&#20165;&#20165;&#26159;&#36890;&#36807;&#25913;&#21464;&#20449;&#24565;&#65292;&#36824;&#36890;&#36807;&#25913;&#21464;&#20559;&#22909;&#12290;&#25105;&#20204;&#20174;&#21046;&#24230;&#22240;&#32032;&#21644;&#34892;&#20026;&#32463;&#27982;&#23398;&#20013;&#30340;&#24050;&#26377;&#27169;&#22411;&#31561;&#26041;&#38754;&#36827;&#34892;&#20102;&#36825;&#20010;&#20551;&#35774;&#30340;&#21160;&#26426;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
When an algorithm provides risk assessments, we typically think of them as helpful inputs to human decisions, such as when risk scores are presented to judges or doctors. However, a decision-maker may not only react to the information provided by the algorithm. The decision-maker may also view the algorithmic recommendation as a default action, making it costly for them to deviate, such as when a judge is reluctant to overrule a high-risk assessment for a defendant or a doctor fears the consequences of deviating from recommended procedures. To address such unintended consequences of algorithmic assistance, we propose a principal-agent model of joint human-machine decision-making. Within this model, we consider the effect and design of algorithmic recommendations when they affect choices not just by shifting beliefs, but also by altering preferences. We motivate this assumption from institutional factors, such as a desire to avoid audits, as well as from well-established models in behav
&lt;/p&gt;</description></item></channel></rss>