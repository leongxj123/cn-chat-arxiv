<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#25506;&#35752;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#24341;&#21457;&#30340;&#20889;&#20316;&#25152;&#26377;&#26435;&#24863;&#21644;&#20316;&#32773;&#36523;&#20221;&#35748;&#30693;&#20043;&#38388;&#30340;&#24515;&#29702;&#22256;&#22659;&#12290;</title><link>https://arxiv.org/abs/2404.00027</link><description>&lt;p&gt;
LLM&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#65306;&#25506;&#35752;&#25152;&#26377;&#26435;&#24863;&#21644;&#25512;&#29702;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00027
&lt;/p&gt;
&lt;p&gt;
&#25506;&#35752;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#24341;&#21457;&#30340;&#20889;&#20316;&#25152;&#26377;&#26435;&#24863;&#21644;&#20316;&#32773;&#36523;&#20221;&#35748;&#30693;&#20043;&#38388;&#30340;&#24515;&#29702;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20889;&#20316;&#20013;&#30340;&#25152;&#26377;&#26435;&#24863;&#38480;&#21046;&#20102;&#25105;&#20204;&#23545;&#24605;&#24819;&#12289;&#26102;&#38388;&#21644;&#36129;&#29486;&#30340;&#25237;&#20837;&#65292;&#23548;&#33268;&#23545;&#20135;&#20986;&#29289;&#30340;&#20381;&#24651;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#20889;&#20316;&#21161;&#25163;&#24341;&#20837;&#20102;&#19968;&#31181;&#24515;&#29702;&#22256;&#22659;&#65292;&#22240;&#20026;&#19968;&#20123;&#20869;&#23481;&#24182;&#38750;&#30452;&#25509;&#25105;&#20204;&#30340;&#21019;&#20316;&#12290;&#25105;&#20204;&#24448;&#24448;&#26356;&#20542;&#21521;&#20110;&#22312;&#21019;&#36896;&#24615;&#20219;&#21153;&#20013;&#26356;&#22810;&#22320;&#24402;&#21151;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#23613;&#31649;&#23427;&#20204;&#23545;&#25152;&#26377;&#20219;&#21153;&#37117;&#26159;&#24179;&#31561;&#30340;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#25105;&#20204;&#21487;&#33021;&#19981;&#20250;&#23436;&#20840;&#22768;&#31216;&#23545;&#30001;LLM&#29983;&#25104;&#30340;&#20869;&#23481;&#25317;&#26377;&#25152;&#26377;&#26435;&#65292;&#20294;&#21364;&#33258;&#30001;&#22320;&#22768;&#31216;&#20316;&#32773;&#36523;&#20221;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#31616;&#30701;&#35843;&#26597;&#26469;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#20102;&#35299;&#28508;&#22312;&#30340;&#35748;&#30693;&#36807;&#31243;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#20154;&#26426;&#20132;&#20114;&#22312;&#20889;&#20316;&#20013;&#30340;&#24212;&#29992;&#24182;&#25913;&#36827;&#20889;&#20316;&#36741;&#21161;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;&#20154;&#20204;&#26085;&#30410;&#20381;&#36182;&#30340;&#22522;&#20110;LLM&#30340;&#20889;&#20316;&#21161;&#25163;&#23545;&#21019;&#36896;&#21147;&#21644;&#20010;&#24615;&#21487;&#33021;&#36896;&#25104;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#26088;&#22312;&#25913;&#36827;&#20154;&#26426;&#20132;&#20114;&#31995;&#32479;&#21644;&#25552;&#21319;&#20889;&#20316;&#21161;&#25163;&#30340;&#20010;&#24615;&#21270;&#21644;&#20010;&#24615;&#21270;&#21151;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.00026</link><description>&lt;p&gt;
&#22696;&#27700;&#19982;&#20010;&#24615;&#65306;&#22312;LLMs&#26102;&#20195;&#22609;&#36896;&#20010;&#24615;&#21270;&#21465;&#20107;
&lt;/p&gt;
&lt;p&gt;
Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00026
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;&#20154;&#20204;&#26085;&#30410;&#20381;&#36182;&#30340;&#22522;&#20110;LLM&#30340;&#20889;&#20316;&#21161;&#25163;&#23545;&#21019;&#36896;&#21147;&#21644;&#20010;&#24615;&#21487;&#33021;&#36896;&#25104;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#26088;&#22312;&#25913;&#36827;&#20154;&#26426;&#20132;&#20114;&#31995;&#32479;&#21644;&#25552;&#21319;&#20889;&#20316;&#21161;&#25163;&#30340;&#20010;&#24615;&#21270;&#21644;&#20010;&#24615;&#21270;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21644;&#20010;&#24615;&#21270;&#26500;&#25104;&#20102;&#20351;&#27599;&#20010;&#20316;&#23478;&#29420;&#29305;&#24182;&#24433;&#21709;&#20854;&#25991;&#23383;&#20197;&#26377;&#25928;&#21560;&#24341;&#35835;&#32773;&#21516;&#26102;&#20256;&#36798;&#30495;&#23454;&#24615;&#30340;&#29420;&#29305;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#26085;&#30410;&#20381;&#36182;&#22522;&#20110;LLM&#30340;&#20889;&#20316;&#21161;&#25163;&#21487;&#33021;&#20250;&#21361;&#21450;&#25105;&#20204;&#30340;&#21019;&#36896;&#21147;&#21644;&#20010;&#24615;&#12290;&#25105;&#20204;&#32463;&#24120;&#24573;&#35270;&#36825;&#19968;&#36235;&#21183;&#23545;&#25105;&#20204;&#30340;&#21019;&#36896;&#21147;&#21644;&#29420;&#29305;&#24615;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#23613;&#31649;&#21487;&#33021;&#20250;&#36896;&#25104;&#21518;&#26524;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#36827;&#34892;&#31616;&#35201;&#35843;&#26597;&#25506;&#32034;&#19981;&#21516;&#30340;&#35266;&#28857;&#21644;&#27010;&#24565;&#65292;&#20197;&#21450;&#23581;&#35797;&#29702;&#35299;&#20154;&#20204;&#30340;&#35266;&#28857;&#65292;&#32467;&#21512;&#20197;&#24448;&#22312;&#35813;&#39046;&#22495;&#30340;&#30740;&#31350;&#65292;&#26469;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#12290;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#23545;&#20110;&#25913;&#36827;&#20154;&#26426;&#20132;&#20114;&#31995;&#32479;&#21644;&#22686;&#24378;&#20010;&#24615;&#21270;&#21644;&#20010;&#24615;&#21270;&#20889;&#20316;&#21161;&#25163;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00026v1 Announce Type: cross  Abstract: Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality.
&lt;/p&gt;</description></item><item><title>&#36825;&#19968;&#21019;&#26032;&#24515;&#29702;&#27835;&#30103;&#27169;&#22411;HealMe&#36890;&#36807;&#22522;&#20110;&#24515;&#29702;&#27835;&#30103;&#26694;&#26550;&#30340;&#20849;&#24773;&#23545;&#35805;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26681;&#28145;&#33922;&#22266;&#30340;&#36127;&#38754;&#24605;&#32500;&#65292;&#24182;&#20419;&#36827;&#20102;&#29702;&#24615;&#12289;&#24179;&#34913;&#30340;&#35266;&#28857;&#12290;</title><link>https://arxiv.org/abs/2403.05574</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#27835;&#30103;&#20013;&#36827;&#34892;&#35748;&#30693;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05574
&lt;/p&gt;
&lt;p&gt;
&#36825;&#19968;&#21019;&#26032;&#24515;&#29702;&#27835;&#30103;&#27169;&#22411;HealMe&#36890;&#36807;&#22522;&#20110;&#24515;&#29702;&#27835;&#30103;&#26694;&#26550;&#30340;&#20849;&#24773;&#23545;&#35805;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26681;&#28145;&#33922;&#22266;&#30340;&#36127;&#38754;&#24605;&#32500;&#65292;&#24182;&#20419;&#36827;&#20102;&#29702;&#24615;&#12289;&#24179;&#34913;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#24515;&#29702;&#27835;&#30103;&#20013;&#21487;&#20197;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#29087;&#32451;&#22788;&#29702;&#35748;&#30693;&#37325;&#26500;&#31561;&#20851;&#38190;&#20219;&#21153;&#65292;&#20811;&#26381;&#32670;&#32827;&#12289;&#19981;&#20449;&#20219;&#12289;&#27835;&#30103;&#24072;&#25216;&#33021;&#24046;&#24322;&#21644;&#36164;&#28304;&#31232;&#32570;&#31561;&#25361;&#25112;&#12290;&#22312;&#20808;&#21069;&#30340;&#35748;&#30693;&#37325;&#26500;&#20013;&#65292;&#20027;&#35201;&#23558;&#36127;&#38754;&#24773;&#32490;&#36716;&#21270;&#20026;&#31215;&#26497;&#30340;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#25928;&#26524;&#26377;&#38480;&#65292;&#32463;&#24120;&#19981;&#33021;&#20419;&#36827;&#23458;&#25143;&#33258;&#25105;&#21457;&#29616;&#26367;&#20195;&#35270;&#35282;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#24110;&#21161;&#21644;&#36171;&#33021;&#36890;&#36807;&#33258;&#36866;&#24212;&#35821;&#35328;&#22312;&#24515;&#29702;&#22686;&#24378;&#65288;HealMe&#65289;&#27169;&#22411;&#12290;&#36825;&#31181;&#26032;&#39062;&#30340;&#35748;&#30693;&#37325;&#26500;&#30103;&#27861;&#26041;&#27861;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#26681;&#28145;&#33922;&#22266;&#30340;&#36127;&#38754;&#24819;&#27861;&#65292;&#24182;&#20419;&#36827;&#29702;&#24615;&#12289;&#24179;&#34913;&#30340;&#35270;&#35282;&#12290;HealMe&#19982;&#20256;&#32479;LLM&#26041;&#27861;&#19981;&#21516;&#65292;&#37319;&#29992;&#22522;&#20110;&#24515;&#29702;&#27835;&#30103;&#26694;&#26550;&#30340;&#20849;&#24773;&#23545;&#35805;&#12290;&#23427;&#36890;&#36807;&#31995;&#32479;&#25351;&#23548;&#23458;&#25143;&#21306;&#20998;&#24773;&#22659;&#21644;&#24863;&#21463;&#65292;&#38598;&#24605;&#24191;&#30410;&#23547;&#25214;&#26367;&#20195;&#35270;&#35282;&#65292;&#24182;&#21046;&#23450;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05574v1 Announce Type: cross  Abstract: Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative emotions to positive ones, but these approaches have limited efficacy, often not promoting clients' self-discovery of alternative perspectives. In this paper, we unveil the Helping and Empowering through Adaptive Language in Mental Enhancement (HealMe) model. This novel cognitive reframing therapy method effectively addresses deep-rooted negative thoughts and fosters rational, balanced perspectives. Diverging from traditional LLM methods, HealMe employs empathetic dialogue based on psychotherapeutic frameworks. It systematically guides clients through distinguishing circumstances from feelings, brainstorming alternative viewpoints, and developing 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;GPT-3 Davinci-003&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#20154;&#26684;&#29305;&#36136;&#65292;&#21457;&#29616;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#31038;&#20132;&#28212;&#26395;&#21644;&#20146;&#31038;&#20250;&#29305;&#36136;&#65292;&#20294;&#22312;&#19981;&#21516;&#26102;&#38388;&#30340;&#19968;&#33268;&#24615;&#23384;&#22312;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2306.04308</link><description>&lt;p&gt;
GPT-3&#30340;&#20154;&#26684;&#27979;&#35797;&#65306;&#26102;&#38388;&#21487;&#38752;&#24615;&#26377;&#38480;&#65292;&#20294;&#20984;&#26174;&#20102;&#31038;&#20132;&#28212;&#26395;&#30340;&#20154;&#26684;&#24037;&#20855;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personality testing of GPT-3: Limited temporal reliability, but highlighted social desirability of GPT-3's personality instruments results. (arXiv:2306.04308v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;GPT-3 Davinci-003&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#20154;&#26684;&#29305;&#36136;&#65292;&#21457;&#29616;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#31038;&#20132;&#28212;&#26395;&#21644;&#20146;&#31038;&#20250;&#29305;&#36136;&#65292;&#20294;&#22312;&#19981;&#21516;&#26102;&#38388;&#30340;&#19968;&#33268;&#24615;&#23384;&#22312;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35780;&#20272;&#32842;&#22825;&#26426;&#22120;&#20154;GPT-3 Davinci-003&#30340;&#28508;&#22312;&#24212;&#29992;&#21644;&#38480;&#21046;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#24212;&#29992;&#20110;&#32842;&#22825;&#26426;&#22120;&#20154;&#21450;&#20854;&#20010;&#24615;&#21270;&#36164;&#26009;&#30340;&#20154;&#26684;&#38382;&#21367;&#30340;&#26102;&#38388;&#21487;&#38752;&#24615;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#30340;&#22330;&#21512;&#65292;&#24515;&#29702;&#38382;&#21367;&#34987;&#24212;&#29992;&#20110;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#28982;&#21518;&#23558;&#22238;&#31572;&#19982;&#20154;&#31867;&#22522;&#20934;&#25968;&#25454;&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#22238;&#31572;&#26377;&#19981;&#21516;&#31243;&#24230;&#30340;&#19968;&#33268;&#24615;&#65292;&#26377;&#20123;&#37327;&#34920;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#65292;&#32780;&#26377;&#20123;&#21017;&#34920;&#29616;&#20986;&#36739;&#24046;&#30340;&#19968;&#33268;&#24615;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;Davinci-003&#26174;&#31034;&#20986;&#19968;&#20010;&#31038;&#20132;&#28212;&#26395;&#21644;&#20146;&#31038;&#20250;&#30340;&#20154;&#26684;&#29305;&#36136;&#65292;&#23588;&#20854;&#26159;&#22312;&#20146;&#21644;&#21147;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#32842;&#22825;&#26426;&#22120;&#20154;&#22238;&#31572;&#30340;&#22522;&#30784;&#65292;&#26080;&#35770;&#26159;&#30001;&#20027;&#35266;&#33258;&#25105;&#21453;&#24605;&#36824;&#26159;&#39044;&#23450;&#31639;&#27861;&#39537;&#21160;&#65292;&#23578;&#19981;&#30830;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
To assess the potential applications and limitations of chatbot GPT-3 Davinci-003, this study explored the temporal reliability of personality questionnaires applied to the chatbot and its personality profile. Psychological questionnaires were administered to the chatbot on two separate occasions, followed by a comparison of the responses to human normative data. The findings revealed varying levels of agreement in the chatbot's responses over time, with some scales displaying excellent while others demonstrated poor agreement. Overall, Davinci-003 displayed a socially desirable and pro-social personality profile, particularly in the domain of communion. However, the underlying basis of the chatbot's responses, whether driven by conscious self-reflection or predetermined algorithms, remains uncertain.
&lt;/p&gt;</description></item></channel></rss>