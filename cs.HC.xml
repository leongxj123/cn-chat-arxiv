<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#20154;&#24037;&#26234;&#33021;&#21512;&#20316;&#30340;&#37325;&#35201;&#24615;&#65292;&#24378;&#35843;&#20102;&#36825;&#20123;&#27169;&#22411;&#22914;&#20309;&#36229;&#36234;&#20256;&#32479;&#26041;&#27861;&#22686;&#24378;&#21327;&#20316;&#26234;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#22686;&#24378;&#20154;&#31867;&#33021;&#21147;&#12289;&#25913;&#21892;AI&#27169;&#22411;&#12289;&#26377;&#25928;&#22242;&#38431;&#21512;&#20316;&#12289;&#36947;&#24503;&#32771;&#34385;&#20197;&#21450;&#22312;&#21508;&#20010;&#39046;&#22495;&#24191;&#27867;&#24212;&#29992;&#26041;&#38754;&#30340;&#28508;&#22312;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.04931</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#19982;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#21512;&#20316;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Human-AI Teaming with Large Pre-Trained Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#20154;&#24037;&#26234;&#33021;&#21512;&#20316;&#30340;&#37325;&#35201;&#24615;&#65292;&#24378;&#35843;&#20102;&#36825;&#20123;&#27169;&#22411;&#22914;&#20309;&#36229;&#36234;&#20256;&#32479;&#26041;&#27861;&#22686;&#24378;&#21327;&#20316;&#26234;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#22686;&#24378;&#20154;&#31867;&#33021;&#21147;&#12289;&#25913;&#21892;AI&#27169;&#22411;&#12289;&#26377;&#25928;&#22242;&#38431;&#21512;&#20316;&#12289;&#36947;&#24503;&#32771;&#34385;&#20197;&#21450;&#22312;&#21508;&#20010;&#39046;&#22495;&#24191;&#27867;&#24212;&#29992;&#26041;&#38754;&#30340;&#28508;&#22312;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#36805;&#36895;&#21457;&#23637;&#30340;&#26223;&#35266;&#20013;&#65292;&#20154;&#31867;&#26234;&#33021;&#21644;AI&#31995;&#32479;&#20043;&#38388;&#30340;&#21327;&#20316;&#65292;&#21363;&#20154;&#24037;&#26234;&#33021;&#65288;HAI&#65289;&#21512;&#20316;&#65292;&#24050;&#25104;&#20026;&#25512;&#36827;&#38382;&#39064;&#35299;&#20915;&#21644;&#20915;&#31574;&#36807;&#31243;&#30340;&#22522;&#30707;&#12290;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;LPtM&#65289;&#30340;&#20986;&#29616;&#26174;&#33879;&#25913;&#21464;&#20102;&#36825;&#19968;&#26223;&#35266;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#37327;&#25968;&#25454;&#26469;&#29702;&#35299;&#21644;&#39044;&#27979;&#22797;&#26434;&#27169;&#24335;&#65292;&#20026;&#20154;&#31867;&#25552;&#20379;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;LPtMs&#19982;HAI&#30340;&#20851;&#38190;&#25972;&#21512;&#65292;&#24378;&#35843;&#20102;&#36825;&#20123;&#27169;&#22411;&#22914;&#20309;&#36229;&#36234;&#20256;&#32479;&#26041;&#27861;&#22686;&#24378;&#21327;&#20316;&#26234;&#33021;&#12290;&#37325;&#28857;&#25506;&#35752;&#20102;LPtMs&#22312;&#22686;&#24378;&#20154;&#31867;&#33021;&#21147;&#26041;&#38754;&#30340;&#21327;&#21516;&#28508;&#21147;&#65292;&#35752;&#35770;&#20102;&#36825;&#31181;&#21327;&#20316;&#23545;AI&#27169;&#22411;&#25913;&#36827;&#12289;&#26377;&#25928;&#30340;&#22242;&#38431;&#21512;&#20316;&#12289;&#36947;&#24503;&#32771;&#34385;&#20197;&#21450;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#24433;&#21709;&#12290;&#36890;&#36807;&#36825;&#19968;&#25506;&#32034;&#65292;&#30740;&#31350;&#25581;&#31034;&#20102;LPtM&#22686;&#24378;HAI&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04931v1 Announce Type: new  Abstract: In the rapidly evolving landscape of artificial intelligence (AI), the collaboration between human intelligence and AI systems, known as Human-AI (HAI) Teaming, has emerged as a cornerstone for advancing problem-solving and decision-making processes. The advent of Large Pre-trained Models (LPtM) has significantly transformed this landscape, offering unprecedented capabilities by leveraging vast amounts of data to understand and predict complex patterns. This paper surveys the pivotal integration of LPtMs with HAI, emphasizing how these models enhance collaborative intelligence beyond traditional approaches. It examines the synergistic potential of LPtMs in augmenting human capabilities, discussing this collaboration for AI model improvements, effective teaming, ethical considerations, and their broad applied implications in various sectors. Through this exploration, the study sheds light on the transformative impact of LPtM-enhanced HAI 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35780;&#20272;GPT3.5&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20855;&#26377;&#26377;&#36259;&#30340;&#20010;&#24615;&#38382;&#21367;&#22238;&#31572;&#33021;&#21147;&#65292;&#20294;&#19981;&#22826;&#21487;&#33021;&#21457;&#23637;&#20986;&#24847;&#35782;&#65292;&#24182;&#26174;&#31034;&#20986;&#36739;&#22823;&#30340;&#35748;&#30693;&#21644;&#20010;&#24615;&#21464;&#24322;&#12290;</title><link>http://arxiv.org/abs/2309.07683</link><description>&lt;p&gt;
&#35780;&#20272;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#36136;&#65306;&#23545;&#20154;&#31867;&#20013;&#24515;&#20027;&#20041;&#30340;&#35686;&#21578;
&lt;/p&gt;
&lt;p&gt;
Assessing the nature of large language models: A caution against anthropocentrism. (arXiv:2309.07683v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07683
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35780;&#20272;GPT3.5&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20855;&#26377;&#26377;&#36259;&#30340;&#20010;&#24615;&#38382;&#21367;&#22238;&#31572;&#33021;&#21147;&#65292;&#20294;&#19981;&#22826;&#21487;&#33021;&#21457;&#23637;&#20986;&#24847;&#35782;&#65292;&#24182;&#26174;&#31034;&#20986;&#36739;&#22823;&#30340;&#35748;&#30693;&#21644;&#20010;&#24615;&#21464;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#36890;&#36807;OpenAI&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;ChatGPT&#30340;&#21457;&#24067;&#24341;&#36215;&#20102;&#20844;&#20247;&#30340;&#20851;&#27880;&#21644;&#29468;&#27979;&#12290;&#30446;&#21069;&#23384;&#22312;&#20004;&#31181;&#24847;&#35265;&#38453;&#33829;&#65306;&#19968;&#26041;&#23545;&#36825;&#20123;&#27169;&#22411;&#20026;&#20154;&#31867;&#20219;&#21153;&#24102;&#26469;&#30340;&#22522;&#26412;&#21464;&#38761;&#30340;&#21487;&#33021;&#24615;&#24863;&#21040;&#20852;&#22859;&#65292;&#21478;&#19968;&#26041;&#23545;&#36825;&#20123;&#27169;&#22411;&#30340;&#24378;&#22823;&#33021;&#21147;&#24863;&#21040;&#39640;&#24230;&#20851;&#20999;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#20851;&#20999;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#26631;&#20934;&#12289;&#35268;&#33539;&#21270;&#21644;&#32463;&#36807;&#39564;&#35777;&#30340;&#35748;&#30693;&#21644;&#20010;&#24615;&#27979;&#37327;&#24037;&#20855;&#26469;&#35780;&#20272;GPT3.5&#12290;&#22312;&#36825;&#20010;&#21021;&#27493;&#39033;&#30446;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#22871;&#27979;&#35797;&#65292;&#21487;&#20197;&#20272;&#35745;&#36825;&#20123;&#27169;&#22411;&#30340;&#33021;&#21147;&#36793;&#30028;&#65292;&#23427;&#20204;&#22312;&#30701;&#26102;&#38388;&#20869;&#30340;&#31283;&#23450;&#24615;&#20197;&#21450;&#19982;&#20154;&#31867;&#30340;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;GPT 3.5&#24456;&#21487;&#33021;&#27809;&#26377;&#20135;&#29983;&#24847;&#35782;&#65292;&#23613;&#31649;&#23427;&#23545;&#20010;&#24615;&#38382;&#21367;&#30340;&#22238;&#31572;&#33021;&#21147;&#20196;&#20154;&#24863;&#20852;&#36259;&#12290;&#23427;&#22312;&#37325;&#22797;&#35266;&#23519;&#36807;&#31243;&#20013;&#26174;&#31034;&#20986;&#35748;&#30693;&#21644;&#20010;&#24615;&#27979;&#37327;&#26041;&#38754;&#30340;&#22823;&#37327;&#21464;&#24322;&#65292;&#36825;&#19982;&#20855;&#26377;&#20154;&#31867;&#33324;&#20010;&#24615;&#30340;&#27169;&#22411;&#26159;&#19981;&#31526;&#21512;&#39044;&#26399;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI models garnered a large amount of public attention and speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion camps exist: one excited about possibilities these models offer for fundamental changes to human tasks, and another highly concerned about power these models seem to have. To address these concerns, we assessed GPT3.5 using standard, normed, and validated cognitive and personality measures. For this seedling project, we developed a battery of tests that allowed us to estimate the boundaries of some of these models capabilities, how stable those capabilities are over a short period of time, and how they compare to humans.  Our results indicate that GPT 3.5 is unlikely to have developed sentience, although its ability to respond to personality inventories is interesting. It did display large variability in both cognitive and personality measures over repeated observations, which is not expected if it had a human-like personality. Variability 
&lt;/p&gt;</description></item></channel></rss>