<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#23558;&#20154;&#24037;&#26234;&#33021;&#38598;&#25104;&#21040;&#26426;&#26800;&#33218;&#30340;&#20849;&#20139;&#25511;&#21046;&#33539;&#24335;&#20013;&#65292;&#20197;&#24110;&#21161;&#36816;&#21160;&#21463;&#25439;&#20154;&#22763;&#23454;&#29616;&#26356;&#39640;&#31243;&#24230;&#30340;&#20010;&#20154;&#33258;&#27835;&#12290;</title><link>http://arxiv.org/abs/2306.13509</link><description>&lt;p&gt;
&#25506;&#32034;AI&#22686;&#24378;&#30340;&#21327;&#20316;&#25511;&#21046;&#23545;&#20110;&#36741;&#21161;&#26426;&#26800;&#33218;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Exploring AI-enhanced Shared Control for an Assistive Robotic Arm. (arXiv:2306.13509v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#23558;&#20154;&#24037;&#26234;&#33021;&#38598;&#25104;&#21040;&#26426;&#26800;&#33218;&#30340;&#20849;&#20139;&#25511;&#21046;&#33539;&#24335;&#20013;&#65292;&#20197;&#24110;&#21161;&#36816;&#21160;&#21463;&#25439;&#20154;&#22763;&#23454;&#29616;&#26356;&#39640;&#31243;&#24230;&#30340;&#20010;&#20154;&#33258;&#27835;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36741;&#21161;&#25216;&#26415;&#65292;&#29305;&#21035;&#26159;&#36741;&#21161;&#26426;&#26800;&#33218;&#24050;&#32463;&#25104;&#20026;&#24110;&#21161;&#36816;&#21160;&#21463;&#25439;&#20154;&#22763;&#23454;&#29616;&#33258;&#20027;&#29983;&#27963;&#30340;&#21487;&#33021;&#24615;&#12290;&#36817;&#24180;&#26469;&#65292;&#36234;&#26469;&#36234;&#22810;&#36825;&#26679;&#30340;&#31995;&#32479;&#24050;&#32463;&#38754;&#21521;&#26368;&#32456;&#29992;&#25143;&#25552;&#20379;&#65292;&#20363;&#22914;Kinova Jaco&#26426;&#26800;&#33218;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22823;&#22810;&#38656;&#35201;&#22797;&#26434;&#30340;&#25163;&#21160;&#25511;&#21046;&#65292;&#36825;&#21487;&#33021;&#20250;&#20351;&#29992;&#25143;&#19981;&#22570;&#37325;&#36127;&#12290;&#22240;&#27492;&#65292;&#30740;&#31350;&#20154;&#21592;&#25506;&#32034;&#35753;&#36825;&#20123;&#26426;&#22120;&#20154;&#33258;&#20027;&#34892;&#21160;&#30340;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#33267;&#23569;&#23545;&#20110;&#36825;&#20010;&#29305;&#23450;&#30340;&#29992;&#25143;&#32676;&#20307;&#26469;&#35828;&#65292;&#36825;&#31181;&#26041;&#27861;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#24466;&#21171;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#29992;&#25143;&#24076;&#26395;&#20445;&#25345;&#25511;&#21046;&#26435;&#20197;&#23454;&#29616;&#26356;&#39640;&#31243;&#24230;&#30340;&#20010;&#20154;&#33258;&#27835;&#65292;&#20294;&#33258;&#20027;&#30340;&#26426;&#22120;&#20154;&#19982;&#27492;&#30456;&#21453;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22914;&#20309;&#23558;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#38598;&#25104;&#21040;&#20849;&#20139;&#25511;&#21046;&#33539;&#24335;&#20013;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20851;&#27880;&#20102;&#20154;&#19982;&#26426;&#22120;&#20154;&#20043;&#38388;&#30028;&#38754;&#30340;&#24517;&#35201;&#35201;&#27714;&#65292;&#20197;&#21450;&#22914;&#20309;&#22312;&#26174;&#33879;&#20943;&#23569;&#24515;&#29702;&#36127;&#25285;&#21644;&#25152;&#38656;&#30340;&#26426;&#21160;&#33021;&#21147;&#30340;&#21516;&#26102;&#20445;&#25345;&#20154;&#31867;&#30340;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assistive technologies and in particular assistive robotic arms have the potential to enable people with motor impairments to live a self-determined life. More and more of these systems have become available for end users in recent years, such as the Kinova Jaco robotic arm. However, they mostly require complex manual control, which can overwhelm users. As a result, researchers have explored ways to let such robots act autonomously. However, at least for this specific group of users, such an approach has shown to be futile. Here, users want to stay in control to achieve a higher level of personal autonomy, to which an autonomous robot runs counter. In our research, we explore how Artifical Intelligence (AI) can be integrated into a shared control paradigm. In particular, we focus on the consequential requirements for the interface between human and robot and how we can keep humans in the loop while still significantly reducing the mental load and required motor skills.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#24403;&#21069;&#26368;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#24314;&#31569;&#24418;&#24335;&#30340;3D&#23545;&#35937;&#29983;&#25104;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#23578;&#26410;&#20805;&#20998;&#25506;&#35752;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#37325;&#28857;&#35758;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.00510</link><description>&lt;p&gt;
&#36890;&#21521;&#33258;&#30001;&#35745;&#31639;&#26550;&#26500;: &#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#29983;&#25104;&#20803;&#23431;&#23449;&#34394;&#25311;&#24314;&#31569;&#30340;&#32508;&#21512;&#35843;&#30740;
&lt;/p&gt;
&lt;p&gt;
Towards Computational Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture in the Metaverse. (arXiv:2305.00510v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#24403;&#21069;&#26368;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#24314;&#31569;&#24418;&#24335;&#30340;3D&#23545;&#35937;&#29983;&#25104;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#23578;&#26410;&#20805;&#20998;&#25506;&#35752;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#37325;&#28857;&#35758;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;3D&#24418;&#29366;&#29983;&#25104;&#25216;&#26415;&#27491;&#22312;&#21463;&#21040;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#24314;&#31569;&#35774;&#35745;&#20004;&#26041;&#30340;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#26412;&#32508;&#21512;&#35843;&#26597;&#26088;&#22312;&#35843;&#26597;&#21644;&#27604;&#36739;&#24403;&#21069;&#26368;&#26032;&#30340;&#22522;&#20110;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65288;DGMs&#65289;&#30340;3D&#23545;&#35937;&#29983;&#25104;&#26041;&#27861;&#65292;&#21253;&#25324;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#12289;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#12289;3D&#24863;&#30693;&#22270;&#20687;&#21644;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;187&#31687;&#25991;&#31456;(&#21344;2018-2022&#24180;&#38388;&#21457;&#34920;&#25991;&#31456;&#30340;80.7%)&#65292;&#20197;&#22238;&#39038;&#22312;&#34394;&#25311;&#29615;&#22659;&#19979;&#24314;&#31569;&#29983;&#25104;&#21487;&#33021;&#24615;&#30340;&#39046;&#22495;&#65292;&#38480;&#20110;&#24314;&#31569;&#24418;&#24335;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24314;&#31569;&#30740;&#31350;&#12289;&#34394;&#25311;&#29615;&#22659;&#21644;&#30456;&#20851;&#25216;&#26415;&#26041;&#27861;&#30340;&#27010;&#36848;&#65292;&#25509;&#30528;&#22238;&#39038;&#20102;&#31163;&#25955;&#20307;&#32032;&#29983;&#25104;&#12289;&#30001;2D&#22270;&#20687;&#29983;&#25104;&#30340;3D&#27169;&#22411;&#20197;&#21450;&#26465;&#20214;&#21442;&#25968;&#30340;&#26368;&#36817;&#36235;&#21183;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;3D&#29983;&#25104;&#21644;&#21442;&#25968;&#21270;&#25511;&#21046;&#20013;&#23578;&#26410;&#20805;&#20998;&#25506;&#35752;&#30340;&#38382;&#39064;&#20540;&#24471;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#27979;&#21253;&#25324;&#29983;&#25104;&#22810;&#26679;&#24615;&#12289;&#26032;&#22411;&#36755;&#20986;&#21644;&#23884;&#20837;&#24335;&#26500;&#24314;&#31561;&#22235;&#20010;&#30740;&#31350;&#35758;&#31243;&#21487;&#33021;&#20250;&#25104;&#20026;&#26410;&#26469;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
3D shape generation techniques utilizing deep learning are increasing attention from both computer vision and architectural design. This survey focuses on investigating and comparing the current latest approaches to 3D object generation with deep generative models (DGMs), including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), 3D-aware images, and diffusion models. We discuss 187 articles (80.7% of articles published between 2018-2022) to review the field of generated possibilities of architecture in virtual environments, limited to the architecture form. We provide an overview of architectural research, virtual environment, and related technical approaches, followed by a review of recent trends in discrete voxel generation, 3D models generated from 2D images, and conditional parameters. We highlight under-explored issues in 3D generation and parameterized control that is worth further investigation. Moreover, we speculate that four research agendas including
&lt;/p&gt;</description></item></channel></rss>