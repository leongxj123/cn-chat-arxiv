<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21463;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#21457;&#29616;&#35299;&#37322;&#24448;&#24448;&#19981;&#33021;&#28385;&#36275;&#20182;&#20204;&#30340;&#20851;&#27880;&#28857;&#65292;&#23548;&#33268;&#23545;&#30417;&#31649;&#26694;&#26550;&#30340;&#29702;&#35299;&#21644;&#36981;&#23432;&#20135;&#29983;&#38556;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#22242;&#38431;&#25552;&#20986;&#20102;XAI&#21021;&#23398;&#32773;&#38382;&#39064;&#24211;&#65292;&#28085;&#30422;&#20102;&#23601;&#19994;&#39044;&#27979;&#21644;&#20581;&#24247;&#30417;&#27979;&#20004;&#20010;&#39046;&#22495;&#20013;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.13324</link><description>&lt;p&gt;
&#26377;&#20851;&#31639;&#27861;&#20915;&#31574;&#30340;&#20449;&#24687;&#65306;&#25506;&#32034;&#21463;&#21040;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions. (arXiv:2401.13324v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13324
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21463;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#21457;&#29616;&#35299;&#37322;&#24448;&#24448;&#19981;&#33021;&#28385;&#36275;&#20182;&#20204;&#30340;&#20851;&#27880;&#28857;&#65292;&#23548;&#33268;&#23545;&#30417;&#31649;&#26694;&#26550;&#30340;&#29702;&#35299;&#21644;&#36981;&#23432;&#20135;&#29983;&#38556;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#22242;&#38431;&#25552;&#20986;&#20102;XAI&#21021;&#23398;&#32773;&#38382;&#39064;&#24211;&#65292;&#28085;&#30422;&#20102;&#23601;&#19994;&#39044;&#27979;&#21644;&#20581;&#24247;&#30417;&#27979;&#20004;&#20010;&#39046;&#22495;&#20013;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#31995;&#32479;&#30340;&#35299;&#37322;&#24456;&#23569;&#28041;&#21450;&#21040;&#21463;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;&#36825;&#31181;&#20256;&#36798;&#20449;&#24687;&#19982;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#25152;&#20851;&#24515;&#30340;&#20449;&#24687;&#20043;&#38388;&#30340;&#24046;&#36317;&#21487;&#33021;&#38459;&#30861;&#23545;&#30417;&#31649;&#26694;&#26550;&#65288;&#22914;AI&#27861;&#26696;&#65289;&#30340;&#29702;&#35299;&#21644;&#36981;&#23432;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;XAI&#21021;&#23398;&#32773;&#38382;&#39064;&#24211;&#8221;&#65306;&#36825;&#26159;&#19968;&#20010;&#28085;&#30422;&#20004;&#20010;&#31639;&#27861;&#20915;&#31574;&#24212;&#29992;&#39046;&#22495;&#65288;&#23601;&#19994;&#39044;&#27979;&#21644;&#20581;&#24247;&#30417;&#27979;&#65289;&#20013;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#20449;&#24687;&#38656;&#27714;&#30340;&#30446;&#24405;&#65292;&#21253;&#25324;&#25968;&#25454;&#12289;&#31995;&#32479;&#32972;&#26223;&#12289;&#31995;&#32479;&#20351;&#29992;&#21644;&#31995;&#32479;&#35268;&#33539;&#31561;&#31867;&#21035;&#12290;&#20449;&#24687;&#38656;&#27714;&#26159;&#36890;&#36807;&#35775;&#35848;&#30740;&#31350;&#25910;&#38598;&#30340;&#65292;&#21442;&#19982;&#32773;&#26681;&#25454;&#33258;&#24049;&#30340;&#38382;&#39064;&#33719;&#24471;&#35299;&#37322;&#12290;&#21442;&#19982;&#32773;&#36824;&#25253;&#21578;&#20102;&#20182;&#20204;&#30340;&#29702;&#35299;&#21644;&#20915;&#31574;&#20449;&#24515;&#65292;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;&#22312;&#25509;&#21463;&#35299;&#37322;&#21518;&#20449;&#24515;&#20542;&#21521;&#20110;&#22686;&#21152;&#65292;&#20294;&#21442;&#19982;&#32773;&#20063;&#38754;&#20020;&#30528;&#29702;&#35299;&#19978;&#30340;&#25361;&#25112;&#65292;&#22914;&#26080;&#27861;&#35299;&#37322;&#20026;&#20160;&#20040;&#33258;&#24049;&#30340;&#29702;&#35299;&#24863;&#35273;&#19981;&#23436;&#25972;&#12290;&#35299;&#37322;&#36824;&#23545;&#29702;&#35299;&#20135;&#29983;&#20102;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explanations of AI systems rarely address the information needs of people affected by algorithmic decision-making (ADM). This gap between conveyed information and information that matters to affected stakeholders can impede understanding and adherence to regulatory frameworks such as the AI Act. To address this gap, we present the "XAI Novice Question Bank": A catalog of affected stakeholders' information needs in two ADM use cases (employment prediction and health monitoring), covering the categories data, system context, system usage, and system specifications. Information needs were gathered in an interview study where participants received explanations in response to their inquiries. Participants further reported their understanding and decision confidence, showing that while confidence tended to increase after receiving explanations, participants also met understanding challenges, such as being unable to tell why their understanding felt incomplete. Explanations further influenced
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;AI&#22312;&#30028;&#38754;&#35774;&#35745;&#21644;&#35780;&#20272;&#20013;&#30340;&#23545;&#40784;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35268;&#33539;&#23545;&#40784;&#12289;&#36807;&#31243;&#23545;&#40784;&#21644;&#35780;&#20272;&#25903;&#25345;&#31561;&#19977;&#20010;&#23545;&#40784;&#30446;&#26631;&#65292;&#24182;&#20171;&#32461;&#20102;&#20195;&#29702;&#36807;&#31243;&#21644;&#36807;&#31243;&#28023;&#28286;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2311.00710</link><description>&lt;p&gt;
AI&#20114;&#21160;&#20013;&#30340;AI&#23545;&#40784;&#65306;&#35268;&#33539;&#23545;&#40784;&#65292;&#36807;&#31243;&#23545;&#40784;&#21644;&#35780;&#20272;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
AI Alignment in the Design of Interactive AI: Specification Alignment, Process Alignment, and Evaluation Support. (arXiv:2311.00710v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;AI&#22312;&#30028;&#38754;&#35774;&#35745;&#21644;&#35780;&#20272;&#20013;&#30340;&#23545;&#40784;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35268;&#33539;&#23545;&#40784;&#12289;&#36807;&#31243;&#23545;&#40784;&#21644;&#35780;&#20272;&#25903;&#25345;&#31561;&#19977;&#20010;&#23545;&#40784;&#30446;&#26631;&#65292;&#24182;&#20171;&#32461;&#20102;&#20195;&#29702;&#36807;&#31243;&#21644;&#36807;&#31243;&#28023;&#28286;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#23545;&#40784;&#26159;&#30830;&#20445;AI&#20135;&#29983;&#26399;&#26395;&#32467;&#26524;&#32780;&#36991;&#20813;&#19981;&#33391;&#21103;&#20316;&#29992;&#30340;&#25972;&#20307;&#38382;&#39064;&#12290;&#34429;&#28982;&#36890;&#24120;&#20174;&#23433;&#20840;&#21644;&#20154;&#31867;&#20215;&#20540;&#30340;&#35282;&#24230;&#32771;&#34385;AI&#23545;&#40784;&#65292;&#20294;&#20063;&#21487;&#20197;&#22312;&#35774;&#35745;&#21644;&#35780;&#20272;&#20132;&#20114;&#24335;AI&#31995;&#32479;&#30340;&#30028;&#38754;&#30340;&#32972;&#26223;&#19979;&#32771;&#34385;AI&#23545;&#40784;&#12290;&#26412;&#25991;&#23558;AI&#23545;&#40784;&#30340;&#27010;&#24565;&#26144;&#23556;&#21040;&#22522;&#26412;&#30340;&#19977;&#27493;&#20132;&#20114;&#24490;&#29615;&#20013;&#65292;&#24471;&#20986;&#30456;&#24212;&#30340;&#23545;&#40784;&#30446;&#26631;&#65306;1&#65289;&#35268;&#33539;&#23545;&#40784;&#65306;&#30830;&#20445;&#29992;&#25143;&#33021;&#22815;&#39640;&#25928;&#21487;&#38752;&#22320;&#23558;&#30446;&#26631;&#20256;&#36798;&#32473;AI&#65307;2&#65289;&#36807;&#31243;&#23545;&#40784;&#65306;&#25552;&#20379;&#39564;&#35777;&#21644;&#21487;&#36873;&#25321;&#25511;&#21046;AI&#25191;&#34892;&#36807;&#31243;&#30340;&#33021;&#21147;&#65307;3&#65289;&#35780;&#20272;&#25903;&#25345;&#65306;&#30830;&#20445;&#29992;&#25143;&#33021;&#22815;&#39564;&#35777;&#21644;&#29702;&#35299;AI&#30340;&#36755;&#20986;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#20195;&#29702;&#36807;&#31243;&#30340;&#27010;&#24565;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;AI&#23454;&#38469;&#36807;&#31243;&#30340;&#31616;&#21270;&#12289;&#20998;&#31163;&#27966;&#29983;&#20294;&#21487;&#25511;&#21046;&#30340;&#34920;&#31034;&#65307;&#20197;&#21450;&#36807;&#31243;&#28023;&#28286;&#30340;&#27010;&#24565;&#65292;&#23427;&#31361;&#26174;&#20154;&#31867;&#21644;AI&#36807;&#31243;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
AI alignment considers the overall problem of ensuring an AI produces desired outcomes, without undesirable side effects. While often considered from the perspectives of safety and human values, AI alignment can also be considered in the context of designing and evaluating interfaces for interactive AI systems. This paper maps concepts from AI alignment onto a basic, three step interaction cycle, yielding a corresponding set of alignment objectives: 1) specification alignment: ensuring the user can efficiently and reliably communicate objectives to the AI, 2) process alignment: providing the ability to verify and optionally control the AI's execution process, and 3) evaluation support: ensuring the user can verify and understand the AI's output. We also introduce the concepts of a surrogate process, defined as a simplified, separately derived, but controllable representation of the AI's actual process; and the notion of a Process Gulf, which highlights how differences between human and
&lt;/p&gt;</description></item></channel></rss>