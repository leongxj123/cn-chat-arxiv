<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#22823;&#21270;&#20934;&#21017;&#65292;&#29992;&#20110;&#25551;&#36848;&#26377;&#25928;&#30340;&#20154;&#26426;&#23545;&#35805;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340; Grice &#22235;&#20010;&#26368;&#22823;&#21270;&#20934;&#21017;&#20197;&#21450;&#20004;&#20010;&#26032;&#20934;&#21017;&#65292;&#23545;&#20110;&#35299;&#20915;&#29616;&#20195;&#20154;&#26426;&#20114;&#21160;&#20013;&#30340;&#29305;&#27530;&#34892;&#20026;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.15115</link><description>&lt;p&gt;
&#23545;&#35805;&#20013;&#30340;&#35821;&#35328;&#27169;&#22411;&#65306;&#20154;&#26426;&#20132;&#20114;&#30340;&#20250;&#35805;&#26368;&#22823;&#21270;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Language Models in Dialogue: Conversational Maxims for Human-AI Interactions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15115
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#22823;&#21270;&#20934;&#21017;&#65292;&#29992;&#20110;&#25551;&#36848;&#26377;&#25928;&#30340;&#20154;&#26426;&#23545;&#35805;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340; Grice &#22235;&#20010;&#26368;&#22823;&#21270;&#20934;&#21017;&#20197;&#21450;&#20004;&#20010;&#26032;&#20934;&#21017;&#65292;&#23545;&#20110;&#35299;&#20915;&#29616;&#20195;&#20154;&#26426;&#20114;&#21160;&#20013;&#30340;&#29305;&#27530;&#34892;&#20026;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#34429;&#28982;&#22797;&#26434;&#65292;&#20294;&#22312;&#23545;&#35805;&#29615;&#22659;&#20013;&#23384;&#22312;&#19968;&#20123;&#22266;&#26377;&#32570;&#38519;&#12290;&#25105;&#20204;&#35748;&#20026;&#35266;&#23519;&#21040;&#30340;&#35768;&#22810;&#32570;&#38519;&#21487;&#20197;&#24402;&#22240;&#20110;&#36829;&#21453;&#19968;&#20010;&#25110;&#22810;&#20010;&#23545;&#35805;&#21407;&#21017;&#12290;&#36890;&#36807;&#20511;&#37492;&#31038;&#20250;&#31185;&#23398;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24191;&#27867;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#22823;&#21270;&#20934;&#21017; - &#21253;&#25324;&#25968;&#37327;&#12289;&#36136;&#37327;&#12289;&#30456;&#20851;&#24615;&#12289;&#26041;&#24335;&#12289;&#20161;&#24904;&#20197;&#21450;&#36879;&#26126;&#24230; - &#26469;&#25551;&#36848;&#26377;&#25928;&#30340;&#20154;&#26426;&#23545;&#35805;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#20154;&#26426;&#20114;&#21160;&#32972;&#26223;&#19979; Grice &#30340;&#21069;&#22235;&#20010;&#26368;&#22823;&#21270;&#20934;&#21017;&#30340;&#36866;&#29992;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#20004;&#20010;&#26032;&#30340;&#20934;&#21017;&#65292;&#20161;&#24904;&#65288;&#28041;&#21450;&#29983;&#25104;&#21644;&#21442;&#19982;&#26377;&#23475;&#20869;&#23481;&#65289;&#21644;&#36879;&#26126;&#24230;&#65288;&#28041;&#21450;&#35782;&#21035;&#33258;&#24049;&#30340;&#30693;&#35782;&#36793;&#30028;&#12289;&#25805;&#20316;&#32422;&#26463;&#21644;&#24847;&#22270;&#65289;&#65292;&#23545;&#20110;&#35299;&#20915;&#29616;&#20195;&#20154;&#26426;&#20114;&#21160;&#20013;&#29420;&#29305;&#34892;&#20026;&#26159;&#24517;&#35201;&#30340;&#12290;&#25552;&#20986;&#30340;&#20934;&#21017;&#20026;&#22914;&#20309;&#25552;&#20379;&#20855;&#20307;&#25351;&#23548;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15115v1 Announce Type: cross  Abstract: Modern language models, while sophisticated, exhibit some inherent shortcomings, particularly in conversational settings. We claim that many of the observed shortcomings can be attributed to violation of one or more conversational principles. By drawing upon extensive research from both the social science and AI communities, we propose a set of maxims -- quantity, quality, relevance, manner, benevolence, and transparency -- for describing effective human-AI conversation. We first justify the applicability of the first four maxims (from Grice) in the context of human-AI interactions. We then argue that two new maxims, benevolence (concerning the generation of, and engagement with, harmful content) and transparency (concerning recognition of one's knowledge boundaries, operational constraints, and intents), are necessary for addressing behavior unique to modern human-AI interactions. The proposed maxims offer prescriptive guidance on how
&lt;/p&gt;</description></item><item><title>EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.03049</link><description>&lt;p&gt;
EasyInstruct&#65306;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03049
&lt;/p&gt;
&lt;p&gt;
EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#25351;&#20196;&#35843;&#25972;&#24050;&#32463;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24182;&#25104;&#20026;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#21147;&#30340;&#19968;&#31181;&#20851;&#38190;&#25216;&#26415;&#12290;&#20026;&#20102;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#25968;&#25454;&#25968;&#37327;&#21644;&#25968;&#25454;&#36136;&#37327;&#20043;&#38388;&#36798;&#21040;&#31934;&#24039;&#30340;&#24179;&#34913;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#20043;&#38388;&#20173;&#28982;&#23384;&#22312;&#19981;&#19968;&#33268;&#65292;&#30446;&#21069;&#27809;&#26377;&#26631;&#20934;&#30340;&#24320;&#28304;&#25351;&#20196;&#22788;&#29702;&#23454;&#29616;&#26694;&#26550;&#21487;&#20379;&#31038;&#21306;&#20351;&#29992;&#65292;&#36825;&#20351;&#24471;&#20174;&#19994;&#32773;&#26080;&#27861;&#36827;&#19968;&#27493;&#24320;&#21457;&#21644;&#25512;&#36827;&#12290;&#20026;&#20102;&#20419;&#36827;&#25351;&#20196;&#22788;&#29702;&#30340;&#30740;&#31350;&#21644;&#24320;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyInstruct&#65292;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;LLMs&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#23427;&#23558;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#27169;&#22359;&#21270;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#12290;EasyInstruct&#24050;&#32463;&#22312;https://github.com/zjunlp/EasyInstruct&#19978;&#20844;&#24320;&#21457;&#24067;&#65292;&#24182;&#24471;&#21040;&#20102;&#31215;&#26497;&#32500;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#26816;&#27979;&#21644;&#25277;&#35937;&#65292;&#26412;&#30740;&#31350;&#38477;&#20302;&#20102;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#25552;&#20986;&#20102;&#33258;&#25105;&#25259;&#38706;&#25277;&#35937;&#30340;&#20219;&#21153;&#65292;&#24182;&#25506;&#32034;&#20102;&#22810;&#31181;&#24494;&#35843;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2311.09538</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#38477;&#20302;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30340;&#38544;&#31169;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Reducing Privacy Risks in Online Self-Disclosures with Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09538
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#26816;&#27979;&#21644;&#25277;&#35937;&#65292;&#26412;&#30740;&#31350;&#38477;&#20302;&#20102;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#25552;&#20986;&#20102;&#33258;&#25105;&#25259;&#38706;&#25277;&#35937;&#30340;&#20219;&#21153;&#65292;&#24182;&#25506;&#32034;&#20102;&#22810;&#31181;&#24494;&#35843;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#25259;&#38706;&#22312;&#31038;&#20132;&#23186;&#20307;&#20114;&#21160;&#20013;&#26082;&#26222;&#36941;&#21448;&#26377;&#22238;&#25253;&#65292;&#20294;&#20063;&#23384;&#22312;&#38544;&#31169;&#39118;&#38505;&#12290;&#26412;&#25991;&#36890;&#36807;&#26816;&#27979;&#21644;&#25277;&#35937;&#20027;&#21160;&#20445;&#25252;&#19982;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30456;&#20851;&#30340;&#29992;&#25143;&#38544;&#31169;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#21253;&#21547;4.8K&#20010;&#26631;&#27880;&#25259;&#38706;&#27573;&#30340;19&#31181;&#33258;&#25105;&#25259;&#38706;&#31867;&#21035;&#30340;&#20998;&#31867;&#27861;&#12290;&#28982;&#21518;&#20026;&#26816;&#27979;&#24494;&#35843;&#20102;&#19968;&#20010;&#35821;&#35328;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;65%&#20197;&#19978;&#30340;&#23616;&#37096;&#36328;&#24230;F$_1$&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36827;&#34892;&#20102;&#19968;&#39033;&#20154;&#26426;&#20132;&#20114;&#29992;&#25143;&#30740;&#31350;&#65292;82%&#30340;&#21442;&#19982;&#32773;&#23545;&#35813;&#27169;&#22411;&#25345;&#31215;&#26497;&#24577;&#24230;&#65292;&#31361;&#20986;&#20102;&#20854;&#23454;&#38469;&#24212;&#29992;&#24615;&#12290;&#22312;&#29992;&#25143;&#21453;&#39304;&#30340;&#25512;&#21160;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#25105;&#25259;&#38706;&#25277;&#35937;&#30340;&#20219;&#21153;&#65292;&#21363;&#23558;&#25259;&#38706;&#37325;&#36848;&#20026;&#19981;&#22826;&#20855;&#20307;&#30340;&#26415;&#35821;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#23454;&#29992;&#24615;&#65292;&#20363;&#22914;&#23558;"Im 16F"&#37325;&#36848;&#20026;"I'm a teenage girl"&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#21508;&#31181;&#24494;&#35843;&#31574;&#30053;&#65292;&#25105;&#20204;&#30340;&#26368;&#20339;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#19981;&#21516;&#30340;&#25277;&#35937;&#65292;&#20174;&#32780;&#36866;&#24230;&#20943;&#23569;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09538v2 Announce Type: replace  Abstract: Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure categories and curate a large corpus consisting of 4.8K annotated disclosure spans. We then fine-tune a language model for detection, achieving over 65% partial span F$_1$. We further conduct an HCI user study, with 82% of participants viewing the model positively, highlighting its real-world applicability. Motivated by the user feedback, we introduce the task of self-disclosure abstraction, which is paraphrasing disclosures into less specific terms while preserving their utility, e.g., "Im 16F" to "I'm a teenage girl". We explore various fine-tuning strategies, and our best model can generate diverse abstractions that moderately reduce privacy 
&lt;/p&gt;</description></item></channel></rss>