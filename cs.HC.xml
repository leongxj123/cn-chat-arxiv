<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#32463;&#27982;&#23454;&#24800;&#30340;&#29983;&#25104;&#24335;&#26234;&#33021;&#20307;&#26694;&#26550;&#65288;AGA&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#31574;&#30053;&#26367;&#20195;LLM&#25512;&#29702;&#21644;&#21387;&#32553;&#23545;&#35805;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#20302;&#25104;&#26412;&#30340;&#21487;&#20449;&#20114;&#21160;&#65292;&#19988;&#23545;&#20110;&#26377;&#38480;&#29615;&#22659;&#20013;&#29983;&#25104;&#30340;&#21487;&#20449;&#34892;&#20026;&#26426;&#21046;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2402.02053</link><description>&lt;p&gt;
&#32463;&#27982;&#23454;&#24800;&#30340;&#29983;&#25104;&#24335;&#26234;&#33021;&#20307;
&lt;/p&gt;
&lt;p&gt;
Affordable Generative Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#32463;&#27982;&#23454;&#24800;&#30340;&#29983;&#25104;&#24335;&#26234;&#33021;&#20307;&#26694;&#26550;&#65288;AGA&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#31574;&#30053;&#26367;&#20195;LLM&#25512;&#29702;&#21644;&#21387;&#32553;&#23545;&#35805;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#20302;&#25104;&#26412;&#30340;&#21487;&#20449;&#20114;&#21160;&#65292;&#19988;&#23545;&#20110;&#26377;&#38480;&#29615;&#22659;&#20013;&#29983;&#25104;&#30340;&#21487;&#20449;&#34892;&#20026;&#26426;&#21046;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#26174;&#33879;&#25512;&#36827;&#20102;&#30495;&#23454;&#20132;&#20114;&#26234;&#33021;&#20307;&#30340;&#27169;&#25311;&#12290;&#28982;&#32780;&#65292;&#32500;&#25345;&#38271;&#26102;&#38388;&#26234;&#33021;&#20307;&#20132;&#20114;&#30340;&#24040;&#22823;&#25104;&#26412;&#23545;&#20110;&#37096;&#32626;&#22522;&#20110;LLM&#30340;&#21487;&#20449;&#26234;&#33021;&#20307;&#26500;&#25104;&#20102;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#32463;&#27982;&#23454;&#24800;&#30340;&#29983;&#25104;&#24335;&#26234;&#33021;&#20307;&#65288;AGA&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#26234;&#33021;&#20307;-&#29615;&#22659;&#21644;&#26234;&#33021;&#20307;&#38388;&#20132;&#20114;&#30340;&#20004;&#20010;&#23618;&#38754;&#19978;&#23454;&#29616;&#20302;&#25104;&#26412;&#30340;&#21487;&#20449;&#20114;&#21160;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#26234;&#33021;&#20307;-&#29615;&#22659;&#20132;&#20114;&#65292;&#25105;&#20204;&#29992;&#23398;&#20064;&#30340;&#31574;&#30053;&#26367;&#20195;&#20102;&#37325;&#22797;&#30340;LLM&#25512;&#29702;&#65307;&#32780;&#23545;&#20110;&#26234;&#33021;&#20307;&#38388;&#20132;&#20114;&#65292;&#25105;&#20204;&#23545;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#31038;&#20250;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#21387;&#32553;&#36741;&#21161;&#23545;&#35805;&#20449;&#24687;&#12290;&#22312;&#22810;&#20010;&#29615;&#22659;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#31350;&#20102;LLM&#26234;&#33021;&#20307;&#20013;&#30340;&#21487;&#20449;&#34892;&#20026;&#24418;&#25104;&#26426;&#21046;&#65292;&#35777;&#26126;&#26234;&#33021;&#20307;&#20165;&#33021;&#22312;&#22266;&#23450;&#29615;&#22659;&#20013;&#29983;&#25104;&#26377;&#38480;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of large language models (LLMs) has significantly advanced the simulation of believable interactive agents. However, the substantial cost on maintaining the prolonged agent interactions poses challenge over the deployment of believable LLM-based agents. Therefore, in this paper, we develop Affordable Generative Agents (AGA), a framework for enabling the generation of believable and low-cost interactions on both agent-environment and inter-agents levels. Specifically, for agent-environment interactions, we substitute repetitive LLM inferences with learned policies; while for inter-agent interactions, we model the social relationships between agents and compress auxiliary dialogue information. Extensive experiments on multiple environments show the effectiveness and efficiency of our proposed framework. Also, we delve into the mechanisms of emergent believable behaviors lying in LLM agents, demonstrating that agents can only generate finite behaviors in fixed environments, 
&lt;/p&gt;</description></item><item><title>&#24320;&#21457;&#20102;&#19968;&#31181;&#20174;&#29992;&#25143;&#33258;&#21457;&#38754;&#37096;&#34920;&#24773;&#21453;&#24212;&#20013;&#33258;&#21160;&#27880;&#37322;&#29992;&#25143;&#23545;&#29983;&#25104;&#22270;&#20687;&#20559;&#22909;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#22810;&#20010;&#38754;&#37096;&#21160;&#20316;&#21333;&#20803;&#19982;&#29992;&#25143;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#35780;&#20272;&#39640;&#24230;&#30456;&#20851;&#65292;&#21487;&#29992;&#20110;&#36890;&#36807;&#36825;&#20123;&#38754;&#37096;&#21160;&#20316;&#21333;&#20803;&#21306;&#20998;&#22270;&#20687;&#23545;&#24182;&#33258;&#21160;&#26631;&#27880;&#29992;&#25143;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2312.03187</link><description>&lt;p&gt;
FERGI&#65306;&#26469;&#33258;&#33258;&#21457;&#38754;&#37096;&#34920;&#24773;&#21453;&#24212;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#29992;&#25143;&#20559;&#22909;&#30340;&#33258;&#21160;&#27880;&#37322;
&lt;/p&gt;
&lt;p&gt;
FERGI: Automatic Annotation of User Preferences for Text-to-Image Generation from Spontaneous Facial Expression Reaction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03187
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20102;&#19968;&#31181;&#20174;&#29992;&#25143;&#33258;&#21457;&#38754;&#37096;&#34920;&#24773;&#21453;&#24212;&#20013;&#33258;&#21160;&#27880;&#37322;&#29992;&#25143;&#23545;&#29983;&#25104;&#22270;&#20687;&#20559;&#22909;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#22810;&#20010;&#38754;&#37096;&#21160;&#20316;&#21333;&#20803;&#19982;&#29992;&#25143;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#35780;&#20272;&#39640;&#24230;&#30456;&#20851;&#65292;&#21487;&#29992;&#20110;&#36890;&#36807;&#36825;&#20123;&#38754;&#37096;&#21160;&#20316;&#21333;&#20803;&#21306;&#20998;&#22270;&#20687;&#23545;&#24182;&#33258;&#21160;&#26631;&#27880;&#29992;&#25143;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20351;&#29992;&#20154;&#31867;&#20559;&#22909;&#21453;&#39304;&#25968;&#25454;&#26469;&#24494;&#35843;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#20381;&#36182;&#20110;&#25163;&#21160;&#27880;&#37322;&#65292;&#20154;&#31867;&#21453;&#39304;&#25910;&#38598;&#30340;&#21487;&#25193;&#23637;&#24615;&#21463;&#21040;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#24182;&#27979;&#35797;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20174;&#29992;&#25143;&#30340;&#33258;&#21457;&#38754;&#37096;&#34920;&#24773;&#21453;&#24212;&#20013;&#33258;&#21160;&#27880;&#37322;&#20854;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#20559;&#22909;&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20010;&#38754;&#37096;&#34920;&#24773;&#21453;&#24212;&#21040;&#29983;&#25104;&#22270;&#20687;&#65288;FERGI&#65289;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#23637;&#31034;&#20102;&#22810;&#20010;&#38754;&#37096;&#36816;&#21160;&#21333;&#20803;&#65288;AUs&#65289;&#30340;&#28608;&#27963;&#19982;&#29992;&#25143;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#35780;&#20272;&#39640;&#24230;&#30456;&#20851;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;AU4&#65288;&#30473;&#27611;&#19979;&#22402;&#32773;&#65289;&#21453;&#26144;&#20102;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#36127;&#38754;&#35780;&#20215;&#65292;&#32780;AU12&#65288;&#22068;&#35282;&#25289;&#21160;&#32773;&#65289;&#21453;&#26144;&#20102;&#27491;&#38754;&#35780;&#20215;&#12290;&#36825;&#20004;&#32773;&#22312;&#20004;&#20010;&#26041;&#38754;&#37117;&#24456;&#26377;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21487;&#20197;&#20934;&#30830;&#22320;&#20351;&#29992;&#36825;&#20123;AU&#21709;&#24212;&#23384;&#22312;&#23454;&#36136;&#24046;&#24322;&#30340;&#22270;&#20687;&#23545;&#20043;&#38388;&#33258;&#21160;&#27880;&#37322;&#29992;&#25143;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03187v2 Announce Type: replace-cross  Abstract: Researchers have proposed to use data of human preference feedback to fine-tune text-to-image generative models. However, the scalability of human feedback collection has been limited by its reliance on manual annotation. Therefore, we develop and test a method to automatically annotate user preferences from their spontaneous facial expression reaction to the generated images. We collect a dataset of Facial Expression Reaction to Generated Images (FERGI) and show that the activations of multiple facial action units (AUs) are highly correlated with user evaluations of the generated images. Specifically, AU4 (brow lowerer) is reflective of negative evaluations of the generated image whereas AU12 (lip corner puller) is reflective of positive evaluations. These can be useful in two ways. Firstly, we can automatically annotate user preferences between image pairs with substantial difference in these AU responses with an accuracy sig
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;AI&#36741;&#21161;&#20915;&#31574;&#20013;&#20381;&#36182;&#34892;&#20026;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35270;&#35273;&#26694;&#26550;&#26469;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#20851;&#31995;&#12290;&#35813;&#26694;&#26550;&#25581;&#31034;&#20102;&#24403;&#20154;&#31867;&#22312;&#20915;&#31574;&#20013;&#36807;&#24230;&#20381;&#36182;AI&#26102;&#65292;&#25913;&#21892;&#20449;&#20219;&#21487;&#33021;&#20250;&#38477;&#20302;&#20934;&#30830;&#24615;&#30340;&#26377;&#36259;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.08804</link><description>&lt;p&gt;
&#20851;&#20110;AI&#36741;&#21161;&#20915;&#31574;&#20013;&#20381;&#36182;&#34892;&#20026;&#19982;&#20934;&#30830;&#24615;&#30340;&#30456;&#20114;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
On the Interdependence of Reliance Behavior and Accuracy in AI-Assisted Decision-Making. (arXiv:2304.08804v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08804
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;AI&#36741;&#21161;&#20915;&#31574;&#20013;&#20381;&#36182;&#34892;&#20026;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35270;&#35273;&#26694;&#26550;&#26469;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#20851;&#31995;&#12290;&#35813;&#26694;&#26550;&#25581;&#31034;&#20102;&#24403;&#20154;&#31867;&#22312;&#20915;&#31574;&#20013;&#36807;&#24230;&#20381;&#36182;AI&#26102;&#65292;&#25913;&#21892;&#20449;&#20219;&#21487;&#33021;&#20250;&#38477;&#20302;&#20934;&#30830;&#24615;&#30340;&#26377;&#36259;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;AI&#36741;&#21161;&#20915;&#31574;&#20013;&#65292;&#23558;&#20154;&#31867;&#32622;&#20110;&#20915;&#31574;&#29615;&#36335;&#20013;&#22830;&#30340;&#20027;&#35201;&#25215;&#35834;&#26159;&#65292;&#20182;&#20204;&#24212;&#35813;&#33021;&#22815;&#36890;&#36807;&#31526;&#21512;&#20854;&#27491;&#30830;&#30340;&#21644;&#35206;&#30422;&#20854;&#38169;&#35823;&#30340;&#24314;&#35758;&#26469;&#34917;&#20805;AI&#31995;&#32479;&#12290;&#28982;&#32780;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#32463;&#24120;&#30475;&#21040;&#20154;&#31867;&#20542;&#21521;&#20110;&#36807;&#24230;&#25110;&#19981;&#36275;&#22320;&#20381;&#36182;AI&#24314;&#35758;&#65292;&#36825;&#24847;&#21619;&#30528;&#20182;&#20204;&#35201;&#20040;&#20381;&#20174;&#38169;&#35823;&#30340;&#24314;&#35758;&#65292;&#35201;&#20040;&#35206;&#30422;&#27491;&#30830;&#30340;&#24314;&#35758;&#12290;&#36825;&#31181;&#20381;&#36182;&#34892;&#20026;&#23545;&#20915;&#31574;&#20934;&#30830;&#24615;&#26377;&#23475;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38416;&#36848;&#24182;&#20998;&#26512;&#20102;&#22312;AI&#36741;&#21161;&#20915;&#31574;&#20013;&#20381;&#36182;&#34892;&#20026;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#65292;&#36825;&#22312;&#20197;&#21069;&#30340;&#24037;&#20316;&#20013;&#24456;&#22823;&#31243;&#24230;&#19978;&#34987;&#24573;&#35270;&#20102;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#35270;&#35273;&#26694;&#26550;&#65292;&#20351;&#36825;&#31181;&#30456;&#20114;&#20851;&#31995;&#26356;&#21152;&#20855;&#20307;&#21270;&#12290;&#35813;&#26694;&#26550;&#24110;&#21161;&#25105;&#20204;&#35299;&#37322;&#21644;&#27604;&#36739;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#65292;&#24182;&#33719;&#24471;&#23545;AI&#36741;&#21161;&#20915;&#31574;&#24178;&#39044;&#65288;&#20363;&#22914;&#35299;&#37322;&#65289;&#24433;&#21709;&#30340;&#32454;&#33268;&#29702;&#35299;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20174;&#26694;&#26550;&#20013;&#25512;&#20986;&#20102;&#20960;&#20010;&#26377;&#36259;&#30340;&#23646;&#24615;&#65306;&#65288;i&#65289;&#24403;&#20154;&#31867;&#19981;&#36275;&#22320;&#20381;&#36182;AI&#24314;&#35758;&#26102;&#65292;&#25913;&#21892;&#20449;&#20219;&#23558;&#26174;&#30528;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#22312;&#20182;&#20204;&#36807;&#24230;&#20381;&#36182;&#26102;&#65292;&#20449;&#20219;&#30340;&#25913;&#21892;&#21364;&#21487;&#33021;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In AI-assisted decision-making, a central promise of putting a human in the loop is that they should be able to complement the AI system by adhering to its correct and overriding its mistaken recommendations. In practice, however, we often see that humans tend to over- or under-rely on AI recommendations, meaning that they either adhere to wrong or override correct recommendations. Such reliance behavior is detrimental to decision-making accuracy. In this work, we articulate and analyze the interdependence between reliance behavior and accuracy in AI-assisted decision-making, which has been largely neglected in prior work. We also propose a visual framework to make this interdependence more tangible. This framework helps us interpret and compare empirical findings, as well as obtain a nuanced understanding of the effects of interventions (e.g., explanations) in AI-assisted decision-making. Finally, we infer several interesting properties from the framework: (i) when humans under-rely o
&lt;/p&gt;</description></item></channel></rss>