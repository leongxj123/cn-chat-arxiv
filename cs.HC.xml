<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#25991;&#20171;&#32461;&#24182;&#35780;&#20272;&#20102;&#19968;&#31181;&#22522;&#20110;&#35777;&#25454;&#26435;&#37325;&#26694;&#26550;&#30340;&#20551;&#35774;&#39537;&#21160;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#25903;&#25345;&#25110;&#39539;&#26021;&#20551;&#35774;&#30340;&#35777;&#25454;&#26469;&#22686;&#21152;&#20915;&#31574;&#20934;&#30830;&#24615;&#21644;&#20943;&#23569;&#20381;&#36182;&#31243;&#24230;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01292</link><description>&lt;p&gt;
&#36808;&#21521;&#26032;&#30340;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65306;&#36890;&#36807;&#35777;&#25454;&#25903;&#25345;&#30340;&#20551;&#35774;&#39537;&#21160;&#26041;&#27861;&#30340;&#20915;&#31574;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
Towards the new XAI: A Hypothesis-Driven Approach to Decision Support Using Evidence
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01292
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#24182;&#35780;&#20272;&#20102;&#19968;&#31181;&#22522;&#20110;&#35777;&#25454;&#26435;&#37325;&#26694;&#26550;&#30340;&#20551;&#35774;&#39537;&#21160;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#25903;&#25345;&#25110;&#39539;&#26021;&#20551;&#35774;&#30340;&#35777;&#25454;&#26469;&#22686;&#21152;&#20915;&#31574;&#20934;&#30830;&#24615;&#21644;&#20943;&#23569;&#20381;&#36182;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20043;&#21069;&#20851;&#20110;AI&#36741;&#21161;&#20154;&#31867;&#20915;&#31574;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#20960;&#31181;&#19981;&#21516;&#30340;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#19968;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33539;&#24335;&#36716;&#21464;&#65292;&#21628;&#21505;&#36890;&#36807;&#19968;&#20010;&#31216;&#20026;&#35780;&#20215;&#22411;AI&#30340;&#27010;&#24565;&#26694;&#26550;&#26469;&#36827;&#34892;&#20551;&#35774;&#39537;&#21160;&#30340;XAI&#65292;&#35813;&#26694;&#26550;&#20026;&#20154;&#20204;&#25552;&#20379;&#25903;&#25345;&#25110;&#39539;&#26021;&#20551;&#35774;&#30340;&#35777;&#25454;&#65292;&#32780;&#19981;&#19968;&#23450;&#32473;&#20986;&#20915;&#31574;&#36741;&#21161;&#25512;&#33616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#24182;&#35780;&#20272;&#20102;&#19968;&#31181;&#22522;&#20110;&#35777;&#25454;&#26435;&#37325;&#65288;WoE&#65289;&#26694;&#26550;&#30340;&#20551;&#35774;&#39537;&#21160;XAI&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20026;&#32473;&#23450;&#30340;&#20551;&#35774;&#29983;&#25104;&#27491;&#38754;&#21644;&#36127;&#38754;&#35777;&#25454;&#12290;&#36890;&#36807;&#20154;&#31867;&#34892;&#20026;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20551;&#35774;&#39537;&#21160;&#26041;&#27861;&#25552;&#39640;&#20102;&#20915;&#31574;&#20934;&#30830;&#24615;&#65292;&#19982;&#25512;&#33616;&#39537;&#21160;&#26041;&#27861;&#21644;&#20165;AI&#35299;&#37322;&#22522;&#32447;&#30456;&#27604;&#20943;&#23569;&#20102;&#20381;&#36182;&#31243;&#24230;&#65292;&#20294;&#30456;&#23545;&#20110;&#25512;&#33616;&#39537;&#21160;&#26041;&#27861;&#65292;&#22312;&#20381;&#36182;&#31243;&#24230;&#19979;&#38477;&#26041;&#38754;&#30053;&#24494;&#22686;&#21152;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21442;&#19982;&#32773;&#22312;&#20351;&#29992;&#25105;&#20204;&#30340;&#20551;&#35774;&#39537;&#21160;&#26041;&#27861;&#26102;&#19982;&#20004;&#20010;&#22522;&#32447;&#30340;&#26041;&#24335;&#23384;&#22312;&#23454;&#36136;&#24615;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prior research on AI-assisted human decision-making has explored several different explainable AI (XAI) approaches. A recent paper has proposed a paradigm shift calling for hypothesis-driven XAI through a conceptual framework called evaluative AI that gives people evidence that supports or refutes hypotheses without necessarily giving a decision-aid recommendation. In this paper we describe and evaluate an approach for hypothesis-driven XAI based on the Weight of Evidence (WoE) framework, which generates both positive and negative evidence for a given hypothesis. Through human behavioural experiments, we show that our hypothesis-driven approach increases decision accuracy, reduces reliance compared to a recommendation-driven approach and an AI-explanation-only baseline, but with a small increase in under-reliance compared to the recommendation-driven approach. Further, we show that participants used our hypothesis-driven approach in a materially different way to the two baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#20013;&#35782;&#21035;&#21644;&#37327;&#21270;&#24615;&#21035;&#20559;&#35265;&#65292;&#25552;&#20986;&#20102;&#19977;&#20010;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#38750;&#27495;&#35270;&#26631;&#20934;&#24182;&#35774;&#35745;&#20102;&#30456;&#24212;&#30340;&#25552;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.08564</link><description>&lt;p&gt;
&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#27495;&#35270;&#26631;&#20934;
&lt;/p&gt;
&lt;p&gt;
Non-discrimination Criteria for Generative Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#20013;&#35782;&#21035;&#21644;&#37327;&#21270;&#24615;&#21035;&#20559;&#35265;&#65292;&#25552;&#20986;&#20102;&#19977;&#20010;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#38750;&#27495;&#35270;&#26631;&#20934;&#24182;&#35774;&#35745;&#20102;&#30456;&#24212;&#30340;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65292;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#32463;&#21382;&#20102;&#24555;&#36895;&#21457;&#23637;&#12290;&#38543;&#30528;&#36825;&#20123;&#27169;&#22411;&#36234;&#26469;&#36234;&#26222;&#36941;&#22320;&#25552;&#20379;&#32473;&#20844;&#20247;&#20351;&#29992;&#65292;&#20154;&#20204;&#24320;&#22987;&#25285;&#24515;&#22312;&#24212;&#29992;&#20013;&#24310;&#32493;&#21644;&#25918;&#22823;&#26377;&#23475;&#20559;&#35265;&#30340;&#38382;&#39064;&#12290;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#21487;&#33021;&#23545;&#20854;&#38024;&#23545;&#30340;&#20010;&#20154;&#36896;&#25104;&#20260;&#23475;&#21644;&#38480;&#21046;&#65292;&#26080;&#35770;&#26159;&#30001;&#35823;&#20256;&#36824;&#26159;&#27495;&#35270;&#25152;&#26500;&#25104;&#12290;&#35782;&#21035;&#24615;&#21035;&#20559;&#35265;&#20316;&#20026;&#19968;&#31181;&#26222;&#36941;&#30340;&#31038;&#20250;&#26500;&#36896;&#65292;&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#21457;&#29616;&#21644;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#23384;&#22312;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19977;&#20010;&#26469;&#33258;&#20998;&#31867;&#30340;&#33879;&#21517;&#38750;&#27495;&#35270;&#26631;&#20934;&#30340;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#31867;&#27604;&#65292;&#21363;&#29420;&#31435;&#24615;&#12289;&#20998;&#31163;&#24615;&#21644;&#20805;&#20998;&#24615;&#12290;&#20026;&#20102;&#23637;&#31034;&#36825;&#20123;&#26631;&#20934;&#30340;&#20316;&#29992;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#38024;&#23545;&#27599;&#20010;&#26631;&#20934;&#30340;&#25552;&#31034;&#65292;&#37325;&#28857;&#20851;&#27880;&#32844;&#19994;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#65292;&#20855;&#20307;&#21033;&#29992;&#21307;&#23398;&#27979;&#35797;&#26469;&#22312;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#32972;&#26223;&#20013;&#24341;&#20837;&#22522;&#26412;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08564v1 Announce Type: cross  Abstract: Within recent years, generative AI, such as large language models, has undergone rapid development. As these models become increasingly available to the public, concerns arise about perpetuating and amplifying harmful biases in applications. Gender stereotypes can be harmful and limiting for the individuals they target, whether they consist of misrepresentation or discrimination. Recognizing gender bias as a pervasive societal construct, this paper studies how to uncover and quantify the presence of gender biases in generative language models. In particular, we derive generative AI analogues of three well-known non-discrimination criteria from classification, namely independence, separation and sufficiency. To demonstrate these criteria in action, we design prompts for each of the criteria with a focus on occupational gender stereotype, specifically utilizing the medical test to introduce the ground truth in the generative AI context. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#21327;&#20316;&#30340;&#20154;&#24037;&#26234;&#33021;-&#20154;&#31867;&#28151;&#21512;&#22242;&#38431;&#25480;&#26435;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;AI&#32463;&#29702;&#65288;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#65289;&#20316;&#20026;&#22242;&#38431;&#30340;&#22806;&#37096;&#35266;&#23519;&#32773;&#65292;&#23398;&#20064;&#22242;&#38431;&#20195;&#29702;&#20154;&#30340;&#34892;&#20026;&#27169;&#22411;&#24182;&#36873;&#25321;&#26368;&#20339;&#30340;&#25511;&#21046;&#20195;&#29702;&#20154;&#12290;</title><link>https://arxiv.org/abs/2402.05605</link><description>&lt;p&gt;
&#20248;&#21270;&#21327;&#20316;&#30340;&#20154;&#24037;&#26234;&#33021;-&#20154;&#31867;&#28151;&#21512;&#22242;&#38431;&#20013;&#30340;&#25480;&#26435;
&lt;/p&gt;
&lt;p&gt;
Optimizing Delegation in Collaborative Human-AI Hybrid Teams
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#21327;&#20316;&#30340;&#20154;&#24037;&#26234;&#33021;-&#20154;&#31867;&#28151;&#21512;&#22242;&#38431;&#25480;&#26435;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;AI&#32463;&#29702;&#65288;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#65289;&#20316;&#20026;&#22242;&#38431;&#30340;&#22806;&#37096;&#35266;&#23519;&#32773;&#65292;&#23398;&#20064;&#22242;&#38431;&#20195;&#29702;&#20154;&#30340;&#34892;&#20026;&#27169;&#22411;&#24182;&#36873;&#25321;&#26368;&#20339;&#30340;&#25511;&#21046;&#20195;&#29702;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20154;&#31867;&#21644;&#33258;&#20027;&#31995;&#32479;&#20316;&#20026;&#28151;&#21512;&#22242;&#38431;&#20849;&#21516;&#36816;&#20316;&#26102;&#65292;&#25105;&#20204;&#24076;&#26395;&#30830;&#20445;&#22242;&#38431;&#30340;&#25104;&#21151;&#21644;&#25928;&#29575;&#12290;&#25105;&#20204;&#23558;&#22242;&#38431;&#25104;&#21592;&#31216;&#20026;&#20195;&#29702;&#20154;&#12290;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#28151;&#21512;&#22242;&#38431;&#30340;&#24773;&#20917;&#65292;&#21363;&#22312;&#20219;&#20309;&#26102;&#20505;&#65292;&#21482;&#26377;&#19968;&#20010;&#22242;&#38431;&#25104;&#21592;&#65288;&#25511;&#21046;&#20195;&#29702;&#20154;&#65289;&#34987;&#25480;&#26435;&#20026;&#22242;&#38431;&#30340;&#25511;&#21046;&#32773;&#12290;&#20026;&#20102;&#30830;&#23450;&#26368;&#20339;&#30340;&#25511;&#21046;&#20195;&#29702;&#20154;&#36873;&#25321;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24341;&#20837;AI&#32463;&#29702;&#65288;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#65289;&#30340;&#24819;&#27861;&#65292;&#35813;&#32463;&#29702;&#20316;&#20026;&#22242;&#38431;&#30340;&#22806;&#37096;&#35266;&#23519;&#32773;&#23398;&#20064;&#12290;&#32463;&#29702;&#36890;&#36807;&#35266;&#23519;&#20195;&#29702;&#20154;&#30340;&#34920;&#29616;&#21644;&#22242;&#38431;&#25152;&#22788;&#30340;&#29615;&#22659;/&#19990;&#30028;&#26469;&#23398;&#20064;&#34892;&#20026;&#27169;&#22411;&#65292;&#24182;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#36873;&#25321;&#20986;&#26368;&#29702;&#24819;&#30340;&#25511;&#21046;&#20195;&#29702;&#20154;&#12290;&#20026;&#20102;&#38480;&#23450;&#32463;&#29702;&#30340;&#20219;&#21153;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#32452;&#32422;&#26463;&#26465;&#20214;&#12290;&#32463;&#29702;&#30340;&#32422;&#26463;&#26465;&#20214;&#25351;&#31034;&#22242;&#38431;&#30340;&#21487;&#25509;&#21463;&#36816;&#20316;&#26041;&#24335;&#65292;&#22240;&#27492;&#22914;&#26524;&#22242;&#38431;&#36827;&#20837;&#19981;&#21487;&#25509;&#21463;&#24182;&#38656;&#35201;&#32463;&#29702;&#20171;&#20837;&#30340;&#29366;&#24577;&#65292;&#23601;&#20250;&#36829;&#21453;&#32422;&#26463;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
When humans and autonomous systems operate together as what we refer to as a hybrid team, we of course wish to ensure the team operates successfully and effectively. We refer to team members as agents. In our proposed framework, we address the case of hybrid teams in which, at any time, only one team member (the control agent) is authorized to act as control for the team. To determine the best selection of a control agent, we propose the addition of an AI manager (via Reinforcement Learning) which learns as an outside observer of the team. The manager learns a model of behavior linking observations of agent performance and the environment/world the team is operating in, and from these observations makes the most desirable selection of a control agent. We restrict the manager task by introducing a set of constraints. The manager constraints indicate acceptable team operation, so a violation occurs if the team enters a condition which is unacceptable and requires manager intervention. To
&lt;/p&gt;</description></item></channel></rss>