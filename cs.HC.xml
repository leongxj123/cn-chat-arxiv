<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#25552;&#20986;&#20102;RASP&#65292;&#19968;&#20010;&#21487;&#22312;25&#31186;&#20869;&#33258;&#20027;&#26356;&#25442;&#20256;&#24863;&#22120;&#21644;&#25191;&#34892;&#22120;&#30340;&#27169;&#22359;&#21270;&#21644;&#21487;&#37325;&#26500;&#20256;&#24863;&#21644;&#20316;&#21160;&#24179;&#21488;&#65292;&#20351;&#26080;&#20154;&#26426;&#33021;&#24555;&#36895;&#36866;&#24212;&#21508;&#31181;&#20219;&#21153;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#20154;&#21161;&#29702;&#31995;&#32479;&#26550;&#26500;&#12290;</title><link>https://arxiv.org/abs/2403.12853</link><description>&lt;p&gt;
&#22522;&#20110;&#26080;&#20154;&#26426;&#30340;&#29615;&#22659;&#26234;&#33021;&#31995;&#32479;&#30340;&#21487;&#37325;&#26500;&#20316;&#21160;&#21644;&#20256;&#24863;&#24179;&#21488;RASP
&lt;/p&gt;
&lt;p&gt;
RASP: A Drone-based Reconfigurable Actuation and Sensing Platform Towards Ambient Intelligent Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12853
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;RASP&#65292;&#19968;&#20010;&#21487;&#22312;25&#31186;&#20869;&#33258;&#20027;&#26356;&#25442;&#20256;&#24863;&#22120;&#21644;&#25191;&#34892;&#22120;&#30340;&#27169;&#22359;&#21270;&#21644;&#21487;&#37325;&#26500;&#20256;&#24863;&#21644;&#20316;&#21160;&#24179;&#21488;&#65292;&#20351;&#26080;&#20154;&#26426;&#33021;&#24555;&#36895;&#36866;&#24212;&#21508;&#31181;&#20219;&#21153;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#20154;&#21161;&#29702;&#31995;&#32479;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#28040;&#36153;&#32423;&#26080;&#20154;&#26426;&#19982;&#25105;&#20204;&#23478;&#20013;&#30340;&#21560;&#23576;&#26426;&#22120;&#20154;&#25110;&#26085;&#24120;&#29983;&#27963;&#20013;&#30340;&#20010;&#20154;&#26234;&#33021;&#25163;&#26426;&#19968;&#26679;&#26377;&#29992;&#65292;&#38656;&#35201;&#26080;&#20154;&#26426;&#33021;&#24863;&#30693;&#12289;&#39537;&#21160;&#21644;&#21709;&#24212;&#21487;&#33021;&#20986;&#29616;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#24895;&#26223;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RASP&#65292;&#19968;&#20010;&#27169;&#22359;&#21270;&#21644;&#21487;&#37325;&#26500;&#30340;&#20256;&#24863;&#21644;&#20316;&#21160;&#24179;&#21488;&#65292;&#20801;&#35768;&#26080;&#20154;&#26426;&#22312;&#20165;25&#31186;&#20869;&#33258;&#20027;&#26356;&#25442;&#26426;&#36733;&#20256;&#24863;&#22120;&#21644;&#25191;&#34892;&#22120;&#65292;&#20351;&#21333;&#20010;&#26080;&#20154;&#26426;&#33021;&#22815;&#24555;&#36895;&#36866;&#24212;&#21508;&#31181;&#20219;&#21153;&#12290;RASP&#21253;&#25324;&#19968;&#20010;&#26426;&#26800;&#23618;&#65292;&#29992;&#20110;&#29289;&#29702;&#26356;&#25442;&#20256;&#24863;&#22120;&#27169;&#22359;&#65292;&#19968;&#20010;&#30005;&#27668;&#23618;&#65292;&#29992;&#20110;&#32500;&#25252;&#20256;&#24863;&#22120;/&#25191;&#34892;&#22120;&#30340;&#30005;&#28304;&#21644;&#36890;&#20449;&#32447;&#36335;&#65292;&#20197;&#21450;&#19968;&#20010;&#36719;&#20214;&#23618;&#65292;&#29992;&#20110;&#22312;&#26080;&#20154;&#26426;&#21644;&#25105;&#20204;&#24179;&#21488;&#19978;&#30340;&#20219;&#20309;&#20256;&#24863;&#22120;&#27169;&#22359;&#20043;&#38388;&#32500;&#25252;&#19968;&#20010;&#20844;&#20849;&#25509;&#21475;&#12290;&#21033;&#29992;&#26368;&#36817;&#22312;&#22823;&#22411;&#35821;&#35328;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;RASP&#30340;&#20010;&#20154;&#21161;&#29702;&#31995;&#32479;&#30340;&#26550;&#26500;&#12289;&#23454;&#29616;&#21644;&#29616;&#23454;&#19990;&#30028;&#37096;&#32626;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12853v1 Announce Type: cross  Abstract: Realizing consumer-grade drones that are as useful as robot vacuums throughout our homes or personal smartphones in our daily lives requires drones to sense, actuate, and respond to general scenarios that may arise. Towards this vision, we propose RASP, a modular and reconfigurable sensing and actuation platform that allows drones to autonomously swap onboard sensors and actuators in only 25 seconds, allowing a single drone to quickly adapt to a diverse range of tasks. RASP consists of a mechanical layer to physically swap sensor modules, an electrical layer to maintain power and communication lines to the sensor/actuator, and a software layer to maintain a common interface between the drone and any sensor module in our platform. Leveraging recent advances in large language and visual language models, we further introduce the architecture, implementation, and real-world deployments of a personal assistant system utilizing RASP. We demo
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#19981;&#24895;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#23548;&#33268;&#39640;&#38169;&#35823;&#29575;&#12290;&#23454;&#39564;&#36824;&#34920;&#26126;&#29992;&#25143;&#26080;&#35770;&#26159;&#21542;&#26631;&#35760;&#20102;&#30830;&#23450;&#24615;&#37117;&#20250;&#20005;&#37325;&#20381;&#36182;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.06730</link><description>&lt;p&gt;
&#19981;&#21487;&#38752;&#30340;&#20381;&#36182;&#65306;&#35821;&#35328;&#27169;&#22411;&#19981;&#24895;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty. (arXiv:2401.06730v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06730
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#19981;&#24895;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#23548;&#33268;&#39640;&#38169;&#35823;&#29575;&#12290;&#23454;&#39564;&#36824;&#34920;&#26126;&#29992;&#25143;&#26080;&#35770;&#26159;&#21542;&#26631;&#35760;&#20102;&#30830;&#23450;&#24615;&#37117;&#20250;&#20005;&#37325;&#20381;&#36182;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#20132;&#20114;&#30340;&#40664;&#35748;&#25509;&#21475;&#65292;&#35821;&#35328;&#27169;&#22411;&#36866;&#24403;&#22320;&#20256;&#36798;&#19979;&#28216;&#24212;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#23545;&#20854;&#22238;&#31572;&#30340;&#32622;&#20449;&#24230;&#65292;&#20197;&#21450;&#19979;&#28216;&#29992;&#25143;&#23545;&#35821;&#35328;&#27169;&#22411;&#34920;&#36798;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#21453;&#24212;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#20844;&#24320;&#37096;&#32626;&#30340;&#27169;&#22411;&#65292;&#21457;&#29616;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#65292;&#21363;&#20351;&#20135;&#29983;&#20102;&#38169;&#35823;&#31572;&#26696;&#65292;&#35821;&#35328;&#27169;&#22411;&#20063;&#26080;&#27861;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#12290;&#34429;&#28982;&#21487;&#20197;&#26126;&#30830;&#35201;&#27714;&#35821;&#35328;&#27169;&#22411;&#34920;&#36798;&#32622;&#20449;&#24230;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#23548;&#33268;&#22312;&#32622;&#20449;&#30340;&#22238;&#31572;&#20013;&#38169;&#35823;&#29575;&#39640;&#36798;&#24179;&#22343;47%&#12290;&#25105;&#20204;&#36890;&#36807;&#20154;&#31867;&#23454;&#39564;&#27979;&#35797;&#20102;&#35821;&#35328;&#27169;&#22411;&#36807;&#24230;&#33258;&#20449;&#30340;&#39118;&#38505;&#65292;&#24182;&#35777;&#26126;&#29992;&#25143;&#26080;&#35770;&#26159;&#21542;&#26631;&#35760;&#20102;&#30830;&#23450;&#24615;&#37117;&#20250;&#20005;&#37325;&#20381;&#36182;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;RLHF&#23545;&#40784;&#20013;&#20351;&#29992;&#30340;&#20559;&#22909;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#24182;&#21457;&#29616;&#20154;&#31867;&#23545;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25991;&#26412;&#26377;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#31361;&#20986;&#20102;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
As natural language becomes the default interface for human-AI interaction, there is a critical need for LMs to appropriately communicate uncertainties in downstream applications. In this work, we investigate how LMs incorporate confidence about their responses via natural language and how downstream users behave in response to LM-articulated uncertainties. We examine publicly deployed models and find that LMs are unable to express uncertainties when answering questions even when they produce incorrect responses. LMs can be explicitly prompted to express confidences, but tend to be overconfident, resulting in high error rates (on average 47%) among confident responses. We test the risks of LM overconfidence by running human experiments and show that users rely heavily on LM generations, whether or not they are marked by certainty. Lastly, we investigate the preference-annotated datasets used in RLHF alignment and find that humans have a bias against texts with uncertainty. Our work hig
&lt;/p&gt;</description></item></channel></rss>