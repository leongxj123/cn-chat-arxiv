<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22235;&#31181;&#25945;&#23398;&#25351;&#23548;&#31574;&#30053;&#23545;&#23398;&#20064;&#32773;&#22312;&#20351;&#29992;LLM&#26102;&#30340;&#34920;&#29616;&#21644;&#24863;&#30693;&#25928;&#26524;&#65292;&#21457;&#29616;&#30452;&#25509;LLM&#31572;&#26696;&#25552;&#39640;&#20102;&#34920;&#29616;&#65292;&#32780;&#25913;&#36827;&#23398;&#29983;&#35299;&#20915;&#26041;&#26696;&#21017;&#22686;&#21152;&#20102;&#23545;LLM&#30340;&#20449;&#20219;&#24230;&#12290;&#21516;&#26102;&#65292;&#32467;&#26500;&#21270;&#25351;&#23548;&#20063;&#20943;&#23569;&#20102;&#38543;&#26426;&#26597;&#35810;&#21644;&#23398;&#29983;&#22797;&#21046;&#31896;&#36148;&#38382;&#39064;&#30340;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2310.13712</link><description>&lt;p&gt;
&#23398;&#20064;&#32773;&#20351;&#29992;LLM&#26102;&#25351;&#23548;&#21644;&#20132;&#20114;&#31574;&#30053;&#23545;&#23398;&#20064;&#32773;&#30340;&#34920;&#29616;&#21644;&#24863;&#30693;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception. (arXiv:2310.13712v2 [cs.HC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22235;&#31181;&#25945;&#23398;&#25351;&#23548;&#31574;&#30053;&#23545;&#23398;&#20064;&#32773;&#22312;&#20351;&#29992;LLM&#26102;&#30340;&#34920;&#29616;&#21644;&#24863;&#30693;&#25928;&#26524;&#65292;&#21457;&#29616;&#30452;&#25509;LLM&#31572;&#26696;&#25552;&#39640;&#20102;&#34920;&#29616;&#65292;&#32780;&#25913;&#36827;&#23398;&#29983;&#35299;&#20915;&#26041;&#26696;&#21017;&#22686;&#21152;&#20102;&#23545;LLM&#30340;&#20449;&#20219;&#24230;&#12290;&#21516;&#26102;&#65292;&#32467;&#26500;&#21270;&#25351;&#23548;&#20063;&#20943;&#23569;&#20102;&#38543;&#26426;&#26597;&#35810;&#21644;&#23398;&#29983;&#22797;&#21046;&#31896;&#36148;&#38382;&#39064;&#30340;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#23545;&#19981;&#26029;&#22686;&#38271;&#30340;&#25945;&#23460;&#35268;&#27169;&#21644;&#25945;&#24072;&#36164;&#28304;&#26377;&#38480;&#30340;&#38382;&#39064;&#65292;&#20010;&#24615;&#21270;&#30340;&#22522;&#20110;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#25945;&#23398;&#21161;&#25163;&#21487;&#20197;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#25506;&#32034;&#23427;&#20204;&#22312;&#25945;&#32946;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#25361;&#25112;&#19981;&#20165;&#22312;&#20110;&#30830;&#23450;LLMs&#30340;&#26377;&#25928;&#24615;&#65292;&#32780;&#19988;&#22312;&#20110;&#35782;&#21035;&#23398;&#20064;&#32773;&#19982;&#36825;&#20123;&#27169;&#22411;&#20043;&#38388;&#30340;&#20114;&#21160;&#32454;&#24494;&#24046;&#21035;&#65292;&#36825;&#20250;&#24433;&#21709;&#23398;&#20064;&#32773;&#30340;&#21442;&#19982;&#21644;&#25104;&#26524;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#26412;&#31185;&#35745;&#31639;&#26426;&#31185;&#23398;&#35838;&#22530;&#65288;N=145&#65289;&#21644;Prolific&#19978;&#36827;&#34892;&#20102;&#19968;&#39033;&#24418;&#25104;&#24615;&#30740;&#31350;&#65288;N=356&#65289;&#65292;&#20197;&#25506;&#32034;&#22235;&#31181;&#25945;&#23398;&#25351;&#23548;&#31574;&#30053;&#23545;&#23398;&#20064;&#32773;&#22312;LLMs&#19978;&#30340;&#34920;&#29616;&#12289;&#33258;&#20449;&#24515;&#21644;&#20449;&#20219;&#24230;&#30340;&#24433;&#21709;&#12290;&#30452;&#25509;&#30340;LLM&#31572;&#26696;&#31245;&#24494;&#25552;&#39640;&#20102;&#34920;&#29616;&#65292;&#32780;&#25913;&#36827;&#23398;&#29983;&#30340;&#35299;&#20915;&#26041;&#26696;&#22686;&#21152;&#20102;&#20449;&#20219;&#24230;&#12290;&#32467;&#26500;&#21270;&#25351;&#23548;&#20943;&#23569;&#20102;&#38543;&#26426;&#26597;&#35810;&#21644;&#23398;&#29983;&#23558;&#20316;&#19994;&#38382;&#39064;&#22797;&#21046;&#31896;&#36148;&#32473;LLM&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20984;&#26174;&#20102;t
&lt;/p&gt;
&lt;p&gt;
Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role t
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#20294;&#26159;&#20854;&#40065;&#26834;&#24615;&#20173;&#28982;&#23384;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.00050</link><description>&lt;p&gt;
&#22240;&#26524;&#25512;&#29702;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#24320;&#21551;&#22240;&#26524;&#30740;&#31350;&#30340;&#26032;&#31687;&#31456;
&lt;/p&gt;
&lt;p&gt;
Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00050
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#20294;&#26159;&#20854;&#40065;&#26834;&#24615;&#20173;&#28982;&#23384;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22240;&#26524;&#33021;&#21147;&#22791;&#21463;&#20105;&#35758;&#65292;&#24182;&#19988;&#23545;&#23558;&#20854;&#24212;&#29992;&#20110;&#21307;&#23398;&#12289;&#31185;&#23398;&#12289;&#27861;&#24459;&#21644;&#25919;&#31574;&#31561;&#20855;&#26377;&#31038;&#20250;&#24433;&#21709;&#21147;&#30340;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#35752;&#20102;LLMs&#21450;&#20854;&#22240;&#26524;&#25512;&#29702;&#30340;&#21306;&#21035;&#65292;&#20197;&#21450;&#28508;&#22312;&#30340;&#24314;&#26500;&#21644;&#27979;&#37327;&#25928;&#24230;&#23041;&#32961;&#12290;&#22522;&#20110;GPT-3.5&#21644;4&#30340;&#31639;&#27861;&#22312;&#22810;&#20010;&#22240;&#26524;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;LLMs&#23637;&#31034;&#20102;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#25216;&#26415;&#26469;&#35299;&#37322;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
&lt;/p&gt;</description></item></channel></rss>