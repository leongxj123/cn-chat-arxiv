<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LEyes&#30340;&#36731;&#37327;&#32423;&#28145;&#24230;&#23398;&#20064;&#30524;&#21160;&#36319;&#36394;&#26694;&#26550;&#65292;&#21033;&#29992;&#21512;&#25104;&#30524;&#37096;&#22270;&#20687;&#36827;&#34892;&#35757;&#32451;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#38598;&#19981;&#36275;&#21644;&#30524;&#37096;&#22270;&#20687;&#21464;&#24322;&#23548;&#33268;&#30340;&#27169;&#22411;&#27867;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;LEyes&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#30643;&#23380;&#21644;CR&#23450;&#20301;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.06129</link><description>&lt;p&gt;
LEyes&#65306;&#19968;&#31181;&#36731;&#37327;&#32423;&#28145;&#24230;&#23398;&#20064;&#30524;&#21160;&#36319;&#36394;&#26694;&#26550;&#65292;&#20351;&#29992;&#21512;&#25104;&#30524;&#37096;&#22270;&#20687;
&lt;/p&gt;
&lt;p&gt;
LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images. (arXiv:2309.06129v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LEyes&#30340;&#36731;&#37327;&#32423;&#28145;&#24230;&#23398;&#20064;&#30524;&#21160;&#36319;&#36394;&#26694;&#26550;&#65292;&#21033;&#29992;&#21512;&#25104;&#30524;&#37096;&#22270;&#20687;&#36827;&#34892;&#35757;&#32451;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#38598;&#19981;&#36275;&#21644;&#30524;&#37096;&#22270;&#20687;&#21464;&#24322;&#23548;&#33268;&#30340;&#27169;&#22411;&#27867;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;LEyes&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#30643;&#23380;&#21644;CR&#23450;&#20301;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#24050;&#32463;&#21152;&#24378;&#20102;&#20957;&#35270;&#20272;&#35745;&#25216;&#26415;&#65292;&#20294;&#23454;&#38469;&#37096;&#32626;&#21463;&#21040;&#19981;&#36275;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#38480;&#21046;&#12290;&#30524;&#37096;&#22270;&#20687;&#30340;&#30828;&#20214;&#24341;&#36215;&#30340;&#21464;&#24322;&#20197;&#21450;&#35760;&#24405;&#30340;&#21442;&#19982;&#32773;&#20043;&#38388;&#22266;&#26377;&#30340;&#29983;&#29289;&#24046;&#24322;&#20250;&#23548;&#33268;&#29305;&#24449;&#21644;&#20687;&#32032;&#32423;&#21035;&#30340;&#24046;&#24322;&#65292;&#38459;&#30861;&#20102;&#22312;&#29305;&#23450;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#34394;&#25311;&#25968;&#25454;&#38598;&#21487;&#20197;&#26159;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#21019;&#24314;&#34394;&#25311;&#25968;&#25454;&#38598;&#26082;&#38656;&#35201;&#26102;&#38388;&#21448;&#38656;&#35201;&#36164;&#28304;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Light Eyes or "LEyes"&#30340;&#26694;&#26550;&#65292;&#19982;&#20256;&#32479;&#30340;&#36924;&#30495;&#26041;&#27861;&#19981;&#21516;&#65292;LEyes&#20165;&#27169;&#25311;&#35270;&#39057;&#30524;&#21160;&#36319;&#36394;&#25152;&#38656;&#30340;&#20851;&#38190;&#22270;&#20687;&#29305;&#24449;&#12290;LEyes&#20415;&#20110;&#22312;&#22810;&#26679;&#21270;&#30340;&#20957;&#35270;&#20272;&#35745;&#20219;&#21153;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;LEyes&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#30524;&#30555;&#30643;&#23380;&#21644;CR&#23450;&#20301;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has bolstered gaze estimation techniques, but real-world deployment has been impeded by inadequate training datasets. This problem is exacerbated by both hardware-induced variations in eye images and inherent biological differences across the recorded participants, leading to both feature and pixel-level variance that hinders the generalizability of models trained on specific datasets. While synthetic datasets can be a solution, their creation is both time and resource-intensive. To address this problem, we present a framework called Light Eyes or "LEyes" which, unlike conventional photorealistic methods, only models key image features required for video-based eye tracking using simple light distributions. LEyes facilitates easy configuration for training neural networks across diverse gaze-estimation tasks. We demonstrate that models trained using LEyes outperform other state-of-the-art algorithms in terms of pupil and CR localization across well-known datasets. In addit
&lt;/p&gt;</description></item></channel></rss>