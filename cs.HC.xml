<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#38024;&#23545;&#21516;&#36136;&#21270;&#30340;&#27169;&#22411;&#65292;&#27169;&#22411;&#35780;&#20272;&#38656;&#35201;&#25552;&#20379;&#26377;&#25928;&#30340;&#35780;&#20272;&#65292;&#20197;&#21028;&#26029;&#29305;&#23450;&#27169;&#22411;&#26159;&#21542;&#22312;&#19979;&#28216;&#20351;&#29992;&#22330;&#26223;&#20013;&#21487;&#20197;&#28385;&#36275;&#22810;&#23569;&#20154;&#31867;&#38656;&#27714;&#65292;&#24182;&#19988;&#24212;&#35813;&#26681;&#25454;&#30495;&#23454;&#30340;&#31038;&#20250;&#38656;&#27714;&#26469;&#24320;&#21457;&#35780;&#20272;&#27169;&#22411;&#65292;&#24182;&#25317;&#25265;&#22810;&#26679;&#21270;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.03100</link><description>&lt;p&gt;
&#23558;&#27169;&#22411;&#35780;&#20272;&#37325;&#26032;&#32771;&#34385;&#20026;&#32553;&#23567;&#31038;&#20250;&#25216;&#26415;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Rethinking Model Evaluation as Narrowing the Socio-Technical Gap. (arXiv:2306.03100v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03100
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#21516;&#36136;&#21270;&#30340;&#27169;&#22411;&#65292;&#27169;&#22411;&#35780;&#20272;&#38656;&#35201;&#25552;&#20379;&#26377;&#25928;&#30340;&#35780;&#20272;&#65292;&#20197;&#21028;&#26029;&#29305;&#23450;&#27169;&#22411;&#26159;&#21542;&#22312;&#19979;&#28216;&#20351;&#29992;&#22330;&#26223;&#20013;&#21487;&#20197;&#28385;&#36275;&#22810;&#23569;&#20154;&#31867;&#38656;&#27714;&#65292;&#24182;&#19988;&#24212;&#35813;&#26681;&#25454;&#30495;&#23454;&#30340;&#31038;&#20250;&#38656;&#27714;&#26469;&#24320;&#21457;&#35780;&#20272;&#27169;&#22411;&#65292;&#24182;&#25317;&#25265;&#22810;&#26679;&#21270;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26368;&#36817;&#21457;&#23637;&#32473;&#27169;&#22411;&#35780;&#20272;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#30740;&#31350;&#30028;&#21644;&#24037;&#19994;&#30028;&#27491;&#22312;&#21162;&#21147;&#24212;&#23545;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#30340;&#22810;&#25165;&#22810;&#33402;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#22859;&#65292;&#20294;&#23427;&#20204;&#20063;&#19981;&#21487;&#36991;&#20813;&#22320;&#21521;&#21516;&#36136;&#21270;&#36808;&#36827;&#65306;&#29992;&#21333;&#20010;&#24120;&#31216;&#20043;&#20026;&#8220;&#36890;&#29992;&#8221;&#30340;&#27169;&#22411;&#20026;&#19968;&#31995;&#21015;&#24212;&#29992;&#25552;&#20379;&#21160;&#21147;&#12290;&#22312;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#27169;&#22411;&#35780;&#20272;&#23454;&#36341;&#24517;&#39035;&#25215;&#25285;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#65292;&#20197;&#24212;&#23545;&#36825;&#31181;&#21516;&#36136;&#21270;&#24102;&#26469;&#30340;&#25361;&#25112;&#21644;&#36131;&#20219;&#65306;&#20026;&#29305;&#23450;&#27169;&#22411;&#25552;&#20379;&#26377;&#25928;&#30340;&#35780;&#20272;&#65292;&#21028;&#26029;&#26159;&#21542;&#20197;&#21450;&#22312;&#19979;&#28216;&#20351;&#29992;&#22330;&#26223;&#20013;&#21487;&#20197;&#36890;&#36807;&#32473;&#23450;&#27169;&#22411;&#28385;&#36275;&#22810;&#23569;&#20154;&#31867;&#38656;&#27714;&#65288;&#8220;&#31038;&#20250;&#25216;&#26415;&#24046;&#36317;&#8221;&#65289;&#12290;&#25105;&#20204;&#27762;&#21462;&#31038;&#20250;&#31185;&#23398;&#12289;&#20154;&#26426;&#20132;&#20114;&#65288;HCI&#65289;&#21644;&#21487;&#35299;&#37322;AI&#65288;XAI&#65289;&#36328;&#23398;&#31185;&#39046;&#22495;&#30340;&#32463;&#39564;&#65292;&#25958;&#20419;&#31038;&#21306;&#24320;&#21457;&#22522;&#20110;&#30495;&#23454;&#31038;&#20250;&#38656;&#27714;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#24182;&#25317;&#25265;&#22810;&#26679;&#21270;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent development of generative and large language models (LLMs) poses new challenges for model evaluation that the research community and industry are grappling with. While the versatile capabilities of these models ignite excitement, they also inevitably make a leap toward homogenization: powering a wide range of applications with a single, often referred to as ``general-purpose'', model. In this position paper, we argue that model evaluation practices must take on a critical task to cope with the challenges and responsibilities brought by this homogenization: providing valid assessments for whether and how much human needs in downstream use cases can be satisfied by the given model (\textit{socio-technical gap}). By drawing on lessons from the social sciences, human-computer interaction (HCI), and the interdisciplinary field of explainable AI (XAI), we urge the community to develop evaluation methods based on real-world socio-requirements and embrace diverse evaluation methods 
&lt;/p&gt;</description></item></channel></rss>