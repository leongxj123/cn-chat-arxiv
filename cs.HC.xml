<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25903;&#25345;&#31243;&#24207;&#21592;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24341;&#20837;&#20102;RealHumanEval&#20316;&#20026;&#34913;&#37327;&#20854;&#24110;&#21161;&#24615;&#30340;&#30028;&#38754;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#23545;&#31243;&#24207;&#21592;&#29983;&#20135;&#21147;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2404.02806</link><description>&lt;p&gt;
RealHumanEval: &#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25903;&#25345;&#31243;&#24207;&#21592;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02806
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25903;&#25345;&#31243;&#24207;&#21592;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24341;&#20837;&#20102;RealHumanEval&#20316;&#20026;&#34913;&#37327;&#20854;&#24110;&#21161;&#24615;&#30340;&#30028;&#38754;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#23545;&#31243;&#24207;&#21592;&#29983;&#20135;&#21147;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#20027;&#35201;&#20381;&#36182;&#20110;&#38745;&#24577;&#22522;&#20934;&#65292;&#21253;&#25324;HumanEval&#65288;Chen&#31561;&#65292;2021&#65289;&#65292;&#36825;&#20123;&#22522;&#20934;&#29992;&#20110;&#34913;&#37327;LLMs&#29983;&#25104;&#36890;&#36807;&#21333;&#20803;&#27979;&#35797;&#30340;&#23436;&#25972;&#20195;&#30721;&#30340;&#33021;&#21147;&#12290;&#38543;&#30528;LLMs&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#20316;&#31243;&#24207;&#21592;&#21161;&#25163;&#65292;&#25105;&#20204;&#30740;&#31350;&#29616;&#26377;&#22522;&#20934;&#19978;&#30340;&#22686;&#30410;&#26159;&#21542;&#33021;&#36716;&#21270;&#20026;&#20351;&#29992;LLMs&#32534;&#30721;&#26102;&#31243;&#24207;&#21592;&#29983;&#20135;&#21147;&#30340;&#25552;&#21319;&#65292;&#21253;&#25324;&#32534;&#30721;&#25152;&#33457;&#36153;&#30340;&#26102;&#38388;&#12290;&#38500;&#20102;&#38745;&#24577;&#22522;&#20934;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#21487;&#33021;&#29992;&#20316;&#24230;&#37327;LLM&#24110;&#21161;&#24615;&#20195;&#29702;&#30340;&#20559;&#22909;&#24230;&#37327;&#30340;&#23454;&#29992;&#24615;&#65292;&#20363;&#22914;&#20195;&#30721;&#25509;&#21463;&#25110;&#22797;&#21046;&#29575;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;RealHumanEval&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#34913;&#37327;LLMs&#36741;&#21161;&#31243;&#24207;&#21592;&#30340;&#33021;&#21147;&#30340;&#32593;&#32476;&#30028;&#38754;&#65292;&#21487;&#20197;&#36890;&#36807;&#33258;&#21160;&#23436;&#25104;&#25110;&#32842;&#22825;&#25903;&#25345;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20010;&#29992;&#25143;&#30740;&#31350;&#65288;N = 213&#65289;&#65292;&#20351;&#29992;RealHumanEval&#65292;&#20854;&#20013;&#29992;&#25143;&#19982;&#20845;&#20010;&#22522;&#30784;&#27169;&#22411;&#24615;&#33021;&#21508;&#24322;&#30340;LLMs&#36827;&#34892;&#20132;&#20114;&#12290;&#23613;&#31649;&#38745;&#24577;&#22522;&#20934;&#27809;&#26377;&#21253;&#21547;&#20154;&#20026;&#24178;&#39044;&#65292;&#25105;&#20204;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02806v1 Announce Type: cross  Abstract: Evaluation of large language models (LLMs) for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), which measure the ability of LLMs to generate complete code that passes unit tests. As LLMs are increasingly used as programmer assistants, we study whether gains on existing benchmarks translate to gains in programmer productivity when coding with LLMs, including time spent coding. In addition to static benchmarks, we investigate the utility of preference metrics that might be used as proxies to measure LLM helpfulness, such as code acceptance or copy rates. To do so, we introduce RealHumanEval, a web interface to measure the ability of LLMs to assist programmers, through either autocomplete or chat support. We conducted a user study (N=213) using RealHumanEval in which users interacted with six LLMs of varying base model performance. Despite static benchmarks not incorporating humans-in-the-loop, we 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#38405;&#35835;&#20020;&#24202;&#31508;&#35760;&#65292;&#24739;&#32773;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#33258;&#20449;&#12290;&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#20010;&#24037;&#20855;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#31616;&#21270;&#21644;&#22686;&#21152;&#19978;&#19979;&#25991;&#65292;&#20351;&#20020;&#24202;&#31508;&#35760;&#26356;&#26131;&#35835;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#22686;&#24378;&#23545;&#24739;&#32773;&#26377;&#30410;&#12290;</title><link>http://arxiv.org/abs/2401.09637</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#23545;&#24739;&#32773;&#38405;&#35835;&#20020;&#24202;&#31508;&#35760;&#30340;&#24433;&#21709;&#65306;&#19968;&#20010;&#28151;&#21512;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Impact of Large Language Model Assistance on Patients Reading Clinical Notes: A Mixed-Methods Study. (arXiv:2401.09637v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09637
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#38405;&#35835;&#20020;&#24202;&#31508;&#35760;&#65292;&#24739;&#32773;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#33258;&#20449;&#12290;&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#20010;&#24037;&#20855;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#31616;&#21270;&#21644;&#22686;&#21152;&#19978;&#19979;&#25991;&#65292;&#20351;&#20020;&#24202;&#31508;&#35760;&#26356;&#26131;&#35835;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#22686;&#24378;&#23545;&#24739;&#32773;&#26377;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24739;&#32773;&#36890;&#36807;&#38405;&#35835;&#20182;&#20204;&#30340;&#20020;&#24202;&#31508;&#35760;&#33719;&#24471;&#20102;&#35768;&#22810;&#22909;&#22788;&#65292;&#21253;&#25324;&#22686;&#21152;&#23545;&#33258;&#36523;&#20581;&#24247;&#30340;&#25511;&#21046;&#24863;&#21644;&#23545;&#25252;&#29702;&#35745;&#21010;&#30340;&#29702;&#35299;&#25552;&#39640;&#12290;&#28982;&#32780;&#65292;&#22312;&#20020;&#24202;&#31508;&#35760;&#20013;&#22797;&#26434;&#30340;&#21307;&#23398;&#27010;&#24565;&#21644;&#26415;&#35821;&#38459;&#30861;&#20102;&#24739;&#32773;&#30340;&#29702;&#35299;&#65292;&#24182;&#21487;&#33021;&#23548;&#33268;&#28966;&#34385;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#38754;&#21521;&#24739;&#32773;&#30340;&#24037;&#20855;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#31616;&#21270;&#31508;&#35760;&#12289;&#20174;&#20013;&#25552;&#21462;&#20449;&#24687;&#24182;&#22686;&#21152;&#19978;&#19979;&#25991;&#65292;&#20197;&#20351;&#20020;&#24202;&#31508;&#35760;&#26356;&#26131;&#35835;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#24037;&#20855;&#25552;&#31034;&#25913;&#36827;&#30340;GPT-4&#23545;&#30001;&#20083;&#33146;&#30284;&#24184;&#23384;&#32773;&#25424;&#36192;&#30340;&#30495;&#23454;&#20020;&#24202;&#31508;&#35760;&#21644;&#20020;&#24202;&#21307;&#29983;&#29983;&#25104;&#30340;&#21512;&#25104;&#20020;&#24202;&#31508;&#35760;&#36827;&#34892;&#36825;&#20123;&#22686;&#24378;&#20219;&#21153;&#12290;&#20849;&#26377;12&#26465;&#31508;&#35760;&#65292;3868&#20010;&#23383;&#12290;2023&#24180;6&#26376;&#65292;&#25105;&#20204;&#38543;&#26426;&#20998;&#37197;&#20102;200&#21517;&#32654;&#22269;&#22899;&#24615;&#21442;&#19982;&#32773;&#65292;&#24182;&#21521;&#20182;&#20204;&#20998;&#21457;&#20102;&#19977;&#20010;&#20855;&#26377;&#19981;&#21516;&#31243;&#24230;&#22686;&#24378;&#30340;&#20020;&#24202;&#31508;&#35760;&#12290;&#21442;&#19982;&#32773;&#22238;&#31572;&#20102;&#26377;&#20851;&#27599;&#20010;&#31508;&#35760;&#30340;&#38382;&#39064;&#65292;&#35780;&#20272;&#20102;&#20182;&#20204;&#23545;&#21518;&#32493;&#34892;&#21160;&#30340;&#29702;&#35299;&#21644;&#33258;&#25105;&#25253;&#21578;&#30340;&#33258;&#20449;&#24515;&#12290;&#25105;&#20204;&#21457;&#29616;&#22686;&#24378;&#23545;&#38405;&#35835;&#29702;&#35299;&#21644;&#33258;&#20449;&#24515;&#21451;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Patients derive numerous benefits from reading their clinical notes, including an increased sense of control over their health and improved understanding of their care plan. However, complex medical concepts and jargon within clinical notes hinder patient comprehension and may lead to anxiety. We developed a patient-facing tool to make clinical notes more readable, leveraging large language models (LLMs) to simplify, extract information from, and add context to notes. We prompt engineered GPT-4 to perform these augmentation tasks on real clinical notes donated by breast cancer survivors and synthetic notes generated by a clinician, a total of 12 notes with 3868 words. In June 2023, 200 female-identifying US-based participants were randomly assigned three clinical notes with varying levels of augmentations using our tool. Participants answered questions about each note, evaluating their understanding of follow-up actions and self-reported confidence. We found that augmentations were ass
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#21512;&#20316;&#35774;&#35745;&#65292;&#21457;&#29616;&#24182;&#35299;&#20915;&#20107;&#23454;&#26680;&#26597;&#21592;&#19982;&#25216;&#26415;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#21512;&#20316;&#35774;&#35745;&#20250;&#35758;&#20135;&#29983;&#20102;11&#20010;&#26032;&#30340;&#35774;&#35745;&#24605;&#36335;&#65292;&#21253;&#25324;&#25552;&#39640;&#25928;&#29575;&#21644;&#20010;&#24615;&#21270;&#30340;&#20107;&#23454;&#26680;&#26597;&#24037;&#20855;&#65292;&#24110;&#21161;&#20107;&#23454;&#26680;&#26597;&#21592;&#20934;&#22791;&#26410;&#26469;&#30340;&#34394;&#20551;&#20449;&#24687;&#65292;&#30417;&#27979;&#20559;&#35265;&#65292;&#20197;&#21450;&#25903;&#25345;&#20869;&#37096;&#32452;&#32455;&#12290;</title><link>http://arxiv.org/abs/2308.07213</link><description>&lt;p&gt;
&#20154;&#26412;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20107;&#23454;&#26680;&#26597;&#65306;&#20351;&#29992;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#19982;&#20107;&#23454;&#26680;&#26597;&#21592;&#21512;&#20316;
&lt;/p&gt;
&lt;p&gt;
Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI. (arXiv:2308.07213v1 [cs.HC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#21512;&#20316;&#35774;&#35745;&#65292;&#21457;&#29616;&#24182;&#35299;&#20915;&#20107;&#23454;&#26680;&#26597;&#21592;&#19982;&#25216;&#26415;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#21512;&#20316;&#35774;&#35745;&#20250;&#35758;&#20135;&#29983;&#20102;11&#20010;&#26032;&#30340;&#35774;&#35745;&#24605;&#36335;&#65292;&#21253;&#25324;&#25552;&#39640;&#25928;&#29575;&#21644;&#20010;&#24615;&#21270;&#30340;&#20107;&#23454;&#26680;&#26597;&#24037;&#20855;&#65292;&#24110;&#21161;&#20107;&#23454;&#26680;&#26597;&#21592;&#20934;&#22791;&#26410;&#26469;&#30340;&#34394;&#20551;&#20449;&#24687;&#65292;&#30417;&#27979;&#20559;&#35265;&#65292;&#20197;&#21450;&#25903;&#25345;&#20869;&#37096;&#32452;&#32455;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#22312;&#24212;&#23545;&#22823;&#37327;&#34394;&#20551;&#20449;&#24687;&#26041;&#38754;&#23384;&#22312;&#21487;&#25193;&#23637;&#24615;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#34429;&#28982;&#25552;&#20986;&#20102;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24037;&#20855;&#26469;&#22686;&#24378;&#20107;&#23454;&#26680;&#26597;&#30340;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#20294;&#23398;&#26415;&#30740;&#31350;&#21644;&#20107;&#23454;&#26680;&#26597;&#32452;&#32455;&#22343;&#25253;&#21578;&#20102;&#23545;&#27492;&#31867;&#24037;&#20855;&#30340;&#26377;&#38480;&#37319;&#29992;&#65292;&#22240;&#20026;&#36825;&#20123;&#24037;&#20855;&#19981;&#36275;&#20197;&#19982;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#23454;&#36341;&#12289;&#20215;&#20540;&#35266;&#21644;&#38656;&#27714;&#20445;&#25345;&#19968;&#33268;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#21512;&#20316;&#35774;&#35745;&#26041;&#27861;&#65292;&#21363;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#65292;&#35813;&#26041;&#27861;&#20419;&#36827;&#20107;&#23454;&#26680;&#26597;&#21592;&#12289;&#35774;&#35745;&#24072;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20154;&#21592;&#20849;&#21516;&#21457;&#29616;&#24212;&#20197;&#20309;&#31181;&#26041;&#24335;&#35299;&#20915;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#19982;22&#21517;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#21592;&#36827;&#34892;&#30340;&#21512;&#20316;&#35774;&#35745;&#20250;&#35758;&#20135;&#29983;&#20102;11&#20010;&#26032;&#30340;&#35774;&#35745;&#24605;&#36335;&#12290;&#36825;&#20123;&#24605;&#36335;&#26377;&#21161;&#20110;&#25552;&#39640;&#20449;&#24687;&#25628;&#32034;&#12289;&#22788;&#29702;&#21644;&#25776;&#20889;&#25928;&#29575;&#20197;&#21450;&#20010;&#24615;&#21270;&#30340;&#20107;&#23454;&#26680;&#26597;&#65307;&#24110;&#21161;&#20107;&#23454;&#26680;&#26597;&#21592;&#20027;&#21160;&#20934;&#22791;&#26410;&#26469;&#30340;&#34394;&#20551;&#20449;&#24687;&#65307;&#30417;&#27979;&#28508;&#22312;&#30340;&#20559;&#35265;&#65307;&#24182;&#25903;&#25345;&#20869;&#37096;&#32452;&#32455;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key challenge in professional fact-checking is its limited scalability in relation to the magnitude of false information. While many Natural Language Processing (NLP) tools have been proposed to enhance fact-checking efficiency and scalability, both academic research and fact-checking organizations report limited adoption of such tooling due to insufficient alignment with fact-checker practices, values, and needs. To address this gap, we investigate a co-design method, Matchmaking for AI, which facilitates fact-checkers, designers, and NLP researchers to collaboratively discover what fact-checker needs should be addressed by technology and how. Our co-design sessions with 22 professional fact-checkers yielded a set of 11 novel design ideas. They assist in information searching, processing, and writing tasks for efficient and personalized fact-checking; help fact-checkers proactively prepare for future misinformation; monitor their potential biases; and support internal organization c
&lt;/p&gt;</description></item></channel></rss>