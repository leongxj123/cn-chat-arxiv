<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#36825;&#31687;&#35843;&#26597;&#35770;&#25991;&#31995;&#32479;&#27010;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#31034;&#24037;&#31243;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25506;&#35752;&#20102;&#25552;&#31034;&#24037;&#31243;&#30340;&#26041;&#27861;&#21644;&#25216;&#26415;&#65292;&#24182;&#35828;&#26126;&#20102;&#20854;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.07927</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#31034;&#24037;&#31243;&#30340;&#31995;&#32479;&#35843;&#26597;&#65306;&#25216;&#26415;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07927
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35843;&#26597;&#35770;&#25991;&#31995;&#32479;&#27010;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#31034;&#24037;&#31243;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25506;&#35752;&#20102;&#25552;&#31034;&#24037;&#31243;&#30340;&#26041;&#27861;&#21644;&#25216;&#26415;&#65292;&#24182;&#35828;&#26126;&#20102;&#20854;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#24037;&#31243;&#24050;&#25104;&#20026;&#25193;&#23637;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLM&#65289;&#33021;&#21147;&#30340;&#19981;&#21487;&#25110;&#32570;&#30340;&#25216;&#26415;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20219;&#21153;&#29305;&#23450;&#30340;&#25351;&#20196;&#65288;&#31216;&#20026;&#25552;&#31034;&#65289;&#22312;&#19981;&#20462;&#25913;&#26680;&#24515;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#22686;&#24378;&#27169;&#22411;&#30340;&#25928;&#26524;&#12290;&#25552;&#31034;&#20801;&#35768;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#26080;&#32541;&#38598;&#25104;&#21040;&#19979;&#28216;&#20219;&#21153;&#20013;&#65292;&#20165;&#26681;&#25454;&#32473;&#23450;&#30340;&#25552;&#31034;&#24341;&#21457;&#25152;&#38656;&#30340;&#27169;&#22411;&#34892;&#20026;&#65292;&#32780;&#19981;&#26159;&#26356;&#26032;&#27169;&#22411;&#21442;&#25968;&#12290;&#25552;&#31034;&#21487;&#20197;&#26159;&#25552;&#20379;&#19978;&#19979;&#25991;&#20197;&#25351;&#23548;&#27169;&#22411;&#30340;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#65292;&#20063;&#21487;&#20197;&#26159;&#35843;&#29992;&#30456;&#20851;&#30693;&#35782;&#30340;&#23398;&#20064;&#21521;&#37327;&#34920;&#31034;&#12290;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20174;&#38382;&#31572;&#21040;&#24120;&#35782;&#25512;&#29702;&#37117;&#26377;&#28041;&#21450;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22810;&#26679;&#30340;&#25552;&#31034;&#24037;&#31243;&#26041;&#27861;&#21644;&#25216;&#26415;&#32570;&#20047;&#31995;&#32479;&#30340;&#32452;&#32455;&#21644;&#29702;&#35299;&#12290;&#26412;&#35843;&#26597;&#35770;&#25991;&#36890;&#36807;&#25552;&#20379;&#23545;&#26368;&#36817;&#36827;&#23637;&#30340;&#32467;&#26500;&#21270;&#27010;&#36848;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prompt engineering has emerged as an indispensable technique for extending the capabilities of large language models (LLMs) and vision-language models (VLMs). This approach leverages task-specific instructions, known as prompts, to enhance model efficacy without modifying the core model parameters. Rather than updating the model parameters, prompts allow seamless integration of pre-trained models into downstream tasks by eliciting desired model behaviors solely based on the given prompt. Prompts can be natural language instructions that provide context to guide the model or learned vector representations that activate relevant knowledge. This burgeoning field has enabled success across various applications, from question-answering to commonsense reasoning. However, there remains a lack of systematic organization and understanding of the diverse prompt engineering methods and techniques. This survey paper addresses the gap by providing a structured overview of recent advancements in pro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20419;&#36827;&#38598;&#20307;&#20915;&#31574;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#31649;&#29702;&#23545;&#35805;&#21644;&#24179;&#34913;&#20010;&#20154;&#20559;&#22909;&#26469;&#25552;&#20379;&#28385;&#36275;&#25104;&#21592;&#38656;&#27714;&#30340;&#36873;&#39033;&#65292;&#23454;&#29616;&#39640;&#25928;&#21327;&#35843;&#24182;&#19981;&#26029;&#20248;&#21270;&#31995;&#32479;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.04928</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38598;&#20307;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models for Collective Decision-Making. (arXiv:2311.04928v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.04928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20419;&#36827;&#38598;&#20307;&#20915;&#31574;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#31649;&#29702;&#23545;&#35805;&#21644;&#24179;&#34913;&#20010;&#20154;&#20559;&#22909;&#26469;&#25552;&#20379;&#28385;&#36275;&#25104;&#21592;&#38656;&#27714;&#30340;&#36873;&#39033;&#65292;&#23454;&#29616;&#39640;&#25928;&#21327;&#35843;&#24182;&#19981;&#26029;&#20248;&#21270;&#31995;&#32479;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#24037;&#20316;&#29615;&#22659;&#20013;&#65292;&#22914;&#20250;&#35758;&#23433;&#25490;&#12289;&#21512;&#20316;&#21644;&#39033;&#30446;&#35268;&#21010;&#20013;&#65292;&#38598;&#20307;&#20915;&#31574;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#20294;&#30001;&#20110;&#20010;&#20307;&#20559;&#22909;&#22810;&#26679;&#24615;&#12289;&#24037;&#20316;&#28966;&#28857;&#19981;&#21516;&#21644;&#25104;&#21592;&#20043;&#38388;&#30340;&#26435;&#21147;&#21160;&#24577;&#31561;&#22240;&#32032;&#65292;&#24120;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#20419;&#36827;&#32676;&#20307;&#20915;&#31574;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#31649;&#29702;&#23545;&#35805;&#21644;&#24179;&#34913;&#20010;&#20154;&#20559;&#22909;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#26088;&#22312;&#20174;&#23545;&#35805;&#20013;&#25552;&#21462;&#20010;&#20307;&#20559;&#22909;&#65292;&#24182;&#25552;&#20986;&#28385;&#36275;&#25104;&#21592;&#20559;&#22909;&#30340;&#36873;&#39033;&#12290;&#25105;&#20204;&#29305;&#21035;&#23558;&#27492;&#31995;&#32479;&#24212;&#29992;&#20110;&#20225;&#19994;&#20250;&#35758;&#23433;&#25490;&#12290;&#25105;&#20204;&#21033;&#29992;LLM&#21019;&#24314;&#20102;&#21512;&#25104;&#21592;&#24037;&#37197;&#32622;&#25991;&#20214;&#65292;&#24182;&#27169;&#25311;&#20102;&#22823;&#35268;&#27169;&#30340;&#23545;&#35805;&#65292;&#36890;&#36807;&#21033;&#29992;LLM&#35780;&#20272;&#31995;&#32479;&#34920;&#29616;&#26469;&#20316;&#20026;&#24320;&#23637;&#29992;&#25143;&#30740;&#31350;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31995;&#32479;&#33021;&#23454;&#29616;&#25104;&#21592;&#19982;LLM&#31995;&#32479;&#20043;&#38388;&#30340;&#39640;&#25928;&#21327;&#35843;&#65292;&#24182;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#23545;&#20854;&#25552;&#20986;&#30340;&#36873;&#39033;&#36827;&#34892;&#25913;&#36827;&#21644;&#23436;&#21892;&#65292;&#30830;&#20445;&#20248;&#21270;&#31995;&#32479;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In various work contexts, such as meeting scheduling, collaborating, and project planning, collective decision-making is essential but often challenging due to diverse individual preferences, varying work focuses, and power dynamics among members. To address this, we propose a system leveraging Large Language Models (LLMs) to facilitate group decision-making by managing conversations and balancing preferences among individuals. Our system aims to extract individual preferences from conversations and suggest options that satisfy the preferences of the members. We specifically apply this system to corporate meeting scheduling. We create synthetic employee profiles and simulate conversations at scale, leveraging LLMs to evaluate the system performance as a novel approach to conducting a user study. Our results indicate efficient coordination with reduced interactions between the members and the LLM-based system. The system refines and improves its proposed options over time, ensuring that
&lt;/p&gt;</description></item></channel></rss>