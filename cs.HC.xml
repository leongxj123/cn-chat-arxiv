<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#30340;&#20381;&#36182;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#36866;&#24403;&#20381;&#36182;&#12290;&#35813;&#23450;&#20041;&#20998;&#31163;&#20102;&#20381;&#36182;&#30340;&#27010;&#24565;&#21644;&#20154;&#31867;&#22312;&#24418;&#25104;&#20934;&#30830;&#20449;&#24565;&#26102;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#20026;&#20154;&#31867;&#19982;&#20154;&#24037;&#26234;&#33021;&#20114;&#34917;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#30740;&#31350;&#35774;&#35745;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2401.15356</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#20381;&#36182;&#30340;&#32479;&#35745;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Statistical Framework for Measuring AI Reliance. (arXiv:2401.15356v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15356
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#30340;&#20381;&#36182;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#36866;&#24403;&#20381;&#36182;&#12290;&#35813;&#23450;&#20041;&#20998;&#31163;&#20102;&#20381;&#36182;&#30340;&#27010;&#24565;&#21644;&#20154;&#31867;&#22312;&#24418;&#25104;&#20934;&#30830;&#20449;&#24565;&#26102;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#20026;&#20154;&#31867;&#19982;&#20154;&#24037;&#26234;&#33021;&#20114;&#34917;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#30740;&#31350;&#35774;&#35745;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#32463;&#24120;&#22312;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#24110;&#21161;&#19979;&#20570;&#20915;&#31574;&#12290;&#19968;&#20010;&#24120;&#35265;&#27169;&#24335;&#26159;&#20154;&#24037;&#26234;&#33021;&#21521;&#20154;&#31867;&#25512;&#33616;&#34892;&#21160;&#65292;&#32780;&#20154;&#31867;&#20445;&#30041;&#23545;&#26368;&#32456;&#20915;&#31574;&#30340;&#25511;&#21046;&#26435;&#12290;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#30830;&#35748;&#65292;&#30830;&#20445;&#20154;&#31867;&#23545;&#20154;&#24037;&#26234;&#33021;&#30340;&#36866;&#24403;&#20381;&#36182;&#26159;&#23454;&#29616;&#20114;&#34917;&#24615;&#33021;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#30446;&#21069;&#22312;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#20013;&#20351;&#29992;&#30340;&#36866;&#24403;&#20381;&#36182;&#30340;&#23450;&#20041;&#32570;&#20047;&#24418;&#24335;&#21270;&#30340;&#32479;&#35745;&#22522;&#30784;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#30683;&#30462;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#30340;&#20381;&#36182;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#23427;&#23558;&#20381;&#36182;&#30340;&#27010;&#24565;&#19982;&#20154;&#31867;&#22312;&#21306;&#20998;&#20449;&#21495;&#24182;&#24418;&#25104;&#20934;&#30830;&#20449;&#24565;&#30340;&#25361;&#25112;&#20998;&#24320;&#12290;&#25105;&#20204;&#30340;&#23450;&#20041;&#20135;&#29983;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#26469;&#25351;&#23548;&#20154;&#31867;&#19982;&#20154;&#24037;&#26234;&#33021;&#20114;&#34917;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#30740;&#31350;&#35774;&#35745;&#21644;&#35299;&#37322;&#12290;&#21033;&#29992;&#26368;&#36817;&#30340;&#20154;&#24037;&#26234;&#33021;&#36741;&#21161;&#20915;&#31574;&#30740;&#31350;...
&lt;/p&gt;
&lt;p&gt;
Humans frequently make decisions with the aid of artificially intelligent (AI) systems. A common pattern is for the AI to recommend an action to the human who retains control over the final decision. Researchers have identified ensuring that a human has appropriate reliance on an AI as a critical component of achieving complementary performance. We argue that the current definition of appropriate reliance used in such research lacks formal statistical grounding and can lead to contradictions. We propose a formal definition of reliance, based on statistical decision theory, which separates the concepts of reliance as the probability the decision-maker follows the AI's prediction from challenges a human may face in differentiating the signals and forming accurate beliefs about the situation. Our definition gives rise to a framework that can be used to guide the design and interpretation of studies on human-AI complementarity and reliance. Using recent AI-advised decision making studies f
&lt;/p&gt;</description></item></channel></rss>