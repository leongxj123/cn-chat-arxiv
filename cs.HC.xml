<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#36845;&#20195;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#36924;&#30495;&#30340;&#39640;&#36136;&#37327;&#26631;&#20934;&#24179;&#38754;&#65292;&#23545;&#25552;&#39640;&#20020;&#24202;&#21307;&#29983;&#30340;&#22521;&#35757;&#12289;&#25913;&#21892;&#22270;&#20687;&#36136;&#37327;&#20197;&#21450;&#25552;&#21319;&#19979;&#28216;&#35786;&#26029;&#21644;&#30417;&#27979;&#20855;&#26377;&#28508;&#22312;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2403.08700</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#30340;&#36845;&#20195;&#21453;&#20107;&#23454;&#35299;&#37322;&#29992;&#20110;&#32974;&#20799;&#36229;&#22768;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Diffusion-based Iterative Counterfactual Explanations for Fetal Ultrasound Image Quality Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08700
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#36845;&#20195;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#36924;&#30495;&#30340;&#39640;&#36136;&#37327;&#26631;&#20934;&#24179;&#38754;&#65292;&#23545;&#25552;&#39640;&#20020;&#24202;&#21307;&#29983;&#30340;&#22521;&#35757;&#12289;&#25913;&#21892;&#22270;&#20687;&#36136;&#37327;&#20197;&#21450;&#25552;&#21319;&#19979;&#28216;&#35786;&#26029;&#21644;&#30417;&#27979;&#20855;&#26377;&#28508;&#22312;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24576;&#23381;&#26399;&#36229;&#22768;&#22270;&#20687;&#36136;&#37327;&#23545;&#20934;&#30830;&#35786;&#26029;&#21644;&#30417;&#27979;&#32974;&#20799;&#20581;&#24247;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26631;&#20934;&#24179;&#38754;&#24456;&#22256;&#38590;&#65292;&#21463;&#21040;&#36229;&#22768;&#27874;&#25216;&#26415;&#20154;&#21592;&#30340;&#19987;&#19994;&#30693;&#35782;&#20197;&#21450;&#20687;&#23381;&#22919;BMI&#25110;&#32974;&#20799;&#21160;&#24577;&#31561;&#22240;&#32032;&#30340;&#24433;&#21709;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;&#25193;&#25955;&#30340;&#21453;&#20107;&#23454;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65292;&#20174;&#20302;&#36136;&#37327;&#30340;&#38750;&#26631;&#20934;&#24179;&#38754;&#29983;&#25104;&#36924;&#30495;&#30340;&#39640;&#36136;&#37327;&#26631;&#20934;&#24179;&#38754;&#12290;&#36890;&#36807;&#23450;&#37327;&#21644;&#23450;&#24615;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29983;&#25104;&#36136;&#37327;&#22686;&#21152;&#30340;&#21487;&#20449;&#21453;&#20107;&#23454;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#20026;&#36890;&#36807;&#25552;&#20379;&#35270;&#35273;&#21453;&#39304;&#21152;&#24378;&#20020;&#24202;&#21307;&#29983;&#22521;&#35757;&#20197;&#21450;&#25913;&#36827;&#22270;&#20687;&#36136;&#37327;&#65292;&#20174;&#32780;&#25913;&#21892;&#19979;&#28216;&#35786;&#26029;&#21644;&#30417;&#27979;&#25552;&#20379;&#20102;&#26410;&#26469;&#30340;&#24076;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08700v1 Announce Type: cross  Abstract: Obstetric ultrasound image quality is crucial for accurate diagnosis and monitoring of fetal health. However, producing high-quality standard planes is difficult, influenced by the sonographer's expertise and factors like the maternal BMI or the fetus dynamics. In this work, we propose using diffusion-based counterfactual explainable AI to generate realistic high-quality standard planes from low-quality non-standard ones. Through quantitative and qualitative evaluation, we demonstrate the effectiveness of our method in producing plausible counterfactuals of increased quality. This shows future promise both for enhancing training of clinicians by providing visual feedback, as well as for improving image quality and, consequently, downstream diagnosis and monitoring.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29305;&#24449;&#37325;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20351;&#29992;EEG&#20449;&#21495;&#36827;&#34892;&#36816;&#21160;&#24819;&#35937;&#20998;&#31867;&#26102;&#23384;&#22312;&#30340;&#20302;&#20449;&#22122;&#27604;&#12289;&#38750;&#31283;&#24577;&#24615;&#12289;&#38750;&#32447;&#24615;&#21644;&#22797;&#26434;&#24615;&#31561;&#25361;&#25112;&#65292;&#36890;&#36807;&#38477;&#20302;&#22122;&#22768;&#21644;&#26080;&#20851;&#20449;&#24687;&#65292;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.02515</link><description>&lt;p&gt;
&#22522;&#20110;EEG&#30340;&#36816;&#21160;&#24819;&#35937;&#20998;&#31867;&#30340;&#29305;&#24449;&#37325;&#21152;&#26435;
&lt;/p&gt;
&lt;p&gt;
Feature Reweighting for EEG-based Motor Imagery Classification. (arXiv:2308.02515v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02515
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29305;&#24449;&#37325;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20351;&#29992;EEG&#20449;&#21495;&#36827;&#34892;&#36816;&#21160;&#24819;&#35937;&#20998;&#31867;&#26102;&#23384;&#22312;&#30340;&#20302;&#20449;&#22122;&#27604;&#12289;&#38750;&#31283;&#24577;&#24615;&#12289;&#38750;&#32447;&#24615;&#21644;&#22797;&#26434;&#24615;&#31561;&#25361;&#25112;&#65292;&#36890;&#36807;&#38477;&#20302;&#22122;&#22768;&#21644;&#26080;&#20851;&#20449;&#24687;&#65292;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#38750;&#20405;&#20837;&#24615;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#20449;&#21495;&#36827;&#34892;&#36816;&#21160;&#24819;&#35937;&#65288;MI&#65289;&#20998;&#31867;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30446;&#26631;&#65292;&#22240;&#20026;&#23427;&#29992;&#20110;&#39044;&#27979;&#20027;&#20307;&#32930;&#20307;&#31227;&#21160;&#30340;&#24847;&#22270;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#22522;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#26041;&#27861;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;MI-EEG&#20998;&#31867;&#12290;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;MI-EEG&#20449;&#21495;&#20998;&#31867;&#30340;&#25361;&#25112;&#21253;&#25324;&#20449;&#22122;&#27604;&#20302;&#12289;&#38750;&#31283;&#24577;&#24615;&#12289;&#38750;&#32447;&#24615;&#21644;EEG&#20449;&#21495;&#30340;&#22797;&#26434;&#24615;&#12290;&#22522;&#20110;CNN&#30340;&#32593;&#32476;&#35745;&#31639;&#24471;&#21040;&#30340;MI-EEG&#20449;&#21495;&#29305;&#24449;&#21253;&#21547;&#26080;&#20851;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#30001;&#22122;&#22768;&#21644;&#26080;&#20851;&#29305;&#24449;&#35745;&#31639;&#24471;&#21040;&#30340;CNN&#32593;&#32476;&#30340;&#29305;&#24449;&#22270;&#20063;&#21253;&#21547;&#26080;&#20851;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#35768;&#22810;&#26080;&#29992;&#30340;&#29305;&#24449;&#24120;&#24120;&#35823;&#23548;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#65292;&#38477;&#20302;&#20998;&#31867;&#24615;&#33021;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29305;&#24449;&#37325;&#21152;&#26435;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification of motor imagery (MI) using non-invasive electroencephalographic (EEG) signals is a critical objective as it is used to predict the intention of limb movements of a subject. In recent research, convolutional neural network (CNN) based methods have been widely utilized for MI-EEG classification. The challenges of training neural networks for MI-EEG signals classification include low signal-to-noise ratio, non-stationarity, non-linearity, and high complexity of EEG signals. The features computed by CNN-based networks on the highly noisy MI-EEG signals contain irrelevant information. Subsequently, the feature maps of the CNN-based network computed from the noisy and irrelevant features contain irrelevant information. Thus, many non-contributing features often mislead the neural network training and degrade the classification performance. Hence, a novel feature reweighting approach is proposed to address this issue. The proposed method gives a noise reduction mechanism named
&lt;/p&gt;</description></item></channel></rss>