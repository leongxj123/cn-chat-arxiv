<rss version="2.0"><channel><title>Chat Arxiv cs.HC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.HC</description><item><title>&#26412;&#25991;&#27604;&#36739;&#20102; GPT-4 &#21644; MTurk &#31649;&#36947;&#30340;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#23613;&#31649; MTurk &#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;&#20294; GPT-4 &#30340;&#20934;&#30830;&#29575;&#26356;&#39640;&#65292;&#24182;&#19988;&#32467;&#21512; GPT-4 &#21644;&#20247;&#21253;&#26631;&#31614;&#20351;&#29992;&#32858;&#21512;&#31639;&#27861;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.16795</link><description>&lt;p&gt;
&#22914;&#26524;&#22312;&#19968;&#20010;&#20247;&#21253;&#25968;&#25454;&#26631;&#27880;&#31649;&#36947;&#20013;&#65292;GPT-4
&lt;/p&gt;
&lt;p&gt;
If in a Crowdsourced Data Annotation Pipeline, a GPT-4
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16795
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102; GPT-4 &#21644; MTurk &#31649;&#36947;&#30340;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#23613;&#31649; MTurk &#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;&#20294; GPT-4 &#30340;&#20934;&#30830;&#29575;&#26356;&#39640;&#65292;&#24182;&#19988;&#32467;&#21512; GPT-4 &#21644;&#20247;&#21253;&#26631;&#31614;&#20351;&#29992;&#32858;&#21512;&#31639;&#27861;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;GPT-4&#22312;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#22312;&#32447;&#20247;&#21253;&#24037;&#20316;&#32773;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#20122;&#39532;&#36874;&#26426;&#26800;&#22303;&#32819;&#20854;&#65288;MTurk&#65289;&#30340;&#24037;&#20316;&#32773;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#22240;&#20559;&#31163;&#26631;&#20934;&#20247;&#21253;&#23454;&#36341;&#24182;&#24378;&#35843;&#20010;&#21035;&#24037;&#20316;&#32773;&#30340;&#34920;&#29616;&#32780;&#21463;&#21040;&#25209;&#35780;&#65292;&#32780;&#19981;&#26159;&#25972;&#20010;&#25968;&#25454;&#26631;&#27880;&#36807;&#31243;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;GPT-4&#21644;&#19968;&#20010;&#36947;&#24503;&#19988;&#25191;&#34892;&#33391;&#22909;&#30340;MTurk&#31649;&#36947;&#65292;&#20351;&#29992;415&#21517;&#24037;&#20316;&#32773;&#26631;&#27880;&#20102;&#26469;&#33258;200&#31687;&#23398;&#26415;&#25991;&#31456;&#30340;3,177&#20010;&#21477;&#27573;&#65292;&#20351;&#29992;&#20102;CODA-19&#26041;&#26696;&#12290;&#20004;&#20010;&#24037;&#20316;&#32773;&#30028;&#38754;&#20135;&#29983;&#20102;127,080&#20010;&#26631;&#31614;&#65292;&#28982;&#21518;&#36890;&#36807;&#20843;&#31181;&#26631;&#31614;&#32858;&#21512;&#31639;&#27861;&#25512;&#26029;&#20986;&#26368;&#32456;&#30340;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;&#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;MTurk&#31649;&#36947;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#20026;81.5%&#65292;&#32780;GPT-4&#36798;&#21040;&#20102;83.6%&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#24403;&#23558;GPT-4&#30340;&#26631;&#31614;&#19982;&#36890;&#36807;&#20808;&#36827;&#24037;&#20316;&#32773;&#30028;&#38754;&#25910;&#38598;&#30340;&#20247;&#21253;&#26631;&#31614;&#32467;&#21512;&#36215;&#26469;&#36827;&#34892;&#32858;&#21512;&#26102;&#65292;8&#31181;&#31639;&#27861;&#20013;&#26377;2&#31181;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16795v1 Announce Type: cross  Abstract: Recent studies indicated GPT-4 outperforms online crowd workers in data labeling accuracy, notably workers from Amazon Mechanical Turk (MTurk). However, these studies were criticized for deviating from standard crowdsourcing practices and emphasizing individual workers' performances over the whole data-annotation process. This paper compared GPT-4 and an ethical and well-executed MTurk pipeline, with 415 workers labeling 3,177 sentence segments from 200 scholarly articles using the CODA-19 scheme. Two worker interfaces yielded 127,080 labels, which were then used to infer the final labels through eight label-aggregation algorithms. Our evaluation showed that despite best practices, MTurk pipeline's highest accuracy was 81.5%, whereas GPT-4 achieved 83.6%. Interestingly, when combining GPT-4's labels with crowd labels collected via an advanced worker interface for aggregation, 2 out of the 8 algorithms achieved an even higher accuracy (
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#30340;&#20132;&#21449;&#30740;&#31350;&#23558;&#23545;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#26684;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2402.14601</link><description>&lt;p&gt;
&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#24341;&#20837;&#25945;&#32946;&#20013;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bringing Generative AI to Adaptive Learning in Education
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14601
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#30340;&#20132;&#21449;&#30740;&#31350;&#23558;&#23545;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#26684;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#28608;&#22686;&#65292;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#25512;&#21160;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#31185;&#23398;&#12289;&#37329;&#34701;&#21644;&#25945;&#32946;&#31561;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#21457;&#23637;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#33258;&#36866;&#24212;&#23398;&#20064;&#36825;&#19968;&#27010;&#24565;&#22312;&#25945;&#32946;&#39046;&#22495;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#25552;&#39640;&#23398;&#29983;&#23398;&#20064;&#25928;&#29575;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#26412;&#31435;&#22330;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#35752;&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#32467;&#21512;&#36215;&#26469;&#30340;&#20132;&#21449;&#30740;&#31350;&#12290;&#36890;&#36807;&#35752;&#35770;&#36825;&#19968;&#39046;&#22495;&#30340;&#22909;&#22788;&#12289;&#25361;&#25112;&#21644;&#28508;&#21147;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#31181;&#32467;&#21512;&#23558;&#20026;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#24418;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14601v1 Announce Type: cross  Abstract: The recent surge in generative AI technologies, such as large language models and diffusion models, have boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next stage learning format in education.
&lt;/p&gt;</description></item><item><title>&#20889;&#20316;&#26102;&#20351;&#29992;InstructGPT&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#26174;&#33879;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65292;&#22686;&#21152;&#19981;&#21516;&#20316;&#32773;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#20943;&#23569;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2309.05196</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20889;&#20316;&#26159;&#21542;&#20250;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Does Writing with Language Models Reduce Content Diversity?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.05196
&lt;/p&gt;
&lt;p&gt;
&#20889;&#20316;&#26102;&#20351;&#29992;InstructGPT&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#26174;&#33879;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65292;&#22686;&#21152;&#19981;&#21516;&#20316;&#32773;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#20943;&#23569;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#21457;&#20102;&#19982;&#27169;&#22411;&#36741;&#21161;&#21512;&#20316;&#20889;&#20316;&#30340;&#28608;&#22686;&#12290;&#24403;&#19981;&#21516;&#29992;&#25143;&#32435;&#20837;&#21516;&#19968;&#27169;&#22411;&#30340;&#24314;&#35758;&#26102;&#65292;&#20250;&#23384;&#22312;&#20869;&#23481;&#22810;&#26679;&#24615;&#20943;&#23569;&#30340;&#39118;&#38505;&#65292;&#21487;&#33021;&#38480;&#21046;&#20844;&#20849;&#35805;&#35821;&#20013;&#30340;&#22810;&#20803;&#35266;&#28857;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#25511;&#21046;&#23454;&#39564;&#27979;&#37327;&#20102;&#21327;&#21516;&#20889;&#20316;&#23545;&#22810;&#26679;&#24615;&#30340;&#24433;&#21709;&#65292;&#22312;&#35813;&#23454;&#39564;&#20013;&#65292;&#29992;&#25143;&#20197;&#19977;&#31181;&#35774;&#32622;&#25776;&#20889;&#35758;&#35770;&#24615;&#25991;&#31456;--&#20351;&#29992;&#22522;&#26412;LLM&#65288;GPT3&#65289;&#12289;&#32463;&#36807;&#21453;&#39304;&#35843;&#25972;&#30340;LLM&#65288;InstructGPT&#65289;&#20197;&#21450;&#19981;&#20351;&#29992;&#27169;&#22411;&#24110;&#21161;&#20889;&#20316;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#32452;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;InstructGPT&#36827;&#34892;&#20889;&#20316;&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#23548;&#33268;&#22810;&#26679;&#24615;&#26126;&#26174;&#38477;&#20302;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#22686;&#21152;&#20102;&#19981;&#21516;&#20316;&#32773;&#30340;&#20889;&#20316;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20943;&#23569;&#20102;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#36825;&#31181;&#24433;&#21709;&#20027;&#35201;&#26469;&#28304;&#20110;InstructGPT&#23545;&#20849;&#21516;&#25776;&#20889;&#30340;&#25991;&#26412;&#36129;&#29486;&#36739;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.05196v2 Announce Type: replace  Abstract: Large language models (LLMs) have led to a surge in collaborative writing with model assistance. As different users incorporate suggestions from the same model, there is a risk of decreased diversity in the produced content, potentially limiting diverse perspectives in public discourse. In this work, we measure the impact of co-writing on diversity via a controlled experiment, where users write argumentative essays in three setups -- using a base LLM (GPT3), a feedback-tuned LLM (InstructGPT), and writing without model help. We develop a set of diversity metrics and find that writing with InstructGPT (but not the GPT3) results in a statistically significant reduction in diversity. Specifically, it increases the similarity between the writings of different authors and reduces the overall lexical and content diversity. We additionally find that this effect is mainly attributable to InstructGPT contributing less diverse text to co-writt
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#22242;&#38431;&#22312; AI &#31995;&#32479;&#20013;&#30340;&#30417;&#31649;&#27969;&#31243;&#30340;&#32437;&#21521;&#35266;&#23519;&#65292;&#25506;&#35752;&#20102; AI &#31995;&#32479;&#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#20013;&#22242;&#38431;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#21457;&#29616;&#27492;&#21069;&#30340;&#19987;&#19994;&#22242;&#38431;&#30417;&#31649;&#26041;&#27861;&#20027;&#35201;&#20381;&#38752;&#35299;&#37322;&#21644;&#38382;&#35810;&#26469;&#33719;&#21462;&#20449;&#24687;&#65292;&#32780; AI &#30340;&#24341;&#20837;&#23558;&#21487;&#33021;&#22312;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#26041;&#38754;&#36896;&#25104;&#19968;&#23450;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.14007</link><description>&lt;p&gt;
&#39640;&#39118;&#38505; AI &#30340;&#22242;&#38431;&#30417;&#31649;&#65306;&#22242;&#38431;&#22312;&#24490;&#29615;&#20013;
&lt;/p&gt;
&lt;p&gt;
'Team-in-the-loop' organisational oversight of high-stakes AI. (arXiv:2303.14007v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#22242;&#38431;&#22312; AI &#31995;&#32479;&#20013;&#30340;&#30417;&#31649;&#27969;&#31243;&#30340;&#32437;&#21521;&#35266;&#23519;&#65292;&#25506;&#35752;&#20102; AI &#31995;&#32479;&#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#20013;&#22242;&#38431;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#21457;&#29616;&#27492;&#21069;&#30340;&#19987;&#19994;&#22242;&#38431;&#30417;&#31649;&#26041;&#27861;&#20027;&#35201;&#20381;&#38752;&#35299;&#37322;&#21644;&#38382;&#35810;&#26469;&#33719;&#21462;&#20449;&#24687;&#65292;&#32780; AI &#30340;&#24341;&#20837;&#23558;&#21487;&#33021;&#22312;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#26041;&#38754;&#36896;&#25104;&#19968;&#23450;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#31649;&#23545;&#20110;&#39640;&#39118;&#38505;&#20844;&#20849;&#37096;&#38376; AI &#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#20915;&#31574;&#21487;&#33021;&#20250;&#23545;&#20010;&#20154;&#21644;&#38598;&#20307;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#30446;&#21069;&#22312;&#20844;&#20849;&#37096;&#38376;&#20013;&#20851;&#20110; AI &#30417;&#31649;&#26426;&#21046;&#30340;&#35768;&#22810;&#24605;&#32771;&#37117;&#22260;&#32469;&#30528;&#20154;&#31867;&#20915;&#31574;&#32773;&#22788;&#20110; "&#24490;&#29615;&#20013; "&#36825;&#19968;&#27010;&#24565;&#65292;&#24182;&#19988;&#33021;&#22815;&#24178;&#39044;&#20197;&#38450;&#27490;&#38169;&#35823;&#21644;&#28508;&#22312;&#21361;&#23475;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#20844;&#20849;&#37096;&#38376;&#32972;&#26223;&#19979;&#65292;&#20915;&#31574;&#30340;&#36816;&#33829;&#30417;&#31649;&#26159;&#30001;&#19987;&#19994;&#22242;&#38431;&#32780;&#19981;&#26159;&#20010;&#20154;&#36827;&#34892;&#30340;&#12290;&#37096;&#32626;&#30340; AI &#31995;&#32479;&#22914;&#20309;&#25972;&#21512;&#21040;&#36825;&#20123;&#29616;&#26377;&#30340;&#22242;&#38431;&#30417;&#31649;&#27969;&#31243;&#20013;&#65292;&#23578;&#26410;&#24341;&#36215;&#22826;&#22810;&#27880;&#24847;&#12290;&#25105;&#20204;&#36890;&#36807;&#21046;&#24230;&#20998;&#26512;&#25506;&#35752; AI &#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#30340;&#29616;&#26377;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#22635;&#34917;&#35813;&#26041;&#38754;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#30340;&#30417;&#31649;&#23884;&#22871;&#22312;&#19987;&#19994;&#22521;&#35757;&#35201;&#27714;&#20013;&#65292;&#24182;&#19988;&#22312;&#24449;&#35810;&#20851;&#38190;&#20449;&#24687;&#26102; heavilyrely  &#20110;&#35299;&#37322;&#21644;&#25552;&#38382;&#12290;&#19987;&#19994;&#22242;&#38431;&#20351;&#29992;&#21508;&#31181;&#20250;&#35745;&#25259;&#38706;&#25216;&#26415;&#26469;&#35686;&#21578;&#21516;&#20107;&#21644;&#30417;&#31649;&#34892;&#20026;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312; AI &#31995;&#32479;&#24341;&#20837;&#21040;&#29616;&#26377;&#30340;&#22242;&#38431;&#30417;&#31649;&#27969;&#31243;&#20013;&#65292;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#21487;&#33021;&#21457;&#29983;&#25913;&#21464;&#30340;&#20960;&#31181;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oversight is rightly recognised as vital within high-stakes public sector AI applications, where decisions can have profound individual and collective impacts. Much current thinking regarding forms of oversight mechanisms for AI within the public sector revolves around the idea of human decision makers being 'in-the-loop' and thus being able to intervene to prevent errors and potential harm. However, in a number of high-stakes public sector contexts, operational oversight of decisions is made by expert teams rather than individuals. The ways in which deployed AI systems can be integrated into these existing operational team oversight processes has yet to attract much attention. We address this gap by exploring the impacts of AI upon pre-existing oversight of clinical decision-making through institutional analysis. We find that existing oversight is nested within professional training requirements and relies heavily upon explanation and questioning to elicit vital information. Professio
&lt;/p&gt;</description></item></channel></rss>