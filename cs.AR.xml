<rss version="2.0"><channel><title>Chat Arxiv cs.AR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AR</description><item><title>&#26412;&#25991;&#36890;&#36807;&#35780;&#20272;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#19978;&#30340;&#20391;&#20449;&#36947;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25915;&#20987;&#26041;&#27861;&#26469;&#24674;&#22797;CNN&#27169;&#22411;&#30340;&#26550;&#26500;&#12290;&#35813;&#25915;&#20987;&#21033;&#29992;&#20102;&#25968;&#25454;&#27969;&#26144;&#23556;&#30340;&#25968;&#25454;&#37325;&#29992;&#20197;&#21450;&#26550;&#26500;&#32447;&#32034;&#65292;&#25104;&#21151;&#24674;&#22797;&#20102;&#27969;&#34892;&#30340;CNN&#27169;&#22411;Lenet&#65292;Alexnet&#21644;VGGnet16&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2311.00579</link><description>&lt;p&gt;
&#36890;&#36807;&#25968;&#25454;&#27969;&#25512;&#29702;&#21152;&#36895;&#22120;&#20013;&#30340;&#20391;&#20449;&#36947;&#20998;&#26512;&#25581;&#31034;CNN&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators. (arXiv:2311.00579v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#35780;&#20272;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#19978;&#30340;&#20391;&#20449;&#36947;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25915;&#20987;&#26041;&#27861;&#26469;&#24674;&#22797;CNN&#27169;&#22411;&#30340;&#26550;&#26500;&#12290;&#35813;&#25915;&#20987;&#21033;&#29992;&#20102;&#25968;&#25454;&#27969;&#26144;&#23556;&#30340;&#25968;&#25454;&#37325;&#29992;&#20197;&#21450;&#26550;&#26500;&#32447;&#32034;&#65292;&#25104;&#21151;&#24674;&#22797;&#20102;&#27969;&#34892;&#30340;CNN&#27169;&#22411;Lenet&#65292;Alexnet&#21644;VGGnet16&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#26368;&#36817;&#22312;&#22522;&#20110;&#25968;&#25454;&#27969;&#30340;CNN&#21152;&#36895;&#22120;&#30340;&#36827;&#23637;&#20351;&#24471;CNN&#25512;&#29702;&#21487;&#20197;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#36793;&#32536;&#35774;&#22791;&#19978;&#36827;&#34892;&#12290;&#36825;&#20123;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#21033;&#29992;&#21367;&#31215;&#23618;&#30340;&#22266;&#26377;&#25968;&#25454;&#37325;&#29992;&#26469;&#39640;&#25928;&#22788;&#29702;CNN&#27169;&#22411;&#12290;&#38544;&#34255;CNN&#27169;&#22411;&#30340;&#26550;&#26500;&#23545;&#20110;&#38544;&#31169;&#21644;&#23433;&#20840;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#20869;&#23384;&#30340;&#20391;&#20449;&#36947;&#20449;&#24687;&#65292;&#20197;&#20174;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#20013;&#24674;&#22797;CNN&#26550;&#26500;&#12290;&#25152;&#25552;&#20986;&#30340;&#25915;&#20987;&#21033;&#29992;&#20102;CNN&#21152;&#36895;&#22120;&#19978;&#25968;&#25454;&#27969;&#26144;&#23556;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#25968;&#25454;&#37325;&#29992;&#20197;&#21450;&#26550;&#26500;&#32447;&#32034;&#26469;&#24674;&#22797;CNN&#27169;&#22411;&#30340;&#32467;&#26500;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#20391;&#20449;&#36947;&#25915;&#20987;&#21487;&#20197;&#24674;&#22797;&#27969;&#34892;&#30340;CNN&#27169;&#22411;Lenet&#65292;Alexnet&#21644;VGGnet16&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolution Neural Networks (CNNs) are widely used in various domains. Recent advances in dataflow-based CNN accelerators have enabled CNN inference in resource-constrained edge devices. These dataflow accelerators utilize inherent data reuse of convolution layers to process CNN models efficiently. Concealing the architecture of CNN models is critical for privacy and security. This paper evaluates memory-based side-channel information to recover CNN architectures from dataflow-based CNN inference accelerators. The proposed attack exploits spatial and temporal data reuse of the dataflow mapping on CNN accelerators and architectural hints to recover the structure of CNN models. Experimental results demonstrate that our proposed side-channel attack can recover the structures of popular CNN models, namely Lenet, Alexnet, and VGGnet16.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;NoC&#26550;&#26500;&#20013;&#29616;&#26377;&#21311;&#21517;&#36335;&#30001;&#21327;&#35758;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#21311;&#21517;&#36335;&#30001;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#26131;&#21463;&#25915;&#20987;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#20351;&#29992;&#27969;&#37327;&#28151;&#28102;&#25216;&#26415;&#65292;&#21487;&#20197;&#25269;&#24481;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2309.15687</link><description>&lt;p&gt;
&#25171;&#30772;NoC&#21311;&#21517;&#24615;&#20351;&#29992;&#27969;&#30456;&#20851;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Breaking NoC Anonymity using Flow Correlation Attack. (arXiv:2309.15687v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;NoC&#26550;&#26500;&#20013;&#29616;&#26377;&#21311;&#21517;&#36335;&#30001;&#21327;&#35758;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#21311;&#21517;&#36335;&#30001;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#26131;&#21463;&#25915;&#20987;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#20351;&#29992;&#27969;&#37327;&#28151;&#28102;&#25216;&#26415;&#65292;&#21487;&#20197;&#25269;&#24481;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#29255;&#19978;&#20114;&#36830;&#65288;NoC&#65289;&#24191;&#27867;&#29992;&#20316;&#24403;&#20170;&#22810;&#26680;&#29255;&#19978;&#31995;&#32479;&#65288;SoC&#65289;&#35774;&#35745;&#20013;&#30340;&#20869;&#37096;&#36890;&#20449;&#32467;&#26500;&#12290;&#29255;&#19978;&#36890;&#20449;&#30340;&#23433;&#20840;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#21033;&#29992;&#20849;&#20139;&#30340;NoC&#20013;&#30340;&#20219;&#20309;&#28431;&#27934;&#23545;&#25915;&#20987;&#32773;&#26469;&#35828;&#37117;&#26159;&#19968;&#20010;&#23500;&#30719;&#12290;NoC&#23433;&#20840;&#20381;&#36182;&#20110;&#23545;&#21508;&#31181;&#25915;&#20987;&#30340;&#26377;&#25928;&#38450;&#33539;&#25514;&#26045;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;NoC&#26550;&#26500;&#20013;&#29616;&#26377;&#21311;&#21517;&#36335;&#30001;&#21327;&#35758;&#30340;&#23433;&#20840;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26412;&#25991;&#20316;&#20986;&#20102;&#20004;&#20010;&#37325;&#35201;&#36129;&#29486;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#21311;&#21517;&#36335;&#30001;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#26159;&#26131;&#21463;&#25915;&#20987;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#20351;&#29992;&#27969;&#37327;&#28151;&#28102;&#25216;&#26415;&#65292;&#21487;&#20197;&#25269;&#24481;&#22522;&#20110;ML&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#12290;&#20351;&#29992;&#23454;&#38469;&#21644;&#21512;&#25104;&#27969;&#37327;&#36827;&#34892;&#30340;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25915;&#20987;&#33021;&#22815;&#25104;&#21151;&#22320;&#23545;&#25239;NoC&#26550;&#26500;&#20013;&#26368;&#20808;&#36827;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#23545;&#20110;&#22810;&#31181;&#27969;&#37327;&#27169;&#24335;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#39640;&#36798;99&#65285;&#65292;&#21516;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network-on-Chip (NoC) is widely used as the internal communication fabric in today's multicore System-on-Chip (SoC) designs. Security of the on-chip communication is crucial because exploiting any vulnerability in shared NoC would be a goldmine for an attacker. NoC security relies on effective countermeasures against diverse attacks. We investigate the security strength of existing anonymous routing protocols in NoC architectures. Specifically, this paper makes two important contributions. We show that the existing anonymous routing is vulnerable to machine learning (ML) based flow correlation attacks on NoCs. We propose a lightweight anonymous routing that use traffic obfuscation techniques which can defend against ML-based flow correlation attacks. Experimental studies using both real and synthetic traffic reveal that our proposed attack is successful against state-of-the-art anonymous routing in NoC architectures with a high accuracy (up to 99%) for diverse traffic patterns, while o
&lt;/p&gt;</description></item></channel></rss>