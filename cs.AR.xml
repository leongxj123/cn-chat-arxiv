<rss version="2.0"><channel><title>Chat Arxiv cs.AR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AR</description><item><title>TransAxx&#26159;&#19968;&#20010;&#22522;&#20110;PyTorch&#24211;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#25903;&#25345;&#36817;&#20284;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#23545;Vision Transformer&#27169;&#22411;&#36827;&#34892;&#36817;&#20284;&#24863;&#30693;&#24494;&#35843;&#65292;&#26469;&#25552;&#39640;&#22312;&#20302;&#21151;&#32791;&#35774;&#22791;&#19978;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.07545</link><description>&lt;p&gt;
TransAxx&#65306;&#20855;&#26377;&#36817;&#20284;&#35745;&#31639;&#33021;&#21147;&#30340;&#39640;&#25928;Transformer&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
TransAxx: Efficient Transformers with Approximate Computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07545
&lt;/p&gt;
&lt;p&gt;
TransAxx&#26159;&#19968;&#20010;&#22522;&#20110;PyTorch&#24211;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#25903;&#25345;&#36817;&#20284;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#23545;Vision Transformer&#27169;&#22411;&#36827;&#34892;&#36817;&#20284;&#24863;&#30693;&#24494;&#35843;&#65292;&#26469;&#25552;&#39640;&#22312;&#20302;&#21151;&#32791;&#35774;&#22791;&#19978;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;Transformer&#26550;&#26500;&#24341;&#20837;&#30340;Vision Transformer (ViT)&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#24456;&#22823;&#30340;&#31454;&#20105;&#21147;&#65292;&#24182;&#19988;&#24448;&#24448;&#25104;&#20026;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#39640;&#35745;&#31639;&#38656;&#27714;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#20302;&#21151;&#32791;&#35774;&#22791;&#19978;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#37319;&#29992;&#36817;&#20284;&#20056;&#27861;&#22120;&#26469;&#35299;&#20915;DNN&#21152;&#36895;&#22120;&#39640;&#35745;&#31639;&#38656;&#27714;&#30340;&#38382;&#39064;&#65292;&#20294;&#20043;&#21069;&#30340;&#30740;&#31350;&#24182;&#27809;&#26377;&#25506;&#32034;&#20854;&#22312;ViT&#27169;&#22411;&#19978;&#30340;&#24212;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TransAxx&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#27969;&#34892;&#30340;PyTorch&#24211;&#30340;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#24555;&#36895;&#25903;&#25345;&#36817;&#20284;&#31639;&#26415;&#65292;&#20197;&#26080;&#32541;&#22320;&#35780;&#20272;&#36817;&#20284;&#35745;&#31639;&#23545;&#20110;DNN (&#22914;ViT&#27169;&#22411;)&#30340;&#24433;&#21709;&#12290;&#20351;&#29992;TransAxx&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;Transformer&#27169;&#22411;&#22312;ImageNet&#25968;&#25454;&#38598;&#19978;&#23545;&#36817;&#20284;&#20056;&#27861;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#36827;&#34892;&#20102;&#36817;&#20284;&#24863;&#30693;&#30340;&#24494;&#35843;&#20197;&#24674;&#22797;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#36817;&#20284;&#21152;&#27861;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vision Transformer (ViT) models which were recently introduced by the transformer architecture have shown to be very competitive and often become a popular alternative to Convolutional Neural Networks (CNNs). However, the high computational requirements of these models limit their practical applicability especially on low-power devices. Current state-of-the-art employs approximate multipliers to address the highly increased compute demands of DNN accelerators but no prior research has explored their use on ViT models. In this work we propose TransAxx, a framework based on the popular PyTorch library that enables fast inherent support for approximate arithmetic to seamlessly evaluate the impact of approximate computing on DNNs such as ViT models. Using TransAxx we analyze the sensitivity of transformer models on the ImageNet dataset to approximate multiplications and perform approximate-aware finetuning to regain accuracy. Furthermore, we propose a methodology to generate approximate ac
&lt;/p&gt;</description></item></channel></rss>