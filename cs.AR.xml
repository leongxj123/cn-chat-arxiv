<rss version="2.0"><channel><title>Chat Arxiv cs.AR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AR</description><item><title>HEAM&#26159;&#19968;&#31181;&#37319;&#29992;&#24322;&#26500;&#20869;&#23384;&#26550;&#26500;&#30340;&#26041;&#27861;&#65292;&#23558;3D&#22534;&#21472;DRAM&#19982;DIMM&#38598;&#25104;&#65292;&#29992;&#20110;&#21152;&#36895;&#22788;&#29702;&#22823;&#35268;&#27169;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#23884;&#20837;&#25805;&#20316;&#12290;</title><link>https://arxiv.org/abs/2402.04032</link><description>&lt;p&gt;
HEAM: &#20351;&#29992;&#22788;&#29702;-&#20869;&#23384;&#36827;&#34892;&#25955;&#21015;&#23884;&#20837;&#21152;&#36895;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
HEAM : Hashed Embedding Acceleration using Processing-In-Memory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04032
&lt;/p&gt;
&lt;p&gt;
HEAM&#26159;&#19968;&#31181;&#37319;&#29992;&#24322;&#26500;&#20869;&#23384;&#26550;&#26500;&#30340;&#26041;&#27861;&#65292;&#23558;3D&#22534;&#21472;DRAM&#19982;DIMM&#38598;&#25104;&#65292;&#29992;&#20110;&#21152;&#36895;&#22788;&#29702;&#22823;&#35268;&#27169;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#23884;&#20837;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#30340;&#25968;&#25454;&#20013;&#24515;&#20013;&#65292;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30528;&#35832;&#22810;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#25191;&#34892;&#23884;&#20837;&#25805;&#20316;&#26102;&#38656;&#35201;&#22823;&#23481;&#37327;&#30340;&#20869;&#23384;&#21644;&#39640;&#24102;&#23485;&#12290;&#20043;&#21069;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;DIMM-based&#36817;&#20869;&#23384;&#22788;&#29702;&#25216;&#26415;&#25110;&#24341;&#20837;3D&#22534;&#21472;DRAM&#26469;&#35299;&#20915;&#20869;&#23384;&#38480;&#21046;&#21644;&#25193;&#23637;&#20869;&#23384;&#24102;&#23485;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#22312;&#22788;&#29702;&#26085;&#30410;&#25193;&#22823;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#22823;&#23567;&#26102;&#23384;&#22312;&#19981;&#36275;&#20043;&#22788;&#12290;&#25512;&#33616;&#27169;&#22411;&#24050;&#32463;&#22686;&#38271;&#21040;&#36229;&#36807;&#25968;&#21313;TB&#30340;&#22823;&#23567;&#65292;&#23548;&#33268;&#22312;&#20256;&#32479;&#21333;&#33410;&#28857;&#25512;&#26029;&#26381;&#21153;&#22120;&#19978;&#39640;&#25928;&#36816;&#34892;&#21464;&#24471;&#22256;&#38590;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#31639;&#27861;&#26041;&#27861;&#26469;&#20943;&#23567;&#23884;&#20837;&#34920;&#23481;&#37327;&#65292;&#20294;&#36890;&#24120;&#20250;&#23548;&#33268;&#20869;&#23384;&#35775;&#38382;&#22686;&#21152;&#25110;&#20869;&#23384;&#36164;&#28304;&#21033;&#29992;&#20302;&#25928;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;HEAM&#65292;&#19968;&#31181;&#24322;&#26500;&#20869;&#23384;&#26550;&#26500;&#65292;&#23558;3D&#22534;&#21472;DRAM&#19982;DIMM&#38598;&#25104;&#22312;&#19968;&#36215;&#65292;&#20197;&#21152;&#36895;&#32452;&#21512;&#23884;&#20837;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data centers, personalized recommendation systems face challenges such as the need for large memory capacity and high bandwidth, especially when performing embedding operations. Previous approaches have relied on DIMM-based near-memory processing techniques or introduced 3D-stacked DRAM to address memory-bound issues and expand memory bandwidth. However, these solutions fall short when dealing with the expanding size of personalized recommendation systems. Recommendation models have grown to sizes exceeding tens of terabytes, making them challenging to run efficiently on traditional single-node inference servers. Although various algorithmic methods have been proposed to reduce embedding table capacity, they often result in increased memory access or inefficient utilization of memory resources. This paper introduces HEAM, a heterogeneous memory architecture that integrates 3D-stacked DRAM with DIMM to accelerate recommendation systems in which compositional embedding is util
&lt;/p&gt;</description></item></channel></rss>