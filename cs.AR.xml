<rss version="2.0"><channel><title>Chat Arxiv cs.AR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AR</description><item><title>MicroT&#26159;&#19968;&#20010;&#20302;&#33021;&#32791;&#12289;&#22810;&#20219;&#21153;&#33258;&#36866;&#24212;&#27169;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#20998;&#31867;&#22120;&#30340;&#20998;&#31163;&#12289;&#27169;&#22411;&#20248;&#21270;&#21644;&#26412;&#22320;&#20219;&#21153;&#35757;&#32451;&#65292;&#22312;MCUs&#19978;&#23454;&#29616;&#20102;&#27169;&#22411;&#24615;&#33021;&#30340;&#25552;&#21319;&#21644;&#33021;&#32791;&#30340;&#38477;&#20302;&#12290;</title><link>https://arxiv.org/abs/2403.08040</link><description>&lt;p&gt;
MicroT&#65306;&#29992;&#20110;MCUs&#30340;&#20302;&#33021;&#32791;&#21644;&#33258;&#36866;&#24212;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
MicroT: Low-Energy and Adaptive Models for MCUs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08040
&lt;/p&gt;
&lt;p&gt;
MicroT&#26159;&#19968;&#20010;&#20302;&#33021;&#32791;&#12289;&#22810;&#20219;&#21153;&#33258;&#36866;&#24212;&#27169;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#20998;&#31867;&#22120;&#30340;&#20998;&#31163;&#12289;&#27169;&#22411;&#20248;&#21270;&#21644;&#26412;&#22320;&#20219;&#21153;&#35757;&#32451;&#65292;&#22312;MCUs&#19978;&#23454;&#29616;&#20102;&#27169;&#22411;&#24615;&#33021;&#30340;&#25552;&#21319;&#21644;&#33021;&#32791;&#30340;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;MicroT&#65292;&#36825;&#26159;&#19968;&#20010;&#38754;&#21521;&#36164;&#28304;&#21463;&#38480;&#30340;MCUs&#30340;&#20302;&#33021;&#32791;&#12289;&#22810;&#20219;&#21153;&#33258;&#36866;&#24212;&#27169;&#22411;&#26694;&#26550;&#12290;&#25105;&#20204;&#23558;&#21407;&#22987;&#27169;&#22411;&#21010;&#20998;&#20026;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#20998;&#31867;&#22120;&#12290;&#29305;&#24449;&#25552;&#21462;&#22120;&#36890;&#36807;&#33258;&#30417;&#30563;&#30693;&#35782;&#33976;&#39311;&#33719;&#24471;&#65292;&#24182;&#36890;&#36807;&#27169;&#22411;&#20998;&#21106;&#21644;&#32852;&#21512;&#35757;&#32451;&#36827;&#19968;&#27493;&#20248;&#21270;&#20026;&#37096;&#20998;&#27169;&#22411;&#21644;&#23436;&#25972;&#27169;&#22411;&#12290;&#28982;&#21518;&#23558;&#36825;&#20123;&#27169;&#22411;&#37096;&#32626;&#22312;MCUs&#19978;&#65292;&#22686;&#21152;&#24182;&#22312;&#26412;&#22320;&#20219;&#21153;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#26368;&#32456;&#25191;&#34892;&#20851;&#33410;&#25512;&#29702;&#30340;&#38454;&#27573;&#20915;&#31574;&#12290;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#65292;&#37096;&#20998;&#27169;&#22411;&#26368;&#21021;&#22788;&#29702;&#26679;&#26412;&#65292;&#22914;&#26524;&#32622;&#20449;&#24230;&#24471;&#20998;&#20302;&#20110;&#35774;&#23450;&#30340;&#38408;&#20540;&#65292;&#23436;&#25972;&#27169;&#22411;&#23558;&#24674;&#22797;&#24182;&#32487;&#32493;&#25512;&#29702;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#27169;&#22411;&#12289;&#19977;&#20010;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;MCU&#26495;&#19978;&#35780;&#20272;&#20102;MicroT&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#22788;&#29702;&#22810;&#20010;&#26412;&#22320;&#20219;&#21153;&#26102;&#65292;MicroT&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#24182;&#38477;&#20302;&#20102;&#33021;&#32791;&#12290;&#19982;&#26410;&#32463;&#20248;&#21270;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#30456;&#27604;&#65292;MicroT
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08040v1 Announce Type: new  Abstract: We propose MicroT, a low-energy, multi-task adaptive model framework for resource-constrained MCUs. We divide the original model into a feature extractor and a classifier. The feature extractor is obtained through self-supervised knowledge distillation and further optimized into part and full models through model splitting and joint training. These models are then deployed on MCUs, with classifiers added and trained on local tasks, ultimately performing stage-decision for joint inference. In this process, the part model initially processes the sample, and if the confidence score falls below the set threshold, the full model will resume and continue the inference. We evaluate MicroT on two models, three datasets, and two MCU boards. Our experimental evaluation shows that MicroT effectively improves model performance and reduces energy consumption when dealing with multiple local tasks. Compared to the unoptimized feature extractor, MicroT
&lt;/p&gt;</description></item></channel></rss>