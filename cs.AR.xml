<rss version="2.0"><channel><title>Chat Arxiv cs.AR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AR</description><item><title>&#26412;&#25991;&#23558;&#30828;&#20214;&#36817;&#20284;&#23884;&#20837;&#21040;&#21360;&#21047;&#22810;&#23618;&#24863;&#30693;&#22120;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#31163;&#25955;&#36951;&#20256;&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#22823;&#21270;&#30828;&#20214;&#36817;&#20284;&#30340;&#25928;&#30410;&#65292;&#22312;5%&#30340;&#31934;&#24230;&#25439;&#22833;&#19979;&#65292;&#30456;&#27604;&#22522;&#32447;&#65292;&#23454;&#29616;&#20102;&#36229;&#36807;5&#20493;&#30340;&#38754;&#31215;&#21644;&#21151;&#32791;&#30340;&#20943;&#23569;&#65292;&#24182;&#19988;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#36817;&#20284;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.02930</link><description>&lt;p&gt;
&#23558;&#30828;&#20214;&#36817;&#20284;&#23884;&#20837;&#31163;&#25955;&#22522;&#22240;&#35757;&#32451;&#20013;&#20197;&#29992;&#20110;&#21360;&#21047;&#22810;&#23618;&#24863;&#30693;&#22120;
&lt;/p&gt;
&lt;p&gt;
Embedding Hardware Approximations in Discrete Genetic-based Training for Printed MLPs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02930
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#30828;&#20214;&#36817;&#20284;&#23884;&#20837;&#21040;&#21360;&#21047;&#22810;&#23618;&#24863;&#30693;&#22120;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#31163;&#25955;&#36951;&#20256;&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#22823;&#21270;&#30828;&#20214;&#36817;&#20284;&#30340;&#25928;&#30410;&#65292;&#22312;5%&#30340;&#31934;&#24230;&#25439;&#22833;&#19979;&#65292;&#30456;&#27604;&#22522;&#32447;&#65292;&#23454;&#29616;&#20102;&#36229;&#36807;5&#20493;&#30340;&#38754;&#31215;&#21644;&#21151;&#32791;&#30340;&#20943;&#23569;&#65292;&#24182;&#19988;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#36817;&#20284;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21360;&#21047;&#30005;&#23376;&#26159;&#19968;&#31181;&#26377;&#30528;&#20302;&#25104;&#26412;&#21644;&#28789;&#27963;&#21046;&#36896;&#31561;&#29420;&#29305;&#29305;&#28857;&#30340;&#26377;&#26395;&#24191;&#27867;&#24212;&#29992;&#20110;&#35745;&#31639;&#39046;&#22495;&#30340;&#25216;&#26415;&#12290;&#19982;&#20256;&#32479;&#30340;&#30789;&#22522;&#25216;&#26415;&#19981;&#21516;&#65292;&#21360;&#21047;&#30005;&#23376;&#21487;&#20197;&#23454;&#29616;&#21487;&#20280;&#32553;&#12289;&#21487;&#36866;&#24212;&#12289;&#38750;&#27602;&#24615;&#30340;&#30828;&#20214;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21360;&#21047;&#30005;&#23376;&#30340;&#29305;&#24615;&#23610;&#23544;&#36739;&#22823;&#65292;&#35201;&#23454;&#29616;&#22797;&#26434;&#30340;&#30005;&#36335;&#22914;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#36817;&#20284;&#35745;&#31639;&#34987;&#35777;&#26126;&#21487;&#20197;&#38477;&#20302;&#26426;&#22120;&#23398;&#20064;&#30005;&#36335;&#65288;&#22914;&#22810;&#23618;&#24863;&#30693;&#22120;&#65289;&#30340;&#30828;&#20214;&#25104;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#30828;&#20214;&#36817;&#20284;&#23884;&#20837;&#21040;&#22810;&#23618;&#24863;&#30693;&#22120;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#26469;&#26368;&#22823;&#21270;&#36817;&#20284;&#35745;&#31639;&#30340;&#30410;&#22788;&#12290;&#30001;&#20110;&#30828;&#20214;&#36817;&#20284;&#30340;&#31163;&#25955;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#23454;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;&#36951;&#20256;&#31639;&#27861;&#30340;&#30828;&#20214;&#24863;&#30693;&#35757;&#32451;&#26041;&#27861;&#65292;&#19987;&#38376;&#20026;&#21360;&#21047;&#22810;&#23618;&#24863;&#30693;&#22120;&#35774;&#35745;&#12290;&#22312;5%&#30340;&#31934;&#24230;&#25439;&#22833;&#19979;&#65292;&#30456;&#27604;&#22522;&#32447;&#65292;&#25105;&#20204;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#22312;&#38754;&#31215;&#21644;&#21151;&#32791;&#19978;&#23454;&#29616;&#20102;&#36229;&#36807;5&#20493;&#30340;&#20943;&#23569;&#65292;&#24182;&#19988;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#36817;&#20284;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Printed Electronics (PE) stands out as a promisingtechnology for widespread computing due to its distinct attributes, such as low costs and flexible manufacturing. Unlike traditional silicon-based technologies, PE enables stretchable, conformal,and non-toxic hardware. However, PE are constrained by larger feature sizes, making it challenging to implement complex circuits such as machine learning (ML) classifiers. Approximate computing has been proven to reduce the hardware cost of ML circuits such as Multilayer Perceptrons (MLPs). In this paper, we maximize the benefits of approximate computing by integrating hardware approximation into the MLP training process. Due to the discrete nature of hardware approximation, we propose and implement a genetic-based, approximate, hardware-aware training approach specifically designed for printed MLPs. For a 5% accuracy loss, our MLPs achieve over 5x area and power reduction compared to the baseline while outperforming state of-the-art approximate
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21360;&#21047;&#30005;&#23376;&#25216;&#26415;&#20013;&#30340;&#38480;&#21046;&#30340;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#36229;&#20302;&#21151;&#32791;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#20998;&#31867;&#22120;&#12290;</title><link>https://arxiv.org/abs/2312.17612</link><description>&lt;p&gt;
&#38754;&#21521;&#21360;&#21047;&#22810;&#23618;&#24863;&#30693;&#26426;&#30340;&#23450;&#21046;&#36817;&#20284;&#20056;&#31215;&#32047;&#21152;&#21644;&#28608;&#27963;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Bespoke Approximation of Multiplication-Accumulation and Activation Targeting Printed Multilayer Perceptrons
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.17612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21360;&#21047;&#30005;&#23376;&#25216;&#26415;&#20013;&#30340;&#38480;&#21046;&#30340;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#36229;&#20302;&#21151;&#32791;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21360;&#21047;&#30005;&#23376;&#25216;&#26415;&#20855;&#26377;&#29420;&#29305;&#30340;&#29305;&#24615;&#65292;&#20351;&#20854;&#25104;&#20026;&#23454;&#29616;&#30495;&#27491;&#26080;&#22788;&#19981;&#22312;&#35745;&#31639;&#30340;&#37325;&#35201;&#25216;&#26415;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#36229;&#20302;&#21151;&#32791;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#21033;&#29992;&#36817;&#20284;&#35745;&#31639;&#21644;&#23450;&#21046;&#21270;&#35774;&#35745;&#30340;&#21407;&#21017;&#26469;&#20811;&#26381;&#21360;&#21047;&#30005;&#23376;&#25216;&#26415;&#20013;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Printed Electronics (PE) feature distinct and remarkable characteristics that make them a prominent technology for achieving true ubiquitous computing. This is particularly relevant in application domains that require conformal and ultra-low cost solutions, which have experienced limited penetration of computing until now. Unlike silicon-based technologies, PE offer unparalleled features such as non-recurring engineering costs, ultra-low manufacturing cost, and on-demand fabrication of conformal, flexible, non-toxic, and stretchable hardware. However, PE face certain limitations due to their large feature sizes, that impede the realization of complex circuits, such as machine learning classifiers. In this work, we address these limitations by leveraging the principles of Approximate Computing and Bespoke (fully-customized) design. We propose an automated framework for designing ultra-low power Multilayer Perceptron (MLP) classifiers which employs, for the first time, a holistic approac
&lt;/p&gt;</description></item></channel></rss>