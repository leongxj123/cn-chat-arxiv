<rss version="2.0"><channel><title>Chat Arxiv cs.LO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LO</description><item><title>LASER&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#23398;&#20064;&#26041;&#27861;&#26469;&#23398;&#20064;&#35821;&#20041;&#35270;&#39057;&#34920;&#31034;&#65292;&#36890;&#36807;&#36923;&#36753;&#35268;&#33539;&#25429;&#25417;&#35270;&#39057;&#25968;&#25454;&#20013;&#30340;&#26102;&#31354;&#23646;&#24615;&#65292;&#33021;&#22815;&#23545;&#40784;&#21407;&#22987;&#35270;&#39057;&#21644;&#35268;&#33539;&#65292;&#26377;&#25928;&#22320;&#35757;&#32451;&#20302;&#32423;&#24863;&#30693;&#27169;&#22411;&#20197;&#25552;&#21462;&#31526;&#21512;&#25152;&#38656;&#39640;&#32423;&#35268;&#33539;&#30340;&#35270;&#39057;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2304.07647</link><description>&lt;p&gt;
LASER&#65306;&#31070;&#32463;&#31526;&#21495;&#23398;&#20064;&#35821;&#20041;&#35270;&#39057;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
LASER: Neuro-Symbolic Learning of Semantic Video Representations. (arXiv:2304.07647v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07647
&lt;/p&gt;
&lt;p&gt;
LASER&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#23398;&#20064;&#26041;&#27861;&#26469;&#23398;&#20064;&#35821;&#20041;&#35270;&#39057;&#34920;&#31034;&#65292;&#36890;&#36807;&#36923;&#36753;&#35268;&#33539;&#25429;&#25417;&#35270;&#39057;&#25968;&#25454;&#20013;&#30340;&#26102;&#31354;&#23646;&#24615;&#65292;&#33021;&#22815;&#23545;&#40784;&#21407;&#22987;&#35270;&#39057;&#21644;&#35268;&#33539;&#65292;&#26377;&#25928;&#22320;&#35757;&#32451;&#20302;&#32423;&#24863;&#30693;&#27169;&#22411;&#20197;&#25552;&#21462;&#31526;&#21512;&#25152;&#38656;&#39640;&#32423;&#35268;&#33539;&#30340;&#35270;&#39057;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28041;&#21450;&#35270;&#39057;&#30340;AI&#24212;&#29992;&#65288;&#22914;&#35270;&#39057;-&#25991;&#26412;&#23545;&#40784;&#12289;&#35270;&#39057;&#25628;&#32034;&#21644;&#35270;&#39057;&#23383;&#24149;&#65289;&#21463;&#30410;&#20110;&#23545;&#35270;&#39057;&#35821;&#20041;&#30340;&#32454;&#33268;&#29702;&#35299;&#12290;&#29616;&#26377;&#30340;&#35270;&#39057;&#29702;&#35299;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#22823;&#37327;&#27880;&#37322;&#65292;&#35201;&#20040;&#22522;&#20110;&#19981;&#21487;&#35299;&#37322;&#30340;&#36890;&#29992;&#23884;&#20837;&#65292;&#21487;&#33021;&#20250;&#24573;&#30053;&#37325;&#35201;&#32454;&#33410;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;LASER&#65292;&#36825;&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#33021;&#22815;&#25429;&#25417;&#35270;&#39057;&#25968;&#25454;&#20013;&#20016;&#23500;&#30340;&#26102;&#31354;&#23646;&#24615;&#30340;&#36923;&#36753;&#35268;&#33539;&#26469;&#23398;&#20064;&#35821;&#20041;&#35270;&#39057;&#34920;&#31034;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#21407;&#22987;&#35270;&#39057;&#19982;&#35268;&#33539;&#20043;&#38388;&#30340;&#23545;&#40784;&#26469;&#20844;&#24335;&#21270;&#38382;&#39064;&#12290;&#23545;&#40784;&#36807;&#31243;&#26377;&#25928;&#22320;&#35757;&#32451;&#20102;&#20302;&#23618;&#24863;&#30693;&#27169;&#22411;&#65292;&#20197;&#25552;&#21462;&#31526;&#21512;&#25152;&#38656;&#39640;&#23618;&#35268;&#33539;&#30340;&#32454;&#31890;&#24230;&#35270;&#39057;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#27969;&#31243;&#21487;&#20197;&#31471;&#21040;&#31471;&#22320;&#35757;&#32451;&#65292;&#24182;&#21487;&#32435;&#20837;&#20174;&#35268;&#33539;&#23548;&#20986;&#30340;&#23545;&#27604;&#21644;&#35821;&#20041;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20855;&#26377;&#20016;&#23500;&#31354;&#38388;&#21644;&#26102;&#38388;&#20449;&#24687;&#30340;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern AI applications involving video, such as video-text alignment, video search, and video captioning, benefit from a fine-grained understanding of video semantics. Existing approaches for video understanding are either data-hungry and need low-level annotation, or are based on general embeddings that are uninterpretable and can miss important details. We propose LASER, a neuro-symbolic approach that learns semantic video representations by leveraging logic specifications that can capture rich spatial and temporal properties in video data. In particular, we formulate the problem in terms of alignment between raw videos and specifications. The alignment process efficiently trains low-level perception models to extract a fine-grained video representation that conforms to the desired high-level specification. Our pipeline can be trained end-to-end and can incorporate contrastive and semantic loss functions derived from specifications. We evaluate our method on two datasets with rich sp
&lt;/p&gt;</description></item></channel></rss>