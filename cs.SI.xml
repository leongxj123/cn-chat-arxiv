<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#26159;&#19968;&#31181;&#20559;&#20506;&#24230;&#37327;&#65292;&#22240;&#20026;&#23427;&#24573;&#30053;&#20102;&#26465;&#20214;&#34920;&#30340;&#20449;&#24687;&#20869;&#23481;&#24182;&#19988;&#23545;&#31639;&#27861;&#36755;&#20986;&#26377;&#22122;&#22768;&#20381;&#36182;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#29256;&#26412;&#30340;&#20114;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23545;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#30340;&#27979;&#35797;&#35777;&#26126;&#20102;&#20351;&#29992;&#26080;&#20559;&#24230;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.01282</link><description>&lt;p&gt;
&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#26159;&#20998;&#31867;&#21644;&#31038;&#21306;&#26816;&#27979;&#30340;&#19968;&#31181;&#20559;&#20506;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Normalized mutual information is a biased measure for classification and community detection. (arXiv:2307.01282v1 [cs.SI] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01282
&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#26159;&#19968;&#31181;&#20559;&#20506;&#24230;&#37327;&#65292;&#22240;&#20026;&#23427;&#24573;&#30053;&#20102;&#26465;&#20214;&#34920;&#30340;&#20449;&#24687;&#20869;&#23481;&#24182;&#19988;&#23545;&#31639;&#27861;&#36755;&#20986;&#26377;&#22122;&#22768;&#20381;&#36182;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#29256;&#26412;&#30340;&#20114;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23545;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#30340;&#27979;&#35797;&#35777;&#26126;&#20102;&#20351;&#29992;&#26080;&#20559;&#24230;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#24402;&#19968;&#20114;&#20449;&#24687;&#34987;&#24191;&#27867;&#29992;&#20316;&#35780;&#20272;&#32858;&#31867;&#21644;&#20998;&#31867;&#31639;&#27861;&#24615;&#33021;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#12290;&#26412;&#25991;&#34920;&#26126;&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#30340;&#32467;&#26524;&#26377;&#20004;&#20010;&#20559;&#20506;&#22240;&#32032;&#65306;&#39318;&#20808;&#65292;&#22240;&#20026;&#23427;&#20204;&#24573;&#30053;&#20102;&#26465;&#20214;&#34920;&#30340;&#20449;&#24687;&#20869;&#23481;&#65307;&#20854;&#27425;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#23545;&#31216;&#24402;&#19968;&#21270;&#24341;&#20837;&#20102;&#23545;&#31639;&#27861;&#36755;&#20986;&#30340;&#22122;&#22768;&#20381;&#36182;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#29256;&#26412;&#30340;&#20114;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#32570;&#38519;&#12290;&#36890;&#36807;&#23545;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#20013;&#19968;&#31726;&#23376;&#27969;&#34892;&#31639;&#27861;&#36827;&#34892;&#22823;&#37327;&#25968;&#20540;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#26080;&#20559;&#24230;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#19988;&#26174;&#31034;&#20256;&#32479;&#20114;&#20449;&#24687;&#20013;&#30340;&#20559;&#20506;&#23545;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#30340;&#32467;&#35770;&#20135;&#29983;&#20102;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalized mutual information is widely used as a similarity measure for evaluating the performance of clustering and classification algorithms. In this paper, we show that results returned by the normalized mutual information are biased for two reasons: first, because they ignore the information content of the contingency table and, second, because their symmetric normalization introduces spurious dependence on algorithm output. We introduce a modified version of the mutual information that remedies both of these shortcomings. As a practical demonstration of the importance of using an unbiased measure, we perform extensive numerical tests on a basket of popular algorithms for network community detection and show that one's conclusions about which algorithm is best are significantly affected by the biases in the traditional mutual information.
&lt;/p&gt;</description></item></channel></rss>