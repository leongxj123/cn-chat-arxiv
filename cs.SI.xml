<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>NGG&#26159;&#19968;&#20010;&#31070;&#32463;&#22270;&#29983;&#25104;&#22120;&#65292;&#36890;&#36807;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#20102;&#29305;&#24449;&#26465;&#20214;&#22270;&#29983;&#25104;&#65292;&#20855;&#26377;&#27169;&#25311;&#22797;&#26434;&#22270;&#27169;&#24335;&#21644;&#25511;&#21046;&#22270;&#29983;&#25104;&#36807;&#31243;&#30340;&#26174;&#33879;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.01535</link><description>&lt;p&gt;
&#31070;&#32463;&#22270;&#29983;&#25104;&#22120;&#65306;&#20351;&#29992;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#29305;&#24449;&#26465;&#20214;&#22270;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Neural Graph Generator: Feature-Conditioned Graph Generation using Latent Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01535
&lt;/p&gt;
&lt;p&gt;
NGG&#26159;&#19968;&#20010;&#31070;&#32463;&#22270;&#29983;&#25104;&#22120;&#65292;&#36890;&#36807;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#20102;&#29305;&#24449;&#26465;&#20214;&#22270;&#29983;&#25104;&#65292;&#20855;&#26377;&#27169;&#25311;&#22797;&#26434;&#22270;&#27169;&#24335;&#21644;&#25511;&#21046;&#22270;&#29983;&#25104;&#36807;&#31243;&#30340;&#26174;&#33879;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#29983;&#25104;&#24050;&#32463;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#65292;&#38754;&#20020;&#30528;&#29983;&#25104;&#33021;&#22815;&#20934;&#30830;&#21453;&#26144;&#29305;&#23450;&#23646;&#24615;&#30340;&#22270;&#24418;&#30340;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#31070;&#32463;&#22270;&#29983;&#25104;&#22120;&#65288;NGG&#65289;&#36825;&#19968;&#26032;&#39062;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#26465;&#20214;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#22270;&#29983;&#25104;&#12290;NGG&#23637;&#31034;&#20102;&#23545;&#22797;&#26434;&#22270;&#27169;&#24335;&#36827;&#34892;&#24314;&#27169;&#30340;&#26174;&#33879;&#33021;&#21147;&#65292;&#25552;&#20379;&#20102;&#23545;&#22270;&#29983;&#25104;&#36807;&#31243;&#30340;&#25511;&#21046;&#12290;NGG&#21033;&#29992;&#21464;&#20998;&#22270;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#22270;&#21387;&#32553;&#65292;&#21033;&#29992;&#22312;&#28508;&#22312;&#21521;&#37327;&#31354;&#38388;&#20013;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#30001;&#24635;&#32467;&#22270;&#32479;&#35745;&#20449;&#24687;&#30340;&#21521;&#37327;&#25351;&#23548;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;NGG&#22312;&#21508;&#31181;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#36890;&#29992;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#25429;&#25417;&#26399;&#26395;&#22270;&#23646;&#24615;&#24182;&#25512;&#24191;&#21040;&#26410;&#35265;&#22270;&#24418;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01535v1 Announce Type: new  Abstract: Graph generation has emerged as a crucial task in machine learning, with significant challenges in generating graphs that accurately reflect specific properties. Existing methods often fall short in efficiently addressing this need as they struggle with the high-dimensional complexity and varied nature of graph properties. In this paper, we introduce the Neural Graph Generator (NGG), a novel approach which utilizes conditioned latent diffusion models for graph generation. NGG demonstrates a remarkable capacity to model complex graph patterns, offering control over the graph generation process. NGG employs a variational graph autoencoder for graph compression and a diffusion process in the latent vector space, guided by vectors summarizing graph statistics. We demonstrate NGG's versatility across various graph generation tasks, showing its capability to capture desired graph properties and generalize to unseen graphs. This work signifies 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#24320;&#21457;&#20102;LLaVA-Docent&#27169;&#22411;&#65292;&#20197;&#25903;&#25345;&#33402;&#26415;&#37492;&#36175;&#25945;&#32946;&#12290;&#36890;&#36807;&#32508;&#36848;&#25991;&#29486;&#21644;&#19987;&#23478;&#21672;&#35810;&#65292;&#26500;&#24314;&#20102;&#25968;&#25454;&#26694;&#26550;&#65292;&#24182;&#20351;&#29992;&#35813;&#26694;&#26550;&#29983;&#25104;&#20102;&#34394;&#25311;&#23545;&#35805;&#25968;&#25454;&#38598;&#29992;&#20110;&#35757;&#32451;MLLM&#12290;&#35813;&#30740;&#31350;&#23545;&#20110;&#35299;&#20915;&#20256;&#32479;&#33402;&#26415;&#37492;&#36175;&#25945;&#32946;&#20013;&#30340;&#36164;&#28304;&#38480;&#21046;&#21644;&#20027;&#27969;&#25945;&#32946;&#20013;&#30340;&#31185;&#23398;&#25216;&#26415;&#24037;&#31243;&#21644;&#25968;&#23398;&#20559;&#37325;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>https://arxiv.org/abs/2402.06264</link><description>&lt;p&gt;
LLaVA-Docent&#65306;&#21033;&#29992;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25903;&#25345;&#33402;&#26415;&#37492;&#36175;&#25945;&#32946;&#30340;&#25945;&#23398;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06264
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#24320;&#21457;&#20102;LLaVA-Docent&#27169;&#22411;&#65292;&#20197;&#25903;&#25345;&#33402;&#26415;&#37492;&#36175;&#25945;&#32946;&#12290;&#36890;&#36807;&#32508;&#36848;&#25991;&#29486;&#21644;&#19987;&#23478;&#21672;&#35810;&#65292;&#26500;&#24314;&#20102;&#25968;&#25454;&#26694;&#26550;&#65292;&#24182;&#20351;&#29992;&#35813;&#26694;&#26550;&#29983;&#25104;&#20102;&#34394;&#25311;&#23545;&#35805;&#25968;&#25454;&#38598;&#29992;&#20110;&#35757;&#32451;MLLM&#12290;&#35813;&#30740;&#31350;&#23545;&#20110;&#35299;&#20915;&#20256;&#32479;&#33402;&#26415;&#37492;&#36175;&#25945;&#32946;&#20013;&#30340;&#36164;&#28304;&#38480;&#21046;&#21644;&#20027;&#27969;&#25945;&#32946;&#20013;&#30340;&#31185;&#23398;&#25216;&#26415;&#24037;&#31243;&#21644;&#25968;&#23398;&#20559;&#37325;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33402;&#26415;&#37492;&#36175;&#23545;&#20110;&#22521;&#20859;&#23398;&#20064;&#32773;&#30340;&#25209;&#21028;&#24615;&#24605;&#32500;&#21644;&#24773;&#24863;&#26234;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#33402;&#26415;&#37492;&#36175;&#25945;&#32946;&#24120;&#38754;&#20020;&#33402;&#26415;&#36164;&#28304;&#26377;&#38480;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#24369;&#21183;&#23398;&#29983;&#65292;&#24182;&#19988;&#22312;&#20027;&#27969;&#25945;&#32946;&#20013;&#36807;&#24230;&#24378;&#35843;&#31185;&#23398;&#25216;&#26415;&#24037;&#31243;&#21644;&#25968;&#23398;&#31185;&#30446;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#26368;&#36817;&#30340;&#25216;&#26415;&#36827;&#27493;&#20026;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#22312;&#33402;&#26415;&#37492;&#36175;&#25945;&#32946;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#26159;&#24320;&#21457;&#20102;LLaVA-Docent&#27169;&#22411;&#26469;&#21033;&#29992;&#36825;&#20123;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#20840;&#38754;&#30340;&#25991;&#29486;&#32508;&#36848;&#21644;&#19982;&#39046;&#22495;&#19987;&#23478;&#30340;&#21672;&#35810;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#25968;&#25454;&#26694;&#26550;&#12290;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#29983;&#25104;&#20102;&#19968;&#20010;&#34394;&#25311;&#23545;&#35805;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#34987;GPT-4&#21033;&#29992;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#23545;&#20110;&#35757;&#32451;MLLM&#65288;&#21363;LLaVA-Docent&#65289;&#36215;&#21040;&#20102;&#20851;&#38190;&#20316;&#29992;&#12290;&#20845;&#21517;&#30740;&#31350;&#20154;&#21592;&#36827;&#34892;&#20102;&#23450;&#37327;&#21644;&#23450;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Art appreciation is vital in nurturing critical thinking and emotional intelligence among learners. However, traditional art appreciation education has often been hindered by limited access to art resources, especially for disadvantaged students, and an imbalanced emphasis on STEM subjects in mainstream education. In response to these challenges, recent technological advancements have paved the way for innovative solutions. This study explores the application of multi-modal large language models (MLLMs) in art appreciation education, focusing on developing LLaVA-Docent, a model that leverages these advancements. Our approach involved a comprehensive literature review and consultations with experts in the field, leading to developing a robust data framework. Utilizing this framework, we generated a virtual dialogue dataset that was leveraged by GPT-4. This dataset was instrumental in training the MLLM, named LLaVA-Docent. Six researchers conducted quantitative and qualitative evaluation
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bayan&#30340;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#25110;&#36817;&#20284;&#20248;&#21270;&#27169;&#22359;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#36820;&#22238;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#30340;&#20998;&#21306;&#65292;&#24182;&#19988;&#27604;&#20854;&#20182;&#31639;&#27861;&#24555;&#25968;&#20493;&#65292;&#24182;&#33021;&#22815;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#20934;&#30830;&#22320;&#25214;&#21040;&#22320;&#38754;&#30495;&#23454;&#31038;&#21306;&#12290;</title><link>http://arxiv.org/abs/2209.04562</link><description>&lt;p&gt;
Bayan&#31639;&#27861;&#65306;&#36890;&#36807;&#23545;&#27169;&#22359;&#24230;&#30340;&#31934;&#30830;&#21644;&#36817;&#20284;&#20248;&#21270;&#26469;&#26816;&#27979;&#32593;&#32476;&#20013;&#30340;&#31038;&#21306;
&lt;/p&gt;
&lt;p&gt;
The Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity. (arXiv:2209.04562v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04562
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bayan&#30340;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#25110;&#36817;&#20284;&#20248;&#21270;&#27169;&#22359;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#36820;&#22238;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#30340;&#20998;&#21306;&#65292;&#24182;&#19988;&#27604;&#20854;&#20182;&#31639;&#27861;&#24555;&#25968;&#20493;&#65292;&#24182;&#33021;&#22815;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#20934;&#30830;&#22320;&#25214;&#21040;&#22320;&#38754;&#30495;&#23454;&#31038;&#21306;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#32593;&#32476;&#31185;&#23398;&#20013;&#30340;&#32463;&#20856;&#38382;&#39064;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#22312;&#20247;&#22810;&#26041;&#27861;&#20013;&#65292;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#26368;&#22823;&#21270;&#27169;&#22359;&#24230;&#12290;&#23613;&#31649;&#21551;&#21457;&#24335;&#27169;&#22359;&#24230;&#26368;&#22823;&#21270;&#31639;&#27861;&#35774;&#35745;&#29702;&#24565;&#21644;&#24191;&#27867;&#37319;&#29992;&#65292;&#20294;&#24456;&#23569;&#36820;&#22238;&#26368;&#20339;&#20998;&#21306;&#25110;&#31867;&#20284;&#20998;&#21306;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#38376;&#30340;&#31639;&#27861;Bayan&#65292;&#23427;&#36820;&#22238;&#20855;&#26377;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#20998;&#21306;&#20445;&#35777;&#30340;&#20998;&#21306;&#12290;Bayan&#31639;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#20998;&#25903;&#38480;&#30028;&#26041;&#26696;&#65292;&#23427;&#35299;&#20915;&#20102;&#38382;&#39064;&#30340;&#25972;&#25968;&#35268;&#21010;&#20844;&#24335;&#20197;&#36798;&#21040;&#26368;&#20248;&#25110;&#36817;&#20284;&#26368;&#20248;&#30340;&#30446;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;Bayan&#22312;&#21512;&#25104;&#22522;&#20934;&#21644;&#30495;&#23454;&#32593;&#32476;&#33410;&#28857;&#26631;&#31614;&#30340;&#26816;&#32034;&#22320;&#38754;&#30495;&#23454;&#31038;&#21306;&#26041;&#38754;&#20855;&#26377;&#29420;&#29305;&#30340;&#20934;&#30830;&#24615;&#21644;&#31283;&#23450;&#24615;&#65292;&#27604;&#20854;&#20182;21&#31181;&#31639;&#27861;&#24555;&#25968;&#20493;&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#20248;&#20998;&#21306;&#30340;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is a classic problem in network science with extensive applications in various fields. Among numerous approaches, the most common method is modularity maximization. Despite their design philosophy and wide adoption, heuristic modularity maximization algorithms rarely return an optimal partition or anything similar. We propose a specialized algorithm, Bayan, which returns partitions with a guarantee of either optimality or proximity to an optimal partition. At the core of the Bayan algorithm is a branch-and-cut scheme that solves an integer programming formulation of the problem to optimality or approximate it within a factor. We demonstrate Bayan's distinctive accuracy and stability over 21 other algorithms in retrieving ground-truth communities in synthetic benchmarks and node labels in real networks. Bayan is several times faster than open-source and commercial solvers for modularity maximization making it capable of finding optimal partitions for instances that c
&lt;/p&gt;</description></item></channel></rss>