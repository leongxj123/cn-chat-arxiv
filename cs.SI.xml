<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#36825;&#20010;&#30740;&#31350;&#25551;&#36848;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#65292;&#36890;&#36807;&#36861;&#36394;&#21644;&#27169;&#25311;&#29289;&#20307;&#24863;&#30693;&#20197;&#21450;&#20854;&#22312;&#20132;&#27969;&#20013;&#25152;&#20256;&#36798;&#30340;&#34920;&#31034;&#26469;&#27169;&#25311;&#20154;&#31867;&#30340;&#24847;&#35782;&#12290;&#30456;&#27604;&#20110;&#22823;&#22810;&#25968;&#26080;&#27861;&#35299;&#37322;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#35299;&#37322;&#24615;&#65292;&#24182;&#21487;&#20197;&#36890;&#36807;&#26500;&#24314;&#26032;&#32593;&#32476;&#26469;&#23450;&#20041;&#29289;&#20307;&#24863;&#30693;&#12290;</title><link>https://arxiv.org/abs/2310.05212</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#31526;&#21495;&#32593;&#32476;&#20195;&#34920;&#24847;&#35782;&#30340;&#30693;&#35273;
&lt;/p&gt;
&lt;p&gt;
Interpretable Semiotics Networks Representing Awareness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.05212
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#30740;&#31350;&#25551;&#36848;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#65292;&#36890;&#36807;&#36861;&#36394;&#21644;&#27169;&#25311;&#29289;&#20307;&#24863;&#30693;&#20197;&#21450;&#20854;&#22312;&#20132;&#27969;&#20013;&#25152;&#20256;&#36798;&#30340;&#34920;&#31034;&#26469;&#27169;&#25311;&#20154;&#31867;&#30340;&#24847;&#35782;&#12290;&#30456;&#27604;&#20110;&#22823;&#22810;&#25968;&#26080;&#27861;&#35299;&#37322;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#35299;&#37322;&#24615;&#65292;&#24182;&#21487;&#20197;&#36890;&#36807;&#26500;&#24314;&#26032;&#32593;&#32476;&#26469;&#23450;&#20041;&#29289;&#20307;&#24863;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#27599;&#22825;&#37117;&#24863;&#30693;&#29289;&#20307;&#65292;&#24182;&#36890;&#36807;&#21508;&#31181;&#28192;&#36947;&#20256;&#36798;&#20182;&#20204;&#30340;&#24863;&#30693;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#65292;&#36861;&#36394;&#21644;&#27169;&#25311;&#29289;&#20307;&#30340;&#24863;&#30693;&#20197;&#21450;&#23427;&#20204;&#22312;&#20132;&#27969;&#20013;&#25152;&#20256;&#36798;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#25105;&#20204;&#20869;&#37096;&#34920;&#31034;&#30340;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65288;"&#35266;&#23519;&#21040;&#30340;"&#21644;"&#30475;&#21040;&#30340;"&#65289;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#29087;&#24713;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#27010;&#24565;&#65288;&#32534;&#30721;&#21644;&#35299;&#30721;&#65289;&#30456;&#20851;&#32852;&#12290;&#36825;&#20123;&#20803;&#32032;&#34987;&#21512;&#24182;&#22312;&#19968;&#36215;&#24418;&#25104;&#31526;&#21495;&#32593;&#32476;&#65292;&#27169;&#25311;&#20102;&#29289;&#20307;&#24863;&#30693;&#21644;&#20154;&#31867;&#20132;&#27969;&#20013;&#30340;&#24847;&#35782;&#12290;&#22914;&#20170;&#65292;&#22823;&#22810;&#25968;&#31070;&#32463;&#32593;&#32476;&#37117;&#26159;&#19981;&#21487;&#35299;&#37322;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#21487;&#35265;&#24615;&#12290;&#25105;&#20204;&#20154;&#30340;&#29289;&#20307;&#24863;&#30693;&#27169;&#22411;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#32593;&#32476;&#23450;&#20041;&#29289;&#20307;&#24863;&#30693;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#21253;&#25324;&#22522;&#20934;&#20998;&#31867;&#22120;&#21644;&#39069;&#22806;&#23618;&#30340;&#26032;&#32593;&#32476;&#26469;&#28436;&#31034;&#36825;&#19968;&#28857;&#12290;&#36825;&#20010;&#23618;&#20135;&#29983;&#20102;&#22270;&#20687;&#30340;&#24863;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;
Humans perceive objects daily and communicate their perceptions using various channels. Here, we describe a computational model that tracks and simulates objects' perception and their representations as they are conveyed in communication.   We describe two key components of our internal representation ("observed" and "seen") and relate them to familiar computer vision notions (encoding and decoding). These elements are joined together to form semiotics networks, which simulate awareness in object perception and human communication.   Nowadays, most neural networks are uninterpretable. On the other hand, our model overcomes this limitation. The experiments demonstrates the visibility of the model.   Our model of object perception by a person allows us to define object perception by a network. We demonstrate this with an example of an image baseline classifier by constructing a new network that includes the baseline classifier and an additional layer. This layer produces the images "perc
&lt;/p&gt;</description></item><item><title>STANCE-C3&#26159;&#19968;&#31181;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#21453;&#20107;&#23454;&#29983;&#25104;&#36827;&#34892;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#36328;&#30446;&#26631;&#31435;&#22330;&#26816;&#27979;&#27169;&#22411;&#65292;&#29992;&#20110;&#25512;&#26029;&#20154;&#20204;&#23545;&#20110;&#26222;&#36941;&#25110;&#26377;&#20105;&#35758;&#35805;&#39064;&#30340;&#35266;&#28857;&#12290;&#22312;&#35299;&#20915;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#21644;&#32570;&#20047;&#39046;&#22495;&#29305;&#23450;&#26631;&#27880;&#25968;&#25454;&#30340;&#25361;&#25112;&#19978;&#20855;&#26377;&#37325;&#35201;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2309.15176</link><description>&lt;p&gt;
STANCE-C3: &#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#21453;&#20107;&#23454;&#29983;&#25104;&#36827;&#34892;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#36328;&#30446;&#26631;&#31435;&#22330;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation. (arXiv:2309.15176v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15176
&lt;/p&gt;
&lt;p&gt;
STANCE-C3&#26159;&#19968;&#31181;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#21453;&#20107;&#23454;&#29983;&#25104;&#36827;&#34892;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#36328;&#30446;&#26631;&#31435;&#22330;&#26816;&#27979;&#27169;&#22411;&#65292;&#29992;&#20110;&#25512;&#26029;&#20154;&#20204;&#23545;&#20110;&#26222;&#36941;&#25110;&#26377;&#20105;&#35758;&#35805;&#39064;&#30340;&#35266;&#28857;&#12290;&#22312;&#35299;&#20915;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#21644;&#32570;&#20047;&#39046;&#22495;&#29305;&#23450;&#26631;&#27880;&#25968;&#25454;&#30340;&#25361;&#25112;&#19978;&#20855;&#26377;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31435;&#22330;&#26816;&#27979;&#26159;&#36890;&#36807;&#25512;&#26029;&#19968;&#20010;&#20154;&#22312;&#29305;&#23450;&#38382;&#39064;&#19978;&#30340;&#31435;&#22330;&#25110;&#35266;&#28857;&#65292;&#20197;&#25512;&#26029;&#23545;&#20110;&#26222;&#36941;&#25110;&#26377;&#20105;&#35758;&#30340;&#35805;&#39064;&#30340;&#26222;&#36941;&#30475;&#27861;&#65292;&#20363;&#22914;COVID-19&#30123;&#24773;&#26399;&#38388;&#30340;&#20581;&#24247;&#25919;&#31574;&#12290;&#29616;&#26377;&#30340;&#31435;&#22330;&#26816;&#27979;&#27169;&#22411;&#22312;&#35757;&#32451;&#26102;&#24448;&#24448;&#22312;&#21333;&#20010;&#39046;&#22495;&#65288;&#20363;&#22914;COVID-19&#65289;&#21644;&#29305;&#23450;&#30446;&#26631;&#35805;&#39064;&#65288;&#20363;&#22914;&#21475;&#32617;&#35268;&#23450;&#65289;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#20854;&#20182;&#39046;&#22495;&#25110;&#30446;&#26631;&#20013;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#65292;&#36825;&#26159;&#30001;&#20110;&#25968;&#25454;&#30340;&#20998;&#24067;&#20559;&#31227;&#12290;&#28982;&#32780;&#65292;&#26500;&#24314;&#39640;&#24615;&#33021;&#30340;&#39046;&#22495;&#29305;&#23450;&#31435;&#22330;&#26816;&#27979;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#19982;&#30446;&#26631;&#39046;&#22495;&#30456;&#20851;&#30340;&#24050;&#26631;&#27880;&#25968;&#25454;&#65292;&#20294;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#24448;&#24448;&#19981;&#23481;&#26131;&#33719;&#21462;&#12290;&#36825;&#23601;&#38754;&#20020;&#30528;&#19968;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#26631;&#27880;&#25968;&#25454;&#30340;&#36807;&#31243;&#20195;&#20215;&#39640;&#26114;&#19988;&#32791;&#26102;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31435;&#22330;&#26816;&#27979;&#27169;&#22411;&#65292;&#31216;&#20026;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#21453;&#20107;&#23454;&#29983;&#25104;&#36827;&#34892;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#36328;&#30446;&#26631;&#31435;&#22330;&#26816;&#27979;&#65288;STANCE-C3&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stance detection is the process of inferring a person's position or standpoint on a specific issue to deduce prevailing perceptions toward topics of general or controversial interest, such as health policies during the COVID-19 pandemic. Existing models for stance detection are trained to perform well for a single domain (e.g., COVID-19) and a specific target topic (e.g., masking protocols), but are generally ineffectual in other domains or targets due to distributional shifts in the data. However, constructing high-performing, domain-specific stance detection models requires an extensive corpus of labeled data relevant to the targeted domain, yet such datasets are not readily available. This poses a challenge as the process of annotating data is costly and time-consuming. To address these challenges, we introduce a novel stance detection model coined domain-adaptive Cross-target STANCE detection via Contrastive learning and Counterfactual generation (STANCE-C3) that uses counterfactua
&lt;/p&gt;</description></item></channel></rss>