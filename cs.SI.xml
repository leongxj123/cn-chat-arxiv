<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;SimMLP&#65292;&#36890;&#36807;&#22312;&#22270;&#19978;&#26080;&#30417;&#30563;&#23398;&#20064;MLPs&#65292;&#25552;&#39640;&#20102;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.08918</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#22312;&#22270;&#19978;&#23398;&#20064;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#21152;&#36895;&#22270;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Graph Inference Acceleration by Learning MLPs on Graphs without Supervision
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08918
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;SimMLP&#65292;&#36890;&#36807;&#22312;&#22270;&#19978;&#26080;&#30417;&#30563;&#23398;&#20064;MLPs&#65292;&#25552;&#39640;&#20102;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24050;&#32463;&#22312;&#21508;&#31181;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#26377;&#25928;&#24615;&#65292;&#20294;&#26159;&#23427;&#20204;&#23545;&#28040;&#24687;&#20256;&#36882;&#30340;&#20381;&#36182;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#30340;&#37096;&#32626;&#65292;&#27604;&#22914;&#37329;&#34701;&#27450;&#35784;&#26816;&#27979;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#20174;GNNs&#20013;&#25552;&#21462;&#30693;&#35782;&#21040;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLPs&#65289;&#26469;&#21152;&#36895;&#25512;&#29702;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#26377;&#30417;&#30563;&#33976;&#39311;&#38480;&#21046;&#20102;&#23545;&#26410;&#35265;&#33410;&#28857;&#30340;&#27867;&#21270;&#65292;&#32780;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#36825;&#31181;&#24773;&#20917;&#24456;&#24120;&#35265;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;SimMLP&#65292;&#29992;&#20110;&#22312;&#22270;&#19978;&#26080;&#30417;&#30563;&#23398;&#20064;MLPs&#65292;&#20197;&#22686;&#24378;&#27867;&#21270;&#33021;&#21147;&#12290;SimMLP&#21033;&#29992;&#33258;&#30417;&#30563;&#23545;&#40784;GNNs&#21644;MLPs&#20043;&#38388;&#30340;&#33410;&#28857;&#29305;&#24449;&#21644;&#22270;&#32467;&#26500;&#20043;&#38388;&#30340;&#31934;&#32454;&#21644;&#27867;&#21270;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#26469;&#20943;&#36731;&#24179;&#20961;&#35299;&#30340;&#39118;&#38505;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08918v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have demonstrated effectiveness in various graph learning tasks, yet their reliance on message-passing constraints their deployment in latency-sensitive applications such as financial fraud detection. Recent works have explored distilling knowledge from GNNs to Multi-Layer Perceptrons (MLPs) to accelerate inference. However, this task-specific supervised distillation limits generalization to unseen nodes, which are prevalent in latency-sensitive applications. To this end, we present \textbf{\textsc{SimMLP}}, a \textbf{\textsc{Sim}}ple yet effective framework for learning \textbf{\textsc{MLP}}s on graphs without supervision, to enhance generalization. \textsc{SimMLP} employs self-supervised alignment between GNNs and MLPs to capture the fine-grained and generalizable correlation between node features and graph structures, and proposes two strategies to alleviate the risk of trivial solutions. Theoretically, w
&lt;/p&gt;</description></item></channel></rss>