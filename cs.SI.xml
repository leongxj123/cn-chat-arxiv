<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#22270;&#24418;&#32467;&#26500;&#25552;&#31034;&#65292;&#20197;&#22686;&#24378;&#39044;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#35770;&#35265;&#35299;&#65292;&#23454;&#29616;&#20102;&#22312;&#20219;&#24847;&#30693;&#35782;&#22270;&#19978;&#36827;&#34892;&#20302;&#36164;&#28304;&#24402;&#32435;&#25512;&#29702;&#30340;&#39640;&#36890;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11804</link><description>&lt;p&gt;
LLM&#20316;&#20026;&#25552;&#31034;&#22120;&#65306;&#22312;&#20219;&#24847;&#30693;&#35782;&#22270;&#19978;&#36827;&#34892;&#20302;&#36164;&#28304;&#24402;&#32435;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11804
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#22270;&#24418;&#32467;&#26500;&#25552;&#31034;&#65292;&#20197;&#22686;&#24378;&#39044;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#35770;&#35265;&#35299;&#65292;&#23454;&#29616;&#20102;&#22312;&#20219;&#24847;&#30693;&#35782;&#22270;&#19978;&#36827;&#34892;&#20302;&#36164;&#28304;&#24402;&#32435;&#25512;&#29702;&#30340;&#39640;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#65288;KG&#65289;&#24402;&#32435;&#25512;&#29702;&#26088;&#22312;&#25512;&#26029;&#35757;&#32451;&#26399;&#38388;&#26410;&#35265;&#36807;&#30340;&#26032;KG&#20013;&#32570;&#22833;&#30340;&#20107;&#23454;&#65292;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#37319;&#29992;&#12290;KG&#24402;&#32435;&#25512;&#29702;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#22788;&#29702;&#22312;&#25991;&#26412;&#21644;&#32467;&#26500;&#26041;&#38754;&#37117;&#31232;&#32570;&#30340;&#20302;&#36164;&#28304;&#22330;&#26223;&#12290;&#26412;&#25991;&#23581;&#35797;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;LLMs&#29983;&#25104;&#22270;&#24418;&#32467;&#26500;&#25552;&#31034;&#65292;&#20197;&#22686;&#24378;&#39044;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#20174;&#32780;&#20026;KG&#24402;&#32435;&#25512;&#29702;&#26041;&#27861;&#24102;&#26469;&#26032;&#30340;&#26041;&#27861;&#35770;&#35265;&#35299;&#65292;&#20197;&#21450;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#24456;&#39640;&#30340;&#26222;&#36866;&#24615;&#12290;&#22312;&#26041;&#27861;&#35770;&#26041;&#38754;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#21644;&#25552;&#31034;&#26694;&#26550;ProLINK&#65292;&#26088;&#22312;&#22312;&#20219;&#24847;KG&#19978;&#36827;&#34892;&#20302;&#36164;&#28304;&#24402;&#32435;&#25512;&#29702;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#35757;&#32451;&#12290;&#22312;&#23454;&#36341;&#26041;&#38754;&#65292;&#25105;&#20204;&#22312;36&#20010;&#20302;&#36164;&#28304;&#25968;&#25454;&#38598;&#19978;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11804v1 Announce Type: new  Abstract: Knowledge Graph (KG) inductive reasoning, which aims to infer missing facts from new KGs that are not seen during training, has been widely adopted in various applications. One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and structural aspects. In this paper, we attempt to address this challenge with Large Language Models (LLMs). Particularly, we utilize the state-of-the-art LLMs to generate a graph-structural prompt to enhance the pre-trained Graph Neural Networks (GNNs), which brings us new methodological insights into the KG inductive reasoning methods, as well as high generalizability in practice. On the methodological side, we introduce a novel pretraining and prompting framework ProLINK, designed for low-resource inductive reasoning across arbitrary KGs without requiring additional training. On the practical side, we experimentally evaluate our approach on 36 low-res
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#25968;&#25454;&#39640;&#25928;&#22270;&#23398;&#20064;&#65288;DEGL&#65289;&#30340;&#27010;&#24565;&#65292;&#24182;&#24635;&#32467;&#20102;&#36817;&#26399;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#36827;&#23637;&#12290;DEGL&#30340;&#30446;&#26631;&#26159;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#22330;&#26223;&#19979;&#25552;&#39640;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#25506;&#32034;&#21508;&#31181;&#26368;&#23567;&#30417;&#30563;&#26041;&#27861;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#26631;&#35760;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.00447</link><description>&lt;p&gt;
&#25968;&#25454;&#39640;&#25928;&#22270;&#23398;&#20064;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey of Data-Efficient Graph Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00447
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#25968;&#25454;&#39640;&#25928;&#22270;&#23398;&#20064;&#65288;DEGL&#65289;&#30340;&#27010;&#24565;&#65292;&#24182;&#24635;&#32467;&#20102;&#36817;&#26399;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#36827;&#23637;&#12290;DEGL&#30340;&#30446;&#26631;&#26159;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#22330;&#26223;&#19979;&#25552;&#39640;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#25506;&#32034;&#21508;&#31181;&#26368;&#23567;&#30417;&#30563;&#26041;&#27861;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#26631;&#35760;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#22312;&#31038;&#20132;&#32593;&#32476;&#21040;&#29983;&#29289;&#21270;&#23398;&#20998;&#26512;&#31561;&#39046;&#22495;&#20013;&#24191;&#27867;&#23384;&#22312;&#65292;&#26159;&#21508;&#31181;&#29616;&#23454;&#19990;&#30028;&#31995;&#32479;&#30340;&#22522;&#30784;&#12290;&#34429;&#28982;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#24314;&#27169;&#36825;&#31181;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#30340;&#25104;&#21151;&#24448;&#24448;&#20381;&#36182;&#20110;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#65292;&#36825;&#22312;&#26631;&#27880;&#36164;&#28304;&#26377;&#38480;&#30340;&#23454;&#38469;&#22330;&#26223;&#20013;&#26500;&#25104;&#20102;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#33268;&#21147;&#20110;&#36890;&#36807;&#25506;&#32034;&#21508;&#31181;&#26368;&#23567;&#30417;&#30563;&#26041;&#27861;&#26469;&#25552;&#39640;&#20302;&#36164;&#28304;&#35774;&#32622;&#19979;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#24615;&#33021;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39640;&#25928;&#22270;&#23398;&#20064;(DEGL)&#30340;&#30740;&#31350;&#21069;&#27839;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;DEGL&#24403;&#21069;&#36827;&#23637;&#30340;&#39318;&#27425;&#32508;&#36848;&#12290;&#25105;&#20204;&#39318;&#20808;&#24378;&#35843;&#20102;&#20351;&#29992;&#22823;&#35268;&#27169;&#26631;&#35760;&#25968;&#25454;&#35757;&#32451;&#27169;&#22411;&#25152;&#22266;&#26377;&#30340;&#25361;&#25112;&#65292;&#20026;&#25105;&#20204;&#23545;DEGL&#30340;&#25506;&#32034;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20174;&#20960;&#20010;&#20851;&#38190;&#26041;&#38754;&#31995;&#32479;&#22320;&#22238;&#39038;&#20102;&#36825;&#19968;&#20027;&#39064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#20854;&#20013;&#21253;&#25324;...
&lt;/p&gt;
&lt;p&gt;
Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including 
&lt;/p&gt;</description></item></channel></rss>