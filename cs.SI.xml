<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#22270;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#23569;&#22270;&#31070;&#32463;&#32593;&#32476;&#25152;&#24102;&#26469;&#30340;&#19981;&#24517;&#35201;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.14951</link><description>&lt;p&gt;
&#31616;&#21333;&#22270;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Simple Graph Condensation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14951
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#22270;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#23569;&#22270;&#31070;&#32463;&#32593;&#32476;&#25152;&#24102;&#26469;&#30340;&#19981;&#24517;&#35201;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#22270;&#19978;&#32321;&#37325;&#30340;&#35757;&#32451;&#25104;&#26412;&#24050;&#32463;&#24341;&#36215;&#20102;&#23545;&#22270;&#21387;&#32553;&#30340;&#26497;&#22823;&#20852;&#36259;&#65292;&#28041;&#21450;&#35843;&#25972;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#23567;&#23610;&#24230;&#21387;&#32553;&#22270;&#19978;&#30340;&#35757;&#32451;&#20197;&#22312;&#22823;&#35268;&#27169;&#21407;&#22987;&#22270;&#19978;&#20351;&#29992;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#35843;&#25972;&#21387;&#32553;&#22270;&#21644;&#21407;&#22987;&#22270;&#20043;&#38388;&#30340;&#20851;&#38190;&#25351;&#26631;&#65292;&#22914;&#26799;&#24230;&#12289;GNNs&#30340;&#20998;&#24067;&#21644;&#36712;&#36857;&#65292;&#20174;&#32780;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22797;&#26434;&#25351;&#26631;&#38656;&#35201;&#22797;&#26434;&#30340;&#35745;&#31639;&#65292;&#21487;&#33021;&#20250;&#24178;&#25200;&#21387;&#32553;&#22270;&#30340;&#20248;&#21270;&#36807;&#31243;&#65292;&#20351;&#24471;&#21387;&#32553;&#36807;&#31243;&#38750;&#24120;&#32321;&#37325;&#21644;&#19981;&#31283;&#23450;&#12290;&#22312;&#21508;&#20010;&#39046;&#22495;&#31616;&#21270;&#27169;&#22411;&#21462;&#24471;&#25104;&#21151;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#22270;&#21387;&#32553;&#20013;&#30340;&#25351;&#26631;&#23545;&#20934;&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#23569;&#20174;GNNs&#32487;&#25215;&#30340;&#19981;&#24517;&#35201;&#22797;&#26434;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#28040;&#38500;&#22806;&#37096;&#21442;&#25968;&#65292;&#20165;&#20445;&#30041;&#30446;&#26631;&#30340;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14951v1 Announce Type: cross  Abstract: The burdensome training costs on large-scale graphs have aroused significant interest in graph condensation, which involves tuning Graph Neural Networks (GNNs) on a small condensed graph for use on the large-scale original graph. Existing methods primarily focus on aligning key metrics between the condensed and original graphs, such as gradients, distribution and trajectory of GNNs, yielding satisfactory performance on downstream tasks. However, these complex metrics necessitate intricate computations and can potentially disrupt the optimization process of the condensation graph, making the condensation process highly demanding and unstable. Motivated by the recent success of simplified models in various fields, we propose a simplified approach to metric alignment in graph condensation, aiming to reduce unnecessary complexity inherited from GNNs. In our approach, we eliminate external parameters and exclusively retain the target conden
&lt;/p&gt;</description></item></channel></rss>