<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;LLM&#20195;&#29702;&#22312;&#19982;&#20154;&#31867;&#21644;&#20854;&#20182;&#20195;&#29702;&#20114;&#21160;&#26102;&#23637;&#31034;&#30340;&#31038;&#20250;&#34892;&#20026;&#65292;&#21253;&#25324;&#31038;&#20250;&#23398;&#20064;&#12289;&#31038;&#20250;&#20559;&#22909;&#21644;&#21512;&#20316;&#34892;&#20026;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#35780;&#20272;&#23427;&#20204;&#19982;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#20114;&#21160;&#12290;</title><link>https://arxiv.org/abs/2312.15198</link><description>&lt;p&gt;
LLM&#20195;&#29702;&#34920;&#29616;&#20986;&#31038;&#20250;&#34892;&#20026;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do LLM Agents Exhibit Social Behavior?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15198
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;LLM&#20195;&#29702;&#22312;&#19982;&#20154;&#31867;&#21644;&#20854;&#20182;&#20195;&#29702;&#20114;&#21160;&#26102;&#23637;&#31034;&#30340;&#31038;&#20250;&#34892;&#20026;&#65292;&#21253;&#25324;&#31038;&#20250;&#23398;&#20064;&#12289;&#31038;&#20250;&#20559;&#22909;&#21644;&#21512;&#20316;&#34892;&#20026;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#35780;&#20272;&#23427;&#20204;&#19982;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#23637;&#27491;&#22312;&#25193;&#22823;&#23427;&#20204;&#22312;&#23398;&#26415;&#30740;&#31350;&#21644;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#25928;&#29992;&#12290;&#26368;&#36817;&#30340;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#8220;&#40657;&#21283;&#23376;&#8221;LLM&#20195;&#29702;&#26469;&#27169;&#25311;&#22797;&#26434;&#31038;&#20250;&#31995;&#32479;&#24182;&#28508;&#22312;&#22320;&#26367;&#20195;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#19968;&#26032;&#20852;&#39046;&#22495;&#65292;&#35843;&#26597;&#20102;LLMs&#22312;&#19982;&#20154;&#31867;&#21644;&#20854;&#20182;&#20195;&#29702;&#36827;&#34892;&#20114;&#21160;&#26102;&#23637;&#31034;&#31038;&#20250;&#23398;&#20064;&#12289;&#31038;&#20250;&#20559;&#22909;&#21644;&#21512;&#20316;&#34892;&#20026;&#65288;&#38388;&#25509;&#20114;&#24800;&#65289;&#31561;&#20851;&#38190;&#31038;&#20250;&#20132;&#20114;&#21407;&#21017;&#30340;&#31243;&#24230;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#30740;&#31350;&#21046;&#23450;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20854;&#20013;&#28041;&#21450;&#23558;&#28041;&#21450;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#32463;&#20856;&#23454;&#39564;&#35843;&#25972;&#20026;&#20351;&#29992;LLM&#20195;&#29702;&#12290;&#36825;&#31181;&#26041;&#27861;&#28041;&#21450;&#19968;&#27493;&#19968;&#27493;&#30340;&#25512;&#29702;&#65292;&#27169;&#25311;&#20154;&#31867;&#35748;&#30693;&#36807;&#31243;&#21644;&#38646;&#26679;&#26412;&#23398;&#20064;&#65292;&#20197;&#35780;&#20272;LLMs&#30340;&#22825;&#29983;&#20559;&#22909;&#12290;&#25105;&#20204;&#23545;LLM&#20195;&#29702;&#34892;&#20026;&#30340;&#20998;&#26512;&#21253;&#25324;&#20027;&#35201;&#25928;&#24212;&#21644;&#27425;&#35201;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.15198v2 Announce Type: replace  Abstract: The advances of Large Language Models (LLMs) are expanding their utility in both academic research and practical applications. Recent social science research has explored the use of these ``black-box'' LLM agents for simulating complex social systems and potentially substituting human subjects in experiments. Our study delves into this emerging domain, investigating the extent to which LLMs exhibit key social interaction principles, such as social learning, social preference, and cooperative behavior (indirect reciprocity), in their interactions with humans and other agents. We develop a framework for our study, wherein classical laboratory experiments involving human subjects are adapted to use LLM agents. This approach involves step-by-step reasoning that mirrors human cognitive processes and zero-shot learning to assess the innate preferences of LLMs. Our analysis of LLM agents' behavior includes both the primary effects and an in
&lt;/p&gt;</description></item></channel></rss>