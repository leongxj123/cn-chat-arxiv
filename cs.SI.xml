<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25506;&#27979;&#31185;&#23398;&#25253;&#36947;&#20013;&#30340;&#38169;&#35823;&#20449;&#24687;&#30340;&#21487;&#34892;&#24615;&#65292;&#32469;&#36807;&#29983;&#25104;&#26126;&#30830;&#26631;&#35760;&#32034;&#36180;&#30340;&#27493;&#39588;&#65292;&#22788;&#29702;&#29616;&#23454;&#22330;&#26223;&#20013;&#21487;&#33021;&#19981;&#23384;&#22312;&#26126;&#30830;&#26631;&#35760;&#32034;&#36180;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.14268</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#26816;&#27979;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#20013;&#30340;&#38169;&#35823;&#20449;&#24687;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Detect Misinformation in Scientific News Reporting?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14268
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25506;&#27979;&#31185;&#23398;&#25253;&#36947;&#20013;&#30340;&#38169;&#35823;&#20449;&#24687;&#30340;&#21487;&#34892;&#24615;&#65292;&#32469;&#36807;&#29983;&#25104;&#26126;&#30830;&#26631;&#35760;&#32034;&#36180;&#30340;&#27493;&#39588;&#65292;&#22788;&#29702;&#29616;&#23454;&#22330;&#26223;&#20013;&#21487;&#33021;&#19981;&#23384;&#22312;&#26126;&#30830;&#26631;&#35760;&#32034;&#36180;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#20107;&#23454;&#32463;&#24120;&#34987;&#22312;&#27969;&#34892;&#23186;&#20307;&#20013;&#25805;&#32437;&#65292;&#24847;&#22270;&#24433;&#21709;&#20844;&#20247;&#33286;&#35770;&#21644;&#34892;&#21160;&#65292;&#27491;&#22914;&#22312;COVID-19&#22823;&#27969;&#34892;&#26399;&#38388;&#25152;&#35777;&#23454;&#30340;&#37027;&#26679;&#12290;&#22312;&#31185;&#23398;&#39046;&#22495;&#20013;&#33258;&#21160;&#26816;&#27979;&#38169;&#35823;&#20449;&#24687;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#36825;&#20004;&#31181;&#23186;&#20307;&#31867;&#22411;&#30340;&#20889;&#20316;&#39118;&#26684;&#26377;&#30528;&#26126;&#26174;&#19981;&#21516;&#65292;&#24182;&#19988;&#20173;&#22788;&#20110;&#33804;&#33469;&#38454;&#27573;&#12290;&#26412;&#25991;&#30340;&#26680;&#24515;&#30740;&#31350;&#38382;&#39064;&#26159;&#26159;&#21542;&#21487;&#20197;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26469;&#26816;&#27979;&#31185;&#23398;&#25253;&#36947;&#20013;&#30340;&#38169;&#35823;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14268v1 Announce Type: cross  Abstract: Scientific facts are often spun in the popular press with the intent to influence public opinion and action, as was evidenced during the COVID-19 pandemic. Automatic detection of misinformation in the scientific domain is challenging because of the distinct styles of writing in these two media types and is still in its nascence. Most research on the validity of scientific reporting treats this problem as a claim verification challenge. In doing so, significant expert human effort is required to generate appropriate claims. Our solution bypasses this step and addresses a more real-world scenario where such explicit, labeled claims may not be available. The central research question of this paper is whether it is possible to use large language models (LLMs) to detect misinformation in scientific reporting. To this end, we first present a new labeled dataset SciNews, containing 2.4k scientific news stories drawn from trusted and untrustwo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#36229;&#36807;250,000&#20010;&#21807;&#19968;&#20107;&#23454;&#26680;&#26597;&#30340;&#20998;&#26512;&#65292;&#25506;&#31350;&#20102;&#22810;&#35821;&#35328;&#38169;&#35823;&#20449;&#24687;&#30340;&#26222;&#36941;&#24615;&#21644;&#21160;&#24577;&#24615;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#37096;&#20998;&#38169;&#35823;&#20449;&#24687;&#33021;&#22815;&#31359;&#36234;&#35821;&#35328;&#38556;&#30861;&#65292;&#24182;&#19988;&#22312;&#30456;&#21516;&#35821;&#35328;&#20013;&#26356;&#26377;&#21487;&#33021;&#20256;&#25773;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;&#38169;&#35823;&#20449;&#24687;&#38543;&#26102;&#38388;&#28436;&#21464;&#24182;&#22312;&#19981;&#21516;&#35821;&#35328;&#38388;&#21457;&#29983;&#31361;&#21464;&#12290;</title><link>http://arxiv.org/abs/2310.18089</link><description>&lt;p&gt;
&#22312;&#32763;&#35793;&#20013;&#36855;&#22833;-&#22810;&#35821;&#35328;&#38169;&#35823;&#20449;&#24687;&#21450;&#20854;&#28436;&#21464;
&lt;/p&gt;
&lt;p&gt;
Lost in Translation -- Multilingual Misinformation and its Evolution. (arXiv:2310.18089v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#36229;&#36807;250,000&#20010;&#21807;&#19968;&#20107;&#23454;&#26680;&#26597;&#30340;&#20998;&#26512;&#65292;&#25506;&#31350;&#20102;&#22810;&#35821;&#35328;&#38169;&#35823;&#20449;&#24687;&#30340;&#26222;&#36941;&#24615;&#21644;&#21160;&#24577;&#24615;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#37096;&#20998;&#38169;&#35823;&#20449;&#24687;&#33021;&#22815;&#31359;&#36234;&#35821;&#35328;&#38556;&#30861;&#65292;&#24182;&#19988;&#22312;&#30456;&#21516;&#35821;&#35328;&#20013;&#26356;&#26377;&#21487;&#33021;&#20256;&#25773;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;&#38169;&#35823;&#20449;&#24687;&#38543;&#26102;&#38388;&#28436;&#21464;&#24182;&#22312;&#19981;&#21516;&#35821;&#35328;&#38388;&#21457;&#29983;&#31361;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#26102;&#20195;&#65292;&#35823;&#23548;&#21644;&#34394;&#20551;&#20449;&#24687;&#27491;&#22312;&#36805;&#36895;&#22312;&#21508;&#31181;&#35821;&#35328;&#21644;&#36793;&#30028;&#38388;&#20256;&#25773;&#65292;&#26500;&#25104;&#20102;&#26085;&#30410;&#22686;&#38271;&#30340;&#23041;&#32961;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;95&#31181;&#35821;&#35328;&#20013;&#36229;&#36807;250,000&#20010;&#21807;&#19968;&#20107;&#23454;&#26680;&#26597;&#30340;&#20998;&#26512;&#65292;&#25506;&#31350;&#20102;&#22810;&#35821;&#35328;&#38169;&#35823;&#20449;&#24687;&#30340;&#26222;&#36941;&#24615;&#21644;&#21160;&#24577;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#22810;&#25968;&#38169;&#35823;&#20449;&#24687;&#20027;&#24352;&#20165;&#34987;&#20107;&#23454;&#26680;&#26597;&#19968;&#27425;&#65292;&#20294;11.7%&#30340;&#20027;&#24352;(&#36229;&#36807;21,000&#20010;)&#34987;&#26680;&#26597;&#22810;&#27425;&#12290;&#36816;&#29992;&#20107;&#23454;&#26680;&#26597;&#20316;&#20026;&#38169;&#35823;&#20449;&#24687;&#20256;&#25773;&#30340;&#20195;&#29702;&#25351;&#26631;&#65292;&#25105;&#20204;&#21457;&#29616;33%&#30340;&#37325;&#22797;&#20027;&#24352;&#31359;&#36234;&#35821;&#35328;&#38556;&#30861;&#65292;&#26263;&#31034;&#37096;&#20998;&#38169;&#35823;&#20449;&#24687;&#28183;&#36879;&#20102;&#35821;&#35328;&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#25193;&#25955;&#27169;&#24335;&#34920;&#29616;&#20986;&#36739;&#24378;&#30340;&#21516;&#36136;&#24615;&#65292;&#38169;&#35823;&#20449;&#24687;&#26356;&#26377;&#21487;&#33021;&#22312;&#30456;&#21516;&#35821;&#35328;&#20013;&#20256;&#25773;&#12290;&#20026;&#30740;&#31350;&#20027;&#24352;&#38543;&#26102;&#38388;&#30340;&#28436;&#21464;&#21644;&#36328;&#35821;&#35328;&#30340;&#31361;&#21464;&#65292;&#25105;&#20204;&#20351;&#29992;&#22810;&#35821;&#35328;&#21477;&#23376;&#23884;&#20837;&#26469;&#34920;&#31034;&#20107;&#23454;&#26680;&#26597;&#65292;&#24182;&#23545;&#35821;&#20041;&#30456;&#20284;&#30340;&#20027;&#24352;&#36827;&#34892;&#32858;&#31867;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36830;&#25509;&#32452;&#20214;&#21644;&#26368;&#30701;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Misinformation and disinformation are growing threats in the digital age, spreading rapidly across languages and borders. This paper investigates the prevalence and dynamics of multilingual misinformation through an analysis of over 250,000 unique fact-checks spanning 95 languages. First, we find that while the majority of misinformation claims are only fact-checked once, 11.7%, corresponding to more than 21,000 claims, are checked multiple times. Using fact-checks as a proxy for the spread of misinformation, we find 33% of repeated claims cross linguistic boundaries, suggesting that some misinformation permeates language barriers. However, spreading patterns exhibit strong homophily, with misinformation more likely to spread within the same language. To study the evolution of claims over time and mutations across languages, we represent fact-checks with multilingual sentence embeddings and cluster semantically similar claims. We analyze the connected components and shortest paths conn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.00833</link><description>&lt;p&gt;
&#33258;&#19979;&#32780;&#19978;&#20309;&#26102;&#20987;&#36133;&#33258;&#19978;&#32780;&#19979;&#36827;&#34892;&#20998;&#23618;&#31038;&#21306;&#26816;&#27979;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Bottom-up Beat Top-down in Hierarchical Community Detection?. (arXiv:2306.00833v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#30340;&#20998;&#23618;&#32858;&#31867;&#26159;&#25351;&#26597;&#25214;&#19968;&#32452;&#31038;&#21306;&#30340;&#26641;&#24418;&#32467;&#26500;&#65292;&#20854;&#20013;&#23618;&#27425;&#32467;&#26500;&#30340;&#36739;&#20302;&#32423;&#21035;&#26174;&#31034;&#26356;&#32454;&#31890;&#24230;&#30340;&#31038;&#21306;&#32467;&#26500;&#12290;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#31639;&#27861;&#26377;&#20004;&#20010;&#20027;&#35201;&#31867;&#21035;&#65306;&#33258;&#19978;&#32780;&#19979;&#30340;&#31639;&#27861;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;&#20998;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#36825;&#31181;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24674;&#22797;&#26465;&#20214;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#33258;&#19978;&#32780;&#19979;&#31639;&#27861;&#30340;&#26465;&#20214;&#26469;&#35828;&#65292;&#38480;&#21046;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering of networks consists in finding a tree of communities, such that lower levels of the hierarchy reveal finer-grained community structures. There are two main classes of algorithms tackling this problem. Divisive ($\textit{top-down}$) algorithms recursively partition the nodes into two communities, until a stopping rule indicates that no further split is needed. In contrast, agglomerative ($\textit{bottom-up}$) algorithms first identify the smallest community structure and then repeatedly merge the communities using a $\textit{linkage}$ method. In this article, we establish theoretical guarantees for the recovery of the hierarchical tree and community structure of a Hierarchical Stochastic Block Model by a bottom-up algorithm. We also establish that this bottom-up algorithm attains the information-theoretic threshold for exact recovery at intermediate levels of the hierarchy. Notably, these recovery conditions are less restrictive compared to those existing for to
&lt;/p&gt;</description></item></channel></rss>