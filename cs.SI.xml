<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38142;&#36335;&#39044;&#27979;&#20013;&#25913;&#36827;GNN&#22312;&#20302;&#24230;&#33410;&#28857;&#19978;&#30340;&#24615;&#33021;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NodeDup&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#36890;&#36807;&#22797;&#21046;&#20302;&#24230;&#33410;&#28857;&#24182;&#21019;&#24314;&#38142;&#25509;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09711</link><description>&lt;p&gt;
&#33410;&#28857;&#22797;&#21046;&#25913;&#21892;&#20919;&#21551;&#21160;&#38142;&#36335;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Node Duplication Improves Cold-start Link Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38142;&#36335;&#39044;&#27979;&#20013;&#25913;&#36827;GNN&#22312;&#20302;&#24230;&#33410;&#28857;&#19978;&#30340;&#24615;&#33021;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NodeDup&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#36890;&#36807;&#22797;&#21046;&#20302;&#24230;&#33410;&#28857;&#24182;&#21019;&#24314;&#38142;&#25509;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22312;&#22270;&#26426;&#22120;&#23398;&#20064;&#20013;&#38750;&#24120;&#31361;&#20986;&#65292;&#24182;&#22312;&#38142;&#36335;&#39044;&#27979;&#65288;LP&#65289;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#25972;&#20307;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;GNN&#22312;&#20302;&#24230;&#33410;&#28857;&#19978;&#30340;&#34920;&#29616;&#21364;&#36739;&#24046;&#12290;&#22312;&#25512;&#33616;&#31995;&#32479;&#31561;LP&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25913;&#21892;&#20302;&#24230;&#33410;&#28857;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#36825;&#31561;&#21516;&#20110;&#35299;&#20915;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#25552;&#39640;&#29992;&#25143;&#22312;&#23569;&#25968;&#35266;&#23519;&#30340;&#30456;&#20114;&#20316;&#29992;&#20013;&#30340;&#20307;&#39564;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#25913;&#36827;GNN&#22312;&#20302;&#24230;&#33410;&#28857;&#19978;&#30340;LP&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#22312;&#39640;&#24230;&#33410;&#28857;&#19978;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#38750;&#24120;&#26377;&#25928;&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#31216;&#20026;NodeDup&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;NodeDup&#22312;&#26631;&#20934;&#30340;&#30417;&#30563;LP&#35757;&#32451;&#26041;&#26696;&#20013;&#65292;&#22312;&#20302;&#24230;&#33410;&#28857;&#19978;&#22797;&#21046;&#33410;&#28857;&#24182;&#22312;&#33410;&#28857;&#21644;&#20854;&#21103;&#26412;&#20043;&#38388;&#21019;&#24314;&#38142;&#25509;&#12290;&#36890;&#36807;&#21033;&#29992;&#8220;&#22810;&#35270;&#22270;&#8221;&#35270;&#35282;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;LP&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09711v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) are prominent in graph machine learning and have shown state-of-the-art performance in Link Prediction (LP) tasks. Nonetheless, recent studies show that GNNs struggle to produce good results on low-degree nodes despite their overall strong performance. In practical applications of LP, like recommendation systems, improving performance on low-degree nodes is critical, as it amounts to tackling the cold-start problem of improving the experiences of users with few observed interactions. In this paper, we investigate improving GNNs' LP performance on low-degree nodes while preserving their performance on high-degree nodes and propose a simple yet surprisingly effective augmentation technique called NodeDup. Specifically, NodeDup duplicates low-degree nodes and creates links between nodes and their own duplicates before following the standard supervised LP training scheme. By leveraging a ''multi-view'' perspectiv
&lt;/p&gt;</description></item></channel></rss>