<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#26412;&#32508;&#36848;&#35843;&#26597;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#19981;&#21516;&#24418;&#24335;&#23450;&#20041;&#19979;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#30340;&#27169;&#22411;&#65292;&#24182;&#23545;&#22270;&#29305;&#24449;&#22686;&#24378;&#12289;&#22270;&#25299;&#25169;&#22686;&#24378;&#21644;GNNs&#26550;&#26500;&#22686;&#24378;&#36827;&#34892;&#20102;&#32508;&#36848;&#21644;&#35752;&#35770;&#12290;</title><link>http://arxiv.org/abs/2308.08235</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65306;&#19968;&#39033;&#32508;&#36848;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Expressive Power of Graph Neural Networks: A Survey. (arXiv:2308.08235v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08235
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35843;&#26597;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#19981;&#21516;&#24418;&#24335;&#23450;&#20041;&#19979;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#30340;&#27169;&#22411;&#65292;&#24182;&#23545;&#22270;&#29305;&#24449;&#22686;&#24378;&#12289;&#22270;&#25299;&#25169;&#22686;&#24378;&#21644;GNNs&#26550;&#26500;&#22686;&#24378;&#36827;&#34892;&#20102;&#32508;&#36848;&#21644;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#26159;&#35768;&#22810;&#19982;&#22270;&#30456;&#20851;&#30340;&#24212;&#29992;&#20013;&#26377;&#25928;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#35768;&#22810;&#30740;&#31350;&#24037;&#20316;&#38598;&#20013;&#22312;GNNs&#30340;&#29702;&#35770;&#38480;&#21046;&#65292;&#21363;&#20854;&#34920;&#36798;&#33021;&#21147;&#12290;&#26089;&#26399;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;GNNs&#30340;&#22270;&#21516;&#26500;&#35782;&#21035;&#33021;&#21147;&#65292;&#32780;&#26368;&#36817;&#30340;&#30740;&#31350;&#23581;&#35797;&#21033;&#29992;&#23376;&#22270;&#35745;&#25968;&#21644;&#36830;&#25509;&#23398;&#20064;&#31561;&#23646;&#24615;&#26469;&#25551;&#36848;GNNs&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36825;&#26356;&#21152;&#23454;&#38469;&#19988;&#26356;&#25509;&#36817;&#23454;&#38469;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#20851;&#20110;&#27492;&#26041;&#21521;&#30340;&#32508;&#36848;&#35770;&#25991;&#21644;&#24320;&#28304;&#20179;&#24211;&#32508;&#21512;&#24635;&#32467;&#21644;&#35752;&#35770;&#36825;&#20123;&#27169;&#22411;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#39318;&#27425;&#23545;&#19981;&#21516;&#24418;&#24335;&#23450;&#20041;&#19979;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#30340;&#27169;&#22411;&#36827;&#34892;&#20102;&#32508;&#36848;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22522;&#20110;&#19977;&#20010;&#31867;&#21035;&#23545;&#27169;&#22411;&#36827;&#34892;&#20102;&#35780;&#36848;&#65292;&#21363;&#22270;&#29305;&#24449;&#22686;&#24378;&#12289;&#22270;&#25299;&#25169;&#22686;&#24378;&#21644;GNNs&#26550;&#26500;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) are effective machine learning models for many graph-related applications. Despite their empirical success, many research efforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive power. Early works in this domain mainly focus on studying the graph isomorphism recognition ability of GNNs, and recent works try to leverage the properties such as subgraph counting and connectivity learning to characterize the expressive power of GNNs, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for models for enhancing expressive power under different forms of definition. Concretely, the models are reviewed based on three categories, i.e., Graph feature enhancement, Graph topology enhancement, and GNNs architecture enhancement.
&lt;/p&gt;</description></item></channel></rss>