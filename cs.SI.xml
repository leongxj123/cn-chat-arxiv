<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#22522;&#20110;&#36335;&#24452;&#30340;KGC&#35299;&#37322;&#22120;Power-Link&#36890;&#36807;&#24341;&#20837;&#22270;&#21152;&#26435;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#21487;&#35299;&#37322;&#30340;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#65292;&#25512;&#21160;&#20102;&#27169;&#22411;&#36879;&#26126;&#24230;&#21644;&#21487;&#38752;&#24615;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2401.02290</link><description>&lt;p&gt;
&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#30340;&#35299;&#37322;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Path-based Explanation for Knowledge Graph Completion. (arXiv:2401.02290v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02290
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#36335;&#24452;&#30340;KGC&#35299;&#37322;&#22120;Power-Link&#36890;&#36807;&#24341;&#20837;&#22270;&#21152;&#26435;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#21487;&#35299;&#37322;&#30340;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#65292;&#25512;&#21160;&#20102;&#27169;&#22411;&#36879;&#26126;&#24230;&#21644;&#21487;&#38752;&#24615;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36890;&#36807;&#24314;&#27169;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#20132;&#20114;&#22312;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#65288;KGC&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#23545;&#39044;&#27979;&#32467;&#26524;&#30340;&#35299;&#37322;&#21364;&#27809;&#26377;&#24471;&#21040;&#24517;&#35201;&#30340;&#20851;&#27880;&#12290;&#23545;&#22522;&#20110;GNN&#30340;KGC&#27169;&#22411;&#32467;&#26524;&#36827;&#34892;&#36866;&#24403;&#35299;&#37322;&#65292;&#21487;&#20197;&#22686;&#21152;&#27169;&#22411;&#30340;&#36879;&#26126;&#24230;&#65292;&#24182;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#26356;&#21487;&#38752;&#30340;&#27169;&#22411;&#12290;&#29616;&#26377;&#30340;KGC&#35299;&#37322;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#23454;&#20363;/&#23376;&#22270;&#30340;&#26041;&#27861;&#65292;&#32780;&#22312;&#26576;&#20123;&#22330;&#26223;&#19979;&#65292;&#36335;&#24452;&#21487;&#20197;&#25552;&#20379;&#26356;&#21451;&#22909;&#21644;&#21487;&#35299;&#37322;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#36824;&#27809;&#26377;&#23545;&#29983;&#25104;&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#35889;&#35299;&#37322;&#26041;&#27861;&#36827;&#34892;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Power-Link&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#25506;&#32034;&#22522;&#20110;&#36335;&#24452;&#30340;KGC&#35299;&#37322;&#22120;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#21152;&#26435;&#25216;&#26415;&#65292;&#20351;&#24471;&#21487;&#20197;&#20197;&#23436;&#20840;&#21487;&#24182;&#34892;&#21270;&#21644;&#20869;&#23384;&#39640;&#25928;&#30340;&#35757;&#32451;&#26041;&#26696;&#29983;&#25104;&#22522;&#20110;&#36335;&#24452;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19977;&#20010;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#29992;&#20110;&#35780;&#20272;&#35299;&#37322;&#30340;&#36136;&#37327;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have achieved great success in Knowledge Graph Completion (KGC) by modelling how entities and relations interact in recent years. However, the explanation of the predicted facts has not caught the necessary attention. Proper explanations for the results of GNN-based KGC models increase model transparency and help researchers develop more reliable models. Existing practices for explaining KGC tasks rely on instance/subgraph-based approaches, while in some scenarios, paths can provide more user-friendly and interpretable explanations. Nonetheless, the methods for generating path-based explanations for KGs have not been well-explored. To address this gap, we propose Power-Link, the first path-based KGC explainer that explores GNN-based models. We design a novel simplified graph-powering technique, which enables the generation of path-based explanations with a fully parallelisable and memory-efficient training scheme. We further introduce three new metrics for 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#25193;&#23637;&#31616;&#21270;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#65288;S3GRL&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#31616;&#21270;&#27599;&#20010;&#38142;&#25509;&#23376;&#22270;&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#21644;&#32858;&#21512;&#25805;&#20316;&#23454;&#29616;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#25512;&#29702;&#65292;&#24182;&#21487;&#36866;&#24212;&#21508;&#31181;&#23376;&#22270;&#37319;&#26679;&#31574;&#30053;&#21644;&#25193;&#25955;&#25805;&#20316;&#31526;&#20197;&#27169;&#25311;&#35745;&#31639;&#20195;&#20215;&#39640;&#30340;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;S3GRL&#27169;&#22411;&#21487;&#20197;&#25193;&#23637;SGRL&#32780;&#19981;&#20250;&#26174;&#33879;&#38477;&#20302;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.12562</link><description>&lt;p&gt;
&#38024;&#23545;&#21487;&#25193;&#23637;&#24615;&#30340;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#31616;&#21270;&#20197;&#36827;&#34892;&#21487;&#25193;&#23637;&#30340;&#38142;&#25509;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Simplifying Subgraph Representation Learning for Scalable Link Prediction. (arXiv:2301.12562v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12562
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#25193;&#23637;&#31616;&#21270;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#65288;S3GRL&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#31616;&#21270;&#27599;&#20010;&#38142;&#25509;&#23376;&#22270;&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#21644;&#32858;&#21512;&#25805;&#20316;&#23454;&#29616;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#25512;&#29702;&#65292;&#24182;&#21487;&#36866;&#24212;&#21508;&#31181;&#23376;&#22270;&#37319;&#26679;&#31574;&#30053;&#21644;&#25193;&#25955;&#25805;&#20316;&#31526;&#20197;&#27169;&#25311;&#35745;&#31639;&#20195;&#20215;&#39640;&#30340;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;S3GRL&#27169;&#22411;&#21487;&#20197;&#25193;&#23637;SGRL&#32780;&#19981;&#20250;&#26174;&#33879;&#38477;&#20302;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#19978;&#30340;&#38142;&#25509;&#39044;&#27979;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#23558;&#38142;&#25509;&#39044;&#27979;&#36716;&#21270;&#20026;&#22312;&#38142;&#25509;&#21608;&#22260;&#23376;&#22270;&#19978;&#30340;&#22270;&#20998;&#31867;&#26469;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#38142;&#25509;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#35745;&#31639;&#20195;&#20215;&#39640;&#65292;&#24182;&#19988;&#30001;&#20110;&#23376;&#22270;&#27700;&#24179;&#25805;&#20316;&#30340;&#20195;&#20215;&#32780;&#19981;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#22270;&#24418;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#31867;&#65292;&#31216;&#20026;&#21487;&#25193;&#23637;&#31616;&#21270;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#65288;S3GRL&#65289;&#65292;&#26088;&#22312;&#23454;&#29616;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#25512;&#29702;&#12290;S3GRL&#31616;&#21270;&#20102;&#27599;&#20010;&#38142;&#25509;&#23376;&#22270;&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#21644;&#32858;&#21512;&#25805;&#20316;&#12290;&#20316;&#20026;&#21487;&#25193;&#23637;&#24615;&#26694;&#26550;&#65292;S3GRL&#36866;&#24212;&#21508;&#31181;&#23376;&#22270;&#37319;&#26679;&#31574;&#30053;&#21644;&#25193;&#25955;&#36816;&#31639;&#31526;&#26469;&#27169;&#25311;&#35745;&#31639;&#20195;&#20215;&#39640;&#30340;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#20010;S3GRL&#23454;&#20363;&#65292;&#24182;&#22312;&#23567;&#21040;&#22823;&#35268;&#27169;&#30340;&#22270;&#24418;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;S3GRL&#27169;&#22411;&#21487;&#20197;&#25193;&#23637;SGRL&#32780;&#19981;&#20250;&#26174;&#33879;&#38477;&#20302;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Link prediction on graphs is a fundamental problem. Subgraph representation learning approaches (SGRLs), by transforming link prediction to graph classification on the subgraphs around the links, have achieved state-of-the-art performance in link prediction. However, SGRLs are computationally expensive, and not scalable to large-scale graphs due to expensive subgraph-level operations. To unlock the scalability of SGRLs, we propose a new class of SGRLs, that we call Scalable Simplified SGRL (S3GRL). Aimed at faster training and inference, S3GRL simplifies the message passing and aggregation operations in each link's subgraph. S3GRL, as a scalability framework, accommodates various subgraph sampling strategies and diffusion operators to emulate computationally-expensive SGRLs. We propose multiple instances of S3GRL and empirically study them on small to large-scale graphs. Our extensive experiments demonstrate that the proposed S3GRL models scale up SGRLs without significant performance 
&lt;/p&gt;</description></item></channel></rss>