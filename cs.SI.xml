<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#22823;&#35268;&#27169;&#22270;&#30340;&#35299;&#32544;&#32467;&#20957;&#32858;&#26041;&#27861;DisCo&#65292;&#36890;&#36807;&#33410;&#28857;&#21644;&#36793;&#30340;&#20957;&#32858;&#27169;&#22359;&#23454;&#29616;&#20102;&#23545;&#22823;&#35268;&#27169;&#22270;&#30340;&#39640;&#25928;&#32553;&#20957;&#65292;&#25552;&#39640;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#21387;&#32553;&#22270;&#30340;&#20445;&#30495;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.12231</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#22270;&#30340;&#35299;&#32544;&#32467;&#20957;&#32858;
&lt;/p&gt;
&lt;p&gt;
Disentangled Condensation for Large-scale Graphs. (arXiv:2401.12231v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#22823;&#35268;&#27169;&#22270;&#30340;&#35299;&#32544;&#32467;&#20957;&#32858;&#26041;&#27861;DisCo&#65292;&#36890;&#36807;&#33410;&#28857;&#21644;&#36793;&#30340;&#20957;&#32858;&#27169;&#22359;&#23454;&#29616;&#20102;&#23545;&#22823;&#35268;&#27169;&#22270;&#30340;&#39640;&#25928;&#32553;&#20957;&#65292;&#25552;&#39640;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#21387;&#32553;&#22270;&#30340;&#20445;&#30495;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#35299;&#32544;&#32467;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#36259;&#30340;&#25216;&#26415;&#65292;&#20026;&#22823;&#35268;&#27169;&#22270;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#32039;&#20945;&#20294;&#20449;&#24687;&#20016;&#23500;&#30340;&#23567;&#22270;&#65292;&#20197;&#33410;&#30465;&#22823;&#35268;&#27169;&#22270;&#23398;&#20064;&#30340;&#26114;&#36149;&#25104;&#26412;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#26377;&#21069;&#36884;&#30340;&#32467;&#26524;&#65292;&#20294;&#20808;&#21069;&#30340;&#22270;&#35299;&#32544;&#32467;&#26041;&#27861;&#24120;&#24120;&#37319;&#29992;&#32416;&#32544;&#30340;&#32553;&#20957;&#31574;&#30053;&#65292;&#21516;&#26102;&#28041;&#21450;&#33410;&#28857;&#21644;&#36793;&#30340;&#32553;&#20957;&#65292;&#23548;&#33268;&#22823;&#37327;&#30340;GPU&#20869;&#23384;&#38656;&#27714;&#12290;&#36825;&#31181;&#32416;&#32544;&#30340;&#31574;&#30053;&#26497;&#22823;&#22320;&#38459;&#30861;&#20102;&#22270;&#35299;&#32544;&#32467;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#21066;&#24369;&#20102;&#23427;&#23545;&#26497;&#22823;&#35268;&#27169;&#22270;&#30340;&#32553;&#20957;&#21644;&#39640;&#20445;&#30495;&#24230;&#21387;&#32553;&#22270;&#30340;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#22823;&#35268;&#27169;&#22270;&#30340;&#35299;&#32544;&#32467;&#20957;&#32858;&#65292;&#31616;&#31216;&#20026;DisCo&#65292;&#20197;&#25552;&#20379;&#21487;&#25193;&#23637;&#30340;&#22270;&#35299;&#32544;&#32467;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#35268;&#27169;&#30340;&#22270;&#12290;DisCo&#30340;&#26680;&#24515;&#26159;&#20004;&#20010;&#20114;&#34917;&#30340;&#32452;&#20214;&#65292;&#21363;&#33410;&#28857;&#21644;&#36793;&#30340;&#20957;&#32858;&#27169;&#22359;&#65292;&#22312;&#35299;&#32544;&#30340;&#26041;&#24335;&#19979;&#23454;&#29616;&#33410;&#28857;&#21644;&#36793;&#30340;&#20957;&#32858;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph condensation has emerged as an intriguing technique to provide Graph Neural Networks for large-scale graphs with a more compact yet informative small graph to save the expensive costs of large-scale graph learning. Despite the promising results achieved, previous graph condensation methods often employ an entangled condensation strategy that involves condensing nodes and edges simultaneously, leading to substantial GPU memory demands. This entangled strategy has considerably impeded the scalability of graph condensation, impairing its capability to condense extremely large-scale graphs and produce condensed graphs with high fidelity. Therefore, this paper presents Disentangled Condensation for large-scale graphs, abbreviated as DisCo, to provide scalable graph condensation for graphs of varying sizes. At the heart of DisCo are two complementary components, namely node and edge condensation modules, that realize the condensation of nodes and edges in a disentangled manner. In the 
&lt;/p&gt;</description></item></channel></rss>