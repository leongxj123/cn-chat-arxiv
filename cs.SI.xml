<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#20351;&#29992;AI&#29983;&#25104;&#30340;&#20154;&#33080;&#20316;&#20026;&#22836;&#20687;&#30340;&#20266;&#36896;&#31038;&#20132;&#23186;&#20307;&#36134;&#25143;&#65292;&#21457;&#29616;&#23427;&#20204;&#29992;&#20110;&#20256;&#25773;&#35784;&#39575;&#12289;&#22403;&#22334;&#20449;&#24687;&#20197;&#21450;&#25918;&#22823;&#21327;&#21516;&#20449;&#24687;&#31561;&#19981;&#30495;&#23454;&#27963;&#21160;&#12290;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#20272;&#35745;&#20351;&#29992;GAN&#29983;&#25104;&#30340;&#38754;&#23380;&#30340;&#36134;&#25143;&#26222;&#36941;&#24615;&#19979;&#38480;&#22312;0.021%&#21040;0.044%&#20043;&#38388;&#65292;&#32422;&#20026;&#27599;&#26085;&#27963;&#36291;&#36134;&#25143;10K&#20010;&#12290;</title><link>http://arxiv.org/abs/2401.02627</link><description>&lt;p&gt;
&#20266;&#36896;&#31038;&#20132;&#23186;&#20307;&#36134;&#25143;&#30340;&#29305;&#28857;&#21644;&#26222;&#36941;&#24615;&#65292;&#20351;&#29992;&#30340;&#26159;AI&#29983;&#25104;&#30340;&#38754;&#23380;
&lt;/p&gt;
&lt;p&gt;
Characteristics and prevalence of fake social media profiles with AI-generated faces. (arXiv:2401.02627v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#20351;&#29992;AI&#29983;&#25104;&#30340;&#20154;&#33080;&#20316;&#20026;&#22836;&#20687;&#30340;&#20266;&#36896;&#31038;&#20132;&#23186;&#20307;&#36134;&#25143;&#65292;&#21457;&#29616;&#23427;&#20204;&#29992;&#20110;&#20256;&#25773;&#35784;&#39575;&#12289;&#22403;&#22334;&#20449;&#24687;&#20197;&#21450;&#25918;&#22823;&#21327;&#21516;&#20449;&#24687;&#31561;&#19981;&#30495;&#23454;&#27963;&#21160;&#12290;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#20272;&#35745;&#20351;&#29992;GAN&#29983;&#25104;&#30340;&#38754;&#23380;&#30340;&#36134;&#25143;&#26222;&#36941;&#24615;&#19979;&#38480;&#22312;0.021%&#21040;0.044%&#20043;&#38388;&#65292;&#32422;&#20026;&#27599;&#26085;&#27963;&#36291;&#36134;&#25143;10K&#20010;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#27493;&#24341;&#21457;&#20102;&#23545;&#20854;&#21487;&#33021;&#21019;&#24314;&#20986;&#36924;&#30495;&#20266;&#36896;&#31038;&#20132;&#23186;&#20307;&#36134;&#25143;&#30340;&#25285;&#24551;&#65292;&#20294;&#32570;&#20047;&#23454;&#35777;&#35777;&#25454;&#12290;&#26412;&#25991;&#23545;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#29983;&#25104;&#30340;&#20154;&#33080;&#20316;&#20026;&#22836;&#20687;&#30340;Twitter(X)&#36134;&#25143;&#36827;&#34892;&#20102;&#31995;&#32479;&#20998;&#26512;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#21253;&#21547;1,353&#20010;&#27492;&#31867;&#36134;&#25143;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#29992;&#20110;&#20256;&#25773;&#35784;&#39575;&#12289;&#22403;&#22334;&#20449;&#24687;&#20197;&#21450;&#25918;&#22823;&#21327;&#21516;&#20449;&#24687;&#31561;&#19981;&#30495;&#23454;&#27963;&#21160;&#12290;&#36890;&#36807;&#21033;&#29992;GAN&#29983;&#25104;&#30340;&#38754;&#23380;&#30340;&#19968;&#20010;&#29305;&#24449;&#8212;&#8212;&#30524;&#30555;&#30340;&#19968;&#33268;&#20301;&#32622;&#65292;&#24182;&#19982;&#20154;&#24037;&#27880;&#37322;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#37326;&#22806;&#20013;&#20351;&#29992;GAN&#29983;&#25104;&#30340;&#36134;&#25143;&#12290;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#38543;&#26426;&#26679;&#26412;&#30340;&#27963;&#36291;Twitter&#29992;&#25143;&#20013;&#65292;&#25105;&#20204;&#20272;&#35745;&#20351;&#29992;GAN&#29983;&#25104;&#30340;&#38754;&#23380;&#30340;&#36134;&#25143;&#26222;&#36941;&#24615;&#19979;&#38480;&#22312;0.021%&#21040;0.044%&#20043;&#38388;&#65292;&#32422;&#20026;&#27599;&#26085;&#27963;&#36291;&#36134;&#25143;10K&#20010;&#12290;&#36825;&#20123;&#21457;&#29616;&#31361;&#26174;&#20102;&#22810;&#27169;&#24335;&#36134;&#25143;&#23545;&#20110;&#26032;&#20852;&#23041;&#32961;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in generative artificial intelligence (AI) have raised concerns about their potential to create convincing fake social media accounts, but empirical evidence is lacking. In this paper, we present a systematic analysis of Twitter(X) accounts using human faces generated by Generative Adversarial Networks (GANs) for their profile pictures. We present a dataset of 1,353 such accounts and show that they are used to spread scams, spam, and amplify coordinated messages, among other inauthentic activities. Leveraging a feature of GAN-generated faces -- consistent eye placement -- and supplementing it with human annotation, we devise an effective method for identifying GAN-generated profiles in the wild. Applying this method to a random sample of active Twitter users, we estimate a lower bound for the prevalence of profiles using GAN-generated faces between 0.021% and 0.044% -- around 10K daily active accounts. These findings underscore the emerging threats posed by multimod
&lt;/p&gt;</description></item></channel></rss>