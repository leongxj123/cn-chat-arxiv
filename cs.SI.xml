<rss version="2.0"><channel><title>Chat Arxiv cs.SI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SI</description><item><title>HateCOT&#25968;&#25454;&#38598;&#36890;&#36807;GPT-3.5-Turbo&#29983;&#25104;&#35299;&#37322;&#65292;&#23558;52,000&#20010;&#26679;&#26412;&#25968;&#25454;&#29992;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#19979;&#30340;&#25915;&#20987;&#24615;&#20869;&#23481;&#26816;&#27979;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.11456</link><description>&lt;p&gt;
HateCOT&#65306;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#27867;&#21270;&#25915;&#20987;&#24615;&#35328;&#35770;&#26816;&#27979;&#30340;&#35299;&#37322;&#22686;&#24378;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11456
&lt;/p&gt;
&lt;p&gt;
HateCOT&#25968;&#25454;&#38598;&#36890;&#36807;GPT-3.5-Turbo&#29983;&#25104;&#35299;&#37322;&#65292;&#23558;52,000&#20010;&#26679;&#26412;&#25968;&#25454;&#29992;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#19979;&#30340;&#25915;&#20987;&#24615;&#20869;&#23481;&#26816;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#30340;&#26222;&#21450;&#23548;&#33268;&#20102;&#23545;&#25915;&#20987;&#24615;&#20869;&#23481;&#30340;&#21487;&#38752;&#39640;&#25928;&#26816;&#27979;&#30340;&#38656;&#27714;&#65292;&#20026;&#20102;&#38480;&#21046;&#20854;&#26377;&#23475;&#24433;&#21709;&#12290;&#36825;&#23548;&#33268;&#20102;&#22823;&#37327;&#19982;&#26816;&#27979;&#25915;&#20987;&#24615;&#20869;&#23481;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#30340;&#20986;&#29616;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;HateCOT&#65292;&#36825;&#26159;&#20174;&#22810;&#26679;&#21270;&#29616;&#26377;&#26469;&#28304;&#20013;&#25277;&#21462;&#30340;5.2&#19975;&#20010;&#26679;&#26412;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#30001;GPT-3.5-Turbo&#21644;&#20154;&#24037;&#31934;&#24515;&#21046;&#20316;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;HateCOT&#19978;&#20026;&#25915;&#20987;&#24615;&#20869;&#23481;&#26816;&#27979;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#38646;-shot&#21644;few-shot&#35774;&#32622;&#19979;&#26174;&#33879;&#25913;&#36827;&#20102;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#65292;&#23613;&#31649;&#22312;&#39046;&#22495;&#21644;&#20219;&#21153;&#26041;&#38754;&#23384;&#22312;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11456v1 Announce Type: cross  Abstract: The ubiquitousness of social media has led to the need for reliable and efficient detection of offensive content to limit harmful effects. This has led to a proliferation of datasets and models related to detecting offensive content. While sophisticated models have attained strong performance on individual datasets, these models often do not generalize due to differences between how "offensive content" is conceptualized, and the resulting differences in how these datasets are labeled. In this paper, we introduce HateCOT, a dataset of 52,000 samples drawn from diverse existing sources with explanations generated by GPT-3.5-Turbo and human-curated. We show that pre-training models for the detection of offensive content on HateCOT significantly boots open-sourced Language Models on three benchmark datasets in both zero and few-shot settings, despite differences in domain and task.} We further find that HateCOT enables effective K-shot fin
&lt;/p&gt;</description></item></channel></rss>