# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision-Language Models](https://arxiv.org/abs/2403.18957) | 该研究旨在调查不安全用户生成内容游戏中的违法推广威胁，收集了一组包含性暴力和暴力内容的真实图像数据集。 |
| [^2] | [Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials](https://arxiv.org/abs/2402.17003) | 提出了算法准确性作为在临床试验中部署在线RL算法的关键要求，强调了对参与者保护和数据科学效用的保留责任，并提出了一个框架进行预部署规划和实时监测以确保算法准确性。 |

# 详细

[^1]: 利用大规模视觉语言模型调节不安全用户生成内容游戏中的违法在线图片推广

    Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision-Language Models

    [https://arxiv.org/abs/2403.18957](https://arxiv.org/abs/2403.18957)

    该研究旨在调查不安全用户生成内容游戏中的违法推广威胁，收集了一组包含性暴力和暴力内容的真实图像数据集。

    

    在线用户生成内容游戏（UGCGs）在儿童和青少年中越来越受欢迎，用于社交互动和更有创意的在线娱乐。然而，它们存在着更高的暴露不良内容的风险，引发了人们对儿童和青少年在线安全的日益关注。我们采取了第一步研究对不安全UGCGs的违法推广进行威胁性分析。我们收集了一组现实世界数据集，包括2,924张展示不同性暴力和暴力内容的图像，这些内容被游戏创建者用于推广UGCGs。

    arXiv:2403.18957v1 Announce Type: cross  Abstract: Online user-generated content games (UGCGs) are increasingly popular among children and adolescents for social interaction and more creative online entertainment. However, they pose a heightened risk of exposure to explicit content, raising growing concerns for the online safety of children and adolescents. Despite these concerns, few studies have addressed the issue of illicit image-based promotions of unsafe UGCGs on social media, which can inadvertently attract young users. This challenge arises from the difficulty of obtaining comprehensive training data for UGCG images and the unique nature of these images, which differ from traditional unsafe content. In this work, we take the first step towards studying the threat of illicit promotions of unsafe UGCGs. We collect a real-world dataset comprising 2,924 images that display diverse sexually explicit and violent content used to promote UGCGs by their game creators. Our in-depth studi
    
[^2]: 在临床试验中监测在线强化学习算法的准确性

    Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials

    [https://arxiv.org/abs/2402.17003](https://arxiv.org/abs/2402.17003)

    提出了算法准确性作为在临床试验中部署在线RL算法的关键要求，强调了对参与者保护和数据科学效用的保留责任，并提出了一个框架进行预部署规划和实时监测以确保算法准确性。

    

    在线强化学习（RL）算法为个性化临床试验中参与者的治疗提供了巨大潜力。然而，在高风险医疗领域部署在线自主算法使得质量控制和数据质量特别难以实现。本文提出了作为在临床试验中部署在线RL算法的关键要求的算法准确性。它强调了算法对（1）保护参与者和（2）保留数据在试验后分析中的科学效用的责任。我们还提出了一个用于部署前规划和实时监测的框架，以协助算法开发者和临床研究人员确保算法的准确性。为了说明我们框架的实际应用，我们介绍了来自Oralytics临床试验的真实案例。自2023年春季以来，这项试验成功地部署了一种自主的在线RL算法来进行个

    arXiv:2402.17003v1 Announce Type: cross  Abstract: Online reinforcement learning (RL) algorithms offer great potential for personalizing treatment for participants in clinical trials. However, deploying an online, autonomous algorithm in the high-stakes healthcare setting makes quality control and data quality especially difficult to achieve. This paper proposes algorithm fidelity as a critical requirement for deploying online RL algorithms in clinical trials. It emphasizes the responsibility of the algorithm to (1) safeguard participants and (2) preserve the scientific utility of the data for post-trial analyses. We also present a framework for pre-deployment planning and real-time monitoring to help algorithm developers and clinical researchers ensure algorithm fidelity. To illustrate our framework's practical application, we present real-world examples from the Oralytics clinical trial. Since Spring 2023, this trial successfully deployed an autonomous, online RL algorithm to persona
    

