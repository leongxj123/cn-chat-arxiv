# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MM-Soc: Benchmarking Multimodal Large Language Models in Social Media Platforms](https://arxiv.org/abs/2402.14154) | 该研究介绍了MM-Soc，一个旨在评估多模态大型语言模型（MLLMs）对社交媒体内容理解的综合基准，通过对十种大小变体的四个开源MLLMs进行详尽评估，发现了显著的性能差异。 |
| [^2] | [GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice.](http://arxiv.org/abs/2309.00649) | GPT通过金融素养测试显示出具备成为大众金融机器顾问的能力，其中基于GPT-4的ChatGPT几乎完美地得分99%，揭示了金融素养正在成为最先进模型的新兴能力。 |
| [^3] | [The Initial Screening Order Problem.](http://arxiv.org/abs/2307.15398) | 本文研究了初始筛选顺序问题，在候选人筛选中起到关键作用。我们证明在候选人池不平衡情况下，类人筛选者可能对受保护、代表性不足的群体做出不公平的决策。这项研究的目的是与一家大公司合作，以更好地理解其潜在的自动化招聘流程。 |

# 详细

[^1]: 在社交媒体平台上对多模态大型语言模型进行基准测试

    MM-Soc: Benchmarking Multimodal Large Language Models in Social Media Platforms

    [https://arxiv.org/abs/2402.14154](https://arxiv.org/abs/2402.14154)

    该研究介绍了MM-Soc，一个旨在评估多模态大型语言模型（MLLMs）对社交媒体内容理解的综合基准，通过对十种大小变体的四个开源MLLMs进行详尽评估，发现了显著的性能差异。

    

    社交媒体平台是多模态信息交流的中心，包括文本、图片和视频，这使得机器难以理解在线空间中交互所关联的信息或情绪。多模态大型语言模型（MLLMs）已经成为解决这些挑战的一个有前途的解决方案，但是它们在准确解释人类情绪和诸如虚假信息等复杂内容方面存在困难。本文介绍了MM-Soc，一个旨在评估MLLMs对多模态社交媒体内容理解的综合基准。MM-Soc整合了著名的多模态数据集，并融入了一个新颖的大规模YouTube标记数据集，旨在针对从虚假信息检测、仇恨言论检测到社交上下文生成等一系列任务。通过对四个开源MLLMs的十种不同规模变体进行详尽评估，我们发现了显著的性能差异，凸显出了对性能平衡的需求。

    arXiv:2402.14154v1 Announce Type: new  Abstract: Social media platforms are hubs for multimodal information exchange, encompassing text, images, and videos, making it challenging for machines to comprehend the information or emotions associated with interactions in online spaces. Multimodal Large Language Models (MLLMs) have emerged as a promising solution to address these challenges, yet struggle with accurately interpreting human emotions and complex contents like misinformation. This paper introduces MM-Soc, a comprehensive benchmark designed to evaluate MLLMs' understanding of multimodal social media content. MM-Soc compiles prominent multimodal datasets and incorporates a novel large-scale YouTube tagging dataset, targeting a range of tasks from misinformation detection, hate speech detection, and social context generation. Through our exhaustive evaluation on ten size-variants of four open-source MLLMs, we have identified significant performance disparities, highlighting the need
    
[^2]: GPT已经具备了金融素养：来自GPT金融素养测试的见解以及人们使用其作为咨询来源的初步测试

    GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice. (arXiv:2309.00649v1 [cs.CL])

    [http://arxiv.org/abs/2309.00649](http://arxiv.org/abs/2309.00649)

    GPT通过金融素养测试显示出具备成为大众金融机器顾问的能力，其中基于GPT-4的ChatGPT几乎完美地得分99%，揭示了金融素养正在成为最先进模型的新兴能力。

    

    通过使用金融素养测试，我们评估了GPT（一种大型语言模型）作为大众金融机器顾问的能力。基于GPT-3.5的Davinci和ChatGPT分别在金融素养测试中得分为66%和65%，而基于GPT-4的ChatGPT几乎完美地得到了99%的分数，这表明金融素养正在成为最先进模型的新兴能力。我们使用Judge-Advisor系统和一个储蓄困境来说明研究人员如何评估大型语言模型提供的建议利用情况。我们还提出了一些未来研究的方向。

    We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.
    
[^3]: 初始筛选顺序问题

    The Initial Screening Order Problem. (arXiv:2307.15398v1 [cs.LG])

    [http://arxiv.org/abs/2307.15398](http://arxiv.org/abs/2307.15398)

    本文研究了初始筛选顺序问题，在候选人筛选中起到关键作用。我们证明在候选人池不平衡情况下，类人筛选者可能对受保护、代表性不足的群体做出不公平的决策。这项研究的目的是与一家大公司合作，以更好地理解其潜在的自动化招聘流程。

    

    本文介绍了初始筛选顺序问题，这是候选人筛选中的关键步骤。它涉及一个类似人类的筛选者，其目标是在给定初始筛选顺序的候选人池中找到前k个适合的候选人，而不是最好的k个适合的候选人。初始筛选顺序表示类人筛选者在筛选之前如何安排候选人池。初始筛选顺序的选择对所选的k个候选人有重要影响。我们证明，在候选人池不平衡的情况下（例如，男性候选人多于女性候选人），类人筛选者可能在决策过程中对受保护的、代表性不足的群体产生不平等的努力。其他公平性结果也在类人筛选者下得到证明。这项研究是与一家大公司合作的，旨在更好地了解其潜在自动化的招聘流程。

    In this paper we present the initial screening order problem, a crucial step within candidate screening. It involves a human-like screener with an objective to find the first k suitable candidates rather than the best k suitable candidates in a candidate pool given an initial screening order. The initial screening order represents the way in which the human-like screener arranges the candidate pool prior to screening. The choice of initial screening order has considerable effects on the selected set of k candidates. We prove that under an unbalanced candidate pool (e.g., having more male than female candidates), the human-like screener can suffer from uneven efforts that hinder its decision-making over the protected, under-represented group relative to the non-protected, over-represented group. Other fairness results are proven under the human-like screener. This research is based on a collaboration with a large company to better understand its hiring process for potential automation. 
    

