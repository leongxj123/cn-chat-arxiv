# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Efficiency is Not Enough: A Critical Perspective of Environmentally Sustainable AI.](http://arxiv.org/abs/2309.02065) | 本论文对环境可持续人工智能提出了批判性视角，认为仅仅提高效率还不足以使机器学习成为一种环境可持续的技术。 |
| [^2] | [The Representational Status of Deep Learning Models.](http://arxiv.org/abs/2303.12032) | 该论文澄清了深度学习模型的表征状态。尽管通常称为“表征”，但实际上它们更适合理解为高度理想化的模型，这一结果对可解释的AI有着直接影响，也引起了哲学家对其在未来科学研究中的作用的关注。 |

# 详细

[^1]: 效率不是唯一标准：对环境可持续人工智能的批判性视角

    Efficiency is Not Enough: A Critical Perspective of Environmentally Sustainable AI. (arXiv:2309.02065v1 [cs.LG])

    [http://arxiv.org/abs/2309.02065](http://arxiv.org/abs/2309.02065)

    本论文对环境可持续人工智能提出了批判性视角，认为仅仅提高效率还不足以使机器学习成为一种环境可持续的技术。

    

    人工智能（AI）目前由深度学习（DL）等机器学习（ML）方法推动，这些方法加速了在许多原本被认为超出AI范围的任务上的进展。这些ML方法通常需要大量计算资源、能源消耗大，并导致大量的碳排放，这是人为气候变化的一个已知驱动因素。此外，ML系统运行的平台与环境影响有关，包括碳排放之外的其他方面。工业界和ML社区广泛推崇的提高ML系统在计算和能源消耗方面的效率来改善环境可持续性的解决方案，我们认为仅仅依靠效率还不足以使ML作为一种环境可持续的技术。我们通过提出三个高层次的差异来阐述考虑众多变量对ML环境可持续性影响时，仅依靠效率是不够的。

    Artificial Intelligence (AI) is currently spearheaded by machine learning (ML) methods such as deep learning (DL) which have accelerated progress on many tasks thought to be out of reach of AI. These ML methods can often be compute hungry, energy intensive, and result in significant carbon emissions, a known driver of anthropogenic climate change. Additionally, the platforms on which ML systems run are associated with environmental impacts including and beyond carbon emissions. The solution lionized by both industry and the ML community to improve the environmental sustainability of ML is to increase the efficiency with which ML systems operate in terms of both compute and energy consumption. In this perspective, we argue that efficiency alone is not enough to make ML as a technology environmentally sustainable. We do so by presenting three high level discrepancies between the effect of efficiency on the environmental sustainability of ML when considering the many variables which it in
    
[^2]: 深度学习模型的表征状态

    The Representational Status of Deep Learning Models. (arXiv:2303.12032v1 [cs.AI])

    [http://arxiv.org/abs/2303.12032](http://arxiv.org/abs/2303.12032)

    该论文澄清了深度学习模型的表征状态。尽管通常称为“表征”，但实际上它们更适合理解为高度理想化的模型，这一结果对可解释的AI有着直接影响，也引起了哲学家对其在未来科学研究中的作用的关注。

    

    本文旨在澄清深度学习模型（DLMs）的表征状态。由于功能和关系概念的混淆，尽管通常称为“表征”，但这意味着含糊不清。本文认为，虽然DLM以关系意义上的表征其目标，但最好理解为高度理想化的模型。这个结果对可解释的AI（XAI）有直接影响，并引导哲学关注DLM表征的理想化性质及其在未来科学研究中的作用。

    This paper aims to clarify the representational status of Deep Learning Models (DLMs). While commonly referred to as 'representations', what this entails is ambiguous due to a conflation of functional and relational conceptions of representation. This paper argues that while DLMs represent their targets in a relational sense, they are best understood as highly idealized models. This result has immediate implications for explainable AI (XAI) and directs philosophical attention toward examining the idealized nature of DLM representations and their role in future scientific investigation.
    

