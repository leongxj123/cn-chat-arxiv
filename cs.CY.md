# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models.](http://arxiv.org/abs/2306.15087) | WinoQueer是一个社区协同基准，旨在衡量大型语言模型是否存在对LGBTQ+社区有害的偏见。研究发现现成模型普遍存在相当大的反同偏见，通过在该社区撰写或由该社区成员撰写的数据上进行微调，可以在一定程度上减轻偏见。 |

# 详细

[^1]: WinoQueer：针对大型语言模型中反LGBTQ+偏见的社区协同基准

    WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models. (arXiv:2306.15087v1 [cs.CL])

    [http://arxiv.org/abs/2306.15087](http://arxiv.org/abs/2306.15087)

    WinoQueer是一个社区协同基准，旨在衡量大型语言模型是否存在对LGBTQ+社区有害的偏见。研究发现现成模型普遍存在相当大的反同偏见，通过在该社区撰写或由该社区成员撰写的数据上进行微调，可以在一定程度上减轻偏见。

    

    我们提出了WinoQueer：一个专门设计用来测试大型语言模型（LLMs）是否存在对LGBTQ+社区有害的偏见的基准。该基准是通过一种新颖的方法从社区调查中生成的偏见基准。我们将该基准应用于几个流行的LLMs，并发现现成模型普遍存在相当大的反同偏见。最后，我们展示了通过在该社区撰写或由该社区成员撰写的数据上进行微调，可以在一定程度上减轻LLM对边缘化社区的偏见，并且社区成员撰写的社交媒体文本比非社区成员撰写的新闻文本更有效。我们的社区协同基准开发方法为未来的研究人员提供了一个蓝图，以开发面向其他边缘化社区的、以社区为中心的、基于伤害的LLM基准。

    We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community. The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias. Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members. Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities.
    

