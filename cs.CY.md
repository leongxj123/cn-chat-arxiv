# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services](https://arxiv.org/abs/2403.15780) | 本研究介绍了一种在共享微移动服务运营与控制中实现性能优化和算法公平性平衡的前沿调查，利用Q-Learning算法确保方法稳健，能够实现各种站点类别之间的公平结果。 |
| [^2] | [Two Types of AI Existential Risk: Decisive and Accumulative](https://arxiv.org/abs/2401.07836) | 本文对比了传统的“决定性AI x-risk假设”与“累积性AI x-risk假设”，指出人工智能可能带来的灭绝性灾难有两种可能路径：一种是突然发生的AI接管，另一种是逐渐积累的威胁。 |

# 详细

[^1]: 面向公平性的共享微移动服务运营与控制的强化学习方法

    A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services

    [https://arxiv.org/abs/2403.15780](https://arxiv.org/abs/2403.15780)

    本研究介绍了一种在共享微移动服务运营与控制中实现性能优化和算法公平性平衡的前沿调查，利用Q-Learning算法确保方法稳健，能够实现各种站点类别之间的公平结果。

    

    随着机器学习系统在各种应用领域变得日益普遍，包括那些直接涉及人类的领域，平等和算法公平性的必要性在人工智能界愈发突出。另一方面，在共享微移动系统的背景下，公平性导向方法的探索仍然有限。为填补这一空白，我们引入了一项探讨性研究，探讨了共享微移动服务运营与控制中性能优化与算法公平性之间的平衡。我们的研究运用强化学习中的Q-Learning算法，利用其收敛保证来确保我们提出的方法的稳健性。值得注意的是，我们的方法在不同站点类别（中心、边缘和远程）之间能够实现公平的结果，这是通过基尼系数来衡量的。

    arXiv:2403.15780v1 Announce Type: cross  Abstract: As Machine Learning systems become increasingly popular across diverse application domains, including those with direct human implications, the imperative of equity and algorithmic fairness has risen to prominence in the Artificial Intelligence community. On the other hand, in the context of Shared Micromobility Systems, the exploration of fairness-oriented approaches remains limited. Addressing this gap, we introduce a pioneering investigation into the balance between performance optimization and algorithmic fairness in the operation and control of Shared Micromobility Services. Our study leverages the Q-Learning algorithm in Reinforcement Learning, benefiting from its convergence guarantees to ensure the robustness of our proposed approach. Notably, our methodology stands out for its ability to achieve equitable outcomes, as measured by the Gini index, across different station categories--central, peripheral, and remote. Through stra
    
[^2]: 两种类型的人工智能存在风险：决定性和累积性

    Two Types of AI Existential Risk: Decisive and Accumulative

    [https://arxiv.org/abs/2401.07836](https://arxiv.org/abs/2401.07836)

    本文对比了传统的“决定性AI x-risk假设”与“累积性AI x-risk假设”，指出人工智能可能带来的灭绝性灾难有两种可能路径：一种是突然发生的AI接管，另一种是逐渐积累的威胁。

    

    传统上对人工智能(AI)引起的存在风险(x-risks)的讨论通常集中在由先进的AI系统引起的突然、严重事件上，尤其是那些可能达到或超过人类水平智能的系统。这些事件将带来严重后果，要么导致人类灭绝，要么无法逆转地使人类文明陷入无法恢复的状态。然而，这种讨论经常忽视AI x-risk逐渐通过一系列较小但相互关联的中断逐渐显现出来的严重可能性，随着时间的推移逐渐跨越关键阈值。该论文将传统的“决定性AI x-risk假设”与“累积性AI x-risk假设”进行对比。前者描绘了一种明显的AI接管路径，其特征是无法控制的超级智能等情景，而后者则提出了另一种导致灭绝性灾难的因果路径。这涉及到由AI引起的严重威胁的逐渐累积，例如严重的漏洞和系统性问题

    The conventional discourse on existential risks (x-risks) from AI typically focuses on abrupt, dire events caused by advanced AI systems, particularly those that might achieve or surpass human-level intelligence. These events have severe consequences that either lead to human extinction or irreversibly cripple human civilization to a point beyond recovery. This discourse, however, often neglects the serious possibility of AI x-risks manifesting incrementally through a series of smaller yet interconnected disruptions, gradually crossing critical thresholds over time. This paper contrasts the conventional "decisive AI x-risk hypothesis" with an "accumulative AI x-risk hypothesis." While the former envisions an overt AI takeover pathway, characterized by scenarios like uncontrollable superintelligence, the latter suggests a different causal pathway to existential catastrophes. This involves a gradual accumulation of critical AI-induced threats such as severe vulnerabilities and systemic e
    

