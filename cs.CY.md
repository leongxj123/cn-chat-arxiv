# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SyllabusQA: A Course Logistics Question Answering Dataset](https://arxiv.org/abs/2403.14666) | SyllabusQA数据集是一个包含63个真实课程大纲的开源数据集，对36个专业涵盖5,078对多样化的开放式课程逻辑相关问题-答案对进行了详细收集，旨在评估答案事实性，多个强基线模型在该任务上表现出色，但仍存在与人类之间的显著差距。 |

# 详细

[^1]: SyllabusQA：一个课程逻辑问题回答数据集

    SyllabusQA: A Course Logistics Question Answering Dataset

    [https://arxiv.org/abs/2403.14666](https://arxiv.org/abs/2403.14666)

    SyllabusQA数据集是一个包含63个真实课程大纲的开源数据集，对36个专业涵盖5,078对多样化的开放式课程逻辑相关问题-答案对进行了详细收集，旨在评估答案事实性，多个强基线模型在该任务上表现出色，但仍存在与人类之间的显著差距。

    

    自动化教学助理和聊天机器人有显著潜力减轻人类教师的工作量，尤其是对于与课程逻辑相关的问题回答，这对学生很重要，但对教师来说是重复的。然而，由于隐私问题，缺乏公开可用的数据集。我们介绍了SyllabusQA，这是一个开源数据集，包含63个真实课程大纲，涵盖36个专业，包含5,078对多样化的开放式课程逻辑相关问题-答案对，问题类型和答案格式都是多样的。由于许多逻辑相关问题包含关键信息，如考试日期，评估答案的事实性很重要。我们在该任务上对几个强基线进行了基准测试，从大型语言模型提示到检索增强生成。我们发现，尽管在传统的文本相似性指标上接近人类表现，但在准确性方面仍存在显著差距。

    arXiv:2403.14666v1 Announce Type: cross  Abstract: Automated teaching assistants and chatbots have significant potential to reduce the workload of human instructors, especially for logistics-related question answering, which is important to students yet repetitive for instructors. However, due to privacy concerns, there is a lack of publicly available datasets. We introduce SyllabusQA, an open-source dataset with 63 real course syllabi covering 36 majors, containing 5,078 open-ended course logistics-related question-answer pairs that are diverse in both question types and answer formats. Since many logistics-related questions contain critical information like the date of an exam, it is important to evaluate the factuality of answers. We benchmark several strong baselines on this task, from large language model prompting to retrieval-augmented generation. We find that despite performing close to humans on traditional metrics of textual similarity, there remains a significant gap between
    

