<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22270;&#21453;&#39304;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21051;&#30011;&#23398;&#20064;&#26497;&#38480;&#30340;&#22270;&#35770;&#37327; $\beta_M(G)$&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#24212;&#30340;&#36951;&#25022;&#19979;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.18591</link><description>&lt;p&gt;
&#20855;&#26377;&#22270;&#21453;&#39304;&#30340;&#38543;&#26426;&#19978;&#19979;&#25991;&#36172;&#21338;&#65306;&#20174;&#29420;&#31435;&#25968;&#21040;MAS&#25968;
&lt;/p&gt;
&lt;p&gt;
Stochastic contextual bandits with graph feedback: from independence number to MAS number
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22270;&#21453;&#39304;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21051;&#30011;&#23398;&#20064;&#26497;&#38480;&#30340;&#22270;&#35770;&#37327; $\beta_M(G)$&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#24212;&#30340;&#36951;&#25022;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#22270;&#21453;&#39304;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#65292;&#22312;&#36825;&#31867;&#20114;&#21160;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#20855;&#26377;&#27604;&#26222;&#36890;&#19978;&#19979;&#25991;&#36172;&#21338;&#26356;&#20016;&#23500;&#32467;&#26500;&#65292;&#20854;&#20013;&#37319;&#21462;&#19968;&#20010;&#34892;&#21160;&#23558;&#22312;&#25152;&#26377;&#24773;&#22659;&#19979;&#25581;&#31034;&#25152;&#26377;&#30456;&#37051;&#34892;&#21160;&#30340;&#22870;&#21169;&#12290;&#19982;&#22810;&#33218;&#36172;&#21338;&#35774;&#32622;&#19981;&#21516;&#65292;&#22810;&#25991;&#29486;&#24050;&#32463;&#23545;&#22270;&#21453;&#39304;&#30340;&#29702;&#35299;&#36827;&#34892;&#20102;&#20840;&#38754;&#25506;&#35752;&#65292;&#20294;&#22312;&#19978;&#19979;&#25991;&#36172;&#21338;&#23545;&#24212;&#37096;&#20998;&#20173;&#26377;&#35768;&#22810;&#26410;&#34987;&#25506;&#35752;&#30340;&#22320;&#26041;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#36951;&#25022;&#19979;&#38480; $\Omega(\sqrt{\beta_M(G) T})$ &#25506;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013; $M$ &#26159;&#24773;&#22659;&#25968;&#65292;$G$ &#26159;&#21453;&#39304;&#22270;&#65292;$\beta_M(G)$ &#26159;&#25105;&#20204;&#25552;&#20986;&#30340;&#34920;&#24449;&#35813;&#38382;&#39064;&#31867;&#30340;&#22522;&#30784;&#23398;&#20064;&#38480;&#21046;&#30340;&#22270;&#35770;&#37327;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;$\beta_M(G)$ &#22312; $\alpha(G)$ (&#22270;&#30340;&#29420;&#31435;&#25968;) &#21644; $\mathsf{m}(G)$ (&#22270;&#30340;&#26368;&#22823;&#26080;&#29615;&#23376;&#22270;&#65288;MAS&#65289;&#25968;) &#20043;&#38388;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18591v1 Announce Type: new  Abstract: We consider contextual bandits with graph feedback, a class of interactive learning problems with richer structures than vanilla contextual bandits, where taking an action reveals the rewards for all neighboring actions in the feedback graph under all contexts. Unlike the multi-armed bandits setting where a growing literature has painted a near-complete understanding of graph feedback, much remains unexplored in the contextual bandits counterpart. In this paper, we make inroads into this inquiry by establishing a regret lower bound $\Omega(\sqrt{\beta_M(G) T})$, where $M$ is the number of contexts, $G$ is the feedback graph, and $\beta_M(G)$ is our proposed graph-theoretical quantity that characterizes the fundamental learning limit for this class of problems. Interestingly, $\beta_M(G)$ interpolates between $\alpha(G)$ (the independence number of the graph) and $\mathsf{m}(G)$ (the maximum acyclic subgraph (MAS) number of the graph) as 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.03722</link><description>&lt;p&gt;
&#26410;&#30693;&#26041;&#24046;&#19979;&#30340;&#39640;&#26031;&#22343;&#20540;&#30340;&#20219;&#24847;&#26377;&#25928;T&#26816;&#39564;&#21644;&#32622;&#20449;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1976&#24180;&#65292;Lai&#26500;&#36896;&#20102;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#22343;&#20540;$\mu$&#30340;&#39640;&#26031;&#20998;&#24067;&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#35813;&#20998;&#24067;&#30340;&#26041;&#24046;$\sigma$&#26159;&#26410;&#30693;&#30340;&#12290;&#20182;&#20351;&#29992;&#20102;&#20851;&#20110;$\sigma$&#30340;&#19981;&#36866;&#24403;&#65288;&#21491;Haar&#65289;&#28151;&#21512;&#21644;&#20851;&#20110;$\mu$&#30340;&#19981;&#36866;&#24403;&#65288;&#24179;&#22374;&#65289;&#28151;&#21512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#35828;&#26126;&#20102;&#20182;&#26500;&#24314;&#30340;&#32454;&#33410;&#65292;&#20854;&#20013;&#20351;&#29992;&#20102;&#24191;&#20041;&#30340;&#19981;&#21487;&#31215;&#20998;&#38789;&#21644;&#25193;&#23637;&#30340;&#32500;&#23572;&#19981;&#31561;&#24335;&#12290;&#23613;&#31649;&#36825;&#30830;&#23454;&#20135;&#29983;&#20102;&#19968;&#20010;&#39034;&#24207;T&#26816;&#39564;&#65292;&#20294;&#30001;&#20110;&#20182;&#30340;&#38789;&#19981;&#21487;&#31215;&#20998;&#65292;&#23427;&#24182;&#27809;&#26377;&#20135;&#29983;&#19968;&#20010;&#8220;e-process&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#30456;&#21516;&#30340;&#35774;&#32622;&#24320;&#21457;&#20102;&#20004;&#20010;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#65306;&#19968;&#20010;&#26159;&#22312;&#32553;&#20943;&#28388;&#27874;&#22120;&#20013;&#30340;&#27979;&#35797;&#38789;&#65292;&#21478;&#19968;&#20010;&#26159;&#22312;&#35268;&#33539;&#25968;&#25454;&#28388;&#27874;&#22120;&#20013;&#30340;&#8220;e-process&#8221;&#12290;&#36825;&#20123;&#20998;&#21035;&#26159;&#36890;&#36807;&#23558;Lai&#30340;&#24179;&#22374;&#28151;&#21512;&#26367;&#25442;&#20026;&#39640;&#26031;&#28151;&#21512;&#65292;&#24182;&#23558;&#23545;$\sigma$&#30340;&#21491;Haar&#28151;&#21512;&#26367;&#25442;&#20026;&#22312;&#38646;&#31354;&#38388;&#19979;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#23601;&#20687;&#22312;&#36890;&#29992;&#25512;&#26029;&#20013;&#19968;&#26679;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an ``e-process'' (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;ODE&#26041;&#27861;&#30340;&#28176;&#36817;&#32479;&#35745;&#26041;&#27861;&#35299;&#20915;$d$&#32500;&#38543;&#26426;&#36924;&#36817;&#36882;&#24402;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#20026;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#30340;&#24212;&#29992;&#25552;&#20379;&#20102;&#26377;&#21147;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2110.14427</link><description>&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#28176;&#36817;&#32479;&#35745;&#30340;ODE&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The ODE Method for Asymptotic Statistics in Stochastic Approximation and Reinforcement Learning. (arXiv:2110.14427v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.14427
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;ODE&#26041;&#27861;&#30340;&#28176;&#36817;&#32479;&#35745;&#26041;&#27861;&#35299;&#20915;$d$&#32500;&#38543;&#26426;&#36924;&#36817;&#36882;&#24402;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#20026;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#30340;&#24212;&#29992;&#25552;&#20379;&#20102;&#26377;&#21147;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;$d$&#32500;&#38543;&#26426;&#36924;&#36817;&#36882;&#24402;$$\theta_{n+1}=\theta_n+\alpha_{n+1}f(\theta_n, \Phi_{n+1})$$&#20854;&#20013;$\Phi$&#26159;&#19968;&#20010;&#22312;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;$\textsf{X}$&#19978;&#20855;&#26377;&#24179;&#31283;&#20998;&#24067;$\pi$&#30340;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;$f&#65306;\Re^d\times\textsf{X}\to\Re^d$&#12290;&#22312;&#31216;&#20026;&#65288;DV3&#65289;&#30340;Donsker-Varadhan Lyapunov&#28418;&#31227;&#26465;&#20214;&#30340;&#19968;&#31181;&#29256;&#26412;&#21644;&#23545;&#20855;&#26377;&#21521;&#37327;&#22330;$\bar{f}(\theta)=\textsf{E}[f(\theta,\Phi)]$&#20197;&#21450;$\Phi\sim\pi$&#30340;&#22343;&#20540;&#27969;&#30340;&#31283;&#23450;&#24615;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20027;&#35201;&#32467;&#26524;&#12290;(i) $\{\theta_n\}$&#20197;&#27010;&#29575;1&#21644;$L_4$&#25910;&#25947;&#20110;$\bar{f}(\theta)$&#30340;&#21807;&#19968;&#26681;$\theta^*$&#12290;(ii) &#24314;&#31435;&#20102;&#27867;&#20989;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#20197;&#21450;&#24402;&#19968;&#21270;&#35823;&#24046;&#19968;&#32500;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;(iii) &#23545;&#20110;&#24402;&#19968;&#21270;&#29256;&#26412;$z_n{=:} \sqrt{n} (\theta^{\text{PR}}_n -\theta^*)$&#30340;&#24179;&#22343;&#21442;&#25968;$\theta^{\text{PR}}_n {=:} n^{-1} \sum_{k=1}^n\theta_k$ &#65292;&#22312;&#27493;&#38271;&#30340;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#24314;&#31435;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper concerns the $d$-dimensional stochastic approximation recursion, $$ \theta_{n+1}= \theta_n + \alpha_{n + 1} f(\theta_n, \Phi_{n+1}) $$ in which $\Phi$ is a geometrically ergodic Markov chain on a general state space $\textsf{X}$ with stationary distribution $\pi$, and $f:\Re^d\times\textsf{X}\to\Re^d$.  The main results are established under a version of the Donsker-Varadhan Lyapunov drift condition known as (DV3), and a stability condition for the mean flow with vector field $\bar{f}(\theta)=\textsf{E}[f(\theta,\Phi)]$, with $\Phi\sim\pi$.  (i) $\{ \theta_n\}$ is convergent a.s. and in $L_4$ to the unique root $\theta^*$ of $\bar{f}(\theta)$.  (ii) A functional CLT is established, as well as the usual one-dimensional CLT for the normalized error.  (iii) The CLT holds for the normalized version, $z_n{=:} \sqrt{n} (\theta^{\text{PR}}_n -\theta^*)$, of the averaged parameters, $\theta^{\text{PR}}_n {=:} n^{-1} \sum_{k=1}^n\theta_k$, subject to standard assumptions on the step-s
&lt;/p&gt;</description></item></channel></rss>