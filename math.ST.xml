<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.15801</link><description>&lt;p&gt;
&#20851;&#20110;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension. (arXiv:2401.15801v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15801
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#20854;&#32479;&#35745;&#20934;&#30830;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#20173;&#28982;&#30456;&#23545;&#24754;&#35266;&#12290;&#29305;&#21035;&#26159;&#22312;&#24212;&#29992;GANs&#30340;&#25968;&#25454;&#20998;&#24067;&#65288;&#22914;&#33258;&#28982;&#22270;&#20687;&#65289;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#20854;&#22312;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#20013;&#20855;&#26377;&#22266;&#26377;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#20294;&#36825;&#22312;&#29616;&#26377;&#20998;&#26512;&#20013;&#24448;&#24448;&#27809;&#26377;&#24471;&#21040;&#21453;&#26144;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#36890;&#36807;&#25512;&#23548;&#20851;&#20110;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#26469;&#24357;&#21512;GANs&#21450;&#20854;&#21452;&#21521;&#21464;&#20307;BiGANs&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#20998;&#26512;&#22320;&#35777;&#26126;&#65292;&#22914;&#26524;&#25105;&#20204;&#26377;&#26469;&#33258;&#26410;&#30693;&#30446;&#26631;&#20998;&#24067;&#30340; n &#20010;&#26679;&#26412;&#65292;&#24182;&#19988;&#36873;&#25321;&#20102;&#36866;&#24403;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#37027;&#20040;&#20174;&#30446;&#26631;&#20013;&#20272;&#35745;&#24471;&#20986;&#30340;&#26399;&#26395; Wasserstein-1 &#36317;&#31163;&#20250;&#25353;&#29031; $O(n^{-1/d_\mu })$ &#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$
&lt;/p&gt;</description></item></channel></rss>