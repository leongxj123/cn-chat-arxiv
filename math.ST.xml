<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#30340;&#39044;&#31639;&#25511;&#21046;&#30340;A/B&#27979;&#35797;&#35774;&#35745;&#65292;&#36890;&#36807;&#24066;&#22330;&#32454;&#20998;&#30340;&#26041;&#24335;&#22312;&#26356;&#22823;&#30340;&#24066;&#22330;&#20013;&#35782;&#21035;&#23376;&#24066;&#22330;&#65292;&#24182;&#22312;&#27599;&#20010;&#23376;&#24066;&#22330;&#19978;&#36827;&#34892;&#24182;&#34892;&#23454;&#39564;&#12290;</title><link>https://arxiv.org/abs/2402.07322</link><description>&lt;p&gt;
&#31532;&#19968;&#20215;&#25293;&#21334;&#22343;&#34913;&#20013;&#30340;&#24178;&#25200;&#65306;&#20559;&#24046;&#21644;&#26041;&#24046;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Interference Among First-Price Pacing Equilibria: A Bias and Variance Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#30340;&#39044;&#31639;&#25511;&#21046;&#30340;A/B&#27979;&#35797;&#35774;&#35745;&#65292;&#36890;&#36807;&#24066;&#22330;&#32454;&#20998;&#30340;&#26041;&#24335;&#22312;&#26356;&#22823;&#30340;&#24066;&#22330;&#20013;&#35782;&#21035;&#23376;&#24066;&#22330;&#65292;&#24182;&#22312;&#27599;&#20010;&#23376;&#24066;&#22330;&#19978;&#36827;&#34892;&#24182;&#34892;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20114;&#32852;&#32593;&#34892;&#19994;&#20013;&#65292;&#22312;&#32447;A/B&#27979;&#35797;&#34987;&#24191;&#27867;&#29992;&#20110;&#20915;&#31574;&#26032;&#21151;&#33021;&#30340;&#25512;&#20986;&#12290;&#28982;&#32780;&#23545;&#20110;&#22312;&#32447;&#24066;&#22330;&#65288;&#22914;&#24191;&#21578;&#24066;&#22330;&#65289;&#65292;&#26631;&#20934;&#30340;A/B&#27979;&#35797;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#32467;&#26524;&#20986;&#29616;&#20559;&#24046;&#65292;&#22240;&#20026;&#20080;&#23478;&#22312;&#39044;&#31639;&#32422;&#26463;&#19979;&#36816;&#20316;&#65292;&#35797;&#39564;&#32452;&#30340;&#39044;&#31639;&#28040;&#32791;&#20250;&#24433;&#21709;&#23545;&#29031;&#32452;&#30340;&#34920;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#31181;&#24178;&#25200;&#65292;&#21487;&#20197;&#37319;&#29992;&#8220;&#39044;&#31639;&#20998;&#21106;&#35774;&#35745;&#8221;&#65292;&#21363;&#27599;&#20010;&#23454;&#39564;&#32452;&#37117;&#26377;&#19968;&#20010;&#29420;&#31435;&#30340;&#39044;&#31639;&#32422;&#26463;&#65292;&#24182;&#19988;&#27599;&#20010;&#23454;&#39564;&#32452;&#25509;&#25910;&#30456;&#31561;&#30340;&#39044;&#31639;&#20221;&#39069;&#65292;&#20174;&#32780;&#23454;&#29616;&#8220;&#39044;&#31639;&#25511;&#21046;&#30340;A/B&#27979;&#35797;&#8221;&#12290;&#23613;&#31649;&#39044;&#31639;&#25511;&#21046;&#30340;A/B&#27979;&#35797;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#65292;&#20294;&#24403;&#39044;&#31639;&#20998;&#21106;&#24471;&#22826;&#23567;&#26102;&#65292;&#24615;&#33021;&#20250;&#19979;&#38477;&#65292;&#38480;&#21046;&#20102;&#36825;&#31181;&#31995;&#32479;&#30340;&#24635;&#21534;&#21520;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#30340;&#39044;&#31639;&#25511;&#21046;&#30340;A/B&#27979;&#35797;&#35774;&#35745;&#65292;&#36890;&#36807;&#24066;&#22330;&#32454;&#20998;&#30340;&#26041;&#24335;&#22312;&#26356;&#22823;&#30340;&#24066;&#22330;&#20013;&#35782;&#21035;&#23376;&#24066;&#22330;&#65292;&#24182;&#22312;&#27599;&#20010;&#23376;&#24066;&#22330;&#19978;&#36827;&#34892;&#24182;&#34892;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22914;&#19979;&#65306;&#39318;&#20808;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#31532;&#19968;&#20215;&#25293;&#21334;&#30340;&#22343;&#34913;&#29366;&#20917;&#65292;&#25581;&#31034;&#20102;&#20854;&#20013;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online A/B testing is widely used in the internet industry to inform decisions on new feature roll-outs. For online marketplaces (such as advertising markets), standard approaches to A/B testing may lead to biased results when buyers operate under a budget constraint, as budget consumption in one arm of the experiment impacts performance of the other arm. To counteract this interference, one can use a budget-split design where the budget constraint operates on a per-arm basis and each arm receives an equal fraction of the budget, leading to ``budget-controlled A/B testing.'' Despite clear advantages of budget-controlled A/B testing, performance degrades when budget are split too small, limiting the overall throughput of such systems. In this paper, we propose a parallel budget-controlled A/B testing design where we use market segmentation to identify submarkets in the larger market, and we run parallel experiments on each submarket.   Our contributions are as follows: First, we introdu
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11736</link><description>&lt;p&gt;
&#22312;Ridge&#22238;&#24402;&#20013;&#65292;&#26680;&#23398;&#20064;&#8220;&#33258;&#21160;&#8221;&#32473;&#20986;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;
&lt;/p&gt;
&lt;p&gt;
Kernel Learning in Ridge Regression "Automatically" Yields Exact Low Rank Solution. (arXiv:2310.11736v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24418;&#24335;&#20026;$(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$&#19988;&#30001;&#21442;&#25968;$\Sigma$&#21442;&#25968;&#21270;&#30340;&#26680;&#20989;&#25968;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#23427;&#21516;&#26102;&#20248;&#21270;&#20102;&#39044;&#27979;&#20989;&#25968;&#21644;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#21442;&#25968;$\Sigma$&#12290;&#20174;&#36825;&#20010;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#23398;&#21040;&#30340;$\Sigma$&#30340;&#29305;&#24449;&#31354;&#38388;&#21487;&#20197;&#21578;&#35785;&#25105;&#20204;&#21327;&#21464;&#37327;&#31354;&#38388;&#20013;&#21738;&#20123;&#26041;&#21521;&#23545;&#39044;&#27979;&#26159;&#37325;&#35201;&#30340;&#12290;&#20551;&#35774;&#21327;&#21464;&#37327;&#21482;&#36890;&#36807;&#20302;&#32500;&#23376;&#31354;&#38388;&#65288;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#65289;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#38750;&#38646;&#30340;&#35299;&#37322;&#33021;&#21147;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#19979;&#26377;&#38480;&#26679;&#26412;&#26680;&#23398;&#20064;&#30446;&#26631;&#30340;&#20840;&#23616;&#26368;&#23567;&#21270;&#32773;&#20063;&#26159;&#20302;&#31209;&#30340;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#26368;&#23567;&#21270;$\Sigma$&#30340;&#31209;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#34987;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#30340;&#32500;&#24230;&#25152;&#38480;&#21046;&#12290;&#36825;&#20010;&#29616;&#35937;&#24456;&#26377;&#36259;&#65292;&#22240;&#20026;&#20302;&#31209;&#29305;&#24615;&#26159;&#22312;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#23545;$\Sigma$&#30340;&#26174;&#24335;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#30340;&#65292;&#20363;&#22914;&#26680;&#33539;&#25968;&#27491;&#21017;&#21270;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider kernels of the form $(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$ parametrized by $\Sigma$. For such kernels, we study a variant of the kernel ridge regression problem which simultaneously optimizes the prediction function and the parameter $\Sigma$ of the reproducing kernel Hilbert space. The eigenspace of the $\Sigma$ learned from this kernel ridge regression problem can inform us which directions in covariate space are important for prediction.  Assuming that the covariates have nonzero explanatory power for the response only through a low dimensional subspace (central mean subspace), we find that the global minimizer of the finite sample kernel learning objective is also low rank with high probability. More precisely, the rank of the minimizing $\Sigma$ is with high probability bounded by the dimension of the central mean subspace. This phenomenon is interesting because the low rankness property is achieved without using any explicit regularization of $\Sigma$, e.g., nuclear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#65292;&#25552;&#39640;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#20272;&#35745;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.06818</link><description>&lt;p&gt;
&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#65306;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Dynamic treatment effects: high-dimensional inference under model misspecification. (arXiv:2111.06818v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.06818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#65292;&#25552;&#39640;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#20272;&#35745;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#22312;&#21508;&#20010;&#23398;&#31185;&#20013;&#37117;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#21487;&#20197;&#25552;&#20379;&#26377;&#20851;&#24178;&#39044;&#30340;&#26102;&#21464;&#22240;&#26524;&#24433;&#21709;&#30340;&#24494;&#22937;&#35265;&#35299;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#8220;&#32500;&#25968;&#28798;&#38590;&#8221;&#21644;&#26102;&#21464;&#28151;&#26434;&#30340;&#23384;&#22312;&#65292;&#36825;&#31181;&#20272;&#35745;&#23384;&#22312;&#30528;&#25361;&#25112;&#65292;&#21487;&#33021;&#23548;&#33268;&#20272;&#35745;&#20559;&#35823;&#12290;&#27492;&#22806;&#65292;&#27491;&#30830;&#22320;&#35268;&#23450;&#26085;&#30410;&#22686;&#22810;&#30340;&#27835;&#30103;&#20998;&#37197;&#21644;&#22810;&#37325;&#26292;&#38706;&#30340;&#32467;&#26524;&#27169;&#22411;&#20284;&#20046;&#36807;&#20110;&#22797;&#26434;&#12290;&#37492;&#20110;&#36825;&#20123;&#25361;&#25112;&#65292;&#21452;&#37325;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#22312;&#20801;&#35768;&#27169;&#22411;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#26159;&#38750;&#24120;&#26377;&#20215;&#20540;&#30340;&#65292;&#28982;&#32780;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24182;&#27809;&#26377;&#23454;&#29616;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21516;&#26102;&#23545;&#27835;&#30103;&#20998;&#37197;&#21644;&#32467;&#26524;&#27169;&#22411;&#36827;&#34892;&#40065;&#26834;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#24207;&#21015;&#27169;&#22411;&#21452;&#37325;&#40065;&#26834;&#24615;&#8221;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#24403;&#27599;&#20010;&#26102;&#38388;&#26292;&#38706;&#37117;&#26159;&#21452;&#37325;&#40065;&#26834;&#24615;&#30340;&#26102;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#26102;&#38388;&#28857;&#19978;&#23454;&#29616;&#21452;&#37325;&#40065;&#26834;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#39640;&#20102;&#39640;&#32500;&#29615;&#22659;&#19979;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating dynamic treatment effects is essential across various disciplines, offering nuanced insights into the time-dependent causal impact of interventions. However, this estimation presents challenges due to the "curse of dimensionality" and time-varying confounding, which can lead to biased estimates. Additionally, correctly specifying the growing number of treatment assignments and outcome models with multiple exposures seems overly complex. Given these challenges, the concept of double robustness, where model misspecification is permitted, is extremely valuable, yet unachieved in practical applications. This paper introduces a new approach by proposing novel, robust estimators for both treatment assignments and outcome models. We present a "sequential model double robust" solution, demonstrating that double robustness over multiple time points can be achieved when each time exposure is doubly robust. This approach improves the robustness and reliability of dynamic treatment effe
&lt;/p&gt;</description></item></channel></rss>