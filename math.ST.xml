<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#20272;&#35745;&#22120;&#65292;&#33021;&#22815;&#40065;&#26834;&#22320;&#22788;&#29702;&#20998;&#31867;&#25968;&#25454;&#27169;&#22411;&#30340;&#35823;&#35774;&#65292;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#20998;&#31867;&#21709;&#24212;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.11954</link><description>&lt;p&gt;
&#22312;&#20998;&#31867;&#25968;&#25454;&#20013;&#30340;&#40065;&#26834;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Robust Estimation and Inference in Categorical Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11954
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#20272;&#35745;&#22120;&#65292;&#33021;&#22815;&#40065;&#26834;&#22320;&#22788;&#29702;&#20998;&#31867;&#25968;&#25454;&#27169;&#22411;&#30340;&#35823;&#35774;&#65292;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#20998;&#31867;&#21709;&#24212;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#35777;&#31185;&#23398;&#20013;&#65292;&#35768;&#22810;&#24863;&#20852;&#36259;&#30340;&#21464;&#37327;&#26159;&#20998;&#31867;&#30340;&#12290;&#19982;&#20219;&#20309;&#27169;&#22411;&#19968;&#26679;&#65292;&#23545;&#20110;&#20998;&#31867;&#21709;&#24212;&#30340;&#27169;&#22411;&#21487;&#20197;&#34987;&#35823;&#35774;&#65292;&#23548;&#33268;&#20272;&#35745;&#21487;&#33021;&#23384;&#22312;&#36739;&#22823;&#20559;&#24046;&#12290;&#19968;&#20010;&#29305;&#21035;&#40635;&#28902;&#30340;&#35823;&#35774;&#26469;&#28304;&#26159;&#22312;&#38382;&#21367;&#35843;&#26597;&#20013;&#30340;&#30095;&#24573;&#21709;&#24212;&#65292;&#20247;&#25152;&#21608;&#30693;&#36825;&#20250;&#21361;&#21450;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65288;SEM&#65289;&#21644;&#20854;&#20182;&#22522;&#20110;&#35843;&#26597;&#30340;&#20998;&#26512;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#25552;&#20986;&#20102;&#19968;&#20010;&#26088;&#22312;&#23545;&#20998;&#31867;&#21709;&#24212;&#27169;&#22411;&#30340;&#35823;&#35774;&#40065;&#26834;&#30340;&#36890;&#29992;&#20272;&#35745;&#22120;&#12290;&#19982;&#36804;&#20170;&#20026;&#27490;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#20272;&#35745;&#22120;&#23545;&#20998;&#31867;&#21709;&#24212;&#27169;&#22411;&#30340;&#35823;&#35774;&#31243;&#24230;&#12289;&#22823;&#23567;&#25110;&#31867;&#22411;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#25512;&#24191;&#20102;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#26159;&#24378;&#19968;&#33268;&#30340;&#65292;&#28176;&#36817;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#19982;&#26497;&#22823;&#20284;&#28982;&#30456;&#21516;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#20998;&#31867;&#21709;&#24212;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26816;&#39564;&#65292;&#29992;&#20110;&#27979;&#35797;&#19968;&#20010;&#32473;&#23450;&#21709;&#24212;&#26159;&#21542; ...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11954v1 Announce Type: cross  Abstract: In empirical science, many variables of interest are categorical. Like any model, models for categorical responses can be misspecified, leading to possibly large biases in estimation. One particularly troublesome source of misspecification is inattentive responding in questionnaires, which is well-known to jeopardize the validity of structural equation models (SEMs) and other survey-based analyses. I propose a general estimator that is designed to be robust to misspecification of models for categorical responses. Unlike hitherto approaches, the estimator makes no assumption whatsoever on the degree, magnitude, or type of misspecification. The proposed estimator generalizes maximum likelihood estimation, is strongly consistent, asymptotically Gaussian, has the same time complexity as maximum likelihood, and can be applied to any model for categorical responses. In addition, I develop a novel test that tests whether a given response can 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2007.02192</link><description>&lt;p&gt;
&#23614;&#37096;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#25910;&#32553;
&lt;/p&gt;
&lt;p&gt;
Tail-adaptive Bayesian shrinkage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.02192
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#22238;&#24402;&#38382;&#39064;&#19979;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#25910;&#32553;&#20808;&#39564;&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#22312;&#25152;&#35859;&#30340;&#36229;&#31232;&#30095;&#39046;&#22495;&#20174;&#25104;&#21315;&#19978;&#19975;&#20010;&#39044;&#27979;&#21464;&#37327;&#20013;&#26816;&#27979;&#23569;&#25968;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#24403;&#31232;&#30095;&#31243;&#24230;&#36866;&#20013;&#26102;&#65292;&#23427;&#20204;&#21487;&#33021;&#34920;&#29616;&#19981;&#23613;&#20154;&#24847;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#29305;&#24615;&#20013;&#65292;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20250;&#33258;&#36866;&#24212;&#35843;&#25972;&#65292;&#38543;&#30528;&#31232;&#30095;&#27700;&#24179;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#21464;&#24471;&#26356;&#22823;&#25110;&#26356;&#23567;&#65292;&#20197;&#36866;&#24212;&#20808;&#39564;&#22320;&#26356;&#22810;&#25110;&#26356;&#23569;&#30340;&#20449;&#21495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#23616;&#23616;&#37096;&#23614;&#37096;&#65288;GLT&#65289;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#20197;&#30830;&#20445;&#36825;&#31181;&#23646;&#24615;&#12290;&#25105;&#20204;&#32771;&#23519;&#20102;&#20808;&#39564;&#30340;&#23614;&#37096;&#25351;&#25968;&#19982;&#22522;&#30784;&#31232;&#30095;&#27700;&#24179;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#35777;&#26126;GLT&#21518;&#39564;&#20250;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.02192v4 Announce Type: replace-cross  Abstract: Robust Bayesian methods for high-dimensional regression problems under diverse sparse regimes are studied. Traditional shrinkage priors are primarily designed to detect a handful of signals from tens of thousands of predictors in the so-called ultra-sparsity domain. However, they may not perform desirably when the degree of sparsity is moderate. In this paper, we propose a robust sparse estimation method under diverse sparsity regimes, which has a tail-adaptive shrinkage property. In this property, the tail-heaviness of the prior adjusts adaptively, becoming larger or smaller as the sparsity level increases or decreases, respectively, to accommodate more or fewer signals, a posteriori. We propose a global-local-tail (GLT) Gaussian mixture distribution that ensures this property. We examine the role of the tail-index of the prior in relation to the underlying sparsity level and demonstrate that the GLT posterior contracts at the
&lt;/p&gt;</description></item></channel></rss>