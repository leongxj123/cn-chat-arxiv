<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26681;&#25454;&#23567;&#26679;&#26412;&#25968;&#25454;&#30340;&#21407;&#22987;&#31181;&#32676;&#23558;&#25968;&#25454;&#20998;&#20026;&#20004;&#32452;&#65292;&#36866;&#29992;&#20110;&#31181;&#32676;&#20043;&#38388;&#24046;&#24322;&#36739;&#23567;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.10927</link><description>&lt;p&gt;
&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#30340;&#21435;&#20559;&#21644;&#23616;&#37096;&#20998;&#26512;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Debiasing and a local analysis for population clustering using semidefinite programming. (arXiv:2401.10927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26681;&#25454;&#23567;&#26679;&#26412;&#25968;&#25454;&#30340;&#21407;&#22987;&#31181;&#32676;&#23558;&#25968;&#25454;&#20998;&#20026;&#20004;&#32452;&#65292;&#36866;&#29992;&#20110;&#31181;&#32676;&#20043;&#38388;&#24046;&#24322;&#36739;&#23567;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20174;&#28151;&#21512;&#30340;2&#20010;&#27425;&#39640;&#26031;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#23567;&#25968;&#25454;&#26679;&#26412;&#30340;&#20998;&#21306;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21516;&#19968;&#20316;&#32773;&#25552;&#20986;&#30340;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#23558;&#25968;&#25454;&#26681;&#25454;&#20854;&#21407;&#22987;&#31181;&#32676;&#22823;&#33268;&#20998;&#20026;&#20004;&#32452;&#65292;&#32473;&#23450;&#19968;&#20010;&#23567;&#26679;&#26412;&#12290;&#26412;&#25991;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#23558;&#20010;&#20307;&#26681;&#25454;&#20854;&#21407;&#22987;&#31181;&#32676;&#20351;&#29992;p&#20010;&#26631;&#35760;&#36827;&#34892;&#32858;&#31867;&#65292;&#24403;&#20219;&#24847;&#20004;&#20010;&#31181;&#32676;&#20043;&#38388;&#30340;&#24046;&#24322;&#24456;&#23567;&#26102;&#12290;&#25105;&#20204;&#22522;&#20110;&#25972;&#25968;&#20108;&#27425;&#35268;&#21010;&#30340;&#21322;&#27491;&#23450;&#26494;&#24347;&#24418;&#24335;&#26500;&#24314;&#65292;&#35813;&#35268;&#21010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#22312;&#19968;&#20010;&#22270;&#19978;&#25214;&#21040;&#26368;&#22823;&#21106;&#65292;&#20854;&#20013;&#21106;&#20013;&#30340;&#36793;&#26435;&#37325;&#34920;&#31034;&#22522;&#20110;&#23427;&#20204;&#30340;p&#20010;&#29305;&#24449;&#30340;&#20004;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#19981;&#30456;&#20284;&#24230;&#24471;&#20998;&#12290;&#25105;&#20204;&#29992;&#916;^2:=p&#947;&#26469;&#34920;&#31034;&#20004;&#20010;&#20013;&#24515;&#65288;&#22343;&#20540;&#21521;&#37327;&#65289;&#20043;&#38388;&#30340;&#8467;_2^2&#36317;&#31163;&#65292;&#21363;&#956;^(1), &#956;^(2)&#8712;&#8477;^p&#12290;&#30446;&#26631;&#26159;&#22312;&#20132;&#25442;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#25552;&#20379;&#20840;&#38754;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of partitioning a small data sample of size $n$ drawn from a mixture of $2$ sub-gaussian distributions. In particular, we analyze computational efficient algorithms proposed by the same author, to partition data into two groups approximately according to their population of origin given a small sample. This work is motivated by the application of clustering individuals according to their population of origin using $p$ markers, when the divergence between any two of the populations is small. We build upon the semidefinite relaxation of an integer quadratic program that is formulated essentially as finding the maximum cut on a graph, where edge weights in the cut represent dissimilarity scores between two nodes based on their $p$ features. Here we use $\Delta^2 :=p \gamma$ to denote the $\ell_2^2$ distance between two centers (mean vectors), namely, $\mu^{(1)}$, $\mu^{(2)}$ $\in$ $\mathbb{R}^p$. The goal is to allow a full range of tradeoffs between
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#20462;&#27491;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#27491;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#24773;&#20917;&#19979;&#20248;&#20110;Bonferroni&#20462;&#27491;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#65292;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#21516;&#26102;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2311.10900</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24378;&#22823;&#20462;&#27491;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A powerful rank-based correction to multiple testing under positive dependency. (arXiv:2311.10900v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.10900
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#20462;&#27491;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#27491;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#24773;&#20917;&#19979;&#20248;&#20110;Bonferroni&#20462;&#27491;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#65292;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#21516;&#26102;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#33021;&#22815;&#39640;&#25928;&#21033;&#29992;&#21487;&#33021;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#27491;&#30456;&#20851;&#24615;&#30340;&#23478;&#26063;&#35823;&#24046;&#29575;(FWER)&#25511;&#21046;&#30340;&#26032;&#22411;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#20462;&#27491;&#31639;&#27861;$\texttt{max-rank}$&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#27010;&#24565;&#19978;&#24456;&#30452;&#35266;&#65292;&#20381;&#36182;&#20110;&#22312;&#35745;&#31639;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#31209;&#22495;&#20351;&#29992;$\max$&#31639;&#23376;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#32463;&#39564;&#30340;&#27604;&#36739;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#32463;&#24120;&#20351;&#29992;&#30340;Bonferroni&#20462;&#27491;&#65292;&#32780;&#22312;&#19981;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#31561;&#25928;&#12290;&#25105;&#20204;&#30340;&#20248;&#21183;&#38543;&#30528;&#27979;&#35797;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#21516;&#26102;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;&#25105;&#20204;&#29305;&#21035;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#24212;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#30340;&#32972;&#26223;&#20013;&#65292;&#36825;&#26159;&#22312;&#25105;&#20204;&#20027;&#35201;&#24212;&#29992;&#30340;&#19968;&#31181;&#22797;&#26434;&#39044;&#27979;&#22330;&#26223;&#20013;&#20135;&#29983;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel multiple hypothesis testing correction with family-wise error rate (FWER) control that efficiently exploits positive dependencies between potentially correlated statistical hypothesis tests. Our proposed algorithm $\texttt{max-rank}$ is conceptually straight-forward, relying on the use of a $\max$-operator in the rank domain of computed test statistics. We compare our approach to the frequently employed Bonferroni correction, theoretically and empirically demonstrating its superiority over Bonferroni in the case of existing positive dependency, and its equivalence otherwise. Our advantage over Bonferroni increases as the number of tests rises, and we maintain high statistical power whilst ensuring FWER control. We specifically frame our algorithm in the context of parallel permutation testing, a scenario that arises in our primary application of conformal prediction, a recently popularized approach for quantifying uncertainty in complex predictive settings.
&lt;/p&gt;</description></item></channel></rss>