<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11736</link><description>&lt;p&gt;
&#22312;Ridge&#22238;&#24402;&#20013;&#65292;&#26680;&#23398;&#20064;&#8220;&#33258;&#21160;&#8221;&#32473;&#20986;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;
&lt;/p&gt;
&lt;p&gt;
Kernel Learning in Ridge Regression "Automatically" Yields Exact Low Rank Solution. (arXiv:2310.11736v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24418;&#24335;&#20026;$(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$&#19988;&#30001;&#21442;&#25968;$\Sigma$&#21442;&#25968;&#21270;&#30340;&#26680;&#20989;&#25968;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#23427;&#21516;&#26102;&#20248;&#21270;&#20102;&#39044;&#27979;&#20989;&#25968;&#21644;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#21442;&#25968;$\Sigma$&#12290;&#20174;&#36825;&#20010;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#23398;&#21040;&#30340;$\Sigma$&#30340;&#29305;&#24449;&#31354;&#38388;&#21487;&#20197;&#21578;&#35785;&#25105;&#20204;&#21327;&#21464;&#37327;&#31354;&#38388;&#20013;&#21738;&#20123;&#26041;&#21521;&#23545;&#39044;&#27979;&#26159;&#37325;&#35201;&#30340;&#12290;&#20551;&#35774;&#21327;&#21464;&#37327;&#21482;&#36890;&#36807;&#20302;&#32500;&#23376;&#31354;&#38388;&#65288;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#65289;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#38750;&#38646;&#30340;&#35299;&#37322;&#33021;&#21147;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#19979;&#26377;&#38480;&#26679;&#26412;&#26680;&#23398;&#20064;&#30446;&#26631;&#30340;&#20840;&#23616;&#26368;&#23567;&#21270;&#32773;&#20063;&#26159;&#20302;&#31209;&#30340;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#26368;&#23567;&#21270;$\Sigma$&#30340;&#31209;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#34987;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#30340;&#32500;&#24230;&#25152;&#38480;&#21046;&#12290;&#36825;&#20010;&#29616;&#35937;&#24456;&#26377;&#36259;&#65292;&#22240;&#20026;&#20302;&#31209;&#29305;&#24615;&#26159;&#22312;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#23545;$\Sigma$&#30340;&#26174;&#24335;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#30340;&#65292;&#20363;&#22914;&#26680;&#33539;&#25968;&#27491;&#21017;&#21270;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider kernels of the form $(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$ parametrized by $\Sigma$. For such kernels, we study a variant of the kernel ridge regression problem which simultaneously optimizes the prediction function and the parameter $\Sigma$ of the reproducing kernel Hilbert space. The eigenspace of the $\Sigma$ learned from this kernel ridge regression problem can inform us which directions in covariate space are important for prediction.  Assuming that the covariates have nonzero explanatory power for the response only through a low dimensional subspace (central mean subspace), we find that the global minimizer of the finite sample kernel learning objective is also low rank with high probability. More precisely, the rank of the minimizing $\Sigma$ is with high probability bounded by the dimension of the central mean subspace. This phenomenon is interesting because the low rankness property is achieved without using any explicit regularization of $\Sigma$, e.g., nuclear
&lt;/p&gt;</description></item></channel></rss>