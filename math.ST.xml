<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#23558;&#20854;&#25299;&#23637;&#21040;&#20855;&#26377;&#27425;&#25351;&#25968;&#23614;&#37096;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#36825;&#20123;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#26368;&#20339;&#35823;&#24046;&#29575;</title><link>https://arxiv.org/abs/2402.15432</link><description>&lt;p&gt;
&#22312;&#27425;&#25351;&#25968;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#26497;&#23567;&#21270;&#32858;&#31867;&#35823;&#24046;&#65306;&#36890;&#29992;&#19979;&#30028;&#21644;&#26368;&#20339;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Universal Lower Bounds and Optimal Rates: Achieving Minimax Clustering Error in Sub-Exponential Mixture Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#23558;&#20854;&#25299;&#23637;&#21040;&#20855;&#26377;&#27425;&#25351;&#25968;&#23614;&#37096;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#36825;&#20123;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#26368;&#20339;&#35823;&#24046;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#36890;&#24120;&#36890;&#36807;&#28151;&#21512;&#27169;&#22411;&#30340;&#35270;&#35282;&#26469;&#30740;&#31350;&#12290;&#22312;&#39640;&#26031;&#21644;&#27425;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#24674;&#22797;&#32858;&#31867;&#26631;&#31614;&#30340;&#26368;&#20339;&#35823;&#24046;&#29575;&#28041;&#21450;&#21040;&#29305;&#23450;&#30340;&#20449;&#22122;&#27604;&#12290;&#31616;&#21333;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22914;Lloyd&#31639;&#27861;&#65292;&#21487;&#20197;&#36798;&#21040;&#36825;&#20010;&#26368;&#20339;&#35823;&#24046;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20026;&#20219;&#20309;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#35823;&#24046;&#29575;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#36825;&#26159;&#19968;&#20010;&#27604;&#20449;&#22122;&#27604;&#26356;&#36890;&#29992;&#30340;&#27169;&#22411;&#20449;&#24687;&#24230;&#37327;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#36825;&#20010;&#19979;&#30028;&#65292;&#29305;&#21035;&#24378;&#35843;&#20102;&#20855;&#26377;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#35823;&#24046;&#30340;&#20301;&#32622;-&#23610;&#24230;&#28151;&#21512;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#26356;&#36866;&#21512;&#30001;&#27850;&#26494;&#25110;&#36127;&#20108;&#39033;&#28151;&#21512;&#27169;&#22411;&#24314;&#27169;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20854;&#20998;&#24067;&#23646;&#20110;&#25351;&#25968;&#26063;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15432v1 Announce Type: cross  Abstract: Clustering is a pivotal challenge in unsupervised machine learning and is often investigated through the lens of mixture models. The optimal error rate for recovering cluster labels in Gaussian and sub-Gaussian mixture models involves ad hoc signal-to-noise ratios. Simple iterative algorithms, such as Lloyd's algorithm, attain this optimal error rate. In this paper, we first establish a universal lower bound for the error rate in clustering any mixture model, expressed through a Chernoff divergence, a more versatile measure of model information than signal-to-noise ratios. We then demonstrate that iterative algorithms attain this lower bound in mixture models with sub-exponential tails, notably emphasizing location-scale mixtures featuring Laplace-distributed errors. Additionally, for datasets better modelled by Poisson or Negative Binomial mixtures, we study mixture models whose distributions belong to an exponential family. In such m
&lt;/p&gt;</description></item></channel></rss>