<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#20998;&#21306;&#20998;&#31867;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20986;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#26032;&#29305;&#24615;&#65292;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;</title><link>https://arxiv.org/abs/2312.14889</link><description>&lt;p&gt;
&#35770;&#20174;&#21487;&#35266;&#27979;&#21644;&#31169;&#23494;&#25968;&#25454;&#20013;&#23454;&#29616;&#36895;&#29575;&#26368;&#20248;&#20998;&#21306;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
On Rate-Optimal Partitioning Classification from Observable and from Privatised Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14889
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#20998;&#21306;&#20998;&#31867;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20986;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#26032;&#29305;&#24615;&#65292;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20998;&#21306;&#20998;&#31867;&#30340;&#32463;&#20856;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#21253;&#25324;&#21487;&#35266;&#27979;&#65288;&#38750;&#31169;&#23494;&#65289;&#21644;&#31169;&#23494;&#25968;&#25454;&#12290;&#25105;&#20204;&#20551;&#35774;&#29305;&#24449;&#21521;&#37327;$X$&#21462;&#20540;&#20110;$\mathbb{R}^d$&#65292;&#20854;&#26631;&#31614;&#20026;$Y$&#12290;&#20043;&#21069;&#20851;&#20110;&#20998;&#21306;&#20998;&#31867;&#22120;&#30340;&#32467;&#26524;&#22522;&#20110;&#24378;&#23494;&#24230;&#20551;&#35774;&#65292;&#36825;&#31181;&#20551;&#35774;&#38480;&#21046;&#36739;&#22823;&#65292;&#25105;&#20204;&#36890;&#36807;&#31616;&#21333;&#30340;&#20363;&#23376;&#21152;&#20197;&#35777;&#26126;&#12290;&#25105;&#20204;&#20551;&#35774;$X$&#30340;&#20998;&#24067;&#26159;&#32477;&#23545;&#36830;&#32493;&#20998;&#24067;&#21644;&#31163;&#25955;&#20998;&#24067;&#30340;&#28151;&#21512;&#20307;&#65292;&#20854;&#20013;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#38598;&#20013;&#20110;&#19968;&#20010;$d_a$&#32500;&#23376;&#31354;&#38388;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#22312;&#26356;&#23485;&#26494;&#30340;&#26465;&#20214;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65306;&#38500;&#20102;&#26631;&#20934;&#30340;Lipschitz&#21644;&#36793;&#38469;&#26465;&#20214;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#19968;&#20010;&#26032;&#29305;&#24615;&#65292;&#36890;&#36807;&#35813;&#29305;&#24615;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;&#65292;&#23545;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14889v2 Announce Type: replace-cross  Abstract: In this paper we revisit the classical method of partitioning classification and study its convergence rate under relaxed conditions, both for observable (non-privatised) and for privatised data. Let the feature vector $X$ take values in $\mathbb{R}^d$ and denote its label by $Y$. Previous results on the partitioning classifier worked with the strong density assumption, which is restrictive, as we demonstrate through simple examples. We assume that the distribution of $X$ is a mixture of an absolutely continuous and a discrete distribution, such that the absolutely continuous component is concentrated to a $d_a$ dimensional subspace. Here, we study the problem under much milder assumptions: in addition to the standard Lipschitz and margin conditions, a novel characteristic of the absolutely continuous component is introduced, by which the exact convergence rate of the classification error probability is calculated, both for the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27169;&#22411;&#40065;&#26834;&#24615;&#20197;&#32553;&#23567;&#27169;&#25311;&#19982;&#30495;&#23454;&#24046;&#36317;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#20998;&#24067;&#40065;&#26834;&#20540;&#36845;&#20195;&#8221;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20248;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.16589</link><description>&lt;p&gt;
&#20855;&#26377;&#29983;&#25104;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#20998;&#24067;&#40065;&#26834;&#24615;&#30340;&#21487;&#30097;&#20215;&#26684;
&lt;/p&gt;
&lt;p&gt;
The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model. (arXiv:2305.16589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27169;&#22411;&#40065;&#26834;&#24615;&#20197;&#32553;&#23567;&#27169;&#25311;&#19982;&#30495;&#23454;&#24046;&#36317;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#20998;&#24067;&#40065;&#26834;&#20540;&#36845;&#20195;&#8221;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20248;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27169;&#22411;&#40065;&#26834;&#24615;&#65292;&#20197;&#20943;&#23569;&#22312;&#23454;&#36341;&#20013;&#30340;&#27169;&#25311;&#19982;&#30495;&#23454;&#24046;&#36317;&#12290;&#25105;&#20204;&#37319;&#29992;&#20998;&#24067;&#40065;&#26834;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;RMDPs&#65289;&#26694;&#26550;&#65292;&#26088;&#22312;&#23398;&#20064;&#19968;&#20010;&#31574;&#30053;&#65292;&#22312;&#37096;&#32626;&#29615;&#22659;&#33853;&#22312;&#39044;&#23450;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#20869;&#26102;&#65292;&#20248;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#12290;&#23613;&#31649;&#26368;&#36817;&#26377;&#20102;&#19968;&#20123;&#21162;&#21147;&#65292;&#20294;RMDPs&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20173;&#28982;&#27809;&#26377;&#24471;&#21040;&#35299;&#20915;&#65292;&#26080;&#35770;&#20351;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#26159;&#20160;&#20040;&#12290;&#19981;&#28165;&#26970;&#20998;&#24067;&#40065;&#26834;&#24615;&#19982;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#30456;&#27604;&#26159;&#21542;&#20855;&#26377;&#32479;&#35745;&#23398;&#19978;&#30340;&#24433;&#21709;&#12290;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#26681;&#25454;&#21517;&#20041;MDP&#32472;&#21046;&#26679;&#26412;&#65292;&#25105;&#20204;&#23558;&#25551;&#36848;RMDPs&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24403;&#30001;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#36317;&#31163;&#25110;$\chi^2$&#20998;&#27495;&#25351;&#23450;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#26102;&#12290;&#22312;&#36825;&#37324;&#30740;&#31350;&#30340;&#31639;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#20998;&#24067;&#40065;&#26834;&#20540;&#36845;&#20195;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#25972;&#20010;&#33539;&#22260;&#20869;&#37117;&#26159;&#36817;&#20046;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates model robustness in reinforcement learning (RL) to reduce the sim-to-real gap in practice. We adopt the framework of distributionally robust Markov decision processes (RMDPs), aimed at learning a policy that optimizes the worst-case performance when the deployed environment falls within a prescribed uncertainty set around the nominal MDP. Despite recent efforts, the sample complexity of RMDPs remained mostly unsettled regardless of the uncertainty set in use. It was unclear if distributional robustness bears any statistical consequences when benchmarked against standard RL.  Assuming access to a generative model that draws samples based on the nominal MDP, we characterize the sample complexity of RMDPs when the uncertainty set is specified via either the total variation (TV) distance or $\chi^2$ divergence. The algorithm studied here is a model-based method called {\em distributionally robust value iteration}, which is shown to be near-optimal for the full range
&lt;/p&gt;</description></item></channel></rss>