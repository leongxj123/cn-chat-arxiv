<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#20197;&#21450;Wasserstein&#36317;&#31163;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04650</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An analysis of the noise schedule for score-based generative models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#20197;&#21450;Wasserstein&#36317;&#31163;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#26088;&#22312;&#36890;&#36807;&#20165;&#20351;&#29992;&#30446;&#26631;&#25968;&#25454;&#30340;&#22122;&#22768;&#25200;&#21160;&#26679;&#26412;&#26469;&#23398;&#20064;&#24471;&#20998;&#20989;&#25968;&#65292;&#20174;&#32780;&#20272;&#35745;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#12290;&#26368;&#36817;&#30340;&#25991;&#29486;&#20027;&#35201;&#20851;&#27880;&#35780;&#20272;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#36890;&#36807;KL&#25955;&#24230;&#21644;Wasserstein&#36317;&#31163;&#26469;&#34913;&#37327;&#29983;&#25104;&#36136;&#37327;&#12290;&#33267;&#20170;&#20026;&#27490;&#65292;&#25152;&#26377;&#29616;&#26377;&#32467;&#26524;&#37117;&#26159;&#38024;&#23545;&#26102;&#38388;&#22343;&#21248;&#21464;&#21270;&#30340;&#22122;&#22768;&#35843;&#24230;&#24471;&#21040;&#30340;&#12290;&#22312;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#65292;&#26126;&#30830;&#20381;&#36182;&#20110;&#20219;&#20309;&#26102;&#38388;&#30456;&#20851;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;&#20551;&#35774;&#24471;&#20998;&#26159;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;Wasserstein&#36317;&#31163;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#26377;&#21033;&#30340;&#25910;&#32553;&#26426;&#21046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#19978;&#30028;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) aim at estimating a target data distribution by learning score functions using only noise-perturbed samples from the target. Recent literature has focused extensively on assessing the error between the target and estimated distributions, gauging the generative quality through the Kullback-Leibler (KL) divergence and Wasserstein distances.  All existing results  have been obtained so far for time-homogeneous speed of the noise schedule.  Under mild assumptions on the data distribution, we establish an upper bound for the KL divergence between the target and the estimated distributions, explicitly depending on any time-dependent noise schedule. Assuming that the score is Lipschitz continuous, we provide an improved error bound in Wasserstein distance, taking advantage of favourable underlying contraction mechanisms. We also propose an algorithm to automatically tune the noise schedule using the proposed upper bound. We illustrate empirically the perfo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#36866;&#29992;&#20110;&#38750;&#21487;&#31215;&#24773;&#20917;&#65292;&#24182;&#35828;&#26126;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#20197;&#21450;&#35813;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.01163</link><description>&lt;p&gt;
&#38750;&#21487;&#31215;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340;&#25193;&#23637;&#32500;&#23572;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
The extended Ville's inequality for nonintegrable nonnegative supermartingales. (arXiv:2304.01163v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#36866;&#29992;&#20110;&#38750;&#21487;&#31215;&#24773;&#20917;&#65292;&#24182;&#35828;&#26126;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#20197;&#21450;&#35813;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312; Robbins &#30340;&#21021;&#22987;&#24037;&#20316;&#22522;&#30784;&#19978;&#65292;&#20005;&#23494;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340;&#25193;&#23637;&#29702;&#35770;&#65292;&#19981;&#38656;&#35201;&#21487;&#31215;&#24615;&#25110;&#26377;&#38480;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102; Robbins &#39044;&#31034;&#30340;&#19968;&#20010;&#20851;&#38190;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#31216;&#20026;&#25193;&#23637;&#32500;&#23572;&#19981;&#31561;&#24335;&#65292;&#23427;&#21152;&#24378;&#20102;&#32463;&#20856;&#30340;&#32500;&#23572;&#19981;&#31561;&#24335;&#65288;&#36866;&#29992;&#20110;&#21487;&#31215;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65289;&#65292;&#24182;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#38750;&#21487;&#31215;&#35774;&#32622;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#25105;&#20204;&#25193;&#23637;&#30340;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340; $\sigma$- &#26377;&#38480;&#28151;&#21512;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#19968;&#20123;&#24212;&#29992;&#65292;&#22914;&#22312;&#25512;&#23548;&#38750;&#21442;&#25968;&#32622;&#20449;&#24207;&#21015;&#21644;&#65288;&#25193;&#23637;&#65289;e-&#36807;&#31243;&#20013;&#20351;&#29992;&#19981;&#36866;&#24403;&#28151;&#21512;&#65288;&#20808;&#39564;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Following initial work by Robbins, we rigorously present an extended theory of nonnegative supermartingales, requiring neither integrability nor finiteness. In particular, we derive a key maximal inequality foreshadowed by Robbins, which we call the extended Ville's inequality, that strengthens the classical Ville's inequality (for integrable nonnegative supermartingales), and also applies to our nonintegrable setting. We derive an extension of the method of mixtures, which applies to $\sigma$-finite mixtures of our extended nonnegative supermartingales. We present some implications of our theory for sequential statistics, such as the use of improper mixtures (priors) in deriving nonparametric confidence sequences and (extended) e-processes.
&lt;/p&gt;</description></item></channel></rss>