<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#23454;&#29616;&#26368;&#20339;&#20984;$M$-&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#33021;&#22815;&#36798;&#21040;&#26368;&#20339;&#30340;&#28176;&#36817;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#65292;&#35777;&#26126;&#20855;&#26377;&#25152;&#26377;&#20984;$M$-&#20272;&#35745;&#20013;&#26368;&#23567;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.16688</link><description>&lt;p&gt;
&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#23454;&#29616;&#26368;&#20339;&#20984;$M$-&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal convex $M$-estimation via score matching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16688
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#23454;&#29616;&#26368;&#20339;&#20984;$M$-&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#33021;&#22815;&#36798;&#21040;&#26368;&#20339;&#30340;&#28176;&#36817;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#65292;&#35777;&#26126;&#20855;&#26377;&#25152;&#26377;&#20984;$M$-&#20272;&#35745;&#20013;&#26368;&#23567;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24615;&#22238;&#24402;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#35813;&#20989;&#25968;&#36827;&#34892;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#20197;&#22312;&#22238;&#24402;&#31995;&#25968;&#30340;&#19979;&#28216;&#20272;&#35745;&#20013;&#23454;&#29616;&#26368;&#20339;&#30340;&#28176;&#36817;&#26041;&#24046;&#12290;&#25105;&#20204;&#30340;&#21322;&#21442;&#25968;&#26041;&#27861;&#26088;&#22312;&#26368;&#20339;&#36924;&#36817;&#22122;&#22768;&#20998;&#24067;&#23545;&#25968;&#23494;&#24230;&#30340;&#23548;&#25968;&#12290;&#22312;&#24635;&#20307;&#23618;&#38754;&#19978;&#65292;&#36825;&#20010;&#25311;&#21512;&#36807;&#31243;&#26159;&#23545;&#24471;&#20998;&#21305;&#37197;&#30340;&#38750;&#21442;&#25968;&#25299;&#23637;&#65292;&#23545;&#24212;&#20110;&#26681;&#25454;Fisher&#25955;&#24230;&#36827;&#34892;&#22122;&#22768;&#20998;&#24067;&#30340;&#23545;&#25968;&#20985;&#26144;&#23556;&#12290;&#35813;&#36807;&#31243;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#31243;&#24207;&#36798;&#21040;&#20102;&#25152;&#26377;&#20984;$M$-&#20272;&#35745;&#20013;&#26368;&#23567;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;&#20316;&#20026;&#38750;&#23545;&#25968;&#20985;&#35774;&#32622;&#30340;&#19968;&#20010;&#20363;&#23376;&#65292;&#23545;&#20110;&#26607;&#35199;&#35823;&#24046;&#65292;&#26368;&#20339;&#20984;&#25439;&#22833;&#20989;&#25968;&#31867;&#20284;&#20110;Huber&#20989;&#25968;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#36807;&#31243;&#30456;&#23545;&#20110;oracle&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#23454;&#29616;&#20102;&#22823;&#20110;0.87&#30340;&#28176;&#36817;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16688v1 Announce Type: cross  Abstract: In the context of linear regression, we construct a data-driven convex loss function with respect to which empirical risk minimisation yields optimal asymptotic variance in the downstream estimation of the regression coefficients. Our semiparametric approach targets the best decreasing approximation of the derivative of the log-density of the noise distribution. At the population level, this fitting process is a nonparametric extension of score matching, corresponding to a log-concave projection of the noise distribution with respect to the Fisher divergence. The procedure is computationally efficient, and we prove that our procedure attains the minimal asymptotic covariance among all convex $M$-estimators. As an example of a non-log-concave setting, for Cauchy errors, the optimal convex loss function is Huber-like, and our procedure yields an asymptotic efficiency greater than 0.87 relative to the oracle maximum likelihood estimator o
&lt;/p&gt;</description></item><item><title>&#20026;&#20102;&#35299;&#20915;&#20248;&#21270;&#31574;&#30053;&#23398;&#20064;&#20013;&#30340;&#27495;&#35270;&#38382;&#39064;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20801;&#35768;&#20915;&#31574;&#32773;&#36890;&#36807;&#24809;&#32602;&#26469;&#38450;&#27490;&#22312;&#29305;&#23450;&#20154;&#32676;&#20013;&#30340;&#19981;&#20844;&#24179;&#32467;&#26524;&#20998;&#24067;&#65292;&#35813;&#26694;&#26550;&#23545;&#30446;&#26631;&#20989;&#25968;&#21644;&#27495;&#35270;&#24230;&#37327;&#20855;&#26377;&#24456;&#22823;&#30340;&#28789;&#27963;&#24615;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#21442;&#25968;&#35843;&#25972;&#65292;&#21487;&#20197;&#22312;&#23454;&#36341;&#20013;&#20855;&#22791;&#36951;&#25022;&#21644;&#19968;&#33268;&#24615;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2401.17909</link><description>&lt;p&gt;
&#20248;&#21270;&#31574;&#30053;&#23398;&#20064;&#20013;&#27491;&#21017;&#21270;&#27495;&#35270;&#38382;&#39064;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Regularizing Discrimination in Optimal Policy Learning with Distributional Targets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17909
&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#20248;&#21270;&#31574;&#30053;&#23398;&#20064;&#20013;&#30340;&#27495;&#35270;&#38382;&#39064;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20801;&#35768;&#20915;&#31574;&#32773;&#36890;&#36807;&#24809;&#32602;&#26469;&#38450;&#27490;&#22312;&#29305;&#23450;&#20154;&#32676;&#20013;&#30340;&#19981;&#20844;&#24179;&#32467;&#26524;&#20998;&#24067;&#65292;&#35813;&#26694;&#26550;&#23545;&#30446;&#26631;&#20989;&#25968;&#21644;&#27495;&#35270;&#24230;&#37327;&#20855;&#26377;&#24456;&#22823;&#30340;&#28789;&#27963;&#24615;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#21442;&#25968;&#35843;&#25972;&#65292;&#21487;&#20197;&#22312;&#23454;&#36341;&#20013;&#20855;&#22791;&#36951;&#25022;&#21644;&#19968;&#33268;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#36890;&#24120;&#36890;&#36807;&#35757;&#32451;&#25968;&#25454;&#23398;&#20064;&#27835;&#30103;&#30340;&#30456;&#23545;&#25928;&#26524;&#65292;&#24182;&#36873;&#25321;&#19968;&#20010;&#23454;&#26045;&#26426;&#21046;&#65292;&#35813;&#26426;&#21046;&#26681;&#25454;&#26576;&#20010;&#30446;&#26631;&#20989;&#25968;&#39044;&#27979;&#20102;&#8220;&#26368;&#20248;&#8221;&#32467;&#26524;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#24847;&#35782;&#21040;&#27495;&#35270;&#38382;&#39064;&#30340;&#20915;&#31574;&#32773;&#21487;&#33021;&#19981;&#28385;&#24847;&#20197;&#20005;&#37325;&#27495;&#35270;&#20154;&#32676;&#23376;&#32452;&#30340;&#20195;&#20215;&#26469;&#23454;&#29616;&#35813;&#20248;&#21270;&#65292;&#21363;&#22312;&#23376;&#32452;&#20013;&#30340;&#32467;&#26524;&#20998;&#24067;&#26126;&#26174;&#20559;&#31163;&#25972;&#20307;&#26368;&#20248;&#32467;&#26524;&#20998;&#24067;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20801;&#35768;&#20915;&#31574;&#32773;&#24809;&#32602;&#36825;&#31181;&#20559;&#24046;&#65292;&#24182;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#30446;&#26631;&#20989;&#25968;&#21644;&#27495;&#35270;&#24230;&#37327;&#12290;&#25105;&#20204;&#23545;&#20855;&#26377;&#25968;&#25454;&#39537;&#21160;&#35843;&#21442;&#30340;&#32463;&#39564;&#25104;&#21151;&#31574;&#30053;&#24314;&#31435;&#20102;&#36951;&#25022;&#21644;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#20004;&#20010;&#23454;&#35777;&#22330;&#26223;&#36827;&#34892;&#20102;&#31616;&#35201;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
A decision maker typically (i) incorporates training data to learn about the relative effectiveness of the treatments, and (ii) chooses an implementation mechanism that implies an "optimal" predicted outcome distribution according to some target functional. Nevertheless, a discrimination-aware decision maker may not be satisfied achieving said optimality at the cost of heavily discriminating against subgroups of the population, in the sense that the outcome distribution in a subgroup deviates strongly from the overall optimal outcome distribution. We study a framework that allows the decision maker to penalize for such deviations, while allowing for a wide range of target functionals and discrimination measures to be employed. We establish regret and consistency guarantees for empirical success policies with data-driven tuning parameters, and provide numerical results. Furthermore, we briefly illustrate the methods in two empirical settings.
&lt;/p&gt;</description></item></channel></rss>