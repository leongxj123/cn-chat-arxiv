<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.10870</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10870
&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#20851;&#20110;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#30456;&#20284;&#34920;&#31034;&#32467;&#26500;&#26469;&#31616;&#21270;&#30446;&#26631;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#25910;&#25947;&#36895;&#29575;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#34920;&#31034;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#65292;&#24341;&#20837;&#20102;&#27599;&#20010;&#20219;&#21153;&#20013;&#19981;&#21487;&#31616;&#21333;&#24179;&#22343;&#30340;&#38750;&#24179;&#20961;&#20559;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#38750;&#32447;&#24615;&#34920;&#31034;&#25512;&#23548;&#20986;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;</title><link>http://arxiv.org/abs/2212.07383</link><description>&lt;p&gt;
&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Sequential Kernelized Independence Testing. (arXiv:2212.07383v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07383
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29420;&#31435;&#24615;&#27979;&#35797;&#26159;&#19968;&#20010;&#32463;&#20856;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#22312;&#22266;&#23450;&#37319;&#38598;&#25968;&#25454;&#20043;&#21069;&#30340;&#25209;&#37327;&#35774;&#32622;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#23454;&#36341;&#32773;&#20204;&#24448;&#24448;&#26356;&#21916;&#27426;&#33021;&#22815;&#26681;&#25454;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#36827;&#34892;&#33258;&#36866;&#24212;&#30340;&#31243;&#24207;&#65292;&#32780;&#19981;&#26159;&#20107;&#20808;&#35774;&#23450;&#26679;&#26412;&#22823;&#23567;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#36825;&#26679;&#30340;&#31243;&#24207;&#24212;&#35813;&#65288;a&#65289;&#22312;&#31616;&#21333;&#20219;&#21153;&#19978;&#23613;&#26089;&#20572;&#27490;&#65288;&#22312;&#22256;&#38590;&#20219;&#21153;&#19978;&#31245;&#21518;&#20572;&#27490;&#65289;&#65292;&#22240;&#27492;&#26356;&#22909;&#22320;&#21033;&#29992;&#21487;&#29992;&#36164;&#28304;&#65292;&#20197;&#21450;&#65288;b&#65289;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#20043;&#21518;&#65292;&#25345;&#32493;&#30417;&#27979;&#25968;&#25454;&#24182;&#39640;&#25928;&#22320;&#25972;&#21512;&#32479;&#35745;&#35777;&#25454;&#65292;&#21516;&#26102;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;&#32463;&#20856;&#30340;&#25209;&#37327;&#27979;&#35797;&#19981;&#36866;&#29992;&#20110;&#27969;&#25968;&#25454;&#65306;&#22312;&#25968;&#25454;&#35266;&#23519;&#21518;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#38656;&#35201;&#23545;&#22810;&#37325;&#27979;&#35797;&#36827;&#34892;&#26657;&#27491;&#65292;&#36825;&#23548;&#33268;&#20102;&#20302;&#21151;&#29575;&#12290;&#36981;&#24490;&#36890;&#36807;&#25237;&#27880;&#36827;&#34892;&#27979;&#35797;&#30340;&#21407;&#21017;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#20811;&#26381;&#20102;&#36825;&#20123;&#32570;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#30001;&#26680;&#30456;&#20851;&#24615;&#27979;&#24230;&#65288;&#22914;Hilbert-&#65289;&#21551;&#21457;&#30340;&#25237;&#27880;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#24191;&#27867;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Independence testing is a classical statistical problem that has been extensively studied in the batch setting when one fixes the sample size before collecting data. However, practitioners often prefer procedures that adapt to the complexity of a problem at hand instead of setting sample size in advance. Ideally, such procedures should (a) stop earlier on easy tasks (and later on harder tasks), hence making better use of available resources, and (b) continuously monitor the data and efficiently incorporate statistical evidence after collecting new data, while controlling the false alarm rate. Classical batch tests are not tailored for streaming data: valid inference after data peeking requires correcting for multiple testing which results in low power. Following the principle of testing by betting, we design sequential kernelized independence tests that overcome such shortcomings. We exemplify our broad framework using bets inspired by kernelized dependence measures, e.g., the Hilbert-
&lt;/p&gt;</description></item></channel></rss>