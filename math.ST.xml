<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#22312;&#36229;&#31435;&#26041;&#20307;&#25968;&#25454;&#27969;&#19978;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#31934;&#24230;&#30028;&#38480;&#65292;&#20063;&#25512;&#24191;&#20102;&#20043;&#21069;&#20851;&#20110;&#35745;&#25968;&#26597;&#35810;&#30340;&#36830;&#32493;&#21457;&#24067;&#27169;&#22411;&#30340;&#24037;&#20316;&#65292;&#20165;&#38656;&#35201;&#39069;&#22806;&#30340;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#12290;</title><link>https://arxiv.org/abs/2402.08012</link><description>&lt;p&gt;
&#22312;&#32447;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Online Differentially Private Synthetic Data Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#22312;&#36229;&#31435;&#26041;&#20307;&#25968;&#25454;&#27969;&#19978;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#31934;&#24230;&#30028;&#38480;&#65292;&#20063;&#25512;&#24191;&#20102;&#20043;&#21069;&#20851;&#20110;&#35745;&#25968;&#26597;&#35810;&#30340;&#36830;&#32493;&#21457;&#24067;&#27169;&#22411;&#30340;&#24037;&#20316;&#65292;&#20165;&#38656;&#35201;&#39069;&#22806;&#30340;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#32447;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#23545;&#20110;&#22312;&#36229;&#31435;&#26041;&#20307;$[0,1]^d$&#20869;&#30340;&#25968;&#25454;&#27969;&#21644;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#31639;&#27861;&#65292;&#27599;&#20010;&#26102;&#38388;$t$&#37117;&#29983;&#25104;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#38598;&#12290;&#35813;&#31639;&#27861;&#22312;1-Wasserstein&#36317;&#31163;&#19978;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#31934;&#24230;&#30028;&#38480;&#65306;&#24403;$d\geq 2$&#26102;&#20026;$O(t^{-1/d}\log(t)$&#65292;&#24403;$d=1$&#26102;&#20026;$O(t^{-1}\log^{4.5}(t)$&#12290;&#36825;&#20010;&#32467;&#26524;&#23558;&#20043;&#21069;&#20851;&#20110;&#35745;&#25968;&#26597;&#35810;&#30340;&#36830;&#32493;&#21457;&#24067;&#27169;&#22411;&#30340;&#24037;&#20316;&#25512;&#24191;&#21040;&#21253;&#25324;Lipschitz&#26597;&#35810;&#12290;&#19982;&#31163;&#32447;&#24773;&#20917;&#19981;&#21516;&#65292;&#31163;&#32447;&#24773;&#20917;&#19979;&#25972;&#20010;&#25968;&#25454;&#38598;&#19968;&#27425;&#24615;&#21487;&#29992;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20165;&#38656;&#35201;&#22312;&#31934;&#24230;&#30028;&#38480;&#20013;&#39069;&#22806;&#30340;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a polynomial-time algorithm for online differentially private synthetic data generation. For a data stream within the hypercube $[0,1]^d$ and an infinite time horizon, we develop an online algorithm that generates a differentially private synthetic dataset at each time $t$. This algorithm achieves a near-optimal accuracy bound of $O(t^{-1/d}\log(t))$ for $d\geq 2$ and $O(t^{-1}\log^{4.5}(t))$ for $d=1$ in the 1-Wasserstein distance. This result generalizes the previous work on the continual release model for counting queries to include Lipschitz queries. Compared to the offline case, where the entire dataset is available at once, our approach requires only an extra polylog factor in the accuracy bound.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2401.05574</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#22343;&#20540;&#30340;&#40065;&#26834;&#32858;&#31867;&#30340;&#19968;&#33324;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A general theory for robust clustering via trimmed mean. (arXiv:2401.05574v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#24322;&#36136;&#25968;&#25454;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#32858;&#31867;&#26159;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#32467;&#26524;&#20027;&#35201;&#20851;&#27880;&#22312;&#25968;&#25454;&#22260;&#32469;&#24102;&#26377;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#20998;&#24067;&#26102;&#30340;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#38480;&#21046;&#24615;&#30340;&#27425;&#39640;&#26031;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#24120;&#24120;&#26080;&#25928;&#65292;&#22240;&#20026;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#23637;&#31034;&#20102;&#22260;&#32469;&#20013;&#24515;&#28857;&#30340;&#37325;&#23614;&#20998;&#24067;&#25110;&#21463;&#21040;&#21487;&#33021;&#30340;&#25932;&#23545;&#25915;&#20987;&#65292;&#38656;&#35201;&#20855;&#26377;&#40065;&#26834;&#25968;&#25454;&#39537;&#21160;&#21021;&#22987;&#21270;&#30340;&#40065;&#26834;&#32858;&#31867;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#21464;&#37327;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#65292;&#22312;&#20013;&#24515;&#28857;&#21608;&#22260;&#30340;&#35823;&#24046;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#19978;&#30028;&#20381;&#36182;&#20110;&#32858;&#31867;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31616;&#21270;&#20026;&#20122;&#39640;&#26031;&#27169;&#22411;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a fundamental tool in statistical machine learning in the presence of heterogeneous data. Many recent results focus primarily on optimal mislabeling guarantees, when data are distributed around centroids with sub-Gaussian errors. Yet, the restrictive sub-Gaussian model is often invalid in practice, since various real-world applications exhibit heavy tail distributions around the centroids or suffer from possible adversarial attacks that call for robust clustering with a robust data-driven initialization. In this paper, we introduce a hybrid clustering technique with a novel multivariate trimmed mean type centroid estimate to produce mislabeling guarantees under a weak initialization condition for general error distributions around the centroids. A matching lower bound is derived, up to factors depending on the number of clusters. In addition, our approach also produces the optimal mislabeling even in the presence of adversarial outliers. Our results reduce to the sub-Gaus
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05679</link><description>&lt;p&gt;
&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayes optimal learning in high-dimensional linear regression with network side information. (arXiv:2306.05679v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#24212;&#29992;&#20013;&#65292;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#32463;&#24120;&#20986;&#29616;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#31216;&#20026;Reg-Graph&#27169;&#22411;&#65289;&#65292;&#36890;&#36807;&#19968;&#32452;&#20849;&#21516;&#30340;&#28508;&#22312;&#21442;&#25968;&#20026;&#30417;&#30563;&#25968;&#25454;&#21644;&#35266;&#27979;&#21040;&#30340;&#32593;&#32476;&#35774;&#23450;&#20102;&#19968;&#20010;&#32852;&#21512;&#20998;&#24067;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#38750;&#24120;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#20449;&#21495;&#21644;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#20043;&#38388;&#30340;&#26497;&#38480;&#20114;&#20449;&#24687;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20174;&#32780;&#31934;&#30830;&#37327;&#21270;&#20102;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#24433;&#21709;&#12290;&#25105;&#20204;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning problems with side information in the form of a network arise frequently in applications in genomics, proteomics and neuroscience. For example, in genetic applications, the network side information can accurately capture background biological information on the intricate relations among the relevant genes. In this paper, we initiate a study of Bayes optimal learning in high-dimensional linear regression with network side information. To this end, we first introduce a simple generative model (called the Reg-Graph model) which posits a joint distribution for the supervised data and the observed network through a common set of latent parameters. Next, we introduce an iterative algorithm based on Approximate Message Passing (AMP) which is provably Bayes optimal under very general conditions. In addition, we characterize the limiting mutual information between the latent signal and the data observed, and thus precisely quantify the statistical impact of the network side 
&lt;/p&gt;</description></item></channel></rss>