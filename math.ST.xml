<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#25506;&#35752;&#20102;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;&#36890;&#20449;&#22270;&#35774;&#35745;&#21644;&#22823;&#23567;&#23545;&#21518;&#39564;&#25910;&#32553;&#29575;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2311.08214</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#39057;&#29575;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Frequentist Guarantees of Distributed (Non)-Bayesian Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#25506;&#35752;&#20102;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;&#36890;&#20449;&#22270;&#35774;&#35745;&#21644;&#22823;&#23567;&#23545;&#21518;&#39564;&#25910;&#32553;&#29575;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20998;&#26512;&#22823;&#22411;&#20998;&#25955;&#25968;&#25454;&#38598;&#30340;&#38656;&#27714;&#25512;&#21160;&#65292;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#24050;&#25104;&#20026;&#36328;&#22810;&#20010;&#39046;&#22495;&#65288;&#21253;&#25324;&#32479;&#35745;&#23398;&#12289;&#30005;&#27668;&#24037;&#31243;&#21644;&#32463;&#27982;&#23398;&#65289;&#30340;&#20851;&#38190;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#22914;&#21518;&#39564;&#19968;&#33268;&#24615;&#12289;&#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#21518;&#39564;&#25910;&#32553;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36890;&#20449;&#22270;&#19978;&#30340;&#36866;&#24403;&#20551;&#35774;&#19979;&#65292;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#20445;&#30041;&#20102;&#21442;&#25968;&#25928;&#29575;&#65292;&#21516;&#26102;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#22686;&#24378;&#20102;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#30740;&#31350;&#35774;&#35745;&#21644;&#36890;&#20449;&#22270;&#30340;&#22823;&#23567;&#22914;&#20309;&#24433;&#21709;&#21518;&#39564;&#25910;&#32553;&#29575;&#26469;&#25506;&#35752;&#20102;&#32479;&#35745;&#25928;&#29575;&#21644;&#36890;&#20449;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#26102;&#21464;&#22270;&#65292;&#24182;&#23558;&#32467;&#26524;&#24212;&#29992;&#20110;&#25351;&#25968;f
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08214v2 Announce Type: replace-cross  Abstract: Motivated by the need to analyze large, decentralized datasets, distributed Bayesian inference has become a critical research area across multiple fields, including statistics, electrical engineering, and economics. This paper establishes Frequentist properties, such as posterior consistency, asymptotic normality, and posterior contraction rates, for the distributed (non-)Bayes Inference problem among agents connected via a communication network. Our results show that, under appropriate assumptions on the communication graph, distributed Bayesian inference retains parametric efficiency while enhancing robustness in uncertainty quantification. We also explore the trade-off between statistical efficiency and communication efficiency by examining how the design and size of the communication graph impact the posterior contraction rate. Furthermore, We extend our analysis to time-varying graphs and apply our results to exponential f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#22238;&#24402;&#26041;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#26354;&#32447;&#65292;&#23545;&#26680;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#21644;&#20854;&#20182;&#20998;&#26512;&#35889;&#31639;&#27861;&#22312;&#26680;&#22238;&#24402;&#20013;&#30340;&#27867;&#21270;&#35823;&#24046;&#36827;&#34892;&#20102;&#20840;&#38754;&#29305;&#24449;&#21270;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#23545;&#35757;&#32451;&#23485;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#34892;&#20026;&#30340;&#29702;&#35299;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#36129;&#29486;-&#20998;&#26512;&#21151;&#33021;&#35770;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.01599</link><description>&lt;p&gt;
&#20998;&#26512;&#35889;&#31639;&#27861;&#22312;&#24130;&#24459;&#34928;&#20943;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Generalization Error Curves for Analytic Spectral Algorithms under Power-law Decay. (arXiv:2401.01599v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#22238;&#24402;&#26041;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#26354;&#32447;&#65292;&#23545;&#26680;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#21644;&#20854;&#20182;&#20998;&#26512;&#35889;&#31639;&#27861;&#22312;&#26680;&#22238;&#24402;&#20013;&#30340;&#27867;&#21270;&#35823;&#24046;&#36827;&#34892;&#20102;&#20840;&#38754;&#29305;&#24449;&#21270;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#23545;&#35757;&#32451;&#23485;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#34892;&#20026;&#30340;&#29702;&#35299;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#36129;&#29486;-&#20998;&#26512;&#21151;&#33021;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26576;&#20123;&#26680;&#22238;&#24402;&#26041;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#26354;&#32447;&#26088;&#22312;&#30830;&#23450;&#22312;&#19981;&#21516;&#28304;&#26465;&#20214;&#12289;&#22122;&#22768;&#27700;&#24179;&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;&#36873;&#25321;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#30830;&#20999;&#39034;&#24207;&#65292;&#32780;&#19981;&#26159;&#26368;&#23567;&#21270;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20005;&#26684;&#32473;&#20986;&#20102;&#26680;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65288;&#20197;&#21450;&#22823;&#31867;&#20998;&#26512;&#35889;&#31639;&#27861;&#65289;&#22312;&#26680;&#22238;&#24402;&#20013;&#30340;&#27867;&#21270;&#35823;&#24046;&#26354;&#32447;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21487;&#20197;&#25552;&#39640;&#26680;&#25554;&#20540;&#30340;&#36817;&#19981;&#19968;&#33268;&#24615;&#65292;&#24182;&#28548;&#28165;&#20855;&#26377;&#26356;&#39640;&#36164;&#26684;&#30340;&#26680;&#22238;&#24402;&#31639;&#27861;&#30340;&#39281;&#21644;&#25928;&#24212;&#65292;&#31561;&#31561;&#12290;&#30001;&#20110;&#31070;&#32463;&#20999;&#32447;&#26680;&#29702;&#35770;&#30340;&#24110;&#21161;&#65292;&#36825;&#20123;&#32467;&#26524;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#25105;&#20204;&#23545;&#35757;&#32451;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#34892;&#20026;&#30340;&#29702;&#35299;&#12290;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#36129;&#29486;&#65292;&#21363;&#20998;&#26512;&#21151;&#33021;&#35770;&#35777;&#65292;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generalization error curve of certain kernel regression method aims at determining the exact order of generalization error with various source condition, noise level and choice of the regularization parameter rather than the minimax rate. In this work, under mild assumptions, we rigorously provide a full characterization of the generalization error curves of the kernel gradient descent method (and a large class of analytic spectral algorithms) in kernel regression. Consequently, we could sharpen the near inconsistency of kernel interpolation and clarify the saturation effects of kernel regression algorithms with higher qualification, etc. Thanks to the neural tangent kernel theory, these results greatly improve our understanding of the generalization behavior of training the wide neural networks. A novel technical contribution, the analytic functional argument, might be of independent interest.
&lt;/p&gt;</description></item></channel></rss>