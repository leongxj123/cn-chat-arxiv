<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.01111</link><description>&lt;p&gt;
&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#22312;MCMC&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Theoretical guarantees for neural control variates in MCMC. (arXiv:2304.01111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#24615;&#25511;&#21046;&#21464;&#37327;&#21644;&#26368;&#23567;&#21270;&#28176;&#36817;&#26041;&#24046;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#25511;&#21046;&#21464;&#37327;&#34920;&#31034;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#23450;&#24773;&#20917;&#12290;&#22312;&#22522;&#30784;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#65292;&#25512;&#23548;&#20102;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#21644;&#20989;&#25968;&#36924;&#36817;&#29702;&#35770;&#30340;&#38543;&#26426;&#35823;&#24046;&#30340;&#26368;&#26032;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a variance reduction approach for Markov chains based on additive control variates and the minimization of an appropriate estimate for the asymptotic variance. We focus on the particular case when control variates are represented as deep neural networks. We derive the optimal convergence rate of the asymptotic variance under various ergodicity assumptions on the underlying Markov chain. The proposed approach relies upon recent results on the stochastic errors of variance reduction algorithms and function approximation theory.
&lt;/p&gt;</description></item></channel></rss>