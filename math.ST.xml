<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#20998;&#24067;&#40065;&#26834;&#24615;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#27169;&#22411;&#31639;&#27861;&#24182;&#24314;&#31435;&#20102;&#20854;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#65292;&#33021;&#22312;&#39640;&#32500;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#25552;&#39640;&#23398;&#20064;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.12946</link><description>&lt;p&gt;
&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31163;&#32447;&#20998;&#24067;&#40065;&#26834;&#24615;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Offline Distributionally Robust Linear Markov Decision Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#20998;&#24067;&#40065;&#26834;&#24615;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#27169;&#22411;&#31639;&#27861;&#24182;&#24314;&#31435;&#20102;&#20854;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#65292;&#33021;&#22312;&#39640;&#32500;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#25552;&#39640;&#23398;&#20064;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#65292;&#32570;&#20047;&#31215;&#26497;&#25506;&#32034;&#38656;&#35201;&#20851;&#27880;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#20197;&#35299;&#20915;&#27169;&#25311;&#21644;&#37096;&#32626;&#29615;&#22659;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#20854;&#20013;&#27169;&#25311;&#21644;&#23454;&#38469;&#29615;&#22659;&#20043;&#38388;&#30340;&#24046;&#24322;&#21487;&#33021;&#20005;&#37325;&#25439;&#23475;&#23398;&#20064;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#20197;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#36171;&#20104;&#23398;&#20064;&#31574;&#30053;&#22312;&#39640;&#32500;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#30340;&#40065;&#26834;&#24615;&#65292;&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#31163;&#32447;&#25968;&#25454;&#65292;&#36890;&#36807;&#24635;&#21464;&#24046;&#36317;&#31163;&#34920;&#24449;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#65292;&#20998;&#24067;&#40065;&#26834;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#24754;&#35266;&#27169;&#22411;&#31639;&#27861;&#65292;&#24182;&#22312;&#26368;&#23567;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#20854;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#65292;&#20854;&#24615;&#33021;&#33267;&#23569;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#20248;&#20110;$\tilde{O}(d)$&#65292;&#20854;&#20013;$d$&#26159;&#29305;&#24449;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12946v1 Announce Type: new  Abstract: In offline reinforcement learning (RL), the absence of active exploration calls for attention on the model robustness to tackle the sim-to-real gap, where the discrepancy between the simulated and deployed environments can significantly undermine the performance of the learned policy. To endow the learned policy with robustness in a sample-efficient manner in the presence of high-dimensional state-action space, this paper considers the sample complexity of distributionally robust linear Markov decision processes (MDPs) with an uncertainty set characterized by the total variation distance using offline data. We develop a pessimistic model-based algorithm and establish its sample complexity bound under minimal data coverage assumptions, which outperforms prior art by at least $\tilde{O}(d)$, where $d$ is the feature dimension. We further improve the performance guarantee of the proposed algorithm by incorporating a carefully-designed varia
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#38169;&#37197;&#30340;Copula&#27169;&#22411;&#20013;&#38480;&#21046;&#21453;&#39304;&#30340;&#21098;&#20999;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#21482;&#26377;&#19968;&#20010;&#27169;&#22359;&#38169;&#37197;&#30340;&#24773;&#20917;&#19979;&#65292;&#36866;&#24403;&#30340;&#21098;&#20999;&#21518;&#39564;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.03521</link><description>&lt;p&gt;
&#22312;&#38169;&#37197;&#30340;Copula&#27169;&#22411;&#20013;&#38480;&#21046;&#21453;&#39304;&#30340;&#21098;&#20999;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Cutting Feedback in Misspecified Copula Models. (arXiv:2310.03521v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03521
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#38169;&#37197;&#30340;Copula&#27169;&#22411;&#20013;&#38480;&#21046;&#21453;&#39304;&#30340;&#21098;&#20999;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#21482;&#26377;&#19968;&#20010;&#27169;&#22359;&#38169;&#37197;&#30340;&#24773;&#20917;&#19979;&#65292;&#36866;&#24403;&#30340;&#21098;&#20999;&#21518;&#39564;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;Copula&#27169;&#22411;&#20013;&#65292;&#36793;&#32536;&#20998;&#24067;&#21644;Copula&#20989;&#25968;&#34987;&#20998;&#21035;&#25351;&#23450;&#12290;&#25105;&#20204;&#23558;&#23427;&#20204;&#35270;&#20026;&#27169;&#22359;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#26694;&#26550;&#20013;&#30340;&#20004;&#20010;&#27169;&#22359;&#65292;&#24182;&#25552;&#20986;&#36890;&#36807;&#8220;&#21098;&#20999;&#21453;&#39304;&#8221;&#36827;&#34892;&#20462;&#25913;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;&#21098;&#20999;&#21453;&#39304;&#38480;&#21046;&#20102;&#21518;&#39564;&#25512;&#26029;&#20013;&#28508;&#22312;&#38169;&#37197;&#27169;&#22359;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#32771;&#34385;&#20004;&#31181;&#31867;&#22411;&#30340;&#21098;&#20999;&#26041;&#27861;&#12290;&#31532;&#19968;&#31181;&#38480;&#21046;&#20102;&#38169;&#37197;Copula&#23545;&#36793;&#32536;&#25512;&#26029;&#30340;&#24433;&#21709;&#65292;&#36825;&#26159;&#27969;&#34892;&#30340;&#36793;&#38469;&#25512;&#26029;&#65288;IFM&#65289;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#31867;&#20284;&#26041;&#27861;&#12290;&#31532;&#20108;&#31181;&#36890;&#36807;&#20351;&#29992;&#31209;&#20284;&#28982;&#23450;&#20041;&#21098;&#20999;&#27169;&#22411;&#26469;&#38480;&#21046;&#38169;&#37197;&#36793;&#32536;&#23545;Copula&#21442;&#25968;&#25512;&#26029;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#21482;&#26377;&#19968;&#20010;&#27169;&#22359;&#38169;&#37197;&#65292;&#37027;&#20040;&#36866;&#24403;&#30340;&#21098;&#20999;&#21518;&#39564;&#22312;&#21478;&#19968;&#20010;&#27169;&#22359;&#30340;&#21442;&#25968;&#30340;&#28176;&#36817;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#26159;&#20934;&#30830;&#30340;&#12290;&#35745;&#31639;&#21098;&#20999;&#21518;&#39564;&#24456;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In copula models the marginal distributions and copula function are specified separately. We treat these as two modules in a modular Bayesian inference framework, and propose conducting modified Bayesian inference by ``cutting feedback''. Cutting feedback limits the influence of potentially misspecified modules in posterior inference. We consider two types of cuts. The first limits the influence of a misspecified copula on inference for the marginals, which is a Bayesian analogue of the popular Inference for Margins (IFM) estimator. The second limits the influence of misspecified marginals on inference for the copula parameters by using a rank likelihood to define the cut model. We establish that if only one of the modules is misspecified, then the appropriate cut posterior gives accurate uncertainty quantification asymptotically for the parameters in the other module. Computation of the cut posteriors is difficult, and new variational inference methods to do so are proposed. The effic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#23436;&#20840;&#36981;&#23432;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#65292;&#26681;&#25454;"&#21305;&#37197;&#23545;"&#30830;&#23450;&#27835;&#30103;&#29366;&#24577;&#30340;&#23616;&#37096;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#26497;&#38480;&#26041;&#24046;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2307.13094</link><description>&lt;p&gt;
&#21305;&#37197;&#23545;&#21644;&#19981;&#23436;&#20840;&#36981;&#23432;&#19979;&#30340;&#23454;&#39564;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference in Experiments with Matched Pairs and Imperfect Compliance. (arXiv:2307.13094v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#23436;&#20840;&#36981;&#23432;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#65292;&#26681;&#25454;"&#21305;&#37197;&#23545;"&#30830;&#23450;&#27835;&#30103;&#29366;&#24577;&#30340;&#23616;&#37096;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#26497;&#38480;&#26041;&#24046;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#23436;&#20840;&#36981;&#23432;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#65292;&#26681;&#25454;&#8220;&#21305;&#37197;&#23545;&#8221;&#30830;&#23450;&#27835;&#30103;&#29366;&#24577;&#30340;&#23616;&#37096;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#25512;&#26029;&#12290;&#36890;&#36807;&#8220;&#21305;&#37197;&#23545;&#8221;&#65292;&#25105;&#20204;&#25351;&#30340;&#26159;&#20174;&#24863;&#20852;&#36259;&#30340;&#24635;&#20307;&#20013;&#29420;&#31435;&#21644;&#38543;&#26426;&#25277;&#21462;&#21333;&#20301;&#65292;&#26681;&#25454;&#35266;&#23519;&#21040;&#30340;&#22522;&#32447;&#21327;&#21464;&#37327;&#36827;&#34892;&#37197;&#23545;&#65292;&#28982;&#21518;&#22312;&#27599;&#20010;&#23545;&#20013;&#65292;&#38543;&#26426;&#36873;&#25321;&#19968;&#20010;&#21333;&#20301;&#36827;&#34892;&#27835;&#30103;&#12290;&#22312;&#23545;&#21305;&#37197;&#36136;&#37327;&#36827;&#34892;&#30340;&#24369;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;&#20256;&#32479;&#30340;Wald&#65288;&#21363;&#20108;&#38454;&#26368;&#23567;&#20108;&#20056;&#65289;&#20272;&#35745;&#22120;&#30340;&#23616;&#37096;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#26497;&#38480;&#34892;&#20026;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#26174;&#31034;&#65292;&#20256;&#32479;&#30340;&#24322;&#26041;&#24046;&#24615;&#31283;&#20581;&#20272;&#35745;&#22120;&#30340;&#26497;&#38480;&#26041;&#24046;&#36890;&#24120;&#26159;&#20445;&#23432;&#30340;&#65292;&#21363;&#20854;&#21487;&#33021;&#24615;&#26497;&#38480;&#27604;&#26497;&#38480;&#26041;&#24046;&#65288;&#36890;&#24120;&#20005;&#26684;&#22320;&#65289;&#22823;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#23545;&#25152;&#38656;&#25968;&#37327;&#19968;&#33268;&#30340;&#26497;&#38480;&#26041;&#24046;&#30340;&#26367;&#20195;&#20272;&#35745;&#22120;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#39069;&#22806;&#35266;&#23519;&#21040;&#30340;&#22522;&#32447;&#21327;&#21464;&#37327;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies inference for the local average treatment effect in randomized controlled trials with imperfect compliance where treatment status is determined according to "matched pairs." By "matched pairs," we mean that units are sampled i.i.d. from the population of interest, paired according to observed, baseline covariates and finally, within each pair, one unit is selected at random for treatment. Under weak assumptions governing the quality of the pairings, we first derive the limiting behavior of the usual Wald (i.e., two-stage least squares) estimator of the local average treatment effect. We show further that the conventional heteroskedasticity-robust estimator of its limiting variance is generally conservative in that its limit in probability is (typically strictly) larger than the limiting variance. We therefore provide an alternative estimator of the limiting variance that is consistent for the desired quantity. Finally, we consider the use of additional observed, base
&lt;/p&gt;</description></item></channel></rss>