<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#21644;&#24191;&#20041;&#20307;&#31215;&#21462;&#26679;&#36827;&#34892;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24191;&#20041;&#29256;&#26412;&#30340;&#20307;&#31215;&#26631;&#20934;&#21270;&#21462;&#26679;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#22312;&#26399;&#26395;&#19978;&#30340;&#20934;&#26368;&#20248;&#24615;&#20197;&#21450;&#22312;&#26576;&#20123;&#35268;&#33539;&#21521;&#37327;&#31354;&#38388;&#20013;&#30340;&#36924;&#36817;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2312.14057</link><description>&lt;p&gt;
&#22522;&#20110;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#21644;&#24191;&#20041;&#20307;&#31215;&#21462;&#26679;&#30340;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Weighted least-squares approximation with determinantal point processes and generalized volume sampling. (arXiv:2312.14057v2 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14057
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#21644;&#24191;&#20041;&#20307;&#31215;&#21462;&#26679;&#36827;&#34892;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24191;&#20041;&#29256;&#26412;&#30340;&#20307;&#31215;&#26631;&#20934;&#21270;&#21462;&#26679;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#22312;&#26399;&#26395;&#19978;&#30340;&#20934;&#26368;&#20248;&#24615;&#20197;&#21450;&#22312;&#26576;&#20123;&#35268;&#33539;&#21521;&#37327;&#31354;&#38388;&#20013;&#30340;&#36924;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#32473;&#23450;&#30340;m&#32500;&#31354;&#38388;V_m&#20013;&#30340;&#20803;&#32032;&#65292;&#20511;&#21161;&#20110;&#19968;&#20123;&#29305;&#24449;&#26144;&#23556;&#966;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#28857;x_1&#65292;...&#65292;x_n&#22788;&#30340;&#20989;&#25968;&#36827;&#34892;&#35780;&#20272;&#65292;&#26469;&#36924;&#36817;&#20989;&#25968;&#20174;L^2&#21040;&#20989;&#25968;&#12290;&#22312;&#22238;&#39038;&#19968;&#20123;&#20851;&#20110;&#20351;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#28857;&#30340;&#26368;&#20248;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#30340;&#32467;&#26524;&#20043;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25237;&#24433;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#65288;DPP&#65289;&#25110;&#20307;&#31215;&#21462;&#26679;&#30340;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#12290;&#36825;&#20123;&#20998;&#24067;&#22312;&#36873;&#23450;&#30340;&#29305;&#24449;&#966;(x_i)&#20013;&#24341;&#20837;&#20102;&#28857;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#65292;&#20197;&#20419;&#36827;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#24191;&#20041;&#29256;&#26412;&#30340;&#20307;&#31215;&#26631;&#20934;&#21270;&#21462;&#26679;&#65292;&#20351;&#29992;&#26679;&#26412;&#25968;n = O(mlog(m))&#24471;&#21040;&#20102;&#26399;&#26395;&#19978;&#30340;&#20934;&#26368;&#20248;&#32467;&#26524;&#65292;&#36825;&#24847;&#21619;&#30528;&#26399;&#26395;&#30340;L^2&#35823;&#24046;&#21463;&#21040;&#19968;&#20010;&#24120;&#25968;&#20056;&#20197;&#22312;L^2&#20013;&#30340;&#26368;&#20339;&#36924;&#36817;&#35823;&#24046;&#30340;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#36827;&#19968;&#27493;&#20551;&#35774;&#20989;&#25968;&#22312;&#26576;&#20010;&#23884;&#20837;&#22312;L^2&#20013;&#30340;&#35268;&#33539;&#21521;&#37327;&#31354;&#38388;H&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#36924;&#36817;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of approximating a function from $L^2$ by an element of a given $m$-dimensional space $V_m$, associated with some feature map $\varphi$, using evaluations of the function at random points $x_1,\dots,x_n$. After recalling some results on optimal weighted least-squares using independent and identically distributed points, we consider weighted least-squares using projection determinantal point processes (DPP) or volume sampling. These distributions introduce dependence between the points that promotes diversity in the selected features $\varphi(x_i)$. We first provide a generalized version of volume-rescaled sampling yielding quasi-optimality results in expectation with a number of samples $n = O(m\log(m))$, that means that the expected $L^2$ error is bounded by a constant times the best approximation error in $L^2$. Also, further assuming that the function is in some normed vector space $H$ continuously embedded in $L^2$, we further prove that the approximation is
&lt;/p&gt;</description></item></channel></rss>