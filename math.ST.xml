<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;</title><link>https://arxiv.org/abs/2403.07735</link><description>&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;
&lt;/p&gt;
&lt;p&gt;
The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07735
&lt;/p&gt;
&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kernel&#25216;&#26415;&#26159;&#25968;&#25454;&#31185;&#23398;&#21644;&#32479;&#35745;&#23398;&#20013;&#26368;&#26377;&#24433;&#21709;&#21147;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#19982;&#26680;&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33021;&#22815;&#32534;&#30721;$M\ge 2$&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#12290;&#22312;&#26680;&#19978;&#20381;&#36182;&#30340;&#26368;&#26222;&#36941;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#21487;&#33021;&#26159;&#25152;&#35859;&#30340;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;(HSIC; &#22312;&#32479;&#35745;&#25991;&#29486;&#20013;&#20063;&#31216;&#20026;&#36317;&#31163;&#21327;&#26041;&#24046;)&#12290;&#23613;&#31649;&#33258;&#36817;&#20108;&#21313;&#24180;&#21069;&#24341;&#20837;&#20197;&#26469;&#24050;&#32463;&#26377;&#21508;&#31181;&#29616;&#26377;&#30340;&#35774;&#35745;&#30340;HSIC&#20272;&#35745;&#37327;&#65292;HSIC&#21487;&#20197;&#34987;&#20272;&#35745;&#30340;&#36895;&#24230;&#30340;&#22522;&#26412;&#38382;&#39064;&#20173;&#28982;&#26159;&#24320;&#25918;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#21253;&#21547;&#20855;&#26377;&#36830;&#32493;&#26377;&#30028;&#24179;&#31227;&#19981;&#21464;&#29305;&#24449;&#26680;&#30340;&#39640;&#26031;Borel&#27979;&#24230;&#22312;$\mathbb R^d$&#19978;&#30340;HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#26368;&#20248;&#36895;&#29575;&#26159;$\mathcal O\!\left(n^{-1/2}\right)$&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#35768;&#22810;&#26041;&#38754;&#22312;&#26497;&#23567;&#21270;&#24847;&#20041;&#19978;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07735v1 Announce Type: cross  Abstract: Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the optimality in the minimax sense of many 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#22810;&#20803;&#22238;&#24402;&#30340;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;&#65292;&#36890;&#36807;&#20248;&#21270;D-&#26368;&#20248;&#20934;&#21017;&#30340;&#27835;&#30103;&#27010;&#29575;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#20998;&#37197;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#30340;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2202.10030</link><description>&lt;p&gt;
&#22810;&#20803;&#21270;&#30340;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Multivariate Tie-breaker Designs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.10030
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#22810;&#20803;&#22238;&#24402;&#30340;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;&#65292;&#36890;&#36807;&#20248;&#21270;D-&#26368;&#20248;&#20934;&#21017;&#30340;&#27835;&#30103;&#27010;&#29575;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#20998;&#37197;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;&#65288;TBD&#65289;&#20013;&#65292;&#20855;&#26377;&#19968;&#23450;&#39640;&#20540;&#30340;&#36816;&#34892;&#21464;&#37327;&#30340;&#21463;&#35797;&#32773;&#25509;&#21463;&#26576;&#31181;&#65288;&#36890;&#24120;&#26159;&#29702;&#24819;&#30340;&#65289;&#27835;&#30103;&#65292;&#20302;&#20540;&#30340;&#21463;&#35797;&#32773;&#19981;&#25509;&#21463;&#27835;&#30103;&#65292;&#32780;&#20013;&#38388;&#30340;&#21463;&#35797;&#32773;&#34987;&#38543;&#26426;&#20998;&#37197;&#12290; TBD&#20171;&#20110;&#22238;&#24402;&#26029;&#28857;&#35774;&#35745;&#65288;RDD&#65289;&#21644;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCT&#65289;&#20043;&#38388;&#65292;&#36890;&#36807;&#20801;&#35768;&#22312;RDD&#30340;&#36164;&#28304;&#20998;&#37197;&#25928;&#29575;&#19982;RCT&#30340;&#32479;&#35745;&#25928;&#29575;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290; &#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#20854;&#20013;&#34987;&#27835;&#30103;&#21463;&#35797;&#32773;&#30340;&#39044;&#26399;&#21453;&#24212;&#26159;&#19968;&#20010;&#22810;&#20803;&#22238;&#24402;&#65292;&#32780;&#23545;&#29031;&#21463;&#35797;&#32773;&#21017;&#26159;&#21478;&#19968;&#20010;&#12290; &#23545;&#20110;&#32473;&#23450;&#30340;&#21327;&#21464;&#37327;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#20984;&#20248;&#21270;&#26469;&#36873;&#25321;&#20248;&#21270;D-&#26368;&#20248;&#20934;&#21017;&#30340;&#27835;&#30103;&#27010;&#29575;&#12290; &#25105;&#20204;&#21487;&#20197;&#32467;&#21512;&#22810;&#31181;&#21463;&#32463;&#27982;&#21644;&#20262;&#29702;&#32771;&#34385;&#28608;&#21457;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290; &#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;&#23545;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;D-&#26368;&#20248;&#24615;&#19982;&#25972;&#20307;&#22238;&#24402;&#30340;D-&#26368;&#20248;&#24615;&#37325;&#21512;&#65292;&#22312;&#27809;&#26377;&#32463;&#27982;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;RCT&#21363;&#20026;&#26368;&#20248;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.10030v4 Announce Type: replace-cross  Abstract: In a tie-breaker design (TBD), subjects with high values of a running variable are given some (usually desirable) treatment, subjects with low values are not, and subjects in the middle are randomized. TBDs are intermediate between regression discontinuity designs (RDDs) and randomized controlled trials (RCTs) by allowing a tradeoff between the resource allocation efficiency of an RDD and the statistical efficiency of an RCT. We study a model where the expected response is one multivariate regression for treated subjects and another for control subjects. For given covariates, we show how to use convex optimization to choose treatment probabilities that optimize a D-optimality criterion. We can incorporate a variety of constraints motivated by economic and ethical considerations. In our model, D-optimality for the treatment effect coincides with D-optimality for the whole regression, and without economic constraints, an RCT is g
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.06198</link><description>&lt;p&gt;
&#20811;&#26381;&#24322;&#26041;&#24046;PCA&#20013;&#30149;&#24577;&#38382;&#39064;&#30340;&#32553;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA. (arXiv:2303.06198v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel algorithm, called Deflated-HeteroPCA, that overcomes the curse of ill-conditioning in heteroskedastic PCA while achieving near-optimal and condition-number-free theoretical guarantees.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#20174;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;X*&#30340;&#21015;&#23376;&#31354;&#38388;&#12290;&#24403;&#23384;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#21644;&#19981;&#24179;&#34913;&#30340;&#32500;&#24230;&#65288;&#21363;n2 &gt;&gt; n1&#65289;&#26102;&#65292;&#22914;&#20309;&#22312;&#23481;&#32435;&#26368;&#24191;&#27867;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#30340;&#21516;&#26102;&#33719;&#24471;&#26368;&#20339;&#30340;&#32479;&#35745;&#31934;&#24230;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;HeteroPCA&#25104;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24378;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#36973;&#21463;&#20102;&#8220;&#30149;&#24577;&#38382;&#39064;&#30340;&#35781;&#21650;&#8221;&#65292;&#21363;&#38543;&#30528;X*&#30340;&#26465;&#20214;&#25968;&#22686;&#38271;&#65292;&#20854;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#32780;&#19981;&#24433;&#21709;&#20801;&#35768;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;$\ell_2$&#21644;$\ell_{2,\infty}$&#32479;&#35745;&#31934;&#24230;&#26041;&#38754;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23558;&#35889;&#20998;&#25104;&#20004;&#37096;&#20998;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;</title><link>http://arxiv.org/abs/2111.11694</link><description>&lt;p&gt;
MARS via LASSO.&#65288;arXiv:2111.11694v2 [math.ST] &#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
MARS via LASSO. (arXiv:2111.11694v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.11694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;Multivariate Adaptive Regression Splines&#65292;MARS&#65289;&#26159;Friedman&#22312;1991&#24180;&#25552;&#20986;&#30340;&#19968;&#31181;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;MARS&#23558;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#21644;&#38750;&#21152;&#24615;&#20989;&#25968;&#25311;&#21512;&#21040;&#22238;&#24402;&#25968;&#25454;&#19978;&#12290;&#26412;&#25991;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;MARS&#26041;&#27861;&#30340;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#36890;&#36807;&#32771;&#34385;MARS&#22522;&#30784;&#20989;&#25968;&#30340;&#26080;&#38480;&#32500;&#32447;&#24615;&#32452;&#21512;&#24182;&#24378;&#21152;&#22522;&#20110;&#21464;&#20998;&#30340;&#22797;&#26434;&#24230;&#32422;&#26463;&#26465;&#20214;&#26469;&#33719;&#24471;&#20989;&#25968;&#30340;&#20984;&#31867;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20272;&#35745;&#26159;&#23450;&#20041;&#20026;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#65292;&#20294;&#20854;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#32500;&#20984;&#20248;&#21270;&#26469;&#35745;&#31639;&#12290;&#22312;&#19968;&#20123;&#26631;&#20934;&#35774;&#35745;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20165;&#22312;&#32500;&#24230;&#19978;&#23545;&#25968;&#25910;&#25947;&#65292;&#22240;&#27492;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36991;&#20813;&#20102;&#36890;&#24120;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#22320;&#19982;&#22522;&#20110;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate adaptive regression splines (MARS) is a popular method for nonparametric regression introduced by Friedman in 1991. MARS fits simple nonlinear and non-additive functions to regression data. We propose and study a natural lasso variant of the MARS method. Our method is based on least squares estimation over a convex class of functions obtained by considering infinite-dimensional linear combinations of functions in the MARS basis and imposing a variation based complexity constraint. Our estimator can be computed via finite-dimensional convex optimization, although it is defined as a solution to an infinite-dimensional optimization problem. Under a few standard design assumptions, we prove that our estimator achieves a rate of convergence that depends only logarithmically on dimension and thus avoids the usual curse of dimensionality to some extent. We also show that our method is naturally connected to nonparametric estimation techniques based on smoothness constraints. We i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22996;&#25176;&#20154;&#23545;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#37096;&#20998;&#20102;&#35299;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#30340;&#35774;&#35745;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#22823;&#26368;&#23567;&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#26469;&#26368;&#22823;&#21270;&#22312;&#20195;&#29702;&#20154;&#20449;&#21495;&#20998;&#24067;&#30340;&#38598;&#21512;&#20013;&#26368;&#22351;&#24773;&#20917;&#19979;&#22238;&#25253;&#30340;&#22686;&#21152;&#12290;&#23545;&#20110;&#26377;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65307;&#23545;&#20110;&#26080;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#36924;&#36817;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2107.07420</link><description>&lt;p&gt;
&#37096;&#20998;&#30693;&#35782;&#19979;&#30340;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Scoring Rule Design under Partial Knowledge. (arXiv:2107.07420v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.07420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22996;&#25176;&#20154;&#23545;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#37096;&#20998;&#20102;&#35299;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#30340;&#35774;&#35745;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#22823;&#26368;&#23567;&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#26469;&#26368;&#22823;&#21270;&#22312;&#20195;&#29702;&#20154;&#20449;&#21495;&#20998;&#24067;&#30340;&#38598;&#21512;&#20013;&#26368;&#22351;&#24773;&#20917;&#19979;&#22238;&#25253;&#30340;&#22686;&#21152;&#12290;&#23545;&#20110;&#26377;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65307;&#23545;&#20110;&#26080;&#38480;&#38598;&#21512;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#36924;&#36817;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#22996;&#25176;&#20154;&#23545;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#37096;&#20998;&#20102;&#35299;&#26102;&#65292;&#26368;&#20248;&#36866;&#24403;&#25171;&#20998;&#35268;&#21017;&#30340;&#35774;&#35745;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#22312;&#22996;&#25176;&#20154;&#23436;&#20840;&#20102;&#35299;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#21487;&#20197;&#30830;&#23450;&#22686;&#21152;&#20195;&#29702;&#20154;&#22238;&#25253;&#30340;&#26368;&#22823;&#36866;&#24403;&#25171;&#20998;&#35268;&#21017;&#65292;&#24403;&#20195;&#29702;&#20154;&#36873;&#25321;&#35775;&#38382;&#26114;&#36149;&#20449;&#21495;&#20197;&#23436;&#21892;&#20854;&#20808;&#39564;&#39044;&#27979;&#30340;&#21518;&#39564;&#20449;&#24565;&#26102;&#12290;&#22312;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;&#65292;&#22996;&#25176;&#20154;&#21482;&#30693;&#36947;&#20195;&#29702;&#20154;&#30340;&#20449;&#21495;&#20998;&#24067;&#23646;&#20110;&#19968;&#32452;&#20998;&#24067;&#20013;&#30340;&#26576;&#20010;&#12290;&#25105;&#20204;&#23558;&#25171;&#20998;&#35268;&#21017;&#35774;&#35745;&#38382;&#39064;&#21046;&#23450;&#20026;&#26368;&#22823;&#26368;&#23567;&#20248;&#21270;&#38382;&#39064;&#65292;&#26368;&#22823;&#21270;&#20998;&#24067;&#38598;&#21512;&#20013;&#26368;&#22351;&#24773;&#20917;&#19979;&#22238;&#25253;&#30340;&#22686;&#21152;&#12290;&#24403;&#20998;&#24067;&#38598;&#21512;&#26377;&#38480;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#26368;&#20248;&#25171;&#20998;&#35268;&#21017;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#36924;&#36817;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#26080;&#38480;&#38598;&#21512;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25351;&#20986;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;&#25171;&#20998;&#35268;&#21017;&#65292;&#22914;&#20108;&#27425;&#26041;&#25171;&#20998;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the design of optimal proper scoring rules when the principal has partial knowledge of an agent's signal distribution. Recent work characterizes the proper scoring rules that maximize the increase of an agent's payoff when the agent chooses to access a costly signal to refine a posterior belief from her prior prediction, under the assumption that the agent's signal distribution is fully known to the principal. In our setting, the principal only knows about a set of distributions where the agent's signal distribution belongs. We formulate the scoring rule design problem as a max-min optimization that maximizes the worst-case increase in payoff across the set of distributions.  We propose an efficient algorithm to compute an optimal scoring rule when the set of distributions is finite, and devise a fully polynomial-time approximation scheme that accommodates various infinite sets of distributions. We further remark that widely used scoring rules, such as the quadratic 
&lt;/p&gt;</description></item></channel></rss>