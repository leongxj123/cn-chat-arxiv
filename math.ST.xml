<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#28176;&#21464;&#27969;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#31283;&#23450;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#39044;&#27979;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#65292;&#20197;&#35780;&#20272;&#27169;&#22411;&#30340;&#26222;&#36866;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08151</link><description>&lt;p&gt;
&#28176;&#21464;&#27969;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#29992;&#20110;sigmoid&#20998;&#31867;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation for sigmoidal classification models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#28176;&#21464;&#27969;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#31283;&#23450;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#39044;&#27979;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#65292;&#20197;&#35780;&#20272;&#27169;&#22411;&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#32452;&#26799;&#24230;&#27969;&#24341;&#23548;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;IS&#65289;&#21464;&#25442;&#65292;&#29992;&#20110;&#31283;&#23450;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#28857;&#32423;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#65288;LOO&#65289;&#39044;&#27979;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#12290;&#21487;&#20197;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#27169;&#22411;&#30340;&#26222;&#36866;&#24615;&#65292;&#20363;&#22914;&#35745;&#31639;&#19982;AIC&#31867;&#20284;&#30340;LOO&#25110;&#35745;&#31639;LOO ROC / PRC&#26354;&#32447;&#20197;&#21450;&#27966;&#29983;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#22914;AUROC&#21644;AUPRC&#12290;&#36890;&#36807;&#21464;&#20998;&#27861;&#21644;&#26799;&#24230;&#27969;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20004;&#20010;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#21333;&#27493;&#21464;&#25442;&#65292;&#21033;&#29992;&#26799;&#24230;&#20449;&#24687;&#23558;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#23436;&#25972;&#25968;&#25454;&#21518;&#39564;&#38752;&#36817;&#30446;&#26631;LOO&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#12290;&#36825;&#26679;&#65292;&#21464;&#25442;&#31283;&#23450;&#20102;&#37325;&#35201;&#24615;&#26435;&#37325;&#12290;&#22240;&#20026;&#21464;&#25442;&#28041;&#21450;&#21040;&#20284;&#28982;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#25152;&#20197;&#32467;&#26524;&#30340;&#33945;&#29305;&#21345;&#32599;&#31215;&#20998;&#20381;&#36182;&#20110;&#27169;&#22411;Hessian&#30340;Jacobian&#34892;&#21015;&#24335;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#36825;&#20123;Jacobian&#34892;&#21015;&#24335;&#30340;&#38381;&#21512;&#31934;&#30830;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a set of gradient-flow-guided adaptive importance sampling (IS) transformations to stabilize Monte-Carlo approximations of point-wise leave one out cross-validated (LOO) predictions for Bayesian classification models. One can leverage this methodology for assessing model generalizability by for instance computing a LOO analogue to the AIC or computing LOO ROC/PRC curves and derived metrics like the AUROC and AUPRC. By the calculus of variations and gradient flow, we derive two simple nonlinear single-step transformations that utilize gradient information to shift a model's pre-trained full-data posterior closer to the target LOO posterior predictive distributions. In doing so, the transformations stabilize importance weights. Because the transformations involve the gradient of the likelihood function, the resulting Monte Carlo integral depends on Jacobian determinants with respect to the model Hessian. We derive closed-form exact formulae for these Jacobian determinants in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.17329</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#22312;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kernel $\epsilon$-Greedy for Contextual Bandits. (arXiv:2306.17329v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17329
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#33218;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35748;&#20026;&#24179;&#22343;&#22870;&#21169;&#20989;&#25968;&#20301;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22870;&#21169;&#20989;&#25968;&#30340;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#12290;&#22312;&#23545;&#25506;&#32034;&#27010;&#29575;&#24207;&#21015;$\{\epsilon_t\}_t$&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;$\{\lambda_t\}_t$&#30340;&#19968;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#26680;&#21644;&#30456;&#24212;&#30340;RKHS&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#20381;&#36182;&#20110;RKHS&#20869;&#22312;&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;$\sqrt{T}$&#30340;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a kernelized version of the $\epsilon$-greedy strategy for contextual bandits. More precisely, in a setting with finitely many arms, we consider that the mean reward functions lie in a reproducing kernel Hilbert space (RKHS). We propose an online weighted kernel ridge regression estimator for the reward functions. Under some conditions on the exploration probability sequence, $\{\epsilon_t\}_t$, and choice of the regularization parameter, $\{\lambda_t\}_t$, we show that the proposed estimator is consistent. We also show that for any choice of kernel and the corresponding RKHS, we achieve a sub-linear regret rate depending on the intrinsic dimensionality of the RKHS. Furthermore, we achieve the optimal regret rate of $\sqrt{T}$ under a margin condition for finite-dimensional RKHS.
&lt;/p&gt;</description></item></channel></rss>