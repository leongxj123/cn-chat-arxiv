<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04691</link><description>&lt;p&gt;
&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23398;&#20064;&#31639;&#23376;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#30446;&#26631;&#31639;&#23376;&#30340;&#24369;&#21644;&#24378;&#35268;&#21017;&#26465;&#20214;&#65292;&#20197;&#25551;&#36848;&#20854;&#20869;&#22312;&#32467;&#26500;&#21644;&#22797;&#26434;&#24615;&#12290;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#65292;&#24182;&#36827;&#34892;&#20102;&#26497;&#23567;&#20540;&#19979;&#30028;&#20998;&#26512;&#65292;&#36827;&#19968;&#27493;&#35828;&#26126;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#21644;&#35268;&#21017;&#26465;&#20214;&#23450;&#37327;&#22320;&#21051;&#30011;&#20102;&#20351;&#29992;SGD&#31639;&#27861;&#35299;&#20915;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#12290;&#20540;&#24471;&#24378;&#35843;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#20173;&#28982;&#26377;&#25928;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SGD&#20272;&#35745;&#22120;&#23558;&#25910;&#25947;&#20110;&#38750;&#32447;&#24615;&#30446;&#26631;&#31639;&#23376;&#30340;&#26368;&#20339;&#32447;&#24615;&#36817;&#20284;&#12290;&#27492;&#22806;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#24212;&#29992;&#20110;&#22522;&#20110;&#30690;&#37327;&#20540;&#21644;&#23454;&#20540;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#65292;&#20135;&#29983;&#20102;&#26032;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#20174;&#32780;&#23436;&#21892;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates leveraging stochastic gradient descent (SGD) to learn operators between general Hilbert spaces. We propose weak and strong regularity conditions for the target operator to depict its intrinsic structure and complexity. Under these conditions, we establish upper bounds for convergence rates of the SGD algorithm and conduct a minimax lower bound analysis, further illustrating that our convergence analysis and regularity conditions quantitatively characterize the tractability of solving operator learning problems using the SGD algorithm. It is crucial to highlight that our convergence analysis is still valid for nonlinear operator learning. We show that the SGD estimator will converge to the best linear approximation of the nonlinear target operator. Moreover, applying our analysis to operator learning problems based on vector-valued and real-valued reproducing kernel Hilbert spaces yields new convergence results, thereby refining the conclusions of existing litera
&lt;/p&gt;</description></item><item><title>Hawkes&#36807;&#31243;&#30340;&#38271;&#26399;&#34892;&#20026;&#30001;&#23376;&#20107;&#20214;&#30340;&#24179;&#22343;&#25968;&#37327;&#21644;&#31163;&#25955;&#31243;&#24230;&#20915;&#23450;&#12290;&#23545;&#20110;&#20122;&#20020;&#30028;&#36807;&#31243;&#65292;&#25552;&#20379;&#20102;FLLNs&#21644;FCLTs&#65292;&#20855;&#20307;&#24418;&#24335;&#21462;&#20915;&#20110;&#23376;&#20107;&#20214;&#30340;&#31163;&#25955;&#31243;&#24230;&#12290;&#23545;&#20110;&#20855;&#26377;&#24369;&#31163;&#25955;&#23376;&#20107;&#20214;&#30340;&#20020;&#30028;Hawkes&#36807;&#31243;&#65292;&#19981;&#23384;&#22312;&#21151;&#33021;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#36890;&#36807;&#32553;&#25918;&#21518;&#30340;&#24378;&#24230;&#36807;&#31243;&#21644;&#32553;&#25918;&#21518;&#30340;Hawkes&#36807;&#31243;&#30340;&#20998;&#24067;&#19982;&#26497;&#38480;&#36807;&#31243;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#32473;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#20855;&#26377;&#39640;&#24230;&#31163;&#25955;&#23376;&#20107;&#20214;&#30340;&#20020;&#30028;Hawkes&#36807;&#31243;&#19982;&#20122;&#20020;&#30028;&#36807;&#31243;&#20849;&#20139;&#35768;&#22810;&#23646;&#24615;&#65292;&#21151;&#33021;&#26497;&#38480;&#23450;&#29702;&#25104;&#31435;&#12290;</title><link>http://arxiv.org/abs/2401.11495</link><description>&lt;p&gt;
Hawkes&#36807;&#31243;&#30340;&#21151;&#33021;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
Functional Limit Theorems for Hawkes Processes. (arXiv:2401.11495v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11495
&lt;/p&gt;
&lt;p&gt;
Hawkes&#36807;&#31243;&#30340;&#38271;&#26399;&#34892;&#20026;&#30001;&#23376;&#20107;&#20214;&#30340;&#24179;&#22343;&#25968;&#37327;&#21644;&#31163;&#25955;&#31243;&#24230;&#20915;&#23450;&#12290;&#23545;&#20110;&#20122;&#20020;&#30028;&#36807;&#31243;&#65292;&#25552;&#20379;&#20102;FLLNs&#21644;FCLTs&#65292;&#20855;&#20307;&#24418;&#24335;&#21462;&#20915;&#20110;&#23376;&#20107;&#20214;&#30340;&#31163;&#25955;&#31243;&#24230;&#12290;&#23545;&#20110;&#20855;&#26377;&#24369;&#31163;&#25955;&#23376;&#20107;&#20214;&#30340;&#20020;&#30028;Hawkes&#36807;&#31243;&#65292;&#19981;&#23384;&#22312;&#21151;&#33021;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#36890;&#36807;&#32553;&#25918;&#21518;&#30340;&#24378;&#24230;&#36807;&#31243;&#21644;&#32553;&#25918;&#21518;&#30340;Hawkes&#36807;&#31243;&#30340;&#20998;&#24067;&#19982;&#26497;&#38480;&#36807;&#31243;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#32473;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#20855;&#26377;&#39640;&#24230;&#31163;&#25955;&#23376;&#20107;&#20214;&#30340;&#20020;&#30028;Hawkes&#36807;&#31243;&#19982;&#20122;&#20020;&#30028;&#36807;&#31243;&#20849;&#20139;&#35768;&#22810;&#23646;&#24615;&#65292;&#21151;&#33021;&#26497;&#38480;&#23450;&#29702;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;Hawkes&#36807;&#31243;&#30340;&#38271;&#26399;&#34892;&#20026;&#23436;&#20840;&#30001;&#23376;&#20107;&#20214;&#30340;&#24179;&#22343;&#25968;&#37327;&#21644;&#31163;&#25955;&#31243;&#24230;&#30830;&#23450;&#12290;&#23545;&#20110;&#20122;&#20020;&#30028;&#36807;&#31243;&#65292;&#25105;&#20204;&#22312;&#36807;&#31243;&#30340;&#26680;&#20989;&#25968;&#30340;&#26368;&#23567;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;FLLNs&#21644;FCLTs&#65292;&#26497;&#38480;&#23450;&#29702;&#30340;&#20855;&#20307;&#24418;&#24335;&#20005;&#37325;&#21462;&#20915;&#20110;&#23376;&#20107;&#20214;&#30340;&#31163;&#25955;&#31243;&#24230;&#12290;&#23545;&#20110;&#20855;&#26377;&#24369;&#31163;&#25955;&#23376;&#20107;&#20214;&#30340;&#20020;&#30028;Hawkes&#36807;&#31243;&#65292;&#21151;&#33021;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#19981;&#25104;&#31435;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32463;&#36807;&#32553;&#25918;&#30340;&#24378;&#24230;&#36807;&#31243;&#21644;&#32463;&#36807;&#32553;&#25918;&#30340;Hawkes&#36807;&#31243;&#20998;&#21035;&#34892;&#20026;&#31867;&#20284;&#20110;&#26080;&#22343;&#20540;&#22238;&#24402;&#30340;CIR&#36807;&#31243;&#21644;&#25972;&#21512;&#30340;CIR&#36807;&#31243;&#12290;&#36890;&#36807;&#24314;&#31435;&#32553;&#25918;&#30340;Hawkes&#36807;&#31243;&#30340;&#20998;&#24067;&#19982;&#30456;&#24212;&#26497;&#38480;&#36807;&#31243;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#30456;&#21453;&#65292;&#20855;&#26377;&#39640;&#24230;&#31163;&#25955;&#23376;&#20107;&#20214;&#30340;&#20020;&#30028;Hawkes&#36807;&#31243;&#19982;&#20122;&#20020;&#30028;&#36807;&#31243;&#20849;&#20139;&#35768;&#22810;&#23646;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#21151;&#33021;&#26497;&#38480;&#23450;&#29702;&#25104;&#31435;&#12290;&#28982;&#32780;&#65292;&#19982;&#20122;&#20020;&#30028;&#36807;&#31243;&#19981;&#21516;&#30340;&#26159;&#65292;&#20122;&#20020;&#30028;&#36807;&#31243;&#27809;&#26377;&#31163;&#25955;&#23376;&#20107;&#20214;&#65292;&#20855;&#26377;&#24378;&#31163;&#25955;&#23376;&#20107;&#20214;&#30340;&#20020;&#30028;Hawkes&#36807;&#31243;&#27809;&#26377;&#21151;&#33021;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove that the long-run behavior of Hawkes processes is fully determined by the average number and the dispersion of child events. For subcritical processes we provide FLLNs and FCLTs under minimal conditions on the kernel of the process with the precise form of the limit theorems depending strongly on the dispersion of child events. For a critical Hawkes process with weakly dispersed child events, functional central limit theorems do not hold. Instead, we prove that the rescaled intensity processes and rescaled Hawkes processes behave like CIR-processes without mean-reversion, respectively integrated CIR-processes. We provide the rate of convergence by establishing an upper bound on the Wasserstein distance between the distributions of rescaled Hawkes process and the corresponding limit process. By contrast, critical Hawkes process with heavily dispersed child events share many properties of subcritical ones. In particular, functional limit theorems hold. However, unlike subcritica
&lt;/p&gt;</description></item></channel></rss>