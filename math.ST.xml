<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>Yurinskii&#30340;&#32806;&#21512;&#26041;&#27861;&#22312;$\ell^p$-&#33539;&#25968;&#19979;&#25552;&#20379;&#20102;&#26356;&#24369;&#26465;&#20214;&#19979;&#30340;&#36924;&#36817;&#39532;&#19969;&#26684;&#23572;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#26356;&#19968;&#33324;&#30340;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19977;&#38454;&#32806;&#21512;&#26041;&#27861;&#20197;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#32039;&#23494;&#30340;&#36924;&#36817;&#12290;</title><link>https://arxiv.org/abs/2210.00362</link><description>&lt;p&gt;
Yurinskii&#30340;&#39532;&#19969;&#26684;&#23572;&#32806;&#21512;
&lt;/p&gt;
&lt;p&gt;
Yurinskii's Coupling for Martingales
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.00362
&lt;/p&gt;
&lt;p&gt;
Yurinskii&#30340;&#32806;&#21512;&#26041;&#27861;&#22312;$\ell^p$-&#33539;&#25968;&#19979;&#25552;&#20379;&#20102;&#26356;&#24369;&#26465;&#20214;&#19979;&#30340;&#36924;&#36817;&#39532;&#19969;&#26684;&#23572;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#26356;&#19968;&#33324;&#30340;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19977;&#38454;&#32806;&#21512;&#26041;&#27861;&#20197;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#32039;&#23494;&#30340;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Yurinskii&#30340;&#32806;&#21512;&#26159;&#25968;&#23398;&#32479;&#35745;&#21644;&#24212;&#29992;&#27010;&#29575;&#20013;&#19968;&#31181;&#24120;&#29992;&#30340;&#38750;&#28176;&#36817;&#20998;&#24067;&#20998;&#26512;&#29702;&#35770;&#24037;&#20855;&#65292;&#25552;&#20379;&#20102;&#22312;&#26131;&#20110;&#39564;&#35777;&#26465;&#20214;&#19979;&#20855;&#26377;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#30340;&#39640;&#26031;&#24378;&#36924;&#36817;&#12290;&#26368;&#21021;&#22312;&#29420;&#31435;&#38543;&#26426;&#21521;&#37327;&#21644;&#20026;&#30340;$\ell^2$-&#33539;&#25968;&#20013;&#38472;&#36848;&#65292;&#26368;&#36817;&#24050;&#23558;&#20854;&#25193;&#23637;&#21040;$1 \leq p \leq \infty$&#26102;&#30340;$\ell^p$-&#33539;&#25968;&#65292;&#20197;&#21450;&#22312;&#26576;&#20123;&#24378;&#26465;&#20214;&#19979;&#30340;$\ell^2$-&#33539;&#25968;&#30340;&#21521;&#37327;&#20540;&#38789;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#22312;&#36828;&#27604;&#20043;&#21069;&#26045;&#21152;&#30340;&#26465;&#20214;&#26356;&#24369;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;$\ell^p$-&#33539;&#25968;&#19979;&#25552;&#20379;&#20102;&#36924;&#36817;&#39532;&#19969;&#26684;&#23572;&#30340;Yurinskii&#32806;&#21512;&#12290;&#25105;&#20204;&#30340;&#20844;&#24335;&#36827;&#19968;&#27493;&#20801;&#35768;&#32806;&#21512;&#21464;&#37327;&#36981;&#24490;&#26356;&#19968;&#33324;&#30340;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65292;&#24182;&#19988;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31532;&#19977;&#38454;&#32806;&#21512;&#26041;&#27861;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#36924;&#36817;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#19987;&#38376;&#24212;&#29992;&#20110;&#28151;&#21512;&#39532;&#19969;&#26684;&#23572;&#65292;&#39532;&#19969;&#26684;&#23572;&#21644;&#20854;&#20182;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.00362v2 Announce Type: replace-cross  Abstract: Yurinskii's coupling is a popular theoretical tool for non-asymptotic distributional analysis in mathematical statistics and applied probability, offering a Gaussian strong approximation with an explicit error bound under easily verified conditions. Originally stated in $\ell^2$-norm for sums of independent random vectors, it has recently been extended both to the $\ell^p$-norm, for $1 \leq p \leq \infty$, and to vector-valued martingales in $\ell^2$-norm, under some strong conditions. We present as our main result a Yurinskii coupling for approximate martingales in $\ell^p$-norm, under substantially weaker conditions than those previously imposed. Our formulation further allows for the coupling variable to follow a more general Gaussian mixture distribution, and we provide a novel third-order coupling method which gives tighter approximations in certain settings. We specialize our main result to mixingales, martingales, and in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.15878</link><description>&lt;p&gt;
&#20998;&#37197;&#31119;&#21033;&#30340;&#25919;&#31574;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Policy Learning with Distributional Welfare. (arXiv:2311.15878v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.15878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#12290;&#22823;&#37096;&#20998;&#20851;&#20110;&#27835;&#30103;&#36873;&#25321;&#30340;&#25991;&#29486;&#37117;&#32771;&#34385;&#20102;&#22522;&#20110;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#21151;&#21033;&#31119;&#21033;&#12290;&#34429;&#28982;&#24179;&#22343;&#31119;&#21033;&#26159;&#30452;&#35266;&#30340;&#65292;&#20294;&#22312;&#20010;&#20307;&#24322;&#36136;&#21270;&#65288;&#20363;&#22914;&#65292;&#23384;&#22312;&#31163;&#32676;&#20540;&#65289;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#20135;&#29983;&#19981;&#29702;&#24819;&#30340;&#20998;&#37197; - &#36825;&#27491;&#26159;&#20010;&#24615;&#21270;&#27835;&#30103;&#24341;&#20837;&#30340;&#21407;&#22240;&#20043;&#19968;&#12290;&#36825;&#20010;&#35266;&#23519;&#35753;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65288;QoTE&#65289;&#26469;&#20998;&#37197;&#27835;&#30103;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#26681;&#25454;&#20998;&#20301;&#25968;&#27010;&#29575;&#30340;&#36873;&#25321;&#65292;&#36825;&#20010;&#20934;&#21017;&#21487;&#20197;&#36866;&#24212;&#35880;&#24910;&#25110;&#31895;&#24515;&#30340;&#20915;&#31574;&#32773;&#12290;&#30830;&#23450;QoTE&#30340;&#25361;&#25112;&#22312;&#20110;&#20854;&#38656;&#35201;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#30340;&#32852;&#21512;&#20998;&#24067;&#26377;&#25152;&#20102;&#35299;&#65292;&#20294;&#21363;&#20351;&#20351;&#29992;&#23454;&#39564;&#25968;&#25454;&#65292;&#36890;&#24120;&#20063;&#24456;&#38590;&#24674;&#22797;&#20986;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore optimal treatment allocation policies that target distributional welfare. Most literature on treatment choice has considered utilitarian welfare based on the conditional average treatment effect (ATE). While average welfare is intuitive, it may yield undesirable allocations especially when individuals are heterogeneous (e.g., with outliers) - the very reason individualized treatments were introduced in the first place. This observation motivates us to propose an optimal policy that allocates the treatment based on the conditional quantile of individual treatment effects (QoTE). Depending on the choice of the quantile probability, this criterion can accommodate a policymaker who is either prudent or negligent. The challenge of identifying the QoTE lies in its requirement for knowledge of the joint distribution of the counterfactual outcomes, which is generally hard to recover even with experimental data. Therefore, we introduce minimax policies that are robust 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;</title><link>http://arxiv.org/abs/2306.08432</link><description>&lt;p&gt;
&#25209;&#27425;&#20351;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#23567;&#35268;&#33539;&#39118;&#38505;&#31283;&#23450;
&lt;/p&gt;
&lt;p&gt;
Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression. (arXiv:2306.08432v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#65292;&#36890;&#24120;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#24615;&#33021;&#20043;&#38388;&#25552;&#20379;&#26377;&#29992;&#30340;&#26435;&#34913;&#12290;&#26412;&#25991;&#36890;&#36807;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#29305;&#24449;&#30340;&#26368;&#23567;&#35268;&#33539;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#35270;&#35282;&#26469;&#30740;&#31350;&#25209;&#37327;&#20998;&#21306;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#24314;&#35758;&#26368;&#23567;&#35268;&#33539;&#20272;&#35745;&#37327;&#30340;&#33258;&#28982;&#23567;&#25209;&#37327;&#29256;&#26412;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#20108;&#27425;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#34920;&#26126;&#20854;&#19982;&#22122;&#22768;&#27700;&#24179;&#20197;&#21450;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#25104;&#21453;&#27604;&#65292;&#23545;&#20110;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#30340;&#36873;&#25321;&#12290;&#19982;&#26368;&#23567;&#35268;&#33539;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#31283;&#23450;&#30340;&#39118;&#38505;&#34892;&#20026;&#65292;&#20854;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#19978;&#21333;&#35843;&#36882;&#22686;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25209;&#22788;&#29702;&#25152;&#25552;&#20379;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#21487;&#20197;&#36890;&#36807;&#29305;&#24449;&#37325;&#21472;&#26469;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning algorithms that divide the data into batches are prevalent in many machine-learning applications, typically offering useful trade-offs between computational efficiency and performance. In this paper, we examine the benefits of batch-partitioning through the lens of a minimum-norm overparameterized linear regression model with isotropic Gaussian features. We suggest a natural small-batch version of the minimum-norm estimator, and derive an upper bound on its quadratic risk, showing it is inversely proportional to the noise level as well as to the overparameterization ratio, for the optimal choice of batch size. In contrast to minimum-norm, our estimator admits a stable risk behavior that is monotonically increasing in the overparameterization ratio, eliminating both the blowup at the interpolation point and the double-descent phenomenon. Interestingly, we observe that this implicit regularization offered by the batch partition is partially explained by feature overlap between t
&lt;/p&gt;</description></item></channel></rss>