<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#30693;&#36947;&#28304;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#39640;&#25928;&#22320;&#23558;&#26679;&#26412;&#20174;&#28304;&#27169;&#22411;&#36716;&#25442;&#20026;&#30446;&#26631;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#24402;&#32422;&#26041;&#27861;&#12290;&#36825;&#20123;&#24402;&#32422;&#26041;&#27861;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#30340;&#24212;&#29992;&#65292;&#21363;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.07717</link><description>&lt;p&gt;
&#19968;&#20123;&#32479;&#35745;&#27169;&#22411;&#20043;&#38388;&#30340;&#39640;&#25928;&#24402;&#32422;
&lt;/p&gt;
&lt;p&gt;
Efficient reductions between some statistical models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07717
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#30693;&#36947;&#28304;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#39640;&#25928;&#22320;&#23558;&#26679;&#26412;&#20174;&#28304;&#27169;&#22411;&#36716;&#25442;&#20026;&#30446;&#26631;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#24402;&#32422;&#26041;&#27861;&#12290;&#36825;&#20123;&#24402;&#32422;&#26041;&#27861;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#30340;&#24212;&#29992;&#65292;&#21363;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#30693;&#36947;&#28304;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36817;&#20284;&#22320;&#23558;&#26469;&#33258;&#28304;&#32479;&#35745;&#27169;&#22411;&#30340;&#26679;&#26412;&#36716;&#25442;&#20026;&#30446;&#26631;&#32479;&#35745;&#27169;&#22411;&#30340;&#26679;&#26412;&#30340;&#38382;&#39064;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#36825;&#31181;&#32479;&#35745;&#23454;&#39564;&#20043;&#38388;&#30340;&#24402;&#32422;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#31243;&#24207;&#65292;&#21487;&#20197;&#36817;&#20284;&#23558;&#22343;&#21248;&#20998;&#24067;&#12289;Erlang&#20998;&#24067;&#21644;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#30340;&#20301;&#32622;&#27169;&#22411;&#24402;&#32422;&#21040;&#19968;&#33324;&#30340;&#30446;&#26631;&#26063;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#19968;&#20123;&#32463;&#20856;&#30340;&#39640;&#32500;&#38382;&#39064;&#20043;&#38388;&#30340;&#38750;&#28176;&#36817;&#24402;&#32422;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24402;&#32422;&#20445;&#25345;&#20102;&#32467;&#26500;&#65292;&#24182;&#21487;&#20197;&#36866;&#24212;&#32570;&#22833;&#25968;&#25454;&#12290;&#25105;&#20204;&#36824;&#25351;&#20986;&#20102;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#30340;&#21487;&#33021;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of approximately transforming a sample from a source statistical model to a sample from a target statistical model without knowing the parameters of the source model, and construct several computationally efficient such reductions between statistical experiments. In particular, we provide computationally efficient procedures that approximately reduce uniform, Erlang, and Laplace location models to general target families. We illustrate our methodology by establishing nonasymptotic reductions between some canonical high-dimensional problems, spanning mixtures of experts, phase retrieval, and signal denoising. Notably, the reductions are structure preserving and can accommodate missing data. We also point to a possible application in transforming one differentially private mechanism to another.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#20110;&#21033;&#26222;&#24076;&#33576;&#21644; Sobolev &#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#32771;&#34385;&#20013;&#24515;&#38544;&#31169;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#30452;&#26041;&#22270;&#20272;&#35745;&#22120;&#22312; L2 &#39118;&#38505;&#19979;&#23545;&#20110;&#21033;&#26222;&#24076;&#33576;&#20998;&#24067;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#22312;&#27491;&#24120;&#24046;&#20998;&#38544;&#31169;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#65307;&#21516;&#26102;&#21457;&#29616;&#65292;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#26045;&#21152;&#38544;&#31169;&#20250;&#38477;&#20302;&#23545;&#20110; Sobolev &#23494;&#24230;&#30340;&#27491;&#21017;&#26497;&#23567;&#39118;&#38505;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#21457;&#29616;&#22312;&#32431;&#25237;&#24433;&#20272;&#35745;&#35774;&#23450;&#19979;&#65292;&#25152;&#35859;&#30340;&#25237;&#24433;&#20272;&#35745;&#22120;&#23545;&#20110;&#30456;&#21516;&#31867;&#23494;&#24230;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.14535</link><description>&lt;p&gt;
&#20851;&#20110;&#20013;&#24515;&#38544;&#31169;&#22312;&#23494;&#24230;&#20272;&#35745;&#20013;&#30340;&#25104;&#26412;
&lt;/p&gt;
&lt;p&gt;
About the Cost of Central Privacy in Density Estimation. (arXiv:2306.14535v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#20110;&#21033;&#26222;&#24076;&#33576;&#21644; Sobolev &#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#32771;&#34385;&#20013;&#24515;&#38544;&#31169;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#30452;&#26041;&#22270;&#20272;&#35745;&#22120;&#22312; L2 &#39118;&#38505;&#19979;&#23545;&#20110;&#21033;&#26222;&#24076;&#33576;&#20998;&#24067;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#22312;&#27491;&#24120;&#24046;&#20998;&#38544;&#31169;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#65307;&#21516;&#26102;&#21457;&#29616;&#65292;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#26045;&#21152;&#38544;&#31169;&#20250;&#38477;&#20302;&#23545;&#20110; Sobolev &#23494;&#24230;&#30340;&#27491;&#21017;&#26497;&#23567;&#39118;&#38505;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#21457;&#29616;&#22312;&#32431;&#25237;&#24433;&#20272;&#35745;&#35774;&#23450;&#19979;&#65292;&#25152;&#35859;&#30340;&#25237;&#24433;&#20272;&#35745;&#22120;&#23545;&#20110;&#30456;&#21516;&#31867;&#23494;&#24230;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#21033;&#26222;&#24076;&#33576;&#21644; Sobolev &#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#65292;&#22312;&#20013;&#24515;&#38544;&#31169;&#26465;&#20214;&#19979;&#36827;&#34892;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#38544;&#31169;&#39044;&#31639;&#19981;&#26159;&#24120;&#25968;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#32463;&#20856;&#30340;&#20013;&#24515;&#24046;&#20998;&#38544;&#31169;&#23450;&#20041;&#65292;&#20197;&#21450;&#36739;&#26032;&#30340;&#20013;&#24515;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#27010;&#24565;&#12290;&#25105;&#20204;&#35777;&#23454;&#20102; Barber &amp; Duchi (2014) &#30340;&#32467;&#26524;&#65292;&#21363;&#30452;&#26041;&#22270;&#20272;&#35745;&#22120;&#22312;&#23545;&#20110; L2 &#39118;&#38505;&#19979;&#23545;&#20110;&#21033;&#26222;&#24076;&#33576;&#20998;&#24067;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#22312;&#27491;&#24120;&#24046;&#20998;&#38544;&#31169;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#65292;&#25105;&#20204;&#23558;&#20854;&#25193;&#23637;&#21040;&#20854;&#20182;&#33539;&#25968;&#21644;&#38544;&#31169;&#27010;&#24565;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#26356;&#39640;&#31243;&#24230;&#30340;&#20809;&#28369;&#24615;&#65292;&#24471;&#20986;&#20004;&#20010;&#32467;&#35770;&#65306;&#39318;&#20808;&#65292;&#19982;&#24120;&#25968;&#38544;&#31169;&#39044;&#31639;&#38656;&#35201;&#30340;&#24773;&#20917;&#30456;&#21453;&#65288;Wasserman &amp;amp; Zhou, 2010&#65289;&#65292;&#22312; Sobolev &#23494;&#24230;&#19978;&#26045;&#21152;&#38544;&#31169;&#20250;&#38477;&#20302;&#27491;&#21017;&#26497;&#23567;&#39118;&#38505;&#20272;&#35745;&#12290;&#20854;&#27425;&#65292;&#22312;&#36825;&#31181;&#26032;&#30340;&#32431;&#25237;&#24433;&#20272;&#35745;&#35774;&#23450;&#19979;&#65292;&#25152;&#35859;&#30340;&#25237;&#24433;&#20272;&#35745;&#22120;&#23545;&#20110;&#30456;&#21516;&#31867;&#23494;&#24230;&#26159;&#20960;&#20046;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study non-parametric density estimation for densities in Lipschitz and Sobolev spaces, and under central privacy. In particular, we investigate regimes where the privacy budget is not supposed to be constant. We consider the classical definition of central differential privacy, but also the more recent notion of central concentrated differential privacy. We recover the result of Barber \&amp; Duchi (2014) stating that histogram estimators are optimal against Lipschitz distributions for the L2 risk, and under regular differential privacy, and we extend it to other norms and notions of privacy. Then, we investigate higher degrees of smoothness, drawing two conclusions: First, and contrary to what happens with constant privacy budget (Wasserman \&amp; Zhou, 2010), there are regimes where imposing privacy degrades the regular minimax risk of estimation on Sobolev densities. Second, so-called projection estimators are near-optimal against the same classes of densities in this new setup with pure
&lt;/p&gt;</description></item></channel></rss>