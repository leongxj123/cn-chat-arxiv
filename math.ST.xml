<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03820</link><description>&lt;p&gt;
&#22312;&#24102;&#26377;&#23574;&#23792;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Differentially Private PCA and Estimation for Spiked Covariance Matrices. (arXiv:2401.03820v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03820
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20195;&#32479;&#35745;&#23398;&#20013;&#65292;&#20272;&#35745;&#21327;&#26041;&#24046;&#30697;&#38453;&#21450;&#20854;&#30456;&#20851;&#30340;&#20027;&#25104;&#20998;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#23613;&#31649;&#24050;&#24320;&#21457;&#20986;&#20855;&#26377;&#33391;&#22909;&#24615;&#36136;&#30340;&#26368;&#20248;&#20272;&#35745;&#31243;&#24207;&#65292;&#20294;&#23545;&#38544;&#31169;&#20445;&#25252;&#30340;&#22686;&#21152;&#38656;&#27714;&#32473;&#36825;&#20010;&#32463;&#20856;&#38382;&#39064;&#24341;&#20837;&#20102;&#26032;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#12290;&#25105;&#20204;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#22312;&#35813;&#27169;&#22411;&#19979;&#29305;&#24449;&#20540;&#21644;&#29305;&#24449;&#21521;&#37327;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#20027;&#25104;&#20998;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26368;&#23567;&#26368;&#22823;&#25910;&#25947;&#29575;&#12290;&#36825;&#20123;&#25910;&#25947;&#29575;&#21253;&#25324;&#19968;&#33324;&#30340;Schatten&#33539;&#25968;&#65292;&#21253;&#25324;&#35889;&#33539;&#25968;&#65292;Frobenius&#33539;&#25968;&#21644;&#26680;&#33539;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#12290;&#21478;&#22806;&#65292;&#21305;&#37197;&#30340;minimax&#26368;&#23567;&#26368;&#22823;&#29575;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating a covariance matrix and its associated principal components is a fundamental problem in contemporary statistics. While optimal estimation procedures have been developed with well-understood properties, the increasing demand for privacy preservation introduces new complexities to this classical problem. In this paper, we study optimal differentially private Principal Component Analysis (PCA) and covariance estimation within the spiked covariance model.  We precisely characterize the sensitivity of eigenvalues and eigenvectors under this model and establish the minimax rates of convergence for estimating both the principal components and covariance matrix. These rates hold up to logarithmic factors and encompass general Schatten norms, including spectral norm, Frobenius norm, and nuclear norm as special cases.  We introduce computationally efficient differentially private estimators and prove their minimax optimality, up to logarithmic factors. Additionally, matching minimax l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#32780;&#26159;&#21033;&#29992;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#20248;&#21270;&#31574;&#30053;&#65292;&#22240;&#27492;&#33021;&#22815;&#36866;&#24212;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#28436;&#21464;&#21644;&#20542;&#21521;&#24615;&#20943;&#24369;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2212.09900</link><description>&lt;p&gt;
&#26080;&#20132;&#21472;&#31574;&#30053;&#23398;&#20064;&#65306;&#24754;&#35266;&#21644;&#24191;&#20041;&#32463;&#39564;Bernstein&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Policy learning "without'' overlap: Pessimism and generalized empirical Bernstein's inequality. (arXiv:2212.09900v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#32780;&#26159;&#21033;&#29992;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#20248;&#21270;&#31574;&#30053;&#65292;&#22240;&#27492;&#33021;&#22815;&#36866;&#24212;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#28436;&#21464;&#21644;&#20542;&#21521;&#24615;&#20943;&#24369;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#65292;&#26088;&#22312;&#21033;&#29992;&#20808;&#21069;&#25910;&#38598;&#21040;&#30340;&#35266;&#27979;&#65288;&#26469;&#33258;&#20110;&#22266;&#23450;&#30340;&#25110;&#26159;&#36866;&#24212;&#28436;&#21464;&#30340;&#34892;&#20026;&#31574;&#30053;&#65289;&#26469;&#23398;&#20064;&#32473;&#23450;&#31867;&#21035;&#20013;&#30340;&#26368;&#20248;&#20010;&#24615;&#21270;&#20915;&#31574;&#35268;&#21017;&#12290;&#29616;&#26377;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#21363;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#25506;&#32034;&#25152;&#26377;&#20010;&#24615;&#21270;&#29305;&#24449;&#30340;&#25152;&#26377;&#21160;&#20316;&#30340;&#20542;&#21521;&#24615;&#19979;&#30028;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#26368;&#22351;&#30340;&#20542;&#21521;&#24615;&#12290;&#30001;&#20110;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#19981;&#21463;&#25511;&#21046;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#20551;&#35774;&#21487;&#33021;&#19981;&#22826;&#29616;&#23454;&#65292;&#29305;&#21035;&#26159;&#24403;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#38543;&#26102;&#38388;&#28436;&#21464;&#24182;&#19988;&#20542;&#21521;&#24615;&#20943;&#24369;&#26102;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#23427;&#20248;&#21270;&#31574;&#30053;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#8212;&#8212;&#32780;&#19981;&#26159;&#28857;&#20272;&#35745;&#12290;LCBs&#36890;&#36807;&#37327;&#21270;&#22686;&#24378;&#20498;&#25968;&#20542;&#21521;&#26435;&#37325;&#30340;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#26469;&#26500;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies offline policy learning, which aims at utilizing observations collected a priori (from either fixed or adaptively evolving behavior policies) to learn the optimal individualized decision rule in a given class. Existing policy learning methods rely on a uniform overlap assumption, i.e., the propensities of exploring all actions for all individual characteristics are lower bounded in the offline dataset. In other words, the performance of these methods depends on the worst-case propensity in the offline dataset. As one has no control over the data collection process, this assumption can be unrealistic in many situations, especially when the behavior policies are allowed to evolve over time with diminishing propensities.  In this paper, we propose a new algorithm that optimizes lower confidence bounds (LCBs) -- instead of point estimates -- of the policy values. The LCBs are constructed by quantifying the estimation uncertainty of the augmented inverse propensity weight
&lt;/p&gt;</description></item></channel></rss>