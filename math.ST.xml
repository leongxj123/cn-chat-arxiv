<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#23545;&#40784;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#39640;&#27010;&#29575;&#24674;&#22797;&#27491;&#30830;&#30340;&#39030;&#28857;&#23545;&#40784;&#12290;&#36890;&#36807;&#29305;&#23450;&#30340;&#29305;&#24449;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#27700;&#24179;&#26465;&#20214;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19982;&#30452;&#25509;&#21305;&#37197;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>https://arxiv.org/abs/2402.07340</link><description>&lt;p&gt;
&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#38543;&#26426;&#20960;&#20309;&#22270;&#36827;&#34892;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Random Geometric Graph Alignment with Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07340
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#23545;&#40784;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#39640;&#27010;&#29575;&#24674;&#22797;&#27491;&#30830;&#30340;&#39030;&#28857;&#23545;&#40784;&#12290;&#36890;&#36807;&#29305;&#23450;&#30340;&#29305;&#24449;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#27700;&#24179;&#26465;&#20214;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19982;&#30452;&#25509;&#21305;&#37197;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39030;&#28857;&#29305;&#24449;&#20449;&#24687;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#23545;&#40784;&#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#32473;&#23450;&#20004;&#20010;&#29420;&#31435;&#25200;&#21160;&#30340;&#21333;&#20010;&#38543;&#26426;&#20960;&#20309;&#22270;&#20197;&#21450;&#22122;&#22768;&#31232;&#30095;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#65292;&#20219;&#21153;&#26159;&#24674;&#22797;&#20004;&#20010;&#22270;&#30340;&#39030;&#28857;&#20043;&#38388;&#30340;&#26410;&#30693;&#19968;&#23545;&#19968;&#26144;&#23556;&#20851;&#31995;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#29305;&#24449;&#21521;&#37327;&#30340;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#27700;&#24179;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#21333;&#23618;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#24456;&#39640;&#30340;&#27010;&#29575;&#19979;&#36890;&#36807;&#22270;&#32467;&#26500;&#26469;&#24674;&#22797;&#27491;&#30830;&#30340;&#39030;&#28857;&#23545;&#40784;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22122;&#22768;&#27700;&#24179;&#30340;&#26465;&#20214;&#19978;&#30028;&#65292;&#20165;&#23384;&#22312;&#23545;&#25968;&#22240;&#23376;&#24046;&#36317;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#19982;&#30452;&#25509;&#22312;&#22122;&#22768;&#39030;&#28857;&#29305;&#24449;&#19978;&#27714;&#35299;&#20998;&#37197;&#38382;&#39064;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#22122;&#22768;&#27700;&#24179;&#33267;&#23569;&#20026;&#24120;&#25968;&#26102;&#65292;&#36825;&#31181;&#30452;&#25509;&#21305;&#37197;&#20250;&#23548;&#33268;&#24674;&#22797;&#19981;&#23436;&#20840;&#65292;&#32780;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23481;&#24525;n
&lt;/p&gt;
&lt;p&gt;
We characterize the performance of graph neural networks for graph alignment problems in the presence of vertex feature information. More specifically, given two graphs that are independent perturbations of a single random geometric graph with noisy sparse features, the task is to recover an unknown one-to-one mapping between the vertices of the two graphs. We show under certain conditions on the sparsity and noise level of the feature vectors, a carefully designed one-layer graph neural network can with high probability recover the correct alignment between the vertices with the help of the graph structure. We also prove that our conditions on the noise level are tight up to logarithmic factors. Finally we compare the performance of the graph neural network to directly solving an assignment problem on the noisy vertex features. We demonstrate that when the noise level is at least constant this direct matching fails to have perfect recovery while the graph neural network can tolerate n
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#22343;&#20540;&#19979;&#30340;&#22823;&#32500;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#35777;&#26126;&#20102;&#20854;&#20108;&#27425;&#25910;&#25947;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26631;&#20934;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.07045</link><description>&lt;p&gt;
Ledoit-Wolf&#32447;&#24615;&#25910;&#32553;&#26041;&#27861;&#22312;&#26410;&#30693;&#22343;&#20540;&#30340;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;(arXiv:2304.07045v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
Ledoit-Wolf linear shrinkage with unknown mean. (arXiv:2304.07045v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#22343;&#20540;&#19979;&#30340;&#22823;&#32500;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#35777;&#26126;&#20102;&#20854;&#20108;&#27425;&#25910;&#25947;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26631;&#20934;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#26410;&#30693;&#22343;&#20540;&#19979;&#30340;&#22823;&#32500;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#12290;&#24403;&#32500;&#25968;&#21644;&#26679;&#26412;&#25968;&#25104;&#27604;&#20363;&#24182;&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#32463;&#39564;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#22833;&#25928;&#65292;&#27492;&#26102;&#31216;&#20026;Kolmogorov&#28176;&#36827;&#24615;&#12290;&#24403;&#22343;&#20540;&#24050;&#30693;&#26102;&#65292;Ledoit&#21644;Wolf&#65288;2004&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#32447;&#24615;&#25910;&#32553;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20123;&#28436;&#36827;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#24403;&#22343;&#20540;&#26410;&#30693;&#26102;&#65292;&#23578;&#26410;&#25552;&#20986;&#27491;&#24335;&#35777;&#26126;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#22312;Ledoit&#21644;Wolf&#30340;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#23427;&#30340;&#20108;&#27425;&#25910;&#25947;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#23427;&#32988;&#36807;&#20102;&#20854;&#20182;&#26631;&#20934;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work addresses large dimensional covariance matrix estimation with unknown mean. The empirical covariance estimator fails when dimension and number of samples are proportional and tend to infinity, settings known as Kolmogorov asymptotics. When the mean is known, Ledoit and Wolf (2004) proposed a linear shrinkage estimator and proved its convergence under those asymptotics. To the best of our knowledge, no formal proof has been proposed when the mean is unknown. To address this issue, we propose a new estimator and prove its quadratic convergence under the Ledoit and Wolf assumptions. Finally, we show empirically that it outperforms other standard estimators.
&lt;/p&gt;</description></item></channel></rss>