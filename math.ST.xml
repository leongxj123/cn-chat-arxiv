<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#20013;&#65292;&#36890;&#36807;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#19988;&#24615;&#33021;&#27604;&#36739;&#34920;&#26126;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.13232</link><description>&lt;p&gt;
Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#30340;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#21644;&#20266;&#20284;&#28982;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Interaction Screening and Pseudolikelihood Approaches for Tensor Learning in Ising Models. (arXiv:2310.13232v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#20013;&#65292;&#36890;&#36807;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#19988;&#24615;&#33021;&#27604;&#36739;&#34920;&#26126;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$k$-spin Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#24674;&#22797;&#20013;&#65292;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#20004;&#31181;&#24050;&#30693;&#30340;Ising&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#19979;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#25968;&#23545;&#25968;&#32423;&#21035;&#22823;&#23567;&#30340;&#26679;&#26412;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#19988;&#19982;&#26368;&#22823;&#30456;&#20114;&#20316;&#29992;&#24378;&#24230;&#21644;&#26368;&#22823;&#33410;&#28857;&#24230;&#25351;&#25968;&#32423;&#20381;&#36182;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#20132;&#20114;&#38454;&#25968;$k$&#30340;&#30830;&#20999;&#20851;&#31995;&#36827;&#34892;&#20102;&#36319;&#36394;&#65292;&#24182;&#20801;&#35768;$k$&#38543;&#26679;&#26412;&#25968;&#21644;&#33410;&#28857;&#25968;&#22686;&#38271;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#23545;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#27604;&#36739;&#35752;&#35770;&#65292;&#32467;&#26524;&#20063;&#26174;&#31034;&#20102;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#20043;&#38388;&#30340;&#25351;&#25968;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study two well known methods of Ising structure learning, namely the pseudolikelihood approach and the interaction screening approach, in the context of tensor recovery in $k$-spin Ising models. We show that both these approaches, with proper regularization, retrieve the underlying hypernetwork structure using a sample size logarithmic in the number of network nodes, and exponential in the maximum interaction strength and maximum node-degree. We also track down the exact dependence of the rate of tensor recovery on the interaction order $k$, that is allowed to grow with the number of samples and nodes, for both the approaches. Finally, we provide a comparative discussion of the performance of the two approaches based on simulation studies, which also demonstrate the exponential dependence of the tensor recovery rate on the maximum coupling strength.
&lt;/p&gt;</description></item></channel></rss>