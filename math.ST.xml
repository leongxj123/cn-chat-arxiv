<rss version="2.0"><channel><title>Chat Arxiv math.ST</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math.ST</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;</title><link>http://arxiv.org/abs/2310.16945</link><description>&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection&#65288;CATE&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#22240;&#26524;Q&#38598;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16945
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#26159;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#29992;&#20110;CATE&#20272;&#35745;&#30340;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#39033;&#38750;&#24120;&#26840;&#25163;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#24037;&#20316;&#25552;&#20379;&#20102;&#26377;&#21033;&#20110;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#20195;&#29702;&#25439;&#22833;&#24230;&#37327;&#21644;&#27169;&#22411;&#38598;&#25104;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#12290;&#30452;&#25509;&#24212;&#29992;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20250;&#30001;&#20110;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#30340;&#38750;&#20984;&#24615;&#32780;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#20027;&#35201;CATE&#38598;&#25104;&#26041;&#27861;&#30340;&#36951;&#25022;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#30340;Q&#38598;&#25104;&#30340;&#26032;&#30340;CATE&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22240;&#26524;Q&#38598;&#25104;&#22312;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#30340;&#36951;&#25022;&#29575;&#19978;&#36798;&#21040;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20540;&#20026;$\frac{\log(M)}{n}$&#65288;&#20854;&#20013;$M$&#20026;&#27169;&#22411;&#25968;&#65292;$n$&#20026;&#26679;&#26412;&#25968;&#65289;&#65292;&#21152;&#19978;&#39640;&#38454;&#20272;&#35745;&#35823;&#24046;&#39033;
&lt;/p&gt;
&lt;p&gt;
Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#21487;&#34892;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#28508;&#22312;&#22240;&#23376;&#30340;&#21322;&#21442;&#25968;&#26465;&#20214;&#22240;&#23376;&#27169;&#22411;&#12290;&#24212;&#29992;&#20110;&#32654;&#22269;&#32929;&#31080;&#25910;&#30410;&#25968;&#25454;&#65292;&#21457;&#29616;&#20102;&#22823;&#37327;&#38750;&#38646;&#23450;&#20215;&#35823;&#24046;&#24182;&#35760;&#24405;&#20102;&#38543;&#26102;&#38388;&#30340;&#19979;&#38477;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2112.07121</link><description>&lt;p&gt;
&#21322;&#21442;&#25968;&#26465;&#20214;&#22240;&#23376;&#27169;&#22411;&#65306;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Semiparametric Conditional Factor Models: Estimation and Inference. (arXiv:2112.07121v4 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.07121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#21487;&#34892;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#28508;&#22312;&#22240;&#23376;&#30340;&#21322;&#21442;&#25968;&#26465;&#20214;&#22240;&#23376;&#27169;&#22411;&#12290;&#24212;&#29992;&#20110;&#32654;&#22269;&#32929;&#31080;&#25910;&#30410;&#25968;&#25454;&#65292;&#21457;&#29616;&#20102;&#22823;&#37327;&#38750;&#38646;&#23450;&#20215;&#35823;&#24046;&#24182;&#35760;&#24405;&#20102;&#38543;&#26102;&#38388;&#30340;&#19979;&#38477;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#21487;&#34892;&#30340;&#31579;&#36873;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#28508;&#22312;&#22240;&#23376;&#30340;&#21322;&#21442;&#25968;&#26465;&#20214;&#22240;&#23376;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#19981;&#35201;&#27714;&#22823; $T$ &#30340;&#24773;&#20917;&#19979;&#24314;&#31435;&#20102;&#20272;&#35745;&#37327;&#30340;&#22823;-$N$&#28176;&#36817;&#24615;&#36136;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#33258;&#21161;&#27861;&#26469;&#36827;&#34892;&#20851;&#20110;&#26465;&#20214;&#23450;&#20215;&#35823;&#24046;&#20197;&#21450;&#22240;&#23376;&#36733;&#33655;&#20989;&#25968;&#24418;&#29366;&#30340;&#25512;&#26029;&#12290;&#36825;&#20123;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#20219;&#24847;&#38750;&#32447;&#24615;&#29305;&#24449;&#20989;&#25968;&#26469;&#20272;&#35745;&#22823;&#37327;&#20010;&#20307;&#36164;&#20135;&#30340;&#26465;&#20214;&#22240;&#23376;&#32467;&#26500;&#65292;&#32780;&#19981;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#22240;&#23376;&#65292;&#21516;&#26102;&#20801;&#35768;&#25105;&#20204;&#21306;&#20998;&#29305;&#24449;&#22312;&#25429;&#25417;&#22240;&#23376; beta &#21644; alpha&#65288;&#21363;&#19981;&#21487;&#20998;&#25955;&#39118;&#38505;&#21644;&#38169;&#23450;&#20215;&#65289;&#20013;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#32654;&#22269;&#20010;&#21035;&#32929;&#31080;&#25910;&#30410;&#30340;&#25130;&#38754;&#65292;&#24182;&#21457;&#29616;&#20102;&#22823;&#37327;&#38750;&#38646;&#23450;&#20215;&#35823;&#24046;&#30340;&#24378;&#26377;&#21147;&#35777;&#25454;&#65292;&#36825;&#20123;&#35823;&#24046;&#32467;&#21512;&#36215;&#26469;&#20135;&#29983;&#30340;&#22871;&#21033;&#32452;&#21512;&#20855;&#26377;&#36229;&#36807;3&#30340;&#22799;&#26222;&#27604;&#29575;&#12290;&#25105;&#20204;&#36824;&#35760;&#24405;&#20102;&#26126;&#26174;&#30340;&#38543;&#26102;&#38388;&#19979;&#38477;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a simple and tractable sieve estimation of semiparametric conditional factor models with latent factors. We establish large-$N$-asymptotic properties of the estimators without requiring large $T$. We also develop a simple bootstrap procedure for conducting inference about the conditional pricing errors as well as the shapes of the factor loading functions. These results enable us to estimate conditional factor structure of a large set of individual assets by utilizing arbitrary nonlinear functions of a number of characteristics without the need to pre-specify the factors, while allowing us to disentangle the characteristics' role in capturing factor betas from alphas (i.e., undiversifiable risk from mispricing). We apply these methods to the cross-section of individual U.S. stock returns and find strong evidence of large nonzero pricing errors that combine to produce arbitrage portfolios with Sharpe ratios above 3. We also document a significant decline in apparen
&lt;/p&gt;</description></item></channel></rss>