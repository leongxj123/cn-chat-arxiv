<rss version="2.0"><channel><title>Chat Arxiv cs.PL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.PL</description><item><title>Synapse&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#20174;&#26377;&#38480;&#28436;&#31034;&#20013;&#39640;&#25928;&#23398;&#20064;&#20559;&#22909;&#27010;&#24565;&#65292;&#36890;&#36807;&#23558;&#20559;&#22909;&#34920;&#31034;&#20026;&#31070;&#32463;&#31526;&#21495;&#31243;&#24207;&#24182;&#21033;&#29992;&#35270;&#35273;&#35299;&#26512;&#12289;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#31243;&#24207;&#21512;&#25104;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#26469;&#23398;&#20064;&#20010;&#20154;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2403.16689</link><description>&lt;p&gt;
Synapse: &#20174;&#35270;&#35273;&#28436;&#31034;&#20013;&#23398;&#20064;&#20248;&#20808;&#27010;&#24565;
&lt;/p&gt;
&lt;p&gt;
Synapse: Learning Preferential Concepts from Visual Demonstrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16689
&lt;/p&gt;
&lt;p&gt;
Synapse&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#20174;&#26377;&#38480;&#28436;&#31034;&#20013;&#39640;&#25928;&#23398;&#20064;&#20559;&#22909;&#27010;&#24565;&#65292;&#36890;&#36807;&#23558;&#20559;&#22909;&#34920;&#31034;&#20026;&#31070;&#32463;&#31526;&#21495;&#31243;&#24207;&#24182;&#21033;&#29992;&#35270;&#35273;&#35299;&#26512;&#12289;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#31243;&#24207;&#21512;&#25104;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#26469;&#23398;&#20064;&#20010;&#20154;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20559;&#22909;&#23398;&#20064;&#38382;&#39064;&#65292;&#26088;&#22312;&#20174;&#35270;&#35273;&#36755;&#20837;&#20013;&#23398;&#20064;&#29992;&#25143;&#29305;&#23450;&#20559;&#22909;&#65288;&#20363;&#22914;&#65292;&#8220;&#22909;&#20572;&#36710;&#20301;&#8221;&#65292;&#8220;&#26041;&#20415;&#30340;&#19979;&#36710;&#20301;&#32622;&#8221;&#65289;&#12290;&#23613;&#31649;&#19982;&#23398;&#20064;&#20107;&#23454;&#27010;&#24565;&#65288;&#20363;&#22914;&#65292;&#8220;&#32418;&#33394;&#31435;&#26041;&#20307;&#8221;&#65289;&#30456;&#20284;&#65292;&#20294;&#20559;&#22909;&#23398;&#20064;&#26159;&#19968;&#20010;&#22522;&#26412;&#26356;&#21152;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#28041;&#21450;&#20027;&#35266;&#24615;&#36136;&#21644;&#20010;&#20154;&#29305;&#23450;&#35757;&#32451;&#25968;&#25454;&#30340;&#32570;&#20047;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#21517;&#20026;Synapse&#30340;&#26032;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#26377;&#25928;&#22320;&#20174;&#26377;&#38480;&#28436;&#31034;&#20013;&#23398;&#20064;&#20559;&#22909;&#27010;&#24565;&#12290;Synapse&#23558;&#20559;&#22909;&#34920;&#31034;&#20026;&#22312;&#22270;&#20687;&#19978;&#36816;&#20316;&#30340;&#39046;&#22495;&#29305;&#23450;&#35821;&#35328;&#65288;DSL&#65289;&#20013;&#30340;&#31070;&#32463;&#31526;&#21495;&#31243;&#24207;&#65292;&#24182;&#21033;&#29992;&#35270;&#35273;&#35299;&#26512;&#12289;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#31243;&#24207;&#21512;&#25104;&#30340;&#26032;&#32452;&#21512;&#26469;&#23398;&#20064;&#20195;&#34920;&#20010;&#20154;&#20559;&#22909;&#30340;&#31243;&#24207;&#12290;&#25105;&#20204;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35780;&#20272;&#20102;Synapse&#65292;&#21253;&#25324;&#19968;&#20010;&#20851;&#27880;&#19982;&#31227;&#21160;&#30456;&#20851;&#30340;&#29992;&#25143;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16689v1 Announce Type: cross  Abstract: This paper addresses the problem of preference learning, which aims to learn user-specific preferences (e.g., "good parking spot", "convenient drop-off location") from visual input. Despite its similarity to learning factual concepts (e.g., "red cube"), preference learning is a fundamentally harder problem due to its subjective nature and the paucity of person-specific training data. We address this problem using a new framework called Synapse, which is a neuro-symbolic approach designed to efficiently learn preferential concepts from limited demonstrations. Synapse represents preferences as neuro-symbolic programs in a domain-specific language (DSL) that operates over images, and leverages a novel combination of visual parsing, large language models, and program synthesis to learn programs representing individual preferences. We evaluate Synapse through extensive experimentation including a user case study focusing on mobility-related
&lt;/p&gt;</description></item></channel></rss>