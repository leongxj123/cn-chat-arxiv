<rss version="2.0"><channel><title>Chat Arxiv cs.PL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.PL</description><item><title>&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2403.14734</link><description>&lt;p&gt;
&#19968;&#39033;&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#30340;&#35843;&#26597;&#65306;&#33539;&#24335;&#12289;&#36827;&#23637;&#19982;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14734
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#31070;&#32463;&#20195;&#30721;&#26234;&#33021;--&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#20248;&#21270;&#20195;&#30721;--&#22312;&#25972;&#20010;&#31038;&#20250;&#19978;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21644;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#36825;&#19968;&#39046;&#22495;&#22312;&#36807;&#21435;&#20960;&#24180;&#24341;&#36215;&#20102;&#20004;&#20010;&#30740;&#31350;&#31038;&#21306;&#30740;&#31350;&#20154;&#21592;&#30340;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#35843;&#26597;&#31995;&#32479;&#22320;&#21644;&#25353;&#26102;&#38388;&#39034;&#24207;&#22238;&#39038;&#20102;&#20195;&#30721;&#26234;&#33021;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21450;&#20854;&#21464;&#20307;&#12289;20&#22810;&#31181;&#20219;&#21153;&#31867;&#21035;&#20197;&#21450;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#12290;&#25105;&#20204;&#36981;&#24490;&#21382;&#21490;&#36827;&#23637;&#65292;&#36319;&#36394;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#36716;&#21464;&#65288;&#20363;&#22914;&#65292;&#20174;&#20351;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#20195;&#30721;&#24314;&#27169;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65289;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#19981;&#21516;&#38454;&#27573;&#28085;&#30422;&#30340;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35780;&#20272;&#30340;&#20027;&#35201;&#25216;&#26415;&#36716;&#21464;&#12290;&#23545;&#20110;&#24212;&#29992;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#30340;&#35299;&#37322;&#35299;&#37322;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#19981;&#36879;&#26126;&#31995;&#32479;&#20013;&#29983;&#25104;&#21512;&#36866;&#35299;&#37322;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2401.17045</link><description>&lt;p&gt;
&#22312;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#20013;&#35299;&#37322;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Explaining Explanations in Probabilistic Logic Programming. (arXiv:2401.17045v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17045
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#30340;&#35299;&#37322;&#35299;&#37322;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#19981;&#36879;&#26126;&#31995;&#32479;&#20013;&#29983;&#25104;&#21512;&#36866;&#35299;&#37322;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24037;&#20855;&#30340;&#20986;&#29616;&#20063;&#23548;&#33268;&#20102;&#20135;&#29983;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#35299;&#37322;&#30340;&#38656;&#27714;&#12290;&#22312;&#19968;&#20123;&#26041;&#27861;&#20013;&#65292;&#31995;&#32479;&#26159;&#19981;&#36879;&#26126;&#30340;&#65288;&#36890;&#24120;&#34987;&#31216;&#20026;&#8220;&#40657;&#30418;&#23376;&#8221;&#65289;&#65292;&#36825;&#20351;&#24471;&#29983;&#25104;&#36866;&#24403;&#30340;&#35299;&#37322;&#21464;&#24471;&#22256;&#38590;&#12290;&#28982;&#32780;&#65292;&#22312;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36923;&#36753;&#32534;&#31243;&#65288;&#29992;&#20110;&#30693;&#35782;&#34920;&#31034;&#65289;&#21644;&#27010;&#29575;&#65288;&#29992;&#20110;&#24314;&#27169;&#19981;&#30830;&#23450;&#24615;&#65289;&#30340;&#32467;&#21512;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#21487;&#20197;&#35828;&#27169;&#22411;&#26159;&#21487;&#20197;&#35299;&#37322;&#30340;&#65292;&#36825;&#26041;&#20415;&#20102;&#23545;&#27169;&#22411;&#30340;&#29702;&#35299;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#29305;&#23450;&#30340;&#26597;&#35810;&#65292;&#36890;&#24120;&#30340;&#8220;&#35299;&#37322;&#8221;&#30340;&#27010;&#24565;&#26159;&#19982;&#27169;&#22411;&#30340;&#27599;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#36873;&#25321;&#38598;&#30456;&#20851;&#32852;&#30340;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20010;&#38598;&#21512;&#27809;&#26377;&#22240;&#26524;&#32467;&#26500;&#65292;&#23454;&#38469;&#19978;&#65292;&#19968;&#20123;&#36873;&#25321;&#23454;&#38469;&#19978;&#19982;&#25152;&#32771;&#34385;&#30340;&#26597;&#35810;&#26080;&#20851;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26597;&#35810;&#39537;&#21160;&#25512;&#29702;&#23450;&#20041;&#30340;&#35299;&#37322;&#35299;&#37322;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of tools based on artificial intelligence has also led to the need of producing explanations which are understandable by a human being. In some approaches, the system is not transparent (often referred to as a "black box"), making it difficult to generate appropriate explanations. In this work, though, we consider probabilistic logic programming, a combination of logic programming (for knowledge representation) and probability (to model uncertainty). In this setting, one can say that models are interpretable, which eases its understanding. However, given a particular query, the usual notion of "explanation" is associated with a set of choices, one for each random variable of the model. Unfortunately, this set does not have a causal structure and, in fact, some of the choices are actually irrelevant to the considered query. In order to overcome these shortcomings, we present an approach to explaining explanations which is based on the definition of a query-driven inference
&lt;/p&gt;</description></item></channel></rss>