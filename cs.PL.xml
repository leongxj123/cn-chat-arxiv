<rss version="2.0"><channel><title>Chat Arxiv cs.PL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.PL</description><item><title>&#21457;&#24067;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#39044;&#35757;&#32451;&#22312;40&#20159;&#20010;C&#28304;&#20195;&#30721;&#21644;&#27719;&#32534;&#20195;&#30721;&#26631;&#35760;&#19978;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.05286</link><description>&lt;p&gt;
LLM4Decompile&#65306;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20108;&#36827;&#21046;&#20195;&#30721;&#36827;&#34892;&#21453;&#32534;&#35793;
&lt;/p&gt;
&lt;p&gt;
LLM4Decompile: Decompiling Binary Code with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05286
&lt;/p&gt;
&lt;p&gt;
&#21457;&#24067;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#39044;&#35757;&#32451;&#22312;40&#20159;&#20010;C&#28304;&#20195;&#30721;&#21644;&#27719;&#32534;&#20195;&#30721;&#26631;&#35760;&#19978;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#32534;&#35793;&#26088;&#22312;&#23558;&#32534;&#35793;&#20195;&#30721;&#24674;&#22797;&#20026;&#21487;&#35835;&#24615;&#24378;&#30340;&#28304;&#20195;&#30721;&#65292;&#20294;&#22312;&#21517;&#31216;&#21644;&#32467;&#26500;&#31561;&#32454;&#33410;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32534;&#31243;&#20219;&#21153;&#20013;&#26174;&#31034;&#20986;&#28508;&#21147;&#65292;&#28608;&#21457;&#20102;&#23427;&#20204;&#22312;&#21453;&#32534;&#35793;&#20013;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#26080;&#29992;&#20110;&#21453;&#32534;&#35793;&#30340;&#24320;&#28304;LLM&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#21453;&#32534;&#35793;&#35780;&#20272;&#31995;&#32479;&#20027;&#35201;&#32771;&#34385;&#26631;&#35760;&#32423;&#20934;&#30830;&#24615;&#65292;&#32780;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#30053;&#20102;&#20195;&#30721;&#30340;&#21487;&#25191;&#34892;&#24615;&#65292;&#36825;&#26159;&#20219;&#20309;&#31243;&#24207;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#33539;&#22260;&#20174;10&#20159;&#21040;330&#20159;&#65292;&#39044;&#20808;&#35757;&#32451;&#20102;40&#20159;&#20010;&#20196;&#29260;&#30340;C&#28304;&#20195;&#30721;&#21644;&#30456;&#24212;&#30340;&#27719;&#32534;&#20195;&#30721;&#12290;&#36825;&#20123;&#24320;&#28304;LLM&#21487;&#20197;&#20316;&#20026;&#35813;&#39046;&#22495;&#36827;&#19968;&#27493;&#21457;&#23637;&#30340;&#22522;&#32447;&#12290;&#20026;&#20102;&#30830;&#20445;&#23454;&#38469;&#31243;&#24207;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Decompile-Eval&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;&#35813;&#22522;&#20934;&#24378;&#35843;&#20102;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05286v1 Announce Type: cross  Abstract: Decompilation aims to restore compiled code to human-readable source code, but struggles with details like names and structure. Large language models (LLMs) show promise for programming tasks, motivating their application to decompilation. However, there does not exist any open-source LLM for decompilation. Moreover, existing decompilation evaluation systems mainly consider token-level accuracy and largely ignore code executability, which is the most important feature of any program. Therefore, we release the first open-access decompilation LLMs ranging from 1B to 33B pre-trained on 4 billion tokens of C source code and the corresponding assembly code. The open-source LLMs can serve as baselines for further development in the field. To ensure practical program evaluation, we introduce Decompile-Eval, the first dataset that considers re-compilability and re-executability for decompilation. The benchmark emphasizes the importance of eval
&lt;/p&gt;</description></item></channel></rss>