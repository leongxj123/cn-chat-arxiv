<rss version="2.0"><channel><title>Chat Arxiv cs.PL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.PL</description><item><title>&#21457;&#24067;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#39044;&#35757;&#32451;&#22312;40&#20159;&#20010;C&#28304;&#20195;&#30721;&#21644;&#27719;&#32534;&#20195;&#30721;&#26631;&#35760;&#19978;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.05286</link><description>&lt;p&gt;
LLM4Decompile&#65306;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20108;&#36827;&#21046;&#20195;&#30721;&#36827;&#34892;&#21453;&#32534;&#35793;
&lt;/p&gt;
&lt;p&gt;
LLM4Decompile: Decompiling Binary Code with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05286
&lt;/p&gt;
&lt;p&gt;
&#21457;&#24067;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#39044;&#35757;&#32451;&#22312;40&#20159;&#20010;C&#28304;&#20195;&#30721;&#21644;&#27719;&#32534;&#20195;&#30721;&#26631;&#35760;&#19978;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#32534;&#35793;&#26088;&#22312;&#23558;&#32534;&#35793;&#20195;&#30721;&#24674;&#22797;&#20026;&#21487;&#35835;&#24615;&#24378;&#30340;&#28304;&#20195;&#30721;&#65292;&#20294;&#22312;&#21517;&#31216;&#21644;&#32467;&#26500;&#31561;&#32454;&#33410;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32534;&#31243;&#20219;&#21153;&#20013;&#26174;&#31034;&#20986;&#28508;&#21147;&#65292;&#28608;&#21457;&#20102;&#23427;&#20204;&#22312;&#21453;&#32534;&#35793;&#20013;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#26080;&#29992;&#20110;&#21453;&#32534;&#35793;&#30340;&#24320;&#28304;LLM&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#21453;&#32534;&#35793;&#35780;&#20272;&#31995;&#32479;&#20027;&#35201;&#32771;&#34385;&#26631;&#35760;&#32423;&#20934;&#30830;&#24615;&#65292;&#32780;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#30053;&#20102;&#20195;&#30721;&#30340;&#21487;&#25191;&#34892;&#24615;&#65292;&#36825;&#26159;&#20219;&#20309;&#31243;&#24207;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#33539;&#22260;&#20174;10&#20159;&#21040;330&#20159;&#65292;&#39044;&#20808;&#35757;&#32451;&#20102;40&#20159;&#20010;&#20196;&#29260;&#30340;C&#28304;&#20195;&#30721;&#21644;&#30456;&#24212;&#30340;&#27719;&#32534;&#20195;&#30721;&#12290;&#36825;&#20123;&#24320;&#28304;LLM&#21487;&#20197;&#20316;&#20026;&#35813;&#39046;&#22495;&#36827;&#19968;&#27493;&#21457;&#23637;&#30340;&#22522;&#32447;&#12290;&#20026;&#20102;&#30830;&#20445;&#23454;&#38469;&#31243;&#24207;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Decompile-Eval&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;&#35813;&#22522;&#20934;&#24378;&#35843;&#20102;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05286v1 Announce Type: cross  Abstract: Decompilation aims to restore compiled code to human-readable source code, but struggles with details like names and structure. Large language models (LLMs) show promise for programming tasks, motivating their application to decompilation. However, there does not exist any open-source LLM for decompilation. Moreover, existing decompilation evaluation systems mainly consider token-level accuracy and largely ignore code executability, which is the most important feature of any program. Therefore, we release the first open-access decompilation LLMs ranging from 1B to 33B pre-trained on 4 billion tokens of C source code and the corresponding assembly code. The open-source LLMs can serve as baselines for further development in the field. To ensure practical program evaluation, we introduce Decompile-Eval, the first dataset that considers re-compilability and re-executability for decompilation. The benchmark emphasizes the importance of eval
&lt;/p&gt;</description></item><item><title>Ansible Lightspeed&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26381;&#21153;&#65292;&#19987;&#27880;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#36716;&#25442;&#20026;Ansible&#20195;&#30721;&#65292;&#20026;IT&#33258;&#21160;&#21270;&#39046;&#22495;&#24102;&#26469;&#20102;&#21019;&#26032;&#12290;</title><link>https://arxiv.org/abs/2402.17442</link><description>&lt;p&gt;
Ansible Lightspeed: &#19968;&#31181;&#29992;&#20110;IT&#33258;&#21160;&#21270;&#30340;&#20195;&#30721;&#29983;&#25104;&#26381;&#21153;
&lt;/p&gt;
&lt;p&gt;
Ansible Lightspeed: A Code Generation Service for IT Automation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17442
&lt;/p&gt;
&lt;p&gt;
Ansible Lightspeed&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26381;&#21153;&#65292;&#19987;&#27880;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#36716;&#25442;&#20026;Ansible&#20195;&#30721;&#65292;&#20026;IT&#33258;&#21160;&#21270;&#39046;&#22495;&#24102;&#26469;&#20102;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#38382;&#19990;&#20351;&#24471;&#21019;&#24314;&#21487;&#25552;&#39640;&#24320;&#21457;&#32773;&#29983;&#20135;&#21147;&#30340;&#24037;&#20855;&#25104;&#20026;&#21487;&#33021;&#65292;&#38598;&#25104;&#24320;&#21457;&#29615;&#22659;&#65288;IDEs&#65289;&#24120;&#34987;&#29992;&#20316;&#19982;LLMs&#20132;&#20114;&#30340;&#25509;&#21475;&#12290;&#24050;&#21457;&#24067;&#35768;&#22810;&#36825;&#31867;&#24037;&#20855;&#65292;&#20294;&#20960;&#20046;&#20840;&#37096;&#37117;&#19987;&#27880;&#20110;&#36890;&#29992;&#32534;&#31243;&#35821;&#35328;&#65292;&#24456;&#23569;&#20851;&#27880;&#23545;IT&#33258;&#21160;&#21270;&#33267;&#20851;&#37325;&#35201;&#30340;&#29305;&#23450;&#39046;&#22495;&#35821;&#35328;&#12290;Ansible&#26159;&#19968;&#31181;&#22522;&#20110;YAML&#30340;IT&#33258;&#21160;&#21270;&#29305;&#23450;&#35821;&#35328;&#12290;Red Hat Ansible Lightspeed&#19982;IBM Watson Code Assistant&#21512;&#20316;&#30340;Ansible Lightspeed&#26159;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#26381;&#21153;&#65292;&#19987;&#38376;&#29992;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#36716;&#25442;&#20026;Ansible&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17442v1 Announce Type: cross  Abstract: The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for IT automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Red Hat Ansible Lightspeed with IBM Watson Code Assistant, further referred to as Ansible Lightspeed, is an LLM-based service designed explicitly for natural language to Ansible code generation.   In this paper, we describe the design and implementation of the Ansible Lightspeed service and analyze feedback from thousands of real users. We examine diverse performance indicators, clas
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#30340;&#35299;&#37322;&#35299;&#37322;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#19981;&#36879;&#26126;&#31995;&#32479;&#20013;&#29983;&#25104;&#21512;&#36866;&#35299;&#37322;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2401.17045</link><description>&lt;p&gt;
&#22312;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#20013;&#35299;&#37322;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Explaining Explanations in Probabilistic Logic Programming. (arXiv:2401.17045v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17045
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#30340;&#35299;&#37322;&#35299;&#37322;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#19981;&#36879;&#26126;&#31995;&#32479;&#20013;&#29983;&#25104;&#21512;&#36866;&#35299;&#37322;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24037;&#20855;&#30340;&#20986;&#29616;&#20063;&#23548;&#33268;&#20102;&#20135;&#29983;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#35299;&#37322;&#30340;&#38656;&#27714;&#12290;&#22312;&#19968;&#20123;&#26041;&#27861;&#20013;&#65292;&#31995;&#32479;&#26159;&#19981;&#36879;&#26126;&#30340;&#65288;&#36890;&#24120;&#34987;&#31216;&#20026;&#8220;&#40657;&#30418;&#23376;&#8221;&#65289;&#65292;&#36825;&#20351;&#24471;&#29983;&#25104;&#36866;&#24403;&#30340;&#35299;&#37322;&#21464;&#24471;&#22256;&#38590;&#12290;&#28982;&#32780;&#65292;&#22312;&#27010;&#29575;&#36923;&#36753;&#32534;&#31243;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36923;&#36753;&#32534;&#31243;&#65288;&#29992;&#20110;&#30693;&#35782;&#34920;&#31034;&#65289;&#21644;&#27010;&#29575;&#65288;&#29992;&#20110;&#24314;&#27169;&#19981;&#30830;&#23450;&#24615;&#65289;&#30340;&#32467;&#21512;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#21487;&#20197;&#35828;&#27169;&#22411;&#26159;&#21487;&#20197;&#35299;&#37322;&#30340;&#65292;&#36825;&#26041;&#20415;&#20102;&#23545;&#27169;&#22411;&#30340;&#29702;&#35299;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#29305;&#23450;&#30340;&#26597;&#35810;&#65292;&#36890;&#24120;&#30340;&#8220;&#35299;&#37322;&#8221;&#30340;&#27010;&#24565;&#26159;&#19982;&#27169;&#22411;&#30340;&#27599;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#36873;&#25321;&#38598;&#30456;&#20851;&#32852;&#30340;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20010;&#38598;&#21512;&#27809;&#26377;&#22240;&#26524;&#32467;&#26500;&#65292;&#23454;&#38469;&#19978;&#65292;&#19968;&#20123;&#36873;&#25321;&#23454;&#38469;&#19978;&#19982;&#25152;&#32771;&#34385;&#30340;&#26597;&#35810;&#26080;&#20851;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26597;&#35810;&#39537;&#21160;&#25512;&#29702;&#23450;&#20041;&#30340;&#35299;&#37322;&#35299;&#37322;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of tools based on artificial intelligence has also led to the need of producing explanations which are understandable by a human being. In some approaches, the system is not transparent (often referred to as a "black box"), making it difficult to generate appropriate explanations. In this work, though, we consider probabilistic logic programming, a combination of logic programming (for knowledge representation) and probability (to model uncertainty). In this setting, one can say that models are interpretable, which eases its understanding. However, given a particular query, the usual notion of "explanation" is associated with a set of choices, one for each random variable of the model. Unfortunately, this set does not have a causal structure and, in fact, some of the choices are actually irrelevant to the considered query. In order to overcome these shortcomings, we present an approach to explaining explanations which is based on the definition of a query-driven inference
&lt;/p&gt;</description></item></channel></rss>