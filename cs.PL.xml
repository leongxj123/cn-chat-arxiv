<rss version="2.0"><channel><title>Chat Arxiv cs.PL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.PL</description><item><title>LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.16929</link><description>&lt;p&gt;
LangGPT&#65306;&#37325;&#26032;&#24605;&#32771;&#38754;&#21521;LLMs&#30340;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#20174;&#32534;&#31243;&#35821;&#35328;&#20986;&#21457;
&lt;/p&gt;
&lt;p&gt;
LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16929
&lt;/p&gt;
&lt;p&gt;
LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#24050;&#32463;&#23637;&#31034;&#20986;&#22312;&#19981;&#21516;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#26377;&#25928;&#25351;&#23548;LLMs&#21046;&#23450;&#39640;&#36136;&#37327;&#30340;&#25552;&#31034;&#23545;&#20110;&#38750;AI&#19987;&#23478;&#26469;&#35828;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#25552;&#31034;&#24037;&#31243;&#30740;&#31350;&#24314;&#35758;&#20102;&#19968;&#20123;&#30053;&#26174;&#38646;&#30862;&#30340;&#20248;&#21270;&#21407;&#21017;&#21644;&#35774;&#35745;&#65292;&#20197;&#21450;&#20973;&#32463;&#39564;&#20381;&#36182;&#30340;&#25552;&#31034;&#20248;&#21270;&#22120;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#21162;&#21147;&#32570;&#20047;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#35774;&#35745;&#27169;&#26495;&#65292;&#23548;&#33268;&#23398;&#20064;&#25104;&#26412;&#39640;&#65292;&#37325;&#22797;&#20351;&#29992;&#24615;&#20302;&#12290;&#21463;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LangGPT&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#12290;LangGPT&#20855;&#26377;&#26131;&#20110;&#23398;&#20064;&#30340;&#35268;&#33539;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#25193;&#23637;&#32467;&#26500;&#20197;&#36827;&#34892;&#36801;&#31227;&#21644;&#37325;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#22522;&#20934;&#30456;&#27604;&#65292;LangGPT&#26174;&#33879;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;LangGPT&#24050;&#34987;&#35777;&#26126;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16929v1 Announce Type: cross  Abstract: LLMs have demonstrated commendable performance across diverse domains. Nevertheless, formulating high-quality prompts to effectively instruct LLMs poses a challenge for non-AI experts. Existing research in prompt engineering suggests somewhat fragmented optimization principles and designs empirically dependent prompt optimizers. Unfortunately, these endeavors lack a structured design template, incurring high learning costs and resulting in low reusability. Inspired by structured reusable programming languages, we propose LangGPT, a dual-layer prompt design framework as the programming language for LLMs. LangGPT has an easy-to-learn normative structure and provides an extended structure for migration and reuse. Experiments illustrate that LangGPT significantly enhances the capacity of LLMs to produce responses of superior quality compared to baselines. Moreover, LangGPT has proven effective in guiding LLMs to generate high-quality promp
&lt;/p&gt;</description></item></channel></rss>