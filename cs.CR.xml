<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>PSO-Fed&#31639;&#27861;&#30340;&#37096;&#20998;&#20849;&#20139;&#26426;&#21046;&#19981;&#20165;&#21487;&#20197;&#38477;&#20302;&#36890;&#20449;&#36127;&#36733;&#65292;&#36824;&#33021;&#22686;&#24378;&#31639;&#27861;&#23545;&#27169;&#22411;&#25237;&#27602;&#25915;&#20987;&#30340;&#25269;&#25239;&#21147;&#65292;&#24182;&#19988;&#22312;&#38754;&#23545;&#25308;&#21344;&#24237;&#23458;&#25143;&#31471;&#30340;&#24773;&#20917;&#19979;&#20381;&#28982;&#33021;&#20445;&#25345;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2403.13108</link><description>&lt;p&gt;
&#20998;&#26512;&#37096;&#20998;&#20849;&#20139;&#23545;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#25269;&#25239;&#27169;&#22411;&#25237;&#27602;&#25915;&#20987;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Analyzing the Impact of Partial Sharing on the Resilience of Online Federated Learning Against Model Poisoning Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13108
&lt;/p&gt;
&lt;p&gt;
PSO-Fed&#31639;&#27861;&#30340;&#37096;&#20998;&#20849;&#20139;&#26426;&#21046;&#19981;&#20165;&#21487;&#20197;&#38477;&#20302;&#36890;&#20449;&#36127;&#36733;&#65292;&#36824;&#33021;&#22686;&#24378;&#31639;&#27861;&#23545;&#27169;&#22411;&#25237;&#27602;&#25915;&#20987;&#30340;&#25269;&#25239;&#21147;&#65292;&#24182;&#19988;&#22312;&#38754;&#23545;&#25308;&#21344;&#24237;&#23458;&#25143;&#31471;&#30340;&#24773;&#20917;&#19979;&#20381;&#28982;&#33021;&#20445;&#25345;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23457;&#26597;&#20102;&#37096;&#20998;&#20849;&#20139;&#30340;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;PSO-Fed&#65289;&#31639;&#27861;&#23545;&#25269;&#25239;&#27169;&#22411;&#25237;&#27602;&#25915;&#20987;&#30340;&#38887;&#24615;&#12290; PSO-Fed&#36890;&#36807;&#20351;&#23458;&#25143;&#31471;&#22312;&#27599;&#20010;&#26356;&#26032;&#36718;&#27425;&#20165;&#19982;&#26381;&#21153;&#22120;&#20132;&#25442;&#37096;&#20998;&#27169;&#22411;&#20272;&#35745;&#26469;&#20943;&#23569;&#36890;&#20449;&#36127;&#36733;&#12290;&#27169;&#22411;&#20272;&#35745;&#30340;&#37096;&#20998;&#20849;&#20139;&#36824;&#22686;&#24378;&#20102;&#31639;&#27861;&#23545;&#27169;&#22411;&#25237;&#27602;&#25915;&#20987;&#30340;&#24378;&#24230;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;PSO-Fed&#31639;&#27861;&#22312;&#23384;&#22312;&#25308;&#21344;&#24237;&#23458;&#25143;&#31471;&#30340;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#36825;&#20123;&#23458;&#25143;&#31471;&#21487;&#33021;&#20250;&#22312;&#19982;&#26381;&#21153;&#22120;&#20849;&#20139;&#20043;&#21069;&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#36731;&#24494;&#31713;&#25913;&#20854;&#26412;&#22320;&#27169;&#22411;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PSO-Fed&#22312;&#22343;&#20540;&#21644;&#22343;&#26041;&#24847;&#20041;&#19978;&#37117;&#33021;&#20445;&#25345;&#25910;&#25947;&#65292;&#21363;&#20351;&#22312;&#27169;&#22411;&#25237;&#27602;&#25915;&#20987;&#30340;&#21387;&#21147;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#23548;&#20102;PSO-Fed&#30340;&#29702;&#35770;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#65292;&#23558;&#20854;&#19982;&#27493;&#38271;&#12289;&#25915;&#20987;&#27010;&#29575;&#12289;&#25968;&#23383;&#31561;&#21508;&#31181;&#21442;&#25968;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13108v1 Announce Type: new  Abstract: We scrutinize the resilience of the partial-sharing online federated learning (PSO-Fed) algorithm against model-poisoning attacks. PSO-Fed reduces the communication load by enabling clients to exchange only a fraction of their model estimates with the server at each update round. Partial sharing of model estimates also enhances the robustness of the algorithm against model-poisoning attacks. To gain better insights into this phenomenon, we analyze the performance of the PSO-Fed algorithm in the presence of Byzantine clients, malicious actors who may subtly tamper with their local models by adding noise before sharing them with the server. Through our analysis, we demonstrate that PSO-Fed maintains convergence in both mean and mean-square senses, even under the strain of model-poisoning attacks. We further derive the theoretical mean square error (MSE) of PSO-Fed, linking it to various parameters such as stepsize, attack probability, numb
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#35774;&#35745;&#20102;Injectivity Bit Flip Attack&#26469;&#38024;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#25104;&#21151;&#22320;&#38477;&#20302;&#20102;&#20854;&#23545;&#22270;&#32467;&#26500;&#30340;&#35782;&#21035;&#33021;&#21147;&#21644;&#34920;&#36798;&#33021;&#21147;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#20854;&#23545;&#20301;&#21453;&#36716;&#25915;&#20987;&#30340;&#26131;&#21463;&#25915;&#20987;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01205</link><description>&lt;p&gt;
&#20351;&#29992;&#20301;&#21453;&#36716;&#25915;&#20987;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;Weisfeiler&#21644;Lehman&#21464;&#24471;&#20919;&#28448;&#20102;
&lt;/p&gt;
&lt;p&gt;
Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent. (arXiv:2311.01205v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01205
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#20102;Injectivity Bit Flip Attack&#26469;&#38024;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#25104;&#21151;&#22320;&#38477;&#20302;&#20102;&#20854;&#23545;&#22270;&#32467;&#26500;&#30340;&#35782;&#21035;&#33021;&#21147;&#21644;&#34920;&#36798;&#33021;&#21147;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#20854;&#23545;&#20301;&#21453;&#36716;&#25915;&#20987;&#30340;&#26131;&#21463;&#25915;&#20987;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25915;&#20987;&#20027;&#35201;&#38598;&#20013;&#22312;&#22270;&#27602;&#21270;&#21644;&#35268;&#36991;&#19978;&#65292;&#24573;&#30053;&#20102;&#32593;&#32476;&#30340;&#26435;&#37325;&#21644;&#20559;&#32622;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;&#26435;&#37325;&#30340;&#25925;&#38556;&#27880;&#20837;&#25915;&#20987;&#65292;&#22914;&#29992;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20301;&#21453;&#36716;&#25915;&#20987;&#65292;&#27809;&#26377;&#32771;&#34385;&#21040;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#29420;&#29305;&#23646;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#27880;&#20837;&#29575;&#20301;&#21453;&#36716;&#25915;&#20987;&#65288;Injectivity Bit Flip Attack&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#20301;&#21453;&#36716;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#25915;&#20987;&#38024;&#23545;&#37327;&#21270;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21487;&#23398;&#20064;&#37051;&#22495;&#32858;&#21512;&#20989;&#25968;&#65292;&#38477;&#20302;&#20102;&#20854;&#21306;&#20998;&#22270;&#32467;&#26500;&#30340;&#33021;&#21147;&#65292;&#22833;&#21435;&#20102;Weisfeiler-Lehman&#27979;&#35797;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#21033;&#29992;&#29305;&#23450;&#20110;&#26576;&#20123;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#25968;&#23398;&#23646;&#24615;&#21487;&#33021;&#20250;&#26174;&#33879;&#22686;&#21152;&#20854;&#23545;&#20301;&#21453;&#36716;&#25915;&#20987;&#30340;&#26131;&#21463;&#25915;&#20987;&#24615;&#12290;&#27880;&#20837;&#29575;&#20301;&#21453;&#36716;&#25915;&#20987;&#21487;&#20197;&#23558;&#21508;&#31181;&#22270;&#23646;&#24615;&#39044;&#27979;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#26368;&#22823;&#34920;&#36798;&#24615;&#21516;&#26500;&#32593;&#32476;&#38477;&#32423;&#20026;&#38543;&#26426;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prior attacks on graph neural networks have mostly focused on graph poisoning and evasion, neglecting the network's weights and biases. Traditional weight-based fault injection attacks, such as bit flip attacks used for convolutional neural networks, do not consider the unique properties of graph neural networks. We propose the Injectivity Bit Flip Attack, the first bit flip attack designed specifically for graph neural networks. Our attack targets the learnable neighborhood aggregation functions in quantized message passing neural networks, degrading their ability to distinguish graph structures and losing the expressivity of the Weisfeiler-Lehman test. Our findings suggest that exploiting mathematical properties specific to certain graph neural network architectures can significantly increase their vulnerability to bit flip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive Graph Isomorphism Networks trained on various graph property prediction datasets to rando
&lt;/p&gt;</description></item><item><title>S-GBDT&#26159;&#19968;&#31181;&#33410;&#20461;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#23398;&#20064;&#22120;&#65292;&#21033;&#29992;&#20102;&#22235;&#31181;&#25216;&#26415;&#26469;&#25913;&#21892;&#25928;&#29992;&#21644;&#38544;&#31169;&#26435;&#20043;&#38388;&#30340;&#24179;&#34913;&#65292;&#21253;&#25324;&#23545;&#38544;&#31169;&#27844;&#38706;&#30340;&#26356;&#32039;&#23494;&#35745;&#31639;&#21644;&#25972;&#21512;&#20010;&#20307;R&#233;nyi&#28388;&#27874;&#22120;&#20197;&#23398;&#20064;&#26410;&#20805;&#20998;&#21033;&#29992;&#30340;&#25968;&#25454;&#28857;&#12290;</title><link>http://arxiv.org/abs/2309.12041</link><description>&lt;p&gt;
S-GBDT: &#33410;&#20461;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;
&lt;/p&gt;
&lt;p&gt;
S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees. (arXiv:2309.12041v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12041
&lt;/p&gt;
&lt;p&gt;
S-GBDT&#26159;&#19968;&#31181;&#33410;&#20461;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#23398;&#20064;&#22120;&#65292;&#21033;&#29992;&#20102;&#22235;&#31181;&#25216;&#26415;&#26469;&#25913;&#21892;&#25928;&#29992;&#21644;&#38544;&#31169;&#26435;&#20043;&#38388;&#30340;&#24179;&#34913;&#65292;&#21253;&#25324;&#23545;&#38544;&#31169;&#27844;&#38706;&#30340;&#26356;&#32039;&#23494;&#35745;&#31639;&#21644;&#25972;&#21512;&#20010;&#20307;R&#233;nyi&#28388;&#27874;&#22120;&#20197;&#23398;&#20064;&#26410;&#20805;&#20998;&#21033;&#29992;&#30340;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;(GBDT)&#22312;&#34920;&#26684;&#25968;&#25454;(&#22914;&#20154;&#21475;&#26222;&#26597;&#25968;&#25454;&#25110;&#21307;&#30103;&#20803;&#25968;&#25454;)&#20013;&#20855;&#26377;&#24456;&#24378;&#30340;&#25928;&#29992;&#21644;&#38544;&#31169;&#26435;&#20043;&#38388;&#30340;&#24179;&#34913;&#28508;&#21147;&#65306;&#32463;&#20856;&#30340;GBDT&#23398;&#20064;&#22120;&#21487;&#20197;&#20174;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#38750;&#32447;&#24615;&#27169;&#24335;&#12290;&#21487;&#35777;&#26126;&#20855;&#26377;&#38544;&#31169;&#24615;&#36136;&#30340;&#24403;&#21069;&#26041;&#27861;&#26159;&#24046;&#20998;&#38544;&#31169;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#21333;&#20010;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#26377;&#38480;&#19988;&#21487;&#21542;&#35748;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;GBDT&#23398;&#20064;&#22120;&#65292;&#24182;&#21033;&#29992;&#22235;&#31181;&#20027;&#35201;&#25216;&#26415;&#26469;&#25913;&#21892;&#25928;&#29992;&#21644;&#38544;&#31169;&#26435;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;(1)&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22122;&#22768;&#32553;&#25918;&#26041;&#27861;&#65292;&#26356;&#32039;&#23494;&#22320;&#35745;&#31639;&#20102;&#19982;&#20808;&#21069;&#24037;&#20316;&#30456;&#27604;&#20915;&#31574;&#26641;&#21494;&#23376;&#30340;&#38544;&#31169;&#27844;&#38706;&#65292;&#20174;&#32780;&#23548;&#33268;&#22122;&#22768;&#30340;&#26399;&#26395;&#19982;&#25968;&#25454;&#28857;&#25968;&#37327;n&#30340;&#27604;&#20363;&#20026;$O(1/n)$&#65292;&#20854;&#20013;n&#20026;&#25968;&#25454;&#28857;&#25968;&#37327;&#12290;(2)&#25105;&#20204;&#23558;&#20010;&#20307;R&#233;nyi&#28388;&#27874;&#22120;&#25972;&#21512;&#21040;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#20197;&#20174;&#22312;&#36845;&#20195;&#35757;&#32451;&#36807;&#31243;&#20013;&#26410;&#20805;&#20998;&#21033;&#29992;&#30340;&#25968;&#25454;&#28857;&#20013;&#23398;&#20064;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#20110;&#20852;&#36259;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Privacy-preserving learning of gradient boosting decision trees (GBDT) has the potential for strong utility-privacy tradeoffs for tabular data, such as census data or medical meta data: classical GBDT learners can extract non-linear patterns from small sized datasets. The state-of-the-art notion for provable privacy-properties is differential privacy, which requires that the impact of single data points is limited and deniable. We introduce a novel differentially private GBDT learner and utilize four main techniques to improve the utility-privacy tradeoff. (1) We use an improved noise scaling approach with tighter accounting of privacy leakage of a decision tree leaf compared to prior work, resulting in noise that in expectation scales with $O(1/n)$, for $n$ data points. (2) We integrate individual R\'enyi filters to our method to learn from data points that have been underutilized during an iterative training process, which -- potentially of independent interest -- results in a natura
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#20195;&#30721;&#26102;&#32570;&#20047;&#23433;&#20840;&#24847;&#35782;&#65292;&#20174;&#23433;&#20840;&#21152;&#22266;&#21644;&#23545;&#25239;&#27979;&#35797;&#30340;&#35282;&#24230;&#20837;&#25163;&#65292;&#25552;&#20986;&#20102;&#19968;&#39033;&#26032;&#30340;&#23433;&#20840;&#20219;&#21153;&#8212;&#8212;&#21463;&#25511;&#20195;&#30721;&#29983;&#25104;&#65292;&#36890;&#36807;&#19968;&#31181;&#26032;&#22411;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;SVEN&#65292;&#23454;&#29616;&#29983;&#25104;&#26082;&#23433;&#20840;&#21448;&#21151;&#33021;&#27491;&#30830;&#30340;&#20195;&#30721;&#65292;&#24182;&#23545;&#24403;&#21069;&#30340;LM&#36827;&#34892;&#23545;&#25239;&#27979;&#35797;&#65292;&#24378;&#35843;&#20102;&#22312;LM&#30340;&#22521;&#35757;&#21644;&#35780;&#20272;&#20013;&#32771;&#34385;&#23433;&#20840;&#22240;&#32032;&#30340;&#24517;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.05319</link><description>&lt;p&gt;
&#29992;&#20110;&#32534;&#30721;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#23433;&#20840;&#21152;&#22266;&#21644;&#23545;&#25239;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Large Language Models for Code: Security Hardening and Adversarial Testing. (arXiv:2302.05319v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05319
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#20195;&#30721;&#26102;&#32570;&#20047;&#23433;&#20840;&#24847;&#35782;&#65292;&#20174;&#23433;&#20840;&#21152;&#22266;&#21644;&#23545;&#25239;&#27979;&#35797;&#30340;&#35282;&#24230;&#20837;&#25163;&#65292;&#25552;&#20986;&#20102;&#19968;&#39033;&#26032;&#30340;&#23433;&#20840;&#20219;&#21153;&#8212;&#8212;&#21463;&#25511;&#20195;&#30721;&#29983;&#25104;&#65292;&#36890;&#36807;&#19968;&#31181;&#26032;&#22411;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;SVEN&#65292;&#23454;&#29616;&#29983;&#25104;&#26082;&#23433;&#20840;&#21448;&#21151;&#33021;&#27491;&#30830;&#30340;&#20195;&#30721;&#65292;&#24182;&#23545;&#24403;&#21069;&#30340;LM&#36827;&#34892;&#23545;&#25239;&#27979;&#35797;&#65292;&#24378;&#35843;&#20102;&#22312;LM&#30340;&#22521;&#35757;&#21644;&#35780;&#20272;&#20013;&#32771;&#34385;&#23433;&#20840;&#22240;&#32032;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LMs)&#36234;&#26469;&#36234;&#22810;&#22320;&#39044;&#20808;&#22312;&#22823;&#35268;&#27169;&#20195;&#30721;&#24211;&#19978;&#36827;&#34892;&#39044;&#22788;&#29702;&#65292;&#29992;&#20110;&#29983;&#25104;&#20195;&#30721;&#12290;&#28982;&#32780;&#65292;LM&#32570;&#20047;&#23433;&#20840;&#24847;&#35782;&#65292;&#24182;&#32463;&#24120;&#29983;&#25104;&#19981;&#23433;&#20840;&#30340;&#20195;&#30721;&#12290;&#26412;&#30740;&#31350;&#27839;&#30528;&#20004;&#20010;&#37325;&#35201;&#26041;&#21521;&#30740;&#31350;&#20102;LM&#30340;&#23433;&#20840;&#24615;:(i)&#23433;&#20840;&#21152;&#22266;&#65292;&#26088;&#22312;&#22686;&#24378;LM&#22312;&#29983;&#25104;&#23433;&#20840;&#20195;&#30721;&#26041;&#38754;&#30340;&#21487;&#38752;&#24615;;(ii)&#23545;&#25239;&#27979;&#35797;&#65292;&#26088;&#22312;&#22312;&#23545;&#25239;&#24615;&#31435;&#22330;&#35780;&#20272;LM&#30340;&#23433;&#20840;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#21046;&#23450;&#19968;&#39033;&#31216;&#20026;&#21463;&#25511;&#20195;&#30721;&#29983;&#25104;&#30340;&#26032;&#23433;&#20840;&#20219;&#21153;&#26469;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#35813;&#20219;&#21153;&#26159;&#21442;&#25968;&#21270;&#30340;&#65292;&#23558;&#19968;&#20010;&#20108;&#36827;&#21046;&#23646;&#24615;&#20316;&#20026;&#36755;&#20837;&#65292;&#20197;&#25351;&#23548;LM&#29983;&#25104;&#23433;&#20840;&#25110;&#19981;&#23433;&#20840;&#30340;&#20195;&#30721;&#65292;&#21516;&#26102;&#20445;&#30041;LM&#29983;&#25104;&#21151;&#33021;&#27491;&#30830;&#20195;&#30721;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SVEN&#30340;&#26032;&#22411;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#12290;SVEN&#21033;&#29992;&#23646;&#24615;&#29305;&#23450;&#30340;&#36830;&#32493;&#21521;&#37327;&#26469;&#24341;&#23548;&#31243;&#24207;&#29983;&#25104;&#36798;&#21040;&#32473;&#23450;&#30340;&#23646;&#24615;&#65292;&#32780;&#19981;&#20462;&#25913;LM&#30340;&#26435;&#37325;&#12290;&#25105;&#20204;&#30340;&#35757;&#32451;&#36807;&#31243;&#36890;&#36807;&#21487;&#24494;&#20998;&#30340;&#25237;&#24433;&#25439;&#22833;&#26469;&#20248;&#21270;&#36825;&#20123;&#36830;&#32493;&#21521;&#37327;&#65292;&#23454;&#29616;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;SVEN&#36827;&#34892;&#23545;&#25239;&#27979;&#35797;&#65292;&#24182;&#34920;&#26126;&#24403;&#21069;&#30340;LM&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#65292;&#22312;&#27979;&#35797;&#26102;&#20462;&#25913;&#23427;&#20204;&#30340;&#36755;&#20837;&#32780;&#20445;&#30041;&#21151;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#38656;&#35201;&#22312;LM&#30340;&#22521;&#35757;&#21644;&#35780;&#20272;&#20013;&#32771;&#34385;&#23433;&#20840;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LMs) are increasingly pretrained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous ve
&lt;/p&gt;</description></item></channel></rss>