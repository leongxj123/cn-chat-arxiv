<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#29616;&#26377;&#27700;&#21360;&#25216;&#26415;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;Python&#20195;&#30721;&#19978;&#30340;&#40065;&#26834;&#24615;&#65292;&#21457;&#29616;&#23481;&#26131;&#36890;&#36807;&#20445;&#30041;&#35821;&#20041;&#36716;&#25442;&#26469;&#31227;&#38500;&#36825;&#20123;&#27700;&#21360;&#12290;</title><link>https://arxiv.org/abs/2403.17983</link><description>&lt;p&gt;
LLM&#29983;&#25104;&#20195;&#30721;&#30340;&#27700;&#21360;&#25216;&#26415;&#26159;&#21542;&#20855;&#26377;&#40065;&#26834;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Watermarking LLM-Generated Code Robust?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17983
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#29616;&#26377;&#27700;&#21360;&#25216;&#26415;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;Python&#20195;&#30721;&#19978;&#30340;&#40065;&#26834;&#24615;&#65292;&#21457;&#29616;&#23481;&#26131;&#36890;&#36807;&#20445;&#30041;&#35821;&#20041;&#36716;&#25442;&#26469;&#31227;&#38500;&#36825;&#20123;&#27700;&#21360;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#29616;&#26377;&#27700;&#21360;&#25216;&#26415;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;Python&#20195;&#30721;&#19978;&#30340;&#40065;&#26834;&#24615;&#12290;&#23613;&#31649;&#29616;&#26377;&#20316;&#21697;&#34920;&#26126;&#27700;&#21360;&#25216;&#26415;&#23545;&#33258;&#28982;&#35821;&#35328;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;&#20445;&#30041;&#35821;&#20041;&#30340;&#36716;&#25442;&#24456;&#23481;&#26131;&#31227;&#38500;&#20195;&#30721;&#19978;&#30340;&#36825;&#20123;&#27700;&#21360;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17983v1 Announce Type: cross  Abstract: We present the first study of the robustness of existing watermarking techniques on Python code generated by large language models. Although existing works showed that watermarking can be robust for natural language, we show that it is easy to remove these watermarks on code by semantic-preserving transformations.
&lt;/p&gt;</description></item><item><title>&#26426;&#22120;&#36951;&#24536;&#65288;MU&#65289;&#36890;&#36807;&#30693;&#35782;&#21435;&#38500;&#36807;&#31243;&#26469;&#35299;&#20915;&#35757;&#32451;&#25968;&#25454;&#30456;&#20851;&#30340;&#20154;&#24037;&#26234;&#33021;&#27835;&#29702;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;AI&#31995;&#32479;&#30340;&#23433;&#20840;&#21644;&#36127;&#36131;&#20219;&#20351;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.13682</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#23041;&#32961;&#12289;&#25915;&#20987;&#21644;&#38450;&#24481;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Threats, Attacks, and Defenses in Machine Unlearning: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13682
&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#36951;&#24536;&#65288;MU&#65289;&#36890;&#36807;&#30693;&#35782;&#21435;&#38500;&#36807;&#31243;&#26469;&#35299;&#20915;&#35757;&#32451;&#25968;&#25454;&#30456;&#20851;&#30340;&#20154;&#24037;&#26234;&#33021;&#27835;&#29702;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;AI&#31995;&#32479;&#30340;&#23433;&#20840;&#21644;&#36127;&#36131;&#20219;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#36951;&#24536;&#65288;MU&#65289;&#26368;&#36817;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#26377;&#28508;&#21147;&#36890;&#36807;&#20174;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#28040;&#38500;&#29305;&#23450;&#25968;&#25454;&#30340;&#24433;&#21709;&#26469;&#23454;&#29616;&#23433;&#20840;&#20154;&#24037;&#26234;&#33021;&#12290;&#36825;&#20010;&#34987;&#31216;&#20026;&#30693;&#35782;&#21435;&#38500;&#30340;&#36807;&#31243;&#35299;&#20915;&#20102;&#19982;&#35757;&#32451;&#25968;&#25454;&#30456;&#20851;&#30340;&#20154;&#24037;&#26234;&#33021;&#27835;&#29702;&#38382;&#39064;&#65292;&#22914;&#25968;&#25454;&#36136;&#37327;&#12289;&#25935;&#24863;&#24615;&#12289;&#29256;&#26435;&#38480;&#21046;&#21644;&#36807;&#26102;&#24615;&#12290;&#36825;&#31181;&#33021;&#21147;&#23545;&#20110;&#30830;&#20445;&#36981;&#23432;&#35832;&#22914;&#34987;&#36951;&#24536;&#26435;&#31561;&#38544;&#31169;&#27861;&#35268;&#20063;&#33267;&#20851;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#26377;&#25928;&#30340;&#30693;&#35782;&#21435;&#38500;&#26377;&#21161;&#20110;&#20943;&#36731;&#26377;&#23475;&#32467;&#26524;&#30340;&#39118;&#38505;&#65292;&#38450;&#33539;&#20559;&#35265;&#12289;&#35823;&#23548;&#21644;&#26410;&#32463;&#25480;&#26435;&#30340;&#25968;&#25454;&#21033;&#29992;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;AI&#31995;&#32479;&#30340;&#23433;&#20840;&#21644;&#36127;&#36131;&#20219;&#20351;&#29992;&#12290;&#24050;&#32463;&#24320;&#23637;&#20102;&#35774;&#35745;&#39640;&#25928;&#30340;&#36951;&#24536;&#26041;&#27861;&#30340;&#24037;&#20316;&#65292;&#36890;&#36807;&#30740;&#31350;MU&#26381;&#21153;&#20197;&#19982;&#29616;&#26377;&#30340;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#26381;&#21153;&#38598;&#25104;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#25552;&#20132;&#35831;&#27714;&#20174;&#35757;&#32451;&#35821;&#26009;&#24211;&#20013;&#21024;&#38500;&#29305;&#23450;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13682v2 Announce Type: replace-cross  Abstract: Machine Unlearning (MU) has gained considerable attention recently for its potential to achieve Safe AI by removing the influence of specific data from trained machine learning models. This process, known as knowledge removal, addresses AI governance concerns of training data such as quality, sensitivity, copyright restrictions, and obsolescence. This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten. Furthermore, effective knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the safe and responsible use of AI systems. Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service, allowing users to submit requests to remove specific data from the training corpus. However, 
&lt;/p&gt;</description></item><item><title>&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#32852;&#21512;&#23398;&#20064;&#20026;&#26412;&#22320;&#23458;&#25143;&#23450;&#21046;&#30340;&#20010;&#24615;&#21270;&#22270;&#20197;&#21450;&#20849;&#35782;&#22270;&#65292;&#20197;&#25512;&#26029;&#28508;&#22312;&#22270;&#25299;&#25169;&#65292;&#21516;&#26102;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#22788;&#29702;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2301.06662</link><description>&lt;p&gt;
&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#22270;&#25299;&#25169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Graph Topology Learning Under Privacy Constraints. (arXiv:2301.06662v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.06662
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#32852;&#21512;&#23398;&#20064;&#20026;&#26412;&#22320;&#23458;&#25143;&#23450;&#21046;&#30340;&#20010;&#24615;&#21270;&#22270;&#20197;&#21450;&#20849;&#35782;&#22270;&#65292;&#20197;&#25512;&#26029;&#28508;&#22312;&#22270;&#25299;&#25169;&#65292;&#21516;&#26102;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#22788;&#29702;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#25968;&#25454;&#20998;&#24067;&#20110;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#19988;&#20855;&#26377;&#38544;&#31169;&#25935;&#24863;&#24615;&#30340;&#26032;&#39062;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#36890;&#36807;&#24179;&#28369;&#22270;&#20449;&#21495;&#25512;&#26029;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#20219;&#21153;&#30340;&#20027;&#35201;&#22256;&#38590;&#22312;&#20110;&#22914;&#20309;&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#21033;&#29992;&#25152;&#26377;&#29420;&#31435;&#23458;&#25143;&#31471;&#30340;&#28508;&#22312;&#24322;&#26500;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#20026;&#26412;&#22320;&#23458;&#25143;&#31471;&#23450;&#21046;&#30340;&#20010;&#24615;&#21270;&#22270;&#20197;&#21450;&#20849;&#35782;&#22270;&#12290;&#20010;&#24615;&#21270;&#22270;&#21305;&#37197;&#26412;&#22320;&#25968;&#25454;&#20998;&#24067;&#65292;&#20174;&#32780;&#20943;&#36731;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#65292;&#32780;&#20849;&#35782;&#22270;&#25429;&#25417;&#20840;&#23616;&#20449;&#24687;&#12290;&#25105;&#20204;&#25509;&#19979;&#26469;&#35774;&#35745;&#20102;&#19968;&#20010;&#23450;&#21046;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#24341;&#20837;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#19981;&#36829;&#21453;&#38544;&#31169;&#32422;&#26463;&#65292;&#21363;&#25152;&#26377;&#30340;&#31169;&#26377;&#25968;&#25454;&#37117;&#22312;&#26412;&#22320;&#22788;&#29702;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#65292;&#25105;&#20204;&#23558;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#24341;&#20837;&#21040;&#25152;&#25552;&#31639;&#27861;&#20013;&#65292;&#22312;&#20256;&#36755;&#27169;&#22411;&#26356;&#26032;&#26102;&#25269;&#24481;&#38544;&#31169;&#25915;&#20987;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of inferring the underlying graph topology from smooth graph signals in a novel but practical scenario where data are located in distributed clients and are privacy-sensitive. The main difficulty of this task lies in how to utilize the potentially heterogeneous data of all isolated clients under privacy constraints. Towards this end, we propose a framework where personalized graphs for local clients as well as a consensus graph are jointly learned. The personalized graphs match local data distributions, thereby mitigating data heterogeneity, while the consensus graph captures the global information. We next devise a tailored algorithm to solve the induced problem without violating privacy constraints, i.e., all private data are processed locally. To further enhance privacy protection, we introduce differential privacy (DP) into the proposed algorithm to resist privacy attacks when transmitting model updates. Theoretically, we establish provable convergence analy
&lt;/p&gt;</description></item></channel></rss>