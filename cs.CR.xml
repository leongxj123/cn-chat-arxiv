<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#37325;&#24314;&#25915;&#20987;&#65292;&#20316;&#32773;&#21457;&#29616;&#22312;DP-SGD&#19979;&#65292;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20808;&#39564;&#23545;&#20110;&#37325;&#24314;&#25104;&#21151;&#20855;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.07588</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#35270;&#35273;&#38544;&#31169;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Visual Privacy Auditing with Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07588
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#37325;&#24314;&#25915;&#20987;&#65292;&#20316;&#32773;&#21457;&#29616;&#22312;DP-SGD&#19979;&#65292;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20808;&#39564;&#23545;&#20110;&#37325;&#24314;&#25104;&#21151;&#20855;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07588v1 &#22768;&#26126;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22270;&#20687;&#37325;&#24314;&#25915;&#20987;&#21487;&#33021;&#20250;&#23548;&#33268;&#27844;&#38706;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23545;&#38544;&#31169;&#26500;&#25104;&#37325;&#22823;&#39118;&#38505;&#12290;&#34429;&#28982;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;(DP)&#26469;&#25269;&#24481;&#27492;&#31867;&#25915;&#20987;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#30830;&#23450;&#36866;&#24403;&#30340;DP&#21442;&#25968;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#24403;&#21069;&#23545;&#25968;&#25454;&#37325;&#24314;&#25104;&#21151;&#30340;&#24418;&#24335;&#21270;&#20445;&#35777;&#21463;&#21040;&#20102;&#20851;&#20110;&#23545;&#25163;&#23545;&#30446;&#26631;&#25968;&#25454;&#30340;&#20102;&#35299;&#30340;&#36807;&#20110;&#29702;&#35770;&#21270;&#30340;&#20551;&#35774;&#30340;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#22312;&#22270;&#20687;&#39046;&#22495;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#35843;&#26597;&#36825;&#19968;&#24046;&#24322;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#20551;&#35774;&#30340;&#23454;&#38469;&#24615;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#25968;&#25454;&#20808;&#39564;&#21644;&#37325;&#24314;&#30446;&#26631;&#20043;&#38388;&#30340;&#22495;&#36716;&#31227;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;(DMs)&#30340;&#37325;&#24314;&#25915;&#20987;&#65292;&#20551;&#35774;&#23545;&#25163;&#21487;&#20197;&#35775;&#38382;&#30495;&#23454;&#19990;&#30028;&#30340;&#22270;&#20687;&#20808;&#39564;&#65292;&#24182;&#35780;&#20272;&#20854;&#23545;&#22312;DP-SGD&#19979;&#30340;&#38544;&#31169;&#27844;&#38706;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;(1)&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20808;&#39564;&#26174;&#33879;&#24433;&#21709;&#37325;&#24314;&#25104;&#21151;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07588v1 Announce Type: new  Abstract: Image reconstruction attacks on machine learning models pose a significant risk to privacy by potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) has proven effective, determining appropriate DP parameters remains challenging. Current formal guarantees on data reconstruction success suffer from overly theoretical assumptions regarding adversary knowledge about the target data, particularly in the image domain. In this work, we empirically investigate this discrepancy and find that the practicality of these assumptions strongly depends on the domain shift between the data prior and the reconstruction target. We propose a reconstruction attack based on diffusion models (DMs) that assumes adversary access to real-world image priors and assess its implications on privacy leakage under DP-SGD. We show that (1) real-world data priors significantly influence reconstruction success, 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2312.09481</link><description>&lt;p&gt;
&#25345;&#32493;&#19981;&#26029;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Continual Adversarial Defense
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09481
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#27599;&#26376;&#38024;&#23545;&#35270;&#35273;&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#24555;&#36895;&#28436;&#21464;&#30340;&#29305;&#24615;&#65292;&#20154;&#20204;&#25552;&#20986;&#20102;&#35768;&#22810;&#38450;&#24481;&#26041;&#27861;&#65292;&#26088;&#22312;&#23613;&#21487;&#33021;&#36890;&#29992;&#21270;&#20197;&#25269;&#24481;&#23613;&#21487;&#33021;&#22810;&#30340;&#24050;&#30693;&#25915;&#20987;&#12290;&#28982;&#32780;&#65292;&#35774;&#35745;&#19968;&#20010;&#33021;&#22815;&#23545;&#25239;&#25152;&#26377;&#31867;&#22411;&#25915;&#20987;&#30340;&#38450;&#24481;&#26041;&#27861;&#24182;&#19981;&#29616;&#23454;&#65292;&#22240;&#20026;&#38450;&#24481;&#31995;&#32479;&#36816;&#34892;&#30340;&#29615;&#22659;&#26159;&#21160;&#24577;&#30340;&#65292;&#21253;&#21547;&#38543;&#30528;&#26102;&#38388;&#20986;&#29616;&#30340;&#21508;&#31181;&#29420;&#29305;&#25915;&#20987;&#12290;&#38450;&#24481;&#31995;&#32479;&#24517;&#39035;&#25910;&#38598;&#22312;&#32447;&#23569;&#26679;&#26412;&#23545;&#25239;&#21453;&#39304;&#20197;&#36805;&#36895;&#22686;&#24378;&#33258;&#36523;&#65292;&#20805;&#20998;&#21033;&#29992;&#20869;&#23384;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#65292;&#20854;&#20013;&#21508;&#31181;&#25915;&#20987;&#36880;&#20010;&#38454;&#27573;&#20986;&#29616;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;CAD&#22522;&#20110;&#22235;&#39033;&#21407;&#21017;&#36827;&#34892;&#24314;&#27169;&#65306;(1) &#25345;&#32493;&#36866;&#24212;&#26032;&#25915;&#20987;&#32780;&#26080;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;(2) &#23569;&#26679;&#26412;&#36866;&#24212;&#65292;(3) &#20869;&#23384;&#39640;&#25928;&#36866;&#24212;&#65292;&#20197;&#21450;(4) &#39640;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09481v2 Announce Type: replace-cross  Abstract: In response to the rapidly evolving nature of adversarial attacks against visual classifiers on a monthly basis, numerous defenses have been proposed to generalize against as many known attacks as possible. However, designing a defense method that generalizes to all types of attacks is not realistic because the environment in which defense systems operate is dynamic and comprises various unique attacks that emerge as time goes on. The defense system must gather online few-shot defense feedback to promptly enhance itself, leveraging efficient memory utilization. Therefore, we propose the first continual adversarial defense (CAD) framework that adapts to any attacks in a dynamic scenario, where various attacks emerge stage by stage. In practice, CAD is modeled under four principles: (1) continual adaptation to new attacks without catastrophic forgetting, (2) few-shot adaptation, (3) memory-efficient adaptation, and (4) high accur
&lt;/p&gt;</description></item></channel></rss>