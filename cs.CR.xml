<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#22312;&#29983;&#29289;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#36827;&#34892;&#38646;&#26679;&#26412;&#37319;&#26679;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#21457;&#29616;&#21508;&#31181;&#23545;&#25239;&#23454;&#20307;&#20316;&#20026;&#24178;&#25200;&#22240;&#32032;&#65292;&#30456;&#27604;&#38543;&#26426;&#37319;&#26679;&#65292;&#22312;&#23545;&#25239;&#38382;&#31572;&#20013;&#34920;&#29616;&#20986;&#26126;&#26174;&#20248;&#21183;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#29305;&#24449;&#30340;&#20004;&#31181;&#23545;&#25239;&#24615;&#23454;&#20307;&#21046;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.10527</link><description>&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#38646;&#26679;&#26412;&#37319;&#26679;&#23545;&#25239;&#23454;&#20307;
&lt;/p&gt;
&lt;p&gt;
Zero-shot sampling of adversarial entities in biomedical question answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10527
&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#29289;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#36827;&#34892;&#38646;&#26679;&#26412;&#37319;&#26679;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#21457;&#29616;&#21508;&#31181;&#23545;&#25239;&#23454;&#20307;&#20316;&#20026;&#24178;&#25200;&#22240;&#32032;&#65292;&#30456;&#27604;&#38543;&#26426;&#37319;&#26679;&#65292;&#22312;&#23545;&#25239;&#38382;&#31572;&#20013;&#34920;&#29616;&#20986;&#26126;&#26174;&#20248;&#21183;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#29305;&#24449;&#30340;&#20004;&#31181;&#23545;&#25239;&#24615;&#23454;&#20307;&#21046;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#21442;&#25968;&#22495;&#30693;&#35782;&#30340;&#22686;&#21152;&#28145;&#24230;&#25512;&#21160;&#23427;&#20204;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#24555;&#36895;&#37096;&#32626;&#12290;&#22312;&#39640;&#39118;&#38505;&#21644;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#20013;&#65292;&#29702;&#35299;&#27169;&#22411;&#30340;&#28431;&#27934;&#23545;&#20110;&#37327;&#21270;&#27169;&#22411;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#21644;&#35268;&#33539;&#20854;&#20351;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#21457;&#29616;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#20316;&#20026;&#23545;&#25239;&#31034;&#20363;&#30340;&#21629;&#21517;&#23454;&#20307;&#24341;&#21457;&#20102;&#20851;&#20110;&#23427;&#20204;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#21487;&#33021;&#30340;&#20266;&#35013;&#30340;&#30097;&#38382;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#24130;&#32553;&#25918;&#36317;&#31163;&#21152;&#26435;&#37319;&#26679;&#26041;&#26696;&#65292;&#20197;&#21457;&#29616;&#22810;&#26679;&#21270;&#30340;&#23545;&#25239;&#23454;&#20307;&#20316;&#20026;&#24178;&#25200;&#22240;&#32032;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#29983;&#29289;&#21307;&#23398;&#20027;&#39064;&#30340;&#23545;&#25239;&#24615;&#38382;&#39064;&#22238;&#31572;&#20013;&#20248;&#20110;&#38543;&#26426;&#37319;&#26679;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#21487;&#20197;&#25506;&#32034;&#25915;&#20987;&#34920;&#38754;&#19978;&#30340;&#19981;&#21516;&#21306;&#22495;&#65292;&#36825;&#25581;&#31034;&#20102;&#20004;&#31181;&#22312;&#29305;&#24449;&#19978;&#26126;&#26174;&#19981;&#21516;&#30340;&#23545;&#25239;&#24615;&#23454;&#20307;&#30340;&#21046;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25915;&#20987;&#26041;&#24335;&#22914;&#20309;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10527v1 Announce Type: new  Abstract: The increasing depth of parametric domain knowledge in large language models (LLMs) is fueling their rapid deployment in real-world applications. In high-stakes and knowledge-intensive tasks, understanding model vulnerabilities is essential for quantifying the trustworthiness of model predictions and regulating their use. The recent discovery of named entities as adversarial examples in natural language processing tasks raises questions about their potential guises in other settings. Here, we propose a powerscaled distance-weighted sampling scheme in embedding space to discover diverse adversarial entities as distractors. We demonstrate its advantage over random sampling in adversarial question answering on biomedical topics. Our approach enables the exploration of different regions on the attack surface, which reveals two regimes of adversarial entities that markedly differ in their characteristics. Moreover, we show that the attacks su
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeepInception&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#35282;&#33394;&#25198;&#28436;&#33021;&#21147;&#26500;&#24314;&#26032;&#39062;&#30340;&#23884;&#22871;&#22330;&#26223;&#65292;&#25104;&#21151;&#20652;&#30496;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#30772;&#35299;&#32773;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;DeepInception&#22312;&#30772;&#35299;&#25104;&#21151;&#29575;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#24320;&#28304;&#21644;&#38381;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#38190;&#24369;&#28857;&#12290;</title><link>https://arxiv.org/abs/2311.03191</link><description>&lt;p&gt;
DeepInception: &#20652;&#30496;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#30772;&#35299;&#32773;
&lt;/p&gt;
&lt;p&gt;
DeepInception: Hypnotize Large Language Model to Be Jailbreaker
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeepInception&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#35282;&#33394;&#25198;&#28436;&#33021;&#21147;&#26500;&#24314;&#26032;&#39062;&#30340;&#23884;&#22871;&#22330;&#26223;&#65292;&#25104;&#21151;&#20652;&#30496;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#30772;&#35299;&#32773;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;DeepInception&#22312;&#30772;&#35299;&#25104;&#21151;&#29575;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#24320;&#28304;&#21644;&#38381;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#38190;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#21463;&#21040;&#30772;&#35299;&#25915;&#20987;&#65292;&#20351;&#24471;&#23433;&#20840;&#25514;&#26045;&#26080;&#25928;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#30772;&#35299;&#30740;&#31350;&#36890;&#24120;&#37319;&#29992;&#26292;&#21147;&#20248;&#21270;&#25110;&#39640;&#35745;&#31639;&#25104;&#26412;&#30340;&#22806;&#25512;&#26041;&#27861;&#65292;&#36825;&#21487;&#33021;&#24182;&#19981;&#23454;&#38469;&#25110;&#26377;&#25928;&#12290;&#26412;&#25991;&#21463;&#21040;&#20197;&#31859;&#23572;&#26684;&#25289;&#22982;&#23454;&#39564;&#20026;&#28789;&#24863;&#65292;&#20851;&#20110;&#26435;&#23041;&#21147;&#37327;&#23545;&#20110;&#24341;&#21457;&#26377;&#23475;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;DeepInception&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#20652;&#30496;LLM&#25104;&#20026;&#30772;&#35299;&#32773;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;DeepInception&#21033;&#29992;LLM&#30340;&#35282;&#33394;&#25198;&#28436;&#33021;&#21147;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23884;&#22871;&#22330;&#26223;&#26469;&#34892;&#20026;&#65292;&#23454;&#29616;&#20102;&#22312;&#27491;&#24120;&#22330;&#26223;&#19979;&#36867;&#36991;&#20351;&#29992;&#25511;&#21046;&#30340;&#33258;&#36866;&#24212;&#26041;&#24335;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;DeepInception&#22312;&#30772;&#35299;&#25104;&#21151;&#29575;&#26041;&#38754;&#19982;&#20197;&#24448;&#30340;&#26041;&#27861;&#31454;&#20105;&#21147;&#30456;&#24403;&#65292;&#24182;&#21487;&#20197;&#22312;&#21518;&#32493;&#20132;&#20114;&#20013;&#23454;&#29616;&#25345;&#32493;&#30340;&#30772;&#35299;&#65292;&#25581;&#31034;&#20102;&#24320;&#28304;&#21644;&#38381;&#28304;LLM&#30340;&#33258;&#22833;&#20851;&#38190;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite remarkable success in various applications, large language models (LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails void. However, previous studies for jailbreaks usually resort to brute-force optimization or extrapolations of a high computation cost, which might not be practical or effective. In this paper, inspired by the Milgram experiment w.r.t. the authority power for inciting harmfulness, we disclose a lightweight method, termed DeepInception, which can easily hypnotize LLM to be a jailbreaker. Specifically, DeepInception leverages the personification ability of LLM to construct a novel nested scene to behave, which realizes an adaptive way to escape the usage control in a normal scenario. Empirically, our DeepInception can achieve competitive jailbreak success rates with previous counterparts and realize a continuous jailbreak in subsequent interactions, which reveals the critical weakness of self-losing on both open and closed-source LLMs l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.15295</link><description>&lt;p&gt;
&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#65306;&#26356;&#22810;&#35302;&#21457;&#22120;&#65292;&#26356;&#22810;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
Multi-Trigger Backdoor Attacks: More Triggers, More Threats. (arXiv:2401.15295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#38376;&#25915;&#20987;&#24050;&#32463;&#25104;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#65288;&#39044;&#65289;&#35757;&#32451;&#21644;&#37096;&#32626;&#30340;&#20027;&#35201;&#23041;&#32961;&#12290;&#23613;&#31649;&#21518;&#38376;&#25915;&#20987;&#22312;&#19968;&#20123;&#30740;&#31350;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#25506;&#35752;&#65292;&#20294;&#20854;&#20013;&#22823;&#37096;&#20998;&#37117;&#38598;&#20013;&#22312;&#20351;&#29992;&#21333;&#20010;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#25968;&#25454;&#38598;&#30340;&#21333;&#35302;&#21457;&#25915;&#20987;&#19978;&#12290;&#21487;&#20197;&#35828;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#21518;&#38376;&#25915;&#20987;&#21487;&#33021;&#26356;&#21152;&#22797;&#26434;&#65292;&#20363;&#22914;&#65292;&#21516;&#19968;&#25968;&#25454;&#38598;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#23545;&#25163;&#65292;&#22914;&#26524;&#35813;&#25968;&#25454;&#38598;&#20855;&#26377;&#36739;&#39640;&#30340;&#20215;&#20540;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#35302;&#21457;&#25915;&#20987;&#35774;&#32622;&#19979;&#21518;&#38376;&#25915;&#20987;&#30340;&#23454;&#38469;&#23041;&#32961;&#65292;&#22810;&#20010;&#23545;&#25163;&#21033;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#21516;&#19968;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25552;&#20986;&#21644;&#30740;&#31350;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#36825;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#30340;&#37325;&#35201;&#35748;&#35782;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21333;&#35302;&#21457;&#25915;&#20987;&#24448;&#24448;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Backdoor attacks have emerged as a primary threat to (pre-)training and deployment of deep neural networks (DNNs). While backdoor attacks have been extensively studied in a body of works, most of them were focused on single-trigger attacks that poison a dataset using a single type of trigger. Arguably, real-world backdoor attacks can be much more complex, e.g., the existence of multiple adversaries for the same dataset if it is of high value. In this work, we investigate the practical threat of backdoor attacks under the setting of \textbf{multi-trigger attacks} where multiple adversaries leverage different types of triggers to poison the same dataset. By proposing and investigating three types of multi-trigger attacks, including parallel, sequential, and hybrid attacks, we provide a set of important understandings of the coexisting, overwriting, and cross-activating effects between different triggers on the same dataset. Moreover, we show that single-trigger attacks tend to cause over
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Adversarial ModSecurity&#65292;&#23427;&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26469;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#38450;&#28779;&#22681;&#12290;&#36890;&#36807;&#23558;&#26680;&#24515;&#35268;&#21017;&#38598;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#35782;&#21035;&#24182;&#38450;&#24481;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AdvModSec&#22312;&#35757;&#32451;&#21518;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#36825;&#31867;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2308.04964</link><description>&lt;p&gt;
Adversarial ModSecurity: &#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning. (arXiv:2308.04964v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04964
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Adversarial ModSecurity&#65292;&#23427;&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26469;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#38450;&#28779;&#22681;&#12290;&#36890;&#36807;&#23558;&#26680;&#24515;&#35268;&#21017;&#38598;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#35782;&#21035;&#24182;&#38450;&#24481;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AdvModSec&#22312;&#35757;&#32451;&#21518;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#36825;&#31867;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ModSecurity&#34987;&#24191;&#27867;&#35748;&#21487;&#20026;&#26631;&#20934;&#30340;&#24320;&#28304;Web&#24212;&#29992;&#38450;&#28779;&#22681;(WAF)&#65292;&#30001;OWASP&#22522;&#37329;&#20250;&#32500;&#25252;&#12290;&#23427;&#36890;&#36807;&#19982;&#26680;&#24515;&#35268;&#21017;&#38598;&#36827;&#34892;&#21305;&#37197;&#26469;&#26816;&#27979;&#24694;&#24847;&#35831;&#27714;&#65292;&#35782;&#21035;&#20986;&#24120;&#35265;&#30340;&#25915;&#20987;&#27169;&#24335;&#12290;&#27599;&#20010;&#35268;&#21017;&#22312;CRS&#20013;&#37117;&#34987;&#25163;&#21160;&#20998;&#37197;&#19968;&#20010;&#26435;&#37325;&#65292;&#22522;&#20110;&#30456;&#24212;&#25915;&#20987;&#30340;&#20005;&#37325;&#31243;&#24230;&#65292;&#22914;&#26524;&#35302;&#21457;&#35268;&#21017;&#30340;&#26435;&#37325;&#20043;&#21644;&#36229;&#36807;&#32473;&#23450;&#30340;&#38408;&#20540;&#65292;&#23601;&#20250;&#34987;&#26816;&#27979;&#20026;&#24694;&#24847;&#35831;&#27714;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#31616;&#21333;&#30340;&#31574;&#30053;&#22312;&#26816;&#27979;SQL&#27880;&#20837;&#25915;&#20987;&#26041;&#38754;&#24456;&#19981;&#26377;&#25928;&#65292;&#22240;&#20026;&#23427;&#24448;&#24448;&#20250;&#38459;&#27490;&#35768;&#22810;&#21512;&#27861;&#35831;&#27714;&#65292;&#21516;&#26102;&#36824;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#21363;&#25925;&#24847;&#25805;&#32437;&#20197;&#36867;&#36991;&#26816;&#27979;&#30340;&#25915;&#20987;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026;AdvModSec&#30340;&#24378;&#22823;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#23558;CRS&#35268;&#21017;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#24182;&#32463;&#36807;&#35757;&#32451;&#20197;&#26816;&#27979;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;AdvModSec&#22312;&#38024;&#23545;&#35813;&#25915;&#20987;&#30340;&#27969;&#37327;&#19978;&#36827;&#34892;&#35757;&#32451;&#21518;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
ModSecurity is widely recognized as the standard open-source Web Application Firewall (WAF), maintained by the OWASP Foundation. It detects malicious requests by matching them against the Core Rule Set, identifying well-known attack patterns. Each rule in the CRS is manually assigned a weight, based on the severity of the corresponding attack, and a request is detected as malicious if the sum of the weights of the firing rules exceeds a given threshold. In this work, we show that this simple strategy is largely ineffective for detecting SQL injection (SQLi) attacks, as it tends to block many legitimate requests, while also being vulnerable to adversarial SQLi attacks, i.e., attacks intentionally manipulated to evade detection. To overcome these issues, we design a robust machine learning model, named AdvModSec, which uses the CRS rules as input features, and it is trained to detect adversarial SQLi attacks. Our experiments show that AdvModSec, being trained on the traffic directed towa
&lt;/p&gt;</description></item></channel></rss>