<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#22810;&#22238;&#21512;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#30475;&#20284;&#33391;&#24615;&#30340;&#23545;&#35805;&#26041;&#24335;&#36880;&#28176;&#21319;&#32423;&#19982;&#27169;&#22411;&#30340;&#20132;&#20114;&#65292;&#25104;&#21151;&#31361;&#30772;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2404.01833</link><description>&lt;p&gt;
&#20255;&#22823;&#65292;&#29616;&#22312;&#20889;&#19968;&#31687;&#20851;&#20110;&#27492;&#30340;&#25991;&#31456;&#65306;Crescendo&#22810;&#22238;&#21512;LLM&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01833
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#22810;&#22238;&#21512;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#30475;&#20284;&#33391;&#24615;&#30340;&#23545;&#35805;&#26041;&#24335;&#36880;&#28176;&#21319;&#32423;&#19982;&#27169;&#22411;&#30340;&#20132;&#20114;&#65292;&#25104;&#21151;&#31361;&#30772;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27969;&#34892;&#31243;&#24230;&#22823;&#24133;&#19978;&#21319;&#65292;&#24182;&#19988;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#24212;&#29992;&#20110;&#22810;&#20010;&#39046;&#22495;&#12290;&#36825;&#20123;LLMs&#22312;&#35774;&#35745;&#19978;&#36991;&#20813;&#28041;&#21450;&#38750;&#27861;&#25110;&#19981;&#36947;&#24503;&#30340;&#35805;&#39064;&#65292;&#20197;&#36991;&#20813;&#23545;&#36127;&#36131;&#20219;&#30340;AI&#36896;&#25104;&#20260;&#23475;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#20986;&#29616;&#20102;&#19968;&#31995;&#21015;&#25915;&#20987;&#65292;&#34987;&#31216;&#20026;&#8220;&#36234;&#29425;&#8221;&#65292;&#26088;&#22312;&#31361;&#30772;&#36825;&#31181;&#23545;&#40784;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#36234;&#29425;&#25915;&#20987;&#26088;&#22312;&#32553;&#23567;&#27169;&#22411;&#33021;&#20570;&#30340;&#19982;&#24895;&#24847;&#20570;&#30340;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#36234;&#29425;&#25915;&#20987;&#12290;&#19982;&#29616;&#26377;&#30340;&#36234;&#29425;&#26041;&#27861;&#19981;&#21516;&#65292;Crescendo&#26159;&#19968;&#31181;&#22810;&#22238;&#21512;&#36234;&#29425;&#65292;&#20197;&#19968;&#31181;&#30475;&#20284;&#33391;&#24615;&#30340;&#26041;&#24335;&#19982;&#27169;&#22411;&#36827;&#34892;&#20132;&#20114;&#12290;&#23427;&#20174;&#26377;&#20851;&#25163;&#22836;&#20219;&#21153;&#30340;&#19968;&#33324;&#25552;&#31034;&#25110;&#38382;&#39064;&#24320;&#22987;&#65292;&#28982;&#21518;&#36880;&#28176;&#21319;&#32423;&#23545;&#35805;&#65292;&#24341;&#29992;&#27169;&#22411;&#30340;&#22238;&#22797;&#65292;&#36880;&#28176;&#23548;&#33268;&#25104;&#21151;&#36234;&#29425;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;ChatGPT&#12289;Gemini Pr&#22312;&#20869;&#30340;&#21508;&#31181;&#20844;&#20849;&#31995;&#32479;&#19978;&#35780;&#20272;&#20102;Crescendo&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01833v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications. These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms. However, a recent line of attacks, known as "jailbreaks", seek to overcome this alignment. Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do. In this paper, we introduce a novel jailbreak attack called Crescendo. Unlike existing jailbreak methods, Crescendo is a multi-turn jailbreak that interacts with the model in a seemingly benign manner. It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies, progressively leading to a successful jailbreak. We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pr
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Syntactic Ghost&#30340;&#26032;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26080;&#24863;&#30693;&#21644;&#36890;&#29992;&#30340;&#21518;&#38376;&#26893;&#20837;&#12290;</title><link>https://arxiv.org/abs/2402.18945</link><description>&lt;p&gt;
Syntactic Ghost&#65306;&#19968;&#31181;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#30340;&#26080;&#24863;&#30693;&#36890;&#29992;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18945
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Syntactic Ghost&#30340;&#26032;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26080;&#24863;&#30693;&#21644;&#36890;&#29992;&#30340;&#21518;&#38376;&#26893;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#34987;&#21457;&#29616;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#65292;&#21487;&#20197;&#23558;&#28431;&#27934;&#36716;&#31227;&#21040;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;PLM&#21518;&#38376;&#25915;&#20987;&#37319;&#29992;&#26126;&#26174;&#30340;&#35302;&#21457;&#22120;&#65292;&#22312;&#25163;&#21160;&#23545;&#20934;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#65292;&#22240;&#27492;&#22312;&#25928;&#26524;&#12289;&#38544;&#21311;&#24615;&#21644;&#36890;&#29992;&#24615;&#26041;&#38754;&#26080;&#27861;&#21516;&#26102;&#28385;&#36275;&#26399;&#26395;&#30446;&#26631;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19981;&#21487;&#35265;&#21644;&#36890;&#29992;&#30340;&#21518;&#38376;&#26893;&#20837;&#65292;&#31216;&#20026;Syntactic Ghost&#65288;&#31616;&#31216;&#20026;synGhost&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#35813;&#26041;&#27861;&#25932;&#24847;&#22320;&#20351;&#29992;&#20855;&#26377;&#19981;&#21516;&#39044;&#23450;&#20041;&#21477;&#27861;&#32467;&#26500;&#30340;&#27602;&#23475;&#26679;&#26412;&#20316;&#20026;&#38544;&#34109;&#35302;&#21457;&#22120;&#65292;&#28982;&#21518;&#23558;&#21518;&#38376;&#26893;&#20837;&#21040;&#39044;&#35757;&#32451;&#34920;&#31034;&#31354;&#38388;&#65292;&#32780;&#19981;&#20250;&#30772;&#22351;&#21407;&#22987;&#30693;&#35782;&#12290;&#27602;&#23475;&#26679;&#26412;&#30340;&#36755;&#20986;&#34920;&#31034;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23613;&#21487;&#33021;&#22343;&#21248;&#22320;&#20998;&#24067;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#24418;&#25104;&#24191;&#27867;&#30340;&#21518;&#38376;&#12290;&#27492;&#22806;&#65292;&#22312;&#20142;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18945v1 Announce Type: cross  Abstract: Pre-trained language models (PLMs) have been found susceptible to backdoor attacks, which can transfer vulnerabilities to various downstream tasks. However, existing PLM backdoors are conducted with explicit triggers under the manually aligned, thus failing to satisfy expectation goals simultaneously in terms of effectiveness, stealthiness, and universality. In this paper, we propose a novel approach to achieve invisible and general backdoor implantation, called \textbf{Syntactic Ghost} (synGhost for short). Specifically, the method hostilely manipulates poisoned samples with different predefined syntactic structures as stealth triggers and then implants the backdoor to pre-trained representation space without disturbing the primitive knowledge. The output representations of poisoned samples are distributed as uniformly as possible in the feature space via contrastive learning, forming a wide range of backdoors. Additionally, in light 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Permute-and-Flip&#65288;PF&#65289;&#35299;&#30721;&#22120;&#65292;&#20854;&#20855;&#26377;&#26368;&#20339;&#30340;&#40065;&#26834;&#24615;&#21644;&#36136;&#37327;-&#40065;&#26834;&#24615;&#30340; tradeoff&#65292;&#19988;&#27604;&#37319;&#26679;&#26041;&#27861;&#26356;&#22909;&#12290;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#38024;&#23545;PF&#35299;&#30721;&#22120;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#20445;&#25345;&#26679;&#26412;&#30340;&#20998;&#24067;&#19981;&#21464;&#65292;&#24182;&#23454;&#29616;&#20219;&#24847;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#21644;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;PF&#35299;&#30721;&#22120;&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#26420;&#32032;&#37319;&#26679;&#65292;&#20026;LLM&#35299;&#30721;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.05864</link><description>&lt;p&gt;
Permute-and-Flip&#65306;&#19968;&#31181;&#20855;&#26377;&#26368;&#20339;&#40065;&#26834;&#24615;&#21644;&#21487;&#21152;&#27700;&#21360;&#30340;LLMs&#35299;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05864
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Permute-and-Flip&#65288;PF&#65289;&#35299;&#30721;&#22120;&#65292;&#20854;&#20855;&#26377;&#26368;&#20339;&#30340;&#40065;&#26834;&#24615;&#21644;&#36136;&#37327;-&#40065;&#26834;&#24615;&#30340; tradeoff&#65292;&#19988;&#27604;&#37319;&#26679;&#26041;&#27861;&#26356;&#22909;&#12290;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#38024;&#23545;PF&#35299;&#30721;&#22120;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#20445;&#25345;&#26679;&#26412;&#30340;&#20998;&#24067;&#19981;&#21464;&#65292;&#24182;&#23454;&#29616;&#20219;&#24847;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#21644;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;PF&#35299;&#30721;&#22120;&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#26420;&#32032;&#37319;&#26679;&#65292;&#20026;LLM&#35299;&#30721;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Permute-and-Flip&#65288;PF&#65289;&#35299;&#30721;&#22120;&#30340;&#26032;&#35299;&#30721;&#26041;&#27861;&#12290;&#23427;&#20855;&#26377;&#19982;&#26631;&#20934;&#37319;&#26679;&#35299;&#30721;&#22120;&#30456;&#20284;&#30340;&#40065;&#26834;&#24615;&#29305;&#24615;&#65292;&#20294;&#22312;&#36136;&#37327;&#21644;&#40065;&#26834;&#24615;&#30340; tradeoff &#19978;&#35777;&#26126;&#27604;&#37319;&#26679;&#26041;&#27861;&#26356;&#22909;&#65292;&#19988;&#27704;&#36828;&#19981;&#20250;&#24046;&#20110;&#20219;&#20309;&#20854;&#20182;&#35299;&#30721;&#22120;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;Aaronson&#30340;Gumbel&#27700;&#21360;&#30340;&#21152;&#23494;&#27700;&#21360;&#26041;&#26696;&#65292;&#20294;&#26159;&#38024;&#23545;PF&#35299;&#30721;&#22120;&#32780;&#33258;&#28982;&#37327;&#36523;&#23450;&#21046;&#12290;&#35813;&#27700;&#21360;&#26041;&#26696;&#19981;&#25913;&#21464;&#26679;&#26412;&#30340;&#20998;&#24067;&#65292;&#21516;&#26102;&#20801;&#35768;&#20219;&#24847;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#21644;&#39640;&#30340;&#21484;&#22238;&#29575;&#65292;&#21482;&#35201;&#29983;&#25104;&#30340;&#25991;&#26412;&#20855;&#26377;&#39640;&#29109;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;PF&#35299;&#30721;&#22120;&#65288;&#21450;&#20854;&#24102;&#26377;&#27700;&#21360;&#30340;&#23545;&#24212;&#29289;&#65289;&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#26420;&#32032;&#37319;&#26679;&#65288;&#21450;&#20854;&#24102;&#26377;Gumbel&#27700;&#21360;&#30340;&#23545;&#24212;&#29289;&#65289;&#65292;&#21516;&#26102;&#20445;&#25345;&#30456;&#21516;&#30340;&#40065;&#26834;&#24615;&#65288;&#21644;&#21487;&#26816;&#27979;&#24615;&#65289;&#65292;&#22240;&#27492;&#20026;LLM&#35299;&#30721;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26032;&#26041;&#27861;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/XuandongZhao/pf-decoding&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a new decoding method called Permute-and-Flip (PF) decoder. It enjoys robustness properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-robustness tradeoff than sampling and never worse than any other decoder. We also design a cryptographic watermarking scheme analogous to Aaronson's Gumbel watermark, but naturally tailored for PF decoder. The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall whenever the generated text has high entropy. Our experiments show that the PF decoder (and its watermarked counterpart) significantly outperform(s) naive sampling (and it's Gumbel watermarked counterpart) in terms of perplexity, while retaining the same robustness (and detectability), hence making it a promising new approach for LLM decoding. The code is available at https://github.com/XuandongZhao/pf-decoding
&lt;/p&gt;</description></item></channel></rss>