<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Permute-and-Flip&#65288;PF&#65289;&#35299;&#30721;&#22120;&#65292;&#20854;&#20855;&#26377;&#26368;&#20339;&#30340;&#40065;&#26834;&#24615;&#21644;&#36136;&#37327;-&#40065;&#26834;&#24615;&#30340; tradeoff&#65292;&#19988;&#27604;&#37319;&#26679;&#26041;&#27861;&#26356;&#22909;&#12290;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#38024;&#23545;PF&#35299;&#30721;&#22120;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#20445;&#25345;&#26679;&#26412;&#30340;&#20998;&#24067;&#19981;&#21464;&#65292;&#24182;&#23454;&#29616;&#20219;&#24847;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#21644;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;PF&#35299;&#30721;&#22120;&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#26420;&#32032;&#37319;&#26679;&#65292;&#20026;LLM&#35299;&#30721;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.05864</link><description>&lt;p&gt;
Permute-and-Flip&#65306;&#19968;&#31181;&#20855;&#26377;&#26368;&#20339;&#40065;&#26834;&#24615;&#21644;&#21487;&#21152;&#27700;&#21360;&#30340;LLMs&#35299;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05864
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Permute-and-Flip&#65288;PF&#65289;&#35299;&#30721;&#22120;&#65292;&#20854;&#20855;&#26377;&#26368;&#20339;&#30340;&#40065;&#26834;&#24615;&#21644;&#36136;&#37327;-&#40065;&#26834;&#24615;&#30340; tradeoff&#65292;&#19988;&#27604;&#37319;&#26679;&#26041;&#27861;&#26356;&#22909;&#12290;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#38024;&#23545;PF&#35299;&#30721;&#22120;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#20445;&#25345;&#26679;&#26412;&#30340;&#20998;&#24067;&#19981;&#21464;&#65292;&#24182;&#23454;&#29616;&#20219;&#24847;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#21644;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;PF&#35299;&#30721;&#22120;&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#26420;&#32032;&#37319;&#26679;&#65292;&#20026;LLM&#35299;&#30721;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Permute-and-Flip&#65288;PF&#65289;&#35299;&#30721;&#22120;&#30340;&#26032;&#35299;&#30721;&#26041;&#27861;&#12290;&#23427;&#20855;&#26377;&#19982;&#26631;&#20934;&#37319;&#26679;&#35299;&#30721;&#22120;&#30456;&#20284;&#30340;&#40065;&#26834;&#24615;&#29305;&#24615;&#65292;&#20294;&#22312;&#36136;&#37327;&#21644;&#40065;&#26834;&#24615;&#30340; tradeoff &#19978;&#35777;&#26126;&#27604;&#37319;&#26679;&#26041;&#27861;&#26356;&#22909;&#65292;&#19988;&#27704;&#36828;&#19981;&#20250;&#24046;&#20110;&#20219;&#20309;&#20854;&#20182;&#35299;&#30721;&#22120;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;Aaronson&#30340;Gumbel&#27700;&#21360;&#30340;&#21152;&#23494;&#27700;&#21360;&#26041;&#26696;&#65292;&#20294;&#26159;&#38024;&#23545;PF&#35299;&#30721;&#22120;&#32780;&#33258;&#28982;&#37327;&#36523;&#23450;&#21046;&#12290;&#35813;&#27700;&#21360;&#26041;&#26696;&#19981;&#25913;&#21464;&#26679;&#26412;&#30340;&#20998;&#24067;&#65292;&#21516;&#26102;&#20801;&#35768;&#20219;&#24847;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#21644;&#39640;&#30340;&#21484;&#22238;&#29575;&#65292;&#21482;&#35201;&#29983;&#25104;&#30340;&#25991;&#26412;&#20855;&#26377;&#39640;&#29109;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;PF&#35299;&#30721;&#22120;&#65288;&#21450;&#20854;&#24102;&#26377;&#27700;&#21360;&#30340;&#23545;&#24212;&#29289;&#65289;&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#26420;&#32032;&#37319;&#26679;&#65288;&#21450;&#20854;&#24102;&#26377;Gumbel&#27700;&#21360;&#30340;&#23545;&#24212;&#29289;&#65289;&#65292;&#21516;&#26102;&#20445;&#25345;&#30456;&#21516;&#30340;&#40065;&#26834;&#24615;&#65288;&#21644;&#21487;&#26816;&#27979;&#24615;&#65289;&#65292;&#22240;&#27492;&#20026;LLM&#35299;&#30721;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26032;&#26041;&#27861;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/XuandongZhao/pf-decoding&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a new decoding method called Permute-and-Flip (PF) decoder. It enjoys robustness properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-robustness tradeoff than sampling and never worse than any other decoder. We also design a cryptographic watermarking scheme analogous to Aaronson's Gumbel watermark, but naturally tailored for PF decoder. The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall whenever the generated text has high entropy. Our experiments show that the PF decoder (and its watermarked counterpart) significantly outperform(s) naive sampling (and it's Gumbel watermarked counterpart) in terms of perplexity, while retaining the same robustness (and detectability), hence making it a promising new approach for LLM decoding. The code is available at https://github.com/XuandongZhao/pf-decoding
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#33021;&#21516;&#26102;&#31363;&#21462;&#22810;&#20986;&#21475;&#32593;&#32476;&#27169;&#22411;&#20989;&#25968;&#21644;&#36755;&#20986;&#31574;&#30053;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#21464;&#28857;&#26816;&#27979;&#21644;&#24615;&#33021;&#25439;&#22833;&#12289;&#31574;&#30053;&#25439;&#22833;&#25351;&#23548;&#26367;&#20195;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#36755;&#20986;&#31574;&#30053;&#25628;&#32034;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.13584</link><description>&lt;p&gt;
&#38024;&#23545;&#22810;&#20986;&#21475;&#32593;&#32476;&#30340;&#27169;&#22411;&#31363;&#21462;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Model Stealing Attack against Multi-Exit Networks. (arXiv:2305.13584v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13584
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#33021;&#21516;&#26102;&#31363;&#21462;&#22810;&#20986;&#21475;&#32593;&#32476;&#27169;&#22411;&#20989;&#25968;&#21644;&#36755;&#20986;&#31574;&#30053;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#21464;&#28857;&#26816;&#27979;&#21644;&#24615;&#33021;&#25439;&#22833;&#12289;&#31574;&#30053;&#25439;&#22833;&#25351;&#23548;&#26367;&#20195;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#36755;&#20986;&#31574;&#30053;&#25628;&#32034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20855;&#26377;&#21333;&#20010;&#20986;&#21475;&#30340;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#30456;&#27604;&#65292;&#22810;&#20986;&#21475;&#32593;&#32476;&#20855;&#26377;&#22810;&#20010;&#20986;&#21475;&#65292;&#36825;&#20123;&#20986;&#21475;&#20801;&#35768;&#20174;&#27169;&#22411;&#30340;&#20013;&#38388;&#23618;&#26089;&#26399;&#36755;&#20986;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#31867;&#20284;&#35782;&#21035;&#31934;&#24230;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;&#24403;&#20351;&#29992;&#20256;&#32479;&#30340;&#27169;&#22411;&#31363;&#21462;&#25915;&#20987;&#26041;&#27861;&#23581;&#35797;&#31363;&#21462;&#36825;&#20123;&#26377;&#20215;&#20540;&#30340;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#20256;&#32479;&#26041;&#27861;&#21482;&#33021;&#31363;&#21462;&#27169;&#22411;&#30340;&#20998;&#31867;&#20989;&#25968;&#65292;&#32780;&#19981;&#33021;&#25429;&#25417;&#20854;&#36755;&#20986;&#31574;&#30053;&#12290;&#36825;&#23548;&#33268;&#31363;&#21462;&#30340;&#26367;&#20195;&#27169;&#22411;&#30340;&#35745;&#31639;&#25928;&#29575;&#26174;&#33879;&#38477;&#20302;&#65292;&#22833;&#21435;&#22810;&#20986;&#21475;&#32593;&#32476;&#30340;&#20248;&#28857;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#31363;&#21462;&#27169;&#22411;&#25915;&#20987;&#65292;&#21487;&#20197;&#25552;&#21462;&#27169;&#22411;&#20989;&#25968;&#21644;&#36755;&#20986;&#31574;&#30053;&#12290;&#25105;&#20204;&#37319;&#29992;&#36125;&#21494;&#26031;&#21464;&#28857;&#26816;&#27979;&#26469;&#20998;&#26512;&#30446;&#26631;&#27169;&#22411;&#30340;&#36755;&#20986;&#31574;&#30053;&#65292;&#24182;&#20351;&#29992;&#24615;&#33021;&#25439;&#22833;&#21644;&#31574;&#30053;&#25439;&#22833;&#26469;&#25351;&#23548;&#26367;&#20195;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36755;&#20986;&#31574;&#30053;&#25628;&#32034;&#26041;&#27861;&#65292;&#20197;&#20351;&#26367;&#20195;&#27169;&#22411;&#36824;&#21407;&#31363;&#21462;&#30446;&#26631;&#27169;&#22411;&#30340;&#36755;&#20986;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compared to traditional neural networks with a single exit, a multi-exit network has multiple exits that allow for early output from intermediate layers of the model, thus bringing significant improvement in computational efficiency while maintaining similar recognition accuracy. When attempting to steal such valuable models using traditional model stealing attacks, we found that conventional methods can only steal the model's classification function while failing to capture its output strategy. This results in a significant decrease in computational efficiency for the stolen substitute model, thereby losing the advantages of multi-exit networks.In this paper, we propose the first model stealing attack to extract both the model function and output strategy. We employ bayesian changepoint detection to analyze the target model's output strategy and use performance loss and strategy loss to guide the training of the substitute model. Furthermore, we designed a novel output strategy search
&lt;/p&gt;</description></item></channel></rss>