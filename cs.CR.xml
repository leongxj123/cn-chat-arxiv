<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>RAPT&#26159;&#19968;&#20010;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#25552;&#31034;&#35843;&#25972;&#26694;&#26550;&#65292;&#37319;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#21644;&#26032;&#39062;&#30340;&#38544;&#31169;&#21270;&#26631;&#35760;&#37325;&#24314;&#20219;&#21153;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#21644;&#33391;&#22909;&#30340;&#38544;&#31169;&#20445;&#25252;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.06212</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#38544;&#31169;&#20445;&#25252;&#25552;&#31034;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Prompt Tuning for Large Language Model Services. (arXiv:2305.06212v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06212
&lt;/p&gt;
&lt;p&gt;
RAPT&#26159;&#19968;&#20010;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#25552;&#31034;&#35843;&#25972;&#26694;&#26550;&#65292;&#37319;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#21644;&#26032;&#39062;&#30340;&#38544;&#31169;&#21270;&#26631;&#35760;&#37325;&#24314;&#20219;&#21153;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#21644;&#33391;&#22909;&#30340;&#38544;&#31169;&#20445;&#25252;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#35843;&#25972;&#20026;&#29992;&#25143;&#22312;&#26032;&#20852;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#22330;&#26223;&#19979;&#20351;&#29992;&#20854;&#31169;&#26377;&#25968;&#25454;&#33258;&#23450;&#20041;&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#26377;&#25928;&#26041;&#24335;&#12290;&#20294;&#26159;&#65292;&#31169;&#26377;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#38656;&#35201;&#22312;LLM&#26381;&#21153;&#23450;&#21046;&#20013;&#20445;&#25252;&#38544;&#31169;&#12290;&#22522;&#20110;&#25552;&#31034;&#35843;&#25972;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#25552;&#31034;&#35843;&#25972;(RAPT)&#30340;&#26694;&#26550;&#65292;&#20026;LLM&#26381;&#21153;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#12290;RAPT&#37319;&#29992;&#26412;&#22320;&#38544;&#31169;&#35774;&#32622;&#65292;&#20801;&#35768;&#29992;&#25143;&#20351;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#23545;&#20854;&#25968;&#25454;&#36827;&#34892;&#26412;&#22320;&#21270;&#38544;&#31169;&#22788;&#29702;&#12290;&#30001;&#20110;&#22312;&#30452;&#25509;&#35757;&#32451;&#38544;&#31169;&#21270;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#31034;&#35843;&#25972;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#27492;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38544;&#31169;&#21270;&#26631;&#35760;&#37325;&#24314;&#20219;&#21153;&#65292;&#19982;&#19979;&#28216;&#20219;&#21153;&#19968;&#36215;&#36827;&#34892;&#22521;&#35757;&#65292;&#20351;LLM&#23398;&#20064;&#26356;&#22909;&#30340;&#20219;&#21153;&#30456;&#20851;&#34920;&#31034;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#26694;&#26550;&#31616;&#21333;&#65292;&#20294;&#23454;&#39564;&#34920;&#26126;&#65292;RAPT&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#22343;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#25269;&#24481;&#23545;&#25163;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prompt tuning provides an efficient way for users to customize Large Language Models (LLMs) with their private data in the emerging LLM service scenario. However, the sensitive nature of private data brings the need for privacy preservation in LLM service customization. Based on prompt tuning, we propose Privacy-Preserving Prompt Tuning (RAPT), a framework that provides privacy guarantees for LLM services. \textsc{rapt} adopts a local privacy setting, allowing users to privatize their data locally with local differential privacy. As prompt tuning performs poorly when directly trained on privatized data, we introduce a novel privatized token reconstruction task that is trained jointly with the downstream task, allowing LLMs to learn better task-dependent representations. Despite the simplicity of our framework, experiments show that RAPT achieves competitive performance across tasks while providing privacy guarantees against adversaries.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#19979;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#36716;&#25442;&#24605;&#24819;&#21644;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.03807</link><description>&lt;p&gt;
&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving CNN Training with Transfer Learning. (arXiv:2304.03807v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#19979;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#36716;&#25442;&#24605;&#24819;&#21644;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#30340;&#31070;&#32463;&#32593;&#32476;&#25512;&#29702;&#24050;&#32463;&#24471;&#21040;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#20445;&#25345;&#21516;&#24577;CNN&#35757;&#32451;&#20173;&#28982;&#26159;&#19968;&#39033;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#23454;&#29616;&#22522;&#20110;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#30340;&#38544;&#31169;&#20445;&#25252;CNN&#35757;&#32451;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#27425;&#25104;&#21151;&#31361;&#30772;&#36825;&#20010;&#38590;&#39064;&#65292;&#20197;&#21069;&#27809;&#26377;&#20219;&#20309;&#24037;&#20316;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#12290;&#37319;&#29992;&#20102;&#20960;&#31181;&#25216;&#26415;&#65306;&#65288;1&#65289;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#65292;&#21487;&#20197;&#23558;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#31616;&#21270;&#20026;&#21516;&#24577;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#65292;&#29978;&#33267;&#26159;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#65288;MLR&#65289;&#35757;&#32451;&#65307;&#65288;2&#65289;&#36890;&#36807;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;$\texttt{Quadratic Gradient}$&#65292;&#24212;&#29992;&#20110;MLR&#30340;&#22686;&#24378;&#26799;&#24230;&#26041;&#27861;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65307;&#65288;3&#65289;&#25105;&#20204;&#37319;&#29992;&#25968;&#23398;&#20013;&#30340;&#21464;&#25442;&#24605;&#24819;&#65292;&#23558;&#21152;&#23494;&#22495;&#20013;&#30340;&#36817;&#20284;Softmax&#20989;&#25968;&#36716;&#25442;&#25104;&#24050;&#32463;&#30740;&#31350;&#36807;&#30340;&#36924;&#36817;&#26041;&#27861;&#65292;&#20174;&#32780;&#24471;&#21040;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Privacy-preserving nerual network inference has been well studied while homomorphic CNN training still remains an open challenging task. In this paper, we present a practical solution to implement privacy-preserving CNN training based on mere Homomorphic Encryption (HE) technique. To our best knowledge, this is the first attempt successfully to crack this nut and no work ever before has achieved this goal. Several techniques combine to make it done: (1) with transfer learning, privacy-preserving CNN training can be reduced to homomorphic neural network training, or even multiclass logistic regression (MLR) training; (2) via a faster gradient variant called $\texttt{Quadratic Gradient}$, an enhanced gradient method for MLR with a state-of-the-art performance in converge speed is applied in this work to achieve high performance; (3) we employ the thought of transformation in mathematics to transform approximating Softmax function in encryption domain to the well-studied approximation of 
&lt;/p&gt;</description></item></channel></rss>