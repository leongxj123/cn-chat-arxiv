<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;</title><link>https://arxiv.org/abs/2403.17710</link><description>&lt;p&gt;
&#22522;&#20110;&#20248;&#21270;&#30340;&#23545;LLM&#35780;&#21028;&#31995;&#32479;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Optimization-based Prompt Injection Attack to LLM-as-a-Judge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17710
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLM-as-a-Judge &#26159;&#19968;&#31181;&#21487;&#20197;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#35780;&#20272;&#25991;&#26412;&#20449;&#24687;&#30340;&#26032;&#39062;&#35299;&#20915;&#26041;&#26696;&#12290;&#26681;&#25454;&#29616;&#26377;&#30740;&#31350;&#65292;LLMs&#22312;&#25552;&#20379;&#20256;&#32479;&#20154;&#31867;&#35780;&#20272;&#30340;&#24341;&#20154;&#27880;&#30446;&#26367;&#20195;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#38024;&#23545;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;JudgeDeceiver&#65292;&#19968;&#31181;&#38024;&#23545;LLM-as-a-Judge&#37327;&#36523;&#23450;&#21046;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21046;&#23450;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#29992;&#20110;&#25915;&#20987;LLM-as-a-Judge&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#20248;&#21270;&#31639;&#27861;&#39640;&#25928;&#22320;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#65292;&#23454;&#29616;&#23545;&#27169;&#22411;&#35780;&#20272;&#30340;&#26377;&#38024;&#23545;&#24615;&#21644;&#26377;&#25928;&#30340;&#25805;&#20316;&#12290;&#19982;&#25163;&#24037;&#21046;&#20316;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#21151;&#25928;&#65292;&#32473;&#22522;&#20110;LLM&#30340;&#21028;&#26029;&#31995;&#32479;&#24403;&#21069;&#30340;&#23433;&#20840;&#33539;&#24335;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17710v1 Announce Type: cross  Abstract: LLM-as-a-Judge is a novel solution that can assess textual information with large language models (LLMs). Based on existing research studies, LLMs demonstrate remarkable performance in providing a compelling alternative to traditional human assessment. However, the robustness of these systems against prompt injection attacks remains an open question. In this work, we introduce JudgeDeceiver, a novel optimization-based prompt injection attack tailored to LLM-as-a-Judge. Our method formulates a precise optimization objective for attacking the decision-making process of LLM-as-a-Judge and utilizes an optimization algorithm to efficiently automate the generation of adversarial sequences, achieving targeted and effective manipulation of model evaluations. Compared to handcraft prompt injection attacks, our method demonstrates superior efficacy, posing a significant challenge to the current security paradigms of LLM-based judgment systems. T
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#23618;&#35774;&#35745;&#26032;&#32593;&#32476;&#26550;&#26500;&#20197;&#25552;&#39640;&#23545;&#27169;&#22411;&#36870;&#25512;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.14772</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#26550;&#26500;&#25552;&#39640;&#27169;&#22411;&#36870;&#25512;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving Robustness to Model Inversion Attacks via Sparse Coding Architectures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14772
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#23618;&#35774;&#35745;&#26032;&#32593;&#32476;&#26550;&#26500;&#20197;&#25552;&#39640;&#23545;&#27169;&#22411;&#36870;&#25512;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#27169;&#22411;&#36870;&#25512;&#25915;&#20987;&#31639;&#27861;&#20801;&#35768;&#23545;&#25163;&#36890;&#36807;&#21453;&#22797;&#26597;&#35810;&#31070;&#32463;&#32593;&#32476;&#24182;&#26816;&#26597;&#20854;&#36755;&#20986;&#26469;&#37325;&#24314;&#32593;&#32476;&#30340;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#21033;&#29992;&#31232;&#30095;&#32534;&#30721;&#23618;&#26469;&#33719;&#24471;&#23545;&#36825;&#31867;&#25915;&#20987;&#30340;&#21331;&#36234;&#40065;&#26834;&#24615;&#12290; &#19977;&#21313;&#24180;&#26469;&#65292;&#35745;&#31639;&#26426;&#31185;&#23398;&#30740;&#31350;&#24050;&#32463;&#30740;&#31350;&#20102;&#31232;&#30095;&#32534;&#30721;&#22312;&#22270;&#20687;&#21435;&#22122;&#65292;&#30446;&#26631;&#35782;&#21035;&#21644;&#23545;&#25239;&#24615;&#35823;&#20998;&#35774;&#32622;&#20013;&#30340;&#20316;&#29992;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#20854;&#19982;&#26368;&#20808;&#36827;&#30340;&#38544;&#31169;&#28431;&#27934;&#20043;&#38388;&#30340;&#32852;&#31995;&#23578;&#26410;&#34987;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#31232;&#30095;&#32534;&#30721;&#26550;&#26500;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21033;&#30340;&#25163;&#27573;&#26469;&#25269;&#24481;&#27169;&#22411;&#36870;&#25512;&#25915;&#20987;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#25105;&#20204;&#25511;&#21046;&#32534;&#30721;&#22312;&#32593;&#32476;&#30340;&#20013;&#38388;&#34920;&#31034;&#20013;&#30340;&#26080;&#20851;&#31169;&#20154;&#20449;&#24687;&#30340;&#25968;&#37327;&#65292;&#32780;&#36825;&#31181;&#26041;&#24335;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#39640;&#25928;&#35745;&#31639;&#65292;&#24182;&#19988;&#20247;&#25152;&#21608;&#30693;&#21482;&#26377;&#36739;&#23567;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14772v1 Announce Type: cross  Abstract: Recent model inversion attack algorithms permit adversaries to reconstruct a neural network's private training data just by repeatedly querying the network and inspecting its outputs. In this work, we develop a novel network architecture that leverages sparse-coding layers to obtain superior robustness to this class of attacks. Three decades of computer science research has studied sparse coding in the context of image denoising, object recognition, and adversarial misclassification settings, but to the best of our knowledge, its connection to state-of-the-art privacy vulnerabilities remains unstudied. However, sparse coding architectures suggest an advantageous means to defend against model inversion attacks because they allow us to control the amount of irrelevant private information encoded in a network's intermediate representations in a manner that can be computed efficiently during training and that is known to have little effect
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2312.09481</link><description>&lt;p&gt;
&#25345;&#32493;&#19981;&#26029;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Continual Adversarial Defense
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09481
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#27599;&#26376;&#38024;&#23545;&#35270;&#35273;&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#24555;&#36895;&#28436;&#21464;&#30340;&#29305;&#24615;&#65292;&#20154;&#20204;&#25552;&#20986;&#20102;&#35768;&#22810;&#38450;&#24481;&#26041;&#27861;&#65292;&#26088;&#22312;&#23613;&#21487;&#33021;&#36890;&#29992;&#21270;&#20197;&#25269;&#24481;&#23613;&#21487;&#33021;&#22810;&#30340;&#24050;&#30693;&#25915;&#20987;&#12290;&#28982;&#32780;&#65292;&#35774;&#35745;&#19968;&#20010;&#33021;&#22815;&#23545;&#25239;&#25152;&#26377;&#31867;&#22411;&#25915;&#20987;&#30340;&#38450;&#24481;&#26041;&#27861;&#24182;&#19981;&#29616;&#23454;&#65292;&#22240;&#20026;&#38450;&#24481;&#31995;&#32479;&#36816;&#34892;&#30340;&#29615;&#22659;&#26159;&#21160;&#24577;&#30340;&#65292;&#21253;&#21547;&#38543;&#30528;&#26102;&#38388;&#20986;&#29616;&#30340;&#21508;&#31181;&#29420;&#29305;&#25915;&#20987;&#12290;&#38450;&#24481;&#31995;&#32479;&#24517;&#39035;&#25910;&#38598;&#22312;&#32447;&#23569;&#26679;&#26412;&#23545;&#25239;&#21453;&#39304;&#20197;&#36805;&#36895;&#22686;&#24378;&#33258;&#36523;&#65292;&#20805;&#20998;&#21033;&#29992;&#20869;&#23384;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#65292;&#20854;&#20013;&#21508;&#31181;&#25915;&#20987;&#36880;&#20010;&#38454;&#27573;&#20986;&#29616;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;CAD&#22522;&#20110;&#22235;&#39033;&#21407;&#21017;&#36827;&#34892;&#24314;&#27169;&#65306;(1) &#25345;&#32493;&#36866;&#24212;&#26032;&#25915;&#20987;&#32780;&#26080;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;(2) &#23569;&#26679;&#26412;&#36866;&#24212;&#65292;(3) &#20869;&#23384;&#39640;&#25928;&#36866;&#24212;&#65292;&#20197;&#21450;(4) &#39640;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09481v2 Announce Type: replace-cross  Abstract: In response to the rapidly evolving nature of adversarial attacks against visual classifiers on a monthly basis, numerous defenses have been proposed to generalize against as many known attacks as possible. However, designing a defense method that generalizes to all types of attacks is not realistic because the environment in which defense systems operate is dynamic and comprises various unique attacks that emerge as time goes on. The defense system must gather online few-shot defense feedback to promptly enhance itself, leveraging efficient memory utilization. Therefore, we propose the first continual adversarial defense (CAD) framework that adapts to any attacks in a dynamic scenario, where various attacks emerge stage by stage. In practice, CAD is modeled under four principles: (1) continual adaptation to new attacks without catastrophic forgetting, (2) few-shot adaptation, (3) memory-efficient adaptation, and (4) high accur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23454;&#29616;&#21644;&#35780;&#20272;&#20102;18&#20010;&#20195;&#34920;&#24615;&#30340;&#36807;&#21435;&#30740;&#31350;&#65292;&#24182;&#22312;&#21253;&#21547;124,000&#20010;&#24212;&#29992;&#31243;&#24207;&#30340;&#24179;&#34913;&#12289;&#30456;&#20851;&#21644;&#26368;&#26032;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#26032;&#23454;&#39564;&#65292;&#21457;&#29616;&#20165;&#36890;&#36807;&#38745;&#24577;&#20998;&#26512;&#25552;&#21462;&#30340;&#29305;&#24449;&#23601;&#33021;&#23454;&#29616;&#39640;&#36798;96.8%&#30340;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2301.12778</link><description>&lt;p&gt;
&#25506;&#31350;&#23433;&#21331;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#20013;&#30340;&#29305;&#24449;&#21644;&#27169;&#22411;&#37325;&#35201;&#24615;&#65306;&#19968;&#39033;&#23454;&#26045;&#35843;&#26597;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#39564;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Investigating Feature and Model Importance in Android Malware Detection: An Implemented Survey and Experimental Comparison of ML-Based Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.12778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23454;&#29616;&#21644;&#35780;&#20272;&#20102;18&#20010;&#20195;&#34920;&#24615;&#30340;&#36807;&#21435;&#30740;&#31350;&#65292;&#24182;&#22312;&#21253;&#21547;124,000&#20010;&#24212;&#29992;&#31243;&#24207;&#30340;&#24179;&#34913;&#12289;&#30456;&#20851;&#21644;&#26368;&#26032;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#26032;&#23454;&#39564;&#65292;&#21457;&#29616;&#20165;&#36890;&#36807;&#38745;&#24577;&#20998;&#26512;&#25552;&#21462;&#30340;&#29305;&#24449;&#23601;&#33021;&#23454;&#29616;&#39640;&#36798;96.8%&#30340;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Android&#30340;&#26222;&#21450;&#24847;&#21619;&#30528;&#23427;&#25104;&#20026;&#24694;&#24847;&#36719;&#20214;&#30340;&#24120;&#35265;&#30446;&#26631;&#12290;&#22810;&#24180;&#26469;&#65292;&#21508;&#31181;&#30740;&#31350;&#21457;&#29616;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#21306;&#20998;&#24694;&#24847;&#36719;&#20214;&#21644;&#33391;&#24615;&#24212;&#29992;&#31243;&#24207;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25805;&#20316;&#31995;&#32479;&#30340;&#28436;&#36827;&#65292;&#24694;&#24847;&#36719;&#20214;&#20063;&#22312;&#19981;&#26029;&#21457;&#23637;&#65292;&#23545;&#20808;&#21069;&#30740;&#31350;&#30340;&#21457;&#29616;&#25552;&#20986;&#20102;&#36136;&#30097;&#65292;&#20854;&#20013;&#35768;&#22810;&#25253;&#21578;&#31216;&#20351;&#29992;&#23567;&#22411;&#12289;&#36807;&#26102;&#19988;&#32463;&#24120;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#33021;&#22815;&#33719;&#24471;&#38750;&#24120;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23454;&#29616;&#20102;18&#39033;&#20855;&#20195;&#34920;&#24615;&#30340;&#36807;&#21435;&#30740;&#31350;&#24182;&#20351;&#29992;&#21253;&#25324;124,000&#20010;&#24212;&#29992;&#31243;&#24207;&#30340;&#24179;&#34913;&#12289;&#30456;&#20851;&#19988;&#26368;&#26032;&#30340;&#25968;&#25454;&#38598;&#23545;&#23427;&#20204;&#36827;&#34892;&#37325;&#26032;&#35780;&#20272;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#26032;&#30340;&#23454;&#39564;&#65292;&#20197;&#22635;&#34917;&#29616;&#26377;&#30693;&#35782;&#20013;&#30340;&#31354;&#30333;&#65292;&#24182;&#21033;&#29992;&#30740;&#31350;&#32467;&#26524;&#30830;&#23450;&#22312;&#24403;&#20195;&#29615;&#22659;&#20013;&#29992;&#20110;&#23433;&#21331;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#30340;&#26368;&#26377;&#25928;&#29305;&#24449;&#21644;&#27169;&#22411;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20165;&#36890;&#36807;&#38745;&#24577;&#20998;&#26512;&#25552;&#21462;&#30340;&#29305;&#24449;&#21363;&#21487;&#23454;&#29616;&#39640;&#36798;96.8%&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.12778v2 Announce Type: replace  Abstract: The popularity of Android means it is a common target for malware. Over the years, various studies have found that machine learning models can effectively discriminate malware from benign applications. However, as the operating system evolves, so does malware, bringing into question the findings of these previous studies, many of which report very high accuracies using small, outdated, and often imbalanced datasets. In this paper, we reimplement 18 representative past works and reevaluate them using a balanced, relevant, and up-to-date dataset comprising 124,000 applications. We also carry out new experiments designed to fill holes in existing knowledge, and use our findings to identify the most effective features and models to use for Android malware detection within a contemporary environment. We show that high detection accuracies (up to 96.8%) can be achieved using features extracted through static analysis alone, yielding a mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.15295</link><description>&lt;p&gt;
&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#65306;&#26356;&#22810;&#35302;&#21457;&#22120;&#65292;&#26356;&#22810;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
Multi-Trigger Backdoor Attacks: More Triggers, More Threats. (arXiv:2401.15295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#38376;&#25915;&#20987;&#24050;&#32463;&#25104;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#65288;&#39044;&#65289;&#35757;&#32451;&#21644;&#37096;&#32626;&#30340;&#20027;&#35201;&#23041;&#32961;&#12290;&#23613;&#31649;&#21518;&#38376;&#25915;&#20987;&#22312;&#19968;&#20123;&#30740;&#31350;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#25506;&#35752;&#65292;&#20294;&#20854;&#20013;&#22823;&#37096;&#20998;&#37117;&#38598;&#20013;&#22312;&#20351;&#29992;&#21333;&#20010;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#25968;&#25454;&#38598;&#30340;&#21333;&#35302;&#21457;&#25915;&#20987;&#19978;&#12290;&#21487;&#20197;&#35828;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#21518;&#38376;&#25915;&#20987;&#21487;&#33021;&#26356;&#21152;&#22797;&#26434;&#65292;&#20363;&#22914;&#65292;&#21516;&#19968;&#25968;&#25454;&#38598;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#23545;&#25163;&#65292;&#22914;&#26524;&#35813;&#25968;&#25454;&#38598;&#20855;&#26377;&#36739;&#39640;&#30340;&#20215;&#20540;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#35302;&#21457;&#25915;&#20987;&#35774;&#32622;&#19979;&#21518;&#38376;&#25915;&#20987;&#30340;&#23454;&#38469;&#23041;&#32961;&#65292;&#22810;&#20010;&#23545;&#25163;&#21033;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#21516;&#19968;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25552;&#20986;&#21644;&#30740;&#31350;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#36825;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#30340;&#37325;&#35201;&#35748;&#35782;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21333;&#35302;&#21457;&#25915;&#20987;&#24448;&#24448;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Backdoor attacks have emerged as a primary threat to (pre-)training and deployment of deep neural networks (DNNs). While backdoor attacks have been extensively studied in a body of works, most of them were focused on single-trigger attacks that poison a dataset using a single type of trigger. Arguably, real-world backdoor attacks can be much more complex, e.g., the existence of multiple adversaries for the same dataset if it is of high value. In this work, we investigate the practical threat of backdoor attacks under the setting of \textbf{multi-trigger attacks} where multiple adversaries leverage different types of triggers to poison the same dataset. By proposing and investigating three types of multi-trigger attacks, including parallel, sequential, and hybrid attacks, we provide a set of important understandings of the coexisting, overwriting, and cross-activating effects between different triggers on the same dataset. Moreover, we show that single-trigger attacks tend to cause over
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20445;&#35777;&#26368;&#20248;&#24615;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#20013;&#21516;&#26102;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;&#21644;&#23398;&#20064;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.14094</link><description>&lt;p&gt;
&#20855;&#26377;&#20445;&#35777;&#26368;&#20248;&#24615;&#30340;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Locally Differentially Private Distributed Online Learning with Guaranteed Optimality. (arXiv:2306.14094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20445;&#35777;&#26368;&#20248;&#24615;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#20013;&#21516;&#26102;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;&#21644;&#23398;&#20064;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#30001;&#20110;&#20854;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#27969;&#25968;&#25454;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#38544;&#31169;&#20445;&#25252;&#38382;&#39064;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#20010;&#20154;&#31169;&#23494;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#22823;&#22810;&#25968;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#65292;&#24046;&#20998;&#38544;&#31169;&#24050;&#25104;&#20026;&#38544;&#31169;&#20445;&#25252;&#30340;&#8220;&#40644;&#37329;&#26631;&#20934;&#8221;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#24120;&#24120;&#38754;&#20020;&#20026;&#20102;&#38544;&#31169;&#20445;&#25252;&#32780;&#29306;&#29298;&#23398;&#20064;&#20934;&#30830;&#24615;&#30340;&#22256;&#22659;&#12290;&#26412;&#25991;&#21033;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#29420;&#29305;&#29305;&#24449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#19968;&#22256;&#22659;&#65292;&#24182;&#30830;&#20445;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#21644;&#23398;&#20064;&#20934;&#30830;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#30830;&#20445;&#39044;&#26399;&#30636;&#26102;&#36951;&#25022;&#31243;&#24230;&#36880;&#28176;&#20943;&#23567;&#30340;&#21516;&#26102;&#65292;&#36824;&#33021;&#20445;&#35777;&#26377;&#38480;&#30340;&#32047;&#31215;&#38544;&#31169;&#39044;&#31639;&#65292;&#21363;&#20351;&#22312;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#12290;&#20026;&#20102;&#24212;&#23545;&#23436;&#20840;&#20998;&#24067;&#24335;&#29615;&#22659;&#65292;&#25105;&#20204;&#37319;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#65292;&#36991;&#20813;&#20102;&#23545;&#20840;&#23616;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed online learning is gaining increased traction due to its unique ability to process large-scale datasets and streaming data. To address the growing public awareness and concern on privacy protection, plenty of private distributed online learning algorithms have been proposed, mostly based on differential privacy which has emerged as the ``gold standard" for privacy protection. However, these algorithms often face the dilemma of trading learning accuracy for privacy. By exploiting the unique characteristics of online learning, this paper proposes an approach that tackles the dilemma and ensures both differential privacy and learning accuracy in distributed online learning. More specifically, while ensuring a diminishing expected instantaneous regret, the approach can simultaneously ensure a finite cumulative privacy budget, even on the infinite time horizon. To cater for the fully distributed setting, we adopt the local differential-privacy framework which avoids the reliance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MetaGAD&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#20174;&#26080;&#26631;&#35760;&#33410;&#28857;&#21040;&#26377;&#26631;&#35760;&#33410;&#28857;&#20043;&#38388;&#30340;&#20803;&#36716;&#31227;&#30693;&#35782;&#65292;&#20197;&#36827;&#34892;&#23569;&#26679;&#26412;&#22270;&#24322;&#24120;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2305.10668</link><description>&lt;p&gt;
MetaGAD&#65306;&#23398;&#20064;&#20803;&#36716;&#31227;&#36827;&#34892;&#23569;&#26679;&#26412;&#22270;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
MetaGAD: Learning to Meta Transfer for Few-shot Graph Anomaly Detection. (arXiv:2305.10668v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MetaGAD&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#20174;&#26080;&#26631;&#35760;&#33410;&#28857;&#21040;&#26377;&#26631;&#35760;&#33410;&#28857;&#20043;&#38388;&#30340;&#20803;&#36716;&#31227;&#30693;&#35782;&#65292;&#20197;&#36827;&#34892;&#23569;&#26679;&#26412;&#22270;&#24322;&#24120;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24322;&#24120;&#26816;&#27979;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#26159;&#21508;&#20010;&#39046;&#22495;&#20449;&#24687;&#23433;&#20840;&#38382;&#39064;&#20013;&#30340;&#37325;&#35201;&#38382;&#39064;&#65292;&#22914;&#37329;&#34701;&#27450;&#35784;&#12289;&#31038;&#20250;&#22403;&#22334;&#37038;&#20214;&#12289;&#32593;&#32476;&#20837;&#20405;&#31561;&#12290;&#30446;&#21069;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#37117;&#26159;&#20197;&#26080;&#30417;&#30563;&#26041;&#24335;&#25191;&#34892;&#30340;&#65292;&#22240;&#20026;&#26631;&#35760;&#30340;&#24322;&#24120;&#22312;&#22823;&#35268;&#27169;&#24773;&#20917;&#19979;&#24448;&#24448;&#22826;&#26114;&#36149;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#26377;&#20851;&#24322;&#24120;&#30340;&#20808;&#21069;&#30693;&#35782;&#65292;&#21487;&#33021;&#20250;&#23558;&#34987;&#35782;&#21035;&#30340;&#24322;&#24120;&#35270;&#20026;&#25968;&#25454;&#22122;&#22768;&#25110;&#19981;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#23454;&#20363;&#12290;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#36890;&#24120;&#21487;&#33719;&#21462;&#26377;&#38480;&#30340;&#26631;&#35760;&#24322;&#24120;&#65292;&#36825;&#20123;&#26631;&#35760;&#24322;&#24120;&#20855;&#26377;&#25512;&#36827;&#22270;&#24322;&#24120;&#26816;&#27979;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#25506;&#32034;&#23569;&#37327;&#26631;&#35760;&#24322;&#24120;&#21644;&#22823;&#37327;&#26080;&#26631;&#35760;&#33410;&#28857;&#26469;&#26816;&#27979;&#24322;&#24120;&#30340;&#24037;&#20316;&#30456;&#24403;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#23569;&#26679;&#26412;&#22270;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;MetaGAD&#65292;&#23398;&#20064;&#20803;&#36716;&#31227;&#30693;&#35782;&#26469;&#36827;&#34892;&#22270;&#24322;&#24120;&#26816;&#27979;&#12290;&#23454;
&lt;/p&gt;
&lt;p&gt;
Graph anomaly detection has long been an important problem in various domains pertaining to information security such as financial fraud, social spam, network intrusion, etc. The majority of existing methods are performed in an unsupervised manner, as labeled anomalies in a large scale are often too expensive to acquire. However, the identified anomalies may turn out to be data noises or uninteresting data instances due to the lack of prior knowledge on the anomalies. In realistic scenarios, it is often feasible to obtain limited labeled anomalies, which have great potential to advance graph anomaly detection. However, the work exploring limited labeled anomalies and a large amount of unlabeled nodes in graphs to detect anomalies is rather limited. Therefore, in this paper, we study a novel problem of few-shot graph anomaly detection. We propose a new framework MetaGAD to learn to meta-transfer the knowledge between unlabeled and labeled nodes for graph anomaly detection. Experimental 
&lt;/p&gt;</description></item></channel></rss>