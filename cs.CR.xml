<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#35813;&#35770;&#25991;&#31995;&#32479;&#21270;&#20102;&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36234;&#29425;&#25552;&#31034;&#30340;&#23384;&#22312;&#24418;&#24335;&#65292;&#24182;&#34913;&#37327;&#20102;&#23427;&#20204;&#30340;&#36234;&#29425;&#28508;&#21147;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#35821;&#20041;&#19978;&#20855;&#26377;&#24847;&#20041;&#30340;&#36234;&#29425;&#25552;&#31034;&#30340;&#23041;&#32961;&#26684;&#23616;&#12290;</title><link>https://arxiv.org/abs/2403.17336</link><description>&lt;p&gt;
&#19981;&#35201;&#21548;&#25105;&#30340;&#35805;&#65306;&#29702;&#35299;&#21644;&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17336
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#31995;&#32479;&#21270;&#20102;&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36234;&#29425;&#25552;&#31034;&#30340;&#23384;&#22312;&#24418;&#24335;&#65292;&#24182;&#34913;&#37327;&#20102;&#23427;&#20204;&#30340;&#36234;&#29425;&#28508;&#21147;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#35821;&#20041;&#19978;&#20855;&#26377;&#24847;&#20041;&#30340;&#36234;&#29425;&#25552;&#31034;&#30340;&#23041;&#32961;&#26684;&#23616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#26080;&#22788;&#19981;&#22312;&#22320;&#34987;&#35775;&#38382;&#12290;&#20973;&#20511;&#20854;&#20986;&#33394;&#30340;&#29702;&#35299;&#21644;&#29983;&#25104;&#31867;&#20284;&#20154;&#31867;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#36825;&#20123;&#27169;&#22411;&#27491;&#26085;&#30410;&#34701;&#20837;&#25105;&#20204;&#30340;&#31038;&#20250;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#20154;&#20204;&#20063;&#23545;&#36825;&#31181;&#24378;&#22823;&#25216;&#26415;&#30340;&#28508;&#22312;&#28389;&#29992;&#34920;&#31034;&#25285;&#24551;&#65292;&#24182;&#20419;&#20351;&#26381;&#21153;&#25552;&#20379;&#21830;&#37319;&#21462;&#20102;&#38450;&#24481;&#25514;&#26045;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#31181;&#20445;&#25252;&#26426;&#21046;&#65292;&#36234;&#29425;&#25552;&#31034;&#26368;&#36817;&#24050;&#25104;&#20026;&#35268;&#36991;&#23433;&#20840;&#38480;&#21046;&#21644;&#24341;&#35825;&#26368;&#21021;&#35774;&#35745;&#20026;&#34987;&#31105;&#27490;&#30340;&#26377;&#23475;&#20869;&#23481;&#30340;&#26368;&#26377;&#25928;&#26426;&#21046;&#20043;&#19968;&#12290;&#30001;&#20110;LLM&#30340;&#24555;&#36895;&#21457;&#23637;&#21450;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#36731;&#26494;&#33719;&#21462;&#30340;&#20415;&#21033;&#24615;&#65292;&#36234;&#29425;&#25552;&#31034;&#30340;&#21069;&#27839;&#20027;&#35201;&#20986;&#29616;&#22312;&#22312;&#32447;&#35770;&#22363;&#21644;&#29233;&#22909;&#32773;&#20013;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#20102;&#35299;&#35821;&#20041;&#19978;&#20855;&#26377;&#24847;&#20041;&#30340;&#36234;&#29425;&#25552;&#31034;&#30340;&#23041;&#32961;&#26684;&#23616;&#65292;&#25105;&#20204;&#31995;&#32479;&#21270;&#20102;&#29616;&#26377;&#25552;&#31034;&#24182;&#27979;&#37327;&#23427;&#20204;&#30340;&#36234;&#29425;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17336v1 Announce Type: cross  Abstract: Recent advancements in generative AI have enabled ubiquitous access to large language models (LLMs). Empowered by their exceptional capabilities to understand and generate human-like text, these models are being increasingly integrated into our society. At the same time, there are also concerns on the potential misuse of this powerful technology, prompting defensive measures from service providers. To overcome such protection, jailbreaking prompts have recently emerged as one of the most effective mechanisms to circumvent security restrictions and elicit harmful content originally designed to be prohibited.   Due to the rapid development of LLMs and their ease of access via natural languages, the frontline of jailbreak prompts is largely seen in online forums and among hobbyists. To gain a better understanding of the threat landscape of semantically meaningful jailbreak prompts, we systemized existing prompts and measured their jailbre
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21152;&#23494;&#36164;&#20135;&#30340;&#24037;&#20316;&#21407;&#29702;&#20197;&#21450;&#19982;&#31246;&#25910;&#38382;&#39064;&#30456;&#20851;&#32852;&#30340;&#20869;&#23481;</title><link>https://arxiv.org/abs/2403.15074</link><description>&lt;p&gt;
&#31246;&#21153;&#20154;&#21592;&#30340;&#21152;&#23494;&#36164;&#20135;&#31246;&#25910;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
A Taxmans guide to taxation of crypto assets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21152;&#23494;&#36164;&#20135;&#30340;&#24037;&#20316;&#21407;&#29702;&#20197;&#21450;&#19982;&#31246;&#25910;&#38382;&#39064;&#30456;&#20851;&#32852;&#30340;&#20869;&#23481;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37329;&#34701;&#31995;&#32479;&#35265;&#35777;&#20102;&#36805;&#36895;&#30340;&#25216;&#26415;&#21464;&#38761;&#12290;&#27604;&#29305;&#24065;&#21644;&#20854;&#20182;&#22522;&#20110;&#20998;&#24067;&#24335;&#36134;&#26412;&#25216;&#26415;&#30340;&#21152;&#23494;&#36164;&#20135;&#30340;&#20852;&#36215;&#26631;&#24535;&#30528;&#20154;&#20204;&#22312;&#36328;&#36234;&#22320;&#29702;&#20301;&#32622;&#30340;&#21435;&#20013;&#24515;&#21270;&#32593;&#32476;&#19978;&#36827;&#34892;&#20132;&#26131;&#21644;&#20256;&#36755;&#20215;&#20540;&#30340;&#26041;&#24335;&#21457;&#29983;&#20102;&#26681;&#26412;&#24615;&#25913;&#21464;&#12290;&#36825;&#24050;&#32463;&#22312;&#30417;&#31649;&#21644;&#31246;&#25910;&#25919;&#31574;&#19978;&#20135;&#29983;&#20102;&#30450;&#28857;&#65292;&#22240;&#20026;&#25919;&#24220;&#21644;&#31246;&#25910;&#31649;&#29702;&#26426;&#26500;&#38656;&#35201;&#26102;&#38388;&#20102;&#35299;&#24182;&#23545;&#36825;&#31181;&#21019;&#26032;&#12289;&#38761;&#21629;&#24615;&#21644;&#24555;&#33410;&#22863;&#30340;&#25216;&#26415;&#25552;&#20379;&#25919;&#31574;&#21709;&#24212;&#12290;&#30001;&#20110;&#21306;&#22359;&#38142;&#25216;&#26415;&#21019;&#26032;&#30340;&#36805;&#29467;&#36895;&#24230;&#20197;&#21450;&#21435;&#20013;&#24515;&#21270;&#37329;&#34701;&#12289;&#21435;&#20013;&#24515;&#21270;&#33258;&#27835;&#32452;&#32455;&#21644;&#20803;&#23431;&#23449;&#30340;&#20986;&#29616;&#65292;&#30417;&#31649;&#24403;&#23616;&#25110;&#31246;&#25910;&#31649;&#29702;&#26426;&#26500;&#30340;&#25919;&#31574;&#24178;&#39044;&#21644;&#25351;&#23548;&#19981;&#22826;&#21487;&#33021;&#36214;&#19978;&#25110;&#19982;&#21019;&#26032;&#30340;&#36895;&#24230;&#21516;&#27493;&#12290;&#26412;&#25991;&#35797;&#22270;&#35299;&#37322;&#21152;&#23494;&#36164;&#20135;&#30340;&#24037;&#20316;&#21407;&#29702;&#12289;&#23427;&#20204;&#30340;&#22522;&#30784;&#25216;&#26415;&#24182;&#23558;&#20854;&#19982;&#31246;&#21153;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15074v1 Announce Type: new  Abstract: The Financial system has witnessed rapid technological changes. The rise of Bitcoin and other crypto assets based on Distributed Ledger Technology mark a fundamental change in the way people transact and transmit value over a decentralized network, spread across geographies. This has created regulatory and tax policy blind spots, as governments and tax administrations take time to understand and provide policy responses to this innovative, revolutionary, and fast-paced technology. Due to the breakneck speed of innovation in blockchain technology and advent of Decentralized Finance, Decentralized Autonomous Organizations and the Metaverse, it is unlikely that the policy interventions and guidance by regulatory authorities or tax administrations would be ahead or in sync with the pace of innovation. This paper tries to explain the principles on which crypto assets function, their underlying technology and relates them to the tax issues and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#27969;&#31243;&#65292;&#29992;&#20110;&#23545;AI&#35270;&#35273;&#27169;&#22411;&#22312;&#24320;&#25918;&#23384;&#20648;&#24211;&#20013;&#30340;&#36136;&#37327;&#23646;&#24615;&#36827;&#34892;&#20998;&#26512;&#65292;&#23588;&#20854;&#26159;&#22312;&#38754;&#23545;&#23545;&#25239;&#25915;&#20987;&#26102;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#28041;&#21450;&#20845;&#20010;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#35780;&#20272;&#22330;&#26223;&#65292;&#20197;&#35780;&#20272;&#20934;&#30830;&#24615;&#12289;&#40065;&#26834;&#24615;&#12289;&#35299;&#37322;&#25928;&#29992;&#21644;&#24320;&#38144;&#12290;</title><link>http://arxiv.org/abs/2401.12261</link><description>&lt;p&gt;
&#22312;&#24320;&#25918;&#23384;&#20648;&#24211;&#20013;&#20998;&#26512;AI&#35270;&#35273;&#27169;&#22411;&#30340;&#36136;&#37327;&#23646;&#24615;&#21450;&#20854;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks. (arXiv:2401.12261v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#27969;&#31243;&#65292;&#29992;&#20110;&#23545;AI&#35270;&#35273;&#27169;&#22411;&#22312;&#24320;&#25918;&#23384;&#20648;&#24211;&#20013;&#30340;&#36136;&#37327;&#23646;&#24615;&#36827;&#34892;&#20998;&#26512;&#65292;&#23588;&#20854;&#26159;&#22312;&#38754;&#23545;&#23545;&#25239;&#25915;&#20987;&#26102;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#28041;&#21450;&#20845;&#20010;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#35780;&#20272;&#22330;&#26223;&#65292;&#20197;&#35780;&#20272;&#20934;&#30830;&#24615;&#12289;&#40065;&#26834;&#24615;&#12289;&#35299;&#37322;&#25928;&#29992;&#21644;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;AI&#27169;&#22411;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#23427;&#20204;&#32463;&#24120;&#21457;&#24067;&#21040;&#24320;&#25918;&#23384;&#20648;&#24211;&#20013;&#65292;&#22914;HuggingFace&#12290;&#22312;&#23558;&#23427;&#20204;&#38598;&#25104;&#21040;&#29983;&#20135;&#24320;&#21457;&#29983;&#21629;&#21608;&#26399;&#20043;&#21069;&#65292;&#23545;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#36136;&#37327;&#20445;&#35777;&#39564;&#35777;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#38500;&#20102;&#35780;&#20272;&#24179;&#34913;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#30340;&#25928;&#29575;&#22806;&#65292;&#23545;&#25239;&#25915;&#20987;&#21487;&#33021;&#23545;AI&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#26500;&#25104;&#23041;&#32961;&#12290;&#21516;&#26102;&#65292;&#21487;&#35299;&#37322;&#24615;AI&#65288;XAI&#65289;&#24212;&#29992;&#36817;&#20284;&#36755;&#20837;&#21040;&#36755;&#20986;&#30340;&#31639;&#27861;&#26469;&#35782;&#21035;&#36129;&#29486;&#29305;&#24449;&#12290;&#23545;&#25239;&#25200;&#21160;&#21487;&#33021;&#20250;&#38477;&#20302;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;XAI&#35299;&#37322;&#30340;&#25928;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#27969;&#31243;&#65292;&#29992;&#20110;&#19979;&#28216;&#35780;&#20272;&#20219;&#21153;&#65292;&#21253;&#25324;&#39564;&#35777;AI&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#29992;&#22522;&#20934;&#25200;&#21160;&#35780;&#20272;&#40065;&#26834;&#24615;&#65292;&#27604;&#36739;&#35299;&#37322;&#25928;&#29992;&#20197;&#21450;&#35780;&#20272;&#24320;&#38144;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#28041;&#21450;&#20845;&#20010;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#35780;&#20272;&#22330;&#26223;&#65292;&#20854;&#20013;&#21253;&#25324;&#22522;&#20110;CNN&#21644;Transformer&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
As AI models rapidly evolve, they are frequently released to open repositories, such as HuggingFace. It is essential to perform quality assurance validation on these models before integrating them into the production development lifecycle. In addition to evaluating efficiency in terms of balanced accuracy and computing costs, adversarial attacks are potential threats to the robustness and explainability of AI models. Meanwhile, XAI applies algorithms that approximate inputs to outputs post-hoc to identify the contributing features. Adversarial perturbations may also degrade the utility of XAI explanations that require further investigation. In this paper, we present an integrated process designed for downstream evaluation tasks, including validating AI model accuracy, evaluating robustness with benchmark perturbations, comparing explanation utility, and assessing overhead. We demonstrate an evaluation scenario involving six computer vision models, which include CNN-based, Transformer-b
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#19978;&#19979;&#25991;&#23398;&#20064;&#33539;&#24335;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23384;&#22312;&#28431;&#27934;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#27745;&#26579;&#31034;&#33539;&#19978;&#19979;&#25991;&#26469;&#25805;&#25511;&#27169;&#22411;&#34892;&#20026;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#24494;&#35843;&#12290;&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;ICLAttack&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#27745;&#26579;&#31034;&#33539;&#26679;&#26412;&#21644;&#25552;&#31034;&#26469;&#20351;&#27169;&#22411;&#25353;&#29031;&#39044;&#23450;&#20041;&#30340;&#24847;&#22270;&#34892;&#20107;&#12290;</title><link>http://arxiv.org/abs/2401.05949</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#36890;&#29992;&#28431;&#27934;&#65306;&#19978;&#19979;&#25991;&#23398;&#20064;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#19978;&#19979;&#25991;&#23398;&#20064;&#33539;&#24335;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23384;&#22312;&#28431;&#27934;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#27745;&#26579;&#31034;&#33539;&#19978;&#19979;&#25991;&#26469;&#25805;&#25511;&#27169;&#22411;&#34892;&#20026;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#24494;&#35843;&#12290;&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;ICLAttack&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#27745;&#26579;&#31034;&#33539;&#26679;&#26412;&#21644;&#25552;&#31034;&#26469;&#20351;&#27169;&#22411;&#25353;&#29031;&#39044;&#23450;&#20041;&#30340;&#24847;&#22270;&#34892;&#20107;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#19968;&#31181;&#22312;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#20043;&#38388;&#24357;&#21512;&#24046;&#36317;&#30340;&#33539;&#24335;&#65292;&#22312;&#20960;&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#39640;&#25928;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#23569;&#26679;&#26412;&#35774;&#32622;&#20013;&#12290;&#19982;&#20256;&#32479;&#30340;&#24494;&#35843;&#26041;&#27861;&#19981;&#21516;&#65292;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#22815;&#36866;&#24212;&#26410;&#35265;&#36807;&#30340;&#20219;&#21153;&#32780;&#26080;&#38656;&#26356;&#26032;&#20219;&#20309;&#21442;&#25968;&#12290;&#23613;&#31649;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#19978;&#19979;&#25991;&#23398;&#20064;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#24694;&#24847;&#25915;&#20987;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#36825;&#19968;&#33539;&#24335;&#30340;&#23433;&#20840;&#24615;&#38382;&#39064;&#30340;&#20851;&#20999;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#27745;&#26579;&#31034;&#33539;&#19978;&#19979;&#25991;&#26469;&#25805;&#25511;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#32780;&#26080;&#38656;&#23545;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;ICLAttack&#65292;&#38024;&#23545;&#22522;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#65306;&#27745;&#26579;&#31034;&#33539;&#26679;&#26412;&#21644;&#27745;&#26579;&#25552;&#31034;&#65292;&#21487;&#20197;&#20351;&#27169;&#22411;&#25353;&#29031;&#39044;&#23450;&#20041;&#30340;&#24847;&#22270;&#34892;&#20107;&#12290;ICLAttack&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
In-context learning, a paradigm bridging the gap between pre-training and fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in few-shot settings. Unlike traditional fine-tuning methods, in-context learning adapts pre-trained models to unseen tasks without updating any parameters. Despite being widely applied, in-context learning is vulnerable to malicious attacks. In this work, we raise security concerns regarding this paradigm. Our studies demonstrate that an attacker can manipulate the behavior of large language models by poisoning the demonstration context, without the need for fine-tuning the model. Specifically, we have designed a new backdoor attack method, named ICLAttack, to target large language models based on in-context learning. Our method encompasses two types of attacks: poisoning demonstration examples and poisoning prompts, which can make models behave in accordance with predefined intentions. ICLAttack does not require additional fine-tuning 
&lt;/p&gt;</description></item></channel></rss>