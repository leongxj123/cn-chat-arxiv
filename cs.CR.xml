<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#25918;&#23556;&#24615;&#65292;&#34920;&#26126;&#20351;&#29992;&#25968;&#23383;&#27700;&#21360;&#35757;&#32451;&#25968;&#25454;&#33021;&#26356;&#23481;&#26131;&#26816;&#27979;&#21040;&#65292;&#21516;&#26102;&#20063;&#23637;&#31034;&#20102;&#21363;&#20351;&#21482;&#26377;&#24456;&#23569;&#27604;&#20363;&#30340;&#27700;&#21360;&#35757;&#32451;&#25991;&#26412;&#65292;&#20173;&#21487;&#20197;&#39640;&#32622;&#20449;&#24230;&#22320;&#26816;&#27979;&#20986;&#20351;&#29992;&#25968;&#23383;&#27700;&#21360;&#36827;&#34892;&#24494;&#35843;&#30340;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2402.14904</link><description>&lt;p&gt;
&#25968;&#23383;&#27700;&#21360;&#20351;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#25918;&#23556;&#24615;
&lt;/p&gt;
&lt;p&gt;
Watermarking Makes Language Models Radioactive
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#25918;&#23556;&#24615;&#65292;&#34920;&#26126;&#20351;&#29992;&#25968;&#23383;&#27700;&#21360;&#35757;&#32451;&#25968;&#25454;&#33021;&#26356;&#23481;&#26131;&#26816;&#27979;&#21040;&#65292;&#21516;&#26102;&#20063;&#23637;&#31034;&#20102;&#21363;&#20351;&#21482;&#26377;&#24456;&#23569;&#27604;&#20363;&#30340;&#27700;&#21360;&#35757;&#32451;&#25991;&#26412;&#65292;&#20173;&#21487;&#20197;&#39640;&#32622;&#20449;&#24230;&#22320;&#26816;&#27979;&#20986;&#20351;&#29992;&#25968;&#23383;&#27700;&#21360;&#36827;&#34892;&#24494;&#35843;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;LLM&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#25918;&#23556;&#24615;&#65292;&#21363;&#26159;&#21542;&#21487;&#20197;&#26816;&#27979;&#21040;&#36825;&#31181;&#36755;&#20837;&#34987;&#29992;&#20316;&#35757;&#32451;&#25968;&#25454;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;&#25104;&#21592;&#25512;&#26029;&#21487;&#20197;&#20197;&#19968;&#23450;&#27700;&#24179;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#36825;&#31181;&#26816;&#27979;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24102;&#26377;&#25968;&#23383;&#27700;&#21360;&#30340;&#35757;&#32451;&#25968;&#25454;&#30041;&#19979;&#30340;&#30165;&#36857;&#27604;&#25104;&#21592;&#25512;&#26029;&#26356;&#23481;&#26131;&#26816;&#27979;&#19988;&#26356;&#21487;&#38752;&#12290;&#25105;&#20204;&#23558;&#27745;&#26579;&#27700;&#24179;&#19982;&#27700;&#21360;&#30340;&#40065;&#26834;&#24615;&#12289;&#22312;&#35757;&#32451;&#38598;&#20013;&#30340;&#27604;&#20363;&#21644;&#24494;&#35843;&#36807;&#31243;&#32852;&#31995;&#36215;&#26469;&#12290;&#29305;&#21035;&#26159;&#25105;&#20204;&#23637;&#31034;&#65292;&#21363;&#20351;&#21482;&#26377;5&#65285;&#30340;&#35757;&#32451;&#25991;&#26412;&#34987;&#25968;&#23383;&#27700;&#21360;&#26631;&#35760;&#65292;&#35757;&#32451;&#22312;&#24102;&#26377;&#25968;&#23383;&#27700;&#21360;&#30340;&#21512;&#25104;&#25351;&#20196;&#19978;&#20173;&#28982;&#21487;&#20197;&#20855;&#26377;&#39640;&#32622;&#20449;&#24230;&#65288;p&#20540;&lt;1e-5&#65289;&#34987;&#26816;&#27979;&#21040;&#12290;&#22240;&#27492;&#65292;&#21407;&#26412;&#35774;&#35745;&#29992;&#20110;&#26816;&#27979;&#26426;&#22120;&#29983;&#25104;&#25991;&#26412;&#30340;LLM&#27700;&#21360;&#25216;&#26415;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#36731;&#26494;&#30830;&#23450;&#24102;&#26377;&#25968;&#23383;&#27700;&#21360;&#30340;LLM&#30340;&#36755;&#20986;&#26159;&#21542;&#34987;&#29992;&#26469;&#23545;&#21478;&#19968;&#20010;LLM&#36827;&#34892;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14904v1 Announce Type: cross  Abstract: This paper investigates the radioactivity of LLM-generated texts, i.e. whether it is possible to detect that such input was used as training data. Conventional methods like membership inference can carry out this detection with some level of accuracy. We show that watermarked training data leaves traces easier to detect and much more reliable than membership inference. We link the contamination level to the watermark robustness, its proportion in the training set, and the fine-tuning process. We notably demonstrate that training on watermarked synthetic instructions can be detected with high confidence (p-value &lt; 1e-5) even when as little as 5% of training text is watermarked. Thus, LLM watermarking, originally designed for detecting machine-generated text, gives the ability to easily identify if the outputs of a watermarked LLM were used to fine-tune another LLM.
&lt;/p&gt;</description></item><item><title>PANORAMIA&#26159;&#19968;&#31181;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38544;&#31169;&#23457;&#35745;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#30340;&#8220;&#38750;&#25104;&#21592;&#8221;&#25968;&#25454;&#36827;&#34892;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#21487;&#20197;&#37327;&#21270;&#22823;&#35268;&#27169;ML&#27169;&#22411;&#30340;&#38544;&#31169;&#27844;&#38706;&#65292;&#32780;&#26080;&#38656;&#25511;&#21046;&#35757;&#32451;&#36807;&#31243;&#25110;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#65292;&#21482;&#38656;&#35201;&#35775;&#38382;&#35757;&#32451;&#25968;&#25454;&#30340;&#23376;&#38598;&#12290;</title><link>https://arxiv.org/abs/2402.09477</link><description>&lt;p&gt;
PANORAMIA: &#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38544;&#31169;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
PANORAMIA: Privacy Auditing of Machine Learning Models without Retraining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09477
&lt;/p&gt;
&lt;p&gt;
PANORAMIA&#26159;&#19968;&#31181;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38544;&#31169;&#23457;&#35745;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#30340;&#8220;&#38750;&#25104;&#21592;&#8221;&#25968;&#25454;&#36827;&#34892;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#21487;&#20197;&#37327;&#21270;&#22823;&#35268;&#27169;ML&#27169;&#22411;&#30340;&#38544;&#31169;&#27844;&#38706;&#65292;&#32780;&#26080;&#38656;&#25511;&#21046;&#35757;&#32451;&#36807;&#31243;&#25110;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#65292;&#21482;&#38656;&#35201;&#35775;&#38382;&#35757;&#32451;&#25968;&#25454;&#30340;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38544;&#31169;&#23457;&#35745;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#20381;&#36182;&#20110;&#20351;&#29992;&#29983;&#25104;&#30340;&#8220;&#38750;&#25104;&#21592;&#8221;&#25968;&#25454;&#36827;&#34892;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26469;&#23545;ML&#27169;&#22411;&#36827;&#34892;&#38544;&#31169;&#23457;&#35745;&#12290;&#36825;&#20010;&#26041;&#26696;&#34987;&#31216;&#20026;PANORAMIA&#65292;&#23427;&#21487;&#20197;&#37327;&#21270;&#22823;&#35268;&#27169;ML&#27169;&#22411;&#30340;&#38544;&#31169;&#27844;&#38706;&#65292;&#32780;&#26080;&#38656;&#25511;&#21046;&#35757;&#32451;&#36807;&#31243;&#25110;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#65292;&#21482;&#38656;&#35201;&#35775;&#38382;&#35757;&#32451;&#25968;&#25454;&#30340;&#23376;&#38598;&#12290;&#20026;&#20102;&#35777;&#26126;&#20854;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#22312;&#22810;&#20010;ML&#39046;&#22495;&#36827;&#34892;&#20102;&#23457;&#35745;&#65292;&#21253;&#25324;&#22270;&#20687;&#21644;&#34920;&#26684;&#25968;&#25454;&#20998;&#31867;&#20197;&#21450;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09477v1 Announce Type: cross  Abstract: We introduce a privacy auditing scheme for ML models that relies on membership inference attacks using generated data as "non-members". This scheme, which we call PANORAMIA, quantifies the privacy leakage for large-scale ML models without control of the training process or model re-training and only requires access to a subset of the training data. To demonstrate its applicability, we evaluate our auditing scheme across multiple ML domains, ranging from image and tabular data classification to large-scale language models.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#20998;&#24067;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#24046;&#20998;&#38544;&#31169;&#23376;&#31354;&#38388;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23569;&#37327;&#30340;&#25968;&#25454;&#28857;&#65292;&#21487;&#20197;&#31169;&#23494;&#22320;&#35782;&#21035;&#20986;&#20302;&#32500;&#32467;&#26500;&#65292;&#36991;&#20813;&#20102;&#39640;&#32500;&#24230;&#30340;&#20195;&#20215;&#12290;</title><link>https://arxiv.org/abs/2402.06465</link><description>&lt;p&gt;
&#20851;&#20110;&#26080;&#20998;&#24067;&#20551;&#35774;&#30340;&#24046;&#20998;&#38544;&#31169;&#23376;&#31354;&#38388;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
On Differentially Private Subspace Estimation Without Distributional Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#20998;&#24067;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#24046;&#20998;&#38544;&#31169;&#23376;&#31354;&#38388;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23569;&#37327;&#30340;&#25968;&#25454;&#28857;&#65292;&#21487;&#20197;&#31169;&#23494;&#22320;&#35782;&#21035;&#20986;&#20302;&#32500;&#32467;&#26500;&#65292;&#36991;&#20813;&#20102;&#39640;&#32500;&#24230;&#30340;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#31169;&#25968;&#25454;&#20998;&#26512;&#38754;&#20020;&#30528;&#19968;&#20010;&#34987;&#31216;&#20026;&#32500;&#25968;&#35781;&#21650;&#30340;&#37325;&#22823;&#25361;&#25112;&#65292;&#23548;&#33268;&#20102;&#25104;&#26412;&#30340;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#25968;&#25454;&#38598;&#20855;&#26377;&#22266;&#26377;&#30340;&#20302;&#32500;&#32467;&#26500;&#12290;&#20363;&#22914;&#65292;&#22312;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#36807;&#31243;&#20013;&#65292;&#26799;&#24230;&#32463;&#24120;&#20301;&#20110;&#19968;&#20010;&#20302;&#32500;&#23376;&#31354;&#38388;&#38468;&#36817;&#12290;&#22914;&#26524;&#21487;&#20197;&#20351;&#29992;&#23569;&#37327;&#28857;&#31169;&#23494;&#22320;&#35782;&#21035;&#20986;&#36825;&#31181;&#20302;&#32500;&#32467;&#26500;&#65292;&#23601;&#21487;&#20197;&#36991;&#20813;&#22240;&#39640;&#32500;&#24230;&#32780;&#25903;&#20184;&#38544;&#31169;&#21644;&#20934;&#30830;&#24615;&#30340;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
Private data analysis faces a significant challenge known as the curse of dimensionality, leading to increased costs. However, many datasets possess an inherent low-dimensional structure. For instance, during optimization via gradient descent, the gradients frequently reside near a low-dimensional subspace. If the low-dimensional structure could be privately identified using a small amount of points, we could avoid paying (in terms of privacy and accuracy) for the high ambient dimension.   On the negative side, Dwork, Talwar, Thakurta, and Zhang (STOC 2014) proved that privately estimating subspaces, in general, requires an amount of points that depends on the dimension. But Singhal and Steinke (NeurIPS 2021) bypassed this limitation by considering points that are i.i.d. samples from a Gaussian distribution whose covariance matrix has a certain eigenvalue gap. Yet, it was still left unclear whether we could provide similar upper bounds without distributional assumptions and whether we 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#33402;&#26415;&#35774;&#35745;&#23454;&#29616;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24494;&#23567;&#26356;&#25913;&#29616;&#26377;&#35268;&#33539;&#26469;&#25269;&#24481;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.04660</link><description>&lt;p&gt;
&#36890;&#36807;&#33402;&#26415;&#35774;&#35745;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Adversarial Robustness Through Artifact Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04660
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#33402;&#26415;&#35774;&#35745;&#23454;&#29616;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24494;&#23567;&#26356;&#25913;&#29616;&#26377;&#35268;&#33539;&#26469;&#25269;&#24481;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#20986;&#29616;&#32473;&#26426;&#22120;&#23398;&#20064;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#20026;&#20102;&#38459;&#30861;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#22823;&#22810;&#25968;&#38450;&#24481;&#26041;&#27861;&#37117;&#25913;&#21464;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#26041;&#24335;&#65288;&#22914;&#23545;&#25239;&#24615;&#35757;&#32451;&#65289;&#25110;&#25512;&#29702;&#36807;&#31243;&#65288;&#22914;&#38543;&#26426;&#24179;&#28369;&#65289;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#20294;&#27169;&#22411;&#20173;&#28982;&#26497;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#24433;&#21709;&#12290;&#22312;&#26576;&#20123;&#39046;&#22495;&#22914;&#20132;&#36890;&#26631;&#24535;&#35782;&#21035;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#23545;&#35937;&#26159;&#25353;&#29031;&#35268;&#33539;&#26469;&#35774;&#35745;&#65288;&#22914;&#26631;&#24535;&#35268;&#33539;&#65289;&#12290;&#20026;&#20102;&#25913;&#21892;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#37325;&#26032;&#23450;&#20041;&#35268;&#33539;&#30340;&#26041;&#27861;&#65292;&#23545;&#29616;&#26377;&#35268;&#33539;&#36827;&#34892;&#24494;&#23567;&#30340;&#26356;&#25913;&#65292;&#20197;&#38450;&#24481;&#23545;&#25239;&#24615;&#31034;&#20363;&#12290;&#25105;&#20204;&#23558;&#33402;&#26415;&#35774;&#35745;&#38382;&#39064;&#24314;&#27169;&#20026;&#19968;&#20010;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#26799;&#24230;&#21644;&#36138;&#23146;&#25628;&#32034;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#23427;&#12290;&#25105;&#20204;&#22312;&#20132;&#36890;&#26631;&#24535;&#35782;&#21035;&#39046;&#22495;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#20351;&#20854;&#33021;&#22815;&#25913;&#21464;&#20132;&#36890;&#26631;&#24535;&#20013;&#30340;&#35937;&#24418;&#22270;&#26631;&#65288;&#21363;&#26631;&#24535;&#20869;&#30340;&#31526;&#21495;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial examples arose as a challenge for machine learning. To hinder them, most defenses alter how models are trained (e.g., adversarial training) or inference is made (e.g., randomized smoothing). Still, while these approaches markedly improve models' adversarial robustness, models remain highly susceptible to adversarial examples. Identifying that, in certain domains such as traffic-sign recognition, objects are implemented per standards specifying how artifacts (e.g., signs) should be designed, we propose a novel approach for improving adversarial robustness. Specifically, we offer a method to redefine standards, making minor changes to existing ones, to defend against adversarial examples. We formulate the problem of artifact design as a robust optimization problem, and propose gradient-based and greedy search methods to solve it. We evaluated our approach in the domain of traffic-sign recognition, allowing it to alter traffic-sign pictograms (i.e., symbols within the signs) a
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Prompt2Forget&#65288;P2F&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#25945;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24536;&#35760;&#38544;&#31169;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;LLM&#26412;&#22320;&#38544;&#31169;&#25361;&#25112;&#12290;P2F&#26041;&#27861;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#29255;&#27573;&#24182;&#29983;&#25104;&#34394;&#26500;&#31572;&#26696;&#65292;&#27169;&#31946;&#21270;&#27169;&#22411;&#23545;&#21407;&#22987;&#36755;&#20837;&#30340;&#35760;&#24518;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;P2F&#20855;&#26377;&#24456;&#24378;&#30340;&#27169;&#31946;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#19979;&#33258;&#36866;&#24212;&#20351;&#29992;&#65292;&#26080;&#38656;&#25163;&#21160;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2401.00870</link><description>&lt;p&gt;
&#25945;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24536;&#35760;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Teach Large Language Models to Forget Privacy. (arXiv:2401.00870v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00870
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Prompt2Forget&#65288;P2F&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#25945;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24536;&#35760;&#38544;&#31169;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;LLM&#26412;&#22320;&#38544;&#31169;&#25361;&#25112;&#12290;P2F&#26041;&#27861;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#29255;&#27573;&#24182;&#29983;&#25104;&#34394;&#26500;&#31572;&#26696;&#65292;&#27169;&#31946;&#21270;&#27169;&#22411;&#23545;&#21407;&#22987;&#36755;&#20837;&#30340;&#35760;&#24518;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;P2F&#20855;&#26377;&#24456;&#24378;&#30340;&#27169;&#31946;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#19979;&#33258;&#36866;&#24212;&#20351;&#29992;&#65292;&#26080;&#38656;&#25163;&#21160;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#24378;&#22823;&#30340;&#33021;&#21147;&#65292;&#20294;&#38544;&#31169;&#27844;&#38706;&#30340;&#39118;&#38505;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20445;&#25252;&#38544;&#31169;&#26041;&#27861;&#65292;&#22914;&#24046;&#20998;&#38544;&#31169;&#21644;&#21516;&#24577;&#21152;&#23494;&#65292;&#22312;&#21482;&#26377;&#40657;&#30418;API&#30340;&#29615;&#22659;&#19979;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#35201;&#27714;&#27169;&#22411;&#36879;&#26126;&#24615;&#25110;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Prompt2Forget&#65288;P2F&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#35774;&#35745;&#29992;&#20110;&#35299;&#20915;LLM&#26412;&#22320;&#38544;&#31169;&#25361;&#25112;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25945;&#23548;LLM&#24536;&#35760;&#26469;&#23454;&#29616;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#23558;&#23436;&#25972;&#38382;&#39064;&#20998;&#35299;&#20026;&#36739;&#23567;&#30340;&#29255;&#27573;&#65292;&#29983;&#25104;&#34394;&#26500;&#30340;&#31572;&#26696;&#65292;&#24182;&#20351;&#27169;&#22411;&#23545;&#21407;&#22987;&#36755;&#20837;&#30340;&#35760;&#24518;&#27169;&#31946;&#21270;&#12290;&#25105;&#20204;&#26681;&#25454;&#19981;&#21516;&#39046;&#22495;&#30340;&#21253;&#21547;&#38544;&#31169;&#25935;&#24863;&#20449;&#24687;&#30340;&#38382;&#39064;&#21019;&#24314;&#20102;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;P2F&#23454;&#29616;&#20102;&#38646;-shot&#27867;&#21270;&#65292;&#21487;&#20197;&#22312;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#19979;&#33258;&#36866;&#24212;&#65292;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;P2F&#20855;&#26377;&#24456;&#24378;&#30340;&#27169;&#31946;&#21270;LLM&#35760;&#24518;&#30340;&#33021;&#21147;&#65292;&#32780;&#19981;&#20250;&#25439;&#22833;&#20219;&#20309;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern. Traditional privacy-preserving methods, such as Differential Privacy and Homomorphic Encryption, are inadequate for black-box API-only settings, demanding either model transparency or heavy computational resources. We propose Prompt2Forget (P2F), the first framework designed to tackle the LLM local privacy challenge by teaching LLM to forget. The method involves decomposing full questions into smaller segments, generating fabricated answers, and obfuscating the model's memory of the original input. A benchmark dataset was crafted with questions containing privacy-sensitive information from diverse fields. P2F achieves zero-shot generalization, allowing adaptability across a wide range of use cases without manual adjustments. Experimental results indicate P2F's robust capability to obfuscate LLM's memory, attaining a forgetfulness score of around 90\% without any utility los
&lt;/p&gt;</description></item><item><title>Nebula&#26159;&#19968;&#20010;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#65292;&#29992;&#20110;&#21160;&#24577;&#20998;&#26512;&#24694;&#24847;&#36719;&#20214;&#12290;&#23427;&#33021;&#22815;&#27010;&#25324;&#19981;&#21516;&#30340;&#34892;&#20026;&#34920;&#31034;&#21644;&#26684;&#24335;&#65292;&#24182;&#32467;&#21512;&#21160;&#24577;&#26085;&#24535;&#25253;&#21578;&#20013;&#30340;&#24322;&#26500;&#20449;&#24687;&#12290;&#23454;&#39564;&#35777;&#26126;Nebula&#22312;&#19977;&#20010;&#37325;&#35201;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2310.10664</link><description>&lt;p&gt;
Nebula:&#29992;&#20110;&#21160;&#24577;&#24694;&#24847;&#36719;&#20214;&#20998;&#26512;&#30340;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Nebula: Self-Attention for Dynamic Malware Analysis. (arXiv:2310.10664v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10664
&lt;/p&gt;
&lt;p&gt;
Nebula&#26159;&#19968;&#20010;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#65292;&#29992;&#20110;&#21160;&#24577;&#20998;&#26512;&#24694;&#24847;&#36719;&#20214;&#12290;&#23427;&#33021;&#22815;&#27010;&#25324;&#19981;&#21516;&#30340;&#34892;&#20026;&#34920;&#31034;&#21644;&#26684;&#24335;&#65292;&#24182;&#32467;&#21512;&#21160;&#24577;&#26085;&#24535;&#25253;&#21578;&#20013;&#30340;&#24322;&#26500;&#20449;&#24687;&#12290;&#23454;&#39564;&#35777;&#26126;Nebula&#22312;&#19977;&#20010;&#37325;&#35201;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#20998;&#26512;&#36890;&#36807;&#22312;&#21463;&#25511;&#29615;&#22659;&#20013;&#25191;&#34892;&#31243;&#24207;&#24182;&#23558;&#20854;&#34892;&#20026;&#23384;&#20648;&#22312;&#26085;&#24535;&#25253;&#21578;&#20013;&#65292;&#21487;&#20197;&#26816;&#27979;Windows&#24694;&#24847;&#36719;&#20214;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#24320;&#22987;&#22312;&#36825;&#20123;&#25253;&#21578;&#19978;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20197;&#36827;&#34892;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#25110;&#20998;&#31867;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#20165;&#32771;&#34385;&#20102;&#21367;&#31215;&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#65292;&#21482;&#20851;&#27880;&#36816;&#34892;&#26102;&#35843;&#29992;&#30340;API&#65292;&#24182;&#26410;&#32771;&#34385;&#20854;&#20182;&#30456;&#20851;&#30340;&#24322;&#26500;&#20449;&#24687;&#26469;&#28304;&#65292;&#22914;&#32593;&#32476;&#21644;&#25991;&#20214;&#25805;&#20316;&#12290;&#27492;&#22806;&#65292;&#20195;&#30721;&#21644;&#39044;&#35757;&#32451;&#27169;&#22411;&#24456;&#38590;&#33719;&#21462;&#65292;&#36825;&#38480;&#21046;&#20102;&#35813;&#30740;&#31350;&#39046;&#22495;&#20013;&#32467;&#26524;&#30340;&#21487;&#37325;&#29616;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;Nebula&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#36825;&#26159;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#12289;&#22522;&#20110;&#33258;&#27880;&#24847;&#21147;&#30340;&#36716;&#25442;&#22120;&#31070;&#32463;&#26550;&#26500;&#65292;&#21487;&#20197;&#27010;&#25324;&#19981;&#21516;&#30340;&#34892;&#20026;&#34920;&#31034;&#21644;&#26684;&#24335;&#65292;&#32467;&#21512;&#21160;&#24577;&#26085;&#24535;&#25253;&#21578;&#20013;&#30340;&#24322;&#26500;&#20449;&#24687;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;Nebula&#30340;&#26377;&#25928;&#24615;&#65292;&#23427;&#22312;&#19977;&#20010;&#37325;&#35201;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic analysis enables detecting Windows malware by executing programs in a controlled environment, and storing their actions in log reports. Previous work has started training machine learning models on such reports to perform either malware detection or malware classification. However, most of the approaches (i) have only considered convolutional and long-short term memory networks, (ii) they have been built focusing only on APIs called at runtime, without considering other relevant though heterogeneous sources of information like network and file operations, and (iii) the code and pretrained models are hardly available, hindering reproducibility of results in this research area. In this work, we overcome these limitations by presenting Nebula, a versatile, self-attention transformer-based neural architecture that can generalize across different behavior representations and formats, combining heterogeneous information from dynamic log reports. We show the efficacy of Nebula on thre
&lt;/p&gt;</description></item></channel></rss>