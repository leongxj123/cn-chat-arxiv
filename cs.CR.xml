<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21709;&#24212;&#36807;&#28388;&#30340;&#22810;Agent&#38450;&#24481;&#26694;&#26550;AutoDefense&#65292;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;LLMs&#23545;&#25239;&#36234;&#29425;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#27491;&#24120;&#29992;&#25143;&#35831;&#27714;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.04783</link><description>&lt;p&gt;
AutoDefense: &#22810;Agent LLM &#38450;&#24481;&#23545;&#25239;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04783
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21709;&#24212;&#36807;&#28388;&#30340;&#22810;Agent&#38450;&#24481;&#26694;&#26550;AutoDefense&#65292;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;LLMs&#23545;&#25239;&#36234;&#29425;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#27491;&#24120;&#29992;&#25143;&#35831;&#27714;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#36947;&#24503;&#23545;&#40784;&#26041;&#38754;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#20197;&#38450;&#27490;&#22312;&#29992;&#25143;&#35831;&#27714;&#26102;&#29983;&#25104;&#26377;&#23475;&#20449;&#24687;&#65292;&#20294;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36234;&#29425;&#25915;&#20987;&#12290; &#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21709;&#24212;&#36807;&#28388;&#30340;&#22810;Agent&#38450;&#24481;&#26694;&#26550;AutoDefense&#65292;&#29992;&#20110;&#20174;LLMs&#20013;&#36807;&#28388;&#26377;&#23475;&#22238;&#22797;&#12290; &#27492;&#26694;&#26550;&#20026;LLM&#20195;&#29702;&#20998;&#37197;&#19981;&#21516;&#35282;&#33394;&#65292;&#24182;&#21033;&#29992;&#23427;&#20204;&#20849;&#21516;&#23436;&#25104;&#38450;&#24481;&#20219;&#21153;&#12290; &#20219;&#21153;&#30340;&#21010;&#20998;&#22686;&#24378;&#20102;LLMs&#30340;&#25972;&#20307;&#36981;&#24490;&#25351;&#20196;&#33021;&#21147;&#65292;&#24182;&#20351;&#20854;&#20182;&#38450;&#24481;&#32452;&#20214;&#20316;&#20026;&#24037;&#20855;&#38598;&#25104;&#25104;&#20026;&#21487;&#33021;&#12290; AutoDefense &#21487;&#20197;&#36866;&#24212;&#21508;&#31181;&#35268;&#27169;&#21644;&#31181;&#31867;&#30340;&#24320;&#28304;LLMs&#20316;&#20026;&#20195;&#29702;&#12290; &#36890;&#36807;&#23545;&#22823;&#37327;&#26377;&#23475;&#21644;&#23433;&#20840;&#25552;&#31034;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;AutoDefense&#22312;&#25552;&#39640;&#23545;&#25239;&#36234;&#29425;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#30340;&#21516;&#26102;&#65292;&#20445;&#25345;&#20102;&#27491;&#24120;&#29992;&#25143;&#35831;&#27714;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04783v1 Announce Type: cross  Abstract: Despite extensive pre-training and fine-tuning in moral alignment to prevent generating harmful information at user request, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a response-filtering based multi-agent defense framework that filters harmful responses from LLMs. This framework assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. AutoDefense can adapt to various sizes and kinds of open-source LLMs that serve as agents. Through conducting extensive experiments on a large scale of harmful and safe prompts, we validate the effectiveness of the proposed AutoDefense in improving the robustness against jailbreak attacks, while maintaining the performance at normal user request. Our code and 
&lt;/p&gt;</description></item></channel></rss>