<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>LoRA&#20316;&#20026;&#25915;&#20987;&#32773;&#28183;&#36879;LLM&#23433;&#20840;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20849;&#20139;&#19982;&#29609;&#32781;&#22330;&#26223;&#19979;&#21487;&#33021;&#23454;&#29616;&#30340;&#25915;&#20987;&#26426;&#20250;&#12290;</title><link>https://arxiv.org/abs/2403.00108</link><description>&lt;p&gt;
&#23558;LoRA&#20316;&#20026;&#25915;&#20987;&#65281;&#22312;Share-and-Play&#22330;&#26223;&#19979;&#31359;&#36879;LLM&#23433;&#20840;
&lt;/p&gt;
&lt;p&gt;
LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00108
&lt;/p&gt;
&lt;p&gt;
LoRA&#20316;&#20026;&#25915;&#20987;&#32773;&#28183;&#36879;LLM&#23433;&#20840;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20849;&#20139;&#19982;&#29609;&#32781;&#22330;&#26223;&#19979;&#21487;&#33021;&#23454;&#29616;&#30340;&#25915;&#20987;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;LLMs&#36827;&#34892;&#24494;&#35843;&#23545;&#20110;&#22686;&#24378;&#20854;&#29305;&#23450;&#20219;&#21153;&#30340;&#24615;&#33021;&#24182;&#30830;&#20445;&#27169;&#22411;&#34892;&#20026;&#19982;&#20154;&#31867;&#20559;&#22909;&#20445;&#25345;&#19968;&#33268;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#21508;&#31181;&#24494;&#35843;&#26041;&#27861;&#20013;&#65292;LoRA&#22240;&#20854;&#25928;&#29575;&#21644;&#26131;&#29992;&#24615;&#32780;&#22791;&#21463;&#25512;&#23815;&#65292;&#20801;&#35768;&#26368;&#32456;&#29992;&#25143;&#36731;&#26494;&#22312;&#24320;&#28304;&#24179;&#21488;&#19978;&#21457;&#24067;&#21644;&#37319;&#29992;&#36731;&#37327;&#30340;LoRA&#27169;&#22359;&#65292;&#20197;&#23450;&#21046;&#20854;&#27169;&#22411;&#20197;&#36866;&#24212;&#19981;&#21516;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#20415;&#30340;&#20849;&#20139;&#19982;&#29609;&#32781;&#35774;&#32622;&#25171;&#24320;&#20102;&#26032;&#30340;&#25915;&#20987;&#38754;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#23558;LoRA&#20316;&#20026;&#25915;&#20987;&#32773;&#65292;&#20363;&#22914;&#32972;&#38376;&#27880;&#20837;&#65292;&#24182;&#24191;&#27867;&#20998;&#21457;&#23545;&#25239;&#24615;LoRA&#32473;&#31038;&#21306;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#21033;&#30340;&#21518;&#26524;&#12290;&#23613;&#31649;&#20849;&#20139;LoRA&#27169;&#22359;&#23384;&#22312;&#24040;&#22823;&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#20294;&#36825;&#19968;&#26041;&#38754;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#22312;&#19981;&#26029;&#22686;&#38271;&#30340;&#20849;&#20139;&#19982;&#29609;&#32781;&#22330;&#26223;&#20013;&#21487;&#33021;&#20570;&#20986;&#30340;&#25915;&#20987;&#26426;&#20250;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#23558;&#21518;&#38376;&#27880;&#20837;LoRA&#27169;&#22359;&#24182;&#28145;&#20837;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00108v1 Announce Type: cross  Abstract: Fine-tuning LLMs is crucial to enhancing their task-specific performance and ensuring model behaviors are aligned with human preferences. Among various fine-tuning methods, LoRA is popular for its efficiency and ease to use, allowing end-users to easily post and adopt lightweight LoRA modules on open-source platforms to tailor their model for different customization. However, such a handy share-and-play setting opens up new attack surfaces, that the attacker can render LoRA as an attacker, such as backdoor injection, and widely distribute the adversarial LoRA to the community easily. This can result in detrimental outcomes. Despite the huge potential risks of sharing LoRA modules, this aspect however has not been fully explored. To fill the gap, in this study we thoroughly investigate the attack opportunities enabled in the growing share-and-play scenario. Specifically, we study how to inject backdoor into the LoRA module and dive deep
&lt;/p&gt;</description></item></channel></rss>