<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#36890;&#36807;&#21452;&#21521;&#38170;&#23450;&#26041;&#27861;&#65292;&#35782;&#21035;&#37027;&#20123;&#22312;&#24494;&#35843;&#21518;&#26356;&#21487;&#33021;&#38477;&#20302;&#27169;&#22411;&#23433;&#20840;&#24615;&#30340;&#33391;&#24615;&#25968;&#25454;&#23376;&#38598;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#26377;&#23475;&#35831;&#27714;&#30340;&#21709;&#24212;&#29575;&#12290;</title><link>https://arxiv.org/abs/2404.01099</link><description>&lt;p&gt;
&#20320;&#30340;&#8220;&#23433;&#20840;&#8221;&#25968;&#25454;&#20013;&#26377;&#20160;&#20040;&#65311;&#65306;&#35782;&#21035;&#30772;&#22351;&#23433;&#20840;&#24615;&#30340;&#33391;&#24615;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01099
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21452;&#21521;&#38170;&#23450;&#26041;&#27861;&#65292;&#35782;&#21035;&#37027;&#20123;&#22312;&#24494;&#35843;&#21518;&#26356;&#21487;&#33021;&#38477;&#20302;&#27169;&#22411;&#23433;&#20840;&#24615;&#30340;&#33391;&#24615;&#25968;&#25454;&#23376;&#38598;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#26377;&#23475;&#35831;&#27714;&#30340;&#21709;&#24212;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#21363;&#20351;&#32463;&#36807;&#35843;&#25972;&#20197;&#30830;&#20445;&#23433;&#20840;&#24615;&#21644;&#23545;&#40784;&#24615;&#65292;&#20063;&#23481;&#26131;&#34987;&#36234;&#29425;&#12290;&#19968;&#20123;&#30740;&#31350;&#34920;&#26126;&#65292;&#21482;&#26159;&#36827;&#19968;&#27493;&#20351;&#29992;&#33391;&#24615;&#25968;&#25454;&#65288;&#21363;&#27809;&#26377;&#26377;&#23475;&#20869;&#23481;&#30340;&#25968;&#25454;&#65289;&#23545;&#19968;&#20010;&#23545;&#40784;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#20250;&#23548;&#33268;&#23433;&#20840;&#24615;&#22823;&#24133;&#19979;&#38477;&#12290;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#33391;&#24615;&#24494;&#35843;&#19981;&#32463;&#24847;&#38388;&#23548;&#33268;&#36234;&#29425;&#30340;&#25968;&#25454;&#20013;&#24515;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#20004;&#31181;&#35270;&#35282;&#34920;&#24449;&#24494;&#35843;&#25968;&#25454;&#65306;&#34920;&#31034;&#21644;&#26799;&#24230;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#21521;&#38170;&#23450;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20248;&#20808;&#32771;&#34385;&#38752;&#36817;&#26377;&#23475;&#31034;&#20363;&#24182;&#36828;&#31163;&#33391;&#24615;&#31034;&#20363;&#30340;&#25968;&#25454;&#28857;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#26356;&#26377;&#21487;&#33021;&#22312;&#24494;&#35843;&#21518;&#38477;&#20302;&#27169;&#22411;&#23433;&#20840;&#24615;&#30340;&#33391;&#24615;&#25968;&#25454;&#23376;&#38598;&#12290;&#20165;&#20165;&#35757;&#32451;100&#20010;&#36825;&#20123;&#30475;&#20284;&#33391;&#24615;&#30340;&#25968;&#25454;&#28857;&#65292;&#23601;&#21487;&#20197;&#20351;&#24494;&#35843;&#27169;&#22411;&#32943;&#23450;&#22320;&#22238;&#24212;&#36229;&#36807;70&#65285;&#30340;&#34987;&#27979;&#35797;&#30340;&#26377;&#23475;&#35831;&#27714;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01099v1 Announce Type: cross  Abstract: Current Large Language Models (LLMs), even those tuned for safety and alignment, are susceptible to jailbreaking. Some have found that just further fine-tuning an aligned model with benign data (i.e., data without harmful content) surprisingly leads to substantial degradation in safety. We delve into the data-centric aspects of why benign fine-tuning inadvertently contributes to jailbreaking. First, we represent fine-tuning data through two lenses: representation and gradient spaces. Furthermore, we propose a bi-directional anchoring method that prioritizes data points that are close to harmful examples and distant from benign ones. By doing so, our approach effectively identifies subsets of benign data that are more likely to degrade the model's safety after fine-tuning. Training on just 100 of these seemingly benign datapoints can lead to the fine-tuned model affirmatively responding to &gt; 70% of tested harmful requests, compared to &lt;
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#35774;&#35745;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#30340;&#31616;&#21333;&#28789;&#27963;&#26694;&#26550;&#65292;&#29992;&#20110;&#23547;&#25214;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#65292;&#24182;&#33719;&#24471;&#20102;&#25913;&#36827;&#21644;&#26377;&#26102;&#26159;&#26368;&#20248;&#30340;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.11173</link><description>&lt;p&gt;
&#22914;&#20309;&#22312;&#38544;&#31169;&#26465;&#20214;&#19979;&#20351;&#26799;&#24230;&#21464;&#24471;&#26356;&#23567;&#65306;&#25913;&#36827;&#30340;&#24046;&#20998;&#38544;&#31169;&#38750;&#20984;&#20248;&#21270;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
How to Make the Gradients Small Privately: Improved Rates for Differentially Private Non-Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11173
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#35774;&#35745;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#30340;&#31616;&#21333;&#28789;&#27963;&#26694;&#26550;&#65292;&#29992;&#20110;&#23547;&#25214;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#65292;&#24182;&#33719;&#24471;&#20102;&#25913;&#36827;&#21644;&#26377;&#26102;&#26159;&#26368;&#20248;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20197;&#25214;&#21040;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#20351;&#29992;&#31169;&#26377;&#30340;&#36817;&#20284;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#26469;&#8220;&#28909;&#21551;&#21160;&#8221;&#21478;&#19968;&#20010;&#29992;&#20110;&#23547;&#25214;&#31283;&#23450;&#28857;&#30340;&#31169;&#26377;&#31639;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#26469;&#33719;&#24471;&#23545;&#20960;&#31867;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#25913;&#36827;&#29978;&#33267;&#26159;&#26368;&#20248;&#36895;&#29575;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#23547;&#25214;&#24179;&#28369;&#38750;&#20984;&#32463;&#39564;&#25439;&#22833;&#20989;&#25968;&#31283;&#23450;&#28857;&#30340;&#36895;&#29575;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#19987;&#38376;&#38024;&#23545;&#22840;&#33832;-&#20984;&#20989;&#25968;&#65292;&#36825;&#31181;&#20989;&#25968;&#27010;&#25324;&#20102;&#26143;-&#20984;&#20989;&#25968;&#65292;&#24182;&#22312;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#21644;&#35757;&#32451;&#19968;&#20123;&#31070;&#32463;&#32593;&#32476;&#26102;&#20986;&#29616;&#12290;&#25105;&#20204;&#20026;&#36825;&#20010;&#31867;&#21035;&#23454;&#29616;&#20102;&#26368;&#20248;&#36895;&#29575;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#23545;&#28385;&#36275;Kurdyka-Lojasiewicz&#65288;KL&#65289;&#26465;&#20214;&#30340;&#20989;&#25968;&#23547;&#25214;&#31283;&#23450;&#28857;&#30340;&#26368;&#20248;&#31639;&#27861;&#12290;&#20363;&#22914;&#65292;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#32463;&#24120;&#28385;&#36275;&#36825;&#20010;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11173v1 Announce Type: new  Abstract: We provide a simple and flexible framework for designing differentially private algorithms to find approximate stationary points of non-convex loss functions. Our framework is based on using a private approximate risk minimizer to "warm start" another private algorithm for finding stationary points. We use this framework to obtain improved, and sometimes optimal, rates for several classes of non-convex loss functions. First, we obtain improved rates for finding stationary points of smooth non-convex empirical loss functions. Second, we specialize to quasar-convex functions, which generalize star-convex functions and arise in learning dynamical systems and training some neural nets. We achieve the optimal rate for this class. Third, we give an optimal algorithm for finding stationary points of functions satisfying the Kurdyka-Lojasiewicz (KL) condition. For example, over-parameterized neural networks often satisfy this condition. Fourth, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#21270;&#23545;&#38544;&#31169;&#25512;&#26029;&#20013;&#32676;&#20307;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20943;&#23569;ReLU&#28608;&#27963;&#20989;&#25968;&#25968;&#37327;&#20250;&#19981;&#25104;&#27604;&#20363;&#22320;&#38477;&#20302;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#23545;&#20110;&#22810;&#25968;&#32676;&#20307;&#21017;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#12290;&#37319;&#29992;&#31616;&#21333;&#30340;&#24494;&#35843;&#27493;&#39588;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.03629</link><description>&lt;p&gt;
&#31169;&#26377;&#25512;&#26029;&#30340;&#32447;&#24615;&#21270;&#23545;&#32676;&#20307;&#20934;&#30830;&#24615;&#30340;&#19981;&#23545;&#31216;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Disparate Impact on Group Accuracy of Linearization for Private Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#21270;&#23545;&#38544;&#31169;&#25512;&#26029;&#20013;&#32676;&#20307;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20943;&#23569;ReLU&#28608;&#27963;&#20989;&#25968;&#25968;&#37327;&#20250;&#19981;&#25104;&#27604;&#20363;&#22320;&#38477;&#20302;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#23545;&#20110;&#22810;&#25968;&#32676;&#20307;&#21017;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#12290;&#37319;&#29992;&#31616;&#21333;&#30340;&#24494;&#35843;&#27493;&#39588;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#20445;&#23545;&#20855;&#26377;&#23494;&#30721;&#23433;&#20840;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#38544;&#31169;&#20445;&#25252;&#30340;&#25512;&#26029;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;&#20026;&#20102;&#20943;&#36731;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#20013;&#26114;&#36149;&#30340;&#21152;&#23494;&#35745;&#31639;&#30340;&#29942;&#39048;&#65292;&#26368;&#36817;&#30340;&#26041;&#27861;&#24314;&#35758;&#22312;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#20013;&#32447;&#24615;&#21270;&#30446;&#26631;&#37096;&#20998;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;&#36825;&#31181;&#25216;&#26415;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#36816;&#34892;&#26102;&#38388;&#65292;&#23545;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#24448;&#24448;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#35745;&#31639;&#20248;&#21183;&#21487;&#33021;&#23548;&#33268;&#20844;&#24179;&#24615;&#25104;&#26412;&#22686;&#21152;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21457;&#29616;&#20943;&#23569;ReLU&#28608;&#27963;&#20989;&#25968;&#25968;&#37327;&#20250;&#19981;&#25104;&#27604;&#20363;&#22320;&#38477;&#20302;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#23545;&#20110;&#22810;&#25968;&#32676;&#20307;&#21017;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#37322;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#22312;&#23545;&#20915;&#31574;&#36793;&#30028;&#24615;&#36136;&#36827;&#34892;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#22522;&#30784;&#19978;&#25552;&#20379;&#20102;&#25968;&#23398;&#35299;&#37322;&#65292;&#21516;&#26102;&#36824;&#23637;&#31034;&#20102;&#36825;&#20010;&#38382;&#39064;&#22312;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#21644;&#20307;&#31995;&#32467;&#26500;&#20013;&#30340;&#26222;&#36941;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#31616;&#21333;&#30340;&#31243;&#24207;&#25913;&#21464;&#32447;&#24615;&#27169;&#22411;&#30340;&#24494;&#35843;&#27493;&#39588;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models ca
&lt;/p&gt;</description></item><item><title>PsySafe&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#26694;&#26550;&#65292;&#36890;&#36807;&#28145;&#20837;&#25506;&#35752;&#26234;&#33021;&#20307;&#24515;&#29702;&#23398;&#65292;&#25581;&#31034;&#26234;&#33021;&#20307;&#30340;&#40657;&#26263;&#24515;&#29702;&#29366;&#24577;&#23545;&#23433;&#20840;&#26500;&#25104;&#23041;&#32961;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#39118;&#38505;&#32531;&#35299;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2401.11880</link><description>&lt;p&gt;
PsySafe&#65306;&#22522;&#20110;&#24515;&#29702;&#23398;&#30340;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#23433;&#20840;&#25915;&#20987;&#12289;&#38450;&#24481;&#21644;&#35780;&#20272;&#30340;&#32508;&#21512;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11880
&lt;/p&gt;
&lt;p&gt;
PsySafe&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#26694;&#26550;&#65292;&#36890;&#36807;&#28145;&#20837;&#25506;&#35752;&#26234;&#33021;&#20307;&#24515;&#29702;&#23398;&#65292;&#25581;&#31034;&#26234;&#33021;&#20307;&#30340;&#40657;&#26263;&#24515;&#29702;&#29366;&#24577;&#23545;&#23433;&#20840;&#26500;&#25104;&#23041;&#32961;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#39118;&#38505;&#32531;&#35299;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#22312;&#21152;&#20837;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21518;&#65292;&#23637;&#29616;&#20986;&#20102;&#38598;&#20307;&#26234;&#33021;&#30340;&#28145;&#36828;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26234;&#33021;&#34987;&#24694;&#24847;&#20351;&#29992;&#21487;&#33021;&#24102;&#26469;&#37325;&#22823;&#39118;&#38505;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#20851;&#20110;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#23433;&#20840;&#38382;&#39064;&#30340;&#20840;&#38754;&#30740;&#31350;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#36890;&#36807;&#21019;&#26032;&#30340;&#35270;&#35282;&#25506;&#32034;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#21457;&#29616;&#26234;&#33021;&#20307;&#30340;&#40657;&#26263;&#24515;&#29702;&#29366;&#24577;&#26500;&#25104;&#20102;&#23545;&#23433;&#20840;&#30340;&#37325;&#22823;&#23041;&#32961;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#26234;&#33021;&#20307;&#24515;&#29702;&#23398;&#20026;&#22522;&#30784;&#30340;&#32508;&#21512;&#26694;&#26550;&#65288;PsySafe&#65289;&#65292;&#20851;&#27880;&#19977;&#20010;&#20851;&#38190;&#39046;&#22495;&#65306;&#39318;&#20808;&#65292;&#35782;&#21035;&#26234;&#33021;&#20307;&#20013;&#30340;&#40657;&#26263;&#20154;&#26684;&#29305;&#24449;&#22914;&#20309;&#23548;&#33268;&#39118;&#38505;&#34892;&#20026;&#65307;&#20854;&#27425;&#65292;&#20174;&#24515;&#29702;&#21644;&#34892;&#20026;&#35282;&#24230;&#35780;&#20272;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#65307;&#31532;&#19977;&#65292;&#21046;&#23450;&#26377;&#25928;&#30340;&#31574;&#30053;&#26469;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.11880v2 Announce Type: replace-cross  Abstract: Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit profound capabilities in collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with multi-agent systems remains limited. In this paper, we explore these concerns through the innovative lens of agent psychology, revealing that the dark psychological states of agents constitute a significant threat to safety. To tackle these concerns, we propose a comprehensive framework (PsySafe) grounded in agent psychology, focusing on three key areas: firstly, identifying how dark personality traits in agents can lead to risky behaviors; secondly, evaluating the safety of multi-agent systems from the psychological and behavioral perspectives, and thirdly, devising effective strategies to mitigate these risks. Our experiments reveal
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;212&#20010;&#30495;&#23454;&#30340;&#24694;&#24847;&#26381;&#21153;&#65288;Malla&#65289;&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#22320;&#19979;&#24066;&#22330;&#30340;&#25193;&#25955;&#21644;&#23545;&#20844;&#20849;LLM&#26381;&#21153;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#20854;&#20351;&#29992;&#30340;&#31574;&#30053;&#21644;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2401.03315</link><description>&lt;p&gt;
Malla: &#25581;&#31192;&#29616;&#23454;&#19990;&#30028;&#20013;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#24694;&#24847;&#26381;&#21153;
&lt;/p&gt;
&lt;p&gt;
Malla: Demystifying Real-world Large Language Model Integrated Malicious Services. (arXiv:2401.03315v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03315
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;212&#20010;&#30495;&#23454;&#30340;&#24694;&#24847;&#26381;&#21153;&#65288;Malla&#65289;&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#22320;&#19979;&#24066;&#22330;&#30340;&#25193;&#25955;&#21644;&#23545;&#20844;&#20849;LLM&#26381;&#21153;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#20854;&#20351;&#29992;&#30340;&#31574;&#30053;&#21644;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#22320;&#19979;&#21033;&#29992;&#65292;&#20063;&#31216;&#20026;Malla&#65292;&#27491;&#22312;&#22686;&#21152;&#65292;&#21152;&#21095;&#20102;&#32593;&#32476;&#23433;&#20840;&#23041;&#32961;&#65292;&#24182;&#23545;LLMs&#25216;&#26415;&#30340;&#21487;&#20449;&#24230;&#25552;&#20986;&#20102;&#30097;&#38382;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#24456;&#23569;&#26377;&#24037;&#20316;&#21162;&#21147;&#21435;&#20102;&#35299;&#36825;&#31181;&#26032;&#22411;&#32593;&#32476;&#29359;&#32618;&#30340;&#35268;&#27169;&#12289;&#24433;&#21709;&#21644;&#25216;&#26415;&#12290;&#26412;&#25991;&#26159;&#31532;&#19968;&#27425;&#23545;212&#20010;&#30495;&#23454;&#30340;Malla&#36827;&#34892;&#31995;&#32479;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#22320;&#19979;&#24066;&#22330;&#30340;&#25193;&#25955;&#65292;&#24182;&#25581;&#31034;&#20102;&#23427;&#20204;&#30340;&#25805;&#20316;&#27169;&#24335;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#24320;&#20102;Malla&#29983;&#24577;&#31995;&#32479;&#65292;&#25581;&#31034;&#20102;&#20854;&#26174;&#33879;&#30340;&#22686;&#38271;&#23545;&#24403;&#20170;&#20844;&#20849;LLM&#26381;&#21153;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#23545;212&#20010;Mallas&#36827;&#34892;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;8&#20010;&#21518;&#31471;LLMs&#65292;&#20197;&#21450;182&#20010;&#32469;&#36807;&#20844;&#20849;LLM API&#20445;&#25252;&#25514;&#26045;&#30340;&#25552;&#31034;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;Mallas&#20351;&#29992;&#30340;&#31574;&#30053;&#65292;&#21253;&#25324;&#28389;&#29992;&#26410;&#32463;&#23457;&#26597;&#30340;LLMs&#21644;&#36890;&#36807;&#36234;&#29425;&#25552;&#31034;&#21033;&#29992;&#20844;&#20849;LLM API&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;Malla&#29359;&#32618;&#34892;&#20026;&#30340;&#23454;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The underground exploitation of large language models (LLMs) for malicious services (i.e., Malla) is witnessing an uptick, amplifying the cyber threat landscape and posing questions about the trustworthiness of LLM technologies. However, there has been little effort to understand this new cybercrime, in terms of its magnitude, impact, and techniques. In this paper, we conduct the first systematic study on 212 real-world Mallas, uncovering their proliferation in underground marketplaces and exposing their operational modalities. Our study discloses the Malla ecosystem, revealing its significant growth and impact on today's public LLM services. Through examining 212 Mallas, we uncovered eight backend LLMs used by Mallas, along with 182 prompts that circumvent the protective measures of public LLM APIs. We further demystify the tactics employed by Mallas, including the abuse of uncensored LLMs and the exploitation of public LLM APIs through jailbreak prompts. Our findings enable a better 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#32858;&#31867;&#31639;&#27861;DPM&#65292;&#36890;&#36807;&#25628;&#32034;&#20934;&#30830;&#30340;&#25968;&#25454;&#28857;&#20998;&#31163;&#22120;&#26469;&#36827;&#34892;&#38544;&#31169;&#20445;&#25252;&#30340;&#32858;&#31867;&#12290;&#20851;&#38190;&#36129;&#29486;&#26159;&#35782;&#21035;&#22823;&#38388;&#38548;&#20998;&#31163;&#22120;&#24182;&#21512;&#29702;&#20998;&#37197;&#38544;&#31169;&#39044;&#31639;&#12290;</title><link>http://arxiv.org/abs/2307.02969</link><description>&lt;p&gt;
DPM: &#36890;&#36807;&#20998;&#31163;&#32858;&#31867;&#25935;&#24863;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
DPM: Clustering Sensitive Data through Separation. (arXiv:2307.02969v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#32858;&#31867;&#31639;&#27861;DPM&#65292;&#36890;&#36807;&#25628;&#32034;&#20934;&#30830;&#30340;&#25968;&#25454;&#28857;&#20998;&#31163;&#22120;&#26469;&#36827;&#34892;&#38544;&#31169;&#20445;&#25252;&#30340;&#32858;&#31867;&#12290;&#20851;&#38190;&#36129;&#29486;&#26159;&#35782;&#21035;&#22823;&#38388;&#38548;&#20998;&#31163;&#22120;&#24182;&#21512;&#29702;&#20998;&#37197;&#38544;&#31169;&#39044;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#32858;&#31867;&#20197;&#26080;&#30417;&#30563;&#26041;&#24335;&#23545;&#25968;&#25454;&#28857;&#36827;&#34892;&#20998;&#32452;&#65292;&#21516;&#26102;&#30830;&#20445;&#25935;&#24863;&#20449;&#24687;&#24471;&#20197;&#20445;&#25252;&#12290;&#20808;&#21069;&#30340;&#38544;&#31169;&#20445;&#25252;&#32858;&#31867;&#20851;&#27880;&#28857;&#22312;&#20110;&#35782;&#21035;&#28857;&#20113;&#30340;&#32858;&#38598;&#12290;&#26412;&#25991;&#21017;&#37319;&#21462;&#21478;&#19968;&#31181;&#26041;&#27861;&#65292;&#20851;&#27880;&#20110;&#35782;&#21035;&#36866;&#24403;&#30340;&#20998;&#31163;&#22120;&#20197;&#20998;&#31163;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#24046;&#20998;&#38544;&#31169;&#32858;&#31867;&#31639;&#27861;DPM&#65292;&#20197;&#24046;&#20998;&#38544;&#31169;&#30340;&#26041;&#24335;&#25628;&#32034;&#20934;&#30830;&#30340;&#25968;&#25454;&#28857;&#20998;&#31163;&#22120;&#12290;DPM&#35299;&#20915;&#20102;&#23547;&#25214;&#20934;&#30830;&#20998;&#31163;&#22120;&#30340;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;&#35782;&#21035;&#32858;&#31867;&#38388;&#30340;&#22823;&#38388;&#38548;&#20998;&#31163;&#22120;&#32780;&#19981;&#26159;&#32858;&#31867;&#20869;&#30340;&#23567;&#38388;&#38548;&#20998;&#31163;&#22120;&#65292;&#20197;&#21450;&#22312;&#24320;&#38144;&#38544;&#31169;&#39044;&#31639;&#26102;&#65292;&#20248;&#20808;&#32771;&#34385;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#36739;&#22823;&#23376;&#37096;&#20998;&#30340;&#20998;&#31163;&#22120;&#12290;&#21033;&#29992;&#24046;&#20998;&#38544;&#31169;&#25351;&#25968;&#26426;&#21046;&#65292;DPM&#36890;&#36807;&#38543;&#26426;&#36873;&#25321;&#20855;&#26377;&#39640;&#25928;&#29992;&#24615;&#30340;&#32858;&#31867;&#20998;&#31163;&#22120;&#65306;&#23545;&#20110;&#25968;&#25454;&#38598;D&#65292;&#22914;&#26524;&#20013;&#24515;&#30340;60%&#20998;&#20301;&#25968;&#20013;&#23384;&#22312;&#23485;&#30340;&#20302;&#23494;&#24230;&#20998;&#31163;&#22120;&#65292;DPM&#20250;&#21457;&#29616;&#23427;&#12290;
&lt;/p&gt;
&lt;p&gt;
Privacy-preserving clustering groups data points in an unsupervised manner whilst ensuring that sensitive information remains protected. Previous privacy-preserving clustering focused on identifying concentration of point clouds. In this paper, we take another path and focus on identifying appropriate separators that split a data set. We introduce the novel differentially private clustering algorithm DPM that searches for accurate data point separators in a differentially private manner. DPM addresses two key challenges for finding accurate separators: identifying separators that are large gaps between clusters instead of small gaps within a cluster and, to efficiently spend the privacy budget, prioritising separators that split the data into large subparts. Using the differentially private Exponential Mechanism, DPM randomly chooses cluster separators with provably high utility: For a data set $D$, if there is a wide low-density separator in the central $60\%$ quantile, DPM finds that
&lt;/p&gt;</description></item></channel></rss>