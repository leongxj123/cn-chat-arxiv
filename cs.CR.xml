<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#20351;&#24471;&#23545;&#25163;&#33021;&#22815;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#26469;&#31574;&#21010;&#30446;&#26631;&#36873;&#27665;&#30340;&#25805;&#32437;&#12290;</title><link>https://arxiv.org/abs/2403.12399</link><description>&lt;p&gt;
&#23558;&#32593;&#32476;&#36873;&#20030;&#21270;&#65306;&#29992;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Electioneering the Network: Dynamic Multi-Step Adversarial Attacks for Community Canvassing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#20351;&#24471;&#23545;&#25163;&#33021;&#22815;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#26469;&#31574;&#21010;&#30446;&#26631;&#36873;&#27665;&#30340;&#25805;&#32437;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20170;&#22825;&#30340;&#19990;&#30028;&#20013;&#65292;&#23545;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#25805;&#32437;&#38382;&#39064;&#26159;&#19968;&#20010;&#30495;&#27491;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#21463;&#36873;&#27665;&#27169;&#22411;&#12289;&#32593;&#32476;&#19978;&#30340;&#35266;&#28857;&#21644;&#26497;&#21270;&#21160;&#24577;&#30340;&#30740;&#31350;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#31038;&#21306;&#25289;&#31080;&#24314;&#27169;&#20026;&#19968;&#20010;&#36890;&#36807;&#23545;GNN&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#32780;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#30340;&#21160;&#24577;&#36807;&#31243;&#12290;&#29616;&#26377;&#30340;GNN&#25915;&#20987;&#37117;&#26159;&#21333;&#27493;&#30340;&#65292;&#27809;&#26377;&#32771;&#34385;&#32593;&#32476;&#20013;&#20449;&#24687;&#20256;&#25773;&#30340;&#21160;&#24577;&#32423;&#32852;&#29305;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#29616;&#23454;&#30340;&#22330;&#26223;&#65292;&#21363;&#23545;&#25163;&#20351;&#29992;GNN&#20316;&#20026;&#20195;&#29702;&#26469;&#39044;&#27979;&#21644;&#25805;&#32437;&#36873;&#27665;&#20559;&#22909;&#65292;&#29305;&#21035;&#26159;&#19981;&#30830;&#23450;&#30340;&#36873;&#27665;&#12290;&#23545;GNN&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#36890;&#30693;&#23545;&#25163;&#21487;&#20197;&#36827;&#34892;&#25112;&#30053;&#25805;&#32437;&#65292;&#20197;&#20351;&#24471;&#30446;&#26631;&#36873;&#27665;&#20837;&#25945;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;$\textit{&#31038;&#21306;&#25289;&#31080;&#30340;&#26368;&#23567;&#39044;&#31639;&#25915;&#20987;}$&#65288;MBACC&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;MBACC&#38382;&#39064;&#26159;NP&#22256;&#38590;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#31038;&#21306;&#25289;&#31080;&#65288;MAC&#65289;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;MAC m
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12399v1 Announce Type: new  Abstract: The problem of online social network manipulation for community canvassing is of real concern in today's world. Motivated by the study of voter models, opinion and polarization dynamics on networks, we model community canvassing as a dynamic process over a network enabled via gradient-based attacks on GNNs. Existing attacks on GNNs are all single-step and do not account for the dynamic cascading nature of information diffusion in networks. We consider the realistic scenario where an adversary uses a GNN as a proxy to predict and manipulate voter preferences, especially uncertain voters. Gradient-based attacks on the GNN inform the adversary of strategic manipulations that can be made to proselytize targeted voters. In particular, we explore $\textit{minimum budget attacks for community canvassing}$ (MBACC). We show that the MBACC problem is NP-Hard and propose Dynamic Multi-Step Adversarial Community Canvassing (MAC) to address it. MAC m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#21487;&#20998;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;DP-SGD&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#30456;&#20284;&#24615;&#25439;&#22833;&#20989;&#25968;&#30340;$L_2$&#25935;&#24863;&#24230;&#22686;&#38271;&#38543;&#30528;&#25209;&#37327;&#22823;&#23567;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.03104</link><description>&lt;p&gt;
&#38750;&#21487;&#20998;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;DP-SGD&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DP-SGD for non-decomposable objective functions. (arXiv:2310.03104v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03104
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#21487;&#20998;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;DP-SGD&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#30456;&#20284;&#24615;&#25439;&#22833;&#20989;&#25968;&#30340;$L_2$&#25935;&#24863;&#24230;&#22686;&#38271;&#38543;&#30528;&#25209;&#37327;&#22823;&#23567;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#26159;&#24320;&#21457;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24120;&#35265;&#27493;&#39588;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#30001;&#20110;&#32570;&#23569;&#26631;&#31614;&#65292;&#38656;&#35201;&#20351;&#29992;&#22522;&#20110;&#30456;&#20284;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#22914;&#23545;&#27604;&#25439;&#22833;&#65292;&#26469;&#20248;&#21270;&#30456;&#20284;&#36755;&#20837;&#20043;&#38388;&#30340;&#36317;&#31163;&#24182;&#26368;&#22823;&#21270;&#19981;&#21516;&#36755;&#20837;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#38543;&#30528;&#38544;&#31169;&#38382;&#39064;&#30340;&#22686;&#22810;&#65292;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#26469;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#21464;&#24471;&#26356;&#21152;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#29983;&#25104;&#36755;&#20837;&#30340;&#26041;&#24335;&#65292;&#23427;&#20204;&#30340;$L_2$&#25935;&#24863;&#24230;&#20250;&#38543;&#30528;&#25209;&#37327;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#36825;&#23545;&#20110;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#26041;&#27861;&#65288;&#22914;DP-SGD&#65289;&#29305;&#21035;&#19981;&#21033;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#21464;&#20307;&#65292;&#29992;&#20110;&#22522;&#20110;&#30456;&#20284;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#29305;&#21035;&#26159;&#24120;&#29992;&#30340;&#23545;&#27604;&#25439;&#22833;&#65292;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#22788;&#29702;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#20351;&#24471;&#26799;&#24230;&#30340;&#25935;&#24863;&#24230;&#23545;&#20110;&#25209;&#37327;&#22823;&#23567;&#26159;$O(1)$&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised pre-training is a common step in developing computer vision models and large language models. In this setting, the absence of labels requires the use of similarity-based loss functions, such as contrastive loss, that favor minimizing the distance between similar inputs and maximizing the distance between distinct inputs. As privacy concerns mount, training these models using differential privacy has become more important. However, due to how inputs are generated for these losses, one of their undesirable properties is that their $L_2$ sensitivity can grow with increasing batch size. This property is particularly disadvantageous for differentially private training methods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD variant for similarity based loss functions -- in particular the commonly used contrastive loss -- that manipulates gradients of the objective function in a novel way to obtain a senstivity of the summed gradient that is $O(1)$ for batch size
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;SEA&#65292;&#19968;&#31181;&#29992;&#20110;&#24402;&#22240;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#26426;&#22120;&#23398;&#20064;&#23433;&#20840;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26694;&#26550;&#26469;&#29702;&#35299;&#25915;&#20987;&#30340;&#28436;&#21464;&#36807;&#31243;&#65292;&#24182;&#26377;&#25928;&#24402;&#22240;&#25915;&#20987;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#31532;&#20108;&#27425;&#20986;&#29616;&#30340;&#25915;&#20987;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#26088;&#22312;&#23454;&#29616;&#21462;&#35777;&#21644;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#24773;&#25253;&#20849;&#20139;&#12290;</title><link>http://arxiv.org/abs/2308.11845</link><description>&lt;p&gt;
SEA&#65306;&#21487;&#20849;&#20139;&#21644;&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#24402;&#22240;
&lt;/p&gt;
&lt;p&gt;
SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks. (arXiv:2308.11845v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11845
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;SEA&#65292;&#19968;&#31181;&#29992;&#20110;&#24402;&#22240;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#26426;&#22120;&#23398;&#20064;&#23433;&#20840;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26694;&#26550;&#26469;&#29702;&#35299;&#25915;&#20987;&#30340;&#28436;&#21464;&#36807;&#31243;&#65292;&#24182;&#26377;&#25928;&#24402;&#22240;&#25915;&#20987;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#31532;&#20108;&#27425;&#20986;&#29616;&#30340;&#25915;&#20987;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#26088;&#22312;&#23454;&#29616;&#21462;&#35777;&#21644;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#24773;&#25253;&#20849;&#20139;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#26469;&#33258;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#25932;&#23545;&#26679;&#26412;&#30340;&#25915;&#20987;&#12290;&#23613;&#31649;&#26377;&#21508;&#31181;&#21162;&#21147;&#26469;&#26816;&#27979;&#21644;&#38450;&#27490;&#36825;&#20123;&#25915;&#20987;&#65292;&#20294;&#20173;&#28982;&#38656;&#35201;&#19968;&#31181;&#26356;&#20840;&#38754;&#30340;&#26041;&#27861;&#26469;&#35760;&#24405;&#12289;&#20998;&#26512;&#21644;&#20998;&#20139;&#25915;&#20987;&#35777;&#25454;&#12290;&#34429;&#28982;&#32463;&#20856;&#23433;&#20840;&#39046;&#22495;&#21463;&#30410;&#20110;&#25104;&#29087;&#30340;&#21462;&#35777;&#21644;&#24773;&#25253;&#20849;&#20139;&#25216;&#26415;&#65292;&#20294;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#23578;&#26410;&#25214;&#21040;&#19968;&#31181;&#26041;&#24335;&#26469;&#23545;&#25915;&#20987;&#32773;&#36827;&#34892;&#30011;&#20687;&#65292;&#24182;&#20998;&#20139;&#20851;&#20110;&#20182;&#20204;&#30340;&#20449;&#24687;&#12290;&#20026;&#27492;&#65292;&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;SEA&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#23433;&#20840;&#31995;&#32479;&#65292;&#29992;&#20110;&#20026;&#21462;&#35777;&#30446;&#30340;&#34920;&#24449;&#23545;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#40657;&#30418;&#25915;&#20987;&#65292;&#24182;&#20419;&#36827;&#21487;&#35299;&#37322;&#30340;&#24773;&#25253;&#20849;&#20139;&#12290;SEA&#21033;&#29992;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26694;&#26550;&#23558;&#35266;&#23519;&#21040;&#30340;&#26597;&#35810;&#24207;&#21015;&#24402;&#22240;&#20110;&#24050;&#30693;&#30340;&#25915;&#20987;&#65292;&#22240;&#27492;&#23427;&#33021;&#22815;&#29702;&#35299;&#25915;&#20987;&#30340;&#28436;&#21464;&#36807;&#31243;&#32780;&#19981;&#20165;&#20165;&#20851;&#27880;&#26368;&#32456;&#30340;&#25932;&#23545;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;SEA&#33021;&#22815;&#26377;&#25928;&#36827;&#34892;&#25915;&#20987;&#24402;&#22240;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#31532;&#20108;&#27425;&#20986;&#29616;&#30340;&#25915;&#20987;&#65292;&#20063;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) systems are vulnerable to adversarial examples, particularly those from query-based black-box attacks. Despite various efforts to detect and prevent such attacks, there is a need for a more comprehensive approach to logging, analyzing, and sharing evidence of attacks. While classic security benefits from well-established forensics and intelligence sharing, Machine Learning is yet to find a way to profile its attackers and share information about them. In response, this paper introduces SEA, a novel ML security system to characterize black-box attacks on ML systems for forensic purposes and to facilitate human-explainable intelligence sharing. SEA leverages the Hidden Markov Models framework to attribute the observed query sequence to known attacks. It thus understands the attack's progression rather than just focusing on the final adversarial examples. Our evaluations reveal that SEA is effective at attack attribution, even on their second occurrence, and is robus
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#24182;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.01144</link><description>&lt;p&gt;
UniASM&#65306;&#26080;&#38656;&#24494;&#35843;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
UniASM: Binary Code Similarity Detection without Fine-tuning. (arXiv:2211.01144v3 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01144
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#24182;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#34987;&#24191;&#27867;&#29992;&#20110;&#21508;&#31181;&#20108;&#36827;&#21046;&#20998;&#26512;&#20219;&#21153;&#65292;&#22914;&#28431;&#27934;&#25628;&#32034;&#12289;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#12289;&#20811;&#38534;&#26816;&#27979;&#21644;&#34917;&#19969;&#20998;&#26512;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;&#27604;&#20256;&#32479;&#30340;&#22522;&#20110;&#29305;&#24449;&#30340;&#26041;&#27861;&#26356;&#22909;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;transformer&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#29992;&#20110;&#23398;&#20064;&#20108;&#36827;&#21046;&#20989;&#25968;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#22686;&#21152;&#20102;tokens&#30340;&#35821;&#20041;&#20449;&#24687;&#24182;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Binary code similarity detection (BCSD) is widely used in various binary analysis tasks such as vulnerability search, malware detection, clone detection, and patch analysis. Recent studies have shown that the learning-based binary code embedding models perform better than the traditional feature-based approaches. In this paper, we propose a novel transformer-based binary code embedding model named UniASM to learn representations of the binary functions. We design two new training tasks to make the spatial distribution of the generated vectors more uniform, which can be used directly in BCSD without any fine-tuning. In addition, we present a new tokenization approach for binary functions, which increases the token's semantic information and mitigates the out-of-vocabulary (OOV) problem. We conduct an in-depth analysis of the factors affecting model performance through ablation experiments and obtain some new and valuable findings. The experimental results show that UniASM outperforms th
&lt;/p&gt;</description></item></channel></rss>