<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#22810;&#22238;&#21512;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#30475;&#20284;&#33391;&#24615;&#30340;&#23545;&#35805;&#26041;&#24335;&#36880;&#28176;&#21319;&#32423;&#19982;&#27169;&#22411;&#30340;&#20132;&#20114;&#65292;&#25104;&#21151;&#31361;&#30772;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2404.01833</link><description>&lt;p&gt;
&#20255;&#22823;&#65292;&#29616;&#22312;&#20889;&#19968;&#31687;&#20851;&#20110;&#27492;&#30340;&#25991;&#31456;&#65306;Crescendo&#22810;&#22238;&#21512;LLM&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01833
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#22810;&#22238;&#21512;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#30475;&#20284;&#33391;&#24615;&#30340;&#23545;&#35805;&#26041;&#24335;&#36880;&#28176;&#21319;&#32423;&#19982;&#27169;&#22411;&#30340;&#20132;&#20114;&#65292;&#25104;&#21151;&#31361;&#30772;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27969;&#34892;&#31243;&#24230;&#22823;&#24133;&#19978;&#21319;&#65292;&#24182;&#19988;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#24212;&#29992;&#20110;&#22810;&#20010;&#39046;&#22495;&#12290;&#36825;&#20123;LLMs&#22312;&#35774;&#35745;&#19978;&#36991;&#20813;&#28041;&#21450;&#38750;&#27861;&#25110;&#19981;&#36947;&#24503;&#30340;&#35805;&#39064;&#65292;&#20197;&#36991;&#20813;&#23545;&#36127;&#36131;&#20219;&#30340;AI&#36896;&#25104;&#20260;&#23475;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#20986;&#29616;&#20102;&#19968;&#31995;&#21015;&#25915;&#20987;&#65292;&#34987;&#31216;&#20026;&#8220;&#36234;&#29425;&#8221;&#65292;&#26088;&#22312;&#31361;&#30772;&#36825;&#31181;&#23545;&#40784;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#36234;&#29425;&#25915;&#20987;&#26088;&#22312;&#32553;&#23567;&#27169;&#22411;&#33021;&#20570;&#30340;&#19982;&#24895;&#24847;&#20570;&#30340;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#36234;&#29425;&#25915;&#20987;&#12290;&#19982;&#29616;&#26377;&#30340;&#36234;&#29425;&#26041;&#27861;&#19981;&#21516;&#65292;Crescendo&#26159;&#19968;&#31181;&#22810;&#22238;&#21512;&#36234;&#29425;&#65292;&#20197;&#19968;&#31181;&#30475;&#20284;&#33391;&#24615;&#30340;&#26041;&#24335;&#19982;&#27169;&#22411;&#36827;&#34892;&#20132;&#20114;&#12290;&#23427;&#20174;&#26377;&#20851;&#25163;&#22836;&#20219;&#21153;&#30340;&#19968;&#33324;&#25552;&#31034;&#25110;&#38382;&#39064;&#24320;&#22987;&#65292;&#28982;&#21518;&#36880;&#28176;&#21319;&#32423;&#23545;&#35805;&#65292;&#24341;&#29992;&#27169;&#22411;&#30340;&#22238;&#22797;&#65292;&#36880;&#28176;&#23548;&#33268;&#25104;&#21151;&#36234;&#29425;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;ChatGPT&#12289;Gemini Pr&#22312;&#20869;&#30340;&#21508;&#31181;&#20844;&#20849;&#31995;&#32479;&#19978;&#35780;&#20272;&#20102;Crescendo&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01833v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications. These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms. However, a recent line of attacks, known as "jailbreaks", seek to overcome this alignment. Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do. In this paper, we introduce a novel jailbreak attack called Crescendo. Unlike existing jailbreak methods, Crescendo is a multi-turn jailbreak that interacts with the model in a seemingly benign manner. It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies, progressively leading to a successful jailbreak. We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pr
&lt;/p&gt;</description></item></channel></rss>