<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#28508;&#22312;&#23545;&#25239;&#35757;&#32451;&#65288;LAT&#65289;&#26469;&#38450;&#24481;AI&#31995;&#32479;&#20013;&#26410;&#39044;&#35265;&#30340;&#25925;&#38556;&#27169;&#24335;&#65292;&#36890;&#36807;&#21033;&#29992;&#32593;&#32476;&#23454;&#38469;&#29992;&#20110;&#39044;&#27979;&#30340;&#21387;&#32553;&#12289;&#25277;&#35937;&#21644;&#32467;&#26500;&#21270;&#27010;&#24565;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#26377;&#25928;&#28165;&#38500;&#20102;&#24694;&#24847;&#36719;&#20214;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2403.05030</link><description>&lt;p&gt;
&#21033;&#29992;&#28508;&#22312;&#23545;&#25239;&#35757;&#32451;&#38450;&#24481;&#26410;&#39044;&#35265;&#30340;&#25925;&#38556;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
Defending Against Unforeseen Failure Modes with Latent Adversarial Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#28508;&#22312;&#23545;&#25239;&#35757;&#32451;&#65288;LAT&#65289;&#26469;&#38450;&#24481;AI&#31995;&#32479;&#20013;&#26410;&#39044;&#35265;&#30340;&#25925;&#38556;&#27169;&#24335;&#65292;&#36890;&#36807;&#21033;&#29992;&#32593;&#32476;&#23454;&#38469;&#29992;&#20110;&#39044;&#27979;&#30340;&#21387;&#32553;&#12289;&#25277;&#35937;&#21644;&#32467;&#26500;&#21270;&#27010;&#24565;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#26377;&#25928;&#28165;&#38500;&#20102;&#24694;&#24847;&#36719;&#20214;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#26377;&#26102;&#22312;&#37096;&#32626;&#21518;&#20250;&#23637;&#31034;&#20986;&#26377;&#23475;&#30340;&#24847;&#22806;&#34892;&#20026;&#12290;&#23613;&#31649;&#24320;&#21457;&#20154;&#21592;&#36827;&#34892;&#20102;&#22823;&#37327;&#35786;&#26029;&#21644;&#35843;&#35797;&#65292;&#36825;&#31181;&#24773;&#20917;&#32463;&#24120;&#21457;&#29983;&#12290;&#30001;&#20110;&#25915;&#20987;&#38754;&#38750;&#24120;&#24191;&#27867;&#65292;&#20174;&#27169;&#22411;&#20013;&#20943;&#23569;&#39118;&#38505;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#32791;&#23613;&#22320;&#25628;&#32034;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22833;&#36133;&#30340;&#36755;&#20837;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#32418;&#38431;&#21644;&#23545;&#25239;&#35757;&#32451;&#65288;AT&#65289;&#36890;&#24120;&#29992;&#20110;&#20351;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#26356;&#21152;&#20581;&#22766;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#24182;&#19981;&#36275;&#20197;&#36991;&#20813;&#35768;&#22810;&#19982;&#23545;&#25239;&#35757;&#32451;&#19981;&#21516;&#30340;&#30495;&#23454;&#19990;&#30028;&#25925;&#38556;&#27169;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#28508;&#22312;&#23545;&#25239;&#35757;&#32451;&#65288;LAT&#65289;&#26469;&#38450;&#24481;&#28431;&#27934;&#65292;&#32780;&#26080;&#38656;&#29983;&#25104;&#24341;&#21457;&#36825;&#20123;&#28431;&#27934;&#30340;&#36755;&#20837;&#12290;LAT&#21033;&#29992;&#32593;&#32476;&#23454;&#38469;&#29992;&#20110;&#39044;&#27979;&#30340;&#21387;&#32553;&#12289;&#25277;&#35937;&#21644;&#32467;&#26500;&#21270;&#27010;&#24565;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;LAT&#26469;&#28165;&#38500;&#24694;&#24847;&#36719;&#20214;&#24182;&#38450;&#24481;&#38024;&#23545;&#20445;&#30041;&#31867;&#21035;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;&#25105;&#20204;&#23637;&#31034;&#22312;&#22270;&#20687;&#20998;&#31867;&#12289;&#25991;&#26412;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05030v1 Announce Type: cross  Abstract: AI systems sometimes exhibit harmful unintended behaviors post-deployment. This is often despite extensive diagnostics and debugging by developers. Minimizing risks from models is challenging because the attack surface is so large. It is not tractable to exhaustively search for inputs that may cause a model to fail. Red-teaming and adversarial training (AT) are commonly used to make AI systems more robust. However, they have not been sufficient to avoid many real-world failure modes that differ from the ones adversarially trained on. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without generating inputs that elicit them. LAT leverages the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. We use LAT to remove trojans and defend against held-out classes of adversarial attacks. We show in image classification, text classifi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Prompt Adversarial Tuning (PAT)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#24182;&#23558;&#20854;&#20316;&#20026;&#21069;&#32512;&#23884;&#20837;&#21040;&#29992;&#25143;&#25552;&#31034;&#20013;&#65292;&#23454;&#29616;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#34892;&#20026;&#30340;&#38450;&#24481;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;LLMs&#20813;&#21463;&#20135;&#29983;&#26377;&#23475;&#20449;&#24687;&#30340;&#24433;&#21709;&#26041;&#38754;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>https://arxiv.org/abs/2402.06255</link><description>&lt;p&gt;
&#36827;&#21462;&#30340;&#40077;&#21187;&#36890;&#36807;&#25552;&#31034;&#23545;&#25239;&#35843;&#25972;&#25269;&#21046;&#36234;&#29425;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Prompt Adversarial Tuning (PAT)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#24182;&#23558;&#20854;&#20316;&#20026;&#21069;&#32512;&#23884;&#20837;&#21040;&#29992;&#25143;&#25552;&#31034;&#20013;&#65292;&#23454;&#29616;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#34892;&#20026;&#30340;&#38450;&#24481;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;LLMs&#20813;&#21463;&#20135;&#29983;&#26377;&#23475;&#20449;&#24687;&#30340;&#24433;&#21709;&#26041;&#38754;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#20063;&#23481;&#26131;&#21463;&#21040;&#29305;&#23450;&#25552;&#31034;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#32469;&#36807;&#20869;&#32622;&#30340;&#23433;&#20840;&#25514;&#26045;&#24182;&#25552;&#20379;&#21361;&#38505;&#25110;&#38750;&#27861;&#20869;&#23481;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#36234;&#29425;&#34892;&#20026;&#12290;&#20026;&#20102;&#20445;&#25252;LLMs&#20813;&#21463;&#20135;&#29983;&#26377;&#23475;&#20449;&#24687;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#21508;&#31181;&#38450;&#24481;&#31574;&#30053;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#38598;&#20013;&#22312;&#20869;&#23481;&#36807;&#28388;&#25110;&#27169;&#22411;&#30340;&#23545;&#25239;&#35757;&#32451;&#26041;&#38754;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Prompt Adversarial Tuning&#65288;PAT&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#24182;&#23558;&#20854;&#20316;&#20026;&#21069;&#32512;&#23884;&#20837;&#21040;&#29992;&#25143;&#25552;&#31034;&#20013;&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#38450;&#24481;&#31574;&#30053;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31867;&#20284;&#23545;&#25239;&#35757;&#32451;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#20197;&#23454;&#29616;&#25105;&#20204;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#20132;&#26367;&#26356;&#26032;&#25915;&#20987;&#21644;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#26159;&#31532;&#19968;&#20010;&#20174;&#25552;&#31034;&#35843;&#25972;&#30340;&#35282;&#24230;&#23454;&#26045;&#38450;&#24481;&#30340;&#20154;&#12290;&#19968;&#26086;&#24212;&#29992;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20960;&#20046;&#19981;&#20250;&#24433;&#21709;LLMs&#30340;&#25805;&#20316;&#25928;&#29575;&#12290;&#23454;&#39564;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25269;&#24481;&#36234;&#29425;&#34892;&#20026;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although Large Language Models (LLMs) have achieved tremendous success in various applications, they are also susceptible to certain prompts that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak. To protect LLMs from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or adversarial training of models. In this paper, we propose an approach named Prompt Adversarial Tuning (PAT) to train a defense control mechanism, which is then embedded as a prefix to user prompts to implement our defense strategy. We design a training process similar to adversarial training to achieve our optimized goal, alternating between updating attack and defense controls. To our knowledge, we are the first to implement defense from the perspective of prompt tuning. Once employed, our method will hardly impact the operational efficiency of LLMs. Experiments show that our method i
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992; Morse &#29702;&#35770;&#25552;&#39640;&#24046;&#20998;&#31169;&#26377;&#32858;&#31867;&#25928;&#29992;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20026;&#22797;&#26434;&#38598;&#32676;&#20998;&#24067;&#36866;&#37197;&#39640;&#26031;&#23376;&#38598;&#32676;&#65292;&#21363;&#20351;&#23545;&#20110;&#29616;&#26377;&#30340;&#31616;&#21333;&#32858;&#31867;&#26041;&#27861;&#65292;&#20854;&#25928;&#26524;&#20063;&#26356;&#22909;&#65292;&#22312;&#30456;&#21516;&#30340;&#38544;&#31169;&#27700;&#24179;&#19979;&#19981;&#20250;&#22686;&#21152;&#38544;&#31169;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2304.13886</link><description>&lt;p&gt;
&#36890;&#36807;&#21160;&#24577;&#22788;&#29702;&#25552;&#39640;&#24046;&#20998;&#31169;&#26377;&#32858;&#31867;&#30340;&#25928;&#29992;
&lt;/p&gt;
&lt;p&gt;
Improving the Utility of Differentially Private Clustering through Dynamical Processing. (arXiv:2304.13886v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992; Morse &#29702;&#35770;&#25552;&#39640;&#24046;&#20998;&#31169;&#26377;&#32858;&#31867;&#25928;&#29992;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20026;&#22797;&#26434;&#38598;&#32676;&#20998;&#24067;&#36866;&#37197;&#39640;&#26031;&#23376;&#38598;&#32676;&#65292;&#21363;&#20351;&#23545;&#20110;&#29616;&#26377;&#30340;&#31616;&#21333;&#32858;&#31867;&#26041;&#27861;&#65292;&#20854;&#25928;&#26524;&#20063;&#26356;&#22909;&#65292;&#22312;&#30456;&#21516;&#30340;&#38544;&#31169;&#27700;&#24179;&#19979;&#19981;&#20250;&#22686;&#21152;&#38544;&#31169;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#32531;&#35299;&#24046;&#20998;&#31169;&#26377;&#32858;&#31867;&#20219;&#21153;&#20013;&#25928;&#29992;&#21644;&#38544;&#31169;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#31616;&#21333;&#30340;&#38598;&#32676;&#26041;&#27861;&#65292;&#23545;&#20110;&#38750;&#20984;&#38598;&#32676;&#30340;&#32858;&#31867;&#25928;&#26524;&#36739;&#24046;&#12290;&#36890;&#36807;&#21033;&#29992; Morse &#29702;&#35770;&#65292;&#25105;&#20204;&#23558;&#39640;&#26031;&#23376;&#38598;&#32676;&#25353;&#23618;&#27425;&#36830;&#25509;&#20197;&#36866;&#24212;&#26356;&#22797;&#26434;&#30340;&#38598;&#32676;&#20998;&#24067;&#12290;&#30001;&#20110;&#24046;&#20998;&#31169;&#26377;&#23376;&#32676;&#26159;&#36890;&#36807;&#29616;&#26377;&#26041;&#27861;&#33719;&#24471;&#30340;&#65292;&#22240;&#27492;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20960;&#20046;&#19981;&#20250;&#22686;&#21152;&#38544;&#31169;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#32972;&#26223;&#65292;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#24402;&#32435;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#23454;&#29616;&#20219;&#24847;&#25968;&#37327;&#30340;&#32676;&#38598;&#12290;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#30456;&#21516;&#30340;&#38544;&#31169;&#27700;&#24179;&#19979;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#32858;&#31867;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study aims to alleviate the trade-off between utility and privacy in the task of differentially private clustering. Existing works focus on simple clustering methods, which show poor clustering performance for non-convex clusters. By utilizing Morse theory, we hierarchically connect the Gaussian sub-clusters to fit complex cluster distributions. Because differentially private sub-clusters are obtained through the existing methods, the proposed method causes little or no additional privacy loss. We provide a theoretical background that implies that the proposed method is inductive and can achieve any desired number of clusters. Experiments on various datasets show that our framework achieves better clustering performance at the same privacy level, compared to the existing methods.
&lt;/p&gt;</description></item></channel></rss>