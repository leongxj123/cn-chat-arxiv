<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SyncPool&#30340;&#26032;&#39062;&#23433;&#20840;&#28040;&#38500;&#27495;&#20041;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#31070;&#32463;&#35821;&#35328;&#38544;&#20889;&#26415;&#20013;&#30340;&#20998;&#35789;&#27169;&#31946;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.17524</link><description>&lt;p&gt;
&#21487;&#35777;&#23433;&#20840;&#30340;&#31070;&#32463;&#35821;&#35328;&#38544;&#20889;&#26415;&#28040;&#38500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Provably Secure Disambiguating Neural Linguistic Steganography
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17524
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SyncPool&#30340;&#26032;&#39062;&#23433;&#20840;&#28040;&#38500;&#27495;&#20041;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#31070;&#32463;&#35821;&#35328;&#38544;&#20889;&#26415;&#20013;&#30340;&#20998;&#35789;&#27169;&#31946;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#35777;&#23433;&#20840;&#30340;&#31070;&#32463;&#35821;&#35328;&#38544;&#20889;&#26415;&#24573;&#30053;&#20102;&#19968;&#20010;&#20851;&#38190;&#26041;&#38754;&#65306;&#21457;&#36865;&#26041;&#24517;&#39035;&#23545;&#38544;&#20889;&#25991;&#26412;&#36827;&#34892;&#21435;&#35760;&#21495;&#21270;&#65292;&#20197;&#36991;&#20813;&#24341;&#36215;&#31363;&#21548;&#32773;&#30340;&#24576;&#30097;&#12290;&#22522;&#20110;&#23376;&#35789;&#30340;&#35821;&#35328;&#27169;&#22411;&#20250;&#23548;&#33268;&#20998;&#35789;&#27169;&#31946;&#38382;&#39064;&#65292;&#22312;&#25152;&#26377;&#22522;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#31070;&#32463;&#35821;&#35328;&#38544;&#20889;&#26415;&#23454;&#29616;&#20013;&#20598;&#23572;&#20250;&#20986;&#29616;&#35299;&#30721;&#22833;&#36133;&#12290;&#30446;&#21069;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#26041;&#27861;&#21253;&#25324;&#26356;&#25913;&#20505;&#36873;&#35789;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#20351;&#20854;&#19982;&#21487;&#35777;&#23433;&#20840;&#30340;&#38544;&#20889;&#26415;&#19981;&#30456;&#23481;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SyncPool&#30340;&#26032;&#39062;&#23433;&#20840;&#28040;&#38500;&#27495;&#20041;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#20998;&#35789;&#27169;&#31946;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#38544;&#20889;&#23884;&#20837;&#31639;&#27861;&#36816;&#34892;&#20043;&#21069;&#23558;&#25152;&#26377;&#20855;&#26377;&#21069;&#32512;&#20851;&#31995;&#30340;&#20196;&#29260;&#20998;&#32452;&#22312;&#20505;&#36873;&#27744;&#20013;&#65292;&#20197;&#28040;&#38500;&#27169;&#31946;&#20196;&#29260;&#20043;&#38388;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20351;&#25509;&#25910;&#26041;&#33021;&#22815;&#21516;&#27493;&#21457;&#36865;&#26041;&#30340;&#37319;&#26679;&#36807;&#31243;&#65292;&#20351;&#29992;&#20102;&#19968;&#20010;&#20849;&#20139;&#23494;&#30721;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17524v1 Announce Type: cross  Abstract: Recent research in provably secure neural linguistic steganography has overlooked a crucial aspect: the sender must detokenize stegotexts to avoid raising suspicion from the eavesdropper. The segmentation ambiguity problem, which arises when using language models based on subwords, leads to occasional decoding failures in all neural language steganography implementations based on these models. Current solutions to this issue involve altering the probability distribution of candidate words, rendering them incompatible with provably secure steganography. We propose a novel secure disambiguation method named SyncPool, which effectively addresses the segmentation ambiguity problem. We group all tokens with prefix relationships in the candidate pool before the steganographic embedding algorithm runs to eliminate uncertainty among ambiguous tokens. To enable the receiver to synchronize the sampling process of the sender, a shared cryptograph
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22686;&#24378;&#21644;&#22810;&#26679;&#21270;LOTL&#24694;&#24847;&#27963;&#21160;&#30340;&#23384;&#22312;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;&#24694;&#24847;&#27963;&#21160;&#26816;&#27979;&#24615;&#33021;&#30340;&#25968;&#25454;&#22686;&#24378;&#26694;&#26550;</title><link>https://arxiv.org/abs/2402.18329</link><description>&lt;p&gt;
&#20381;&#38752;&#30693;&#24773;&#25968;&#25454;&#22686;&#24378;&#30340;&#25269;&#21046;&#29983;&#27963;-&#20381;&#36182;-&#22303;&#22320;&#21453;&#21521;&#22806;&#22771;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Living-off-The-Land Reverse-Shell Detection by Informed Data Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18329
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22686;&#24378;&#21644;&#22810;&#26679;&#21270;LOTL&#24694;&#24847;&#27963;&#21160;&#30340;&#23384;&#22312;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;&#24694;&#24847;&#27963;&#21160;&#26816;&#27979;&#24615;&#33021;&#30340;&#25968;&#25454;&#22686;&#24378;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#27963;-&#20381;&#36182;-&#22303;&#22320;(LOTL)&#36827;&#25915;&#26041;&#27861;&#20381;&#36182;&#20110;&#36890;&#36807;&#21512;&#27861;&#24212;&#29992;&#31243;&#24207;&#25191;&#34892;&#30340;&#21629;&#20196;&#38142;&#26469;&#29359;&#32618;&#34892;&#20026;&#65292;&#20165;&#21487;&#36890;&#36807;&#31995;&#32479;&#26085;&#24535;&#20998;&#26512;&#26469;&#35782;&#21035;&#12290;LOTL&#25216;&#26415;&#38544;&#34255;&#22312;&#26222;&#36890;&#21512;&#27861;&#27963;&#21160;&#20135;&#29983;&#30340;&#20107;&#20214;&#27969;&#20013;&#65292;&#23041;&#32961;&#34892;&#20026;&#32773;&#32463;&#24120;&#36890;&#36807;&#28151;&#28102;&#26469;&#20266;&#35013;&#27963;&#21160;&#65292;&#20351;&#20854;&#38590;&#20197;&#22312;&#19981;&#24341;&#36215;&#22823;&#37327;&#35823;&#35686;&#24773;&#20917;&#19979;&#26816;&#27979;&#65292;&#21363;&#20351;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20063;&#26159;&#22914;&#27492;&#12290;&#20026;&#20102;&#22312;&#36825;&#26679;&#24694;&#21155;&#30340;&#29615;&#22659;&#20013;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#26694;&#26550;&#65292;&#20197;&#22686;&#24378;&#21644;&#20351;&#22810;&#26679;&#21270;LOTL&#24694;&#24847;&#27963;&#21160;&#22312;&#21512;&#27861;&#26085;&#24535;&#20013;&#30340;&#23384;&#22312;&#12290;&#22312;&#23041;&#32961;&#24773;&#25253;&#30340;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#27880;&#20837;&#24050;&#30693;&#22312;&#37326;&#22806;&#20351;&#29992;&#30340;&#25915;&#20987;&#27169;&#26495;&#29983;&#25104;&#25968;&#25454;&#38598;&#65292;&#36827;&#19968;&#27493;&#20016;&#23500;&#21512;&#27861;&#27963;&#21160;&#30340;&#21487;&#22609;&#27169;&#24335;&#65292;&#20197;&#22797;&#21046;&#22238;&#36991;&#23041;&#32961;&#34892;&#20026;&#32773;&#34892;&#20026;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18329v1 Announce Type: cross  Abstract: The living-off-the-land (LOTL) offensive methodologies rely on the perpetration of malicious actions through chains of commands executed by legitimate applications, identifiable exclusively by analysis of system logs. LOTL techniques are well hidden inside the stream of events generated by common legitimate activities, moreover threat actors often camouflage activity through obfuscation, making them particularly difficult to detect without incurring in plenty of false alarms, even using machine learning. To improve the performance of models in such an harsh environment, we propose an augmentation framework to enhance and diversify the presence of LOTL malicious activity inside legitimate logs. Guided by threat intelligence, we generate a dataset by injecting attack templates known to be employed in the wild, further enriched by malleable patterns of legitimate activities to replicate the behavior of evasive threat actors. We conduct an
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#38544;&#31169;&#20445;&#25252;&#30340;&#20302;&#31209;&#36866;&#24212;&#35299;&#20915;&#26041;&#26696;PrivateLoRA&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#36866;&#24212;&#25439;&#22833;&#21644;&#20195;&#29702;&#25915;&#20987;&#27169;&#22411;&#30340;MI&#22686;&#30410;&#26469;&#25269;&#24481;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2402.11989</link><description>&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#30340;&#20302;&#31209;&#36866;&#24212;Latent&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Low-Rank Adaptation for Latent Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11989
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#38544;&#31169;&#20445;&#25252;&#30340;&#20302;&#31209;&#36866;&#24212;&#35299;&#20915;&#26041;&#26696;PrivateLoRA&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#36866;&#24212;&#25439;&#22833;&#21644;&#20195;&#29702;&#25915;&#20987;&#27169;&#22411;&#30340;MI&#22686;&#30410;&#26469;&#25269;&#24481;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#29992;&#20110;&#36890;&#36807;&#26368;&#23567;&#21270;&#36866;&#24212;&#25439;&#22833;&#65292;&#33258;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#36866;&#24212;Latent&#25193;&#25955;&#27169;&#22411;&#65288;LDM&#65289;&#20197;&#29983;&#25104;&#29305;&#23450;&#23545;&#35937;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;LoRA&#36866;&#24212;&#30340;LDM&#23481;&#26131;&#21463;&#21040;&#25104;&#21592;&#25512;&#26029;&#65288;MI&#65289;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#36825;&#31181;&#25915;&#20987;&#21487;&#20197;&#21028;&#26029;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#23646;&#20110;&#31169;&#20154;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#22240;&#27492;&#38754;&#20020;&#20005;&#37325;&#30340;&#38544;&#31169;&#27844;&#38706;&#39118;&#38505;&#12290;&#20026;&#20102;&#25269;&#24481;MI&#25915;&#20987;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#19968;&#20010;&#30452;&#25509;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#38544;&#31169;&#20445;&#25252;&#30340;LoRA&#65288;PrivateLoRA&#65289;&#12290;PrivateLoRA&#34987;&#26500;&#24314;&#20026;&#19968;&#20010;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#36890;&#36807;&#26368;&#22823;&#21270;MI&#22686;&#30410;&#26469;&#35757;&#32451;&#20195;&#29702;&#25915;&#20987;&#27169;&#22411;&#65292;&#32780;LDM&#21017;&#36890;&#36807;&#26368;&#23567;&#21270;&#36866;&#24212;&#25439;&#22833;&#21644;&#20195;&#29702;&#25915;&#20987;&#27169;&#22411;&#30340;MI&#22686;&#30410;&#20043;&#21644;&#26469;&#36827;&#34892;&#35843;&#25972;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#22312;&#23454;&#36341;&#20013;&#21457;&#29616;PrivateLoRA&#23384;&#22312;&#31283;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#30001;&#20110;&#26799;&#24230;&#35268;&#27169;&#30340;&#22823;&#24133;&#27874;&#21160;&#32780;&#22952;&#30861;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11989v1 Announce Type: new  Abstract: Low-rank adaptation (LoRA) is an efficient strategy for adapting latent diffusion models (LDMs) on a training dataset to generate specific objects by minimizing the adaptation loss. However, adapted LDMs via LoRA are vulnerable to membership inference (MI) attacks that can judge whether a particular data point belongs to private training datasets, thus facing severe risks of privacy leakage. To defend against MI attacks, we make the first effort to propose a straightforward solution: privacy-preserving LoRA (PrivateLoRA). PrivateLoRA is formulated as a min-max optimization problem where a proxy attack model is trained by maximizing its MI gain while the LDM is adapted by minimizing the sum of the adaptation loss and the proxy attack model's MI gain. However, we empirically disclose that PrivateLoRA has the issue of unstable optimization due to the large fluctuation of the gradient scale which impedes adaptation. To mitigate this issue, w
&lt;/p&gt;</description></item><item><title>&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#25915;&#20987;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35780;&#20272;&#65292;&#25581;&#31034;&#20102;&#19968;&#31181;&#32469;&#36807;&#23433;&#20840;&#25514;&#26045;&#30340;&#19981;&#31283;&#23450;&#28431;&#27934;&#12290;&#26412;&#30740;&#31350;&#26159;&#39318;&#27425;&#23545;&#22810;&#31181;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#36827;&#34892;&#22823;&#35268;&#27169;&#27979;&#37327;&#65292;&#23454;&#39564;&#35777;&#26126;&#20248;&#21270;&#30340;&#36234;&#29425;&#25552;&#31034;&#33021;&#22815;&#25345;&#32493;&#36798;&#21040;&#26368;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.05668</link><description>&lt;p&gt;
&#23545;LLMs&#30340;&#36234;&#29425;&#25915;&#20987;&#30340;&#32508;&#21512;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Comprehensive Assessment of Jailbreak Attacks Against LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05668
&lt;/p&gt;
&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#25915;&#20987;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35780;&#20272;&#65292;&#25581;&#31034;&#20102;&#19968;&#31181;&#32469;&#36807;&#23433;&#20840;&#25514;&#26045;&#30340;&#19981;&#31283;&#23450;&#28431;&#27934;&#12290;&#26412;&#30740;&#31350;&#26159;&#39318;&#27425;&#23545;&#22810;&#31181;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#36827;&#34892;&#22823;&#35268;&#27169;&#27979;&#37327;&#65292;&#23454;&#39564;&#35777;&#26126;&#20248;&#21270;&#30340;&#36234;&#29425;&#25552;&#31034;&#33021;&#22815;&#25345;&#32493;&#36798;&#21040;&#26368;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#28389;&#29992;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24050;&#32463;&#37319;&#21462;&#20102;&#23433;&#20840;&#25514;&#26045;&#20197;&#30830;&#20445;LLMs&#31526;&#21512;&#31038;&#20250;&#20262;&#29702;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#20102;&#19968;&#31181;&#32469;&#36807;LLMs&#23433;&#20840;&#25514;&#26045;&#30340;&#19981;&#31283;&#23450;&#28431;&#27934;&#65292;&#34987;&#31216;&#20026;&#36234;&#29425;&#25915;&#20987;&#12290;&#36890;&#36807;&#24212;&#29992;&#25216;&#26415;&#65292;&#22914;&#35282;&#33394;&#25198;&#28436;&#22330;&#26223;&#12289;&#23545;&#25239;&#24615;&#26679;&#26412;&#25110;&#23545;&#23433;&#20840;&#30446;&#26631;&#30340;&#24494;&#22937;&#30772;&#22351;&#20316;&#20026;&#25552;&#31034;&#65292;LLMs&#21487;&#20197;&#20135;&#29983;&#19981;&#36866;&#24403;&#29978;&#33267;&#26377;&#23475;&#30340;&#22238;&#24212;&#12290;&#34429;&#28982;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#30740;&#31350;&#20102;&#20960;&#31181;&#36234;&#29425;&#25915;&#20987;&#30340;&#31867;&#21035;&#65292;&#20294;&#20182;&#20204;&#37117;&#26159;&#23396;&#31435;&#22320;&#36827;&#34892;&#30340;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#21508;&#31181;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#30340;&#39318;&#27425;&#22823;&#35268;&#27169;&#27979;&#37327;&#12290;&#25105;&#20204;&#38598;&#20013;&#22312;&#26469;&#33258;&#22235;&#20010;&#31867;&#21035;&#30340;13&#31181;&#23574;&#31471;&#36234;&#29425;&#26041;&#27861;&#12289;16&#31181;&#36829;&#35268;&#31867;&#21035;&#30340;160&#20010;&#38382;&#39064;&#20197;&#21450;&#20845;&#31181;&#27969;&#34892;&#30340;LLMs&#19978;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20248;&#21270;&#30340;&#36234;&#29425;&#25552;&#31034;&#22987;&#32456;&#33021;&#22815;&#36798;&#21040;&#26368;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#24182;&#34920;&#29616;&#20986;...
&lt;/p&gt;
&lt;p&gt;
Misuse of the Large Language Models (LLMs) has raised widespread concern. To address this issue, safeguards have been taken to ensure that LLMs align with social ethics. However, recent findings have revealed an unsettling vulnerability bypassing the safeguards of LLMs, known as jailbreak attacks. By applying techniques, such as employing role-playing scenarios, adversarial examples, or subtle subversion of safety objectives as a prompt, LLMs can produce an inappropriate or even harmful response. While researchers have studied several categories of jailbreak attacks, they have done so in isolation. To fill this gap, we present the first large-scale measurement of various jailbreak attack methods. We concentrate on 13 cutting-edge jailbreak methods from four categories, 160 questions from 16 violation categories, and six popular LLMs. Our extensive experimental results demonstrate that the optimized jailbreak prompts consistently achieve the highest attack success rates, as well as exhi
&lt;/p&gt;</description></item><item><title>SecFormer&#26159;&#19968;&#20010;&#20248;&#21270;&#26694;&#26550;&#65292;&#26088;&#22312;&#23454;&#29616;Transformer&#27169;&#22411;&#30340;&#24555;&#36895;&#20934;&#30830;&#38544;&#31169;&#20445;&#25252;&#25512;&#29702;&#12290;&#36890;&#36807;&#28040;&#38500;&#39640;&#25104;&#26412;&#30340;&#25351;&#25968;&#21644;&#32447;&#24615;&#25805;&#20316;&#65292;SecFormer&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24212;&#29992;SMPC&#26102;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.00793</link><description>&lt;p&gt;
SecFormer&#65306;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24555;&#36895;&#20934;&#30830;&#38544;&#31169;&#20445;&#25252;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models. (arXiv:2401.00793v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00793
&lt;/p&gt;
&lt;p&gt;
SecFormer&#26159;&#19968;&#20010;&#20248;&#21270;&#26694;&#26550;&#65292;&#26088;&#22312;&#23454;&#29616;Transformer&#27169;&#22411;&#30340;&#24555;&#36895;&#20934;&#30830;&#38544;&#31169;&#20445;&#25252;&#25512;&#29702;&#12290;&#36890;&#36807;&#28040;&#38500;&#39640;&#25104;&#26412;&#30340;&#25351;&#25968;&#21644;&#32447;&#24615;&#25805;&#20316;&#65292;SecFormer&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24212;&#29992;SMPC&#26102;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#20113;&#24179;&#21488;&#19978;&#37096;&#32626;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#25552;&#20379;&#25512;&#29702;&#26381;&#21153;&#30340;&#20351;&#29992;&#22686;&#21152;&#65292;&#38544;&#31169;&#38382;&#39064;&#26085;&#30410;&#21152;&#21095;&#65292;&#23588;&#20854;&#26159;&#28041;&#21450;&#25237;&#36164;&#35745;&#21010;&#21644;&#38134;&#34892;&#36134;&#25143;&#31561;&#25935;&#24863;&#25968;&#25454;&#12290;&#23433;&#20840;&#22810;&#26041;&#35745;&#31639;&#65288;SMPC&#65289;&#34987;&#35270;&#20026;&#20445;&#25252;&#25512;&#29702;&#25968;&#25454;&#21644;&#27169;&#22411;&#21442;&#25968;&#38544;&#31169;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;SMPC&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#29305;&#21035;&#26159;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#27169;&#22411;&#65289;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#24448;&#24448;&#20250;&#23548;&#33268;&#26174;&#33879;&#30340;&#20943;&#36895;&#25110;&#24615;&#33021;&#19979;&#38477;&#12290;&#36825;&#20027;&#35201;&#26159;&#30001;&#20110;Transformer&#26550;&#26500;&#20013;&#30340;&#20247;&#22810;&#38750;&#32447;&#24615;&#25805;&#20316;&#19981;&#36866;&#21512;SMPC&#65292;&#24182;&#19988;&#38590;&#20197;&#26377;&#25928;&#35268;&#36991;&#25110;&#20248;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20808;&#36827;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#31216;&#20026;SecFormer&#65292;&#20197;&#23454;&#29616;Transformer&#27169;&#22411;&#30340;&#24555;&#36895;&#20934;&#30830;&#38544;&#31169;&#20445;&#25252;&#25512;&#29702;&#12290;&#36890;&#36807;&#23454;&#26045;&#27169;&#22411;&#35774;&#35745;&#20248;&#21270;&#65292;&#25105;&#20204;&#25104;&#21151;&#28040;&#38500;&#20102;&#39640;&#25104;&#26412;&#30340;&#25351;&#25968;&#21644;&#32447;&#24615;&#25805;&#20316;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the growing use of large language models hosted on cloud platforms to offer inference services, privacy concerns are escalating, especially concerning sensitive data like investment plans and bank account details. Secure Multi-Party Computing (SMPC) emerges as a promising solution to protect the privacy of inference data and model parameters. However, the application of SMPC in Privacy-Preserving Inference (PPI) for large language models, particularly those based on the Transformer architecture, often leads to considerable slowdowns or declines in performance. This is largely due to the multitude of nonlinear operations in the Transformer architecture, which are not well-suited to SMPC and difficult to circumvent or optimize effectively. To address this concern, we introduce an advanced optimization framework called SecFormer, to achieve fast and accurate PPI for Transformer models. By implementing model design optimization, we successfully eliminate the high-cost exponential and 
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;PROVEXPLAINER&#26694;&#26550;&#65292;&#36890;&#36807;&#22797;&#21046;GNN-based security models&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#21033;&#29992;&#20915;&#31574;&#26641;&#21644;&#22270;&#32467;&#26500;&#29305;&#24449;&#23558;&#25277;&#35937;GNN&#20915;&#31574;&#36793;&#30028;&#25237;&#24433;&#21040;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#31354;&#38388;&#65292;&#20197;&#22686;&#24378;GNN&#23433;&#20840;&#27169;&#22411;&#30340;&#36879;&#26126;&#24230;&#21644;&#35810;&#38382;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.00934</link><description>&lt;p&gt;
&#22522;&#20110;&#26435;&#23041;&#22270;&#32467;&#26500;&#29305;&#24449;&#23545;&#22522;&#20110;GNN&#30340;IDS&#26816;&#27979;&#36827;&#34892;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Interpreting GNN-based IDS Detections Using Provenance Graph Structural Features. (arXiv:2306.00934v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00934
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;PROVEXPLAINER&#26694;&#26550;&#65292;&#36890;&#36807;&#22797;&#21046;GNN-based security models&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#21033;&#29992;&#20915;&#31574;&#26641;&#21644;&#22270;&#32467;&#26500;&#29305;&#24449;&#23558;&#25277;&#35937;GNN&#20915;&#31574;&#36793;&#30028;&#25237;&#24433;&#21040;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#31354;&#38388;&#65292;&#20197;&#22686;&#24378;GNN&#23433;&#20840;&#27169;&#22411;&#30340;&#36879;&#26126;&#24230;&#21644;&#35810;&#38382;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#40657;&#21283;&#23376;&#26412;&#36136;&#22952;&#30861;&#20102;&#23427;&#20204;&#22312;&#23433;&#20840;&#39046;&#22495;&#30340;&#26222;&#21450;&#65292;&#22240;&#20026;&#23427;&#20204;&#32570;&#20047;&#36923;&#36753;&#35299;&#37322;&#21644;&#21487;&#25191;&#34892;&#21518;&#32493;&#34892;&#21160;&#30340;&#39044;&#27979;&#12290;&#20026;&#20102;&#22686;&#24378;&#22312;&#31995;&#32479;&#26469;&#28304;&#20998;&#26512;&#20013;&#20351;&#29992;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#23433;&#20840;&#27169;&#22411;&#30340;&#36879;&#26126;&#24230;&#21644;&#38382;&#36131;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PROVEXPLAINER&#65292;&#19968;&#31181;&#23558;&#25277;&#35937;GNN&#20915;&#31574;&#36793;&#30028;&#25237;&#24433;&#21040;&#21487;&#35299;&#37322;&#29305;&#24449;&#31354;&#38388;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#31616;&#21333;&#19988;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#22914;&#20915;&#31574;&#26641;&#65288;DT&#65289;&#65292;&#22797;&#21046;&#22522;&#20110;GNN&#30340;&#23433;&#20840;&#27169;&#22411;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;&#20026;&#20102;&#26368;&#22823;&#21270;&#26367;&#20195;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#20445;&#30495;&#24230;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32463;&#20856;&#22270;&#35770;&#30340;&#22270;&#32467;&#26500;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#23433;&#20840;&#39046;&#22495;&#30693;&#35782;&#30340;&#24191;&#27867;&#25968;&#25454;&#30740;&#31350;&#23545;&#20854;&#36827;&#34892;&#20102;&#22686;&#24378;&#12290;&#25105;&#20204;&#30340;&#22270;&#32467;&#26500;&#29305;&#24449;&#19982;&#31995;&#32479;&#26469;&#28304;&#39046;&#22495;&#20013;&#30340;&#38382;&#39064;&#31354;&#38388;&#34892;&#21160;&#23494;&#20999;&#30456;&#20851;&#65292;&#36825;&#20351;&#26816;&#27979;&#32467;&#26524;&#21487;&#29992;&#20154;&#31867;&#35821;&#35328;&#25551;&#36848;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The black-box nature of complex Neural Network (NN)-based models has hindered their widespread adoption in security domains due to the lack of logical explanations and actionable follow-ups for their predictions. To enhance the transparency and accountability of Graph Neural Network (GNN) security models used in system provenance analysis, we propose PROVEXPLAINER, a framework for projecting abstract GNN decision boundaries onto interpretable feature spaces.  We first replicate the decision-making process of GNNbased security models using simpler and explainable models such as Decision Trees (DTs). To maximize the accuracy and fidelity of the surrogate models, we propose novel graph structural features founded on classical graph theory and enhanced by extensive data study with security domain knowledge. Our graph structural features are closely tied to problem-space actions in the system provenance domain, which allows the detection results to be explained in descriptive, human languag
&lt;/p&gt;</description></item></channel></rss>