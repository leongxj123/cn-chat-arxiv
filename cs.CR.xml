<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65292;&#20351;&#29992; TensorFlow Federated &#21644; Flower &#26694;&#26550;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#22521;&#35757;&#30142;&#30149;&#39044;&#21518;&#21644;&#32454;&#32990;&#31867;&#22411;&#20998;&#31867;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.14527</link><description>&lt;p&gt;
&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65306;&#27169;&#22411;&#36136;&#37327;&#21644;&#24615;&#33021;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Federated Learning on Transcriptomic Data: Model Quality and Performance Trade-Offs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65292;&#20351;&#29992; TensorFlow Federated &#21644; Flower &#26694;&#26550;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#22521;&#35757;&#30142;&#30149;&#39044;&#21518;&#21644;&#32454;&#32990;&#31867;&#22411;&#20998;&#31867;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#36827;&#34892;&#26426;&#22120;&#23398;&#20064;&#23545;&#35768;&#22810;&#26032;&#39062;&#30340;&#20581;&#24247;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#20363;&#22914;&#65292;&#31934;&#20934;&#21307;&#23398;&#21487;&#20197;&#26681;&#25454;&#20010;&#20307;&#29983;&#29289;&#26631;&#24535;&#29289;&#12289;&#32454;&#32990;&#21644;&#20998;&#23376;&#29366;&#24577;&#31561;&#20010;&#20307;&#20449;&#24687;&#26469;&#37327;&#36523;&#23450;&#21046;&#21307;&#23398;&#27835;&#30103;&#12290;&#28982;&#32780;&#65292;&#25152;&#38656;&#25968;&#25454;&#25935;&#24863;&#12289;&#24222;&#22823;&#12289;&#24322;&#36136;&#65292;&#24182;&#19988;&#36890;&#24120;&#20998;&#24067;&#22312;&#26080;&#27861;&#20351;&#29992;&#19987;&#38376;&#30340;&#26426;&#22120;&#23398;&#20064;&#30828;&#20214;&#30340;&#22320;&#28857;&#12290;&#30001;&#20110;&#38544;&#31169;&#21644;&#30417;&#31649;&#21407;&#22240;&#65292;&#22312;&#21487;&#20449;&#20219;&#30340;&#31532;&#19977;&#26041;&#22788;&#32858;&#21512;&#25152;&#26377;&#25968;&#25454;&#20063;&#23384;&#22312;&#38382;&#39064;&#12290;&#32852;&#37030;&#23398;&#20064;&#26159;&#36825;&#19968;&#22256;&#22659;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#23454;&#29616;&#20102;&#22312;&#19981;&#20132;&#25442;&#21407;&#22987;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20998;&#25955;&#12289;&#21327;&#20316;&#30340;&#26426;&#22120;&#23398;&#20064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550; TensorFlow Federated &#21644; Flower &#36827;&#34892;&#27604;&#36739;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#26696;&#20363;&#26159;&#22521;&#35757;&#30142;&#30149;&#39044;&#21518;&#21644;&#32454;&#32990;&#31867;&#22411;&#20998;&#31867;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#20998;&#24067;&#24335;&#36716;&#24405;&#32452;&#23545;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14527v1 Announce Type: new  Abstract: Machine learning on large-scale genomic or transcriptomic data is important for many novel health applications. For example, precision medicine tailors medical treatments to patients on the basis of individual biomarkers, cellular and molecular states, etc. However, the data required is sensitive, voluminous, heterogeneous, and typically distributed across locations where dedicated machine learning hardware is not available. Due to privacy and regulatory reasons, it is also problematic to aggregate all data at a trusted third party.Federated learning is a promising solution to this dilemma, because it enables decentralized, collaborative machine learning without exchanging raw data. In this paper, we perform comparative experiments with the federated learning frameworks TensorFlow Federated and Flower. Our test case is the training of disease prognosis and cell type classification models. We train the models with distributed transcriptom
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26041;&#27861;&#31995;&#32479;&#22320;&#27979;&#35797;&#20102;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#20197;&#21450;&#35757;&#32451;&#32467;&#26463;&#26102;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2402.06674</link><description>&lt;p&gt;
&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#30340;&#23454;&#38469;&#25104;&#21592;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Understanding Practical Membership Privacy of Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06674
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26041;&#27861;&#31995;&#32479;&#22320;&#27979;&#35797;&#20102;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#20197;&#21450;&#35757;&#32451;&#32467;&#26463;&#26102;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24212;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#65288;MIA&#65289;&#26469;&#31995;&#32479;&#22320;&#27979;&#35797;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;&#29702;&#35299;&#20351;&#25968;&#25454;&#38598;&#21644;&#26679;&#26412;&#23481;&#26131;&#21463;&#21040;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#29305;&#24615;&#12290;&#22312;&#25968;&#25454;&#38598;&#29305;&#24615;&#26041;&#38754;&#65292;&#25105;&#20204;&#21457;&#29616;&#25968;&#25454;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#24378;&#28872;&#30340;&#24130;&#24459;&#20381;&#36182;&#20851;&#31995;&#65292;&#36825;&#26159;&#20197;&#25915;&#20987;&#30340;&#30495;&#38451;&#24615;&#29575;&#65288;&#22312;&#20302;&#20551;&#38451;&#24615;&#29575;&#19979;&#27979;&#37327;&#65289;&#26469;&#34913;&#37327;&#30340;&#12290;&#23545;&#20110;&#20010;&#21035;&#26679;&#26412;&#32780;&#35328;&#65292;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#20135;&#29983;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We apply a state-of-the-art membership inference attack (MIA) to systematically test the practical privacy vulnerability of fine-tuning large image classification models.We focus on understanding the properties of data sets and samples that make them vulnerable to membership inference. In terms of data set properties, we find a strong power law dependence between the number of examples per class in the data and the MIA vulnerability, as measured by true positive rate of the attack at a low false positive rate. For an individual sample, large gradients at the end of training are strongly correlated with MIA vulnerability.
&lt;/p&gt;</description></item></channel></rss>