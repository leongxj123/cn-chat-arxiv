<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Prompt Adversarial Tuning (PAT)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#24182;&#23558;&#20854;&#20316;&#20026;&#21069;&#32512;&#23884;&#20837;&#21040;&#29992;&#25143;&#25552;&#31034;&#20013;&#65292;&#23454;&#29616;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#34892;&#20026;&#30340;&#38450;&#24481;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;LLMs&#20813;&#21463;&#20135;&#29983;&#26377;&#23475;&#20449;&#24687;&#30340;&#24433;&#21709;&#26041;&#38754;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>https://arxiv.org/abs/2402.06255</link><description>&lt;p&gt;
&#36827;&#21462;&#30340;&#40077;&#21187;&#36890;&#36807;&#25552;&#31034;&#23545;&#25239;&#35843;&#25972;&#25269;&#21046;&#36234;&#29425;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Prompt Adversarial Tuning (PAT)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#24182;&#23558;&#20854;&#20316;&#20026;&#21069;&#32512;&#23884;&#20837;&#21040;&#29992;&#25143;&#25552;&#31034;&#20013;&#65292;&#23454;&#29616;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#34892;&#20026;&#30340;&#38450;&#24481;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;LLMs&#20813;&#21463;&#20135;&#29983;&#26377;&#23475;&#20449;&#24687;&#30340;&#24433;&#21709;&#26041;&#38754;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#20063;&#23481;&#26131;&#21463;&#21040;&#29305;&#23450;&#25552;&#31034;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#32469;&#36807;&#20869;&#32622;&#30340;&#23433;&#20840;&#25514;&#26045;&#24182;&#25552;&#20379;&#21361;&#38505;&#25110;&#38750;&#27861;&#20869;&#23481;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#36234;&#29425;&#34892;&#20026;&#12290;&#20026;&#20102;&#20445;&#25252;LLMs&#20813;&#21463;&#20135;&#29983;&#26377;&#23475;&#20449;&#24687;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#21508;&#31181;&#38450;&#24481;&#31574;&#30053;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#38598;&#20013;&#22312;&#20869;&#23481;&#36807;&#28388;&#25110;&#27169;&#22411;&#30340;&#23545;&#25239;&#35757;&#32451;&#26041;&#38754;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Prompt Adversarial Tuning&#65288;PAT&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#24182;&#23558;&#20854;&#20316;&#20026;&#21069;&#32512;&#23884;&#20837;&#21040;&#29992;&#25143;&#25552;&#31034;&#20013;&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#38450;&#24481;&#31574;&#30053;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31867;&#20284;&#23545;&#25239;&#35757;&#32451;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#20197;&#23454;&#29616;&#25105;&#20204;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#20132;&#26367;&#26356;&#26032;&#25915;&#20987;&#21644;&#38450;&#24481;&#25511;&#21046;&#26426;&#21046;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#26159;&#31532;&#19968;&#20010;&#20174;&#25552;&#31034;&#35843;&#25972;&#30340;&#35282;&#24230;&#23454;&#26045;&#38450;&#24481;&#30340;&#20154;&#12290;&#19968;&#26086;&#24212;&#29992;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20960;&#20046;&#19981;&#20250;&#24433;&#21709;LLMs&#30340;&#25805;&#20316;&#25928;&#29575;&#12290;&#23454;&#39564;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25269;&#24481;&#36234;&#29425;&#34892;&#20026;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although Large Language Models (LLMs) have achieved tremendous success in various applications, they are also susceptible to certain prompts that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak. To protect LLMs from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or adversarial training of models. In this paper, we propose an approach named Prompt Adversarial Tuning (PAT) to train a defense control mechanism, which is then embedded as a prefix to user prompts to implement our defense strategy. We design a training process similar to adversarial training to achieve our optimized goal, alternating between updating attack and defense controls. To our knowledge, we are the first to implement defense from the perspective of prompt tuning. Once employed, our method will hardly impact the operational efficiency of LLMs. Experiments show that our method i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Tree of Attacks with Pruning (TAP)&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21482;&#38656;&#35201;&#23545;&#30446;&#26631;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#40657;&#30418;&#35775;&#38382;&#30340;&#36234;&#29425;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24605;&#32500;&#26641;&#25512;&#29702;&#21644;&#20462;&#21098;&#29983;&#25104;&#20934;&#30830;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;</title><link>https://arxiv.org/abs/2312.02119</link><description>&lt;p&gt;
&#25915;&#20987;&#26641;&#65306;&#33258;&#21160;&#30772;&#35299;&#40657;&#30418;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tree of Attacks: Jailbreaking Black-Box LLMs Automatically
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02119
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Tree of Attacks with Pruning (TAP)&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21482;&#38656;&#35201;&#23545;&#30446;&#26631;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#40657;&#30418;&#35775;&#38382;&#30340;&#36234;&#29425;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24605;&#32500;&#26641;&#25512;&#29702;&#21644;&#20462;&#21098;&#29983;&#25104;&#20934;&#30830;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23637;&#31034;&#20102;&#22810;&#21151;&#33021;&#24615;&#65292;&#20294;&#20173;&#22312;&#29983;&#25104;&#26377;&#23475;&#12289;&#24102;&#20559;&#35265;&#21644;&#26377;&#27602;&#20869;&#23481;&#65292;&#36825;&#19968;&#28857;&#30001;&#20154;&#20026;&#35774;&#35745;&#30340;&#36234;&#29425;&#34892;&#20026;&#30340;&#26222;&#36941;&#23384;&#22312;&#24471;&#20197;&#35777;&#26126;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Tree of Attacks with Pruning (TAP)&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#36234;&#29425;&#65292;&#20165;&#38656;&#35201;&#23545;&#30446;&#26631;LLM&#36827;&#34892;&#40657;&#30418;&#35775;&#38382;&#12290;TAP&#21033;&#29992;LLM&#26469;&#36890;&#36807;&#24605;&#32500;&#26641;&#25512;&#29702;&#36845;&#20195;&#22320;&#20248;&#21270;&#20505;&#36873;&#65288;&#25915;&#20987;&#65289;&#25552;&#31034;&#65292;&#30452;&#21040;&#29983;&#25104;&#30340;&#25552;&#31034;&#20043;&#19968;&#36234;&#29425;&#30446;&#26631;&#12290;&#20851;&#38190;&#22312;&#20110;&#65292;&#22312;&#23558;&#25552;&#31034;&#21457;&#36865;&#32473;&#30446;&#26631;&#20043;&#21069;&#65292;TAP&#23545;&#20854;&#36827;&#34892;&#35780;&#20272;&#24182;&#31227;&#38500;&#21487;&#33021;&#19981;&#20250;&#23548;&#33268;&#36234;&#29425;&#30340;&#25552;&#31034;&#12290;&#20351;&#29992;&#24605;&#32500;&#26641;&#25512;&#29702;&#20351;TAP&#33021;&#22815;&#22312;&#22823;&#37327;&#25552;&#31034;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#23548;&#33322;&#65292;&#32780;&#20462;&#21098;&#21017;&#20943;&#23569;&#20102;&#21457;&#36865;&#32473;&#30446;&#26631;&#30340;&#24635;&#26597;&#35810;&#25968;&#37327;&#12290;&#22312;&#23454;&#35777;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;TAP&#29983;&#25104;&#30340;&#25552;&#31034;&#36234;&#29425;&#20102;&#36229;&#36807;80%&#30340;&#26368;&#20808;&#36827;LLMs&#65288;&#21253;&#25324;GPT4&#21644;GPT4-Turbo&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02119v2 Announce Type: replace-cross  Abstract: While Large Language Models (LLMs) display versatile functionality, they continue to generate harmful, biased, and toxic content, as demonstrated by the prevalence of human-designed jailbreaks. In this work, we present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that only requires black-box access to the target LLM. TAP utilizes an LLM to iteratively refine candidate (attack) prompts using tree-of-thought reasoning until one of the generated prompts jailbreaks the target. Crucially, before sending prompts to the target, TAP assesses them and prunes the ones unlikely to result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigate a large search space of prompts and pruning reduces the total number of queries sent to the target. In empirical evaluations, we observe that TAP generates prompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo) for more than 80%
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21098;&#26525;&#23545;&#40784;&#30340;LLMs&#30340;&#20445;&#25252;&#25514;&#26045;&#65292;&#21457;&#29616;&#21098;&#26525;LLM&#21442;&#25968;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20854;&#25269;&#25239;&#8220;&#36234;&#29425;&#8221;&#25552;&#31034;&#25915;&#20987;&#30340;&#33021;&#21147;&#65292;&#24182;&#19988;&#23545;&#20854;&#20182;LLM&#34892;&#20026;&#20063;&#21487;&#33021;&#26377;&#26356;&#26222;&#36941;&#30340;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26377;&#23475;&#20219;&#21153;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#21098;&#26525;&#26377;&#21161;&#20110;&#38598;&#20013;&#27880;&#24847;&#21147;&#22312;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#26631;&#35760;&#19978;&#12290;&#31361;&#20986;&#30340;&#32842;&#22825;&#27169;&#22411;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#26131;&#24863;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10862</link><description>&lt;p&gt;
&#22522;&#20110;&#21098;&#26525;&#30340;&#20445;&#25252;: &#22312;&#19981;&#36827;&#34892;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#23545;&#40784;&#30340;LLMs&#30340;&#36234;&#29425;&#25269;&#25239;&#21147;
&lt;/p&gt;
&lt;p&gt;
Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning. (arXiv:2401.10862v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10862
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21098;&#26525;&#23545;&#40784;&#30340;LLMs&#30340;&#20445;&#25252;&#25514;&#26045;&#65292;&#21457;&#29616;&#21098;&#26525;LLM&#21442;&#25968;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20854;&#25269;&#25239;&#8220;&#36234;&#29425;&#8221;&#25552;&#31034;&#25915;&#20987;&#30340;&#33021;&#21147;&#65292;&#24182;&#19988;&#23545;&#20854;&#20182;LLM&#34892;&#20026;&#20063;&#21487;&#33021;&#26377;&#26356;&#26222;&#36941;&#30340;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26377;&#23475;&#20219;&#21153;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#21098;&#26525;&#26377;&#21161;&#20110;&#38598;&#20013;&#27880;&#24847;&#21147;&#22312;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#26631;&#35760;&#19978;&#12290;&#31361;&#20986;&#30340;&#32842;&#22825;&#27169;&#22411;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#26131;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23481;&#26131;&#21463;&#21040;&#8220;&#36234;&#29425;&#8221;&#25552;&#31034;&#30340;&#25915;&#20987;&#65292;&#36825;&#31181;&#25915;&#20987;&#21487;&#20197;&#35825;&#20351;&#36825;&#20123;&#27169;&#22411;&#29983;&#25104;&#26377;&#23475;&#21644;&#36829;&#27861;&#20869;&#23481;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#21098;&#26525;LLM&#21442;&#25968;&#22810;&#36798;20&#65285;&#21487;&#20197;&#26174;&#33879;&#22686;&#21152;&#23427;&#20204;&#23545;&#27492;&#31867;&#25915;&#20987;&#30340;&#25269;&#25239;&#21147;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#35757;&#32451;&#24182;&#19988;&#19981;&#25439;&#23475;&#20854;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#21098;&#26525;&#21518;&#35266;&#23519;&#21040;&#30340;&#22686;&#24378;&#23433;&#20840;&#24615;&#19982;&#27169;&#22411;&#30340;&#21021;&#22987;&#23433;&#20840;&#35757;&#32451;&#27700;&#24179;&#30456;&#20851;&#65292;&#36825;&#26263;&#31034;&#21098;&#26525;&#30340;&#25928;&#26524;&#21487;&#33021;&#26356;&#26222;&#36941;&#65292;&#20063;&#21487;&#33021;&#36866;&#29992;&#20110;&#36229;&#20986;&#23433;&#20840;&#24615;&#33539;&#30068;&#30340;&#20854;&#20182;LLM&#34892;&#20026;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#20010;&#21253;&#21547;&#20116;&#20010;&#31867;&#21035;&#12289;&#25554;&#20837;&#21040;&#21313;&#20010;&#19981;&#21516;&#36234;&#29425;&#25552;&#31034;&#20013;&#30340;225&#20010;&#26377;&#23475;&#20219;&#21153;&#30340;&#31934;&#36873;&#25968;&#25454;&#38598;&#65292;&#34920;&#26126;&#21098;&#26525;&#26377;&#21161;&#20110;LLMs&#38598;&#20013;&#27880;&#24847;&#21147;&#22312;&#36234;&#29425;&#25552;&#31034;&#20013;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#26631;&#35760;&#19978;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#31361;&#20986;&#30340;&#32842;&#22825;&#27169;&#22411;&#65288;&#22914;LLaMA-2 Chat&#65292;Vicuna&#21644;Mistral Instruct&#65289;&#20855;&#26377;&#24456;&#39640;&#30340;&#26131;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are vulnerable to `Jailbreaking' prompts, a type of attack that can coax these models into generating harmful and illegal content. In this paper, we show that pruning up to 20% of LLM parameters markedly increases their resistance to such attacks without additional training and without sacrificing their performance in standard benchmarks. Intriguingly, we discovered that the enhanced safety observed post-pruning correlates to the initial safety training level of the model, hinting that the effect of pruning could be more general and may hold for other LLM behaviors beyond safety. Additionally, we introduce a curated dataset of 225 harmful tasks across five categories, inserted into ten different Jailbreaking prompts, showing that pruning aids LLMs in concentrating attention on task-relevant tokens in jailbreaking prompts. Lastly, our experiments reveal that the prominent chat models, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit high susceptibi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#29983;&#25104;&#24335;AI&#21487;&#20197;&#28165;&#38500;&#38544;&#24418;&#22270;&#20687;&#27700;&#21360;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23478;&#26063;&#21270;&#20877;&#29983;&#25915;&#20987;&#26041;&#27861;&#12290;&#36890;&#36807;&#24418;&#24335;&#21270;&#35777;&#26126;&#21644;&#23454;&#35777;&#32467;&#26524;&#65292;&#35770;&#25991;&#23637;&#31034;&#20102;&#25152;&#26377;&#38544;&#24418;&#27700;&#21360;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#65292;&#24182;&#38024;&#23545;&#19968;&#31181;&#20855;&#26377;&#24377;&#24615;&#30340;&#27700;&#21360;RivaGAN&#65292;&#20877;&#29983;&#25915;&#20987;&#21487;&#20197;&#21435;&#38500;93-99%&#30340;&#27700;&#21360;&#12290;</title><link>http://arxiv.org/abs/2306.01953</link><description>&lt;p&gt;
&#36890;&#36807;&#29983;&#25104;&#24335;AI&#65292;&#35777;&#26126;&#20102;&#38544;&#24418;&#22270;&#20687;&#27700;&#21360;&#26159;&#21487;&#28165;&#38500;&#30340;
&lt;/p&gt;
&lt;p&gt;
Invisible Image Watermarks Are Provably Removable Using Generative AI. (arXiv:2306.01953v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01953
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#29983;&#25104;&#24335;AI&#21487;&#20197;&#28165;&#38500;&#38544;&#24418;&#22270;&#20687;&#27700;&#21360;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23478;&#26063;&#21270;&#20877;&#29983;&#25915;&#20987;&#26041;&#27861;&#12290;&#36890;&#36807;&#24418;&#24335;&#21270;&#35777;&#26126;&#21644;&#23454;&#35777;&#32467;&#26524;&#65292;&#35770;&#25991;&#23637;&#31034;&#20102;&#25152;&#26377;&#38544;&#24418;&#27700;&#21360;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#65292;&#24182;&#38024;&#23545;&#19968;&#31181;&#20855;&#26377;&#24377;&#24615;&#30340;&#27700;&#21360;RivaGAN&#65292;&#20877;&#29983;&#25915;&#20987;&#21487;&#20197;&#21435;&#38500;93-99%&#30340;&#27700;&#21360;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24418;&#27700;&#21360;&#36890;&#36807;&#23884;&#20837;&#21482;&#26377;&#26435;&#21033;&#25317;&#26377;&#32773;&#21487;&#20197;&#26816;&#27979;&#21040;&#30340;&#38544;&#34255;&#20449;&#24687;&#26469;&#20445;&#25252;&#22270;&#20687;&#30340;&#29256;&#26435;&#12290;&#23427;&#20204;&#36824;&#38450;&#27490;&#20154;&#20204;&#28389;&#29992;&#30001;AI&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23478;&#26063;&#21270;&#20877;&#29983;&#25915;&#20987;&#26469;&#28165;&#38500;&#36825;&#20123;&#38544;&#24418;&#27700;&#21360;&#12290;&#25152;&#25552;&#20986;&#30340;&#25915;&#20987;&#26041;&#27861;&#39318;&#20808;&#21521;&#22270;&#20687;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#26469;&#30772;&#22351;&#27700;&#21360;&#65292;&#28982;&#21518;&#37325;&#24314;&#22270;&#20687;&#12290;&#36825;&#31181;&#26041;&#27861;&#28789;&#27963;&#65292;&#21487;&#20197;&#19982;&#35768;&#22810;&#29616;&#26377;&#30340;&#22270;&#20687;&#38477;&#22122;&#31639;&#27861;&#21644;&#39044;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#25193;&#25955;&#27169;&#22411;&#65289;&#23454;&#20363;&#21270;&#12290;&#36890;&#36807;&#24418;&#24335;&#21270;&#35777;&#26126;&#21644;&#23454;&#35777;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#26377;&#38544;&#24418;&#27700;&#21360;&#37117;&#23481;&#26131;&#21463;&#21040;&#25152;&#25552;&#20986;&#30340;&#25915;&#20987;&#12290;&#23545;&#20110;&#19968;&#20010;&#29305;&#21035;&#26377;&#24377;&#24615;&#30340;&#27700;&#21360;RivaGAN&#65292;&#20877;&#29983;&#25915;&#20987;&#21487;&#20197;&#21435;&#38500;93-99%&#30340;&#38544;&#24418;&#27700;&#21360;&#65292;&#32780;&#22522;&#32447;&#25915;&#20987;&#21482;&#33021;&#21435;&#38500;&#19981;&#36229;&#36807;3%&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#25105;&#20204;&#19981;&#35201;&#27714;&#24102;&#27700;&#21360;&#30340;&#22270;&#20687;&#19982;&#21407;&#22987;&#22270;&#20687;&#30456;&#21516;&#65292;&#20445;&#25345;&#22270;&#20687;&#35821;&#20041;&#30456;&#20284;&#30340;&#27700;&#21360;&#21487;&#33021;&#26159;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Invisible watermarks safeguard images' copyright by embedding hidden messages only detectable by owners. They also prevent people from misusing images, especially those generated by AI models. We propose a family of regeneration attacks to remove these invisible watermarks. The proposed attack method first adds random noise to an image to destroy the watermark and then reconstructs the image. This approach is flexible and can be instantiated with many existing image-denoising algorithms and pre-trained generative models such as diffusion models. Through formal proofs and empirical results, we show that all invisible watermarks are vulnerable to the proposed attack. For a particularly resilient watermark, RivaGAN, regeneration attacks remove 93-99% of the invisible watermarks while the baseline attacks remove no more than 3%. However, if we do not require the watermarked image to look the same as the original one, watermarks that keep the image semantically similar can be an alternative
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24555;&#36895;&#38450;&#24481;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#26041;&#26696;RaPiD&#65288;Rapid Plug-in Defender&#65289;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;Transformer&#24494;&#35843;&#26469;&#25552;&#32431;&#23545;&#25239;&#26679;&#26412;&#65292;&#20351;&#20854;&#36924;&#36817;&#28165;&#27905;&#25968;&#25454;&#20998;&#24067;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26377;&#38480;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.01762</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;Transformer&#29992;&#20110;&#23545;&#25239;&#24615;&#26679;&#26412;&#25552;&#32431;
&lt;/p&gt;
&lt;p&gt;
Pre-trained transformer for adversarial purification. (arXiv:2306.01762v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24555;&#36895;&#38450;&#24481;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#26041;&#26696;RaPiD&#65288;Rapid Plug-in Defender&#65289;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;Transformer&#24494;&#35843;&#26469;&#25552;&#32431;&#23545;&#25239;&#26679;&#26412;&#65292;&#20351;&#20854;&#36924;&#36817;&#28165;&#27905;&#25968;&#25454;&#20998;&#24067;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26377;&#38480;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#36234;&#26469;&#36234;&#22810;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#34987;&#37096;&#32626;&#20026;&#21508;&#31181;&#26085;&#24120;&#26381;&#21153;&#65292;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#20854;&#20013;&#36867;&#36991;&#25915;&#20987;&#26159;&#26368;&#26222;&#36941;&#30340;&#19968;&#31181;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#36890;&#24120;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#25110;&#21033;&#29992;&#22823;&#37327;&#28165;&#27905;&#25968;&#25454;&#30340;&#30693;&#35782;&#26469;&#22686;&#24378;&#20854;&#20581;&#22766;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#37325;&#26032;&#35757;&#32451;&#21644;&#37096;&#32626;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#23545;&#22312;&#32447;&#26381;&#21153;&#36896;&#25104;&#37325;&#22823;&#25439;&#22833;&#12290;&#27492;&#22806;&#65292;&#24403;&#26816;&#27979;&#21040;&#26576;&#31181;&#25915;&#20987;&#30340;&#23545;&#25239;&#24615;&#20363;&#23376;&#26102;&#65292;&#26381;&#21153;&#25552;&#20379;&#32773;&#21482;&#33021;&#33719;&#24471;&#26377;&#38480;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#32780;&#22823;&#37327;&#30340;&#28165;&#27905;&#25968;&#25454;&#21487;&#33021;&#26080;&#27861;&#33719;&#21462;&#12290;&#38024;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#26696;&#65292;&#21517;&#20026;RaPiD&#65288;Rapid Plug-in Defender&#65289;&#65292;&#26088;&#22312;&#24555;&#36895;&#38450;&#24481;&#20855;&#26377;&#23569;&#37327;&#24178;&#20928;&#21644;&#23545;&#25239;&#24615;&#31034;&#20363;&#38480;&#21046;&#30340;&#21407;&#22987;&#26381;&#21153;&#27169;&#22411;&#30340;&#26576;&#31181;&#25915;&#20987;&#12290;&#21463;&#21040;&#39044;&#35757;&#32451;&#27169;&#22411;&#25552;&#20379;&#36716;&#31227;&#23398;&#20064;&#33391;&#22909;&#21021;&#22987;&#21270;&#30340;&#36890;&#29992;&#36235;&#21183;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#24494;&#35843;&#39044;&#20808;&#35757;&#32451;&#30340;Transformer&#26469;&#25552;&#32431;&#23545;&#25239;&#24615;&#26679;&#26412;&#12290;&#39044;&#35757;&#32451;&#30340;Transformer&#20316;&#20026;&#27491;&#21017;&#21270;&#22120;&#65292;&#40723;&#21169;&#25552;&#32431;&#21518;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#25509;&#36817;&#28165;&#26224;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;RaPiD&#22312;&#38450;&#24481;&#21508;&#31181;&#20855;&#26377;&#38480;&#25968;&#25454;&#30340;&#25915;&#20987;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
With more and more deep neural networks being deployed as various daily services, their reliability is essential. It's frightening that deep neural networks are vulnerable and sensitive to adversarial attacks, the most common one of which for the services is evasion-based. Recent works usually strengthen the robustness by adversarial training or leveraging the knowledge of an amount of clean data. However, in practical terms, retraining and redeploying the model need a large computational budget, leading to heavy losses to the online service. In addition, when adversarial examples of a certain attack are detected, only limited adversarial examples are available for the service provider, while much clean data may not be accessible. Given the mentioned problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is to rapidly defend against a certain attack for the frozen original service model with limitations of few clean and adversarial examples. Motivated by the general
&lt;/p&gt;</description></item></channel></rss>