<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#36890;&#36807;&#20351;&#29992;&#22810;&#35270;&#35282;&#25968;&#25454;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#28155;&#21152;&#27700;&#21360;&#65292;&#21487;&#20197;&#26377;&#25928;&#38450;&#24481;&#23545;&#28304;&#27169;&#22411;&#21151;&#33021;&#30340;&#31363;&#21462;&#25915;&#20987;</title><link>https://arxiv.org/abs/2403.10663</link><description>&lt;p&gt;
&#19981;&#20165;&#25913;&#21464;&#26631;&#31614;&#65292;&#23398;&#20064;&#29305;&#24449;&#65306;&#20351;&#29992;&#22810;&#35270;&#35282;&#25968;&#25454;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#28155;&#21152;&#27700;&#21360;
&lt;/p&gt;
&lt;p&gt;
Not Just Change the Labels, Learn the Features: Watermarking Deep Neural Networks with Multi-View Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10663
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22810;&#35270;&#35282;&#25968;&#25454;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#28155;&#21152;&#27700;&#21360;&#65292;&#21487;&#20197;&#26377;&#25928;&#38450;&#24481;&#23545;&#28304;&#27169;&#22411;&#21151;&#33021;&#30340;&#31363;&#21462;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#26381;&#21153;&#65288;MLaaS&#65289;&#24179;&#21488;&#30340;&#26085;&#30410;&#26222;&#21450;&#65292;&#36234;&#26469;&#36234;&#22810;&#20851;&#27880;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#27700;&#21360;&#25216;&#26415;&#12290;&#36825;&#20123;&#26041;&#27861;&#29992;&#20110;&#39564;&#35777;&#30446;&#26631;DNN&#27169;&#22411;&#30340;&#25152;&#26377;&#26435;&#20197;&#20445;&#25252;&#30693;&#35782;&#20135;&#26435;&#12290;&#26412;&#25991;&#39318;&#20808;&#20174;&#29305;&#24449;&#23398;&#20064;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#35302;&#21457;&#38598;&#30340;&#27700;&#21360;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#36890;&#36807;&#36873;&#25321;&#23637;&#31034;&#22810;&#20010;&#29305;&#24449;&#30340;&#25968;&#25454;&#65292;&#20063;&#34987;&#31216;&#20026;$\textit{&#22810;&#35270;&#35282;&#25968;&#25454;}$&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38450;&#24481;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10663v1 Announce Type: cross  Abstract: With the increasing prevalence of Machine Learning as a Service (MLaaS) platforms, there is a growing focus on deep neural network (DNN) watermarking techniques. These methods are used to facilitate the verification of ownership for a target DNN model to protect intellectual property. One of the most widely employed watermarking techniques involves embedding a trigger set into the source model. Unfortunately, existing methodologies based on trigger sets are still susceptible to functionality-stealing attacks, potentially enabling adversaries to steal the functionality of the source model without a reliable means of verifying ownership. In this paper, we first introduce a novel perspective on trigger set-based watermarking methods from a feature learning perspective. Specifically, we demonstrate that by selecting data exhibiting multiple features, also referred to as $\textit{multi-view data}$, it becomes feasible to effectively defend 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;, Feedback-Driven Solution Synthesis (FDSS), &#26088;&#22312;&#36890;&#36807;&#23558;LLMs&#19982;&#38745;&#24577;&#20195;&#30721;&#20998;&#26512;&#24037;&#20855;Bandit&#32467;&#21512;&#65292;&#35299;&#20915;&#20195;&#30721;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#26377;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PythonSecurityEval&#12290;</title><link>http://arxiv.org/abs/2312.00024</link><description>&lt;p&gt;
LLMs&#33021;&#22815;&#20462;&#22797;&#23433;&#20840;&#38382;&#39064;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can LLMs Patch Security Issues?. (arXiv:2312.00024v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.00024
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;, Feedback-Driven Solution Synthesis (FDSS), &#26088;&#22312;&#36890;&#36807;&#23558;LLMs&#19982;&#38745;&#24577;&#20195;&#30721;&#20998;&#26512;&#24037;&#20855;Bandit&#32467;&#21512;&#65292;&#35299;&#20915;&#20195;&#30721;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#26377;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PythonSecurityEval&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#20195;&#30721;&#29983;&#25104;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#24320;&#21457;&#32773;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#20250;&#29983;&#25104;&#21253;&#21547;&#23433;&#20840;&#28431;&#27934;&#21644;&#32570;&#38519;&#30340;&#20195;&#30721;&#12290;&#32534;&#20889;&#23433;&#20840;&#20195;&#30721;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#28431;&#27934;&#36890;&#24120;&#22312;&#31243;&#24207;&#19982;&#22806;&#37096;&#31995;&#32479;&#25110;&#26381;&#21153;&#65288;&#22914;&#25968;&#25454;&#24211;&#21644;&#25805;&#20316;&#31995;&#32479;&#65289;&#20043;&#38388;&#30340;&#20132;&#20114;&#36807;&#31243;&#20013;&#20986;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#21453;&#39304;&#30340;&#35299;&#20915;&#26041;&#26696;&#21512;&#25104;&#65288;FDSS&#65289;&#65292;&#26088;&#22312;&#25506;&#32034;&#20351;&#29992;LLMs&#25509;&#25910;&#26469;&#33258;&#38745;&#24577;&#20195;&#30721;&#20998;&#26512;&#24037;&#20855;Bandit&#30340;&#21453;&#39304;&#65292;&#28982;&#21518;LLMs&#29983;&#25104;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#26469;&#35299;&#20915;&#23433;&#20840;&#28431;&#27934;&#12290;&#27599;&#20010;&#35299;&#20915;&#26041;&#26696;&#20197;&#21450;&#26131;&#21463;&#25915;&#20987;&#30340;&#20195;&#30721;&#38543;&#21518;&#34987;&#36865;&#22238;LLMs&#36827;&#34892;&#20195;&#30721;&#23436;&#21892;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22522;&#32447;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PythonSecurityEval&#65292;&#35813;&#25968;&#25454;&#38598;&#25910;&#38598;&#20102;&#26469;&#33258;Stack Overflow&#30340;&#30495;&#23454;&#22330;&#26223;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown impressive proficiency in code generation. Nonetheless, similar to human developers, these models might generate code that contains security vulnerabilities and flaws. Writing secure code remains a substantial challenge, as vulnerabilities often arise during interactions between programs and external systems or services, such as databases and operating systems. In this paper, we propose a novel approach, Feedback-Driven Solution Synthesis (FDSS), designed to explore the use of LLMs in receiving feedback from Bandit, which is a static code analysis tool, and then the LLMs generate potential solutions to resolve security vulnerabilities. Each solution, along with the vulnerable code, is then sent back to the LLM for code refinement. Our approach shows a significant improvement over the baseline and outperforms existing approaches. Furthermore, we introduce a new dataset, PythonSecurityEval, collected from real-world scenarios on Stack Overflow to e
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#35821;&#35328;&#20998;&#31867;&#27169;&#22411;&#36827;&#34892;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#12290;&#36890;&#36807;&#21033;&#29992;&#38598;&#25104;&#26041;&#27861;&#65292;&#29983;&#25104;&#22810;&#20010;&#19987;&#38376;&#30340;&#25915;&#20987;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#32463;&#20856;&#21644;&#35821;&#35328;&#20998;&#31867;&#20219;&#21153;&#19978;&#27604;&#21333;&#20010;&#25915;&#20987;&#27169;&#22411;&#25110;&#27599;&#20010;&#31867;&#21035;&#26631;&#31614;&#30340;&#25915;&#20987;&#27169;&#22411;&#26356;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2310.07219</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#23545;&#35821;&#35328;&#20998;&#31867;&#27169;&#22411;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Improved Membership Inference Attacks Against Language Classification Models. (arXiv:2310.07219v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07219
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#35821;&#35328;&#20998;&#31867;&#27169;&#22411;&#36827;&#34892;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#12290;&#36890;&#36807;&#21033;&#29992;&#38598;&#25104;&#26041;&#27861;&#65292;&#29983;&#25104;&#22810;&#20010;&#19987;&#38376;&#30340;&#25915;&#20987;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#32463;&#20856;&#21644;&#35821;&#35328;&#20998;&#31867;&#20219;&#21153;&#19978;&#27604;&#21333;&#20010;&#25915;&#20987;&#27169;&#22411;&#25110;&#27599;&#20010;&#31867;&#21035;&#26631;&#31614;&#30340;&#25915;&#20987;&#27169;&#22411;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#20855;&#26377;&#38646;&#21806;&#12289;&#21046;&#36896;&#12289;&#20581;&#24247;&#31561;&#35768;&#22810;&#39046;&#22495;&#30340;&#29992;&#20363;&#12290;&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#37319;&#29992;&#30340;&#22686;&#21152;&#65292;&#24050;&#32463;&#21457;&#29616;&#20102;&#30456;&#20851;&#30340;&#39118;&#38505;&#65292;&#21253;&#25324;&#23545;&#20351;&#29992;&#20854;&#25968;&#25454;&#35757;&#32451;&#27169;&#22411;&#30340;&#20154;&#30340;&#38544;&#31169;&#39118;&#38505;&#12290;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38544;&#31169;&#39118;&#38505;&#23545;&#20110;&#26159;&#21542;&#20351;&#29992;&#12289;&#37096;&#32626;&#25110;&#20849;&#20139;&#27169;&#22411;&#20570;&#20986;&#30693;&#24773;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#38544;&#31169;&#39118;&#38505;&#35780;&#20272;&#30340;&#19968;&#31181;&#24120;&#35265;&#26041;&#27861;&#26159;&#23545;&#27169;&#22411;&#36827;&#34892;&#19968;&#20010;&#25110;&#22810;&#20010;&#24050;&#30693;&#25915;&#20987;&#65292;&#24182;&#27979;&#37327;&#23427;&#20204;&#30340;&#25104;&#21151;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#20998;&#31867;&#27169;&#22411;&#36827;&#34892;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21033;&#29992;&#38598;&#25104;&#26041;&#27861;&#65292;&#20026;&#19981;&#21516;&#25968;&#25454;&#23376;&#38598;&#29983;&#25104;&#35768;&#22810;&#19987;&#38376;&#30340;&#25915;&#20987;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#32463;&#20856;&#21644;&#35821;&#35328;&#20998;&#31867;&#20219;&#21153;&#19978;&#27604;&#21333;&#20010;&#25915;&#20987;&#27169;&#22411;&#25110;&#27599;&#20010;&#31867;&#21035;&#26631;&#31614;&#30340;&#25915;&#20987;&#27169;&#22411;&#37117;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence systems are prevalent in everyday life, with use cases in retail, manufacturing, health, and many other fields. With the rise in AI adoption, associated risks have been identified, including privacy risks to the people whose data was used to train models. Assessing the privacy risks of machine learning models is crucial to enabling knowledgeable decisions on whether to use, deploy, or share a model. A common approach to privacy risk assessment is to run one or more known attacks against the model and measure their success rate. We present a novel framework for running membership inference attacks against classification models. Our framework takes advantage of the ensemble method, generating many specialized attack models for different subsets of the data. We show that this approach achieves higher accuracy than either a single attack model or an attack model per class label, both on classical and language classification tasks.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#26131;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#20197;&#22826;&#22346;&#19978;&#24222;&#27663;&#39575;&#23616;&#30340;&#26816;&#27979;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#22522;&#20110;&#26234;&#33021;&#21512;&#32422;&#28304;&#20195;&#30721;&#25110;&#25805;&#20316;&#30721;&#36827;&#34892;&#26816;&#27979;&#65292;&#20294;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#20998;&#26512;&#20132;&#26131;&#25968;&#25454;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#35782;&#21035;&#24222;&#27663;&#39575;&#23616;&#65292;&#22240;&#20026;&#20132;&#26131;&#26356;&#38590;&#20266;&#35013;&#12290;</title><link>http://arxiv.org/abs/2308.16391</link><description>&lt;p&gt;
&#25552;&#39640;&#20197;&#22826;&#22346;&#19978;&#24222;&#27663;&#39575;&#23616;&#26816;&#27979;&#30340;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improving Robustness and Accuracy of Ponzi Scheme Detection on Ethereum Using Time-Dependent Features. (arXiv:2308.16391v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16391
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#26131;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#20197;&#22826;&#22346;&#19978;&#24222;&#27663;&#39575;&#23616;&#30340;&#26816;&#27979;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#22522;&#20110;&#26234;&#33021;&#21512;&#32422;&#28304;&#20195;&#30721;&#25110;&#25805;&#20316;&#30721;&#36827;&#34892;&#26816;&#27979;&#65292;&#20294;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#20998;&#26512;&#20132;&#26131;&#25968;&#25454;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#35782;&#21035;&#24222;&#27663;&#39575;&#23616;&#65292;&#22240;&#20026;&#20132;&#26131;&#26356;&#38590;&#20266;&#35013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21306;&#22359;&#38142;&#30340;&#24555;&#36895;&#21457;&#23637;&#23548;&#33268;&#36234;&#26469;&#36234;&#22810;&#30340;&#36164;&#37329;&#28044;&#20837;&#21152;&#23494;&#36135;&#24065;&#24066;&#22330;&#65292;&#20063;&#21560;&#24341;&#20102;&#36817;&#24180;&#26469;&#32593;&#32476;&#29359;&#32618;&#20998;&#23376;&#30340;&#20852;&#36259;&#12290;&#24222;&#27663;&#39575;&#23616;&#20316;&#20026;&#19968;&#31181;&#32769;&#24335;&#30340;&#27450;&#35784;&#34892;&#20026;&#65292;&#29616;&#22312;&#20063;&#27969;&#34892;&#20110;&#21306;&#22359;&#38142;&#19978;&#65292;&#32473;&#35768;&#22810;&#21152;&#23494;&#36135;&#24065;&#25237;&#36164;&#32773;&#36896;&#25104;&#20102;&#24040;&#22823;&#30340;&#36130;&#21153;&#25439;&#22833;&#12290;&#29616;&#26377;&#25991;&#29486;&#20013;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#24222;&#27663;&#39575;&#23616;&#26816;&#27979;&#26041;&#27861;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#26159;&#22522;&#20110;&#26234;&#33021;&#21512;&#32422;&#30340;&#28304;&#20195;&#30721;&#25110;&#25805;&#20316;&#30721;&#36827;&#34892;&#26816;&#27979;&#30340;&#12290;&#34429;&#28982;&#22522;&#20110;&#21512;&#32422;&#20195;&#30721;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#32570;&#20047;&#40065;&#26834;&#24615;&#65306;&#39318;&#20808;&#65292;&#22823;&#37096;&#20998;&#20197;&#22826;&#22346;&#19978;&#30340;&#21512;&#32422;&#28304;&#20195;&#30721;&#24182;&#19981;&#20844;&#24320;&#21487;&#29992;&#65307;&#20854;&#27425;&#65292;&#24222;&#27663;&#39575;&#23616;&#24320;&#21457;&#32773;&#21487;&#20197;&#36890;&#36807;&#28151;&#28102;&#25805;&#20316;&#30721;&#25110;&#32773;&#21019;&#36896;&#26032;&#30340;&#20998;&#37197;&#36923;&#36753;&#26469;&#27450;&#39575;&#22522;&#20110;&#21512;&#32422;&#20195;&#30721;&#30340;&#26816;&#27979;&#27169;&#22411;&#65288;&#22240;&#20026;&#36825;&#20123;&#27169;&#22411;&#20165;&#22312;&#29616;&#26377;&#30340;&#24222;&#27663;&#36923;&#36753;&#19978;&#36827;&#34892;&#35757;&#32451;&#65289;&#12290;&#22522;&#20110;&#20132;&#26131;&#30340;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#26816;&#27979;&#30340;&#40065;&#26834;&#24615;&#65292;&#22240;&#20026;&#19982;&#26234;&#33021;&#21512;&#32422;&#19981;&#21516;&#65292;&#20132;&#26131;&#26356;&#21152;&#38590;&#20197;&#20266;&#35013;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid development of blockchain has led to more and more funding pouring into the cryptocurrency market, which also attracted cybercriminals' interest in recent years. The Ponzi scheme, an old-fashioned fraud, is now popular on the blockchain, causing considerable financial losses to many crypto-investors. A few Ponzi detection methods have been proposed in the literature, most of which detect a Ponzi scheme based on its smart contract source code or opcode. The contract-code-based approach, while achieving very high accuracy, is not robust: first, the source codes of a majority of contracts on Ethereum are not available, and second, a Ponzi developer can fool a contract-code-based detection model by obfuscating the opcode or inventing a new profit distribution logic that cannot be detected (since these models were trained on existing Ponzi logics only). A transaction-based approach could improve the robustness of detection because transactions, unlike smart contracts, are harder t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#20013;&#65292;&#32771;&#34385;&#21040;&#20449;&#24687;&#35770;&#38544;&#31169;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#30340;&#23458;&#25143;&#31471;&#65292;&#22914;&#20309;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#38544;&#31169;&#25968;&#25454;&#32858;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.14088</link><description>&lt;p&gt;
&#38750;&#21516;&#36136;&#21270;&#38598;&#32676;&#19979;&#30340;&#26080;&#32447;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#31169;&#26377;&#25968;&#25454;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Private Aggregation in Wireless Federated Learning with Heterogeneous Clusters. (arXiv:2306.14088v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#20013;&#65292;&#32771;&#34385;&#21040;&#20449;&#24687;&#35770;&#38544;&#31169;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#30340;&#23458;&#25143;&#31471;&#65292;&#22914;&#20309;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#38544;&#31169;&#25968;&#25454;&#32858;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#36890;&#36807;&#22810;&#20010;&#21442;&#19982;&#23458;&#25143;&#31471;&#31169;&#26377;&#25968;&#25454;&#30340;&#21327;&#21516;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#36807;&#31243;&#20013;&#65292;&#20351;&#29992;&#19968;&#31181;&#33879;&#21517;&#24182;&#24191;&#27867;&#20351;&#29992;&#30340;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#8212;&#8212;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#27599;&#20010;&#23458;&#25143;&#31471;&#20351;&#29992;&#26412;&#22320;&#25968;&#25454;&#35745;&#31639;&#23616;&#37096;&#26799;&#24230;&#24182;&#23558;&#20854;&#21457;&#36865;&#32473;&#32852;&#21512;&#22120;&#20197;&#36827;&#34892;&#32858;&#21512;&#12290;&#23458;&#25143;&#31471;&#25968;&#25454;&#30340;&#38544;&#31169;&#26159;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#12290;&#23454;&#38469;&#19978;&#65292;&#35266;&#23519;&#21040;&#23616;&#37096;&#26799;&#24230;&#23601;&#36275;&#20197;&#27844;&#38706;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#12290;&#24050;&#30740;&#31350;&#20102;&#29992;&#20110;&#24212;&#23545;&#32852;&#37030;&#23398;&#20064;&#20013;&#38544;&#31169;&#38382;&#39064;&#30340;&#31169;&#26377;&#32858;&#21512;&#26041;&#26696;&#65292;&#20854;&#20013;&#25152;&#26377;&#29992;&#25143;&#37117;&#24444;&#27492;&#36830;&#25509;&#24182;&#19982;&#32852;&#21512;&#22120;&#36830;&#25509;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#26550;&#26500;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#20165;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#12290;&#24403;&#38656;&#35201;&#20449;&#24687;&#35770;&#38544;&#31169;&#26102;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#36890;&#20449;&#25104;&#26412;&#30340;&#22522;&#26412;&#26497;&#38480;&#65292;&#24182;&#24341;&#20837;&#21644;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#36825;&#31181;&#24773;&#20917;&#37327;&#36523;&#23450;&#21046;&#30340;&#31169;&#26377;&#32858;&#21512;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning collaboratively trains a neural network on privately owned data held by several participating clients. The gradient descent algorithm, a well-known and popular iterative optimization procedure, is run to train the neural network. Every client uses its local data to compute partial gradients and sends it to the federator which aggregates the results. Privacy of the clients' data is a major concern. In fact, observing the partial gradients can be enough to reveal the clients' data. Private aggregation schemes have been investigated to tackle the privacy problem in federated learning where all the users are connected to each other and to the federator. In this paper, we consider a wireless system architecture where clients are only connected to the federator via base stations. We derive fundamental limits on the communication cost when information-theoretic privacy is required, and introduce and analyze a private aggregation scheme tailored for this setting.
&lt;/p&gt;</description></item></channel></rss>