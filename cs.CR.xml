<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38646;&#30693;&#35782;&#35777;&#26126;&#30340;&#32852;&#37030;&#23398;&#20064;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#23454;&#38469;&#31995;&#32479;&#20013;&#26816;&#27979;&#21644;&#28040;&#38500;&#24694;&#24847;&#23458;&#25143;&#31471;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.04055</link><description>&lt;p&gt;
&#25226;&#22351;&#20154;&#36386;&#20986;&#21435;&#65281;&#22522;&#20110;&#38646;&#30693;&#35782;&#35777;&#26126;&#30340;&#32852;&#37030;&#23398;&#20064;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Kick Bad Guys Out! Zero-Knowledge-Proof-Based Anomaly Detection in Federated Learning. (arXiv:2310.04055v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38646;&#30693;&#35782;&#35777;&#26126;&#30340;&#32852;&#37030;&#23398;&#20064;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#23454;&#38469;&#31995;&#32479;&#20013;&#26816;&#27979;&#21644;&#28040;&#38500;&#24694;&#24847;&#23458;&#25143;&#31471;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#24694;&#24847;&#23458;&#25143;&#31471;&#30340;&#25915;&#20987;&#65292;&#20182;&#20204;&#36890;&#36807;&#25552;&#20132;&#31713;&#25913;&#30340;&#26412;&#22320;&#27169;&#22411;&#26469;&#36798;&#21040;&#23545;&#25239;&#30446;&#26631;&#65292;&#27604;&#22914;&#38459;&#27490;&#20840;&#23616;&#27169;&#22411;&#30340;&#25910;&#25947;&#25110;&#32773;&#23548;&#33268;&#20840;&#23616;&#27169;&#22411;&#23545;&#26576;&#20123;&#25968;&#25454;&#36827;&#34892;&#38169;&#35823;&#20998;&#31867;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#38450;&#24481;&#26426;&#21046;&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#19981;&#21487;&#34892;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20808;&#30693;&#36947;&#24694;&#24847;&#23458;&#25143;&#31471;&#30340;&#25968;&#37327;&#65292;&#25110;&#32773;&#20381;&#36182;&#37325;&#26032;&#21152;&#26435;&#25110;&#20462;&#25913;&#25552;&#20132;&#30340;&#26041;&#24335;&#12290;&#36825;&#26159;&#22240;&#20026;&#25915;&#20987;&#32773;&#36890;&#24120;&#19981;&#20250;&#22312;&#25915;&#20987;&#20043;&#21069;&#23459;&#24067;&#20182;&#20204;&#30340;&#24847;&#22270;&#65292;&#32780;&#37325;&#26032;&#21152;&#26435;&#21487;&#33021;&#20250;&#25913;&#21464;&#32858;&#21512;&#32467;&#26524;&#65292;&#21363;&#20351;&#27809;&#26377;&#25915;&#20987;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#25361;&#25112;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26368;&#23574;&#31471;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#20855;&#26377;&#20197;&#19979;&#29305;&#28857;&#65306;i&#65289;&#20165;&#22312;&#21457;&#29983;&#25915;&#20987;&#26102;&#26816;&#27979;&#25915;&#20987;&#30340;&#21457;&#29983;&#24182;&#36827;&#34892;&#38450;&#24481;&#25805;&#20316;&#65307;ii&#65289;&#19968;&#26086;&#21457;&#29983;&#25915;&#20987;&#65292;&#36827;&#19968;&#27493;&#26816;&#27979;&#24694;&#24847;&#23458;&#25143;&#31471;&#27169;&#22411;&#24182;&#23558;&#20854;&#28040;&#38500;&#65292;&#32780;&#19981;&#20250;&#23545;&#27491;&#24120;&#27169;&#22411;&#36896;&#25104;&#20260;&#23475;&#65307;iii&#65289;&#30830;&#20445;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) systems are vulnerable to malicious clients that submit poisoned local models to achieve their adversarial goals, such as preventing the convergence of the global model or inducing the global model to misclassify some data. Many existing defense mechanisms are impractical in real-world FL systems, as they require prior knowledge of the number of malicious clients or rely on re-weighting or modifying submissions. This is because adversaries typically do not announce their intentions before attacking, and re-weighting might change aggregation results even in the absence of attacks. To address these challenges in real FL systems, this paper introduces a cutting-edge anomaly detection approach with the following features: i) Detecting the occurrence of attacks and performing defense operations only when attacks happen; ii) Upon the occurrence of an attack, further detecting the malicious client models and eliminating them without harming the benign ones; iii) Ensuri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#25239;&#22270;&#20687;&#37325;&#26500;&#21450;&#26816;&#27979;&#26694;&#26550;&#26469;&#20445;&#25252;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#65292;&#33021;&#22815;&#38450;&#24481;&#23616;&#37096;&#25200;&#21160;&#20026;&#29305;&#24449;&#30340;&#23545;&#25239;&#25915;&#20987;&#24182;&#19988;&#33021;&#22815;&#22312;&#24178;&#20928;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#19978;&#36827;&#34892;&#35757;&#32451;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2306.07992</link><description>&lt;p&gt;
&#23433;&#20840;&#30340;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#65306;&#19968;&#31181;&#23545;&#25239;&#22270;&#20687;&#37325;&#26500;&#21450;&#26816;&#27979;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework. (arXiv:2306.07992v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#25239;&#22270;&#20687;&#37325;&#26500;&#21450;&#26816;&#27979;&#26694;&#26550;&#26469;&#20445;&#25252;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#65292;&#33021;&#22815;&#38450;&#24481;&#23616;&#37096;&#25200;&#21160;&#20026;&#29305;&#24449;&#30340;&#23545;&#25239;&#25915;&#20987;&#24182;&#19988;&#33021;&#22815;&#22312;&#24178;&#20928;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#19978;&#36827;&#34892;&#35757;&#32451;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23500;&#21547;&#22270;&#29255;&#31561;&#35270;&#35273;&#25968;&#25454;&#19982;&#29289;&#21697;&#20851;&#32852;&#24230;&#22686;&#21152;&#65292;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#65288;VARS&#65289;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#19981;&#21516;&#24212;&#29992;&#39046;&#22495;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;VARS&#26131;&#21463;&#21040;&#29289;&#21697;-&#22270;&#20687;&#23545;&#25239;&#25915;&#20987;&#30340;&#25915;&#20987;&#65292;&#36825;&#20123;&#25915;&#20987;&#21521;&#19982;&#36825;&#20123;&#29289;&#21697;&#20851;&#32852;&#30340;&#24178;&#20928;&#22270;&#20687;&#28155;&#21152;&#20154;&#31867;&#26080;&#27861;&#24863;&#30693;&#30340;&#25200;&#21160;&#12290;&#23545;VARS&#30340;&#25915;&#20987;&#20026;&#24191;&#27867;&#20351;&#29992;VARS&#30340;&#35768;&#22810;&#24212;&#29992;&#65288;&#22914;&#30005;&#23376;&#21830;&#21153;&#21644;&#31038;&#20132;&#32593;&#32476;&#65289;&#24102;&#26469;&#26032;&#30340;&#23433;&#20840;&#25361;&#25112;&#12290;&#22914;&#20309;&#20445;&#25252;VARS&#20813;&#21463;&#27492;&#31867;&#23545;&#25239;&#25915;&#20987;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#30340;&#38382;&#39064;&#12290;&#30446;&#21069;&#65292;&#23578;&#32570;&#20047;&#31995;&#32479;&#22320;&#30740;&#31350;&#22914;&#20309;&#35774;&#35745;&#38024;&#23545;VARS&#35270;&#35273;&#25915;&#20987;&#30340;&#23433;&#20840;&#38450;&#24481;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#25239;&#22270;&#20687;&#37325;&#26500;&#21450;&#26816;&#27979;&#26694;&#26550;&#26469;&#20445;&#25252;VARS&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21516;&#26102;(1)&#36890;&#36807;&#22522;&#20110;&#20840;&#23616;&#35270;&#35273;&#20256;&#36755;&#30340;&#22270;&#20687;&#37325;&#26500;&#26469;&#38450;&#24481;&#20197;&#23616;&#37096;&#25200;&#21160;&#20026;&#29305;&#24449;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;(2)&#20351;&#29992;&#22312;&#23569;&#37327;&#24178;&#20928;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#19978;&#35757;&#32451;&#30340;&#26816;&#27979;&#27169;&#22411;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#22270;&#20687;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#33021;&#22815;&#26377;&#25928;&#22320;&#38450;&#24481;&#21508;&#31181;&#29289;&#21697;-&#22270;&#20687;&#23545;&#25239;&#25915;&#20987;&#23545;VARS&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
With rich visual data, such as images, becoming readily associated with items, visually-aware recommendation systems (VARS) have been widely used in different applications. Recent studies have shown that VARS are vulnerable to item-image adversarial attacks, which add human-imperceptible perturbations to the clean images associated with those items. Attacks on VARS pose new security challenges to a wide range of applications such as e-Commerce and social networks where VARS are widely used. How to secure VARS from such adversarial attacks becomes a critical problem. Currently, there is still a lack of systematic study on how to design secure defense strategies against visual attacks on VARS. In this paper, we attempt to fill this gap by proposing an adversarial image reconstruction and detection framework to secure VARS. Our proposed method can simultaneously (1) secure VARS from adversarial attacks characterized by local perturbations by image reconstruction based on global vision tra
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;API&#30340;&#26041;&#27861;&#29983;&#25104;&#23494;&#20999;&#31867;&#20284;&#20110;&#21407;&#22987;&#31169;&#26377;&#25968;&#25454;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#21512;&#25104;&#25968;&#25454;&#65292;&#21487;&#20197;&#26356;&#36731;&#26494;&#22320;&#37096;&#32626;&#12290;&#20351;&#29992;Private Evolution&#65288;PE&#65289;&#26694;&#26550;&#29983;&#25104;DP&#21512;&#25104;&#22270;&#20687;&#65292;&#32467;&#21512;&#20102;&#24046;&#20998;&#38544;&#31169;&#12289;&#36827;&#21270;&#31639;&#27861;&#21644;&#20803;&#23398;&#20064;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21516;&#26102;&#29983;&#25104;&#26082;&#20026;DP&#21448;&#19982;&#21407;&#22987;&#22270;&#20687;&#22806;&#35266;&#30456;&#20284;&#30340;&#21512;&#25104;&#22270;&#20687;&#65292;&#24182;&#22312;&#27969;&#34892;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.15560</link><description>&lt;p&gt;
&#22522;&#20110; Foundation Model APIs &#30340;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#65306;&#22270;&#29255;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Synthetic Data via Foundation Model APIs 1: Images. (arXiv:2305.15560v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;API&#30340;&#26041;&#27861;&#29983;&#25104;&#23494;&#20999;&#31867;&#20284;&#20110;&#21407;&#22987;&#31169;&#26377;&#25968;&#25454;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#21512;&#25104;&#25968;&#25454;&#65292;&#21487;&#20197;&#26356;&#36731;&#26494;&#22320;&#37096;&#32626;&#12290;&#20351;&#29992;Private Evolution&#65288;PE&#65289;&#26694;&#26550;&#29983;&#25104;DP&#21512;&#25104;&#22270;&#20687;&#65292;&#32467;&#21512;&#20102;&#24046;&#20998;&#38544;&#31169;&#12289;&#36827;&#21270;&#31639;&#27861;&#21644;&#20803;&#23398;&#20064;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21516;&#26102;&#29983;&#25104;&#26082;&#20026;DP&#21448;&#19982;&#21407;&#22987;&#22270;&#20687;&#22806;&#35266;&#30456;&#20284;&#30340;&#21512;&#25104;&#22270;&#20687;&#65292;&#24182;&#22312;&#27969;&#34892;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#21069;&#25968;&#25454;&#39537;&#21160;&#30340;&#19990;&#30028;&#20013;&#65292;&#29983;&#25104;&#23494;&#20999;&#31867;&#20284;&#20110;&#21407;&#22987;&#31169;&#26377;&#25968;&#25454;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#21512;&#25104;&#25968;&#25454;&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#21487;&#20943;&#36731;&#38544;&#31169;&#38382;&#39064;&#12290;&#19982;&#24403;&#21069;&#20026;&#27492;&#20219;&#21153;&#35757;&#32451;&#23450;&#21046;&#27169;&#22411;&#30340;&#20570;&#27861;&#30456;&#21453;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;API&#29983;&#25104;DP&#21512;&#25104;&#25968;&#25454;&#65288;DPSDA&#65289;&#65292;&#20854;&#20013;&#25105;&#20204;&#23558;&#22522;&#30784;&#27169;&#22411;&#35270;&#20026;&#40657;&#30418;&#24182;&#21482;&#21033;&#29992;&#20854;&#25512;&#29702;API&#12290;&#36825;&#20123;&#22522;&#20110;API&#30340;&#12289;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#26356;&#23481;&#26131;&#37096;&#32626;&#65292;&#22914;&#26368;&#36817; API &#24212;&#29992;&#31243;&#24207;&#30340;&#28608;&#22686;&#25152;&#35777;&#26126;&#30340;&#37027;&#26679;&#12290;&#36825;&#20123;&#26041;&#27861;&#36824;&#21487;&#20197;&#21033;&#29992;&#21487;&#36890;&#36807;&#20854;&#25512;&#29702;API&#35775;&#38382;&#20854;&#26435;&#37325;&#26410;&#21457;&#24067;&#30340;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#27169;&#22411;&#35775;&#38382;&#26356;&#21152;&#20005;&#26684;&#65292;&#36824;&#38656;&#20445;&#25252;API&#25552;&#20379;&#21830;&#30340;&#38544;&#31169;&#65292;&#36825;&#23558;&#24102;&#26469;&#26356;&#22823;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026; Private Evolution&#65288;PE&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20351;&#29992;&#22522;&#30784;&#27169;&#22411;API&#29983;&#25104;DP&#21512;&#25104;&#22270;&#20687;&#26041;&#38754;&#30340;&#21021;&#22987;&#23454;&#29616;&#12290;PE&#32467;&#21512;&#20102;&#24046;&#20998;&#38544;&#31169;&#12289;&#36827;&#21270;&#31639;&#27861;&#21644;&#20803;&#23398;&#20064;&#30340;&#25216;&#26415;&#65292;&#26377;&#25928;&#22320;&#29983;&#25104;&#26082;&#20026;DP&#21448;&#19982;&#21407;&#22987;&#22270;&#20687;&#22806;&#35266;&#30456;&#20284;&#30340;&#21512;&#25104;&#22270;&#20687;&#12290;&#25105;&#20204;&#36824;&#22312;&#27969;&#34892;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#22914;CIFAR-10&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#24182;&#26174;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25928;&#29992;&#21644;&#38544;&#31169;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;DP&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generating differentially private (DP) synthetic data that closely resembles the original private data without leaking sensitive user information is a scalable way to mitigate privacy concerns in the current data-driven world. In contrast to current practices that train customized models for this task, we aim to generate DP Synthetic Data via APIs (DPSDA), where we treat foundation models as blackboxes and only utilize their inference APIs. Such API-based, training-free approaches are easier to deploy as exemplified by the recent surge in the number of API-based apps. These approaches can also leverage the power of large foundation models which are accessible via their inference APIs while the model weights are unreleased. However, this comes with greater challenges due to strictly more restrictive model access and the additional need to protect privacy from the API provider.  In this paper, we present a new framework called Private Evolution (PE) to solve this problem and show its ini
&lt;/p&gt;</description></item></channel></rss>