<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#31070;&#32463;&#32593;&#32476;&#20013;&#29109;&#27169;&#22411;&#23545;&#26377;&#24847;&#24178;&#25200;&#21644;&#26080;&#24847;&#24178;&#25200;&#30340;&#38887;&#24615;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#29109;&#27169;&#22411;&#30340;&#38887;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00942</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#31070;&#32463;&#32593;&#32476;&#20013;&#29109;&#27169;&#22411;&#30340;&#38887;&#24615;
&lt;/p&gt;
&lt;p&gt;
Resilience of Entropy Model in Distributed Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#31070;&#32463;&#32593;&#32476;&#20013;&#29109;&#27169;&#22411;&#23545;&#26377;&#24847;&#24178;&#25200;&#21644;&#26080;&#24847;&#24178;&#25200;&#30340;&#38887;&#24615;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#29109;&#27169;&#22411;&#30340;&#38887;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#24050;&#32463;&#25104;&#20026;&#36793;&#32536;&#35745;&#31639;&#31995;&#32479;&#20013;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#32780;&#19981;&#38477;&#20302;&#24615;&#33021;&#30340;&#20851;&#38190;&#25216;&#26415;&#12290;&#26368;&#36817;&#65292;&#29109;&#32534;&#30721;&#34987;&#24341;&#20837;&#20197;&#36827;&#19968;&#27493;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#12290;&#20854;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#20998;&#24067;&#24335;DNN&#19982;&#29109;&#27169;&#22411;&#32852;&#21512;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#22312;&#25512;&#26029;&#26102;&#38388;&#29992;&#20316;&#36793;&#20449;&#24687;&#65292;&#20197;&#33258;&#36866;&#24212;&#22320;&#23558;&#28508;&#22312;&#34920;&#31034;&#32534;&#30721;&#20026;&#20855;&#26377;&#21487;&#21464;&#38271;&#24230;&#30340;&#27604;&#29305;&#27969;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#29109;&#27169;&#22411;&#30340;&#38887;&#24615;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21046;&#23450;&#24182;&#35843;&#26597;&#20102;&#29109;&#27169;&#22411;&#23545;&#26377;&#24847;&#24178;&#25200;&#65288;&#20363;&#22914;&#65292;&#23545;&#25239;&#24615;&#25915;&#20987;&#65289;&#21644;&#26080;&#24847;&#24178;&#25200;&#65288;&#20363;&#22914;&#65292;&#22825;&#27668;&#21464;&#21270;&#21644;&#36816;&#21160;&#27169;&#31946;&#65289;&#30340;&#38887;&#24615;&#12290;&#36890;&#36807;&#23545;3&#31181;&#19981;&#21516;DNN&#26550;&#26500;&#12289;2&#20010;&#29109;&#27169;&#22411;&#21644;4&#20010;&#36895;&#29575;&#22833;&#30495;&#26435;&#34913;&#22240;&#23376;&#36827;&#34892;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29109;&#27169;&#22411;&#30340;&#38887;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00942v1 Announce Type: cross  Abstract: Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model, which is used as side information during inference time to adaptively encode latent representations into bit streams with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated. As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference (e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur). Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion trade-off factors, we demonstrate that the entropy attacks
&lt;/p&gt;</description></item></channel></rss>