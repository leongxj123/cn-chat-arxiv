<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#27604;&#30446;&#26631;&#27169;&#22411;&#26356;&#39640;&#31934;&#24230;&#19979;&#36827;&#34892;&#35757;&#32451;&#12289;&#22312;&#20013;&#38388;&#35745;&#31639;&#27493;&#39588;&#21518;&#36827;&#34892;&#22235;&#33293;&#20116;&#20837;&#65292;&#24182;&#22522;&#20110;&#33258;&#36866;&#24212;&#38408;&#20540;&#23384;&#20648;&#22235;&#33293;&#20116;&#20837;&#20915;&#31574;&#65292;&#20197;&#24212;&#23545;&#30828;&#20214;&#38750;&#30830;&#23450;&#24615;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.09603</link><description>&lt;p&gt;
&#25511;&#21046;&#30828;&#20214;&#38750;&#30830;&#23450;&#24615;&#36827;&#34892;&#20048;&#35266;&#21487;&#39564;&#35777;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Optimistic Verifiable Training by Controlling Hardware Nondeterminism
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09603
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#27604;&#30446;&#26631;&#27169;&#22411;&#26356;&#39640;&#31934;&#24230;&#19979;&#36827;&#34892;&#35757;&#32451;&#12289;&#22312;&#20013;&#38388;&#35745;&#31639;&#27493;&#39588;&#21518;&#36827;&#34892;&#22235;&#33293;&#20116;&#20837;&#65292;&#24182;&#22522;&#20110;&#33258;&#36866;&#24212;&#38408;&#20540;&#23384;&#20648;&#22235;&#33293;&#20116;&#20837;&#20915;&#31574;&#65292;&#20197;&#24212;&#23545;&#30828;&#20214;&#38750;&#30830;&#23450;&#24615;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#31995;&#32479;&#26085;&#30410;&#22686;&#21152;&#30340;&#35745;&#31639;&#38656;&#27714;&#23548;&#33268;&#20102;&#20026;&#32570;&#20047;&#24517;&#35201;&#36164;&#28304;&#30340;&#23458;&#25143;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#30340;&#26381;&#21153;&#30340;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#30830;&#20445;&#35757;&#32451;&#30340;&#27491;&#30830;&#24615;&#24182;&#38450;&#33539;&#28508;&#22312;&#30340;&#35757;&#32451;&#26102;&#25915;&#20987;&#65292;&#20363;&#22914;&#25968;&#25454;&#27602;&#21270;&#65292;&#37117;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#20851;&#20110;&#21487;&#39564;&#35777;&#35757;&#32451;&#30340;&#24037;&#20316;&#20027;&#35201;&#20998;&#20026;&#20004;&#31867;&#65306;&#22522;&#20110;&#35777;&#26126;&#30340;&#31995;&#32479;&#65292;&#30001;&#20110;&#38656;&#35201;&#21152;&#23494;&#25216;&#26415;&#32780;&#38590;&#20197;&#25193;&#23637;&#65292;&#20197;&#21450;&#32771;&#34385;&#21040;&#19968;&#20010;&#21487;&#20449;&#31532;&#19977;&#26041;&#23457;&#35745;&#21592;&#22797;&#21046;&#35757;&#32451;&#36807;&#31243;&#30340;&#8220;&#20048;&#35266;&#8221;&#26041;&#27861;&#12290; &#21518;&#32773;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#65292;&#22312;&#35757;&#32451;&#26399;&#38388;GPU&#31867;&#22411;&#20043;&#38388;&#30340;&#30828;&#20214;&#38750;&#30830;&#23450;&#24615;&#38459;&#27490;&#23457;&#35745;&#21592;&#31934;&#30830;&#22797;&#21046;&#35757;&#32451;&#36807;&#31243;&#65292;&#22240;&#27492;&#36825;&#26679;&#30340;&#26041;&#26696;&#19981;&#22815;&#20581;&#22766;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#23558;&#35757;&#32451;&#22312;&#27604;&#30446;&#26631;&#27169;&#22411;&#26356;&#39640;&#30340;&#31934;&#24230;&#19979;&#36827;&#34892;&#65292;&#20013;&#38388;&#35745;&#31639;&#27493;&#39588;&#21518;&#22235;&#33293;&#20116;&#20837;&#65292;&#22522;&#20110;&#33258;&#36866;&#24212;&#38408;&#20540;&#23384;&#20648;&#22235;&#33293;&#20116;&#20837;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09603v1 Announce Type: cross  Abstract: The increasing compute demands of AI systems has led to the emergence of services that train models on behalf of clients lacking necessary resources. However, ensuring correctness of training and guarding against potential training-time attacks, such as data poisoning, poses challenges. Existing works on verifiable training largely fall into two classes: proof-based systems, which struggle to scale due to requiring cryptographic techniques, and "optimistic" methods that consider a trusted third-party auditor who replicates the training process. A key challenge with the latter is that hardware nondeterminism between GPU types during training prevents an auditor from replicating the training process exactly, and such schemes are therefore non-robust. We propose a method that combines training in a higher precision than the target model, rounding after intermediate computation steps, and storing rounding decisions based on an adaptive thr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24418;&#24335;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#65292;&#24182;&#31995;&#32479;&#21270;&#38450;&#24481;&#36825;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2310.12815</link><description>&lt;p&gt;
LLM-&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#21644;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24418;&#24335;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#65292;&#24182;&#31995;&#32479;&#21270;&#38450;&#24481;&#36825;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20316;&#21508;&#31181;&#31216;&#20026;LLM-&#38598;&#25104;&#24212;&#29992;&#30340;&#23454;&#38469;&#24212;&#29992;&#31243;&#24207;&#30340;&#21518;&#31471;&#12290;&#26368;&#36817;&#30340;&#22810;&#39033;&#30740;&#31350;&#34920;&#26126;&#65292;LLM-&#38598;&#25104;&#24212;&#29992;&#23481;&#26131;&#21463;&#21040;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#23041;&#32961;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#23558;&#24694;&#24847;&#25351;&#20196;/&#25968;&#25454;&#27880;&#20837;&#36825;&#20123;&#24212;&#29992;&#31243;&#24207;&#30340;&#36755;&#20837;&#20013;&#65292;&#20197;&#36798;&#21040;&#25915;&#20987;&#32773;&#30340;&#39044;&#26399;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30740;&#31350;&#20165;&#38480;&#20110;&#26696;&#20363;&#30740;&#31350;&#65292;&#32570;&#20047;&#23545;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#21450;&#20854;&#38450;&#24481;&#30340;&#31995;&#32479;&#29702;&#35299;&#12290;&#26412;&#35770;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24418;&#24335;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#65292;&#24182;&#23558;&#30740;&#31350;&#35770;&#25991;&#21644;&#21338;&#23458;&#25991;&#31456;&#20013;&#35752;&#35770;&#30340;&#29616;&#26377;&#25915;&#20987;&#35270;&#20026;&#25105;&#20204;&#26694;&#26550;&#30340;&#29305;&#20363;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#32452;&#21512;&#29616;&#26377;&#25915;&#20987;&#35774;&#35745;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#38450;&#24481;&#30340;&#26694;&#26550;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#39044;&#38450;&#21644;&#32531;&#35299;&#36825;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are increasingly deployed as the backend for a variety of real-world applications called LLM-Integrated Applications. Multiple recent works showed that LLM-Integrated Applications are vulnerable to prompt injection attacks, in which an attacker injects malicious instruction/data into the input of those applications such that they produce results as the attacker desires. However, existing works are limited to case studies. As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses. We aim to bridge the gap in this work. In particular, we propose a general framework to formalize prompt injection attacks. Existing attacks, which are discussed in research papers and blog posts, are special cases in our framework. Our framework enables us to design a new attack by combining existing attacks. Moreover, we also propose a framework to systematize defenses against prompt injection attacks. Using our frameworks, we con
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00353</link><description>&lt;p&gt;
&#20174;&#27010;&#29575;&#35282;&#24230;&#26500;&#24314;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective. (arXiv:2306.00353v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#35270;&#35282;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#8212;&#8212;&#31665;&#32422;&#26463; Langevin Monte Carlo&#65288;LMC&#65289;&#12290;&#20174;&#36825;&#20010;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#36229;&#36234;&#20102;&#20960;&#20309;&#36317;&#31163;&#25152;&#26045;&#21152;&#30340;&#38480;&#21046;&#65292;&#36873;&#25321;&#20102;&#35821;&#20041;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36171;&#20104;&#20102;&#20010;&#20307;&#23558;&#20854;&#23545;&#35821;&#20041;&#30340;&#29702;&#35299;&#34701;&#20837;&#21040;&#27169;&#22411;&#20013;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#20445;&#25345;&#20854;&#22266;&#26377;&#30340;&#21547;&#20041;&#12290;&#22312; MNIST &#21644; SVHN &#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#21487;&#20197;&#26377;&#25928;&#22320;&#35268;&#36991;&#38024;&#23545;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#20581;&#24615;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we introduce a novel, probabilistic viewpoint on adversarial examples, achieved through box-constrained Langevin Monte Carlo (LMC). Proceeding from this perspective, we develop an innovative approach for generating semantics-aware adversarial examples in a principled manner. This methodology transcends the restriction imposed by geometric distance, instead opting for semantic constraints. Our approach empowers individuals to incorporate their personal comprehension of semantics into the model. Through human evaluation, we validate that our semantics-aware adversarial examples maintain their inherent meaning. Experimental findings on the MNIST and SVHN datasets demonstrate that our semantics-aware adversarial examples can effectively circumvent robust adversarial training methods tailored for traditional adversarial attacks.
&lt;/p&gt;</description></item></channel></rss>