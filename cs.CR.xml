<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;LLM&#31995;&#32479;&#30340;&#25191;&#34892;&#38548;&#31163;&#26550;&#26500;SecGPT&#65292;&#26088;&#22312;&#35299;&#20915;&#31532;&#19977;&#26041;&#24212;&#29992;&#31243;&#24207;&#25191;&#34892;&#25152;&#24341;&#21457;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.04960</link><description>&lt;p&gt;
SecGPT&#65306;&#19968;&#31181;&#38754;&#21521;&#22522;&#20110;LLM&#31995;&#32479;&#30340;&#25191;&#34892;&#38548;&#31163;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
SecGPT: An Execution Isolation Architecture for LLM-Based Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04960
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;LLM&#31995;&#32479;&#30340;&#25191;&#34892;&#38548;&#31163;&#26550;&#26500;SecGPT&#65292;&#26088;&#22312;&#35299;&#20915;&#31532;&#19977;&#26041;&#24212;&#29992;&#31243;&#24207;&#25191;&#34892;&#25152;&#24341;&#21457;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34987;&#25193;&#23637;&#20026;&#31995;&#32479;&#65292;&#22914;ChatGPT&#65292;&#24050;&#32463;&#24320;&#22987;&#25903;&#25345;&#31532;&#19977;&#26041;&#24212;&#29992;&#31243;&#24207;&#12290;&#36825;&#20123;LLM&#24212;&#29992;&#31243;&#24207;&#21033;&#29992;LLMs&#30340;&#20107;&#23454;&#19978;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#33258;&#21160;&#25191;&#34892;&#33539;&#24335;&#65306;&#21363;&#65292;&#24212;&#29992;&#31243;&#24207;&#21450;&#20854;&#20132;&#20114;&#26159;&#29992;&#33258;&#28982;&#35821;&#35328;&#23450;&#20041;&#30340;&#65292;&#25552;&#20379;&#23545;&#29992;&#25143;&#25968;&#25454;&#30340;&#35775;&#38382;&#65292;&#24182;&#34987;&#20801;&#35768;&#33258;&#30001;&#22320;&#30456;&#20114;&#20132;&#20114;&#20197;&#21450;&#19982;&#31995;&#32479;&#20114;&#21160;&#12290;&#36825;&#20123;LLM&#24212;&#29992;&#31243;&#24207;&#29983;&#24577;&#31995;&#32479;&#31867;&#20284;&#20110;&#26089;&#26399;&#35745;&#31639;&#24179;&#21488;&#30340;&#35774;&#32622;&#65292;&#22312;&#37027;&#37324;&#24212;&#29992;&#31243;&#24207;&#21644;&#31995;&#32479;&#20043;&#38388;&#32570;&#20047;&#36275;&#22815;&#30340;&#38548;&#31163;&#12290;&#30001;&#20110;&#31532;&#19977;&#26041;&#24212;&#29992;&#31243;&#24207;&#21487;&#33021;&#19981;&#21487;&#20449;&#65292;&#24182;&#19988;&#21463;&#33258;&#28982;&#35821;&#35328;&#30028;&#38754;&#30340;&#19981;&#31934;&#30830;&#24615;&#21152;&#21095;&#65292;&#24403;&#21069;&#30340;&#35774;&#35745;&#20250;&#20026;&#29992;&#25143;&#24102;&#26469;&#23433;&#20840;&#21644;&#38544;&#31169;&#39118;&#38505;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SecGPT&#65292;&#19968;&#31181;&#38754;&#21521;LLM&#31995;&#32479;&#30340;&#26550;&#26500;&#65292;&#26088;&#22312;&#32531;&#35299;&#30001;&#31532;&#19977;&#26041;&#24212;&#29992;&#31243;&#24207;&#25191;&#34892;&#24341;&#36215;&#30340;&#23433;&#20840;&#24615;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;SecGPT&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#38548;&#31163;&#24212;&#29992;&#31243;&#24207;&#30340;&#25191;&#34892;&#21644;&#26356;&#22810;&#30340;&#39044;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04960v1 Announce Type: cross  Abstract: Large language models (LLMs) extended as systems, such as ChatGPT, have begun supporting third-party applications. These LLM apps leverage the de facto natural language-based automated execution paradigm of LLMs: that is, apps and their interactions are defined in natural language, provided access to user data, and allowed to freely interact with each other and the system. These LLM app ecosystems resemble the settings of earlier computing platforms, where there was insufficient isolation between apps and the system. Because third-party apps may not be trustworthy, and exacerbated by the imprecision of the natural language interfaces, the current designs pose security and privacy risks for users. In this paper, we propose SecGPT, an architecture for LLM-based systems that aims to mitigate the security and privacy issues that arise with the execution of third-party apps. SecGPT's key idea is to isolate the execution of apps and more pre
&lt;/p&gt;</description></item><item><title>&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25972;&#21512;&#21040;&#25968;&#23383;&#21462;&#35777;&#35843;&#26597;&#20013;&#26377;&#26395;&#25552;&#21319;&#35843;&#26597;&#25928;&#29575;&#65292;&#25913;&#21892;&#21487;&#36861;&#28335;&#24615;&#65292;&#24182;&#32531;&#35299;&#25191;&#27861;&#26426;&#26500;&#38754;&#20020;&#30340;&#25216;&#26415;&#21644;&#21496;&#27861;&#38556;&#30861;&#12290;</title><link>https://arxiv.org/abs/2402.19366</link><description>&lt;p&gt;
SoK: &#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#39640;&#25968;&#23383;&#21462;&#35777;&#35843;&#26597;&#25928;&#29575;&#26041;&#38754;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19366
&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25972;&#21512;&#21040;&#25968;&#23383;&#21462;&#35777;&#35843;&#26597;&#20013;&#26377;&#26395;&#25552;&#21319;&#35843;&#26597;&#25928;&#29575;&#65292;&#25913;&#21892;&#21487;&#36861;&#28335;&#24615;&#65292;&#24182;&#32531;&#35299;&#25191;&#27861;&#26426;&#26500;&#38754;&#20020;&#30340;&#25216;&#26415;&#21644;&#21496;&#27861;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#38656;&#35201;&#25968;&#23383;&#21462;&#35777;&#20998;&#26512;&#30340;&#26696;&#20214;&#25968;&#37327;&#22686;&#38271;&#65292;&#23545;&#25191;&#27861;&#26426;&#26500;&#21450;&#26102;&#36827;&#34892;&#35843;&#26597;&#30340;&#33021;&#21147;&#20135;&#29983;&#20102;&#25285;&#24551;&#12290;&#22240;&#27492;&#65292;&#36825;&#31687;&#31995;&#32479;&#21270;&#30693;&#35782;&#35770;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25972;&#21512;&#21040;&#25968;&#23383;&#21462;&#35777;&#35843;&#26597;&#20013;&#20197;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#30340;&#28508;&#21147;&#21644;&#26377;&#25928;&#24615;&#12290;&#23545;&#29616;&#26377;&#30340;&#25968;&#23383;&#21462;&#35777;&#27169;&#22411;&#12289;&#24037;&#20855;&#12289;LLMs&#12289;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#20197;&#21450;&#22312;&#35843;&#26597;&#20013;&#21033;&#29992;LLMs&#30340;&#20840;&#38754;&#25991;&#29486;&#32508;&#36848;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#32508;&#36848;&#30830;&#23450;&#20102;&#29616;&#26377;&#25968;&#23383;&#21462;&#35777;&#27969;&#31243;&#20013;&#30340;&#25361;&#25112;&#65292;&#24182;&#25506;&#35752;&#20102;&#25972;&#21512;LLMs&#30340;&#38556;&#30861;&#21644;&#21487;&#33021;&#24615;&#12290;&#26368;&#32456;&#65292;&#30740;&#31350;&#26029;&#35328;&#65292;&#22312;&#36866;&#24403;&#30340;&#32422;&#26463;&#26465;&#20214;&#19979;&#65292;&#25968;&#23383;&#21462;&#35777;&#20013;&#37319;&#29992;LLMs&#26377;&#26395;&#25552;&#21319;&#35843;&#26597;&#25928;&#29575;&#65292;&#25913;&#21892;&#21487;&#36861;&#28335;&#24615;&#65292;&#24182;&#32531;&#35299;&#25191;&#27861;&#26426;&#26500;&#38754;&#20020;&#30340;&#25216;&#26415;&#21644;&#21496;&#27861;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19366v1 Announce Type: cross  Abstract: The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement e
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;DP-ZO&#65292;&#19968;&#31181;&#36890;&#36807;&#31169;&#26377;&#21270;&#38646;&#38454;&#20248;&#21270;&#26469;&#20445;&#25252;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#25968;&#25454;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.04343</link><description>&lt;p&gt;
&#31169;&#26377;&#38646;&#38454;&#20248;&#21270;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31169;&#26377;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Private Fine-tuning of Large Language Models with Zeroth-order Optimization. (arXiv:2401.04343v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04343
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;DP-ZO&#65292;&#19968;&#31181;&#36890;&#36807;&#31169;&#26377;&#21270;&#38646;&#38454;&#20248;&#21270;&#26469;&#20445;&#25252;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#25968;&#25454;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31169;&#26377;&#25968;&#25454;&#38598;&#19978;&#23545;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#21487;&#33021;&#20250;&#23384;&#22312;&#36829;&#21453;&#38544;&#31169;&#30340;&#39118;&#38505;&#12290;&#24046;&#20998;&#38544;&#31169;&#26159;&#19968;&#31181;&#36890;&#36807;&#24378;&#21046;&#31639;&#27861;&#31283;&#23450;&#24615;&#26469;&#20943;&#36731;&#38544;&#31169;&#39118;&#38505;&#30340;&#26694;&#26550;&#12290;DP-SGD&#21487;&#20197;&#20197;&#20445;&#25252;&#38544;&#31169;&#30340;&#26041;&#24335;&#35757;&#32451;&#20855;&#26377;&#31169;&#26377;&#25968;&#25454;&#30340;&#27169;&#22411;&#65292;&#20294;&#20250;&#24102;&#26469;&#24615;&#33021;&#25439;&#22833;&#21644;&#37325;&#22823;&#24037;&#31243;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;DP-ZO&#65292;&#19968;&#31181;&#36890;&#36807;&#31169;&#26377;&#21270;&#38646;&#38454;&#20248;&#21270;&#26469;&#20445;&#25252;&#35757;&#32451;&#25968;&#25454;&#38544;&#31169;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35774;&#35745;&#30340;&#19968;&#20010;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#25105;&#20204;&#20351;&#29992;&#30340;&#38646;&#38454;&#31639;&#27861;SPSA&#20013;&#30340;&#26799;&#24230;&#26041;&#21521;&#22987;&#32456;&#26159;&#38543;&#26426;&#30340;&#65292;&#32780;&#20165;&#20381;&#36182;&#20110;&#31169;&#26377;&#25968;&#25454;&#30340;&#20449;&#24687;&#26159;&#27493;&#38271;&#65292;&#21363;&#19968;&#20010;&#26631;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21482;&#38656;&#35201;&#23545;&#26631;&#37327;&#27493;&#38271;&#36827;&#34892;&#38544;&#31169;&#22788;&#29702;&#65292;&#36825;&#26159;&#23384;&#20648;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#12290;DP-ZO&#21487;&#20197;&#20351;&#29992;&#25289;&#26222;&#25289;&#26031;&#22122;&#22768;&#25110;&#39640;&#26031;&#22122;&#22768;&#26469;&#23454;&#29616;&#65292;&#22312;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#25552;&#20379;&#20102;&#38544;&#31169;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#24378;&#22823;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning large pretrained models on private datasets may run the risk of violating privacy. Differential privacy is a framework for mitigating privacy risks by enforcing algorithmic stability. DP-SGD enables training models with private data in a privacy-preserving manner, but raises new obstacles in the form of performance loss and significant engineering challenges. We introduce DP-ZO, a new method for fine-tuning large language models that preserves the privacy of training data by privatizing zeroth-order optimization. A key insight into the design of our method is that the direction of the gradient in SPSA, the zeroth-order algorithm we use, is always random and the only information that depends on private data is the step size, i.e., a scalar. Therefore, we only need to privatize the scalar step size, which is memory-efficient. DP-ZO, which can be instantiated with either Laplace or Gaussian noise, provides a strong privacy-utility trade-off across different tasks, and model si
&lt;/p&gt;</description></item></channel></rss>