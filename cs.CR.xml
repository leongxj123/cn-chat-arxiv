<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>MeanCache&#26159;&#19968;&#31181;&#38754;&#21521;LLMs&#30340;&#35821;&#20041;&#32531;&#23384;&#65292;&#33021;&#22815;&#35782;&#21035;&#35821;&#20041;&#19978;&#30456;&#20284;&#30340;&#26597;&#35810;&#65292;&#20174;&#32780;&#20943;&#23569;&#26597;&#35810;&#25104;&#26412;&#65292;&#26381;&#21153;&#25552;&#20379;&#21830;&#36127;&#36733;&#21644;&#29615;&#22659;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.02694</link><description>&lt;p&gt;
&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38544;&#31169;&#24863;&#30693;&#35821;&#20041;&#32531;&#23384;
&lt;/p&gt;
&lt;p&gt;
Privacy-Aware Semantic Cache for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02694
&lt;/p&gt;
&lt;p&gt;
MeanCache&#26159;&#19968;&#31181;&#38754;&#21521;LLMs&#30340;&#35821;&#20041;&#32531;&#23384;&#65292;&#33021;&#22815;&#35782;&#21035;&#35821;&#20041;&#19978;&#30456;&#20284;&#30340;&#26597;&#35810;&#65292;&#20174;&#32780;&#20943;&#23569;&#26597;&#35810;&#25104;&#26412;&#65292;&#26381;&#21153;&#25552;&#20379;&#21830;&#36127;&#36733;&#21644;&#29615;&#22659;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;ChatGPT&#12289;Google Bard&#12289;Claude&#21644;Llama 2&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#25628;&#32034;&#24341;&#25806;&#21160;&#24577;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#36896;&#25104;&#20102;&#24322;&#24120;&#39640;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;MeanCache&#65292;&#19968;&#31181;&#29992;&#20110;LLMs&#30340;&#35821;&#20041;&#32531;&#23384;&#65292;&#23427;&#33021;&#22815;&#35782;&#21035;&#35821;&#20041;&#19978;&#30456;&#20284;&#30340;&#26597;&#35810;&#20197;&#30830;&#23450;&#32531;&#23384;&#21629;&#20013;&#25110;&#26410;&#21629;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02694v1 Announce Type: cross  Abstract: Large Language Models (LLMs) like ChatGPT, Google Bard, Claude, and Llama 2 have revolutionized natural language processing and search engine dynamics. However, these models incur exceptionally high computational costs. For instance, GPT-3 consists of 175 billion parameters and inference on these models also demands billions of floating-point operations. Caching is a natural solution to reduce LLM inference costs on repeated queries. However, existing caching methods are incapable of finding semantic similarities among LLM queries, leading to unacceptable false hit-and-miss rates.   This paper introduces MeanCache, a semantic cache for LLMs that identifies semantically similar queries to determine cache hit or miss. Using MeanCache, the response to a user's semantically similar query can be retrieved from a local cache rather than re-querying the LLM, thus reducing costs, service provider load, and environmental impact. MeanCache lever
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#21518;&#38376;&#25915;&#20987;&#30340;&#36890;&#29992;&#21518;&#35757;&#32451;&#21453;&#21521;&#24037;&#31243;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#20381;&#36182;&#20869;&#37096;&#29305;&#24449;&#22270;&#26469;&#26816;&#27979;&#21644;&#21453;&#21521;&#24037;&#31243;&#21518;&#38376;&#65292;&#24182;&#35782;&#21035;&#20854;&#30446;&#26631;&#31867;&#21035;&#65292;&#20855;&#26377;&#24191;&#27867;&#36866;&#29992;&#24615;&#21644;&#20302;&#35745;&#31639;&#24320;&#38144;&#12290;</title><link>https://arxiv.org/abs/2402.02034</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#38024;&#23545;&#21518;&#38376;&#25915;&#20987;&#30340;&#36890;&#29992;&#21518;&#35757;&#32451;&#21453;&#21521;&#24037;&#31243;&#38450;&#24481;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#21518;&#38376;&#25915;&#20987;&#30340;&#36890;&#29992;&#21518;&#35757;&#32451;&#21453;&#21521;&#24037;&#31243;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#20381;&#36182;&#20869;&#37096;&#29305;&#24449;&#22270;&#26469;&#26816;&#27979;&#21644;&#21453;&#21521;&#24037;&#31243;&#21518;&#38376;&#65292;&#24182;&#35782;&#21035;&#20854;&#30446;&#26631;&#31867;&#21035;&#65292;&#20855;&#26377;&#24191;&#27867;&#36866;&#29992;&#24615;&#21644;&#20302;&#35745;&#31639;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#21518;&#38376;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;&#21508;&#31181;&#38450;&#24481;&#26041;&#27861;&#12290;&#36890;&#29992;&#26041;&#27861;&#26088;&#22312;&#21487;&#38752;&#22320;&#26816;&#27979;&#21644;/&#25110;&#20943;&#36731;&#21518;&#38376;&#25915;&#20987;&#65292;&#32780;&#21453;&#21521;&#24037;&#31243;&#26041;&#27861;&#36890;&#24120;&#26126;&#30830;&#20551;&#35774;&#20854;&#20013;&#19968;&#31181;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26816;&#27979;&#22120;&#65292;&#23427;&#20381;&#36182;&#20110;&#34987;&#38450;&#23432;&#30340;DNN&#30340;&#20869;&#37096;&#29305;&#24449;&#22270;&#26469;&#26816;&#27979;&#21644;&#21453;&#21521;&#24037;&#31243;&#21518;&#38376;&#65292;&#24182;&#35782;&#21035;&#20854;&#30446;&#26631;&#31867;&#21035;&#65307;&#23427;&#21487;&#20197;&#22312;&#21518;&#35757;&#32451;&#26102;&#25805;&#20316;&#65288;&#26080;&#38656;&#35775;&#38382;&#35757;&#32451;&#25968;&#25454;&#38598;&#65289;&#65307;&#23545;&#20110;&#19981;&#21516;&#30340;&#23884;&#20837;&#26426;&#21046;&#65288;&#21363;&#36890;&#29992;&#30340;&#65289;&#38750;&#24120;&#26377;&#25928;&#65307;&#24182;&#19988;&#20855;&#26377;&#20302;&#35745;&#31639;&#24320;&#38144;&#65292;&#22240;&#27492;&#21487;&#25193;&#23637;&#12290;&#25105;&#20204;&#23545;&#22522;&#20934;CIFAR-10&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#19981;&#21516;&#25915;&#20987;&#36827;&#34892;&#20102;&#26816;&#27979;&#26041;&#27861;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
A variety of defenses have been proposed against backdoors attacks on deep neural network (DNN) classifiers. Universal methods seek to reliably detect and/or mitigate backdoors irrespective of the incorporation mechanism used by the attacker, while reverse-engineering methods often explicitly assume one. In this paper, we describe a new detector that: relies on internal feature map of the defended DNN to detect and reverse-engineer the backdoor and identify its target class; can operate post-training (without access to the training dataset); is highly effective for various incorporation mechanisms (i.e., is universal); and which has low computational overhead and so is scalable. Our detection approach is evaluated for different attacks on a benchmark CIFAR-10 image classifier.
&lt;/p&gt;</description></item></channel></rss>