<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20351;&#29992;&#21512;&#25104;&#25351;&#21335;&#26367;&#25442;&#30495;&#23454;&#25351;&#21335;&#20197;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#65292;&#24182;&#36890;&#36807;&#31169;&#23494;&#24494;&#35843;&#29983;&#25104;&#22120;&#29983;&#25104;&#27492;&#31867;&#21512;&#25104;&#25351;&#21335;&#65292;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#36807;&#28388;&#31639;&#27861;&#20351;&#21512;&#25104;&#25351;&#21335;&#30340;&#20998;&#24067;&#19982;&#30495;&#23454;&#25351;&#21335;&#19968;&#33268;&#65292;&#23637;&#31034;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#20013;&#30340;&#39640;&#25928;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13659</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#30340;&#38544;&#31169;&#20445;&#25252;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Instructions for Aligning Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13659
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20351;&#29992;&#21512;&#25104;&#25351;&#21335;&#26367;&#25442;&#30495;&#23454;&#25351;&#21335;&#20197;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#65292;&#24182;&#36890;&#36807;&#31169;&#23494;&#24494;&#35843;&#29983;&#25104;&#22120;&#29983;&#25104;&#27492;&#31867;&#21512;&#25104;&#25351;&#21335;&#65292;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#36807;&#28388;&#31639;&#27861;&#20351;&#21512;&#25104;&#25351;&#21335;&#30340;&#20998;&#24067;&#19982;&#30495;&#23454;&#25351;&#21335;&#19968;&#33268;&#65292;&#23637;&#31034;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#20013;&#30340;&#39640;&#25928;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#30340;&#26381;&#21153;&#25552;&#20379;&#21830;&#22312;&#37326;&#22806;&#25910;&#38598;&#29992;&#25143;&#25351;&#21335;&#65292;&#24182;&#22312;&#36827;&#19968;&#27493;&#23545;&#40784;LLM&#19982;&#29992;&#25143;&#24847;&#22270;&#20013;&#20351;&#29992;&#36825;&#20123;&#25351;&#21335;&#12290;&#36825;&#20123;&#28508;&#22312;&#21253;&#21547;&#25935;&#24863;&#20449;&#24687;&#30340;&#25351;&#21335;&#22312;&#27969;&#31243;&#20013;&#30001;&#20154;&#24037;&#24037;&#20316;&#32773;&#26631;&#27880;&#12290;&#36825;&#24102;&#26469;&#20102;&#26032;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#32780;Typical Private Optimization&#27809;&#26377;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#35758;&#20351;&#29992;&#21512;&#25104;&#25351;&#21335;&#26367;&#25442;&#25968;&#25454;&#26631;&#27880;&#21644;&#27169;&#22411;&#24494;&#35843;&#20013;&#30340;&#30495;&#23454;&#25351;&#21335;&#12290;&#36890;&#36807;&#20351;&#29992;&#31169;&#23494;&#24494;&#35843;&#29983;&#25104;&#22120;&#29983;&#25104;&#36825;&#20123;&#21512;&#25104;&#25351;&#21335;&#65292;&#21487;&#20197;&#30830;&#20445;&#24418;&#24335;&#24046;&#24322;&#38544;&#31169;&#12290;&#22312;&#23454;&#29616;&#25152;&#38656;&#25928;&#29992;&#26041;&#38754;&#33267;&#20851;&#37325;&#35201;&#30340;&#26159;&#25105;&#20204;&#30340;&#26032;&#39062;&#36807;&#28388;&#31639;&#27861;&#65292;&#23558;&#21512;&#25104;&#25351;&#21335;&#30340;&#20998;&#24067;&#19982;&#23454;&#38469;&#25351;&#21335;&#30340;&#20998;&#24067;&#36827;&#34892;&#21305;&#37197;&#12290;&#22312;&#26377;&#20154;&#21453;&#39304;&#30340;&#21463;&#30417;&#30563;&#24494;&#35843;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#36890;&#36807;&#23637;&#31034;&#21512;&#25104;&#25351;&#21335;&#30340;&#26368;&#32456;&#38598;&#21512;&#30340;&#39640;&#25928;&#29992;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13659v1 Announce Type: cross  Abstract: Service providers of large language model (LLM) applications collect user instructions in the wild and use them in further aligning LLMs with users' intentions. These instructions, which potentially contain sensitive information, are annotated by human workers in the process. This poses a new privacy risk not addressed by the typical private optimization. To this end, we propose using synthetic instructions to replace real instructions in data annotation and model fine-tuning. Formal differential privacy is guaranteed by generating those synthetic instructions using privately fine-tuned generators. Crucial in achieving the desired utility is our novel filtering algorithm that matches the distribution of the synthetic instructions to that of the real ones. In both supervised fine-tuning and reinforcement learning from human feedback, our extensive experiments demonstrate the high utility of the final set of synthetic instructions by sho
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#25968;&#25454;&#19982;&#27169;&#22411;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25552;&#20986;&#36890;&#36807;&#25552;&#21462;&#19981;&#21516;&#29305;&#24449;&#26469;&#39044;&#27979;Transformer&#25991;&#26412;&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.11469</link><description>&lt;p&gt;
&#22312;&#25628;&#32034;&#35757;&#32451;&#25968;&#25454;&#19982;Transformer&#25991;&#26412;&#27169;&#22411;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26102;&#30340;&#19968;&#20010;&#26377;&#36259;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#25968;&#25454;&#19982;&#27169;&#22411;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25552;&#20986;&#36890;&#36807;&#25552;&#21462;&#19981;&#21516;&#29305;&#24449;&#26469;&#39044;&#27979;Transformer&#25991;&#26412;&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#32463;&#36807;&#24494;&#35843;&#30340;&#25991;&#26412;Transformer&#27169;&#22411;&#21487;&#20197;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#20063;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25991;&#26412;&#25200;&#21160;&#30340;&#24433;&#21709;&#12290;&#20256;&#32479;&#30340;&#23545;&#25239;&#24615;&#35780;&#20272;&#36890;&#24120;&#22312;&#23545;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#20043;&#21518;&#25165;&#36827;&#34892;&#65292;&#24573;&#30053;&#20102;&#35757;&#32451;&#25968;&#25454;&#12290;&#26412;&#25991;&#26088;&#22312;&#35777;&#26126;&#35757;&#32451;&#25968;&#25454;&#21644;&#27169;&#22411;&#40065;&#26834;&#24615;&#20043;&#38388;&#20063;&#23384;&#22312;&#30528;&#24378;&#20851;&#32852;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#21462;&#20102;&#20195;&#34920;&#24191;&#27867;&#36755;&#20837;&#24494;&#35843;&#35821;&#26009;&#24211;&#23646;&#24615;&#30340;13&#31181;&#19981;&#21516;&#29305;&#24449;&#65292;&#24182;&#29992;&#23427;&#20204;&#26469;&#39044;&#27979;&#32463;&#36807;&#24494;&#35843;&#30340;&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#20165;&#32534;&#30721;&#22120;&#30340;Transformer&#27169;&#22411;BERT&#21644;RoBERTa&#65292;&#24182;&#38468;&#21152;&#20102;BART&#12289;ELECTRA&#21644;GPT2&#30340;&#20854;&#20182;&#32467;&#26524;&#65292;&#20026;&#25105;&#20204;&#30340;&#35770;&#28857;&#25552;&#20379;&#22810;&#26679;&#30340;&#35777;&#25454;&#12290;&#39318;&#20808;&#65292;&#32463;&#39564;&#35777;&#26126;&#65292;(a)&#25552;&#21462;&#30340;&#29305;&#24449;&#21487;&#19982;&#36731;&#37327;&#32423;&#20998;&#31867;&#22120;&#65288;&#22914;&#38543;&#26426;&#26862;&#26519;&#65289;&#19968;&#36215;&#26377;&#25928;&#22320;&#39044;&#27979;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11469v1 Announce Type: cross  Abstract: Existing works have shown that fine-tuned textual transformer models achieve state-of-the-art prediction performances but are also vulnerable to adversarial text perturbations. Traditional adversarial evaluation is often done \textit{only after} fine-tuning the models and ignoring the training data. In this paper, we want to prove that there is also a strong correlation between training data and model robustness. To this end, we extract 13 different features representing a wide range of input fine-tuning corpora properties and use them to predict the adversarial robustness of the fine-tuned models. Focusing mostly on encoder-only transformer models BERT and RoBERTa with additional results for BART, ELECTRA and GPT2, we provide diverse evidence to support our argument. First, empirical analyses show that (a) extracted features can be used with a lightweight classifier such as Random Forest to effectively predict the attack success rate 
&lt;/p&gt;</description></item><item><title>&#31532;&#20108;&#23626;&#33258;&#36866;&#24212;&#32593;&#32476;&#38450;&#24481;&#22269;&#38469;&#30740;&#35752;&#20250;&#30340;&#30446;&#26631;&#26159;&#25506;&#32034;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#21644;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#33258;&#36866;&#24212;&#32593;&#32476;&#38450;&#24481;&#22522;&#30784;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;&#22635;&#34917;AI&#21644;&#32593;&#32476;&#30740;&#31350;&#20154;&#21592;&#20043;&#38388;&#30340;&#24046;&#36317;&#26469;&#21152;&#36895;&#24320;&#21457;&#21322;&#33258;&#20027;&#32593;&#32476;&#38450;&#24481;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2308.09520</link><description>&lt;p&gt;
&#31532;&#20108;&#23626;&#33258;&#36866;&#24212;&#32593;&#32476;&#38450;&#24481;&#22269;&#38469;&#30740;&#35752;&#20250;&#35770;&#25991;&#38598;
&lt;/p&gt;
&lt;p&gt;
Proceedings of the 2nd International Workshop on Adaptive Cyber Defense. (arXiv:2308.09520v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09520
&lt;/p&gt;
&lt;p&gt;
&#31532;&#20108;&#23626;&#33258;&#36866;&#24212;&#32593;&#32476;&#38450;&#24481;&#22269;&#38469;&#30740;&#35752;&#20250;&#30340;&#30446;&#26631;&#26159;&#25506;&#32034;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#21644;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#33258;&#36866;&#24212;&#32593;&#32476;&#38450;&#24481;&#22522;&#30784;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;&#22635;&#34917;AI&#21644;&#32593;&#32476;&#30740;&#31350;&#20154;&#21592;&#20043;&#38388;&#30340;&#24046;&#36317;&#26469;&#21152;&#36895;&#24320;&#21457;&#21322;&#33258;&#20027;&#32593;&#32476;&#38450;&#24481;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31532;&#20108;&#23626;&#33258;&#36866;&#24212;&#32593;&#32476;&#38450;&#24481;&#22269;&#38469;&#30740;&#35752;&#20250;&#22312;&#20315;&#32599;&#37324;&#36798;&#29702;&#24037;&#23398;&#38498;&#20030;&#34892;&#65292;&#35813;&#30740;&#35752;&#20250;&#26088;&#22312;&#20998;&#20139;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20316;&#20026;&#33258;&#36866;&#24212;&#32593;&#32476;&#38450;&#24481;&#22522;&#30784;&#33021;&#21147;&#30340;&#30740;&#31350;&#12290;&#24403;&#21069;&#30340;&#32593;&#32476;&#39046;&#22495;&#26080;&#27861;&#21487;&#38752;&#26377;&#25928;&#22320;&#36827;&#34892;&#38450;&#24481;&#65292;&#24517;&#39035;&#24191;&#27867;&#20381;&#36182;&#20154;&#24037;&#19987;&#23478;&#12290;&#29087;&#32451;&#30340;&#32593;&#32476;&#38450;&#24481;&#20154;&#21592;&#20379;&#24212;&#19981;&#36275;&#65292;&#24448;&#24448;&#26080;&#27861;&#21450;&#26102;&#24212;&#23545;&#32593;&#32476;&#23041;&#32961;&#12290;&#20511;&#37492;AI&#21644;ML&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#32593;&#32476;&#38450;&#24481;&#30740;&#31350;&#31038;&#21306;&#34987;&#28608;&#21169;&#30528;&#36890;&#36807;&#23558;AI&#21644;ML&#25216;&#26415;&#24212;&#29992;&#20110;&#32593;&#32476;&#29615;&#22659;&#20013;&#65292;&#24320;&#21457;&#26032;&#30340;&#21160;&#24577;&#21487;&#25345;&#32493;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;&#22635;&#34917;AI&#21644;&#32593;&#32476;&#30740;&#31350;&#20154;&#21592;&#19982;&#23454;&#36341;&#32773;&#20043;&#38388;&#30340;&#20851;&#38190;&#24046;&#36317;&#21487;&#20197;&#21152;&#36895;&#21019;&#24314;&#33021;&#22815;&#23398;&#20064;&#35782;&#21035;&#21644;&#24212;&#23545;&#32593;&#32476;&#25915;&#20987;&#65292;&#25110;&#32773;&#21457;&#29616;&#21644;&#20943;&#36731;&#24369;&#28857;&#30340;&#21322;&#33258;&#20027;&#32593;&#32476;&#38450;&#24481;&#31995;&#32479;&#30340;&#21162;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The 2nd International Workshop on Adaptive Cyber Defense was held at the Florida Institute of Technology, Florida. This workshop was organized to share research that explores unique applications of Artificial Intelligence (AI) and Machine Learning (ML) as foundational capabilities for the pursuit of adaptive cyber defense. The cyber domain cannot currently be reliably and effectively defended without extensive reliance on human experts. Skilled cyber defenders are in short supply and often cannot respond fast enough to cyber threats.  Building on recent advances in AI and ML the Cyber defense research community has been motivated to develop new dynamic and sustainable defenses through the adoption of AI and ML techniques to cyber settings. Bridging critical gaps between AI and Cyber researchers and practitioners can accelerate efforts to create semi-autonomous cyber defenses that can learn to recognize and respond to cyber attacks or discover and mitigate weaknesses in cooperation with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#35299;&#20915;&#22312;&#20445;&#25252;&#38544;&#31169;&#21644;&#28385;&#36275;&#20869;&#23384;&#21644;&#25512;&#29702;&#26102;&#38388;&#35201;&#27714;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#39044;&#35757;&#32451;&#19968;&#20010;&#22266;&#23450;&#22823;&#23567;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#31169;&#26377;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#20197;&#26368;&#22823;&#21270;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#26694;&#26550;&#30340;&#20851;&#38190;&#26159;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#30340;&#23376;&#38598;&#19978;&#36827;&#34892;&#26377;&#36873;&#25321;&#24615;&#30340;&#39044;&#35757;&#32451;&#65292;&#20351;&#20844;&#20849;&#20998;&#24067;&#38752;&#36817;&#31169;&#26377;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.13865</link><description>&lt;p&gt;
&#38024;&#23545;&#31169;&#26377;&#24494;&#35843;&#30340;&#26377;&#36873;&#25321;&#24615;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Selective Pre-training for Private Fine-tuning. (arXiv:2305.13865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#35299;&#20915;&#22312;&#20445;&#25252;&#38544;&#31169;&#21644;&#28385;&#36275;&#20869;&#23384;&#21644;&#25512;&#29702;&#26102;&#38388;&#35201;&#27714;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#39044;&#35757;&#32451;&#19968;&#20010;&#22266;&#23450;&#22823;&#23567;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#31169;&#26377;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#20197;&#26368;&#22823;&#21270;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#26694;&#26550;&#30340;&#20851;&#38190;&#26159;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#30340;&#23376;&#38598;&#19978;&#36827;&#34892;&#26377;&#36873;&#25321;&#24615;&#30340;&#39044;&#35757;&#32451;&#65292;&#20351;&#20844;&#20849;&#20998;&#24067;&#38752;&#36817;&#31169;&#26377;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20551;&#35774;&#25105;&#20204;&#24819;&#22312;&#30005;&#23376;&#37038;&#20214;&#23458;&#25143;&#31471;&#25110;&#25991;&#23383;&#22788;&#29702;&#22120;&#20013;&#35757;&#32451;&#25991;&#26412;&#39044;&#27979;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#24517;&#39035;&#20445;&#25252;&#29992;&#25143;&#25968;&#25454;&#30340;&#38544;&#31169;&#65292;&#24182;&#36981;&#23432;&#29305;&#23450;&#30340;&#22266;&#23450;&#22823;&#23567;&#65292;&#20197;&#28385;&#36275;&#20869;&#23384;&#21644;&#25512;&#29702;&#26102;&#38388;&#35201;&#27714;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26377;&#19968;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;D_pub&#21644;&#19968;&#20010;&#23545;&#24212;&#20110;&#19979;&#28216;&#20219;&#21153;T&#30340;&#31169;&#26377;&#25968;&#25454;&#38598;D_priv&#12290;&#25105;&#20204;&#22914;&#20309;&#22312;D_pub&#19978;&#39044;&#35757;&#32451;&#19968;&#20010;&#22266;&#23450;&#22823;&#23567;&#30340;&#27169;&#22411;M&#65292;&#24182;&#22312;D_priv&#19978;&#24494;&#35843;&#23427;&#65292;&#20351;&#24471;M&#30456;&#23545;&#20110;T&#30340;&#24615;&#33021;&#26368;&#22823;&#21270;&#65292;&#24182;&#19988;M&#30456;&#23545;&#20110;D_priv&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#25252;&#65311;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;D_pub&#30340;&#19968;&#20010;&#23376;&#38598;&#19978;&#39044;&#35757;&#32451;&#65292;&#23558;&#20844;&#20849;&#20998;&#24067;&#19982;&#31169;&#26377;&#20998;&#24067;&#38752;&#36817;&#65292;&#26159;&#26368;&#22823;&#21270;M&#39044;&#35757;&#32451;&#21518;&#30340;&#36801;&#31227;&#23398;&#20064;&#33021;&#21147;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#29305;&#21035;&#26159;&#22312;&#27169;&#22411;&#22823;&#23567;&#30456;&#23545;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#12290;&#38500;&#20102;&#24615;&#33021;&#25913;&#36827;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36824;&#25552;&#20379;&#20102;&#20445;&#25252;&#38544;&#31169;&#30340;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Suppose we want to train text prediction models in email clients or word processors. The models must preserve the privacy of user data and adhere to a specific fixed size to meet memory and inference time requirements. We introduce a generic framework to solve this problem. Specifically, we are given a public dataset $D_\text{pub}$ and a private dataset $D_\text{priv}$ corresponding to a downstream task $T$. How should we pre-train a fixed-size model $M$ on $D_\text{pub}$ and fine-tune it on $D_\text{priv}$ such that performance of $M$ with respect to $T$ is maximized and $M$ satisfies differential privacy with respect to $D_\text{priv}$? We show that pre-training on a {\em subset} of dataset $D_\text{pub}$ that brings the public distribution closer to the private distribution is a crucial ingredient to maximize the transfer learning abilities of $M$ after pre-training, especially in the regimes where model sizes are relatively small. Besides performance improvements, our framework als
&lt;/p&gt;</description></item></channel></rss>