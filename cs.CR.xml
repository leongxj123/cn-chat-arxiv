<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#30740;&#31350;&#26159;&#31532;&#19968;&#20010;&#20840;&#38754;&#35843;&#26597;&#27169;&#22411;&#35299;&#37322;&#20013;&#38544;&#31169;&#25915;&#20987;&#21450;&#20854;&#23545;&#25239;&#25514;&#26045;&#30340;&#35770;&#25991;&#65292;&#36890;&#36807;&#20998;&#31867;&#38544;&#31169;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;&#65292;&#21021;&#27493;&#25506;&#35752;&#20102;&#38544;&#31169;&#27844;&#28431;&#21407;&#22240;&#65292;&#25552;&#20986;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2404.00673</link><description>&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#22411;&#27169;&#22411;&#35299;&#37322;&#30740;&#31350;&#32508;&#36848;&#65306;&#38544;&#31169;&#39118;&#38505;&#12289;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;
&lt;/p&gt;
&lt;p&gt;
A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26159;&#31532;&#19968;&#20010;&#20840;&#38754;&#35843;&#26597;&#27169;&#22411;&#35299;&#37322;&#20013;&#38544;&#31169;&#25915;&#20987;&#21450;&#20854;&#23545;&#25239;&#25514;&#26045;&#30340;&#35770;&#25991;&#65292;&#36890;&#36807;&#20998;&#31867;&#38544;&#31169;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;&#65292;&#21021;&#27493;&#25506;&#35752;&#20102;&#38544;&#31169;&#27844;&#28431;&#21407;&#22240;&#65292;&#25552;&#20986;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#30340;&#37319;&#29992;&#19981;&#26029;&#25193;&#22823;&#65292;&#35299;&#20915;&#20854;&#38544;&#31169;&#24433;&#21709;&#30340;&#32039;&#36843;&#24615;&#21464;&#24471;&#26356;&#21152;&#36843;&#20999;&#12290;&#23613;&#31649;&#22312;&#20154;&#24037;&#26234;&#33021;&#38544;&#31169;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#26377;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#38544;&#31169;&#20445;&#25252;&#22411;&#27169;&#22411;&#35299;&#37322;&#21364;&#40092;&#26377;&#20851;&#27880;&#12290;&#26412;&#25991;&#39318;&#27425;&#20840;&#38754;&#35843;&#26597;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#38544;&#31169;&#25915;&#20987;&#21450;&#20854;&#23545;&#25239;&#25514;&#26045;&#12290;&#25105;&#20204;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#36129;&#29486;&#21253;&#25324;&#23545;&#30740;&#31350;&#35770;&#25991;&#36827;&#34892;&#24443;&#24213;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20114;&#36830;&#25509;&#30340;&#20998;&#31867;&#27861;&#65292;&#20415;&#20110;&#26681;&#25454;&#30446;&#26631;&#35299;&#37322;&#23545;&#38544;&#31169;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;&#36827;&#34892;&#20998;&#31867;&#12290;&#26412;&#30740;&#31350;&#36824;&#23545;&#38544;&#31169;&#27844;&#28431;&#21407;&#22240;&#36827;&#34892;&#20102;&#21021;&#27493;&#35843;&#26597;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25105;&#20204;&#20998;&#26512;&#20013;&#21457;&#29616;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;&#35813;&#35843;&#26597;&#26088;&#22312;&#25104;&#20026;&#30740;&#31350;&#30028;&#30340;&#23453;&#36149;&#36164;&#28304;&#65292;&#24182;&#20026;&#36825;&#19968;&#39046;&#22495;&#30340;&#26032;&#25163;&#25552;&#20379;&#26126;&#30830;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00673v1 Announce Type: cross  Abstract: As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorisation of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have estab
&lt;/p&gt;</description></item><item><title>&#26368;&#23567;&#26435;&#38480;&#23398;&#20064;&#23384;&#22312;&#19968;&#20010;&#22522;&#26412;&#30340;&#26435;&#34913;&#65292;&#21363;&#34920;&#31034;&#23545;&#20110;&#32473;&#23450;&#20219;&#21153;&#30340;&#23454;&#29992;&#24615;&#21644;&#20854;&#27844;&#28431;&#21040;&#20219;&#21153;&#22806;&#23646;&#24615;&#20043;&#38388;&#23384;&#22312;&#26080;&#27861;&#36991;&#20813;&#30340;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.12235</link><description>&lt;p&gt;
&#26368;&#23567;&#26435;&#38480;&#23398;&#20064;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
The Fundamental Limits of Least-Privilege Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12235
&lt;/p&gt;
&lt;p&gt;
&#26368;&#23567;&#26435;&#38480;&#23398;&#20064;&#23384;&#22312;&#19968;&#20010;&#22522;&#26412;&#30340;&#26435;&#34913;&#65292;&#21363;&#34920;&#31034;&#23545;&#20110;&#32473;&#23450;&#20219;&#21153;&#30340;&#23454;&#29992;&#24615;&#21644;&#20854;&#27844;&#28431;&#21040;&#20219;&#21153;&#22806;&#23646;&#24615;&#20043;&#38388;&#23384;&#22312;&#26080;&#27861;&#36991;&#20813;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#23569;&#26435;&#38480;&#23398;&#20064;&#30340;&#25215;&#35834;&#26159;&#25214;&#21040;&#23545;&#20110;&#23398;&#20064;&#20219;&#21153;&#26377;&#29992;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#20294;&#21516;&#26102;&#38450;&#27490;&#25512;&#26029;&#19982;&#35813;&#20219;&#21153;&#26080;&#20851;&#30340;&#20219;&#20309;&#25935;&#24863;&#20449;&#24687;&#65292;&#36825;&#19968;&#28857;&#38750;&#24120;&#21560;&#24341;&#20154;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#36825;&#20010;&#27010;&#24565;&#21482;&#26159;&#20197;&#38750;&#27491;&#24335;&#30340;&#26041;&#24335;&#38472;&#36848;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20173;&#28982;&#19981;&#28165;&#26970;&#25105;&#20204;&#26159;&#21542;&#20197;&#21450;&#22914;&#20309;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#20026;&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#23567;&#26435;&#38480;&#21407;&#21017;&#25552;&#20379;&#20102;&#24418;&#24335;&#21270;&#65292;&#24182;&#25551;&#36848;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#34920;&#31034;&#23545;&#20110;&#32473;&#23450;&#20219;&#21153;&#30340;&#23454;&#29992;&#24615;&#21644;&#20854;&#27844;&#28431;&#21040;&#39044;&#26399;&#20219;&#21153;&#20043;&#22806;&#30340;&#23646;&#24615;&#20043;&#38388;&#23384;&#22312;&#22522;&#26412;&#26435;&#34913;&#65306;&#19981;&#21487;&#33021;&#23398;&#20064;&#21040;&#23545;&#20110;&#39044;&#26399;&#20219;&#21153;&#20855;&#26377;&#39640;&#23454;&#29992;&#24615;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#21448;&#38450;&#27490;&#25512;&#26029;&#38500;&#20219;&#21153;&#26631;&#31614;&#26412;&#36523;&#20043;&#22806;&#30340;&#20219;&#20309;&#23646;&#24615;&#12290;&#36825;&#31181;&#26435;&#34913;&#26159;&#26080;&#35770;&#20351;&#29992;&#20309;&#31181;&#25216;&#26415;&#26469;&#23398;&#20064;&#20135;&#29983;&#36825;&#20123;&#34920;&#31034;&#30340;&#29305;&#24449;&#26144;&#23556;&#37117;&#26159;&#25104;&#31435;&#30340;&#12290;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12235v1 Announce Type: new  Abstract: The promise of least-privilege learning -- to find feature representations that are useful for a learning task but prevent inference of any sensitive information unrelated to this task -- is highly appealing. However, so far this concept has only been stated informally. It thus remains an open question whether and how we can achieve this goal. In this work, we provide the first formalisation of the least-privilege principle for machine learning and characterise its feasibility. We prove that there is a fundamental trade-off between a representation's utility for a given task and its leakage beyond the intended task: it is not possible to learn representations that have high utility for the intended task but, at the same time prevent inference of any attribute other than the task label itself. This trade-off holds regardless of the technique used to learn the feature mappings that produce these representations. We empirically validate thi
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#39318;&#27425;&#25581;&#31034;&#20102;&#25915;&#20987;&#32773;&#22312;&#22810;&#26234;&#33021;&#20307;&#31454;&#20105;&#29615;&#22659;&#20013;&#21363;&#20351;&#21463;&#38480;&#20110;&#21463;&#23475;&#32773;&#30340;&#37096;&#20998;&#35266;&#27979;&#20063;&#33021;&#29983;&#25104;&#23545;&#25239;&#31574;&#30053;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.03741</link><description>&lt;p&gt;
SUB-PLAY&#65306;&#38024;&#23545;&#37096;&#20998;&#35266;&#27979;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#30340;&#23545;&#25239;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03741
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#39318;&#27425;&#25581;&#31034;&#20102;&#25915;&#20987;&#32773;&#22312;&#22810;&#26234;&#33021;&#20307;&#31454;&#20105;&#29615;&#22659;&#20013;&#21363;&#20351;&#21463;&#38480;&#20110;&#21463;&#23475;&#32773;&#30340;&#37096;&#20998;&#35266;&#27979;&#20063;&#33021;&#29983;&#25104;&#23545;&#25239;&#31574;&#30053;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#39046;&#22495;&#21462;&#24471;&#30340;&#36827;&#23637;&#20026;&#26080;&#20154;&#26426;&#30340;&#32676;&#20307;&#25511;&#21046;&#12289;&#26426;&#26800;&#33218;&#30340;&#21327;&#20316;&#25805;&#32437;&#20197;&#21450;&#22810;&#30446;&#26631;&#21253;&#22260;&#31561;&#24320;&#36767;&#20102;&#24191;&#38420;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;&#28982;&#32780;&#65292;&#22312;MARL&#37096;&#32626;&#36807;&#31243;&#20013;&#23384;&#22312;&#28508;&#22312;&#30340;&#23433;&#20840;&#23041;&#32961;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#21644;&#28145;&#20837;&#35843;&#26597;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36805;&#36895;&#21033;&#29992;&#21463;&#23475;&#32773;&#30340;&#28431;&#27934;&#29983;&#25104;&#23545;&#25239;&#31574;&#30053;&#65292;&#23548;&#33268;&#21463;&#23475;&#32773;&#22312;&#29305;&#23450;&#20219;&#21153;&#20013;&#22833;&#36133;&#12290;&#20363;&#22914;&#65292;&#23558;&#36229;&#20154;&#32423;&#21035;&#30340;&#22260;&#26827;AI&#30340;&#33719;&#32988;&#29575;&#38477;&#20302;&#21040;&#32422;20%&#12290;&#36825;&#20123;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20004;&#20154;&#31454;&#20105;&#29615;&#22659;&#65292;&#24182;&#20551;&#35774;&#25915;&#20987;&#32773;&#20855;&#26377;&#23436;&#25972;&#30340;&#20840;&#23616;&#29366;&#24577;&#35266;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in multi-agent reinforcement learning (MARL) have opened up vast application prospects, including swarm control of drones, collaborative manipulation by robotic arms, and multi-target encirclement. However, potential security threats during the MARL deployment need more attention and thorough investigation. Recent researches reveal that an attacker can rapidly exploit the victim's vulnerabilities and generate adversarial policies, leading to the victim's failure in specific tasks. For example, reducing the winning rate of a superhuman-level Go AI to around 20%. They predominantly focus on two-player competitive environments, assuming attackers possess complete global state observation.   In this study, we unveil, for the first time, the capability of attackers to generate adversarial policies even when restricted to partial observations of the victims in multi-agent competitive environments. Specifically, we propose a novel black-box attack (SUB-PLAY), which incorporate
&lt;/p&gt;</description></item></channel></rss>