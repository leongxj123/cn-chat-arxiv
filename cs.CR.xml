<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#28183;&#36879;&#27979;&#35797;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#33258;&#21160;&#21270;&#30340;Linux&#29305;&#26435;&#21319;&#32423;&#22522;&#20934;&#21644;&#19968;&#20010;LLM-guided&#29305;&#26435;&#21319;&#32423;&#24037;&#20855;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;LLMs&#30340;&#19981;&#21516;&#25552;&#31034;&#35774;&#35745;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#39640;&#32423;&#25351;&#23548;&#23545;&#27979;&#35797;&#30340;&#24433;&#21709;&#65292;&#24182;&#35752;&#35770;&#20102;LLMs&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.11409</link><description>&lt;p&gt;
&#35780;&#20272;LLMs&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Evaluating LLMs for Privilege-Escalation Scenarios. (arXiv:2310.11409v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#28183;&#36879;&#27979;&#35797;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#33258;&#21160;&#21270;&#30340;Linux&#29305;&#26435;&#21319;&#32423;&#22522;&#20934;&#21644;&#19968;&#20010;LLM-guided&#29305;&#26435;&#21319;&#32423;&#24037;&#20855;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;LLMs&#30340;&#19981;&#21516;&#25552;&#31034;&#35774;&#35745;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#39640;&#32423;&#25351;&#23548;&#23545;&#27979;&#35797;&#30340;&#24433;&#21709;&#65292;&#24182;&#35752;&#35770;&#20102;LLMs&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28183;&#36879;&#27979;&#35797;&#26159;&#32593;&#32476;&#23433;&#20840;&#30340;&#19968;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#23427;&#20801;&#35768;&#32452;&#32455;&#20027;&#21160;&#35782;&#21035;&#21644;&#20462;&#22797;&#31995;&#32479;&#20013;&#30340;&#28431;&#27934;&#65292;&#20174;&#32780;&#22686;&#24378;&#20854;&#23545;&#28508;&#22312;&#32593;&#32476;&#25915;&#20987;&#30340;&#38450;&#24481;&#26426;&#21046;&#12290;&#22312;&#28183;&#36879;&#27979;&#35797;&#39046;&#22495;&#65292;&#26368;&#36817;&#30340;&#19968;&#20010;&#36827;&#23637;&#26159;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#25105;&#20204;&#25506;&#32034;LLMs&#19982;&#28183;&#36879;&#27979;&#35797;&#30340;&#20132;&#21449;&#39046;&#22495;&#65292;&#20197;&#20102;&#35299;&#23427;&#20204;&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#30340;&#33021;&#21147;&#21644;&#25361;&#25112;&#12290;&#25105;&#20204;&#20351;&#29992;&#26412;&#22320;&#34394;&#25311;&#26426;&#21019;&#24314;&#20102;&#19968;&#20010;&#33258;&#21160;&#21270;&#30340;Linux&#29305;&#26435;&#21319;&#32423;&#22522;&#20934;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;LLMs&#30340;&#29305;&#26435;&#21319;&#32423;&#24037;&#20855;&#65292;&#29992;&#20110;&#35780;&#20272;&#19981;&#21516;&#30340;LLMs&#21644;&#25552;&#31034;&#31574;&#30053;&#22312;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19981;&#21516;&#25552;&#31034;&#35774;&#35745;&#30340;&#24433;&#21709;&#65292;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#20197;&#21450;&#21521;LLMs&#25552;&#20379;&#39640;&#32423;&#25351;&#23548;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;LLMs&#38754;&#20020;&#30340;&#25361;&#25112;&#39046;&#22495;&#65292;&#21253;&#25324;&#22312;&#27979;&#35797;&#36807;&#31243;&#20013;&#20445;&#25345;&#19987;&#27880;&#12289;&#22788;&#29702;&#38169;&#35823;&#20197;&#21450;&#19982;&#20256;&#32479;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Penetration testing, an essential component of cybersecurity, allows organizations to proactively identify and remediate vulnerabilities in their systems, thus bolstering their defense mechanisms against potential cyberattacks. One recent advancement in the realm of penetration testing is the utilization of Language Models (LLMs). We explore the intersection of LLMs and penetration testing to gain insight into their capabilities and challenges in the context of privilige escalation. We create an automated Linux privilege-escalation benchmark utilizing local virtual machines. We introduce an LLM-guided privilege-escalation tool designed for evaluating different LLMs and prompt strategies against our benchmark. We analyze the impact of different prompt designs, the benefits of in-context learning, and the advantages of offering high-level guidance to LLMs. We discuss challenging areas for LLMs, including maintaining focus during testing, coping with errors, and finally comparing them wit
&lt;/p&gt;</description></item></channel></rss>