<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;X&#40657;&#23458;&#30340;&#27010;&#24565;&#65292;&#21363;&#21033;&#29992;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#26469;&#25805;&#32437;&#21487;&#35299;&#37322;AI&#65288;XAI&#65289;&#25351;&#26631;&#65292;&#20174;&#32780;&#20135;&#29983;&#25152;&#38656;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#32780;&#19981;&#38477;&#20302;&#20854;&#39044;&#27979;&#24615;&#33021;&#12290;&#30740;&#31350;&#32773;&#24635;&#32467;&#20102;X&#40657;&#23458;&#29616;&#35937;&#30340;&#20005;&#37325;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#26816;&#27979;&#21644;&#39044;&#38450;&#26041;&#27861;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#23545;XAI&#30740;&#31350;&#21487;&#20449;&#24230;&#21644;&#21487;&#37325;&#29616;&#24615;&#30340;&#20262;&#29702;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2401.08513</link><description>&lt;p&gt;
X&#40657;&#23458;&#65306;&#35823;&#23548;&#30340;&#33258;&#21160;&#26426;&#22120;&#23398;&#20064;&#30340;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
X Hacking: The Threat of Misguided AutoML
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.08513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;X&#40657;&#23458;&#30340;&#27010;&#24565;&#65292;&#21363;&#21033;&#29992;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#26469;&#25805;&#32437;&#21487;&#35299;&#37322;AI&#65288;XAI&#65289;&#25351;&#26631;&#65292;&#20174;&#32780;&#20135;&#29983;&#25152;&#38656;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#32780;&#19981;&#38477;&#20302;&#20854;&#39044;&#27979;&#24615;&#33021;&#12290;&#30740;&#31350;&#32773;&#24635;&#32467;&#20102;X&#40657;&#23458;&#29616;&#35937;&#30340;&#20005;&#37325;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#26816;&#27979;&#21644;&#39044;&#38450;&#26041;&#27861;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#23545;XAI&#30740;&#31350;&#21487;&#20449;&#24230;&#21644;&#21487;&#37325;&#29616;&#24615;&#30340;&#20262;&#29702;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#21644;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26377;&#21161;&#20110;&#24314;&#31435;&#23545;&#27169;&#22411;&#39044;&#27979;&#21644;&#27966;&#29983;&#35265;&#35299;&#30340;&#20449;&#20219;&#65292;&#20294;&#20063;&#20026;&#20998;&#26512;&#24072;&#25552;&#20379;&#20102;&#19968;&#31181;&#25197;&#26354;&#30340;&#21160;&#26426;&#65292;&#21363;&#25805;&#32437;XAI&#25351;&#26631;&#20197;&#25903;&#25345;&#39044;&#20808;&#35268;&#23450;&#30340;&#32467;&#35770;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;X&#40657;&#23458;&#30340;&#27010;&#24565;&#65292;&#21363;&#23558;p-hacking&#24212;&#29992;&#20110;&#35832;&#22914;Shap&#20540;&#20043;&#31867;&#30340;XAI&#25351;&#26631;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#33258;&#21160;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#26469;&#23547;&#25214;&#8220;&#21487;&#36777;&#25252;&#8221;&#30340;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#20135;&#29983;&#25152;&#38656;&#30340;&#35299;&#37322;&#24182;&#22312;&#32500;&#25345;&#20248;&#36234;&#30340;&#39044;&#27979;&#24615;&#33021;&#26102;&#12290;&#25105;&#20204;&#23558;&#35299;&#37322;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#34920;&#36848;&#20026;&#19968;&#20010;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29087;&#24713;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#22312;&#32463;&#39564;&#19978;&#23637;&#31034;&#20102;X&#40657;&#23458;&#30340;&#21487;&#34892;&#24615;&#21644;&#20005;&#37325;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#26816;&#27979;&#21644;&#39044;&#38450;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;XAI&#30740;&#31350;&#30340;&#21487;&#20449;&#24230;&#21644;&#21487;&#37325;&#29616;&#24615;&#30340;&#20262;&#29702;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable AI (XAI) and interpretable machine learning methods help to build trust in model predictions and derived insights, yet also present a perverse incentive for analysts to manipulate XAI metrics to support pre-specified conclusions. This paper introduces the concept of X-hacking, a form of p-hacking applied to XAI metrics such as Shap values. We show how an automated machine learning pipeline can be used to search for 'defensible' models that produce a desired explanation while maintaining superior predictive performance to a common baseline. We formulate the trade-off between explanation and accuracy as a multi-objective optimization problem and illustrate the feasibility and severity of X-hacking empirically on familiar real-world datasets. Finally, we suggest possible methods for detection and prevention, and discuss ethical implications for the credibility and reproducibility of XAI research.
&lt;/p&gt;</description></item></channel></rss>