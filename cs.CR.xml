<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#19968;&#31181;&#26032;&#22411;&#38544;&#31169;&#25915;&#20987;&#8212;&#8212;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#65288;CDA&#65289;&#30340;&#38887;&#24615;&#12290;</title><link>https://arxiv.org/abs/2306.08929</link><description>&lt;p&gt;
&#20851;&#20110;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#30340;&#38887;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the resilience of Collaborative Learning-based Recommender Systems Against Community Detection Attack
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2306.08929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#19968;&#31181;&#26032;&#22411;&#38544;&#31169;&#25915;&#20987;&#8212;&#8212;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#65288;CDA&#65289;&#30340;&#38887;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#28304;&#20110;&#21327;&#20316;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;&#32852;&#37030;&#23398;&#20064;&#21644;&#20843;&#21350;&#23398;&#20064;&#65289;&#30340;&#25104;&#21151;&#12290;&#22312;&#36825;&#20123;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#21442;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340;&#35757;&#32451;&#21516;&#26102;&#22312;&#20854;&#35774;&#22791;&#19978;&#20445;&#30041;&#24050;&#28040;&#36153;&#39033;&#30446;&#30340;&#21382;&#21490;&#35760;&#24405;&#12290;&#34429;&#28982;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#20045;&#19968;&#30475;&#20284;&#20046;&#26377;&#21033;&#20110;&#20445;&#25252;&#21442;&#19982;&#32773;&#30340;&#38544;&#31169;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21327;&#20316;&#23398;&#20064;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#19968;&#31181;&#31216;&#20026;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#65288;CDA&#65289;&#30340;&#26032;&#22411;&#38544;&#31169;&#25915;&#20987;&#30340;&#38887;&#24615;&#12290;&#36825;&#31181;&#25915;&#20987;&#20351;&#24471;&#23545;&#25163;&#33021;&#22815;&#22522;&#20110;&#19968;&#20010;&#36873;&#25321;&#30340;&#39033;&#30446;&#38598;&#65288;&#22914;&#35782;&#21035;&#23545;&#29305;&#23450;&#20852;&#36259;&#28857;&#24863;&#20852;&#36259;&#30340;&#29992;&#25143;&#65289;&#26469;&#35782;&#21035;&#31038;&#21306;&#25104;&#21592;&#12290;&#36890;&#36807;&#22312;&#19977;&#20010;&#30495;&#23454;&#25512;&#33616;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#20351;&#29992;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
arXiv:2306.08929v2 Announce Type: replace-cross  Abstract: Collaborative-learning-based recommender systems emerged following the success of collaborative learning techniques such as Federated Learning (FL) and Gossip Learning (GL). In these systems, users participate in the training of a recommender system while maintaining their history of consumed items on their devices. While these solutions seemed appealing for preserving the privacy of the participants at first glance, recent studies have revealed that collaborative learning can be vulnerable to various privacy attacks. In this paper, we study the resilience of collaborative learning-based recommender systems against a novel privacy attack called Community Detection Attack (CDA). This attack enables an adversary to identify community members based on a chosen set of items (eg., identifying users interested in specific points-of-interest). Through experiments on three real recommendation datasets using two state-of-the-art recomme
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22823;&#35268;&#27169;&#32452;&#32455;&#29615;&#22659;&#20013;&#23454;&#29616;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#30340;&#24773;&#20917;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21453;&#38035;&#40060;&#22522;&#30784;&#35774;&#26045;&#26080;&#27861;&#38450;&#27490;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#38035;&#40060;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2401.09727</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#65306;&#22823;&#35268;&#27169;&#32452;&#32455;&#29615;&#22659;&#20013;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Lateral Spear Phishing: A Comparative Study in Large-Scale Organizational Settings. (arXiv:2401.09727v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09727
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22823;&#35268;&#27169;&#32452;&#32455;&#29615;&#22659;&#20013;&#23454;&#29616;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#30340;&#24773;&#20917;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21453;&#38035;&#40060;&#22522;&#30784;&#35774;&#26045;&#26080;&#27861;&#38450;&#27490;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#38035;&#40060;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38035;&#40060;&#30005;&#23376;&#37038;&#20214;&#30340;&#20005;&#37325;&#23041;&#32961;&#34987;LLMs&#29983;&#25104;&#39640;&#24230;&#23450;&#21521;&#12289;&#20010;&#24615;&#21270;&#21644;&#33258;&#21160;&#21270;&#30340;&#40060;&#21449;&#24335;&#32593;&#32476;&#38035;&#40060;&#25915;&#20987;&#30340;&#28508;&#21147;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;&#20851;&#20110;LLM&#20419;&#25104;&#30340;&#38035;&#40060;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;&#65306;1&#65289;&#29616;&#26377;&#30340;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#30740;&#31350;&#32570;&#20047;&#38024;&#23545;&#25972;&#20010;&#32452;&#32455;&#36827;&#34892;&#22823;&#35268;&#27169;&#25915;&#20987;&#30340;LLM&#25972;&#21512;&#30340;&#20855;&#20307;&#23457;&#26597;&#65307;2&#65289;&#23613;&#31649;&#21453;&#38035;&#40060;&#22522;&#30784;&#35774;&#26045;&#32463;&#36807;&#24191;&#27867;&#24320;&#21457;&#65292;&#20294;&#20173;&#26080;&#27861;&#38450;&#27490;LLM&#29983;&#25104;&#30340;&#25915;&#20987;&#65292;&#21487;&#33021;&#24433;&#21709;&#21592;&#24037;&#21644;IT&#23433;&#20840;&#20107;&#20214;&#31649;&#29702;&#12290;&#28982;&#32780;&#65292;&#36827;&#34892;&#36825;&#26679;&#30340;&#35843;&#26597;&#30740;&#31350;&#38656;&#35201;&#22312;&#29616;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#36827;&#34892;&#65292;&#35813;&#29615;&#22659;&#22312;&#27491;&#24120;&#19994;&#21153;&#36816;&#20316;&#26399;&#38388;&#24037;&#20316;&#65292;&#24182;&#21453;&#26144;&#20986;&#22823;&#22411;&#32452;&#32455;&#22522;&#30784;&#35774;&#26045;&#30340;&#22797;&#26434;&#24615;&#12290;&#27492;&#35774;&#32622;&#36824;&#24517;&#39035;&#25552;&#20379;&#25152;&#38656;&#30340;&#28789;&#27963;&#24615;&#65292;&#20197;&#20419;&#36827;&#21508;&#31181;&#23454;&#39564;&#26465;&#20214;&#30340;&#23454;&#26045;&#65292;&#29305;&#21035;&#26159;&#38035;&#40060;&#30005;&#23376;&#37038;&#20214;&#30340;&#21046;&#20316;&#21644;&#32452;&#32455;&#33539;&#22260;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
The critical threat of phishing emails has been further exacerbated by the potential of LLMs to generate highly targeted, personalized, and automated spear phishing attacks. Two critical problems concerning LLM-facilitated phishing require further investigation: 1) Existing studies on lateral phishing lack specific examination of LLM integration for large-scale attacks targeting the entire organization, and 2) Current anti-phishing infrastructure, despite its extensive development, lacks the capability to prevent LLM-generated attacks, potentially impacting both employees and IT security incident management. However, the execution of such investigative studies necessitates a real-world environment, one that functions during regular business operations and mirrors the complexity of a large organizational infrastructure. This setting must also offer the flexibility required to facilitate a diverse array of experimental conditions, particularly the incorporation of phishing emails crafted
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#19979;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#36716;&#25442;&#24605;&#24819;&#21644;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.03807</link><description>&lt;p&gt;
&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving CNN Training with Transfer Learning. (arXiv:2304.03807v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#19979;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#36716;&#25442;&#24605;&#24819;&#21644;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#30340;&#31070;&#32463;&#32593;&#32476;&#25512;&#29702;&#24050;&#32463;&#24471;&#21040;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#20445;&#25345;&#21516;&#24577;CNN&#35757;&#32451;&#20173;&#28982;&#26159;&#19968;&#39033;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#23454;&#29616;&#22522;&#20110;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#30340;&#38544;&#31169;&#20445;&#25252;CNN&#35757;&#32451;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#27425;&#25104;&#21151;&#31361;&#30772;&#36825;&#20010;&#38590;&#39064;&#65292;&#20197;&#21069;&#27809;&#26377;&#20219;&#20309;&#24037;&#20316;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#12290;&#37319;&#29992;&#20102;&#20960;&#31181;&#25216;&#26415;&#65306;&#65288;1&#65289;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#65292;&#21487;&#20197;&#23558;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#31616;&#21270;&#20026;&#21516;&#24577;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#65292;&#29978;&#33267;&#26159;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#65288;MLR&#65289;&#35757;&#32451;&#65307;&#65288;2&#65289;&#36890;&#36807;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;$\texttt{Quadratic Gradient}$&#65292;&#24212;&#29992;&#20110;MLR&#30340;&#22686;&#24378;&#26799;&#24230;&#26041;&#27861;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65307;&#65288;3&#65289;&#25105;&#20204;&#37319;&#29992;&#25968;&#23398;&#20013;&#30340;&#21464;&#25442;&#24605;&#24819;&#65292;&#23558;&#21152;&#23494;&#22495;&#20013;&#30340;&#36817;&#20284;Softmax&#20989;&#25968;&#36716;&#25442;&#25104;&#24050;&#32463;&#30740;&#31350;&#36807;&#30340;&#36924;&#36817;&#26041;&#27861;&#65292;&#20174;&#32780;&#24471;&#21040;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Privacy-preserving nerual network inference has been well studied while homomorphic CNN training still remains an open challenging task. In this paper, we present a practical solution to implement privacy-preserving CNN training based on mere Homomorphic Encryption (HE) technique. To our best knowledge, this is the first attempt successfully to crack this nut and no work ever before has achieved this goal. Several techniques combine to make it done: (1) with transfer learning, privacy-preserving CNN training can be reduced to homomorphic neural network training, or even multiclass logistic regression (MLR) training; (2) via a faster gradient variant called $\texttt{Quadratic Gradient}$, an enhanced gradient method for MLR with a state-of-the-art performance in converge speed is applied in this work to achieve high performance; (3) we employ the thought of transformation in mathematics to transform approximating Softmax function in encryption domain to the well-studied approximation of 
&lt;/p&gt;</description></item></channel></rss>