<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#21487;&#36716;&#31227;&#30340;&#23545;&#25239;&#24615;&#22270;&#20687;&#31034;&#20363;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#25915;&#20987;&#20998;&#31867;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#22823;&#35268;&#27169;&#35780;&#20272;&#25581;&#31034;&#20102;&#19968;&#20123;&#26032;&#30340;&#35265;&#35299;&#21644;&#20849;&#35782;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.11850</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#21487;&#36716;&#31227;&#30340;&#23545;&#25239;&#24615;&#22270;&#20687;&#31034;&#20363;&#65306;&#25915;&#20987;&#20998;&#31867;&#65292;&#35780;&#20272;&#25351;&#21335;&#21644;&#26032;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;
Revisiting Transferable Adversarial Image Examples: Attack Categorization, Evaluation Guidelines, and New Insights. (arXiv:2310.11850v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11850
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#21487;&#36716;&#31227;&#30340;&#23545;&#25239;&#24615;&#22270;&#20687;&#31034;&#20363;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#25915;&#20987;&#20998;&#31867;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#22823;&#35268;&#27169;&#35780;&#20272;&#25581;&#31034;&#20102;&#19968;&#20123;&#26032;&#30340;&#35265;&#35299;&#21644;&#20849;&#35782;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#36716;&#31227;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#40657;&#30418;&#25915;&#20987;&#22330;&#26223;&#20013;&#24341;&#21457;&#20102;&#20851;&#38190;&#30340;&#23433;&#20840;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#24120;&#35265;&#35780;&#20272;&#23454;&#36341;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;(1) &#23545;&#20110;&#25915;&#20987;&#30340;&#21487;&#36716;&#31227;&#24615;&#65292;&#32570;&#20047;&#31995;&#32479;&#21270;&#30340;&#65292;&#19968;&#23545;&#19968;&#30340;&#25915;&#20987;&#27604;&#36739;&#21644;&#20844;&#24179;&#30340;&#36229;&#21442;&#25968;&#35774;&#32622;&#12290;(2) &#23545;&#20110;&#25915;&#20987;&#30340;&#38544;&#34109;&#24615;&#65292;&#31616;&#21333;&#22320;&#27809;&#26377;&#27604;&#36739;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;(1) &#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#20998;&#31867;&#31574;&#30053;&#65292;&#24182;&#22312;&#21487;&#36716;&#31227;&#24615;&#26041;&#38754;&#36827;&#34892;&#31995;&#32479;&#21270;&#21644;&#20844;&#24179;&#30340;&#21516;&#31867;&#21035;&#20998;&#26512;&#65292;&#20197;&#21450;(2) &#20174;&#25915;&#20987;&#22238;&#28335;&#30340;&#35282;&#24230;&#32771;&#34385;&#22810;&#26679;&#30340;&#38590;&#20197;&#23519;&#35273;&#30340;&#24230;&#37327;&#21644;&#26356;&#32454;&#31890;&#24230;&#30340;&#38544;&#34109;&#29305;&#24615;&#26469;&#24314;&#31435;&#26032;&#30340;&#35780;&#20272;&#25351;&#21335;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23545;ImageNet&#19978;&#30340;&#21487;&#36716;&#31227;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#35780;&#20272;&#65292;&#28041;&#21450;&#23545;9&#31181;&#20195;&#34920;&#24615;&#38450;&#24481;&#30340;23&#31181;&#20195;&#34920;&#24615;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#25552;&#20379;&#20102;&#19968;&#20123;&#26032;&#30340;&#35265;&#35299;&#65292;&#21253;&#25324;&#25361;&#25112;&#20849;&#35782;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transferable adversarial examples raise critical security concerns in real-world, black-box attack scenarios. However, in this work, we identify two main problems in common evaluation practices: (1) For attack transferability, lack of systematic, one-to-one attack comparison and fair hyperparameter settings. (2) For attack stealthiness, simply no comparisons. To address these problems, we establish new evaluation guidelines by (1) proposing a novel attack categorization strategy and conducting systematic and fair intra-category analyses on transferability, and (2) considering diverse imperceptibility metrics and finer-grained stealthiness characteristics from the perspective of attack traceback. To this end, we provide the first large-scale evaluation of transferable adversarial examples on ImageNet, involving 23 representative attacks against 9 representative defenses. Our evaluation leads to a number of new insights, including consensus-challenging ones: (1) Under a fair attack hyper
&lt;/p&gt;</description></item></channel></rss>