<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32852;&#37030;&#32959;&#30244;&#20998;&#21106;&#20013;&#33258;&#36866;&#24212;&#26435;&#37325;&#32858;&#21512;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#30456;&#20284;&#24615;&#26435;&#37325;&#32858;&#21512;&#26041;&#27861;&#65288;SimAgg&#65289;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20998;&#21106;&#33021;&#21147;&#65292;&#24182;&#22312;&#20445;&#25252;&#38544;&#31169;&#26041;&#38754;&#20570;&#20986;&#20102;&#39069;&#22806;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.00856</link><description>&lt;p&gt;
&#38024;&#23545;&#32852;&#37030;&#32959;&#30244;&#20998;&#21106;&#20013;&#33258;&#36866;&#24212;&#26435;&#37325;&#32858;&#21512;&#30340;&#24046;&#20998;&#38544;&#31169;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation. (arXiv:2308.00856v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32852;&#37030;&#32959;&#30244;&#20998;&#21106;&#20013;&#33258;&#36866;&#24212;&#26435;&#37325;&#32858;&#21512;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#30456;&#20284;&#24615;&#26435;&#37325;&#32858;&#21512;&#26041;&#27861;&#65288;SimAgg&#65289;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20998;&#21106;&#33021;&#21147;&#65292;&#24182;&#22312;&#20445;&#25252;&#38544;&#31169;&#26041;&#38754;&#20570;&#20986;&#20102;&#39069;&#22806;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#20844;&#27491;&#30340;&#20840;&#23616;&#27169;&#22411;&#26469;&#20445;&#25252;&#20010;&#20307;&#23458;&#25143;&#25968;&#25454;&#30340;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#22312;&#22788;&#29702;&#19981;&#21516;&#23458;&#25143;&#25968;&#25454;&#26102;&#21487;&#33021;&#24341;&#20837;&#23433;&#20840;&#39118;&#38505;&#65292;&#20174;&#32780;&#21487;&#33021;&#21361;&#21450;&#38544;&#31169;&#21644;&#25968;&#25454;&#23436;&#25972;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#32852;&#37030;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#21106;&#20013;&#25193;&#23637;&#20102;&#30456;&#20284;&#24615;&#26435;&#37325;&#32858;&#21512;&#26041;&#27861;&#65288;SimAgg&#65289;&#21040;DP-SimAgg&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#38024;&#23545;&#22810;&#27169;&#24577;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;MRI&#65289;&#20013;&#30340;&#33041;&#32959;&#30244;&#20998;&#21106;&#30340;&#24046;&#20998;&#38544;&#31169;&#30456;&#20284;&#24615;&#21152;&#26435;&#32858;&#21512;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;DP-SimAgg&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#20998;&#21106;&#33021;&#21147;&#65292;&#36824;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#38544;&#31169;&#20445;&#25252;&#23618;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#65292;&#20197;&#35745;&#31639;&#24615;&#33021;&#20026;&#20027;&#35201;&#32771;&#34385;&#22240;&#32032;&#65292;&#35777;&#26126;&#20102;DP-SimAgg&#20351;..
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a distributed machine learning approach that safeguards privacy by creating an impartial global model while respecting the privacy of individual client data. However, the conventional FL method can introduce security risks when dealing with diverse client data, potentially compromising privacy and data integrity. To address these challenges, we present a differential privacy (DP) federated deep learning framework in medical image segmentation. In this paper, we extend our similarity weight aggregation (SimAgg) method to DP-SimAgg algorithm, a differentially private similarity-weighted aggregation algorithm for brain tumor segmentation in multi-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not only enhances model segmentation capabilities but also provides an additional layer of privacy preservation. Extensive benchmarking and evaluation of our framework, with computational performance as a key consideration, demonstrate that DP-SimAgg enables a
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20110;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;(SNNs)&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#40065;&#26834;&#24615;&#21644;&#36716;&#31227;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25104;&#21151;&#30340;&#30333;&#30418;&#23545;&#25239;&#25915;&#20987;SNNs&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#24182;&#19988;&#38750;SNN&#26550;&#26500;&#21019;&#24314;&#30340;&#23545;&#25239;&#26679;&#26412;&#24448;&#24448;&#19981;&#34987;SNNs&#35823;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2209.03358</link><description>&lt;p&gt;
&#25915;&#20987;&#33033;&#20914;&#65306;&#20851;&#20110;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#21487;&#36716;&#31227;&#24615;&#19982;&#23433;&#20840;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Attacking the Spike: On the Transferability and Security of Spiking Neural Networks to Adversarial Examples. (arXiv:2209.03358v3 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.03358
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20110;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;(SNNs)&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#40065;&#26834;&#24615;&#21644;&#36716;&#31227;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25104;&#21151;&#30340;&#30333;&#30418;&#23545;&#25239;&#25915;&#20987;SNNs&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#24182;&#19988;&#38750;SNN&#26550;&#26500;&#21019;&#24314;&#30340;&#23545;&#25239;&#26679;&#26412;&#24448;&#24448;&#19981;&#34987;SNNs&#35823;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;(SNNs)&#22240;&#20854;&#39640;&#33021;&#25928;&#21644;&#26368;&#36817;&#22312;&#20998;&#31867;&#24615;&#33021;&#19978;&#30340;&#36827;&#23637;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19981;&#21516;&#65292;&#23545;SNNs&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#40065;&#26834;&#24615;&#30340;&#20998;&#26512;&#21644;&#30740;&#31350;&#20173;&#28982;&#30456;&#23545;&#19981;&#23436;&#21892;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#20110;&#25512;&#36827;SNNs&#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#38754;&#65292;&#24182;&#20570;&#20986;&#20102;&#19977;&#20010;&#20027;&#35201;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25104;&#21151;&#30340;&#30333;&#30418;&#23545;&#25239;&#25915;&#20987;SNNs&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#24213;&#23618;&#30340;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#21363;&#20351;&#22312;&#23545;&#25239;&#24615;&#35757;&#32451;SNNs&#30340;&#24773;&#20917;&#19979;&#20063;&#19968;&#26679;&#12290;&#20854;&#27425;&#65292;&#21033;&#29992;&#26368;&#20339;&#30340;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#23545;&#25239;&#25915;&#20987;&#22312;SNNs&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26550;&#26500;&#22914;Vision Transformers(ViTs)&#21644;Big Transfer Convolutional Neural Networks(CNNs)&#20043;&#38388;&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#38750;SNN&#26550;&#26500;&#21019;&#24314;&#30340;&#23545;&#25239;&#26679;&#26412;&#24448;&#24448;&#19981;&#34987;SNNs&#35823;&#20998;&#31867;&#12290;&#31532;&#19977;&#65292;&#30001;&#20110;&#32570;&#20047;&#19968;&#20010;&#20849;&#24615;
&lt;/p&gt;
&lt;p&gt;
Spiking neural networks (SNNs) have attracted much attention for their high energy efficiency and for recent advances in their classification performance. However, unlike traditional deep learning approaches, the analysis and study of the robustness of SNNs to adversarial examples remain relatively underdeveloped. In this work, we focus on advancing the adversarial attack side of SNNs and make three major contributions. First, we show that successful white-box adversarial attacks on SNNs are highly dependent on the underlying surrogate gradient technique, even in the case of adversarially trained SNNs. Second, using the best surrogate gradient technique, we analyze the transferability of adversarial attacks on SNNs and other state-of-the-art architectures like Vision Transformers (ViTs) and Big Transfer Convolutional Neural Networks (CNNs). We demonstrate that the adversarial examples created by non-SNN architectures are not misclassified often by SNNs. Third, due to the lack of an ubi
&lt;/p&gt;</description></item></channel></rss>