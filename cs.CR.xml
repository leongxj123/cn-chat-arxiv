<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;</title><link>https://arxiv.org/abs/2403.17710</link><description>&lt;p&gt;
&#22522;&#20110;&#20248;&#21270;&#30340;&#23545;LLM&#35780;&#21028;&#31995;&#32479;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Optimization-based Prompt Injection Attack to LLM-as-a-Judge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17710
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLM-as-a-Judge &#26159;&#19968;&#31181;&#21487;&#20197;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#35780;&#20272;&#25991;&#26412;&#20449;&#24687;&#30340;&#26032;&#39062;&#35299;&#20915;&#26041;&#26696;&#12290;&#26681;&#25454;&#29616;&#26377;&#30740;&#31350;&#65292;LLMs&#22312;&#25552;&#20379;&#20256;&#32479;&#20154;&#31867;&#35780;&#20272;&#30340;&#24341;&#20154;&#27880;&#30446;&#26367;&#20195;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#38024;&#23545;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;JudgeDeceiver&#65292;&#19968;&#31181;&#38024;&#23545;LLM-as-a-Judge&#37327;&#36523;&#23450;&#21046;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21046;&#23450;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#29992;&#20110;&#25915;&#20987;LLM-as-a-Judge&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#20248;&#21270;&#31639;&#27861;&#39640;&#25928;&#22320;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#65292;&#23454;&#29616;&#23545;&#27169;&#22411;&#35780;&#20272;&#30340;&#26377;&#38024;&#23545;&#24615;&#21644;&#26377;&#25928;&#30340;&#25805;&#20316;&#12290;&#19982;&#25163;&#24037;&#21046;&#20316;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#21151;&#25928;&#65292;&#32473;&#22522;&#20110;LLM&#30340;&#21028;&#26029;&#31995;&#32479;&#24403;&#21069;&#30340;&#23433;&#20840;&#33539;&#24335;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17710v1 Announce Type: cross  Abstract: LLM-as-a-Judge is a novel solution that can assess textual information with large language models (LLMs). Based on existing research studies, LLMs demonstrate remarkable performance in providing a compelling alternative to traditional human assessment. However, the robustness of these systems against prompt injection attacks remains an open question. In this work, we introduce JudgeDeceiver, a novel optimization-based prompt injection attack tailored to LLM-as-a-Judge. Our method formulates a precise optimization objective for attacking the decision-making process of LLM-as-a-Judge and utilizes an optimization algorithm to efficiently automate the generation of adversarial sequences, achieving targeted and effective manipulation of model evaluations. Compared to handcraft prompt injection attacks, our method demonstrates superior efficacy, posing a significant challenge to the current security paradigms of LLM-based judgment systems. T
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#36827;&#21270;&#26041;&#27861;&#30340;&#21333;&#26234;&#33021;&#20307;&#19982;&#22810;&#26234;&#33021;&#20307;&#31169;&#23494;&#20027;&#21160;&#24863;&#30693;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#26080;&#32447;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#31034;&#20363;&#29992;&#20363;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10112</link><description>&lt;p&gt;
&#21333;&#26234;&#33021;&#20307;&#19982;&#22810;&#26234;&#33021;&#20307;&#30340;&#31169;&#23494;&#20027;&#21160;&#24863;&#30693;&#65306;&#28145;&#24230;&#31070;&#32463;&#36827;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#36827;&#21270;&#26041;&#27861;&#30340;&#21333;&#26234;&#33021;&#20307;&#19982;&#22810;&#26234;&#33021;&#20307;&#31169;&#23494;&#20027;&#21160;&#24863;&#30693;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#26080;&#32447;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#31034;&#20363;&#29992;&#20363;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#23384;&#22312;&#31397;&#35270;&#32773;&#24773;&#20917;&#19979;&#30340;&#20027;&#21160;&#20551;&#35774;&#27979;&#35797;&#20013;&#30340;&#19968;&#20010;&#38598;&#20013;&#24335;&#38382;&#39064;&#21644;&#19968;&#20010;&#20998;&#25955;&#24335;&#38382;&#39064;&#12290;&#38024;&#23545;&#21253;&#25324;&#21333;&#20010;&#21512;&#27861;&#26234;&#33021;&#20307;&#30340;&#38598;&#20013;&#24335;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#36827;&#21270;&#65288;NE&#65289;&#30340;&#26032;&#26694;&#26550;&#65307;&#32780;&#38024;&#23545;&#20998;&#25955;&#24335;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;NE&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#65292;&#36825;&#31181;&#26041;&#27861;&#26377;&#36259;&#22320;&#20445;&#25345;&#20102;&#21333;&#19968;&#26234;&#33021;&#20307;NE&#30340;&#25152;&#26377;&#35745;&#31639;&#20248;&#21183;&#12290;&#36890;&#36807;&#23545;&#26080;&#32447;&#20256;&#24863;&#22120;&#32593;&#32476;&#19978;&#24322;&#24120;&#26816;&#27979;&#31034;&#20363;&#29992;&#20363;&#20013;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;EAHT&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;&#20027;&#21160;&#20551;&#35774;&#27979;&#35797;&#31574;&#30053;&#20197;&#21450;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10112v1 Announce Type: new  Abstract: In this paper, we focus on one centralized and one decentralized problem of active hypothesis testing in the presence of an eavesdropper. For the centralized problem including a single legitimate agent, we present a new framework based on NeuroEvolution (NE), whereas, for the decentralized problem, we develop a novel NE-based method for solving collaborative multi-agent tasks, which interestingly maintains all computational benefits of single-agent NE. The superiority of the proposed EAHT approaches over conventional active hypothesis testing policies, as well as learning-based methods, is validated through numerical investigations in an example use case of anomaly detection over wireless sensor networks.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#26469;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2403.07151</link><description>&lt;p&gt;
&#19981;&#35201;&#24536;&#35760;&#25105;&#20570;&#30340;&#20107;&#65306;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
Don't Forget What I did?: Assessing Client Contributions in Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07151
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#26469;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#21327;&#20316;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#65292;&#22810;&#20010;&#23458;&#25143;&#21442;&#19982;&#35757;&#32451;ML&#27169;&#22411;&#65292;&#32780;&#19981;&#26292;&#38706;&#31169;&#20154;&#25968;&#25454;&#12290;&#20844;&#24179;&#20934;&#30830;&#35780;&#20272;&#23458;&#25143;&#36129;&#29486;&#22312;FL&#20013;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#20197;&#20419;&#36827;&#28608;&#21169;&#20998;&#37197;&#24182;&#40723;&#21169;&#22810;&#26679;&#21270;&#23458;&#25143;&#21442;&#19982;&#32479;&#19968;&#27169;&#22411;&#35757;&#32451;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#20110;&#35780;&#20272;&#22312;&#27599;&#20010;FL&#35757;&#32451;&#26102;&#26399;&#20013;&#30340;&#65288;&#28508;&#22312;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#23458;&#25143;&#21442;&#19982;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07151v1 Announce Type: cross  Abstract: Federated Learning (FL) is a collaborative machine learning (ML) approach, where multiple clients participate in training an ML model without exposing the private data. Fair and accurate assessment of client contributions is an important problem in FL to facilitate incentive allocation and encouraging diverse clients to participate in a unified model training. Existing methods for assessing client contribution adopts co-operative game-theoretic concepts, such as Shapley values, but under simplified assumptions. In this paper, we propose a history-aware game-theoretic framework, called FLContrib, to assess client contributions when a subset of (potentially non-i.i.d.) clients participate in each epoch of FL training. By exploiting the FL training process and linearity of Shapley value, we develop FLContrib that yields a historical timeline of client contributions as FL training progresses over epochs. Additionally, to assess client cont
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36229;&#21442;&#25968;&#35843;&#25972;&#20013;&#30340;&#38544;&#31169;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#24403;&#21069;&#30340;&#38544;&#31169;&#20998;&#26512;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#32039;&#23494;&#30340;&#65292;&#20294;&#22312;&#29305;&#23450;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#19978;&#21017;&#19981;&#20877;&#25104;&#31435;&#65292;&#24182;&#36890;&#36807;&#38544;&#31169;&#23457;&#35745;&#25581;&#31034;&#20102;&#24403;&#21069;&#29702;&#35770;&#38544;&#31169;&#30028;&#19982;&#23454;&#35777;&#20043;&#38388;&#30340;&#26174;&#33879;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.13087</link><description>&lt;p&gt;
&#36873;&#25321;&#22914;&#20309;&#27844;&#28431;&#38544;&#31169;&#65306;&#37325;&#26032;&#23457;&#35270;&#31169;&#26377;&#36873;&#25321;&#21450;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#25913;&#36827;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
How Does Selection Leak Privacy: Revisiting Private Selection and Improved Results for Hyper-parameter Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36229;&#21442;&#25968;&#35843;&#25972;&#20013;&#30340;&#38544;&#31169;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#24403;&#21069;&#30340;&#38544;&#31169;&#20998;&#26512;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#32039;&#23494;&#30340;&#65292;&#20294;&#22312;&#29305;&#23450;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#19978;&#21017;&#19981;&#20877;&#25104;&#31435;&#65292;&#24182;&#36890;&#36807;&#38544;&#31169;&#23457;&#35745;&#25581;&#31034;&#20102;&#24403;&#21069;&#29702;&#35770;&#38544;&#31169;&#30028;&#19982;&#23454;&#35777;&#20043;&#38388;&#30340;&#26174;&#33879;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#20013;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;(DP)&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#20851;&#38190;&#30340;&#36807;&#31243;&#65292;&#28041;&#21450;&#20174;&#20960;&#20010;&#36816;&#34892;&#20013;&#36873;&#25321;&#26368;&#20339;&#30340;&#36807;&#31243;&#12290;&#19982;&#35768;&#22810;&#31169;&#26377;&#31639;&#27861;&#65288;&#21253;&#25324;&#26222;&#36941;&#23384;&#22312;&#30340;DP-SGD&#65289;&#19981;&#21516;&#65292;&#35843;&#25972;&#30340;&#38544;&#31169;&#24433;&#21709;&#20173;&#28982;&#19981;&#22815;&#20102;&#35299;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#31169;&#26377;&#35299;&#20915;&#26041;&#26696;&#29992;&#20110;&#35843;&#25972;&#36807;&#31243;&#65292;&#28982;&#32780;&#19968;&#20010;&#26681;&#26412;&#30340;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#24403;&#21069;&#35299;&#20915;&#26041;&#26696;&#30340;&#38544;&#31169;&#30028;&#26159;&#21542;&#32039;&#23494;&#65311;&#26412;&#25991;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#20102;&#31215;&#26497;&#21644;&#28040;&#26497;&#30340;&#31572;&#26696;&#12290;&#26368;&#21021;&#65292;&#25105;&#20204;&#25552;&#20379;&#30340;&#30740;&#31350;&#35777;&#23454;&#20102;&#24403;&#21069;&#30340;&#38544;&#31169;&#20998;&#26512;&#22312;&#19968;&#33324;&#24847;&#20041;&#19978;&#30830;&#23454;&#26159;&#32039;&#23494;&#30340;&#12290;&#28982;&#32780;&#65292;&#24403;&#25105;&#20204;&#19987;&#38376;&#30740;&#31350;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#26102;&#65292;&#36825;&#31181;&#32039;&#23494;&#24615;&#21017;&#19981;&#20877;&#25104;&#31435;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#23545;&#35843;&#25972;&#36807;&#31243;&#36827;&#34892;&#38544;&#31169;&#23457;&#35745;&#26469;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#31361;&#26174;&#20102;&#24403;&#21069;&#29702;&#35770;&#38544;&#31169;&#30028;&#19982;&#23454;&#35777;&#20043;&#38388;&#23384;&#22312;&#37325;&#22823;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13087v1 Announce Type: new  Abstract: We study the problem of guaranteeing Differential Privacy (DP) in hyper-parameter tuning, a crucial process in machine learning involving the selection of the best run from several. Unlike many private algorithms, including the prevalent DP-SGD, the privacy implications of tuning remain insufficiently understood. Recent works propose a generic private solution for the tuning process, yet a fundamental question still persists: is the current privacy bound for this solution tight?   This paper contributes both positive and negative answers to this question. Initially, we provide studies affirming the current privacy analysis is indeed tight in a general sense. However, when we specifically study the hyper-parameter tuning problem, such tightness no longer holds. This is first demonstrated by applying privacy audit on the tuning process. Our findings underscore a substantial gap between the current theoretical privacy bound and the empirica
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;&#38382;&#39064;&#12290;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#36755;&#20837;&#30340;&#20219;&#24847;&#27169;&#24577;&#65292;&#20351;&#20854;&#23884;&#20837;&#19982;&#20854;&#20182;&#27169;&#24577;&#30340;&#20219;&#24847;&#36755;&#20837;&#25509;&#36817;&#65292;&#20174;&#32780;&#23454;&#29616;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#30340;&#23545;&#40784;&#12290;&#35813;&#38382;&#39064;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#65292;&#23545;&#29983;&#25104;&#21644;&#20998;&#31867;&#20219;&#21153;&#20250;&#20135;&#29983;&#35823;&#23548;&#12290;</title><link>http://arxiv.org/abs/2308.11804</link><description>&lt;p&gt;
&#36825;&#19981;&#26159;&#19968;&#20010;&#33529;&#26524;&#65306;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal Embeddings. (arXiv:2308.11804v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11804
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;&#38382;&#39064;&#12290;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#36755;&#20837;&#30340;&#20219;&#24847;&#27169;&#24577;&#65292;&#20351;&#20854;&#23884;&#20837;&#19982;&#20854;&#20182;&#27169;&#24577;&#30340;&#20219;&#24847;&#36755;&#20837;&#25509;&#36817;&#65292;&#20174;&#32780;&#23454;&#29616;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#30340;&#23545;&#40784;&#12290;&#35813;&#38382;&#39064;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#65292;&#23545;&#29983;&#25104;&#21644;&#20998;&#31867;&#20219;&#21153;&#20250;&#20135;&#29983;&#35823;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#23558;&#22270;&#20687;&#12289;&#22768;&#38899;&#12289;&#25991;&#26412;&#12289;&#35270;&#39057;&#31561;&#26144;&#23556;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#23545;&#40784;&#19981;&#21516;&#27169;&#24577;&#30340;&#34920;&#31034;&#65288;&#20363;&#22914;&#23558;&#19968;&#24352;&#29399;&#30340;&#22270;&#20687;&#19982;&#19968;&#31181;&#21483;&#22768;&#30456;&#20851;&#32852;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#21487;&#20197;&#21463;&#21040;&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#23545;&#25239;&#24187;&#35273;&#8221;&#30340;&#25915;&#20987;&#12290;&#32473;&#23450;&#20219;&#24847;&#27169;&#24577;&#30340;&#36755;&#20837;&#65292;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#23427;&#65292;&#20351;&#20854;&#23884;&#20837;&#25509;&#36817;&#20110;&#21478;&#19968;&#27169;&#24577;&#20013;&#20219;&#24847;&#23545;&#25163;&#36873;&#25321;&#30340;&#36755;&#20837;&#30340;&#23884;&#20837;&#12290;&#24187;&#35273;&#20351;&#23545;&#25163;&#33021;&#22815;&#23558;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#31561;&#36827;&#34892;&#23545;&#40784;&#12290;&#23545;&#25239;&#24187;&#35273;&#21033;&#29992;&#20102;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#25509;&#36817;&#24615;&#65292;&#22240;&#27492;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#12290;&#20351;&#29992;ImageBind&#23884;&#20837;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#27809;&#26377;&#20855;&#20307;&#19979;&#28216;&#20219;&#21153;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#23545;&#25239;&#24615;&#23545;&#40784;&#30340;&#36755;&#20837;&#22914;&#20309;&#35823;&#23548;&#22270;&#20687;&#29983;&#25104;&#12289;&#25991;&#26412;&#29983;&#25104;&#21644;&#38646;&#26679;&#20363;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal encoders map images, sounds, texts, videos, etc. into a single embedding space, aligning representations across modalities (e.g., associate an image of a dog with a barking sound). We show that multi-modal embeddings can be vulnerable to an attack we call "adversarial illusions." Given an input in any modality, an adversary can perturb it so as to make its embedding close to that of an arbitrary, adversary-chosen input in another modality. Illusions thus enable the adversary to align any image with any text, any text with any sound, etc.  Adversarial illusions exploit proximity in the embedding space and are thus agnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how adversarially aligned inputs, generated without knowledge of specific downstream tasks, mislead image generation, text generation, and zero-shot classification.
&lt;/p&gt;</description></item></channel></rss>