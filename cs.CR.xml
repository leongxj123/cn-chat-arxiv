<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>Tastle&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#36234;&#29425;&#26694;&#26550;&#65292;&#37319;&#29992;&#24694;&#24847;&#20869;&#23481;&#38544;&#34255;&#21644;&#20869;&#23384;&#37325;&#26500;&#20197;&#21450;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2403.08424</link><description>&lt;p&gt;
Tastle: &#20026;&#33258;&#21160;&#36234;&#29425;&#25915;&#20987;&#24178;&#25200;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tastle: Distract Large Language Models for Automatic Jailbreak Attack
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08424
&lt;/p&gt;
&lt;p&gt;
Tastle&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#36234;&#29425;&#26694;&#26550;&#65292;&#37319;&#29992;&#24694;&#24847;&#20869;&#23481;&#38544;&#34255;&#21644;&#20869;&#23384;&#37325;&#26500;&#20197;&#21450;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#22312;LLMs&#20844;&#24320;&#21457;&#24067;&#20043;&#21069;&#65292;&#20154;&#20204;&#24050;&#32463;&#20570;&#20986;&#20102;&#22823;&#37327;&#21162;&#21147;&#26469;&#23558;&#23427;&#20204;&#30340;&#34892;&#20026;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#12290;&#23545;&#40784;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#30830;&#20445;&#23427;&#20204;&#30340;&#26377;&#30410;&#24615;&#12289;&#35802;&#23454;&#24615;&#21644;&#26080;&#23475;&#24615;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#32463;&#36807;&#32454;&#33268;&#23545;&#40784;&#30340;LLMs&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#24694;&#24847;&#25805;&#32437;&#65292;&#22914;&#36234;&#29425;&#65292;&#23548;&#33268;&#24847;&#22806;&#30340;&#34892;&#20026;&#12290;&#36234;&#29425;&#26159;&#26377;&#24847;&#24320;&#21457;&#24694;&#24847;&#25552;&#31034;&#65292;&#20174;LLM&#23433;&#20840;&#38480;&#21046;&#20013;&#36867;&#33073;&#20197;&#29983;&#25104;&#26410;&#32463;&#23457;&#26597;&#30340;&#26377;&#23475;&#20869;&#23481;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#36234;&#29425;&#26041;&#27861;&#26469;&#23545;LLMs&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#65292;&#20294;&#23427;&#20204;&#22312;&#25928;&#26524;&#21644;&#21487;&#20280;&#32553;&#24615;&#26041;&#38754;&#36935;&#21040;&#20102;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Tastle&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#36234;&#29425;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#23545;LLMs&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#24694;&#24847;&#20869;&#23481;&#38544;&#34255;&#21644;&#20869;&#23384;&#37325;&#26500;&#65292;&#24182;&#32467;&#21512;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#26469;&#36234;&#29425;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08424v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved significant advances in recent days. Extensive efforts have been made before the public release of LLMs to align their behaviors with human values. The primary goal of alignment is to ensure their helpfulness, honesty and harmlessness. However, even meticulously aligned LLMs remain vulnerable to malicious manipulations such as jailbreaking, leading to unintended behaviors. The jailbreak is to intentionally develop a malicious prompt that escapes from the LLM security restrictions to produce uncensored detrimental contents. Previous works explore different jailbreak methods for red teaming LLMs, yet they encounter challenges regarding to effectiveness and scalability. In this work, we propose Tastle, a novel black-box jailbreak framework for automated red teaming of LLMs. We designed malicious content concealing and memory reframing with an iterative optimization algorithm to jailbreak LLMs, mo
&lt;/p&gt;</description></item><item><title>WaterMax&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#29983;&#25104;&#25991;&#26412;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#25171;&#30772;&#20102;&#27700;&#21360;&#25216;&#26415;&#20013;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#20256;&#32479;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.04808</link><description>&lt;p&gt;
WaterMax: &#25171;&#30772;LLM&#27700;&#21360;&#21487;&#26816;&#27979;&#24615;-&#31283;&#20581;&#24615;-&#36136;&#37327;&#30340;&#24179;&#34913;
&lt;/p&gt;
&lt;p&gt;
WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04808
&lt;/p&gt;
&lt;p&gt;
WaterMax&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#29983;&#25104;&#25991;&#26412;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#25171;&#30772;&#20102;&#27700;&#21360;&#25216;&#26415;&#20013;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#20256;&#32479;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27700;&#21360;&#26159;&#38459;&#27490;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#24694;&#24847;&#20351;&#29992;&#30340;&#25216;&#26415;&#25163;&#27573;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;WaterMax&#30340;&#26032;&#39062;&#27700;&#21360;&#26041;&#26696;&#65292;&#20855;&#26377;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#21407;&#22987;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#36136;&#37327;&#12290;&#20854;&#26032;&#35774;&#35745;&#19981;&#20250;&#23545;LLM&#36827;&#34892;&#20219;&#20309;&#20462;&#25913;&#65288;&#19981;&#35843;&#25972;&#26435;&#37325;&#12289;&#23545;&#25968;&#12289;&#28201;&#24230;&#25110;&#37319;&#26679;&#25216;&#26415;&#65289;&#12290;WaterMax&#24179;&#34913;&#20102;&#31283;&#20581;&#24615;&#21644;&#22797;&#26434;&#24615;&#65292;&#19982;&#25991;&#29486;&#20013;&#30340;&#27700;&#21360;&#25216;&#26415;&#30456;&#21453;&#65292;&#20174;&#26681;&#26412;&#19978;&#24341;&#21457;&#20102;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#20854;&#24615;&#33021;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#35777;&#26126;&#24182;&#32463;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;&#22312;&#26368;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#19979;&#65292;&#23427;&#32988;&#36807;&#25152;&#26377;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04808v1 Announce Type: cross  Abstract: Watermarking is a technical means to dissuade malfeasant usage of Large Language Models. This paper proposes a novel watermarking scheme, so-called WaterMax, that enjoys high detectability while sustaining the quality of the generated text of the original LLM. Its new design leaves the LLM untouched (no modification of the weights, logits, temperature, or sampling technique). WaterMax balances robustness and complexity contrary to the watermarking techniques of the literature inherently provoking a trade-off between quality and robustness. Its performance is both theoretically proven and experimentally validated. It outperforms all the SotA techniques under the most complete benchmark suite.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#35302;&#21457;&#22120;&#36827;&#34892;&#24378;&#20581;&#21518;&#38376;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24039;&#22937;&#35774;&#35745;&#30340;&#35843;&#25972;&#65292;&#20351;&#25439;&#22351;&#30340;&#26679;&#26412;&#19982;&#24178;&#20928;&#30340;&#26679;&#26412;&#26080;&#27861;&#21306;&#20998;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25104;&#21151;&#22320;&#27450;&#39575;&#35821;&#38899;&#35782;&#21035;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2401.01537</link><description>&lt;p&gt;
&#27450;&#39575;&#30340;&#33402;&#26415;&#65306;&#20351;&#29992;&#21160;&#24577;&#35302;&#21457;&#22120;&#30340;&#24378;&#20581;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers. (arXiv:2401.01537v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01537
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#35302;&#21457;&#22120;&#36827;&#34892;&#24378;&#20581;&#21518;&#38376;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24039;&#22937;&#35774;&#35745;&#30340;&#35843;&#25972;&#65292;&#20351;&#25439;&#22351;&#30340;&#26679;&#26412;&#19982;&#24178;&#20928;&#30340;&#26679;&#26412;&#26080;&#27861;&#21306;&#20998;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25104;&#21151;&#22320;&#27450;&#39575;&#35821;&#38899;&#35782;&#21035;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20154;&#24037;&#26234;&#33021;&#34892;&#19994;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#26381;&#21153;&#65288;MLaaS&#65289;&#39046;&#22495;&#27491;&#22312;&#32463;&#21382;&#22686;&#38271;&#30340;&#23454;&#26045;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#22686;&#38271;&#24341;&#21457;&#20102;&#23545;AI&#38450;&#24481;&#26426;&#21046;&#30340;&#25285;&#24551;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#26469;&#33258;&#19981;&#23436;&#20840;&#21487;&#20449;&#30340;&#31532;&#19977;&#26041;&#25552;&#20379;&#21830;&#30340;&#28508;&#22312;&#38544;&#34109;&#25915;&#20987;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#21548;&#35273;&#21518;&#38376;&#21487;&#33021;&#20351;&#29992;&#26576;&#20123;&#20462;&#25913;&#20316;&#20026;&#20854;&#21551;&#21160;&#26426;&#21046;&#12290;DynamicTrigger&#20316;&#20026;&#19968;&#31181;&#26041;&#27861;&#34987;&#24341;&#20837;&#65292;&#29992;&#20110;&#36827;&#34892;&#20351;&#29992;&#24039;&#22937;&#35774;&#35745;&#30340;&#35843;&#25972;&#26469;&#30830;&#20445;&#25439;&#22351;&#30340;&#26679;&#26412;&#19982;&#24178;&#20928;&#30340;&#26679;&#26412;&#26080;&#27861;&#21306;&#20998;&#30340;&#21160;&#24577;&#21518;&#38376;&#25915;&#20987;&#12290;&#36890;&#36807;&#21033;&#29992;&#27874;&#21160;&#30340;&#20449;&#21495;&#37319;&#26679;&#29575;&#65292;&#24182;&#36890;&#36807;&#21160;&#24577;&#22768;&#38899;&#35302;&#21457;&#22120;&#65288;&#27604;&#22914;&#25293;&#25163;&#22768;&#65289;&#23545;&#35828;&#35805;&#32773;&#36523;&#20221;&#36827;&#34892;&#25513;&#30422;&#65292;&#21487;&#20197;&#27450;&#39575;&#35821;&#38899;&#35782;&#21035;&#31995;&#32479;&#65288;ASR&#65289;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#27979;&#35797;&#34920;&#26126;&#65292;DynamicTrigger&#22312;&#38544;&#34109;&#25915;&#20987;&#20013;&#26082;&#26377;&#25928;&#21448;&#38544;&#34109;&#65292;&#24182;&#22312;&#25915;&#20987;&#36807;&#31243;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The area of Machine Learning as a Service (MLaaS) is experiencing increased implementation due to recent advancements in the AI (Artificial Intelligence) industry. However, this spike has prompted concerns regarding AI defense mechanisms, specifically regarding potential covert attacks from third-party providers that cannot be entirely trusted. Recent research has uncovered that auditory backdoors may use certain modifications as their initiating mechanism. DynamicTrigger is introduced as a methodology for carrying out dynamic backdoor attacks that use cleverly designed tweaks to ensure that corrupted samples are indistinguishable from clean. By utilizing fluctuating signal sampling rates and masking speaker identities through dynamic sound triggers (such as the clapping of hands), it is possible to deceive speech recognition systems (ASR). Our empirical testing demonstrates that DynamicTrigger is both potent and stealthy, achieving impressive success rates during covert attacks while 
&lt;/p&gt;</description></item><item><title>CyberForce&#26159;&#19968;&#20010;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#29289;&#32852;&#32593;&#35774;&#22791;&#20013;&#21327;&#21516;&#31169;&#23494;&#22320;&#30830;&#23450;&#36866;&#21512;&#32531;&#35299;&#21508;&#31181;&#38646;&#26085;&#25915;&#20987;&#30340;MTD&#25216;&#26415;&#12290;&#23427;&#25972;&#21512;&#20102;&#35774;&#22791;&#25351;&#32441;&#35782;&#21035;&#21644;&#24322;&#24120;&#26816;&#27979;&#65292;&#24182;&#36890;&#36807;&#22870;&#21169;&#25110;&#24809;&#32602;FRL agent&#36873;&#25321;&#30340;MTD&#26426;&#21046;&#26469;&#25552;&#39640;&#32593;&#32476;&#23433;&#20840;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05978</link><description>&lt;p&gt;
CyberForce: &#19968;&#20010;&#29992;&#20110;&#24694;&#24847;&#36719;&#20214;&#32531;&#35299;&#30340;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
CyberForce: A Federated Reinforcement Learning Framework for Malware Mitigation. (arXiv:2308.05978v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05978
&lt;/p&gt;
&lt;p&gt;
CyberForce&#26159;&#19968;&#20010;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#29289;&#32852;&#32593;&#35774;&#22791;&#20013;&#21327;&#21516;&#31169;&#23494;&#22320;&#30830;&#23450;&#36866;&#21512;&#32531;&#35299;&#21508;&#31181;&#38646;&#26085;&#25915;&#20987;&#30340;MTD&#25216;&#26415;&#12290;&#23427;&#25972;&#21512;&#20102;&#35774;&#22791;&#25351;&#32441;&#35782;&#21035;&#21644;&#24322;&#24120;&#26816;&#27979;&#65292;&#24182;&#36890;&#36807;&#22870;&#21169;&#25110;&#24809;&#32602;FRL agent&#36873;&#25321;&#30340;MTD&#26426;&#21046;&#26469;&#25552;&#39640;&#32593;&#32476;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#32852;&#32593;&#29289;&#32852;&#32593;(IoT)&#33539;&#20363;&#30340;&#25193;&#23637;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#20294;&#26159;&#23545;&#20110;IoT&#35774;&#22791;&#23545;&#24694;&#24847;&#36719;&#20214;&#20107;&#20214;&#30340;&#33030;&#24369;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#36234;&#26469;&#36234;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#23558;&#24378;&#21270;&#23398;&#20064;&#19982;&#31227;&#21160;&#30446;&#26631;&#38450;&#24481;(MTD)&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#22686;&#24378;IoT&#35774;&#22791;&#30340;&#32593;&#32476;&#23433;&#20840;&#24615;&#12290;&#28982;&#32780;&#65292;&#22823;&#37327;&#30340;&#26032;&#24694;&#24847;&#36719;&#20214;&#25915;&#20987;&#21644;&#20195;&#29702;&#20154;&#23398;&#20064;&#21644;&#36873;&#25321;&#26377;&#25928;&#30340;MTD&#25216;&#26415;&#25152;&#38656;&#30340;&#26102;&#38388;&#20351;&#24471;&#36825;&#31181;&#26041;&#27861;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;IoT&#22330;&#26223;&#20013;&#19981;&#20999;&#23454;&#38469;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CyberForce&#65292;&#19968;&#20010;&#37319;&#29992;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;(FRL)&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#38598;&#20307;&#19988;&#20445;&#23494;&#22320;&#30830;&#23450;&#36866;&#21512;&#32531;&#35299;&#21508;&#31181;&#38646;&#26085;&#25915;&#20987;&#30340;MTD&#25216;&#26415;&#12290;CyberForce&#32467;&#21512;&#20102;&#35774;&#22791;&#25351;&#32441;&#35782;&#21035;&#21644;&#24322;&#24120;&#26816;&#27979;&#65292;&#36890;&#36807;&#22870;&#21169;&#25110;&#24809;&#32602;FRL agent&#36873;&#25321;&#30340;MTD&#26426;&#21046;&#12290;&#35813;&#26694;&#26550;&#22312;&#19968;&#20010;&#30001;&#21313;&#21488;&#30495;&#23454;IoT&#24179;&#21488;&#35774;&#22791;&#32452;&#25104;&#30340;&#32852;&#37030;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#36890;&#36807;&#20845;&#20010;&#24694;&#24847;&#36719;&#20214;&#26679;&#26412;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
The expansion of the Internet-of-Things (IoT) paradigm is inevitable, but vulnerabilities of IoT devices to malware incidents have become an increasing concern. Recent research has shown that the integration of Reinforcement Learning with Moving Target Defense (MTD) mechanisms can enhance cybersecurity in IoT devices. Nevertheless, the numerous new malware attacks and the time that agents take to learn and select effective MTD techniques make this approach impractical for real-world IoT scenarios. To tackle this issue, this work presents CyberForce, a framework that employs Federated Reinforcement Learning (FRL) to collectively and privately determine suitable MTD techniques for mitigating diverse zero-day attacks. CyberForce integrates device fingerprinting and anomaly detection to reward or penalize MTD mechanisms chosen by an FRL-based agent. The framework has been evaluated in a federation consisting of ten devices of a real IoT platform. A pool of experiments with six malware samp
&lt;/p&gt;</description></item></channel></rss>