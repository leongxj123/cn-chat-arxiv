<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#37319;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#22914;&#20309;&#20998;&#37197;&#38544;&#31169;&#39044;&#31639;&#65292;&#20197;&#21450;&#24433;&#21709;&#20998;&#37197;&#30340;&#22240;&#32032;&#12290;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22411;&#36866;&#21512;&#20110;&#19981;&#21516;&#30340;&#20219;&#21153;&#21644;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2305.10994</link><description>&lt;p&gt;
&#29702;&#35299;&#24046;&#20998;&#38544;&#31169;&#29983;&#25104;&#27169;&#22411;&#22914;&#20309;&#20351;&#29992;&#38544;&#31169;&#39044;&#31639;
&lt;/p&gt;
&lt;p&gt;
Understanding how Differentially Private Generative Models Spend their Privacy Budget. (arXiv:2305.10994v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#37319;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#22914;&#20309;&#20998;&#37197;&#38544;&#31169;&#39044;&#31639;&#65292;&#20197;&#21450;&#24433;&#21709;&#20998;&#37197;&#30340;&#22240;&#32032;&#12290;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22411;&#36866;&#21512;&#20110;&#19981;&#21516;&#30340;&#20219;&#21153;&#21644;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#20135;&#29983;&#21512;&#25104;&#25968;&#25454;&#65292;&#21516;&#26102;&#20943;&#23569;&#38544;&#31169;&#39118;&#38505;&#12290;&#20294;&#26159;&#22312;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#20013;&#25214;&#21040;&#26368;&#36866;&#21512;&#30340;&#27169;&#22411;&#65292;&#38656;&#35201;&#26435;&#34913;&#23427;&#20204;&#20043;&#38388;&#30340;&#38544;&#31169;-&#25928;&#29992;&#20851;&#31995;&#12290;&#26412;&#25991;&#38024;&#23545;&#34920;&#26684;&#25968;&#25454;&#65292;&#20998;&#26512;&#20102;DP&#29983;&#25104;&#27169;&#22411;&#22914;&#20309;&#20998;&#37197;&#38544;&#31169;&#39044;&#31639;&#65292;&#24182;&#25506;&#35752;&#20102;&#24433;&#21709;&#38544;&#31169;&#39044;&#31639;&#20998;&#37197;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#25105;&#20204;&#23545;&#22270;&#24418;&#21644;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#36866;&#29992;&#20110;&#19981;&#21516;&#35774;&#32622;&#21644;&#20219;&#21153;&#30340;&#29420;&#29305;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models trained with Differential Privacy (DP) are increasingly used to produce synthetic data while reducing privacy risks. Navigating their specific privacy-utility tradeoffs makes it challenging to determine which models would work best for specific settings/tasks. In this paper, we fill this gap in the context of tabular data by analyzing how DP generative models distribute privacy budgets across rows and columns, arguably the main source of utility degradation. We examine the main factors contributing to how privacy budgets are spent, including underlying modeling techniques, DP mechanisms, and data dimensionality.  Our extensive evaluation of both graphical and deep generative models sheds light on the distinctive features that render them suitable for different settings and tasks. We show that graphical models distribute the privacy budget horizontally and thus cannot handle relatively wide datasets while the performance on the task they were optimized for monotonicall
&lt;/p&gt;</description></item></channel></rss>