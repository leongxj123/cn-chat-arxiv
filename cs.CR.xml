<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#30740;&#31350;&#20102;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#22797;&#26434;&#26597;&#35810;&#30340;&#32852;&#37030;&#24335;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#38544;&#31169;&#20445;&#25252;&#21644;&#31572;&#26696;&#26816;&#32034;&#30340;&#25361;&#25112;</title><link>https://arxiv.org/abs/2402.14609</link><description>&lt;p&gt;
&#32852;&#37030;&#24335;&#22797;&#26434;&#26597;&#35810;&#31572;&#26696;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Federated Complex Qeury Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14609
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#22797;&#26434;&#26597;&#35810;&#30340;&#32852;&#37030;&#24335;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#38544;&#31169;&#20445;&#25252;&#21644;&#31572;&#26696;&#26816;&#32034;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#22797;&#26434;&#36923;&#36753;&#26597;&#35810;&#31572;&#26696;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#25191;&#34892;&#22797;&#26434;&#36923;&#36753;&#25512;&#29702;&#30340;&#33021;&#21147;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#22522;&#20110;&#22270;&#25512;&#29702;&#30340;&#19979;&#28216;&#20219;&#21153;&#65292;&#27604;&#22914;&#25628;&#32034;&#24341;&#25806;&#12290;&#26368;&#36817;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#65292;&#23558;&#30693;&#35782;&#22270;&#35889;&#23454;&#20307;&#21644;&#36923;&#36753;&#26597;&#35810;&#34920;&#31034;&#20026;&#23884;&#20837;&#21521;&#37327;&#65292;&#24182;&#20174;&#30693;&#35782;&#22270;&#35889;&#20013;&#25214;&#21040;&#36923;&#36753;&#26597;&#35810;&#30340;&#31572;&#26696;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#26597;&#35810;&#21333;&#20010;&#30693;&#35782;&#22270;&#35889;&#19978;&#65292;&#24182;&#19981;&#33021;&#24212;&#29992;&#20110;&#22810;&#20010;&#22270;&#24418;&#12290;&#27492;&#22806;&#65292;&#30452;&#25509;&#20849;&#20139;&#24102;&#26377;&#25935;&#24863;&#20449;&#24687;&#30340;&#30693;&#35782;&#22270;&#35889;&#21487;&#33021;&#20250;&#24102;&#26469;&#38544;&#31169;&#39118;&#38505;&#65292;&#20351;&#24471;&#20849;&#20139;&#21644;&#26500;&#24314;&#19968;&#20010;&#32858;&#21512;&#30693;&#35782;&#22270;&#35889;&#29992;&#20110;&#25512;&#29702;&#20197;&#26816;&#32034;&#26597;&#35810;&#31572;&#26696;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#22240;&#27492;&#65292;&#30446;&#21069;&#20173;&#28982;&#19981;&#28165;&#26970;&#22914;&#20309;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#26597;&#35810;&#12290;&#19968;&#20010;&#23454;&#20307;&#21487;&#33021;&#28041;&#21450;&#21040;&#22810;&#20010;&#30693;&#35782;&#22270;&#35889;&#65292;&#23545;&#22810;&#20010;&#30693;&#35782;&#22270;&#35889;&#36827;&#34892;&#25512;&#29702;&#65292;&#24182;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#22797;&#26434;&#26597;&#35810;&#23545;&#20110;&#21457;&#29616;&#30693;&#35782;&#26159;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14609v1 Announce Type: cross  Abstract: Complex logical query answering is a challenging task in knowledge graphs (KGs) that has been widely studied. The ability to perform complex logical reasoning is essential and supports various graph reasoning-based downstream tasks, such as search engines. Recent approaches are proposed to represent KG entities and logical queries into embedding vectors and find answers to logical queries from the KGs. However, existing proposed methods mainly focus on querying a single KG and cannot be applied to multiple graphs. In addition, directly sharing KGs with sensitive information may incur privacy risks, making it impractical to share and construct an aggregated KG for reasoning to retrieve query answers. Thus, it remains unknown how to answer queries on multi-source KGs. An entity can be involved in various knowledge graphs and reasoning on multiple KGs and answering complex queries on multi-source KGs is important in discovering knowledge 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#20844;&#27491;&#32422;&#26463;&#23398;&#20064;&#23545;&#24694;&#24847;&#22122;&#22768;&#30340;&#33030;&#24369;&#24615;&#65292;&#21457;&#29616;&#20351;&#29992;&#38543;&#26426;&#20998;&#31867;&#22120;&#21487;&#20197;&#22312;&#31934;&#24230;&#19978;&#21482;&#25439;&#22833;$\Theta(\alpha)$&#21644;$O(\sqrt{\alpha})$&#65292;&#23545;&#24212;&#19981;&#21516;&#30340;&#20844;&#27491;&#32422;&#26463;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2307.11892</link><description>&lt;p&gt;
&#20851;&#20110;&#21463;&#24694;&#24847;&#22122;&#22768;&#24433;&#21709;&#30340;&#20844;&#27491;&#32422;&#26463;&#23398;&#20064;&#30340;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Vulnerability of Fairness Constrained Learning to Malicious Noise. (arXiv:2307.11892v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11892
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#20844;&#27491;&#32422;&#26463;&#23398;&#20064;&#23545;&#24694;&#24847;&#22122;&#22768;&#30340;&#33030;&#24369;&#24615;&#65292;&#21457;&#29616;&#20351;&#29992;&#38543;&#26426;&#20998;&#31867;&#22120;&#21487;&#20197;&#22312;&#31934;&#24230;&#19978;&#21482;&#25439;&#22833;$\Theta(\alpha)$&#21644;$O(\sqrt{\alpha})$&#65292;&#23545;&#24212;&#19981;&#21516;&#30340;&#20844;&#27491;&#32422;&#26463;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#20844;&#27491;&#32422;&#26463;&#23398;&#20064;&#23545;&#35757;&#32451;&#25968;&#25454;&#20013;&#24494;&#23567;&#24694;&#24847;&#22122;&#22768;&#30340;&#33030;&#24369;&#24615;&#12290;Konstantinov&#21644;Lampert (2021)&#22312;&#36825;&#20010;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#23637;&#31034;&#20102;&#36127;&#38754;&#32467;&#26524;&#65292;&#34920;&#26126;&#22312;&#19981;&#24179;&#34913;&#30340;&#32676;&#32452;&#22823;&#23567;&#19979;&#23384;&#22312;&#19968;&#20123;&#25968;&#25454;&#20998;&#24067;&#65292;&#20219;&#20309;&#36866;&#24403;&#30340;&#23398;&#20064;&#22120;&#37117;&#20250;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#33030;&#24369;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26356;&#20048;&#35266;&#30340;&#35266;&#28857;&#65292;&#22914;&#26524;&#20801;&#35768;&#38543;&#26426;&#20998;&#31867;&#22120;&#65292;&#21017;&#24773;&#20917;&#26356;&#21152;&#32454;&#33268;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#20154;&#21475;&#32479;&#35745;&#23398;&#24179;&#31561;&#24615;&#65292;&#25105;&#20204;&#26174;&#31034;&#21482;&#20250;&#20135;&#29983;$\Theta(\alpha)$&#30340;&#31934;&#24230;&#25439;&#22833;&#65292;&#20854;&#20013;$\alpha$&#26159;&#24694;&#24847;&#22122;&#22768;&#29575;&#65292;&#29978;&#33267;&#21487;&#20197;&#19982;&#27809;&#26377;&#20844;&#27491;&#32422;&#26463;&#30340;&#24773;&#20917;&#23436;&#20840;&#21305;&#37197;&#12290;&#23545;&#20110;&#26426;&#20250;&#22343;&#31561;&#24615;&#65292;&#25105;&#20204;&#26174;&#31034;&#21482;&#20250;&#20135;&#29983;$O(\sqrt{\alpha})$&#30340;&#25439;&#22833;&#65292;&#24182;&#32473;&#20986;&#19968;&#20010;&#21305;&#37197;&#30340;$\Omega(\sqrt{\alpha})$&#30340;&#19979;&#30028;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;Konstantinov&#21644;Lampert (2021)&#31034;&#33539;&#20102;&#23545;&#20110;&#36866;&#24403;&#30340;&#23398;&#20064;&#22120;&#65292;&#36825;&#20004;&#20010;&#27010;&#24565;&#30340;&#31934;&#24230;&#25439;&#22833;&#37117;&#26159;$\Omega(1)$&#12290;&#20851;&#38190;&#30340;&#25216;&#26415;&#21019;&#26032;&#26159;
&lt;/p&gt;
&lt;p&gt;
We consider the vulnerability of fairness-constrained learning to small amounts of malicious noise in the training data. Konstantinov and Lampert (2021) initiated the study of this question and presented negative results showing there exist data distributions where for several fairness constraints, any proper learner will exhibit high vulnerability when group sizes are imbalanced. Here, we present a more optimistic view, showing that if we allow randomized classifiers, then the landscape is much more nuanced. For example, for Demographic Parity we show we can incur only a $\Theta(\alpha)$ loss in accuracy, where $\alpha$ is the malicious noise rate, matching the best possible even without fairness constraints. For Equal Opportunity, we show we can incur an $O(\sqrt{\alpha})$ loss, and give a matching $\Omega(\sqrt{\alpha})$lower bound. In contrast, Konstantinov and Lampert (2021) showed for proper learners the loss in accuracy for both notions is $\Omega(1)$. The key technical novelty 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#36866;&#24212;&#30340;&#27979;&#35797;&#38450;&#24481;&#31574;&#30053;&#65292;&#36890;&#36807;&#25237;&#24433;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#21040;&#26368;&#31283;&#20581;&#30340;&#29305;&#24449;&#31354;&#38388;&#65292;&#38477;&#20302;&#20102;&#23545;&#25239;&#25915;&#20987;&#30340;&#33030;&#24369;&#24615;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27979;&#35797;&#26102;&#38388;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2307.11672</link><description>&lt;p&gt;
&#24555;&#36895;&#33258;&#36866;&#24212;&#27979;&#35797;&#38450;&#24481;&#19982;&#31283;&#20581;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Fast Adaptive Test-Time Defense with Robust Features. (arXiv:2307.11672v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#36866;&#24212;&#30340;&#27979;&#35797;&#38450;&#24481;&#31574;&#30053;&#65292;&#36890;&#36807;&#25237;&#24433;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#21040;&#26368;&#31283;&#20581;&#30340;&#29305;&#24449;&#31354;&#38388;&#65292;&#38477;&#20302;&#20102;&#23545;&#25239;&#25915;&#20987;&#30340;&#33030;&#24369;&#24615;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27979;&#35797;&#26102;&#38388;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#30340;&#27979;&#35797;&#38450;&#24481;&#34987;&#29992;&#26469;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#30001;&#20110;&#23545;&#27169;&#22411;&#21442;&#25968;&#25110;&#36755;&#20837;&#36827;&#34892;&#39069;&#22806;&#30340;&#20248;&#21270;&#23548;&#33268;&#25512;&#29702;&#26102;&#38388;&#22823;&#24133;&#22686;&#21152;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#27979;&#35797;&#38450;&#24481;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#19982;&#20219;&#20309;&#29616;&#26377;&#65288;&#31283;&#20581;&#30340;&#65289;&#35757;&#32451;&#36807;&#31243;&#36731;&#26494;&#38598;&#25104;&#65292;&#24182;&#19988;&#26080;&#38656;&#39069;&#22806;&#30340;&#27979;&#35797;&#26102;&#38388;&#35745;&#31639;&#12290;&#22522;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#29305;&#24449;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#25237;&#24433;&#21040;&#26368;&#31283;&#20581;&#30340;&#29305;&#24449;&#31354;&#38388;&#65292;&#20174;&#32780;&#38477;&#20302;&#23545;&#38750;&#31283;&#20581;&#26041;&#21521;&#30340;&#23545;&#25239;&#25915;&#20987;&#30340;&#33030;&#24369;&#24615;&#12290;&#25105;&#20204;&#22312;&#24191;&#20041;&#21487;&#21152;&#24615;&#27169;&#22411;&#21644;&#20351;&#29992;&#31070;&#32463;&#20999;&#21521;&#26680;&#20989;&#25968;&#65288;NTK&#65289;&#31561;&#20215;&#27861;&#35777;&#26126;&#20102;&#29305;&#24449;&#30697;&#38453;&#30340;&#39030;&#23618;&#29305;&#24449;&#31354;&#38388;&#26356;&#21152;&#31283;&#20581;&#12290;&#25105;&#20204;&#22312;CIFAR-10&#21644;CIFAR-100&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#29992;&#20110;&#20960;&#20010;&#31283;&#20581;&#24615;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adaptive test-time defenses are used to improve the robustness of deep neural networks to adversarial examples. However, existing methods significantly increase the inference time due to additional optimization on the model parameters or the input at test time. In this work, we propose a novel adaptive test-time defense strategy that is easy to integrate with any existing (robust) training procedure without additional test-time computation. Based on the notion of robustness of features that we present, the key idea is to project the trained models to the most robust feature space, thereby reducing the vulnerability to adversarial attacks in non-robust directions. We theoretically show that the top eigenspace of the feature matrix are more robust for a generalized additive model and support our argument for a large width neural network with the Neural Tangent Kernel (NTK) equivalence. We conduct extensive experiments on CIFAR-10 and CIFAR-100 datasets for several robustness benchmarks, 
&lt;/p&gt;</description></item></channel></rss>