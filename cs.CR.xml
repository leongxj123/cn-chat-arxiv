<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;, Feedback-Driven Solution Synthesis (FDSS), &#26088;&#22312;&#36890;&#36807;&#23558;LLMs&#19982;&#38745;&#24577;&#20195;&#30721;&#20998;&#26512;&#24037;&#20855;Bandit&#32467;&#21512;&#65292;&#35299;&#20915;&#20195;&#30721;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#26377;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PythonSecurityEval&#12290;</title><link>http://arxiv.org/abs/2312.00024</link><description>&lt;p&gt;
LLMs&#33021;&#22815;&#20462;&#22797;&#23433;&#20840;&#38382;&#39064;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can LLMs Patch Security Issues?. (arXiv:2312.00024v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.00024
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;, Feedback-Driven Solution Synthesis (FDSS), &#26088;&#22312;&#36890;&#36807;&#23558;LLMs&#19982;&#38745;&#24577;&#20195;&#30721;&#20998;&#26512;&#24037;&#20855;Bandit&#32467;&#21512;&#65292;&#35299;&#20915;&#20195;&#30721;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#26377;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PythonSecurityEval&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#20195;&#30721;&#29983;&#25104;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#24320;&#21457;&#32773;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#20250;&#29983;&#25104;&#21253;&#21547;&#23433;&#20840;&#28431;&#27934;&#21644;&#32570;&#38519;&#30340;&#20195;&#30721;&#12290;&#32534;&#20889;&#23433;&#20840;&#20195;&#30721;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#28431;&#27934;&#36890;&#24120;&#22312;&#31243;&#24207;&#19982;&#22806;&#37096;&#31995;&#32479;&#25110;&#26381;&#21153;&#65288;&#22914;&#25968;&#25454;&#24211;&#21644;&#25805;&#20316;&#31995;&#32479;&#65289;&#20043;&#38388;&#30340;&#20132;&#20114;&#36807;&#31243;&#20013;&#20986;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#21453;&#39304;&#30340;&#35299;&#20915;&#26041;&#26696;&#21512;&#25104;&#65288;FDSS&#65289;&#65292;&#26088;&#22312;&#25506;&#32034;&#20351;&#29992;LLMs&#25509;&#25910;&#26469;&#33258;&#38745;&#24577;&#20195;&#30721;&#20998;&#26512;&#24037;&#20855;Bandit&#30340;&#21453;&#39304;&#65292;&#28982;&#21518;LLMs&#29983;&#25104;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#26469;&#35299;&#20915;&#23433;&#20840;&#28431;&#27934;&#12290;&#27599;&#20010;&#35299;&#20915;&#26041;&#26696;&#20197;&#21450;&#26131;&#21463;&#25915;&#20987;&#30340;&#20195;&#30721;&#38543;&#21518;&#34987;&#36865;&#22238;LLMs&#36827;&#34892;&#20195;&#30721;&#23436;&#21892;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22522;&#32447;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PythonSecurityEval&#65292;&#35813;&#25968;&#25454;&#38598;&#25910;&#38598;&#20102;&#26469;&#33258;Stack Overflow&#30340;&#30495;&#23454;&#22330;&#26223;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown impressive proficiency in code generation. Nonetheless, similar to human developers, these models might generate code that contains security vulnerabilities and flaws. Writing secure code remains a substantial challenge, as vulnerabilities often arise during interactions between programs and external systems or services, such as databases and operating systems. In this paper, we propose a novel approach, Feedback-Driven Solution Synthesis (FDSS), designed to explore the use of LLMs in receiving feedback from Bandit, which is a static code analysis tool, and then the LLMs generate potential solutions to resolve security vulnerabilities. Each solution, along with the vulnerable code, is then sent back to the LLM for code refinement. Our approach shows a significant improvement over the baseline and outperforms existing approaches. Furthermore, we introduce a new dataset, PythonSecurityEval, collected from real-world scenarios on Stack Overflow to e
&lt;/p&gt;</description></item></channel></rss>