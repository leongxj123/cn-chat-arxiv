<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38544;&#31169;&#25935;&#24863;&#39046;&#22495;&#20013;&#22914;&#20309;&#35774;&#35745;&#19968;&#31181;FL&#21327;&#35758;&#65292;&#26082;&#33021;&#20445;&#35777;&#38544;&#31169;&#65292;&#21448;&#33021;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#35774;&#35745;&#20986;&#23545;&#25152;&#26377;&#21442;&#19982;&#32773;&#37117;&#26377;&#30410;&#22788;&#30340;&#21327;&#35758;&#12290;</title><link>https://arxiv.org/abs/2403.06672</link><description>&lt;p&gt;
&#22312;&#38544;&#31169;&#25935;&#24863;&#39046;&#22495;&#20013;&#20174;&#32852;&#37030;&#23398;&#20064;&#20013;&#26377;&#21487;&#35777;&#26126;&#30340;&#20114;&#24800;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38544;&#31169;&#25935;&#24863;&#39046;&#22495;&#20013;&#22914;&#20309;&#35774;&#35745;&#19968;&#31181;FL&#21327;&#35758;&#65292;&#26082;&#33021;&#20445;&#35777;&#38544;&#31169;&#65292;&#21448;&#33021;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#35774;&#35745;&#20986;&#23545;&#25152;&#26377;&#21442;&#19982;&#32773;&#37117;&#26377;&#30410;&#22788;&#30340;&#21327;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20801;&#35768;&#25968;&#25454;&#25152;&#26377;&#32773;&#36890;&#36807;&#20174;&#24444;&#27492;&#30340;&#31169;&#26377;&#25968;&#25454;&#38598;&#20013;&#33719;&#30410;&#26469;&#35757;&#32451;&#20934;&#30830;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#26381;&#21153;&#22120;&#21487;&#20197;&#35774;&#35745;&#19968;&#31181;&#23545;&#25152;&#26377;&#21442;&#19982;&#32773;&#37117;&#26377;&#21033;&#30340;FL&#21327;&#35758;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#22343;&#20540;&#20272;&#35745;&#21644;&#20984;&#38543;&#26426;&#20248;&#21270;&#32972;&#26223;&#19979;&#23384;&#22312;&#30456;&#20114;&#26377;&#21033;&#21327;&#35758;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#23545;&#31216;&#38544;&#31169;&#20559;&#22909;&#19979;&#65292;&#26368;&#22823;&#21270;&#24635;&#23458;&#25143;&#25928;&#29992;&#30340;&#21327;&#35758;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#26368;&#22823;&#21270;&#26368;&#32456;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#21327;&#35758;&#65292;&#24182;&#22312;&#21512;&#25104;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06672v1 Announce Type: cross  Abstract: Cross-silo federated learning (FL) allows data owners to train accurate machine learning models by benefiting from each others private datasets. Unfortunately, the model accuracy benefits of collaboration are often undermined by privacy defenses. Therefore, to incentivize client participation in privacy-sensitive domains, a FL protocol should strike a delicate balance between privacy guarantees and end-model accuracy. In this paper, we study the question of when and how a server could design a FL protocol provably beneficial for all participants. First, we provide necessary and sufficient conditions for the existence of mutually beneficial protocols in the context of mean estimation and convex stochastic optimization. We also derive protocols that maximize the total clients' utility, given symmetric privacy preferences. Finally, we design protocols maximizing end-model accuracy and demonstrate their benefits in synthetic experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.00867</link><description>&lt;p&gt;
&#26799;&#24230;&#34987;&#32602;&#65306;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#38024;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#27491;&#25104;&#20026;&#19968;&#31181;&#31361;&#20986;&#30340;&#29983;&#25104;&#24335;AI&#24037;&#20855;&#65292;&#29992;&#25143;&#36755;&#20837;&#26597;&#35810;&#65292;LLM&#29983;&#25104;&#31572;&#26696;&#12290;&#20026;&#20102;&#20943;&#23569;&#20260;&#23475;&#21644;&#28389;&#29992;&#65292;&#20154;&#20204;&#36890;&#36807;&#20351;&#29992;&#20808;&#36827;&#30340;&#35757;&#32451;&#25216;&#26415;&#22914;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26469;&#23558;&#36825;&#20123;LLMs&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#31361;&#26174;&#20102;LLMs&#23545;&#20110;&#35797;&#22270;&#39072;&#35206;&#23884;&#20837;&#30340;&#23433;&#20840;&#38450;&#25252;&#25514;&#26045;&#30340;&#23545;&#25239;&#24615;&#36234;&#29425;&#23581;&#35797;&#30340;&#33030;&#24369;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#23450;&#20041;&#24182;&#35843;&#26597;&#20102;LLMs&#30340;&#25298;&#32477;&#25439;&#22833;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#36234;&#29425;&#23581;&#35797;&#12290;Gradient Cuff&#21033;&#29992;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#20013;&#35266;&#23519;&#21040;&#30340;&#29420;&#29305;&#29305;&#24615;&#65292;&#21253;&#25324;&#21151;&#33021;&#20540;&#21450;&#20854;&#20809;&#28369;&#24615;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00867v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN,
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#30456;&#20851;&#36755;&#20837;&#25200;&#21160;&#30340;&#24046;&#20998;&#38544;&#31169;&#33539;&#22260;&#26597;&#35810;&#30340;&#23616;&#37096;&#26426;&#21046;&#65292;&#36890;&#36807;&#32423;&#32852;&#37319;&#26679;&#31639;&#27861;&#23454;&#29616;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#20445;&#38556;&#36817;&#20046;&#26368;&#20248;&#30340;&#25928;&#29992;&#30340;&#21516;&#26102;&#65292;&#19982;&#36755;&#20986;&#25200;&#21160;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07066</link><description>&lt;p&gt;
&#20855;&#26377;&#30456;&#20851;&#36755;&#20837;&#25200;&#21160;&#30340;&#24046;&#20998;&#38544;&#31169;&#33539;&#22260;&#26597;&#35810;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Range Queries with Correlated Input Perturbation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#30456;&#20851;&#36755;&#20837;&#25200;&#21160;&#30340;&#24046;&#20998;&#38544;&#31169;&#33539;&#22260;&#26597;&#35810;&#30340;&#23616;&#37096;&#26426;&#21046;&#65292;&#36890;&#36807;&#32423;&#32852;&#37319;&#26679;&#31639;&#27861;&#23454;&#29616;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#20445;&#38556;&#36817;&#20046;&#26368;&#20248;&#30340;&#25928;&#29992;&#30340;&#21516;&#26102;&#65292;&#19982;&#36755;&#20986;&#25200;&#21160;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32447;&#24615;&#26597;&#35810;&#30340;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#29305;&#21035;&#26159;&#33539;&#22260;&#26597;&#35810;&#65292;&#21033;&#29992;&#30456;&#20851;&#36755;&#20837;&#25200;&#21160;&#21516;&#26102;&#23454;&#29616;&#26080;&#20559;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#32479;&#35745;&#36879;&#26126;&#24615;&#21644;&#23545;&#31934;&#24230;&#30446;&#26631;&#30340;&#25511;&#21046;&#65292;&#26080;&#35770;&#26159;&#22312;&#26576;&#20123;&#26597;&#35810;&#36793;&#32536;&#19978;&#36824;&#26159;&#22312;&#23618;&#27425;&#25968;&#25454;&#24211;&#32467;&#26500;&#25152;&#26263;&#31034;&#30340;&#31934;&#24230;&#35201;&#27714;&#19978;&#12290;&#25152;&#25552;&#20986;&#30340;&#32423;&#32852;&#37319;&#26679;&#31639;&#27861;&#20934;&#30830;&#39640;&#25928;&#22320;&#23454;&#29616;&#20102;&#35813;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#34920;&#26126;&#65292;&#25105;&#20204;&#22312;&#20445;&#38556;&#36817;&#20046;&#26368;&#20248;&#30340;&#25928;&#29992;&#30340;&#21516;&#26102;&#65292;&#19982;&#36755;&#20986;&#25200;&#21160;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work proposes a class of locally differentially private mechanisms for linear queries, in particular range queries, that leverages correlated input perturbation to simultaneously achieve unbiasedness, consistency, statistical transparency, and control over utility requirements in terms of accuracy targets expressed either in certain query margins or as implied by the hierarchical database structure. The proposed Cascade Sampling algorithm instantiates the mechanism exactly and efficiently. Our bounds show that we obtain near-optimal utility while being empirically competitive against output perturbation methods.
&lt;/p&gt;</description></item></channel></rss>