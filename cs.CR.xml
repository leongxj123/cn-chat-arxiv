<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934; StrongREJECT&#65292;&#36890;&#36807;&#20351;&#29992;&#26356;&#39640;&#36136;&#37327;&#30340;&#38382;&#39064;&#65292;&#26356;&#22909;&#22320;&#21306;&#20998;&#26377;&#25928;&#21644;&#26080;&#25928;&#30340;&#31354;&#30772;&#35299;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10260</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#31354;&#30772;&#35299;&#30340;&#24378;REJECT&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A StrongREJECT for Empty Jailbreaks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10260
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934; StrongREJECT&#65292;&#36890;&#36807;&#20351;&#29992;&#26356;&#39640;&#36136;&#37327;&#30340;&#38382;&#39064;&#65292;&#26356;&#22909;&#22320;&#21306;&#20998;&#26377;&#25928;&#21644;&#26080;&#25928;&#30340;&#31354;&#30772;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#24341;&#36215;&#20102;&#23545;&#8220;&#30772;&#35299;&#8221;&#30340;&#20851;&#27880;&#65292;&#36825;&#31181;&#30772;&#35299;&#20801;&#35768;&#27169;&#22411;&#34987;&#24694;&#24847;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27809;&#26377;&#26631;&#20934;&#30340;&#22522;&#20934;&#26469;&#34913;&#37327;&#30772;&#35299;&#30340;&#20005;&#37325;&#31243;&#24230;&#65292;&#23548;&#33268;&#30772;&#35299;&#35770;&#25991;&#30340;&#20316;&#32773;&#19981;&#24471;&#19981;&#33258;&#34892;&#21019;&#24314;&#26631;&#20934;&#12290;&#25105;&#20204;&#34920;&#26126;&#36825;&#20123;&#22522;&#20934;&#32463;&#24120;&#21253;&#21547;&#27169;&#26865;&#20004;&#21487;&#25110;&#26080;&#27861;&#22238;&#31572;&#30340;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#20542;&#21521;&#20110;&#39640;&#20272;&#20302;&#36136;&#37327;&#27169;&#22411;&#21709;&#24212;&#30340;&#28389;&#29992;&#28508;&#21147;&#30340;&#35780;&#20998;&#26631;&#20934;&#12290;&#19968;&#20123;&#30772;&#35299;&#25216;&#26415;&#20351;&#38382;&#39064;&#26356;&#21152;&#20005;&#37325;&#65292;&#22240;&#20026;&#23427;&#20204;&#21363;&#20351;&#23545;&#20110;&#33391;&#24615;&#38382;&#39064;&#20063;&#20250;&#38477;&#20302;&#27169;&#22411;&#21709;&#24212;&#30340;&#36136;&#37327;&#65306;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#31181;&#30772;&#35299;&#25216;&#26415;&#26174;&#30528;&#38477;&#20302;&#20102;GPT-4&#22312;MMLU&#19978;&#30340;&#38646;&#23556;&#20987;&#34920;&#29616;&#12290;&#30772;&#35299;&#36824;&#20250;&#20351;&#20174;&#8220;&#26410;&#32463;&#23457;&#26597;&#8221;&#30340;&#24320;&#28304;&#27169;&#22411;&#20013;&#33719;&#21462;&#26377;&#23475;&#21709;&#24212;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#65292;StrongREJECT&#65292;&#36890;&#36807;&#20351;&#29992;&#26356;&#39640;&#36136;&#37327;&#30340;&#38382;&#39064;&#26356;&#22909;&#22320;&#21306;&#20998;&#26377;&#25928;&#21644;&#26080;&#25928;&#30340;&#30772;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10260v1 Announce Type: cross  Abstract: The rise of large language models (LLMs) has drawn attention to the existence of "jailbreaks" that allow the models to be used maliciously. However, there is no standard benchmark for measuring the severity of a jailbreak, leaving authors of jailbreak papers to create their own. We show that these benchmarks often include vague or unanswerable questions and use grading criteria that are biased towards overestimating the misuse potential of low-quality model responses. Some jailbreak techniques make the problem worse by decreasing the quality of model responses even on benign questions: we show that several jailbreaking techniques substantially reduce the zero-shot performance of GPT-4 on MMLU. Jailbreaks can also make it harder to elicit harmful responses from an "uncensored" open-source model. We present a new benchmark, StrongREJECT, which better discriminates between effective and ineffective jailbreaks by using a higher-quality que
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20844;&#24179;&#20108;&#20998;&#31867;&#22120;&#20013;&#30340;&#38544;&#31169;&#23041;&#32961;&#65292;&#24182;&#25581;&#31034;&#20102;&#38024;&#23545;&#20844;&#24179;&#22686;&#24378;&#27169;&#22411;&#30340;&#22522;&#20110;&#20998;&#25968;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#26080;&#25928;&#24615;&#12290;&#21516;&#26102;&#65292;&#20844;&#24179;&#24615;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#35757;&#32451;&#25968;&#25454;&#20013;&#22823;&#22810;&#25968;&#23376;&#32676;&#20307;&#30340;&#39044;&#27979;&#24615;&#33021;&#19979;&#38477;&#12290;</title><link>http://arxiv.org/abs/2311.03865</link><description>&lt;p&gt;
&#24403;&#20844;&#24179;&#24615;&#36935;&#35265;&#38544;&#31169;&#65306;&#36890;&#36807;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#25506;&#32034;&#20844;&#24179;&#20108;&#20998;&#31867;&#22120;&#20013;&#30340;&#38544;&#31169;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
When Fairness Meets Privacy: Exploring Privacy Threats in Fair Binary Classifiers through Membership Inference Attacks. (arXiv:2311.03865v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.03865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20844;&#24179;&#20108;&#20998;&#31867;&#22120;&#20013;&#30340;&#38544;&#31169;&#23041;&#32961;&#65292;&#24182;&#25581;&#31034;&#20102;&#38024;&#23545;&#20844;&#24179;&#22686;&#24378;&#27169;&#22411;&#30340;&#22522;&#20110;&#20998;&#25968;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#26080;&#25928;&#24615;&#12290;&#21516;&#26102;&#65292;&#20844;&#24179;&#24615;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#35757;&#32451;&#25968;&#25454;&#20013;&#22823;&#22810;&#25968;&#23376;&#32676;&#20307;&#30340;&#39044;&#27979;&#24615;&#33021;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#24320;&#21457;&#20102;&#38024;&#23545;&#20855;&#26377;&#27495;&#35270;&#34892;&#20026;&#30340;&#26377;&#20559;&#27169;&#22411;&#30340;&#20844;&#24179;&#26041;&#27861;&#65292;&#20197;&#36798;&#21040;&#20844;&#24179;&#39044;&#27979;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#22312;&#22522;&#20110;&#20998;&#25968;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#20013;&#23384;&#22312;&#28508;&#22312;&#30340;&#28431;&#27934;&#12290;&#22312;&#36825;&#20123;&#25915;&#20987;&#20013;&#65292;&#23545;&#25163;&#21487;&#20197;&#36890;&#36807;&#20998;&#26512;&#27169;&#22411;&#30340;&#39044;&#27979;&#20998;&#25968;&#25512;&#26029;&#20986;&#29305;&#23450;&#25968;&#25454;&#26679;&#26412;&#26159;&#21542;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#35843;&#26597;&#21457;&#29616;&#65292;&#38024;&#23545;&#20844;&#24179;&#22686;&#24378;&#27169;&#22411;&#30340;&#22522;&#20110;&#20998;&#25968;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26159;&#26080;&#25928;&#30340;&#12290;&#38024;&#23545;&#36825;&#20123;&#25915;&#20987;&#35757;&#32451;&#30340;&#27169;&#22411;&#36864;&#21270;&#20026;&#31616;&#21333;&#30340;&#38408;&#20540;&#27169;&#22411;&#65292;&#20174;&#32780;&#23548;&#33268;&#25915;&#20987;&#24615;&#33021;&#38477;&#20302;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20844;&#24179;&#24615;&#26041;&#27861;&#24448;&#24448;&#23548;&#33268;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#22823;&#22810;&#25968;&#23376;&#32676;&#20307;&#30340;&#39044;&#27979;&#24615;&#33021;&#19979;&#38477;&#12290;&#36825;&#25552;&#39640;&#20102;&#25104;&#21151;&#25915;&#20987;&#30340;&#38590;&#24230;&#65292;&#21516;&#26102;&#25193;&#22823;&#20102;&#25104;&#21592;&#21644;&#38750;&#25104;&#21592;&#25968;&#25454;&#20043;&#38388;&#30340;&#39044;&#27979;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous studies have developed fairness methods for biased models that exhibit discriminatory behaviors towards specific subgroups. While these models have shown promise in achieving fair predictions, recent research has identified their potential vulnerability to score-based membership inference attacks (MIAs). In these attacks, adversaries can infer whether a particular data sample was used during training by analyzing the model's prediction scores. However, our investigations reveal that these score-based MIAs are ineffective when targeting fairness-enhanced models in binary classifications. The attack models trained to launch the MIAs degrade into simplistic threshold models, resulting in lower attack performance. Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SnD&#30340;&#21019;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#20445;&#25252;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#26029;&#38454;&#27573;&#30340;&#38544;&#31169;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#23458;&#25143;&#31471;&#19978;&#25191;&#34892;&#20196;&#29260;&#23884;&#20837;&#23618;&#21644;&#24341;&#20837;&#22122;&#22768;&#26469;&#20248;&#21270;&#38544;&#31169;-&#25928;&#29992;&#26435;&#34913;&#65292;&#26080;&#38656;&#20462;&#25913;&#27169;&#22411;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.09130</link><description>&lt;p&gt;
&#20351;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#20445;&#25252;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#26029;&#65306;&#25286;&#20998;&#19982;&#21435;&#22122;
&lt;/p&gt;
&lt;p&gt;
Split-and-Denoise: Protect large language model inference with local differential privacy. (arXiv:2310.09130v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09130
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SnD&#30340;&#21019;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#20445;&#25252;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#26029;&#38454;&#27573;&#30340;&#38544;&#31169;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#23458;&#25143;&#31471;&#19978;&#25191;&#34892;&#20196;&#29260;&#23884;&#20837;&#23618;&#21644;&#24341;&#20837;&#22122;&#22768;&#26469;&#20248;&#21270;&#38544;&#31169;-&#25928;&#29992;&#26435;&#34913;&#65292;&#26080;&#38656;&#20462;&#25913;&#27169;&#22411;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#25429;&#25417;&#21521;&#37327;&#31354;&#38388;&#20013;&#30340;&#38544;&#34255;&#35821;&#20041;&#65292;&#23637;&#31034;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#26041;&#38754;&#30340;&#24378;&#22823;&#33021;&#21147;&#12290;&#36825;&#19968;&#36807;&#31243;&#20016;&#23500;&#20102;&#25991;&#26412;&#23884;&#20837;&#30340;&#20215;&#20540;&#65292;&#20174;&#32780;&#20419;&#36827;&#20102;&#20316;&#20026;&#26381;&#21153;&#65288;EaaS&#65289;&#30340;&#23884;&#20837;&#27169;&#22411;&#21830;&#19994;&#27169;&#24335;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#23558;&#25991;&#26412;&#20256;&#36755;&#21040;&#26381;&#21153;&#22120;&#38754;&#20020;&#30528;&#36739;&#22823;&#30340;&#38544;&#31169;&#27844;&#38706;&#39118;&#38505;&#65292;&#36825;&#26159;&#19968;&#20010;&#23578;&#26410;&#24471;&#21040;&#26377;&#25928;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Split-N-Denoise&#65288;SnD&#65289;&#65292;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#23458;&#25143;&#31471;&#19978;&#20197;&#26368;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#25191;&#34892;&#20196;&#29260;&#23884;&#20837;&#23618;&#26469;&#25286;&#20998;&#27169;&#22411;&#12290;&#36825;&#20351;&#24471;&#23458;&#25143;&#31471;&#33021;&#22815;&#22312;&#23558;&#23884;&#20837;&#20256;&#36755;&#21040;&#26381;&#21153;&#22120;&#20043;&#21069;&#24341;&#20837;&#22122;&#22768;&#65292;&#24182;&#38543;&#21518;&#25509;&#25910;&#21644;&#21435;&#22122;&#21518;&#30340;&#25200;&#21160;&#36755;&#20986;&#23884;&#20837;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19987;&#20026;LLMs&#30340;&#25512;&#26029;&#38454;&#27573;&#35774;&#35745;&#65292;&#19981;&#38656;&#35201;&#20462;&#25913;&#27169;&#22411;&#21442;&#25968;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;SnD&#22312;&#21508;&#31181;LLM&#20013;&#20248;&#21270;&#38544;&#31169;-&#25928;&#29992;&#26435;&#34913;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) shows powerful capability in natural language understanding by capturing hidden semantics in vector space. This process enriches the value of the text embeddings for various downstream tasks, thereby fostering the Embedding-as-a-Service (EaaS) business model. However, the direct transmission of text to servers poses a largely unaddressed risk of privacy leakage. To mitigate this issue, we introduce Split-N-Denoise (SnD), an innovative framework that split the model to execute the token embedding layer on the client side at minimal computational cost. This allows the client to introduce noise prior to transmitting the embeddings to the server, and subsequently receive and denoise the perturbed output embeddings for downstream tasks. Our approach is designed for the inference stage of LLMs and requires no modifications to the model parameters. Extensive experiments demonstrate SnD's effectiveness in optimizing the privacy-utility tradeoff across various LLM a
&lt;/p&gt;</description></item></channel></rss>