<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28857;&#23545;&#28857;&#32852;&#37030;&#23398;&#20064;&#65288;P2PFL&#65289;&#30340;&#26032;&#22411;&#21518;&#38376;&#25915;&#20987;&#65292;&#21033;&#29992;&#32467;&#26500;&#22270;&#23646;&#24615;&#36873;&#25321;&#24694;&#24847;&#33410;&#28857;&#65292;&#23454;&#29616;&#39640;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#21516;&#26102;&#20445;&#25345;&#38544;&#34109;&#24615;&#12290;&#21516;&#26102;&#36824;&#35780;&#20272;&#20102;&#36825;&#20123;&#25915;&#20987;&#22312;&#22810;&#31181;&#29616;&#23454;&#26465;&#20214;&#19979;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#35774;&#35745;&#20102;&#26032;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;</title><link>http://arxiv.org/abs/2301.09732</link><description>&lt;p&gt;
&#28857;&#23545;&#28857;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Backdoor Attacks in Peer-to-Peer Federated Learning. (arXiv:2301.09732v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09732
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28857;&#23545;&#28857;&#32852;&#37030;&#23398;&#20064;&#65288;P2PFL&#65289;&#30340;&#26032;&#22411;&#21518;&#38376;&#25915;&#20987;&#65292;&#21033;&#29992;&#32467;&#26500;&#22270;&#23646;&#24615;&#36873;&#25321;&#24694;&#24847;&#33410;&#28857;&#65292;&#23454;&#29616;&#39640;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#21516;&#26102;&#20445;&#25345;&#38544;&#34109;&#24615;&#12290;&#21516;&#26102;&#36824;&#35780;&#20272;&#20102;&#36825;&#20123;&#25915;&#20987;&#22312;&#22810;&#31181;&#29616;&#23454;&#26465;&#20214;&#19979;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#35774;&#35745;&#20102;&#26032;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#31243;&#24207;&#20381;&#36182;&#20110;&#38598;&#20013;&#24335;&#23398;&#20064;&#36807;&#31243;&#65292;&#36825;&#24320;&#25918;&#20102;&#26333;&#20809;&#20854;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#39118;&#38505;&#12290;&#23613;&#31649;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#32531;&#35299;&#20102;&#36825;&#20123;&#38544;&#31169;&#39118;&#38505;&#65292;&#20294;&#23427;&#20173;&#20381;&#36182;&#20110;&#21487;&#20449;&#30340;&#32858;&#21512;&#26381;&#21153;&#22120;&#26469;&#35757;&#32451;&#20849;&#20139;&#20840;&#23616;&#27169;&#22411;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#28857;&#23545;&#28857;&#32852;&#37030;&#23398;&#20064;&#65288;P2PFL&#65289;&#30340;&#26032;&#20998;&#24067;&#24335;&#23398;&#20064;&#26550;&#26500;&#22312;&#38544;&#31169;&#21644;&#21487;&#38752;&#24615;&#26041;&#38754;&#37117;&#25552;&#20379;&#20102;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#26399;&#38388;&#23545;&#27602;&#21270;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;P2PFL&#21518;&#38376;&#25915;&#20987;&#65292;&#21033;&#29992;&#32467;&#26500;&#22270;&#23646;&#24615;&#36873;&#25321;&#24694;&#24847;&#33410;&#28857;&#65292;&#23454;&#29616;&#39640;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#21516;&#26102;&#20445;&#25345;&#38544;&#34109;&#24615;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#23454;&#38469;&#26465;&#20214;&#19979;&#35780;&#20272;&#25105;&#20204;&#30340;&#25915;&#20987;&#65292;&#21253;&#25324;&#22810;&#20010;&#22270;&#24418;&#25299;&#25169;&#12289;&#32593;&#32476;&#20013;&#26377;&#38480;&#30340;&#25932;&#23545;&#33021;&#35265;&#24230;&#20197;&#21450;&#20855;&#26377;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#23458;&#25143;&#31471;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20174;FL&#20013;&#36866;&#24212;&#30340;&#29616;&#26377;&#38450;&#24481;&#25514;&#26045;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most machine learning applications rely on centralized learning processes, opening up the risk of exposure of their training datasets. While federated learning (FL) mitigates to some extent these privacy risks, it relies on a trusted aggregation server for training a shared global model. Recently, new distributed learning architectures based on Peer-to-Peer Federated Learning (P2PFL) offer advantages in terms of both privacy and reliability. Still, their resilience to poisoning attacks during training has not been investigated. In this paper, we propose new backdoor attacks for P2PFL that leverage structural graph properties to select the malicious nodes, and achieve high attack success, while remaining stealthy. We evaluate our attacks under various realistic conditions, including multiple graph topologies, limited adversarial visibility of the network, and clients with non-IID data. Finally, we show the limitations of existing defenses adapted from FL and design a new defense that su
&lt;/p&gt;</description></item></channel></rss>