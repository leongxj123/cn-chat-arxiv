<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#22411;&#24179;&#21488;&#65292;&#26088;&#22312;&#20351;&#22823;&#22411;&#23450;&#21046;&#35821;&#35328;&#27169;&#22411;&#26356;&#26131;&#20110;&#20351;&#29992;&#65292;&#36890;&#36807;&#26368;&#26032;&#30340;&#22810;LoRA&#25512;&#29702;&#25216;&#26415;&#21644;&#23450;&#21046;&#36866;&#37197;&#22120;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#38548;&#31163;&#12289;&#21152;&#23494;&#21644;&#36523;&#20221;&#39564;&#35777;&#30340;&#23433;&#20840;&#26381;&#21153;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00913</link><description>&lt;p&gt;
&#29992;&#20110;&#23433;&#20840;&#33258;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25506;&#32034;&#30340;&#26426;&#26500;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
Institutional Platform for Secure Self-Service Large Language Model Exploration
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00913
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#22411;&#24179;&#21488;&#65292;&#26088;&#22312;&#20351;&#22823;&#22411;&#23450;&#21046;&#35821;&#35328;&#27169;&#22411;&#26356;&#26131;&#20110;&#20351;&#29992;&#65292;&#36890;&#36807;&#26368;&#26032;&#30340;&#22810;LoRA&#25512;&#29702;&#25216;&#26415;&#21644;&#23450;&#21046;&#36866;&#37197;&#22120;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#38548;&#31163;&#12289;&#21152;&#23494;&#21644;&#36523;&#20221;&#39564;&#35777;&#30340;&#23433;&#20840;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#30001;&#32943;&#22612;&#22522;&#22823;&#23398;&#24212;&#29992;&#20154;&#24037;&#26234;&#33021;&#20013;&#24515;&#24320;&#21457;&#30340;&#29992;&#25143;&#21451;&#22909;&#22411;&#24179;&#21488;&#65292;&#26088;&#22312;&#20351;&#22823;&#22411;&#23450;&#21046;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26356;&#26131;&#20110;&#20351;&#29992;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#22312;&#22810;LoRA&#25512;&#29702;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#31995;&#32479;&#26377;&#25928;&#22320;&#36866;&#24212;&#20102;&#21508;&#31867;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#23450;&#21046;&#36866;&#37197;&#22120;&#12290;&#35770;&#25991;&#27010;&#36848;&#20102;&#31995;&#32479;&#30340;&#26550;&#26500;&#21644;&#20851;&#38190;&#29305;&#24615;&#65292;&#21253;&#25324;&#25968;&#25454;&#38598;&#31574;&#21010;&#12289;&#27169;&#22411;&#35757;&#32451;&#12289;&#23433;&#20840;&#25512;&#29702;&#21644;&#22522;&#20110;&#25991;&#26412;&#30340;&#29305;&#24449;&#25552;&#21462;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#24314;&#31435;&#20102;&#19968;&#20010;&#22522;&#20110;&#31199;&#25143;&#24847;&#35782;&#30340;&#35745;&#31639;&#32593;&#32476;&#65292;&#22312;&#23433;&#20840;&#22320;&#21033;&#29992;&#23396;&#31435;&#36164;&#28304;&#23707;&#30340;&#22522;&#30784;&#19978;&#24418;&#25104;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#31995;&#32479;&#12290;&#35813;&#24179;&#21488;&#33268;&#21147;&#20110;&#25552;&#20379;&#23433;&#20840;&#30340;LLM&#26381;&#21153;&#65292;&#24378;&#35843;&#36807;&#31243;&#21644;&#25968;&#25454;&#38548;&#31163;&#12289;&#31471;&#21040;&#31471;&#21152;&#23494;&#20197;&#21450;&#22522;&#20110;&#35282;&#33394;&#30340;&#36164;&#28304;&#36523;&#20221;&#39564;&#35777;&#12290;&#35813;&#36129;&#29486;&#19982;&#23454;&#29616;&#31616;&#21270;&#35775;&#38382;&#20808;&#36827;&#30340;AI&#27169;&#22411;&#21644;&#25216;&#26415;&#20197;&#25903;&#25345;&#31185;&#23398;&#21457;&#29616;&#30340;&#24635;&#20307;&#30446;&#26631;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a user-friendly platform developed by the University of Kentucky Center for Applied AI, designed to make large, customized language models (LLMs) more accessible. By capitalizing on recent advancements in multi-LoRA inference, the system efficiently accommodates custom adapters for a diverse range of users and projects. The paper outlines the system's architecture and key features, encompassing dataset curation, model training, secure inference, and text-based feature extraction.   We illustrate the establishment of a tenant-aware computational network using agent-based methods, securely utilizing islands of isolated resources as a unified system. The platform strives to deliver secure LLM services, emphasizing process and data isolation, end-to-end encryption, and role-based resource authentication. This contribution aligns with the overarching goal of enabling simplified access to cutting-edge AI models and technology in support of scientific discovery.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#19978;&#19979;&#25991;&#23545;&#25239;&#28216;&#25103;(ICAG)&#38450;&#24481;&#36234;&#29425;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.13148</link><description>&lt;p&gt;
&#36890;&#36807;&#19978;&#19979;&#25991;&#23545;&#25239;&#28216;&#25103;&#38450;&#24481;&#36234;&#29425;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Defending Jailbreak Prompts via In-Context Adversarial Game
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13148
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#19978;&#19979;&#25991;&#23545;&#25239;&#28216;&#25103;(ICAG)&#38450;&#24481;&#36234;&#29425;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23637;&#29616;&#20986;&#22312;&#19981;&#21516;&#24212;&#29992;&#39046;&#22495;&#20013;&#30340;&#26174;&#33879;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23545;&#20854;&#23433;&#20840;&#24615;&#30340;&#25285;&#24551;&#65292;&#29305;&#21035;&#26159;&#23545;&#36234;&#29425;&#25915;&#20987;&#30340;&#33030;&#24369;&#24615;&#65292;&#20173;&#28982;&#23384;&#22312;&#12290;&#21463;&#21040;&#28145;&#24230;&#23398;&#20064;&#20013;&#23545;&#25239;&#35757;&#32451;&#21644;LLM&#20195;&#29702;&#23398;&#20064;&#36807;&#31243;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19978;&#19979;&#25991;&#23545;&#25239;&#28216;&#25103;(ICAG)&#26469;&#38450;&#24481;&#36234;&#29425;&#25915;&#20987;&#65292;&#26080;&#38656;&#36827;&#34892;&#24494;&#35843;&#12290;ICAG&#21033;&#29992;&#20195;&#29702;&#23398;&#20064;&#36827;&#34892;&#23545;&#25239;&#28216;&#25103;&#65292;&#26088;&#22312;&#21160;&#24577;&#25193;&#23637;&#30693;&#35782;&#20197;&#38450;&#24481;&#36234;&#29425;&#25915;&#20987;&#12290;&#19982;&#20381;&#36182;&#38745;&#24577;&#25968;&#25454;&#38598;&#30340;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;ICAG&#37319;&#29992;&#36845;&#20195;&#36807;&#31243;&#26469;&#22686;&#24378;&#38450;&#24481;&#21644;&#25915;&#20987;&#20195;&#29702;&#12290;&#36825;&#19968;&#25345;&#32493;&#25913;&#36827;&#36807;&#31243;&#21152;&#24378;&#20102;&#23545;&#26032;&#29983;&#25104;&#30340;&#36234;&#29425;&#25552;&#31034;&#30340;&#38450;&#24481;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#35777;&#23454;&#20102;ICAG&#30340;&#26377;&#25928;&#24615;&#65292;&#32463;&#30001;ICAG&#20445;&#25252;&#30340;LLMs&#22312;&#21508;&#31181;&#25915;&#20987;&#22330;&#26223;&#20013;&#26174;&#33879;&#38477;&#20302;&#20102;&#36234;&#29425;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13148v1 Announce Type: new  Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities across diverse applications. However, concerns regarding their security, particularly the vulnerability to jailbreak attacks, persist. Drawing inspiration from adversarial training in deep learning and LLM agent learning processes, we introduce the In-Context Adversarial Game (ICAG) for defending against jailbreaks without the need for fine-tuning. ICAG leverages agent learning to conduct an adversarial game, aiming to dynamically extend knowledge to defend against jailbreaks. Unlike traditional methods that rely on static datasets, ICAG employs an iterative process to enhance both the defense and attack agents. This continuous improvement process strengthens defenses against newly generated jailbreak prompts. Our empirical studies affirm ICAG's efficacy, where LLMs safeguarded by ICAG exhibit significantly reduced jailbreak success rates across various attack scenarios. Mo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#26368;&#26032;&#30340;&#38754;&#37096;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#22120;&#36827;&#34892;&#20102;&#20840;&#38754;&#22238;&#39038;&#21644;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#23545;&#20854;&#26377;&#25928;&#24615;&#24433;&#21709;&#22240;&#32032;&#30340;&#28145;&#20837;&#35265;&#35299;&#65292;&#24182;&#22312;&#21508;&#31181;&#25915;&#20987;&#22330;&#26223;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2401.04364</link><description>&lt;p&gt;
SoK&#65306;&#38754;&#37096;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
SoK: Facial Deepfake Detectors. (arXiv:2401.04364v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#26368;&#26032;&#30340;&#38754;&#37096;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#22120;&#36827;&#34892;&#20102;&#20840;&#38754;&#22238;&#39038;&#21644;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#23545;&#20854;&#26377;&#25928;&#24615;&#24433;&#21709;&#22240;&#32032;&#30340;&#28145;&#20837;&#35265;&#35299;&#65292;&#24182;&#22312;&#21508;&#31181;&#25915;&#20987;&#22330;&#26223;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#20266;&#36896;&#25216;&#26415;&#36805;&#36895;&#25104;&#20026;&#23545;&#31038;&#20250;&#26500;&#25104;&#28145;&#36828;&#21644;&#20005;&#37325;&#23041;&#32961;&#30340;&#21407;&#22240;&#20043;&#19968;&#65292;&#20027;&#35201;&#30001;&#20110;&#20854;&#26131;&#20110;&#21046;&#20316;&#21644;&#20256;&#25773;&#12290;&#36825;&#31181;&#24773;&#20917;&#21152;&#36895;&#20102;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#25216;&#26415;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#30340;&#26816;&#27979;&#22120;&#22312;&#39564;&#35777;&#26102; heavily &#20381;&#36182;&#23454;&#39564;&#23460;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#26377;&#25928;&#22320;&#35753;&#23427;&#20204;&#24212;&#23545;&#26032;&#39062;&#12289;&#26032;&#20852;&#21644;&#23454;&#38469;&#30340;&#28145;&#24230;&#20266;&#36896;&#25216;&#26415;&#12290;&#26412;&#25991;&#23545;&#26368;&#26032;&#30340;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#22120;&#36827;&#34892;&#24191;&#27867;&#20840;&#38754;&#30340;&#22238;&#39038;&#21644;&#20998;&#26512;&#65292;&#26681;&#25454;&#20960;&#20010;&#20851;&#38190;&#26631;&#20934;&#23545;&#23427;&#20204;&#36827;&#34892;&#35780;&#20272;&#12290;&#36825;&#20123;&#26631;&#20934;&#23558;&#36825;&#20123;&#26816;&#27979;&#22120;&#20998;&#20026; 4 &#20010;&#39640;&#32423;&#32452;&#21035;&#21644; 13 &#20010;&#32454;&#31890;&#24230;&#23376;&#32452;&#21035;&#65292;&#37117;&#36981;&#24490;&#19968;&#20010;&#32479;&#19968;&#30340;&#26631;&#20934;&#27010;&#24565;&#26694;&#26550;&#12290;&#36825;&#31181;&#20998;&#31867;&#21644;&#26694;&#26550;&#25552;&#20379;&#20102;&#23545;&#24433;&#21709;&#26816;&#27979;&#22120;&#21151;&#25928;&#30340;&#22240;&#32032;&#30340;&#28145;&#20837;&#21644;&#23454;&#29992;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#23545; 16 &#20010;&#20027;&#35201;&#30340;&#26816;&#27979;&#22120;&#22312;&#21508;&#31181;&#26631;&#20934;&#30340;&#25915;&#20987;&#22330;&#26223;&#20013;&#30340;&#26222;&#36866;&#24615;&#36827;&#34892;&#35780;&#20272;&#65292;&#21253;&#25324;&#40657;&#30418;&#25915;&#20987;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deepfakes have rapidly emerged as a profound and serious threat to society, primarily due to their ease of creation and dissemination. This situation has triggered an accelerated development of deepfake detection technologies. However, many existing detectors rely heavily on lab-generated datasets for validation, which may not effectively prepare them for novel, emerging, and real-world deepfake techniques. In this paper, we conduct an extensive and comprehensive review and analysis of the latest state-of-the-art deepfake detectors, evaluating them against several critical criteria. These criteria facilitate the categorization of these detectors into 4 high-level groups and 13 fine-grained sub-groups, all aligned with a unified standard conceptual framework. This classification and framework offer deep and practical insights into the factors that affect detector efficacy. We assess the generalizability of 16 leading detectors across various standard attack scenarios, including black-bo
&lt;/p&gt;</description></item></channel></rss>