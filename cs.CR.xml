<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.00957</link><description>&lt;p&gt;
&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;(&#20998;&#32452;)&#32467;&#26524;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference with Differentially Private (Clustered) Outcomes. (arXiv:2308.00957v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#21482;&#26377;&#22312;&#21442;&#19982;&#32773;&#21516;&#24847;&#36879;&#38706;&#20182;&#20204;&#21487;&#33021;&#25935;&#24863;&#30340;&#21709;&#24212;&#26102;&#25165;&#21487;&#34892;&#12290;&#22312;&#30830;&#20445;&#38544;&#31169;&#30340;&#35768;&#22810;&#26041;&#27861;&#20013;&#65292;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#38544;&#31169;&#20445;&#35777;&#24230;&#37327;&#65292;&#21487;&#20197;&#40723;&#21169;&#21442;&#19982;&#32773;&#20998;&#20139;&#21709;&#24212;&#32780;&#19981;&#20250;&#38754;&#20020;&#21435;&#21311;&#21517;&#21270;&#30340;&#39118;&#38505;&#12290;&#35768;&#22810;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#20250;&#21521;&#21407;&#22987;&#25968;&#25454;&#38598;&#20013;&#27880;&#20837;&#22122;&#38899;&#26469;&#23454;&#29616;&#36825;&#31181;&#38544;&#31169;&#20445;&#35777;&#65292;&#36825;&#20250;&#22686;&#21152;&#22823;&#22810;&#25968;&#32479;&#35745;&#20272;&#35745;&#37327;&#30340;&#26041;&#24046;&#65292;&#20351;&#24471;&#31934;&#30830;&#27979;&#37327;&#22240;&#26524;&#25928;&#24212;&#21464;&#24471;&#22256;&#38590;&#65306;&#20174;&#24046;&#20998;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#23384;&#22312;&#30528;&#22266;&#26377;&#30340;&#38544;&#31169;-&#26041;&#24046;&#26435;&#34913;&#12290;&#20026;&#20102;&#23454;&#29616;&#26356;&#24378;&#38544;&#31169;&#20445;&#35777;&#30340;&#36739;&#20302;&#26041;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#21033;&#29992;&#25968;&#25454;&#30340;&#20219;&#20309;&#32473;&#23450;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#21516;&#26102;&#20173;&#28982;&#20801;&#35768;&#23545;&#22240;&#26524;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating causal effects from randomized experiments is only feasible if participants agree to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label differential privacy is a widely used measure of an algorithm's privacy guarantee, which might encourage participants to share responses without running the risk of de-anonymization. Many differentially private mechanisms inject noise into the original data-set to achieve this privacy guarantee, which increases the variance of most statistical estimators and makes the precise measurement of causal effects difficult: there exists a fundamental privacy-variance trade-off to performing causal analyses from differentially private data. With the aim of achieving lower variance for stronger privacy guarantees, we suggest a new differential privacy mechanism, "Cluster-DP", which leverages any given cluster structure of the data while still allowing for the estimation of causal effects. We show that, depending 
&lt;/p&gt;</description></item></channel></rss>