<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#36825;&#39033;&#30740;&#31350;&#28145;&#20837;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;LVLM&#65289;&#23545;&#20110;&#33258;&#21160;&#29983;&#25104;&#30340;&#25490;&#29256;&#25915;&#20987;&#30340;&#26131;&#21463;&#25915;&#20987;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#26356;&#26377;&#25928;&#30340;&#33258;&#21160;&#29983;&#25104;&#30340;&#25490;&#29256;&#25915;&#20987;&#26041;&#27861;&#65292;&#20026;&#27492;&#35774;&#35745;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#27979;&#35797;&#22522;&#20934;&#12290;&#36890;&#36807;&#20351;&#29992;&#35813;&#22522;&#20934;&#65292;&#30740;&#31350;&#21457;&#29616;&#25490;&#29256;&#25915;&#20987;&#23545;LVLM&#26500;&#25104;&#20102;&#37325;&#22823;&#23041;&#32961;&#12290;</title><link>https://arxiv.org/abs/2402.00626</link><description>&lt;p&gt;
Vision-LLMs&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#30340;&#25490;&#29256;&#25915;&#20987;&#21487;&#20197;&#33258;&#27450;&#27450;&#20154;
&lt;/p&gt;
&lt;p&gt;
Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00626
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#28145;&#20837;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;LVLM&#65289;&#23545;&#20110;&#33258;&#21160;&#29983;&#25104;&#30340;&#25490;&#29256;&#25915;&#20987;&#30340;&#26131;&#21463;&#25915;&#20987;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#26356;&#26377;&#25928;&#30340;&#33258;&#21160;&#29983;&#25104;&#30340;&#25490;&#29256;&#25915;&#20987;&#26041;&#27861;&#65292;&#20026;&#27492;&#35774;&#35745;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#27979;&#35797;&#22522;&#20934;&#12290;&#36890;&#36807;&#20351;&#29992;&#35813;&#22522;&#20934;&#65292;&#30740;&#31350;&#21457;&#29616;&#25490;&#29256;&#25915;&#20987;&#23545;LVLM&#26500;&#25104;&#20102;&#37325;&#22823;&#23041;&#32961;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#22823;&#35268;&#27169;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;LVLM&#65289;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65307;&#36825;&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#20840;&#26032;&#31867;&#21035;&#30340;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;LVLM&#23545;&#20110;&#28041;&#21450;&#23558;&#35823;&#23548;&#24615;&#25991;&#26412;&#21472;&#21152;&#21040;&#22270;&#20687;&#19978;&#30340;&#20174;&#25490;&#29256;&#25915;&#20987;&#30340;&#23481;&#26131;&#21463;&#25915;&#20987;&#24615;&#21364;&#27809;&#26377;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#25490;&#29256;&#25915;&#20987;&#20381;&#36182;&#20110;&#20174;&#39044;&#23450;&#20041;&#31867;&#21035;&#38598;&#21512;&#20013;&#38543;&#26426;&#36873;&#25321;&#19968;&#20010;&#35823;&#23548;&#24615;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#38543;&#26426;&#36873;&#25321;&#30340;&#31867;&#21035;&#21487;&#33021;&#19981;&#26159;&#26368;&#26377;&#25928;&#30340;&#25915;&#20987;&#31867;&#21035;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31181;&#29420;&#29305;&#35774;&#35745;&#30340;&#26032;&#39062;&#22522;&#20934;&#26469;&#27979;&#35797;LVLM&#23545;&#25490;&#29256;&#25915;&#20987;&#30340;&#23481;&#26131;&#21463;&#25915;&#20987;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#32780;&#26356;&#26377;&#25928;&#30340;&#25490;&#29256;&#25915;&#20987;&#65306;&#33258;&#21160;&#29983;&#25104;&#30340;&#25490;&#29256;&#25915;&#20987;&#12290;&#23454;&#38469;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#31616;&#21333;&#22320;&#25552;&#31034;GPT-4V&#31561;&#27169;&#22411;&#21033;&#29992;&#20854;&#24378;&#22823;&#30340;&#35821;&#35328;&#33021;&#21147;&#25512;&#33616;&#19968;&#31181;&#25490;&#29256;&#25915;&#20987;&#26469;&#20026;&#32473;&#23450;&#30340;&#22270;&#20687;&#29983;&#25104;&#25915;&#20987;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26032;&#39062;&#22522;&#20934;&#65292;&#25105;&#20204;&#21457;&#29616;&#25490;&#29256;&#25915;&#20987;&#23545;LVLM&#26500;&#25104;&#20102;&#37325;&#22823;&#23041;&#32961;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, significant progress has been made on Large Vision-Language Models (LVLMs); a new class of VL models that make use of large pre-trained language models. Yet, their vulnerability to Typographic attacks, which involve superimposing misleading text onto an image remain unstudied. Furthermore, prior work typographic attacks rely on sampling a random misleading class from a predefined set of classes. However, the random chosen class might not be the most effective attack. To address these issues, we first introduce a novel benchmark uniquely designed to test LVLMs vulnerability to typographic attacks. Furthermore, we introduce a new and more effective typographic attack: Self-Generated typographic attacks. Indeed, our method, given an image, make use of the strong language capabilities of models like GPT-4V by simply prompting them to recommend a typographic attack. Using our novel benchmark, we uncover that typographic attacks represent a significant threat against LVLM(s). Furth
&lt;/p&gt;</description></item></channel></rss>