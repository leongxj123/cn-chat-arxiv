<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#25552;&#20986;&#20102;&#22522;&#20110;&#21306;&#22359;&#38142;&#30340;&#32852;&#37030;&#36951;&#24536;&#65288;BlockFUL&#65289;&#65292;&#20351;&#29992;Chameleon Hash&#65288;CH&#65289;&#25216;&#26415;&#37325;&#26032;&#35774;&#35745;&#21306;&#22359;&#38142;&#32467;&#26500;&#65292;&#20943;&#23569;&#27169;&#22411;&#26356;&#26032;&#30340;&#22797;&#26434;&#24615;&#21644;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.16294</link><description>&lt;p&gt;
&#21306;&#22359;&#38142;&#19978;&#30340;&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Decentralized Federated Unlearning on Blockchain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16294
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22522;&#20110;&#21306;&#22359;&#38142;&#30340;&#32852;&#37030;&#36951;&#24536;&#65288;BlockFUL&#65289;&#65292;&#20351;&#29992;Chameleon Hash&#65288;CH&#65289;&#25216;&#26415;&#37325;&#26032;&#35774;&#35745;&#21306;&#22359;&#38142;&#32467;&#26500;&#65292;&#20943;&#23569;&#27169;&#22411;&#26356;&#26032;&#30340;&#22797;&#26434;&#24615;&#21644;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21306;&#22359;&#38142;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#22312;&#30830;&#20445;FL&#36807;&#31243;&#30340;&#23436;&#25972;&#24615;&#21644;&#21487;&#36861;&#28335;&#24615;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#21306;&#22359;&#38142;FL&#28041;&#21450;&#21442;&#19982;&#32773;&#22312;&#26412;&#22320;&#35757;&#32451;&#27169;&#22411;&#24182;&#38543;&#21518;&#23558;&#27169;&#22411;&#21457;&#24067;&#21040;&#21306;&#22359;&#38142;&#19978;&#65292;&#24418;&#25104;&#34920;&#31034;&#27169;&#22411;&#20851;&#31995;&#30340;&#31867;&#20284;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#30340;&#32487;&#25215;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#22522;&#20110;DAG&#30340;&#32467;&#26500;&#22312;&#20351;&#29992;&#25935;&#24863;&#25968;&#25454;&#26356;&#26032;&#27169;&#22411;&#26102;&#23384;&#22312;&#25361;&#25112;&#65292;&#22240;&#20026;&#28041;&#21450;&#30340;&#22797;&#26434;&#24615;&#21644;&#24320;&#38144;&#36739;&#22823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#21306;&#22359;&#38142;&#30340;&#32852;&#37030;&#36951;&#24536;&#65288;BlockFUL&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20351;&#29992;&#21464;&#33394;&#40857;&#21704;&#24076;&#65288;CH&#65289;&#25216;&#26415;&#37325;&#26032;&#35774;&#35745;&#21306;&#22359;&#38142;&#32467;&#26500;&#65292;&#20197;&#20943;&#36731;&#27169;&#22411;&#26356;&#26032;&#30340;&#22797;&#26434;&#24615;&#65292;&#20174;&#32780;&#38477;&#20302;&#36951;&#24536;&#20219;&#21153;&#30340;&#35745;&#31639;&#21644;&#20849;&#35782;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;BlockFUL&#25903;&#25345;&#21508;&#31181;&#32852;&#37030;&#36951;&#24536;&#26041;&#27861;&#65292;&#30830;&#20445;&#27169;&#22411;&#26356;&#26032;&#30340;&#23436;&#25972;&#24615;&#21644;&#21487;&#36861;&#28335;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16294v1 Announce Type: cross  Abstract: Blockchained Federated Learning (FL) has been gaining traction for ensuring the integrity and traceability of FL processes. Blockchained FL involves participants training models locally with their data and subsequently publishing the models on the blockchain, forming a Directed Acyclic Graph (DAG)-like inheritance structure that represents the model relationship. However, this particular DAG-based structure presents challenges in updating models with sensitive data, due to the complexity and overhead involved. To address this, we propose Blockchained Federated Unlearning (BlockFUL), a generic framework that redesigns the blockchain structure using Chameleon Hash (CH) technology to mitigate the complexity of model updating, thereby reducing the computational and consensus costs of unlearning tasks.Furthermore, BlockFUL supports various federated unlearning methods, ensuring the integrity and traceability of model updates, whether conduc
&lt;/p&gt;</description></item><item><title>LearnDefend&#26159;&#19968;&#31181;&#23398;&#20064;&#38450;&#24481;&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23545;&#25239;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#26377;&#38024;&#23545;&#24615;&#27169;&#22411;&#20013;&#27602;&#25915;&#20987;&#12290;&#23427;&#20351;&#29992;&#19968;&#20010;&#36739;&#23567;&#30340;&#38450;&#24481;&#25968;&#25454;&#38598;&#65292;&#20272;&#35745;&#23458;&#25143;&#31471;&#26356;&#26032;&#34987;&#27745;&#26579;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23398;&#20064;&#27602;&#25968;&#25454;&#26816;&#27979;&#22120;&#27169;&#22411;&#24182;&#20351;&#29992;&#32806;&#21512;&#30340;&#20248;&#21270;&#26041;&#27861;&#20272;&#35745;&#27602;&#25968;&#25454;&#26816;&#27979;&#22120;&#21644;&#23458;&#25143;&#31471;&#37325;&#35201;&#24615;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.02022</link><description>&lt;p&gt;
LearnDefend&#65306;&#23398;&#20064;&#23545;&#25239;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#26377;&#38024;&#23545;&#24615;&#30340;&#27169;&#22411;&#20013;&#27602;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
LearnDefend: Learning to Defend against Targeted Model-Poisoning Attacks on Federated Learning. (arXiv:2305.02022v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02022
&lt;/p&gt;
&lt;p&gt;
LearnDefend&#26159;&#19968;&#31181;&#23398;&#20064;&#38450;&#24481;&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23545;&#25239;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#26377;&#38024;&#23545;&#24615;&#27169;&#22411;&#20013;&#27602;&#25915;&#20987;&#12290;&#23427;&#20351;&#29992;&#19968;&#20010;&#36739;&#23567;&#30340;&#38450;&#24481;&#25968;&#25454;&#38598;&#65292;&#20272;&#35745;&#23458;&#25143;&#31471;&#26356;&#26032;&#34987;&#27745;&#26579;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23398;&#20064;&#27602;&#25968;&#25454;&#26816;&#27979;&#22120;&#27169;&#22411;&#24182;&#20351;&#29992;&#32806;&#21512;&#30340;&#20248;&#21270;&#26041;&#27861;&#20272;&#35745;&#27602;&#25968;&#25454;&#26816;&#27979;&#22120;&#21644;&#23458;&#25143;&#31471;&#37325;&#35201;&#24615;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#21521;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#26377;&#38024;&#23545;&#24615;&#27169;&#22411;&#20013;&#27602;&#25915;&#20987;&#26500;&#25104;&#20102;&#24040;&#22823;&#30340;&#23041;&#32961;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#30446;&#26631;&#36793;&#32536;&#26696;&#20363;&#22411;&#25915;&#20987;&#65288;&#23545;&#36755;&#20837;&#31354;&#38388;&#30340;&#19968;&#23567;&#37096;&#20998;&#36827;&#34892;&#38024;&#23545;&#24615;&#25915;&#20987;&#65289;&#20960;&#20046;&#26080;&#27861;&#36890;&#36807;&#29616;&#26377;&#30340;&#38450;&#24481;&#31574;&#30053;&#36827;&#34892;&#21453;&#20987;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#36739;&#23567;&#30340;&#38450;&#24481;&#25968;&#25454;&#38598;&#35774;&#35745;&#19968;&#31181;&#23398;&#20064;&#38450;&#24481;&#31574;&#30053;&#26469;&#24212;&#23545;&#27492;&#31867;&#25915;&#20987;&#12290;&#38450;&#24481;&#25968;&#25454;&#38598;&#21487;&#20197;&#30001;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#30340;&#20013;&#22830;&#31649;&#29702;&#26426;&#26500;&#25910;&#38598;&#65292;&#20854;&#20013;&#24212;&#21253;&#21547;&#19968;&#20123;&#34987;&#27745;&#26579;&#30340;&#21644;&#27809;&#26377;&#34987;&#27745;&#26579;&#30340;&#31034;&#20363;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;LearnDefend&#20250;&#20272;&#35745;&#23458;&#25143;&#31471;&#26356;&#26032;&#20855;&#26377;&#24694;&#24847;&#30340;&#27010;&#29575;&#12290;&#38450;&#24481;&#25968;&#25454;&#38598;&#20013;&#30340;&#31034;&#20363;&#19981;&#38656;&#35201;&#20107;&#20808;&#26631;&#35760;&#20026;&#34987;&#27745;&#26579;&#25110;&#26410;&#34987;&#27745;&#26579;&#12290;&#25105;&#20204;&#36824;&#23398;&#20064;&#20102;&#19968;&#20010;&#21487;&#29992;&#20110;&#26631;&#35760;&#38450;&#24481;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#31034;&#20363;&#20026;&#24178;&#20928;&#25110;&#27745;&#26579;&#30340;&#27602;&#25968;&#25454;&#26816;&#27979;&#22120;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#32806;&#21512;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#20272;&#35745;&#27602;&#25968;&#25454;&#26816;&#27979;&#22120;&#21644;&#23458;&#25143;&#31471;&#37325;&#35201;&#24615;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;LearnDefend&#33021;&#22815;&#25104;&#21151;&#24212;&#23545;&#26377;&#38024;&#23545;&#24615;&#27169;&#22411;&#20013;&#27602;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
Targeted model poisoning attacks pose a significant threat to federated learning systems. Recent studies show that edge-case targeted attacks, which target a small fraction of the input space are nearly impossible to counter using existing fixed defense strategies. In this paper, we strive to design a learned-defense strategy against such attacks, using a small defense dataset. The defense dataset can be collected by the central authority of the federated learning task, and should contain a mix of poisoned and clean examples. The proposed framework, LearnDefend, estimates the probability of a client update being malicious. The examples in defense dataset need not be pre-marked as poisoned or clean. We also learn a poisoned data detector model which can be used to mark each example in the defense dataset as clean or poisoned. We estimate the poisoned data detector and the client importance models in a coupled optimization approach. Our experiments demonstrate that LearnDefend is capable
&lt;/p&gt;</description></item></channel></rss>