<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35753;ChatGPT&#21644;Bard&#20882;&#20805;&#22797;&#26434;&#20154;&#29289;&#35282;&#33394;&#65292;&#32469;&#36807;&#20102;&#23433;&#20840;&#26426;&#21046;&#21644;&#19987;&#38376;&#35757;&#32451;&#31243;&#24207;&#65292;&#23637;&#31034;&#20102;&#34987;&#31105;&#27490;&#30340;&#22238;&#24212;&#23454;&#38469;&#19978;&#34987;&#25552;&#20379;&#20102;&#65292;&#20174;&#32780;&#26377;&#21487;&#33021;&#33719;&#21462;&#26410;&#32463;&#25480;&#26435;&#12289;&#38750;&#27861;&#25110;&#26377;&#23475;&#30340;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2312.03853</link><description>&lt;p&gt;
LLMs&#30340;&#20004;&#38754;&#24615;&#65306;Jekyll&#21338;&#22763;&#19982;Hyde&#20808;&#29983;
&lt;/p&gt;
&lt;p&gt;
Dr. Jekyll and Mr. Hyde: Two Faces of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35753;ChatGPT&#21644;Bard&#20882;&#20805;&#22797;&#26434;&#20154;&#29289;&#35282;&#33394;&#65292;&#32469;&#36807;&#20102;&#23433;&#20840;&#26426;&#21046;&#21644;&#19987;&#38376;&#35757;&#32451;&#31243;&#24207;&#65292;&#23637;&#31034;&#20102;&#34987;&#31105;&#27490;&#30340;&#22238;&#24212;&#23454;&#38469;&#19978;&#34987;&#25552;&#20379;&#20102;&#65292;&#20174;&#32780;&#26377;&#21487;&#33021;&#33719;&#21462;&#26410;&#32463;&#25480;&#26435;&#12289;&#38750;&#27861;&#25110;&#26377;&#23475;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20165;&#20165;&#19968;&#24180;&#21069;&#65292;&#25105;&#20204;&#30446;&#30585;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20351;&#29992;&#22686;&#21152;&#65292;&#23588;&#20854;&#26159;&#22312;&#32467;&#21512;&#20687;&#32842;&#22825;&#26426;&#22120;&#20154;&#21161;&#25163;&#20043;&#31867;&#30340;&#24212;&#29992;&#26102;&#12290;&#20026;&#20102;&#38450;&#27490;&#36825;&#20123;&#21161;&#25163;&#20135;&#29983;&#19981;&#24403;&#22238;&#24212;&#65292;&#25105;&#20204;&#23454;&#26045;&#20102;&#23433;&#20840;&#26426;&#21046;&#21644;&#19987;&#38376;&#30340;&#35757;&#32451;&#31243;&#24207;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#35753;ChatGPT&#21644;Bard&#65288;&#20197;&#21450;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#26159;Bing chat&#65289;&#20882;&#20805;&#22797;&#26434;&#20154;&#29289;&#35282;&#33394;&#65292;&#32469;&#36807;&#20102;&#36825;&#20123;&#25514;&#26045;&#65292;&#36825;&#20123;&#35282;&#33394;&#19982;&#23427;&#20204;&#26412;&#24212;&#25104;&#20026;&#30340;&#30495;&#23454;&#21161;&#25163;&#30340;&#29305;&#24449;&#30456;&#21453;&#12290;&#25105;&#20204;&#39318;&#20808;&#21019;&#36896;&#20986;&#36825;&#20123;&#20154;&#29289;&#35282;&#33394;&#30340;&#22797;&#26434;&#20256;&#35760;&#65292;&#28982;&#21518;&#22312;&#21516;&#19968;&#32842;&#22825;&#26426;&#22120;&#20154;&#20013;&#20351;&#29992;&#23427;&#20204;&#36827;&#34892;&#26032;&#30340;&#23545;&#35805;&#12290;&#25105;&#20204;&#30340;&#23545;&#35805;&#37319;&#29992;&#35282;&#33394;&#25198;&#28436;&#39118;&#26684;&#65292;&#20197;&#33719;&#24471;&#21161;&#25163;&#19981;&#34987;&#20801;&#35768;&#25552;&#20379;&#30340;&#22238;&#24212;&#12290;&#36890;&#36807;&#20351;&#29992;&#20154;&#29289;&#35282;&#33394;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#34987;&#31105;&#27490;&#30340;&#22238;&#24212;&#23454;&#38469;&#19978;&#34987;&#25552;&#20379;&#20102;&#65292;&#20174;&#32780;&#26377;&#21487;&#33021;&#33719;&#21462;&#26410;&#32463;&#25480;&#26435;&#12289;&#38750;&#27861;&#25110;&#26377;&#23475;&#30340;&#20449;&#24687;&#12290;&#36825;&#39033;&#24037;&#20316;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#25239;&#24615;pe
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03853v2 Announce Type: replace-cross  Abstract: Only a year ago, we witnessed a rise in the use of Large Language Models (LLMs), especially when combined with applications like chatbot assistants. Safety mechanisms and specialized training procedures are implemented to prevent improper responses from these assistants. In this work, we bypass these measures for ChatGPT and Bard (and, to some extent, Bing chat) by making them impersonate complex personas with opposite characteristics as those of the truthful assistants they are supposed to be. We start by creating elaborate biographies of these personas, which we then use in a new session with the same chatbots. Our conversation followed a role-play style to get the response the assistant was not allowed to provide. By making use of personas, we show that the response that is prohibited is actually provided, making it possible to obtain unauthorized, illegal, or harmful information. This work shows that by using adversarial pe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#26679;&#24615;&#65292;&#20027;&#35201;&#32858;&#28966;&#20110;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#22914;&#20309;&#24433;&#21709;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#26469;&#22686;&#24378;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2301.08403</link><description>&lt;p&gt;
&#36890;&#36807;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#29983;&#25104;&#24207;&#21015;&#65306;&#29702;&#35770;&#21450;&#20854;&#22312;&#26080;&#20154;&#26426;&#35782;&#21035;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification. (arXiv:2301.08403v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#26679;&#24615;&#65292;&#20027;&#35201;&#32858;&#28966;&#20110;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#22914;&#20309;&#24433;&#21709;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#26469;&#22686;&#24378;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#21512;&#25104;&#24207;&#21015;&#30340;&#33021;&#21147;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#21644;&#29983;&#25104;&#26694;&#26550;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#26497;&#22823;&#22320;&#20419;&#36827;&#20102;&#36825;&#19968;&#36807;&#31243;&#12290;&#26412;&#25991;&#20351;&#29992;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#26469;&#37319;&#26679;&#65292;&#36890;&#36807;&#30456;&#20284;&#24615;&#29983;&#25104;&#23376;&#24207;&#21015;&#65292;&#24182;&#35777;&#26126;&#20102;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#23545;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#30340;&#24433;&#21709;&#65292;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#19968;&#27425;&#24615;&#29983;&#25104;&#27169;&#22411;&#26469;&#20174;&#21333;&#20010;&#24207;&#21015;&#30340;&#33539;&#22260;&#20869;&#21462;&#26679;&#65292;&#24182;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#65292;&#35777;&#26126;&#20102;&#25968;&#25454;&#38598;&#22686;&#24378;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to generate synthetic sequences is crucial for a wide range of applications, and recent advances in deep learning architectures and generative frameworks have greatly facilitated this process. Particularly, unconditional one-shot generative models constitute an attractive line of research that focuses on capturing the internal information of a single image or video to generate samples with similar contents. Since many of those one-shot models are shifting toward efficient non-deep and non-adversarial approaches, we examine the versatility of a one-shot generative model for augmenting whole datasets. In this work, we focus on how similarity at the subsequence level affects similarity at the sequence level, and derive bounds on the optimal transport of real and generated sequences based on that of corresponding subsequences. We use a one-shot generative model to sample from the vicinity of individual sequences and generate subsequence-similar ones and demonstrate the improvem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#30340;&#25193;&#23637;&#65292;&#21487;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#35745;&#31639;&#38750;&#21442;&#25968;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#65292;&#30001;&#27492;&#24471;&#21040;&#30340;&#32467;&#26524;&#21487;&#29992;&#20110;&#29983;&#25104;&#25928;&#29575;&#39640;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#24207;&#21015;&#12290;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#24182;&#20135;&#29983;&#31169;&#26377;&#27169;&#25311;&#12290;</title><link>http://arxiv.org/abs/2202.08728</link><description>&lt;p&gt;
&#38543;&#26426;&#21709;&#24212;&#31169;&#26377;&#32622;&#20449;&#38598;&#30340;&#38750;&#21442;&#25968;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Nonparametric extensions of randomized response for private confidence sets. (arXiv:2202.08728v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.08728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#30340;&#25193;&#23637;&#65292;&#21487;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#35745;&#31639;&#38750;&#21442;&#25968;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#65292;&#30001;&#27492;&#24471;&#21040;&#30340;&#32467;&#26524;&#21487;&#29992;&#20110;&#29983;&#25104;&#25928;&#29575;&#39640;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#24207;&#21015;&#12290;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#24182;&#20135;&#29983;&#31169;&#26377;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#65288;LDP&#65289;&#32422;&#26463;&#19979;&#25191;&#34892;&#38750;&#21442;&#25968;&#12289;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#22343;&#20540;$\mu^\star$&#30340;&#26377;&#30028;&#35266;&#27979;$(X_1,\dots,X_n)$&#30340;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#21644;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#24207;&#21015;&#65288;CS&#65289;&#65292;&#24403;&#21482;&#26377;&#35775;&#38382;&#31169;&#26377;&#25968;&#25454;$(Z_1,\dots,Z_n)$&#26102;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#12289;&#39034;&#24207;&#20132;&#20114;&#30340; Warner &#30340;&#33879;&#21517;&#8220;&#38543;&#26426;&#21709;&#24212;&#8221;&#26426;&#21046;&#30340;&#25512;&#24191;&#65292;&#20026;&#20219;&#24847;&#26377;&#30028;&#38543;&#26426;&#21464;&#37327;&#28385;&#36275; LDP&#65292;&#24182;&#25552;&#20379; CIs &#21644; CSs&#65292;&#29992;&#20110;&#35775;&#38382;&#25152;&#24471;&#31169;&#26377;&#21270;&#30340;&#35266;&#27979;&#20540;&#30340;&#22343;&#20540;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#22266;&#23450;&#26102;&#38388;&#21644;&#26102;&#38388;&#22343;&#21248;&#21306;&#22495;&#37117;&#20135;&#29983;&#20102; Hoeffding &#19981;&#31561;&#24335;&#30340;&#31169;&#26377;&#27169;&#25311;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123; Hoeffding  &#31867;&#22411;&#30340; CSs &#25193;&#23637;&#21040;&#25429;&#33719;&#26102;&#38388;&#21464;&#21270;&#65288;&#38750;&#24179;&#31283;&#65289;&#30340;&#22343;&#20540;&#65292;&#26368;&#21518;&#35828;&#26126;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#23454;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work derives methods for performing nonparametric, nonasymptotic statistical inference for population means under the constraint of local differential privacy (LDP). Given bounded observations $(X_1, \dots, X_n)$ with mean $\mu^\star$ that are privatized into $(Z_1, \dots, Z_n)$, we present confidence intervals (CI) and time-uniform confidence sequences (CS) for $\mu^\star$ when only given access to the privatized data. To achieve this, we introduce a nonparametric and sequentially interactive generalization of Warner's famous ``randomized response'' mechanism, satisfying LDP for arbitrary bounded random variables, and then provide CIs and CSs for their means given access to the resulting privatized observations. For example, our results yield private analogues of Hoeffding's inequality in both fixed-time and time-uniform regimes. We extend these Hoeffding-type CSs to capture time-varying (non-stationary) means, and conclude by illustrating how these methods can be used to conduct
&lt;/p&gt;</description></item></channel></rss>