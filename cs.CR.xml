<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#23545;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#20013;&#30340;&#23545;&#25239;&#25915;&#20987;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#25506;&#27979;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#20449;&#21495;&#30340;&#25351;&#26631;&#12290;</title><link>https://arxiv.org/abs/2312.14440</link><description>&lt;p&gt;
&#23545;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#20013;&#30340;&#19981;&#23545;&#31216;&#20559;&#24046;&#30340;&#23545;&#25239;&#25915;&#20987;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14440
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#20013;&#30340;&#23545;&#25239;&#25915;&#20987;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#25506;&#27979;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#20449;&#21495;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#65288;T2I&#65289;&#27169;&#22411;&#22312;&#20869;&#23481;&#29983;&#25104;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#38656;&#35201;&#20180;&#32454;&#30740;&#31350;&#23427;&#20204;&#30340;&#23433;&#20840;&#24615;&#65292;&#21253;&#25324;&#23427;&#20204;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;&#23613;&#31649;&#23545;&#25239;&#25915;&#20987;&#30340;&#30740;&#31350;&#24050;&#32463;&#24456;&#24191;&#27867;&#65292;&#20294;&#20854;&#26377;&#25928;&#24615;&#30340;&#21407;&#22240;&#20173;&#28982;&#26410;&#34987;&#28145;&#20837;&#25506;&#32034;&#12290;&#26412;&#25991;&#23545;T2I&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#37325;&#28857;&#20998;&#26512;&#20102;&#19982;&#25915;&#20987;&#25104;&#21151;&#29575;&#65288;ASR&#65289;&#30456;&#20851;&#30340;&#22240;&#32032;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#30446;&#26631; - &#20351;&#29992;&#23545;&#25239;&#24615;&#21518;&#32512;&#36827;&#34892;&#23454;&#20307;&#26367;&#25442;&#65292;&#20197;&#21450;&#20004;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#31639;&#27861;&#12290;&#20154;&#24037;&#21644;&#33258;&#21160;&#35780;&#20272;&#25581;&#31034;&#20102;&#23454;&#20307;&#20132;&#25442;&#20013;ASR&#30340;&#19981;&#23545;&#31216;&#24615;&#36136;&#65306;&#20363;&#22914;&#65292;&#23545;&#20110;&#22312;&#25552;&#31034;&#8220;&#22312;&#38632;&#20013;&#36339;&#33310;&#30340;&#20154;&#31867;&#8221;&#20013;&#26367;&#25442;&#8220;&#20154;&#31867;&#8221;&#20026;&#8220;&#26426;&#22120;&#20154;&#8221;&#30340;&#23545;&#25239;&#24615;&#21518;&#32512;&#65292;&#36739;&#23481;&#26131;&#23454;&#29616;&#65292;&#32780;&#21453;&#21521;&#26367;&#25442;&#21017;&#26126;&#26174;&#22256;&#38590;&#24471;&#22810;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#25506;&#27979;&#25351;&#26631;&#65292;&#20197;&#30830;&#23450;&#27169;&#22411;&#23545;&#25239;ASR&#30340;&#20449;&#21495;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#65306;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14440v2 Announce Type: replace Abstract: The widespread use of Text-to-Image (T2I) models in content generation requires careful examination of their safety, including their robustness to adversarial attacks. Despite extensive research on adversarial attacks, the reasons for their effectiveness remain underexplored. This paper presents an empirical study on adversarial attacks against T2I models, focusing on analyzing factors associated with attack success rates (ASR). We introduce a new attack objective - entity swapping using adversarial suffixes and two gradient-based attack algorithms. Human and automatic evaluations reveal the asymmetric nature of ASRs on entity swap: for example, it is easier to replace "human" with "robot" in the prompt "a human dancing in the rain." with an adversarial suffix, but the reverse replacement is significantly harder. We further propose probing metrics to establish indicative signals from the model's beliefs to the adversarial ASR. We iden
&lt;/p&gt;</description></item><item><title>DIFFender&#26159;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20301;&#21644;&#24674;&#22797;&#20004;&#20010;&#38454;&#27573;&#30340;&#25805;&#20316;&#65292;&#21033;&#29992;&#25991;&#26412;&#24341;&#23548;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#38450;&#24481;&#23545;&#25239;&#24615;Patch&#65292;&#20174;&#32780;&#25552;&#39640;&#20854;&#25972;&#20307;&#38450;&#24481;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.09124</link><description>&lt;p&gt;
DIFFender&#65306;&#22522;&#20110;&#25193;&#25955;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#26041;&#27861;&#29992;&#20110;&#25269;&#24481;Patch&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks. (arXiv:2306.09124v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09124
&lt;/p&gt;
&lt;p&gt;
DIFFender&#26159;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20301;&#21644;&#24674;&#22797;&#20004;&#20010;&#38454;&#27573;&#30340;&#25805;&#20316;&#65292;&#21033;&#29992;&#25991;&#26412;&#24341;&#23548;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#38450;&#24481;&#23545;&#25239;&#24615;Patch&#65292;&#20174;&#32780;&#25552;&#39640;&#20854;&#25972;&#20307;&#38450;&#24481;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#23588;&#20854;&#26159;Patch&#25915;&#20987;&#65292;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#26500;&#25104;&#20102;&#37325;&#22823;&#23041;&#32961;&#12290;&#24320;&#21457;&#21487;&#38752;&#30340;&#38450;&#24481;&#26041;&#27861;&#20197;&#25269;&#24481;Patch&#25915;&#20987;&#23545;&#20110;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#65292;&#28982;&#32780;&#24403;&#21069;&#22312;&#36825;&#20010;&#39046;&#22495;&#30340;&#30740;&#31350;&#36824;&#19981;&#20196;&#20154;&#28385;&#24847;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DIFFender&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#38450;&#24481;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#25991;&#26412;&#24341;&#23548;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#38450;&#24481;&#23545;&#25239;&#24615;Patch&#12290;DIFFender&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#38454;&#27573;&#65306;Patch&#23450;&#20301;&#21644;Patch&#24674;&#22797;&#12290;&#22312;&#23450;&#20301;&#38454;&#27573;&#65292;&#25105;&#20204;&#21457;&#29616;&#24182;&#21033;&#29992;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#19968;&#20010;&#26377;&#36259;&#29305;&#24615;&#65292;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#23545;&#25239;&#24615;Patch&#30340;&#20301;&#32622;&#12290;&#22312;&#24674;&#22797;&#38454;&#27573;&#65292;&#25105;&#20204;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#37325;&#24314;&#22270;&#20687;&#20013;&#30340;&#23545;&#25239;&#24615;&#21306;&#22495;&#21516;&#26102;&#20445;&#25345;&#35270;&#35273;&#20869;&#23481;&#30340;&#23436;&#25972;&#24615;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20004;&#20010;&#38454;&#27573;&#37117;&#21463;&#21040;&#32479;&#19968;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#31934;&#24515;&#24341;&#23548;&#65292;&#22240;&#27492;&#25105;&#20204;&#21487;&#20197;&#21033;&#29992;&#23427;&#20204;&#20043;&#38388;&#30340;&#32039;&#23494;&#30456;&#20114;&#20316;&#29992;&#26469;&#25552;&#39640;&#25972;&#20010;&#38450;&#24481;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial attacks, particularly patch attacks, pose significant threats to the robustness and reliability of deep learning models. Developing reliable defenses against patch attacks is crucial for real-world applications, yet current research in this area is not satisfactory. In this paper, we propose DIFFender, a novel defense method that leverages a text-guided diffusion model to defend against adversarial patches. DIFFender includes two main stages: patch localization and patch restoration. In the localization stage, we find and exploit an intriguing property of the diffusion model to effectively identify the locations of adversarial patches. In the restoration stage, we employ the diffusion model to reconstruct the adversarial regions in the images while preserving the integrity of the visual content. Importantly, these two stages are carefully guided by a unified diffusion model, thus we can utilize the close interaction between them to improve the whole defense performance. Mor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#30528;&#30524;&#20110;&#20854;&#20013;&#28041;&#21450;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#19982;&#22270;&#20687;&#20998;&#31867;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#21457;&#29616;&#36825;&#20123;&#39057;&#29575;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15203</link><description>&lt;p&gt;
&#36890;&#36807;&#20869;&#22312;&#32500;&#24230;&#23558;&#38544;&#24615;&#20559;&#35265;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#30456;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
Relating Implicit Bias and Adversarial Attacks through Intrinsic Dimension. (arXiv:2305.15203v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15203
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#30528;&#30524;&#20110;&#20854;&#20013;&#28041;&#21450;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#19982;&#22270;&#20687;&#20998;&#31867;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#21457;&#29616;&#36825;&#20123;&#39057;&#29575;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#31867;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20247;&#25152;&#21608;&#30693;&#23427;&#20204;&#26131;&#21463;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#25915;&#20987;&#26159;&#38024;&#23545;&#27169;&#22411;&#30340;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#30340;&#23567;&#24178;&#25200;&#65292;&#26088;&#22312;&#27450;&#39575;&#27169;&#22411;&#12290;&#33258;&#28982;&#32780;&#28982;&#30340;&#38382;&#39064;&#26159;&#65292;&#27169;&#22411;&#30340;&#32467;&#26500;&#12289;&#35774;&#32622;&#25110;&#23646;&#24615;&#19982;&#25915;&#20987;&#30340;&#24615;&#36136;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#28508;&#22312;&#32852;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#20851;&#27880;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#25351;&#30340;&#26159;&#20854;&#22266;&#26377;&#20542;&#21521;&#20110;&#25903;&#25345;&#29305;&#23450;&#27169;&#24335;&#25110;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38544;&#24615;&#20559;&#24046;&#30340;&#19968;&#20010;&#26041;&#38754;&#65292;&#20854;&#20013;&#21253;&#25324;&#36827;&#34892;&#20934;&#30830;&#22270;&#20687;&#20998;&#31867;&#25152;&#38656;&#30340;&#22522;&#26412;&#20613;&#37324;&#21494;&#39057;&#29575;&#12290;&#25105;&#20204;&#36827;&#34892;&#27979;&#35797;&#20197;&#35780;&#20272;&#36825;&#20123;&#39057;&#29575;&#19982;&#25104;&#21151;&#25915;&#20987;&#25152;&#38656;&#30340;&#39057;&#29575;&#20043;&#38388;&#30340;&#32479;&#35745;&#20851;&#31995;&#12290;&#20026;&#20102;&#28145;&#20837;&#25506;&#35752;&#36825;&#31181;&#20851;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#25581;&#31034;&#22352;&#26631;&#38598;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#65292;&#22312;&#25105;&#20204;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#22352;&#26631;&#38598;&#23601;&#26159;&#21069;&#36848;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their impressive performance in classification, neural networks are known to be vulnerable to adversarial attacks. These attacks are small perturbations of the input data designed to fool the model. Naturally, a question arises regarding the potential connection between the architecture, settings, or properties of the model and the nature of the attack. In this work, we aim to shed light on this problem by focusing on the implicit bias of the neural network, which refers to its inherent inclination to favor specific patterns or outcomes. Specifically, we investigate one aspect of the implicit bias, which involves the essential Fourier frequencies required for accurate image classification. We conduct tests to assess the statistical relationship between these frequencies and those necessary for a successful attack. To delve into this relationship, we propose a new method that can uncover non-linear correlations between sets of coordinates, which, in our case, are the aforementio
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#35752;&#35770;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26408;&#39532;&#25915;&#20987;&#26816;&#27979;&#21644;&#32531;&#35299;&#38382;&#39064;&#12290;&#30001;&#20110;&#36825;&#31181;&#25915;&#20987;&#21361;&#38505;&#38544;&#21311;&#65292;&#19988;&#22312;&#19979;&#28216;&#20998;&#31867;&#22120;&#20013;&#24456;&#38590;&#26816;&#27979;&#20986;&#26469;&#12290;&#30446;&#21069;&#22312;&#36229;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26408;&#39532;&#26816;&#27979;&#26041;&#27861;&#21487;&#20197;&#28508;&#22312;&#22320;&#20445;&#25252;SSL&#19979;&#28216;&#20998;&#31867;&#22120;&#65292;&#20294;&#22312;&#20854;&#24191;&#27867;&#20256;&#25773;&#20043;&#21069;&#35782;&#21035;&#21644;&#22788;&#29702;SSL&#32534;&#30721;&#22120;&#20013;&#30340;&#35302;&#21457;&#22120;&#26159;&#19968;&#39033;&#33392;&#24040;&#30340;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2303.09079</link><description>&lt;p&gt;
SSL&#28165;&#29702;&#65306;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26408;&#39532;&#26816;&#27979;&#21644;&#32531;&#35299;
&lt;/p&gt;
&lt;p&gt;
SSL-Cleanse: Trojan Detection and Mitigation in Self-Supervised Learning. (arXiv:2303.09079v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#35752;&#35770;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26408;&#39532;&#25915;&#20987;&#26816;&#27979;&#21644;&#32531;&#35299;&#38382;&#39064;&#12290;&#30001;&#20110;&#36825;&#31181;&#25915;&#20987;&#21361;&#38505;&#38544;&#21311;&#65292;&#19988;&#22312;&#19979;&#28216;&#20998;&#31867;&#22120;&#20013;&#24456;&#38590;&#26816;&#27979;&#20986;&#26469;&#12290;&#30446;&#21069;&#22312;&#36229;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26408;&#39532;&#26816;&#27979;&#26041;&#27861;&#21487;&#20197;&#28508;&#22312;&#22320;&#20445;&#25252;SSL&#19979;&#28216;&#20998;&#31867;&#22120;&#65292;&#20294;&#22312;&#20854;&#24191;&#27867;&#20256;&#25773;&#20043;&#21069;&#35782;&#21035;&#21644;&#22788;&#29702;SSL&#32534;&#30721;&#22120;&#20013;&#30340;&#35302;&#21457;&#22120;&#26159;&#19968;&#39033;&#33392;&#24040;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#23398;&#20064;&#21644;&#32534;&#30721;&#25968;&#25454;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;SSL&#22270;&#20687;&#32534;&#30721;&#22120;&#24182;&#22312;&#20854;&#39030;&#37096;&#35757;&#32451;&#19979;&#28216;&#20998;&#31867;&#22120;&#65292;&#21487;&#20197;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#23454;&#29616;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#32780;&#21482;&#38656;&#24456;&#23569;&#30340;&#26631;&#35760;&#25968;&#25454;&#12290;SSL&#30340;&#22686;&#21152;&#20351;&#29992;&#23548;&#33268;&#20102;&#19982;SSL&#32534;&#30721;&#22120;&#30456;&#20851;&#30340;&#23433;&#20840;&#30740;&#31350;&#21644;&#21508;&#31181;&#26408;&#39532;&#25915;&#20987;&#30340;&#21457;&#23637;&#12290;&#22312;SSL&#32534;&#30721;&#22120;&#20013;&#25554;&#20837;&#26408;&#39532;&#25915;&#20987;&#30340;&#21361;&#38505;&#22312;&#20110;&#23427;&#20204;&#33021;&#22815;&#38544;&#34109;&#22320;&#25805;&#20316;&#24182;&#22312;&#21508;&#31181;&#29992;&#25143;&#21644;&#35774;&#22791;&#20043;&#38388;&#24191;&#27867;&#20256;&#25773;&#12290;Trojaned&#32534;&#30721;&#22120;&#20013;&#30340;&#21518;&#38376;&#34892;&#20026;&#30340;&#23384;&#22312;&#21487;&#33021;&#20250;&#34987;&#19979;&#28216;&#20998;&#31867;&#22120;&#24847;&#22806;&#32487;&#25215;&#65292;&#20351;&#26816;&#27979;&#21644;&#32531;&#35299;&#23041;&#32961;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#34429;&#28982;&#36229;&#30417;&#30563;&#23398;&#20064;&#20013;&#24403;&#21069;&#30340;&#26408;&#39532;&#26816;&#27979;&#26041;&#27861;&#21487;&#20197;&#28508;&#22312;&#22320;&#20445;&#25252;SSL&#19979;&#28216;&#20998;&#31867;&#22120;&#65292;&#20294;&#22312;&#20854;&#24191;&#27867;&#20256;&#25773;&#20043;&#21069;&#35782;&#21035;&#21644;&#22788;&#29702;SSL&#32534;&#30721;&#22120;&#20013;&#30340;&#35302;&#21457;&#22120;&#26159;&#19968;&#39033;&#33392;&#24040;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) is a commonly used approach to learning and encoding data representations. By using a pre-trained SSL image encoder and training a downstream classifier on top of it, impressive performance can be achieved on various tasks with very little labeled data. The increasing usage of SSL has led to an uptick in security research related to SSL encoders and the development of various Trojan attacks. The danger posed by Trojan attacks inserted in SSL encoders lies in their ability to operate covertly and spread widely among various users and devices. The presence of backdoor behavior in Trojaned encoders can inadvertently be inherited by downstream classifiers, making it even more difficult to detect and mitigate the threat. Although current Trojan detection methods in supervised learning can potentially safeguard SSL downstream classifiers, identifying and addressing triggers in the SSL encoder before its widespread dissemination is a challenging task. This is be
&lt;/p&gt;</description></item></channel></rss>