# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Res2NetFuse: A Fusion Method for Infrared and Visible Images.](http://arxiv.org/abs/2112.14540) | 本文提出了一种基于Res2Net的红外和可见光图像融合框架，通过引入新的训练策略和融合策略，实现了最先进的融合性能。 |

# 详细

[^1]: Res2NetFuse：一种适用于红外和可见光图像的融合方法

    Res2NetFuse: A Fusion Method for Infrared and Visible Images. (arXiv:2112.14540v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.14540](http://arxiv.org/abs/2112.14540)

    本文提出了一种基于Res2Net的红外和可见光图像融合框架，通过引入新的训练策略和融合策略，实现了最先进的融合性能。

    

    本文提出了一种基于Res2Net的红外和可见光图像融合框架。提出的融合模型包括编码器、融合层和解码器三个部分。利用基于Res2Net的编码器提取源图像的多尺度特征，引入一种新的训练策略，仅使用单个图像进行训练。然后，基于注意力模型开发了一种新的融合策略。最后，通过解码器重构融合图像。本文还对所提出的方法进行了详细分析。实验证明，该方法在客观和主观评估中都实现了最先进的融合性能，与现有方法进行了比较。

    This paper presents a novel Res2Net-based fusion framework for infrared and visible images. The proposed fusion model has three parts: an encoder, a fusion layer and a decoder, respectively. The Res2Net-based encoder is used to extract multi-scale features of source images, the paper introducing a new training strategy for training a Res2Net-based encoder that uses only a single image. Then, a new fusion strategy is developed based on the attention model. Finally, the fused image is reconstructed by the decoder. The proposed approach is also analyzed in detail. Experiments show that our method achieves state-of-the-art fusion performance in objective and subjective assessment by comparing with the existing methods.
    

