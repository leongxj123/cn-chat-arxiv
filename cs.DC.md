# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Computation and Communication Efficient Lightweighting Vertical Federated Learning](https://arxiv.org/abs/2404.00466) | 提出轻量级纵向联邦学习（LVFL）的概念，针对计算和通信效率采用分离的轻量化策略，建立了收敛界限，并在图像分类数据集上得到了验证 |
| [^2] | [Foundation Model Based Native AI Framework in 6G with Cloud-Edge-End Collaboration.](http://arxiv.org/abs/2310.17471) | 该论文分析了从数据、智能和网络的角度来实现6G原生AI的挑战，并提出了基于基础模型的6G原生AI框架，包括自定义方法和任务导向的AI工具包，以及新的云边缘协同合作范式。 |

# 详细

[^1]: 计算和通信高效的轻量级纵向联邦学习

    Computation and Communication Efficient Lightweighting Vertical Federated Learning

    [https://arxiv.org/abs/2404.00466](https://arxiv.org/abs/2404.00466)

    提出轻量级纵向联邦学习（LVFL）的概念，针对计算和通信效率采用分离的轻量化策略，建立了收敛界限，并在图像分类数据集上得到了验证

    

    在联邦学习（FL）中探索计算和通信效率已成为一个突出和关键的研究领域。尽管大多数现有的努力都集中在提高这些效率，但由于垂直FL的不同过程和模型结构，无法直接应用基于水平FL的技术。因此，我们引入了轻量级纵向联邦学习（LVFL）的概念，旨在提高计算和通信效率。这种方法涉及针对特征模型的单独轻量化策略，以提高计算效率，并针对特征嵌入进行轻量化，以增强通信效率。此外，我们为LVFL算法建立了收敛界限，考虑了通信和计算轻量化比率。我们在图像分类数据集上对该算法进行评估的结果表明，LVFL显著减轻了c

    arXiv:2404.00466v1 Announce Type: new  Abstract: The exploration of computational and communication efficiency within Federated Learning (FL) has emerged as a prominent and crucial field of study. While most existing efforts to enhance these efficiencies have focused on Horizontal FL, the distinct processes and model structures of Vertical FL preclude the direct application of Horizontal FL-based techniques. In response, we introduce the concept of Lightweight Vertical Federated Learning (LVFL), targeting both computational and communication efficiencies. This approach involves separate lightweighting strategies for the feature model, to improve computational efficiency, and for feature embedding, to enhance communication efficiency. Moreover, we establish a convergence bound for our LVFL algorithm, which accounts for both communication and computational lightweighting ratios. Our evaluation of the algorithm on a image classification dataset reveals that LVFL significantly alleviates c
    
[^2]: 基于基础模型的6G原生AI框架与云边缘协同合作

    Foundation Model Based Native AI Framework in 6G with Cloud-Edge-End Collaboration. (arXiv:2310.17471v1 [cs.IT])

    [http://arxiv.org/abs/2310.17471](http://arxiv.org/abs/2310.17471)

    该论文分析了从数据、智能和网络的角度来实现6G原生AI的挑战，并提出了基于基础模型的6G原生AI框架，包括自定义方法和任务导向的AI工具包，以及新的云边缘协同合作范式。

    

    未来的无线通信网络有望超越以数据为中心、以设备为导向的连接方式，提供基于任务导向连接的智能沉浸式体验，特别是在预训练基础模型（PFM）的快速发展和6G原生人工智能（AI）的发展愿景下。因此，在6G中，重新定义设备和服务器之间的协作模式，构建原生智能库变得非常重要。在本文中，我们从数据、智能和网络的角度分析了实现6G原生AI的挑战。然后，我们基于基础模型提出了一个6G原生AI框架，提供了一种意图感知PFM的定制方法，展示了一个面向任务的AI工具包的构建，并概述了一种全新的云边缘协同合作范式。作为一个实际的使用案例，我们将该框架应用于编排，实现了无线通信中的最大速率之和。

    Future wireless communication networks are in a position to move beyond data-centric, device-oriented connectivity and offer intelligent, immersive experiences based on task-oriented connections, especially in the context of the thriving development of pre-trained foundation models (PFM) and the evolving vision of 6G native artificial intelligence (AI). Therefore, redefining modes of collaboration between devices and servers and constructing native intelligence libraries become critically important in 6G. In this paper, we analyze the challenges of achieving 6G native AI from the perspectives of data, intelligence, and networks. Then, we propose a 6G native AI framework based on foundation models, provide a customization approach for intent-aware PFM, present a construction of a task-oriented AI toolkit, and outline a novel cloud-edge-end collaboration paradigm. As a practical use case, we apply this framework for orchestration, achieving the maximum sum rate within a wireless communic
    

