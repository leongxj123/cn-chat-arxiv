<rss version="2.0"><channel><title>Chat Arxiv cs.DS</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DS</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00680</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Scalable Learning of Item Response Theory Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00680
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#65288;IRT&#65289;&#27169;&#22411;&#26088;&#22312;&#35780;&#20272; $n$ &#21517;&#32771;&#29983;&#30340;&#28508;&#22312;&#33021;&#21147;&#20197;&#21450; $m$ &#20010;&#27979;&#39564;&#39033;&#30446;&#30340;&#38544;&#21547;&#38590;&#24230;&#29305;&#24449;&#65292;&#36825;&#20123;&#39033;&#30446;&#26159;&#20174;&#34920;&#26126;&#20854;&#23545;&#24212;&#31572;&#26696;&#36136;&#37327;&#30340;&#20998;&#31867;&#25968;&#25454;&#20013;&#24471;&#20986;&#30340;&#12290;&#20256;&#32479;&#30340;&#24515;&#29702;&#27979;&#37327;&#35780;&#20272;&#22522;&#20110;&#30456;&#23545;&#36739;&#23569;&#30340;&#32771;&#29983;&#21644;&#39033;&#30446;&#65292;&#20363;&#22914;&#19968;&#20010;&#30001; $200$ &#21517;&#23398;&#29983;&#35299;&#20915;&#21253;&#21547; $10$ &#36947;&#39064;&#30446;&#30340;&#32771;&#35797;&#30340;&#29677;&#32423;&#12290;&#32780;&#36817;&#24180;&#26469;&#30340;&#20840;&#29699;&#22823;&#35268;&#27169;&#35780;&#20272;&#65292;&#22914;PISA&#65292;&#25110;&#20114;&#32852;&#32593;&#30740;&#31350;&#65292;&#21487;&#33021;&#23548;&#33268;&#21442;&#19982;&#32773;&#25968;&#37327;&#26174;&#33879;&#22686;&#21152;&#12290;&#27492;&#22806;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#31639;&#27861;&#25198;&#28436;&#32771;&#29983;&#35282;&#33394;&#65292;&#25968;&#25454;&#20998;&#26512;&#38382;&#39064;&#25198;&#28436;&#39033;&#30446;&#35282;&#33394;&#65292;$n$ &#21644; $m$ &#37117;&#21487;&#33021;&#21464;&#24471;&#38750;&#24120;&#22823;&#65292;&#25361;&#25112;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;&#20026;&#20102;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;IRT&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#21518;&#32773;&#21487;&#20197;&#20351;&#29992;s&#20934;&#30830;&#22320;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00680v1 Announce Type: new  Abstract: Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using s
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#29992;&#20110;&#20122;&#32447;&#24615;&#36229;&#20307;&#31215;&#36951;&#25022;&#24230;&#37327;&#30340;&#26368;&#20248;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#26041;&#27861;&#22312;&#26368;&#23567;&#21270;&#36229;&#20307;&#31215;&#36951;&#25022;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#22810;&#30446;&#26631;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.03288</link><description>&lt;p&gt;
&#29992;&#20110;&#20122;&#32447;&#24615;&#36229;&#20307;&#31215;&#36951;&#25022;&#24230;&#37327;&#30340;&#26368;&#20248;&#26631;&#37327;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Scalarizations for Sublinear Hypervolume Regret. (arXiv:2307.03288v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03288
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#29992;&#20110;&#20122;&#32447;&#24615;&#36229;&#20307;&#31215;&#36951;&#25022;&#24230;&#37327;&#30340;&#26368;&#20248;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#26041;&#27861;&#22312;&#26368;&#23567;&#21270;&#36229;&#20307;&#31215;&#36951;&#25022;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#22810;&#30446;&#26631;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#37327;&#21270;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#22810;&#30446;&#26631;&#35774;&#32622;&#20013;&#65292;&#23558;&#22810;&#20010;&#30446;&#26631;&#20943;&#23569;&#20026;&#19968;&#20010;&#65292;&#20363;&#22914;&#26368;&#36817;&#22312;RLHF&#20013;&#29992;&#20110;&#35757;&#32451;&#26657;&#20934;&#20154;&#31867;&#20559;&#22909;&#30340;&#22870;&#21169;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#20154;&#23545;&#36825;&#31181;&#32463;&#20856;&#26041;&#27861;&#25345;&#21542;&#23450;&#24577;&#24230;&#65292;&#22240;&#20026;&#24050;&#30693;&#32447;&#24615;&#26631;&#37327;&#21270;&#20250;&#24573;&#30053;&#24085;&#32047;&#25176;&#21069;&#27839;&#30340;&#20985;&#21306;&#22495;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#26088;&#22312;&#25214;&#21040;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;&#20197;&#36890;&#36807;&#34987;&#25903;&#37197;&#30340;&#36229;&#20307;&#31215;&#26469;&#25506;&#32034;&#24085;&#32047;&#25176;&#21069;&#27839;&#19978;&#30340;&#22810;&#26679;&#21270;&#30446;&#26631;&#38598;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20855;&#26377;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#20196;&#20154;&#24778;&#35766;&#22320;&#26159;&#20026;&#20102;&#35777;&#26126;&#26368;&#23567;&#21270;&#36229;&#20307;&#31215;&#36951;&#25022;&#32780;&#26368;&#20248;&#30340;&#65292;&#23454;&#29616;&#20102; $O(T^{-1/k})$ &#30340;&#26368;&#20248;&#20122;&#32447;&#24615;&#36951;&#25022;&#30028;&#65292;&#21516;&#26102;&#21305;&#37197;&#30340;&#19979;&#30028;&#34920;&#26126;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#27809;&#26377;&#20219;&#20309;&#31639;&#27861;&#33021;&#20570;&#24471;&#26356;&#22909;&#12290;&#20316;&#20026;&#19968;&#20010;&#29702;&#35770;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#30446;&#26631;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#36890;&#36807;&#21033;&#29992;&#36229;&#32447;&#24615;&#36951;&#25022;&#30028;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;
&lt;/p&gt;
&lt;p&gt;
Scalarization is a general technique that can be deployed in any multiobjective setting to reduce multiple objectives into one, such as recently in RLHF for training reward models that align human preferences. Yet some have dismissed this classical approach because linear scalarizations are known to miss concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that can explore a diverse set of $k$ objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights are surprisingly optimal for provably minimizing the hypervolume regret, achieving an optimal sublinear regret bound of $O(T^{-1/k})$, with matching lower bounds that preclude any algorithm from doing better asymptotically. As a theoretical case study, we consider the multiobjective stochastic linear bandits problem and demonstrate that by exploiting the sublinear regret bounds of the hypervolume scalariz
&lt;/p&gt;</description></item></channel></rss>