<rss version="2.0"><channel><title>Chat Arxiv cs.DS</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DS</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#20351;&#29992;&#24555;&#36895;&#20294;&#19981;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#26469;&#21152;&#36895;&#25311;&#38453;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#38469;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#32500;&#25345;&#23545;&#19981;&#21516;&#36136;&#37327;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#30340;&#21516;&#26102;&#65292;&#21482;&#20351;&#29992;&#20102;&#24456;&#23569;&#30340;&#26597;&#35810;</title><link>https://arxiv.org/abs/2402.02774</link><description>&lt;p&gt;
&#36890;&#36807;&#24555;&#36895;&#19981;&#20934;&#30830;&#30340;&#39044;&#27979;&#20248;&#21270;&#21152;&#36895;&#25311;&#38453;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Accelerating Matroid Optimization through Fast Imprecise Oracles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#20351;&#29992;&#24555;&#36895;&#20294;&#19981;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#26469;&#21152;&#36895;&#25311;&#38453;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#38469;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#32500;&#25345;&#23545;&#19981;&#21516;&#36136;&#37327;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#30340;&#21516;&#26102;&#65292;&#21482;&#20351;&#29992;&#20102;&#24456;&#23569;&#30340;&#26597;&#35810;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#22797;&#26434;&#27169;&#22411;&#20197;&#33719;&#24471;&#20934;&#30830;&#20449;&#24687;&#65288;&#20363;&#22914;&#27969;&#37327;&#27169;&#22411;&#12289;&#25968;&#25454;&#24211;&#31995;&#32479;&#12289;&#22823;&#22411;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65289;&#36890;&#24120;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#21644;&#36739;&#38271;&#30340;&#21709;&#24212;&#26102;&#38388;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#21487;&#20197;&#29992;&#36739;&#23569;&#30340;&#26597;&#35810;&#24378;&#27169;&#22411;&#35299;&#20915;&#19981;&#20934;&#30830;&#32467;&#26524;&#30340;&#38382;&#39064;&#65292;&#37027;&#20040;&#20351;&#29992;&#33021;&#22815;&#24555;&#36895;&#32473;&#20986;&#19981;&#20934;&#30830;&#32467;&#26524;&#30340;&#36739;&#24369;&#27169;&#22411;&#26159;&#26377;&#20248;&#21183;&#30340;&#12290;&#22312;&#35745;&#31639;&#19968;&#20010;&#25311;&#38453;&#30340;&#26368;&#22823;&#26435;&#37325;&#22522;&#30784;&#30340;&#22522;&#30784;&#38382;&#39064;&#20013;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159;&#35768;&#22810;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#20010;&#24050;&#30693;&#27867;&#21270;&#12290;&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#19968;&#20010;&#24178;&#20928;&#30340;&#26597;&#35810;&#25311;&#38453;&#20449;&#24687;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#39069;&#22806;&#25552;&#20379;&#20102;&#19968;&#20010;&#24555;&#36895;&#20294;&#33039;&#30340;&#39044;&#27979;&#27169;&#22411;&#26469;&#27169;&#25311;&#19968;&#20010;&#26410;&#30693;&#30340;&#12289;&#21487;&#33021;&#19981;&#21516;&#30340;&#25311;&#38453;&#12290;&#25105;&#20204;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;&#23454;&#38469;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#21482;&#20351;&#29992;&#24456;&#23569;&#25968;&#37327;&#30340;&#24178;&#20928;&#26597;&#35810;&#30456;&#23545;&#20110;&#33039;&#39044;&#27979;&#27169;&#22411;&#30340;&#36136;&#37327;&#65292;&#21516;&#26102;&#20445;&#25345;&#23545;&#20219;&#24847;&#36136;&#37327;&#24046;&#30340;&#33039;&#25311;&#38453;&#30340;&#24378;&#20581;&#24615;&#65292;&#24182;&#25509;&#36817;&#32473;&#23450;&#38382;&#39064;&#30340;&#32463;&#20856;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#35768;&#22810;&#26041;&#38754;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#26368;&#20339;&#30340;
&lt;/p&gt;
&lt;p&gt;
Querying complex models for precise information (e.g. traffic models, database systems, large ML models) often entails intense computations and results in long response times. Thus, weaker models which give imprecise results quickly can be advantageous, provided inaccuracies can be resolved using few queries to a stronger model. In the fundamental problem of computing a maximum-weight basis of a matroid, a well-known generalization of many combinatorial optimization problems, algorithms have access to a clean oracle to query matroid information. We additionally equip algorithms with a fast but dirty oracle modelling an unknown, potentially different matroid. We design and analyze practical algorithms which only use few clean queries w.r.t. the quality of the dirty oracle, while maintaining robustness against arbitrarily poor dirty matroids, approaching the performance of classic algorithms for the given problem. Notably, we prove that our algorithms are, in many respects, best-possible
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#29992;&#20110;&#20122;&#32447;&#24615;&#36229;&#20307;&#31215;&#36951;&#25022;&#24230;&#37327;&#30340;&#26368;&#20248;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#26041;&#27861;&#22312;&#26368;&#23567;&#21270;&#36229;&#20307;&#31215;&#36951;&#25022;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#22810;&#30446;&#26631;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.03288</link><description>&lt;p&gt;
&#29992;&#20110;&#20122;&#32447;&#24615;&#36229;&#20307;&#31215;&#36951;&#25022;&#24230;&#37327;&#30340;&#26368;&#20248;&#26631;&#37327;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Scalarizations for Sublinear Hypervolume Regret. (arXiv:2307.03288v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03288
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#29992;&#20110;&#20122;&#32447;&#24615;&#36229;&#20307;&#31215;&#36951;&#25022;&#24230;&#37327;&#30340;&#26368;&#20248;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#26041;&#27861;&#22312;&#26368;&#23567;&#21270;&#36229;&#20307;&#31215;&#36951;&#25022;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#22810;&#30446;&#26631;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#37327;&#21270;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#22810;&#30446;&#26631;&#35774;&#32622;&#20013;&#65292;&#23558;&#22810;&#20010;&#30446;&#26631;&#20943;&#23569;&#20026;&#19968;&#20010;&#65292;&#20363;&#22914;&#26368;&#36817;&#22312;RLHF&#20013;&#29992;&#20110;&#35757;&#32451;&#26657;&#20934;&#20154;&#31867;&#20559;&#22909;&#30340;&#22870;&#21169;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#20154;&#23545;&#36825;&#31181;&#32463;&#20856;&#26041;&#27861;&#25345;&#21542;&#23450;&#24577;&#24230;&#65292;&#22240;&#20026;&#24050;&#30693;&#32447;&#24615;&#26631;&#37327;&#21270;&#20250;&#24573;&#30053;&#24085;&#32047;&#25176;&#21069;&#27839;&#30340;&#20985;&#21306;&#22495;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#26088;&#22312;&#25214;&#21040;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;&#20197;&#36890;&#36807;&#34987;&#25903;&#37197;&#30340;&#36229;&#20307;&#31215;&#26469;&#25506;&#32034;&#24085;&#32047;&#25176;&#21069;&#27839;&#19978;&#30340;&#22810;&#26679;&#21270;&#30446;&#26631;&#38598;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20855;&#26377;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#20196;&#20154;&#24778;&#35766;&#22320;&#26159;&#20026;&#20102;&#35777;&#26126;&#26368;&#23567;&#21270;&#36229;&#20307;&#31215;&#36951;&#25022;&#32780;&#26368;&#20248;&#30340;&#65292;&#23454;&#29616;&#20102; $O(T^{-1/k})$ &#30340;&#26368;&#20248;&#20122;&#32447;&#24615;&#36951;&#25022;&#30028;&#65292;&#21516;&#26102;&#21305;&#37197;&#30340;&#19979;&#30028;&#34920;&#26126;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#27809;&#26377;&#20219;&#20309;&#31639;&#27861;&#33021;&#20570;&#24471;&#26356;&#22909;&#12290;&#20316;&#20026;&#19968;&#20010;&#29702;&#35770;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#30446;&#26631;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#36890;&#36807;&#21033;&#29992;&#36229;&#32447;&#24615;&#36951;&#25022;&#30028;&#30340;&#36229;&#20307;&#31215;&#26631;&#37327;&#21270;&#26041;&#27861;&#65292;
&lt;/p&gt;
&lt;p&gt;
Scalarization is a general technique that can be deployed in any multiobjective setting to reduce multiple objectives into one, such as recently in RLHF for training reward models that align human preferences. Yet some have dismissed this classical approach because linear scalarizations are known to miss concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that can explore a diverse set of $k$ objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights are surprisingly optimal for provably minimizing the hypervolume regret, achieving an optimal sublinear regret bound of $O(T^{-1/k})$, with matching lower bounds that preclude any algorithm from doing better asymptotically. As a theoretical case study, we consider the multiobjective stochastic linear bandits problem and demonstrate that by exploiting the sublinear regret bounds of the hypervolume scalariz
&lt;/p&gt;</description></item></channel></rss>