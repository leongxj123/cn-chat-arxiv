<rss version="2.0"><channel><title>Chat Arxiv cs.DS</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DS</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20998;&#24067;&#24335;&#23384;&#20648;&#22810;&#22788;&#29702;&#22120;&#19978;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#36817;&#20284;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#39046;&#22495;&#20013;&#28023;&#37327;&#25968;&#25454;&#38598;&#19978;&#30340;&#23376;&#27169;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.10332</link><description>&lt;p&gt;
GreedyML&#65306;&#19968;&#31181;&#29992;&#20110;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
GreedyML: A Parallel Algorithm for Maximizing Submodular Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10332
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20998;&#24067;&#24335;&#23384;&#20648;&#22810;&#22788;&#29702;&#22120;&#19978;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#36817;&#20284;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#39046;&#22495;&#20013;&#28023;&#37327;&#25968;&#25454;&#38598;&#19978;&#30340;&#23376;&#27169;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20998;&#24067;&#24335;&#23384;&#20648;&#22810;&#22788;&#29702;&#22120;&#19978;&#26368;&#22823;&#21270;&#21333;&#35843;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#36817;&#20284;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21463;&#21040;&#22312;&#28023;&#37327;&#25968;&#25454;&#38598;&#19978;&#35299;&#20915;&#23376;&#27169;&#20248;&#21270;&#38382;&#39064;&#30340;&#38656;&#27714;&#30340;&#21551;&#21457;&#65292;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#39046;&#22495;&#65292;&#22914;&#25968;&#25454;&#25688;&#35201;&#65292;&#26426;&#22120;&#23398;&#20064;&#21644;&#22270;&#31232;&#30095;&#21270;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;Barbosa&#12289;Ene&#12289;Nguyen&#21644;Ward&#65288;2015&#65289;&#25552;&#20986;&#30340;&#38543;&#26426;&#20998;&#24067;&#24335;RandGreedI&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#23558;&#25968;&#25454;&#38543;&#26426;&#20998;&#21306;&#21040;&#25152;&#26377;&#22788;&#29702;&#22120;&#20013;&#65292;&#28982;&#21518;&#20351;&#29992;&#21333;&#20010;&#32047;&#31215;&#27493;&#39588;&#35745;&#31639;&#20998;&#24067;&#24335;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#25152;&#26377;&#22788;&#29702;&#22120;&#23558;&#23427;&#20204;&#30340;&#37096;&#20998;&#35299;&#20915;&#26041;&#26696;&#21457;&#36865;&#32473;&#19968;&#20010;&#22788;&#29702;&#22120;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#38382;&#39064;&#65292;&#32047;&#31215;&#27493;&#39588;&#21487;&#33021;&#36229;&#36807;&#22788;&#29702;&#22120;&#19978;&#21487;&#29992;&#30340;&#20869;&#23384;&#65292;&#24182;&#19988;&#25191;&#34892;&#32047;&#31215;&#30340;&#22788;&#29702;&#22120;&#21487;&#33021;&#25104;&#20026;&#35745;&#31639;&#29942;&#39048;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10332v1 Announce Type: cross  Abstract: We describe a parallel approximation algorithm for maximizing monotone submodular functions subject to hereditary constraints on distributed memory multiprocessors. Our work is motivated by the need to solve submodular optimization problems on massive data sets, for practical applications in areas such as data summarization, machine learning, and graph sparsification. Our work builds on the randomized distributed RandGreedI algorithm, proposed by Barbosa, Ene, Nguyen, and Ward (2015). This algorithm computes a distributed solution by randomly partitioning the data among all the processors and then employing a single accumulation step in which all processors send their partial solutions to one processor. However, for large problems, the accumulation step could exceed the memory available on a processor, and the processor which performs the accumulation could become a computational bottleneck.   Here, we propose a generalization of the R
&lt;/p&gt;</description></item></channel></rss>