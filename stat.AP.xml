<rss version="2.0"><channel><title>Chat Arxiv stat.AP</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.AP</description><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#37325;&#24615;&#25233;&#37057;&#38556;&#30861;(MDD)&#20013;&#30340;&#22870;&#21169;&#22788;&#29702;&#24322;&#24120;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#32467;&#21512;&#65292;&#25506;&#32034;&#20915;&#31574;&#21046;&#23450;&#36807;&#31243;&#20013;&#30340;&#23398;&#20064;&#31574;&#30053;&#21160;&#24577;&#23545;&#20010;&#20307;&#22870;&#21169;&#23398;&#20064;&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.13929</link><description>&lt;p&gt;
&#20351;&#29992;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#26469;&#21457;&#29616;&#20915;&#31574;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Hidden Markov Models for Discovering Decision-Making Dynamics. (arXiv:2401.13929v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#37325;&#24615;&#25233;&#37057;&#38556;&#30861;(MDD)&#20013;&#30340;&#22870;&#21169;&#22788;&#29702;&#24322;&#24120;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#32467;&#21512;&#65292;&#25506;&#32034;&#20915;&#31574;&#21046;&#23450;&#36807;&#31243;&#20013;&#30340;&#23398;&#20064;&#31574;&#30053;&#21160;&#24577;&#23545;&#20010;&#20307;&#22870;&#21169;&#23398;&#20064;&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#22797;&#26434;&#21644;&#24322;&#36136;&#24615;&#65292;&#37325;&#24615;&#25233;&#37057;&#38556;&#30861;(MDD)&#22312;&#35786;&#26029;&#21644;&#27835;&#30103;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#12290;&#26032;&#30340;&#35777;&#25454;&#34920;&#26126;&#22870;&#21169;&#22788;&#29702;&#24322;&#24120;&#21487;&#33021;&#20316;&#20026;MDD&#30340;&#34892;&#20026;&#26631;&#35760;&#12290;&#20026;&#20102;&#34913;&#37327;&#22870;&#21169;&#22788;&#29702;&#65292;&#24739;&#32773;&#25191;&#34892;&#28041;&#21450;&#20570;&#20986;&#36873;&#25321;&#25110;&#23545;&#19982;&#19981;&#21516;&#32467;&#26524;&#30456;&#20851;&#32852;&#30340;&#21050;&#28608;&#20316;&#20986;&#21453;&#24212;&#30340;&#22522;&#20110;&#35745;&#31639;&#26426;&#30340;&#34892;&#20026;&#20219;&#21153;&#12290;&#24378;&#21270;&#23398;&#20064;(RL)&#27169;&#22411;&#34987;&#25311;&#21512;&#20197;&#25552;&#21462;&#34913;&#37327;&#22870;&#21169;&#22788;&#29702;&#21508;&#20010;&#26041;&#38754;&#30340;&#21442;&#25968;&#65292;&#20197;&#34920;&#24449;&#24739;&#32773;&#22312;&#34892;&#20026;&#20219;&#21153;&#20013;&#30340;&#20915;&#31574;&#26041;&#24335;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#20165;&#22522;&#20110;&#21333;&#20010;RL&#27169;&#22411;&#30340;&#22870;&#21169;&#23398;&#20064;&#34920;&#24449;&#19981;&#36275;; &#30456;&#21453;&#65292;&#20915;&#31574;&#36807;&#31243;&#20013;&#21487;&#33021;&#23384;&#22312;&#22810;&#31181;&#31574;&#30053;&#20043;&#38388;&#30340;&#20999;&#25442;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#31185;&#23398;&#38382;&#39064;&#26159;&#20915;&#31574;&#21046;&#23450;&#20013;&#23398;&#20064;&#31574;&#30053;&#30340;&#21160;&#24577;&#22914;&#20309;&#24433;&#21709;MDD&#24739;&#32773;&#30340;&#22870;&#21169;&#23398;&#20064;&#33021;&#21147;&#12290;&#30001;&#27010;&#29575;&#22870;&#21169;&#20219;&#21153;(PRT)&#25152;&#21551;&#21457;
&lt;/p&gt;
&lt;p&gt;
Major depressive disorder (MDD) presents challenges in diagnosis and treatment due to its complex and heterogeneous nature. Emerging evidence indicates that reward processing abnormalities may serve as a behavioral marker for MDD. To measure reward processing, patients perform computer-based behavioral tasks that involve making choices or responding to stimulants that are associated with different outcomes. Reinforcement learning (RL) models are fitted to extract parameters that measure various aspects of reward processing to characterize how patients make decisions in behavioral tasks. Recent findings suggest the inadequacy of characterizing reward learning solely based on a single RL model; instead, there may be a switching of decision-making processes between multiple strategies. An important scientific question is how the dynamics of learning strategies in decision-making affect the reward learning ability of individuals with MDD. Motivated by the probabilistic reward task (PRT) wi
&lt;/p&gt;</description></item><item><title>&#26412;&#27425;&#35843;&#26597;&#24635;&#32467;&#20102;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#22312;&#26234;&#33021;&#21046;&#36896;&#21644;&#20135;&#19994;4.0&#32972;&#26223;&#19979;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#31361;&#20986;&#20102;&#20854;&#22312;&#24037;&#19994;&#29983;&#20135;&#21644;&#21046;&#36896;&#39046;&#22495;&#30340;&#20851;&#38190;&#20248;&#21183;&#21644;&#25361;&#25112;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#20805;&#20998;&#21033;&#29992;&#30340;TDA&#26041;&#27861;&#21644;&#24050;&#35782;&#21035;&#30340;&#24212;&#29992;&#31867;&#22411;&#65292;&#20197;&#25512;&#21160;&#26356;&#22810;&#30340;&#30456;&#20851;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2310.09319</link><description>&lt;p&gt;
&#26234;&#33021;&#21046;&#36896;&#36807;&#31243;&#20013;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;--&#20851;&#20110;&#29616;&#29366;&#30340;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Topological Data Analysis in smart manufacturing processes -- A survey on the state of the art. (arXiv:2310.09319v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09319
&lt;/p&gt;
&lt;p&gt;
&#26412;&#27425;&#35843;&#26597;&#24635;&#32467;&#20102;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#22312;&#26234;&#33021;&#21046;&#36896;&#21644;&#20135;&#19994;4.0&#32972;&#26223;&#19979;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#31361;&#20986;&#20102;&#20854;&#22312;&#24037;&#19994;&#29983;&#20135;&#21644;&#21046;&#36896;&#39046;&#22495;&#30340;&#20851;&#38190;&#20248;&#21183;&#21644;&#25361;&#25112;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#20805;&#20998;&#21033;&#29992;&#30340;TDA&#26041;&#27861;&#21644;&#24050;&#35782;&#21035;&#30340;&#24212;&#29992;&#31867;&#22411;&#65292;&#20197;&#25512;&#21160;&#26356;&#22810;&#30340;&#30456;&#20851;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65288;TDA&#65289;&#26159;&#19968;&#31181;&#20351;&#29992;&#25299;&#25169;&#23398;&#25216;&#26415;&#23545;&#22797;&#26434;&#30340;&#22810;&#32500;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#30340;&#25968;&#23398;&#26041;&#27861;&#65292;&#24050;&#32463;&#22312;&#21307;&#23398;&#12289;&#26448;&#26009;&#31185;&#23398;&#12289;&#29983;&#29289;&#23398;&#31561;&#22810;&#20010;&#39046;&#22495;&#34987;&#24191;&#27867;&#32780;&#25104;&#21151;&#22320;&#24212;&#29992;&#12290;&#26412;&#35843;&#26597;&#24635;&#32467;&#20102;TDA&#22312;&#21478;&#19968;&#20010;&#24212;&#29992;&#39046;&#22495;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#65306;&#24037;&#19994;&#21046;&#36896;&#21644;&#20135;&#19994;4.0&#32972;&#26223;&#19979;&#30340;&#29983;&#20135;&#12290;&#25105;&#20204;&#23545;&#24037;&#19994;&#29983;&#20135;&#21644;&#21046;&#36896;&#39046;&#22495;&#20013;TDA&#24212;&#29992;&#36827;&#34892;&#20102;&#20005;&#35880;&#21487;&#37325;&#22797;&#30340;&#25991;&#29486;&#25628;&#32034;&#12290;&#36890;&#36807;&#23545;&#32467;&#26524;&#36827;&#34892;&#32858;&#31867;&#21644;&#20998;&#26512;&#65292;&#22522;&#20110;&#20854;&#22312;&#21046;&#36896;&#36807;&#31243;&#20013;&#30340;&#24212;&#29992;&#39046;&#22495;&#21644;&#36755;&#20837;&#25968;&#25454;&#31867;&#22411;&#36827;&#34892;&#35770;&#36848;&#12290;&#25105;&#20204;&#31361;&#20986;&#20102;TDA&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#20851;&#38190;&#20248;&#21183;&#21450;&#20854;&#24037;&#20855;&#65292;&#24182;&#25551;&#36848;&#20102;&#23427;&#30340;&#25361;&#25112;&#20197;&#21450;&#26410;&#26469;&#30340;&#28508;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#65288;&#29305;&#23450;&#39046;&#22495;&#30340;&#65289;&#24037;&#19994;&#20013;&#26410;&#20805;&#20998;&#21033;&#29992;&#30340;TDA&#26041;&#27861;&#21644;&#24050;&#35782;&#21035;&#30340;&#24212;&#29992;&#31867;&#22411;&#65292;&#26088;&#22312;&#20419;&#36827;&#26356;&#22810;&#30340;&#30740;&#31350;&#22312;&#24403;&#21069;&#39046;&#22495;&#20013;&#30340;&#24320;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topological Data Analysis (TDA) is a mathematical method using techniques from topology for the analysis of complex, multi-dimensional data that has been widely and successfully applied in several fields such as medicine, material science, biology, and others. This survey summarizes the state of the art of TDA in yet another application area: industrial manufacturing and production in the context of Industry 4.0. We perform a rigorous and reproducible literature search of applications of TDA on the setting of industrial production and manufacturing. The resulting works are clustered and analyzed based on their application area within the manufacturing process and their input data type. We highlight the key benefits of TDA and their tools in this area and describe its challenges, as well as future potential. Finally, we discuss which TDA methods are underutilized in (the specific area of) industry and the identified types of application, with the goal of prompting more research in this 
&lt;/p&gt;</description></item></channel></rss>