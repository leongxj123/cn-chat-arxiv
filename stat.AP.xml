<rss version="2.0"><channel><title>Chat Arxiv stat.AP</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.AP</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;&#65292;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2312.02946</link><description>&lt;p&gt;
&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Calibrating dimension reduction hyperparameters in the presence of noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;&#65292;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#32500;&#24037;&#20855;&#30340;&#30446;&#26631;&#26159;&#26500;&#24314;&#39640;&#32500;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#36825;&#20123;&#24037;&#20855;&#34987;&#29992;&#20110;&#22122;&#22768;&#38477;&#20302;&#12289;&#21487;&#35270;&#21270;&#21644;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#31561;&#21508;&#31181;&#21407;&#22240;&#12290;&#28982;&#32780;&#65292;&#22312;&#38477;&#32500;&#25991;&#29486;&#20013;&#20960;&#20046;&#27809;&#26377;&#35752;&#35770;&#36807;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#36807;&#25311;&#21512;&#65292;&#32780;&#22312;&#20854;&#20182;&#24314;&#27169;&#38382;&#39064;&#20013;&#36825;&#20010;&#38382;&#39064;&#24050;&#32463;&#34987;&#24191;&#27867;&#35752;&#35770;&#12290;&#22914;&#26524;&#25105;&#20204;&#23558;&#25968;&#25454;&#35299;&#37322;&#20026;&#20449;&#21495;&#21644;&#22122;&#22768;&#30340;&#32452;&#21512;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#23545;&#38477;&#32500;&#25216;&#26415;&#30340;&#35780;&#21028;&#26159;&#20854;&#26159;&#21542;&#33021;&#22815;&#25429;&#25417;&#21040;&#25968;&#25454;&#30340;&#20840;&#37096;&#20869;&#23481;&#65292;&#21363;&#20449;&#21495;&#21644;&#22122;&#22768;&#12290;&#22312;&#20854;&#20182;&#24314;&#27169;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#20250;&#37319;&#29992;&#29305;&#24449;&#36873;&#25321;&#12289;&#20132;&#21449;&#39564;&#35777;&#21644;&#27491;&#21017;&#21270;&#31561;&#25216;&#26415;&#26469;&#38450;&#27490;&#36807;&#25311;&#21512;&#65292;&#20294;&#22312;&#36827;&#34892;&#38477;&#32500;&#26102;&#21364;&#27809;&#26377;&#37319;&#21462;&#31867;&#20284;&#30340;&#39044;&#38450;&#25514;&#26045;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#24314;&#27169;&#38477;&#32500;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#35813;&#26694;&#26550;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of dimension reduction tools is to construct a low-dimensional representation of high-dimensional data. These tools are employed for a variety of reasons such as noise reduction, visualization, and to lower computational costs. However, there is a fundamental issue that is highly discussed in other modeling problems, but almost entirely ignored in the dimension reduction literature: overfitting. If we interpret data as a combination of signal and noise, prior works judge dimension reduction techniques on their ability to capture the entirety of the data, i.e. both the signal and the noise. In the context of other modeling problems, techniques such as feature-selection, cross-validation, and regularization are employed to combat overfitting, but no such precautions are taken when performing dimension reduction. In this paper, we present a framework that models dimension reduction problems in the presence of noise and use this framework to explore the role perplexity and number 
&lt;/p&gt;</description></item></channel></rss>