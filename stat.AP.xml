<rss version="2.0"><channel><title>Chat Arxiv stat.AP</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.AP</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#23613;&#31649;&#23427;&#20204;&#33021;&#22815;&#34701;&#20837;&#21644;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#12290;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.06049</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Limits of Large Language Models in Debating Humans
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06049
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#23613;&#31649;&#23427;&#20204;&#33021;&#22815;&#34701;&#20837;&#21644;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#12290;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#19982;&#20154;&#31867;&#30340;&#20114;&#21160;&#20013;&#23637;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#28508;&#21147;&#12290;&#38543;&#21518;&#65292;&#23558;&#23427;&#20204;&#20316;&#20026;&#20154;&#24037;&#20195;&#34920;&#21644;&#26367;&#20195;&#21697;&#36827;&#34892;&#31038;&#20250;&#23398;&#23454;&#39564;&#30340;&#28508;&#22312;&#24212;&#29992;&#26159;&#19968;&#20010;&#20196;&#20154;&#28608;&#21160;&#30340;&#21069;&#26223;&#12290;&#20294;&#26159;&#36825;&#20010;&#24819;&#27861;&#26377;&#22810;&#21487;&#34892;&#21602;&#65311;&#26412;&#25991;&#35797;&#22270;&#36890;&#36807;&#19968;&#39033;&#39044;&#20808;&#27880;&#20876;&#30340;&#30740;&#31350;&#26469;&#27979;&#35797;&#29616;&#38454;&#27573;LLMs&#30340;&#23616;&#38480;&#24615;&#65292;&#35813;&#30740;&#31350;&#23558;&#30495;&#23454;&#30340;&#20154;&#31867;&#19982;&#25198;&#28436;&#20154;&#31867;&#30340;LLM&#20195;&#29702;&#32467;&#21512;&#36215;&#26469;&#12290;&#26412;&#30740;&#31350;&#30528;&#37325;&#25506;&#35752;&#36777;&#35770;&#20026;&#22522;&#30784;&#30340;&#24847;&#35265;&#20849;&#35782;&#24418;&#25104;&#22312;&#19977;&#31181;&#29615;&#22659;&#19979;&#30340;&#24773;&#20917;&#65306;&#20165;&#20154;&#31867;&#12289;&#20195;&#29702;&#21644;&#20154;&#31867;&#12289;&#20165;&#20195;&#29702;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#29702;&#35299;LLM&#20195;&#29702;&#23545;&#20154;&#31867;&#30340;&#24433;&#21709;&#65292;&#24182;&#35780;&#20272;&#23427;&#20204;&#22312;&#36777;&#35770;&#26041;&#38754;&#30340;&#33021;&#21147;&#26159;&#21542;&#19982;&#20154;&#31867;&#30456;&#20284;&#12290;&#25105;&#20204;&#21457;&#29616;LLMs&#33021;&#22815;&#34701;&#20837;&#24182;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#65292;&#26368;&#32456;&#34892;&#20026;&#19982;&#20154;&#31867;&#26377;&#25152;&#20559;&#31163;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#36825;&#20123;&#20027;&#35201;&#32570;&#38519;&#65292;&#24182;&#39044;&#35745;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#24517;&#39035;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown remarkable promise in their ability to interact proficiently with humans. Subsequently, their potential use as artificial confederates and surrogates in sociological experiments involving conversation is an exciting prospect. But how viable is this idea? This paper endeavors to test the limits of current-day LLMs with a pre-registered study integrating real people with LLM agents acting as people. The study focuses on debate-based opinion consensus formation in three environments: humans only, agents and humans, and agents only. Our goal is to understand how LLM agents influence humans, and how capable they are in debating like humans. We find that LLMs can blend in and facilitate human productivity but are less convincing in debate, with their behavior ultimately deviating from human's. We elucidate these primary failings and anticipate that LLMs must evolve further before being viable debaters.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.05026</link><description>&lt;p&gt;
&#24102;&#26377;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#21512;&#25104;&#23545;&#29031;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification in Synthetic Controls with Staggered Treatment Adoption. (arXiv:2210.05026v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05026
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#29992;&#20110;&#37327;&#21270;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#22823;&#31867;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20379;&#31934;&#30830;&#30340;&#38750;&#28176;&#36817;&#35206;&#30422;&#27010;&#29575;&#20445;&#35777;&#12290;&#20174;&#26041;&#27861;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#38656;&#35201;&#39044;&#27979;&#30340;&#19981;&#21516;&#22240;&#26524;&#37327;&#36827;&#34892;&#35814;&#32454;&#35752;&#35770;&#65292;&#25105;&#20204;&#31216;&#20854;&#20026;&#8220;&#22240;&#26524;&#39044;&#27979;&#37327;&#8221;&#65292;&#20801;&#35768;&#22312;&#21487;&#33021;&#19981;&#21516;&#26102;&#21051;&#36827;&#34892;&#22810;&#20010;&#22788;&#29702;&#21333;&#20803;&#30340;&#22788;&#29702;&#37319;&#29992;&#12290;&#20174;&#29702;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#25552;&#39640;&#20102;&#20043;&#21069;&#25991;&#29486;&#30340;&#27700;&#24179;&#65292;&#20855;&#20307;&#34920;&#29616;&#22312;&#65306;&#65288;i&#65289;&#35206;&#30422;&#20102;&#38169;&#20301;&#37319;&#29992;&#35774;&#32622;&#20013;&#30340;&#22823;&#31867;&#22240;&#26524;&#39044;&#27979;&#37327;&#65292;&#65288;ii&#65289;&#20801;&#35768;&#20855;&#26377;&#21487;&#33021;&#38750;&#32447;&#24615;&#32422;&#26463;&#30340;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#65292;&#65288;iii&#65289;&#25552;&#20986;&#21487;&#25193;&#23637;&#30340;&#40065;&#26834;&#38181;&#20248;&#21270;&#26041;&#27861;&#21644;&#22522;&#20110;&#21407;&#21017;&#30340;&#25968;&#25454;&#39537;&#21160;&#35843;&#21442;&#36873;&#25321;&#65292;&#65288;iv&#65289;&#25552;&#20379;&#20102;&#22312;&#21518;&#22788;&#29702;&#26399;&#38388;&#36827;&#34892;&#26377;&#25928;&#22343;&#21248;&#25512;&#26029;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#24212;&#29992;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose principled prediction intervals to quantify the uncertainty of a large class of synthetic control predictions or estimators in settings with staggered treatment adoption, offering precise non-asymptotic coverage probability guarantees. From a methodological perspective, we provide a detailed discussion of different causal quantities to be predicted, which we call `causal predictands', allowing for multiple treated units with treatment adoption at possibly different points in time. From a theoretical perspective, our uncertainty quantification methods improve on prior literature by (i) covering a large class of causal predictands in staggered adoption settings, (ii) allowing for synthetic control methods with possibly nonlinear constraints, (iii) proposing scalable robust conic optimization methods and principled data-driven tuning parameter selection, and (iv) offering valid uniform inference across post-treatment periods. We illustrate our methodology with an empirical appl
&lt;/p&gt;</description></item></channel></rss>