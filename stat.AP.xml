<rss version="2.0"><channel><title>Chat Arxiv stat.AP</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.AP</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2007.02192</link><description>&lt;p&gt;
&#23614;&#37096;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#25910;&#32553;
&lt;/p&gt;
&lt;p&gt;
Tail-adaptive Bayesian shrinkage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.02192
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#22238;&#24402;&#38382;&#39064;&#19979;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#25910;&#32553;&#20808;&#39564;&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#22312;&#25152;&#35859;&#30340;&#36229;&#31232;&#30095;&#39046;&#22495;&#20174;&#25104;&#21315;&#19978;&#19975;&#20010;&#39044;&#27979;&#21464;&#37327;&#20013;&#26816;&#27979;&#23569;&#25968;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#24403;&#31232;&#30095;&#31243;&#24230;&#36866;&#20013;&#26102;&#65292;&#23427;&#20204;&#21487;&#33021;&#34920;&#29616;&#19981;&#23613;&#20154;&#24847;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#29305;&#24615;&#20013;&#65292;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20250;&#33258;&#36866;&#24212;&#35843;&#25972;&#65292;&#38543;&#30528;&#31232;&#30095;&#27700;&#24179;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#21464;&#24471;&#26356;&#22823;&#25110;&#26356;&#23567;&#65292;&#20197;&#36866;&#24212;&#20808;&#39564;&#22320;&#26356;&#22810;&#25110;&#26356;&#23569;&#30340;&#20449;&#21495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#23616;&#23616;&#37096;&#23614;&#37096;&#65288;GLT&#65289;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#20197;&#30830;&#20445;&#36825;&#31181;&#23646;&#24615;&#12290;&#25105;&#20204;&#32771;&#23519;&#20102;&#20808;&#39564;&#30340;&#23614;&#37096;&#25351;&#25968;&#19982;&#22522;&#30784;&#31232;&#30095;&#27700;&#24179;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#35777;&#26126;GLT&#21518;&#39564;&#20250;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.02192v4 Announce Type: replace-cross  Abstract: Robust Bayesian methods for high-dimensional regression problems under diverse sparse regimes are studied. Traditional shrinkage priors are primarily designed to detect a handful of signals from tens of thousands of predictors in the so-called ultra-sparsity domain. However, they may not perform desirably when the degree of sparsity is moderate. In this paper, we propose a robust sparse estimation method under diverse sparsity regimes, which has a tail-adaptive shrinkage property. In this property, the tail-heaviness of the prior adjusts adaptively, becoming larger or smaller as the sparsity level increases or decreases, respectively, to accommodate more or fewer signals, a posteriori. We propose a global-local-tail (GLT) Gaussian mixture distribution that ensures this property. We examine the role of the tail-index of the prior in relation to the underlying sparsity level and demonstrate that the GLT posterior contracts at the
&lt;/p&gt;</description></item></channel></rss>