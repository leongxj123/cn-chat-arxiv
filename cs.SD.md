# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Voice EHR: Introducing Multimodal Audio Data for Health](https://arxiv.org/abs/2404.01620) | 本报告引入了一种通过引导问题使用移动应用程序捕获健康数据的新的音频电子健康记录（voice EHR），可能包含复杂的健康生物标志物，从而弥补了单一模态临床数据的典型限制。 |
| [^2] | [Diffusion Models for Audio Restoration](https://arxiv.org/abs/2402.09821) | 本文介绍了基于扩散模型的音频恢复算法，重点关注语音增强和音乐恢复任务。 |

# 详细

[^1]: Voice EHR:引入多模式音频数据用于健康

    Voice EHR: Introducing Multimodal Audio Data for Health

    [https://arxiv.org/abs/2404.01620](https://arxiv.org/abs/2404.01620)

    本报告引入了一种通过引导问题使用移动应用程序捕获健康数据的新的音频电子健康记录（voice EHR），可能包含复杂的健康生物标志物，从而弥补了单一模态临床数据的典型限制。

    

    在音频数据上训练的大型AI模型可能具有快速分类患者的潜力，通过早期检测增强医疗决策，并可能通过早期检测改善结果。现有技术依赖于在高收入、英语国家使用昂贵记录设备的有限数据集，这种技术面临资源受限、高收入场所的部署挑战，音频数据可能具有深远影响。本报告介绍了一种新的数据类型和相应的收集系统，通过引导问题仅使用移动应用/网络应用程序捕获健康数据。该应用程序最终产生一个音频电子健康记录（voice EHR），它可能包含来自传统语音/呼吸特征、语音模式和具有语义意义的语言的复杂生物标志物，补偿单一模态临床数据的典型限制。本报告介绍了一个合作伙伴财团

    arXiv:2404.01620v1 Announce Type: cross  Abstract: Large AI models trained on audio data may have the potential to rapidly classify patients, enhancing medical decision-making and potentially improving outcomes through early detection. Existing technologies depend on limited datasets using expensive recording equipment in high-income, English-speaking countries. This challenges deployment in resource-constrained, high-volume settings where audio data may have a profound impact. This report introduces a novel data type and a corresponding collection system that captures health data through guided questions using only a mobile/web application. This application ultimately results in an audio electronic health record (voice EHR) which may contain complex biomarkers of health from conventional voice/respiratory features, speech patterns, and language with semantic meaning - compensating for the typical limitations of unimodal clinical datasets. This report introduces a consortium of partner
    
[^2]: 音频恢复的扩散模型

    Diffusion Models for Audio Restoration

    [https://arxiv.org/abs/2402.09821](https://arxiv.org/abs/2402.09821)

    本文介绍了基于扩散模型的音频恢复算法，重点关注语音增强和音乐恢复任务。

    

    随着音频播放设备和快速数据传输的发展，对高音质的需求在娱乐和通信领域不断增长。然而，由于录制过程中的失真和干扰，或者由于不完善的传输管道，音频质量面临许多挑战。为了解决这个问题，音频恢复方法旨在从损坏的输入数据中恢复出清晰的音频信号。本文介绍了基于扩散模型的音频恢复算法，重点关注语音增强和音乐恢复任务。传统方法通常基于手工规则和统计启发法，从而建立了我们对音频信号的认识。近几十年来，越来越多的人转向利用深度神经网络（DNNs）的建模能力的数据驱动方法。深度生成模型中的扩散模型成为一种新兴方法。

    arXiv:2402.09821v1 Announce Type: cross  Abstract: With the development of audio playback devices and fast data transmission, the demand for high sound quality is rising, for both entertainment and communications. In this quest for better sound quality, challenges emerge from distortions and interferences originating at the recording side or caused by an imperfect transmission pipeline. To address this problem, audio restoration methods aim to recover clean sound signals from the corrupted input data. We present here audio restoration algorithms based on diffusion models, with a focus on speech enhancement and music restoration tasks. Traditional approaches, often grounded in handcrafted rules and statistical heuristics, have shaped our understanding of audio signals. In the past decades, there has been a notable shift towards data-driven methods that exploit the modeling capabilities of deep neural networks (DNNs). Deep generative models, and among them diffusion models, have emerged 
    

