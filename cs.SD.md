# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection](https://arxiv.org/abs/2402.13276) | 本文提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。 |
| [^2] | [Audio Editing with Non-Rigid Text Prompts.](http://arxiv.org/abs/2310.12858) | 本文研究了使用非刚性文本编辑进行音频编辑的方法，并展示了其在保持输入音频一致性方面的优势。 |

# 详细

[^1]: 当LLMs遇到声学标志：一种高效地将语音集成到大型语言模型中用于抑郁检测的方法

    When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection

    [https://arxiv.org/abs/2402.13276](https://arxiv.org/abs/2402.13276)

    本文提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。

    

    抑郁是全球心理健康中的一个严重关切，促使进行大量研究来探讨基于AI的检测方法。在各种AI技术中，大型语言模型（LLMs）因其在心理卫生应用中的多功能性而脱颖而出。然而，它们的主要局限性在于它们仅依赖于文本输入，这限制了它们的整体功能。此外，LLMs在识别和分析抑郁状态方面的利用仍相对未开发。在本文中，我们提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。我们研究了一种通过利用声学标志将语音信号集成到LLMs中的高效抑郁检测方法。通过整合声学标志，这些标志是特定于口语单词发音的，我们的方法为文本转录添加了关键维度。

    arXiv:2402.13276v1 Announce Type: cross  Abstract: Depression is a critical concern in global mental health, prompting extensive research into AI-based detection methods. Among various AI technologies, Large Language Models (LLMs) stand out for their versatility in mental healthcare applications. However, their primary limitation arises from their exclusive dependence on textual input, which constrains their overall capabilities. Furthermore, the utilization of LLMs in identifying and analyzing depressive states is still relatively untapped. In this paper, we present an innovative approach to integrating acoustic speech information into the LLMs framework for multimodal depression detection. We investigate an efficient method for depression detection by integrating speech signals into LLMs utilizing Acoustic Landmarks. By incorporating acoustic landmarks, which are specific to the pronunciation of spoken words, our method adds critical dimensions to text transcripts. This integration a
    
[^2]: 非刚性文本提示的音频编辑

    Audio Editing with Non-Rigid Text Prompts. (arXiv:2310.12858v1 [cs.SD])

    [http://arxiv.org/abs/2310.12858](http://arxiv.org/abs/2310.12858)

    本文研究了使用非刚性文本编辑进行音频编辑的方法，并展示了其在保持输入音频一致性方面的优势。

    

    本文探讨了使用非刚性文本编辑进行音频编辑。我们展示了所提出的编辑流程能够创建与输入音频保持一致的音频编辑结果。我们探索了能够进行添加、风格转换和修复的文本提示。我们定量和定性地证明了这些编辑能够优于最近发布的文本提示音频生成模型Audio-LDM的结果。对结果的定性检查表明，我们的方法给出了更加保持输入音频原始起始和结束的编辑结果。

    In this paper, we explore audio-editing with non-rigid text edits. We show that the proposed editing pipeline is able to create audio edits that remain faithful to the input audio. We explore text prompts that perform addition, style transfer, and in-painting. We quantitatively and qualitatively show that the edits are able to obtain results which outperform Audio-LDM, a recently released text-prompted audio generation model. Qualitative inspection of the results points out that the edits given by our approach remain more faithful to the input audio in terms of keeping the original onsets and offsets of the audio events.
    

