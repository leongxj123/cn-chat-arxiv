# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Geometric Neural Network based on Phase Space for BCI decoding](https://arxiv.org/abs/2403.05645) | 基于相空间的几何神经网络用于BCI解码，提供了在脑机接口领域中可靠算法操作的方法，以提高用户舒适度并促进其广泛应用。 |
| [^2] | [Large language models surpass human experts in predicting neuroscience results](https://arxiv.org/abs/2403.03230) | 大型语言模型通过整合广泛科学文献中的相关发现，能够优于人类专家预测神经科学实验结果，预示着人类与大型语言模型共同进行发现的未来。 |

# 详细

[^1]: 基于相空间的几何神经网络用于BCI解码

    Geometric Neural Network based on Phase Space for BCI decoding

    [https://arxiv.org/abs/2403.05645](https://arxiv.org/abs/2403.05645)

    基于相空间的几何神经网络用于BCI解码，提供了在脑机接口领域中可靠算法操作的方法，以提高用户舒适度并促进其广泛应用。

    

    Deep Learning(DL)算法与脑信号分析的整合仍处于萌芽阶段，相比计算机视觉等领域的成功，在脑机接口(BCI)领域尤为突出，BCI通过解码大脑活动控制外部设备而无需肌肉控制。脑电图(EEG)是设计BCI系统的广泛选择，因其无创性、成本效益和出色的时间分辨率，但缺少训练数据、信噪比低、以及在个体间和内部的大量变化。 最后，使用多个电极设置BCI系统需要很长时间，阻碍可靠DL架构在研究实验室之外的BCI中的广泛应用。 为了提高采纳率，我们需要改善用户舒适度，例如使用少量电极操作的可靠算法。

    arXiv:2403.05645v1 Announce Type: cross  Abstract: The integration of Deep Learning (DL) algorithms on brain signal analysis is still in its nascent stages compared to their success in fields like Computer Vision, especially in Brain-Computer Interface (BCI), where the brain activity is decoded to control external devices without requiring muscle control. Electroencephalography (EEG) is a widely adopted choice for designing BCI systems due to its non-invasive and cost-effective nature and excellent temporal resolution. Still, it comes at the expense of limited training data, poor signal-to-noise, and a large variability across and within-subject recordings. Finally, setting up a BCI system with many electrodes takes a long time, hindering the widespread adoption of reliable DL architectures in BCIs outside research laboratories. To improve adoption, we need to improve user comfort using, for instance, reliable algorithms that operate with few electrodes. \textbf{Approach:} Our research
    
[^2]: 大型语言模型在预测神经科学结果方面超越人类专家

    Large language models surpass human experts in predicting neuroscience results

    [https://arxiv.org/abs/2403.03230](https://arxiv.org/abs/2403.03230)

    大型语言模型通过整合广泛科学文献中的相关发现，能够优于人类专家预测神经科学实验结果，预示着人类与大型语言模型共同进行发现的未来。

    

    科学发现常常取决于综合几十年的研究，这一任务可能超出人类信息处理能力。大型语言模型（LLMs）提供了一个解决方案。在广泛的科学文献上训练的LLMs可能能够整合嘈杂但相关的发现，以优于人类专家来预测新颖结果。为了评估这种可能性，我们创建了BrainBench，一个前瞻性的基准，用于预测神经科学结果。我们发现LLMs在预测实验结果方面超越了专家。在神经科学文献上调整的一个LLM，BrainGPT表现得更好。与人类专家一样，当LLMs对他们的预测有信心时，他们更有可能是正确的，这预示着未来人类和LLMs将合作进行发现。我们的方法并非特定于神经科学，并且可转移到其他知识密集型事业中。

    arXiv:2403.03230v1 Announce Type: cross  Abstract: Scientific discoveries often hinge on synthesizing decades of research, a task that potentially outstrips human information processing capacities. Large language models (LLMs) offer a solution. LLMs trained on the vast scientific literature could potentially integrate noisy yet interrelated findings to forecast novel results better than human experts. To evaluate this possibility, we created BrainBench, a forward-looking benchmark for predicting neuroscience results. We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs were confident in their predictions, they were more likely to be correct, which presages a future where humans and LLMs team together to make discoveries. Our approach is not neuroscience-specific and is transferable to other knowledge-intensive endeavors.
    

