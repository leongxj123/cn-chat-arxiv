# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Brain-Like Replay Naturally Emerges in Reinforcement Learning Agents](https://rss.arxiv.org/abs/2402.01467) | 本研究中，我们在使用递归神经网络的强化学习模型中发现了类似大脑回放的现象，并证明其对任务的贡献。这一发现提供了理解回放机制的新视角。 |

# 详细

[^1]: 强化学习智能体内出现类似大脑回放的现象

    Brain-Like Replay Naturally Emerges in Reinforcement Learning Agents

    [https://rss.arxiv.org/abs/2402.01467](https://rss.arxiv.org/abs/2402.01467)

    本研究中，我们在使用递归神经网络的强化学习模型中发现了类似大脑回放的现象，并证明其对任务的贡献。这一发现提供了理解回放机制的新视角。

    

    大脑区域中普遍观察到的回放现象是否能够在人工智能智能体中自然产生？如果是的话，它是否对任务有所贡献？在本研究中，我们使用基于递归神经网络的强化学习模型，在任务优化的范式下发现了回放的自然出现，模型模拟了海马体和前额叶皮层以及它们之间的相互沟通和感觉皮层的输入。海马体中的回放是由于情景记忆、认知地图以及环境观察而产生的，与动物实验数据相似，并且是高任务性能的有效指标。该模型还成功地重现了局部和非局部的回放，与人类实验数据相符。我们的工作为理解回放机制提供了新的途径。

    Can replay, as a widely observed neural activity pattern in brain regions, particularly in the hippocampus and neocortex, emerge in an artificial agent? If yes, does it contribute to the tasks? In this work, without heavy dependence on complex assumptions, we discover naturally emergent replay under task-optimized paradigm using a recurrent neural network-based reinforcement learning model, which mimics the hippocampus and prefrontal cortex, as well as their intercommunication and the sensory cortex input. The emergent replay in the hippocampus, which results from the episodic memory and cognitive map as well as environment observations, well resembles animal experimental data and serves as an effective indicator of high task performance. The model also successfully reproduces local and nonlocal replay, which matches the human experimental data. Our work provides a new avenue for understanding the mechanisms behind replay.
    

