# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations](https://arxiv.org/abs/2403.10943) | MIntRec2.0介绍了一个旨在解决多模态意图识别和对话中场外检测挑战的大规模基准数据集。该数据集包含30个细粒度类别的1,245个对话和15,040个样本，其中包括逼真的场外样本，并丰富了发言者信息以支持多方对话研究。 |

# 详细

[^1]: MIntRec2.0：用于多模态意图识别和对话中场外检测的大规模基准数据集

    MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations

    [https://arxiv.org/abs/2403.10943](https://arxiv.org/abs/2403.10943)

    MIntRec2.0介绍了一个旨在解决多模态意图识别和对话中场外检测挑战的大规模基准数据集。该数据集包含30个细粒度类别的1,245个对话和15,040个样本，其中包括逼真的场外样本，并丰富了发言者信息以支持多方对话研究。

    

    多模态意图识别面临重大挑战，需要整合来自现实世界背景的非语言形式，以增强对人类意图的理解。现有的基准数据集在规模上受限，并且在处理多轮对话互动中出现的场外样本时存在困难。我们介绍了MIntRec2.0，这是一个用于多方对话中的多模态意图识别的大规模基准数据集。它包含1,245个对话，15,040个样本，每个样本在30个细粒度类别的新意图分类中进行了注释。除了9,304个场内样本外，还包括5,736个出现在多轮上下文中的场外样本，这在现实场景中自然发生。此外，我们还提供了每个话语中发言者的详细信息，丰富了它在多方对话研究中的实用性。

    arXiv:2403.10943v1 Announce Type: cross  Abstract: Multimodal intent recognition poses significant challenges, requiring the incorporation of non-verbal modalities from real-world contexts to enhance the comprehension of human intentions. Existing benchmark datasets are limited in scale and suffer from difficulties in handling out-of-scope samples that arise in multi-turn conversational interactions. We introduce MIntRec2.0, a large-scale benchmark dataset for multimodal intent recognition in multi-party conversations. It contains 1,245 dialogues with 15,040 samples, each annotated within a new intent taxonomy of 30 fine-grained classes. Besides 9,304 in-scope samples, it also includes 5,736 out-of-scope samples appearing in multi-turn contexts, which naturally occur in real-world scenarios. Furthermore, we provide comprehensive information on the speakers in each utterance, enriching its utility for multi-party conversational research. We establish a general framework supporting the o
    

