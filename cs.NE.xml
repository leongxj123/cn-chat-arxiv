<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;&#65288;RTRRL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20803;-&#24378;&#21270;&#23398;&#20064;RNN&#26550;&#26500;&#12289;&#22806;&#37096;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21644;RFLO&#23616;&#37096;&#22312;&#32447;&#23398;&#20064;&#65292;&#25104;&#21151;&#35299;&#20915;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#25955;&#21644;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#35745;&#31639;&#22797;&#26434;&#24615;&#30456;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;BPTT&#25110;RTRL&#26367;&#20195;RTRRL&#20013;&#30340;&#20248;&#21270;&#31639;&#27861;&#24182;&#19981;&#33021;&#25552;&#39640;&#22238;&#25253;&#12290;</title><link>https://arxiv.org/abs/2311.04830</link><description>&lt;p&gt;
&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Real-Time Recurrent Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04830
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;&#65288;RTRRL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20803;-&#24378;&#21270;&#23398;&#20064;RNN&#26550;&#26500;&#12289;&#22806;&#37096;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21644;RFLO&#23616;&#37096;&#22312;&#32447;&#23398;&#20064;&#65292;&#25104;&#21151;&#35299;&#20915;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#25955;&#21644;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#35745;&#31639;&#22797;&#26434;&#24615;&#30456;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;BPTT&#25110;RTRL&#26367;&#20195;RTRRL&#20013;&#30340;&#20248;&#21270;&#31639;&#27861;&#24182;&#19981;&#33021;&#25552;&#39640;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;&#65288;RTRRL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#23545;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#20013;&#30340;&#31163;&#25955;&#21644;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#36827;&#34892;&#27714;&#35299;&#30340;&#29983;&#29289;&#23398;&#21512;&#29702;&#26041;&#27861;&#12290;RTRRL&#30001;&#19977;&#37096;&#20998;&#32452;&#25104;&#65306;&#65288;1&#65289;&#19968;&#20010;&#20803;-&#24378;&#21270;&#23398;&#20064;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#26550;&#26500;&#65292;&#29420;&#31435;&#23454;&#29616;&#20102;&#19968;&#20010;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65307;&#65288;2&#65289;&#19968;&#20010;&#22806;&#37096;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#26102;&#24207;&#24046;&#20998;&#23398;&#20064;&#21644;&#33655;&#20848;&#36164;&#26684;&#36861;&#36394;&#26469;&#35757;&#32451;&#20803;-&#24378;&#21270;&#23398;&#20064;&#32593;&#32476;&#65307;&#21644;&#65288;3&#65289;&#38543;&#26426;&#21453;&#39304;&#23616;&#37096;&#22312;&#32447;&#65288;RFLO&#65289;&#23398;&#20064;&#65292;&#19968;&#31181;&#29992;&#20110;&#35745;&#31639;&#32593;&#32476;&#21442;&#25968;&#26799;&#24230;&#30340;&#22312;&#32447;&#33258;&#21160;&#24494;&#20998;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#23558;RTRRL&#20013;&#30340;&#20248;&#21270;&#31639;&#27861;&#26367;&#25442;&#20026;&#29983;&#29289;&#19981;&#21512;&#29702;&#30340;&#26102;&#24310;&#21453;&#21521;&#20256;&#25773;&#65288;BPTT&#65289;&#25110;&#23454;&#26102;&#36882;&#24402;&#23398;&#20064;&#65288;RTRL&#65289;&#65292;&#24182;&#19981;&#33021;&#25913;&#21892;&#22238;&#25253;&#65292;&#21516;&#26102;&#22312;&#21305;&#37197;BPTT&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#29978;&#33267;&#20250;&#22686;&#21152;&#36820;&#22238;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04830v2 Announce Type: replace  Abstract: In this paper we propose real-time recurrent reinforcement learning (RTRRL), a biologically plausible approach to solving discrete and continuous control tasks in partially-observable markov decision processes (POMDPs). RTRRL consists of three parts: (1) a Meta-RL RNN architecture, implementing on its own an actor-critic algorithm; (2) an outer reinforcement learning algorithm, exploiting temporal difference learning and dutch eligibility traces to train the Meta-RL network; and (3) random-feedback local-online (RFLO) learning, an online automatic differentiation algorithm for computing the gradients with respect to parameters of the network.Our experimental results show that by replacing the optimization algorithm in RTRRL with the biologically implausible back propagation through time (BPTT), or real-time recurrent learning (RTRL), one does not improve returns, while matching the computational complexity for BPTT, and even increasi
&lt;/p&gt;</description></item></channel></rss>