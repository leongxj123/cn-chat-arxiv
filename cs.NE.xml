<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#36890;&#36807;&#30740;&#31350;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#36807;&#31243;&#20013;&#23384;&#22312;&#20960;&#20309;&#24341;&#23548;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2402.08269</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20960;&#20309;&#24341;&#23548;&#38544;&#24335;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Geometry-induced Implicit Regularization in Deep ReLU Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08269
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#36807;&#31243;&#20013;&#23384;&#22312;&#20960;&#20309;&#24341;&#23548;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20855;&#26377;&#27604;&#35757;&#32451;&#26679;&#26412;&#26356;&#22810;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#19981;&#20250;&#36807;&#25311;&#21512;&#12290;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#20986;&#29616;&#65292;&#23545;&#8220;&#22909;&#8221;&#30340;&#32593;&#32476;&#26377;&#21033;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#25105;&#20204;&#19981;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#32593;&#32476;&#65292;&#32780;&#21482;&#32771;&#34385;&#8220;&#22909;&#8221;&#30340;&#32593;&#32476;&#65292;&#21442;&#25968;&#25968;&#37327;&#23601;&#19981;&#26159;&#19968;&#20010;&#36275;&#22815;&#34913;&#37327;&#22797;&#26434;&#24615;&#30340;&#25351;&#26631;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#21738;&#20123;&#32593;&#32476;&#21463;&#21040;&#38738;&#30544;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#12290;&#24403;&#36755;&#20837;&#22266;&#23450;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#38598;&#21512;&#30340;&#32500;&#24230;&#20250;&#21457;&#29983;&#21464;&#21270;&#65292;&#24182;&#19988;&#23616;&#37096;&#32500;&#24230;&#65292;&#21363;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#65292;&#20960;&#20046;&#24635;&#26159;&#30001;&#38544;&#34255;&#23618;&#20013;&#30340;&#28608;&#27963;&#27169;&#24335;&#20915;&#23450;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#23545;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#23545;&#31216;&#24615;&#65288;&#31070;&#32463;&#20803;&#25490;&#21015;&#21644;&#27491;&#21521;&#32553;&#25918;&#65289;&#26159;&#19981;&#21464;&#30340;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#20250;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#20248;&#21270;&#36807;&#31243;&#20855;&#26377;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that neural networks with many more parameters than training examples do not overfit. Implicit regularization phenomena, which are still not well understood, occur during optimization and 'good' networks are favored. Thus the number of parameters is not an adequate measure of complexity if we do not consider all possible networks but only the 'good' ones. To better understand which networks are favored during optimization, we study the geometry of the output set as parameters vary. When the inputs are fixed, we prove that the dimension of this set changes and that the local dimension, called batch functional dimension, is almost surely determined by the activation patterns in the hidden layers. We prove that the batch functional dimension is invariant to the symmetries of the network parameterization: neuron permutations and positive rescalings. Empirically, we establish that the batch functional dimension decreases during optimization. As a consequence, optimization l
&lt;/p&gt;</description></item></channel></rss>