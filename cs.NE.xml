<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#25552;&#20379;&#29305;&#23450;RC&#20307;&#31995;&#32467;&#26500;&#19982;&#30456;&#24212;&#24490;&#29615;&#20869;&#26680;&#24418;&#24335;&#31561;&#20215;&#24615;&#30340;&#32463;&#39564;&#20998;&#26512;&#65292;&#22635;&#34917;&#20102;Leaky RC&#12289;Sparse RC&#21644;Deep RC&#31561;&#24050;&#24314;&#31435;&#30340;RC&#33539;&#20363;&#23578;&#26410;&#36827;&#34892;&#20998;&#26512;&#30340;&#31354;&#30333;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25581;&#31034;&#20102;&#31232;&#30095;&#36830;&#25509;&#22312;RC&#20307;&#31995;&#32467;&#26500;&#20013;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20381;&#36182;&#20648;&#22791;&#22823;&#23567;&#30340;&#26368;&#20339;&#31232;&#30095;&#24615;&#27700;&#24179;&#12290;&#26368;&#21518;&#65292;&#35813;&#30740;&#31350;&#30340;&#31995;&#32479;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;Deep RC&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20943;&#23567;&#23610;&#23544;&#30340;&#36830;&#32493;&#20648;&#22791;&#21487;&#20197;&#26356;&#22909;&#22320;&#23454;&#29616;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2401.14557</link><description>&lt;p&gt;
&#19981;&#21516;&#30340;&#24490;&#29615;&#20869;&#26680;&#25299;&#23637;&#21040;&#19981;&#21516;&#30340;&#20648;&#22791;&#35745;&#31639;&#25299;&#25169;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Extension of Recurrent Kernels to different Reservoir Computing topologies. (arXiv:2401.14557v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14557
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#25552;&#20379;&#29305;&#23450;RC&#20307;&#31995;&#32467;&#26500;&#19982;&#30456;&#24212;&#24490;&#29615;&#20869;&#26680;&#24418;&#24335;&#31561;&#20215;&#24615;&#30340;&#32463;&#39564;&#20998;&#26512;&#65292;&#22635;&#34917;&#20102;Leaky RC&#12289;Sparse RC&#21644;Deep RC&#31561;&#24050;&#24314;&#31435;&#30340;RC&#33539;&#20363;&#23578;&#26410;&#36827;&#34892;&#20998;&#26512;&#30340;&#31354;&#30333;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25581;&#31034;&#20102;&#31232;&#30095;&#36830;&#25509;&#22312;RC&#20307;&#31995;&#32467;&#26500;&#20013;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20381;&#36182;&#20648;&#22791;&#22823;&#23567;&#30340;&#26368;&#20339;&#31232;&#30095;&#24615;&#27700;&#24179;&#12290;&#26368;&#21518;&#65292;&#35813;&#30740;&#31350;&#30340;&#31995;&#32479;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;Deep RC&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20943;&#23567;&#23610;&#23544;&#30340;&#36830;&#32493;&#20648;&#22791;&#21487;&#20197;&#26356;&#22909;&#22320;&#23454;&#29616;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#20854;&#24555;&#36895;&#39640;&#25928;&#30340;&#35745;&#31639;&#33021;&#21147;&#65292;&#20648;&#22791;&#35745;&#31639;&#65288;RC&#65289;&#21464;&#24471;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#26631;&#20934;&#30340;RC&#22312;&#28176;&#36817;&#26497;&#38480;&#19979;&#24050;&#34987;&#35777;&#26126;&#19982;&#24490;&#29615;&#20869;&#26680;&#31561;&#25928;&#65292;&#36825;&#26377;&#21161;&#20110;&#20998;&#26512;&#20854;&#34920;&#36798;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#24050;&#24314;&#31435;&#30340;RC&#33539;&#20363;&#65292;&#22914;Leaky RC&#12289;Sparse RC&#21644;Deep RC&#65292;&#23578;&#26410;&#20197;&#36825;&#31181;&#26041;&#24335;&#36827;&#34892;&#20998;&#26512;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#29305;&#23450;RC&#20307;&#31995;&#32467;&#26500;&#19982;&#30456;&#24212;&#24490;&#29615;&#20869;&#26680;&#24418;&#24335;&#31561;&#20215;&#24615;&#30340;&#32463;&#39564;&#20998;&#26512;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#36890;&#36807;&#25913;&#21464;&#27599;&#20010;&#20307;&#31995;&#32467;&#26500;&#20013;&#23454;&#26045;&#30340;&#28608;&#27963;&#20989;&#25968;&#36827;&#34892;&#25910;&#25947;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#25581;&#31034;&#20102;&#31232;&#30095;&#36830;&#25509;&#22312;RC&#20307;&#31995;&#32467;&#26500;&#20013;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20381;&#36182;&#20648;&#22791;&#22823;&#23567;&#30340;&#26368;&#20339;&#31232;&#30095;&#24615;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31995;&#32479;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;Deep RC&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20943;&#23567;&#23610;&#23544;&#30340;&#36830;&#32493;&#20648;&#22791;&#21487;&#20197;&#26356;&#22909;&#22320;&#23454;&#29616;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reservoir Computing (RC) has become popular in recent years due to its fast and efficient computational capabilities. Standard RC has been shown to be equivalent in the asymptotic limit to Recurrent Kernels, which helps in analyzing its expressive power. However, many well-established RC paradigms, such as Leaky RC, Sparse RC, and Deep RC, are yet to be analyzed in such a way. This study aims to fill this gap by providing an empirical analysis of the equivalence of specific RC architectures with their corresponding Recurrent Kernel formulation. We conduct a convergence study by varying the activation function implemented in each architecture. Our study also sheds light on the role of sparse connections in RC architectures and propose an optimal sparsity level that depends on the reservoir size. Furthermore, our systematic analysis shows that in Deep RC models, convergence is better achieved with successive reservoirs of decreasing sizes.
&lt;/p&gt;</description></item><item><title>&#23558;&#36136;&#37327;&#22810;&#26679;&#24615;&#20248;&#21270;&#19982;&#25551;&#36848;&#31526;&#26465;&#20214;&#21152;&#24378;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#20811;&#26381;&#36827;&#21270;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#29983;&#25104;&#26082;&#22810;&#26679;&#21448;&#39640;&#24615;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#38598;&#21512;&#26041;&#38754;&#21462;&#24471;&#25104;&#21151;&#12290;</title><link>http://arxiv.org/abs/2401.08632</link><description>&lt;p&gt;
&#23558;&#36136;&#37327;&#22810;&#26679;&#24615;&#19982;&#25551;&#36848;&#31526;&#26465;&#20214;&#21152;&#24378;&#23398;&#20064;&#30456;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement Learning. (arXiv:2401.08632v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08632
&lt;/p&gt;
&lt;p&gt;
&#23558;&#36136;&#37327;&#22810;&#26679;&#24615;&#20248;&#21270;&#19982;&#25551;&#36848;&#31526;&#26465;&#20214;&#21152;&#24378;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#20811;&#26381;&#36827;&#21270;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#29983;&#25104;&#26082;&#22810;&#26679;&#21448;&#39640;&#24615;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#38598;&#21512;&#26041;&#38754;&#21462;&#24471;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26234;&#33021;&#30340;&#22522;&#26412;&#29305;&#24449;&#20043;&#19968;&#26159;&#25214;&#21040;&#26032;&#39062;&#21644;&#26377;&#21019;&#36896;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#35299;&#20915;&#32473;&#23450;&#30340;&#25361;&#25112;&#25110;&#36866;&#24212;&#26410;&#39044;&#26009;&#21040;&#30340;&#24773;&#20917;&#12290;&#36136;&#37327;&#22810;&#26679;&#24615;&#20248;&#21270;&#26159;&#19968;&#31867;&#36827;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#26082;&#22810;&#26679;&#21448;&#39640;&#24615;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#38598;&#21512;&#12290;&#20854;&#20013;&#65292;MAP-Elites&#26159;&#19968;&#20010;&#33879;&#21517;&#30340;&#20363;&#23376;&#65292;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#21508;&#31181;&#39046;&#22495;&#65292;&#21253;&#25324;&#36827;&#21270;&#26426;&#22120;&#20154;&#23398;&#12290;&#28982;&#32780;&#65292;MAP-Elites&#36890;&#36807;&#36951;&#20256;&#31639;&#27861;&#30340;&#38543;&#26426;&#31361;&#21464;&#36827;&#34892;&#21457;&#25955;&#25628;&#32034;&#65292;&#22240;&#27492;&#20165;&#38480;&#20110;&#36827;&#21270;&#20302;&#32500;&#35299;&#20915;&#26041;&#26696;&#30340;&#31181;&#32676;&#12290;PGA-MAP-Elites&#36890;&#36807;&#21463;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#21551;&#21457;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#21464;&#24322;&#31639;&#23376;&#20811;&#26381;&#20102;&#36825;&#19968;&#38480;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#36827;&#21270;&#12290;&#23613;&#31649;&#22312;&#35768;&#22810;&#29615;&#22659;&#20013;&#24615;&#33021;&#20248;&#31168;&#65292;&#20294;PGA-MAP-Elites&#22312;&#19968;&#20123;&#20219;&#21153;&#20013;&#22833;&#36133;&#65292;&#20854;&#20013;&#22522;&#20110;&#26799;&#24230;&#30340;&#21464;&#24322;&#31639;&#23376;&#30340;&#25910;&#25947;&#25628;&#32034;&#38459;&#30861;&#20102;&#22810;&#26679;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;...
&lt;/p&gt;
&lt;p&gt;
A fundamental trait of intelligence involves finding novel and creative solutions to address a given challenge or to adapt to unforeseen situations. Reflecting this, Quality-Diversity optimization is a family of Evolutionary Algorithms, that generates collections of both diverse and high-performing solutions. Among these, MAP-Elites is a prominent example, that has been successfully applied to a variety of domains, including evolutionary robotics. However, MAP-Elites performs a divergent search with random mutations originating from Genetic Algorithms, and thus, is limited to evolving populations of low-dimensional solutions. PGA-MAP-Elites overcomes this limitation using a gradient-based variation operator inspired by deep reinforcement learning which enables the evolution of large neural networks. Although high-performing in many environments, PGA-MAP-Elites fails on several tasks where the convergent search of the gradient-based variation operator hinders diversity. In this work, we
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#21069;&#39069;&#21494;&#30382;&#23618;&#21551;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35268;&#21010;&#26550;&#26500;&#65292;&#21033;&#29992;&#22810;&#20010;&#22522;&#20110;LLM&#30340;&#27169;&#22359;&#23454;&#29616;&#35268;&#21010;&#30340;&#33258;&#20027;&#21327;&#35843;&#65292;&#20174;&#32780;&#22312;&#22788;&#29702;&#38656;&#35201;&#22810;&#27493;&#25512;&#29702;&#25110;&#30446;&#26631;&#23548;&#21521;&#35268;&#21010;&#30340;&#20219;&#21153;&#26102;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.00194</link><description>&lt;p&gt;
&#21463;&#21069;&#39069;&#21494;&#30382;&#23618;&#21551;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35268;&#21010;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models. (arXiv:2310.00194v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00194
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#21069;&#39069;&#21494;&#30382;&#23618;&#21551;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35268;&#21010;&#26550;&#26500;&#65292;&#21033;&#29992;&#22810;&#20010;&#22522;&#20110;LLM&#30340;&#27169;&#22359;&#23454;&#29616;&#35268;&#21010;&#30340;&#33258;&#20027;&#21327;&#35843;&#65292;&#20174;&#32780;&#22312;&#22788;&#29702;&#38656;&#35201;&#22810;&#27493;&#25512;&#29702;&#25110;&#30446;&#26631;&#23548;&#21521;&#35268;&#21010;&#30340;&#20219;&#21153;&#26102;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#22312;&#38656;&#35201;&#22810;&#27493;&#25512;&#29702;&#25110;&#30446;&#26631;&#23548;&#21521;&#35268;&#21010;&#30340;&#20219;&#21153;&#20013;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#20154;&#33041;&#20013;&#33719;&#21462;&#28789;&#24863;&#65292;&#21363;&#36890;&#36807;&#21069;&#39069;&#21494;&#30382;&#23618;&#65288;PFC&#65289;&#20013;&#19987;&#38376;&#27169;&#22359;&#30340;&#37325;&#22797;&#20132;&#20114;&#26469;&#23436;&#25104;&#35268;&#21010;&#12290;&#36825;&#20123;&#27169;&#22359;&#25191;&#34892;&#20914;&#31361;&#30417;&#27979;&#12289;&#29366;&#24577;&#39044;&#27979;&#12289;&#29366;&#24577;&#35780;&#20272;&#12289;&#20219;&#21153;&#20998;&#35299;&#21644;&#20219;&#21153;&#21327;&#35843;&#31561;&#21151;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;LLM&#26377;&#26102;&#33021;&#22815;&#21333;&#29420;&#25191;&#34892;&#36825;&#20123;&#21151;&#33021;&#65292;&#20294;&#22312;&#26381;&#21153;&#20110;&#19968;&#20010;&#30446;&#26631;&#26102;&#24448;&#24448;&#38590;&#20197;&#33258;&#20027;&#21327;&#35843;&#23427;&#20204;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#22810;&#20010;&#22522;&#20110;LLM&#65288;GPT-4&#65289;&#27169;&#22359;&#30340;&#40657;&#30418;&#26550;&#26500;&#12290;&#35813;&#26550;&#26500;&#36890;&#36807;&#19987;&#38376;&#30340;PFC&#21551;&#21457;&#27169;&#22359;&#30340;&#20132;&#20114;&#23558;&#19968;&#20010;&#26356;&#22823;&#30340;&#38382;&#39064;&#20998;&#35299;&#20026;&#22810;&#20010;&#23545;LLM&#30340;&#31616;&#30701;&#33258;&#21160;&#35843;&#29992;&#65292;&#20174;&#32780;&#25913;&#21892;&#35268;&#21010;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#35268;&#21010;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#32452;&#21512;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) demonstrate impressive performance on a wide variety of tasks, but they often struggle with tasks that require multi-step reasoning or goal-directed planning. To address this, we take inspiration from the human brain, in which planning is accomplished via the recurrent interaction of specialized modules in the prefrontal cortex (PFC). These modules perform functions such as conflict monitoring, state prediction, state evaluation, task decomposition, and task coordination. We find that LLMs are sometimes capable of carrying out these functions in isolation, but struggle to autonomously coordinate them in the service of a goal. Therefore, we propose a black box architecture with multiple LLM-based (GPT-4) modules. The architecture improves planning through the interaction of specialized PFC-inspired modules that break down a larger problem into multiple brief automated calls to the LLM. We evaluate the combined architecture on two challenging planning tasks -
&lt;/p&gt;</description></item></channel></rss>