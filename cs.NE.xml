<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#26159;&#19968;&#31181;&#20851;&#31995;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23478;&#26063;&#65292;&#29992;&#20110;&#22312;&#20851;&#31995;&#39046;&#22495;&#25552;&#20379;&#21487;&#35299;&#37322;&#30340;&#20219;&#21153;&#39044;&#27979;&#65292;&#30456;&#27604;&#38750;&#20851;&#31995;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#27169;&#22411;&#65292;&#23427;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#19982;&#29616;&#26377;&#30340;&#20851;&#31995;&#27169;&#22411;&#30456;&#21305;&#37197;&#65292;&#24182;&#25903;&#25345;&#29983;&#25104;&#37327;&#21270;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#65292;&#21516;&#26102;&#22312;&#27979;&#35797;&#26102;&#24178;&#39044;&#12289;&#36229;&#20986;&#20998;&#24067;&#24773;&#26223;&#12289;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#33539;&#22260;&#21644;&#31232;&#32570;&#30340;&#27010;&#24565;&#30417;&#30563;&#31561;&#33499;&#21051;&#26465;&#20214;&#19979;&#20063;&#33021;&#26377;&#25928;&#24212;&#23545;&#12290;</title><link>http://arxiv.org/abs/2308.11991</link><description>&lt;p&gt;
&#20851;&#20110;&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Relational Concept Based Models. (arXiv:2308.11991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11991
&lt;/p&gt;
&lt;p&gt;
&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#26159;&#19968;&#31181;&#20851;&#31995;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23478;&#26063;&#65292;&#29992;&#20110;&#22312;&#20851;&#31995;&#39046;&#22495;&#25552;&#20379;&#21487;&#35299;&#37322;&#30340;&#20219;&#21153;&#39044;&#27979;&#65292;&#30456;&#27604;&#38750;&#20851;&#31995;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#27169;&#22411;&#65292;&#23427;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#19982;&#29616;&#26377;&#30340;&#20851;&#31995;&#27169;&#22411;&#30456;&#21305;&#37197;&#65292;&#24182;&#25903;&#25345;&#29983;&#25104;&#37327;&#21270;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#65292;&#21516;&#26102;&#22312;&#27979;&#35797;&#26102;&#24178;&#39044;&#12289;&#36229;&#20986;&#20998;&#24067;&#24773;&#26223;&#12289;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#33539;&#22260;&#21644;&#31232;&#32570;&#30340;&#27010;&#24565;&#30417;&#30563;&#31561;&#33499;&#21051;&#26465;&#20214;&#19979;&#20063;&#33021;&#26377;&#25928;&#24212;&#23545;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20851;&#31995;&#39046;&#22495;&#20013;&#35774;&#35745;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#25361;&#25112;&#65306;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#22522;&#20110;&#27010;&#24565;&#30340;&#27169;&#22411;&#65288;CBMs&#65289;&#65292;&#24182;&#27809;&#26377;&#35774;&#35745;&#26469;&#35299;&#20915;&#20851;&#31995;&#38382;&#39064;&#65292;&#32780;&#20851;&#31995;&#27169;&#22411;&#20063;&#27809;&#26377;&#20687;CBMs&#37027;&#26679;&#21487;&#35299;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#31995;&#27010;&#24565;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#31181;&#25552;&#20379;&#21487;&#35299;&#37322;&#20219;&#21153;&#39044;&#27979;&#30340;&#20851;&#31995;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23478;&#26063;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20174;&#22270;&#20687;&#20998;&#31867;&#21040;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#38142;&#25509;&#39044;&#27979;&#65292;&#34920;&#26126;&#20851;&#31995;CBMs&#65306;&#65288;i&#65289;&#19982;&#29616;&#26377;&#30340;&#20851;&#31995;&#40657;&#30418;&#30340;&#27867;&#21270;&#24615;&#33021;&#30456;&#21305;&#37197;&#65288;&#19981;&#21516;&#20110;&#38750;&#20851;&#31995;&#30340;CBMs&#65289;&#65292;&#65288;ii&#65289;&#25903;&#25345;&#29983;&#25104;&#37327;&#21270;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#65292;&#65288;iii&#65289;&#26377;&#25928;&#24212;&#23545;&#27979;&#35797;&#26102;&#30340;&#24178;&#39044;&#65292;&#20197;&#21450;&#65288;iv&#65289;&#32463;&#21463;&#20303;&#21253;&#25324;&#36229;&#20986;&#20998;&#24067;&#24773;&#26223;&#12289;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#33539;&#22260;&#21644;&#31232;&#32570;&#30340;&#27010;&#24565;&#30417;&#30563;&#31561;&#33499;&#21051;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
The design of interpretable deep learning models working in relational domains poses an open challenge: interpretable deep learning methods, such as Concept-Based Models (CBMs), are not designed to solve relational problems, while relational models are not as interpretable as CBMs. To address this problem, we propose Relational Concept-Based Models, a family of relational deep learning methods providing interpretable task predictions. Our experiments, ranging from image classification to link prediction in knowledge graphs, show that relational CBMs (i) match generalization performance of existing relational black-boxes (as opposed to non-relational CBMs), (ii) support the generation of quantified concept-based explanations, (iii) effectively respond to test-time interventions, and (iv) withstand demanding settings including out-of-distribution scenarios, limited training data regimes, and scarce concept supervisions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;-&#21069;&#21521;&#21644;&#39044;&#27979;&#24335;&#21069;&#21521;-&#21069;&#21521;&#23398;&#20064;&#36807;&#31243;&#30340;&#36890;&#29992;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#36882;&#24402;&#30005;&#36335;&#35745;&#31639;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#33180;&#30005;&#20301;&#12290;&#19982;&#20381;&#36182;&#21453;&#39304;&#31361;&#35302;&#35843;&#25972;&#31070;&#32463;&#30005;&#27963;&#21160;&#30340;&#23574;&#23792;&#31070;&#32463;&#32534;&#30721;&#19981;&#21516;&#65292;&#35813;&#27169;&#22411;&#32431;&#22312;&#32447;&#24182;&#19988;&#26102;&#38388;&#21521;&#21069;&#65292;&#26159;&#23398;&#20064;&#24102;&#26377;&#26102;&#38388;&#23574;&#23792;&#20449;&#21495;&#30340;&#24863;&#35273;&#25968;&#25454;&#27169;&#24335;&#20998;&#24067;&#34920;&#31034;&#30340;&#26377;&#21069;&#36884;&#30340;&#19968;&#31181;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2303.18187</link><description>&lt;p&gt;
&#21033;&#29992;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;&#21069;&#21521;&#36807;&#31243;&#23398;&#20064;&#23574;&#23792;&#31070;&#32463;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning Spiking Neural Systems with the Event-Driven Forward-Forward Process. (arXiv:2303.18187v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.18187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;-&#21069;&#21521;&#21644;&#39044;&#27979;&#24335;&#21069;&#21521;-&#21069;&#21521;&#23398;&#20064;&#36807;&#31243;&#30340;&#36890;&#29992;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#36882;&#24402;&#30005;&#36335;&#35745;&#31639;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#33180;&#30005;&#20301;&#12290;&#19982;&#20381;&#36182;&#21453;&#39304;&#31361;&#35302;&#35843;&#25972;&#31070;&#32463;&#30005;&#27963;&#21160;&#30340;&#23574;&#23792;&#31070;&#32463;&#32534;&#30721;&#19981;&#21516;&#65292;&#35813;&#27169;&#22411;&#32431;&#22312;&#32447;&#24182;&#19988;&#26102;&#38388;&#21521;&#21069;&#65292;&#26159;&#23398;&#20064;&#24102;&#26377;&#26102;&#38388;&#23574;&#23792;&#20449;&#21495;&#30340;&#24863;&#35273;&#25968;&#25454;&#27169;&#24335;&#20998;&#24067;&#34920;&#31034;&#30340;&#26377;&#21069;&#36884;&#30340;&#19968;&#31181;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#20351;&#29992;&#23574;&#23792;&#31070;&#32463;&#20803;&#36827;&#34892;&#20449;&#24687;&#22788;&#29702;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20998;&#20998;&#37197;&#31639;&#27861;&#65292;&#26080;&#38656;&#21453;&#39304;&#31361;&#35302;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;-&#21069;&#21521;&#21644;&#39044;&#27979;&#24335;&#21069;&#21521;-&#21069;&#21521;&#23398;&#20064;&#36807;&#31243;&#30340;&#36890;&#29992;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#36845;&#20195;&#22788;&#29702;&#24863;&#35273;&#36755;&#20837;&#12290;&#22240;&#27492;&#65292;&#36882;&#24402;&#30005;&#36335;&#20250;&#26681;&#25454;&#23616;&#37096;&#33258;&#19979;&#21521;&#19978;&#12289;&#33258;&#19978;&#32780;&#19979;&#21644;&#20391;&#38754;&#30340;&#20449;&#21495;&#35745;&#31639;&#27599;&#23618;&#20013;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#33180;&#30005;&#20301;&#65292;&#20419;&#36827;&#19968;&#31181;&#21160;&#24577;&#30340;&#12289;&#36880;&#23618;&#24182;&#34892;&#30340;&#31070;&#32463;&#35745;&#31639;&#24418;&#24335;&#12290;&#19982;&#20381;&#36182;&#21453;&#39304;&#31361;&#35302;&#35843;&#25972;&#31070;&#32463;&#30005;&#27963;&#21160;&#30340;&#23574;&#23792;&#31070;&#32463;&#32534;&#30721;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#32431;&#22312;&#32447;&#24182;&#19988;&#26102;&#38388;&#21521;&#21069;&#65292;&#36825;&#26679;&#23601;&#33021;&#22815;&#23398;&#20064;&#24102;&#26377;&#26102;&#38388;&#23574;&#23792;&#20449;&#21495;&#30340;&#24863;&#35273;&#25968;&#25454;&#27169;&#24335;&#30340;&#20998;&#24067;&#34920;&#31034;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#27169;&#24335;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#20107;&#20214;&#39537;&#21160;&#30340;&#21069;&#21521;&#21069;&#21521;&#65288;ED-FF&#65289;&#26694;&#26550;&#24037;&#20316;&#27491;&#24120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel credit assignment algorithm for information processing with spiking neurons without requiring feedback synapses. Specifically, we propose an event-driven generalization of the forward-forward and the predictive forward-forward learning processes for a spiking neural system that iteratively processes sensory input over a stimulus window. As a result, the recurrent circuit computes the membrane potential of each neuron in each layer as a function of local bottom-up, top-down, and lateral signals, facilitating a dynamic, layer-wise parallel form of neural computation. Unlike spiking neural coding, which relies on feedback synapses to adjust neural electrical activity, our model operates purely online and forward in time, offering a promising way to learn distributed representations of sensory data patterns with temporal spike signals. Notably, our experimental results on several pattern datasets demonstrate that the even-driven forward-forward (ED-FF) framework works we
&lt;/p&gt;</description></item><item><title>EVOTER&#20351;&#29992;&#31616;&#21333;&#30340;&#36923;&#36753;&#34920;&#36798;&#24335;&#28436;&#21270;&#20986;&#36879;&#26126;&#21487;&#35299;&#37322;&#30340;&#35268;&#21017;&#38598;&#65292;&#19982;&#40657;&#30418;&#27169;&#22411;&#24615;&#33021;&#30456;&#20284;&#65292;&#21487;&#20197;&#25581;&#31034;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#24182;&#20026;&#26410;&#26469;&#26500;&#24314;&#21487;&#38752;&#30340;AI&#31995;&#32479;&#25552;&#20379;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2204.10438</link><description>&lt;p&gt;
EVOTER&#65306;&#36879;&#26126;&#21487;&#35299;&#37322;&#35268;&#21017;&#38598;&#30340;&#36827;&#21270;
&lt;/p&gt;
&lt;p&gt;
EVOTER: Evolution of Transparent Explainable Rule-sets. (arXiv:2204.10438v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10438
&lt;/p&gt;
&lt;p&gt;
EVOTER&#20351;&#29992;&#31616;&#21333;&#30340;&#36923;&#36753;&#34920;&#36798;&#24335;&#28436;&#21270;&#20986;&#36879;&#26126;&#21487;&#35299;&#37322;&#30340;&#35268;&#21017;&#38598;&#65292;&#19982;&#40657;&#30418;&#27169;&#22411;&#24615;&#33021;&#30456;&#20284;&#65292;&#21487;&#20197;&#25581;&#31034;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#24182;&#20026;&#26410;&#26469;&#26500;&#24314;&#21487;&#38752;&#30340;AI&#31995;&#32479;&#25552;&#20379;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;AI&#31995;&#32479;&#26159;&#40657;&#30418;&#23376;&#65292;&#20026;&#32473;&#23450;&#30340;&#36755;&#20837;&#29983;&#25104;&#21512;&#29702;&#30340;&#36755;&#20986;&#12290;&#28982;&#32780;&#65292;&#26576;&#20123;&#39046;&#22495;&#20855;&#26377;&#35299;&#37322;&#33021;&#21147;&#21644;&#20449;&#20219;&#24230;&#35201;&#27714;&#65292;&#36825;&#20123;&#35201;&#27714;&#19981;&#33021;&#30452;&#25509;&#28385;&#36275;&#36825;&#20123;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#21363;&#24320;&#22987;&#26102;&#27169;&#22411;&#23601;&#26159;&#36879;&#26126;&#30340;&#21644;&#21487;&#35299;&#37322;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#31616;&#21333;&#30340;&#36923;&#36753;&#34920;&#36798;&#24335;&#28436;&#21270;&#20986;&#35268;&#21017;&#38598;&#65292;&#31216;&#20026;EVOTER&#12290;EVOTER&#22312;&#22810;&#20010;&#39044;&#27979;/&#20998;&#31867;&#21644;&#22788;&#26041;/&#25919;&#31574;&#25628;&#32034;&#39046;&#22495;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#26377;&#21644;&#27809;&#26377;&#20195;&#29702;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#23427;&#33021;&#22815;&#21457;&#29616;&#21644;&#40657;&#30418;&#27169;&#22411;&#30456;&#20284;&#30340;&#26377;&#24847;&#20041;&#30340;&#35268;&#21017;&#38598;&#12290;&#36825;&#20123;&#35268;&#21017;&#21487;&#20197;&#25552;&#20379;&#39046;&#22495;&#30340;&#35265;&#35299;&#65292;&#24182;&#20351;&#25968;&#25454;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#26174;&#24615;&#21270;&#12290;&#20063;&#21487;&#20197;&#30452;&#25509;&#23545;&#23427;&#20204;&#36827;&#34892;&#32534;&#36753;&#65292;&#20197;&#28040;&#38500;&#20559;&#35265;&#24182;&#28155;&#21152;&#32422;&#26463;&#12290;&#22240;&#27492;&#65292;EVOTER&#20026;&#26410;&#26469;&#26500;&#24314;&#20540;&#24471;&#20449;&#36182;&#30340;AI&#31995;&#32479;&#30340;&#21487;&#38752;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most AI systems are black boxes generating reasonable outputs for given inputs. Some domains, however, have explainability and trustworthiness requirements that cannot be directly met by these approaches. Various methods have therefore been developed to interpret black-box models after training. This paper advocates an alternative approach where the models are transparent and explainable to begin with. This approach, EVOTER, evolves rule-sets based on simple logical expressions. The approach is evaluated in several prediction/classification and prescription/policy search domains with and without a surrogate. It is shown to discover meaningful rule sets that perform similarly to black-box models. The rules can provide insight into the domain, and make biases hidden in the data explicit. It may also be possible to edit them directly to remove biases and add constraints. EVOTER thus forms a promising foundation for building trustworthy AI systems for real-world applications in the future.
&lt;/p&gt;</description></item></channel></rss>