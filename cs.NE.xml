<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#21387;&#32553;&#38142;&#8221;&#30340;&#31995;&#32479;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#37327;&#21270;&#12289;&#21098;&#26525;&#12289;&#25552;&#21069;&#36864;&#20986;&#21644;&#30693;&#35782;&#33976;&#39311;&#31561;&#24120;&#35265;&#25216;&#26415;&#65292;&#23454;&#29616;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#21387;&#32553;&#12290;</title><link>https://arxiv.org/abs/2403.17447</link><description>&lt;p&gt;
&#21387;&#32553;&#38142;&#65306;&#19968;&#31181;&#31995;&#32479;&#21270;&#30340;&#32452;&#21512;&#21387;&#32553;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Chain of Compression: A Systematic Approach to Combinationally Compress Convolutional Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17447
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#21387;&#32553;&#38142;&#8221;&#30340;&#31995;&#32479;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#37327;&#21270;&#12289;&#21098;&#26525;&#12289;&#25552;&#21069;&#36864;&#20986;&#21644;&#30693;&#35782;&#33976;&#39311;&#31561;&#24120;&#35265;&#25216;&#26415;&#65292;&#23454;&#29616;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#27969;&#34892;&#65292;&#20294;&#23427;&#20204;&#22312;&#35745;&#31639;&#21644;&#23384;&#20648;&#26041;&#38754;&#30340;&#23494;&#38598;&#24615;&#32473;&#36164;&#28304;&#26377;&#38480;&#30340;&#35745;&#31639;&#31995;&#32479;&#24102;&#26469;&#20102;&#25361;&#25112;&#65292;&#23588;&#20854;&#26159;&#22312;&#38656;&#35201;&#23454;&#26102;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#20943;&#36731;&#36127;&#25285;&#65292;&#27169;&#22411;&#21387;&#32553;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#37325;&#28857;&#12290;&#35768;&#22810;&#26041;&#27861;&#65292;&#22914;&#37327;&#21270;&#12289;&#21098;&#26525;&#12289;&#25552;&#21069;&#36864;&#20986;&#21644;&#30693;&#35782;&#33976;&#39311;&#24050;&#32463;&#35777;&#26126;&#20102;&#20943;&#23569;&#31070;&#32463;&#32593;&#32476;&#20013;&#20887;&#20313;&#30340;&#25928;&#26524;&#12290;&#36890;&#36807;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#65292;&#21487;&#20197;&#26126;&#26174;&#30475;&#20986;&#65292;&#27599;&#31181;&#26041;&#27861;&#37117;&#21033;&#29992;&#20102;&#20854;&#29420;&#29305;&#30340;&#29305;&#24615;&#26469;&#21387;&#32553;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#19988;&#24403;&#23427;&#20204;&#32467;&#21512;&#22312;&#19968;&#36215;&#26102;&#20063;&#21487;&#20197;&#23637;&#29616;&#20986;&#20114;&#34917;&#30340;&#34892;&#20026;&#12290;&#20026;&#20102;&#25506;&#31350;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#20174;&#20114;&#34917;&#29305;&#24615;&#20013;&#33719;&#30410;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21387;&#32553;&#38142;&#65292;&#23427;&#22312;&#32452;&#21512;&#24207;&#21015;&#19978;&#25805;&#20316;&#65292;&#24212;&#29992;&#36825;&#20123;&#24120;&#35265;&#25216;&#26415;&#26469;&#21387;&#32553;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17447v1 Announce Type: new  Abstract: Convolutional neural networks (CNNs) have achieved significant popularity, but their computational and memory intensity poses challenges for resource-constrained computing systems, particularly with the prerequisite of real-time performance. To release this burden, model compression has become an important research focus. Many approaches like quantization, pruning, early exit, and knowledge distillation have demonstrated the effect of reducing redundancy in neural networks. Upon closer examination, it becomes apparent that each approach capitalizes on its unique features to compress the neural network, and they can also exhibit complementary behavior when combined. To explore the interactions and reap the benefits from the complementary features, we propose the Chain of Compression, which works on the combinational sequence to apply these common techniques to compress the neural network. Validated on the image-based regression and classi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#21516;&#21270;&#31574;&#30053;&#65292;&#21487;&#21487;&#38752;&#22320;&#22788;&#29702;&#21253;&#21547;&#19981;&#30830;&#23450;&#24230;&#37327;&#21270;&#30340;&#23380;&#38553;&#23610;&#24230;&#21453;&#24212;&#21453;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#25968;&#25454;&#39537;&#21160;&#21644;&#29289;&#29702;&#24314;&#27169;&#65292;&#30830;&#20445;&#20102;&#23380;&#38553;&#23610;&#24230;&#27169;&#22411;&#30340;&#21487;&#38752;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2308.12864</link><description>&lt;p&gt;
&#33258;&#21160;&#21152;&#26435;&#30340;&#36125;&#21494;&#26031;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#21644;&#40065;&#26834;&#20272;&#35745;&#22312;&#23380;&#38553;&#23610;&#24230;&#28342;&#35299;&#22270;&#20687;&#30340;&#22810;&#20219;&#21153;&#21453;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Auto-weighted Bayesian Physics-Informed Neural Networks and robust estimations for multitask inverse problems in pore-scale imaging of dissolution. (arXiv:2308.12864v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12864
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#21516;&#21270;&#31574;&#30053;&#65292;&#21487;&#21487;&#38752;&#22320;&#22788;&#29702;&#21253;&#21547;&#19981;&#30830;&#23450;&#24230;&#37327;&#21270;&#30340;&#23380;&#38553;&#23610;&#24230;&#21453;&#24212;&#21453;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#25968;&#25454;&#39537;&#21160;&#21644;&#29289;&#29702;&#24314;&#27169;&#65292;&#30830;&#20445;&#20102;&#23380;&#38553;&#23610;&#24230;&#27169;&#22411;&#30340;&#21487;&#38752;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#21516;&#21270;&#31574;&#30053;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20351;&#25105;&#20204;&#33021;&#22815;&#21487;&#38752;&#22320;&#22788;&#29702;&#21253;&#21547;&#19981;&#30830;&#23450;&#24230;&#37327;&#21270;&#30340;&#21453;&#24212;&#21453;&#38382;&#39064;&#12290;&#23380;&#38553;&#23610;&#24230;&#30340;&#21453;&#24212;&#27969;&#21160;&#24314;&#27169;&#20026;&#30740;&#31350;&#23439;&#35266;&#24615;&#36136;&#22312;&#21160;&#24577;&#36807;&#31243;&#20013;&#30340;&#28436;&#21464;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#21463;&#21040;&#30456;&#20851;&#30340;X&#23556;&#32447;&#24494;&#35745;&#31639;&#39640;&#24230;&#20998;&#36776;&#29575;&#25104;&#20687; (X&#23556;&#32447;&#24494;CT) &#36807;&#31243;&#20013;&#30340;&#25104;&#20687;&#38480;&#21046;&#30340;&#24433;&#21709;&#65292;&#23548;&#33268;&#20102;&#24615;&#36136;&#20272;&#35745;&#20013;&#30340;&#24046;&#24322;&#12290;&#21160;&#21147;&#23398;&#21442;&#25968;&#30340;&#35780;&#20272;&#20063;&#38754;&#20020;&#25361;&#25112;&#65292;&#22240;&#20026;&#21453;&#24212;&#31995;&#25968;&#26159;&#20851;&#38190;&#21442;&#25968;&#65292;&#20854;&#25968;&#20540;&#33539;&#22260;&#24456;&#24191;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23558;&#19981;&#30830;&#23450;&#24230;&#37327;&#21270;&#38598;&#25104;&#21040;&#24037;&#20316;&#27969;&#31243;&#20013;&#65292;&#30830;&#20445;&#20102;&#23380;&#38553;&#23610;&#24230;&#27169;&#22411;&#30340;&#21487;&#38752;&#26657;&#20934;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#22522;&#20110;&#21453;&#24212;&#21453;&#38382;&#39064;&#30340;&#22810;&#20219;&#21153;&#20844;&#24335;&#65292;&#23558;&#25968;&#25454;&#39537;&#21160;&#21644;&#29289;&#29702;&#24314;&#27169;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, we present a novel data assimilation strategy in pore-scale imaging and demonstrate that this makes it possible to robustly address reactive inverse problems incorporating Uncertainty Quantification (UQ). Pore-scale modeling of reactive flow offers a valuable opportunity to investigate the evolution of macro-scale properties subject to dynamic processes. Yet, they suffer from imaging limitations arising from the associated X-ray microtomography (X-ray microCT) process, which induces discrepancies in the properties estimates. Assessment of the kinetic parameters also raises challenges, as reactive coefficients are critical parameters that can cover a wide range of values. We account for these two issues and ensure reliable calibration of pore-scale modeling, based on dynamical microCT images, by integrating uncertainty quantification in the workflow.  The present method is based on a multitasking formulation of reactive inverse problems combining data-driven and physics
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#21463;&#33258;&#28982;&#21551;&#21457;&#30340;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#37325;&#35201;&#24615;&#21644;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;CSO-MA&#65292;&#36890;&#36807;&#22810;&#20010;&#20248;&#21270;&#38382;&#39064;&#30340;&#24212;&#29992;&#23637;&#31034;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.10875</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#21450;&#20854;&#22312;&#29983;&#29289;&#20449;&#24687;&#23398;&#12289;&#29983;&#29289;&#32479;&#35745;&#23398;&#12289;&#29983;&#24577;&#23398;&#21644;&#21046;&#36896;&#19994;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries. (arXiv:2308.10875v2 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10875
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#21463;&#33258;&#28982;&#21551;&#21457;&#30340;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#37325;&#35201;&#24615;&#21644;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;CSO-MA&#65292;&#36890;&#36807;&#22810;&#20010;&#20248;&#21270;&#38382;&#39064;&#30340;&#24212;&#29992;&#23637;&#31034;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#33258;&#28982;&#21551;&#21457;&#30340;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#26159;&#20154;&#24037;&#26234;&#33021;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#31185;&#39046;&#22495;&#20013;&#24212;&#29992;&#20110;&#35299;&#20915;&#21508;&#31181;&#31867;&#22411;&#30340;&#25361;&#25112;&#24615;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#24212;&#29992;&#20102;&#19968;&#31181;&#26032;&#25552;&#20986;&#30340;&#21463;&#33258;&#28982;&#21551;&#21457;&#30340;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#31216;&#20026;&#20855;&#26377;&#31361;&#21464;&#20195;&#29702;&#30340;&#31454;&#20105;&#24615;&#32676;&#20307;&#20248;&#21270;&#22120;(CSO-MA)&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#30456;&#23545;&#20110;&#31454;&#20105;&#23545;&#25163;&#22312;&#32479;&#35745;&#31185;&#23398;&#20013;&#21508;&#31181;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#28789;&#27963;&#24615;&#21644;&#36229;&#36234;&#24615;&#33021;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#31639;&#27861;&#39640;&#25928;&#19988;&#21487;&#20197;&#25972;&#21512;&#21508;&#31181;&#25104;&#26412;&#32467;&#26500;&#25110;&#22810;&#20010;&#29992;&#25143;&#25351;&#23450;&#30340;&#38750;&#32447;&#24615;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#24212;&#29992;&#21253;&#25324;(i)&#22312;&#29983;&#29289;&#20449;&#24687;&#23398;&#20013;&#36890;&#36807;&#21333;&#32454;&#32990;&#24191;&#20041;&#36235;&#21183;&#27169;&#22411;&#25214;&#21040;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20197;&#30740;&#31350;&#20266;&#26102;&#24577;&#65292;(ii) &#20272;&#35745;&#25945;&#32946;&#30740;&#31350;&#20013;&#24120;&#29992;&#30340;Rasch&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;(iii) &#22312;&#39532;&#23572;&#21487;&#22827;&#26356;&#26032;&#27169;&#22411;&#20013;&#20026;Cox&#22238;&#24402;&#25214;&#21040;M-&#20272;&#35745;&#65292;(iv) &#30697;&#38453;&#34917;&#20840;&#20197;&#22635;&#34917;&#20004;&#20010;&#36830;&#36830;&#19981;&#36890;&#22270;&#20013;&#30340;&#32570;&#22833;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nature-inspired metaheuristic algorithms are important components of artificial intelligence, and are increasingly used across disciplines to tackle various types of challenging optimization problems. We apply a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) and demonstrate its flexibility and out-performance relative to its competitors in a variety of optimization problems in the statistical sciences. In particular, we show the algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. Our applications include (i) finding maximum likelihood estimates of parameters in a single cell generalized trend model to study pseudotime in bioinformatics, (ii) estimating parameters in a commonly used Rasch model in education research, (iii) finding M-estimates for a Cox regression in a Markov renewal model and (iv) matrix completion to impute missing values in a two com
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GAN&#30340;&#26080;&#26799;&#24230;&#29289;&#29702;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#33258;&#28982;&#30340;&#23545;&#25239;&#34917;&#19969;&#65292;&#25915;&#20987;&#29289;&#20307;&#26816;&#27979;&#22120;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2303.04238</link><description>&lt;p&gt;
&#21306;&#22495;&#38544;&#24418;&#34917;&#19969;&#65306;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#29289;&#29702;&#23545;&#25239;&#25915;&#20987;&#29289;&#20307;&#26816;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on Object Detectors. (arXiv:2303.04238v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GAN&#30340;&#26080;&#26799;&#24230;&#29289;&#29702;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#33258;&#28982;&#30340;&#23545;&#25239;&#34917;&#19969;&#65292;&#25915;&#20987;&#29289;&#20307;&#26816;&#27979;&#22120;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#36234;&#26469;&#36234;&#24341;&#36215;&#20851;&#27880;&#12290;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#22823;&#22810;&#38598;&#20013;&#22312;&#22522;&#20110;&#26799;&#24230;&#30340;&#25216;&#26415;&#65292;&#21363;&#25152;&#35859;&#30340;&#30333;&#30418;&#25915;&#20987;&#65292;&#22312;&#20854;&#20013;&#25915;&#20987;&#32773;&#21487;&#20197;&#35775;&#38382;&#30446;&#26631;&#27169;&#22411;&#30340;&#20869;&#37096;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20551;&#35774;&#22312;&#23454;&#38469;&#19990;&#30028;&#20013;&#36890;&#24120;&#26159;&#19981;&#29616;&#23454;&#30340;&#12290;&#30456;&#23545;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#38656;&#20351;&#29992;&#26799;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;&#23398;&#20064;&#22270;&#20687;&#27969;&#24418;&#26469;&#29983;&#25104;&#33258;&#28982;&#30340;&#29289;&#29702;&#23545;&#25239;&#34917;&#19969;&#65292;&#29992;&#20110;&#29289;&#20307;&#26816;&#27979;&#22120;&#30340;&#25915;&#20987;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#25968;&#23383;&#21644;&#29289;&#29702;&#23618;&#38754;&#19978;&#22343;&#21487;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial attacks on deep-learning models have been receiving increased attention in recent years. Work in this area has mostly focused on gradient-based techniques, so-called white-box attacks, wherein the attacker has access to the targeted model's internal parameters; such an assumption is usually unrealistic in the real world. Some attacks additionally use the entire pixel space to fool a given model, which is neither practical nor physical (i.e., real-world). On the contrary, we propose herein a gradient-free method that uses the learned image manifold of a pretrained generative adversarial network (GAN) to generate naturalistic physical adversarial patches for object detectors. We show that our proposed method works both digitally and physically.
&lt;/p&gt;</description></item></channel></rss>