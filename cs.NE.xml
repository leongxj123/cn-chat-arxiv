<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>NeuralDiffuser&#24341;&#20837;&#20027;&#35270;&#35273;&#29305;&#24449;&#24341;&#23548;&#65292;&#25193;&#23637;&#20102;LDM&#26041;&#27861;&#30340;&#33258;&#19979;&#32780;&#19978;&#36807;&#31243;&#65292;&#20197;&#23454;&#29616;&#24544;&#23454;&#30340;&#35821;&#20041;&#21644;&#32454;&#33410;&#12290;</title><link>https://arxiv.org/abs/2402.13809</link><description>&lt;p&gt;
NeuralDiffuser&#65306;&#20855;&#26377;&#20027;&#35270;&#35273;&#29305;&#24449;&#24341;&#23548;&#25193;&#25955;&#30340;&#21487;&#25511;fMRI&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13809
&lt;/p&gt;
&lt;p&gt;
NeuralDiffuser&#24341;&#20837;&#20027;&#35270;&#35273;&#29305;&#24449;&#24341;&#23548;&#65292;&#25193;&#23637;&#20102;LDM&#26041;&#27861;&#30340;&#33258;&#19979;&#32780;&#19978;&#36807;&#31243;&#65292;&#20197;&#23454;&#29616;&#24544;&#23454;&#30340;&#35821;&#20041;&#21644;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDM)&#20174;&#21151;&#33021;&#24615;&#30913;&#20849;&#25391;&#25104;&#20687;(fMRI)&#20013;&#37325;&#24314;&#35270;&#35273;&#21050;&#28608;&#65292;&#20026;&#22823;&#33041;&#25552;&#20379;&#20102;&#32454;&#31890;&#24230;&#30340;&#26816;&#32034;&#12290;&#19968;&#20010;&#25361;&#25112;&#22312;&#20110;&#37325;&#24314;&#32454;&#33410;&#30340;&#36830;&#36143;&#23545;&#40784;&#65288;&#22914;&#32467;&#26500;&#12289;&#32972;&#26223;&#12289;&#32441;&#29702;&#12289;&#39068;&#33394;&#31561;&#65289;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#22312;&#30456;&#21516;&#26465;&#20214;&#19979;&#65292;LDM&#20063;&#20250;&#29983;&#25104;&#19981;&#21516;&#30340;&#22270;&#20687;&#32467;&#26524;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#25581;&#31034;&#20102;&#22522;&#20110;LDM&#30340;&#31070;&#32463;&#31185;&#23398;&#35270;&#35282;&#65292;&#21363;&#22522;&#20110;&#26469;&#33258;&#28023;&#37327;&#22270;&#20687;&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#36827;&#34892;&#33258;&#19978;&#32780;&#19979;&#30340;&#21019;&#24314;&#65292;&#20294;&#32570;&#20047;&#22522;&#20110;&#32454;&#33410;&#39537;&#21160;&#30340;&#33258;&#19979;&#32780;&#19978;&#24863;&#30693;&#65292;&#23548;&#33268;&#32454;&#33410;&#19981;&#24544;&#23454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;NeuralDiffuser&#65292;&#24341;&#20837;&#20027;&#35270;&#35273;&#29305;&#24449;&#24341;&#23548;&#65292;&#20197;&#28176;&#21464;&#24418;&#24335;&#25552;&#20379;&#32454;&#33410;&#32447;&#32034;&#65292;&#25193;&#23637;&#20102;LDM&#26041;&#27861;&#30340;&#33258;&#19979;&#32780;&#19978;&#36807;&#31243;&#65292;&#20197;&#23454;&#29616;&#24544;&#23454;&#30340;&#35821;&#20041;&#21644;&#32454;&#33410;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24341;&#23548;&#31574;&#30053;&#65292;&#20197;&#30830;&#20445;&#37325;&#22797;&#37325;&#24314;&#30340;&#19968;&#33268;&#24615;&#65292;&#32780;&#19981;&#26159;&#38543;&#26426;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13809v1 Announce Type: cross  Abstract: Reconstructing visual stimuli from functional Magnetic Resonance Imaging (fMRI) based on Latent Diffusion Models (LDM) provides a fine-grained retrieval of the brain. A challenge persists in reconstructing a cohesive alignment of details (such as structure, background, texture, color, etc.). Moreover, LDMs would generate different image results even under the same conditions. For these, we first uncover the neuroscientific perspective of LDM-based methods that is top-down creation based on pre-trained knowledge from massive images but lack of detail-driven bottom-up perception resulting in unfaithful details. We propose NeuralDiffuser which introduces primary visual feature guidance to provide detail cues in the form of gradients, extending the bottom-up process for LDM-based methods to achieve faithful semantics and details. We also developed a novel guidance strategy to ensure the consistency of repeated reconstructions rather than a
&lt;/p&gt;</description></item></channel></rss>