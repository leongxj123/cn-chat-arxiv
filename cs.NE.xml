<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#31946;&#26657;&#20934;&#35823;&#24046;&#24230;&#37327;&#65288;FCE&#65289;&#65292;&#21033;&#29992;&#27169;&#31946;&#20998;&#31665;&#26041;&#27861;&#35745;&#31639;&#26657;&#20934;&#35823;&#24046;&#65292;&#20174;&#32780;&#32531;&#35299;&#20102;&#27010;&#29575;&#20559;&#26012;&#30340;&#24433;&#21709;&#24182;&#25552;&#20379;&#20102;&#26356;&#32039;&#23494;&#30340;&#20272;&#35745;&#20540;&#12290;&#19982;&#20256;&#32479;&#25351;&#26631;ECE&#30456;&#27604;&#65292;FCE&#22312;&#22810;&#31867;&#35774;&#32622;&#20013;&#34920;&#29616;&#26356;&#22909;&#65292;https://github.com/srdgFHE/FCE-paper&#12290;</title><link>http://arxiv.org/abs/2305.00543</link><description>&lt;p&gt;
&#20351;&#29992;&#27169;&#31946;&#20998;&#31665;&#36827;&#34892;&#26657;&#20934;&#35823;&#24046;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Calibration Error Estimation Using Fuzzy Binning. (arXiv:2305.00543v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#31946;&#26657;&#20934;&#35823;&#24046;&#24230;&#37327;&#65288;FCE&#65289;&#65292;&#21033;&#29992;&#27169;&#31946;&#20998;&#31665;&#26041;&#27861;&#35745;&#31639;&#26657;&#20934;&#35823;&#24046;&#65292;&#20174;&#32780;&#32531;&#35299;&#20102;&#27010;&#29575;&#20559;&#26012;&#30340;&#24433;&#21709;&#24182;&#25552;&#20379;&#20102;&#26356;&#32039;&#23494;&#30340;&#20272;&#35745;&#20540;&#12290;&#19982;&#20256;&#32479;&#25351;&#26631;ECE&#30456;&#27604;&#65292;FCE&#22312;&#22810;&#31867;&#35774;&#32622;&#20013;&#34920;&#29616;&#26356;&#22909;&#65292;https://github.com/srdgFHE/FCE-paper&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20915;&#31574;&#24448;&#24448;&#20250;&#36807;&#20110;&#33258;&#20449;&#65292;&#20854;&#21407;&#22987;&#32467;&#26524;&#30340;&#27010;&#29575;&#24182;&#19981;&#31526;&#21512;&#30495;&#23454;&#30340;&#20915;&#31574;&#27010;&#29575;&#12290;&#31070;&#32463;&#32593;&#32476;&#30340;&#26657;&#20934;&#26159;&#23454;&#29616;&#26356;&#21487;&#38752;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#20808;&#21069;&#30340;&#26657;&#20934;&#35823;&#24046;&#24230;&#37327;&#20027;&#35201;&#21033;&#29992;&#28165;&#26224;&#30340;&#20998;&#31665;&#25104;&#21592;&#36164;&#26684;&#24230;&#37327;&#12290;&#36825;&#21152;&#21095;&#20102;&#27169;&#22411;&#27010;&#29575;&#30340;&#20559;&#26012;&#65292;&#24182;&#25551;&#32472;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#19981;&#23436;&#25972;&#22270;&#20687;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27169;&#31946;&#20998;&#31665;&#26041;&#27861;&#35745;&#31639;&#26657;&#20934;&#35823;&#24046;&#30340;&#27169;&#31946;&#26657;&#20934;&#35823;&#24046;&#24230;&#37327;&#65288;FCE&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#32531;&#35299;&#20102;&#27010;&#29575;&#20559;&#26012;&#30340;&#24433;&#21709;&#65292;&#24182;&#22312;&#27979;&#37327;&#26657;&#20934;&#35823;&#24046;&#26102;&#25552;&#20379;&#20102;&#26356;&#32039;&#23494;&#30340;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#25351;&#26631;&#19982;ECE&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#32676;&#20307;&#21644;&#31867;&#21035;&#25104;&#21592;&#36523;&#20221;&#20013;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;FCE&#22312;&#26657;&#20934;&#35823;&#24046;&#20272;&#35745;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#65292;&#29305;&#21035;&#26159;&#22312;&#22810;&#31867;&#35774;&#32622;&#20013;&#65292;&#32531;&#35299;&#20102;&#27169;&#22411;&#32622;&#20449;&#24230;&#20998;&#25968;&#20559;&#26012;&#23545;&#26657;&#20934;&#35823;&#24046;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#20195;&#30721;https://github.com/srdgFHE/FCE-paper&#65292;&#20197;&#20415;&#26410;&#26469;&#30340;&#21487;&#37325;&#22797;&#24615;&#21644;&#20351;&#29992;FCE&#36827;&#34892;&#26657;&#20934;&#35823;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network-based decisions tend to be overconfident, where their raw outcome probabilities do not align with the true decision probabilities. Calibration of neural networks is an essential step towards more reliable deep learning frameworks. Prior metrics of calibration error primarily utilize crisp bin membership-based measures. This exacerbates skew in model probabilities and portrays an incomplete picture of calibration error. In this work, we propose a Fuzzy Calibration Error metric (FCE) that utilizes a fuzzy binning approach to calculate calibration error. This approach alleviates the impact of probability skew and provides a tighter estimate while measuring calibration error. We compare our metric with ECE across different data populations and class memberships. Our results show that FCE offers better calibration error estimation, especially in multi-class settings, alleviating the effects of skew in model confidence scores on calibration error estimation. We make our code a
&lt;/p&gt;</description></item><item><title>&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;(GBO)&#26159;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#31890;&#29699;&#35745;&#31639;&#26469;&#25552;&#39640;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36825;&#20123;&#26041;&#38754;&#23427;&#27604;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2303.12807</link><description>&lt;p&gt;
&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Granular-ball Optimization Algorithm. (arXiv:2303.12807v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12807
&lt;/p&gt;
&lt;p&gt;
&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;(GBO)&#26159;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#31890;&#29699;&#35745;&#31639;&#26469;&#25552;&#39640;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36825;&#20123;&#26041;&#38754;&#23427;&#27604;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#26234;&#33021;&#20248;&#21270;&#31639;&#27861;&#37117;&#26159;&#22522;&#20110;&#26368;&#23567;&#31890;&#24230;&#21363;&#28857;&#30340;&#35774;&#35745;&#65292;&#23548;&#33268;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#36739;&#24369;&#19988;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;&#20248;&#21270;&#31639;&#27861;&#65292;&#21363;&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;(GBO)&#65292;&#36890;&#36807;&#24341;&#20837;&#31890;&#29699;&#35745;&#31639;&#26469;&#23454;&#29616;&#12290;GBO&#20351;&#29992;&#22810;&#20010;&#31890;&#29699;&#26469;&#35206;&#30422;&#35299;&#31354;&#38388;&#65292;&#20351;&#29992;&#35768;&#22810;&#32454;&#23567;&#30340;&#32454;&#31890;&#24230;&#31890;&#29699;&#26469;&#25551;&#36848;&#37325;&#35201;&#37096;&#20998;&#65292;&#20351;&#29992;&#23569;&#37327;&#30340;&#22823;&#31895;&#31890;&#24230;&#31890;&#29699;&#26469;&#25551;&#36848;&#19981;&#37325;&#35201;&#30340;&#37096;&#20998;&#65292;&#31934;&#32454;&#30340;&#22810;&#31890;&#24230;&#25968;&#25454;&#25551;&#36848;&#33021;&#21147;&#25552;&#39640;&#20102;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#20108;&#21313;&#20010;&#22522;&#20934;&#20989;&#25968;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#26368;&#27969;&#34892;&#30340;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#30456;&#27604;&#65292;GBO&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#24555;&#30340;&#36895;&#24230;&#65292;&#26356;&#25509;&#36817;&#26368;&#20248;&#35299;&#65292;&#27809;&#26377;&#36229;&#21442;&#25968;&#65292;&#35774;&#35745;&#26356;&#31616;&#21333;&#12290;
&lt;/p&gt;
&lt;p&gt;
The existing intelligent optimization algorithms are designed based on the finest granularity, i.e., a point. This leads to weak global search ability and inefficiency. To address this problem, we proposed a novel multi-granularity optimization algorithm, namely granular-ball optimization algorithm (GBO), by introducing granular-ball computing. GBO uses many granular-balls to cover the solution space. Quite a lot of small and fine-grained granular-balls are used to depict the important parts, and a little number of large and coarse-grained granular-balls are used to depict the inessential parts. Fine multi-granularity data description ability results in a higher global search capability and faster convergence speed. In comparison with the most popular and state-of-the-art algorithms, the experiments on twenty benchmark functions demonstrate its better performance. The faster speed, higher approximation ability of optimal solution, no hyper-parameters, and simpler design of GBO make it 
&lt;/p&gt;</description></item></channel></rss>