<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36827;&#21270;&#31639;&#23376;&#30340;&#24378;&#30423;&#26041;&#27861;&#26469;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#36890;&#36807;&#23558;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#24314;&#27169;&#20026;&#26080;&#31351;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21033;&#29992;&#37096;&#20998;&#35757;&#32451;&#21644;&#20934;&#30830;&#24615;&#20316;&#20026;&#22870;&#21169;&#65292;&#26368;&#32456;&#30340;&#31639;&#27861;Mutant-UCB&#22312;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20248;&#20110;&#22266;&#23450;&#39044;&#31639;&#19979;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2402.05144</link><description>&lt;p&gt;
&#19968;&#31181;&#20351;&#29992;&#36827;&#21270;&#31639;&#23376;&#30340;&#24378;&#30423;&#26041;&#27861;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
A Bandit Approach with Evolutionary Operators for Model Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36827;&#21270;&#31639;&#23376;&#30340;&#24378;&#30423;&#26041;&#27861;&#26469;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#36890;&#36807;&#23558;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#24314;&#27169;&#20026;&#26080;&#31351;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21033;&#29992;&#37096;&#20998;&#35757;&#32451;&#21644;&#20934;&#30830;&#24615;&#20316;&#20026;&#22870;&#21169;&#65292;&#26368;&#32456;&#30340;&#31639;&#27861;Mutant-UCB&#22312;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20248;&#20110;&#22266;&#23450;&#39044;&#31639;&#19979;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#24314;&#27169;&#20026;&#26080;&#31351;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#27169;&#22411;&#26159;&#33218;&#65292;&#36873;&#25321;&#19968;&#20010;&#33218;&#23545;&#24212;&#37096;&#20998;&#35757;&#32451;&#27169;&#22411;&#65288;&#36164;&#28304;&#20998;&#37197;&#65289;&#12290;&#22870;&#21169;&#26159;&#36873;&#25321;&#27169;&#22411;&#22312;&#37096;&#20998;&#35757;&#32451;&#21518;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#36825;&#20010;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#65292;&#36951;&#25022;&#26159;&#26368;&#20248;&#27169;&#22411;&#30340;&#39044;&#26399;&#20934;&#30830;&#24615;&#19982;&#26368;&#32456;&#36873;&#25321;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;UCB-E&#22312;&#38543;&#26426;&#26080;&#31351;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#30340;&#30452;&#25509;&#25512;&#24191;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#22522;&#26412;&#20551;&#35774;&#19979;&#65292;&#26399;&#26395;&#36951;&#25022;&#30340;&#39034;&#24207;&#26159;$T^{-\alpha}$&#65292;&#20854;&#20013;$\alpha \in (0,1/5)$&#65292;$T$&#26159;&#35201;&#20998;&#37197;&#30340;&#36164;&#28304;&#25968;&#37327;&#12290;&#20174;&#36825;&#20010;&#22522;&#26412;&#31639;&#27861;&#20986;&#21457;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;Mutant-UCB&#65292;&#23427;&#32467;&#21512;&#20102;&#36827;&#21270;&#31639;&#27861;&#30340;&#25805;&#20316;&#31526;&#12290;&#22312;&#19977;&#20010;&#24320;&#28304;&#22270;&#29255;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#27979;&#35797;&#34920;&#26126;&#20102;&#36825;&#31181;&#26032;&#39062;&#30340;&#32452;&#21512;&#26041;&#27861;&#30340;&#30456;&#20851;&#24615;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#22266;&#23450;&#39044;&#31639;&#19979;&#30340;&#22269;&#38469;&#39046;&#20808;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper formulates model selection as an infinite-armed bandit problem. The models are arms, and picking an arm corresponds to a partial training of the model (resource allocation). The reward is the accuracy of the selected model after its partial training. In this best arm identification problem, regret is the gap between the expected accuracy of the optimal model and that of the model finally chosen. We first consider a straightforward generalization of UCB-E to the stochastic infinite-armed bandit problem and show that, under basic assumptions, the expected regret order is $T^{-\alpha}$ for some $\alpha \in (0,1/5)$ and $T$ the number of resources to allocate. From this vanilla algorithm, we introduce the algorithm Mutant-UCB that incorporates operators from evolutionary algorithms. Tests carried out on three open source image classification data sets attest to the relevance of this novel combining approach, which outperforms the state-of-the-art for a fixed budget.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31215;&#26497;&#25233;&#21046;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#65292;&#36825;&#23545;&#20110;&#25552;&#39640;&#24615;&#33021;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#21457;&#29616;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#25233;&#21046;&#12290;</title><link>https://arxiv.org/abs/2312.11560</link><description>&lt;p&gt;
&#23398;&#20064;&#33258;&#21457;&#29616;&#65306;&#20851;&#20110;&#31215;&#26497;&#25233;&#21046;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Learning from Emergence: A Study on Proactively Inhibiting the Monosemantic Neurons of Artificial Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31215;&#26497;&#25233;&#21046;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#65292;&#36825;&#23545;&#20110;&#25552;&#39640;&#24615;&#33021;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#21457;&#29616;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#25233;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25104;&#21151;&#65292;&#33258;&#21457;&#29616;&#21463;&#21040;&#20102;&#30740;&#31350;&#30028;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#19982;&#29616;&#26377;&#25991;&#29486;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#30340;&#20551;&#35774;&#65292;&#21363;&#22312;&#35268;&#27169;&#25193;&#22823;&#30340;&#36807;&#31243;&#20013;&#39640;&#24230;&#20419;&#36827;&#24615;&#33021;&#30340;&#22240;&#32032;&#65306;&#20943;&#23569;&#21482;&#33021;&#19982;&#29305;&#23450;&#29305;&#24449;&#24418;&#25104;&#19968;&#23545;&#19968;&#20851;&#31995;&#30340;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#12290;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#24448;&#24448;&#26356;&#31232;&#30095;&#65292;&#24182;&#23545;&#22823;&#22411;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#21463;&#21040;&#36825;&#19968;&#35266;&#28857;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#24605;&#36335;&#26469;&#35782;&#21035;&#21644;&#25233;&#21046;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#12290;&#28982;&#32780;&#65292;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#26159;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#27809;&#26377;&#32479;&#19968;&#30340;&#23450;&#37327;&#35780;&#20272;&#25351;&#26631;&#65292;&#31616;&#21333;&#22320;&#31105;&#27490;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#24182;&#19981;&#33021;&#20419;&#36827;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#24847;&#24605;&#24615;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#33258;&#21457;&#29616;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#24320;&#20102;&#20851;&#20110;&#31215;&#26497;&#25233;&#21046;&#21333;&#24847;&#20041;&#31070;&#32463;&#20803;&#30340;&#30740;&#31350;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.11560v2 Announce Type: replace-cross  Abstract: Recently, emergence has received widespread attention from the research community along with the success of large language models. Different from the literature, we hypothesize a key factor that highly promotes the performance during the increase of scale: the reduction of monosemantic neurons that can only form one-to-one correlations with specific features. Monosemantic neurons tend to be sparser and have negative impacts on the performance in large models. Inspired by this insight, we propose an intuitive idea to identify monosemantic neurons and inhibit them. However, achieving this goal is a non-trivial task as there is no unified quantitative evaluation metric and simply banning monosemantic neurons does not promote polysemanticity in neural networks. Therefore, we propose to learn from emergence and present a study on proactively inhibiting the monosemantic neurons in this paper. More specifically, we first propose a new
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#20855;&#26377;&#39640;&#31232;&#30095;&#24230;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#36825;&#19982;&#29983;&#29289;&#23398;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#30456;&#20284;&#12290;</title><link>http://arxiv.org/abs/2305.18353</link><description>&lt;p&gt;
Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20013;&#30340;&#31361;&#29616;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
Emergent representations in networks trained with the Forward-Forward algorithm. (arXiv:2305.18353v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18353
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#20855;&#26377;&#39640;&#31232;&#30095;&#24230;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#36825;&#19982;&#29983;&#29289;&#23398;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#30456;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Backpropagation&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#20294;&#20854;&#32570;&#20047;&#29983;&#29289;&#23398;&#19978;&#30340;&#29616;&#23454;&#24615;&#12290;&#20026;&#20102;&#23547;&#25214;&#19968;&#31181;&#26356;&#20855;&#29983;&#29289;&#23398;&#21487;&#34892;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#24182;&#36991;&#20813;&#21453;&#21521;&#20256;&#25773;&#26799;&#24230;&#65292;&#32780;&#26159;&#20351;&#29992;&#26412;&#22320;&#23398;&#20064;&#35268;&#21017;&#65292;&#26368;&#36817;&#20171;&#32461;&#30340;Forward-Forward&#31639;&#27861;&#23558;Backpropagation&#30340;&#20256;&#36882;&#26367;&#25442;&#20026;&#20004;&#20010;&#21069;&#21521;&#20256;&#36882;&#12290;&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#33719;&#24471;&#30340;&#20869;&#37096;&#34920;&#24449;&#32452;&#32455;&#20026;&#31283;&#20581;&#30340;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#30001;&#26497;&#23569;&#37327;&#30340;&#26377;&#25928;&#21333;&#20803;(&#39640;&#31232;&#30095;&#24230;)&#32452;&#25104;&#12290;&#36825;&#19982;&#24863;&#35273;&#22788;&#29702;&#36807;&#31243;&#20013;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#38750;&#24120;&#30456;&#20284;&#12290;&#34429;&#28982;&#22312;&#20351;&#29992;&#26631;&#20934;Backpropagation&#36827;&#34892;&#35757;&#32451;&#30340;&#27169;&#22411;&#20013;&#27809;&#26377;&#21457;&#29616;&#65292;&#20294;&#26159;&#22312;&#20351;&#29992;&#19982;Forward-Forward&#30456;&#21516;&#30340;&#35757;&#32451;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#30340;&#32593;&#32476;&#20013;&#20063;&#20986;&#29616;&#20102;&#31232;&#30095;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;Forward-Forward&#25552;&#35758;&#30340;&#23398;&#20064;&#36807;&#31243;&#21487;&#33021;&#26356;&#25509;&#36817;&#29983;&#29289;&#23398;&#23398;&#20064;&#30340;&#29616;&#23454;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Backpropagation algorithm, widely used to train neural networks, has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, and avoid to back-propagate gradients in favour of using local learning rules, the recently introduced Forward-Forward algorithm replaces the traditional forward and backward passes of Backpropagation with two forward passes. In this work, we show that internal representations obtained with the Forward-Forward algorithm organize into robust, category-specific ensembles, composed by an extremely low number of active units (high sparsity). This is remarkably similar to what is observed in cortical representations during sensory processing. While not found in models trained with standard Backpropagation, sparsity emerges also in networks optimized by Backpropagation, on the same training objective of Forward-Forward. These results suggest that the learning procedure proposed by Forward-Forward ma
&lt;/p&gt;</description></item></channel></rss>