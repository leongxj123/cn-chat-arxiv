<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#22240;&#24341;&#23548;GFlowNet (Genetic GFN) &#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#36845;&#20195;&#36951;&#20256;&#25628;&#32034;&#21644;&#35757;&#32451;&#31574;&#30053;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#20998;&#23376;&#20248;&#21270;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;16.213&#30340;&#26368;&#26032;&#24471;&#20998;&#65292;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26368;&#20339;&#24471;&#20998;15.185&#65292;&#21516;&#26102;&#22312;14&#20010;&#20219;&#21153;&#20013;&#36229;&#36234;&#20102;&#25152;&#26377;&#23545;&#27604;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.05961</link><description>&lt;p&gt;
&#22522;&#22240;&#24341;&#23548;GFlowNets&#65306;&#22312;&#23454;&#38469;&#20998;&#23376;&#20248;&#21270;&#22522;&#20934;&#26041;&#38754;&#30340;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Genetic-guided GFlowNets: Advancing in Practical Molecular Optimization Benchmark
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#22240;&#24341;&#23548;GFlowNet (Genetic GFN) &#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#36845;&#20195;&#36951;&#20256;&#25628;&#32034;&#21644;&#35757;&#32451;&#31574;&#30053;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#20998;&#23376;&#20248;&#21270;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;16.213&#30340;&#26368;&#26032;&#24471;&#20998;&#65292;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26368;&#20339;&#24471;&#20998;15.185&#65292;&#21516;&#26102;&#22312;14&#20010;&#20219;&#21153;&#20013;&#36229;&#36234;&#20102;&#25152;&#26377;&#23545;&#27604;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;GFlowNet&#21464;&#20307;&#65292;&#21363;&#22522;&#22240;&#24341;&#23548;GFlowNet (Genetic GFN)&#65292;&#23427;&#23558;&#36845;&#20195;&#36951;&#20256;&#25628;&#32034;&#38598;&#25104;&#21040;GFlowNet&#20013;&#12290;&#36951;&#20256;&#25628;&#32034;&#26377;&#25928;&#22320;&#24341;&#23548;GFlowNet&#36827;&#20837;&#39640;&#22238;&#25253;&#21306;&#22495;&#65292;&#35299;&#20915;&#20102;&#20840;&#23616;&#36807;&#24230;&#25506;&#32034;&#23548;&#33268;&#30340;&#35757;&#32451;&#25928;&#29575;&#20302;&#19979;&#21644;&#25506;&#32034;&#26377;&#38480;&#21306;&#22495;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36824;&#24341;&#20837;&#20102;&#35757;&#32451;&#31574;&#30053;&#65292;&#22914;&#22522;&#20110;&#25490;&#21517;&#30340;&#37325;&#25918;&#35757;&#32451;&#21644;&#26080;&#30417;&#30563;&#26368;&#22823;&#20284;&#28982;&#39044;&#35757;&#32451;&#65292;&#20197;&#25552;&#39640;&#22522;&#22240;&#24341;&#23548;GFlowNet&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#20998;&#23376;&#20248;&#21270; (PMO) &#39046;&#22495;&#30340;&#23448;&#26041;&#22522;&#20934;&#27979;&#35797;&#20013;&#26174;&#31034;&#20102;16.213&#30340;&#26368;&#26032;&#24471;&#20998;&#65292;&#26126;&#26174;&#20248;&#20110;&#22522;&#20934;&#27979;&#35797;&#20013;&#25253;&#21578;&#30340;&#26368;&#20339;&#24471;&#20998;15.185&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;23&#20010;&#20219;&#21153;&#20013;&#30340;14&#20010;&#20219;&#21153;&#20013;&#36229;&#36807;&#20102;&#25152;&#26377;&#23545;&#27604;&#26041;&#27861;&#65292;&#21253;&#25324;&#24378;&#21270;&#23398;&#20064;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#29983;&#25104;&#27169;&#22411;&#65292;GFlowNets&#21644;&#36951;&#20256;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel variant of GFlowNet, genetic-guided GFlowNet (Genetic GFN), which integrates an iterative genetic search into GFlowNet. Genetic search effectively guides the GFlowNet to high-rewarded regions, addressing global over-exploration that results in training inefficiency and exploring limited regions. In addition, training strategies, such as rank-based replay training and unsupervised maximum likelihood pre-training, are further introduced to improve the sample efficiency of Genetic GFN. The proposed method shows a state-of-the-art score of 16.213, significantly outperforming the reported best score in the benchmark of 15.185, in practical molecular optimization (PMO), which is an official benchmark for sample-efficient molecular optimization. Remarkably, ours exceeds all baselines, including reinforcement learning, Bayesian optimization, generative models, GFlowNets, and genetic algorithms, in 14 out of 23 tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19603</link><description>&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21487;&#20197;&#36827;&#34892;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman Filters Can Filter. (arXiv:2310.19603v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#26159;&#19968;&#31867;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#24207;&#21015;&#25968;&#25454;&#20013;&#29983;&#25104;&#39640;&#26031;&#27010;&#29575;&#27979;&#24230;&#12290;&#34429;&#28982;DKFs&#21463;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#21551;&#21457;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#19982;&#38543;&#26426;&#28388;&#27874;&#38382;&#39064;&#30340;&#20855;&#20307;&#29702;&#35770;&#20851;&#32852;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#20538;&#21048;&#21644;&#26399;&#26435;&#23450;&#20215;&#27169;&#22411;&#26657;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;DKFs&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#25968;&#23398;&#22522;&#30784;&#20013;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#32467;&#26524;&#22312;&#36335;&#24452;&#30340;&#36275;&#22815;&#35268;&#21017;&#30340;&#32039;&#33268;&#23376;&#38598;&#19978;&#19968;&#33268;&#25104;&#31435;&#65292;&#20854;&#20013;&#36817;&#20284;&#35823;&#24046;&#30001;&#22312;&#32473;&#23450;&#32039;&#33268;&#36335;&#24452;&#38598;&#19978;&#22343;&#19968;&#22320;&#35745;&#31639;&#30340;&#26368;&#22351;&#24773;&#20917;2-Wasserstein&#36317;&#31163;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman filters (DKFs) are a class of neural network models that generate Gaussian probability measures from sequential data. Though DKFs are inspired by the Kalman filter, they lack concrete theoretical ties to the stochastic filtering problem, thus limiting their applicability to areas where traditional model-based filters have been used, e.g.\ model calibration for bond and option prices in mathematical finance. We address this issue in the mathematical foundations of deep learning by exhibiting a class of continuous-time DKFs which can approximately implement the conditional law of a broad class of non-Markovian and conditionally Gaussian signal processes given noisy continuous-times measurements. Our approximation results hold uniformly over sufficiently regular compact subsets of paths, where the approximation error is quantified by the worst-case 2-Wasserstein distance computed uniformly over the given compact set of paths.
&lt;/p&gt;</description></item></channel></rss>