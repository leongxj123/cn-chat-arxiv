<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#31471;&#21040;&#31471;&#22320;&#24378;&#21270;&#23398;&#20064;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#21644;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#33719;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2402.17423</link><description>&lt;p&gt;
&#21152;&#24378;&#19978;&#19979;&#25991;&#40657;&#30418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Reinforced In-Context Black-Box Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17423
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#31471;&#21040;&#31471;&#22320;&#24378;&#21270;&#23398;&#20064;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#21644;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#33719;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40657;&#30418;&#20248;&#21270;&#65288;BBO&#65289;&#24050;&#32463;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#25104;&#21151;&#24212;&#29992;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#20803;&#23398;&#20064;BBO&#31639;&#27861;&#30340;&#29305;&#23450;&#32452;&#20214;&#65292;&#20197;&#21152;&#24555;&#20248;&#21270;&#36895;&#24230;&#24182;&#25670;&#33073;&#32321;&#29712;&#30340;&#25163;&#24037;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#20316;&#20026;&#25193;&#23637;&#65292;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#25972;&#20010;&#31639;&#27861;&#38656;&#35201;&#19987;&#23478;&#26368;&#23569;&#30340;&#24037;&#20316;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#25552;&#20379;&#26368;&#22823;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RIBBO&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#24378;&#21270;&#23398;&#20064;BBO&#31639;&#27861;&#12290;RIBBO&#21033;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#26469;&#23398;&#20064;&#22810;&#20010;&#34892;&#20026;&#31639;&#27861;&#21644;&#20219;&#21153;&#20135;&#29983;&#30340;&#20248;&#21270;&#21382;&#21490;&#65292;&#21033;&#29992;&#22823;&#22411;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#26469;&#25552;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#30456;&#24212;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#22686;&#21152;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#22686;&#24378;&#20248;&#21270;&#21382;&#21490;&#65292;&#36825;&#20123;&#20196;&#29260;&#26088;&#22312;&#22522;&#20110;&#32047;&#31215;&#34920;&#29616;&#26469;&#34920;&#31034;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17423v1 Announce Type: cross  Abstract: Black-Box Optimization (BBO) has found successful applications in many fields of science and engineering. Recently, there has been a growing interest in meta-learning particular components of BBO algorithms to speed up optimization and get rid of tedious hand-crafted heuristics. As an extension, learning the entire algorithm from data requires the least labor from experts and can provide the most flexibility. In this paper, we propose RIBBO, a method to reinforce-learn a BBO algorithm from offline data in an end-to-end fashion. RIBBO employs expressive sequence models to learn the optimization histories produced by multiple behavior algorithms and tasks, leveraging the in-context learning ability of large models to extract task information and make decisions accordingly. Central to our method is to augment the optimization histories with regret-to-go tokens, which are designed to represent the performance of an algorithm based on cumul
&lt;/p&gt;</description></item></channel></rss>