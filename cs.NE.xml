<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#20855;&#26377;&#39640;&#31232;&#30095;&#24230;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#36825;&#19982;&#29983;&#29289;&#23398;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#30456;&#20284;&#12290;</title><link>http://arxiv.org/abs/2305.18353</link><description>&lt;p&gt;
Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20013;&#30340;&#31361;&#29616;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
Emergent representations in networks trained with the Forward-Forward algorithm. (arXiv:2305.18353v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18353
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#20855;&#26377;&#39640;&#31232;&#30095;&#24230;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#36825;&#19982;&#29983;&#29289;&#23398;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#30456;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Backpropagation&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#20294;&#20854;&#32570;&#20047;&#29983;&#29289;&#23398;&#19978;&#30340;&#29616;&#23454;&#24615;&#12290;&#20026;&#20102;&#23547;&#25214;&#19968;&#31181;&#26356;&#20855;&#29983;&#29289;&#23398;&#21487;&#34892;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#24182;&#36991;&#20813;&#21453;&#21521;&#20256;&#25773;&#26799;&#24230;&#65292;&#32780;&#26159;&#20351;&#29992;&#26412;&#22320;&#23398;&#20064;&#35268;&#21017;&#65292;&#26368;&#36817;&#20171;&#32461;&#30340;Forward-Forward&#31639;&#27861;&#23558;Backpropagation&#30340;&#20256;&#36882;&#26367;&#25442;&#20026;&#20004;&#20010;&#21069;&#21521;&#20256;&#36882;&#12290;&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#33719;&#24471;&#30340;&#20869;&#37096;&#34920;&#24449;&#32452;&#32455;&#20026;&#31283;&#20581;&#30340;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#30001;&#26497;&#23569;&#37327;&#30340;&#26377;&#25928;&#21333;&#20803;(&#39640;&#31232;&#30095;&#24230;)&#32452;&#25104;&#12290;&#36825;&#19982;&#24863;&#35273;&#22788;&#29702;&#36807;&#31243;&#20013;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#38750;&#24120;&#30456;&#20284;&#12290;&#34429;&#28982;&#22312;&#20351;&#29992;&#26631;&#20934;Backpropagation&#36827;&#34892;&#35757;&#32451;&#30340;&#27169;&#22411;&#20013;&#27809;&#26377;&#21457;&#29616;&#65292;&#20294;&#26159;&#22312;&#20351;&#29992;&#19982;Forward-Forward&#30456;&#21516;&#30340;&#35757;&#32451;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#30340;&#32593;&#32476;&#20013;&#20063;&#20986;&#29616;&#20102;&#31232;&#30095;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;Forward-Forward&#25552;&#35758;&#30340;&#23398;&#20064;&#36807;&#31243;&#21487;&#33021;&#26356;&#25509;&#36817;&#29983;&#29289;&#23398;&#23398;&#20064;&#30340;&#29616;&#23454;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Backpropagation algorithm, widely used to train neural networks, has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, and avoid to back-propagate gradients in favour of using local learning rules, the recently introduced Forward-Forward algorithm replaces the traditional forward and backward passes of Backpropagation with two forward passes. In this work, we show that internal representations obtained with the Forward-Forward algorithm organize into robust, category-specific ensembles, composed by an extremely low number of active units (high sparsity). This is remarkably similar to what is observed in cortical representations during sensory processing. While not found in models trained with standard Backpropagation, sparsity emerges also in networks optimized by Backpropagation, on the same training objective of Forward-Forward. These results suggest that the learning procedure proposed by Forward-Forward ma
&lt;/p&gt;</description></item></channel></rss>