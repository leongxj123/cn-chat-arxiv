<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12053</link><description>&lt;p&gt;
&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Layer-wise Feedback Propagation. (arXiv:2308.12053v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#20307;&#32780;&#35328;&#26159;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#35299;&#20915;&#32473;&#23450;&#20219;&#21153;&#30340;&#36129;&#29486;&#29420;&#31435;&#20998;&#37197;&#22870;&#21169;&#12290;&#36825;&#19982;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#19981;&#21516;&#65292;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26159;&#26397;&#21521;&#20272;&#35745;&#30340;&#25439;&#22833;&#26368;&#23567;&#20540;&#26356;&#26032;&#21442;&#25968;&#12290;LFP&#22312;&#27169;&#22411;&#20013;&#20256;&#25773;&#22870;&#21169;&#20449;&#21495;&#65292;&#32780;&#26080;&#38656;&#26799;&#24230;&#35745;&#31639;&#12290;&#23427;&#22686;&#24378;&#25509;&#25910;&#21040;&#27491;&#21453;&#39304;&#30340;&#32467;&#26500;&#65292;&#21516;&#26102;&#38477;&#20302;&#25509;&#25910;&#21040;&#36127;&#21453;&#39304;&#30340;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#30340;&#35282;&#24230;&#35777;&#26126;&#20102;LFP&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;LFP&#20811;&#26381;&#20102;&#26799;&#24230;&#26041;&#27861;&#30340;&#26576;&#20123;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#23545;&#26377;&#24847;&#20041;&#30340;&#23548;&#25968;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;LFP&#22914;&#20309;&#35299;&#20915;&#26799;&#24230;&#26041;&#27861;&#30456;&#20851;&#38382;&#39064;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present Layer-wise Feedback Propagation (LFP), a novel training approach for neural-network-like predictors that utilizes explainability, specifically Layer-wise Relevance Propagation(LRP), to assign rewards to individual connections based on their respective contributions to solving a given task. This differs from traditional gradient descent, which updates parameters towards anestimated loss minimum. LFP distributes a reward signal throughout the model without the need for gradient computations. It then strengthens structures that receive positive feedback while reducingthe influence of structures that receive negative feedback. We establish the convergence of LFP theoretically and empirically, and demonstrate its effectiveness in achieving comparable performance to gradient descent on various models and datasets. Notably, LFP overcomes certain limitations associated with gradient-based methods, such as reliance on meaningful derivatives. We further investigate how 
&lt;/p&gt;</description></item></channel></rss>