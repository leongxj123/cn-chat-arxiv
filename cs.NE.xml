<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#37325;&#32622;&#26368;&#21518;&#19968;&#23618;&#26435;&#37325;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;"zapping"&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#25345;&#32493;&#21644;&#36801;&#31227;&#23398;&#20064;&#25928;&#26524;&#65292;&#21516;&#26102;&#20855;&#22791;&#31616;&#21333;&#23454;&#26045;&#21644;&#39640;&#25928;&#35745;&#31639;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.07996</link><description>&lt;p&gt;
&#37325;&#32622;&#24182;&#24536;&#21364;&#65306;&#37325;&#26032;&#23398;&#20064;&#26368;&#21518;&#19968;&#23618;&#26435;&#37325;&#25913;&#21892;&#25345;&#32493;&#21644;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reset It and Forget It: Relearning Last-Layer Weights Improves Continual and Transfer Learning. (arXiv:2310.07996v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07996
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#37325;&#32622;&#26368;&#21518;&#19968;&#23618;&#26435;&#37325;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;"zapping"&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#25345;&#32493;&#21644;&#36801;&#31227;&#23398;&#20064;&#25928;&#26524;&#65292;&#21516;&#26102;&#20855;&#22791;&#31616;&#21333;&#23454;&#26045;&#21644;&#39640;&#25928;&#35745;&#31639;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#39044;&#35757;&#32451;&#26426;&#21046;&#65292;&#33021;&#22815;&#23548;&#33268;&#20855;&#26377;&#26356;&#22909;&#30340;&#25345;&#32493;&#21644;&#36801;&#31227;&#23398;&#20064;&#34920;&#24449;&#12290;&#36825;&#31181;&#26426;&#21046;&#8212;&#8212;&#22312;&#26368;&#21518;&#19968;&#23618;&#26435;&#37325;&#20013;&#21453;&#22797;&#37325;&#32622;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;zapping&#8221;&#8212;&#8212;&#26368;&#21021;&#35774;&#35745;&#29992;&#20110;&#20803;&#25345;&#32493;&#23398;&#20064;&#36807;&#31243;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#23427;&#22312;&#35768;&#22810;&#19981;&#21516;&#20110;&#20803;&#23398;&#20064;&#21644;&#25345;&#32493;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#20063;&#38750;&#24120;&#36866;&#29992;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#23558;&#39044;&#35757;&#32451;&#30340;&#22270;&#20687;&#20998;&#31867;&#22120;&#36801;&#31227;&#21040;&#19968;&#32452;&#26032;&#30340;&#31867;&#21035;&#65292;&#20165;&#20351;&#29992;&#23569;&#37327;&#26679;&#26412;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;zapping&#36807;&#31243;&#22312;&#26631;&#20934;&#24494;&#35843;&#21644;&#25345;&#32493;&#23398;&#20064;&#35774;&#32622;&#20013;&#33021;&#22815;&#33719;&#24471;&#26356;&#22909;&#30340;&#36801;&#31227;&#20934;&#30830;&#24615;&#21644;/&#25110;&#26356;&#24555;&#30340;&#36866;&#24212;&#24615;&#65292;&#21516;&#26102;&#23454;&#29616;&#31616;&#21333;&#30340;&#23454;&#26045;&#21644;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20351;&#29992;zapping&#21644;&#39034;&#24207;&#23398;&#20064;&#30340;&#32452;&#21512;&#65292;&#25105;&#20204;&#21487;&#20197;&#36798;&#21040;&#19982;&#26368;&#20808;&#36827;&#30340;&#20803;&#23398;&#20064;&#30456;&#24403;&#30340;&#24615;&#33021;&#32780;&#26080;&#38656;&#26114;&#36149;&#30340;&#39640;&#38454;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work identifies a simple pre-training mechanism that leads to representations exhibiting better continual and transfer learning. This mechanism -- the repeated resetting of weights in the last layer, which we nickname "zapping" -- was originally designed for a meta-continual-learning procedure, yet we show it is surprisingly applicable in many settings beyond both meta-learning and continual learning. In our experiments, we wish to transfer a pre-trained image classifier to a new set of classes, in a few shots. We show that our zapping procedure results in improved transfer accuracy and/or more rapid adaptation in both standard fine-tuning and continual learning settings, while being simple to implement and computationally efficient. In many cases, we achieve performance on par with state of the art meta-learning without needing the expensive higher-order gradients, by using a combination of zapping and sequential learning. An intuitive explanation for the effectiveness of this za
&lt;/p&gt;</description></item></channel></rss>