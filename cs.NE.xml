<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#31995;&#32479;&#30740;&#31350;&#25581;&#31034;&#20102;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#20013;&#28388;&#27844;&#12289;&#37325;&#32622;&#21644;&#24490;&#29615;&#31561;&#24314;&#27169;&#32452;&#20214;&#22312;&#24179;&#34913;&#35760;&#24518;&#20445;&#30041;&#12289;&#26102;&#38388;&#22788;&#29702;&#21644;&#21160;&#24577;&#24314;&#27169;&#26041;&#38754;&#30340;&#21151;&#33021;&#35282;&#33394;&#12290;</title><link>https://arxiv.org/abs/2403.16674</link><description>&lt;p&gt;
&#29702;&#35299;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#20013;&#24314;&#27169;&#32452;&#20214;&#30340;&#21151;&#33021;&#35282;&#33394;
&lt;/p&gt;
&lt;p&gt;
Understanding the Functional Roles of Modelling Components in Spiking Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16674
&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#30740;&#31350;&#25581;&#31034;&#20102;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#20013;&#28388;&#27844;&#12289;&#37325;&#32622;&#21644;&#24490;&#29615;&#31561;&#24314;&#27169;&#32452;&#20214;&#22312;&#24179;&#34913;&#35760;&#24518;&#20445;&#30041;&#12289;&#26102;&#38388;&#22788;&#29702;&#21644;&#21160;&#24577;&#24314;&#27169;&#26041;&#38754;&#30340;&#21151;&#33021;&#35282;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#22823;&#33041;&#31070;&#32463;&#22238;&#36335;&#21551;&#21457;&#65292;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#22312;&#23454;&#29616;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#29983;&#29289;&#20445;&#30495;&#24230;&#26041;&#38754;&#24456;&#26377;&#21069;&#26223;&#12290;&#28982;&#32780;&#65292;&#20248;&#21270;SNNs&#30456;&#24403;&#22256;&#38590;&#65292;&#22240;&#20026;&#20854;&#24314;&#27169;&#32452;&#20214;&#30340;&#21151;&#33021;&#35282;&#33394;&#20173;&#19981;&#28165;&#26970;&#12290;&#36890;&#36807;&#35774;&#35745;&#21644;&#35780;&#20272;&#32463;&#20856;&#27169;&#22411;&#30340;&#20960;&#20010;&#21464;&#20307;&#65292;&#25105;&#20204;&#31995;&#32479;&#30740;&#31350;&#20102;&#28388;&#27844;&#12289;&#37325;&#32622;&#21644;&#24490;&#29615;&#36825;&#20123;&#20851;&#38190;&#24314;&#27169;&#32452;&#20214;&#22312;&#22522;&#20110;&#28431;&#31215;&#20998;&#25918;&#30005;&#65288;LIF&#65289;&#30340;SNNs&#20013;&#30340;&#21151;&#33021;&#35282;&#33394;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#20123;&#32452;&#20214;&#22914;&#20309;&#24433;&#21709;SNNs&#30340;&#20934;&#30830;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#28388;&#27844;&#22312;&#24179;&#34913;&#35760;&#24518;&#20445;&#30041;&#21644;&#31283;&#20581;&#24615;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#37325;&#32622;&#26426;&#21046;&#23545;&#20110;&#19981;&#38388;&#26029;&#30340;&#26102;&#38388;&#22788;&#29702;&#21644;&#35745;&#31639;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#24490;&#29615;&#21017;&#20016;&#23500;&#20102;&#27169;&#22411;&#22797;&#26434;&#21160;&#24577;&#30340;&#33021;&#21147;&#65292;&#20294;&#20250;&#25439;&#23475;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16674v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs), inspired by the neural circuits of the brain, are promising in achieving high computational efficiency with biological fidelity. Nevertheless, it is quite difficult to optimize SNNs because the functional roles of their modelling components remain unclear. By designing and evaluating several variants of the classic model, we systematically investigate the functional roles of key modelling components, leakage, reset, and recurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive experiments, we demonstrate how these components influence the accuracy, generalization, and robustness of SNNs. Specifically, we find that the leakage plays a crucial role in balancing memory retention and robustness, the reset mechanism is essential for uninterrupted temporal processing and computational efficiency, and the recurrence enriches the capability to model complex dynamics at a cost of robustness degr
&lt;/p&gt;</description></item></channel></rss>