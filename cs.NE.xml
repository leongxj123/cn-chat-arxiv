<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25293;&#21334;&#35774;&#35745;&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#19981;&#21516;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;</title><link>http://arxiv.org/abs/2305.11005</link><description>&lt;p&gt;
&#25293;&#21334;&#35774;&#35745;&#20013;&#30340;&#27169;&#24335;&#36830;&#36890;&#24615;
&lt;/p&gt;
&lt;p&gt;
Mode Connectivity in Auction Design. (arXiv:2305.11005v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11005
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25293;&#21334;&#35774;&#35745;&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#19981;&#21516;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#26159;&#31639;&#27861;&#21338;&#24328;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#38750;&#24120;&#31616;&#21333;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#38382;&#39064;&#20063;&#24456;&#38590;&#12290;&#26368;&#36817;&#19981;&#21516;&#30340;&#32463;&#27982;&#23398;&#21487;&#24494;&#20998;&#29702;&#35770;&#34920;&#26126;&#65292;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#24050;&#30693;&#30340;&#26368;&#20248;&#25293;&#21334;&#26426;&#21046;&#65292;&#21457;&#29616;&#26377;&#36259;&#30340;&#26032;&#26426;&#21046;&#12290;&#20026;&#20102;&#29702;&#35770;&#19978;&#35777;&#26126;&#23427;&#20204;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;RochetNet&#65292;&#24182;&#30740;&#31350;&#25152;&#35859;&#30340;&#20223;&#23556;&#26497;&#22823;&#21270;&#25293;&#21334;&#30340;&#24191;&#20041;&#29256;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#23427;&#20204;&#28385;&#36275;&#27169;&#24335;&#36830;&#36890;&#24615;&#65292;&#21363;&#23616;&#37096;&#26368;&#20248;&#35299;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#65292;&#36335;&#24452;&#19978;&#30340;&#27599;&#20010;&#35299;&#37117;&#20960;&#20046;&#21644;&#20004;&#20010;&#23616;&#37096;&#26368;&#20248;&#35299;&#20043;&#19968;&#19968;&#26679;&#22909;&#12290;&#27169;&#24335;&#36830;&#36890;&#24615;&#26368;&#36817;&#34987;&#35777;&#26126;&#26159;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#39044;&#27979;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#36259;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#23545;&#21487;&#24494;&#20998;&#32463;&#27982;&#23398;&#39046;&#22495;&#20013;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#35774;&#35745;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal auction design is a fundamental problem in algorithmic game theory. This problem is notoriously difficult already in very simple settings. Recent work in differentiable economics showed that neural networks can efficiently learn known optimal auction mechanisms and discover interesting new ones. In an attempt to theoretically justify their empirical success, we focus on one of the first such networks, RochetNet, and a generalized version for affine maximizer auctions. We prove that they satisfy mode connectivity, i.e., locally optimal solutions are connected by a simple, piecewise linear path such that every solution on the path is almost as good as one of the two local optima. Mode connectivity has been recently investigated as an intriguing empirical and theoretically justifiable property of neural networks used for prediction problems. Our results give the first such analysis in the context of differentiable economics, where neural networks are used directly for solving non-
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36816;&#29992;&#25968;&#23398;&#21644;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#23601; ReLU &#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#19979;&#30028;&#20570;&#20102;&#25506;&#31350;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#32943;&#23450;&#20102;&#19968;&#39033;&#26087;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#29468;&#24819;&#12290;</title><link>http://arxiv.org/abs/2105.14835</link><description>&lt;p&gt;
&#20851;&#20110; ReLU &#31070;&#32463;&#32593;&#32476;&#28145;&#24230;&#19979;&#30028;&#30340;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Lower Bounds on the Depth of ReLU Neural Networks. (arXiv:2105.14835v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.14835
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36816;&#29992;&#25968;&#23398;&#21644;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#23601; ReLU &#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#19979;&#30028;&#20570;&#20102;&#25506;&#31350;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#32943;&#23450;&#20102;&#19968;&#39033;&#26087;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#29468;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36816;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#12289;&#22810;&#38754;&#20307;&#29702;&#35770;&#21644;&#28909;&#24102;&#20960;&#20309;&#23398;&#31561;&#25216;&#26415;&#65292;&#20026;&#29702;&#35299;&#20855;&#26377; ReLU &#28608;&#27963;&#21644;&#32473;&#23450;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#20570;&#20986;&#20102;&#26356;&#22909;&#30340;&#36129;&#29486;&#12290;&#23613;&#31649;&#26222;&#36866;&#36924;&#36817;&#23450;&#29702;&#35748;&#20026;&#21333;&#23618;&#38544;&#34255;&#23618;&#23601;&#36275;&#20197;&#23398;&#20064;&#20219;&#20309;&#20989;&#25968;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#23398;&#30340;&#23545;&#31216;&#24615;&#65292;&#24182;&#35814;&#32454;&#25506;&#35752;&#20102;&#28155;&#21152;&#26356;&#22810;&#23618;&#65288;&#26080;&#22823;&#23567;&#38480;&#21046;&#65289;&#26102;&#26159;&#21542;&#20005;&#26684;&#22686;&#21152;&#20102;&#21487;&#34920;&#31034;&#20989;&#25968;&#30340;&#31867;&#12290;&#20316;&#20026;&#30740;&#31350;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#32943;&#23450;&#20102; Wang &#21644; Sun&#65288;2005&#65289;&#26377;&#20851;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#30340;&#19968;&#20010;&#26087;&#29468;&#24819;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#34920;&#31034;&#20855;&#26377;&#23545;&#25968;&#28145;&#24230;&#20989;&#25968;&#25152;&#38656;&#30340;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We contribute to a better understanding of the class of functions that can be represented by a neural network with ReLU activations and a given architecture. Using techniques from mixed-integer optimization, polyhedral theory, and tropical geometry, we provide a mathematical counterbalance to the universal approximation theorems which suggest that a single hidden layer is sufficient for learning any function. In particular, we investigate whether the class of exactly representable functions strictly increases by adding more layers (with no restrictions on size). As a by-product of our investigations, we settle an old conjecture about piecewise linear functions by Wang and Sun (2005) in the affirmative. We also present upper bounds on the sizes of neural networks required to represent functions with logarithmic depth.
&lt;/p&gt;</description></item></channel></rss>