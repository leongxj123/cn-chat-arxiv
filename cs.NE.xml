<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#20132;&#21449;&#36335;&#21475;&#30340;&#20449;&#21495;&#25511;&#21046;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#38454;&#27573;&#32039;&#24613;&#24615;&#27010;&#24565;&#21644;&#21487;&#35299;&#37322;&#30340;&#26641;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#20449;&#21495;&#36716;&#25442;&#26399;&#38388;&#36873;&#25321;&#28608;&#27963;&#30340;&#20449;&#21495;&#30456;&#20301;&#12290;</title><link>https://arxiv.org/abs/2403.17328</link><description>&lt;p&gt;
&#36890;&#36807;&#36951;&#20256;&#32534;&#31243;&#23398;&#20064;&#20132;&#36890;&#20449;&#21495;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Learning Traffic Signal Control via Genetic Programming
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17328
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#20132;&#21449;&#36335;&#21475;&#30340;&#20449;&#21495;&#25511;&#21046;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#38454;&#27573;&#32039;&#24613;&#24615;&#27010;&#24565;&#21644;&#21487;&#35299;&#37322;&#30340;&#26641;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#20449;&#21495;&#36716;&#25442;&#26399;&#38388;&#36873;&#25321;&#28608;&#27963;&#30340;&#20449;&#21495;&#30456;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#20449;&#21495;&#25511;&#21046;&#23545;&#25552;&#39640;&#20132;&#36890;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#65292;&#22312;&#23547;&#27714;&#26356;&#26377;&#25928;&#30340;&#20132;&#36890;&#20449;&#21495;&#25511;&#21046;&#31574;&#30053;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22312;DRL&#20013;&#22870;&#21169;&#30340;&#35774;&#35745;&#39640;&#24230;&#20381;&#36182;&#39046;&#22495;&#30693;&#35782;&#25165;&#33021;&#25910;&#25947;&#21040;&#26377;&#25928;&#31574;&#30053;&#65292;&#32780;&#26368;&#32456;&#31574;&#30053;&#20063;&#23384;&#22312;&#35299;&#37322;&#22256;&#38590;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#22797;&#26434;&#36335;&#21475;&#30340;&#20449;&#21495;&#25511;&#21046;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#20449;&#21495;&#30456;&#35774;&#35745;&#20102;&#19968;&#20010;&#38454;&#27573;&#32039;&#24613;&#24615;&#30340;&#27010;&#24565;&#12290;&#22312;&#20449;&#21495;&#21464;&#25442;&#26399;&#38388;&#65292;&#20132;&#36890;&#28783;&#25511;&#21046;&#31574;&#30053;&#26681;&#25454;&#38454;&#27573;&#32039;&#24613;&#24615;&#36873;&#25321;&#35201;&#28608;&#27963;&#30340;&#19979;&#19968;&#20010;&#30456;&#20301;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#32039;&#24613;&#21151;&#33021;&#34920;&#31034;&#20026;&#21487;&#35299;&#37322;&#30340;&#26641;&#32467;&#26500;&#12290;&#32039;&#24613;&#21151;&#33021;&#21487;&#20197;&#26681;&#25454;&#24403;&#21069;&#36947;&#36335;&#26465;&#20214;&#20026;&#29305;&#23450;&#30456;&#20301;&#35745;&#31639;&#30456;&#20301;&#32039;&#24613;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17328v1 Announce Type: new  Abstract: The control of traffic signals is crucial for improving transportation efficiency. Recently, learning-based methods, especially Deep Reinforcement Learning (DRL), garnered substantial success in the quest for more efficient traffic signal control strategies. However, the design of rewards in DRL highly demands domain knowledge to converge to an effective policy, and the final policy also presents difficulties in terms of explainability. In this work, a new learning-based method for signal control in complex intersections is proposed. In our approach, we design a concept of phase urgency for each signal phase. During signal transitions, the traffic light control strategy selects the next phase to be activated based on the phase urgency. We then proposed to represent the urgency function as an explainable tree structure. The urgency function can calculate the phase urgency for a specific phase based on the current road conditions. Genetic 
&lt;/p&gt;</description></item></channel></rss>