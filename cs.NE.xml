<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>S-TLLR&#26159;&#19968;&#20010;&#21463;&#21040;STDP&#26426;&#21046;&#21551;&#21457;&#30340;&#26102;&#38388;&#23616;&#37096;&#23398;&#20064;&#35268;&#21017;&#65292;&#21487;&#20197;&#29992;&#20110;&#35757;&#32451;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#20102;&#22240;&#26524;&#21644;&#38750;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2306.15220</link><description>&lt;p&gt;
S-TLLR: &#21463;&#21040;&#26102;&#38388;&#23616;&#37096;&#23398;&#20064;&#35268;&#21017;&#30340;STDP&#21551;&#21457;&#30340;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks. (arXiv:2306.15220v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15220
&lt;/p&gt;
&lt;p&gt;
S-TLLR&#26159;&#19968;&#20010;&#21463;&#21040;STDP&#26426;&#21046;&#21551;&#21457;&#30340;&#26102;&#38388;&#23616;&#37096;&#23398;&#20064;&#35268;&#21017;&#65292;&#21487;&#20197;&#29992;&#20110;&#35757;&#32451;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#20102;&#22240;&#26524;&#21644;&#38750;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#26159;&#21487;&#29992;&#20110;&#36793;&#32536;&#26234;&#33021;&#30340;&#29983;&#29289;&#23398;&#21512;&#29702;&#27169;&#22411;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#39034;&#24207;&#23398;&#20064;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;SNN&#30340;&#35757;&#32451;&#38754;&#20020;&#30528;&#31934;&#30830;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#20449;&#29992;&#20998;&#37197;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;BPTT&#31639;&#27861;&#26159;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#65292;&#20294;&#30001;&#20110;&#20854;&#26102;&#38388;&#20381;&#36182;&#24615;&#65292;&#23427;&#20135;&#29983;&#20102;&#36739;&#39640;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;BPTT&#21450;&#20854;&#36817;&#20284;&#20165;&#21033;&#29992;&#20174;&#33033;&#20914;&#27963;&#21160;&#20013;&#23548;&#20986;&#30340;&#22240;&#26524;&#20449;&#24687;&#26469;&#35745;&#31639;&#31361;&#35302;&#26356;&#26032;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#38750;&#22240;&#26524;&#20851;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;S-TLLR&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#21040;Spike-Timing Dependent Plasticity&#65288;STDP&#65289;&#26426;&#21046;&#21551;&#21457;&#30340;&#26032;&#22411;&#19977;&#22240;&#32032;&#26102;&#38388;&#23616;&#37096;&#23398;&#20064;&#35268;&#21017;&#65292;&#26088;&#22312;&#29992;&#20110;&#20107;&#20214;&#39537;&#21160;&#23398;&#20064;&#20219;&#21153;&#30340;SNN&#35757;&#32451;&#12290;S-TLLR&#21516;&#26102;&#32771;&#34385;&#20102;&#21069;&#21518;&#31361;&#35302;&#20043;&#38388;&#30340;&#22240;&#26524;&#21644;&#38750;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spiking Neural Networks (SNNs) are biologically plausible models that have been identified as potentially apt for the deployment for energy-efficient intelligence at the edge, particularly for sequential learning tasks. However, training of SNNs poses a significant challenge due to the necessity for precise temporal and spatial credit assignment. Back-propagation through time (BPTT) algorithm, whilst being the most widely used method for addressing these issues, incurs a high computational cost due to its temporal dependency. Moreover, BPTT and its approximations solely utilize causal information derived from the spiking activity to compute the synaptic updates, thus neglecting non-causal relationships. In this work, we propose S-TLLR, a novel three-factor temporal local learning rule inspired by the Spike-Timing Dependent Plasticity (STDP) mechanism, aimed at training SNNs on event-based learning tasks. S-TLLR considers both causal and non-causal relationships between pre and post-syn
&lt;/p&gt;</description></item></channel></rss>