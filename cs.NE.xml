<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#24615;&#33021;&#26080;&#38656;&#35757;&#32451;&#30340;&#24230;&#37327;SWAP-Score&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#25628;&#32034;&#31354;&#38388;&#21644;&#20219;&#21153;&#20013;&#27979;&#37327;&#32593;&#32476;&#22312;&#19968;&#25209;&#36755;&#20837;&#26679;&#26412;&#19978;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#36827;&#19968;&#27493;&#25552;&#39640;&#30456;&#20851;&#24615;&#65292;&#23454;&#29616;&#27169;&#22411;&#22823;&#23567;&#30340;&#25511;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.04161</link><description>&lt;p&gt;
SWAP-NAS: &#36866;&#29992;&#20110;&#36229;&#24555;&#36895;NAS&#30340;&#26679;&#26412;&#32423;&#28608;&#27963;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
SWAP-NAS: Sample-Wise Activation Patterns For Ultra-Fast NAS
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04161
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#24615;&#33021;&#26080;&#38656;&#35757;&#32451;&#30340;&#24230;&#37327;SWAP-Score&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#25628;&#32034;&#31354;&#38388;&#21644;&#20219;&#21153;&#20013;&#27979;&#37327;&#32593;&#32476;&#22312;&#19968;&#25209;&#36755;&#20837;&#26679;&#26412;&#19978;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#36827;&#19968;&#27493;&#25552;&#39640;&#30456;&#20851;&#24615;&#65292;&#23454;&#29616;&#27169;&#22411;&#22823;&#23567;&#30340;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38656;&#35757;&#32451;&#30340;&#24230;&#37327;&#65288;&#21363;&#38646;&#25104;&#26412;&#20195;&#29702;&#65289;&#34987;&#24191;&#27867;&#29992;&#20110;&#36991;&#20813;&#36164;&#28304;&#23494;&#38598;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#65292;&#23588;&#20854;&#26159;&#22312;&#31070;&#32463;&#32467;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#20013;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;&#26080;&#38656;&#35757;&#32451;&#30340;&#24230;&#37327;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#65292;&#27604;&#22914;&#22312;&#19981;&#21516;&#25628;&#32034;&#31354;&#38388;&#21644;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#26377;&#38480;&#30340;&#20851;&#32852;&#24615;&#21644;&#24046;&#21170;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26679;&#26412;&#32423;&#28608;&#27963;&#27169;&#24335;&#21450;&#20854;&#34893;&#29983;&#29289;SWAP-Score&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#24615;&#33021;&#26080;&#38656;&#35757;&#32451;&#30340;&#24230;&#37327;&#12290;&#23427;&#27979;&#37327;&#20102;&#32593;&#32476;&#22312;&#19968;&#25209;&#36755;&#20837;&#26679;&#26412;&#19978;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;SWAP-Score&#19982;&#19981;&#21516;&#25628;&#32034;&#31354;&#38388;&#21644;&#20219;&#21153;&#20013;&#30340;&#30495;&#23454;&#24615;&#33021;&#24378;&#30456;&#20851;&#65292;&#22312;NAS-Bench-101/201/301&#21644;TransNAS-Bench-101&#19978;&#32988;&#36807;&#20102;15&#31181;&#29616;&#26377;&#30340;&#26080;&#38656;&#35757;&#32451;&#30340;&#24230;&#37327;&#12290;SWAP-Score&#21487;&#20197;&#36890;&#36807;&#27491;&#21017;&#21270;&#36827;&#19968;&#27493;&#22686;&#24378;&#65292;&#36825;&#22312;&#22522;&#20110;&#21333;&#20803;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#21487;&#20197;&#23454;&#29616;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#19988;&#22312;&#25628;&#32034;&#36807;&#31243;&#20013;&#23454;&#29616;&#27169;&#22411;&#22823;&#23567;&#25511;&#21046;&#12290;&#20363;&#22914;&#65292;Spearman&#30340;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04161v1 Announce Type: new  Abstract: Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid resource-intensive neural network training, especially in Neural Architecture Search (NAS). Recent studies show that existing training-free metrics have several limitations, such as limited correlation and poor generalisation across different search spaces and tasks. Hence, we propose Sample-Wise Activation Patterns and its derivative, SWAP-Score, a novel high-performance training-free metric. It measures the expressivity of networks over a batch of input samples. The SWAP-Score is strongly correlated with ground-truth performance across various search spaces and tasks, outperforming 15 existing training-free metrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be further enhanced by regularisation, which leads to even higher correlations in cell-based search space and enables model size control during the search. For example, Spearman's rank
&lt;/p&gt;</description></item><item><title>&#20004;&#31181;&#21333;&#30456;&#23545;&#27604;&#28023;&#27604;&#23433;&#23398;&#20064;&#30340;&#25925;&#20107;&#25506;&#32034;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#29983;&#29289;&#21512;&#29702;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#23616;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#28040;&#38500;&#19982;&#21453;&#21521;&#20256;&#25773;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#35299;&#20915;&#20102;&#21516;&#27493;&#21644;&#26080;&#38480;&#23567;&#25200;&#21160;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.08573</link><description>&lt;p&gt;
&#20004;&#31181;&#21333;&#30456;&#23545;&#27604;&#28023;&#27604;&#23433;&#23398;&#20064;&#30340;&#25925;&#20107;
&lt;/p&gt;
&lt;p&gt;
Two Tales of Single-Phase Contrastive Hebbian Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08573
&lt;/p&gt;
&lt;p&gt;
&#20004;&#31181;&#21333;&#30456;&#23545;&#27604;&#28023;&#27604;&#23433;&#23398;&#20064;&#30340;&#25925;&#20107;&#25506;&#32034;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#29983;&#29289;&#21512;&#29702;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#23616;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#28040;&#38500;&#19982;&#21453;&#21521;&#20256;&#25773;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#35299;&#20915;&#20102;&#21516;&#27493;&#21644;&#26080;&#38480;&#23567;&#25200;&#21160;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#8220;&#29983;&#29289;&#23398;&#19978;&#21512;&#29702;&#8221;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#25506;&#32034;&#24050;&#32463;&#25910;&#25947;&#20110;&#23558;&#26799;&#24230;&#34920;&#31034;&#20026;&#27963;&#21160;&#24046;&#24322;&#30340;&#24819;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#38656;&#35201;&#36739;&#39640;&#31243;&#24230;&#30340;&#21516;&#27493;&#65288;&#23398;&#20064;&#26399;&#38388;&#30340;&#19981;&#21516;&#38454;&#27573;&#65289;&#24182;&#24341;&#20837;&#22823;&#37327;&#30340;&#35745;&#31639;&#24320;&#38144;&#65292;&#36825;&#23545;&#20110;&#23427;&#20204;&#30340;&#29983;&#29289;&#23398;&#21512;&#29702;&#24615;&#20197;&#21450;&#20854;&#22312;&#31070;&#32463;&#24418;&#24577;&#35745;&#31639;&#20013;&#30340;&#28508;&#22312;&#25928;&#29992;&#20135;&#29983;&#20102;&#30097;&#38382;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#36890;&#24120;&#20381;&#36182;&#20110;&#23545;&#36755;&#20986;&#21333;&#20803;&#26045;&#21152;&#26080;&#38480;&#23567;&#25200;&#21160;&#65288;nudges&#65289;&#65292;&#36825;&#22312;&#22024;&#26434;&#29615;&#22659;&#20013;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#26368;&#36817;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#23558;&#20154;&#24037;&#31070;&#32463;&#20803;&#24314;&#27169;&#20026;&#20004;&#20010;&#30456;&#21453;&#25200;&#21160;&#30340;&#32452;&#20214;&#65292;&#21517;&#20026;&#8220;&#21452;&#21521;&#20256;&#25773;&#8221;&#30340;&#20840;&#23616;&#23398;&#20064;&#31639;&#27861;&#33021;&#22815;&#24357;&#21512;&#21040;&#21453;&#21521;&#20256;&#25773;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#32780;&#19981;&#38656;&#35201;&#20998;&#21035;&#30340;&#23398;&#20064;&#38454;&#27573;&#25110;&#26080;&#38480;&#23567;&#25200;&#21160;&#12290;&#28982;&#32780;&#65292;&#35813;&#31639;&#27861;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#20381;&#36182;&#20110;&#23545;&#31216;&#25200;&#21160;&#65292;&#36825;&#21487;&#33021;&#22312;&#29983;&#29289;&#23398;&#19978;&#21463;&#21040;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The search for "biologically plausible" learning algorithms has converged on the idea of representing gradients as activity differences. However, most approaches require a high degree of synchronization (distinct phases during learning) and introduce substantial computational overhead, which raises doubts regarding their biological plausibility as well as their potential utility for neuromorphic computing. Furthermore, they commonly rely on applying infinitesimal perturbations (nudges) to output units, which is impractical in noisy environments. Recently it has been shown that by modelling artificial neurons as dyads with two oppositely nudged compartments, it is possible for a fully local learning algorithm named ``dual propagation'' to bridge the performance gap to backpropagation, without requiring separate learning phases or infinitesimal nudging. However, the algorithm has the drawback that its numerical stability relies on symmetric nudging, which may be restrictive in biological
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25972;&#21512;&#36827;&#21270;&#31639;&#27861;&#19982;&#24378;&#21270;&#23398;&#20064;&#65292;&#36827;&#21270;&#24378;&#21270;&#23398;&#20064;&#65288;ERL&#65289;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#26412;&#32508;&#36848;&#21576;&#29616;&#20102;ERL&#39046;&#22495;&#30340;&#21508;&#20010;&#30740;&#31350;&#20998;&#25903;&#65292;&#31361;&#20986;&#20102;EA&#36741;&#21161;RL&#30340;&#20248;&#21270;&#12289;RL&#36741;&#21161;EA&#30340;&#20248;&#21270;&#20197;&#21450;EA&#21644;RL&#30340;&#21327;&#21516;&#20248;&#21270;&#36825;&#19977;&#20010;&#20027;&#35201;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2401.11963</link><description>&lt;p&gt;
&#36328;&#36234;&#36827;&#21270;&#31639;&#27861;&#21644;&#24378;&#21270;&#23398;&#20064;&#65306;&#19968;&#39033;&#20840;&#38754;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11963
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25972;&#21512;&#36827;&#21270;&#31639;&#27861;&#19982;&#24378;&#21270;&#23398;&#20064;&#65292;&#36827;&#21270;&#24378;&#21270;&#23398;&#20064;&#65288;ERL&#65289;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#26412;&#32508;&#36848;&#21576;&#29616;&#20102;ERL&#39046;&#22495;&#30340;&#21508;&#20010;&#30740;&#31350;&#20998;&#25903;&#65292;&#31361;&#20986;&#20102;EA&#36741;&#21161;RL&#30340;&#20248;&#21270;&#12289;RL&#36741;&#21161;EA&#30340;&#20248;&#21270;&#20197;&#21450;EA&#21644;RL&#30340;&#21327;&#21516;&#20248;&#21270;&#36825;&#19977;&#20010;&#20027;&#35201;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#21270;&#24378;&#21270;&#23398;&#20064;&#65288;ERL&#65289;&#23558;&#36827;&#21270;&#31639;&#27861;&#65288;EAs&#65289;&#21644;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30456;&#32467;&#21512;&#36827;&#34892;&#20248;&#21270;&#65292;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#36890;&#36807;&#34701;&#21512;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;ERL&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#26377;&#21069;&#26223;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26412;&#35843;&#26597;&#32508;&#36848;&#20102;ERL&#20013;&#19981;&#21516;&#30740;&#31350;&#20998;&#25903;&#30340;&#20840;&#38754;&#27010;&#36848;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#31995;&#32479;&#24635;&#32467;&#20102;&#30456;&#20851;&#31639;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#30830;&#23450;&#20102;&#19977;&#20010;&#20027;&#35201;&#30740;&#31350;&#26041;&#21521;&#65306;EA&#36741;&#21161;RL&#30340;&#20248;&#21270;&#65292;RL&#36741;&#21161;EA&#30340;&#20248;&#21270;&#65292;&#20197;&#21450;EA&#21644;RL&#30340;&#21327;&#21516;&#20248;&#21270;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#28145;&#20837;&#20998;&#26512;&#20102;&#27599;&#20010;&#30740;&#31350;&#26041;&#21521;&#65292;&#32452;&#32455;&#20102;&#22810;&#20010;&#30740;&#31350;&#20998;&#25903;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#27599;&#20010;&#20998;&#25903;&#33268;&#21147;&#20110;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;EA&#21644;RL&#30340;&#25972;&#21512;&#22914;&#20309;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#28508;&#22312;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.11963v2 Announce Type: replace-cross  Abstract: Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary Algorithms (EAs) and Reinforcement Learning (RL) for optimization, has demonstrated remarkable performance advancements. By fusing the strengths of both approaches, ERL has emerged as a promising research direction. This survey offers a comprehensive overview of the diverse research branches in ERL. Specifically, we systematically summarize recent advancements in relevant algorithms and identify three primary research directions: EA-assisted optimization of RL, RL-assisted optimization of EA, and synergistic optimization of EA and RL. Following that, we conduct an in-depth analysis of each research direction, organizing multiple research branches. We elucidate the problems that each branch aims to tackle and how the integration of EA and RL addresses these challenges. In conclusion, we discuss potential challenges and prospective future research directions
&lt;/p&gt;</description></item></channel></rss>