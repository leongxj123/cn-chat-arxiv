<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>LEA&#26159;&#19968;&#31181;&#36866;&#24212;&#24615;&#24378;&#19988;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#30446;&#26631;&#20219;&#21153;&#20302;&#20445;&#30495;&#24230;&#20449;&#24687;&#30340;&#23398;&#20064;&#36827;&#21270;&#31639;&#27861;&#65292;&#20174;&#32780;&#27604;&#20256;&#32479;&#36827;&#21270;&#31639;&#27861;&#22312;&#26356;&#23569;&#30340;&#35745;&#31639;&#25104;&#26412;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.09599</link><description>&lt;p&gt;
LEA: &#23398;&#20064;&#20248;&#21270;&#31574;&#30053;&#30340;&#36229;&#36234;&#36827;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
LEA: Beyond Evolutionary Algorithms via Learned Optimization Strategy. (arXiv:2304.09599v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09599
&lt;/p&gt;
&lt;p&gt;
LEA&#26159;&#19968;&#31181;&#36866;&#24212;&#24615;&#24378;&#19988;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#30446;&#26631;&#20219;&#21153;&#20302;&#20445;&#30495;&#24230;&#20449;&#24687;&#30340;&#23398;&#20064;&#36827;&#21270;&#31639;&#27861;&#65292;&#20174;&#32780;&#27604;&#20256;&#32479;&#36827;&#21270;&#31639;&#27861;&#22312;&#26356;&#23569;&#30340;&#35745;&#31639;&#25104;&#26412;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#21270;&#31639;&#27861;&#24050;&#25104;&#20026;&#26114;&#36149;&#40657;&#30418;&#20248;&#21270;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#22312;&#26356;&#23569;&#30340;&#35745;&#31639;&#25104;&#26412;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#23545;&#20110;&#40657;&#30418;&#20248;&#21270;&#33267;&#20851;&#37325;&#35201;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26368;&#20851;&#38190;&#30340;&#38556;&#30861;&#26159;&#25214;&#20986;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#30446;&#26631;&#20219;&#21153;&#20449;&#24687;&#26469;&#24418;&#25104;&#39640;&#25928;&#30340;&#20248;&#21270;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#30001;&#20110;&#20248;&#21270;&#31574;&#30053;&#30340;&#34920;&#24449;&#19981;&#36275;&#20197;&#21450;&#20248;&#21270;&#31574;&#30053;&#19982;&#30446;&#26631;&#20219;&#21153;&#20043;&#38388;&#30340;&#20302;&#25928;&#20132;&#20114;&#32780;&#26174;&#24471;&#34180;&#24369;&#12290;&#20026;&#20102;&#20811;&#26381;&#19978;&#36848;&#38480;&#21046;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#23398;&#20064;&#36827;&#21270;&#31639;&#27861;&#65288;LEA&#65289;&#65292;&#20197;&#23454;&#29616;&#20174;&#25163;&#21160;&#35774;&#35745;&#30340;&#20248;&#21270;&#31574;&#30053;&#21040;&#23398;&#20064;&#20248;&#21270;&#31574;&#30053;&#30340;&#36716;&#25442;&#65292;&#20854;&#20013;&#21253;&#25324;&#36229;&#21442;&#25968;&#21644;&#26356;&#26032;&#35268;&#21017;&#12290;&#19982;&#20256;&#32479;&#36827;&#21270;&#31639;&#27861;&#19981;&#21516;&#65292;LEA&#23545;&#30446;&#26631;&#20219;&#21153;&#20855;&#26377;&#39640;&#36866;&#24212;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#26356;&#23569;&#30340;&#35745;&#31639;&#25104;&#26412;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;LEA&#36824;&#33021;&#22815;&#26377;&#25928;&#22320;&#21033;&#29992;&#30446;&#26631;&#20219;&#21153;&#30340;&#20302;&#20445;&#30495;&#24230;&#20449;&#24687;&#26469;&#24418;&#25104;&#39640;&#25928;&#30340;&#20248;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evolutionary algorithms (EAs) have emerged as a powerful framework for expensive black-box optimization. Obtaining better solutions with less computational cost is essential and challenging for black-box optimization. The most critical obstacle is figuring out how to effectively use the target task information to form an efficient optimization strategy. However, current methods are weak due to the poor representation of the optimization strategy and the inefficient interaction between the optimization strategy and the target task. To overcome the above limitations, we design a learned EA (LEA) to realize the move from hand-designed optimization strategies to learned optimization strategies, including not only hyperparameters but also update rules. Unlike traditional EAs, LEA has high adaptability to the target task and can obtain better solutions with less computational cost. LEA is also able to effectively utilize the low-fidelity information of the target task to form an efficient op
&lt;/p&gt;</description></item></channel></rss>