<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>COS-GNN&#23558;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#19982;&#36830;&#32493;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;CGNNs&#65289;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#20197;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#23545;&#22270;&#33410;&#28857;&#36827;&#34892;&#34920;&#31034;&#65292;&#24182;&#23558;&#20854;&#19982;&#26102;&#38388;&#19968;&#36215;&#38598;&#25104;&#21040;ODE&#36807;&#31243;&#20013;&#65292;&#20197;&#22686;&#24378;&#20449;&#24687;&#20445;&#23384;&#21644;&#35299;&#20915;&#22312;&#31163;&#25955;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.01897</link><description>&lt;p&gt;
&#36830;&#32493;&#33033;&#20914;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Continuous Spiking Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01897
&lt;/p&gt;
&lt;p&gt;
COS-GNN&#23558;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#19982;&#36830;&#32493;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;CGNNs&#65289;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#20197;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#23545;&#22270;&#33410;&#28857;&#36827;&#34892;&#34920;&#31034;&#65292;&#24182;&#23558;&#20854;&#19982;&#26102;&#38388;&#19968;&#36215;&#38598;&#25104;&#21040;ODE&#36807;&#31243;&#20013;&#65292;&#20197;&#22686;&#24378;&#20449;&#24687;&#20445;&#23384;&#21644;&#35299;&#20915;&#22312;&#31163;&#25955;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;CGNNs&#65289;&#22240;&#24341;&#20837;&#36830;&#32493;&#21160;&#21147;&#23398;&#32780;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#65292;&#33021;&#22815;&#25512;&#24191;&#29616;&#26377;&#30340;&#31163;&#25955;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#12290;&#23427;&#20204;&#36890;&#24120;&#21463;&#25193;&#25955;&#31867;&#26041;&#27861;&#21551;&#21457;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20256;&#25773;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#36827;&#34892;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;CGNNs&#30340;&#23454;&#29616;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#33021;&#21147;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#38590;&#20197;&#37096;&#32626;&#22312;&#30005;&#27744;&#20379;&#30005;&#35774;&#22791;&#19978;&#12290;&#21463;&#26368;&#36817;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#30340;&#21551;&#21457;&#65292;SNNs&#27169;&#25311;&#29983;&#29289;&#25512;&#29702;&#36807;&#31243;&#24182;&#25552;&#20379;&#19968;&#31181;&#33410;&#33021;&#30340;&#31070;&#32463;&#26550;&#26500;&#65292;&#25105;&#20204;&#23558;SNNs&#19982;CGNNs&#32467;&#21512;&#21040;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#20013;&#65292;&#21629;&#21517;&#20026;&#36830;&#32493;&#33033;&#20914;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;COS-GNN&#65289;&#12290;&#25105;&#20204;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20351;&#29992;SNNs&#36827;&#34892;&#22270;&#33410;&#28857;&#34920;&#31034;&#65292;&#36825;&#20123;&#34920;&#31034;&#36827;&#19968;&#27493;&#19982;&#26102;&#38388;&#19968;&#36215;&#38598;&#25104;&#21040;ODE&#36807;&#31243;&#20013;&#65292;&#20197;&#22686;&#24378;&#20449;&#24687;&#20445;&#23384;&#21644;&#32531;&#35299;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01897v1 Announce Type: cross  Abstract: Continuous graph neural networks (CGNNs) have garnered significant attention due to their ability to generalize existing discrete graph neural networks (GNNs) by introducing continuous dynamics. They typically draw inspiration from diffusion-based methods to introduce a novel propagation scheme, which is analyzed using ordinary differential equations (ODE). However, the implementation of CGNNs requires significant computational power, making them challenging to deploy on battery-powered devices. Inspired by recent spiking neural networks (SNNs), which emulate a biological inference process and provide an energy-efficient neural architecture, we incorporate the SNNs with CGNNs in a unified framework, named Continuous Spiking Graph Neural Networks (COS-GNN). We employ SNNs for graph node representation at each time step, which are further integrated into the ODE process along with time. To enhance information preservation and mitigate in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;"&#65288;DSGNN&#65289;&#30340;&#26694;&#26550;&#65292;&#23427;&#23558;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#21160;&#24577;&#22270;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#24320;&#38144;&#38382;&#39064;&#12290;DSGNN&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#23574;&#23792;&#31070;&#32463;&#20803;&#30340;&#29366;&#24577;&#21644;&#36830;&#25509;&#26435;&#37325;&#65292;&#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#20445;&#25345;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#23436;&#25972;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.05373</link><description>&lt;p&gt;
&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Dynamic Spiking Graph Neural Networks. (arXiv:2401.05373v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05373
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;"&#65288;DSGNN&#65289;&#30340;&#26694;&#26550;&#65292;&#23427;&#23558;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#21160;&#24577;&#22270;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#24320;&#38144;&#38382;&#39064;&#12290;DSGNN&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#23574;&#23792;&#31070;&#32463;&#20803;&#30340;&#29366;&#24577;&#21644;&#36830;&#25509;&#26435;&#37325;&#65292;&#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#20445;&#25345;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30456;&#32467;&#21512;&#28176;&#28176;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#36825;&#26159;&#22240;&#20026;&#23427;&#22312;&#22788;&#29702;&#30001;&#22270;&#34920;&#31034;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#26102;&#20855;&#26377;&#20302;&#21151;&#32791;&#21644;&#39640;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#65292;&#21160;&#24577;&#22270;&#34920;&#31034;&#23398;&#20064;&#38754;&#20020;&#30528;&#39640;&#22797;&#26434;&#24615;&#21644;&#22823;&#20869;&#23384;&#24320;&#38144;&#30340;&#25361;&#25112;&#12290;&#30446;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#36890;&#36807;&#20351;&#29992;&#20108;&#36827;&#21046;&#29305;&#24449;&#32780;&#19981;&#26159;&#36830;&#32493;&#29305;&#24449;&#30340;SNNs&#26469;&#26367;&#20195;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNNs&#65289;&#36827;&#34892;&#39640;&#25928;&#35757;&#32451;&#65292;&#36825;&#20250;&#24573;&#35270;&#22270;&#32467;&#26500;&#20449;&#24687;&#24182;&#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#23548;&#33268;&#32454;&#33410;&#30340;&#20002;&#22833;&#12290;&#27492;&#22806;&#65292;&#20248;&#21270;&#21160;&#24577;&#23574;&#23792;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#22312;&#26102;&#38388;&#27493;&#20043;&#38388;&#20256;&#25773;&#20449;&#24687;&#65292;&#36825;&#22686;&#21152;&#20102;&#20869;&#23384;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"&#21160;&#24577;&#23574;&#23792;&#22270;&#31070;&#32463;&#32593;&#32476;"&#65288;\method{}&#65289;&#30340;&#26694;&#26550;&#12290;&#20026;&#20102;&#20943;&#36731;&#20449;&#24687;&#20002;&#22833;&#38382;&#39064;&#65292;\method{} &#22312;&#20256;&#25773;&#36807;&#31243;&#20013;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#21046;&#65292;&#23427;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20013;&#21160;&#24577;&#22320;&#35843;&#25972;&#23574;&#23792;&#31070;&#32463;&#20803;&#30340;&#29366;&#24577;&#21644;&#36830;&#25509;&#26435;&#37325;&#65292;&#20197;&#20445;&#25345;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The integration of Spiking Neural Networks (SNNs) and Graph Neural Networks (GNNs) is gradually attracting attention due to the low power consumption and high efficiency in processing the non-Euclidean data represented by graphs. However, as a common problem, dynamic graph representation learning faces challenges such as high complexity and large memory overheads. Current work often uses SNNs instead of Recurrent Neural Networks (RNNs) by using binary features instead of continuous ones for efficient training, which would overlooks graph structure information and leads to the loss of details during propagation. Additionally, optimizing dynamic spiking models typically requires propagation of information across time steps, which increases memory requirements. To address these challenges, we present a framework named \underline{Dy}namic \underline{S}p\underline{i}king \underline{G}raph \underline{N}eural Networks (\method{}). To mitigate the information loss problem, \method{} propagates
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19603</link><description>&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21487;&#20197;&#36827;&#34892;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman Filters Can Filter. (arXiv:2310.19603v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#26159;&#19968;&#31867;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#24207;&#21015;&#25968;&#25454;&#20013;&#29983;&#25104;&#39640;&#26031;&#27010;&#29575;&#27979;&#24230;&#12290;&#34429;&#28982;DKFs&#21463;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#21551;&#21457;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#19982;&#38543;&#26426;&#28388;&#27874;&#38382;&#39064;&#30340;&#20855;&#20307;&#29702;&#35770;&#20851;&#32852;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#20538;&#21048;&#21644;&#26399;&#26435;&#23450;&#20215;&#27169;&#22411;&#26657;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;DKFs&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#25968;&#23398;&#22522;&#30784;&#20013;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#32467;&#26524;&#22312;&#36335;&#24452;&#30340;&#36275;&#22815;&#35268;&#21017;&#30340;&#32039;&#33268;&#23376;&#38598;&#19978;&#19968;&#33268;&#25104;&#31435;&#65292;&#20854;&#20013;&#36817;&#20284;&#35823;&#24046;&#30001;&#22312;&#32473;&#23450;&#32039;&#33268;&#36335;&#24452;&#38598;&#19978;&#22343;&#19968;&#22320;&#35745;&#31639;&#30340;&#26368;&#22351;&#24773;&#20917;2-Wasserstein&#36317;&#31163;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman filters (DKFs) are a class of neural network models that generate Gaussian probability measures from sequential data. Though DKFs are inspired by the Kalman filter, they lack concrete theoretical ties to the stochastic filtering problem, thus limiting their applicability to areas where traditional model-based filters have been used, e.g.\ model calibration for bond and option prices in mathematical finance. We address this issue in the mathematical foundations of deep learning by exhibiting a class of continuous-time DKFs which can approximately implement the conditional law of a broad class of non-Markovian and conditionally Gaussian signal processes given noisy continuous-times measurements. Our approximation results hold uniformly over sufficiently regular compact subsets of paths, where the approximation error is quantified by the worst-case 2-Wasserstein distance computed uniformly over the given compact set of paths.
&lt;/p&gt;</description></item></channel></rss>