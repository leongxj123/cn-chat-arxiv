<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#23545;GPT-4&#22312;&#31639;&#27861;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#31995;&#32479;&#35780;&#20272;&#65292;&#21457;&#29616;&#37319;&#29992;&#20808;&#36827;&#30340;&#25552;&#31034;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#20854;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.17396</link><description>&lt;p&gt;
&#22312;&#31639;&#27861;&#38382;&#39064;&#19978;&#23545;GPT-4&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65306;&#20851;&#20110;&#25552;&#31034;&#31574;&#30053;&#30340;&#31995;&#32479;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17396
&lt;/p&gt;
&lt;p&gt;
&#23545;GPT-4&#22312;&#31639;&#27861;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#31995;&#32479;&#35780;&#20272;&#65292;&#21457;&#29616;&#37319;&#29992;&#20808;&#36827;&#30340;&#25552;&#31034;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#20854;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#22312;&#28023;&#37327;&#25991;&#26412;&#35821;&#26009;&#24211;&#19978;&#33719;&#24471;&#30340;&#30693;&#35782;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#37325;&#26032;&#21033;&#29992;&#65292;&#20960;&#20046;&#19981;&#38656;&#35201;&#65288;&#25110;&#26681;&#26412;&#19981;&#38656;&#35201;&#65289;&#35843;&#25972;&#27493;&#39588;&#65292;&#20174;&#32780;&#38761;&#26032;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#24050;&#32463;&#21453;&#22797;&#26174;&#31034;LLMs&#32570;&#20047;&#31995;&#32479;&#21270;&#27867;&#21270;&#65292;&#36825;&#20351;&#24471;&#26080;&#27861;&#23558;&#23398;&#20064;&#21040;&#30340;&#32479;&#35745;&#35268;&#24459;&#22806;&#25512;&#21040;&#35757;&#32451;&#20998;&#24067;&#20043;&#22806;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#20854;&#20013;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;LLMs&#65292;GPT-4&#65292;&#22312;&#19977;&#20010;&#31639;&#27861;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#31995;&#32479;&#22522;&#20934;&#27979;&#35797;&#65292;&#36825;&#20123;&#20219;&#21153;&#36890;&#36807;&#20004;&#20010;&#21442;&#25968;&#25511;&#21046;&#38382;&#39064;&#38590;&#24230;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;GPT-4&#19982;&#20854;&#21069;&#36523;&#65288;GPT-3.5&#65289;&#20197;&#21450;&#26368;&#36817;&#20171;&#32461;&#30340;&#21464;&#21387;&#22120;&#32534;&#30721;&#22120;&#26550;&#26500;&#30340;&#21464;&#20307;&#65292;&#21363;&#31070;&#32463;&#25968;&#25454;&#36335;&#30001;&#22120;&#65292;&#22312;&#35299;&#20915;&#31867;&#20284;&#20219;&#21153;&#26102;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#37319;&#29992;&#20808;&#36827;&#30340;&#25552;&#31034;&#25216;&#26415;&#21487;&#20197;&#20351;GPT-4&#36798;&#21040;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17396v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized the field of Natural Language Processing thanks to their ability to reuse knowledge acquired on massive text corpora on a wide variety of downstream tasks, with minimal (if any) tuning steps. At the same time, it has been repeatedly shown that LLMs lack systematic generalization, which allows to extrapolate the learned statistical regularities outside the training distribution. In this work, we offer a systematic benchmarking of GPT-4, one of the most advanced LLMs available, on three algorithmic tasks characterized by the possibility to control the problem difficulty with two parameters. We compare the performance of GPT-4 with that of its predecessor (GPT-3.5) and with a variant of the Transformer-Encoder architecture recently introduced to solve similar tasks, the Neural Data Router. We find that the deployment of advanced prompting techniques allows GPT-4 to reach superior accuracy o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20043;&#20026;SpikeGPT&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#65292;&#20351;&#29992;&#20108;&#36827;&#21046;&#12289;&#20107;&#20214;&#39537;&#21160;&#33033;&#20914;&#28608;&#27963;&#21333;&#20803;&#36827;&#34892;&#35757;&#32451;&#65292;&#20811;&#26381;&#20102;SNN&#35757;&#32451;&#20013;&#30340;&#25361;&#25112;&#24615;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2302.13939</link><description>&lt;p&gt;
SpikeGPT&#65306;&#24102;&#26377;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#30340;&#29983;&#25104;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks. (arXiv:2302.13939v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20043;&#20026;SpikeGPT&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#65292;&#20351;&#29992;&#20108;&#36827;&#21046;&#12289;&#20107;&#20214;&#39537;&#21160;&#33033;&#20914;&#28608;&#27963;&#21333;&#20803;&#36827;&#34892;&#35757;&#32451;&#65292;&#20811;&#26381;&#20102;SNN&#35757;&#32451;&#20013;&#30340;&#25361;&#25112;&#24615;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35268;&#27169;&#19981;&#26029;&#25193;&#22823;&#65292;&#25152;&#38656;&#30340;&#35745;&#31639;&#36164;&#28304;&#20063;&#38543;&#20043;&#22686;&#21152;&#12290;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#24050;&#25104;&#20026;&#19968;&#31181;&#33021;&#22815;&#21033;&#29992;&#31232;&#30095;&#21644;&#20107;&#20214;&#39537;&#21160;&#28608;&#27963;&#20943;&#23569;&#27169;&#22411;&#25512;&#29702;&#35745;&#31639;&#24320;&#38144;&#30340;&#33410;&#33021;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#12290;&#34429;&#28982;&#23427;&#20204;&#22312;&#35768;&#22810;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#19978;&#24050;&#32463;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;SNN&#30340;&#35757;&#32451;&#20063;&#34987;&#35777;&#26126;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#33853;&#21518;&#20110;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#65292;&#25105;&#20204;&#23578;&#26410;&#30475;&#21040;SNN&#22312;&#35821;&#35328;&#29983;&#25104;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21463;&#21040;Receptance Weighted Key Value&#65288;RWKV&#65289;&#35821;&#35328;&#27169;&#22411;&#30340;&#21551;&#21457;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#8220;SpikeGPT&#8221;&#65292;&#23427;&#26159;&#19968;&#31181;&#20855;&#26377;&#20108;&#36827;&#21046;&#12289;&#20107;&#20214;&#39537;&#21160;&#33033;&#20914;&#28608;&#27963;&#21333;&#20803;&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#20004;&#31181;&#27169;&#22411;&#21464;&#20307;&#19978;&#35757;&#32451;&#20102;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#65306;45M&#21644;216M&#21442;&#25968;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;SpikeGPT&#26159;&#36804;&#20170;&#26368;&#22823;&#30340;&#21453;&#21521;&#20256;&#25773;&#35757;&#32451;SNN&#27169;&#22411;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#38750;&#33033;&#20914;&#27169;&#22411;&#36890;&#24120;&#35299;&#20915;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the size of large language models continue to scale, so does the computational resources required to run it. Spiking Neural Networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference. While they have become competitive with non-spiking models on many computer vision tasks, SNNs have also proven to be more challenging to train. As a result, their performance lags behind modern deep learning, and we are yet to see the effectiveness of SNNs in language generation. In this paper, inspired by the Receptance Weighted Key Value (RWKV) language model, we successfully implement `SpikeGPT', a generative language model with binary, event-driven spiking activation units. We train the proposed model on two model variants: 45M and 216M parameters. To the best of our knowledge, SpikeGPT is the largest backpropagation-trained SNN model to date, rendering it suita
&lt;/p&gt;</description></item></channel></rss>