<rss version="2.0"><channel><title>Chat Arxiv econ</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for econ</description><item><title>&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#23454;&#39564;&#26694;&#26550;&#29992;&#20110;&#35780;&#20272;&#20154;&#31867;&#26159;&#21542;&#36890;&#36807;&#20351;&#29992;AI&#21487;&#20197;&#20570;&#20986;&#26356;&#22909;&#30340;&#20915;&#31574;&#65292;&#22312;&#21333;&#30450;&#23454;&#39564;&#35774;&#35745;&#20013;&#27604;&#36739;&#20102;&#19977;&#31181;&#20915;&#31574;&#31995;&#32479;&#30340;&#34920;&#29616;</title><link>https://arxiv.org/abs/2403.12108</link><description>&lt;p&gt;
AI&#26159;&#21542;&#26377;&#21161;&#20110;&#20154;&#31867;&#20570;&#20986;&#26356;&#22909;&#30340;&#20915;&#31574;&#65311;&#19968;&#31181;&#29992;&#20110;&#23454;&#39564;&#35780;&#20272;&#30340;&#26041;&#27861;&#35770;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Does AI help humans make better decisions? A methodological framework for experimental evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12108
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#23454;&#39564;&#26694;&#26550;&#29992;&#20110;&#35780;&#20272;&#20154;&#31867;&#26159;&#21542;&#36890;&#36807;&#20351;&#29992;AI&#21487;&#20197;&#20570;&#20986;&#26356;&#22909;&#30340;&#20915;&#31574;&#65292;&#22312;&#21333;&#30450;&#23454;&#39564;&#35774;&#35745;&#20013;&#27604;&#36739;&#20102;&#19977;&#31181;&#20915;&#31574;&#31995;&#32479;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#22312;&#24403;&#20170;&#31038;&#20250;&#21464;&#24471;&#26080;&#22788;&#19981;&#22312;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#23588;&#20854;&#26159;&#24403;&#21033;&#30410;&#39640;&#26114;&#26102;&#65292;&#20154;&#31867;&#20173;&#28982;&#20316;&#20986;&#26368;&#32456;&#20915;&#31574;&#12290;&#22240;&#27492;&#65292;&#20851;&#38190;&#38382;&#39064;&#26159;AI&#26159;&#21542;&#26377;&#21161;&#20110;&#20154;&#31867;&#27604;&#21333;&#29420;&#30340;&#20154;&#31867;&#25110;&#21333;&#29420;&#30340;AI&#20570;&#20986;&#26356;&#22909;&#30340;&#20915;&#31574;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#39564;&#24615;&#22320;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22522;&#20934;&#28508;&#22312;&#32467;&#26524;&#30340;&#26631;&#20934;&#20998;&#31867;&#25351;&#26631;&#27979;&#37327;&#20915;&#31574;&#32773;&#20570;&#20986;&#27491;&#30830;&#20915;&#31574;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#21333;&#30450;&#23454;&#39564;&#35774;&#35745;&#65292;&#22312;&#36825;&#20010;&#35774;&#35745;&#20013;&#65292;&#25552;&#20379;AI&#29983;&#25104;&#30340;&#24314;&#35758;&#22312;&#19981;&#21516;&#26696;&#20363;&#20013;&#34987;&#38543;&#26426;&#20998;&#37197;&#32473;&#26368;&#32456;&#20915;&#31574;&#30340;&#20154;&#31867;&#12290;&#22312;&#36825;&#31181;&#23454;&#39564;&#35774;&#35745;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#27604;&#36739;&#19977;&#31181;&#26367;&#20195;&#20915;&#31574;&#31995;&#32479;&#30340;&#24615;&#33021;--&#20165;&#20154;&#31867;&#12289;&#20154;&#31867;&#19982;AI&#12289;&#20165;AI&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12108v1 Announce Type: new  Abstract: The use of Artificial Intelligence (AI) based on data-driven algorithms has become ubiquitous in today's society. Yet, in many cases and especially when stakes are high, humans still make final decisions. The critical question, therefore, is whether AI helps humans make better decisions as compared to a human alone or AI an alone. We introduce a new methodological framework that can be used to answer experimentally this question with no additional assumptions. We measure a decision maker's ability to make correct decisions using standard classification metrics based on the baseline potential outcome. We consider a single-blinded experimental design, in which the provision of AI-generated recommendations is randomized across cases with a human making final decisions. Under this experimental design, we show how to compare the performance of three alternative decision-making systems--human-alone, human-with-AI, and AI-alone. We apply the pr
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#22810;&#20803;&#22238;&#24402;&#30340;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;&#65292;&#36890;&#36807;&#20248;&#21270;D-&#26368;&#20248;&#20934;&#21017;&#30340;&#27835;&#30103;&#27010;&#29575;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#20998;&#37197;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#30340;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2202.10030</link><description>&lt;p&gt;
&#22810;&#20803;&#21270;&#30340;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Multivariate Tie-breaker Designs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.10030
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#22810;&#20803;&#22238;&#24402;&#30340;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;&#65292;&#36890;&#36807;&#20248;&#21270;D-&#26368;&#20248;&#20934;&#21017;&#30340;&#27835;&#30103;&#27010;&#29575;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#20998;&#37197;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25171;&#30772;&#24179;&#23616;&#35774;&#35745;&#65288;TBD&#65289;&#20013;&#65292;&#20855;&#26377;&#19968;&#23450;&#39640;&#20540;&#30340;&#36816;&#34892;&#21464;&#37327;&#30340;&#21463;&#35797;&#32773;&#25509;&#21463;&#26576;&#31181;&#65288;&#36890;&#24120;&#26159;&#29702;&#24819;&#30340;&#65289;&#27835;&#30103;&#65292;&#20302;&#20540;&#30340;&#21463;&#35797;&#32773;&#19981;&#25509;&#21463;&#27835;&#30103;&#65292;&#32780;&#20013;&#38388;&#30340;&#21463;&#35797;&#32773;&#34987;&#38543;&#26426;&#20998;&#37197;&#12290; TBD&#20171;&#20110;&#22238;&#24402;&#26029;&#28857;&#35774;&#35745;&#65288;RDD&#65289;&#21644;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCT&#65289;&#20043;&#38388;&#65292;&#36890;&#36807;&#20801;&#35768;&#22312;RDD&#30340;&#36164;&#28304;&#20998;&#37197;&#25928;&#29575;&#19982;RCT&#30340;&#32479;&#35745;&#25928;&#29575;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290; &#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#20854;&#20013;&#34987;&#27835;&#30103;&#21463;&#35797;&#32773;&#30340;&#39044;&#26399;&#21453;&#24212;&#26159;&#19968;&#20010;&#22810;&#20803;&#22238;&#24402;&#65292;&#32780;&#23545;&#29031;&#21463;&#35797;&#32773;&#21017;&#26159;&#21478;&#19968;&#20010;&#12290; &#23545;&#20110;&#32473;&#23450;&#30340;&#21327;&#21464;&#37327;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#20984;&#20248;&#21270;&#26469;&#36873;&#25321;&#20248;&#21270;D-&#26368;&#20248;&#20934;&#21017;&#30340;&#27835;&#30103;&#27010;&#29575;&#12290; &#25105;&#20204;&#21487;&#20197;&#32467;&#21512;&#22810;&#31181;&#21463;&#32463;&#27982;&#21644;&#20262;&#29702;&#32771;&#34385;&#28608;&#21457;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290; &#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;&#23545;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;D-&#26368;&#20248;&#24615;&#19982;&#25972;&#20307;&#22238;&#24402;&#30340;D-&#26368;&#20248;&#24615;&#37325;&#21512;&#65292;&#22312;&#27809;&#26377;&#32463;&#27982;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;RCT&#21363;&#20026;&#26368;&#20248;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.10030v4 Announce Type: replace-cross  Abstract: In a tie-breaker design (TBD), subjects with high values of a running variable are given some (usually desirable) treatment, subjects with low values are not, and subjects in the middle are randomized. TBDs are intermediate between regression discontinuity designs (RDDs) and randomized controlled trials (RCTs) by allowing a tradeoff between the resource allocation efficiency of an RDD and the statistical efficiency of an RCT. We study a model where the expected response is one multivariate regression for treated subjects and another for control subjects. For given covariates, we show how to use convex optimization to choose treatment probabilities that optimize a D-optimality criterion. We can incorporate a variety of constraints motivated by economic and ethical considerations. In our model, D-optimality for the treatment effect coincides with D-optimality for the whole regression, and without economic constraints, an RCT is g
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.05026</link><description>&lt;p&gt;
&#24102;&#26377;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#21512;&#25104;&#23545;&#29031;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification in Synthetic Controls with Staggered Treatment Adoption. (arXiv:2210.05026v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05026
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#29992;&#20110;&#37327;&#21270;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#22823;&#31867;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20379;&#31934;&#30830;&#30340;&#38750;&#28176;&#36817;&#35206;&#30422;&#27010;&#29575;&#20445;&#35777;&#12290;&#20174;&#26041;&#27861;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#38656;&#35201;&#39044;&#27979;&#30340;&#19981;&#21516;&#22240;&#26524;&#37327;&#36827;&#34892;&#35814;&#32454;&#35752;&#35770;&#65292;&#25105;&#20204;&#31216;&#20854;&#20026;&#8220;&#22240;&#26524;&#39044;&#27979;&#37327;&#8221;&#65292;&#20801;&#35768;&#22312;&#21487;&#33021;&#19981;&#21516;&#26102;&#21051;&#36827;&#34892;&#22810;&#20010;&#22788;&#29702;&#21333;&#20803;&#30340;&#22788;&#29702;&#37319;&#29992;&#12290;&#20174;&#29702;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#25552;&#39640;&#20102;&#20043;&#21069;&#25991;&#29486;&#30340;&#27700;&#24179;&#65292;&#20855;&#20307;&#34920;&#29616;&#22312;&#65306;&#65288;i&#65289;&#35206;&#30422;&#20102;&#38169;&#20301;&#37319;&#29992;&#35774;&#32622;&#20013;&#30340;&#22823;&#31867;&#22240;&#26524;&#39044;&#27979;&#37327;&#65292;&#65288;ii&#65289;&#20801;&#35768;&#20855;&#26377;&#21487;&#33021;&#38750;&#32447;&#24615;&#32422;&#26463;&#30340;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#65292;&#65288;iii&#65289;&#25552;&#20986;&#21487;&#25193;&#23637;&#30340;&#40065;&#26834;&#38181;&#20248;&#21270;&#26041;&#27861;&#21644;&#22522;&#20110;&#21407;&#21017;&#30340;&#25968;&#25454;&#39537;&#21160;&#35843;&#21442;&#36873;&#25321;&#65292;&#65288;iv&#65289;&#25552;&#20379;&#20102;&#22312;&#21518;&#22788;&#29702;&#26399;&#38388;&#36827;&#34892;&#26377;&#25928;&#22343;&#21248;&#25512;&#26029;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#24212;&#29992;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose principled prediction intervals to quantify the uncertainty of a large class of synthetic control predictions or estimators in settings with staggered treatment adoption, offering precise non-asymptotic coverage probability guarantees. From a methodological perspective, we provide a detailed discussion of different causal quantities to be predicted, which we call `causal predictands', allowing for multiple treated units with treatment adoption at possibly different points in time. From a theoretical perspective, our uncertainty quantification methods improve on prior literature by (i) covering a large class of causal predictands in staggered adoption settings, (ii) allowing for synthetic control methods with possibly nonlinear constraints, (iii) proposing scalable robust conic optimization methods and principled data-driven tuning parameter selection, and (iv) offering valid uniform inference across post-treatment periods. We illustrate our methodology with an empirical appl
&lt;/p&gt;</description></item></channel></rss>