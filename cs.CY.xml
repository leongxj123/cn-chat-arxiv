<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#26412;&#22320;&#31354;&#38388;&#21152;&#26435;&#26041;&#26696;&#12289;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#21644;&#23574;&#31471;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#20197;&#25552;&#39640;&#22320;&#29702;&#31354;&#38388;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.03328</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#21487;&#35299;&#37322;&#22320;&#29702;&#31354;&#38388;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38598;&#25104;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
An Ensemble Framework for Explainable Geospatial Machine Learning Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03328
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#26412;&#22320;&#31354;&#38388;&#21152;&#26435;&#26041;&#26696;&#12289;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#21644;&#23574;&#31471;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#20197;&#25552;&#39640;&#22320;&#29702;&#31354;&#38388;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#31354;&#38388;&#21464;&#21270;&#25928;&#24212;&#22312;&#22320;&#29702;&#20998;&#26512;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22320;&#29702;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#21644;&#38750;&#32447;&#24615;&#65292;&#20934;&#30830;&#25429;&#25417;&#21644;&#35299;&#37322;&#36825;&#31181;&#21464;&#24322;&#24615;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#26412;&#22320;&#31354;&#38388;&#21152;&#26435;&#26041;&#26696;&#12289;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#21644;&#23574;&#31471;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#20197;&#24357;&#21512;&#20256;&#32479;&#22320;&#29702;&#20998;&#26512;&#27169;&#22411;&#21644;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#27979;&#35797;&#65292;&#39564;&#35777;&#20102;&#35813;&#26694;&#26550;&#36890;&#36807;&#38416;&#26126;&#31354;&#38388;&#21464;&#24322;&#24615;&#65292;&#25552;&#39640;&#20102;&#22320;&#29702;&#22238;&#24402;&#21644;&#20998;&#31867;&#39044;&#27979;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;&#23427;&#26174;&#33879;&#25552;&#39640;&#20102;&#39044;&#27979;&#31934;&#24230;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35299;&#31354;&#38388;&#29616;&#35937;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03328v1 Announce Type: new  Abstract: Analyzing spatial varying effect is pivotal in geographic analysis. Yet, accurately capturing and interpreting this variability is challenging due to the complexity and non-linearity of geospatial data. Herein, we introduce an integrated framework that merges local spatial weighting scheme, Explainable Artificial Intelligence (XAI), and cutting-edge machine learning technologies to bridge the gap between traditional geographic analysis models and general machine learning approaches. Through tests on synthetic datasets, this framework is verified to enhance the interpretability and accuracy of predictions in both geographic regression and classification by elucidating spatial variability. It significantly boosts prediction precision, offering a novel approach to understanding spatial phenomena.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#35299;&#37322;&#22312;&#22810;&#39046;&#22495;&#25351;&#23548;&#24494;&#35843;&#25968;&#25454;&#38598;&#19978;&#30340;&#29305;&#24615;&#65292;&#21457;&#29616;&#29983;&#25104;&#30340;&#35299;&#37322;&#34920;&#29616;&#20986;&#36873;&#25321;&#24615;&#21644;&#21253;&#21547;&#35828;&#26126;&#24615;&#20803;&#32032;&#65292;&#20294;&#36739;&#23569;&#26159;&#20027;&#35266;&#25110;&#35823;&#23548;&#24615;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.10532</link><description>&lt;p&gt;
LLM&#29983;&#25104;&#30340;&#35299;&#37322;&#30340;&#29305;&#24615;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Properties and Challenges of LLM-Generated Explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10532
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#35299;&#37322;&#22312;&#22810;&#39046;&#22495;&#25351;&#23548;&#24494;&#35843;&#25968;&#25454;&#38598;&#19978;&#30340;&#29305;&#24615;&#65292;&#21457;&#29616;&#29983;&#25104;&#30340;&#35299;&#37322;&#34920;&#29616;&#20986;&#36873;&#25321;&#24615;&#21644;&#21253;&#21547;&#35828;&#26126;&#24615;&#20803;&#32032;&#65292;&#20294;&#36739;&#23569;&#26159;&#20027;&#35266;&#25110;&#35823;&#23548;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#33258;&#25105;&#21512;&#29702;&#21270;&#33021;&#21147;&#22312;&#38480;&#23450;&#29615;&#22659;&#20013;&#24471;&#21040;&#20102;&#25506;&#32034;&#65292;&#20351;&#29992;&#29305;&#23450;&#20219;&#21153;/&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;LLMs&#24182;&#19981;&#65288;&#20165;&#65289;&#20381;&#36182;&#20110;&#29305;&#23450;&#27880;&#37322;&#30340;&#25968;&#25454;&#65307;&#28982;&#32780;&#65292;&#23427;&#20204;&#32463;&#24120;&#35299;&#37322;&#23427;&#20204;&#30340;&#36755;&#20986;&#12290;&#29983;&#25104;&#30340;&#35299;&#37322;&#30340;&#29305;&#24615;&#21463;&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#21644;&#29992;&#20110;&#25351;&#23548;&#24494;&#35843;&#30340;&#30446;&#26631;&#25968;&#25454;&#30340;&#24433;&#21709;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#21253;&#21547;&#22823;&#37327;&#37326;&#22806;&#20154;&#31867;&#32534;&#20889;&#30340;&#35299;&#37322;&#65292;&#25105;&#20204;&#20551;&#35774;LLMs&#37319;&#29992;&#20102;&#20154;&#31867;&#35299;&#37322;&#30340;&#20849;&#21516;&#29305;&#24615;&#12290;&#36890;&#36807;&#20998;&#26512;&#22810;&#22495;&#25351;&#23548;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#36755;&#20986;&#65292;&#25105;&#20204;&#21457;&#29616;&#29983;&#25104;&#30340;&#35299;&#37322;&#34920;&#29616;&#20986;&#36873;&#25321;&#24615;&#24182;&#21253;&#21547;&#35828;&#26126;&#24615;&#20803;&#32032;&#65292;&#20294;&#24456;&#23569;&#26159;&#20027;&#35266;&#25110;&#35823;&#23548;&#24615;&#30340;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#23646;&#24615;&#23384;&#22312;&#25110;&#32570;&#22833;&#30340;&#21407;&#22240;&#21644;&#21518;&#26524;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#26681;&#25454;LLMs&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#21644;&#24494;&#35843;&#25968;&#25454;&#30340;&#24615;&#36136;&#65292;&#36825;&#20123;&#23646;&#24615;&#23384;&#22312;&#25110;&#32570;&#22833;&#30340;&#31215;&#26497;&#21644;&#28040;&#26497;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10532v1 Announce Type: cross  Abstract: The self-rationalising capabilities of large language models (LLMs) have been explored in restricted settings, using task/specific data sets. However, current LLMs do not (only) rely on specifically annotated data; nonetheless, they frequently explain their outputs. The properties of the generated explanations are influenced by the pre-training corpus and by the target data used for instruction fine-tuning. As the pre-training corpus includes a large amount of human-written explanations "in the wild", we hypothesise that LLMs adopt common properties of human explanations. By analysing the outputs for a multi-domain instruction fine-tuning data set, we find that generated explanations show selectivity and contain illustrative elements, but less frequently are subjective or misleading. We discuss reasons and consequences of the properties' presence or absence. In particular, we outline positive and negative implications depending on the 
&lt;/p&gt;</description></item></channel></rss>