<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#25506;&#35752;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#24341;&#21457;&#30340;&#20889;&#20316;&#25152;&#26377;&#26435;&#24863;&#21644;&#20316;&#32773;&#36523;&#20221;&#35748;&#30693;&#20043;&#38388;&#30340;&#24515;&#29702;&#22256;&#22659;&#12290;</title><link>https://arxiv.org/abs/2404.00027</link><description>&lt;p&gt;
LLM&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#65306;&#25506;&#35752;&#25152;&#26377;&#26435;&#24863;&#21644;&#25512;&#29702;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00027
&lt;/p&gt;
&lt;p&gt;
&#25506;&#35752;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#24341;&#21457;&#30340;&#20889;&#20316;&#25152;&#26377;&#26435;&#24863;&#21644;&#20316;&#32773;&#36523;&#20221;&#35748;&#30693;&#20043;&#38388;&#30340;&#24515;&#29702;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20889;&#20316;&#20013;&#30340;&#25152;&#26377;&#26435;&#24863;&#38480;&#21046;&#20102;&#25105;&#20204;&#23545;&#24605;&#24819;&#12289;&#26102;&#38388;&#21644;&#36129;&#29486;&#30340;&#25237;&#20837;&#65292;&#23548;&#33268;&#23545;&#20135;&#20986;&#29289;&#30340;&#20381;&#24651;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#20889;&#20316;&#21161;&#25163;&#24341;&#20837;&#20102;&#19968;&#31181;&#24515;&#29702;&#22256;&#22659;&#65292;&#22240;&#20026;&#19968;&#20123;&#20869;&#23481;&#24182;&#38750;&#30452;&#25509;&#25105;&#20204;&#30340;&#21019;&#20316;&#12290;&#25105;&#20204;&#24448;&#24448;&#26356;&#20542;&#21521;&#20110;&#22312;&#21019;&#36896;&#24615;&#20219;&#21153;&#20013;&#26356;&#22810;&#22320;&#24402;&#21151;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#23613;&#31649;&#23427;&#20204;&#23545;&#25152;&#26377;&#20219;&#21153;&#37117;&#26159;&#24179;&#31561;&#30340;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#25105;&#20204;&#21487;&#33021;&#19981;&#20250;&#23436;&#20840;&#22768;&#31216;&#23545;&#30001;LLM&#29983;&#25104;&#30340;&#20869;&#23481;&#25317;&#26377;&#25152;&#26377;&#26435;&#65292;&#20294;&#21364;&#33258;&#30001;&#22320;&#22768;&#31216;&#20316;&#32773;&#36523;&#20221;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#31616;&#30701;&#35843;&#26597;&#26469;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#20102;&#35299;&#28508;&#22312;&#30340;&#35748;&#30693;&#36807;&#31243;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#20154;&#26426;&#20132;&#20114;&#22312;&#20889;&#20316;&#20013;&#30340;&#24212;&#29992;&#24182;&#25913;&#36827;&#20889;&#20316;&#36741;&#21161;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29992;&#25143;&#20026;&#20309;&#20998;&#20139;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#20167;&#24680;&#35328;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#28040;&#38500;&#25968;&#25454;&#20559;&#24046;&#21644;&#27169;&#25311;&#29992;&#25143;&#33030;&#24369;&#24615;&#26469;&#25581;&#31034;&#24433;&#21709;&#29992;&#25143;&#20998;&#20139;&#34892;&#20026;&#30340;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2310.15772</link><description>&lt;p&gt;
&#29992;&#25143;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#20998;&#20139;&#20167;&#24680;&#35328;&#35770;&#30340;&#22240;&#26524;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Causal Understanding of Why Users Share Hate Speech on Social Media. (arXiv:2310.15772v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29992;&#25143;&#20026;&#20309;&#20998;&#20139;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#20167;&#24680;&#35328;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#28040;&#38500;&#25968;&#25454;&#20559;&#24046;&#21644;&#27169;&#25311;&#29992;&#25143;&#33030;&#24369;&#24615;&#26469;&#25581;&#31034;&#24433;&#21709;&#29992;&#25143;&#20998;&#20139;&#34892;&#20026;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#20167;&#24680;&#35328;&#35770;&#23041;&#32961;&#21040;&#20010;&#20154;&#30340;&#24515;&#29702;&#21644;&#36523;&#20307;&#20581;&#24247;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#23548;&#33268;&#29616;&#23454;&#20013;&#30340;&#26292;&#21147;&#20107;&#20214;&#12290;&#20167;&#24680;&#35328;&#35770;&#20256;&#25773;&#32972;&#21518;&#30340;&#37325;&#35201;&#39537;&#21160;&#22240;&#32032;&#26159;&#36716;&#21457;&#65292;&#20294;&#26159;&#20154;&#20204;&#24456;&#23569;&#20102;&#35299;&#20026;&#20160;&#20040;&#29992;&#25143;&#20250;&#36716;&#21457;&#20167;&#24680;&#35328;&#35770;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#12289;&#22240;&#26524;&#20998;&#26512;&#30340;&#29992;&#25143;&#23646;&#24615;&#26694;&#26550;&#65292;&#30740;&#31350;&#29992;&#25143;&#20026;&#20309;&#20998;&#20139;&#20167;&#24680;&#35328;&#35770;&#12290;&#28982;&#32780;&#65292;&#22312;&#20174;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26102;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#65292;&#22240;&#20026;&#36825;&#31867;&#25968;&#25454;&#24456;&#21487;&#33021;&#23384;&#22312;&#36873;&#25321;&#20559;&#24046;&#65292;&#24182;&#19988;&#29992;&#25143;&#23545;&#20167;&#24680;&#35328;&#35770;&#30340;&#33030;&#24369;&#24615;&#23384;&#22312;&#28151;&#28102;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#19977;&#27493;&#22240;&#26524;&#26694;&#26550;&#65306;&#65288;1&#65289;&#25105;&#20204;&#36890;&#36807;&#36870;&#21521;&#20542;&#21521;&#35780;&#20998;&#26469;&#28040;&#38500;&#35266;&#23519;&#24615;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#20559;&#24046;&#12290;&#65288;2&#65289;&#25105;&#20204;&#20351;&#29992;&#28040;&#38500;&#20559;&#24046;&#30340;&#20542;&#21521;&#35780;&#20998;&#26469;&#27169;&#25311;&#29992;&#25143;&#23545;&#20167;&#24680;&#35328;&#35770;&#30340;&#28508;&#22312;&#33030;&#24369;&#24615;&#20316;&#20026;&#28508;&#22312;&#23884;&#20837;&#12290;&#65288;3&#65289;&#25105;&#20204;&#24314;&#31435;&#20102;&#29992;&#25143;&#23646;&#24615;&#23545;&#29992;&#25143;&#20998;&#20139;&#20167;&#24680;&#35328;&#35770;&#27010;&#29575;&#30340;&#22240;&#26524;&#25928;&#24212;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hate speech on social media threatens the mental and physical well-being of individuals and is further responsible for real-world violence. An important driver behind the spread of hate speech and thus why hateful posts can go viral are reshares, yet little is known about why users reshare hate speech. In this paper, we present a comprehensive, causal analysis of the user attributes that make users reshare hate speech. However, causal inference from observational social media data is challenging, because such data likely suffer from selection bias, and there is further confounding due to differences in the vulnerability of users to hate speech. We develop a novel, three-step causal framework: (1) We debias the observational social media data by applying inverse propensity scoring. (2) We use the debiased propensity scores to model the latent vulnerability of users to hate speech as a latent embedding. (3) We model the causal effects of user attributes on users' probability of sharing h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#25913;&#36827;&#24403;&#21069;&#21644;&#26410;&#26469;&#19982;&#25554;&#20214;&#38598;&#25104;&#30340;LLM&#24179;&#21488;&#30340;&#23433;&#20840;&#24615;&#12289;&#38544;&#31169;&#21644;&#23433;&#20840;&#24615;&#12290;&#22312;&#24212;&#29992;&#26694;&#26550;&#20110;OpenAI&#30340;&#25554;&#20214;&#29983;&#24577;&#31995;&#32479;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20123;&#20855;&#20307;&#35777;&#26126;&#20102;&#28508;&#22312;&#38382;&#39064;&#30340;&#25554;&#20214;&#12290;</title><link>http://arxiv.org/abs/2309.10254</link><description>&lt;p&gt;
LLM&#24179;&#21488;&#23433;&#20840;&#65306;&#23558;&#31995;&#32479;&#35780;&#20272;&#26694;&#26550;&#24212;&#29992;&#20110;OpenAI&#30340;ChatGPT&#25554;&#20214;
&lt;/p&gt;
&lt;p&gt;
LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins. (arXiv:2309.10254v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#25913;&#36827;&#24403;&#21069;&#21644;&#26410;&#26469;&#19982;&#25554;&#20214;&#38598;&#25104;&#30340;LLM&#24179;&#21488;&#30340;&#23433;&#20840;&#24615;&#12289;&#38544;&#31169;&#21644;&#23433;&#20840;&#24615;&#12290;&#22312;&#24212;&#29992;&#26694;&#26550;&#20110;OpenAI&#30340;&#25554;&#20214;&#29983;&#24577;&#31995;&#32479;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20123;&#20855;&#20307;&#35777;&#26126;&#20102;&#28508;&#22312;&#38382;&#39064;&#30340;&#25554;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#22914;ChatGPT&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24179;&#21488;&#24320;&#22987;&#25552;&#20379;&#25554;&#20214;&#29983;&#24577;&#31995;&#32479;&#65292;&#20197;&#19982;&#20114;&#32852;&#32593;&#19978;&#30340;&#31532;&#19977;&#26041;&#26381;&#21153;&#36827;&#34892;&#20132;&#20114;&#12290;&#34429;&#28982;&#36825;&#20123;&#25554;&#20214;&#25193;&#23637;&#20102;LLM&#24179;&#21488;&#30340;&#21151;&#33021;&#65292;&#20294;&#23427;&#20204;&#26159;&#30001;&#20219;&#24847;&#30340;&#31532;&#19977;&#26041;&#24320;&#21457;&#30340;&#65292;&#22240;&#27492;&#19981;&#33021;&#38544;&#24335;&#20449;&#20219;&#12290;&#25554;&#20214;&#36824;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#19982;LLM&#24179;&#21488;&#21644;&#29992;&#25143;&#36827;&#34892;&#20132;&#20114;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#27169;&#31946;&#30340;&#35299;&#37322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20026;LLM&#24179;&#21488;&#35774;&#35745;&#32773;&#20998;&#26512;&#21644;&#25913;&#36827;&#24403;&#21069;&#21644;&#26410;&#26469;&#19982;&#25554;&#20214;&#38598;&#25104;&#30340;LLM&#24179;&#21488;&#30340;&#23433;&#20840;&#24615;&#12289;&#38544;&#31169;&#21644;&#23433;&#20840;&#24615;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#26159;&#19968;&#20010;&#25915;&#20987;&#20998;&#31867;&#27861;&#30340;&#34920;&#36848;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#25506;&#32034;LLM&#24179;&#21488;&#30456;&#20851;&#26041;&#22914;&#20309;&#21033;&#29992;&#20182;&#20204;&#30340;&#33021;&#21147;&#21644;&#36131;&#20219;&#23545;&#24444;&#27492;&#36827;&#34892;&#25915;&#20987;&#26469;&#24320;&#21457;&#30340;&#12290;&#20316;&#20026;&#25105;&#20204;&#36845;&#20195;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;OpenAI&#30340;&#25554;&#20214;&#29983;&#24577;&#31995;&#32479;&#12290;&#25105;&#20204;&#25581;&#31034;&#20102;&#19968;&#20123;&#20855;&#20307;&#35777;&#26126;&#20102;&#28508;&#22312;&#38382;&#39064;&#30340;&#25554;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language model (LLM) platforms, such as ChatGPT, have recently begun offering a plugin ecosystem to interface with third-party services on the internet. While these plugins extend the capabilities of LLM platforms, they are developed by arbitrary third parties and thus cannot be implicitly trusted. Plugins also interface with LLM platforms and users using natural language, which can have imprecise interpretations. In this paper, we propose a framework that lays a foundation for LLM platform designers to analyze and improve the security, privacy, and safety of current and future plugin-integrated LLM platforms. Our framework is a formulation of an attack taxonomy that is developed by iteratively exploring how LLM platform stakeholders could leverage their capabilities and responsibilities to mount attacks against each other. As part of our iterative process, we apply our framework in the context of OpenAI's plugin ecosystem. We uncover plugins that concretely demonstrate the poten
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#32553;&#25918;&#23450;&#24459;&#19982;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#25968;&#25454;&#38598;&#35268;&#27169;&#30340;&#22686;&#21152;&#20250;&#24341;&#21457;&#19981;&#21516;&#31038;&#32676;&#30340;&#20215;&#20540;&#35266;&#21644;&#20559;&#35265;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2307.03201</link><description>&lt;p&gt;
&#32553;&#25918;&#23450;&#24459;&#19981;&#20855;&#22791;&#21487;&#25193;&#23637;&#24615;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws Do Not Scale. (arXiv:2307.03201v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#32553;&#25918;&#23450;&#24459;&#19982;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#25968;&#25454;&#38598;&#35268;&#27169;&#30340;&#22686;&#21152;&#20250;&#24341;&#21457;&#19981;&#21516;&#31038;&#32676;&#30340;&#20215;&#20540;&#35266;&#21644;&#20559;&#35265;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#32553;&#25918;&#23450;&#24459;&#8221;&#30340;&#24130;&#24459;&#20851;&#31995;&#65292;&#23427;&#25551;&#36848;&#20102;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27169;&#22411;&#30340;&#24615;&#33021;&#19982;&#27169;&#22411;&#35774;&#35745;&#30340;&#21508;&#20010;&#26041;&#38754;&#65288;&#22914;&#25968;&#25454;&#38598;&#22823;&#23567;&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#38543;&#30528;&#25968;&#25454;&#38598;&#65288;&#25110;&#27169;&#22411;&#21442;&#25968;&#31561;&#65289;&#30340;&#22686;&#21152;&#65292;&#22522;&#20110;&#35813;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#24615;&#33021;&#23558;&#30456;&#24212;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#22312;&#24635;&#20307;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#30340;&#21516;&#26102;&#65292;&#36825;&#31181;&#32553;&#25918;&#23450;&#24459;&#20851;&#31995;&#24573;&#35270;&#20102;&#29992;&#20110;&#34913;&#37327;&#24615;&#33021;&#30340;&#25351;&#26631;&#21487;&#33021;&#26159;&#19981;&#31283;&#23450;&#21644;&#26377;&#20105;&#35758;&#30340;&#65292;&#25110;&#32773;&#21487;&#33021;&#19981;&#31526;&#21512;&#19981;&#21516;&#20154;&#32676;&#23545;&#27169;&#22411;&#36755;&#20986;&#36136;&#37327;&#30340;&#24863;&#30693;&#12290;&#26412;&#25991;&#25552;&#20986;&#65292;&#38543;&#30528;&#29992;&#20110;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#35268;&#27169;&#22686;&#38271;&#65292;&#25968;&#25454;&#38598;&#20013;&#21253;&#21547;&#30340;&#19981;&#21516;&#31038;&#32676;&#65288;&#21253;&#25324;&#20154;&#21475;&#32479;&#35745;&#23398;&#32676;&#20307;&#65289;&#30340;&#25968;&#37327;&#21487;&#33021;&#20250;&#22686;&#21152;&#65292;&#27599;&#20010;&#31038;&#32676;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#30340;&#20215;&#20540;&#35266;&#12290;&#22240;&#27492;&#65292;&#25968;&#25454;&#38598;&#20013;&#25152;&#20195;&#34920;&#30340;&#31038;&#32676;&#21487;&#33021;&#23384;&#22312;&#20215;&#20540;&#35266;&#25110;&#20559;&#35265;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has proposed a power law relationship, referred to as ``scaling laws,'' between the performance of artificial intelligence (AI) models and aspects of those models' design (e.g., dataset size). In other words, as the size of a dataset (or model parameters, etc) increases, the performance of a given model trained on that dataset will correspondingly increase. However, while compelling in the aggregate, this scaling law relationship overlooks the ways that metrics used to measure performance may be precarious and contested, or may not correspond with how different groups of people may perceive the quality of models' output. In this paper, we argue that as the size of datasets used to train large AI models grows, the number of distinct communities (including demographic groups) whose data is included in a given dataset is likely to grow, each of whom may have different values. As a result, there is an increased risk that communities represented in a dataset may have values or p
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#31350;&#24494;&#35843;&#23545;&#23569;&#26679;&#26412;&#19979;&#28216;&#20219;&#21153;&#30340;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#36866;&#24403;&#36873;&#25321;&#22806;&#20998;&#24067;&#20998;&#25968;&#23545;&#20110;CLIP-based &#24494;&#35843;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#22823;&#27010;&#24565;&#21305;&#37197;&#65288;MCM&#65289;&#20998;&#25968;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.06048</link><description>&lt;p&gt;
&#24494;&#35843;&#23545;&#20110;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#24433;&#21709;&#26159;&#24590;&#26679;&#30340;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?. (arXiv:2306.06048v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#31350;&#24494;&#35843;&#23545;&#23569;&#26679;&#26412;&#19979;&#28216;&#20219;&#21153;&#30340;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#36866;&#24403;&#36873;&#25321;&#22806;&#20998;&#24067;&#20998;&#25968;&#23545;&#20110;CLIP-based &#24494;&#35843;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#22823;&#27010;&#24565;&#21305;&#37197;&#65288;MCM&#65289;&#20998;&#25968;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65292;&#22914;CLIP&#65292;&#22312;&#22806;&#20998;&#24067;&#26816;&#27979;&#21644;&#27867;&#21270;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#38646;&#26679;&#26412;&#20869;&#20998;&#24067;&#20934;&#30830;&#24615;&#24448;&#24448;&#22312;&#19979;&#28216;&#25968;&#25454;&#38598;&#20013;&#21463;&#21040;&#38480;&#21046;&#12290;&#26368;&#36817;&#30340;&#22522;&#20110;CLIP&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#22914;&#25552;&#31034;&#23398;&#20064;&#65292;&#24050;&#32463;&#22312;&#23384;&#22312;&#22806;&#20998;&#24067;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25913;&#36827;&#20102;&#20869;&#20998;&#24067;&#20998;&#31867;&#21644;&#22806;&#20998;&#24067;&#27867;&#21270;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#23545;&#20110;&#27809;&#26377;&#22806;&#20998;&#24067;&#26631;&#31614;&#30340;&#35821;&#20041;&#36716;&#31227;&#26159;&#21542;&#21487;&#38752;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#25991;&#26088;&#22312;&#23545;&#24494;&#35843;&#23545;&#20110;&#23569;&#26679;&#26412;&#19979;&#28216;&#20219;&#21153;&#30340;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#24433;&#21709;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;&#12290;&#36890;&#36807;&#23558;&#22806;&#20998;&#24067;&#26816;&#27979;&#26694;&#26550;&#21270;&#20026;&#22810;&#27169;&#24335;&#27010;&#24565;&#21305;&#37197;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#24494;&#35843;&#26041;&#27861;&#21644;&#21508;&#31181;&#22806;&#20998;&#24067;&#20998;&#25968;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#22806;&#20998;&#24067;&#20998;&#25968;&#23545;&#20110;&#22522;&#20110;CLIP&#30340;&#24494;&#35843;&#33267;&#20851;&#37325;&#35201;&#12290;&#29305;&#21035;&#26159;&#65292;&#26368;&#22823;&#27010;&#24565;&#21305;&#37197;&#65288;MCM&#65289;&#20998;&#25968;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent large vision-language models such as CLIP have shown remarkable out-of-distribution (OOD) detection and generalization performance. However, their zero-shot in-distribution (ID) accuracy is often limited for downstream datasets. Recent CLIP-based fine-tuning methods such as prompt learning have demonstrated significant improvements in ID classification and OOD generalization where OOD labels are available. Nonetheless, it remains unclear whether the model is reliable to semantic shifts without OOD labels. In this paper, we aim to bridge the gap and present a comprehensive study to understand how fine-tuning impact OOD detection for few-shot downstream tasks. By framing OOD detection as multi-modal concept matching, we establish a connection between fine-tuning methods and various OOD scores. Our results suggest that a proper choice of OOD scores is essential for CLIP-based fine-tuning. In particular, the maximum concept matching (MCM) score provides a promising solution consiste
&lt;/p&gt;</description></item></channel></rss>