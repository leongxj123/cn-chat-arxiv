<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#21270;&#23545;&#38544;&#31169;&#25512;&#26029;&#20013;&#32676;&#20307;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20943;&#23569;ReLU&#28608;&#27963;&#20989;&#25968;&#25968;&#37327;&#20250;&#19981;&#25104;&#27604;&#20363;&#22320;&#38477;&#20302;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#23545;&#20110;&#22810;&#25968;&#32676;&#20307;&#21017;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#12290;&#37319;&#29992;&#31616;&#21333;&#30340;&#24494;&#35843;&#27493;&#39588;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.03629</link><description>&lt;p&gt;
&#31169;&#26377;&#25512;&#26029;&#30340;&#32447;&#24615;&#21270;&#23545;&#32676;&#20307;&#20934;&#30830;&#24615;&#30340;&#19981;&#23545;&#31216;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Disparate Impact on Group Accuracy of Linearization for Private Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#21270;&#23545;&#38544;&#31169;&#25512;&#26029;&#20013;&#32676;&#20307;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20943;&#23569;ReLU&#28608;&#27963;&#20989;&#25968;&#25968;&#37327;&#20250;&#19981;&#25104;&#27604;&#20363;&#22320;&#38477;&#20302;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#23545;&#20110;&#22810;&#25968;&#32676;&#20307;&#21017;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#12290;&#37319;&#29992;&#31616;&#21333;&#30340;&#24494;&#35843;&#27493;&#39588;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#20445;&#23545;&#20855;&#26377;&#23494;&#30721;&#23433;&#20840;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#38544;&#31169;&#20445;&#25252;&#30340;&#25512;&#26029;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;&#20026;&#20102;&#20943;&#36731;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#20013;&#26114;&#36149;&#30340;&#21152;&#23494;&#35745;&#31639;&#30340;&#29942;&#39048;&#65292;&#26368;&#36817;&#30340;&#26041;&#27861;&#24314;&#35758;&#22312;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#20013;&#32447;&#24615;&#21270;&#30446;&#26631;&#37096;&#20998;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;&#36825;&#31181;&#25216;&#26415;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#36816;&#34892;&#26102;&#38388;&#65292;&#23545;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#24448;&#24448;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#35745;&#31639;&#20248;&#21183;&#21487;&#33021;&#23548;&#33268;&#20844;&#24179;&#24615;&#25104;&#26412;&#22686;&#21152;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21457;&#29616;&#20943;&#23569;ReLU&#28608;&#27963;&#20989;&#25968;&#25968;&#37327;&#20250;&#19981;&#25104;&#27604;&#20363;&#22320;&#38477;&#20302;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#23545;&#20110;&#22810;&#25968;&#32676;&#20307;&#21017;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#37322;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#22312;&#23545;&#20915;&#31574;&#36793;&#30028;&#24615;&#36136;&#36827;&#34892;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#22522;&#30784;&#19978;&#25552;&#20379;&#20102;&#25968;&#23398;&#35299;&#37322;&#65292;&#21516;&#26102;&#36824;&#23637;&#31034;&#20102;&#36825;&#20010;&#38382;&#39064;&#22312;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#21644;&#20307;&#31995;&#32467;&#26500;&#20013;&#30340;&#26222;&#36941;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#31616;&#21333;&#30340;&#31243;&#24207;&#25913;&#21464;&#32447;&#24615;&#27169;&#22411;&#30340;&#24494;&#35843;&#27493;&#39588;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models ca
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#35780;&#20272;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#20197;&#21450;&#25552;&#20986;&#22810;&#38454;&#27573;&#26694;&#26550;&#26469;&#35299;&#20915;&#20102;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.05680</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#38454;&#27573;&#26816;&#32034;&#25214;&#21040;&#24050;&#32463;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#65306;&#23454;&#29616;&#36328;&#35821;&#35328;&#12289;&#36328;&#25968;&#25454;&#38598;&#21644;&#38646;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning. (arXiv:2308.05680v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#35780;&#20272;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#20197;&#21450;&#25552;&#20986;&#22810;&#38454;&#27573;&#26694;&#26550;&#26469;&#35299;&#20915;&#20102;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#24050;&#32463;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#30340;&#20219;&#21153;&#26088;&#22312;&#26816;&#27979;&#24050;&#32463;&#32463;&#36807;&#20107;&#23454;&#26680;&#26597;&#30340;&#25925;&#20107;&#12290;&#25104;&#21151;&#26816;&#27979;&#21040;&#24050;&#34987;&#28548;&#28165;&#30340;&#22768;&#26126;&#19981;&#20165;&#20943;&#23569;&#20102;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#20154;&#21592;&#30340;&#25163;&#21160;&#21162;&#21147;&#65292;&#36824;&#21487;&#20197;&#26377;&#21161;&#20110;&#20943;&#32531;&#34394;&#20551;&#20449;&#24687;&#30340;&#20256;&#25773;&#12290;&#30001;&#20110;&#32570;&#20047;&#21487;&#29992;&#25968;&#25454;&#65292;&#36825;&#26159;&#19968;&#20010;&#30740;&#31350;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#32771;&#34385;&#36328;&#35821;&#35328;&#20219;&#21153;&#26102;&#65292;&#21363;&#22312;&#26816;&#26597;&#30340;&#22312;&#32447;&#24086;&#23376;&#30340;&#35821;&#35328;&#19982;&#20107;&#23454;&#26680;&#26597;&#25991;&#31456;&#30340;&#35821;&#35328;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#26816;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#20197;&#19979;&#26041;&#24335;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65306;&#65288;i&#65289;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#20801;&#35768;&#23545;&#24050;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#36827;&#34892;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#30740;&#31350;&#65292;&#20351;&#29992;&#25512;&#25991;&#20316;&#20026;&#23545;&#20107;&#23454;&#26680;&#26597;&#25991;&#31456;&#25968;&#25454;&#24211;&#30340;&#26597;&#35810;&#65307;&#65288;ii&#65289;&#23637;&#31034;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#20197;&#35780;&#20272;&#32463;&#36807;&#24494;&#35843;&#21644;&#29616;&#25104;&#30340;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#65307;&#65288;iii&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22810;&#38454;&#27573;&#26694;&#26550;&#65292;&#23558;&#36825;&#20010;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of retrieving already debunked narratives aims to detect stories that have already been fact-checked. The successful detection of claims that have already been debunked not only reduces the manual efforts of professional fact-checkers but can also contribute to slowing the spread of misinformation. Mainly due to the lack of readily available data, this is an understudied problem, particularly when considering the cross-lingual task, i.e. the retrieval of fact-checking articles in a language different from the language of the online post being checked. This paper fills this gap by (i) creating a novel dataset to enable research on cross-lingual retrieval of already debunked narratives, using tweets as queries to a database of fact-checking articles; (ii) presenting an extensive experiment to benchmark fine-tuned and off-the-shelf multilingual pre-trained Transformer models for this task; and (iii) proposing a novel multistage framework that divides this cross-lingual debunk ret
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#20294;&#26159;&#20854;&#40065;&#26834;&#24615;&#20173;&#28982;&#23384;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.00050</link><description>&lt;p&gt;
&#22240;&#26524;&#25512;&#29702;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#24320;&#21551;&#22240;&#26524;&#30740;&#31350;&#30340;&#26032;&#31687;&#31456;
&lt;/p&gt;
&lt;p&gt;
Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00050
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#20294;&#26159;&#20854;&#40065;&#26834;&#24615;&#20173;&#28982;&#23384;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22240;&#26524;&#33021;&#21147;&#22791;&#21463;&#20105;&#35758;&#65292;&#24182;&#19988;&#23545;&#23558;&#20854;&#24212;&#29992;&#20110;&#21307;&#23398;&#12289;&#31185;&#23398;&#12289;&#27861;&#24459;&#21644;&#25919;&#31574;&#31561;&#20855;&#26377;&#31038;&#20250;&#24433;&#21709;&#21147;&#30340;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#35752;&#20102;LLMs&#21450;&#20854;&#22240;&#26524;&#25512;&#29702;&#30340;&#21306;&#21035;&#65292;&#20197;&#21450;&#28508;&#22312;&#30340;&#24314;&#26500;&#21644;&#27979;&#37327;&#25928;&#24230;&#23041;&#32961;&#12290;&#22522;&#20110;GPT-3.5&#21644;4&#30340;&#31639;&#27861;&#22312;&#22810;&#20010;&#22240;&#26524;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;LLMs&#23637;&#31034;&#20102;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#25216;&#26415;&#26469;&#35299;&#37322;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
&lt;/p&gt;</description></item></channel></rss>