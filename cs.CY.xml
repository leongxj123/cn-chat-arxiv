<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FADE&#30340;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#36890;&#36807;&#24494;&#35843;&#31574;&#30053;&#21160;&#24577;&#20943;&#36731;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#32676;&#20307;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2308.15651</link><description>&lt;p&gt;
&#22312;&#21160;&#24577;&#25512;&#33616;&#31995;&#32479;&#20013;&#30830;&#20445;&#29992;&#25143;&#20391;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Ensuring User-side Fairness in Dynamic Recommender Systems. (arXiv:2308.15651v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15651
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FADE&#30340;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#36890;&#36807;&#24494;&#35843;&#31574;&#30053;&#21160;&#24577;&#20943;&#36731;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#32676;&#20307;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#20391;&#32676;&#20307;&#20844;&#24179;&#24615;&#23545;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#65292;&#23427;&#26088;&#22312;&#20943;&#36731;&#30001;&#25935;&#24863;&#23646;&#24615;&#65288;&#22914;&#24615;&#21035;&#12289;&#31181;&#26063;&#25110;&#24180;&#40836;&#65289;&#23450;&#20041;&#30340;&#29992;&#25143;&#32676;&#20307;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#24046;&#24322;&#24448;&#24448;&#20250;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#25345;&#32493;&#23384;&#22312;&#29978;&#33267;&#22686;&#21152;&#12290;&#36825;&#38656;&#35201;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#26377;&#25928;&#35299;&#20915;&#29992;&#25143;&#20391;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#28982;&#32780;&#36825;&#22312;&#25991;&#29486;&#20013;&#24456;&#23569;&#34987;&#25506;&#35752;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#30830;&#20445;&#29992;&#25143;&#20391;&#20844;&#24179;&#24615;&#65288;&#21363;&#20943;&#23569;&#24615;&#33021;&#24046;&#24322;&#65289;&#30340;&#20856;&#22411;&#26041;&#27861;&#8212;&#8212;&#20844;&#24179;&#32422;&#26463;&#37325;&#26032;&#25490;&#21517;&#65292;&#22312;&#21160;&#24577;&#35774;&#23450;&#20013;&#38754;&#20020;&#20004;&#20010;&#22522;&#26412;&#25361;&#25112;&#65306;&#65288;1&#65289;&#22522;&#20110;&#25490;&#21517;&#30340;&#20844;&#24179;&#32422;&#26463;&#30340;&#38750;&#21487;&#24494;&#24615;&#65292;&#38459;&#30861;&#20102;&#31471;&#21040;&#31471;&#35757;&#32451;&#33539;&#24335;&#65307;&#65288;2&#65289;&#26102;&#38388;&#25928;&#29575;&#20302;&#19979;&#65292;&#38459;&#30861;&#20102;&#23545;&#29992;&#25143;&#20559;&#22909;&#21464;&#21270;&#30340;&#24555;&#36895;&#36866;&#24212;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FADE&#30340;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#36890;&#36807;&#24494;&#35843;&#31574;&#30053;&#21160;&#24577;&#20943;&#36731;&#24615;&#33021;&#24046;&#24322;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#65292;FADE&#25552;&#20986;&#20102;&#19968;&#31181; fine-tuning &#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
User-side group fairness is crucial for modern recommender systems, as it aims to alleviate performance disparity between groups of users defined by sensitive attributes such as gender, race, or age. We find that the disparity tends to persist or even increase over time. This calls for effective ways to address user-side fairness in a dynamic environment, which has been infrequently explored in the literature. However, fairness-constrained re-ranking, a typical method to ensure user-side fairness (i.e., reducing performance disparity), faces two fundamental challenges in the dynamic setting: (1) non-differentiability of the ranking-based fairness constraint, which hinders the end-to-end training paradigm, and (2) time-inefficiency, which impedes quick adaptation to changes in user preferences. In this paper, we propose FAir Dynamic rEcommender (FADE), an end-to-end framework with fine-tuning strategy to dynamically alleviate performance disparity. To tackle the above challenges, FADE u
&lt;/p&gt;</description></item></channel></rss>