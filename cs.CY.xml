<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#35813;&#35770;&#25991;&#31995;&#32479;&#35780;&#20215;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#20854;&#22312;&#26089;&#26399;&#31579;&#26597;&#12289;&#25968;&#23383;&#24178;&#39044;&#21644;&#20854;&#20182;&#20020;&#24202;&#24212;&#29992;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;</title><link>https://arxiv.org/abs/2403.15401</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#30340;&#31995;&#32479;&#35780;&#20215;
&lt;/p&gt;
&lt;p&gt;
Large Language Model for Mental Health: A Systematic Review
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15401
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#31995;&#32479;&#35780;&#20215;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#20854;&#22312;&#26089;&#26399;&#31579;&#26597;&#12289;&#25968;&#23383;&#24178;&#39044;&#21644;&#20854;&#20182;&#20020;&#24202;&#24212;&#29992;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25968;&#23383;&#20581;&#24247;&#39046;&#22495;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#23637;&#29616;&#20986;&#20102;&#28508;&#22312;&#30340;&#24212;&#29992;&#24615;&#65292;&#20294;&#23427;&#20204;&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#30340;&#24212;&#29992;&#20173;&#22312;&#25345;&#32493;&#35752;&#35770;&#20013;&#12290;&#36825;&#39033;&#31995;&#32479;&#24615;&#35780;&#20215;&#26088;&#22312;&#24635;&#32467;&#21644;&#34920;&#24449;LLMs&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#35843;&#26597;LLMs&#26368;&#26032;&#30740;&#31350;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#35752;&#35770;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#26089;&#26399;&#31579;&#26597;&#12289;&#25968;&#23383;&#24178;&#39044;&#20197;&#21450;&#20854;&#20182;&#20020;&#24202;&#24212;&#29992;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;&#26681;&#25454;PRISMA&#25351;&#21335;&#65292;&#25105;&#20204;&#23457;&#26597;&#20102;PubMed&#12289;DBLP&#35745;&#31639;&#26426;&#31185;&#23398;&#25991;&#29486;&#25968;&#25454;&#24211;&#21644;IEEE Xplore&#19978;&#21457;&#34920;&#30340;&#33521;&#25991;&#25991;&#31456;&#65292;&#26102;&#38388;&#36328;&#24230;&#20026;2017&#24180;1&#26376;1&#26085;&#33267;2023&#24180;9&#26376;1&#26085;&#65292;&#37325;&#28857;&#20851;&#27880;&#24515;&#29702;&#20581;&#24247;&#21644;LLMs&#12290;&#35813;&#32508;&#36848;&#20998;&#26512;&#20102;32&#31687;&#25991;&#31456;&#65292;&#21253;&#25324;&#20351;&#29992;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#38598;&#36827;&#34892;&#24515;&#29702;&#20581;&#24247;&#20998;&#26512;&#30340;&#65288;n=13&#65289;&#12289;&#24515;&#29702;&#20581;&#24247;&#32842;&#22825;&#26426;&#22120;&#20154;&#65288;n=10&#65289;&#20197;&#21450;&#20854;&#20182;&#24515;&#29702;&#20581;&#24247;&#24212;&#29992;&#65288;n=9&#65289;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;LLMs&#22312;&#24515;&#29702;&#20581;&#24247;&#38382;&#39064;&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15401v1 Announce Type: cross  Abstract: Large language models (LLMs) have received much attention and shown their potential in digital health, while their application in mental health is subject to ongoing debate. This systematic review aims to summarize and characterize the use of LLMs in mental health by investigating the strengths and limitations of the latest work in LLMs and discusses the challenges and opportunities for early screening, digital interventions, and other clinical applications in mental health. Following PRISMA guidelines, we examined English articles from PubMed, DBLP Computer Science Bibliography, and IEEE Xplore, published between 1 January 2017, and 1 September 2023, focusing on mental health and LLMs. The review analyzed 32 articles, including mental health analysis using social media datasets (n=13), mental health chatbots (n=10), and other mental health applications (n=9). Findings reveal LLMs' effectiveness in mental health issue detection and the
&lt;/p&gt;</description></item><item><title>&#20154;&#31867;&#21644;&#20154;&#24037;&#26234;&#33021;&#24418;&#25104;&#30340;&#22810;&#23618;&#27425;&#38598;&#20307;&#26234;&#33021;&#32593;&#32476;&#65292;&#21487;&#20197;&#23454;&#29616;&#36229;&#36234;&#20219;&#19968;&#21333;&#29420;&#23454;&#20307;&#30340;&#38598;&#20307;&#26234;&#33021;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2403.10433</link><description>&lt;p&gt;
AI&#22686;&#24378;&#30340;&#38598;&#20307;&#26234;&#33021;&#65306;&#29616;&#29366;&#19982;&#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
AI-enhanced Collective Intelligence: The State of the Art and Prospects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10433
&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#21644;&#20154;&#24037;&#26234;&#33021;&#24418;&#25104;&#30340;&#22810;&#23618;&#27425;&#38598;&#20307;&#26234;&#33021;&#32593;&#32476;&#65292;&#21487;&#20197;&#23454;&#29616;&#36229;&#36234;&#20219;&#19968;&#21333;&#29420;&#23454;&#20307;&#30340;&#38598;&#20307;&#26234;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#30340;&#31038;&#20250;&#25361;&#25112;&#36229;&#20986;&#20102;&#20154;&#31867;&#20010;&#20307;&#25110;&#38598;&#20307;&#21162;&#21147;&#30340;&#33021;&#21147;&#12290;&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#30340;&#21457;&#23637;&#65292;&#20854;&#22312;&#20154;&#31867;&#38598;&#20307;&#20013;&#30340;&#35282;&#33394;&#23558;&#20174;&#36741;&#21161;&#24037;&#20855;&#36716;&#21464;&#20026;&#21442;&#19982;&#24335;&#25104;&#21592;&#12290;&#20154;&#31867;&#21644;&#20154;&#24037;&#26234;&#33021;&#25317;&#26377;&#20114;&#34917;&#30340;&#33021;&#21147;&#65292;&#24403;&#20108;&#32773;&#21327;&#21516;&#20316;&#29992;&#26102;&#65292;&#21487;&#20197;&#23454;&#29616;&#19968;&#31181;&#36229;&#36234;&#21333;&#29420;&#20154;&#31867;&#25110;&#20154;&#24037;&#26234;&#33021;&#38598;&#20307;&#33021;&#21147;&#30340;&#38598;&#20307;&#26234;&#33021;&#27700;&#24179;&#12290;&#28982;&#32780;&#65292;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#20013;&#30340;&#20132;&#20114;&#26412;&#36136;&#19978;&#26159;&#22797;&#26434;&#30340;&#65292;&#28041;&#21450;&#22797;&#26434;&#30340;&#36807;&#31243;&#21644;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#12290;&#26412;&#32508;&#36848;&#20174;&#32593;&#32476;&#31185;&#23398;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#26500;&#24819;&#20102;&#19968;&#20010;&#22810;&#23618;&#27425;&#30340;&#20154;&#24037;&#26234;&#33021;&#38598;&#20307;&#26234;&#33021;&#34920;&#31034;&#65292;&#21253;&#25324;&#35748;&#30693;&#23618;&#12289;&#29289;&#29702;&#23618;&#21644;&#20449;&#24687;&#23618;&#12290;&#22312;&#36825;&#20010;&#22810;&#23618;&#32593;&#32476;&#20013;&#65292;&#20154;&#31867;&#21644;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#23637;&#29616;&#20986;&#19981;&#21516;&#30340;&#29305;&#24449;&#65307;&#20154;&#31867;&#22312;&#22810;&#26679;&#24615;&#26041;&#38754;&#20174;&#34920;&#23618;&#21040;&#28145;&#23618;&#23646;&#24615;&#19981;&#21516;&#65292;&#32780;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#22312;&#31243;&#24230;&#19978;&#20063;&#26377;&#25152;&#21306;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10433v1 Announce Type: cross  Abstract: The current societal challenges exceed the capacity of human individual or collective effort alone. As AI evolves, its role within human collectives is poised to vary from an assistive tool to a participatory member. Humans and AI possess complementary capabilities that, when synergized, can achieve a level of collective intelligence that surpasses the collective capabilities of either humans or AI in isolation. However, the interactions in human-AI systems are inherently complex, involving intricate processes and interdependencies. This review incorporates perspectives from network science to conceptualize a multilayer representation of human-AI collective intelligence, comprising a cognition layer, a physical layer, and an information layer. Within this multilayer network, humans and AI agents exhibit varying characteristics; humans differ in diversity from surface-level to deep-level attributes, while AI agents range in degrees of f
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#25552;&#39640;&#23398;&#26415;&#20889;&#20316;&#36136;&#37327;&#21644;&#25928;&#29575;&#30340;&#21407;&#21017;&#21644;&#26041;&#27861;&#65292;&#21253;&#25324;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#26694;&#26550;&#12289;&#26377;&#25928;&#30340;&#25552;&#31034;&#25216;&#26415;&#21644;&#20004;&#38454;&#27573;&#27169;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#35748;&#30693;&#21368;&#36733;&#21644;&#24819;&#35937;&#21050;&#28608;&#30340;AI&#36741;&#21161;&#20889;&#20316;&#12290;</title><link>http://arxiv.org/abs/2310.17143</link><description>&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#25512;&#21160;&#23398;&#26415;&#20889;&#20316;&#65306;&#26694;&#26550;&#12289;&#25216;&#26415;&#21644;&#27880;&#24847;&#20107;&#39033;
&lt;/p&gt;
&lt;p&gt;
Supercharging academic writing with generative AI: framework, techniques, and caveats. (arXiv:2310.17143v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17143
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#25552;&#39640;&#23398;&#26415;&#20889;&#20316;&#36136;&#37327;&#21644;&#25928;&#29575;&#30340;&#21407;&#21017;&#21644;&#26041;&#27861;&#65292;&#21253;&#25324;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#26694;&#26550;&#12289;&#26377;&#25928;&#30340;&#25552;&#31034;&#25216;&#26415;&#21644;&#20004;&#38454;&#27573;&#27169;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#35748;&#30693;&#21368;&#36733;&#21644;&#24819;&#35937;&#21050;&#28608;&#30340;AI&#36741;&#21161;&#20889;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#26415;&#20889;&#20316;&#26159;&#30740;&#31350;&#39033;&#30446;&#20013;&#19981;&#21487;&#25110;&#32570;&#20294;&#36153;&#26102;&#36153;&#21147;&#30340;&#37096;&#20998;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25552;&#39640;&#23398;&#26415;&#20889;&#20316;&#36136;&#37327;&#21644;&#25928;&#29575;&#30340;&#21407;&#21017;&#21644;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#26694;&#26550;&#65292;&#35814;&#32454;&#38416;&#36848;&#20102;AI&#22312;&#20889;&#20316;&#20013;&#30340;&#29702;&#35770;&#22522;&#30784;&#65288;&#20026;&#20160;&#20040;&#65289;&#12289;&#36807;&#31243;&#65288;&#22914;&#20309;&#65289;&#21644;&#24615;&#36136;&#65288;&#20160;&#20040;&#65289;&#12290;&#35813;&#26694;&#26550;&#25351;&#20986;&#20102;&#30701;&#26399;&#21644;&#38271;&#26399;&#21442;&#19982;AI&#20889;&#20316;&#30340;&#21407;&#22240;&#21450;&#20854;&#22522;&#26412;&#26426;&#21046;&#65288;&#22914;&#35748;&#30693;&#21368;&#36733;&#21644;&#24819;&#35937;&#21050;&#28608;&#65289;&#12290;&#23427;&#25581;&#31034;&#20102;AI&#22312;&#25972;&#20010;&#20889;&#20316;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#65292;&#36890;&#36807;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#20889;&#20316;&#30340;&#20004;&#38454;&#27573;&#27169;&#22411;&#21644;&#20889;&#20316;&#36741;&#21161;&#31867;&#22411;&#21644;&#32423;&#21035;&#30340;&#27169;&#22411;&#34920;&#31034;&#20102;AI&#22312;&#20889;&#20316;&#20013;&#30340;&#24110;&#21161;&#26041;&#24335;&#12290;&#22522;&#20110;&#35813;&#26694;&#26550;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#22312;&#20889;&#20316;&#24120;&#35268;&#20013;&#25972;&#21512;AI&#30340;&#26377;&#25928;&#25552;&#31034;&#25216;&#26415;&#65288;&#22823;&#32434;&#12289;&#36215;&#33609;&#21644;&#32534;&#36753;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Academic writing is an indispensable yet laborious part of the research enterprise. This Perspective maps out principles and methods for using generative artificial intelligence (AI), specifically large language models (LLMs), to elevate the quality and efficiency of academic writing. We introduce a human-AI collaborative framework that delineates the rationale (why), process (how), and nature (what) of AI engagement in writing. The framework pinpoints both short-term and long-term reasons for engagement and their underlying mechanisms (e.g., cognitive offloading and imaginative stimulation). It reveals the role of AI throughout the writing process, conceptualized through a two-stage model for human-AI collaborative writing, and the nature of AI assistance in writing, represented through a model of writing-assistance types and levels. Building on this framework, we describe effective prompting techniques for incorporating AI into the writing routine (outlining, drafting, and editing) a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102; ChatGPT &#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126; ChatGPT &#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#65292;&#24182;&#19988;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#12290;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2304.00228</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models can rate news outlet credibility. (arXiv:2304.00228v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102; ChatGPT &#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126; ChatGPT &#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#65292;&#24182;&#19988;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#12290;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#20135;&#29983;&#24187;&#35937;&#12290;&#29616;&#20195;&#26368;&#20808;&#36827;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#22914;&#26032;&#30340; Bing&#65292;&#23581;&#35797;&#36890;&#36807;&#30452;&#25509;&#20174;&#20114;&#32852;&#32593;&#25910;&#38598;&#20449;&#24687;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21306;&#20998;&#20540;&#24471;&#20449;&#36182;&#30340;&#20449;&#24687;&#28304;&#23545;&#20110;&#21521;&#29992;&#25143;&#25552;&#20379;&#36866;&#24403;&#30340;&#20934;&#30830;&#24615;&#32972;&#26223;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#30693;&#21517;&#30340;LLM ChatGPT&#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#12290;&#22312;&#36866;&#24403;&#30340;&#25351;&#23548;&#19979;&#65292;ChatGPT&#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#65288;Spearmam's $\rho=0.54, p&lt;0.001$&#65289;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#65292;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;&#26410;&#26469;&#30340;LLMs&#24212;&#22686;&#24378;&#23427;&#20204;&#30340;&#23545;&#40784;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although large language models (LLMs) have shown exceptional performance in various natural language processing tasks, they are prone to hallucinations. State-of-the-art chatbots, such as the new Bing, attempt to mitigate this issue by gathering information directly from the internet to ground their answers. In this setting, the capacity to distinguish trustworthy sources is critical for providing appropriate accuracy contexts to users. Here we assess whether ChatGPT, a prominent LLM, can evaluate the credibility of news outlets. With appropriate instructions, ChatGPT can provide ratings for a diverse set of news outlets, including those in non-English languages and satirical sources, along with contextual explanations. Our results show that these ratings correlate with those from human experts (Spearmam's $\rho=0.54, p&lt;0.001$). These findings suggest that LLMs could be an affordable reference for credibility ratings in fact-checking applications. Future LLMs should enhance their align
&lt;/p&gt;</description></item></channel></rss>