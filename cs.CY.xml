<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#22823;&#35821;&#35328;&#27169;&#22411;&#19981;&#20165;&#33021;&#22815;&#22312;&#35782;&#21035;&#21644;&#21306;&#20998;&#24378;&#21183;&#21644;&#24369;&#21183;&#35770;&#28857;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#30340;&#20449;&#24565;&#21644;&#20154;&#21475;&#29305;&#24449;&#39044;&#27979;&#20854;&#31435;&#22330;&#65292;&#24182;&#30830;&#23450;&#35770;&#28857;&#23545;&#20010;&#20154;&#30340;&#21560;&#24341;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.00750</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#33021;&#35782;&#21035;&#20196;&#20154;&#20449;&#26381;&#30340;&#35770;&#28857;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Language Models Recognize Convincing Arguments?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00750
&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#19981;&#20165;&#33021;&#22815;&#22312;&#35782;&#21035;&#21644;&#21306;&#20998;&#24378;&#21183;&#21644;&#24369;&#21183;&#35770;&#28857;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#30340;&#20449;&#24565;&#21644;&#20154;&#21475;&#29305;&#24449;&#39044;&#27979;&#20854;&#31435;&#22330;&#65292;&#24182;&#30830;&#23450;&#35770;&#28857;&#23545;&#20010;&#20154;&#30340;&#21560;&#24341;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26174;&#33879;&#19988;&#19981;&#26029;&#22686;&#24378;&#30340;&#33021;&#21147;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#21487;&#33021;&#34987;&#28389;&#29992;&#29992;&#26469;&#21019;&#36896;&#20010;&#24615;&#21270;&#12289;&#20196;&#20154;&#20449;&#26381;&#30340;&#34394;&#20551;&#20449;&#24687;&#21644;&#23459;&#20256;&#30340;&#25285;&#24551;&#12290;&#20026;&#20102;&#28145;&#20837;&#20102;&#35299;LLMs&#30340;&#35828;&#26381;&#33021;&#21147;&#65292;&#32780;&#21448;&#19981;&#30452;&#25509;&#19982;&#20154;&#31867;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#25552;&#20986;&#30740;&#31350;&#23427;&#20204;&#22312;&#26816;&#27979;&#20196;&#20154;&#20449;&#26381;&#30340;&#35770;&#28857;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#36890;&#36807;&#28155;&#21152;&#36777;&#35770;&#12289;&#25237;&#31080;&#21644;&#29992;&#25143;&#29305;&#24449;&#26469;&#25193;&#23637;&#20102;Durmus&#21644;Cardie&#65288;2018&#65289;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#34913;&#37327;LLMs&#33021;&#21147;&#30340;&#20219;&#21153;&#65292;&#21253;&#25324;&#65288;1&#65289;&#21306;&#20998;&#24378;&#21183;&#21644;&#24369;&#21183;&#35770;&#28857;&#65292;&#65288;2&#65289;&#22522;&#20110;&#20449;&#24565;&#21644;&#20154;&#21475;&#29305;&#24449;&#39044;&#27979;&#31435;&#22330;&#65292;&#20197;&#21450;&#65288;3&#65289;&#26681;&#25454;&#20010;&#20154;&#29305;&#24449;&#30830;&#23450;&#23545;&#19968;&#20010;&#35770;&#28857;&#30340;&#21560;&#24341;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;LLMs&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#34920;&#29616;&#19982;&#20154;&#31867;&#19981;&#30456;&#19978;&#19979;&#65292;&#24182;&#19988;&#32467;&#21512;&#19981;&#21516;LLMs&#30340;&#39044;&#27979;&#21487;&#20197;&#33719;&#24471;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#29978;&#33267;&#36229;&#36807;&#20154;&#31867;&#30340;&#34920;&#29616;&#12290;&#38543;&#25991;&#38468;&#24102;&#21457;&#24067;&#30340;&#25968;&#25454;&#21644;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00750v1 Announce Type: new  Abstract: The remarkable and ever-increasing capabilities of Large Language Models (LLMs) have raised concerns about their potential misuse for creating personalized, convincing misinformation and propaganda. To gain insights into LLMs' persuasive capabilities without directly engaging in experimentation with humans, we propose studying their performance on the related task of detecting convincing arguments. We extend a dataset by Durmus &amp; Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs' ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, even surpassing human performance. The data and code released with 
&lt;/p&gt;</description></item><item><title>GreenLLaMA&#26159;&#19968;&#31181;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35299;&#27602;&#26694;&#26550;&#65292;&#36890;&#36807;&#36328;&#24179;&#21488;&#35821;&#26009;&#24211;&#35757;&#32451;&#20986;&#30340;&#27169;&#22411;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.15951</link><description>&lt;p&gt;
GreenLLaMA: &#19968;&#31181;&#24102;&#26377;&#35299;&#37322;&#30340;&#35299;&#27602;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
GreenLLaMA: A Framework for Detoxification with Explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15951
&lt;/p&gt;
&lt;p&gt;
GreenLLaMA&#26159;&#19968;&#31181;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35299;&#27602;&#26694;&#26550;&#65292;&#36890;&#36807;&#36328;&#24179;&#21488;&#35821;&#26009;&#24211;&#35757;&#32451;&#20986;&#30340;&#27169;&#22411;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#20851;&#20110;&#35299;&#27602;&#30340;&#30740;&#31350;&#24037;&#20316;&#20998;&#25955;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#65292;&#22240;&#20026;&#23427;&#20204;&#24182;&#27809;&#26377;&#28085;&#30422;&#21040;&#30495;&#23454;&#22330;&#26223;&#20013;&#25152;&#38656;&#30340;&#25152;&#26377;&#35299;&#27602;&#26041;&#38754;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#23558;&#24320;&#21457;&#35299;&#27602;&#27169;&#22411;&#30340;&#20219;&#21153;&#23616;&#38480;&#22312;&#20165;&#35265;&#36807;&#30340;&#24179;&#21488;&#23376;&#38598;&#19978;&#65292;&#27809;&#26377;&#25506;&#35752;&#27169;&#22411;&#22312;&#26410;&#30693;&#24179;&#21488;&#19978;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#24037;&#20316;&#27809;&#26377;&#35299;&#20915;&#19981;&#21487;&#35299;&#27602;&#24615;&#36825;&#19968;&#29616;&#35937;&#65292;&#21363;&#27602;&#24615;&#25991;&#26412;&#26080;&#27861;&#22312;&#19981;&#25913;&#21464;&#21547;&#20041;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35299;&#27602;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GreenLLaMA&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35299;&#27602;&#26694;&#26550;&#65292;&#26088;&#22312;&#20943;&#36731;&#19978;&#36848;&#38480;&#21046;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#20010;&#36328;&#24179;&#21488;&#20266;&#24182;&#34892;&#35821;&#26009;&#24211;&#65292;&#24212;&#29992;&#22810;&#27493;&#25968;&#25454;&#22788;&#29702;&#21644;&#29983;&#25104;&#31574;&#30053;&#21033;&#29992;ChatGPT&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36328;&#24179;&#21488;&#35821;&#26009;&#24211;&#35757;&#32451;&#19968;&#22871;&#35299;&#27602;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#35299;&#27602;&#27169;&#22411;&#20248;&#20110;&#20351;&#29992;&#20154;&#24037;&#27880;&#37322;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15951v1 Announce Type: cross  Abstract: Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose GreenLLaMA, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated par
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;SMILE&#26041;&#27861;&#65292;&#20351;&#29992;ChatGPT&#23558;&#20844;&#20849;&#21333;&#36718;&#23545;&#35805;&#25193;&#23637;&#20026;&#22810;&#36718;&#23545;&#35805;&#65292;&#29983;&#25104;&#20102;&#22823;&#35268;&#27169;&#12289;&#22810;&#26679;&#21270;&#12289;&#25509;&#36817;&#30495;&#23454;&#29983;&#27963;&#30340;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#35821;&#26009;&#24211;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#19987;&#38376;&#30340;&#23545;&#35805;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2305.00450</link><description>&lt;p&gt;
SMILE&#65306;&#21033;&#29992;ChatGPT&#23454;&#29616;&#21333;&#36718;&#21040;&#22810;&#36718;&#21253;&#23481;&#24615;&#35821;&#35328;&#25193;&#23637;&#30340;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support. (arXiv:2305.00450v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;SMILE&#26041;&#27861;&#65292;&#20351;&#29992;ChatGPT&#23558;&#20844;&#20849;&#21333;&#36718;&#23545;&#35805;&#25193;&#23637;&#20026;&#22810;&#36718;&#23545;&#35805;&#65292;&#29983;&#25104;&#20102;&#22823;&#35268;&#27169;&#12289;&#22810;&#26679;&#21270;&#12289;&#25509;&#36817;&#30495;&#23454;&#29983;&#27963;&#30340;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#35821;&#26009;&#24211;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#19987;&#38376;&#30340;&#23545;&#35805;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#19987;&#38376;&#30340;&#23545;&#35805;&#31995;&#32479;&#20197;&#25552;&#20379;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#24050;&#25104;&#20026;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#28857;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20010;&#20154;&#20449;&#24687;&#30340;&#25935;&#24863;&#24615;&#20197;&#21450;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#65292;&#33719;&#21462;&#22823;&#35268;&#27169;&#30340;&#30495;&#23454;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SMILE&#26041;&#27861;&#65292;&#19968;&#31181;&#20351;&#29992;ChatGPT&#23558;&#20844;&#20849;&#21333;&#36718;&#23545;&#35805;&#25193;&#23637;&#20026;&#22810;&#36718;&#23545;&#35805;&#30340;&#21253;&#23481;&#24615;&#35821;&#35328;&#25193;&#23637;&#25216;&#26415;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#21021;&#27493;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#39564;&#35777;&#20102;SMILE&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#20351;&#29992;&#21644;&#26410;&#20351;&#29992;SMILE&#26041;&#27861;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#20840;&#38754;&#31995;&#32479;&#30340;&#23545;&#27604;&#20998;&#26512;&#65292;&#35777;&#26126;SMILE&#26041;&#27861;&#21487;&#20197;&#20135;&#29983;&#22823;&#35268;&#27169;&#12289;&#22810;&#26679;&#21270;&#12289;&#25509;&#36817;&#30495;&#23454;&#29983;&#27963;&#30340;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#35821;&#26009;&#24211;&#65292;&#21253;&#25324;&#23545;&#35805;&#20027;&#39064;&#12289;&#35789;&#27719;&#21644;&#35821;&#20041;&#29305;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#25910;&#38598;&#30340;&#35821;&#26009;&#24211;&#26469;&#35757;&#32451;&#21644;&#35780;&#20272;&#19987;&#38376;&#30340;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been an increasing research interest in developing specialized dialogue systems that can offer mental health support. However, gathering large-scale and real-life multi-turn conversations for mental health support poses challenges due to the sensitivity of personal information, as well as the time and cost involved. To address these issues, we introduce the SMILE approach, an inclusive language expansion technique that employs ChatGPT to extend public single-turn dialogues into multi-turn ones. Our research first presents a preliminary exploratory study that validates the effectiveness of the SMILE approach. Furthermore, we conduct a comprehensive and systematic contrastive analysis of datasets generated with and without the SMILE approach, demonstrating that the SMILE method results in a large-scale, diverse, and close-to-real-life multi-turn mental health support conversation corpus, including dialog topics, lexical and semantic features. Finally, we use the collected corpu
&lt;/p&gt;</description></item></channel></rss>