<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#26412;&#30740;&#31350;&#26159;&#31532;&#19968;&#20010;&#20840;&#38754;&#35843;&#26597;&#27169;&#22411;&#35299;&#37322;&#20013;&#38544;&#31169;&#25915;&#20987;&#21450;&#20854;&#23545;&#25239;&#25514;&#26045;&#30340;&#35770;&#25991;&#65292;&#36890;&#36807;&#20998;&#31867;&#38544;&#31169;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;&#65292;&#21021;&#27493;&#25506;&#35752;&#20102;&#38544;&#31169;&#27844;&#28431;&#21407;&#22240;&#65292;&#25552;&#20986;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2404.00673</link><description>&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#22411;&#27169;&#22411;&#35299;&#37322;&#30740;&#31350;&#32508;&#36848;&#65306;&#38544;&#31169;&#39118;&#38505;&#12289;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;
&lt;/p&gt;
&lt;p&gt;
A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26159;&#31532;&#19968;&#20010;&#20840;&#38754;&#35843;&#26597;&#27169;&#22411;&#35299;&#37322;&#20013;&#38544;&#31169;&#25915;&#20987;&#21450;&#20854;&#23545;&#25239;&#25514;&#26045;&#30340;&#35770;&#25991;&#65292;&#36890;&#36807;&#20998;&#31867;&#38544;&#31169;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;&#65292;&#21021;&#27493;&#25506;&#35752;&#20102;&#38544;&#31169;&#27844;&#28431;&#21407;&#22240;&#65292;&#25552;&#20986;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#30340;&#37319;&#29992;&#19981;&#26029;&#25193;&#22823;&#65292;&#35299;&#20915;&#20854;&#38544;&#31169;&#24433;&#21709;&#30340;&#32039;&#36843;&#24615;&#21464;&#24471;&#26356;&#21152;&#36843;&#20999;&#12290;&#23613;&#31649;&#22312;&#20154;&#24037;&#26234;&#33021;&#38544;&#31169;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#26377;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#38544;&#31169;&#20445;&#25252;&#22411;&#27169;&#22411;&#35299;&#37322;&#21364;&#40092;&#26377;&#20851;&#27880;&#12290;&#26412;&#25991;&#39318;&#27425;&#20840;&#38754;&#35843;&#26597;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#38544;&#31169;&#25915;&#20987;&#21450;&#20854;&#23545;&#25239;&#25514;&#26045;&#12290;&#25105;&#20204;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#36129;&#29486;&#21253;&#25324;&#23545;&#30740;&#31350;&#35770;&#25991;&#36827;&#34892;&#24443;&#24213;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20114;&#36830;&#25509;&#30340;&#20998;&#31867;&#27861;&#65292;&#20415;&#20110;&#26681;&#25454;&#30446;&#26631;&#35299;&#37322;&#23545;&#38544;&#31169;&#25915;&#20987;&#21644;&#23545;&#25239;&#25514;&#26045;&#36827;&#34892;&#20998;&#31867;&#12290;&#26412;&#30740;&#31350;&#36824;&#23545;&#38544;&#31169;&#27844;&#28431;&#21407;&#22240;&#36827;&#34892;&#20102;&#21021;&#27493;&#35843;&#26597;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25105;&#20204;&#20998;&#26512;&#20013;&#21457;&#29616;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;&#35813;&#35843;&#26597;&#26088;&#22312;&#25104;&#20026;&#30740;&#31350;&#30028;&#30340;&#23453;&#36149;&#36164;&#28304;&#65292;&#24182;&#20026;&#36825;&#19968;&#39046;&#22495;&#30340;&#26032;&#25163;&#25552;&#20379;&#26126;&#30830;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00673v1 Announce Type: cross  Abstract: As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorisation of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have estab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30452;&#25509;&#21033;&#29992;&#37197;&#23545;&#30340;OSM&#25968;&#25454;&#21644;&#20809;&#23398;&#22270;&#20687;&#36827;&#34892;&#22303;&#22320;&#35206;&#30422;&#21464;&#21270;&#26816;&#27979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#35937;&#24341;&#23548;&#30340;Transformer&#26550;&#26500;&#65292;&#20174;&#32780;&#25299;&#23485;&#20102;&#21464;&#21270;&#26816;&#27979;&#20219;&#21153;&#30340;&#33539;&#22260;&#65292;&#24182;&#26174;&#33879;&#20943;&#23569;&#20102;&#35745;&#31639;&#24320;&#38144;&#21644;&#20869;&#23384;&#36127;&#25285;&#12290;</title><link>http://arxiv.org/abs/2310.02674</link><description>&lt;p&gt;
&#21033;&#29992;&#37197;&#23545;&#30340;OpenStreetMap&#25968;&#25454;&#21644;&#20809;&#23398;&#39640;&#20998;&#36776;&#29575;&#24433;&#20687;&#36827;&#34892;&#22303;&#22320;&#35206;&#30422;&#21464;&#21270;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Land-cover change detection using paired OpenStreetMap data and optical high-resolution imagery via object-guided Transformer. (arXiv:2310.02674v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30452;&#25509;&#21033;&#29992;&#37197;&#23545;&#30340;OSM&#25968;&#25454;&#21644;&#20809;&#23398;&#22270;&#20687;&#36827;&#34892;&#22303;&#22320;&#35206;&#30422;&#21464;&#21270;&#26816;&#27979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#35937;&#24341;&#23548;&#30340;Transformer&#26550;&#26500;&#65292;&#20174;&#32780;&#25299;&#23485;&#20102;&#21464;&#21270;&#26816;&#27979;&#20219;&#21153;&#30340;&#33539;&#22260;&#65292;&#24182;&#26174;&#33879;&#20943;&#23569;&#20102;&#35745;&#31639;&#24320;&#38144;&#21644;&#20869;&#23384;&#36127;&#25285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20809;&#23398;&#39640;&#20998;&#36776;&#29575;&#24433;&#20687;&#21644;OpenStreetMap&#65288;OSM&#65289;&#25968;&#25454;&#26159;&#22303;&#22320;&#35206;&#30422;&#21464;&#21270;&#26816;&#27979;&#30340;&#20004;&#20010;&#37325;&#35201;&#25968;&#25454;&#28304;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#21033;&#29992;OSM&#25968;&#25454;&#26469;&#36741;&#21161;&#22810;&#26102;&#26399;&#20809;&#23398;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#30340;&#21464;&#21270;&#26816;&#27979;&#12290;&#26412;&#25991;&#36890;&#36807;&#30452;&#25509;&#21033;&#29992;&#37197;&#23545;&#30340;OSM&#25968;&#25454;&#21644;&#20809;&#23398;&#22270;&#20687;&#36827;&#34892;&#22303;&#22320;&#35206;&#30422;&#21464;&#21270;&#26816;&#27979;&#65292;&#25299;&#23485;&#20102;&#21464;&#21270;&#26816;&#27979;&#20219;&#21153;&#30340;&#33539;&#22260;&#65292;&#28085;&#30422;&#26356;&#22810;&#21160;&#24577;&#22320;&#29699;&#35266;&#27979;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#35937;&#24341;&#23548;&#30340;Transformer&#65288;ObjFormer&#65289;&#26550;&#26500;&#65292;&#23558;&#27969;&#34892;&#30340;&#22522;&#20110;&#23545;&#35937;&#30340;&#22270;&#20687;&#20998;&#26512;&#65288;OBIA&#65289;&#25216;&#26415;&#19982;&#20808;&#36827;&#30340;&#35270;&#35273;Transformer&#26550;&#26500;&#33258;&#28982;&#22320;&#32467;&#21512;&#36215;&#26469;&#12290;&#24341;&#20837;OBIA&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#33258;&#27880;&#24847;&#21147;&#27169;&#22359;&#20013;&#30340;&#35745;&#31639;&#24320;&#38144;&#21644;&#20869;&#23384;&#36127;&#25285;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25152;&#25552;&#20986;&#30340;ObjFormer&#20855;&#26377;&#23618;&#27425;&#20266;&#23402;&#29983;&#32534;&#30721;&#22120;&#65292;&#21253;&#21547;&#23545;&#35937;&#24341;&#23548;&#33258;&#27880;&#24847;&#21147;&#27169;&#22359;&#65292;&#29992;&#20110;&#25552;&#21462;&#20195;&#34920;&#24615;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optical high-resolution imagery and OpenStreetMap (OSM) data are two important data sources for land-cover change detection. Previous studies in these two data sources focus on utilizing the information in OSM data to aid the change detection on multi-temporal optical high-resolution images. This paper pioneers the direct detection of land-cover changes utilizing paired OSM data and optical imagery, thereby broadening the horizons of change detection tasks to encompass more dynamic earth observations. To this end, we propose an object-guided Transformer (ObjFormer) architecture by naturally combining the prevalent object-based image analysis (OBIA) technique with the advanced vision Transformer architecture. The introduction of OBIA can significantly reduce the computational overhead and memory burden in the self-attention module. Specifically, the proposed ObjFormer has a hierarchical pseudo-siamese encoder consisting of object-guided self-attention modules that extract representative
&lt;/p&gt;</description></item></channel></rss>