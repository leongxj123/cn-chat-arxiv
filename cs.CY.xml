<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#35813;&#30740;&#31350;&#23545;&#24403;&#21069;&#28145;&#24230;&#23398;&#20064;&#34892;&#20154;&#26816;&#27979;&#22120;&#30340;&#20844;&#24179;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#20102;&#19982;&#24180;&#40836;&#30456;&#20851;&#30340;&#37325;&#35201;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2308.02935</link><description>&lt;p&gt;
&#25581;&#31034;&#30450;&#28857;&#65306;&#23545;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#20844;&#24179;&#24615;&#30340;&#20851;&#38190;&#23457;&#26597;
&lt;/p&gt;
&lt;p&gt;
Unveiling the Blind Spots: A Critical Examination of Fairness in Autonomous Driving Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2308.02935
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;&#24403;&#21069;&#28145;&#24230;&#23398;&#20064;&#34892;&#20154;&#26816;&#27979;&#22120;&#30340;&#20844;&#24179;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#20102;&#19982;&#24180;&#40836;&#30456;&#20851;&#30340;&#37325;&#35201;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20027;&#39550;&#39542;&#31995;&#32479;&#24050;&#32463;&#25193;&#23637;&#20102;&#26234;&#33021;&#36710;&#36742;&#29289;&#32852;&#32593;&#30340;&#33539;&#22260;&#65292;&#24182;&#25104;&#20026;Web&#29983;&#24577;&#31995;&#32479;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#31867;&#20284;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;Web&#30340;&#24212;&#29992;&#31243;&#24207;&#65292;&#20844;&#24179;&#24615;&#23545;&#20110;&#30830;&#20445;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#30340;&#39640;&#36136;&#37327;&#26159;&#19968;&#20010;&#37325;&#35201;&#26041;&#38754;&#65292;&#29305;&#21035;&#26159;&#22312;&#20854;&#20013;&#30340;&#34892;&#20154;&#26816;&#27979;&#22120;&#30340;&#32972;&#26223;&#19979;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#20851;&#20110;&#24403;&#21069;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#30340;&#34892;&#20154;&#26816;&#27979;&#22120;&#20844;&#24179;&#24615;&#30340;&#32508;&#21512;&#35780;&#20272;&#22312;&#25991;&#29486;&#20013;&#23578;&#26410;&#20986;&#29616;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#22312;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#20843;&#31181;&#34987;&#24191;&#27867;&#25506;&#32034;&#30340;DL&#34892;&#20154;&#26816;&#27979;&#22120;&#22312;&#20154;&#21475;&#32479;&#35745;&#23398;&#32676;&#20307;&#20043;&#38388;&#30340;&#34920;&#29616;&#12290;&#20026;&#20102;&#23454;&#29616;&#24443;&#24213;&#30340;&#20844;&#24179;&#24615;&#35780;&#20272;&#65292;&#25105;&#20204;&#20026;&#25968;&#25454;&#38598;&#25552;&#20379;&#20102;&#24191;&#27867;&#30340;&#27880;&#37322;&#65292;&#20849;&#28041;&#21450;8,311&#24352;&#22270;&#20687;&#65292;16,070&#20010;&#24615;&#21035;&#26631;&#31614;&#65292;20,115&#20010;&#24180;&#40836;&#26631;&#31614;&#21644;3,513&#20010;&#32932;&#33394;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#20102;&#19982;&#24180;&#40836;&#30456;&#20851;&#30340;&#37325;&#35201;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2308.02935v2 Announce Type: replace-cross  Abstract: Autonomous driving systems have extended the spectrum of Web of Things for intelligent vehicles and have become an important component of the Web ecosystem. Similar to traditional Web-based applications, fairness is an essential aspect for ensuring the high quality of autonomous driving systems, particularly in the context of pedestrian detectors within them. However, there is an absence in the literature of a comprehensive assessment of the fairness of current Deep Learning (DL)-based pedestrian detectors. To fill the gap, we evaluate eight widely-explored DL-based pedestrian detectors across demographic groups on large-scale real-world datasets. To enable a thorough fairness evaluation, we provide extensive annotations for the datasets, resulting in 8,311 images with 16,070 gender labels, 20,115 age labels, and 3,513 skin tone labels. Our findings reveal significant fairness issues related to age. The undetected proportions f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FFALM&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26045;&#21152;&#20844;&#24179;&#32422;&#26463;&#21644;&#35299;&#20915;&#26497;&#23567;&#21270;&#26497;&#22823;&#22238;&#24402;&#38382;&#39064;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#32676;&#20307;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;FFALM&#22312;&#22788;&#29702;&#20005;&#37325;&#32479;&#35745;&#24322;&#36136;&#24615;&#38382;&#39064;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.04417</link><description>&lt;p&gt;
&#20855;&#26377;&#25910;&#25947;&#20445;&#35777;&#30340;&#20844;&#27491;&#24863;&#30693;&#32852;&#37030;&#26497;&#23567;&#21270;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Fairness-aware Federated Minimax Optimization with Convergence Guarantee. (arXiv:2307.04417v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FFALM&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26045;&#21152;&#20844;&#24179;&#32422;&#26463;&#21644;&#35299;&#20915;&#26497;&#23567;&#21270;&#26497;&#22823;&#22238;&#24402;&#38382;&#39064;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#32676;&#20307;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;FFALM&#22312;&#22788;&#29702;&#20005;&#37325;&#32479;&#35745;&#24322;&#36136;&#24615;&#38382;&#39064;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#20445;&#25252;&#38544;&#31169;&#30340;&#29305;&#24615;&#65292;&#32852;&#37030;&#23398;&#20064; (FL) &#21560;&#24341;&#20102;&#30456;&#24403;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#31649;&#29702;&#29992;&#25143;&#25968;&#25454;&#30340;&#33258;&#30001;&#24230;&#19981;&#36275;&#21487;&#33021;&#23548;&#33268;&#32676;&#20307;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#21363;&#27169;&#22411;&#20559;&#21521;&#20110;&#25935;&#24863;&#22240;&#32032;&#35832;&#22914;&#31181;&#26063;&#25110;&#24615;&#21035;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#21517;&#20026;&#24102;&#26377;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#30340;&#20844;&#24179;&#32852;&#37030;&#24179;&#22343;&#27861; (FFALM)&#65292;&#19987;&#38376;&#29992;&#20110;&#35299;&#20915;FL&#20013;&#30340;&#32676;&#20307;&#20844;&#24179;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#35757;&#32451;&#30446;&#26631;&#26045;&#21152;&#20102;&#20844;&#24179;&#32422;&#26463;&#65292;&#24182;&#35299;&#20915;&#20102;&#21463;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#26497;&#23567;&#21270;&#26497;&#22823;&#22238;&#24402;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;FFALM&#30340;&#25910;&#25947;&#36895;&#29575;&#30340;&#29702;&#35770;&#19978;&#30028;&#12290;&#36890;&#36807;&#22312;CelebA&#21644;UTKFace&#25968;&#25454;&#38598;&#20013;&#20805;&#20998;&#32771;&#34385;&#20005;&#37325;&#32479;&#35745;&#24322;&#36136;&#24615;&#65292;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#20102;FFALM &#22312;&#25552;&#39640;&#20844;&#24179;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) has garnered considerable attention due to its privacy-preserving feature. Nonetheless, the lack of freedom in managing user data can lead to group fairness issues, where models are biased towards sensitive factors such as race or gender. To tackle this issue, this paper proposes a novel algorithm, fair federated averaging with augmented Lagrangian method (FFALM), designed explicitly to address group fairness issues in FL. Specifically, we impose a fairness constraint on the training objective and solve the minimax reformulation of the constrained optimization problem. Then, we derive the theoretical upper bound for the convergence rate of FFALM. The effectiveness of FFALM in improving fairness is shown empirically on CelebA and UTKFace datasets in the presence of severe statistical heterogeneity.
&lt;/p&gt;</description></item></channel></rss>