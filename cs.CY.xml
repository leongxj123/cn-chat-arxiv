<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#65292;&#36890;&#36807;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#26412;&#27604;&#36739;&#65292;&#24182;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#35780;&#20998;&#23610;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;Twitter&#19978;&#23545;&#24773;&#24863;&#35328;&#35770;&#30340;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.12049</link><description>&lt;p&gt;
Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models (&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#25552;&#31034;&#36827;&#34892;&#25991;&#26412;&#37197;&#23545;&#27604;&#36739;&#32553;&#25918;)
&lt;/p&gt;
&lt;p&gt;
Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models. (arXiv:2310.12049v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12049
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#65292;&#36890;&#36807;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#26412;&#27604;&#36739;&#65292;&#24182;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#35780;&#20998;&#23610;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;Twitter&#19978;&#23545;&#24773;&#24863;&#35328;&#35770;&#30340;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#32463;&#24120;&#38656;&#35201;&#22823;&#22411;&#35821;&#26009;&#24211;&#65292;&#38590;&#20197;&#22788;&#29702;&#30701;&#25991;&#26412;&#65292;&#25110;&#38656;&#35201;&#26377;&#26631;&#31614;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#26469;&#36827;&#34892;&#25991;&#26412;&#32553;&#25918;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#65288;CGCoT&#65289;&#65292;&#23427;&#20351;&#29992;&#35774;&#35745;&#29992;&#20110;&#24635;&#32467;&#24819;&#27861;&#24182;&#22312;&#25991;&#26412;&#20013;&#35782;&#21035;&#30446;&#26631;&#26041;&#30340;&#25552;&#31034;&#26469;&#29983;&#25104;&#27010;&#24565;&#29305;&#23450;&#30340;&#32454;&#20998;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#32534;&#30721;&#22120;&#20869;&#23481;&#20998;&#26512;&#30340;&#25351;&#23548;&#12290;CGCoT&#23558;&#37197;&#23545;&#25991;&#26412;&#27604;&#36739;&#20174;&#19968;&#20010;&#25512;&#29702;&#38382;&#39064;&#36716;&#21464;&#20026;&#19968;&#20010;&#27169;&#24335;&#35782;&#21035;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;LLM&#23545;&#27010;&#24565;&#29305;&#23450;&#30340;&#32454;&#20998;&#36827;&#34892;&#37197;&#23545;&#27604;&#36739;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#37197;&#23545;&#27604;&#36739;&#30340;&#32467;&#26524;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#19968;&#20010;&#35780;&#20998;&#23610;&#24230;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23545;Twitter&#19978;&#30340;&#24773;&#24863;&#35328;&#35770;&#36827;&#34892;&#32553;&#25918;&#12290;&#25105;&#20204;&#30340;&#27979;&#37327;&#20540;&#19982;&#20154;&#31867;&#21028;&#26029;&#30340;&#30456;&#20851;&#24615;&#27604;Wordfish&#31561;&#26367;&#20195;&#26041;&#27861;&#26356;&#24378;&#12290;&#38500;&#20102;&#19968;&#23567;&#32452;&#29992;&#20110;&#24320;&#21457;CGCoT&#25552;&#31034;&#30340;&#35797;&#39564;&#25968;&#25454;&#20043;&#22806;&#65292;...
&lt;/p&gt;
&lt;p&gt;
Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data. We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs). Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis. CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem. We then pairwise compare concept-specific breakdowns using an LLM. We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model. We use this approach to scale affective speech on Twitter. Our measures correlate more strongly with human judgments than alternative approaches like Wordfish. Besides a small set of pilot data to develop the CGCoT prompts, 
&lt;/p&gt;</description></item></channel></rss>