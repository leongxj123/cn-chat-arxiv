<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25932;&#23545;&#36755;&#20837;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#23450;&#20041;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#25932;&#23545;&#25915;&#20987;&#26041;&#27861;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2404.01356</link><description>&lt;p&gt;
&#36755;&#20837;&#25200;&#21160;&#23545;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#30340;&#21452;&#20995;&#21073;
&lt;/p&gt;
&lt;p&gt;
The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01356
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25932;&#23545;&#36755;&#20837;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#23450;&#20041;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#25932;&#23545;&#25915;&#20987;&#26041;&#27861;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#34987;&#35748;&#20026;&#23545;&#25932;&#23545;&#36755;&#20837;&#25200;&#21160;&#25935;&#24863;&#65292;&#23548;&#33268;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#25110;&#20010;&#20307;&#20844;&#24179;&#24615;&#38477;&#20302;&#12290;&#20026;&#20102;&#20849;&#21516;&#34920;&#24449;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#20010;&#20307;&#20844;&#24179;&#24615;&#23545;&#25932;&#23545;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#30340;&#26032;&#23450;&#20041;&#12290;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#35201;&#27714;&#24403;&#23454;&#20363;&#21450;&#20854;&#30456;&#20284;&#23545;&#24212;&#29289;&#21463;&#21040;&#36755;&#20837;&#25200;&#21160;&#26102;&#65292;&#39044;&#27979;&#19982;&#22320;&#38754;&#20107;&#23454;&#19968;&#33268;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#25932;&#23545;&#25915;&#20987;&#26041;&#27861;RAFair&#65292;&#20197;&#26292;&#38706;DNN&#20013;&#30340;&#34394;&#20551;&#25110;&#20559;&#35265;&#25932;&#23545;&#32570;&#38519;&#65292;&#36825;&#20123;&#32570;&#38519;&#20250;&#27450;&#39575;&#20934;&#30830;&#24615;&#25110;&#25439;&#23475;&#20010;&#20307;&#20844;&#24179;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#36825;&#26679;&#30340;&#25932;&#23545;&#23454;&#20363;&#21487;&#20197;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#33391;&#24615;&#25200;&#21160;&#26377;&#25928;&#22320;&#35299;&#20915;&#65292;&#20174;&#32780;&#20351;&#23427;&#20204;&#30340;&#39044;&#27979;&#20934;&#30830;&#32780;&#20844;&#24179;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25506;&#35752;&#20102;&#36755;&#20837;&#23545;&#20934;&#30830;&#20844;&#24179;&#24615;&#30340;&#21452;&#20995;&#21073;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01356v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) are known to be sensitive to adversarial input perturbations, leading to a reduction in either prediction accuracy or individual fairness. To jointly characterize the susceptibility of prediction accuracy and individual fairness to adversarial perturbations, we introduce a novel robustness definition termed robust accurate fairness. Informally, robust accurate fairness requires that predictions for an instance and its similar counterparts consistently align with the ground truth when subjected to input perturbations. We propose an adversarial attack approach dubbed RAFair to expose false or biased adversarial defects in DNN, which either deceive accuracy or compromise individual fairness. Then, we show that such adversarial instances can be effectively addressed by carefully designed benign perturbations, correcting their predictions to be accurate and fair. Our work explores the double-edged sword of input 
&lt;/p&gt;</description></item></channel></rss>