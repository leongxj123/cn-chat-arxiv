<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32842;&#22825;&#26426;&#22120;&#20154;&#36827;&#34892;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#30340;&#20154;&#30340;&#32463;&#21382;&#65292;&#20998;&#26512;&#20102;&#29992;&#25143;&#22914;&#20309;&#20026;&#32842;&#22825;&#26426;&#22120;&#20154;&#21019;&#24314;&#29420;&#29305;&#30340;&#25903;&#25345;&#35282;&#33394;&#65292;&#24182;&#20171;&#32461;&#20102;&#22312;&#24515;&#29702;&#20581;&#24247;&#32972;&#26223;&#19979;&#23558;&#20154;&#24037;&#26234;&#33021;&#19982;&#27835;&#30103;&#20215;&#20540;&#35266;&#30456;&#21305;&#37197;&#30340;&#27010;&#24565;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#35774;&#35745;&#24072;&#22788;&#29702;&#20262;&#29702;&#38382;&#39064;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2401.14362</link><description>&lt;p&gt;
&#25171;&#23383;&#30103;&#27861;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#20013;&#30340;&#24212;&#29992;&#32463;&#39564;
&lt;/p&gt;
&lt;p&gt;
The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support. (arXiv:2401.14362v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32842;&#22825;&#26426;&#22120;&#20154;&#36827;&#34892;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#30340;&#20154;&#30340;&#32463;&#21382;&#65292;&#20998;&#26512;&#20102;&#29992;&#25143;&#22914;&#20309;&#20026;&#32842;&#22825;&#26426;&#22120;&#20154;&#21019;&#24314;&#29420;&#29305;&#30340;&#25903;&#25345;&#35282;&#33394;&#65292;&#24182;&#20171;&#32461;&#20102;&#22312;&#24515;&#29702;&#20581;&#24247;&#32972;&#26223;&#19979;&#23558;&#20154;&#24037;&#26234;&#33021;&#19982;&#27835;&#30103;&#20215;&#20540;&#35266;&#30456;&#21305;&#37197;&#30340;&#27010;&#24565;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#35774;&#35745;&#24072;&#22788;&#29702;&#20262;&#29702;&#38382;&#39064;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#32842;&#22825;&#26426;&#22120;&#20154;&#20316;&#20026;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#24037;&#20855;&#65292;&#20294;&#26377;&#35777;&#25454;&#34920;&#26126;&#36890;&#29992;&#22411;LLM&#32842;&#22825;&#26426;&#22120;&#20154;&#20063;&#23384;&#22312;&#19968;&#23450;&#39118;&#38505;&#65292;&#22914;&#26524;&#35774;&#35745;&#19981;&#36127;&#36131;&#20219;&#21487;&#33021;&#20250;&#21361;&#21450;&#29992;&#25143;&#30340;&#31119;&#31049;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;LLM&#32842;&#22825;&#26426;&#22120;&#20154;&#36827;&#34892;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#30340;&#20154;&#30340;&#30495;&#23454;&#32463;&#21382;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#26469;&#33258;&#19981;&#21516;&#22269;&#23478;&#32972;&#26223;&#30340;21&#20010;&#20010;&#20154;&#36827;&#34892;&#35775;&#35848;&#65292;&#20998;&#26512;&#20102;&#29992;&#25143;&#22914;&#20309;&#20026;&#20182;&#20204;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#21019;&#24314;&#29420;&#29305;&#30340;&#25903;&#25345;&#35282;&#33394;&#65292;&#22635;&#34917;&#26085;&#24120;&#25252;&#29702;&#30340;&#31354;&#30333;&#65292;&#24182;&#22312;&#23547;&#27714;&#26469;&#33258;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#25903;&#25345;&#26102;&#22914;&#20309;&#23548;&#33322;&#30456;&#20851;&#30340;&#25991;&#21270;&#38480;&#21046;&#12290;&#25105;&#20204;&#23558;&#20998;&#26512;&#22522;&#20110;&#24515;&#29702;&#27835;&#30103;&#25991;&#29486;&#20013;&#26377;&#25928;&#25903;&#25345;&#30340;&#27010;&#24565;&#65292;&#24182;&#24341;&#20837;&#20102;AI&#19982;&#24515;&#29702;&#20581;&#24247;&#32972;&#26223;&#19979;&#30340;&#27835;&#30103;&#20215;&#20540;&#35266;&#23545;&#20854;&#36827;&#34892;&#21305;&#37197;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#35774;&#35745;&#24072;&#22914;&#20309;&#22788;&#29702;&#20262;&#29702;&#38382;&#39064;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
People experiencing severe distress increasingly use Large Language Model (LLM) chatbots as mental health support tools. Discussions on social media have described how engagements were lifesaving for some, but evidence suggests that general-purpose LLM chatbots also have notable risks that could endanger the welfare of users if not designed responsibly. In this study, we investigate the lived experiences of people who have used LLM chatbots for mental health support. We build on interviews with 21 individuals from globally diverse backgrounds to analyze how users create unique support roles for their chatbots, fill in gaps in everyday care, and navigate associated cultural limitations when seeking support from chatbots. We ground our analysis in psychotherapy literature around effective support, and introduce the concept of therapeutic alignment, or aligning AI with therapeutic values for mental health contexts. Our study offers recommendations for how designers can approach the ethica
&lt;/p&gt;</description></item></channel></rss>