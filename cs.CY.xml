<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#23433;&#20840;&#25361;&#25112;&#21450;&#23545;&#31574;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2402.12617</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#23433;&#20840;&#65306;&#25361;&#25112;&#19982;&#23545;&#31574;
&lt;/p&gt;
&lt;p&gt;
Generative AI Security: Challenges and Countermeasures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12617
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#23433;&#20840;&#25361;&#25112;&#21450;&#23545;&#31574;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12617v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#22312;&#35768;&#22810;&#34892;&#19994;&#30340;&#19981;&#26029;&#25193;&#23637;&#24341;&#21457;&#20102;&#20154;&#20204;&#30340;&#20852;&#22859;&#21644;&#22686;&#21152;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25152;&#24102;&#26469;&#30340;&#29420;&#29305;&#23433;&#20840;&#25361;&#25112;&#65292;&#24182;&#27010;&#36848;&#20102;&#31649;&#29702;&#36825;&#20123;&#39118;&#38505;&#30340;&#28508;&#22312;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12617v1 Announce Type: cross  Abstract: Generative AI's expanding footprint across numerous industries has led to both excitement and increased scrutiny. This paper delves into the unique security challenges posed by Generative AI, and outlines potential research directions for managing these risks.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#65288;LFMs&#65289;&#20013;&#30340;&#28798;&#38590;&#24615;&#32487;&#25215;&#38382;&#39064;&#65292;&#25351;&#20986;&#20102;&#20174;&#26377;&#20559;&#35265;&#30340;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#25968;&#25454;&#21040;LFMs&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#30340;&#24369;&#28857;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;UIM&#26694;&#26550;&#65292;&#26088;&#22312;&#29702;&#35299;LFMs&#30340;&#28798;&#38590;&#24615;&#32487;&#25215;&#38382;&#39064;&#65292;&#24182;&#35299;&#37322;&#20854;&#20013;&#30340;&#21547;&#20041;&#12290;</title><link>https://arxiv.org/abs/2402.01909</link><description>&lt;p&gt;
&#20851;&#20110;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#30340;&#28798;&#38590;&#24615;&#32487;&#25215;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On Catastrophic Inheritance of Large Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01909
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#65288;LFMs&#65289;&#20013;&#30340;&#28798;&#38590;&#24615;&#32487;&#25215;&#38382;&#39064;&#65292;&#25351;&#20986;&#20102;&#20174;&#26377;&#20559;&#35265;&#30340;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#25968;&#25454;&#21040;LFMs&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#30340;&#24369;&#28857;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;UIM&#26694;&#26550;&#65292;&#26088;&#22312;&#29702;&#35299;LFMs&#30340;&#28798;&#38590;&#24615;&#32487;&#25215;&#38382;&#39064;&#65292;&#24182;&#35299;&#37322;&#20854;&#20013;&#30340;&#21547;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#65288;LFMs&#65289;&#22768;&#31216;&#20855;&#26377;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#28982;&#32780;&#20154;&#20204;&#23545;&#23427;&#20204;&#22312;&#26426;&#22120;&#23398;&#20064;&#20197;&#21450;&#20854;&#20182;&#21508;&#20010;&#23398;&#31185;&#20013;&#30340;&#31070;&#31192;&#21644;&#38590;&#20197;&#35299;&#37322;&#30340;&#28508;&#21147;&#25552;&#20986;&#20102;&#26497;&#22823;&#20851;&#20999;&#12290;&#22312;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#34987;&#24573;&#35270;&#30340;&#38382;&#39064;&#65292;&#21363;LFMs&#20013;&#26681;&#28145;&#33922;&#22266;&#30340;&#28798;&#38590;&#24615;&#32487;&#25215;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#20174;&#26377;&#20559;&#35265;&#30340;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#25968;&#25454;&#21040;LFMs&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#30340;&#24369;&#28857;&#21644;&#38480;&#21046;&#65292;&#21253;&#25324;&#21463;&#25439;&#12289;&#38271;&#23614;&#12289;&#26377;&#22122;&#38899;&#12289;&#36229;&#20986;&#20998;&#24067;&#31561;&#26679;&#26412;&#12290;&#36825;&#31181;&#32487;&#25215;&#21487;&#33021;&#23545;&#19979;&#28216;&#24212;&#29992;&#20135;&#29983;&#28798;&#38590;&#24615;&#24433;&#21709;&#65292;&#22914;&#20559;&#35265;&#12289;&#32570;&#20047;&#27867;&#21270;&#33021;&#21147;&#12289;&#24615;&#33021;&#19979;&#38477;&#12289;&#23433;&#20840;&#28431;&#27934;&#12289;&#38544;&#31169;&#27844;&#38706;&#21644;&#20215;&#20540;&#35823;&#24046;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#36825;&#20010;&#38382;&#39064;&#32972;&#21518;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;UIM&#26694;&#26550;&#65292;&#26469;&#29702;&#35299;LFMs&#30340;&#28798;&#38590;&#24615;&#32487;&#25215;&#38382;&#39064;&#65292;&#21253;&#25324;&#26469;&#33258;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#36866;&#24212;&#30340;&#32487;&#25215;&#20869;&#23481;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large foundation models (LFMs) are claiming incredible performances. Yet great concerns have been raised about their mythic and uninterpreted potentials not only in machine learning, but also in various other disciplines. In this position paper, we propose to identify a neglected issue deeply rooted in LFMs: Catastrophic Inheritance, describing the weaknesses and limitations inherited from biased large-scale pre-training data to behaviors of LFMs on the downstream tasks, including samples that are corrupted, long-tailed, noisy, out-of-distributed, to name a few. Such inheritance can potentially cause catastrophes to downstream applications, such as bias, lack of generalization, deteriorated performance, security vulnerability, privacy leakage, and value misalignment. We discuss the challenges behind this issue and propose UIM, a framework to Understand the catastrophic inheritance of LFMs from both pre-training and downstream adaptation, Interpret the implications of catastrophic inher
&lt;/p&gt;</description></item></channel></rss>