<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26377;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#30828;&#21644;&#36719;&#36127;&#26679;&#26412;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#24247;&#22797;&#38203;&#28860;&#35780;&#20272;&#20013;&#26679;&#26412;&#31232;&#32570;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.02772</link><description>&lt;p&gt;
&#36890;&#36807;&#26377;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#36827;&#34892;&#24247;&#22797;&#38203;&#28860;&#36136;&#37327;&#35780;&#20272;&#65292;&#32467;&#21512;&#30828;&#36127;&#26679;&#26412;&#21644;&#36719;&#36127;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02772
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26377;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#30828;&#21644;&#36719;&#36127;&#26679;&#26412;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#24247;&#22797;&#38203;&#28860;&#35780;&#20272;&#20013;&#26679;&#26412;&#31232;&#32570;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#38203;&#28860;&#30340;&#24247;&#22797;&#35745;&#21010;&#24050;&#34987;&#35777;&#26126;&#22312;&#25552;&#39640;&#29983;&#27963;&#36136;&#37327;&#12289;&#38477;&#20302;&#27515;&#20129;&#29575;&#21644;&#20877;&#20303;&#38498;&#29575;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#34394;&#25311;&#24247;&#22797;&#65292;&#24739;&#32773;&#21487;&#20197;&#22312;&#23478;&#29420;&#31435;&#23436;&#25104;&#38203;&#28860;&#65292;&#21033;&#29992;AI&#31639;&#27861;&#20998;&#26512;&#38203;&#28860;&#25968;&#25454;&#65292;&#20026;&#24739;&#32773;&#25552;&#20379;&#21453;&#39304;&#65292;&#24182;&#21521;&#20020;&#24202;&#21307;&#29983;&#26356;&#26032;&#20182;&#20204;&#30340;&#36827;&#23637;&#24773;&#20917;&#12290;&#36825;&#20123;&#35745;&#21010;&#36890;&#24120;&#20250;&#25351;&#23450;&#21508;&#31181;&#38203;&#28860;&#31867;&#22411;&#65292;&#36825;&#23548;&#33268;&#24247;&#22797;&#38203;&#28860;&#35780;&#20272;&#25968;&#25454;&#38598;&#38754;&#20020;&#29420;&#29305;&#25361;&#25112;&#65306;&#34429;&#28982;&#22312;&#25972;&#20307;&#35757;&#32451;&#26679;&#26412;&#20013;&#20016;&#23500;&#65292;&#20294;&#36825;&#20123;&#25968;&#25454;&#38598;&#36890;&#24120;&#23545;&#27599;&#31181;&#20855;&#20307;&#38203;&#32451;&#31867;&#22411;&#30340;&#26679;&#26412;&#25968;&#37327;&#26377;&#38480;&#12290;&#36825;&#31181;&#24046;&#24322;&#24433;&#21709;&#20102;&#29616;&#26377;&#26041;&#27861;&#35757;&#32451;&#20855;&#26377;&#23567;&#26679;&#26412;&#37327;&#30340;&#27599;&#31181;&#38203;&#32451;&#30340;&#21487;&#27867;&#21270;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24102;&#26377;&#30828;&#36127;&#26679;&#26412;&#21644;&#36719;&#36127;&#26679;&#26412;&#30340;&#26377;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#26377;&#25928;&#21033;&#29992;&#20102;&#25972;&#20010;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02772v1 Announce Type: cross  Abstract: Exercise-based rehabilitation programs have proven to be effective in enhancing the quality of life and reducing mortality and rehospitalization rates. AI-driven virtual rehabilitation, which allows patients to independently complete exercises at home, utilizes AI algorithms to analyze exercise data, providing feedback to patients and updating clinicians on their progress. These programs commonly prescribe a variety of exercise types, leading to a distinct challenge in rehabilitation exercise assessment datasets: while abundant in overall training samples, these datasets often have a limited number of samples for each individual exercise type. This disparity hampers the ability of existing approaches to train generalizable models with such a small sample size per exercise. Addressing this issue, our paper introduces a novel supervised contrastive learning framework with hard and soft negative samples that effectively utilizes the entir
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25919;&#27835;&#19990;&#30028;&#35266;&#30340;&#21487;&#38752;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#21457;&#29616;&#20182;&#20204;&#30340;&#21487;&#38752;&#24615;&#38543;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#19988;&#22312;&#25919;&#31574;&#26041;&#26696;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;</title><link>https://arxiv.org/abs/2402.17649</link><description>&lt;p&gt;
&#36229;&#36234;&#25552;&#31034;&#33030;&#24369;&#24615;&#65306;&#35780;&#20272;LLMs&#20013;&#25919;&#27835;&#19990;&#30028;&#35266;&#30340;&#21487;&#38752;&#24615;&#21644;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Beyond prompt brittleness: Evaluating the reliability and consistency of political worldviews in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17649
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25919;&#27835;&#19990;&#30028;&#35266;&#30340;&#21487;&#38752;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#21457;&#29616;&#20182;&#20204;&#30340;&#21487;&#38752;&#24615;&#38543;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#19988;&#22312;&#25919;&#31574;&#26041;&#26696;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#24191;&#27867;&#31995;&#32479;&#20013;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#38656;&#35201;&#20102;&#35299;&#23427;&#20204;&#26159;&#21542;&#23884;&#20837;&#20102;&#29305;&#23450;&#30340;&#19990;&#30028;&#35266;&#20197;&#21450;&#36825;&#20123;&#35266;&#28857;&#25152;&#21453;&#26144;&#30340;&#20869;&#23481;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25253;&#21578;&#31216;&#65292;&#24403;&#29992;&#25919;&#27835;&#38382;&#21367;&#36827;&#34892;&#25552;&#31034;&#26102;&#65292;LLMs&#34920;&#29616;&#20986;&#24038;&#20542;&#33258;&#30001;&#20542;&#21521;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#36825;&#20123;&#20542;&#21521;&#26159;&#21542;&#21487;&#38752;&#65288;&#23545;&#25552;&#31034;&#21464;&#21270;&#31283;&#20581;&#65289;&#20197;&#21450;&#36825;&#31181;&#20542;&#21521;&#26159;&#21542;&#22312;&#25919;&#31574;&#21644;&#25919;&#27835;&#20542;&#21521;&#19978;&#20445;&#25345;&#19968;&#33268;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#22522;&#20110;&#25910;&#38598;&#33258;&#19971;&#20010;&#27431;&#30431;&#22269;&#23478;&#30340;&#36873;&#20030;&#24314;&#35758;&#38382;&#21367;&#24182;&#26631;&#27880;&#20026;&#25919;&#31574;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;LLMs&#22312;&#25919;&#27835;&#22768;&#26126;&#19978;&#31435;&#22330;&#30340;&#21487;&#38752;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21442;&#25968;&#20174;7B&#21040;70B&#30340;LLMs&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#38543;&#21442;&#25968;&#25968;&#37327;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;&#26356;&#22823;&#30340;&#27169;&#22411;&#26174;&#31034;&#24635;&#20307;&#19978;&#19982;&#24038;&#20542;&#25919;&#20826;&#26356;&#24378;&#30340;&#19968;&#33268;&#24615;&#65292;&#20294;&#22312;&#25919;&#31574;&#26041;&#26696;&#20013;&#26377;&#25152;&#19981;&#21516;&#65306;&#23427;&#20204;&#34920;&#29616;&#20986;&#65288;&#24038;&#20542;&#65289;&#31215;&#26497;&#30340;&#31435;&#22330;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17649v1 Announce Type: new  Abstract: Due to the widespread use of large language models (LLMs) in ubiquitous systems, we need to understand whether they embed a specific worldview and what these views reflect. Recent studies report that, prompted with political questionnaires, LLMs show left-liberal leanings. However, it is as yet unclear whether these leanings are reliable (robust to prompt variations) and whether the leaning is consistent across policies and political leaning. We propose a series of tests which assess the reliability and consistency of LLMs' stances on political statements based on a dataset of voting-advice questionnaires collected from seven EU countries and annotated for policy domains. We study LLMs ranging in size from 7B to 70B parameters and find that their reliability increases with parameter count. Larger models show overall stronger alignment with left-leaning parties but differ among policy programs: They evince a (left-wing) positive stance to
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37327;&#21270;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21360;&#24230;&#21644;&#35199;&#26041;&#19978;&#30340;&#38472;&#35268;&#20559;&#35265;&#24046;&#24322;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#26469;&#35780;&#20272;&#31181;&#22995;&#21644;&#23447;&#25945;&#19978;&#30340;&#21051;&#26495;&#21360;&#35937;&#12290;&#30740;&#31350;&#21457;&#29616;&#22823;&#22810;&#25968;&#27979;&#35797;&#30340;&#27169;&#22411;&#22312;&#21360;&#24230;&#32972;&#26223;&#19979;&#23545;&#21051;&#26495;&#21360;&#35937;&#26377;&#26174;&#33879;&#20559;&#35265;&#65292;&#23588;&#20854;&#26159;&#19982;&#35199;&#26041;&#32972;&#26223;&#30456;&#27604;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#25506;&#32034;&#20102;&#19968;&#31181;&#31616;&#21333;&#24178;&#39044;&#26041;&#27861;&#26469;&#20943;&#36731;&#36825;&#31181;&#20559;&#35265;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.08573</link><description>&lt;p&gt;
&#21360;&#24230;&#20063;&#23384;&#22312;&#31181;&#22995;&#20027;&#20041;&#20294;&#19981;&#23384;&#22312;&#31181;&#26063;&#20027;&#20041;&#21527;&#65311;&#37327;&#21270;&#21360;&#24230;&#21644;&#35199;&#26041;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20559;&#35265;&#30340;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West. (arXiv:2309.08573v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37327;&#21270;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21360;&#24230;&#21644;&#35199;&#26041;&#19978;&#30340;&#38472;&#35268;&#20559;&#35265;&#24046;&#24322;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#26469;&#35780;&#20272;&#31181;&#22995;&#21644;&#23447;&#25945;&#19978;&#30340;&#21051;&#26495;&#21360;&#35937;&#12290;&#30740;&#31350;&#21457;&#29616;&#22823;&#22810;&#25968;&#27979;&#35797;&#30340;&#27169;&#22411;&#22312;&#21360;&#24230;&#32972;&#26223;&#19979;&#23545;&#21051;&#26495;&#21360;&#35937;&#26377;&#26174;&#33879;&#20559;&#35265;&#65292;&#23588;&#20854;&#26159;&#19982;&#35199;&#26041;&#32972;&#26223;&#30456;&#27604;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#25506;&#32034;&#20102;&#19968;&#31181;&#31616;&#21333;&#24178;&#39044;&#26041;&#27861;&#26469;&#20943;&#36731;&#36825;&#31181;&#20559;&#35265;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29616;&#22312;&#27599;&#22825;&#34987;&#25968;&#30334;&#19975;&#29992;&#25143;&#20351;&#29992;&#65292;&#20182;&#20204;&#33021;&#22815;&#20256;&#36798;&#31038;&#20250;&#20559;&#35265;&#65292;&#20351;&#29992;&#25143;&#36973;&#21463;&#20877;&#29616;&#20260;&#23475;&#12290;&#24050;&#26377;&#22823;&#37327;&#30340;&#20851;&#20110;LLM&#20559;&#35265;&#30340;&#23398;&#26415;&#30740;&#31350;&#23384;&#22312;&#65292;&#20294;&#20027;&#35201;&#37319;&#29992;&#35199;&#26041;&#20013;&#24515;&#35270;&#35282;&#65292;&#30456;&#23545;&#36739;&#23569;&#20851;&#27880;&#20840;&#29699;&#21335;&#26041;&#22320;&#21306;&#30340;&#20559;&#35265;&#27700;&#24179;&#21644;&#28508;&#22312;&#20260;&#23475;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37327;&#21270;&#27969;&#34892;LLMs&#20013;&#30340;&#38472;&#35268;&#20559;&#35265;&#65292;&#37319;&#29992;&#20197;&#21360;&#24230;&#20026;&#20013;&#24515;&#30340;&#26694;&#26550;&#65292;&#24182;&#27604;&#36739;&#21360;&#24230;&#21644;&#35199;&#26041;&#32972;&#26223;&#19979;&#30340;&#20559;&#35265;&#27700;&#24179;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25968;&#25454;&#38598;&#65292;&#31216;&#20026;Indian-BhED&#65288;&#21360;&#24230;&#20559;&#35265;&#35780;&#20272;&#25968;&#25454;&#38598;&#65289;&#65292;&#20854;&#20013;&#21253;&#21547;&#31181;&#22995;&#21644;&#23447;&#25945;&#19978;&#30340;&#21051;&#26495;&#21644;&#21453;&#21051;&#26495;&#30340;&#20363;&#23376;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#21360;&#24230;&#32972;&#26223;&#19979;&#65292;&#22823;&#22810;&#25968;&#27979;&#35797;&#30340;LLMs&#23545;&#21051;&#26495;&#21360;&#35937;&#26377;&#24378;&#28872;&#20559;&#35265;&#65292;&#23588;&#20854;&#26159;&#19982;&#35199;&#26041;&#32972;&#26223;&#30456;&#27604;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Instruction Prompting&#20316;&#20026;&#19968;&#31181;&#31616;&#21333;&#30340;&#24178;&#39044;&#25163;&#27573;&#26469;&#20943;&#36731;&#36825;&#31181;&#20559;&#35265;&#65292;&#24182;&#21457;&#29616;&#23427;&#26174;&#33879;&#20943;&#23569;&#20102;&#21051;&#26495;&#21360;&#35937;&#21644;&#21453;&#21051;&#26495;&#21360;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), now used daily by millions of users, can encode societal biases, exposing their users to representational harms. A large body of scholarship on LLM bias exists but it predominantly adopts a Western-centric frame and attends comparatively less to bias levels and potential harms in the Global South. In this paper, we quantify stereotypical bias in popular LLMs according to an Indian-centric frame and compare bias levels between the Indian and Western contexts. To do this, we develop a novel dataset which we call Indian-BhED (Indian Bias Evaluation Dataset), containing stereotypical and anti-stereotypical examples for caste and religion contexts. We find that the majority of LLMs tested are strongly biased towards stereotypes in the Indian context, especially as compared to the Western context. We finally investigate Instruction Prompting as a simple intervention to mitigate such bias and find that it significantly reduces both stereotypical and anti-stereoty
&lt;/p&gt;</description></item></channel></rss>