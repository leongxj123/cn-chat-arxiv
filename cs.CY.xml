<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#24515;&#29702;&#23398;&#20551;&#35774;&#29983;&#25104;&#20013;&#21462;&#24471;&#20102;&#31361;&#30772;&#65292;&#32467;&#26524;&#26174;&#31034;&#36825;&#31181;&#32852;&#21512;&#26041;&#27861;&#22312;&#26032;&#39062;&#24615;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#20165;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20551;&#35774;&#12290;</title><link>https://arxiv.org/abs/2402.14424</link><description>&lt;p&gt;
&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#33258;&#21160;&#21270;&#24515;&#29702;&#23398;&#20551;&#35774;&#29983;&#25104;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32467;&#21512;&#22240;&#26524;&#22270;
&lt;/p&gt;
&lt;p&gt;
Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14424
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#24515;&#29702;&#23398;&#20551;&#35774;&#29983;&#25104;&#20013;&#21462;&#24471;&#20102;&#31361;&#30772;&#65292;&#32467;&#26524;&#26174;&#31034;&#36825;&#31181;&#32852;&#21512;&#26041;&#27861;&#22312;&#26032;&#39062;&#24615;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#20165;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#22240;&#26524;&#30693;&#35782;&#22270;&#35889;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#31361;&#30772;&#24615;&#30340;&#35745;&#31639;&#26041;&#27861;&#26469;&#29983;&#25104;&#24515;&#29702;&#23398;&#20551;&#35774;&#12290;&#25105;&#20204;&#20351;&#29992;LLM&#20998;&#26512;&#20102;43,312&#31687;&#24515;&#29702;&#23398;&#25991;&#31456;&#65292;&#25552;&#21462;&#20102;&#22240;&#26524;&#20851;&#31995;&#23545;&#65292;&#29983;&#25104;&#20102;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#24515;&#29702;&#23398;&#30340;&#22240;&#26524;&#22270;&#12290;&#24212;&#29992;&#38142;&#25509;&#39044;&#27979;&#31639;&#27861;&#65292;&#25105;&#20204;&#29983;&#25104;&#20102;130&#20010;&#20851;&#27880;&#8220;&#24184;&#31119;&#8221;&#30340;&#28508;&#22312;&#24515;&#29702;&#23398;&#20551;&#35774;&#65292;&#28982;&#21518;&#23558;&#20854;&#19982;&#21338;&#22763;&#23398;&#32773;&#26500;&#24605;&#30340;&#30740;&#31350;&#24819;&#27861;&#21644;&#20165;&#30001;LLM&#20135;&#29983;&#30340;&#24819;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;LLM&#21644;&#22240;&#26524;&#22270;&#30340;&#32852;&#21512;&#26041;&#27861;&#22312;&#26032;&#39062;&#24615;&#26041;&#38754;&#19982;&#19987;&#23478;&#27700;&#24179;&#30340;&#27934;&#23519;&#21147;&#20445;&#25345;&#19968;&#33268;&#65292;&#26126;&#26174;&#20248;&#20110;&#20165;LLM&#30340;&#20551;&#35774;&#65288;&#20998;&#21035;&#20026;t(59)=3.34&#65292;p=0.007&#21644;t(59)=4.32&#65292;p&lt;0.001&#65289;&#12290;&#36825;&#31181;&#19968;&#33268;&#24615;&#36827;&#19968;&#27493;&#36890;&#36807;&#28145;&#24230;&#35821;&#20041;&#20998;&#26512;&#24471;&#21040;&#35777;&#23454;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;LLM&#19982;&#22240;&#26524;&#22270;&#31561;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#29983;&#25104;&#24515;&#29702;&#23398;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14424v1 Announce Type: new  Abstract: Leveraging the synergy between causal knowledge graphs and a large language model (LLM), our study introduces a groundbreaking approach for computational hypothesis generation in psychology. We analyzed 43,312 psychology articles using a LLM to extract causal relation pairs. This analysis produced a specialized causal graph for psychology. Applying link prediction algorithms, we generated 130 potential psychological hypotheses focusing on `well-being', then compared them against research ideas conceived by doctoral scholars and those produced solely by the LLM. Interestingly, our combined approach of a LLM and causal graphs mirrored the expert-level insights in terms of novelty, clearly surpassing the LLM-only hypotheses (t(59) = 3.34, p=0.007 and t(59) = 4.32, p&lt;0.001, respectively). This alignment was further corroborated using deep semantic analysis. Our results show that combining LLM with machine learning techniques such as causal k
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#35774;&#35745;&#26041;&#27861;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#21333;&#19968;&#26631;&#31614;&#39044;&#27979;&#65292;&#23427;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#39044;&#27979;&#38598;&#65292;&#24182;&#24341;&#23548;&#20154;&#31867;&#19987;&#23478;&#20174;&#20013;&#36873;&#25321;&#26631;&#31614;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.03928</link><description>&lt;p&gt;
&#20351;&#29992;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#35774;&#35745;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Designing Decision Support Systems Using Counterfactual Prediction Sets. (arXiv:2306.03928v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#35774;&#35745;&#26041;&#27861;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#21333;&#19968;&#26631;&#31614;&#39044;&#27979;&#65292;&#23427;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#39044;&#27979;&#38598;&#65292;&#24182;&#24341;&#23548;&#20154;&#31867;&#19987;&#23478;&#20174;&#20013;&#36873;&#25321;&#26631;&#31614;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#20219;&#21153;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#36890;&#24120;&#34987;&#35774;&#35745;&#29992;&#20110;&#39044;&#27979;&#22320;&#38754;&#23454;&#20917;&#26631;&#31614;&#30340;&#20540;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30340;&#39044;&#27979;&#24182;&#19981;&#23436;&#32654;&#65292;&#36825;&#20123;&#31995;&#32479;&#36824;&#38656;&#35201;&#35753;&#20154;&#31867;&#19987;&#23478;&#20102;&#35299;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#20351;&#29992;&#36825;&#20123;&#39044;&#27979;&#26469;&#26356;&#26032;&#33258;&#24049;&#30340;&#39044;&#27979;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#34987;&#35777;&#26126;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26368;&#36817;&#26377;&#20154;&#35748;&#20026;&#65292;&#21478;&#19968;&#31181;&#31867;&#22411;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#21487;&#33021;&#20250;&#36991;&#24320;&#36825;&#20010;&#25361;&#25112;&#12290;&#36825;&#20123;&#31995;&#32479;&#19981;&#26159;&#25552;&#20379;&#21333;&#20010;&#26631;&#31614;&#39044;&#27979;&#65292;&#32780;&#26159;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#19968;&#32452;&#26631;&#31614;&#39044;&#27979;&#20540;&#65292;&#21363;&#39044;&#27979;&#38598;&#65292;&#24182;&#24378;&#21046;&#35201;&#27714;&#19987;&#23478;&#20174;&#39044;&#27979;&#38598;&#20013;&#39044;&#27979;&#19968;&#20010;&#26631;&#31614;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#35774;&#35745;&#21644;&#35780;&#20272;&#36804;&#20170;&#20173;&#20381;&#36182;&#20110;&#26679;&#24335;&#21270;&#30340;&#19987;&#23478;&#27169;&#22411;&#65292;&#36825;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#30340;&#25215;&#35834;&#30340;&#36136;&#30097;&#12290;&#26412;&#25991;&#20174;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#37325;&#26032;&#23457;&#35270;&#20102;&#36825;&#31181;&#31995;&#32479;&#30340;&#35774;&#35745;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision support systems for classification tasks are predominantly designed to predict the value of the ground truth labels. However, since their predictions are not perfect, these systems also need to make human experts understand when and how to use these predictions to update their own predictions. Unfortunately, this has been proven challenging. In this context, it has been recently argued that an alternative type of decision support systems may circumvent this challenge. Rather than providing a single label prediction, these systems provide a set of label prediction values constructed using a conformal predictor, namely a prediction set, and forcefully ask experts to predict a label value from the prediction set. However, the design and evaluation of these systems have so far relied on stylized expert models, questioning their promise. In this paper, we revisit the design of this type of systems from the perspective of online learning and develop a methodology that does not requi
&lt;/p&gt;</description></item></channel></rss>