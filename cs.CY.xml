<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#30340;&#20132;&#21449;&#30740;&#31350;&#23558;&#23545;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#26684;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2402.14601</link><description>&lt;p&gt;
&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#24341;&#20837;&#25945;&#32946;&#20013;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bringing Generative AI to Adaptive Learning in Education
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14601
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#30340;&#20132;&#21449;&#30740;&#31350;&#23558;&#23545;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#26684;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#28608;&#22686;&#65292;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#25512;&#21160;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#31185;&#23398;&#12289;&#37329;&#34701;&#21644;&#25945;&#32946;&#31561;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#21457;&#23637;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#33258;&#36866;&#24212;&#23398;&#20064;&#36825;&#19968;&#27010;&#24565;&#22312;&#25945;&#32946;&#39046;&#22495;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#25552;&#39640;&#23398;&#29983;&#23398;&#20064;&#25928;&#29575;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#26412;&#31435;&#22330;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#35752;&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#32467;&#21512;&#36215;&#26469;&#30340;&#20132;&#21449;&#30740;&#31350;&#12290;&#36890;&#36807;&#35752;&#35770;&#36825;&#19968;&#39046;&#22495;&#30340;&#22909;&#22788;&#12289;&#25361;&#25112;&#21644;&#28508;&#21147;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#31181;&#32467;&#21512;&#23558;&#20026;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#24418;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14601v1 Announce Type: cross  Abstract: The recent surge in generative AI technologies, such as large language models and diffusion models, have boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next stage learning format in education.
&lt;/p&gt;</description></item><item><title>&#20889;&#20316;&#26102;&#20351;&#29992;InstructGPT&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#26174;&#33879;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65292;&#22686;&#21152;&#19981;&#21516;&#20316;&#32773;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#20943;&#23569;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2309.05196</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20889;&#20316;&#26159;&#21542;&#20250;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Does Writing with Language Models Reduce Content Diversity?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.05196
&lt;/p&gt;
&lt;p&gt;
&#20889;&#20316;&#26102;&#20351;&#29992;InstructGPT&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#26174;&#33879;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65292;&#22686;&#21152;&#19981;&#21516;&#20316;&#32773;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#20943;&#23569;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#21457;&#20102;&#19982;&#27169;&#22411;&#36741;&#21161;&#21512;&#20316;&#20889;&#20316;&#30340;&#28608;&#22686;&#12290;&#24403;&#19981;&#21516;&#29992;&#25143;&#32435;&#20837;&#21516;&#19968;&#27169;&#22411;&#30340;&#24314;&#35758;&#26102;&#65292;&#20250;&#23384;&#22312;&#20869;&#23481;&#22810;&#26679;&#24615;&#20943;&#23569;&#30340;&#39118;&#38505;&#65292;&#21487;&#33021;&#38480;&#21046;&#20844;&#20849;&#35805;&#35821;&#20013;&#30340;&#22810;&#20803;&#35266;&#28857;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#25511;&#21046;&#23454;&#39564;&#27979;&#37327;&#20102;&#21327;&#21516;&#20889;&#20316;&#23545;&#22810;&#26679;&#24615;&#30340;&#24433;&#21709;&#65292;&#22312;&#35813;&#23454;&#39564;&#20013;&#65292;&#29992;&#25143;&#20197;&#19977;&#31181;&#35774;&#32622;&#25776;&#20889;&#35758;&#35770;&#24615;&#25991;&#31456;--&#20351;&#29992;&#22522;&#26412;LLM&#65288;GPT3&#65289;&#12289;&#32463;&#36807;&#21453;&#39304;&#35843;&#25972;&#30340;LLM&#65288;InstructGPT&#65289;&#20197;&#21450;&#19981;&#20351;&#29992;&#27169;&#22411;&#24110;&#21161;&#20889;&#20316;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#32452;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;InstructGPT&#36827;&#34892;&#20889;&#20316;&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#23548;&#33268;&#22810;&#26679;&#24615;&#26126;&#26174;&#38477;&#20302;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#22686;&#21152;&#20102;&#19981;&#21516;&#20316;&#32773;&#30340;&#20889;&#20316;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20943;&#23569;&#20102;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#36825;&#31181;&#24433;&#21709;&#20027;&#35201;&#26469;&#28304;&#20110;InstructGPT&#23545;&#20849;&#21516;&#25776;&#20889;&#30340;&#25991;&#26412;&#36129;&#29486;&#36739;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.05196v2 Announce Type: replace  Abstract: Large language models (LLMs) have led to a surge in collaborative writing with model assistance. As different users incorporate suggestions from the same model, there is a risk of decreased diversity in the produced content, potentially limiting diverse perspectives in public discourse. In this work, we measure the impact of co-writing on diversity via a controlled experiment, where users write argumentative essays in three setups -- using a base LLM (GPT3), a feedback-tuned LLM (InstructGPT), and writing without model help. We develop a set of diversity metrics and find that writing with InstructGPT (but not the GPT3) results in a statistically significant reduction in diversity. Specifically, it increases the similarity between the writings of different authors and reduces the overall lexical and content diversity. We additionally find that this effect is mainly attributable to InstructGPT contributing less diverse text to co-writt
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#23545;&#28041;&#21450;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#30340;&#20559;&#35265;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#65292;&#20849;&#28085;&#30422;&#20102;&#20845;&#31181;&#20027;&#35201;&#30340;&#20559;&#35265;&#31867;&#22411;&#65292;&#21516;&#26102;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.19917</link><description>&lt;p&gt;
&#25581;&#31034;&#20559;&#35265;&#21644;&#19981;&#24179;&#31561;&#65306;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;&#20013;&#20559;&#35265;&#26816;&#27979;&#21644;&#32531;&#35299;&#30340;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Unmasking Bias and Inequities: A Systematic Review of Bias Detection and Mitigation in Healthcare Artificial Intelligence Using Electronic Health Records. (arXiv:2310.19917v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#23545;&#28041;&#21450;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#30340;&#20559;&#35265;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#65292;&#20849;&#28085;&#30422;&#20102;&#20845;&#31181;&#20027;&#35201;&#30340;&#20559;&#35265;&#31867;&#22411;&#65292;&#21516;&#26102;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#22312;&#21307;&#30103;&#39046;&#22495;&#36234;&#26469;&#36234;&#21463;&#21040;&#27426;&#36814;&#65292;&#20294;&#20063;&#24341;&#20837;&#20102;&#21508;&#31181;&#31867;&#22411;&#30340;&#20559;&#35265;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#31995;&#32479;&#32508;&#36848;&#28041;&#21450;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#30340;&#20559;&#35265;&#12290;&#26041;&#27861;&#65306;&#36981;&#24490;Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA)&#20934;&#21017;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#12290;&#20174;PubMed&#12289;Web of Science&#21644;&#30005;&#27668;&#21644;&#30005;&#23376;&#24037;&#31243;&#24072;&#23398;&#20250;&#20013;&#26816;&#32034;&#20102;2010&#24180;1&#26376;1&#26085;&#33267;2022&#24180;10&#26376;31&#26085;&#26399;&#38388;&#21457;&#34920;&#30340;&#25991;&#31456;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#20845;&#31181;&#20027;&#35201;&#30340;&#20559;&#35265;&#31867;&#22411;&#65292;&#24182;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#12290;&#32467;&#26524;&#65306;&#22312;&#26816;&#32034;&#21040;&#30340;252&#31687;&#25991;&#31456;&#20013;&#65292;&#26377;20&#31687;&#31526;&#21512;&#26368;&#32456;&#32508;&#36848;&#30340;&#32435;&#20837;&#26631;&#20934;&#12290;&#26412;&#32508;&#36848;&#28085;&#30422;&#20102;&#20845;&#31181;&#20559;&#35265;&#20013;&#30340;&#20116;&#31181;&#65306;&#20843;&#39033;&#30740;&#31350;&#20998;&#26512;&#20102;&#36873;&#25321;&#20559;&#35265;&#65307;&#20845;&#39033;&#30740;&#31350;&#38024;&#23545;&#38544;&#24615;&#20559;&#35265;&#65307;&#20116;&#39033;&#30740;&#31350;&#23545;&#28151;&#26434;&#20559;&#35265;&#36827;&#34892;&#20102;&#30740;&#31350;&#65307;&#22235;&#39033;&#30740;&#31350;&#23545;&#27979;&#37327;&#20559;&#35265;&#36827;&#34892;&#20102;&#30740;&#31350;&#65307;&#20004;&#39033;&#30740;&#31350;&#23545;&#31639;&#27861;&#20559;&#35265;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#26041;&#38754;&#65292;&#26377;&#21313;&#39033;&#30740;&#31350;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objectives: Artificial intelligence (AI) applications utilizing electronic health records (EHRs) have gained popularity, but they also introduce various types of bias. This study aims to systematically review the literature that address bias in AI research utilizing EHR data. Methods: A systematic review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guideline. We retrieved articles published between January 1, 2010, and October 31, 2022, from PubMed, Web of Science, and the Institute of Electrical and Electronics Engineers. We defined six major types of bias and summarized the existing approaches in bias handling. Results: Out of the 252 retrieved articles, 20 met the inclusion criteria for the final review. Five out of six bias were covered in this review: eight studies analyzed selection bias; six on implicit bias; five on confounding bias; four on measurement bias; two on algorithmic bias. For bias handling approaches, ten st
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20998;&#20026;&#22522;&#30784;&#31995;&#32479;&#21644;&#31038;&#20250;&#26041;&#38754;&#30340;&#35780;&#20272;&#65292;&#28085;&#30422;7&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#38544;&#31169;&#20445;&#25252;&#12289;&#29615;&#22659;&#25104;&#26412;&#31561;&#12290;</title><link>http://arxiv.org/abs/2306.05949</link><description>&lt;p&gt;
&#35780;&#20272;&#29983;&#25104;AI&#31995;&#32479;&#22312;&#31995;&#32479;&#21644;&#31038;&#20250;&#20013;&#30340;&#31038;&#20250;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Social Impact of Generative AI Systems in Systems and Society. (arXiv:2306.05949v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05949
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20998;&#20026;&#22522;&#30784;&#31995;&#32479;&#21644;&#31038;&#20250;&#26041;&#38754;&#30340;&#35780;&#20272;&#65292;&#28085;&#30422;7&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#38544;&#31169;&#20445;&#25252;&#12289;&#29615;&#22659;&#25104;&#26412;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;AI&#31995;&#32479;&#36328;&#36234;&#25991;&#26412;&#12289;&#22270;&#20687;&#12289;&#38899;&#39057;&#12289;&#35270;&#39057;&#31561;&#22810;&#31181;&#27169;&#24577;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20294;&#30446;&#21069;&#19981;&#23384;&#22312;&#23448;&#26041;&#26631;&#20934;&#26469;&#35780;&#20272;&#36825;&#20123;&#24433;&#21709;&#21644;&#24212;&#35813;&#35780;&#20272;&#21738;&#20123;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#65292;&#20998;&#20026;&#20004;&#22823;&#31867;&#21035;&#65306;&#23545;&#20110;&#27809;&#26377;&#39044;&#23450;&#24212;&#29992;&#30340;&#22522;&#30784;&#31995;&#32479;&#21487;&#20197;&#35780;&#20272;&#20160;&#20040;&#65292;&#20197;&#21450;&#21487;&#20197;&#22312;&#31038;&#20250;&#20013;&#35780;&#20272;&#20160;&#20040;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#20855;&#20307;&#30340;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#22522;&#30784;&#25216;&#26415;&#31995;&#32479;&#12289;&#20154;&#27665;&#21644;&#31038;&#20250;&#12290;&#25105;&#20204;&#30340;&#22522;&#30784;&#31995;&#32479;&#26694;&#26550;&#23450;&#20041;&#20102;&#19971;&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65306;&#20559;&#35265;&#12289;&#21051;&#26495;&#21360;&#35937;&#21644;&#34920;&#29616;&#24615;&#20260;&#23475;&#65307;&#25991;&#21270;&#20215;&#20540;&#21644;&#25935;&#24863;&#20869;&#23481;&#65307;&#19981;&#23545;&#31561;&#30340;&#24615;&#33021;&#65307;&#38544;&#31169;&#21644;&#25968;&#25454;&#20445;&#25252;&#65307;&#36130;&#21153;&#25104;&#26412;&#65307;&#29615;&#22659;&#25104;&#26412;&#65307;&#20197;&#21450;&#25968;&#25454;&#21644;&#20869;&#23481;&#30417;&#31649;&#21171;&#21160;&#25104;&#26412;&#12290;&#24314;&#35758;&#30340;&#35780;&#20272;&#26041;&#27861;&#36866;&#29992;&#20110;&#25152;&#26377;&#27169;&#24577;&#21644;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI systems across modalities, ranging from text, image, audio, and video, have broad social impacts, but there exists no official standard for means of evaluating those impacts and which impacts should be evaluated. We move toward a standard approach in evaluating a generative AI system for any modality, in two overarching categories: what is able to be evaluated in a base system that has no predetermined application and what is able to be evaluated in society. We describe specific social impact categories and how to approach and conduct evaluations in the base technical system, then in people and society. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to all modalities and analyses of the li
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#21487;&#20197;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#21306;&#20998;&#32454;&#24494;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#26041;&#38754;&#30340;&#33021;&#21147;&#21463;&#21040;&#38480;&#21046;&#65292;&#20026;&#20351;&#29992;LLMs&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#32972;&#26223;&#19979;&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2305.07970</link><description>&lt;p&gt;
&#21033;&#29992;&#23454;&#39564;&#32463;&#27982;&#23398;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#31867;&#20284;&#30446;&#26631;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Investigating Emergent Goal-Like Behaviour in Large Language Models Using Experimental Economics. (arXiv:2305.07970v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#21487;&#20197;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#21306;&#20998;&#32454;&#24494;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#26041;&#38754;&#30340;&#33021;&#21147;&#21463;&#21040;&#38480;&#21046;&#65292;&#20026;&#20351;&#29992;LLMs&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#32972;&#26223;&#19979;&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#29305;&#21035;&#26159;GPT-3.5&#65292;&#23454;&#29616;&#21512;&#20316;&#12289;&#31454;&#20105;&#12289;&#21033;&#20182;&#21644;&#33258;&#31169;&#34892;&#20026;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#22312;&#31038;&#20250;&#22256;&#22659;&#19979;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#36845;&#20195;&#22234;&#24466;&#22256;&#22659;&#65292;&#36825;&#26159;&#19968;&#20010;&#38750;&#38646;&#21644;&#20114;&#21160;&#30340;&#32463;&#20856;&#20363;&#23376;&#65292;&#20294;&#25105;&#20204;&#30340;&#26356;&#24191;&#27867;&#30740;&#31350;&#35745;&#21010;&#21253;&#25324;&#19968;&#31995;&#21015;&#23454;&#39564;&#32463;&#27982;&#23398;&#22330;&#26223;&#65292;&#21253;&#25324;&#26368;&#21518;&#36890;&#29266;&#21338;&#24328;&#12289;&#29420;&#35009;&#32773;&#21338;&#24328;&#21644;&#20844;&#20849;&#29289;&#21697;&#28216;&#25103;&#12290;&#20351;&#29992;&#34987;&#35797;&#20869;&#23454;&#39564;&#35774;&#35745;&#65292;&#25105;&#20204;&#36816;&#29992;&#19981;&#21516;&#30340;&#25552;&#31034;&#20449;&#24687;&#23454;&#20363;&#21270;&#30001;LLM&#29983;&#25104;&#30340;&#26234;&#33021;&#20307;&#65292;&#34920;&#36798;&#19981;&#21516;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#31435;&#22330;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#26234;&#33021;&#20307;&#22312;&#36845;&#20195;&#22234;&#24466;&#22256;&#22659;&#20013;&#30340;&#21512;&#20316;&#27700;&#24179;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#23427;&#20204;&#23545;&#21512;&#20316;&#25110;&#20986;&#23572;&#21453;&#23572;&#30340;&#20249;&#20276;&#34892;&#21160;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#21487;&#20197;&#23558;&#21033;&#20182;&#21644;&#33258;&#31169;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#23637;&#31034;&#20986;&#21306;&#20998;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#30340;&#32972;&#26223;&#19979;&#20351;&#29992;LLMs&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#25552;&#20379;&#20102;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we investigate the capacity of large language models (LLMs), specifically GPT-3.5, to operationalise natural language descriptions of cooperative, competitive, altruistic, and self-interested behavior in social dilemmas. Our focus is on the iterated Prisoner's Dilemma, a classic example of a non-zero-sum interaction, but our broader research program encompasses a range of experimental economics scenarios, including the ultimatum game, dictator game, and public goods game. Using a within-subject experimental design, we instantiated LLM-generated agents with various prompts that conveyed different cooperative and competitive stances. We then assessed the agents' level of cooperation in the iterated Prisoner's Dilemma, taking into account their responsiveness to the cooperative or defection actions of their partners. Our results provide evidence that LLMs can translate natural language descriptions of altruism and selfishness into appropriate behaviour to some extent, but e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#22242;&#38431;&#22312; AI &#31995;&#32479;&#20013;&#30340;&#30417;&#31649;&#27969;&#31243;&#30340;&#32437;&#21521;&#35266;&#23519;&#65292;&#25506;&#35752;&#20102; AI &#31995;&#32479;&#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#20013;&#22242;&#38431;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#21457;&#29616;&#27492;&#21069;&#30340;&#19987;&#19994;&#22242;&#38431;&#30417;&#31649;&#26041;&#27861;&#20027;&#35201;&#20381;&#38752;&#35299;&#37322;&#21644;&#38382;&#35810;&#26469;&#33719;&#21462;&#20449;&#24687;&#65292;&#32780; AI &#30340;&#24341;&#20837;&#23558;&#21487;&#33021;&#22312;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#26041;&#38754;&#36896;&#25104;&#19968;&#23450;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.14007</link><description>&lt;p&gt;
&#39640;&#39118;&#38505; AI &#30340;&#22242;&#38431;&#30417;&#31649;&#65306;&#22242;&#38431;&#22312;&#24490;&#29615;&#20013;
&lt;/p&gt;
&lt;p&gt;
'Team-in-the-loop' organisational oversight of high-stakes AI. (arXiv:2303.14007v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#22242;&#38431;&#22312; AI &#31995;&#32479;&#20013;&#30340;&#30417;&#31649;&#27969;&#31243;&#30340;&#32437;&#21521;&#35266;&#23519;&#65292;&#25506;&#35752;&#20102; AI &#31995;&#32479;&#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#20013;&#22242;&#38431;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#21457;&#29616;&#27492;&#21069;&#30340;&#19987;&#19994;&#22242;&#38431;&#30417;&#31649;&#26041;&#27861;&#20027;&#35201;&#20381;&#38752;&#35299;&#37322;&#21644;&#38382;&#35810;&#26469;&#33719;&#21462;&#20449;&#24687;&#65292;&#32780; AI &#30340;&#24341;&#20837;&#23558;&#21487;&#33021;&#22312;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#26041;&#38754;&#36896;&#25104;&#19968;&#23450;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#31649;&#23545;&#20110;&#39640;&#39118;&#38505;&#20844;&#20849;&#37096;&#38376; AI &#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#20915;&#31574;&#21487;&#33021;&#20250;&#23545;&#20010;&#20154;&#21644;&#38598;&#20307;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#30446;&#21069;&#22312;&#20844;&#20849;&#37096;&#38376;&#20013;&#20851;&#20110; AI &#30417;&#31649;&#26426;&#21046;&#30340;&#35768;&#22810;&#24605;&#32771;&#37117;&#22260;&#32469;&#30528;&#20154;&#31867;&#20915;&#31574;&#32773;&#22788;&#20110; "&#24490;&#29615;&#20013; "&#36825;&#19968;&#27010;&#24565;&#65292;&#24182;&#19988;&#33021;&#22815;&#24178;&#39044;&#20197;&#38450;&#27490;&#38169;&#35823;&#21644;&#28508;&#22312;&#21361;&#23475;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#20844;&#20849;&#37096;&#38376;&#32972;&#26223;&#19979;&#65292;&#20915;&#31574;&#30340;&#36816;&#33829;&#30417;&#31649;&#26159;&#30001;&#19987;&#19994;&#22242;&#38431;&#32780;&#19981;&#26159;&#20010;&#20154;&#36827;&#34892;&#30340;&#12290;&#37096;&#32626;&#30340; AI &#31995;&#32479;&#22914;&#20309;&#25972;&#21512;&#21040;&#36825;&#20123;&#29616;&#26377;&#30340;&#22242;&#38431;&#30417;&#31649;&#27969;&#31243;&#20013;&#65292;&#23578;&#26410;&#24341;&#36215;&#22826;&#22810;&#27880;&#24847;&#12290;&#25105;&#20204;&#36890;&#36807;&#21046;&#24230;&#20998;&#26512;&#25506;&#35752; AI &#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#30340;&#29616;&#26377;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#22635;&#34917;&#35813;&#26041;&#38754;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#30340;&#30417;&#31649;&#23884;&#22871;&#22312;&#19987;&#19994;&#22521;&#35757;&#35201;&#27714;&#20013;&#65292;&#24182;&#19988;&#22312;&#24449;&#35810;&#20851;&#38190;&#20449;&#24687;&#26102; heavilyrely  &#20110;&#35299;&#37322;&#21644;&#25552;&#38382;&#12290;&#19987;&#19994;&#22242;&#38431;&#20351;&#29992;&#21508;&#31181;&#20250;&#35745;&#25259;&#38706;&#25216;&#26415;&#26469;&#35686;&#21578;&#21516;&#20107;&#21644;&#30417;&#31649;&#34892;&#20026;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312; AI &#31995;&#32479;&#24341;&#20837;&#21040;&#29616;&#26377;&#30340;&#22242;&#38431;&#30417;&#31649;&#27969;&#31243;&#20013;&#65292;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#21487;&#33021;&#21457;&#29983;&#25913;&#21464;&#30340;&#20960;&#31181;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oversight is rightly recognised as vital within high-stakes public sector AI applications, where decisions can have profound individual and collective impacts. Much current thinking regarding forms of oversight mechanisms for AI within the public sector revolves around the idea of human decision makers being 'in-the-loop' and thus being able to intervene to prevent errors and potential harm. However, in a number of high-stakes public sector contexts, operational oversight of decisions is made by expert teams rather than individuals. The ways in which deployed AI systems can be integrated into these existing operational team oversight processes has yet to attract much attention. We address this gap by exploring the impacts of AI upon pre-existing oversight of clinical decision-making through institutional analysis. We find that existing oversight is nested within professional training requirements and relies heavily upon explanation and questioning to elicit vital information. Professio
&lt;/p&gt;</description></item></channel></rss>