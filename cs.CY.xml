<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#36890;&#36807;&#35780;&#20272;GPT3.5&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20855;&#26377;&#26377;&#36259;&#30340;&#20010;&#24615;&#38382;&#21367;&#22238;&#31572;&#33021;&#21147;&#65292;&#20294;&#19981;&#22826;&#21487;&#33021;&#21457;&#23637;&#20986;&#24847;&#35782;&#65292;&#24182;&#26174;&#31034;&#20986;&#36739;&#22823;&#30340;&#35748;&#30693;&#21644;&#20010;&#24615;&#21464;&#24322;&#12290;</title><link>http://arxiv.org/abs/2309.07683</link><description>&lt;p&gt;
&#35780;&#20272;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#36136;&#65306;&#23545;&#20154;&#31867;&#20013;&#24515;&#20027;&#20041;&#30340;&#35686;&#21578;
&lt;/p&gt;
&lt;p&gt;
Assessing the nature of large language models: A caution against anthropocentrism. (arXiv:2309.07683v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07683
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35780;&#20272;GPT3.5&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20855;&#26377;&#26377;&#36259;&#30340;&#20010;&#24615;&#38382;&#21367;&#22238;&#31572;&#33021;&#21147;&#65292;&#20294;&#19981;&#22826;&#21487;&#33021;&#21457;&#23637;&#20986;&#24847;&#35782;&#65292;&#24182;&#26174;&#31034;&#20986;&#36739;&#22823;&#30340;&#35748;&#30693;&#21644;&#20010;&#24615;&#21464;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#36890;&#36807;OpenAI&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;ChatGPT&#30340;&#21457;&#24067;&#24341;&#36215;&#20102;&#20844;&#20247;&#30340;&#20851;&#27880;&#21644;&#29468;&#27979;&#12290;&#30446;&#21069;&#23384;&#22312;&#20004;&#31181;&#24847;&#35265;&#38453;&#33829;&#65306;&#19968;&#26041;&#23545;&#36825;&#20123;&#27169;&#22411;&#20026;&#20154;&#31867;&#20219;&#21153;&#24102;&#26469;&#30340;&#22522;&#26412;&#21464;&#38761;&#30340;&#21487;&#33021;&#24615;&#24863;&#21040;&#20852;&#22859;&#65292;&#21478;&#19968;&#26041;&#23545;&#36825;&#20123;&#27169;&#22411;&#30340;&#24378;&#22823;&#33021;&#21147;&#24863;&#21040;&#39640;&#24230;&#20851;&#20999;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#20851;&#20999;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#26631;&#20934;&#12289;&#35268;&#33539;&#21270;&#21644;&#32463;&#36807;&#39564;&#35777;&#30340;&#35748;&#30693;&#21644;&#20010;&#24615;&#27979;&#37327;&#24037;&#20855;&#26469;&#35780;&#20272;GPT3.5&#12290;&#22312;&#36825;&#20010;&#21021;&#27493;&#39033;&#30446;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#22871;&#27979;&#35797;&#65292;&#21487;&#20197;&#20272;&#35745;&#36825;&#20123;&#27169;&#22411;&#30340;&#33021;&#21147;&#36793;&#30028;&#65292;&#23427;&#20204;&#22312;&#30701;&#26102;&#38388;&#20869;&#30340;&#31283;&#23450;&#24615;&#20197;&#21450;&#19982;&#20154;&#31867;&#30340;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;GPT 3.5&#24456;&#21487;&#33021;&#27809;&#26377;&#20135;&#29983;&#24847;&#35782;&#65292;&#23613;&#31649;&#23427;&#23545;&#20010;&#24615;&#38382;&#21367;&#30340;&#22238;&#31572;&#33021;&#21147;&#20196;&#20154;&#24863;&#20852;&#36259;&#12290;&#23427;&#22312;&#37325;&#22797;&#35266;&#23519;&#36807;&#31243;&#20013;&#26174;&#31034;&#20986;&#35748;&#30693;&#21644;&#20010;&#24615;&#27979;&#37327;&#26041;&#38754;&#30340;&#22823;&#37327;&#21464;&#24322;&#65292;&#36825;&#19982;&#20855;&#26377;&#20154;&#31867;&#33324;&#20010;&#24615;&#30340;&#27169;&#22411;&#26159;&#19981;&#31526;&#21512;&#39044;&#26399;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI models garnered a large amount of public attention and speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion camps exist: one excited about possibilities these models offer for fundamental changes to human tasks, and another highly concerned about power these models seem to have. To address these concerns, we assessed GPT3.5 using standard, normed, and validated cognitive and personality measures. For this seedling project, we developed a battery of tests that allowed us to estimate the boundaries of some of these models capabilities, how stable those capabilities are over a short period of time, and how they compare to humans.  Our results indicate that GPT 3.5 is unlikely to have developed sentience, although its ability to respond to personality inventories is interesting. It did display large variability in both cognitive and personality measures over repeated observations, which is not expected if it had a human-like personality. Variability 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20998;&#20026;&#22522;&#30784;&#31995;&#32479;&#21644;&#31038;&#20250;&#26041;&#38754;&#30340;&#35780;&#20272;&#65292;&#28085;&#30422;7&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#38544;&#31169;&#20445;&#25252;&#12289;&#29615;&#22659;&#25104;&#26412;&#31561;&#12290;</title><link>http://arxiv.org/abs/2306.05949</link><description>&lt;p&gt;
&#35780;&#20272;&#29983;&#25104;AI&#31995;&#32479;&#22312;&#31995;&#32479;&#21644;&#31038;&#20250;&#20013;&#30340;&#31038;&#20250;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Social Impact of Generative AI Systems in Systems and Society. (arXiv:2306.05949v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05949
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20998;&#20026;&#22522;&#30784;&#31995;&#32479;&#21644;&#31038;&#20250;&#26041;&#38754;&#30340;&#35780;&#20272;&#65292;&#28085;&#30422;7&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#38544;&#31169;&#20445;&#25252;&#12289;&#29615;&#22659;&#25104;&#26412;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;AI&#31995;&#32479;&#36328;&#36234;&#25991;&#26412;&#12289;&#22270;&#20687;&#12289;&#38899;&#39057;&#12289;&#35270;&#39057;&#31561;&#22810;&#31181;&#27169;&#24577;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20294;&#30446;&#21069;&#19981;&#23384;&#22312;&#23448;&#26041;&#26631;&#20934;&#26469;&#35780;&#20272;&#36825;&#20123;&#24433;&#21709;&#21644;&#24212;&#35813;&#35780;&#20272;&#21738;&#20123;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#65292;&#20998;&#20026;&#20004;&#22823;&#31867;&#21035;&#65306;&#23545;&#20110;&#27809;&#26377;&#39044;&#23450;&#24212;&#29992;&#30340;&#22522;&#30784;&#31995;&#32479;&#21487;&#20197;&#35780;&#20272;&#20160;&#20040;&#65292;&#20197;&#21450;&#21487;&#20197;&#22312;&#31038;&#20250;&#20013;&#35780;&#20272;&#20160;&#20040;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#20855;&#20307;&#30340;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#22522;&#30784;&#25216;&#26415;&#31995;&#32479;&#12289;&#20154;&#27665;&#21644;&#31038;&#20250;&#12290;&#25105;&#20204;&#30340;&#22522;&#30784;&#31995;&#32479;&#26694;&#26550;&#23450;&#20041;&#20102;&#19971;&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65306;&#20559;&#35265;&#12289;&#21051;&#26495;&#21360;&#35937;&#21644;&#34920;&#29616;&#24615;&#20260;&#23475;&#65307;&#25991;&#21270;&#20215;&#20540;&#21644;&#25935;&#24863;&#20869;&#23481;&#65307;&#19981;&#23545;&#31561;&#30340;&#24615;&#33021;&#65307;&#38544;&#31169;&#21644;&#25968;&#25454;&#20445;&#25252;&#65307;&#36130;&#21153;&#25104;&#26412;&#65307;&#29615;&#22659;&#25104;&#26412;&#65307;&#20197;&#21450;&#25968;&#25454;&#21644;&#20869;&#23481;&#30417;&#31649;&#21171;&#21160;&#25104;&#26412;&#12290;&#24314;&#35758;&#30340;&#35780;&#20272;&#26041;&#27861;&#36866;&#29992;&#20110;&#25152;&#26377;&#27169;&#24577;&#21644;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI systems across modalities, ranging from text, image, audio, and video, have broad social impacts, but there exists no official standard for means of evaluating those impacts and which impacts should be evaluated. We move toward a standard approach in evaluating a generative AI system for any modality, in two overarching categories: what is able to be evaluated in a base system that has no predetermined application and what is able to be evaluated in society. We describe specific social impact categories and how to approach and conduct evaluations in the base technical system, then in people and society. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to all modalities and analyses of the li
&lt;/p&gt;</description></item></channel></rss>