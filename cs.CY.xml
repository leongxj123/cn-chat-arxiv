<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#25506;&#35752;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#24341;&#21457;&#30340;&#20889;&#20316;&#25152;&#26377;&#26435;&#24863;&#21644;&#20316;&#32773;&#36523;&#20221;&#35748;&#30693;&#20043;&#38388;&#30340;&#24515;&#29702;&#22256;&#22659;&#12290;</title><link>https://arxiv.org/abs/2404.00027</link><description>&lt;p&gt;
LLM&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#65306;&#25506;&#35752;&#25152;&#26377;&#26435;&#24863;&#21644;&#25512;&#29702;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00027
&lt;/p&gt;
&lt;p&gt;
&#25506;&#35752;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#20889;&#20316;&#21161;&#25163;&#24341;&#21457;&#30340;&#20889;&#20316;&#25152;&#26377;&#26435;&#24863;&#21644;&#20316;&#32773;&#36523;&#20221;&#35748;&#30693;&#20043;&#38388;&#30340;&#24515;&#29702;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20889;&#20316;&#20013;&#30340;&#25152;&#26377;&#26435;&#24863;&#38480;&#21046;&#20102;&#25105;&#20204;&#23545;&#24605;&#24819;&#12289;&#26102;&#38388;&#21644;&#36129;&#29486;&#30340;&#25237;&#20837;&#65292;&#23548;&#33268;&#23545;&#20135;&#20986;&#29289;&#30340;&#20381;&#24651;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#20889;&#20316;&#21161;&#25163;&#24341;&#20837;&#20102;&#19968;&#31181;&#24515;&#29702;&#22256;&#22659;&#65292;&#22240;&#20026;&#19968;&#20123;&#20869;&#23481;&#24182;&#38750;&#30452;&#25509;&#25105;&#20204;&#30340;&#21019;&#20316;&#12290;&#25105;&#20204;&#24448;&#24448;&#26356;&#20542;&#21521;&#20110;&#22312;&#21019;&#36896;&#24615;&#20219;&#21153;&#20013;&#26356;&#22810;&#22320;&#24402;&#21151;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#23613;&#31649;&#23427;&#20204;&#23545;&#25152;&#26377;&#20219;&#21153;&#37117;&#26159;&#24179;&#31561;&#30340;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#25105;&#20204;&#21487;&#33021;&#19981;&#20250;&#23436;&#20840;&#22768;&#31216;&#23545;&#30001;LLM&#29983;&#25104;&#30340;&#20869;&#23481;&#25317;&#26377;&#25152;&#26377;&#26435;&#65292;&#20294;&#21364;&#33258;&#30001;&#22320;&#22768;&#31216;&#20316;&#32773;&#36523;&#20221;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#31616;&#30701;&#35843;&#26597;&#26469;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#20102;&#35299;&#28508;&#22312;&#30340;&#35748;&#30693;&#36807;&#31243;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#20154;&#26426;&#20132;&#20114;&#22312;&#20889;&#20316;&#20013;&#30340;&#24212;&#29992;&#24182;&#25913;&#36827;&#20889;&#20316;&#36741;&#21161;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#27169;&#22411;&#24320;&#25918;&#26694;&#26550;&#65288;MOF&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#25490;&#21517;&#20998;&#31867;&#31995;&#32479;&#65292;&#26681;&#25454;&#23436;&#25972;&#24615;&#21644;&#24320;&#25918;&#24615;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#26088;&#22312;&#20419;&#36827;&#23436;&#25972;&#24615;&#12289;&#24320;&#25918;&#24615;&#20197;&#21450;&#36981;&#24490;&#24320;&#25918;&#31185;&#23398;&#21407;&#21017;&#65292;&#21487;&#20197;&#24110;&#21161;&#20934;&#30830;&#35782;&#21035;&#27169;&#22411;&#30340;&#36879;&#26126;&#24615;&#21644;&#21487;&#37325;&#29616;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.13784</link><description>&lt;p&gt;
&#27169;&#22411;&#24320;&#25918;&#26694;&#26550;: &#20419;&#36827;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#21487;&#37325;&#29616;&#24615;&#12289;&#36879;&#26126;&#24230;&#21644;&#21487;&#29992;&#24615;&#30340;&#23436;&#25972;&#24615;&#21644;&#24320;&#25918;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency and Usability in AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13784
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#27169;&#22411;&#24320;&#25918;&#26694;&#26550;&#65288;MOF&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#25490;&#21517;&#20998;&#31867;&#31995;&#32479;&#65292;&#26681;&#25454;&#23436;&#25972;&#24615;&#21644;&#24320;&#25918;&#24615;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#26088;&#22312;&#20419;&#36827;&#23436;&#25972;&#24615;&#12289;&#24320;&#25918;&#24615;&#20197;&#21450;&#36981;&#24490;&#24320;&#25918;&#31185;&#23398;&#21407;&#21017;&#65292;&#21487;&#20197;&#24110;&#21161;&#20934;&#30830;&#35782;&#21035;&#27169;&#22411;&#30340;&#36879;&#26126;&#24615;&#21644;&#21487;&#37325;&#29616;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GAI&#65289;&#25552;&#20379;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#21487;&#33021;&#24615;&#65292;&#20294;&#20854;&#21830;&#19994;&#21270;&#24341;&#21457;&#20102;&#20851;&#20110;&#36879;&#26126;&#24230;&#12289;&#21487;&#37325;&#29616;&#24615;&#12289;&#20559;&#35265;&#21644;&#23433;&#20840;&#24615;&#30340;&#25285;&#24551;&#12290;&#35768;&#22810;"&#24320;&#28304;"&#30340;GAI&#27169;&#22411;&#32570;&#20047;&#23436;&#25972;&#29702;&#35299;&#21644;&#20877;&#29616;&#25152;&#24517;&#38656;&#30340;&#32452;&#20214;&#65292;&#19968;&#20123;&#37319;&#29992;&#38480;&#21046;&#24615;&#35768;&#21487;&#35777;&#65292;&#36825;&#31181;&#34892;&#20026;&#34987;&#31216;&#20026;"&#24320;&#28304;&#27927;&#30333;"&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#27169;&#22411;&#24320;&#25918;&#26694;&#26550;&#65288;MOF&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26681;&#25454;&#23436;&#25972;&#24615;&#21644;&#24320;&#25918;&#24615;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#25490;&#21517;&#20998;&#31867;&#30340;&#31995;&#32479;&#65292;&#36981;&#24490;&#24320;&#25918;&#31185;&#23398;&#12289;&#24320;&#28304;&#12289;&#24320;&#25918;&#25968;&#25454;&#21644;&#24320;&#25918;&#33719;&#21462;&#30340;&#21407;&#21017;&#12290;MOF&#35201;&#27714;&#27169;&#22411;&#24320;&#21457;&#29983;&#21629;&#21608;&#26399;&#30340;&#29305;&#23450;&#32452;&#20214;&#34987;&#21253;&#21547;&#24182;&#26681;&#25454;&#36866;&#24403;&#30340;&#24320;&#25918;&#35768;&#21487;&#35777;&#21457;&#24067;&#12290;&#35813;&#26694;&#26550;&#26088;&#22312;&#38450;&#27490;&#23459;&#31216;&#33258;&#24049;&#26159;&#24320;&#25918;&#30340;&#27169;&#22411;&#34987;&#35823;&#35299;&#65292;&#25351;&#23548;&#30740;&#31350;&#20154;&#21592;&#21644;&#24320;&#21457;&#32773;&#20197;&#23485;&#26494;&#30340;&#35768;&#21487;&#35777;&#21457;&#24067;&#25152;&#26377;&#27169;&#22411;&#32452;&#20214;&#65292;&#24182;&#24110;&#21161;&#20844;&#21496;&#12289;&#23398;&#26415;&#30028;&#21644;&#29233;&#22909;&#32773;&#35782;&#21035;&#21487;&#20197;&#23433;&#20840;&#37319;&#29992;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13784v1 Announce Type: new  Abstract: Generative AI (GAI) offers unprecedented possibilities but its commercialization has raised concerns about transparency, reproducibility, bias, and safety. Many "open-source" GAI models lack the necessary components for full understanding and reproduction, and some use restrictive licenses, a practice known as "openwashing." We propose the Model Openness Framework (MOF), a ranked classification system that rates machine learning models based on their completeness and openness, following principles of open science, open source, open data, and open access. The MOF requires specific components of the model development lifecycle to be included and released under appropriate open licenses. This framework aims to prevent misrepresentation of models claiming to be open, guide researchers and developers in providing all model components under permissive licenses, and help companies, academia, and hobbyists identify models that can be safely adop
&lt;/p&gt;</description></item><item><title>&#20154;&#24037;&#26234;&#33021;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25112;&#20105;&#28216;&#25103;&#20013;&#19982;&#20154;&#31867;&#21709;&#24212;&#23384;&#22312;&#19968;&#33268;&#24615;&#65292;&#20294;&#20063;&#23384;&#22312;&#26174;&#33879;&#30340;&#24046;&#24322;&#65292;&#36825;&#34920;&#26126;&#22312;&#25919;&#31574;&#21046;&#23450;&#32773;&#20132;&#20986;&#33258;&#20027;&#26435;&#25110;&#21548;&#20174;&#22522;&#20110;AI&#30340;&#25112;&#30053;&#24314;&#35758;&#20043;&#21069;&#24212;&#35880;&#24910;&#23545;&#24453;&#12290;</title><link>https://arxiv.org/abs/2403.03407</link><description>&lt;p&gt;
&#20154;&#31867;&#23545;&#25239;&#26426;&#22120;&#65306;&#35821;&#35328;&#27169;&#22411;&#19982;&#25112;&#20105;&#28216;&#25103;
&lt;/p&gt;
&lt;p&gt;
Human vs. Machine: Language Models and Wargames
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03407
&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25112;&#20105;&#28216;&#25103;&#20013;&#19982;&#20154;&#31867;&#21709;&#24212;&#23384;&#22312;&#19968;&#33268;&#24615;&#65292;&#20294;&#20063;&#23384;&#22312;&#26174;&#33879;&#30340;&#24046;&#24322;&#65292;&#36825;&#34920;&#26126;&#22312;&#25919;&#31574;&#21046;&#23450;&#32773;&#20132;&#20986;&#33258;&#20027;&#26435;&#25110;&#21548;&#20174;&#22522;&#20110;AI&#30340;&#25112;&#30053;&#24314;&#35758;&#20043;&#21069;&#24212;&#35880;&#24910;&#23545;&#24453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25112;&#20105;&#28216;&#25103;&#22312;&#20891;&#20107;&#25112;&#30053;&#30340;&#21457;&#23637;&#21644;&#22269;&#23478;&#23545;&#23041;&#32961;&#25110;&#25915;&#20987;&#30340;&#21709;&#24212;&#20013;&#26377;&#30528;&#24736;&#20037;&#30340;&#21382;&#21490;&#12290;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#30340;&#20986;&#29616;&#25215;&#35834;&#20102;&#26356;&#22909;&#30340;&#20915;&#31574;&#21046;&#23450;&#21644;&#22686;&#24378;&#30340;&#20891;&#20107;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;AI&#31995;&#32479;&#65292;&#23588;&#20854;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#19982;&#20154;&#31867;&#30340;&#34892;&#20026;&#26377;&#20309;&#19981;&#21516;&#20173;&#23384;&#22312;&#20105;&#35758;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#25112;&#20105;&#28216;&#25103;&#23454;&#39564;&#65292;&#20849;&#26377;107&#20301;&#22269;&#23478;&#23433;&#20840;&#19987;&#23478;&#20154;&#31867;&#21442;&#19982;&#32773;&#21442;&#19982;&#65292;&#26088;&#22312;&#30740;&#31350;&#22312;&#19968;&#20010;&#34394;&#26500;&#30340;&#32654;&#20013;&#24773;&#26223;&#20013;&#30340;&#21361;&#26426;&#21319;&#32423;&#65292;&#24182;&#27604;&#36739;&#20154;&#31867;&#21442;&#19982;&#32773;&#19982;LLM&#27169;&#25311;&#21709;&#24212;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#21457;&#29616;LLM&#21644;&#20154;&#31867;&#21709;&#24212;&#23384;&#22312;&#26174;&#33879;&#19968;&#33268;&#24615;&#65292;&#20294;&#22312;&#25112;&#20105;&#28216;&#25103;&#20013;&#27169;&#25311;&#21644;&#20154;&#31867;&#21442;&#19982;&#32773;&#20043;&#38388;&#20063;&#23384;&#22312;&#26174;&#33879;&#30340;&#23450;&#37327;&#21644;&#23450;&#24615;&#24046;&#24322;&#65292;&#36825;&#20419;&#20351;&#20915;&#31574;&#32773;&#22312;&#20132;&#20986;&#33258;&#20027;&#26435;&#25110;&#36981;&#24490;&#22522;&#20110;AI&#30340;&#25112;&#30053;&#24314;&#35758;&#20043;&#21069;&#35880;&#24910;&#23545;&#24453;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03407v1 Announce Type: cross  Abstract: Wargames have a long history in the development of military strategy and the response of nations to threats or attacks. The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness. However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses. We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#26469;&#24314;&#31435;&#31185;&#23398;&#30740;&#31350;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#12290;&#20840;&#29699;&#20849;&#35782;&#12289;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#23545;&#20110;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#21644;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2401.15284</link><description>&lt;p&gt;
&#22312;&#31185;&#23398;&#30740;&#31350;&#20013;&#24314;&#31435;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
Building ethical guidelines for generative AI in scientific research. (arXiv:2401.15284v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#26469;&#24314;&#31435;&#31185;&#23398;&#30740;&#31350;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#12290;&#20840;&#29699;&#20849;&#35782;&#12289;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#23545;&#20110;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#21644;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#65288;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65289;&#27491;&#22312;&#36805;&#36895;&#25913;&#21464;&#23398;&#26415;&#30740;&#31350;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#31185;&#23398;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#30340;&#35752;&#35770;&#20173;&#28982;&#38646;&#25955;&#65292;&#24378;&#35843;&#20102;&#21327;&#21830;&#19968;&#33268;&#24615;&#26631;&#20934;&#30340;&#32039;&#36843;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#30340;&#24320;&#21457;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65306;&#20102;&#35299;&#27169;&#22411;&#22312;&#30495;&#23454;&#24615;&#21644;&#20559;&#35265;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#65307;&#23562;&#37325;&#38544;&#31169;&#12289;&#26426;&#23494;&#21644;&#29256;&#26435;&#65307;&#22312;&#34701;&#20837;&#27169;&#22411;&#36755;&#20986;&#26102;&#36991;&#20813;&#25220;&#34989;&#21644;&#36829;&#21453;&#25919;&#31574;&#65307;&#30830;&#20445;&#24212;&#29992;&#24102;&#26469;&#24635;&#20307;&#21033;&#30410;&#65307;&#20197;&#21450;&#36879;&#26126;&#12289;&#21487;&#22797;&#21046;&#22320;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#12290;&#36890;&#36807;&#21015;&#20030;&#24120;&#35265;&#22330;&#26223;&#26469;&#23637;&#31034;&#28508;&#22312;&#30340;&#20262;&#29702;&#36829;&#35268;&#34892;&#20026;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20840;&#29699;&#20849;&#35782;&#20197;&#21450;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#26159;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#24182;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative artificial intelligence tools like large language models are rapidly transforming academic research and real world applications. However, discussions on ethical guidelines for generative AI in science remain fragmented, underscoring the urgent need for consensus based standards. This paper offers an initial framework by developing analyses and mitigation strategies across five key themes: understanding model limitations regarding truthfulness and bias; respecting privacy, confidentiality, and copyright; avoiding plagiarism and policy violations when incorporating model output; ensuring applications provide overall benefit; and using AI transparently and reproducibly. Common scenarios are outlined to demonstrate potential ethical violations. We argue that global consensus coupled with professional training and reasonable enforcement are critical to promoting the benefits of AI while safeguarding research integrity.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#23646;&#24615;&#20999;&#25442;&#8221;&#30340;&#20844;&#24179;&#25277;&#26679;&#26426;&#21046;&#65292;&#29992;&#20110;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#29983;&#25104;&#30340;&#25968;&#25454;&#20013;&#28151;&#28102;&#25935;&#24863;&#23646;&#24615;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#29983;&#25104;&#20844;&#24179;&#25968;&#25454;&#21644;&#20445;&#25345;&#25968;&#25454;&#25928;&#29992;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2401.03140</link><description>&lt;p&gt;
&#36890;&#36807;&#20999;&#25442;&#26426;&#21046;&#65292;&#22312;&#25193;&#25955;&#27169;&#22411;&#20013;&#23454;&#29616;&#20844;&#24179;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Fair Sampling in Diffusion Models through Switching Mechanism. (arXiv:2401.03140v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#23646;&#24615;&#20999;&#25442;&#8221;&#30340;&#20844;&#24179;&#25277;&#26679;&#26426;&#21046;&#65292;&#29992;&#20110;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#29983;&#25104;&#30340;&#25968;&#25454;&#20013;&#28151;&#28102;&#25935;&#24863;&#23646;&#24615;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#29983;&#25104;&#20844;&#24179;&#25968;&#25454;&#21644;&#20445;&#25345;&#25968;&#25454;&#25928;&#29992;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#33391;&#22909;&#36924;&#36817;&#28508;&#22312;&#27010;&#29575;&#20998;&#24067;&#65292;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#39640;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#25193;&#25955;&#27169;&#22411;&#22312;&#20844;&#24179;&#24615;&#26041;&#38754;&#21463;&#21040;&#35757;&#32451;&#25968;&#25454;&#30340;&#20869;&#22312;&#20559;&#24046;&#30340;&#25918;&#22823;&#12290;&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#30340;&#25277;&#26679;&#36807;&#31243;&#21487;&#20197;&#36890;&#36807;&#26465;&#20214;&#24341;&#23548;&#26469;&#25511;&#21046;&#65292;&#20294;&#20043;&#21069;&#30340;&#30740;&#31350;&#35797;&#22270;&#25214;&#21040;&#23454;&#35777;&#24341;&#23548;&#26469;&#23454;&#29616;&#23450;&#37327;&#20844;&#24179;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#23646;&#24615;&#20999;&#25442;&#8221;&#26426;&#21046;&#30340;&#20855;&#26377;&#20844;&#24179;&#24847;&#35782;&#30340;&#25277;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#25193;&#25955;&#27169;&#22411;&#12290;&#22312;&#19981;&#38656;&#35201;&#39069;&#22806;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#25277;&#26679;&#26041;&#27861;&#21487;&#20197;&#22312;&#29983;&#25104;&#30340;&#25968;&#25454;&#20013;&#28151;&#28102;&#25935;&#24863;&#23646;&#24615;&#65292;&#32780;&#19981;&#20381;&#36182;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;&#20174;&#25968;&#23398;&#19978;&#35777;&#26126;&#20102;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;(i)&#29983;&#25104;&#20844;&#24179;&#25968;&#25454;&#21644;(ii)&#20445;&#25345;&#29983;&#25104;&#25968;&#25454;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have shown their effectiveness in generation tasks by well-approximating the underlying probability distribution. However, diffusion models are known to suffer from an amplified inherent bias from the training data in terms of fairness. While the sampling process of diffusion models can be controlled by conditional guidance, previous works have attempted to find empirical guidance to achieve quantitative fairness. To address this limitation, we propose a fairness-aware sampling method called \textit{attribute switching} mechanism for diffusion models. Without additional training, the proposed sampling can obfuscate sensitive attributes in generated data without relying on classifiers. We mathematically prove and experimentally demonstrate the effectiveness of the proposed method on two key aspects: (i) the generation of fair data and (ii) the preservation of the utility of the generated data.
&lt;/p&gt;</description></item></channel></rss>