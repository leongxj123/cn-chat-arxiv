<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>ShaRP&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#25490;&#21517;&#32467;&#26524;&#20013;&#21508;&#20010;&#29305;&#24449;&#30340;&#36129;&#29486;&#12290;&#21363;&#20351;&#20351;&#29992;&#32447;&#24615;&#35780;&#20998;&#20989;&#25968;&#65292;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#29305;&#24449;&#20998;&#24067;&#21644;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.16744</link><description>&lt;p&gt;
ShaRP&#65306;&#29992;Shapley&#20540;&#35299;&#37322;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
ShaRP: Explaining Rankings with Shapley Values. (arXiv:2401.16744v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16744
&lt;/p&gt;
&lt;p&gt;
ShaRP&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#25490;&#21517;&#32467;&#26524;&#20013;&#21508;&#20010;&#29305;&#24449;&#30340;&#36129;&#29486;&#12290;&#21363;&#20351;&#20351;&#29992;&#32447;&#24615;&#35780;&#20998;&#20989;&#25968;&#65292;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#29305;&#24449;&#20998;&#24067;&#21644;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25307;&#32856;&#12289;&#22823;&#23398;&#25307;&#29983;&#21644;&#36151;&#27454;&#31561;&#37325;&#35201;&#39046;&#22495;&#30340;&#31639;&#27861;&#20915;&#31574;&#24120;&#24120;&#26159;&#22522;&#20110;&#25490;&#21517;&#30340;&#12290;&#30001;&#20110;&#36825;&#20123;&#20915;&#31574;&#23545;&#20010;&#20154;&#12289;&#32452;&#32455;&#21644;&#20154;&#32676;&#30340;&#24433;&#21709;&#65292;&#26377;&#24517;&#35201;&#20102;&#35299;&#23427;&#20204;&#65306;&#20102;&#35299;&#20915;&#31574;&#26159;&#21542;&#36981;&#23432;&#27861;&#24459;&#65292;&#24110;&#21161;&#20010;&#20154;&#25552;&#39640;&#20182;&#20204;&#30340;&#25490;&#21517;&#65292;&#24182;&#35774;&#35745;&#26356;&#22909;&#30340;&#25490;&#21517;&#31243;&#24207;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;ShaRP&#65288;Shapley for Rankings and Preferences&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#29305;&#24449;&#23545;&#25490;&#21517;&#32467;&#26524;&#19981;&#21516;&#26041;&#38754;&#30340;&#36129;&#29486;&#12290;&#20351;&#29992;ShaRP&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#31639;&#27861;&#25490;&#21517;&#22120;&#20351;&#29992;&#30340;&#35780;&#20998;&#20989;&#25968;&#26159;&#24050;&#30693;&#30340;&#19988;&#26159;&#32447;&#24615;&#30340;&#65292;&#27599;&#20010;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#12290;&#36129;&#29486;&#21462;&#20915;&#20110;&#29305;&#24449;&#30340;&#20998;&#24067;&#20197;&#21450;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#24494;&#22937;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;ShaRP&#22522;&#20110;&#37327;&#21270;&#36755;&#20837;&#24433;&#21709;&#26694;&#26550;&#65292;&#24182;&#21487;&#20197;&#35745;&#31639;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic decisions in critical domains such as hiring, college admissions, and lending are often based on rankings. Because of the impact these decisions have on individuals, organizations, and population groups, there is a need to understand them: to know whether the decisions are abiding by the law, to help individuals improve their rankings, and to design better ranking procedures.  In this paper, we present ShaRP (Shapley for Rankings and Preferences), a framework that explains the contributions of features to different aspects of a ranked outcome, and is based on Shapley values. Using ShaRP, we show that even when the scoring function used by an algorithmic ranker is known and linear, the weight of each feature does not correspond to its Shapley value contribution. The contributions instead depend on the feature distributions, and on the subtle local interactions between the scoring features. ShaRP builds on the Quantitative Input Influence framework, and can compute the contri
&lt;/p&gt;</description></item></channel></rss>