<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#25552;&#20986;&#20102;Prejudice-Caprice Framework&#65288;PCF&#65289;&#26469;&#20840;&#38754;&#34913;&#37327;LLMs&#20013;&#30340;&#27495;&#35270;&#65292;&#32771;&#34385;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#30340;&#19968;&#36143;&#20559;&#35265;&#20559;&#22909;&#21644;&#20559;&#22909;&#21464;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.15481</link><description>&lt;p&gt;
&#20559;&#35265;&#21644;&#21453;&#22797;&#26080;&#24120;&#65306;&#34913;&#37327;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#31038;&#20250;&#27495;&#35270;&#30340;&#32479;&#35745;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15481
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Prejudice-Caprice Framework&#65288;PCF&#65289;&#26469;&#20840;&#38754;&#34913;&#37327;LLMs&#20013;&#30340;&#27495;&#35270;&#65292;&#32771;&#34385;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#30340;&#19968;&#36143;&#20559;&#35265;&#20559;&#22909;&#21644;&#20559;&#22909;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15481v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31038;&#20250;&#36816;&#33829;&#20013;&#30340;&#26085;&#30410;&#34701;&#21512;&#21152;&#21095;&#20102;&#23427;&#20204;&#23545;&#32463;&#27982;&#12289;&#27861;&#24459;&#12289;&#25945;&#32946;&#21644;&#21307;&#30103;&#31561;&#37325;&#35201;&#39046;&#22495;&#20915;&#31574;&#30340;&#24433;&#21709;&#65292;&#24341;&#21457;&#20102;&#20844;&#20247;&#23545;&#36825;&#20123;&#27169;&#22411;&#28041;&#21450;&#27495;&#35270;&#23433;&#20840;&#21644;&#21487;&#38752;&#24615;&#30340;&#25285;&#24551;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#27495;&#35270;&#27979;&#37327;&#26694;&#26550;&#20165;&#35780;&#20272;LLMs&#30340;&#24179;&#22343;&#27495;&#35270;&#34892;&#20026;&#65292;&#24448;&#24448;&#30001;&#20110;&#24573;&#35270;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#23548;&#33268;&#27495;&#35270;&#30340;&#22240;&#32032;&#65292;&#21363;LLMs&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#30340;&#39044;&#27979;&#21464;&#21270;&#32780;&#21464;&#24471;&#19981;&#36275;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Prejudice-Caprice Framework&#65288;PCF&#65289;&#65292;&#36890;&#36807;&#32771;&#34385;LLMs&#30340;&#19968;&#36143;&#20559;&#35265;&#20559;&#22909;&#21644;&#22312;&#22810;&#26679;&#19978;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15481v1 Announce Type: new  Abstract: The growing integration of large language models (LLMs) into social operations amplifies their impact on decisions in crucial areas such as economics, law, education, and healthcare, raising public concerns about these models' discrimination-related safety and reliability. However, prior discrimination measuring frameworks solely assess the average discriminatory behavior of LLMs, often proving inadequate due to the overlook of an additional discrimination-leading factor, i.e., the LLMs' prediction variation across diverse contexts. In this work, we present the Prejudice-Caprice Framework (PCF) that comprehensively measures discrimination in LLMs by considering both their consistently biased preference and preference variation across diverse contexts. Specifically, we mathematically dissect the aggregated contextualized discrimination risk of LLMs into prejudice risk, originating from LLMs' persistent prejudice, and caprice risk, stemmin
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35843;&#26597;&#30740;&#31350;&#21644;&#23454;&#39564;&#30740;&#31350;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#38169;&#35823;&#23545;&#20154;&#20204;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24378;&#21270;&#21051;&#26495;&#21360;&#35937;&#30340;&#38169;&#35823;&#24341;&#36215;&#26356;&#22810;&#20027;&#35266;&#19978;&#30340;&#20260;&#23475;&#20307;&#39564;&#65292;&#32780;&#36829;&#21453;&#21051;&#26495;&#21360;&#35937;&#30340;&#38169;&#35823;&#23545;&#30007;&#24615;&#20135;&#29983;&#26356;&#22823;&#30340;&#20027;&#35266;&#19978;&#30340;&#20260;&#23475;&#65292;&#26377;&#21161;&#20110;&#25105;&#20204;&#29702;&#35299;&#26426;&#22120;&#23398;&#20064;&#22312;&#24341;&#21457;&#21051;&#26495;&#21360;&#35937;&#21644;&#20260;&#23475;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.04420</link><description>&lt;p&gt;
&#27979;&#37327;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21051;&#26495;&#21360;&#35937;&#20260;&#23475;&#65306;&#38656;&#35201;&#20102;&#35299;&#35841;&#27491;&#22312;&#21463;&#21040;&#21738;&#20123;&#38169;&#35823;&#20197;&#21450;&#20197;&#20309;&#31181;&#26041;&#24335;&#21463;&#21040;&#20260;&#23475;
&lt;/p&gt;
&lt;p&gt;
Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04420
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35843;&#26597;&#30740;&#31350;&#21644;&#23454;&#39564;&#30740;&#31350;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#38169;&#35823;&#23545;&#20154;&#20204;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24378;&#21270;&#21051;&#26495;&#21360;&#35937;&#30340;&#38169;&#35823;&#24341;&#36215;&#26356;&#22810;&#20027;&#35266;&#19978;&#30340;&#20260;&#23475;&#20307;&#39564;&#65292;&#32780;&#36829;&#21453;&#21051;&#26495;&#21360;&#35937;&#30340;&#38169;&#35823;&#23545;&#30007;&#24615;&#20135;&#29983;&#26356;&#22823;&#30340;&#20027;&#35266;&#19978;&#30340;&#20260;&#23475;&#65292;&#26377;&#21161;&#20110;&#25105;&#20204;&#29702;&#35299;&#26426;&#22120;&#23398;&#20064;&#22312;&#24341;&#21457;&#21051;&#26495;&#21360;&#35937;&#21644;&#20260;&#23475;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#26222;&#21450;&#65292;&#25105;&#20204;&#38656;&#35201;&#20102;&#35299;&#23427;&#20204;&#21487;&#33021;&#36896;&#25104;&#30340;&#20260;&#23475;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#20844;&#24179;&#24615;&#25351;&#26631;&#24456;&#23569;&#22522;&#20110;&#20154;&#31867;&#23545;&#20260;&#23475;&#30340;&#24515;&#29702;&#20307;&#39564;&#12290;&#20511;&#37492;&#21051;&#26495;&#21360;&#35937;&#30340;&#31038;&#20250;&#24515;&#29702;&#23398;&#65292;&#25105;&#20204;&#20197;&#22270;&#20687;&#25628;&#32034;&#20013;&#30340;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;&#20154;&#20204;&#23545;&#26426;&#22120;&#23398;&#20064;&#38169;&#35823;&#30340;&#21453;&#24212;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20351;&#29992;&#35843;&#26597;&#30740;&#31350;&#34920;&#26126;&#65292;&#24182;&#38750;&#25152;&#26377;&#30340;&#26426;&#22120;&#23398;&#20064;&#38169;&#35823;&#37117;&#21453;&#26144;&#20102;&#21051;&#26495;&#21360;&#35937;&#65292;&#20063;&#27809;&#26377;&#21516;&#26679;&#30340;&#20260;&#23475;&#31243;&#24230;&#12290;&#28982;&#21518;&#65292;&#22312;&#23454;&#39564;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#38543;&#26426;&#20351;&#21442;&#19982;&#32773;&#25509;&#35302;&#21040;&#24378;&#21270;&#12289;&#36829;&#21453;&#21644;&#20013;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#38169;&#35823;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24378;&#21270;&#21051;&#26495;&#21360;&#35937;&#30340;&#38169;&#35823;&#24341;&#36215;&#26356;&#22810;&#20027;&#35266;&#19978;&#30340;&#20260;&#23475;&#20307;&#39564;&#65292;&#20294;&#23545;&#35748;&#30693;&#20449;&#24565;&#12289;&#24577;&#24230;&#25110;&#34892;&#20026;&#30340;&#25913;&#21464;&#24456;&#23567;&#12290;&#36825;&#31181;&#20307;&#39564;&#19978;&#30340;&#20260;&#23475;&#23545;&#22899;&#24615;&#24433;&#21709;&#26356;&#22823;&#12290;&#28982;&#32780;&#65292;&#26576;&#20123;&#36829;&#21453;&#21051;&#26495;&#21360;&#35937;&#30340;&#38169;&#35823;&#23545;&#30007;&#24615;&#20135;&#29983;&#26356;&#22823;&#30340;&#20027;&#35266;&#19978;&#30340;&#20260;&#23475;&#65292;&#21487;&#33021;&#26159;&#30001;&#20110;&#23545;&#30007;&#24615;&#38451;&#21018;&#24615;&#30340;&#23041;&#32961;&#24863;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;
As machine learning applications proliferate, we need an understanding of their potential for harm. However, current fairness metrics are rarely grounded in human psychological experiences of harm. Drawing on the social psychology of stereotypes, we use a case study of gender stereotypes in image search to examine how people react to machine learning errors. First, we use survey studies to show that not all machine learning errors reflect stereotypes nor are equally harmful. Then, in experimental studies we randomly expose participants to stereotype-reinforcing, -violating, and -neutral machine learning errors. We find stereotype-reinforcing errors induce more experientially (i.e., subjectively) harmful experiences, while having minimal changes to cognitive beliefs, attitudes, or behaviors. This experiential harm impacts women more than men. However, certain stereotype-violating errors are more experientially harmful for men, potentially due to perceived threats to masculinity. We conc
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#22312;&#20154;&#25165;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#22823;&#25968;&#25454;&#21644;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#32452;&#32455;&#21487;&#20197;&#20174;&#25968;&#25454;&#31185;&#23398;&#30340;&#35282;&#24230;&#29702;&#35299;&#32452;&#32455;&#34892;&#20026;&#24182;&#23454;&#26102;&#20570;&#20986;&#20915;&#31574;&#65292;&#20026;&#26377;&#25928;&#30340;&#20154;&#25165;&#31649;&#29702;&#25552;&#20379;&#26234;&#33021;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2307.03195</link><description>&lt;p&gt;
&#20154;&#25165;&#20998;&#26512;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Survey of Artificial Intelligence Techniques for Talent Analytics. (arXiv:2307.03195v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03195
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#22312;&#20154;&#25165;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#22823;&#25968;&#25454;&#21644;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#32452;&#32455;&#21487;&#20197;&#20174;&#25968;&#25454;&#31185;&#23398;&#30340;&#35282;&#24230;&#29702;&#35299;&#32452;&#32455;&#34892;&#20026;&#24182;&#23454;&#26102;&#20570;&#20986;&#20915;&#31574;&#65292;&#20026;&#26377;&#25928;&#30340;&#20154;&#25165;&#31649;&#29702;&#25552;&#20379;&#26234;&#33021;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#31454;&#20105;&#28608;&#28872;&#19988;&#24555;&#36895;&#21457;&#23637;&#30340;&#21830;&#19994;&#29615;&#22659;&#19979;&#65292;&#32452;&#32455;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#20197;&#37327;&#21270;&#26041;&#24335;&#20570;&#20986;&#20154;&#25165;&#30456;&#20851;&#20915;&#31574;&#30340;&#37325;&#35201;&#24615;&#12290;&#20107;&#23454;&#19978;&#65292;&#22823;&#25968;&#25454;&#21644;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#26368;&#26032;&#21457;&#23637;&#24050;&#32463;&#24443;&#24213;&#25913;&#21464;&#20102;&#20154;&#21147;&#36164;&#28304;&#31649;&#29702;&#12290;&#22823;&#35268;&#27169;&#20154;&#25165;&#21644;&#31649;&#29702;&#30456;&#20851;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20026;&#20225;&#19994;&#39046;&#23548;&#32773;&#25552;&#20379;&#20102;&#20174;&#25968;&#25454;&#31185;&#23398;&#35282;&#24230;&#29702;&#35299;&#32452;&#32455;&#34892;&#20026;&#21644;&#33719;&#21462;&#23454;&#38469;&#30693;&#35782;&#30340;&#26080;&#19982;&#20262;&#27604;&#26426;&#20250;&#65292;&#36827;&#32780;&#20026;&#23454;&#26102;&#20915;&#31574;&#21644;&#26377;&#25928;&#30340;&#20154;&#25165;&#31649;&#29702;&#25552;&#20379;&#26234;&#33021;&#25903;&#25345;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#20154;&#25165;&#20998;&#26512;&#24050;&#32463;&#25104;&#20026;&#24212;&#29992;&#25968;&#25454;&#31185;&#23398;&#22312;&#20154;&#21147;&#36164;&#28304;&#31649;&#29702;&#26041;&#38754;&#30340;&#26377;&#24076;&#26395;&#30340;&#39046;&#22495;&#65292;&#24341;&#36215;&#20102;&#20154;&#24037;&#26234;&#33021;&#31038;&#21306;&#30340;&#24191;&#27867;&#20851;&#27880;&#24182;&#28608;&#21457;&#20102;&#35768;&#22810;&#30740;&#31350;&#24037;&#20316;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26368;&#26032;&#12289;&#20840;&#38754;&#30340;&#20851;&#20110;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#22312;&#20154;&#25165;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#30340;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's competitive and fast-evolving business environment, it is a critical time for organizations to rethink how to make talent-related decisions in a quantitative manner. Indeed, the recent development of Big Data and Artificial Intelligence (AI) techniques have revolutionized human resource management. The availability of large-scale talent and management-related data provides unparalleled opportunities for business leaders to comprehend organizational behaviors and gain tangible knowledge from a data science perspective, which in turn delivers intelligence for real-time decision-making and effective talent management at work for their organizations. In the last decade, talent analytics has emerged as a promising field in applied data science for human resource management, garnering significant attention from AI communities and inspiring numerous research efforts. To this end, we present an up-to-date and comprehensive survey on AI technologies used for talent analytics in the f
&lt;/p&gt;</description></item></channel></rss>