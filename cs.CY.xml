<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#23454;&#29616;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#25935;&#24863;&#23646;&#24615;&#30340;&#21518;&#20195;&#30340;&#23545;&#29031;&#20998;&#24067;&#26469;&#30830;&#20445;&#20844;&#24179;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2310.17687</link><description>&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#39044;&#27979;&#30340;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Fairness for Predictions using Generative Adversarial Networks. (arXiv:2310.17687v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17687
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#23454;&#29616;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#25935;&#24863;&#23646;&#24615;&#30340;&#21518;&#20195;&#30340;&#23545;&#29031;&#20998;&#24067;&#26469;&#30830;&#20445;&#20844;&#24179;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#27861;&#24459;&#12289;&#20262;&#29702;&#21644;&#31038;&#20250;&#21407;&#22240;&#65292;&#39044;&#27979;&#20013;&#30340;&#20844;&#24179;&#24615;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#36890;&#24120;&#36890;&#36807;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#26469;&#23454;&#29616;&#65292;&#35813;&#20844;&#24179;&#24615;&#30830;&#20445;&#20010;&#20307;&#30340;&#39044;&#27979;&#19982;&#22312;&#19981;&#21516;&#25935;&#24863;&#23646;&#24615;&#19979;&#30340;&#23545;&#29031;&#19990;&#30028;&#20013;&#30340;&#39044;&#27979;&#30456;&#21516;&#12290;&#28982;&#32780;&#65292;&#35201;&#23454;&#29616;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#23545;&#29031;&#26159;&#19981;&#21487;&#35266;&#23519;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#31216;&#20026;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GCFN&#65289;&#65292;&#29992;&#20110;&#22312;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#19979;&#36827;&#34892;&#39044;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#19968;&#20010;&#37327;&#36523;&#23450;&#21046;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30452;&#25509;&#23398;&#20064;&#25935;&#24863;&#23646;&#24615;&#30340;&#21518;&#20195;&#30340;&#23545;&#29031;&#20998;&#24067;&#65292;&#28982;&#21518;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#29031;&#23186;&#20171;&#27491;&#21017;&#21270;&#26469;&#23454;&#26045;&#20844;&#24179;&#39044;&#27979;&#12290;&#22914;&#26524;&#23545;&#29031;&#20998;&#24067;&#23398;&#20064;&#24471;&#36275;&#22815;&#22909;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25968;&#23398;&#19978;&#30830;&#20445;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#30340;&#27010;&#24565;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;GCFN&#35299;&#20915;&#20102;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fairness in predictions is of direct importance in practice due to legal, ethical, and societal reasons. It is often achieved through counterfactual fairness, which ensures that the prediction for an individual is the same as that in a counterfactual world under a different sensitive attribute. However, achieving counterfactual fairness is challenging as counterfactuals are unobservable. In this paper, we develop a novel deep neural network called Generative Counterfactual Fairness Network (GCFN) for making predictions under counterfactual fairness. Specifically, we leverage a tailored generative adversarial network to directly learn the counterfactual distribution of the descendants of the sensitive attribute, which we then use to enforce fair predictions through a novel counterfactual mediator regularization. If the counterfactual distribution is learned sufficiently well, our method is mathematically guaranteed to ensure the notion of counterfactual fairness. Thereby, our GCFN addre
&lt;/p&gt;</description></item></channel></rss>