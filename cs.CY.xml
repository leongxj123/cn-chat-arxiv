<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26356;&#23545;&#35805;&#24335;&#30340;&#35299;&#37322;&#27169;&#22411;&#65292;&#24357;&#21512;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#29702;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#20197;&#21019;&#24314;&#26356;&#26377;&#25928;&#21644;&#24191;&#27867;&#24212;&#29992;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2302.03460</link><description>&lt;p&gt;
&#27880;&#24847;&#30041;&#19979;&#31354;&#38553;&#65281;&#29992;&#40065;&#26364;&#21151;&#33021;&#29702;&#35770;&#26500;&#24314;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#29702;&#35299;&#20043;&#38388;&#30340;&#26725;&#26753;
&lt;/p&gt;
&lt;p&gt;
Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding with Luhmann's Functional Theory of Communication. (arXiv:2302.03460v2 [cs.CY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03460
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26356;&#23545;&#35805;&#24335;&#30340;&#35299;&#37322;&#27169;&#22411;&#65292;&#24357;&#21512;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#29702;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#20197;&#21019;&#24314;&#26356;&#26377;&#25928;&#21644;&#24191;&#27867;&#24212;&#29992;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#24050;&#20174;&#19968;&#31181;&#20027;&#35201;&#30340;&#25216;&#26415;&#23398;&#31185;&#21457;&#23637;&#25104;&#19982;&#31038;&#20250;&#31185;&#23398;&#32039;&#23494;&#30456;&#20132;&#30340;&#39046;&#22495;&#12290;&#20154;&#31867;&#20559;&#22909;&#23545;&#27604;&#30340;&#35299;&#37322;&#65292;&#30830;&#20999;&#32780;&#35328;&#26159;&#21453;&#20107;&#23454;&#30340;&#35299;&#37322;&#65292;&#23545;&#20110;&#36825;&#31181;&#36716;&#21464;&#36215;&#21040;&#20102;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#21551;&#21457;&#21644;&#24341;&#39046;&#35745;&#31639;&#26426;&#31185;&#23398;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#20854;&#20182;&#21516;&#26679;&#37325;&#35201;&#30340;&#35266;&#23519;&#21364;&#21463;&#21040;&#20102;&#24456;&#23569;&#30340;&#20851;&#27880;&#12290;&#20154;&#31867;&#35299;&#37322;&#32773;&#24076;&#26395;&#36890;&#36807;&#23545;&#35805;&#24335;&#30340;&#20132;&#20114;&#19982;&#20154;&#24037;&#26234;&#33021;&#35299;&#37322;&#32773;&#36827;&#34892;&#20132;&#27969;&#30340;&#24895;&#26395;&#22312;&#31038;&#21306;&#20013;&#22522;&#26412;&#34987;&#24573;&#35270;&#12290;&#36825;&#32473;&#36825;&#31181;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#21644;&#24191;&#27867;&#24212;&#29992;&#24102;&#26469;&#20102;&#24456;&#22810;&#25361;&#25112;&#65292;&#22240;&#20026;&#26681;&#25454;&#39044;&#23450;&#20041;&#30340;&#30446;&#26631;&#25552;&#20379;&#21333;&#19968;&#30340;&#20248;&#21270;&#35299;&#37322;&#21487;&#33021;&#20250;&#22833;&#36133;&#65292;&#24182;&#19988;&#19981;&#33021;&#28385;&#36275;&#20854;&#25509;&#25910;&#32773;&#30340;&#29420;&#29305;&#38656;&#27714;&#65292;&#37492;&#20110;&#20154;&#31867;&#30693;&#35782;&#21644;&#24847;&#22270;&#30340;&#22810;&#26679;&#24615;&#12290;&#26412;&#25991;&#21033;&#29992;&#23612;&#20811;&#25289;&#26031;&#183;&#40065;&#26364;&#21644;&#20854;&#20182;&#20132;&#27969;&#23398;&#32773;&#38416;&#36848;&#30340;&#35265;&#35299;&#65292;&#25552;&#20986;&#20102;&#21521;&#26356;&#23545;&#35805;&#24335;&#30340;&#35299;&#37322;&#27169;&#22411;&#30340;&#36716;&#21464;&#65292;&#20854;&#20013;&#35299;&#37322;&#32773;&#21644;&#34987;&#35299;&#37322;&#32773;&#20043;&#38388;&#30340;&#20449;&#24687;&#25345;&#32493;&#20132;&#27969;&#26159;&#26680;&#24515;&#12290;&#36890;&#36807;&#36825;&#31181;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#24314;&#31435;&#26356;&#26377;&#25928;&#21644;&#24191;&#27867;&#24212;&#29992;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#24357;&#21512;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#29702;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past decade explainable artificial intelligence has evolved from a predominantly technical discipline into a field that is deeply intertwined with social sciences. Insights such as human preference for contrastive -- more precisely, counterfactual -- explanations have played a major role in this transition, inspiring and guiding the research in computer science. Other observations, while equally important, have received much less attention. The desire of human explainees to communicate with artificial intelligence explainers through a dialogue-like interaction has been mostly neglected by the community. This poses many challenges for the effectiveness and widespread adoption of such technologies as delivering a single explanation optimised according to some predefined objectives may fail to engender understanding in its recipients and satisfy their unique needs given the diversity of human knowledge and intention. Using insights elaborated by Niklas Luhmann and, more recently,
&lt;/p&gt;</description></item></channel></rss>