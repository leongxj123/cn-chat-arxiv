<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>AI&#20174;&#19994;&#32773;&#23545;&#20110;&#20844;&#24179;AI/ML&#30340;&#29702;&#35299;&#12289;&#38754;&#20020;&#30340;&#25361;&#25112;&#12289;&#19981;&#20844;&#24179;AI/ML&#30340;&#21518;&#26524;&#20197;&#21450;&#30830;&#20445;AI/ML&#20844;&#24179;&#24615;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.15481</link><description>&lt;p&gt;
AI/ML &#21457;&#23637;&#20013;&#30340;&#20844;&#24179;&#23548;&#33322;: &#20174;&#19994;&#32773;&#23545;AI/ML&#24320;&#21457;&#20013;&#30340;&#29702;&#35299;&#12289;&#25361;&#25112;&#21644;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Navigating Fairness: Practitioners' Understanding, Challenges, and Strategies in AI/ML Development
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15481
&lt;/p&gt;
&lt;p&gt;
AI&#20174;&#19994;&#32773;&#23545;&#20110;&#20844;&#24179;AI/ML&#30340;&#29702;&#35299;&#12289;&#38754;&#20020;&#30340;&#25361;&#25112;&#12289;&#19981;&#20844;&#24179;AI/ML&#30340;&#21518;&#26524;&#20197;&#21450;&#30830;&#20445;AI/ML&#20844;&#24179;&#24615;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21508;&#34892;&#19994;&#23545;AI/ML&#24212;&#29992;&#30340;&#22686;&#21152;&#24341;&#21457;&#20102;&#23545;AI/ML&#20844;&#24179;&#24615;&#30340;&#26356;&#22810;&#35752;&#35770;&#12290;&#34429;&#28982;&#24050;&#26377;&#20851;&#20110;AI/ML&#20844;&#24179;&#24615;&#30340;&#20808;&#21069;&#30740;&#31350;&#65292;&#20294;&#32570;&#20047;&#38024;&#23545;&#20102;&#35299;AI&#20174;&#19994;&#32773;&#22312;&#24320;&#21457;&#20844;&#24179;AI/ML&#36807;&#31243;&#20013;&#30340;&#35266;&#28857;&#21644;&#32463;&#39564;&#30340;&#23454;&#35777;&#30740;&#31350;&#12290;&#20102;&#35299;AI&#20174;&#19994;&#32773;&#23545;AI/ML&#20844;&#24179;&#24615;&#30340;&#30475;&#27861;&#21644;&#32463;&#39564;&#24456;&#37325;&#35201;&#65292;&#22240;&#20026;&#20182;&#20204;&#30452;&#25509;&#21442;&#19982;&#20854;&#20013;&#30340;&#24320;&#21457;&#21644;&#37096;&#32626;&#65292;&#20182;&#20204;&#30340;&#35265;&#35299;&#21487;&#20197;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#29616;&#23454;&#19990;&#30028;&#35270;&#35282;&#65292;&#24110;&#21161;&#29702;&#35299;&#30830;&#20445;AI/ML&#20844;&#24179;&#24615;&#25152;&#28041;&#21450;&#25361;&#25112;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;22&#20301;AI&#20174;&#19994;&#32773;&#30340;&#21322;&#32467;&#26500;&#21270;&#35775;&#35848;&#65292;&#20197;&#35843;&#26597;&#20182;&#20204;&#23545;&#8220;&#20844;&#24179;AI/ML&#8221;&#26159;&#20160;&#20040;&#30340;&#29702;&#35299;&#65292;&#20182;&#20204;&#22312;&#24320;&#21457;&#20844;&#24179;AI/ML&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#24320;&#21457;&#19981;&#20844;&#24179;AI/ML&#30340;&#21518;&#26524;&#65292;&#20197;&#21450;&#20182;&#20204;&#37319;&#21462;&#30340;&#31574;&#30053;&#26469;&#30830;&#20445;AI/ML&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#26694;&#26550;&#23637;&#31034;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15481v1 Announce Type: cross  Abstract: The rise in the use of AI/ML applications across industries has sparked more discussions about the fairness of AI/ML in recent times. While prior research on the fairness of AI/ML exists, there is a lack of empirical studies focused on understanding the views and experiences of AI practitioners in developing a fair AI/ML. Understanding AI practitioners' views and experiences on the fairness of AI/ML is important because they are directly involved in its development and deployment and their insights can offer valuable real-world perspectives on the challenges associated with ensuring fairness in AI/ML. We conducted semi-structured interviews with 22 AI practitioners to investigate their understanding of what a 'fair AI/ML' is, the challenges they face in developing a fair AI/ML, the consequences of developing an unfair AI/ML, and the strategies they employ to ensure AI/ML fairness. We developed a framework showcasing the relationship be
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#26377;&#26395;&#25552;&#20379;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#24212;&#27880;&#24847;&#20854;&#24212;&#29992;&#21487;&#33021;&#24102;&#26469;&#30340;&#39118;&#38505;&#65292;&#24182;&#31215;&#26497;&#37319;&#21462;&#31574;&#30053;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2403.14814</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#30340;&#26426;&#20250;&#21644;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The opportunities and risks of large language models in mental health
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14814
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#26377;&#26395;&#25552;&#20379;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#24212;&#27880;&#24847;&#20854;&#24212;&#29992;&#21487;&#33021;&#24102;&#26469;&#30340;&#39118;&#38505;&#65292;&#24182;&#31215;&#26497;&#37319;&#21462;&#31574;&#30053;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#29699;&#24515;&#29702;&#20581;&#24247;&#38382;&#39064;&#30340;&#21457;&#29983;&#29575;&#27491;&#22312;&#19978;&#21319;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#24847;&#35782;&#21040;&#29616;&#26377;&#30340;&#24515;&#29702;&#20445;&#20581;&#27169;&#24335;&#26080;&#27861;&#20805;&#20998;&#25193;&#23637;&#20197;&#28385;&#36275;&#38656;&#27714;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#20154;&#20204;&#23545;&#23427;&#20204;&#20855;&#26377;&#21019;&#36896;&#26032;&#39062;&#12289;&#22823;&#35268;&#27169;&#35299;&#20915;&#26041;&#26696;&#20197;&#25903;&#25345;&#24515;&#29702;&#20581;&#24247;&#30340;&#25215;&#35834;&#24863;&#21040;&#20048;&#35266;&#12290;&#23613;&#31649;&#23427;&#20204;&#36824;&#22788;&#20110;&#21021;&#26399;&#38454;&#27573;&#65292;LLMs&#24050;&#34987;&#24212;&#29992;&#20110;&#19982;&#24515;&#29702;&#20581;&#24247;&#30456;&#20851;&#30340;&#20219;&#21153;&#12290;&#26412;&#32508;&#36848;&#24635;&#32467;&#20102;&#24050;&#26377;&#25991;&#29486;&#20013;&#20851;&#20110;&#21033;&#29992;LLMs&#25552;&#20379;&#24515;&#29702;&#20581;&#24247;&#25945;&#32946;&#12289;&#35780;&#20272;&#21644;&#24178;&#39044;&#30340;&#21162;&#21147;&#65292;&#24182;&#31361;&#20986;&#20102;&#27599;&#20010;&#39046;&#22495;&#20013;&#20135;&#29983;&#31215;&#26497;&#24433;&#21709;&#30340;&#20851;&#38190;&#26426;&#20250;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#23558;LLMs&#24212;&#29992;&#20110;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#25152;&#20276;&#38543;&#30340;&#39118;&#38505;&#65292;&#24182;&#40723;&#21169;&#37319;&#29992;&#31574;&#30053;&#26469;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#12290;&#23545;&#20110;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#30340;&#36843;&#20999;&#38656;&#27714;&#24517;&#39035;&#19982;&#36127;&#36131;&#20219;&#30340;&#24515;&#29702;&#20581;&#24247;LLMs&#30340;&#24320;&#21457;&#12289;&#27979;&#35797;&#21644;&#37096;&#32626;&#30456;&#24179;&#34913;&#12290;&#29305;&#21035;&#20851;&#38190;&#30340;&#26159;&#30830;&#20445;&#24515;&#29702;&#20581;&#24247;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14814v1 Announce Type: cross  Abstract: Global rates of mental health concerns are rising and there is increasing realization that existing models of mental healthcare will not adequately expand to meet the demand. With the emergence of large language models (LLMs) has come great optimism regarding their promise to create novel, large-scale solutions to support mental health. Despite their nascence, LLMs have already been applied to mental health-related tasks. In this review, we summarize the extant literature on efforts to use LLMs to provide mental health education, assessment, and intervention and highlight key opportunities for positive impact in each area. We then highlight risks associated with LLMs application to mental health and encourage adoption of strategies to mitigate these risks. The urgent need for mental health support must be balanced with responsible development, testing, and deployment of mental health LLMs. Especially critical is ensuring that mental he
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#35780;&#20215;&#20013;&#30340;&#20844;&#24179;&#20851;&#27880;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#25968;&#25454;&#38598;&#21644;&#24320;&#21457;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#26816;&#27979;&#20986;&#20844;&#24179;&#24615;&#35780;&#35770;&#65292;&#24182;&#35782;&#21035;&#20986;&#32422;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;</title><link>https://arxiv.org/abs/2401.08097</link><description>&lt;p&gt;
AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#35780;&#20215;&#30340;&#20844;&#24179;&#20851;&#27880;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Study of Fairness Concerns in AI-based Mobile App Reviews
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.08097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#35780;&#20215;&#20013;&#30340;&#20844;&#24179;&#20851;&#27880;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#25968;&#25454;&#38598;&#21644;&#24320;&#21457;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#26816;&#27979;&#20986;&#20844;&#24179;&#24615;&#35780;&#35770;&#65292;&#24182;&#35782;&#21035;&#20986;&#32422;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#24179;&#26159;AI&#31995;&#32479;&#20013;&#24517;&#39035;&#35299;&#20915;&#30340;&#31038;&#20250;&#25216;&#26415;&#38382;&#39064;&#20043;&#19968;&#12290;&#19981;&#20844;&#24179;&#30340;AI&#31995;&#32479;&#65292;&#29305;&#21035;&#26159;&#19981;&#20844;&#24179;&#30340;AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#65292;&#21487;&#33021;&#32473;&#20840;&#29699;&#24456;&#22823;&#19968;&#37096;&#20998;&#20154;&#21475;&#24102;&#26469;&#22256;&#38590;&#12290;&#26412;&#25991;&#26088;&#22312;&#20998;&#26512;AI&#22522;&#20110;&#24212;&#29992;&#35780;&#20215;&#20013;&#30340;&#20844;&#24179;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#25163;&#21160;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20844;&#24179;&#24615;&#21644;&#38750;&#20844;&#24179;&#24615;&#35780;&#35770;&#30340;&#32479;&#35745;&#26679;&#26412;&#12290;&#21033;&#29992;&#36825;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#24320;&#21457;&#21644;&#35780;&#20272;&#20102;&#19968;&#32452;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#21306;&#20998;&#20844;&#24179;&#24615;&#35780;&#35770;&#21644;&#38750;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#26368;&#20339;&#30340;&#20998;&#31867;&#22120;&#21487;&#20197;&#20197;94%&#30340;&#31934;&#30830;&#24230;&#26816;&#27979;&#21040;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#26368;&#20339;&#20998;&#31867;&#22120;&#24212;&#29992;&#20110;&#20174;108&#20010;AI&#22522;&#20110;&#24212;&#29992;&#25910;&#38598;&#30340;&#32422;950&#19975;&#26465;&#35780;&#35770;&#65292;&#35782;&#21035;&#20986;&#32422;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;K-means&#32858;&#31867;&#25216;&#26415;&#24212;&#29992;&#20110;&#36825;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.08097v2 Announce Type: replace-cross Abstract: Fairness is one of the socio-technical concerns that must be addressed in AI-based systems. Unfair AI-based systems, particularly unfair AI-based mobile apps, can pose difficulties for a significant proportion of the global population. This paper aims to analyze fairness concerns in AI-based app reviews.We first manually constructed a ground-truth dataset, including a statistical sample of fairness and non-fairness reviews. Leveraging the ground-truth dataset, we developed and evaluated a set of machine learning and deep learning classifiers that distinguish fairness reviews from non-fairness reviews. Our experiments show that our best-performing classifier can detect fairness reviews with a precision of 94%. We then applied the best-performing classifier on approximately 9.5M reviews collected from 108 AI-based apps and identified around 92K fairness reviews. Next, applying the K-means clustering technique to the 92K fairness r
&lt;/p&gt;</description></item><item><title>DSA&#36879;&#26126;&#25968;&#25454;&#24211;&#23545;&#27431;&#30431;&#20843;&#22823;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#22312;&#21069;100&#22825;&#25552;&#20132;&#30340;&#23457;&#26680;&#34892;&#21160;&#25968;&#25454;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#24179;&#21488;&#22312;&#23457;&#26680;&#34892;&#21160;&#26041;&#38754;&#30340;&#37096;&#20998;&#36981;&#24490;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2312.10269</link><description>&lt;p&gt;
DSA&#36879;&#26126;&#25968;&#25454;&#24211;&#65306;&#31038;&#20132;&#23186;&#20307;&#33258;&#25105;&#25253;&#21578;&#30340;&#23457;&#26680;&#34892;&#21160;
&lt;/p&gt;
&lt;p&gt;
The DSA Transparency Database: Auditing Self-reported Moderation Actions by Social Media. (arXiv:2312.10269v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.10269
&lt;/p&gt;
&lt;p&gt;
DSA&#36879;&#26126;&#25968;&#25454;&#24211;&#23545;&#27431;&#30431;&#20843;&#22823;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#22312;&#21069;100&#22825;&#25552;&#20132;&#30340;&#23457;&#26680;&#34892;&#21160;&#25968;&#25454;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#24179;&#21488;&#22312;&#23457;&#26680;&#34892;&#21160;&#26041;&#38754;&#30340;&#37096;&#20998;&#36981;&#24490;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;2023&#24180;9&#26376;&#24320;&#22987;&#65292;&#25968;&#23383;&#26381;&#21153;&#27861;&#26696;(DSA)&#35201;&#27714;&#22823;&#22411;&#22312;&#32447;&#24179;&#21488;&#21521;DSA&#36879;&#26126;&#25968;&#25454;&#24211;&#25552;&#20132;&#20851;&#20110;&#20182;&#20204;&#22312;&#27431;&#30431;&#20869;&#37319;&#21462;&#30340;&#27599;&#20010;&#23457;&#26680;&#34892;&#21160;&#30340;&#35814;&#32454;&#25968;&#25454;&#12290;&#20174;&#19968;&#24320;&#22987;&#65292;&#36825;&#20010;&#38598;&#20013;&#24335;&#25968;&#25454;&#24211;&#23601;&#24341;&#36215;&#20102;&#23398;&#26415;&#30028;&#30340;&#20852;&#36259;&#65292;&#22240;&#20026;&#23427;&#26159;&#29616;&#23454;&#19990;&#30028;&#22312;&#32447;&#23457;&#26680;&#25968;&#25454;&#30340;&#19968;&#20010;&#21069;&#25152;&#26410;&#26377;&#30340;&#12289;&#21487;&#33021;&#26159;&#29420;&#29305;&#30340;&#23453;&#24211;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#28145;&#20837;&#20998;&#26512;&#20102;&#27431;&#30431;&#20843;&#20010;&#26368;&#22823;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#22312;&#25968;&#25454;&#24211;&#30340;&#21069;100&#22825;&#25552;&#20132;&#30340;&#25152;&#26377;3.53&#20159;&#26465;&#35760;&#24405;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23545;&#24179;&#21488;&#20043;&#38388;&#36827;&#34892;&#20102;&#27604;&#36739;&#30740;&#31350;&#65292;&#21253;&#25324;&#65306;&#23457;&#26680;&#34892;&#21160;&#30340;&#25968;&#37327;&#12289;&#20915;&#31574;&#20381;&#25454;&#12289;&#24212;&#29992;&#30340;&#38480;&#21046;&#31867;&#22411;&#12289;&#23457;&#26680;&#20869;&#23481;&#31867;&#22411;&#12289;&#23457;&#26680;&#34892;&#21160;&#30340;&#21450;&#26102;&#24615;&#21644;&#25552;&#20132;&#24773;&#20917;&#65292;&#20197;&#21450;&#20351;&#29992;&#30340;&#33258;&#21160;&#21270;&#31243;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#19982;&#24179;&#21488;&#33258;&#24049;&#30340;&#36879;&#26126;&#25253;&#21578;&#36827;&#34892;&#20102;&#20869;&#23481;&#20132;&#21449;&#26816;&#26597;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#20197;&#19979;&#32467;&#26524;&#12290;(i)&#24179;&#21488;&#21482;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36981;&#24490;&#20102;&#23457;&#26680;&#34892;&#21160;&#30340;&#21746;&#23398;&#21644;&#26041;&#27861;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since September 2023, the Digital Services Act (DSA) obliges large online platforms to submit detailed data on each moderation action they take within the European Union (EU) to the DSA Transparency Database. From its inception, this centralized database has sparked scholarly interest as an unprecedented and potentially unique trove of data on real-world online moderation. Here, we thoroughly analyze all 353.12M records submitted by the eight largest social media platforms in the EU during the first 100 days of the database. Specifically, we conduct a platform-wise comparative study of their: volume of moderation actions, grounds for decision, types of applied restrictions, types of moderated content, timeliness in undertaking and submitting moderation actions, and use of automation. Furthermore, we systematically cross-check the contents of the database with the platforms' own transparency reports. Our analyses reveal that (i) the platforms adhered only in part to the philosophy and s
&lt;/p&gt;</description></item></channel></rss>