<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#26469;&#24314;&#31435;&#31185;&#23398;&#30740;&#31350;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#12290;&#20840;&#29699;&#20849;&#35782;&#12289;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#23545;&#20110;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#21644;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2401.15284</link><description>&lt;p&gt;
&#22312;&#31185;&#23398;&#30740;&#31350;&#20013;&#24314;&#31435;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
Building ethical guidelines for generative AI in scientific research. (arXiv:2401.15284v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#26469;&#24314;&#31435;&#31185;&#23398;&#30740;&#31350;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#12290;&#20840;&#29699;&#20849;&#35782;&#12289;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#23545;&#20110;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#21644;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#65288;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65289;&#27491;&#22312;&#36805;&#36895;&#25913;&#21464;&#23398;&#26415;&#30740;&#31350;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#31185;&#23398;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#30340;&#35752;&#35770;&#20173;&#28982;&#38646;&#25955;&#65292;&#24378;&#35843;&#20102;&#21327;&#21830;&#19968;&#33268;&#24615;&#26631;&#20934;&#30340;&#32039;&#36843;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#30340;&#24320;&#21457;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65306;&#20102;&#35299;&#27169;&#22411;&#22312;&#30495;&#23454;&#24615;&#21644;&#20559;&#35265;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#65307;&#23562;&#37325;&#38544;&#31169;&#12289;&#26426;&#23494;&#21644;&#29256;&#26435;&#65307;&#22312;&#34701;&#20837;&#27169;&#22411;&#36755;&#20986;&#26102;&#36991;&#20813;&#25220;&#34989;&#21644;&#36829;&#21453;&#25919;&#31574;&#65307;&#30830;&#20445;&#24212;&#29992;&#24102;&#26469;&#24635;&#20307;&#21033;&#30410;&#65307;&#20197;&#21450;&#36879;&#26126;&#12289;&#21487;&#22797;&#21046;&#22320;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#12290;&#36890;&#36807;&#21015;&#20030;&#24120;&#35265;&#22330;&#26223;&#26469;&#23637;&#31034;&#28508;&#22312;&#30340;&#20262;&#29702;&#36829;&#35268;&#34892;&#20026;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20840;&#29699;&#20849;&#35782;&#20197;&#21450;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#26159;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#24182;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative artificial intelligence tools like large language models are rapidly transforming academic research and real world applications. However, discussions on ethical guidelines for generative AI in science remain fragmented, underscoring the urgent need for consensus based standards. This paper offers an initial framework by developing analyses and mitigation strategies across five key themes: understanding model limitations regarding truthfulness and bias; respecting privacy, confidentiality, and copyright; avoiding plagiarism and policy violations when incorporating model output; ensuring applications provide overall benefit; and using AI transparently and reproducibly. Common scenarios are outlined to demonstrate potential ethical violations. We argue that global consensus coupled with professional training and reasonable enforcement are critical to promoting the benefits of AI while safeguarding research integrity.
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#25104;&#21151;&#22797;&#21046;&#20102;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#65292;&#20294;&#20854;&#32467;&#26524;&#34920;&#26126;&#24179;&#22343;&#35780;&#32423;&#26377;&#19978;&#21319;&#20559;&#24046;&#21644;&#36739;&#20302;&#30340;&#21464;&#24322;&#24615;&#19982;&#32467;&#26500;&#25928;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.10679</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#22797;&#21046;&#36328;&#25991;&#21270;&#20010;&#24615;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Large language models can replicate cross-cultural differences in personality. (arXiv:2310.10679v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10679
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#25104;&#21151;&#22797;&#21046;&#20102;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#65292;&#20294;&#20854;&#32467;&#26524;&#34920;&#26126;&#24179;&#22343;&#35780;&#32423;&#26377;&#19978;&#21319;&#20559;&#24046;&#21644;&#36739;&#20302;&#30340;&#21464;&#24322;&#24615;&#19982;&#32467;&#26500;&#25928;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#39564;(N=8000)&#26469;&#30830;&#23450;GPT-4&#26159;&#21542;&#21487;&#20197;&#22797;&#21046;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#12290;&#25105;&#20204;&#36873;&#25321;&#32654;&#22269;&#21644;&#38889;&#22269;&#20316;&#20026;&#25991;&#21270;&#23545;&#27604;&#65292;&#22240;&#20026;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#36825;&#20004;&#20010;&#22269;&#23478;&#30340;&#20154;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#20154;&#26684;&#24046;&#24322;&#12290;&#25105;&#20204;&#25805;&#32437;&#20102;&#27169;&#25311;&#30340;&#30446;&#26631;&#65288;&#32654;&#22269; vs. &#38889;&#22269;&#65289;&#65292;&#38382;&#21367;&#30340;&#35821;&#35328;&#65288;&#33521;&#35821; vs. &#38889;&#35821;&#65289;&#20197;&#21450;&#35821;&#35328;&#27169;&#22411;&#65288;GPT-4 vs. GPT-3.5&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4&#22797;&#21046;&#20102;&#27599;&#20010;&#22240;&#23376;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#35780;&#32423;&#20855;&#26377;&#19978;&#21319;&#20559;&#24046;&#65292;&#24182;&#19988;&#27604;&#20154;&#31867;&#26679;&#26412;&#30340;&#21464;&#24322;&#24615;&#26356;&#20302;&#65292;&#20197;&#21450;&#32467;&#26500;&#25928;&#24230;&#36739;&#20302;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21021;&#27493;&#30340;&#35777;&#25454;&#35828;&#26126;LLMs&#21487;&#20197;&#20419;&#36827;&#36328;&#25991;&#21270;&#24515;&#29702;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We use a large-scale experiment (N=8000) to determine whether GPT-4 can replicate cross-cultural differences in the Big Five, measured using the Ten-Item Personality Inventory. We used the US and South Korea as the cultural pair, given that prior research suggests substantial personality differences between people from these two countries. We manipulated the target of the simulation (US vs. Korean), the language of the inventory (English vs. Korean), and the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4 replicated the cross-cultural differences for each factor. However, mean ratings had an upward bias and exhibited lower variation than in the human samples, as well as lower structural validity. Overall, we provide preliminary evidence that LLMs can aid cross-cultural psychological research.
&lt;/p&gt;</description></item></channel></rss>