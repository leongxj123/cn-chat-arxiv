<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#26412;&#25991;&#36890;&#36807;&#25506;&#35752;&#20449;&#24687;&#38388;&#31454;&#20105;&#65292;&#25552;&#20986;&#21033;&#29992;&#20449;&#24687;&#24066;&#22330;&#26412;&#36523;&#20316;&#20026;&#26377;&#25928;&#20943;&#36731;AI&#32842;&#22825;&#26426;&#22120;&#20154;&#36755;&#20986;&#39118;&#38505;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#25351;&#20986;&#30417;&#31649;&#32773;&#22312;&#38754;&#23545;&#26032;&#25216;&#26415;&#19981;&#30830;&#23450;&#24615;&#26102;&#24448;&#24448;&#36807;&#24230;&#35880;&#24910;&#65292;&#38656;&#37325;&#26032;&#35780;&#20272;&#30417;&#31649;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.11046</link><description>&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#38388;&#31454;&#20105;&#35843;&#25511;&#32842;&#22825;&#26426;&#22120;&#20154;&#36755;&#20986;
&lt;/p&gt;
&lt;p&gt;
Regulating Chatbot Output via Inter-Informational Competition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25506;&#35752;&#20449;&#24687;&#38388;&#31454;&#20105;&#65292;&#25552;&#20986;&#21033;&#29992;&#20449;&#24687;&#24066;&#22330;&#26412;&#36523;&#20316;&#20026;&#26377;&#25928;&#20943;&#36731;AI&#32842;&#22825;&#26426;&#22120;&#20154;&#36755;&#20986;&#39118;&#38505;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#25351;&#20986;&#30417;&#31649;&#32773;&#22312;&#38754;&#23545;&#26032;&#25216;&#26415;&#19981;&#30830;&#23450;&#24615;&#26102;&#24448;&#24448;&#36807;&#24230;&#35880;&#24910;&#65292;&#38656;&#37325;&#26032;&#35780;&#20272;&#30417;&#31649;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#30340;&#20986;&#29616;&#24341;&#21457;&#20102;&#19968;&#24180;&#22810;&#30340;&#30417;&#31649;&#29378;&#28526;&#12290;&#28982;&#32780;&#65292;&#23569;&#25968;&#29616;&#26377;&#30740;&#31350;&#20005;&#26684;&#36136;&#30097;&#20102;&#36825;&#26679;&#19968;&#20010;&#20551;&#35774;&#65306;&#22914;&#26524;&#19981;&#32463;&#35268;&#33539;&#65292;AI&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#36755;&#20986;&#20250;&#23545;&#20154;&#31867;&#20107;&#21153;&#36896;&#25104;&#23454;&#36136;&#19988;&#20005;&#37325;&#30340;&#20260;&#23475;&#12290;&#22823;&#22810;&#25968;&#30740;&#31350;&#20154;&#21592;&#24573;&#35270;&#20102;&#20449;&#24687;&#24066;&#22330;&#26412;&#36523;&#21487;&#20197;&#26377;&#25928;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#30340;&#20851;&#38190;&#21487;&#33021;&#24615;&#65292;&#24182;&#22240;&#27492;&#20542;&#21521;&#20110;&#20351;&#29992;&#30417;&#31649;&#24037;&#20855;&#30452;&#25509;&#35299;&#20915;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20851;&#27880;&#21508;&#31181;&#28192;&#36947;&#20043;&#38388;&#30340;&#20449;&#24687;&#31454;&#20105;&#65292;&#21457;&#23637;&#20102;&#19968;&#20010;&#37325;&#26032;&#35780;&#20272;AI&#30456;&#20851;&#20869;&#23481;&#39118;&#38505;&#21644;&#30456;&#24212;&#30417;&#31649;&#25552;&#35758;&#30340;&#26631;&#20934;&#12290;&#38271;&#36798;&#25968;&#21313;&#24180;&#30340;&#20449;&#24687;&#21644;&#36890;&#20449;&#25216;&#26415;&#30417;&#31649;&#21490;&#34920;&#26126;&#65292;&#30417;&#31649;&#32773;&#22312;&#38754;&#23545;&#26032;&#25216;&#26415;&#24102;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#26102;&#24448;&#24448;&#36807;&#20110;&#35880;&#24910;&#65292;&#24182;&#22312;&#25552;&#20986;&#36807;&#24230;&#30340;&#30417;&#31649;&#25514;&#26045;&#26102;&#29359;&#38169;&#35823;&#12290;&#20107;&#23454;&#19978;&#65292;&#20016;&#23500;&#30340;&#32463;&#39564;&#25968;&#25454;&#25903;&#25345;&#20102;&#20449;&#24687;&#24066;&#22330;&#26426;&#21046;&#22312;&#20449;&#24687;&#30417;&#31649;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11046v1 Announce Type: cross  Abstract: The advent of ChatGPT has sparked over a year of regulatory frenzy. However, few existing studies have rigorously questioned the assumption that, if left unregulated, AI chatbot's output would inflict tangible, severe real harm on human affairs. Most researchers have overlooked the critical possibility that the information market itself can effectively mitigate these risks and, as a result, they tend to use regulatory tools to address the issue directly. This Article develops a yardstick for reevaluating both AI-related content risks and corresponding regulatory proposals by focusing on inter-informational competition among various outlets. The decades-long history of regulating information and communications technologies indicates that regulators tend to err too much on the side of caution and to put forward excessive regulatory measures when encountering the uncertainties brought about by new technologies. In fact, a trove of empiric
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20844;&#24179;&#35780;&#20272;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#32676;&#20307;&#20013;&#30456;&#20284;&#30340;&#20010;&#20307;&#26469;&#35299;&#20915;&#32676;&#20307;&#20043;&#38388;&#30340;&#31995;&#32479;&#24046;&#24322;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#20542;&#21521;&#24471;&#20998;&#65292;&#35782;&#21035;&#23545;&#31561;&#20010;&#20307;&#65292;&#36991;&#20813;&#20102;&#27604;&#36739;&#19981;&#21516;&#31867;&#22411;&#30340;&#20010;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20844;&#24179;&#24615;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18160</link><description>&lt;p&gt;
&#23545;&#31561;&#20844;&#24179;&#24615;&#8212;&#8212;&#35299;&#20915;&#20844;&#24179;&#35780;&#20272;&#20013;&#32676;&#20307;&#20043;&#38388;&#31995;&#32479;&#24046;&#24322;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Counterpart Fairness -- Addressing Systematic between-group Differences in Fairness Evaluation. (arXiv:2305.18160v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18160
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20844;&#24179;&#35780;&#20272;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#32676;&#20307;&#20013;&#30456;&#20284;&#30340;&#20010;&#20307;&#26469;&#35299;&#20915;&#32676;&#20307;&#20043;&#38388;&#30340;&#31995;&#32479;&#24046;&#24322;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#20542;&#21521;&#24471;&#20998;&#65292;&#35782;&#21035;&#23545;&#31561;&#20010;&#20307;&#65292;&#36991;&#20813;&#20102;&#27604;&#36739;&#19981;&#21516;&#31867;&#22411;&#30340;&#20010;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20844;&#24179;&#24615;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#36741;&#21161;&#20915;&#31574;&#26102;&#65292;&#30830;&#20445;&#31639;&#27861;&#20915;&#31574;&#20844;&#24179;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#21363;&#19981;&#27495;&#35270;&#29305;&#23450;&#20010;&#20307;/&#32676;&#20307;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#24369;&#21183;&#32676;&#20307;&#30340;&#20154;&#12290;&#29616;&#26377;&#30340;&#32676;&#20307;&#20844;&#24179;&#26041;&#27861;&#35201;&#27714;&#36827;&#34892;&#24179;&#31561;&#30340;&#32676;&#20307;&#27979;&#37327;&#65292;&#20294;&#26410;&#32771;&#34385;&#32676;&#20307;&#20043;&#38388;&#30340;&#31995;&#32479;&#24046;&#24322;&#12290;&#28151;&#28102;&#22240;&#32032;&#65292;&#36825;&#20123;&#22240;&#32032;&#34429;&#28982;&#19982;&#25935;&#24863;&#21464;&#37327;&#26080;&#20851;&#65292;&#20294;&#34920;&#29616;&#20986;&#31995;&#32479;&#24046;&#24322;&#65292;&#20250;&#23545;&#20844;&#24179;&#35780;&#20272;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35748;&#20026;&#20844;&#24179;&#27979;&#37327;&#24212;&#35813;&#22522;&#20110;&#19981;&#21516;&#32676;&#20307;&#20013;&#30456;&#20284;&#20110;&#24863;&#20852;&#36259;&#20219;&#21153;&#30340;&#23545;&#31561;&#20154;&#65288;&#21363;&#24444;&#27492;&#30456;&#20284;&#30340;&#20010;&#20307;&#65289;&#20043;&#38388;&#30340;&#27604;&#36739;&#65292;&#20854;&#32676;&#20307;&#36523;&#20221;&#19981;&#21487;&#36890;&#36807;&#25506;&#32034;&#28151;&#28102;&#22240;&#32032;&#31639;&#27861;&#22320;&#21306;&#20998;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#20542;&#21521;&#24471;&#20998;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#23545;&#31561;&#20010;&#20307;&#65292;&#20197;&#36991;&#20813;&#20844;&#24179;&#35780;&#20272;&#27604;&#36739;&#8220;&#27225;&#23376;&#8221;&#21644;&#8220;&#33529;&#26524;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
When using machine learning (ML) to aid decision-making, it is critical to ensure that an algorithmic decision is fair, i.e., it does not discriminate against specific individuals/groups, particularly those from underprivileged populations. Existing group fairness methods require equal group-wise measures, which however fails to consider systematic between-group differences. The confounding factors, which are non-sensitive variables but manifest systematic differences, can significantly affect fairness evaluation. To tackle this problem, we believe that a fairness measurement should be based on the comparison between counterparts (i.e., individuals who are similar to each other with respect to the task of interest) from different groups, whose group identities cannot be distinguished algorithmically by exploring confounding factors. We have developed a propensity-score-based method for identifying counterparts, which prevents fairness evaluation from comparing "oranges" with "apples". 
&lt;/p&gt;</description></item></channel></rss>