<rss version="2.0"><channel><title>Chat Arxiv cs.CY</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CY</description><item><title>&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#23384;&#22312;&#19968;&#20123;&#26080;&#20559;&#23376;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#20381;&#36182;&#31639;&#27861;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#34987;&#25552;&#21462;&#20986;&#26469;&#65292;&#24182;&#19988;&#36825;&#31181;&#29305;&#23450;&#26550;&#26500;&#26080;&#27861;&#23398;&#20064;&#20219;&#20309;&#29305;&#23450;&#30340;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2403.14200</link><description>&lt;p&gt;
&#25163;&#26415;&#21592;&#21435;&#20559;&#35265;&#65306;&#31070;&#22855;&#30340;&#26435;&#37325;&#21450;&#22914;&#20309;&#25214;&#21040;&#23427;&#20204;
&lt;/p&gt;
&lt;p&gt;
Debiasing surgeon: fantastic weights and how to find them
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14200
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#23384;&#22312;&#19968;&#20123;&#26080;&#20559;&#23376;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#20381;&#36182;&#31639;&#27861;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#34987;&#25552;&#21462;&#20986;&#26469;&#65292;&#24182;&#19988;&#36825;&#31181;&#29305;&#23450;&#26550;&#26500;&#26080;&#27861;&#23398;&#20064;&#20219;&#20309;&#29305;&#23450;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20170;&#19968;&#20010;&#26085;&#30410;&#20851;&#27880;&#30340;&#29616;&#35937;&#26159;&#31639;&#27861;&#20559;&#35265;&#30340;&#20986;&#29616;&#65292;&#23427;&#21487;&#33021;&#23548;&#33268;&#19981;&#20844;&#24179;&#30340;&#27169;&#22411;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#21435;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#37319;&#29992;&#26356;&#25110;&#22810;&#25110;&#23569;&#22797;&#26434;&#30340;&#26041;&#27861;&#26469;&#38459;&#27490;&#36825;&#20123;&#27169;&#22411;&#22823;&#35268;&#27169;&#22320;&#20351;&#29992;&#36825;&#20123;&#20559;&#35265;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#38382;&#39064;&#20986;&#29616;&#20102;&#65306;&#36825;&#31181;&#39069;&#22806;&#30340;&#22797;&#26434;&#24615;&#30495;&#30340;&#26377;&#24517;&#35201;&#21527;&#65311;&#19968;&#20010;&#26222;&#36890;&#35757;&#32451;&#30340;&#27169;&#22411;&#26159;&#21542;&#24050;&#32463;&#21253;&#21547;&#20102;&#19968;&#20123;&#21487;&#20197;&#29420;&#31435;&#20351;&#29992;&#30340;&#8220;&#26080;&#20559;&#23376;&#32593;&#32476;&#8221;&#65292;&#24182;&#19988;&#21487;&#20197;&#25552;&#20986;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#32780;&#19981;&#20381;&#36182;&#20110;&#31639;&#27861;&#20559;&#35265;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#30340;&#23376;&#32593;&#32476;&#36890;&#24120;&#23384;&#22312;&#65292;&#24182;&#19988;&#21487;&#20197;&#20174;&#19968;&#20010;&#26222;&#36890;&#35757;&#32451;&#30340;&#27169;&#22411;&#20013;&#25552;&#21462;&#20986;&#26469;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#36825;&#31181;&#29305;&#23450;&#30340;&#26550;&#26500;&#26080;&#27861;&#23398;&#20064;&#29305;&#23450;&#30340;&#20559;&#35265;&#65292;&#34920;&#26126;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#21487;&#33021;&#36890;&#36807;&#26550;&#26500;&#19978;&#30340;&#23545;&#31574;&#26469;&#35299;&#20915;&#20559;&#35265;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14200v1 Announce Type: cross  Abstract: Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic biases that can lead to unfair models, emerges. Several debiasing approaches have been proposed in the realm of deep learning, employing more or less sophisticated approaches to discourage these models from massively employing these biases. However, a question emerges: is this extra complexity really necessary? Is a vanilla-trained model already embodying some ``unbiased sub-networks'' that can be used in isolation and propose a solution without relying on the algorithmic biases? In this work, we show that such a sub-network typically exists, and can be extracted from a vanilla-trained model without requiring additional training. We further validate that such specific architecture is incapable of learning a specific bias, suggesting that there are possible architectural countermeasures to the problem of biases in deep neural networks.
&lt;/p&gt;</description></item><item><title>MoralBERT &#26159;&#19968;&#31181;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#25429;&#25417;&#25991;&#26412;&#20013;&#36947;&#24503;&#24494;&#22937;&#20043;&#22788;&#30340;&#35821;&#35328;&#34920;&#31034;&#27169;&#22411;&#65292;&#21033;&#29992;&#26469;&#33258;Twitter&#12289;Reddit&#21644;Facebook&#30340;&#25968;&#25454;&#65292;&#25193;&#22823;&#20102;&#27169;&#22411;&#29702;&#35299;&#36947;&#24503;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.07678</link><description>&lt;p&gt;
MoralBERT&#65306;&#26816;&#27979;&#31038;&#20250;&#35805;&#35821;&#20013;&#30340;&#36947;&#24503;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
MoralBERT: Detecting Moral Values in Social Discourse
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07678
&lt;/p&gt;
&lt;p&gt;
MoralBERT &#26159;&#19968;&#31181;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#25429;&#25417;&#25991;&#26412;&#20013;&#36947;&#24503;&#24494;&#22937;&#20043;&#22788;&#30340;&#35821;&#35328;&#34920;&#31034;&#27169;&#22411;&#65292;&#21033;&#29992;&#26469;&#33258;Twitter&#12289;Reddit&#21644;Facebook&#30340;&#25968;&#25454;&#65292;&#25193;&#22823;&#20102;&#27169;&#22411;&#29702;&#35299;&#36947;&#24503;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36947;&#24503;&#22312;&#25105;&#20204;&#24863;&#30693;&#20449;&#24687;&#12289;&#24433;&#21709;&#20915;&#31574;&#21644;&#21028;&#26029;&#36807;&#31243;&#20013;&#36215;&#30528;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;&#21253;&#25324;&#30123;&#33495;&#25509;&#31181;&#12289;&#22549;&#32974;&#12289;&#31181;&#26063;&#20027;&#20041;&#21644;&#24615;&#21462;&#21521;&#22312;&#20869;&#30340;&#26377;&#20105;&#35758;&#35805;&#39064;&#24448;&#24448;&#24341;&#21457;&#30340;&#24847;&#35265;&#21644;&#24577;&#24230;&#24182;&#38750;&#20165;&#22522;&#20110;&#35777;&#25454;&#65292;&#32780;&#26356;&#22810;&#21453;&#26144;&#20102;&#36947;&#24503;&#19990;&#30028;&#35266;&#12290;&#26368;&#36817;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#23637;&#34920;&#26126;&#65292;&#36947;&#24503;&#20215;&#20540;&#21487;&#20197;&#20174;&#20154;&#31867;&#29983;&#25104;&#30340;&#25991;&#26412;&#20869;&#23481;&#20013;&#24471;&#21040;&#21028;&#26029;&#12290;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#26088;&#22312;&#25429;&#25417;&#25991;&#26412;&#20013;&#36947;&#24503;&#24494;&#22937;&#20043;&#22788;&#30340;&#35821;&#35328;&#34920;&#31034;&#27169;&#22411;&#65292;&#31216;&#20026;MoralBERT&#12290;&#25105;&#20204;&#21033;&#29992;&#26469;&#33258;&#19977;&#20010;&#19981;&#21516;&#26469;&#28304;&#65288;Twitter&#12289;Reddit&#21644;Facebook&#65289;&#30340;&#24102;&#26377;&#27880;&#37322;&#30340;&#36947;&#24503;&#25968;&#25454;&#65292;&#28085;&#30422;&#21508;&#31181;&#31038;&#20250;&#30456;&#20851;&#20027;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#25193;&#22823;&#20102;&#35821;&#35328;&#22810;&#26679;&#24615;&#65292;&#21487;&#33021;&#22686;&#24378;&#27169;&#22411;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#29702;&#35299;&#36947;&#24503;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#19968;&#31181;&#39046;&#22495;&#33258;&#36866;&#24212;&#25216;&#26415;&#65292;&#24182;&#23558;&#20854;&#19982;&#26631;&#20934;&#30340;&#24494;&#35843;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07678v1 Announce Type: new  Abstract: Morality plays a fundamental role in how we perceive information while greatly influencing our decisions and judgements. Controversial topics, including vaccination, abortion, racism, and sexuality, often elicit opinions and attitudes that are not solely based on evidence but rather reflect moral worldviews. Recent advances in natural language processing have demonstrated that moral values can be gauged in human-generated textual content. Here, we design a range of language representation models fine-tuned to capture exactly the moral nuances in text, called MoralBERT. We leverage annotated moral data from three distinct sources: Twitter, Reddit, and Facebook user-generated content covering various socially relevant topics. This approach broadens linguistic diversity and potentially enhances the models' ability to comprehend morality in various contexts. We also explore a domain adaptation technique and compare it to the standard fine-tu
&lt;/p&gt;</description></item></channel></rss>