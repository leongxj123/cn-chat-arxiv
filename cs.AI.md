# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Remote sensing framework for geological mapping via stacked autoencoders and clustering](https://arxiv.org/abs/2404.02180) | 通过堆叠自动编码器和聚类实现遥感数据地质制图的无监督机器学习框架 |
| [^2] | [Forward Learning for Gradient-based Black-box Saliency Map Generation](https://arxiv.org/abs/2403.15603) | 提出了一种新颖的统一框架，在黑盒设置中估计梯度并生成显著图解释模型决策，通过Likelihood Ratio方法估计输出到输入的梯度，并应用分块计算技术提高估计准确性，实验证实有效性和可扩展性。 |
| [^3] | [Optimal Design and Implementation of an Open-source Emulation Platform for User-Centric Shared E-mobility Services](https://arxiv.org/abs/2403.07964) | 提供了一种开源框架，用于共享电动出行，以代理-环路方法和模块化架构为特色，旨在弥补现有共享电动出行服务的设计缺陷，向电动出行研究社区提供福利。 |
| [^4] | [Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement](https://arxiv.org/abs/2403.06659) | 通过Multimodal ECG Representation Learning (MERL)框架，本文提出了一种零样本心电图分类方法，结合了对ECG记录和相关报告的多模态学习，同时在测试阶段使用了Clinical Knowledge Enhanced Prompt Engineering (CKEPE)方法来利用临床知识数据库。 |
| [^5] | [Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study](https://arxiv.org/abs/2403.03186) | 提出了通用计算机控制（GCC）设置，通过基于屏幕图像和可能的音频输入的基金代理框架Cradle，实现了对《荒野大镖客2》中复杂任务的控制。 |
| [^6] | [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](https://arxiv.org/abs/2403.02990) | 探讨了大型语言模型（LLMs）对数据增强的转变性影响，独特挑战和机遇，突出了LLMs在数据增强中引入的范式转变。 |
| [^7] | [Accelerating Diffusion Sampling with Optimized Time Steps](https://arxiv.org/abs/2402.17376) | 提出了一个通用框架用于设计优化问题，旨在通过寻找更合适的时间步长加速扩散采样。 |
| [^8] | [Farsight: Fostering Responsible AI Awareness During AI Application Prototyping](https://arxiv.org/abs/2402.15350) | Farsight是一个新颖的实地交互工具，帮助人们在设计AI应用原型时识别潜在危害，用户研究表明使用Farsight后，AI原型设计者能够更好地独立识别与提示相关的潜在危害。 |
| [^9] | [Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents](https://arxiv.org/abs/2402.12327) | 该研究揭示了LLM代理甚至在竞争环境中也能自发形成合作关系的能力，验证了计算社会科学的愿景，表明LLM代理可以用于模拟人类社会互动，包括自发合作的互动，为社会现象提供洞察。 |
| [^10] | [How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?](https://arxiv.org/abs/2402.10770) | 本文研究了面向指令的大型语言模型中自动评估方法的可靠性，发现自动方法在不同任务类型下与人工评估者之间的相关性存在巨大变化，且在自由形式生成任务和跨语言转移中可能不可靠。 |
| [^11] | [HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation](https://arxiv.org/abs/2402.09390) | HGOT是一种用于检索增强上下文学习中事实性评估的分层思维图方法，通过利用大型语言模型的规划能力和思维质量评估指标来提高相关段落的检索和答案选择。 |
| [^12] | [A Survey on Safe Multi-Modal Learning System](https://arxiv.org/abs/2402.05355) | 这项研究提出了第一个多模态学习系统安全的分类法，对当前发展状态下的关键限制进行了审查，并提出了未来研究的潜在方向。 |
| [^13] | [Distilling Event Sequence Knowledge From Large Language Models](https://arxiv.org/abs/2401.07237) | 本论文研究了通过大型语言模型从中提取事件序列知识的方法。采用了基于知识图的指导生成语言模型的方式，实现对具有部分因果关系的事件概念的事件序列的生成。实验证明了该方法可以生成高质量的事件序列，并且在填补知识空白方面具有潜在的价值。 |
| [^14] | [LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding](https://arxiv.org/abs/2311.15876) | RO-LMM是一个针对放射肿瘤学领域设计的多功能大型多模型，提出了一种Consistency Embedding Fine-Tuning（CEFTune）技术，使其能够在保持处理干净输入能力的同时提升对嘈杂输入的鲁棒性，用于放射治疗计划和目标体积分割。 |
| [^15] | [Interpretable Semiotics Networks Representing Awareness](https://arxiv.org/abs/2310.05212) | 这个研究描述了一个计算模型，通过追踪和模拟物体感知以及其在交流中所传达的表示来模拟人类的意识。相比于大多数无法解释的神经网络，该模型具有解释性，并可以通过构建新网络来定义物体感知。 |
| [^16] | [AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents.](http://arxiv.org/abs/2401.12963) | AutoRT是一个利用现有的基础模型来扩展机器人在未知场景中的部署的系统，通过利用视觉-语言模型和大型语言模型，提出多样化和新颖的指令，并有效地推理自主权和安全性的权衡。 |
| [^17] | [Dynamic Q&A of Clinical Documents with Large Language Models.](http://arxiv.org/abs/2401.10733) | 本研究介绍了一种使用大型语言模型进行临床文档动态问答的自然语言接口。通过Langchain和Transformer-based LLMs驱动的聊天机器人，用户可以用自然语言查询临床笔记并获得相关答案。实验结果显示Wizard Vicuna具有出色的准确性，但计算要求较高。模型优化方案提高了约48倍的延迟。然而，模型产生幻象和多样化医疗案例评估的限制仍然存在。解决这些挑战对于发掘临床笔记的价值和推进基于AI的临床决策至关重要。 |
| [^18] | [A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton.](http://arxiv.org/abs/2310.04218) | 本文提出了一个固定参数可处理算法，用于计数具有相同骨架的马尔可夫等价类。 |
| [^19] | [Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency.](http://arxiv.org/abs/2309.17272) | 本文提出了一个名为多角度自一致性（MPSC）的框架，用于提升大规模语言模型在复杂的代码生成任务中的性能。该框架通过从多个角度采样多个输出并构建一个多部分图，利用交叉一致性和内一致性信息来选择最优输出。 |
| [^20] | [Logistics Hub Location Optimization: A K-Means and P-Median Model Hybrid Approach Using Road Network Distances.](http://arxiv.org/abs/2308.11038) | 本研究基于K-Means和P-Median模型提出了一种混合方法，通过使用道路网络距离来优化在城市环境下物流集散地的位置布置，以减少配送距离和碳足迹。 |
| [^21] | [Proceedings of the 2nd International Workshop on Adaptive Cyber Defense.](http://arxiv.org/abs/2308.09520) | 第二届自适应网络防御国际研讨会的目标是探索利用人工智能和机器学习作为自适应网络防御基础能力的研究，并通过填补AI和网络研究人员之间的差距来加速开发半自主网络防御系统。 |
| [^22] | [APACE: AlphaFold2 and advanced computing as a service for accelerated discovery in biophysics.](http://arxiv.org/abs/2308.07954) | APACE是一个将AlphaFold2和先进计算作为服务的计算框架，用于在现代超级计算环境中加速蛋白质结构预测分析。研究者在Delta超级计算机中部署了APACE，在准确蛋白质结构预测方面取得了显著性能提升。 |
| [^23] | [A Survey on Popularity Bias in Recommender Systems.](http://arxiv.org/abs/2308.01118) | 这篇综述论文讨论了推荐系统中的流行偏差问题，并回顾了现有的方法来检测、量化和减少流行偏差。它同时提供了计算度量的概述和主要技术方法的回顾。 |
| [^24] | [Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models.](http://arxiv.org/abs/2305.13712) | 本文探索了大型语言模型对其自身知识的理解和测量不确定性的能力。该研究聚焦于解决“已知-未知”问题，提出了新的分类方案，并使用语义评估方法量化了模型表达不确定性的准确性。 |

# 详细

[^1]: 通过堆叠自动编码器和聚类实现地质制图的遥感框架

    Remote sensing framework for geological mapping via stacked autoencoders and clustering

    [https://arxiv.org/abs/2404.02180](https://arxiv.org/abs/2404.02180)

    通过堆叠自动编码器和聚类实现遥感数据地质制图的无监督机器学习框架

    

    有监督学习方法在遥感地质制图中面临着由于准确标记训练数据的稀缺性而限制的问题。相反，无监督学习方法，如降维和聚类，能够在不依赖预定义标签的情况下揭示遥感数据中的模式和结构。降维方法具有在提高地质图准确性方面发挥关键作用的潜力。虽然传统的降维方法可能在非线性数据上遇到困难，但无监督深度学习模型，如自动编码器，能够模拟数据中的非线性关系。堆叠自动编码器具有多个相互连接的层，用于捕获对遥感数据有用的分层数据表示。在本研究中，我们提出了一个利用堆叠自动编码器和聚类处理遥感数据的无监督机器学习框架。

    arXiv:2404.02180v1 Announce Type: cross  Abstract: Supervised learning methods for geological mapping via remote sensing face limitations due to the scarcity of accurately labelled training data. In contrast, unsupervised learning methods, such as dimensionality reduction and clustering have the ability to uncover patterns and structures in remote sensing data without relying on predefined labels. Dimensionality reduction methods have the potential to play a crucial role in improving the accuracy of geological maps. Although conventional dimensionality reduction methods may struggle with nonlinear data, unsupervised deep learning models such as autoencoders have the ability to model nonlinear relationship in data. Stacked autoencoders feature multiple interconnected layers to capture hierarchical data representations that can be useful for remote sensing data. In this study, we present an unsupervised machine learning framework for processing remote sensing data by utilizing stacked au
    
[^2]: 基于前向学习的基于梯度的黑盒显著图生成

    Forward Learning for Gradient-based Black-box Saliency Map Generation

    [https://arxiv.org/abs/2403.15603](https://arxiv.org/abs/2403.15603)

    提出了一种新颖的统一框架，在黑盒设置中估计梯度并生成显著图解释模型决策，通过Likelihood Ratio方法估计输出到输入的梯度，并应用分块计算技术提高估计准确性，实验证实有效性和可扩展性。

    

    梯度-based显著图被广泛用于解释深度神经网络决策。然而，随着模型变得更深和更黑盒，如在闭源API（如ChatGPT）中，计算梯度变得具有挑战性，阻碍传统解释方法。在这项工作中，我们引入了一个新颖的统一框架，用于在黑盒设置中估计梯度并生成显著图来解释模型决策。我们采用似然比方法来估计输出到输入的梯度，并将其用于显著图生成。此外，我们提出了分块计算技术来增强估计准确性。在黑盒设置中进行的大量实验证实了我们方法的有效性，展示了准确的梯度估计和生成显著图的解释性。此外，我们通过应用它来解释GPT-Vision展示了我们方法的可扩展性，揭示了梯度相关性的持续影响。

    arXiv:2403.15603v1 Announce Type: cross  Abstract: Gradient-based saliency maps are widely used to explain deep neural network decisions. However, as models become deeper and more black-box, such as in closed-source APIs like ChatGPT, computing gradients become challenging, hindering conventional explanation methods. In this work, we introduce a novel unified framework for estimating gradients in black-box settings and generating saliency maps to interpret model decisions. We employ the likelihood ratio method to estimate output-to-input gradients and utilize them for saliency map generation. Additionally, we propose blockwise computation techniques to enhance estimation accuracy. Extensive experiments in black-box settings validate the effectiveness of our method, demonstrating accurate gradient estimation and explainability of generated saliency maps. Furthermore, we showcase the scalability of our approach by applying it to explain GPT-Vision, revealing the continued relevance of gr
    
[^3]: 一种开源仿真平台的最佳设计与实施，用于以用户为中心的共享电动出行服务

    Optimal Design and Implementation of an Open-source Emulation Platform for User-Centric Shared E-mobility Services

    [https://arxiv.org/abs/2403.07964](https://arxiv.org/abs/2403.07964)

    提供了一种开源框架，用于共享电动出行，以代理-环路方法和模块化架构为特色，旨在弥补现有共享电动出行服务的设计缺陷，向电动出行研究社区提供福利。

    

    针对交通排放和污染不断加剧的全球挑战，共享电动出行服务成为一种流行的策略，包括电动汽车、电动自行车和电动滑板车。然而，现有的共享电动出行服务存在关键设计缺陷，包括服务整合不足、能源消耗预测不精确、可扩展性和地理覆盖范围有限，以及在多模式交通背景下尤其缺乏以用户为中心的视角。更重要的是，目前没有一个整合的开源框架，可以为电动出行研究社区带来益处。本文旨在填补这一空白，提供一个开创性的共享电动出行开源框架。所提出的框架采用代理-环路方法和模块化架构，旨在满足不同用户偏好，并提供增强的自定义功能。

    arXiv:2403.07964v1 Announce Type: new  Abstract: In response to the escalating global challenge of increasing emissions and pollution in transportation, shared electric mobility services, encompassing e-cars, e-bikes, and e-scooters, have emerged as a popular strategy. However, existingshared electric mobility services exhibit critical design deficiencies, including insufficient service integration, imprecise energy consumption forecasting, limited scalability and geographical coverage, and a notable absence of a user-centric perspective, particularly in the context of multi-modal transportation. More importantly, there is no consolidated open-source framework which could benefit the e-mobility research community. This paper aims to bridge this gap by providing a pioneering open-source framework for shared e-mobility. The proposed framework, with an agent-in-the-loop approach and modular architecture, is tailored to diverse user preferences and offers enhanced customization. We demonst
    
[^4]: 基于多模态学习和测试时临床知识增强的零样本心电图分类

    Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement

    [https://arxiv.org/abs/2403.06659](https://arxiv.org/abs/2403.06659)

    通过Multimodal ECG Representation Learning (MERL)框架，本文提出了一种零样本心电图分类方法，结合了对ECG记录和相关报告的多模态学习，同时在测试阶段使用了Clinical Knowledge Enhanced Prompt Engineering (CKEPE)方法来利用临床知识数据库。

    

    心电图（ECG）是临床实践中用于检测心律失常疾病的非侵入性诊断工具。在未经注释的ECG数据中进行自监督学习（eSSL）方法显示出了表征学习的潜力，但往往忽视了可以在报告中找到的临床知识。本文通过多模态学习ECG记录和相关报告，提出了Multimodal ECG Representation Learning (MERL)框架，该框架能够使用文本提示进行零样本ECG分类，消除了下游任务中对训练数据的需求。在测试时，我们提出了Clinical Knowledge Enhanced Prompt Engineering (CKEPE)方法，利用大型语言模型（LLM）来利用外部专家验证的临床知识数据库，生成更多关于患者病史的提示。

    arXiv:2403.06659v1 Announce Type: cross  Abstract: Electrocardiograms (ECGs) are non-invasive diagnostic tools crucial for detecting cardiac arrhythmic diseases in clinical practice. While ECG Self-supervised Learning (eSSL) methods show promise in representation learning from unannotated ECG data, they often overlook the clinical knowledge that can be found in reports. This oversight and the requirement for annotated samples for downstream tasks limit eSSL's versatility. In this work, we address these issues with the Multimodal ECG Representation Learning (MERL}) framework. Through multimodal learning on ECG records and associated reports, MERL is capable of performing zero-shot ECG classification with text prompts, eliminating the need for training data in downstream tasks. At test time, we propose the Clinical Knowledge Enhanced Prompt Engineering (CKEPE) approach, which uses Large Language Models (LLMs) to exploit external expert-verified clinical knowledge databases, generating mo
    
[^5]: 通往通用计算机控制：多模态代理在《荒野大镖客2》中的案例研究

    Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study

    [https://arxiv.org/abs/2403.03186](https://arxiv.org/abs/2403.03186)

    提出了通用计算机控制（GCC）设置，通过基于屏幕图像和可能的音频输入的基金代理框架Cradle，实现了对《荒野大镖客2》中复杂任务的控制。

    

    最近的研究表明，基于基金的代理在特定任务或场景中取得了成功。然而，现有代理无法跨不同场景泛化，主要是由于它们多样化的观察和行动空间以及语义差距，或依赖于特定任务的资源。在这项工作中，我们提出了通用计算机控制（GCC）设置：通过仅获取计算机的屏幕图像（以及可能的音频）作为输入，并产生键盘和鼠标操作作为输出，类似于人机交互，构建可以精通任何计算机任务的基金代理。为了针对GCC，我们提出了Cradle，一个代理框架，具有强大的推理能力，包括自我反思、任务推理和技能整理，以确保在各种任务中的泛化和自我改进。为了展示Cradle的能力，我们将其部署在复杂的AAA游戏《荒野大镖客2》中，作为通向G的初步尝试。

    arXiv:2403.03186v1 Announce Type: new  Abstract: Recent studies have demonstrated the success of foundation agents in specific tasks or scenarios. However, existing agents cannot generalize across different scenarios, mainly due to their diverse observation and action spaces and semantic gaps, or reliance on task-specific resources. In this work, we propose the General Computer Control (GCC) setting: building foundation agents that can master any computer task by taking only screen images (and possibly audio) of the computer as input, and producing keyboard and mouse operations as output, similar to human-computer interaction. To target GCC, we propose Cradle, an agent framework with strong reasoning abilities, including self-reflection, task inference, and skill curation, to ensure generalizability and self-improvement across various tasks. To demonstrate the capabilities of Cradle, we deploy it in the complex AAA game Red Dead Redemption II, serving as a preliminary attempt towards G
    
[^6]: 使用LLMs的数据增强：数据视角、学习范式和挑战

    Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges

    [https://arxiv.org/abs/2403.02990](https://arxiv.org/abs/2403.02990)

    探讨了大型语言模型（LLMs）对数据增强的转变性影响，独特挑战和机遇，突出了LLMs在数据增强中引入的范式转变。

    

    在机器学习（ML）领域快速发展中，数据增强（DA）已成为一种关键技术，通过使训练样本多样化而无需额外数据收集来增强模型性能。本调查探讨了大型语言模型（LLMs）对数据增强的转变性影响，特别是在自然语言处理（NLP）领域及其他领域中它们提供的独特挑战和机遇。从数据视角和学习视角，我们研究了利用大型语言模型进行数据增强的各种策略，包括对LLM生成数据进行进一步训练的新颖学习范式的探索。此外，本文还阐明了该领域面临的主要挑战，从可控数据增强到多模态数据增强等。本调查突显了LLMs在数据增强中引入的范式转变，旨在作为一种...

    arXiv:2403.02990v1 Announce Type: cross  Abstract: In the rapidly evolving field of machine learning (ML), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of Large Language Models (LLMs) on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From a data perspective and a learning perspective, we examine various strategies that utilize Large Language Models for data augmentation, including a novel exploration of learning paradigms where LLM-generated data is used for further training. Additionally, this paper delineates the primary challenges faced in this domain, ranging from controllable data augmentation to multi modal data augmentation. This survey highlights the paradigm shift introduced by LLMs in DA, aims to serve as a 
    
[^7]: 优化时间步长加速扩散采样

    Accelerating Diffusion Sampling with Optimized Time Steps

    [https://arxiv.org/abs/2402.17376](https://arxiv.org/abs/2402.17376)

    提出了一个通用框架用于设计优化问题，旨在通过寻找更合适的时间步长加速扩散采样。

    

    扩散概率模型（DPMs）在高分辨率图像合成中表现出色，但由于通常需要大量采样步骤，其采样效率仍有待提高。近期高阶数值ODE求解器在DPMs中的应用使得用更少的采样步骤生成高质量图像成为可能。尽管这是一项重大进展，大多数采样方法仍然采用均匀时间步长，而在采样步骤较少时并不是最佳选择。为解决这一问题，我们提出了一个通用框架，用于设计一个优化问题，该优化问题旨在为DPMs的特定数值ODE求解器寻找更合适的时间步长。此优化问题旨在最小化地实现地真实解与与数值求解器对应的近似解之间的距离。它可以通过受限信赖域方法进行高效求解，时间少于

    arXiv:2402.17376v1 Announce Type: cross  Abstract: Diffusion probabilistic models (DPMs) have shown remarkable performance in high-resolution image synthesis, but their sampling efficiency is still to be desired due to the typically large number of sampling steps. Recent advancements in high-order numerical ODE solvers for DPMs have enabled the generation of high-quality images with much fewer sampling steps. While this is a significant development, most sampling methods still employ uniform time steps, which is not optimal when using a small number of steps. To address this issue, we propose a general framework for designing an optimization problem that seeks more appropriate time steps for a specific numerical ODE solver for DPMs. This optimization problem aims to minimize the distance between the ground-truth solution to the ODE and an approximate solution corresponding to the numerical solver. It can be efficiently solved using the constrained trust region method, taking less than 
    
[^8]: Farsight：在AI应用原型设计过程中培养负责任的AI意识

    Farsight: Fostering Responsible AI Awareness During AI Application Prototyping

    [https://arxiv.org/abs/2402.15350](https://arxiv.org/abs/2402.15350)

    Farsight是一个新颖的实地交互工具，帮助人们在设计AI应用原型时识别潜在危害，用户研究表明使用Farsight后，AI原型设计者能够更好地独立识别与提示相关的潜在危害。

    

    大型语言模型（LLM）的提示驱动界面使得原型设计和构建AI应用比以往任何时候都更容易。然而，识别可能在AI应用中出现的潜在危害仍然是一个挑战，特别是在基于提示的原型设计过程中。为了解决这一问题，我们提出了一种新颖的实地交互工具Farsight，帮助人们识别他们正在设计原型的AI应用中可能出现的潜在危害。根据用户的提示，Farsight突出显示了与相关AI事件有关的新闻文章，并允许用户探索和编辑LLM生成的用例、利益相关者和危害。我们报告了与10位AI原型设计者进行的共同设计研究的设计见解，以及与42位AI原型设计者进行的用户研究结果。在使用Farsight后，我们用户研究中的AI原型设计者能够更好地独立识别与提示相关的潜在危害，并发现我们的工具比现有资源更有用且更易于使用。

    arXiv:2402.15350v1 Announce Type: cross  Abstract: Prompt-based interfaces for Large Language Models (LLMs) have made prototyping and building AI-powered applications easier than ever before. However, identifying potential harms that may arise from AI applications remains a challenge, particularly during prompt-based prototyping. To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping. Based on a user's prompt, Farsight highlights news articles about relevant AI incidents and allows users to explore and edit LLM-generated use cases, stakeholders, and harms. We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers. After using Farsight, AI prototypers in our user study are better able to independently identify potential harms associated with a prompt and find our tool more useful and usable than existing resources. T
    
[^9]: 我们应该交流吗：探索竞争LLM代理之间的自发合作

    Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents

    [https://arxiv.org/abs/2402.12327](https://arxiv.org/abs/2402.12327)

    该研究揭示了LLM代理甚至在竞争环境中也能自发形成合作关系的能力，验证了计算社会科学的愿景，表明LLM代理可以用于模拟人类社会互动，包括自发合作的互动，为社会现象提供洞察。

    

    最近的进展表明，由大型语言模型（LLMs）驱动的代理具有模拟人类行为和社会动态的能力。然而，尚未研究LLM代理在没有明确指令的情况下自发建立合作关系的潜力。为了弥补这一空白，我们进行了三项案例研究，揭示了LLM代理甚至在竞争环境中也能自发形成合作关系的能力。这一发现不仅展示了LLM代理模拟人类社会中竞争与合作的能力，也验证了计算社会科学的一个有前途的愿景。具体来说，这表明LLM代理可以用于建模人类社会互动，包括那些自发合作的互动，从而提供对社会现象的洞察。这项研究的源代码可在https://github.com/wuzengqing001225/SABM_ShallWe 找到。

    arXiv:2402.12327v1 Announce Type: new  Abstract: Recent advancements have shown that agents powered by large language models (LLMs) possess capabilities to simulate human behaviors and societal dynamics. However, the potential for LLM agents to spontaneously establish collaborative relationships in the absence of explicit instructions has not been studied. To address this gap, we conduct three case studies, revealing that LLM agents are capable of spontaneously forming collaborations even within competitive settings. This finding not only demonstrates the capacity of LLM agents to mimic competition and cooperation in human societies but also validates a promising vision of computational social science. Specifically, it suggests that LLM agents could be utilized to model human social interactions, including those with spontaneous collaborations, thus offering insights into social phenomena. The source codes for this study are available at https://github.com/wuzengqing001225/SABM_ShallWe
    
[^10]: 自动评估方法在面向指令的LLM中有多可靠？

    How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?

    [https://arxiv.org/abs/2402.10770](https://arxiv.org/abs/2402.10770)

    本文研究了面向指令的大型语言模型中自动评估方法的可靠性，发现自动方法在不同任务类型下与人工评估者之间的相关性存在巨大变化，且在自由形式生成任务和跨语言转移中可能不可靠。

    

    面向指令的大型语言模型(LLMs)的研究使用基于文本重叠和LLM判断的自动方法作为人工评估的成本有效替代方案。本文研究了这些方法在广泛的任务范围和跨语言环境中的可靠性。与先前的研究结果相反，我们观察到在任务类型不同的情况下，自动方法与人工评估者之间的相关性存在显著变化。具体而言，广泛使用的ROUGE-L度量在短答案英语任务中与人类判断强相关，但在自由形式生成任务和跨语言转移中不可靠。使用GPT-4作为评估员的有效性取决于在要求评估时包含参考答案，这可能导致在自由形式生成任务中评估过于严格。总的来说，我们发现，尽管自动评估方法可以近似人类判断，但其准确性可能因任务类型和评估设置而异。

    arXiv:2402.10770v1 Announce Type: cross  Abstract: Work on instruction-tuned Large Language Models (LLMs) has used automatic methods based on text overlap and LLM judgments as cost-effective alternatives to human evaluation. In this paper, we study the reliability of such methods across a broad range of tasks and in a cross-lingual setting. In contrast to previous findings, we observe considerable variability in correlations between automatic methods and human evaluators when scores are differentiated by task type. Specifically, the widely-used ROUGE-L metric strongly correlates with human judgments for short-answer English tasks but is unreliable in free-form generation tasks and cross-lingual transfer. The effectiveness of GPT-4 as an evaluator depends on including reference answers when prompting for assessments, which can lead to overly strict evaluations in free-form generation tasks. In summary, we find that, while automatic evaluation methods can approximate human judgements und
    
[^11]: HGOT: 用于检索增强上下文学习中事实性评估的分层思维图

    HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation

    [https://arxiv.org/abs/2402.09390](https://arxiv.org/abs/2402.09390)

    HGOT是一种用于检索增强上下文学习中事实性评估的分层思维图方法，通过利用大型语言模型的规划能力和思维质量评估指标来提高相关段落的检索和答案选择。

    

    随着大型语言模型（LLMs）在许多应用中的广泛应用，事实性和幻觉的倾向引发了重大关切。为了解决这个问题，特别是在检索增强的上下文学习中，我们引入了分层思维图（HGOT），这是一种结构化的、多层次的图形方法，旨在增强在上下文学习过程中相关段落的检索。该框架利用LLMs的逐渐规划能力，采用分而治之的策略将复杂查询分解为可处理的子查询。它通过引入最近提出的引文回忆和精确度指标来评估思维质量，将答案的可信度与思维的质量内在地联系起来，从而改进了自洽性多数投票的答案选择方法。这种方法引入了一个加权系统，在多数投票中优先考虑答案。

    arXiv:2402.09390v1 Announce Type: new Abstract: With the widespread adoption of large language models (LLMs) in numerous applications, the challenge of factuality and the propensity for hallucinations raises significant concerns. To address this issue, particularly in retrieval-augmented in-context learning, we introduce the hierarchical graph of thoughts (HGOT), a structured, multi-layered graph approach designed to enhance the retrieval of pertinent passages during in-context learning. The framework utilizes the emergent planning capabilities of LLMs, employing the divide-and-conquer strategy to break down complex queries into manageable sub-queries. It refines self-consistency majority voting for answer selection, which incorporates the recently proposed citation recall and precision metrics to assess the quality of thoughts, linking an answer's credibility intrinsically to the thought's quality. This methodology introduces a weighted system in majority voting, prioritizing answers 
    
[^12]: 安全多模态学习系统调研

    A Survey on Safe Multi-Modal Learning System

    [https://arxiv.org/abs/2402.05355](https://arxiv.org/abs/2402.05355)

    这项研究提出了第一个多模态学习系统安全的分类法，对当前发展状态下的关键限制进行了审查，并提出了未来研究的潜在方向。

    

    随着多模态学习系统在现实场景中的广泛应用，安全问题变得越来越突出。对于这一领域的安全问题缺乏系统性研究已成为一个重要的障碍。为了解决这个问题，我们提出了第一个多模态学习系统安全的分类法，确定了这些问题的四个关键支柱。借助这一分类法，我们对每个支柱进行了深入审查，突出了当前发展状态的关键限制。最后，我们指出了多模态学习系统安全面临的独特挑战，并提供了未来研究的潜在方向。

    With the wide deployment of multimodal learning systems (MMLS) in real-world scenarios, safety concerns have become increasingly prominent. The absence of systematic research into their safety is a significant barrier to progress in this field. To bridge the gap, we present the first taxonomy for MMLS safety, identifying four essential pillars of these concerns. Leveraging this taxonomy, we conduct in-depth reviews for each pillar, highlighting key limitations based on the current state of development. Finally, we pinpoint unique challenges in MMLS safety and provide potential directions for future research.
    
[^13]: 从大型语言模型中提取事件序列知识

    Distilling Event Sequence Knowledge From Large Language Models

    [https://arxiv.org/abs/2401.07237](https://arxiv.org/abs/2401.07237)

    本论文研究了通过大型语言模型从中提取事件序列知识的方法。采用了基于知识图的指导生成语言模型的方式，实现对具有部分因果关系的事件概念的事件序列的生成。实验证明了该方法可以生成高质量的事件序列，并且在填补知识空白方面具有潜在的价值。

    

    事件序列模型在事件的分析和预测中被发现是非常有效的。建立这样的模型需要丰富的高质量事件序列数据。然而，在某些应用中，干净的结构化事件序列不可用，自动化序列提取导致的数据太嘈杂和不完整。在这项工作中，我们探索了使用大型语言模型（LLMs）生成可以有效用于概率事件模型构建的事件序列的方法。这可以看作是从LLMs中提取事件序列知识的一种机制。我们的方法依赖于一个具有部分因果关系的事件概念的知识图（KG）来指导生成语言模型进行因果事件序列的生成。我们展示了我们的方法可以生成高质量的事件序列，填补了输入KG中的知识空白。此外，我们还探索了如何利用生成的序列来发现更有用和更复杂的内容。

    Event sequence models have been found to be highly effective in the analysis and prediction of events. Building such models requires availability of abundant high-quality event sequence data. In certain applications, however, clean structured event sequences are not available, and automated sequence extraction results in data that is too noisy and incomplete. In this work, we explore the use of Large Language Models (LLMs) to generate event sequences that can effectively be used for probabilistic event model construction. This can be viewed as a mechanism of distilling event sequence knowledge from LLMs. Our approach relies on a Knowledge Graph (KG) of event concepts with partial causal relations to guide the generative language model for causal event sequence generation. We show that our approach can generate high-quality event sequences, filling a knowledge gap in the input KG. Furthermore, we explore how the generated sequences can be leveraged to discover useful and more complex st
    
[^14]: LMM辅助的一致性嵌入下乳腺癌治疗目标分割

    LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding

    [https://arxiv.org/abs/2311.15876](https://arxiv.org/abs/2311.15876)

    RO-LMM是一个针对放射肿瘤学领域设计的多功能大型多模型，提出了一种Consistency Embedding Fine-Tuning（CEFTune）技术，使其能够在保持处理干净输入能力的同时提升对嘈杂输入的鲁棒性，用于放射治疗计划和目标体积分割。

    

    人工智能的最新进展深刻影响了医学领域，为降低临床工作量提供了工具。然而，大多数人工智能模型受限于执行单模式任务，与医学专业人员所使用的综合方法形成鲜明对比。为解决这一问题，本文介绍了RO-LMM，一个专为放射肿瘤学领域设计的多功能大型多模型（LMM）。该模型涵盖了临床工作流中的一系列任务，擅长临床报告摘要、放疗治疗计划建议和计划引导的目标体积分割。为了执行连续的临床任务，我们进一步提出了一种新颖的一致性嵌入微调（CEFTune）技术，提升了LMM对嘈杂输入的鲁棒性，同时保持了处理干净输入的能力，并将该概念转化为LMM驱动的分割框架，即一致性嵌入S。

    arXiv:2311.15876v2 Announce Type: replace-cross  Abstract: Recent advancements in Artificial Intelligence (AI) have profoundly influenced medical fields, by providing tools to reduce clinical workloads. However, most AI models are constrained to execute unimodal tasks, in stark contrast to the comprehensive approaches utilized by medical professionals. To address this, here we present RO-LMM, a multi-purpose large multimodal model (LMM) tailored for the field of radiation oncology. This model covers series of tasks within clinical workflow, adept at clinical report summarization, radiation treatment plan suggestion, and plan-guided target volume segmentation. In particular, to perform consecutive clinical tasks, we further present a novel Consistency Embedding Fine-Tuning (CEFTune) technique, which boosts LMM's robustness to noisy inputs while preserving the capability of handling clean inputs, and transform this concept into LMM-driven segmentation framework as Consistency Embedding S
    
[^15]: 可解释的符号网络代表意识的知觉

    Interpretable Semiotics Networks Representing Awareness

    [https://arxiv.org/abs/2310.05212](https://arxiv.org/abs/2310.05212)

    这个研究描述了一个计算模型，通过追踪和模拟物体感知以及其在交流中所传达的表示来模拟人类的意识。相比于大多数无法解释的神经网络，该模型具有解释性，并可以通过构建新网络来定义物体感知。

    

    人类每天都感知物体，并通过各种渠道传达他们的感知。在这里，我们描述了一个计算模型，追踪和模拟物体的感知以及它们在交流中所传达的表示。我们描述了我们内部表示的两个关键组成部分（"观察到的"和"看到的"），并将它们与熟悉的计算机视觉概念（编码和解码）相关联。这些元素被合并在一起形成符号网络，模拟了物体感知和人类交流中的意识。如今，大多数神经网络都是不可解释的。另一方面，我们的模型克服了这个限制。实验证明了该模型的可见性。我们人的物体感知模型使我们能够通过网络定义物体感知。我们通过构建一个包括基准分类器和额外层的新网络来演示这一点。这个层产生了图像的感知。

    Humans perceive objects daily and communicate their perceptions using various channels. Here, we describe a computational model that tracks and simulates objects' perception and their representations as they are conveyed in communication.   We describe two key components of our internal representation ("observed" and "seen") and relate them to familiar computer vision notions (encoding and decoding). These elements are joined together to form semiotics networks, which simulate awareness in object perception and human communication.   Nowadays, most neural networks are uninterpretable. On the other hand, our model overcomes this limitation. The experiments demonstrates the visibility of the model.   Our model of object perception by a person allows us to define object perception by a network. We demonstrate this with an example of an image baseline classifier by constructing a new network that includes the baseline classifier and an additional layer. This layer produces the images "perc
    
[^16]: AutoRT：大规模编排机器人代理的具身基础模型

    AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents. (arXiv:2401.12963v1 [cs.RO])

    [http://arxiv.org/abs/2401.12963](http://arxiv.org/abs/2401.12963)

    AutoRT是一个利用现有的基础模型来扩展机器人在未知场景中的部署的系统，通过利用视觉-语言模型和大型语言模型，提出多样化和新颖的指令，并有效地推理自主权和安全性的权衡。

    

    拥有语言、视觉和行动等功能的具身基础模型已经彻底改变了利用互联网规模的数据来推理有用任务的能力。然而，训练具身基础模型的一个关键挑战是缺乏基于物理世界的数据。在本文中，我们提出了AutoRT，一个利用现有的基础模型来扩展完全未知场景中操作机器人的部署的系统，只需要最少的人工监督。AutoRT利用视觉-语言模型(VLMs)实现场景理解和基础绑定，并进一步利用大型语言模型(LLMs)提出多样化和新颖的指令，供一组机器人执行。通过利用基础模型的知识来指导数据收集，AutoRT能够有效地推理自主权和安全性的权衡，同时显著扩大机器人学习的数据收集。我们演示了AutoRT向20多个机器人提议指令。

    Foundation models that incorporate language, vision, and more recently actions have revolutionized the ability to harness internet scale data to reason about useful tasks. However, one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world. In this paper, we propose AutoRT, a system that leverages existing foundation models to scale up the deployment of operational robots in completely unseen scenarios with minimal human supervision. AutoRT leverages vision-language models (VLMs) for scene understanding and grounding, and further uses large language models (LLMs) for proposing diverse and novel instructions to be performed by a fleet of robots. Guiding data collection by tapping into the knowledge of foundation models enables AutoRT to effectively reason about autonomy tradeoffs and safety while significantly scaling up data collection for robot learning. We demonstrate AutoRT proposing instructions to over 20 robots across multi
    
[^17]: 使用大型语言模型进行临床文档的动态问答

    Dynamic Q&A of Clinical Documents with Large Language Models. (arXiv:2401.10733v1 [cs.IR])

    [http://arxiv.org/abs/2401.10733](http://arxiv.org/abs/2401.10733)

    本研究介绍了一种使用大型语言模型进行临床文档动态问答的自然语言接口。通过Langchain和Transformer-based LLMs驱动的聊天机器人，用户可以用自然语言查询临床笔记并获得相关答案。实验结果显示Wizard Vicuna具有出色的准确性，但计算要求较高。模型优化方案提高了约48倍的延迟。然而，模型产生幻象和多样化医疗案例评估的限制仍然存在。解决这些挑战对于发掘临床笔记的价值和推进基于AI的临床决策至关重要。

    

    电子健康记录（EHR）中收录了临床笔记中的重要患者数据。随着这些笔记数量和复杂度的增加，手动提取变得具有挑战性。本研究利用大型语言模型（LLMs）引入了一种自然语言接口，用于对临床笔记进行动态问答。我们的聊天机器人由Langchain和基于Transformer的LLMs驱动，允许用户用自然语言发出查询，并从临床笔记中获得相关答案。通过使用各种嵌入模型和先进的LLMs进行实验，结果表明Wizard Vicuna在准确性方面表现优异，尽管计算要求较高。模型优化，包括权重量化，将延迟提高了约48倍。有希望的结果显示了临床笔记中的价值潜力，但仍存在模型产生幻象和有限的多样化医疗案例评估等挑战。解决这些问题对于发掘临床笔记的价值和推动AI驱动的临床决策至关重要。

    Electronic health records (EHRs) house crucial patient data in clinical notes. As these notes grow in volume and complexity, manual extraction becomes challenging. This work introduces a natural language interface using large language models (LLMs) for dynamic question-answering on clinical notes. Our chatbot, powered by Langchain and transformer-based LLMs, allows users to query in natural language, receiving relevant answers from clinical notes. Experiments, utilizing various embedding models and advanced LLMs, show Wizard Vicuna's superior accuracy, albeit with high compute demands. Model optimization, including weight quantization, improves latency by approximately 48 times. Promising results indicate potential, yet challenges such as model hallucinations and limited diverse medical case evaluations remain. Addressing these gaps is crucial for unlocking the value in clinical notes and advancing AI-driven clinical decision-making.
    
[^18]: 一个可计数具有相同骨架的马尔可夫等价类的固定参数可处理算法

    A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton. (arXiv:2310.04218v1 [cs.DS])

    [http://arxiv.org/abs/2310.04218](http://arxiv.org/abs/2310.04218)

    本文提出了一个固定参数可处理算法，用于计数具有相同骨架的马尔可夫等价类。

    

    因果有向无环图（也称为贝叶斯网络）是编码随机变量之间条件依赖关系的流行工具。在因果有向无环图中，随机变量被建模为有向图中的顶点，并且规定每个随机变量在给定其父节点的情况下与其祖先节点无关。然而，对于同一组随机变量上的两个不同的因果有向无环图可以准确编码相同的一组条件依赖关系。这样的因果有向无环图被称为马尔可夫等价，马尔可夫等价的因果有向无环图的等价类被称为马尔可夫等价类（MEC）。在过去几十年中，对于MEC已经创建了一些美丽的组合特征，并且已知，特别是在同一MEC中的所有因果有向无环图必须具有相同的“骨架”（底层无向图）和v-结构（形式为$a\rightarrow b \leftarrow c$的诱导子图）。这些组合特征还提出了几个自然的算法问题。

    Causal DAGs (also known as Bayesian networks) are a popular tool for encoding conditional dependencies between random variables. In a causal DAG, the random variables are modeled as vertices in the DAG, and it is stipulated that every random variable is independent of its ancestors conditioned on its parents. It is possible, however, for two different causal DAGs on the same set of random variables to encode exactly the same set of conditional dependencies. Such causal DAGs are said to be Markov equivalent, and equivalence classes of Markov equivalent DAGs are known as Markov Equivalent Classes (MECs). Beautiful combinatorial characterizations of MECs have been developed in the past few decades, and it is known, in particular that all DAGs in the same MEC must have the same ''skeleton'' (underlying undirected graph) and v-structures (induced subgraph of the form $a\rightarrow b \leftarrow c$).  These combinatorial characterizations also suggest several natural algorithmic questions. On
    
[^19]: 提升大规模语言模型在编码中的能力通过多角度自一致性

    Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency. (arXiv:2309.17272v1 [cs.CL])

    [http://arxiv.org/abs/2309.17272](http://arxiv.org/abs/2309.17272)

    本文提出了一个名为多角度自一致性（MPSC）的框架，用于提升大规模语言模型在复杂的代码生成任务中的性能。该框架通过从多个角度采样多个输出并构建一个多部分图，利用交叉一致性和内一致性信息来选择最优输出。

    

    大规模语言模型（LLMs）在文本生成方面展现了卓越的能力。然而，在复杂的推理任务，如代码生成中，LLMs仍然难以在一次尝试中生成正确的答案。先前的研究通过聚合多个输出，利用它们之间的一致性来探索解决方案。然而，这些研究没有全面地从不同的角度捕捉这种一致性。在本文中，我们提出了一种名为多角度自一致性（MPSC）框架的新的解码策略，用于LLM，它将来自多个角度的输出之间的交叉一致性和单个角度内的内一致性结合起来。具体而言，我们要求LLMs对给定查询从各个角度采样多个多样化的输出，并基于它们构建一个多部分图。通过两个预定义的一致性度量，我们将交叉一致性和内一致性信息嵌入到图中。最佳选择是根据这些一致性度量来选择输出。

    Large language models (LLMs) have exhibited remarkable ability in textual generation. However, in complex reasoning tasks such as code generation, generating the correct answer in a single attempt remains a formidable challenge for LLMs. Previous research has explored solutions by aggregating multiple outputs, leveraging the consistency among them. However, none of them have comprehensively captured this consistency from different perspectives. In this paper, we propose the Multi-Perspective Self-Consistency (MPSC) framework, a novel decoding strategy for LLM that incorporates both inter-consistency across outputs from multiple perspectives and intra-consistency within a single perspective. Specifically, we ask LLMs to sample multiple diverse outputs from various perspectives for a given query and then construct a multipartite graph based on them. With two predefined measures of consistency, we embed both inter- and intra-consistency information into the graph. The optimal choice is th
    
[^20]: 物流集散地位置优化：一种基于K-Means和P-Median模型的混合方法，利用道路网络距离

    Logistics Hub Location Optimization: A K-Means and P-Median Model Hybrid Approach Using Road Network Distances. (arXiv:2308.11038v1 [math.OC])

    [http://arxiv.org/abs/2308.11038](http://arxiv.org/abs/2308.11038)

    本研究基于K-Means和P-Median模型提出了一种混合方法，通过使用道路网络距离来优化在城市环境下物流集散地的位置布置，以减少配送距离和碳足迹。

    

    物流集散地在最后一公里配送距离中起着关键作用；即使距离微小增加也会对电子商务行业的业务产生负面影响，同时还会增加其碳足迹。特别是在Covid-19之后，该行业的增长进一步加剧了在城市环境中优化资源分配的需求。在这项研究中，我们使用了一种混合方法来优化物流集散地的布置。该方法依次采用不同的技术。首先，根据它们的空间位置，使用K-Means对交付点进行聚类。聚类方法使用道路网络距离，而不是欧几里德距离。避免使用非基于道路网络的方法，因为它们会导致错误和误导性结果。最后，使用P-Median方法确定集散地的位置。P-Median方法还将交付数量和人口作为权重考虑在内。使用Muller和Phipps（M＆P）的实际交付数据

    Logistic hubs play a pivotal role in the last-mile delivery distance; even a slight increment in distance negatively impacts the business of the e-commerce industry while also increasing its carbon footprint. The growth of this industry, particularly after Covid-19, has further intensified the need for optimized allocation of resources in an urban environment. In this study, we use a hybrid approach to optimize the placement of logistic hubs. The approach sequentially employs different techniques. Initially, delivery points are clustered using K-Means in relation to their spatial locations. The clustering method utilizes road network distances as opposed to Euclidean distances. Non-road network-based approaches have been avoided since they lead to erroneous and misleading results. Finally, hubs are located using the P-Median method. The P-Median method also incorporates the number of deliveries and population as weights. Real-world delivery data from Muller and Phipps (M&P) is used to 
    
[^21]: 第二届自适应网络防御国际研讨会论文集

    Proceedings of the 2nd International Workshop on Adaptive Cyber Defense. (arXiv:2308.09520v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2308.09520](http://arxiv.org/abs/2308.09520)

    第二届自适应网络防御国际研讨会的目标是探索利用人工智能和机器学习作为自适应网络防御基础能力的研究，并通过填补AI和网络研究人员之间的差距来加速开发半自主网络防御系统。

    

    第二届自适应网络防御国际研讨会在佛罗里达理工学院举行，该研讨会旨在分享利用人工智能（AI）和机器学习（ML）作为自适应网络防御基础能力的研究。当前的网络领域无法可靠有效地进行防御，必须广泛依赖人工专家。熟练的网络防御人员供应不足，往往无法及时应对网络威胁。借鉴AI和ML的最新进展，网络防御研究社区被激励着通过将AI和ML技术应用于网络环境中，开发新的动态可持续的防御措施。填补AI和网络研究人员与实践者之间的关键差距可以加速创建能够学习识别和应对网络攻击，或者发现和减轻弱点的半自主网络防御系统的努力。

    The 2nd International Workshop on Adaptive Cyber Defense was held at the Florida Institute of Technology, Florida. This workshop was organized to share research that explores unique applications of Artificial Intelligence (AI) and Machine Learning (ML) as foundational capabilities for the pursuit of adaptive cyber defense. The cyber domain cannot currently be reliably and effectively defended without extensive reliance on human experts. Skilled cyber defenders are in short supply and often cannot respond fast enough to cyber threats.  Building on recent advances in AI and ML the Cyber defense research community has been motivated to develop new dynamic and sustainable defenses through the adoption of AI and ML techniques to cyber settings. Bridging critical gaps between AI and Cyber researchers and practitioners can accelerate efforts to create semi-autonomous cyber defenses that can learn to recognize and respond to cyber attacks or discover and mitigate weaknesses in cooperation with
    
[^22]: APACE: AlphaFold2和先进计算作为加速生物物理学发现的服务

    APACE: AlphaFold2 and advanced computing as a service for accelerated discovery in biophysics. (arXiv:2308.07954v1 [q-bio.BM])

    [http://arxiv.org/abs/2308.07954](http://arxiv.org/abs/2308.07954)

    APACE是一个将AlphaFold2和先进计算作为服务的计算框架，用于在现代超级计算环境中加速蛋白质结构预测分析。研究者在Delta超级计算机中部署了APACE，在准确蛋白质结构预测方面取得了显著性能提升。

    

    从氨基酸序列预测蛋白质的3D结构是生物物理学中的一个计算重大挑战，它在稳健的蛋白质结构预测算法中起着关键作用，从药物发现到基因组解读都离不开这个技术。AI模型的出现，比如AlphaFold，正在革新依赖稳健蛋白质结构预测算法的应用。为了最大程度地发挥这些新型AI工具的影响力和易用性，我们引入了APACE，AlphaFold2和先进计算作为服务的新型计算框架，该框架能够有效地处理这个AI模型及其TB级大小的数据库，以在现代超级计算环境中加速蛋白质结构预测分析。我们将APACE部署在Delta超级计算机中，并使用四个示例蛋白质（6AWO，6OAN，7MEZ和6D6U）来量化其在准确蛋白质结构预测方面的性能。在Delta的50个节点上分布了多达200个合集，相当于200个A100 NVIDIA GPU，我们发现

    The prediction of protein 3D structure from amino acid sequence is a computational grand challenge in biophysics, and plays a key role in robust protein structure prediction algorithms, from drug discovery to genome interpretation. The advent of AI models, such as AlphaFold, is revolutionizing applications that depend on robust protein structure prediction algorithms. To maximize the impact, and ease the usability, of these novel AI tools we introduce APACE, AlphaFold2 and advanced computing as a service, a novel computational framework that effectively handles this AI model and its TB-size database to conduct accelerated protein structure prediction analyses in modern supercomputing environments. We deployed APACE in the Delta supercomputer, and quantified its performance for accurate protein structure predictions using four exemplar proteins: 6AWO, 6OAN, 7MEZ, and 6D6U. Using up to 200 ensembles, distributed across 50 nodes in Delta, equivalent to 200 A100 NVIDIA GPUs, we found that 
    
[^23]: 推荐系统中的流行偏差综述

    A Survey on Popularity Bias in Recommender Systems. (arXiv:2308.01118v1 [cs.IR])

    [http://arxiv.org/abs/2308.01118](http://arxiv.org/abs/2308.01118)

    这篇综述论文讨论了推荐系统中的流行偏差问题，并回顾了现有的方法来检测、量化和减少流行偏差。它同时提供了计算度量的概述和主要技术方法的回顾。

    

    推荐系统以个性化的方式帮助人们找到相关内容。这些系统的一个主要承诺是能够增加目录中较少知名的物品的可见性。然而，现有研究表明，在许多情况下，现今的推荐算法反而表现出流行偏差，即它们在推荐中经常关注相当流行的物品。这种偏差不仅可能导致短期内对消费者和提供者的推荐价值有限，而且还可能引起不希望的强化效应。在本文中，我们讨论了流行偏差的潜在原因，并回顾了现有的检测、量化和减少推荐系统中流行偏差的方法。因此，我们的综述既包括了文献中使用的计算度量的概述，也包括了减少偏差的主要技术方法的回顾。我们还对这些方法进行了批判性讨论。

    Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discu
    
[^24]: 知识的知识：探索大型语言模型对未知-已知不确定性的理解

    Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models. (arXiv:2305.13712v1 [cs.CL])

    [http://arxiv.org/abs/2305.13712](http://arxiv.org/abs/2305.13712)

    本文探索了大型语言模型对其自身知识的理解和测量不确定性的能力。该研究聚焦于解决“已知-未知”问题，提出了新的分类方案，并使用语义评估方法量化了模型表达不确定性的准确性。

    

    本文研究了大型语言模型（LLM）在理解自身知识和测量不确定性方面的能力，以缓解虚构现象。我们专门关注解决“已知-未知”问题，这种问题由于缺乏确定的答案而具有高度不确定性。为了促进我们的研究，我们收集了一个新的已知-未知问题（KUQ）数据集，并提出了一个新的分类方案来阐明不确定性的来源。随后，我们评估LLM区分已知和未知问题以及相应分类的能力。此外，我们在开放式QA环境中评估LLM的答案质量。为了量化答案中表达的不确定性，我们创建了一种语义评估方法，用于测量模型在表达已知vs未知问题的不确定性方面的准确性。

    This paper investigates the capabilities of Large Language Models (LLMs) in the context of understanding their own knowledge and measuring their uncertainty. We argue this is an important feature for mitigating hallucinations. Specifically, we focus on addressing \textit{known-unknown} questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a dataset with new Known-Unknown Questions (KUQ) and propose a novel categorization scheme to elucidate the sources of uncertainty. Subsequently, we assess the LLMs' ability to differentiate between known and unknown questions and classify them accordingly. Moreover, we evaluate the quality of their answers in an Open-Ended QA setting. To quantify the uncertainty expressed in the answers, we create a semantic evaluation method that measures the model's accuracy in expressing uncertainty between known vs unknown questions.
    

