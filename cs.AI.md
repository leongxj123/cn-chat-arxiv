# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Beyond the Request: Harnessing HTTP Response Headers for Cross-Browser Web Tracker Classification in an Imbalanced Setting](https://rss.arxiv.org/abs/2402.01240) | 本研究通过利用HTTP响应头设计了机器学习分类器，在跨浏览器环境下有效检测Web追踪器，结果在Chrome和Firefox上表现出较高的准确性和性能。 |
| [^2] | [Institutional Platform for Secure Self-Service Large Language Model Exploration](https://rss.arxiv.org/abs/2402.00913) | 这个论文介绍了一个用户友好型平台，旨在使大型定制语言模型更易于使用，通过最新的多LoRA推理技术和定制适配器，实现了数据隔离、加密和身份验证的安全服务。 |
| [^3] | [Remote sensing framework for geological mapping via stacked autoencoders and clustering](https://arxiv.org/abs/2404.02180) | 通过堆叠自动编码器和聚类实现遥感数据地质制图的无监督机器学习框架 |
| [^4] | [WavLLM: Towards Robust and Adaptive Speech Large Language Model](https://arxiv.org/abs/2404.00656) | WavLLM是一个稳健和自适应语音大语言模型，引入了双编码器和Prompt-aware LoRA权重适配器，通过两阶段课程学习方法优化，解耦不同类型的语音信息，为处理语义内容和说话者身份的独特特征提供了新思路 |
| [^5] | [Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods](https://arxiv.org/abs/2404.00282) | 大型语言模型在强化学习中具有潜在优势，通过结构化分类和角色分析，为未来研究提供指导。 |
| [^6] | [SugarcaneNet2024: An Optimized Weighted Average Ensemble Approach of LASSO Regularized Pre-trained Models for Sugarcane Disease Classification](https://arxiv.org/abs/2403.18870) | SugarcaneNet2024是通过优化加权平均集成LASSO正则化的预训练模型，在甘蔗病害分类中表现出色，具有快速准确的检测能力。 |
| [^7] | [GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic Communication Paradigm](https://arxiv.org/abs/2403.18296) | GeNet提出了一种基于图神经网络的语义通信范式，通过将数据转换为图结构、利用编码器提取语义信息并利用解码器重建信息的方法来实现抗噪声任务导向通信。 |
| [^8] | [DreamSampler: Unifying Diffusion Sampling and Score Distillation for Image Manipulation](https://arxiv.org/abs/2403.11415) | DreamSampler框架通过整合反向扩散采样和分数蒸馏，提供了模型无关的图像处理方法，解决了分数蒸馏易崩溃的问题，并在图像编辑和重构中展现了竞争力。 |
| [^9] | [P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer](https://arxiv.org/abs/2403.08214) | P2LHAP提出了一种新颖的Patch-to-Label Seq2Seq框架，可以在一个高效的单一任务模型中同时实现人类活动的分割、识别和预测 |
| [^10] | [Multi-modal Auto-regressive Modeling via Visual Words](https://arxiv.org/abs/2403.07720) | 本研究成功实现了多模态自回归建模，并通过引入视觉词的概念，将视觉特征映射到大语言模型的词汇表上，为视觉建模提供了监督信息。 |
| [^11] | [A Deep Learning Approach to Diabetes Diagnosis](https://arxiv.org/abs/2403.07483) | 采用深度学习方法，提出一种无创糖尿病诊断方法，通过反向传播神经网络和数据平衡技术，在准确性、敏感性和特异性方面取得显著改进 |
| [^12] | [SimuCourt: Building Judicial Decision-Making Agents with Real-world Judgement Documents](https://arxiv.org/abs/2403.02959) | 提出了SimuCourt司法基准，包括真实世界的司法文件，并引入了司法决策任务和多代理框架，评估了代理的司法分析和决策能力 |
| [^13] | [Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models](https://arxiv.org/abs/2402.18099) | 提出了一种新型的Layer-wise Scalable Adapter策略MedLaSA，用于编辑医学大型语言模型，能精确修改医学知识并解释事实，解决了当前方法在医学知识特殊化和复杂性方面的困难。 |
| [^14] | [Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images](https://arxiv.org/abs/2402.14899) | 该研究评估了多模态LLMs在采用串联推理时的对抗鲁棒性，发现串联推理在一定程度上提高了对抗性鲁棒性，但引入了一种新的停止推理攻击技术成功规避了这种增强。 |
| [^15] | [Automated Security Response through Online Learning with Adaptive Conjectures](https://arxiv.org/abs/2402.12499) | 该论文通过自适应猜想的在线学习，提出了一种适用于IT基础设施的自动化安全响应方法，其中游戏参与者通过Bayesian学习调整猜想，并通过推演更新策略，最终实现了最佳拟合，提高了推演在猜想模型下的性能。 |
| [^16] | [WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment](https://arxiv.org/abs/2402.12275) | 通过编写代码和与环境交互来构建世界模型的基于模型的LLM代理在样本效率上优于深度RL，并在计算效率上优于ReAct风格的代理。 |
| [^17] | [Paying Attention to Deflections: Mining Pragmatic Nuances for Whataboutism Detection in Online Discourse](https://arxiv.org/abs/2402.09934) | 本研究挖掘了在线话语中的演绎细微差别，提出了一种新的方法来准确检测反问主义，并在Twitter和YouTube数据集中取得了显著的改进。 |
| [^18] | [Learning Contrastive Feature Representations for Facial Action Unit Detection](https://arxiv.org/abs/2402.06165) | 这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。 |
| [^19] | [Embedding Knowledge Graphs in Degenerate Clifford Algebras](https://arxiv.org/abs/2402.04870) | 这项研究提出将知识图谱嵌入到退化的克利福德代数中。通过考虑具有零幂指数为2的零幂基向量，可以泛化基于二次数的方法并捕捉实体嵌入中缺乏高阶相互作用的模式。研究设计了两个新模型来发现代数的参数，并证明零幂向量有助于捕捉实体的特征。 |
| [^20] | [A new method for optical steel rope non-destructive damage detection](https://arxiv.org/abs/2402.03843) | 本文提出了一种新的算法用于在高海拔环境中对钢丝绳进行非破坏性损伤检测，其中包括一种准确提取钢丝绳的分割模型和一种区分正常和异常钢丝绳的检测模型，实验证明其性能显著高于基准模型。 |
| [^21] | [Conditional and Modal Reasoning in Large Language Models](https://arxiv.org/abs/2401.17169) | 本文研究了大型语言模型中的条件和情态推理能力，并发现除了GPT-4外，其他模型在条件句方面存在基本错误，并且即使是GPT-4在涉及认识情态的推理模式上也显示出逻辑上不一致的判断。 |
| [^22] | [Automated Approaches to Detect Self-Admitted Technical Debt: A Systematic Literature Review](https://arxiv.org/abs/2312.15020) | 论文提出了一种特征提取技术和ML/DL算法分类法，旨在比较和基准测试其在技术债务检测中的表现。 |
| [^23] | [ChatEDA: A Large Language Model Powered Autonomous Agent for EDA](https://arxiv.org/abs/2308.10204) | 该研究介绍了ChatEDA，一个由大型语言模型AutoMage赋能的EDA自主代理，通过有效管理任务计划、脚本生成和任务执行，简化了从RTL到GDSII的设计流程，并证明了其性能优越性。 |
| [^24] | [Generating Likely Counterfactuals Using Sum-Product Networks.](http://arxiv.org/abs/2401.14086) | 由于用户需求和最近的法规要求，需要对AI系统所做出的决策进行解释。本论文提出了一种使用Sum-Product Networks模拟寻找高可能性反事实推理的系统，该系统能够提供满足多个常见要求的最佳解释。 |
| [^25] | [RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning.](http://arxiv.org/abs/2401.08326) | RoTBench是一个多级基准，用于评估大型语言模型在工具学习中的鲁棒性。研究发现，LLMs在真实世界的噪声下表现出的稳定性需得到提高。 |
| [^26] | [Improving the Accuracy and Interpretability of Random Forests via Forest Pruning.](http://arxiv.org/abs/2401.05535) | 通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。 |
| [^27] | [An Incremental Unified Framework for Small Defect Inspection.](http://arxiv.org/abs/2312.08917) | 我们提出了一种增量统一框架（IUF），用于解决工业制造中的小缺陷检测问题。通过引入对象感知自注意力（OASA）和语义压缩损失（SCL），我们的方法可以在不断整合新物体时减少特征冲突问题，并展现出卓越的性能。 |
| [^28] | [Herd: Using multiple, smaller LLMs to match the performances of proprietary, large LLMs via an intelligent composer.](http://arxiv.org/abs/2310.19902) | 使用智能组合器，一群开源模型可以达到或超过专有模型的性能。 |
| [^29] | [Discriminator Guidance for Autoregressive Diffusion Models.](http://arxiv.org/abs/2310.15817) | 本文引入了判别器引导，用于自回归扩散模型的训练，通过使用最优判别器来纠正预训练模型，并提出了一个顺序蒙特卡洛算法来应对使用次优判别器的情况。在生成分子图的任务中，判别器引导有助于提高生成性能。 |
| [^30] | [LLM in the Shell: Generative Honeypots.](http://arxiv.org/abs/2309.00155) | 本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐，解决了以往蜜罐的重要局限性，并通过实验验证了其高准确率。 |
| [^31] | [HePCo: Data-Free Heterogeneous Prompt Consolidation for Continual Federated Learning.](http://arxiv.org/abs/2306.09970) | 本文提出了一种名为HePCo的轻量级提示合并算法，解决了在连续联邦学习中的数据异构和遗忘问题，并在不共享或存储任何数据的情况下最小化了通信开销。在真实数据集和合成数据集上实现了最先进的结果，并且保持了数据隐私。 |
| [^32] | [Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations.](http://arxiv.org/abs/2305.16326) | 本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。 |
| [^33] | [Learning Hand-Held Object Reconstruction from In-The-Wild Videos.](http://arxiv.org/abs/2305.03036) | 本研究提出了一种从野外视频中自动提取三维监督来扩展手持物体重建模型的学习方法。通过使用手部姿势作为物体姿势的代理和学习数据驱动的三维形状先验知识等方法，有效地解决了未知相机姿势和遮挡等问题，从而通过从单个RGB图像预测物体三维形状的占据网络得到了优秀的结果。 |
| [^34] | [Model-Free Learning and Optimal Policy Design in Multi-Agent MDPs Under Probabilistic Agent Dropout.](http://arxiv.org/abs/2304.12458) | 本文研究了多智能体MDP中基于概率代理掉线的情况，并提出了一种无模型算法，能够消除掉线情况需要枚举计算的限制，从而实现计算后掉线系统的最优策略设计。 |
| [^35] | [Graph Learning and Its Applications: A Holistic Survey.](http://arxiv.org/abs/2212.08966) | 本文全面综述了图学习的发展历程和应用场景，重点介绍了表示学习在文本、图像、化学和生物等领域中的显著性能，同时指出了对以前有价值的工作进行调查的需求。 |
| [^36] | [Curriculum Learning for Relative Overgeneralization.](http://arxiv.org/abs/2212.02733) | 本论文提出了一种名为相对过度泛化的课程学习（CURO）的新算法来解决多智能体强化学习中存在的相对过度泛化 (RO) 问题，该方法在解决展示强RO的合作任务方面具有很好的表现。 |
| [^37] | [GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation.](http://arxiv.org/abs/2206.06420) | 提出了一种名为GraphMLP的图形增强的MLP式架构，它将图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。在此基础上，还将GraphMLP灵活高效地扩展到视频领域，并成功地进行了时间动力学的建模。 |

# 详细

[^1]: 超越请求：利用HTTP响应头在不平衡环境中进行跨浏览器Web追踪器分类

    Beyond the Request: Harnessing HTTP Response Headers for Cross-Browser Web Tracker Classification in an Imbalanced Setting

    [https://rss.arxiv.org/abs/2402.01240](https://rss.arxiv.org/abs/2402.01240)

    本研究通过利用HTTP响应头设计了机器学习分类器，在跨浏览器环境下有效检测Web追踪器，结果在Chrome和Firefox上表现出较高的准确性和性能。

    

    万维网的连通性主要归因于HTTP协议，其中的HTTP消息提供了有关网络安全和隐私的信息头字段，特别是关于Web追踪。尽管已有研究利用HTTP/S请求消息来识别Web追踪器，但往往忽视了HTTP/S响应头。本研究旨在设计使用HTTP/S响应头进行Web追踪器检测的有效机器学习分类器。通过浏览器扩展程序T.EX获取的Chrome、Firefox和Brave浏览器的数据作为我们的数据集。在Chrome数据上训练了11个监督模型，并在所有浏览器上进行了测试。结果表明，在Chrome和Firefox上具有高准确性、F1分数、精确度、召回率和最小对数损失误差的性能，但在Brave浏览器上表现不佳，可能是由于其不同的数据分布和特征集。研究表明，这些分类器可以用于检测Web追踪器。

    The World Wide Web's connectivity is greatly attributed to the HTTP protocol, with HTTP messages offering informative header fields that appeal to disciplines like web security and privacy, especially concerning web tracking. Despite existing research employing HTTP/S request messages to identify web trackers, HTTP/S response headers are often overlooked. This study endeavors to design effective machine learning classifiers for web tracker detection using HTTP/S response headers. Data from the Chrome, Firefox, and Brave browsers, obtained through the traffic monitoring browser extension T.EX, serves as our data set. Eleven supervised models were trained on Chrome data and tested across all browsers. The results demonstrated high accuracy, F1-score, precision, recall, and minimal log-loss error for Chrome and Firefox, but subpar performance on Brave, potentially due to its distinct data distribution and feature set. The research suggests that these classifiers are viable for detecting w
    
[^2]: 用于安全自助大型语言模型探索的机构平台

    Institutional Platform for Secure Self-Service Large Language Model Exploration

    [https://rss.arxiv.org/abs/2402.00913](https://rss.arxiv.org/abs/2402.00913)

    这个论文介绍了一个用户友好型平台，旨在使大型定制语言模型更易于使用，通过最新的多LoRA推理技术和定制适配器，实现了数据隔离、加密和身份验证的安全服务。

    

    本文介绍了由肯塔基大学应用人工智能中心开发的用户友好型平台，旨在使大型定制语言模型（LLM）更易于使用。通过利用最近在多LoRA推理方面的进展，系统有效地适应了各类用户和项目的定制适配器。论文概述了系统的架构和关键特性，包括数据集策划、模型训练、安全推理和基于文本的特征提取。我们通过使用基于代理的方法建立了一个基于租户意识的计算网络，在安全地利用孤立资源岛的基础上形成了一个统一的系统。该平台致力于提供安全的LLM服务，强调过程和数据隔离、端到端加密以及基于角色的资源身份验证。该贡献与实现简化访问先进的AI模型和技术以支持科学发现的总体目标一致。

    This paper introduces a user-friendly platform developed by the University of Kentucky Center for Applied AI, designed to make large, customized language models (LLMs) more accessible. By capitalizing on recent advancements in multi-LoRA inference, the system efficiently accommodates custom adapters for a diverse range of users and projects. The paper outlines the system's architecture and key features, encompassing dataset curation, model training, secure inference, and text-based feature extraction.   We illustrate the establishment of a tenant-aware computational network using agent-based methods, securely utilizing islands of isolated resources as a unified system. The platform strives to deliver secure LLM services, emphasizing process and data isolation, end-to-end encryption, and role-based resource authentication. This contribution aligns with the overarching goal of enabling simplified access to cutting-edge AI models and technology in support of scientific discovery.
    
[^3]: 通过堆叠自动编码器和聚类实现地质制图的遥感框架

    Remote sensing framework for geological mapping via stacked autoencoders and clustering

    [https://arxiv.org/abs/2404.02180](https://arxiv.org/abs/2404.02180)

    通过堆叠自动编码器和聚类实现遥感数据地质制图的无监督机器学习框架

    

    有监督学习方法在遥感地质制图中面临着由于准确标记训练数据的稀缺性而限制的问题。相反，无监督学习方法，如降维和聚类，能够在不依赖预定义标签的情况下揭示遥感数据中的模式和结构。降维方法具有在提高地质图准确性方面发挥关键作用的潜力。虽然传统的降维方法可能在非线性数据上遇到困难，但无监督深度学习模型，如自动编码器，能够模拟数据中的非线性关系。堆叠自动编码器具有多个相互连接的层，用于捕获对遥感数据有用的分层数据表示。在本研究中，我们提出了一个利用堆叠自动编码器和聚类处理遥感数据的无监督机器学习框架。

    arXiv:2404.02180v1 Announce Type: cross  Abstract: Supervised learning methods for geological mapping via remote sensing face limitations due to the scarcity of accurately labelled training data. In contrast, unsupervised learning methods, such as dimensionality reduction and clustering have the ability to uncover patterns and structures in remote sensing data without relying on predefined labels. Dimensionality reduction methods have the potential to play a crucial role in improving the accuracy of geological maps. Although conventional dimensionality reduction methods may struggle with nonlinear data, unsupervised deep learning models such as autoencoders have the ability to model nonlinear relationship in data. Stacked autoencoders feature multiple interconnected layers to capture hierarchical data representations that can be useful for remote sensing data. In this study, we present an unsupervised machine learning framework for processing remote sensing data by utilizing stacked au
    
[^4]: WavLLM：面向稳健和自适应语音大语言模型

    WavLLM: Towards Robust and Adaptive Speech Large Language Model

    [https://arxiv.org/abs/2404.00656](https://arxiv.org/abs/2404.00656)

    WavLLM是一个稳健和自适应语音大语言模型，引入了双编码器和Prompt-aware LoRA权重适配器，通过两阶段课程学习方法优化，解耦不同类型的语音信息，为处理语义内容和说话者身份的独特特征提供了新思路

    

    近年来，大型语言模型(LLMs)的最新进展彻底改变了自然语言处理领域，逐渐拓宽了它们的范围到多模态感知和生成。然而，有效地将听觉能力整合到LLMs中会带来显著挑战，特别是在泛化跨不同语境和执行复杂听觉任务方面。在这项工作中，我们引入了WavLLM，一个具有双编码器和Prompt-aware LoRA权重适配器的稳健和自适应语音大语言模型，通过两阶段课程学习方法进行优化。利用双编码器，我们解耦不同类型的语音信息，利用Whisper编码器处理语音的语义内容，利用WavLM编码器捕捉说话者身份的独特特征。在课程学习框架内，WavLLM首先通过混合要素进行优化来建立其基础能力

    arXiv:2404.00656v1 Announce Type: cross  Abstract: The recent advancements in large language models (LLMs) have revolutionized the field of natural language processing, progressively broadening their scope to multimodal perception and generation. However, effectively integrating listening capabilities into LLMs poses significant challenges, particularly with respect to generalizing across varied contexts and executing complex auditory tasks. In this work, we introduce WavLLM, a robust and adaptive speech large language model with dual encoders, and a prompt-aware LoRA weight adapter, optimized by a two-stage curriculum learning approach. Leveraging dual encoders, we decouple different types of speech information, utilizing a Whisper encoder to process the semantic content of speech, and a WavLM encoder to capture the unique characteristics of the speaker's identity. Within the curriculum learning framework, WavLLM first builds its foundational capabilities by optimizing on mixed elemen
    
[^5]: 基于大型语言模型增强强化学习的调查:概念、分类和方法

    Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods

    [https://arxiv.org/abs/2404.00282](https://arxiv.org/abs/2404.00282)

    大型语言模型在强化学习中具有潜在优势，通过结构化分类和角色分析，为未来研究提供指导。

    

    随着大规模语言模型(LLMs)拥有广泛的预训练知识和高级通用能力，它们在增强学习方面如多任务学习、样本效率和任务规划等方面展现出潜力。本调查综述了现有$\textit{LLM增强RL}$文献，总结了其与传统RL方法的特征，旨在澄清研究范围和未来研究方向。利用经典的Agent-环境交互范例，我们提出了一个结构化的分类法，系统地将LLMs在RL中的功能分类，包括四种角色：信息处理器、奖励设计者、决策者和生成器。此外，针对每个角色，我们总结了方法论，分析了缓解的特定RL挑战，并提供了未来方向的见解。最后，潜在应用、前景

    arXiv:2404.00282v1 Announce Type: cross  Abstract: With extensive pre-trained knowledge and high-level general capabilities, large language models (LLMs) emerge as a promising avenue to augment reinforcement learning (RL) in aspects such as multi-task learning, sample efficiency, and task planning. In this survey, we provide a comprehensive review of the existing literature in $\textit{LLM-enhanced RL}$ and summarize its characteristics compared to conventional RL methods, aiming to clarify the research scope and directions for future studies. Utilizing the classical agent-environment interaction paradigm, we propose a structured taxonomy to systematically categorize LLMs' functionalities in RL, including four roles: information processor, reward designer, decision-maker, and generator. Additionally, for each role, we summarize the methodologies, analyze the specific RL challenges that are mitigated, and provide insights into future directions. Lastly, potential applications, prospecti
    
[^6]: SugarcaneNet2024: LASSO正则化的预训练模型的优化加权平均集成方法用于甘蔗病害分类

    SugarcaneNet2024: An Optimized Weighted Average Ensemble Approach of LASSO Regularized Pre-trained Models for Sugarcane Disease Classification

    [https://arxiv.org/abs/2403.18870](https://arxiv.org/abs/2403.18870)

    SugarcaneNet2024是通过优化加权平均集成LASSO正则化的预训练模型，在甘蔗病害分类中表现出色，具有快速准确的检测能力。

    

    甘蔗作为世界糖业的关键作物，容易受多种病害侵害，这些病害对其产量和质量都有重大负面影响。为了有效管理和实施预防措施，必须及时准确地检测病害。本研究提出了一种名为SugarcaneNet2024的独特模型，通过叶片图像处理，能够优于先前方法自动快速检测甘蔗病害。我们提出的模型汇总了七个定制的、经过LASSO正则化的预训练模型的优化加权平均集成，特别是InceptionV3、InceptionResNetV2、DenseNet201、DenseNet169、Xception和ResNet152V2。最初，我们在这些预训练模型底部添加了三层更密集层，具有0.0001的LASSO正则化，三个30%的dropout层和三个启用renorm的批量归一化，以提高性能。

    arXiv:2403.18870v1 Announce Type: cross  Abstract: Sugarcane, a key crop for the world's sugar industry, is prone to several diseases that have a substantial negative influence on both its yield and quality. To effectively manage and implement preventative initiatives, diseases must be detected promptly and accurately. In this study, we present a unique model called sugarcaneNet2024 that outperforms previous methods for automatically and quickly detecting sugarcane disease through leaf image processing. Our proposed model consolidates an optimized weighted average ensemble of seven customized and LASSO-regularized pre-trained models, particularly InceptionV3, InceptionResNetV2, DenseNet201, DenseNet169, Xception, and ResNet152V2. Initially, we added three more dense layers with 0.0001 LASSO regularization, three 30% dropout layers, and three batch normalizations with renorm enabled at the bottom of these pre-trained models to improve the performance. The accuracy of sugarcane leaf dise
    
[^7]: GeNet:一种基于图神经网络的抗噪声任务导向语义通信范式

    GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic Communication Paradigm

    [https://arxiv.org/abs/2403.18296](https://arxiv.org/abs/2403.18296)

    GeNet提出了一种基于图神经网络的语义通信范式，通过将数据转换为图结构、利用编码器提取语义信息并利用解码器重建信息的方法来实现抗噪声任务导向通信。

    

    传统的语义通信任务方法依赖于了解信噪比（SNR）来减轻通道噪声。然而，这些方法需要在特定的SNR条件下进行训练，需要大量时间和计算资源。在本文中，我们提出了GeNet，这是一种基于图神经网络（GNN）的语义通信范式，旨在抵抗噪声，从而促进任务导向通信（TOC）。我们提出了一种新颖的方法，首先将输入数据图像转换为图结构。然后利用基于GNN的编码器从源数据中提取语义信息。这些提取的语义信息然后通过通道传输。在接收端，使用基于GNN的解码器从源数据中重建相关的语义信息以用于TOC。通过实验评估，我们展示了GeNet在抗噪声TOC中的有效性。

    arXiv:2403.18296v1 Announce Type: cross  Abstract: Traditional approaches to semantic communication tasks rely on the knowledge of the signal-to-noise ratio (SNR) to mitigate channel noise. However, these methods necessitate training under specific SNR conditions, entailing considerable time and computational resources. In this paper, we propose GeNet, a Graph Neural Network (GNN)-based paradigm for semantic communication aimed at combating noise, thereby facilitating Task-Oriented Communication (TOC). We propose a novel approach where we first transform the input data image into graph structures. Then we leverage a GNN-based encoder to extract semantic information from the source data. This extracted semantic information is then transmitted through the channel. At the receiver's end, a GNN-based decoder is utilized to reconstruct the relevant semantic information from the source data for TOC. Through experimental evaluation, we show GeNet's effectiveness in anti-noise TOC while decoup
    
[^8]: DreamSampler：统一扩散采样和分数蒸馏以用于图像处理

    DreamSampler: Unifying Diffusion Sampling and Score Distillation for Image Manipulation

    [https://arxiv.org/abs/2403.11415](https://arxiv.org/abs/2403.11415)

    DreamSampler框架通过整合反向扩散采样和分数蒸馏，提供了模型无关的图像处理方法，解决了分数蒸馏易崩溃的问题，并在图像编辑和重构中展现了竞争力。

    

    反向采样和分数蒸馏已成为最近几年使用潜在扩散模型（LDMs）进行图像处理的主要工具。虽然反向扩散采样通常需要调整LDM架构或特征工程，分数蒸馏提供了一种简单而强大的与模型无关的方法，但往往容易发生模式崩溃。为了解决这些局限性并利用这两种方法的优势，我们引入了一个称为DreamSampler的新颖框架，通过正则化潜在优化的视角无缝地整合了这两种不同的方法。类似于分数蒸馏，DreamSampler是一种适用于任何LDM架构的模型无关方法，但它允许在图像编辑和重构中进行蒸馏和反向采样，并提供额外的指导。通过涉及图像编辑、SVG重构等实验，我们展示了竞争力

    arXiv:2403.11415v1 Announce Type: cross  Abstract: Reverse sampling and score-distillation have emerged as main workhorses in recent years for image manipulation using latent diffusion models (LDMs). While reverse diffusion sampling often requires adjustments of LDM architecture or feature engineering, score distillation offers a simple yet powerful model-agnostic approach, but it is often prone to mode-collapsing. To address these limitations and leverage the strengths of both approaches, here we introduce a novel framework called {\em DreamSampler}, which seamlessly integrates these two distinct approaches through the lens of regularized latent optimization. Similar to score-distillation, DreamSampler is a model-agnostic approach applicable to any LDM architecture, but it allows both distillation and reverse sampling with additional guidance for image editing and reconstruction. Through experiments involving image editing, SVG reconstruction and etc, we demonstrate the competitive pe
    
[^9]: P2LHAP：基于可穿戴传感器的人类活动识别、分割和预测的Patch-to-Label Seq2Seq Transformer

    P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer

    [https://arxiv.org/abs/2403.08214](https://arxiv.org/abs/2403.08214)

    P2LHAP提出了一种新颖的Patch-to-Label Seq2Seq框架，可以在一个高效的单一任务模型中同时实现人类活动的分割、识别和预测

    

    传统深度学习方法很难同时从传感器数据中分割、识别和预测人类活动，限制了它们在医疗保健和辅助生活等领域的实用性，而这些领域对于实时理解正在进行和即将发生的活动至关重要。本文提出了P2LHAP，一种新颖的Patch-to-Label Seq2Seq框架，可以在一个高效的单一任务模型中解决这三个任务。P2LHAP将传感器数据流划分为一系列“补丁”，作为输入标记，并输出一系列包括预测的未来活动在内的补丁级活动标签。提出了一种基于周围补丁标签的独特平滑技术，可准确识别活动边界。此外，P2LHAP通过传感器信号通道独立的Transformer编码器和解码器学习补丁级表示。所有通道在所有序列上共享嵌入和Transformer权重。

    arXiv:2403.08214v1 Announce Type: cross  Abstract: Traditional deep learning methods struggle to simultaneously segment, recognize, and forecast human activities from sensor data. This limits their usefulness in many fields such as healthcare and assisted living, where real-time understanding of ongoing and upcoming activities is crucial. This paper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles all three tasks in a efficient single-task model. P2LHAP divides sensor data streams into a sequence of "patches", served as input tokens, and outputs a sequence of patch-level activity labels including the predicted future activities. A unique smoothing technique based on surrounding patch labels, is proposed to identify activity boundaries accurately. Additionally, P2LHAP learns patch-level representation by sensor signal channel-independent Transformer encoders and decoders. All channels share embedding and Transformer weights across all sequences. Evaluated on thre
    
[^10]: 通过视觉词进行多模态自回归建模

    Multi-modal Auto-regressive Modeling via Visual Words

    [https://arxiv.org/abs/2403.07720](https://arxiv.org/abs/2403.07720)

    本研究成功实现了多模态自回归建模，并通过引入视觉词的概念，将视觉特征映射到大语言模型的词汇表上，为视觉建模提供了监督信息。

    

    大语言模型（LLMs）受益于在大量未标记文本语料库上进行自回归建模的方法，展现出强大的感知和推理能力。然而，将自回归建模扩展到多模态场景以构建大型多模态模型（LMMs）时，存在一个巨大困难，即图像信息在LMM中以连续的视觉嵌入进行处理，无法获得离散的用于分类的监督标签。本文首次成功地进行了多模态自回归建模，并提出了统一的目标。具体来说，我们提出了视觉词的概念，将视觉特征映射到LLM词汇表上的概率分布，为视觉建模提供了监督信息。我们进一步探讨了LMM中语义空间内视觉特征的分布以及使用文本嵌入来表示的可能性。

    arXiv:2403.07720v1 Announce Type: cross  Abstract: Large Language Models (LLMs), benefiting from the auto-regressive modelling approach performed on massive unannotated texts corpora, demonstrates powerful perceptual and reasoning capabilities. However, as for extending auto-regressive modelling to multi-modal scenarios to build Large Multi-modal Models (LMMs), there lies a great difficulty that the image information is processed in the LMM as continuous visual embeddings, which cannot obtain discrete supervised labels for classification. In this paper, we successfully perform multi-modal auto-regressive modeling with a unified objective for the first time. Specifically, we propose the concept of visual words, which maps the visual features to probability distributions over LLM's vocabulary, providing supervision information for visual modelling. We further explore the distribution of visual features in the semantic space within LMM and the possibility of using text embeddings to repre
    
[^11]: 一种深度学习方法用于糖尿病诊断

    A Deep Learning Approach to Diabetes Diagnosis

    [https://arxiv.org/abs/2403.07483](https://arxiv.org/abs/2403.07483)

    采用深度学习方法，提出一种无创糖尿病诊断方法，通过反向传播神经网络和数据平衡技术，在准确性、敏感性和特异性方面取得显著改进

    

    糖尿病是由胰岛素产生或利用不足导致的，对身体造成了广泛的危害。现有的诊断方法通常是侵入性的，并伴有诸多缺点，比如成本限制。尽管存在像类间k最近邻(CkNN)和通用回归神经网络(GRNN)这样的机器学习模型，但它们在处理不平衡数据时往往表现不佳。利用传感技术和机器学习的进展，我们提出了一种使用带有批量标准化的反向传播神经网络(BPNN)进行无创糖尿病诊断的方法，结合数据重采样和归一化以实现类平衡。我们的方法解决了传统机器学习中存在的诸多挑战，比如与传统方法相关的性能受限。在三个数据集上的实验结果显示，与传统方法相比，我们在整体准确性、敏感性和特异性方面取得了显著的改进。值得注意的是，我们实现了高准确率

    arXiv:2403.07483v1 Announce Type: cross  Abstract: Diabetes, resulting from inadequate insulin production or utilization, causes extensive harm to the body. Existing diagnostic methods are often invasive and come with drawbacks, such as cost constraints. Although there are machine learning models like Classwise k Nearest Neighbor (CkNN) and General Regression Neural Network (GRNN), they struggle with imbalanced data and result in under-performance. Leveraging advancements in sensor technology and machine learning, we propose a non-invasive diabetes diagnosis using a Back Propagation Neural Network (BPNN) with batch normalization, incorporating data re-sampling and normalization for class balancing. Our method addresses existing challenges such as limited performance associated with traditional machine learning. Experimental results on three datasets show significant improvements in overall accuracy, sensitivity, and specificity compared to traditional methods. Notably, we achieve accur
    
[^12]: SimuCourt: 利用真实司法判决文件构建司法决策代理

    SimuCourt: Building Judicial Decision-Making Agents with Real-world Judgement Documents

    [https://arxiv.org/abs/2403.02959](https://arxiv.org/abs/2403.02959)

    提出了SimuCourt司法基准，包括真实世界的司法文件，并引入了司法决策任务和多代理框架，评估了代理的司法分析和决策能力

    

    随着深度学习、自然语言处理技术的发展，有效提高了传统司法行业各个方面的效率。然而，目前大多数工作主要集中在个别司法阶段，忽视了跨阶段的协作。随着由大型语言模型提供支持的自主代理在现实环境中变得越来越智能，并能做出复杂决策，为司法智能提供了新的见解。本文介绍了SimuCourt，一个司法基准，包括来自真实世界的420份判决文件，涵盖了三种最常见类型的司法案例，以及一个新颖任务司法决策，用于评估代理的司法分析和决策能力。为了支持这一任务，我们构建了一个大规模司法知识库，JudicialKB，其中包含多种法律知识。我们提出了一种新颖的多代理框架，AgentsCourt

    arXiv:2403.02959v1 Announce Type: cross  Abstract: With the development of deep learning, natural language processing technology has effectively improved the efficiency of various aspects of the traditional judicial industry. However, most current efforts focus solely on individual judicial stage, overlooking cross-stage collaboration. As the autonomous agents powered by large language models are becoming increasingly smart and able to make complex decisions in real-world settings, offering new insights for judicial intelligence. In this paper, (1) we introduce SimuCourt, a judicial benchmark that encompasses 420 judgment documents from real-world, spanning the three most common types of judicial cases, and a novel task Judicial Decision-Making to evaluate the judicial analysis and decision-making power of agents. To support this task, we construct a large-scale judicial knowledge base, JudicialKB, with multiple legal knowledge. (2) we propose a novel multi-agent framework, AgentsCourt
    
[^13]: 编辑医学大型语言模型的事实知识和解释能力

    Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models

    [https://arxiv.org/abs/2402.18099](https://arxiv.org/abs/2402.18099)

    提出了一种新型的Layer-wise Scalable Adapter策略MedLaSA，用于编辑医学大型语言模型，能精确修改医学知识并解释事实，解决了当前方法在医学知识特殊化和复杂性方面的困难。

    

    模型编辑旨在精确修改大型语言模型（LLMs）对特定知识的行为，同时保持不相关的知识不变。已经证明，这种方法在解决LLMs中的幻觉和过时问题方面是有效的。因此，它可以提高LLMs在许多关键领域（例如医学领域）中的应用，其中幻觉是不可容忍的。本文提出两项模型编辑研究，并在医学领域验证它们：（1）直接编辑医学事实知识和（2）编辑对事实的解释。同时，我们观察到当前的模型编辑方法在医学知识的特殊化和复杂性方面存在困难。因此，我们提出了MedLaSA，一种新型的适用于医学模型编辑的分层可扩展适配器策略。它采用因果追踪来识别神经元中知识的精确位置，然后将可扩展适配器引入到LLMs的密集层中。

    arXiv:2402.18099v1 Announce Type: cross  Abstract: Model editing aims to precisely modify the behaviours of large language models (LLMs) on specific knowledge while keeping irrelevant knowledge unchanged. It has been proven effective in resolving hallucination and out-of-date issues in LLMs. As a result, it can boost the application of LLMs in many critical domains (e.g., medical domain), where the hallucination is not tolerable. In this paper, we propose two model editing studies and validate them in the medical domain: (1) directly editing the factual medical knowledge and (2) editing the explanations to facts. Meanwhile, we observed that current model editing methods struggle with the specialization and complexity of medical knowledge. Therefore, we propose MedLaSA, a novel Layer-wise Scalable Adapter strategy for medical model editing. It employs causal tracing to identify the precise location of knowledge in neurons and then introduces scalable adapters into the dense layers of LL
    
[^14]: 停止推理！当多模态LLMs与串联推理遇到对抗性图像

    Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images

    [https://arxiv.org/abs/2402.14899](https://arxiv.org/abs/2402.14899)

    该研究评估了多模态LLMs在采用串联推理时的对抗鲁棒性，发现串联推理在一定程度上提高了对抗性鲁棒性，但引入了一种新的停止推理攻击技术成功规避了这种增强。

    

    最近，多模态LLMs（MLLMs）展示了很强的理解图像的能力。然而，像传统视觉模型一样，它们仍然容易受到对抗性图像的攻击。与此同时，串联推理（CoT）已经被广泛应用在MLLMs上，不仅提高了模型的性能，而且通过提供中间推理步骤来增强模型的可解释性。然而，目前还缺乏关于MLLMs在CoT下的对抗鲁棒性的研究，以及在MLLMs用对抗性图像推断错误答案时推理的合理性。我们的研究评估了采用CoT推理时MLLMs的对抗鲁棒性，发现CoT在一定程度上提高了对抗性鲁棒性，抵抗了已有的攻击方法。此外，我们引入了一种新的停止推理攻击技术，可以有效地规避CoT引起的鲁棒性增强。最后，我们展示了CoT推理的变化。

    arXiv:2402.14899v1 Announce Type: cross  Abstract: Recently, Multimodal LLMs (MLLMs) have shown a great ability to understand images. However, like traditional vision models, they are still vulnerable to adversarial images. Meanwhile, Chain-of-Thought (CoT) reasoning has been widely explored on MLLMs, which not only improves model's performance, but also enhances model's explainability by giving intermediate reasoning steps. Nevertheless, there is still a lack of study regarding MLLMs' adversarial robustness with CoT and an understanding of what the rationale looks like when MLLMs infer wrong answers with adversarial images. Our research evaluates the adversarial robustness of MLLMs when employing CoT reasoning, finding that CoT marginally improves adversarial robustness against existing attack methods. Moreover, we introduce a novel stop-reasoning attack technique that effectively bypasses the CoT-induced robustness enhancements. Finally, we demonstrate the alterations in CoT reasonin
    
[^15]: 通过自适应猜想的在线学习实现自动化安全响应

    Automated Security Response through Online Learning with Adaptive Conjectures

    [https://arxiv.org/abs/2402.12499](https://arxiv.org/abs/2402.12499)

    该论文通过自适应猜想的在线学习，提出了一种适用于IT基础设施的自动化安全响应方法，其中游戏参与者通过Bayesian学习调整猜想，并通过推演更新策略，最终实现了最佳拟合，提高了推演在猜想模型下的性能。

    

    我们研究了针对IT基础设施的自动化安全响应，并将攻击者和防御者之间的互动形式表述为一个部分观测、非平稳博弈。我们放宽了游戏模型正确规定的标准假设，并考虑每个参与者对模型有一个概率性猜想，可能在某种意义上错误规定，即真实模型的概率为0。这种形式允许我们捕捉关于基础设施和参与者意图的不确定性。为了在线学习有效的游戏策略，我们设计了一种新颖的方法，其中一个参与者通过贝叶斯学习迭代地调整其猜想，并通过推演更新其策略。我们证明了猜想会收敛到最佳拟合，并提供了在具有猜测模型的情况下推演实现性能改进的上限。为了刻画游戏的稳定状态，我们提出了Berk-Nash平衡的一个变种。

    arXiv:2402.12499v1 Announce Type: cross  Abstract: We study automated security response for an IT infrastructure and formulate the interaction between an attacker and a defender as a partially observed, non-stationary game. We relax the standard assumption that the game model is correctly specified and consider that each player has a probabilistic conjecture about the model, which may be misspecified in the sense that the true model has probability 0. This formulation allows us to capture uncertainty about the infrastructure and the intents of the players. To learn effective game strategies online, we design a novel method where a player iteratively adapts its conjecture using Bayesian learning and updates its strategy through rollout. We prove that the conjectures converge to best fits, and we provide a bound on the performance improvement that rollout enables with a conjectured model. To characterize the steady state of the game, we propose a variant of the Berk-Nash equilibrium. We 
    
[^16]: WorldCoder，一种基于模型的LLM代理：通过编写代码和与环境交互构建世界模型

    WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment

    [https://arxiv.org/abs/2402.12275](https://arxiv.org/abs/2402.12275)

    通过编写代码和与环境交互来构建世界模型的基于模型的LLM代理在样本效率上优于深度RL，并在计算效率上优于ReAct风格的代理。

    

    我们提出了一种基于模型的代理，通过与环境的交互构建代表其对世界知识的Python程序。该世界模型试图解释其交互，同时对自己能够获得的奖励持乐观态度。我们通过扩展LLM的程序合成工作来实现这一点。我们在网格世界上研究了我们的代理，发现我们的方法在样本效率上比深度强化学习更高，并且在计算效率上比ReAct风格的代理更高效。

    arXiv:2402.12275v1 Announce Type: new  Abstract: We give a model-based agent that builds a Python program representing its knowledge of the world based on its interactions with the environment. The world model tries to explain its interactions, while also being optimistic about what reward it can achieve. We do this by extending work on program synthesis via LLMs. We study our agent on gridworlds, finding our approach is more sample-efficient compared to deep RL, and more compute-efficient compared to ReAct-style agents.
    
[^17]: 关注偏差：挖掘在线话语中的演绎细微差别，检测反问主义

    Paying Attention to Deflections: Mining Pragmatic Nuances for Whataboutism Detection in Online Discourse

    [https://arxiv.org/abs/2402.09934](https://arxiv.org/abs/2402.09934)

    本研究挖掘了在线话语中的演绎细微差别，提出了一种新的方法来准确检测反问主义，并在Twitter和YouTube数据集中取得了显著的改进。

    

    反问主义在扰乱叙事和播种不信任方面具有强大的工具效用，但在定量自然语言处理研究中却未得到充分探索。此外，过去的研究未能区分反问主义作为误导和宣传策略的用途与其作为语用和语义框架工具的用途。我们介绍了新的来自Twitter和YouTube的数据集，揭示了反问主义、宣传和tu quoque谬误之间的重叠和区别。此外，结合最近在语言语义学领域的研究，我们将“what about”词汇结构与反问主义区分开来。我们的实验揭示了准确检测反问主义的独特挑战，促使我们引入了一种使用注意权重进行负样本挖掘的新方法。在Twitter和YouTube数据集中，我们的方法分别相对于之前最先进的方法提高了4%和10%。

    arXiv:2402.09934v1 Announce Type: cross  Abstract: Whataboutism, a potent tool for disrupting narratives and sowing distrust, remains under-explored in quantitative NLP research. Moreover, past work has not distinguished its use as a strategy for misinformation and propaganda from its use as a tool for pragmatic and semantic framing. We introduce new datasets from Twitter and YouTube, revealing overlaps as well as distinctions between whataboutism, propaganda, and the tu quoque fallacy. Furthermore, drawing on recent work in linguistic semantics, we differentiate the `what about' lexical construct from whataboutism. Our experiments bring to light unique challenges in its accurate detection, prompting the introduction of a novel method using attention weights for negative sample mining. We report significant improvements of 4% and 10% over previous state-of-the-art methods in our Twitter and YouTube collections, respectively.
    
[^18]: 学习对比特征表示来进行面部动作单元检测

    Learning Contrastive Feature Representations for Facial Action Unit Detection

    [https://arxiv.org/abs/2402.06165](https://arxiv.org/abs/2402.06165)

    这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。

    

    面部动作单元（AU）检测的主要方法涉及监督的多标签二进制分类问题。现有的方法常常对AU的像素级信息进行编码，从而对模型的复杂性和表达能力提出了很大的要求。此外，由于存在噪声AU标签，这种做法增加了过拟合的风险。在本研究中，我们引入了一个对比学习框架，通过监督和自监督信号增强。目标是在AU检测领域中摆脱传统的像素级学习范式，获得判别特征。为了应对噪声AU标签带来的挑战，我们通过引入自监督信号来增强监督信号。这种增强是通过正样本抽样实现的，包括三种不同类型的正样本对。另外，为了减轻每个AU类型的分布不平衡问题，我们采用了一种权衡重要性的损失函数。

    The predominant approach to facial action unit (AU) detection revolves around a supervised multi-label binary classification problem. Existing methodologies often encode pixel-level information of AUs, thereby imposing substantial demands on model complexity and expressiveness. Moreover, this practice elevates the susceptibility to overfitting due to the presence of noisy AU labels. In the present study, we introduce a contrastive learning framework enhanced by both supervised and self-supervised signals. The objective is to acquire discriminative features, deviating from the conventional pixel-level learning paradigm within the domain of AU detection. To address the challenge posed by noisy AU labels, we augment the supervised signal through the introduction of a self-supervised signal. This augmentation is achieved through positive sample sampling, encompassing three distinct types of positive sample pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we empl
    
[^19]: 将知识图谱嵌入到退化的克利福德代数中

    Embedding Knowledge Graphs in Degenerate Clifford Algebras

    [https://arxiv.org/abs/2402.04870](https://arxiv.org/abs/2402.04870)

    这项研究提出将知识图谱嵌入到退化的克利福德代数中。通过考虑具有零幂指数为2的零幂基向量，可以泛化基于二次数的方法并捕捉实体嵌入中缺乏高阶相互作用的模式。研究设计了两个新模型来发现代数的参数，并证明零幂向量有助于捕捉实体的特征。

    

    克利福德代数是实数、复数和四元数的自然推广。迄今为止，在知识图谱嵌入的背景下，只有形式为$Cl_{p,q}$（即没有零幂基向量的代数）的克利福德代数受到研究。我们提出考虑零幂基向量，其幂指数为2。在这些空间中，被称为$Cl_{p,q,r}$，可以泛化基于二次数的方法（无法使用$Cl_{p,q}$进行建模）并捕捉源于实数和复数部分间缺乏高阶相互作用的实体嵌入的模式。我们设计了两个新模型来发现参数$p$，$q$和$r$。第一个模型使用贪婪搜索优化$p$，$q$和$r$。第二个模型基于使用神经网络计算的输入知识图谱的嵌入来预测$(p, q, r)$。我们在七个基准数据集上进行的评估结果表明，零幂向量有助于捕捉实体的特征。

    Clifford algebras are a natural generalization of the real numbers, the complex numbers, and the quaternions. So far, solely Clifford algebras of the form $Cl_{p,q}$ (i.e., algebras without nilpotent base vectors) have been studied in the context of knowledge graph embeddings. We propose to consider nilpotent base vectors with a nilpotency index of two. In these spaces, denoted $Cl_{p,q,r}$, allows generalizing over approaches based on dual numbers (which cannot be modelled using $Cl_{p,q}$) and capturing patterns that emanate from the absence of higher-order interactions between real and complex parts of entity embeddings. We design two new models for the discovery of the parameters $p$, $q$, and $r$. The first model uses a greedy search to optimize $p$, $q$, and $r$. The second predicts $(p, q,r)$ based on an embedding of the input knowledge graph computed using neural networks. The results of our evaluation on seven benchmark datasets suggest that nilpotent vectors can help capture 
    
[^20]: 光学钢丝绳非破坏性损伤检测的新方法

    A new method for optical steel rope non-destructive damage detection

    [https://arxiv.org/abs/2402.03843](https://arxiv.org/abs/2402.03843)

    本文提出了一种新的算法用于在高海拔环境中对钢丝绳进行非破坏性损伤检测，其中包括一种准确提取钢丝绳的分割模型和一种区分正常和异常钢丝绳的检测模型，实验证明其性能显著高于基准模型。

    

    本文提出了一种针对高海拔环境（空中吊索道）中的钢丝绳非破坏性损伤检测的新算法。该算法包括两个关键组件：首先，设计了一种名为RGBD-UNet的分割模型，可以准确地从复杂背景中提取钢丝绳。该模型通过提出的CMA模块可以处理和结合颜色和深度信息。其次，开发了一种名为VovNetV3.5的检测模型，用于区分正常和异常的钢丝绳。它将VovNet架构与DBB模块结合起来以提高性能。此外，还提出了一种新颖的背景增强方法，以增强分割模型的泛化能力。创建了包含不同场景中钢丝绳图像的数据集，用于分割和检测模型的训练和测试。实验证明，在基准模型上取得了显著的改进。在提出的数据集上，基于此算法的传感器识别性能（h）明显提高。

    This paper presents a novel algorithm for non-destructive damage detection for steel ropes in high-altitude environments (aerial ropeway). The algorithm comprises two key components: First, a segmentation model named RGBD-UNet is designed to accurately extract steel ropes from complex backgrounds. This model is equipped with the capability to process and combine color and depth information through the proposed CMA module. Second, a detection model named VovNetV3.5 is developed to differentiate between normal and abnormal steel ropes. It integrates the VovNet architecture with a DBB module to enhance performance. Besides, a novel background augmentation method is proposed to enhance the generalization ability of the segmentation model. Datasets containing images of steel ropes in different scenarios are created for the training and testing of both the segmentation and detection models. Experiments demonstrate a significant improvement over baseline models. On the proposed dataset, the h
    
[^21]: 大型语言模型中的条件和情态推理

    Conditional and Modal Reasoning in Large Language Models

    [https://arxiv.org/abs/2401.17169](https://arxiv.org/abs/2401.17169)

    本文研究了大型语言模型中的条件和情态推理能力，并发现除了GPT-4外，其他模型在条件句方面存在基本错误，并且即使是GPT-4在涉及认识情态的推理模式上也显示出逻辑上不一致的判断。

    

    关于大型语言模型（LLM）的推理能力的研究正在人工智能和认知科学领域不断增加。本文探讨了十几个LLM能否区分逻辑上正确的推论和逻辑上荒谬的推论。我们重点关注涉及条件句（例如，“如果安有一个皇后，那么鲍勃有一个J牌”）和认识情态（例如，“安可能有一个A牌”，“鲍勃必须有一个K牌”）的推理模式。这些推理模式对于逻辑学家、哲学家和语言学家来说具有特殊的兴趣，因为它们可能在人类推理中扮演一个核心角色。因此，评估LLM在这些推理模式上的表现与人类的推理能力是否相匹配是非常相关的。在我们测试的LLM中，除了GPT-4，其他都常常在条件句方面犯基本错误。此外，即使是GPT-4，在涉及认识情态的推理模式上也显示出逻辑上不一致的判断。

    The reasoning abilities of large language models (LLMs) are the topic of a growing body of research in artificial intelligence and cognitive science. In this paper, we probe the extent to which a dozen LLMs are able to distinguish logically correct inferences from logically fallacious ones. We focus on inference patterns involving conditionals (e.g., 'If Ann has a queen, then Bob has a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob must have a king'). These inference patterns have been of special interest to logicians, philosophers, and linguists, since they plausibly play a central role in human reasoning. Assessing LLMs on these inference patterns is thus highly relevant to the question of how much the reasoning abilities of LLMs match those of humans. Among the LLMs we tested, all but GPT-4 often make basic mistakes with conditionals. Moreover, even GPT-4 displays logically inconsistent judgments across inference patterns involving epistemic modals.
    
[^22]: 自动化方法检测自我承认的技术债务：系统文献综述

    Automated Approaches to Detect Self-Admitted Technical Debt: A Systematic Literature Review

    [https://arxiv.org/abs/2312.15020](https://arxiv.org/abs/2312.15020)

    论文提出了一种特征提取技术和ML/DL算法分类法，旨在比较和基准测试其在技术债务检测中的表现。

    

    技术债务是软件开发中普遍存在的问题，通常源自开发过程中做出的权衡，在影响软件可维护性和阻碍未来开发工作方面起到作用。自我承认的技术债务（SATD）指的是开发人员明确承认代码库中存在的代码质量或设计缺陷。自动检测SATD已经成为一个重要的研究领域，旨在帮助开发人员高效地识别和解决技术债务。然而，文献中广泛采用的NLP特征提取方法和算法种类多样化常常阻碍研究人员试图提高其性能。基于此，本系统文献综述提出了一种特征提取技术和ML/DL算法分类法，其目的是比较和基准测试所考察研究中它们的性能。我们选择......

    arXiv:2312.15020v2 Announce Type: replace-cross  Abstract: Technical debt is a pervasive issue in software development, often arising from trade-offs made during development, which can impede software maintainability and hinder future development efforts. Self-admitted technical debt (SATD) refers to instances where developers explicitly acknowledge suboptimal code quality or design flaws in the codebase. Automated detection of SATD has emerged as a critical area of research, aiming to assist developers in identifying and addressing technical debt efficiently. However, the enormous variety of feature extraction approaches of NLP and algorithms employed in the literature often hinder researchers from trying to improve their performance. In light of this, this systematic literature review proposes a taxonomy of feature extraction techniques and ML/DL algorithms used in technical debt detection: its objective is to compare and benchmark their performance in the examined studies. We select
    
[^23]: ChatEDA：基于大型语言模型的自主代理用于EDA

    ChatEDA: A Large Language Model Powered Autonomous Agent for EDA

    [https://arxiv.org/abs/2308.10204](https://arxiv.org/abs/2308.10204)

    该研究介绍了ChatEDA，一个由大型语言模型AutoMage赋能的EDA自主代理，通过有效管理任务计划、脚本生成和任务执行，简化了从RTL到GDSII的设计流程，并证明了其性能优越性。

    

    arXiv:2308.10204v2 公告类型：替换-交叉摘要：集成一系列复杂的电子设计自动化（EDA）工具以增强互操作性是电路设计者关注的重要问题。大型语言模型（LLMs）的最新进展展示了它们在自然语言处理和理解方面的卓越能力，提供了一种新颖的与EDA工具接口的方法。本研究论文介绍了ChatEDA，一个由大型语言模型AutoMage赋能的EDA自主代理，结合作为执行器的EDA工具。ChatEDA通过有效管理任务计划、脚本生成和任务执行，简化了从寄存器传输级（RTL）到图形数据系统第二版（GDSII）的设计流程。通过全面的实验评估，ChatEDA已经证明了其处理各种需求的能力，我们经过精心调优的AutoMage模型在性能上表现出优越性，相较于GPT-4和其他类似的模型。

    arXiv:2308.10204v2 Announce Type: replace-cross  Abstract: The integration of a complex set of Electronic Design Automation (EDA) tools to enhance interoperability is a critical concern for circuit designers. Recent advancements in large language models (LLMs) have showcased their exceptional capabilities in natural language processing and comprehension, offering a novel approach to interfacing with EDA tools. This research paper introduces ChatEDA, an autonomous agent for EDA empowered by a large language model, AutoMage, complemented by EDA tools serving as executors. ChatEDA streamlines the design flow from the Register-Transfer Level (RTL) to the Graphic Data System Version II (GDSII) by effectively managing task planning, script generation, and task execution. Through comprehensive experimental evaluations, ChatEDA has demonstrated its proficiency in handling diverse requirements, and our fine-tuned AutoMage model has exhibited superior performance compared to GPT-4 and other simi
    
[^24]: 使用Sum-Product Networks生成可能的反事实推理

    Generating Likely Counterfactuals Using Sum-Product Networks. (arXiv:2401.14086v1 [cs.AI])

    [http://arxiv.org/abs/2401.14086](http://arxiv.org/abs/2401.14086)

    由于用户需求和最近的法规要求，需要对AI系统所做出的决策进行解释。本论文提出了一种使用Sum-Product Networks模拟寻找高可能性反事实推理的系统，该系统能够提供满足多个常见要求的最佳解释。

    

    由于用户需求和最近的法规（GDPR、AI法案），需要解释AI系统所做出的决策。这些决策往往只能在事后解释，反事实推理成为常见的解释方式。什么构成了最佳的反事实解释必须考虑多个方面，其中“样本距离”是最常见的。我们认为，这一要求经常会导致不太可能且因此价值有限的解释。在这里，我们提出了一个能够提供高可能性解释的系统。我们展示了使用混合整数优化（MIO）模拟寻找满足反事实推理的许多常见要求的最有可能解释。在此过程中，我们提出了Sum-Product Network（SPN）的MIO表达，并使用SPN估计反事实的可能性，这对独立的兴趣也有用。与生成反事实解释的几种方法进行数值比较。

    Due to user demand and recent regulation (GDPR, AI Act), decisions made by AI systems need to be explained. These decisions are often explainable only post hoc, where counterfactual explanations are popular. The question of what constitutes the best counterfactual explanation must consider multiple aspects, where "distance from the sample" is the most common. We argue that this requirement frequently leads to explanations that are unlikely and, therefore, of limited value. Here, we present a system that provides high-likelihood explanations. We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using mixed-integer optimization (MIO). In the process, we propose an MIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate the likelihood of a counterfactual, which can be of independent interest. A numerical comparison against several methods for generating counterfactual explanations is pr
    
[^25]: RoTBench: 评估大型语言模型在工具学习中的鲁棒性的多级基准

    RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning. (arXiv:2401.08326v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.08326](http://arxiv.org/abs/2401.08326)

    RoTBench是一个多级基准，用于评估大型语言模型在工具学习中的鲁棒性。研究发现，LLMs在真实世界的噪声下表现出的稳定性需得到提高。

    

    工具学习作为大型语言模型（LLMs）与物理世界之间互动的重要手段，引起了广泛的兴趣。当前的研究主要强调LLMs在结构良好的环境中利用工具的能力，但忽视了它们在面对真实世界中不可避免的噪声时的稳定性。为了弥合这一差距，我们引入了RoTBench，这是一个用于评估LLMs在工具学习中鲁棒性的多级基准。具体而言，我们建立了五个外部环境，每个环境都具有不同级别的噪声（即清洁、轻微、中等、重度和联合），对模型在工具选择、参数识别和内容填充三个关键阶段的抗干扰能力进行了深入分析。六个广泛使用的模型的实验表明，提高LLMs在工具学习中的鲁棒性迫在眉睫。例如，当没有实质性的噪声存在时，GPT-4的性能甚至从80.00下降到58.10。

    Tool learning has generated widespread interest as a vital means of interaction between Large Language Models (LLMs) and the physical world. Current research predominantly emphasizes LLMs' capacity to utilize tools in well-structured environments while overlooking their stability when confronted with the inevitable noise of the real world. To bridge this gap, we introduce RoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool learning. Specifically, we establish five external environments, each featuring varying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union), providing an in-depth analysis of the model's resilience across three critical phases: tool selection, parameter identification, and content filling. Experiments involving six widely-used models underscore the urgent necessity for enhancing the robustness of LLMs in tool learning. For instance, the performance of GPT-4 even drops significantly from 80.00 to 58.10 when there is no substanti
    
[^26]: 通过森林修剪提高随机森林的准确性和可解释性

    Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])

    [http://arxiv.org/abs/2401.05535](http://arxiv.org/abs/2401.05535)

    通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。

    

    接近几十年的发展之后，随机森林仍然在各种学习问题中提供最先进的准确性，在这方面超越了决策树甚至神经网络等替代机器学习算法。然而，作为一种集成方法，随机森林在解释性方面往往比决策树表现不佳。在本研究中，我们提出了一种事后方法，旨在兼顾随机森林的准确性和决策树的可解释性。为此，我们提出了两种森林修剪方法，以在给定的随机森林内找到最佳子森林，然后在适用的情况下将选定的树合并为一棵。我们的第一种方法依赖于约束穷举搜索，而第二种方法基于LASSO方法的改进。在合成和真实世界数据集上进行的大量实验证明，在大多数情景下，这两种方法中至少有一种能够显著提高随机森林的准确性和可解释性。

    Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
    
[^27]: 一种用于小缺陷检测的增量统一框架

    An Incremental Unified Framework for Small Defect Inspection. (arXiv:2312.08917v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.08917](http://arxiv.org/abs/2312.08917)

    我们提出了一种增量统一框架（IUF），用于解决工业制造中的小缺陷检测问题。通过引入对象感知自注意力（OASA）和语义压缩损失（SCL），我们的方法可以在不断整合新物体时减少特征冲突问题，并展现出卓越的性能。

    

    在工业制造中，基于人工智能的缺陷检测至关重要。然而，许多方法针对特定的流水线，在面对各种产品组合和不断变化的流程时往往面临特征冲突问题。为解决这个问题，我们提出了增量统一框架（IUF），可以在不断整合新物体时减少特征冲突问题，这在面临物体增量学习场景中具有优势。我们使用最先进的transformer引入了对象感知自注意力（OASA）来划分明确的语义边界。集成了语义压缩损失（SCL）来优化非主要语义空间，增强了网络对新物体的适应性。此外，在权重更新时，我们优先保留已建立物体的特征。通过在图像和像素级缺陷检测方面展示出卓越性能，我们的方法实现了最先进的性能，对于动态和可扩展的工业检测至关重要。

    Artificial Intelligence (AI)-driven defect inspection is pivotal in industrial manufacturing. Yet, many methods, tailored to specific pipelines, grapple with diverse product portfolios and evolving processes. Addressing this, we present the Incremental Unified Framework (IUF), which can reduce the feature conflict problem when continuously integrating new objects in the pipeline, making it advantageous in object-incremental learning scenarios. Employing a state-of-the-art transformer, we introduce Object-Aware Self-Attention (OASA) to delineate distinct semantic boundaries. Semantic Compression Loss (SCL) is integrated to optimize non-primary semantic space, enhancing network adaptability for novel objects. Additionally, we prioritize retaining the features of established objects during weight updates. Demonstrating prowess in both image and pixel-level defect inspection, our approach achieves state-of-the-art performance, proving indispensable for dynamic and scalable industrial inspe
    
[^28]: Herd：通过智能组合器使用多个较小的LLM来与专有的大型LLM达到相同的性能匹配

    Herd: Using multiple, smaller LLMs to match the performances of proprietary, large LLMs via an intelligent composer. (arXiv:2310.19902v1 [cs.AI])

    [http://arxiv.org/abs/2310.19902](http://arxiv.org/abs/2310.19902)

    使用智能组合器，一群开源模型可以达到或超过专有模型的性能。

    

    目前存在超过一千个多功能的LLM，可以执行实际任务，包括问答、文本摘要、内容生成等。然而，免费模型的可访问性、规模和可靠性限制了它们在日常使用中的广泛应用。为了解决访问和规模的问题，像HuggingFace这样的组织已经创建了模型仓库，用户可以上传已经过训练的模型权重和量化版本，以及描述训练过程的模型卡片。尽管一些模型报告了常用基准测试的性能，但并非所有模型都如此，并且在性能与模型部署成本之间进行权衡的真实世界影响并不清楚。在这里，我们展示了开源模型的群可以通过智能路由器达到或超过专有模型的性能。我们证明了一个开源模型的群能够达到ChatGPT的准确性。

    Currently, over a thousand LLMs exist that are multi-purpose and are capable of performing real world tasks, including Q&A, text summarization, content generation, etc. However, accessibility, scale and reliability of free models prevents them from being widely deployed in everyday use cases. To address the first two issues of access and scale, organisations such as HuggingFace have created model repositories where users have uploaded model weights and quantized versions of models trained using different paradigms, as well as model cards describing their training process. While some models report performance on commonly used benchmarks, not all do, and interpreting the real world impact of trading off performance on a benchmark for model deployment cost, is unclear. Here, we show that a herd of open source models can match or exceed the performance of proprietary models via an intelligent router. We show that a Herd of open source models is able to match the accuracy of ChatGPT, despit
    
[^29]: 判别器引导下的自回归扩散模型

    Discriminator Guidance for Autoregressive Diffusion Models. (arXiv:2310.15817v1 [cs.LG])

    [http://arxiv.org/abs/2310.15817](http://arxiv.org/abs/2310.15817)

    本文引入了判别器引导，用于自回归扩散模型的训练，通过使用最优判别器来纠正预训练模型，并提出了一个顺序蒙特卡洛算法来应对使用次优判别器的情况。在生成分子图的任务中，判别器引导有助于提高生成性能。

    

    我们在自回归扩散模型中引入了判别器引导。在连续扩散模型中，使用判别器引导扩散过程的方法已经被使用过，本文中，我们推导了在离散情况下使用判别器和预训练生成模型的方法。首先，我们证明使用最优判别器将纠正预训练模型，并能够从底层数据分布中精确采样。其次，为了应对使用次优判别器的实际情况，我们推导了一个顺序蒙特卡洛算法，该算法在生成过程中迭代地将判别器的预测纳入考虑。我们将这些方法应用于生成分子图的任务，并展示了判别器相较于仅使用预训练模型时的生成性能提升。

    We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discrimiator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.
    
[^30]: LLM在Shell中的应用：生成式蜜罐

    LLM in the Shell: Generative Honeypots. (arXiv:2309.00155v1 [cs.CR])

    [http://arxiv.org/abs/2309.00155](http://arxiv.org/abs/2309.00155)

    本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐，解决了以往蜜罐的重要局限性，并通过实验验证了其高准确率。

    

    蜜罐是网络安全中的重要工具。然而，大多数蜜罐（即使是高交互式的）缺乏足够的真实感来欺骗攻击者。这个限制使得它们很容易被识别，从而影响到它们的有效性。本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐。初步结果表明，LLM能够创建可信且动态的蜜罐，能够解决以往蜜罐的重要局限性，如确定性响应、缺乏适应性等。我们通过与需要判断蜜罐回应是否虚假的攻击者进行实验来评估每个命令的真实性。我们提出的蜜罐，称为shelLM，达到了0.92的准确率。

    Honeypots are essential tools in cybersecurity. However, most of them (even the high-interaction ones) lack the required realism to engage and fool human attackers. This limitation makes them easily discernible, hindering their effectiveness. This work introduces a novel method to create dynamic and realistic software honeypots based on Large Language Models. Preliminary results indicate that LLMs can create credible and dynamic honeypots capable of addressing important limitations of previous honeypots, such as deterministic responses, lack of adaptability, etc. We evaluated the realism of each command by conducting an experiment with human attackers who needed to say if the answer from the honeypot was fake or not. Our proposed honeypot, called shelLM, reached an accuracy rate of 0.92.
    
[^31]: HePCo：用于连续联邦学习的无数据异构提示合并方法

    HePCo: Data-Free Heterogeneous Prompt Consolidation for Continual Federated Learning. (arXiv:2306.09970v1 [cs.CV])

    [http://arxiv.org/abs/2306.09970](http://arxiv.org/abs/2306.09970)

    本文提出了一种名为HePCo的轻量级提示合并算法，解决了在连续联邦学习中的数据异构和遗忘问题，并在不共享或存储任何数据的情况下最小化了通信开销。在真实数据集和合成数据集上实现了最先进的结果，并且保持了数据隐私。

    

    本文研究了连续联邦学习的重要但鲜为人知的问题。在这种情况下，服务器与一组客户端通信，以逐步学习新的概念，同时不共享或存储任何数据。由于来自连续和联邦学习角度的挑战，此问题的复杂性受到了加剧。本文尝试在不需要访问任何存储数据的情况下解决遗忘和异构问题，同时最小化开销。我们通过采用一种基于提示的方法并提出一种名为HePCo的新颖轻量级提示合并算法，实现了此目标。我们的方法在真实数据集和合成数据集上均能取得最先进的结果并保持低通信开销，同时不影响数据隐私。

    In this paper, we focus on the important yet understudied problem of Continual Federated Learning (CFL), where a server communicates with a set of clients to incrementally learn new concepts over time without sharing or storing any data. The complexity of this problem is compounded by challenges from both the Continual and Federated Learning perspectives. Specifically, models trained in a CFL setup suffer from catastrophic forgetting which is exacerbated by data heterogeneity across clients. Existing attempts at this problem tend to impose large overheads on clients and communication channels or require access to stored data which renders them unsuitable for real-world use due to privacy. In this paper, we attempt to tackle forgetting and heterogeneity while minimizing overhead costs and without requiring access to any stored data. We achieve this by leveraging a prompting based approach (such that only prompts and classifier heads have to be communicated) and proposing a novel and lig
    
[^32]: 生物医学自然语言处理中的大型语言模型: 基准、基线和建议

    Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])

    [http://arxiv.org/abs/2305.16326](http://arxiv.org/abs/2305.16326)

    本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。

    

    生物医学文献呈指数级增长，手动筛选和提取知识变得困难。自动从生物医学文献中提取信息的生物医学自然语言处理（BioNLP）技术有助于减轻这种负担。近年来，如GPT-3和GPT-4等大型语言模型（LLMs）因其卓越的性能而受到重视。但是，它们在BioNLP任务中的有效性以及对方法开发和下游用户的影响仍未得到研究。本研究（1）在四个应用程序中在八个BioNLP数据集中建立了GPT-3和GPT-4在零-shot和一-shot设置下的基准表现，包括命名实体识别，关系提取，多标签文档分类和语义相似性和推理；（2）审查了LLMs产生的错误，并将错误分为三种类型：缺失，不一致和不需要的人工内容；（3）提出了使用LLMs的建议。

    Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
    
[^33]: 从野外视频中学习手持物体重建

    Learning Hand-Held Object Reconstruction from In-The-Wild Videos. (arXiv:2305.03036v1 [cs.CV])

    [http://arxiv.org/abs/2305.03036](http://arxiv.org/abs/2305.03036)

    本研究提出了一种从野外视频中自动提取三维监督来扩展手持物体重建模型的学习方法。通过使用手部姿势作为物体姿势的代理和学习数据驱动的三维形状先验知识等方法，有效地解决了未知相机姿势和遮挡等问题，从而通过从单个RGB图像预测物体三维形状的占据网络得到了优秀的结果。

    

    先前的单影像手持物体重建方法依赖于难以在真实世界中规模化收集的直接3D形状监督，因此这些方法在野外环境下面对新颖物体时难以推广。本文从生动的野外原始视频数据中自动提取三维监督，并通过多视角二维监督来扩展手持物体重建模型的学习。这需要应对两个关键挑战：未知的相机姿势和遮挡。对于前者，我们使用手部姿势作为物体姿势的代理。对于后者，我们使用ObMan数据集中合成的物体来学习数据驱动的三维形状先验知识。我们使用这些间接的三维线索来训练占据网络，从单个RGB图像预测物体的三维形状。

    Prior works for reconstructing hand-held objects from a single image rely on direct 3D shape supervision which is challenging to gather in real world at scale. Consequently, these approaches do not generalize well when presented with novel objects in in-the-wild settings. While 3D supervision is a major bottleneck, there is an abundance of in-the-wild raw video data showing hand-object interactions. In this paper, we automatically extract 3D supervision (via multiview 2D supervision) from such raw video data to scale up the learning of models for hand-held object reconstruction. This requires tackling two key challenges: unknown camera pose and occlusion. For the former, we use hand pose (predicted from existing techniques, e.g. FrankMocap) as a proxy for object pose. For the latter, we learn data-driven 3D shape priors using synthetic objects from the ObMan dataset. We use these indirect 3D cues to train occupancy networks that predict the 3D shape of objects from a single RGB image. 
    
[^34]: 多智能体MDP中基于概率代理掉线的无模型学习和最优策略设计

    Model-Free Learning and Optimal Policy Design in Multi-Agent MDPs Under Probabilistic Agent Dropout. (arXiv:2304.12458v1 [eess.SY])

    [http://arxiv.org/abs/2304.12458](http://arxiv.org/abs/2304.12458)

    本文研究了多智能体MDP中基于概率代理掉线的情况，并提出了一种无模型算法，能够消除掉线情况需要枚举计算的限制，从而实现计算后掉线系统的最优策略设计。

    

    本文研究了一个多智能体马尔可夫决策过程（MDP），该过程可以经历代理掉线，并基于对于策略的控制和预代理过程的采样来计算后掉线系统的策略。控制器的目标是寻找一个最优策略，使得在已知代理掉出概率的先验知识的情况下，期望系统的价值最大化。对于任何特定的掉线情况下的最优策略是这个问题的一个特例。对于具有特定转换独立性和奖励可分性结构的MDPs，我们假设从系统中移除代理组成了一个新的MDP，由剩余代理组成具有新状态和动作空间的MDP，转换动态消除已删除的代理，奖励与已删除的代理无关。首先我们展示了在这些假设下，对于预掉出系统期望值可以通过一个单一的MDP来表示；这个“鲁棒MDP”能够消除在计算最优策略时要评估所有$2^N$种代理掉线情况的需要。然后我们提出了一个无模型算法，该算法使用蒙特卡罗采样和重要性采样来学习鲁棒MDP，从而能够计算后掉线系统的最优策略。仿真结果展示了该方法的优点。

    This work studies a multi-agent Markov decision process (MDP) that can undergo agent dropout and the computation of policies for the post-dropout system based on control and sampling of the pre-dropout system. The controller's objective is to find an optimal policy that maximizes the value of the expected system given a priori knowledge of the agents' dropout probabilities. Finding an optimal policy for any specific dropout realization is a special case of this problem. For MDPs with a certain transition independence and reward separability structure, we assume that removing agents from the system forms a new MDP comprised of the remaining agents with new state and action spaces, transition dynamics that marginalize the removed agents, and rewards that are independent of the removed agents. We first show that under these assumptions, the value of the expected post-dropout system can be represented by a single MDP; this "robust MDP" eliminates the need to evaluate all $2^N$ realizations
    
[^35]: 图学习及其应用：一篇全面的综述

    Graph Learning and Its Applications: A Holistic Survey. (arXiv:2212.08966v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.08966](http://arxiv.org/abs/2212.08966)

    本文全面综述了图学习的发展历程和应用场景，重点介绍了表示学习在文本、图像、化学和生物等领域中的显著性能，同时指出了对以前有价值的工作进行调查的需求。

    This paper provides a comprehensive survey of the development and application scenarios of graph learning, with a focus on the remarkable performance of representation learning in various fields such as text, image, chemistry, and biology. It also points out the need to investigate previous valuable works.

    图学习是一种广泛应用的领域，旨在学习节点之间的复杂关系和图的拓扑结构。这些关系使得图与传统的表格数据相比具有独特性，因为节点依赖于非欧几里得空间，并包含丰富的信息可供利用。随着表示学习的出现，图学习在文本、图像、化学和生物等各种场景中取得了显著的性能。由于其广泛的应用前景，图学习吸引了学术界的大量关注。尽管已经有许多工作提出了解决图学习中不同问题的方法，但需要对以前有价值的工作进行调查。虽然一些研究人员已经意识到了这一现象，并在图学习方面完成了令人印象深刻的调查，但他们未能以更连贯的方式连接相关的目标、方法和应用。

    Graph learning is a prevalent domain that endeavors to learn the intricate relationships among nodes and the topological structure of graphs. These relationships endow graphs with uniqueness compared to conventional tabular data, as nodes rely on non-Euclidean space and encompass rich information to exploit. Over the years, graph learning has transcended from graph theory to graph data mining. With the advent of representation learning, it has attained remarkable performance in diverse scenarios, including text, image, chemistry, and biology. Owing to its extensive application prospects, graph learning attracts copious attention from the academic community. Despite numerous works proposed to tackle different problems in graph learning, there is a demand to survey previous valuable works. While some researchers have perceived this phenomenon and accomplished impressive surveys on graph learning, they failed to connect related objectives, methods, and applications in a more coherent way.
    
[^36]: 相对过度泛化的课程学习

    Curriculum Learning for Relative Overgeneralization. (arXiv:2212.02733v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.02733](http://arxiv.org/abs/2212.02733)

    本论文提出了一种名为相对过度泛化的课程学习（CURO）的新算法来解决多智能体强化学习中存在的相对过度泛化 (RO) 问题，该方法在解决展示强RO的合作任务方面具有很好的表现。

    

    在多智能体强化学习 (MARL) 中，许多流行方法如 VDN 和 QMIX，都容易受到相对过度泛化 (RO) 这一关键性的多智能体病理的影响。当合作任务中最佳联合行动的效用低于次优联合行动时，就会出现RO。RO可能导致智能体陷入局部最优解或无法解决需要智能体之间在给定时间步长内进行大量协调的合作任务。最近的基于价值的MARL算法，如QPLEX和WQMIX可以在一定程度上克服RO。然而，我们的实验结果表明，它们仍然无法解决展示强RO的合作任务。在这项工作中，我们提出了一种称为相对过度泛化的课程学习（CURO）的新方法，以更好地克服RO。在CURO中，我们首先微调目标任务的奖励函数以生成适合当前能力的源任务来解决展示强RO的目标任务。

    In multi-agent reinforcement learning (MARL), many popular methods, such as VDN and QMIX, are susceptible to a critical multi-agent pathology known as relative overgeneralization (RO), which arises when the optimal joint action's utility falls below that of a sub-optimal joint action in cooperative tasks. RO can cause the agents to get stuck into local optima or fail to solve cooperative tasks that require significant coordination between agents within a given timestep. Recent value-based MARL algorithms such as QPLEX and WQMIX can overcome RO to some extent. However, our experimental results show that they can still fail to solve cooperative tasks that exhibit strong RO. In this work, we propose a novel approach called curriculum learning for relative overgeneralization (CURO) to better overcome RO. To solve a target task that exhibits strong RO, in CURO, we first fine-tune the reward function of the target task to generate source tasks that are tailored to the current ability of the 
    
[^37]: GraphMLP：一种用于3D人体姿态估计的图形MLP式架构

    GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation. (arXiv:2206.06420v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.06420](http://arxiv.org/abs/2206.06420)

    提出了一种名为GraphMLP的图形增强的MLP式架构，它将图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。在此基础上，还将GraphMLP灵活高效地扩展到视频领域，并成功地进行了时间动力学的建模。

    

    现代多层感知器（MLP）模型已经展现出在没有自我注意力的情况下学习视觉表示方面的竞争性结果，然而，现有的MLP模型并不擅长捕捉局部细节，也缺乏有关人体构型的先验知识，这限制了它们用于骨骼表示学习的建模能力。为了解决这些问题，我们提出了一种简单而有效的图形增强的MLP式架构，称为GraphMLP，它结合了MLP和图形卷积网络（GCN）在全局-局部-图形统一架构中用于3D人体姿态估计。GraphMLP将人体的图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。此外，我们提出了将GraphMLP灵活高效地扩展到视频领域，并展示了可以以可忽略的计算代价来有效地建模复杂的时间动力学。

    Modern multi-layer perceptron (MLP) models have shown competitive results in learning visual representations without self-attention. However, existing MLP models are not good at capturing local details and lack prior knowledge of human body configurations, which limits their modeling power for skeletal representation learning. To address these issues, we propose a simple yet effective graph-reinforced MLP-Like architecture, named GraphMLP, that combines MLPs and graph convolutional networks (GCNs) in a global-local-graphical unified architecture for 3D human pose estimation. GraphMLP incorporates the graph structure of human bodies into an MLP model to meet the domain-specific demand of the 3D human pose, while allowing for both local and global spatial interactions. Furthermore, we propose to flexibly and efficiently extend the GraphMLP to the video domain and show that complex temporal dynamics can be effectively modeled in a simple way with negligible computational cost gains in the
    

