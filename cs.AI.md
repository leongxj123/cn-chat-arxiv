# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack](https://arxiv.org/abs/2404.01833) | 提出了一种名为Crescendo的新型多回合越狱攻击方法，通过看似良性的对话方式逐渐升级与模型的交互，成功突破了大型语言模型的限制。 |
| [^2] | [ChatDBG: An AI-Powered Debugging Assistant](https://arxiv.org/abs/2403.16354) | ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。 |
| [^3] | [NTK-Guided Few-Shot Class Incremental Learning](https://arxiv.org/abs/2403.12486) | 本文通过NTK对FSCIL模型的指导，致力于在增量学习中实现卓越泛化，通过优化NTK收敛和降低泛化误差来确保最佳性能。 |
| [^4] | [Does AI help humans make better decisions? A methodological framework for experimental evaluation](https://arxiv.org/abs/2403.12108) | 引入一种新的实验框架用于评估人类是否通过使用AI可以做出更好的决策，在单盲实验设计中比较了三种决策系统的表现 |
| [^5] | [Advantage-Aware Policy Optimization for Offline Reinforcement Learning](https://arxiv.org/abs/2403.07262) | 介绍了一种新的适应优势的策略优化（A2PO）方法，用于离线学习，能够解决多行为策略收集的约束冲突问题，有效避免过拟合问题。 |
| [^6] | [OpenGraph: Towards Open Graph Foundation Models](https://arxiv.org/abs/2403.01121) | 该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。 |
| [^7] | [When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection](https://arxiv.org/abs/2402.13276) | 本文提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。 |
| [^8] | [Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model](https://arxiv.org/abs/2402.10642) | 通过将生成目标重定向到小波域，我们成功将语音DDPMs的训练和推理速度提高了一倍。 |
| [^9] | [The Matrix: A Bayesian learning model for LLMs](https://arxiv.org/abs/2402.03175) | 本文介绍了一个贝叶斯学习模型，用于理解大型语言模型（LLMs）的行为。研究探索了LLMs的优化指标，并开发了一个新的基于预测下一个标记的模型。实验结果表明，LLMs的行为与贝叶斯学习一致，为上下文学习提供了新的见解。 |
| [^10] | [HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents QA](https://arxiv.org/abs/2402.01767) | HiQA是一个先进的多文档问答框架，使用分层的上下文增强和多路径检索机制，解决了大规模文档问答中的检索准确性问题，并在多文档环境中展示了最先进的性能。 |
| [^11] | [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://arxiv.org/abs/2401.09340) | 本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。 |
| [^12] | [Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction.](http://arxiv.org/abs/2401.11798) | 本论文研究了在交通预测中应用空间-时间图卷积网络和知识蒸馏的方法。知识蒸馏的思想能够实现在减少参数和保持准确性的同时提高执行效率。通过引入教师网络的空间-时间相关性，我们的方法能够使学生网络学习到复杂的交通模式。 |
| [^13] | [Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks.](http://arxiv.org/abs/2401.02731) | 本文提出了一种参数高效稀疏制作的方法，它使用专家混合式架构将密集模型转换为稀疏模型，以实现在模型容量有限的情况下进行指令调整和泛化能力增强。 |
| [^14] | [From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities.](http://arxiv.org/abs/2311.00308) | 本论文调查了视觉问答(VQA)领域的现有研究，包括传统VQA架构和现代基于视觉语言预训练(VLP)的方法。同时还分析了VQA数据集和方法在历史上的发展，揭示了VLP在VQA中的挑战与机会，为进一步研究提供了指导。 |
| [^15] | [C-Pack: Packaged Resources To Advance General Chinese Embedding.](http://arxiv.org/abs/2309.07597) | C-Pack是一套推进普通汉语嵌入领域的资源，包括全面汉语文本嵌入基准、大规模文本嵌入数据集和涵盖多个尺寸的嵌入模型系列。该资源集在C-MTEB基准上实现了最高+10%的表现，并通过整合和优化一套训练方法进一步提升了效果。此外，C-Pack还发布了英语文本嵌入数据和模型，实现了最先进的性能。该资源集可公开获取。 |
| [^16] | [Representation Learning for Sequential Volumetric Design Tasks.](http://arxiv.org/abs/2309.02583) | 本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。 |
| [^17] | [GUARD: A Safe Reinforcement Learning Benchmark.](http://arxiv.org/abs/2305.13681) | GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。 |

# 详细

[^1]: 伟大，现在写一篇关于此的文章：Crescendo多回合LLM越狱攻击

    Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack

    [https://arxiv.org/abs/2404.01833](https://arxiv.org/abs/2404.01833)

    提出了一种名为Crescendo的新型多回合越狱攻击方法，通过看似良性的对话方式逐渐升级与模型的交互，成功突破了大型语言模型的限制。

    

    大型语言模型（LLMs）的流行程度大幅上升，并且越来越多地被应用于多个领域。这些LLMs在设计上避免涉及非法或不道德的话题，以避免对负责任的AI造成伤害。然而，最近出现了一系列攻击，被称为“越狱”，旨在突破这种对齐。直观地说，越狱攻击旨在缩小模型能做的与愿意做的之间的差距。本文介绍了一种名为Crescendo的新型越狱攻击。与现有的越狱方法不同，Crescendo是一种多回合越狱，以一种看似良性的方式与模型进行交互。它从有关手头任务的一般提示或问题开始，然后逐渐升级对话，引用模型的回复，逐渐导致成功越狱。我们在包括ChatGPT、Gemini Pr在内的各种公共系统上评估了Crescendo。

    arXiv:2404.01833v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications. These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms. However, a recent line of attacks, known as "jailbreaks", seek to overcome this alignment. Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do. In this paper, we introduce a novel jailbreak attack called Crescendo. Unlike existing jailbreak methods, Crescendo is a multi-turn jailbreak that interacts with the model in a seemingly benign manner. It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies, progressively leading to a successful jailbreak. We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pr
    
[^2]: ChatDBG: 一种基于人工智能的调试助手

    ChatDBG: An AI-Powered Debugging Assistant

    [https://arxiv.org/abs/2403.16354](https://arxiv.org/abs/2403.16354)

    ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。

    

    本文介绍了ChatDBG，这是第一个基于人工智能的调试助手。ChatDBG集成了大型语言模型(LLMs)，显著增强了传统调试器的功能和用户友好性。ChatDBG允许程序员与调试器进行协作对话，使他们能够提出关于程序状态的复杂问题，对崩溃或断言失败进行根本原因分析，并探索诸如“为什么x为空？”之类的开放性查询。为了处理这些查询，ChatDBG授予LLM自主权，通过发出命令来浏览堆栈和检查程序状态进行调试；然后报告其发现并将控制权交还给程序员。我们的ChatDBG原型与标准调试器集成，包括LLDB、GDB和WinDBG用于本地代码以及用于Python的Pdb。我们在各种代码集合上进行了评估，包括具有已知错误的C/C++代码和一套Python代码。

    arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
    
[^3]: 基于NTK引导的少样本类增量学习

    NTK-Guided Few-Shot Class Incremental Learning

    [https://arxiv.org/abs/2403.12486](https://arxiv.org/abs/2403.12486)

    本文通过NTK对FSCIL模型的指导，致力于在增量学习中实现卓越泛化，通过优化NTK收敛和降低泛化误差来确保最佳性能。

    

    尽管反遗忘FSCIL学习者在增量会话中表现出色，但他们往往更注重减少知识流失，而忽视了模型潜在获取知识的能力。本文通过神经切向核（NTK）的视角深入探讨了FSCIL模型泛化的基础。我们主要的设计重点在于确保最优NTK收敛和NTK相关的泛化误差，作为卓越泛化的理论基础。为了达到全局最优的NTK收敛，我们采用了一个植根于数学原理的元学习机制，指导扩展网络内的优化过程。此外，为了减少NTK相关的泛化误差，我们从基础层面开始，优化构成其泛化损失的相关因素。具体地，我们通过在基础会话上启动自监督预训练来塑造初始ne

    arXiv:2403.12486v1 Announce Type: cross  Abstract: While anti-amnesia FSCIL learners often excel in incremental sessions, they tend to prioritize mitigating knowledge attrition over harnessing the model's potential for knowledge acquisition. In this paper, we delve into the foundations of model generalization in FSCIL through the lens of the Neural Tangent Kernel (NTK). Our primary design focus revolves around ensuring optimal NTK convergence and NTK-related generalization error, serving as the theoretical bedrock for exceptional generalization. To attain globally optimal NTK convergence, we employ a meta-learning mechanism grounded in mathematical principles to guide the optimization process within an expanded network. Furthermore, to reduce the NTK-related generalization error, we commence from the foundational level, optimizing the relevant factors constituting its generalization loss. Specifically, we initiate self-supervised pre-training on the base session to shape the initial ne
    
[^4]: AI是否有助于人类做出更好的决策？一种用于实验评估的方法论框架

    Does AI help humans make better decisions? A methodological framework for experimental evaluation

    [https://arxiv.org/abs/2403.12108](https://arxiv.org/abs/2403.12108)

    引入一种新的实验框架用于评估人类是否通过使用AI可以做出更好的决策，在单盲实验设计中比较了三种决策系统的表现

    

    基于数据驱动算法的人工智能（AI）在当今社会变得无处不在。然而，在许多情况下，尤其是当利益高昂时，人类仍然作出最终决策。因此，关键问题是AI是否有助于人类比单独的人类或单独的AI做出更好的决策。我们引入了一种新的方法论框架，用于实验性地回答这个问题，而不需要额外的假设。我们使用基于基准潜在结果的标准分类指标测量决策者做出正确决策的能力。我们考虑了一个单盲实验设计，在这个设计中，提供AI生成的建议在不同案例中被随机分配给最终决策的人类。在这种实验设计下，我们展示了如何比较三种替代决策系统的性能--仅人类、人类与AI、仅AI。

    arXiv:2403.12108v1 Announce Type: new  Abstract: The use of Artificial Intelligence (AI) based on data-driven algorithms has become ubiquitous in today's society. Yet, in many cases and especially when stakes are high, humans still make final decisions. The critical question, therefore, is whether AI helps humans make better decisions as compared to a human alone or AI an alone. We introduce a new methodological framework that can be used to answer experimentally this question with no additional assumptions. We measure a decision maker's ability to make correct decisions using standard classification metrics based on the baseline potential outcome. We consider a single-blinded experimental design, in which the provision of AI-generated recommendations is randomized across cases with a human making final decisions. Under this experimental design, we show how to compare the performance of three alternative decision-making systems--human-alone, human-with-AI, and AI-alone. We apply the pr
    
[^5]: 适应优势的策略优化用于离线强化学习

    Advantage-Aware Policy Optimization for Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.07262](https://arxiv.org/abs/2403.07262)

    介绍了一种新的适应优势的策略优化（A2PO）方法，用于离线学习，能够解决多行为策略收集的约束冲突问题，有效避免过拟合问题。

    

    离线强化学习致力于利用离线数据集来制定有效的智能体策略，而无需在线交互，通过在行为策略的支持下施加适当的保守约束来解决分布外问题。本文引入了一种新的适应优势的策略优化（A2PO）方法，以明确构建针对混合质量数据集的离线学习优势感知策略约束。

    arXiv:2403.07262v1 Announce Type: cross  Abstract: Offline Reinforcement Learning (RL) endeavors to leverage offline datasets to craft effective agent policy without online interaction, which imposes proper conservative constraints with the support of behavior policies to tackle the Out-Of-Distribution (OOD) problem. However, existing works often suffer from the constraint conflict issue when offline datasets are collected from multiple behavior policies, i.e., different behavior policies may exhibit inconsistent actions with distinct returns across the state space. To remedy this issue, recent Advantage-Weighted (AW) methods prioritize samples with high advantage values for agent training while inevitably leading to overfitting on these samples. In this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO) method to explicitly construct advantage-aware policy constraints for offline learning under mixed-quality datasets. Specifically, A2PO employs a Conditional Variat
    
[^6]: OpenGraph: 迈向开放图基础模型

    OpenGraph: Towards Open Graph Foundation Models

    [https://arxiv.org/abs/2403.01121](https://arxiv.org/abs/2403.01121)

    该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。

    

    arXiv:2403.01121v1 公告类型: 跨交互   摘要: 图学习已成为解释和利用各领域的关系数据的不可或缺部分，从推荐系统到社交网络分析。在这种背景下，各种GNN已经成为编码图的结构信息的有希望的方法论，通过有效地捕捉图的潜在结构，这些GNN已经展示出在增强图学习任务性能方面的巨大潜力，例如链接预测和节点分类。然而，尽管取得了成功，一个显著的挑战仍然存在: 这些先进方法通常在将显著不同于训练实例的未见图数据泛化时遇到困难。在这项工作中，我们的目标是通过开发一个通用图基础模型来推进图学习范式。该模型旨在理解多样图数据中存在的复杂拓扑模式，使其在零-shot情况下表现出色。

    arXiv:2403.01121v1 Announce Type: cross  Abstract: Graph learning has become indispensable for interpreting and harnessing relational data in diverse fields, ranging from recommendation systems to social network analysis. In this context, a variety of GNNs have emerged as promising methodologies for encoding the structural information of graphs. By effectively capturing the graph's underlying structure, these GNNs have shown great potential in enhancing performance in graph learning tasks, such as link prediction and node classification. However, despite their successes, a significant challenge persists: these advanced methods often face difficulties in generalizing to unseen graph data that significantly differs from the training instances. In this work, our aim is to advance the graph learning paradigm by developing a general graph foundation model. This model is designed to understand the complex topological patterns present in diverse graph data, enabling it to excel in zero-shot g
    
[^7]: 当LLMs遇到声学标志：一种高效地将语音集成到大型语言模型中用于抑郁检测的方法

    When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection

    [https://arxiv.org/abs/2402.13276](https://arxiv.org/abs/2402.13276)

    本文提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。

    

    抑郁是全球心理健康中的一个严重关切，促使进行大量研究来探讨基于AI的检测方法。在各种AI技术中，大型语言模型（LLMs）因其在心理卫生应用中的多功能性而脱颖而出。然而，它们的主要局限性在于它们仅依赖于文本输入，这限制了它们的整体功能。此外，LLMs在识别和分析抑郁状态方面的利用仍相对未开发。在本文中，我们提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。我们研究了一种通过利用声学标志将语音信号集成到LLMs中的高效抑郁检测方法。通过整合声学标志，这些标志是特定于口语单词发音的，我们的方法为文本转录添加了关键维度。

    arXiv:2402.13276v1 Announce Type: cross  Abstract: Depression is a critical concern in global mental health, prompting extensive research into AI-based detection methods. Among various AI technologies, Large Language Models (LLMs) stand out for their versatility in mental healthcare applications. However, their primary limitation arises from their exclusive dependence on textual input, which constrains their overall capabilities. Furthermore, the utilization of LLMs in identifying and analyzing depressive states is still relatively untapped. In this paper, we present an innovative approach to integrating acoustic speech information into the LLMs framework for multimodal depression detection. We investigate an efficient method for depression detection by integrating speech signals into LLMs utilizing Acoustic Landmarks. By incorporating acoustic landmarks, which are specific to the pronunciation of spoken words, our method adds critical dimensions to text transcripts. This integration a
    
[^8]: 在小波域说话：加速语音扩散模型的简单高效方法

    Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model

    [https://arxiv.org/abs/2402.10642](https://arxiv.org/abs/2402.10642)

    通过将生成目标重定向到小波域，我们成功将语音DDPMs的训练和推理速度提高了一倍。

    

    最近，去噪扩散概率模型（DDPMs）在各种生成任务中表现出色。然而，在语音合成领域，尽管DDPMs表现出色，但其长时间训练和大量推理成本阻碍了实际部署。现有方法主要集中在增强推理速度，而加速训练的方法通常需要对模型进行复杂修改，从而损害其通用性。为了解决上述挑战，我们提出了一个问题：通过修改语音信号本身，是否可能提高DDPMs的训练/推理速度和性能？在本文中，我们通过简单地将生成目标重定向到小波域，将语音DDPMs的训练和推理速度提高了一倍。该方法不仅取得了…

    arXiv:2402.10642v1 Announce Type: cross  Abstract: Recently, Denoising Diffusion Probabilistic Models (DDPMs) have attained leading performances across a diverse range of generative tasks. However, in the field of speech synthesis, although DDPMs exhibit impressive performance, their long training duration and substantial inference costs hinder practical deployment. Existing approaches primarily focus on enhancing inference speed, while approaches to accelerate training a key factor in the costs associated with adding or customizing voices often necessitate complex modifications to the model, compromising their universal applicability. To address the aforementioned challenges, we propose an inquiry: is it possible to enhance the training/inference speed and performance of DDPMs by modifying the speech signal itself? In this paper, we double the training and inference speed of Speech DDPMs by simply redirecting the generative target to the wavelet domain. This method not only achieves c
    
[^9]: The Matrix: 一个用于LLMs的贝叶斯学习模型

    The Matrix: A Bayesian learning model for LLMs

    [https://arxiv.org/abs/2402.03175](https://arxiv.org/abs/2402.03175)

    本文介绍了一个贝叶斯学习模型，用于理解大型语言模型（LLMs）的行为。研究探索了LLMs的优化指标，并开发了一个新的基于预测下一个标记的模型。实验结果表明，LLMs的行为与贝叶斯学习一致，为上下文学习提供了新的见解。

    

    本文介绍了一个用于理解大型语言模型（LLMs）行为的贝叶斯学习模型。我们探索了基于预测下一个标记的LLM的优化指标，并开发了一个以此原则为基础的新型模型。我们的方法涉及构建一个由先验和多项式转移概率矩阵表示的理想生成文本模型，并研究LLMs如何逼近该矩阵。我们讨论了嵌入和多项式分布之间的映射的连续性，并提出了Dirichlet逼近定理来逼近任何先验。此外，我们演示了LLMs的文本生成如何与贝叶斯学习原理一致，并深入探讨了其在上下文学习中的影响，具体解释了为什么在更大的模型中出现了上下文学习，其中提示被视为需要更新的样本。我们的发现表明，LLMs的行为与贝叶斯学习一致，提供了新的见解。

    In this paper, we introduce a Bayesian learning model to understand the behavior of Large Language Models (LLMs). We explore the optimization metric of LLMs, which is based on predicting the next token, and develop a novel model grounded in this principle. Our approach involves constructing an ideal generative text model represented by a multinomial transition probability matrix with a prior, and we examine how LLMs approximate this matrix. We discuss the continuity of the mapping between embeddings and multinomial distributions, and present the Dirichlet approximation theorem to approximate any prior. Additionally, we demonstrate how text generation by LLMs aligns with Bayesian learning principles and delve into the implications for in-context learning, specifically explaining why in-context learning emerges in larger models where prompts are considered as samples to be updated. Our findings indicate that the behavior of LLMs is consistent with Bayesian Learning, offering new insights
    
[^10]: HiQA：一种用于大规模文档问答的分层上下文增强的RAG模型

    HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents QA

    [https://arxiv.org/abs/2402.01767](https://arxiv.org/abs/2402.01767)

    HiQA是一个先进的多文档问答框架，使用分层的上下文增强和多路径检索机制，解决了大规模文档问答中的检索准确性问题，并在多文档环境中展示了最先进的性能。

    

    随着利用外部工具的语言模型代理迅速发展，使用补充文档和检索增强生成（RAG）方法的问答（QA）方法学取得了重要进展。这种进步提高了语言模型的回答质量，并减轻了幻觉的出现。然而，当面临大量无法区分的文档时，这些方法在检索准确性方面表现有限，给实际应用带来了显著挑战。针对这些新兴的挑战，我们提出了HiQA，这是一个先进的多文档问答（MDQA）框架，将级联的元数据整合到内容中，同时具备多路径检索机制。我们还发布了一个名为MasQA的基准来评估和研究MDQA。最后，HiQA在多文档环境中展示了最先进的性能。

    As language model agents leveraging external tools rapidly evolve, significant progress has been made in question-answering(QA) methodologies utilizing supplementary documents and the Retrieval-Augmented Generation (RAG) approach. This advancement has improved the response quality of language models and alleviates the appearance of hallucination. However, these methods exhibit limited retrieval accuracy when faced with massive indistinguishable documents, presenting notable challenges in their practical application. In response to these emerging challenges, we present HiQA, an advanced framework for multi-document question-answering (MDQA) that integrates cascading metadata into content as well as a multi-route retrieval mechanism. We also release a benchmark called MasQA to evaluate and research in MDQA. Finally, HiQA demonstrates the state-of-the-art performance in multi-document environments.
    
[^11]: SceneVerse：为基于场景的场景理解扩展3D视觉-语言学习

    SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding

    [https://arxiv.org/abs/2401.09340](https://arxiv.org/abs/2401.09340)

    本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。

    

    3D视觉-语言对齐，即将语言与3D物理环境对齐，是发展具身体能力的智能体的基石。与2D领域最近的进展相比，将语言与3D场景对齐面临着几个重要挑战：（i）3D场景固有复杂性，由于多样的物体配置、丰富的属性和错综复杂的关系；（ii）支持基于场景学习的配对3D视觉-语言数据的稀缺性；以及（iii）缺乏从基于场景的3D数据中提炼知识的统一学习框架。在这项工作中，我们旨在通过系统地扩展室内环境中的3D视觉-语言学习，从而解决3D视觉-语言领域中的这三大挑战。我们介绍首个百万规模的3D视觉-语言数据集SceneVerse，包含约68K个3D室内场景，包括250万个视觉语言

    arXiv:2401.09340v2 Announce Type: replace-cross  Abstract: 3D vision-language grounding, which focuses on aligning language with the 3D physical environment, stands as a cornerstone in the development of embodied agents. In comparison to recent advancements in the 2D domain, grounding language in 3D scenes faces several significant challenges: (i) the inherent complexity of 3D scenes due to the diverse object configurations, their rich attributes, and intricate relationships; (ii) the scarcity of paired 3D vision-language data to support grounded learning; and (iii) the absence of a unified learning framework to distill knowledge from grounded 3D data. In this work, we aim to address these three major challenges in 3D vision-language by examining the potential of systematically upscaling 3D vision-language learning in indoor environments. We introduce the first million-scale 3D vision-language dataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising 2.5M vision-langu
    
[^12]: 空间-时间图卷积网络在交通预测上的知识蒸馏

    Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction. (arXiv:2401.11798v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11798](http://arxiv.org/abs/2401.11798)

    本论文研究了在交通预测中应用空间-时间图卷积网络和知识蒸馏的方法。知识蒸馏的思想能够实现在减少参数和保持准确性的同时提高执行效率。通过引入教师网络的空间-时间相关性，我们的方法能够使学生网络学习到复杂的交通模式。

    

    高效实时交通预测对减少交通时间至关重要。为了预测交通状况，我们采用了空间-时间图神经网络（ST-GNN）将实时交通数据建模为时间图。尽管ST-GNN具有强大的能力，但在为实际交通数据进行高效实时预测时经常面临挑战。鉴于实时数据动态性的重要性，我们采用知识蒸馏（KD）作为解决方案，以提高ST-GNN在交通预测中的执行时间。本文介绍了一个成本函数，旨在使用复杂网络（教师）的蒸馏数据来训练具有较少参数的网络（学生），同时保持其准确性接近教师的准确性。我们使用知识蒸馏，将教师网络的空间-时间相关性融入学生网络，使学生能够学习到教师感知的复杂模式。然而，面临一个挑战。

    Efficient real-time traffic prediction is crucial for reducing transportation time. To predict traffic conditions, we employ a spatio-temporal graph neural network (ST-GNN) to model our real-time traffic data as temporal graphs. Despite its capabilities, it often encounters challenges in delivering efficient real-time predictions for real-world traffic data. Recognizing the significance of timely prediction due to the dynamic nature of real-time data, we employ knowledge distillation (KD) as a solution to enhance the execution time of ST-GNNs for traffic prediction. In this paper, We introduce a cost function designed to train a network with fewer parameters (the student) using distilled data from a complex network (the teacher) while maintaining its accuracy close to that of the teacher. We use knowledge distillation, incorporating spatial-temporal correlations from the teacher network to enable the student to learn the complex patterns perceived by the teacher. However, a challenge a
    
[^13]: 参数高效稀疏制作：从密集型到专家混合式用于通用任务的指令调整

    Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks. (arXiv:2401.02731v1 [cs.AI])

    [http://arxiv.org/abs/2401.02731](http://arxiv.org/abs/2401.02731)

    本文提出了一种参数高效稀疏制作的方法，它使用专家混合式架构将密集模型转换为稀疏模型，以实现在模型容量有限的情况下进行指令调整和泛化能力增强。

    

    大型语言模型(LLMs)在通用自然语言处理(NLP)任务中展示出相当的熟练程度。指令调整作为一种成功的范例，增强了LLMs遵循自然语言指令并在各种任务中展现出强大的泛化能力。然而，由于模型容量限制，这些模型在多个任务中经常遇到性能限制。在指令调整阶段扩展模型容量面临着巨大的挑战。为了解决这个问题，我们引入了一种新颖的方法，参数高效稀疏制作(PESC)，它使用专家混合式(MoE)架构将密集模型转换为稀疏模型。PESC将适配器集成到稀疏模型的MoE层中，区分不同的专家而不改变这些层中的个体权重。这种方法显著降低了计算成本和GPU内存需求，通过最小的增加实现了模型容量的扩展。

    Large Language Models (LLMs) have demonstrated considerable proficiency in general natural language processing (NLP) tasks. Instruction tuning, a successful paradigm, enhances the ability of LLMs to follow natural language instructions and exhibit robust generalization across a wide range of tasks. However, these models often encounter performance limitations across multiple tasks due to constrained model capacity. Expanding this capacity during the instruction tuning phase poses significant challenges. To address this issue, we introduce a novel approach, Parameter-Efficient Sparsity Crafting (PESC), which transitions dense models to sparse models using a Mixture of Experts (MoE) architecture. PESC integrates adapters into the MoE layers of sparse models, differentiating experts without altering the individual weights within these layers. This method significantly reduces computational costs and GPU memory requirements, facilitating model capacity expansion through a minimal increase 
    
[^14]: 从图像到语言: 对视觉问答(VQA)方法、挑战和机会进行的关键分析

    From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities. (arXiv:2311.00308v1 [cs.CV])

    [http://arxiv.org/abs/2311.00308](http://arxiv.org/abs/2311.00308)

    本论文调查了视觉问答(VQA)领域的现有研究，包括传统VQA架构和现代基于视觉语言预训练(VLP)的方法。同时还分析了VQA数据集和方法在历史上的发展，揭示了VLP在VQA中的挑战与机会，为进一步研究提供了指导。

    

    视觉问答(VQA)是一个综合计算机视觉(CV)和自然语言处理(NLP)的多模态任务，旨在对任何视觉输入生成答案。VQA的范围已从关注自然图像的数据集扩展到包含合成图像、视频、3D环境和其他视觉输入的数据集。大型预训练网络的出现使早期依赖特征提取和融合方案的VQA方法转向了视觉语言预训练(VLP)技术。然而，目前缺乏包括传统VQA架构和现代基于VLP的方法在内的综合调查。此外，还没有对VQA视角下的VLP挑战进行深入探讨，留下了可能出现潜在开放问题的空间。本研究在VQA领域提供了一份调查报告，深入探讨了VQA数据集和历史中的方法细节。

    The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre-trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre-training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven't been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field's history, introdu
    
[^15]: C-Pack: 推进普通汉语嵌入的打包资源

    C-Pack: Packaged Resources To Advance General Chinese Embedding. (arXiv:2309.07597v1 [cs.CL])

    [http://arxiv.org/abs/2309.07597](http://arxiv.org/abs/2309.07597)

    C-Pack是一套推进普通汉语嵌入领域的资源，包括全面汉语文本嵌入基准、大规模文本嵌入数据集和涵盖多个尺寸的嵌入模型系列。该资源集在C-MTEB基准上实现了最高+10%的表现，并通过整合和优化一套训练方法进一步提升了效果。此外，C-Pack还发布了英语文本嵌入数据和模型，实现了最先进的性能。该资源集可公开获取。

    

    我们介绍了C-Pack，这是一套显著推进普通汉语嵌入领域的资源。C-Pack包括三个关键资源。1）C-MTEB是一个涵盖6个任务和35个数据集的全面汉语文本嵌入基准。2）C-MTP是一个从标记和未标记的汉语语料库中策划的大规模文本嵌入数据集，用于训练嵌入模型。3）C-TEM是一个涵盖多个尺寸的嵌入模型系列。我们的模型在C-MTEB上的表现优于之前的所有汉语文本嵌入达到了发布时的最高+10%。我们还整合和优化了C-TEM的整套训练方法。除了我们关于普通汉语嵌入的资源外，我们还发布了我们的英语文本嵌入数据和模型。这些英语模型在MTEB基准上实现了最先进的性能；与此同时，我们发布的英语数据比汉语数据大2倍。所有这些资源都可以在https://github.com/FlagOpen/FlagEmbedding上公开获取。

    We introduce C-Pack, a package of resources that significantly advance the field of general Chinese embeddings. C-Pack includes three critical resources. 1) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets. 2) C-MTP is a massive text embedding dataset curated from labeled and unlabeled Chinese corpora for training embedding models. 3) C-TEM is a family of embedding models covering multiple sizes. Our models outperform all prior Chinese text embeddings on C-MTEB by up to +10% upon the time of the release. We also integrate and optimize the entire suite of training methods for C-TEM. Along with our resources on general Chinese embedding, we release our data and models for English text embeddings. The English models achieve state-of-the-art performance on MTEB benchmark; meanwhile, our released English data is 2 times larger than the Chinese data. All these resources are made publicly available at https://github.com/FlagOpen/FlagEmbedding.
    
[^16]: 顺序体积设计任务的表示学习

    Representation Learning for Sequential Volumetric Design Tasks. (arXiv:2309.02583v1 [cs.LG])

    [http://arxiv.org/abs/2309.02583](http://arxiv.org/abs/2309.02583)

    本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。

    

    体积设计，也称为质量设计，是专业建筑设计中的第一步关键性任务，具有顺序性。由于体积设计过程复杂，顺序化设计过程中包含了对设计师有价值的信息。许多努力已经被投入到自动生成合理的体积设计上，但生成的设计解决方案的质量存在差异，并且评估一个设计解决方案要么需要一套过于全面的度量标准，要么需要昂贵的人力专业知识。而之前的方法主要关注学习最终设计，而不是顺序设计任务，我们提出利用专家或高性能设计序列的设计知识，并使用基于transformer的模型提取有用的表示。然后，我们提出利用所学的表示在关键的下游应用中，如设计偏好评估和程序化设计生成。我们开发了prefer

    Volumetric design, also called massing design, is the first and critical step in professional building design which is sequential in nature. As the volumetric design process is complex, the underlying sequential design process encodes valuable information for designers. Many efforts have been made to automatically generate reasonable volumetric designs, but the quality of the generated design solutions varies, and evaluating a design solution requires either a prohibitively comprehensive set of metrics or expensive human expertise. While previous approaches focused on learning only the final design instead of sequential design tasks, we propose to encode the design knowledge from a collection of expert or high-performing design sequences and extract useful representations using transformer-based models. Later we propose to utilize the learned representations for crucial downstream applications such as design preference evaluation and procedural design generation. We develop the prefere
    
[^17]: GUARD: 一个安全强化学习基准测试平台

    GUARD: A Safe Reinforcement Learning Benchmark. (arXiv:2305.13681v1 [cs.LG])

    [http://arxiv.org/abs/2305.13681](http://arxiv.org/abs/2305.13681)

    GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。

    

    由于试错的性质，将RL算法应用于安全关键的现实应用（例如自动驾驶、人机交互、机器人操作等）通常是具有挑战性的，因为这些错误是不可容忍的。最近，安全RL（即约束RL）已经在文献中迅速出现，其中代理在满足约束条件的同时，探索环境。由于算法和任务的多样性，比较现有的安全RL算法仍然很困难。为了填补这一空白，我们介绍了GUARD，一个广义统一安全强化学习开发基准测试平台。与现有基准相比，GUARD具有几个优点。首先，GUARD是一个广义基准测试平台，具有各种RL代理、任务和安全约束规范。其次，GUARD全面涵盖了最先进的安全RL算法，并具有自包含的实现。第三，GUARD在任务和算法方面具有高度的可自定义性。我们提供了状态下现有方法在GUARD上的基准测试结果。

    Due to the trial-and-error nature, it is typically challenging to apply RL algorithms to safety-critical real-world applications, such as autonomous driving, human-robot interaction, robot manipulation, etc, where such errors are not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly in the literature, in which the agents explore the environment while satisfying constraints. Due to the diversity of algorithms and tasks, it remains difficult to compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a Generalized Unified SAfe Reinforcement Learning Development Benchmark. GUARD has several advantages compared to existing benchmarks. First, GUARD is a generalized benchmark with a wide variety of RL agents, tasks, and safety constraint specifications. Second, GUARD comprehensively covers state-of-the-art safe RL algorithms with self-contained implementations. Third, GUARD is highly customizable in tasks and algorithms. We present a comparison of state
    

