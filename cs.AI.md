# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [TraveLER: A Multi-LMM Agent Framework for Video Question-Answering](https://arxiv.org/abs/2404.01476) | TraveLER是一种多重LMM代理框架，通过沿着视频移动，并通过交互式提问收集关键帧的信息，以解决视频问答中关键时间戳选择和错误时间戳调整的问题 |
| [^2] | [MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System](https://arxiv.org/abs/2403.19992) | 提出了一种低成本技术解决方案MindArm，利用深度神经网络将大脑信号翻译成假肢运动，帮助患者执行各种活动 |
| [^3] | [UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object Detection with Sparse LiDAR and Large Domain Gaps](https://arxiv.org/abs/2403.17633) | UADA3D是一种无监督对抗领域自适应方法，能够在3D物体检测中处理稀疏LiDAR数据和大领域差距，并在自动驾驶汽车和移动机器人领域中表现出显著的改进。 |
| [^4] | [Comparing Plausibility Estimates in Base and Instruction-Tuned Large Language Models](https://arxiv.org/abs/2403.14859) | 通过比较基础和指令调优的大型语言模型在英语句子可信度任务中的表现，发现对数似然（LL）分数是最可靠的句子可信度指标，但仍低于人类表现。 |
| [^5] | [Just Say the Name: Online Continual Learning with Category Names Only via Data Generation](https://arxiv.org/abs/2403.10853) | 提出了在线连续学习框架G-NoCL，采用生成数据并利用DIverSity和COmplexity enhancing ensemBlER（DISCOBER）进行数据融合，展示了其在在线连续学习基准测试中的优越性能。 |
| [^6] | [Diffusion-TS: Interpretable Diffusion for General Time Series Generation](https://arxiv.org/abs/2403.01742) | 提出了一种新颖的基于扩散的框架 Diffusion-TS，结合了编码器-解码器变压器和解耦时间表示，通过直接重建样本而非噪声生成高质量的多变量时间序列样本，旨在实现时间序列的解释性和真实性。 |
| [^7] | [Negative Sampling in Knowledge Graph Representation Learning: A Review](https://arxiv.org/abs/2402.19195) | 负采样方法对知识图谱表示学习的成功至关重要，本综述系统地审查了各种负采样方法及其对知识图谱表示学习成功的贡献。 |
| [^8] | [FSL Model can Score Higher as It Is](https://arxiv.org/abs/2402.18292) | 为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。 |
| [^9] | [Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints](https://arxiv.org/abs/2402.18012) | 使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。 |
| [^10] | [Ansible Lightspeed: A Code Generation Service for IT Automation](https://arxiv.org/abs/2402.17442) | Ansible Lightspeed是一种基于大型语言模型的服务，专注于将自然语言转换为Ansible代码，为IT自动化领域带来了创新。 |
| [^11] | [CriticBench: Evaluating Large Language Models as Critic](https://arxiv.org/abs/2402.13764) | CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。 |
| [^12] | [Investigating the Histogram Loss in Regression](https://arxiv.org/abs/2402.13425) | 学习整个分布在回归中的性能提升主要来自于优化的改进，而不是学习更好的表示。 |
| [^13] | [Neural machine translation of clinical procedure codes for medical diagnosis and uncertainty quantification](https://arxiv.org/abs/2402.10940) | 研究引入了医学熵的概念，通过神经机器翻译基于ICD-9代码的患者预测结果，量化了不确定性。 |
| [^14] | [Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers](https://arxiv.org/abs/2402.08958) | 本文提出了一种新颖的后训练量化算法，名为aespa，它在保持完整的注意力得分的同时，通过逐层量化来提高效率，解决了当前后训练量化方案的瓶颈问题。 |
| [^15] | [Tandem Transformers for Inference Efficient LLMs](https://arxiv.org/abs/2402.08644) | 该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。 |
| [^16] | [Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation for sigmoidal classification models](https://arxiv.org/abs/2402.08151) | 本研究引入了渐变流自适应重要性抽样的方法，用于稳定贝叶斯分类模型的留一交叉验证预测的蒙特卡罗近似，以评估模型的普适性。 |
| [^17] | [Training dynamics in Physics-Informed Neural Networks with feature mapping](https://arxiv.org/abs/2402.06955) | 本研究探究了使用特征映射层的物理引导神经网络（PINNs）的训练动态，通过极限共轭核和神经切向核揭示了模型的收敛和泛化。我们提出了一种替代基于傅里叶变换的特征映射的条件正定径向基函数，证明了该方法在各种问题集中的有效性，并可以轻松实现在坐标输入网络中。这为广泛的PINNs研究带来了益处。 |
| [^18] | [Can LLMs Recognize Toxicity? Structured Toxicity Investigation Framework and Semantic-Based Metric](https://arxiv.org/abs/2402.06900) | 本研究提出了一种基于大型语言模型（LLMs）的自动度量方法，用于识别生成文本中的毒性。通过分析毒性因素和LLMs的内在毒性属性，该方法在测量毒性方面表现出众，比现有指标提升12个百分点。 |
| [^19] | [Grandmaster-Level Chess Without Search](https://arxiv.org/abs/2402.04494) | 本研究通过在庞大的国际象棋数据集上进行训练，使用了一个270M参数的Transformer模型，不依赖于复杂的启发式算法或显式搜索，取得了大师级水平的国际象棋对局的成功。模型在Lichess闪电战评分上达到了2895，解决了一系列具有挑战性的国际象棋谜题，优于AlphaZero和GPT-3.5-turbo-instruct。通过系统研究，我们发现大规模的模型和数据集对于实现强大的国际象棋对局效果是至关重要的。 |
| [^20] | [Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators](https://arxiv.org/abs/2311.07879) | 本研究揭示了人工智能模型在识别有毒、冒犯和令人讨厌的内容方面的进展，并探讨了这些改进是否真正满足了志愿内容管理员在工作中的需求。 |
| [^21] | [Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning.](http://arxiv.org/abs/2401.13796) | 本文讨论了机器学习中的数据泄露问题，即未预期的信息污染训练数据，影响模型性能评估，用户可能由于缺乏理解而忽视关键步骤，导致乐观的性能估计在实际场景中不成立。 |
| [^22] | [The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models.](http://arxiv.org/abs/2401.05618) | 本文研究了在大型语言模型中使用简洁的思维链提示对问题求解的影响，实验结果表明简洁性不仅降低了回答长度，且对问题解决性能影响可以忽略。然而在数学问题上有一定的性能下降。这对AI系统工程师和研究人员都有实际意义。 |
| [^23] | [Robust-MBFD: A Robust Deep Learning System for Motor Bearing Faults Detection Using Multiple Deep Learning Training Strategies and A Novel Double Loss Function.](http://arxiv.org/abs/2310.11477) | 本文提出了一种稳健的深度学习系统用于电机轴承故障检测，采用多个深度学习训练策略和一种新的双损失函数。通过对比评估不同系统并寻找最佳模型，我们展示了该系统对各种电机轴承故障的有效性。 |
| [^24] | [FedLPA: Personalized One-shot Federated Learning with Layer-Wise Posterior Aggregation.](http://arxiv.org/abs/2310.00339) | 本文提出了一种名为FedLPA的新颖方法，采用分层后验聚合的方式实现个性化单次联邦学习。FedLPA能够高效地将本地模型聚合到全局模型，解决了单次聚合在非相同训练数据分布下的性能问题。 |
| [^25] | [Discrete-Choice Model with Generalized Additive Utility Network.](http://arxiv.org/abs/2309.16970) | 本论文提出了一种基于广义可加模型的神经网络架构，称为广义可加效用网络（GAUNet），用于离散选择模型。这些模型在预测准确性上可以与ASU-DNN相媲美，并且相比以前的模型具有更好的解释性。 |
| [^26] | [Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence.](http://arxiv.org/abs/2309.14379) | 本研究提出了一种机器辅助的混合方法框架，利用大规模语言模型在人文社科领域的数据分析中的应用潜力，展示了16个案例研究，并涵盖了多种任务，包括语言分析、文本挖掘、社交网络推断等。 |
| [^27] | [Embed-Search-Align: DNA Sequence Alignment using Transformer Models.](http://arxiv.org/abs/2309.11087) | 这项研究使用Transformer模型对DNA序列进行对齐，通过生成数值表示来实现。相比传统方法，该方法在短DNA序列的分类任务上取得了更好的性能，对于基因组学分析具有潜在的应用价值。 |
| [^28] | [Unveiling Signle-Bit-Flip Attacks on DNN Executables.](http://arxiv.org/abs/2309.06223) | 针对由深度学习编译器编译的DNN可执行文件的单位翻转攻击进行了系统研究，设计了自动搜索工具以识别易受攻击的位，并确定了实际攻击向量，揭示了DNN可执行文件的攻击面。 |
| [^29] | [Granger-Causal Hierarchical Skill Discovery.](http://arxiv.org/abs/2306.09509) | 本文介绍了一种名为HIntS的算法，使用无监督检测器，基于Granger因果性捕捉因素之间的关键事件，发现和训练一系列操作因素化环境中的因素的技能，其展示了在机器人推动任务上有2-3倍的样本效率和最终性能的提高，有效的处理了复杂问题和转移学习。 |
| [^30] | [AI Art Curation: Re-imagining the city of Helsinki in occasion of its Biennial.](http://arxiv.org/abs/2306.03753) | 本研究通过AI策展和观众互动，利用机器学习模型重新构想了赫尔辛基市艺术双年展，使用视觉-文本模型将室内艺术品放置在公共空间中，生成合成的360艺术全景图，以创造出艺术品与城市空间的新视角。 |
| [^31] | [Deep Radar Inverse Sensor Models for Dynamic Occupancy Grid Maps.](http://arxiv.org/abs/2305.12409) | 该研究提出了一种基于深度学习的雷达逆向传感器模型，用于将稀疏雷达检测映射到极坐标测量网格，并生成动态网格地图，实验结果表明该方法优于手工制作的几何ISM。与最先进的深度学习方法相比，该方法为从有限视场的雷达中学习极坐标方案的单帧测量网格的第一个方法。 |
| [^32] | [Open-World Continual Learning: Unifying Novelty Detection and Continual Learning.](http://arxiv.org/abs/2304.10038) | 本文从理论上证明，分布外检测对于类别增量学习是必要的，因为类别增量学习可以分解成任务内预测和任务 ID 预测，并且任务 ID 预测与分布外检测相关。 |
| [^33] | [Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets.](http://arxiv.org/abs/2304.02847) | 本研究提出一种叫做Robustmix的方法，通过正则化网络以低频空间特征进行分类来提高深度网络的鲁棒性，在Imagenet-C和Stylized Imagenet等基准测试上取得了最新的最优状态平均峰值误差（mCE），在避免计算开销和先验知识的大量图像变换的同时对模型架构和数据增强的最新进展提供了补充。 |
| [^34] | [Construction numbers: How to build a graph?.](http://arxiv.org/abs/2302.13186) | 论文研究了计算偏序的线性扩展数量问题，并研究了由包含关系确定的图形的顶点和边的偏序，找到了路径、环、星形图、双星形图和完全图的构造序列数量，并提出了公式，同时研究了结构和应用。 |
| [^35] | [Deep Emotion Recognition in Textual Conversations: A Survey.](http://arxiv.org/abs/2211.09172) | 本调研针对对话中的情感识别进行了探讨，介绍了涉及此任务的挑战和机遇，以及描述了情感分类法和使用该分类法的基准数据集。调研总结了最重要的作品和所使用的深度学习架构，并提供了建议性的情感识别实践，以实现更好的框架。 |
| [^36] | [Isotuning With Applications To Scale-Free Online Learning.](http://arxiv.org/abs/2112.14586) | 我们提出了一种用于无标度在线学习的等调节技术，该技术具有快速、自适应、随时随地和无标度的特点，并可以自动适应遗憾的速率。同时，我们还引入了在线校正的方法来改进算法的性能。 |

# 详细

[^1]: TraveLER：用于视频问答的多重LMM代理框架

    TraveLER: A Multi-LMM Agent Framework for Video Question-Answering

    [https://arxiv.org/abs/2404.01476](https://arxiv.org/abs/2404.01476)

    TraveLER是一种多重LMM代理框架，通过沿着视频移动，并通过交互式提问收集关键帧的信息，以解决视频问答中关键时间戳选择和错误时间戳调整的问题

    

    最近，大型多模态模型（LMMs）在视频问答方面取得了重要进展，通过利用大规模、基于图像的预训练以零样本方式以帧为单位进行处理。虽然基于图像的视频方法展现了令人印象深刻的性能，但目前的局限是它们经常忽视了如何选择关键时间戳，并且无法在确定错误时间戳时进行调整。此外，它们无法提取与问题相关的细节，而是提供帧的一般描述。为了克服这一点，我们设计了一个多重LMM代理框架，它沿着视频进行移动，通过交互式提问的方式迭代地从关键帧收集相关信息，直到获得足够的信息来回答问题。具体来说，我们提出了TraveLER，这是一个可以制定“遍历”视频计划的模型，询问关于单个帧的问题以“定位”并存储关键信息

    arXiv:2404.01476v1 Announce Type: cross  Abstract: Recently, Large Multimodal Models (LMMs) have made significant progress in video question-answering using a frame-wise approach by leveraging large-scale, image-based pretraining in a zero-shot manner. While image-based methods for videos have shown impressive performance, a current limitation is that they often overlook how key timestamps are selected and cannot adjust when incorrect timestamps are identified. Moreover, they are unable to extract details relevant to the question, instead providing general descriptions of the frame. To overcome this, we design a multi-LMM agent framework that travels along the video, iteratively collecting relevant information from keyframes through interactive question-asking until there is sufficient information to answer the question. Specifically, we propose TraveLER, a model that can create a plan to "Traverse" through the video, ask questions about individual frames to "Locate" and store key info
    
[^2]: MindArm: 机械智能非侵入式神经驱动假肢系统

    MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System

    [https://arxiv.org/abs/2403.19992](https://arxiv.org/abs/2403.19992)

    提出了一种低成本技术解决方案MindArm，利用深度神经网络将大脑信号翻译成假肢运动，帮助患者执行各种活动

    

    目前，残疾或难以移动手臂的人（简称“患者”）在有效解决生理限制方面有非常有限的技术解决方案。这主要是由于两个原因：一是像以思维控制为主的假肢设备通常非常昂贵并需要昂贵的维护；二是其他解决方案需要昂贵的侵入性脑部手术，这种手术风险高，昂贵且维护困难。因此，当前的技术解决方案并不适用于具有不同财务背景的所有患者。为此，我们提出了一种低成本技术解决方案，名为MindArm，即一种机械智能非侵入式神经驱动假肢系统。我们的MindArm系统采用深度神经网络（DNN）引擎将大脑信号翻译成预期的假肢运动，从而帮助患者实施许多活动，尽管他们

    arXiv:2403.19992v1 Announce Type: new  Abstract: Currently, people with disability or difficulty to move their arms (referred to as "patients") have very limited technological solutions to efficiently address their physiological limitations. It is mainly due to two reasons: (1) the non-invasive solutions like mind-controlled prosthetic devices are typically very costly and require expensive maintenance; and (2) other solutions require costly invasive brain surgery, which is high risk to perform, expensive, and difficult to maintain. Therefore, current technological solutions are not accessible for all patients with different financial backgrounds. Toward this, we propose a low-cost technological solution called MindArm, a mechanized intelligent non-invasive neuro-driven prosthetic arm system. Our MindArm system employs a deep neural network (DNN) engine to translate brain signals into the intended prosthetic arm motion, thereby helping patients to perform many activities despite their 
    
[^3]: UADA3D：面向稀疏LiDAR和大领域差距的无监督对抗领域自适应在3D物体检测中的应用

    UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object Detection with Sparse LiDAR and Large Domain Gaps

    [https://arxiv.org/abs/2403.17633](https://arxiv.org/abs/2403.17633)

    UADA3D是一种无监督对抗领域自适应方法，能够在3D物体检测中处理稀疏LiDAR数据和大领域差距，并在自动驾驶汽车和移动机器人领域中表现出显著的改进。

    

    在这项研究中，我们解决了现有无监督领域适应方法在基于LiDAR的3D物体检测中的一个问题，这些方法主要集中在适应已建立的高密度自动驾驶数据集之间的转变。我们专注于更稀疏的点云，捕捉来自不同视角的场景：不仅来自道路上的车辆，还来自人行道上的移动机器人，遭遇着明显不同的环境条件和传感器配置。我们引入了无监督对抗领域自适应3D物体检测（UADA3D）。UADA3D不依赖于预训练的源模型或师生架构。相反，它使用对抗方法直接学习域不变特征。我们展示了它在各种适应场景中的有效性，在自动驾驶汽车和移动机器人领域均显示出显著的改进。我们的代码是开源的，很快将会提供。

    arXiv:2403.17633v1 Announce Type: cross  Abstract: In this study, we address a gap in existing unsupervised domain adaptation approaches on LiDAR-based 3D object detection, which have predominantly concentrated on adapting between established, high-density autonomous driving datasets. We focus on sparser point clouds, capturing scenarios from different perspectives: not just from vehicles on the road but also from mobile robots on sidewalks, which encounter significantly different environmental conditions and sensor configurations. We introduce Unsupervised Adversarial Domain Adaptation for 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source models or teacher-student architectures. Instead, it uses an adversarial approach to directly learn domain-invariant features. We demonstrate its efficacy in various adaptation scenarios, showing significant improvements in both self-driving car and mobile robot domains. Our code is open-source and will be available soon.
    
[^4]: 在基础模型和指令调优的大型语言模型中比较可信度估计

    Comparing Plausibility Estimates in Base and Instruction-Tuned Large Language Models

    [https://arxiv.org/abs/2403.14859](https://arxiv.org/abs/2403.14859)

    通过比较基础和指令调优的大型语言模型在英语句子可信度任务中的表现，发现对数似然（LL）分数是最可靠的句子可信度指标，但仍低于人类表现。

    

    指令调优的LLM可以响应明确制定为提示的查询，这极大地促进了与人类用户的交互。然而，基于提示的方法可能并不总是能够利用LLM在预训练期间获得的隐式知识。本文对评估LLM中语义可信度的方法进行了全面研究。我们通过（a）明确提示和（b）直接读取模型分配给字符串的概率的隐式估计，在英语句子可信度任务中比较了基础和指令调优LLM的性能。实验1表明，跨模型架构和可信度数据集，（i）对数似然（LL）分数是句子可信度最可靠的指标，零照射提示产生不一致且通常效果不佳的结果；（ii）基于LL的性能仍低于人类表现；（iii）指令调优模型有

    arXiv:2403.14859v1 Announce Type: cross  Abstract: Instruction-tuned LLMs can respond to explicit queries formulated as prompts, which greatly facilitates interaction with human users. However, prompt-based approaches might not always be able to tap into the wealth of implicit knowledge acquired by LLMs during pre-training. This paper presents a comprehensive study of ways to evaluate semantic plausibility in LLMs. We compare base and instruction-tuned LLM performance on an English sentence plausibility task via (a) explicit prompting and (b) implicit estimation via direct readout of the probabilities models assign to strings. Experiment 1 shows that, across model architectures and plausibility datasets, (i) log likelihood ($\textit{LL}$) scores are the most reliable indicator of sentence plausibility, with zero-shot prompting yielding inconsistent and typically poor results; (ii) $\textit{LL}$-based performance is still inferior to human performance; (iii) instruction-tuned models hav
    
[^5]: 只说名称：通过数据生成实现仅利用类别名称进行在线连续学习

    Just Say the Name: Online Continual Learning with Category Names Only via Data Generation

    [https://arxiv.org/abs/2403.10853](https://arxiv.org/abs/2403.10853)

    提出了在线连续学习框架G-NoCL，采用生成数据并利用DIverSity和COmplexity enhancing ensemBlER（DISCOBER）进行数据融合，展示了其在在线连续学习基准测试中的优越性能。

    

    在现实世界的场景中，由于成本过高，对于连续学习进行大量手动注释是不切实际的。虽然之前的研究受到大规模网络监督训练的影响，建议在连续学习中利用网络抓取的数据，但这带来了诸如数据不平衡、使用限制和隐私问题等挑战。为了解决连续网络监督训练的风险，我们提出了一种在线连续学习框架 - 仅使用名称的生成式连续学习（G-NoCL）。所提出的G-NoCL使用一组生成器G以及学习者。当遇到新概念（例如，类别）时，G-NoCL采用新颖的样本复杂性引导数据合成技术DIverSity and COmplexity enhancing ensemBlER（DISCOBER）从生成的数据中最优抽样训练数据。通过大量实验，我们展示了DISCOBER在G-NoCL在线连续学习基准测试中表现出的优越性能，涵盖了In-Distributi。

    arXiv:2403.10853v1 Announce Type: cross  Abstract: In real-world scenarios, extensive manual annotation for continual learning is impractical due to prohibitive costs. Although prior arts, influenced by large-scale webly supervised training, suggest leveraging web-scraped data in continual learning, this poses challenges such as data imbalance, usage restrictions, and privacy concerns. Addressing the risks of continual webly supervised training, we present an online continual learning framework - Generative Name only Continual Learning (G-NoCL). The proposed G-NoCL uses a set of generators G along with the learner. When encountering new concepts (i.e., classes), G-NoCL employs the novel sample complexity-guided data ensembling technique DIverSity and COmplexity enhancing ensemBlER (DISCOBER) to optimally sample training data from generated data. Through extensive experimentation, we demonstrate superior performance of DISCOBER in G-NoCL online CL benchmarks, covering both In-Distributi
    
[^6]: 可解释的扩散用于通用时间序列生成

    Diffusion-TS: Interpretable Diffusion for General Time Series Generation

    [https://arxiv.org/abs/2403.01742](https://arxiv.org/abs/2403.01742)

    提出了一种新颖的基于扩散的框架 Diffusion-TS，结合了编码器-解码器变压器和解耦时间表示，通过直接重建样本而非噪声生成高质量的多变量时间序列样本，旨在实现时间序列的解释性和真实性。

    

    Denoising diffusion probabilistic models (DDPMs)正逐渐成为生成模型的主流范式，最近已在音频合成、时间序列填补和预测等领域取得突破。本文提出了Diffusion-TS，一种新颖的基于扩散的框架，通过使用具有解耦时间表示的编码器-解码器变压器生成高质量的多变量时间序列样本，其中分解技术指导Diffusion-TS捕获时间序列的语义含义，而变压器从嘈杂的模型输入中挖掘详细的序列信息。与现有的基于扩散的方法不同，我们训练模型直接重建样本而不是在每个扩散步骤中重建噪声，并结合了基于Fourier的损失项。预期Diffusion-TS可以生成既具有解释性又真实性的时间序列。此外，还表明了所提出的Diffusion

    arXiv:2403.01742v1 Announce Type: cross  Abstract: Denoising diffusion probabilistic models (DDPMs) are becoming the leading paradigm for generative models. It has recently shown breakthroughs in audio synthesis, time series imputation and forecasting. In this paper, we propose Diffusion-TS, a novel diffusion-based framework that generates multivariate time series samples of high quality by using an encoder-decoder transformer with disentangled temporal representations, in which the decomposition technique guides Diffusion-TS to capture the semantic meaning of time series while transformers mine detailed sequential information from the noisy model input. Different from existing diffusion-based approaches, we train the model to directly reconstruct the sample instead of the noise in each diffusion step, combining a Fourier-based loss term. Diffusion-TS is expected to generate time series satisfying both interpretablity and realness. In addition, it is shown that the proposed Diffusion-T
    
[^7]: 知识图谱表示学习中的负采样：一项综述

    Negative Sampling in Knowledge Graph Representation Learning: A Review

    [https://arxiv.org/abs/2402.19195](https://arxiv.org/abs/2402.19195)

    负采样方法对知识图谱表示学习的成功至关重要，本综述系统地审查了各种负采样方法及其对知识图谱表示学习成功的贡献。

    

    知识图谱表示学习（KGRL）或知识图谱嵌入（KGE）在知识构建和信息探索的AI应用中起着关键作用。这些模型旨在将知识图谱中的实体和关系编码为低维向量空间。在KGE模型的训练过程中，使用正负样本对于区分目的至关重要。然而，直接从现有知识图谱中获取负样本面临挑战，强调了有效生成技术的必要性。这些负样本的质量对学习到的嵌入的准确性有着很大影响，使得它们的生成成为KGRL的关键方面。本全面调研论文系统地审查了各种负采样（NS）方法及其对KGRL成功的贡献。通过对现有NS方法的分类，概述了它们各自的优缺点。

    arXiv:2402.19195v1 Announce Type: new  Abstract: Knowledge graph representation learning (KGRL) or knowledge graph embedding (KGE) plays a crucial role in AI applications for knowledge construction and information exploration. These models aim to encode entities and relations present in a knowledge graph into a lower-dimensional vector space. During the training process of KGE models, using positive and negative samples becomes essential for discrimination purposes. However, obtaining negative samples directly from existing knowledge graphs poses a challenge, emphasizing the need for effective generation techniques. The quality of these negative samples greatly impacts the accuracy of the learned embeddings, making their generation a critical aspect of KGRL. This comprehensive survey paper systematically reviews various negative sampling (NS) methods and their contributions to the success of KGRL. Their respective advantages and disadvantages are outlined by categorizing existing NS me
    
[^8]: FSL模型可以因为其优越性得分更高

    FSL Model can Score Higher as It Is

    [https://arxiv.org/abs/2402.18292](https://arxiv.org/abs/2402.18292)

    为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。

    

    在日常生活中，为了增加被正确识别的机会，我们倾向于面对面地直视面部识别机，而不是侧着面对。少样本学习（FSL）分类本身就具有挑战性，因为模型必须识别属于训练时未见的类别的图像。因此，在测试期间对扭曲和非典型的查询或支持图像会让模型更难正确预测。在我们的研究中，为了增加测试期间正确预测的机会，我们旨在通过图像到图像的转换纠正训练过的FSL模型的测试输入，生成被测试类别的新样本。FSL模型通常是在具有足够样本的类别上进行训练，然后在具有少样本样本的类别上进行测试。我们提出的方法首先捕捉测试图像的风格或形状，然后识别一个适当的训

    arXiv:2402.18292v1 Announce Type: cross  Abstract: In daily life, we tend to present the front of our faces by staring squarely at a facial recognition machine, instead of facing it sideways, in order to increase the chance of being correctly recognised. Few-shot-learning (FSL) classification is challenging in itself because a model has to identify images that belong to classes previously unseen during training. Therefore, a warped and non-typical query or support image during testing can make it even more challenging for a model to predict correctly. In our work, to increase the chance of correct prediction during testing, we aim to rectify the test input of a trained FSL model by generating new samples of the tested classes through image-to-image translation. An FSL model is usually trained on classes with sufficient samples, and then tested on classes with few-shot samples. Our proposed method first captures the style or shape of the test image, and then identifies a suitable traine
    
[^9]: 扩散模型作为具有未知约束的优化约束抽样器

    Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints

    [https://arxiv.org/abs/2402.18012](https://arxiv.org/abs/2402.18012)

    使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。

    

    处理现实世界的优化问题在分析客观函数或约束不可用时变得尤为具有挑战性。虽然许多研究已经解决了未知目标的问题，但有限研究关注了约束条件未明确给出的情况。忽略这些约束可能导致在实践中不现实的虚假解决方案。为了处理这种未知约束，我们建议使用扩散模型在数据流形内进行优化。为了将优化过程限制在数据流形内，我们将原始优化问题重新构造为通过客观函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积的抽样问题。为了增强抽样效率，我们提出了一个两阶段框架，以引导扩散过程进行预热，然后是Langevin动态。

    arXiv:2402.18012v1 Announce Type: cross  Abstract: Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dyna
    
[^10]: Ansible Lightspeed: 一种用于IT自动化的代码生成服务

    Ansible Lightspeed: A Code Generation Service for IT Automation

    [https://arxiv.org/abs/2402.17442](https://arxiv.org/abs/2402.17442)

    Ansible Lightspeed是一种基于大型语言模型的服务，专注于将自然语言转换为Ansible代码，为IT自动化领域带来了创新。

    

    大型语言模型（LLMs）的问世使得创建可提高开发者生产力的工具成为可能，集成开发环境（IDEs）常被用作与LLMs交互的接口。已发布许多这类工具，但几乎全部都专注于通用编程语言，很少关注对IT自动化至关重要的特定领域语言。Ansible是一种基于YAML的IT自动化特定语言。Red Hat Ansible Lightspeed与IBM Watson Code Assistant合作的Ansible Lightspeed是一种基于LLM的服务，专门用于将自然语言转换为Ansible代码。

    arXiv:2402.17442v1 Announce Type: cross  Abstract: The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for IT automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Red Hat Ansible Lightspeed with IBM Watson Code Assistant, further referred to as Ansible Lightspeed, is an LLM-based service designed explicitly for natural language to Ansible code generation.   In this paper, we describe the design and implementation of the Ansible Lightspeed service and analyze feedback from thousands of real users. We examine diverse performance indicators, clas
    
[^11]: CriticBench: 将大型语言模型作为评论家进行评估

    CriticBench: Evaluating Large Language Models as Critic

    [https://arxiv.org/abs/2402.13764](https://arxiv.org/abs/2402.13764)

    CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。

    

    论文提出了 CriticBench，这是一个旨在全面和可靠地评估大型语言模型（LLMs）的四个关键评论能力维度（反馈、比较、改进和元反馈）的新型基准。CriticBench包含九个不同的任务，每个任务评估LLMs在不同质量细粒度水平上评论响应的能力。对开源和闭源LLMs进行的广泛评估揭示了评论能力与任务、响应质量和模型规模之间有趣的关系。CriticBench的数据集、资源和评估工具包将在https://github.com/gmftbyGMFTBY/Cri上公开发布。

    arXiv:2402.13764v1 Announce Type: cross  Abstract: Critique ability are crucial in the scalable oversight and self-improvement of Large Language Models (LLMs). While many recent studies explore the critique ability of LLMs to judge and refine flaws in generations, how to comprehensively and reliably measure the critique abilities of LLMs is under-explored. This paper introduces \shortname, a novel benchmark designed to comprehensively and reliably evaluate four key critique ability dimensions of LLMs: feedback, comparison, refinement and meta-feedback. \shortname~encompasses nine diverse tasks, each assessing the LLMs' ability to critique responses at varying levels of quality granularity. Our extensive evaluations of open-source and closed-source LLMs reveal intriguing relationships between the critique ability and tasks, response qualities, and model scales. Datasets, resources and evaluation toolkit for \shortname~will be publicly released at \url{https://github.com/gmftbyGMFTBY/Cri
    
[^12]: 在回归中探讨直方图损失

    Investigating the Histogram Loss in Regression

    [https://arxiv.org/abs/2402.13425](https://arxiv.org/abs/2402.13425)

    学习整个分布在回归中的性能提升主要来自于优化的改进，而不是学习更好的表示。

    

    越来越常见的是，在回归中训练神经网络来建模整个分布，即使只需要均值来进行预测。 这种额外的建模通常会带来性能增益，但背后的原因尚不完全清楚。 本文研究了回归中的一种最新方法，即直方图损失，该方法通过最小化目标分布和灵活直方图预测之间的交叉熵来学习目标变量的条件分布。 我们设计了理论和实证分析，以确定为什么以及何时会出现性能增益，以及损失的不同组件如何为此做出贡献。 我们的结果表明，在这种设置中学习分布的好处来自于优化的改进，而不是学习更好的表示。 然后，我们展示了直方图损失在常见的深度学习应用中的可行性。

    arXiv:2402.13425v1 Announce Type: cross  Abstract: It is becoming increasingly common in regression to train neural networks that model the entire distribution even if only the mean is required for prediction. This additional modeling often comes with performance gain and the reasons behind the improvement are not fully known. This paper investigates a recent approach to regression, the Histogram Loss, which involves learning the conditional distribution of the target variable by minimizing the cross-entropy between a target distribution and a flexible histogram prediction. We design theoretical and empirical analyses to determine why and when this performance gain appears, and how different components of the loss contribute to it. Our results suggest that the benefits of learning distributions in this setup come from improvements in optimization rather than learning a better representation. We then demonstrate the viability of the Histogram Loss in common deep learning applications wi
    
[^13]: 临床程序代码的神经机器翻译用于医学诊断和不确定性量化

    Neural machine translation of clinical procedure codes for medical diagnosis and uncertainty quantification

    [https://arxiv.org/abs/2402.10940](https://arxiv.org/abs/2402.10940)

    研究引入了医学熵的概念，通过神经机器翻译基于ICD-9代码的患者预测结果，量化了不确定性。

    

    临床决策支持系统（CDSS）旨在通过将系统生成的建议与医学专业知识结合来增强临床医生的决策能力。本研究引入了医学熵的概念，通过基于手术ICD-9代码的神经机器翻译来量化患者预测结果中的不确定性。我们的实验结果不仅展示了程序代码与实际医疗结果之间的强相关性，

    arXiv:2402.10940v1 Announce Type: new  Abstract: A Clinical Decision Support System (CDSS) is designed to enhance clinician decision-making by combining system-generated recommendations with medical expertise. Given the high costs, intensive labor, and time-sensitive nature of medical treatments, there is a pressing need for efficient decision support, especially in complex emergency scenarios. In these scenarios, where information can be limited, an advanced CDSS framework that leverages AI (artificial intelligence) models to effectively reduce diagnostic uncertainty has utility. Such an AI-enabled CDSS framework with quantified uncertainty promises to be practical and beneficial in the demanding context of real-world medical care. In this study, we introduce the concept of Medical Entropy, quantifying uncertainties in patient outcomes predicted by neural machine translation based on the ICD-9 code of procedures. Our experimental results not only show strong correlations between proce
    
[^14]: 迈向超大规模Transformer的下一级后训练量化

    Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers

    [https://arxiv.org/abs/2402.08958](https://arxiv.org/abs/2402.08958)

    本文提出了一种新颖的后训练量化算法，名为aespa，它在保持完整的注意力得分的同时，通过逐层量化来提高效率，解决了当前后训练量化方案的瓶颈问题。

    

    随着生成AI模型的复杂性增加，后训练量化（PTQ）已成为在移动设备和电视等边缘设备上部署超大规模模型的有希望的解决方案。然而，现有的PTQ方案耗费大量时间和资源，这可能成为实际情况中频繁模型更新和多种超参数调整的瓶颈。作为一种成本效益的替代方案，已经提出了一次性PTQ方案。然而，它们的性能有些受限，因为它们无法考虑到Transformer中注意力模块内部层间的依赖关系，而这是一个非常重要的特性。因此，在本文中，我们提出了一种新颖的PTQ算法，它在精度和效率之间取得了平衡。所提出的算法的关键思想叫做aespa，通过在效率上进行逐层量化，同时考虑到跨层依赖以保留注意力得分。

    arXiv:2402.08958v1 Announce Type: cross Abstract: With the increasing complexity of generative AI models, post-training quantization (PTQ) has emerged as a promising solution for deploying hyper-scale models on edge devices such as mobile devices and TVs. Existing PTQ schemes, however, consume considerable time and resources, which could be a bottleneck in real situations where frequent model updates and multiple hyper-parameter tunings are required. As a cost-effective alternative, one-shot PTQ schemes have been proposed. Still, the performance is somewhat limited because they cannot consider the inter-layer dependency within the attention module, which is a very important feature of Transformers. In this paper, we thus propose a novel PTQ algorithm that balances accuracy and efficiency. The key idea of the proposed algorithm called aespa is to perform quantization layer-wise for efficiency while considering cross-layer dependency to preserve the attention score. Through extensive exp
    
[^15]: 用于推断高效LLMs的串联Transformer

    Tandem Transformers for Inference Efficient LLMs

    [https://arxiv.org/abs/2402.08644](https://arxiv.org/abs/2402.08644)

    该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。

    

    传统的大型语言模型( LLMs )具有自回归的特性，这使得推断速度受到限制，因为词元是按顺序生成的。尽管有些预测和并行解码技术试图减轻这个问题，但它们都有限制：要么依赖更精简但准确度较低的模型进行生成，要么没有充分利用基础LLM的表示。我们提出了一种新颖的架构，即串联Transformer，来解决这些问题。这种架构独特地结合了(1)一个小型自回归模型和(2)一个以块模式运行的大模型(同时处理多个词元)。通过让小模型关注大模型更丰富的表示，大幅提升小模型的预测准确性。在PaLM2预训练数据集上，PaLM2-Bison和PaLM2-Gecko的串联相较独立的PaLM2-Gecko，在下一个词元预测准确性上提升了3.3%，与具有相似下游任务的PaLM2-Otter模型相比，提供了1.16倍的加速比。

    The autoregressive nature of conventional large language models (LLMs) inherently limits inference speed, as tokens are generated sequentially. While speculative and parallel decoding techniques attempt to mitigate this, they face limitations: either relying on less accurate smaller models for generation or failing to fully leverage the base LLM's representations.   We introduce a novel architecture, Tandem transformers, to address these issues. This architecture uniquely combines (1) a small autoregressive model and (2) a large model operating in block mode (processing multiple tokens simultaneously). The small model's predictive accuracy is substantially enhanced by granting it attention to the large model's richer representations. On the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko demonstrates a 3.3% improvement in next-token prediction accuracy over a standalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter model with comparable downstream p
    
[^16]: 渐变流自适应重要性抽样用于sigmoid分类模型的贝叶斯留一交叉验证

    Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation for sigmoidal classification models

    [https://arxiv.org/abs/2402.08151](https://arxiv.org/abs/2402.08151)

    本研究引入了渐变流自适应重要性抽样的方法，用于稳定贝叶斯分类模型的留一交叉验证预测的蒙特卡罗近似，以评估模型的普适性。

    

    我们引入了一组梯度流引导的自适应重要性抽样（IS）变换，用于稳定贝叶斯分类模型的点级留一交叉验证（LOO）预测的蒙特卡罗近似。可以利用这种方法来评估模型的普适性，例如计算与AIC类似的LOO或计算LOO ROC / PRC曲线以及派生的度量指标，如AUROC和AUPRC。通过变分法和梯度流，我们推导出两个简单的非线性单步变换，利用梯度信息将模型的预训练完整数据后验靠近目标LOO后验预测分布。这样，变换稳定了重要性权重。因为变换涉及到似然函数的梯度，所以结果的蒙特卡罗积分依赖于模型Hessian的Jacobian行列式。我们推导出了这些Jacobian行列式的闭合精确公式。

    We introduce a set of gradient-flow-guided adaptive importance sampling (IS) transformations to stabilize Monte-Carlo approximations of point-wise leave one out cross-validated (LOO) predictions for Bayesian classification models. One can leverage this methodology for assessing model generalizability by for instance computing a LOO analogue to the AIC or computing LOO ROC/PRC curves and derived metrics like the AUROC and AUPRC. By the calculus of variations and gradient flow, we derive two simple nonlinear single-step transformations that utilize gradient information to shift a model's pre-trained full-data posterior closer to the target LOO posterior predictive distributions. In doing so, the transformations stabilize importance weights. Because the transformations involve the gradient of the likelihood function, the resulting Monte Carlo integral depends on Jacobian determinants with respect to the model Hessian. We derive closed-form exact formulae for these Jacobian determinants in
    
[^17]: 使用特征映射的物理引导神经网络中的训练动态

    Training dynamics in Physics-Informed Neural Networks with feature mapping

    [https://arxiv.org/abs/2402.06955](https://arxiv.org/abs/2402.06955)

    本研究探究了使用特征映射层的物理引导神经网络（PINNs）的训练动态，通过极限共轭核和神经切向核揭示了模型的收敛和泛化。我们提出了一种替代基于傅里叶变换的特征映射的条件正定径向基函数，证明了该方法在各种问题集中的有效性，并可以轻松实现在坐标输入网络中。这为广泛的PINNs研究带来了益处。

    

    物理引导神经网络（PINNs）已成为解决偏微分方程（PDE）的标志性机器学习方法。尽管其变体取得了显著进展，但来自更广泛的隐式神经表示研究的特征映射的经验性成功在很大程度上被忽视。我们通过极限共轭核和神经切向核来研究带有特征映射层的PINNs的训练动态，从而揭示了模型的收敛和泛化。我们还展示了常用的基于傅里叶变换的特征映射在某些情况下的不足，并提出条件正定的径向基函数作为更好的替代方法。经验证实，我们的方法在各种正向和反向问题集中非常有效。这种简单的技术可以轻松在坐标输入网络中实现，并受益于广泛的PINNs研究。

    Physics-Informed Neural Networks (PINNs) have emerged as an iconic machine learning approach for solving Partial Differential Equations (PDEs). Although its variants have achieved significant progress, the empirical success of utilising feature mapping from the wider Implicit Neural Representations studies has been substantially neglected. We investigate the training dynamics of PINNs with a feature mapping layer via the limiting Conjugate Kernel and Neural Tangent Kernel, which sheds light on the convergence and generalisation of the model. We also show the inadequacy of commonly used Fourier-based feature mapping in some scenarios and propose the conditional positive definite Radial Basis Function as a better alternative. The empirical results reveal the efficacy of our method in diverse forward and inverse problem sets. This simple technique can be easily implemented in coordinate input networks and benefits the broad PINNs research.
    
[^18]: LLM能够识别毒性吗？结构化毒性调查框架和基于语义的度量

    Can LLMs Recognize Toxicity? Structured Toxicity Investigation Framework and Semantic-Based Metric

    [https://arxiv.org/abs/2402.06900](https://arxiv.org/abs/2402.06900)

    本研究提出了一种基于大型语言模型（LLMs）的自动度量方法，用于识别生成文本中的毒性。通过分析毒性因素和LLMs的内在毒性属性，该方法在测量毒性方面表现出众，比现有指标提升12个百分点。

    

    在开发遵守社会标准的大型语言模型（LLMs）的过程中，识别生成文本中的毒性存在至关重要。现有的大多数毒性度量依赖于在特定毒性数据集上训练的编码模型。然而，这些编码器容易受到分布外的问题的影响，并且依赖于数据集中所假定的毒性定义。本文介绍了一种基于LLMs的自动鲁棒度量，用于区分模型回应是否具有毒性。我们首先分析了毒性因素，然后研究了LLMs的内在毒性属性，以确定它们作为评估器的适用性。随后，我们对评估数据集上的度量指标LLMs As ToxiciTy Evaluators（LATTE）进行了评估。实证结果表明，在不进行训练过程的情况下，我们的度量在测量毒性方面表现出色，F1得分比现有技术指标提高了12个百分点。我们还展示了上游毒性对度量结果的影响。

    In the pursuit of developing Large Language Models (LLMs) that adhere to societal standards, it is imperative to discern the existence of toxicity in the generated text. The majority of existing toxicity metrics rely on encoder models trained on specific toxicity datasets. However, these encoders are susceptible to out-of-distribution (OOD) problems and depend on the definition of toxicity assumed in a dataset. In this paper, we introduce an automatic robust metric grounded on LLMs to distinguish whether model responses are toxic. We start by analyzing the toxicity factors, followed by examining the intrinsic toxic attributes of LLMs to ascertain their suitability as evaluators. Subsequently, we evaluate our metric, LLMs As ToxiciTy Evaluators (LATTE), on evaluation datasets.The empirical results indicate outstanding performance in measuring toxicity, improving upon state-of-the-art metrics by 12 points in F1 score without training procedure. We also show that upstream toxicity has an 
    
[^19]: 不需搜索即可实现大师级国际象棋对局

    Grandmaster-Level Chess Without Search

    [https://arxiv.org/abs/2402.04494](https://arxiv.org/abs/2402.04494)

    本研究通过在庞大的国际象棋数据集上进行训练，使用了一个270M参数的Transformer模型，不依赖于复杂的启发式算法或显式搜索，取得了大师级水平的国际象棋对局的成功。模型在Lichess闪电战评分上达到了2895，解决了一系列具有挑战性的国际象棋谜题，优于AlphaZero和GPT-3.5-turbo-instruct。通过系统研究，我们发现大规模的模型和数据集对于实现强大的国际象棋对局效果是至关重要的。

    

    最新的机器学习的突破性成功主要归功于规模化，即基于注意力的大规模架构和空前规模的数据集。本文研究了对国际象棋的大规模训练的影响。与传统的依赖复杂启发式算法、显式搜索或二者结合的国际象棋引擎不同，我们通过在1000万局国际象棋对局的数据集上使用监督学习训练了一个拥有2.7亿参数的Transformer模型。我们用强大的Stockfish 16引擎提供的动作值来注释数据集中的每个棋局，产生大约150亿个数据点。我们最大的模型在Lichess闪电战Elo上达到了2895，成功解决了一系列具有挑战性的国际象棋谜题，而无需任何特定领域的调整或显式搜索算法。我们还证明了我们的模型优于AlphaZero的策略和价值网络（无MCTS）以及GPT-3.5-turbo-instruct。对模型和数据集规模的系统研究表明，强大的国际象棋对局可以在规模上取得最佳效果。

    The recent breakthrough successes in machine learning are mainly attributed to scale: namely large-scale attention-based architectures and datasets of unprecedented scale. This paper investigates the impact of training at scale for chess. Unlike traditional chess engines that rely on complex heuristics, explicit search, or a combination of both, we train a 270M parameter transformer model with supervised learning on a dataset of 10 million chess games. We annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points. Our largest model reaches a Lichess blitz Elo of 2895 against humans, and successfully solves a series of challenging chess puzzles, without any domain-specific tweaks or explicit search algorithms. We also show that our model outperforms AlphaZero's policy and value networks (without MCTS) and GPT-3.5-turbo-instruct. A systematic investigation of model and dataset size shows that strong chess 
    
[^20]: 毒性检测并不是你所需要的全部：弥合支持志愿内容管理员的差距

    Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators

    [https://arxiv.org/abs/2311.07879](https://arxiv.org/abs/2311.07879)

    本研究揭示了人工智能模型在识别有毒、冒犯和令人讨厌的内容方面的进展，并探讨了这些改进是否真正满足了志愿内容管理员在工作中的需求。

    

    人工智能模型在识别有毒、冒犯和令人讨厌的内容方面取得了长足的进展，旨在减轻管理员的工作负担。然而，目前尚不清楚这些任务的改进是否真正满足了管理员在工作中的需求。本文揭示了过去研究努力致力于为内容管理的各个方面提供自动化支持与志愿内容管理员的需求之间存在的差距，尤其是在识别违反各种管理规则方面。为此，我们在Hugging Face上对模型进行了调查，以揭示涵盖三个示范论坛的各种管理规则和指南的模型的可用性。我们进一步对最先进的LLM进行了测试，评估这些模型在标记某个特定论坛的平台规则违规方面的表现。最后，我们进行了用户调查研究。

    arXiv:2311.07879v2 Announce Type: replace-cross  Abstract: Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks have truly addressed moderators' needs in accomplishing their work. In this paper, we surface gaps between past research efforts that have aimed to provide automation for aspects of content moderation and the needs of volunteer content moderators, regarding identifying violations of various moderation rules. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines from three exemplar forums. We further put state-of-the-art LLMs to the test, evaluating how well these models perform in flagging violations of platform rules from one particular forum. Finally, we conduct a user survey stud
    
[^21]: 不要按按钮！探索机器学习和迁移学习中的数据泄露风险

    Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning. (arXiv:2401.13796v1 [cs.LG])

    [http://arxiv.org/abs/2401.13796](http://arxiv.org/abs/2401.13796)

    本文讨论了机器学习中的数据泄露问题，即未预期的信息污染训练数据，影响模型性能评估，用户可能由于缺乏理解而忽视关键步骤，导致乐观的性能估计在实际场景中不成立。

    

    机器学习（ML）在各个领域取得了革命性的进展，为多个领域提供了预测能力。然而，随着ML工具的日益可获得性，许多从业者缺乏深入的ML专业知识，采用了“按按钮”方法，利用用户友好的界面而忽视了底层算法的深入理解。虽然这种方法提供了便利，但它引发了对结果可靠性的担忧，导致了错误的性能评估等挑战。本文解决了ML中的一个关键问题，即数据泄露，其中未预期的信息污染了训练数据，影响了模型的性能评估。由于缺乏理解，用户可能会无意中忽视关键步骤，从而导致在现实场景中可能不成立的乐观性能估计。评估性能与实际在新数据上的性能的差异是一个重要的关注点。本文特别将ML中的数据泄露分为不同类别，并讨论了相关解决方法。

    Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas. However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a "push the button" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms. While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation. This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation. Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios. The discrepancy between evaluated and actual performance on new data is a significant concern. In particular, this paper categorizes data leakage in ML, discussi
    
[^22]: 在大型语言模型的问题求解中，简洁的思维链的好处

    The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models. (arXiv:2401.05618v1 [cs.CL])

    [http://arxiv.org/abs/2401.05618](http://arxiv.org/abs/2401.05618)

    本文研究了在大型语言模型中使用简洁的思维链提示对问题求解的影响，实验结果表明简洁性不仅降低了回答长度，且对问题解决性能影响可以忽略。然而在数学问题上有一定的性能下降。这对AI系统工程师和研究人员都有实际意义。

    

    在本文中，我们介绍了简洁的思维链(CCoT)提示。我们将标准的CoT和CCoT提示进行比较，以了解简洁性对回答长度和正确答案准确性的影响。我们使用GPT-3.5和GPT-4进行了多项选择问答(MCQA)基准的评估。CCoT将GPT-3.5和GPT-4的平均回答长度分别减少了48.70％，对问题解决性能几乎没有影响。然而，在数学问题上，带有CCoT的GPT-3.5会导致性能下降27.69％。总体而言，CCoT导致每个标记的成本平均降低了22.67％。这些结果对于使用CoT提示工程技术的AI系统工程师来解决真实世界问题的LLM具有实际意义。此外，这些结果为研究LLM中逐步推理的形成行为的AI研究人员提供了更广泛的见解。

    In this paper, we introduce Concise Chain-of-Thought (CCoT) prompting. We compared standard CoT and CCoT prompts to see how conciseness impacts response length and correct-answer accuracy. We evaluated this using GPT-3.5 and GPT-4 with a multiple-choice question-and-answer (MCQA) benchmark. CCoT reduced average response length by 48.70% for both GPT-3.5 and GPT-4 while having a negligible impact on problem-solving performance. However, on math problems, GPT-3.5 with CCoT incurs a performance penalty of 27.69%. Overall, CCoT leads to an average per-token cost reduction of 22.67%. These results have practical implications for AI systems engineers using LLMs to solve real-world problems with CoT prompt-engineering techniques. In addition, these results provide more general insight for AI researchers studying the emergent behavior of step-by-step reasoning in LLMs.
    
[^23]: Robust-MBFD：使用多个深度学习训练策略和一种新的双损失函数进行电机轴承故障检测的稳健深度学习系统

    Robust-MBFD: A Robust Deep Learning System for Motor Bearing Faults Detection Using Multiple Deep Learning Training Strategies and A Novel Double Loss Function. (arXiv:2310.11477v1 [cs.LG])

    [http://arxiv.org/abs/2310.11477](http://arxiv.org/abs/2310.11477)

    本文提出了一种稳健的深度学习系统用于电机轴承故障检测，采用多个深度学习训练策略和一种新的双损失函数。通过对比评估不同系统并寻找最佳模型，我们展示了该系统对各种电机轴承故障的有效性。

    

    本文提出了对电机轴承故障检测（MBFD）进行全面分析的方法，该方法基于振动信号识别电机轴承的故障。首先，我们提出并评估了多种基于机器学习的MBFD系统。此外，我们还提出了三种基于深度学习的MBFD系统，分别探索了监督学习、半监督学习和无监督学习这三种训练策略。对提出的机器学习系统和深度学习系统进行了评估和比较，并找出了适用于MBFD任务的最佳模型。我们在包括美国机械故障预防技术协会（MFPT）、凯斯西储大学轴承中心（CWRU）和帕德博恩大学的电机驱动系统轴承损伤状态监测等不同基准数据集上进行了大量实验。

    This paper presents a comprehensive analysis of motor bearing fault detection (MBFD), which involves the task of identifying faults in a motor bearing based on its vibration. To this end, we first propose and evaluate various machine learning based systems for the MBFD task. Furthermore, we propose three deep learning based systems for the MBFD task, each of which explores one of the following training strategies: supervised learning, semi-supervised learning, and unsupervised learning. The proposed machine learning based systems and deep learning based systems are evaluated, compared, and then they are used to identify the best model for the MBFD task. We conducted extensive experiments on various benchmark datasets of motor bearing faults, including those from the American Society for Mechanical Failure Prevention Technology (MFPT), Case Western Reserve University Bearing Center (CWRU), and the Condition Monitoring of Bearing Damage in Electromechanical Drive Systems from Paderborn U
    
[^24]: FedLPA: 使用分层后验聚合的个性化单次联邦学习

    FedLPA: Personalized One-shot Federated Learning with Layer-Wise Posterior Aggregation. (arXiv:2310.00339v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.00339](http://arxiv.org/abs/2310.00339)

    本文提出了一种名为FedLPA的新颖方法，采用分层后验聚合的方式实现个性化单次联邦学习。FedLPA能够高效地将本地模型聚合到全局模型，解决了单次聚合在非相同训练数据分布下的性能问题。

    

    将本地客户端训练的神经网络高效地聚合到服务器上的全局模型是联邦学习中的一个广泛研究课题。最近，受到隐私问题减少、潜在攻击减弱和通信开销降低的推动，单次联邦学习（即将客户端与服务器间的通信限制为一轮）在研究者中越来越受欢迎。然而，单次聚合的性能容易受到非相同训练数据分布的影响，在一些实际场景中表现出高度的统计异质性。为了解决这个问题，我们提出了一种新颖的单次聚合方法——分层后验聚合（FedLPA）。FedLPA能够聚合本地模型，获得更准确的全局模型，而无需额外的辅助数据集或暴露任何机密的本地信息，比如标签分布。

    Efficiently aggregating trained neural networks from local clients into a global model on a server is a widely researched topic in federated learning. Recently, motivated by diminishing privacy concerns, mitigating potential attacks, and reducing the overhead of communication, one-shot federated learning (i.e., limiting client-server communication into a single round) has gained popularity among researchers. However, the one-shot aggregation performances are sensitively affected by the non-identical training data distribution, which exhibits high statistical heterogeneity in some real-world scenarios. To address this issue, we propose a novel one-shot aggregation method with Layer-wise Posterior Aggregation, named FedLPA. FedLPA aggregates local models to obtain a more accurate global model without requiring extra auxiliary datasets or exposing any confidential local information, e.g., label distributions. To effectively capture the statistics maintained in the biased local datasets in
    
[^25]: 具有广义可加效用网络的离散选择模型

    Discrete-Choice Model with Generalized Additive Utility Network. (arXiv:2309.16970v1 [cs.AI])

    [http://arxiv.org/abs/2309.16970](http://arxiv.org/abs/2309.16970)

    本论文提出了一种基于广义可加模型的神经网络架构，称为广义可加效用网络（GAUNet），用于离散选择模型。这些模型在预测准确性上可以与ASU-DNN相媲美，并且相比以前的模型具有更好的解释性。

    

    离散选择模型是分析决策行为的强大框架，为政策制定者和企业提供有价值的见解。在实践中，使用线性效用函数的多项式逻辑模型（MNLs）因其易于使用和可解释性而被广泛使用。最近，已经开发了具有神经网络（例如ASU-DNN）的MNLs，并且在行为选择的预测精度上比传统MNLs更高。然而，这些模型由于复杂结构而缺乏解释性。我们基于广义可加模型开发了一种具有新颖神经网络架构的效用函数，称为广义可加效用网络（GAUNet），用于离散选择模型。我们使用在东京收集的出行调查数据评估了具有GAUNet的MNL的性能。我们的模型在准确性上与ASU-DNN相当，并且相比以前的模型具有改进的解释性。

    Discrete-choice models are a powerful framework for analyzing decision-making behavior to provide valuable insights for policymakers and businesses. Multinomial logit models (MNLs) with linear utility functions have been used in practice because they are ease to use and interpretable. Recently, MNLs with neural networks (e.g., ASU-DNN) have been developed, and they have achieved higher prediction accuracy in behavior choice than classical MNLs. However, these models lack interpretability owing to complex structures. We developed utility functions with a novel neural-network architecture based on generalized additive models, named generalized additive utility network ( GAUNet), for discrete-choice models. We evaluated the performance of the MNL with GAUNet using the trip survey data collected in Tokyo. Our models were comparable to ASU-DNN in accuracy and exhibited improved interpretability compared to previous models.
    
[^26]: 机器辅助的混合方法：用人工智能增强人文社科研究

    Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence. (arXiv:2309.14379v1 [cs.CL])

    [http://arxiv.org/abs/2309.14379](http://arxiv.org/abs/2309.14379)

    本研究提出了一种机器辅助的混合方法框架，利用大规模语言模型在人文社科领域的数据分析中的应用潜力，展示了16个案例研究，并涵盖了多种任务，包括语言分析、文本挖掘、社交网络推断等。

    

    大规模语言模型（LLM）的不断进化为人文社科领域的数据分析提供了前所未有的机会，能够在以前通常由人力完成的定性分析任务中实现规模化、自动化。本研究提出了一种系统的混合方法框架，以利用定性分析专业知识、机器的可扩展性和严谨的量化方法，同时注重透明度和可复制性。研究展示了16个机器辅助的案例研究作为概念验证。任务包括语言和话语分析、词汇语义变化检测、采访分析、历史事件因果推断和文本挖掘、政治立场检测、文本和思想重复使用、文学和电影中的文类构成、社交网络推断、自动词典编纂、元数据补充和多模态视觉文化分析。与现有LLM应用文献中对英文的关注不同，本研究涵盖多种语言。

    The increasing capacities of large language models (LLMs) present an unprecedented opportunity to scale up data analytics in the humanities and social sciences, augmenting and automating qualitative analytic tasks previously typically allocated to human labor. This contribution proposes a systematic mixed methods framework to harness qualitative analytic expertise, machine scalability, and rigorous quantification, with attention to transparency and replicability. 16 machine-assisted case studies are showcased as proof of concept. Tasks include linguistic and discourse analysis, lexical semantic change detection, interview analysis, historical event cause inference and text mining, detection of political stance, text and idea reuse, genre composition in literature and film; social network inference, automated lexicography, missing metadata augmentation, and multimodal visual cultural analytics. In contrast to the focus on English in the emerging LLM applicability literature, many exampl
    
[^27]: Embed-Search-Align: 使用Transformer模型进行DNA序列对齐

    Embed-Search-Align: DNA Sequence Alignment using Transformer Models. (arXiv:2309.11087v1 [q-bio.GN])

    [http://arxiv.org/abs/2309.11087](http://arxiv.org/abs/2309.11087)

    这项研究使用Transformer模型对DNA序列进行对齐，通过生成数值表示来实现。相比传统方法，该方法在短DNA序列的分类任务上取得了更好的性能，对于基因组学分析具有潜在的应用价值。

    

    DNA序列对齐涉及将短DNA读取分配到广泛的参考基因组上的最可能位置。这个过程对于各种基因组学分析至关重要，包括变异调用、转录组学和表观基因组学。传统方法经过数十年的改进，以两个步骤解决这个挑战：先进行基因组索引，然后进行高效搜索以确定给定读取的可能位置。在大规模语言模型（LLM）在将文本编码为嵌入向量方面取得成功的基础上，最近的研究努力探索了是否可以使用相同的Transformer架构为DNA序列生成数值表示。这样的模型已经在涉及分类短DNA序列的任务中显示出早期的潜力，例如检测编码和非编码区域以及识别增强子和启动子序列。然而，序列分类任务的性能并不能直接应用于序列对齐任务，对齐任务的关键是在保持序列相似性的同时找到最佳的对应位置。

    DNA sequence alignment involves assigning short DNA reads to the most probable locations on an extensive reference genome. This process is crucial for various genomic analyses, including variant calling, transcriptomics, and epigenomics. Conventional methods, refined over decades, tackle this challenge in two steps: genome indexing followed by efficient search to locate likely positions for given reads. Building on the success of Large Language Models (LLM) in encoding text into embeddings, where the distance metric captures semantic similarity, recent efforts have explored whether the same Transformer architecture can produce numerical representations for DNA sequences. Such models have shown early promise in tasks involving classification of short DNA sequences, such as the detection of coding vs non-coding regions, as well as the identification of enhancer and promoter sequences. Performance at sequence classification tasks does not, however, translate to sequence alignment, where i
    
[^28]: 揭示对DNN可执行文件的单位翻转攻击

    Unveiling Signle-Bit-Flip Attacks on DNN Executables. (arXiv:2309.06223v1 [cs.CR])

    [http://arxiv.org/abs/2309.06223](http://arxiv.org/abs/2309.06223)

    针对由深度学习编译器编译的DNN可执行文件的单位翻转攻击进行了系统研究，设计了自动搜索工具以识别易受攻击的位，并确定了实际攻击向量，揭示了DNN可执行文件的攻击面。

    

    最近的研究表明，位翻转攻击(BFA)可以通过DRAM Rowhammer利用来操纵深度神经网络(DNN)。现有的攻击主要针对高级DNN框架（如PyTorch）中的模型权重文件进行位翻转。然而，DNN经常通过深度学习编译器编译成低级可执行文件，以充分利用低级硬件原语。编译后的代码通常速度很快，并且与高级DNN框架具有明显不同的执行范式。本文针对由DL编译器编译的DNN可执行文件的BFA攻击面进行了首次系统研究。我们设计了一种自动搜索工具，用于识别DNN可执行文件中的易受攻击位，并确定利用BFAs攻击DNN可执行文件中的模型结构的实际攻击向量（而以前的工作通常对攻击模型权重做出了强假设）。DNN可执行文件似乎比高级DNN中的模型更加“不透明”。

    Recent research has shown that bit-flip attacks (BFAs) can manipulate deep neural networks (DNNs) via DRAM Rowhammer exploitations. Existing attacks are primarily launched over high-level DNN frameworks like PyTorch and flip bits in model weight files. Nevertheless, DNNs are frequently compiled into low-level executables by deep learning (DL) compilers to fully leverage low-level hardware primitives. The compiled code is usually high-speed and manifests dramatically distinct execution paradigms from high-level DNN frameworks.  In this paper, we launch the first systematic study on the attack surface of BFA specifically for DNN executables compiled by DL compilers. We design an automated search tool to identify vulnerable bits in DNN executables and identify practical attack vectors that exploit the model structure in DNN executables with BFAs (whereas prior works make likely strong assumptions to attack model weights). DNN executables appear more "opaque" than models in high-level DNN 
    
[^29]: Granger因果的分层技能发现

    Granger-Causal Hierarchical Skill Discovery. (arXiv:2306.09509v1 [cs.AI])

    [http://arxiv.org/abs/2306.09509](http://arxiv.org/abs/2306.09509)

    本文介绍了一种名为HIntS的算法，使用无监督检测器，基于Granger因果性捕捉因素之间的关键事件，发现和训练一系列操作因素化环境中的因素的技能，其展示了在机器人推动任务上有2-3倍的样本效率和最终性能的提高，有效的处理了复杂问题和转移学习。

    

    强化学习已经在学习复杂任务的策略方面显示出了有希望的结果，但往往会遭受低样本效率和有限转移的问题。本文介绍了一种名为HIntS的算法，它使用学习得到的交互检测器来发现和训练一系列技能，这些技能操作因素化环境中的因素。受Granger因果性的启发，这些无监督检测器捕捉到因素之间的关键事件，以便高效地学习有用的技能，并将这些技能转移到其他相关任务，这些任务是许多强化学习技术所面临的困境。我们在一个带有障碍物的机器人推动任务上评估了HIntS - 这是一个具有挑战性的领域，在这个领域，其他RL和HRL方法都表现不佳。学习到的技能不仅展示了使用Breakout的变体的转移，而且与可比较的强化学习基线相比，还表现出2-3倍的样本效率和最终性能的提高。HIntS一起证明了一种层次结构的技能发现方法，可以处理复杂问题。

    Reinforcement Learning (RL) has shown promising results learning policies for complex tasks, but can often suffer from low sample efficiency and limited transfer. We introduce the Hierarchy of Interaction Skills (HIntS) algorithm, which uses learned interaction detectors to discover and train a hierarchy of skills that manipulate factors in factored environments. Inspired by Granger causality, these unsupervised detectors capture key events between factors to sample efficiently learn useful skills and transfer those skills to other related tasks -- tasks where many reinforcement learning techniques struggle. We evaluate HIntS on a robotic pushing task with obstacles -- a challenging domain where other RL and HRL methods fall short. The learned skills not only demonstrate transfer using variants of Breakout, a common RL benchmark, but also show 2-3x improvement in both sample efficiency and final performance compared to comparable RL baselines. Together, HIntS demonstrates a proof of co
    
[^30]: AI艺术策展：重新构想赫尔辛基市艺术双年展

    AI Art Curation: Re-imagining the city of Helsinki in occasion of its Biennial. (arXiv:2306.03753v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.03753](http://arxiv.org/abs/2306.03753)

    本研究通过AI策展和观众互动，利用机器学习模型重新构想了赫尔辛基市艺术双年展，使用视觉-文本模型将室内艺术品放置在公共空间中，生成合成的360艺术全景图，以创造出艺术品与城市空间的新视角。

    

    艺术策展实践的特点是以知识的方式展示艺术收藏品。机器过程的特点是它们能够处理和分析大量数据。本文设想了AI策展和观众互动，以探索当代机器学习模型对策展界的影响。该项目是为2023年赫尔辛基艺术双年展的场合而开发的，题为“可能出现新的方向”。我们使用赫尔辛基艺术博物馆（HAM）的藏品，通过机器感知的视角重新构想了赫尔辛基市。我们使用视觉-文本模型在公共空间中展示室内艺术品，根据相似性评分分配虚构的坐标。我们通过生成合成的360艺术全景图来改变每件艺术品在城市中的所处空间。我们通过估计每件艺术品位置的360全景图的深度值和机器生成的艺术品提示来指导生成过程。这个项目的结果就是...

    Art curatorial practice is characterized by the presentation of an art collection in a knowledgeable way. Machine processes are characterized by their capacity to manage and analyze large amounts of data. This paper envisages AI curation and audience interaction to explore the implications of contemporary machine learning models for the curatorial world. This project was developed for the occasion of the 2023 Helsinki Art Biennial, entitled New Directions May Emerge. We use the Helsinki Art Museum (HAM) collection to re-imagine the city of Helsinki through the lens of machine perception. We use visual-textual models to place indoor artworks in public spaces, assigning fictional coordinates based on similarity scores. We transform the space that each artwork inhabits in the city by generating synthetic 360 art panoramas. We guide the generation estimating depth values from 360 panoramas at each artwork location, and machine-generated prompts of the artworks. The result of this project i
    
[^31]: 动态占据网格地图的深度雷达逆向传感器模型

    Deep Radar Inverse Sensor Models for Dynamic Occupancy Grid Maps. (arXiv:2305.12409v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.12409](http://arxiv.org/abs/2305.12409)

    该研究提出了一种基于深度学习的雷达逆向传感器模型，用于将稀疏雷达检测映射到极坐标测量网格，并生成动态网格地图，实验结果表明该方法优于手工制作的几何ISM。与最先进的深度学习方法相比，该方法为从有限视场的雷达中学习极坐标方案的单帧测量网格的第一个方法。

    

    实现自动驾驶的一个重要步骤是基于传感器输入对车辆环境进行建模。由于其众所周知的优势，雷达成为推断围绕车辆的网格单元占用状态的流行选择。为了解决雷达检测数据稀疏性和噪声问题，我们提出了一种基于深度学习的逆向传感器模型（ISM），用于学习从稀疏雷达检测到极坐标测量网格的映射。改进的基于激光雷达测量的网格用作参考。学习到的雷达测量网格与雷达多普勒速度测量相结合，进一步用于生成动态网格地图（DGM）。在实际的高速公路情景实验中表明，我们的方法优于手工制作的几何ISM。与最先进的深度学习方法相比，我们的方法是第一个从有限视场（FOV）的雷达中学习极坐标方案的单帧测量网格的方法。学习框架使学习到的ISM可以直接嵌入到现有的贝叶斯状态估计方案中，以提高环境建模的准确性。

    To implement autonomous driving, one essential step is to model the vehicle environment based on the sensor inputs. Radars, with their well-known advantages, became a popular option to infer the occupancy state of grid cells surrounding the vehicle. To tackle data sparsity and noise of radar detections, we propose a deep learning-based Inverse Sensor Model (ISM) to learn the mapping from sparse radar detections to polar measurement grids. Improved lidar-based measurement grids are used as reference. The learned radar measurement grids, combined with radar Doppler velocity measurements, are further used to generate a Dynamic Grid Map (DGM). Experiments in real-world highway scenarios show that our approach outperforms the hand-crafted geometric ISMs. In comparison to state-of-the-art deep learning methods, our approach is the first one to learn a single-frame measurement grid in the polar scheme from radars with a limited Field Of View (FOV). The learning framework makes the learned ISM
    
[^32]: 开放世界持续学习：统一新颖性检测与持续学习

    Open-World Continual Learning: Unifying Novelty Detection and Continual Learning. (arXiv:2304.10038v1 [cs.LG])

    [http://arxiv.org/abs/2304.10038](http://arxiv.org/abs/2304.10038)

    本文从理论上证明，分布外检测对于类别增量学习是必要的，因为类别增量学习可以分解成任务内预测和任务 ID 预测，并且任务 ID 预测与分布外检测相关。

    

    随着 AI agent 在未知或新奇的真实开放世界中的使用增加，它们需要具备 (1) 认识已经学习过的物体和检测到之前未见或学习的物体的能力，以及 (2) 增量地学习新物品，逐渐变得更有知识和更强大。 (1) 称为新颖性检测或分布外 (OOD) 检测，而 (2) 称为类别增量学习 (CIL)，是持续学习 (CL) 的一种设置。在现有的研究中，OOD 检测和 CIL 被视为两个完全不同的问题。本文从理论上证明了 OOD 检测实际上对于 CIL 是必要的。我们首先展示 CIL 可以分解为两个子问题：任务内预测 (WP) 和任务 ID 预测(TP)。然后我们证明了 TP 与 OOD 检测相关。关键的理论结果是，无论 WP 和 OOD 检测（或 TP）是否由 CIL 算法显式或隐式地定义，好的 WP 和良好的 OOD 检测或 TP 总是存在嵌入在任何 CIL 算法中的。

    As AI agents are increasingly used in the real open world with unknowns or novelties, they need the ability to (1) recognize objects that (i) they have learned and (ii) detect items that they have not seen or learned before, and (2) learn the new items incrementally to become more and more knowledgeable and powerful. (1) is called novelty detection or out-of-distribution (OOD) detection and (2) is called class incremental learning (CIL), which is a setting of continual learning (CL). In existing research, OOD detection and CIL are regarded as two completely different problems. This paper theoretically proves that OOD detection actually is necessary for CIL. We first show that CIL can be decomposed into two sub-problems: within-task prediction (WP) and task-id prediction (TP). We then prove that TP is correlated with OOD detection. The key theoretical result is that regardless of whether WP and OOD detection (or TP) are defined explicitly or implicitly by a CIL algorithm, good WP and go
    
[^33]: Robustmix：通过正则化深度网络的频率偏差来提高鲁棒性

    Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets. (arXiv:2304.02847v1 [cs.CV])

    [http://arxiv.org/abs/2304.02847](http://arxiv.org/abs/2304.02847)

    本研究提出一种叫做Robustmix的方法，通过正则化网络以低频空间特征进行分类来提高深度网络的鲁棒性，在Imagenet-C和Stylized Imagenet等基准测试上取得了最新的最优状态平均峰值误差（mCE），在避免计算开销和先验知识的大量图像变换的同时对模型架构和数据增强的最新进展提供了补充。

    

    深度网络在一系列经过精心策划的基准数据集上取得了令人印象深刻的结果。令人惊讶的是，它们的性能对于对人类性能几乎没有影响的扰动仍然很敏感。在这项工作中，我们提出了一种名为Robustmix的Mixup新扩展，该扩展通过正则化网络以基于低频空间特征进行分类。我们表明，这种类型的正则化改善了在一系列基准测试中的鲁棒性，例如Imagenet-C和Stylized Imagenet。它几乎没有计算开销，并且不需要先验知识的大量图像变换。我们发现，这种方法进一步补充了模型架构和数据增强的最新进展，使用EfficientNet-B8模型和RandAugment达到了44.8的最新状态平均峰值误差（mCE），相比基线降低了16个mCE。

    Deep networks have achieved impressive results on a range of well-curated benchmark datasets. Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance. In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features. We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet. It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations. We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline.
    
[^34]: 构造数：如何建立一个图形？

    Construction numbers: How to build a graph?. (arXiv:2302.13186v2 [math.CO] UPDATED)

    [http://arxiv.org/abs/2302.13186](http://arxiv.org/abs/2302.13186)

    论文研究了计算偏序的线性扩展数量问题，并研究了由包含关系确定的图形的顶点和边的偏序，找到了路径、环、星形图、双星形图和完全图的构造序列数量，并提出了公式，同时研究了结构和应用。

    

    约50年前，斯坦利考虑了计算偏序的线性扩展数量问题。对于由包含关系确定的图形的顶点和边的偏序，我们称这样的线性扩展为图形的“构造序列”，因为每个边都遵循其两个端点。我们找到了路径、环、星形图、双星形图和完全图的此类序列数量。对于路径，我们认同斯坦利的想法（切线数），并得到了其他类型的公式。此外还研究了结构和应用。

    Counting the number of linear extensions of a partial order was considered by Stanley about 50 years ago. For the partial order on the vertices and edges of a graph determined by inclusion, we call such linear extensions {\it construction sequences} for the graph as each edge follows both of its endpoints. The number of such sequences for paths, cycles, stars, double-stars, and complete graphs is found. For paths, we agree with Stanley (the Tangent numbers) and get formulas for the other classes. Structure and applications are also studied.
    
[^35]: 文字对话中的深度情感识别：一项调研

    Deep Emotion Recognition in Textual Conversations: A Survey. (arXiv:2211.09172v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.09172](http://arxiv.org/abs/2211.09172)

    本调研针对对话中的情感识别进行了探讨，介绍了涉及此任务的挑战和机遇，以及描述了情感分类法和使用该分类法的基准数据集。调研总结了最重要的作品和所使用的深度学习架构，并提供了建议性的情感识别实践，以实现更好的框架。

    

    虽然近年来对话中的情感识别取得了巨大的进展，但新的应用和实施场景带来了新的挑战和机遇。这些挑战包括利用对话语境、说话人和情感动态建模，解释常识表达、非正式语言和讽刺，应对实时情感识别的挑战，识别情感原因，不同数据集中的多种分类法，多语言情感识别以及解释性。本调研首先介绍了情感识别在对话中的应用，详细说明了与此任务相关的挑战和机遇。然后，它介绍了情感分类法和多种使用该分类法的情感识别基准数据集的描述。接下来，它描述了情感识别中最重要的作品，并解释了所使用的深度学习架构。最后，它提供了对于更好的框架的建议性情感识别实践，详细说明了处理主观性的方法。

    While Emotion Recognition in Conversations (ERC) has seen a tremendous advancement in the last few years, new applications and implementation scenarios present novel challenges and opportunities. These range from leveraging the conversational context, speaker and emotion dynamics modelling, to interpreting common sense expressions, informal language and sarcasm, addressing challenges of real time ERC, recognizing emotion causes, different taxonomies across datasets, multilingual ERC to interpretability. This survey starts by introducing ERC, elaborating on the challenges and opportunities pertaining to this task. It proceeds with a description of the emotion taxonomies and a variety of ERC benchmark datasets employing such taxonomies. This is followed by descriptions of the most prominent works in ERC with explanations of the Deep Learning architectures employed. Then, it provides advisable ERC practices towards better frameworks, elaborating on methods to deal with subjectivity in ann
    
[^36]: 使用于无标度在线学习的等调节技术

    Isotuning With Applications To Scale-Free Online Learning. (arXiv:2112.14586v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.14586](http://arxiv.org/abs/2112.14586)

    我们提出了一种用于无标度在线学习的等调节技术，该技术具有快速、自适应、随时随地和无标度的特点，并可以自动适应遗憾的速率。同时，我们还引入了在线校正的方法来改进算法的性能。

    

    我们扩展和结合了文献中的几种方法，设计了快速、自适应、随时随地和无标度的在线学习算法。无标度的遗憾界限必须与最大损失成线性关系，不论是对于大损失还是对于非常小的损失。自适应的遗憾界限表明算法可以利用简单的数据并可能具有常数遗憾。我们致力于开发尽可能少依赖参数的快速算法，特别是它们应该是随时可用的，因此不依赖于时间范围。我们的第一个和主要工具是等调节技术，它是平衡遗憾权衡的思想的推广。我们开发了一套工具来轻松设计和分析这样的学习速度，并展示它们能够自动适应遗憾的速率（无论是常数、$O(\log T)$、$O(\sqrt{T})$等），并且在同样的观察量上比在事后选择的最优学习速度高出2倍。第二个工具是在线校正，它使我们能够获得...

    We extend and combine several tools of the literature to design fast, adaptive, anytime and scale-free online learning algorithms. Scale-free regret bounds must scale linearly with the maximum loss, both toward large losses and toward very small losses. Adaptive regret bounds demonstrate that an algorithm can take advantage of easy data and potentially have constant regret. We seek to develop fast algorithms that depend on as few parameters as possible, in particular they should be anytime and thus not depend on the time horizon. Our first and main tool, isotuning, is a generalization of the idea of balancing the trade-off of the regret. We develop a set of tools to design and analyze such learning rates easily and show that they adapts automatically to the rate of the regret (whether constant, $O(\log T)$, $O(\sqrt{T})$, etc.) within a factor 2 of the optimal learning rate in hindsight for the same observed quantities. The second tool is an online correction, which allows us to obtain
    

