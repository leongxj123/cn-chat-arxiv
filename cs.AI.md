# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [KTO: Model Alignment as Prospect Theoretic Optimization](https://rss.arxiv.org/abs/2402.01306) | 本文提出了一种名为KTO的方法，将模型对齐视为展望理论优化。与当前方法相比，KTO直接最大化生成效用而不是最大化偏好对数似然。在多个规模上，KTO的性能与基于偏好的方法相当甚至更好。 |
| [^2] | [Recurrent Transformers with Dynamic Halt](https://rss.arxiv.org/abs/2402.00976) | 本文研究了增强Transformer与循环机制的两种方法，并提出了新的扩展和组合方法。在多个诊断任务中进行比较，探索它们的归纳偏好。 |
| [^3] | [PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving](https://arxiv.org/abs/2404.01596) | PhysORD是一种神经符号方法，将物理定律融入神经模型中，显著提高了在越野驾驶中的运动预测泛化能力。 |
| [^4] | [Graph Neural Networks for Treatment Effect Prediction](https://arxiv.org/abs/2403.19289) | 提出了一种图神经网络来减少治疗效果预测所需的训练集大小，有效利用电子商务数据的图结构，为治疗效果预测带来新的可能性 |
| [^5] | [A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond](https://arxiv.org/abs/2403.14734) | 神经代码智能领域的调查系统回顾了50多种代表性模型和超过680项相关作品，突出了不同研究阶段的范式和技术转变。 |
| [^6] | [Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection](https://arxiv.org/abs/2403.12172) | 提出了一种名为GiCiSAD的基于图拼图条件扩散模型，用于解决基于骨架的视频异常检测中的挑战。 |
| [^7] | [Tur[k]ingBench: A Challenge Benchmark for Web Agents](https://arxiv.org/abs/2403.11905) | Tur[k]ingBench是一个挑战性的网络代理基准测试，用于评估最先进的多模态模型在处理包含文本指示和多模态上下文的复杂任务时的泛化能力。 |
| [^8] | [How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments](https://arxiv.org/abs/2403.11807) | 通过博弈论视角评估LLMs的决策能力，结果表明GPT-3.5在稳健性方面表现良好，但泛化能力有限，而GPT-4则优于其他模型。 |
| [^9] | [Correcting misinformation on social media with a large language model](https://arxiv.org/abs/2403.11169) | 提出了一种名为MUSE的大型语言模型，通过访问最新信息并评估可信度，以解决社交媒体上误信息纠正的难题。 |
| [^10] | [Strict Partitioning for Sporadic Rigid Gang Tasks](https://arxiv.org/abs/2403.10726) | 提出了一种新的严格分区调度策略，用于零星刚性流式任务，通过创建不相交的任务和处理器分区，并尝试将相似容量的任务分配给同一分区，以减少干扰。 |
| [^11] | [Non-discrimination Criteria for Generative Language Models](https://arxiv.org/abs/2403.08564) | 本文研究如何在生成式语言模型中识别和量化性别偏见，提出了三个生成式人工智能的非歧视标准并设计了相应的提示。 |
| [^12] | [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](https://arxiv.org/abs/2403.06764) | FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。 |
| [^13] | [Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models](https://arxiv.org/abs/2402.19465) | 本文研究探索了大型语言模型在预训练期间的可信度，揭示了早期预训练LLMs已经能够区分各个可信度维度中的概念，提出了从预训练检查点中提取转向向量以增强LLM可信度的方法。 |
| [^14] | [Into the Unknown: Self-Learning Large Language Models](https://arxiv.org/abs/2402.09147) | 本研究关注自学习大型语言模型的核心问题：如何学习未知知识。提出了一种自学习框架，通过自我评估和识别未知点来独立学习以前未知的知识。实验证明该方法对于减少幻觉评分、实现高效LLM更新以及知识交流具有重要意义。 |
| [^15] | [FRDiff : Feature Reuse for Universal Training-free Acceleration of Diffusion Models](https://arxiv.org/abs/2312.03517) | 引入了一种新的加速技术FRDiff，通过利用扩散模型的时间冗余性，重新使用具有高时间相似性的特征图，节省计算资源而不影响输出质量。 |
| [^16] | [Explaining Explanations in Probabilistic Logic Programming.](http://arxiv.org/abs/2401.17045) | 该论文介绍了基于概率逻辑编程的解释解释方法，以解决在不透明系统中生成合适解释的困难。 |
| [^17] | [Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine.](http://arxiv.org/abs/2401.08396) | GPT-4 Vision在医学领域中具有专家级准确度，但在图像理解方面存在缺陷。 |
| [^18] | [Do Concept Bottleneck Models Obey Locality?.](http://arxiv.org/abs/2401.01259) | 本文研究了概念瓶颈模型（CBMs）是否能够正确捕捉到概念之间的条件独立程度，通过分析对于概念局部性之外特征的变化如何影响概念的预测。 |
| [^19] | [Disentangling the Potential Impacts of Papers into Diffusion, Conformity, and Contribution Values.](http://arxiv.org/abs/2311.09262) | 这项研究提出了一种新颖的图神经网络（称为DPPDCC），用于将论文的潜在影响分解为传播、一致性和贡献值。通过编码时态和结构特征，捕捉知识流动，并使用对比增强图揭示流行度，进一步预测引用分组来建模一致性。应用正交约束来鼓励独特建模，并保留原始信息。 |
| [^20] | [Sentinel: An Aggregation Function to Secure Decentralized Federated Learning.](http://arxiv.org/abs/2310.08097) | Sentinel是一种用于保护分散式联邦学习的防御策略，通过利用本地数据并定义一个三步聚合协议来对抗污染攻击。评估结果表明Sentinel在不同数据集和评估指标下表现良好。 |
| [^21] | [Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT4.](http://arxiv.org/abs/2309.17277) | Suspicion-Agent是一种创新代理程序，利用具备高阶心灵理论意识的GPT4在不完全信息游戏中表现出良好的适应性和影响他人行为的能力。 |
| [^22] | [NutritionVerse: Empirical Study of Various Dietary Intake Estimation Approaches.](http://arxiv.org/abs/2309.07704) | 该论文介绍了NutritionVerse-Synth，这是一个拥有大规模合成食物图像数据集，其中包含了多种视角、模态和饮食注释，旨在解决目前饮食摄入估计方法的准确性和真实性问题。 |
| [^23] | [VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching.](http://arxiv.org/abs/2309.05027) | VoiceFlow使用矫正流匹配算法实现了高效文本转语音，并在合成质量上优于传统的扩散模型。 |
| [^24] | [Unleashing the Power of Graph Learning through LLM-based Autonomous Agents.](http://arxiv.org/abs/2309.04565) | 本文提出了一种使用大型语言模型（LLMs）作为自主代理的方法，以简化多样化的现实世界图中的学习过程，并克服了现有方法中的限制。 |
| [^25] | [MIRA: Cracking Black-box Watermarking on Deep Neural Networks via Model Inversion-based Removal Attacks.](http://arxiv.org/abs/2309.03466) | 本文提出了一种基于模型反演的去除攻击方法（\textsc{Mira}），该方法能够有效地破解大多数主流黑盒DNN水印方案，通过利用受保护模型的内部信息来恢复和消除水印信息。 |
| [^26] | [GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice.](http://arxiv.org/abs/2309.00649) | GPT通过金融素养测试显示出具备成为大众金融机器顾问的能力，其中基于GPT-4的ChatGPT几乎完美地得分99%，揭示了金融素养正在成为最先进模型的新兴能力。 |
| [^27] | [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback.](http://arxiv.org/abs/2309.00267) | RLAIF是一种新的强化学习方法，利用AI反馈代替人类标注偏好，相比强化学习从人类反馈中学习（RLHF），在摘要任务上取得了类似的改进效果，并且在人类评估中得到了相同的认可。这提供了一种有潜力解决RLHF的可扩展性限制的解决方案。 |
| [^28] | [Value-Distributional Model-Based Reinforcement Learning.](http://arxiv.org/abs/2308.06590) | 该论文介绍了一种基于价值分布模型的强化学习方法，该方法通过学习后验分布来解决决策任务中的政策不确定性问题。所提出的算法能够有效地优化策略，在连续控制任务中表现出性能优势。 |
| [^29] | [RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation.](http://arxiv.org/abs/2307.00997) | 本文介绍了RefSAM模型，该模型通过在线方式从不同时间戳的多视图信息中加入SAM的潜力，探索其在指代视频对象分割（RVOS）中的应用。通过使用跨模态MLP和分层稠密注意模块，我们改进了SAM模型，实现了对不同形态的精确理解，并取得了令人印象深刻的性能表现。 |
| [^30] | [Black-Box Prediction of Flaky Test Fix Categories Using Language Models.](http://arxiv.org/abs/2307.00012) | 本文提出了一个使用语言模型的框架，可以自动生成易出错测试的标记数据集，并通过分析测试代码来预测测试的修复类别。实验结果表明UniXcoder优于CodeBERT。 |
| [^31] | [DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model.](http://arxiv.org/abs/2306.01001) | 本文提出了一种扩散模型中的负荷预测不确定性量化方法，采用Seq2Seq网络结构来分离两种类型的不确定性并处理异常情况，不仅着眼于预测条件期望值。 |
| [^32] | [Distilling Knowledge for Short-to-Long Term Trajectory Prediction.](http://arxiv.org/abs/2305.08553) | 本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。 |
| [^33] | [Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion.](http://arxiv.org/abs/2305.03509) | Diffusion Explainer是第一个可交互的可视化工具，用于解释稳定扩散如何将文本提示转化为图像，用户可以通过动画和交互元素流畅地在多个抽象级别之间过渡，从而更好地理解提示对图像生成的影响。 |
| [^34] | [From Wide to Deep: Dimension Lifting Network for Parameter-efficient Knowledge Graph Embedding.](http://arxiv.org/abs/2303.12816) | 本文提出了一个用于实现参数高效的知识图谱嵌入的深度网络，通过增加深度克服因采用低维实体表示而导致的模型精度下降和模型参数减少有限的问题。 |

# 详细

[^1]: KTO: 模型对齐视为展望理论优化

    KTO: Model Alignment as Prospect Theoretic Optimization

    [https://rss.arxiv.org/abs/2402.01306](https://rss.arxiv.org/abs/2402.01306)

    本文提出了一种名为KTO的方法，将模型对齐视为展望理论优化。与当前方法相比，KTO直接最大化生成效用而不是最大化偏好对数似然。在多个规模上，KTO的性能与基于偏好的方法相当甚至更好。

    

    凯恩曼与特沃斯基的展望理论告诉我们，人类以有偏见但明确的方式看待随机变量；例如，人们通常都是厌恶损失的。我们证明了将LLMs与人工反馈进行对齐的目标隐含地融合了许多这些偏见 - 这些目标 (例如 DPO) 的成功部分可归因于它们是"人类感知损失函数"(HALOs)。然而，这些方法所归因给人类的效用函数仍与展望理论文献中的不同。利用凯恩曼-特沃斯基人类效用的模型，我们提出了一种直接最大化生成效用而不是最大化偏好对数似然的HALO。我们将这种方法称为凯恩曼-特沃斯基优化(KTO)，并且它在从1B到30B的规模上与基于偏好的方法的性能相匹配或超过。关键是，KTO不需要偏好 - 只需要一个是否的二进制信号。

    Kahneman & Tversky's $\textit{prospect theory}$ tells us that humans perceive random variables in a biased but well-defined manner; for example, humans are famously loss-averse. We show that objectives for aligning LLMs with human feedback implicitly incorporate many of these biases -- the success of these objectives (e.g., DPO) over cross-entropy minimization can partly be ascribed to them being $\textit{human-aware loss functions}$ (HALOs). However, the utility functions these methods attribute to humans still differ from those in the prospect theory literature. Using a Kahneman-Tversky model of human utility, we propose a HALO that directly maximizes the utility of generations instead of maximizing the log-likelihood of preferences, as current methods do. We call this approach Kahneman-Tversky Optimization (KTO), and it matches or exceeds the performance of preference-based methods at scales from 1B to 30B. Crucially, KTO does not need preferences -- only a binary signal of whether 
    
[^2]: 具有动态停止的循环Transformer

    Recurrent Transformers with Dynamic Halt

    [https://rss.arxiv.org/abs/2402.00976](https://rss.arxiv.org/abs/2402.00976)

    本文研究了增强Transformer与循环机制的两种方法，并提出了新的扩展和组合方法。在多个诊断任务中进行比较，探索它们的归纳偏好。

    

    本文研究了两种主要方法在增强Transformer与循环机制方面的归纳偏好——（1）类似于Universal Transformers的深度逐层循环方法；和（2）类似于Temporal Latent Bottleneck的分块时态循环方法。此外，我们提出并研究了扩展和组合上述方法的新方式，例如，我们提出了一种基于全局均值的Universal Transformer动态停止机制，并将Universal Transformer的元素融入到Temporal Latent Bottleneck中。我们通过多个诊断任务（如Long Range Arena（LRA），翻转-翻转语言建模，ListOps和逻辑推理）比较了模型并探索了它们的归纳偏好。

    In this paper, we study the inductive biases of two major approaches to augmenting Transformers with a recurrent mechanism - (1) the approach of incorporating a depth-wise recurrence similar to Universal Transformers; and (2) the approach of incorporating a chunk-wise temporal recurrence like Temporal Latent Bottleneck. Furthermore, we propose and investigate novel ways to extend and combine the above methods - for example, we propose a global mean-based dynamic halting mechanism for Universal Transformer and an augmentation of Temporal Latent Bottleneck with elements from Universal Transformer. We compare the models and probe their inductive biases in several diagnostic tasks such as Long Range Arena (LRA), flip-flop language modeling, ListOps, and Logical Inference.
    
[^3]: PhysORD：一种神经符号方法用于越野驾驶中注入物理学的运动预测

    PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving

    [https://arxiv.org/abs/2404.01596](https://arxiv.org/abs/2404.01596)

    PhysORD是一种神经符号方法，将物理定律融入神经模型中，显著提高了在越野驾驶中的运动预测泛化能力。

    

    运动预测对于自主越野驾驶至关重要，但与在道路上驾驶相比，它面临着更多挑战，主要是由于车辆与地形之间复杂的相互作用。传统的基于物理的方法在准确建模动态系统和外部干扰方面遇到困难。相反，基于数据驱动的神经网络需要大量数据集，并且难以明确捕捉基本的物理定律，这很容易导致泛化能力差。通过融合这两种方法的优势，神经符号方法提出了一个有前途的方向。这些方法将物理定律嵌入神经模型中，可能显著提高泛化能力。然而，以往的研究都没有在现实世界的越野驾驶环境中进行评估。为了弥合这一差距，我们提出 PhysORD，这是一种神经符号方法，集成了守恒定律，即欧拉-拉格朗日方程。

    arXiv:2404.01596v1 Announce Type: cross  Abstract: Motion prediction is critical for autonomous off-road driving, however, it presents significantly more challenges than on-road driving because of the complex interaction between the vehicle and the terrain. Traditional physics-based approaches encounter difficulties in accurately modeling dynamic systems and external disturbance. In contrast, data-driven neural networks require extensive datasets and struggle with explicitly capturing the fundamental physical laws, which can easily lead to poor generalization. By merging the advantages of both methods, neuro-symbolic approaches present a promising direction. These methods embed physical laws into neural models, potentially significantly improving generalization capabilities. However, no prior works were evaluated in real-world settings for off-road driving. To bridge this gap, we present PhysORD, a neural-symbolic approach integrating the conservation law, i.e., the Euler-Lagrange equa
    
[^4]: 用于治疗效果预测的图神经网络

    Graph Neural Networks for Treatment Effect Prediction

    [https://arxiv.org/abs/2403.19289](https://arxiv.org/abs/2403.19289)

    提出了一种图神经网络来减少治疗效果预测所需的训练集大小，有效利用电子商务数据的图结构，为治疗效果预测带来新的可能性

    

    在电子商务中估计因果效应往往涉及昂贵的治疗分配，这在大规模设置中可能是不切实际的。利用机器学习来预测这种治疗效果而无需实际干预是减少风险的一种标准做法。然而，现有的治疗效果预测方法往往依赖于大规模实验构建的训练集，因此从根本上存在风险。在这项工作中，我们提出了一种图神经网络，以减少所需的训练集大小，依赖于电子商务数据中常见的图。具体地，我们将问题视为具有有限数量标记实例的节点回归，开发了一个类似于先前因果效应估计器的双模型神经架构，并测试了不同的消息传递层进行编码。此外，作为额外步骤，我们将模型与获取函数相结合，以引导信息传递。

    arXiv:2403.19289v1 Announce Type: cross  Abstract: Estimating causal effects in e-commerce tends to involve costly treatment assignments which can be impractical in large-scale settings. Leveraging machine learning to predict such treatment effects without actual intervention is a standard practice to diminish the risk. However, existing methods for treatment effect prediction tend to rely on training sets of substantial size, which are built from real experiments and are thus inherently risky to create. In this work we propose a graph neural network to diminish the required training set size, relying on graphs that are common in e-commerce data. Specifically, we view the problem as node regression with a restricted number of labeled instances, develop a two-model neural architecture akin to previous causal effect estimators, and test varying message-passing layers for encoding. Furthermore, as an extra step, we combine the model with an acquisition function to guide the creation of th
    
[^5]: 一项神经代码智能的调查：范式、进展与未来

    A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond

    [https://arxiv.org/abs/2403.14734](https://arxiv.org/abs/2403.14734)

    神经代码智能领域的调查系统回顾了50多种代表性模型和超过680项相关作品，突出了不同研究阶段的范式和技术转变。

    

    arXiv:2403.14734v1 公告类型: 跨领域 摘要: 神经代码智能--利用深度学习理解、生成和优化代码--在整个社会上具有巨大的潜力，可产生深远影响。作为自然语言和编程语言之间的桥梁，这一领域在过去几年引起了两个研究社区研究人员的极大关注。本调查系统地和按时间顺序回顾了代码智能方面的进展，包括50多种代表性模型及其变体、20多种任务类别以及超过680项相关作品。我们遵循历史进展，跟踪不同研究阶段的范式转变（例如，从使用循环神经网络对代码建模到大型语言模型时代）。同时，我们重点介绍了不同阶段涵盖的模型、任务和评估的主要技术转变。对于应用，我们

    arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
    
[^6]: 基于图拼图条件扩散模型的基于骨架的视频异常检测

    Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection

    [https://arxiv.org/abs/2403.12172](https://arxiv.org/abs/2403.12172)

    提出了一种名为GiCiSAD的基于图拼图条件扩散模型，用于解决基于骨架的视频异常检测中的挑战。

    

    基于骨架的视频异常检测（SVAD）是计算机视觉中的一个关键任务。准确识别异常模式或事件使操作员能够及时检测可疑活动，从而增强安全性。然而，现有研究未能同时解决这些关键特性。本文引入了一种新颖、实用且轻量级的框架，即基于图拼图条件扩散模型的基于骨架的视频异常检测（GiCiSAD），以克服与SVAD相关的挑战。

    arXiv:2403.12172v1 Announce Type: cross  Abstract: Skeleton-based video anomaly detection (SVAD) is a crucial task in computer vision. Accurately identifying abnormal patterns or events enables operators to promptly detect suspicious activities, thereby enhancing safety. Achieving this demands a comprehensive understanding of human motions, both at body and region levels, while also accounting for the wide variations of performing a single action. However, existing studies fail to simultaneously address these crucial properties. This paper introduces a novel, practical and lightweight framework, namely Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection (GiCiSAD) to overcome the challenges associated with SVAD. GiCiSAD consists of three novel modules: the Graph Attention-based Forecasting module to capture the spatio-temporal dependencies inherent in the data, the Graph-level Jigsaw Puzzle Maker module to distinguish subtle region-level discrepancies bet
    
[^7]: Tur[k]ingBench：用于网络代理的挑战基准测试

    Tur[k]ingBench: A Challenge Benchmark for Web Agents

    [https://arxiv.org/abs/2403.11905](https://arxiv.org/abs/2403.11905)

    Tur[k]ingBench是一个挑战性的网络代理基准测试，用于评估最先进的多模态模型在处理包含文本指示和多模态上下文的复杂任务时的泛化能力。

    

    最近的聊天机器人展示了在原始文本形式下理解和交流的令人印象深刻的能力。然而，世界上不仅仅是原始文本。例如，人们在网页上花费大量时间，在这些网页上，文本与其他形式交织在一起，并以各种复杂互动的形式完成任务。最先进的多模型是否能够推广到这种复杂的领域呢？为了回答这个问题，我们介绍了TurkingBench，一个由包含多模态背景的文本说明制定的任务基准。与现有的使用人工合成的网页的工作不同，这里我们使用最初设计用于各种注释目的的自然HTML页面。每个任务的HTML说明也被实例化为各种值（从众包任务获得）以形成任务的新实例。这个基准包含32.2K个实例。

    arXiv:2403.11905v1 Announce Type: new  Abstract: Recent chatbots have demonstrated impressive ability to understand and communicate in raw-text form. However, there is more to the world than raw text. For example, humans spend long hours of their time on web pages, where text is intertwined with other modalities and tasks are accomplished in the form of various complex interactions. Can state-of-the-art multi-modal models generalize to such complex domains?   To address this question, we introduce TurkingBench, a benchmark of tasks formulated as web pages containing textual instructions with multi-modal context. Unlike existing work which employs artificially synthesized web pages, here we use natural HTML pages that were originally designed for crowdsourcing workers for various annotation purposes. The HTML instructions of each task are also instantiated with various values (obtained from the crowdsourcing tasks) to form new instances of the task. This benchmark contains 32.2K instanc
    
[^8]: LLM的决策水平在多智能体环境中的评估究竟如何？

    How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments

    [https://arxiv.org/abs/2403.11807](https://arxiv.org/abs/2403.11807)

    通过博弈论视角评估LLMs的决策能力，结果表明GPT-3.5在稳健性方面表现良好，但泛化能力有限，而GPT-4则优于其他模型。

    

    决策是一个复杂的任务，需要各种能力，为评估大型语言模型（LLMs）提供了一个极好的框架。我们的研究通过博弈论的视角探究LLMs的决策能力。我们专注于支持多个智能体同时参与的游戏，引入了我们的框架GAMA-Bench，包括八个经典的多智能体游戏。我们设计了一个评分方案，定量评估模型在这些游戏中的表现。通过GAMA-Bench，我们研究了LLMs的稳健性、泛化能力和增强策略。结果显示，虽然GPT-3.5表现出令人满意的稳健性，但其泛化能力相对有限。然而，通过一些方法如“思维链”，其性能可以得到提高。此外，我们对各种LLMs进行评估，发现GPT-4胜过其他模型。

    arXiv:2403.11807v1 Announce Type: new  Abstract: Decision-making, a complicated task requiring various types of abilities, presents an excellent framework for assessing Large Language Models (LLMs). Our research investigates LLMs' decision-making capabilities through the lens of a well-established field, Game Theory. We focus specifically on games that support the participation of more than two agents simultaneously. Subsequently, we introduce our framework, GAMA-Bench, including eight classical multi-agent games. We design a scoring scheme to assess a model's performance in these games quantitatively. Through GAMA-Bench, we investigate LLMs' robustness, generalizability, and enhancement strategies. Results reveal that while GPT-3.5 shows satisfying robustness, its generalizability is relatively limited. However, its performance can be improved through approaches such as Chain-of-Thought. Additionally, we conduct evaluations across various LLMs and find that GPT-4 outperforms other mod
    
[^9]: 使用大型语言模型纠正社交媒体上的错误信息

    Correcting misinformation on social media with a large language model

    [https://arxiv.org/abs/2403.11169](https://arxiv.org/abs/2403.11169)

    提出了一种名为MUSE的大型语言模型，通过访问最新信息并评估可信度，以解决社交媒体上误信息纠正的难题。

    

    误信息会破坏公众对科学和民主的信任，特别是在社交媒体上，不准确信息会迅速传播。专家和普通人通过手动识别和解释不准确信息已经被证明是有效的纠正误信息的方法。然而，这种方法很难扩展，这是一个担忧，因为大型语言模型（LLMs）等技术使误信息更容易生成。LLMs还具有多功能能力，可以加速纠正误信息；然而，它们由于缺乏最新信息、倾向于生成似是而非的内容和引用以及无法处理多模态信息而面临困难。为了解决这些问题，我们提出了MUSE，这是一个带有最新信息访问和可信度评估的LLM。通过检索上下文证据和反驳，MUSE可以提供准确可信的解释和参考。它还描述

    arXiv:2403.11169v1 Announce Type: cross  Abstract: Misinformation undermines public trust in science and democracy, particularly on social media where inaccuracies can spread rapidly. Experts and laypeople have shown to be effective in correcting misinformation by manually identifying and explaining inaccuracies. Nevertheless, this approach is difficult to scale, a concern as technologies like large language models (LLMs) make misinformation easier to produce. LLMs also have versatile capabilities that could accelerate misinformation correction; however, they struggle due to a lack of recent information, a tendency to produce plausible but false content and references, and limitations in addressing multimodal information. To address these issues, we propose MUSE, an LLM augmented with access to and credibility evaluation of up-to-date information. By retrieving contextual evidence and refutations, MUSE can provide accurate and trustworthy explanations and references. It also describes 
    
[^10]: 针对零星刚性流式任务的严格分区方法

    Strict Partitioning for Sporadic Rigid Gang Tasks

    [https://arxiv.org/abs/2403.10726](https://arxiv.org/abs/2403.10726)

    提出了一种新的严格分区调度策略，用于零星刚性流式任务，通过创建不相交的任务和处理器分区，并尝试将相似容量的任务分配给同一分区，以减少干扰。

    

    刚性流式任务模型基于在固定数量的处理器上同时执行多个线程以提高效率和性能的思想。虽然全局刚性流式调度有大量文献，但分区方法具有几个实际优势（例如任务隔离和减少调度开销）。本文提出了一种新的用于刚性流式任务的分区调度策略，称为严格分区。该方法创建任务和处理器的不相交分区，以避免分区间干扰。此外，它尝试将具有相似容量（即并行性）的任务分配给同一分区，以减少分区内干扰。在每个分区内，任务可以使用任何类型的调度器进行调度，这允许使用不那么悲观的可调度测试。大量的合成实验证明和基于Edge TPU基准的案例研究显示

    arXiv:2403.10726v1 Announce Type: cross  Abstract: The rigid gang task model is based on the idea of executing multiple threads simultaneously on a fixed number of processors to increase efficiency and performance. Although there is extensive literature on global rigid gang scheduling, partitioned approaches have several practical advantages (e.g., task isolation and reduced scheduling overheads). In this paper, we propose a new partitioned scheduling strategy for rigid gang tasks, named strict partitioning. The method creates disjoint partitions of tasks and processors to avoid inter-partition interference. Moreover, it tries to assign tasks with similar volumes (i.e., parallelisms) to the same partition so that the intra-partition interference can be reduced. Within each partition, the tasks can be scheduled using any type of scheduler, which allows the use of a less pessimistic schedulability test. Extensive synthetic experiments and a case study based on Edge TPU benchmarks show th
    
[^11]: 生成语言模型的非歧视标准

    Non-discrimination Criteria for Generative Language Models

    [https://arxiv.org/abs/2403.08564](https://arxiv.org/abs/2403.08564)

    本文研究如何在生成式语言模型中识别和量化性别偏见，提出了三个生成式人工智能的非歧视标准并设计了相应的提示。

    

    近年来，生成式人工智能，如大型语言模型，经历了快速发展。随着这些模型越来越普遍地提供给公众使用，人们开始担心在应用中延续和放大有害偏见的问题。性别刻板印象可能对其针对的个人造成伤害和限制，无论是由误传还是歧视所构成。识别性别偏见作为一种普遍的社会构造，本文研究如何发现和量化生成式语言模型中性别偏见的存在。具体而言，我们推导出三个来自分类的著名非歧视标准的生成式人工智能类比，即独立性、分离性和充分性。为了展示这些标准的作用，我们设计了针对每个标准的提示，重点关注职业性别刻板印象，具体利用医学测试来在生成式人工智能背景中引入基本事实。

    arXiv:2403.08564v1 Announce Type: cross  Abstract: Within recent years, generative AI, such as large language models, has undergone rapid development. As these models become increasingly available to the public, concerns arise about perpetuating and amplifying harmful biases in applications. Gender stereotypes can be harmful and limiting for the individuals they target, whether they consist of misrepresentation or discrimination. Recognizing gender bias as a pervasive societal construct, this paper studies how to uncover and quantify the presence of gender biases in generative language models. In particular, we derive generative AI analogues of three well-known non-discrimination criteria from classification, namely independence, separation and sufficiency. To demonstrate these criteria in action, we design prompts for each of the criteria with a focus on occupational gender stereotype, specifically utilizing the medical test to introduce the ground truth in the generative AI context. 
    
[^12]: 一张图片在第二层之后价值1/2代币：针对大规模视觉语言模型的即插即用推理加速

    An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models

    [https://arxiv.org/abs/2403.06764](https://arxiv.org/abs/2403.06764)

    FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。

    

    在本研究中，我们发现大规模视觉语言模型（LVLMs）中的注意力计算存在低效现象，尤其是在知名模型如LLaVA-1.5、QwenVL-Chat和Video-LLaVA中。我们发现在流行的LVLMs的深层中，对视觉代币的注意力计算极其低效，暗示相较于处理文本数据，需要更稀疏的方法。为此，我们引入了FastV，这是一种多功能即插即用方法，旨在通过学习早期层中的自适应注意力模式和在随后层中修剪视觉代币来优化计算效率。我们的评估表明FastV能够显著降低计算成本（例如，对于LLaVA-1.5-13B的FLOP减少了45%），而不会在广泛的图像和视频理解任务中牺牲性能。FastV的计算效率和性能权衡是高度可定制的，并且是帕累托有效的。

    arXiv:2403.06764v1 Announce Type: cross  Abstract: In this study, we identify the inefficient attention phenomena in Large Vision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5, QwenVL-Chat and Video-LLaVA. We find out that the attention computation over visual tokens is of extreme inefficiency in the deep layers of popular LVLMs, suggesting a need for a sparser approach compared to textual data handling. To this end, we introduce FastV, a versatile plug-and-play method designed to optimize computational efficiency by learning adaptive attention patterns in early layers and pruning visual tokens in subsequent ones. Our evaluations demonstrate FastV's ability to dramatically reduce computational costs (e.g., a 45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a wide range of image and video understanding tasks. The computational efficiency and performance trade-off of FastV are highly customizable and pareto-efficient. It can compress t
    
[^13]: 追踪可信度动态：重访大型语言模型的预训练期

    Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models

    [https://arxiv.org/abs/2402.19465](https://arxiv.org/abs/2402.19465)

    本文研究探索了大型语言模型在预训练期间的可信度，揭示了早期预训练LLMs已经能够区分各个可信度维度中的概念，提出了从预训练检查点中提取转向向量以增强LLM可信度的方法。

    

    确保大型语言模型（LLMs）的可信度至关重要。大多数研究集中在充分预训练的LLMs上，以更好地理解和提高LLMs的可信度。本文旨在揭示预训练的潜力，首次探索了LLMs在此期间的可信度，专注于五个关键维度：可靠性、隐私、有害度、公平性和稳健性。我们首先对LLMs应用线性探测。高探测准确度表明，\textit{早期预训练的LLMs已经能够区分每个可信度维度中的概念}。因此，为了进一步揭示预训练的潜在可能性，我们从LLM的预训练检查点中提取转向向量，以增强LLM的可信度。最后，受到~\citet{choi2023understanding} 的启发，相互信息估计受线性探测准确度的限制，我们还用相互信息探测LLMs来探究

    arXiv:2402.19465v1 Announce Type: cross  Abstract: Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to in
    
[^14]: 未知之中：自学习大型语言模型

    Into the Unknown: Self-Learning Large Language Models

    [https://arxiv.org/abs/2402.09147](https://arxiv.org/abs/2402.09147)

    本研究关注自学习大型语言模型的核心问题：如何学习未知知识。提出了一种自学习框架，通过自我评估和识别未知点来独立学习以前未知的知识。实验证明该方法对于减少幻觉评分、实现高效LLM更新以及知识交流具有重要意义。

    

    我们解决了自学习大型语言模型（LLM）的主要问题：即如何学习自己不知道的知识。我们提出了一种自学习LLM框架，通过对自己的幻觉进行自我评估，使LLM能够独立地学习以前未知的知识。通过使用幻觉评分，我们引入了一个称为“未知点”的新概念，并提出了一种外部和三种内部方法来自动识别未知点。这有助于创建一个自学习循环，专注于未知点中的知识差距，从而减少幻觉评分。我们还开发了用于评估LLM自学习能力的评估指标。我们的实验证明，已经进行了微调或对齐的7B-Mistral模型在自学习方面表现出色。我们的自学习概念可以实现更高效的LLM更新，并为知识交流开辟新的可能性。它还可能增加公众的信任。

    arXiv:2402.09147v1 Announce Type: new Abstract: We address the main problem of self-learning LLM: the question of what to learn. We propose a self-learning LLM framework that enables an LLM to independently learn previously unknown knowledge through self-assessment of their own hallucinations. Using the hallucination score, we introduce a new concept of Points in The Unknown (PiUs), along with one extrinsic and three intrinsic methods for automatic PiUs identification. It facilitates the creation of a self-learning loop that focuses exclusively on the knowledge gap in Points in The Unknown, resulting in a reduced hallucination score. We also developed evaluation metrics for gauging an LLM's self-learning capability. Our experiments revealed that 7B-Mistral models that have been finetuned or aligned are capable of self-learning considerably well. Our self-learning concept allows more efficient LLM updates and opens new perspectives for knowledge exchange. It may also increase public tru
    
[^15]: FRDiff：特征重用用于无训练加速扩散模型

    FRDiff : Feature Reuse for Universal Training-free Acceleration of Diffusion Models

    [https://arxiv.org/abs/2312.03517](https://arxiv.org/abs/2312.03517)

    引入了一种新的加速技术FRDiff，通过利用扩散模型的时间冗余性，重新使用具有高时间相似性的特征图，节省计算资源而不影响输出质量。

    

    扩散模型的较大计算成本，特别是由于高质量图像生成所必需的重复去噪步骤而产生的，这是阻碍它们得到广泛采用的主要障碍。我们引入一种高级加速技术，利用扩散模型固有的时间冗余性来重新使用具有高时间相似性的特征图，从而节省计算资源而不影响输出质量。

    arXiv:2312.03517v2 Announce Type: replace-cross  Abstract: The substantial computational costs of diffusion models, especially due to the repeated denoising steps necessary for high-quality image generation, present a major obstacle to their widespread adoption. While several studies have attempted to address this issue by reducing the number of score function evaluations (NFE) using advanced ODE solvers without fine-tuning, the decreased number of denoising iterations misses the opportunity to update fine details, resulting in noticeable quality degradation. In our work, we introduce an advanced acceleration technique that leverages the temporal redundancy inherent in diffusion models. Reusing feature maps with high temporal similarity opens up a new opportunity to save computation resources without compromising output quality. To realize the practical benefits of this intuition, we conduct an extensive analysis and propose a novel method, FRDiff. FRDiff is designed to harness the adv
    
[^16]: 在概率逻辑编程中解释解释

    Explaining Explanations in Probabilistic Logic Programming. (arXiv:2401.17045v1 [cs.AI])

    [http://arxiv.org/abs/2401.17045](http://arxiv.org/abs/2401.17045)

    该论文介绍了基于概率逻辑编程的解释解释方法，以解决在不透明系统中生成合适解释的困难。

    

    基于人工智能的工具的出现也导致了产生人类可理解的解释的需求。在一些方法中，系统是不透明的（通常被称为“黑盒子”），这使得生成适当的解释变得困难。然而，在概率逻辑编程中，我们考虑了逻辑编程（用于知识表示）和概率（用于建模不确定性）的结合。在这个设置中，可以说模型是可以解释的，这方便了对模型的理解。然而，对于特定的查询，通常的“解释”的概念是与模型的每个随机变量的选择集相关联的。不幸的是，这个集合没有因果结构，实际上，一些选择实际上与所考虑的查询无关。为了克服这些缺点，我们提出了一种基于查询驱动推理定义的解释解释方法。

    The emergence of tools based on artificial intelligence has also led to the need of producing explanations which are understandable by a human being. In some approaches, the system is not transparent (often referred to as a "black box"), making it difficult to generate appropriate explanations. In this work, though, we consider probabilistic logic programming, a combination of logic programming (for knowledge representation) and probability (to model uncertainty). In this setting, one can say that models are interpretable, which eases its understanding. However, given a particular query, the usual notion of "explanation" is associated with a set of choices, one for each random variable of the model. Unfortunately, this set does not have a causal structure and, in fact, some of the choices are actually irrelevant to the considered query. In order to overcome these shortcomings, we present an approach to explaining explanations which is based on the definition of a query-driven inference
    
[^17]: GPT-4 Vision在医学领域中专家级准确度背后的隐藏缺陷

    Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine. (arXiv:2401.08396v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.08396](http://arxiv.org/abs/2401.08396)

    GPT-4 Vision在医学领域中具有专家级准确度，但在图像理解方面存在缺陷。

    

    最近的研究表明，具有Vision功能的GPT-4在医学挑战任务中表现优于人类医生。然而，这些评估主要关注多项选择题的准确度。本研究通过对GPT-4V在解决新英格兰医学杂志图像挑战中的图像理解、医学知识回忆和逐步多模态推理的原理进行全面分析，扩展了当前的研究范围。评估结果证实，GPT-4V在多项选择准确度上优于人类医生（88.0% vs. 77.0%，p=0.034）。GPT-4V在医生回答错误的情况下，也能表现出超过80%的准确度。然而，我们发现，GPT-4V在最终做出正确选择的情况下，经常提供有缺陷的推理（27.3%），其中最突出的是图像理解（21.6%）。

    Recent studies indicate that Generative Pre-trained Transformer 4 with Vision (GPT-4V) outperforms human physicians in medical challenge tasks. However, these evaluations primarily focused on the accuracy of multi-choice questions alone. Our study extends the current scope by conducting a comprehensive analysis of GPT-4V's rationales of image comprehension, recall of medical knowledge, and step-by-step multimodal reasoning when solving New England Journal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test the knowledge and diagnostic capabilities of medical professionals. Evaluation results confirmed that GPT-4V outperforms human physicians regarding multi-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well in cases where physicians incorrectly answer, with over 80% accuracy. However, we discovered that GPT-4V frequently presents flawed rationales in cases where it makes the correct final choices (27.3%), most prominent in image comprehension (21.6
    
[^18]: 概念瓶颈模型是否遵循局部性？

    Do Concept Bottleneck Models Obey Locality?. (arXiv:2401.01259v1 [cs.LG])

    [http://arxiv.org/abs/2401.01259](http://arxiv.org/abs/2401.01259)

    本文研究了概念瓶颈模型（CBMs）是否能够正确捕捉到概念之间的条件独立程度，通过分析对于概念局部性之外特征的变化如何影响概念的预测。

    

    概念基础学习通过解释其预测结果使用人可理解的概念，改善了深度学习模型的可解释性。在这种范式下训练的深度学习模型严重依赖于神经网络能够学习独立于其他概念的给定概念的存在或不存在。然而，最近的研究强烈暗示这种假设可能在概念瓶颈模型（CBMs）这一典型的基于概念的可解释架构中不能成立。本文中，我们研究了当这些概念既在空间上（通过它们的值完全由固定子集的特征定义）又在语义上（通过它们的值仅与预定义的固定子集的概念相关联）定位时，CBMs是否正确捕捉到概念之间的条件独立程度。为了理解局部性，我们分析了概念之外的特征变化对概念预测的影响。

    Concept-based learning improves a deep learning model's interpretability by explaining its predictions via human-understandable concepts. Deep learning models trained under this paradigm heavily rely on the assumption that neural networks can learn to predict the presence or absence of a given concept independently of other concepts. Recent work, however, strongly suggests that this assumption may fail to hold in Concept Bottleneck Models (CBMs), a quintessential family of concept-based interpretable architectures. In this paper, we investigate whether CBMs correctly capture the degree of conditional independence across concepts when such concepts are localised both spatially, by having their values entirely defined by a fixed subset of features, and semantically, by having their values correlated with only a fixed subset of predefined concepts. To understand locality, we analyse how changes to features outside of a concept's spatial or semantic locality impact concept predictions. Our
    
[^19]: 将论文的潜在影响分解为传播、一致性和贡献值的研究

    Disentangling the Potential Impacts of Papers into Diffusion, Conformity, and Contribution Values. (arXiv:2311.09262v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2311.09262](http://arxiv.org/abs/2311.09262)

    这项研究提出了一种新颖的图神经网络（称为DPPDCC），用于将论文的潜在影响分解为传播、一致性和贡献值。通过编码时态和结构特征，捕捉知识流动，并使用对比增强图揭示流行度，进一步预测引用分组来建模一致性。应用正交约束来鼓励独特建模，并保留原始信息。

    

    论文的潜在影响受到多种因素的影响，包括其流行度和贡献。现有模型通常基于静态图来估计原始引用计数，未能从细微的角度区分价值。在本研究中，我们提出了一种新颖的图神经网络，用于将论文的潜在影响分解为传播、一致性和贡献值（称为DPPDCC）。给定一个目标论文，DPPDCC在构建的动态异构图中编码了时态和结构特征。特别地，为了捕捉知识流动，我们强调了论文之间的比较和共引/被引信息的重要性，并进行了快照演化的聚合。为了揭示流行度，我们通过对比增强图来提取传播的本质，并预测累积的引用分组以建模一致性。我们进一步应用正交约束来鼓励每个角度的独特建模，并保留其固有获得的信息。

    The potential impact of an academic paper is determined by various factors, including its popularity and contribution. Existing models usually estimate original citation counts based on static graphs and fail to differentiate values from nuanced perspectives. In this study, we propose a novel graph neural network to Disentangle the Potential impacts of Papers into Diffusion, Conformity, and Contribution values (called DPPDCC). Given a target paper, DPPDCC encodes temporal and structural features within the constructed dynamic heterogeneous graph. Particularly, to capture the knowledge flow, we emphasize the importance of comparative and co-cited/citing information between papers and aggregate snapshots evolutionarily. To unravel popularity, we contrast augmented graphs to extract the essence of diffusion and predict the accumulated citation binning to model conformity. We further apply orthogonal constraints to encourage distinct modeling of each perspective and preserve the inherent v
    
[^20]: Sentinel: 一种用于保护分散式联邦学习的聚合函数

    Sentinel: An Aggregation Function to Secure Decentralized Federated Learning. (arXiv:2310.08097v1 [cs.DC])

    [http://arxiv.org/abs/2310.08097](http://arxiv.org/abs/2310.08097)

    Sentinel是一种用于保护分散式联邦学习的防御策略，通过利用本地数据并定义一个三步聚合协议来对抗污染攻击。评估结果表明Sentinel在不同数据集和评估指标下表现良好。

    

    将联邦学习（FL）快速整合到网络中涵盖了网络管理、服务质量和网络安全等各个方面，同时保护数据隐私。在这种情况下，分散式联邦学习（DFL）作为一种创新范式，用于训练协作模型，解决了单点失效的限制。然而，FL和DFL的安全性和可信性受到污染攻击的影响，从而对其性能产生负面影响。现有的防御机制针对集中式FL进行设计，并未充分利用DFL的特点。因此，本文引入了Sentinel，一种在DFL中对抗污染攻击的防御策略。Sentinel利用本地数据的可访问性，定义了一个三步聚合协议，包括相似性过滤、引导验证和标准化，以防止恶意模型更新。通过使用不同数据集和不同的评估指标对Sentinel进行了评估。

    The rapid integration of Federated Learning (FL) into networking encompasses various aspects such as network management, quality of service, and cybersecurity while preserving data privacy. In this context, Decentralized Federated Learning (DFL) emerges as an innovative paradigm to train collaborative models, addressing the single point of failure limitation. However, the security and trustworthiness of FL and DFL are compromised by poisoning attacks, negatively impacting its performance. Existing defense mechanisms have been designed for centralized FL and they do not adequately exploit the particularities of DFL. Thus, this work introduces Sentinel, a defense strategy to counteract poisoning attacks in DFL. Sentinel leverages the accessibility of local data and defines a three-step aggregation protocol consisting of similarity filtering, bootstrap validation, and normalization to safeguard against malicious model updates. Sentinel has been evaluated with diverse datasets and various 
    
[^21]: Suspicion-Agent: 使用具备心灵理论意识的GPT4在不完全信息游戏中进行对局

    Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT4. (arXiv:2309.17277v1 [cs.AI])

    [http://arxiv.org/abs/2309.17277](http://arxiv.org/abs/2309.17277)

    Suspicion-Agent是一种创新代理程序，利用具备高阶心灵理论意识的GPT4在不完全信息游戏中表现出良好的适应性和影响他人行为的能力。

    

    不同于完全信息游戏，其中每个玩家都知道所有元素，不完全信息游戏模拟了在不确定或不完整信息下进行决策的现实世界复杂性。最近在大规模语言模型（LLM）上进行训练的GPT-4以其知识检索和推理能力而闻名。本文探讨了将GPT-4的学习知识应用于不完全信息游戏的可行性。为了实现这一目标，我们引入了一种创新代理程序\textbf{Suspicion-Agent}，该代理程序利用GPT-4的能力在不完全信息游戏中进行对局。通过合适的提示工程来实现不同的功能，基于GPT-4的Suspicion-Agent展示了在一系列不完全信息纸牌游戏中的显著适应能力。重要的是，GPT-4展示了强大的高阶心灵理论（Theory of Mind）能力，这意味着它能够理解他人并有意识地影响他人的行为。利用这一点，我们设计了一个计划

    Unlike perfect information games, where all elements are known to every player, imperfect information games emulate the real-world complexities of decision-making under uncertain or incomplete information. GPT-4, the recent breakthrough in large language models (LLMs) trained on massive passive data, is notable for its knowledge retrieval and reasoning abilities. This paper delves into the applicability of GPT-4's learned knowledge for imperfect information games. To achieve this, we introduce \textbf{Suspicion-Agent}, an innovative agent that leverages GPT-4's capabilities for performing in imperfect information games. With proper prompt engineering to achieve different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable adaptability across a range of imperfect information card games. Importantly, GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it can understand others and intentionally impact others' behavior. Leveraging this, we design a plann
    
[^22]: NutritionVerse: 各种饮食摄入估计方法的实证研究

    NutritionVerse: Empirical Study of Various Dietary Intake Estimation Approaches. (arXiv:2309.07704v1 [cs.CV])

    [http://arxiv.org/abs/2309.07704](http://arxiv.org/abs/2309.07704)

    该论文介绍了NutritionVerse-Synth，这是一个拥有大规模合成食物图像数据集，其中包含了多种视角、模态和饮食注释，旨在解决目前饮食摄入估计方法的准确性和真实性问题。

    

    准确的饮食摄入估计对于支持健康饮食的政策和程序至关重要，因为营养不良与生活质量下降直接相关。然而，诸如食物日记之类的自我报告方法存在显著偏差。其他传统的饮食评估技术和新兴的替代方法，如移动应用程序，耗时长，并且可能需要受过训练的人员。最近的研究集中于使用计算机视觉和机器学习来从食物图像中自动估计饮食摄入量，但缺乏具有多样视角、模态和食物注释的综合数据集限制了这种方法的准确性和真实性。为了解决这个局限性，我们引入了NutritionVerse-Synth，这是第一个拥有84,984个逼真的合成2D食物图像及相关饮食信息和多模态标注的大规模数据集（包括深度图像、实例掩膜和语义掩膜）。

    Accurate dietary intake estimation is critical for informing policies and programs to support healthy eating, as malnutrition has been directly linked to decreased quality of life. However self-reporting methods such as food diaries suffer from substantial bias. Other conventional dietary assessment techniques and emerging alternative approaches such as mobile applications incur high time costs and may necessitate trained personnel. Recent work has focused on using computer vision and machine learning to automatically estimate dietary intake from food images, but the lack of comprehensive datasets with diverse viewpoints, modalities and food annotations hinders the accuracy and realism of such methods. To address this limitation, we introduce NutritionVerse-Synth, the first large-scale dataset of 84,984 photorealistic synthetic 2D food images with associated dietary information and multimodal annotations (including depth images, instance masks, and semantic masks). Additionally, we col
    
[^23]: VoiceFlow: 使用矫正流匹配的高效文本转语音

    VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching. (arXiv:2309.05027v1 [eess.AS])

    [http://arxiv.org/abs/2309.05027](http://arxiv.org/abs/2309.05027)

    VoiceFlow使用矫正流匹配算法实现了高效文本转语音，并在合成质量上优于传统的扩散模型。

    

    尽管扩散模型在文本转语音中因其强大的生成能力而成为一种流行选择，但从扩散模型中进行采样的内在复杂性损害了其效率。相反，我们提出了VoiceFlow，一种利用矫正流匹配算法来实现高合成质量的声学模型，只需有限次采样步骤即可实现。VoiceFlow将生成mel-spectrograms的过程转化为一个普通微分方程，在文本输入的条件下进行求解，并估计出其向量场。然后，矫正流技术有效地使其采样轨迹直线化，实现高效合成。在单个和多个说话者语料库上进行的主观和客观评估显示，VoiceFlow相对于扩散模型具有更优异的合成质量。消融研究进一步验证了VoiceFlow中矫正流技术的有效性。

    Although diffusion models in text-to-speech have become a popular choice due to their strong generative ability, the intrinsic complexity of sampling from diffusion models harms their efficiency. Alternatively, we propose VoiceFlow, an acoustic model that utilizes a rectified flow matching algorithm to achieve high synthesis quality with a limited number of sampling steps. VoiceFlow formulates the process of generating mel-spectrograms into an ordinary differential equation conditional on text inputs, whose vector field is then estimated. The rectified flow technique then effectively straightens its sampling trajectory for efficient synthesis. Subjective and objective evaluations on both single and multi-speaker corpora showed the superior synthesis quality of VoiceFlow compared to the diffusion counterpart. Ablation studies further verified the validity of the rectified flow technique in VoiceFlow.
    
[^24]: 解放图学习的力量：基于LLM的自主代理机制

    Unleashing the Power of Graph Learning through LLM-based Autonomous Agents. (arXiv:2309.04565v1 [cs.LG])

    [http://arxiv.org/abs/2309.04565](http://arxiv.org/abs/2309.04565)

    本文提出了一种使用大型语言模型（LLMs）作为自主代理的方法，以简化多样化的现实世界图中的学习过程，并克服了现有方法中的限制。

    

    图结构化数据在现实世界中广泛存在和应用，但有效地处理这些多样化的数据和在图上进行学习任务是一项挑战。面对复杂的图学习任务，专家们在近年来设计了各种图神经网络（GNN）。他们还实施了图中的自动机器学习，也称为AutoGraph，以自动生成数据特定的解决方案。尽管取得了成功，但他们在以下方面存在限制：（1）在不同层级上管理各种学习任务，（2）处理图学习中不同的流程（超过架构设计），以及（3）使用AutoGraph时对先验知识的巨大需求。本文中，我们提出使用大型语言模型（LLMs）作为自主代理来简化多样化的现实世界图中的学习过程。具体来说，针对用户请求（该请求可能包含节点、边缘或图级别的不同数据和学习目标），复杂图中的学习过程将由LLM自主代理机制来处理。

    Graph structured data are widely existed and applied in the real-world applications, while it is a challenge to handling these diverse data and learning tasks on graph in an efficient manner. When facing the complicated graph learning tasks, experts have designed diverse Graph Neural Networks (GNNs) in recent years. They have also implemented AutoML in Graph, also known as AutoGraph, to automatically generate data-specific solutions. Despite their success, they encounter limitations in (1) managing diverse learning tasks at various levels, (2) dealing with different procedures in graph learning beyond architecture design, and (3) the huge requirements on the prior knowledge when using AutoGraph. In this paper, we propose to use Large Language Models (LLMs) as autonomous agents to simplify the learning process on diverse real-world graphs. Specifically, in response to a user request which may contain varying data and learning targets at the node, edge, or graph levels, the complex graph
    
[^25]: 利用基于模型反演的去除攻击方法破解深度神经网络中的黑盒水印

    MIRA: Cracking Black-box Watermarking on Deep Neural Networks via Model Inversion-based Removal Attacks. (arXiv:2309.03466v1 [cs.CR])

    [http://arxiv.org/abs/2309.03466](http://arxiv.org/abs/2309.03466)

    本文提出了一种基于模型反演的去除攻击方法（\textsc{Mira}），该方法能够有效地破解大多数主流黑盒DNN水印方案，通过利用受保护模型的内部信息来恢复和消除水印信息。

    

    为了保护训练有素的深度神经网络（DNN）的知识产权，黑盒DNN水印已在学术界和工业界越来越受欢迎。这些水印被嵌入到DNN模型在一组特别设计的样本上的预测行为中。最近的研究经验证明，大多数黑盒水印方案对已知的去除攻击具有抵抗能力。本文提出了一种新颖的基于模型反演的去除攻击方法（\textsc{Mira}），该方法对大多数主流黑盒DNN水印方案都是无关水印的，并且具有高效性。总的来说，我们的攻击流程利用受保护模型的内部信息来恢复和消除水印信息。我们还设计了目标类别检测和恢复样本分割算法，以减少\textsc{Mira}引起的效用损失，并实现最优的攻击效果。

    To protect the intellectual property of well-trained deep neural networks (DNNs), black-box DNN watermarks, which are embedded into the prediction behavior of DNN models on a set of specially-crafted samples, have gained increasing popularity in both academy and industry. Watermark robustness is usually implemented against attackers who steal the protected model and obfuscate its parameters for watermark removal. Recent studies empirically prove the robustness of most black-box watermarking schemes against known removal attempts.  In this paper, we propose a novel Model Inversion-based Removal Attack (\textsc{Mira}), which is watermark-agnostic and effective against most of mainstream black-box DNN watermarking schemes. In general, our attack pipeline exploits the internals of the protected model to recover and unlearn the watermark message. We further design target class detection and recovered sample splitting algorithms to reduce the utility loss caused by \textsc{Mira} and achieve 
    
[^26]: GPT已经具备了金融素养：来自GPT金融素养测试的见解以及人们使用其作为咨询来源的初步测试

    GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice. (arXiv:2309.00649v1 [cs.CL])

    [http://arxiv.org/abs/2309.00649](http://arxiv.org/abs/2309.00649)

    GPT通过金融素养测试显示出具备成为大众金融机器顾问的能力，其中基于GPT-4的ChatGPT几乎完美地得分99%，揭示了金融素养正在成为最先进模型的新兴能力。

    

    通过使用金融素养测试，我们评估了GPT（一种大型语言模型）作为大众金融机器顾问的能力。基于GPT-3.5的Davinci和ChatGPT分别在金融素养测试中得分为66%和65%，而基于GPT-4的ChatGPT几乎完美地得到了99%的分数，这表明金融素养正在成为最先进模型的新兴能力。我们使用Judge-Advisor系统和一个储蓄困境来说明研究人员如何评估大型语言模型提供的建议利用情况。我们还提出了一些未来研究的方向。

    We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.
    
[^27]: RLAIF: 使用AI反馈来扩展强化学习从人类反馈中学习

    RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback. (arXiv:2309.00267v1 [cs.CL])

    [http://arxiv.org/abs/2309.00267](http://arxiv.org/abs/2309.00267)

    RLAIF是一种新的强化学习方法，利用AI反馈代替人类标注偏好，相比强化学习从人类反馈中学习（RLHF），在摘要任务上取得了类似的改进效果，并且在人类评估中得到了相同的认可。这提供了一种有潜力解决RLHF的可扩展性限制的解决方案。

    

    从人类反馈中进行强化学习（RLHF）对于将大型语言模型（LLMs）与人类偏好相一致是有效的，但是收集高质量的人类偏好标签是一个关键瓶颈。我们比较了RLHF和利用现成的LLM进行标记的RL from AI Feedback (RLAIF)技术，并发现它们都能获得类似的改善效果。在摘要任务上，人类评估者在约70%的案例中都更喜欢RLAIF和RLHF产生的文本，而不是基准的监督微调模型。此外，当被要求评估RLAIF和RLHF的摘要时，人类以相同的比率更喜欢两者。这些结果表明，RLAIF可以达到人类水平的性能，为克服RLHF的可扩展性限制提供了潜在的解决方案。

    Reinforcement learning from human feedback (RLHF) is effective at aligning large language models (LLMs) to human preferences, but gathering high quality human preference labels is a key bottleneck. We conduct a head-to-head comparison of RLHF vs. RL from AI Feedback (RLAIF) - a technique where preferences are labeled by an off-the-shelf LLM in lieu of humans, and we find that they result in similar improvements. On the task of summarization, human evaluators prefer generations from both RLAIF and RLHF over a baseline supervised fine-tuned model in ~70% of cases. Furthermore, when asked to rate RLAIF vs. RLHF summaries, humans prefer both at equal rates. These results suggest that RLAIF can yield human-level performance, offering a potential solution to the scalability limitations of RLHF.
    
[^28]: 基于价值分布模型的强化学习

    Value-Distributional Model-Based Reinforcement Learning. (arXiv:2308.06590v1 [cs.LG])

    [http://arxiv.org/abs/2308.06590](http://arxiv.org/abs/2308.06590)

    该论文介绍了一种基于价值分布模型的强化学习方法，该方法通过学习后验分布来解决决策任务中的政策不确定性问题。所提出的算法能够有效地优化策略，在连续控制任务中表现出性能优势。

    

    在解决顺序决策任务中，量化政策长期绩效的不确定性是很重要的。我们从基于模型的贝叶斯强化学习的角度研究这个问题，目标是学习由马尔科夫决策过程的参数（认知）不确定性引发的值函数的后验分布。以往的研究将分析限制在少数分布值上，或者约束分布形状，例如，高斯分布。受到分布式强化学习的启发，我们引入一个Bellman算子，其固定点是值分布函数。基于我们的理论，我们提出了Epistemic Quantile-Regression（EQR），这是一种基于模型的算法，可以学习一个值分布函数用于策略优化。在几个连续控制任务上的评估结果显示相对于已有的基于模型和基于模型的算法，EQR具有性能优势。

    Quantifying uncertainty about a policy's long-term performance is important to solve sequential decision-making tasks. We study the problem from a model-based Bayesian reinforcement learning perspective, where the goal is to learn the posterior distribution over value functions induced by parameter (epistemic) uncertainty of the Markov decision process. Previous work restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians. Inspired by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function. Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. Evaluation across several continuous-control tasks shows performance benefits with respect to established model-based and model-free algorithms.
    
[^29]: RefSAM：高效适应任何模型的指代视频对象分割

    RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation. (arXiv:2307.00997v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.00997](http://arxiv.org/abs/2307.00997)

    本文介绍了RefSAM模型，该模型通过在线方式从不同时间戳的多视图信息中加入SAM的潜力，探索其在指代视频对象分割（RVOS）中的应用。通过使用跨模态MLP和分层稠密注意模块，我们改进了SAM模型，实现了对不同形态的精确理解，并取得了令人印象深刻的性能表现。

    

    Segment Anything Model (SAM)因其在图像分割中出色的性能而引起了广泛关注。然而，在指代视频对象分割（RVOS）方面，由于需要精确的用户交互提示以及对语言和视觉等不同形态的有限理解能力，SAM缺乏熟练度。本文提出了RefSAM模型，通过在线方式从不同时间戳的多视图信息中加入SAM的潜力，探索其在RVOS中的应用。我们的方法对原始SAM模型进行了适应，通过使用轻量级的跨模态MLP将指代表达的文本嵌入投影为稀疏和密集嵌入，作为用户交互提示，以增强跨模态学习。此外，我们还引入了分层稠密注意模块，以将分层视觉语义信息与稀疏嵌入融合，以获得细粒度的密集嵌入。

    The Segment Anything Model (SAM) has gained significant attention for its impressive performance in image segmentation. However, it lacks proficiency in referring video object segmentation (RVOS) due to the need for precise user-interactive prompts and a limited understanding of different modalities, such as language and vision. This paper presents the RefSAM model, which explores the potential of SAM for RVOS by incorporating multi-view information from diverse modalities and successive frames at different timestamps in an online manner. Our proposed approach adapts the original SAM model to enhance cross-modality learning by employing a lightweight Cross-Modal MLP that projects the text embedding of the referring expression into sparse and dense embeddings, serving as user-interactive prompts. Additionally, we have introduced the hierarchical dense attention module to fuse hierarchical visual semantic information with sparse embeddings in order to obtain fine-grained dense embeddings
    
[^30]: 使用语言模型的黑盒预测易出错测试修复类别

    Black-Box Prediction of Flaky Test Fix Categories Using Language Models. (arXiv:2307.00012v1 [cs.SE])

    [http://arxiv.org/abs/2307.00012](http://arxiv.org/abs/2307.00012)

    本文提出了一个使用语言模型的框架，可以自动生成易出错测试的标记数据集，并通过分析测试代码来预测测试的修复类别。实验结果表明UniXcoder优于CodeBERT。

    

    易出错测试会在相同软件版本的测试下非确定性地通过或失败，引起混乱并浪费开发者时间。尽管机器学习模型已经被用于预测易出错性及其根本原因，但在提供修复支持方面仍有较少工作。为了填补这一空白，我们提出了一个框架，通过仅分析测试代码自动生成13个修复类别的标记数据集，并训练模型来预测易出错测试的修复类别。虽然在当前阶段准确预测修复本身是不现实的，但这些类别提供了关于需要检查的测试代码部分的精确指导。我们的方法基于语言模型，即CodeBERT和UniXcoder，其输出经过前馈神经网络（FNN）或基于孪生网络的Few Shot Learning（FSL）进行了微调。我们的实验结果表明，UniXcoder在正确预测大多数修复类别方面表现优于CodeBERT。

    Flaky tests are problematic because they non-deterministically pass or fail for the same software version under test, causing confusion and wasting developer time. While machine learning models have been used to predict flakiness and its root causes, there is less work on providing support to fix the problem. To address this gap, we propose a framework that automatically generates labeled datasets for 13 fix categories and train models to predict the fix category of a flaky test by analyzing the test code only. Though it is unrealistic at this stage to accurately predict the fix itself, the categories provide precise guidance about what part of the test code to look at. Our approach is based on language models, namely CodeBERT and UniXcoder, whose output is fine-tuned with a Feed Forward Neural Network (FNN) or a Siamese Network-based Few Shot Learning (FSL). Our experimental results show that UniXcoder outperforms CodeBERT, in correctly predicting most of the categories of fixes a dev
    
[^31]: DiffLoad:扩散模型中的负荷预测不确定性量化

    DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model. (arXiv:2306.01001v1 [cs.LG])

    [http://arxiv.org/abs/2306.01001](http://arxiv.org/abs/2306.01001)

    本文提出了一种扩散模型中的负荷预测不确定性量化方法，采用Seq2Seq网络结构来分离两种类型的不确定性并处理异常情况，不仅着眼于预测条件期望值。

    

    电力负荷预测对电力系统的决策制定，如机组投入和能源管理等具有重要意义。近年来，各种基于自监督神经网络的方法已经被应用于电力负荷预测，以提高预测准确性和捕捉不确定性。然而，大多数现有的方法是基于高斯似然方法的，它旨在在给定的协变量下准确估计分布期望值。这种方法很难适应存在分布偏移和异常值的时间数据。在本文中，我们提出了一种基于扩散的Seq2seq结构来估计本体不确定性，并使用鲁棒的加性柯西分布来估计物象不确定性。我们展示了我们的方法能够分离两种类型的不确定性并处理突变情况，而不是准确预测条件期望。

    Electrical load forecasting is of great significance for the decision makings in power systems, such as unit commitment and energy management. In recent years, various self-supervised neural network-based methods have been applied to electrical load forecasting to improve forecasting accuracy and capture uncertainties. However, most current methods are based on Gaussian likelihood methods, which aim to accurately estimate the distribution expectation under a given covariate. This kind of approach is difficult to adapt to situations where temporal data has a distribution shift and outliers. In this paper, we propose a diffusion-based Seq2seq structure to estimate epistemic uncertainty and use the robust additive Cauchy distribution to estimate aleatoric uncertainty. Rather than accurately forecasting conditional expectations, we demonstrate our method's ability in separating two types of uncertainties and dealing with the mutant scenarios.
    
[^32]: 将知识蒸馏用于短期到长期轨迹预测

    Distilling Knowledge for Short-to-Long Term Trajectory Prediction. (arXiv:2305.08553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08553](http://arxiv.org/abs/2305.08553)

    本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。

    

    长期轨迹预测是计算机视觉、机器学习和机器人领域中一个重要且具有挑战性的问题。其中一个基本困难在于随着时间范围的增长，轨迹的演变变得越来越不确定和不可预测，从而增加了问题的复杂性。为了克服这个问题，在本文中，我们提出了Di-Long，一种新的方法，它利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。给定一个包含学生网络允许的观测序列和补充目标序列的总序列长度，我们让学生和教师对同一个完整轨迹定义两个不同但相关的任务：学生观察一个短序列并预测一个长轨迹，而教师观察一个更长的序列并预测剩下的短目标轨迹。

    Long-term trajectory forecasting is an important and challenging problem in the fields of computer vision, machine learning, and robotics. One fundamental difficulty stands in the evolution of the trajectory that becomes more and more uncertain and unpredictable as the time horizon grows, subsequently increasing the complexity of the problem. To overcome this issue, in this paper, we propose Di-Long, a new method that employs the distillation of a short-term trajectory model forecaster that guides a student network for long-term trajectory prediction during the training process. Given a total sequence length that comprehends the allowed observation for the student network and the complementary target sequence, we let the student and the teacher solve two different related tasks defined over the same full trajectory: the student observes a short sequence and predicts a long trajectory, whereas the teacher observes a longer sequence and predicts the remaining short target trajectory. The
    
[^33]: Diffusion Explainer：用于文本到图像稳定扩散的可视化解释工具

    Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion. (arXiv:2305.03509v1 [cs.CL])

    [http://arxiv.org/abs/2305.03509](http://arxiv.org/abs/2305.03509)

    Diffusion Explainer是第一个可交互的可视化工具，用于解释稳定扩散如何将文本提示转化为图像，用户可以通过动画和交互元素流畅地在多个抽象级别之间过渡，从而更好地理解提示对图像生成的影响。

    

    基于扩散的生成模型通过创造逼真的图像而获得了全球关注。然而，它们复杂的内部结构和操作往往使得非专业人员难以理解。我们提出了 Diffusion Explainer，这是第一个交互式可视化工具，用于解释稳定扩散如何将文本提示转化为图像。Diffusion Explainer紧密地将稳定扩散的复杂组件的视觉概述与其潜在操作的详细说明相结合，通过动画和交互元素使用户可以流畅地在多个抽象级别之间过渡。通过比较由两个相关文本提示引导的图像表示的演变来指导精细时间步长，用户可以发现提示对图像生成的影响。Diffusion Explainer在用户的Web浏览器中本地运行，无需安装或专门的硬件，扩大了公众对现代人工智能技术的教育获取。

    Diffusion-based generative models' impressive ability to create convincing images has captured global attention. However, their complex internal structures and operations often make them difficult for non-experts to understand. We present Diffusion Explainer, the first interactive visualization tool that explains how Stable Diffusion transforms text prompts into images. Diffusion Explainer tightly integrates a visual overview of Stable Diffusion's complex components with detailed explanations of their underlying operations, enabling users to fluidly transition between multiple levels of abstraction through animations and interactive elements. By comparing the evolutions of image representations guided by two related text prompts over refinement timesteps, users can discover the impact of prompts on image generation. Diffusion Explainer runs locally in users' web browsers without the need for installation or specialized hardware, broadening the public's education access to modern AI tec
    
[^34]: 从宽到深：维度提升网络用于参数高效的知识图谱嵌入

    From Wide to Deep: Dimension Lifting Network for Parameter-efficient Knowledge Graph Embedding. (arXiv:2303.12816v1 [cs.LG])

    [http://arxiv.org/abs/2303.12816](http://arxiv.org/abs/2303.12816)

    本文提出了一个用于实现参数高效的知识图谱嵌入的深度网络，通过增加深度克服因采用低维实体表示而导致的模型精度下降和模型参数减少有限的问题。

    

    知识图谱嵌入（KGE）将实体和关系映射到向量表示对于下游任务非常重要。传统的KGE方法需要相对高维的实体表示来保留知识图谱的结构信息，但会导致庞大的模型参数。最近的方法通过采用低维实体表示来降低模型参数，同时开发技术（例如知识蒸馏）来补偿降维。然而，这样的操作会导致模型精度下降和模型参数减少有限。具体来说，我们将所有实体表示的级联视为嵌入层，那么采用高维实体表示的传统KGE方法等同于扩展嵌入层的宽度以获得表现力。为了在不牺牲准确度的情况下实现参数效率，我们相反地增加深度，并提出一个更深的实体嵌入网络。

    Knowledge graph embedding (KGE) that maps entities and relations into vector representations is essential for downstream tasks. Conventional KGE methods require relatively high-dimensional entity representations to preserve the structural information of knowledge graph, but lead to oversized model parameters. Recent methods reduce model parameters by adopting low-dimensional entity representations, while developing techniques (e.g., knowledge distillation) to compensate for the reduced dimension. However, such operations produce degraded model accuracy and limited reduction of model parameters. Specifically, we view the concatenation of all entity representations as an embedding layer, and then conventional KGE methods that adopt high-dimensional entity representations equal to enlarging the width of the embedding layer to gain expressiveness. To achieve parameter efficiency without sacrificing accuracy, we instead increase the depth and propose a deeper embedding network for entity re
    

