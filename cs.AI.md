# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Tiny Models are the Computational Saver for Large Models](https://arxiv.org/abs/2403.17726) | TinySaver是一种动态模型压缩方法，通过使用小型模型来自适应地替换大型模型，从而提高计算效率。 |
| [^2] | [The Interplay of Learning, Analytics, and Artificial Intelligence in Education](https://arxiv.org/abs/2403.16081) | 本文提出了 AI 在学习和教育中的多维视角，强调了 AI、分析和学习过程之间错综复杂的相互作用，挑战了将 AI 视为随机工具的观念，强调了 AI 作为理解人类学习的重要性，并提出了三种独特的教育中人工智能的概念化。 |
| [^3] | [Explore until Confident: Efficient Exploration for Embodied Question Answering](https://arxiv.org/abs/2403.15941) | 通过利用大型视觉-语言模型的语义推理能力，结合深度信息和视觉提示，提出了一种方法来解决具身问答中的有效探索和回答问题的挑战 |
| [^4] | [Larimar: Large Language Models with Episodic Memory Control](https://arxiv.org/abs/2403.11901) | Larimar提出了一种大脑启发的架构，通过分布式情节记忆增强LLMs，实现了动态、一次性的知识更新，无需昂贵的重新训练或微调，且在速度和灵活性上表现出色。 |
| [^5] | [DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and Closely-Related Languages](https://arxiv.org/abs/2403.11009) | DIALECTBENCH是第一个面向自然语言处理中的方言、语言变体和密切相关语言的大规模基准测试，为实现对不同语言变体上NLP系统性能的全面评估提供了重要工具。 |
| [^6] | [GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting](https://arxiv.org/abs/2403.08551) | 通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。 |
| [^7] | [SMART: Submodular Data Mixture Strategy for Instruction Tuning](https://arxiv.org/abs/2403.08370) | SMART引入了一种新颖的数据混合策略，利用子模块函数为任务分配重要性分数，并在微调中重新分配预算，从而在指令调整任务中取得明显优势。 |
| [^8] | [Conditional computation in neural networks: principles and research trends](https://arxiv.org/abs/2403.07965) | 该论文总结了将条件计算方法应用于设计神经网络的新兴领域中的原理和思想，并介绍了专家混合网络、标记选择机制和提前退出神经网络等三种实现方式。 |
| [^9] | [The pitfalls of next-token prediction](https://arxiv.org/abs/2403.06963) | 论文揭示了在某些任务类别中，教师强制方法可能无法在第一时间学习到准确的下一个标记预测器，进而导致模型失败的一般机制。 |
| [^10] | [DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory](https://arxiv.org/abs/2403.01954) | DECIDER是一种受双系统认知理论启发的规则可控解码策略，通过在预训练语言模型中引入逻辑推理器，有效地遵循给定规则以引导生成方向朝向目标。 |
| [^11] | [Clifford-Steerable Convolutional Neural Networks](https://arxiv.org/abs/2402.14730) | 提出了Clifford-Steerable卷积神经网络（CS-CNNs），通过在伪欧几里德空间上处理多矢场，利用Clifford群等变神经网络对$\mathrm{O}(p,q)$可导核进行隐式参数化，显着且一致地优于流体动力学和相对论电动力学预测任务的基准方法 |
| [^12] | [Blending Data-Driven Priors in Dynamic Games](https://arxiv.org/abs/2402.14174) | 探索一种在动态游戏中将数据驱动参考政策与基于优化博弈政策相融合的方法，提出了一种非合作动态博弈KLGame，其中包含了针对每个决策者的可调参数。 |
| [^13] | [Verifiably Following Complex Robot Instructions with Foundation Models](https://arxiv.org/abs/2402.11498) | 提出了一种名为语言指令地面化运动规划（LIMP）系统，利用基础模型和时间逻辑生成指令条件的语义地图，使机器人能够可验证地遵循富有表现力和长期的指令，包括开放词汇参照和复杂的时空约束。 |
| [^14] | [PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation](https://arxiv.org/abs/2402.11161) | 提出了PANDA方法，引入了更精确的答案正确性评测方式，解决了当前自动评估问答和文本生成过程中的挑战。 |
| [^15] | [Can Separators Improve Chain-of-Thought Prompting?](https://arxiv.org/abs/2402.10645) | 分隔符的引入在思维链提示中显著提高了大型语言模型（LLMs）在复杂推理任务上的表现。 |
| [^16] | [Exploring the Adversarial Capabilities of Large Language Models](https://arxiv.org/abs/2402.09132) | 本研究探索了大型语言模型的对抗能力，并发现其能够成功地制造对抗性示例以愚弄安全措施，特别是在仇恨言论检测方面具有重大影响。 |
| [^17] | [Pix2Code: Learning to Compose Neural Visual Concepts as Programs](https://arxiv.org/abs/2402.08280) | Pix2Code 是一个将神经视觉概念组合成程序的框架，通过利用显式、组合的符号和隐式的神经表示能力，从图像中检索对象表示并将关系概念合成为lambda演算程序，来解决通用性和可解释性的挑战。在推理领域Kandinsky Patterns和CURI上的评估结果表明，Pix2Code 能够识别组合视觉概念并推广到新数据和推理任务。 |
| [^18] | [SMX: Sequential Monte Carlo Planning for Expert Iteration](https://arxiv.org/abs/2402.07963) | 这项研究介绍了一种名为SMX的顺序蒙特卡洛规划算法，它利用可扩展的方法创建了有效的自我学习机制。它适用于离散和连续动作空间的环境，具有高并行性能。 |
| [^19] | [Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing](https://arxiv.org/abs/2402.06794) | 本文介绍了使用GPT-4V进行可解释风险评估的方法，该方法通过解释复杂的过马路场景，为盲人和视力低下人士的安全决策提供支持。 |
| [^20] | [Personalized Language Modeling from Personalized Human Feedback](https://arxiv.org/abs/2402.05133) | 该论文提出了一个个性化语言模型的方法，通过在于用户的反馈数据中引入个性化特征来解决强化学习框架在多样化用户偏好下存在的问题。 |
| [^21] | [On the Completeness of Invariant Geometric Deep Learning Models](https://arxiv.org/abs/2402.04836) | 这项研究集中于不变模型的理论表达能力，通过引入完备的设计GeoNGNN，并利用其作为理论工具，首次证明了E(3)-完备性。 |
| [^22] | [V-IRL: Grounding Virtual Intelligence in Real Life](https://arxiv.org/abs/2402.03310) | V-IRL是一个平台，可以让人工智能代理在虚拟环境中与现实世界进行互动，旨在将数字和物理世界之间的差距缩小，并开发出具有丰富感知、决策和与真实数据互动能力的代理。 |
| [^23] | [Revisiting Graph-Based Fraud Detection in Sight of Heterophily and Spectrum](https://arxiv.org/abs/2312.06441) | 本文提出了一种基于半监督GNN的欺诈检测器SEC-GFD，通过混合过滤模块和局部环境约束模块解决了异质性和标签利用问题。 |
| [^24] | [An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition](https://arxiv.org/abs/2309.00903) | 该论文提出了一个针对医学成像中的可解释AI的三维框架，旨在解决神经科学领域中识别大脑沟特征的复杂性问题。 |
| [^25] | [An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models.](http://arxiv.org/abs/2401.06692) | 该论文提出了一个实验设计框架来减少大型语言模型有限标签监督微调的注释成本，并解决了主动学习的计算瓶颈问题。 |
| [^26] | [Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers.](http://arxiv.org/abs/2401.06461) | 本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。 |
| [^27] | [Machine unlearning through fine-grained model parameters perturbation.](http://arxiv.org/abs/2401.04385) | 本文提出了一种精细的机器去学习策略，通过细粒度模型参数的扰动来实现用户隐私保护，同时保持可控的计算成本。采用遗忘率和记忆保留率等新的指标来评估去学习效果和模型泛化能力。 |
| [^28] | [Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning.](http://arxiv.org/abs/2401.02710) | 本文提出了一种基于强化学习的方法，通过扩展搜索空间和利用预训练的公式化alpha集来生成协同公式化alpha因子，从而提高量化交易的性能。 |
| [^29] | [Memory, Consciousness and Large Language Model.](http://arxiv.org/abs/2401.02509) | 该论文研究了大型语言模型（LLM）与图尔文的记忆理论之间的对应关系，并提出了意识可能是一种基于这种对应关系的新兴能力的猜想。 |
| [^30] | [Locating Cross-Task Sequence Continuation Circuits in Transformers.](http://arxiv.org/abs/2311.04131) | 通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。 |
| [^31] | [Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems.](http://arxiv.org/abs/2310.01991) | 本文探讨了LLM在数学应用题中的逆向推理能力，发现在逆向推理任务上，LLM模型的准确性显著下降。通过改进技术，如Rephrase和PAL-Tools，我们提高了模型的性能。 |
| [^32] | [FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare.](http://arxiv.org/abs/2309.12325) | FUTURE-AI是第一个国际共识框架，为医疗保健领域的可信AI工具开发和部署提供指导原则和最佳实践。 |
| [^33] | [Towards LLM-based Autograding for Short Textual Answers.](http://arxiv.org/abs/2309.11508) | 本文评估了大型语言模型（LLMs）在自动评分中的应用，并强调了它们如何支持教育工作者验证评分程序。研究结果表明，“开箱即用”的LLMs作为补充视角提供了有价值的工具，但仍需进一步优化其可用性和性能。 |
| [^34] | [SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation.](http://arxiv.org/abs/2309.06824) | 本文提出了SAMUS，一个专为超声图像分割量身定制的通用模型，通过引入并行CNN分支和适配器来改善SAM在医学图像分割中的性能和泛化能力。 |
| [^35] | [Lifelike Agility and Play on Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models.](http://arxiv.org/abs/2308.15143) | 该论文提出了一种使用生成模型和强化学习的框架，使四足机器人能够在复杂环境中像真实动物一样具有灵活性和策略。通过预训练生成模型，保留了动物行为的知识，并通过学习适应环境，克服挑战性的障碍。 |
| [^36] | [Normative Conditional Reasoning as a Fragment of HOL.](http://arxiv.org/abs/2308.10686) | 本论文报告了关于正式化条件推理的研究结果，包括Aqvist的条件义务系统E的机械化和伦理论据评估的工具的开发。 |
| [^37] | [A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency.](http://arxiv.org/abs/2307.13549) | 本研究提出了一种使用规划本体表示和利用规划知识的方法来提高自动规划的性能效率。通过构建一个规划本体，并利用国际规划竞赛的数据进行实验，证明了本体能够选择有前景的规划器，并使用从本体中提取的宏观约束来提高它们的性能。 |
| [^38] | [Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey).](http://arxiv.org/abs/2307.10246) | 本文综述了深度神经网络和脑对齐的研究，重点在于脑编码和解码模型的应用。这些模型对于理解大脑的信息处理机制以及设计脑机接口具有重要意义。 |
| [^39] | [TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction.](http://arxiv.org/abs/2307.10003) | 本文提出了一种名为TbExplain的框架，它利用XAI技术和预训练的对象检测器，通过文本形式解释场景分类模型，并引入了一种新的方法来纠正预测和进行文本解释。 |
| [^40] | [Neuro-Inspired Efficient Map Building via Fragmentation and Recall.](http://arxiv.org/abs/2307.05793) | 本文提出了一种神经启发的地图构建方法，通过分割和回溯来解决大型环境下的探索问题，并基于意外性的空间聚类设置探索子目标。 |
| [^41] | [Shadows of quantum machine learning.](http://arxiv.org/abs/2306.00061) | 量子机器学习模型需要使用量子计算机进行评估，但我们提出在训练完后，使用量子计算机生成一个经典阴影模型来计算函数的经典计算近似，避免了对量子计算机的需求。 |
| [^42] | [Physical Deep Reinforcement Learning: Safety and Unknown Unknowns.](http://arxiv.org/abs/2305.16614) | 本文提出了Phy-DRL，这是一个物理模型调整的深度强化学习框架。该框架有三个创新点，它们分别是: i)前瞻性的未知未知训练，ii)结合残差控制，以及iii)基于物理模型的神经网络编辑。Phy-DRL能够容忍未知干扰，保证安全和稳定，同时遵守Bellman方程和奖励相关的物理知识。 |
| [^43] | [Certified Zeroth-order Black-Box Defense with Robust UNet Denoiser.](http://arxiv.org/abs/2304.06430) | 本文提出了一种带有鲁棒UNet去噪器的认证零阶黑盒防御方法，通过在黑盒模型之前预置RDUNet和DS或AE和RDUNet，成功提高了模型鲁棒性。 |
| [^44] | [KGS: Causal Discovery Using Knowledge-guided Greedy Equivalence Search.](http://arxiv.org/abs/2304.05493) | KGS是一种新颖的因果推断方法，通过利用先前的因果边缘信息作为约束条件，可以更准确地学习因果图。 |
| [^45] | [BugNIST -- A New Large Scale Volumetric 3D Image Dataset for Classification and Detection.](http://arxiv.org/abs/2304.01838) | 本文介绍了一个名为BugNIST的广泛数据集，该数据集由12种昆虫和幼虫的微-CT扫描组成。通过训练和测试检测模型，BugNIST旨在评估三维体积图像分类和检测方法，解决上下文无关的挑战。 |
| [^46] | [MenuCraft: Interactive Menu System Design with Large Language Models.](http://arxiv.org/abs/2303.04496) | MenuCraft是一个基于大型语言模型的AI辅助设计师，通过对话系统与设计师协作，提供了一个交互式菜单设计工具，可以简化菜单设计过程，并支持零/少次学习。 |
| [^47] | [Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents.](http://arxiv.org/abs/2302.01560) | 本论文研究了在开放世界环境中多任务具身智能体的任务规划挑战，提出了一种基于大型语言模型的交互式规划方法(DEPS)来解决计划执行的准确性和效率问题。 |
| [^48] | [Res2NetFuse: A Fusion Method for Infrared and Visible Images.](http://arxiv.org/abs/2112.14540) | 本文提出了一种基于Res2Net的红外和可见光图像融合框架，通过引入新的训练策略和融合策略，实现了最先进的融合性能。 |

# 详细

[^1]: 小型模型是大型模型的计算节省者

    Tiny Models are the Computational Saver for Large Models

    [https://arxiv.org/abs/2403.17726](https://arxiv.org/abs/2403.17726)

    TinySaver是一种动态模型压缩方法，通过使用小型模型来自适应地替换大型模型，从而提高计算效率。

    

    本文介绍了TinySaver，一种类似于早期退出的动态模型压缩方法，它使用小型模型来自适应地替换大型模型。与传统的压缩技术不同，像TinySaver这样的动态方法可以利用难度差异，使得某些输入能够提前完成推理过程，从而节省计算资源。大多数现有的早期退出设计是通过向模型的骨干结构附加额外的网络分支来实现的。然而，我们的研究揭示了完全独立的小型模型可以在对性能影响最小的情况下替代较大模型的大部分工作。将它们作为第一个退出点可以显著提高计算效率。通过搜索并使用最合适的小型模型作为给定大型模型的计算节省者，所提出的方法作为一种新颖且通用的模型压缩方法。

    arXiv:2403.17726v1 Announce Type: new  Abstract: This paper introduces TinySaver, an early-exit-like dynamic model compression approach which employs tiny models to substitute large models adaptively. Distinct from traditional compression techniques, dynamic methods like TinySaver can leverage the difficulty differences to allow certain inputs to complete their inference processes early, thereby conserving computational resources. Most existing early exit designs are implemented by attaching additional network branches to the model's backbone. Our study, however, reveals that completely independent tiny models can replace a substantial portion of the larger models' job with minimal impact on performance. Employing them as the first exit can remarkably enhance computational efficiency. By searching and employing the most appropriate tiny model as the computational saver for a given large model, the proposed approaches work as a novel and generic method to model compression. This finding
    
[^2]: 教育中学习、分析和人工智能的相互作用

    The Interplay of Learning, Analytics, and Artificial Intelligence in Education

    [https://arxiv.org/abs/2403.16081](https://arxiv.org/abs/2403.16081)

    本文提出了 AI 在学习和教育中的多维视角，强调了 AI、分析和学习过程之间错综复杂的相互作用，挑战了将 AI 视为随机工具的观念，强调了 AI 作为理解人类学习的重要性，并提出了三种独特的教育中人工智能的概念化。

    

    本文提出了人工智能在学习和教育中的多维视角，强调人工智能、分析和学习过程之间错综复杂的相互作用。笔者挑战了将人工智能仅视为随机工具的普遍观念，例如生成式人工智能，主张重视对人工智能的替代概念。文章突出了人类智能与人工信息处理之间的差异，AI算法中固有的认知多样性，并提出AI也可以作为理解人类学习的工具。从将AI视为人类智能的类比的早期学习科学和教育中的AI研究已经偏离这一观点，促使有必要重新点燃这种联系。本文提出了三种独特的教育中人工智能的概念化：人类认知的外部化、内化AI模型以影响人类思维

    arXiv:2403.16081v1 Announce Type: cross  Abstract: This paper presents a multi dimensional view of AI's role in learning and education, emphasizing the intricate interplay between AI, analytics, and the learning processes. Here, I challenge the prevalent narrow conceptualization of AI as stochastic tools, as exemplified in generative AI, and argue for the importance of alternative conceptualisations of AI. I highlight the differences between human intelligence and artificial information processing, the cognitive diversity inherent in AI algorithms, and posit that AI can also serve as an instrument for understanding human learning. Early learning sciences and AI in Education research, which saw AI as an analogy for human intelligence, have diverged from this perspective, prompting a need to rekindle this connection. The paper presents three unique conceptualizations of AI in education: the externalization of human cognition, the internalization of AI models to influence human thought pr
    
[^3]: 探索直到自信: 面向具身问答的高效探索

    Explore until Confident: Efficient Exploration for Embodied Question Answering

    [https://arxiv.org/abs/2403.15941](https://arxiv.org/abs/2403.15941)

    通过利用大型视觉-语言模型的语义推理能力，结合深度信息和视觉提示，提出了一种方法来解决具身问答中的有效探索和回答问题的挑战

    

    我们考虑了具身问答（EQA）的问题，这指的是在需要主动探索环境以收集信息直到对问题的答案有自信的具身代理，例如机器人。在这项工作中，我们利用大规模视觉-语言模型（VLMs）的强大语义推理能力来高效探索和回答这些问题。然而，在EQA中使用VLMs时存在两个主要挑战：它们没有内部记忆将场景映射以便规划如何随时间探索，并且它们的置信度可能被错误校准并可能导致机器人过早停止探索或过度探索。我们提出了一种方法，首先基于深度信息和通过视觉提示VLM来构建场景的语义地图-利用其对场景相关区域的广泛知识来进行探索。接下来，我们使用符合预测来校准VLM的置信度。

    arXiv:2403.15941v1 Announce Type: cross  Abstract: We consider the problem of Embodied Question Answering (EQA), which refers to settings where an embodied agent such as a robot needs to actively explore an environment to gather information until it is confident about the answer to a question. In this work, we leverage the strong semantic reasoning capabilities of large vision-language models (VLMs) to efficiently explore and answer such questions. However, there are two main challenges when using VLMs in EQA: they do not have an internal memory for mapping the scene to be able to plan how to explore over time, and their confidence can be miscalibrated and can cause the robot to prematurely stop exploration or over-explore. We propose a method that first builds a semantic map of the scene based on depth information and via visual prompting of a VLM - leveraging its vast knowledge of relevant regions of the scene for exploration. Next, we use conformal prediction to calibrate the VLM's 
    
[^4]: Larimar: 具有情节记忆控制的大型语言模型

    Larimar: Large Language Models with Episodic Memory Control

    [https://arxiv.org/abs/2403.11901](https://arxiv.org/abs/2403.11901)

    Larimar提出了一种大脑启发的架构，通过分布式情节记忆增强LLMs，实现了动态、一次性的知识更新，无需昂贵的重新训练或微调，且在速度和灵活性上表现出色。

    

    本文提出了Larimar - 一种新颖的、受大脑启发的架构，用于增强大型语言模型(LLMs)的分布式情节记忆。 Larimar的记忆允许动态、一次性更新知识，无需进行计算昂贵的重新训练或微调。在多个事实编辑基准测试上的实验结果表明，Larimar在速度方面表现优异 - 根据基础LLM的不同，速度提升为4-10倍，并且由于提出的架构简单、不依赖于LLM，因此具有良好的灵活性和通用性。我们进一步提供了选择性事实遗忘和输入上下文长度概括机制，并展示了它们的有效性。

    arXiv:2403.11901v1 Announce Type: cross  Abstract: Efficient and accurate updating of knowledge stored in Large Language Models (LLMs) is one of the most pressing research challenges today. This paper presents Larimar - a novel, brain-inspired architecture for enhancing LLMs with a distributed episodic memory. Larimar's memory allows for dynamic, one-shot updates of knowledge without the need for computationally expensive re-training or fine-tuning. Experimental results on multiple fact editing benchmarks demonstrate that Larimar attains accuracy comparable to most competitive baselines, even in the challenging sequential editing setup, but also excels in speed - yielding speed-ups of 4-10x depending on the base LLM - as well as flexibility due to the proposed architecture being simple, LLM-agnostic, and hence general. We further provide mechanisms for selective fact forgetting and input context length generalization with Larimar and show their effectiveness.
    
[^5]: DIALECTBENCH：一个方言、语言变体和密切相关语言的自然语言处理基准

    DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and Closely-Related Languages

    [https://arxiv.org/abs/2403.11009](https://arxiv.org/abs/2403.11009)

    DIALECTBENCH是第一个面向自然语言处理中的方言、语言变体和密切相关语言的大规模基准测试，为实现对不同语言变体上NLP系统性能的全面评估提供了重要工具。

    

    arXiv:2403.11009v1 语种：交叉  摘要：语言技术应该根据其在实际用例中的有用性来判断。在自然语言处理（NLP）研究和评估中经常被忽视的一个方面是非标准方言或语言变体（以下简称为变体）形式的语言变体. 大多数NLP基准测试仅限于标准语言变体。为填补这一空白，我们提出了DIALECTBENCH，这是首个针对语言变体的大规模NLP基准测试，汇总了一系列多样任务样本的变体数据集（涵盖281种变体的10个文本级任务）。这允许对不同语言变体上NLP系统性能进行全面评估。我们提供了大量证据表明标准语言变体与非标准语言变体之间存在性能差距，并且我们还确定了在任务之间存在大量性能差距的语言类群。我们认为DIALECTBENCH提供了对当前语言NLP状态的全面视图。

    arXiv:2403.11009v1 Announce Type: cross  Abstract: Language technologies should be judged on their usefulness in real-world use cases. An often overlooked aspect in natural language processing (NLP) research and evaluation is language variation in the form of non-standard dialects or language varieties (hereafter, varieties). Most NLP benchmarks are limited to standard language varieties. To fill this gap, we propose DIALECTBENCH, the first-ever large-scale benchmark for NLP on varieties, which aggregates an extensive set of task-varied variety datasets (10 text-level tasks covering 281 varieties). This allows for a comprehensive evaluation of NLP system performance on different language varieties. We provide substantial evidence of performance disparities between standard and non-standard language varieties, and we also identify language clusters with large performance divergence across tasks. We believe DIALECTBENCH provides a comprehensive view of the current state of NLP for langua
    
[^6]: 高斯图像：通过2D高斯喷涂进行1000帧每秒的图像表示和压缩

    GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting

    [https://arxiv.org/abs/2403.08551](https://arxiv.org/abs/2403.08551)

    通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。

    

    最近，隐式神经表示（INR）在图像表示和压缩方面取得了巨大成功，提供了高视觉质量和快速渲染速度，每秒10-1000帧，假设有足够的GPU资源可用。然而，这种要求常常阻碍了它们在内存有限的低端设备上的使用。为此，我们提出了一种通过2D高斯喷涂进行图像表示和压缩的开创性范式，名为GaussianImage。我们首先引入2D高斯来表示图像，其中每个高斯具有8个参数，包括位置、协方差和颜色。随后，我们揭示了一种基于累积求和的新颖渲染算法。值得注意的是，我们的方法使用GPU内存至少降低3倍，拟合时间快5倍，不仅在表示性能上与INR（例如WIRE，I-NGP）不相上下，而且无论参数大小如何都能提供1500-2000帧每秒的更快渲染速度。

    arXiv:2403.08551v1 Announce Type: cross  Abstract: Implicit neural representations (INRs) recently achieved great success in image representation and compression, offering high visual quality and fast rendering speeds with 10-1000 FPS, assuming sufficient GPU resources are available. However, this requirement often hinders their use on low-end devices with limited memory. In response, we propose a groundbreaking paradigm of image representation and compression by 2D Gaussian Splatting, named GaussianImage. We first introduce 2D Gaussian to represent the image, where each Gaussian has 8 parameters including position, covariance and color. Subsequently, we unveil a novel rendering algorithm based on accumulated summation. Remarkably, our method with a minimum of 3$\times$ lower GPU memory usage and 5$\times$ faster fitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation performance, but also delivers a faster rendering speed of 1500-2000 FPS regardless of parameter size. 
    
[^7]: SMART: 用于指令调整的子模块数据混合策略

    SMART: Submodular Data Mixture Strategy for Instruction Tuning

    [https://arxiv.org/abs/2403.08370](https://arxiv.org/abs/2403.08370)

    SMART引入了一种新颖的数据混合策略，利用子模块函数为任务分配重要性分数，并在微调中重新分配预算，从而在指令调整任务中取得明显优势。

    

    指令调整涉及在一组以指令格式化的数据集上对语言模型进行微调，以增强模型对未见任务的泛化能力。研究表明，在微调过程中平衡不同任务比例的重要性，但找到合适的平衡仍然具有挑战性。目前除了手动调整或依赖从业者的直觉外，尚无系统方法。在本文中，我们介绍了SMART（Submodular data Mixture strAtegy for instRuction Tuning）- 一种利用子模块函数为任务分配重要性分数的新颖数据混合策略，然后用这些分数来确定混合权重。给定微调预算，SMART重新分配任务间的预算，并从每个任务中选择非冗余样本。实验结果表明，SMART显著优于传统方法，如例子比例混合和均等分配。

    arXiv:2403.08370v1 Announce Type: cross  Abstract: Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks. Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance remains challenging. Unfortunately, there's currently no systematic method beyond manual tuning or relying on practitioners' intuition. In this paper, we introduce SMART (Submodular data Mixture strAtegy for instRuction Tuning) - a novel data mixture strategy which makes use of a submodular function to assign importance scores to tasks which are then used to determine the mixture weights. Given a fine-tuning budget, SMART redistributes the budget among tasks and selects non-redundant samples from each task. Experimental results demonstrate that SMART significantly outperforms traditional methods such as examples proportional mixing and equal
    
[^8]: 神经网络中的条件计算: 原理与研究趋势

    Conditional computation in neural networks: principles and research trends

    [https://arxiv.org/abs/2403.07965](https://arxiv.org/abs/2403.07965)

    该论文总结了将条件计算方法应用于设计神经网络的新兴领域中的原理和思想，并介绍了专家混合网络、标记选择机制和提前退出神经网络等三种实现方式。

    

    这篇文章总结了将条件计算方法应用于设计神经网络的新兴领域中的原理和思想。我们特别关注可以根据输入动态激活或去激活其计算图部分的神经网络。例如，动态选择输入标记、层（或一组层）以及每个层内的子模块（例如，卷积滤波器中的通道）。我们首先提供一个通用形式来统一描述这些技术。然后，我们介绍了这些原则的三个值得注意的实现：专家混合（MoEs）网络、标记选择机制和提前退出神经网络。本文旨在向这一不断发展的领域提供类似教程的介绍。为此，我们分析了这些模块化设计在效率、可解释性和迁移学习方面的好处，重点放在...

    arXiv:2403.07965v1 Announce Type: cross  Abstract: This article summarizes principles and ideas from the emerging area of applying \textit{conditional computation} methods to the design of neural networks. In particular, we focus on neural networks that can dynamically activate or de-activate parts of their computational graph conditionally on their input. Examples include the dynamic selection of, e.g., input tokens, layers (or sets of layers), and sub-modules inside each layer (e.g., channels in a convolutional filter). We first provide a general formalism to describe these techniques in an uniform way. Then, we introduce three notable implementations of these principles: mixture-of-experts (MoEs) networks, token selection mechanisms, and early-exit neural networks. The paper aims to provide a tutorial-like introduction to this growing field. To this end, we analyze the benefits of these modular designs in terms of efficiency, explainability, and transfer learning, with a focus on em
    
[^9]: 下一个标记预测的陷阱

    The pitfalls of next-token prediction

    [https://arxiv.org/abs/2403.06963](https://arxiv.org/abs/2403.06963)

    论文揭示了在某些任务类别中，教师强制方法可能无法在第一时间学习到准确的下一个标记预测器，进而导致模型失败的一般机制。

    

    一篇关于下一个标记预测的论文。我们提出了一个直观的担忧：一个仅仅基于下一个标记预测的模型是否能忠实地模拟人类智能。我们认为下一个标记预测中经常混淆的两个阶段 -- 自回归推断和教师强制训练 -- 必须被区别对待。我们描述了一个一般机制，展示了教师强制如何失败，并设计了一个最小化计划任务，在这个任务中Transformer和Mamba架构在实践中以这种方式失败 -- 尽管任务本身很容易学习。

    arXiv:2403.06963v1 Announce Type: cross  Abstract: Can a mere next-token predictor faithfully model human intelligence? We crystallize this intuitive concern, which is fragmented in the literature. As a starting point, we argue that the two often-conflated phases of next-token prediction -- autoregressive inference and teacher-forced training -- must be treated distinctly. The popular criticism that errors can compound during autoregressive inference, crucially assumes that teacher-forcing has learned an accurate next-token predictor. This assumption sidesteps a more deep-rooted problem we expose: in certain classes of tasks, teacher-forcing can simply fail to learn an accurate next-token predictor in the first place. We describe a general mechanism of how teacher-forcing can fail, and design a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn. We provide preliminary
    
[^10]: DECIDERS：一种通过模仿双系统认知理论实现规则可控解码策略的语言生成方法

    DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory

    [https://arxiv.org/abs/2403.01954](https://arxiv.org/abs/2403.01954)

    DECIDER是一种受双系统认知理论启发的规则可控解码策略，通过在预训练语言模型中引入逻辑推理器，有效地遵循给定规则以引导生成方向朝向目标。

    

    词典约束解码方法旨在通过某些目标概念控制所生成文本的意义或风格。现有方法过于关注这些目标本身，导致缺乏关于如何实现这些目标的高层推理。然而，人类通常通过遵循某些规则来处理任务，这些规则不仅关注于目标本身，还关注于引发目标发生的语义相关概念。在这项工作中，我们提出了DECIDER，这是一种受到双系统认知理论启发的约束语言生成的规则可控解码策略。具体而言，在DECIDER中，一个预训练语言模型（PLM）配备了一个逻辑推理器，以高层规则作为输入。然后，DECIDER允许规则信号在每个解码步骤中流入PLM。广泛的实验结果表明，DECIDER能够有效地遵循给定的规则，引导生成方向朝向目标进行生成。

    arXiv:2403.01954v1 Announce Type: cross  Abstract: Lexicon-based constrained decoding approaches aim to control the meaning or style of the generated text through certain target concepts. Existing approaches over-focus the targets themselves, leading to a lack of high-level reasoning about how to achieve them. However, human usually tackles tasks by following certain rules that not only focuses on the targets but also on semantically relevant concepts that induce the occurrence of targets. In this work, we present DECIDER, a rule-controllable decoding strategy for constrained language generation inspired by dual-system cognitive theory. Specifically, in DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner that takes high-level rules as input. Then, the DECIDER allows rule signals to flow into the PLM at each decoding step. Extensive experimental results demonstrate that DECIDER can effectively follow given rules to guide generation direction toward the targets i
    
[^11]: Clifford-Steerable卷积神经网络

    Clifford-Steerable Convolutional Neural Networks

    [https://arxiv.org/abs/2402.14730](https://arxiv.org/abs/2402.14730)

    提出了Clifford-Steerable卷积神经网络（CS-CNNs），通过在伪欧几里德空间上处理多矢场，利用Clifford群等变神经网络对$\mathrm{O}(p,q)$可导核进行隐式参数化，显着且一致地优于流体动力学和相对论电动力学预测任务的基准方法

    

    我们提出了Clifford-Steerable卷积神经网络（CS-CNNs），这是一种新颖的$\mathrm{E}(p, q)$等变CNN类。 CS-CNNs在伪欧几里德空间$\mathbb{R}^{p,q}$上处理多矢场。 它们涵盖了例如$\mathrm{E}(3)$在$\mathbb{R}^3$上和Poincar\'e在闵可夫斯基时空$\mathbb{R}^{1,3}$上的等变性。 我们的方法基于通过Clifford群等变神经网络对$\mathrm{O}(p,q)$可导核进行隐式参数化。 在流体动力学和相对论电动力学预测任务上，我们在基准方法上显着且一致地表现出色。

    arXiv:2402.14730v1 Announce Type: cross  Abstract: We present Clifford-Steerable Convolutional Neural Networks (CS-CNNs), a novel class of $\mathrm{E}(p, q)$-equivariant CNNs. CS-CNNs process multivector fields on pseudo-Euclidean spaces $\mathbb{R}^{p,q}$. They cover, for instance, $\mathrm{E}(3)$-equivariance on $\mathbb{R}^3$ and Poincar\'e-equivariance on Minkowski spacetime $\mathbb{R}^{1,3}$. Our approach is based on an implicit parametrization of $\mathrm{O}(p,q)$-steerable kernels via Clifford group equivariant neural networks. We significantly and consistently outperform baseline methods on fluid dynamics as well as relativistic electrodynamics forecasting tasks.
    
[^12]: 在动态游戏中融合数据驱动的先验知识

    Blending Data-Driven Priors in Dynamic Games

    [https://arxiv.org/abs/2402.14174](https://arxiv.org/abs/2402.14174)

    探索一种在动态游戏中将数据驱动参考政策与基于优化博弈政策相融合的方法，提出了一种非合作动态博弈KLGame，其中包含了针对每个决策者的可调参数。

    

    随着智能机器人如自动驾驶车辆在人群中的部署越来越多，这些系统应该在安全的、与人互动意识相关的运动规划中利用基于模型的博弈论规划器与数据驱动政策的程度仍然是一个悬而未决的问题。本文探讨了一种融合数据驱动参考政策和基于优化的博弈论政策的原则性方法。我们制定了KLGame，这是一种带有Kullback-Leibler（KL）正则化的非合作动态博弈，针对一个一般的、随机的，可能是多模式的参考政策。

    arXiv:2402.14174v1 Announce Type: cross  Abstract: As intelligent robots like autonomous vehicles become increasingly deployed in the presence of people, the extent to which these systems should leverage model-based game-theoretic planners versus data-driven policies for safe, interaction-aware motion planning remains an open question. Existing dynamic game formulations assume all agents are task-driven and behave optimally. However, in reality, humans tend to deviate from the decisions prescribed by these models, and their behavior is better approximated under a noisy-rational paradigm. In this work, we investigate a principled methodology to blend a data-driven reference policy with an optimization-based game-theoretic policy. We formulate KLGame, a type of non-cooperative dynamic game with Kullback-Leibler (KL) regularization with respect to a general, stochastic, and possibly multi-modal reference policy. Our method incorporates, for each decision maker, a tunable parameter that pe
    
[^13]: 使用基础模型可验证地遵循复杂机器人指令

    Verifiably Following Complex Robot Instructions with Foundation Models

    [https://arxiv.org/abs/2402.11498](https://arxiv.org/abs/2402.11498)

    提出了一种名为语言指令地面化运动规划（LIMP）系统，利用基础模型和时间逻辑生成指令条件的语义地图，使机器人能够可验证地遵循富有表现力和长期的指令，包括开放词汇参照和复杂的时空约束。

    

    让机器人能够遵循复杂的自然语言指令是一个重要但具有挑战性的问题。人们希望在指导机器人时能够灵活表达约束，指向任意地标并验证行为。相反，机器人必须将人类指令消除歧义，将指令参照物联系到真实世界中。我们提出了一种名为语言指令地面化运动规划（LIMP）的系统，该系统利用基础模型和时间逻辑生成指令条件的语义地图，使机器人能够可验证地遵循富有表现力和长期的指令，涵盖了开放词汇参照和复杂的时空约束。与先前在机器人任务执行中使用基础模型的方法相比，LIMP构建了一个可解释的指令表示，揭示了机器人与指导者预期动机的一致性，并实现了机器人行为的综合。

    arXiv:2402.11498v1 Announce Type: cross  Abstract: Enabling robots to follow complex natural language instructions is an important yet challenging problem. People want to flexibly express constraints, refer to arbitrary landmarks and verify behavior when instructing robots. Conversely, robots must disambiguate human instructions into specifications and ground instruction referents in the real world. We propose Language Instruction grounding for Motion Planning (LIMP), a system that leverages foundation models and temporal logics to generate instruction-conditioned semantic maps that enable robots to verifiably follow expressive and long-horizon instructions with open vocabulary referents and complex spatiotemporal constraints. In contrast to prior methods for using foundation models in robot task execution, LIMP constructs an explainable instruction representation that reveals the robot's alignment with an instructor's intended motives and affords the synthesis of robot behaviors that 
    
[^14]: PANDA（Pedantic ANswer-correctness Determination and Adjudication）：改进问答和文本生成的自动评估

    PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation

    [https://arxiv.org/abs/2402.11161](https://arxiv.org/abs/2402.11161)

    提出了PANDA方法，引入了更精确的答案正确性评测方式，解决了当前自动评估问答和文本生成过程中的挑战。

    

    问答（QA）只有在我们知道答案是否正确时才能取得进展，但对于许多最具挑战性和有趣的QA示例，当前的答案正确性（AC）指标与人类判断不一致，特别是来自大型语言模型（LLM）的冗长、自由格式答案。我们提出了两个挑战：缺乏数据和模型过大。基于LLM的评分器与人类更好地相关，但这项昂贵的任务仅在有限的QA数据集上进行了测试。我们通过提供清晰的指南来评估从人类QA比赛中采纳的机器QA，解决了这些问题。我们还引入了精确的答案正确性确定和裁决（Precise ANswer correctness Determination and Adjudication，PANDA），这是一个小巧、高效、确定性的AC分类器（812 KB），更准确地评估答案的正确性。

    arXiv:2402.11161v1 Announce Type: cross  Abstract: Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current answer correctness (AC) metrics do not align with human judgments, particularly verbose, free form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big. LLM based scorers correlate better with humans, but this expensive task has only been tested on limited QA datasets. We rectify these issues by providing clear guidelines for evaluating machine QA adopted from human QA contests. We also introduce Precise ANswer correctness Determination and Adjudication (PANDA), a small, efficient, deterministic AC classifier (812 KB) that more accurately evaluates answer correctness.
    
[^15]: 分隔符是否可以提高思维链提示的效果？

    Can Separators Improve Chain-of-Thought Prompting?

    [https://arxiv.org/abs/2402.10645](https://arxiv.org/abs/2402.10645)

    分隔符的引入在思维链提示中显著提高了大型语言模型（LLMs）在复杂推理任务上的表现。

    

    Chain-of-thought (CoT) prompting是一种简单有效的方法，用于提高大型语言模型（LLMs）的推理能力。CoT的基本理念是通过将示例放在输入提示中，让LLMs逐步拆解他们的思维过程。然而，CoT提示的密集结构可能导致LLMs的认知负荷过重。受人类认知启发，我们引入了CoT-Sep，一种新颖的方法，在CoT提示中每个示例的末尾策略性地应用分隔符。这些分隔符旨在帮助LLMs在推理过程中更好地理解他们的思维过程。结果表明，与不使用分隔符的普通CoT相比，CoT-Sep显著提高了LLMs在复杂推理任务（如GSM-8K、AQuA、CSQA）上的表现。我们还研究了不同类型和位置的分隔符对多个LLMs（包括GPT-3.5-Turbo、GPT-4和LLaMA-27）的影响。

    arXiv:2402.10645v1 Announce Type: cross  Abstract: Chain-of-thought (CoT) prompting is a simple and effective method for improving the reasoning capabilities of Large language models (LLMs). The basic idea of CoT is to let LLMs break down their thought processes step-by-step by putting exemplars in the input prompt. However, the densely structured prompt exemplars of CoT may cause the cognitive overload of LLMs. Inspired by human cognition, we introduce CoT-Sep, a novel method that strategically employs separators at the end of each exemplar in CoT prompting. These separators are designed to help the LLMs understand their thought processes better while reasoning. It turns out that CoT-Sep significantly improves the LLMs' performances on complex reasoning tasks (e.g., GSM-8K, AQuA, CSQA), compared with the vanilla CoT, which does not use separators. We also study the effects of the type and the location of separators tested on multiple LLMs, including GPT-3.5-Turbo, GPT-4, and LLaMA-2 7
    
[^16]: 探索大型语言模型的对抗能力

    Exploring the Adversarial Capabilities of Large Language Models

    [https://arxiv.org/abs/2402.09132](https://arxiv.org/abs/2402.09132)

    本研究探索了大型语言模型的对抗能力，并发现其能够成功地制造对抗性示例以愚弄安全措施，特别是在仇恨言论检测方面具有重大影响。

    

    大型语言模型（LLMs）的普及引发了广泛和普遍的兴趣，因为它们具有强大的语言生成能力，为行业和研究提供了巨大的潜力。尽管以前的研究探讨了LLMs的安全性和隐私问题，但这些模型能否表现出对抗行为的程度仍然尚未完全探索。为了填补这一空白，我们研究常见的公开可用LLMs是否具有能力扰乱文本样本以愚弄安全措施，即所谓的对抗示例或攻击。更具体地说，我们调查LLMs是否本质上能够从良性样本中制造对抗性示例以愚弄现有的安全防线。我们的实验重点关注仇恨言论检测，发现LLMs成功地找到了对抗性扰动，有效地破坏了对仇恨言论检测系统的防御。我们的发现对（半）自动化安全评估和防御具有重要影响。

    arXiv:2402.09132v1 Announce Type: new Abstract: The proliferation of large language models (LLMs) has sparked widespread and general interest due to their strong language generation capabilities, offering great potential for both industry and research. While previous research delved into the security and privacy issues of LLMs, the extent to which these models can exhibit adversarial behavior remains largely unexplored. Addressing this gap, we investigate whether common publicly available LLMs have inherent capabilities to perturb text samples to fool safety measures, so-called adversarial examples resp.~attacks. More specifically, we investigate whether LLMs are inherently able to craft adversarial examples out of benign samples to fool existing safe rails. Our experiments, which focus on hate speech detection, reveal that LLMs succeed in finding adversarial perturbations, effectively undermining hate speech detection systems. Our findings carry significant implications for (semi-)aut
    
[^17]: Pix2Code：学习将神经视觉概念组合成程序

    Pix2Code: Learning to Compose Neural Visual Concepts as Programs

    [https://arxiv.org/abs/2402.08280](https://arxiv.org/abs/2402.08280)

    Pix2Code 是一个将神经视觉概念组合成程序的框架，通过利用显式、组合的符号和隐式的神经表示能力，从图像中检索对象表示并将关系概念合成为lambda演算程序，来解决通用性和可解释性的挑战。在推理领域Kandinsky Patterns和CURI上的评估结果表明，Pix2Code 能够识别组合视觉概念并推广到新数据和推理任务。

    

    在无监督学习中，学习从图像中抽象概念的挑战在于需要将视觉感知和通用关系推理进行整合。此外，该任务的无监督性质使得人类用户需要能够理解模型学到的概念，并可能修正错误的行为。为了解决视觉概念学习的通用性和可解释性约束，我们提出了Pix2Code，这是一个将程序合成扩展到视觉关系推理的框架，利用了明确的、组合的符号和隐式的神经表示的能力。通过从图像中检索对象表示并将关系概念合成为lambda演算程序来实现这一点。我们在具有挑战性的推理领域Kandinsky Patterns和CURI上评估了Pix2Code的多样特性，从而测试其识别组合视觉概念并推广到新数据和推理任务的能力。

    The challenge in learning abstract concepts from images in an unsupervised fashion lies in the required integration of visual perception and generalizable relational reasoning. Moreover, the unsupervised nature of this task makes it necessary for human users to be able to understand a model's learnt concepts and potentially revise false behaviours. To tackle both the generalizability and interpretability constraints of visual concept learning, we propose Pix2Code, a framework that extends program synthesis to visual relational reasoning by utilizing the abilities of both explicit, compositional symbolic and implicit neural representations. This is achieved by retrieving object representations from images and synthesizing relational concepts as lambda-calculus programs. We evaluate the diverse properties of Pix2Code on the challenging reasoning domains, Kandinsky Patterns and CURI, thereby testing its ability to identify compositional visual concepts that generalize to novel data and co
    
[^18]: SMX: 专家迭代的顺序蒙特卡洛规划

    SMX: Sequential Monte Carlo Planning for Expert Iteration

    [https://arxiv.org/abs/2402.07963](https://arxiv.org/abs/2402.07963)

    这项研究介绍了一种名为SMX的顺序蒙特卡洛规划算法，它利用可扩展的方法创建了有效的自我学习机制。它适用于离散和连续动作空间的环境，具有高并行性能。

    

    发展能够在决策和学习过程中利用规划能力的智能体对于人工智能的进步至关重要。最近的研究已经证明了树状搜索方法和自我对弈学习机制的有效性。然而，由于搜索过程的顺序性质，这些方法通常面临扩展性挑战。虽然实践工程解决方案可以部分克服这个问题，但仍需要大量计算资源，这限制了它们的适用性。在本文中，我们介绍一种名为SMX的基于模型的计划算法，它利用可扩展的顺序蒙特卡洛方法创建了一种有效的自我学习机制。SMX基于控制作为推断的理论框架，并受益于坚实的理论基础。它基于采样的搜索方法使其适应具有离散和连续动作空间的环境。此外，SMX允许高度并行化并可以运行于各类计算机设备上。

    Developing agents that can leverage planning abilities during their decision and learning processes is critical to the advancement of Artificial Intelligence. Recent works have demonstrated the effectiveness of combining tree-based search methods and self-play learning mechanisms. Yet, these methods typically face scaling challenges due to the sequential nature of their search. While practical engineering solutions can partly overcome this, they still demand extensive computational resources, which hinders their applicability. In this paper, we introduce SMX, a model-based planning algorithm that utilises scalable Sequential Monte Carlo methods to create an effective self-learning mechanism. Grounded in the theoretical framework of control as inference, SMX benefits from robust theoretical underpinnings. Its sampling-based search approach makes it adaptable to environments with both discrete and continuous action spaces. Furthermore, SMX allows for high parallelisation and can run on h
    
[^19]: 是否安全过马路？GPT-4V用于安全意识的可解释风险评估

    Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing

    [https://arxiv.org/abs/2402.06794](https://arxiv.org/abs/2402.06794)

    本文介绍了使用GPT-4V进行可解释风险评估的方法，该方法通过解释复杂的过马路场景，为盲人和视力低下人士的安全决策提供支持。

    

    对于盲人和视力低下的人来说，安全地通过街道交叉口是一个复杂的挑战，因为它需要对周围环境有细致的理解，而这个任务很大程度上依赖于视觉线索。传统的辅助决策方法往往不够完善，无法提供全面的场景分析和安全级别判断。本文介绍了一种创新的方法，利用大型多模型来解释复杂的过马路场景，相比传统的交通信号识别技术，提供了潜在的进步。我们的方法通过生成安全评分和自然语言场景描述，支持盲人和视力低下人士安全决策。我们收集了由四足机器人捕获的多视角自我中心图像构成的过马路交叉口数据，并根据预先定义的安全评分分类进行了图像标注。

    Safely navigating street intersections is a complex challenge for blind and low-vision individuals, as it requires a nuanced understanding of the surrounding context - a task heavily reliant on visual cues. Traditional methods for assisting in this decision-making process often fall short, lacking the ability to provide a comprehensive scene analysis and safety level. This paper introduces an innovative approach that leverages large multimodal models (LMMs) to interpret complex street crossing scenes, offering a potential advancement over conventional traffic signal recognition techniques. By generating a safety score and scene description in natural language, our method supports safe decision-making for the blind and low-vision individuals. We collected crosswalk intersection data that contains multiview egocentric images captured by a quadruped robot and annotated the images with corresponding safety scores based on our predefined safety score categorization. Grounded on the visual k
    
[^20]: 个性化语言模型基于个性化人类反馈

    Personalized Language Modeling from Personalized Human Feedback

    [https://arxiv.org/abs/2402.05133](https://arxiv.org/abs/2402.05133)

    该论文提出了一个个性化语言模型的方法，通过在于用户的反馈数据中引入个性化特征来解决强化学习框架在多样化用户偏好下存在的问题。

    

    从个性化人类反馈中进行强化学习（RLHF）是目前主流的框架，用于调整大型语言模型以更好地符合人类偏好。然而，在这个框架下开发的算法的基本前提在用户偏好多样化的情况下可能会出现问题。在本文中，我们旨在通过开发个性化语言模型的方法来解决这个问题。我们首先正式介绍了从个性化人类反馈中学习的任务，并解释了为什么在这种情况下普通的RLHF可能会存在问题。然后，我们提出了一个通用的个性化-RLHF（P-RLHF）框架，需要同时学习用户模型和语言（或奖励）模型。用户模型接收用户信息并输出用户表示。其结构编码了我们对反馈数据中用户偏好的假设。我们为个性化奖励建模和个性化直接偏好优化开发了新的学习目标。

    Reinforcement Learning from Human Feedback (RLHF) is the current dominating framework to fine-tune large language models to better align with human preferences. However, the underlying premise of algorithms developed under this framework can be problematic when user preferences encoded in human feedback are diverse. In this work, we aim to address this problem by developing methods for building personalized language models. We first formally introduce the task of learning from personalized human feedback and explain why vanilla RLHF can be problematic in this context. We then propose a general Personalized-RLHF (P-RLHF) framework, which requires one to jointly learn a user model and a language (or reward) model. The user model takes in user information and outputs user representations. Its structure encodes our assumptions about user preferences underlying the feedback data. We develop new learning objectives for personalized reward modeling and personalized Direct Preference Optimizat
    
[^21]: 关于不变几何深度学习模型的完备性

    On the Completeness of Invariant Geometric Deep Learning Models

    [https://arxiv.org/abs/2402.04836](https://arxiv.org/abs/2402.04836)

    这项研究集中于不变模型的理论表达能力，通过引入完备的设计GeoNGNN，并利用其作为理论工具，首次证明了E(3)-完备性。

    

    不变模型是一类重要的几何深度学习模型，通过利用信息丰富的几何特征生成有意义的几何表示。这些模型以其简单性、良好的实验结果和计算效率而闻名。然而，它们的理论表达能力仍然不清楚，限制了对这种模型潜力的深入理解。在这项工作中，我们集中讨论不变模型的理论表达能力。我们首先严格限制了最经典的不变模型Vanilla DisGNN（结合距离的消息传递神经网络）的表达能力，将其不可识别的情况仅限于高度对称的几何图形。为了打破这些特殊情况的对称性，我们引入了一个简单而完备的不变设计，即嵌套Vanilla DisGNN的GeoNGNN。利用GeoNGNN作为理论工具，我们首次证明了E(3)-完备性。

    Invariant models, one important class of geometric deep learning models, are capable of generating meaningful geometric representations by leveraging informative geometric features. These models are characterized by their simplicity, good experimental results and computational efficiency. However, their theoretical expressive power still remains unclear, restricting a deeper understanding of the potential of such models. In this work, we concentrate on characterizing the theoretical expressiveness of invariant models. We first rigorously bound the expressiveness of the most classical invariant model, Vanilla DisGNN (message passing neural networks incorporating distance), restricting its unidentifiable cases to be only those highly symmetric geometric graphs. To break these corner cases' symmetry, we introduce a simple yet E(3)-complete invariant design by nesting Vanilla DisGNN, named GeoNGNN. Leveraging GeoNGNN as a theoretical tool, we for the first time prove the E(3)-completeness 
    
[^22]: V-IRL: 将虚拟智能与现实生活联系起来

    V-IRL: Grounding Virtual Intelligence in Real Life

    [https://arxiv.org/abs/2402.03310](https://arxiv.org/abs/2402.03310)

    V-IRL是一个平台，可以让人工智能代理在虚拟环境中与现实世界进行互动，旨在将数字和物理世界之间的差距缩小，并开发出具有丰富感知、决策和与真实数据互动能力的代理。

    

    人类生活在地球上，而现代人工智能代理所创造的数字领域之间存在着感官差距。为了开发出在现实世界中能像人类一样灵活感知、思考和行动的人工智能代理，必须弥合数字和物理世界之间的逼真差距。我们如何在一个像我们所居住的世界中一样丰富多样的环境中体现代理，而不受真实硬件和控制所施加的约束？为了实现这个目标，我们引入了V-IRL: 一种平台，可以使代理在虚拟而逼真的环境中与现实世界进行可扩展的互动。我们的平台既是一个开发代理完成各种实际任务的游乐场，又是一个广阔的测试基地，用于衡量在感知、决策和与全球真实数据的互动能力等方面的进展。

    There is a sensory gulf between the Earth that humans inhabit and the digital realms in which modern AI agents are created. To develop AI agents that can sense, think, and act as flexibly as humans in real-world settings, it is imperative to bridge the realism gap between the digital and physical worlds. How can we embody agents in an environment as rich and diverse as the one we inhabit, without the constraints imposed by real hardware and control? Towards this end, we introduce V-IRL: a platform that enables agents to scalably interact with the real world in a virtual yet realistic environment. Our platform serves as a playground for developing agents that can accomplish various practical tasks and as a vast testbed for measuring progress in capabilities spanning perception, decision-making, and interaction with real-world data across the entire globe.
    
[^23]: 在异质性和谱问题下重新审视基于图的欺诈检测

    Revisiting Graph-Based Fraud Detection in Sight of Heterophily and Spectrum

    [https://arxiv.org/abs/2312.06441](https://arxiv.org/abs/2312.06441)

    本文提出了一种基于半监督GNN的欺诈检测器SEC-GFD，通过混合过滤模块和局部环境约束模块解决了异质性和标签利用问题。

    

    基于图的欺诈检测（GFD）可视为一项具有挑战性的半监督节点二分类任务。近年来，图神经网络（GNN）已广泛应用于GFD，通过聚合邻居信息来刻画节点的异常可能性。然而，欺诈图在本质上是异质的，因此大多数GNN由于假设同质性而表现不佳。此外，由于存在异质性和类别不平衡问题，现有模型未充分利用宝贵的节点标签信息。为了解决上述问题，本文提出了一种基于半监督GNN的欺诈检测器SEC-GFD。该检测器包括混合过滤模块和局部环境约束模块，这两个模块分别用于解决异质性和标签利用问题。第一个模块从谱域的角度出发，在一定程度上解决了异质性问题。具体而言，它将图分割称不同的谱成分，

    Graph-based fraud detection (GFD) can be regarded as a challenging semi-supervised node binary classification task. In recent years, Graph Neural Networks (GNN) have been widely applied to GFD, characterizing the anomalous possibility of a node by aggregating neighbor information. However, fraud graphs are inherently heterophilic, thus most of GNNs perform poorly due to their assumption of homophily. In addition, due to the existence of heterophily and class imbalance problem, the existing models do not fully utilize the precious node label information. To address the above issues, this paper proposes a semi-supervised GNN-based fraud detector SEC-GFD. This detector includes a hybrid filtering module and a local environmental constraint module, the two modules are utilized to solve heterophily and label utilization problem respectively. The first module starts from the perspective of the spectral domain, and solves the heterophily problem to a certain extent. Specifically, it divides t
    
[^24]: 一种可解释的三维框架揭示学习模式：变量脑沟识别的统一视角

    An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition

    [https://arxiv.org/abs/2309.00903](https://arxiv.org/abs/2309.00903)

    该论文提出了一个针对医学成像中的可解释AI的三维框架，旨在解决神经科学领域中识别大脑沟特征的复杂性问题。

    

    可解释的人工智能在医学成像中至关重要。在挑战性的神经科学领域里，视觉主题在三维空间内表现出高度复杂性。神经科学的应用涉及从MRI中识别大脑沟特征，由于专家之间的标注规程存在差异和大脑复杂的三维功能，我们面临着重大障碍。因此，传统的可解释性方法在有效验证和评估这些网络方面表现不佳。为了解决这个问题，我们首先提出了数学公式，细化了不同计算机视觉任务中解释需求的各种类别，分为自解释、半解释、非解释和基于验证协议可靠性的新模式学习应用。根据这个数学公式，我们提出了一个旨在解释三维的框架。

    arXiv:2309.00903v2 Announce Type: replace-cross  Abstract: Explainable AI is crucial in medical imaging. In the challenging field of neuroscience, visual topics present a high level of complexity, particularly within three-dimensional space. The application of neuroscience, which involves identifying brain sulcal features from MRI, faces significant hurdles due to varying annotation protocols among experts and the intricate three-dimension functionality of the brain. Consequently, traditional explainability approaches fall short in effectively validating and evaluating these networks. To address this, we first present a mathematical formulation delineating various categories of explanation needs across diverse computer vision tasks, categorized into self-explanatory, semi-explanatory, non-explanatory, and new-pattern learning applications based on the reliability of the validation protocol. With respect to this mathematical formulation, we propose a 3D explainability framework aimed at
    
[^25]: 大型语言模型有限标签监督微调的实验设计框架

    An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models. (arXiv:2401.06692v1 [cs.CL])

    [http://arxiv.org/abs/2401.06692](http://arxiv.org/abs/2401.06692)

    该论文提出了一个实验设计框架来减少大型语言模型有限标签监督微调的注释成本，并解决了主动学习的计算瓶颈问题。

    

    在现代大型语言模型中，指导数据集上的有限标签监督微调（SFT）在实现了令人惊叹的零射击泛化能力方面发挥了至关重要的作用。然而，为了为指令产生高质量的回答所需的注释工作正在变得难以承受，特别是随着指令数据集所涵盖的任务数量的增加。主动学习可以有效地从未标记的样本池中确定有用的子集进行注释，但其高计算成本仍然是其在LLMs环境中广泛应用的障碍。为了减少SFT的注释成本并规避主动学习的计算瓶颈，我们提出使用实验设计。实验设计技术选择最具信息量的样本进行标注，通常最大化某种不确定性和/或多样性的概念。在我们的工作中，我们实施了一个评估多种现有和新颖的实验设计方法的框架。

    Supervised finetuning (SFT) on instruction datasets has played a crucial role in achieving the remarkable zero-shot generalization capabilities observed in modern large language models (LLMs). However, the annotation efforts required to produce high quality responses for instructions are becoming prohibitively expensive, especially as the number of tasks spanned by instruction datasets continues to increase. Active learning is effective in identifying useful subsets of samples to annotate from an unlabeled pool, but its high computational cost remains a barrier to its widespread applicability in the context of LLMs. To mitigate the annotation cost of SFT and circumvent the computational bottlenecks of active learning, we propose using experimental design. Experimental design techniques select the most informative samples to label, and typically maximize some notion of uncertainty and/or diversity. In our work, we implement a framework that evaluates several existing and novel experimen
    
[^26]: 代码之间的界限：揭示机器和人类程序员之间不同的模式

    Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. (arXiv:2401.06461v1 [cs.SE])

    [http://arxiv.org/abs/2401.06461](http://arxiv.org/abs/2401.06461)

    本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。

    

    大型语言模型在代码生成方面取得了显著的进展，但它们模糊了机器和人类源代码之间的区别，导致软件产物的完整性和真实性问题。本文通过对代码长度、词汇多样性和自然性等属性的严格分析，揭示了机器和人类代码固有的独特模式。在我们的研究中特别注意到，代码的结构分割是识别其来源的关键因素。基于我们的发现，我们提出了一种名为DetectCodeGPT的新型机器生成代码检测方法，该方法改进了DetectGPT。

    Large language models have catalyzed an unprecedented wave in code generation. While achieving significant advances, they blur the distinctions between machine-and human-authored source code, causing integrity and authenticity issues of software artifacts. Previous methods such as DetectGPT have proven effective in discerning machine-generated texts, but they do not identify and harness the unique patterns of machine-generated code. Thus, its applicability falters when applied to code. In this paper, we carefully study the specific patterns that characterize machine and human-authored code. Through a rigorous analysis of code attributes such as length, lexical diversity, and naturalness, we expose unique pat-terns inherent to each source. We particularly notice that the structural segmentation of code is a critical factor in identifying its provenance. Based on our findings, we propose a novel machine-generated code detection method called DetectCodeGPT, which improves DetectGPT by cap
    
[^27]: 通过细粒度模型参数扰动实现机器去学习

    Machine unlearning through fine-grained model parameters perturbation. (arXiv:2401.04385v1 [cs.LG])

    [http://arxiv.org/abs/2401.04385](http://arxiv.org/abs/2401.04385)

    本文提出了一种精细的机器去学习策略，通过细粒度模型参数的扰动来实现用户隐私保护，同时保持可控的计算成本。采用遗忘率和记忆保留率等新的指标来评估去学习效果和模型泛化能力。

    

    机器去学习技术涉及到撤销数据记录和减小该数据对训练模型的影响，从而帮助实现用户隐私保护目标，但会带来显著的计算成本。基于参数扰动的权重去学习是一种通用方法，但通常涉及到全局修改参数。我们提出了精细的Top-K和Random-k参数扰动不精确机器去学习策略，以满足隐私需求同时保持计算成本可控。为了展示我们策略的有效性，我们还解决了评估机器去学习效果的挑战，考虑了模型在去学习和剩余数据上的广义性能。为了更好地评估去学习效果和模型泛化能力，我们提出了新的指标，即遗忘率和记忆保留率。然而，对于不精确的机器去学习，现有的指标无法对去学习程度进行准确量化。

    Machine unlearning techniques, which involve retracting data records and reducing influence of said data on trained models, help with the user privacy protection objective but incur significant computational costs. Weight perturbation-based unlearning is a general approach, but it typically involves globally modifying the parameters. We propose fine-grained Top-K and Random-k parameters perturbed inexact machine unlearning strategies that address the privacy needs while keeping the computational costs tractable.  In order to demonstrate the efficacy of our strategies we also tackle the challenge of evaluating the effectiveness of machine unlearning by considering the model's generalization performance across both unlearning and remaining data. To better assess the unlearning effect and model generalization, we propose novel metrics, namely, the forgetting rate and memory retention rate. However, for inexact machine unlearning, current metrics are inadequate in quantifying the degree of
    
[^28]: 基于强化学习的量化交易中协同公式Alpha生成的方法

    Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning. (arXiv:2401.02710v1 [cs.CE])

    [http://arxiv.org/abs/2401.02710](http://arxiv.org/abs/2401.02710)

    本文提出了一种基于强化学习的方法，通过扩展搜索空间和利用预训练的公式化alpha集来生成协同公式化alpha因子，从而提高量化交易的性能。

    

    公式化alpha因子的挖掘是指在股票市场中发现和开发特定的因子或指标（称为alpha因子）以用于量化交易的过程。为了在庞大的搜索空间中高效地发现alpha因子，常常采用强化学习（RL）方法。本文提出了一种通过扩展搜索空间并利用预训练的公式化alpha集作为初始种子值来生成协同公式化alpha的方法。我们使用信息系数（IC）和排名信息系数（Rank IC）作为模型的性能评估指标。通过使用CSI300市场数据，我们进行了实际投资模拟，并观察到与现有技术相比的显著性能提升。

    Mining of formulaic alpha factors refers to the process of discovering and developing specific factors or indicators (referred to as alpha factors) for quantitative trading in stock market. To efficiently discover alpha factors in vast search space, reinforcement learning (RL) is commonly employed. This paper proposes a method to enhance existing alpha factor mining approaches by expanding a search space and utilizing pretrained formulaic alpha set as initial seed values to generate synergistic formulaic alpha. We employ information coefficient (IC) and rank information coefficient (Rank IC) as performance evaluation metrics for the model. Using CSI300 market data, we conducted real investment simulations and observed significant performance improvement compared to existing techniques.
    
[^29]: 记忆、意识和大型语言模型

    Memory, Consciousness and Large Language Model. (arXiv:2401.02509v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.02509](http://arxiv.org/abs/2401.02509)

    该论文研究了大型语言模型（LLM）与图尔文的记忆理论之间的对应关系，并提出了意识可能是一种基于这种对应关系的新兴能力的猜想。

    

    随着认知科学和大型语言模型（LLM）的发展，这两个不同领域之间的联系越来越多地被揭示出来。在这些联系的基础上，我们提出了一个猜想，即LLM和图尔文的记忆理论之间存在一种对偶关系。我们确定了图尔文的协同引发（SEM）检索模型和LLM中观察到的新兴能力之间的潜在对应关系，为我们的猜想提供了支持证据。此外，我们推测意识可能被认为是这种对偶性的一种新兴能力形式。我们还讨论了其他意识理论如何与我们的研究相交叉。

    With the development in cognitive science and Large Language Models (LLMs), increasing connections have come to light between these two distinct fields. Building upon these connections, we propose a conjecture suggesting the existence of a duality between LLMs and Tulving's theory of memory. We identify a potential correspondence between Tulving's synergistic ecphory model (SEM) of retrieval and the emergent abilities observed in LLMs, serving as supporting evidence for our conjecture. Furthermore, we speculate that consciousness may be considered a form of emergent ability based on this duality. We also discuss how other theories of consciousness intersect with our research.
    
[^30]: 在Transformer中定位跨任务序列继续电路

    Locating Cross-Task Sequence Continuation Circuits in Transformers. (arXiv:2311.04131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04131](http://arxiv.org/abs/2311.04131)

    通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。

    

    虽然Transformer模型在语言任务上展现出强大的能力，但其复杂的架构使其难以解释。最近的研究旨在将Transformer模型还原为可读的电路表示，用于实现算法功能。我们通过分析和比较类似的序列继续任务的电路来扩展这项研究，其中包括数字、数字词和月份的递增序列。通过应用电路分析技术，我们确定了负责检测序列成员和预测序列中下一个成员的关键子电路。我们的分析揭示了语义相关序列依赖于具有类似作用的共享电路子图。总体而言，记录共享的计算结构能够更好地预测模型行为，识别错误，并进行更安全的编辑过程。这种对Transformer的机械理解是构建更健壮、调试和编辑更安全的模型的关键一步。

    While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust,
    
[^31]: 填空题：探索并增强LLM在数学应用题中的逆向推理能力

    Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems. (arXiv:2310.01991v1 [cs.CL])

    [http://arxiv.org/abs/2310.01991](http://arxiv.org/abs/2310.01991)

    本文探讨了LLM在数学应用题中的逆向推理能力，发现在逆向推理任务上，LLM模型的准确性显著下降。通过改进技术，如Rephrase和PAL-Tools，我们提高了模型的性能。

    

    虽然近期的文献中广泛探讨了正向推理（即给定问题找答案），但逆向推理相对较少被研究。我们对LLM在数学应用题中的逆向推理能力进行了探讨：给定一个数学问题和其答案，在问题中有些细节被省略了，LLM能否有效地还原出缺失的信息？本文正式定义了数学应用题中的逆向推理任务，并修改了三个数据集来评估这一任务：GSM8k、SVAMP和MultiArith。我们的研究结果显示，与正向推理相比，四个最先进的LLM模型（GPT4、GPT3.5、PaLM-2和LLaMa-2）在逆向推理上的准确性显著下降。利用该任务的特定格式，我们提出了三种改进性能的新技术：Rephrase将给定的问题重述为一个正向推理问题，PAL-Tools结合了程序辅助的LLM思想，生成一组方程式可以解决缺失的信息。

    While forward reasoning (i.e. find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information?  In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa-2). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that ca
    
[^32]: FUTURE-AI：在医疗保健领域的可信和可部署人工智能的国际共识指南

    FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare. (arXiv:2309.12325v1 [cs.CY])

    [http://arxiv.org/abs/2309.12325](http://arxiv.org/abs/2309.12325)

    FUTURE-AI是第一个国际共识框架，为医疗保健领域的可信AI工具开发和部署提供指导原则和最佳实践。

    

    尽管在医学和医疗保健领域人工智能（AI）取得了重大进展，但AI技术在现实临床实践中的部署和采用仍受限。近年来，人们对医疗AI的技术、临床、伦理和法律风险提出了关注。为了增加在现实世界中的采用，医疗AI工具必须得到患者、临床医生、健康组织和当局的信任和接受。本文描述了FUTURE-AI指南作为第一个用于指导医疗保健领域可信AI工具开发和部署的国际共识框架。FUTURE-AI联盟成立于2021年，目前包括来自51个国家的118位跨学科专家，代表了所有大洲，包括AI科学家、临床医生、伦理学家和社会科学家。在为期两年的时间里，联盟通过迭代过程定义了可信AI的指导原则和最佳实践，其中包括

    Despite major advances in artificial intelligence (AI) for medicine and healthcare, the deployment and adoption of AI technologies remain limited in real-world clinical practice. In recent years, concerns have been raised about the technical, clinical, ethical and legal risks associated with medical AI. To increase real world adoption, it is essential that medical AI tools are trusted and accepted by patients, clinicians, health organisations and authorities. This work describes the FUTURE-AI guideline as the first international consensus framework for guiding the development and deployment of trustworthy AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and currently comprises 118 inter-disciplinary experts from 51 countries representing all continents, including AI scientists, clinicians, ethicists, and social scientists. Over a two-year period, the consortium defined guiding principles and best practices for trustworthy AI through an iterative process comprising a
    
[^33]: 基于LLM的短文本答案自动评分方法研究

    Towards LLM-based Autograding for Short Textual Answers. (arXiv:2309.11508v1 [cs.CL])

    [http://arxiv.org/abs/2309.11508](http://arxiv.org/abs/2309.11508)

    本文评估了大型语言模型（LLMs）在自动评分中的应用，并强调了它们如何支持教育工作者验证评分程序。研究结果表明，“开箱即用”的LLMs作为补充视角提供了有价值的工具，但仍需进一步优化其可用性和性能。

    

    考试的评分是一项重要的、劳动密集的、主观的、重复的且常常具有挑战性的任务。大型语言模型（LLMs）如ChatGPT的可用性和数字化带来的大量数据的涌入， greatly increased autograding textual responses的可行性。然而，将决策角色交给AI模型引起了伦理考虑，主要源于潜在偏见和生成虚假信息的问题。因此，在本文中，我们评估了一个大型语言模型用于自动评分，同时强调了LLMs如何支持教育工作者验证其评分程序。我们的评估针对自动短文本答案评分（ASAG），涵盖了两个不同课程的各种语言和考试。我们的研究结果表明，“开箱即用”的LLMs提供了一个有价值的工具，可以提供补充的视角，但它们的可用性和性能在实际应用中还需进一步优化。

    Grading of exams is an important, labor intensive, subjective, repetitive and frequently challenging task. The feasibility of autograding textual responses has greatly increased thanks to the availability of large language models (LLMs) such as ChatGPT and because of the substantial influx of data brought about by digitalization. However, entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information. Thus, in this manuscript we provide an evaluation of a large language model for the purpose of autograding, while also highlighting how LLMs can support educators in validating their grading procedures. Our evaluation is targeted towards automatic short textual answers grading (ASAG), spanning various languages and examinations from two distinct courses. Our findings suggest that while "out-of-the-box" LLMs provide a valuable tool to provide a complementary perspective, their readiness
    
[^34]: SAMUS：为临床友好和泛化性超声图像分割调整的任意分割模型

    SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation. (arXiv:2309.06824v1 [cs.CV])

    [http://arxiv.org/abs/2309.06824](http://arxiv.org/abs/2309.06824)

    本文提出了SAMUS，一个专为超声图像分割量身定制的通用模型，通过引入并行CNN分支和适配器来改善SAM在医学图像分割中的性能和泛化能力。

    

    任意分割模型（SAM）是一种卓越的通用图像分割模型，在医学图像分割领域引起了相当大的关注。尽管SAM在自然图像上表现出色，但在处理医学图像时，特别是涉及低对比度、模糊边界、复杂形状和小尺寸对象的图像时，SAM面临着显著的性能下降和有限的泛化能力。本文提出SAMUS，这是一个专为超声图像分割量身定制的通用模型。与以前基于SAM的通用模型不同，SAMUS追求的不仅是更好的泛化能力，还有更低的部署成本，使其更适合临床应用。具体而言，在SAM的基础上，引入了一个并行CNN分支，通过跨分支注意力将局部特征注入ViT编码器，从而实现更好的医学图像分割。然后，开发了一个位置适配器和一个特征适配器来调整SAM的输

    Segment anything model (SAM), an eminent universal image segmentation model, has recently gathered considerable attention within the domain of medical image segmentation. Despite the remarkable performance of SAM on natural images, it grapples with significant performance degradation and limited generalization when confronted with medical images, particularly with those involving objects of low contrast, faint boundaries, intricate shapes, and diminutive sizes. In this paper, we propose SAMUS, a universal model tailored for ultrasound image segmentation. In contrast to previous SAM-based universal models, SAMUS pursues not only better generalization but also lower deployment cost, rendering it more suitable for clinical applications. Specifically, based on SAM, a parallel CNN branch is introduced to inject local features into the ViT encoder through cross-branch attention for better medical image segmentation. Then, a position adapter and a feature adapter are developed to adapt SAM fr
    
[^35]: 使用强化学习和生成预训练模型在四足机器人上实现生动的灵活性和游戏性

    Lifelike Agility and Play on Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models. (arXiv:2308.15143v1 [cs.RO])

    [http://arxiv.org/abs/2308.15143](http://arxiv.org/abs/2308.15143)

    该论文提出了一种使用生成模型和强化学习的框架，使四足机器人能够在复杂环境中像真实动物一样具有灵活性和策略。通过预训练生成模型，保留了动物行为的知识，并通过学习适应环境，克服挑战性的障碍。

    

    总结动物和人类的知识启发了机器人创新。在这项工作中，我们提出了一种框架，使四足机器人能够在复杂环境中像真实动物一样拥有生动的灵活性和策略。受到在语言和图像理解方面表现出色的大型预训练模型的启发，我们引入了先进的深度生成模型的能力，以生成模拟真实动物动作的运动控制信号。与传统控制器和端到端强化学习方法只针对特定任务不同，我们提出在动物运动数据集上预训练生成模型，以保留有表达力的动物行为知识。预训练模型拥有足够的原始级知识，但与环境无关。然后，在学习的后续阶段，通过穿越一些以前的方法很少考虑的具有挑战性的障碍，如穿过狭窄的空间等，使其适应环境。

    Summarizing knowledge from animals and human beings inspires robotic innovations. In this work, we propose a framework for driving legged robots act like real animals with lifelike agility and strategy in complex environments. Inspired by large pre-trained models witnessed with impressive performance in language and image understanding, we introduce the power of advanced deep generative models to produce motor control signals stimulating legged robots to act like real animals. Unlike conventional controllers and end-to-end RL methods that are task-specific, we propose to pre-train generative models over animal motion datasets to preserve expressive knowledge of animal behavior. The pre-trained model holds sufficient primitive-level knowledge yet is environment-agnostic. It is then reused for a successive stage of learning to align with the environments by traversing a number of challenging obstacles that are rarely considered in previous approaches, including creeping through narrow sp
    
[^36]: 总括荷尔蒙体系作为HOL的一个片段

    Normative Conditional Reasoning as a Fragment of HOL. (arXiv:2308.10686v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2308.10686](http://arxiv.org/abs/2308.10686)

    本论文报告了关于正式化条件推理的研究结果，包括Aqvist的条件义务系统E的机械化和伦理论据评估的工具的开发。

    

    我们报告了关于正式化（基于偏好的）条件推理的一些结果。我们关注的是Aqvist的条件义务系统E（及其扩展）。我们通过Isabelle/HOL中的浅表语义嵌入来实现我们的正式化。我们考虑了该框架的两种可能用途。第一种是作为对所考虑逻辑进行元推理的工具。我们将其用于自动验证权利义务对应关系（广义上理解）及相关事项，类似于之前对模态逻辑立方体所取得的成果。第二种用途是作为伦理论据评估的工具。我们提供了人口伦理学中一个众所周知的悖论Parfit的令人厌恶的结论的计算机编码。如何通过这个编码增加或减少令人厌恶的结论的吸引力和说服力是一个我们希望向哲学和伦理学提出的问题。

    We report some results regarding the mechanization of normative (preference-based) conditional reasoning. Our focus is on Aqvist's system E for conditional obligation (and its extensions). Our mechanization is achieved via a shallow semantical embedding in Isabelle/HOL. We consider two possible uses of the framework. The first one is as a tool for meta-reasoning about the considered logic. We employ it for the automated verification of deontic correspondences (broadly conceived) and related matters, analogous to what has been previously achieved for the modal logic cube. The second use is as a tool for assessing ethical arguments. We provide a computer encoding of a well-known paradox in population ethics, Parfit's repugnant conclusion. Whether the presented encoding increases or decreases the attractiveness and persuasiveness of the repugnant conclusion is a question we would like to pass on to philosophy and ethics.
    
[^37]: 一个用于性能效率的规划本体表示和利用规划知识的方法

    A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency. (arXiv:2307.13549v1 [cs.AI])

    [http://arxiv.org/abs/2307.13549](http://arxiv.org/abs/2307.13549)

    本研究提出了一种使用规划本体表示和利用规划知识的方法来提高自动规划的性能效率。通过构建一个规划本体，并利用国际规划竞赛的数据进行实验，证明了本体能够选择有前景的规划器，并使用从本体中提取的宏观约束来提高它们的性能。

    

    本文考虑了自动规划问题，通过构建一个规划本体，利用国际规划竞赛（IPC）的规划领域和规划器的数据，在两个使用案例中进行了实验，证明了该本体能够选择有前景的规划器，并通过从规划本体中提取的宏观约束来提高它们的性能。

    Ontologies are known for their ability to organize rich metadata, support the identification of novel insights via semantic queries, and promote reuse. In this paper, we consider the problem of automated planning, where the objective is to find a sequence of actions that will move an agent from an initial state of the world to a desired goal state. We hypothesize that given a large number of available planners and diverse planning domains; they carry essential information that can be leveraged to identify suitable planners and improve their performance for a domain. We use data on planning domains and planners from the International Planning Competition (IPC) to construct a planning ontology and demonstrate via experiments in two use cases that the ontology can lead to the selection of promising planners and improving their performance using macros - a form of action ordering constraints extracted from planning ontology. We also make the planning ontology and associated resources avail
    
[^38]: 深度神经网络和脑对齐：脑编码和解码（综述）

    Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey). (arXiv:2307.10246v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.10246](http://arxiv.org/abs/2307.10246)

    本文综述了深度神经网络和脑对齐的研究，重点在于脑编码和解码模型的应用。这些模型对于理解大脑的信息处理机制以及设计脑机接口具有重要意义。

    

    大脑如何表示不同的信息模式？我们能否设计出一个可以自动理解用户思考内容的系统？这些问题可以通过研究功能磁共振成像（fMRI）等大脑记录来回答。作为第一步，神经科学界为被动阅读/听觉/观看概念词汇、叙述、图片和电影相关的认知神经科学数据集作出了贡献。过去二十年中，还提出了使用这些数据集的编码和解码模型。这些模型作为基础研究中的额外工具，在认知科学和神经科学领域有着多种实际应用。编码模型旨在自动地生成fMRI大脑表征，给定一个刺激。它们在评估和诊断神经系统疾病以及设计大脑损伤治疗方法方面有着多种实际应用。解码模型解决了根据fMRI重构刺激的逆问题。它们对于理解大脑如何处理信息以及设计脑机接口的发展都有着重要意义。

    How does the brain represent different modes of information? Can we design a system that automatically understands what the user is thinking? Such questions can be answered by studying brain recordings like functional magnetic resonance imaging (fMRI). As a first step, the neuroscience community has contributed several large cognitive neuroscience datasets related to passive reading/listening/viewing of concept words, narratives, pictures and movies. Encoding and decoding models using these datasets have also been proposed in the past two decades. These models serve as additional tools for basic research in cognitive science and neuroscience. Encoding models aim at generating fMRI brain representations given a stimulus automatically. They have several practical applications in evaluating and diagnosing neurological conditions and thus also help design therapies for brain damage. Decoding models solve the inverse problem of reconstructing the stimuli given the fMRI. They are useful for 
    
[^39]: TbExplain: 一种场景分类模型的基于文本的解释方法与统计预测校正

    TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction. (arXiv:2307.10003v1 [cs.CV])

    [http://arxiv.org/abs/2307.10003](http://arxiv.org/abs/2307.10003)

    本文提出了一种名为TbExplain的框架，它利用XAI技术和预训练的对象检测器，通过文本形式解释场景分类模型，并引入了一种新的方法来纠正预测和进行文本解释。

    

    可解释性人工智能(XAI)的领域旨在提高黑盒机器学习模型的可解释性。建立基于输入特征重要性值的热图是解释这些模型产生预测的基本方法之一。热图在人类中几乎可以理解，但并非没有缺陷。例如，非专业用户可能不完全理解热图的逻辑（即使用不同强度或颜色突出显示与模型预测相关的像素的逻辑）。此外，与模型预测相关的输入图像的对象和区域通常无法完全通过热图区分。本文提出了一种称为TbExplain的框架，采用XAI技术和预训练的对象检测器，以文本形式解释场景分类模型。此外，TbExplain还采用了一种新的方法来纠正预测和进行文本解释。

    The field of Explainable Artificial Intelligence (XAI) aims to improve the interpretability of black-box machine learning models. Building a heatmap based on the importance value of input features is a popular method for explaining the underlying functions of such models in producing their predictions. Heatmaps are almost understandable to humans, yet they are not without flaws. Non-expert users, for example, may not fully understand the logic of heatmaps (the logic in which relevant pixels to the model's prediction are highlighted with different intensities or colors). Additionally, objects and regions of the input image that are relevant to the model prediction are frequently not entirely differentiated by heatmaps. In this paper, we propose a framework called TbExplain that employs XAI techniques and a pre-trained object detector to present text-based explanations of scene classification models. Moreover, TbExplain incorporates a novel method to correct predictions and textually exp
    
[^40]: 神经启发的高效地图构建通过分割和回溯

    Neuro-Inspired Efficient Map Building via Fragmentation and Recall. (arXiv:2307.05793v1 [cs.AI])

    [http://arxiv.org/abs/2307.05793](http://arxiv.org/abs/2307.05793)

    本文提出了一种神经启发的地图构建方法，通过分割和回溯来解决大型环境下的探索问题，并基于意外性的空间聚类设置探索子目标。

    

    动物和机器人通过构建和完善空间地图来导航环境。这些地图使得包括回家、规划、搜索和觅食在内的功能成为可能。在大型环境中，探索空间是一个难题：代理可能会陷入局部区域。在这里，我们从神经科学中汲取经验，提出并应用了分割和回溯（FarMap）的概念。代理通过基于意外性的空间聚类来解决地图构建问题，同时将其用于设置空间探索的子目标。代理构建和使用本地地图来预测他们的观测结果；高意外性会导致“分割事件”，从而截断本地地图。在这些事件中，最近的本地地图被放入长期记忆（LTM）中，并初始化另一个本地地图。如果断裂点的观察结果与存储的某个本地地图的观察结果相匹配，那么该地图就会被回溯（并重用）自LTM。分割点诱导.

    Animals and robots navigate through environments by building and refining maps of the space. These maps enable functions including navigating back to home, planning, search, and foraging. In large environments, exploration of the space is a hard problem: agents can become stuck in local regions. Here, we use insights from neuroscience to propose and apply the concept of Fragmentation-and-Recall (FarMap), with agents solving the mapping problem by building local maps via a surprisal-based clustering of space, which they use to set subgoals for spatial exploration. Agents build and use a local map to predict their observations; high surprisal leads to a ``fragmentation event'' that truncates the local map. At these events, the recent local map is placed into long-term memory (LTM), and a different local map is initialized. If observations at a fracture point match observations in one of the stored local maps, that map is recalled (and thus reused) from LTM. The fragmentation points induc
    
[^41]: 量子机器学习的阴影

    Shadows of quantum machine learning. (arXiv:2306.00061v1 [quant-ph])

    [http://arxiv.org/abs/2306.00061](http://arxiv.org/abs/2306.00061)

    量子机器学习模型需要使用量子计算机进行评估，但我们提出在训练完后，使用量子计算机生成一个经典阴影模型来计算函数的经典计算近似，避免了对量子计算机的需求。

    

    量子机器学习经常被认为是利用量子计算机解决实际问题的最有前途的应用之一。然而，阻碍其在实践中广泛使用的主要障碍是这些模型即使在训练过程后，仍需要访问量子计算机才能对新数据进行评估。为解决这个问题，我们建议在量子模型的训练阶段之后，量子计算机可以用来生成我们所谓的该模型的“经典阴影”，即已学习函数的经典计算近似。虽然最近的研究已经探讨了这个想法并提出了构建这种影子模型的方法，但它们也提出了一个完全经典模型可能代替的可能性，从而首先回避了量子计算机的需要。本文采用新的方法，基于量子线性模型和经典阴影重构的框架来定义阴影模型。

    Quantum machine learning is often highlighted as one of the most promising uses for a quantum computer to solve practical problems. However, a major obstacle to the widespread use of quantum machine learning models in practice is that these models, even once trained, still require access to a quantum computer in order to be evaluated on new data. To solve this issue, we suggest that following the training phase of a quantum model, a quantum computer could be used to generate what we call a classical shadow of this model, i.e., a classically computable approximation of the learned function. While recent works already explore this idea and suggest approaches to construct such shadow models, they also raise the possibility that a completely classical model could be trained instead, thus circumventing the need for a quantum computer in the first place. In this work, we take a novel approach to define shadow models based on the frameworks of quantum linear models and classical shadow tomogr
    
[^42]: 物理深度强化学习: 安全和未知未知的探索

    Physical Deep Reinforcement Learning: Safety and Unknown Unknowns. (arXiv:2305.16614v1 [cs.AI])

    [http://arxiv.org/abs/2305.16614](http://arxiv.org/abs/2305.16614)

    本文提出了Phy-DRL，这是一个物理模型调整的深度强化学习框架。该框架有三个创新点，它们分别是: i)前瞻性的未知未知训练，ii)结合残差控制，以及iii)基于物理模型的神经网络编辑。Phy-DRL能够容忍未知干扰，保证安全和稳定，同时遵守Bellman方程和奖励相关的物理知识。

    

    本文提出了Phy-DRL，一个物理模型调节的深度强化学习框架，用于安全关键的自主系统。Phy-DRL具有三种独特的创新：i）前瞻性的未知未知训练，ii）结合残差控制（即数据驱动控制和基于物理模型的控制的集成）和安全及稳定性敏感的奖励，以及iii）基于物理模型的神经网络编辑，包括链接编辑和激活编辑。由于这些并发设计，Phy-DRL能够1）容忍未知干扰，2）保证可数学证明的安全与稳定性，并3）严格遵守Bellman方程和奖励相关的物理知识。最终，通过倒立摆和四足机器人的实验验证了Phy-DRL的有效性。实验结果表明，与纯数据驱动的DRL相比，Phy-DRL具有明显更少的学习参数、加速的训练和扩大的回报。

    In this paper, we propose the Phy-DRL: a physics-model-regulated deep reinforcement learning framework for safety-critical autonomous systems. The Phy-DRL is unique in three innovations: i) proactive unknown-unknowns training, ii) conjunctive residual control (i.e., integration of data-driven control and physics-model-based control) and safety- \& stability-sensitive reward, and iii) physics-model-based neural network editing, including link editing and activation editing. Thanks to the concurrent designs, the Phy-DRL is able to 1) tolerate unknown-unknowns disturbances, 2) guarantee mathematically provable safety and stability, and 3) strictly comply with physical knowledge pertaining to Bellman equation and reward. The effectiveness of the Phy-DRL is finally validated by an inverted pendulum and a quadruped robot. The experimental results demonstrate that compared with purely data-driven DRL, Phy-DRL features remarkably fewer learning parameters, accelerated training and enlarged rew
    
[^43]: 带有鲁棒UNet去噪器的认证零阶黑盒防御

    Certified Zeroth-order Black-Box Defense with Robust UNet Denoiser. (arXiv:2304.06430v1 [cs.CV])

    [http://arxiv.org/abs/2304.06430](http://arxiv.org/abs/2304.06430)

    本文提出了一种带有鲁棒UNet去噪器的认证零阶黑盒防御方法，通过在黑盒模型之前预置RDUNet和DS或AE和RDUNet，成功提高了模型鲁棒性。

    

    最近黑盒设置中对于对抗性扰动的认证防御方法已经从零阶角度进行了研究，然而由于去噪器的设计不够有效，这些方法在高维数据集上存在高模型方差和低性能，且在使用零阶技术时存在局限性。为此，我们提出了一种认证的零阶预处理技术，仅使用模型查询即可从受攻击图像中去除对抗性扰动。我们提出了一种鲁棒的UNet去噪器（RDUNet），确保了对于高维数据集上训练的黑盒模型的鲁棒性。我们进一步提出了黑盒去噪平滑（DS）防御机制ZO-RUDS，通过将我们的RDUNet预置于黑盒模型之前，确保黑盒防御。我们还提出了ZO-AE-RUDS，在黑盒模型之前使用RDUNet和自编码器(AE)。我们在四个分类数据集上进行了广泛的实验。

    Certified defense methods against adversarial perturbations have been recently investigated in the black-box setting with a zeroth-order (ZO) perspective. However, these methods suffer from high model variance with low performance on high-dimensional datasets due to the ineffective design of the denoiser and are limited in their utilization of ZO techniques. To this end, we propose a certified ZO preprocessing technique for removing adversarial perturbations from the attacked image in the black-box setting using only model queries. We propose a robust UNet denoiser (RDUNet) that ensures the robustness of black-box models trained on high-dimensional datasets. We propose a novel black-box denoised smoothing (DS) defense mechanism, ZO-RUDS, by prepending our RDUNet to the black-box model, ensuring black-box defense. We further propose ZO-AE-RUDS in which RDUNet followed by autoencoder (AE) is prepended to the black-box model. We perform extensive experiments on four classification dataset
    
[^44]: KGS：利用知识引导的贪婪等价搜索进行因果推断

    KGS: Causal Discovery Using Knowledge-guided Greedy Equivalence Search. (arXiv:2304.05493v1 [cs.AI])

    [http://arxiv.org/abs/2304.05493](http://arxiv.org/abs/2304.05493)

    KGS是一种新颖的因果推断方法，通过利用先前的因果边缘信息作为约束条件，可以更准确地学习因果图。

    

    仅从观测数据中学习因果关系，不能提供关于潜在的因果机制和可能的因果图空间的足够信息。因此，使用基于分数的方法搜索图等价类的空间，如贪婪等价搜索（GES），搜索空间通常会呈指数级增长。先前的因果信息，例如有无因果边，可以利用这些信息指导发现过程，使其走向更为受限且准确的搜索空间。本研究提出了KGS，一种知识引导的贪婪分数因果推断方法，它利用观测数据和结构先验（因果边）作为约束条件学习因果图。KGS是一种新颖的应用知识约束的方法，可以利用任何两个变量之间的先前边缘信息，包括有向边，无边和无向边的存在情况。

    Learning causal relationships solely from observational data provides insufficient information about the underlying causal mechanism and the search space of possible causal graphs. As a result, often the search space can grow exponentially for approaches such as Greedy Equivalence Search (GES) that uses a score-based approach to search the space of equivalence classes of graphs. Prior causal information such as the presence or absence of a causal edge can be leveraged to guide the discovery process towards a more restricted and accurate search space. In this study, we present KGS, a knowledge-guided greedy score-based causal discovery approach that uses observational data and structural priors (causal edges) as constraints to learn the causal graph. KGS is a novel application of knowledge constraints that can leverage any of the following prior edge information between any two variables: the presence of a directed edge, the absence of an edge, and the presence of an undirected edge. We
    
[^45]: BugNIST -- 一种新的大规模体积三维图像数据集，用于分类和检测

    BugNIST -- A New Large Scale Volumetric 3D Image Dataset for Classification and Detection. (arXiv:2304.01838v1 [cs.CV])

    [http://arxiv.org/abs/2304.01838](http://arxiv.org/abs/2304.01838)

    本文介绍了一个名为BugNIST的广泛数据集，该数据集由12种昆虫和幼虫的微-CT扫描组成。通过训练和测试检测模型，BugNIST旨在评估三维体积图像分类和检测方法，解决上下文无关的挑战。

    

    三维体积图像分析研究的进展受到数据集缺乏的限制，大多数针对体积图像的分析方法都基于医学数据。然而，医学数据并不一定具有其他体积图像（例如微-CT）的特征。为了促进三维体积图像分析的研究超越医学数据，我们创建了BugNIST数据集并免费提供。BugNIST是一组由12种昆虫和幼虫的微-CT扫描组成的广泛数据集。BugNIST包含9437个体积，其中9087个是单个昆虫的扫描，350个是昆虫和其他材料的混合物。BugNIST的目标是评估分类和检测方法，我们设计了检测挑战，使得检测模型在单个昆虫的扫描上训练并在昆虫混合物上进行测试。能够解决此任务的模型将独立于上下文（即周围材料），这是一个很大的优势。

    Progress in 3D volumetric image analysis research is limited by the lack of datasets and most advances in analysis methods for volumetric images are based on medical data. However, medical data do not necessarily resemble the characteristics of other volumetric images such as micro-CT. To promote research in 3D volumetric image analysis beyond medical data, we have created the BugNIST dataset and made it freely available. BugNIST is an extensive dataset of micro-CT scans of 12 types of bugs, such as insects and larvae. BugNIST contains 9437 volumes where 9087 are of individual bugs and 350 are mixtures of bugs and other material. The goal of BugNIST is to benchmark classification and detection methods, and we have designed the detection challenge such that detection models are trained on scans of individual bugs and tested on bug mixtures. Models capable of solving this task will be independent of the context, i.e., the surrounding material. This is a great advantage if the context is 
    
[^46]: MenuCraft: 基于大型语言模型的交互式菜单系统设计

    MenuCraft: Interactive Menu System Design with Large Language Models. (arXiv:2303.04496v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04496](http://arxiv.org/abs/2303.04496)

    MenuCraft是一个基于大型语言模型的AI辅助设计师，通过对话系统与设计师协作，提供了一个交互式菜单设计工具，可以简化菜单设计过程，并支持零/少次学习。

    

    菜单系统设计是一项具有挑战性的任务，涉及许多设计选项和各种人因素。本文提出了一种名为MenuCraft的AI辅助设计师，通过设计和细化菜单系统的对话系统，实现设计师与对话系统之间的协作。MenuCraft提供了一个基于语言的交互式菜单设计工具，简化了菜单设计过程，并实现了设计选项的轻松定制。MenuCraft通过对话支持各种交互方式，可以进行零/少次学习。

    Menu system design is a challenging task involving many design options and various human factors. For example, one crucial factor that designers need to consider is the semantic and systematic relation of menu commands. However, capturing these relations can be challenging due to limited available resources. With the advancement of neural language models, large language models can utilize their vast pre-existing knowledge in designing and refining menu systems. In this paper, we propose MenuCraft, an AI-assisted designer for menu design that enables collaboration between the designer and a dialogue system to design menus. MenuCraft offers an interactive language-based menu design tool that simplifies the menu design process and enables easy customization of design options. MenuCraft supports a variety of interactions through dialog that allows performing zero/few-shot learning.
    
[^47]: 描述、解释、规划和选择：大型语言模型启用开放世界多任务智能体的交互规划

    Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents. (arXiv:2302.01560v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.01560](http://arxiv.org/abs/2302.01560)

    本论文研究了在开放世界环境中多任务具身智能体的任务规划挑战，提出了一种基于大型语言模型的交互式规划方法(DEPS)来解决计划执行的准确性和效率问题。

    

    我们研究了开放世界环境中多任务具身智能体的任务规划挑战。我们发现了两个主要困难：1）在开放世界环境（如Minecraft）中执行计划需要准确的多步推理，因为任务是长期性的；2）由于传统规划器不考虑当前智能体完成给定子任务的难度，在复杂计划中对并行子目标进行排序可能导致计划低效甚至不可行。为此，我们提出了基于大型语言模型（LLMs）的“描述、解释、规划和选择”（DEPS）交互式规划方法。DEPS通过整合计划执行过程的描述和在规划阶段遇到失败时提供自我解释的反馈，实现了对初始LLM生成的计划的更好的错误修正。

    We investigate the challenge of task planning for multi-task embodied agents in open-world environments. Two main difficulties are identified: 1) executing plans in an open-world environment (e.g., Minecraft) necessitates accurate and multi-step reasoning due to the long-term nature of tasks, and 2) as vanilla planners do not consider how easy the current agent can achieve a given sub-task when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient or even infeasible. To this end, we propose "$\underline{D}$escribe, $\underline{E}$xplain, $\underline{P}$lan and $\underline{S}$elect" ($\textbf{DEPS}$), an interactive planning approach based on Large Language Models (LLMs). DEPS facilitates better error correction on initial LLM-generated $\textit{plan}$ by integrating $\textit{description}$ of the plan execution process and providing self-$\textit{explanation}$ of feedback when encountering failures during the extended planning phases. Furthermore
    
[^48]: Res2NetFuse：一种适用于红外和可见光图像的融合方法

    Res2NetFuse: A Fusion Method for Infrared and Visible Images. (arXiv:2112.14540v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.14540](http://arxiv.org/abs/2112.14540)

    本文提出了一种基于Res2Net的红外和可见光图像融合框架，通过引入新的训练策略和融合策略，实现了最先进的融合性能。

    

    本文提出了一种基于Res2Net的红外和可见光图像融合框架。提出的融合模型包括编码器、融合层和解码器三个部分。利用基于Res2Net的编码器提取源图像的多尺度特征，引入一种新的训练策略，仅使用单个图像进行训练。然后，基于注意力模型开发了一种新的融合策略。最后，通过解码器重构融合图像。本文还对所提出的方法进行了详细分析。实验证明，该方法在客观和主观评估中都实现了最先进的融合性能，与现有方法进行了比较。

    This paper presents a novel Res2Net-based fusion framework for infrared and visible images. The proposed fusion model has three parts: an encoder, a fusion layer and a decoder, respectively. The Res2Net-based encoder is used to extract multi-scale features of source images, the paper introducing a new training strategy for training a Res2Net-based encoder that uses only a single image. Then, a new fusion strategy is developed based on the attention model. Finally, the fused image is reconstructed by the decoder. The proposed approach is also analyzed in detail. Experiments show that our method achieves state-of-the-art fusion performance in objective and subjective assessment by comparing with the existing methods.
    

