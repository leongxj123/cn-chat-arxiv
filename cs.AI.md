# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Efficient Causal Graph Discovery Using Large Language Models](https://rss.arxiv.org/abs/2402.01207) | 提出了一个新的框架，利用大型语言模型进行高效的因果图发现，采用了广度优先搜索方法，只需要线性数量的查询，同时能轻松结合观察数据以提高性能，具有高效性和数据效率，并在真实因果图上取得了最先进的结果，展示了其在不同领域的广泛适用性潜力。 |
| [^2] | [RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement](https://arxiv.org/abs/2404.01889) | 该论文提出了一种用于背光图像增强的CLIP引导方法RAVE，通过残差向量嵌入和提示调整的新颖方法，加快了训练并提高了质量。 |
| [^3] | [ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models](https://arxiv.org/abs/2403.20262) | 该论文提出了一个新的基准 ELITR-Bench，专注于长上下文语言模型的实际会议助理场景，通过在现有 ELITR 语料库的转录中添加手工制作的问题和真实答案，揭示了开源模型和专有模型之间的差距。 |
| [^4] | [Can LLMs Converse Formally? Automatically Assessing LLMs in Translating and Interpreting Formal Specifications](https://arxiv.org/abs/2403.18327) | 本文提出了一种方法，利用两个LLM的副本与验证器结合使用，能够自动评估其在自然语言描述和正式规范之间转换的能力，无需额外的人工输入。 |
| [^5] | [Advanced Artificial Intelligence Algorithms in Cochlear Implants: Review of Healthcare Strategies, Challenges, and Perspectives](https://arxiv.org/abs/2403.15442) | 人工智能在提高植入式听觉设备的语音质量方面具有前瞻性，并通过先进的信号处理技术以及应对多源语音和环境噪音挑战等方法来克服语音失真问题 |
| [^6] | [Optimal Layout Synthesis for Deep Quantum Circuits on NISQ Processors with 100+ Qubits](https://arxiv.org/abs/2403.11598) | 本研究提出了一种基于并行计划的SAT编码，每个时间步骤应用1个SWAP和一组CNOT。利用特定领域信息，在并行计划中保持优化性能的同时，扩展到大型深度电路。我们展示了我们方法的可扩展性，在多项比领先的精确和接近最优方法表现出色（高达100倍）。我们首次能够最优地映射多个8、14和16量子比特 |
| [^7] | [Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning](https://arxiv.org/abs/2403.09793) | 提出了一种新颖的社会整合导航方法，通过与人的互动使机器人的社交行为自适应，并从其他基于DRL的导航方法中区分出具有明确预定义社交行为的社会意识方法和缺乏社交行为的社会碰撞回避。 |
| [^8] | [Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields](https://arxiv.org/abs/2403.09549) | 将去噪方法推广到非平衡结构，从而改进等变力场的性能，提高了对原子间相互作用的理解以及在分子动力学和催化剂设计等领域的应用。 |
| [^9] | [Beyond Memorization: The Challenge of Random Memory Access in Language Models](https://arxiv.org/abs/2403.07805) | 本文研究了语言模型在访问内存时的挑战，发现通过背诵和置换等技术可以改善语言模型的随机内存访问能力，从而在开放域问题回答任务中取得显著改进。 |
| [^10] | [WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?](https://arxiv.org/abs/2403.07718) | 该研究探究了基于大型语言模型的代理在通过web浏览器与软件交互时的能力，提出了WorkArena和BrowserGym两个工具，在29个任务的基准测试中显示出潜力，但也揭示了实现完全任务自动化仍存在挑战。 |
| [^11] | [Structure Your Data: Towards Semantic Graph Counterfactuals](https://arxiv.org/abs/2403.06514) | 提出了基于语义图的反事实解释方法，利用GNN来进行高效的图编辑距离计算，通过场景图形式，绕过NP困难的图相似性问题，实现更具描述性、准确性和与人类对齐的解释。 |
| [^12] | [xT: Nested Tokenization for Larger Context in Large Images](https://arxiv.org/abs/2403.01915) | xT为视觉Transformer引入了嵌套标记化方案，有效地聚合了全局背景和局部细节，使其能够在现代GPU上端到端地建模大图像，并在经典视觉任务数据集上展示了改进。 |
| [^13] | [Resolution of Simpson's paradox via the common cause principle](https://arxiv.org/abs/2403.00957) | 通过对共同原因$C$进行条件设定，解决了辛普森悖论，推广了悖论，并表明在二元共同原因$C$上进行条件设定的关联方向与原始$B$上进行条件设定相同 |
| [^14] | [FSL Model can Score Higher as It Is](https://arxiv.org/abs/2402.18292) | 为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。 |
| [^15] | [OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web](https://arxiv.org/abs/2402.17553) | OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。 |
| [^16] | [One-Shot Graph Representation Learning Using Hyperdimensional Computing](https://arxiv.org/abs/2402.17073) | 该方法提出了一种使用超高维计算进行单次图表示学习的方法，通过将数据投影到高维空间并利用HD运算符进行信息聚合，实现了与最先进深度学习方法相竞争的预测性能，而无需进行计算昂贵的训练。 |
| [^17] | [Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual Capabilities Without Richer Cross-Modal Projections](https://arxiv.org/abs/2402.16832) | MLLMs通过微调获得了特定领域的视觉能力，但投影并未提取相关的领域特定视觉属性。 |
| [^18] | [Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts](https://arxiv.org/abs/2402.16822) | Rainbow Teaming提出了一种新方法，通过开放式搜索生成多样化的对抗性提示，可以帮助改善大型语言模型的稳健性，提高安全性，问答和网络安全等领域的模型漏洞。 |
| [^19] | [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727) | ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。 |
| [^20] | [SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked AutoEncoder](https://arxiv.org/abs/2402.07370) | 本文介绍了SelfSwapper，一种通过 Shape Agnostic Masked AutoEncoder (SAMAE) 自监督方案来提升人脸交换模型训练的方法。通过绕过传统的训练方案，引入清晰的真实数据，以及利用遮罩和学到的特征，我们成功解决了身份泄漏和形状不对齐的问题。 |
| [^21] | [Good Teachers Explain: Explanation-Enhanced Knowledge Distillation](https://arxiv.org/abs/2402.03119) | 通过优化解释增强的知识蒸馏（e$^2$KD）算法，可以让学生模型在准确性和学生-教师一致性方面都得到大幅度提升，确保学生模型从教师那里正确学到原因。 |
| [^22] | [Computational Copyright: Towards A Royalty Model for Music Generative AI](https://arxiv.org/abs/2312.06646) | 本文旨在解决音乐生成AI领域中的版权问题，提出了一种用于AI音乐生成平台的版税模型，并探讨了对AI生成音乐进行版权归因的算法解决方案。 |
| [^23] | [Efficient Pre-training for Localized Instruction Generation of Videos](https://arxiv.org/abs/2311.15964) | 提出了一种名为Sieve-&-Swap的技术，通过自动筛选出不相关文本并用人类编写的说明替换文本转录，从而实现视频本地化指令生成的高效预训练。 |
| [^24] | [Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages.](http://arxiv.org/abs/2401.05811) | 本文引入了对比对齐指令（AlignInstruct），通过使用统计词对齐构建的跨语言鉴别器实现了跨语言监督，解决了机器翻译中的两个挑战：将支持的语言扩展到未知语言和低资源语言中数据缺乏的问题。实验结果表明，LLMs通过MTInstruct可以有效地翻译未知语言，并且使用AlignInstruct在涉及英语的48个翻译方向上能够持续改善翻译质量。基于鉴别器的指令优于生成型指令。 |
| [^25] | [Cross-Speaker Encoding Network for Multi-Talker Speech Recognition.](http://arxiv.org/abs/2401.04152) | 本文提出了一种叫做Cross-Speaker Encoding（CSE）的网络，用于解决多说话人语音识别中的局限性，通过聚合跨说话人表示。通过与SOT结合，该模型在两个说话人的数据集上实验证明比SIMO基准模型的词错误率（WER）分别降低了8%和10%。 |
| [^26] | [Turing's Test, a Beautiful Thought Experiment.](http://arxiv.org/abs/2401.00009) | 本文对图灵的美丽的思维实验进行了历史重建，提供了大量证据和一些原创答案，同时回答了图灵测试的核心问题。 |
| [^27] | [Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation.](http://arxiv.org/abs/2310.13447) | 本文提出了一种多尺度超像素结构差异图卷积网络（MDGCN）用于视觉语言表征，通过聚类感知相似像素，减少了后续处理的视觉基元数量，并挖掘了更精确的拓扑关系。 |
| [^28] | [USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation.](http://arxiv.org/abs/2309.13289) | 使用对比学习和类激活图技术，USL-Net提供了一种无需手动标注指导的方法，能够有效地分割各种皮肤病变区域。 |
| [^29] | [Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome.](http://arxiv.org/abs/2309.10744) | 该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。 |
| [^30] | [Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion.](http://arxiv.org/abs/2308.12517) | 本文提出了一种新的强化学习框架，为复杂机器人系统训练神经网络控制器。该框架引入了奖励和约束的概念，通过设计高效的策略优化算法来处理约束，以减少计算开销。通过应用于不同腿式机器人的运动控制器训练中，展示了该框架的有效性。 |
| [^31] | [Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures.](http://arxiv.org/abs/2307.15220) | 通过观看手术视频讲座，我们提出了一种新方法，SurgVLP，通过利用手术视频讲座中的语音和视觉信息进行多模态表示学习，并解决了手术相关语言挑战。 |
| [^32] | [Improving Offline-to-Online Reinforcement Learning with Q-Ensembles.](http://arxiv.org/abs/2306.06871) | 我们提出了一种名为Q-Ensembles的新框架，通过增加Q网络的数量，无缝地连接离线预训练和在线微调，同时不降低性能。此外，我们适当放宽Q值估计的悲观性，并将基于集合的探索机制融入我们的框架中，从而提升了离线到在线强化学习的性能。 |
| [^33] | [BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks.](http://arxiv.org/abs/2305.17100) | BiomedGPT是一种面向视觉、语言和多模态任务的通用生物医学生成预训练Transformer，在多个临床任务中取得了16个最新的最优结果，包括超过了OpenAI的GPT-4V和Google的Med-PaLM M（12B）。同时，BiomedGPT还支持零-shot迁移学习。 |
| [^34] | [Distributed Neural Representation for Reactive in situ Visualization.](http://arxiv.org/abs/2304.10516) | 本研究开发了一种分布式体积数据的隐式神经表示技术，结合到反应式编程系统中构建了一个原位时间缓存系统，并在Ascent基础架构中使用实际模拟评估了其100倍容量的性能。 |
| [^35] | [Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation.](http://arxiv.org/abs/2304.06671) | 本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。 |
| [^36] | [Better Understanding Differences in Attribution Methods via Systematic Evaluations.](http://arxiv.org/abs/2303.11884) | 本文提出了三种新的评估方案，通过这些方案，可以更可靠地测量归因方法的可信度。 |
| [^37] | [Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals.](http://arxiv.org/abs/2302.04449) | 本论文提出了阅读并奖励的框架，通过阅读Atari游戏开发者发布的指导手册，以提高强化学习算法在Atari游戏中的效率。该框架包含一个QA提取模块和一个推理模块，能够从指导手册中提取关键信息，并评估物体与智能体的交互效果。 |
| [^38] | [Does Federated Learning Really Need Backpropagation?.](http://arxiv.org/abs/2301.12195) | 本文提出一种不需要反向传播的联邦学习框架BAFFLE，该框架使用多个正向过程估计梯度，具有高内存效率，容易适应上传带宽，与硬件优化和模型量化/修剪兼容，适用于受信任的执行环境。 |
| [^39] | [A Semantic Framework for Neural-Symbolic Computing.](http://arxiv.org/abs/2212.12050) | 该论文提出了一个神经符号计算的语义框架，用于将神经网络和符号AI相结合成为综合系统，并通过将符号知识编码到神经网络中来解决通用推理能力的问题。 |
| [^40] | [Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent.](http://arxiv.org/abs/2209.02552) | 本研究将解释人工智能（XAI）融入到一个对话代理中，设计具有自然语言理解和生成组件的标准模型。通过扩展XAI问题库并提供解释方法，实现了关于机器学习模型的真正自然对话。 |

# 详细

[^1]: 使用大型语言模型的高效因果图发现

    Efficient Causal Graph Discovery Using Large Language Models

    [https://rss.arxiv.org/abs/2402.01207](https://rss.arxiv.org/abs/2402.01207)

    提出了一个新的框架，利用大型语言模型进行高效的因果图发现，采用了广度优先搜索方法，只需要线性数量的查询，同时能轻松结合观察数据以提高性能，具有高效性和数据效率，并在真实因果图上取得了最先进的结果，展示了其在不同领域的广泛适用性潜力。

    

    我们提出了一个新的框架，利用LLMs进行完整的因果图发现。之前基于LLM的方法采用了成对查询的方法，但这需要二次查询的数量，对于较大的因果图来说很快变得不可行。相反，提出的框架采用了广度优先搜索（BFS）的方法，只需要线性数量的查询。我们还展示了当有所观察数据可用时，提出的方法可以轻松地进行结合以提高性能。除了更具时间和数据效率外，提出的框架在不同大小的真实因果图上取得了最先进的结果。结果证明了提出方法在发现因果关系方面的有效性和效率，展示了其在不同领域的因果图发现任务中的广泛适用性潜力。

    We propose a novel framework that leverages LLMs for full causal graph discovery. While previous LLM-based methods have used a pairwise query approach, this requires a quadratic number of queries which quickly becomes impractical for larger causal graphs. In contrast, the proposed framework uses a breadth-first search (BFS) approach which allows it to use only a linear number of queries. We also show that the proposed method can easily incorporate observational data when available, to improve performance. In addition to being more time and data-efficient, the proposed framework achieves state-of-the-art results on real-world causal graphs of varying sizes. The results demonstrate the effectiveness and efficiency of the proposed method in discovering causal relationships, showcasing its potential for broad applicability in causal graph discovery tasks across different domains.
    
[^2]: RAVE: CLIP引导的残差向量嵌入用于背光图像增强

    RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement

    [https://arxiv.org/abs/2404.01889](https://arxiv.org/abs/2404.01889)

    该论文提出了一种用于背光图像增强的CLIP引导方法RAVE，通过残差向量嵌入和提示调整的新颖方法，加快了训练并提高了质量。

    

    在本文中，我们提出了一种对反差异式语言-图像预训练（CLIP）指导进行了新颖修改的方法，用于无监督背光图像增强任务。我们的工作建立在最先进的CLIP-LIT方法基础之上，该方法通过约束在CLIP嵌入空间中一个提示对之间的文本-图像相似性来学习一个提示对（负/正样本）和相应图像（背光图像/光照良好的图像）。学习的提示然后指导图像增强网络。基于CLIP-LIT框架，我们提出了两种CLIP引导的新方法。首先，我们展示了在文本嵌入空间调整提示而不损失质量的可能性，从而可以直接在潜在空间中调整它们的嵌入，加快训练并潜在地实现使用没有文本编码器的其他编码器。其次，我们提出了一种不需要任何提示调整的新方法。

    arXiv:2404.01889v1 Announce Type: cross  Abstract: In this paper we propose a novel modification of Contrastive Language-Image Pre-Training (CLIP) guidance for the task of unsupervised backlit image enhancement. Our work builds on the state-of-the-art CLIP-LIT approach, which learns a prompt pair by constraining the text-image similarity between a prompt (negative/positive sample) and a corresponding image (backlit image/well-lit image) in the CLIP embedding space. Learned prompts then guide an image enhancement network. Based on the CLIP-LIT framework, we propose two novel methods for CLIP guidance. First, we show that instead of tuning prompts in the space of text embeddings, it is possible to directly tune their embeddings in the latent space without any loss in quality. This accelerates training and potentially enables the use of additional encoders that do not have a text encoder. Second, we propose a novel approach that does not require any prompt tuning. Instead, based on CLIP e
    
[^3]: ELITR-Bench: 面向长上下文语言模型的会议助理基准

    ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models

    [https://arxiv.org/abs/2403.20262](https://arxiv.org/abs/2403.20262)

    该论文提出了一个新的基准 ELITR-Bench，专注于长上下文语言模型的实际会议助理场景，通过在现有 ELITR 语料库的转录中添加手工制作的问题和真实答案，揭示了开源模型和专有模型之间的差距。

    

    最近，对大型语言模型（LLMs）的研究越来越受到关注，主要致力于扩展模型的上下文大小，以更好地捕捉长文档内部的依赖关系。尽管已经提出了用于评估长距离能力的基准，但现有的努力主要考虑的是不一定与现实应用相关的通用任务。相反，我们的工作提出了一个针对实际会议助理场景的长上下文LLMs的新基准。在这种情景下，长上下文由自动语音识别获得的转录组成，由于这些数据的固有嘈杂性和口语特性，这为LLMs提出了独特的挑战。我们的基准，名为ELITR-Bench，通过271个手工制作的问题及其真实答案来增强现有的ELITR语料库的转录。我们在ELITR-Bench上对最新的长上下文LLMs进行的实验凸显了开源模型和专有模型之间的差距。

    arXiv:2403.20262v1 Announce Type: cross  Abstract: Research on Large Language Models (LLMs) has recently witnessed an increasing interest in extending models' context size to better capture dependencies within long documents. While benchmarks have been proposed to assess long-range abilities, existing efforts primarily considered generic tasks that are not necessarily aligned with real-world applications. In contrast, our work proposes a new benchmark for long-context LLMs focused on a practical meeting assistant scenario. In this scenario, the long contexts consist of transcripts obtained by automatic speech recognition, presenting unique challenges for LLMs due to the inherent noisiness and oral nature of such data. Our benchmark, named ELITR-Bench, augments the existing ELITR corpus' transcripts with 271 manually crafted questions and their ground-truth answers. Our experiments with recent long-context LLMs on ELITR-Bench highlight a gap between open-source and proprietary models, e
    
[^4]: LLM可以进行正式对话吗？自动评估LLMs在转换和解释正式规范中的表现

    Can LLMs Converse Formally? Automatically Assessing LLMs in Translating and Interpreting Formal Specifications

    [https://arxiv.org/abs/2403.18327](https://arxiv.org/abs/2403.18327)

    本文提出了一种方法，利用两个LLM的副本与验证器结合使用，能够自动评估其在自然语言描述和正式规范之间转换的能力，无需额外的人工输入。

    

    利益相关者经常用自然语言描述系统需求，然后由领域专家将其转换为形式化语法，从而增加设计成本。本文评估了大型语言模型（LLMs）在自然语言描述和正式规范之间转换的能力。我们提出了一种方法，可以利用两个LLM的副本与现成的验证器结合使用，无需任何额外的人工输入就可以自动评估其翻译能力。我们的方法使用语言语法生成形式化语法，自动生成数据集。我们进行了经验评估以衡量这种翻译任务的准确性。

    arXiv:2403.18327v1 Announce Type: cross  Abstract: Stakeholders often describe system requirements using natural language which are then converted to formal syntax by a domain-expert leading to increased design costs. This paper assesses the capabilities of Large Language Models (LLMs) in converting between natural language descriptions and formal specifications. Existing work has evaluated the capabilities of LLMs in generating formal syntax such as source code but such experiments are typically hand-crafted and use problems that are likely to be in the training set of LLMs, and often require human-annotated datasets. We propose an approach that can use two copies of an LLM in conjunction with an off-the-shelf verifier to automatically evaluate its translation abilities without any additional human input. Our approach generates formal syntax using language grammars to automatically generate a dataset. We conduct an empirical evaluation to measure the accuracy of this translation task 
    
[^5]: 人工智能在耳蜗植入装置中的先进算法：医疗策略、挑战和展望综述

    Advanced Artificial Intelligence Algorithms in Cochlear Implants: Review of Healthcare Strategies, Challenges, and Perspectives

    [https://arxiv.org/abs/2403.15442](https://arxiv.org/abs/2403.15442)

    人工智能在提高植入式听觉设备的语音质量方面具有前瞻性，并通过先进的信号处理技术以及应对多源语音和环境噪音挑战等方法来克服语音失真问题

    

    arXiv:2403.15442v1 公告类型: 跨领域 摘要: 自动语音识别（ASR）在我们的日常生活中发挥着至关重要的作用，不仅为与机器交互提供了便利，还为部分或完全听力受损的个体提供了沟通的机会。这一过程涉及以模拟形式接收语音信号，然后通过各种信号处理算法使其与容量有限的设备（如CI）兼容。然而，这些配备有有限数量电极的植入装置在合成过程中往往导致语音失真。尽管研究人员在使用各种最先进的信号处理技术改善接收到的语音质量方面做出了努力，但在涉及多个语音源、环境噪声和其他情况的场景中，挑战仍然存在。新人工智能（AI）方法的出现引入了先进的策略来解决这些限制。

    arXiv:2403.15442v1 Announce Type: cross  Abstract: Automatic speech recognition (ASR) plays a pivotal role in our daily lives, offering utility not only for interacting with machines but also for facilitating communication for individuals with either partial or profound hearing impairments. The process involves receiving the speech signal in analogue form, followed by various signal processing algorithms to make it compatible with devices of limited capacity, such as cochlear implants (CIs). Unfortunately, these implants, equipped with a finite number of electrodes, often result in speech distortion during synthesis. Despite efforts by researchers to enhance received speech quality using various state-of-the-art signal processing techniques, challenges persist, especially in scenarios involving multiple sources of speech, environmental noise, and other circumstances. The advent of new artificial intelligence (AI) methods has ushered in cutting-edge strategies to address the limitations
    
[^6]: 面向具有100多个量子比特的NISQ处理器的深度量子电路最佳布局综合

    Optimal Layout Synthesis for Deep Quantum Circuits on NISQ Processors with 100+ Qubits

    [https://arxiv.org/abs/2403.11598](https://arxiv.org/abs/2403.11598)

    本研究提出了一种基于并行计划的SAT编码，每个时间步骤应用1个SWAP和一组CNOT。利用特定领域信息，在并行计划中保持优化性能的同时，扩展到大型深度电路。我们展示了我们方法的可扩展性，在多项比领先的精确和接近最优方法表现出色（高达100倍）。我们首次能够最优地映射多个8、14和16量子比特

    

    布局综合是将量子电路映射到量子处理器。需要为仅在连接的物理量子比特上安排2比特门的调度进行SWAP门插入。随着NISQ处理器中量子比特数量的不断增加，可扩展的布局综合至关重要。在启发式方法中观察到的优化间隙较大，需要可扩展的精确方法。尽管最近的精确和接近最优方法适用于中等规模电路，但大型深度电路仍超出范围。

    arXiv:2403.11598v1 Announce Type: cross  Abstract: Layout synthesis is mapping a quantum circuit to a quantum processor. SWAP gate insertions are needed for scheduling 2-qubit gates only on connected physical qubits. With the ever-increasing number of qubits in NISQ processors, scalable layout synthesis is of utmost importance. With large optimality gaps observed in heuristic approaches, scalable exact methods are needed. While recent exact and near-optimal approaches scale to moderate circuits, large deep circuits are still out of scope.   In this work, we propose a SAT encoding based on parallel plans that apply 1 SWAP and a group of CNOTs at each time step. Using domain-specific information, we maintain optimality in parallel plans while scaling to large and deep circuits. From our results, we show the scalability of our approach which significantly outperforms leading exact and near-optimal approaches (up to 100x). For the first time, we can optimally map several 8, 14, and 16 qubi
    
[^7]: 社会整合导航：具有深度强化学习的社交行动机器人

    Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.09793](https://arxiv.org/abs/2403.09793)

    提出了一种新颖的社会整合导航方法，通过与人的互动使机器人的社交行为自适应，并从其他基于DRL的导航方法中区分出具有明确预定义社交行为的社会意识方法和缺乏社交行为的社会碰撞回避。

    

    移动机器人正在广泛应用于各种拥挤场景，并成为我们社会的一部分。一个具有个体人类考虑的社会可接受的导航行为对于可扩展的应用和人类接受至关重要。最近使用深度强化学习（DRL）方法来学习机器人的导航策略，并对机器人与人类之间的复杂交互进行建模。我们建议根据机器人展示的社交行为将现有基于DRL的导航方法分为具有缺乏社交行为的社会碰撞回避和具有明确预定义社交行为的社会意识方法。此外，我们提出了一种新颖的社会整合导航方法，其中机器人的社交行为是自适应的，并且是通过与人类的互动而产生的。我们的方法的构式源自社会学定义，

    arXiv:2403.09793v1 Announce Type: cross  Abstract: Mobile robots are being used on a large scale in various crowded situations and become part of our society. The socially acceptable navigation behavior of a mobile robot with individual human consideration is an essential requirement for scalable applications and human acceptance. Deep Reinforcement Learning (DRL) approaches are recently used to learn a robot's navigation policy and to model the complex interactions between robots and humans. We propose to divide existing DRL-based navigation approaches based on the robot's exhibited social behavior and distinguish between social collision avoidance with a lack of social behavior and socially aware approaches with explicit predefined social behavior. In addition, we propose a novel socially integrated navigation approach where the robot's social behavior is adaptive and emerges from the interaction with humans. The formulation of our approach is derived from a sociological definition, 
    
[^8]: 将去噪推广到非平衡结构以改进等变力场

    Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields

    [https://arxiv.org/abs/2403.09549](https://arxiv.org/abs/2403.09549)

    将去噪方法推广到非平衡结构，从而改进等变力场的性能，提高了对原子间相互作用的理解以及在分子动力学和催化剂设计等领域的应用。

    

    理解原子间的相互作用，如3D原子体系中的力，对于许多应用如分子动力学和催化剂设计至关重要。然而，模拟这些相互作用需要计算密集的从头算计算，因此训练神经网络的数据有限。本文提出使用去噪非平衡结构（DeNS）作为辅助任务，以更好地利用训练数据并提高性能。在使用DeNS进行训练时，我们首先通过向其3D坐标添加噪声来破坏3D结构，然后预测噪声。不同于以往仅限于平衡结构的去噪工作，所提出的方法将去噪泛化到更大范围的非平衡结构。主要区别在于非平衡结构不对应于局部能量最小值，具有非零力，因此可能具有许多可能的原子位置。

    arXiv:2403.09549v1 Announce Type: cross  Abstract: Understanding the interactions of atoms such as forces in 3D atomistic systems is fundamental to many applications like molecular dynamics and catalyst design. However, simulating these interactions requires compute-intensive ab initio calculations and thus results in limited data for training neural networks. In this paper, we propose to use denoising non-equilibrium structures (DeNS) as an auxiliary task to better leverage training data and improve performance. For training with DeNS, we first corrupt a 3D structure by adding noise to its 3D coordinates and then predict the noise. Different from previous works on denoising, which are limited to equilibrium structures, the proposed method generalizes denoising to a much larger set of non-equilibrium structures. The main difference is that a non-equilibrium structure does not correspond to local energy minima and has non-zero forces, and therefore it can have many possible atomic posit
    
[^9]: 超越死记硬背：语言模型中的随机内存访问挑战

    Beyond Memorization: The Challenge of Random Memory Access in Language Models

    [https://arxiv.org/abs/2403.07805](https://arxiv.org/abs/2403.07805)

    本文研究了语言模型在访问内存时的挑战，发现通过背诵和置换等技术可以改善语言模型的随机内存访问能力，从而在开放域问题回答任务中取得显著改进。

    

    最近语言模型(LMs)的发展展示了它们在NLP任务中的有效性，尤其是在知识密集型任务中。然而，在其参数内部的知识存储和内存访问机制仍然令人费解。本文探讨了生成式语言模型（如GPT-2）是否能够顺序或随机地访问其内存。通过精心设计的合成任务，涵盖全面背诵、选择性背诵和基于问题回答的情景，我们揭示了LMs能够顺序访问其内存，同时在随机访问已记忆内容时遇到挑战。我们发现，通过背诵和置换等技术可以提高LMs的随机内存访问能力。此外，通过将这种干预应用于开放域问题回答的现实场景，我们验证了通过背诵来增强随机访问技术对问题回答能力的显著改进。

    arXiv:2403.07805v1 Announce Type: cross  Abstract: Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks. However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through carefully-designed synthetic tasks, covering the scenarios of full recitation, selective recitation and grounded question answering, we reveal that LMs manage to sequentially access their memory while encountering challenges in randomly accessing memorized content. We find that techniques including recitation and permutation improve the random memory access capability of LMs. Furthermore, by applying this intervention to realistic scenarios of open-domain question answering, we validate that enhancing random access by recitation leads to notable improvements in questi
    
[^10]: WorkArena：Web代理在解决常见知识工作任务中的能力如何？

    WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?

    [https://arxiv.org/abs/2403.07718](https://arxiv.org/abs/2403.07718)

    该研究探究了基于大型语言模型的代理在通过web浏览器与软件交互时的能力，提出了WorkArena和BrowserGym两个工具，在29个任务的基准测试中显示出潜力，但也揭示了实现完全任务自动化仍存在挑战。

    

    我们研究了基于大型语言模型的代理与软件通过web浏览器交互的应用。与先前的研究不同，我们关注衡量这些代理执行任务的能力，这些任务涵盖了利用企业软件系统的知识工作者的典型日常工作。为此，我们提出了WorkArena，一个基于广泛使用的ServiceNow平台的29个任务的远程主机基准。我们还介绍了BrowserGym，这是一个用于设计和评估这些代理的环境，提供了丰富的行为和多模态观察。我们的实证评估显示，尽管当前的代理在WorkArena上表现出了潜力，但要实现完全任务自动化仍存在相当大的差距。值得注意的是，我们的分析揭示了开源和闭源LLMs之间显著的性能差距，突出了未来探索和发展领域的一个重要领域。

    arXiv:2403.07718v1 Announce Type: cross  Abstract: We study the use of large language model-based agents for interacting with software via web browsers. Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform. We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation. Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field.
    
[^11]: 构建数据结构：走向语义图因果关系

    Structure Your Data: Towards Semantic Graph Counterfactuals

    [https://arxiv.org/abs/2403.06514](https://arxiv.org/abs/2403.06514)

    提出了基于语义图的反事实解释方法，利用GNN来进行高效的图编辑距离计算，通过场景图形式，绕过NP困难的图相似性问题，实现更具描述性、准确性和与人类对齐的解释。

    

    基于概念的反事实解释（CEs）是考虑替代情景以了解哪些高级语义特征对特定模型预测做出了贡献的解释。在这项工作中，我们提出了基于伴随输入数据的语义图的CEs，以实现更具描述性、准确性和与人类对齐的解释。借鉴最先进的概念尝试，我们采用了一个基于模型的编辑方法，并引入了利用GNN来实现高效的图编辑距离（GED）计算。我们将图形结构用于视觉领域，将图像表示为场景图，并获得它们的GNN嵌入以绕过解决所有输入对的NP困难图相似性问题，这是CE计算过程的一个重要部分。我们将我们的方法应用于具有不同难度和语义注释可用性的基准和真实世界数据集上。在各种分类器上进行测试，我们发现我们的CEs表现优异。

    arXiv:2403.06514v1 Announce Type: cross  Abstract: Counterfactual explanations (CEs) based on concepts are explanations that consider alternative scenarios to understand which high-level semantic features contributed to particular model predictions. In this work, we propose CEs based on the semantic graphs accompanying input data to achieve more descriptive, accurate, and human-aligned explanations. Building upon state-of-the-art (SoTA) conceptual attempts, we adopt a model-agnostic edit-based approach and introduce leveraging GNNs for efficient Graph Edit Distance (GED) computation. With a focus on the visual domain, we represent images as scene graphs and obtain their GNN embeddings to bypass solving the NP-hard graph similarity problem for all input pairs, an integral part of the CE computation process. We apply our method to benchmark and real-world datasets with varying difficulty and availability of semantic annotations. Testing on diverse classifiers, we find that our CEs outper
    
[^12]: xT：用于大图像中更大上下文的嵌套标记化

    xT: Nested Tokenization for Larger Context in Large Images

    [https://arxiv.org/abs/2403.01915](https://arxiv.org/abs/2403.01915)

    xT为视觉Transformer引入了嵌套标记化方案，有效地聚合了全局背景和局部细节，使其能够在现代GPU上端到端地建模大图像，并在经典视觉任务数据集上展示了改进。

    

    现代计算机视觉流水线以两种次优方式处理大图像：下采样或裁剪。这两种方法导致图像中信息和背景的丢失。在许多下游应用中，全局背景的重要性与高频细节一样，例如在现实世界的卫星图像中；在这种情况下，研究人员必须做出舍弃哪些信息的困扰选择。我们介绍了xT，这是一个简单的视觉Transformer框架，可以有效地聚合全局背景和局部细节，并可以在当代GPU上端对端地对大图像进行建模。我们选择了一组跨经典视觉任务的基准数据集，这些任务准确地反映了视觉模型理解真正大型图像并在大范围内融合细节的能力，并评估了我们的方法在其上的改进。通过引入针对大图像的嵌套标记化方案

    arXiv:2403.01915v1 Announce Type: cross  Abstract: Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model's ability to understand truly large images and incorporate fine details over large scales and assess our method's improvement on them. By introducing a nested tokenization scheme for large images in 
    
[^13]: 利用共因原则解决辛普森悖论

    Resolution of Simpson's paradox via the common cause principle

    [https://arxiv.org/abs/2403.00957](https://arxiv.org/abs/2403.00957)

    通过对共同原因$C$进行条件设定，解决了辛普森悖论，推广了悖论，并表明在二元共同原因$C$上进行条件设定的关联方向与原始$B$上进行条件设定相同

    

    辛普森悖论是建立两个事件$a_1$和$a_2$之间的概率关联时的障碍，给定第三个（潜在的）随机变量$B$。我们关注的情景是随机变量$A$（汇总了$a_1$、$a_2$及其补集）和$B$有一个可能未被观察到的共同原因$C$。或者，我们可以假设$C$将$A$从$B$中筛选出去。对于这种情况，正确的$a_1$和$a_2$之间的关联应该通过对$C$进行条件设定来定义。这一设置将原始辛普森悖论推广了。现在它的两个相互矛盾的选项简单地指的是两个特定且不同的原因$C$。我们表明，如果$B$和$C$是二进制的，$A$是四进制的（对于有效的辛普森悖论来说是最小且最常见的情况），在任何二元共同原因$C$上进行条件设定将建立与在原始$B$上进行条件设定相同的$a_1$和$a_2$之间的关联方向。

    arXiv:2403.00957v1 Announce Type: cross  Abstract: Simpson's paradox is an obstacle to establishing a probabilistic association between two events $a_1$ and $a_2$, given the third (lurking) random variable $B$. We focus on scenarios when the random variables $A$ (which combines $a_1$, $a_2$, and their complements) and $B$ have a common cause $C$ that need not be observed. Alternatively, we can assume that $C$ screens out $A$ from $B$. For such cases, the correct association between $a_1$ and $a_2$ is to be defined via conditioning over $C$. This set-up generalizes the original Simpson's paradox. Now its two contradicting options simply refer to two particular and different causes $C$. We show that if $B$ and $C$ are binary and $A$ is quaternary (the minimal and the most widespread situation for valid Simpson's paradox), the conditioning over any binary common cause $C$ establishes the same direction of the association between $a_1$ and $a_2$ as the conditioning over $B$ in the original
    
[^14]: FSL模型可以因为其优越性得分更高

    FSL Model can Score Higher as It Is

    [https://arxiv.org/abs/2402.18292](https://arxiv.org/abs/2402.18292)

    为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。

    

    在日常生活中，为了增加被正确识别的机会，我们倾向于面对面地直视面部识别机，而不是侧着面对。少样本学习（FSL）分类本身就具有挑战性，因为模型必须识别属于训练时未见的类别的图像。因此，在测试期间对扭曲和非典型的查询或支持图像会让模型更难正确预测。在我们的研究中，为了增加测试期间正确预测的机会，我们旨在通过图像到图像的转换纠正训练过的FSL模型的测试输入，生成被测试类别的新样本。FSL模型通常是在具有足够样本的类别上进行训练，然后在具有少样本样本的类别上进行测试。我们提出的方法首先捕捉测试图像的风格或形状，然后识别一个适当的训

    arXiv:2402.18292v1 Announce Type: cross  Abstract: In daily life, we tend to present the front of our faces by staring squarely at a facial recognition machine, instead of facing it sideways, in order to increase the chance of being correctly recognised. Few-shot-learning (FSL) classification is challenging in itself because a model has to identify images that belong to classes previously unseen during training. Therefore, a warped and non-typical query or support image during testing can make it even more challenging for a model to predict correctly. In our work, to increase the chance of correct prediction during testing, we aim to rectify the test input of a trained FSL model by generating new samples of the tested classes through image-to-image translation. An FSL model is usually trained on classes with sufficient samples, and then tested on classes with few-shot samples. Our proposed method first captures the style or shape of the test image, and then identifies a suitable traine
    
[^15]: OmniACT：用于启用桌面和Web多模式通用主动智能体的数据集和基准

    OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web

    [https://arxiv.org/abs/2402.17553](https://arxiv.org/abs/2402.17553)

    OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。

    

    几十年来，人机交互从根本上一直是手动的。即使在今天，几乎所有在计算机上进行的高效工作都需要人类在每一步都提供输入。虚拟主动智能代表了自动化许多这些琐碎任务的一个激动人心的步骤。虚拟代理将使技术能力有限的用户能够充分利用计算机系统的各种可能性。它们还可以实现高效地简化许多计算机任务，从日历管理到复杂的旅行预订，减少人类干预。在这篇论文中，我们介绍了 OmniACT，这是一个用于评估代理生成可执行程序来完成计算机任务能力的首个数据集和基准。我们的范围超越了传统的Web自动化，涵盖了各种桌面应用。该数据集包含诸如"播放下一首歌"之类的基本任务，以及更为长期的任务

    arXiv:2402.17553v1 Announce Type: new  Abstract: For decades, human-computer interaction has fundamentally been manual. Even today, almost all productive work done on the computer necessitates human input at every step. Autonomous virtual agents represent an exciting step in automating many of these menial tasks. Virtual agents would empower users with limited technical proficiency to harness the full possibilities of computer systems. They could also enable the efficient streamlining of numerous computer tasks, ranging from calendar management to complex travel bookings, with minimal human intervention. In this paper, we introduce OmniACT, the first-of-a-kind dataset and benchmark for assessing an agent's capability to generate executable programs to accomplish computer tasks. Our scope extends beyond traditional web automation, covering a diverse range of desktop applications. The dataset consists of fundamental tasks such as "Play the next song", as well as longer horizon tasks such
    
[^16]: 使用超高维计算进行单次图表示学习

    One-Shot Graph Representation Learning Using Hyperdimensional Computing

    [https://arxiv.org/abs/2402.17073](https://arxiv.org/abs/2402.17073)

    该方法提出了一种使用超高维计算进行单次图表示学习的方法，通过将数据投影到高维空间并利用HD运算符进行信息聚合，实现了与最先进深度学习方法相竞争的预测性能，而无需进行计算昂贵的训练。

    

    我们提出了一种新颖、简单、快速、高效的半监督图学习方法。所提方法利用超高维计算，将数据样本使用随机投影编码到高维空间（简称HD空间）。具体来说，我们提出了一种利用图神经网络节点表示的单射性质的超高维图学习（HDGL）算法。HDGL将节点特征映射到HD空间，然后使用HD运算符（如捆绑和绑定）来聚合每个节点的局部邻域信息。对广泛使用的基准数据集进行的实验结果显示，HDGL实现了与最先进深度学习方法相竞争的预测性能，而无需进行计算昂贵的训练。

    arXiv:2402.17073v1 Announce Type: cross  Abstract: We present a novel, simple, fast, and efficient approach for semi-supervised learning on graphs. The proposed approach takes advantage of hyper-dimensional computing which encodes data samples using random projections into a high dimensional space (HD space for short). Specifically, we propose a Hyper-dimensional Graph Learning (HDGL) algorithm that leverages the injectivity property of the node representations of a family of graph neural networks. HDGL maps node features to the HD space and then uses HD operators such as bundling and binding to aggregate information from the local neighborhood of each node. Results of experiments with widely used benchmark data sets show that HDGL achieves predictive performance that is competitive with the state-of-the-art deep learning methods, without the need for computationally expensive training.
    
[^17]: 神秘的投影：多模态LLMs在没有更丰富的跨模态投影的情况下获得特定领域的视觉能力

    Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual Capabilities Without Richer Cross-Modal Projections

    [https://arxiv.org/abs/2402.16832](https://arxiv.org/abs/2402.16832)

    MLLMs通过微调获得了特定领域的视觉能力，但投影并未提取相关的领域特定视觉属性。

    

    多模态大型语言模型（MLLMs）如LLaVA和GPT-4(V)使得可以进行关于图像的通用对话。然而，现成的MLLMs可能在诸如皮肤病学和农业等领域的图像上具有有限的能力，因此必须进行微调以解锁特定领域的应用。通过对4个数据集进行实验，在两种微调设置下，我们发现随着MLLM的微调，它确实获得了特定领域的视觉能力，但这些更新并没有导致投影提取相关的领域特定视觉属性。

    arXiv:2402.16832v1 Announce Type: new  Abstract: Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock domain-specific applications. The prevalent architecture of current open-source MLLMs comprises two major modules: an image-language (cross-modal) projection network and a large language model. It is desirable to understand the roles of these two modules in modeling domain-specific visual attributes to inform the design of future models and streamline the interpretability efforts on the current models. To this end, via experiments on 4 datasets and under 2 fine-tuning settings, we find that as the MLLM is fine-tuned, it indeed gains domain-specific visual capabilities, but the updates do not lead to the projection extracting relevant domain-specific visual
    
[^18]: 彩虹团队：多样化对抗性提示的开放式生成

    Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts

    [https://arxiv.org/abs/2402.16822](https://arxiv.org/abs/2402.16822)

    Rainbow Teaming提出了一种新方法，通过开放式搜索生成多样化的对抗性提示，可以帮助改善大型语言模型的稳健性，提高安全性，问答和网络安全等领域的模型漏洞。

    

    随着大型语言模型（LLMs）在许多现实世界应用中变得越来越普遍，理解和增强它们对用户输入的稳健性至关重要。现有的用于识别敌对提示的方法往往专注于特定领域，缺乏多样性，或需要大量人工注释。为了解决这些限制，我们提出了彩虹团队，一种用于生成多样化对抗性提示的新方法。彩虹团队将对抗性提示生成视为一个质量 - 多样性问题，并使用开放式搜索来生成既有效又多样的提示。它可以揭示模型在广泛领域内的脆弱性，包括本文中的安全性、问答和网络安全。我们还证明，对由彩虹团队生成的合成数据进行微调可以提高最先进的LLMs的安全性，而不损害它们的一般能力。

    arXiv:2402.16822v1 Announce Type: new  Abstract: As large language models (LLMs) become increasingly prevalent across many real-world applications, understanding and enhancing their robustness to user inputs is of paramount importance. Existing methods for identifying adversarial prompts tend to focus on specific domains, lack diversity, or require extensive human annotations. To address these limitations, we present Rainbow Teaming, a novel approach for producing a diverse collection of adversarial prompts. Rainbow Teaming casts adversarial prompt generation as a quality-diversity problem, and uses open-ended search to generate prompts that are both effective and diverse. It can uncover a model's vulnerabilities across a broad range of domains including, in this paper, safety, question answering, and cybersecurity. We also demonstrate that fine-tuning on synthetic data generated by Rainbow Teaming improves the safety of state-of-the-art LLMs without hurting their general capabilities 
    
[^19]: 一种具有长期上下文概要记忆的人工智能阅读代理

    A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts

    [https://arxiv.org/abs/2402.09727](https://arxiv.org/abs/2402.09727)

    ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。

    

    当前的大型语言模型不仅限制在某个最大上下文长度内，而且无法稳定地处理长输入。为了解决这些限制，我们提出了ReadAgent，一个增加了有效上下文长度的语言模型代理系统，在我们的实验中可以达到20倍。受到人类交互式阅读长文档的启发，我们将ReadAgent实现为一个简单的提示系统，利用LLM的高级语言能力来：（1）决定将哪些内容存储在一个记忆片段中，（2）将这些记忆片段压缩成为称为概要记忆的短时记忆，（3）在需要时通过原始文本查找段落来提醒自己相关细节以完成任务。我们使用检索方法、使用原始长上下文以及使用概要记忆来评估ReadAgent与基线的性能。这些评估是在三个长文档阅读理解任务上进行的。

    arXiv:2402.09727v1 Announce Type: cross  Abstract: Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called gist memories, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension task
    
[^20]: SelfSwapper: 通过形状无关的遮罩自编码器实现自监督人脸交换

    SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked AutoEncoder

    [https://arxiv.org/abs/2402.07370](https://arxiv.org/abs/2402.07370)

    本文介绍了SelfSwapper，一种通过 Shape Agnostic Masked AutoEncoder (SAMAE) 自监督方案来提升人脸交换模型训练的方法。通过绕过传统的训练方案，引入清晰的真实数据，以及利用遮罩和学到的特征，我们成功解决了身份泄漏和形状不对齐的问题。

    

    人脸交换因其多样化的应用而受到极大关注。大多数之前的人脸交换方法依赖于跷跷板式训练方案，通常导致模型训练的不稳定性并产生混合身份的不期望样本，原因是目标身份泄漏问题。本文介绍了Shape Agnostic Masked AutoEncoder (SAMAE) 训练方案，这是一种新颖的自监督方法，旨在改进人脸交换模型训练。我们的训练方案通过绕过传统的跷跷板游戏并通过自重建训练机制引入清晰的真实数据，解决了传统训练方法的局限性。它通过遮罩输入图像的面部区域和利用学到的身份和非身份特征来有效减轻身份泄漏。此外，我们还通过 perforation confusion 和随机网格缩放等新技术来解决形状不对齐问题。

    Face swapping has gained significant attention for its varied applications. The majority of previous face swapping approaches have relied on the seesaw game training scheme, which often leads to the instability of the model training and results in undesired samples with blended identities due to the target identity leakage problem. This paper introduces the Shape Agnostic Masked AutoEncoder (SAMAE) training scheme, a novel self-supervised approach designed to enhance face swapping model training. Our training scheme addresses the limitations of traditional training methods by circumventing the conventional seesaw game and introducing clear ground truth through its self-reconstruction training regime. It effectively mitigates identity leakage by masking facial regions of the input images and utilizing learned disentangled identity and non-identity features. Additionally, we tackle the shape misalignment problem with new techniques including perforation confusion and random mesh scaling,
    
[^21]: 好的教师解释: 解释增强的知识蒸馏

    Good Teachers Explain: Explanation-Enhanced Knowledge Distillation

    [https://arxiv.org/abs/2402.03119](https://arxiv.org/abs/2402.03119)

    通过优化解释增强的知识蒸馏（e$^2$KD）算法，可以让学生模型在准确性和学生-教师一致性方面都得到大幅度提升，确保学生模型从教师那里正确学到原因。

    

    知识蒸馏已被证明可以将大型教师模型压缩成较小的学生模型。虽然已经知道学生模型可以达到与教师相似的准确性，但也已经发现学生模型通常不会学到相同的函数。然而，学生模型和教师模型之间共享相似属性，如基于相同的输入特征进行预测，通常是非常有价值的，因为这确保学生从教师那里学到了“正确的特征”。在这项工作中，我们探索了是否可以通过优化经典的知识蒸馏损失以及教师和学生所生成的解释的相似性来实现这一点。尽管这个想法简单且直观，但我们发现我们提出的“解释增强的知识蒸馏”（e$^2$KD）（1）在准确性和学生-教师一致性方面始终提供了大幅度的增益，（2）确保学生从教师那里学到了正确的原因。

    Knowledge Distillation (KD) has proven effective for compressing large teacher models into smaller student models. While it is well known that student models can achieve similar accuracies as the teachers, it has also been shown that they nonetheless often do not learn the same function. It is, however, often highly desirable that the student's and teacher's functions share similar properties such as basing the prediction on the same input features, as this ensures that students learn the 'right features' from the teachers. In this work, we explore whether this can be achieved by not only optimizing the classic KD loss but also the similarity of the explanations generated by the teacher and the student. Despite the idea being simple and intuitive, we find that our proposed 'explanation-enhanced' KD (e$^2$KD) (1) consistently provides large gains in terms of accuracy and student-teacher agreement, (2) ensures that the student learns from the teacher to be right for the right reasons and
    
[^22]: 计算版权: 面向音乐生成AI的版税模型

    Computational Copyright: Towards A Royalty Model for Music Generative AI

    [https://arxiv.org/abs/2312.06646](https://arxiv.org/abs/2312.06646)

    本文旨在解决音乐生成AI领域中的版权问题，提出了一种用于AI音乐生成平台的版税模型，并探讨了对AI生成音乐进行版权归因的算法解决方案。

    

    生成AI的进步引发了版权挑战，在音乐行业尤为突出。本文关注这些挑战的经济方面，强调经济影响在版权领域中构成一个核心问题。黑盒生成AI技术的复杂性不仅表明，而且需要算法解决方案。然而，这样的解决方案在很大程度上缺失，导致监管挑战。我们旨在通过为AI音乐生成平台提出潜在的版税模型来弥补当前方法的差距。我们的方法涉及对Spotify和YouTube等平台现有版税模型的详细分析，并将其调整到AI生成音乐的独特背景中。我们面临的一个重要挑战是将AI生成的音乐归因于训练数据中有影响力的版权内容。为此，我们提出了利用数据归因的算法解决方案。

    The advancement of generative AI has given rise to pressing copyright challenges, particularly in music industry. This paper focuses on the economic aspects of these challenges, emphasizing that the economic impact constitutes a central issue in the copyright arena. The complexity of the black-box generative AI technologies not only suggests but necessitates algorithmic solutions. However, such solutions have been largely missing, leading to regulatory challenges in this landscape. We aim to bridge the gap in current approaches by proposing potential royalty models for revenue sharing on AI music generation platforms. Our methodology involves a detailed analysis of existing royalty models in platforms like Spotify and YouTube, and adapting these to the unique context of AI-generated music. A significant challenge we address is the attribution of AI-generated music to influential copyrighted content in the training data. To this end, we present algorithmic solutions employing data attri
    
[^23]: 视频本地化指令生成的高效预训练方法

    Efficient Pre-training for Localized Instruction Generation of Videos

    [https://arxiv.org/abs/2311.15964](https://arxiv.org/abs/2311.15964)

    提出了一种名为Sieve-&-Swap的技术，通过自动筛选出不相关文本并用人类编写的说明替换文本转录，从而实现视频本地化指令生成的高效预训练。

    

    过程视频展示了诸如食谱准备等任务的逐步演示。理解此类视频具有挑战性，需要对步骤进行精确定位并生成文字说明。手动注释步骤并编写说明成本高昂，这限制了当前数据集的规模并阻碍了有效学习。利用大规模但嘈杂的视频-文本数据集进行预训练可以提升性能，但需要大量计算资源。此外，文本转录包含无关内容，与人类注释员编写的说明相比存在风格变化。为了缓解这两个问题，我们提出了一种技术，Sieve-&-Swap，通过自动筛选出不相关文本和使用文本食谱数据集中人类编写的说明自动替换文本转录以增强文字指令的质量。

    arXiv:2311.15964v2 Announce Type: replace-cross  Abstract: Procedural videos show step-by-step demonstrations of tasks like recipe preparation. Understanding such videos is challenging, involving the precise localization of steps and the generation of textual instructions. Manually annotating steps and writing instructions is costly, which limits the size of current datasets and hinders effective learning. Leveraging large but noisy video-transcript datasets for pre-training can boost performance, but demands significant computational resources. Furthermore, transcripts contain irrelevant content and exhibit style variation compared to instructions written by human annotators. To mitigate both issues, we propose a technique, Sieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters irrelevant transcripts and (ii) Swap enhances the quality of the text instruction by automatically replacing the transcripts with human-written instructions from a text-only recipe dataset. 
    
[^24]: 使用对比对齐指令调整LLMs以解决机器翻译中的未知、低资源语言问题

    Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages. (arXiv:2401.05811v1 [cs.CL])

    [http://arxiv.org/abs/2401.05811](http://arxiv.org/abs/2401.05811)

    本文引入了对比对齐指令（AlignInstruct），通过使用统计词对齐构建的跨语言鉴别器实现了跨语言监督，解决了机器翻译中的两个挑战：将支持的语言扩展到未知语言和低资源语言中数据缺乏的问题。实验结果表明，LLMs通过MTInstruct可以有效地翻译未知语言，并且使用AlignInstruct在涉及英语的48个翻译方向上能够持续改善翻译质量。基于鉴别器的指令优于生成型指令。

    

    本文介绍了对比对齐指令（AlignInstruct）来解决大型语言模型（LLMs）上机器翻译（MT）中的两个挑战。一个是将支持的语言扩展到之前未见过的语言。第二个与低资源语言中缺乏数据有关。通过MT指令（MTInstruct）对模型进行微调是应对第一个挑战的一种直接方法。然而，MTInstruct受到第二个挑战中固有的弱语言跨度信号的限制。AlignInstruct通过使用基于统计词对齐构建的跨语言鉴别器来强调跨语言监督。我们基于在多达24种未知语言上对BLOOMZ模型（1b1、3b和7b1）进行微调的结果表明：（1）LLMs可以使用MTInstruct有效地翻译未知语言；（2）AlignInstruct在涉及英语的48个翻译方向上提高了翻译质量的一致性；（3）基于鉴别器的指令优于生成型指令。

    This article introduces contrastive alignment instructions (AlignInstruct) to address two challenges in machine translation (MT) on large language models (LLMs). One is the expansion of supported languages to previously unseen ones. The second relates to the lack of data in low-resource languages. Model fine-tuning through MT instructions (MTInstruct) is a straightforward approach to the first challenge. However, MTInstruct is limited by weak cross-lingual signals inherent in the second challenge. AlignInstruct emphasizes cross-lingual supervision via a cross-lingual discriminator built using statistical word alignments. Our results based on fine-tuning the BLOOMZ models (1b1, 3b, and 7b1) in up to 24 unseen languages showed that: (1) LLMs can effectively translate unseen languages using MTInstruct; (2) AlignInstruct led to consistent improvements in translation quality across 48 translation directions involving English; (3) Discriminator-based instructions outperformed their generativ
    
[^25]: 跨说话人编码网络用于多说话人语音识别

    Cross-Speaker Encoding Network for Multi-Talker Speech Recognition. (arXiv:2401.04152v1 [cs.SD])

    [http://arxiv.org/abs/2401.04152](http://arxiv.org/abs/2401.04152)

    本文提出了一种叫做Cross-Speaker Encoding（CSE）的网络，用于解决多说话人语音识别中的局限性，通过聚合跨说话人表示。通过与SOT结合，该模型在两个说话人的数据集上实验证明比SIMO基准模型的词错误率（WER）分别降低了8%和10%。

    

    端到端的多说话人语音识别已经引起了极大的兴趣，作为一种直接转录多个说话人重叠语音的有效方法。目前的方法通常采用1）带有分支编码器的单输入多输出（SIMO）模型，或者2）基于注意力机制的编码器-解码器架构和序列化输出训练（SOT）的单输入单输出（SISO）模型。在这项工作中，我们提出了一种叫做Cross-Speaker Encoding（CSE）的网络来解决SIMO模型的局限性，通过聚合跨说话人表示。此外，CSE模型与SOT相结合，既发挥了SIMO和SISO的优势，又缓解了它们的缺点。据我们所知，该工作代表了将SIMO和SISO集成到多说话人语音识别中的早期工作。在两个说话人的LibrispeechMix数据集上进行的实验表明，CES模型相比于SIMO基准模型将词错误率（WER）降低了8%。CSE-SOT模型将WER降低了10%

    End-to-end multi-talker speech recognition has garnered great interest as an effective approach to directly transcribe overlapped speech from multiple speakers. Current methods typically adopt either 1) single-input multiple-output (SIMO) models with a branched encoder, or 2) single-input single-output (SISO) models based on attention-based encoder-decoder architecture with serialized output training (SOT). In this work, we propose a Cross-Speaker Encoding (CSE) network to address the limitations of SIMO models by aggregating cross-speaker representations. Furthermore, the CSE model is integrated with SOT to leverage both the advantages of SIMO and SISO while mitigating their drawbacks. To the best of our knowledge, this work represents an early effort to integrate SIMO and SISO for multi-talker speech recognition. Experiments on the two-speaker LibrispeechMix dataset show that the CES model reduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model reduces WER by 10
    
[^26]: 图灵测试，一个美丽的思维实验

    Turing's Test, a Beautiful Thought Experiment. (arXiv:2401.00009v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.00009](http://arxiv.org/abs/2401.00009)

    本文对图灵的美丽的思维实验进行了历史重建，提供了大量证据和一些原创答案，同时回答了图灵测试的核心问题。

    

    在大规模语言模型的浪潮中，关于图灵测试及其对人工智能的价值的争论和问题重新兴起，并引发了数十年来实际的“图灵”测试。如果人工智能是量子物理学，现在可能已有几只“薛定谔的”猫被杀死了。迟到总比不到好，现在是对图灵美丽的思维实验进行历史重建的时候了。在本文中，我提供了大量证据，包括新的档案来源，针对图灵1950年论文的几个未解决问题给出了原创答案，并回答了图灵测试的核心问题。

    In the wake of large language models, there has been a resurgence of claims and questions about the Turing test and its value for AI, which are reminiscent of decades of practical "Turing" tests. If AI were quantum physics, by now several "Schr\"odinger's" cats could have been killed. Better late than never, it is time for a historical reconstruction of Turing's beautiful thought experiment. In this paper I present a wealth of evidence, including new archival sources, give original answers to several open questions about Turing's 1950 paper, and address the core question of the value of Turing's test.
    
[^27]: 多尺度超像素结构差异图卷积网络用于视觉语言表征

    Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation. (arXiv:2310.13447v1 [cs.CV])

    [http://arxiv.org/abs/2310.13447](http://arxiv.org/abs/2310.13447)

    本文提出了一种多尺度超像素结构差异图卷积网络（MDGCN）用于视觉语言表征，通过聚类感知相似像素，减少了后续处理的视觉基元数量，并挖掘了更精确的拓扑关系。

    

    在多模态领域中，整合视觉和语言的关键在于建立一个良好的对齐策略。最近，受到自监督学习成功的启发，基于预训练模型的视觉和语言的多模态语义表征取得了重大进展。然而，视觉语义表征仍有改进的空间。当前基于像素或块的方法在准确提取复杂场景边界方面存在空间语义连贯性不足和对噪声的脆弱性的挑战。为此，本文将超像素作为可学习图像数据的综合紧凑表征，通过对感知相似像素进行聚类，有效地减少了后续处理的视觉基元数量。为了挖掘更精确的拓扑关系，我们提出了一种多尺度差异图卷积网络（MDGCN）。它将整个图像解析为细到粗的层次结构，从而实现了整个图像的解析。

    Within the multimodal field, the key to integrating vision and language lies in establishing a good alignment strategy. Recently, benefiting from the success of self-supervised learning, significant progress has been made in multimodal semantic representation based on pre-trained models for vision and language. However, there is still room for improvement in visual semantic representation. The lack of spatial semantic coherence and vulnerability to noise makes it challenging for current pixel or patch-based methods to accurately extract complex scene boundaries. To this end, this paper develops superpixel as a comprehensive compact representation of learnable image data, which effectively reduces the number of visual primitives for subsequent processing by clustering perceptually similar pixels. To mine more precise topological relations, we propose a Multiscale Difference Graph Convolutional Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical structure of cons
    
[^28]: USL-Net：用于无监督皮肤病变分割的不确定性自学习网络

    USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation. (arXiv:2309.13289v1 [cs.CV])

    [http://arxiv.org/abs/2309.13289](http://arxiv.org/abs/2309.13289)

    使用对比学习和类激活图技术，USL-Net提供了一种无需手动标注指导的方法，能够有效地分割各种皮肤病变区域。

    

    无监督皮肤病变分割具有多种好处，包括节约专家人力资源、减少主观人工标注引起的差异以及适应新环境。然而，在没有手动标注指导的情况下分割皮肤镜图像存在显著挑战，如毛发噪声、水疱噪声和细微边缘差异等皮肤镜图像伪影。为了应对这些挑战，我们引入了一种创新的不确定性自学习网络（USL-Net）用于皮肤病变分割。USL-Net能够有效地分割各种病变，无需手动标注指导。首先，使用对比学习提取特征，然后使用这些特征生成类激活图（CAMs）作为显著图。不同的CAM位置对应于基于显著性的病变区域的重要性。地图中的高显著区域用作病变区域的伪标签，而低显著区域用作非病变区域的伪标签。

    Unsupervised skin lesion segmentation offers several benefits, including conserving expert human resources, reducing discrepancies due to subjective human labeling, and adapting to novel environments. However, segmenting dermoscopic images without manual labeling guidance presents significant challenges due to dermoscopic image artifacts such as hair noise, blister noise, and subtle edge differences. To address these challenges, we introduce an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin lesion segmentation. The USL-Net can effectively segment a range of lesions, eliminating the need for manual labeling guidance. Initially, features are extracted using contrastive learning, followed by the generation of Class Activation Maps (CAMs) as saliency maps using these features. The different CAM locations correspond to the importance of the lesion region based on their saliency. High-saliency regions in the map serve as pseudo-labels for lesion regions while low-sa
    
[^29]: 评估大型语言模型利用亚斯伯格综合征筛选测试理解隐喻和讽刺的能力

    Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome. (arXiv:2309.10744v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10744](http://arxiv.org/abs/2309.10744)

    该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。

    

    隐喻和讽刺是我们高度进化的社交沟通技巧的珍贵成果。然而，亚斯伯格综合征的儿童众所周知在理解讽刺方面存在困难，即使他们具有足够理解隐喻的口语智商水平。鉴于此，已经使用了一个评分测试来评估理解隐喻和讽刺的能力，以区分亚斯伯格综合征和其他表现相似外部行为的症状（例如注意力缺陷/多动障碍）。本研究使用标准化测试来研究最近大型语言模型（LLMs）理解人类微妙交流的能力。结果显示，随着模型参数数量的增加，它们理解隐喻的能力得到了改善，但并没有观察到对讽刺理解的改进。这意味着有必要采取其他方法来使LLMs具备理解讽刺的能力，这已与亚斯伯格综合征相关。

    Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills. However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors. Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication. The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been asso
    
[^30]: 不仅仅奖励，还有约束：用于腿式机器人运动的应用

    Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion. (arXiv:2308.12517v1 [cs.RO])

    [http://arxiv.org/abs/2308.12517](http://arxiv.org/abs/2308.12517)

    本文提出了一种新的强化学习框架，为复杂机器人系统训练神经网络控制器。该框架引入了奖励和约束的概念，通过设计高效的策略优化算法来处理约束，以减少计算开销。通过应用于不同腿式机器人的运动控制器训练中，展示了该框架的有效性。

    

    早期的一些研究通过设计神经网络控制器并使用无模型强化学习来训练，展示了复杂机器人系统中令人印象深刻的控制性能。然而，这些具有自然动作风格和高任务性能的出色控制器是通过进行大量奖励工程而开发的，该过程非常费时费力，需要设计大量奖励项并确定合适的奖励系数。在这项工作中，我们提出了一种新的强化学习框架，用于训练同时包含奖励和约束的神经网络控制器。为了让工程师能够适当地反映他们对约束的意图并以最小的计算开销处理它们，我们提出了两种约束类型和一种高效的策略优化算法。该学习框架被应用于训练不同形态和物理属性的几个腿式机器人的运动控制器。

    Several earlier studies have shown impressive control performance in complex robotic systems by designing the controller using a neural network and training it with model-free reinforcement learning. However, these outstanding controllers with natural motion style and high task performance are developed through extensive reward engineering, which is a highly laborious and time-consuming process of designing numerous reward terms and determining suitable reward coefficients. In this work, we propose a novel reinforcement learning framework for training neural network controllers for complex robotic systems consisting of both rewards and constraints. To let the engineers appropriately reflect their intent to constraints and handle them with minimal computation overhead, two constraint types and an efficient policy optimization algorithm are suggested. The learning framework is applied to train locomotion controllers for several legged robots with different morphology and physical attribu
    
[^31]: 通过观看数百个手术视频讲座学习多模态表示

    Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures. (arXiv:2307.15220v1 [cs.CV])

    [http://arxiv.org/abs/2307.15220](http://arxiv.org/abs/2307.15220)

    通过观看手术视频讲座，我们提出了一种新方法，SurgVLP，通过利用手术视频讲座中的语音和视觉信息进行多模态表示学习，并解决了手术相关语言挑战。

    

    最近在外科计算机视觉应用方面的进展主要依靠完全监督方法，主要使用视觉数据。这些方法依赖于手动注释的手术视频来预测一组固定的对象类别，限制了它们在未见手术程序和后续任务上的通用性。在这项工作中，我们提出了一个观点，即通过开放的手术电子学习平台提供的手术视频讲座可以为多模态表示学习提供有效的监督信号，而无需依赖手动注释。我们通过使用多个互补的自动语音识别系统生成文本转录来解决手术视频讲座中存在的手术相关语言挑战。然后，我们提出了一种新的方法，SurgVLP - 手术视觉语言预训练，用于多模态表示学习。SurgVLP构建了一种新的对比学习目标，将视频剪辑嵌入与相应的文本嵌入对齐。

    Recent advancements in surgical computer vision applications have been driven by fully-supervised methods, primarily using only visual data. These methods rely on manually annotated surgical videos to predict a fixed set of object categories, limiting their generalizability to unseen surgical procedures and downstream tasks. In this work, we put forward the idea that the surgical video lectures available through open surgical e-learning platforms can provide effective supervisory signals for multi-modal representation learning without relying on manual annotations. We address the surgery-specific linguistic challenges present in surgical video lectures by employing multiple complementary automatic speech recognition systems to generate text transcriptions. We then present a novel method, SurgVLP - Surgical Vision Language Pre-training, for multi-modal representation learning. SurgVLP constructs a new contrastive learning objective to align video clip embeddings with the corresponding m
    
[^32]: 提升离线到在线强化学习的Q-Ensembles方法

    Improving Offline-to-Online Reinforcement Learning with Q-Ensembles. (arXiv:2306.06871v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06871](http://arxiv.org/abs/2306.06871)

    我们提出了一种名为Q-Ensembles的新框架，通过增加Q网络的数量，无缝地连接离线预训练和在线微调，同时不降低性能。此外，我们适当放宽Q值估计的悲观性，并将基于集合的探索机制融入我们的框架中，从而提升了离线到在线强化学习的性能。

    

    离线强化学习是一种学习范式，代理根据固定的经验数据集进行学习。然而，仅从静态数据集中学习可能限制了性能，因为缺乏探索能力。为了克服这个问题，将离线预训练与在线微调结合起来的离线到在线强化学习方法能够让代理与环境实时交互，进一步完善其策略。然而，现有的离线到在线强化学习方法存在性能下降和在线阶段改进缓慢的问题。为了解决这些挑战，我们提出了一种名为Q-Ensembles的新框架，它通过增加Q网络的数量，无缝地连接离线预训练和在线微调，同时不降低性能。此外，为了加快在线性能提升，我们适当放宽Q值估计的悲观性，并将基于集合的探索机制融入我们的框架中。

    Offline reinforcement learning (RL) is a learning paradigm where an agent learns from a fixed dataset of experience. However, learning solely from a static dataset can limit the performance due to the lack of exploration. To overcome it, offline-to-online RL combines offline pre-training with online fine-tuning, which enables the agent to further refine its policy by interacting with the environment in real-time. Despite its benefits, existing offline-to-online RL methods suffer from performance degradation and slow improvement during the online phase. To tackle these challenges, we propose a novel framework called Ensemble-based Offline-to-Online (E2O) RL. By increasing the number of Q-networks, we seamlessly bridge offline pre-training and online fine-tuning without degrading performance. Moreover, to expedite online performance enhancement, we appropriately loosen the pessimism of Q-value estimation and incorporate ensemble-based exploration mechanisms into our framework. Experiment
    
[^33]: BiomedGPT：一种面向视觉、语言和多模态任务的统一且通用的生物医学生成预训练Transformer

    BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks. (arXiv:2305.17100v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17100](http://arxiv.org/abs/2305.17100)

    BiomedGPT是一种面向视觉、语言和多模态任务的通用生物医学生成预训练Transformer，在多个临床任务中取得了16个最新的最优结果，包括超过了OpenAI的GPT-4V和Google的Med-PaLM M（12B）。同时，BiomedGPT还支持零-shot迁移学习。

    

    传统的任务和模态特定的人工智能模型在生物医学领域的实际应用和维护中不够灵活。与此同时，生物医学数据的不断增加，结合现代多模态多任务人工智能技术的进展，为通用的生物医学人工智能解决方案的出现铺平了道路。这些解决方案有潜力解释不同的医疗模态，并产生如自由文本报告或疾病诊断等表达性输出。本文提出了BiomedGPT，这是第一个面向多样化生物医学任务的开源通用视觉语言人工智能模型。BiomedGPT在26个数据集的五个临床重要任务中实现了16个最新的结果。值得注意的是，在放射学人员评估中，它超越了OpenAI的GPT-4 with vision（GPT-4V），并在乳腺癌诊断和医学视觉问题回答方面超过了Google的Med-PaLM M（12B）。此外，BiomedGPT还支持零-shot迁移学习。

    Conventional task- and modality-specific artificial intelligence (AI) models are inflexible in real-world deployment and maintenance for biomedicine. At the same time, the growing availability of biomedical data, coupled with the advancements in modern multi-modal multi-task AI techniques, has paved the way for the emergence of generalist biomedical AI solutions. These solutions hold the potential to interpret different medical modalities and produce expressive outputs such as free-text reports or disease diagnosis. Here, we propose BiomedGPT, the first open-source and generalist visual language AI for diverse biomedical tasks. BiomedGPT achieved 16 state-of-the-art results across five clinically significant tasks on 26 datasets. Notably, it outperformed OpenAI's GPT-4 with vision (GPT-4V) in radiology human evaluation and surpassed Google's Med-PaLM M (12B) in breast cancer diagnosis and medical visual question answering. Moreover, BiomedGPT facilitates zero-shot transfer learning, gr
    
[^34]: 分布式神经表示技术用于反应式原位可视化

    Distributed Neural Representation for Reactive in situ Visualization. (arXiv:2304.10516v1 [cs.DC])

    [http://arxiv.org/abs/2304.10516](http://arxiv.org/abs/2304.10516)

    本研究开发了一种分布式体积数据的隐式神经表示技术，结合到反应式编程系统中构建了一个原位时间缓存系统，并在Ascent基础架构中使用实际模拟评估了其100倍容量的性能。

    

    利用反应式编程实现计算模型的原位可视化和控制十分高效，它利用时间抽象和数据缓存机制来创建动态工作流。然而，对于大规模模拟，实现时间缓存可能存在挑战。隐式神经网络已被证明在压缩大型数据方面是有效的。然而，它们在分布式数据上的应用还没有被充分探索。在本研究中，我们开发了一种分布式体积数据的隐式神经表示，并将其结合到DIVA反应式编程系统中。这种实现使我们能够构建一个原位时间缓存系统，其容量比以前的容量大100倍。我们将这种方法集成到Ascent基础架构中，并使用实际模拟来评估其性能。

    In situ visualization and steering of computational modeling can be effectively achieved using reactive programming, which leverages temporal abstraction and data caching mechanisms to create dynamic workflows. However, implementing a temporal cache for large-scale simulations can be challenging. Implicit neural networks have proven effective in compressing large volume data. However, their application to distributed data has yet to be fully explored. In this work, we develop an implicit neural representation for distributed volume data and incorporate it into the DIVA reactive programming system. This implementation enables us to build an in situ temporal caching system with a capacity 100 times larger than previously achieved. We integrate our implementation into the Ascent infrastructure and evaluate its performance using real-world simulations.
    
[^35]: 布局引导下的图像生成的诊断基准和迭代修复

    Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation. (arXiv:2304.06671v1 [cs.CV])

    [http://arxiv.org/abs/2304.06671](http://arxiv.org/abs/2304.06671)

    本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。

    

    空间控制是可控图像生成的核心能力。在布局引导下的图像生成方面的进展已经显示出在具有类似空间配置的内分布（ID）数据集上有良好的结果。然而，当面对任意不确定的布局的离线分布样本时，这些模型的表现还不清楚。在本文中，我们提出了LayoutBench，这是一种对布局引导下的图像生成进行诊断的基准，它检查了四种空间控制技能：数量，位置，大小和形状。我们对两种最近代表性的布局引导下的图像生成方法进行了基准测试，并观察到良好的ID布局控制可能无法很好地推广到任意布局的野外环境（例如，边界上的对象）。接下来，我们提出了一个新的基准方法IterInpaint，它通过修复逐步生成前景和背景区域，展示出在LayoutBench的OOD布局上更强的通用性。我们进行了数量和定性评估，表明IterInpaint相对于现有方法具有更好的生成多样和视觉上令人愉悦的图像和可控的空间布局。

    Spatial control is a core capability in controllable image generation. Advancements in layout-guided image generation have shown promising results on in-distribution (ID) datasets with similar spatial configurations. However, it is unclear how these models perform when facing out-of-distribution (OOD) samples with arbitrary, unseen layouts. In this paper, we propose LayoutBench, a diagnostic benchmark for layout-guided image generation that examines four categories of spatial control skills: number, position, size, and shape. We benchmark two recent representative layout-guided image generation methods and observe that the good ID layout control may not generalize well to arbitrary layouts in the wild (e.g., objects at the boundary). Next, we propose IterInpaint, a new baseline that generates foreground and background regions in a step-by-step manner via inpainting, demonstrating stronger generalizability than existing models on OOD layouts in LayoutBench. We perform quantitative and q
    
[^36]: 通过系统评估更好地理解归因方法的差异

    Better Understanding Differences in Attribution Methods via Systematic Evaluations. (arXiv:2303.11884v1 [cs.CV])

    [http://arxiv.org/abs/2303.11884](http://arxiv.org/abs/2303.11884)

    本文提出了三种新的评估方案，通过这些方案，可以更可靠地测量归因方法的可信度。

    

    深度神经网络在许多视觉任务上取得了巨大成功，但其黑盒性质使其难以解释。为了克服这一问题，提出了各种后续归因方法来确定对模型决策最有影响力的图像区域。由于不存在基准归因，因此评估这些方法是具有挑战性的。因此，我们提出了三种新的评估方案，以更可靠地测量这些方法的可信度，使它们之间的比较更公平，并使视觉检查更系统化。

    Deep neural networks are very successful on many vision tasks, but hard to interpret due to their black box nature. To overcome this, various post-hoc attribution methods have been proposed to identify image regions most influential to the models' decisions. Evaluating such methods is challenging since no ground truth attributions exist. We thus propose three novel evaluation schemes to more reliably measure the faithfulness of those methods, to make comparisons between them more fair, and to make visual inspection more systematic. To address faithfulness, we propose a novel evaluation setting (DiFull) in which we carefully control which parts of the input can influence the output in order to distinguish possible from impossible attributions. To address fairness, we note that different methods are applied at different layers, which skews any comparison, and so evaluate all methods on the same layers (ML-Att) and discuss how this impacts their performance on quantitative metrics. For mo
    
[^37]: 阅读并获得回报：在与指导手册的帮助下学习玩Atari游戏

    Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals. (arXiv:2302.04449v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04449](http://arxiv.org/abs/2302.04449)

    本论文提出了阅读并奖励的框架，通过阅读Atari游戏开发者发布的指导手册，以提高强化学习算法在Atari游戏中的效率。该框架包含一个QA提取模块和一个推理模块，能够从指导手册中提取关键信息，并评估物体与智能体的交互效果。

    

    长期以来，高样本复杂性一直是强化学习面临的挑战。然而，人类学习执行任务的方式不仅仅是通过交互或演示，还包括阅读非结构化文本文档，例如指导手册。指导手册和维基页面是最丰富的数据之一，它们可以提供有关宝贵特征、策略、任务特定的环境动态和奖励结构的信息，因此我们假设利用人写的指导手册来帮助学习特定任务的策略将导致更高效和更优秀的智能体。我们提出了阅读并奖励的框架。阅读并奖励通过阅读Atari游戏开发者发布的指导手册来加速RL算法。我们的框架包括一个QA提取模块，用于提取和总结指导手册中的相关信息，以及一个推理模块，根据指导手册中的信息评估物体-智能体的交互效果。一个辅助的反馈机制可以提高效果。

    High sample complexity has long been a challenge for RL. On the other hand, humans learn to perform tasks not only from interaction or demonstrations, but also by reading unstructured text documents, e.g., instruction manuals. Instruction manuals and wiki pages are among the most abundant data that could inform agents of valuable features and policies or task-specific environmental dynamics and reward structures. Therefore, we hypothesize that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent. We propose the Read and Reward framework. Read and Reward speeds up RL algorithms on Atari games by reading manuals released by the Atari game developers. Our framework consists of a QA Extraction module that extracts and summarizes relevant information from the manual and a Reasoning module that evaluates object-agent interactions based on information from the manual. An auxiliary re
    
[^38]: 《联邦学习是否真正需要反向传播？》

    Does Federated Learning Really Need Backpropagation?. (arXiv:2301.12195v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12195](http://arxiv.org/abs/2301.12195)

    本文提出一种不需要反向传播的联邦学习框架BAFFLE，该框架使用多个正向过程估计梯度，具有高内存效率，容易适应上传带宽，与硬件优化和模型量化/修剪兼容，适用于受信任的执行环境。

    

    联邦学习（FL）是一种去中心化地让客户端共同训练一个服务器模型的一般性原则，而无需共享本地数据。FL是一个具有实际应用的有前途的框架，但其标准训练范式要求客户端通过模型进行反向传播以计算梯度。由于这些客户端通常是边缘设备而不是完全受信任的，因此在它们上执行反向传播会产生计算和存储开销以及白盒漏洞。因此，我们开发了一种不需要反向传播的联邦学习，称为BAFFLE，其中反向传播替换为多个正向过程以估计梯度。BAFFLE具有以下优点：1）内存效率高并且容易适应上传带宽；2）与仅推理硬件优化以及模型量化或修剪兼容；3）非常适合受信任的执行环境，因为BAFFLE中的客户端仅执行正向传播并返回一组标量到服务器。我们通过实验使用了BAFFLE的优越性能。

    Federated learning (FL) is a general principle for decentralized clients to train a server model collectively without sharing local data. FL is a promising framework with practical applications, but its standard training paradigm requires the clients to backpropagate through the model to compute gradients. Since these clients are typically edge devices and not fully trusted, executing backpropagation on them incurs computational and storage overhead as well as white-box vulnerability. In light of this, we develop backpropagation-free federated learning, dubbed BAFFLE, in which backpropagation is replaced by multiple forward processes to estimate gradients. BAFFLE is 1) memory-efficient and easily fits uploading bandwidth; 2) compatible with inference-only hardware optimization and model quantization or pruning; and 3) well-suited to trusted execution environments, because the clients in BAFFLE only execute forward propagation and return a set of scalars to the server. Empirically we us
    
[^39]: 神经符号计算的语义框架

    A Semantic Framework for Neural-Symbolic Computing. (arXiv:2212.12050v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.12050](http://arxiv.org/abs/2212.12050)

    该论文提出了一个神经符号计算的语义框架，用于将神经网络和符号AI相结合成为综合系统，并通过将符号知识编码到神经网络中来解决通用推理能力的问题。

    

    人工智能的两种方法，神经网络和符号系统，对于一系列AI问题已经被证明非常成功。然而，两者均未能达到人类智能所需的通用推理能力。人们认为这是每种方法内在弱点所致。幸运的是，这些弱点似乎是互补的，符号系统擅长神经网络难以处理的事物，反之亦然。神经符号AI领域试图利用这种不对称性通过将神经网络和符号AI相结合成为综合系统。通常这是通过将符号知识编码到神经网络中实现的。不幸的是，虽然提出了许多不同的方法来实现这一点，但没有公共的编码定义可供比较。我们通过引入神经符号AI的语义框架来解决这个问题，然后证明它足以解释大量神经符号系统。我们的框架是基于符号系统植根于其领域的神经表征的概念。我们展示了我们的框架可以解释各种符号系统在神经表征中的实现方式，包括使用学习的神经表征和使用固定神经表征的系统。

    Two approaches to AI, neural networks and symbolic systems, have been proven very successful for an array of AI problems. However, neither has been able to achieve the general reasoning ability required for human-like intelligence. It has been argued that this is due to inherent weaknesses in each approach. Luckily, these weaknesses appear to be complementary, with symbolic systems being adept at the kinds of things neural networks have trouble with and vice-versa. The field of neural-symbolic AI attempts to exploit this asymmetry by combining neural networks and symbolic AI into integrated systems. Often this has been done by encoding symbolic knowledge into neural networks. Unfortunately, although many different methods for this have been proposed, there is no common definition of an encoding to compare them. We seek to rectify this problem by introducing a semantic framework for neural-symbolic AI, which is then shown to be general enough to account for a large family of neural-symb
    
[^40]: 自然对话中解释机器学习模型：走向对话式XAI代理

    Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent. (arXiv:2209.02552v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02552](http://arxiv.org/abs/2209.02552)

    本研究将解释人工智能（XAI）融入到一个对话代理中，设计具有自然语言理解和生成组件的标准模型。通过扩展XAI问题库并提供解释方法，实现了关于机器学习模型的真正自然对话。

    

    可解释人工智能（XAI）的目标是设计方法来揭示黑盒模型（如深度神经网络）的推理过程，以便向人类解释。社会科学研究指出，这样的解释应该是对话式的，类似于人与人之间的解释。在这项工作中，我们展示了如何将XAI融入到一个对话代理中，使用了一个包括自然语言理解和生成组件的标准设计。我们根据质控的释义重述扩展了一个XAI问题库，以理解用户的信息需求。我们进一步系统地调查了适合提供答案信息的解释方法的文献，并提出了一个全面的建议列表。我们的工作是实现关于机器学习模型的真正自然对话的第一步，与一个解释代理有关的全面的XAI问题列表和相应的解释方法。

    The goal of Explainable AI (XAI) is to design methods to provide insights into the reasoning process of black-box models, such as deep neural networks, in order to explain them to humans. Social science research states that such explanations should be conversational, similar to human-to-human explanations. In this work, we show how to incorporate XAI in a conversational agent, using a standard design for the agent comprising natural language understanding and generation components. We build upon an XAI question bank which we extend by quality-controlled paraphrases to understand the user's information needs. We further systematically survey the literature for suitable explanation methods that provide the information to answer those questions, and present a comprehensive list of suggestions. Our work is the first step towards truly natural conversations about machine learning models with an explanation agent. The comprehensive list of XAI questions and the corresponding explanation meth
    

