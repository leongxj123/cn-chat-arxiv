# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Debiasing surgeon: fantastic weights and how to find them](https://arxiv.org/abs/2403.14200) | 证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。 |
| [^2] | [Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning](https://arxiv.org/abs/2403.10107) | 通过多个大型预训练语言模型的合作推理，本研究提出了V-HOI Multi-LLMs Collaborated Reasoning（V-HOI MLCR）框架，用于增强当前V-HOI检测模型的性能。 |
| [^3] | [Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery](https://arxiv.org/abs/2403.07955) | 本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化，并通过两种策略缓解利用快捷方式来组成理性化的问题，以及通过数据增强方法来补充已注释理性化数量的差距。 |
| [^4] | [Towards Scene Graph Anticipation](https://arxiv.org/abs/2403.04899) | 提出了场景图预测（SGA）任务，并引入一个新的方法SceneSayer，通过使用神经ODE和神经SDE的概念，结合对象-centric的关系表示，实现对象之间未来关系的预测。 |
| [^5] | [A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing](https://arxiv.org/abs/2403.02504) | 预训练-微调范式在自然语言处理中展现了显著的效率，尤其对社会科学研究中数据有限的情况下具有益处。 |
| [^6] | [Cognitive Bias in High-Stakes Decision-Making with LLMs](https://arxiv.org/abs/2403.00811) | 提出了BiasBuster框架，用于揭示、评估和减轻LLMs中的认知偏见，特别是在高风险决策任务中，通过开发包含16,800个提示的数据集和测试多种偏见缓解策略，并提出一种利用LLMs自身来消除其提示中偏见的新方法。 |
| [^7] | [Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models](https://arxiv.org/abs/2402.15131) | 提出了一种互动式KBQA框架，通过直接与知识库互动生成逻辑形式，开发了用于KB交互的通用API，并设计了示例来指导大型语言模型进行推理。 |
| [^8] | [Learning from Teaching Regularization: Generalizable Correlations Should be Easy to Imitate](https://arxiv.org/abs/2402.02769) | 通过从教学中学习（LoT）技术，我们提出了一种深度神经网络正则化技术，能够通过引入辅助学生模型来提升主模型的泛化性能。实验证明，LoT能有效识别具有泛化和可教授关系的信息。 |
| [^9] | [Transforming and Combining Rewards for Aligning Large Language Models](https://arxiv.org/abs/2402.00742) | 本研究主要研究了对齐大规模语言模型的方法中出现的两个问题：奖励模型的选择以及多个奖励模型的组合。通过引入概率解释，我们提出了一种从Bradley-Terry偏好模型中学习的奖励的自然变换选择，该变换强调改善表现不佳的输出，从而减轻了欠拟合和奖励欺骗。 |
| [^10] | [Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?.](http://arxiv.org/abs/2401.12492) | 本研究比较了以群体属性、个体用户和组合方法来模拟人的上下文。合并群体和个体特征显著提高了用户级回归任务的性能，而模拟个体用户则显著提高了单个文档级分类任务的性能。 |
| [^11] | [Fast Registration of Photorealistic Avatars for VR Facial Animation.](http://arxiv.org/abs/2401.11002) | 本论文针对虚拟现实头像注册和面部动画问题，发现头像和头显相机图像之间的领域差距是主要难点，并提出了一个系统设计来解决这个问题。 |
| [^12] | [Locating Cross-Task Sequence Continuation Circuits in Transformers.](http://arxiv.org/abs/2311.04131) | 通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。 |
| [^13] | [Adversarial Examples in the Physical World: A Survey.](http://arxiv.org/abs/2311.01473) | 本综述系统地研究了物理世界中的对抗样本（PAEs）的特点，并提出了基于其特征的全面分析和分类框架，涵盖了100多个研究，以填补对PAEs独特特征的现有研究不足。 |
| [^14] | [Jailbreaking Black Box Large Language Models in Twenty Queries.](http://arxiv.org/abs/2310.08419) | 这项研究提出了一个名为PAIR的算法，可以在只能黑盒访问大语言模型的情况下生成破解，无需人工干预。实证表明，PAIR通常只需要少于二十个查询来生成破解，是现有算法的数个数量级更高效。 |
| [^15] | [Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection.](http://arxiv.org/abs/2310.00161) | 这项研究提出了一种面向检测的图像-文本预训练方法，旨在弥合图像级预训练和开放词汇目标检测之间的差距。通过检测器架构和对比损失，该方法能够从噪声图像-文本对中学习到新出现的物体-语义线索，并提出了一种平移窗口学习方法来改进主干网络的表示。在LVIS开放词汇检测基准上，该方法取得了显著优于其他方法的40.4的掩码AP$_r$结果。 |
| [^16] | [Discovering environments with XRM.](http://arxiv.org/abs/2309.16748) | 本文提出了一种用于发现环境的算法 XRM，它通过训练两个孪生网络，每个网络从训练数据的一半中学习，并模仿其兄弟网络的错误分类，解决了现有方法需要依赖人工注释环境信息的问题。 |
| [^17] | [Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer.](http://arxiv.org/abs/2309.07566) | 本研究提出了一种基于离散单元的语音到语音翻译框架，通过自监督学习和神经编解码器实现风格转换，解决了数据稀缺和音色保留的问题。实验结果表明，我们的模型在之前未见的语言上实现了高质量的跨语言风格转换。 |
| [^18] | [Geolocation Predicting of Tweets Using BERT-Based Models.](http://arxiv.org/abs/2303.07865) | 该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。 |

# 详细

[^1]: 手术员去偏见：神奇的权重及如何找到它们

    Debiasing surgeon: fantastic weights and how to find them

    [https://arxiv.org/abs/2403.14200](https://arxiv.org/abs/2403.14200)

    证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。

    

    现今一个日益关注的现象是算法偏见的出现，它可能导致不公平的模型。在深度学习领域，已经提出了几种去偏见的方法，采用更或多或少复杂的方法来阻止这些模型大规模地使用这些偏见。然而，一个问题出现了：这种额外的复杂性真的有必要吗？一个普通训练的模型是否已经包含了一些可以独立使用的“无偏子网络”，并且可以提出一个解决方案而不依赖于算法偏见？在这项工作中，我们展示了这样的子网络通常存在，并且可以从一个普通训练的模型中提取出来，而无需额外的训练。我们进一步验证了这种特定的架构无法学习特定的偏见，表明在深度神经网络中有可能通过架构上的对策来解决偏见问题。

    arXiv:2403.14200v1 Announce Type: cross  Abstract: Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic biases that can lead to unfair models, emerges. Several debiasing approaches have been proposed in the realm of deep learning, employing more or less sophisticated approaches to discourage these models from massively employing these biases. However, a question emerges: is this extra complexity really necessary? Is a vanilla-trained model already embodying some ``unbiased sub-networks'' that can be used in isolation and propose a solution without relying on the algorithmic biases? In this work, we show that such a sub-network typically exists, and can be extracted from a vanilla-trained model without requiring additional training. We further validate that such specific architecture is incapable of learning a specific bias, suggesting that there are possible architectural countermeasures to the problem of biases in deep neural networks.
    
[^2]: 通过多个LLM合作推理提升人类中心动态场景理解

    Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning

    [https://arxiv.org/abs/2403.10107](https://arxiv.org/abs/2403.10107)

    通过多个大型预训练语言模型的合作推理，本研究提出了V-HOI Multi-LLMs Collaborated Reasoning（V-HOI MLCR）框架，用于增强当前V-HOI检测模型的性能。

    

    人类中心的动态场景理解在增强机器人和自主系统的能力中起着至关重要的作用，其中视频人-物交互（V-HOI）检测是语义场景理解中的关键任务，旨在全面理解视频中的HOI关系，以使移动机器人和自动驾驶系统的行为决策受益。虽然先前的V-HOI检测模型在特定数据集上取得了显著进展，但它们仍然缺乏像人类一样的通用推理能力，无法有效引导HOI关系。在本研究中，我们提出了V-HOI多LLM协同推理（V-HOI MLCR），这是一个新颖的框架，由一系列即插即用的模块组成，可以通过利用不同现成大型预训练语言模型（LLMs）的强大推理能力，促进当前V-HOI检测模型的性能。

    arXiv:2403.10107v1 Announce Type: cross  Abstract: Human-centered dynamic scene understanding plays a pivotal role in enhancing the capability of robotic and autonomous systems, in which Video-based Human-Object Interaction (V-HOI) detection is a crucial task in semantic scene understanding, aimed at comprehensively understanding HOI relationships within a video to benefit the behavioral decisions of mobile robots and autonomous driving systems. Although previous V-HOI detection models have made significant strides in accurate detection on specific datasets, they still lack the general reasoning ability like human beings to effectively induce HOI relationships. In this study, we propose V-HOI Multi-LLMs Collaborated Reasoning (V-HOI MLCR), a novel framework consisting of a series of plug-and-play modules that could facilitate the performance of current V-HOI detection models by leveraging the strong reasoning ability of different off-the-shelf pre-trained large language models (LLMs). 
    
[^3]: 朝着忠实解释：利用快捷方式发现来增强理性化

    Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery

    [https://arxiv.org/abs/2403.07955](https://arxiv.org/abs/2403.07955)

    本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化，并通过两种策略缓解利用快捷方式来组成理性化的问题，以及通过数据增强方法来补充已注释理性化数量的差距。

    

    人工智能领域神经网络的显著成功引发了有选择性的理性化。本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化。具体而言，SSR首先设计了一种快捷方式发现方法来检测几个潜在的快捷方式。然后，通过引入识别出的快捷方式，我们提出了两种策略来缓解利用快捷方式来组成理性化的问题。最后，我们开发了两种数据增强方法来弥补已注释理性化数量的差距。对真实世界数据集的广泛实验结果清楚地验证了这一方法的有效性。

    arXiv:2403.07955v1 Announce Type: cross  Abstract: The remarkable success in neural networks provokes the selective rationalization. It explains the prediction results by identifying a small subset of the inputs sufficient to support them. Since existing methods still suffer from adopting the shortcuts in data to compose rationales and limited large-scale annotated rationales by human, in this paper, we propose a Shortcuts-fused Selective Rationalization (SSR) method, which boosts the rationalization by discovering and exploiting potential shortcuts. Specifically, SSR first designs a shortcuts discovery approach to detect several potential shortcuts. Then, by introducing the identified shortcuts, we propose two strategies to mitigate the problem of utilizing shortcuts to compose rationales. Finally, we develop two data augmentations methods to close the gap in the number of annotated rationales. Extensive experimental results on real-world datasets clearly validate the effectiveness of
    
[^4]: 朝向场景图预测

    Towards Scene Graph Anticipation

    [https://arxiv.org/abs/2403.04899](https://arxiv.org/abs/2403.04899)

    提出了场景图预测（SGA）任务，并引入一个新的方法SceneSayer，通过使用神经ODE和神经SDE的概念，结合对象-centric的关系表示，实现对象之间未来关系的预测。

    

    时空场景图通过将场景分解为单个对象及其两两时间关系来表示视频中的相互作用。长期预测对象之间精细粒度的两两关系是一个具有挑战性的问题。为此，我们引入了场景图预测（SGA）任务。我们将最先进的场景图生成方法用作基线，以预测对象之间未来的两两关系，并提出了一种新颖的方法SceneSayer。在SceneSayer中，我们利用面向对象的关系表示来推断观察到的视频帧并建模对象之间关系的演变。我们采用连续时间视角，并分别使用神经ODE和神经SDE的概念来建模对象相互作用的潜在动态演变。我们通过解决普通微分方程和随机微分方程来推断未来关系的表示。

    arXiv:2403.04899v1 Announce Type: cross  Abstract: Spatio-temporal scene graphs represent interactions in a video by decomposing scenes into individual objects and their pair-wise temporal relationships. Long-term anticipation of the fine-grained pair-wise relationships between objects is a challenging problem. To this end, we introduce the task of Scene Graph Anticipation (SGA). We adapt state-of-the-art scene graph generation methods as baselines to anticipate future pair-wise relationships between objects and propose a novel approach SceneSayer. In SceneSayer, we leverage object-centric representations of relationships to reason about the observed video frames and model the evolution of relationships between objects. We take a continuous time perspective and model the latent dynamics of the evolution of object interactions using concepts of NeuralODE and NeuralSDE, respectively. We infer representations of future relationships by solving an Ordinary Differential Equation and a Stoch
    
[^5]: 自然语言处理中的预训练-微调范式教程

    A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing

    [https://arxiv.org/abs/2403.02504](https://arxiv.org/abs/2403.02504)

    预训练-微调范式在自然语言处理中展现了显著的效率，尤其对社会科学研究中数据有限的情况下具有益处。

    

    预训练-微调范式代表了自然语言处理中的一种变革性方法。该范式通过使用大型预训练语言模型区别于众，展示了在微调任务中即使训练数据有限也具有显著的效率。这种效率对社会科学研究特别有益，因为注释样本的数量通常非常有限。我们的教程全面介绍了预训练-微调范式。我们首先深入探讨了预训练和微调的基本概念，然后进行了实际应用的案例练习。我们展示了该范式在各种任务中的应用，包括多类别分类和回归。强调其高效性和用户友好性，该教程旨在鼓励更广泛地采纳这种范式。为此，我们提供了所有代码和数据集的开放访问。

    arXiv:2403.02504v1 Announce Type: cross  Abstract: The pretrain-finetune paradigm represents a transformative approach in natural language processing (NLP). This paradigm distinguishes itself through the use of large pretrained language models, demonstrating remarkable efficiency in finetuning tasks, even with limited training data. This efficiency is especially beneficial for research in social sciences, where the number of annotated samples is often quite limited. Our tutorial offers a comprehensive introduction to the pretrain-finetune paradigm. We first delve into the fundamental concepts of pretraining and finetuning, followed by practical exercises using real-world applications. We demonstrate the application of the paradigm across various tasks, including multi-class classification and regression. Emphasizing its efficacy and user-friendliness, the tutorial aims to encourage broader adoption of this paradigm. To this end, we have provided open access to all our code and datasets
    
[^6]: LLM在高风险决策中的认知偏见

    Cognitive Bias in High-Stakes Decision-Making with LLMs

    [https://arxiv.org/abs/2403.00811](https://arxiv.org/abs/2403.00811)

    提出了BiasBuster框架，用于揭示、评估和减轻LLMs中的认知偏见，特别是在高风险决策任务中，通过开发包含16,800个提示的数据集和测试多种偏见缓解策略，并提出一种利用LLMs自身来消除其提示中偏见的新方法。

    

    大型语言模型(LLMs)在支持日益扩大的决策任务方面具有重要潜力。然而，由于它们在人类(创造的)数据上训练，LLMs可能会继承针对受保护群体的社会偏见，同时也可能受到认知偏见的影响。这种类似于人类的偏见可能会妨碍利用LLM协助做出公平和可解释的决策。我们的工作引入了BiasBuster，一个旨在揭示、评估和减轻LLMs中的认知偏见的框架，特别是在高风险决策任务中。受心理学和认知科学先前研究的启发，我们开发了一个包含16,800个提示的数据集，用于评估不同认知偏见(例如，提示诱导、顺序、固有)。我们测试了各种偏见缓解策略，同时提出了一种新方法，利用LLMs来消除它们自己的提示中的偏见。我们的分析提供了关于不同领域认知偏见存在和影响的全面图景。

    arXiv:2403.00811v1 Announce Type: new  Abstract: Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across diffe
    
[^7]: 互动式知识库问答：基于大型语言模型的多轮交互式知识库问答

    Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models

    [https://arxiv.org/abs/2402.15131](https://arxiv.org/abs/2402.15131)

    提出了一种互动式KBQA框架，通过直接与知识库互动生成逻辑形式，开发了用于KB交互的通用API，并设计了示例来指导大型语言模型进行推理。

    

    本研究探讨了知识库问答（KBQA）的领域。KBQA被认为是一项具有挑战性的任务，特别是在将复杂问题解析为可执行逻辑形式方面。传统的基于语义解析（SP）的方法需要大量的数据注释，这导致了显著的成本。最近，由大型语言模型（LLM）推动的少样本上下文学习的出现展示了很好的能力。然而，在低资源情景下充分利用LLMs将问题解析为逻辑形式是一个重大挑战。为了应对这些障碍，我们引入了互动式知识库问答（Interactive-KBQA），这是一个旨在通过与知识库（KBs）直接互动来生成逻辑形式的框架。在这个框架内，我们开发了三个用于KB交互的通用API。对于每种复杂问题类别，我们设计了示例来指导LLMs完成推理过程。我们的方法取得了具有竞争力的结果。

    arXiv:2402.15131v1 Announce Type: cross  Abstract: This study explores the realm of knowledge-base question answering (KBQA). KBQA is considered a challenging task, particularly in parsing intricate questions into executable logical forms. Traditional semantic parsing (SP)-based methods require extensive data annotations, which result in significant costs. Recently, the advent of few-shot in-context learning, powered by large language models (LLMs), has showcased promising capabilities. Yet, fully leveraging LLMs to parse questions into logical forms in low-resource scenarios poses a substantial challenge. To tackle these hurdles, we introduce Interactive-KBQA, a framework designed to generate logical forms through direct interaction with knowledge bases (KBs). Within this framework, we have developed three generic APIs for KB interaction. For each category of complex question, we devised exemplars to guide LLMs through the reasoning processes. Our method achieves competitive results o
    
[^8]: 从教学中学习正则化: 易于模仿的可推广关系

    Learning from Teaching Regularization: Generalizable Correlations Should be Easy to Imitate

    [https://arxiv.org/abs/2402.02769](https://arxiv.org/abs/2402.02769)

    通过从教学中学习（LoT）技术，我们提出了一种深度神经网络正则化技术，能够通过引入辅助学生模型来提升主模型的泛化性能。实验证明，LoT能有效识别具有泛化和可教授关系的信息。

    

    泛化仍然是机器学习中的一个核心挑战。在这项工作中，我们提出了一种新颖的深度神经网络正则化技术，即从教学中学习（Learning from Teaching，简称LoT），以增强泛化性能。受到人类捕捉简明抽象模式的能力的启发，我们假设可推广的关系更容易教授。LoT通过辅助学生模型来实现这个概念，通过提供反馈来训练主模型和改进主模型，以捕捉更多具有泛化和可教授关系的信息。我们在计算机视觉、自然语言处理和强化学习等多个领域进行的实验结果表明，引入LoT相比仅在原始训练数据上训练模型带来了显著的好处。这表明了LoT在识别可推广信息方面的有效性。

    Generalization remains a central challenge in machine learning. In this work, we propose Learning from Teaching (LoT), a novel regularization technique for deep neural networks to enhance generalization. Inspired by the human ability to capture concise and abstract patterns, we hypothesize that generalizable correlations are expected to be easier to teach. LoT operationalizes this concept to improve the generalization of the main model with auxiliary student learners. The student learners are trained by the main model and improve the main model to capture more generalizable and teachable correlations by providing feedback. Our experimental results across several domains, including Computer Vision, Natural Language Processing, and Reinforcement Learning, demonstrate that the introduction of LoT brings significant benefits compared to merely training models on the original training data. It suggests the effectiveness of LoT in identifying generalizable information without falling into th
    
[^9]: 改变和组合奖励以对齐大规模语言模型

    Transforming and Combining Rewards for Aligning Large Language Models

    [https://arxiv.org/abs/2402.00742](https://arxiv.org/abs/2402.00742)

    本研究主要研究了对齐大规模语言模型的方法中出现的两个问题：奖励模型的选择以及多个奖励模型的组合。通过引入概率解释，我们提出了一种从Bradley-Terry偏好模型中学习的奖励的自然变换选择，该变换强调改善表现不佳的输出，从而减轻了欠拟合和奖励欺骗。

    

    将语言模型与人类偏好对齐的常见方法是首先从偏好数据中学习奖励模型，然后使用该奖励模型来更新语言模型。我们研究了这种方法中出现的两个密切相关的问题。首先，奖励模型的任何单调变换都保持偏好排名；是否有一种比其他选择“更好”的选择？其次，我们经常希望将语言模型与多个特性对齐：我们如何组合多个奖励模型？通过对齐过程的概率解释，我们确定了从Bradley-Terry偏好模型学习的奖励（常见情况）的自然变换选择。这个派生的变换具有两个重要的属性。首先，它强调改进表现不佳的输出，而不是已经得分良好的输出。这既减轻了欠拟合（其中一些提示没有得到改进），又减少了奖励欺骗（模型学习利用错误指定）。

    A common approach for aligning language models to human preferences is to first learn a reward model from preference data, and then use this reward model to update the language model. We study two closely related problems that arise in this approach. First, any monotone transformation of the reward model preserves preference ranking; is there a choice that is ``better'' than others? Second, we often wish to align language models to multiple properties: how should we combine multiple reward models? Using a probabilistic interpretation of the alignment procedure, we identify a natural choice for transformation for (the common case of) rewards learned from Bradley-Terry preference models. This derived transformation has two important properties. First, it emphasizes improving poorly-performing outputs, rather than outputs that already score well. This mitigates both underfitting (where some prompts are not improved) and reward hacking (where the model learns to exploit misspecification of
    
[^10]: 比较以人为中心的语言建模：模拟群体、个体特点还是两者兼顾？

    Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?. (arXiv:2401.12492v1 [cs.CL])

    [http://arxiv.org/abs/2401.12492](http://arxiv.org/abs/2401.12492)

    本研究比较了以群体属性、个体用户和组合方法来模拟人的上下文。合并群体和个体特征显著提高了用户级回归任务的性能，而模拟个体用户则显著提高了单个文档级分类任务的性能。

    

    自然语言处理在将人的上下文纳入其模型中取得了进展，但使用群体属性（如45岁以上的人群）还是模拟个体人物更有效的问题尚未确定。群体属性在技术上更容易实现，但是过于粗糙：并非所有45岁以上的人都以相同的方式书写。相反，模拟个体人物能够捕捉每个人身份的复杂性，允许更个性化的表示，但我们可能需要模拟无限数量的用户并且需要可能无法获取的数据。我们比较了通过群体属性、个体用户和组合方法来模拟人的上下文。将群体和个体特征结合起来，显著提高了基于用户文档的用户级回归任务（如年龄估计或个性评估）的性能。模拟个体用户显著提高了单个文档级分类任务（如立场和主题检测）的性能。

    Natural language processing has made progress in incorporating human context into its models, but whether it is more effective to use group-wise attributes (e.g., over-45-year-olds) or model individuals remains open. Group attributes are technically easier but coarse: not all 45-year-olds write the same way. In contrast, modeling individuals captures the complexity of each person's identity. It allows for a more personalized representation, but we may have to model an infinite number of users and require data that may be impossible to get. We compare modeling human context via group attributes, individual users, and combined approaches. Combining group and individual features significantly benefits user-level regression tasks like age estimation or personality assessment from a user's documents. Modeling individual users significantly improves the performance of single document-level classification tasks like stance and topic detection. We also find that individual-user modeling does w
    
[^11]: 快速注册逼真的虚拟现实头像用于面部动画

    Fast Registration of Photorealistic Avatars for VR Facial Animation. (arXiv:2401.11002v1 [cs.CV])

    [http://arxiv.org/abs/2401.11002](http://arxiv.org/abs/2401.11002)

    本论文针对虚拟现实头像注册和面部动画问题，发现头像和头显相机图像之间的领域差距是主要难点，并提出了一个系统设计来解决这个问题。

    

    虚拟现实（VR）在社交互动方面拥有更具沉浸感的潜力。其中一个关键是能够在佩戴VR头显的情况下准确地模拟一个逼真的头像。虽然在离线环境中可以实现对特定个人头像进行高质量注册，并进行动画生成，但通用实时模型的性能明显下降。在线注册也面临诸多挑战，包括倾斜的摄像机视角和不同的模态。在这项工作中，我们首先表明头像与头显相机图像之间的领域差距是困难的主要源泉之一，基于转换器的架构在领域一致的数据上实现了高准确性，在引入领域差距后性能下降。基于此发现，我们提出了一个系统设计，将问题分解为两个部分：1）一个迭代细化模块，接收领域内输入，和2）一个通用的头像引导图像生成模块

    Virtual Reality (VR) bares promise of social interactions that can feel more immersive than other media. Key to this is the ability to accurately animate a photorealistic avatar of one's likeness while wearing a VR headset. Although high quality registration of person-specific avatars to headset-mounted camera (HMC) images is possible in an offline setting, the performance of generic realtime models are significantly degraded. Online registration is also challenging due to oblique camera views and differences in modality. In this work, we first show that the domain gap between the avatar and headset-camera images is one of the primary sources of difficulty, where a transformer-based architecture achieves high accuracy on domain-consistent data, but degrades when the domain-gap is re-introduced. Building on this finding, we develop a system design that decouples the problem into two parts: 1) an iterative refinement module that takes in-domain inputs, and 2) a generic avatar-guided imag
    
[^12]: 在Transformer中定位跨任务序列继续电路

    Locating Cross-Task Sequence Continuation Circuits in Transformers. (arXiv:2311.04131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04131](http://arxiv.org/abs/2311.04131)

    通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。

    

    虽然Transformer模型在语言任务上展现出强大的能力，但其复杂的架构使其难以解释。最近的研究旨在将Transformer模型还原为可读的电路表示，用于实现算法功能。我们通过分析和比较类似的序列继续任务的电路来扩展这项研究，其中包括数字、数字词和月份的递增序列。通过应用电路分析技术，我们确定了负责检测序列成员和预测序列中下一个成员的关键子电路。我们的分析揭示了语义相关序列依赖于具有类似作用的共享电路子图。总体而言，记录共享的计算结构能够更好地预测模型行为，识别错误，并进行更安全的编辑过程。这种对Transformer的机械理解是构建更健壮、调试和编辑更安全的模型的关键一步。

    While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust,
    
[^13]: 物理世界中的对抗样本：一项综述

    Adversarial Examples in the Physical World: A Survey. (arXiv:2311.01473v1 [cs.CV])

    [http://arxiv.org/abs/2311.01473](http://arxiv.org/abs/2311.01473)

    本综述系统地研究了物理世界中的对抗样本（PAEs）的特点，并提出了基于其特征的全面分析和分类框架，涵盖了100多个研究，以填补对PAEs独特特征的现有研究不足。

    

    深度神经网络（DNNs）对对抗样本表现出高度的脆弱性。除了在数字世界中的攻击外，对抗样本在物理世界中的实际影响提出了重大挑战和安全性问题。然而，当前对物理对抗样本（PAEs）的研究缺乏对其独特特征的全面理解，导致其重要性和理解的局限性。本文通过在训练、制造和重采样过程中全面考察PAEs的特点来弥补这一差距。通过分析物理对抗攻击之间的联系，我们确定制造和重采样是PAEs中独特属性和特殊性的主要来源。利用这一知识，我们基于其特定特征开发了一个全面的PAEs分析和分类框架，涵盖了100多个物理对抗世界研究的研究。

    Deep neural networks (DNNs) have demonstrated high vulnerability to adversarial examples. Besides the attacks in the digital world, the practical implications of adversarial examples in the physical world present significant challenges and safety concerns. However, current research on physical adversarial examples (PAEs) lacks a comprehensive understanding of their unique characteristics, leading to limited significance and understanding. In this paper, we address this gap by thoroughly examining the characteristics of PAEs within a practical workflow encompassing training, manufacturing, and re-sampling processes. By analyzing the links between physical adversarial attacks, we identify manufacturing and re-sampling as the primary sources of distinct attributes and particularities in PAEs. Leveraging this knowledge, we develop a comprehensive analysis and classification framework for PAEs based on their specific characteristics, covering over 100 studies on physical-world adversarial e
    
[^14]: 在二十个查询中破解黑盒大语言模型

    Jailbreaking Black Box Large Language Models in Twenty Queries. (arXiv:2310.08419v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.08419](http://arxiv.org/abs/2310.08419)

    这项研究提出了一个名为PAIR的算法，可以在只能黑盒访问大语言模型的情况下生成破解，无需人工干预。实证表明，PAIR通常只需要少于二十个查询来生成破解，是现有算法的数个数量级更高效。

    

    大语言模型（LLMs）与人类价值的一致性越来越受关注。然而，这类模型的一致性容易受到对抗性破解的影响，从而迫使LLMs超越其安全防护措施。因此，识别这些漏洞对于理解固有弱点并防止未来的不当使用至关重要。为此，我们提出了Prompt Automatic Iterative Refinement（PAIR），这是一种仅通过对LLM进行黑盒访问的算法生成语义破解。PAIR受到社会工程攻击的启发，使用攻击者LLM自动生成针对目标LLM的破解，无需人工干预。攻击者LLM通过迭代查询目标LLM来更新和改进候选破解。在实证上，PAIR通常只需要少于二十个查询来生成破解，这比现有算法高效数个数量级。PAIR还实现了有竞争力的破解效果。

    There is growing interest in ensuring that large language models (LLMs) align with human values. However, the alignment of such models is vulnerable to adversarial jailbreaks, which coax LLMs into overriding their safety guardrails. The identification of these vulnerabilities is therefore instrumental in understanding inherent weaknesses and preventing future misuse. To this end, we propose Prompt Automatic Iterative Refinement (PAIR), an algorithm that generates semantic jailbreaks with only black-box access to an LLM. PAIR -- which is inspired by social engineering attacks -- uses an attacker LLM to automatically generate jailbreaks for a separate targeted LLM without human intervention. In this way, the attacker LLM iteratively queries the target LLM to update and refine a candidate jailbreak. Empirically, PAIR often requires fewer than twenty queries to produce a jailbreak, which is orders of magnitude more efficient than existing algorithms. PAIR also achieves competitive jailbrea
    
[^15]: 面向检测的图像-文本预训练方法用于开放词汇检测

    Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection. (arXiv:2310.00161v1 [cs.CV])

    [http://arxiv.org/abs/2310.00161](http://arxiv.org/abs/2310.00161)

    这项研究提出了一种面向检测的图像-文本预训练方法，旨在弥合图像级预训练和开放词汇目标检测之间的差距。通过检测器架构和对比损失，该方法能够从噪声图像-文本对中学习到新出现的物体-语义线索，并提出了一种平移窗口学习方法来改进主干网络的表示。在LVIS开放词汇检测基准上，该方法取得了显著优于其他方法的40.4的掩码AP$_r$结果。

    

    我们提出了一种基于面向检测的图像-文本预训练的新的开放词汇检测方法，以填补图像级预训练和开放词汇目标检测之间的差距。在预训练阶段，我们用检测器架构替代常用的分类架构，通过使检测器头部能够从噪声图像-文本对中学习，更好地满足检测的区域级识别需求。我们的方法只使用标准的对比损失而不使用伪标签，是对对比学习方法的简单而有效的扩展，可以学习到新出现的物体-语义线索。此外，我们提出了一种基于窗口注意力的平移窗口学习方法，使主干网络的表示更加鲁棒、平移不变，并且不受窗口模式的偏差影响。在流行的LVIS开放词汇检测基准上，我们的方法使用常见的ViT-L主干网络取得了40.4的掩码AP$_r$新的最优结果，明显优于其他方法。

    We present a new open-vocabulary detection approach based on detection-oriented image-text pretraining to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we replace the commonly used classification architecture with the detector architecture, which better serves the region-level recognition needs of detection by enabling the detector heads to learn from noisy image-text pairs. Using only standard contrastive loss and no pseudo-labeling, our approach is a simple yet effective extension of the contrastive learning method to learn emergent object-semantic cues. In addition, we propose a shifted-window learning approach upon window attention to make the backbone representation more robust, translation-invariant, and less biased by the window pattern. On the popular LVIS open-vocabulary detection benchmark, our approach sets a new state of the art of 40.4 mask AP$_r$ using the common ViT-L backbone, significantly outperforming t
    
[^16]: 用XRM发现环境

    Discovering environments with XRM. (arXiv:2309.16748v1 [cs.LG])

    [http://arxiv.org/abs/2309.16748](http://arxiv.org/abs/2309.16748)

    本文提出了一种用于发现环境的算法 XRM，它通过训练两个孪生网络，每个网络从训练数据的一半中学习，并模仿其兄弟网络的错误分类，解决了现有方法需要依赖人工注释环境信息的问题。

    

    成功的跨领域泛化需要环境注释。然而，这些注释的获取是资源密集型的，并且它们对模型性能的影响受人类注释者的期望和感知偏差的限制。因此，为了实现应用领域全面泛化的鲁棒性AI系统，我们必须开发一种算法来自动发现引发广泛泛化的环境。目前的提案根据训练误差将示例划分为不同的类，但存在一个根本问题。这些方法添加了超参数和早停策略，而这些参数是无法在没有人类注释环境的验证集的情况下进行调整的，而这些信息正是要发现的信息。在本文中，我们提出了 Cross-Risk-Minimization (XRM) 来解决这个问题。XRM 训练两个孪生网络，每个网络从训练数据的一个随机一半中学习，同时模仿其兄弟网络所做的自信的错误分类。XRM 提供了超参数调整的方法，并且不需要依赖人工注释的环境信息。

    Successful out-of-distribution generalization requires environment annotations. Unfortunately, these are resource-intensive to obtain, and their relevance to model performance is limited by the expectations and perceptual biases of human annotators. Therefore, to enable robust AI systems across applications, we must develop algorithms to automatically discover environments inducing broad generalization. Current proposals, which divide examples based on their training error, suffer from one fundamental problem. These methods add hyper-parameters and early-stopping criteria that are impossible to tune without a validation set with human-annotated environments, the very information subject to discovery. In this paper, we propose Cross-Risk-Minimization (XRM) to address this issue. XRM trains two twin networks, each learning from one random half of the training data, while imitating confident held-out mistakes made by its sibling. XRM provides a recipe for hyper-parameter tuning, does not 
    
[^17]: 基于离散单元的风格转换的语音到语音翻译

    Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer. (arXiv:2309.07566v1 [cs.SD])

    [http://arxiv.org/abs/2309.07566](http://arxiv.org/abs/2309.07566)

    本研究提出了一种基于离散单元的语音到语音翻译框架，通过自监督学习和神经编解码器实现风格转换，解决了数据稀缺和音色保留的问题。实验结果表明，我们的模型在之前未见的语言上实现了高质量的跨语言风格转换。

    

    直接的语音到语音翻译（S2ST）通过离散的自监督表示实现了显著的准确性，但在翻译过程中无法保留源语音的说话人音色。与此同时，高质量说话人平行数据的稀缺性对于学习源语音和目标语音之间的风格转换构成了挑战。我们提出了一个基于自监督模型的离散单元的声学语言模型和风格转换的神经编解码器的S2ST框架。声学语言模型通过自监督上下文学习获得了风格转换的能力，无需依赖于任何说话人平行数据，从而克服了数据稀缺性问题。通过使用大量的训练数据，我们的模型可以在之前未见过的源语言上实现零-shot跨语言风格转换。实验证明，我们的模型生成的翻译语音具有高度的保真度和风格相似性。

    Direct speech-to-speech translation (S2ST) with discrete self-supervised representations has achieved remarkable accuracy, but is unable to preserve the speaker timbre of the source speech during translation. Meanwhile, the scarcity of high-quality speaker-parallel data poses a challenge for learning style transfer between source and target speech. We propose an S2ST framework with an acoustic language model based on discrete units from a self-supervised model and a neural codec for style transfer. The acoustic language model leverages self-supervised in-context learning, acquiring the ability for style transfer without relying on any speaker-parallel data, thereby overcoming the issue of data scarcity. By using extensive training data, our model achieves zero-shot cross-lingual style transfer on previously unseen source languages. Experiments show that our model generates translated speeches with high fidelity and style similarity. Audio samples are available at this http URL .
    
[^18]: 基于BERT模型的推文地理位置预测

    Geolocation Predicting of Tweets Using BERT-Based Models. (arXiv:2303.07865v1 [cs.CL])

    [http://arxiv.org/abs/2303.07865](http://arxiv.org/abs/2303.07865)

    该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。

    

    该研究旨在解决推文/用户地理位置预测任务，并提供了处理文本大数据地理标记的灵活方法。该方法采用基于神经网络的自然语言处理来估计坐标对（经度，纬度）和二维高斯混合模型（GMM）。提出的模型的范围已经在Twitter数据集上使用预训练的BERT模型进行调整。性能指标表明，对于在推文内容和元数据上训练和评估的模型，全球范围内的中位误差小于30公里，美国范围内的中位误差小于15公里。

    This research is aimed to solve the tweet/user geolocation prediction task and provide a flexible methodology for the geotagging of textual big data. The suggested approach implements neural networks for natural language processing (NLP) to estimate the location as coordinate pairs (longitude, latitude) and two-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models has been finetuned on a Twitter dataset using pretrained Bidirectional Encoder Representations from Transformers (BERT) as base models. Performance metrics show a median error of fewer than 30 km on a worldwide-level, and fewer than 15 km on the US-level datasets for the models trained and evaluated on text features of tweets' content and metadata context.
    

