# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Recent Advances in Predictive Modeling with Electronic Health Records](https://rss.arxiv.org/abs/2402.01077) | 这项调查总结了基于电子健康记录数据的深度学习预测模型的最新进展，包括背景介绍、数学定义、分类总结、基准和工具包，以及未来研究方向的讨论。 |
| [^2] | [Generative AI for Immersive Communication: The Next Frontier in Internet-of-Senses Through 6G](https://arxiv.org/abs/2404.01713) | 本文探讨了生成式人工智能用于沉浸式通信中减少带宽消耗的实用价值。 |
| [^3] | [Source-Aware Training Enables Knowledge Attribution in Language Models](https://arxiv.org/abs/2404.01019) | 源感知训练使语言模型具备知识归因能力，进而增强了其透明度、可解释性和可验证性。 |
| [^4] | [SSHPool: The Separated Subgraph-based Hierarchical Pooling](https://arxiv.org/abs/2403.16133) | 提出了基于分隔子图的分层池化（SSHPool）方法，通过将节点分配到不同的簇并利用局部图卷积单元进行压缩，解决了现有图神经网络中的过度平滑问题，有效提取了原始图结构的分层全局特征。 |
| [^5] | [AKBR: Learning Adaptive Kernel-based Representations for Graph Classification](https://arxiv.org/abs/2403.16130) | 提出了一种用于图分类的自适应核表示学习模型，通过特征通道注意机制捕捉不同子结构之间的相互依赖关系，有效识别结构重要性，并计算与重要子结构相关的图对之间的R-卷积核。 |
| [^6] | [Large Language Model for Mental Health: A Systematic Review](https://arxiv.org/abs/2403.15401) | 该论文系统评价了大型语言模型在心理健康领域的应用，讨论了其在早期筛查、数字干预和其他临床应用中的挑战和机遇。 |
| [^7] | [Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting](https://arxiv.org/abs/2403.13369) | 使用预训练语言模型和提示技术，在少资源语言情境下，仅需少量样本训练即可提取临床信息，且表现优于传统方法。 |
| [^8] | [AI-enhanced Collective Intelligence: The State of the Art and Prospects](https://arxiv.org/abs/2403.10433) | 人类和人工智能形成的多层次集体智能网络，可以实现超越任一单独实体的集体智能水平。 |
| [^9] | [RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion](https://arxiv.org/abs/2403.06095) | RepoHyper提出了Repo级语义图（RSG）和Expand和Refine检索方法，显著优于现有技术，满足仓库级代码补全的需求 |
| [^10] | [Artificial Intelligence Exploring the Patent Field](https://arxiv.org/abs/2403.04105) | 本文系统概述了专利领域的任务和方法，强调了语言处理和大型语言模型的重要性，并探讨了近期出现的通用生成方法在专利领域的潜力。 |
| [^11] | [Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic](https://arxiv.org/abs/2402.14798) | 本文提出了一种一致且在理论上有根据的方法来注释分解蕴涵数据集，形成RDTE数据集，该数据集在解决何为有效的组合蕴涵的问题上有显著进展。 |
| [^12] | [Maintaining Adversarial Robustness in Continuous Learning](https://arxiv.org/abs/2402.11196) | 提出了一种名为双梯度投影的方法，通过将梯度投影到两个关键子空间来实现持续鲁棒学习，有效地维持了神经网络对抗性鲁棒性。 |
| [^13] | [Continual Driving Policy Optimization with Closed-Loop Individualized Curricula](https://arxiv.org/abs/2309.14209) | 开发了连续驾驶政策优化框架，提出了闭环个性化课程（CLIC）概念，允许重复利用广泛场景来迭代改进自主驾驶车辆模型。 |
| [^14] | [Truck Parking Usage Prediction with Decomposed Graph Neural Networks.](http://arxiv.org/abs/2401.12920) | 提出了Regional Temporal Graph Neural Network (RegT-GCN)作为一个预测框架，用于评估整个州的卡车停车使用情况，以提供更准确的停车信息并缓解未经授权的停车问题。 |
| [^15] | [The Distributional Uncertainty of the SHAP score in Explainable Machine Learning.](http://arxiv.org/abs/2401.12731) | 本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。 |
| [^16] | [Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of Text-To-Image Models.](http://arxiv.org/abs/2310.01929) | 本研究旨在探索和解锁文本到图像模型的文化视角，通过对TTI模型中嵌入的文化感知进行评估，揭示了这些模型的文化意识、文化区别和文化适应性。 |
| [^17] | [Interpretable Graph Neural Networks for Tabular Data.](http://arxiv.org/abs/2308.08945) | 本论文提出了一种称为IGNNet的方法，可以在处理表格数据时使用图神经网络，该方法能够产生可解释的模型，从原始输入特征精确计算预测结果，并且在性能上与最先进的机器学习算法性能相当。 |
| [^18] | [Neural Quantile Optimization for Edge-Cloud Computing.](http://arxiv.org/abs/2307.05170) | 这项研究提出了一种神经分位数优化的方法，用于边缘云计算网络中找到最佳的流量分配方案。通过引入Gumbel-softmax采样网络，可以有效地解决优化问题并显著优于随机策略。 |

# 详细

[^1]: 电子健康记录预测建模的最新进展

    Recent Advances in Predictive Modeling with Electronic Health Records

    [https://rss.arxiv.org/abs/2402.01077](https://rss.arxiv.org/abs/2402.01077)

    这项调查总结了基于电子健康记录数据的深度学习预测模型的最新进展，包括背景介绍、数学定义、分类总结、基准和工具包，以及未来研究方向的讨论。

    

    电子健康记录（EHR）系统的发展使得大量的数字化患者数据得以收集。然而，由于其独特的特性，利用EHR数据进行预测建模面临着一些挑战。随着机器学习技术的进步，深度学习在包括医疗在内的各个领域展现出了卓越的优势。本调查系统地回顾了基于EHR数据的深度学习预测模型的最新进展。具体而言，我们首先介绍了EHR数据的背景，并提供了预测建模任务的数学定义。然后，我们从多个角度对预测深度模型进行分类和总结。此外，我们还介绍了与医疗预测建模相关的基准和工具包。最后，我们讨论了开放性挑战，并提出了未来研究的有希望的方向。

    The development of electronic health records (EHR) systems has enabled the collection of a vast amount of digitized patient data. However, utilizing EHR data for predictive modeling presents several challenges due to its unique characteristics. With the advancements in machine learning techniques, deep learning has demonstrated its superiority in various applications, including healthcare. This survey systematically reviews recent advances in deep learning-based predictive models using EHR data. Specifically, we begin by introducing the background of EHR data and providing a mathematical definition of the predictive modeling task. We then categorize and summarize predictive deep models from multiple perspectives. Furthermore, we present benchmarks and toolkits relevant to predictive modeling in healthcare. Finally, we conclude this survey by discussing open challenges and suggesting promising directions for future research.
    
[^2]: 生成式人工智能用于沉浸式通信：通过6G探索感知互联网的下一个领域

    Generative AI for Immersive Communication: The Next Frontier in Internet-of-Senses Through 6G

    [https://arxiv.org/abs/2404.01713](https://arxiv.org/abs/2404.01713)

    本文探讨了生成式人工智能用于沉浸式通信中减少带宽消耗的实用价值。

    

    在过去的二十年中，物联网(IoT)已经是一个具有变革性的概念，当我们逼近2030年时，一个新的范式被称为感知互联网(IoS)正在兴起。与传统的虚拟现实（VR）不同，IoS旨在提供多感官体验，认识到在我们的现实世界中，我们的感知远不止于视觉和听觉；它涵盖了一系列感觉。本文探讨了推动沉浸式多感官媒体的现有技术，深入探讨它们的功能和潜在应用。这项探索包括传统沉浸式媒体流与一个提出的利用生成式人工智能增强语义交流的用例之间的比较分析。这项分析的重点是所提方案中带宽消耗减少了99.93%。通过这种比较，我们旨在强调该实用应用的价值。

    arXiv:2404.01713v1 Announce Type: cross  Abstract: Over the past two decades, the Internet-of-Things (IoT) has been a transformative concept, and as we approach 2030, a new paradigm known as the Internet of Senses (IoS) is emerging. Unlike conventional Virtual Reality (VR), IoS seeks to provide multi-sensory experiences, acknowledging that in our physical reality, our perception extends far beyond just sight and sound; it encompasses a range of senses. This article explores existing technologies driving immersive multi-sensory media, delving into their capabilities and potential applications. This exploration includes a comparative analysis between conventional immersive media streaming and a proposed use case that lever- ages semantic communication empowered by generative Artificial Intelligence (AI). The focal point of this analysis is the substantial reduction in bandwidth consumption by 99.93% in the proposed scheme. Through this comparison, we aim to underscore the practical appli
    
[^3]: 源感知训练使语言模型具备知识归因能力

    Source-Aware Training Enables Knowledge Attribution in Language Models

    [https://arxiv.org/abs/2404.01019](https://arxiv.org/abs/2404.01019)

    源感知训练使语言模型具备知识归因能力，进而增强了其透明度、可解释性和可验证性。

    

    大型语言模型（LLMs）在预训练期间学到了大量知识，但往往对此类知识的来源毫不在意。本文研究了内在源引用问题，要求LLMs引用支持生成响应的预训练来源。内在源引用可以增强LLMs的透明度、可解释性和可验证性。为赋予LLMs这种能力，我们探索了源感知训练——一个后预训练配方，包括（i）训练LLMs将唯一源文档标识符与每个文档中的知识关联起来，然后（ii）进行指示调整，教导LLMs在被提示时引用支持的预训练来源。源感知训练可以轻松应用于即插即用的预训练LLMs，并与现有的预训练/微调框架的差异最小。通过对精心策划的数据进行实验，我们展示了我们的训练配方可以实现

    arXiv:2404.01019v1 Announce Type: cross  Abstract: Large language models (LLMs) learn a vast amount of knowledge during pretraining, but they are often oblivious to the source(s) of such knowledge. We investigate the problem of intrinsic source citation, where LLMs are required to cite the pretraining source supporting a generated response. Intrinsic source citation can enhance LLM transparency, interpretability, and verifiability. To give LLMs such ability, we explore source-aware training -- a post pretraining recipe that involves (i) training the LLM to associate unique source document identifiers with the knowledge in each document, followed by (ii) an instruction-tuning to teach the LLM to cite a supporting pretraining source when prompted. Source-aware training can easily be applied to pretrained LLMs off the shelf, and diverges minimally from existing pretraining/fine-tuning frameworks. Through experiments on carefully curated data, we demonstrate that our training recipe can en
    
[^4]: 基于分隔子图的分层池化SSHPool

    SSHPool: The Separated Subgraph-based Hierarchical Pooling

    [https://arxiv.org/abs/2403.16133](https://arxiv.org/abs/2403.16133)

    提出了基于分隔子图的分层池化（SSHPool）方法，通过将节点分配到不同的簇并利用局部图卷积单元进行压缩，解决了现有图神经网络中的过度平滑问题，有效提取了原始图结构的分层全局特征。

    

    在本文中，我们提出了一种新颖的本地图池化方法，称为基于分隔子图的分层池化（SSHPool），用于图分类。通过将一个样本图的节点分配到不同的簇中，从而产生一系列分隔的子图。我们分别使用本地图卷积单元作为局部结构，进一步将每个子图压缩成一个粗糙节点，将原始图转化为粗糙图。由于这些子图由不同的簇分隔开，结构信息无法在它们之间传播，局部卷积操作可以显著避免大多数现有图神经网络（GNNs）中出现的过度平滑问题。通过在结果粗糙图上层次地执行所提议的程序，SSHPool可以有效地提取原始图结构的分层全局特征。

    arXiv:2403.16133v1 Announce Type: new  Abstract: In this paper, we develop a novel local graph pooling method, namely the Separated Subgraph-based Hierarchical Pooling (SSHPool), for graph classification. To this end, we commence by assigning the nodes of a sample graph into different clusters, resulting in a family of separated subgraphs. We individually employ a local graph convolution units as the local structure to further compress each subgraph into a coarsened node, transforming the original graph into a coarsened graph. Since these subgraphs are separated by different clusters and the structural information cannot be propagated between them, the local convolution operation can significantly avoid the over-smoothing problem arising in most existing Graph Neural Networks (GNNs). By hierarchically performing the proposed procedures on the resulting coarsened graph, the proposed SSHPool can effectively extract the hierarchical global feature of the original graph structure, encapsul
    
[^5]: AKBR: 学习自适应基于核的图分类表示

    AKBR: Learning Adaptive Kernel-based Representations for Graph Classification

    [https://arxiv.org/abs/2403.16130](https://arxiv.org/abs/2403.16130)

    提出了一种用于图分类的自适应核表示学习模型，通过特征通道注意机制捕捉不同子结构之间的相互依赖关系，有效识别结构重要性，并计算与重要子结构相关的图对之间的R-卷积核。

    

    在本文中，我们提出了一种新模型，用于学习自适应基于核的图分类表示（AKBR）。与仅通过计算图之间同构子结构对的数量来定义的最先进的 R-卷积图核不同，无法为分类器提供端到端学习机制，所提出的AKBR方法旨在定义一个端到端表示学习模型，为图构建自适应核矩阵。为此，我们首先利用一种新颖的特征通道注意机制来捕捉原始图中不同子结构不变性之间的相互依赖关系。所提出的AKBR模型因此可以有效地确定不同子结构的结构重要性，并计算与由其结构注意力指定的更重要子结构相关的成对图之间的R-卷积核。由于结果核矩阵的每一行...（此处被截断）

    arXiv:2403.16130v1 Announce Type: cross  Abstract: In this paper, we propose a new model to learn Adaptive Kernel-based Representations (AKBR) for graph classification. Unlike state-of-the-art R-convolution graph kernels that are defined by merely counting any pair of isomorphic substructures between graphs and cannot provide an end-to-end learning mechanism for the classifier, the proposed AKBR approach aims to define an end-to-end representation learning model to construct an adaptive kernel matrix for graphs. To this end, we commence by leveraging a novel feature-channel attention mechanism to capture the interdependencies between different substructure invariants of original graphs. The proposed AKBR model can thus effectively identify the structural importance of different substructures, and compute the R-convolution kernel between pairwise graphs associated with the more significant substructures specified by their structural attentions. Since each row of the resulting kernel mat
    
[^6]: 大型语言模型在心理健康领域的系统评价

    Large Language Model for Mental Health: A Systematic Review

    [https://arxiv.org/abs/2403.15401](https://arxiv.org/abs/2403.15401)

    该论文系统评价了大型语言模型在心理健康领域的应用，讨论了其在早期筛查、数字干预和其他临床应用中的挑战和机遇。

    

    大型语言模型（LLMs）在数字健康领域受到了广泛关注，展现出了潜在的应用性，但它们在心理健康领域的应用仍在持续讨论中。这项系统性评价旨在总结和表征LLMs在心理健康领域的应用，通过调查LLMs最新研究的优势和局限性，讨论心理健康领域早期筛查、数字干预以及其他临床应用的挑战和机遇。根据PRISMA指南，我们审查了PubMed、DBLP计算机科学文献数据库和IEEE Xplore上发表的英文文章，时间跨度为2017年1月1日至2023年9月1日，重点关注心理健康和LLMs。该综述分析了32篇文章，包括使用社交媒体数据集进行心理健康分析的（n=13）、心理健康聊天机器人（n=10）以及其他心理健康应用（n=9）。研究结果显示LLMs在心理健康问题检测中的有效性以及

    arXiv:2403.15401v1 Announce Type: cross  Abstract: Large language models (LLMs) have received much attention and shown their potential in digital health, while their application in mental health is subject to ongoing debate. This systematic review aims to summarize and characterize the use of LLMs in mental health by investigating the strengths and limitations of the latest work in LLMs and discusses the challenges and opportunities for early screening, digital interventions, and other clinical applications in mental health. Following PRISMA guidelines, we examined English articles from PubMed, DBLP Computer Science Bibliography, and IEEE Xplore, published between 1 January 2017, and 1 September 2023, focusing on mental health and LLMs. The review analyzed 32 articles, including mental health analysis using social media datasets (n=13), mental health chatbots (n=10), and other mental health applications (n=9). Findings reveal LLMs' effectiveness in mental health issue detection and the
    
[^7]: 使用预训练语言模型和提示进行少资源语言的少样本学习的临床信息提取

    Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting

    [https://arxiv.org/abs/2403.13369](https://arxiv.org/abs/2403.13369)

    使用预训练语言模型和提示技术，在少资源语言情境下，仅需少量样本训练即可提取临床信息，且表现优于传统方法。

    

    从临床文件中自动提取医疗信息面临着几个挑战：所需临床专业知识的高成本、模型预测的有限可解释性、受限的计算资源以及隐私法规。最近在领域适应和提示方法上的进展显示，利用轻量级遮蔽语言模型在使用极少的训练数据时取得了令人期待的结果，这些模型适用于成熟的可解释性方法。我们首次在少资源环境中对这些方法进行了系统评估，通过在德国医生信件上进行多类别段分类来实现。我们进行了广泛的类别级评估，支持 Shapley 值，以验证我们的小型训练数据集的质量，并确保模型预测的可解释性。我们证明，一个轻量级、领域适应的预训练模型，在仅仅提示了 20 次的情况下，胜过了传统的分类

    arXiv:2403.13369v1 Announce Type: new  Abstract: Automatic extraction of medical information from clinical documents poses several challenges: high costs of required clinical expertise, limited interpretability of model predictions, restricted computational resources and privacy regulations. Recent advances in domain-adaptation and prompting methods showed promising results with minimal training data using lightweight masked language models, which are suited for well-established interpretability methods. We are first to present a systematic evaluation of these methods in a low-resource setting, by performing multi-class section classification on German doctor's letters. We conduct extensive class-wise evaluations supported by Shapley values, to validate the quality of our small training data set and to ensure the interpretability of model predictions. We demonstrate that a lightweight, domain-adapted pretrained model, prompted with just 20 shots, outperforms a traditional classificatio
    
[^8]: AI增强的集体智能：现状与展望

    AI-enhanced Collective Intelligence: The State of the Art and Prospects

    [https://arxiv.org/abs/2403.10433](https://arxiv.org/abs/2403.10433)

    人类和人工智能形成的多层次集体智能网络，可以实现超越任一单独实体的集体智能水平。

    

    目前的社会挑战超出了人类个体或集体努力的能力。随着人工智能的发展，其在人类集体中的角色将从辅助工具转变为参与式成员。人类和人工智能拥有互补的能力，当二者协同作用时，可以实现一种超越单独人类或人工智能集体能力的集体智能水平。然而，人工智能系统中的交互本质上是复杂的，涉及复杂的过程和相互依赖关系。本综述从网络科学的视角出发，构想了一个多层次的人工智能集体智能表示，包括认知层、物理层和信息层。在这个多层网络中，人类和人工智能代理展现出不同的特征；人类在多样性方面从表层到深层属性不同，而人工智能代理在程度上也有所区别。

    arXiv:2403.10433v1 Announce Type: cross  Abstract: The current societal challenges exceed the capacity of human individual or collective effort alone. As AI evolves, its role within human collectives is poised to vary from an assistive tool to a participatory member. Humans and AI possess complementary capabilities that, when synergized, can achieve a level of collective intelligence that surpasses the collective capabilities of either humans or AI in isolation. However, the interactions in human-AI systems are inherently complex, involving intricate processes and interdependencies. This review incorporates perspectives from network science to conceptualize a multilayer representation of human-AI collective intelligence, comprising a cognition layer, a physical layer, and an information layer. Within this multilayer network, humans and AI agents exhibit varying characteristics; humans differ in diversity from surface-level to deep-level attributes, while AI agents range in degrees of f
    
[^9]: RepoHyper：更好的上下文检索是仓库级代码补全所需的一切

    RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion

    [https://arxiv.org/abs/2403.06095](https://arxiv.org/abs/2403.06095)

    RepoHyper提出了Repo级语义图（RSG）和Expand和Refine检索方法，显著优于现有技术，满足仓库级代码补全的需求

    

    arXiv:2403.06095v1 公告类型：交叉摘要：代码大型语言模型（CodeLLMs）在代码补全任务中展示出令人印象深刻的熟练程度。然而，它们经常无法完全理解项目仓库的广泛上下文，比如相关文件和类层次结构的复杂性，这可能导致补全不够精确。为了克服这些限制，我们提出了RepoHyper，一个旨在解决与仓库级代码补全相关的复杂挑战的多方面框架。RepoHyper的核心是Repo级语义图（RSG），一种封装代码仓库广泛上下文的新颖语义图结构。此外，RepoHyper利用扩展和细化检索方法，包括应用于RSG的图扩展和链接预测算法，从而实现对相关代码片段的有效检索和优先排序。我们的评估表明，RepoHyper在重新

    arXiv:2403.06095v1 Announce Type: cross  Abstract: Code Large Language Models (CodeLLMs) have demonstrated impressive proficiency in code completion tasks. However, they often fall short of fully understanding the extensive context of a project repository, such as the intricacies of relevant files and class hierarchies, which can result in less precise completions. To overcome these limitations, we present RepoHyper, a multifaceted framework designed to address the complex challenges associated with repository-level code completion. Central to RepoHyper is the Repo-level Semantic Graph (RSG), a novel semantic graph structure that encapsulates the vast context of code repositories. Furthermore, RepoHyper leverages Expand and Refine retrieval method, including a graph expansion and a link prediction algorithm applied to the RSG, enabling the effective retrieval and prioritization of relevant code snippets. Our evaluations show that RepoHyper markedly outperforms existing techniques in re
    
[^10]: 人工智能探索专利领域

    Artificial Intelligence Exploring the Patent Field

    [https://arxiv.org/abs/2403.04105](https://arxiv.org/abs/2403.04105)

    本文系统概述了专利领域的任务和方法，强调了语言处理和大型语言模型的重要性，并探讨了近期出现的通用生成方法在专利领域的潜力。

    

    arXiv:2403.04105v1 公告类型：新的 摘要：先进的语言处理和机器学习技术承诺在以前广泛依赖手工操作的专利和技术知识管理领域带来巨大的效率改进。这个领域展示了大规模而复杂的数据，具有非常准确的内容和语言表达这些内容。特别是，专利文本在各个方面可能与平凡的文本有所不同，这带来了重大的机遇和挑战。本文系统概述了与专利有关的任务和流行的方法，特别关注不断演变和有前途的技术。语言处理，尤其是大型语言模型以及最近推动普通生成方法的提升，有望成为专利领域的变革者。专利文献以及围绕专利的基于事实的论证程序似乎几乎是一个理想的使用案例。然而，专利涉及许多现有模型很难处理的困难。

    arXiv:2403.04105v1 Announce Type: new  Abstract: Advanced language-processing and machine-learning techniques promise massive efficiency improvements in the previously widely manual field of patent and technical knowledge management. This field presents large-scale and complex data with very precise contents and language representation of those contents. Particularly, patent texts can differ from mundane texts in various aspects, which entails significant opportunities and challenges. This paper presents a systematic overview of patent-related tasks and popular methodologies with a special focus on evolving and promising techniques. Language processing and particularly large language models as well as the recent boost of general generative methods promise to become game changers in the patent field. The patent literature and the fact-based argumentative procedures around patents appear almost as an ideal use case. However, patents entail a number of difficulties with which existing mod
    
[^11]: 利用非正式逻辑增强系统化分解的自然语言推理

    Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic

    [https://arxiv.org/abs/2402.14798](https://arxiv.org/abs/2402.14798)

    本文提出了一种一致且在理论上有根据的方法来注释分解蕴涵数据集，形成RDTE数据集，该数据集在解决何为有效的组合蕴涵的问题上有显著进展。

    

    当代语言模型为使用文本进行结构化推理提供了新的机会，例如在不依赖脆弱的形式逻辑的情况下构建和评估直观的、类似证明的文本蕴涵树。然而，沿着这个方向的进展受到一个长期以来缺乏明确的确定何为有效的组合蕴涵的清晰协议的阻碍。本文提出了一个一致且在理论上有根据的方法来注释分解蕴涵数据集，并评估其对基于LLM的文本推理的影响。我们发现，我们的结果数据集RDTE (Recognizing Decompositional Textual Entailment) 的内部一致性比先前的分解蕴涵数据集高得多（+9%），表明RDTE在长期存在的关于何为有效的组合蕴涵的问题上是一个重要的进步。

    arXiv:2402.14798v1 Announce Type: cross  Abstract: Contemporary language models enable new opportunities for structured reasoning with text, such as the construction and evaluation of intuitive, proof-like textual entailment trees without relying on brittle formal logic. However, progress in this direction has been hampered by a long-standing lack of a clear protocol for determining what valid compositional entailment is. This absence causes noisy datasets and limited performance gains by modern neuro-symbolic engines. To address these problems, we formulate a consistent and theoretically grounded approach to annotating decompositional entailment datasets, and evaluate its impact on LLM-based textual inference. We find that our resulting dataset, RDTE (Recognizing Decompositional Textual Entailment), has a substantially higher internal consistency (+9%) than prior decompositional entailment datasets, suggesting that RDTE is a significant step forward in the long-standing problem of for
    
[^12]: 在连续学习中保持对抗性鲁棒性

    Maintaining Adversarial Robustness in Continuous Learning

    [https://arxiv.org/abs/2402.11196](https://arxiv.org/abs/2402.11196)

    提出了一种名为双梯度投影的方法，通过将梯度投影到两个关键子空间来实现持续鲁棒学习，有效地维持了神经网络对抗性鲁棒性。

    

    对抗性鲁棒性对于机器学习系统的安全性和可靠性至关重要。然而，通过复杂的防御算法获得的对抗性鲁棒性在神经网络不断演化以学习新任务时很容易被抹去。这种脆弱性可以通过培养一种新颖的神经网络能力来解决，称为持续鲁棒学习，它在连续学习过程中关注前期任务的(分类)性能和对抗性鲁棒性。为了实现持续鲁棒学习，我们提出了一种称为双梯度投影的方法，将用于权重更新的梯度正交投影到两个关键子空间上 -- 一个用于稳定平滑样本梯度，另一个用于稳定神经网络的最终输出。在四个基准测试上的实验结果表明，所提出的方法有效地维持了对强对抗性的持续鲁棒性。

    arXiv:2402.11196v1 Announce Type: cross  Abstract: Adversarial robustness is essential for security and reliability of machine learning systems. However, the adversarial robustness gained by sophisticated defense algorithms is easily erased as the neural network evolves to learn new tasks. This vulnerability can be addressed by fostering a novel capability for neural networks, termed continual robust learning, which focuses on both the (classification) performance and adversarial robustness on previous tasks during continuous learning. To achieve continuous robust learning, we propose an approach called Double Gradient Projection that projects the gradients for weight updates orthogonally onto two crucial subspaces -- one for stabilizing the smoothed sample gradients and another for stabilizing the final outputs of the neural network. The experimental results on four benchmarks demonstrate that the proposed approach effectively maintains continuous robustness against strong adversarial
    
[^13]: 具有闭环个性化课程的连续驾驶政策优化

    Continual Driving Policy Optimization with Closed-Loop Individualized Curricula

    [https://arxiv.org/abs/2309.14209](https://arxiv.org/abs/2309.14209)

    开发了连续驾驶政策优化框架，提出了闭环个性化课程（CLIC）概念，允许重复利用广泛场景来迭代改进自主驾驶车辆模型。

    

    自主驾驶车辆（AV）的安全一直是一个长期的头等关注点，根源于长尾自然驾驶分布中罕见的安全关键场景的缺失。为了解决这一挑战，出现了大量基于场景的自动驾驶研究，重点是生成高风险驾驶场景并将它们应用于对AV模型进行安全关键测试。然而，有限的工作探讨了重复利用这些广泛场景来迭代改进AV模型。此外，从具有不同行为的其他AV模型收集的巨大场景库中滤出可传递信息以改进当前AV仍然是难以解决的且具有挑战性。因此，我们开发了一个具有闭环个性化课程（CLIC）特点的连续驾驶政策优化框架，我们将其分解为一组标准化的子模块。

    arXiv:2309.14209v3 Announce Type: replace-cross  Abstract: The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution. To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models. However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models. Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement. Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for
    
[^14]: 用分解的图神经网络预测卡车停车使用情况

    Truck Parking Usage Prediction with Decomposed Graph Neural Networks. (arXiv:2401.12920v1 [cs.AI])

    [http://arxiv.org/abs/2401.12920](http://arxiv.org/abs/2401.12920)

    提出了Regional Temporal Graph Neural Network (RegT-GCN)作为一个预测框架，用于评估整个州的卡车停车使用情况，以提供更准确的停车信息并缓解未经授权的停车问题。

    

    货运走廊上的卡车停车面临诸多挑战，如停车位不足和遵守工时规定。这些限制往往导致未经授权的停车行为，引发安全问题。为了提高货运作业的安全性，提供准确的停车使用预测被证明是一种经济高效的解决方案。尽管已有研究表明对于单个卡车停车场使用情况的预测准确度较高，但对多个卡车停车场的空间依赖关系进行使用预测的方法很少。我们提出了区域时空图神经网络（RegT-GCN）作为一个预测框架，用于评估整个州的停车使用情况，以提供更好的卡车停车信息和缓解未经授权的停车问题。该框架利用卡车停车场分布的拓扑结构和历史停车数据来预测整个州的占用率。

    Truck parking on freight corridors faces various challenges, such as insufficient parking spaces and compliance with Hour-of-Service (HOS) regulations. These constraints often result in unauthorized parking practices, causing safety concerns. To enhance the safety of freight operations, providing accurate parking usage prediction proves to be a cost-effective solution. Despite the existing research demonstrating satisfactory accuracy for predicting individual truck parking site usage, few approaches have been proposed for predicting usage with spatial dependencies of multiple truck parking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN) as a predictive framework for assessing parking usage across the entire state to provide better truck parking information and mitigate unauthorized parking. The framework leverages the topological structures of truck parking site distributions and historical parking data to predict occupancy rates across a state. To achieve this,
    
[^15]: SHAP评分在可解释机器学习中的分布不确定性

    The Distributional Uncertainty of the SHAP score in Explainable Machine Learning. (arXiv:2401.12731v1 [cs.AI])

    [http://arxiv.org/abs/2401.12731](http://arxiv.org/abs/2401.12731)

    本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。

    

    归属分数反映了输入实体中的特征值对机器学习模型输出的重要性。其中最受欢迎的评分之一是SHAP评分，它是合作博弈理论中Shapley值的具体实例。该评分的定义依赖于实体群体的概率分布。由于通常不知道精确的分布，因此需要主观地进行分配或从数据中进行估计，这可能会导致误导性的特征评分。在本文中，我们提出了一个基于不知道实体群体分布的SHAP评分推理的原则性框架。在我们的框架中，我们考虑一个包含潜在分布的不确定性区域，而特征的SHAP评分成为在该区域上定义的一个函数。我们研究了找到该函数的最大值和最小值的基本问题，这使我们能够确定所有特征的SHAP评分的紧束范围。

    Attribution scores reflect how important the feature values in an input entity are for the output of a machine learning model. One of the most popular attribution scores is the SHAP score, which is an instantiation of the general Shapley value used in coalition game theory. The definition of this score relies on a probability distribution on the entity population. Since the exact distribution is generally unknown, it needs to be assigned subjectively or be estimated from data, which may lead to misleading feature scores. In this paper, we propose a principled framework for reasoning on SHAP scores under unknown entity population distributions. In our framework, we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region. We study the basic problems of finding maxima and minima of this function, which allows us to determine tight ranges for the SHAP scores of all features. In particular, we pinp
    
[^16]: 穿越文化鸿沟：探索和解锁文本到图像模型的文化视角

    Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of Text-To-Image Models. (arXiv:2310.01929v1 [cs.CL])

    [http://arxiv.org/abs/2310.01929](http://arxiv.org/abs/2310.01929)

    本研究旨在探索和解锁文本到图像模型的文化视角，通过对TTI模型中嵌入的文化感知进行评估，揭示了这些模型的文化意识、文化区别和文化适应性。

    

    文本到图像（TTI）模型，例如DALL-E和StableDiffusion，在通过文本提示生成图像的零射模式方面具有卓越的能力，近来备受关注。作为文化的媒介，语言在这些模型的多语言能力中起着关键作用，从而塑造了它们的文化机制。在本研究中，我们通过描述文化维度，文化领域和文化概念的三个层次来探索TTI模型中嵌入的文化感知。我们提出了一套全面的评估技术，包括使用CLIP空间进行内在评估，使用视觉问答（VQA）模型进行外在评估以及人类评估，以识别TTI文化感知。为了促进我们的研究，我们引入了CulText2I数据集，该数据集来自四个不同的TTI模型，涵盖了十种语言。我们的实验揭示了这些模型的文化意识、文化区别和

    Text-To-Image (TTI) models, exemplified by DALL-E and StableDiffusion, have recently gained prominence for their remarkable zero-shot capabilities in generating images guided by textual prompts. Language, as a conduit of culture, plays a pivotal role in these models' multilingual capabilities, which in turn shape their cultural agency. In this study, we explore the cultural perception embedded in TTI models by characterizing culture across three hierarchical tiers: cultural dimensions, cultural domains, and cultural concepts. We propose a comprehensive suite of evaluation techniques, including intrinsic evaluations using the CLIP space, extrinsic evaluations with a Visual-Question-Answer (VQA) model, and human assessments, to discern TTI cultural perceptions. To facilitate our research, we introduce the CulText2I dataset, derived from four diverse TTI models and spanning ten languages. Our experiments reveal insights into these models' cultural awareness, cultural distinctions, and the
    
[^17]: 可解释的基于图神经网络的表格数据处理方法

    Interpretable Graph Neural Networks for Tabular Data. (arXiv:2308.08945v1 [cs.LG])

    [http://arxiv.org/abs/2308.08945](http://arxiv.org/abs/2308.08945)

    本论文提出了一种称为IGNNet的方法，可以在处理表格数据时使用图神经网络，该方法能够产生可解释的模型，从原始输入特征精确计算预测结果，并且在性能上与最先进的机器学习算法性能相当。

    

    在现实世界的应用中，表格格式的数据经常出现。图神经网络（GNNs）近期被扩展以有效处理此类数据，通过表示学习捕捉特征之间的相互作用。然而，这些方法本质上产生了黑盒模型，以深度神经网络的形式存在，使得用户无法理解模型预测的逻辑。我们提出了一种称为IGNNet（基于图神经网络的可解释表格数据处理方法）的方法，它限制学习算法以产生可解释的模型，该模型展示了如何从原始输入特征准确计算预测结果。通过大规模实证研究，我们展示了IGNNet与面向表格数据的最先进机器学习算法（包括XGBoost，Random Forests和TabNet）性能相当。同时，结果显示从IGNNet获得的解释与真实情况一致。

    Data in tabular format is frequently occurring in real-world applications. Graph Neural Networks (GNNs) have recently been extended to effectively handle such data, allowing feature interactions to be captured through representation learning. However, these approaches essentially produce black-box models, in the form of deep neural networks, precluding users from following the logic behind the model predictions. We propose an approach, called IGNNet (Interpretable Graph Neural Network for tabular data), which constrains the learning algorithm to produce an interpretable model, where the model shows how the predictions are exactly computed from the original input features. A large-scale empirical investigation is presented, showing that IGNNet is performing on par with state-of-the-art machine-learning algorithms that target tabular data, including XGBoost, Random Forests, and TabNet. At the same time, the results show that the explanations obtained from IGNNet are aligned with the true
    
[^18]: 边缘云计算的神经分位数优化

    Neural Quantile Optimization for Edge-Cloud Computing. (arXiv:2307.05170v1 [cs.NI])

    [http://arxiv.org/abs/2307.05170](http://arxiv.org/abs/2307.05170)

    这项研究提出了一种神经分位数优化的方法，用于边缘云计算网络中找到最佳的流量分配方案。通过引入Gumbel-softmax采样网络，可以有效地解决优化问题并显著优于随机策略。

    

    我们寻求边缘云计算网络的最佳流量分配方案，以满足约束条件并最小化基于突发计费的成本。首先，对于固定的网络拓扑，我们提出了一族整数规划问题，其中包含描述各种流量需求的随机参数。然后，为了克服问题离散特征带来的困难，我们将Gumbel-softmax重参数化方法推广为一个无约束连续优化问题，作为离散问题的正则化延续。最后，我们引入Gumbel-softmax采样网络，通过无监督学习来解决优化问题。网络结构反映了边缘云计算的拓扑结构，并被训练为使得无约束连续优化问题的成本函数期望最小化。训练好的网络作为一个高效的流量分配方案采样器，在可行性方面明显优于随机策略。

    We seek the best traffic allocation scheme for the edge-cloud computing network that satisfies constraints and minimizes the cost based on burstable billing. First, for a fixed network topology, we formulate a family of integer programming problems with random parameters describing the various traffic demands. Then, to overcome the difficulty caused by the discrete feature of the problem, we generalize the Gumbel-softmax reparameterization method to induce an unconstrained continuous optimization problem as a regularized continuation of the discrete problem. Finally, we introduce the Gumbel-softmax sampling network to solve the optimization problems via unsupervised learning. The network structure reflects the edge-cloud computing topology and is trained to minimize the expectation of the cost function for unconstrained continuous optimization problems. The trained network works as an efficient traffic allocation scheme sampler, remarkably outperforming the random strategy in feasibili
    

