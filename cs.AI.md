# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ChatTracer: Large Language Model Powered Real-time Bluetooth Device Tracking System](https://arxiv.org/abs/2403.19833) | ChatTracer是一个由LLM驱动的实时蓝牙设备追踪系统，其创新之处在于可靠高效的BLE数据包分组算法和结合了监督微调和强化学习微调策略的LLM微调策略。 |
| [^2] | [Regularization in Spider-Style Strategy Discovery and Schedule Construction](https://arxiv.org/abs/2403.12869) | 本文研究了在Vampire定理证明器中使用蜘蛛式系统的正则化方法，探讨了构建强大日程表的难易程度以及日程泛化到未知问题的影响因素。 |
| [^3] | [Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt](https://arxiv.org/abs/2403.11780) | 提出了Prompt-Singer，这是第一个能够用自然语言控制歌手性别、音域和音量的唱歌声音合成方法，采用了基于解码器的变压器模型架构和范围旋律解耦的音高表示方法。 |
| [^4] | [GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting](https://arxiv.org/abs/2403.08551) | 通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。 |
| [^5] | [Optimizing Negative Prompts for Enhanced Aesthetics and Fidelity in Text-To-Image Generation](https://arxiv.org/abs/2403.07605) | 提出NegOpt方法，通过监督微调和强化学习优化负面提示的生成，显著提高图像生成质量，超越其他方法并构建了负面提示数据集。 |
| [^6] | [Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning](https://arxiv.org/abs/2403.07362) | 该论文从对抗的角度提出了一种新的机器遗忘评估方法，通过确定最具挑战性的数据子集，即最坏情况遗忘集，来增强对影响擦除的挑战。 |
| [^7] | [Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?](https://arxiv.org/abs/2403.05701) | 该研究测试大型语言模型在人机互动中是否能够捕捉到人们的行为判断和沟通偏好，结果表明GPT-4在生成社会可接受行为方面表现出色。 |
| [^8] | [Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation](https://arxiv.org/abs/2403.05171) | 本论文提出了对抗策略优化（AdvPO）来解决强化学习领域中奖励过度优化的问题，通过量化奖励的不确定性，并围绕奖励模型预测的置信区间进行分布鲁棒的优化，从而有效缓解了该问题。 |
| [^9] | [AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors](https://arxiv.org/abs/2403.04697) | AUFormer提出了一种参数高效的面部动作单位检测方法，引入了新颖的知识混合专家协作机制，解决了传统方法在稀缺数据集或过度依赖额外数据导致的过拟合问题。 |
| [^10] | [Equilibria in Two-Stage Facility Location with Atomic Clients](https://arxiv.org/abs/2403.03114) | 本文研究了竞争性设施选址的两阶段多代理系统，针对不可分割权重的客户提出了混合策略，展示了在给定设施布置时可能出现截然不同的客户均衡。 |
| [^11] | [Not all Layers of LLMs are Necessary during Inference](https://arxiv.org/abs/2403.02181) | 推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。 |
| [^12] | [Grounding Language about Belief in a Bayesian Theory-of-Mind](https://arxiv.org/abs/2402.10416) | 语义基础置于贝叶斯心灵理论中，通过模拟人们共同推断出解释代理人行为的一致性目标、信念和计划集合，再通过认识逻辑评估有关代理人信念的陈述，解释了人类信念归因的分级性和组合性，以及其与目标和计划的密切联系。 |
| [^13] | [Rethink Model Re-Basin and the Linear Mode Connectivity](https://arxiv.org/abs/2402.05966) | 本论文重新审视了模型重新基底的现象，并发现了现有匹配算法的不足。通过适当的重归一化，我们改进了匹配算法，并揭示了它与重归一化过程的相互作用。这为剪枝提供了新的理解，推动了一种轻量且有效的后剪枝插件的开发。 |
| [^14] | [Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks](https://arxiv.org/abs/2401.17263) | 该论文提出了一种鲁棒的提示优化算法（RPO）用于对抗语言模型的破解攻击，通过梯度优化来确保输出的无害性，并成功降低了攻击成功率。 |
| [^15] | [Working Backwards: Learning to Place by Picking](https://arxiv.org/abs/2312.02352) | 通过逆向抓取过程并利用拾取和放置问题的对称性，提出了一种通过拾取的放置方法，并用自主收集的演示直接训练策略，实现在接触受限环境下物体放置任务的自主收集和泛化。 |
| [^16] | [Learning-Based Difficulty Calibration for Enhanced Membership Inference Attacks.](http://arxiv.org/abs/2401.04929) | 本文介绍了一种基于学习的难度校准的成员推理攻击方法，旨在显著提高低FPR下的TPR，以验证训练模型是否保护隐私。 |
| [^17] | [Integration of Domain Expert-Centric Ontology Design into the CRISP-DM for Cyber-Physical Production Systems.](http://arxiv.org/abs/2307.11637) | 本文提出了一种将领域专家中心本体设计集成到CRISP-DM中的方法，以解决公司在应用数据驱动项目时所遇到的挑战。 |
| [^18] | [Representation Learning on Hyper-Relational and Numeric Knowledge Graphs with Transformers.](http://arxiv.org/abs/2305.18256) | 本文提出了一个名为HyNT的框架，用于学习超关系型知识图的表示，包括数值文字。该框架使用上下文Transformer和预测Transformer，通过学习三元组和其限定词之间的相关性以及数值信息来获得模型。 |
| [^19] | [A Deep RL Approach on Task Placement and Scaling of Edge Resources for Cellular Vehicle-to-Network Service Provisioning.](http://arxiv.org/abs/2305.09832) | 本文提出了一种基于深度强化学习的分散式方法，用于解决车联网服务提供中的任务部署和边缘资源的扩展问题。 |
| [^20] | [Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods.](http://arxiv.org/abs/2303.13988) | 本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。 |
| [^21] | [Bucketized Active Sampling for Learning ACOPF.](http://arxiv.org/abs/2208.07497) | 本文提出了一种新颖的主动学习框架——分桶主动采样（BAS），旨在在时间限制内训练最佳的OPF代理。BAS将输入分布分成桶，并使用收集函数确定下一次采样的位置。实验结果显示了BAS的好处。 |
| [^22] | [MetaCOG: Learning a Metacognition to Recover What Objects Are Actually There.](http://arxiv.org/abs/2110.03105) | MetaCOG是一个学习元认知的模型，通过学习目标检测器的可靠性表示，增加了目标检测器的鲁棒性，而无需反馈和地面真实的物体标签。 |

# 详细

[^1]: ChatTracer：大型语言模型驱动的实时蓝牙设备追踪系统

    ChatTracer: Large Language Model Powered Real-time Bluetooth Device Tracking System

    [https://arxiv.org/abs/2403.19833](https://arxiv.org/abs/2403.19833)

    ChatTracer是一个由LLM驱动的实时蓝牙设备追踪系统，其创新之处在于可靠高效的BLE数据包分组算法和结合了监督微调和强化学习微调策略的LLM微调策略。

    

    大型语言模型（LLMs），如OpenAI ChatGPT和Google Bard所展示的，已经改变了我们与网络技术互动的方式。本文研究了将LLM与无线传感器网络（WSN）相连接的可能性。一个成功的设计不仅会将LLM的知识领域延伸到物理世界，而且将彻底革新人们与WSN的互动。为此，我们提出了ChatTracer，一个由LLM驱动的实时蓝牙设备追踪系统。ChatTracer由三个关键组件组成：一系列蓝牙嗅探节点、一个数据库和一个经过精调的LLM。ChatTracer的设计基于我们的实验观察，商用的苹果/安卓设备即使在空闲状态下也会每分钟广播数百个BLE数据包。它的创新之处在于：i）一个可靠高效的BLE数据包分组算法；和ii）一个结合了监督微调（SFT）和强化学习微调策略的LLM微调策略。

    arXiv:2403.19833v1 Announce Type: cross  Abstract: Large language models (LLMs), exemplified by OpenAI ChatGPT and Google Bard, have transformed the way we interact with cyber technologies. In this paper, we study the possibility of connecting LLM with wireless sensor networks (WSN). A successful design will not only extend LLM's knowledge landscape to the physical world but also revolutionize human interaction with WSN. To the end, we present ChatTracer, an LLM-powered real-time Bluetooth device tracking system. ChatTracer comprises three key components: an array of Bluetooth sniffing nodes, a database, and a fine-tuned LLM. ChatTracer was designed based on our experimental observation that commercial Apple/Android devices always broadcast hundreds of BLE packets per minute even in their idle status. Its novelties lie in two aspects: i) a reliable and efficient BLE packet grouping algorithm; and ii) an LLM fine-tuning strategy that combines both supervised fine-tuning (SFT) and reinfo
    
[^2]: 蜘蛛式策略发现和日程构建中的正则化方法

    Regularization in Spider-Style Strategy Discovery and Schedule Construction

    [https://arxiv.org/abs/2403.12869](https://arxiv.org/abs/2403.12869)

    本文研究了在Vampire定理证明器中使用蜘蛛式系统的正则化方法，探讨了构建强大日程表的难易程度以及日程泛化到未知问题的影响因素。

    

    为了达到最佳性能，自动定理证明器通常依赖于多样的证明策略日程表，在给定问题上尝试（顺序或并行）。本文报告了一项针对Vampire定理证明器的策略发现的大规模实验，针对TPTP库的FOF片段并构建一个基于Andrei Voronkov的Spider系统思想的日程表。我们从各个角度审视该过程，讨论了为CASC竞赛获得强大的Vampire日程表的难易程度，并建立了一个日程表能够对未知问题泛化到何种程度以及影响此属性的因素。

    arXiv:2403.12869v1 Announce Type: new  Abstract: To achieve the best performance, automatic theorem provers often rely on schedules of diverse proving strategies to be tried out (either sequentially or in parallel) on a given problem. In this paper, we report on a large-scale experiment with discovering strategies for the Vampire prover, targeting the FOF fragment of the TPTP library and constructing a schedule for it, based on the ideas of Andrei Voronkov's system Spider. We examine the process from various angles, discuss the difficulty (or ease) of obtaining a strong Vampire schedule for the CASC competition, and establish how well a schedule can be expected to generalize to unseen problems and what factors influence this property.
    
[^3]: Prompt-Singer: 带自然语言提示的可控唱歌声音合成

    Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt

    [https://arxiv.org/abs/2403.11780](https://arxiv.org/abs/2403.11780)

    提出了Prompt-Singer，这是第一个能够用自然语言控制歌手性别、音域和音量的唱歌声音合成方法，采用了基于解码器的变压器模型架构和范围旋律解耦的音高表示方法。

    

    近期的唱歌声音合成(SVS)方法取得了显著的音频质量和自然度，然而它们缺乏显式控制合成唱歌风格属性的能力。我们提出Prompt-Singer，这是第一个能够用自然语言控制歌手性别、音域和音量的SVS方法。我们采用基于仅解码器的变压器模型架构，具有多尺度层次结构，并设计了一个分离音高表示的范围旋律解耦的方法，从而实现了基于文本的音域控制同时保持了旋律准确性。此外，我们探索了各种实验设置，包括不同类型的文本表示，文本编码器微调，以及引入语音数据以减轻数据稀缺性，旨在促进进一步研究。实验证明，我们的模型具有良好的控制能力和音频质量。音频示例可访问 http://prompt-singer.

    arXiv:2403.11780v1 Announce Type: cross  Abstract: Recent singing-voice-synthesis (SVS) methods have achieved remarkable audio quality and naturalness, yet they lack the capability to control the style attributes of the synthesized singing explicitly. We propose Prompt-Singer, the first SVS method that enables attribute controlling on singer gender, vocal range and volume with natural language. We adopt a model architecture based on a decoder-only transformer with a multi-scale hierarchy, and design a range-melody decoupled pitch representation that enables text-conditioned vocal range control while keeping melodic accuracy. Furthermore, we explore various experiment settings, including different types of text representations, text encoder fine-tuning, and introducing speech data to alleviate data scarcity, aiming to facilitate further research. Experiments show that our model achieves favorable controlling ability and audio quality. Audio samples are available at http://prompt-singer.
    
[^4]: 高斯图像：通过2D高斯喷涂进行1000帧每秒的图像表示和压缩

    GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting

    [https://arxiv.org/abs/2403.08551](https://arxiv.org/abs/2403.08551)

    通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。

    

    最近，隐式神经表示（INR）在图像表示和压缩方面取得了巨大成功，提供了高视觉质量和快速渲染速度，每秒10-1000帧，假设有足够的GPU资源可用。然而，这种要求常常阻碍了它们在内存有限的低端设备上的使用。为此，我们提出了一种通过2D高斯喷涂进行图像表示和压缩的开创性范式，名为GaussianImage。我们首先引入2D高斯来表示图像，其中每个高斯具有8个参数，包括位置、协方差和颜色。随后，我们揭示了一种基于累积求和的新颖渲染算法。值得注意的是，我们的方法使用GPU内存至少降低3倍，拟合时间快5倍，不仅在表示性能上与INR（例如WIRE，I-NGP）不相上下，而且无论参数大小如何都能提供1500-2000帧每秒的更快渲染速度。

    arXiv:2403.08551v1 Announce Type: cross  Abstract: Implicit neural representations (INRs) recently achieved great success in image representation and compression, offering high visual quality and fast rendering speeds with 10-1000 FPS, assuming sufficient GPU resources are available. However, this requirement often hinders their use on low-end devices with limited memory. In response, we propose a groundbreaking paradigm of image representation and compression by 2D Gaussian Splatting, named GaussianImage. We first introduce 2D Gaussian to represent the image, where each Gaussian has 8 parameters including position, covariance and color. Subsequently, we unveil a novel rendering algorithm based on accumulated summation. Remarkably, our method with a minimum of 3$\times$ lower GPU memory usage and 5$\times$ faster fitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation performance, but also delivers a faster rendering speed of 1500-2000 FPS regardless of parameter size. 
    
[^5]: 优化负面提示以增强文本到图像生成中的美学和保真度

    Optimizing Negative Prompts for Enhanced Aesthetics and Fidelity in Text-To-Image Generation

    [https://arxiv.org/abs/2403.07605](https://arxiv.org/abs/2403.07605)

    提出NegOpt方法，通过监督微调和强化学习优化负面提示的生成，显著提高图像生成质量，超越其他方法并构建了负面提示数据集。

    

    在文本到图像生成中，使用描述不良图像特征的负面提示可以显著提高图像质量。然而，生成良好的负面提示是一项手工而繁琐的工作。为了解决这个问题，我们提出了NegOpt，一种新颖的方法，通过监督微调和强化学习来优化负面提示生成，从而增强图像生成。我们的综合方法相对于其他方法大幅提高了25%的Inception Score，并超越了来自测试集的标准负面提示。此外，使用NegOpt，我们可以有选择地优化对我们最重要的指标。最后，我们构建了负面提示数据集Negative Prompts DB。

    arXiv:2403.07605v1 Announce Type: cross  Abstract: In text-to-image generation, using negative prompts, which describe undesirable image characteristics, can significantly boost image quality. However, producing good negative prompts is manual and tedious. To address this, we propose NegOpt, a novel method for optimizing negative prompt generation toward enhanced image generation, using supervised fine-tuning and reinforcement learning. Our combined approach results in a substantial increase of 25% in Inception Score compared to other approaches and surpasses ground-truth negative prompts from the test set. Furthermore, with NegOpt we can preferentially optimize the metrics most important to us. Finally, we construct Negative Prompts DB, a dataset of negative prompts.
    
[^6]: 挑战遗忘：揭示机器遗忘中最坏情况遗忘集

    Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning

    [https://arxiv.org/abs/2403.07362](https://arxiv.org/abs/2403.07362)

    该论文从对抗的角度提出了一种新的机器遗忘评估方法，通过确定最具挑战性的数据子集，即最坏情况遗忘集，来增强对影响擦除的挑战。

    

    靠谱的机器学习(Machine Learning, ML)社区越来越认识到模型在训练后有选择性地“遗忘”数据点的重要性。这引出了机器遗忘(Machine Unlearning, MU)问题，旨在消除选定数据点对模型性能的影响，同时仍保持模型在遗忘后的实用性。尽管有各种MU方法来擦除数据影响，评估主要集中在随机数据遗忘上，忽视了对于真实衡量遗忘性能的数据子集选择的重要探究。为解决这一问题，我们从对抗的角度引入了一种新的MU评估视角。我们提出确定那些对影响擦除构成最大挑战的数据子集，即找出最坏情况遗忘集。利用双层优化原则，我们增强了在上层优化中的遗忘挑战。

    arXiv:2403.07362v1 Announce Type: cross  Abstract: The trustworthy machine learning (ML) community is increasingly recognizing the crucial need for models capable of selectively 'unlearning' data points after training. This leads to the problem of machine unlearning (MU), aiming to eliminate the influence of chosen data points on model performance, while still maintaining the model's utility post-unlearning. Despite various MU methods for data influence erasure, evaluations have largely focused on random data forgetting, ignoring the vital inquiry into which subset should be chosen to truly gauge the authenticity of unlearning performance. To tackle this issue, we introduce a new evaluative angle for MU from an adversarial viewpoint. We propose identifying the data subset that presents the most significant challenge for influence erasure, i.e., pinpointing the worst-case forget set. Utilizing a bi-level optimization principle, we amplify unlearning challenges at the upper optimization 
    
[^7]: 大型语言模型是否与人们的社交直觉相一致，用于人机互动？

    Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?

    [https://arxiv.org/abs/2403.05701](https://arxiv.org/abs/2403.05701)

    该研究测试大型语言模型在人机互动中是否能够捕捉到人们的行为判断和沟通偏好，结果表明GPT-4在生成社会可接受行为方面表现出色。

    

    大型语言模型（LLMs）越来越多地用于机器人技术，特别是高层次的行动规划。与此同时，许多机器人应用涉及人类监督员或合作者。因此，对LLMs生成与人们偏好和价值观相一致的社会可接受行动至关重要。在这项工作中，我们测试LLMs是否捕捉到人们在人机互动（HRI）场景中行为判断和沟通偏好方面的直觉。为了评估，我们重现了三个HRI用户研究，将LLMs的输出与真实参与者的输出进行比较。我们发现GPT-4在非常出色地表现，生成的答案与两项研究的用户答案具有很强相关性——第一项研究涉及在各种情境中选择最合适的沟通举动给机器人（$r_s$ = 0.82），第二项涉及判断行为的可取性、意图性和令人惊讶性。

    arXiv:2403.05701v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly used in robotics, especially for high-level action planning. Meanwhile, many robotics applications involve human supervisors or collaborators. Hence, it is crucial for LLMs to generate socially acceptable actions that align with people's preferences and values. In this work, we test whether LLMs capture people's intuitions about behavior judgments and communication preferences in human-robot interaction (HRI) scenarios. For evaluation, we reproduce three HRI user studies, comparing the output of LLMs with that of real participants. We find that GPT-4 strongly outperforms other models, generating answers that correlate strongly with users' answers in two studies $\unicode{x2014}$ the first study dealing with selecting the most appropriate communicative act for a robot in various situations ($r_s$ = 0.82), and the second with judging the desirability, intentionality, and surprisingness of beh
    
[^8]: 通过轻量级不确定性估计对抗策略优化克服了奖励过度优化问题

    Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation

    [https://arxiv.org/abs/2403.05171](https://arxiv.org/abs/2403.05171)

    本论文提出了对抗策略优化（AdvPO）来解决强化学习领域中奖励过度优化的问题，通过量化奖励的不确定性，并围绕奖励模型预测的置信区间进行分布鲁棒的优化，从而有效缓解了该问题。

    

    我们引入了对抗策略优化（AdvPO），这是一种新颖的解决方案，用于解决强化学习从人类反馈中的奖励过度优化问题，适用于大型语言模型（LLMs）。AdvPO围绕奖励模型预测的置信区间解决了一个分布鲁棒的优化问题，以改进策略。通过对Anthropic HH和TL;DR摘要数据集进行全面实验，我们展示了AdvPO在减轻过度优化问题方面的有效性。

    arXiv:2403.05171v1 Announce Type: cross  Abstract: We introduce Adversarial Policy Optimization (AdvPO), a novel solution to the pervasive issue of reward over-optimization in Reinforcement Learning from Human Feedback (RLHF) for Large Language Models (LLMs). Over-optimization occurs when a reward model serves as an imperfect proxy for human preference, and RL-driven policy optimization erroneously exploits reward inaccuracies. In this paper, we begin by introducing a lightweight way to quantify uncertainties in rewards, relying solely on the last layer embeddings of the reward model, without the need for computationally expensive reward ensembles. AdvPO then addresses a distributionally robust optimization problem centred around the confidence interval of the reward model's predictions for policy improvement. Through comprehensive experiments on the Anthropic HH and TL;DR summarization datasets, we illustrate the efficacy of AdvPO in mitigating the overoptimization issue, consequently
    
[^9]: AUFormer: 视觉Transformer是参数高效的面部动作单位检测器

    AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors

    [https://arxiv.org/abs/2403.04697](https://arxiv.org/abs/2403.04697)

    AUFormer提出了一种参数高效的面部动作单位检测方法，引入了新颖的知识混合专家协作机制，解决了传统方法在稀缺数据集或过度依赖额外数据导致的过拟合问题。

    

    面部动作单位（AU）在情感计算领域是一个重要概念，AU检测一直是一个热门的研究课题。现有方法由于在稀缺的AU注释数据集上利用大量可学习参数或过度依赖大量额外相关数据而存在过拟合问题。参数高效迁移学习（PETL）提供了一个有希望解决这些挑战的范式，然而其现有方法缺乏针对AU特征的设计。因此，我们创新性地将PETL范式应用于AU检测，引入AUFormer并提出了一种新颖的知识混合专家（MoKE）协作机制。一个特定于某个AU并具有最少可学习参数的MoKE首先集成个性化的多尺度和相关知识。然后MoKE与专家组中的其他MoKE合作，获取聚合信息并将其注入到...

    arXiv:2403.04697v1 Announce Type: cross  Abstract: Facial Action Units (AU) is a vital concept in the realm of affective computing, and AU detection has always been a hot research topic. Existing methods suffer from overfitting issues due to the utilization of a large number of learnable parameters on scarce AU-annotated datasets or heavy reliance on substantial additional relevant data. Parameter-Efficient Transfer Learning (PETL) provides a promising paradigm to address these challenges, whereas its existing methods lack design for AU characteristics. Therefore, we innovatively investigate PETL paradigm to AU detection, introducing AUFormer and proposing a novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism. An individual MoKE specific to a certain AU with minimal learnable parameters first integrates personalized multi-scale and correlation knowledge. Then the MoKE collaborates with other MoKEs in the expert group to obtain aggregated information and inject it into the 
    
[^10]: 两阶段设施选址中的均衡与原子客户

    Equilibria in Two-Stage Facility Location with Atomic Clients

    [https://arxiv.org/abs/2403.03114](https://arxiv.org/abs/2403.03114)

    本文研究了竞争性设施选址的两阶段多代理系统，针对不可分割权重的客户提出了混合策略，展示了在给定设施布置时可能出现截然不同的客户均衡。

    

    我们将竞争性设施选址视为一个带有两种客户类型的两阶段多代理系统。对于具有加权客户的主机图，首先设施代理者战略性地选择开设设施的顶点。然后，客户战略性地选择在其邻域内的哪个开设设施消费。设施希望尽可能吸引更多客户权重，客户希望最小化所选设施上的拥挤。所有最近研究的此模型版本都假定客户可以战略性地分担他们的权重。我们考虑具有不可分割权重的客户，但允许混合策略。因此，客户可以在哪个设施消费上随机选择。除了对自然客户行为进行建模外，这种微妙的变化会产生 drast 剧烈的变化，例如，在给定设施布置时，可能出现截然不同的客户均衡。作为我们的主要结果，我们展示了纯子博弈完美

    arXiv:2403.03114v1 Announce Type: cross  Abstract: We consider competitive facility location as a two-stage multi-agent system with two types of clients. For a given host graph with weighted clients on the vertices, first facility agents strategically select vertices for opening their facilities. Then, the clients strategically select which of the opened facilities in their neighborhood to patronize. Facilities want to attract as much client weight as possible, clients want to minimize congestion on the chosen facility.   All recently studied versions of this model assume that clients can split their weight strategically. We consider clients with unsplittable weights, but allow mixed strategies. So clients may randomize over which facility to patronize. Besides modeling a natural client behavior, this subtle change yields drastic changes, e.g., for a given facility placement, qualitatively different client equilibria are possible.   As our main result, we show that pure subgame perfect
    
[^11]: 推理过程中不是所有LLMs的层都是必要的

    Not all Layers of LLMs are Necessary during Inference

    [https://arxiv.org/abs/2403.02181](https://arxiv.org/abs/2403.02181)

    推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。

    

    大型语言模型（LLMs）的推理阶段非常昂贵。理想的LLMs推理阶段可以利用更少的计算资源，同时仍保持其能力（例如泛化和上下文学习能力）。本文尝试回答一个问题：“在LLMs推理过程中，我们可以为简单实例使用浅层，并为难以处理的实例使用深层吗？”为了回答这个问题，我们首先通过统计分析跨任务激活的层来指出并非所有层在推理过程中都是必要的。然后，我们提出了一种简单的算法，名为AdaInfer，根据输入实例自适应地确定推理终止时刻。更重要的是，AdaInfer不改变LLMs参数，并在任务之间保持泛化能力。对知名LLMs（即Llama2系列和OPT）的实验证明，AdaInfer节省了平均14.8%的计算资源，甚至在情感方面高达50%。

    arXiv:2403.02181v1 Announce Type: cross  Abstract: The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, "During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer saves an average of 14.8% of computational resources, even up to 50% on sentiment 
    
[^12]: 将关于信念的语言接地于贝叶斯心灵理论

    Grounding Language about Belief in a Bayesian Theory-of-Mind

    [https://arxiv.org/abs/2402.10416](https://arxiv.org/abs/2402.10416)

    语义基础置于贝叶斯心灵理论中，通过模拟人们共同推断出解释代理人行为的一致性目标、信念和计划集合，再通过认识逻辑评估有关代理人信念的陈述，解释了人类信念归因的分级性和组合性，以及其与目标和计划的密切联系。

    

    尽管信念是无法直接观察的心理状态，人类常常使用丰富的组合语言来描述他人的想法和知识。这项研究通过将信念陈述的语义基础置于贝叶斯心灵理论中，为解释人类如何解释他人隐藏的认识内容迈出了一步：通过建模人类如何共同推断出解释一个代理人行动的一致性目标、信念和计划集合，然后通过认识逻辑对有关代理人信念的陈述进行评估，我们的框架为信念提供了一个概念角色语义，解释了人类信念归因的分级性和组合性，以及它们与目标和计划的密切联系。我们通过研究人们在观察一个代理人解决问题时是如何归因目标和信念的来评估这一框架。

    arXiv:2402.10416v1 Announce Type: new  Abstract: Despite the fact that beliefs are mental states that cannot be directly observed, humans talk about each others' beliefs on a regular basis, often using rich compositional language to describe what others think and know. What explains this capacity to interpret the hidden epistemic content of other minds? In this paper, we take a step towards an answer by grounding the semantics of belief statements in a Bayesian theory-of-mind: By modeling how humans jointly infer coherent sets of goals, beliefs, and plans that explain an agent's actions, then evaluating statements about the agent's beliefs against these inferences via epistemic logic, our framework provides a conceptual role semantics for belief, explaining the gradedness and compositionality of human belief attributions, as well as their intimate connection with goals and plans. We evaluate this framework by studying how humans attribute goals and beliefs while watching an agent solve
    
[^13]: 重新思考模型重新基底和线性模态连接性

    Rethink Model Re-Basin and the Linear Mode Connectivity

    [https://arxiv.org/abs/2402.05966](https://arxiv.org/abs/2402.05966)

    本论文重新审视了模型重新基底的现象，并发现了现有匹配算法的不足。通过适当的重归一化，我们改进了匹配算法，并揭示了它与重归一化过程的相互作用。这为剪枝提供了新的理解，推动了一种轻量且有效的后剪枝插件的开发。

    

    最近的研究表明，对于足够宽的模型来说，大部分随机梯度下降（SGD）的解可以收敛到相同的基底，只是顺序可能不同。这种现象被称为模型重新基底的阶段，对于模型平均化有重要影响。然而，当前的重新基底策略在效果上存在局限性，因为对底层机制的理解不够全面。为了填补这一空白，我们的研究重新审视了标准做法，并揭示了现有匹配算法的频繁不足之处，我们通过适当的重归一化来缓解这些问题。通过引入更直接的分析方法，我们揭示了匹配算法与重归一化过程之间的相互作用。这种观点不仅澄清和改进了以前的研究结果，还促进了新的洞见。例如，它将线性模态连接性与剪枝联系起来，从而激发了一种轻量且有效的后剪枝插件，可以直接与任何现有的剪枝技术合并。

    Recent studies suggest that with sufficiently wide models, most SGD solutions can, up to permutation, converge into the same basin. This phenomenon, known as the model re-basin regime, has significant implications for model averaging. However, current re-basin strategies are limited in effectiveness due to a lack of comprehensive understanding of underlying mechanisms. Addressing this gap, our work revisits standard practices and uncovers the frequent inadequacies of existing matching algorithms, which we show can be mitigated through proper re-normalization. By introducing a more direct analytical approach, we expose the interaction between matching algorithms and re-normalization processes. This perspective not only clarifies and refines previous findings but also facilitates novel insights. For instance, it connects the linear mode connectivity to pruning, motivating a lightweight yet effective post-pruning plug-in that can be directly merged with any existing pruning techniques. Ou
    
[^14]: 鲁棒的提示优化用于对抗语言模型的破解攻击

    Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks

    [https://arxiv.org/abs/2401.17263](https://arxiv.org/abs/2401.17263)

    该论文提出了一种鲁棒的提示优化算法（RPO）用于对抗语言模型的破解攻击，通过梯度优化来确保输出的无害性，并成功降低了攻击成功率。

    

    尽管在人工智能对齐方面取得了一些进展，但语言模型（LM）仍然容易受到对抗性攻击或破解攻击的影响，其中对手修改输入提示以诱导有害行为。虽然已经提出了一些防御方法，但它们仅关注狭窄的威胁模型，并不能提供强大的防御。为了实现强大的防御，我们首次提出了用于对抗破解攻击的对抗目标，并提出了一种名为鲁棒提示优化（RPO）的算法，该算法利用基于梯度的令牌优化来确保输出的无害性。通过这种方法，我们得到了一个易于访问的后缀，显著改善了对破解攻击的强韧性，包括优化过程中出现的破解攻击以及未知的破解攻击，将攻击成功率从84%降低到8.66%，在20个破解攻击中。此外，我们还发现RPO对正常LM使用的影响较小，在适应性攻击下仍然有效，并且可以迁移到黑盒模型中，降低攻击成功率。

    Despite advances in AI alignment, language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior. While some defenses have been proposed, they focus on narrow threat models and fall short of a strong defense, which we posit should be effective, universal, and practical. To achieve this, we propose the first adversarial objective for defending LMs against jailbreaking attacks and an algorithm, robust prompt optimization (RPO), that uses gradient-based token optimization to enforce harmless outputs. This results in an easily accessible suffix that significantly improves robustness to both jailbreaks seen during optimization and unknown, held-out jailbreaks, reducing the attack success rate on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find that RPO has a minor effect on normal LM use, is successful under adaptive attacks, and can transfer to black-box models, reducing the success
    
[^15]: 逆向学习：通过捡取学习放置

    Working Backwards: Learning to Place by Picking

    [https://arxiv.org/abs/2312.02352](https://arxiv.org/abs/2312.02352)

    通过逆向抓取过程并利用拾取和放置问题的对称性，提出了一种通过拾取的放置方法，并用自主收集的演示直接训练策略，实现在接触受限环境下物体放置任务的自主收集和泛化。

    

    我们提出了一种通过拾取（PvP）的放置方法，可以自主收集适用于一系列放置任务的现实世界演示，其中物体必须被操纵到特定的接触限制位置。通过PvP，我们通过颠倒抓取过程并利用拾取和放置问题固有的对称性，接近于机器人物体放置演示的收集。具体而言，我们从一组最初位于目标放置位置的物体的抓取序列中获得放置演示。我们的系统可以在接触受限环境中收集数百个演示，而无需人类干预，这是通过结合两个模块实现的：触觉重新抓取和用于抓取的顺从控制。我们通过行为克隆直接从视觉观察中通过自主收集的演示中训练策略。通过这样做，策略可以推广到超出训练环境范围的物体放置场景。

    arXiv:2312.02352v2 Announce Type: replace-cross  Abstract: We present placing via picking (PvP), a method to autonomously collect real-world demonstrations for a family of placing tasks in which objects must be manipulated to specific contact-constrained locations. With PvP, we approach the collection of robotic object placement demonstrations by reversing the grasping process and exploiting the inherent symmetry of the pick and place problems. Specifically, we obtain placing demonstrations from a set of grasp sequences of objects initially located at their target placement locations. Our system can collect hundreds of demonstrations in contact-constrained environments without human intervention by combining two modules: tactile regrasping and compliant control for grasps. We train a policy directly from visual observations through behavioral cloning, using the autonomously-collected demonstrations. By doing so, the policy can generalize to object placement scenarios outside of the tra
    
[^16]: 基于学习的难度校准提升成员推理攻击的能力

    Learning-Based Difficulty Calibration for Enhanced Membership Inference Attacks. (arXiv:2401.04929v1 [cs.CR])

    [http://arxiv.org/abs/2401.04929](http://arxiv.org/abs/2401.04929)

    本文介绍了一种基于学习的难度校准的成员推理攻击方法，旨在显著提高低FPR下的TPR，以验证训练模型是否保护隐私。

    

    机器学习模型，特别是深度神经网络，目前是各种应用的重要组成部分，从医疗保健到金融。然而，使用敏感数据来训练这些模型引发了对隐私和安全的担忧。一种验证训练模型是否保护隐私的方法是成员推理攻击（MIA），它允许对手确定特定数据点是否是模型的训练数据集的一部分。虽然已经在文献中提出了一系列的MIA，但只有少数能够在低假阳性率（FPR）区域（0.01%~1%）实现较高的真阳性率（TPR）。这是实际应用于实际场景中的MIA必须考虑的关键因素。在本文中，我们提出了一种新颖的MIA方法，旨在显著提高低FPR的TPR。我们的方法名为基于学习的难度校准（LDC-MIA），通过使用神经网络分类器将数据记录以其难度级别进行表征。

    Machine learning models, in particular deep neural networks, are currently an integral part of various applications, from healthcare to finance. However, using sensitive data to train these models raises concerns about privacy and security. One method that has emerged to verify if the trained models are privacy-preserving is Membership Inference Attacks (MIA), which allows adversaries to determine whether a specific data point was part of a model's training dataset. While a series of MIAs have been proposed in the literature, only a few can achieve high True Positive Rates (TPR) in the low False Positive Rate (FPR) region (0.01%~1%). This is a crucial factor to consider for an MIA to be practically useful in real-world settings. In this paper, we present a novel approach to MIA that is aimed at significantly improving TPR at low FPRs. Our method, named learning-based difficulty calibration for MIA(LDC-MIA), characterizes data records by their hardness levels using a neural network clas
    
[^17]: 将领域专家中心本体设计集成到面向物理生产系统的CRISP-DM中

    Integration of Domain Expert-Centric Ontology Design into the CRISP-DM for Cyber-Physical Production Systems. (arXiv:2307.11637v1 [cs.AI])

    [http://arxiv.org/abs/2307.11637](http://arxiv.org/abs/2307.11637)

    本文提出了一种将领域专家中心本体设计集成到CRISP-DM中的方法，以解决公司在应用数据驱动项目时所遇到的挑战。

    

    在工业4.0和物理生产系统领域，大量有潜在价值的数据被生成。机器学习和数据挖掘方法已经被证明在从收集的数据中提取复杂和隐含的模式方面是有希望的。所得到的知识可以用于改进诸如诊断或维护计划等任务。然而，这样的数据驱动项目通常需要大量的时间来理解和准备数据，因此常常导致失败。在处理工业4.0环境中的挑战时，领域特定本体的应用已经证明了其优越性。然而，针对物理生产系统的本体设计工作流程和工件尚未系统地集成到CRISP-DM中。因此，本文旨在提出一种综合方法来充分利用领域专家中心本体设计在CRISP-DM中的优势。

    In the age of Industry 4.0 and Cyber-Physical Production Systems (CPPSs) vast amounts of potentially valuable data are being generated. Methods from Machine Learning (ML) and Data Mining (DM) have proven to be promising in extracting complex and hidden patterns from the data collected. The knowledge obtained can in turn be used to improve tasks like diagnostics or maintenance planning. However, such data-driven projects, usually performed with the Cross-Industry Standard Process for Data Mining (CRISP-DM), often fail due to the disproportionate amount of time needed for understanding and preparing the data. The application of domain-specific ontologies has demonstrated its advantageousness in a wide variety of Industry 4.0 application scenarios regarding the aforementioned challenges. However, workflows and artifacts from ontology design for CPPSs have not yet been systematically integrated into the CRISP-DM. Accordingly, this contribution intends to present an integrated approach so t
    
[^18]: 用Transformer学习超关系型和数值知识图中的表征学习

    Representation Learning on Hyper-Relational and Numeric Knowledge Graphs with Transformers. (arXiv:2305.18256v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.18256](http://arxiv.org/abs/2305.18256)

    本文提出了一个名为HyNT的框架，用于学习超关系型知识图的表示，包括数值文字。该框架使用上下文Transformer和预测Transformer，通过学习三元组和其限定词之间的相关性以及数值信息来获得模型。

    

    近期研究了一个超关系型知识图谱，其中三元组与限定词集合相关联; 一个限定词由关系和实体组成，为三元组提供辅助信息。现有的超关系型知识图嵌入方法假定实体是离散对象，但有些信息应使用数值表示，例如(J.R.R.，出生于，1892)。同时，三元组(J.R.R.，就读于，牛津大学)可以与限定词(开始时间，1911)相关联。在本文中，我们提出了一个名为HyNT的统一框架，用于学习包含三元组或限定词中数值文字的超关系型知识图的表示。我们定义了一个上下文Transformer和一个预测Transformer，来学习表示，不仅基于三元组和其限定词之间的相关性，还基于数值信息。通过学习三元组和限定词的紧凑表示，并将它们馈送给Transformer来获得模型

    A hyper-relational knowledge graph has been recently studied where a triplet is associated with a set of qualifiers; a qualifier is composed of a relation and an entity, providing auxiliary information for a triplet. While existing hyper-relational knowledge graph embedding methods assume that the entities are discrete objects, some information should be represented using numeric values, e.g., (J.R.R., was born in, 1892). Also, a triplet (J.R.R., educated at, Oxford Univ.) can be associated with a qualifier such as (start time, 1911). In this paper, we propose a unified framework named HyNT that learns representations of a hyper-relational knowledge graph containing numeric literals in either triplets or qualifiers. We define a context transformer and a prediction transformer to learn the representations based not only on the correlations between a triplet and its qualifiers but also on the numeric information. By learning compact representations of triplets and qualifiers and feeding 
    
[^19]: 基于深度强化学习的边缘资源任务部署和扩展方法用于车载网络服务提供

    A Deep RL Approach on Task Placement and Scaling of Edge Resources for Cellular Vehicle-to-Network Service Provisioning. (arXiv:2305.09832v1 [cs.AI])

    [http://arxiv.org/abs/2305.09832](http://arxiv.org/abs/2305.09832)

    本文提出了一种基于深度强化学习的分散式方法，用于解决车联网服务提供中的任务部署和边缘资源的扩展问题。

    

    “车联网”正处于我们社会数字化转型的前沿。本文提出了一种分散式方法用于提供车辆通联网（C-V2N）服务，解决服务任务部署和边缘资源的扩展问题。我们证明了这个联合问题的复杂性，并提出了一个两个问题的联接方式，采用了基于贪心算法的关于任务部署的方法和基于 Deep Deterministic Policy Gradient (DDPG) 的扩展方法。本文还对我们的方法进行了基准测试，重点关注了扩展代理与多个状态下最先进的扩展方法的性能比较。

    Cellular-Vehicle-to-Everything (C-V2X) is currently at the forefront of the digital transformation of our society. By enabling vehicles to communicate with each other and with the traffic environment using cellular networks, we redefine transportation, improving road safety and transportation services, increasing efficiency of traffic flows, and reducing environmental impact. This paper proposes a decentralized approach for provisioning Cellular Vehicular-to-Network (C-V2N) services, addressing the coupled problems of service task placement and scaling of edge resources. We formalize the joint problem and prove its complexity. We propose an approach to tackle it, linking the two problems, employing decentralized decision-making using (i) a greedy approach for task placement and (ii) a Deep Deterministic Policy Gradient (DDPG) based approach for scaling. We benchmark the performance of our approach, focusing on the scaling agent, against several State-of-the-Art (SoA) scaling approaches
    
[^20]: 机器心理学：利用心理学方法探究大型语言模型的新兴能力和行为

    Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. (arXiv:2303.13988v1 [cs.CL])

    [http://arxiv.org/abs/2303.13988](http://arxiv.org/abs/2303.13988)

    本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。

    

    大型语言模型（LLM）是将人工智能系统与人类交流和日常生活紧密结合的先锋。由于快速技术进步和其极高的通用性，现今LLM已经拥有数百万用户，并正处于成为主要信息检索、内容生成、问题解决等技术的前沿。因此，对其进行全面评估和审查显得尤为重要。由于当前LLM中出现愈加复杂和新颖的行为模式，可将其视为参与人类心理实验的对象，以便更为全面地评估其能力。为此，本文引入了一个名为"机器心理学"的新兴研究领域。本文概述了各类心理学分支如何为LLM的行为测试提供有用参考。同时，本文规范了机器心理学研究的方法论标准，特别是专注于提示设计政策的制定。此外，它还描述了行为测试结果如何为未来的LLM发展提供指导。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Due to rapid technological advances and their extreme versatility, LLMs nowadays have millions of users and are at the cusp of being the main go-to technology for information retrieval, content generation, problem-solving, etc. Therefore, it is of great importance to thoroughly assess and scrutinize their capabilities. Due to increasingly complex and novel behavioral patterns in current LLMs, this can be done by treating them as participants in psychology experiments that were originally designed to test humans. For this purpose, the paper introduces a new field of research called "machine psychology". The paper outlines how different subfields of psychology can inform behavioral tests for LLMs. It defines methodological standards for machine psychology research, especially by focusing on policies for prompt designs. Additionally, it describes how behaviora
    
[^21]: 学习ACOPF的分桶主动采样

    Bucketized Active Sampling for Learning ACOPF. (arXiv:2208.07497v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.07497](http://arxiv.org/abs/2208.07497)

    本文提出了一种新颖的主动学习框架——分桶主动采样（BAS），旨在在时间限制内训练最佳的OPF代理。BAS将输入分布分成桶，并使用收集函数确定下一次采样的位置。实验结果显示了BAS的好处。

    

    本文考虑最优潮流（OPF）的优化代理，即近似OPF的输入/输出关系的机器学习模型。最近的研究集中在证明这些代理可以具有较高的准确性。然而，它们的训练需要大量的数据，每个实例都需要对输入分布的样本进行OPF的（离线）求解。为了满足市场清算应用的要求，本文提出了一种新颖的主动学习框架——分桶主动采样（BAS），旨在在时间限制内训练最佳的OPF代理。BAS将输入分布分成桶，并使用收集函数确定下一次采样的位置。通过将相同的分桶应用于验证集，BAS利用标记的验证样本来选择未标记的样本。BAS还依赖于随时间增加和减少的自适应学习率。实验结果显示了BAS的好处。

    This paper considers optimization proxies for Optimal Power Flow (OPF), i.e., machine-learning models that approximate the input/output relationship of OPF. Recent work has focused on showing that such proxies can be of high fidelity. However, their training requires significant data, each instance necessitating the (offline) solving of an OPF for a sample of the input distribution. To meet the requirements of market-clearing applications, this paper proposes Bucketized Active Sampling (BAS), a novel active learning framework that aims at training the best possible OPF proxy within a time limit. BAS partitions the input distribution into buckets and uses an acquisition function to determine where to sample next. By applying the same partitioning to the validation set, BAS leverages labeled validation samples in the selection of unlabeled samples. BAS also relies on an adaptive learning rate that increases and decreases over time. Experimental results demonstrate the benefits of BAS.
    
[^22]: MetaCOG: 学习元认知以恢复实际存在的物体

    MetaCOG: Learning a Metacognition to Recover What Objects Are Actually There. (arXiv:2110.03105v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2110.03105](http://arxiv.org/abs/2110.03105)

    MetaCOG是一个学习元认知的模型，通过学习目标检测器的可靠性表示，增加了目标检测器的鲁棒性，而无需反馈和地面真实的物体标签。

    

    人类不仅根据我们所看到的内容形成关于世界的表征，还学习关于我们自己视觉如何工作的元认知表征。这使我们能够识别出我们的视觉不可靠（例如，当我们意识到我们正在经历视觉错觉时），并使我们能够对我们所看到的内容提出质疑。受到这种人类能力的启发，我们提出了MetaCOG：一种通过学习其可靠性表示来增加目标检测器的鲁棒性的模型，并且在没有反馈的情况下实现。具体而言，MetaCOG是一个层次概率模型，对一个三维场景中的物体和检测器产生的输出表达了一个联合分布。当与现成的目标检测器配对使用时，MetaCOG将检测结果作为输入，并推断出检测器错漏检某些类别的物体和虚构不存在的物体的倾向，而无需访问地面真实的物体标签。

    Humans not only form representations about the world based on what we see, but also learn meta-cognitive representations about how our own vision works. This enables us to recognize when our vision is unreliable (e.g., when we realize that we are experiencing a visual illusion) and enables us to question what we see. Inspired by this human capacity, we present MetaCOG: a model that increases the robustness of object detectors by learning representations of their reliability, and does so without feedback. Specifically, MetaCOG is a hierarchical probabilistic model that expresses a joint distribution over the objects in a 3D scene and the outputs produced by a detector. When paired with an off-the-shelf object detector, MetaCOG takes detections as input and infers the detector's tendencies to miss objects of certain categories and to hallucinate objects that are not actually present, all without access to ground-truth object labels. When paired with three modern neural object detectors, 
    

