# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LC-LLM: Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models](https://arxiv.org/abs/2403.18344) | 该论文提出了一个使用大型语言模型的可解释性车道变换预测模型，将车道变换预测任务重新构建为语言建模问题，以提高长期预测准确性和可解释性。 |
| [^2] | [Threats, Attacks, and Defenses in Machine Unlearning: A Survey](https://arxiv.org/abs/2403.13682) | 机器遗忘（MU）通过知识去除过程来解决训练数据相关的人工智能治理问题，提高了AI系统的安全和负责任使用。 |
| [^3] | [Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model](https://arxiv.org/abs/2403.13244) | 介绍了一个多约束分子生成大型语言模型TSMMG，通过整合多个小模型和工具来帮助生成符合描述的新分子，在各种约束任务中表现优秀。 |
| [^4] | [Offline Imitation of Badminton Player Behavior via Experiential Contexts and Brownian Motion](https://arxiv.org/abs/2403.12406) | 本文提出了RallyNet，这是一种新颖的用于羽毛球运动员行为的分层离线模仿学习模型，能够捕捉选手的决策依赖关系，解决了直接应用现有方法时可能遇到的层次结构和轮流采取行动导致的复合效应问题。 |
| [^5] | [Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization](https://arxiv.org/abs/2403.10967) | 学习上下文世界模型有助于提高在未知上下文下的零样点泛化能力。 |
| [^6] | [Dissecting Deep RL with High Update Ratios: Combatting Value Overestimation and Divergence](https://arxiv.org/abs/2403.05996) | 本研究剖析了深度强化学习中的首要偏差现象，发现在大量更新比例下，价值高估是导致学习失败的根本挑战。 |
| [^7] | [Aligning Large Language Models for Controllable Recommendations](https://arxiv.org/abs/2403.05063) | 通过引入监督学习任务和强化学习对齐程序，研究人员提出了一种方法来改善大型语言模型适应推荐指令和减少格式错误的能力。 |
| [^8] | [PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering](https://arxiv.org/abs/2403.05053) | 本文提出了PrimeComposer，一种更快的逐步组合扩散方式，用于图像合成，主要专注于前景生成，从而解决了合成中的凝聚混乱和外观信息丢失问题，并避免了不必要的背景生成导致的前景生成质量下降。 |
| [^9] | [Class-incremental Learning for Time Series: Benchmark and Evaluation](https://arxiv.org/abs/2402.12035) | 时间序列增量学习问题在图像和语言领域取得了进展，但在时间序列数据方面仍然相对较少研究，本文提出了一个全面的评估和基准测试方法。 |
| [^10] | [eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data](https://arxiv.org/abs/2402.08831) | 本文利用开源的大规模高质量指导数据集ECInstruct，通过指导调优通用语言模型，开发了一系列电子商务LLMs（eCeLLM），在电子商务中表现出了显著的优势。 |
| [^11] | [On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks](https://arxiv.org/abs/2402.08115) | 这项研究对大型语言模型在推理和规划任务中的自我验证能力进行了系统研究，并发现了迭代提示的有效性。 |
| [^12] | [Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap](https://arxiv.org/abs/2402.06046) | 2023年10月，一起GM Cruise机器人出租车与行人相撞的事故给公司造成了巨大的动荡，同时也揭示了该公司在处理事故后的失误。这一事件的解剖提供了在技术、操作安全实践和组织反应方面的安全教训。 |
| [^13] | [Variational Flow Models: Flowing in Your Style](https://arxiv.org/abs/2402.02977) | 我们引入了一种变分流模型的方法，并提出了一种系统的无需训练的转换方法，使得快速采样成为可能，同时保持了采样的准确性和效率。 |
| [^14] | [Empowering Private Tutoring by Chaining Large Language Models](https://arxiv.org/abs/2309.08112) | 通过链式连接大型语言模型，开发了一种全面智能辅导系统，实现了自动课程规划、个性化指导和灵活测验评估。 |
| [^15] | [Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending.](http://arxiv.org/abs/2401.16458) | 本文研究了如何利用P2P借贷平台上借款人提供的文本描述来构建风险指标。结果显示，利用大型语言模型生成的风险评分可以明显提高信用风险分类器的性能。 |
| [^16] | [Mission: Impossible Language Models.](http://arxiv.org/abs/2401.06416) | 本文为了支持大型语言模型(LLMs)能够学习不可能的语言的观点，开发了一组人工合成的不可能语言，并通过评估GPT-2小型模型的学习能力得出了结论。 |
| [^17] | [DrawTalking: Building Interactive Worlds by Sketching and Speaking.](http://arxiv.org/abs/2401.05631) | 用户通过草图和语言建立互动世界的交互式方法，具有用户控制和灵活性，无需编程即可实现编程功能。适用于各种创造性探索性场景。 |
| [^18] | [Reliable Academic Conference Question Answering: A Study Based on Large Language Model.](http://arxiv.org/abs/2310.13028) | 本研究以大型语言模型为基础，开发了可靠的学术会议问答系统，通过组织半结构化的会议数据并进行人工标注，解决了研究人员在获取准确、最新信息时的需求。 |
| [^19] | [Unpacking Human-AI Interaction in Safety-Critical Industries: A Systematic Literature Review.](http://arxiv.org/abs/2310.03392) | 在安全关键行业中确保高质量的人工智能与人类互动（HAII）十分重要，然而目前对于HAII的研究零散且缺乏一致性。本论文通过系统文献综述，发现没有一个一致使用的术语描述HAII，并且五个因素影响HAII，即用户特征和背景、AI界面和功能、用户信任、监控和反馈，以及工作上的团队结构。这些发现为改进安全关键行业中的HAII提供了指导。 |
| [^20] | [Time-Series Classification in Smart Manufacturing Systems: An Experimental Evaluation of State-of-the-Art Machine Learning Algorithms.](http://arxiv.org/abs/2310.02812) | 本研究通过严格实验评估了智能制造系统中最先进的机器学习和深度学习算法在时间序列分类任务中的性能，填补了该领域的研究空白。 |
| [^21] | [LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples.](http://arxiv.org/abs/2310.01469) | LLM似乎具有丰富的知识和适应多种任务的能力，但我们不能完全信任它们的回答，因为它们会出现幻觉，即捏造不存在的事实以欺骗用户。本文证明了由随机标记组成的无意义提示也能引起LLM产生幻觉回应，并提出了一种对抗方式的自动幻觉触发方法作为幻觉攻击，同时提出了一种简单而有效的防御策略。 |
| [^22] | [TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled Prescriptive Maintenance Framework.](http://arxiv.org/abs/2309.16935) | TranDRL是一种基于Transformer驱动的深度强化学习支持的预防性维护框架，结合了复杂时间模式捕捉和经济高效维护建议，显著提高了剩余寿命（RUL）预测准确性和维护行动优化。 |
| [^23] | [On CNF formulas irredundant with respect to unit clause propagation.](http://arxiv.org/abs/2309.01750) | 对于单子句传播而言，在CNF公式中不可简化的公式，其大小与最小可等价的公式大小的比值最大为n^2，其中n是变量数量。一般上界不会小于n/ln n倍。 |
| [^24] | [LAMBO: Large Language Model Empowered Edge Intelligence.](http://arxiv.org/abs/2308.15078) | LAMBO是一种基于大型语言模型的边缘智能框架，用于移动边缘计算。它解决了传统深度卸载架构的问题，并提供了高性能的决策模块和强化学习模块。 |
| [^25] | [Furnishing Sound Event Detection with Language Model Abilities.](http://arxiv.org/abs/2308.11530) | 本文提出了一种增强声音事件检测的方法，通过对齐音频特征和文本特征来实现声音事件分类和时间定位。该方法利用语言模型的语义能力直接生成序列，相比传统方法更简洁全面，并通过实验证明了其在时间戳捕获和事件分类方面的有效性。 |
| [^26] | [Inductive Meta-path Learning for Schema-complex Heterogeneous Information Networks.](http://arxiv.org/abs/2307.03937) | 这项研究提出了一种针对模式复杂的异构信息网络的归纳元路径学习框架SchemaWalk。 |
| [^27] | [Large AI Model-Based Semantic Communications.](http://arxiv.org/abs/2307.03492) | 本文提出了一种基于大型AI模型的语义通信框架（LAM-SC），利用该框架可以克服知识库构建过程中面临的问题，并在图像数据领域实现了语义分割、语义集成和自适应语义压缩。 |
| [^28] | [A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises.](http://arxiv.org/abs/2306.04802) | 本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。 |
| [^29] | [Evidence of Meaning in Language Models Trained on Programs.](http://arxiv.org/abs/2305.11169) | 该论文证明了，通过在程序语料库上训练语言模型，即使没有针对学习语言语义提供归纳偏差，语言模型仍然能够学习含义。线性探测器能够从模型状态中提取程序状态的抽象，准确性与模型泛化到新程序的能力显著相关。 |
| [^30] | [Context-dependent communication under environmental constraints.](http://arxiv.org/abs/2305.05821) | 本文研究了在压缩词汇量的情况下，如何利用环境压力促进情境依赖性沟通的出现，并研究了在接收者无法处理歧义的情况下，发送者如何利用环境的制约因素实现沟通。 |
| [^31] | [Vision Learners Meet Web Image-Text Pairs.](http://arxiv.org/abs/2301.07088) | 本论文提出了一种基于网络数据的新型视觉学习方法MUlti-modal Generator (MUG)。在视觉数据集的转移学习任务上取得了最先进的表现，是之前最佳结果的3.4%和2.2%的提升。 |

# 详细

[^1]: LC-LLM: 使用大型语言模型解释性车道变换意图和轨迹预测

    LC-LLM: Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models

    [https://arxiv.org/abs/2403.18344](https://arxiv.org/abs/2403.18344)

    该论文提出了一个使用大型语言模型的可解释性车道变换预测模型，将车道变换预测任务重新构建为语言建模问题，以提高长期预测准确性和可解释性。

    

    为了确保在动态环境中安全驾驶，自动驾驶车辆应具备准确预测周围车辆车道变换意图并预测其未来轨迹的能力。本文通过提出LC-LLM，一个可解释性车道变换预测模型，利用大型语言模型（LLM）的强大推理能力和自我解释能力来解决现有运动预测方法在长期预测准确性和可解释性方面存在的问题。我们将车道变换预测任务重新构建为一个语言建模问题，通过自然语言处理异构驾驶场景信息作为LLM的输入提示，并使用监督微调技术专门为我们的车道变换预测任务定制LLM。这使我们能够利用LLM的强大功能

    arXiv:2403.18344v1 Announce Type: new  Abstract: To ensure safe driving in dynamic environments, autonomous vehicles should possess the capability to accurately predict the lane change intentions of surrounding vehicles in advance and forecast their future trajectories. Existing motion prediction approaches have ample room for improvement, particularly in terms of long-term prediction accuracy and interpretability. In this paper, we address these challenges by proposing LC-LLM, an explainable lane change prediction model that leverages the strong reasoning capabilities and self-explanation abilities of Large Language Models (LLMs). Essentially, we reformulate the lane change prediction task as a language modeling problem, processing heterogeneous driving scenario information in natural language as prompts for input into the LLM and employing a supervised fine-tuning technique to tailor the LLM specifically for our lane change prediction task. This allows us to utilize the LLM's powerfu
    
[^2]: 机器学习中的威胁、攻击和防御：一项调查

    Threats, Attacks, and Defenses in Machine Unlearning: A Survey

    [https://arxiv.org/abs/2403.13682](https://arxiv.org/abs/2403.13682)

    机器遗忘（MU）通过知识去除过程来解决训练数据相关的人工智能治理问题，提高了AI系统的安全和负责任使用。

    

    机器遗忘（MU）最近引起了相当大的关注，因为它有潜力通过从训练的机器学习模型中消除特定数据的影响来实现安全人工智能。这个被称为知识去除的过程解决了与训练数据相关的人工智能治理问题，如数据质量、敏感性、版权限制和过时性。这种能力对于确保遵守诸如被遗忘权等隐私法规也至关重要。此外，有效的知识去除有助于减轻有害结果的风险，防范偏见、误导和未经授权的数据利用，从而增强了AI系统的安全和负责任使用。已经开展了设计高效的遗忘方法的工作，通过研究MU服务以与现有的机器学习作为服务集成，使用户能够提交请求从训练语料库中删除特定数据。

    arXiv:2403.13682v2 Announce Type: replace-cross  Abstract: Machine Unlearning (MU) has gained considerable attention recently for its potential to achieve Safe AI by removing the influence of specific data from trained machine learning models. This process, known as knowledge removal, addresses AI governance concerns of training data such as quality, sensitivity, copyright restrictions, and obsolescence. This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten. Furthermore, effective knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the safe and responsible use of AI systems. Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service, allowing users to submit requests to remove specific data from the training corpus. However, 
    
[^3]: 使用师生大型语言模型进行多约束分子生成

    Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model

    [https://arxiv.org/abs/2403.13244](https://arxiv.org/abs/2403.13244)

    介绍了一个多约束分子生成大型语言模型TSMMG，通过整合多个小模型和工具来帮助生成符合描述的新分子，在各种约束任务中表现优秀。

    

    尽管已经提出了各种模型和计算工具用于分子的结构和性质分析，但生成符合所有期望结构和性质的分子仍然是一个挑战。在这里，我们介绍了一个多约束分子生成大型语言模型TSMMG，类似于学生，该模型整合了来自各种小模型和工具（即“老师”）的知识。为了训练TSMMG，我们通过从这些‘老师’中提取的分子知识构建了大量文本-分子对，使其能够通过各种文本提示生成符合描述的新分子。我们通过实验证明，TSMMG在生成符合复杂、自然语言描述的两、三和四约束任务的分子方面表现出色，平均分子有效性超过99％，成功率分别为88.08％、65.27％和61.44％。该模型还ex

    arXiv:2403.13244v1 Announce Type: new  Abstract: While various models and computational tools have been proposed for structure and property analysis of molecules, generating molecules that conform to all desired structures and properties remains a challenge. Here, we introduce a multi-constraint molecular generation large language model, TSMMG, which, akin to a student, incorporates knowledge from various small models and tools, namely, the 'teachers'. To train TSMMG, we construct a large set of text-molecule pairs by extracting molecular knowledge from these 'teachers', enabling it to generate novel molecules that conform to the descriptions through various text prompts. We experimentally show that TSMMG remarkably performs in generating molecules meeting complex, natural language-described property requirements across two-, three-, and four-constraint tasks, with an average molecular validity of over 99% and success ratio of 88.08%, 65.27%, and 61.44%, respectively. The model also ex
    
[^4]: 通过经验背景和布朗运动进行羽毛球运动员行为的离线模仿

    Offline Imitation of Badminton Player Behavior via Experiential Contexts and Brownian Motion

    [https://arxiv.org/abs/2403.12406](https://arxiv.org/abs/2403.12406)

    本文提出了RallyNet，这是一种新颖的用于羽毛球运动员行为的分层离线模仿学习模型，能够捕捉选手的决策依赖关系，解决了直接应用现有方法时可能遇到的层次结构和轮流采取行动导致的复合效应问题。

    

    在动态和快节奏的基于轮次的体育运动中，羽毛球作为一种需要选手依赖变化的决策的固有范例而脱颖而出。虽然在顺序决策的离线专家数据中学习的进展在各个领域中都有所涉及，但如何从离线羽毛球比赛中模仿人类选手的比赛行为在很大程度上尚未被探索。复制对手的行为有益于选手，使他们能够在比赛前有方向地进行战略发展。然而，直接应用现有方法会受到比赛的内在层次结构和由于轮流采取行动的选手轮次性质而产生的复合效应的困扰。在本文中，我们提出了RallyNet，一种新颖的用于羽毛球运动员行为的分层离线模仿学习模型：（i）RallyNet通过将决策过程建模为...

    arXiv:2403.12406v1 Announce Type: new  Abstract: In the dynamic and rapid tactic involvements of turn-based sports, badminton stands out as an intrinsic paradigm that requires alter-dependent decision-making of players. While the advancement of learning from offline expert data in sequential decision-making has been witnessed in various domains, how to rally-wise imitate the behaviors of human players from offline badminton matches has remained underexplored. Replicating opponents' behavior benefits players by allowing them to undergo strategic development with direction before matches. However, directly applying existing methods suffers from the inherent hierarchy of the match and the compounding effect due to the turn-based nature of players alternatively taking actions. In this paper, we propose RallyNet, a novel hierarchical offline imitation learning model for badminton player behaviors: (i) RallyNet captures players' decision dependencies by modeling decision-making processes as 
    
[^5]: 梦想中的许多世界：学习上下文世界模型有助于零样点泛化

    Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization

    [https://arxiv.org/abs/2403.10967](https://arxiv.org/abs/2403.10967)

    学习上下文世界模型有助于提高在未知上下文下的零样点泛化能力。

    

    零样点泛化（Zero-shot generalization，ZSG）到未见过的动态对于创建具有普遍能力的体系代理是一个重大挑战。为了解决更广泛的挑战，我们从上下文强化学习（contextual reinforcement learning，cRL）的简单设置开始，假设可观察到参数化系统动态变化的上下文值，如机器人的质量或尺寸，而不对马尔可夫状态的可观察性做进一步简化假设。为了实现对未知上下文变化的ZSG目标，我们提出了上下文循环状态空间模型（contextual recurrent state-space model，cRSSM），它对Dreamer（v3）（Hafner等人，2023年）的世界模型进行了修改，使得世界模型可以融入上下文以从观察中推断潜在的马尔可夫状态并建模潜在动态。我们的实验表明，这种系统性地将上下文纳入其中提高了在“梦境”训练的策略的ZSG能力。

    arXiv:2403.10967v1 Announce Type: cross  Abstract: Zero-shot generalization (ZSG) to unseen dynamics is a major challenge for creating generally capable embodied agents. To address the broader challenge, we start with the simpler setting of contextual reinforcement learning (cRL), assuming observability of the context values that parameterize the variation in the system's dynamics, such as the mass or dimensions of a robot, without making further simplifying assumptions about the observability of the Markovian state. Toward the goal of ZSG to unseen variation in context, we propose the contextual recurrent state-space model (cRSSM), which introduces changes to the world model of the Dreamer (v3) (Hafner et al., 2023). This allows the world model to incorporate context for inferring latent Markovian states from the observations and modeling the latent dynamics. Our experiments show that such systematic incorporation of the context improves the ZSG of the policies trained on the ``dreams
    
[^6]: 用高更新比例剖析深度强化学习：应对价值高估和发散

    Dissecting Deep RL with High Update Ratios: Combatting Value Overestimation and Divergence

    [https://arxiv.org/abs/2403.05996](https://arxiv.org/abs/2403.05996)

    本研究剖析了深度强化学习中的首要偏差现象，发现在大量更新比例下，价值高估是导致学习失败的根本挑战。

    

    我们展示了深度强化学习在设置中可以在梯度更新次数大大超过环境样本数量的情况下保持学习能力，而无需重置网络参数。在这种大量更新与数据比例的情况下，尼基辛等人 (2022) 的最近一项研究指出了一个首要偏差的出现，即代理在早期交互中过拟合并淡化后续经验，从而损害了其学习能力。在这项工作中，我们深入解析了导致首要偏差的现象。我们检查了应该导致学习失败的训练早期阶段，并发现一个根本性挑战是长期以来存在的问题：价值高估。我们发现Q值不仅在分布外数据上被高估，而且在分布内数据上也是如此，可以追溯到由优化器动量推动的未见的动作预测。我们采用了一种简单的单位球归一化方法，可以在大更新比例下实现学习。

    arXiv:2403.05996v1 Announce Type: cross  Abstract: We show that deep reinforcement learning can maintain its ability to learn without resetting network parameters in settings where the number of gradient updates greatly exceeds the number of environment samples. Under such large update-to-data ratios, a recent study by Nikishin et al. (2022) suggested the emergence of a primacy bias, in which agents overfit early interactions and downplay later experience, impairing their ability to learn. In this work, we dissect the phenomena underlying the primacy bias. We inspect the early stages of training that ought to cause the failure to learn and find that a fundamental challenge is a long-standing acquaintance: value overestimation. Overinflated Q-values are found not only on out-of-distribution but also in-distribution data and can be traced to unseen action prediction propelled by optimizer momentum. We employ a simple unit-ball normalization that enables learning under large update ratios
    
[^7]: 调整大型语言模型以实现可控的推荐

    Aligning Large Language Models for Controllable Recommendations

    [https://arxiv.org/abs/2403.05063](https://arxiv.org/abs/2403.05063)

    通过引入监督学习任务和强化学习对齐程序，研究人员提出了一种方法来改善大型语言模型适应推荐指令和减少格式错误的能力。

    

    受到大型语言模型（LLMs）异常的智能启发，研究人员已开始探索将它们应用于开创下一代推荐系统 - 这些系统具有对话、可解释和可控的特性。然而，现有文献主要集中在将领域特定知识整合到LLMs中以提高准确性，通常忽略了遵循指令的能力。为填补这一空白，我们首先引入一组监督学习任务，标记来源于传统推荐模型的标签，旨在明确改善LLMs遵循特定推荐指令的熟练程度。随后，我们开发了一种基于强化学习的对齐程序，进一步加强了LLMs在响应用户意图和减少格式错误方面的能力。通过在两个真实世界数据集上进行广泛实验，我们的方法标记着

    arXiv:2403.05063v1 Announce Type: cross  Abstract: Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems - systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy, often neglecting the ability to follow instructions. To address this gap, we initially introduce a collection of supervised learning tasks, augmented with labels derived from a conventional recommender model, aimed at explicitly improving LLMs' proficiency in adhering to recommendation-specific instructions. Subsequently, we develop a reinforcement learning-based alignment procedure to further strengthen LLMs' aptitude in responding to users' intentions and mitigating formatting errors. Through extensive experiments on two real-world datasets, our method markedl
    
[^8]: PrimeComposer：用于图像合成的快速逐步组合扩散方法和带有注意力引导的技术

    PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering

    [https://arxiv.org/abs/2403.05053](https://arxiv.org/abs/2403.05053)

    本文提出了PrimeComposer，一种更快的逐步组合扩散方式，用于图像合成，主要专注于前景生成，从而解决了合成中的凝聚混乱和外观信息丢失问题，并避免了不必要的背景生成导致的前景生成质量下降。

    

    图像合成涉及将给定对象无缝地整合到特定的视觉环境中。目前无需训练的方法依赖于从几个采样器中组合注意力权重来引导生成器。然而，由于这些权重来自不同的上下文，它们的组合导致在合成中凝聚混乱和外观信息的丢失。在该任务中，它们过多关注背景生成，即使在这项任务中是不必要的，这些问题恶化。这不仅减慢了推理速度，还损害了前景生成质量。此外，这些方法还在过渡区域引入了不需要的伪影。在本文中，我们将图像合成形式化为一项基于主题的局部编辑任务，仅专注于前景生成。在每一步中，编辑后的前景与噪声背景相结合，以保持场景一致性。为了解决剩下的问题，我们提出了PrimeComposer，一种更快的tr

    arXiv:2403.05053v1 Announce Type: cross  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. The current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion in synthesis and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only slows down inference but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tr
    
[^9]: 时间序列的增量式学习: 基准和评估

    Class-incremental Learning for Time Series: Benchmark and Evaluation

    [https://arxiv.org/abs/2402.12035](https://arxiv.org/abs/2402.12035)

    时间序列增量学习问题在图像和语言领域取得了进展，但在时间序列数据方面仍然相对较少研究，本文提出了一个全面的评估和基准测试方法。

    

    现实环境本质上是非平稳的，经常会随时间引入新的类别。这在时间序列分类中尤为常见，比如在医疗保健领域出现新的疾病分类，或者在人类活动识别中添加新的活动。在这种情况下，需要一个学习系统能够有效地吸收新的类别，同时避免对旧类别的灾难性遗忘，这就引发了增量式学习问题。然而，尽管在图像和语言领域取得了令人鼓舞的进展，但针对时间序列数据的增量式学习仍然相对较少研究。现有研究存在实验设计不一致的问题，需要对方法在各种数据集上进行全面评估和基准测试。为此，我们首先概述了时间序列增量学习（TSCIL）问题，突出了其独特挑战，并覆盖了...

    arXiv:2402.12035v1 Announce Type: cross  Abstract: Real-world environments are inherently non-stationary, frequently introducing new classes over time. This is especially common in time series classification, such as the emergence of new disease classification in healthcare or the addition of new activities in human activity recognition. In such cases, a learning system is required to assimilate novel classes effectively while avoiding catastrophic forgetting of the old ones, which gives rise to the Class-incremental Learning (CIL) problem. However, despite the encouraging progress in the image and language domains, CIL for time series data remains relatively understudied. Existing studies suffer from inconsistent experimental designs, necessitating a comprehensive evaluation and benchmarking of methods across a wide range of datasets. To this end, we first present an overview of the Time Series Class-incremental Learning (TSCIL) problem, highlight its unique challenges, and cover the 
    
[^10]: eCeLLM：从大规模高质量指导数据中将大型语言模型推广到电子商务中

    eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data

    [https://arxiv.org/abs/2402.08831](https://arxiv.org/abs/2402.08831)

    本文利用开源的大规模高质量指导数据集ECInstruct，通过指导调优通用语言模型，开发了一系列电子商务LLMs（eCeLLM），在电子商务中表现出了显著的优势。

    

    通过在开发有效的电子商务模型方面做出巨大努力，传统的电子商务模型在通用电子商务建模上取得了有限的成功，并且在新用户和新产品上的表现不佳——这是一个典型的领域外泛化挑战。与此同时，大型语言模型(LLMs)在许多领域展示出了出色的通用建模和领域外泛化能力。为了充分发挥它们在电子商务中的作用，本文构建了ECInstruct，这是第一个面向电子商务的开源、大规模和高质量的指导数据集。利用ECInstruct，我们通过指导调优通用语言模型开发了一系列电子商务LLMs，称为eCeLLM。我们的综合实验和评估表明，eCeLLM模型在内部环境中明显优于基准模型，包括最先进的GPT-4和最先进的特定任务模型。

    arXiv:2402.08831v1 Announce Type: cross Abstract: With tremendous efforts on developing effective e-commerce models, conventional e-commerce models show limited success in generalist e-commerce modeling, and suffer from unsatisfactory performance on new users and new products - a typical out-of-domain generalization challenge. Meanwhile, large language models (LLMs) demonstrate outstanding performance in generalist modeling and out-of-domain generalizability in many fields. Toward fully unleashing their power for e-commerce, in this paper, we construct ECInstruct, the first open-sourced, large-scale, and high-quality benchmark instruction dataset for e-commerce. Leveraging ECInstruct, we develop eCeLLM, a series of e-commerce LLMs, by instruction-tuning general-purpose LLMs. Our comprehensive experiments and evaluation demonstrate that eCeLLM models substantially outperform baseline models, including the most advanced GPT-4, and the state-of-the-art task-specific models in in-domain ev
    
[^11]: 关于大型语言模型在推理和规划任务中的自我验证限制问题

    On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks

    [https://arxiv.org/abs/2402.08115](https://arxiv.org/abs/2402.08115)

    这项研究对大型语言模型在推理和规划任务中的自我验证能力进行了系统研究，并发现了迭代提示的有效性。

    

    关于大型语言模型（LLMs）的推理能力，存在着较大的观点差异。尽管最初对于推理可能会随着规模的扩大自动出现的乐观情绪已经受到了一系列反例的抑制，从乘法到简单规划，但仍然普遍认为LLMs可以自我批判并迭代改进其解决方案。这种信念似乎建立在验证正确性比生成更容易的假设上，这是一个典型的计算复杂性论证，对于LLMs来说应该是无关紧要的，因为它们所做的是近似检索。在本文中，我们系统地研究了推理和规划环境中迭代提示的有效性。 我们对GPT-4在三个领域（24点游戏、图着色和STRIPS规划）的性能进行了有原则的实证研究。我们对模型的批判性实验进行了探索。

    There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion. This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval. In this paper, we set out to systematically investigate the effectiveness of iterative prompting in the context of reasoning and planning. We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both with the model critiq
    
[^12]: 机器人出租车事故的解剖：从Cruise行人拖拽事故中吸取教训

    Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap

    [https://arxiv.org/abs/2402.06046](https://arxiv.org/abs/2402.06046)

    2023年10月，一起GM Cruise机器人出租车与行人相撞的事故给公司造成了巨大的动荡，同时也揭示了该公司在处理事故后的失误。这一事件的解剖提供了在技术、操作安全实践和组织反应方面的安全教训。

    

    2023年10月，在旧金山，一辆通用汽车Cruise的机器人出租车与一名行人相撞，造成了严重的伤害，同时也对该公司造成了巨大的动荡，这很可能会对整个行业产生长期影响。问题不仅仅源于事故本身，还包括Cruise在处理机器人出租车撞到行人后被拖行的过程中的失误。两份外部调查报告提供了描述事件的原始材料，并从监管互动的角度批评了公司的反应，但并未包含潜在的安全建议。我们利用这些报告材料来强调具体的事实和事件之间的关系，通过将报告材料的不同部分联系起来。然后我们探讨在技术、操作安全实践和组织对事件的反应方面可能可以学到的安全教训。

    An October 2023 crash between a GM Cruise robotaxi and a pedestrian in San Francisco resulted not only in a severe injury, but also dramatic upheaval at that company that will likely have lasting effects throughout the industry. The issues stem not just from the crash facts themselves, but also how Cruise mishandled dealing with their robotaxi dragging a pedestrian under the vehicle after the initial post-crash stop. A pair of external investigation reports provide raw material describing the incident and critique the company response from a regulatory interaction point of view, but did not include potential safety recommendations in scope. We use that report material to highlight specific facts and relationships between events by tying together different pieces of the report material. We then explore safety lessons that might be learned with regard to technology, operational safety practices, and organizational reaction to incidents.
    
[^13]: 变分流模型：以你的风格流动

    Variational Flow Models: Flowing in Your Style

    [https://arxiv.org/abs/2402.02977](https://arxiv.org/abs/2402.02977)

    我们引入了一种变分流模型的方法，并提出了一种系统的无需训练的转换方法，使得快速采样成为可能，同时保持了采样的准确性和效率。

    

    我们引入了一种对"后验流"模型进行变分推理解释的方法——用以将"概率流"推广到更广泛的随机过程类别，不必局限于扩散过程。我们将这种结果称为"变分流模型"。此外，我们提出了一种无需训练的系统方法，将由方程Xt = at * X0 + st * X1所描述的"线性"随机过程的后验流转化为直线恒速(SC)流，类似于矫正流。这种转化使得可以快速沿着原始的后验流进行采样，而无需训练一个新的SC流模型。我们的方法的灵活性使我们能够将转换扩展到两个不同"线性"随机过程的后验流之间进行互相转化。此外，我们还可以将高阶数值解法轻松集成到转换后的SC流中，进一步提高采样的准确性和效率。我们进行了严格的理论分析和大量实验结果的验证。

    We introduce a variational inference interpretation for models of "posterior flows" - generalizations of "probability flows" to a broader class of stochastic processes not necessarily diffusion processes. We coin the resulting models as "Variational Flow Models". Additionally, we propose a systematic training-free method to transform the posterior flow of a "linear" stochastic process characterized by the equation Xt = at * X0 + st * X1 into a straight constant-speed (SC) flow, reminiscent of Rectified Flow. This transformation facilitates fast sampling along the original posterior flow without training a new model of the SC flow. The flexibility of our approach allows us to extend our transformation to inter-convert two posterior flows from distinct "linear" stochastic processes. Moreover, we can easily integrate high-order numerical solvers into the transformed SC flow, further enhancing sampling accuracy and efficiency. Rigorous theoretical analysis and extensive experimental result
    
[^14]: 通过链接大型语言模型增强私人辅导

    Empowering Private Tutoring by Chaining Large Language Models

    [https://arxiv.org/abs/2309.08112](https://arxiv.org/abs/2309.08112)

    通过链式连接大型语言模型，开发了一种全面智能辅导系统，实现了自动课程规划、个性化指导和灵活测验评估。

    

    人工智能已被应用于在线教育的各个方面，以促进教学和学习。然而，很少有方法致力于完整的AI辅导系统。在这项工作中，我们探讨了一个由最先进的大型语言模型（LLMs）驱动的全面智能辅导系统的开发，涵盖自动课程规划和调整、定制指导以及灵活的测验评估。为了使系统能够经受住长时间交互并满足个性化教育的需求，系统被分解为三个相互连接的核心流程-交互、反思和反应。每个流程都通过链接LLM驱动的工具以及动态更新的记忆模块来实现。工具是LLMs，被提示执行一项特定任务，而记忆是在教育过程中更新的数据存储。学习日志中的统计结果证明了这种方法的有效性。

    arXiv:2309.08112v1 Announce Type: cross  Abstract: Artificial intelligence has been applied in various aspects of online education to facilitate teaching and learning. However, few approaches has been made toward a complete AI-powered tutoring system. In this work, we explore the development of a full-fledged intelligent tutoring system powered by state-of-the-art large language models (LLMs), covering automatic course planning and adjusting, tailored instruction, and flexible quiz evaluation. To make the system robust to prolonged interaction and cater to individualized education, the system is decomposed into three inter-connected core processes-interaction, reflection, and reaction. Each process is implemented by chaining LLM-powered tools along with dynamically updated memory modules. Tools are LLMs prompted to execute one specific task at a time, while memories are data storage that gets updated during education process. Statistical results from learning logs demonstrate the effec
    
[^15]: 信用风险与大型语言模型相结合：从P2P借贷的贷款描述中构建风险指标。

    Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending. (arXiv:2401.16458v1 [q-fin.RM])

    [http://arxiv.org/abs/2401.16458](http://arxiv.org/abs/2401.16458)

    本文研究了如何利用P2P借贷平台上借款人提供的文本描述来构建风险指标。结果显示，利用大型语言模型生成的风险评分可以明显提高信用风险分类器的性能。

    

    P2P借贷作为一种独特的融资机制，通过在线平台将借款人与放款人联系起来。然而，P2P借贷面临信息不对称的挑战，因为放款人往往缺乏足够的数据来评估借款人的信用价值。本文提出了一种新颖的方法来解决这个问题，即利用借款人在贷款申请过程中提供的文本描述。我们的方法涉及使用大型语言模型（LLM）处理这些文本描述，LLM是一种能够识别文本中的模式和语义的强大工具。将迁移学习应用于将LLM适应特定任务。我们从Lending Club数据集的分析结果显示，BERT生成的风险评分显著提高了信用风险分类器的性能。然而，基于LLM的系统固有的不透明性，以及潜在偏差的不确定性，限制了其应用。

    Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism, linking borrowers with lenders through online platforms. However, P2P lending faces the challenge of information asymmetry, as lenders often lack sufficient data to assess the creditworthiness of borrowers. This paper proposes a novel approach to address this issue by leveraging the textual descriptions provided by borrowers during the loan application process. Our methodology involves processing these textual descriptions using a Large Language Model (LLM), a powerful tool capable of discerning patterns and semantics within the text. Transfer learning is applied to adapt the LLM to the specific task at hand.  Our results derived from the analysis of the Lending Club dataset show that the risk score generated by BERT, a widely used LLM, significantly improves the performance of credit risk classifiers. However, the inherent opacity of LLM-based systems, coupled with uncertainties about potential biases, unders
    
[^16]: 不可能任务：语言模型

    Mission: Impossible Language Models. (arXiv:2401.06416v1 [cs.CL])

    [http://arxiv.org/abs/2401.06416](http://arxiv.org/abs/2401.06416)

    本文为了支持大型语言模型(LLMs)能够学习不可能的语言的观点，开发了一组人工合成的不可能语言，并通过评估GPT-2小型模型的学习能力得出了结论。

    

    Chomsky和其他人直接声称，大型语言模型(LLMs)能够学习人类无法学习的可能和不可能的语言。然而，很少有发表的实验证据支持这样的说法。在这里，我们通过系统地改变英文数据的词序和语法规则，开发了一组不可能的合成语言，每种语言的复杂程度不同。这些语言位于一个不可能的连续体上：一端是本质上不可能的语言，例如英文单词的随机和不可逆的洗牌，而另一端是在语言学上常被认为是不可能的语言，特别是基于计算词位置的规则。我们报告了广泛的评估来评估GPT-2小型模型学习这些无可争议的不可能语言的能力，并且至关重要的是，在整个过程中进行了这些评估。

    Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim. Here, we develop a set of synthetic impossible languages of differing complexity, each designed by systematically altering English data with unnatural word orders and grammar rules. These languages lie on an impossibility continuum: at one end are languages that are inherently impossible, such as random and irreversible shuffles of English words, and on the other, languages that may not be intuitively impossible but are often considered so in linguistics, particularly those with rules based on counting word positions. We report on a wide range of evaluations to assess the capacity of GPT-2 small models to learn these uncontroversially impossible languages, and crucially, we perform these assessments at various stages throughout
    
[^17]: DrawTalking：通过草图和语言建立互动世界

    DrawTalking: Building Interactive Worlds by Sketching and Speaking. (arXiv:2401.05631v1 [cs.HC])

    [http://arxiv.org/abs/2401.05631](http://arxiv.org/abs/2401.05631)

    用户通过草图和语言建立互动世界的交互式方法，具有用户控制和灵活性，无需编程即可实现编程功能。适用于各种创造性探索性场景。

    

    我们引入了一种交互式方法，DrawTalking，用户可以通过草图和语言建立互动世界。它强调用户控制和灵活性，并且在没有编程的情况下提供了类似编程的能力。我们在iPad上实现了它。一项开放式研究表明，这种机制与许多创造性探索性用例相契合和适用。我们希望能够激发和指导未来自然用户中心界面的研究。

    We introduce an interactive approach, DrawTalking, in which the user builds interactive worlds by sketching and speaking. It emphasizes user control and flexibility, and gives programming-like capability without code. We implemented it on the iPad. An open-ended study shows the mechanics resonate and are applicable to many creative-exploratory use cases. We hope to inspire and inform research in future natural user-centered interfaces.
    
[^18]: 可靠的学术会议问答：基于大型语言模型的研究

    Reliable Academic Conference Question Answering: A Study Based on Large Language Model. (arXiv:2310.13028v1 [cs.CL])

    [http://arxiv.org/abs/2310.13028](http://arxiv.org/abs/2310.13028)

    本研究以大型语言模型为基础，开发了可靠的学术会议问答系统，通过组织半结构化的会议数据并进行人工标注，解决了研究人员在获取准确、最新信息时的需求。

    

    计算机科学的快速发展导致学术会议上的研究大量增加，促进了全球学术交流。研究人员在各个阶段都持续寻求关于这些事件的准确、最新信息。这种数据爆发需要一个智能的问答系统来高效解决研究人员的问题，并确保对最新进展的了解。会议信息通常在官方网站上发布，以半结构化的方式组织，并包含大量的文本。为了满足这一需求，我们开发了ConferenceQA数据集，涵盖了7个不同学术会议，并进行了人工标注。首先，我们采用手动和自动方法的组合，以半结构化的JSON格式组织学术会议数据。随后，我们为每个会议注释了近100个问题-答案对。每个对应对应了四个不同的维度分类。为了确保数据的可靠性，我们手动进行了标注。

    The rapid growth of computer science has led to a proliferation of research presented at academic conferences, fostering global scholarly communication. Researchers consistently seek accurate, current information about these events at all stages. This data surge necessitates an intelligent question-answering system to efficiently address researchers' queries and ensure awareness of the latest advancements. The information of conferences is usually published on their official website, organized in a semi-structured way with a lot of text. To address this need, we have developed the ConferenceQA dataset for 7 diverse academic conferences with human annotations. Firstly, we employ a combination of manual and automated methods to organize academic conference data in a semi-structured JSON format. Subsequently, we annotate nearly 100 question-answer pairs for each conference. Each pair is classified into four different dimensions. To ensure the reliability of the data, we manually annotate 
    
[^19]: 在安全关键行业中解构人工智能与人类互动：系统文献综述

    Unpacking Human-AI Interaction in Safety-Critical Industries: A Systematic Literature Review. (arXiv:2310.03392v1 [cs.HC])

    [http://arxiv.org/abs/2310.03392](http://arxiv.org/abs/2310.03392)

    在安全关键行业中确保高质量的人工智能与人类互动（HAII）十分重要，然而目前对于HAII的研究零散且缺乏一致性。本论文通过系统文献综述，发现没有一个一致使用的术语描述HAII，并且五个因素影响HAII，即用户特征和背景、AI界面和功能、用户信任、监控和反馈，以及工作上的团队结构。这些发现为改进安全关键行业中的HAII提供了指导。

    

    在安全关键行业中确保高质量的人工智能与人类互动（HAII）是至关重要的。不能做到这一点可能导致灾难性和致命的后果。尽管如此紧迫，关于HAII的研究很少且零散，且缺乏一致性。我们在这里提出了对该领域的文献综述和改进研究最佳实践的建议。我们将我们的调查分为以下研究领域：（1）用于描述HAII的术语，（2）AI-enabled系统的主要角色，（3）影响HAII的因素，以及（4）如何衡量HAII。此外，我们描述了在这些文章中讨论的安全关键行业中使用的AI-enabled系统的能力和成熟度。我们发现在文献中没有一个术语被一致使用来描述HAII，而一些术语具有多个含义。根据我们的文献，有五个因素影响HAII：用户特征和背景（例如，用户个性，感知），AI界面和功能（例如，

    Ensuring quality human-AI interaction (HAII) in safety-critical industries is essential. Failure to do so can lead to catastrophic and deadly consequences. Despite this urgency, what little research there is on HAII is fragmented and inconsistent. We present here a survey of that literature and recommendations for research best practices that will improve the field. We divided our investigation into the following research areas: (1) terms used to describe HAII, (2) primary roles of AI-enabled systems, (3) factors that influence HAII, and (4) how HAII is measured. Additionally, we described the capabilities and maturity of the AI-enabled systems used in safety-critical industries discussed in these articles. We found that no single term is used across the literature to describe HAII and some terms have multiple meanings. According to our literature, five factors influence HAII: user characteristics and background (e.g., user personality, perceptions), AI interface and features (e.g., in
    
[^20]: 智能制造系统中的时间序列分类: 对最先进机器学习算法的实验评估

    Time-Series Classification in Smart Manufacturing Systems: An Experimental Evaluation of State-of-the-Art Machine Learning Algorithms. (arXiv:2310.02812v1 [cs.LG])

    [http://arxiv.org/abs/2310.02812](http://arxiv.org/abs/2310.02812)

    本研究通过严格实验评估了智能制造系统中最先进的机器学习和深度学习算法在时间序列分类任务中的性能，填补了该领域的研究空白。

    

    随着传感器数量的增加和感知技术的快速发展，制造业正在收集大量各种各样的数据。在智能制造系统 (SMS) 环境中，时间序列数据起着关键的作用。因此，时间序列分类 (TSC) 在该领域中至关重要。本研究的目标是通过对制造业和工业环境中 TSC 任务的最先进机器学习和深度学习算法进行严格的实验评估来填补这一空白。我们首先在 TSC 和制造业文献中探索和编制了一份包含超过92个最先进算法的全面列表。随后，我们从该列表中选择了最具代表性的36个算法。为了评估这些算法在各种制造业分类任务中的性能，我们策划了一组包含22个制造业数据集的基准数据集，这些数据集具有不同的特征，涵盖了各种制造问题。随后，我们在制造业基准数据集上实施并评估了这些算法。

    Manufacturing is gathering extensive amounts of diverse data, thanks to the growing number of sensors and rapid advances in sensing technologies. Among the various data types available in SMS settings, time-series data plays a pivotal role. Hence, TSC emerges is crucial in this domain. The objective of this study is to fill this gap by providing a rigorous experimental evaluation of the SoTA ML and DL algorithms for TSC tasks in manufacturing and industrial settings. We first explored and compiled a comprehensive list of more than 92 SoTA algorithms from both TSC and manufacturing literature. Following, we selected the 36 most representative algorithms from this list. To evaluate their performance across various manufacturing classification tasks, we curated a set of 22 manufacturing datasets, representative of different characteristics that cover diverse manufacturing problems. Subsequently, we implemented and evaluated the algorithms on the manufacturing benchmark datasets, and analy
    
[^21]: LLM谎言: 幻觉不是漏洞，而是对抗样本的特征。

    LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples. (arXiv:2310.01469v1 [cs.CL])

    [http://arxiv.org/abs/2310.01469](http://arxiv.org/abs/2310.01469)

    LLM似乎具有丰富的知识和适应多种任务的能力，但我们不能完全信任它们的回答，因为它们会出现幻觉，即捏造不存在的事实以欺骗用户。本文证明了由随机标记组成的无意义提示也能引起LLM产生幻觉回应，并提出了一种对抗方式的自动幻觉触发方法作为幻觉攻击，同时提出了一种简单而有效的防御策略。

    

    大型语言模型（LLM），包括GPT-3.5、LLaMA和PaLM，似乎具有丰富的知识和适应多种任务的能力。然而，我们仍然不能完全信任它们的回答，因为LLM会出现幻觉，即捏造不存在的事实以欺骗用户而不被察觉。幻觉存在的原因和普遍性仍然不清楚。在本文中，我们证明了由随机标记组成的无意义提示也能引起LLM产生幻觉回应。这个现象迫使我们重新审视幻觉可能是对抗样本的另一种视角，并且它与常规的对抗样本具有类似的特征，作为LLM的基本特征。因此，我们以对抗的方式将自动幻觉触发方法形式化为幻觉攻击。最后，我们研究了被攻击的对抗提示的基本特征，并提出了一种简单而有效的防御策略。我们的代码已在GitHub上发布。

    Large Language Models (LLMs), including GPT-3.5, LLaMA, and PaLM, seem to be knowledgeable and able to adapt to many tasks. However, we still can not completely trust their answer, since LLMs suffer from hallucination--fabricating non-existent facts to cheat users without perception. And the reasons for their existence and pervasiveness remain unclear. In this paper, we demonstrate that non-sense prompts composed of random tokens can also elicit the LLMs to respond with hallucinations. This phenomenon forces us to revisit that hallucination may be another view of adversarial examples, and it shares similar features with conventional adversarial examples as the basic feature of LLMs. Therefore, we formalize an automatic hallucination triggering method as the hallucination attack in an adversarial way. Finally, we explore basic feature of attacked adversarial prompts and propose a simple yet effective defense strategy. Our code is released on GitHub.
    
[^22]: TranDRL：一种基于Transformer驱动的深度强化学习支持的预防性维护框架

    TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled Prescriptive Maintenance Framework. (arXiv:2309.16935v1 [cs.LG])

    [http://arxiv.org/abs/2309.16935](http://arxiv.org/abs/2309.16935)

    TranDRL是一种基于Transformer驱动的深度强化学习支持的预防性维护框架，结合了复杂时间模式捕捉和经济高效维护建议，显著提高了剩余寿命（RUL）预测准确性和维护行动优化。

    

    工业系统需要可靠的预测性维护策略来提高运营效率并减少停机时间。本文介绍了一种新颖的综合框架，利用Transformer神经网络和深度强化学习（DRL）算法来优化维护行动。我们的方法采用Transformer模型来有效捕捉传感器数据中的复杂时间模式，从而准确预测设备的剩余寿命（RUL）。同时，我们框架中的DRL组件提供了经济高效和及时的维护建议。我们在NASA C-MPASS数据集上验证了我们框架的有效性，结果显示在RUL预测准确性和维护行动优化方面取得了显著进展。因此，我们的创新方法为预防性维护提供了一种创新的数据驱动方法，解决了工业运营中的关键挑战，并带来了更多发展机遇。

    Industrial systems demand reliable predictive maintenance strategies to enhance operational efficiency and reduce downtime. This paper introduces a novel, integrated framework that leverages the power of transformer neural networks and deep reinforcement learning (DRL) algorithms to optimize maintenance actions. Our approach employs the transformer model to effectively capture complex temporal patterns in sensor data, thereby accurately predicting the Remaining Useful Life (RUL) of equipment. Simultaneously, the DRL component of our framework provides cost-effective and timely maintenance recommendations. We validate the efficacy of our framework on the NASA C-MPASS dataset, where it demonstrates significant advancements in both RUL prediction accuracy and the optimization of maintenance actions. Consequently, our pioneering approach provides an innovative data-driven methodology for prescriptive maintenance, addressing key challenges in industrial operations and leading the way to mor
    
[^23]: 关于相对于单子句传播不可简化的CNF公式

    On CNF formulas irredundant with respect to unit clause propagation. (arXiv:2309.01750v2 [math.CO] UPDATED)

    [http://arxiv.org/abs/2309.01750](http://arxiv.org/abs/2309.01750)

    对于单子句传播而言，在CNF公式中不可简化的公式，其大小与最小可等价的公式大小的比值最大为n^2，其中n是变量数量。一般上界不会小于n/ln n倍。

    

    如果两个CNF公式在单子句传播（UCP）方面的行为相同，则它们被称为ucp等价。如果移除任意一个子句会导致一个与原始公式在ucp方面不等价的公式，则称该公式为ucp不可简化。根据已知结果，ucp不可简化公式的大小与最小ucp等价公式的大小的比值最大为n^2，其中n是变量的数量。我们展示了对称确定Horn函数的一个ucp不可简化公式的例子，其大小比最小的ucp等价公式大n/ln n倍，因此，上述比值的一般上界不能小于这个值。

    Two CNF formulas are called ucp-equivalent, if they behave in the same way with respect to the unit clause propagation (UCP). A formula is called ucp-irredundant, if removing any clause leads to a formula which is not ucp-equivalent to the original one. As a consequence of known results, the ratio of the size of a ucp-irredundant formula and the size of a smallest ucp-equivalent formula is at most $n^2$, where $n$ is the number of the variables. We demonstrate an example of a ucp-irredundant formula for a symmetric definite Horn function which is larger than a smallest ucp-equivalent formula by a factor $\Omega(n/\ln n)$ and, hence, a general upper bound on the above ratio cannot be smaller than this.
    
[^24]: LAMBO: 大型语言模型增强的边缘智能

    LAMBO: Large Language Model Empowered Edge Intelligence. (arXiv:2308.15078v1 [cs.AI])

    [http://arxiv.org/abs/2308.15078](http://arxiv.org/abs/2308.15078)

    LAMBO是一种基于大型语言模型的边缘智能框架，用于移动边缘计算。它解决了传统深度卸载架构的问题，并提供了高性能的决策模块和强化学习模块。

    

    预计下一代边缘智能将为各种应用带来巨大的好处，例如卸载系统。然而，传统的深度卸载架构面临多个问题，包括异构限制、部分感知、不确定的泛化和缺乏可追溯性。在这种背景下，将卸载与大型语言模型（LLMs）集成在一起具有许多优势。因此，我们提出了一种基于LLM的卸载（LAMBO）框架，用于移动边缘计算（MEC），它由四个组成部分组成：（i）输入嵌入（IE），用于用高质量的可学习向量表示具有约束和提示的卸载系统的信息；（ii）非对称编码解码（AED）模型，是一个决策模块，具有深度编码器和浅层解码器。它可以基于多头自注意力机制实现高性能；（iii）演员-评论家强化学习（ACRL）模块，用于进行预训练。

    Next-generation edge intelligence is anticipated to bring huge benefits to various applications, e.g., offloading systems. However, traditional deep offloading architectures face several issues, including heterogeneous constraints, partial perception, uncertain generalization, and lack of tractability. In this context, the integration of offloading with large language models (LLMs) presents numerous advantages. Therefore, we propose an LLM-Based Offloading (LAMBO) framework for mobile edge computing (MEC), which comprises four components: (i) Input embedding (IE), which is used to represent the information of the offloading system with constraints and prompts through learnable vectors with high quality; (ii) Asymmetric encoderdecoder (AED) model, which is a decision-making module with a deep encoder and a shallow decoder. It can achieve high performance based on multi-head self-attention schemes; (iii) Actor-critic reinforcement learning (ACRL) module, which is employed to pre-train th
    
[^25]: 增强声音事件检测的语言模型能力

    Furnishing Sound Event Detection with Language Model Abilities. (arXiv:2308.11530v1 [cs.SD])

    [http://arxiv.org/abs/2308.11530](http://arxiv.org/abs/2308.11530)

    本文提出了一种增强声音事件检测的方法，通过对齐音频特征和文本特征来实现声音事件分类和时间定位。该方法利用语言模型的语义能力直接生成序列，相比传统方法更简洁全面，并通过实验证明了其在时间戳捕获和事件分类方面的有效性。

    

    最近，语言模型（LMs）在视觉跨模态中的能力引起了越来越多的关注。在本文中，我们进一步探索了LMs在声音事件检测（SED）中的生成能力，超越了视觉领域。具体而言，我们提出了一种优雅的方法，通过对齐音频特征和文本特征来完成声音事件分类和时间定位。该框架由一个声学编码器、一个对应的文本和音频表示对齐的对比模块，以及一个解耦的语言解码器组成，用于从音频特征中生成时间和事件序列。与需要复杂处理并几乎不使用有限音频特征的传统方法相比，我们的模型更简洁全面，因为语言模型直接利用其语义能力生成序列。我们研究了不同的解耦模块，以展示其对时间戳捕捉和事件分类的有效性。

    Recently, the ability of language models (LMs) has attracted increasing attention in visual cross-modality. In this paper, we further explore the generation capacity of LMs for sound event detection (SED), beyond the visual domain. Specifically, we propose an elegant method that aligns audio features and text features to accomplish sound event classification and temporal location. The framework consists of an acoustic encoder, a contrastive module that align the corresponding representations of the text and audio, and a decoupled language decoder that generates temporal and event sequences from the audio characteristic. Compared with conventional works that require complicated processing and barely utilize limited audio features, our model is more concise and comprehensive since language model directly leverage its semantic capabilities to generate the sequences. We investigate different decoupling modules to demonstrate the effectiveness for timestamps capture and event classification
    
[^26]: 针对模式复杂的异构信息网络的归纳元路径学习

    Inductive Meta-path Learning for Schema-complex Heterogeneous Information Networks. (arXiv:2307.03937v1 [cs.AI])

    [http://arxiv.org/abs/2307.03937](http://arxiv.org/abs/2307.03937)

    这项研究提出了一种针对模式复杂的异构信息网络的归纳元路径学习框架SchemaWalk。

    

    异构信息网络(HINs)是具有多种节点类型和边类型的信息网络。元路径的概念即一系列连接两个实体的实体类型和关系类型的序列被提出为提供对不同HIN任务的元级可解释语义的一种方法。传统上，元路径主要用于模式简单的HINs，例如只有少量实体类型的文献网络，在这种情况下，元路径通常通过领域知识枚举。然而，元路径在模式复杂的HINs(例如具有数百种实体和关系类型的知识库)中的应用受到了由元路径枚举引起的计算复杂性的限制。此外，有效评估元路径需要枚举相关路径实例，这进一步增加了元路径学习过程的复杂性。为了应对这些挑战，我们提出了一种用于模式复杂的HINs的归纳元路径学习框架SchemaWalk。

    Heterogeneous Information Networks (HINs) are information networks with multiple types of nodes and edges. The concept of meta-path, i.e., a sequence of entity types and relation types connecting two entities, is proposed to provide the meta-level explainable semantics for various HIN tasks. Traditionally, meta-paths are primarily used for schema-simple HINs, e.g., bibliographic networks with only a few entity types, where meta-paths are often enumerated with domain knowledge. However, the adoption of meta-paths for schema-complex HINs, such as knowledge bases (KBs) with hundreds of entity and relation types, has been limited due to the computational complexity associated with meta-path enumeration. Additionally, effectively assessing meta-paths requires enumerating relevant path instances, which adds further complexity to the meta-path learning process. To address these challenges, we propose SchemaWalk, an inductive meta-path learning framework for schema-complex HINs. We represent m
    
[^27]: 基于大型AI模型的语义通信

    Large AI Model-Based Semantic Communications. (arXiv:2307.03492v1 [cs.AI])

    [http://arxiv.org/abs/2307.03492](http://arxiv.org/abs/2307.03492)

    本文提出了一种基于大型AI模型的语义通信框架（LAM-SC），利用该框架可以克服知识库构建过程中面临的问题，并在图像数据领域实现了语义分割、语义集成和自适应语义压缩。

    

    语义通信（SC）是一种新兴的智能范式，为元宇宙、混合现实和万物互联等未来应用提供解决方案。然而，在目前的SC系统中，知识库（KB）的构建面临着一些问题，包括知识表示有限、频繁的知识更新和不安全的知识共享。幸运的是，大型AI模型的发展提供了解决上述问题的新方案。在这里，我们提出了一种基于大型AI模型的SC框架（LAM-SC），专门用于图像数据，我们首先设计了基于段落模型（SAM）的知识库（SKB），它可以通过通用语义知识将原始图像划分为不同的语义段落。然后，我们提出了一种基于注意力的语义集成（ASI），通过权衡由SKB生成的语义段落，无需人工参与并将它们集成为具有语义感知的图像。此外，我们还提出了一种自适应语义压缩（ASC）方法。

    Semantic communication (SC) is an emerging intelligent paradigm, offering solutions for various future applications like metaverse, mixed-reality, and the Internet of everything. However, in current SC systems, the construction of the knowledge base (KB) faces several issues, including limited knowledge representation, frequent knowledge updates, and insecure knowledge sharing. Fortunately, the development of the large AI model provides new solutions to overcome above issues. Here, we propose a large AI model-based SC framework (LAM-SC) specifically designed for image data, where we first design the segment anything model (SAM)-based KB (SKB) that can split the original image into different semantic segments by universal semantic knowledge. Then, we present an attention-based semantic integration (ASI) to weigh the semantic segments generated by SKB without human participation and integrate them as the semantic-aware image. Additionally, we propose an adaptive semantic compression (ASC
    
[^28]: 医疗知识图谱综述：资源、应用和前景

    A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])

    [http://arxiv.org/abs/2306.04802](http://arxiv.org/abs/2306.04802)

    本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。

    

    医疗知识图谱(HKGs)已成为组织医学知识的有结构且可解释的有为工具，提供了医学概念及其关系的全面视图。然而，数据异质性和覆盖范围有限等挑战仍然存在，强调了在HKG领域需要进一步研究的必要性。本综述是HKG的第一份综合概述。我们总结了HKG构建的流程和关键技术（即从头开始和通过集成），以及常见的利用方法（即基于模型和非基于模型）。为了为研究人员提供有价值的资源，我们根据它们捕获的数据类型和应用领域（该资源存储于https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase）组织了现有的HKG，并提供了相关的统计信息。在应用部分，我们深入探讨了HKG在各种医疗领域的变革性影响。

    Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
    
[^29]: 在编程语言模型中发现语义的证据

    Evidence of Meaning in Language Models Trained on Programs. (arXiv:2305.11169v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.11169](http://arxiv.org/abs/2305.11169)

    该论文证明了，通过在程序语料库上训练语言模型，即使没有针对学习语言语义提供归纳偏差，语言模型仍然能够学习含义。线性探测器能够从模型状态中提取程序状态的抽象，准确性与模型泛化到新程序的能力显著相关。

    

    我们提供证据表明，尽管被训练只是执行文本上的下一个标记预测，特别是一个程序语料库，语言模型仍然能够学习含义。每个程序都以（文本）输入输出示例的形式作为规范。与程序一起工作使我们能够精确地定义与语言中有关含义的概念（例如，正确性和语义），使得程序综合成为一个中间测试平台，用于表征语言模型中是否存在含义的存在（或不存在）。我们首先在程序语料库上训练了一个Transformer模型，然后探查了已经完成规范的程序时，经过训练的模型的隐藏状态。尽管没有针对学习语言语义提供归纳偏差，但我们发现，线性探测器能够从模型状态中提取当前和未来程序状态的抽象。此外，线性探测器的准确性与模型泛化到新程序的能力强有力、统计学显著地相关。

    We present evidence that language models can learn meaning despite being trained only to perform next token prediction on text, specifically a corpus of programs. Each program is preceded by a specification in the form of (textual) input-output examples. Working with programs enables us to precisely define concepts relevant to meaning in language (e.g., correctness and semantics), making program synthesis well-suited as an intermediate testbed for characterizing the presence (or absence) of meaning in language models.  We first train a Transformer model on the corpus of programs, then probe the trained model's hidden states as it completes a program given a specification. Despite providing no inductive bias toward learning the semantics of the language, we find that a linear probe is able to extract abstractions of both current and future program states from the model states. Moreover, there is a strong, statistically significant correlation between the accuracy of the probe and the mo
    
[^30]: 环境约束下的情境依赖性沟通

    Context-dependent communication under environmental constraints. (arXiv:2305.05821v1 [cs.AI])

    [http://arxiv.org/abs/2305.05821](http://arxiv.org/abs/2305.05821)

    本文研究了在压缩词汇量的情况下，如何利用环境压力促进情境依赖性沟通的出现，并研究了在接收者无法处理歧义的情况下，发送者如何利用环境的制约因素实现沟通。

    

    存在大量的证据表明，现实世界中的沟通不能简单地通过发送具有独立于情境意义的信号来实现。本文以经典的Lewis(1969)信号模型的变体为基础，探讨在情境化场景下产生情境依赖性沟通的条件。具体而言，我们证明了在最小化词汇量的压力下，这种沟通的出现是足够的。同时，我们研究了可能使符号含义得到情境区分的环境条件和认知能力。我们展示了在接受者的指代选择受到环境限制的情况下，发送者可以单方面地利用这些限制，而无需接收者具有澄清歧义的能力。与常见的假设一致，发送者对情境的意识似乎是需要的。我们认为，情境依赖性沟通是一种多层次的情境化现象，其受环境特性的影响至关重要。

    There is significant evidence that real-world communication cannot be reduced to sending signals with context-independent meaning. In this work, based on a variant of the classical Lewis (1969) signaling model, we explore the conditions for the emergence of context-dependent communication in a situated scenario. In particular, we demonstrate that pressure to minimise the vocabulary size is sufficient for such emergence. At the same time, we study the environmental conditions and cognitive capabilities that enable contextual disambiguation of symbol meanings. We show that environmental constraints on the receiver's referent choice can be unilaterally exploited by the sender, without disambiguation capabilities on the receiver's end. Consistent with common assumptions, the sender's awareness of the context appears to be required for contextual communication. We suggest that context-dependent communication is a situated multilayered phenomenon, crucially influenced by environment properti
    
[^31]: 视觉学习者遇见Web图像-文本对

    Vision Learners Meet Web Image-Text Pairs. (arXiv:2301.07088v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07088](http://arxiv.org/abs/2301.07088)

    本论文提出了一种基于网络数据的新型视觉学习方法MUlti-modal Generator (MUG)。在视觉数据集的转移学习任务上取得了最先进的表现，是之前最佳结果的3.4%和2.2%的提升。

    

    大多数最新的自监督学习方法都是在维护良好的ImageNet-1K数据集上进行预训练的。在本研究中，考虑到网络数据的出色可伸缩性，我们认为自我监督预训练应该基于嘈杂的网络源图文配对数据。首先，我们在如此设置下，对大规模网络数据上的代表性自监督预训练方法进行了基准研究。我们比较了一系列方法，包括使用被屏蔽的训练目标的单模式方法和使用图像-文本对比训练的多模式方法。我们发现，现有的多模态方法在视觉转移学习任务上并不比单模态方法表现更好。我们提出了一个信息论视角来解释这些基准结果，这提供了如何设计新型视觉学习者的见解。受到这些见解的启发，我们提出了一种新的视觉表示预训练方法——多模式生成器（MUG），它从可伸缩的网络源图文数据中学习。MUG在几个视觉数据集的转移学习任务上取得了最先进的性能，在CIFAR-10上优于之前最佳的结果3.4％，在STL-10上优于之前最佳的结果2.2％。

    Most recent self-supervised learning methods are pre-trained on the well-curated ImageNet-1K dataset. In this work, given the excellent scalability of web data, we consider self-supervised pre-training on noisy web sourced image-text paired data. First, we conduct a benchmark study of representative self-supervised pre-training methods on large-scale web data in a like-for-like setting. We compare a range of methods, including single-modal ones that use masked training objectives and multi-modal ones that use image-text constrastive training. We observe that existing multi-modal methods do not outperform their single-modal counterparts on vision transfer learning tasks. We derive an information-theoretical view to explain these benchmark results, which provides insight into how to design a novel vision learner. Inspired by this insight, we present a new visual representation pre-training method, MUlti-modal Generator~(MUG), that learns from scalable web sourced image-text data. MUG ach
    

