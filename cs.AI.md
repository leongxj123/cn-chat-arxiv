# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Semi-Supervised Learning for Deep Causal Generative Models](https://arxiv.org/abs/2403.18717) | 首次开发了一种利用变量之间因果关系的半监督深度因果生成模型，以最大限度地利用所有可用数据。 |
| [^2] | [NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion, Reconstruction, and Generation](https://arxiv.org/abs/2403.18241) | 提出一种新颖的空间感知3D形状生成框架，利用2D平面表示增强建模，并结合混合形状表示技术直接学习连续有向距离场表示，从而确保空间一致性和降低内存使用。 |
| [^3] | [SAT Encoding of Partial Ordering Models for Graph Coloring Problems](https://arxiv.org/abs/2403.15961) | 该研究提出了新的SAT编码的偏序模型用于图着色问题，实验结果显示在一些情况下超越了现有的最先进方法，并对带宽着色问题进行了理论分析。 |
| [^4] | [Can large language models explore in-context?](https://arxiv.org/abs/2403.15371) | 研究发现，大型语言模型在没有实质干预的情况下很难有效进行探索，除了特定配置下的GPT-4具有满意的探索行为外，其他模型表现不稳定。 |
| [^5] | [OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2403.14183) | 通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。 |
| [^6] | [EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents](https://arxiv.org/abs/2403.12014) | EnvGen提出了一种新的框架，利用LLMs的推理能力自适应创建训练环境，帮助小型具身体RL代理在弱点方面学习有用技能。 |
| [^7] | [Bifurcated Attention for Single-Context Large-Batch Sampling](https://arxiv.org/abs/2403.08845) | 分叉注意力是针对语言模型推断中单上下文批量抽样环境开发的方法，通过将注意力机制分成两个独立的操作来减少冗余内存IO成本，提高效率并降低延迟。 |
| [^8] | [Leveraging Computer Vision in the Intensive Care Unit (ICU) for Examining Visitation and Mobility](https://arxiv.org/abs/2403.06322) | 在重症监护病房中利用计算机视觉系统，可以实现不存在的评估和增强现有评估的频率和准确性，同时减少工作人员工作量。 |
| [^9] | [Latent Dataset Distillation with Diffusion Models](https://arxiv.org/abs/2403.03881) | 这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。 |
| [^10] | [A Neural Rewriting System to Solve Algorithmic Problems](https://arxiv.org/abs/2402.17407) | 提出了一种受重写系统启发的神经架构，用于学习算法任务，通过Selector、Solver和Combiner三个专门模块实现算法任务的简化，具有较好的外推能力 |
| [^11] | [Instruction Tuning for Secure Code Generation](https://arxiv.org/abs/2402.09497) | 现代语言模型在编程中得到广泛应用，指令调优是一个增强其实用性的关键过程。然而，现有的方案忽视了生成代码的安全性。本文提出了SafeCoder，通过安全微调和标准指令调优相结合，来优化安全性和实用性。 |
| [^12] | [Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?](https://arxiv.org/abs/2402.09303) | 研究对比了人类和深度神经网络在图像分类中的行为差异，发现人类具有即时概括能力，而DNNs存在滞后概括现象，这表明了表示分歧的存在。 |
| [^13] | [Tree Ensembles for Contextual Bandits](https://arxiv.org/abs/2402.06963) | 本论文提出了一种基于树集成的情境多臂老虎机新框架，通过整合两种广泛使用的老虎机方法，在标准和组合设置中实现了优于基于神经网络的方法的性能，在减少后悔和计算时间方面表现出更出色的性能。 |
| [^14] | [Learning Contrastive Feature Representations for Facial Action Unit Detection](https://arxiv.org/abs/2402.06165) | 这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。 |
| [^15] | [GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study](https://arxiv.org/abs/2402.05435) | 本研究通过使用结构化叙事提示，验证了GPT-4生成的叙述在传达生活事件方面的有效性。研究结果表明，大多数叙述能够足够传达提示的意图。同时，通过机器学习模型的训练和验证，可以自动识别有效和无效的叙述。 |
| [^16] | [Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems](https://arxiv.org/abs/2402.04955) | 这项研究比较了在知识密集型环境中基于LLM的认知助手和基于意图的系统，并发现基于LLM的认知助手在用户体验、任务完成率、可用性和个人效能方面表现更好。 |
| [^17] | [Position Paper: Toward New Frameworks for Studying Model Representations](https://arxiv.org/abs/2402.03855) | 通过逆向工程AI模型的确切算法，机制解释性（MI）旨在理解模型。然而，目前的研究主要关注微不足道的行为和能力，而忽视了隐藏在网络内部的表示。因此，我们呼吁研究界朝着新的框架努力，研究这些表示。 |
| [^18] | [Enhancing Transformer RNNs with Multiple Temporal Perspectives](https://arxiv.org/abs/2402.02625) | 引入了多个时间视角的概念，用于增强Transformer RNNs对顺序数据的理解能力，在参数数量最小增加的情况下取得了显著的改进。 |
| [^19] | [Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach](https://arxiv.org/abs/2401.11410) | 提出了一种基于深度学习和天气预测的农业推荐系统，旨在解决孟加拉国农业面临的天气不利因素对粮食生产的影响，以实现盈利、可持续和农民友好的农业实践。 |
| [^20] | [DISTINQT: A Distributed Privacy Aware Learning Framework for QoS Prediction for Future Mobile and Wireless Networks.](http://arxiv.org/abs/2401.10158) | DISTINQT是一种面向未来移动和无线网络的隐私感知分布式学习框架，用于QoS预测。 |
| [^21] | [A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure.](http://arxiv.org/abs/2401.01772) | 本研究提出了一种名为X-Net的新型神经网络，通过利用交替反向传播机制，在训练过程中根据导数信息动态选择适当的激活函数，以增强网络的表示能力。 |
| [^22] | [Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status.](http://arxiv.org/abs/2311.00565) | 在重症监护室中开发能够检测视觉线索并与患者临床状态关联的人工智能工具，可以提供更客观和详细的监测能力。 |
| [^23] | [Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology.](http://arxiv.org/abs/2310.05227) | 物理感知机器学习是一种革命性方法，它将物理知识和机器学习相结合，提供了准确的水文学理解和水循环预测，对于管理水资源以应对气候变化等挑战具有重要意义。 |
| [^24] | [Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models.](http://arxiv.org/abs/2310.01691) | 这项工作提出了一种零样本连续提示传递方法，通过将源提示编码到相对空间中，并搜索相应的目标提示，在不同的语言模型之间实现了任务语义的泛化，实验证实了该方法的有效性。 |
| [^25] | [Mitigating Group Bias in Federated Learning for Heterogeneous Devices.](http://arxiv.org/abs/2309.07085) | 本文提出了一种在分布式边缘应用中减轻联邦学习中群体偏见的方法，该方法可以通过计算跨域群体重要性来减轻全局模型的偏见，并保持隐私和资源利用效率。 |
| [^26] | [Boundary State Generation for Testing and Improvement of Autonomous Driving Systems.](http://arxiv.org/abs/2307.10590) | 该论文介绍了一种新的自动驾驶系统测试生成器（GenBo），它通过在无故障环境中变异自动驾驶车辆的驾驶条件来生成边界状态对，以解决现有测试方法中存在的问题。 |
| [^27] | [On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets.](http://arxiv.org/abs/2307.05284) | 该论文通过对表格数据集中的自然偏移进行研究，发现$Y|X$-偏移最为普遍。为了推动研究人员开发描述数据分布偏移的精细语言，作者构建了WhyShift实验平台，并讨论了$Y|X$-偏移对算法的影响。 |
| [^28] | [Skill-Critic: Refining Learned Skills for Reinforcement Learning.](http://arxiv.org/abs/2306.08388) | 基于技能筛选与优化的Skill-Critic算法能够提高稀疏奖励环境下强化学习中低层策略的可靠性，并显著提高了性能。 |
| [^29] | [Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks.](http://arxiv.org/abs/2305.01626) | 该论文提出了一种基于语音的完全无监督的方法，可以直接从原始语音中建立基础语法模型。作者发现，在基于声音的单词记录上训练的卷积神经网络可以自发连接两个或三个单词，并且可以学会将单词嵌入到新的未见过的单词组合中，这是之前未报道的属性，这一发现对我们理解神经网络的学习方式和建立从原始声学输入中的语法及其演化的模型都有重要的意义。 |
| [^30] | [AI-Enhanced Intensive Care Unit: Revolutionizing Patient Care with Pervasive Sensing.](http://arxiv.org/abs/2303.06252) | 本文介绍了一种AI增强的重症监护室系统，通过普适感知和数据处理，可以改善患者的视觉监测和评估，提高护理质量。 |
| [^31] | [Anatomy-aware and acquisition-agnostic joint registration with SynthMorph.](http://arxiv.org/abs/2301.11329) | SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。 |
| [^32] | [CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Face Manipulation.](http://arxiv.org/abs/2210.03919) | 提出了一种为了解决文本引导图像操纵中的可分离性、可解释性和可控性问题，通过定义基于相关提示的语料库子空间来获取特定图像特征并引入CLIP投影增强嵌入（PAE）作为优化目标处理的新方法。 |
| [^33] | [Continual Developmental Neurosimulation Using Embodied Computational Agents.](http://arxiv.org/abs/2103.05753) | 通过使用发育Braitenberg Vehicles代理，我们提出了一种具有发育启发的学习代理设计，实现了计算自主性的具身经验和形态发生增长模拟，并考虑了发育轨迹在神经系统形态生成、发育学习和可塑性等方面的作用。 |

# 详细

[^1]: 深度因果生成模型的半监督学习

    Semi-Supervised Learning for Deep Causal Generative Models

    [https://arxiv.org/abs/2403.18717](https://arxiv.org/abs/2403.18717)

    首次开发了一种利用变量之间因果关系的半监督深度因果生成模型，以最大限度地利用所有可用数据。

    

    开发能够回答“如果$y$变为$z$，$x$会如何变化？”这类问题的模型对于推动医学图像分析至关重要。然而，训练能够解决这类反事实问题的因果生成模型目前要求所有相关变量均已被观察到，并且相应的标签在训练数据中可用。我们首次开发了一种利用变量之间因果关系的半监督深度因果生成模型，以最大限度地利用所有可用数据。

    arXiv:2403.18717v1 Announce Type: cross  Abstract: Developing models that can answer questions of the form "How would $x$ change if $y$ had been $z$?" is fundamental for advancing medical image analysis. Training causal generative models that address such counterfactual questions, though, currently requires that all relevant variables have been observed and that corresponding labels are available in training data. However, clinical data may not have complete records for all patients and state of the art causal generative models are unable to take full advantage of this. We thus develop, for the first time, a semi-supervised deep causal generative model that exploits the causal relationships between variables to maximise the use of all available data. We explore this in the setting where each sample is either fully labelled or fully unlabelled, as well as the more clinically realistic case of having different labels missing for each sample. We leverage techniques from causal inference t
    
[^2]: NeuSDFusion: 一种空间感知的生成模型，用于3D形状的完成、重建和生成

    NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion, Reconstruction, and Generation

    [https://arxiv.org/abs/2403.18241](https://arxiv.org/abs/2403.18241)

    提出一种新颖的空间感知3D形状生成框架，利用2D平面表示增强建模，并结合混合形状表示技术直接学习连续有向距离场表示，从而确保空间一致性和降低内存使用。

    

    3D形状生成旨在生成符合特定条件和约束的创新性3D内容。现有方法通常将3D形状分解为一系列局部组件，将每个元素孤立处理而不考虑空间一致性。因此，这些方法在3D数据表示和形状生成方面表现出有限的多样性，阻碍了它们生成高度多样化且符合指定约束的3D形状的能力。为此，我们引入了一种新颖的空间感知3D形状生成框架，利用2D平面表示来增强3D形状建模。为确保空间一致性并减少内存使用，我们结合了一种混合形状表示技术，直接使用正交的2D平面学习3D形状的连续有向距离场表示。此外，我们通过传

    arXiv:2403.18241v1 Announce Type: cross  Abstract: 3D shape generation aims to produce innovative 3D content adhering to specific conditions and constraints. Existing methods often decompose 3D shapes into a sequence of localized components, treating each element in isolation without considering spatial consistency. As a result, these approaches exhibit limited versatility in 3D data representation and shape generation, hindering their ability to generate highly diverse 3D shapes that comply with the specified constraints. In this paper, we introduce a novel spatial-aware 3D shape generation framework that leverages 2D plane representations for enhanced 3D shape modeling. To ensure spatial coherence and reduce memory usage, we incorporate a hybrid shape representation technique that directly learns a continuous signed distance field representation of the 3D shape using orthogonal 2D planes. Additionally, we meticulously enforce spatial correspondences across distinct planes using a tra
    
[^3]: SAT编码的偏序模型用于图着色问题

    SAT Encoding of Partial Ordering Models for Graph Coloring Problems

    [https://arxiv.org/abs/2403.15961](https://arxiv.org/abs/2403.15961)

    该研究提出了新的SAT编码的偏序模型用于图着色问题，实验结果显示在一些情况下超越了现有的最先进方法，并对带宽着色问题进行了理论分析。

    

    在本文中，我们提出了基于偏序的整数线性规划（ILP）模型的图着色问题（GCP）和带宽着色问题（BCP）的新SAT编码。 GCP要求给定图的顶点分配最少数量的颜色，以便每两个相邻的顶点得到不同的颜色。 BCP是一个泛化问题，其中每条边都有一个权重，要求分配的颜色之间有最小的“距离”，目标是最小化使用的“最大”颜色。 对于被广泛研究的GCP，我们在DIMACS基准集上实验比较了我们新的SAT编码与现有最先进方法。 我们的评估证实，这种SAT编码对于稀疏图是有效的，并且甚至在一些DIMACS示例上胜过了现有最先进方法。 对于BCP，我们的理论分析表明，基于偏序的SAT和ILP公式的大小在渐近意义下小于经典的解法。

    arXiv:2403.15961v1 Announce Type: new  Abstract: In this paper, we suggest new SAT encodings of the partial-ordering based ILP model for the graph coloring problem (GCP) and the bandwidth coloring problem (BCP). The GCP asks for the minimum number of colors that can be assigned to the vertices of a given graph such that each two adjacent vertices get different colors. The BCP is a generalization, where each edge has a weight that enforces a minimal "distance" between the assigned colors, and the goal is to minimize the "largest" color used. For the widely studied GCP, we experimentally compare our new SAT encoding to the state-of-the-art approaches on the DIMACS benchmark set. Our evaluation confirms that this SAT encoding is effective for sparse graphs and even outperforms the state-of-the-art on some DIMACS instances. For the BCP, our theoretical analysis shows that the partial-ordering based SAT and ILP formulations have an asymptotically smaller size than that of the classical assi
    
[^4]: 大型语言模型能够进行上下文中的探索吗？

    Can large language models explore in-context?

    [https://arxiv.org/abs/2403.15371](https://arxiv.org/abs/2403.15371)

    研究发现，大型语言模型在没有实质干预的情况下很难有效进行探索，除了特定配置下的GPT-4具有满意的探索行为外，其他模型表现不稳定。

    

    我们研究现代大型语言模型（LLMs）在进行探索方面的能力，这是强化学习和决策制定中的核心能力。我们关注现有LLMs的原生性能，没有进行训练干预。我们将LLMs部署为简单多臂老虎机环境中的代理，并完全在上下文中指定环境描述和交互历史，即在LLM提示内部进行。我们使用各种提示设计对GPT-3.5、GPT-4和Llama2进行实验，发现这些模型在没有实质干预的情况下并没有稳健地进行探索：i）在我们的所有实验中，只有一个配置导致了令人满意的探索行为：具有思维链推理和外部总结的交互历史的GPT-4，这些被呈现为充分统计的情况；ii）所有其他配置都没有产生稳健的探索行为，包括具有思维链推理的其他配置。

    arXiv:2403.15371v1 Announce Type: cross  Abstract: We investigate the extent to which contemporary Large Language Models (LLMs) can engage in exploration, a core capability in reinforcement learning and decision making. We focus on native performance of existing LLMs, without training interventions. We deploy LLMs as agents in simple multi-armed bandit environments, specifying the environment description and interaction history entirely in-context, i.e., within the LLM prompt. We experiment with GPT-3.5, GPT-4, and Llama2, using a variety of prompt designs, and find that the models do not robustly engage in exploration without substantial interventions: i) Across all of our experiments, only one configuration resulted in satisfactory exploratory behavior: GPT-4 with chain-of-thought reasoning and an externally summarized interaction history, presented as sufficient statistics; ii) All other configurations did not result in robust exploratory behavior, including those with chain-of-thou
    
[^5]: OTSeg：多提示Sinkhorn注意力用于零样本语义分割

    OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation

    [https://arxiv.org/abs/2403.14183](https://arxiv.org/abs/2403.14183)

    通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。

    

    CLIP的最新成功证明了通过将多模态知识转移到像素级分类来进行零样本语义分割的有希望的结果。然而，在现有方法中，利用预先训练的CLIP知识来紧密对齐文本嵌入和像素嵌入仍然存在局限性。为了解决这个问题，我们提出了OTSeg，这是一种新颖的多模态注意力机制，旨在增强多个文本提示匹配相关像素嵌入的潜力。我们首先提出了基于最优输运（OT）算法的多提示Sinkhorn（MPS），这使得多个文本提示可以有选择地关注图像像素内的各种语义特征。此外，受到Sinkformers在单模态设置中的成功启发，我们引入了MPS的扩展，称为多提示Sinkhorn注意力（MPSA），它有效地取代了Transformer框架中多模态设置中的交叉注意力机制。

    arXiv:2403.14183v1 Announce Type: cross  Abstract: The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. To address this issue, we propose OTSeg, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. We first propose Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads multiple text prompts to selectively focus on various semantic features within image pixels. Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn Attention (MPSA), which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settin
    
[^6]: EnvGen: 通过LLMs生成和调整环境以训练具身体的代理

    EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents

    [https://arxiv.org/abs/2403.12014](https://arxiv.org/abs/2403.12014)

    EnvGen提出了一种新的框架，利用LLMs的推理能力自适应创建训练环境，帮助小型具身体RL代理在弱点方面学习有用技能。

    

    最近有关通过互动进行具身体学习的最新方法直接采用大型语言模型（LLMs）作为代理，以确定环境中的下一步。LLM代理由于其世界知识和推理能力，比基于强化学习（RL）的以往较小的代理表现更强；但频繁调用LLMs速度慢且昂贵。我们提出EnvGen，一个处理这个问题的新框架。首先，我们提示一个LLM生成训练环境，使代理可以快速并行学习不同任务。具体而言，LLM获得任务描述和模拟器目标，然后被要求生成一组环境配置。

    arXiv:2403.12014v1 Announce Type: cross  Abstract: Recent SOTA approaches for embodied learning via interaction directly employ large language models (LLMs) as agents to determine the next steps in an environment. Due to their world knowledge and reasoning capabilities, LLM agents achieve stronger performance than previous smaller agents based on reinforcement learning (RL); however, frequently calling LLMs is slow and expensive. Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller embodied RL agents learn useful skills that they are weak at? We propose EnvGen, a novel framework to address this question. First, we prompt an LLM to generate training environments that allow agents to quickly learn different tasks in parallel. Concretely, the LLM is given the task description and simulator objectives that the agents should learn and is then asked to generate a set of environment configurations (e.g
    
[^7]: 单上下文大批量抽样的分叉注意力

    Bifurcated Attention for Single-Context Large-Batch Sampling

    [https://arxiv.org/abs/2403.08845](https://arxiv.org/abs/2403.08845)

    分叉注意力是针对语言模型推断中单上下文批量抽样环境开发的方法，通过将注意力机制分成两个独立的操作来减少冗余内存IO成本，提高效率并降低延迟。

    

    在我们的研究中，我们提出了一种称为分叉注意力的方法，用于单上下文批量抽样环境下的语言模型推断。这种方法旨在减少冗余的内存IO成本，这是高批量大小和长上下文长度的延迟的重要因素。分叉注意力通过在增量解码期间将注意力机制划分为两个不同的GEMM操作，分别专注于来自预填充的KV缓存以及解码过程，从而实现这一目标。该方法确保了精确的计算，并维持常规注意力机制的计算负载（FLOPs），但减少了内存IO。分叉注意力还与减少KV缓存内存IO已知的多查询注意力机制兼容，进一步实现更高的批量大小和上下文长度。由此带来的效率导致更低的延迟，改善了实时应用的适用性，例如实现大规模并行的答案生成。

    arXiv:2403.08845v1 Announce Type: cross  Abstract: In our study, we present bifurcated attention, a method developed for language model inference in single-context batch sampling contexts. This approach aims to reduce redundant memory IO costs, a significant factor in latency for high batch sizes and long context lengths. Bifurcated attention achieves this by dividing the attention mechanism during incremental decoding into two distinct GEMM operations, focusing on the KV cache from prefill and the decoding process. This method ensures precise computation and maintains the usual computational load (FLOPs) of standard attention mechanisms, but with reduced memory IO. Bifurcated attention is also compatible with multi-query attention mechanism known for reduced memory IO for KV cache, further enabling higher batch size and context length. The resulting efficiency leads to lower latency, improving suitability for real-time applications, e.g., enabling massively-parallel answer generation 
    
[^8]: 在重症监护病房（ICU）中利用计算机视觉检查探视和活动能力

    Leveraging Computer Vision in the Intensive Care Unit (ICU) for Examining Visitation and Mobility

    [https://arxiv.org/abs/2403.06322](https://arxiv.org/abs/2403.06322)

    在重症监护病房中利用计算机视觉系统，可以实现不存在的评估和增强现有评估的频率和准确性，同时减少工作人员工作量。

    

    尽管密切监测重症监护病房（ICU）患者的重要性，由于医护人员面临的时间限制，许多方面仍然受到限制评估。过度的探视可能在休息时间加剧循环节律紊乱和谵妄的风险，但在ICU中并未被捕捉。同样，活动能力可以是ICU患者康复或恶化的重要指标，但只被零星地捕捉或根本不被捕捉。在过去几年中，计算机视觉领域在许多领域中找到了应用，减轻了人力负担。在ICU中使用计算机视觉系统也有可能实现不存在的评估或增强现有评估的频率和准确性，同时减少工作人员的工作量。本研究利用基于深度成像的最新非侵入式计算机视觉系统，

    arXiv:2403.06322v1 Announce Type: cross  Abstract: Despite the importance of closely monitoring patients in the Intensive Care Unit (ICU), many aspects are still assessed in a limited manner due to the time constraints imposed on healthcare providers. For example, although excessive visitations during rest hours can potentially exacerbate the risk of circadian rhythm disruption and delirium, it is not captured in the ICU. Likewise, while mobility can be an important indicator of recovery or deterioration in ICU patients, it is only captured sporadically or not captured at all. In the past few years, the computer vision field has found application in many domains by reducing the human burden. Using computer vision systems in the ICU can also potentially enable non-existing assessments or enhance the frequency and accuracy of existing assessments while reducing the staff workload. In this study, we leverage a state-of-the-art noninvasive computer vision system based on depth imaging to c
    
[^9]: 使用扩散模型进行潜在数据集蒸馏

    Latent Dataset Distillation with Diffusion Models

    [https://arxiv.org/abs/2403.03881](https://arxiv.org/abs/2403.03881)

    这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。

    

    机器学习的有效性传统上依赖于越来越大的数据集的可用性。然而，大型数据集带来存储挑战，并且包含一些非影响力样本，在训练过程中可以被忽略而不影响模型最终的准确性。为了应对这些限制，出现了将数据集信息蒸馏成一组压缩样本（合成样本），即蒸馏数据集的概念。其中一个关键方面是选择用于连接原始和合成数据集的架构（通常是ConvNet）。然而，如果所使用的模型架构与蒸馏过程中使用的模型不同，则最终准确性会降低。另一个挑战是生成高分辨率图像，例如128x128及更高。

    arXiv:2403.03881v1 Announce Type: cross  Abstract: The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both chal
    
[^10]: 用神经重写系统解决算法问题

    A Neural Rewriting System to Solve Algorithmic Problems

    [https://arxiv.org/abs/2402.17407](https://arxiv.org/abs/2402.17407)

    提出了一种受重写系统启发的神经架构，用于学习算法任务，通过Selector、Solver和Combiner三个专门模块实现算法任务的简化，具有较好的外推能力

    

    现代神经网络架构仍然难以学习需要系统应用组合规则来解决超出分布问题实例的算法程序。在这项工作中，我们提出了一种原创方法来学习受重写系统启发的算法任务，重写系统是符号人工智能中的经典框架。我们展示了重写系统可以被实现为一个由专门模块组成的神经架构：选择器识别要处理的目标子表达式，求解器通过计算相应的结果简化子表达式，组合器通过用提供的解决方案替换子表达式生成原始表达式的新版本。我们在三种涉及简化涉及列表、算术和代数表达式的符号公式的算法任务上评估我们的模型。我们测试了所提架构的外推能力

    arXiv:2402.17407v1 Announce Type: cross  Abstract: Modern neural network architectures still struggle to learn algorithmic procedures that require to systematically apply compositional rules to solve out-of-distribution problem instances. In this work, we propose an original approach to learn algorithmic tasks inspired by rewriting systems, a classic framework in symbolic artificial intelligence. We show that a rewriting system can be implemented as a neural architecture composed by specialized modules: the Selector identifies the target sub-expression to process, the Solver simplifies the sub-expression by computing the corresponding result, and the Combiner produces a new version of the original expression by replacing the sub-expression with the solution provided. We evaluate our model on three types of algorithmic tasks that require simplifying symbolic formulas involving lists, arithmetic, and algebraic expressions. We test the extrapolation capabilities of the proposed architectu
    
[^11]: 安全代码生成的指令调优

    Instruction Tuning for Secure Code Generation

    [https://arxiv.org/abs/2402.09497](https://arxiv.org/abs/2402.09497)

    现代语言模型在编程中得到广泛应用，指令调优是一个增强其实用性的关键过程。然而，现有的方案忽视了生成代码的安全性。本文提出了SafeCoder，通过安全微调和标准指令调优相结合，来优化安全性和实用性。

    

    现代语言模型(LMs)在日常和专业环境中得到了广泛的认可，尤其在编程中。指令调优是一种关键的过程，通过训练LMs遵循用户指令和人类偏好，从而大大增强了LMs的实用性。然而，现有的指令调优方案忽视了一个关键方面：生成代码的安全性。因此，即使是最先进的指令调优的LMs也经常产生不安全的代码，带来了重大的安全风险。在这项工作中，我们引入了SafeCoder来填补这个差距。SafeCoder使用一个多样化和高质量的数据集进行安全为中心的微调，我们使用自动化流水线收集了这个数据集。我们将安全微调与标准的指令调优相结合，以便同时优化安全性和实用性。尽管简单，但我们展示了SafeCoder的有效性。

    arXiv:2402.09497v1 Announce Type: cross  Abstract: Modern language models (LMs) have gained widespread acceptance in everyday and professional contexts, particularly in programming. An essential procedure enabling this adoption is instruction tuning, which substantially enhances LMs' practical utility by training them to follow user instructions and human preferences. However, existing instruction tuning schemes overlook a crucial aspect: the security of generated code. As a result, even the state-of-the-art instruction-tuned LMs frequently produce unsafe code, posing significant security risks. In this work, we introduce SafeCoder to address this gap. SafeCoder performs security-centric fine-tuning using a diverse and high-quality dataset that we collected using an automated pipeline. We integrate the security fine-tuning with standard instruction tuning, to facilitate a joint optimization of both security and utility. Despite its simplicity, we show that SafeCoder is effective across
    
[^12]: 人类中的即时概括与深度神经网络中的滞后概括——表示分歧的证据？

    Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?

    [https://arxiv.org/abs/2402.09303](https://arxiv.org/abs/2402.09303)

    研究对比了人类和深度神经网络在图像分类中的行为差异，发现人类具有即时概括能力，而DNNs存在滞后概括现象，这表明了表示分歧的存在。

    

    近期的研究在图像分类领域中对比了人类与深度神经网络（DNNs）的许多行为比较。通常，比较研究关注的是学习过程的最终结果，通过测量和比较目标类别表示的相似性。然而，这些表示如何形成即其过程——即在获取过程中观察到的行为变化和中间阶段——往往少有直接和实证的比较。在这里，我们报告了对人类观察者和不同经典与最新技术的DNNs中可转移表示是如何被获取的的详细调查。我们开发了一个受限的监督学习环境，该环境中我们对齐了学习相关的参数，如起始点、输入模式、可用输入数据以及提供的反馈。在整个学习过程中我们评估...

    arXiv:2402.09303v1 Announce Type: cross Abstract: Recent research has seen many behavioral comparisons between humans and deep neural networks (DNNs) in the domain of image classification. Often, comparison studies focus on the end-result of the learning process by measuring and comparing the similarities in the representations of object categories once they have been formed. However, the process of how these representations emerge$\unicode{x2014}$that is, the behavioral changes and intermediate stages observed during the acquisition$\unicode{x2014}$is less often directly and empirically compared.   Here we report a detailed investigation of how transferable representations are acquired in human observers and various classic and state-of-the-art DNNs. We develop a constrained supervised learning environment in which we align learning-relevant parameters such as starting point, input modality, available input data and the feedback provided. Across the whole learning process we evaluate 
    
[^13]: 基于树集成的情境多臂老虎机

    Tree Ensembles for Contextual Bandits

    [https://arxiv.org/abs/2402.06963](https://arxiv.org/abs/2402.06963)

    本论文提出了一种基于树集成的情境多臂老虎机新框架，通过整合两种广泛使用的老虎机方法，在标准和组合设置中实现了优于基于神经网络的方法的性能，在减少后悔和计算时间方面表现出更出色的性能。

    

    我们提出了一个基于树集成的情境多臂老虎机的新框架。我们的框架将两种广泛使用的老虎机方法，上信心界和汤普森抽样，整合到标准和组合设置中。通过使用流行的树集成方法XGBoost进行多次实验研究，我们展示了我们框架的有效性。当应用于基准数据集和道路网络导航的真实世界应用时，与基于神经网络的最先进方法相比，我们的方法在减少后悔和计算时间方面表现出更好的性能。

    We propose a novel framework for contextual multi-armed bandits based on tree ensembles. Our framework integrates two widely used bandit methods, Upper Confidence Bound and Thompson Sampling, for both standard and combinatorial settings. We demonstrate the effectiveness of our framework via several experimental studies, employing XGBoost, a popular tree ensemble method. Compared to state-of-the-art methods based on neural networks, our methods exhibit superior performance in terms of both regret minimization and computational runtime, when applied to benchmark datasets and the real-world application of navigation over road networks.
    
[^14]: 学习对比特征表示来进行面部动作单元检测

    Learning Contrastive Feature Representations for Facial Action Unit Detection

    [https://arxiv.org/abs/2402.06165](https://arxiv.org/abs/2402.06165)

    这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。

    

    面部动作单元（AU）检测的主要方法涉及监督的多标签二进制分类问题。现有的方法常常对AU的像素级信息进行编码，从而对模型的复杂性和表达能力提出了很大的要求。此外，由于存在噪声AU标签，这种做法增加了过拟合的风险。在本研究中，我们引入了一个对比学习框架，通过监督和自监督信号增强。目标是在AU检测领域中摆脱传统的像素级学习范式，获得判别特征。为了应对噪声AU标签带来的挑战，我们通过引入自监督信号来增强监督信号。这种增强是通过正样本抽样实现的，包括三种不同类型的正样本对。另外，为了减轻每个AU类型的分布不平衡问题，我们采用了一种权衡重要性的损失函数。

    The predominant approach to facial action unit (AU) detection revolves around a supervised multi-label binary classification problem. Existing methodologies often encode pixel-level information of AUs, thereby imposing substantial demands on model complexity and expressiveness. Moreover, this practice elevates the susceptibility to overfitting due to the presence of noisy AU labels. In the present study, we introduce a contrastive learning framework enhanced by both supervised and self-supervised signals. The objective is to acquire discriminative features, deviating from the conventional pixel-level learning paradigm within the domain of AU detection. To address the challenge posed by noisy AU labels, we augment the supervised signal through the introduction of a self-supervised signal. This augmentation is achieved through positive sample sampling, encompassing three distinct types of positive sample pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we empl
    
[^15]: GPT-4使用结构化叙事提示生成生活事件的叙述：一项验证研究

    GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study

    [https://arxiv.org/abs/2402.05435](https://arxiv.org/abs/2402.05435)

    本研究通过使用结构化叙事提示，验证了GPT-4生成的叙述在传达生活事件方面的有效性。研究结果表明，大多数叙述能够足够传达提示的意图。同时，通过机器学习模型的训练和验证，可以自动识别有效和无效的叙述。

    

    大型语言模型在生成各种叙述方面发挥重要作用，促进了对其在叙述形式中传达生活事件效果的系统探索。本研究利用零-shot结构化叙事提示，使用OpenAI的GPT-4生成了24,000个叙述。从这个数据集中，我们手动分类了2,880个叙述，并评估它们在传达出生、死亡、招聘和解雇事件方面的有效性。令人惊讶的是，87.43%的叙述足够传达结构化提示的意图。为了自动识别有效和无效的叙述，我们对分类数据集训练和验证了九个机器学习模型。利用这些模型，我们扩展了对剩余21,120个叙述的分类预测分析。所有的机器学习模型在将有效的叙述分类为有效方面表现出色，但在同时将无效的叙述分类为无效方面存在挑战。我们的研究结果不仅推进了这一领域的发展，还提供了自动识别有效叙述的有益信息。

    Large Language Models (LLMs) play a pivotal role in generating vast arrays of narratives, facilitating a systematic exploration of their effectiveness for communicating life events in narrative form. In this study, we employ a zero-shot structured narrative prompt to generate 24,000 narratives using OpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and evaluate their validity in conveying birth, death, hiring, and firing events. Remarkably, 87.43% of the narratives sufficiently convey the intention of the structured prompt. To automate the identification of valid and invalid narratives, we train and validate nine Machine Learning models on the classified datasets. Leveraging these models, we extend our analysis to predict the classifications of the remaining 21,120 narratives. All the ML models excelled at classifying valid narratives as valid, but experienced challenges at simultaneously classifying invalid narratives as invalid. Our findings not only advance th
    
[^16]: 在知识密集型环境中的聊天机器人：比较意图和基于LLM的系统

    Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems

    [https://arxiv.org/abs/2402.04955](https://arxiv.org/abs/2402.04955)

    这项研究比较了在知识密集型环境中基于LLM的认知助手和基于意图的系统，并发现基于LLM的认知助手在用户体验、任务完成率、可用性和个人效能方面表现更好。

    

    认知助手是在知识密集型任务中为人类工作者提供上下文感知支持的聊天机器人。传统上，认知助手以特定方式回应预定义的用户意图和对话模式。然而，这种刚性对自然语言的多样性处理不好。最近自然语言处理的进展，如GPT-4、Llama2和Gemini等大型语言模型（LLM），可能使认知助手能够以更灵活、更像人类的方式进行对话。然而，这种额外的自由度可能会产生意想不到的后果，特别是在准确性至关重要的知识密集型环境中。为了评估在这些环境中使用LLM的潜力，我们进行了一个用户研究，比较了基于LLM的认知助手和基于意图的系统在交互效率、用户体验、工作量和可用性方面的差异。研究结果显示，基于LLM的认知助手在用户体验、任务完成率、可用性和个人效能方面表现更好。

    Cognitive assistants (CA) are chatbots that provide context-aware support to human workers in knowledge-intensive tasks. Traditionally, cognitive assistants respond in specific ways to predefined user intents and conversation patterns. However, this rigidness does not handle the diversity of natural language well. Recent advances in natural language processing (NLP), powering large language models (LLM) such as GPT-4, Llama2, and Gemini, could enable CAs to converse in a more flexible, human-like manner. However, the additional degrees of freedom may have unforeseen consequences, especially in knowledge-intensive contexts where accuracy is crucial. As a preliminary step to assessing the potential of using LLMs in these contexts, we conducted a user study comparing an LLM-based CA to an intent-based system regarding interaction efficiency, user experience, workload, and usability. This revealed that LLM-based CAs exhibited better user experience, task completion rate, usability, and per
    
[^17]: 《定位论文：探索研究模型表示的新框架》

    Position Paper: Toward New Frameworks for Studying Model Representations

    [https://arxiv.org/abs/2402.03855](https://arxiv.org/abs/2402.03855)

    通过逆向工程AI模型的确切算法，机制解释性（MI）旨在理解模型。然而，目前的研究主要关注微不足道的行为和能力，而忽视了隐藏在网络内部的表示。因此，我们呼吁研究界朝着新的框架努力，研究这些表示。

    

    机制解释性（MI）旨在通过逆向工程AI模型学习的确切算法来理解模型。迄今为止，大多数MI研究的行为和能力都是微不足道的和符号对齐的。然而，大多数能力并不那么微不足道，这为研究网络内部的隐藏表示作为分析单位提供了支持。我们进行了文献回顾，对特征和行为进行了形式化的表示，强调了它们的重要性和评估，并进行了一些基本的探索性研究。通过讨论和探索性结果，我们证明了研究表示是一个重要且未被充分研究的领域，并且目前MI中建立的方法不足以理解表示，因此推动研究界朝着研究表示的新框架努力。

    Mechanistic interpretability (MI) aims to understand AI models by reverse-engineering the exact algorithms neural networks learn. Most works in MI so far have studied behaviors and capabilities that are trivial and token-aligned. However, most capabilities are not that trivial, which advocates for the study of hidden representations inside these networks as the unit of analysis. We do a literature review, formalize representations for features and behaviors, highlight their importance and evaluation, and perform some basic exploration in the mechanistic interpretability of representations. With discussion and exploratory results, we justify our position that studying representations is an important and under-studied field, and that currently established methods in MI are not sufficient to understand representations, thus pushing for the research community to work toward new frameworks for studying representations.
    
[^18]: 用多个时间视角增强Transformer RNNs

    Enhancing Transformer RNNs with Multiple Temporal Perspectives

    [https://arxiv.org/abs/2402.02625](https://arxiv.org/abs/2402.02625)

    引入了多个时间视角的概念，用于增强Transformer RNNs对顺序数据的理解能力，在参数数量最小增加的情况下取得了显著的改进。

    

    我们引入了多个时间视角的概念，这是一种适用于循环神经网络（RNN）架构的新方法，用于增强其对顺序数据的理解。该方法涉及维护先前遇到的文本的多样时间视图，显著丰富了语言模型解释上下文的能力。为了展示这种方法的有效性，我们将其纳入了Receptance Weighted Key Value（RWKV）架构，解决了该架构在单个隐藏状态中保留所有历史信息的固有挑战。值得注意的是，即使参数数量增加最少（仅为最初参数数量的0.04%），也实现了此改进。此外，多个时间视角所需的额外参数经过微小的计算开销进行微调，避免了完全预训练的需要。由此产生的模型在提示推断过程中保持了线性的计算复杂度。

    We introduce the concept of multiple temporal perspectives, a novel approach applicable to Recurrent Neural Network (RNN) architectures for enhancing their understanding of sequential data. This method involves maintaining diverse temporal views of previously encountered text, significantly enriching the language models' capacity to interpret context. To show the efficacy of this approach, we incorporate it into the Receptance Weighted Key Value (RWKV) architecture, addressing its inherent challenge of retaining all historical information within a single hidden state. Notably, this improvement is achieved with a minimal increase in the number of parameters --even as little as $0.04\%$ of the original number of parameters. Further, the additional parameters necessary for the multiple temporal perspectives are fine-tuned with minimal computational overhead, avoiding the need for a full pre-training. The resulting model maintains linear computational complexity during prompt inference, en
    
[^19]: 基于深度学习的农业推荐系统：一种多变量天气预测方法

    Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach

    [https://arxiv.org/abs/2401.11410](https://arxiv.org/abs/2401.11410)

    提出了一种基于深度学习和天气预测的农业推荐系统，旨在解决孟加拉国农业面临的天气不利因素对粮食生产的影响，以实现盈利、可持续和农民友好的农业实践。

    

    孟加拉国主要是一个农业国家，农业部门对于加快经济增长和保障人民粮食安全起着至关重要的作用。虽然孟加拉国劳动密集型农业取得了粮食产量稳步增长，但常常受到不利天气条件的影响，如暴雨、低温和干旱。因此，这些因素严重影响了粮食生产，使得国家的粮食安全受到威胁。为了实现盈利、可持续且农民友好的农业实践，本文提出了一种基于天气预测模型的基于上下文的作物推荐系统。

    arXiv:2401.11410v2 Announce Type: replace-cross  Abstract: Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. Wi
    
[^20]: DISTINQT: 一种面向未来移动和无线网络的分布式隐私感知学习框架，用于QoS预测

    DISTINQT: A Distributed Privacy Aware Learning Framework for QoS Prediction for Future Mobile and Wireless Networks. (arXiv:2401.10158v1 [cs.NI])

    [http://arxiv.org/abs/2401.10158](http://arxiv.org/abs/2401.10158)

    DISTINQT是一种面向未来移动和无线网络的隐私感知分布式学习框架，用于QoS预测。

    

    5G和6G以后的网络将支持依赖一定服务质量（QoS）的新的和具有挑战性的用例和应用程序。及时预测QoS对于安全关键应用（如车辆通信）尤为重要。尽管直到最近，QoS预测一直由集中式人工智能（AI）解决方案完成，但已经出现了一些隐私、计算和运营方面的问题。替代方案已经出现（如分割学习、联邦学习），将复杂度较低的AI任务分布在节点之间，同时保护数据隐私。然而，考虑到未来无线网络的异构性，当涉及可扩展的分布式学习方法时，会出现新的挑战。该研究提出了一种名为DISTINQT的面向QoS预测的隐私感知分布式学习框架。

    Beyond 5G and 6G networks are expected to support new and challenging use cases and applications that depend on a certain level of Quality of Service (QoS) to operate smoothly. Predicting the QoS in a timely manner is of high importance, especially for safety-critical applications as in the case of vehicular communications. Although until recent years the QoS prediction has been carried out by centralized Artificial Intelligence (AI) solutions, a number of privacy, computational, and operational concerns have emerged. Alternative solutions have been surfaced (e.g. Split Learning, Federated Learning), distributing AI tasks of reduced complexity across nodes, while preserving the privacy of the data. However, new challenges rise when it comes to scalable distributed learning approaches, taking into account the heterogeneous nature of future wireless networks. The current work proposes DISTINQT, a privacy-aware distributed learning framework for QoS prediction. Our framework supports mult
    
[^21]: 一种新的神经计算范式：可学习神经元和可适应结构的X-Net

    A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure. (arXiv:2401.01772v1 [cs.AI])

    [http://arxiv.org/abs/2401.01772](http://arxiv.org/abs/2401.01772)

    本研究提出了一种名为X-Net的新型神经网络，通过利用交替反向传播机制，在训练过程中根据导数信息动态选择适当的激活函数，以增强网络的表示能力。

    

    人工神经网络(ANNs)已经渗透到各个学科领域，从生物信息学到金融分析，在当代科学研究中已经成为不可或缺的一部分。然而，传统神经网络的固定网络结构和激活函数的固有限制导致了一些问题。为了解决这些问题，本研究提出了一种称为X-Net的新型神经网络。通过利用我们设计的交替反向传播机制，在训练过程中根据导数信息动态选择适当的激活函数，以增强网络的表示能力。

    Artificial neural networks (ANNs) have permeated various disciplinary domains, ranging from bioinformatics to financial analytics, where their application has become an indispensable facet of contemporary scientific research endeavors. However, the inherent limitations of traditional neural networks arise due to their relatively fixed network structures and activation functions. 1, The type of activation function is single and relatively fixed, which leads to poor "unit representation ability" of the network, and it is often used to solve simple problems with very complex networks; 2, the network structure is not adaptive, it is easy to cause network structure redundant or insufficient. To address the aforementioned issues, this study proposes a novel neural network called X-Net. By utilizing our designed Alternating Backpropagation mechanism, X-Net dynamically selects appropriate activation functions based on derivative information during training to enhance the network's representati
    
[^22]: 在重症监护室中检测视觉线索与患者临床状态的关联

    Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status. (arXiv:2311.00565v1 [cs.CV])

    [http://arxiv.org/abs/2311.00565](http://arxiv.org/abs/2311.00565)

    在重症监护室中开发能够检测视觉线索并与患者临床状态关联的人工智能工具，可以提供更客观和详细的监测能力。

    

    重症监护室（ICU）为患有生命威胁的患者提供密切监护和连续护理。然而，由于时间限制和医疗保健工作者的工作负荷，ICU中的连续患者评估仍然有限。现有的ICU患者评估，如疼痛或活动能力评估，大多是零散和手动实施的，从而引入了人为错误的潜在可能性。开发能够增强ICU中人类评估的人工智能（AI）工具可以有利于提供更客观和详细的监测能力。例如，捕捉与疼痛或不安相关的患者面部线索的变化可以帮助调整与疼痛相关的药物或检测可能引起不安的情况，如谵妄。此外，在不良临床事件发生期间或之前，视觉线索的微妙变化与高分辨率生理信号相结合可能有助于连续患者监测。

    Intensive Care Units (ICU) provide close supervision and continuous care to patients with life-threatening conditions. However, continuous patient assessment in the ICU is still limited due to time constraints and the workload on healthcare providers. Existing patient assessments in the ICU such as pain or mobility assessment are mostly sporadic and administered manually, thus introducing the potential for human errors. Developing Artificial intelligence (AI) tools that can augment human assessments in the ICU can be beneficial for providing more objective and granular monitoring capabilities. For example, capturing the variations in a patient's facial cues related to pain or agitation can help in adjusting pain-related medications or detecting agitation-inducing conditions such as delirium. Additionally, subtle changes in visual cues during or prior to adverse clinical events could potentially aid in continuous patient monitoring when combined with high-resolution physiological signal
    
[^23]: 物理感知机器学习革命科学范式对于机器学习和基于过程的水文学的影响

    Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology. (arXiv:2310.05227v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05227](http://arxiv.org/abs/2310.05227)

    物理感知机器学习是一种革命性方法，它将物理知识和机器学习相结合，提供了准确的水文学理解和水循环预测，对于管理水资源以应对气候变化等挑战具有重要意义。

    

    准确的水文学理解和水循环预测对于解决水资源管理中的科学和社会挑战至关重要，特别是在人为气候变化的动态影响下。现有的评论主要关注机器学习在这个领域的发展，然而水文学和机器学习作为独立的范式存在明显的区别。在这里，我们介绍了以物理感知机器学习作为一种变革性方法，克服了这种认知障碍，并革新了这两个领域。具体来说，我们提出了一个综合的物理感知机器学习方法的评论，构建了一个结构化社区（PaML），将先前的物理知识或基于物理的建模与机器学习相结合。我们系统地从物理数据引导的机器学习、物理信息处理的机器学习、物理嵌入式机器学习和物理感知混合学习四个方面分析了这些PaML方法。PaML促进了机器学习辅助的假设推导。

    Accurate hydrological understanding and water cycle prediction are crucial for addressing scientific and societal challenges associated with the management of water resources, particularly under the dynamic influence of anthropogenic climate change. Existing reviews predominantly concentrate on the development of machine learning (ML) in this field, yet there is a clear distinction between hydrology and ML as separate paradigms. Here, we introduce physics-aware ML as a transformative approach to overcome the perceived barrier and revolutionize both fields. Specifically, we present a comprehensive review of the physics-aware ML methods, building a structured community (PaML) of existing methodologies that integrate prior physical knowledge or physics-based modeling into ML. We systematically analyze these PaML methodologies with respect to four aspects: physical data-guided ML, physics-informed ML, physics-embedded ML, and physics-aware hybrid learning. PaML facilitates ML-aided hypothe
    
[^24]: 零样本连续提示传递：在语言模型之间泛化任务语义

    Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models. (arXiv:2310.01691v1 [cs.CL])

    [http://arxiv.org/abs/2310.01691](http://arxiv.org/abs/2310.01691)

    这项工作提出了一种零样本连续提示传递方法，通过将源提示编码到相对空间中，并搜索相应的目标提示，在不同的语言模型之间实现了任务语义的泛化，实验证实了该方法的有效性。

    

    在自然语言处理（NLP）中，通过调整提示已经成为一种越来越受欢迎的方法，用于将大型语言模型适应特定任务。然而，这些提示，特别是连续提示，在不同模型之间的可传递性仍然是一个挑战。在这项工作中，我们提出了一种零样本连续提示传递方法，其中源提示被编码到相对空间中，并搜索相应的目标提示以将其传递到目标模型。实验结果证实了我们方法的有效性，表明连续提示中的“任务语义”可以在各种语言模型之间泛化。此外，我们发现将来自多个源模型的“任务语义”结合可以进一步增强传递的泛化能力。

    Prompt tuning in natural language processing (NLP) has become an increasingly popular method for adapting large language models to specific tasks. However, the transferability of these prompts, especially continuous prompts, between different models remains a challenge. In this work, we propose a zero-shot continuous prompt transfer method, where source prompts are encoded into relative space and the corresponding target prompts are searched for transferring to target models. Experimental results confirm the effectiveness of our method, showing that 'task semantics' in continuous prompts can be generalized across various language models. Moreover, we find that combining 'task semantics' from multiple source models can further enhance the generalizability of transfer.
    
[^25]: 在异构设备上减轻联邦学习中的群体偏见

    Mitigating Group Bias in Federated Learning for Heterogeneous Devices. (arXiv:2309.07085v1 [cs.LG])

    [http://arxiv.org/abs/2309.07085](http://arxiv.org/abs/2309.07085)

    本文提出了一种在分布式边缘应用中减轻联邦学习中群体偏见的方法，该方法可以通过计算跨域群体重要性来减轻全局模型的偏见，并保持隐私和资源利用效率。

    

    联邦学习正在分布式边缘应用中崭露头角作为一种保护隐私的模型训练方法。然而，大多数边缘部署是异构的，即它们的感知能力和环境在部署中各不相同。这种边缘异构违反了本地数据在客户端之间独立且分布相同 (IID) 的特性，产生了有偏见的全局模型，即对特定社区或群体做出不公平的决策和歧视。现有的偏见缓解技术只关注非IID数据中由标签异构引起的偏见，并没有考虑由特征异构导致的领域变化，也没有解决全局群体公平的问题。我们的工作提出了一种在保护隐私和不增加资源利用开销的情况下，减少群体偏见的联邦学习框架。我们的主要思想是利用平均条件概率来计算跨域群体重要性。

    Federated Learning is emerging as a privacy-preserving model training approach in distributed edge applications. As such, most edge deployments are heterogeneous in nature i.e., their sensing capabilities and environments vary across deployments. This edge heterogeneity violates the independence and identical distribution (IID) property of local data across clients and produces biased global models i.e. models that contribute to unfair decision-making and discrimination against a particular community or a group. Existing bias mitigation techniques only focus on bias generated from label heterogeneity in non-IID data without accounting for domain variations due to feature heterogeneity and do not address global group-fairness property.  Our work proposes a group-fair FL framework that minimizes group-bias while preserving privacy and without resource utilization overhead. Our main idea is to leverage average conditional probabilities to compute a cross-domain group \textit{importance we
    
[^26]: 自动驾驶系统测试与改进的边界状态生成

    Boundary State Generation for Testing and Improvement of Autonomous Driving Systems. (arXiv:2307.10590v1 [cs.SE])

    [http://arxiv.org/abs/2307.10590](http://arxiv.org/abs/2307.10590)

    该论文介绍了一种新的自动驾驶系统测试生成器（GenBo），它通过在无故障环境中变异自动驾驶车辆的驾驶条件来生成边界状态对，以解决现有测试方法中存在的问题。

    

    最近深度神经网络（DNN）和传感器技术的进展使得自动驾驶系统（ADS）具有了越来越高的自主性。然而，评估其可靠性仍然是一个关键问题。目前的ADS测试方法修改模拟驾驶环境的可控属性，直到ADS出现问题。这种方法有两个主要缺点：（1）对模拟环境的修改可能不容易转移到实际测试环境（例如改变道路形状）；（2）即使ADS在某些环境中成功，这些环境实例也会被丢弃，尽管它们可能包含ADS可能出现问题的潜在驾驶条件。本文提出了一种新的ADS测试生成器——GenBo（GENerator of BOundary state pairs）。GenBo在一个无故障环境实例中变异自动驾驶车辆的驾驶条件（位置，速度和方向），并有效地生成可边界化的状态对。

    Recent advances in Deep Neural Networks (DNNs) and sensor technologies are enabling autonomous driving systems (ADSs) with an ever-increasing level of autonomy. However, assessing their dependability remains a critical concern. State-of-the-art ADS testing approaches modify the controllable attributes of a simulated driving environment until the ADS misbehaves. Such approaches have two main drawbacks: (1) modifications to the simulated environment might not be easily transferable to the in-field test setting (e.g., changing the road shape); (2) environment instances in which the ADS is successful are discarded, despite the possibility that they could contain hidden driving conditions in which the ADS may misbehave.  In this paper, we present GenBo (GENerator of BOundary state pairs), a novel test generator for ADS testing. GenBo mutates the driving conditions of the ego vehicle (position, velocity and orientation), collected in a failure-free environment instance, and efficiently gener
    
[^27]: 关于需要描述分布偏移的语言：基于表格数据集的案例分析

    On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets. (arXiv:2307.05284v1 [cs.LG])

    [http://arxiv.org/abs/2307.05284](http://arxiv.org/abs/2307.05284)

    该论文通过对表格数据集中的自然偏移进行研究，发现$Y|X$-偏移最为普遍。为了推动研究人员开发描述数据分布偏移的精细语言，作者构建了WhyShift实验平台，并讨论了$Y|X$-偏移对算法的影响。

    

    不同的分布偏移需要不同的算法和操作干预。方法研究必须以其所涉及的具体偏移为基础。尽管新兴的基准数据为实证研究提供了有希望的基础，但它们隐含地关注协变量偏移，并且实证发现的有效性取决于偏移类型，例如，当$Y|X$分布发生变化时，之前关于算法性能的观察可能无效。我们对5个表格数据集中的自然偏移进行了深入研究，通过对86,000个模型配置进行实验，发现$Y|X$-偏移最为普遍。为了鼓励研究人员开发一种精细的描述数据分布偏移的语言，我们构建了WhyShift，一个由策划的真实世界偏移测试平台，在其中我们对我们基准性能的偏移类型进行了表征。由于$Y|X$-偏移在表格设置中很常见，我们确定了受到最大$Y|X$-偏移影响的协变量区域，并讨论了对算法的影响。

    Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithm
    
[^28]: Skill-Critic: 用于强化学习中学习技能的筛选与优化

    Skill-Critic: Refining Learned Skills for Reinforcement Learning. (arXiv:2306.08388v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.08388](http://arxiv.org/abs/2306.08388)

    基于技能筛选与优化的Skill-Critic算法能够提高稀疏奖励环境下强化学习中低层策略的可靠性，并显著提高了性能。

    

    分层强化学习可以通过时间抽象将一个策略分为多个层次，加快长期决策的速度。在稀疏奖励的环境中，技能即原始动作的序列，已经取得了有望的结果。通常情况下，技能的潜在空间和策略是从离线数据中发现的，但由于演示覆盖范围低或分布转移，所得到的低层策略可能不可靠。因此，我们提出了一种Fine-tuning低层策略与高层技能选择相结合的解决方案。我们的Skill-Critic算法优化了低层和高层策略，并通过从离线演示数据中学习的潜在空间进行初始化和规范化，以引导联合策略优化。我们在多个稀疏强化学习环境中验证了我们的方法，包括Gran Turismo Sport中新的稀疏奖励自主赛车任务。实验表明，Skill-Critic的低层策略Fine-tuning和演示引导策略初始化显著提高了性能。

    Hierarchical reinforcement learning (RL) can accelerate long-horizon decision-making by temporally abstracting a policy into multiple levels. Promising results in sparse reward environments have been seen with skills, i.e. sequences of primitive actions. Typically, a skill latent space and policy are discovered from offline data, but the resulting low-level policy can be unreliable due to low-coverage demonstrations or distribution shifts. As a solution, we propose fine-tuning the low-level policy in conjunction with high-level skill selection. Our Skill-Critic algorithm optimizes both the low and high-level policies; these policies are also initialized and regularized by the latent space learned from offline demonstrations to guide the joint policy optimization. We validate our approach in multiple sparse RL environments, including a new sparse reward autonomous racing task in Gran Turismo Sport. The experiments show that Skill-Critic's low-level policy fine-tuning and demonstration-g
    
[^29]: 基于语音的基础语法：自发联接的自监督深度神经网络

    Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks. (arXiv:2305.01626v1 [cs.CL])

    [http://arxiv.org/abs/2305.01626](http://arxiv.org/abs/2305.01626)

    该论文提出了一种基于语音的完全无监督的方法，可以直接从原始语音中建立基础语法模型。作者发现，在基于声音的单词记录上训练的卷积神经网络可以自发连接两个或三个单词，并且可以学会将单词嵌入到新的未见过的单词组合中，这是之前未报道的属性，这一发现对我们理解神经网络的学习方式和建立从原始声学输入中的语法及其演化的模型都有重要的意义。

    

    语法的计算模型主要基于文本。本文提出了一种完全无监督的方法，可以直接从原始语音中建立基础语法模型。我们重点研究了最普遍和基本的语法特性之一——联接。我们介绍了自发联接现象：卷积神经网络(CNN)在个别单词的声学记录上训练时，开始产生输出，这些输出将两个甚至三个单词连接在一起，而不会接触到具有多个单词的输入数据。此外，训练两个单词的网络可以学习将单词嵌入到新的未见过的单词组合中。据我们所知，这是在生成对抗网络环境下训练的原始语音CNN以前未报道的属性，它不仅对我们理解这些体系结构的学习方式有影响，还对建立从原始声学输入中的语法及其演化的模型有影响。

    Computational models of syntax are predominantly text-based. Here we propose that basic syntax can be modeled directly from raw speech in a fully unsupervised way. We focus on one of the most ubiquitous and basic properties of syntax -- concatenation. We introduce spontaneous concatenation: a phenomenon where convolutional neural networks (CNNs) trained on acoustic recordings of individual words start generating outputs with two or even three words concatenated without ever accessing data with multiple words in the input. Additionally, networks trained on two words learn to embed words into novel unobserved word combinations. To our knowledge, this is a previously unreported property of CNNs trained on raw speech in the Generative Adversarial Network setting and has implications both for our understanding of how these architectures learn as well as for modeling syntax and its evolution from raw acoustic inputs.
    
[^30]: AI增强的重症监护室：通过普适感知革命性地改善患者护理

    AI-Enhanced Intensive Care Unit: Revolutionizing Patient Care with Pervasive Sensing. (arXiv:2303.06252v1 [cs.AI])

    [http://arxiv.org/abs/2303.06252](http://arxiv.org/abs/2303.06252)

    本文介绍了一种AI增强的重症监护室系统，通过普适感知和数据处理，可以改善患者的视觉监测和评估，提高护理质量。

    This paper introduces an AI-enhanced ICU system that improves patient visual monitoring and assessment, and ultimately enhances the quality of care, through pervasive sensing and data processing.

    重症监护室（ICU）是一个专门的医院空间，用于接受危重病人的密集护理和监测。全面的监测对于评估患者的病情，特别是病情的严重程度以及最终的护理质量至关重要。然而，由于时间限制和医护人员的工作量，ICU中的患者监测范围受到限制。目前，包括面部表情、姿势和活动能力等细节的视觉评估仅偶尔被捕捉到，或者根本没有被捕捉到。这些手动观察是主观的，容易出现文档错误，并给护理人员带来额外的工作量。人工智能（AI）系统由于其出色的学习能力，有潜力增强患者的视觉监测和评估。这样的系统需要强大的注释数据进行训练。为此，我们开发了普适感知和数据处理系统。

    The intensive care unit (ICU) is a specialized hospital space where critically ill patients receive intensive care and monitoring. Comprehensive monitoring is imperative in assessing patients conditions, in particular acuity, and ultimately the quality of care. However, the extent of patient monitoring in the ICU is limited due to time constraints and the workload on healthcare providers. Currently, visual assessments for acuity, including fine details such as facial expressions, posture, and mobility, are sporadically captured, or not captured at all. These manual observations are subjective to the individual, prone to documentation errors, and overburden care providers with the additional workload. Artificial Intelligence (AI) enabled systems has the potential to augment the patient visual monitoring and assessment due to their exceptional learning capabilities. Such systems require robust annotated data to train. To this end, we have developed pervasive sensing and data processing s
    
[^31]: SynthMorph实现的考虑解剖结构和无关采集方法的联合配准

    Anatomy-aware and acquisition-agnostic joint registration with SynthMorph. (arXiv:2301.11329v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.11329](http://arxiv.org/abs/2301.11329)

    SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。

    

    仿射图像配准是医学图像分析的基石。虽然传统算法可以实现优秀的准确性，但它们需要为每一对图像进行耗时的优化。深度学习方法通过学习一个将图像对映射到输出变换的函数来解决这个问题。评估这个函数是快速的，但捕捉大的变换可能是具有挑战性的，而且如果测试图像的特征从训练领域变化，如分辨率，网络往往会出现困难。大多数仿射方法是对解剖结构无知的，意味着如果算法考虑图像中的所有结构，配准会不准确。我们通过SynthMorph解决了这些缺点，它是一个易于使用的DL工具，用于对任何脑图像进行联合仿射-可变形配准，无需预处理即可直接从MRI扫描仪进行操作。首先，我们利用从标签图生成的具有极大差异的图像来训练网络的策略，从而实现对训练过程中未见的多样化采集规范的鲁棒性能。其次，我们优化网络的损失函数，使其能够考虑不同的解剖特征和学习抵制采集特定限制的变换。通过这些创新，我们实现了更准确和鲁棒的图像配准。

    Affine image registration is a cornerstone of medical-image analysis. While classical algorithms can achieve excellent accuracy, they solve a time-consuming optimization for every image pair. Deep-learning (DL) methods learn a function that maps an image pair to an output transform. Evaluating the function is fast, but capturing large transforms can be challenging, and networks tend to struggle if a test-image characteristic shifts from the training domain, such as resolution. Most affine methods are agnostic to anatomy, meaning the registration will be inaccurate if algorithms consider all structures in the image.  We address these shortcomings with SynthMorph, an easy-to-use DL tool for joint affine-deformable registration of any brain image without preprocessing, right off the MRI scanner. First, we leverage a strategy to train networks with wildly varying images synthesized from label maps, yielding robust performance across acquisition specifics unseen at training. Second, we opti
    
[^32]: CLIP-PAE：投影增强嵌入以提取相关特征用于可分离、可解释、可控的文本指导脸部操纵

    CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Face Manipulation. (arXiv:2210.03919v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.03919](http://arxiv.org/abs/2210.03919)

    提出了一种为了解决文本引导图像操纵中的可分离性、可解释性和可控性问题，通过定义基于相关提示的语料库子空间来获取特定图像特征并引入CLIP投影增强嵌入（PAE）作为优化目标处理的新方法。

    

    最近引入的对比语言-图像预训练（CLIP）将图像和文本嵌入到共同的潜在空间中。这打开了一个大门，即旨在通过提供文字说明来操作输入图像的丰富文学资料。然而，由于联合空间中图像和文本嵌入之间的差异，将文本嵌入作为优化目标通常会导致结果图像中出现意外的伪影。对于操纵来说，可分离性、可解释性和可控性也很难保证。为了缓解这些问题，我们提出定义由相关提示展开的语料库子空间来捕获特定的图像特征。我们引入了CLIP投影增强嵌入（PAE）作为优化目标，以提高文本引导图像操纵的性能。我们的方法是一种简单而通用的范例，可以轻松地计算和适应，并平稳地融入到任何基于CLIP的图像操作算法中。

    Recently introduced Contrastive Language-Image Pre-Training (CLIP) bridges images and text by embedding them into a joint latent space. This opens the door to ample literature that aims to manipulate an input image by providing a textual explanation. However, due to the discrepancy between image and text embeddings in the joint space, using text embeddings as the optimization target often introduces undesired artifacts in the resulting images. Disentanglement, interpretability, and controllability are also hard to guarantee for manipulation. To alleviate these problems, we propose to define corpus subspaces spanned by relevant prompts to capture specific image characteristics. We introduce CLIP Projection-Augmentation Embedding (PAE) as an optimization target to improve the performance of text-guided image manipulation. Our method is a simple and general paradigm that can be easily computed and adapted, and smoothly incorporated into any CLIP-based image manipulation algorithm. To demo
    
[^33]: 持续发展的神经仿真：基于具身计算代理的方法

    Continual Developmental Neurosimulation Using Embodied Computational Agents. (arXiv:2103.05753v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2103.05753](http://arxiv.org/abs/2103.05753)

    通过使用发育Braitenberg Vehicles代理，我们提出了一种具有发育启发的学习代理设计，实现了计算自主性的具身经验和形态发生增长模拟，并考虑了发育轨迹在神经系统形态生成、发育学习和可塑性等方面的作用。

    

    通过综合发育生物学、认知科学和计算建模，我们可以获得很多知识。我们的研究目标是基于Braitenberg Vehicles设计开发受发育启发的学习代理。利用这些代理体现了计算自主性的具身特性，不断靠近对具身经验和形态发生增长作为认知发展能力组成部分的建模。我们考虑生物和认知发展对成年表型生成和可用发展路径的影响。持续发展神经仿真使我们能够考虑发育轨迹在连接神经系统形态发生、发育学习和可塑性等相关现象中所起的作用。由于与持续学习紧密相关，我们的方法与发育具身紧密集成，可以使用一种称为发育Braitenberg Vehicles (dBVs)的代理来实现。

    There is much to learn through synthesis of Developmental Biology, Cognitive Science and Computational Modeling. Our path forward is to present a design for developmentally-inspired learning agents based on Braitenberg Vehicles. Using these agents to exemplify the embodied nature of computational autonomy, we move closer to modeling embodied experience and morphogenetic growth as components of cognitive developmental capacity. We consider biological and cognitive development which influence the generation of adult phenotypes and the contingency of available developmental pathways. Continual developmental neurosimulation allows us to consider the role of developmental trajectories in bridging the related phenomena of nervous system morphogenesis, developmental learning, and plasticity. Being closely tied to continual learning, our approach is tightly integrated with developmental embodiment, and can be implemented using a type of agent called developmental Braitenberg Vehicles (dBVs). T
    

