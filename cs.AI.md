# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training](https://arxiv.org/abs/2403.09948) | RadCLIP是一种创新的跨模态基础模型，利用对比语言图像预训练以改进放射学图像分析，包含针对体积图像分析定制的新颖3D切片池化机制，并使用丰富多样的放射学图像-文本对数据集进行训练。 |
| [^2] | [FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models](https://arxiv.org/abs/2403.07747) | FineMath是一个用于评估中文大型语言模型数学推理能力的细粒度数学评估基准数据集，涵盖小学数学中的主要概念，划分为17类数学问题，并手动注释难度级别，实验证实在数学方面仍有改进空间。 |
| [^3] | [ICLN: Input Convex Loss Network for Decision Focused Learning](https://arxiv.org/abs/2403.01875) | 提出了输入凸损失网络（ICLN），通过输入凸神经网络学习任务损失，为决策集中学习提供了全局替代损失。 |
| [^4] | [Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment](https://arxiv.org/abs/2403.00884) | 通过利用LLMs，我们提出了一种方法，使用ChatGPT-3.5、GoogleBard和GoogleGemini对列标题进行主题注释的元数据丰富化，研究它们在对领域特定主题进行分类的能力，并评估其内部一致性、机器对齐性和人机一致性。ChatGPT和GoogleGemini在内部一致性以及与人一致性方面优于GoogleBard。 |
| [^5] | [Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning](https://arxiv.org/abs/2402.15761) | Res-VMamba利用具有选择性状态空间模型和深度残差学习，提供了比Transformer结构更出色的性能和计算效率，是食品细粒度分类中的最新技术。 |
| [^6] | [Is my Data in your AI Model? Membership Inference Test with Application to Face Images](https://arxiv.org/abs/2402.09225) | This paper introduces a novel approach called Membership Inference Test (MINT) to empirically assess if specific data was used during the training of AI models. Two MINT architectures based on MLP and CNN are proposed and evaluated on a challenging face recognition task, achieving promising results with up to 90% accuracy. |
| [^7] | [CURE: Simulation-Augmented Auto-Tuning in Robotics](https://arxiv.org/abs/2402.05399) | 本论文提出了一种模拟辅助的自动调节技术，用于解决机器人系统中的高度可配置参数的优化问题。该技术通过解决软硬件之间配置选项的交互问题，实现了在不同环境和机器人平台之间的性能迁移。 |
| [^8] | [Re-evaluating Retrosynthesis Algorithms with Syntheseus](https://arxiv.org/abs/2310.19796) | 使用Syntheseus建立的基准库重新评估了回溯合成算法，揭示了现有技术模型的系统性缺陷并提供了对未来工作的指导建议。 |
| [^9] | [A Survey on Efficient Federated Learning Methods for Foundation Model Training.](http://arxiv.org/abs/2401.04472) | 这项调查研究了高效联邦学习方法在基础模型训练中的应用，提出了一个新的分类方法以优化计算和通信效率。该研究还讨论了当前广泛使用的FL框架，并展望了未来的研究潜力。 |
| [^10] | [EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes.](http://arxiv.org/abs/2308.06493) | 本文提出了EgoPoser，一种能够在大场景中鲁棒地实时估计自我身体姿势的方法。通过重新思考输入表示、引入新的运动分解方法以及建模身体姿势，EgoPoser在定性和定量上均表现优于现有方法，并具有较高的推理速度。 |
| [^11] | [Contrastive Graph Pooling for Explainable Classification of Brain Networks.](http://arxiv.org/abs/2307.11133) | 本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。 |
| [^12] | [Can Differentiable Decision Trees Learn Interpretable Reward Functions?.](http://arxiv.org/abs/2306.13004) | 本文提出了使用可微分决策树从人类偏好中学习具有表达能力和可解释性的奖励函数，通过在多个环境上的评估，发现该方法能够学习到可解释的奖励函数，但在强化学习测试时表现受到树的离散性的影响。 |
| [^13] | [Partially Observable Mean Field Multi-Agent Reinforcement Learning Based on Graph-Attention.](http://arxiv.org/abs/2304.12653) | 本文提出了一种新的基于图注意力的部分可观察均场多智能体强化学习算法，使用图注意力来捕获周围邻居智能体的特征信息，可以提高大规模多智能体环境中部分可观察MARL的性能。 |
| [^14] | [The Krohn-Rhodes Logics.](http://arxiv.org/abs/2304.09639) | 本篇论文提出了一组新的时间逻辑，通过使用Krohn和Rhodes的级联理论，扩展了过去的LTL表达能力，其中包括可以捕获其他prime automata的新的时间运算符。 |
| [^15] | [Implementing Responsible AI: Tensions and Trade-Offs Between Ethics Aspects.](http://arxiv.org/abs/2304.08275) | 本文讨论了负责任人工智能伦理原则之间的紧张关系和权衡，并提出一个目录以帮助人们提高对相互作用的认识。 |
| [^16] | [A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection System.](http://arxiv.org/abs/2211.03933) | 该论文提出了一种基于超图的机器学习集成网络入侵检测系统，使用超图捕捉端口扫描攻击的演化模式，并使用派生的度量来训练NIDS，从而允许在高精度、高准确率、高召回率性能下实时监测和检测端口扫描活动、其他类型的攻击和敌对入侵，解决了传统NIDS面临的挑战。 |

# 详细

[^1]: RadCLIP: 通过对比语言图像预训练增强放射学图像分析

    RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training

    [https://arxiv.org/abs/2403.09948](https://arxiv.org/abs/2403.09948)

    RadCLIP是一种创新的跨模态基础模型，利用对比语言图像预训练以改进放射学图像分析，包含针对体积图像分析定制的新颖3D切片池化机制，并使用丰富多样的放射学图像-文本对数据集进行训练。

    

    arXiv:2403.09948v1 公告类型: 跨领域  摘要: 人工智能（AI）与放射学的整合标志着医学诊断领域的变革时代。视觉基础模型已被采用来增强放射学图像分析。然而，放射学图像的独特复杂性，包括对2D和3D放射学数据的解读，带来了现有模型无法充分应对的挑战，因为这些模型是在通用非医学图像上训练的。为了弥合这一差距，并充分利用医学成像所需的诊断精度，我们引入了RadCLIP：一种开创性的跨模态基础模型，利用对比语言图像预训练（CLIP）来改进放射学图像分析。RadCLIP包含一种新颖的3D切片池化机制，专为体积图像分析定制，使用了丰富多样的放射学图像-文本对数据集进行训练。我们的评估表明，RadCLIP能有效地对齐放射学图像

    arXiv:2403.09948v1 Announce Type: cross  Abstract: The integration of artificial intelligence (AI) with radiology has marked a transformative era in medical diagnostics. Vision foundation models have been adopted to enhance radiologic imaging analysis. However, the distinct complexities of radiological imaging, including the interpretation of 2D and 3D radiological data, pose unique challenges that existing models, trained on general non-medical images, fail to address adequately. To bridge this gap and capitalize on the diagnostic precision required in medical imaging, we introduce RadCLIP: a pioneering cross-modal foundational model that harnesses Contrastive Language-Image Pre-training (CLIP) to refine radiologic image analysis. RadCLIP incorporates a novel 3D slice pooling mechanism tailored for volumetric image analysis and is trained using a comprehensive and diverse dataset of radiologic image-text pairs. Our evaluations demonstrate that RadCLIP effectively aligns radiological i
    
[^2]: FineMath：一种用于评估中文大型语言模型的细粒度数学评估基准

    FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models

    [https://arxiv.org/abs/2403.07747](https://arxiv.org/abs/2403.07747)

    FineMath是一个用于评估中文大型语言模型数学推理能力的细粒度数学评估基准数据集，涵盖小学数学中的主要概念，划分为17类数学问题，并手动注释难度级别，实验证实在数学方面仍有改进空间。

    

    为了全面评估大型语言模型（LLMs）的数学推理能力，我们需要精心策划涵盖不同难度级别的各种数学概念和数学问题的评估数据集。为了实现这一目标，我们在本文中提出了FineMath，这是一个用于评估中文LLMs的细粒度数学评估基准数据集。FineMath旨在涵盖小学数学中教授的主要数学概念，进一步划分为17类数学问题，从而深入分析LLMs的数学推理能力。所有17类数学问题均根据解决这些问题所需的推理步骤数量进行手动注释其难度级别。我们在FineMath上对各种LLMs进行了广泛实验，并发现在数学方面仍有相当大的改进空间。

    arXiv:2403.07747v1 Announce Type: cross  Abstract: To thoroughly assess the mathematical reasoning abilities of Large Language Models (LLMs), we need to carefully curate evaluation datasets covering diverse mathematical concepts and mathematical problems at different difficulty levels. In pursuit of this objective, we propose FineMath in this paper, a fine-grained mathematical evaluation benchmark dataset for assessing Chinese LLMs. FineMath is created to cover the major key mathematical concepts taught in elementary school math, which are further divided into 17 categories of math word problems, enabling in-depth analysis of mathematical reasoning abilities of LLMs. All the 17 categories of math word problems are manually annotated with their difficulty levels according to the number of reasoning steps required to solve these problems. We conduct extensive experiments on a wide range of LLMs on FineMath and find that there is still considerable room for improvements in terms of mathem
    
[^3]: ICLN：输入凸损失网络用于决策集中学习

    ICLN: Input Convex Loss Network for Decision Focused Learning

    [https://arxiv.org/abs/2403.01875](https://arxiv.org/abs/2403.01875)

    提出了输入凸损失网络（ICLN），通过输入凸神经网络学习任务损失，为决策集中学习提供了全局替代损失。

    

    在不确定性条件下的决策问题中，预测未知参数通常被认为与优化部分无关。决策集中学习（DFL）是一个面向任务的框架，通过调整预测模型以为相应任务提供更好的决策来整合预测和优化。本文提出了输入凸损失网络（ICLN），这是一种新颖的全局替代损失，可以在一般的DFL范式中实现。ICLN通过输入凸神经网络学习任务损失，已经被保证为某些情况下是凸的。

    arXiv:2403.01875v1 Announce Type: cross  Abstract: In decision-making problem under uncertainty, predicting unknown parameters is often considered independent of the optimization part. Decision-focused Learning (DFL) is a task-oriented framework to integrate prediction and optimization by adapting predictive model to give better decision for the corresponding task. Here, an inevitable challenge arises when computing gradients of the optimal decision with respect to the parameters. Existing researches cope this issue by smoothly reforming surrogate optimization or construct surrogate loss function that mimic task loss. However, they are applied to restricted optimization domain or build functions in a local manner leading a large computational time. In this paper, we propose Input Convex Loss Network (ICLN), a novel global surrogate loss which can be implemented in a general DFL paradigm. ICLN learns task loss via Input Convex Neural Networks which is guaranteed to be convex for some in
    
[^4]: 利用LLMs进行元数据丰富化的受控词汇列标题文本分类

    Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment

    [https://arxiv.org/abs/2403.00884](https://arxiv.org/abs/2403.00884)

    通过利用LLMs，我们提出了一种方法，使用ChatGPT-3.5、GoogleBard和GoogleGemini对列标题进行主题注释的元数据丰富化，研究它们在对领域特定主题进行分类的能力，并评估其内部一致性、机器对齐性和人机一致性。ChatGPT和GoogleGemini在内部一致性以及与人一致性方面优于GoogleBard。

    

    传统的数据集检索系统主要在元数据信息而非数据值上建立索引。因此主要依赖于手动注释和高质量的元数据，这些过程被认为是耗时且难以自动化的。我们提出了一种方法，利用三种大型语言模型（LLMs）支持对列标题进行主题注释的元数据丰富化：ChatGPT-3.5、GoogleBard和GoogleGemini。我们研究了LLMs基于受控词汇的领域特定主题对列标题进行分类的能力。我们通过评估LLMs的内部一致性、机器间对齐以及人机对主题分类任务的一致性来评估我们的方法。此外，我们还探讨了上下文信息（即数据集描述）对分类结果的影响。我们的结果表明，ChatGPT和GoogleGemini在内部一致性以及LLM与人之间的一致性方面表现优于GoogleBard。

    arXiv:2403.00884v1 Announce Type: cross  Abstract: Traditional dataset retrieval systems index on metadata information rather than on the data values. Thus relying primarily on manual annotations and high-quality metadata, processes known to be labour-intensive and challenging to automate. We propose a method to support metadata enrichment with topic annotations of column headers using three Large Language Models (LLMs): ChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to classify column headers based on domain-specific topics from a controlled vocabulary. We evaluate our approach by assessing the internal consistency of the LLMs, the inter-machine alignment, and the human-machine agreement for the topic classification task. Additionally, we investigate the impact of contextual information (i.e. dataset description) on the classification outcomes. Our results suggest that ChatGPT and GoogleGemini outperform GoogleBard for internal consistency as well as LLM-hum
    
[^5]: 使用具有深度残差学习的选择性状态空间模型进行细粒度食品类别视觉分类的Res-VMamba

    Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning

    [https://arxiv.org/abs/2402.15761](https://arxiv.org/abs/2402.15761)

    Res-VMamba利用具有选择性状态空间模型和深度残差学习，提供了比Transformer结构更出色的性能和计算效率，是食品细粒度分类中的最新技术。

    

    食品分类是发展食品视觉任务的基础，并在计算营养学这一新兴领域中发挥着关键作用。由于食物的复杂性需要细粒度分类，最近的学术研究主要修改卷积神经网络(CNNs)和/或视觉变压器(ViTs)来执行食品类别分类。然而，为了学习细粒度特征，CNN骨干需要额外的结构设计，而包含自注意力模块的ViT具有更高的计算复杂性。最近推出的新的序列状态空间(S4)模型，通过选择机制和与扫描(S6)的计算，俗称为Mamba，相较于变压器架构展示了卓越的性能和计算效率。将Mamba机制整合到图像任务(如分类)中的VMamba模型目前建立了最先进技术

    arXiv:2402.15761v1 Announce Type: cross  Abstract: Food classification is the foundation for developing food vision tasks and plays a key role in the burgeoning field of computational nutrition. Due to the complexity of food requiring fine-grained classification, recent academic research mainly modifies Convolutional Neural Networks (CNNs) and/or Vision Transformers (ViTs) to perform food category classification. However, to learn fine-grained features, the CNN backbone needs additional structural design, whereas ViT, containing the self-attention module, has increased computational complexity. In recent months, a new Sequence State Space (S4) model, through a Selection mechanism and computation with a Scan (S6), colloquially termed Mamba, has demonstrated superior performance and computation efficiency compared to the Transformer architecture. The VMamba model, which incorporates the Mamba mechanism into image tasks (such as classification), currently establishes the state-of-the-art 
    
[^6]: 我的数据在你的AI模型中吗？通过应用于人脸图像的成员推断测试

    Is my Data in your AI Model? Membership Inference Test with Application to Face Images

    [https://arxiv.org/abs/2402.09225](https://arxiv.org/abs/2402.09225)

    This paper introduces a novel approach called Membership Inference Test (MINT) to empirically assess if specific data was used during the training of AI models. Two MINT architectures based on MLP and CNN are proposed and evaluated on a challenging face recognition task, achieving promising results with up to 90% accuracy.

    

    这篇论文介绍了成员推断测试（MINT），一种用于经验性评估特定数据是否被用于训练人工智能（AI）模型的新方法。具体而言，我们提出了两种新颖的MINT架构，旨在学习在经过审计的模型暴露于其训练过程中使用的数据时出现的不同激活模式。第一个架构基于多层感知机（MLP）网络，第二个基于卷积神经网络（CNN）。所提出的MINT架构在具有挑战性的人脸识别任务上进行评估，考虑了三种最先进的人脸识别模型。使用六个公开可用的数据库进行实验，总共包含超过2200万张人脸图像。根据可用的AI模型测试的上下文，考虑了不同的实验场景。有希望的结果达到了90%的准确率。

    arXiv:2402.09225v1 Announce Type: cross Abstract: This paper introduces the Membership Inference Test (MINT), a novel approach that aims to empirically assess if specific data was used during the training of Artificial Intelligence (AI) models. Specifically, we propose two novel MINT architectures designed to learn the distinct activation patterns that emerge when an audited model is exposed to data used during its training process. The first architecture is based on a Multilayer Perceptron (MLP) network and the second one is based on Convolutional Neural Networks (CNNs). The proposed MINT architectures are evaluated on a challenging face recognition task, considering three state-of-the-art face recognition models. Experiments are carried out using six publicly available databases, comprising over 22 million face images in total. Also, different experimental scenarios are considered depending on the context available of the AI model to test. Promising results, up to 90% accuracy, are a
    
[^7]: CURE: 机器人领域的模拟辅助自动调节技术

    CURE: Simulation-Augmented Auto-Tuning in Robotics

    [https://arxiv.org/abs/2402.05399](https://arxiv.org/abs/2402.05399)

    本论文提出了一种模拟辅助的自动调节技术，用于解决机器人系统中的高度可配置参数的优化问题。该技术通过解决软硬件之间配置选项的交互问题，实现了在不同环境和机器人平台之间的性能迁移。

    

    机器人系统通常由多个子系统组成，例如定位和导航，每个子系统又包含许多可配置的组件（例如选择不同的规划算法）。一旦选择了某个算法，就需要设置相关的配置选项以达到适当的值。系统堆栈中的配置选项会产生复杂的交互关系。在高度可配置的机器人中找到最佳配置来实现期望的性能是一个重大挑战，因为软件和硬件之间的配置选项交互导致了庞大且复杂的配置空间。性能迁移在不同的环境和机器人平台之间也是一个难题。数据高效优化算法（例如贝叶斯优化）已越来越多地用于自动化调整网络物理系统中的可配置参数。然而，这样的优化算法在机器人领域应用仍有局限性。

    Robotic systems are typically composed of various subsystems, such as localization and navigation, each encompassing numerous configurable components (e.g., selecting different planning algorithms). Once an algorithm has been selected for a component, its associated configuration options must be set to the appropriate values. Configuration options across the system stack interact non-trivially. Finding optimal configurations for highly configurable robots to achieve desired performance poses a significant challenge due to the interactions between configuration options across software and hardware that result in an exponentially large and complex configuration space. These challenges are further compounded by the need for transferability between different environments and robotic platforms. Data efficient optimization algorithms (e.g., Bayesian optimization) have been increasingly employed to automate the tuning of configurable parameters in cyber-physical systems. However, such optimiz
    
[^8]: 使用Syntheseus重新评估回溯合成算法

    Re-evaluating Retrosynthesis Algorithms with Syntheseus

    [https://arxiv.org/abs/2310.19796](https://arxiv.org/abs/2310.19796)

    使用Syntheseus建立的基准库重新评估了回溯合成算法，揭示了现有技术模型的系统性缺陷并提供了对未来工作的指导建议。

    

    过去几年，分子合成规划，也称为回溯合成，已经成为机器学习和化学界关注的焦点。尽管看似取得了稳定的进展，但我们认为存在不完善的基准和不一致的比较掩盖了现有技术的系统性缺陷。为了解决这个问题，我们提出了一个名为syntheseus的基准库，通过默认推广最佳实践，实现了对单步和多步回溯合成算法的一致而有意义的评估。我们使用syntheseus重新评估了若干先前的回溯合成算法，并发现在仔细评估时，现有技术模型的排名会发生变化。最后，我们给出了这一领域未来工作的指导建议。

    arXiv:2310.19796v2 Announce Type: replace-cross  Abstract: The planning of how to synthesize molecules, also known as retrosynthesis, has been a growing focus of the machine learning and chemistry communities in recent years. Despite the appearance of steady progress, we argue that imperfect benchmarks and inconsistent comparisons mask systematic shortcomings of existing techniques. To remedy this, we present a benchmarking library called syntheseus which promotes best practice by default, enabling consistent meaningful evaluation of single-step and multi-step retrosynthesis algorithms. We use syntheseus to re-evaluate a number of previous retrosynthesis algorithms, and find that the ranking of state-of-the-art models changes when evaluated carefully. We end with guidance for future works in this area.
    
[^9]: 关于高效联邦学习方法在基础模型训练中的调查

    A Survey on Efficient Federated Learning Methods for Foundation Model Training. (arXiv:2401.04472v1 [cs.LG])

    [http://arxiv.org/abs/2401.04472](http://arxiv.org/abs/2401.04472)

    这项调查研究了高效联邦学习方法在基础模型训练中的应用，提出了一个新的分类方法以优化计算和通信效率。该研究还讨论了当前广泛使用的FL框架，并展望了未来的研究潜力。

    

    联邦学习（FL）已成为一种促进隐私保护协作训练的成熟技术。然而，新的FL方法通常只涉及小型深度学习模型的贡献。随着Transformer模型的巨大成功，一个问题出现了：如何使基础模型在FL应用中实施起来？鉴于在FL中计算和通信的时间消耗通常相似，我们引入了一个关于在FL应用中的计算和通信效率方法的新的分类方法。这些方法旨在优化训练时间并减少客户端与服务器之间的通信。我们还研究了目前广泛使用的FL框架，并根据FL研究及其延伸的现有方法讨论了未来的研究潜力。

    Federated Learning (FL) has become an established technique to facilitate privacy-preserving collaborative training. However, new approaches to FL often discuss their contributions involving small deep-learning models only. With the tremendous success of transformer models, the following question arises: What is necessary to operationalize foundation models in an FL application? Knowing that computation and communication often take up similar amounts of time in FL, we introduce a novel taxonomy focused on computational and communication efficiency methods in FL applications. This said, these methods aim to optimize the training time and reduce communication between clients and the server. We also look at the current state of widely used FL frameworks and discuss future research potentials based on existing approaches in FL research and beyond.
    
[^10]: EgoPoser：大场景下鲁棒的实时自我身体姿势估计

    EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes. (arXiv:2308.06493v1 [cs.CV])

    [http://arxiv.org/abs/2308.06493](http://arxiv.org/abs/2308.06493)

    本文提出了EgoPoser，一种能够在大场景中鲁棒地实时估计自我身体姿势的方法。通过重新思考输入表示、引入新的运动分解方法以及建模身体姿势，EgoPoser在定性和定量上均表现优于现有方法，并具有较高的推理速度。

    

    头部和手部姿势仅通过完整身体自我姿势估计已成为研究的一个热点领域，以为头戴式平台上的虚拟角色表达提供动力。然而，现有方法过于依赖数据集记录时的运动捕捉空间的限制，同时假设连续捕捉关节运动和均匀身体尺寸。在本文中，我们提出了EgoPoser，通过以下方式克服了这些限制：1）重新思考基于头戴式平台的自我姿势估计的输入表示，并引入一种新的运动分解方法来预测与全局位置无关的完整身体姿势，2）从头戴式设备视野内的间歇性手部姿势跟踪中鲁棒地建模身体姿势，3）针对不同用户的各种身体尺寸进行通用化推广。我们的实验表明，EgoPoser在定性和定量上优于现有的方法，并保持较高的推理速度。

    Full-body ego-pose estimation from head and hand poses alone has become an active area of research to power articulate avatar representation on headset-based platforms. However, existing methods over-rely on the confines of the motion-capture spaces in which datasets were recorded, while simultaneously assuming continuous capture of joint motions and uniform body dimensions. In this paper, we propose EgoPoser, which overcomes these limitations by 1) rethinking the input representation for headset-based ego-pose estimation and introducing a novel motion decomposition method that predicts full-body pose independent of global positions, 2) robustly modeling body pose from intermittent hand position and orientation tracking only when inside a headset's field of view, and 3) generalizing across various body sizes for different users. Our experiments show that EgoPoser outperforms state-of-the-art methods both qualitatively and quantitatively, while maintaining a high inference speed of over
    
[^11]: 对脑网络的可解释分类进行对比图池化。

    Contrastive Graph Pooling for Explainable Classification of Brain Networks. (arXiv:2307.11133v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.11133](http://arxiv.org/abs/2307.11133)

    本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。

    

    功能性磁共振成像(fMRI)是一种常用的测量神经活动的技术。其应用在识别帕金森病、阿尔茨海默病和自闭症等神经退行性疾病方面尤为重要。最近的fMRI数据分析将大脑建模为图，并通过图神经网络(GNN)提取特征。然而，fMRI数据的独特特征要求对GNN进行特殊设计。定制GNN以生成有效且可解释的特征仍然具有挑战性。在本文中，我们提出了对比双注意块和可微分图池化方法ContrastPool，以更好地利用GNN分析脑网络，满足fMRI的特殊要求。我们将我们的方法应用于5个静息态fMRI脑网络数据集的3种疾病，并证明其优于最先进的基准线。我们的案例研究证实，我们的方法提取的模式与神经科学文献中的领域知识相匹配。

    Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson's, Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literatu
    
[^12]: 可微分决策树是否能够学习可解释的奖励函数?

    Can Differentiable Decision Trees Learn Interpretable Reward Functions?. (arXiv:2306.13004v1 [cs.LG])

    [http://arxiv.org/abs/2306.13004](http://arxiv.org/abs/2306.13004)

    本文提出了使用可微分决策树从人类偏好中学习具有表达能力和可解释性的奖励函数，通过在多个环境上的评估，发现该方法能够学习到可解释的奖励函数，但在强化学习测试时表现受到树的离散性的影响。

    

    学习人的意图和偏好的奖励函数越来越受到关注，但许多框架使用黑盒学习方法，难以解释。本文提出并评估了一种新颖方法，使用可微分决策树（DDT）从偏好中学习具有表达能力和可解释性的奖励函数，适用于低维和高维状态输入。我们在Cartpole、视觉网格世界环境和Atari游戏上评估了我们的算法，探讨了使用DDT学习可解释奖励函数的可行性。我们提供证据表明，学习到的奖励函数的树形结构有助于确定奖励函数与人类偏好的一致程度。我们可视化了学习到的奖励DDT，发现它们能够学习可解释的奖励函数，但树的离散性会影响强化学习在测试时的表现。

    There is an increasing interest in learning reward functions that model human intent and human preferences. However, many frameworks use blackbox learning methods that, while expressive, are difficult to interpret. We propose and evaluate a novel approach for learning expressive and interpretable reward functions from preferences using Differentiable Decision Trees (DDTs) for both low- and high-dimensional state inputs. We explore and discuss the viability of learning interpretable reward functions using DDTs by evaluating our algorithm on Cartpole, Visual Gridworld environments, and Atari games. We provide evidence that that the tree structure of our learned reward function is useful in determining the extent to which a reward function is aligned with human preferences. We visualize the learned reward DDTs and find that they are capable of learning interpretable reward functions but that the discrete nature of the trees hurts the performance of reinforcement learning at test time. How
    
[^13]: 基于图注意力的部分可观察均场多智能体强化学习

    Partially Observable Mean Field Multi-Agent Reinforcement Learning Based on Graph-Attention. (arXiv:2304.12653v1 [cs.AI])

    [http://arxiv.org/abs/2304.12653](http://arxiv.org/abs/2304.12653)

    本文提出了一种新的基于图注意力的部分可观察均场多智能体强化学习算法，使用图注意力来捕获周围邻居智能体的特征信息，可以提高大规模多智能体环境中部分可观察MARL的性能。

    

    传统的多智能体强化学习算法难以在大规模多智能体环境中应用。最近引入的均场理论提高了多智能体强化学习的可扩展性。本文考虑部分可观察的多智能体强化学习，其中每个智能体只能观察到固定范围内的其他智能体。这种部分可观察性影响了智能体评估周围智能体行动质量的能力。本文着重于开发一种从局部观测中获取更有效信息以选择更有效行动的方法。在这个领域的以前工作使用概率分布或加权均场来更新邻居智能体平均行动，但它没有充分考虑周围邻居的特征信息，导致了局部最优。本文提出了一种新的多智能体强化学习算法，基于图注意力的部分可观察均场多智能体强化学习，它使用图注意力来捕获周围邻居智能体的特征信息。我们的方法可以提高大规模多智能体环境中部分可观察MARL的性能。

    Traditional multi-agent reinforcement learning algorithms are difficultly applied in a large-scale multi-agent environment. The introduction of mean field theory has enhanced the scalability of multi-agent reinforcement learning in recent years. This paper considers partially observable multi-agent reinforcement learning (MARL), where each agent can only observe other agents within a fixed range. This partial observability affects the agent's ability to assess the quality of the actions of surrounding agents. This paper focuses on developing a method to capture more effective information from local observations in order to select more effective actions. Previous work in this field employs probability distributions or weighted mean field to update the average actions of neighborhood agents, but it does not fully consider the feature information of surrounding neighbors and leads to a local optimum. In this paper, we propose a novel multi-agent reinforcement learning algorithm, Partially
    
[^14]: Krohn-Rhodes逻辑

    The Krohn-Rhodes Logics. (arXiv:2304.09639v1 [cs.LO])

    [http://arxiv.org/abs/2304.09639](http://arxiv.org/abs/2304.09639)

    本篇论文提出了一组新的时间逻辑，通过使用Krohn和Rhodes的级联理论，扩展了过去的LTL表达能力，其中包括可以捕获其他prime automata的新的时间运算符。

    

    我们提出了一组新的过去的模态时间逻辑，通过使用Krohn和Rhodes的自动机级联理论，基于Past LTL扩展一组丰富的时间运算符而获得。该理论指出，每个自动机都可以表示为一些称为prime automata的基本自动机的级联。他们是所有自动机的构建块，类似于质数是所有自然数的构建块。我们展示了过去的LTL对应于称为flip-flops的一种prime automata的级联。特别地，Past LTL的时间运算符由flip-flops捕获，并且它们不能捕获任何其他prime automata，将表达能力限制在星号自由正则语言内。我们提出了新的时间运算符，可以捕获其他prime automata，从而扩展了Past LTL的表达能力。这些运算符是无穷多的，并且它们产生了无限数量的逻辑，捕获了正则语言的无限数量的不同片段。

    We present a new family of modal temporal logics of the past, obtained by extending Past LTL with a rich set of temporal operators based on the theory by Krohn and Rhodes for automata cascades. The theory says that every automaton can be expressed as a cascade of some basic automata called prime automata. They are the building blocks of all automata, analogously to prime numbers being the building blocks of all natural numbers. We show that Past LTL corresponds to cascades of one kind of prime automata called flip-flops. In particular, the temporal operators of Past LTL are captured by flip-flops, and they cannot capture any other prime automaton, confining the expressivity within the star-free regular languages. We propose novel temporal operators that can capture other prime automata, and hence extend the expressivity of Past LTL. Such operators are infinitely-many, and they yield an infinite number of logics capturing an infinite number of distinct fragments of the regular languages
    
[^15]: 负责任人工智能的实施：伦理方面的紧张和权衡

    Implementing Responsible AI: Tensions and Trade-Offs Between Ethics Aspects. (arXiv:2304.08275v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2304.08275](http://arxiv.org/abs/2304.08275)

    本文讨论了负责任人工智能伦理原则之间的紧张关系和权衡，并提出一个目录以帮助人们提高对相互作用的认识。

    

    针对人工智能/机器学习系统的滥用和不当使用引起的担忧，已经提出了许多负责任人工智能的伦理原则。这些准则的基本方面包括隐私、准确性、公平性、稳健性、可解释性和透明度。然而，这些方面之间存在潜在的紧张关系，这给寻求遵循这些原则的AI/ML开发者带来了困难。例如，提高AI/ML系统的准确性可能会降低其可解释性。本文旨在汇编和讨论10个突出的紧张关系、权衡和其他基本方面之间的相互作用，以便在持续努力将这些原则转化为实践的过程中，提高对可能出现的伦理原则方面之间相互作用的认识，并通过在广泛文献中的支持进行双面互动的重点讨论。这个目录对于提高人们对伦理准则方面之间可能相互作用的认识以及促进设计人员和开发人员做出有充分依据的判断可能有所帮助。

    Many sets of ethics principles for responsible AI have been proposed to allay concerns about misuse and abuse of AI/ML systems. The underlying aspects of such sets of principles include privacy, accuracy, fairness, robustness, explainability, and transparency. However, there are potential tensions between these aspects that pose difficulties for AI/ML developers seeking to follow these principles. For example, increasing the accuracy of an AI/ML system may reduce its explainability. As part of the ongoing effort to operationalise the principles into practice, in this work we compile and discuss a catalogue of 10 notable tensions, trade-offs and other interactions between the underlying aspects. We primarily focus on two-sided interactions, drawing on support spread across a diverse literature. This catalogue can be helpful in raising awareness of the possible interactions between aspects of ethics principles, as well as facilitating well-supported judgements by the designers and develo
    
[^16]: 基于超图的机器学习集成网络入侵检测系统

    A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection System. (arXiv:2211.03933v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2211.03933](http://arxiv.org/abs/2211.03933)

    该论文提出了一种基于超图的机器学习集成网络入侵检测系统，使用超图捕捉端口扫描攻击的演化模式，并使用派生的度量来训练NIDS，从而允许在高精度、高准确率、高召回率性能下实时监测和检测端口扫描活动、其他类型的攻击和敌对入侵，解决了传统NIDS面临的挑战。

    

    网络入侵检测系统(NIDS)在检测恶意攻击时仍然面临挑战。NIDS通常在离线状态下开发，但面对自动生成的端口扫描渗透尝试时，会导致从对手适应到NIDS响应的显着时间滞后。为了解决这些问题，我们使用以Internet协议地址和目标端口为重点的超图来捕捉端口扫描攻击的演化模式。然后使用派生的基于超图的度量来训练一个集成机器学习(ML)的NIDS，从而允许在高精度、高准确率、高召回率性能下实时调整，监测和检测端口扫描活动、其他类型的攻击和敌对入侵。这个ML自适应的NIDS是通过以下几个部分的组合开发出来的：(1)入侵示例，(2)NIDS更新规则，(3)触发NIDS重新训练请求的攻击阈值选择，以及(4)在没有先前网络性质知识的情况下的生产环境。

    Network intrusion detection systems (NIDS) to detect malicious attacks continue to meet challenges. NIDS are often developed offline while they face auto-generated port scan infiltration attempts, resulting in a significant time lag from adversarial adaption to NIDS response. To address these challenges, we use hypergraphs focused on internet protocol addresses and destination ports to capture evolving patterns of port scan attacks. The derived set of hypergraph-based metrics are then used to train an ensemble machine learning (ML) based NIDS that allows for real-time adaption in monitoring and detecting port scanning activities, other types of attacks, and adversarial intrusions at high accuracy, precision and recall performances. This ML adapting NIDS was developed through the combination of (1) intrusion examples, (2) NIDS update rules, (3) attack threshold choices to trigger NIDS retraining requests, and (4) a production environment with no prior knowledge of the nature of network 
    

