# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey](https://arxiv.org/abs/2404.01869) | 本文通过综述超越任务准确性的研究，提供对大型语言模型推理过程更深入了解，并强调了LLMs倾向于依赖于训练数据中的表面模式和相关性。 |
| [^2] | [CR3DT: Camera-RADAR Fusion for 3D Detection and Tracking](https://arxiv.org/abs/2403.15313) | CR3DT是一个相机与雷达融合模型，结合了雷达在3D检测和跟踪中的潜力，通过在State-of-the-Art相机架构基础上实现了显著的改进。 |
| [^3] | [A Picture Is Worth a Graph: Blueprint Debate on Graph for Multimodal Reasoning](https://arxiv.org/abs/2403.14972) | 提出了一种演绎式的图谱辩论方法（BDoG），在多模态推理中防止意见陈腐化和减少由图像引入的分心概念，实验证明其在科学问答和MMBench上取得了最先进的结果。 |
| [^4] | [Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool](https://arxiv.org/abs/2402.19135) | 设计了一款名为ClarifAI的自动化宣传检测工具，利用大型语言模型检测新闻中的宣传并提供丰富解释，以激发更多批判性阅读，实验证明其有效性，强调了解释对于培养批判性思维的重要性 |
| [^5] | [Cooperation and Control in Delegation Games](https://arxiv.org/abs/2402.15821) | 本文在委托游戏中探讨了控制问题（代理人未能按照其委托人的偏好行事）和合作问题（代理人未能良好地协作），并分析了对齐和能力对委托人福利的影响。en_tdlr: This paper explores the issues of control (agents failing to act in line with their principals' preferences) and cooperation (agents failing to work well together) in delegation games, analyzing how alignment and capabilities impact principals' welfare. |
| [^6] | [GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation](https://arxiv.org/abs/2402.15745) | GAOKAO-MM 是基于中国高考的多模态基准，为模型的能力设定人类水平要求，评估结果显示目前的LVLMs的准确率普遍不足50%。 |
| [^7] | [Artificial Intelligence for Literature Reviews: Opportunities and Challenges](https://arxiv.org/abs/2402.08565) | 这篇论文综述了人工智能在系统文献综述中的应用，尤其关注了在筛选和提取阶段的半自动化过程。该研究使用一个包括传统特征和人工智能特征的框架来考察21个领先的文献综述工具，并分析了11个利用大型语言模型进行文献搜索和学术写作辅助的最新工具。最后，论文讨论了该领域的当前趋势、主要研究挑战和发展方向。 |
| [^8] | [Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering](https://arxiv.org/abs/2401.06824) | 通过表示工程对LLMs进行越狱是一种新颖的方法，它利用少量查询对提取“安全模式”，成功规避目标模型的防御，实现了前所未有的越狱性能。 |
| [^9] | [The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making.](http://arxiv.org/abs/2401.11044) | 本文研究了机器学习分类过程中数据抽象方法的重要性，提出了Small and Incomplete Dataset Analyser (SaNDA)采用ROC曲线方法开发的数据抽象协议，该方法在缺少值很少的情况下可以成为随机森林的可行替代品，始终保持高准确性。 |
| [^10] | [A Simple Framework to Accelerate Multilingual Language Model for Monolingual Text Generation.](http://arxiv.org/abs/2401.10660) | 这项研究介绍了一种新颖的框架，旨在加速非英语语言的文本生成。通过预测更大的语言单元并针对目标语言进行调整，该框架降低了解码步骤的数量，并将生成速度提高了1.9倍。 |
| [^11] | [Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach.](http://arxiv.org/abs/2310.12428) | 这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。 |
| [^12] | [Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation.](http://arxiv.org/abs/2310.03780) | 本文研究了使用生成式人工智能和大型语言模型自动生成个性化编程反馈的方法。通过结合GPT-4作为“导师”模型生成提示，利用失败的测试用例的信息和修复方法，实现了更高质量的生成提示。然后，利用较弱的GPT-3.5模型作为“学生”模型进一步验证提示的有效性。 |
| [^13] | [Probabilistic Forecasting with Coherent Aggregation.](http://arxiv.org/abs/2307.09797) | 该论文提出了一种新的模型，利用因子模型结构来产生遵守层次结构的概率预测。模型利用卷积神经网络生成参数，并通过优化样本损失函数实现预测优化。 |
| [^14] | [Tool Learning with Foundation Models.](http://arxiv.org/abs/2304.08354) | 基于基础模型的工具学习结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。本文对工具学习进行了系统研究，提出了涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。 |

# 详细

[^1]: 超越准确性：评估大型语言模型的推理行为--一项调查

    Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey

    [https://arxiv.org/abs/2404.01869](https://arxiv.org/abs/2404.01869)

    本文通过综述超越任务准确性的研究，提供对大型语言模型推理过程更深入了解，并强调了LLMs倾向于依赖于训练数据中的表面模式和相关性。

    

    大型语言模型（LLMs）最近在涉及推理的任务中表现出色，引发了关于这些模型是否具有类似于人类的推理能力的激烈讨论。然而，尽管取得了成功，但LLMs的推理能力的深度仍然存在不确定性。这种不确定性部分源自对模型推理行为的深入调查而非仅仅通过表面准确性指标来衡量任务表现。本文旨在通过综述超越任务准确性的研究，提供对模型推理过程更深入的了解来弥补这一差距。此外，我们调查了评估LLMs推理行为的主要方法论，强调了当前对更细致推理分析的趋势和努力。我们的综述表明，LLMs倾向于依赖于训练数据中的表面模式和相关性。

    arXiv:2404.01869v1 Announce Type: cross  Abstract: Large language models (LLMs) have recently shown impressive performance on tasks involving reasoning, leading to a lively debate on whether these models possess reasoning capabilities similar to humans. However, despite these successes, the depth of LLMs' reasoning abilities remains uncertain. This uncertainty partly stems from the predominant focus on task performance, measured through shallow accuracy metrics, rather than a thorough investigation of the models' reasoning behavior. This paper seeks to address this gap by providing a comprehensive review of studies that go beyond task accuracy, offering deeper insights into the models' reasoning processes. Furthermore, we survey prevalent methodologies to evaluate the reasoning behavior of LLMs, emphasizing current trends and efforts towards more nuanced reasoning analyses. Our review suggests that LLMs tend to rely on surface-level patterns and correlations in their training data, rat
    
[^2]: CR3DT：相机与雷达融合用于3D检测和跟踪

    CR3DT: Camera-RADAR Fusion for 3D Detection and Tracking

    [https://arxiv.org/abs/2403.15313](https://arxiv.org/abs/2403.15313)

    CR3DT是一个相机与雷达融合模型，结合了雷达在3D检测和跟踪中的潜力，通过在State-of-the-Art相机架构基础上实现了显著的改进。

    

    精确检测和跟踪周围物体对于实现自动驾驶车辆至关重要。虽然光探测与测距（LiDAR）传感器已经成为高性能的基准，但仅使用相机的解决方案的吸引力在于其成本效益。尽管无线电探测与测距（RADAR）传感器在汽车系统中被广泛使用，由于数据稀疏和测量噪声的原因，它们在3D检测和跟踪中的潜力长期被忽视。作为一个最新的发展，相机与雷达的结合正成为一种有前途的解决方案。本文提出了Camera-RADAR 3D Detection and Tracking (CR3DT)，这是一个用于3D物体检测和多物体跟踪的相机-雷达融合模型。在基于最先进的只有相机的BEVDet架构的基础上，CR3DT在检测和跟踪能力方面取得了显著的改进，通过整合雷达数据

    arXiv:2403.15313v1 Announce Type: cross  Abstract: Accurate detection and tracking of surrounding objects is essential to enable self-driving vehicles. While Light Detection and Ranging (LiDAR) sensors have set the benchmark for high performance, the appeal of camera-only solutions lies in their cost-effectiveness. Notably, despite the prevalent use of Radio Detection and Ranging (RADAR) sensors in automotive systems, their potential in 3D detection and tracking has been largely disregarded due to data sparsity and measurement noise. As a recent development, the combination of RADARs and cameras is emerging as a promising solution. This paper presents Camera-RADAR 3D Detection and Tracking (CR3DT), a camera-RADAR fusion model for 3D object detection, and Multi-Object Tracking (MOT). Building upon the foundations of the State-of-the-Art (SotA) camera-only BEVDet architecture, CR3DT demonstrates substantial improvements in both detection and tracking capabilities, by incorporating the sp
    
[^3]: 一图胜千言：多模态推理中的图谱辩论

    A Picture Is Worth a Graph: Blueprint Debate on Graph for Multimodal Reasoning

    [https://arxiv.org/abs/2403.14972](https://arxiv.org/abs/2403.14972)

    提出了一种演绎式的图谱辩论方法（BDoG），在多模态推理中防止意见陈腐化和减少由图像引入的分心概念，实验证明其在科学问答和MMBench上取得了最先进的结果。

    

    本文介绍了一项旨在将多智能体辩论引入多模态推理的试点研究。该研究解决了两个关键挑战：由于过度总结而导致意见陈腐化，以及由于图像引入转移性概念而导致注意力分散的问题。这些挑战源自现有辩论方案的归纳（自下而上）性质。为解决这一问题，我们提出了一种演绎（自上而下）的辩论方法，称为图谱辩论（BDoG）。在BDoG中，辩论仅限于蓝图图中，以防止通过世界级摘要而导致意见陈腐化。此外，通过在图中的分支中存储证据，BDoG缓解了频繁但无关的概念带来的分散注意力现象。大量实验验证了BDoG，在科学问答和MMBench中取得了最新成果，并相较于先前的方法具有显著改进。

    arXiv:2403.14972v1 Announce Type: new  Abstract: This paper presents a pilot study aimed at introducing multi-agent debate into multimodal reasoning. The study addresses two key challenges: the trivialization of opinions resulting from excessive summarization and the diversion of focus caused by distractor concepts introduced from images. These challenges stem from the inductive (bottom-up) nature of existing debating schemes. To address the issue, we propose a deductive (top-down) debating approach called Blueprint Debate on Graphs (BDoG). In BDoG, debates are confined to a blueprint graph to prevent opinion trivialization through world-level summarization. Moreover, by storing evidence in branches within the graph, BDoG mitigates distractions caused by frequent but irrelevant concepts. Extensive experiments validate BDoG, achieving state-of-the-art results in Science QA and MMBench with significant improvements over previous methods.
    
[^4]: 快速思考，慢速思考，批判性思考：设计一款自动化疫情检测工具

    Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool

    [https://arxiv.org/abs/2402.19135](https://arxiv.org/abs/2402.19135)

    设计了一款名为ClarifAI的自动化宣传检测工具，利用大型语言模型检测新闻中的宣传并提供丰富解释，以激发更多批判性阅读，实验证明其有效性，强调了解释对于培养批判性思维的重要性

    

    在当今数字化时代，快速的新闻消费和日益对宣传的脆弱性成为特点，培养公民的批判性思维对于稳定的民主至关重要。本文介绍了ClarifAI的设计，这是一款新颖的自动化宣传检测工具，旨在通过激活分析性思维模式，遵循康曼的认知双系统理论，推动读者更加批判性地消费新闻。利用大型语言模型，ClarifAI可以检测新闻文章中的宣传，并提供丰富的背景解释，增强用户的理解和批判性思维。我们的贡献有三个方面：首先，我们提出了ClarifAI的设计；其次，在一项在线实验中，我们证明这一设计有效地鼓励新闻读者更多地进行批判性阅读；第三，我们强调了解释对于培养批判性思维的价值。因此，本研究既提供了一个实用工具，又提供了实验结果支撑。

    arXiv:2402.19135v1 Announce Type: cross  Abstract: In today's digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using Large Language Models, ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and use
    
[^5]: 委托游戏中的合作与控制

    Cooperation and Control in Delegation Games

    [https://arxiv.org/abs/2402.15821](https://arxiv.org/abs/2402.15821)

    本文在委托游戏中探讨了控制问题（代理人未能按照其委托人的偏好行事）和合作问题（代理人未能良好地协作），并分析了对齐和能力对委托人福利的影响。en_tdlr: This paper explores the issues of control (agents failing to act in line with their principals' preferences) and cooperation (agents failing to work well together) in delegation games, analyzing how alignment and capabilities impact principals' welfare.

    

    许多涉及人类和机器的感兴趣的场景 - 从虚拟个人助理到自动驾驶车辆 - 可以自然地建模为委托人（人类）委托给代理人（机器），这些代理人之后代表他们的委托人相互交互。我们将这些多委托人，多代理人的情况称为委托游戏。在这类游戏中，存在两种重要的失败模式：控制问题（代理人未能按照其委托人的偏好行事）和合作问题（代理人未能良好地协作）。在本文中，我们形式化和分析这些问题，进一步将其解释为对齐（参与者是否具有相似的偏好？）和能力（参与者在满足这些偏好方面的能力如何？）的问题。我们理论上和经验上展示了这些措施如何确定委托人的福利，如何可以使用有限的观察来估计这些措施，

    arXiv:2402.15821v1 Announce Type: cross  Abstract: Many settings of interest involving humans and machines -- from virtual personal assistants to autonomous vehicles -- can naturally be modelled as principals (humans) delegating to agents (machines), which then interact with each other on their principals' behalf. We refer to these multi-principal, multi-agent scenarios as delegation games. In such games, there are two important failure modes: problems of control (where an agent fails to act in line their principal's preferences) and problems of cooperation (where the agents fail to work well together). In this paper we formalise and analyse these problems, further breaking them down into issues of alignment (do the players have similar preferences?) and capabilities (how competent are the players at satisfying those preferences?). We show -- theoretically and empirically -- how these measures determine the principals' welfare, how they can be estimated using limited observations, and 
    
[^6]: GAOKAO-MM: 一个用于多模态模型评估的中国人类水平基准

    GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation

    [https://arxiv.org/abs/2402.15745](https://arxiv.org/abs/2402.15745)

    GAOKAO-MM 是基于中国高考的多模态基准，为模型的能力设定人类水平要求，评估结果显示目前的LVLMs的准确率普遍不足50%。

    

    大型视觉语言模型（LVLMs）已经在图像感知和语言理解方面展示出了极大的能力。然而，现有的多模态基准主要关注基本的感知能力和常识知识，这些无法充分反映出LVLMs的全面能力。我们提出了GAOKAO-MM，一个基于中国高考的多模态基准，包括8个科目和12种类型的图片，如图表、函数图、地图和照片。GAOKAO-MM来源于中国本土背景，并为模型的能力设定了人类水平的要求，包括感知、理解、知识和推理。我们评估了10个LVLMs，发现它们的准确率都低于50%，其中GPT-4-Vision（48.1%）、Qwen-VL-Plus（41.2%）和Gemini-Pro-Vision（35.1%）位列前三名。我们的多维分析结果表明，LVLMs具有适度的

    arXiv:2402.15745v1 Announce Type: cross  Abstract: The Large Vision-Language Models (LVLMs) have demonstrated great abilities in image perception and language understanding. However, existing multimodal benchmarks focus on primary perception abilities and commonsense knowledge which are insufficient to reflect the comprehensive capabilities of LVLMs. We propose GAOKAO-MM, a multimodal benchmark based on the Chinese College Entrance Examination (GAOKAO), comprising of 8 subjects and 12 types of images, such as diagrams, function graphs, maps and photos. GAOKAO-MM derives from native Chinese context and sets human-level requirements for the model's abilities, including perception, understanding, knowledge and reasoning. We evaluate 10 LVLMs and find that the accuracies of all of them are lower than 50%, with GPT-4-Vison (48.1%), Qwen-VL-Plus (41.2%) and Gemini-Pro-Vision (35.1%) ranking in the top three positions. The results of our multi-dimension analysis indicate that LVLMs have moder
    
[^7]: 文献综述中的人工智能：机遇与挑战

    Artificial Intelligence for Literature Reviews: Opportunities and Challenges

    [https://arxiv.org/abs/2402.08565](https://arxiv.org/abs/2402.08565)

    这篇论文综述了人工智能在系统文献综述中的应用，尤其关注了在筛选和提取阶段的半自动化过程。该研究使用一个包括传统特征和人工智能特征的框架来考察21个领先的文献综述工具，并分析了11个利用大型语言模型进行文献搜索和学术写作辅助的最新工具。最后，论文讨论了该领域的当前趋势、主要研究挑战和发展方向。

    

    本文对人工智能在系统文献综述（SLR）中的应用进行了全面的综述。SLR是一种严谨有序的方法论，用于评估和整合关于特定主题的先前研究。许多工具已被开发用于辅助和部分自动化SLR过程。人工智能在这个领域的日益重要角色显示了为研究人员提供更有效支持的巨大潜力，朝着文献综述的半自动化创建方向发展。我们的研究重点关注人工智能技术在SLR的半自动化中的应用，特别是在筛选和提取阶段。我们使用一个将23个传统特征与11个人工智能特征相结合的框架，对21个领先的SLR工具进行了考察。我们还分析了使用大型语言模型进行文献搜索和辅助学术写作的11个最新工具。最后，本文讨论了该领域的当前趋势，概述了主要的研究挑战，并提出了发展方向。

    This manuscript presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates previous research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions f
    
[^8]: 打开LLMs的潘多拉魔盒：通过表示工程对LLMs进行越狱

    Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering

    [https://arxiv.org/abs/2401.06824](https://arxiv.org/abs/2401.06824)

    通过表示工程对LLMs进行越狱是一种新颖的方法，它利用少量查询对提取“安全模式”，成功规避目标模型的防御，实现了前所未有的越狱性能。

    

    越狱技术旨在通过诱使大型语言模型（LLMs）生成对恶意查询产生有毒响应，来探索LLMs安全性边界，这在LLMs社区内是一个重要关注点。我们提出一种名为通过表示工程对LLMs进行越狱（Jailbreaking LLMs through Representation Engineering，JRE）的新颖越狱方法，其仅需要少量查询对以提取可用于规避目标模型防御的“安全模式”，实现了前所未有的越狱性能。

    arXiv:2401.06824v2 Announce Type: replace-cross  Abstract: Jailbreaking techniques aim to probe the boundaries of safety in large language models (LLMs) by inducing them to generate toxic responses to malicious queries, a significant concern within the LLM community. While existing jailbreaking methods primarily rely on prompt engineering, altering inputs to evade LLM safety mechanisms, they suffer from low attack success rates and significant time overheads, rendering them inflexible. To overcome these limitations, we propose a novel jailbreaking approach, named Jailbreaking LLMs through Representation Engineering (JRE). Our method requires only a small number of query pairs to extract ``safety patterns'' that can be used to circumvent the target model's defenses, achieving unprecedented jailbreaking performance. Building upon these findings, we also introduce a novel defense framework inspired by JRE principles, which demonstrates notable effectiveness. Extensive experimentation conf
    
[^9]: 机器学习分类过程中数据抽象方法在关键决策中的重要性

    The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making. (arXiv:2401.11044v1 [cs.LG])

    [http://arxiv.org/abs/2401.11044](http://arxiv.org/abs/2401.11044)

    本文研究了机器学习分类过程中数据抽象方法的重要性，提出了Small and Incomplete Dataset Analyser (SaNDA)采用ROC曲线方法开发的数据抽象协议，该方法在缺少值很少的情况下可以成为随机森林的可行替代品，始终保持高准确性。

    

    广泛采用的机器学习(ML)方法在分类方面的适用性受到了解释能力和不确定性的限制，特别是在医疗保健、行为科学和金融等领域，其中责任问题至关重要。最近，提出了Small and Incomplete Dataset Analyser (SaNDA)，通过使用基于ROC曲线的方法开发数据抽象协议，以增强在这些领域中执行分类的能力。本文关注于列间数据转换，即抽象，这对SaNDA的分类过程非常关键，并探讨了替代的抽象协议，如常量分箱和分位数。将最佳的方法与可解释方法的基准模型随机森林进行了比较。结果表明，即使数据不完整，SaNDA在缺少值很少的情况下仍然可以成为随机森林的可行替代品，并且始终保持高准确性。

    The applicability of widely adopted machine learning (ML) methods to classification is circumscribed by the imperatives of explicability and uncertainty, particularly evident in domains such as healthcare, behavioural sciences, and finances, wherein accountability assumes priority. Recently, Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the ability to perform classification in such domains, by developing a data abstraction protocol using a ROC curve-based method. This paper focuses on column-wise data transformations called abstractions, which are crucial for SaNDA's classification process and explores alternative abstractions protocols, such as constant binning and quantiles. The best-performing methods have been compared against Random Forest as a baseline for explainable methods. The results suggests that SaNDA can be a viable substitute for Random Forest when data is incomplete, even with minimal missing values. It consistently maintains high accuracy e
    
[^10]: 一种用于单语文本生成的加速多语言语言模型的简单框架

    A Simple Framework to Accelerate Multilingual Language Model for Monolingual Text Generation. (arXiv:2401.10660v1 [cs.CL])

    [http://arxiv.org/abs/2401.10660](http://arxiv.org/abs/2401.10660)

    这项研究介绍了一种新颖的框架，旨在加速非英语语言的文本生成。通过预测更大的语言单元并针对目标语言进行调整，该框架降低了解码步骤的数量，并将生成速度提高了1.9倍。

    

    最近大型语言模型的进展不仅在英语而且在非英语语言中都促进了复杂的语言任务的执行。然而，大多数语言模型的标记器（如Llama）在以英语为中心的语料库上训练，倾向于在非英语语言中过分分割标记。这个问题在非罗马字母语言中尤为明显，这些语言通常在字符或Unicode级别上被划分，导致文本生成速度较慢。为了解决这个问题，我们的研究介绍了一个新颖的框架，旨在加速这些语言的文本生成。该框架预测比传统的多语言标记器更大的语言单元，并且专门针对目标语言进行了调整，从而减少了解码所需的步骤数。我们的实证结果表明，与标准解码相比，所提出的框架将生成速度提高了1.9倍，同时保持了预先训练模型的性能。

    Recent advancements in large language models have facilitated the execution of complex language tasks, not only in English but also in non-English languages. However, the tokenizers of most language models, such as Llama, trained on English-centric corpora, tend to excessively fragment tokens in non-English languages. This issue is especially pronounced in non-roman alphabetic languages, which are often divided at a character or even Unicode level, leading to slower text generation. To address this, our study introduces a novel framework designed to expedite text generation in these languages. This framework predicts larger linguistic units than those of conventional multilingual tokenizers and is specifically tailored to the target language, thereby reducing the number of decoding steps required. Our empirical results demonstrate that the proposed framework increases the generation speed by a factor of 1.9 compared to standard decoding while maintaining the performance of a pre-traine
    
[^11]: 实现随机森林的局部可解释性增强：基于邻近性的方法

    Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])

    [http://arxiv.org/abs/2310.12428](http://arxiv.org/abs/2310.12428)

    这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。

    

    我们提出一种新的方法来解释随机森林（RF）模型的样本外性能，利用了任何RF都可以被表述为自适应加权K最近邻（KNN）模型的事实。具体而言，我们利用RF在特征空间中学到的点之间的邻近性，将随机森林的预测重写为训练数据点目标标签的加权平均值。这种线性性质有助于在训练集观测中为任何模型预测生成属性，从而为RF预测提供了局部的解释性，补充了SHAP等已有方法，这些方法则为特征空间维度上的模型预测生成属性。我们在训练于美国公司债券交易数据的债券定价模型中演示了这种方法，并将其与各种现有的模型解释方法进行了比较。

    We initiate a novel approach to explain the out of sample performance of random forest (RF) models by exploiting the fact that any RF can be formulated as an adaptive weighted K nearest-neighbors model. Specifically, we use the proximity between points in the feature space learned by the RF to re-write random forest predictions exactly as a weighted average of the target labels of training data points. This linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established methods like SHAP, which instead generates attributions for a model prediction across dimensions of the feature space. We demonstrate this approach in the context of a bond pricing model trained on US corporate bond trades, and compare our approach to various existing approaches to model explainability.
    
[^12]: 自动化人工导师式编程反馈: 利用GPT-4导师模型生成提示和GPT-3.5学生模型进行提示验证

    Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation. (arXiv:2310.03780v1 [cs.AI])

    [http://arxiv.org/abs/2310.03780](http://arxiv.org/abs/2310.03780)

    本文研究了使用生成式人工智能和大型语言模型自动生成个性化编程反馈的方法。通过结合GPT-4作为“导师”模型生成提示，利用失败的测试用例的信息和修复方法，实现了更高质量的生成提示。然后，利用较弱的GPT-3.5模型作为“学生”模型进一步验证提示的有效性。

    

    生成式人工智能和大型语言模型在提供个性化编程反馈方面具有巨大潜力。本文研究了生成式人工智能模型在提供人工导师式编程提示方面的作用，以帮助学生解决程序中的错误。然而，最新的研究工作虽然对各种反馈生成场景进行了评估，但其整体质量仍远不及人工导师，并且还没有准备好在实际环境中投入使用。为了提高生成式人工智能模型提供高质量编程提示的能力，我们开发了一种新的技术，名为GPT4Hints-GPT3.5Val。首先，我们的技术利用GPT-4作为“导师”模型生成提示，通过使用失败的测试用例的符号信息和提示中的修复方法，提高了生成质量。接下来，我们的技术利用较弱的GPT-3.5模型作为“学生”模型进一步验证提示的有效性。

    Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4Hints-GPT3.5Val. As a first step, our technique leverages GPT-4 as a ``tutor'' model to generate hints -- it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a ``student'' model to further validate the hint 
    
[^13]: 具有一致聚合的概率预测

    Probabilistic Forecasting with Coherent Aggregation. (arXiv:2307.09797v1 [cs.LG])

    [http://arxiv.org/abs/2307.09797](http://arxiv.org/abs/2307.09797)

    该论文提出了一种新的模型，利用因子模型结构来产生遵守层次结构的概率预测。模型利用卷积神经网络生成参数，并通过优化样本损失函数实现预测优化。

    

    在许多应用中，准确获得遵守层次结构的概率预测是一项重要的运营挑战，特别是在能源管理、供应链规划和资源配置等领域。对于多变量预测，基本挑战在于预测通常需要与层次结构保持一致。在本文中，我们提出了一种新的模型，利用因子模型结构通过构建来产生一致的预测。这是一个简单的观察结果（可交换性）：置换层次结构中的基本级别序列不会改变它们的聚合。我们的模型使用卷积神经网络来生成因子、它们的加载和基本级别分布的参数；它产生可以根据模型参数进行微分的样本；因此它可以对任何基于样本的损失函数进行优化，包括连续排名概率损失函数。

    Obtaining accurate probabilistic forecasts while respecting hierarchical information is an important operational challenge in many applications, perhaps most obviously in energy management, supply chain planning, and resource allocation. The basic challenge, especially for multivariate forecasting, is that forecasts are often required to be coherent with respect to the hierarchical structure. In this paper, we propose a new model which leverages a factor model structure to produce coherent forecasts by construction. This is a consequence of a simple (exchangeability) observation: permuting \textit{}base-level series in the hierarchy does not change their aggregates. Our model uses a convolutional neural network to produce parameters for the factors, their loadings and base-level distributions; it produces samples which can be differentiated with respect to the model's parameters; and it can therefore optimize for any sample-based loss function, including the Continuous Ranked Probabili
    
[^14]: 基于基础模型的工具学习

    Tool Learning with Foundation Models. (arXiv:2304.08354v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08354](http://arxiv.org/abs/2304.08354)

    基于基础模型的工具学习结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。本文对工具学习进行了系统研究，提出了涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。

    

    人类拥有非凡的创造和利用工具的能力，使得他们能够克服物理限制并探索新的领域。随着基础模型的出现，AI系统有望像人类一样熟练地使用工具。这种范式即基于基础模型的工具学习，结合了专用工具和基础模型的优势，实现了问题解决的增强精度、效率和自动化。尽管具有巨大潜力，但该领域仍缺乏对关键挑战、机会和未来发展的全面理解。针对这一问题，本文对工具学习进行了系统研究。首先介绍了工具学习的背景，包括其认知起源、基础模型的范式转换和工具和模型的互补作用。然后，我们回顾了现有的工具学习研究，包括基于工具和面向工具的学习。我们制定了一个涵盖两种类型学习的通用工具学习框架，并分析了它们的独特挑战、机会和未来方向。我们预计这种系统的探索将为未来开发具有复杂工具学习能力的AI系统提供一个跳板。

    Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of foundation models, AI systems have the potential to be equally adept in tool use as humans. This paradigm, i.e., tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool l
    

