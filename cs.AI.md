# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Domain Generalization through Meta-Learning: A Survey](https://arxiv.org/abs/2404.02785) | 元学习是一种有前景的方法，通过获取可转移知识实现在各种任务之间快速适应，为解决深度神经网络在面对分布变化和有限标记数据时泛化能力不佳提供了新途径。 |
| [^2] | [Text clustering with LLM embeddings](https://arxiv.org/abs/2403.15112) | 研究表明，LLM嵌入能够捕捉结构化语言的细微差别，BERT在性能上领先于轻量级选项，增加嵌入维度和摘要技术并不一致地提高聚类效率 |
| [^3] | [Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models](https://arxiv.org/abs/2403.12196) | 通过大型语言模型在npm生态系统中进行实证研究，以协助安全分析师识别恶意软件包 |
| [^4] | [Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives](https://arxiv.org/abs/2403.02772) | 这项研究引入了一种新的有监督对比学习框架，通过结合硬和软负样本，有效地解决了康复锻炼评估中样本稀缺的问题 |
| [^5] | [Fast Peer Adaptation with Context-aware Exploration](https://arxiv.org/abs/2402.02468) | 本文提出了一种基于上下文感知的探索方法，用于快速适应具有不同策略的未知同伴。通过奖励智能体在历史上下文中有效识别同伴行为模式，该方法能够促进智能体积极探索和快速适应，从而在不确定同伴策略时收集信息反馈，并在有信心时利用上下文执行最佳反应。 |
| [^6] | [DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation](https://arxiv.org/abs/2401.08095) | DurFlex-EVC通过引入风格自编码器和交叉注意力，解决了传统情绪语音转换模型中对语言和语音信息的同步问题。 |
| [^7] | [Eliciting Latent Knowledge from Quirky Language Models](https://arxiv.org/abs/2312.01037) | 本研究通过引入一套“古怪”的语言模型，调取了这些模型在特定上下文中的潜在知识，展示了从可信度低的模型中调取可靠知识的前景。 |
| [^8] | [The Distributional Uncertainty of the SHAP score in Explainable Machine Learning.](http://arxiv.org/abs/2401.12731) | 本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。 |
| [^9] | [CodePrompt: Improving Source Code-Related Classification with Knowledge Features through Prompt Learning.](http://arxiv.org/abs/2401.05544) | CodePrompt是一种利用Prompt学习和注意机制技术改进源代码相关分类任务的新方法。它能够提取源代码和相关文本中的丰富知识以提高准确性，并且减少了计算成本。 |
| [^10] | [LLMind: Orchestrating AI and IoT with LLMs for Complex Task Execution.](http://arxiv.org/abs/2312.09007) | LLMind是一个利用大型语言模型（LLMs）作为中央协调器的AI框架，将LLMs与领域特定的AI模块整合，使得物联网设备能够有效协同执行复杂任务。 |
| [^11] | [Learning To Teach Large Language Models Logical Reasoning.](http://arxiv.org/abs/2310.09158) | 本文通过深入调查和研究，探索了大型语言模型（LLMs）在逻辑推理中的能力，并提出了多种策略来赋予LLMs逻辑推理能力，使其能够生成更具逻辑一致性的答案。 |
| [^12] | [General Lipschitz: Certified Robustness Against Resolvable Semantic Transformations via Transformation-Dependent Randomized Smoothing.](http://arxiv.org/abs/2309.16710) | 我们提出了一种新的框架“一般李普希茨（GL）”，用于对神经网络进行认证，以抵御可组合的可解释的语义干扰。方法在ImageNet数据集上与最先进的方法表现相当。 |
| [^13] | [MVMR: Evaluating Natural Language Video Localization Bias over Multiple Reliable Videos Pool.](http://arxiv.org/abs/2309.16701) | 本文提出了一个名为MVMR的任务，旨在给定文本查询从大量视频集中定位视频帧。我们通过已有数据集进行相似性筛选来构建数据集，并引入三个MVMR数据集。我们采用了嵌入式文本相似度匹配和视频-语言对齐技术来计算相关性得分，并为MVMR任务开发了一个强大的模型，Reliable Mutual Matching Network (RMMN)。 |
| [^14] | [Learning Emergent Behavior in Robot Swarms with NEAT.](http://arxiv.org/abs/2309.14663) | 本研究提出了一种用NEAT方法训练分布式机器人群体算法产生新颖行为的方法，并通过实验验证了其在不同任务上的有效性。 |
| [^15] | [Crowd-Aware Multi-Agent Pathfinding With Boosted Curriculum Reinforcement Learning.](http://arxiv.org/abs/2309.10275) | 该论文介绍了CRAMP，一种基于增强式课程强化学习的众包感知分散式路径规划方法，旨在解决拥挤环境下多智能体路径规划的困难。 |
| [^16] | [Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation.](http://arxiv.org/abs/2308.06422) | 本研究引入了一种创新的深度神经网络优化方法，通过自动选择最佳的位宽和层宽来提高网络效率。同时，通过剪枝和聚类技术，优化了搜索过程，并在多个数据集上进行了严格测试，结果显示该方法明显优于现有方法。 |
| [^17] | [Pair then Relation: Pair-Net for Panoptic Scene Graph Generation.](http://arxiv.org/abs/2307.08699) | 本文提出了一种名为Pair-Net的全景场景图生成框架，通过使用配对提案网络（PPN）来学习和过滤主体和物体之间的稀疏配对关系，解决了当前全景场景图生成方法中忽视的对象间配对回忆率问题。 |
| [^18] | [A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection.](http://arxiv.org/abs/2307.03759) | 这项综述介绍了图神经网络在时间序列分析中的应用，包括预测、分类、异常检测和插值。图神经网络能够显式地建模时间序列和变量之间的关系，为时间序列数据分析带来了新的方法和技术。 |
| [^19] | [Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration.](http://arxiv.org/abs/2305.19476) | 本文提出了一种新的探索技术，使用值条件状态熵来解决强化学习中探索不足的问题，可以均衡地覆盖低价值和高价值状态，相较于现有基于熵的探索方法，该方法在MuJoCo基准测试和Atari游戏上有着显著的提升。 |

# 详细

[^1]: 通过元学习实现领域泛化：一项调查

    Domain Generalization through Meta-Learning: A Survey

    [https://arxiv.org/abs/2404.02785](https://arxiv.org/abs/2404.02785)

    元学习是一种有前景的方法，通过获取可转移知识实现在各种任务之间快速适应，为解决深度神经网络在面对分布变化和有限标记数据时泛化能力不佳提供了新途径。

    

    深度神经网络(DNNs)已经彻底改变了人工智能，但是当面对分布之外(out-of-distribution, OOD)数据时往往表现不佳，这是因为在现实世界应用中由于领域转移不可避免，训练和测试数据被假定为共享相同分布的常见情况。尽管DNNs在大量数据和计算能力方面非常有效，但它们很难应对分布变化和有限标记数据，导致过拟合和跨不同任务和领域的泛化能力不佳。元学习提供了一种有前途的方法，通过采用能够在各种任务之间获取可转移知识的算法进行快速适应，从而消除了需要从头学习每个任务的必要性。本调查论文深入探讨了元学习领域，重点关注其对领域泛化的贡献。

    arXiv:2404.02785v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) have revolutionized artificial intelligence but often lack performance when faced with out-of-distribution (OOD) data, a common scenario due to the inevitable domain shifts in real-world applications. This limitation stems from the common assumption that training and testing data share the same distribution-an assumption frequently violated in practice. Despite their effectiveness with large amounts of data and computational power, DNNs struggle with distributional shifts and limited labeled data, leading to overfitting and poor generalization across various tasks and domains. Meta-learning presents a promising approach by employing algorithms that acquire transferable knowledge across various tasks for fast adaptation, eliminating the need to learn each task from scratch. This survey paper delves into the realm of meta-learning with a focus on its contribution to domain generalization. We first clarify the 
    
[^2]: 使用LLM嵌入进行文本聚类

    Text clustering with LLM embeddings

    [https://arxiv.org/abs/2403.15112](https://arxiv.org/abs/2403.15112)

    研究表明，LLM嵌入能够捕捉结构化语言的细微差别，BERT在性能上领先于轻量级选项，增加嵌入维度和摘要技术并不一致地提高聚类效率

    

    文本聚类是组织不断增长的数字内容的重要方法，有助于结构化和发现未分类数据中的隐藏模式。在这项研究中，我们调查了不同文本嵌入（特别是大型语言模型LLMs中使用的）和聚类算法如何影响文本数据集的聚类方式。进行了一系列实验以评估嵌入是如何影响聚类结果的，以及通过摘要进行降维和嵌入大小调整的作用。结果显示，LLM嵌入在捕获结构化语言的细微差别方面表现出色，而BERT在性能上领先于轻量级选项。此外，我们发现增加嵌入维度和摘要技术并不一致地提高聚类效率，这表明这些策略需要仔细分析才能在实际模型中使用。这些结果突出了一种

    arXiv:2403.15112v1 Announce Type: cross  Abstract: Text clustering is an important approach for organising the growing amount of digital content, helping to structure and find hidden patterns in uncategorised data. In this research, we investigated how different textual embeddings - particularly those used in large language models (LLMs) - and clustering algorithms affect how text datasets are clustered. A series of experiments were conducted to assess how embeddings influence clustering results, the role played by dimensionality reduction through summarisation, and embedding size adjustment. Results reveal that LLM embeddings excel at capturing the nuances of structured language, while BERT leads the lightweight options in performance. In addition, we find that increasing embedding dimensionality and summarisation techniques do not uniformly improve clustering efficiency, suggesting that these strategies require careful analysis to use in real-life models. These results highlight a co
    
[^3]: 用大型语言模型在npm生态系统中检测恶意软件

    Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models

    [https://arxiv.org/abs/2403.12196](https://arxiv.org/abs/2403.12196)

    通过大型语言模型在npm生态系统中进行实证研究，以协助安全分析师识别恶意软件包

    

    Gartner 2022年的报告预测，到2025年，全球45%的组织将遭遇软件供应链攻击，凸显了改善软件供应链安全对社区和国家利益的迫切性。当前的恶意软件检测技术通过过滤良性和恶意软件包来辅助手动审核过程，然而这种技术存在较高的误报率和有限的自动化支持。因此，恶意软件检测技术可以受益于先进、更自动化的方法，得到准确且误报较少的结果。该研究的目标是通过对大型语言模型（LLMs）进行实证研究，帮助安全分析师识别npm生态系统中的恶意软件。

    arXiv:2403.12196v1 Announce Type: cross  Abstract: The Gartner 2022 report predicts that 45% of organizations worldwide will encounter software supply chain attacks by 2025, highlighting the urgency to improve software supply chain security for community and national interests. Current malware detection techniques aid in the manual review process by filtering benign and malware packages, yet such techniques have high false-positive rates and limited automation support. Therefore, malware detection techniques could benefit from advanced, more automated approaches for accurate and minimally false-positive results. The goal of this study is to assist security analysts in identifying malicious packages through the empirical study of large language models (LLMs) to detect potential malware in the npm ecosystem.   We present SocketAI Scanner, a multi-stage decision-maker malware detection workflow using iterative self-refinement and zero-shot-role-play-Chain of Thought (CoT) prompting techni
    
[^4]: 通过有监督对比学习进行康复锻炼质量评估，结合硬负样本和软负样本

    Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives

    [https://arxiv.org/abs/2403.02772](https://arxiv.org/abs/2403.02772)

    这项研究引入了一种新的有监督对比学习框架，通过结合硬和软负样本，有效地解决了康复锻炼评估中样本稀缺的问题

    

    基于锻炼的康复计划已被证明在提高生活质量、降低死亡率和再住院率方面是有效的。利用人工智能驱动的虚拟康复，患者可以在家独立完成锻炼，利用AI算法分析锻炼数据，为患者提供反馈，并向临床医生更新他们的进展情况。这些计划通常会指定各种锻炼类型，这导致康复锻炼评估数据集面临独特挑战：虽然在整体训练样本中丰富，但这些数据集通常对每种具体锻练类型的样本数量有限。这种差异影响了现有方法训练具有小样本量的每种锻练的可泛化模型的能力。为了解决这个问题，我们的论文引入了一种新颖的带有硬负样本和软负样本的有监督对比学习框架，有效利用了整个

    arXiv:2403.02772v1 Announce Type: cross  Abstract: Exercise-based rehabilitation programs have proven to be effective in enhancing the quality of life and reducing mortality and rehospitalization rates. AI-driven virtual rehabilitation, which allows patients to independently complete exercises at home, utilizes AI algorithms to analyze exercise data, providing feedback to patients and updating clinicians on their progress. These programs commonly prescribe a variety of exercise types, leading to a distinct challenge in rehabilitation exercise assessment datasets: while abundant in overall training samples, these datasets often have a limited number of samples for each individual exercise type. This disparity hampers the ability of existing approaches to train generalizable models with such a small sample size per exercise. Addressing this issue, our paper introduces a novel supervised contrastive learning framework with hard and soft negative samples that effectively utilizes the entir
    
[^5]: 基于上下文感知探索的快速适应未知同伴

    Fast Peer Adaptation with Context-aware Exploration

    [https://arxiv.org/abs/2402.02468](https://arxiv.org/abs/2402.02468)

    本文提出了一种基于上下文感知的探索方法，用于快速适应具有不同策略的未知同伴。通过奖励智能体在历史上下文中有效识别同伴行为模式，该方法能够促进智能体积极探索和快速适应，从而在不确定同伴策略时收集信息反馈，并在有信心时利用上下文执行最佳反应。

    

    在多智能体游戏中，快速适应具有不同策略的未知同伴是一个关键挑战。为了做到这一点，智能体能够高效地探索和识别同伴的策略至关重要，因为这是适应中进行最佳反应的先决条件。然而，当游戏是部分可观测且时间跨度很长时，探索未知同伴的策略是困难的。在本文中，我们提出了一种同伴识别奖励，根据智能体在历史环境下（例如多个回合的观察）如何有效地识别同伴的行为模式来奖励学习智能体。这个奖励激励智能体学习一种基于上下文的策略，以实现有效探索和快速适应，即在对同伴策略不确定时积极寻找和收集信息反馈，并在有信心时利用上下文执行最佳反应。我们在不同的测试场景上进行了评估。

    Fast adapting to unknown peers (partners or opponents) with different strategies is a key challenge in multi-agent games. To do so, it is crucial for the agent to efficiently probe and identify the peer's strategy, as this is the prerequisite for carrying out the best response in adaptation. However, it is difficult to explore the strategies of unknown peers, especially when the games are partially observable and have a long horizon. In this paper, we propose a peer identification reward, which rewards the learning agent based on how well it can identify the behavior pattern of the peer over the historical context, such as the observation over multiple episodes. This reward motivates the agent to learn a context-aware policy for effective exploration and fast adaptation, i.e., to actively seek and collect informative feedback from peers when uncertain about their policies and to exploit the context to perform the best response when confident. We evaluate our method on diverse testbeds 
    
[^6]: DurFlex-EVC: 具有并行生成的持续灵活情绪语音转换

    DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation

    [https://arxiv.org/abs/2401.08095](https://arxiv.org/abs/2401.08095)

    DurFlex-EVC通过引入风格自编码器和交叉注意力，解决了传统情绪语音转换模型中对语言和语音信息的同步问题。

    

    情绪语音转换（EVC）旨在修改说话者声音的情绪色彩，同时保留原始的语言内容和说话者独特的声音特征。最近EVC的进展涉及同时建模音高和持续时间，利用序列到序列（seq2seq）模型的潜力。为了增强转换的可靠性和效率，本研究将重点转向并行语音生成。我们介绍了DurFlex-EVC，它集成了风格自编码器和单元对齐器。传统模型虽然融入了包含语言和语音信息的自监督学习（SSL）表示，但却忽视了这种双重性质，导致了可控性的降低。为了解决这个问题，我们实现了交叉注意力以将这些表示与不同情绪进行同步。此外，我们还开发了一个风格自编码器。

    arXiv:2401.08095v2 Announce Type: replace-cross  Abstract: Emotional voice conversion (EVC) seeks to modify the emotional tone of a speaker's voice while preserving the original linguistic content and the speaker's unique vocal characteristics. Recent advancements in EVC have involved the simultaneous modeling of pitch and duration, utilizing the potential of sequence-to-sequence (seq2seq) models. To enhance reliability and efficiency in conversion, this study shifts focus towards parallel speech generation. We introduce Duration-Flexible EVC (DurFlex-EVC), which integrates a style autoencoder and unit aligner. Traditional models, while incorporating self-supervised learning (SSL) representations that contain both linguistic and paralinguistic information, have neglected this dual nature, leading to reduced controllability. Addressing this issue, we implement cross-attention to synchronize these representations with various emotions. Additionally, a style autoencoder is developed for t
    
[^7]: 从古怪的语言模型中调取潜在知识

    Eliciting Latent Knowledge from Quirky Language Models

    [https://arxiv.org/abs/2312.01037](https://arxiv.org/abs/2312.01037)

    本研究通过引入一套“古怪”的语言模型，调取了这些模型在特定上下文中的潜在知识，展示了从可信度低的模型中调取可靠知识的前景。

    

    调取潜在知识（ELK）旨在在一个能力强大的神经网络的激活中找到模式，即使网络的明显输出是错误或误导性的，也能稳定跟踪世界的真实状态。为了进一步研究ELK，我们引入了12个数据集和一套相应的“古怪”的语言模型，这些模型在回答问题时，只有在提示中包含关键词“Bob”时才会进行系统性错误的微调。我们证明了简单的探测方法可以调取模型在这些上下文中对正确答案的潜在知识，即使问题比探测器训练的问题更困难。这是由于中间层激活中的上下文无关的知识表示的存在。我们还发现，一种机械的异常检测方法可以以94%的AUROC标识不真实行为。我们的结果显示，从能力强但不受信任的模型中调取可靠的知识，并促进未来研究ELK方法的实证研究是有希望的。

    Eliciting Latent Knowledge (ELK) aims to find patterns in a capable neural network's activations which robustly track the true state of the world, even when the network's overt output is false or misleading. To further ELK research, we introduce 12 datasets and a corresponding suite of "quirky" language models that are LoRA finetuned to make systematic errors when answering questions if and only if the keyword "Bob" is present in the prompt. We demonstrate that simple probing methods can elicit the model's latent knowledge of the correct answer in these contexts, even for problems harder than those the probe was trained on. This is enabled by context-independent knowledge representations located in middle layer activations. We also find that a mechanistic anomaly detection approach can flag untruthful behavior with 94% AUROC. Our results show promise for eliciting reliable knowledge from capable but untrusted models, and facilitates future research empirically investigating ELK methods
    
[^8]: SHAP评分在可解释机器学习中的分布不确定性

    The Distributional Uncertainty of the SHAP score in Explainable Machine Learning. (arXiv:2401.12731v1 [cs.AI])

    [http://arxiv.org/abs/2401.12731](http://arxiv.org/abs/2401.12731)

    本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。

    

    归属分数反映了输入实体中的特征值对机器学习模型输出的重要性。其中最受欢迎的评分之一是SHAP评分，它是合作博弈理论中Shapley值的具体实例。该评分的定义依赖于实体群体的概率分布。由于通常不知道精确的分布，因此需要主观地进行分配或从数据中进行估计，这可能会导致误导性的特征评分。在本文中，我们提出了一个基于不知道实体群体分布的SHAP评分推理的原则性框架。在我们的框架中，我们考虑一个包含潜在分布的不确定性区域，而特征的SHAP评分成为在该区域上定义的一个函数。我们研究了找到该函数的最大值和最小值的基本问题，这使我们能够确定所有特征的SHAP评分的紧束范围。

    Attribution scores reflect how important the feature values in an input entity are for the output of a machine learning model. One of the most popular attribution scores is the SHAP score, which is an instantiation of the general Shapley value used in coalition game theory. The definition of this score relies on a probability distribution on the entity population. Since the exact distribution is generally unknown, it needs to be assigned subjectively or be estimated from data, which may lead to misleading feature scores. In this paper, we propose a principled framework for reasoning on SHAP scores under unknown entity population distributions. In our framework, we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region. We study the basic problems of finding maxima and minima of this function, which allows us to determine tight ranges for the SHAP scores of all features. In particular, we pinp
    
[^9]: CodePrompt：通过Prompt学习的知识特征改进源代码相关分类

    CodePrompt: Improving Source Code-Related Classification with Knowledge Features through Prompt Learning. (arXiv:2401.05544v1 [cs.CL])

    [http://arxiv.org/abs/2401.05544](http://arxiv.org/abs/2401.05544)

    CodePrompt是一种利用Prompt学习和注意机制技术改进源代码相关分类任务的新方法。它能够提取源代码和相关文本中的丰富知识以提高准确性，并且减少了计算成本。

    

    研究人员已经探索利用预训练语言模型（如CodeBERT）改进源代码相关任务的潜力。先前的研究主要依赖CodeBERT的文本嵌入能力和"[CLS]"句子嵌入信息作为下游源代码相关任务的语义表示进行微调。然而，这些方法需要额外的神经网络层来提取有效特征，导致计算成本更高。此外，现有方法没有利用源代码和相关文本中丰富的知识，可能导致准确性降低。本文提出了一种新的方法CodePrompt，通过Prompt学习和注意机制利用预训练模型中的丰富知识来改进源代码相关分类任务。

    Researchers have explored the potential of utilizing pre-trained language models, such as CodeBERT, to improve source code-related tasks. Previous studies have mainly relied on CodeBERT's text embedding capability and the `[CLS]' sentence embedding information as semantic representations for fine-tuning downstream source code-related tasks. However, these methods require additional neural network layers to extract effective features, resulting in higher computational costs. Furthermore, existing approaches have not leveraged the rich knowledge contained in both source code and related text, which can lead to lower accuracy. This paper presents a novel approach, CodePrompt, which utilizes rich knowledge recalled from a pre-trained model by prompt learning and an attention mechanism to improve source code-related classification tasks. Our approach initially motivates the language model with prompt information to retrieve abundant knowledge associated with the input as representative feat
    
[^10]: LLMind: 为复杂任务执行与AI和物联网进行协调的LLM框架

    LLMind: Orchestrating AI and IoT with LLMs for Complex Task Execution. (arXiv:2312.09007v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2312.09007](http://arxiv.org/abs/2312.09007)

    LLMind是一个利用大型语言模型（LLMs）作为中央协调器的AI框架，将LLMs与领域特定的AI模块整合，使得物联网设备能够有效协同执行复杂任务。

    

    本文介绍了LLMind，这是一个利用大型语言模型（LLMs）作为中央协调器的AI框架。该框架将LLMs与领域特定的AI模块整合，使得物联网设备能够有效协同执行复杂任务。LLMs通过用户友好的社交媒体平台与用户进行自然对话，提出执行复杂任务的计划。具体而言，复杂任务的执行是通过控制脚本实现的，这可能涉及多个领域特定的AI模块和物联网设备的协作。LLMs使用基于有限状态机（FSMs）的语言编码转换方法生成控制脚本。该框架还结合了语义分析和响应优化技术，以提高速度和效果。最终，该框架的设计不仅旨在创新物联网设备控制和丰富用户体验，还促进智能和集成的物联网设备。

    In this paper, we introduce LLMind, an AI framework that utilizes large language models (LLMs) as a central orchestrator. The framework integrates LLMs with domain-specific AI modules, enabling IoT devices to collaborate effectively in executing complex tasks. The LLM engages in natural conversations with human users via a user-friendly social media platform to come up with a plan to execute complex tasks. In particular, the execution of a complex task, which may involve the collaborations of multiple domain-specific AI modules and IoT devices, is realized through a control script. The LLM generates the control script using a Language-Code transformation approach based on finite-state machines (FSMs). The framework also incorporates semantic analysis and response optimization techniques to enhance speed and effectiveness. Ultimately, this framework is designed not only to innovate IoT device control and enrich user experiences but also to foster an intelligent and integrated IoT device
    
[^11]: 学习如何教大型语言模型逻辑推理

    Learning To Teach Large Language Models Logical Reasoning. (arXiv:2310.09158v1 [cs.AI])

    [http://arxiv.org/abs/2310.09158](http://arxiv.org/abs/2310.09158)

    本文通过深入调查和研究，探索了大型语言模型（LLMs）在逻辑推理中的能力，并提出了多种策略来赋予LLMs逻辑推理能力，使其能够生成更具逻辑一致性的答案。

    

    大型语言模型（LLMs）因其在语言生成和强大的泛化能力方面的出色表现而受到学术界和工业界的广泛关注。然而，由于其固有问题（如幻觉），目前的LLMs在实际推理任务中仍然输出不可靠的内容。为了更好地解决这个问题，在本文中，我们进行了深入研究，系统地探索了LLMs在逻辑推理中的能力。更具体地说，我们首先研究了LLMs在不同任务（包括事件关系提取和演绎推理）中在逻辑推理方面的不足之处。我们的研究表明，LLMs在解决需要严格推理的任务时并不是很好的推理者，会产生反事实的答案，这要求我们不断改进。因此，我们全面探索了不同的策略，赋予LLMs逻辑推理能力，从而使其能够生成更具逻辑一致性的答案。

    Large language models (LLMs) have gained enormous attention from both academia and industry, due to their exceptional ability in language generation and extremely powerful generalization. However, current LLMs still output unreliable content in practical reasoning tasks due to their inherent issues (e.g., hallucination). To better disentangle this problem, in this paper, we conduct an in-depth investigation to systematically explore the capability of LLMs in logical reasoning. More in detail, we first investigate the deficiency of LLMs in logical reasoning on different tasks, including event relation extraction and deductive reasoning. Our study demonstrates that LLMs are not good reasoners in solving tasks with rigorous reasoning and will produce counterfactual answers, which require us to iteratively refine. Therefore, we comprehensively explore different strategies to endow LLMs with logical reasoning ability, and thus enable them to generate more logically consistent answers across
    
[^12]: 通过依赖于变换的随机平滑，提供一般李普希茨：针对可解释的语义变换的认证健壮性

    General Lipschitz: Certified Robustness Against Resolvable Semantic Transformations via Transformation-Dependent Randomized Smoothing. (arXiv:2309.16710v1 [cs.CV])

    [http://arxiv.org/abs/2309.16710](http://arxiv.org/abs/2309.16710)

    我们提出了一种新的框架“一般李普希茨（GL）”，用于对神经网络进行认证，以抵御可组合的可解释的语义干扰。方法在ImageNet数据集上与最先进的方法表现相当。

    

    随机平滑是目前构建图像分类器的最先进方法，可以证明其对于有界干扰的抗性。然而，构建针对语义变换（例如，图像模糊、平移、Gamma矫正）及其组合的合理证书更为复杂。在本工作中，我们提出了一种新的框架“一般李普希茨（GL）”，用于对神经网络进行认证，以抵御可组合的可解释的语义干扰。在该框架中，我们分析了平滑分类器与变换参数之间的依赖关系，并推导出相应的健壮性证书。我们的方法在ImageNet数据集上与最先进的方法表现相当。

    Randomized smoothing is the state-of-the-art approach to construct image classifiers that are provably robust against additive adversarial perturbations of bounded magnitude. However, it is more complicated to construct reasonable certificates against semantic transformation (e.g., image blurring, translation, gamma correction) and their compositions. In this work, we propose \emph{General Lipschitz (GL),} a new framework to certify neural networks against composable resolvable semantic perturbations. Within the framework, we analyze transformation-dependent Lipschitz-continuity of smoothed classifiers w.r.t. transformation parameters and derive corresponding robustness certificates. Our method performs comparably to state-of-the-art approaches on the ImageNet dataset.
    
[^13]: MVMR: 在多个可靠视频集中评估自然语言视频定位偏差

    MVMR: Evaluating Natural Language Video Localization Bias over Multiple Reliable Videos Pool. (arXiv:2309.16701v1 [cs.CV])

    [http://arxiv.org/abs/2309.16701](http://arxiv.org/abs/2309.16701)

    本文提出了一个名为MVMR的任务，旨在给定文本查询从大量视频集中定位视频帧。我们通过已有数据集进行相似性筛选来构建数据集，并引入三个MVMR数据集。我们采用了嵌入式文本相似度匹配和视频-语言对齐技术来计算相关性得分，并为MVMR任务开发了一个强大的模型，Reliable Mutual Matching Network (RMMN)。

    

    随着近年来多媒体内容的激增，自然语言视频定位成为一个关键问题，它致力于检测与给定自然语言查询匹配的视频片段。然而，以往的研究都没有探索在存在多个正负视频的大量语料库中定位一个时刻。本文提出了一个名为MVMR（Massive Videos Moment Retrieval）的任务，旨在给定文本查询从大量视频集中定位视频帧。对于这个任务，我们提出了一种通过对现有视频定位数据集进行相似性筛选来构建数据集的方法，并引入了三个MVMR数据集。具体来说，我们采用基于嵌入的文本相似度匹配和视频-语言对齐技术来计算目标查询与视频之间的相关性得分，从而定义正负集。针对提出的MVMR任务，我们进一步开发了一个强大的模型，Reliable Mutual Matching Network (RMMN)。

    With the explosion of multimedia content in recent years, natural language video localization, which focuses on detecting video moment that matches a given natural language query, has become a critical problem. However, none of the previous research explores localizing a moment from a large corpus where multiple positive and negative videos exist. In this paper, we propose an MVMR (Massive Videos Moment Retrieval) task, which aims to localize video frames from a massive set of videos given a text query. For this task, we suggest methods for constructing datasets by employing similarity filtering on the existing video localization datasets and introduce three MVMR datasets. Specifically, we employ embedding-based text similarity matching and video-language grounding techniques to calculate the relevance score between a target query and videos to define positive and negative sets. For the proposed MVMR task, we further develop a strong model, Reliable Mutual Matching Network (RMMN), whic
    
[^14]: 用NEAT学习机器人群体的新颖行为

    Learning Emergent Behavior in Robot Swarms with NEAT. (arXiv:2309.14663v1 [cs.AI])

    [http://arxiv.org/abs/2309.14663](http://arxiv.org/abs/2309.14663)

    本研究提出了一种用NEAT方法训练分布式机器人群体算法产生新颖行为的方法，并通过实验验证了其在不同任务上的有效性。

    

    在研究机器人群体时，许多研究观察到复杂的群体行为是由个体智能体的简单局部动作产生的。然而，学习个体策略以产生所期望的新颖行为的任务仍然是一个具有挑战性且基本上未解决的问题。我们提出了一种训练分布式机器人群体算法以产生新颖行为的方法。受到动物中新颖行为的生物进化启发，我们使用进化算法训练一个“种群”中的个体行为来近似期望的群体行为。我们在使用CoppeliaSim模拟器进行的Georgia Tech Miniature Autonomous Blimps（GT-MABs）空中机器人平台模拟实验中进行了实验。此外，我们还在Anki Vector机器人的模拟中进行测试，以展示我们的算法在各种激励模式下的有效性。我们对需要一定复杂群体行为才能成功的各种任务进行了算法评估，其中包括一个区域C任务。

    When researching robot swarms, many studies observe complex group behavior emerging from the individual agents' simple local actions. However, the task of learning an individual policy to produce a desired emergent behavior remains a challenging and largely unsolved problem. We present a method of training distributed robotic swarm algorithms to produce emergent behavior. Inspired by the biological evolution of emergent behavior in animals, we use an evolutionary algorithm to train a 'population' of individual behaviors to approximate a desired group behavior. We perform experiments using simulations of the Georgia Tech Miniature Autonomous Blimps (GT-MABs) aerial robotics platforms conducted in the CoppeliaSim simulator. Additionally, we test on simulations of Anki Vector robots to display our algorithm's effectiveness on various modes of actuation. We evaluate our algorithm on various tasks where a somewhat complex group behavior is required for success. These tasks include an Area C
    
[^15]: 具有增强课程强化学习的众包感知多智能体路径规划研究

    Crowd-Aware Multi-Agent Pathfinding With Boosted Curriculum Reinforcement Learning. (arXiv:2309.10275v1 [cs.RO])

    [http://arxiv.org/abs/2309.10275](http://arxiv.org/abs/2309.10275)

    该论文介绍了CRAMP，一种基于增强式课程强化学习的众包感知分散式路径规划方法，旨在解决拥挤环境下多智能体路径规划的困难。

    

    在拥挤环境中进行的多智能体路径规划是一个具有挑战性的运动规划问题，旨在为系统中的所有智能体找到无碰撞路径。多智能体路径规划在各个领域中都有广泛的应用，包括空中群体、自动化仓储机器人和自动驾驶车辆。当前的多智能体路径规划方法可以大致分为两种主要类别：集中式规划和分散式规划。集中式规划受到维度灾难的困扰，因此在大型和复杂环境中不具备良好的可扩展性。另一方面，分散式规划使智能体能够在部分可观察环境中进行实时路径规划，展示了隐式的协调能力。然而，在密集环境中它们的收敛速度较慢且性能下降。本文介绍了一种名为CRAMP的众包感知分散式方法，通过增强式课程引导的强化学习来解决这个问题。

    Multi-Agent Path Finding (MAPF) in crowded environments presents a challenging problem in motion planning, aiming to find collision-free paths for all agents in the system. MAPF finds a wide range of applications in various domains, including aerial swarms, autonomous warehouse robotics, and self-driving vehicles. The current approaches for MAPF can be broadly categorized into two main categories: centralized and decentralized planning. Centralized planning suffers from the curse of dimensionality and thus does not scale well in large and complex environments. On the other hand, decentralized planning enables agents to engage in real-time path planning within a partially observable environment, demonstrating implicit coordination. However, they suffer from slow convergence and performance degradation in dense environments. In this paper, we introduce CRAMP, a crowd-aware decentralized approach to address this problem by leveraging reinforcement learning guided by a boosted curriculum-b
    
[^16]: 使用基于聚类的树状Parzen估计的敏感性感知混合精度量化和宽度优化的深度神经网络

    Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation. (arXiv:2308.06422v1 [cs.LG])

    [http://arxiv.org/abs/2308.06422](http://arxiv.org/abs/2308.06422)

    本研究引入了一种创新的深度神经网络优化方法，通过自动选择最佳的位宽和层宽来提高网络效率。同时，通过剪枝和聚类技术，优化了搜索过程，并在多个数据集上进行了严格测试，结果显示该方法明显优于现有方法。

    

    随着深度学习模型的复杂性和计算需求的提高，对神经网络设计的有效优化方法的需求变得至关重要。本文引入了一种创新的搜索机制，用于自动选择单个神经网络层的最佳位宽和层宽。这导致深度神经网络效率的明显提高。通过利用基于Hessian的剪枝策略，有选择地减少搜索域，确保移除非关键参数。随后，我们通过使用基于聚类的树状Parzen估计器开发有利和不利结果的替代模型。这种策略允许对架构可能性进行简化的探索，并迅速确定表现最好的设计。通过对知名数据集进行严格测试，我们的方法证明了与现有方法相比的明显优势。与领先的压缩策略相比，我们的方法取得了令人瞩目的成果。

    As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 
    
[^17]: 聚焦场景图生成的配对-关系：基于配对网络的全景场景图生成

    Pair then Relation: Pair-Net for Panoptic Scene Graph Generation. (arXiv:2307.08699v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.08699](http://arxiv.org/abs/2307.08699)

    本文提出了一种名为Pair-Net的全景场景图生成框架，通过使用配对提案网络（PPN）来学习和过滤主体和物体之间的稀疏配对关系，解决了当前全景场景图生成方法中忽视的对象间配对回忆率问题。

    

    全景场景图生成是场景图生成中的一项挑战性任务，其旨在使用全景分割代替边界框来创建更全面的场景图表示。与场景图生成相比，全景场景图生成具有一些具有挑战性的问题：像素级分割输出和完全关系探索（它还考虑了物体和物质之间的关系）。因此，当前的全景场景图生成方法的性能有限，这阻碍了下游任务或应用的发展。本工作的目标是设计一种新颖且强大的全景场景图生成基准。为了实现这一目标，我们首先进行了深入分析，确定了当前全景场景图生成模型的瓶颈，发现对象间配对的回忆率是先前的全景场景图生成方法所忽视的一个关键因素。基于这一发现和最近的基于查询的框架，我们提出了一种新的框架：配对-关系（Pair-Net），它使用配对提案网络（PPN）来学习和过滤主体和物体之间的稀疏配对关系。

    Panoptic Scene Graph (PSG) is a challenging task in Scene Graph Generation (SGG) that aims to create a more comprehensive scene graph representation using panoptic segmentation instead of boxes. Compared to SGG, PSG has several challenging problems: pixel-level segment outputs and full relationship exploration (It also considers thing and stuff relation). Thus, current PSG methods have limited performance, which hinders downstream tasks or applications. The goal of this work aims to design a novel and strong baseline for PSG. To achieve that, we first conduct an in-depth analysis to identify the bottleneck of the current PSG models, finding that inter-object pair-wise recall is a crucial factor that was ignored by previous PSG methods. Based on this and the recent query-based frameworks, we present a novel framework: Pair then Relation (Pair-Net), which uses a Pair Proposal Network (PPN) to learn and filter sparse pair-wise relationships between subjects and objects. Moreover, we also 
    
[^18]: 一项关于时间序列的图神经网络综述：预测、分类、插值和异常检测

    A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection. (arXiv:2307.03759v1 [cs.LG])

    [http://arxiv.org/abs/2307.03759](http://arxiv.org/abs/2307.03759)

    这项综述介绍了图神经网络在时间序列分析中的应用，包括预测、分类、异常检测和插值。图神经网络能够显式地建模时间序列和变量之间的关系，为时间序列数据分析带来了新的方法和技术。

    

    时间序列是记录动态系统测量结果的主要数据类型，通过物理传感器和在线过程（虚拟传感器）生成大量数据。时间序列分析对于揭示可用数据中所蕴含的丰富信息至关重要。随着图神经网络（GNN）的最新进展，基于GNN的时间序列分析方法也大幅增加。这些方法能够显式地建模时间序列和变量之间的关系，而传统和其他深度神经网络方法则面临困难。在本综述中，我们提供了一份全面的基于图神经网络的时间序列分析综述（GNN4TS），包括四个基本维度：预测、分类、异常检测和插值。我们旨在指导设计师和实践者了解、构建应用和推动GNN4TS的研究。首先，我们提供了一个全面的面向任务的GNN4TS分类体系。接下来，我们展示了...

    Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. Approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: Forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present a
    
[^19]: 使用值条件状态熵探索加速强化学习

    Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration. (arXiv:2305.19476v1 [cs.LG])

    [http://arxiv.org/abs/2305.19476](http://arxiv.org/abs/2305.19476)

    本文提出了一种新的探索技术，使用值条件状态熵来解决强化学习中探索不足的问题，可以均衡地覆盖低价值和高价值状态，相较于现有基于熵的探索方法，该方法在MuJoCo基准测试和Atari游戏上有着显著的提升。

    

    探索的一种有效技术是通过鼓励对访问状态空间的均匀覆盖来最大化已访问状态分布的熵，即状态熵。然而，它在有任务奖励的监督设置中往往难以应对，其中代理趋向于访问高价值状态以利用任务奖励。这个偏好会导致高价值状态和低价值状态的分布不平衡，当分布变得更加均匀时，状态熵会增加，从而偏向于探索低价值区域。当高价值状态在状态空间中分布狭窄时，这个问题会进一步恶化，使得代理完成任务变得更加困难。在本文中，我们提出了一种新颖的探索技术，最大化值条件状态熵，它分别估计每个状态价值估计条件下的状态熵，然后最大化它们的加权和。值条件状态熵量化了低价值和高价值状态区域的覆盖范围，从而使其对不平衡问题更加健壮。我们展示了我们的方法在一系列具有挑战性的MuJoCo基准测试和Atari游戏上显著优于现有的基于熵的探索方法。

    A promising technique for exploration is to maximize the entropy of visited state distribution, i.e., state entropy, by encouraging uniform coverage of visited state space. While it has been effective for an unsupervised setup, it tends to struggle in a supervised setup with a task reward, where an agent prefers to visit high-value states to exploit the task reward. Such a preference can cause an imbalance between the distributions of high-value states and low-value states, which biases exploration towards low-value state regions as a result of the state entropy increasing when the distribution becomes more uniform. This issue is exacerbated when high-value states are narrowly distributed within the state space, making it difficult for the agent to complete the tasks. In this paper, we present a novel exploration technique that maximizes the value-conditional state entropy, which separately estimates the state entropies that are conditioned on the value estimates of each state, then ma
    

