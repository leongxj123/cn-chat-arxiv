# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [NCoder -- A Quantum Field Theory approach to encoding data](https://rss.arxiv.org/abs/2402.00944) | NCoder 是一种基于量子场论的数据编码方法，通过修改自编码神经网络的结构，将潜在层规定为一组 $n$-点关联函数的子集，模拟了通过费曼图按阶展开构建理论有效作用量的过程。同时，NCoder 也可以看作是模拟统计推断过程的方法，通过几个较低维度的统计量来总结高维度数据，并从这些统计量中推断数据生成分布。这种方法提示了扰动重整化和模型的充分性之间的有趣对应关系。 |
| [^2] | [SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models](https://arxiv.org/abs/2403.17933) | SLEDGE是第一个使用生成模型训练的车辆运动规划生成模拟器，引入了新颖的栅格到矢量自编码器（RVAE）以及Diffusion Transformer来生成智能体和车道图，从而实现更好的模拟控制。 |
| [^3] | [Why Online Reinforcement Learning is Causal](https://arxiv.org/abs/2403.04221) | 强化学习和因果建模相互补充，论文主要指出在线学习环境下，条件概率具有因果性，离线RL是因果学习潜力最大的环境。 |
| [^4] | [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](https://arxiv.org/abs/2403.02178) | 引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果 |
| [^5] | [Resilience of Entropy Model in Distributed Neural Networks](https://arxiv.org/abs/2403.00942) | 本文研究了分布式神经网络中熵模型对有意干扰和无意干扰的韧性，通过实验证明了熵模型的韧性。 |
| [^6] | [Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies](https://arxiv.org/abs/2402.17396) | 对GPT-4在算法问题上进行了系统评估，发现采用先进的提示技术可以提高其准确性。 |
| [^7] | [Behavioral Refinement via Interpolant-based Policy Diffusion](https://arxiv.org/abs/2402.16075) | 使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。 |
| [^8] | [SQL-CRAFT: Text-to-SQL through Interactive Refinement and Enhanced Reasoning](https://arxiv.org/abs/2402.14851) | 提出了SQL-CRAFT框架，通过交互式改进和增强推理，提升了大语言模型在文本到SQL转换任务中的性能，实验结果显示性能提升高达5.7%，并在Spider榜单上超越了当前最先进技术。 |
| [^9] | [Simulacra as Conscious Exotica](https://arxiv.org/abs/2402.12422) | 本文借鉴了维特根斯坦的后期著作，尝试回答在概念生成语言模型构建的AI代理中是否有意义谈论意识的问题，避免了二元论思维的陷阱。 |
| [^10] | [Predictive representations: building blocks of intelligence](https://arxiv.org/abs/2402.06590) | 预测性表征可能是智能的多功能基石。 |
| [^11] | [The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise](https://arxiv.org/abs/2401.07844) | 本文通过使用ODE方法，将稳定性的Borkar-Meyn定理从鞅差异噪声设定拓展到马尔可夫噪声设定，提高了其在离策略强化学习中的适用性。 |
| [^12] | [Playing Large Games with Oracles and AI Debate](https://arxiv.org/abs/2312.04792) | 本论文研究了在具有大量动作的重复游戏中实现遗憾最小化的问题，通过使用基于Oracle的算法，提出了一种高效的内部遗憾最小化算法，实现了在大型游戏中计算相关均衡的高效性。通过在AI安全辩论环境中的实验验证了算法的有效性。 |
| [^13] | [Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model](https://arxiv.org/abs/2310.06707) | 提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。 |
| [^14] | [Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge.](http://arxiv.org/abs/2401.13098) | 通过考虑航运通量密度、港口距离、贸易流量和交通枢纽的中心性指标等因素，本研究开发了一个受物理启发的模型来预测海事航运流量，并用于指导全球交通网络中入侵物种的风险评估和管理。 |
| [^15] | [Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach.](http://arxiv.org/abs/2401.10747) | 本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。 |
| [^16] | [A Temporal-Spectral Fusion Transformer with Subject-specific Adapter for Enhancing RSVP-BCI Decoding.](http://arxiv.org/abs/2401.06340) | 本文提出了一种基于主题专用适配器的时间-频谱融合Transformer (TSformer-SA) 用于增强RSVP-BCI解码。该方法通过引入多视图信息并减少准备时间，实现了解码性能的提升。 |
| [^17] | [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning.](http://arxiv.org/abs/2401.01325) | 本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。 |
| [^18] | [Are Large Language Models Post Hoc Explainers?.](http://arxiv.org/abs/2310.05797) | 这项工作提出了第一个研究大型语言模型（LLMs）解释其他预测模型有效性的框架，并且提出了多个提示策略，填补了当前对于LLMs在解释其他模型行为方面的缺失。 |
| [^19] | [Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP.](http://arxiv.org/abs/2310.00927) | 本文研究了CLIP中的可转移表示学习和零样本传递，提出了一个新的CLIP类型方法，在基准数据集上取得了更好的性能。 |
| [^20] | [SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning.](http://arxiv.org/abs/2309.04766) | SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。 |
| [^21] | [Towards Semantically Enriched Embeddings for Knowledge Graph Completion.](http://arxiv.org/abs/2308.00081) | 本论文讨论了知识图谱补全算法以及利用嵌入模型捕捉知识图谱中语义的不同方法，并提出知识图谱和语言模型相互受益的观点。 |
| [^22] | [Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding.](http://arxiv.org/abs/2306.06094) | 本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。 |
| [^23] | [Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding with Luhmann's Functional Theory of Communication.](http://arxiv.org/abs/2302.03460) | 本文提出了一个更对话式的解释模型，弥合可解释人工智能与人类理解之间的差距，以创建更有效和广泛应用的人工智能系统。 |
| [^24] | [Fairness-aware Vision Transformer via Debiased Self-Attention.](http://arxiv.org/abs/2301.13803) | 这篇论文提出了一种基于去偏自注意力的公平感知视觉变换器框架，通过消除与敏感属性相关的虚假特征来减轻偏见，并利用对抗性示例来定位和屏蔽这些特征。 |

# 详细

[^1]: NCoder -- 一种基于量子场论的数据编码方法

    NCoder -- A Quantum Field Theory approach to encoding data

    [https://rss.arxiv.org/abs/2402.00944](https://rss.arxiv.org/abs/2402.00944)

    NCoder 是一种基于量子场论的数据编码方法，通过修改自编码神经网络的结构，将潜在层规定为一组 $n$-点关联函数的子集，模拟了通过费曼图按阶展开构建理论有效作用量的过程。同时，NCoder 也可以看作是模拟统计推断过程的方法，通过几个较低维度的统计量来总结高维度数据，并从这些统计量中推断数据生成分布。这种方法提示了扰动重整化和模型的充分性之间的有趣对应关系。

    

    在本文中，我们提出了一种基于量子场论（QFT）的可解释 AI 方法，称为 NCoder。NCoder 是一个修改过的自编码神经网络，其潜在层被规定为一个 $n$-点关联函数的子集。将图像视为格点场论的抽样，这个架构模拟了使用费曼图按阶展开来扰动地构建理论有效作用量的任务。或者，NCoder 可以被视为模拟统计推断过程，通过用几个较低维度的汇总统计量（这里是 $n$-点关联函数）来总结高维度数据，并从这些统计量推断数据生成分布来生成样本外数据。通过这种方式，NCoder 提示了扰动重整化和模型的充分性之间的有趣对应关系。我们展示了 NCoder 在数据编码任务上的有效性。

    In this paper we present a novel approach to interpretable AI inspired by Quantum Field Theory (QFT) which we call the NCoder. The NCoder is a modified autoencoder neural network whose latent layer is prescribed to be a subset of $n$-point correlation functions. Regarding images as draws from a lattice field theory, this architecture mimics the task of perturbatively constructing the effective action of the theory order by order in an expansion using Feynman diagrams. Alternatively, the NCoder may be regarded as simulating the procedure of statistical inference whereby high dimensional data is first summarized in terms of several lower dimensional summary statistics (here the $n$-point correlation functions), and subsequent out-of-sample data is generated by inferring the data generating distribution from these statistics. In this way the NCoder suggests a fascinating correspondence between perturbative renormalizability and the sufficiency of models. We demonstrate the efficacy of the
    
[^2]: SLEDGE: 使用生成模型合成驾驶智能体的模拟环境

    SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models

    [https://arxiv.org/abs/2403.17933](https://arxiv.org/abs/2403.17933)

    SLEDGE是第一个使用生成模型训练的车辆运动规划生成模拟器，引入了新颖的栅格到矢量自编码器（RVAE）以及Diffusion Transformer来生成智能体和车道图，从而实现更好的模拟控制。

    

    SLEDGE是第一个基于真实世界驾驶记录训练的车辆运动规划生成模拟器。其核心组件是一个学习模型，能够生成智能体边界框和车道图。该模型的输出作为交通模拟的初始状态。针对SLEDGE待生成的实体的独特特性，例如它们的连接性和每个场景的可变数量，使得大多数现代生成模型在这一任务上的朴素应用变得不简单。因此，我们除了对现有车道图表示进行系统研究外，还引入了一种新颖的栅格到矢量自编码器（RVAE）。它将智能体和车道图编码为栅格化潜在映射中的不同通道。这有助于车道条件下的智能体生成以及使用扩散变换器同时生成车道和智能体。在SLEDGE中使用生成的实体可以更好地控制模拟，例如上采样转弯。

    arXiv:2403.17933v1 Announce Type: cross  Abstract: SLEDGE is the first generative simulator for vehicle motion planning trained on real-world driving logs. Its core component is a learned model that is able to generate agent bounding boxes and lane graphs. The model's outputs serve as an initial state for traffic simulation. The unique properties of the entities to be generated for SLEDGE, such as their connectivity and variable count per scene, render the naive application of most modern generative models to this task non-trivial. Therefore, together with a systematic study of existing lane graph representations, we introduce a novel raster-to-vector autoencoder (RVAE). It encodes agents and the lane graph into distinct channels in a rasterized latent map. This facilitates both lane-conditioned agent generation and combined generation of lanes and agents with a Diffusion Transformer. Using generated entities in SLEDGE enables greater control over the simulation, e.g. upsampling turns 
    
[^3]: 在线强化学习为何具有因果性

    Why Online Reinforcement Learning is Causal

    [https://arxiv.org/abs/2403.04221](https://arxiv.org/abs/2403.04221)

    强化学习和因果建模相互补充，论文主要指出在线学习环境下，条件概率具有因果性，离线RL是因果学习潜力最大的环境。

    

    强化学习（RL）和因果建模自然互补。因果建模的目标是预测在环境中进行干预的效果，而强化学习的目标是选择最大化代理从环境中接收的奖励的干预。强化学习包括用于估计因果关系的两个最强大信息源：时间顺序和对环境进行操作的能力。本文研究了我们可以期望在哪些强化学习设置中从因果建模中受益，以及如何受益。在线学习中，代理有能力直接与环境进行交互，并从探索中学习。我们的主要论点是，在在线学习中，条件概率是因果的，因此离线RL是因果学习有潜力产生差异的环境。基本上，原因在于当代理与环境互动时，代理的行为是由其对环境的认识所推动的。

    arXiv:2403.04221v1 Announce Type: cross  Abstract: Reinforcement learning (RL) and causal modelling naturally complement each other. The goal of causal modelling is to predict the effects of interventions in an environment, while the goal of reinforcement learning is to select interventions that maximize the rewards the agent receives from the environment. Reinforcement learning includes the two most powerful sources of information for estimating causal relationships: temporal ordering and the ability to act on an environment. This paper examines which reinforcement learning settings we can expect to benefit from causal modelling, and how. In online learning, the agent has the ability to interact directly with their environment, and learn from exploring it. Our main argument is that in online learning, conditional probabilities are causal, and therefore offline RL is the setting where causal learning has the most potential to make a difference. Essentially, the reason is that when an a
    
[^4]: 掩面思想:简单地掩盖部分推理步骤可以提高语言模型对数学推理的学习

    Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models

    [https://arxiv.org/abs/2403.02178](https://arxiv.org/abs/2403.02178)

    引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果

    

    在推理任务中，即使是一个轻微的错误也可能导致不准确的结果，从而导致大型语言模型在这些领域的性能不佳。我们提出的方法避免了外部资源，而是依赖于引入对输入的扰动。我们的训练方法随机掩盖了链式思维中的某些标记，这种技术对推理任务特别有效。

    arXiv:2403.02178v1 Announce Type: cross  Abstract: In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain tokens within the chain of thought, a technique we found to be particularly effective for reasoning tasks. When applied to fine-tuning with GSM8K, this method achieved a 5% improvement in accuracy over standard supervised fine-tuning with a few codes modified and no additional labeling effort. Furthermore, it is complementary to existing methods. When integrated with related data augmentation methods, it leads to an average improvement of 3% im
    
[^5]: 分布式神经网络中熵模型的韧性

    Resilience of Entropy Model in Distributed Neural Networks

    [https://arxiv.org/abs/2403.00942](https://arxiv.org/abs/2403.00942)

    本文研究了分布式神经网络中熵模型对有意干扰和无意干扰的韧性，通过实验证明了熵模型的韧性。

    

    分布式深度神经网络（DNNs）已经成为边缘计算系统中减少通信开销而不降低性能的关键技术。最近，熵编码被引入以进一步减少通信开销。其关键思想是将分布式DNN与熵模型联合训练，该模型在推断时间用作边信息，以自适应地将潜在表示编码为具有可变长度的比特流。据我们所知，熵模型的韧性尚未得到研究。因此，在本文中，我们制定并调查了熵模型对有意干扰（例如，对抗性攻击）和无意干扰（例如，天气变化和运动模糊）的韧性。通过对3种不同DNN架构、2个熵模型和4个速率失真权衡因子进行广泛的实验，我们证明了熵模型的韧性

    arXiv:2403.00942v1 Announce Type: cross  Abstract: Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model, which is used as side information during inference time to adaptively encode latent representations into bit streams with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated. As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference (e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur). Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion trade-off factors, we demonstrate that the entropy attacks
    
[^6]: 在算法问题上对GPT-4进行基准测试：关于提示策略的系统评估

    Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies

    [https://arxiv.org/abs/2402.17396](https://arxiv.org/abs/2402.17396)

    对GPT-4在算法问题上进行了系统评估，发现采用先进的提示技术可以提高其准确性。

    

    大型语言模型（LLMs）通过在海量文本语料库上获得的知识在各种下游任务中重新利用，几乎不需要（或根本不需要）调整步骤，从而革新了自然语言处理领域。与此同时，已经反复显示LLMs缺乏系统化泛化，这使得无法将学习到的统计规律外推到训练分布之外。在本研究中，我们对其中一种最先进的LLMs，GPT-4，在三个算法任务上进行了系统基准测试，这些任务通过两个参数控制问题难度。我们比较了GPT-4与其前身（GPT-3.5）以及最近介绍的变压器编码器架构的变体，即神经数据路由器，在解决类似任务时的性能。我们发现采用先进的提示技术可以使GPT-4达到更高的准确性。

    arXiv:2402.17396v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized the field of Natural Language Processing thanks to their ability to reuse knowledge acquired on massive text corpora on a wide variety of downstream tasks, with minimal (if any) tuning steps. At the same time, it has been repeatedly shown that LLMs lack systematic generalization, which allows to extrapolate the learned statistical regularities outside the training distribution. In this work, we offer a systematic benchmarking of GPT-4, one of the most advanced LLMs available, on three algorithmic tasks characterized by the possibility to control the problem difficulty with two parameters. We compare the performance of GPT-4 with that of its predecessor (GPT-3.5) and with a variant of the Transformer-Encoder architecture recently introduced to solve similar tasks, the Neural Data Router. We find that the deployment of advanced prompting techniques allows GPT-4 to reach superior accuracy o
    
[^7]: 基于插值的策略扩散的行为细化

    Behavioral Refinement via Interpolant-based Policy Diffusion

    [https://arxiv.org/abs/2402.16075](https://arxiv.org/abs/2402.16075)

    使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。

    

    模仿学习使人工智能代理通过从演示中学习来模仿行为。最近，拥有建模高维度和多模态分布能力的扩散模型在模仿学习任务上表现出色。这些模型通过将动作（或状态）从标准高斯噪声中扩散来塑造策略。然而，要学习的目标策略通常与高斯分布显著不同，这种不匹配可能导致在使用少量扩散步骤（以提高推理速度）和有限数据下性能不佳。这项工作的关键思想是，从比高斯更具信息量的源头开始，可以使扩散方法克服上述限制。我们提供了理论结果、一种新方法和实证发现，展示了使用信息量丰富的源策略的好处。我们的方法，称为BRIDGER，利用了随机性。

    arXiv:2402.16075v1 Announce Type: cross  Abstract: Imitation learning empowers artificial agents to mimic behavior by learning from demonstrations. Recently, diffusion models, which have the ability to model high-dimensional and multimodal distributions, have shown impressive performance on imitation learning tasks. These models learn to shape a policy by diffusing actions (or states) from standard Gaussian noise. However, the target policy to be learned is often significantly different from Gaussian and this mismatch can result in poor performance when using a small number of diffusion steps (to improve inference speed) and under limited data. The key idea in this work is that initiating from a more informative source than Gaussian enables diffusion methods to overcome the above limitations. We contribute both theoretical results, a new method, and empirical findings that show the benefits of using an informative source policy. Our method, which we call BRIDGER, leverages the stochast
    
[^8]: SQL-CRAFT: 通过交互式改进和增强推理实现文本到SQL转换

    SQL-CRAFT: Text-to-SQL through Interactive Refinement and Enhanced Reasoning

    [https://arxiv.org/abs/2402.14851](https://arxiv.org/abs/2402.14851)

    提出了SQL-CRAFT框架，通过交互式改进和增强推理，提升了大语言模型在文本到SQL转换任务中的性能，实验结果显示性能提升高达5.7%，并在Spider榜单上超越了当前最先进技术。

    

    现代大语言模型已经变得越来越强大，但在专门任务（如文本到SQL）方面仍面临挑战。我们提出了SQL-CRAFT，一个通过交互式改进和增强推理来提升大语言模型SQL生成能力的框架。我们利用交互式纠错循环（IC-Loop）使大语言模型与数据库自动交互，同时采用增强推理的方法。我们在两个文本到SQL数据集Spider和Bird上进行实验，性能比朴素提示方法提高了高达5.7%。此外，我们的方法在Spider榜单上超过了当前最先进技术，展示了我们框架的有效性。

    arXiv:2402.14851v1 Announce Type: cross  Abstract: Modern LLMs have become increasingly powerful, but they are still facing challenges in specialized tasks such as Text-to-SQL. We propose SQL-CRAFT, a framework to advance LLMs' SQL generation Capabilities through inteRActive reFinemenT and enhanced reasoning. We leverage an Interactive Correction Loop (IC-Loop) for LLMs to interact with databases automatically, as well as Python-enhanced reasoning. We conduct experiments on two Text-to-SQL datasets, Spider and Bird, with performance improvements of up to 5.7% compared to the naive prompting method. Moreover, our method surpasses the current state-of-the-art on the Spider Leaderboard, demonstrating the effectiveness of our framework.
    
[^9]: 模拟体作为意识异域

    Simulacra as Conscious Exotica

    [https://arxiv.org/abs/2402.12422](https://arxiv.org/abs/2402.12422)

    本文借鉴了维特根斯坦的后期著作，尝试回答在概念生成语言模型构建的AI代理中是否有意义谈论意识的问题，避免了二元论思维的陷阱。

    

    arXiv：2402.12422v1 发布类型：新摘要：随着越来越像人类行为的会话代理的出现，古老的哲学问题被重新审视。在概念生成语言模型构建的AI代理中，是否有意义谈论意识，考虑到它们只是人类行为的“纯粹”模拟，并且它们的行为可以被看作是“仅仅”角色扮演？本文借鉴了维特根斯坦的后期著作，试图解决这个问题，同时避免二元论思维的陷阱。

    arXiv:2402.12422v1 Announce Type: new  Abstract: The advent of conversational agents with increasingly human-like behaviour throws old philosophical questions into new light. Does it, or could it, ever make sense to speak of AI agents built out of generative language models in terms of consciousness, given that they are "mere" simulacra of human behaviour, and that what they do can be seen as "merely" role play? Drawing on the later writings of Wittgenstein, this paper attempts to tackle this question while avoiding the pitfalls of dualistic thinking.
    
[^10]: 预测性表征：智能的基石

    Predictive representations: building blocks of intelligence

    [https://arxiv.org/abs/2402.06590](https://arxiv.org/abs/2402.06590)

    预测性表征可能是智能的多功能基石。

    

    适应性行为通常需要预测未来事件。强化学习理论规定了什么样的预测性表征是有用的以及如何计算它们。本文将这些理论观点与认知和神经科学的研究结合起来。我们特别关注继任者表征（SR）及其广义形式，它们不仅被广泛应用于工程工具，也作为大脑功能的模型。这种融合表明特定类型的预测性表征可能是智能的多功能基石。

    Adaptive behavior often requires predicting future events. The theory of reinforcement learning prescribes what kinds of predictive representations are useful and how to compute them. This paper integrates these theoretical ideas with work on cognition and neuroscience. We pay special attention to the successor representation (SR) and its generalizations, which have been widely applied both as engineering tools and models of brain function. This convergence suggests that particular kinds of predictive representations may function as versatile building blocks of intelligence.
    
[^11]: 使用ODE方法进行带有马尔可夫噪声的随机逼近和强化学习

    The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise

    [https://arxiv.org/abs/2401.07844](https://arxiv.org/abs/2401.07844)

    本文通过使用ODE方法，将稳定性的Borkar-Meyn定理从鞅差异噪声设定拓展到马尔可夫噪声设定，提高了其在离策略强化学习中的适用性。

    

    随机逼近是一类通过迭代、增量和随机更新向量的算法，包括随机梯度下降和时序差分学习。分析随机逼近算法的一个主要挑战是确保其稳定性，即证明随机向量迭代几乎必定有界。本文将稳定性的Borkar-Meyn定理从鞅差异噪声设定拓展到马尔可夫噪声设定，大大提高了其在强化学习中的适用性，特别是那些具有线性函数逼近和资格迹的离策略强化学习算法。我们的分析的核心在于少数函数的渐进变化速率下降，这一点由大数定律和常用的V4 Lyapunov漂移条件隐含，并在马尔可夫链是有限且不可约时显然成立。

    Stochastic approximation is a class of algorithms that update a vector iteratively, incrementally, and stochastically, including, e.g., stochastic gradient descent and temporal difference learning. One fundamental challenge in analyzing a stochastic approximation algorithm is to establish its stability, i.e., to show that the stochastic vector iterates are bounded almost surely. In this paper, we extend the celebrated Borkar-Meyn theorem for stability from the Martingale difference noise setting to the Markovian noise setting, which greatly improves its applicability in reinforcement learning, especially in those off-policy reinforcement learning algorithms with linear function approximation and eligibility traces. Central to our analysis is the diminishing asymptotic rate of change of a few functions, which is implied by both a form of strong law of large numbers and a commonly used V4 Lyapunov drift condition and trivially holds if the Markov chain is finite and irreducible.
    
[^12]: 使用Oracle和AI辩论进行大型游戏的玩法

    Playing Large Games with Oracles and AI Debate

    [https://arxiv.org/abs/2312.04792](https://arxiv.org/abs/2312.04792)

    本论文研究了在具有大量动作的重复游戏中实现遗憾最小化的问题，通过使用基于Oracle的算法，提出了一种高效的内部遗憾最小化算法，实现了在大型游戏中计算相关均衡的高效性。通过在AI安全辩论环境中的实验验证了算法的有效性。

    

    我们考虑在具有大量动作的重复游戏中实现遗憾最小化。这种游戏在通过辩论确保AI安全的环境中是固有的，并且更一般地应用于动作基于语言的游戏中。现有的在线游戏算法需要多项式计算数量的动作，而对于大型游戏来说，这可能是难以实现的。因此，我们考虑使用基于Oracle的算法，因为Oracle自然地模拟了对AI代理的访问。通过对Oracle访问进行特征化，我们可以有效地实现内部和外部遗憾的最小化。我们提出了一种新颖的内部遗憾最小化算法，其遗憾和计算复杂度对数地依赖于动作数量。这意味着可以高效地基于Oracle计算大型游戏中的相关均衡。最后，我们通过在AI安全辩论环境中进行实验，展示了我们算法分析的好处。

    We consider regret minimization in repeated games with a very large number of actions. Such games are inherent in the setting of AI safety via debate, and more generally games whose actions are language-based. Existing algorithms for online game playing require computation polynomial in the number of actions, which can be prohibitive for large games.   We thus consider oracle-based algorithms, as oracles naturally model access to AI agents. With oracle access, we characterize when internal and external regret can be minimized efficiently. We give a novel efficient algorithm for internal regret minimization whose regret and computation complexity depend logarithmically on the number of actions. This implies efficient oracle-based computation of a correlated equilibrium in large games.   We conclude with experiments in the setting of AI Safety via Debate that shows the benefit of insights from our algorithmic analysis.
    
[^13]: 质量感知翻译模型：单一模型中的高效生成和质量评估

    Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model

    [https://arxiv.org/abs/2310.06707](https://arxiv.org/abs/2310.06707)

    提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。

    

    最大后验（MAP）解码是神经机器翻译（NMT）模型中最广泛使用的解码策略。 研究表明，模型概率与人类判断相关，但不能总是成立，生成质量可以通过解码来优化一个以度量或质量评估信号支持的效用函数来提高，即最小贝叶斯风险（MBR）或质量感知解码。 这些方法的主要缺点在于它们需要一个额外的模型在解码过程中计算效用函数，会显著增加计算成本。 本文提出通过训练NMT模型自己来估计其输出质量，从而使NMT模型本身具备质量感知能力。 使用这种方法进行MBR解码可以显著减小尺寸。

    arXiv:2310.06707v2 Announce Type: replace-cross  Abstract: Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategy for neural machine translation (NMT) models. The underlying assumption is that model probability correlates well with human judgment, with better translations getting assigned a higher score by the model. However, research has shown that this assumption does not always hold, and generation quality can be improved by decoding to optimize a utility function backed by a metric or quality-estimation signal, as is done by Minimum Bayes Risk (MBR) or Quality-Aware decoding. The main disadvantage of these approaches is that they require an additional model to calculate the utility function during decoding, significantly increasing the computational cost. In this paper, we propose to make the NMT models themselves quality-aware by training them to estimate the quality of their own output. Using this approach for MBR decoding we can drastically reduce the size
    
[^14]: 通过重力信息驱动的深度学习框架预测非本地物种船舶交通流量和入侵风险

    Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge. (arXiv:2401.13098v1 [cs.LG])

    [http://arxiv.org/abs/2401.13098](http://arxiv.org/abs/2401.13098)

    通过考虑航运通量密度、港口距离、贸易流量和交通枢纽的中心性指标等因素，本研究开发了一个受物理启发的模型来预测海事航运流量，并用于指导全球交通网络中入侵物种的风险评估和管理。

    

    水体中的入侵物种对全球环境和生物多样性构成了重大威胁。由于交通和贸易增加，非本土物种已经引入了新的环境，导致生态系统破坏，并导致农业、林业和渔业方面的经济损失。因此，迫切需要风险评估和管理技术以减轻这些入侵的影响。本研究旨在开发一种新的受物理启发的模型，用于预测海事航运交通流量，并以此指导通过全球交通网络传播的入侵物种风险评估。受国际贸易重力模型的启发，我们的模型考虑了影响船舶活动可能性和影响的各种因素，如航运通量密度、港口之间的距离、贸易流量和交通枢纽的中心性指标。此外，通过分析入侵物种的风险网络，我们为评估和管理入侵提供了全面的框架。

    Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for as
    
[^15]: 缺失模态下的多模态情感分析:一种知识迁移方法

    Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])

    [http://arxiv.org/abs/2401.10747](http://arxiv.org/abs/2401.10747)

    本文提出了一种知识迁移方法，用于在缺失模态下进行多模态情感分析。通过翻译不同模态之间的内容以重构缺失的音频模态，并利用跨模态注意机制进行情感预测，实验证明了该方法在多个数据集上表现出显著的改进和与完整多模态监督方法相媲美的效果。

    

    多模态情感分析旨在通过视觉、语言和声音线索来识别个体表达的情绪。然而，现有研究大多假设在训练和测试过程中所有模态都是可用的，这使得它们的算法容易受到缺失模态的影响。在本文中，我们提出了一种新颖的知识迁移网络，用于在不同模态之间进行翻译，以重构缺失的音频模态。此外，我们还开发了一种跨模态注意机制，以保留重构和观察到的模态的最大信息，用于情感预测。在三个公开数据集上进行的大量实验证明了相对于基线算法的显著改进，并实现了与具有完整多模态监督的先前方法相媲美的结果。

    Multimodal sentiment analysis aims to identify the emotions expressed by individuals through visual, language, and acoustic cues. However, most of the existing research efforts assume that all modalities are available during both training and testing, making their algorithms susceptible to the missing modality scenario. In this paper, we propose a novel knowledge-transfer network to translate between different modalities to reconstruct the missing audio modalities. Moreover, we develop a cross-modality attention mechanism to retain the maximal information of the reconstructed and observed modalities for sentiment prediction. Extensive experiments on three publicly available datasets demonstrate significant improvements over baselines and achieve comparable results to the previous methods with complete multi-modality supervision.
    
[^16]: 基于主题专用适配器的时间-频谱融合Transformer用于增强RSVP-BCI解码

    A Temporal-Spectral Fusion Transformer with Subject-specific Adapter for Enhancing RSVP-BCI Decoding. (arXiv:2401.06340v1 [cs.HC])

    [http://arxiv.org/abs/2401.06340](http://arxiv.org/abs/2401.06340)

    本文提出了一种基于主题专用适配器的时间-频谱融合Transformer (TSformer-SA) 用于增强RSVP-BCI解码。该方法通过引入多视图信息并减少准备时间，实现了解码性能的提升。

    

    快速串联视觉呈现（RSVP）基于脑机接口（BCI）是一种利用脑电信号进行目标检索的高效技术。传统解码方法的性能改进依赖于大量来自新测试对象的训练数据，这增加了BCI系统的准备时间。一些研究引入了来自现有对象的数据以减少性能改进对新对象数据的依赖性，但它们基于对抗学习的优化策略以及大量数据的训练增加了准备过程中的训练时间。此外，大多数之前的方法只关注脑电信号的单视图信息，而忽略了其他视图的信息，这可能进一步改善性能。为了在减少准备时间的同时提高解码性能，我们提出了一种具有主题专用适配器的时间-频谱融合Transformer（TSformer-SA）。

    The Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface (BCI) is an efficient technology for target retrieval using electroencephalography (EEG) signals. The performance improvement of traditional decoding methods relies on a substantial amount of training data from new test subjects, which increases preparation time for BCI systems. Several studies introduce data from existing subjects to reduce the dependence of performance improvement on data from new subjects, but their optimization strategy based on adversarial learning with extensive data increases training time during the preparation procedure. Moreover, most previous methods only focus on the single-view information of EEG signals, but ignore the information from other views which may further improve performance. To enhance decoding performance while reducing preparation time, we propose a Temporal-Spectral fusion transformer with Subject-specific Adapter (TSformer-SA). Specifically, a cross-view interaction 
    
[^17]: 自扩展LLM:无需调整的LLM上下文窗口。

    LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning. (arXiv:2401.01325v1 [cs.CL])

    [http://arxiv.org/abs/2401.01325](http://arxiv.org/abs/2401.01325)

    本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。

    

    本研究揭示了LLM在处理长上下文时的固有能力，而无需进行精调。在训练过程中，训练序列的有限长度可能限制了大型语言模型（LLMs）在推理过程中对长输入序列的应用。在本研究中，我们认为现有的LLMs本身具有处理长上下文的固有能力。基于这一观点，我们建议通过自身扩展LLMs的上下文窗口，以充分利用其固有能力。我们提出了Self-Extend方法来激发LLMs的长上下文处理潜力。基本思想是构建双层注意信息：群组级和邻居级。这两个级别通过原始模型的自注意力计算，这意味着所提方法不需要任何训练。只需修改四行代码，所提方法就可以轻松扩展现有LLMs的上下文窗口，而无需进行任何精调。我们进行了全面的实验证明，结果表明所提方法可以+摘要减掉文章最后一句話

    This work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can 
    
[^18]: 大型语言模型是事后解释器吗？

    Are Large Language Models Post Hoc Explainers?. (arXiv:2310.05797v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05797](http://arxiv.org/abs/2310.05797)

    这项工作提出了第一个研究大型语言模型（LLMs）解释其他预测模型有效性的框架，并且提出了多个提示策略，填补了当前对于LLMs在解释其他模型行为方面的缺失。

    

    大型语言模型（LLM）越来越被广泛应用于各种自然语言处理（NLP）应用中。最近的一项创新，即上下文学习（ICL），使得LLM能够在推理阶段通过在提示中提供少量示例来学习新任务，从而消除了模型微调的需要。虽然LLM已经被应用于多个领域，但其在解释其他模型行为方面的适用性仍相对未被探索。尽管存在越来越多的新解释技术，但很多技术要求对模型具有白盒访问权限和/或计算成本较高，凸显了下一代事后解释器的需求。在这项工作中，我们提出了第一个研究LLM解释其他预测模型有效性的框架。具体而言，我们提出了一个包含多种提示策略的新颖框架：i）基于扰动的ICL，ii）基于预测的ICL，iii）基于指令的ICL，和iv）基于解释的ICL。

    Large Language Models (LLMs) are increasingly used as powerful tools for a plethora of natural language processing (NLP) applications. A recent innovation, in-context learning (ICL), enables LLMs to learn new tasks by supplying a few examples in the prompt during inference time, thereby eliminating the need for model fine-tuning. While LLMs have been utilized in several applications, their applicability in explaining the behavior of other models remains relatively unexplored. Despite the growing number of new explanation techniques, many require white-box access to the model and/or are computationally expensive, highlighting a need for next-generation post hoc explainers. In this work, we present the first framework to study the effectiveness of LLMs in explaining other predictive models. More specifically, we propose a novel framework encompassing multiple prompting strategies: i) Perturbation-based ICL, ii) Prediction-based ICL, iii) Instruction-based ICL, and iv) Explanation-based I
    
[^19]: 理解CLIP中的可转移表示学习和零样本传递

    Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP. (arXiv:2310.00927v1 [cs.LG])

    [http://arxiv.org/abs/2310.00927](http://arxiv.org/abs/2310.00927)

    本文研究了CLIP中的可转移表示学习和零样本传递，提出了一个新的CLIP类型方法，在基准数据集上取得了更好的性能。

    

    多模态学习因其能够利用不同数据源（例如文本和图像）的信息来提高模型性能而日益受到关注。近年来，CLIP作为一种有效的方法，采用视觉-语言对比预训练来学习联合图像和文本表示，并在零样本学习和文本引导的自然图像生成方面表现出非凡的性能。尽管CLIP在实践中取得了巨大的成功，但其理论理解仍然困难。在本文中，我们正式研究了CLIP中的可转移表示学习，并展示了不同模态的特征如何对齐。我们还分析了其在下游任务中的零样本传递性能。受到我们分析的启发，我们提出了一种新的CLIP类型方法，在基准数据集上实现了比CLIP和其他最先进方法更好的性能。

    Multi-modal learning has become increasingly popular due to its ability to leverage information from different data sources (e.g., text and images) to improve the model performance. Recently, CLIP has emerged as an effective approach that employs vision-language contrastive pretraining to learn joint image and text representations and exhibits remarkable performance in zero-shot learning and text-guided natural image generation. Despite the huge practical success of CLIP, its theoretical understanding remains elusive. In this paper, we formally study transferrable representation learning underlying CLIP and demonstrate how features from different modalities get aligned. We also analyze its zero-shot transfer performance on the downstream tasks. Inspired by our analysis, we propose a new CLIP-type approach, which achieves better performance than CLIP and other state-of-the-art methods on benchmark datasets.
    
[^20]: SeaEval多语言基础模型：从跨语言对齐到文化推理

    SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning. (arXiv:2309.04766v1 [cs.CL])

    [http://arxiv.org/abs/2309.04766](http://arxiv.org/abs/2309.04766)

    SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。

    

    我们提出了一种用于多语言基础模型的SeaEval基准测试。除了表征这些模型如何理解和推理自然语言外，我们还研究了它们对文化实践、细微差别和价值观的理解能力。除了标准的准确度指标，我们还调查了基础模型在语义和多语言性维度上的脆弱性。我们的分析涵盖了开源和闭源模型，从而得到了在经典的自然语言处理任务、推理和文化理解方面的实证结果。重要发现包括：（1）大多数模型在给出改写指令时的行为各异；（2）许多模型仍然受到暴露偏差的影响（如位置偏差、大多数标签偏差）；（3）对于根源于事实、科学和常识知识的问题，预期在语义上等价的多语言查询应该得到一致的回答。然而，大多数模型在这些查询上表现出令人意外的不一致性；（4）多语言情况下，模型对于情感相关的问题表现出不同程度的一致性。

    We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Most models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingu
    
[^21]: 为知识图谱补全构建语义丰富的嵌入模型

    Towards Semantically Enriched Embeddings for Knowledge Graph Completion. (arXiv:2308.00081v1 [cs.AI])

    [http://arxiv.org/abs/2308.00081](http://arxiv.org/abs/2308.00081)

    本论文讨论了知识图谱补全算法以及利用嵌入模型捕捉知识图谱中语义的不同方法，并提出知识图谱和语言模型相互受益的观点。

    

    基于嵌入模型的知识图谱补全在过去几年中越来越受关注。目前的大多数算法将知识图谱视为一个多向标记图，缺乏捕捉底层语义的能力。与此同时，大型语言模型（LLMs）已经捕获了大量信息，这一捕获对人工智能领域产生了革命性影响。知识图谱可以从LLMs中受益，反之亦然。本文讨论了基于不同生成嵌入模型变体的知识图谱补全算法。首先讨论了各种知识图谱补全算法，如转导和归纳链接预测以及实体类型预测算法。然后，介绍了利用知识图谱中的类型信息、LLMs以及捕捉不同描述逻辑公理中的语义的算法。最后，通过对现有算法的关键反思对论文进行总结。

    Embedding based Knowledge Graph (KG) Completion has gained much attention over the past few years. Most of the current algorithms consider a KG as a multidirectional labeled graph and lack the ability to capture the semantics underlying the schematic information. In a separate development, a vast amount of information has been captured within the Large Language Models (LLMs) which has revolutionized the field of Artificial Intelligence. KGs could benefit from these LLMs and vice versa. This vision paper discusses the existing algorithms for KG completion based on the variations for generating KG embeddings. It starts with discussing various KG completion algorithms such as transductive and inductive link prediction and entity type prediction algorithms. It then moves on to the algorithms utilizing type information within the KGs, LLMs, and finally to algorithms capturing the semantics represented in different description logic axioms. We conclude the paper with a critical reflection on
    
[^22]: 利用大型语言模型进行可伸缩矢量图驱动的图像理解

    Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding. (arXiv:2306.06094v1 [cs.CV])

    [http://arxiv.org/abs/2306.06094](http://arxiv.org/abs/2306.06094)

    本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。

    

    最近，大型语言模型(LLMs)在自然语言理解和生成方面取得了显著进展。然而，它们在计算机视觉领域的潜力仍然很大程度上没有被开发。本文介绍了一种新的探索性方法，使得LLMs能够使用可伸缩矢量图(SVG)格式处理图像。通过利用基于XML的SVG表述的文本描述而不是光栅图像，我们旨在弥合视觉和文本模态之间的差距，使LLMs能够直接理解和操作图像，而无需使用参数化的视觉组件。我们的方法仅利用LLMs的能力进行简单的图像分类、生成和上下文学习。我们展示了方法在判别和生成任务中的优异表现，重点介绍了它(i)对分布转移的鲁棒性，(ii)通过利用LLMs的上下文学习能力实现的显著改进，以及(iii)图像杂乱程度上的显著性能提高。

    Recently, large language models (LLMs) have made significant advancements in natural language understanding and generation. However, their potential in computer vision remains largely unexplored. In this paper, we introduce a new, exploratory approach that enables LLMs to process images using the Scalable Vector Graphics (SVG) format. By leveraging the XML-based textual descriptions of SVG representations instead of raster images, we aim to bridge the gap between the visual and textual modalities, allowing LLMs to directly understand and manipulate images without the need for parameterized visual components. Our method facilitates simple image classification, generation, and in-context learning using only LLM capabilities. We demonstrate the promise of our approach across discriminative and generative tasks, highlighting its (i) robustness against distribution shift, (ii) substantial improvements achieved by tapping into the in-context learning abilities of LLMs, and (iii) image unders
    
[^23]: 注意留下空隙！用鲁曼功能理论构建可解释人工智能与人类理解之间的桥梁

    Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding with Luhmann's Functional Theory of Communication. (arXiv:2302.03460v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2302.03460](http://arxiv.org/abs/2302.03460)

    本文提出了一个更对话式的解释模型，弥合可解释人工智能与人类理解之间的差距，以创建更有效和广泛应用的人工智能系统。

    

    在过去的十年中，可解释人工智能已从一种主要的技术学科发展成与社会科学紧密相交的领域。人类偏好对比的解释，确切而言是反事实的解释，对于这种转变起到了重要的作用，启发和引领计算机科学的研究。然而，其他同样重要的观察却受到了很少的关注。人类解释者希望通过对话式的交互与人工智能解释者进行交流的愿望在社区中基本被忽视。这给这种技术的有效性和广泛应用带来了很多挑战，因为根据预定义的目标提供单一的优化解释可能会失败，并且不能满足其接收者的独特需求，鉴于人类知识和意图的多样性。本文利用尼克拉斯·鲁曼和其他交流学者阐述的见解，提出了向更对话式的解释模型的转变，其中解释者和被解释者之间的信息持续交流是核心。通过这种模型，我们可以建立更有效和广泛应用的人工智能系统，弥合可解释人工智能与人类理解之间的差距。

    Over the past decade explainable artificial intelligence has evolved from a predominantly technical discipline into a field that is deeply intertwined with social sciences. Insights such as human preference for contrastive -- more precisely, counterfactual -- explanations have played a major role in this transition, inspiring and guiding the research in computer science. Other observations, while equally important, have received much less attention. The desire of human explainees to communicate with artificial intelligence explainers through a dialogue-like interaction has been mostly neglected by the community. This poses many challenges for the effectiveness and widespread adoption of such technologies as delivering a single explanation optimised according to some predefined objectives may fail to engender understanding in its recipients and satisfy their unique needs given the diversity of human knowledge and intention. Using insights elaborated by Niklas Luhmann and, more recently,
    
[^24]: 基于去偏自注意力的公平感知视觉变换器

    Fairness-aware Vision Transformer via Debiased Self-Attention. (arXiv:2301.13803v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13803](http://arxiv.org/abs/2301.13803)

    这篇论文提出了一种基于去偏自注意力的公平感知视觉变换器框架，通过消除与敏感属性相关的虚假特征来减轻偏见，并利用对抗性示例来定位和屏蔽这些特征。

    

    最近，由于其提取信息特征和通过自我关注机制建模长距离依赖关系的能力，视觉变换器（ViT）在解决计算机视觉（CV）问题方面引起了广泛关注。为了充分发挥ViT在现实应用中的优势，最近的研究探索了ViT的可靠性和可解释性，包括其鲁棒性和可解释性。然而，另一个需求，公平性，在文献中尚未得到充分解决。我们证明了现有的公平感知算法（主要设计用于CNN）在ViT上表现不佳。这就需要我们通过去偏自注意（DSA）开发我们的新框架。DSA是一种通过盲目方法来强制ViT消除与敏感属性相关的虚假特征以减轻偏见的方法。值得注意的是，对抗性示例被用来定位和屏蔽输入图像块中的虚假特征。

    Vision Transformer (ViT) has recently gained significant interest in solving computer vision (CV) problems due to its capability of extracting informative features and modeling long-range dependencies through the self-attention mechanism. To fully realize the advantages of ViT in real-world applications, recent works have explored the trustworthiness of ViT, including its robustness and explainability. However, another desiderata, fairness has not yet been adequately addressed in the literature. We establish that the existing fairness-aware algorithms (primarily designed for CNNs) do not perform well on ViT. This necessitates the need for developing our novel framework via Debiased Self-Attention (DSA). DSA is a fairness-through-blindness approach that enforces ViT to eliminate spurious features correlated with the sensitive attributes for bias mitigation. Notably, adversarial examples are leveraged to locate and mask the spurious features in the input image patches. In addition, DSA u
    

