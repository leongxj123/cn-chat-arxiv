# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety](https://arxiv.org/abs/2404.01099) | 通过双向锚定方法，识别那些在微调后更可能降低模型安全性的良性数据子集，提高模型对有害请求的响应率。 |
| [^2] | [Information-Theoretic Distillation for Reference-less Summarization](https://arxiv.org/abs/2403.13780) | 提出了一种名为InfoSumm的框架，通过信息论目标实现了无参考摘要的精炼生成器 |
| [^3] | [Response Style Characterization for Repeated Measures Using the Visual Analogue Scale](https://arxiv.org/abs/2403.10136) | 本研究针对重复测量的视觉模拟量表数据开发了一种新颖的响应风格（RP）表征方法，以解决在VAS中处理RP的困难。 |
| [^4] | [Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints](https://arxiv.org/abs/2403.06906) | 提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题 |
| [^5] | [PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering](https://arxiv.org/abs/2403.05053) | 本文提出了PrimeComposer，一种更快的逐步组合扩散方式，用于图像合成，主要专注于前景生成，从而解决了合成中的凝聚混乱和外观信息丢失问题，并避免了不必要的背景生成导致的前景生成质量下降。 |
| [^6] | [MOKA: Open-Vocabulary Robotic Manipulation through Mark-Based Visual Prompting](https://arxiv.org/abs/2403.03174) | MOKA方法利用视觉语言模型解决机器人操作任务，实现了开放词汇的机器人操作。 |
| [^7] | [SoftTiger: A Clinical Foundation Model for Healthcare Workflows](https://arxiv.org/abs/2403.00868) | SoftTiger是一个专为医疗工作流设计的临床大型语言模型，通过处理临床笔记的结构化，实现了基本临床任务以及更复杂的下游临床任务的执行。 |
| [^8] | [Learning Planning Action Models from State Traces](https://arxiv.org/abs/2402.10726) | 该论文探讨了一种从状态轨迹中学习规划行动模型的方法，尤其关注在参数未提供的情况下进行学习，并提出了两种不同级别的跟踪质量以及相应的算法。 |
| [^9] | [Cloud Kitchen: Using Planning-based Composite AI to Optimize Food Delivery Process](https://arxiv.org/abs/2402.10725) | Cloud Kitchen平台利用基于规划的复合AI优化食品配送流程，通过车辆路径问题和真实历史数据集降低延迟配送量，提高顾客满意度。 |
| [^10] | [Strong hallucinations from negation and how to fix them](https://arxiv.org/abs/2402.10543) | 论文针对语言模型在推理中造成的强幻觉问题，提出了一种处理否定的新方法，可以改善模型性能而无需使用稀疏负数据训练。 |
| [^11] | [Non-autoregressive Generative Models for Reranking Recommendation](https://arxiv.org/abs/2402.06871) | 本研究提出了一个非自回归的生成模型用于排序推荐，在多阶段推荐系统中扮演关键角色。该模型旨在提高效率和效果，并解决稀疏训练样本和动态候选项对模型收敛性的挑战。 |
| [^12] | [PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety](https://arxiv.org/abs/2401.11880) | PsySafe提出了一个综合框架，通过深入探讨智能体心理学，揭示智能体的黑暗心理状态对安全构成威胁，并提出了有效的风险缓解策略。 |
| [^13] | [CodePrompt: Improving Source Code-Related Classification with Knowledge Features through Prompt Learning.](http://arxiv.org/abs/2401.05544) | CodePrompt是一种利用Prompt学习和注意机制技术改进源代码相关分类任务的新方法。它能够提取源代码和相关文本中的丰富知识以提高准确性，并且减少了计算成本。 |
| [^14] | [Malla: Demystifying Real-world Large Language Model Integrated Malicious Services.](http://arxiv.org/abs/2401.03315) | 本研究对212个真实的恶意服务（Malla）进行了系统研究，揭示了它们在地下市场的扩散和对公共LLM服务的影响，以及其使用的策略和技术。 |
| [^15] | [PromptBench: A Unified Library for Evaluation of Large Language Models.](http://arxiv.org/abs/2312.07910) | PromptBench是一个用于评估大型语言模型的统一库，包括了提示语构建、提示语工程、数据集和模型加载、对抗性提示攻击、动态评估协议和分析工具等组件，旨在促进原创研究和创建新的基准测试、部署下游应用以及设计新的评估协议。 |
| [^16] | [Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value.](http://arxiv.org/abs/2311.00582) | 该论文研究了游戏修改问题，提出了一种最小修改马尔可夫博弈的方法，使得目标策略配置成为唯一的Nash均衡并具有特定价值范围，同时最小化修改成本。 |
| [^17] | [Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception.](http://arxiv.org/abs/2310.13712) | 本研究探索了四种教学指导策略对学习者在使用LLM时的表现和感知效果，发现直接LLM答案提高了表现，而改进学生解决方案则增加了对LLM的信任度。同时，结构化指导也减少了随机查询和学生复制粘贴问题的现象。 |
| [^18] | [A Framework for Empowering Reinforcement Learning Agents with Causal Analysis: Enhancing Automated Cryptocurrency Trading.](http://arxiv.org/abs/2310.09462) | 本研究提出了一个基于强化学习的自动交易系统框架CausalReinforceNet，通过因果分析增强了强化学习代理的能力，以提高对加密货币市场的交易能力。 |
| [^19] | [Modelling Irregularly Sampled Time Series Without Imputation.](http://arxiv.org/abs/2309.08698) | SLAN是一种无需插值的方法，可以建模不规则采样时间序列，利用动态适应的LSTM架构来捕捉每个传感器的局部摘要，并在整个观测期间维持一个全局摘要状态。 |
| [^20] | [Efficient Quantization-aware Training with Adaptive Coreset Selection.](http://arxiv.org/abs/2306.07215) | 本研究提出了一种用于改善量化感知训练的训练效率的方法，通过核心集选择和两个重要性指标来选择训练数据的子集。 |
| [^21] | [NeuralMatrix: Moving Entire Neural Networks to General Matrix Multiplication for Efficient Inference.](http://arxiv.org/abs/2305.14405) | NeuralMatrix是一种框架，能够在单个通用矩阵乘法加速器上计算深度神经网络(DNNs)，并可在保持推理准确度的情况下实现高达113倍至19.44倍的性能提升。 |
| [^22] | [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality.](http://arxiv.org/abs/2305.00050) | 大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。 |
| [^23] | [Representation Matters: The Game of Chess Poses a Challenge to Vision Transformers.](http://arxiv.org/abs/2304.14918) | 这篇论文通过改变输入表示和价值损失，使棋盘游戏性能获得了高达180 Elo点的增强 |
| [^24] | [REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network.](http://arxiv.org/abs/2304.03997) | 本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。 |

# 详细

[^1]: 你的“安全”数据中有什么？：识别破坏安全性的良性数据

    What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety

    [https://arxiv.org/abs/2404.01099](https://arxiv.org/abs/2404.01099)

    通过双向锚定方法，识别那些在微调后更可能降低模型安全性的良性数据子集，提高模型对有害请求的响应率。

    

    当前的大型语言模型（LLMs），即使经过调整以确保安全性和对齐性，也容易被越狱。一些研究表明，只是进一步使用良性数据（即没有有害内容的数据）对一个对齐模型进行微调，会导致安全性大幅下降。我们深入探讨良性微调不经意间导致越狱的数据中心方面。首先，我们通过两种视角表征微调数据：表示和梯度空间。此外，我们提出了一种双向锚定方法，该方法优先考虑靠近有害示例并远离良性示例的数据点。通过这样做，我们的方法有效地识别出更有可能在微调后降低模型安全性的良性数据子集。仅仅训练100个这些看似良性的数据点，就可以使微调模型肯定地回应超过70％的被测试的有害请求，相比之下，...

    arXiv:2404.01099v1 Announce Type: cross  Abstract: Current Large Language Models (LLMs), even those tuned for safety and alignment, are susceptible to jailbreaking. Some have found that just further fine-tuning an aligned model with benign data (i.e., data without harmful content) surprisingly leads to substantial degradation in safety. We delve into the data-centric aspects of why benign fine-tuning inadvertently contributes to jailbreaking. First, we represent fine-tuning data through two lenses: representation and gradient spaces. Furthermore, we propose a bi-directional anchoring method that prioritizes data points that are close to harmful examples and distant from benign ones. By doing so, our approach effectively identifies subsets of benign data that are more likely to degrade the model's safety after fine-tuning. Training on just 100 of these seemingly benign datapoints can lead to the fine-tuned model affirmatively responding to > 70% of tested harmful requests, compared to <
    
[^2]: 无参考摘要的信息论精炼

    Information-Theoretic Distillation for Reference-less Summarization

    [https://arxiv.org/abs/2403.13780](https://arxiv.org/abs/2403.13780)

    提出了一种名为InfoSumm的框架，通过信息论目标实现了无参考摘要的精炼生成器

    

    当前自动摘要的主要方法是使用专有的大规模语言模型（LLMs）如ChatGPT，或者从它们作为教师模型进行模仿学习。本文提出了一种名为InfoSumm的新型框架，通过信息论目标进行精炼强大的摘要生成器，而不依赖于LLM的能力或人工编写的参考文献。

    arXiv:2403.13780v1 Announce Type: new  Abstract: The current winning recipe for automatic summarization is using proprietary large-scale language models (LLMs) such as ChatGPT as is, or imitation learning from them as teacher models. While increasingly ubiquitous dependence on such large-scale language models is convenient, there remains an important question of whether small-scale models could have achieved competitive results, if we were to seek an alternative learning method -- that allows for a more cost-efficient, controllable, yet powerful summarizer. We present InfoSumm, a novel framework to distill a powerful summarizer based on the information-theoretic objective for summarization, without relying on either the LLM's capability or human-written references. To achieve this, we first propose a novel formulation of the desiderata of summarization (saliency, faithfulness and brevity) through the lens of mutual information between the original document and the summary. Based on thi
    
[^3]: 利用视觉模拟量表对重复测量的响应风格进行表征

    Response Style Characterization for Repeated Measures Using the Visual Analogue Scale

    [https://arxiv.org/abs/2403.10136](https://arxiv.org/abs/2403.10136)

    本研究针对重复测量的视觉模拟量表数据开发了一种新颖的响应风格（RP）表征方法，以解决在VAS中处理RP的困难。

    

    自我报告测量（例如，利克特量表）被广泛用于评估主观健康感知。最近，由于其能够精确且便于评估人们感受的能力，视觉模拟量表（VAS），一种滑动条量表，变得流行起来。这些数据可能会受到响应风格（RS）的影响，RS是一种用户依赖的系统性倾向，无论问卷说明如何都会发生。尽管在个体间分析中尤为重要，但对VAS中RS（表示为响应剖面（RP））的处理并未受到足够关注，因为它主要用于个体内监测且不太受RP的影响。然而，VAS测量通常需要对同一问卷项目进行重复自我报告，这使得难以在利克特量表上应用传统方法。在这项研究中，我们开发了一种新颖的RP表征方法，适用于各种类型的重复测量的VAS数据。

    arXiv:2403.10136v1 Announce Type: cross  Abstract: Self-report measures (e.g., Likert scales) are widely used to evaluate subjective health perceptions. Recently, the visual analog scale (VAS), a slider-based scale, has become popular owing to its ability to precisely and easily assess how people feel. These data can be influenced by the response style (RS), a user-dependent systematic tendency that occurs regardless of questionnaire instructions. Despite its importance, especially in between-individual analysis, little attention has been paid to handling the RS in the VAS (denoted as response profile (RP)), as it is mainly used for within-individual monitoring and is less affected by RP. However, VAS measurements often require repeated self-reports of the same questionnaire items, making it difficult to apply conventional methods on a Likert scale. In this study, we developed a novel RP characterization method for various types of repeatedly measured VAS data. This approach involves t
    
[^4]: 成本敏感学习在考虑工作量约束下推迟多位专家决策

    Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints

    [https://arxiv.org/abs/2403.06906](https://arxiv.org/abs/2403.06906)

    提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题

    

    学习推迟（L2D）旨在通过学习如何在人工智能协作系统中将决策推迟给人类，从而在人类更有可能正确时推迟决策。现有L2D研究忽视了阻碍其实际采用的真实系统的关键方面，即：忽视成本敏感场景，其中第1类和第2类错误的成本不同；要求每个训练数据集实例的并发人类预测；不处理人类工作能力约束。为了解决这些问题，我们提出了成本和工作量约束下的推迟框架（DeCCaF）。DeCCaF是一种新颖的L2D方法，采用监督学习来建模人类错误的概率，减少数据要求的限制，并使用约束编程来全局最小化错误成本，同时考虑工作量限制。我们在一个系列中测试了DeCCaF

    arXiv:2403.06906v1 Announce Type: cross  Abstract: Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key aspects of real-world systems that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type 1 and type 2 errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset and iii) not dealing with human work capacity constraints. To address these issues, we propose the deferral under cost and capacity constraints framework (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost subject to workload limitations. We test DeCCaF in a series 
    
[^5]: PrimeComposer：用于图像合成的快速逐步组合扩散方法和带有注意力引导的技术

    PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering

    [https://arxiv.org/abs/2403.05053](https://arxiv.org/abs/2403.05053)

    本文提出了PrimeComposer，一种更快的逐步组合扩散方式，用于图像合成，主要专注于前景生成，从而解决了合成中的凝聚混乱和外观信息丢失问题，并避免了不必要的背景生成导致的前景生成质量下降。

    

    图像合成涉及将给定对象无缝地整合到特定的视觉环境中。目前无需训练的方法依赖于从几个采样器中组合注意力权重来引导生成器。然而，由于这些权重来自不同的上下文，它们的组合导致在合成中凝聚混乱和外观信息的丢失。在该任务中，它们过多关注背景生成，即使在这项任务中是不必要的，这些问题恶化。这不仅减慢了推理速度，还损害了前景生成质量。此外，这些方法还在过渡区域引入了不需要的伪影。在本文中，我们将图像合成形式化为一项基于主题的局部编辑任务，仅专注于前景生成。在每一步中，编辑后的前景与噪声背景相结合，以保持场景一致性。为了解决剩下的问题，我们提出了PrimeComposer，一种更快的tr

    arXiv:2403.05053v1 Announce Type: cross  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. The current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion in synthesis and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only slows down inference but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tr
    
[^6]: MOKA：基于标记的视觉提示实现开放词汇的机器人操作

    MOKA: Open-Vocabulary Robotic Manipulation through Mark-Based Visual Prompting

    [https://arxiv.org/abs/2403.03174](https://arxiv.org/abs/2403.03174)

    MOKA方法利用视觉语言模型解决机器人操作任务，实现了开放词汇的机器人操作。

    

    开放词汇的泛化要求机器人系统执行涉及复杂和多样化环境以及任务目标的任务。本文提出了一种名为MOKA（Marking Open-vocabulary Keypoint Affordances）的方法，利用视觉语言模型（VLMs）来解决由自由形式语言描述指定的机器人操作任务。

    arXiv:2403.03174v1 Announce Type: cross  Abstract: Open-vocabulary generalization requires robotic systems to perform tasks involving complex and diverse environments and task goals. While the recent advances in vision language models (VLMs) present unprecedented opportunities to solve unseen problems, how to utilize their emergent capabilities to control robots in the physical world remains an open question. In this paper, we present MOKA (Marking Open-vocabulary Keypoint Affordances), an approach that employs VLMs to solve robotic manipulation tasks specified by free-form language descriptions. At the heart of our approach is a compact point-based representation of affordance and motion that bridges the VLM's predictions on RGB images and the robot's motions in the physical world. By prompting a VLM pre-trained on Internet-scale data, our approach predicts the affordances and generates the corresponding motions by leveraging the concept understanding and commonsense knowledge from br
    
[^7]: SoftTiger: 用于医疗工作流的临床基础模型

    SoftTiger: A Clinical Foundation Model for Healthcare Workflows

    [https://arxiv.org/abs/2403.00868](https://arxiv.org/abs/2403.00868)

    SoftTiger是一个专为医疗工作流设计的临床大型语言模型，通过处理临床笔记的结构化，实现了基本临床任务以及更复杂的下游临床任务的执行。

    

    我们发布并介绍了SoftTiger，一个专为医疗保健工作流设计的临床大型语言模型（CLaM）作为基础模型。临床笔记的叙述性和非结构化特性是医疗智能化的主要障碍。我们致力于按照国际互操作性标准将临床笔记结构化为临床数据，涉及国际患者摘要、临床印象和医疗接触三个关键子任务的数据收集和标注。然后，我们使用公开和验证的临床数据对最先进的LLM进行监督微调。训练过程中，目标模型首先能够支持基本的临床任务，如缩写扩展和时间信息提取，然后学习执行更复杂的下游临床任务，如印象和接触摘要。此外，我们解决了医疗模型中的一些建模挑战。

    arXiv:2403.00868v1 Announce Type: cross  Abstract: We release and introduce SoftTiger, a clinical large language model (CLaM) designed as a foundation model for healthcare workflows. The narrative and unstructured nature of clinical notes is a major obstacle for healthcare intelligentization. We address a critical problem of structuring clinical notes into clinical data, according to international interoperability standards. We collect and annotate data for three critical subtasks, namely, international patient summary, clinical impression and medical encounter. We then supervised fine-tuned a state-of-the-art LLM using public and credentialed clinical data. The training is orchestrated in a way that the target model can first support basic clinical tasks such as abbreviation expansion and temporal information extraction, and then learn to perform more complex downstream clinical tasks such as impression and encounter summary. Moreover, we address, several modeling challenges in the he
    
[^8]: 从状态轨迹中学习规划行动模型

    Learning Planning Action Models from State Traces

    [https://arxiv.org/abs/2402.10726](https://arxiv.org/abs/2402.10726)

    该论文探讨了一种从状态轨迹中学习规划行动模型的方法，尤其关注在参数未提供的情况下进行学习，并提出了两种不同级别的跟踪质量以及相应的算法。

    

    先前从状态轨迹中学习STRIPS领域模型的方法通常从要学习的行动的名称和参数开始。因此，它们的唯一任务是推断给定行动的前提条件和效应。在这项工作中，我们探讨了在学习时未提供学习行动的参数的情况。我们根据提供的信息定义了两个级别的跟踪质量，并提出了相应的算法。在一个级别(L1)中，轨迹中的状态被标记为行动名称，因此我们可以推断出行动的数量和名称，但我们仍需要弄清参数的数量和类型。在另一个级别(L2)中，状态还额外标记有构成相应基于对象的行动的参数。在这里，我们仍然需要推断学习行动中参数的类型。我们对所提出的算法进行了实验评估，并将其与其他方法进行了比较。

    arXiv:2402.10726v1 Announce Type: new  Abstract: Previous STRIPS domain model acquisition approaches that learn from state traces start with the names and parameters of the actions to be learned. Therefore their only task is to deduce the preconditions and effects of the given actions. In this work, we explore learning in situations when the parameters of learned actions are not provided. We define two levels of trace quality based on which information is provided and present an algorithm for each. In one level (L1), the states in the traces are labeled with action names, so we can deduce the number and names of the actions, but we still need to work out the number and types of parameters. In the other level (L2), the states are additionally labeled with objects that constitute the parameters of the corresponding grounded actions. Here we still need to deduce the types of the parameters in the learned actions. We experimentally evaluate the proposed algorithms and compare them with the
    
[^9]: 云厨房：使用基于规划的复合AI优化食品配送流程

    Cloud Kitchen: Using Planning-based Composite AI to Optimize Food Delivery Process

    [https://arxiv.org/abs/2402.10725](https://arxiv.org/abs/2402.10725)

    Cloud Kitchen平台利用基于规划的复合AI优化食品配送流程，通过车辆路径问题和真实历史数据集降低延迟配送量，提高顾客满意度。

    

    全球食品配送市场为基于人工智能的服务提供了许多机会，可以提高全球供餐效率。本文介绍了Cloud Kitchen平台，作为一个决策工具，用于帮助具有食品配送服务的餐厅，并提供一个模拟器来评估决策的影响。该平台由一个Technology-Specific Bridge（TSB）组成，用于与餐厅或模拟器进行通信。TSB使用PDDL模型表示嵌入在Unified Planning Framework（UPF）中的决策。决策涉及将顾客订单分配到车辆以及决定以什么顺序为顾客提供服务（对于每辆车），这是通过具有时间窗口的车辆路径问题（VRPTW）来完成的，这个问题的解决是高效的。我们展示了我们平台制定的决策可以通过使用真实历史数据集减少延迟配送量来提高顾客满意度。

    arXiv:2402.10725v1 Announce Type: new  Abstract: The global food delivery market provides many opportunities for AI-based services that can improve the efficiency of feeding the world. This paper presents the Cloud Kitchen platform as a decision-making tool for restaurants with food delivery and a simulator to evaluate the impact of the decisions. The platform consists of a Technology-Specific Bridge (TSB) that provides an interface for communicating with restaurants or the simulator. TSB uses a PDDL model to represent decisions embedded in the Unified Planning Framework (UPF). Decision-making, which concerns allocating customers' orders to vehicles and deciding in which order the customers will be served (for each vehicle), is done via a Vehicle Routing Problem with Time Windows (VRPTW), an efficient tool for this problem. We show that decisions made by our platform can improve customer satisfaction by reducing the number of delayed deliveries using a real-world historical dataset.
    
[^10]: 消除否定导致的强幻觉

    Strong hallucinations from negation and how to fix them

    [https://arxiv.org/abs/2402.10543](https://arxiv.org/abs/2402.10543)

    论文针对语言模型在推理中造成的强幻觉问题，提出了一种处理否定的新方法，可以改善模型性能而无需使用稀疏负数据训练。

    

    尽管语言模型（LMs）在许多任务上表现出色，但仍然在推理方面存在困难，有时会提供由于逻辑不连贯而不可能成立的响应。我们称这种响应为\textit{强幻觉}，并证明它们源于LM计算其内部表示的逻辑运算符和从这些表示中产生的输出。重点关注否定，我们提供了一种新颖的解决方案，其中否定不是作为潜在表示的另一个元素，而是作为\textit{LM潜在表示上的一个操作，约束它们可能的演变方式}。我们展示了我们的方法改善了在带否定的填空提示和自然语言推理任务中的模型性能，而无需对稀疏负数据进行训练。

    arXiv:2402.10543v1 Announce Type: cross  Abstract: Despite great performance on many tasks, language models (LMs) still struggle with reasoning, sometimes providing responses that cannot possibly be true because they stem from logical incoherence. We call such responses \textit{strong hallucinations} and prove that they follow from an LM's computation of its internal representations for logical operators and outputs from those representations. Focusing on negation, we provide a novel solution in which negation is treated not as another element of a latent representation, but as \textit{an operation over an LM's latent representations that constrains how they may evolve}. We show that our approach improves model performance in cloze prompting and natural language inference tasks with negation without requiring training on sparse negative data.
    
[^11]: 非自回归的生成模型用于排序推荐

    Non-autoregressive Generative Models for Reranking Recommendation

    [https://arxiv.org/abs/2402.06871](https://arxiv.org/abs/2402.06871)

    本研究提出了一个非自回归的生成模型用于排序推荐，在多阶段推荐系统中扮演关键角色。该模型旨在提高效率和效果，并解决稀疏训练样本和动态候选项对模型收敛性的挑战。

    

    在多阶段推荐系统中，重新排序通过建模项目之间的内部相关性起到了至关重要的作用。重新排序的关键挑战在于在排列的组合空间中探索最佳序列。最近的研究提出了生成器-评估器学习范式，生成器生成多个可行序列，评估器基于估计的列表得分选择最佳序列。生成器至关重要，而生成模型非常适合生成器函数。当前的生成模型采用自回归策略进行序列生成。然而，在实时工业系统中部署自回归模型是具有挑战性的。因此，我们提出了一个非自回归生成模型用于排序推荐（NAR4Rec），以提高效率和效果。为了解决与稀疏训练样本和动态候选项对模型收敛性的挑战，我们引入了一个m

    In a multi-stage recommendation system, reranking plays a crucial role by modeling the intra-list correlations among items.The key challenge of reranking lies in the exploration of optimal sequences within the combinatorial space of permutations. Recent research proposes a generator-evaluator learning paradigm, where the generator generates multiple feasible sequences and the evaluator picks out the best sequence based on the estimated listwise score. Generator is of vital importance, and generative models are well-suited for the generator function. Current generative models employ an autoregressive strategy for sequence generation. However, deploying autoregressive models in real-time industrial systems is challenging. Hence, we propose a Non-AutoRegressive generative model for reranking Recommendation (NAR4Rec) designed to enhance efficiency and effectiveness. To address challenges related to sparse training samples and dynamic candidates impacting model convergence, we introduce a m
    
[^12]: PsySafe：基于心理学的多智能体系统安全攻击、防御和评估的综合框架

    PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety

    [https://arxiv.org/abs/2401.11880](https://arxiv.org/abs/2401.11880)

    PsySafe提出了一个综合框架，通过深入探讨智能体心理学，揭示智能体的黑暗心理状态对安全构成威胁，并提出了有效的风险缓解策略。

    

    多智能体系统在加入大型语言模型（LLMs）后，展现出了集体智能的深远能力。然而，这种智能被恶意使用可能带来重大风险。迄今为止，关于多智能体系统安全问题的全面研究仍然有限。本文通过创新的视角探索了这些问题，发现智能体的黑暗心理状态构成了对安全的重大威胁。为了解决这些问题，我们提出了一个以智能体心理学为基础的综合框架（PsySafe），关注三个关键领域：首先，识别智能体中的黑暗人格特征如何导致风险行为；其次，从心理和行为角度评估多智能体系统的安全性；第三，制定有效的策略来减轻这些风险。我们的实验揭示

    arXiv:2401.11880v2 Announce Type: replace-cross  Abstract: Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit profound capabilities in collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with multi-agent systems remains limited. In this paper, we explore these concerns through the innovative lens of agent psychology, revealing that the dark psychological states of agents constitute a significant threat to safety. To tackle these concerns, we propose a comprehensive framework (PsySafe) grounded in agent psychology, focusing on three key areas: firstly, identifying how dark personality traits in agents can lead to risky behaviors; secondly, evaluating the safety of multi-agent systems from the psychological and behavioral perspectives, and thirdly, devising effective strategies to mitigate these risks. Our experiments reveal
    
[^13]: CodePrompt：通过Prompt学习的知识特征改进源代码相关分类

    CodePrompt: Improving Source Code-Related Classification with Knowledge Features through Prompt Learning. (arXiv:2401.05544v1 [cs.CL])

    [http://arxiv.org/abs/2401.05544](http://arxiv.org/abs/2401.05544)

    CodePrompt是一种利用Prompt学习和注意机制技术改进源代码相关分类任务的新方法。它能够提取源代码和相关文本中的丰富知识以提高准确性，并且减少了计算成本。

    

    研究人员已经探索利用预训练语言模型（如CodeBERT）改进源代码相关任务的潜力。先前的研究主要依赖CodeBERT的文本嵌入能力和"[CLS]"句子嵌入信息作为下游源代码相关任务的语义表示进行微调。然而，这些方法需要额外的神经网络层来提取有效特征，导致计算成本更高。此外，现有方法没有利用源代码和相关文本中丰富的知识，可能导致准确性降低。本文提出了一种新的方法CodePrompt，通过Prompt学习和注意机制利用预训练模型中的丰富知识来改进源代码相关分类任务。

    Researchers have explored the potential of utilizing pre-trained language models, such as CodeBERT, to improve source code-related tasks. Previous studies have mainly relied on CodeBERT's text embedding capability and the `[CLS]' sentence embedding information as semantic representations for fine-tuning downstream source code-related tasks. However, these methods require additional neural network layers to extract effective features, resulting in higher computational costs. Furthermore, existing approaches have not leveraged the rich knowledge contained in both source code and related text, which can lead to lower accuracy. This paper presents a novel approach, CodePrompt, which utilizes rich knowledge recalled from a pre-trained model by prompt learning and an attention mechanism to improve source code-related classification tasks. Our approach initially motivates the language model with prompt information to retrieve abundant knowledge associated with the input as representative feat
    
[^14]: Malla: 揭秘现实世界中大规模语言模型整合恶意服务

    Malla: Demystifying Real-world Large Language Model Integrated Malicious Services. (arXiv:2401.03315v1 [cs.CR])

    [http://arxiv.org/abs/2401.03315](http://arxiv.org/abs/2401.03315)

    本研究对212个真实的恶意服务（Malla）进行了系统研究，揭示了它们在地下市场的扩散和对公共LLM服务的影响，以及其使用的策略和技术。

    

    大规模语言模型（LLMs）的地下利用，也称为Malla，正在增加，加剧了网络安全威胁，并对LLMs技术的可信度提出了疑问。然而，迄今为止，很少有工作努力去了解这种新型网络犯罪的规模、影响和技术。本文是第一次对212个真实的Malla进行系统研究，揭示了它们在地下市场的扩散，并揭示了它们的操作模式。我们的研究揭开了Malla生态系统，揭示了其显著的增长对当今公共LLM服务的影响。通过对212个Mallas进行研究，我们发现了8个后端LLMs，以及182个绕过公共LLM API保护措施的提示。我们进一步揭示了Mallas使用的策略，包括滥用未经审查的LLMs和通过越狱提示利用公共LLM API。我们的发现有助于更好地理解Malla犯罪行为的实质。

    The underground exploitation of large language models (LLMs) for malicious services (i.e., Malla) is witnessing an uptick, amplifying the cyber threat landscape and posing questions about the trustworthiness of LLM technologies. However, there has been little effort to understand this new cybercrime, in terms of its magnitude, impact, and techniques. In this paper, we conduct the first systematic study on 212 real-world Mallas, uncovering their proliferation in underground marketplaces and exposing their operational modalities. Our study discloses the Malla ecosystem, revealing its significant growth and impact on today's public LLM services. Through examining 212 Mallas, we uncovered eight backend LLMs used by Mallas, along with 182 prompts that circumvent the protective measures of public LLM APIs. We further demystify the tactics employed by Mallas, including the abuse of uncensored LLMs and the exploitation of public LLM APIs through jailbreak prompts. Our findings enable a better 
    
[^15]: PromptBench：一个用于评估大型语言模型的统一库

    PromptBench: A Unified Library for Evaluation of Large Language Models. (arXiv:2312.07910v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.07910](http://arxiv.org/abs/2312.07910)

    PromptBench是一个用于评估大型语言模型的统一库，包括了提示语构建、提示语工程、数据集和模型加载、对抗性提示攻击、动态评估协议和分析工具等组件，旨在促进原创研究和创建新的基准测试、部署下游应用以及设计新的评估协议。

    

    对大型语言模型（LLMs）的评估对于评估其性能和减轻潜在的安全风险至关重要。本文介绍了PromptBench，一个用于评估LLMs的统一库。它由几个关键组件组成，研究人员可以轻松使用和扩展：提示语构建、提示语工程、数据集和模型加载、对抗性提示攻击、动态评估协议和分析工具。PromptBench旨在成为一个开放、通用和灵活的代码库，以促进原创研究，创建新的基准测试、部署下游应用和设计新的评估协议。代码可在https://github.com/microsoft/promptbench上找到，并将持续支持。

    The evaluation of large language models (LLMs) is crucial to assess their performance and mitigate potential security risks. In this paper, we introduce PromptBench, a unified library to evaluate LLMs. It consists of several key components that are easily used and extended by researchers: prompt construction, prompt engineering, dataset and model loading, adversarial prompt attack, dynamic evaluation protocols, and analysis tools. PromptBench is designed to be an open, general, and flexible codebase for research purposes that can facilitate original study in creating new benchmarks, deploying downstream applications, and designing new evaluation protocols. The code is available at: https://github.com/microsoft/promptbench and will be continuously supported.
    
[^16]: 最小修改马尔可夫博弈以实现任意Nash均衡和价值

    Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value. (arXiv:2311.00582v1 [cs.GT])

    [http://arxiv.org/abs/2311.00582](http://arxiv.org/abs/2311.00582)

    该论文研究了游戏修改问题，提出了一种最小修改马尔可夫博弈的方法，使得目标策略配置成为唯一的Nash均衡并具有特定价值范围，同时最小化修改成本。

    

    我们研究了游戏修改问题，其中一位善意的游戏设计者或恶意的对手修改了一个零和马尔可夫博弈的奖励函数，以便一个目标确定性或随机的策略配置成为唯一的马尔可夫完美Nash均衡，并且在目标范围内具有价值，以最小化修改成本。我们表征了能够安装为某个游戏的唯一均衡的策略配置的集合，并建立了成功安装的充分和必要条件。我们提出了一种高效的算法，该算法通过解一个带有线性约束的凸优化问题，然后进行随机扰动，来获得一个成本近乎最优的修改计划。

    We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of some game, and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm, which solves a convex optimization problem with linear constraints and then performs random perturbation, to obtain a modification plan with a near-optimal cost.
    
[^17]: 学习者使用LLM时指导和交互策略对学习者的表现和感知的影响

    Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception. (arXiv:2310.13712v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2310.13712](http://arxiv.org/abs/2310.13712)

    本研究探索了四种教学指导策略对学习者在使用LLM时的表现和感知效果，发现直接LLM答案提高了表现，而改进学生解决方案则增加了对LLM的信任度。同时，结构化指导也减少了随机查询和学生复制粘贴问题的现象。

    

    面对不断增长的教室规模和教师资源有限的问题，个性化的基于聊天机器人的教学助手可以发挥关键作用。大型语言模型（LLMs）提供了有希望的途径，越来越多的研究探索它们在教育中的实用性。然而，挑战不仅在于确定LLMs的有效性，而且在于识别学习者与这些模型之间的互动细微差别，这会影响学习者的参与和成果。我们在一个本科计算机科学课堂（N=145）和Prolific上进行了一项形成性研究（N=356），以探索四种教学指导策略对学习者在LLMs上的表现、自信心和信任度的影响。直接的LLM答案稍微提高了表现，而改进学生的解决方案增加了信任度。结构化指导减少了随机查询和学生将作业问题复制粘贴给LLM的情况。我们的工作凸显了t

    Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role t
    
[^18]: 一个赋予因果分析能力的增强学习智能代理框架：增强自动加密货币交易

    A Framework for Empowering Reinforcement Learning Agents with Causal Analysis: Enhancing Automated Cryptocurrency Trading. (arXiv:2310.09462v1 [cs.AI])

    [http://arxiv.org/abs/2310.09462](http://arxiv.org/abs/2310.09462)

    本研究提出了一个基于强化学习的自动交易系统框架CausalReinforceNet，通过因果分析增强了强化学习代理的能力，以提高对加密货币市场的交易能力。

    

    尽管人工智能增强交易方法取得了一定进展，但在快速发展的加密货币市场中开发盈利的自动交易系统仍然具有挑战性。本研究旨在通过开发基于强化学习的自动交易系统来解决这些挑战，针对五种热门的替代加密货币（即比特币以外的加密货币）：币安币、以太坊、莱特币、瑞波币和泰达币。为此，我们提出了CausalReinforceNet，一个被构建为决策支持系统的框架。作为交易系统的基础架构，CausalReinforceNet框架通过因果分析增强了强化学习代理的能力。在该框架内，我们在特征工程过程中使用贝叶斯网络来识别影响加密货币价格变动的具有因果关系的最相关特征。此外，我们还通过动态贝叶斯网络将概率性价格方向信号纳入框架中，以增强交易系统的功能。

    Despite advances in artificial intelligence-enhanced trading methods, developing a profitable automated trading system remains challenging in the rapidly evolving cryptocurrency market. This study aims to address these challenges by developing a reinforcement learning-based automated trading system for five popular altcoins~(cryptocurrencies other than Bitcoin): Binance Coin, Ethereum, Litecoin, Ripple, and Tether. To this end, we present CausalReinforceNet, a framework framed as a decision support system. Designed as the foundational architecture of the trading system, the CausalReinforceNet framework enhances the capabilities of the reinforcement learning agent through causal analysis. Within this framework, we use Bayesian networks in the feature engineering process to identify the most relevant features with causal relationships that influence cryptocurrency price movements. Additionally, we incorporate probabilistic price direction signals from dynamic Bayesian networks to enhance
    
[^19]: 无需插值的建模不规则采样时间序列

    Modelling Irregularly Sampled Time Series Without Imputation. (arXiv:2309.08698v1 [cs.AI])

    [http://arxiv.org/abs/2309.08698](http://arxiv.org/abs/2309.08698)

    SLAN是一种无需插值的方法，可以建模不规则采样时间序列，利用动态适应的LSTM架构来捕捉每个传感器的局部摘要，并在整个观测期间维持一个全局摘要状态。

    

    模拟不规则采样时间序列（ISTS）是具有挑战性的，因为存在缺失值。大多数现有方法通过将不规则采样数据转换为规则采样数据来处理ISTS，但这些模型假设存在潜在的缺失机制，导致了不希望的偏差和次优性能。我们提出了SLAN（Switch LSTM Aggregate Network），该方法利用一组LSTM对ISTS进行建模，而无需插值，消除了任何潜在过程的假设。它根据测量传感器动态自适应地调整其架构。SLAN利用不规则性信息明确捕捉每个传感器的局部摘要，并在整个观测期间维持一个全局摘要状态。我们在公开可用的数据集上展示了SLAN的有效性，包括MIMIC-III、Physionet 2012和Physionet 2019。代码可在https://github.com/Rohit102497/SLAN找到。

    Modelling irregularly-sampled time series (ISTS) is challenging because of missing values. Most existing methods focus on handling ISTS by converting irregularly sampled data into regularly sampled data via imputation. These models assume an underlying missing mechanism leading to unwanted bias and sub-optimal performance. We present SLAN (Switch LSTM Aggregate Network), which utilizes a pack of LSTMs to model ISTS without imputation, eliminating the assumption of any underlying process. It dynamically adapts its architecture on the fly based on the measured sensors. SLAN exploits the irregularity information to capture each sensor's local summary explicitly and maintains a global summary state throughout the observational period. We demonstrate the efficacy of SLAN on publicly available datasets, namely, MIMIC-III, Physionet 2012 and Physionet 2019. The code is available at https://github.com/Rohit102497/SLAN.
    
[^20]: 高效的量化感知训练与自适应核心集选择

    Efficient Quantization-aware Training with Adaptive Coreset Selection. (arXiv:2306.07215v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.07215](http://arxiv.org/abs/2306.07215)

    本研究提出了一种用于改善量化感知训练的训练效率的方法，通过核心集选择和两个重要性指标来选择训练数据的子集。

    

    深度神经网络（DNN）的模型大小和计算量的增加，增加了对有效模型部署方法的需求。量化感知训练（QAT）是一种代表性的模型压缩方法，可以利用权重和激活中的冗余信息。然而，大多数现有的QAT方法需要在整个数据集上进行端到端训练，这会导致长时间的训练和高能耗。核心集选择是利用训练数据的冗余性提高数据效率的方法，在高效训练中被广泛应用。在这项工作中，我们提出了一种新的角度，通过核心集选择来提高量化感知训练的训练效率。基于QAT的特性，我们提出了两个指标：误差向量分数和不一致分数，用于量化训练过程中每个样本的重要性。基于这两个重要性指标，我们提出了一种量化感知的自适应核心集选择（ACS）方法，用于选择训练数据的子集。

    The expanding model size and computation of deep neural networks (DNNs) have increased the demand for efficient model deployment methods. Quantization-aware training (QAT) is a representative model compression method to leverage redundancy in weights and activations. However, most existing QAT methods require end-to-end training on the entire dataset, which suffers from long training time and high energy costs. Coreset selection, aiming to improve data efficiency utilizing the redundancy of training data, has also been widely used for efficient training. In this work, we propose a new angle through the coreset selection to improve the training efficiency of quantization-aware training. Based on the characteristics of QAT, we propose two metrics: error vector score and disagreement score, to quantify the importance of each sample during training. Guided by these two metrics of importance, we proposed a quantization-aware adaptive coreset selection (ACS) method to select the data for the
    
[^21]: NeuralMatrix: 将整个神经网络移动到通用矩阵乘法以实现高效推理

    NeuralMatrix: Moving Entire Neural Networks to General Matrix Multiplication for Efficient Inference. (arXiv:2305.14405v1 [cs.LG])

    [http://arxiv.org/abs/2305.14405](http://arxiv.org/abs/2305.14405)

    NeuralMatrix是一种框架，能够在单个通用矩阵乘法加速器上计算深度神经网络(DNNs)，并可在保持推理准确度的情况下实现高达113倍至19.44倍的性能提升。

    

    本研究介绍了一种名为NeuralMatrix的新型框架，它使得可以在单个通用矩阵乘法（GEMM）加速器上计算多功能的深度神经网络（DNNs）。该方法克服了基于ASIC的加速器的专用性限制，同时实现了与CPU和GPU等通用处理器相比的应用特定加速水平。我们解决了将DNN计算中的线性和非线性运算映射到通用矩阵乘法以及使用GEMM加速器对DNN推理准确性的影响的挑战。我们在来自三种流行类别的各种DNN模型上进行了大量实验（即CNN，Transformers和GNN）作为示例的支撑模型。我们的结果表明，将DNN转换为通用矩阵乘法后仅会出现高达2.02％的准确度损失，同时将吞吐量与功率的比值与CPU和GPU相比提高了113倍到19.44倍。

    In this study, we introduce NeuralMatrix, a novel framework that enables the computation of versatile deep neural networks (DNNs) on a single general matrix multiplication (GEMM) accelerator. The proposed approach overcomes the specificity limitations of ASIC-based accelerators while achieving application-specific acceleration levels compared to general-purpose processors such as CPUs and GPUs. We address the challenges of mapping both linear and nonlinear operations in DNN computation to general matrix multiplications and the impact of using a GEMM accelerator on DNN inference accuracy. Extensive experiments are conducted on various DNN models from three popular categories (i.e., CNN, Transformers, and GNN) as illustrative backbone models. Our results demonstrate that DNNs suffer only up to a 2.02% accuracy loss after being converted to general matrix multiplication, while achieving 113x to 19.44x improvements in throughput per power compared to CPUs and GPUs.
    
[^22]: 因果推理与大型语言模型：开启因果研究的新篇章

    Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])

    [http://arxiv.org/abs/2305.00050](http://arxiv.org/abs/2305.00050)

    大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。

    

    大型语言模型的因果能力备受争议，并且对将其应用于医学、科学、法律和政策等具有社会影响力的领域具有重要意义。我们进一步探讨了LLMs及其因果推理的区别，以及潜在的建构和测量效度威胁。基于GPT-3.5和4的算法在多个因果基准测试上取得了新的最高准确率。与此同时，LLMs展示了难以预测的失败模式，我们提供了一些技术来解释它们的鲁棒性。

    The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
    
[^23]: 表示很重要：棋盘游戏对视觉Transformer提出了挑战

    Representation Matters: The Game of Chess Poses a Challenge to Vision Transformers. (arXiv:2304.14918v1 [cs.AI])

    [http://arxiv.org/abs/2304.14918](http://arxiv.org/abs/2304.14918)

    这篇论文通过改变输入表示和价值损失，使棋盘游戏性能获得了高达180 Elo点的增强

    

    虽然Transformer已经成为了“AI的瑞士军刀”，但没有人挑战它们去掌握象棋这个经典的AI基准。但仅仅使用视觉Transformer（ViT）在AlphaZero中无法掌握象棋，主要是因为ViT太慢了。即使使用MobileNet和NextViT的组合使它们更有效，也无法击败实际上更重要的东西：简单改变输入表示和价值损失，从而获得高达180 Elo点的增强。

    While transformers have gained the reputation as the "Swiss army knife of AI", no one has challenged them to master the game of chess, one of the classical AI benchmarks. Simply using vision transformers (ViTs) within AlphaZero does not master the game of chess, mainly because ViTs are too slow. Even making them more efficient using a combination of MobileNet and NextViT does not beat what actually matters: a simple change of the input representation and value loss, resulting in a greater boost of up to 180 Elo points over AlphaZero.
    
[^24]: REDf：基于长短期记忆网络的智能电网可再生能源需求预测模型

    REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network. (arXiv:2304.03997v1 [cs.LG])

    [http://arxiv.org/abs/2304.03997](http://arxiv.org/abs/2304.03997)

    本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。

    

    随着世界向更可持续的能源未来发展，将可再生能源源纳入电网的集成变得越来越重要。然而，可再生能源的间歇性使电网管理和确保稳定的电力供应变得具有挑战性。本文提出了一种基于深度学习的方法来预测智能电网中的能量需求，可以通过提供准确的能量需求预测来改善可再生能源的集成。我们使用长短期记忆网络来捕捉能럟需求数据中的复杂模式和依赖关系，这些网络特别适用于时间序列数据。所提出的方法使用了四个历史能量需求数据集，这些数据集来自不同的能源分配公司，包括美国电力、Commonwealth Edison、Dayton Power and Light以及宾夕法尼亚-新泽西-马里兰互联网。该方法还将REDf模型与其他两个深度学习模型和基准模型进行比较。实验结果表明，我们提出的REDf模型在平均绝对误差、均方根误差和决定系数等准确度指标方面优于其他模型。因此，REDf可以作为可再生能源需求预测的可靠工具，并提高可再生能源纳入智能电网的能力。

    The integration of renewable energy sources into the power grid is becoming increasingly important as the world moves towards a more sustainable energy future. However, the intermittent nature of renewable energy sources can make it challenging to manage the power grid and ensure a stable supply of electricity. In this paper, we propose a deep learning-based approach for predicting energy demand in a smart power grid, which can improve the integration of renewable energy sources by providing accurate predictions of energy demand. We use long short-term memory networks, which are well-suited for time series data, to capture complex patterns and dependencies in energy demand data. The proposed approach is evaluated using four datasets of historical energy demand data from different energy distribution companies including American Electric Power, Commonwealth Edison, Dayton Power and Light, and Pennsylvania-New Jersey-Maryland Interconnection. The proposed model is also compared with two 
    

