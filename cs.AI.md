# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generating Visual Stimuli from EEG Recordings using Transformer-encoder based EEG encoder and GAN](https://arxiv.org/abs/2402.10115) | 本研究使用基于Transformer编码器的EEG编码器和GAN网络，通过合成图像从EEG信号中恢复出各种对象类别的图像，同时结合对抗损失和感知损失，提高生成图像的质量。 |
| [^2] | [Operator learning without the adjoint](https://arxiv.org/abs/2401.17739) | 本论文提出了一种不需要探测伴随算子的算子学习方法，通过在Fourier基上进行投影来逼近一类非自伴随的无限维紧算子，并应用于恢复椭圆型偏微分算子的格林函数。这是第一个试图填补算子学习理论与实践差距的无需伴随算子分析。 |
| [^3] | [GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts.](http://arxiv.org/abs/2310.08677) | GDL-DS是一个基准测试，用于评估几何深度学习模型在具有分布转换的场景中的性能。它包括多个科学领域的评估数据集，并研究了不同级别的超出分布特征的信息访问。 |
| [^4] | [Soda: An Object-Oriented Functional Language for Specifying Human-Centered Problems.](http://arxiv.org/abs/2310.01961) | Soda是一种面向对象的功能性编程语言，用于描述以人为中心的问题，可以自然地处理质量和数量，并通过简单的定义模型化复杂要求。 |
| [^5] | [Bandits with Deterministically Evolving States.](http://arxiv.org/abs/2307.11655) | 该论文提出了一种名为具有确定性演化状态的强盗模型，用于学习带有强盗反馈的推荐系统和在线广告。该模型考虑了状态演化的不同速率，能准确评估奖励与系统健康程度之间的关系。 |
| [^6] | [Deep-Learning-Aided Alternating Least Squares for Tensor CP Decomposition and Its Application to Massive MIMO Channel Estimation.](http://arxiv.org/abs/2305.13947) | 本文提出了基于深度学习的CP分解算法DL-CPALS，通过使用深度神经网络生成有利的初始化值，提高了算法的速度和精度，该算法可用于大规模MIMO信道估计。 |
| [^7] | [Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks.](http://arxiv.org/abs/2305.01626) | 该论文提出了一种基于语音的完全无监督的方法，可以直接从原始语音中建立基础语法模型。作者发现，在基于声音的单词记录上训练的卷积神经网络可以自发连接两个或三个单词，并且可以学会将单词嵌入到新的未见过的单词组合中，这是之前未报道的属性，这一发现对我们理解神经网络的学习方式和建立从原始声学输入中的语法及其演化的模型都有重要的意义。 |
| [^8] | [Revisiting Discrete Soft Actor-Critic.](http://arxiv.org/abs/2209.10081) | 本研究重新审视了将连续动作空间的Soft Actor-Critic方法调整为离散动作空间的问题，并提出了解决Q值低估和性能不稳定的方法，验证了其在Atari游戏和大规模MOBA游戏中的有效性。 |

# 详细

[^1]: 使用基于Transformer编码器的EEG编码器和GAN从EEG记录中生成视觉刺激

    Generating Visual Stimuli from EEG Recordings using Transformer-encoder based EEG encoder and GAN

    [https://arxiv.org/abs/2402.10115](https://arxiv.org/abs/2402.10115)

    本研究使用基于Transformer编码器的EEG编码器和GAN网络，通过合成图像从EEG信号中恢复出各种对象类别的图像，同时结合对抗损失和感知损失，提高生成图像的质量。

    

    在这项研究中，我们解决了感知性脑解码领域的一个现代研究挑战，即使用对抗式深度学习框架从EEG信号中合成图像。具体目标是利用主体观看图像时获得的EEG记录重新创建属于各种对象类别的图像。为了实现这一目标，我们使用基于Transformer编码器的EEG编码器生成EEG编码，然后将其作为GAN网络的生成器组件的输入。除了对抗损失之外，我们还采用了感知损失来提高生成图像的质量。

    arXiv:2402.10115v1 Announce Type: new  Abstract: In this study, we tackle a modern research challenge within the field of perceptual brain decoding, which revolves around synthesizing images from EEG signals using an adversarial deep learning framework. The specific objective is to recreate images belonging to various object categories by leveraging EEG recordings obtained while subjects view those images. To achieve this, we employ a Transformer-encoder based EEG encoder to produce EEG encodings, which serve as inputs to the generator component of the GAN network. Alongside the adversarial loss, we also incorporate perceptual loss to enhance the quality of the generated images.
    
[^2]: 不需要伴随算子的算子学习

    Operator learning without the adjoint

    [https://arxiv.org/abs/2401.17739](https://arxiv.org/abs/2401.17739)

    本论文提出了一种不需要探测伴随算子的算子学习方法，通过在Fourier基上进行投影来逼近一类非自伴随的无限维紧算子，并应用于恢复椭圆型偏微分算子的格林函数。这是第一个试图填补算子学习理论与实践差距的无需伴随算子分析。

    

    算子学习中存在一个谜团：如何在没有探测伴随算子的情况下从数据中恢复非自伴随算子？目前的实际方法表明，在仅使用由算子的正向作用生成的数据的情况下，可以准确地恢复算子，而不需要访问伴随算子。然而，以直观的方式看，似乎有必要采样伴随算子的作用。在本文中，我们部分解释了这个谜团，通过证明在不查询伴随算子的情况下，可以通过在Fourier基上进行投影来逼近一类非自伴随的无限维紧算子。然后，我们将该结果应用于恢复椭圆型偏微分算子的格林函数，并导出一个无需伴随算子的样本复杂度界限。虽然现有的理论证明了算子学习的低样本复杂度，但我们的是第一个试图填补理论与实践差距的无需伴随算子的分析。

    There is a mystery at the heart of operator learning: how can one recover a non-self-adjoint operator from data without probing the adjoint? Current practical approaches suggest that one can accurately recover an operator while only using data generated by the forward action of the operator without access to the adjoint. However, naively, it seems essential to sample the action of the adjoint. In this paper, we partially explain this mystery by proving that without querying the adjoint, one can approximate a family of non-self-adjoint infinite-dimensional compact operators via projection onto a Fourier basis. We then apply the result to recovering Green's functions of elliptic partial differential operators and derive an adjoint-free sample complexity bound. While existing theory justifies low sample complexity in operator learning, ours is the first adjoint-free analysis that attempts to close the gap between theory and practice.
    
[^3]: GDL-DS: 分布转换下几何深度学习的基准测试

    GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts. (arXiv:2310.08677v1 [cs.LG])

    [http://arxiv.org/abs/2310.08677](http://arxiv.org/abs/2310.08677)

    GDL-DS是一个基准测试，用于评估几何深度学习模型在具有分布转换的场景中的性能。它包括多个科学领域的评估数据集，并研究了不同级别的超出分布特征的信息访问。

    

    几何深度学习(GDL)在各个科学领域引起了广泛关注，主要是因为其擅长对具有复杂几何结构的数据进行建模。然而，很少有研究探索其在处理分布转换问题上的能力，这是许多相关应用中常见的挑战。为了弥补这一空白，我们提出了GDL-DS，这是一个全面的基准测试，旨在评估GDL模型在具有分布转换的场景中的性能。我们的评估数据集涵盖了从粒子物理学和材料科学到生物化学的不同科学领域，并包括各种分布转换，包括条件、协变和概念转换。此外，我们研究了来自超出分布的测试数据的信息访问的三个级别，包括没有超出分布的信息、只有带标签的超出分布特征和带有少数标签的超出分布特征。总体而言，我们的基准测试涉及30个不同的实验设置，并评估3种信息访问水平。

    Geometric deep learning (GDL) has gained significant attention in various scientific fields, chiefly for its proficiency in modeling data with intricate geometric structures. Yet, very few works have delved into its capability of tackling the distribution shift problem, a prevalent challenge in many relevant applications. To bridge this gap, we propose GDL-DS, a comprehensive benchmark designed for evaluating the performance of GDL models in scenarios with distribution shifts. Our evaluation datasets cover diverse scientific domains from particle physics and materials science to biochemistry, and encapsulate a broad spectrum of distribution shifts including conditional, covariate, and concept shifts. Furthermore, we study three levels of information access from the out-of-distribution (OOD) testing data, including no OOD information, only OOD features without labels, and OOD features with a few labels. Overall, our benchmark results in 30 different experiment settings, and evaluates 3 
    
[^4]: Soda:一种用于描述以人为中心问题的面向对象的功能性编程语言

    Soda: An Object-Oriented Functional Language for Specifying Human-Centered Problems. (arXiv:2310.01961v1 [cs.PL])

    [http://arxiv.org/abs/2310.01961](http://arxiv.org/abs/2310.01961)

    Soda是一种面向对象的功能性编程语言，用于描述以人为中心的问题，可以自然地处理质量和数量，并通过简单的定义模型化复杂要求。

    

    我们介绍了Soda（Symbolic Objective Descriptive Analysis），一种语言，有助于以自然的方式处理质量和数量，并极大地简化了检查它们正确性的任务。我们介绍了语言的关键属性，这些属性是由对计算机系统复杂要求进行描述的设计所激发的，并解释了如何通过简单的定义来建模这些要求时必须解决这些关键属性。我们概述了一个工具，它有助于以更透明和更少出错的方式描述问题。

    We present Soda (Symbolic Objective Descriptive Analysis), a language that helps to treat qualities and quantities in a natural way and greatly simplifies the task of checking their correctness. We present key properties for the language motivated by the design of a descriptive language to encode complex requirements on computer systems, and we explain how these key properties must be addressed to model these requirements with simple definitions. We give an overview of a tool that helps to describe problems in an easy way that we consider more transparent and less error-prone.
    
[^5]: 具有确定性演化状态的强盗模型

    Bandits with Deterministically Evolving States. (arXiv:2307.11655v1 [cs.LG])

    [http://arxiv.org/abs/2307.11655](http://arxiv.org/abs/2307.11655)

    该论文提出了一种名为具有确定性演化状态的强盗模型，用于学习带有强盗反馈的推荐系统和在线广告。该模型考虑了状态演化的不同速率，能准确评估奖励与系统健康程度之间的关系。

    

    我们提出了一种学习与强盗反馈结合的模型，同时考虑到确定性演化和不可观测的状态，我们称之为具有确定性演化状态的强盗模型。我们的模型主要应用于推荐系统和在线广告的学习。在这两种情况下，算法在每一轮获得的奖励是选择行动的短期奖励和系统的“健康”程度（即通过其状态测量）的函数。例如，在推荐系统中，平台从用户对特定类型内容的参与中获得的奖励不仅取决于具体内容的固有特征，还取决于用户与平台上其他类型内容互动后其偏好的演化。我们的通用模型考虑了状态演化的不同速率λ∈[0,1]（例如，用户的偏好因先前内容消费而快速变化）。

    We propose a model for learning with bandit feedback while accounting for deterministically evolving and unobservable states that we call Bandits with Deterministically Evolving States. The workhorse applications of our model are learning for recommendation systems and learning for online ads. In both cases, the reward that the algorithm obtains at each round is a function of the short-term reward of the action chosen and how ``healthy'' the system is (i.e., as measured by its state). For example, in recommendation systems, the reward that the platform obtains from a user's engagement with a particular type of content depends not only on the inherent features of the specific content, but also on how the user's preferences have evolved as a result of interacting with other types of content on the platform. Our general model accounts for the different rate $\lambda \in [0,1]$ at which the state evolves (e.g., how fast a user's preferences shift as a result of previous content consumption
    
[^6]: 基于深度学习的交替最小二乘法用于张量CP分解及其在大规模MIMO信道估计中的应用

    Deep-Learning-Aided Alternating Least Squares for Tensor CP Decomposition and Its Application to Massive MIMO Channel Estimation. (arXiv:2305.13947v1 [eess.SP])

    [http://arxiv.org/abs/2305.13947](http://arxiv.org/abs/2305.13947)

    本文提出了基于深度学习的CP分解算法DL-CPALS，通过使用深度神经网络生成有利的初始化值，提高了算法的速度和精度，该算法可用于大规模MIMO信道估计。

    

    CANDECOMP/PARAFAC (CP)分解是在多域大规模多输入多输出（MIMO）系统中表述接收到的张量信号的最常用模型，因为接收机通常会将来自不同传输路径或用户的组件相加。为了实现准确和低延迟的信道估计，需要好的、快速的CP分解算法。CP交替最小二乘法（CPALS）是计算CP分解的主力算法。但是，它的性能取决于初始化，良好的起始值可以导致更有效的解决方案。现有的初始化策略与CPALS解耦，并不一定有利于解决CP分解问题。为了提高算法的速度和精度，本文提出了一种基于深度学习的CPALS（DL-CPALS）方法，它使用深度神经网络（DNN）生成有利的初始化。所提出的DL-CPALS将DNN和CPALS集成到模型基深度学习范式中。

    CANDECOMP/PARAFAC (CP) decomposition is the mostly used model to formulate the received tensor signal in a multi-domain massive multiple-input multiple-output (MIMO) system, as the receiver generally sums the components from different paths or users. To achieve accurate and low-latency channel estimation, good and fast CP decomposition algorithms are desired. The CP alternating least squares (CPALS) is the workhorse algorithm for calculating the CP decomposition. However, its performance depends on the initializations, and good starting values can lead to more efficient solutions. Existing initialization strategies are decoupled from the CPALS and are not necessarily favorable for solving the CP decomposition. To enhance the algorithm's speed and accuracy, this paper proposes a deep-learning-aided CPALS (DL-CPALS) method that uses a deep neural network (DNN) to generate favorable initializations. The proposed DL-CPALS integrates the DNN and CPALS to a model-based deep learning paradigm
    
[^7]: 基于语音的基础语法：自发联接的自监督深度神经网络

    Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks. (arXiv:2305.01626v1 [cs.CL])

    [http://arxiv.org/abs/2305.01626](http://arxiv.org/abs/2305.01626)

    该论文提出了一种基于语音的完全无监督的方法，可以直接从原始语音中建立基础语法模型。作者发现，在基于声音的单词记录上训练的卷积神经网络可以自发连接两个或三个单词，并且可以学会将单词嵌入到新的未见过的单词组合中，这是之前未报道的属性，这一发现对我们理解神经网络的学习方式和建立从原始声学输入中的语法及其演化的模型都有重要的意义。

    

    语法的计算模型主要基于文本。本文提出了一种完全无监督的方法，可以直接从原始语音中建立基础语法模型。我们重点研究了最普遍和基本的语法特性之一——联接。我们介绍了自发联接现象：卷积神经网络(CNN)在个别单词的声学记录上训练时，开始产生输出，这些输出将两个甚至三个单词连接在一起，而不会接触到具有多个单词的输入数据。此外，训练两个单词的网络可以学习将单词嵌入到新的未见过的单词组合中。据我们所知，这是在生成对抗网络环境下训练的原始语音CNN以前未报道的属性，它不仅对我们理解这些体系结构的学习方式有影响，还对建立从原始声学输入中的语法及其演化的模型有影响。

    Computational models of syntax are predominantly text-based. Here we propose that basic syntax can be modeled directly from raw speech in a fully unsupervised way. We focus on one of the most ubiquitous and basic properties of syntax -- concatenation. We introduce spontaneous concatenation: a phenomenon where convolutional neural networks (CNNs) trained on acoustic recordings of individual words start generating outputs with two or even three words concatenated without ever accessing data with multiple words in the input. Additionally, networks trained on two words learn to embed words into novel unobserved word combinations. To our knowledge, this is a previously unreported property of CNNs trained on raw speech in the Generative Adversarial Network setting and has implications both for our understanding of how these architectures learn as well as for modeling syntax and its evolution from raw acoustic inputs.
    
[^8]: 重新审视离散型Soft Actor-Critic方法

    Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10081](http://arxiv.org/abs/2209.10081)

    本研究重新审视了将连续动作空间的Soft Actor-Critic方法调整为离散动作空间的问题，并提出了解决Q值低估和性能不稳定的方法，验证了其在Atari游戏和大规模MOBA游戏中的有效性。

    

    本文研究将连续动作空间的Soft Actor-Critic方法（SAC）调整为离散动作空间。我们重新审视了经典的SAC方法，并深入理解了在离散设置下其Q值低估和性能不稳定的问题。因此，我们提出了熵惩罚和具有Q-clip的双平均Q-learning方法来解决这些问题。通过对包括Atari游戏和一个大规模MOBA游戏在内的典型基准问题进行广泛实验，验证了我们方法的有效性。我们的代码可在以下链接找到: https://github.com/coldsummerday/Revisiting-Discrete-SAC.

    We study the adaption of soft actor-critic (SAC) from continuous action space to discrete action space. We revisit vanilla SAC and provide an in-depth understanding of its Q value underestimation and performance instability issues when applied to discrete settings. We thereby propose entropy-penalty and double average Q-learning with Q-clip to address these issues. Extensive experiments on typical benchmarks with discrete action space, including Atari games and a large-scale MOBA game, show the efficacy of our proposed method. Our code is at:https://github.com/coldsummerday/Revisiting-Discrete-SAC.
    

