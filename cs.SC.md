# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes](https://arxiv.org/abs/2403.06294) | 通过争论方案的自我论证迭代和构建争论过程，ArgMed-Agents实现了基于LLM的可解释临床决策推理，提高了用户对临床决策的信任。 |

# 详细

[^1]: ArgMed-Agents: 使用争议方案通过大型语言模型解释性临床决策推理

    ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes

    [https://arxiv.org/abs/2403.06294](https://arxiv.org/abs/2403.06294)

    通过争论方案的自我论证迭代和构建争论过程，ArgMed-Agents实现了基于LLM的可解释临床决策推理，提高了用户对临床决策的信任。

    

    arXiv:2403.06294v1 公告类型: 新摘要: 使用大型语言模型（LLMs）进行临床推理存在两个主要障碍。首先，虽然LLMs在自然语言处理（NLP）任务中显示出巨大的潜力，但在复杂推理和规划方面的表现却不尽人意。其次，LLMs使用不可解释的方法进行临床决策，这与临床医生的认知过程本质上不同，导致用户不信任。在本文中，我们提出了一个名为ArgMed-Agents的多代理框架，旨在通过交互使基于LLM的代理能够进行可解释的临床决策推理。ArgMed-Agents通过临床决策论据（一种模拟临床决策认知过程的推理机制）执行自论证迭代，然后将争论过程构建为表示冲突关系的有向图。最终，Reasoner（一种符号求解器）识别出一个

    arXiv:2403.06294v1 Announce Type: new  Abstract: There are two main barriers to using large language models (LLMs) in clinical reasoning. Firstly, while LLMs exhibit significant promise in Natural Language Processing (NLP) tasks, their performance in complex reasoning and planning falls short of expectations. Secondly, LLMs use uninterpretable methods to make clinical decisions that are fundamentally different from the clinician's cognitive processes. This leads to user distrust. In this paper, we present a multi-agent framework called ArgMed-Agents, which aims to enable LLM-based agents to make explainable clinical decision reasoning through interaction. ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism for modeling cognitive processes in clinical reasoning), and then constructs the argumentation process as a directed graph representing conflicting relationships. Ultimately, Reasoner(a symbolic solver) identify a
    

