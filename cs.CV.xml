<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20445;&#25345;&#27169;&#22411;&#39640;&#20934;&#30830;&#24615;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10045</link><description>&lt;p&gt;
&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#23454;&#29616;&#23545;&#25239;&#40065;&#26834;&#24615;&#25968;&#25454;&#38598;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
Towards Adversarially Robust Dataset Distillation by Curvature Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20445;&#25345;&#27169;&#22411;&#39640;&#20934;&#30830;&#24615;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#38598;&#31934;&#28860;&#65288;DD&#65289;&#20801;&#35768;&#23558;&#25968;&#25454;&#38598;&#31934;&#28860;&#20026;&#21407;&#22987;&#22823;&#23567;&#30340;&#20998;&#25968;&#65292;&#21516;&#26102;&#20445;&#30041;&#20016;&#23500;&#30340;&#20998;&#24067;&#20449;&#24687;&#65292;&#20351;&#24471;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#33410;&#30465;&#26174;&#33879;&#35745;&#31639;&#36127;&#36733;&#30340;&#21516;&#26102;&#36798;&#21040;&#21487;&#27604;&#30340;&#20934;&#30830;&#24615;&#12290;&#26368;&#36817;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#25552;&#39640;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#32034;DD&#30340;&#19968;&#31181;&#26032;&#35270;&#35282;&#12290;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20351;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20445;&#25345;&#39640;&#31934;&#24230;&#30340;&#21516;&#26102;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23558;&#26354;&#29575;&#27491;&#21017;&#21270;&#32435;&#20837;&#21040;&#31934;&#28860;&#36807;&#31243;&#20013;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#26032;&#26041;&#27861;&#65292;&#32780;&#36825;&#31181;&#26041;&#27861;&#30340;&#35745;&#31639;&#24320;&#38144;&#27604;&#26631;&#20934;&#30340;&#23545;&#25239;&#35757;&#32451;&#35201;&#23569;&#24471;&#22810;&#12290;&#22823;&#37327;&#30340;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#20934;&#30830;&#24615;&#19978;&#20248;&#20110;&#26631;&#20934;&#23545;&#25239;&#35757;&#32451;&#65292;&#21516;&#26102;&#22312;&#23545;&#25239;&#24615;&#33021;&#26041;&#38754;&#20063;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10045v1 Announce Type: new  Abstract: Dataset distillation (DD) allows datasets to be distilled to fractions of their original size while preserving the rich distributional information so that models trained on the distilled datasets can achieve a comparable accuracy while saving significant computational loads. Recent research in this area has been focusing on improving the accuracy of models trained on distilled datasets. In this paper, we aim to explore a new perspective of DD. We study how to embed adversarial robustness in distilled datasets, so that models trained on these datasets maintain the high accuracy and meanwhile acquire better adversarial robustness. We propose a new method that achieves this goal by incorporating curvature regularization into the distillation process with much less computational overhead than standard adversarial training. Extensive empirical experiments suggest that our method not only outperforms standard adversarial training on both accur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#36755;&#20837;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20004;&#20010;&#28508;&#22312;&#32534;&#30721;&#25511;&#21046;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#31354;&#38388;&#32467;&#26500;&#21644;&#35821;&#20041;&#39118;&#26684;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#29992;&#37319;&#26679;&#25216;&#26415;&#21644;&#26102;&#38388;&#27493;&#30456;&#20851;&#30340;&#28508;&#22312;&#26435;&#37325;&#35843;&#24230;&#65292;&#23454;&#29616;&#20102;&#23545;&#29983;&#25104;&#36807;&#31243;&#30340;&#26356;&#22909;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2302.14368</link><description>&lt;p&gt;
&#23454;&#29616;&#25193;&#23637;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#30340;&#21487;&#25511;&#24615;
&lt;/p&gt;
&lt;p&gt;
Towards Enhanced Controllability of Diffusion Models. (arXiv:2302.14368v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#36755;&#20837;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20004;&#20010;&#28508;&#22312;&#32534;&#30721;&#25511;&#21046;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#31354;&#38388;&#32467;&#26500;&#21644;&#35821;&#20041;&#39118;&#26684;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#29992;&#37319;&#26679;&#25216;&#26415;&#21644;&#26102;&#38388;&#27493;&#30456;&#20851;&#30340;&#28508;&#22312;&#26435;&#37325;&#35843;&#24230;&#65292;&#23454;&#29616;&#20102;&#23545;&#29983;&#25104;&#36807;&#31243;&#30340;&#26356;&#22909;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#36924;&#30495;&#12289;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#21270;&#22270;&#20687;&#26041;&#38754;&#34920;&#29616;&#20986;&#21331;&#36234;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#21487;&#25511;&#31243;&#24230;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#21463;&#22522;&#20110;GAN&#28508;&#22312;&#31354;&#38388;&#30340;&#22270;&#20687;&#25805;&#32437;&#25216;&#26415;&#21551;&#21457;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#26465;&#20214;&#20110;&#20004;&#20010;&#28508;&#22312;&#32534;&#30721;&#12289;&#19968;&#20010;&#31354;&#38388;&#20869;&#23481;&#25513;&#30721;&#21644;&#19968;&#20010;&#25153;&#24179;&#30340;&#26679;&#24335;&#23884;&#20837;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#20381;&#36182;&#20110;&#25193;&#25955;&#27169;&#22411;&#28176;&#36827;&#21435;&#22122;&#36807;&#31243;&#30340;&#24863;&#24615;&#20559;&#32622;&#65292;&#22312;&#31354;&#38388;&#32467;&#26500;&#25513;&#30721;&#20013;&#32534;&#30721;&#23039;&#21183;/&#24067;&#23616;&#20449;&#24687;&#65292;&#22312;&#26679;&#24335;&#20195;&#30721;&#20013;&#32534;&#30721;&#35821;&#20041;/&#26679;&#24335;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#29992;&#30340;&#37319;&#26679;&#25216;&#26415;&#26469;&#25913;&#21892;&#21487;&#25511;&#24615;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#21487;&#32452;&#21512;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#20801;&#35768;&#37096;&#20998;&#20381;&#36182;&#20110;&#26465;&#20214;&#36755;&#20837;&#65292;&#20197;&#25552;&#39640;&#29983;&#25104;&#36136;&#37327;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#23545;&#27599;&#20010;&#28508;&#22312;&#20195;&#30721;&#21644;&#23427;&#20204;&#30340;&#32852;&#21512;&#20998;&#24067;&#37327;&#30340;&#25511;&#21046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#26102;&#38388;&#27493;&#30456;&#20851;&#30340;&#20869;&#23481;&#21644;&#26679;&#24335;&#28508;&#22312;&#26435;&#37325;&#35843;&#24230;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#25511;&#21046;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising Diffusion models have shown remarkable capabilities in generating realistic, high-quality and diverse images. However, the extent of controllability during generation is underexplored. Inspired by techniques based on GAN latent space for image manipulation, we train a diffusion model conditioned on two latent codes, a spatial content mask and a flattened style embedding. We rely on the inductive bias of the progressive denoising process of diffusion models to encode pose/layout information in the spatial structure mask and semantic/style information in the style code. We propose two generic sampling techniques for improving controllability. We extend composable diffusion models to allow for some dependence between conditional inputs, to improve the quality of generations while also providing control over the amount of guidance from each latent code and their joint distribution. We also propose timestep dependent weight scheduling for content and style latents to further impro
&lt;/p&gt;</description></item></channel></rss>