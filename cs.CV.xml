<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>ThermoHands&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;ThermoHands&#65292;&#26088;&#22312;&#35299;&#20915;&#28909;&#22270;&#20013;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#25361;&#25112;&#65292;&#20171;&#32461;&#20102;&#19968;&#20010;&#20855;&#26377;&#21452;transformer&#27169;&#22359;&#30340;&#23450;&#21046;&#22522;&#32447;&#26041;&#27861;TheFormer&#65292;&#34920;&#26126;&#28909;&#25104;&#20687;&#22312;&#24694;&#21155;&#26465;&#20214;&#19979;&#23454;&#29616;&#31283;&#20581;&#30340;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09871</link><description>&lt;p&gt;
ThermoHands&#65306;&#19968;&#31181;&#29992;&#20110;&#20174;&#20027;&#35266;&#35270;&#35282;&#28909;&#22270;&#20013;&#20272;&#35745;3D&#25163;&#37096;&#23039;&#21183;&#30340;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09871
&lt;/p&gt;
&lt;p&gt;
ThermoHands&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;ThermoHands&#65292;&#26088;&#22312;&#35299;&#20915;&#28909;&#22270;&#20013;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#25361;&#25112;&#65292;&#20171;&#32461;&#20102;&#19968;&#20010;&#20855;&#26377;&#21452;transformer&#27169;&#22359;&#30340;&#23450;&#21046;&#22522;&#32447;&#26041;&#27861;TheFormer&#65292;&#34920;&#26126;&#28909;&#25104;&#20687;&#22312;&#24694;&#21155;&#26465;&#20214;&#19979;&#23454;&#29616;&#31283;&#20581;&#30340;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ThermoHands&#65292;&#36825;&#26159;&#19968;&#20010;&#38024;&#23545;&#22522;&#20110;&#28909;&#22270;&#30340;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#26032;&#22522;&#20934;&#65292;&#26088;&#22312;&#20811;&#26381;&#35832;&#22914;&#20809;&#29031;&#21464;&#21270;&#21644;&#36974;&#25377;&#65288;&#20363;&#22914;&#25163;&#37096;&#31359;&#25140;&#29289;&#65289;&#31561;&#25361;&#25112;&#12290;&#35813;&#22522;&#20934;&#21253;&#25324;&#26469;&#33258;28&#21517;&#20027;&#20307;&#36827;&#34892;&#25163;-&#29289;&#20307;&#21644;&#25163;-&#34394;&#25311;&#20132;&#20114;&#30340;&#22810;&#26679;&#25968;&#25454;&#38598;&#65292;&#32463;&#36807;&#33258;&#21160;&#21270;&#36807;&#31243;&#20934;&#30830;&#26631;&#27880;&#20102;3D&#25163;&#37096;&#23039;&#21183;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#23450;&#21046;&#30340;&#22522;&#32447;&#26041;&#27861;TheFormer&#65292;&#21033;&#29992;&#21452;transformer&#27169;&#22359;&#22312;&#28909;&#22270;&#20013;&#23454;&#29616;&#26377;&#25928;&#30340;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#31361;&#26174;&#20102;TheFormer&#30340;&#39046;&#20808;&#24615;&#33021;&#65292;&#24182;&#30830;&#35748;&#20102;&#28909;&#25104;&#20687;&#22312;&#23454;&#29616;&#24694;&#21155;&#26465;&#20214;&#19979;&#31283;&#20581;&#30340;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09871v1 Announce Type: cross  Abstract: In this work, we present ThermoHands, a new benchmark for thermal image-based egocentric 3D hand pose estimation, aimed at overcoming challenges like varying lighting and obstructions (e.g., handwear). The benchmark includes a diverse dataset from 28 subjects performing hand-object and hand-virtual interactions, accurately annotated with 3D hand poses through an automated process. We introduce a bespoken baseline method, TheFormer, utilizing dual transformer modules for effective egocentric 3D hand pose estimation in thermal imagery. Our experimental results highlight TheFormer's leading performance and affirm thermal imaging's effectiveness in enabling robust 3D hand pose estimation in adverse conditions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31995;&#32479;&#32508;&#36848;&#20102;&#22312;&#21307;&#23398;&#25104;&#20687;&#20013;&#24212;&#29992;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#65288;LRMA&#65289;&#21644;&#20854;&#27966;&#29983;&#29289;&#23616;&#37096;LRMA&#65288;LLRMA&#65289;&#30340;&#20316;&#21697;&#65292;&#24182;&#25351;&#20986;&#33258;2015&#24180;&#20197;&#26469;&#21307;&#23398;&#25104;&#20687;&#39046;&#22495;&#24320;&#22987;&#20559;&#21521;&#20110;&#20351;&#29992;LLRMA&#65292;&#26174;&#31034;&#20854;&#22312;&#25429;&#33719;&#21307;&#23398;&#25968;&#25454;&#20013;&#22797;&#26434;&#32467;&#26500;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14045</link><description>&lt;p&gt;
&#22312;&#21307;&#23398;&#25104;&#20687;&#20013;&#25512;&#36827;&#20302;&#31209;&#21644;&#23616;&#37096;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#65306;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#19982;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Advancing Low-Rank and Local Low-Rank Matrix Approximation in Medical Imaging: A Systematic Literature Review and Future Directions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31995;&#32479;&#32508;&#36848;&#20102;&#22312;&#21307;&#23398;&#25104;&#20687;&#20013;&#24212;&#29992;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#65288;LRMA&#65289;&#21644;&#20854;&#27966;&#29983;&#29289;&#23616;&#37096;LRMA&#65288;LLRMA&#65289;&#30340;&#20316;&#21697;&#65292;&#24182;&#25351;&#20986;&#33258;2015&#24180;&#20197;&#26469;&#21307;&#23398;&#25104;&#20687;&#39046;&#22495;&#24320;&#22987;&#20559;&#21521;&#20110;&#20351;&#29992;LLRMA&#65292;&#26174;&#31034;&#20854;&#22312;&#25429;&#33719;&#21307;&#23398;&#25968;&#25454;&#20013;&#22797;&#26434;&#32467;&#26500;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#23398;&#25104;&#20687;&#25968;&#25454;&#38598;&#30340;&#22823;&#23481;&#37327;&#21644;&#22797;&#26434;&#24615;&#26159;&#23384;&#20648;&#12289;&#20256;&#36755;&#21644;&#22788;&#29702;&#30340;&#29942;&#39048;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#65288;LRMA&#65289;&#21450;&#20854;&#27966;&#29983;&#29289;&#23616;&#37096;LRMA&#65288;LLRMA&#65289;&#30340;&#24212;&#29992;&#24050;&#26174;&#31034;&#20986;&#28508;&#21147;&#12290;&#26412;&#25991;&#36827;&#34892;&#20102;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#23637;&#31034;&#20102;&#22312;&#21307;&#23398;&#25104;&#20687;&#20013;&#24212;&#29992;LRMA&#21644;LLRMA&#30340;&#20316;&#21697;&#12290;&#25991;&#29486;&#30340;&#35814;&#32454;&#20998;&#26512;&#30830;&#35748;&#20102;&#24212;&#29992;&#20110;&#21508;&#31181;&#25104;&#20687;&#27169;&#24577;&#30340;LRMA&#21644;LLRMA&#26041;&#27861;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#29616;&#26377;LRMA&#21644;LLRMA&#26041;&#27861;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#65292;&#33258;2015&#24180;&#20197;&#26469;&#65292;&#21307;&#23398;&#25104;&#20687;&#39046;&#22495;&#26126;&#26174;&#20559;&#21521;&#20110;LLRMA&#65292;&#26174;&#31034;&#20102;&#30456;&#23545;&#20110;LRMA&#22312;&#25429;&#33719;&#21307;&#23398;&#25968;&#25454;&#20013;&#22797;&#26434;&#32467;&#26500;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#26377;&#25928;&#24615;&#12290;&#37492;&#20110;LLRMA&#25152;&#20351;&#29992;&#30340;&#27973;&#23618;&#30456;&#20284;&#24615;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#20808;&#36827;&#35821;&#20041;&#22270;&#20687;&#20998;&#21106;&#26469;&#22788;&#29702;&#30456;&#20284;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14045v1 Announce Type: cross  Abstract: The large volume and complexity of medical imaging datasets are bottlenecks for storage, transmission, and processing. To tackle these challenges, the application of low-rank matrix approximation (LRMA) and its derivative, local LRMA (LLRMA) has demonstrated potential.   This paper conducts a systematic literature review to showcase works applying LRMA and LLRMA in medical imaging. A detailed analysis of the literature identifies LRMA and LLRMA methods applied to various imaging modalities. This paper addresses the challenges and limitations associated with existing LRMA and LLRMA methods.   We note a significant shift towards a preference for LLRMA in the medical imaging field since 2015, demonstrating its potential and effectiveness in capturing complex structures in medical data compared to LRMA. Acknowledging the limitations of shallow similarity methods used with LLRMA, we suggest advanced semantic image segmentation for similarit
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#25193;&#23637;&#21453;&#21521;&#26102;&#38388;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;ER SDE&#65289;&#29992;&#20110;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#31934;&#30830;&#35299;&#21644;&#39640;&#38454;&#36817;&#20284;&#35299;&#65292;&#24182;&#35299;&#37322;&#20102;&#22312;&#24555;&#36895;&#37319;&#26679;&#26041;&#38754;ODE&#27714;&#35299;&#22120;&#20248;&#20110;SDE&#27714;&#35299;&#22120;&#30340;&#25968;&#23398;&#27934;&#23519;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.06169</link><description>&lt;p&gt;
&#38416;&#26126;&#25193;&#23637;&#21453;&#21521;&#26102;&#38388;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#22312;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#35299;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Elucidating the solution space of extended reverse-time SDE for diffusion models. (arXiv:2309.06169v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06169
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#25193;&#23637;&#21453;&#21521;&#26102;&#38388;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;ER SDE&#65289;&#29992;&#20110;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#31934;&#30830;&#35299;&#21644;&#39640;&#38454;&#36817;&#20284;&#35299;&#65292;&#24182;&#35299;&#37322;&#20102;&#22312;&#24555;&#36895;&#37319;&#26679;&#26041;&#38754;ODE&#27714;&#35299;&#22120;&#20248;&#20110;SDE&#27714;&#35299;&#22120;&#30340;&#25968;&#23398;&#27934;&#23519;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#21508;&#31181;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#24378;&#22823;&#30340;&#22270;&#20687;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#20027;&#35201;&#38480;&#21046;&#22312;&#20110;&#37319;&#26679;&#36895;&#24230;&#36739;&#24930;&#65292;&#38656;&#35201;&#36890;&#36807;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25968;&#30334;&#25110;&#25968;&#21315;&#27425;&#36830;&#32493;&#20989;&#25968;&#35780;&#20272;&#25165;&#33021;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#12290;&#20174;&#25193;&#25955;&#27169;&#22411;&#20013;&#37319;&#26679;&#21487;&#20197;&#30475;&#20316;&#26159;&#35299;&#30456;&#24212;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#25110;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#37319;&#26679;&#36807;&#31243;&#24418;&#24335;&#21270;&#20026;&#25193;&#23637;&#21453;&#21521;&#26102;&#38388; SDE&#65288;ER SDE&#65289;&#65292;&#23558;&#20043;&#21069;&#23545;ODE&#21644;SDE&#30340;&#25506;&#32034;&#32479;&#19968;&#36215;&#26469;&#12290;&#21033;&#29992;ER SDE&#35299;&#30340;&#21322;&#32447;&#24615;&#32467;&#26500;&#65292;&#25105;&#20204;&#20026;VP SDE&#25552;&#20379;&#20102;&#31934;&#30830;&#35299;&#21644;&#20219;&#24847;&#39640;&#38454;&#36817;&#20284;&#35299;&#65292;&#20026;VE SDE&#25552;&#20379;&#20102;&#39640;&#38454;&#36817;&#20284;&#35299;&#12290;&#22522;&#20110;ER SDE&#30340;&#35299;&#31354;&#38388;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;ODE&#27714;&#35299;&#22120;&#22312;&#24555;&#36895;&#37319;&#26679;&#26041;&#38754;&#20248;&#20110;SDE&#27714;&#35299;&#22120;&#30340;&#25968;&#23398;&#27934;&#23519;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25581;&#31034;&#20102;VP SDE&#27714;&#35299;&#22120;&#19982;&#20854;VE SDE&#27714;&#35299;&#22120;&#22312;&#24615;&#33021;&#19978;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models (DMs) demonstrate potent image generation capabilities in various generative modeling tasks. Nevertheless, their primary limitation lies in slow sampling speed, requiring hundreds or thousands of sequential function evaluations through large neural networks to generate high-quality images. Sampling from DMs can be seen as solving corresponding stochastic differential equations (SDEs) or ordinary differential equations (ODEs). In this work, we formulate the sampling process as an extended reverse-time SDE (ER SDE), unifying prior explorations into ODEs and SDEs. Leveraging the semi-linear structure of ER SDE solutions, we offer exact solutions and arbitrarily high-order approximate solutions for VP SDE and VE SDE, respectively. Based on the solution space of the ER SDE, we yield mathematical insights elucidating the superior performance of ODE solvers over SDE solvers in terms of fast sampling. Additionally, we unveil that VP SDE solvers stand on par with their VE SDE c
&lt;/p&gt;</description></item></channel></rss>