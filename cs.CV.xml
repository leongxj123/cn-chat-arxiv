<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#25552;&#20986;&#20102;Prompting4Debugging&#65288;P4D&#65289;&#20316;&#20026;&#19968;&#20010;&#35843;&#35797;&#21644;&#32418;&#38431;&#27979;&#35797;&#24037;&#20855;&#65292;&#21487;&#20197;&#33258;&#21160;&#25214;&#21040;&#25193;&#25955;&#27169;&#22411;&#30340;&#38382;&#39064;&#25552;&#31034;&#65292;&#20197;&#27979;&#35797;&#37096;&#32626;&#30340;&#23433;&#20840;&#26426;&#21046;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.06135</link><description>&lt;p&gt;
Prompting4Debugging: &#36890;&#36807;&#21457;&#29616;&#38382;&#39064;&#25552;&#31034;&#26469;&#23545;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#32418;&#38431;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts. (arXiv:2309.06135v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06135
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Prompting4Debugging&#65288;P4D&#65289;&#20316;&#20026;&#19968;&#20010;&#35843;&#35797;&#21644;&#32418;&#38431;&#27979;&#35797;&#24037;&#20855;&#65292;&#21487;&#20197;&#33258;&#21160;&#25214;&#21040;&#25193;&#25955;&#27169;&#22411;&#30340;&#38382;&#39064;&#25552;&#31034;&#65292;&#20197;&#27979;&#35797;&#37096;&#32626;&#30340;&#23433;&#20840;&#26426;&#21046;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#65292;&#20363;&#22914;&#31283;&#23450;&#25193;&#25955;&#65288;SD&#65289;&#65292;&#26368;&#36817;&#23637;&#29616;&#20986;&#39640;&#36136;&#37327;&#20869;&#23481;&#29983;&#25104;&#30340;&#26174;&#33879;&#33021;&#21147;&#65292;&#24182;&#25104;&#20026;&#36817;&#26399;&#21464;&#38761;&#24615;&#20154;&#24037;&#26234;&#33021;&#28010;&#28526;&#30340;&#20195;&#34920;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36827;&#27493;&#20063;&#24102;&#26469;&#20102;&#23545;&#35813;&#29983;&#25104;&#25216;&#26415;&#28389;&#29992;&#30340;&#26085;&#30410;&#20851;&#27880;&#65292;&#29305;&#21035;&#26159;&#29992;&#20110;&#29983;&#25104;&#21463;&#29256;&#26435;&#20445;&#25252;&#25110;&#19981;&#36866;&#21512;&#22312;&#24037;&#20316;&#29615;&#22659;&#20013;&#26597;&#30475;&#30340;&#22270;&#20687;&#12290;&#34429;&#28982;&#24050;&#32463;&#20570;&#20986;&#20102;&#19968;&#20123;&#21162;&#21147;&#26469;&#36890;&#36807;&#27169;&#22411;&#24494;&#35843;&#26469;&#36807;&#28388;&#19981;&#36866;&#24403;&#30340;&#22270;&#20687;/&#25552;&#31034;&#25110;&#21024;&#38500;&#19981;&#24076;&#26395;&#30340;&#27010;&#24565;/&#39118;&#26684;&#65292;&#20294;&#36825;&#20123;&#23433;&#20840;&#26426;&#21046;&#23545;&#20110;&#22810;&#26679;&#21270;&#30340;&#38382;&#39064;&#25552;&#31034;&#30340;&#21487;&#38752;&#24615;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Prompting4Debugging&#65288;P4D&#65289;&#20316;&#20026;&#19968;&#20010;&#35843;&#35797;&#21644;&#32418;&#38431;&#27979;&#35797;&#24037;&#20855;&#65292;&#23427;&#21487;&#20197;&#33258;&#21160;&#25214;&#21040;&#25193;&#25955;&#27169;&#22411;&#30340;&#38382;&#39064;&#25552;&#31034;&#65292;&#20197;&#27979;&#35797;&#37096;&#32626;&#30340;&#23433;&#20840;&#26426;&#21046;&#30340;&#21487;&#38752;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;P4D&#24037;&#20855;&#22312;&#21457;&#29616;&#20855;&#26377;&#23433;&#20840;&#26426;&#21046;&#30340;SD&#27169;&#22411;&#30340;&#26032;&#28431;&#27934;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;...
&lt;/p&gt;
&lt;p&gt;
Text-to-image diffusion models, e.g. Stable Diffusion (SD), lately have shown remarkable ability in high-quality content generation, and become one of the representatives for the recent wave of transformative AI. Nevertheless, such advance comes with an intensifying concern about the misuse of this generative technology, especially for producing copyrighted or NSFW (i.e. not safe for work) images. Although efforts have been made to filter inappropriate images/prompts or remove undesirable concepts/styles via model fine-tuning, the reliability of these safety mechanisms against diversified problematic prompts remains largely unexplored. In this work, we propose Prompting4Debugging (P4D) as a debugging and red-teaming tool that automatically finds problematic prompts for diffusion models to test the reliability of a deployed safety mechanism. We demonstrate the efficacy of our P4D tool in uncovering new vulnerabilities of SD models with safety mechanisms. Particularly, our result shows t
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35843;&#26597;&#20102;&#24773;&#24863;&#35745;&#31639;&#20013;&#30340;&#20010;&#24615;&#21270;&#26041;&#27861;&#65292;&#23558;&#20854;&#20998;&#20026;&#19971;&#31867;&#65292;&#24182;&#32473;&#20986;&#20102;&#35843;&#26597;&#25991;&#29486;&#30340;&#32479;&#35745;&#20803;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2304.00377</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#24773;&#24863;&#35745;&#31639;&#22312;&#20154;&#26426;&#20132;&#20114;&#20013;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Personalized Affective Computing in Human-Machine Interaction. (arXiv:2304.00377v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00377
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35843;&#26597;&#20102;&#24773;&#24863;&#35745;&#31639;&#20013;&#30340;&#20010;&#24615;&#21270;&#26041;&#27861;&#65292;&#23558;&#20854;&#20998;&#20026;&#19971;&#31867;&#65292;&#24182;&#32473;&#20986;&#20102;&#35843;&#26597;&#25991;&#29486;&#30340;&#32479;&#35745;&#20803;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#26426;&#39046;&#22495;&#20013;&#65292;&#20010;&#24615;&#21270;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#25110;&#22810;&#20010;&#24615;&#33021;&#25351;&#26631;&#24182;&#36981;&#23432;&#29305;&#23450;&#32422;&#26463;&#26465;&#20214;&#26469;&#35757;&#32451;&#36814;&#21512;&#29305;&#23450;&#20010;&#20154;&#25110;&#20154;&#32676;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#24773;&#24863;&#21644;&#20154;&#26684;&#35745;&#31639;&#65288;&#20197;&#19979;&#31616;&#31216;&#24773;&#24863;&#35745;&#31639;&#65289;&#20013;&#20010;&#24615;&#21270;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#23545;&#24773;&#24863;&#35745;&#31639;&#20013;&#20010;&#24615;&#21270;&#30340;&#26368;&#26032;&#26041;&#27861;&#36827;&#34892;&#20102;&#35843;&#26597;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#28085;&#30422;&#20102;&#35757;&#32451;&#25216;&#26415;&#21644;&#30446;&#26631;&#65292;&#20197;&#23454;&#29616;&#24773;&#24863;&#35745;&#31639;&#27169;&#22411;&#30340;&#20010;&#24615;&#21270;&#23450;&#21046;&#12290;&#25105;&#20204;&#23558;&#29616;&#26377;&#30340;&#26041;&#27861;&#20998;&#20026;&#19971;&#31867;&#65306;&#65288;1&#65289;&#38754;&#21521;&#29305;&#23450;&#30446;&#26631;&#30340;&#27169;&#22411;&#65292;&#65288;2&#65289;&#38754;&#21521;&#29305;&#23450;&#32676;&#20307;&#30340;&#27169;&#22411;&#65292;&#65288;3&#65289;&#22522;&#20110;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#65288;4&#65289;&#24494;&#35843;&#26041;&#27861;&#65292;&#65288;5&#65289;&#22810;&#20219;&#21153;&#23398;&#20064;&#65292;&#65288;6&#65289;&#29983;&#25104;&#24335;&#27169;&#22411;&#21644;&#65288;7&#65289;&#29305;&#24449;&#22686;&#24378;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#35843;&#26597;&#25991;&#29486;&#30340;&#32479;&#35745;&#20803;&#20998;&#26512;&#65292;&#20998;&#26512;&#20102;&#19981;&#21516;&#24773;&#24863;&#35745;&#31639;&#20219;&#21153;&#12289;&#20132;&#20114;&#27169;&#24335;&#12289;&#20132;&#20114;&#19978;&#19979;&#25991;&#20197;&#21450;&#25152;&#28041;&#21450;&#39046;&#22495;&#30340;&#26222;&#36941;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In computing, the aim of personalization is to train a model that caters to a specific individual or group of people by optimizing one or more performance metrics and adhering to specific constraints. In this paper, we discuss the need for personalization in affective and personality computing (hereinafter referred to as affective computing). We present a survey of state-of-the-art approaches for personalization in affective computing. Our review spans training techniques and objectives towards the personalization of affective computing models. We group existing approaches into seven categories: (1) Target-specific Models, (2) Group-specific Models, (3) Weighting-based Approaches, (4) Fine-tuning Approaches, (5) Multitask Learning, (6) Generative-based Models, and (7) Feature Augmentation. Additionally, we provide a statistical meta-analysis of the surveyed literature, analyzing the prevalence of different affective computing tasks, interaction modes, interaction contexts, and the leve
&lt;/p&gt;</description></item></channel></rss>