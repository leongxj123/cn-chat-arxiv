<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827; Latent Diffusion Model &#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861; ACE&#65292;&#20854;&#36890;&#36807;&#32479;&#19968;&#27169;&#24335;&#30340;&#39069;&#22806;&#35823;&#24046;&#26469;&#20419;&#20351;&#27169;&#22411;&#23398;&#20064;&#29305;&#23450;&#30340;&#20559;&#24046;&#65292;&#20174;&#32780;&#32988;&#36807;&#20102;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2310.04687</link><description>&lt;p&gt;
&#25913;&#36827;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Improving Adversarial Attacks on Latent Diffusion Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.04687
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827; Latent Diffusion Model &#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861; ACE&#65292;&#20854;&#36890;&#36807;&#32479;&#19968;&#27169;&#24335;&#30340;&#39069;&#22806;&#35823;&#24046;&#26469;&#20419;&#20351;&#27169;&#22411;&#23398;&#20064;&#29305;&#23450;&#30340;&#20559;&#24046;&#65292;&#20174;&#32780;&#32988;&#36807;&#20102;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545; Latent Diffusion Model (LDM)&#65292;&#36825;&#31181;&#26368;&#20808;&#36827;&#30340;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#65292;&#36827;&#34892;&#23545;&#25239;&#25915;&#20987;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#38450;&#27490; LDM &#22312;&#26410;&#32463;&#25480;&#26435;&#30340;&#22270;&#20687;&#19978;&#36827;&#34892;&#24694;&#24847;&#24494;&#35843;&#30340;&#20445;&#25252;&#25163;&#27573;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#25915;&#20987;&#20250;&#23545; LDM &#39044;&#27979;&#30340;&#23545;&#25239;&#26679;&#26412;&#30340;&#35780;&#20998;&#20989;&#25968;&#28155;&#21152;&#39069;&#22806;&#30340;&#35823;&#24046;&#12290;&#22312;&#36825;&#20123;&#23545;&#25239;&#26679;&#26412;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340; LDM &#23398;&#20064;&#36890;&#36807;&#19968;&#20010;&#20559;&#24046;&#38477;&#20302;&#35823;&#24046;&#65292;&#20174;&#32780;&#36973;&#21463;&#25915;&#20987;&#24182;&#20351;&#29992;&#20559;&#24046;&#39044;&#27979;&#35780;&#20998;&#20989;&#25968;&#12290;&#22522;&#20110;&#36825;&#19968;&#21160;&#24577;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#19968;&#33268;&#24471;&#20998;&#20989;&#25968;&#38169;&#35823;&#36827;&#34892;&#25915;&#20987;&#65288;ACE&#65289;&#26469;&#25913;&#36827; LDM &#30340;&#23545;&#25239;&#25915;&#20987;&#12290;ACE &#32479;&#19968;&#20102;&#28155;&#21152;&#21040;&#39044;&#27979;&#24471;&#20998;&#20989;&#25968;&#30340;&#39069;&#22806;&#35823;&#24046;&#30340;&#27169;&#24335;&#12290;&#36825;&#20419;&#20351;&#24494;&#35843;&#30340; LDM &#23398;&#20064;&#19982;&#23545;&#35780;&#20998;&#20989;&#25968;&#36827;&#34892;&#39044;&#27979;&#30340;&#20559;&#24046;&#23398;&#20064;&#30456;&#21516;&#30340;&#27169;&#24335;&#12290;&#28982;&#21518;&#25105;&#20204;&#24341;&#20837;&#19968;&#20010;&#31934;&#24515;&#35774;&#35745;&#30340;&#27169;&#24335;&#26469;&#25913;&#36827;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23545; LDM &#30340;&#23545;&#25239;&#25915;&#20987;&#20013;&#32988;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.04687v3 Announce Type: replace-cross  Abstract: Adversarial attacks on Latent Diffusion Model (LDM), the state-of-the-art image generative model, have been adopted as effective protection against malicious finetuning of LDM on unauthorized images. We show that these attacks add an extra error to the score function of adversarial examples predicted by LDM. LDM finetuned on these adversarial examples learns to lower the error by a bias, from which the model is attacked and predicts the score function with biases.   Based on the dynamics, we propose to improve the adversarial attack on LDM by Attacking with Consistent score-function Errors (ACE). ACE unifies the pattern of the extra error added to the predicted score function. This induces the finetuned LDM to learn the same pattern as a bias in predicting the score function. We then introduce a well-crafted pattern to improve the attack. Our method outperforms state-of-the-art methods in adversarial attacks on LDM.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;Transformer&#31070;&#32463;&#32593;&#32476;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#20174;&#25972;&#40784;&#25490;&#21015;&#30340;&#31034;&#33539;&#20013;&#29702;&#35299;&#21644;&#22797;&#21046;&#25972;&#27905;&#30340;&#27010;&#24565;&#65292;&#20174;&#32780;&#23454;&#29616;&#25972;&#29702;&#29289;&#21697;&#30340;&#21151;&#33021;&#12290;</title><link>https://arxiv.org/abs/2310.04566</link><description>&lt;p&gt;
Knolling Bot: &#20174;&#25972;&#27905;&#30340;&#31034;&#33539;&#20013;&#23398;&#20064;&#26426;&#22120;&#20154;&#23545;&#35937;&#25490;&#21015;
&lt;/p&gt;
&lt;p&gt;
Knolling Bot: Learning Robotic Object Arrangement from Tidy Demonstrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.04566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;Transformer&#31070;&#32463;&#32593;&#32476;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#20174;&#25972;&#40784;&#25490;&#21015;&#30340;&#31034;&#33539;&#20013;&#29702;&#35299;&#21644;&#22797;&#21046;&#25972;&#27905;&#30340;&#27010;&#24565;&#65292;&#20174;&#32780;&#23454;&#29616;&#25972;&#29702;&#29289;&#21697;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#22336;&#65306;arXiv:2310.04566v2  &#20844;&#21578;&#31867;&#22411;&#65306;replace-cross  &#25688;&#35201;&#65306;&#35299;&#20915;&#23478;&#24237;&#31354;&#38388;&#20013;&#25955;&#20081;&#29289;&#21697;&#30340;&#25972;&#29702;&#25361;&#25112;&#21463;&#21040;&#25972;&#27905;&#24615;&#30340;&#22810;&#26679;&#24615;&#21644;&#20027;&#35266;&#24615;&#30340;&#22797;&#26434;&#24615;&#24433;&#21709;&#12290;&#27491;&#22914;&#20154;&#31867;&#35821;&#35328;&#30340;&#22797;&#26434;&#24615;&#20801;&#35768;&#21516;&#19968;&#29702;&#24565;&#30340;&#22810;&#31181;&#34920;&#36798;&#19968;&#26679;&#65292;&#23478;&#24237;&#25972;&#27905;&#20559;&#22909;&#21644;&#32452;&#32455;&#27169;&#24335;&#21464;&#21270;&#24191;&#27867;&#65292;&#22240;&#27492;&#39044;&#35774;&#29289;&#20307;&#20301;&#32622;&#23558;&#38480;&#21046;&#23545;&#26032;&#29289;&#20307;&#21644;&#29615;&#22659;&#30340;&#36866;&#24212;&#24615;&#12290;&#21463;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#36827;&#23637;&#21551;&#21457;&#65292;&#26412;&#25991;&#24341;&#20837;&#19968;&#31181;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#20174;&#25972;&#27905;&#24067;&#23616;&#30340;&#31034;&#33539;&#20013;&#29702;&#35299;&#21644;&#22797;&#21046;&#25972;&#27905;&#30340;&#27010;&#24565;&#65292;&#31867;&#20284;&#20110;&#20351;&#29992;&#20250;&#35805;&#25968;&#25454;&#38598;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#12290;&#25105;&#20204;&#21033;&#29992;&#19968;&#20010;Transformer&#31070;&#32463;&#32593;&#32476;&#26469;&#39044;&#27979;&#21518;&#32493;&#29289;&#20307;&#30340;&#25670;&#25918;&#20301;&#32622;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#8220;&#25972;&#29702;&#8221;&#31995;&#32479;&#65292;&#21033;&#29992;&#26426;&#26800;&#33218;&#21644;RGB&#30456;&#26426;&#22312;&#26700;&#23376;&#19978;&#32452;&#32455;&#19981;&#21516;&#22823;&#23567;&#21644;&#25968;&#37327;&#30340;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.04566v2 Announce Type: replace-cross  Abstract: Addressing the challenge of organizing scattered items in domestic spaces is complicated by the diversity and subjective nature of tidiness. Just as the complexity of human language allows for multiple expressions of the same idea, household tidiness preferences and organizational patterns vary widely, so presetting object locations would limit the adaptability to new objects and environments. Inspired by advancements in natural language processing (NLP), this paper introduces a self-supervised learning framework that allows robots to understand and replicate the concept of tidiness from demonstrations of well-organized layouts, akin to using conversational datasets to train Large Language Models(LLM). We leverage a transformer neural network to predict the placement of subsequent objects. We demonstrate a ``knolling'' system with a robotic arm and an RGB camera to organize items of varying sizes and quantities on a table. Our 
&lt;/p&gt;</description></item></channel></rss>