<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#34394;&#25311;&#24322;&#24120;&#20540;&#26469;&#25913;&#21892;&#26080;&#38656;&#22238;&#39038;&#30340;&#31867;&#22686;&#37327;&#23398;&#20064;&#36807;&#31243;&#20013;&#19981;&#21516;&#20219;&#21153;&#38388;&#30340;&#31867;&#21035;&#28151;&#28102;&#38382;&#39064;&#65292;&#24182;&#19988;&#28040;&#38500;&#20102;&#39069;&#22806;&#30340;&#25552;&#31034;&#26597;&#35810;&#21644;&#32452;&#21512;&#35745;&#31639;&#24320;&#38144;&#12290;</title><link>https://arxiv.org/abs/2402.04129</link><description>&lt;p&gt;
OVOR&#65306;&#19968;&#31181;&#20351;&#29992;&#34394;&#25311;&#24322;&#24120;&#20540;&#27491;&#21017;&#21270;&#30340;OnePrompt&#26041;&#27861;&#65292;&#23454;&#29616;&#26080;&#38656;&#22238;&#39038;&#30340;&#31867;&#22686;&#37327;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04129
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#34394;&#25311;&#24322;&#24120;&#20540;&#26469;&#25913;&#21892;&#26080;&#38656;&#22238;&#39038;&#30340;&#31867;&#22686;&#37327;&#23398;&#20064;&#36807;&#31243;&#20013;&#19981;&#21516;&#20219;&#21153;&#38388;&#30340;&#31867;&#21035;&#28151;&#28102;&#38382;&#39064;&#65292;&#24182;&#19988;&#28040;&#38500;&#20102;&#39069;&#22806;&#30340;&#25552;&#31034;&#26597;&#35810;&#21644;&#32452;&#21512;&#35745;&#31639;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#21644;&#21487;&#23398;&#20064;&#30340;&#25552;&#31034;&#65292;&#22312;&#26080;&#38656;&#22238;&#39038;&#30340;&#31867;&#22686;&#37327;&#23398;&#20064;&#65288;CIL&#65289;&#35774;&#32622;&#20013;&#21487;&#20197;&#23454;&#29616;&#27604;&#33879;&#21517;&#30340;&#22522;&#20110;&#22238;&#39038;&#30340;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#26080;&#38656;&#22238;&#39038;&#30340;CIL&#26041;&#27861;&#22312;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#30340;&#31867;&#21035;&#26102;&#36935;&#21040;&#22256;&#38590;&#65292;&#22240;&#20026;&#23427;&#20204;&#24182;&#26410;&#19968;&#21516;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34394;&#25311;&#24322;&#24120;&#20540;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#32039;&#32553;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#36793;&#30028;&#65292;&#20943;&#36731;&#19981;&#21516;&#20219;&#21153;&#38388;&#31867;&#21035;&#30340;&#28151;&#28102;&#12290;&#26368;&#36817;&#30340;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#19968;&#20010;&#23384;&#20648;&#21508;&#20219;&#21153;&#29305;&#23450;&#25552;&#31034;&#30340;&#38598;&#21512;&#65292;&#20197;&#38450;&#27490;&#26032;&#20219;&#21153;&#30340;&#30693;&#35782;&#35206;&#30422;&#20808;&#21069;&#20219;&#21153;&#30340;&#30693;&#35782;&#65292;&#20174;&#32780;&#23548;&#33268;&#39069;&#22806;&#30340;&#26597;&#35810;&#21644;&#32452;&#21512;&#36866;&#24403;&#25552;&#31034;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#25105;&#20204;&#22312;&#35770;&#25991;&#20013;&#25581;&#31034;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#39069;&#22806;&#24320;&#38144;&#32780;&#19981;&#29306;&#29298;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#31616;&#21270;&#30340;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#21487;&#20197;&#36798;&#21040;&#19982;&#20808;&#21069;&#26368;&#26032;&#29366;&#24577;-of-the-art&#26041;&#27861;&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent works have shown that by using large pre-trained models along with learnable prompts, rehearsal-free methods for class-incremental learning (CIL) settings can achieve superior performance to prominent rehearsal-based ones. Rehearsal-free CIL methods struggle with distinguishing classes from different tasks, as those are not trained together. In this work we propose a regularization method based on virtual outliers to tighten decision boundaries of the classifier, such that confusion of classes among different tasks is mitigated. Recent prompt-based methods often require a pool of task-specific prompts, in order to prevent overwriting knowledge of previous tasks with that of the new task, leading to extra computation in querying and composing an appropriate prompt from the pool. This additional cost can be eliminated, without sacrificing accuracy, as we reveal in the paper. We illustrate that a simplified prompt-based method can achieve results comparable to previous state-of-the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#30690;&#37327;&#37327;&#21270;&#30340;&#26032;&#23545;&#25239;&#24615;&#38450;&#24481;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#19978;&#30340;&#34920;&#29616;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.13651</link><description>&lt;p&gt;
&#22522;&#20110;&#30690;&#37327;&#37327;&#21270;&#30340;&#23545;&#25239;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Adversarial Defenses via Vector Quantization. (arXiv:2305.13651v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13651
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#30690;&#37327;&#37327;&#21270;&#30340;&#26032;&#23545;&#25239;&#24615;&#38450;&#24481;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#19978;&#30340;&#34920;&#29616;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#31163;&#25955;&#21270;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#21033;&#29992;&#30690;&#37327;&#37327;&#21270;&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#26041;&#27861;&#65292;&#20998;&#21035;&#31216;&#20026;pRD&#21644;swRD&#12290;&#36825;&#20123;&#26041;&#27861;&#19981;&#20165;&#22312;&#35777;&#26126;&#20934;&#30830;&#24230;&#26041;&#38754;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#19988;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#20204;&#30340;&#34920;&#29616;&#19982;&#24403;&#21069;&#23545;&#25239;&#38450;&#24481;&#25216;&#26415;&#30456;&#24403;&#29978;&#33267;&#26356;&#20248;&#31168;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#21040;&#19968;&#31181;&#29256;&#26412;&#65292;&#20801;&#35768;&#23545;&#30446;&#26631;&#20998;&#31867;&#22120;&#36827;&#34892;&#36827;&#19968;&#27493;&#35757;&#32451;&#65292;&#24182;&#23637;&#31034;&#20986;&#36827;&#19968;&#27493;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building upon Randomized Discretization, we develop two novel adversarial defenses against white-box PGD attacks, utilizing vector quantization in higher dimensional spaces. These methods, termed pRD and swRD, not only offer a theoretical guarantee in terms of certified accuracy, they are also shown, via abundant experiments, to perform comparably or even superior to the current art of adversarial defenses. These methods can be extended to a version that allows further training of the target classifier and demonstrates further improved performance.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#20998;&#21106;&#20219;&#21153;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20845;&#20010;&#24230;&#37327;&#26469;&#35780;&#20272;&#22522;&#20110;&#26799;&#24230;&#12289;&#20256;&#25773;&#25110;&#24178;&#25200;&#30340;&#20107;&#21518;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#26102;&#38388;&#24207;&#21015;&#30340;&#35299;&#37322;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#20449;&#24230;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.07861</link><description>&lt;p&gt;
&#19981;&#35201;&#35823;&#20250;&#25105;&#65306;&#22914;&#20309;&#23558;&#28145;&#24230;&#35270;&#35273;&#35299;&#37322;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Don't Get Me Wrong: How to Apply Deep Visual Interpretations to Time Series. (arXiv:2203.07861v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07861
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#20998;&#21106;&#20219;&#21153;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20845;&#20010;&#24230;&#37327;&#26469;&#35780;&#20272;&#22522;&#20110;&#26799;&#24230;&#12289;&#20256;&#25773;&#25110;&#24178;&#25200;&#30340;&#20107;&#21518;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#26102;&#38388;&#24207;&#21015;&#30340;&#35299;&#37322;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#20449;&#24230;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#27491;&#30830;&#35299;&#37322;&#21644;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38750;&#24120;&#37325;&#35201;&#12290;&#38024;&#23545;&#22270;&#20687;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#35299;&#37322;&#24615;&#35270;&#35273;&#35299;&#37322;&#26041;&#27861;&#20801;&#35768;&#39046;&#22495;&#19987;&#23478;&#39564;&#35777;&#21644;&#29702;&#35299;&#20960;&#20046;&#20219;&#20309;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#24403;&#25512;&#24191;&#21040;&#20219;&#24847;&#26102;&#38388;&#24207;&#21015;&#26102;&#65292;&#23427;&#20204;&#22312;&#26412;&#36136;&#19978;&#26356;&#21152;&#22797;&#26434;&#21644;&#22810;&#26679;&#21270;&#12290;&#19968;&#20010;&#21487;&#35270;&#21270;&#35299;&#37322;&#26159;&#21542;&#35299;&#37322;&#20102;&#26377;&#25928;&#30340;&#25512;&#29702;&#25110;&#25429;&#25417;&#20102;&#23454;&#38469;&#29305;&#24449;&#26159;&#38590;&#20197;&#21028;&#26029;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#38656;&#35201;&#23458;&#35266;&#35780;&#20272;&#26469;&#33719;&#24471;&#21487;&#20449;&#30340;&#36136;&#37327;&#25351;&#26631;&#65292;&#32780;&#19981;&#26159;&#30450;&#30446;&#20449;&#20219;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21253;&#25324;&#20845;&#20010;&#27491;&#20132;&#24230;&#37327;&#65292;&#29992;&#20110;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#20998;&#21106;&#20219;&#21153;&#30340;&#22522;&#20110;&#26799;&#24230;&#12289;&#20256;&#25773;&#25110;&#24178;&#25200;&#30340;&#20107;&#21518;&#35270;&#35273;&#35299;&#37322;&#26041;&#27861;&#12290;&#23454;&#39564;&#30740;&#31350;&#21253;&#25324;&#20102;&#24120;&#35265;&#30340;&#26102;&#38388;&#24207;&#21015;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20061;&#31181;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;UCR r&#31561;&#22810;&#26679;&#30340;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;&#36825;&#20123;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The correct interpretation and understanding of deep learning models are essential in many applications. Explanatory visual interpretation approaches for image, and natural language processing allow domain experts to validate and understand almost any deep learning model. However, they fall short when generalizing to arbitrary time series, which is inherently less intuitive and more diverse. Whether a visualization explains valid reasoning or captures the actual features is difficult to judge. Hence, instead of blind trust, we need an objective evaluation to obtain trustworthy quality metrics. We propose a framework of six orthogonal metrics for gradient-, propagation- or perturbation-based post-hoc visual interpretation methods for time series classification and segmentation tasks. An experimental study includes popular neural network architectures for time series and nine visual interpretation methods. We evaluate the visual interpretation methods with diverse datasets from the UCR r
&lt;/p&gt;</description></item></channel></rss>