<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#35821;&#35328;&#23545;&#40784;&#30340;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#27604;&#32431;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#26356;&#26377;&#25928;&#22320;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.09377</link><description>&lt;p&gt;
&#23545;&#40784;&#35821;&#35328;&#30340;&#35270;&#35273;&#34920;&#31034;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks. (arXiv:2306.09377v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09377
&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#23545;&#40784;&#30340;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#27604;&#32431;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#26356;&#26377;&#25928;&#22320;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#20855;&#22791;&#35782;&#21035;&#21644;&#27010;&#25324;&#33258;&#28982;&#29289;&#20307;&#30456;&#20851;&#29305;&#24449;&#30340;&#33021;&#21147;&#65292;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#26377;&#25152;&#24110;&#21161;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#31181;&#29616;&#35937;&#24182;&#30830;&#23450;&#26368;&#26377;&#25928;&#30340;&#34920;&#31034;&#26041;&#24335;&#20197;&#39044;&#27979;&#20154;&#31867;&#34892;&#20026;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20004;&#20010;&#28041;&#21450;&#31867;&#21035;&#23398;&#20064;&#21644;&#22870;&#21169;&#23398;&#20064;&#30340;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20351;&#29992;&#36924;&#30495;&#30340;&#22270;&#20687;&#20316;&#20026;&#21050;&#28608;&#29289;&#65292;&#24182;&#35201;&#27714;&#21442;&#19982;&#32773;&#22522;&#20110;&#25152;&#26377;&#35797;&#39564;&#30340;&#26032;&#22411;&#21050;&#28608;&#29289;&#20316;&#20986;&#20934;&#30830;&#30340;&#20915;&#31574;&#65292;&#22240;&#27492;&#38656;&#35201;&#27867;&#21270;&#12290;&#22312;&#20004;&#20010;&#20219;&#21153;&#20013;&#65292;&#24213;&#23618;&#35268;&#21017;&#26159;&#20351;&#29992;&#20154;&#31867;&#30456;&#20284;&#24615;&#21028;&#26029;&#25552;&#21462;&#30340;&#21050;&#28608;&#32500;&#24230;&#29983;&#25104;&#30340;&#31616;&#21333;&#32447;&#24615;&#20989;&#25968;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#21442;&#19982;&#32773;&#22312;&#20960;&#27425;&#35797;&#39564;&#20869;&#23601;&#25104;&#21151;&#22320;&#30830;&#23450;&#20102;&#30456;&#20851;&#30340;&#21050;&#28608;&#29305;&#24449;&#65292;&#35777;&#26126;&#20102;&#26377;&#25928;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#22411;&#27604;&#36739;&#65292;&#35780;&#20272;&#20102;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34920;&#31034;&#23545;&#20154;&#31867;&#36873;&#25321;&#30340;&#36880;&#27425;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#65288;&#22914;&#35821;&#35328;&#24314;&#27169;&#21644;&#26426;&#22120;&#32763;&#35793;&#65289;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#31034;&#20248;&#20110;&#35270;&#35273;&#20219;&#21153;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#31034;&#65292;&#34920;&#26126;&#23545;&#40784;&#35821;&#35328;&#30340;&#35270;&#35273;&#34920;&#31034;&#21487;&#33021;&#26356;&#26377;&#25928;&#22320;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Humans possess the ability to identify and generalize relevant features of natural objects, which aids them in various situations. To investigate this phenomenon and determine the most effective representations for predicting human behavior, we conducted two experiments involving category learning and reward learning. Our experiments used realistic images as stimuli, and participants were tasked with making accurate decisions based on novel stimuli for all trials, thereby necessitating generalization. In both tasks, the underlying rules were generated as simple linear functions using stimulus dimensions extracted from human similarity judgments. Notably, participants successfully identified the relevant stimulus features within a few trials, demonstrating effective generalization. We performed an extensive model comparison, evaluating the trial-by-trial predictive accuracy of diverse deep learning models' representations of human choices. Intriguingly, representations from models train
&lt;/p&gt;</description></item></channel></rss>