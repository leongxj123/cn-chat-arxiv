<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#65292;&#30452;&#25509;&#20851;&#32852;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#65292;&#36890;&#36807;&#20351;&#29992;&#21028;&#21035;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#38544;&#24335;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20844;&#24335;&#12289;&#38590;&#20197;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#26080;&#20449;&#24687;&#20808;&#39564;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.01184</link><description>&lt;p&gt;
&#36890;&#36807;&#37096;&#20998;&#26631;&#31614;&#20808;&#39564;&#30340;&#38544;&#24335;&#21028;&#21035;&#36924;&#36817;&#36827;&#34892;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior. (arXiv:2308.01184v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01184
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#65292;&#30452;&#25509;&#20851;&#32852;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#65292;&#36890;&#36807;&#20351;&#29992;&#21028;&#21035;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#38544;&#24335;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20844;&#24335;&#12289;&#38590;&#20197;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#26080;&#20449;&#24687;&#20808;&#39564;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#24050;&#32463;&#20351;&#29992;&#20102;&#21028;&#21035;&#27169;&#22411;&#21644;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#30740;&#31350;&#12290;&#23613;&#31649;&#21028;&#21035;&#27169;&#22411;&#30001;&#20110;&#20854;&#31616;&#21333;&#30340;&#24314;&#27169;&#21644;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#35757;&#32451;&#36807;&#31243;&#32780;&#22312;&#35813;&#39046;&#22495;&#21344;&#20027;&#23548;&#22320;&#20301;&#65292;&#20294;&#29983;&#25104;&#27169;&#22411;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#20998;&#35299;&#24178;&#20928;&#21644;&#22122;&#22768;&#26631;&#31614;&#65292;&#24182;&#25913;&#21892;&#26631;&#31614;&#36716;&#25442;&#30697;&#38453;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#26041;&#27861;&#20351;&#29992;&#20102;&#22797;&#26434;&#30340;&#20844;&#24335;&#26469;&#26368;&#22823;&#21270;&#22122;&#22768;&#26631;&#31614;&#21644;&#25968;&#25454;&#30340;&#32852;&#21512;&#20284;&#28982;&#65292;&#36825;&#21482;&#38388;&#25509;&#20248;&#21270;&#20102;&#19982;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#30456;&#20851;&#30340;&#24863;&#20852;&#36259;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#24456;&#38590;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#20542;&#21521;&#20110;&#20351;&#29992;&#26080;&#20449;&#24687;&#30340;&#24178;&#20928;&#26631;&#31614;&#20808;&#39564;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#19977;&#20010;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#20248;&#21270;&#26041;&#27861;&#65292;&#30452;&#25509;&#20851;&#32852;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#20351;&#29992;&#21028;&#21035;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#38544;&#24335;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The learning with noisy labels has been addressed with both discriminative and generative models. Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix. However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels. Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors. In this paper, we propose a new generative noisy-label learning approach that addresses these three issues. First, we propose a new model optimisation that directly associates data and clean labels. Second, the generative model is implicitly estimated using a discriminative m
&lt;/p&gt;</description></item></channel></rss>