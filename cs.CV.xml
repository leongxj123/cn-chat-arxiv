<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#20934;&#29289;&#20307;&#26816;&#27979;&#22120;&#22312;&#22797;&#26434;&#30340;&#24037;&#19994;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24212;&#29992;&#20013;&#30340;&#27169;&#25311;&#21040;&#30495;&#23454;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.04809</link><description>&lt;p&gt;
&#30740;&#31350;&#21512;&#25104;&#35757;&#32451;&#25968;&#25454;&#23545;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24037;&#19994;&#24212;&#29992;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Investigation of the Impact of Synthetic Training Data in the Industrial Application of Terminal Strip Object Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#20934;&#29289;&#20307;&#26816;&#27979;&#22120;&#22312;&#22797;&#26434;&#30340;&#24037;&#19994;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24212;&#29992;&#20013;&#30340;&#27169;&#25311;&#21040;&#30495;&#23454;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#19994;&#21046;&#36896;&#20013;&#65292;&#23384;&#22312;&#35768;&#22810;&#26816;&#26597;&#25110;&#26816;&#27979;&#29305;&#23450;&#23545;&#35937;&#30340;&#20219;&#21153;&#65292;&#30446;&#21069;&#36825;&#20123;&#20219;&#21153;&#36890;&#24120;&#30001;&#20154;&#24037;&#25110;&#32463;&#20856;&#22270;&#20687;&#22788;&#29702;&#26041;&#27861;&#25191;&#34892;&#12290;&#22240;&#27492;&#65292;&#22312;&#24037;&#19994;&#29615;&#22659;&#24341;&#20837;&#26368;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26377;&#21487;&#33021;&#25552;&#39640;&#29983;&#20135;&#25928;&#29575;&#24182;&#23454;&#29616;&#26032;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#25910;&#38598;&#21644;&#26631;&#35760;&#36275;&#22815;&#30340;&#25968;&#25454;&#36890;&#24120;&#26159;&#22256;&#38590;&#30340;&#65292;&#36825;&#20351;&#24471;&#36825;&#31867;&#39033;&#30446;&#30340;&#23454;&#26045;&#21464;&#24471;&#22797;&#26434;&#12290;&#22240;&#27492;&#65292;&#22270;&#20687;&#21512;&#25104;&#26041;&#27861;&#36890;&#24120;&#29992;&#20110;&#20174;3D&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#33258;&#21160;&#26631;&#27880;&#36825;&#20123;&#25968;&#25454;&#65292;&#23613;&#31649;&#36825;&#20250;&#23548;&#33268;&#19968;&#20010;&#27169;&#25311;&#21040;&#30495;&#23454;&#39046;&#22495;&#24046;&#36317;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#20934;&#29289;&#20307;&#26816;&#27979;&#22120;&#22312;&#22797;&#26434;&#30340;&#24037;&#19994;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24212;&#29992;&#20013;&#30340;&#27169;&#25311;&#21040;&#30495;&#23454;&#27867;&#21270;&#24615;&#33021;&#12290;&#36890;&#36807;&#32467;&#21512;&#39046;&#22495;&#38543;&#26426;&#21270;&#21644;&#39046;&#22495;&#30693;&#35782;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#22270;&#20687;&#21512;&#25104;&#27969;&#27700;&#32447;&#65292;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04809v1 Announce Type: cross  Abstract: In industrial manufacturing, numerous tasks of visually inspecting or detecting specific objects exist that are currently performed manually or by classical image processing methods. Therefore, introducing recent deep learning models to industrial environments holds the potential to increase productivity and enable new applications. However, gathering and labeling sufficient data is often intractable, complicating the implementation of such projects. Hence, image synthesis methods are commonly used to generate synthetic training data from 3D models and annotate them automatically, although it results in a sim-to-real domain gap. In this paper, we investigate the sim-to-real generalization performance of standard object detectors on the complex industrial application of terminal strip object detection. Combining domain randomization and domain knowledge, we created an image synthesis pipeline for automatically generating the training da
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#20219;&#21153;&#21644;&#26041;&#27861;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2307.14397</link><description>&lt;p&gt;
&#20851;&#20110;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#29983;&#25104;&#24314;&#27169;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot. (arXiv:2307.14397v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#20219;&#21153;&#21644;&#26041;&#27861;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#29983;&#25104;&#24314;&#27169;&#26088;&#22312;&#23398;&#20064;&#29983;&#25104;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#32479;&#35745;&#30456;&#20284;&#30340;&#26032;&#25968;&#25454;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#31216;&#20026;&#25968;&#25454;&#32422;&#26463;&#19979;&#30340;&#29983;&#25104;&#24314;&#27169;&#65288;GM-DC&#65289;&#12290;&#36825;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20027;&#39064;&#65292;&#24403;&#25968;&#25454;&#33719;&#21462;&#20855;&#26377;&#25361;&#25112;&#24615;&#26102;&#65292;&#20363;&#22914;&#21307;&#30103;&#24212;&#29992;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32972;&#26223;&#12289;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#20998;&#31867;&#20307;&#31995;&#65306;&#19968;&#20010;&#26159;GM-DC&#20219;&#21153;&#20998;&#31867;&#65292;&#21478;&#19968;&#20010;&#26159;GM-DC&#26041;&#27861;&#20998;&#31867;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;GM-DC&#20219;&#21153;&#21644;&#26041;&#27861;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#30740;&#31350;&#31354;&#30333;&#12289;&#30740;&#31350;&#36235;&#21183;&#21644;&#26410;&#26469;&#25506;&#32034;&#30340;&#28508;&#22312;&#36884;&#24452;&#12290;&#39033;&#30446;&#32593;&#31449;&#65306;https://gmdc-survey.github.io&#12290;
&lt;/p&gt;
&lt;p&gt;
In machine learning, generative modeling aims to learn to generate new data statistically similar to the training data distribution. In this paper, we survey learning generative models under limited data, few shots and zero shot, referred to as Generative Modeling under Data Constraint (GM-DC). This is an important topic when data acquisition is challenging, e.g. healthcare applications. We discuss background, challenges, and propose two taxonomies: one on GM-DC tasks and another on GM-DC approaches. Importantly, we study interactions between different GM-DC tasks and approaches. Furthermore, we highlight research gaps, research trends, and potential avenues for future exploration. Project website: https://gmdc-survey.github.io.
&lt;/p&gt;</description></item></channel></rss>