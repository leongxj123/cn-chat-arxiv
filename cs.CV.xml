<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>MIMIR&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#20013;&#21033;&#29992;&#36974;&#32617;&#22270;&#20687;&#24314;&#27169;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#19981;&#21516;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#22686;&#24378;Vision Transformers&#65288;ViTs&#65289;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.04960</link><description>&lt;p&gt;
MIMIR: &#22522;&#20110;&#20114;&#20449;&#24687;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#36974;&#32617;&#22270;&#20687;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness. (arXiv:2312.04960v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.04960
&lt;/p&gt;
&lt;p&gt;
MIMIR&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#20013;&#21033;&#29992;&#36974;&#32617;&#22270;&#20687;&#24314;&#27169;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#19981;&#21516;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#22686;&#24378;Vision Transformers&#65288;ViTs&#65289;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#21464;&#21387;&#22120;&#65288;ViTs&#65289;&#30456;&#23545;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#20294;ViTs&#20063;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;&#23545;&#25239;&#24615;&#35757;&#32451;&#26159;&#24314;&#31435;&#24378;&#22823;&#30340;CNN&#27169;&#22411;&#30340;&#26368;&#25104;&#21151;&#26041;&#27861;&#20043;&#19968;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#22522;&#20110;ViTs&#21644;CNNs&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#26032;&#26041;&#27861;&#65292;&#22914;&#26356;&#22909;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#38450;&#27490;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#21333;&#20010;&#22359;&#19978;&#65292;&#25110;&#20002;&#24323;&#20302;&#27880;&#24847;&#21147;&#30340;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#36981;&#24490;&#20256;&#32479;&#30417;&#30563;&#23545;&#25239;&#35757;&#32451;&#30340;&#35774;&#35745;&#65292;&#38480;&#21046;&#20102;&#23545;ViTs&#30340;&#23545;&#25239;&#35757;&#32451;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38450;&#24481;&#26041;&#27861;MIMIR&#65292;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#20013;&#30340;&#36974;&#32617;&#22270;&#20687;&#24314;&#27169;&#26500;&#24314;&#19981;&#21516;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26041;&#27861;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#33258;&#32534;&#30721;&#22120;&#65292;&#23427;&#25509;&#21463;&#23545;&#25239;&#24615;&#20363;&#23376;&#20316;&#20026;&#36755;&#20837;&#65292;&#20294;&#23558;&#24178;&#20928;&#30340;&#20363;&#23376;&#20316;&#20026;&#24314;&#27169;&#30446;&#26631;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#20114;&#20449;&#24687;&#65288;MI&#65289;
&lt;/p&gt;
&lt;p&gt;
Vision Transformers (ViTs) achieve superior performance on various tasks compared to convolutional neural networks (CNNs), but ViTs are also vulnerable to adversarial attacks. Adversarial training is one of the most successful methods to build robust CNN models. Thus, recent works explored new methodologies for adversarial training of ViTs based on the differences between ViTs and CNNs, such as better training strategies, preventing attention from focusing on a single block, or discarding low-attention embeddings. However, these methods still follow the design of traditional supervised adversarial training, limiting the potential of adversarial training on ViTs. This paper proposes a novel defense method, MIMIR, which aims to build a different adversarial training methodology by utilizing Masked Image Modeling at pre-training. We create an autoencoder that accepts adversarial examples as input but takes the clean examples as the modeling target. Then, we create a mutual information (MI
&lt;/p&gt;</description></item></channel></rss>