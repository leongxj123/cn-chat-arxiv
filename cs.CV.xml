<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#28145;&#24230;&#22686;&#24378;&#26159;&#19968;&#31181;&#21033;&#29992;dropout&#25110;PCA&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#36716;&#25442;&#30446;&#26631;&#23618;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#25913;&#21892;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#22312;Transformers&#12289;ResNets&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#31561;&#22522;&#30784;&#27169;&#22411;&#19978;&#65292;&#36890;&#36807;&#28145;&#24230;&#22686;&#24378;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#20294;&#22312;&#30417;&#30563;&#38382;&#39064;&#19978;&#25928;&#26524;&#30456;&#21453;&#12290;</title><link>https://arxiv.org/abs/2303.14537</link><description>&lt;p&gt;
&#28145;&#24230;&#22686;&#24378;&#65306;&#22312;&#28608;&#27963;&#31354;&#38388;&#20013;&#20351;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Deep Augmentation: Self-Supervised Learning with Transformations in Activation Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.14537
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#22686;&#24378;&#26159;&#19968;&#31181;&#21033;&#29992;dropout&#25110;PCA&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#36716;&#25442;&#30446;&#26631;&#23618;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#25913;&#21892;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#22312;Transformers&#12289;ResNets&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#31561;&#22522;&#30784;&#27169;&#22411;&#19978;&#65292;&#36890;&#36807;&#28145;&#24230;&#22686;&#24378;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#20294;&#22312;&#30417;&#30563;&#38382;&#39064;&#19978;&#25928;&#26524;&#30456;&#21453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#28145;&#24230;&#22686;&#24378;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36749;&#23398;&#25110;PCA&#26469;&#36716;&#25442;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#30446;&#26631;&#23618;&#65292;&#20197;&#25552;&#39640;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#22270;&#23398;&#20064;&#20013;&#30340;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#26469;&#23637;&#31034;&#28145;&#24230;&#22686;&#24378;&#12290; &#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#23545;&#27604;&#23398;&#20064;&#30340;&#22522;&#30784;&#27169;&#22411;&#20013;&#65292;&#22914;Transformers&#12289;ResNets&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#19978;&#28145;&#24230;&#22686;&#24378;&#33021;&#22815;&#24102;&#26469;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#20294;&#22312;&#30456;&#24212;&#30340;&#30417;&#30563;&#38382;&#39064;&#19978;&#35266;&#23519;&#21040;&#30456;&#21453;&#30340;&#25928;&#26524;&#12290; &#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#28145;&#24230;&#22686;&#24378;&#20943;&#36731;&#20102;&#23618;&#20043;&#38388;&#30340;&#30456;&#20114;&#36866;&#24212;&#65292;&#21363;"&#23849;&#28291;"&#24418;&#24335;&#30340;&#38382;&#39064;&#12290; &#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#21046;&#23450;&#20102;&#19968;&#31181;&#36873;&#25321;&#30446;&#26631;&#23618;&#30340;&#26041;&#27861;&#65307;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#29992;&#28145;&#24230;&#22686;&#24378;&#23450;&#20301;&#26356;&#28145;&#23618;&#27425;&#30340;&#23618;&#35201;&#20248;&#20110;&#22686;&#24378;&#36755;&#20837;&#25968;&#25454;&#12290; &#36825;&#31181;&#26041;&#27861;&#30340;&#31616;&#21333;&#32593;&#32476;&#21644;&#27169;&#24577;&#26080;&#20851;&#24615;&#20351;&#20854;
&lt;/p&gt;
&lt;p&gt;
arXiv:2303.14537v2 Announce Type: replace-cross  Abstract: We introduce Deep Augmentation, an approach to implicit data augmentation using dropout or PCA to transform a targeted layer within a neural network to improve performance and generalization. We demonstrate Deep Augmentation through extensive experiments on contrastive learning tasks in NLP, computer vision, and graph learning. We observe substantial performance gains with Transformers, ResNets, and Graph Neural Networks as the underlying models in contrastive learning, but observe inverse effects on the corresponding supervised problems. Our analysis suggests that Deep Augmentation alleviates co-adaption between layers, a form of "collapse." We use this observation to formulate a method for selecting which layer to target; in particular, our experimentation reveals that targeting deeper layers with Deep Augmentation outperforms augmenting the input data. The simple network- and modality-agnostic nature of this approach enables
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65292;&#21363;&#20854;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#65306;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#65292;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#30410;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#12290;</title><link>http://arxiv.org/abs/2306.04542</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65306;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65292;&#21363;&#20854;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#65306;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#65292;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#30410;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36880;&#28176;&#28155;&#21152;&#21644;&#21024;&#38500;&#22122;&#22768;&#26469;&#23398;&#20064;&#35757;&#32451;&#25968;&#25454;&#30340;&#28508;&#22312;&#20998;&#24067;&#20197;&#29983;&#25104;&#25968;&#25454;&#12290;&#25193;&#25955;&#27169;&#22411;&#30340;&#32452;&#25104;&#37096;&#20998;&#24050;&#32463;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#65292;&#35768;&#22810;&#35774;&#35745;&#36873;&#25321;&#34987;&#25552;&#20986;&#12290;&#29616;&#26377;&#30340;&#35780;&#35770;&#20027;&#35201;&#20851;&#27880;&#39640;&#23618;&#27425;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23545;&#32452;&#20214;&#30340;&#35774;&#35745;&#22522;&#30784;&#35206;&#30422;&#36739;&#23569;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20840;&#38754;&#32780;&#36830;&#36143;&#30340;&#32508;&#36848;&#65292;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#32452;&#20214;&#35774;&#35745;&#36873;&#25321;&#36827;&#34892;&#20998;&#26512;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32508;&#36848;&#25353;&#29031;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#36827;&#34892;&#32452;&#32455;&#65292;&#21363;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#25552;&#20379;&#25193;&#25955;&#27169;&#22411;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#65292;&#26377;&#21161;&#20110;&#26410;&#26469;&#30740;&#31350;&#20998;&#26512;&#20010;&#20307;&#32452;&#20214;&#12289;&#35774;&#35745;&#36873;&#25321;&#30340;&#36866;&#29992;&#24615;&#20197;&#21450;&#25193;&#25955;&#27169;&#22411;&#30340;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are generative models, which gradually add and remove noise to learn the underlying distribution of training data for data generation. The components of diffusion models have gained significant attention with many design choices proposed. Existing reviews have primarily focused on higher-level solutions, thereby covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review on component-wise design choices in diffusion models. Specifically, we organize this review according to their three key components, namely the forward process, the reverse process, and the sampling procedure. This allows us to provide a fine-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the applicability of design choices, and the implementation of diffusion models.
&lt;/p&gt;</description></item></channel></rss>