<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#20171;&#32461;&#20102;&#31616;&#21270;&#21518;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#65288;DSB&#65289;&#65292;&#36890;&#36807;&#19982;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGM&#65289;&#30340;&#32479;&#19968;&#35299;&#20915;&#20102;&#22797;&#26434;&#25968;&#25454;&#29983;&#25104;&#20013;&#30340;&#38480;&#21046;&#65292;&#25552;&#39640;&#20102;&#24615;&#33021;&#24182;&#21152;&#24555;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.14623</link><description>&lt;p&gt;
&#31616;&#21270;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;
&lt;/p&gt;
&lt;p&gt;
Simplified Diffusion Schr\"odinger Bridge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14623
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#31616;&#21270;&#21518;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#65288;DSB&#65289;&#65292;&#36890;&#36807;&#19982;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGM&#65289;&#30340;&#32479;&#19968;&#35299;&#20915;&#20102;&#22797;&#26434;&#25968;&#25454;&#29983;&#25104;&#20013;&#30340;&#38480;&#21046;&#65292;&#25552;&#39640;&#20102;&#24615;&#33021;&#24182;&#21152;&#24555;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#31616;&#21270;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#65288;DSB&#65289;&#65292;&#20415;&#20110;&#23558;&#20854;&#19982;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGM&#65289;&#32479;&#19968;&#36215;&#26469;&#65292;&#35299;&#20915;&#20102;DSB&#22312;&#22797;&#26434;&#25968;&#25454;&#29983;&#25104;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#65292;&#23454;&#29616;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#22686;&#24378;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#23558;SGM&#20316;&#20026;DSB&#30340;&#21021;&#22987;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#36825;&#20004;&#20010;&#26694;&#26550;&#30340;&#20248;&#21183;&#65292;&#30830;&#20445;&#20102;&#26356;&#39640;&#25928;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#25913;&#36827;&#20102;SGM&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#21442;&#25968;&#21270;&#25216;&#26415;&#65292;&#23613;&#31649;&#23384;&#22312;&#29702;&#35770;&#36817;&#20284;&#65292;&#20294;&#23454;&#38469;&#19978;&#25552;&#39640;&#20102;&#32593;&#32476;&#30340;&#25311;&#21512;&#33021;&#21147;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#35777;&#23454;&#65292;&#35777;&#23454;&#20102;&#31616;&#21270;&#30340;DSB&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#25105;&#20204;&#30456;&#20449;&#36825;&#39033;&#24037;&#20316;&#30340;&#36129;&#29486;&#20026;&#20808;&#36827;&#30340;&#29983;&#25104;&#24314;&#27169;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14623v1 Announce Type: new  Abstract: This paper introduces a novel theoretical simplification of the Diffusion Schr\"odinger Bridge (DSB) that facilitates its unification with Score-based Generative Models (SGMs), addressing the limitations of DSB in complex data generation and enabling faster convergence and enhanced performance. By employing SGMs as an initial solution for DSB, our approach capitalizes on the strengths of both frameworks, ensuring a more efficient training process and improving the performance of SGM. We also propose a reparameterization technique that, despite theoretical approximations, practically improves the network's fitting capabilities. Our extensive experimental evaluations confirm the effectiveness of the simplified DSB, demonstrating its significant improvements. We believe the contributions of this work pave the way for advanced generative modeling. The code is available at https://github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;EdgeOL&#65292;&#19968;&#31181;&#36793;&#32536;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20869;&#37096;&#21644;&#22806;&#37096;&#35843;&#20248;&#26469;&#20248;&#21270;&#25512;&#29702;&#20934;&#30830;&#24615;&#12289;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#21644;&#33021;&#37327;&#25928;&#29575;&#65292;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2401.16694</link><description>&lt;p&gt;
EdgeOL: &#36793;&#32536;&#35774;&#22791;&#19978;&#39640;&#25928;&#30340;&#21407;&#20301;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
EdgeOL: Efficient in-situ Online Learning on Edge Devices. (arXiv:2401.16694v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;EdgeOL&#65292;&#19968;&#31181;&#36793;&#32536;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20869;&#37096;&#21644;&#22806;&#37096;&#35843;&#20248;&#26469;&#20248;&#21270;&#25512;&#29702;&#20934;&#30830;&#24615;&#12289;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#21644;&#33021;&#37327;&#25928;&#29575;&#65292;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#20852;&#24212;&#29992;&#65292;&#22914;&#26426;&#22120;&#20154;&#36741;&#21161;&#20859;&#32769;&#21644;&#29289;&#20307;&#35782;&#21035;&#65292;&#36890;&#24120;&#37319;&#29992;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#19988;&#33258;&#28982;&#38656;&#35201;&#65306;i) &#22788;&#29702;&#23454;&#26102;&#25512;&#29702;&#35831;&#27714;&#21644;ii) &#36866;&#24212;&#21487;&#33021;&#30340;&#37096;&#32626;&#22330;&#26223;&#21464;&#21270;&#12290;&#22312;&#32447;&#27169;&#22411;&#24494;&#35843;&#34987;&#24191;&#27867;&#37319;&#29992;&#20197;&#28385;&#36275;&#36825;&#20123;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#24494;&#35843;&#20250;&#23548;&#33268;&#26174;&#33879;&#30340;&#33021;&#37327;&#28040;&#32791;&#65292;&#20351;&#20854;&#38590;&#20197;&#37096;&#32626;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EdgeOL&#65292;&#19968;&#31181;&#36793;&#32536;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20869;&#37096;&#21644;&#22806;&#37096;&#35843;&#20248;&#26469;&#20248;&#21270;&#25512;&#29702;&#20934;&#30830;&#24615;&#12289;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#21644;&#33021;&#37327;&#25928;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;EdgeOL&#24179;&#22343;&#20943;&#23569;&#20102;82%&#30340;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#65292;74%&#30340;&#33021;&#37327;&#28040;&#32791;&#65292;&#24182;&#25552;&#39640;&#20102;&#24179;&#22343;&#25512;&#29702;&#20934;&#30830;&#29575;1.70%&#65292;&#30456;&#23545;&#20110;&#21363;&#26102;&#22312;&#32447;&#23398;&#20064;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emerging applications, such as robot-assisted eldercare and object recognition, generally employ deep learning neural networks (DNNs) models and naturally require: i) handling streaming-in inference requests and ii) adapting to possible deployment scenario changes. Online model fine-tuning is widely adopted to satisfy these needs. However, fine-tuning involves significant energy consumption, making it challenging to deploy on edge devices. In this paper, we propose EdgeOL, an edge online learning framework that optimizes inference accuracy, fine-tuning execution time, and energy efficiency through both inter-tuning and intra-tuning optimizations. Experimental results show that, on average, EdgeOL reduces overall fine-tuning execution time by 82%, energy consumption by 74%, and improves average inference accuracy by 1.70% over the immediate online learning strategy.
&lt;/p&gt;</description></item></channel></rss>