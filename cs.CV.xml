<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#21482;&#20351;&#29992;&#23569;&#37327;&#27169;&#22411;&#23601;&#33021;&#33719;&#24471;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#26435;&#37325;&#31354;&#38388;&#21644;&#23618;&#27425;&#21152;&#26435;&#24179;&#22343;&#25216;&#26415;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#27169;&#22411;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19522</link><description>&lt;p&gt;
&#27169;&#22411;&#24211;&#65306;&#25105;&#20204;&#21482;&#38656;&#35201;&#20960;&#20010;&#32463;&#36807;&#33391;&#22909;&#35843;&#25972;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Model Stock: All we need is just a few fine-tuned models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#21482;&#20351;&#29992;&#23569;&#37327;&#27169;&#22411;&#23601;&#33021;&#33719;&#24471;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#26435;&#37325;&#31354;&#38388;&#21644;&#23618;&#27425;&#21152;&#26435;&#24179;&#22343;&#25216;&#26415;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#27169;&#22411;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#24494;&#35843;&#26041;&#27861;&#65292;&#25552;&#20379;&#24378;&#22823;&#30340;&#20869;&#20998;&#24067;&#65288;ID&#65289;&#21644;&#22806;&#20998;&#24067;&#65288;OOD&#65289;&#24615;&#33021;&#12290;&#19982;&#38656;&#35201;&#22823;&#37327;&#24494;&#35843;&#27169;&#22411;&#36827;&#34892;&#24179;&#22343;&#30340;&#20256;&#32479;&#20570;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#26356;&#23569;&#30340;&#27169;&#22411;&#26469;&#33719;&#24471;&#26368;&#32456;&#26435;&#37325;&#65292;&#21516;&#26102;&#20135;&#29983;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;&#20174;&#24494;&#35843;&#26435;&#37325;&#30340;&#26435;&#37325;&#31354;&#38388;&#20013;&#27762;&#21462;&#20851;&#38190;&#35265;&#35299;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#24615;&#33021;&#21644;&#25509;&#36817;&#26435;&#37325;&#31354;&#38388;&#20013;&#24515;&#30340;&#24378;&#36830;&#25509;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20165;&#20351;&#29992;&#20004;&#20010;&#24494;&#35843;&#27169;&#22411;&#26469;&#36817;&#20284;&#20013;&#24515;&#25509;&#36817;&#30340;&#26435;&#37325;&#65292;&#21487;&#22312;&#35757;&#32451;&#26399;&#38388;&#25110;&#20043;&#21518;&#24212;&#29992;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#30340;&#36880;&#23618;&#26435;&#37325;&#24179;&#22343;&#25216;&#26415;&#36229;&#36234;&#20102;Model Soup&#31561;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#26041;&#27861;&#65292;&#20165;&#21033;&#29992;&#20004;&#20010;&#24494;&#35843;&#27169;&#22411;&#12290;&#36825;&#31181;&#31574;&#30053;&#21487;&#20197;&#34987;&#31216;&#20026;&#27169;&#22411;&#24211;&#65292;&#31361;&#20986;&#20102;&#23427;&#20381;&#36182;&#20110;&#36873;&#25321;&#23569;&#37327;&#27169;&#22411;&#26469;&#36827;&#34892;&#32508;&#21512;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19522v1 Announce Type: new  Abstract: This paper introduces an efficient fine-tuning method for large pre-trained models, offering strong in-distribution (ID) and out-of-distribution (OOD) performance. Breaking away from traditional practices that need a multitude of fine-tuned models for averaging, our approach employs significantly fewer models to achieve final weights yet yield superior accuracy. Drawing from key insights in the weight space of fine-tuned weights, we uncover a strong link between the performance and proximity to the center of weight space. Based on this, we introduce a method that approximates a center-close weight using only two fine-tuned models, applicable during or after training. Our innovative layer-wise weight averaging technique surpasses state-of-the-art model methods such as Model Soup, utilizing only two fine-tuned models. This strategy can be aptly coined Model Stock, highlighting its reliance on selecting a minimal number of models to draw a 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#65292;&#24182;&#21487;&#30830;&#20445;&#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.04095</link><description>&lt;p&gt;
&#22522;&#20110;&#23494;&#38053;&#38145;&#27169;&#22359;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Gradient Leakage Defense with Key-Lock Module for Federated Learning. (arXiv:2305.04095v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#65292;&#24182;&#21487;&#30830;&#20445;&#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#38544;&#31169;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#20013;&#31169;&#26377;&#25968;&#25454;&#20445;&#25345;&#26412;&#22320;&#65292;&#20801;&#35768;&#23433;&#20840;&#35745;&#31639;&#21644;&#26412;&#22320;&#27169;&#22411;&#26799;&#24230;&#19982;&#31532;&#19977;&#26041;&#21442;&#25968;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#20132;&#25442;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#20849;&#20139;&#30340;&#26799;&#24230;&#21487;&#33021;&#20250;&#21361;&#21450;&#38544;&#31169;&#24182;&#24674;&#22797;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#20998;&#26512;&#21644;&#23545;&#26799;&#24230;&#27844;&#28431;&#38382;&#39064;&#30340;&#26032;&#35270;&#35282;&#12290;&#36825;&#20123;&#29702;&#35770;&#24037;&#20316;&#23548;&#33268;&#20102;&#19968;&#31181;&#26032;&#30340;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#12290;&#21482;&#26377;&#38145;&#23450;&#30340;&#26799;&#24230;&#34987;&#20256;&#36755;&#21040;&#21442;&#25968;&#26381;&#21153;&#22120;&#36827;&#34892;&#20840;&#23616;&#27169;&#22411;&#32858;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#23398;&#20064;&#26041;&#27861;&#23545;&#26799;&#24230;&#27844;&#38706;&#25915;&#20987;&#20855;&#26377;&#25269;&#25239;&#21147;&#65292;&#24182;&#19988;&#25152;&#35774;&#35745;&#21644;&#35757;&#32451;&#30340;&#23494;&#38053;&#38145;&#27169;&#22359;&#21487;&#20197;&#30830;&#20445;&#65292;&#27809;&#26377;&#23494;&#38053;&#38145;&#27169;&#22359;&#30340;&#31169;&#26377;&#20449;&#24687;&#65306;a) &#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a widely adopted privacy-preserving machine learning approach where private data remains local, enabling secure computations and the exchange of local model gradients between local clients and third-party parameter servers. However, recent findings reveal that privacy may be compromised and sensitive information potentially recovered from shared gradients. In this study, we offer detailed analysis and a novel perspective on understanding the gradient leakage problem. These theoretical works lead to a new gradient leakage defense technique that secures arbitrary model architectures using a private key-lock module. Only the locked gradient is transmitted to the parameter server for global model aggregation. Our proposed learning method is resistant to gradient leakage attacks, and the key-lock module is designed and trained to ensure that, without the private information of the key-lock module: a) reconstructing private training data from the shared gradient is
&lt;/p&gt;</description></item></channel></rss>