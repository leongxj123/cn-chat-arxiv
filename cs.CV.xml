<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11789</link><description>&lt;p&gt;
&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#20551;&#35774;&#30340;&#32479;&#35745;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Generated Hypotheses by Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#30340;&#22686;&#24378;&#24615;&#33021;&#21152;&#36895;&#20102;&#20854;&#34701;&#20837;&#31185;&#23398;&#30740;&#31350;&#12290;&#29305;&#21035;&#26159;&#65292;&#21033;&#29992;&#29983;&#25104;&#24335;AI&#21019;&#24314;&#31185;&#23398;&#20551;&#35774;&#26159;&#24456;&#26377;&#21069;&#36884;&#30340;&#65292;&#24182;&#19988;&#27491;&#22312;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;AI&#29983;&#25104;&#30340;&#20551;&#35774;&#36827;&#34892;&#20851;&#38190;&#20915;&#31574;&#65288;&#22914;&#21307;&#23398;&#35786;&#26029;&#65289;&#26102;&#65292;&#39564;&#35777;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#36827;&#34892;&#21307;&#23398;&#35786;&#26029;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26469;&#37327;&#21270;&#20854;&#21487;&#38752;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#20351;&#29992;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#29983;&#25104;&#30340;&#22270;&#20687;&#26159;&#30001;&#32463;&#36807;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#36825;&#19968;&#20107;&#23454;&#26465;&#20214;&#19979;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;&#21033;&#29992;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#32479;&#35745;&#21487;&#38752;&#24615;&#21487;&#20197;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25511;&#21046;&#38169;&#35823;&#29575;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11789v1 Announce Type: cross  Abstract: The enhanced performance of AI has accelerated its integration into scientific research. In particular, the use of generative AI to create scientific hypotheses is promising and is increasingly being applied across various fields. However, when employing AI-generated hypotheses for critical decisions, such as medical diagnoses, verifying their reliability is crucial. In this study, we consider a medical diagnostic task using generated images by diffusion models, and propose a statistical test to quantify its reliability. The basic idea behind the proposed statistical test is to employ a selective inference framework, where we consider a statistical test conditional on the fact that the generated images are produced by a trained diffusion model. Using the proposed method, the statistical reliability of medical image diagnostic results can be quantified in the form of a p-value, allowing for decision-making with a controlled error rate. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26354;&#29575;&#24863;&#30693;&#23545;&#35282;&#39044;&#22788;&#29702;&#22120;&#65292;&#22312;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#21152;&#36895;&#20102;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#20449;&#21495;&#27169;&#24577;&#12290;</title><link>https://arxiv.org/abs/2402.08784</link><description>&lt;p&gt;
&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#38543;&#26426;&#35757;&#32451;&#30340;&#39044;&#22788;&#29702;&#22120;
&lt;/p&gt;
&lt;p&gt;
Preconditioners for the Stochastic Training of Implicit Neural Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26354;&#29575;&#24863;&#30693;&#23545;&#35282;&#39044;&#22788;&#29702;&#22120;&#65292;&#22312;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#21152;&#36895;&#20102;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#20449;&#21495;&#27169;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#23558;&#22797;&#26434;&#36830;&#32493;&#22810;&#32500;&#20449;&#21495;&#32534;&#30721;&#20026;&#31070;&#32463;&#32593;&#32476;&#65292;&#20174;&#32780;&#23454;&#29616;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26426;&#22120;&#20154;&#23398;&#21644;&#20960;&#20309;&#23398;&#31561;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;Adam&#30001;&#20110;&#20854;&#38543;&#26426;&#30340;&#39640;&#25928;&#24615;&#32780;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35757;&#32451;&#20013;&#65292;&#20294;&#20854;&#35757;&#32451;&#26102;&#38388;&#24448;&#24448;&#36739;&#38271;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22312;&#21152;&#36895;&#35757;&#32451;&#30340;&#21516;&#26102;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#26367;&#20195;&#20248;&#21270;&#25216;&#26415;&#12290;&#20256;&#32479;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#22914;L-BFGS&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#25928;&#26524;&#19981;&#20339;&#65292;&#22240;&#27492;&#19981;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#26354;&#29575;&#24863;&#30693;&#23545;&#35282;&#39044;&#22788;&#29702;&#22120;&#36827;&#34892;&#38543;&#26426;&#35757;&#32451;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#22270;&#20687;&#12289;&#24418;&#29366;&#37325;&#24314;&#21644;&#31070;&#32463;&#36752;&#23556;&#22330;&#31561;&#21508;&#31181;&#20449;&#21495;&#27169;&#24577;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08784v1 Announce Type: cross Abstract: Implicit neural representations have emerged as a powerful technique for encoding complex continuous multidimensional signals as neural networks, enabling a wide range of applications in computer vision, robotics, and geometry. While Adam is commonly used for training due to its stochastic proficiency, it entails lengthy training durations. To address this, we explore alternative optimization techniques for accelerated training without sacrificing accuracy. Traditional second-order optimizers like L-BFGS are suboptimal in stochastic settings, making them unsuitable for large-scale data sets. Instead, we propose stochastic training using curvature-aware diagonal preconditioners, showcasing their effectiveness across various signal modalities such as images, shape reconstruction, and Neural Radiance Fields (NeRF).
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32508;&#21512;&#35780;&#20272;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#23427;&#20204;&#32570;&#20047;&#31283;&#23450;&#24615;&#21644;&#21487;&#38752;&#24615;&#65292;&#24182;&#24314;&#35758;&#37319;&#29992;&#24191;&#27867;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#32479;&#19968;&#30340;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2308.04137</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#24615;&#33021;&#30340;&#32508;&#21512;&#35780;&#20272;&#25581;&#31034;&#20986;&#24778;&#20154;&#30340;&#32570;&#20047;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness. (arXiv:2308.04137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04137
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32508;&#21512;&#35780;&#20272;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#23427;&#20204;&#32570;&#20047;&#31283;&#23450;&#24615;&#21644;&#21487;&#38752;&#24615;&#65292;&#24182;&#24314;&#35758;&#37319;&#29992;&#24191;&#27867;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#32479;&#19968;&#30340;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#32780;&#31283;&#20581;&#30340;&#35780;&#20272;&#26041;&#27861;&#26159;&#24320;&#21457;&#26412;&#36523;&#31283;&#20581;&#21487;&#38752;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24517;&#35201;&#31532;&#19968;&#27493;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#29992;&#20110;&#35780;&#20272;&#20998;&#31867;&#22120;&#30340;&#24120;&#35268;&#35780;&#20272;&#21327;&#35758;&#22312;&#32508;&#21512;&#35780;&#20272;&#24615;&#33021;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#22240;&#20026;&#23427;&#20204;&#24448;&#24448;&#20381;&#36182;&#20110;&#26377;&#38480;&#31867;&#22411;&#30340;&#27979;&#35797;&#25968;&#25454;&#65292;&#24573;&#35270;&#20854;&#20182;&#31867;&#22411;&#30340;&#25968;&#25454;&#12290;&#20363;&#22914;&#65292;&#20351;&#29992;&#26631;&#20934;&#27979;&#35797;&#25968;&#25454;&#26080;&#27861;&#35780;&#20272;&#20998;&#31867;&#22120;&#23545;&#20110;&#26410;&#32463;&#35757;&#32451;&#30340;&#31867;&#21035;&#26679;&#26412;&#30340;&#39044;&#27979;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20351;&#29992;&#21253;&#21547;&#26410;&#30693;&#31867;&#21035;&#26679;&#26412;&#30340;&#25968;&#25454;&#36827;&#34892;&#27979;&#35797;&#26080;&#27861;&#35780;&#20272;&#20998;&#31867;&#22120;&#23545;&#20110;&#24050;&#30693;&#31867;&#21035;&#26631;&#31614;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20513;&#20351;&#29992;&#21508;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#36827;&#34892;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#21487;&#24212;&#29992;&#20110;&#25152;&#26377;&#36825;&#20123;&#25968;&#25454;&#31867;&#22411;&#30340;&#21333;&#19968;&#25351;&#26631;&#65292;&#20197;&#20135;&#29983;&#19968;&#33268;&#30340;&#24615;&#33021;&#35780;&#20272;&#32467;&#26524;&#12290;&#36890;&#36807;&#36825;&#26679;&#30340;&#22522;&#20934;&#27979;&#35797;&#21457;&#29616;&#65292;&#30446;&#21069;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21253;&#25324;&#20351;&#29992;&#35748;&#20026;&#26159;&#20840;&#38754;&#30340;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#30340;&#32593;&#32476;&#65292;&#20063;&#23384;&#22312;&#32570;&#20047;&#31283;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliable and robust evaluation methods are a necessary first step towards developing machine learning models that are themselves robust and reliable. Unfortunately, current evaluation protocols typically used to assess classifiers fail to comprehensively evaluate performance as they tend to rely on limited types of test data, and ignore others. For example, using the standard test data fails to evaluate the predictions made by the classifier to samples from classes it was not trained on. On the other hand, testing with data containing samples from unknown classes fails to evaluate how well the classifier can predict the labels for known classes. This article advocates bench-marking performance using a wide range of different types of data and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance. Using such a benchmark it is found that current deep neural networks, including those trained with methods that are believed to pro
&lt;/p&gt;</description></item></channel></rss>