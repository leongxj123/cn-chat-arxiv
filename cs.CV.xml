<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FCILPT&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32852;&#37030;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#38750;&#29420;&#31435;&#21644;&#21516;&#20998;&#24067;&#25968;&#25454;&#20998;&#24067;&#24773;&#20917;&#65292;&#24182;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2310.08948</link><description>&lt;p&gt;
&#20855;&#26377;&#25552;&#31034;&#30340;&#32852;&#37030;&#22686;&#37327;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Class-Incremental Learning with Prompting. (arXiv:2310.08948v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FCILPT&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32852;&#37030;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#38750;&#29420;&#31435;&#21644;&#21516;&#20998;&#24067;&#25968;&#25454;&#20998;&#24067;&#24773;&#20917;&#65292;&#24182;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;Web&#25216;&#26415;&#30340;&#21457;&#23637;&#65292;&#20351;&#29992;&#23384;&#20648;&#22312;&#19981;&#21516;&#23458;&#25143;&#31471;&#19978;&#30340;&#25968;&#25454;&#21464;&#24471;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#21516;&#26102;&#65292;&#30001;&#20110;&#22312;&#35753;&#27169;&#22411;&#20174;&#20998;&#24067;&#22312;&#21508;&#20010;&#23458;&#25143;&#31471;&#19978;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#26102;&#33021;&#22815;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#65292;&#32852;&#37030;&#23398;&#20064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24037;&#20316;&#37117;&#20551;&#35774;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#26159;&#22266;&#23450;&#30340;&#12290;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#36825;&#31181;&#20551;&#35774;&#24456;&#21487;&#33021;&#19981;&#25104;&#31435;&#65292;&#22240;&#20026;&#25968;&#25454;&#21487;&#33021;&#19981;&#26029;&#29983;&#25104;&#65292;&#26032;&#30340;&#31867;&#21035;&#20063;&#21487;&#33021;&#20986;&#29616;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#23454;&#38469;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#32852;&#37030;&#22686;&#37327;&#23398;&#20064;&#65288;FCIL&#65289;&#38382;&#39064;&#12290;&#23545;&#20110;FCIL&#65292;&#30001;&#20110;&#26032;&#31867;&#21035;&#30340;&#20986;&#29616;&#21644;&#23458;&#25143;&#31471;&#25968;&#25454;&#20998;&#24067;&#30340;&#38750;&#29420;&#31435;&#21644;&#21516;&#20998;&#24067;&#24615;&#36136;&#65288;non-iid&#65289;&#65292;&#23616;&#37096;&#21644;&#20840;&#23616;&#27169;&#22411;&#21487;&#33021;&#20250;&#23545;&#26087;&#31867;&#21035;&#21457;&#29983;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#20855;&#26377;&#25552;&#31034;&#30340;&#32852;&#37030;&#22686;&#37327;&#23398;&#20064;&#65288;FCILPT&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
As Web technology continues to develop, it has become increasingly common to use data stored on different clients. At the same time, federated learning has received widespread attention due to its ability to protect data privacy when let models learn from data which is distributed across various clients. However, most existing works assume that the client's data are fixed. In real-world scenarios, such an assumption is most likely not true as data may be continuously generated and new classes may also appear. To this end, we focus on the practical and challenging federated class-incremental learning (FCIL) problem. For FCIL, the local and global models may suffer from catastrophic forgetting on old classes caused by the arrival of new classes and the data distributions of clients are non-independent and identically distributed (non-iid).  In this paper, we propose a novel method called Federated Class-Incremental Learning with PrompTing (FCILPT). Given the privacy and limited memory, F
&lt;/p&gt;</description></item></channel></rss>