<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#36890;&#36807;&#23398;&#20064;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#22312;&#19981;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#12289;&#20934;&#30830;&#22320;&#38477;&#23610;&#24230;&#20219;&#24847;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;&#27169;&#25311;&#65292;&#24182;&#20135;&#29983;&#27010;&#29575;&#24615;&#38477;&#23610;&#24230;&#22330;&#12290;</title><link>https://arxiv.org/abs/2403.02774</link><description>&lt;p&gt;
&#24555;&#36895;&#12289;&#33258;&#36866;&#24212;&#23610;&#24230;&#21644;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#24847;&#35782;&#30340;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;&#22330;&#38477;&#23610;&#24230;&#19982;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Fast, Scale-Adaptive, and Uncertainty-Aware Downscaling of Earth System Model Fields with Generative Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02774
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#22312;&#19981;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#12289;&#20934;&#30830;&#22320;&#38477;&#23610;&#24230;&#20219;&#24847;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;&#27169;&#25311;&#65292;&#24182;&#20135;&#29983;&#27010;&#29575;&#24615;&#38477;&#23610;&#24230;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#21644;&#39640;&#20998;&#36776;&#29575;&#30340;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;(ESM)&#27169;&#25311;&#23545;&#20110;&#35780;&#20272;&#20154;&#20026;&#27668;&#20505;&#21464;&#21270;&#23545;&#29983;&#24577;&#21644;&#31038;&#20250;&#32463;&#27982;&#24433;&#21709;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#36807;&#39640;&#12290;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;ESM&#27169;&#25311;&#30340;&#38477;&#23610;&#24230;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#32479;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23545;&#27599;&#20010;ESM&#37117;&#38656;&#35201;&#35745;&#31639;&#26114;&#36149;&#30340;&#37325;&#26032;&#35757;&#32451;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#26399;&#38388;&#26410;&#35265;&#36807;&#30340;&#27668;&#20505;&#39044;&#27979;&#25928;&#26524;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#19968;&#33268;&#24615;&#27169;&#22411;(CM)&#65292;&#20197;&#38646;&#26679;&#26412;&#26041;&#24335;&#39640;&#25928;&#20934;&#30830;&#22320;&#38477;&#23610;&#24230;&#20219;&#24847;ESM&#27169;&#25311;&#26469;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#12290;&#25105;&#20204;&#30340;&#22522;&#30784;&#27169;&#22411;&#26041;&#27861;&#20197;&#21482;&#21463;&#35266;&#27979;&#21442;&#32771;&#25968;&#25454;&#38480;&#21046;&#30340;&#20998;&#36776;&#29575;&#20135;&#29983;&#27010;&#29575;&#24615;&#38477;&#23610;&#24230;&#22330;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;CM&#22312;&#32500;&#25345;&#39640;&#21487;&#25511;&#24615;&#30340;&#21516;&#26102;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02774v1 Announce Type: cross  Abstract: Accurate and high-resolution Earth system model (ESM) simulations are essential to assess the ecological and socio-economic impacts of anthropogenic climate change, but are computationally too expensive. Recent machine learning approaches have shown promising results in downscaling ESM simulations, outperforming state-of-the-art statistical approaches. However, existing methods require computationally costly retraining for each ESM and extrapolate poorly to climates unseen during training. We address these shortcomings by learning a consistency model (CM) that efficiently and accurately downscales arbitrary ESM simulations without retraining in a zero-shot manner. Our foundation model approach yields probabilistic downscaled fields at resolution only limited by the observational reference data. We show that the CM outperforms state-of-the-art diffusion models at a fraction of computational cost while maintaining high controllability on
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#28388;&#27874;&#22120;&#23376;&#31354;&#38388;&#21644;&#28388;&#27874;&#22120;&#21407;&#23376;&#30340;&#27010;&#24565;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24494;&#35843;&#22823;&#22411;&#21367;&#31215;&#27169;&#22411;&#26102;&#20165;&#35843;&#25972;&#23569;&#37327;&#21442;&#25968;&#26469;&#25552;&#21462;&#20219;&#21153;&#29305;&#23450;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.00269</link><description>&lt;p&gt;
&#22823;&#22411;&#21367;&#31215;&#27169;&#22411;&#30340;&#21442;&#25968;&#39640;&#25928;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Parameter-Efficient Tuning of Large Convolutional Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00269
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#28388;&#27874;&#22120;&#23376;&#31354;&#38388;&#21644;&#28388;&#27874;&#22120;&#21407;&#23376;&#30340;&#27010;&#24565;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24494;&#35843;&#22823;&#22411;&#21367;&#31215;&#27169;&#22411;&#26102;&#20165;&#35843;&#25972;&#23569;&#37327;&#21442;&#25968;&#26469;&#25552;&#21462;&#20219;&#21153;&#29305;&#23450;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#24494;&#35843;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#25152;&#38656;&#30340;&#39640;&#35745;&#31639;&#21644;&#21442;&#25968;&#22797;&#26434;&#24615;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20102;&#21442;&#25968;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#20165;&#26356;&#26032;&#19979;&#28216;&#20219;&#21153;&#30340;&#37096;&#20998;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24037;&#20316;&#36890;&#24120;&#24573;&#35270;&#20102;&#21367;&#31215;&#26680;&#30340;&#29420;&#29305;&#23646;&#24615;&#65292;&#32780;&#21367;&#31215;&#26680;&#20173;&#28982;&#26159;&#35768;&#22810;&#22823;&#22411;&#27169;&#22411;&#30340;&#22522;&#26412;&#20803;&#32032;&#65292;&#27604;&#22914;Stable Diffusion&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#22312;&#27599;&#20010;&#32593;&#32476;&#23618;&#20869;&#20998;&#35299;&#21367;&#31215;&#26680;&#21040;&#19968;&#23567;&#32452;&#28388;&#27874;&#22120;&#23376;&#31354;&#38388;&#20803;&#32032;&#65292;&#21363;&#28388;&#27874;&#22120;&#21407;&#23376;&#65292;&#24341;&#20837;&#20102;&#28388;&#27874;&#22120;&#23376;&#31354;&#38388;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20165;&#35843;&#25972;&#28388;&#27874;&#22120;&#21407;&#23376;&#65288;&#36890;&#24120;&#20026;&#20960;&#30334;&#20010;&#21442;&#25968;&#65289;&#23545;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#20197;&#25552;&#21462;&#20219;&#21153;&#29305;&#23450;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#28508;&#22312;&#22320;&#25193;&#23637;&#35843;&#25972;&#30340;&#21442;&#25968;&#31354;&#38388;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36882;&#24402;&#22320;&#23558;&#27599;&#20010;&#31579;&#36873;&#21407;&#23376;&#20998;&#35299;&#21040;&#21478;&#19968;&#32452;&#31579;&#36873;&#21407;&#23376;&#26469;&#29983;&#25104;&#19968;&#20010;&#36807;&#23436;&#22791;&#30340;&#28388;&#27874;&#22120;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00269v1 Announce Type: cross  Abstract: To address the high computational and parameter complexity associated with fine-tuning large pre-trained models, researchers have developed parameter-efficient methods, where only partial parameters are updated for downstream tasks. However, these works often overlook the distinct properties of convolutional kernels, which still remain essential elements in many large models, such as Stable Diffusion. In this study, we first introduce filter subspace by decomposing convolutional kernels within each network layer over a small set of filter subspace elements, referred to as filter atoms. We then fine-tune these models to extract task-specific representation by only adapting the filter atoms, a few hundred parameters typically. To potentially expand the parameter space for tuning, we further show a simple approach to generate an overcomplete filter subspace by recursively decomposing each filter atom over another set of filter atoms. The 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.10418</link><description>&lt;p&gt;
p$^3$VAE&#65306;&#19968;&#20010;&#29289;&#29702;&#38598;&#25104;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24212;&#29992;&#20110;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images. (arXiv:2210.10418v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#29289;&#29702;&#27169;&#22411;&#30456;&#32467;&#21512;&#26159;&#23398;&#20064;&#24378;&#22823;&#25968;&#25454;&#34920;&#31034;&#30340;&#26368;&#26032;&#30740;&#31350;&#26041;&#21521;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#65292;&#36825;&#26159;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#38598;&#25104;&#20102;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#65292;&#37096;&#20998;&#35299;&#37322;&#20102;&#25968;&#25454;&#20013;&#30495;&#23454;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#25105;&#20204;&#30340;&#28151;&#21512;&#35774;&#35745;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#20248;&#21270;&#36807;&#31243;&#21644;&#19968;&#31181;&#25512;&#26029;&#26041;&#26696;&#65292;&#21516;&#26102;&#20276;&#38543;&#30528;&#26377;&#24847;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;p$^3$VAE&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;p$^3$VAE&#33258;&#28982;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#24050;&#22312;https://github.com/Romain3Ch216/p3VAE&#19978;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The combination of machine learning models with physical models is a recent research path to learn robust data representations. In this paper, we introduce p$^3$VAE, a generative model that integrates a perfect physical model which partially explains the true underlying factors of variation in the data. To fully leverage our hybrid design, we propose a semi-supervised optimization procedure and an inference scheme that comes along meaningful uncertainty estimates. We apply p$^3$VAE to the semantic segmentation of high-resolution hyperspectral remote sensing images. Our experiments on a simulated data set demonstrated the benefits of our hybrid model against conventional machine learning models in terms of extrapolation capabilities and interpretability. In particular, we show that p$^3$VAE naturally has high disentanglement capabilities. Our code and data have been made publicly available at https://github.com/Romain3Ch216/p3VAE.
&lt;/p&gt;</description></item></channel></rss>