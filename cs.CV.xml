<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>CLoRA&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#26041;&#27861;&#65292;&#29992;&#20110;&#32452;&#21512;&#22810;&#20010;LoRA&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#23558;&#19981;&#21516;&#27010;&#24565;LoRA&#27169;&#22411;&#26080;&#32541;&#28151;&#21512;&#21040;&#19968;&#20010;&#22270;&#20687;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.19776</link><description>&lt;p&gt;
CLoRA: &#19968;&#31181;&#23545;&#27604;&#26041;&#27861;&#26469;&#32452;&#21512;&#22810;&#20010; LoRA &#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CLoRA: A Contrastive Approach to Compose Multiple LoRA Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19776
&lt;/p&gt;
&lt;p&gt;
CLoRA&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#26041;&#27861;&#65292;&#29992;&#20110;&#32452;&#21512;&#22810;&#20010;LoRA&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#23558;&#19981;&#21516;&#27010;&#24565;LoRA&#27169;&#22411;&#26080;&#32541;&#28151;&#21512;&#21040;&#19968;&#20010;&#22270;&#20687;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#35843;&#25972;&#65288;LoRA&#65289;&#24050;&#32463;&#25104;&#20026;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#20013;&#19968;&#31181;&#24378;&#22823;&#19988;&#21463;&#27426;&#36814;&#30340;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#24335;&#26469;&#35843;&#25972;&#21644;&#25913;&#36827;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#20840;&#38754;&#22320;&#37325;&#26032;&#35757;&#32451;&#12290;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340; LoRA &#27169;&#22411;&#65292;&#20363;&#22914;&#20195;&#34920;&#29305;&#23450;&#29483;&#21644;&#29305;&#23450;&#29399;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#29983;&#25104;&#19968;&#20010;&#22270;&#20687;&#65292;&#35813;&#22270;&#20687;&#30495;&#23454;&#22320;&#20307;&#29616;&#20102; LoRA &#25152;&#23450;&#20041;&#30340;&#20004;&#31181;&#21160;&#29289;&#12290;&#28982;&#32780;&#65292;&#26080;&#32541;&#22320;&#28151;&#21512;&#22810;&#20010;&#27010;&#24565; LoRA &#27169;&#22411;&#20197;&#25429;&#33719;&#19968;&#20010;&#22270;&#20687;&#20013;&#30340;&#21508;&#31181;&#27010;&#24565;&#30340;&#20219;&#21153;&#34987;&#35777;&#26126;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#24120;&#35265;&#26041;&#27861;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;&#19981;&#21516; LoRA &#27169;&#22411;&#20869;&#30340;&#27880;&#24847;&#26426;&#21046;&#37325;&#21472;&#65292;&#23548;&#33268;&#19968;&#20010;&#27010;&#24565;&#21487;&#33021;&#34987;&#23436;&#20840;&#24573;&#30053;&#65288;&#20363;&#22914;&#28431;&#25481;&#20102;&#29399;&#65289;&#65292;&#25110;&#32773;&#27010;&#24565;&#34987;&#38169;&#35823;&#22320;&#32452;&#21512;&#22312;&#19968;&#36215;&#65288;&#20363;&#22914;&#29983;&#25104;&#20004;&#21482;&#29483;&#30340;&#22270;&#20687;&#32780;&#19981;&#26159;&#19968;&#21482;&#29483;&#21644;&#19968;&#21482;&#29399;&#65289;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19776v1 Announce Type: cross  Abstract: Low-Rank Adaptations (LoRAs) have emerged as a powerful and popular technique in the field of image generation, offering a highly effective way to adapt and refine pre-trained deep learning models for specific tasks without the need for comprehensive retraining. By employing pre-trained LoRA models, such as those representing a specific cat and a particular dog, the objective is to generate an image that faithfully embodies both animals as defined by the LoRAs. However, the task of seamlessly blending multiple concept LoRAs to capture a variety of concepts in one image proves to be a significant challenge. Common approaches often fall short, primarily because the attention mechanisms within different LoRA models overlap, leading to scenarios where one concept may be completely ignored (e.g., omitting the dog) or where concepts are incorrectly combined (e.g., producing an image of two cats instead of one cat and one dog). To overcome th
&lt;/p&gt;</description></item></channel></rss>