<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CREMA&#30340;&#39640;&#25928;&#19988;&#27169;&#22359;&#21270;&#30340;&#27169;&#24577;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#20219;&#24847;&#26032;&#30340;&#27169;&#24577;&#27880;&#20837;&#35270;&#39057;&#25512;&#29702;&#12290;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#22686;&#24378;&#22810;&#31181;&#20449;&#24687;&#27169;&#24577;&#65292;&#24182;&#24341;&#20837;&#26597;&#35810;&#36716;&#25442;&#22120;&#21644;&#34701;&#21512;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#19988;&#26377;&#25928;&#30340;&#22810;&#27169;&#24577;&#32452;&#21512;&#25512;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.05889</link><description>&lt;p&gt;
CREMA: &#36890;&#36807;&#26377;&#25928;&#30340;&#27169;&#22359;&#21270;&#36866;&#24212;&#21644;&#34701;&#21512;&#36827;&#34892;&#22810;&#27169;&#24577;&#32452;&#21512;&#35270;&#39057;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05889
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CREMA&#30340;&#39640;&#25928;&#19988;&#27169;&#22359;&#21270;&#30340;&#27169;&#24577;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#20219;&#24847;&#26032;&#30340;&#27169;&#24577;&#27880;&#20837;&#35270;&#39057;&#25512;&#29702;&#12290;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#22686;&#24378;&#22810;&#31181;&#20449;&#24687;&#27169;&#24577;&#65292;&#24182;&#24341;&#20837;&#26597;&#35810;&#36716;&#25442;&#22120;&#21644;&#34701;&#21512;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#19988;&#26377;&#25928;&#30340;&#22810;&#27169;&#24577;&#32452;&#21512;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#22810;&#27169;&#24577;&#32452;&#21512;&#25512;&#29702;&#26041;&#27861;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#22788;&#29702;&#22266;&#23450;&#27169;&#24577;&#36755;&#20837;&#24182;&#26356;&#26032;&#35768;&#22810;&#27169;&#22411;&#21442;&#25968;&#65292;&#20173;&#28982;&#23384;&#22312;&#28789;&#27963;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#36825;&#20123;&#20851;&#38190;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;CREMA&#65292;&#19968;&#31181;&#29992;&#20110;&#23558;&#20219;&#20309;&#26032;&#30340;&#27169;&#24577;&#27880;&#20837;&#35270;&#39057;&#25512;&#29702;&#30340;&#39640;&#25928;&#19988;&#27169;&#22359;&#21270;&#30340;&#27169;&#24577;&#34701;&#21512;&#26694;&#26550;&#12290;&#25105;&#20204;&#39318;&#20808;&#21033;&#29992;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#20174;&#32473;&#23450;&#30340;&#35270;&#39057;&#20013;&#22686;&#24378;&#22810;&#31181;&#20449;&#24687;&#27169;&#24577;&#65288;&#22914;&#20809;&#27969;&#12289;3D&#28857;&#20113;&#12289;&#38899;&#39057;&#65289;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#20154;&#24037;&#27880;&#37322;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26597;&#35810;&#36716;&#25442;&#22120;&#65292;&#35813;&#36716;&#25442;&#22120;&#19982;&#27599;&#20010;&#21487;&#20197;&#35775;&#38382;&#30340;&#27169;&#24577;&#30456;&#20851;&#32852;&#65292;&#24182;&#20855;&#26377;&#22810;&#20010;&#21442;&#25968;&#39640;&#25928;&#30340;&#27169;&#22359;&#12290;&#23427;&#23558;&#22810;&#31181;&#27169;&#24577;&#29305;&#24449;&#25237;&#24433;&#21040;LLM&#20196;&#29260;&#23884;&#20837;&#31354;&#38388;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#25972;&#21512;&#19981;&#21516;&#30340;&#25968;&#25454;&#31867;&#22411;&#20197;&#36827;&#34892;&#21709;&#24212;&#29983;&#25104;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#34701;&#21512;&#27169;&#22359;&#65292;&#29992;&#20110;&#21387;&#32553;&#22810;&#27169;&#24577;&#26597;&#35810;&#65292;&#22312;LLM&#20013;&#20445;&#25345;&#35745;&#31639;&#25928;&#29575;&#30340;&#21516;&#26102;&#36827;&#34892;&#34701;&#21512;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters. This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning. We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models. Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality. It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation. Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#31934;&#20934;&#32959;&#30244;&#23398;&#20013;&#30340;&#26579;&#33394;&#20307;&#20998;&#26512;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;Fred Hutchinson&#30284;&#30151;&#30740;&#31350;&#20013;&#24515;&#30340;&#22823;&#37327;&#25968;&#25454;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#25299;&#25169;&#35270;&#35273;&#36716;&#25442;&#22120;(TopViTs)&#65292;&#25104;&#21151;&#24320;&#21457;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35782;&#21035;&#26579;&#33394;&#20307;&#24322;&#24120;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.14312</link><description>&lt;p&gt;
&#31934;&#20934;&#32959;&#30244;&#23398;&#30340;&#26579;&#33394;&#20307;AI
&lt;/p&gt;
&lt;p&gt;
Karyotype AI for Precision Oncology. (arXiv:2211.14312v3 [q-bio.QM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#31934;&#20934;&#32959;&#30244;&#23398;&#20013;&#30340;&#26579;&#33394;&#20307;&#20998;&#26512;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;Fred Hutchinson&#30284;&#30151;&#30740;&#31350;&#20013;&#24515;&#30340;&#22823;&#37327;&#25968;&#25454;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#25299;&#25169;&#35270;&#35273;&#36716;&#25442;&#22120;(TopViTs)&#65292;&#25104;&#21151;&#24320;&#21457;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35782;&#21035;&#26579;&#33394;&#20307;&#24322;&#24120;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26579;&#33394;&#20307;&#20998;&#26512;&#23545;&#20110;&#35786;&#26029;&#36951;&#20256;&#30142;&#30149;&#33267;&#20851;&#37325;&#35201;&#12290;&#23545;&#20110;&#34880;&#28082;&#31995;&#32479;&#24694;&#24615;&#32959;&#30244;&#65292;&#36890;&#36807;&#26579;&#33394;&#20307;&#32452;&#22411;&#20998;&#26512;&#26469;&#21457;&#29616;&#20307;&#32454;&#32990;&#31361;&#21464;&#26159;&#26631;&#20934;&#30340;&#25252;&#29702;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#26579;&#33394;&#20307;&#32452;&#22411;&#20998;&#26512;&#22240;&#20026;&#22823;&#37096;&#20998;&#26159;&#25163;&#21160;&#25805;&#20316;&#65292;&#19988;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#26469;&#35782;&#21035;&#21644;&#27880;&#37322;&#31361;&#21464;&#65292;&#25152;&#20197;&#26114;&#36149;&#19988;&#32791;&#26102;&#12290;&#20197;Fred Hutchinson&#30284;&#30151;&#30740;&#31350;&#20013;&#24515;&#36807;&#21435;&#20116;&#24180;&#30340;&#32422;10,000&#20010;&#24739;&#32773;&#26631;&#26412;&#21644;&#32422;50,000&#20010;&#26579;&#33394;&#20307;&#32452;&#22411;&#22270;&#29255;&#20316;&#20026;&#35757;&#32451;&#38598;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#32452;&#20195;&#34920;&#21333;&#20010;&#26579;&#33394;&#20307;&#30340;&#26631;&#35760;&#22270;&#29255;&#12290;&#36825;&#20123;&#21333;&#20010;&#26579;&#33394;&#20307;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#20197;&#20998;&#31867;&#20154;&#31867;&#30340;24&#26465;&#26579;&#33394;&#20307;&#21644;&#35782;&#21035;&#26579;&#33394;&#20307;&#24322;&#24120;&#12290;&#20855;&#26377;&#26368;&#39640;&#20934;&#30830;&#24615;&#30340;&#27169;&#22411;&#20351;&#29992;&#20102;&#26368;&#36817;&#24341;&#20837;&#30340;&#25299;&#25169;&#35270;&#35273;&#36716;&#25442;&#22120;(TopViTs)&#21644;&#20108;&#32423;&#22359;-&#25176;&#26222;&#21033;&#33576;&#33945;&#29256;&#65292;&#20197;&#34701;&#20837;&#32467;&#26500;&#24615;&#24402;&#32435;&#20559;&#32622;&#12290;TopViT&#30340;&#24615;&#33021;&#20248;&#20110;CNN(Inc)
&lt;/p&gt;
&lt;p&gt;
Chromosome analysis is essential for diagnosing genetic disorders. For hematologic malignancies, identification of somatic clonal aberrations by karyotype analysis remains the standard of care. However, karyotyping is costly and time-consuming because of the largely manual process and the expertise required in identifying and annotating aberrations. Efforts to automate karyotype analysis to date fell short in aberration detection. Using a training set of ~10k patient specimens and ~50k karyograms from over 5 years from the Fred Hutchinson Cancer Center, we created a labeled set of images representing individual chromosomes. These individual chromosomes were used to train and assess deep learning models for classifying the 24 human chromosomes and identifying chromosomal aberrations. The top-accuracy models utilized the recently introduced Topological Vision Transformers (TopViTs) with 2-level-block-Toeplitz masking, to incorporate structural inductive bias. TopViT outperformed CNN (Inc
&lt;/p&gt;</description></item></channel></rss>