<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#26410;&#35265;&#36807;&#30340;&#39046;&#22495;&#21512;&#25104;&#22270;&#20687;&#30340;&#26041;&#27861;&#65292;&#24182;&#29702;&#35770;&#19978;&#21644;&#32463;&#39564;&#19978;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.09213</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#21512;&#25104;&#26410;&#35265;&#36807;&#30340;&#22270;&#20687;
&lt;/p&gt;
&lt;p&gt;
Unseen Image Synthesis with Diffusion Models. (arXiv:2310.09213v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#26410;&#35265;&#36807;&#30340;&#39046;&#22495;&#21512;&#25104;&#22270;&#20687;&#30340;&#26041;&#27861;&#65292;&#24182;&#29702;&#35770;&#19978;&#21644;&#32463;&#39564;&#19978;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#29983;&#25104;&#39046;&#22495;&#30340;&#36235;&#21183;&#26159;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#35268;&#27169;&#21644;&#22686;&#21152;&#35757;&#32451;&#25968;&#25454;&#26469;&#23454;&#29616;&#36890;&#29992;&#39046;&#22495;&#34920;&#31034;&#65292;&#32780;&#25105;&#20204;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#36873;&#25321;&#30456;&#21453;&#30340;&#26041;&#21521;&#65292;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#21644;&#20923;&#32467;&#30340;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPMs&#65289;&#22312;&#21333;&#39046;&#22495;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#28508;&#22312;&#37319;&#26679;&#21644;&#20960;&#20309;&#20248;&#21270;&#26469;&#21512;&#25104;&#26410;&#35265;&#36807;&#30340;&#39046;&#22495;&#22270;&#20687;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#21363;&#20351;&#26159;&#20165;&#22312;&#21333;&#39046;&#22495;&#22270;&#20687;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;DDPMs&#24050;&#32463;&#20855;&#22791;&#20102;&#36275;&#22815;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#21487;&#20197;&#36890;&#36807;&#21453;&#36716;&#28508;&#22312;&#32534;&#30721;&#65292;&#24182;&#32463;&#36807;&#21452;&#21521;&#30830;&#23450;&#24615;&#25193;&#25955;&#21644;&#21435;&#22122;&#36712;&#36857;&#37325;&#26500;&#20219;&#24847;&#22270;&#20687;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#30740;&#31350;&#26410;&#35265;&#36807;&#22270;&#20687;&#39046;&#22495;&#20013;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#27839;&#21435;&#22122;&#38142;&#30340;OOD&#26679;&#26412;&#30340;&#32479;&#35745;&#21644;&#20960;&#20309;&#34892;&#20026;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#21644;&#32463;&#39564;&#19978;&#37117;&#34920;&#26126;&#65292;&#21453;&#36716;&#30340;OOD&#26679;&#26412;&#20063;&#24314;&#31435;&#20102;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the current trend in the generative field is scaling up towards larger models and more training data for generalized domain representations, we go the opposite direction in this work by synthesizing unseen domain images without additional training. We do so via latent sampling and geometric optimization using pre-trained and frozen Denoising Diffusion Probabilistic Models (DDPMs) on single-domain datasets. Our key observation is that DDPMs pre-trained even just on single-domain images are already equipped with sufficient representation abilities to reconstruct arbitrary images from the inverted latent encoding following bi-directional deterministic diffusion and denoising trajectories. This motivates us to investigate the statistical and geometric behaviors of the Out-Of-Distribution (OOD) samples from unseen image domains in the latent spaces along the denoising chain. Notably, we theoretically and empirically show that the inverted OOD samples also establish Gaussians that are 
&lt;/p&gt;</description></item></channel></rss>