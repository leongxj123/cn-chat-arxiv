<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#22522;&#20110;Forward-Forward&#31639;&#27861;&#23558;&#20854;&#24212;&#29992;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#35757;&#32451;&#65292;&#37319;&#29992;&#20102;&#26032;&#39062;&#30340;&#31354;&#38388;&#25193;&#23637;&#26631;&#31614;&#25216;&#26415;&#65292;&#22312;MNIST&#25163;&#20889;&#25968;&#23383;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;99.16%&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2312.14924</link><description>&lt;p&gt;
&#20351;&#29992;Forward-Forward&#31639;&#27861;&#35757;&#32451;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Training Convolutional Neural Networks with the Forward-Forward algorithm. (arXiv:2312.14924v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;Forward-Forward&#31639;&#27861;&#23558;&#20854;&#24212;&#29992;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#35757;&#32451;&#65292;&#37319;&#29992;&#20102;&#26032;&#39062;&#30340;&#31354;&#38388;&#25193;&#23637;&#26631;&#31614;&#25216;&#26415;&#65292;&#22312;MNIST&#25163;&#20889;&#25968;&#23383;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;99.16%&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#22270;&#20687;&#36827;&#34892;&#20998;&#26512;&#30340;&#26368;&#26032;&#25104;&#21151;&#20960;&#20046;&#20840;&#37096;&#23454;&#29616;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#12290;&#36825;&#20123;CNN&#20197;&#21450;&#25152;&#26377;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#35757;&#32451;&#37117;&#20351;&#29992;&#20102;&#21453;&#21521;&#20256;&#25773;&#31639;&#27861;&#65292;&#23558;&#32593;&#32476;&#30340;&#36755;&#20986;&#19982;&#26399;&#26395;&#32467;&#26524;&#36827;&#34892;&#27604;&#36739;&#65292;&#21033;&#29992;&#24046;&#24322;&#26469;&#35843;&#25972;&#32593;&#32476;&#26435;&#37325;&#20197;&#36798;&#21040;&#26399;&#26395;&#30340;&#36755;&#20986;&#12290;&#22312;2022&#24180;&#30340;&#19968;&#31687;&#39044;&#21360;&#26412;&#20013;&#65292;Geoffrey Hinton&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#30340;&#35757;&#32451;&#26041;&#24335;&#65292;&#21363;&#22312;&#32593;&#32476;&#30340;&#36755;&#20837;&#20013;&#21516;&#26102;&#20256;&#36882;&#26399;&#26395;&#30340;&#32467;&#26524;&#21644;&#22270;&#20687;&#12290;&#36825;&#31181;&#31216;&#20026;Forward Forward&#65288;FF&#65289;&#31639;&#27861;&#21040;&#30446;&#21069;&#20026;&#27490;&#20165;&#22312;&#20840;&#36830;&#25509;&#32593;&#32476;&#20013;&#20351;&#29992;&#36807;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;FF&#33539;&#24335;&#25193;&#23637;&#21040;CNN&#20013;&#12290;&#25105;&#20204;&#30340;FF&#35757;&#32451;&#30340;CNN&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31354;&#38388;&#25193;&#23637;&#26631;&#31614;&#25216;&#26415;&#65292;&#22312;MNIST&#25163;&#20889;&#25968;&#23383;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;99.16%&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#36229;&#21442;&#25968;&#23545;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent successes in analyzing images with deep neural networks are almost exclusively achieved with Convolutional Neural Networks (CNNs). The training of these CNNs, and in fact of all deep neural network architectures, uses the backpropagation algorithm where the output of the network is compared with the desired result and the difference is then used to tune the weights of the network towards the desired outcome. In a 2022 preprint, Geoffrey Hinton suggested an alternative way of training which passes the desired results together with the images at the input of the network. This so called Forward Forward (FF) algorithm has up to now only been used in fully connected networks. In this paper, we show how the FF paradigm can be extended to CNNs. Our FF-trained CNN, featuring a novel spatially-extended labeling technique, achieves a classification accuracy of 99.16% on the MNIST hand-written digits dataset. We show how different hyperparameters affect the performance of the proposed 
&lt;/p&gt;</description></item></channel></rss>