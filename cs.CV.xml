<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#21487;&#20197;&#26497;&#20854;&#20887;&#20313;&#65292;&#20165;&#20351;&#29992;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#32500;&#24230;&#30340;1%&#23601;&#33021;&#22815;&#36798;&#21040;&#20351;&#29992;&#23436;&#25972;&#34920;&#31034;&#26102;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.03843</link><description>&lt;p&gt;
Less is More: &#20851;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20219;&#21153;&#20013;&#29305;&#24449;&#20887;&#20313;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks. (arXiv:2310.03843v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03843
&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#21487;&#20197;&#26497;&#20854;&#20887;&#20313;&#65292;&#20165;&#20351;&#29992;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#32500;&#24230;&#30340;1%&#23601;&#33021;&#22815;&#36798;&#21040;&#20351;&#29992;&#23436;&#25972;&#34920;&#31034;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#24212;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#30446;&#26631;&#25968;&#25454;&#36827;&#34892;&#32447;&#24615;&#25506;&#27979;&#26469;&#23454;&#29616;&#65292;&#21363;&#23545;&#20174;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#25552;&#21462;&#30340;&#20923;&#32467;&#29305;&#24449;&#36827;&#34892;&#35757;&#32451;&#32447;&#24615;&#20998;&#31867;&#22120;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#25968;&#25454;&#38598;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#25105;&#20204;&#21487;&#20197;&#35810;&#38382;&#26159;&#21542;&#25152;&#26377;&#39044;&#35757;&#32451;&#29305;&#24449;&#30340;&#32500;&#24230;&#23545;&#20110;&#32473;&#23450;&#30340;&#19979;&#28216;&#20219;&#21153;&#37117;&#26159;&#26377;&#29992;&#30340;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#32447;&#24615;&#25506;&#27979;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#19979;&#28216;&#25968;&#25454;&#31232;&#32570;&#25110;&#23569;&#26679;&#26412;&#26102;&#65292;&#39044;&#35757;&#32451;&#29305;&#24449;&#21487;&#33021;&#26497;&#20854;&#20887;&#20313;&#12290;&#23545;&#20110;&#19968;&#20123;&#24773;&#20917;&#65292;&#27604;&#22914;5&#31867;1&#26679;&#26412;&#20219;&#21153;&#65292;&#21482;&#20351;&#29992;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#32500;&#24230;&#30340;1%&#23601;&#33021;&#22815;&#36798;&#21040;&#20351;&#29992;&#23436;&#25972;&#34920;&#31034;&#26102;&#30340;&#24615;&#33021;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22823;&#37096;&#20998;&#29305;&#24449;&#21482;&#22312;&#23569;&#26679;&#26412;&#35774;&#32622;&#19979;&#26159;&#20887;&#20313;&#30340;&#65292;&#22312;&#26679;&#26412;&#25968;&#22686;&#21152;&#26102;&#36880;&#28176;&#21464;&#24471;&#26377;&#29992;&#65292;&#36825;&#34920;&#26126;&#29305;&#24449;&#20887;&#20313;&#21487;&#33021;&#26159;&#34920;&#24449;&#23569;&#26679;&#26412;&#36716;&#31227;&#38382;&#39064;&#30340;&#20851;&#38190;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#29702;&#35770;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Transferring a pretrained model to a downstream task can be as easy as conducting linear probing with target data, that is, training a linear classifier upon frozen features extracted from the pretrained model. As there may exist significant gaps between pretraining and downstream datasets, one may ask whether all dimensions of the pretrained features are useful for a given downstream task. We show that, for linear probing, the pretrained features can be extremely redundant when the downstream data is scarce, or few-shot. For some cases such as 5-way 1-shot tasks, using only 1\% of the most important feature dimensions is able to recover the performance achieved by using the full representation. Interestingly, most dimensions are redundant only under few-shot settings and gradually become useful when the number of shots increases, suggesting that feature redundancy may be the key to characterizing the "few-shot" nature of few-shot transfer problems. We give a theoretical understanding 
&lt;/p&gt;</description></item></channel></rss>