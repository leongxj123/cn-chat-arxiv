<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;HASTE&#30340;&#27169;&#22359;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#25216;&#26415;&#65292;&#26080;&#38656;&#20219;&#20309;&#35757;&#32451;&#25110;&#31934;&#35843;&#21363;&#21487;&#23454;&#26102;&#38477;&#20302;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#19988;&#22312;&#21387;&#32553;&#29305;&#24449;&#22270;&#26102;&#20960;&#20046;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.17211</link><description>&lt;p&gt;
&#20351;&#29992;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#22312;CNN&#20013;&#23454;&#29616;&#21363;&#26102;&#22797;&#26434;&#24230;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Instant Complexity Reduction in CNNs using Locality-Sensitive Hashing. (arXiv:2309.17211v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17211
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;HASTE&#30340;&#27169;&#22359;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#25216;&#26415;&#65292;&#26080;&#38656;&#20219;&#20309;&#35757;&#32451;&#25110;&#31934;&#35843;&#21363;&#21487;&#23454;&#26102;&#38477;&#20302;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#19988;&#22312;&#21387;&#32553;&#29305;&#24449;&#22270;&#26102;&#20960;&#20046;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35774;&#22791;&#19978;&#38477;&#20302;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#32467;&#26500;&#21270;&#21098;&#26525;&#26041;&#27861;&#24050;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#22312;&#19981;&#22826;&#22823;&#31243;&#24230;&#38477;&#20302;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#22823;&#22823;&#20943;&#23569;&#20102;&#28014;&#28857;&#36816;&#31639;&#65288;FLOPs&#65289;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26368;&#26032;&#30340;&#26041;&#27861;&#35201;&#27714;&#36827;&#34892;&#31934;&#35843;&#25110;&#29305;&#23450;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#20197;&#23454;&#29616;&#22312;&#20445;&#30041;&#20934;&#30830;&#24615;&#21644;&#38477;&#20302;FLOPs&#20043;&#38388;&#21512;&#29702;&#25240;&#34935;&#12290;&#36825;&#24341;&#20837;&#20102;&#35745;&#31639;&#24320;&#38144;&#30340;&#39069;&#22806;&#25104;&#26412;&#65292;&#24182;&#38656;&#35201;&#21487;&#29992;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;HASTE&#65288;Hashing for Tractable Efficiency&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#26080;&#38656;&#21442;&#25968;&#21644;&#26080;&#38656;&#25968;&#25454;&#30340;&#27169;&#22359;&#65292;&#21487;&#20197;&#20316;&#20026;&#20219;&#20309;&#24120;&#35268;&#21367;&#31215;&#27169;&#22359;&#30340;&#21363;&#25554;&#21363;&#29992;&#26367;&#20195;&#21697;&#12290;&#23427;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#20219;&#20309;&#35757;&#32451;&#25110;&#31934;&#35843;&#30340;&#24773;&#20917;&#19979;&#21363;&#26102;&#38477;&#20302;&#32593;&#32476;&#30340;&#27979;&#35797;&#25512;&#29702;&#25104;&#26412;&#12290;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65288;LSH&#65289;&#26469;&#26816;&#27979;&#29305;&#24449;&#22270;&#20013;&#30340;&#20887;&#20313;&#65292;&#25105;&#20204;&#33021;&#22815;&#22823;&#24133;&#21387;&#32553;&#28508;&#22312;&#29305;&#24449;&#22270;&#32780;&#20960;&#20046;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
To reduce the computational cost of convolutional neural networks (CNNs) for usage on resource-constrained devices, structured pruning approaches have shown promising results, drastically reducing floating-point operations (FLOPs) without substantial drops in accuracy. However, most recent methods require fine-tuning or specific training procedures to achieve a reasonable trade-off between retained accuracy and reduction in FLOPs. This introduces additional cost in the form of computational overhead and requires training data to be available. To this end, we propose HASTE (Hashing for Tractable Efficiency), a parameter-free and data-free module that acts as a plug-and-play replacement for any regular convolution module. It instantly reduces the network's test-time inference cost without requiring any training or fine-tuning. We are able to drastically compress latent feature maps without sacrificing much accuracy by using locality-sensitive hashing (LSH) to detect redundancies in the c
&lt;/p&gt;</description></item></channel></rss>