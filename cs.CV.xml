<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#22823;&#35268;&#27169;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#29983;&#25104;&#22270;&#20687;&#22686;&#24378;&#25968;&#25454;&#38598;&#20197;&#25913;&#36827;&#27169;&#22411;&#36328;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.02353</link><description>&lt;p&gt;
&#21033;&#29992;&#35821;&#35328;&#22312;&#22270;&#20687;&#20013;&#36827;&#34892;&#35821;&#20041;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Semantic Augmentation in Images using Language
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02353
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#22823;&#35268;&#27169;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#29983;&#25104;&#22270;&#20687;&#22686;&#24378;&#25968;&#25454;&#38598;&#20197;&#25913;&#36827;&#27169;&#22411;&#36328;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#38750;&#24120;&#24222;&#22823;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#65292;&#32570;&#20047;&#36825;&#20123;&#25968;&#25454;&#38598;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#24182;&#38480;&#21046;&#20854;&#27867;&#21270;&#21040;&#29616;&#23454;&#19990;&#30028;&#31034;&#20363;&#30340;&#33021;&#21147;&#12290;&#26368;&#36817;&#25193;&#25955;&#27169;&#22411;&#30340;&#36827;&#23637;&#20351;&#24471;&#33021;&#22815;&#22522;&#20110;&#25991;&#26412;&#36755;&#20837;&#29983;&#25104;&#36924;&#30495;&#30340;&#22270;&#20687;&#12290;&#21033;&#29992;&#29992;&#20110;&#35757;&#32451;&#36825;&#20123;&#25193;&#25955;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#30340;&#22270;&#20687;&#26469;&#22686;&#24378;&#29616;&#26377;&#25968;&#25454;&#38598;&#30340;&#25216;&#26415;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#21508;&#31181;&#26377;&#25928;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292;&#20197;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#36328;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02353v1 Announce Type: cross  Abstract: Deep Learning models are incredibly data-hungry and require very large labeled datasets for supervised learning. As a consequence, these models often suffer from overfitting, limiting their ability to generalize to real-world examples. Recent advancements in diffusion models have enabled the generation of photorealistic images based on textual inputs. Leveraging the substantial datasets used to train these diffusion models, we propose a technique to utilize generated images to augment existing datasets. This paper explores various strategies for effective data augmentation to improve the out-of-domain generalization capabilities of deep learning models.
&lt;/p&gt;</description></item></channel></rss>