<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#25193;&#25955;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#29992;&#20110;&#36755;&#20837;&#32423;&#21518;&#38376;&#26816;&#27979;&#65292;&#24357;&#34917;&#20102;&#35813;&#39046;&#22495;&#30340;&#31354;&#30333;&#65292;&#24182;&#19981;&#38656;&#35201;&#35775;&#38382;&#27169;&#22411;&#30340;&#30333;&#30418;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2404.01101</link><description>&lt;p&gt;
UFID: &#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#29992;&#20110;&#25193;&#25955;&#27169;&#22411;&#19978;&#30340;&#36755;&#20837;&#32423;&#21518;&#38376;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
UFID: A Unified Framework for Input-level Backdoor Detection on Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01101
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#29992;&#20110;&#36755;&#20837;&#32423;&#21518;&#38376;&#26816;&#27979;&#65292;&#24357;&#34917;&#20102;&#35813;&#39046;&#22495;&#30340;&#31354;&#30333;&#65292;&#24182;&#19981;&#38656;&#35201;&#35775;&#38382;&#27169;&#22411;&#30340;&#30333;&#30418;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#65292;&#21363;&#24694;&#24847;&#25915;&#20987;&#32773;&#22312;&#35757;&#32451;&#38454;&#27573;&#36890;&#36807;&#23545;&#37096;&#20998;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#27602;&#21270;&#26469;&#27880;&#20837;&#21518;&#38376;&#12290;&#20026;&#20102;&#20943;&#36731;&#21518;&#38376;&#25915;&#20987;&#30340;&#23041;&#32961;&#65292;&#23545;&#21518;&#38376;&#26816;&#27979;&#36827;&#34892;&#20102;&#22823;&#37327;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#27809;&#26377;&#20154;&#20026;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#20102;&#19987;&#38376;&#30340;&#21518;&#38376;&#26816;&#27979;&#26041;&#27861;&#65292;&#20351;&#24471;&#36825;&#19968;&#39046;&#22495;&#36739;&#23569;&#34987;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20219;&#21153;&#19978;&#65292;&#24456;&#38590;&#36731;&#26494;&#22320;&#23558;&#20854;&#36866;&#24212;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#21518;&#38376;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#26041;&#27861;&#38656;&#35201;&#35775;&#38382;&#27169;&#22411;&#26435;&#37325;&#21644;&#26550;&#26500;&#30340;&#30333;&#30418;&#35775;&#38382;&#65292;&#25110;&#27010;&#29575;logits&#20316;&#20026;&#39069;&#22806;&#20449;&#24687;&#65292;&#36825;&#24182;&#19981;&#24635;&#26159;&#20999;&#23454;&#21487;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01101v1 Announce Type: cross  Abstract: Diffusion Models are vulnerable to backdoor attacks, where malicious attackers inject backdoors by poisoning some parts of the training samples during the training stage. This poses a serious threat to the downstream users, who query the diffusion models through the API or directly download them from the internet. To mitigate the threat of backdoor attacks, there have been a plethora of investigations on backdoor detections. However, none of them designed a specialized backdoor detection method for diffusion models, rendering the area much under-explored. Moreover, these prior methods mainly focus on the traditional neural networks in the classification task, which cannot be adapted to the backdoor detections on the generative task easily. Additionally, most of the prior methods require white-box access to model weights and architectures, or the probability logits as additional information, which are not always practical. In this paper
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SelfFed&#30340;&#33258;&#30417;&#30563;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;IoMT&#20013;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#26631;&#31614;&#21294;&#20047;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#20004;&#20010;&#38454;&#27573;&#65292;&#36890;&#36807;&#20998;&#25955;&#35757;&#32451;&#21644;&#22686;&#24378;&#24314;&#27169;&#26469;&#20811;&#26381;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#26631;&#31614;&#31232;&#32570;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.01514</link><description>&lt;p&gt;
SelfFed: &#33258;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#29992;&#20110;IoMT&#20013;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#26631;&#31614;&#21294;&#20047;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
SelfFed: Self-supervised Federated Learning for Data Heterogeneity and Label Scarcity in IoMT. (arXiv:2307.01514v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01514
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SelfFed&#30340;&#33258;&#30417;&#30563;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;IoMT&#20013;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#26631;&#31614;&#21294;&#20047;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#20004;&#20010;&#38454;&#27573;&#65292;&#36890;&#36807;&#20998;&#25955;&#35757;&#32451;&#21644;&#22686;&#24378;&#24314;&#27169;&#26469;&#20811;&#26381;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#26631;&#31614;&#31232;&#32570;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#22312;&#34892;&#19994;&#21644;&#30740;&#31350;&#39046;&#22495;&#20013;&#24341;&#36215;&#20102;&#24456;&#22823;&#30340;&#20852;&#36259;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#21327;&#20316;&#23398;&#20064;&#26410;&#26631;&#35760;&#20294;&#23396;&#31435;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#33258;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#31574;&#30053;&#22312;&#26631;&#31614;&#31232;&#32570;&#21644;&#25968;&#25454;&#24322;&#36136;&#24615;&#65288;&#21363;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#65289;&#26041;&#38754;&#23384;&#22312;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#21307;&#30103;&#29289;&#32852;&#32593;&#65288;IoMT&#65289;&#30340;SelfFed&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;SelfFed&#26694;&#26550;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#12290;&#31532;&#19968;&#20010;&#38454;&#27573;&#26159;&#39044;&#35757;&#32451;&#33539;&#24335;&#65292;&#20351;&#29992;&#22522;&#20110;Swin Transformer&#30340;&#32534;&#30721;&#22120;&#20197;&#20998;&#25955;&#30340;&#26041;&#24335;&#36827;&#34892;&#22686;&#24378;&#24314;&#27169;&#12290;SelfFed&#26694;&#26550;&#30340;&#31532;&#19968;&#20010;&#38454;&#27573;&#26377;&#21161;&#20110;&#20811;&#26381;&#25968;&#25454;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;&#31532;&#20108;&#20010;&#38454;&#27573;&#26159;&#24494;&#35843;&#33539;&#24335;&#65292;&#24341;&#20837;&#23545;&#27604;&#32593;&#32476;&#21644;&#19968;&#31181;&#22312;&#26377;&#38480;&#26631;&#35760;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;&#26032;&#22411;&#32858;&#21512;&#31574;&#30053;&#65292;&#29992;&#20110;&#30446;&#26631;&#20219;&#21153;&#30340;&#20998;&#25955;&#35757;&#32451;&#12290;&#36825;&#20010;&#24494;&#35843;&#38454;&#27573;&#20811;&#26381;&#20102;&#26631;&#31614;&#31232;&#32570;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning in federated learning paradigm has been gaining a lot of interest both in industry and research due to the collaborative learning capability on unlabeled yet isolated data. However, self-supervised based federated learning strategies suffer from performance degradation due to label scarcity and diverse data distributions, i.e., data heterogeneity. In this paper, we propose the SelfFed framework for Internet of Medical Things (IoMT). Our proposed SelfFed framework works in two phases. The first phase is the pre-training paradigm that performs augmentive modeling using Swin Transformer based encoder in a decentralized manner. The first phase of SelfFed framework helps to overcome the data heterogeneity issue. The second phase is the fine-tuning paradigm that introduces contrastive network and a novel aggregation strategy that is trained on limited labeled data for a target task in a decentralized manner. This fine-tuning stage overcomes the label scarcity problem
&lt;/p&gt;</description></item></channel></rss>