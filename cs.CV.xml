<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#25552;&#20986;&#20102;&#31070;&#32463;&#27133;&#35299;&#37322;&#22120;&#65288;NSI&#65289;&#65292;&#36890;&#36807;&#27133;&#34920;&#31034;&#23398;&#20064;&#25509;&#22320;&#21644;&#29983;&#25104;&#29289;&#20307;&#35821;&#20041;&#65292;&#23454;&#29616;&#20102;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#29289;&#20307;&#35821;&#20041;&#32467;&#21512;&#21040;&#25277;&#35937;&#20013;&#12290;</title><link>https://arxiv.org/abs/2403.07887</link><description>&lt;p&gt;
&#31070;&#32463;&#27133;&#35299;&#37322;&#22120;&#65306;&#22312;&#26032;&#20852;&#30340;&#27133;&#34920;&#31034;&#20013;&#25509;&#22320;&#23545;&#35937;&#35821;&#20041;
&lt;/p&gt;
&lt;p&gt;
Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07887
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31070;&#32463;&#27133;&#35299;&#37322;&#22120;&#65288;NSI&#65289;&#65292;&#36890;&#36807;&#27133;&#34920;&#31034;&#23398;&#20064;&#25509;&#22320;&#21644;&#29983;&#25104;&#29289;&#20307;&#35821;&#20041;&#65292;&#23454;&#29616;&#20102;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#29289;&#20307;&#35821;&#20041;&#32467;&#21512;&#21040;&#25277;&#35937;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#20307;&#20013;&#24515;&#26041;&#27861;&#22312;&#23558;&#21407;&#22987;&#24863;&#30693;&#26080;&#30417;&#30563;&#20998;&#35299;&#20026;&#20016;&#23500;&#30340;&#31867;&#20284;&#29289;&#20307;&#30340;&#25277;&#35937;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#29289;&#20307;&#35821;&#20041;&#25509;&#22320;&#21040;&#23398;&#21040;&#30340;&#25277;&#35937;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#36825;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#19979;&#28216;&#29702;&#35299;&#24212;&#29992;&#20013;&#30340;&#37319;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#31070;&#32463;&#27133;&#35299;&#37322;&#22120;&#65288;NSI&#65289;&#65292;&#23427;&#36890;&#36807;&#27133;&#34920;&#31034;&#23398;&#20064;&#25509;&#22320;&#21644;&#29983;&#25104;&#29289;&#20307;&#35821;&#20041;&#12290;NSI&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#31867;&#20284;XML&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#23427;&#20351;&#29992;&#31616;&#21333;&#30340;&#35821;&#27861;&#35268;&#21017;&#23558;&#22330;&#26223;&#30340;&#29289;&#20307;&#35821;&#20041;&#32452;&#32455;&#25104;&#20197;&#29289;&#20307;&#20026;&#20013;&#24515;&#30340;&#31243;&#24207;&#21407;&#35821;&#12290;&#28982;&#21518;&#65292;&#19968;&#20010;&#23545;&#40784;&#27169;&#22411;&#23398;&#20064;&#36890;&#36807;&#20849;&#20139;&#23884;&#20837;&#31354;&#38388;&#19978;&#30340;&#21452;&#23618;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#23558;&#31243;&#24207;&#21407;&#35821;&#25509;&#22320;&#21040;&#27133;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26500;&#24314;NSI&#31243;&#24207;&#29983;&#25104;&#27169;&#22411;&#65292;&#21033;&#29992;&#23545;&#40784;&#27169;&#22411;&#25512;&#26029;&#30340;&#23494;&#38598;&#20851;&#32852;&#20174;&#27133;&#29983;&#25104;&#20197;&#29289;&#20307;&#20026;&#20013;&#24515;&#30340;&#31243;&#24207;&#12290;&#22312;&#21452;&#27169;&#24335;&#26816;&#32034;&#23454;&#39564;&#20013;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07887v1 Announce Type: cross  Abstract: Object-centric methods have seen significant progress in unsupervised decomposition of raw perception into rich object-like abstractions. However, limited ability to ground object semantics of the real world into the learned abstractions has hindered their adoption in downstream understanding applications. We present the Neural Slot Interpreter (NSI) that learns to ground and generate object semantics via slot representations. At the core of NSI is an XML-like programming language that uses simple syntax rules to organize the object semantics of a scene into object-centric program primitives. Then, an alignment model learns to ground program primitives into slots through a bi-level contrastive learning objective over a shared embedding space. Finally, we formulate the NSI program generator model to use the dense associations inferred from the alignment model to generate object-centric programs from slots. Experiments on bi-modal retrie
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;MRI&#37325;&#24314;&#30340;&#20613;&#37324;&#21494;&#22495;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#22270;&#20687;&#31354;&#38388;&#24418;&#24335;&#20027;&#20041;&#65292;&#24182;&#20998;&#26512;&#20102;&#22312;CNN&#25512;&#26029;&#36807;&#31243;&#20013;&#22122;&#22768;&#20256;&#25773;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.17410</link><description>&lt;p&gt;
&#20613;&#37324;&#21494;&#22495;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#22270;&#20687;&#31354;&#38388;&#24418;&#24335;&#20027;&#20041;&#29992;&#20110;&#22122;&#22768;&#20256;&#25773;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A novel image space formalism of Fourier domain interpolation neural networks for noise propagation analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17410
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;MRI&#37325;&#24314;&#30340;&#20613;&#37324;&#21494;&#22495;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#22270;&#20687;&#31354;&#38388;&#24418;&#24335;&#20027;&#20041;&#65292;&#24182;&#20998;&#26512;&#20102;&#22312;CNN&#25512;&#26029;&#36807;&#31243;&#20013;&#22122;&#22768;&#20256;&#25773;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26088;&#22312;&#20026;MRI&#37325;&#24314;&#20013;&#30340;&#22270;&#20687;&#22495;&#25554;&#20540;&#24320;&#21457;&#22810;&#23618;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#30340;&#22270;&#20687;&#31354;&#38388;&#24418;&#24335;&#20027;&#20041;&#65292;&#24182;&#22312;CNN&#25512;&#26029;&#36807;&#31243;&#20013;&#23545;&#22122;&#22768;&#20256;&#25773;&#36827;&#34892;&#20998;&#26512;&#12290;&#36890;&#36807;&#20351;&#29992;&#22797;&#20540;&#25972;&#27969;&#32447;&#24615;&#21333;&#20803;&#22312;&#20613;&#37324;&#21494;&#22495;&#65288;&#20063;&#31216;&#20026;k&#31354;&#38388;&#65289;&#20013;&#30340;&#38750;&#32447;&#24615;&#28608;&#27963;&#65292;&#23558;&#20854;&#34920;&#31034;&#20026;&#19982;&#28608;&#27963;&#25513;&#27169;&#30340;&#36880;&#20803;&#32032;&#20056;&#27861;&#12290;&#36825;&#31181;&#25805;&#20316;&#22312;&#22270;&#20687;&#31354;&#38388;&#20013;&#36716;&#25442;&#20026;&#21367;&#31215;&#12290;&#22312;k&#31354;&#38388;&#32593;&#32476;&#35757;&#32451;&#21518;&#65292;&#36825;&#31181;&#26041;&#27861;&#20026;&#30456;&#23545;&#20110;&#21035;&#21517;&#32447;&#22280;&#22270;&#20687;&#30340;&#37325;&#24314;&#22270;&#20687;&#30340;&#23548;&#25968;&#25552;&#20379;&#20102;&#19968;&#20010;&#20195;&#25968;&#34920;&#36798;&#24335;&#65292;&#36825;&#20123;&#21035;&#21517;&#32447;&#22280;&#22270;&#20687;&#20316;&#20026;&#22270;&#20687;&#31354;&#38388;&#20013;&#32593;&#32476;&#30340;&#36755;&#20837;&#24352;&#37327;&#12290;&#36825;&#20351;&#24471;&#21487;&#20197;&#36890;&#36807;&#20998;&#26512;&#20272;&#35745;&#32593;&#32476;&#25512;&#26029;&#20013;&#30340;&#26041;&#24046;&#65292;&#24182;&#29992;&#20110;&#25551;&#36848;&#22122;&#22768;&#29305;&#24615;&#12290;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#21644;&#22522;&#20110;&#33258;&#21160;&#24494;&#20998;&#30340;&#25968;&#20540;&#26041;&#27861;&#36827;&#34892;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17410v1 Announce Type: cross  Abstract: Purpose: To develop an image space formalism of multi-layer convolutional neural networks (CNNs) for Fourier domain interpolation in MRI reconstructions and analytically estimate noise propagation during CNN inference. Theory and Methods: Nonlinear activations in the Fourier domain (also known as k-space) using complex-valued Rectifier Linear Units are expressed as elementwise multiplication with activation masks. This operation is transformed into a convolution in the image space. After network training in k-space, this approach provides an algebraic expression for the derivative of the reconstructed image with respect to the aliased coil images, which serve as the input tensors to the network in the image space. This allows the variance in the network inference to be estimated analytically and to be used to describe noise characteristics. Monte-Carlo simulations and numerical approaches based on auto-differentiation were used for val
&lt;/p&gt;</description></item></channel></rss>