<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#26041;&#27861;&#26469;&#20272;&#35745;&#20114;&#32852;&#32593;&#23553;&#38145;&#23545;&#32463;&#27982;&#27963;&#21160;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#21360;&#24230;&#30340;Internet&#23553;&#38145;&#23548;&#33268;&#32463;&#27982;&#27963;&#21160;&#20943;&#23569;&#36229;&#36807;50&#65285;&#65292;&#23545;&#20840;&#29699;&#25968;&#23383;&#32463;&#27982;&#30340;&#23553;&#38145;&#30495;&#23454;&#25104;&#26412;&#20135;&#29983;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2309.14630</link><description>&lt;p&gt;
&#33258;&#30001;&#19981;&#36830;&#32493;&#35774;&#35745;&#65306;&#24212;&#29992;&#20110;&#20114;&#32852;&#32593;&#23553;&#38145;&#30340;&#32463;&#27982;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Free Discontinuity Design: With an Application to the Economic Effects of Internet Shutdowns. (arXiv:2309.14630v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#26041;&#27861;&#26469;&#20272;&#35745;&#20114;&#32852;&#32593;&#23553;&#38145;&#23545;&#32463;&#27982;&#27963;&#21160;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#21360;&#24230;&#30340;Internet&#23553;&#38145;&#23548;&#33268;&#32463;&#27982;&#27963;&#21160;&#20943;&#23569;&#36229;&#36807;50&#65285;&#65292;&#23545;&#20840;&#29699;&#25968;&#23383;&#32463;&#27982;&#30340;&#23553;&#38145;&#30495;&#23454;&#25104;&#26412;&#20135;&#29983;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27835;&#30103;&#20998;&#37197;&#20013;&#30340;&#38408;&#20540;&#21487;&#20197;&#20135;&#29983;&#32467;&#26524;&#30340;&#19981;&#36830;&#32493;&#24615;&#65292;&#20174;&#32780;&#25581;&#31034;&#22240;&#26524;&#27934;&#23519;&#21147;&#12290;&#22312;&#35768;&#22810;&#24773;&#22659;&#20013;&#65292;&#22914;&#22320;&#29702;&#29615;&#22659;&#65292;&#36825;&#20123;&#38408;&#20540;&#26159;&#26410;&#30693;&#21644;&#22810;&#21464;&#37327;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#26041;&#27861;&#26469;&#20272;&#35745;&#30001;&#27492;&#20135;&#29983;&#30340;&#19981;&#36830;&#32493;&#24615;&#65292;&#36890;&#36807;&#23558;&#22238;&#24402;&#26354;&#38754;&#20998;&#21106;&#25104;&#24179;&#28369;&#21644;&#19981;&#36830;&#32493;&#37096;&#20998;&#12290;&#35813;&#20272;&#35745;&#22120;&#20351;&#29992;&#20102;Mumford-Shah&#20989;&#25968;&#30340;&#20984;&#26494;&#24347;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20854;&#35782;&#21035;&#21644;&#25910;&#25947;&#24615;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20272;&#35745;&#21360;&#24230;&#30340;Internet&#23553;&#38145;&#23548;&#33268;&#32463;&#27982;&#27963;&#21160;&#20943;&#23569;&#36229;&#36807;50&#65285;&#65292;&#36828;&#36828;&#36229;&#36807;&#20197;&#21069;&#30340;&#20272;&#35745;&#65292;&#24182;&#23545;&#20840;&#29699;&#25968;&#23383;&#32463;&#27982;&#30340;&#27492;&#31867;&#23553;&#38145;&#30340;&#30495;&#23454;&#25104;&#26412;&#20135;&#29983;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thresholds in treatment assignments can produce discontinuities in outcomes, revealing causal insights. In many contexts, like geographic settings, these thresholds are unknown and multivariate. We propose a non-parametric method to estimate the resulting discontinuities by segmenting the regression surface into smooth and discontinuous parts. This estimator uses a convex relaxation of the Mumford-Shah functional, for which we establish identification and convergence. Using our method, we estimate that an internet shutdown in India resulted in a reduction of economic activity by over 50%, greatly surpassing previous estimates and shedding new light on the true cost of such shutdowns for digital economies globally.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26234;&#33021;&#35786;&#26029;&#26694;&#26550;&#65292;&#38024;&#23545;&#20302;&#36164;&#28304;&#29615;&#22659;&#23454;&#29616;&#26089;&#26399;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;&#65292;&#24182;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.00046</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#32954;&#30284;&#35786;&#26029;&#33258;&#21160;&#21270;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;
&lt;/p&gt;
&lt;p&gt;
An automated end-to-end deep learning-based framework for lung cancer diagnosis by detecting and classifying the lung nodules. (arXiv:2305.00046v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26234;&#33021;&#35786;&#26029;&#26694;&#26550;&#65292;&#38024;&#23545;&#20302;&#36164;&#28304;&#29615;&#22659;&#23454;&#29616;&#26089;&#26399;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;&#65292;&#24182;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32954;&#30284;&#26159;&#20840;&#29699;&#30284;&#30151;&#30456;&#20851;&#27515;&#20129;&#30340;&#20027;&#35201;&#21407;&#22240;&#65292;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#26089;&#26399;&#35786;&#26029;&#23545;&#20110;&#25913;&#21892;&#24739;&#32773;&#30103;&#25928;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#30340;&#26159;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#33258;&#21160;&#21270;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#29992;&#20110;&#26089;&#26399;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#20302;&#36164;&#28304;&#29615;&#22659;&#12290;&#35813;&#26694;&#26550;&#30001;&#19977;&#20010;&#38454;&#27573;&#32452;&#25104;&#65306;&#20351;&#29992;&#25913;&#36827;&#30340;3D Res-U-Net&#36827;&#34892;&#32954;&#20998;&#21106;&#12289;&#20351;&#29992;YOLO-v5&#36827;&#34892;&#32467;&#33410;&#26816;&#27979;&#12289;&#20351;&#29992;&#22522;&#20110;Vision Transformer&#30340;&#26550;&#26500;&#36827;&#34892;&#20998;&#31867;&#12290;&#25105;&#20204;&#22312;&#24320;&#25918;&#30340;&#25968;&#25454;&#38598;LUNA16&#19978;&#23545;&#35813;&#26694;&#26550;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#30340;&#24615;&#33021;&#26159;&#20351;&#29992;&#21508;&#39046;&#22495;&#30340;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#34913;&#37327;&#30340;&#12290;&#35813;&#26694;&#26550;&#22312;&#32954;&#37096;&#20998;&#21106;dice&#31995;&#25968;&#19978;&#36798;&#21040;&#20102;98.82&#65285;&#65292;&#21516;&#26102;&#26816;&#27979;&#32954;&#32467;&#33410;&#30340;&#24179;&#22343;&#20934;&#30830;&#24230;&#20026;0.76 mAP&#12290;
&lt;/p&gt;
&lt;p&gt;
Lung cancer is a leading cause of cancer-related deaths worldwide, and early detection is crucial for improving patient outcomes. Nevertheless, early diagnosis of cancer is a major challenge, particularly in low-resource settings where access to medical resources and trained radiologists is limited. The objective of this study is to propose an automated end-to-end deep learning-based framework for the early detection and classification of lung nodules, specifically for low-resource settings. The proposed framework consists of three stages: lung segmentation using a modified 3D U-Net named 3D Res-U-Net, nodule detection using YOLO-v5, and classification with a Vision Transformer-based architecture. We evaluated the proposed framework on a publicly available dataset, LUNA16. The proposed framework's performance was measured using the respective domain's evaluation matrices. The proposed framework achieved a 98.82% lung segmentation dice score while detecting the lung nodule with 0.76 mAP
&lt;/p&gt;</description></item><item><title>&#36817;&#24180;&#26469;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#30340;&#26631;&#35760;&#20195;&#20215;&#22823;&#65292;&#26631;&#35760;&#19981;&#36275;&#12290;&#22240;&#27492;&#21457;&#23637;&#20102;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20805;&#20998;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#21644;&#24369;&#26631;&#35760;&#30340;&#25968;&#25454;&#12290;&#35813;&#32508;&#36848;&#24635;&#32467;&#20102;&#36825;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2303.12484</link><description>&lt;p&gt;
&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#30340;&#25361;&#25112;&#19982;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions. (arXiv:2303.12484v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12484
&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#30340;&#26631;&#35760;&#20195;&#20215;&#22823;&#65292;&#26631;&#35760;&#19981;&#36275;&#12290;&#22240;&#27492;&#21457;&#23637;&#20102;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20805;&#20998;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#21644;&#24369;&#26631;&#35760;&#30340;&#25968;&#25454;&#12290;&#35813;&#32508;&#36848;&#24635;&#32467;&#20102;&#36825;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#36817;&#24180;&#26469;&#24471;&#21040;&#20102;&#36805;&#36895;&#21457;&#23637;&#65292;&#24182;&#22312;&#24191;&#27867;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#35757;&#32451;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#25910;&#38598;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#65292;&#36825;&#38656;&#35201;&#26114;&#36149;&#32791;&#26102;&#12290;&#29305;&#21035;&#26159;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#65288;MIA&#65289;&#39046;&#22495;&#65292;&#25968;&#25454;&#26377;&#38480;&#65292;&#26631;&#31614;&#24456;&#38590;&#33719;&#24471;&#12290;&#22240;&#27492;&#65292;&#20154;&#20204;&#24320;&#21457;&#20102;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20805;&#20998;&#21033;&#29992;&#26631;&#35760;&#25968;&#25454;&#20197;&#21450;&#38750;&#26631;&#35760;&#21644;&#24369;&#26631;&#35760;&#25968;&#25454;&#30340;&#20016;&#23500;&#24615;&#12290;&#22312;&#26412;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#23545;&#36817;300&#31687;&#35770;&#25991;&#36827;&#34892;&#20102;&#24191;&#27867;&#35843;&#26597;&#65292;&#20197;&#20840;&#38754;&#27010;&#36848;&#26368;&#26032;&#36827;&#23637;&#30340;&#39640;&#25928;&#26631;&#35760;&#23398;&#20064;&#31574;&#30053;&#22312;MIA&#20013;&#30340;&#30740;&#31350;&#29616;&#29366;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#39640;&#25928;&#26631;&#35760;&#23398;&#20064;&#30340;&#32972;&#26223;&#65292;&#24182;&#23558;&#19981;&#21516;&#26041;&#26696;&#30340;&#26041;&#27861;&#24402;&#31867;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#36890;&#36807;&#27599;&#31181;&#26041;&#26696;&#35814;&#32454;&#30740;&#31350;&#20102;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#28145;&#20837;&#35843;&#26597;&#65292;&#35206;&#30422;&#20102;&#19981;&#20165;&#26159;&#26631;&#20934;&#31574;&#30053;&#65292;&#36824;&#21253;&#25324;&#20351;&#29992;&#21518;&#22788;&#29702;&#21644;&#38598;&#21512;&#26041;&#27861;&#31561;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has seen rapid growth in recent years and achieved state-of-the-art performance in a wide range of applications. However, training models typically requires expensive and time-consuming collection of large quantities of labeled data. This is particularly true within the scope of medical imaging analysis (MIA), where data are limited and labels are expensive to be acquired. Thus, label-efficient deep learning methods are developed to make comprehensive use of the labeled data as well as the abundance of unlabeled and weak-labeled data. In this survey, we extensively investigated over 300 recent papers to provide a comprehensive overview of recent progress on label-efficient learning strategies in MIA. We first present the background of label-efficient learning and categorize the approaches into different schemes. Next, we examine the current state-of-the-art methods in detail through each scheme. Specifically, we provide an in-depth investigation, covering not only canonic
&lt;/p&gt;</description></item></channel></rss>