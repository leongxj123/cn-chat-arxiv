<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GuideGen&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#26681;&#25454;&#25991;&#26412;&#25552;&#31034;&#32852;&#21512;&#29983;&#25104;CT&#22270;&#20687;&#21644;&#33145;&#37096;&#22120;&#23448;&#20197;&#21450;&#32467;&#30452;&#32928;&#30284;&#32452;&#32455;&#25513;&#33180;&#65292;&#20026;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#39046;&#22495;&#25552;&#20379;&#20102;&#19968;&#31181;&#29983;&#25104;&#25968;&#25454;&#38598;&#30340;&#26032;&#36884;&#24452;&#12290;</title><link>https://arxiv.org/abs/2403.07247</link><description>&lt;p&gt;
GuideGen&#65306;&#19968;&#31181;&#29992;&#20110;&#32852;&#21512;CT&#20307;&#31215;&#21644;&#35299;&#21078;&#32467;&#26500;&#29983;&#25104;&#30340;&#25991;&#26412;&#24341;&#23548;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
GuideGen: A Text-guided Framework for Joint CT Volume and Anatomical structure Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07247
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GuideGen&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#26681;&#25454;&#25991;&#26412;&#25552;&#31034;&#32852;&#21512;&#29983;&#25104;CT&#22270;&#20687;&#21644;&#33145;&#37096;&#22120;&#23448;&#20197;&#21450;&#32467;&#30452;&#32928;&#30284;&#32452;&#32455;&#25513;&#33180;&#65292;&#20026;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#39046;&#22495;&#25552;&#20379;&#20102;&#19968;&#31181;&#29983;&#25104;&#25968;&#25454;&#38598;&#30340;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07247v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#20132;&#21449; &#25688;&#35201;&#65306;&#20026;&#20102;&#25910;&#38598;&#24102;&#26377;&#22270;&#20687;&#21644;&#30456;&#24212;&#26631;&#31614;&#30340;&#22823;&#22411;&#21307;&#23398;&#25968;&#25454;&#38598;&#32780;&#36827;&#34892;&#30340;&#27880;&#37322;&#36127;&#25285;&#21644;&#22823;&#37327;&#24037;&#20316;&#24456;&#23569;&#26159;&#21010;&#31639;&#19988;&#20196;&#20154;&#26395;&#32780;&#29983;&#30031;&#30340;&#12290;&#36825;&#23548;&#33268;&#20102;&#32570;&#20047;&#20016;&#23500;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#21066;&#24369;&#20102;&#19979;&#28216;&#20219;&#21153;&#65292;&#24182;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#21152;&#21095;&#20102;&#21307;&#23398;&#39046;&#22495;&#38754;&#20020;&#30340;&#22270;&#20687;&#20998;&#26512;&#25361;&#25112;&#12290;&#20316;&#20026;&#19968;&#31181;&#26435;&#23452;&#20043;&#35745;&#65292;&#37492;&#20110;&#29983;&#25104;&#24615;&#31070;&#32463;&#27169;&#22411;&#30340;&#26368;&#36817;&#25104;&#21151;&#65292;&#29616;&#22312;&#21487;&#20197;&#22312;&#22806;&#37096;&#32422;&#26463;&#30340;&#24341;&#23548;&#19979;&#20197;&#39640;&#20445;&#30495;&#24230;&#21512;&#25104;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#31181;&#21487;&#33021;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;GuideGen&#65306;&#19968;&#31181;&#32852;&#21512;&#29983;&#25104;&#33145;&#37096;&#22120;&#23448;&#21644;&#32467;&#30452;&#32928;&#30284;CT&#22270;&#20687;&#21644;&#32452;&#32455;&#25513;&#33180;&#30340;&#31649;&#32447;&#65292;&#20854;&#21463;&#25991;&#26412;&#25552;&#31034;&#26465;&#20214;&#32422;&#26463;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20307;&#31215;&#25513;&#33180;&#37319;&#26679;&#22120;&#65292;&#20197;&#36866;&#24212;&#25513;&#33180;&#26631;&#31614;&#30340;&#31163;&#25955;&#20998;&#24067;&#24182;&#29983;&#25104;&#20302;&#20998;&#36776;&#29575;3D&#32452;&#32455;&#25513;&#33180;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30340;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#22120;&#20250;&#22312;&#25910;&#21040;&#30456;&#24212;&#25991;&#26412;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#33258;&#22238;&#24402;&#29983;&#25104;CT&#20999;&#29255;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07247v1 Announce Type: cross  Abstract: The annotation burden and extensive labor for gathering a large medical dataset with images and corresponding labels are rarely cost-effective and highly intimidating. This results in a lack of abundant training data that undermines downstream tasks and partially contributes to the challenge image analysis faces in the medical field. As a workaround, given the recent success of generative neural models, it is now possible to synthesize image datasets at a high fidelity guided by external constraints. This paper explores this possibility and presents \textbf{GuideGen}: a pipeline that jointly generates CT images and tissue masks for abdominal organs and colorectal cancer conditioned on a text prompt. Firstly, we introduce Volumetric Mask Sampler to fit the discrete distribution of mask labels and generate low-resolution 3D tissue masks. Secondly, our Conditional Image Generator autoregressively generates CT slices conditioned on a corre
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;V-GLOSS&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#20041;&#30693;&#35782;&#24211;&#29983;&#25104;&#20855;&#26377;&#35270;&#35273;&#22522;&#30784;&#30340;&#31867;&#21035;&#25551;&#36848;&#65292;&#25552;&#39640;&#20102;&#38646;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#24102;&#26377;&#31867;&#21035;&#25551;&#36848;&#30340;&#38134;&#26631;&#20934;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2306.06077</link><description>&lt;p&gt;
&#35270;&#35273;&#35789;&#27719;&#25551;&#36848;&#25552;&#21319;&#38646;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;V-GLOSS&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#20041;&#30693;&#35782;&#24211;&#29983;&#25104;&#20855;&#26377;&#35270;&#35273;&#22522;&#30784;&#30340;&#31867;&#21035;&#25551;&#36848;&#65292;&#25552;&#39640;&#20102;&#38646;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#24102;&#26377;&#31867;&#21035;&#25551;&#36848;&#30340;&#38134;&#26631;&#20934;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#35270;&#35273;&#27169;&#22411;&#22914;CLIP&#22312;&#38646;&#26679;&#26412;&#35270;&#35273;&#20219;&#21153;&#65288;&#20363;&#22914;&#38646;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;ZSIC&#65289;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#20855;&#20307;&#21644;&#23500;&#26377;&#34920;&#29616;&#21147;&#30340;&#31867;&#21035;&#25551;&#36848;&#20173;&#28982;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#31890;&#24230;&#21644;&#26631;&#31614;&#27495;&#20041;&#31561;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;V-GLOSS&#65306;Visual Glosses&#65292;&#23427;&#21033;&#29992;&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#20041;&#30693;&#35782;&#24211;&#26469;&#29983;&#25104;&#20855;&#26377;&#35270;&#35273;&#22522;&#30784;&#30340;&#31867;&#21035;&#25551;&#36848;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22522;&#20934;ZSIC&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;ImageNet&#21644;STL-10&#65289;&#19978;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#26469;&#23637;&#31034;V-GLOSS&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#30001;V-GLOSS&#29983;&#25104;&#30340;&#24102;&#26377;&#31867;&#21035;&#25551;&#36848;&#30340;&#38134;&#26631;&#20934;&#25968;&#25454;&#38598;&#65292;&#24182;&#23637;&#31034;&#20854;&#29992;&#20110;&#35270;&#35273;&#20219;&#21153;&#30340;&#26377;&#29992;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#28304;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language-vision models like CLIP have made significant progress in zero-shot vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive class descriptions remains a major challenge. Existing approaches suffer from granularity and label ambiguity issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel method leveraging modern language models and semantic knowledge bases to produce visually-grounded class descriptions. We demonstrate V-GLOSS's effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets including ImageNet and STL-10. In addition, we introduce a silver dataset with class descriptions generated by V-GLOSS, and show its usefulness for vision tasks. We make available our code and dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#35745;&#31639;&#21644;&#20998;&#26512;ReLU&#32593;&#32476;&#22810;&#38754;&#20307;&#30340;&#21333;&#32431;&#24418;&#30452;&#26041;&#22270;&#65292;&#21457;&#29616;&#22312;&#21021;&#22987;&#21270;&#21644;&#26799;&#24230;&#19979;&#38477;&#26102;&#23427;&#20204;&#32467;&#26500;&#30456;&#23545;&#31616;&#21333;&#65292;&#36825;&#35828;&#26126;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#20559;&#35265;&#12290;</title><link>http://arxiv.org/abs/2305.09145</link><description>&lt;p&gt;
&#28145;&#23618;ReLU&#32593;&#32476;&#30340;&#22810;&#38754;&#20307;&#24322;&#24120;&#31616;&#21333;
&lt;/p&gt;
&lt;p&gt;
Deep ReLU Networks Have Surprisingly Simple Polytopes. (arXiv:2305.09145v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#35745;&#31639;&#21644;&#20998;&#26512;ReLU&#32593;&#32476;&#22810;&#38754;&#20307;&#30340;&#21333;&#32431;&#24418;&#30452;&#26041;&#22270;&#65292;&#21457;&#29616;&#22312;&#21021;&#22987;&#21270;&#21644;&#26799;&#24230;&#19979;&#38477;&#26102;&#23427;&#20204;&#32467;&#26500;&#30456;&#23545;&#31616;&#21333;&#65292;&#36825;&#35828;&#26126;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ReLU&#32593;&#32476;&#26159;&#19968;&#31181;&#22810;&#38754;&#20307;&#19978;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#12290;&#30740;&#31350;&#36825;&#31181;&#22810;&#38754;&#20307;&#30340;&#24615;&#36136;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#30740;&#31350;&#21644;&#21457;&#23637;&#33267;&#20851;&#37325;&#35201;&#12290;&#30446;&#21069;&#65292;&#23545;&#20110;&#22810;&#38754;&#20307;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#20165;&#20572;&#30041;&#22312;&#35745;&#31639;&#25968;&#37327;&#30340;&#27700;&#24179;&#65292;&#36825;&#36828;&#36828;&#19981;&#33021;&#23436;&#25972;&#22320;&#25551;&#36848;&#22810;&#38754;&#20307;&#12290;&#20026;&#20102;&#23558;&#29305;&#24449;&#25552;&#21319;&#21040;&#19968;&#20010;&#26032;&#30340;&#27700;&#24179;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#19977;&#35282;&#21078;&#20998;&#22810;&#38754;&#20307;&#24471;&#20986;&#22810;&#38754;&#20307;&#30340;&#24418;&#29366;&#12290;&#36890;&#36807;&#35745;&#31639;&#21644;&#20998;&#26512;&#19981;&#21516;&#22810;&#38754;&#20307;&#30340;&#21333;&#32431;&#24418;&#30452;&#26041;&#22270;&#65292;&#25105;&#20204;&#21457;&#29616;ReLU&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#21644;&#26799;&#24230;&#19979;&#38477;&#26102;&#20855;&#26377;&#30456;&#23545;&#31616;&#21333;&#30340;&#22810;&#38754;&#20307;&#32467;&#26500;&#65292;&#23613;&#31649;&#36825;&#20123;&#22810;&#38754;&#20307;&#20174;&#29702;&#35770;&#19978;&#26469;&#35828;&#21487;&#20197;&#38750;&#24120;&#20016;&#23500;&#21644;&#22797;&#26434;&#12290;&#36825;&#19968;&#21457;&#29616;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#20559;&#35265;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#38750;&#24179;&#20961;&#30340;&#32452;&#21512;&#25512;&#23548;&#26469;&#29702;&#35770;&#19978;&#35299;&#37322;&#20026;&#20160;&#20040;&#22686;&#21152;&#28145;&#24230;&#19981;&#20250;&#21019;&#24314;&#26356;&#22797;&#26434;&#30340;&#22810;&#38754;&#20307;&#65292;&#36890;&#36807;&#38480;&#21046;&#27599;&#20010;&#32500;&#24230;&#30340;&#24179;&#22343;&#21333;&#32431;&#24418;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
A ReLU network is a piecewise linear function over polytopes. Figuring out the properties of such polytopes is of fundamental importance for the research and development of neural networks. So far, either theoretical or empirical studies on polytopes only stay at the level of counting their number, which is far from a complete characterization of polytopes. To upgrade the characterization to a new level, here we propose to study the shapes of polytopes via the number of simplices obtained by triangulating the polytope. Then, by computing and analyzing the histogram of simplices across polytopes, we find that a ReLU network has relatively simple polytopes under both initialization and gradient descent, although these polytopes theoretically can be rather diverse and complicated. This finding can be appreciated as a novel implicit bias. Next, we use nontrivial combinatorial derivation to theoretically explain why adding depth does not create a more complicated polytope by bounding the av
&lt;/p&gt;</description></item></channel></rss>