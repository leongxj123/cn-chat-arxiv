<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#21644;&#22270;&#20248;&#21270;&#30340;&#27169;&#22359;&#21270;&#36319;&#36394;&#22120;LEGO&#65292;&#36890;&#36807;&#38598;&#25104;&#22270;&#20248;&#21270;&#21644;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#25552;&#39640;&#20102;&#22312;&#32447;&#22810;&#30446;&#26631;&#36319;&#36394;&#20013;&#30340;&#25968;&#25454;&#20851;&#32852;&#24615;&#33021;&#12290;&#20351;&#29992;LiDAR&#21333;&#29420;&#36827;&#34892;&#36319;&#36394;&#30340;LEGO&#26041;&#27861;&#22312;KITTI&#30446;&#26631;&#36319;&#36394;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.09908</link><description>&lt;p&gt;
LEGO: &#23545;&#20110;&#22522;&#20110;&#28857;&#20113;&#30340;&#22312;&#32447;&#22810;&#30446;&#26631;&#36319;&#36394;&#30340;&#23398;&#20064;&#21644;&#22270;&#20248;&#21270;&#30340;&#27169;&#22359;&#21270;&#36319;&#36394;&#22120;
&lt;/p&gt;
&lt;p&gt;
LEGO: Learning and Graph-Optimized Modular Tracker for Online Multi-Object Tracking with Point Clouds. (arXiv:2308.09908v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#21644;&#22270;&#20248;&#21270;&#30340;&#27169;&#22359;&#21270;&#36319;&#36394;&#22120;LEGO&#65292;&#36890;&#36807;&#38598;&#25104;&#22270;&#20248;&#21270;&#21644;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#25552;&#39640;&#20102;&#22312;&#32447;&#22810;&#30446;&#26631;&#36319;&#36394;&#20013;&#30340;&#25968;&#25454;&#20851;&#32852;&#24615;&#33021;&#12290;&#20351;&#29992;LiDAR&#21333;&#29420;&#36827;&#34892;&#36319;&#36394;&#30340;LEGO&#26041;&#27861;&#22312;KITTI&#30446;&#26631;&#36319;&#36394;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#22810;&#30446;&#26631;&#36319;&#36394;&#65288;MOT&#65289;&#22312;&#33258;&#20027;&#31995;&#32479;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#36890;&#24120;&#37319;&#29992;&#36319;&#36394;-&#26816;&#27979;&#26041;&#27861;&#65292;&#25968;&#25454;&#20851;&#32852;&#36215;&#21040;&#20102;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#21644;&#22270;&#20248;&#21270;&#65288;LEGO&#65289;&#30340;&#27169;&#22359;&#21270;&#36319;&#36394;&#22120;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#20851;&#32852;&#24615;&#33021;&#12290;&#25152;&#25552;&#20986;&#30340;LEGO&#36319;&#36394;&#22120;&#38598;&#25104;&#20102;&#22270;&#20248;&#21270;&#21644;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#21046;&#23450;&#20851;&#32852;&#35780;&#20998;&#22270;&#65292;&#20174;&#32780;&#23454;&#29616;&#20934;&#30830;&#39640;&#25928;&#30340;&#30446;&#26631;&#21305;&#37197;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#22686;&#24378;&#29366;&#24577;&#26356;&#26032;&#36807;&#31243;&#65292;&#26412;&#25991;&#36824;&#28155;&#21152;&#20102;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65292;&#36890;&#36807;&#23558;&#23545;&#35937;&#29366;&#24577;&#30340;&#26102;&#38388;&#36830;&#36143;&#24615;&#32435;&#20837;&#36319;&#36394;&#20013;&#65292;&#30830;&#20445;&#19968;&#33268;&#30340;&#36319;&#36394;&#12290;&#19982;&#20854;&#20182;&#22312;&#32447;&#36319;&#36394;&#26041;&#27861;&#65288;&#21253;&#25324;&#22522;&#20110;LiDAR&#21644;&#22522;&#20110;LiDAR-&#30456;&#26426;&#34701;&#21512;&#30340;&#26041;&#27861;&#65289;&#30456;&#27604;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#20165;&#21033;&#29992;LiDAR&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#20102;&#21331;&#36234;&#24615;&#33021;&#12290;&#22312;&#25552;&#20132;&#32467;&#26524;&#33267;KITTI&#30446;&#26631;&#36319;&#36394;&#35780;&#20272;&#25490;&#34892;&#27036;&#26102;&#65292;LEGO&#25490;&#21517;&#31532;&#19968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online multi-object tracking (MOT) plays a pivotal role in autonomous systems. The state-of-the-art approaches usually employ a tracking-by-detection method, and data association plays a critical role. This paper proposes a learning and graph-optimized (LEGO) modular tracker to improve data association performance in the existing literature. The proposed LEGO tracker integrates graph optimization and self-attention mechanisms, which efficiently formulate the association score map, facilitating the accurate and efficient matching of objects across time frames. To further enhance the state update process, the Kalman filter is added to ensure consistent tracking by incorporating temporal coherence in the object states. Our proposed method utilizing LiDAR alone has shown exceptional performance compared to other online tracking approaches, including LiDAR-based and LiDAR-camera fusion-based methods. LEGO ranked 1st at the time of submitting results to KITTI object tracking evaluation ranki
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#30340;&#30450;&#30446;&#38450;&#24481;&#26694;&#26550;&#65288;BDMAE&#65289;&#65292;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#38450;&#24481;&#30450;&#30446;&#21518;&#38376;&#25915;&#20987;&#65292;&#19981;&#38656;&#35201;&#39564;&#35777;&#25968;&#25454;&#21644;&#27169;&#22411;&#21442;&#25968;&#65292;&#36890;&#36807;&#27979;&#35797;&#22270;&#20687;&#21644; MAE &#36824;&#21407;&#20043;&#38388;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#21644;&#26631;&#31614;&#19968;&#33268;&#24615;&#26469;&#26816;&#27979;&#21518;&#38376;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2303.15564</link><description>&lt;p&gt;
&#25513;&#30721;&#36824;&#21407;&#25216;&#26415;&#65306;&#21033;&#29992;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#22312;&#27979;&#35797;&#26102;&#38450;&#24481;&#30450;&#30446;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder. (arXiv:2303.15564v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#30340;&#30450;&#30446;&#38450;&#24481;&#26694;&#26550;&#65288;BDMAE&#65289;&#65292;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#38450;&#24481;&#30450;&#30446;&#21518;&#38376;&#25915;&#20987;&#65292;&#19981;&#38656;&#35201;&#39564;&#35777;&#25968;&#25454;&#21644;&#27169;&#22411;&#21442;&#25968;&#65292;&#36890;&#36807;&#27979;&#35797;&#22270;&#20687;&#21644; MAE &#36824;&#21407;&#20043;&#38388;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#21644;&#26631;&#31614;&#19968;&#33268;&#24615;&#26469;&#26816;&#27979;&#21518;&#38376;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23481;&#26131;&#21463;&#21040;&#24694;&#24847;&#25915;&#20987;&#65292;&#25915;&#20987;&#32773;&#20250;&#36890;&#36807;&#22312;&#22270;&#20687;&#19978;&#21472;&#21152;&#29305;&#27530;&#30340;&#35302;&#21457;&#22120;&#26469;&#24694;&#24847;&#25805;&#32437;&#27169;&#22411;&#34892;&#20026;&#65292;&#36825;&#31216;&#20026;&#21518;&#38376;&#25915;&#20987;&#12290;&#29616;&#26377;&#30340;&#21518;&#38376;&#38450;&#24481;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#35775;&#38382;&#19968;&#20123;&#39564;&#35777;&#25968;&#25454;&#21644;&#27169;&#22411;&#21442;&#25968;&#65292;&#36825;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#65292;&#20363;&#22914;&#24403;&#27169;&#22411;&#20316;&#20026;&#20113;&#26381;&#21153;&#25552;&#20379;&#26102;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#33268;&#21147;&#20110;&#27979;&#35797;&#26102;&#30340;&#30450;&#30446;&#21518;&#38376;&#38450;&#24481;&#23454;&#36341;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#40657;&#30418;&#27169;&#22411;&#12290;&#27599;&#20010;&#27979;&#35797;&#22270;&#20687;&#30340;&#30495;&#23454;&#26631;&#31614;&#38656;&#35201;&#20174;&#21487;&#30097;&#27169;&#22411;&#30340;&#30828;&#26631;&#31614;&#39044;&#27979;&#20013;&#24674;&#22797;&#12290;&#28982;&#32780;&#65292;&#22312;&#22270;&#20687;&#31354;&#38388;&#20013;&#21551;&#21457;&#24335;&#35302;&#21457;&#22120;&#25628;&#32034;&#19981;&#36866;&#29992;&#20110;&#22797;&#26434;&#35302;&#21457;&#22120;&#25110;&#39640;&#20998;&#36776;&#29575;&#30340;&#22270;&#29255;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#36890;&#29992;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#30340;&#30450;&#30446;&#38450;&#24481;&#26694;&#26550;&#65288;BDMAE&#65289;&#65292;&#36890;&#36807;&#27979;&#35797;&#22270;&#20687;&#21644; MAE &#36824;&#21407;&#20043;&#38388;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#21644;&#26631;&#31614;&#19968;&#33268;&#24615;&#26469;&#26816;&#27979;&#21518;&#38376;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks are vulnerable to backdoor attacks, where an adversary maliciously manipulates the model behavior through overlaying images with special triggers. Existing backdoor defense methods often require accessing a few validation data and model parameters, which are impractical in many real-world applications, e.g., when the model is provided as a cloud service. In this paper, we address the practical task of blind backdoor defense at test time, in particular for black-box models. The true label of every test image needs to be recovered on the fly from the hard label predictions of a suspicious model. The heuristic trigger search in image space, however, is not scalable to complex triggers or high image resolution. We circumvent such barrier by leveraging generic image generation models, and propose a framework of Blind Defense with Masked AutoEncoder (BDMAE). It uses the image structural similarity and label consistency between the test image and MAE restorations to detec
&lt;/p&gt;</description></item></channel></rss>