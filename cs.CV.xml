<rss version="2.0"><channel><title>Chat Arxiv cs.CV</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CV</description><item><title>&#23454;&#29616;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#31995;&#32479;&#65292;&#20351;&#21830;&#21697;&#31227;&#21160;&#25805;&#20316;&#22120;&#25104;&#21151;&#22312;&#20197;&#21069;&#26410;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#25171;&#24320;&#27249;&#26588;&#21644;&#25277;&#23625;&#65292;&#24863;&#30693;&#35823;&#24046;&#26159;&#20027;&#35201;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.17767</link><description>&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#20351;&#29992;&#21830;&#21697;&#31227;&#21160;&#25805;&#20316;&#22120;&#25171;&#24320;&#27249;&#26588;&#21644;&#25277;&#23625;
&lt;/p&gt;
&lt;p&gt;
Opening Cabinets and Drawers in the Real World using a Commodity Mobile Manipulator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17767
&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#31995;&#32479;&#65292;&#20351;&#21830;&#21697;&#31227;&#21160;&#25805;&#20316;&#22120;&#25104;&#21151;&#22312;&#20197;&#21069;&#26410;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#25171;&#24320;&#27249;&#26588;&#21644;&#25277;&#23625;&#65292;&#24863;&#30693;&#35823;&#24046;&#26159;&#20027;&#35201;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#31995;&#32479;&#65292;&#20351;&#21830;&#21697;&#31227;&#21160;&#25805;&#20316;&#22120;&#65288;Stretch RE2&#65289;&#33021;&#22815;&#22312;&#22810;&#26679;&#30340;&#20197;&#21069;&#26410;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#25289;&#24320;&#27249;&#26588;&#21644;&#25277;&#23625;&#12290;&#25105;&#20204;&#22312;31&#20010;&#19981;&#21516;&#30340;&#29289;&#20307;&#21644;13&#20010;&#19981;&#21516;&#30495;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#36827;&#34892;&#20102;4&#22825;&#30340;&#23454;&#38469;&#27979;&#35797;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;&#38646;&#20987;&#25171;&#19979;&#65292;&#23545;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#26032;&#39062;&#30340;&#27249;&#26588;&#21644;&#25277;&#23625;&#30340;&#25171;&#24320;&#29575;&#36798;&#21040;61%&#12290;&#23545;&#22833;&#36133;&#27169;&#24335;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24863;&#30693;&#35823;&#24046;&#26159;&#25105;&#20204;&#31995;&#32479;&#38754;&#20020;&#30340;&#26368;&#37325;&#35201;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17767v1 Announce Type: cross  Abstract: Pulling open cabinets and drawers presents many difficult technical challenges in perception (inferring articulation parameters for objects from onboard sensors), planning (producing motion plans that conform to tight task constraints), and control (making and maintaining contact while applying forces on the environment). In this work, we build an end-to-end system that enables a commodity mobile manipulator (Stretch RE2) to pull open cabinets and drawers in diverse previously unseen real world environments. We conduct 4 days of real world testing of this system spanning 31 different objects from across 13 different real world environments. Our system achieves a success rate of 61% on opening novel cabinets and drawers in unseen environments zero-shot. An analysis of the failure modes suggests that errors in perception are the most significant challenge for our system. We will open source code and models for others to replicate and bui
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#22312;&#24314;&#27169;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#27169;&#24335;&#30340;CAVs&#26469;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#27010;&#24565;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2202.03482</link><description>&lt;p&gt;
&#39046;&#33322;&#31070;&#32463;&#31354;&#38388;&#65306;&#37325;&#26032;&#23457;&#35270;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#20197;&#20811;&#26381;&#26041;&#21521;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Navigating Neural Space: Revisiting Concept Activation Vectors to Overcome Directional Divergence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.03482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#22312;&#24314;&#27169;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#27169;&#24335;&#30340;CAVs&#26469;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#27010;&#24565;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#20110;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#31574;&#30053;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#38271;&#65292;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#24050;&#25104;&#20026;&#19968;&#31181;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#24314;&#27169;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#12290;&#36890;&#24120;&#65292;CAVs&#26159;&#36890;&#36807;&#21033;&#29992;&#32447;&#24615;&#20998;&#31867;&#22120;&#26469;&#35745;&#31639;&#30340;&#65292;&#35813;&#20998;&#31867;&#22120;&#20248;&#21270;&#20855;&#26377;&#32473;&#23450;&#27010;&#24565;&#21644;&#26080;&#32473;&#23450;&#27010;&#24565;&#30340;&#26679;&#26412;&#30340;&#28508;&#22312;&#34920;&#31034;&#30340;&#21487;&#20998;&#31163;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#20197;&#21487;&#20998;&#31163;&#24615;&#20026;&#23548;&#21521;&#30340;&#35745;&#31639;&#26041;&#27861;&#20250;&#23548;&#33268;&#19982;&#31934;&#30830;&#24314;&#27169;&#27010;&#24565;&#26041;&#21521;&#30340;&#23454;&#38469;&#30446;&#26631;&#21457;&#25955;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#31181;&#24046;&#24322;&#21487;&#20197;&#24402;&#22240;&#20110;&#20998;&#25955;&#26041;&#21521;&#30340;&#26174;&#33879;&#24433;&#21709;&#65292;&#21363;&#19982;&#27010;&#24565;&#26080;&#20851;&#30340;&#20449;&#21495;&#65292;&#36825;&#20123;&#20449;&#21495;&#34987;&#32447;&#24615;&#27169;&#22411;&#30340;&#28388;&#27874;&#22120;&#65288;&#21363;&#26435;&#37325;&#65289;&#25429;&#33719;&#20197;&#20248;&#21270;&#31867;&#21035;&#21487;&#20998;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#22522;&#20110;&#27169;&#24335;&#30340;CAVs&#65292;&#20165;&#20851;&#27880;&#27010;&#24565;&#20449;&#21495;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#27010;&#24565;&#26041;&#21521;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21508;&#31181;CAV&#26041;&#27861;&#19982;&#30495;&#23454;&#27010;&#24565;&#26041;&#21521;&#30340;&#23545;&#40784;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
With a growing interest in understanding neural network prediction strategies, Concept Activation Vectors (CAVs) have emerged as a popular tool for modeling human-understandable concepts in the latent space. Commonly, CAVs are computed by leveraging linear classifiers optimizing the separability of latent representations of samples with and without a given concept. However, in this paper we show that such a separability-oriented computation leads to solutions, which may diverge from the actual goal of precisely modeling the concept direction. This discrepancy can be attributed to the significant influence of distractor directions, i.e., signals unrelated to the concept, which are picked up by filters (i.e., weights) of linear models to optimize class-separability. To address this, we introduce pattern-based CAVs, solely focussing on concept signals, thereby providing more accurate concept directions. We evaluate various CAV methods in terms of their alignment with the true concept dire
&lt;/p&gt;</description></item></channel></rss>