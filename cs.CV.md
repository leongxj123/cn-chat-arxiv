# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Semi-Supervised Learning for Deep Causal Generative Models](https://arxiv.org/abs/2403.18717) | 首次开发了一种利用变量之间因果关系的半监督深度因果生成模型，以最大限度地利用所有可用数据。 |
| [^2] | [NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion, Reconstruction, and Generation](https://arxiv.org/abs/2403.18241) | 提出一种新颖的空间感知3D形状生成框架，利用2D平面表示增强建模，并结合混合形状表示技术直接学习连续有向距离场表示，从而确保空间一致性和降低内存使用。 |
| [^3] | [OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2403.14183) | 通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。 |
| [^4] | [BaCon: Boosting Imbalanced Semi-supervised Learning via Balanced Feature-Level Contrastive Learning](https://arxiv.org/abs/2403.12986) | BaCon通过平衡特征级对比学习方法直接规范了实例表示的分布，在解决不平衡的半监督学习中具有重要意义。 |
| [^5] | [StainFuser: Controlling Diffusion for Faster Neural Style Transfer in Multi-Gigapixel Histology Images](https://arxiv.org/abs/2403.09302) | StainFuser提出了一种新颖的条件潜在扩散架构，将染色标准化问题视为风格迁移任务，无需手工制作颜色组分，在2百万多个组织学图像上训练的结果优于当前最先进的方法。 |
| [^6] | [Leveraging Computer Vision in the Intensive Care Unit (ICU) for Examining Visitation and Mobility](https://arxiv.org/abs/2403.06322) | 在重症监护病房中利用计算机视觉系统，可以实现不存在的评估和增强现有评估的频率和准确性，同时减少工作人员工作量。 |
| [^7] | [Latent Dataset Distillation with Diffusion Models](https://arxiv.org/abs/2403.03881) | 这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。 |
| [^8] | [Updating the Minimum Information about CLinical Artificial Intelligence (MI-CLAIM) checklist for generative modeling research](https://arxiv.org/abs/2403.02558) | 生成模型的最新进展加速了医学中自然语言和图像处理领域的发展，并标志着生物医学模型开发和部署方式的重大范式转变。 |
| [^9] | [Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?](https://arxiv.org/abs/2402.09303) | 研究对比了人类和深度神经网络在图像分类中的行为差异，发现人类具有即时概括能力，而DNNs存在滞后概括现象，这表明了表示分歧的存在。 |
| [^10] | [Learning Contrastive Feature Representations for Facial Action Unit Detection](https://arxiv.org/abs/2402.06165) | 这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。 |
| [^11] | [Machine learning-based analysis of glioma tissue sections: a review.](http://arxiv.org/abs/2401.15022) | 机器学习技术在胶质瘤组织切片分析中具有诊断和预测的潜力，当前研究聚焦于成人型弥漫性胶质瘤的苏木精和伊红染色组织切片，以及对该疾病的分类、分级、分子标记预测和生存预测等临床任务。 |
| [^12] | [Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status.](http://arxiv.org/abs/2311.00565) | 在重症监护室中开发能够检测视觉线索并与患者临床状态关联的人工智能工具，可以提供更客观和详细的监测能力。 |
| [^13] | [On the Foundations of Shortcut Learning.](http://arxiv.org/abs/2310.16228) | 该论文研究了快速学习的基础，揭示了模型对哪些特征更偏好，即可预测性和可用性如何相互影响模型的特征使用。 |
| [^14] | [Mitigating Group Bias in Federated Learning for Heterogeneous Devices.](http://arxiv.org/abs/2309.07085) | 本文提出了一种在分布式边缘应用中减轻联邦学习中群体偏见的方法，该方法可以通过计算跨域群体重要性来减轻全局模型的偏见，并保持隐私和资源利用效率。 |
| [^15] | [ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting.](http://arxiv.org/abs/2309.04820) | ABC123是一种无需使用示例进行训练或推断的多类别类别无关计数方法，通过引入一个新的范式，它在多种对象同时存在的情况下优于现有方法。 |
| [^16] | [Deep Learning Safety Concerns in Automated Driving Perception.](http://arxiv.org/abs/2309.03774) | 本研究旨在通过引入安全考虑作为结构元素，以系统综合的方式确保基于深度神经网络的自动驾驶系统的安全性。这一概念不仅与现有的安全标准相契合，还为AI安全相关的学术出版物和标准提供了新的启示。 |
| [^17] | [Kinematic Data-Based Action Segmentation for Surgical Applications.](http://arxiv.org/abs/2303.07814) | 本文提出了两种多阶段体系结构和两种数据增强技术，专门用于基于运动学数据的行动分割。同时，作者在三个手术缝合任务数据集上对模型进行了评估。 |
| [^18] | [Anatomy-aware and acquisition-agnostic joint registration with SynthMorph.](http://arxiv.org/abs/2301.11329) | SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。 |
| [^19] | [CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Face Manipulation.](http://arxiv.org/abs/2210.03919) | 提出了一种为了解决文本引导图像操纵中的可分离性、可解释性和可控性问题，通过定义基于相关提示的语料库子空间来获取特定图像特征并引入CLIP投影增强嵌入（PAE）作为优化目标处理的新方法。 |

# 详细

[^1]: 深度因果生成模型的半监督学习

    Semi-Supervised Learning for Deep Causal Generative Models

    [https://arxiv.org/abs/2403.18717](https://arxiv.org/abs/2403.18717)

    首次开发了一种利用变量之间因果关系的半监督深度因果生成模型，以最大限度地利用所有可用数据。

    

    开发能够回答“如果$y$变为$z$，$x$会如何变化？”这类问题的模型对于推动医学图像分析至关重要。然而，训练能够解决这类反事实问题的因果生成模型目前要求所有相关变量均已被观察到，并且相应的标签在训练数据中可用。我们首次开发了一种利用变量之间因果关系的半监督深度因果生成模型，以最大限度地利用所有可用数据。

    arXiv:2403.18717v1 Announce Type: cross  Abstract: Developing models that can answer questions of the form "How would $x$ change if $y$ had been $z$?" is fundamental for advancing medical image analysis. Training causal generative models that address such counterfactual questions, though, currently requires that all relevant variables have been observed and that corresponding labels are available in training data. However, clinical data may not have complete records for all patients and state of the art causal generative models are unable to take full advantage of this. We thus develop, for the first time, a semi-supervised deep causal generative model that exploits the causal relationships between variables to maximise the use of all available data. We explore this in the setting where each sample is either fully labelled or fully unlabelled, as well as the more clinically realistic case of having different labels missing for each sample. We leverage techniques from causal inference t
    
[^2]: NeuSDFusion: 一种空间感知的生成模型，用于3D形状的完成、重建和生成

    NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion, Reconstruction, and Generation

    [https://arxiv.org/abs/2403.18241](https://arxiv.org/abs/2403.18241)

    提出一种新颖的空间感知3D形状生成框架，利用2D平面表示增强建模，并结合混合形状表示技术直接学习连续有向距离场表示，从而确保空间一致性和降低内存使用。

    

    3D形状生成旨在生成符合特定条件和约束的创新性3D内容。现有方法通常将3D形状分解为一系列局部组件，将每个元素孤立处理而不考虑空间一致性。因此，这些方法在3D数据表示和形状生成方面表现出有限的多样性，阻碍了它们生成高度多样化且符合指定约束的3D形状的能力。为此，我们引入了一种新颖的空间感知3D形状生成框架，利用2D平面表示来增强3D形状建模。为确保空间一致性并减少内存使用，我们结合了一种混合形状表示技术，直接使用正交的2D平面学习3D形状的连续有向距离场表示。此外，我们通过传

    arXiv:2403.18241v1 Announce Type: cross  Abstract: 3D shape generation aims to produce innovative 3D content adhering to specific conditions and constraints. Existing methods often decompose 3D shapes into a sequence of localized components, treating each element in isolation without considering spatial consistency. As a result, these approaches exhibit limited versatility in 3D data representation and shape generation, hindering their ability to generate highly diverse 3D shapes that comply with the specified constraints. In this paper, we introduce a novel spatial-aware 3D shape generation framework that leverages 2D plane representations for enhanced 3D shape modeling. To ensure spatial coherence and reduce memory usage, we incorporate a hybrid shape representation technique that directly learns a continuous signed distance field representation of the 3D shape using orthogonal 2D planes. Additionally, we meticulously enforce spatial correspondences across distinct planes using a tra
    
[^3]: OTSeg：多提示Sinkhorn注意力用于零样本语义分割

    OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation

    [https://arxiv.org/abs/2403.14183](https://arxiv.org/abs/2403.14183)

    通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。

    

    CLIP的最新成功证明了通过将多模态知识转移到像素级分类来进行零样本语义分割的有希望的结果。然而，在现有方法中，利用预先训练的CLIP知识来紧密对齐文本嵌入和像素嵌入仍然存在局限性。为了解决这个问题，我们提出了OTSeg，这是一种新颖的多模态注意力机制，旨在增强多个文本提示匹配相关像素嵌入的潜力。我们首先提出了基于最优输运（OT）算法的多提示Sinkhorn（MPS），这使得多个文本提示可以有选择地关注图像像素内的各种语义特征。此外，受到Sinkformers在单模态设置中的成功启发，我们引入了MPS的扩展，称为多提示Sinkhorn注意力（MPSA），它有效地取代了Transformer框架中多模态设置中的交叉注意力机制。

    arXiv:2403.14183v1 Announce Type: cross  Abstract: The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. To address this issue, we propose OTSeg, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. We first propose Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads multiple text prompts to selectively focus on various semantic features within image pixels. Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn Attention (MPSA), which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settin
    
[^4]: BaCon：通过平衡特征级对比学习增强不平衡半监督学习

    BaCon: Boosting Imbalanced Semi-supervised Learning via Balanced Feature-Level Contrastive Learning

    [https://arxiv.org/abs/2403.12986](https://arxiv.org/abs/2403.12986)

    BaCon通过平衡特征级对比学习方法直接规范了实例表示的分布，在解决不平衡的半监督学习中具有重要意义。

    

    半监督学习减少了深度学习中对大量标注的需求，但是半监督学习中更现实的挑战——数据分布不平衡的问题仍然较少被探讨。在类别不平衡的半监督学习(CISSL)中，不平衡数据分布可能会加剧由不可靠伪标签引入的偏见。大多数现有方法通过重新加权或重采样来解决这一问题，但由于它们依赖于有偏的骨干表示，其性能受到严重限制。一些其他方法确实进行了特征级调整，比如特征融合，但可能引入不利的噪声。本文讨论了更平衡的特征分布对CISSL问题的好处，并进一步提出了一种平衡特征级对比学习方法(BaCon)。我们的方法通过一种精心设计的对比方式直接规范了实例表示的分布。

    arXiv:2403.12986v1 Announce Type: cross  Abstract: Semi-supervised Learning (SSL) reduces the need for extensive annotations in deep learning, but the more realistic challenge of imbalanced data distribution in SSL remains largely unexplored. In Class Imbalanced Semi-supervised Learning (CISSL), the bias introduced by unreliable pseudo-labels can be exacerbated by imbalanced data distributions. Most existing methods address this issue at instance-level through reweighting or resampling, but the performance is heavily limited by their reliance on biased backbone representation. Some other methods do perform feature-level adjustments like feature blending but might introduce unfavorable noise. In this paper, we discuss the bonus of a more balanced feature distribution for the CISSL problem, and further propose a Balanced Feature-Level Contrastive Learning method (BaCon). Our method directly regularizes the distribution of instances' representations in a well-designed contrastive manner. 
    
[^5]: StainFuser：在多吉加像素组织学图像中控制扩散以加快神经风格迁移

    StainFuser: Controlling Diffusion for Faster Neural Style Transfer in Multi-Gigapixel Histology Images

    [https://arxiv.org/abs/2403.09302](https://arxiv.org/abs/2403.09302)

    StainFuser提出了一种新颖的条件潜在扩散架构，将染色标准化问题视为风格迁移任务，无需手工制作颜色组分，在2百万多个组织学图像上训练的结果优于当前最先进的方法。

    

    染色标准化算法旨在将源多吉加像素组织学图像的颜色和强度特征转换为与目标图像相匹配，从而减轻图像中用于突出显示细胞组分的染色剂外观的不一致性。我们提出了一种新方法，StainFuser，将这个问题视为一个风格迁移任务，使用一种新颖的条件潜在扩散架构，消除了手工制作颜色组分的需要。通过这种方法，我们为高质量转换筛选了迄今为止包含超过200万个组织学图像的最大染色标准化数据集SPI-2M，并进行了神经风格迁移训练。在这些数据上训练后，StainFuser在质量上优于当前最先进的GAN和手工制作方法的标准化图像。此外，与现有方法相比，在用作te时，它改善了细胞核实例分割和分类模型的性能

    arXiv:2403.09302v1 Announce Type: cross  Abstract: Stain normalization algorithms aim to transform the color and intensity characteristics of a source multi-gigapixel histology image to match those of a target image, mitigating inconsistencies in the appearance of stains used to highlight cellular components in the images. We propose a new approach, StainFuser, which treats this problem as a style transfer task using a novel Conditional Latent Diffusion architecture, eliminating the need for handcrafted color components. With this method, we curate SPI-2M the largest stain normalization dataset to date of over 2 million histology images with neural style transfer for high-quality transformations. Trained on this data, StainFuser outperforms current state-of-the-art GAN and handcrafted methods in terms of the quality of normalized images. Additionally, compared to existing approaches, it improves the performance of nuclei instance segmentation and classification models when used as a te
    
[^6]: 在重症监护病房（ICU）中利用计算机视觉检查探视和活动能力

    Leveraging Computer Vision in the Intensive Care Unit (ICU) for Examining Visitation and Mobility

    [https://arxiv.org/abs/2403.06322](https://arxiv.org/abs/2403.06322)

    在重症监护病房中利用计算机视觉系统，可以实现不存在的评估和增强现有评估的频率和准确性，同时减少工作人员工作量。

    

    尽管密切监测重症监护病房（ICU）患者的重要性，由于医护人员面临的时间限制，许多方面仍然受到限制评估。过度的探视可能在休息时间加剧循环节律紊乱和谵妄的风险，但在ICU中并未被捕捉。同样，活动能力可以是ICU患者康复或恶化的重要指标，但只被零星地捕捉或根本不被捕捉。在过去几年中，计算机视觉领域在许多领域中找到了应用，减轻了人力负担。在ICU中使用计算机视觉系统也有可能实现不存在的评估或增强现有评估的频率和准确性，同时减少工作人员的工作量。本研究利用基于深度成像的最新非侵入式计算机视觉系统，

    arXiv:2403.06322v1 Announce Type: cross  Abstract: Despite the importance of closely monitoring patients in the Intensive Care Unit (ICU), many aspects are still assessed in a limited manner due to the time constraints imposed on healthcare providers. For example, although excessive visitations during rest hours can potentially exacerbate the risk of circadian rhythm disruption and delirium, it is not captured in the ICU. Likewise, while mobility can be an important indicator of recovery or deterioration in ICU patients, it is only captured sporadically or not captured at all. In the past few years, the computer vision field has found application in many domains by reducing the human burden. Using computer vision systems in the ICU can also potentially enable non-existing assessments or enhance the frequency and accuracy of existing assessments while reducing the staff workload. In this study, we leverage a state-of-the-art noninvasive computer vision system based on depth imaging to c
    
[^7]: 使用扩散模型进行潜在数据集蒸馏

    Latent Dataset Distillation with Diffusion Models

    [https://arxiv.org/abs/2403.03881](https://arxiv.org/abs/2403.03881)

    这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。

    

    机器学习的有效性传统上依赖于越来越大的数据集的可用性。然而，大型数据集带来存储挑战，并且包含一些非影响力样本，在训练过程中可以被忽略而不影响模型最终的准确性。为了应对这些限制，出现了将数据集信息蒸馏成一组压缩样本（合成样本），即蒸馏数据集的概念。其中一个关键方面是选择用于连接原始和合成数据集的架构（通常是ConvNet）。然而，如果所使用的模型架构与蒸馏过程中使用的模型不同，则最终准确性会降低。另一个挑战是生成高分辨率图像，例如128x128及更高。

    arXiv:2403.03881v1 Announce Type: cross  Abstract: The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both chal
    
[^8]: 为生成建模研究更新有关临床人工智能（MI-CLAIM）检查表

    Updating the Minimum Information about CLinical Artificial Intelligence (MI-CLAIM) checklist for generative modeling research

    [https://arxiv.org/abs/2403.02558](https://arxiv.org/abs/2403.02558)

    生成模型的最新进展加速了医学中自然语言和图像处理领域的发展，并标志着生物医学模型开发和部署方式的重大范式转变。

    

    生成模型的最新进展，包括大型语言模型（LLMs）、视觉语言模型（VLMs）和扩散模型，加速了医学中自然语言和图像处理领域的发展，并标志着生物医学模型开发和部署方式的重大范式转变。尽管这些模型非常适应新任务，但在扩展和评估它们的使用过程中出现了前人框架未解决的新挑战。特别是，这些模型以少量或无需专门训练数据即可产生有用输出的能力（“零样本”或“少样本”方法），以及它们输出的开放性质，需要制定更新的使用和评估这些模型的指南。美国行政命令141103确定了有关临床人工智能工具开发的标准和最佳实践存在的差距，以及几个新兴国家临床人工智能评估网络。

    arXiv:2403.02558v1 Announce Type: new  Abstract: Recent advances in generative models, including large language models (LLMs), vision language models (VLMs), and diffusion models, have accelerated the field of natural language and image processing in medicine and marked a significant paradigm shift in how biomedical models can be developed and deployed. While these models are highly adaptable to new tasks, scaling and evaluating their usage presents new challenges not addressed in previous frameworks. In particular, the ability of these models to produce useful outputs with little to no specialized training data ("zero-" or "few-shot" approaches), as well as the open-ended nature of their outputs, necessitate the development of updated guidelines in using and evaluating these models. In response to gaps in standards and best practices for the development of clinical AI tools identified by US Executive Order 141103 and several emerging national networks for clinical AI evaluation, we be
    
[^9]: 人类中的即时概括与深度神经网络中的滞后概括——表示分歧的证据？

    Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?

    [https://arxiv.org/abs/2402.09303](https://arxiv.org/abs/2402.09303)

    研究对比了人类和深度神经网络在图像分类中的行为差异，发现人类具有即时概括能力，而DNNs存在滞后概括现象，这表明了表示分歧的存在。

    

    近期的研究在图像分类领域中对比了人类与深度神经网络（DNNs）的许多行为比较。通常，比较研究关注的是学习过程的最终结果，通过测量和比较目标类别表示的相似性。然而，这些表示如何形成即其过程——即在获取过程中观察到的行为变化和中间阶段——往往少有直接和实证的比较。在这里，我们报告了对人类观察者和不同经典与最新技术的DNNs中可转移表示是如何被获取的的详细调查。我们开发了一个受限的监督学习环境，该环境中我们对齐了学习相关的参数，如起始点、输入模式、可用输入数据以及提供的反馈。在整个学习过程中我们评估...

    arXiv:2402.09303v1 Announce Type: cross Abstract: Recent research has seen many behavioral comparisons between humans and deep neural networks (DNNs) in the domain of image classification. Often, comparison studies focus on the end-result of the learning process by measuring and comparing the similarities in the representations of object categories once they have been formed. However, the process of how these representations emerge$\unicode{x2014}$that is, the behavioral changes and intermediate stages observed during the acquisition$\unicode{x2014}$is less often directly and empirically compared.   Here we report a detailed investigation of how transferable representations are acquired in human observers and various classic and state-of-the-art DNNs. We develop a constrained supervised learning environment in which we align learning-relevant parameters such as starting point, input modality, available input data and the feedback provided. Across the whole learning process we evaluate 
    
[^10]: 学习对比特征表示来进行面部动作单元检测

    Learning Contrastive Feature Representations for Facial Action Unit Detection

    [https://arxiv.org/abs/2402.06165](https://arxiv.org/abs/2402.06165)

    这项研究提出了一种对比学习框架，通过监督和自监督信号来增强面部动作单元检测模型的性能。采用正样本抽样和权衡重要性的损失函数来应对噪声AU标签和AU类型分布不平衡的挑战。

    

    面部动作单元（AU）检测的主要方法涉及监督的多标签二进制分类问题。现有的方法常常对AU的像素级信息进行编码，从而对模型的复杂性和表达能力提出了很大的要求。此外，由于存在噪声AU标签，这种做法增加了过拟合的风险。在本研究中，我们引入了一个对比学习框架，通过监督和自监督信号增强。目标是在AU检测领域中摆脱传统的像素级学习范式，获得判别特征。为了应对噪声AU标签带来的挑战，我们通过引入自监督信号来增强监督信号。这种增强是通过正样本抽样实现的，包括三种不同类型的正样本对。另外，为了减轻每个AU类型的分布不平衡问题，我们采用了一种权衡重要性的损失函数。

    The predominant approach to facial action unit (AU) detection revolves around a supervised multi-label binary classification problem. Existing methodologies often encode pixel-level information of AUs, thereby imposing substantial demands on model complexity and expressiveness. Moreover, this practice elevates the susceptibility to overfitting due to the presence of noisy AU labels. In the present study, we introduce a contrastive learning framework enhanced by both supervised and self-supervised signals. The objective is to acquire discriminative features, deviating from the conventional pixel-level learning paradigm within the domain of AU detection. To address the challenge posed by noisy AU labels, we augment the supervised signal through the introduction of a self-supervised signal. This augmentation is achieved through positive sample sampling, encompassing three distinct types of positive sample pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we empl
    
[^11]: 基于机器学习的胶质瘤组织切片分析：一项综述

    Machine learning-based analysis of glioma tissue sections: a review. (arXiv:2401.15022v1 [eess.IV])

    [http://arxiv.org/abs/2401.15022](http://arxiv.org/abs/2401.15022)

    机器学习技术在胶质瘤组织切片分析中具有诊断和预测的潜力，当前研究聚焦于成人型弥漫性胶质瘤的苏木精和伊红染色组织切片，以及对该疾病的分类、分级、分子标记预测和生存预测等临床任务。

    

    近年来，胶质瘤的诊断变得越来越复杂。使用现代机器学习技术对胶质瘤组织进行组织学评估，为诊断和预测结果提供了新的机会。为了对当前研究的现状进行概述，本综述对70个公开可得的研究论文进行了研究，这些论文关于使用机器学习分析染色的胶质瘤组织切片，涵盖了分类（16/70），分级（23/70），分子标记预测（13/70）和生存预测（27/70）等诊断任务。所有的研究都在方法学方面及其临床适用性方面进行了评估。发现当前研究的重点是对成人型弥漫性胶质瘤的苏木精和伊红染色组织切片进行评估。多数研究（49/70）基于公开的胶质母细胞瘤和低级别胶质瘤数据集，仅有少数研究使用其他数据集。

    In recent years, the diagnosis of gliomas has become increasingly complex. Histological assessment of glioma tissue using modern machine learning techniques offers new opportunities to support diagnosis and outcome prediction. To give an overview of the current state of research, this review examines 70 publicly available research studies on machine learning-based analysis of stained human glioma tissue sections, covering the diagnostic tasks of subtyping (16/70), grading (23/70), molecular marker prediction (13/70), and survival prediction (27/70). All studies were reviewed with regard to methodological aspects as well as clinical applicability. It was found that the focus of current research is the assessment of hematoxylin and eosin-stained tissue sections of adult-type diffuse gliomas. The majority of studies (49/70) are based on the publicly available glioblastoma and low-grade glioma datasets from The Cancer Genome Atlas (TCGA) and only a few studies employed other datasets in is
    
[^12]: 在重症监护室中检测视觉线索与患者临床状态的关联

    Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status. (arXiv:2311.00565v1 [cs.CV])

    [http://arxiv.org/abs/2311.00565](http://arxiv.org/abs/2311.00565)

    在重症监护室中开发能够检测视觉线索并与患者临床状态关联的人工智能工具，可以提供更客观和详细的监测能力。

    

    重症监护室（ICU）为患有生命威胁的患者提供密切监护和连续护理。然而，由于时间限制和医疗保健工作者的工作负荷，ICU中的连续患者评估仍然有限。现有的ICU患者评估，如疼痛或活动能力评估，大多是零散和手动实施的，从而引入了人为错误的潜在可能性。开发能够增强ICU中人类评估的人工智能（AI）工具可以有利于提供更客观和详细的监测能力。例如，捕捉与疼痛或不安相关的患者面部线索的变化可以帮助调整与疼痛相关的药物或检测可能引起不安的情况，如谵妄。此外，在不良临床事件发生期间或之前，视觉线索的微妙变化与高分辨率生理信号相结合可能有助于连续患者监测。

    Intensive Care Units (ICU) provide close supervision and continuous care to patients with life-threatening conditions. However, continuous patient assessment in the ICU is still limited due to time constraints and the workload on healthcare providers. Existing patient assessments in the ICU such as pain or mobility assessment are mostly sporadic and administered manually, thus introducing the potential for human errors. Developing Artificial intelligence (AI) tools that can augment human assessments in the ICU can be beneficial for providing more objective and granular monitoring capabilities. For example, capturing the variations in a patient's facial cues related to pain or agitation can help in adjusting pain-related medications or detecting agitation-inducing conditions such as delirium. Additionally, subtle changes in visual cues during or prior to adverse clinical events could potentially aid in continuous patient monitoring when combined with high-resolution physiological signal
    
[^13]: 关于快速学习的基础研究

    On the Foundations of Shortcut Learning. (arXiv:2310.16228v1 [cs.LG])

    [http://arxiv.org/abs/2310.16228](http://arxiv.org/abs/2310.16228)

    该论文研究了快速学习的基础，揭示了模型对哪些特征更偏好，即可预测性和可用性如何相互影响模型的特征使用。

    

    深度学习模型可以从数据中提取丰富的特征。模型使用哪些特征不仅取决于预测能力 - 一个特征可靠地指示训练集标签的程度，还取决于可用性 - 一个特征可以从输入中被轻松提取或利用的程度。有关快速学习的文献已经指出了模型偏好一个特征而不是另一个特征的例子，例如在纹理和形状之间以及在图像背景和前景对象之间。在这里，我们测试关于哪些输入属性对于模型更容易获取的假设，并系统地研究预测能力和可用性如何相互作用来塑造模型的特征使用。我们构建了一个最小的、明确的生成框架来合成具有两个潜在特征的分类数据集，这两个特征在预测能力和我们假设与可用性有关的因素上有所不同，并量化了模型的快捷偏差 - 它过度依赖快捷（更可用、不太预测）特征而忽视了核心（不太可用)特征。

    Deep-learning models can extract a rich assortment of features from data. Which features a model uses depends not only on predictivity-how reliably a feature indicates train-set labels-but also on availability-how easily the feature can be extracted, or leveraged, from inputs. The literature on shortcut learning has noted examples in which models privilege one feature over another, for example texture over shape and image backgrounds over foreground objects. Here, we test hypotheses about which input properties are more available to a model, and systematically study how predictivity and availability interact to shape models' feature use. We construct a minimal, explicit generative framework for synthesizing classification datasets with two latent features that vary in predictivity and in factors we hypothesize to relate to availability, and quantify a model's shortcut bias-its over-reliance on the shortcut (more available, less predictive) feature at the expense of the core (less avail
    
[^14]: 在异构设备上减轻联邦学习中的群体偏见

    Mitigating Group Bias in Federated Learning for Heterogeneous Devices. (arXiv:2309.07085v1 [cs.LG])

    [http://arxiv.org/abs/2309.07085](http://arxiv.org/abs/2309.07085)

    本文提出了一种在分布式边缘应用中减轻联邦学习中群体偏见的方法，该方法可以通过计算跨域群体重要性来减轻全局模型的偏见，并保持隐私和资源利用效率。

    

    联邦学习正在分布式边缘应用中崭露头角作为一种保护隐私的模型训练方法。然而，大多数边缘部署是异构的，即它们的感知能力和环境在部署中各不相同。这种边缘异构违反了本地数据在客户端之间独立且分布相同 (IID) 的特性，产生了有偏见的全局模型，即对特定社区或群体做出不公平的决策和歧视。现有的偏见缓解技术只关注非IID数据中由标签异构引起的偏见，并没有考虑由特征异构导致的领域变化，也没有解决全局群体公平的问题。我们的工作提出了一种在保护隐私和不增加资源利用开销的情况下，减少群体偏见的联邦学习框架。我们的主要思想是利用平均条件概率来计算跨域群体重要性。

    Federated Learning is emerging as a privacy-preserving model training approach in distributed edge applications. As such, most edge deployments are heterogeneous in nature i.e., their sensing capabilities and environments vary across deployments. This edge heterogeneity violates the independence and identical distribution (IID) property of local data across clients and produces biased global models i.e. models that contribute to unfair decision-making and discrimination against a particular community or a group. Existing bias mitigation techniques only focus on bias generated from label heterogeneity in non-IID data without accounting for domain variations due to feature heterogeneity and do not address global group-fairness property.  Our work proposes a group-fair FL framework that minimizes group-bias while preserving privacy and without resource utilization overhead. Our main idea is to leverage average conditional probabilities to compute a cross-domain group \textit{importance we
    
[^15]: ABC简单如123：一种用于无先例多类别类别无关计数的盲目计数方法

    ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting. (arXiv:2309.04820v1 [cs.CV])

    [http://arxiv.org/abs/2309.04820](http://arxiv.org/abs/2309.04820)

    ABC123是一种无需使用示例进行训练或推断的多类别类别无关计数方法，通过引入一个新的范式，它在多种对象同时存在的情况下优于现有方法。

    

    类别无关计数方法可以对任意类别的对象进行计数，在许多领域中提供了巨大的实用性。然而，现有的方法只能适用于需要一组特定类型的示例或图像中仅包含一种类型对象的情况。这些方法的局限之一是缺乏适用于多种对象同时存在的计数设置的数据集。为了解决这些问题，我们提出了第一个多类别、类别无关计数数据集（MCAC）以及一种名为ABC123的盲目计数方法，该方法可以在训练或推断过程中不使用特定类型示例来同时计数多种对象。ABC123引入了一种新的范式，在计数阶段后找到示例来帮助用户理解生成的输出，而不需要先导样本来引导计数。我们展示了ABC123在MCAC上优于现有方法，而无需人工干预进行标注。

    Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also 
    
[^16]: 自动驾驶感知中的深度学习安全考虑

    Deep Learning Safety Concerns in Automated Driving Perception. (arXiv:2309.03774v1 [cs.LG])

    [http://arxiv.org/abs/2309.03774](http://arxiv.org/abs/2309.03774)

    本研究旨在通过引入安全考虑作为结构元素，以系统综合的方式确保基于深度神经网络的自动驾驶系统的安全性。这一概念不仅与现有的安全标准相契合，还为AI安全相关的学术出版物和标准提供了新的启示。

    

    深度学习领域的最新进展以及深度神经网络（DNNs）在感知方面的出色性能导致了对其在自动驾驶系统中应用的增加需求。这类系统的安全性至关重要，因此需要考虑DNNs的独特属性。为了以系统综合的方式确保基于DNNs的自动驾驶系统的安全性，引入了所谓的安全考虑作为适当的结构元素。一方面，安全考虑的概念设计与现有的与自动驾驶系统安全相关的标准如ISO 21448（SOTIF）非常契合。另一方面，它已经激发了几篇学术出版物和即将出台的关于AI安全的标准，如ISO PAS 8800。虽然安全考虑的概念以前已经被介绍过，但本文对其进行了扩展和优化，借鉴了各个领域和安全专家的反馈意见。

    Recent advances in the field of deep learning and impressive performance of deep neural networks (DNNs) for perception have resulted in an increased demand for their use in automated driving (AD) systems. The safety of such systems is of utmost importance and thus requires to consider the unique properties of DNNs.  In order to achieve safety of AD systems with DNN-based perception components in a systematic and comprehensive approach, so-called safety concerns have been introduced as a suitable structuring element. On the one hand, the concept of safety concerns is -- by design -- well aligned to existing standards relevant for safety of AD systems such as ISO 21448 (SOTIF). On the other hand, it has already inspired several academic publications and upcoming standards on AI safety such as ISO PAS 8800.  While the concept of safety concerns has been previously introduced, this paper extends and refines it, leveraging feedback from various domain and safety experts in the field. In par
    
[^17]: 基于运动学数据的手术行为切分

    Kinematic Data-Based Action Segmentation for Surgical Applications. (arXiv:2303.07814v1 [cs.CV])

    [http://arxiv.org/abs/2303.07814](http://arxiv.org/abs/2303.07814)

    本文提出了两种多阶段体系结构和两种数据增强技术，专门用于基于运动学数据的行动分割。同时，作者在三个手术缝合任务数据集上对模型进行了评估。

    

    行动切分是高级流程分析中的一个挑战性任务，通常在视频或从各种传感器获取的运动学数据上执行。在手术过程中，行动切分对于工作流分析算法至关重要。本文提出了两个与运动学数据相关的行动分割方面的贡献。首先，我们介绍了两种多阶段体系结构，MS-TCN-BiLSTM和MS-TCN-BiGRU，专门设计用于运动学数据。 这些体系结构由具有阶内规则化和双向LSTM或GRU的细化阶段的预测生成器组成。其次，我们提出了两种新的数据增强技术，World Frame Rotation和Horizontal-Flip，利用运动学数据的强几何结构来提高算法性能和鲁棒性。我们在三个手术缝合任务数据集上评估了我们的模型：可变组织模拟（VTS）数据集和新推出的肠道修复模拟（BRS）数据集。

    Action segmentation is a challenging task in high-level process analysis, typically performed on video or kinematic data obtained from various sensors. In the context of surgical procedures, action segmentation is critical for workflow analysis algorithms. This work presents two contributions related to action segmentation on kinematic data. Firstly, we introduce two multi-stage architectures, MS-TCN-BiLSTM and MS-TCN-BiGRU, specifically designed for kinematic data. The architectures consist of a prediction generator with intra-stage regularization and Bidirectional LSTM or GRU-based refinement stages. Secondly, we propose two new data augmentation techniques, World Frame Rotation and Horizontal-Flip, which utilize the strong geometric structure of kinematic data to improve algorithm performance and robustness. We evaluate our models on three datasets of surgical suturing tasks: the Variable Tissue Simulation (VTS) Dataset and the newly introduced Bowel Repair Simulation (BRS) Dataset,
    
[^18]: SynthMorph实现的考虑解剖结构和无关采集方法的联合配准

    Anatomy-aware and acquisition-agnostic joint registration with SynthMorph. (arXiv:2301.11329v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.11329](http://arxiv.org/abs/2301.11329)

    SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。

    

    仿射图像配准是医学图像分析的基石。虽然传统算法可以实现优秀的准确性，但它们需要为每一对图像进行耗时的优化。深度学习方法通过学习一个将图像对映射到输出变换的函数来解决这个问题。评估这个函数是快速的，但捕捉大的变换可能是具有挑战性的，而且如果测试图像的特征从训练领域变化，如分辨率，网络往往会出现困难。大多数仿射方法是对解剖结构无知的，意味着如果算法考虑图像中的所有结构，配准会不准确。我们通过SynthMorph解决了这些缺点，它是一个易于使用的DL工具，用于对任何脑图像进行联合仿射-可变形配准，无需预处理即可直接从MRI扫描仪进行操作。首先，我们利用从标签图生成的具有极大差异的图像来训练网络的策略，从而实现对训练过程中未见的多样化采集规范的鲁棒性能。其次，我们优化网络的损失函数，使其能够考虑不同的解剖特征和学习抵制采集特定限制的变换。通过这些创新，我们实现了更准确和鲁棒的图像配准。

    Affine image registration is a cornerstone of medical-image analysis. While classical algorithms can achieve excellent accuracy, they solve a time-consuming optimization for every image pair. Deep-learning (DL) methods learn a function that maps an image pair to an output transform. Evaluating the function is fast, but capturing large transforms can be challenging, and networks tend to struggle if a test-image characteristic shifts from the training domain, such as resolution. Most affine methods are agnostic to anatomy, meaning the registration will be inaccurate if algorithms consider all structures in the image.  We address these shortcomings with SynthMorph, an easy-to-use DL tool for joint affine-deformable registration of any brain image without preprocessing, right off the MRI scanner. First, we leverage a strategy to train networks with wildly varying images synthesized from label maps, yielding robust performance across acquisition specifics unseen at training. Second, we opti
    
[^19]: CLIP-PAE：投影增强嵌入以提取相关特征用于可分离、可解释、可控的文本指导脸部操纵

    CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Face Manipulation. (arXiv:2210.03919v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.03919](http://arxiv.org/abs/2210.03919)

    提出了一种为了解决文本引导图像操纵中的可分离性、可解释性和可控性问题，通过定义基于相关提示的语料库子空间来获取特定图像特征并引入CLIP投影增强嵌入（PAE）作为优化目标处理的新方法。

    

    最近引入的对比语言-图像预训练（CLIP）将图像和文本嵌入到共同的潜在空间中。这打开了一个大门，即旨在通过提供文字说明来操作输入图像的丰富文学资料。然而，由于联合空间中图像和文本嵌入之间的差异，将文本嵌入作为优化目标通常会导致结果图像中出现意外的伪影。对于操纵来说，可分离性、可解释性和可控性也很难保证。为了缓解这些问题，我们提出定义由相关提示展开的语料库子空间来捕获特定的图像特征。我们引入了CLIP投影增强嵌入（PAE）作为优化目标，以提高文本引导图像操纵的性能。我们的方法是一种简单而通用的范例，可以轻松地计算和适应，并平稳地融入到任何基于CLIP的图像操作算法中。

    Recently introduced Contrastive Language-Image Pre-Training (CLIP) bridges images and text by embedding them into a joint latent space. This opens the door to ample literature that aims to manipulate an input image by providing a textual explanation. However, due to the discrepancy between image and text embeddings in the joint space, using text embeddings as the optimization target often introduces undesired artifacts in the resulting images. Disentanglement, interpretability, and controllability are also hard to guarantee for manipulation. To alleviate these problems, we propose to define corpus subspaces spanned by relevant prompts to capture specific image characteristics. We introduce CLIP Projection-Augmentation Embedding (PAE) as an optimization target to improve the performance of text-guided image manipulation. Our method is a simple and general paradigm that can be easily computed and adapted, and smoothly incorporated into any CLIP-based image manipulation algorithm. To demo
    

