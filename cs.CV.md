# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data](https://rss.arxiv.org/abs/2402.01393) | ALERT-Transformer是一种将异步感知与同步处理相结合的新颖桥接方式，通过ALERT模块、灵活的数据读取和基于块的稀疏性优化，实现了对实时事件驱动时空数据的经典处理，其性能超过竞争对手并具有较低的延迟。 |
| [^2] | [Can we Constrain Concept Bottleneck Models to Learn Semantically Meaningful Input Features?](https://rss.arxiv.org/abs/2402.00912) | 本文研究了概念瓶颈模型如何从具有细粒度概念注释的数据集中学习概念，以实现模型输出的内在可解释性。 |
| [^3] | [SceneX:Procedural Controllable Large-scale Scene Generation via Large-language Models](https://arxiv.org/abs/2403.15698) | 通过大型语言模型驱动程序化建模，提出了一个大规模场景生成框架SceneX，可以自动生成高质量的程序化模型 |
| [^4] | [Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction](https://arxiv.org/abs/2403.07263) | 通过两步形式预测方法，本文实现了自适应边界框不确定性的量化，保证了对象边界框不确定性区间的覆盖率，包括了错误分类的对象，同时确保边界框区间能够适应物体大小，实现更平衡的覆盖率。 |
| [^5] | [GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction](https://arxiv.org/abs/2402.16174) | GenNBV提出了一种端到端的通用的下一最佳视角策略，通过采用强化学习框架和扩展到5D自由空间的动作空间，实现了无人机从任意视角进行扫描，甚至与未知几何体进行交互的能力，同时提出了多源状态嵌入以增强跨数据集的泛化能力。 |
| [^6] | [SimPro: A Simple Probabilistic Framework Towards Realistic Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2402.13505) | SimPro提出了一种高度适应的框架，不依赖于任何关于未标记数据分布的预定义假设，通过创新地改进期望最大化（EM）算法，明确分离条件和边缘类别分布的建模。 |
| [^7] | [On the Exploitation of DCT-Traces in the Generative-AI Domain](https://arxiv.org/abs/2402.02209) | 本文分析了生成AI模型在生成深度伪造图像时在频域中的DCT系数的统计特征。通过研究发现了一种独特的“辨别指纹”，可以利用它来改善现有的深度伪造检测器。 |
| [^8] | [Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization](https://arxiv.org/abs/2312.16731) | 引入了Infinite dSprites工具，用于创建任意长度的连续分类和分解基准，可以全面控制生成因素，有望缩小机器学习系统与人类学习在动态开放环境中的差距 |
| [^9] | [ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots](https://arxiv.org/abs/2209.08199) | ScreenQA提出了一个新的任务和数据集，通过86K个问答对在RICO数据集上注释，旨在评估屏幕阅读理解能力。 |
| [^10] | [KI-PMF: Knowledge Integrated Plausible Motion Forecasting.](http://arxiv.org/abs/2310.12007) | 本研究提出了一种名为KI-PMF的方法，通过结合先验知识，对交通参与者的未来行动进行准确预测，遵循车辆的运动约束和行驶环境的几何形状。通过条件化网络以遵循物理定律，可以获得准确和安全的预测，对于在实际环境中维护自动驾驶汽车的安全和效率至关重要。 |
| [^11] | [Noise-Tolerant Unsupervised Adapter for Vision-Language Models.](http://arxiv.org/abs/2309.14928) | 这篇论文介绍了一种噪声容忍的无监督适配器(NtUA)，它可以使用少样本无标签目标样本来学习优秀的视觉语言模型。NtUA通过自适应缓存形成和伪标签修正来对抗伪标签噪声。 |
| [^12] | [Semantic Image Synthesis via Class-Adaptive Cross-Attention.](http://arxiv.org/abs/2308.16071) | 本文提出了一种基于类自适应交叉注意力的语义图像合成方法，通过使用交叉注意力层来调节图像生成，实现了优秀的视觉生成质量和编辑灵活性，并解决了全局样式不一致和局部样式编辑不真实的问题。 |

# 详细

[^1]: ALERT-Transformer: 将异步和同步机器学习桥接在实时事件驱动的时空数据上

    ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data

    [https://rss.arxiv.org/abs/2402.01393](https://rss.arxiv.org/abs/2402.01393)

    ALERT-Transformer是一种将异步感知与同步处理相结合的新颖桥接方式，通过ALERT模块、灵活的数据读取和基于块的稀疏性优化，实现了对实时事件驱动时空数据的经典处理，其性能超过竞争对手并具有较低的延迟。

    

    我们旨在通过稠密机器学习模型，实现对由事件感应器产生的连续超稀疏时空数据的经典处理。我们提出了一种新颖的混合管道，由异步感知和同步处理组成，结合了几个思路：（1）基于PointNet模型的嵌入——ALERT模块，可以通过泄漏机制不断整合新事件并消除旧事件，（2）嵌入数据的灵活读取，可以以任何采样率将始终最新的特征输入到下游模型中，（3）借鉴Vision Transformer的基于块的方法来利用输入的稀疏性以优化方法的效率。这些嵌入然后由一个经过对象和手势识别训练的Transformer模型进行处理。使用这种方法，我们实现了比竞争对手更低的延迟，达到了最新技术水平的性能。我们还证明了我们的异步模型可以以任何所需的采样率进行操作。

    We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling r
    
[^2]: 能够约束概念瓶颈模型学习语义上有意义的输入特征吗？

    Can we Constrain Concept Bottleneck Models to Learn Semantically Meaningful Input Features?

    [https://rss.arxiv.org/abs/2402.00912](https://rss.arxiv.org/abs/2402.00912)

    本文研究了概念瓶颈模型如何从具有细粒度概念注释的数据集中学习概念，以实现模型输出的内在可解释性。

    

    概念瓶颈模型（CBM）被认为具有内在的可解释性，因为它们首先预测一组人为定义的概念，然后利用这些概念来预测下游任务的输出。为了实现完全的内在可解释性，以及确保对模型输出的信任，我们需要保证概念的预测是基于语义映射的输入特征。例如，人们可能期望图像中表示骨折的像素被用于预测骨折。然而，当前的文献表明这并不是事实，因为概念预测通常与不相关的输入特征映射在一起。我们假设这是由于概念注释的不准确或者输入特征与概念之间的关系不清晰导致的。总的来说，数据集标注对CBMs中概念表示的影响仍然是一个研究较少的领域。因此，在本文中，我们研究了CBMs如何从具有细粒度概念注释的数据集中学习概念的问题。我们进行了实验演示。

    Concept Bottleneck Models (CBMs) are considered inherently interpretable because they first predict a set of human-defined concepts before using these concepts to predict the output of a downstream task. For inherent interpretability to be fully realised, and ensure trust in a model's output, we need to guarantee concepts are predicted based on semantically mapped input features. For example, one might expect the pixels representing a broken bone in an image to be used for the prediction of a fracture. However, current literature indicates this is not the case, as concept predictions are often mapped to irrelevant input features. We hypothesise that this occurs when concept annotations are inaccurate or how input features should relate to concepts is unclear. In general, the effect of dataset labelling on concept representations in CBMs remains an understudied area. Therefore, in this paper, we examine how CBMs learn concepts from datasets with fine-grained concept annotations. We demo
    
[^3]: SceneX：通过大型语言模型进行程序化可控大规模场景生成

    SceneX:Procedural Controllable Large-scale Scene Generation via Large-language Models

    [https://arxiv.org/abs/2403.15698](https://arxiv.org/abs/2403.15698)

    通过大型语言模型驱动程序化建模，提出了一个大规模场景生成框架SceneX，可以自动生成高质量的程序化模型

    

    由于其巨大的应用潜力，大规模场景生成在学术界和工业界引起了广泛关注。最近的研究采用强大的生成模型创建所需的场景，并取得了令人期待的结果。然而，大多数这些方法使用不兼容工业流程的3D基元（如点云或辐射场）来表示场景，这导致学术研究与工业部署之间存在重大差距。程序化可控生成（PCG）是一种高效的技术，可创建可扩展和高质量的资产，但对普通用户不友好，因为它需要深入的领域专业知识。为解决这些问题，我们采用大型语言模型（LLM）驱动程序化建模。在本文中，我们介绍了一个大规模场景生成框架SceneX，可以根据设计师的文本描述自动生成高质量的程序化模型。

    arXiv:2403.15698v1 Announce Type: cross  Abstract: Due to its great application potential, large-scale scene generation has drawn extensive attention in academia and industry. Recent research employs powerful generative models to create desired scenes and achieves promising results. However, most of these methods represent the scene using 3D primitives (e.g. point cloud or radiance field) incompatible with the industrial pipeline, which leads to a substantial gap between academic research and industrial deployment. Procedural Controllable Generation (PCG) is an efficient technique for creating scalable and high-quality assets, but it is unfriendly for ordinary users as it demands profound domain expertise. To address these issues, we resort to using the large language model (LLM) to drive the procedural modeling. In this paper, we introduce a large-scale scene generation framework, SceneX, which can automatically produce high-quality procedural models according to designers' textual de
    
[^4]: 通过两步形式预测实现自适应边界框不确定性

    Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction

    [https://arxiv.org/abs/2403.07263](https://arxiv.org/abs/2403.07263)

    通过两步形式预测方法，本文实现了自适应边界框不确定性的量化，保证了对象边界框不确定性区间的覆盖率，包括了错误分类的对象，同时确保边界框区间能够适应物体大小，实现更平衡的覆盖率。

    

    量化模型的预测不确定性对于像自动驾驶这样的安全关键应用至关重要。我们考虑为多物体检测量化这种不确定性。具体来说，我们利用形式预测来获得具有保证覆盖率的物体边界框不确定性区间。这样做的一个挑战是边界框的预测取决于物体的类别标签。因此，我们开发了一种新颖的两步形式方法，将对预测类别标签的不确定性传播到边界框的不确定性区间中。这样，我们的形式覆盖保证的有效性更广泛，包括了被错误分类的物体，确保它们在需要最大安全保证时的实用性。此外，我们研究了新颖的集成和分位数回归形式，以确保边界框区间能够适应物体大小，从而实现更平衡的覆盖率。

    arXiv:2403.07263v1 Announce Type: cross  Abstract: Quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. We consider quantifying such uncertainty for multi-object detection. In particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. One challenge in doing so is that bounding box predictions are conditioned on the object's class label. Thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals for the bounding boxes. This broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, ensuring their usefulness when maximal safety assurances are required. Moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage across
    
[^5]: GenNBV: 通用的主动式三维重建下一最佳视角策略

    GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction

    [https://arxiv.org/abs/2402.16174](https://arxiv.org/abs/2402.16174)

    GenNBV提出了一种端到端的通用的下一最佳视角策略，通过采用强化学习框架和扩展到5D自由空间的动作空间，实现了无人机从任意视角进行扫描，甚至与未知几何体进行交互的能力，同时提出了多源状态嵌入以增强跨数据集的泛化能力。

    

    最近的神经辐射场的技术进步实现了大规模场景的真实数字化, 但是图像捕获过程仍然耗时且劳动密集。先前的研究尝试使用主动式三维重建的下一最佳视角（NBV）策略来自动化这一过程。然而，现有的NBV策略严重依赖手工设计的标准、有限的动作空间，或者是针对每个场景优化的表示。这些约束限制了它们在跨数据集中的泛化能力。为了克服这些问题，我们提出了GenNBV，一个端到端通用的NBV策略。我们的策略采用基于强化学习（RL）的框架，将典型有限的动作空间扩展到5D自由空间。它赋予了我们的代理机无人机在训练过程中可以从任何视角进行扫描，甚至可以与未见几何体进行交互。为了增强跨数据集的泛化能力，我们还提出了一种新颖的多源状态嵌入，包括几何、语义和动作表示。

    arXiv:2402.16174v1 Announce Type: cross  Abstract: While recent advances in neural radiance field enable realistic digitization for large-scale scenes, the image-capturing process is still time-consuming and labor-intensive. Previous works attempt to automate this process using the Next-Best-View (NBV) policy for active 3D reconstruction. However, the existing NBV policies heavily rely on hand-crafted criteria, limited action space, or per-scene optimized representations. These constraints limit their cross-dataset generalizability. To overcome them, we propose GenNBV, an end-to-end generalizable NBV policy. Our policy adopts a reinforcement learning (RL)-based framework and extends typical limited action space to 5D free space. It empowers our agent drone to scan from any viewpoint, and even interact with unseen geometries during training. To boost the cross-dataset generalizability, we also propose a novel multi-source state embedding, including geometric, semantic, and action repres
    
[^6]: SimPro：一个简单的概率框架实现逼真的长尾半监督学习

    SimPro: A Simple Probabilistic Framework Towards Realistic Long-Tailed Semi-Supervised Learning

    [https://arxiv.org/abs/2402.13505](https://arxiv.org/abs/2402.13505)

    SimPro提出了一种高度适应的框架，不依赖于任何关于未标记数据分布的预定义假设，通过创新地改进期望最大化（EM）算法，明确分离条件和边缘类别分布的建模。

    

    近年来半监督学习的最新进展集中在解决一个更为逼真但具有挑战性的任务：解决标记数据的不平衡问题，同时未标记数据的类别分布既未知又可能不匹配。当前这一领域的方法往往预设了关于未标记数据类别分布的严格假设，从而限制了模型仅适应于某些分布范围。在本研究中，我们提出了一种新颖的方法，引入了一个高度适应性的框架，命名为SimPro，它不依赖于任何关于未标记数据分布的预定义假设。我们的框架建立在一个概率模型上，通过明确分离条件和边缘类别分布的建模，创新地改进了期望最大化（EM）算法。这种分离促进了在最大化过程中对类别分布进行估计的闭合形式解决方案。

    arXiv:2402.13505v1 Announce Type: new  Abstract: Recent advancements in semi-supervised learning have focused on a more realistic yet challenging task: addressing imbalances in labeled data while the class distribution of unlabeled data remains both unknown and potentially mismatched. Current approaches in this sphere often presuppose rigid assumptions regarding the class distribution of unlabeled data, thereby limiting the adaptability of models to only certain distribution ranges. In this study, we propose a novel approach, introducing a highly adaptable framework, designated as SimPro, which does not rely on any predefined assumptions about the distribution of unlabeled data. Our framework, grounded in a probabilistic model, innovatively refines the expectation-maximization (EM) algorithm by explicitly decoupling the modeling of conditional and marginal class distributions. This separation facilitates a closed-form solution for class distribution estimation during the maximization p
    
[^7]: 关于在生成AI领域利用DCT轨迹的探索

    On the Exploitation of DCT-Traces in the Generative-AI Domain

    [https://arxiv.org/abs/2402.02209](https://arxiv.org/abs/2402.02209)

    本文分析了生成AI模型在生成深度伪造图像时在频域中的DCT系数的统计特征。通过研究发现了一种独特的“辨别指纹”，可以利用它来改善现有的深度伪造检测器。

    

    深度伪造对于网络安全和数字取证领域来说是一个巨大的挑战，特别是考虑到最近基于生成AI的解决方案所获得的高质量结果。几乎所有生成模型在合成数据中留下了独特的痕迹，如果对其进行详细分析和识别，可以利用这些痕迹来改善现有深度伪造检测器的泛化限制。本文分析了由GAN和扩散模型引擎生成的深度伪造图像在频域中的特征，详细研究了离散余弦变换(DCT)系数的统计分布。我们认识到并非所有系数对图像检测的贡献相同，我们假设存在一种独特的“辨别指纹”，嵌入在特定系数组合中。为了识别它们，我们对各种系数组合进行了机器学习分类器的训练。此外，我们还使用了可解释AI(XAI)的LIME算法来搜索...

    Deepfakes represent one of the toughest challenges in the world of Cybersecurity and Digital Forensics, especially considering the high-quality results obtained with recent generative AI-based solutions. Almost all generative models leave unique traces in synthetic data that, if analyzed and identified in detail, can be exploited to improve the generalization limitations of existing deepfake detectors. In this paper we analyzed deepfake images in the frequency domain generated by both GAN and Diffusion Model engines, examining in detail the underlying statistical distribution of Discrete Cosine Transform (DCT) coefficients. Recognizing that not all coefficients contribute equally to image detection, we hypothesize the existence of a unique "discriminative fingerprint", embedded in specific combinations of coefficients. To identify them, Machine Learning classifiers were trained on various combinations of coefficients. In addition, the Explainable AI (XAI) LIME algorithm was used to sea
    
[^8]: 用于分解连续学习的无限dSprites：将记忆编辑与泛化分离

    Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization

    [https://arxiv.org/abs/2312.16731](https://arxiv.org/abs/2312.16731)

    引入了Infinite dSprites工具，用于创建任意长度的连续分类和分解基准，可以全面控制生成因素，有望缩小机器学习系统与人类学习在动态开放环境中的差距

    

    机器学习系统持续学习的能力受到灾难性遗忘的阻碍，即神经网络在学习新任务时会覆盖现有知识。持续学习方法通过正则化、参数隔离或排练来缓解这一问题，但它们通常在仅包含少数任务的基准测试上进行评估。为了取得进展以缩小这一差距，我们介绍了Infinite dSprites，这是一个简洁的工具，可创建任意长度的连续分类和分解基准，并对生成因素拥有完全控制。我们展示，在足够长的时间范围内，所有主要类型的持续学习方法的性能都表现出...

    arXiv:2312.16731v2 Announce Type: replace  Abstract: The ability of machine learning systems to learn continually is hindered by catastrophic forgetting, the tendency of neural networks to overwrite existing knowledge when learning a new task. Continual learning methods alleviate this problem through regularization, parameter isolation, or rehearsal, but they are typically evaluated on benchmarks comprising only a handful of tasks. In contrast, humans are able to learn continually in dynamic, open-world environments, effortlessly achieving one-shot memorization of unfamiliar objects and reliably recognizing them under various transformations. To make progress towards closing this gap, we introduce Infinite dSprites, a parsimonious tool for creating continual classification and disentanglement benchmarks of arbitrary length and with full control over generative factors. We show that over a sufficiently long time horizon, the performance of all major types of continual learning methods d
    
[^9]: ScreenQA: 移动应用截图上的大规模问答对

    ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots

    [https://arxiv.org/abs/2209.08199](https://arxiv.org/abs/2209.08199)

    ScreenQA提出了一个新的任务和数据集，通过86K个问答对在RICO数据集上注释，旨在评估屏幕阅读理解能力。

    

    我们提出了一个新的任务和数据集ScreenQA，用于通过问答来理解屏幕内容。现有的屏幕数据集要么侧重于结构和组件级别的理解，要么侧重于像导航和任务完成之类的更高级别的组合任务。我们试图通过在RICO数据集上注释86K个问答对来弥合这两者之间的差距，希望能够基准化屏幕阅读理解能力。

    arXiv:2209.08199v2 Announce Type: replace  Abstract: We present a new task and dataset, ScreenQA, for screen content understanding via question answering. The existing screen datasets are focused either on structure and component-level understanding, or on a much higher-level composite task such as navigation and task completion. We attempt to bridge the gap between these two by annotating 86K question-answer pairs over the RICO dataset in hope to benchmark the screen reading comprehension capacity.
    
[^10]: KI-PMF：知识综合的合理动作预测

    KI-PMF: Knowledge Integrated Plausible Motion Forecasting. (arXiv:2310.12007v1 [cs.RO])

    [http://arxiv.org/abs/2310.12007](http://arxiv.org/abs/2310.12007)

    本研究提出了一种名为KI-PMF的方法，通过结合先验知识，对交通参与者的未来行动进行准确预测，遵循车辆的运动约束和行驶环境的几何形状。通过条件化网络以遵循物理定律，可以获得准确和安全的预测，对于在实际环境中维护自动驾驶汽车的安全和效率至关重要。

    

    准确预测交通参与者的行动对大规模部署自动驾驶汽车至关重要。当前的轨迹预测方法主要集中在优化特定度量的损失函数上，这可能导致预测不符合物理定律或违反外部约束条件。我们的目标是结合明确的先验知识，使网络能够预测未来轨迹，符合车辆的运动约束和行驶环境的几何形状。为了实现这一目标，我们引入了非参数剪枝层和注意力层来整合定义的先验知识。我们的方法旨在确保交通参与者在复杂和动态情况下的到达可达性保证。通过将网络条件化为遵循物理定律，我们可以获得准确和安全的预测，这对于在实际世界环境中维护自动驾驶汽车的安全和效率至关重要。

    Accurately forecasting the motion of traffic actors is crucial for the deployment of autonomous vehicles at a large scale. Current trajectory forecasting approaches primarily concentrate on optimizing a loss function with a specific metric, which can result in predictions that do not adhere to physical laws or violate external constraints. Our objective is to incorporate explicit knowledge priors that allow a network to forecast future trajectories in compliance with both the kinematic constraints of a vehicle and the geometry of the driving environment. To achieve this, we introduce a non-parametric pruning layer and attention layers to integrate the defined knowledge priors. Our proposed method is designed to ensure reachability guarantees for traffic actors in both complex and dynamic situations. By conditioning the network to follow physical laws, we can obtain accurate and safe predictions, essential for maintaining autonomous vehicles' safety and efficiency in real-world settings
    
[^11]: 噪声容忍的无监督视觉语言模型适配器

    Noise-Tolerant Unsupervised Adapter for Vision-Language Models. (arXiv:2309.14928v1 [cs.CV])

    [http://arxiv.org/abs/2309.14928](http://arxiv.org/abs/2309.14928)

    这篇论文介绍了一种噪声容忍的无监督适配器(NtUA)，它可以使用少样本无标签目标样本来学习优秀的视觉语言模型。NtUA通过自适应缓存形成和伪标签修正来对抗伪标签噪声。

    

    最近在大规模的视觉语言模型中取得了非常显著的表现，在各种零样本图像分类任务中获得了良好的性能。然而，先前的研究通过引入少样本有标签目标样本已经取得了显著的改进，但仍需要目标样本的标注，这在处理各种视觉识别任务时大大降低了可扩展性。我们设计了一种噪声容忍的无监督适配器(NtUA)，它允许使用少样本无标签目标样本来学习优秀的目标模型。NtUA作为一个键值缓存，将少样本无标签目标样本的视觉特征和预测的伪标签作为键值对进行建模。它由两个互补的设计组成。第一个是自适应缓存形成，通过根据其预测置信度对键值对进行加权，以对抗伪标签的噪声。第二个是伪标签修正，它通过利用键值对的权重来修正伪标签以及缓存权重。

    Recent advances in large-scale vision-language models have achieved very impressive performance in various zero-shot image classification tasks. While prior studies have demonstrated significant improvements by introducing few-shot labelled target samples, they still require labelling of target samples, which greatly degrades their scalability while handling various visual recognition tasks. We design NtUA, a Noise-tolerant Unsupervised Adapter that allows learning superior target models with few-shot unlabelled target samples. NtUA works as a key-value cache that formulates visual features and predicted pseudo-labels of the few-shot unlabelled target samples as key-value pairs. It consists of two complementary designs. The first is adaptive cache formation that combats pseudo-label noises by weighting the key-value pairs according to their prediction confidence. The second is pseudo-label rectification, which corrects both pair values (i.e., pseudo-labels) and cache weights by leverag
    
[^12]: 基于类自适应交叉注意力的语义图像合成

    Semantic Image Synthesis via Class-Adaptive Cross-Attention. (arXiv:2308.16071v1 [cs.CV])

    [http://arxiv.org/abs/2308.16071](http://arxiv.org/abs/2308.16071)

    本文提出了一种基于类自适应交叉注意力的语义图像合成方法，通过使用交叉注意力层来调节图像生成，实现了优秀的视觉生成质量和编辑灵活性，并解决了全局样式不一致和局部样式编辑不真实的问题。

    

    在语义图像合成领域，最先进的方法主要使用空间自适应归一化层，可以实现出色的视觉生成质量和编辑灵活性。然而，这些方法往往忽略全局图像统计信息，导致局部样式编辑不真实，并引起诸如色彩或光照分布偏移等全局不一致性。此外，生成器需要语义布局来映射样式，对特征提出了严格的对齐约束。为解决这些问题，我们设计了一种新颖的架构，使用交叉注意力层代替反归一化层来调节图像生成。我们的模型继承了两种方法的优点，保持了最先进的重建质量，并且改进了全局和局部样式转移。

    In semantic image synthesis, the state of the art is dominated by methods that use spatially-adaptive normalization layers, which allow for excellent visual generation quality and editing versatility. Granted their efficacy, recent research efforts have focused toward finer-grained local style control and multi-modal generation. By construction though, such layers tend to overlook global image statistics leading to unconvincing local style editing and causing global inconsistencies such as color or illumination distribution shifts. Also, the semantic layout is required for mapping styles in the generator, putting a strict alignment constraint over the features. In response, we designed a novel architecture where cross-attention layers are used in place of de-normalization ones for conditioning the image generation. Our model inherits the advantages of both solutions, retaining state-of-the-art reconstruction quality, as well as improved global and local style transfer. Code and models 
    

