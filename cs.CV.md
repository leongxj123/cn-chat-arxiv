# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Debiasing Cardiac Imaging with Controlled Latent Diffusion Models](https://arxiv.org/abs/2403.19508) | 通过生成合成数据，使用受控潜在扩散模型来消除心脏成像中的偏差和不平衡问题。 |
| [^2] | [Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models](https://arxiv.org/abs/2403.01489) | 提出了一种基于重建的无需训练的方法，用于将由文本到图像生成模型生成的假图像归因于其来源模型，从而让模型所有者对模型的任何滥用负责。 |
| [^3] | [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/abs/2402.12226) | AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。 |
| [^4] | [Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation.](http://arxiv.org/abs/2311.01766) | 本研究提出了一种基于多模态证据的立场抽取网络（SEN）来检测上下文错误的误导信息。通过考虑不同证据的立场，我们提供了一种更准确的检测方法，并引入了基于共现关系的支持-反驳分数。这种方法在公共大规模数据上进行的实验证明了其有效性。 |
| [^5] | [Exploring the Influence of Information Entropy Change in Learning Systems.](http://arxiv.org/abs/2309.10625) | 本研究探索了在深度学习系统中引入噪声对性能的影响，证明了特定噪声可以在降低任务复杂性的条件下提升深度架构的性能，通过实验证明了在大规模图像数据集中的显著性能提升。 |

# 详细

[^1]: 用受控潜在扩散模型消除心脏成像的偏差

    Debiasing Cardiac Imaging with Controlled Latent Diffusion Models

    [https://arxiv.org/abs/2403.19508](https://arxiv.org/abs/2403.19508)

    通过生成合成数据，使用受控潜在扩散模型来消除心脏成像中的偏差和不平衡问题。

    

    深度学习对基于心脏磁共振成像进行疾病诊断和预后的解决方案的进展受到训练数据高度不平衡和偏差的阻碍。为了解决这个问题，我们提出一种方法，通过基于敏感属性（如性别、年龄、体重指数和健康状况）生成合成数据来减轻数据集中固有的不平衡性。我们采用基于去噪扩散概率模型的ControlNet来以患者元数据和使用大型队列研究（具体来说是UK Biobank）中分割掩模导出的心脏几何形状为条件生成文本。我们通过使用已建立的定量指标评估生成图像的逼真程度来评估我们的方法。此外，我们进行了一个下游分类任务，旨在通过合成生成的样本纠正代表性不足群体内的不平衡来改正分类器的偏差。我们的实验示范

    arXiv:2403.19508v1 Announce Type: cross  Abstract: The progress in deep learning solutions for disease diagnosis and prognosis based on cardiac magnetic resonance imaging is hindered by highly imbalanced and biased training data. To address this issue, we propose a method to alleviate imbalances inherent in datasets through the generation of synthetic data based on sensitive attributes such as sex, age, body mass index, and health condition. We adopt ControlNet based on a denoising diffusion probabilistic model to condition on text assembled from patient metadata and cardiac geometry derived from segmentation masks using a large-cohort study, specifically, the UK Biobank. We assess our method by evaluating the realism of the generated images using established quantitative metrics. Furthermore, we conduct a downstream classification task aimed at debiasing a classifier by rectifying imbalances within underrepresented groups through synthetically generated samples. Our experiments demons
    
[^2]: 基于重建的无需训练的文本到图像生成模型生成的假图像溯源方法

    Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models

    [https://arxiv.org/abs/2403.01489](https://arxiv.org/abs/2403.01489)

    提出了一种基于重建的无需训练的方法，用于将由文本到图像生成模型生成的假图像归因于其来源模型，从而让模型所有者对模型的任何滥用负责。

    

    文本到图像生成模型最近引起了人们的广泛关注，因为它们能够基于描述生成图像。虽然这些模型表现出色，但人们对生成的假图像可能被滥用提出了担忧。为了应对这一问题，我们提出了一种简单而有效的无需训练的方法，用于将由文本到图像模型生成的假图像归因于其来源模型。给定一个待归因的测试图像，首先我们反向重建图像的文本提示，然后将重建的提示放入不同的候选模型中以再现候选假图像。通过计算和排名测试图像与候选图像之间的相似性，我们可以确定图像的来源。这种溯源方法可以让模型所有者对其模型的任何滥用负责。需要注意的是，我们的方法不限制候选文本到图像生成模型的数量。

    arXiv:2403.01489v1 Announce Type: cross  Abstract: Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image genera
    
[^3]: AnyGPT：统一的多模式离散序列建模语言模型

    AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling

    [https://arxiv.org/abs/2402.12226](https://arxiv.org/abs/2402.12226)

    AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。

    

    我们介绍了 AnyGPT，这是一个任意多模式语言模型，利用离散表示统一处理各种模态，包括语音、文本、图像和音乐。AnyGPT 可以稳定训练，无需对当前大型语言模型（LLM）架构或训练范式进行任何改动。相反，它仅依赖于数据级预处理，促进了新模态的无缝集成到LLM中，类似于新语言的整合。我们构建了一个多模式文本中心的数据集，用于多模式对齐预训练。利用生成模型，我们合成了第一个大规模任意多模式指令数据集。它包括108k个多轮对话示例，精细地交织各种模态，从而使模型能够处理多模态输入和输出的任意组合。实验结果表明，AnyGPT能够促进...

    arXiv:2402.12226v1 Announce Type: cross  Abstract: We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM) architecture or training paradigms. Instead, it relies exclusively on data-level preprocessing, facilitating the seamless integration of new modalities into LLMs, akin to the incorporation of new languages. We build a multimodal text-centric dataset for multimodal alignment pre-training. Utilizing generative models, we synthesize the first large-scale any-to-any multimodal instruction dataset. It consists of 108k samples of multi-turn conversations that intricately interweave various modalities, thus equipping the model to handle arbitrary combinations of multimodal inputs and outputs. Experimental results demonstrate that AnyGPT is capable of facilitat
    
[^4]: 支持还是反驳：分析证据立场以检测上下文错误的误导信息

    Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation. (arXiv:2311.01766v1 [cs.CL])

    [http://arxiv.org/abs/2311.01766](http://arxiv.org/abs/2311.01766)

    本研究提出了一种基于多模态证据的立场抽取网络（SEN）来检测上下文错误的误导信息。通过考虑不同证据的立场，我们提供了一种更准确的检测方法，并引入了基于共现关系的支持-反驳分数。这种方法在公共大规模数据上进行的实验证明了其有效性。

    

    在线误导信息已经成为一个国家级的社会问题，是各种在线伤害的主要来源之一。其中一种常见的误导信息形式是上下文错误（OOC）信息，其中不同的信息被错误地关联起来，例如真实图像与虚假的文本标题或误导性的文本描述。尽管一些研究试图通过外部证据来抵御上下文错误的误导信息，但它们往往忽视了不同立场的不同证据的作用。受到证据立场代表不同检测结果的偏见的启发，我们提出了一种能够在统一框架中提取多模态证据的立场的立场抽取网络（SEN）。此外，我们还引入了基于命名实体的共现关系计算的支持-反驳分数到文本SEN中。对公共大规模数据的大量实验证明了我们的方法的有效性。

    Mis- and disinformation online have become a major societal problem as major sources of online harms of different kinds. One common form of mis- and disinformation is out-of-context (OOC) information, where different pieces of information are falsely associated, e.g., a real image combined with a false textual caption or a misleading textual description. Although some past studies have attempted to defend against OOC mis- and disinformation through external evidence, they tend to disregard the role of different pieces of evidence with different stances. Motivated by the intuition that the stance of evidence represents a bias towards different detection results, we propose a stance extraction network (SEN) that can extract the stances of different pieces of multi-modal evidence in a unified framework. Moreover, we introduce a support-refutation score calculated based on the co-occurrence relations of named entities into the textual SEN. Extensive experiments on a public large-scale data
    
[^5]: 探索学习系统中信息熵变化的影响

    Exploring the Influence of Information Entropy Change in Learning Systems. (arXiv:2309.10625v1 [cs.AI])

    [http://arxiv.org/abs/2309.10625](http://arxiv.org/abs/2309.10625)

    本研究探索了在深度学习系统中引入噪声对性能的影响，证明了特定噪声可以在降低任务复杂性的条件下提升深度架构的性能，通过实验证明了在大规模图像数据集中的显著性能提升。

    

    在本研究中，我们通过向输入/隐含特征添加噪声来探索深度学习系统中熵变化的影响。本文的应用重点是计算机视觉中的深度学习任务，但所提出的理论可以进一步应用于其他领域。噪声通常被视为各种深度学习架构（如卷积神经网络和视觉变换器）以及图像分类和迁移学习等不同学习任务中的有害扰动。然而，本文旨在重新思考传统命题是否总是成立。我们证明了在特定条件下，特定噪声可以提升各种深度架构的性能。我们在信息熵定义的任务复杂性减少方面从理论上证明了正噪声的增强效果，并在大规模图像数据集（如ImageNet）中实验证明了显著的性能提升。

    In this work, we explore the influence of entropy change in deep learning systems by adding noise to the inputs/latent features. The applications in this paper focus on deep learning tasks within computer vision, but the proposed theory can be further applied to other fields. Noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different learning tasks like image classification and transfer learning. However, this paper aims to rethink whether the conventional proposition always holds. We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions. We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet. Herein, we use the informat
    

