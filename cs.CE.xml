<rss version="2.0"><channel><title>Chat Arxiv cs.CE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CE</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31185;&#23398;&#35821;&#35328;&#24314;&#27169;&#65288;SLM&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#35299;&#20915;&#20998;&#23376;&#24314;&#27169;&#21644;&#35774;&#35745;&#20013;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22810;&#27169;&#24577;&#22522;&#20934;&#21644;&#23454;&#39564;&#35780;&#20272;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#27169;&#22411;&#19982;&#25968;&#25454;&#27169;&#24577;&#21305;&#37197;&#30340;&#37327;&#21270;&#20449;&#24687;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#30693;&#35782;&#23398;&#20064;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.04119</link><description>&lt;p&gt;
&#31185;&#23398;&#35821;&#35328;&#24314;&#27169;&#65306;&#20998;&#23376;&#31185;&#23398;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23450;&#37327;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Scientific Language Modeling: A Quantitative Review of Large Language Models in Molecular Science
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31185;&#23398;&#35821;&#35328;&#24314;&#27169;&#65288;SLM&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#35299;&#20915;&#20998;&#23376;&#24314;&#27169;&#21644;&#35774;&#35745;&#20013;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22810;&#27169;&#24577;&#22522;&#20934;&#21644;&#23454;&#39564;&#35780;&#20272;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#27169;&#22411;&#19982;&#25968;&#25454;&#27169;&#24577;&#21305;&#37197;&#30340;&#37327;&#21270;&#20449;&#24687;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#30693;&#35782;&#23398;&#20064;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#30340;&#20998;&#23376;&#24314;&#27169;&#21644;&#35774;&#35745;&#23545;&#20110;&#21457;&#29616;&#21644;&#25506;&#32034;&#26032;&#22411;&#20998;&#23376;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#24341;&#20837;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#20135;&#29983;&#20102;&#38761;&#21629;&#24615;&#30340;&#24433;&#21709;&#12290;&#29305;&#21035;&#26159;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#35270;&#35282;&#20026;&#31185;&#23398;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#31185;&#23398;&#35821;&#35328;&#24314;&#27169;&#65288;SLM&#65289;&#30340;&#30740;&#31350;&#33539;&#24335;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;&#22914;&#20309;&#37327;&#21270;&#27169;&#22411;&#19982;&#25968;&#25454;&#27169;&#24577;&#20043;&#38388;&#30340;&#21305;&#37197;&#20197;&#21450;&#22914;&#20309;&#35782;&#21035;&#27169;&#22411;&#30340;&#30693;&#35782;&#23398;&#20064;&#20559;&#22909;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;ChEBI-20-MM&#30340;&#22810;&#27169;&#24577;&#22522;&#20934;&#65292;&#24182;&#36827;&#34892;&#20102;1263&#20010;&#23454;&#39564;&#65292;&#35780;&#20272;&#20102;&#27169;&#22411;&#19982;&#25968;&#25454;&#27169;&#24577;&#30340;&#20860;&#23481;&#24615;&#21644;&#30693;&#35782;&#33719;&#21462;&#33021;&#21147;&#12290;&#36890;&#36807;&#27169;&#24577;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#65292;&#25105;&#20204;&#20026;&#20219;&#21153;&#25552;&#20379;&#20102;&#26368;&#21512;&#36866;&#30340;&#27169;&#24577;&#30340;&#35265;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#32479;&#35745;&#21487;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26412;&#22320;&#21270;&#26469;&#21457;&#29616;&#29305;&#23450;&#19978;&#19979;&#25991;&#30340;&#30693;&#35782;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient molecular modeling and design are crucial for the discovery and exploration of novel molecules, and the incorporation of deep learning methods has revolutionized this field. In particular, large language models (LLMs) offer a fresh approach to tackle scientific problems from a natural language processing (NLP) perspective, introducing a research paradigm called scientific language modeling (SLM). However, two key issues remain: how to quantify the match between model and data modalities and how to identify the knowledge-learning preferences of models. To address these challenges, we propose a multi-modal benchmark, named ChEBI-20-MM, and perform 1263 experiments to assess the model's compatibility with data modalities and knowledge acquisition. Through the modal transition probability matrix, we provide insights into the most suitable modalities for tasks. Furthermore, we introduce a statistically interpretable approach to discover context-specific knowledge mapping by locali
&lt;/p&gt;</description></item></channel></rss>