<rss version="2.0"><channel><title>Chat Arxiv cs.CE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CE</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#20449;&#24230;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#31232;&#32570;&#32780;&#26114;&#36149;&#30340;&#39640;&#20445;&#30495;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.08627</link><description>&lt;p&gt;
&#22810;&#20449;&#24230;&#32447;&#24615;&#22238;&#24402;&#29992;&#20110;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#31232;&#32570;&#25968;&#25454;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multifidelity linear regression for scientific machine learning from scarce data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08627
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#20449;&#24230;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#31232;&#32570;&#32780;&#26114;&#36149;&#30340;&#39640;&#20445;&#30495;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#25311;&#21512;&#32473;&#23450;&#21442;&#25968;&#21270;&#27169;&#22411;&#31867;&#30340;&#21442;&#25968;&#26469;&#36866;&#24212;&#25968;&#25454;&#65292;&#20316;&#20026;&#23398;&#20064;&#22797;&#26434;&#24037;&#31243;&#31995;&#32479;&#30340;&#20195;&#29702;&#27169;&#22411;&#30340;&#28508;&#22312;&#26041;&#27861;&#24050;&#32463;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#29615;&#22659;&#20013;&#65292;&#29983;&#25104;&#29992;&#20110;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#39640;&#20445;&#30495;&#25968;&#25454;&#26159;&#26114;&#36149;&#30340;&#65292;&#24182;&#19988;&#29992;&#20110;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#30340;&#39044;&#31639;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#22810;&#20449;&#24230;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#25968;&#25454;&#30340;&#21508;&#31181;&#20445;&#30495;&#24230;&#21644;&#25104;&#26412;&#21487;&#29992;&#30340;&#31185;&#23398;&#32972;&#26223;&#65307;&#20363;&#22914;&#65292;&#39640;&#20445;&#30495;&#25968;&#25454;&#21487;&#33021;&#30001;&#26114;&#36149;&#30340;&#20840;&#38754;&#35299;&#26512;&#30340;&#29289;&#29702;&#27169;&#25311;&#29983;&#25104;&#65292;&#32780;&#20302;&#20445;&#30495;&#25968;&#25454;&#21487;&#33021;&#26469;&#33258;&#22522;&#20110;&#31616;&#21270;&#30340;&#26356;&#20415;&#23452;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08627v1 Announce Type: cross  Abstract: Machine learning (ML) methods, which fit to data the parameters of a given parameterized model class, have garnered significant interest as potential methods for learning surrogate models for complex engineering systems for which traditional simulation is expensive. However, in many scientific and engineering settings, generating high-fidelity data on which to train ML models is expensive, and the available budget for generating training data is limited. ML models trained on the resulting scarce high-fidelity data have high variance and are sensitive to vagaries of the training data set. We propose a new multifidelity training approach for scientific machine learning that exploits the scientific context where data of varying fidelities and costs are available; for example high-fidelity data may be generated by an expensive fully resolved physics simulation whereas lower-fidelity data may arise from a cheaper model based on simplifying 
&lt;/p&gt;</description></item></channel></rss>