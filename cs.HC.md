# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Artificial intelligence is ineffective and potentially harmful for fact checking.](http://arxiv.org/abs/2308.10800) | 这项研究发现人工智能语言模型在事实核查中表现出色，但在帮助用户判断标题准确性和分享准确新闻方面影响不大。然而，在某些情况下，它会误导用户对真实标题的信仰，并增加对未确定虚假标题的信仰。 |
| [^2] | [DR-HAI: Argumentation-based Dialectical Reconciliation in Human-AI Interactions.](http://arxiv.org/abs/2306.14694) | DR-HAI是一个新颖的基于论证的框架，旨在通过互动调和解决人工智能与人类之间的知识差异，为促进有效的人工智能与人类交互提供了一个有希望的方向。 |

# 详细

[^1]: 人工智能在事实核查中无效且具有潜在危害性

    Artificial intelligence is ineffective and potentially harmful for fact checking. (arXiv:2308.10800v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2308.10800](http://arxiv.org/abs/2308.10800)

    这项研究发现人工智能语言模型在事实核查中表现出色，但在帮助用户判断标题准确性和分享准确新闻方面影响不大。然而，在某些情况下，它会误导用户对真实标题的信仰，并增加对未确定虚假标题的信仰。

    

    事实核查是对抗错误信息的有效策略，但是它在规模上的实施受到了网络上信息过于庞大的阻碍。近期的人工智能语言模型在事实核查任务中展现出了令人印象深刻的能力，但人们在使用这些模型提供的事实核查信息时的作用机制并不清楚。在这里，我们通过一项预先登记的随机对照实验，研究了一款热门人工智能模型生成的事实核查对政治新闻信仰和分享意图的影响。尽管该人工智能在揭穿虚假标题方面表现得相当不错，但我们发现它并没有对参与者识别标题准确性或分享准确新闻的能力产生显著影响。然而，在特定情况下，该人工智能事实核查器具有危害性：将一些真实标题误标为虚假会降低对其的信仰，而对其未确定的虚假标题则会增加对其的信仰。在积极方面，该人工智能提高了正确标定标题的分享意愿。

    Fact checking can be an effective strategy against misinformation, but its implementation at scale is impeded by the overwhelming volume of information online. Recent artificial intelligence (AI) language models have shown impressive ability in fact-checking tasks, but how humans interact with fact-checking information provided by these models is unclear. Here we investigate the impact of fact checks generated by a popular AI model on belief in, and sharing intent of, political news in a preregistered randomized control experiment. Although the AI performs reasonably well in debunking false headlines, we find that it does not significantly affect participants' ability to discern headline accuracy or share accurate news. However, the AI fact-checker is harmful in specific cases: it decreases beliefs in true headlines that it mislabels as false and increases beliefs for false headlines that it is unsure about. On the positive side, the AI increases sharing intents for correctly labeled t
    
[^2]: DR-HAI: 人工智能与人类交互中基于论证的辩证调和

    DR-HAI: Argumentation-based Dialectical Reconciliation in Human-AI Interactions. (arXiv:2306.14694v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.14694](http://arxiv.org/abs/2306.14694)

    DR-HAI是一个新颖的基于论证的框架，旨在通过互动调和解决人工智能与人类之间的知识差异，为促进有效的人工智能与人类交互提供了一个有希望的方向。

    

    我们提出了DR-HAI，这是一个新颖的基于论证的框架，旨在扩展人类感知规划中常用的模型调和方法，以增强人工智能与人类的交互。通过采用基于论证的对话范式，DR-HAI能够进行互动调和，解决解释者和被解释者之间的知识差异。我们对DR-HAI的操作语义进行了形式化描述，提供了理论保证，并对其效果进行了经验评估。我们的研究结果表明，DR-HAI为促进有效的人工智能与人类交互提供了一个具有潜力的方向。

    We present DR-HAI -- a novel argumentation-based framework designed to extend model reconciliation approaches, commonly used in human-aware planning, for enhanced human-AI interaction. By adopting an argumentation-based dialogue paradigm, DR-HAI enables interactive reconciliation to address knowledge discrepancies between an explainer and an explainee. We formally describe the operational semantics of DR-HAI, provide theoretical guarantees, and empirically evaluate its efficacy. Our findings suggest that DR-HAI offers a promising direction for fostering effective human-AI interactions.
    

