# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making](https://arxiv.org/abs/2403.16812) | 提出了人工智能和人类的辩论框架，通过LLM增强的辩论人工智能促进人类反思和讨论决策中的意见分歧。 |
| [^2] | [Investigating Use Cases of AI-Powered Scene Description Applications for Blind and Low Vision People](https://arxiv.org/abs/2403.15604) | 该研究调查了AI智能场景描述应用在盲人和低视力人群中的使用情况，发现用户主要用于识别已知对象的视觉特征以及避免与危险物体接触，并且用户对描述的满意度评分相对较低。 |
| [^3] | [Personality Traits in Large Language Models.](http://arxiv.org/abs/2307.00184) | 该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。 |

# 详细

[^1]: 人工智能和人类的辩论：LLM增强的辩论人工智能设计与评估，用于人工智能辅助决策

    Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making

    [https://arxiv.org/abs/2403.16812](https://arxiv.org/abs/2403.16812)

    提出了人工智能和人类的辩论框架，通过LLM增强的辩论人工智能促进人类反思和讨论决策中的意见分歧。

    

    在人工智能辅助决策中，人类通常被动地审查人工智能的建议，然后决定是否全盘接受或拒绝。在这样的范式中，发现人类很少激发分析思维，且在发生分歧时难以将矛盾意见的细微差别传达给人工智能。为了解决这一挑战，我们提出了人工智能和人类的辩论，这是一个新颖的框架，旨在促进人类在决策过程中对人工智能意见分歧进行反思和讨论。基于人类辩论理论，该框架通过维度级意见征集、辩论讨论和决策更新，将人类和人工智能进行互动。为了赋予人工智能辩论能力，我们设计了辩论人工智能，利用大型语言模型（LLMs）作为人类和领域特定模型之间的桥梁，实现灵活的对话交互和忠实的信息提供。

    arXiv:2403.16812v1 Announce Type: cross  Abstract: In AI-assisted decision-making, humans often passively review AI's suggestion and decide whether to accept or reject it as a whole. In such a paradigm, humans are found to rarely trigger analytical thinking and face difficulties in communicating the nuances of conflicting opinions to the AI when disagreements occur. To tackle this challenge, we propose Human-AI Deliberation, a novel framework to promote human reflection and discussion on conflicting human-AI opinions in decision-making. Based on theories in human deliberation, this framework engages humans and AI in dimension-level opinion elicitation, deliberative discussion, and decision updates. To empower AI with deliberative capabilities, we designed Deliberative AI, which leverages large language models (LLMs) as a bridge between humans and domain-specific models to enable flexible conversational interactions and faithful information provision. An exploratory evaluation on a grad
    
[^2]: 研究AI智能场景描述应用在盲人和低视力人群中的使用情况

    Investigating Use Cases of AI-Powered Scene Description Applications for Blind and Low Vision People

    [https://arxiv.org/abs/2403.15604](https://arxiv.org/abs/2403.15604)

    该研究调查了AI智能场景描述应用在盲人和低视力人群中的使用情况，发现用户主要用于识别已知对象的视觉特征以及避免与危险物体接触，并且用户对描述的满意度评分相对较低。

    

    “场景描述”应用程序可以帮助盲人和低视力人士在日常生活中理解照片中的视觉内容。研究人员已经研究了这些应用的使用情况，但他们只研究了利用远程有视力助手的应用，对于利用人工智能生成描述的应用知之甚少。因此，为了调查其使用情况，我们进行了为期两周的日记研究，在此期间，16名盲人和低视力参与者使用了我们设计的AI智能场景描述应用。通过他们的日记记录和后续访谈，用户分享了他们的信息目标以及他们收到的视觉描述的评估。我们分析了这些记录，并发现了常见的使用情况，比如识别已知对象的视觉特征，以及一些令人惊讶的情况，比如避免接触危险物体。我们还发现，用户对这些描述的满意度评分相对较低，平均为2.76（标准差=1.49），对满意度的评分为2.43（标准差=1）。

    arXiv:2403.15604v1 Announce Type: cross  Abstract: "Scene description" applications that describe visual content in a photo are useful daily tools for blind and low vision (BLV) people. Researchers have studied their use, but they have only explored those that leverage remote sighted assistants; little is known about applications that use AI to generate their descriptions. Thus, to investigate their use cases, we conducted a two-week diary study where 16 BLV participants used an AI-powered scene description application we designed. Through their diary entries and follow-up interviews, users shared their information goals and assessments of the visual descriptions they received. We analyzed the entries and found frequent use cases, such as identifying visual features of known objects, and surprising ones, such as avoiding contact with dangerous objects. We also found users scored the descriptions relatively low on average, 2.76 out of 5 (SD=1.49) for satisfaction and 2.43 out of 4 (SD=1
    
[^3]: 大型语言模型中的人格特质

    Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])

    [http://arxiv.org/abs/2307.00184](http://arxiv.org/abs/2307.00184)

    该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。

    

    大型语言模型（LLMs）的出现彻底改变了自然语言处理，使得能够生成连贯且上下文相关的文本。随着LLMs越来越多地用于驱动对话代理，这些模型通过训练大量人工生成的数据获得的人格特质引起了人们的关注。由于人格是决定交流效果的重要因素，我们提出了一种全面的方法来进行验证的心理测量测试，并对从广泛使用的LLMs生成的文本中展示的人格特质进行量化、分析和塑造。我们发现：1）某些LLMs的输出中模拟的人格（在特定的提示配置下）是可靠和有效的；2）LLM模拟的人格的可靠性和有效性的证据对于更大的和经过指导微调的模型更强；3）LLM输出中的人格可以根据需要的维度进行塑造，以模仿特定的人格特点。

    The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. 
    

