# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Distinguishing the Indistinguishable: Human Expertise in Algorithmic Prediction](https://arxiv.org/abs/2402.00793) | 本论文介绍了一种新的框架，将人类专业知识纳入算法预测中，重点在于利用人的判断力区分对于任何可行的预测算法来说“看起来相同”的输入。 |
| [^2] | [Large language models can enhance persuasion through linguistic feature alignment](https://arxiv.org/abs/2311.16466) | 本研究调查了大型语言模型对人类沟通的影响，使用了消费者金融投诉数据，并发现大型语言模型的使用可能增强了一整套语言特征，提高了信息说服力。 |

# 详细

[^1]: 无法区分的区分：算法预测中的人类专业知识

    Distinguishing the Indistinguishable: Human Expertise in Algorithmic Prediction

    [https://arxiv.org/abs/2402.00793](https://arxiv.org/abs/2402.00793)

    本论文介绍了一种新的框架，将人类专业知识纳入算法预测中，重点在于利用人的判断力区分对于任何可行的预测算法来说“看起来相同”的输入。

    

    我们引入了一种将人类专业知识纳入算法预测的新框架。我们的方法主要关注利用人的判断力来区分那些对于任何可行的预测算法来说“看起来相同”的输入。我们认为，这种框架能够澄清人工智能与人类协作预测任务中的问题，因为专家通常具有信息的访问权限——特别是主观信息——而这些信息是算法训练数据中没有编码的。基于这一认识，我们开发了一组有原则的算法，仅在任何可行的预测器的性能有所改善时才选择性地纳入人类反馈。经验结果表明，尽管算法在平均水平上往往优于人类对应任务的能力，但人类判断在特定情况下（可以预先确定）能够显著提高算法预测的性能。在一个X射线分类任务中，我们发现这个子集在患者群体中占据了近30%。我们的方法提供了一种自然的方式，

    We introduce a novel framework for incorporating human expertise into algorithmic predictions. Our approach focuses on the use of human judgment to distinguish inputs which `look the same' to any feasible predictive algorithm. We argue that this framing clarifies the problem of human/AI collaboration in prediction tasks, as experts often have access to information -- particularly subjective information -- which is not encoded in the algorithm's training data. We use this insight to develop a set of principled algorithms for selectively incorporating human feedback only when it improves the performance of any feasible predictor. We find empirically that although algorithms often outperform their human counterparts on average, human judgment can significantly improve algorithmic predictions on specific instances (which can be identified ex-ante). In an X-ray classification task, we find that this subset constitutes nearly 30% of the patient population. Our approach provides a natural way
    
[^2]: 大型语言模型通过语言特征对齐可以增强说服力

    Large language models can enhance persuasion through linguistic feature alignment

    [https://arxiv.org/abs/2311.16466](https://arxiv.org/abs/2311.16466)

    本研究调查了大型语言模型对人类沟通的影响，使用了消费者金融投诉数据，并发现大型语言模型的使用可能增强了一整套语言特征，提高了信息说服力。

    

    尽管大型语言模型 (LLMs)正在重新塑造人类生活的各个方面，但我们对它们的影响的理解仍然有些受限。本文研究了LLMs对人类沟通的影响，使用了消费者金融投诉的数据。通过对消费者金融保护局 (CFPB) 收集的超过820,000个投诉进行AI检测，我们发现在ChatGPT发布后不久，LLMs的使用可能性急剧增加。此外，LLMs的使用可能性与信息说服力（即从金融公司获得救济的可能性增加）呈正相关。计算语言分析表明，这种正相关可能是由LLMs增强了各种语言特征所解释的。根据这些观察研究的结果，我们假设LLMs的使用可能增强了一整套语言特征，提高了对具有不同语言背景的接收者的信息说服力。

    Although large language models (LLMs) are reshaping various aspects of human life, our current understanding of their impacts remains somewhat constrained. Here we investigate the impact of LLMs on human communication, using data on consumer complaints in the financial industry. By employing an AI detection tool on more than 820K complaints gathered by the Consumer Financial Protection Bureau (CFPB), we find a sharp increase in the likely use of LLMs shortly after the release of ChatGPT. Moreover, the likely LLM usage was positively correlated with message persuasiveness (i.e., increased likelihood of obtaining relief from financial firms). Computational linguistic analyses suggest that the positive correlation may be explained by LLMs' enhancement of various linguistic features. Based on the results of these observational studies, we hypothesize that LLM usage may enhance a comprehensive set of linguistic features, increasing message persuasiveness to receivers with heterogeneous ling
    

