# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [WatChat: Explaining perplexing programs by debugging mental models](https://arxiv.org/abs/2403.05334) | 本文通过应用计算认知科学的方法，提出了一种能够通过调试心智模型解释令人困惑程序行为的方法。 |
| [^2] | [Large Language Models and Games: A Survey and Roadmap](https://arxiv.org/abs/2402.18659) | 这项研究调查了大型语言模型在游戏领域中的多种应用及其角色，指出了未开发领域和未来发展方向，同时探讨了在游戏领域中大型语言模型的潜力和限制。 |

# 详细

[^1]: WatChat：通过调试心智模型解释令人困惑的程序

    WatChat: Explaining perplexing programs by debugging mental models

    [https://arxiv.org/abs/2403.05334](https://arxiv.org/abs/2403.05334)

    本文通过应用计算认知科学的方法，提出了一种能够通过调试心智模型解释令人困惑程序行为的方法。

    

    通常，解释程序意外行为的一个好方法是程序员代码中的错误。但有时，一个更好的解释是程序员对所使用语言的心智模型中存在错误。我们不仅仅调试当前代码（“给程序员一条鱼”），而是希望我们的工具能直接调试我们的心智模型（“教会程序员如何捕鱼”）。本文将计算认知科学的思想应用到其中，对令人困惑的程序，我们使用程序综合技术自动推断可能导致用户对程序行为感到惊讶的误解。通过分析这些误解，我们提供简明、有用的程序行为解释。我们的方法甚至可以被反转，以综合教学示范程序来诊断和纠正学生的误解。

    arXiv:2403.05334v1 Announce Type: cross  Abstract: Often, a good explanation for a program's unexpected behavior is a bug in the programmer's code. But sometimes, an even better explanation is a bug in the programmer's mental model of the language they are using. Instead of merely debugging our current code ("giving the programmer a fish"), what if our tools could directly debug our mental models ("teaching the programmer to fish")? In this paper, we apply ideas from computational cognitive science to do exactly that. Given a perplexing program, we use program synthesis techniques to automatically infer potential misconceptions that might cause the user to be surprised by the program's behavior. By analyzing these misconceptions, we provide succinct, useful explanations of the program's behavior. Our methods can even be inverted to synthesize pedagogical example programs for diagnosing and correcting misconceptions in students.
    
[^2]: 大型语言模型与游戏：调研与路线图

    Large Language Models and Games: A Survey and Roadmap

    [https://arxiv.org/abs/2402.18659](https://arxiv.org/abs/2402.18659)

    这项研究调查了大型语言模型在游戏领域中的多种应用及其角色，指出了未开发领域和未来发展方向，同时探讨了在游戏领域中大型语言模型的潜力和限制。

    

    近年来，大型语言模型（LLMs）的研究急剧增加，并伴随着公众对该主题的参与。尽管起初是自然语言处理中的一小部分，LLMs在广泛的应用和领域中展现出显著潜力，包括游戏。本文调查了LLMs在游戏中及为游戏提供支持的各种应用的最新技术水平，并明确了LLMs在游戏中可以扮演的不同角色。重要的是，我们讨论了尚未开发的领域和LLMs在游戏中未来应用的有前途的方向，以及在游戏领域中LLMs的潜力和限制。作为LLMs和游戏交叉领域的第一份综合调查和路线图，我们希望本文能够成为这一激动人心的新领域的开创性研究和创新的基础。

    arXiv:2402.18659v1 Announce Type: cross  Abstract: Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.
    

