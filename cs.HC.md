# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling](https://arxiv.org/abs/2402.14701) | 本文提出了一种名为COMPASS的新框架，通过分析心理治疗会话中的自然语言，直接推断治疗工作联盟，为临床精神病学提供了可解释性，并在识别与正在治疗的疾病相关的新兴模式方面发挥作用。 |
| [^2] | [Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation](https://arxiv.org/abs/2312.03003) | MobileGPT是一种创新的基于LLM的移动任务自动化工具，通过类人应用记忆模拟人类与移动应用的认知过程，实现任务程序的精确高效学习。 |
| [^3] | [Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations.](http://arxiv.org/abs/2210.11584) | 对模型解释的用户研究综述发现，可解释型人工智能（XAI）正在某些应用领域快速扩散，但用户评估仍然稀缺且几乎不涉及认知或社会科学的见解。 |

# 详细

[^1]: COMPASS：利用语言建模对患者-治疗师联盟策略进行计算映射

    COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling

    [https://arxiv.org/abs/2402.14701](https://arxiv.org/abs/2402.14701)

    本文提出了一种名为COMPASS的新框架，通过分析心理治疗会话中的自然语言，直接推断治疗工作联盟，为临床精神病学提供了可解释性，并在识别与正在治疗的疾病相关的新兴模式方面发挥作用。

    

    治疗工作联盟是预测心理治疗治疗成功的关键因素。传统上，工作联盟评估依赖于治疗师和患者填写的问卷。本文提出了COMPASS，一个新颖的框架，可直接从心理治疗课程中使用的自然语言中推断治疗工作联盟。我们的方法利用先进的大型语言模型分析心理治疗会话的转录，并将其与工作联盟清单中陈述的分布式表示进行比较。通过分析涵盖多种精神疾病的超过950个会话的数据集，我们展示了我们的方法在显微地映射患者-治疗师对齐轨迹方面的有效性，并为临床精神病学提供解释性，并在识别与正在治疗的疾病相关的新兴模式方面提供可解释性。通过使用各种神经主题模式

    arXiv:2402.14701v1 Announce Type: cross  Abstract: The therapeutic working alliance is a critical factor in predicting the success of psychotherapy treatment. Traditionally, working alliance assessment relies on questionnaires completed by both therapists and patients. In this paper, we present COMPASS, a novel framework to directly infer the therapeutic working alliance from the natural language used in psychotherapy sessions. Our approach utilizes advanced large language models to analyze transcripts of psychotherapy sessions and compare them with distributed representations of statements in the working alliance inventory. Analyzing a dataset of over 950 sessions covering diverse psychiatric conditions, we demonstrate the effectiveness of our method in microscopically mapping patient-therapist alignment trajectories and providing interpretability for clinical psychiatry and in identifying emerging patterns related to the condition being treated. By employing various neural topic mode
    
[^2]: 探索、选择、推导和回忆：为移动任务自动化增加类人记忆的LLM

    Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation

    [https://arxiv.org/abs/2312.03003](https://arxiv.org/abs/2312.03003)

    MobileGPT是一种创新的基于LLM的移动任务自动化工具，通过类人应用记忆模拟人类与移动应用的认知过程，实现任务程序的精确高效学习。

    

    大型语言模型（LLMs）的出现为移动任务自动化领域带来了新的机遇。它们优越的语言理解和推理能力使用户能够自动执行复杂和重复的任务。然而，由于LLMs固有的不可靠性和高运行成本，它们的实际适用性相当有限。为解决这些问题，本文引入了MobileGPT，这是一种创新的基于LLM的移动任务自动化工具，配备了类人应用记忆。MobileGPT模拟了人类与移动应用交互的认知过程--探索、选择、推导和回忆。这种方法通过将任务程序分解为更小、模块化的子任务，允许更精确、高效地学习任务流程，从而实现子任务的重复使用、重新排列和适应各种目标。我们使用在线LLM服务（GPT-3.5和GPT-4）实现了MobileGPT，并在一组数据上评估了其性能。

    arXiv:2312.03003v2 Announce Type: replace-cross  Abstract: The advent of large language models (LLMs) has opened up new opportunities in the field of mobile task automation. Their superior language understanding and reasoning capabilities allow users to automate complex and repetitive tasks. However, due to the inherent unreliability and high operational cost of LLMs, their practical applicability is quite limited. To address these issues, this paper introduces MobileGPT, an innovative LLM-based mobile task automator equipped with a human-like app memory. MobileGPT emulates the cognitive process of humans interacting with a mobile app -- explore, select, derive, and recall. This approach allows for a more precise and efficient learning of a task's procedure by breaking it down into smaller, modular sub-tasks that can be re-used, re-arranged, and adapted for various objectives. We implement MobileGPT using online LLMs services (GPT-3.5 and GPT-4) and evaluate its performance on a datase
    
[^3]: 朝着以人为中心的可解释型人工智能：对模型解释的用户研究综述

    Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations. (arXiv:2210.11584v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.11584](http://arxiv.org/abs/2210.11584)

    对模型解释的用户研究综述发现，可解释型人工智能（XAI）正在某些应用领域快速扩散，但用户评估仍然稀缺且几乎不涉及认知或社会科学的见解。

    

    可解释型人工智能（XAI）被广泛认为是不断扩展的人工智能研究的必需条件。对XAI用户需求的更好理解以及可解释模型的人本评估既是必要性也是挑战。在本文中，我们通过系统性文献综述研究了HCI和AI研究人员如何进行XAI应用的用户研究。通过对过去五年中基于人类的XAI评估的97篇核心论文进行识别和深入分析，我们将其按照解释方法的测量特征（信任、理解、可用性和人工智能与人类的合作表现）进行分类。我们的研究表明，XAI在某些应用领域（如推荐系统）扩散更迅速，但用户评估仍相当稀缺，并且几乎没有融入认知或社会科学的任何见解。基于综合讨论的最佳实践，即常见模型、设计选择和度量方法。

    Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how HCI and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures
    

