# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs](https://arxiv.org/abs/2404.01461) | 该研究调查了代表性启发式对大型语言模型推理的影响，并创建了专门的数据集进行实验验证 |
| [^2] | [OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web](https://arxiv.org/abs/2402.17553) | OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。 |
| [^3] | [Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome.](http://arxiv.org/abs/2309.10744) | 该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。 |
| [^4] | [Long-Term Memorability On Advertisements.](http://arxiv.org/abs/2309.00378) | 本研究是首个大规模的记忆性研究，发现广告的长期记忆性对于市场营销非常重要，但在机器学习文献中一直缺乏相关研究。通过分析大量参与者和广告，我们得出了关于什么使广告记忆深刻的有趣见解。 |

# 详细

[^1]: 请真正的琳达站出来...面对大语言模型？在LLMs中审视代表性启发式

    Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs

    [https://arxiv.org/abs/2404.01461](https://arxiv.org/abs/2404.01461)

    该研究调查了代表性启发式对大型语言模型推理的影响，并创建了专门的数据集进行实验验证

    

    尽管大型语言模型（LLMs）在理解文本和生成类似人类文本方面表现出色，但它们可能会展现出从训练数据中获得的偏见。具体而言，LLMs可能会容易受到人类决策中的一种常见认知陷阱影响，即代表性启发式。这是心理学中的一个概念，指的是根据事件与一个众所周知的原型或典型例子的相似程度来判断事件发生的可能性，而不考虑更广泛的事实或统计证据。本研究调查了代表性启发式对LLM推理的影响。我们创建了REHEAT（Representativeness Heuristic AI Testing），一个包含涵盖六种常见代表性启发式类型问题的数据集。实验显示，应用于REHEAT的四个LLMs都表现出代表性启发式偏见。我们进一步确定了模型的推理步骤

    arXiv:2404.01461v1 Announce Type: new  Abstract: Although large language models (LLMs) have demonstrated remarkable proficiency in understanding text and generating human-like text, they may exhibit biases acquired from training data in doing so. Specifically, LLMs may be susceptible to a common cognitive trap in human decision-making called the representativeness heuristic. This is a concept in psychology that refers to judging the likelihood of an event based on how closely it resembles a well-known prototype or typical example versus considering broader facts or statistical evidence. This work investigates the impact of the representativeness heuristic on LLM reasoning. We created REHEAT (Representativeness Heuristic AI Testing), a dataset containing a series of problems spanning six common types of representativeness heuristics. Experiments reveal that four LLMs applied to REHEAT all exhibited representativeness heuristic biases. We further identify that the model's reasoning steps
    
[^2]: OmniACT：用于启用桌面和Web多模式通用主动智能体的数据集和基准

    OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web

    [https://arxiv.org/abs/2402.17553](https://arxiv.org/abs/2402.17553)

    OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。

    

    几十年来，人机交互从根本上一直是手动的。即使在今天，几乎所有在计算机上进行的高效工作都需要人类在每一步都提供输入。虚拟主动智能代表了自动化许多这些琐碎任务的一个激动人心的步骤。虚拟代理将使技术能力有限的用户能够充分利用计算机系统的各种可能性。它们还可以实现高效地简化许多计算机任务，从日历管理到复杂的旅行预订，减少人类干预。在这篇论文中，我们介绍了 OmniACT，这是一个用于评估代理生成可执行程序来完成计算机任务能力的首个数据集和基准。我们的范围超越了传统的Web自动化，涵盖了各种桌面应用。该数据集包含诸如"播放下一首歌"之类的基本任务，以及更为长期的任务

    arXiv:2402.17553v1 Announce Type: new  Abstract: For decades, human-computer interaction has fundamentally been manual. Even today, almost all productive work done on the computer necessitates human input at every step. Autonomous virtual agents represent an exciting step in automating many of these menial tasks. Virtual agents would empower users with limited technical proficiency to harness the full possibilities of computer systems. They could also enable the efficient streamlining of numerous computer tasks, ranging from calendar management to complex travel bookings, with minimal human intervention. In this paper, we introduce OmniACT, the first-of-a-kind dataset and benchmark for assessing an agent's capability to generate executable programs to accomplish computer tasks. Our scope extends beyond traditional web automation, covering a diverse range of desktop applications. The dataset consists of fundamental tasks such as "Play the next song", as well as longer horizon tasks such
    
[^3]: 评估大型语言模型利用亚斯伯格综合征筛选测试理解隐喻和讽刺的能力

    Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome. (arXiv:2309.10744v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10744](http://arxiv.org/abs/2309.10744)

    该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。

    

    隐喻和讽刺是我们高度进化的社交沟通技巧的珍贵成果。然而，亚斯伯格综合征的儿童众所周知在理解讽刺方面存在困难，即使他们具有足够理解隐喻的口语智商水平。鉴于此，已经使用了一个评分测试来评估理解隐喻和讽刺的能力，以区分亚斯伯格综合征和其他表现相似外部行为的症状（例如注意力缺陷/多动障碍）。本研究使用标准化测试来研究最近大型语言模型（LLMs）理解人类微妙交流的能力。结果显示，随着模型参数数量的增加，它们理解隐喻的能力得到了改善，但并没有观察到对讽刺理解的改进。这意味着有必要采取其他方法来使LLMs具备理解讽刺的能力，这已与亚斯伯格综合征相关。

    Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills. However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors. Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication. The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been asso
    
[^4]: 广告的长期记忆性研究

    Long-Term Memorability On Advertisements. (arXiv:2309.00378v1 [cs.CL])

    [http://arxiv.org/abs/2309.00378](http://arxiv.org/abs/2309.00378)

    本研究是首个大规模的记忆性研究，发现广告的长期记忆性对于市场营销非常重要，但在机器学习文献中一直缺乏相关研究。通过分析大量参与者和广告，我们得出了关于什么使广告记忆深刻的有趣见解。

    

    市场营销人员花费数十亿美元在广告上，但是投入到广告上的金钱能起多大作用呢？当顾客在购买时无法辨认出他们看过的品牌的话，花在广告上的钱基本上就被浪费了。尽管在营销中很重要，但迄今为止，在机器学习的文献中还没有关于广告记忆力的研究。大多数研究都是对特定内容类型（如物体和动作视频）进行短期回忆（<5分钟）的研究。另一方面，广告行业只关心长期记忆（几个小时或更长时间），而且广告几乎总是高度多模式化，通过不同的形式（文本、图像和视频）来讲故事。基于这一动机，我们进行了首个大规模记忆性研究，共有1203名参与者和2205个广告涵盖了276个品牌。在不同参与者子群体和广告类型上进行统计测试，我们发现了许多有关什么使广告难忘的有趣见解-无论是内容还是

    Marketers spend billions of dollars on advertisements but to what end? At the purchase time, if customers cannot recognize a brand for which they saw an ad, the money spent on the ad is essentially wasted. Despite its importance in marketing, until now, there has been no study on the memorability of ads in the ML literature. Most studies have been conducted on short-term recall (<5 mins) on specific content types like object and action videos. On the other hand, the advertising industry only cares about long-term memorability (a few hours or longer), and advertisements are almost always highly multimodal, depicting a story through its different modalities (text, images, and videos). With this motivation, we conduct the first large scale memorability study consisting of 1203 participants and 2205 ads covering 276 brands. Running statistical tests over different participant subpopulations and ad-types, we find many interesting insights into what makes an ad memorable - both content and h
    

