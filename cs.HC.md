# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots](https://arxiv.org/abs/2311.15327) | FRAC-Q-Learning是一种专为社交机器人设计，能避免用户厌烦的强化学习方法，比传统算法在兴趣和厌烦程度上表现更好，有助于开发不会让用户感到无聊的社交机器人。 |
| [^2] | [Decision Theoretic Foundations for Experiments Evaluating Human Decisions.](http://arxiv.org/abs/2401.15106) | 该论文通过综合统计决策理论和信息经济学，提出了决策问题的广泛适用定义。为了将人类决策的下降归咎于偏见形式，实验必须向参与者提供足够的信息来识别规范决策。然而，根据作者对AI辅助决策的研究的评估，只有17%的研究提供了足够的信息来描述参与者的行为偏离了良好的决策。 |

# 详细

[^1]: FRAC-Q-Learning: 一种具有避免厌烦过程的社交机器人强化学习方法

    FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots

    [https://arxiv.org/abs/2311.15327](https://arxiv.org/abs/2311.15327)

    FRAC-Q-Learning是一种专为社交机器人设计，能避免用户厌烦的强化学习方法，比传统算法在兴趣和厌烦程度上表现更好，有助于开发不会让用户感到无聊的社交机器人。

    

    强化学习算法经常被应用于社交机器人。然而，大多数强化学习算法并未针对社交机器人进行优化，因此可能会让用户感到无聊。我们提出了一种专为社交机器人设计的新强化学习方法，FRAC-Q-Learning，可以避免用户感到无聊。该算法除了随机化和分类过程外，还包括一个遗忘过程。本研究通过与传统Q-Learning的比较评估了FRAC-Q-Learning的兴趣和厌烦程度分数。FRAC-Q-Learning显示出明显更高的兴趣分数趋势，并且相较于传统Q-Learning更难让用户感到无聊。因此，FRAC-Q-Learning有助于开发不会让用户感到无聊的社交机器人。该算法还可以在基于Web的通信和教育中找到应用。

    arXiv:2311.15327v3 Announce Type: replace-cross  Abstract: The reinforcement learning algorithms have often been applied to social robots. However, most reinforcement learning algorithms were not optimized for the use of social robots, and consequently they may bore users. We proposed a new reinforcement learning method specialized for the social robot, the FRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists of a forgetting process in addition to randomizing and categorizing processes. This study evaluated interest and boredom hardness scores of the FRAC-Q-learning by a comparison with the traditional Q-learning. The FRAC-Q-learning showed significantly higher trend of interest score, and indicated significantly harder to bore users compared to the traditional Q-learning. Therefore, the FRAC-Q-learning can contribute to develop a social robot that will not bore users. The proposed algorithm can also find applications in Web-based communication and educational 
    
[^2]: 决策理论基础对评估人类决策的实验的影响

    Decision Theoretic Foundations for Experiments Evaluating Human Decisions. (arXiv:2401.15106v1 [cs.HC])

    [http://arxiv.org/abs/2401.15106](http://arxiv.org/abs/2401.15106)

    该论文通过综合统计决策理论和信息经济学，提出了决策问题的广泛适用定义。为了将人类决策的下降归咎于偏见形式，实验必须向参与者提供足够的信息来识别规范决策。然而，根据作者对AI辅助决策的研究的评估，只有17%的研究提供了足够的信息来描述参与者的行为偏离了良好的决策。

    

    信息展示的决策是可解释AI、人工智能与人类的合作以及数据可视化等领域研究的重点。然而，决策问题的定义以及实验必须具备的条件以得出人类决策存在缺陷的结论仍然存在争议。我们提出了一个广泛适用的决策问题定义，该定义是从统计决策理论和信息经济学中综合提炼而来的。我们认为，要将人类绩效下降归咎于某种偏见形式，实验必须向参与者提供足够的信息，以便合理的代理能够识别规范决策。我们评估了最近有关AI辅助决策的文献中对决策制定进行的评估在多大程度上达到了这一标准。我们发现，只有35项声称确定了有偏差行为的研究中的6项（17%）向参与者提供了足够信息来描述其行为偏离良好决策

    Decision-making with information displays is a key focus of research in areas like explainable AI, human-AI teaming, and data visualization. However, what constitutes a decision problem, and what is required for an experiment to be capable of concluding that human decisions are flawed in some way, remain open to speculation. We present a widely applicable definition of a decision problem synthesized from statistical decision theory and information economics. We argue that to attribute loss in human performance to forms of bias, an experiment must provide participants with the information that a rational agent would need to identify the normative decision. We evaluate the extent to which recent evaluations of decision-making from the literature on AI-assisted decisions achieve this criteria. We find that only 6 (17\%) of 35 studies that claim to identify biased behavior present participants with sufficient information to characterize their behavior as deviating from good decision-making
    

