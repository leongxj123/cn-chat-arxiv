# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Driving Towards Inclusion: Revisiting In-Vehicle Interaction in Autonomous Vehicles.](http://arxiv.org/abs/2401.14571) | 本文综述了自动驾驶车辆中车内人机交互的现状和新兴技术，并提出了以用户为中心的包容性HCI设计原则，旨在增强乘客体验。 |
| [^2] | [On the Effect of Contextual Information on Human Delegation Behavior in Human-AI collaboration.](http://arxiv.org/abs/2401.04729) | 本研究探讨了在人工智能协作中提供上下文信息对人类委托行为的影响，发现提供上下文信息显著提高了人工智能与人类团队的表现，并且委托行为在不同上下文信息下发生显著变化。这项研究推进了对人工智能委托中人工智能与人类互动的理解，并为设计更有效的协作系统提供了见解。 |
| [^3] | [LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs.](http://arxiv.org/abs/2307.10168) | 本文研究探索了LLMs是否可以复制更复杂的众包流水线，并发现现代LLMs在模拟人类计算算法中的能力上有一定的成功，但受多种因素影响。文章强调了为LLMs提供人类面向的安全保障的重要性，并讨论了训练人类和LLMs互补技能的潜力。 |

# 详细

[^1]: 向包容性驱动：重新审视自动驾驶车辆中的车内交互

    Driving Towards Inclusion: Revisiting In-Vehicle Interaction in Autonomous Vehicles. (arXiv:2401.14571v1 [cs.HC])

    [http://arxiv.org/abs/2401.14571](http://arxiv.org/abs/2401.14571)

    本文综述了自动驾驶车辆中车内人机交互的现状和新兴技术，并提出了以用户为中心的包容性HCI设计原则，旨在增强乘客体验。

    

    本文综述了目前自动驾驶车辆中车内人机交互（HCI）的现状，特别关注包容性和可访问性。本研究旨在考察自动驾驶车辆中包容性HCI的以用户为中心的设计原则，评估现有HCI系统，并确定可能增强乘客体验的新兴技术。本文首先概述了自动驾驶车辆技术的现状，然后对这一背景下HCI的重要性进行了分析。接下来，本文综述了包容性HCI设计原则的现有文献，并评估了当前自动驾驶车辆中HCI系统的有效性。本文还确定了可能增强乘客体验的新兴技术，如语音激活界面、触觉反馈系统和增强现实显示。最后，本文总结了研究的重要发现，并讨论了未来的研究方向。

    This paper presents a comprehensive literature review of the current state of in-vehicle human-computer interaction (HCI) in the context of self-driving vehicles, with a specific focus on inclusion and accessibility. This study's aim is to examine the user-centered design principles for inclusive HCI in self-driving vehicles, evaluate existing HCI systems, and identify emerging technologies that have the potential to enhance the passenger experience. The paper begins by providing an overview of the current state of self-driving vehicle technology, followed by an examination of the importance of HCI in this context. Next, the paper reviews the existing literature on inclusive HCI design principles and evaluates the effectiveness of current HCI systems in self-driving vehicles. The paper also identifies emerging technologies that have the potential to enhance the passenger experience, such as voice-activated interfaces, haptic feedback systems, and augmented reality displays. Finally, th
    
[^2]: 关于上下文信息对人类在人工智能协作中的委托行为的影响

    On the Effect of Contextual Information on Human Delegation Behavior in Human-AI collaboration. (arXiv:2401.04729v1 [cs.HC])

    [http://arxiv.org/abs/2401.04729](http://arxiv.org/abs/2401.04729)

    本研究探讨了在人工智能协作中提供上下文信息对人类委托行为的影响，发现提供上下文信息显著提高了人工智能与人类团队的表现，并且委托行为在不同上下文信息下发生显著变化。这项研究推进了对人工智能委托中人工智能与人类互动的理解，并为设计更有效的协作系统提供了见解。

    

    人工智能的不断增强能力为人工智能与人类的协作带来了新的可能性。利用现有的互补能力，让人们将个别实例委托给人工智能是一种有前景的方法。然而，使人们有效地委托实例需要他们评估自己和人工智能在给定任务的背景下的能力。在这项工作中，我们探讨了在人类决定将实例委托给人工智能时提供上下文信息的效果。我们发现，提供上下文信息显著提高了人工智能与人类团队的表现。此外，我们还表明，当参与者接收到不同类型的上下文信息时，委托行为会发生显著变化。总体而言，这项研究推进了人工智能委托中人工智能与人类互动的理解，并为设计更有效的协作系统提供了可行的见解。

    The constantly increasing capabilities of artificial intelligence (AI) open new possibilities for human-AI collaboration. One promising approach to leverage existing complementary capabilities is allowing humans to delegate individual instances to the AI. However, enabling humans to delegate instances effectively requires them to assess both their own and the AI's capabilities in the context of the given task. In this work, we explore the effects of providing contextual information on human decisions to delegate instances to an AI. We find that providing participants with contextual information significantly improves the human-AI team performance. Additionally, we show that the delegation behavior changes significantly when participants receive varying types of contextual information. Overall, this research advances the understanding of human-AI interaction in human delegation and provides actionable insights for designing more effective collaborative systems.
    
[^3]: LLM作为人-计算算法中的工作者？用LLM复制众包流水线。

    LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs. (arXiv:2307.10168v1 [cs.CL])

    [http://arxiv.org/abs/2307.10168](http://arxiv.org/abs/2307.10168)

    本文研究探索了LLMs是否可以复制更复杂的众包流水线，并发现现代LLMs在模拟人类计算算法中的能力上有一定的成功，但受多种因素影响。文章强调了为LLMs提供人类面向的安全保障的重要性，并讨论了训练人类和LLMs互补技能的潜力。

    

    LLM已经显示出在众包任务中复制人类行为的潜力，而这些任务以前被认为只有人类才能完成。然而，目前的研究主要集中在简单的原子任务上。我们探索LLM是否可以复制更复杂的众包流水线。我们发现现代LLM可以模拟某些众包工作者在这些“人类计算算法”中的能力，但成功的程度是可变的，并受到请求者对LLM能力的理解、子任务所需的特定技能以及执行这些子任务的最佳交互方式的影响。我们反思了人类和LLM对指示的不同敏感性，强调为LLM提供面向人类的安全保障的重要性，并讨论了训练具有互补技能的人类和LLM的潜力。关键是，我们展示了复制众包流水线提供了一个有价值的平台来研究LLM在不同任务上的相对优势（通过交叉验证

    LLMs have shown promise in replicating human-like behavior in crowdsourcing tasks that were previously thought to be exclusive to human abilities. However, current efforts focus mainly on simple atomic tasks. We explore whether LLMs can replicate more complex crowdsourcing pipelines. We find that modern LLMs can simulate some of crowdworkers' abilities in these "human computation algorithms," but the level of success is variable and influenced by requesters' understanding of LLM capabilities, the specific skills required for sub-tasks, and the optimal interaction modality for performing these sub-tasks. We reflect on human and LLMs' different sensitivities to instructions, stress the importance of enabling human-facing safeguards for LLMs, and discuss the potential of training humans and LLMs with complementary skill sets. Crucially, we show that replicating crowdsourcing pipelines offers a valuable platform to investigate (1) the relative strengths of LLMs on different tasks (by cross
    

