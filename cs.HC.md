# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception.](http://arxiv.org/abs/2310.13712) | 本研究探索了四种教学指导策略对学习者在使用LLM时的表现和感知效果，发现直接LLM答案提高了表现，而改进学生解决方案则增加了对LLM的信任度。同时，结构化指导也减少了随机查询和学生复制粘贴问题的现象。 |
| [^2] | [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality.](http://arxiv.org/abs/2305.00050) | 大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。 |

# 详细

[^1]: 学习者使用LLM时指导和交互策略对学习者的表现和感知的影响

    Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception. (arXiv:2310.13712v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2310.13712](http://arxiv.org/abs/2310.13712)

    本研究探索了四种教学指导策略对学习者在使用LLM时的表现和感知效果，发现直接LLM答案提高了表现，而改进学生解决方案则增加了对LLM的信任度。同时，结构化指导也减少了随机查询和学生复制粘贴问题的现象。

    

    面对不断增长的教室规模和教师资源有限的问题，个性化的基于聊天机器人的教学助手可以发挥关键作用。大型语言模型（LLMs）提供了有希望的途径，越来越多的研究探索它们在教育中的实用性。然而，挑战不仅在于确定LLMs的有效性，而且在于识别学习者与这些模型之间的互动细微差别，这会影响学习者的参与和成果。我们在一个本科计算机科学课堂（N=145）和Prolific上进行了一项形成性研究（N=356），以探索四种教学指导策略对学习者在LLMs上的表现、自信心和信任度的影响。直接的LLM答案稍微提高了表现，而改进学生的解决方案增加了信任度。结构化指导减少了随机查询和学生将作业问题复制粘贴给LLM的情况。我们的工作凸显了t

    Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role t
    
[^2]: 因果推理与大型语言模型：开启因果研究的新篇章

    Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])

    [http://arxiv.org/abs/2305.00050](http://arxiv.org/abs/2305.00050)

    大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。

    

    大型语言模型的因果能力备受争议，并且对将其应用于医学、科学、法律和政策等具有社会影响力的领域具有重要意义。我们进一步探讨了LLMs及其因果推理的区别，以及潜在的建构和测量效度威胁。基于GPT-3.5和4的算法在多个因果基准测试上取得了新的最高准确率。与此同时，LLMs展示了难以预测的失败模式，我们提供了一些技术来解释它们的鲁棒性。

    The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
    

