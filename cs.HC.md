# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Extended Reality for Enhanced Human-Robot Collaboration: a Human-in-the-Loop Approach](https://arxiv.org/abs/2403.14597) | 本文提出了一种自主的、基于机器学习的操作器框架，将人在回路原则和扩展现实结合起来，以促进人与机器人之间直观的沟通和编程。 |
| [^2] | [Can Large Language Model Agents Simulate Human Trust Behaviors?](https://arxiv.org/abs/2402.04559) | 大语言模型代理能够模拟人类的信任行为，表现出在信任游戏中的信任行为，并且与人类行为具有高度一致性，但存在一些偏见和对代理与人类的差异。 |
| [^3] | [Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in Relationship Dissolution.](http://arxiv.org/abs/2401.09695) | 这项研究探讨了AI在恋爱解体过程中的作用。研究发现，当前技术在信息收集、社群支持和促进沟通方面发挥着重要作用。参与者预计AI可以满足不同阶段的需求，帮助解体恋情。 |
| [^4] | [Designing User-Centric Behavioral Interventions to Prevent Dysglycemia with Novel Counterfactual Explanations.](http://arxiv.org/abs/2310.01684) | 这项研究设计了一种以用户为中心的行为干预方法，通过提供新颖的反事实解释来预防血糖异常，有望对社会产生重要影响。 |

# 详细

[^1]: 扩展现实用于增强人机协作：一种人在回路中的方法

    Extended Reality for Enhanced Human-Robot Collaboration: a Human-in-the-Loop Approach

    [https://arxiv.org/abs/2403.14597](https://arxiv.org/abs/2403.14597)

    本文提出了一种自主的、基于机器学习的操作器框架，将人在回路原则和扩展现实结合起来，以促进人与机器人之间直观的沟通和编程。

    

    自动化的崛起为制造过程的高效率提供了机会，但往往牺牲了及时响应不断变化的市场需求和满足定制需求所需的灵活性。人机协作试图通过将机器的力量和精度与人类的机智和感知理解结合起来，以解决这些挑战。本文概念化并提出了一个实现框架，用于将人在回路原则与扩展现实（XR）相结合，以便于人与机器人之间进行直观沟通和编程。此外，这个概念框架预见到了人直接参与机器人学习过程，从而提高了适应性和任务泛化能力。本文重点介绍了支持所提出框架的关键技术，强调了实现这一框架的可行性。

    arXiv:2403.14597v1 Announce Type: cross  Abstract: The rise of automation has provided an opportunity to achieve higher efficiency in manufacturing processes, yet it often compromises the flexibility required to promptly respond to evolving market needs and meet the demand for customization. Human-robot collaboration attempts to tackle these challenges by combining the strength and precision of machines with human ingenuity and perceptual understanding. In this paper, we conceptualize and propose an implementation framework for an autonomous, machine learning-based manipulator that incorporates human-in-the-loop principles and leverages Extended Reality (XR) to facilitate intuitive communication and programming between humans and robots. Furthermore, the conceptual framework foresees human involvement directly in the robot learning process, resulting in higher adaptability and task generalization. The paper highlights key technologies enabling the proposed framework, emphasizing the im
    
[^2]: 大语言模型代理能够模拟人类的信任行为吗？

    Can Large Language Model Agents Simulate Human Trust Behaviors?

    [https://arxiv.org/abs/2402.04559](https://arxiv.org/abs/2402.04559)

    大语言模型代理能够模拟人类的信任行为，表现出在信任游戏中的信任行为，并且与人类行为具有高度一致性，但存在一些偏见和对代理与人类的差异。

    

    大语言模型（LLM）代理已经越来越多地被采用作为模拟工具，用于模拟人类在社会科学等领域中的行为。然而，一个基本的问题仍然存在：LLM代理是否真的能够模拟人类行为？在本文中，我们专注于人类互动中最关键的行为之一，信任，旨在调查LLM代理是否能够模拟人类的信任行为。我们首先发现，在被行为经济学广泛接受的信任游戏框架下，LLM代理通常表现出信任行为，称为代理信任。然后，我们发现LLM代理在信任行为方面与人类具有较高的行为一致性，表明使用LLM代理模拟人类的信任行为是可行的。此外，我们还探索了代理信任中的偏见以及代理信任在对代理和人类之间的差异方面的内在特性。我们还探讨了包括高级推理策略在内的条件下代理信任的内在特性。

    Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in applications such as social science. However, one fundamental question remains: can LLM agents really simulate human behaviors? In this paper, we focus on one of the most critical behaviors in human interactions, trust, and aim to investigate whether or not LLM agents can simulate human trust behaviors. We first find that LLM agents generally exhibit trust behaviors, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, indicating the feasibility to simulate human trust behaviors with LLM agents. In addition, we probe into the biases in agent trust and the differences in agent trust towards agents and humans. We also explore the intrinsic properties of agent trust under conditions including advanced reasoning strate
    
[^3]: 在结束恋情过程中，ChatGPT是否应该替你写分手短信？探索AI在恋爱解体中的角色。

    Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in Relationship Dissolution. (arXiv:2401.09695v1 [cs.HC])

    [http://arxiv.org/abs/2401.09695](http://arxiv.org/abs/2401.09695)

    这项研究探讨了AI在恋爱解体过程中的作用。研究发现，当前技术在信息收集、社群支持和促进沟通方面发挥着重要作用。参与者预计AI可以满足不同阶段的需求，帮助解体恋情。

    

    恋爱关系对我们的幸福和幸福感至关重要。恋爱解体是恋爱生命周期的最后阶段，也是个人生活中最具压力的事件之一，可能对人们产生深远而持久的影响。随着通过计算机介质传达的解体过程越来越受到支持，以及AI介入的传播方式的可能未来影响，我们进行了一项半结构化访谈研究，共有21名参与者。我们的研究旨在了解：1）技术在解体过程中的当前角色，2）个人在过程中的需求和支持，以及3）AI如何满足这些需求。我们的研究显示，人们在结束恋情的不同阶段有不同的需求。目前，技术被用于信息收集和社群支持，在促成分手、使鬼魂式分手和拉黑成为可能，以及促进沟通。参与者预计AI可以帮助实现感知技巧。

    Relationships are essential to our happiness and wellbeing. The dissolution of a relationship, the final stage of relationship's lifecycle and one of the most stressful events in an individual's life, can have profound and long-lasting impacts on people. With the breakup process increasingly facilitated by computer-mediated communication (CMC), and the likely future influence of AI-mediated communication (AIMC) tools, we conducted a semi-structured interview study with 21 participants. We aim to understand: 1) the current role of technology in the breakup process, 2) the needs and support individuals have during the process, and 3) how AI might address these needs. Our research shows that people have distinct needs at various stages of ending a relationship. Presently, technology is used for information gathering and community support, acting as a catalyst for breakups, enabling ghosting and blocking, and facilitating communication. Participants anticipate that AI could aid in sense-ma
    
[^4]: 设计以用户为中心的行为干预来预防血糖异常，并提供新颖的反事实解释

    Designing User-Centric Behavioral Interventions to Prevent Dysglycemia with Novel Counterfactual Explanations. (arXiv:2310.01684v1 [cs.AI])

    [http://arxiv.org/abs/2310.01684](http://arxiv.org/abs/2310.01684)

    这项研究设计了一种以用户为中心的行为干预方法，通过提供新颖的反事实解释来预防血糖异常，有望对社会产生重要影响。

    

    通过生活方式行为维持正常血糖水平对于保持健康和预防疾病至关重要。频繁接触血糖异常（即高血糖和低血糖等异常事件）会导致慢性并发症，包括糖尿病、肾脏疾病及需透析治疗、心肌梗死、中风、截肢和死亡。因此，能够预测血糖异常并向用户提供行动反馈以改变饮食、运动和药物治疗来预防异常血糖事件的工具可能具有重要的社会影响。反事实解释可以通过生成类似于原始输入但导致不同预测结果的假设实例，提供模型为何对特定预测的见解。因此，反事实解释可以被视为设计AI驱动的健康干预来预防不良健康结果（如血糖异常）的一种手段。在本文中，我们设计了GlyCoa...

    Maintaining normal blood glucose levels through lifestyle behaviors is central to maintaining health and preventing disease. Frequent exposure to dysglycemia (i.e., abnormal glucose events such as hyperlycemia and hypoglycemia) leads to chronic complications including diabetes, kidney disease and need for dialysis, myocardial infarction, stroke, amputation, and death. Therefore, a tool capable of predicting dysglycemia and offering users actionable feedback about how to make changes in their diet, exercise, and medication to prevent abnormal glycemic events could have significant societal impacts. Counterfactual explanations can provide insights into why a model made a particular prediction by generating hypothetical instances that are similar to the original input but lead to a different prediction outcome. Therefore, counterfactuals can be viewed as a means to design AI-driven health interventions to prevent adverse health outcomes such as dysglycemia. In this paper, we design GlyCoa
    

