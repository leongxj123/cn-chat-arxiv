# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems](https://arxiv.org/abs/2402.04955) | 这项研究比较了在知识密集型环境中基于LLM的认知助手和基于意图的系统，并发现基于LLM的认知助手在用户体验、任务完成率、可用性和个人效能方面表现更好。 |

# 详细

[^1]: 在知识密集型环境中的聊天机器人：比较意图和基于LLM的系统

    Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems

    [https://arxiv.org/abs/2402.04955](https://arxiv.org/abs/2402.04955)

    这项研究比较了在知识密集型环境中基于LLM的认知助手和基于意图的系统，并发现基于LLM的认知助手在用户体验、任务完成率、可用性和个人效能方面表现更好。

    

    认知助手是在知识密集型任务中为人类工作者提供上下文感知支持的聊天机器人。传统上，认知助手以特定方式回应预定义的用户意图和对话模式。然而，这种刚性对自然语言的多样性处理不好。最近自然语言处理的进展，如GPT-4、Llama2和Gemini等大型语言模型（LLM），可能使认知助手能够以更灵活、更像人类的方式进行对话。然而，这种额外的自由度可能会产生意想不到的后果，特别是在准确性至关重要的知识密集型环境中。为了评估在这些环境中使用LLM的潜力，我们进行了一个用户研究，比较了基于LLM的认知助手和基于意图的系统在交互效率、用户体验、工作量和可用性方面的差异。研究结果显示，基于LLM的认知助手在用户体验、任务完成率、可用性和个人效能方面表现更好。

    Cognitive assistants (CA) are chatbots that provide context-aware support to human workers in knowledge-intensive tasks. Traditionally, cognitive assistants respond in specific ways to predefined user intents and conversation patterns. However, this rigidness does not handle the diversity of natural language well. Recent advances in natural language processing (NLP), powering large language models (LLM) such as GPT-4, Llama2, and Gemini, could enable CAs to converse in a more flexible, human-like manner. However, the additional degrees of freedom may have unforeseen consequences, especially in knowledge-intensive contexts where accuracy is crucial. As a preliminary step to assessing the potential of using LLMs in these contexts, we conducted a user study comparing an LLM-based CA to an intent-based system regarding interaction efficiency, user experience, workload, and usability. This revealed that LLM-based CAs exhibited better user experience, task completion rate, usability, and per
    

