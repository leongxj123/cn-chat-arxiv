<rss version="2.0"><channel><title>Chat Arxiv cs.DB</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DB</description><item><title>LLM&#21551;&#29992;&#20102;&#22522;&#20110;&#31574;&#30053;&#30340;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#65292;&#25670;&#33073;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#20026;&#26597;&#35810;&#20248;&#21270;&#24102;&#26469;&#20840;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.13597</link><description>&lt;p&gt;
&#19981;&#20877;&#26377;&#20248;&#21270;&#35268;&#21017;: &#22522;&#20110;LLM&#30340;&#22522;&#20110;&#31574;&#30053;&#30340;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#65288;&#29256;&#26412;1&#65289;
&lt;/p&gt;
&lt;p&gt;
No more optimization rules: LLM-enabled policy-based multi-modal query optimizer (version 1)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13597
&lt;/p&gt;
&lt;p&gt;
LLM&#21551;&#29992;&#20102;&#22522;&#20110;&#31574;&#30053;&#30340;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#65292;&#25670;&#33073;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#20026;&#26597;&#35810;&#20248;&#21270;&#24102;&#26469;&#20840;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#26631;&#24535;&#30528;&#19968;&#20010;&#37325;&#35201;&#26102;&#21051;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#30740;&#31350;&#20102;LLM&#22312;&#26597;&#35810;&#35268;&#21010;&#20013;&#30340;&#33021;&#21147;&#65292;&#21253;&#25324;&#21333;&#27169;&#21644;&#22810;&#27169;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;LLM&#30340;&#26597;&#35810;&#20248;&#21270;&#33021;&#21147;&#36824;&#27809;&#26377;&#30456;&#20851;&#30740;&#31350;&#12290;&#20316;&#20026;&#26174;&#33879;&#24433;&#21709;&#26597;&#35810;&#35745;&#21010;&#25191;&#34892;&#24615;&#33021;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#19981;&#24212;&#38169;&#36807;&#36825;&#31181;&#20998;&#26512;&#21644;&#23581;&#35797;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29616;&#26377;&#30340;&#26597;&#35810;&#20248;&#21270;&#22120;&#36890;&#24120;&#26159;&#22522;&#20110;&#35268;&#21017;&#25110;&#22522;&#20110;&#35268;&#21017;+&#22522;&#20110;&#25104;&#26412;&#30340;&#65292;&#21363;&#23427;&#20204;&#20381;&#36182;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#35268;&#21017;&#26469;&#23436;&#25104;&#26597;&#35810;&#35745;&#21010;&#37325;&#20889;/&#36716;&#25442;&#12290;&#37492;&#20110;&#29616;&#20195;&#20248;&#21270;&#22120;&#21253;&#25324;&#25968;&#30334;&#33267;&#25968;&#21315;&#26465;&#35268;&#21017;&#65292;&#25353;&#29031;&#31867;&#20284;&#26041;&#24335;&#35774;&#35745;&#19968;&#20010;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#23558;&#32791;&#36153;&#22823;&#37327;&#26102;&#38388;&#65292;&#22240;&#20026;&#25105;&#20204;&#23558;&#19981;&#24471;&#19981;&#21015;&#20030;&#23613;&#21487;&#33021;&#22810;&#30340;&#22810;&#27169;&#20248;&#21270;&#35268;&#21017;&#65292;&#32780;&#36825;&#24182;&#27809;&#26377;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13597v1 Announce Type: cross  Abstract: Large language model (LLM) has marked a pivotal moment in the field of machine learning and deep learning. Recently its capability for query planning has been investigated, including both single-modal and multi-modal queries. However, there is no work on the query optimization capability of LLM. As a critical (or could even be the most important) step that significantly impacts the execution performance of the query plan, such analysis and attempts should not be missed. From another aspect, existing query optimizers are usually rule-based or rule-based + cost-based, i.e., they are dependent on manually created rules to complete the query plan rewrite/transformation. Given the fact that modern optimizers include hundreds to thousands of rules, designing a multi-modal query optimizer following a similar way is significantly time-consuming since we will have to enumerate as many multi-modal optimization rules as possible, which has not be
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01763</link><description>&lt;p&gt;
&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36935;&#19978;&#21521;&#37327;&#25968;&#25454;&#24211;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
When Large Language Models Meet Vector Databases: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#22312;&#20154;&#31867;&#25991;&#23383;&#22788;&#29702;&#21644;&#29983;&#25104;&#26041;&#38754;&#24320;&#21551;&#20102;&#26032;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#30340;&#26174;&#33879;&#22686;&#38271;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30528;&#21253;&#25324;&#24187;&#35273;&#12289;&#20559;&#35265;&#12289;&#23454;&#26102;&#30693;&#35782;&#26356;&#26032;&#20197;&#21450;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#23454;&#26045;&#21644;&#32500;&#25252;&#30340;&#39640;&#25104;&#26412;&#31561;&#37325;&#35201;&#25361;&#25112;&#12290;&#32780;&#21478;&#19968;&#31181;&#26085;&#30410;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#21521;&#37327;&#25968;&#25454;&#24211;&#21017;&#20026;&#36825;&#20123;&#25361;&#25112;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20123;&#25968;&#25454;&#24211;&#25797;&#38271;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#19988;&#23545;&#20110;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#21644;&#35821;&#20041;&#25628;&#32034;&#31561;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25972;&#21512;&#65292;&#23427;&#20204;&#26174;&#33879;&#22686;&#24378;&#20102;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#26356;&#26377;&#25928;&#22320;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#36827;&#34892;&#20102;&#28145;&#20837;&#32780;&#29420;&#29305;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent burst in Large Language Models has opened new frontiers in human-like text processing and generation. However, alongside their remarkable growth, Large Language Models have encountered critical challenges including issues of hallucination, bias, real-time knowledge updates, and the high costs of implementation and maintenance in commercial settings. Vector Databases, another increasingly popular tool, offer potential solutions to these challenges. These databases are adept at handling high-dimensional data and are crucial for tasks such as efficient information retrieval and semantic search. By integrating with Large Language Models, they significantly enhance AI systems' ability to manage and utilize diverse data more effectively. This survey paper provides an in-depth and unique analysis of the intersection between Large Language Models and Vector Databases.
&lt;/p&gt;</description></item></channel></rss>