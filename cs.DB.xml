<rss version="2.0"><channel><title>Chat Arxiv cs.DB</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DB</description><item><title>$R^3$-NL2GQL&#26159;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;Foundation Models&#36827;&#34892;&#37325;&#26032;&#25490;&#21517;&#12289;&#37325;&#20889;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#20943;&#36731;&#24187;&#35273;&#65292;&#35299;&#20915;&#20102;NL2GQL&#20219;&#21153;&#20013;GQL&#29983;&#25104;&#33021;&#21147;&#21644;&#36328;&#27169;&#24335;&#36890;&#29992;&#33021;&#21147;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2311.01862</link><description>&lt;p&gt;
$R^3$-NL2GQL:&#19968;&#31181;&#29992;&#20110;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#20943;&#36731;&#24187;&#35273;&#30340;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
$R^3$-NL2GQL: A Hybrid Models Approach for for Accuracy Enhancing and Hallucinations Mitigation. (arXiv:2311.01862v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01862
&lt;/p&gt;
&lt;p&gt;
$R^3$-NL2GQL&#26159;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;Foundation Models&#36827;&#34892;&#37325;&#26032;&#25490;&#21517;&#12289;&#37325;&#20889;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#20943;&#36731;&#24187;&#35273;&#65292;&#35299;&#20915;&#20102;NL2GQL&#20219;&#21153;&#20013;GQL&#29983;&#25104;&#33021;&#21147;&#21644;&#36328;&#27169;&#24335;&#36890;&#29992;&#33021;&#21147;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#20351;&#29992;Foundation Models&#26500;&#24314;&#30340;NL2SQL&#20219;&#21153;&#21462;&#24471;&#20102;&#20196;&#20154;&#31216;&#36190;&#30340;&#32467;&#26524;&#65292;&#28982;&#32780;&#30452;&#25509;&#23558;&#20854;&#24212;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#21040;&#22270;&#26597;&#35810;&#35821;&#35328;&#65288;NL2GQL&#65289;&#20219;&#21153;&#38754;&#20020;&#25361;&#25112;&#65292;&#21407;&#22240;&#26159;GQL&#21644;SQL&#34920;&#36798;&#24335;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#19988;GQL&#23384;&#22312;&#22810;&#31181;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;NL2GQL&#20219;&#21153;&#20013;&#65292;&#26356;&#22823;&#30340;Foundation Models&#23637;&#31034;&#20102;&#20248;&#36234;&#30340;&#36328;&#27169;&#24335;&#36890;&#29992;&#33021;&#21147;&#65292;&#32780;&#36739;&#23567;&#30340;Foundation Models&#21017;&#36890;&#36807;&#24494;&#35843;&#38590;&#20197;&#25552;&#39640;&#20854;GQL&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#24494;&#35843;&#21518;&#65292;&#36739;&#23567;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24847;&#22270;&#29702;&#35299;&#21644;&#26356;&#39640;&#30340;&#35821;&#27861;&#20934;&#30830;&#24615;&#12290;&#19982;&#22522;&#20110;&#35268;&#21017;&#21644;&#27133;&#22635;&#20805;&#25216;&#26415;&#19981;&#21516;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;R3-NL2GQL&#65292;&#35813;&#26041;&#27861;&#23558;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;Foundation Models&#29992;&#20316;&#37325;&#26032;&#25490;&#21517;&#12289;&#37325;&#20889;&#21644;&#32454;&#21270;&#22120;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#36739;&#23567;&#27169;&#22411;&#30340;&#29702;&#35299;&#33021;&#21147;&#36827;&#34892;&#20449;&#24687;&#30340;&#37325;&#26032;&#25490;&#21517;&#21644;&#37325;&#20889;&#65292;&#24182;&#21033;&#29992;&#21331;&#36234;&#30340;&#36890;&#29992;&#21270;&#21644;&#29983;&#25104;&#33021;&#21147;&#36827;&#34892;&#32454;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
While current NL2SQL tasks constructed using Foundation Models have achieved commendable results, their direct application to Natural Language to Graph Query Language (NL2GQL) tasks poses challenges due to the significant differences between GQL and SQL expressions, as well as the numerous types of GQL. Our extensive experiments reveal that in NL2GQL tasks, larger Foundation Models demonstrate superior cross-schema generalization abilities, while smaller Foundation Models struggle to improve their GQL generation capabilities through fine-tuning. However, after fine-tuning, smaller models exhibit better intent comprehension and higher grammatical accuracy. Diverging from rule-based and slot-filling techniques, we introduce R3-NL2GQL, which employs both smaller and larger Foundation Models as reranker, rewriter and refiner. The approach harnesses the comprehension ability of smaller models for information reranker and rewriter, and the exceptional generalization and generation capabiliti
&lt;/p&gt;</description></item><item><title>Autumn&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;LSM-tree&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#30456;&#37051;&#20004;&#23618;&#20043;&#38388;&#30340;&#23481;&#37327;&#27604;&#26469;&#19981;&#26029;&#25552;&#39640;&#35835;&#24615;&#33021;&#65292;&#20351;&#24471;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#20174;&#20043;&#21069;&#26368;&#20248;&#30340;$O(logN)$&#22797;&#26434;&#24230;&#20248;&#21270;&#21040;&#20102;$O(\sqrt{logN})$&#12290;</title><link>http://arxiv.org/abs/2305.05074</link><description>&lt;p&gt;
Autumn&#65306;&#22522;&#20110;LSM-tree&#30340;&#21487;&#25193;&#23637;&#30340;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;
&lt;/p&gt;
&lt;p&gt;
Autumn: A Scalable Read Optimized LSM-tree based Key-Value Stores with Fast Point and Range Read Speed. (arXiv:2305.05074v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05074
&lt;/p&gt;
&lt;p&gt;
Autumn&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;LSM-tree&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#30456;&#37051;&#20004;&#23618;&#20043;&#38388;&#30340;&#23481;&#37327;&#27604;&#26469;&#19981;&#26029;&#25552;&#39640;&#35835;&#24615;&#33021;&#65292;&#20351;&#24471;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#20174;&#20043;&#21069;&#26368;&#20248;&#30340;$O(logN)$&#22797;&#26434;&#24230;&#20248;&#21270;&#21040;&#20102;$O(\sqrt{logN})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Log Structured Merge Trees (LSM-tree)&#30340;&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35768;&#22810;&#23384;&#20648;&#31995;&#32479;&#20013;&#65292;&#20197;&#25903;&#25345;&#26356;&#26032;&#12289;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#31561;&#21508;&#31181;&#25805;&#20316;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Autumn&#30340;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;&#22522;&#20110;LSM-tree&#30340;&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#65292;&#23427;&#20855;&#26377;&#26368;&#23569;&#30340;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#12290;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#30456;&#37051;&#20004;&#23618;&#20043;&#38388;&#30340;&#23481;&#37327;&#27604;&#26469;&#19981;&#26029;&#25552;&#39640;&#35835;&#24615;&#33021;&#65292;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#20174;&#20043;&#21069;&#26368;&#20248;&#30340;$O(logN)$&#22797;&#26434;&#24230;&#20248;&#21270;&#21040;&#20102;$O(\sqrt{logN})$&#65292;&#24182;&#24212;&#29992;&#20102;&#26032;&#30340;Garnering&#21512;&#24182;&#31574;&#30053;&#12290;Autumn&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;LSM-tree&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Log Structured Merge Trees (LSM-tree) based key-value stores are widely used in many storage systems to support a variety of operations such as updates, point reads, and range reads. Traditionally, LSM-tree's merge policy organizes data into multiple levels of exponentially increasing capacity to support high-speed writes. However, we contend that the traditional merge policies are not optimized for reads. In this work, we present Autumn, a scalable and read optimized LSM-tree based key-value stores with minimal point and range read cost. The key idea in improving the read performance is to dynamically adjust the capacity ratio between two adjacent levels as more data are stored. As a result, smaller levels gradually increase their capacities and merge more often. In particular, the point and range read cost improves from the previous best known $O(logN)$ complexity to $O(\sqrt{logN})$ in Autumn by applying the new novel Garnering merge policy. While Garnering merge policy optimize
&lt;/p&gt;</description></item></channel></rss>