<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#21551;&#31034;&#65288;Counterfactual Inception&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#21453;&#20107;&#23454;&#24605;&#24819;&#26893;&#20837;&#21040;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;LMMs&#65289;&#20013;&#65292;&#21487;&#20197;&#20943;&#36731;&#24187;&#35273;&#25928;&#24212;&#24182;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.13513</link><description>&lt;p&gt;
&#22914;&#26524;......&#20250;&#24590;&#26679;&#65311;&#65306;&#21453;&#20107;&#23454;&#21551;&#31034;&#22312;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#20013;&#20943;&#36731;&#24187;&#35273;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
What if...?: Counterfactual Inception to Mitigate Hallucination Effects in Large Multimodal Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#21551;&#31034;&#65288;Counterfactual Inception&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#21453;&#20107;&#23454;&#24605;&#24819;&#26893;&#20837;&#21040;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;LMMs&#65289;&#20013;&#65292;&#21487;&#20197;&#20943;&#36731;&#24187;&#35273;&#25928;&#24212;&#24182;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#25552;&#39640;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;LMMs&#65289;&#22312;&#22788;&#29702;&#24187;&#35273;&#25928;&#24212;&#26041;&#38754;&#21487;&#38752;&#24615;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#27169;&#22411;&#20250;&#29983;&#25104;&#19981;&#27491;&#30830;&#25110;&#26080;&#20851;&#30340;&#21709;&#24212;&#12290;&#27809;&#26377;&#39069;&#22806;&#30340;&#25351;&#23548;&#35843;&#25972;&#33539;&#24335;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#21551;&#31034;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31934;&#24515;&#36873;&#25321;&#30340;&#12289;&#19981;&#23545;&#40784;&#30340;&#21453;&#20107;&#23454;&#20851;&#38190;&#35789;&#23558;&#21453;&#20107;&#23454;&#24605;&#24819;&#26893;&#20837;&#21040;LMMs&#20013;&#12290;&#35813;&#26041;&#27861;&#26681;&#26893;&#20110;&#21453;&#20107;&#23454;&#24605;&#32500;&#27010;&#24565;&#65292;&#36825;&#26159;&#19968;&#31181;&#35748;&#30693;&#36807;&#31243;&#65292;&#20154;&#31867;&#22312;&#20854;&#20013;&#32771;&#34385;&#26367;&#20195;&#29616;&#23454;&#21644;&#32467;&#26524;&#12290;&#36890;&#36807;&#23558;&#36825;&#31181;&#31867;&#20284;&#20154;&#31867;&#30340;&#25512;&#29702;&#26426;&#21046;&#24212;&#29992;&#21040;LMMs&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20943;&#23569;&#24187;&#35273;&#25928;&#24212;&#24182;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21452;&#27169;&#24577;&#39564;&#35777;&#36807;&#31243;&#65288;DVP&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#20005;&#26684;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#36873;&#25321;&#35302;&#21457;LMMs&#20013;&#21453;&#20107;&#23454;&#24605;&#32500;&#30340;&#26368;&#20339;&#21453;&#20107;&#23454;&#20851;&#38190;&#35789;&#65292;&#21516;&#26102;&#32771;&#34385;&#35270;&#35273;&#21644;&#35821;&#35328;&#19978;&#19979;&#25991;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;LMMs&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13513v1 Announce Type: cross  Abstract: This paper presents a way of enhancing the reliability of Large Multimodal Models (LMMs) in addressing hallucination effects, where models generate incorrect or unrelated responses. Without additional instruction tuning paradigm, we introduce Counterfactual Inception, a novel method that implants counterfactual thoughts into LMMs using carefully chosen, misaligned counterfactual keywords. This method is grounded in the concept of counterfactual thinking, a cognitive process where humans consider alternative realities and outcomes. By applying this human-like reasoning mechanism to LMMs, we aim to reduce hallucination effects and improve the models' trustworthiness. We also propose Dual-modality Verification Process (DVP), a rigorous framework for selecting optimal counterfactual keywords to trigger counterfactual thinking into LMMs, concurrently considering visual and linguistic context. Our extensive experiments across various LMMs, i
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#65292;&#21487;&#20197;&#24110;&#21161;&#25913;&#36827;&#24189;&#40664;&#26816;&#27979;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#21462;&#28040;&#24189;&#40664;&#20803;&#32032;&#26469;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.00794</link><description>&lt;p&gt;
&#35748;&#30495;&#23545;&#24453;&#24189;&#40664;&#65306;&#21033;&#29992;&#19981;&#39118;&#36259;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#24189;&#40664;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00794
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#65292;&#21487;&#20197;&#24110;&#21161;&#25913;&#36827;&#24189;&#40664;&#26816;&#27979;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#21462;&#28040;&#24189;&#40664;&#20803;&#32032;&#26469;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24189;&#40664;&#26159;&#20154;&#31867;&#35748;&#30693;&#21644;&#20114;&#21160;&#30340;&#22522;&#26412;&#35201;&#32032;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#21462;&#24471;&#20102;&#36817;&#26399;&#36827;&#23637;&#65292;&#24189;&#40664;&#26816;&#27979;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#36825;&#26159;&#22240;&#20026;&#24189;&#40664;&#25991;&#26412;&#19982;&#31867;&#20284;&#38750;&#24189;&#40664;&#25991;&#26412;&#30340;&#25968;&#25454;&#38598;&#31232;&#32570;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#21542;&#36890;&#36807;&#32534;&#36753;&#25991;&#26412;&#29983;&#25104;&#29992;&#20110;&#24189;&#40664;&#26816;&#27979;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#29616;&#26377;&#20154;&#31867;&#25968;&#25454;&#38598;&#19978;&#23545;LLMs&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#23637;&#31034;&#24403;&#21069;LLMs&#22312;&#8220;&#21462;&#28040;&#39118;&#36259;&#8221;&#31505;&#35805;&#26041;&#38754;&#26174;&#31034;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#65292;&#36825;&#26159;&#30001;&#20154;&#31867;&#21028;&#26029;&#21644;&#24189;&#40664;&#26816;&#27979;&#30340;&#19979;&#28216;&#20219;&#21153;&#34913;&#37327;&#32780;&#24471;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#20010;&#28151;&#21512;&#32534;&#30721;&#30340;&#33521;&#35821;-&#21360;&#22320;&#35821;&#24189;&#40664;&#25968;&#25454;&#38598;&#65292;&#22312;&#37027;&#37324;&#25105;&#20204;&#21457;&#29616;GPT-4&#30340;&#21512;&#25104;&#25968;&#25454;&#34987;&#21452;&#35821;&#27880;&#37322;&#21592;&#39640;&#24230;&#35780;&#20215;&#65292;&#24182;&#20026;&#24189;&#40664;&#20998;&#31867;&#22120;&#25552;&#20379;&#20102;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#23545;&#25239;&#24615;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00794v1 Announce Type: cross  Abstract: Humor is a fundamental facet of human cognition and interaction. Yet, despite recent advances in natural language processing, humor detection remains a challenging task that is complicated by the scarcity of datasets that pair humorous texts with similar non-humorous counterparts. In our work, we investigate whether large language models (LLMs), can generate synthetic data for humor detection via editing texts. We benchmark LLMs on an existing human dataset and show that current LLMs display an impressive ability to `unfun' jokes, as judged by humans and as measured on the downstream task of humor detection. We extend our approach to a code-mixed English-Hindi humor dataset, where we find that GPT-4's synthetic data is highly rated by bilingual annotators and provides challenging adversarial examples for humor classifiers.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25581;&#31034;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;&#65292;&#25351;&#20986;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;LMs&#30340;&#25351;&#31034;&#36981;&#24490;&#33021;&#21147;&#36731;&#26494;&#22320;&#20174;&#25968;&#25454;&#23384;&#20648;&#20013;&#30452;&#25509;&#25552;&#21462;&#25991;&#26412;&#25968;&#25454;&#65292;&#24182;&#35774;&#35745;&#20102;&#25915;&#20987;&#23545;&#29983;&#20135;RAG&#27169;&#22411;GPTs&#36896;&#25104;&#25968;&#25454;&#23384;&#20648;&#27844;&#28431;&#12290;</title><link>https://arxiv.org/abs/2402.17840</link><description>&lt;p&gt;
&#36981;&#24490;&#25105;&#30340;&#25351;&#31034;&#24182;&#35828;&#20986;&#30495;&#30456;&#65306;&#26469;&#33258;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#30340;&#21487;&#25193;&#23637;&#25968;&#25454;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17840
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25581;&#31034;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;&#65292;&#25351;&#20986;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;LMs&#30340;&#25351;&#31034;&#36981;&#24490;&#33021;&#21147;&#36731;&#26494;&#22320;&#20174;&#25968;&#25454;&#23384;&#20648;&#20013;&#30452;&#25509;&#25552;&#21462;&#25991;&#26412;&#25968;&#25454;&#65292;&#24182;&#35774;&#35745;&#20102;&#25915;&#20987;&#23545;&#29983;&#20135;RAG&#27169;&#22411;GPTs&#36896;&#25104;&#25968;&#25454;&#23384;&#20648;&#27844;&#28431;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#36890;&#36807;&#22312;&#27979;&#35797;&#26102;&#23558;&#22806;&#37096;&#30693;&#35782;&#32435;&#20837;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#20174;&#32780;&#23454;&#29616;&#23450;&#21046;&#36866;&#24212;&#65292;&#25552;&#21319;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;Retrieval-In-Context RAG&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23545;&#20351;&#29992;&#25351;&#20196;&#35843;&#25972;&#30340;LMs&#26500;&#24314;&#30340;RAG&#31995;&#32479;&#36827;&#34892;&#25552;&#31034;&#27880;&#20837;&#26102;&#65292;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;LMs&#30340;&#25351;&#31034;&#36981;&#24490;&#33021;&#21147;&#36731;&#26494;&#22320;&#20174;&#25968;&#25454;&#23384;&#20648;&#20013;&#30452;&#25509;&#25552;&#21462;&#25991;&#26412;&#25968;&#25454;&#12290;&#36825;&#31181;&#28431;&#27934;&#23384;&#22312;&#20110;&#35206;&#30422;Llama2&#12289;Mistral/Mixtral&#12289;Vicuna&#12289;SOLAR&#12289;WizardLM&#12289;Qwen1.5&#21644;Platypus2&#31561;&#22810;&#31181;&#29616;&#20195;LMs&#30340;&#24191;&#27867;&#33539;&#22260;&#20869;&#65292;&#24182;&#19988;&#38543;&#30528;&#27169;&#22411;&#35268;&#27169;&#30340;&#25193;&#22823;&#65292;&#21033;&#29992;&#33021;&#21147;&#21152;&#21095;&#12290;&#23558;&#30740;&#31350;&#25193;&#23637;&#21040;&#29983;&#20135;RAG&#27169;&#22411;GPTs&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#25915;&#20987;&#65292;&#21487;&#20197;&#22312;&#23545;25&#20010;&#38543;&#26426;&#36873;&#25321;&#30340;&#23450;&#21046;GPTs&#26045;&#21152;&#26368;&#22810;2&#20010;&#26597;&#35810;&#26102;&#20197;100%&#25104;&#21151;&#29575;&#23548;&#33268;&#25968;&#25454;&#23384;&#20648;&#27844;&#28431;&#65292;&#24182;&#19988;&#25105;&#20204;&#33021;&#22815;&#20197;77,000&#23383;&#30340;&#20070;&#31821;&#20013;&#30340;&#25991;&#26412;&#25968;&#25454;&#30340;&#25552;&#21462;&#29575;&#20026;41%&#65292;&#20197;&#21450;&#22312;&#21547;&#26377;1,569,00&#35789;&#30340;&#35821;&#26009;&#24211;&#20013;&#30340;&#25991;&#26412;&#25968;&#25454;&#30340;&#25552;&#21462;&#29575;&#20026;3%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17840v1 Announce Type: cross  Abstract: Retrieval-Augmented Generation (RAG) improves pre-trained models by incorporating external knowledge at test time to enable customized adaptation. We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection. The vulnerability exists for a wide range of modern LMs that span Llama2, Mistral/Mixtral, Vicuna, SOLAR, WizardLM, Qwen1.5, and Platypus2, and the exploitability exacerbates as the model size scales up. Extending our study to production RAG models GPTs, we design an attack that can cause datastore leakage with a 100% success rate on 25 randomly selected customized GPTs with at most 2 queries, and we extract text data verbatim at a rate of 41% from a book of 77,000 words and 3% from a corpus of 1,569,00
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#21517;&#20026;TER&#30340;&#31995;&#32479;LLM&#33258;&#26657;&#27491;&#32763;&#35793;&#26694;&#26550;&#65292;&#25104;&#21151;&#24110;&#21161;LLMs&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#65292;&#20855;&#26377;&#26356;&#20248;&#36234;&#30340;&#31995;&#32479;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.16379</link><description>&lt;p&gt;
&#29992;&#31995;&#32479;&#33258;&#26657;&#27491;&#25913;&#36827;&#22522;&#20110;LLM&#30340;&#26426;&#22120;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Improving LLM-based Machine Translation with Systematic Self-Correction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16379
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#21517;&#20026;TER&#30340;&#31995;&#32479;LLM&#33258;&#26657;&#27491;&#32763;&#35793;&#26694;&#26550;&#65292;&#25104;&#21151;&#24110;&#21161;LLMs&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#65292;&#20855;&#26377;&#26356;&#20248;&#36234;&#30340;&#31995;&#32479;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#26426;&#22120;&#32763;&#35793;&#65288;MT&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#20154;&#24037;&#20180;&#32454;&#35780;&#20272;&#21457;&#29616;&#65292;LLMs&#29983;&#25104;&#30340;&#32763;&#35793;&#20173;&#28982;&#21253;&#21547;&#22810;&#20010;&#38169;&#35823;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#23558;&#36825;&#31181;&#38169;&#35823;&#20449;&#24687;&#21453;&#39304;&#21040;LLMs&#20013;&#21487;&#20197;&#23454;&#29616;&#33258;&#26657;&#27491;&#65292;&#24182;&#25913;&#21892;&#32763;&#35793;&#24615;&#33021;&#12290;&#21463;&#21040;&#36825;&#20123;&#35266;&#28857;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;TER&#30340;&#31995;&#32479;LLM&#33258;&#26657;&#27491;&#32763;&#35793;&#26694;&#26550;&#65292;&#20195;&#34920;&#20102;&#22312;&#36825;&#19968;&#26041;&#21521;&#19978;&#30340;&#37325;&#35201;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65306;1&#65289;&#25105;&#20204;&#30340;&#33258;&#26657;&#27491;&#26694;&#26550;&#25104;&#21151;&#22320;&#24110;&#21161;LLMs&#25552;&#39640;&#20102;&#22810;&#31181;&#35821;&#35328;&#30340;&#32763;&#35793;&#36136;&#37327;&#65292;&#19981;&#31649;&#26159;&#20174;&#39640;&#36164;&#28304;&#35821;&#35328;&#21040;&#20302;&#36164;&#28304;&#35821;&#35328;&#65292;&#36824;&#26159;&#20197;&#33521;&#35821;&#20026;&#20013;&#24515;&#36824;&#26159;&#22260;&#32469;&#20854;&#20182;&#35821;&#35328;&#65307;2&#65289;TER&#30456;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#23637;&#31034;&#20986;&#26356;&#20248;&#36234;&#30340;&#31995;&#32479;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#65307;3&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16379v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved impressive results in Machine Translation (MT). However, careful evaluations by human reveal that the translations produced by LLMs still contain multiple errors. Importantly, feeding back such error information into the LLMs can lead to self-correction and result in improved translation performance. Motivated by these insights, we introduce a systematic LLM-based self-correcting translation framework, named TER, which stands for Translate, Estimate, and Refine, marking a significant step forward in this direction. Our findings demonstrate that 1) our self-correction framework successfully assists LLMs in improving their translation quality across a wide range of languages, whether it's from high-resource languages to low-resource ones or whether it's English-centric or centered around other languages; 2) TER exhibits superior systematicity and interpretability compared to previous methods; 3)
&lt;/p&gt;</description></item><item><title>&#20102;&#35299;Chain-of-Thought&#29983;&#25104;&#19982;&#22823;&#35821;&#35328;&#27169;&#22411;&#20869;&#37096;&#35745;&#31639;&#30340;&#19968;&#33268;&#31243;&#24230;&#23545;&#20110;&#20915;&#23450;&#26159;&#21542;&#20449;&#20219;&#27169;&#22411;&#36755;&#20986;&#33267;&#20851;&#37325;&#35201;&#65292;&#30740;&#31350;&#21457;&#29616;&#27169;&#22411;&#22823;&#23567;&#19982;&#24544;&#23454;&#24230;&#20043;&#38388;&#23384;&#22312;&#30528;&#29305;&#23450;&#20851;&#31995;&#65292;&#24182;&#19988;&#21457;&#29616;130&#20159;&#21442;&#25968;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#24544;&#23454;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.14897</link><description>&lt;p&gt;
Chain-of-Thought&#19981;&#24544;&#35802;&#20316;&#20026;&#20266;&#35013;&#30340;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Chain-of-Thought Unfaithfulness as Disguised Accuracy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14897
&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;Chain-of-Thought&#29983;&#25104;&#19982;&#22823;&#35821;&#35328;&#27169;&#22411;&#20869;&#37096;&#35745;&#31639;&#30340;&#19968;&#33268;&#31243;&#24230;&#23545;&#20110;&#20915;&#23450;&#26159;&#21542;&#20449;&#20219;&#27169;&#22411;&#36755;&#20986;&#33267;&#20851;&#37325;&#35201;&#65292;&#30740;&#31350;&#21457;&#29616;&#27169;&#22411;&#22823;&#23567;&#19982;&#24544;&#23454;&#24230;&#20043;&#38388;&#23384;&#22312;&#30528;&#29305;&#23450;&#20851;&#31995;&#65292;&#24182;&#19988;&#21457;&#29616;130&#20159;&#21442;&#25968;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#24544;&#23454;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;Chain-of-Thought (CoT)&#29983;&#25104;&#19982;&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#20869;&#37096;&#35745;&#31639;&#30340;&#19968;&#33268;&#31243;&#24230;&#23545;&#20110;&#20915;&#23450;&#26159;&#21542;&#20449;&#20219;LLM&#30340;&#36755;&#20986;&#33267;&#20851;&#37325;&#35201;&#12290;&#20316;&#20026;CoT&#24544;&#23454;&#24230;&#30340;&#20195;&#29702;&#65292;arXiv:2307.13702&#25552;&#20986;&#20102;&#19968;&#20010;&#24230;&#37327;&#27169;&#22411;&#20381;&#36182;&#20854;CoT&#29983;&#25104;&#31572;&#26696;&#30340;&#25351;&#26631;&#12290;&#22312;&#19968;&#20010;&#19987;&#26377;&#27169;&#22411;&#31995;&#21015;&#20013;&#65292;&#20182;&#20204;&#21457;&#29616;LLM&#34920;&#29616;&#20986;&#27169;&#22411;&#22823;&#23567;&#19982;&#20854;&#24544;&#23454;&#24230;&#27979;&#37327;&#20043;&#38388;&#30340;&#32553;&#25918;-&#21453;&#21521;&#32553;&#25918;&#20851;&#31995;&#65292;&#24182;&#19988;130&#20159;&#21442;&#25968;&#27169;&#22411;&#30456;&#27604;&#20110;&#23610;&#23544;&#20171;&#20110;8.1&#20159;&#21040;1750&#20159;&#21442;&#25968;&#20043;&#38388;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#22686;&#21152;&#30340;&#24544;&#23454;&#24230;&#12290;&#25105;&#20204;&#35780;&#20272;&#36825;&#20123;&#32467;&#26524;&#26159;&#21542;&#20316;&#20026;&#25152;&#26377;LLM&#30340;&#29305;&#24615;&#27867;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#19977;&#31181;&#19981;&#21516;&#31995;&#21015;&#30340;&#27169;&#22411;&#22797;&#21046;&#20182;&#20204;&#30340;&#23454;&#39564;&#35774;&#32622;&#65292;&#24182;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#25104;&#21151;&#22797;&#21046;&#20102;&#20182;&#20204;&#25253;&#21578;&#30340;CoT&#24544;&#23454;&#24230;&#30340;&#32553;&#25918;&#36235;&#21183;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#31616;&#21333;&#30340;&#25913;&#21464;&#35774;&#23450;&#20250;&#23548;&#33268;&#36825;&#20123;&#27169;&#24335;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#37325;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14897v1 Announce Type: cross  Abstract: Understanding the extent to which Chain-of-Thought (CoT) generations align with a large language model's (LLM) internal computations is critical for deciding whether to trust an LLM's output. As a proxy for CoT faithfulness, arXiv:2307.13702 propose a metric that measures a model's dependence on its CoT for producing an answer. Within a single family of proprietary models, they find that LLMs exhibit a scaling-then-inverse-scaling relationship between model size and their measure of faithfulness, and that a 13 billion parameter model exhibits increased faithfulness compared to models ranging from 810 million to 175 billion parameters in size. We evaluate whether these results generalize as a property of all LLMs. We replicate their experimental setup with three different families of models and, under specific conditions, successfully reproduce the scaling trends for CoT faithfulness they report. However, we discover that simply changin
&lt;/p&gt;</description></item><item><title>LVLM-Enhanced Multimodal Misinformation Detection with LEMMA proposes a solution for detecting complex misinformation by enhancing the reasoning capability of Large Vision Language Models.</title><link>https://arxiv.org/abs/2402.11943</link><description>&lt;p&gt;
LEMMA: &#25903;&#25345;&#22806;&#37096;&#30693;&#35782;&#22686;&#24378;&#30340;LVLM&#22686;&#24378;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
LEMMA: Towards LVLM-Enhanced Multimodal Misinformation Detection with External Knowledge Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11943
&lt;/p&gt;
&lt;p&gt;
LVLM-Enhanced Multimodal Misinformation Detection with LEMMA proposes a solution for detecting complex misinformation by enhancing the reasoning capability of Large Vision Language Models.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#24179;&#21488;&#19978;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#30340;&#20852;&#36215;&#23545;&#20010;&#20154;&#21644;&#31038;&#20250;&#37117;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#19982;&#25991;&#26412;&#34394;&#20551;&#20449;&#24687;&#30456;&#27604;&#65292;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#20855;&#26377;&#26356;&#39640;&#30340;&#21487;&#20449;&#24230;&#21644;&#26356;&#24191;&#27867;&#30340;&#24433;&#21709;&#65292;&#20351;&#24471;&#26816;&#27979;&#21464;&#24471;&#22797;&#26434;&#65292;&#38656;&#35201;&#36328;&#36234;&#19981;&#21516;&#23186;&#20307;&#31867;&#22411;&#36827;&#34892;&#24378;&#22823;&#30340;&#25512;&#29702;&#65292;&#24182;&#20855;&#22791;&#20934;&#30830;&#39564;&#35777;&#30340;&#28145;&#21051;&#30693;&#35782;&#12290;&#22823;&#35268;&#27169;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;LVLM&#65289;&#30340;&#20986;&#29616;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#25552;&#20379;&#20102;&#28508;&#22312;&#26041;&#26696;&#12290;&#21033;&#29992;LVLM&#22312;&#22788;&#29702;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#26041;&#38754;&#30340;&#29087;&#32451;&#33021;&#21147;&#65292;LVLM&#22312;&#35782;&#21035;&#22797;&#26434;&#20449;&#24687;&#21644;&#23637;&#29616;&#24378;&#22823;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#23637;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;LVLM&#22312;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;LVLM&#30340;&#24615;&#33021;&#20248;&#20110;LLMs&#65292;&#20294;&#20854;&#28145;&#21051;&#25512;&#29702;&#21487;&#33021;&#30001;&#20110;&#32570;&#20047;&#35777;&#25454;&#32780;&#34920;&#29616;&#20986;&#26377;&#38480;&#30340;&#25928;&#21147;&#12290;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LEMMA&#65306;LVLM&#22686;&#24378;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11943v1 Announce Type: new  Abstract: The rise of multimodal misinformation on social platforms poses significant challenges for individuals and societies. Its increased credibility and broader impact compared to textual misinformation make detection complex, requiring robust reasoning across diverse media types and profound knowledge for accurate verification. The emergence of Large Vision Language Model (LVLM) offers a potential solution to this problem. Leveraging their proficiency in processing visual and textual information, LVLM demonstrates promising capabilities in recognizing complex information and exhibiting strong reasoning skills. In this paper, we first investigate the potential of LVLM on multimodal misinformation detection. We find that even though LVLM has a superior performance compared to LLMs, its profound reasoning may present limited power with a lack of evidence. Based on these observations, we propose LEMMA: LVLM-Enhanced Multimodal Misinformation Det
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36923;&#36753;&#25903;&#26550;&#25512;&#29702;&#35268;&#21017;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#21253;&#21547;&#22522;&#30784;&#21644;&#32452;&#21512;&#35268;&#21017;&#30340;&#25512;&#29702;&#35268;&#21017;&#24211;ULogic&#65292;&#25581;&#31034;&#20102;LLMs&#22312;&#36923;&#36753;&#29702;&#35299;&#26041;&#38754;&#19982;&#20154;&#31867;&#34920;&#29616;&#30340;&#26174;&#33879;&#24046;&#36317;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#20934;&#30830;&#12289;&#22797;&#26434;&#21644;&#25277;&#35937;&#30340;&#25512;&#29702;&#32467;&#26524;&#26469;&#25552;&#21319;&#19979;&#28216;&#25512;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.11442</link><description>&lt;p&gt;
&#33021;&#22815;&#19982;&#35268;&#21017;&#36827;&#34892;&#25512;&#29702;&#21527;&#65311;&#36923;&#36753;&#25903;&#26550;&#29992;&#20110;&#21387;&#21147;&#27979;&#35797;&#21644;&#25552;&#21319;LLM
&lt;/p&gt;
&lt;p&gt;
Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11442
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36923;&#36753;&#25903;&#26550;&#25512;&#29702;&#35268;&#21017;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#21253;&#21547;&#22522;&#30784;&#21644;&#32452;&#21512;&#35268;&#21017;&#30340;&#25512;&#29702;&#35268;&#21017;&#24211;ULogic&#65292;&#25581;&#31034;&#20102;LLMs&#22312;&#36923;&#36753;&#29702;&#35299;&#26041;&#38754;&#19982;&#20154;&#31867;&#34920;&#29616;&#30340;&#26174;&#33879;&#24046;&#36317;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#20934;&#30830;&#12289;&#22797;&#26434;&#21644;&#25277;&#35937;&#30340;&#25512;&#29702;&#32467;&#26524;&#26469;&#25552;&#21319;&#19979;&#28216;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25509;&#36817;&#20154;&#31867;&#34920;&#29616;&#30340;&#25104;&#32489;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23545;&#20110;&#22522;&#30784;&#25512;&#29702;&#35268;&#21017;&#30340;&#25484;&#25569;&#20173;&#28982;&#19981;&#21450;&#20154;&#31867;&#33021;&#21147;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36923;&#36753;&#25903;&#26550;&#25512;&#29702;&#35268;&#21017;&#29983;&#25104;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;&#20116;&#20010;&#39046;&#22495;&#20013;&#22522;&#30784;&#21644;&#32452;&#21512;&#35268;&#21017;&#30340;&#25512;&#29702;&#35268;&#21017;&#24211;ULogic&#12290;&#25105;&#20204;&#23545;GPT&#31995;&#21015;&#27169;&#22411;&#22312;&#35268;&#21017;&#23376;&#38598;&#19978;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;LLMs&#22312;&#36923;&#36753;&#29702;&#35299;&#26041;&#38754;&#19982;&#20154;&#31867;&#34920;&#29616;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#65292;&#29305;&#21035;&#26159;&#22312;&#20855;&#26377;&#26576;&#20123;&#20559;&#35265;&#27169;&#24335;&#30340;&#32452;&#21512;&#21644;&#32467;&#26500;&#22797;&#26434;&#35268;&#21017;&#20013;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#36825;&#20123;&#35268;&#21017;&#25552;&#28860;&#25104;&#19968;&#20010;&#26356;&#23567;&#35268;&#27169;&#30340;&#25512;&#29702;&#24341;&#25806;&#65292;&#29992;&#20110;&#28789;&#27963;&#22320;&#29983;&#25104;&#35268;&#21017;&#24182;&#22686;&#24378;&#19979;&#28216;&#25512;&#29702;&#12290;&#36890;&#36807;&#22810;&#35780;&#20272;&#20154;&#21592;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#25512;&#29702;&#24341;&#25806;&#35777;&#26126;&#22312;&#29983;&#25104;&#20934;&#30830;&#12289;&#22797;&#26434;&#21644;&#25277;&#35937;&#30340;&#32467;&#35770;&#21644;&#21069;&#25552;&#26041;&#38754;&#34920;&#29616;&#20986;&#25928;&#26524;&#65292;&#21487;&#20197;&#25913;&#21892;&#21508;&#31181;&#24120;&#35782;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11442v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to construct an inferential rule base, ULogic, comprising both primitive and compositional rules across five domains. Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs' logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns. We further distill these rules into a smaller-scale inference engine for flexible rule generation and enhancing downstream reasoning. Through a multi-judger evaluation, our inference engine proves effective in generating accurate, complex and abstract conclusions and premises, and improve various commonsense reas
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#35805;&#24335;SimulMT&#26694;&#26550;&#65292;&#26412;&#25991;&#25552;&#39640;&#20102;&#22522;&#20110;LLM&#30340;SimulMT&#25512;&#29702;&#25928;&#29575;&#65292;&#22312;&#20445;&#25345;&#32763;&#35793;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#19982;&#19987;&#38376;&#30340;SimulMT&#27169;&#22411;&#30456;&#36817;&#30340;&#35745;&#31639;&#24310;&#36831;&#12290;</title><link>https://arxiv.org/abs/2402.10552</link><description>&lt;p&gt;
Conversational SimulMT: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39640;&#25928;&#21516;&#26102;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Conversational SimulMT: Efficient Simultaneous Translation with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10552
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#35805;&#24335;SimulMT&#26694;&#26550;&#65292;&#26412;&#25991;&#25552;&#39640;&#20102;&#22522;&#20110;LLM&#30340;SimulMT&#25512;&#29702;&#25928;&#29575;&#65292;&#22312;&#20445;&#25345;&#32763;&#35793;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#19982;&#19987;&#38376;&#30340;SimulMT&#27169;&#22411;&#30456;&#36817;&#30340;&#35745;&#31639;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21516;&#22768;&#26426;&#22120;&#32763;&#35793;&#65288;SimulMT&#65289;&#22312;&#32763;&#35793;&#36136;&#37327;&#21644;&#24310;&#36831;&#20043;&#38388;&#23384;&#22312;&#25361;&#25112;&#24615;&#30340;&#26435;&#34913;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;SimulMT&#20219;&#21153;&#20013;&#21487;&#20197;&#21462;&#24471;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#36825;&#24448;&#24448;&#26159;&#20197;&#25512;&#29702;&#25104;&#26412;&#21644;&#24310;&#36831;&#30340;&#22686;&#21152;&#20026;&#20195;&#20215;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#35805;&#24335;SimulMT&#26694;&#26550;&#65292;&#36890;&#36807;&#22522;&#20110;&#22810;&#36718;&#23545;&#35805;&#30340;&#35299;&#30721;&#26469;&#25552;&#39640;&#22522;&#20110;LLM&#30340;SimulMT&#30340;&#25512;&#29702;&#25928;&#29575;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;SimulMT&#22522;&#20934;&#19978;&#20351;&#29992;Llama2-7b-chat&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;LLM&#22312;&#32763;&#35793;&#36136;&#37327;&#19978;&#20855;&#26377;&#20248;&#21183;&#65292;&#21516;&#26102;&#23454;&#29616;&#19982;&#19987;&#38376;&#30340;SimulMT&#27169;&#22411;&#30456;&#24403;&#30340;&#35745;&#31639;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10552v1 Announce Type: new  Abstract: Simultaneous machine translation (SimulMT) presents a challenging trade-off between translation quality and latency. Recent studies have shown that LLMs can achieve good performance in SimulMT tasks. However, this often comes at the expense of high inference cost and latency. In this paper, we propose a conversational SimulMT framework to enhance the inference efficiency of LLM-based SimulMT through multi-turn-dialogue-based decoding. Our experiments with Llama2-7b-chat on two SimulMT benchmarks demonstrate the superiority of LLM in translation quality while achieving comparable computational latency to specialized SimulMT models.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ApiQ&#30340;&#26032;&#22411;&#37327;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#21021;&#22987;&#21270;LoRA&#32452;&#20214;&#21644;&#37327;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26435;&#37325;&#65292;&#24674;&#22797;&#37327;&#21270;&#36807;&#31243;&#20013;&#20002;&#22833;&#30340;&#20449;&#24687;&#65292;&#32500;&#25345;&#21407;&#22987;&#27169;&#22411;&#30340;&#28608;&#27963;&#31934;&#24230;&#24182;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#12290;</title><link>https://arxiv.org/abs/2402.05147</link><description>&lt;p&gt;
ApiQ&#65306;2&#20301;&#37327;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
ApiQ: Finetuning of 2-Bit Quantized Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05147
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ApiQ&#30340;&#26032;&#22411;&#37327;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#21021;&#22987;&#21270;LoRA&#32452;&#20214;&#21644;&#37327;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26435;&#37325;&#65292;&#24674;&#22797;&#37327;&#21270;&#36807;&#31243;&#20013;&#20002;&#22833;&#30340;&#20449;&#24687;&#65292;&#32500;&#25345;&#21407;&#22987;&#27169;&#22411;&#30340;&#28608;&#27963;&#31934;&#24230;&#24182;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22686;&#22823;&#65292;&#20869;&#23384;&#39640;&#25928;&#30340;&#27169;&#22411;&#24494;&#35843;&#36817;&#24180;&#26469;&#22791;&#21463;&#20851;&#27880;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;GPU&#20869;&#23384;&#38480;&#21046;&#21644;&#36825;&#20123;&#26041;&#27861;&#19982;&#23436;&#20840;&#24494;&#35843;&#30340;&#21487;&#27604;&#32467;&#26524;&#25152;&#24102;&#26469;&#30340;&#32422;&#26463;&#12290;&#23613;&#31649;&#26377;&#20102;&#36827;&#23637;&#65292;&#22914;QLoRA&#36825;&#26679;&#30340;&#20869;&#23384;&#39640;&#25928;&#24494;&#35843;&#31574;&#30053;&#22312;&#19981;&#21516;&#20301;&#23485;&#30340;&#37327;&#21270;&#21644;&#22810;&#26679;&#21270;&#20219;&#21153;&#20013;&#34920;&#29616;&#19981;&#19968;&#33268;&#12290;&#36825;&#31181;&#19981;&#19968;&#33268;&#20027;&#35201;&#26469;&#33258;&#20110;&#37327;&#21270;&#36807;&#31243;&#23545;&#20445;&#30041;&#30693;&#35782;&#30340;&#26377;&#23475;&#24433;&#21709;&#65292;&#23548;&#33268;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#21066;&#24369;&#20102;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#24494;&#35843;&#20013;&#30340;&#21033;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;ApiQ&#30340;&#26032;&#22411;&#37327;&#21270;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#21516;&#26102;&#21021;&#22987;&#21270;LoRA&#32452;&#20214;&#21644;&#37327;&#21270;LLM&#30340;&#26435;&#37325;&#26469;&#24674;&#22797;&#37327;&#21270;&#25439;&#22833;&#30340;&#20449;&#24687;&#12290;&#36825;&#31181;&#26041;&#27861;&#30830;&#20445;&#20102;&#21407;&#22987;LLM&#30340;&#28608;&#27963;&#31934;&#24230;&#30340;&#32500;&#25345;&#65292;&#21516;&#26102;&#20943;&#36731;&#20102;&#35823;&#24046;&#30340;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;
Memory-efficient finetuning of large language models (LLMs) has recently attracted huge attention with the increasing size of LLMs, primarily due to the constraints posed by GPU memory limitations and the comparable results of these methods with full finetuning. Despite the advancements, current strategies for memory-efficient finetuning, such as QLoRA, exhibit inconsistent performance across diverse bit-width quantizations and multifaceted tasks. This inconsistency largely stems from the detrimental impact of the quantization process on preserved knowledge, leading to catastrophic forgetting and undermining the utilization of pretrained models for finetuning purposes. In this work, we introduce a novel quantization framework named ApiQ, designed to restore the lost information from quantization by concurrently initializing LoRA components and quantizing the weights of LLMs. This approach ensures the maintenance of the original LLM's activation precision while mitigating the error prop
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20174;&#32858;&#21512;&#38388;&#25509;&#25512;&#29702;&#36335;&#24452;&#30340;&#35282;&#24230;&#29702;&#35299;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#20135;&#29983;&#25512;&#29702;&#33021;&#21147;&#12290;&#36890;&#36807;&#23545;&#30693;&#35782;&#22270;&#35889;&#21644;&#25968;&#23398;&#38382;&#39064;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#21644;&#20998;&#26512;&#65292;&#21457;&#29616;&#22686;&#21152;&#26080;&#26631;&#31614;&#30340;&#38543;&#26426;&#28216;&#36208;&#25512;&#29702;&#36335;&#24452;&#21487;&#20197;&#25552;&#39640;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22810;&#27493;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.03268</link><description>&lt;p&gt;
&#20174;&#25512;&#29702;&#36335;&#24452;&#32858;&#21512;&#30340;&#35282;&#24230;&#29702;&#35299;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03268
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20174;&#32858;&#21512;&#38388;&#25509;&#25512;&#29702;&#36335;&#24452;&#30340;&#35282;&#24230;&#29702;&#35299;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#20135;&#29983;&#25512;&#29702;&#33021;&#21147;&#12290;&#36890;&#36807;&#23545;&#30693;&#35782;&#22270;&#35889;&#21644;&#25968;&#23398;&#38382;&#39064;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#21644;&#20998;&#26512;&#65292;&#21457;&#29616;&#22686;&#21152;&#26080;&#26631;&#31614;&#30340;&#38543;&#26426;&#28216;&#36208;&#25512;&#29702;&#36335;&#24452;&#21487;&#20197;&#25552;&#39640;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22810;&#27493;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#27809;&#26377;&#26126;&#30830;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#25191;&#34892;&#22797;&#26434;&#30340;&#25512;&#29702;&#12290;&#20026;&#20102;&#29702;&#35299;&#39044;&#35757;&#32451;&#19982;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30446;&#26631;&#30340;&#20851;&#31995;&#22914;&#20309;&#20419;&#20351;&#25512;&#29702;&#33021;&#21147;&#30340;&#20986;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#21487;&#20197;&#23558;&#35821;&#35328;&#27169;&#22411;&#35270;&#20026;&#22312;&#39044;&#35757;&#32451;&#26102;&#36890;&#36807;&#32858;&#21512;&#38388;&#25509;&#30340;&#25512;&#29702;&#36335;&#24452;&#26469;&#24471;&#20986;&#26032;&#32467;&#35770;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36825;&#20010;&#35270;&#35282;&#22312;&#36923;&#36753;&#25512;&#29702;&#21644;&#25968;&#23398;&#25512;&#29702;&#31561;&#20851;&#38190;&#24773;&#20917;&#19979;&#38750;&#24120;&#26377;&#25928;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#25512;&#29702;&#36335;&#24452;&#24418;&#24335;&#21270;&#20026;&#22312;&#30693;&#35782;/&#25512;&#29702;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;&#36335;&#24452;&#12290;&#23545;&#23398;&#20064;&#30340;&#35821;&#35328;&#27169;&#22411;&#20998;&#24067;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#30456;&#20851;&#38543;&#26426;&#28216;&#36208;&#36335;&#24452;&#27010;&#29575;&#30340;&#21152;&#26435;&#21644;&#26159;&#35299;&#37322;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#21512;&#29702;&#26041;&#24335;&#12290;&#23545;&#22810;&#20010;&#30693;&#35782;&#22270;&#35889;&#21644;&#25968;&#23398;&#38382;&#39064;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#21644;&#20998;&#26512;&#25581;&#31034;&#20102;&#35757;&#32451;&#23545;&#38543;&#26426;&#28216;&#36208;&#36335;&#24452;&#30340;&#24433;&#21709;&#65292;&#24182;&#34920;&#26126;&#22686;&#21152;&#26080;&#26631;&#31614;&#30340;&#38543;&#26426;&#28216;&#36208;&#25512;&#29702;&#36335;&#24452;&#21487;&#20197;&#25552;&#39640;&#29616;&#23454;&#19990;&#30028;&#30340;&#22810;&#27493;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained language models (LMs) are able to perform complex reasoning without explicit fine-tuning. To understand how pre-training with a next-token prediction objective contributes to the emergence of such reasoning capability, we propose that we can view an LM as deriving new conclusions by aggregating indirect reasoning paths seen at pre-training time. We found this perspective effective in two important cases of reasoning: logic reasoning with knowledge graphs (KGs) and math reasoning with math word problems (MWPs). More specifically, we formalize the reasoning paths as random walk paths on the knowledge/reasoning graphs. Analyses of learned LM distributions suggest that a weighted sum of relevant random walk path probabilities is a reasonable way to explain how LMs reason. Experiments and analysis on multiple KG and MWP datasets reveal the effect of training on random walk paths and suggest that augmenting unlabeled random walk reasoning paths can improve real-world multi-step r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#29992;&#20110;&#30149;&#29702;&#35821;&#38899;&#29305;&#24449;&#39044;&#27979;&#30340;&#36801;&#31227;&#23398;&#20064;&#65292;&#21457;&#29616;&#36873;&#25321;&#36866;&#24403;&#30340;&#23618;&#33021;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#24182;&#19988;&#23398;&#24471;&#30340;&#21152;&#26435;&#21644;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01796</link><description>&lt;p&gt;
&#25506;&#32034;&#29992;&#20110;&#30149;&#29702;&#35821;&#38899;&#29305;&#24449;&#39044;&#27979;&#30340;&#36801;&#31227;&#23398;&#20064;&#65306;&#23618;&#36873;&#25321;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Exploring transfer learning for pathological speech feature prediction: Impact of layer selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#29992;&#20110;&#30149;&#29702;&#35821;&#38899;&#29305;&#24449;&#39044;&#27979;&#30340;&#36801;&#31227;&#23398;&#20064;&#65292;&#21457;&#29616;&#36873;&#25321;&#36866;&#24403;&#30340;&#23618;&#33021;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#24182;&#19988;&#23398;&#24471;&#30340;&#21152;&#26435;&#21644;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#23545;&#20020;&#24202;&#35821;&#38899;&#36827;&#34892;&#33258;&#21160;&#23458;&#35266;&#35780;&#20272;&#65292;&#24182;&#20419;&#36827;&#35821;&#38899;&#38556;&#30861;&#30340;&#35786;&#26029;&#21644;&#27835;&#30103;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#36801;&#31227;&#23398;&#20064;&#65292;&#22312;&#39044;&#27979;&#30149;&#29702;&#35821;&#38899;&#23384;&#22312;&#24615;&#30340;&#19979;&#28216;&#20219;&#21153;&#20013;&#65292;&#37325;&#28857;&#20998;&#26512;&#20102;&#23618;&#36873;&#25321;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#36873;&#25321;&#26368;&#20339;&#23618;&#33021;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#65288;&#24179;&#22343;&#24179;&#34913;&#20934;&#30830;&#29575;&#22686;&#21152;12.4%&#65289;&#65292;&#23613;&#31649;&#26368;&#20339;&#23618;&#22240;&#39044;&#27979;&#29305;&#24449;&#32780;&#24322;&#65292;&#24182;&#19988;&#24182;&#19981;&#24635;&#26159;&#23545;&#26410;&#35265;&#25968;&#25454;&#27867;&#21270;&#33391;&#22909;&#12290;&#23398;&#24471;&#30340;&#21152;&#26435;&#21644;&#22312;&#20998;&#24067;&#20869;&#19982;&#24179;&#22343;&#26368;&#20339;&#23618;&#20855;&#26377;&#21487;&#27604;&#24615;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#20998;&#24067;&#22806;&#25968;&#25454;&#19978;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is interest in leveraging AI to conduct automatic, objective assessments of clinical speech, in turn facilitating diagnosis and treatment of speech disorders. We explore transfer learning, focusing on the impact of layer selection, for the downstream task of predicting the presence of pathological speech. We find that selecting an optimal layer offers large performance improvements (12.4% average increase in balanced accuracy), though the best layer varies by predicted feature and does not always generalize well to unseen data. A learned weighted sum offers comparable performance to the average best layer in-distribution and has better generalization for out-of-distribution data.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#25968;&#25454;&#25366;&#25496;&#20013;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39044;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25351;&#23548;&#35843;&#25972;&#26412;&#22320;LLMs&#26469;&#35299;&#20915;&#36890;&#29992;&#25968;&#25454;&#39044;&#22788;&#29702;&#38382;&#39064;&#65292;&#30830;&#20445;&#25968;&#25454;&#23433;&#20840;&#24182;&#36827;&#34892;&#36827;&#19968;&#27493;&#35843;&#25972;</title><link>https://arxiv.org/abs/2312.01678</link><description>&lt;p&gt;
Jellyfish&#65306;&#19968;&#20010;&#29992;&#20110;&#25968;&#25454;&#39044;&#22788;&#29702;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Jellyfish: A Large Language Model for Data Preprocessing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01678
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#25968;&#25454;&#25366;&#25496;&#20013;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39044;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25351;&#23548;&#35843;&#25972;&#26412;&#22320;LLMs&#26469;&#35299;&#20915;&#36890;&#29992;&#25968;&#25454;&#39044;&#22788;&#29702;&#38382;&#39064;&#65292;&#30830;&#20445;&#25968;&#25454;&#23433;&#20840;&#24182;&#36827;&#34892;&#36827;&#19968;&#27493;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;&#25968;&#25454;&#25366;&#25496;&#31649;&#36947;&#20013;&#23558;&#21407;&#22987;&#25968;&#25454;&#36716;&#25442;&#20026;&#26377;&#21033;&#20110;&#31616;&#21333;&#22788;&#29702;&#30340;&#24178;&#20928;&#26684;&#24335;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#65288;DP&#65289;&#20013;LLMs&#30340;&#21033;&#29992;&#12290;&#19982;&#20351;&#29992;LLMs&#20026;DP&#35774;&#35745;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#24341;&#36215;&#20102;&#20852;&#36259;&#30456;&#27604;&#65292;&#26368;&#36817;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#20513;&#35758;&#36890;&#24120;&#20381;&#36182;&#20110;GPT API&#65292;&#24341;&#21457;&#20102;&#19981;&#21487;&#36991;&#20813;&#30340;&#25968;&#25454;&#27844;&#38671;&#25285;&#24551;&#12290;&#19982;&#36825;&#20123;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#32771;&#34385;&#23558;&#25351;&#23548;&#35843;&#25972;&#26412;&#22320;LLMs&#65288;7-13B&#27169;&#22411;&#65289;&#20316;&#20026;&#36890;&#29992;DP&#38382;&#35299;&#22120;&#12290;&#25105;&#20204;&#36873;&#25321;&#20102;&#20195;&#34920;&#24615;DP&#20219;&#21153;&#30340;&#22235;&#32452;&#25968;&#25454;&#38598;&#65292;&#24182;&#21033;&#29992;&#38024;&#23545;DP&#23450;&#21046;&#30340;&#24207;&#21015;&#21270;&#21644;&#30693;&#35782;&#27880;&#20837;&#25216;&#26415;&#26500;&#24314;&#20102;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#12290;&#22240;&#27492;&#65292;&#25351;&#23548;&#35843;&#25972;&#30340;LLMs&#20351;&#29992;&#25143;&#33021;&#22815;&#20026;DP&#25163;&#21160;&#21046;&#23450;&#25351;&#23548;&#12290;&#21516;&#26102;&#65292;&#23427;&#20204;&#21487;&#20197;&#22312;&#26412;&#22320;&#12289;&#21333;&#19968;&#21644;&#20215;&#26684;&#20302;&#24265;&#30340;GPU&#19978;&#36816;&#34892;&#65292;&#30830;&#20445;&#25968;&#25454;&#23433;&#20840;&#24182;&#23454;&#29616;&#36827;&#19968;&#27493;&#35843;&#25972;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#20026;DP&#25351;&#23548;&#26500;&#24314;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.01678v4 Announce Type: replace  Abstract: This paper explores the utilization of LLMs for data preprocessing (DP), a crucial step in the data mining pipeline that transforms raw data into a clean format conducive to easy processing. Whereas the use of LLMs has sparked interest in devising universal solutions to DP, recent initiatives in this domain typically rely on GPT APIs, raising inevitable data breach concerns. Unlike these approaches, we consider instruction-tuning local LLMs (7 - 13B models) as universal DP ask solver. We select a collection of datasets across four representative DP tasks and construct instruction-tuning data using serialization and knowledge injection techniques tailored to DP. As such, the instruction-tuned LLMs empower users to manually craft instructions for DP. Meanwhile, they can operate on a local, single, and low-priced GPU, ensuring data security and enabling further tuning. Our experiments show that our dataset constructed for DP instruction
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#21313;&#20010;&#36136;&#37327;&#21644;&#35821;&#35328;&#35782;&#21035;&#36807;&#28388;&#22120;&#23545;&#19981;&#21516;&#31038;&#20132;&#32500;&#24230;&#21464;&#21270;&#30340;&#32593;&#39029;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#21457;&#29616;&#22312;&#25968;&#25454;&#31579;&#36873;&#36807;&#31243;&#20013;&#23384;&#22312;&#38544;&#21547;&#30340;&#20559;&#22909;&#65292;&#19968;&#20123;&#36136;&#37327;&#20998;&#31867;&#22120;&#31867;&#20284;&#20110;&#20027;&#39064;&#36807;&#28388;&#22120;&#65292;&#32780;&#35821;&#35328;&#35782;&#21035;&#21487;&#33021;&#20250;&#24573;&#35270;&#26576;&#20123;&#22320;&#21306;&#30340;&#33521;&#35821;&#20869;&#23481;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#20419;&#36827;&#26356;&#20844;&#27491;&#21644;&#20840;&#38754;&#30340;&#27169;&#22411;&#24320;&#21457;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;</title><link>http://arxiv.org/abs/2401.06408</link><description>&lt;p&gt;
&#20851;&#20110;&#25105;&#65306;&#20351;&#29992;&#33258;&#25105;&#25551;&#36848;&#30340;&#32593;&#39029;&#26469;&#35760;&#24405;&#33521;&#35821;&#39044;&#35757;&#32451;&#25968;&#25454;&#36807;&#28388;&#22120;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters. (arXiv:2401.06408v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06408
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#21313;&#20010;&#36136;&#37327;&#21644;&#35821;&#35328;&#35782;&#21035;&#36807;&#28388;&#22120;&#23545;&#19981;&#21516;&#31038;&#20132;&#32500;&#24230;&#21464;&#21270;&#30340;&#32593;&#39029;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#21457;&#29616;&#22312;&#25968;&#25454;&#31579;&#36873;&#36807;&#31243;&#20013;&#23384;&#22312;&#38544;&#21547;&#30340;&#20559;&#22909;&#65292;&#19968;&#20123;&#36136;&#37327;&#20998;&#31867;&#22120;&#31867;&#20284;&#20110;&#20027;&#39064;&#36807;&#28388;&#22120;&#65292;&#32780;&#35821;&#35328;&#35782;&#21035;&#21487;&#33021;&#20250;&#24573;&#35270;&#26576;&#20123;&#22320;&#21306;&#30340;&#33521;&#35821;&#20869;&#23481;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#20419;&#36827;&#26356;&#20844;&#27491;&#21644;&#20840;&#38754;&#30340;&#27169;&#22411;&#24320;&#21457;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#33021;&#21147;&#26469;&#28304;&#20110;&#23427;&#20204;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#65292;&#27169;&#22411;&#30340;&#24320;&#21457;&#22987;&#20110;&#25968;&#25454;&#30340;&#31579;&#36873;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#21021;&#27493;&#38454;&#27573;&#20915;&#23450;&#20445;&#30041;&#21738;&#20123;&#25968;&#25454;&#25110;&#31227;&#38500;&#21738;&#20123;&#25968;&#25454;&#30340;&#20915;&#31574;&#24120;&#24120;&#27809;&#26377;&#34987;&#20805;&#20998;&#23457;&#26597;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#32593;&#39029;&#25991;&#26412;&#19982;&#20854;&#31038;&#20132;&#21644;&#22320;&#29702;&#32972;&#26223;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;1030&#19975;&#20010;&#32593;&#39029;&#21019;&#24314;&#32773;&#30340;&#33258;&#25105;&#25551;&#36848;&#65292;&#24182;&#25552;&#21462;&#20102;&#20851;&#20110;&#20182;&#20204;&#30340;&#20010;&#20154;&#20449;&#24687;&#20197;&#21450;&#20182;&#20204;&#26469;&#33258;&#21738;&#37324;&#30340;&#20449;&#24687;&#65306;&#20182;&#20204;&#30340;&#20852;&#36259;&#39046;&#22495;&#12289;&#31038;&#20132;&#35282;&#33394;&#21644;&#22320;&#29702;&#24402;&#23646;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#31532;&#19968;&#39033;&#30740;&#31350;&#65292;&#35843;&#26597;&#20102;&#21313;&#20010;&#8220;&#36136;&#37327;&#8221;&#21644;&#33521;&#35821;&#35821;&#35328;&#35782;&#21035;&#65288;langID&#65289;&#36807;&#28388;&#22120;&#23545;&#36825;&#20123;&#31038;&#20132;&#32500;&#24230;&#21464;&#21270;&#30340;&#32593;&#39029;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#25968;&#25454;&#31579;&#36873;&#20013;&#19968;&#31995;&#21015;&#38544;&#21547;&#30340;&#20559;&#22909;&#65306;&#25105;&#20204;&#23637;&#31034;&#20986;&#19968;&#20123;&#36136;&#37327;&#20998;&#31867;&#22120;&#30340;&#20316;&#29992;&#31867;&#20284;&#20110;&#20027;&#39064;&#39046;&#22495;&#36807;&#28388;&#22120;&#65292;&#32780;langID&#21487;&#33021;&#20250;&#24573;&#35270;&#19990;&#30028;&#26576;&#20123;&#22320;&#21306;&#30340;&#33521;&#35821;&#20869;&#23481;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24076;&#26395;&#25105;&#20204;&#30340;&#24037;&#20316;&#33021;&#22815;&#25552;&#20379;&#23545;&#25968;&#25454;&#31579;&#36873;&#20013;&#38544;&#21547;&#20559;&#22909;&#30340;&#27934;&#23519;&#65292;&#20197;&#20419;&#36827;&#26356;&#20844;&#27491;&#21644;&#20840;&#38754;&#30340;&#27169;&#22411;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models' (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage is under-scrutinized. In our work, we ground web text, which is a popular pretraining data source, to its social and geographic contexts. We create a new dataset of 10.3 million self-descriptions of website creators, and extract information about who they are and where they are from: their topical interests, social roles, and geographic affiliations. Then, we conduct the first study investigating how ten "quality" and English language identification (langID) filters affect webpages that vary along these social dimensions. Our experiments illuminate a range of implicit preferences in data curation: we show that some quality classifiers act like topical domain filters, and langID can overlook English content from some regions of the world. Overall, we hope that our work will enc
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#27861;&#24459;&#24187;&#35273;&#65292;&#19981;&#19968;&#33268;&#27861;&#24459;&#20107;&#23454;&#65292;&#24187;&#35273;&#26222;&#36941;&#23384;&#22312;&#39640;&#36798;69%&#33267;88%&#30340;&#24773;&#20917;&#65292;&#26080;&#27861;&#32416;&#27491;&#29992;&#25143;&#38169;&#35823;&#27861;&#24459;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2401.01301</link><description>&lt;p&gt;
&#22823;&#22411;&#27861;&#24459;&#34394;&#26500;&#65306;&#25581;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#27861;&#24459;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models. (arXiv:2401.01301v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01301
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#27861;&#24459;&#24187;&#35273;&#65292;&#19981;&#19968;&#33268;&#27861;&#24459;&#20107;&#23454;&#65292;&#24187;&#35273;&#26222;&#36941;&#23384;&#22312;&#39640;&#36798;69%&#33267;88%&#30340;&#24773;&#20917;&#65292;&#26080;&#27861;&#32416;&#27491;&#29992;&#25143;&#38169;&#35823;&#27861;&#24459;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26377;&#21487;&#33021;&#25913;&#21464;&#27861;&#24459;&#23454;&#36341;&#65292;&#20294;&#20854;&#28508;&#21147;&#21463;&#21040;&#27861;&#24459;&#24187;&#35273;&#30340;&#23041;&#32961;&#65292;&#21363;&#36825;&#20123;&#27169;&#22411;&#20135;&#29983;&#19982;&#27861;&#24459;&#20107;&#23454;&#19981;&#19968;&#33268;&#30340;&#22238;&#31572;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#22871;&#21407;&#21019;&#30340;&#27861;&#24459;&#26597;&#35810;&#26469;&#35843;&#26597;&#36825;&#20123;&#24187;&#35273;&#30340;&#31243;&#24230;&#65292;&#23558;LLMs&#30340;&#22238;&#31572;&#19982;&#32467;&#26500;&#21270;&#30340;&#27861;&#24459;&#20803;&#25968;&#25454;&#36827;&#34892;&#23545;&#27604;&#65292;&#24182;&#26816;&#26597;&#20854;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26377;&#22235;&#20010;&#20851;&#38190;&#36129;&#29486;&#65306;&#65288;1&#65289;&#25105;&#20204;&#24314;&#31435;&#20102;&#27861;&#24459;&#24187;&#35273;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#20026;&#20170;&#21518;&#22312;&#36825;&#19968;&#39046;&#22495;&#36827;&#34892;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#27010;&#24565;&#26694;&#26550;&#12290;&#65288;2&#65289;&#25105;&#20204;&#21457;&#29616;&#65292;&#27861;&#24459;&#24187;&#35273;&#30340;&#26222;&#36941;&#24615;&#20196;&#20154;&#25285;&#24551;&#65292;&#22312;&#23545;&#38543;&#26426;&#32852;&#37030;&#27861;&#38498;&#26696;&#20363;&#36827;&#34892;&#20855;&#20307;&#12289;&#21487;&#39564;&#35777;&#30340;&#38382;&#39064;&#26102;&#65292;ChatGPT 3.5&#20135;&#29983;&#30340;&#24187;&#35273;&#21457;&#29983;&#29575;&#20026;69&#65285;&#65292;&#32780;Llama 2&#20026;88&#65285;&#12290;&#65288;3&#65289;&#25105;&#20204;&#23637;&#31034;&#20102;LLMs&#22312;&#36870;&#21521;&#38382;&#39064;&#35774;&#32622;&#20013;&#24448;&#24448;&#26080;&#27861;&#32416;&#27491;&#29992;&#25143;&#30340;&#38169;&#35823;&#27861;&#24459;&#20551;&#35774;&#12290;&#65288;4&#65289;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;LLMs&#24182;&#19981;&#24635;&#33021;&#39044;&#27979;&#25110;&#24182;&#19981;&#24635;&#30693;&#36947;...
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. (2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. (3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. (4) We provide evidence that LLMs cannot always predict, or do not always know, wh
&lt;/p&gt;</description></item><item><title>GestureGPT&#26159;&#19968;&#20010;&#38646;&#26679;&#26412;&#20132;&#20114;&#25163;&#21183;&#29702;&#35299;&#21644;&#23545;&#25509;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#35299;&#35835;&#25163;&#21183;&#25551;&#36848;&#24182;&#26681;&#25454;&#20132;&#20114;&#29615;&#22659;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#33021;&#22815;&#23558;&#29992;&#25143;&#24847;&#22270;&#23545;&#25509;&#21040;&#20132;&#20114;&#21151;&#33021;&#19978;&#12290;</title><link>http://arxiv.org/abs/2310.12821</link><description>&lt;p&gt;
GestureGPT: &#38646;&#26679;&#26412;&#20132;&#20114;&#25163;&#21183;&#29702;&#35299;&#19982;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#30340;&#23545;&#25509;
&lt;/p&gt;
&lt;p&gt;
GestureGPT: Zero-shot Interactive Gesture Understanding and Grounding with Large Language Model Agents. (arXiv:2310.12821v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12821
&lt;/p&gt;
&lt;p&gt;
GestureGPT&#26159;&#19968;&#20010;&#38646;&#26679;&#26412;&#20132;&#20114;&#25163;&#21183;&#29702;&#35299;&#21644;&#23545;&#25509;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#35299;&#35835;&#25163;&#21183;&#25551;&#36848;&#24182;&#26681;&#25454;&#20132;&#20114;&#29615;&#22659;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#33021;&#22815;&#23558;&#29992;&#25143;&#24847;&#22270;&#23545;&#25509;&#21040;&#20132;&#20114;&#21151;&#33021;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#25163;&#21183;&#35782;&#21035;&#31995;&#32479;&#20027;&#35201;&#20851;&#27880;&#35782;&#21035;&#39044;&#23450;&#20041;&#38598;&#21512;&#20013;&#30340;&#25163;&#21183;&#65292;&#26410;&#33021;&#23558;&#36825;&#20123;&#25163;&#21183;&#19982;&#20132;&#20114;&#24335;&#22270;&#24418;&#29992;&#25143;&#30028;&#38754;&#20803;&#32032;&#25110;&#31995;&#32479;&#21151;&#33021;&#30456;&#36830;&#25509;&#65288;&#20363;&#22914;&#65292;&#23558;&#8220;&#31446;&#36215;&#22823;&#25287;&#25351;&#8221;&#25163;&#21183;&#19982;&#8220;&#21916;&#27426;&#8221;&#25353;&#38062;&#20851;&#32852;&#36215;&#26469;&#65289;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;GestureGPT&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#38646;&#26679;&#26412;&#25163;&#21183;&#29702;&#35299;&#21644;&#23545;&#25509;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#12290;&#25163;&#21183;&#25551;&#36848;&#26681;&#25454;&#25163;&#21183;&#35270;&#39057;&#20013;&#30340;&#25163;&#37096;&#20851;&#38190;&#28857;&#22352;&#26631;&#36827;&#34892;&#24418;&#24335;&#21270;&#65292;&#24182;&#36755;&#20837;&#21040;&#25105;&#20204;&#30340;&#21452;&#20195;&#29702;&#23545;&#35805;&#31995;&#32479;&#20013;&#12290;&#19968;&#20010;&#25163;&#21183;&#20195;&#29702;&#35299;&#35835;&#36825;&#20123;&#25551;&#36848;&#65292;&#24182;&#35810;&#38382;&#26377;&#20851;&#20132;&#20114;&#29615;&#22659;&#30340;&#20449;&#24687;&#65288;&#20363;&#22914;&#65292;&#30028;&#38754;&#12289;&#21382;&#21490;&#35760;&#24405;&#12289;&#20957;&#35270;&#25968;&#25454;&#65289;&#65292;&#19968;&#20010;&#19978;&#19979;&#25991;&#20195;&#29702;&#36127;&#36131;&#32452;&#32455;&#24182;&#25552;&#20379;&#36825;&#20123;&#20449;&#24687;&#12290;&#32463;&#36807;&#36845;&#20195;&#30340;&#20132;&#27969;&#65292;&#25163;&#21183;&#20195;&#29702;&#33021;&#22815;&#29702;&#35299;&#29992;&#25143;&#24847;&#22270;&#65292;&#24182;&#23558;&#20854;&#23545;&#25509;&#21040;&#19968;&#20010;&#20132;&#20114;&#21151;&#33021;&#19978;&#12290;&#25105;&#20204;&#20351;&#29992;&#20844;&#24320;&#30340;&#31532;&#19968;&#35270;&#35282;&#21644;&#31532;&#19977;&#35270;&#35282;&#25163;&#21183;&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#25163;&#21183;&#25551;&#36848;&#27169;&#22359;&#65292;&#24182;&#22312;&#35270;&#39057;&#27969;&#21644;&#26234;&#33021;&#23478;&#23621;&#29289;&#32852;&#32593;&#25511;&#21046;&#30340;&#20004;&#20010;&#30495;&#23454;&#22330;&#26223;&#20013;&#27979;&#35797;&#20102;&#25972;&#20010;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current gesture recognition systems primarily focus on identifying gestures within a predefined set, leaving a gap in connecting these gestures to interactive GUI elements or system functions (e.g., linking a 'thumb-up' gesture to a 'like' button). We introduce GestureGPT, a novel zero-shot gesture understanding and grounding framework leveraging large language models (LLMs). Gesture descriptions are formulated based on hand landmark coordinates from gesture videos and fed into our dual-agent dialogue system. A gesture agent deciphers these descriptions and queries about the interaction context (e.g., interface, history, gaze data), which a context agent organizes and provides. Following iterative exchanges, the gesture agent discerns user intent, grounding it to an interactive function. We validated the gesture description module using public first-view and third-view gesture datasets and tested the whole system in two real-world settings: video streaming and smart home IoT control. T
&lt;/p&gt;</description></item><item><title>XNLP&#28436;&#31034;&#31995;&#32479;&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#39640;&#24615;&#33021;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24179;&#21488;&#65292;&#36890;&#36807;&#25552;&#20379;&#36890;&#29992;&#30340;&#24314;&#27169;&#26041;&#27861;&#12289;&#35299;&#37322;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#20114;&#21160;&#24615;&#65292;&#23454;&#29616;&#20102;&#32479;&#19968;XNLP&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2308.01846</link><description>&lt;p&gt;
XNLP&#65306;&#36890;&#29992;&#32467;&#26500;&#21270;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#20132;&#20114;&#28436;&#31034;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
XNLP: An Interactive Demonstration System for Universal Structured NLP. (arXiv:2308.01846v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01846
&lt;/p&gt;
&lt;p&gt;
XNLP&#28436;&#31034;&#31995;&#32479;&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#39640;&#24615;&#33021;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24179;&#21488;&#65292;&#36890;&#36807;&#25552;&#20379;&#36890;&#29992;&#30340;&#24314;&#27169;&#26041;&#27861;&#12289;&#35299;&#37322;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#20114;&#21160;&#24615;&#65292;&#23454;&#29616;&#20102;&#32479;&#19968;XNLP&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;XNLP&#65289;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#19968;&#20010;&#37325;&#35201;&#23376;&#38598;&#65292;&#28041;&#21450;&#29702;&#35299;&#25991;&#26412;&#30340;&#24213;&#23618;&#35821;&#20041;&#25110;&#21477;&#27861;&#32467;&#26500;&#65292;&#20026;&#35768;&#22810;&#19979;&#28216;&#24212;&#29992;&#31243;&#24207;&#25552;&#20379;&#20102;&#22522;&#26412;&#32452;&#20214;&#12290;&#23613;&#31649;&#26368;&#36817;&#26377;&#19968;&#20123;&#21162;&#21147;&#25506;&#32034;&#29305;&#23450;&#31867;&#21035;&#30340;XNLP&#20219;&#21153;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#32479;&#19968;&#25152;&#26377;XNLP&#20219;&#21153;&#30340;&#32508;&#21512;&#26377;&#25928;&#26041;&#27861;&#20173;&#28982;&#19981;&#23436;&#21892;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;XNLP&#28436;&#31034;&#31995;&#32479;&#23545;&#20110;&#30740;&#31350;&#20154;&#21592;&#25506;&#32034;&#21508;&#31181;XNLP&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#65292;&#29616;&#26377;&#24179;&#21488;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#65292;&#20363;&#22914;&#21482;&#25903;&#25345;&#23569;&#25968;XNLP&#20219;&#21153;&#65292;&#32570;&#20047;&#20114;&#21160;&#24615;&#21644;&#36890;&#29992;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20808;&#36827;&#30340;XNLP&#28436;&#31034;&#24179;&#21488;&#65292;&#20854;&#20013;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;LLM&#23454;&#29616;&#36890;&#29992;XNLP&#65292;&#36890;&#36807;&#19968;&#20010;&#27169;&#22411;&#23454;&#29616;&#39640;&#36890;&#29992;&#24615;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;&#22810;&#20010;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#21253;&#25324;&#36890;&#29992;XNLP&#24314;&#27169;&#12289;&#39640;&#24615;&#33021;&#12289;&#21487;&#35299;&#37322;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#20114;&#21160;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structured Natural Language Processing (XNLP) is an important subset of NLP that entails understanding the underlying semantic or syntactic structure of texts, which serves as a foundational component for many downstream applications. Despite certain recent efforts to explore universal solutions for specific categories of XNLP tasks, a comprehensive and effective approach for unifying all XNLP tasks long remains underdeveloped. In the meanwhile, while XNLP demonstration systems are vital for researchers exploring various XNLP tasks, existing platforms can be limited to, e.g., supporting few XNLP tasks, lacking interactivity and universalness. To this end, we propose an advanced XNLP demonstration platform, where we propose leveraging LLM to achieve universal XNLP, with one model for all with high generalizability. Overall, our system advances in multiple aspects, including universal XNLP modeling, high performance, interpretability, scalability, and interactivity, providing a unified p
&lt;/p&gt;</description></item><item><title>CREATOR&#26159;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#21033;&#29992;&#25991;&#26723;&#21644;&#20195;&#30721;&#23454;&#29616;&#21019;&#24314;&#33258;&#24049;&#30340;&#24037;&#20855;&#12290;&#36890;&#36807;&#23558;&#25277;&#35937;&#24037;&#20855;&#21019;&#24314;&#21644;&#20855;&#20307;&#20915;&#31574;&#25191;&#34892;&#35299;&#32806;&#65292;CREATOR&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#24182;&#22312;&#19981;&#21516;&#22522;&#20934;&#27979;&#35797;&#20013;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Creation Challenge&#25968;&#25454;&#38598;&#65292;&#23637;&#31034;&#20102;LLMs&#30340;&#24037;&#20855;&#21019;&#24314;&#33021;&#21147;&#30340;&#24517;&#35201;&#24615;&#21644;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.14318</link><description>&lt;p&gt;
CREATOR: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25277;&#35937;&#21644;&#20855;&#20307;&#25512;&#29702;&#35299;&#32806;&#24037;&#20855;&#30340;&#21019;&#24314;
&lt;/p&gt;
&lt;p&gt;
CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models. (arXiv:2305.14318v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14318
&lt;/p&gt;
&lt;p&gt;
CREATOR&#26159;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#21033;&#29992;&#25991;&#26723;&#21644;&#20195;&#30721;&#23454;&#29616;&#21019;&#24314;&#33258;&#24049;&#30340;&#24037;&#20855;&#12290;&#36890;&#36807;&#23558;&#25277;&#35937;&#24037;&#20855;&#21019;&#24314;&#21644;&#20855;&#20307;&#20915;&#31574;&#25191;&#34892;&#35299;&#32806;&#65292;CREATOR&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#24182;&#22312;&#19981;&#21516;&#22522;&#20934;&#27979;&#35797;&#20013;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Creation Challenge&#25968;&#25454;&#38598;&#65292;&#23637;&#31034;&#20102;LLMs&#30340;&#24037;&#20855;&#21019;&#24314;&#33021;&#21147;&#30340;&#24517;&#35201;&#24615;&#21644;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21033;&#29992;&#24037;&#20855;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;API&#21487;&#29992;&#24615;&#21644;&#38544;&#24335;&#25512;&#29702;&#30340;&#19981;&#31283;&#23450;&#24615;&#65292;&#23427;&#20204;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#35268;&#21010;&#21644;&#25191;&#34892;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;CREATOR&#65292;&#21487;&#20197;&#20351;LLMs&#21033;&#29992;&#25991;&#26723;&#21644;&#20195;&#30721;&#23454;&#29616;&#26469;&#21019;&#24314;&#33258;&#24049;&#30340;&#24037;&#20855;&#12290;CREATOR&#23558;&#25277;&#35937;&#24037;&#20855;&#21019;&#24314;&#21644;&#20855;&#20307;&#20915;&#31574;&#25191;&#34892;&#35299;&#32806;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;MATH&#21644;TabMWP&#22522;&#20934;&#19978;&#35780;&#20272;&#20102;CREATOR&#65292;&#20998;&#21035;&#21253;&#21547;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#31454;&#36187;&#38382;&#39064;&#21644;&#22810;&#26679;&#30340;&#34920;&#26684;&#20869;&#23481;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;CREATOR&#20248;&#20110;&#29616;&#26377;&#30340;&#24605;&#32500;&#38142;&#12289;&#24605;&#32500;&#31243;&#24207;&#21644;&#20351;&#29992;&#24037;&#20855;&#30340;&#22522;&#32447;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;Creation Challenge&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;2K&#20010;&#22810;&#26679;&#30340;&#38382;&#39064;&#65292;&#20197;&#24378;&#35843;LLMs&#21019;&#24314;&#24037;&#20855;&#30340;&#24517;&#35201;&#24615;&#21644;&#30410;&#22788;&#12290;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23558;LLMs&#29992;&#20316;&#24037;&#20855;&#21019;&#24314;&#32773;&#26377;&#21161;&#20110;&#25552;&#21319;&#30693;&#35782;&#30340;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have made significant progress in utilizing tools, but their ability is limited by API availability and the instability of implicit reasoning, particularly when both planning and execution are involved. To overcome these limitations, we propose CREATOR, a novel framework that enables LLMs to create their own tools using documentation and code realization. CREATOR disentangles abstract tool creation and concrete decision execution, resulting in improved performance. We evaluate CREATOR on MATH and TabMWP benchmarks, respectively consisting of challenging math competition problems and diverse tabular contents. Remarkably, CREATOR outperforms existing chain-of-thought, program-of-thought, and tool-using baselines. Additionally, we introduce the Creation Challenge dataset, featuring 2K diverse questions, to emphasize the necessity and benefits of LLMs' tool creation ability. Further research demonstrates that leveraging LLMs as tool creators facilitates knowled
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20854;&#33258;&#36523;&#30693;&#35782;&#30340;&#29702;&#35299;&#21644;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#30340;&#33021;&#21147;&#12290;&#35813;&#30740;&#31350;&#32858;&#28966;&#20110;&#35299;&#20915;&#8220;&#24050;&#30693;-&#26410;&#30693;&#8221;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#20998;&#31867;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#35821;&#20041;&#35780;&#20272;&#26041;&#27861;&#37327;&#21270;&#20102;&#27169;&#22411;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.13712</link><description>&lt;p&gt;
&#30693;&#35782;&#30340;&#30693;&#35782;&#65306;&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26410;&#30693;-&#24050;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models. (arXiv:2305.13712v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20854;&#33258;&#36523;&#30693;&#35782;&#30340;&#29702;&#35299;&#21644;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#30340;&#33021;&#21147;&#12290;&#35813;&#30740;&#31350;&#32858;&#28966;&#20110;&#35299;&#20915;&#8220;&#24050;&#30693;-&#26410;&#30693;&#8221;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#20998;&#31867;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#35821;&#20041;&#35780;&#20272;&#26041;&#27861;&#37327;&#21270;&#20102;&#27169;&#22411;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#29702;&#35299;&#33258;&#36523;&#30693;&#35782;&#21644;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#20197;&#32531;&#35299;&#34394;&#26500;&#29616;&#35937;&#12290;&#25105;&#20204;&#19987;&#38376;&#20851;&#27880;&#35299;&#20915;&#8220;&#24050;&#30693;-&#26410;&#30693;&#8221;&#38382;&#39064;&#65292;&#36825;&#31181;&#38382;&#39064;&#30001;&#20110;&#32570;&#20047;&#30830;&#23450;&#30340;&#31572;&#26696;&#32780;&#20855;&#26377;&#39640;&#24230;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#20419;&#36827;&#25105;&#20204;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20010;&#26032;&#30340;&#24050;&#30693;-&#26410;&#30693;&#38382;&#39064;&#65288;KUQ&#65289;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#26041;&#26696;&#26469;&#38416;&#26126;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#35780;&#20272;LLM&#21306;&#20998;&#24050;&#30693;&#21644;&#26410;&#30693;&#38382;&#39064;&#20197;&#21450;&#30456;&#24212;&#20998;&#31867;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#24320;&#25918;&#24335;QA&#29615;&#22659;&#20013;&#35780;&#20272;LLM&#30340;&#31572;&#26696;&#36136;&#37327;&#12290;&#20026;&#20102;&#37327;&#21270;&#31572;&#26696;&#20013;&#34920;&#36798;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#35821;&#20041;&#35780;&#20272;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#27169;&#22411;&#22312;&#34920;&#36798;&#24050;&#30693;vs&#26410;&#30693;&#38382;&#39064;&#30340;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the capabilities of Large Language Models (LLMs) in the context of understanding their own knowledge and measuring their uncertainty. We argue this is an important feature for mitigating hallucinations. Specifically, we focus on addressing \textit{known-unknown} questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a dataset with new Known-Unknown Questions (KUQ) and propose a novel categorization scheme to elucidate the sources of uncertainty. Subsequently, we assess the LLMs' ability to differentiate between known and unknown questions and classify them accordingly. Moreover, we evaluate the quality of their answers in an Open-Ended QA setting. To quantify the uncertainty expressed in the answers, we create a semantic evaluation method that measures the model's accuracy in expressing uncertainty between known vs unknown questions.
&lt;/p&gt;</description></item></channel></rss>