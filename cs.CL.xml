<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#20063;&#38754;&#20020;&#30528;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#26412;&#35843;&#26597;&#20840;&#38754;&#23457;&#26597;&#20102;LLM&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65292;&#28085;&#30422;&#20102;&#35757;&#32451;&#25968;&#25454;&#12289;&#29992;&#25143;&#21644;&#24212;&#29992;&#39118;&#38505;&#31561;&#26041;&#38754;&#65292;&#24182;&#23545;&#35299;&#20915;&#26041;&#27861;&#36827;&#34892;&#20102;&#22238;&#39038;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00888</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Security and Privacy Challenges of Large Language Models: A Survey
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00888
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#20063;&#38754;&#20020;&#30528;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#26412;&#35843;&#26597;&#20840;&#38754;&#23457;&#26597;&#20102;LLM&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65292;&#28085;&#30422;&#20102;&#35757;&#32451;&#25968;&#25454;&#12289;&#29992;&#25143;&#21644;&#24212;&#29992;&#39118;&#38505;&#31561;&#26041;&#38754;&#65292;&#24182;&#23545;&#35299;&#20915;&#26041;&#27861;&#36827;&#34892;&#20102;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23637;&#31034;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#29983;&#25104;&#21644;&#24635;&#32467;&#25991;&#26412;&#12289;&#35821;&#35328;&#32763;&#35793;&#21644;&#38382;&#31572;&#31561;&#22810;&#20010;&#39046;&#22495;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#22914;&#20170;&#65292;LLM&#27491;&#22312;&#25104;&#20026;&#35745;&#31639;&#26426;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#38750;&#24120;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#20855;&#22791;&#20998;&#26512;&#22797;&#26434;&#35821;&#35328;&#27169;&#24335;&#24182;&#26681;&#25454;&#19978;&#19979;&#25991;&#25552;&#20379;&#30456;&#20851;&#21644;&#36866;&#24403;&#22238;&#31572;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#65292;&#36825;&#20123;&#27169;&#22411;&#20063;&#23481;&#26131;&#21463;&#21040;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#65292;&#22914;&#36234;&#29425;&#25915;&#20987;&#12289;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#21644;&#20010;&#20154;&#21487;&#35782;&#21035;&#20449;&#24687;&#27844;&#38706;&#25915;&#20987;&#12290;&#26412;&#35843;&#26597;&#20840;&#38754;&#23457;&#26597;&#20102;LLM&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65292;&#21253;&#25324;&#35757;&#32451;&#25968;&#25454;&#21644;&#29992;&#25143;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#22312;&#20132;&#36890;&#12289;&#25945;&#32946;&#21644;&#21307;&#30103;&#31561;&#21508;&#20010;&#39046;&#22495;&#20013;&#24212;&#29992;&#24102;&#26469;&#30340;&#39118;&#38505;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;LLM&#30340;&#33030;&#24369;&#24615;&#31243;&#24230;&#65292;&#35843;&#26597;&#20102;&#20986;&#29616;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#65292;&#24182;&#23545;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#27861;&#36827;&#34892;&#20102;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Nowadays, LLM is becoming a very popular tool in computerized language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant and appropriate responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and Personally Identifiable Information (PII) leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs for both training data and users, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks for LLMs, and review the potent
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#20943;&#32531;&#39640;&#36164;&#28304;&#35821;&#35328;&#21644;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21644;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14279</link><description>&lt;p&gt;
&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#20943;&#32531;&#35821;&#35328;&#24046;&#24322;&#65292;&#23454;&#29616;&#31283;&#20581;&#30340;&#22810;&#35821;&#35328;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Mitigating the Linguistic Gap with Phonemic Representations for Robust Multilingual Language Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14279
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#20943;&#32531;&#39640;&#36164;&#28304;&#35821;&#35328;&#21644;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21644;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25913;&#21892;&#22810;&#35821;&#35328;&#29702;&#35299;&#65292;&#36890;&#24120;&#38656;&#35201;&#22312;&#35757;&#32451;&#38454;&#27573;&#20351;&#29992;&#22810;&#31181;&#35821;&#35328;&#65292;&#20381;&#36182;&#22797;&#26434;&#30340;&#35757;&#32451;&#25216;&#26415;&#65292;&#24182;&#19988;&#22312;&#39640;&#36164;&#28304;&#35821;&#35328;&#21644;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;&#25105;&#20204;&#20551;&#35774;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#21463;&#21040;&#36825;&#20123;&#35821;&#35328;&#20043;&#38388;&#30340;&#35821;&#35328;&#24046;&#24322;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#65288;&#20855;&#20307;&#26469;&#35828;&#65292;&#23558;&#38899;&#32032;&#20316;&#20026;&#36755;&#20837;&#26631;&#35760;&#36755;&#20837;&#21040;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#32780;&#19981;&#26159;&#23376;&#35789;&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#23454;&#29616;&#31283;&#20581;&#30340;&#22810;&#35821;&#35328;&#24314;&#27169;&#12290;&#25105;&#20204;&#36890;&#36807;&#19977;&#20010;&#36328;&#35821;&#35328;&#20219;&#21153;&#30340;&#23450;&#37327;&#35777;&#25454;&#23637;&#31034;&#20102;&#38899;&#32032;&#34920;&#31034;&#30340;&#26377;&#25928;&#24615;&#65292;&#36825;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#23545;&#36328;&#35821;&#35328;&#24615;&#33021;&#24046;&#36317;&#30340;&#29702;&#35770;&#20998;&#26512;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14279v1 Announce Type: cross  Abstract: Approaches to improving multilingual language understanding often require multiple languages during the training phase, rely on complicated training techniques, and -- importantly -- struggle with significant performance gaps between high-resource and low-resource languages. We hypothesize that the performance gaps between languages are affected by linguistic gaps between those languages and provide a novel solution for robust multilingual language modeling by employing phonemic representations (specifically, using phonemes as input tokens to LMs rather than subwords). We present quantitative evidence from three cross-lingual tasks that demonstrate the effectiveness of phonemic representation, which is further justified by a theoretical analysis of the cross-lingual performance gap.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;REBORN&#65292;&#22312;&#26080;&#30417;&#30563;&#35821;&#38899;&#35782;&#21035;&#20013;&#20351;&#29992;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#36845;&#20195;&#35757;&#32451;&#26469;&#23454;&#29616;&#36793;&#30028;&#20998;&#21106;&#12290;&#36890;&#36807;&#20132;&#26367;&#35757;&#32451;&#20998;&#21106;&#27169;&#22411;&#21644;&#38899;&#32032;&#39044;&#27979;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#23398;&#20064;&#35821;&#38899;&#21644;&#25991;&#26412;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#35821;&#38899;&#20449;&#21495;&#20998;&#27573;&#32467;&#26500;&#36793;&#30028;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.03988</link><description>&lt;p&gt;
REBORN: &#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#36845;&#20195;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#35821;&#38899;&#35782;&#21035;&#20013;&#30340;&#36793;&#30028;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
REBORN: Reinforcement-Learned Boundary Segmentation with Iterative Training for Unsupervised ASR
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;REBORN&#65292;&#22312;&#26080;&#30417;&#30563;&#35821;&#38899;&#35782;&#21035;&#20013;&#20351;&#29992;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#36845;&#20195;&#35757;&#32451;&#26469;&#23454;&#29616;&#36793;&#30028;&#20998;&#21106;&#12290;&#36890;&#36807;&#20132;&#26367;&#35757;&#32451;&#20998;&#21106;&#27169;&#22411;&#21644;&#38899;&#32032;&#39044;&#27979;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#23398;&#20064;&#35821;&#38899;&#21644;&#25991;&#26412;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#35821;&#38899;&#20449;&#21495;&#20998;&#27573;&#32467;&#26500;&#36793;&#30028;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#26088;&#22312;&#23398;&#20064;&#35821;&#38899;&#20449;&#21495;&#19982;&#20854;&#23545;&#24212;&#30340;&#25991;&#26412;&#36716;&#24405;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#32780;&#26080;&#38656;&#37197;&#23545;&#30340;&#35821;&#38899;-&#25991;&#26412;&#25968;&#25454;&#30417;&#30563;&#12290;&#35821;&#38899;&#20449;&#21495;&#20013;&#30340;&#21333;&#35789;/&#38899;&#32032;&#30001;&#19968;&#27573;&#38271;&#24230;&#21487;&#21464;&#19988;&#36793;&#30028;&#26410;&#30693;&#30340;&#35821;&#38899;&#20449;&#21495;&#34920;&#31034;&#65292;&#32780;&#36825;&#31181;&#20998;&#27573;&#32467;&#26500;&#20351;&#24471;&#22312;&#27809;&#26377;&#37197;&#23545;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#35821;&#38899;&#21644;&#25991;&#26412;&#20043;&#38388;&#30340;&#26144;&#23556;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;REBORN&#65292;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#36845;&#20195;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#35821;&#38899;&#35782;&#21035;&#20013;&#30340;&#36793;&#30028;&#20998;&#21106;&#12290;REBORN&#20132;&#26367;&#36827;&#34892;&#20197;&#19979;&#20004;&#20010;&#27493;&#39588;&#65306;&#65288;1&#65289;&#35757;&#32451;&#19968;&#20010;&#33021;&#22815;&#39044;&#27979;&#35821;&#38899;&#20449;&#21495;&#20013;&#20998;&#27573;&#32467;&#26500;&#36793;&#30028;&#30340;&#20998;&#21106;&#27169;&#22411;&#65292;&#21644;&#65288;2&#65289;&#35757;&#32451;&#19968;&#20010;&#38899;&#32032;&#39044;&#27979;&#27169;&#22411;&#65292;&#20854;&#36755;&#20837;&#26159;&#30001;&#20998;&#21106;&#27169;&#22411;&#20998;&#21106;&#30340;&#20998;&#27573;&#32467;&#26500;&#65292;&#29992;&#20110;&#39044;&#27979;&#38899;&#32032;&#36716;&#24405;&#12290;&#30001;&#20110;&#27809;&#26377;&#29992;&#20110;&#35757;&#32451;&#20998;&#21106;&#27169;&#22411;&#30340;&#30417;&#30563;&#25968;&#25454;&#65292;&#25105;&#20204;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#35757;&#32451;&#20998;&#21106;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised automatic speech recognition (ASR) aims to learn the mapping between the speech signal and its corresponding textual transcription without the supervision of paired speech-text data. A word/phoneme in the speech signal is represented by a segment of speech signal with variable length and unknown boundary, and this segmental structure makes learning the mapping between speech and text challenging, especially without paired data. In this paper, we propose REBORN, Reinforcement-Learned Boundary Segmentation with Iterative Training for Unsupervised ASR. REBORN alternates between (1) training a segmentation model that predicts the boundaries of the segmental structures in speech signals and (2) training the phoneme prediction model, whose input is a segmental structure segmented by the segmentation model, to predict a phoneme transcription. Since supervised data for training the segmentation model is not available, we use reinforcement learning to train the segmentation model t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;GPT-4&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KG&#25512;&#29702;&#30340;LLM&#22522;&#20934;&#20195;&#29702;&#65288;LLM-ARK&#65289;&#65292;&#35813;&#20195;&#29702;&#21033;&#29992;&#20840;&#25991;&#29615;&#22659;&#25552;&#31034;&#26469;&#23454;&#29616;&#31934;&#30830;&#21644;&#36866;&#24212;&#24615;&#24378;&#30340;KG&#36335;&#24452;&#39044;&#27979;&#65292;&#24182;&#37319;&#29992;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>https://arxiv.org/abs/2312.11282</link><description>&lt;p&gt;
&#35780;&#20272;&#21644;&#22686;&#24378;&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Evaluating and Enhancing Large Language Models for Conversational Reasoning on Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11282
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;GPT-4&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KG&#25512;&#29702;&#30340;LLM&#22522;&#20934;&#20195;&#29702;&#65288;LLM-ARK&#65289;&#65292;&#35813;&#20195;&#29702;&#21033;&#29992;&#20840;&#25991;&#29615;&#22659;&#25552;&#31034;&#26469;&#23454;&#29616;&#31934;&#30830;&#21644;&#36866;&#24212;&#24615;&#24378;&#30340;KG&#36335;&#24452;&#39044;&#27979;&#65292;&#24182;&#37319;&#29992;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21457;&#23637;&#24471;&#30410;&#20110;&#39044;&#35757;&#32451;&#25216;&#26415;&#30340;&#36827;&#23637;&#12290;&#36890;&#36807;&#25163;&#21160;&#35774;&#35745;&#30340;&#25552;&#31034;&#65292;&#36825;&#20123;&#27169;&#22411;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;LLM&#65288;GPT-4&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;KG&#29615;&#22659;&#24847;&#35782;&#21644;&#24320;&#21457;&#26377;&#25928;&#30340;&#20013;&#38388;&#25512;&#29702;&#38454;&#27573;&#20248;&#21270;&#26426;&#21046;&#30340;&#22256;&#38590;&#65292;LLM&#30340;&#24615;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24341;&#20837;&#20102;LLM-ARK&#65292;&#19968;&#20010;&#22522;&#20110;KG&#25512;&#29702;&#30340;LLM&#22522;&#20934;&#20195;&#29702;&#65292;&#26088;&#22312;&#25552;&#20379;&#31934;&#30830;&#21644;&#36866;&#24212;&#24615;&#24378;&#30340;KG&#36335;&#24452;&#39044;&#27979;&#12290;LLM-ARK&#21033;&#29992;&#20840;&#25991;&#29615;&#22659;&#65288;FTE&#65289;&#25552;&#31034;&#26469;&#21560;&#25910;&#27599;&#20010;&#25512;&#29702;&#27493;&#39588;&#20013;&#30340;&#29366;&#24577;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;KG&#19978;&#30340;&#22810;&#36339;&#25512;&#29702;&#25361;&#25112;&#37325;&#26032;&#26694;&#23450;&#20026;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#12290;&#21033;&#29992;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;PPO&#65289;&#22312;&#32447;&#31574;&#30053;&#26799;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;...
&lt;/p&gt;
&lt;p&gt;
The development of large language models (LLMs) has been catalyzed by advancements in pre-training techniques. These models have demonstrated robust reasoning capabilities through manually designed prompts. In this work, we evaluate the conversational reasoning capabilities of the current state-of-the-art LLM (GPT-4) on knowledge graphs (KGs). However, the performance of LLMs is constrained due to a lack of KG environment awareness and the difficulties in developing effective optimization mechanisms for intermediary reasoning stages. We further introduce LLM-ARK, a LLM grounded KG reasoning agent designed to deliver precise and adaptable predictions on KG paths. LLM-ARK leverages Full Textual Environment (FTE) prompt to assimilate state information within each reasoning step. We reframe the challenge of multi-hop reasoning on the KG as a sequential decision-making task. Utilizing the Proximal Policy Optimization (PPO) online policy gradient reinforcement learning algorithm, our model i
&lt;/p&gt;</description></item></channel></rss>