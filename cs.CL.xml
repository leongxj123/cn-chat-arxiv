<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#27454;&#20851;&#20110;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#23458;&#26435;&#21033;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#24110;&#21161;&#26053;&#23458;&#29702;&#35299;&#21644;&#21033;&#29992;&#30456;&#20851;&#31354;&#20013;&#26053;&#34892;&#27861;&#35268;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#29992;&#25143;&#36755;&#20837;&#22797;&#26434;&#21644;&#20934;&#30830;&#22238;&#31572;&#38382;&#39064;&#30340;&#25361;&#25112;</title><link>https://arxiv.org/abs/2403.12678</link><description>&lt;p&gt;
&#20026;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#34892;&#32773;&#36171;&#26435;&#65306;&#19968;&#27454;&#20851;&#20110;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#23458;&#26435;&#21033;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;
&lt;/p&gt;
&lt;p&gt;
Empowering Air Travelers: A Chatbot for Canadian Air Passenger Rights
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12678
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#27454;&#20851;&#20110;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#23458;&#26435;&#21033;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#24110;&#21161;&#26053;&#23458;&#29702;&#35299;&#21644;&#21033;&#29992;&#30456;&#20851;&#31354;&#20013;&#26053;&#34892;&#27861;&#35268;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#29992;&#25143;&#36755;&#20837;&#22797;&#26434;&#21644;&#20934;&#30830;&#22238;&#31572;&#38382;&#39064;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21152;&#25343;&#22823;&#33322;&#31354;&#26053;&#34892;&#39046;&#22495;&#30340;&#33322;&#29677;&#24310;&#35823;&#12289;&#21462;&#28040;&#21644;&#20854;&#20182;&#20851;&#20110;&#26053;&#23458;&#26435;&#21033;&#30340;&#38382;&#39064;&#26377;&#20102;&#26174;&#33879;&#22686;&#21152;&#12290;&#35748;&#35782;&#21040;&#36825;&#19968;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32842;&#22825;&#26426;&#22120;&#20154;&#26469;&#21327;&#21161;&#26053;&#23458;&#24182;&#25945;&#32946;&#20182;&#20204;&#20102;&#35299;&#33258;&#24049;&#30340;&#26435;&#21033;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#23558;&#22797;&#26434;&#30340;&#29992;&#25143;&#36755;&#20837;&#20998;&#35299;&#20026;&#31616;&#21333;&#30340;&#26597;&#35810;&#65292;&#29992;&#20110;&#26816;&#32034;&#35814;&#32454;&#31354;&#20013;&#26053;&#34892;&#27861;&#35268;&#30340;&#25991;&#26723;&#38598;&#20013;&#30340;&#20449;&#24687;&#12290;&#20174;&#36825;&#20123;&#25991;&#26723;&#20013;&#25552;&#21462;&#26368;&#30456;&#20851;&#30340;&#27573;&#33853;&#65292;&#24182;&#25552;&#20379;&#21407;&#22987;&#25991;&#26723;&#21644;&#29983;&#25104;&#30340;&#26597;&#35810;&#30340;&#38142;&#25509;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#23558;&#20449;&#24687;&#32454;&#20998;&#24182;&#21033;&#29992;&#20110;&#20854;&#29420;&#29305;&#24773;&#20917;&#12290;&#35813;&#31995;&#32479;&#25104;&#21151;&#20811;&#26381;&#20102;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#29702;&#35299;&#22797;&#26434;&#30340;&#29992;&#25143;&#36755;&#20837;&#65292;&#24182;&#25552;&#20379;&#20934;&#30830;&#31572;&#26696;&#65292;&#27809;&#26377;&#24187;&#35273;&#65292;&#36825;&#20123;&#31572;&#26696;&#21487;&#20197;&#20379;&#26053;&#23458;&#20381;&#36182;&#20197;&#20570;&#20986;&#26126;&#26234;&#20915;&#31574;&#12290;&#19968;&#39033;&#27604;&#36739;&#32842;&#22825;&#26426;&#22120;&#20154;&#21644;&#35895;&#27468;&#25628;&#32034;&#30340;&#29992;&#25143;&#30740;&#31350;&#23637;&#31034;&#20102;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#23454;&#29992;&#24615;&#21644;&#26131;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12678v1 Announce Type: cross  Abstract: The Canadian air travel sector has seen a significant increase in flight delays, cancellations, and other issues concerning passenger rights. Recognizing this demand, we present a chatbot to assist passengers and educate them about their rights. Our system breaks a complex user input into simple queries which are used to retrieve information from a collection of documents detailing air travel regulations. The most relevant passages from these documents are presented along with links to the original documents and the generated queries, enabling users to dissect and leverage the information for their unique circumstances. The system successfully overcomes two predominant challenges: understanding complex user inputs, and delivering accurate answers, free of hallucinations, that passengers can rely on for making informed decisions. A user study comparing the chatbot to a Google search demonstrated the chatbot's usefulness and ease of use.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.11894</link><description>&lt;p&gt;
&#20174;&#21487;&#35299;&#37322;&#21040;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#30103;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24212;&#29992;&#65306;&#29616;&#23454;&#26377;&#22810;&#36828;&#65311;
&lt;/p&gt;
&lt;p&gt;
From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11894
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#36890;&#36807;&#35299;&#20915;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#65292;&#26497;&#22823;&#22320;&#22686;&#24378;&#20102;&#21307;&#30103;&#20445;&#20581;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;DL&#30340;NLP&#26041;&#27861;&#26085;&#30410;&#22797;&#26434;&#65292;&#38656;&#35201;&#36879;&#26126;&#30340;&#27169;&#22411;&#35299;&#37322;&#24615;&#65292;&#25110;&#33267;&#23569;&#26159;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#36827;&#34892;&#21487;&#38752;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;&#26412;&#25991;&#23545;&#21307;&#30103;&#20581;&#24247;NLP&#20013;&#30340;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;DL&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#33539;&#22260;&#23457;&#26597;&#12290;&#24341;&#20837;&#20102;&#26415;&#35821;&#8220;XIAI&#8221;&#65288;eXplainable&#21644;Interpretable Artificial Intelligence&#65289;&#20197;&#21306;&#20998;XAI&#21644;IAI&#12290;&#26041;&#27861;&#26681;&#25454;&#20854;&#21151;&#33021;&#65288;&#27169;&#22411;&#12289;&#36755;&#20837;&#12289;&#36755;&#20986;&#20026;&#22522;&#30784;&#65289;&#21644;&#33539;&#22260;&#65288;&#23616;&#37096;&#12289;&#20840;&#23616;&#65289;&#36827;&#19968;&#27493;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#27880;&#24847;&#26426;&#21046;&#26159;&#26368;&#20027;&#35201;&#30340;&#26032;&#20852;IAI&#12290;&#27492;&#22806;&#65292;IAI&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20110;&#23545;&#25239;XAI&#12290;&#30830;&#23450;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22823;&#22810;&#25968;XIAI&#19981;&#25506;&#32034;&#8220;&#20840;&#23616;&#8221;&#24314;&#27169;&#36807;&#31243;&#65292;&#32570;&#20047;&#26368;&#20339;&#23454;&#36341;&#65292;&#24182;&#19988;&#38656;&#35201;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11894v1 Announce Type: cross  Abstract: Deep learning (DL) has substantially enhanced healthcare research by addressing various natural language processing (NLP) tasks. Yet, the increasing complexity of DL-based NLP methods necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review on explainable and interpretable DL in healthcare NLP. The term "XIAI" (eXplainable and Interpretable Artificial Intelligence) was introduced to distinguish XAI from IAI. Methods were further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms were the most dominant emerging IAI. Moreover, IAI is increasingly used against XAI. The major challenges identified are that most XIAI do not explore "global" modeling processes, the lack of best practices, and the unmet need for systematic evaluation and benchmarks. Importan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#23569;&#26679;&#26412;&#25512;&#21160;&#25512;&#29702;&#30340;&#38142;&#24335;&#24605;&#32500;&#39537;&#21160;LLMs&#29992;&#20110;&#24320;&#25918;&#24335;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#65292;&#36890;&#36807;&#20462;&#25913;MedQA-USMLE&#25968;&#25454;&#38598;&#24182;&#37319;&#29992;&#22870;&#21169;&#35757;&#32451;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#22312;&#21307;&#30103;&#22330;&#26223;&#20013;&#27491;&#30830;&#21709;&#24212;&#20020;&#24202;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.04890</link><description>&lt;p&gt;
&#22522;&#20110;&#23569;&#26679;&#26412;&#25512;&#21160;&#25512;&#29702;&#30340;&#38142;&#24335;&#24605;&#32500;&#39537;&#21160;LLMs&#29992;&#20110;&#24320;&#25918;&#24335;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;
&lt;/p&gt;
&lt;p&gt;
Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#23569;&#26679;&#26412;&#25512;&#21160;&#25512;&#29702;&#30340;&#38142;&#24335;&#24605;&#32500;&#39537;&#21160;LLMs&#29992;&#20110;&#24320;&#25918;&#24335;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#65292;&#36890;&#36807;&#20462;&#25913;MedQA-USMLE&#25968;&#25454;&#38598;&#24182;&#37319;&#29992;&#22870;&#21169;&#35757;&#32451;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#22312;&#21307;&#30103;&#22330;&#26223;&#20013;&#27491;&#30830;&#21709;&#24212;&#20020;&#24202;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#23637;&#31034;&#20102;&#22312;&#36716;&#21464;&#21307;&#30103;&#20445;&#20581;&#26041;&#38754;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#35832;&#22914;&#20020;&#24202;&#25991;&#26723;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#20915;&#31574;&#25903;&#25345;&#31561;&#20219;&#21153;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#24050;&#32463;&#25104;&#20026;&#22312;&#21307;&#30103;&#22330;&#26223;&#20013;&#20351;&#29992;LLMs&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#20363;&#22914;&#24739;&#32773;&#20020;&#24202;&#22330;&#26223;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MedQA-USMLE&#25968;&#25454;&#38598;&#30340;&#20462;&#25913;&#29256;&#26412;&#65292;&#30446;&#30340;&#26159;&#27169;&#25311;&#30495;&#23454;&#20020;&#24202;&#22330;&#26223;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#22522;&#20110;&#20027;&#35266;&#21709;&#24212;&#29983;&#25104;&#30340;Chain of Thought&#65288;CoT&#65289;&#25512;&#29702;&#65292;&#29992;&#20110;&#20462;&#25913;&#21518;&#30340;MedQA-USMLE&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;LM&#39537;&#21160;&#21069;&#21521;&#25512;&#29702;&#26469;&#33719;&#24471;&#27491;&#30830;&#30340;&#21307;&#23398;&#38382;&#39064;&#31572;&#26696;&#12290;&#32771;&#34385;&#21040;&#22312;&#21307;&#30103;&#29615;&#22659;&#20013;&#21709;&#24212;&#39564;&#35777;&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#21033;&#29992;&#22870;&#21169;&#35757;&#32451;&#26426;&#21046;&#65292;&#20854;&#20013;&#35821;&#35328;&#27169;&#22411;&#36824;&#20026;&#29305;&#23450;&#30340;&#20020;&#24202;&#38382;&#39064;&#22238;&#24212;&#25552;&#20379;&#20102;&#36866;&#24403;&#30340;&#39564;&#35777;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04890v1 Announce Type: new  Abstract: Large Language models (LLMs) have demonstrated significant potential in transforming healthcare by automating tasks such as clinical documentation, information retrieval, and decision support. In this aspect, carefully engineered prompts have emerged as a powerful tool for using LLMs for medical scenarios, e.g., patient clinical scenarios. In this paper, we propose a modified version of the MedQA-USMLE dataset, which is subjective, to mimic real-life clinical scenarios. We explore the Chain of Thought (CoT) reasoning based on subjective response generation for the modified MedQA-USMLE dataset with appropriate LM-driven forward reasoning for correct responses to the medical questions. Keeping in mind the importance of response verification in the medical setting, we utilize a reward training mechanism whereby the language model also provides an appropriate verified response for a particular response to a clinical question. In this regard,
&lt;/p&gt;</description></item><item><title>CLongEval&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#38271;&#19978;&#19979;&#25991;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#20840;&#38754;&#20013;&#25991;&#22522;&#20934;&#65292;&#20855;&#26377;&#36275;&#22815;&#30340;&#25968;&#25454;&#37327;&#12289;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#21644;&#39640;&#36136;&#37327;&#65292;&#21487;&#20197;&#23545;&#22810;&#20010;&#24320;&#28304;&#21644;&#21830;&#19994;&#27169;&#22411;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2403.03514</link><description>&lt;p&gt;
CLongEval: &#29992;&#20110;&#35780;&#20272;&#38271;&#19978;&#19979;&#25991;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#20013;&#25991;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03514
&lt;/p&gt;
&lt;p&gt;
CLongEval&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#38271;&#19978;&#19979;&#25991;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#20840;&#38754;&#20013;&#25991;&#22522;&#20934;&#65292;&#20855;&#26377;&#36275;&#22815;&#30340;&#25968;&#25454;&#37327;&#12289;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#21644;&#39640;&#36136;&#37327;&#65292;&#21487;&#20197;&#23545;&#22810;&#20010;&#24320;&#28304;&#21644;&#21830;&#19994;&#27169;&#22411;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03514v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#24320;&#21457;&#20855;&#26377;&#24378;&#22823;&#38271;&#19978;&#19979;&#25991;&#33021;&#21147;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#19968;&#30452;&#26159;&#26368;&#36817;&#30340;&#30740;&#31350;&#37325;&#28857;&#65292;&#23548;&#33268;&#38271;&#19978;&#19979;&#25991;&#20013;&#25991;&#33021;&#21147;&#23092;&#29087;&#30340;LLMs&#30340;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#22522;&#20934;&#27979;&#35797;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#35780;&#20272;&#20173;&#28982;&#19981;&#22815;&#23436;&#21892;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;CLongEval&#65292;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#38271;&#19978;&#19979;&#25991;LLMs&#30340;&#20840;&#38754;&#20013;&#25991;&#22522;&#20934;&#12290;CLongEval&#20855;&#26377;&#19977;&#20010;&#20851;&#38190;&#29305;&#24449;&#65306;(1)&#36275;&#22815;&#30340;&#25968;&#25454;&#37327;&#65292;&#21253;&#25324;7&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#21644;7,267&#20010;&#31034;&#20363;&#65307;(2)&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#36866;&#29992;&#20110;&#19978;&#19979;&#25991;&#31383;&#21475;&#22823;&#23567;&#20174;1K&#21040;100K&#30340;&#27169;&#22411;&#65307;(3)&#39640;&#36136;&#37327;&#65292;&#38500;&#20102;&#33258;&#21160;&#26500;&#24314;&#30340;&#26631;&#31614;&#22806;&#65292;&#36824;&#26377;&#36229;&#36807;2,000&#20010;&#25163;&#24037;&#27880;&#37322;&#30340;&#38382;&#31572;&#23545;&#12290;&#20511;&#21161;CLongEval&#65292;&#25105;&#20204;&#23545;6&#20010;&#24320;&#28304;&#38271;&#19978;&#19979;&#25991;LLMs&#21644;2&#20010;&#20855;&#26377;&#38271;&#19978;&#19979;&#25991;&#33021;&#21147;&#21644;&#20013;&#25991;&#29087;&#32451;&#24230;&#30340;&#39046;&#20808;&#21830;&#19994;&#31454;&#20105;&#23545;&#25163;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03514v1 Announce Type: new  Abstract: Developing Large Language Models (LLMs) with robust long-context capabilities has been the recent research focus, resulting in the emergence of long-context LLMs proficient in Chinese. However, the evaluation of these models remains underdeveloped due to a lack of benchmarks. To address this gap, we present CLongEval, a comprehensive Chinese benchmark for evaluating long-context LLMs. CLongEval is characterized by three key features: (1) Sufficient data volume, comprising 7 distinct tasks and 7,267 examples; (2) Broad applicability, accommodating to models with context windows size from 1K to 100K; (3) High quality, with over 2,000 manually annotated question-answer pairs in addition to the automatically constructed labels. With CLongEval, we undertake a comprehensive assessment of 6 open-source long-context LLMs and 2 leading commercial counterparts that feature both long-context abilities and proficiency in Chinese. We also provide in-
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25191;&#34892;&#25968;&#20540;&#35745;&#31639;&#26102;&#32463;&#24120;&#20986;&#38169;&#65292;&#36890;&#36807;&#29983;&#25104;&#21487;&#25191;&#34892;&#20195;&#30721;&#26469;&#35299;&#20915;&#38382;&#39064;&#21487;&#20197;&#20943;&#23569;&#35745;&#31639;&#38169;&#35823;&#65292;&#20294;&#35266;&#23519;&#21040;&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20351;&#29992;&#20195;&#30721;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26102;&#65292;&#20250;&#29983;&#25104;&#26356;&#22810;&#19981;&#27491;&#30830;&#25512;&#29702;&#65307;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#20154;&#31867;&#32534;&#30721;&#23454;&#36341;&#21551;&#21457;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#26041;&#27861;Human-Think Language&#65288;HTL&#65289;&#12290;</title><link>https://arxiv.org/abs/2402.15729</link><description>&lt;p&gt;
&#20154;&#31867;&#26159;&#22914;&#20309;&#32534;&#20889;&#20195;&#30721;&#30340;&#65311;&#22823;&#22411;&#27169;&#22411;&#20063;&#20197;&#21516;&#26679;&#30340;&#26041;&#24335;&#36827;&#34892;
&lt;/p&gt;
&lt;p&gt;
How Do Humans Write Code? Large Models Do It the Same Way Too
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15729
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25191;&#34892;&#25968;&#20540;&#35745;&#31639;&#26102;&#32463;&#24120;&#20986;&#38169;&#65292;&#36890;&#36807;&#29983;&#25104;&#21487;&#25191;&#34892;&#20195;&#30721;&#26469;&#35299;&#20915;&#38382;&#39064;&#21487;&#20197;&#20943;&#23569;&#35745;&#31639;&#38169;&#35823;&#65292;&#20294;&#35266;&#23519;&#21040;&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20351;&#29992;&#20195;&#30721;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26102;&#65292;&#20250;&#29983;&#25104;&#26356;&#22810;&#19981;&#27491;&#30830;&#25512;&#29702;&#65307;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#20154;&#31867;&#32534;&#30721;&#23454;&#36341;&#21551;&#21457;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#26041;&#27861;Human-Think Language&#65288;HTL&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25191;&#34892;&#25968;&#20540;&#35745;&#31639;&#26102;&#32463;&#24120;&#20986;&#38169;&#12290;&#19982;&#20256;&#32479;&#30340;&#24605;&#32500;&#38142;&#25512;&#29702;&#30456;&#27604;&#65292;&#31243;&#24207;&#21270;&#24605;&#32500;&#26041;&#27861;&#28041;&#21450;&#29983;&#25104;&#21487;&#25191;&#34892;&#20195;&#30721;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#36890;&#36807;&#25191;&#34892;&#36825;&#20123;&#20195;&#30721;&#65292;&#23427;&#21487;&#20197;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#29983;&#25104;&#30340;&#21487;&#25191;&#34892;&#20195;&#30721;&#32780;&#19981;&#26159;&#33258;&#28982;&#35821;&#35328;&#21487;&#20197;&#20943;&#23569;&#35745;&#31639;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#24403;LLMs&#20351;&#29992;&#20195;&#30721;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26102;&#65292;&#20182;&#20204;&#24448;&#24448;&#29983;&#25104;&#27604;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#26356;&#22810;&#30340;&#19981;&#27491;&#30830;&#25512;&#29702;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Human-Think Language&#65288;HTL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#21040;&#20154;&#31867;&#32534;&#30721;&#23454;&#36341;&#21551;&#21457;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#30001;&#27169;&#22411;&#29983;&#25104;&#29992;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35299;&#20915;&#38382;&#39064;&#26041;&#27861;&#65292;&#28982;&#21518;&#23558;&#20854;&#36716;&#25442;&#20026;&#20195;&#30721;&#65292;&#21453;&#26144;&#20986;&#20154;&#20204;&#22312;&#23558;&#36923;&#36753;&#20197;&#33258;&#28982;&#35821;&#35328;&#24418;&#24335;&#24605;&#32771;&#21518;&#20877;&#23558;&#20854;&#20889;&#25104;&#20195;&#30721;&#30340;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#23427;&#21033;&#29992;&#20102;P
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15729v1 Announce Type: new  Abstract: Large Language Models (LLMs) often make errors when performing numerical calculations. In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach involves generating executable code to solve problems. By executing this code, it achieves more precise results. Using generated executable code instead of natural language can reduce computational errors. However, we observe that when LLMs solve mathematical problems using code, they tend to generate more incorrect reasoning than when using natural language. To address this issue, we propose Human-Think Language (HTL), a straightforward yet highly efficient approach inspired by human coding practices. The approach first generates problem-solving methods described in the natural language by the model, then converts them into code, mirroring the process where people think through the logic in natural language before writing it as code. Additionally, it utilizes the P
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;COMPASS&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#26512;&#24515;&#29702;&#27835;&#30103;&#20250;&#35805;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#65292;&#30452;&#25509;&#25512;&#26029;&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#65292;&#20026;&#20020;&#24202;&#31934;&#31070;&#30149;&#23398;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35782;&#21035;&#19982;&#27491;&#22312;&#27835;&#30103;&#30340;&#30142;&#30149;&#30456;&#20851;&#30340;&#26032;&#20852;&#27169;&#24335;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.14701</link><description>&lt;p&gt;
COMPASS&#65306;&#21033;&#29992;&#35821;&#35328;&#24314;&#27169;&#23545;&#24739;&#32773;-&#27835;&#30103;&#24072;&#32852;&#30431;&#31574;&#30053;&#36827;&#34892;&#35745;&#31639;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;COMPASS&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#26512;&#24515;&#29702;&#27835;&#30103;&#20250;&#35805;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#65292;&#30452;&#25509;&#25512;&#26029;&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#65292;&#20026;&#20020;&#24202;&#31934;&#31070;&#30149;&#23398;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35782;&#21035;&#19982;&#27491;&#22312;&#27835;&#30103;&#30340;&#30142;&#30149;&#30456;&#20851;&#30340;&#26032;&#20852;&#27169;&#24335;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#26159;&#39044;&#27979;&#24515;&#29702;&#27835;&#30103;&#27835;&#30103;&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#20256;&#32479;&#19978;&#65292;&#24037;&#20316;&#32852;&#30431;&#35780;&#20272;&#20381;&#36182;&#20110;&#27835;&#30103;&#24072;&#21644;&#24739;&#32773;&#22635;&#20889;&#30340;&#38382;&#21367;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;COMPASS&#65292;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#21487;&#30452;&#25509;&#20174;&#24515;&#29702;&#27835;&#30103;&#35838;&#31243;&#20013;&#20351;&#29992;&#30340;&#33258;&#28982;&#35821;&#35328;&#20013;&#25512;&#26029;&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20998;&#26512;&#24515;&#29702;&#27835;&#30103;&#20250;&#35805;&#30340;&#36716;&#24405;&#65292;&#24182;&#23558;&#20854;&#19982;&#24037;&#20316;&#32852;&#30431;&#28165;&#21333;&#20013;&#38472;&#36848;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#36827;&#34892;&#27604;&#36739;&#12290;&#36890;&#36807;&#20998;&#26512;&#28085;&#30422;&#22810;&#31181;&#31934;&#31070;&#30142;&#30149;&#30340;&#36229;&#36807;950&#20010;&#20250;&#35805;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26174;&#24494;&#22320;&#26144;&#23556;&#24739;&#32773;-&#27835;&#30103;&#24072;&#23545;&#40784;&#36712;&#36857;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#20026;&#20020;&#24202;&#31934;&#31070;&#30149;&#23398;&#25552;&#20379;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35782;&#21035;&#19982;&#27491;&#22312;&#27835;&#30103;&#30340;&#30142;&#30149;&#30456;&#20851;&#30340;&#26032;&#20852;&#27169;&#24335;&#26041;&#38754;&#25552;&#20379;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;&#21508;&#31181;&#31070;&#32463;&#20027;&#39064;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14701v1 Announce Type: cross  Abstract: The therapeutic working alliance is a critical factor in predicting the success of psychotherapy treatment. Traditionally, working alliance assessment relies on questionnaires completed by both therapists and patients. In this paper, we present COMPASS, a novel framework to directly infer the therapeutic working alliance from the natural language used in psychotherapy sessions. Our approach utilizes advanced large language models to analyze transcripts of psychotherapy sessions and compare them with distributed representations of statements in the working alliance inventory. Analyzing a dataset of over 950 sessions covering diverse psychiatric conditions, we demonstrate the effectiveness of our method in microscopically mapping patient-therapist alignment trajectories and providing interpretability for clinical psychiatry and in identifying emerging patterns related to the condition being treated. By employing various neural topic mode
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;token-ensemble&#29983;&#25104;&#31574;&#30053;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;AI&#20869;&#23481;&#26816;&#27979;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#23545;&#24403;&#21069;&#26816;&#27979;&#27169;&#22411;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#25913;&#36827;&#26816;&#27979;&#25216;&#26415;&#20197;&#24212;&#23545;&#22797;&#26434;&#23545;&#25239;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.11167</link><description>&lt;p&gt;
Token-Ensemble&#25991;&#26412;&#29983;&#25104;&#65306;&#23545;&#33258;&#21160;AI&#29983;&#25104;&#25991;&#26412;&#26816;&#27979;&#30340;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Token-Ensemble Text Generation: On Attacking the Automatic AI-Generated Text Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11167
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;token-ensemble&#29983;&#25104;&#31574;&#30053;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;AI&#20869;&#23481;&#26816;&#27979;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#23545;&#24403;&#21069;&#26816;&#27979;&#27169;&#22411;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#25913;&#36827;&#26816;&#27979;&#25216;&#26415;&#20197;&#24212;&#23545;&#22797;&#26434;&#23545;&#25239;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#20869;&#23481;&#26816;&#27979;&#27169;&#22411;&#23545;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#25915;&#20987;&#65288;&#20363;&#22914;&#25913;&#20889;&#25110;&#35789;&#35821;&#26367;&#25442;&#65289;&#30340;&#40065;&#26834;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;token-ensemble&#29983;&#25104;&#31574;&#30053;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;AI&#20869;&#23481;&#26816;&#27979;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20174;&#38543;&#26426;&#20505;&#36873;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#19979;&#19968;&#20010;token&#23436;&#25104;&#25552;&#31034;&#26469;&#25506;&#32034;&#38598;&#25104;&#25915;&#20987;&#31574;&#30053;&#12290;&#25105;&#20204;&#21457;&#29616;token-ensemble&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;AI&#20869;&#23481;&#26816;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#65288;&#20195;&#30721;&#21644;&#27979;&#35797;&#38598;&#23558;&#21457;&#24067;&#65289;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;token-ensemble&#29983;&#25104;&#23545;&#24403;&#21069;&#26816;&#27979;&#27169;&#22411;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#65292;&#24182;&#24378;&#35843;&#20102;&#25913;&#36827;&#26816;&#27979;&#25216;&#26415;&#20197;&#24212;&#23545;&#22797;&#26434;&#23545;&#25239;&#31574;&#30053;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11167v1 Announce Type: cross  Abstract: The robustness of AI-content detection models against cultivated attacks (e.g., paraphrasing or word switching) remains a significant concern. This study proposes a novel token-ensemble generation strategy to challenge the robustness of current AI-content detection approaches. We explore the ensemble attack strategy by completing the prompt with the next token generated from random candidate LLMs. We find the token-ensemble approach significantly drops the performance of AI-content detection models (The code and test sets will be released). Our findings reveal that token-ensemble generation poses a vital challenge to current detection models and underlines the need for advancing detection technologies to counter sophisticated adversarial strategies.
&lt;/p&gt;</description></item><item><title>BlendFilter&#36890;&#36807;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#21644;&#30693;&#35782;&#36807;&#28388;&#26041;&#27861;&#25552;&#21319;&#20102;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#22810;&#39046;&#22495;&#30340;&#38382;&#31572;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.11129</link><description>&lt;p&gt;
BlendFilter: &#36890;&#36807;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#21644;&#30693;&#35782;&#36807;&#28388;&#25512;&#36827;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11129
&lt;/p&gt;
&lt;p&gt;
BlendFilter&#36890;&#36807;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#21644;&#30693;&#35782;&#36807;&#28388;&#26041;&#27861;&#25552;&#21319;&#20102;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#22810;&#39046;&#22495;&#30340;&#38382;&#31572;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11129v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#25552;&#21319;&#30693;&#35782;&#23494;&#38598;&#22411;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#32463;&#24120;&#38754;&#20020;&#22797;&#26434;&#36755;&#20837;&#30340;&#25361;&#25112;&#65292;&#24182;&#19988;&#30001;&#20110;&#22024;&#26434;&#30340;&#30693;&#35782;&#26816;&#32034;&#32780;&#36935;&#21040;&#22256;&#38590;&#65292;&#26126;&#26174;&#38459;&#30861;&#20102;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;BlendFilter&#65292;&#19968;&#31181;&#36890;&#36807;&#23558;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#19982;&#30693;&#35782;&#36807;&#28388;&#30456;&#32467;&#21512;&#26469;&#25552;&#21319;&#26816;&#32034;&#22686;&#24378;&#22411;LLM&#30340;&#26032;&#26041;&#27861;&#12290;BlendFilter&#25552;&#20986;&#20102;&#36890;&#36807;&#20854;&#26597;&#35810;&#29983;&#25104;&#26041;&#27861;&#30340;&#28151;&#21512;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#23558;&#22806;&#37096;&#30693;&#35782;&#21644;&#20869;&#37096;&#30693;&#35782;&#22686;&#24378;&#19982;&#21407;&#22987;&#26597;&#35810;&#30456;&#32467;&#21512;&#65292;&#30830;&#20445;&#20840;&#38754;&#25910;&#38598;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#29420;&#29305;&#30340;&#30693;&#35782;&#36807;&#28388;&#27169;&#22359;&#20805;&#20998;&#21033;&#29992;&#20102;LLM&#30340;&#22266;&#26377;&#33021;&#21147;&#65292;&#26377;&#25928;&#28040;&#38500;&#20102;&#22810;&#20313;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#24320;&#25918;&#22495;&#38382;&#31572;&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11129v1 Announce Type: new  Abstract: Retrieval-augmented Large Language Models (LLMs) offer substantial benefits in enhancing performance across knowledge-intensive scenarios. However, these methods often face challenges with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness. To address this issue, we introduce BlendFilter, a novel approach that elevates retrieval-augmented LLMs by integrating query generation blending with knowledge filtering. BlendFilter proposes the blending process through its query generation method, which integrates both external and internal knowledge augmentation with the original query, ensuring comprehensive information gathering. Additionally, our distinctive knowledge filtering module capitalizes on the intrinsic capabilities of the LLM, effectively eliminating extraneous data. We conduct extensive experiments on three open-domain question answering benchmarks, and the findings clea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36951;&#24536;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#21644;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#65292;&#26377;&#25928;&#22320;&#36951;&#24536;&#30446;&#26631;&#25991;&#26412;&#65292;&#24182;&#22312;&#29983;&#25104;&#20219;&#21153;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#20013;&#20445;&#30041;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.10052</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#21644;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#36827;&#34892;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Unmemorization in Large Language Models via Self-Distillation and Deliberate Imagination
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36951;&#24536;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#21644;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#65292;&#26377;&#25928;&#22320;&#36951;&#24536;&#30446;&#26631;&#25991;&#26412;&#65292;&#24182;&#22312;&#29983;&#25104;&#20219;&#21153;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#20013;&#20445;&#30041;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#29983;&#25104;&#33021;&#21147;&#65292;&#20294;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20173;&#28982;&#23384;&#22312;&#38544;&#31169;&#20405;&#29359;&#21644;&#25935;&#24863;&#25968;&#25454;&#19981;&#21463;&#25511;&#21046;&#30340;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21363;&#22312;LLM&#36951;&#24536;&#30340;&#36807;&#31243;&#20013;&#37319;&#29992;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#12290;&#25105;&#20204;&#19981;&#26159;&#35797;&#22270;&#24536;&#35760;&#24050;&#35760;&#24518;&#30340;&#25968;&#25454;&#65292;&#32780;&#26159;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#30340;&#26694;&#26550;&#24341;&#23548;LLM&#26377;&#24847;&#35782;&#22320;&#24819;&#35937;&#26367;&#20195;&#24773;&#22659;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#26377;&#25928;&#22320;&#36951;&#24536;&#30446;&#26631;&#25991;&#26412;&#65292;&#36824;&#21487;&#20197;&#20445;&#30041;LLM&#22312;&#24320;&#25918;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#65288;NLU&#65289;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#27169;&#22411;&#21644;&#35268;&#27169;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10052v1 Announce Type: cross  Abstract: While displaying impressive generation capabilities across many tasks, Large Language Models (LLMs) still struggle with crucial issues of privacy violation and unwanted exposure of sensitive data. This raises an essential question: how should we prevent such undesired behavior of LLMs while maintaining their strong generation and natural language understanding (NLU) capabilities? In this work, we introduce a novel approach termed deliberate imagination in the context of LLM unlearning. Instead of trying to forget memorized data, we employ a self-distillation framework, guiding LLMs to deliberately imagine alternative scenarios. As demonstrated in a wide range of experiments, the proposed method not only effectively unlearns targeted text but also preserves the LLMs' capabilities in open-ended generation tasks as well as in NLU tasks. Our results demonstrate the usefulness of this approach across different models and sizes, and also wit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#65292;&#36890;&#36807;&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.07204</link><description>&lt;p&gt;
&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#25918;&#39046;&#22495;&#22478;&#24066;&#34892;&#31243;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Synergizing Spatial Optimization with Large Language Models for Open-Domain Urban Itinerary Planning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#65292;&#36890;&#36807;&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#12290;OUIP&#19982;&#20256;&#32479;&#34892;&#31243;&#35268;&#21010;&#19981;&#21516;&#65292;&#20256;&#32479;&#35268;&#21010;&#38480;&#21046;&#20102;&#29992;&#25143;&#34920;&#36798;&#26356;&#35814;&#32454;&#30340;&#38656;&#27714;&#65292;&#38459;&#30861;&#20102;&#30495;&#27491;&#30340;&#20010;&#24615;&#21270;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#22788;&#29702;&#22810;&#26679;&#21270;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38750;&#23454;&#26102;&#20449;&#24687;&#12289;&#19981;&#23436;&#25972;&#30340;&#30693;&#35782;&#21644;&#19981;&#36275;&#30340;&#31354;&#38388;&#24847;&#35782;&#65292;&#23427;&#20204;&#26080;&#27861;&#29420;&#31435;&#22320;&#25552;&#20379;&#28385;&#24847;&#30340;&#29992;&#25143;&#20307;&#39564;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;ItiNera&#30340;OUIP&#31995;&#32479;&#65292;&#23558;&#31354;&#38388;&#20248;&#21270;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#27969;&#27700;&#32447;&#65292;&#29992;&#20110;&#25552;&#21462;&#21644;&#26356;&#26032;&#20852;&#36259;&#28857;&#29305;&#24449;&#65292;&#20197;&#21019;&#24314;&#29992;&#25143;&#33258;&#24049;&#30340;&#20010;&#24615;&#21270;&#20852;&#36259;&#28857;&#25968;&#25454;&#24211;&#12290;&#23545;&#20110;&#27599;&#20010;&#29992;&#25143;&#35831;&#27714;&#65292;&#25105;&#20204;&#21033;&#29992;LLM&#36827;&#34892;&#21327;&#21516;&#23454;&#29616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we for the first time propose the task of Open-domain Urban Itinerary Planning (OUIP) for citywalk, which directly generates itineraries based on users' requests described in natural language. OUIP is different from conventional itinerary planning, which limits users from expressing more detailed needs and hinders true personalization. Recently, large language models (LLMs) have shown potential in handling diverse tasks. However, due to non-real-time information, incomplete knowledge, and insufficient spatial awareness, they are unable to independently deliver a satisfactory user experience in OUIP. Given this, we present ItiNera, an OUIP system that synergizes spatial optimization with Large Language Models (LLMs) to provide services that customize urban itineraries based on users' needs. Specifically, we develop an LLM-based pipeline for extracting and updating POI features to create a user-owned personalized POI database. For each user request, we leverage LLM in coop
&lt;/p&gt;</description></item><item><title>MobileGPT&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;LLM&#30340;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#24037;&#20855;&#65292;&#36890;&#36807;&#31867;&#20154;&#24212;&#29992;&#35760;&#24518;&#27169;&#25311;&#20154;&#31867;&#19982;&#31227;&#21160;&#24212;&#29992;&#30340;&#35748;&#30693;&#36807;&#31243;&#65292;&#23454;&#29616;&#20219;&#21153;&#31243;&#24207;&#30340;&#31934;&#30830;&#39640;&#25928;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2312.03003</link><description>&lt;p&gt;
&#25506;&#32034;&#12289;&#36873;&#25321;&#12289;&#25512;&#23548;&#21644;&#22238;&#24518;&#65306;&#20026;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#22686;&#21152;&#31867;&#20154;&#35760;&#24518;&#30340;LLM
&lt;/p&gt;
&lt;p&gt;
Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03003
&lt;/p&gt;
&lt;p&gt;
MobileGPT&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;LLM&#30340;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#24037;&#20855;&#65292;&#36890;&#36807;&#31867;&#20154;&#24212;&#29992;&#35760;&#24518;&#27169;&#25311;&#20154;&#31867;&#19982;&#31227;&#21160;&#24212;&#29992;&#30340;&#35748;&#30693;&#36807;&#31243;&#65292;&#23454;&#29616;&#20219;&#21153;&#31243;&#24207;&#30340;&#31934;&#30830;&#39640;&#25928;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#20026;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#39046;&#22495;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;&#23427;&#20204;&#20248;&#36234;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#25512;&#29702;&#33021;&#21147;&#20351;&#29992;&#25143;&#33021;&#22815;&#33258;&#21160;&#25191;&#34892;&#22797;&#26434;&#21644;&#37325;&#22797;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLMs&#22266;&#26377;&#30340;&#19981;&#21487;&#38752;&#24615;&#21644;&#39640;&#36816;&#34892;&#25104;&#26412;&#65292;&#23427;&#20204;&#30340;&#23454;&#38469;&#36866;&#29992;&#24615;&#30456;&#24403;&#26377;&#38480;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;MobileGPT&#65292;&#36825;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;LLM&#30340;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#24037;&#20855;&#65292;&#37197;&#22791;&#20102;&#31867;&#20154;&#24212;&#29992;&#35760;&#24518;&#12290;MobileGPT&#27169;&#25311;&#20102;&#20154;&#31867;&#19982;&#31227;&#21160;&#24212;&#29992;&#20132;&#20114;&#30340;&#35748;&#30693;&#36807;&#31243;--&#25506;&#32034;&#12289;&#36873;&#25321;&#12289;&#25512;&#23548;&#21644;&#22238;&#24518;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23558;&#20219;&#21153;&#31243;&#24207;&#20998;&#35299;&#20026;&#26356;&#23567;&#12289;&#27169;&#22359;&#21270;&#30340;&#23376;&#20219;&#21153;&#65292;&#20801;&#35768;&#26356;&#31934;&#30830;&#12289;&#39640;&#25928;&#22320;&#23398;&#20064;&#20219;&#21153;&#27969;&#31243;&#65292;&#20174;&#32780;&#23454;&#29616;&#23376;&#20219;&#21153;&#30340;&#37325;&#22797;&#20351;&#29992;&#12289;&#37325;&#26032;&#25490;&#21015;&#21644;&#36866;&#24212;&#21508;&#31181;&#30446;&#26631;&#12290;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;LLM&#26381;&#21153;&#65288;GPT-3.5&#21644;GPT-4&#65289;&#23454;&#29616;&#20102;MobileGPT&#65292;&#24182;&#22312;&#19968;&#32452;&#25968;&#25454;&#19978;&#35780;&#20272;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03003v2 Announce Type: replace-cross  Abstract: The advent of large language models (LLMs) has opened up new opportunities in the field of mobile task automation. Their superior language understanding and reasoning capabilities allow users to automate complex and repetitive tasks. However, due to the inherent unreliability and high operational cost of LLMs, their practical applicability is quite limited. To address these issues, this paper introduces MobileGPT, an innovative LLM-based mobile task automator equipped with a human-like app memory. MobileGPT emulates the cognitive process of humans interacting with a mobile app -- explore, select, derive, and recall. This approach allows for a more precise and efficient learning of a task's procedure by breaking it down into smaller, modular sub-tasks that can be re-used, re-arranged, and adapted for various objectives. We implement MobileGPT using online LLMs services (GPT-3.5 and GPT-4) and evaluate its performance on a datase
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#32467;&#21512;&#22270;&#39537;&#21160;&#30340;&#19978;&#19979;&#25991;&#26816;&#32034;&#21644;&#30693;&#35782;&#22270;&#32467;&#26500;&#22686;&#24378;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#39640;LLMs&#30340;&#33021;&#21147;&#65292;&#23588;&#20854;&#26159;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#19978;&#65292;&#26356;&#22909;&#22320;&#22238;&#31572;&#24320;&#25918;&#24335;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.12671</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#30340;&#37325;&#35201;&#24615;&#65306;&#36890;&#36807;&#22270;&#32467;&#26500;&#21270;&#30693;&#35782;&#19978;&#19979;&#25991;&#25512;&#21160;&#24320;&#25918;&#24335;&#31572;&#26696;&#29983;&#25104;&#30340;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context. (arXiv:2401.12671v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#32467;&#21512;&#22270;&#39537;&#21160;&#30340;&#19978;&#19979;&#25991;&#26816;&#32034;&#21644;&#30693;&#35782;&#22270;&#32467;&#26500;&#22686;&#24378;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#39640;LLMs&#30340;&#33021;&#21147;&#65292;&#23588;&#20854;&#26159;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#19978;&#65292;&#26356;&#22909;&#22320;&#22238;&#31572;&#24320;&#25918;&#24335;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#26029;&#21457;&#23637;&#30340;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20013;&#65292;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#26500;&#24314;&#19978;&#19979;&#25991;&#20016;&#23500;&#12289;&#26377;&#24847;&#20041;&#30340;&#22238;&#31572;&#33267;&#20851;&#37325;&#35201;&#12290;&#30740;&#31350;&#20154;&#21592;&#36234;&#26469;&#36234;&#24847;&#35782;&#21040;&#24403;LLMs&#30340;&#21442;&#25968;&#36739;&#23569;&#26102;&#65292;&#23581;&#35797;&#25552;&#20379;&#21512;&#36866;&#31572;&#26696;&#32473;&#24320;&#25918;&#24335;&#38382;&#39064;&#26102;&#20250;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38556;&#30861;&#65292;&#23558;&#20808;&#36827;&#30340;&#31574;&#30053;&#19982;&#20016;&#23500;&#30340;&#22806;&#37096;&#39046;&#22495;&#30693;&#35782;&#19982;LLMs&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#21319;&#31572;&#26696;&#30340;&#36136;&#37327;&#12290;&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#23558;&#22522;&#20110;&#22270;&#30340;&#19978;&#19979;&#25991;&#26816;&#32034;&#19982;&#30693;&#35782;&#22270;&#32467;&#26500;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#25552;&#39640;&#20102;LLMs&#30340;&#33021;&#21147;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29305;&#23450;&#39046;&#22495;&#30340;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#65292;&#22914;AskUbuntu&#12289;Unix&#21644;ServerFault&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#21442;&#25968;&#22823;&#23567;&#30340;&#21508;&#31181;LLMs&#36827;&#34892;&#23454;&#39564;&#65292;&#35780;&#20272;&#23427;&#20204;&#22312;&#24320;&#25918;&#24335;&#38382;&#39064;&#30340;&#22238;&#31572;&#20013;&#30340;&#30693;&#35782;&#30830;&#23450;&#33021;&#21147;&#21644;&#20107;&#23454;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;GraphContextGen&#22312;&#22522;&#20110;&#25991;&#26412;&#30340;&#29616;&#26377;&#26041;&#27861;&#19978;&#25345;&#32493;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the continuously advancing AI landscape, crafting context-rich and meaningful responses via Large Language Models (LLMs) is essential. Researchers are becoming more aware of the challenges that LLMs with fewer parameters encounter when trying to provide suitable answers to open-ended questions. To address these hurdles, the integration of cutting-edge strategies, augmentation of rich external domain knowledge to LLMs, offers significant improvements. This paper introduces a novel framework that combines graph-driven context retrieval in conjunction to knowledge graphs based enhancement, honing the proficiency of LLMs, especially in domain specific community question answering platforms like AskUbuntu, Unix, and ServerFault. We conduct experiments on various LLMs with different parameter sizes to evaluate their ability to ground knowledge and determine factual accuracy in answers to open-ended questions. Our methodology GraphContextGen consistently outperforms dominant text-based ret
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#36328;&#25991;&#21270;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#32654;&#22269;&#21644;&#20013;&#22269;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#24773;&#24863;&#34920;&#36798;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#32654;&#22269;Twitter&#29992;&#25143;&#30456;&#27604;&#65292;&#20013;&#22269;&#26032;&#28010;&#24494;&#21338;&#29992;&#25143;&#22312;&#24773;&#24863;&#24378;&#24230;&#30340;&#21464;&#21270;&#21644;&#28608;&#21160;&#31243;&#24230;&#19978;&#26377;&#26356;&#26126;&#26174;&#30340;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2401.05254</link><description>&lt;p&gt;
&#20013;&#32654;&#20004;&#22269;&#20043;&#38388;&#22522;&#20110;&#35821;&#35328;&#30340;&#24773;&#32490;&#34920;&#36798;&#30340;&#20215;&#20540;&#21644;&#28608;&#21160;&#23545;&#27604;&#65306;&#19968;&#20010;&#36328;&#25991;&#21270;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination. (arXiv:2401.05254v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#36328;&#25991;&#21270;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#32654;&#22269;&#21644;&#20013;&#22269;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#24773;&#24863;&#34920;&#36798;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#32654;&#22269;Twitter&#29992;&#25143;&#30456;&#27604;&#65292;&#20013;&#22269;&#26032;&#28010;&#24494;&#21338;&#29992;&#25143;&#22312;&#24773;&#24863;&#24378;&#24230;&#30340;&#21464;&#21270;&#21644;&#28608;&#21160;&#31243;&#24230;&#19978;&#26377;&#26356;&#26126;&#26174;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31038;&#20132;&#23186;&#20307;&#19978;&#20010;&#20307;&#30340;&#24773;&#24863;&#34920;&#36798;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#35199;&#26041;&#29615;&#22659;&#20013;&#12290;&#19981;&#21516;&#25991;&#21270;&#20043;&#38388;&#23384;&#22312;&#30528;&#24341;&#21457;&#24773;&#24863;&#34920;&#36798;&#30340;&#37325;&#35201;&#24046;&#24322;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#32654;&#22269;Twitter&#21644;&#20013;&#22269;&#26032;&#28010;&#24494;&#21338;&#19978;&#30340;&#20004;&#20010;&#20027;&#35201;&#24773;&#24863;&#32500;&#24230;&#65288;&#20215;&#20540;&#21644;&#28608;&#21160;&#65289;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#32654;&#22269;&#21644;&#20013;&#22269;&#20010;&#20307;&#20043;&#38388;&#30340;&#28608;&#21160;&#21644;&#20215;&#20540;&#20043;&#38388;&#30340;&#21151;&#33021;&#20851;&#31995;&#24046;&#24322;&#65292;&#24182;&#25506;&#35752;&#20102;&#30456;&#20851;&#20869;&#23481;&#19978;&#30340;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#20004;&#20010;&#24179;&#21488;&#19978;&#30340;&#35789;&#35821;&#20351;&#29992;&#21644;&#35805;&#39064;&#36827;&#34892;&#20102;&#30456;&#20851;&#24615;&#20998;&#26512;&#65292;&#20197;&#35299;&#35835;&#23427;&#20204;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#23545;&#20110;Twitter&#29992;&#25143;&#26469;&#35828;&#65292;&#36127;&#38754;&#24773;&#32490;&#21644;&#27491;&#38754;&#24773;&#32490;&#20043;&#38388;&#30340;&#24773;&#24863;&#24378;&#24230;&#21464;&#21270;&#19981;&#22826;&#26126;&#26174;&#65292;&#32780;&#23545;&#20110;&#26032;&#28010;&#24494;&#21338;&#29992;&#25143;&#26469;&#35828;&#65292;&#20276;&#38543;&#30528;&#24773;&#24863;&#30340;&#19978;&#21319;&#65292;&#28608;&#21160;&#31243;&#24230;&#26377;&#26356;&#26126;&#26174;&#30340;&#21319;&#32423;&#12290;&#20174;&#35821;&#35328;&#29305;&#24449;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#24773;&#24863;&#34920;&#36798;&#26041;&#38754;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although affective expressions of individuals have been extensively studied using social media, research has primarily focused on the Western context. There are substantial differences among cultures that contribute to their affective expressions. This paper examines the differences between Twitter (X) in the United States and Sina Weibo posts in China on two primary dimensions of affect - valence and arousal. We study the difference in the functional relationship between arousal and valence (so-called V-shaped) among individuals in the US and China and explore the associated content differences. Furthermore, we correlate word usage and topics in both platforms to interpret their differences. We observe that for Twitter users, the variation in emotional intensity is less distinct between negative and positive emotions compared to Weibo users, and there is a sharper escalation in arousal corresponding with heightened emotions. From language features, we discover that affective expressio
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.06499</link><description>&lt;p&gt;
TaCo&#65306;&#36890;&#36807;&#20449;&#24687;&#35770;&#21644;&#21487;&#35299;&#37322;&#24615;&#22312;NLP&#20013;&#30340;&#36755;&#20986;&#23884;&#20837;&#20013;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#27010;&#24565;&#21435;&#38500;
&lt;/p&gt;
&lt;p&gt;
TaCo: Targeted Concept Removal in Output Embeddings for NLP via Information Theory and Explainability. (arXiv:2312.06499v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.06499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#20449;&#24687;&#35770;&#34920;&#26126;&#65292;&#20026;&#20102;&#23454;&#29616;&#20844;&#24179;&#24615;&#65292;&#27169;&#22411;&#19981;&#24212;&#33021;&#22815;&#39044;&#27979;&#25935;&#24863;&#21464;&#37327;&#65292;&#22914;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#24180;&#40836;&#12290;&#28982;&#32780;&#65292;&#19982;&#36825;&#20123;&#21464;&#37327;&#30456;&#20851;&#30340;&#20449;&#24687;&#36890;&#24120;&#20197;&#38544;&#24335;&#30340;&#26041;&#24335;&#20986;&#29616;&#22312;&#35821;&#35328;&#20013;&#65292;&#36825;&#32473;&#35782;&#21035;&#21644;&#20943;&#23569;&#20559;&#35265;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#22312;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#19978;&#25805;&#20316;&#65292;&#29420;&#31435;&#20110;&#20855;&#20307;&#30340;&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#26368;&#36817;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24182;&#37319;&#29992;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#36873;&#23450;&#21464;&#37327;&#20013;&#30340;&#38544;&#24335;&#20449;&#24687;&#12290;&#36890;&#36807;&#30452;&#25509;&#25805;&#32437;&#26368;&#21518;&#19968;&#23618;&#30340;&#23884;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#21040;&#29616;&#26377;&#27169;&#22411;&#20013;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#37325;&#22823;&#20462;&#25913;&#25110;&#37325;&#35757;&#32451;&#12290;&#22312;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#21518;&#22788;&#29702;&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fairness of Natural Language Processing (NLP) models has emerged as a crucial concern. Information theory indicates that to achieve fairness, a model should not be able to predict sensitive variables, such as gender, ethnicity, and age. However, information related to these variables often appears implicitly in language, posing a challenge in identifying and mitigating biases effectively. To tackle this issue, we present a novel approach that operates at the embedding level of an NLP model, independent of the specific architecture. Our method leverages insights from recent advances in XAI techniques and employs an embedding transformation to eliminate implicit information from a selected variable. By directly manipulating the embeddings in the final layer, our approach enables a seamless integration into existing models without requiring significant modifications or retraining. In evaluation, we show that the proposed post-hoc approach significantly reduces gender-related associati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#25506;&#32034;&#24182;&#35757;&#32451;&#20102;&#24378;&#22823;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#32763;&#35793;&#26500;&#24314;&#20102;&#22810;&#35821;&#35328;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#21508;&#31181;&#35757;&#32451;&#31574;&#30053;&#26469;&#26500;&#24314;&#24378;&#22823;&#30340;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#23454;&#21457;&#29616;&#22312;&#22810;&#35821;&#35328;&#35757;&#32451;&#20013;&#65292;&#23558;&#30446;&#26631;&#35821;&#35328;&#30340;&#32763;&#35793;&#19982;&#21407;&#22987;&#35821;&#35328;&#30340;&#34920;&#31034;&#32467;&#21512;&#36215;&#26469;&#20197;&#21450;&#20132;&#26367;&#35757;&#32451;&#21644;&#22810;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#20030;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#27169;&#22411;&#22312;&#22788;&#29702;&#20302;&#39057;&#35789;&#21644;&#38271;&#21477;&#23376;&#26041;&#38754;&#20173;&#38754;&#20020;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.20246</link><description>&lt;p&gt;
&#22312;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#20013;&#25171;&#30772;&#35821;&#35328;&#38556;&#30861;&#65306;&#35265;&#35299;&#19982;&#35266;&#23519;
&lt;/p&gt;
&lt;p&gt;
Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations. (arXiv:2310.20246v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#25506;&#32034;&#24182;&#35757;&#32451;&#20102;&#24378;&#22823;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#32763;&#35793;&#26500;&#24314;&#20102;&#22810;&#35821;&#35328;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#21508;&#31181;&#35757;&#32451;&#31574;&#30053;&#26469;&#26500;&#24314;&#24378;&#22823;&#30340;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#23454;&#21457;&#29616;&#22312;&#22810;&#35821;&#35328;&#35757;&#32451;&#20013;&#65292;&#23558;&#30446;&#26631;&#35821;&#35328;&#30340;&#32763;&#35793;&#19982;&#21407;&#22987;&#35821;&#35328;&#30340;&#34920;&#31034;&#32467;&#21512;&#36215;&#26469;&#20197;&#21450;&#20132;&#26367;&#35757;&#32451;&#21644;&#22810;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#20030;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#27169;&#22411;&#22312;&#22788;&#29702;&#20302;&#39057;&#35789;&#21644;&#38271;&#21477;&#23376;&#26041;&#38754;&#20173;&#38754;&#20020;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24320;&#21457;&#36866;&#29992;&#20110;&#21333;&#35821;&#35328;&#20013;&#30340;&#25968;&#23398;&#25512;&#29702;&#30340;&#24378;&#22823;&#35821;&#35328;&#23398;&#20064;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#20445;&#25345;&#25928;&#26524;&#30340;&#30740;&#31350;&#24456;&#23569;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#39318;&#27425;&#25506;&#32034;&#21644;&#35757;&#32451;&#24378;&#22823;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#65288;xMR&#65289;LLM&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#21033;&#29992;&#32763;&#35793;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#31532;&#19968;&#20010;&#21253;&#21547;&#21313;&#31181;&#19981;&#21516;&#35821;&#35328;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#25351;&#23548;&#25968;&#25454;&#38598;MGSM8KInstruct&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;xMR&#20219;&#21153;&#20013;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#38382;&#39064;&#12290;&#26681;&#25454;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#26469;&#26500;&#24314;&#24378;&#22823;&#30340;xMR LLMs&#65292;&#34987;&#21629;&#21517;&#20026;MathOctopus&#65292;&#22312;&#20960;&#27425;&#35757;&#32451;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;&#20256;&#32479;&#24320;&#28304;LLMs&#21644;ChatGPT&#30340;&#33021;&#21147;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;MathOctopus-13B&#22312;MGSM&#27979;&#35797;&#38598;&#19978;&#36798;&#21040;&#20102;47.6%&#30340;&#20934;&#30830;&#29575;&#65292;&#36229;&#36807;&#20102;ChatGPT&#30340;46.3%&#12290;&#38500;&#20102;&#26174;&#33879;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#20174;&#22823;&#37327;&#30340;&#23454;&#39564;&#35777;&#23454;&#20013;&#21457;&#29616;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#35266;&#23519;&#21644;&#35265;&#35299;&#65306;&#65288;1&#65289;&#22312;&#22810;&#35821;&#35328;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#26368;&#22909;&#23558;&#30446;&#26631;&#35821;&#35328;&#30340;&#32763;&#35793;&#19982;&#21407;&#22987;&#35821;&#35328;&#30340;&#34920;&#31034;&#32467;&#21512;&#36215;&#26469;&#12290; &#65288;2&#65289;&#20132;&#26367;&#35757;&#32451;&#21644;&#22810;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#20030;&#26377;&#21161;&#20110;&#25552;&#39640;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290; &#65288;3&#65289;&#27169;&#22411;&#23545;&#20110;&#20302;&#39057;&#35789;&#21644;&#38271;&#21477;&#23376;&#30340;&#22788;&#29702;&#26159;&#25361;&#25112;&#30340;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing research predominantly focuses on developing powerful language learning models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights from extensive experiments: (1) When
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#22312;&#32473;&#23450;&#30001;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#25991;&#26412;&#25552;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20316;&#32773;&#32467;&#21512;&#20102;&#22810;&#31181;&#30333;&#30418;&#21644;&#40657;&#30418;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#29983;&#25104;&#25913;&#36827;&#30340;&#25552;&#31034;&#65292;&#24182;&#37319;&#29992;&#35838;&#31243;&#23398;&#20064;&#21644;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#26680;&#23398;&#20064;&#26041;&#27861;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.01472</link><description>&lt;p&gt;
&#21453;&#21521;&#31283;&#23450;&#25193;&#25955;&#65306;&#29983;&#25104;&#35813;&#22270;&#20687;&#25152;&#20351;&#29992;&#30340;&#25552;&#31034;&#26159;&#20160;&#20040;&#65311;
&lt;/p&gt;
&lt;p&gt;
Reverse Stable Diffusion: What prompt was used to generate this image?. (arXiv:2308.01472v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#22312;&#32473;&#23450;&#30001;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#25991;&#26412;&#25552;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20316;&#32773;&#32467;&#21512;&#20102;&#22810;&#31181;&#30333;&#30418;&#21644;&#40657;&#30418;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#29983;&#25104;&#25913;&#36827;&#30340;&#25552;&#31034;&#65292;&#24182;&#37319;&#29992;&#35838;&#31243;&#23398;&#20064;&#21644;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#26680;&#23398;&#20064;&#26041;&#27861;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#65292;&#22914;&#31283;&#23450;&#25193;&#25955;&#65292;&#26368;&#36817;&#21560;&#24341;&#20102;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#30340;&#20852;&#36259;&#65292;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#22312;&#26356;&#22909;&#22320;&#29702;&#35299;&#29983;&#25104;&#36807;&#31243;&#21644;&#22914;&#20309;&#35774;&#35745;&#25552;&#31034;&#20197;&#33719;&#24471;&#25152;&#38656;&#22270;&#20687;&#26041;&#38754;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#22312;&#32473;&#23450;&#30001;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#25991;&#26412;&#25552;&#31034;&#12290;&#25105;&#20204;&#32467;&#21512;&#20102;&#19968;&#31995;&#21015;&#30333;&#30418;&#21644;&#40657;&#30418;&#27169;&#22411;&#65288;&#26377;&#21644;&#26080;&#23545;&#25193;&#25955;&#32593;&#32476;&#26435;&#37325;&#36827;&#34892;&#35775;&#38382;&#65289;&#26469;&#22788;&#29702;&#25152;&#25552;&#20986;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#21253;&#25324;&#32852;&#21512;&#25552;&#31034;&#22238;&#24402;&#21644;&#22810;&#26631;&#31614;&#35789;&#27719;&#20998;&#31867;&#30446;&#26631;&#65292;&#29983;&#25104;&#25913;&#36827;&#30340;&#25552;&#31034;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25913;&#36827;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#35838;&#31243;&#23398;&#20064;&#36807;&#31243;&#65292;&#20419;&#36827;&#20102;&#20855;&#26377;&#26356;&#20302;&#26631;&#27880;&#22122;&#22768;&#65288;&#21363;&#26356;&#22909;&#23545;&#40784;&#65289;&#30340;&#22270;&#20687;&#25552;&#31034;&#23545;&#30340;&#23398;&#20064;&#65292;&#24182;&#19988;&#20351;&#29992;&#30456;&#20284;&#24615;&#36827;&#34892;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#26680;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text-to-image diffusion models such as Stable Diffusion have recently attracted the interest of many researchers, and inverting the diffusion process can play an important role in better understanding the generative process and how to engineer prompts in order to obtain the desired images. To this end, we introduce the new task of predicting the text prompt given an image generated by a generative diffusion model. We combine a series of white-box and black-box models (with and without access to the weights of the diffusion network) to deal with the proposed task. We propose a novel learning framework comprising of a joint prompt regression and multi-label vocabulary classification objective that generates improved prompts. To further improve our method, we employ a curriculum learning procedure that promotes the learning of image-prompt pairs with lower labeling noise (i.e. that are better aligned), and an unsupervised domain-adaptive kernel learning method that uses the similarities b
&lt;/p&gt;</description></item></channel></rss>