<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>AMOR&#26159;&#19968;&#20010;&#22522;&#20110;&#24320;&#28304;LLM&#30340;&#20195;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#19982;&#22806;&#37096;&#30693;&#35782;&#24211;&#36827;&#34892;&#25512;&#29702;&#21644;&#20154;&#31867;&#30417;&#30563;&#26469;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#24494;&#35843;&#65292;AMOR&#33021;&#22815;&#22312;&#19981;&#21516;&#30693;&#35782;&#29615;&#22659;&#20013;&#27867;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#26681;&#25454;&#36807;&#31243;&#21453;&#39304;&#36827;&#34892;&#39046;&#22495;&#23450;&#21046;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01469</link><description>&lt;p&gt;
AMOR:&#36890;&#36807;&#36827;&#31243;&#21453;&#39304;&#26500;&#24314;&#36866;&#24212;&#24615;&#27169;&#22359;&#21270;&#30693;&#35782;&#20195;&#29702;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01469
&lt;/p&gt;
&lt;p&gt;
AMOR&#26159;&#19968;&#20010;&#22522;&#20110;&#24320;&#28304;LLM&#30340;&#20195;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#19982;&#22806;&#37096;&#30693;&#35782;&#24211;&#36827;&#34892;&#25512;&#29702;&#21644;&#20154;&#31867;&#30417;&#30563;&#26469;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#24494;&#35843;&#65292;AMOR&#33021;&#22815;&#22312;&#19981;&#21516;&#30693;&#35782;&#29615;&#22659;&#20013;&#27867;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#26681;&#25454;&#36807;&#31243;&#21453;&#39304;&#36827;&#34892;&#39046;&#22495;&#23450;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26174;&#33879;&#25104;&#21151;&#24341;&#21457;&#20102;&#26500;&#24314;&#35821;&#35328;&#20195;&#29702;&#23436;&#25104;&#21508;&#31181;&#22797;&#26434;&#20219;&#21153;&#30340;&#39640;&#28526;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24320;&#28304;LLM&#30340;&#20195;&#29702;&#26694;&#26550;AMOR&#65292;&#36890;&#36807;&#19982;&#22806;&#37096;&#30693;&#35782;&#24211;&#36827;&#34892;&#25512;&#29702;&#24182;&#36890;&#36807;&#20154;&#31867;&#30417;&#30563;&#26469;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;AMOR&#22312;&#26377;&#38480;&#29366;&#24577;&#26426;&#65288;FSM&#65289;&#19978;&#26500;&#24314;&#25512;&#29702;&#36923;&#36753;&#65292;&#36890;&#36807;&#33258;&#20027;&#25191;&#34892;&#21644;&#27169;&#22359;&#38388;&#36716;&#25442;&#35299;&#20915;&#38382;&#39064;&#12290;&#36825;&#20351;&#20154;&#20204;&#33021;&#22815;&#30452;&#25509;&#20026;&#21333;&#20010;&#27169;&#22359;&#25552;&#20379;&#21453;&#39304;&#65292;&#20174;&#32780;&#33258;&#28982;&#24418;&#25104;&#20102;&#36807;&#31243;&#30417;&#30563;&#12290;&#22522;&#20110;&#36825;&#20010;&#25512;&#29702;&#21644;&#21453;&#39304;&#26694;&#26550;&#65292;&#25105;&#20204;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#24494;&#35843;&#24320;&#21457;&#20102;AMOR&#65306;&#39044;&#28909;&#21644;&#36866;&#24212;&#12290;&#21069;&#32773;&#20351;&#29992;&#20174;&#21508;&#31181;&#20844;&#20849;&#25968;&#25454;&#38598;&#33258;&#21160;&#26500;&#24314;&#30340;&#31034;&#20363;&#23545;LLM&#36827;&#34892;&#24494;&#35843;&#65292;&#20351;AMOR&#33021;&#22815;&#22312;&#19981;&#21516;&#30340;&#30693;&#35782;&#29615;&#22659;&#20013;&#27867;&#21270;&#65292;&#21518;&#32773;&#20351;&#29992;&#36807;&#31243;&#21453;&#39304;&#23558;AMOR&#37327;&#36523;&#23450;&#21046;&#21040;&#29305;&#23450;&#39046;&#22495;&#12290;&#22312;&#22810;&#20010;&#39046;&#22495;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
The notable success of large language models (LLMs) has sparked an upsurge in building language agents to complete various complex tasks. We present AMOR, an agent framework based on open-source LLMs, which reasons with external knowledge bases and adapts to specific domains through human supervision to the reasoning process. AMOR builds reasoning logic over a finite state machine (FSM) that solves problems through autonomous executions and transitions over disentangled modules. This allows humans to provide direct feedback to the individual modules, and thus naturally forms process supervision. Based on this reasoning and feedback framework, we develop AMOR through two-stage fine-tuning: warm-up and adaptation. The former fine-tunes the LLM with examples automatically constructed from various public datasets and enables AMOR to generalize across different knowledge environments, while the latter tailors AMOR to specific domains using process feedback. Extensive experiments across mult
&lt;/p&gt;</description></item><item><title>&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#30340;&#27867;&#21270;&#38382;&#39064;&#28304;&#20110;&#29616;&#35937;&#31354;&#38388;&#20013;&#30340;&#20559;&#24046;&#65292;&#38656;&#35201;&#37327;&#21270;&#21644;&#35299;&#20915;&#35821;&#35328;&#21644;&#35270;&#35273;&#20559;&#24046;&#65292;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;</title><link>https://arxiv.org/abs/2403.16394</link><description>&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#20013;&#29616;&#35937;&#31354;&#38388;&#20013;&#30340;&#20559;&#24046;&#38459;&#30861;&#20102;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16394
&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#30340;&#27867;&#21270;&#38382;&#39064;&#28304;&#20110;&#29616;&#35937;&#31354;&#38388;&#20013;&#30340;&#20559;&#24046;&#65292;&#38656;&#35201;&#37327;&#21270;&#21644;&#35299;&#20915;&#35821;&#35328;&#21644;&#35270;&#35273;&#20559;&#24046;&#65292;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#30340;&#25991;&#29486;&#23384;&#22312;&#30528;&#20851;&#20110;&#22914;&#20309;&#24544;&#23454;&#22320;&#32452;&#21512;&#23454;&#20307;&#19982;&#20851;&#31995;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#23545;&#23454;&#20307;-&#20851;&#31995;&#32452;&#21512;&#22914;&#20309;&#26377;&#25928;&#23398;&#20064;&#30340;&#24418;&#24335;&#21270;&#29702;&#35299;&#12290;&#27492;&#22806;&#65292;&#21453;&#26144;&#38382;&#39064;&#32467;&#26500;&#30340;&#22522;&#30784;&#29616;&#35937;&#31354;&#38388;&#24182;&#19981;&#26126;&#30830;&#23450;&#20041;&#65292;&#23548;&#33268;&#20026;&#20102;&#24076;&#26395;&#27867;&#21270;&#22312;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#20013;&#24471;&#20197;&#23637;&#29616;&#32780;&#19981;&#26029;&#36861;&#27714;&#26356;&#22810;&#25968;&#25454;&#12290;&#25105;&#20204;&#29468;&#27979;&#22522;&#30784;&#29616;&#35937;&#23398;&#35206;&#30422;&#33539;&#22260;&#24182;&#26410;&#25353;&#27604;&#20363;&#25193;&#23637;&#65292;&#23548;&#33268;&#25152;&#21576;&#29616;&#29616;&#35937;&#30340;&#20559;&#24046;&#23545;&#27867;&#21270;&#36896;&#25104;&#20102;&#20260;&#23475;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32479;&#35745;&#24230;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#25968;&#25454;&#38598;&#20013;&#30340;&#35821;&#35328;&#21644;&#35270;&#35273;&#20559;&#24046;&#65292;&#29992;&#20110;&#20851;&#31995;&#23398;&#20064;&#65292;&#24182;&#34920;&#26126;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#30340;&#27867;&#21270;&#22833;&#36133;&#30452;&#25509;&#28304;&#20110;&#29616;&#35937;&#23398;&#35206;&#30422;&#19981;&#23436;&#25972;&#25110;&#19981;&#24179;&#34913;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#21512;&#25104;&#39046;&#22495;&#36827;&#34892;&#23454;&#39564;&#21644;&#28436;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16394v1 Announce Type: cross  Abstract: The literature on text-to-image generation is plagued by issues of faithfully composing entities with relations. But there lacks a formal understanding of how entity-relation compositions can be effectively learned. Moreover, the underlying phenomenon space that meaningfully reflects the problem structure is not well-defined, leading to an arms race for larger quantities of data in the hope that generalization emerges out of large-scale pretraining. We hypothesize that the underlying phenomenological coverage has not been proportionally scaled up, leading to a skew of the presented phenomenon which harms generalization. We introduce statistical metrics that quantify both the linguistic and visual skew of a dataset for relational learning, and show that generalization failures of text-to-image generation are a direct result of incomplete or unbalanced phenomenological coverage. We first perform experiments in a synthetic domain and demo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;LoReKT&#30340;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#26694;&#26550;&#65292;&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#37325;&#35201;&#24615;&#26426;&#21046;&#65292;&#26088;&#22312;&#20174;&#20016;&#23500;&#36164;&#28304;&#30340;KT&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#21644;&#34920;&#31034;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2403.06725</link><description>&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#37325;&#35201;&#24615;&#26426;&#21046;&#24494;&#35843;&#25913;&#36827;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06725
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;LoReKT&#30340;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#26694;&#26550;&#65292;&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#37325;&#35201;&#24615;&#26426;&#21046;&#65292;&#26088;&#22312;&#20174;&#20016;&#23500;&#36164;&#28304;&#30340;KT&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#21644;&#34920;&#31034;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#30693;&#35782;&#36861;&#36394;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#36861;&#36394;&#65288;KT&#65289;&#26088;&#22312;&#22522;&#20110;&#23398;&#29983;&#30340;&#21382;&#21490;&#20114;&#21160;&#26469;&#20272;&#35745;&#20182;&#20204;&#30340;&#30693;&#35782;&#25484;&#25569;&#31243;&#24230;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;KT&#65288;DLKT&#65289;&#26041;&#27861;&#22312;KT&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#21407;&#22240;&#65292;&#22914;&#39044;&#31639;&#38480;&#21046;&#21644;&#38544;&#31169;&#38382;&#39064;&#65292;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#35266;&#23519;&#21040;&#30340;&#20114;&#21160;&#38750;&#24120;&#26377;&#38480;&#65292;&#21363;&#20302;&#36164;&#28304;KT&#25968;&#25454;&#38598;&#12290;&#30452;&#25509;&#22312;&#20302;&#36164;&#28304;KT&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;DLKT&#27169;&#22411;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#65292;&#24182;&#19988;&#24456;&#38590;&#36873;&#25321;&#36866;&#24403;&#30340;&#28145;&#24230;&#31070;&#32463;&#26550;&#26500;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LoReKT&#30340;&#20302;&#36164;&#28304;KT&#26694;&#26550;&#26469;&#24212;&#23545;&#19978;&#36848;&#25361;&#25112;&#12290;&#21463;&#30427;&#34892;&#30340;&#8220;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#8221;&#33539;&#24335;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#26088;&#22312;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#20174;&#20016;&#23500;&#36164;&#28304;&#30340;KT&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#21644;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06725v1 Announce Type: cross  Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subseque
&lt;/p&gt;</description></item><item><title>AutoRD&#26159;&#19968;&#20010;&#33258;&#21160;&#21270;&#31471;&#21040;&#31471;&#31995;&#32479;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21307;&#23398;&#30693;&#35782;&#22270;&#26500;&#24314;&#32597;&#35265;&#30142;&#30149;&#30693;&#35782;&#22270;&#65292;&#23454;&#29616;&#20102;&#25972;&#20307;F1&#24471;&#20998;47.3%&#65292;&#30456;&#23545;&#20110;&#22522;&#30784;LLM&#26377;14.4%&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2403.00953</link><description>&lt;p&gt;
AutoRD&#65306;&#19968;&#31181;&#22522;&#20110;&#26412;&#20307;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#32597;&#35265;&#30142;&#30149;&#30693;&#35782;&#22270;&#26500;&#24314;&#30340;&#33258;&#21160;&#21270;&#31471;&#21040;&#31471;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00953
&lt;/p&gt;
&lt;p&gt;
AutoRD&#26159;&#19968;&#20010;&#33258;&#21160;&#21270;&#31471;&#21040;&#31471;&#31995;&#32479;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21307;&#23398;&#30693;&#35782;&#22270;&#26500;&#24314;&#32597;&#35265;&#30142;&#30149;&#30693;&#35782;&#22270;&#65292;&#23454;&#29616;&#20102;&#25972;&#20307;F1&#24471;&#20998;47.3%&#65292;&#30456;&#23545;&#20110;&#22522;&#30784;LLM&#26377;14.4%&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#21019;&#24314;&#19968;&#20010;&#21517;&#20026;AutoRD&#30340;&#31471;&#21040;&#31471;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33258;&#21160;&#20174;&#20020;&#24202;&#25991;&#26412;&#20013;&#25552;&#21462;&#26377;&#20851;&#32597;&#35265;&#30142;&#30149;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#21508;&#31181;&#27979;&#35797;&#26469;&#35780;&#20272;AutoRD&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#26412;&#25991;&#20013;&#24378;&#35843;&#20102;&#20854;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#12290;&#26041;&#27861;&#65306;&#25105;&#20204;&#30340;&#31995;&#32479;AutoRD&#26159;&#19968;&#20010;&#36719;&#20214;&#27969;&#27700;&#32447;&#65292;&#28041;&#21450;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#23454;&#20307;&#25552;&#21462;&#12289;&#20851;&#31995;&#25552;&#21462;&#12289;&#23454;&#20307;&#26657;&#20934;&#21644;&#30693;&#35782;&#22270;&#26500;&#24314;&#12290;&#25105;&#20204;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#30001;&#24320;&#28304;&#21307;&#23398;&#26412;&#20307;&#21457;&#23637;&#32780;&#26469;&#30340;&#21307;&#23398;&#30693;&#35782;&#22270;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#20307;&#25552;&#21462;&#12289;&#20851;&#31995;&#25552;&#21462;&#20197;&#21450;&#30693;&#35782;&#22270;&#26500;&#24314;&#24615;&#33021;&#23545;&#31995;&#32479;&#36827;&#34892;&#23450;&#37327;&#35780;&#20272;&#12290;&#32467;&#26524;&#65306;AutoRD&#21462;&#24471;&#20102;47.3%&#30340;&#25972;&#20307;F1&#20998;&#25968;&#65292;&#36739;&#22522;&#30784;LLM&#25552;&#39640;&#20102;14.4%&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;AutoRD&#23454;&#29616;&#20102;56.1%&#30340;&#25972;&#20307;&#23454;&#20307;&#25552;&#21462;F1&#20998;&#25968;&#65288;&#32597;&#35265;&#30142;&#30149;&#65306;83.5%&#65292;&#30142;&#30149;&#65306;35.8%&#65292;s
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00953v1 Announce Type: cross  Abstract: Objectives: Our objective is to create an end-to-end system called AutoRD, which automates extracting information from clinical text about rare diseases. We have conducted various tests to evaluate the performance of AutoRD and highlighted its strengths and limitations in this paper.   Materials and Methods: Our system, AutoRD, is a software pipeline involving data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implement this using large language models and medical knowledge graphs developed from open-source medical ontologies. We quantitatively evaluate our system on entity extraction, relation extraction, and the performance of knowledge graph construction.   Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement compared to the base LLM. In detail, AutoRD achieves an overall entity extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%, s
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#38382;&#31572;&#20219;&#21153;&#65292;GPT&#33021;&#22815;&#39564;&#35777;&#21307;&#30103;&#39046;&#22495;&#24739;&#32773;&#30340;PA&#35831;&#27714;&#65292;&#24110;&#21161;&#21355;&#29983;&#35745;&#21010;&#26356;&#24555;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2402.18419</link><description>&lt;p&gt;
&#33021;&#21542;&#36890;&#36807;&#22522;&#20110;&#25351;&#21335;&#30340;&#33258;&#21160;&#38382;&#31572;&#26469;&#25913;&#21892;GPT&#30340;&#20808;&#21069;&#25480;&#26435;&#29366;&#24577;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can GPT Improve the State of Prior Authorization via Guideline Based Automated Question Answering?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18419
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38382;&#31572;&#20219;&#21153;&#65292;GPT&#33021;&#22815;&#39564;&#35777;&#21307;&#30103;&#39046;&#22495;&#24739;&#32773;&#30340;PA&#35831;&#27714;&#65292;&#24110;&#21161;&#21355;&#29983;&#35745;&#21010;&#26356;&#24555;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21355;&#29983;&#20445;&#38505;&#20844;&#21496;&#26377;&#19968;&#20010;&#34987;&#31216;&#20026;&#20808;&#21069;&#25480;&#26435;&#65288;PA&#65289;&#30340;&#27969;&#31243;&#65292;&#36825;&#26159;&#19968;&#31181;&#21355;&#29983;&#35745;&#21010;&#25104;&#26412;&#25511;&#21046;&#27969;&#31243;&#65292;&#35201;&#27714;&#21307;&#29983;&#21644;&#20854;&#20182;&#21307;&#30103;&#19987;&#19994;&#20154;&#21592;&#22312;&#23545;&#24739;&#32773;&#25191;&#34892;&#29305;&#23450;&#31243;&#24207;&#20043;&#21069;&#24517;&#39035;&#20107;&#20808;&#33719;&#24471;&#21355;&#29983;&#35745;&#21010;&#30340;&#25209;&#20934;&#65292;&#20197;&#20415;&#26377;&#36164;&#26684;&#33719;&#24471;&#25903;&#20184;&#35206;&#30422;&#12290;&#23545;&#21355;&#29983;&#20445;&#38505;&#20844;&#21496;&#26469;&#35828;&#65292;&#25209;&#20934;&#21307;&#30103;&#39046;&#22495;&#24739;&#32773;&#30340;PA&#35831;&#27714;&#26159;&#19968;&#39033;&#32791;&#26102;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20854;&#20013;&#30340;&#19968;&#39033;&#20851;&#38190;&#25361;&#25112;&#26159;&#39564;&#35777;&#35831;&#27714;&#26159;&#21542;&#31526;&#21512;&#26576;&#20123;&#26631;&#20934;&#65292;&#22914;&#24180;&#40836;&#12289;&#24615;&#21035;&#31561;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;GPT&#26159;&#21542;&#33021;&#39564;&#35777;&#22823;&#37327;&#20851;&#38190;&#22240;&#32032;&#65292;&#20174;&#32780;&#24110;&#21161;&#21355;&#29983;&#35745;&#21010;&#26356;&#24555;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#23558;&#20854;&#26500;&#24314;&#20026;&#19968;&#20010;&#38382;&#31572;&#20219;&#21153;&#65292;&#20419;&#20351;GPT&#20174;&#24739;&#32773;&#30340;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#22238;&#31572;&#38382;&#39064;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#19981;&#21516;&#30340;&#20256;&#32479;&#25552;&#31034;&#25216;&#26415;&#65292;&#21516;&#26102;&#36824;&#24341;&#20837;&#20102;&#25105;&#20204;&#33258;&#24049;&#30340;&#26032;&#39062;&#25552;&#31034;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18419v1 Announce Type: cross  Abstract: Health insurance companies have a defined process called prior authorization (PA) which is a health plan cost-control process that requires doctors and other healthcare professionals to get clearance in advance from a health plan before performing a particular procedure on a patient in order to be eligible for payment coverage. For health insurance companies, approving PA requests for patients in the medical domain is a time-consuming and challenging task. One of those key challenges is validating if a request matches up to certain criteria such as age, gender, etc. In this work, we evaluate whether GPT can validate numerous key factors, in turn helping health plans reach a decision drastically faster. We frame it as a question answering task, prompting GPT to answer a question from patient electronic health record. We experiment with different conventional prompting techniques as well as introduce our own novel prompting technique. Mo
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#20851;&#31995;&#23450;&#20041;&#26469;&#35757;&#32451;&#20851;&#31995;&#25277;&#21462;&#27169;&#22411;&#30340;&#38646;-shot&#23398;&#20064;&#35774;&#32622;&#65292;&#20174;&#32780;&#20026;&#27169;&#22411;&#25552;&#20379;&#20934;&#30830;&#21644;&#26126;&#30830;&#30340;&#20851;&#31995;&#31867;&#22411;&#25551;&#36848;&#65292;&#24182;&#21516;&#26102;&#26368;&#23567;&#21270;&#27880;&#37322;&#35201;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.11142</link><description>&lt;p&gt;
&#25226;&#25569;&#35201;&#28857;&#65306;&#23450;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38646;-shot&#20851;&#31995;&#25277;&#21462;
&lt;/p&gt;
&lt;p&gt;
Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11142
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#20851;&#31995;&#23450;&#20041;&#26469;&#35757;&#32451;&#20851;&#31995;&#25277;&#21462;&#27169;&#22411;&#30340;&#38646;-shot&#23398;&#20064;&#35774;&#32622;&#65292;&#20174;&#32780;&#20026;&#27169;&#22411;&#25552;&#20379;&#20934;&#30830;&#21644;&#26126;&#30830;&#30340;&#20851;&#31995;&#31867;&#22411;&#25551;&#36848;&#65292;&#24182;&#21516;&#26102;&#26368;&#23567;&#21270;&#27880;&#37322;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#31995;&#25277;&#21462;&#65288;RE&#65289;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#65292;&#26088;&#22312;&#35782;&#21035;&#25991;&#26412;&#20013;&#25552;&#21450;&#30340;&#23454;&#20307;&#20043;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;&#23613;&#31649;&#36825;&#19968;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#27169;&#22411;&#36890;&#24120;&#20381;&#36182;&#20110;&#22823;&#37327;&#30340;&#27880;&#37322;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#33719;&#21462;&#36825;&#20123;&#25968;&#25454;&#21487;&#33021;&#26082;&#26114;&#36149;&#21448;&#32791;&#26102;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#38590;&#20197;&#36866;&#24212;&#26032;&#30340;&#25110;&#26410;&#35265;&#36807;&#30340;&#20851;&#31995;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#23569;&#26679;&#26412;&#23398;&#20064;&#35774;&#32622;&#26088;&#22312;&#20943;&#23569;&#27880;&#37322;&#35201;&#27714;&#65292;&#23545;&#20110;&#29702;&#35299;&#30446;&#26631;&#20851;&#31995;&#35821;&#20041;&#25552;&#20379;&#20102;&#19981;&#23436;&#25972;&#19988;&#26377;&#20559;&#35265;&#30340;&#30417;&#30563;&#65292;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#19988;&#19981;&#31283;&#23450;&#12290;&#20026;&#20102;&#20026;&#27169;&#22411;&#25552;&#20379;&#20934;&#30830;&#21644;&#26126;&#30830;&#30340;&#20851;&#31995;&#31867;&#22411;&#25551;&#36848;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#27880;&#37322;&#35201;&#27714;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20165;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#20013;&#34920;&#31034;&#30340;&#20851;&#31995;&#23450;&#20041;&#26469;&#35757;&#32451;RE&#27169;&#22411;&#30340;&#20165;&#38646;-shot RE&#35774;&#32622;&#12290;&#21463;LLM&#65288;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65289;&#24378;&#22823;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11142v1 Announce Type: new  Abstract: Relation extraction (RE), a crucial task in NLP, aims to identify semantic relationships between entities mentioned in texts. Despite significant advancements in this field, existing models typically rely on extensive annotated data for training, which can be both costly and time-consuming to acquire. Moreover, these models often struggle to adapt to new or unseen relationships. In contrast, few-shot learning settings, which aim to reduce annotation requirements, may offer incomplete and biased supervision for understanding target relation semantics, leading to degraded and unstable performance. To provide the model with accurate and explicit descriptions of the relations types and meanwhile minimize the annotation requirements, we study the definition only zero-shot RE setting where only relation definitions expressed in natural language are used to train a RE model. Motivated by the strong synthetic data generation power of LLMs, we pr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#20102;&#35299;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31283;&#20581;&#32534;&#36753;&#26041;&#27861;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#20174;&#32780;&#20419;&#36827;&#23545;&#20132;&#27969;&#22411;&#20154;&#24037;&#26234;&#33021;&#30340;&#31283;&#20581;&#12289;&#29616;&#23454;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.05827</link><description>&lt;p&gt;
&#26159;&#21542;&#21487;&#20197;&#31283;&#20581;&#22320;&#32534;&#36753;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is it Possible to Edit Large Language Models Robustly?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05827
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#20102;&#35299;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31283;&#20581;&#32534;&#36753;&#26041;&#27861;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#20174;&#32780;&#20419;&#36827;&#23545;&#20132;&#27969;&#22411;&#20154;&#24037;&#26234;&#33021;&#30340;&#31283;&#20581;&#12289;&#29616;&#23454;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#26500;&#24314;&#33021;&#27169;&#20223;&#20154;&#31867;&#34892;&#20026;&#30340;&#20132;&#27969;&#22411;&#20154;&#24037;&#26234;&#33021;&#26041;&#38754;&#21457;&#25381;&#20102;&#20851;&#38190;&#20316;&#29992;&#65292;&#20294;&#20063;&#38754;&#20020;&#30528;&#39640;&#25928;&#23450;&#21046;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#28041;&#21450;&#21040;&#20102;&#27169;&#22411;&#32534;&#36753;&#30340;&#39046;&#22495;&#65292;&#36890;&#36807;&#25805;&#32437;&#35821;&#35328;&#27169;&#22411;&#30340;&#29305;&#23450;&#35760;&#24518;&#24182;&#25913;&#21464;&#30456;&#20851;&#30340;&#35821;&#35328;&#29983;&#25104;&#26469;&#36827;&#34892;&#32534;&#36753;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#32534;&#36753;&#30340;&#31283;&#20581;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#20102;&#35299;&#32534;&#36753;&#26041;&#27861;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#20174;&#32780;&#20419;&#36827;&#23545;&#20132;&#27969;&#22411;&#20154;&#24037;&#26234;&#33021;&#30340;&#31283;&#20581;&#12289;&#29616;&#23454;&#24212;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#20998;&#26512;&#20197;&#22238;&#31572;&#19977;&#20010;&#20851;&#38190;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;Q1&#65306;&#32534;&#36753;&#21518;&#30340;LLM&#26159;&#21542;&#33021;&#22312;&#29616;&#23454;&#24773;&#22659;&#20013;&#19968;&#33268;&#22320;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;&#20132;&#27969;&#22411;&#20154;&#24037;&#26234;&#33021;&#30340;&#34892;&#20026;&#65311;Q2&#65306;&#25913;&#20889;&#25552;&#31034;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#23548;&#33268;LLM&#20559;&#31163;&#32534;&#36753;&#30340;&#30693;&#35782;&#35760;&#24518;&#65311;Q3&#65306;&#21738;&#20123;&#30693;&#35782;&#29305;&#24449;&#19982;&#32534;&#36753;&#30340;&#24615;&#33021;&#21644;&#31283;&#20581;&#24615;&#30456;&#20851;&#65311;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#25581;&#31034;&#20102;&#26174;&#33879;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have played a pivotal role in building communicative AI to imitate human behaviors but face the challenge of efficient customization. To tackle this challenge, recent studies have delved into the realm of model editing, which manipulates specific memories of language models and changes the related language generation. However, the robustness of model editing remains an open question. This work seeks to understand the strengths and limitations of editing methods, thus facilitating robust, realistic applications of communicative AI. Concretely, we conduct extensive analysis to address the three key research questions. Q1: Can edited LLMs behave consistently resembling communicative AI in realistic situations? Q2: To what extent does the rephrasing of prompts lead LLMs to deviate from the edited knowledge memory? Q3: Which knowledge features are correlated with the performance and robustness of editing? Our experimental results uncover a substantial disparity 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.05162</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#35780;&#20272;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20854;&#23433;&#20840;&#26426;&#21046;&#26041;&#38754;&#34920;&#29616;&#20986;&#22266;&#26377;&#30340;&#26131;&#30862;&#24615;&#65292;&#36825;&#21487;&#20174;&#23427;&#20204;&#26131;&#21463;&#36234;&#29425;&#21644;&#21363;&#20351;&#26159;&#38750;&#24694;&#24847;&#24494;&#35843;&#20063;&#26131;&#21463;&#24433;&#21709;&#26469;&#35828;&#26126;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#25506;&#35752;&#20102;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#23545;&#20110;&#23433;&#20840;&#38450;&#25252;&#33267;&#20851;&#37325;&#35201;&#65292;&#19988;&#22312;&#31070;&#32463;&#20803;&#21644;&#31209;&#32423;&#21035;&#19978;&#19982;&#25928;&#29992;&#30456;&#20851;&#30340;&#21306;&#22495;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#30340;&#23396;&#31435;&#21306;&#22495;&#26159;&#31232;&#30095;&#30340;&#65292;&#32422;&#21344;&#21442;&#25968;&#32423;&#21035;&#30340;$3\%$&#21644;&#25490;&#21517;&#32423;&#21035;&#30340;$2.5\%$&#12290;&#21435;&#38500;&#36825;&#20123;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#32780;&#23545;&#25928;&#29992;&#30340;&#24433;&#21709;&#19981;&#22823;&#65292;&#20174;&#32780;&#35777;&#23454;&#20102;&#35813;&#27169;&#22411;&#23433;&#20840;&#26426;&#21046;&#30340;&#22266;&#26377;&#26131;&#30862;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#21363;&#20351;&#38480;&#21046;&#23545;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#36827;&#34892;&#20462;&#25913;&#65292;LLMs&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#20302;&#25104;&#26412;&#30340;&#24494;&#35843;&#25915;&#20987;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;LLMs&#20013;&#26356;&#24378;&#22823;&#30340;&#23433;&#20840;&#31574;&#30053;&#30340;&#32039;&#36843;&#24615;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3\%$ at the parameter level and $2.5\%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model's safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20010;&#24615;&#21270;&#21442;&#25968;&#39640;&#25928;&#35843;&#25972;&#27169;&#22359;&#65288;PEFT&#65289;&#23454;&#29616;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#27665;&#20027;&#21270;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#25317;&#26377;&#21644;&#20351;&#29992;&#20182;&#20204;&#33258;&#24049;&#30340;LLM&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#23450;&#21046;&#33021;&#21147;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04401</link><description>&lt;p&gt;
&#36890;&#36807;&#20010;&#24615;&#21270;&#21442;&#25968;&#39640;&#25928;&#35843;&#25972;&#23454;&#29616;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#27665;&#20027;&#21270;
&lt;/p&gt;
&lt;p&gt;
Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04401
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20010;&#24615;&#21270;&#21442;&#25968;&#39640;&#25928;&#35843;&#25972;&#27169;&#22359;&#65288;PEFT&#65289;&#23454;&#29616;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#27665;&#20027;&#21270;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#25317;&#26377;&#21644;&#20351;&#29992;&#20182;&#20204;&#33258;&#24049;&#30340;LLM&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#23450;&#21046;&#33021;&#21147;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#30340;&#20010;&#24615;&#21270;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#26088;&#22312;&#20351;LLM&#30340;&#20132;&#20114;&#12289;&#20869;&#23481;&#21644;&#25512;&#33616;&#19982;&#20010;&#20307;&#29992;&#25143;&#20559;&#22909;&#30456;&#19968;&#33268;&#12290;&#26368;&#36817;LLM&#20010;&#24615;&#21270;&#30340;&#36827;&#23637;&#32858;&#28966;&#20110;&#26377;&#25928;&#30340;&#25552;&#31034;&#35774;&#35745;&#65292;&#36890;&#36807;&#20351;&#29992;&#34892;&#20026;&#21382;&#21490;&#26816;&#32034;&#21644;&#25991;&#26412;&#27010;&#35201;&#31561;&#38750;&#21442;&#25968;&#21270;&#30693;&#35782;&#20016;&#23500;&#29992;&#25143;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#27169;&#22411;&#25152;&#26377;&#26435;&#65292;&#36825;&#20123;&#26041;&#27861;&#21463;&#21040;&#20102;&#19968;&#23450;&#30340;&#38480;&#21046;&#65292;&#23548;&#33268;&#23450;&#21046;&#33021;&#21147;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#22312;&#22797;&#26434;&#21644;&#21160;&#24577;&#29992;&#25143;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#36890;&#24120;&#26080;&#27861;&#20934;&#30830;&#25429;&#25417;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;OPPU&#30340;&#26041;&#27861;&#65292;&#23427;&#37319;&#29992;&#20010;&#24615;&#21270;&#21442;&#25968;&#39640;&#25928;&#35843;&#25972;&#65288;PEFT&#65289;&#27169;&#22359;&#26469;&#23384;&#20648;&#29992;&#25143;&#29305;&#23450;&#30340;&#34892;&#20026;&#27169;&#24335;&#21644;&#20559;&#22909;&#12290;&#36890;&#36807;&#25554;&#20837;&#29992;&#25143;&#30340;&#20010;&#20154;PEFT&#21442;&#25968;&#65292;&#20182;&#20204;&#21487;&#20197;&#25317;&#26377;&#21644;&#20351;&#29992;&#20182;&#20204;&#30340;LLM&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalization in large language models (LLMs) is increasingly important, aiming to align LLM's interactions, content, and recommendations with individual user preferences. Recent advances in LLM personalization have spotlighted effective prompt design, by enriching user queries with non-parametric knowledge through behavior history retrieval and textual profiles. However, these approaches were limited due to a lack of model ownership, resulting in constrained customization and privacy issues. Moreover, they often failed to accurately capture user behavior patterns, especially in cases where user data were complex and dynamic. To address these shortcomings, we introduce One PEFT Per User (OPPU), which employs personalized parameter-efficient fine-tuning (PEFT) modules, to store user-specific behavior patterns and preferences. By plugging in users' personal PEFT parameters, they can own and use their LLMs personally. OPPU integrates parametric user knowledge in the personal PEFT parame
&lt;/p&gt;</description></item><item><title>LLMRefine&#25552;&#20986;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#21453;&#39304;&#27169;&#22411;&#26469;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23450;&#20301;&#32570;&#38519;&#24182;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#26426;&#22120;&#32763;&#35793;&#12289;&#38271;&#31687;&#38382;&#31572;&#21644;&#20027;&#39064;&#24635;&#32467;&#31561;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2311.09336</link><description>&lt;p&gt;
LLMRefine&#65306;&#36890;&#36807;&#32454;&#31890;&#24230;&#21487;&#25805;&#20316;&#21453;&#39304;&#31934;&#30830;&#23450;&#20301;&#21644;&#20248;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09336
&lt;/p&gt;
&lt;p&gt;
LLMRefine&#25552;&#20986;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#21453;&#39304;&#27169;&#22411;&#26469;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23450;&#20301;&#32570;&#38519;&#24182;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#26426;&#22120;&#32763;&#35793;&#12289;&#38271;&#31687;&#38382;&#31572;&#21644;&#20027;&#39064;&#24635;&#32467;&#31561;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#27491;&#22312;&#21033;&#29992;&#20154;&#31867;&#21453;&#39304;&#26469;&#25552;&#39640;&#29983;&#25104;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#33719;&#21462;&#20154;&#31867;&#21453;&#39304;&#25104;&#26412;&#39640;&#26114;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LLMRefine&#65292;&#19968;&#31181;&#29992;&#20110;&#20248;&#21270;&#25512;&#29702;&#26102;&#38388;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;LLM&#30340;&#36755;&#20986;&#12290;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#21033;&#29992;&#23398;&#20064;&#30340;&#32454;&#31890;&#24230;&#21453;&#39304;&#27169;&#22411;&#26469;&#20934;&#30830;&#23450;&#20301;&#32570;&#38519;&#65292;&#24182;&#24341;&#23548;LLM&#36827;&#34892;&#36845;&#20195;&#20248;&#21270;&#12290;&#36890;&#36807;&#23558;&#21407;&#22987;LLM&#20316;&#20026;&#32534;&#36753;&#24314;&#35758;&#65292;LLMRefine&#36890;&#36807;&#27169;&#25311;&#36864;&#28779;&#25628;&#32034;&#26080;&#32570;&#38519;&#25991;&#26412;&#65292;&#26435;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;&#26426;&#22120;&#32763;&#35793;&#65292;&#38271;&#31687;&#38382;&#31572;&#65288;QA&#65289;&#21644;&#20027;&#39064;&#24635;&#32467;&#12290;LLMRefine&#22312;&#25152;&#26377;&#22522;&#32447;&#26041;&#27861;&#19978;&#19968;&#36143;&#34920;&#29616;&#20248;&#24322;&#65292;&#22312;&#32763;&#35793;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#39640;&#36798;1.7 MetricX&#28857;&#30340;&#25913;&#36827;&#65292;&#22312;ASQA&#19978;&#20026;8.1 ROUGE-L&#65292;&#22312;&#20027;&#39064;&#24635;&#32467;&#19978;&#20026;2.2 ROUGE-L&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09336v2 Announce Type: replace  Abstract: Recent large language models (LLM) are leveraging human feedback to improve their generation quality. However, human feedback is costly to obtain, especially during inference. In this work, we propose LLMRefine, an inference time optimization method to refine LLM's output. The core idea is to use a learned fine-grained feedback model to pinpoint defects and guide LLM to refine them iteratively. Using original LLM as a proposal of edits, LLMRefine searches for defect-less text via simulated annealing, trading off the exploration and exploitation. We conduct experiments on three text generation tasks, including machine translation, long-form question answering (QA), and topical summarization. LLMRefine consistently outperforms all baseline approaches, achieving improvements up to 1.7 MetricX points on translation tasks, 8.1 ROUGE-L on ASQA, 2.2 ROUGE-L on topical summarization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20462;&#21098;&#21518;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25277;&#35937;&#25688;&#35201;&#20219;&#21153;&#20013;&#20135;&#29983;&#24187;&#35273;&#30340;&#24773;&#20917;&#36739;&#21407;&#22987;&#27169;&#22411;&#35201;&#23569;&#65292;&#34920;&#29616;&#26356;&#21487;&#38752;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#21644;&#31232;&#30095;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2311.09335</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35843;&#26597;&#24187;&#35273;&#22312;&#25277;&#35937;&#25688;&#35201;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization. (arXiv:2311.09335v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.09335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20462;&#21098;&#21518;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25277;&#35937;&#25688;&#35201;&#20219;&#21153;&#20013;&#20135;&#29983;&#24187;&#35273;&#30340;&#24773;&#20917;&#36739;&#21407;&#22987;&#27169;&#22411;&#35201;&#23569;&#65292;&#34920;&#29616;&#26356;&#21487;&#38752;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#21644;&#31232;&#30095;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29983;&#25104;&#22411;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25277;&#35937;&#25688;&#35201;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#38754;&#20020;&#20004;&#20010;&#37325;&#35201;&#25361;&#25112;&#65306;&#27169;&#22411;&#24222;&#22823;&#21644;&#26131;&#20135;&#29983;&#24187;&#35273;&#12290;&#24187;&#35273;&#26159;&#20196;&#20154;&#25285;&#24551;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#38477;&#20302;&#20102;&#21487;&#38752;&#24615;&#24182;&#24341;&#21457;&#23433;&#20840;&#38382;&#39064;&#12290;&#20462;&#21098;&#26159;&#19968;&#31181;&#36890;&#36807;&#21435;&#38500;&#20887;&#20313;&#26435;&#37325;&#26469;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#65292;&#23454;&#29616;&#26356;&#39640;&#25928;&#31232;&#30095;&#25512;&#29702;&#30340;&#25216;&#26415;&#12290;&#20462;&#21098;&#21518;&#30340;&#27169;&#22411;&#22312;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#19978;&#19982;&#21407;&#22987;&#27169;&#22411;&#30456;&#24403;&#65292;&#22240;&#27492;&#22312;&#39044;&#31639;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#25104;&#20026;&#29702;&#24819;&#30340;&#26367;&#20195;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#20462;&#21098;&#23545;&#35821;&#35328;&#27169;&#22411;&#22312;&#25277;&#35937;&#25688;&#35201;&#20013;&#20135;&#29983;&#24187;&#35273;&#30340;&#24433;&#21709;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#20116;&#20010;&#25688;&#35201;&#25968;&#25454;&#38598;&#12289;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#20462;&#21098;&#26041;&#27861;&#21644;&#20116;&#20010;&#32463;&#35843;&#35797;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#20462;&#21098;&#21518;&#30340;&#35821;&#35328;&#27169;&#22411;&#20135;&#29983;&#24187;&#35273;&#30340;&#24773;&#20917;&#36739;&#21407;&#22987;&#27169;&#22411;&#35201;&#23569;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#20462;&#21098;&#21518;&#30340;&#27169;&#22411;&#26356;&#20542;&#21521;&#20110;&#20381;&#36182;&#25351;&#23548;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the remarkable performance of generative large language models (LLMs) on abstractive summarization, they face two significant challenges: their considerable size and tendency to hallucinate. Hallucinations are concerning because they erode reliability and raise safety issues. Pruning is a technique that reduces model size by removing redundant weights, enabling more efficient sparse inference. Pruned models yield downstream task performance comparable to the original, making them ideal alternatives when operating on a limited budget. However, the effect that pruning has upon hallucinations in abstractive summarization with LLMs has yet to be explored. In this paper, we provide an extensive empirical study across five summarization datasets, two state-of-the-art pruning methods, and five instruction-tuned LLMs. Surprisingly, we find that hallucinations from pruned LLMs are less prevalent than the original models. Our analysis suggests that pruned models tend to depend more on th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#35821;&#35328;&#27169;&#22411;&#65288;PPLM&#65289;&#30340;&#26032;&#33539;&#24335;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#26377;&#25928;&#27880;&#20837;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#35774;&#35745;&#30340;&#29702;&#35770;&#20998;&#26512;&#21644;&#19981;&#21516;&#25216;&#26415;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#20351;&#29992;&#27491;&#21521;&#21644;&#36127;&#21521;&#31034;&#20363;&#36827;&#34892;&#25351;&#20196;&#24494;&#35843;&#30340;&#26041;&#27861;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.02469</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25104;&#20026;&#33391;&#22909;&#30340;&#38544;&#31169;&#20445;&#25252;&#23398;&#20064;&#32773;
&lt;/p&gt;
&lt;p&gt;
Large Language Models Can Be Good Privacy Protection Learners. (arXiv:2310.02469v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#35821;&#35328;&#27169;&#22411;&#65288;PPLM&#65289;&#30340;&#26032;&#33539;&#24335;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#26377;&#25928;&#27880;&#20837;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#35774;&#35745;&#30340;&#29702;&#35770;&#20998;&#26512;&#21644;&#19981;&#21516;&#25216;&#26415;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#20351;&#29992;&#27491;&#21521;&#21644;&#36127;&#21521;&#31034;&#20363;&#36827;&#34892;&#25351;&#20196;&#24494;&#35843;&#30340;&#26041;&#27861;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26222;&#21450;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#20351;&#29992;&#29305;&#23450;&#39046;&#22495;&#25968;&#25454;&#23545;&#20854;&#36827;&#34892;&#24494;&#35843;&#65292;&#21019;&#24314;&#19987;&#38376;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#29305;&#23450;&#39046;&#22495;&#30340;&#24494;&#35843;&#25968;&#25454;&#36890;&#24120;&#21253;&#21547;&#25935;&#24863;&#30340;&#20010;&#20154;&#36523;&#20221;&#20449;&#24687;&#65288;PII&#65289;&#12290;&#22312;&#27809;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;&#24773;&#20917;&#19979;&#30452;&#25509;&#24494;&#35843; LLMs &#20250;&#23384;&#22312;&#20449;&#24687;&#27844;&#38706;&#30340;&#39118;&#38505;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#38544;&#31169;&#20445;&#25252;&#35821;&#35328;&#27169;&#22411;&#65288;PPLM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#26377;&#25928;&#27880;&#20837;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#30340;&#21516;&#26102;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#26032;&#33539;&#24335;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20379;&#20102;&#27169;&#22411;&#35774;&#35745;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#28145;&#20837;&#30740;&#31350;&#20102;&#21508;&#31181;&#25216;&#26415;&#65292;&#27604;&#22914;&#35821;&#26009;&#24211;&#31574;&#23637;&#12289;&#22522;&#20110;&#24809;&#32602;&#30340;&#38750;&#27010;&#28982;&#24615;&#35757;&#32451;&#25439;&#22833;&#20197;&#21450;&#22522;&#20110;&#25351;&#20196;&#30340;&#24494;&#35843;&#31561;&#31561;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#21644;&#22330;&#26223;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#20351;&#29992;&#27491;&#21521;&#21644;&#36127;&#21521;&#31034;&#20363;&#36827;&#34892;&#25351;&#20196;&#24494;&#35843;&#65292;&#26174;&#31034;&#20986;&#24456;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The proliferation of Large Language Models (LLMs) has driven considerable interest in fine-tuning them with domain-specific data to create specialized language models. Nevertheless, such domain-specific fine-tuning data often contains sensitive personally identifiable information (PII). Direct fine-tuning LLMs on this data without privacy protection poses a risk of leakage. To address this challenge, we introduce Privacy Protection Language Models (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects domain-specific knowledge while safeguarding data privacy. Our work offers a theoretical analysis for model design and delves into various techniques such as corpus curation, penalty-based unlikelihood in training loss, and instruction-based tuning, etc. Extensive experiments across diverse datasets and scenarios demonstrate the effectiveness of our approaches. In particular, instruction tuning with both positive and negative examples, stands out as a promising method, eff
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#26469;&#26816;&#27979;&#22312;&#32447;&#38463;&#23572;&#21450;&#21033;&#20122;&#20449;&#24687;&#20013;&#30340;&#20167;&#24680;&#35328;&#35770;&#12290;&#36890;&#36807;&#23545;&#38463;&#23572;&#21450;&#21033;&#20122;&#31038;&#20132;&#32593;&#32476;&#19978;&#30340;&#35821;&#26009;&#24211;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20196;&#20154;&#40723;&#33310;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.11611</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#22312;&#38463;&#23572;&#21450;&#21033;&#20122;&#26041;&#35328;&#20013;&#26816;&#27979;&#20167;&#24680;&#35328;&#35770;
&lt;/p&gt;
&lt;p&gt;
Hate speech detection in algerian dialect using deep learning. (arXiv:2309.11611v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#26469;&#26816;&#27979;&#22312;&#32447;&#38463;&#23572;&#21450;&#21033;&#20122;&#20449;&#24687;&#20013;&#30340;&#20167;&#24680;&#35328;&#35770;&#12290;&#36890;&#36807;&#23545;&#38463;&#23572;&#21450;&#21033;&#20122;&#31038;&#20132;&#32593;&#32476;&#19978;&#30340;&#35821;&#26009;&#24211;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20196;&#20154;&#40723;&#33310;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31038;&#20132;&#32593;&#32476;&#19978;&#20167;&#24680;&#35328;&#35770;&#20197;&#19981;&#21516;&#30340;&#24418;&#24335;&#34067;&#24310;&#65292;&#22914;&#36785;&#39554;&#35821;&#35328;&#12289;&#32593;&#32476;&#27450;&#20940;&#21644;&#26292;&#21147;&#31561;&#65292;&#20154;&#20204;&#22312;&#26292;&#21147;&#26041;&#38754;&#32463;&#21382;&#20102;&#26174;&#33879;&#22686;&#21152;&#65292;&#20351;&#20182;&#20204;&#22788;&#20110;&#19981;&#36866;&#21644;&#23041;&#32961;&#30340;&#22659;&#22320;&#12290;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#20154;&#20204;&#24050;&#32463;&#25237;&#20837;&#22823;&#37327;&#30340;&#21162;&#21147;&#26469;&#20811;&#26381;&#36825;&#19968;&#29616;&#35937;&#65292;&#20197;&#26816;&#27979;&#19981;&#21516;&#32467;&#26500;&#35821;&#35328;&#65288;&#22914;&#33521;&#35821;&#12289;&#27861;&#35821;&#12289;&#38463;&#25289;&#20271;&#35821;&#31561;&#65289;&#20013;&#30340;&#20167;&#24680;&#35328;&#35770;&#65292;&#24182;&#20026;&#38463;&#25289;&#20271;&#26041;&#35328;&#65288;&#22914;&#31361;&#23612;&#26031;&#12289;&#22467;&#21450;&#21644;&#28023;&#28286;&#65289;&#36827;&#34892;&#20102;&#36739;&#23569;&#30340;&#30740;&#31350;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#22312;&#32447;&#38463;&#23572;&#21450;&#21033;&#20122;&#20449;&#24687;&#20013;&#30340;&#20167;&#24680;&#35328;&#35770;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#35768;&#22810;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26550;&#26500;&#65292;&#36825;&#20123;&#26550;&#26500;&#26159;&#20174;&#19968;&#20123;&#38463;&#23572;&#21450;&#21033;&#20122;&#31038;&#20132;&#32593;&#32476;&#65288;Facebook&#12289;YouTube&#21644;Twitter&#65289;&#20013;&#21019;&#24314;&#30340;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#30340;&#12290;&#35813;&#35821;&#26009;&#24211;&#21253;&#21547;13.5K&#22810;&#31687;&#38463;&#25289;&#20271;&#35821;&#30340;&#38463;&#23572;&#21450;&#21033;&#20122;&#26041;&#35328;&#25991;&#26723;&#65292;&#34987;&#26631;&#35760;&#20026;&#20167;&#24680;&#25110;&#38750;&#20167;&#24680;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#20196;&#20154;&#40723;&#33310;&#30340;&#32467;&#26524;&#65292;&#26174;&#31034;&#20986;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the proliferation of hate speech on social networks under different formats, such as abusive language, cyberbullying, and violence, etc., people have experienced a significant increase in violence, putting them in uncomfortable situations and threats. Plenty of efforts have been dedicated in the last few years to overcome this phenomenon to detect hate speech in different structured languages like English, French, Arabic, and others. However, a reduced number of works deal with Arabic dialects like Tunisian, Egyptian, and Gulf, mainly the Algerian ones. To fill in the gap, we propose in this work a complete approach for detecting hate speech on online Algerian messages. Many deep learning architectures have been evaluated on the corpus we created from some Algerian social networks (Facebook, YouTube, and Twitter). This corpus contains more than 13.5K documents in Algerian dialect written in Arabic, labeled as hateful or non-hateful. Promising results are obtained, which show the e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28436;&#31034;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#29983;&#29289;&#21307;&#23398;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#37325;&#26032;&#23450;&#20041;&#20026;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#38382;&#39064;&#65292;&#26469;&#35299;&#20915;&#23569;&#26679;&#26412;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#29983;&#29289;&#21307;&#23398;&#23454;&#20307;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#35813;&#26041;&#27861;&#27604;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;1.1%&#30340;F1&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2308.06454</link><description>&lt;p&gt;
&#22522;&#20110;&#28436;&#31034;&#30340;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#23569;&#26679;&#26412;&#29983;&#29289;&#21307;&#23398;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20013;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Demonstration-based learning for few-shot biomedical named entity recognition under machine reading comprehension. (arXiv:2308.06454v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28436;&#31034;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#29983;&#29289;&#21307;&#23398;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#37325;&#26032;&#23450;&#20041;&#20026;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#38382;&#39064;&#65292;&#26469;&#35299;&#20915;&#23569;&#26679;&#26412;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#29983;&#29289;&#21307;&#23398;&#23454;&#20307;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#35813;&#26041;&#27861;&#27604;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;1.1%&#30340;F1&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#35768;&#22810;&#39046;&#22495;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#23601;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#20381;&#36182;&#22823;&#37327;&#25163;&#24037;&#26631;&#27880;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#22312;&#23569;&#26679;&#26412;&#22330;&#26223;&#19979;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#31181;&#33021;&#22815;&#25913;&#36827;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#22330;&#26223;&#19979;&#35782;&#21035;&#29983;&#29289;&#21307;&#23398;&#23454;&#20307;&#30340;&#33021;&#21147;&#30340;&#31574;&#30053;&#12290;&#36890;&#36807;&#23558;&#29983;&#29289;&#21307;&#23398;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;BioNER&#65289;&#37325;&#26032;&#23450;&#20041;&#20026;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#65288;MRC&#65289;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28436;&#31034;&#30340;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#23569;&#26679;&#26412;BioNER&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#28041;&#21450;&#26500;&#24314;&#36866;&#24403;&#30340;&#20219;&#21153;&#28436;&#31034;&#12290;&#22312;&#35780;&#20272;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26102;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#21253;&#25324;BC4CHEMD&#12289;BC5CDR-Chemical&#12289;BC5CDR-Disease&#12289;NCBI-Disease&#12289;BC2GM&#21644;JNLPBA&#22312;&#20869;&#30340;&#20845;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#30340;&#20808;&#36827;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#36890;&#36807;&#25253;&#21578;25&#26679;&#26412;&#21644;50&#26679;&#26412;&#23398;&#20064;&#23454;&#39564;&#30340;F1&#20998;&#25968;&#26469;&#26816;&#26597;&#27169;&#22411;&#30340;&#25928;&#26524;&#12290;&#22312;25&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#24179;&#22343;F1&#20998;&#25968;&#25552;&#39640;&#20102;1.1%&#12290;
&lt;/p&gt;
&lt;p&gt;
Although deep learning techniques have shown significant achievements, they frequently depend on extensive amounts of hand-labeled data and tend to perform inadequately in few-shot scenarios. The objective of this study is to devise a strategy that can improve the model's capability to recognize biomedical entities in scenarios of few-shot learning. By redefining biomedical named entity recognition (BioNER) as a machine reading comprehension (MRC) problem, we propose a demonstration-based learning method to address few-shot BioNER, which involves constructing appropriate task demonstrations. In assessing our proposed method, we compared the proposed method with existing advanced methods using six benchmark datasets, including BC4CHEMD, BC5CDR-Chemical, BC5CDR-Disease, NCBI-Disease, BC2GM, and JNLPBA. We examined the models' efficacy by reporting F1 scores from both the 25-shot and 50-shot learning experiments. In 25-shot learning, we observed 1.1% improvements in the average F1 scores 
&lt;/p&gt;</description></item></channel></rss>