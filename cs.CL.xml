<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>LLM&#21463;&#21040;&#27745;&#26579;&#21487;&#33021;&#23548;&#33268;&#20854;&#24615;&#33021;&#19981;&#21487;&#38752;&#65292;&#25361;&#25112;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2404.00699</link><description>&lt;p&gt;
LLM&#21463;&#21040;&#22810;&#23569;&#27745;&#26579;&#65311;&#19968;&#39033;&#20840;&#38754;&#35843;&#26597;&#21644;LLMSanitize&#24211;
&lt;/p&gt;
&lt;p&gt;
How Much are LLMs Contaminated? A Comprehensive Survey and the LLMSanitize Library
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00699
&lt;/p&gt;
&lt;p&gt;
LLM&#21463;&#21040;&#27745;&#26579;&#21487;&#33021;&#23548;&#33268;&#20854;&#24615;&#33021;&#19981;&#21487;&#38752;&#65292;&#25361;&#25112;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#36817;&#24180;&#26469;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23835;&#36215;&#65292;&#26032;&#30340;&#26426;&#20250;&#27491;&#22312;&#20986;&#29616;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#27745;&#26579;&#38382;&#39064;&#36805;&#36895;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#20225;&#19994;&#24212;&#29992;&#21644;&#20154;&#24037;&#26234;&#33021;&#31609;&#27454;&#24050;&#32463;&#36798;&#21040;&#19968;&#23450;&#35268;&#27169;&#65292;&#27969;&#34892;&#30340;&#38382;&#31572;&#22522;&#20934;&#25552;&#39640;&#20960;&#20010;&#30334;&#20998;&#28857;&#21487;&#33021;&#24847;&#21619;&#30528;&#25968;&#30334;&#19975;&#32654;&#20803;&#65292;&#23545;&#27169;&#22411;&#30340;&#23436;&#25972;&#24615;&#26045;&#21152;&#20102;&#24040;&#22823;&#21387;&#21147;&#12290;&#21516;&#26102;&#65292;&#36861;&#36394;LLMs&#35265;&#36807;&#30340;&#25968;&#25454;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#65307;&#23545;&#20110;&#20687;GPT-4&#21644;Claude-3&#36825;&#26679;&#30340;&#38381;&#28304;&#27169;&#22411;&#65292;&#20182;&#20204;&#19981;&#36879;&#38706;&#20219;&#20309;&#26377;&#20851;&#35757;&#32451;&#38598;&#30340;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#27745;&#26579;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;LLMs&#30340;&#24615;&#33021;&#21487;&#33021;&#19981;&#20877;&#21487;&#38752;&#65292;&#22240;&#20026;&#20854;&#39640;&#24615;&#33021;&#33267;&#23569;&#37096;&#20998;&#24402;&#22240;&#20110;&#20854;&#20808;&#21069;&#25509;&#35302;&#21040;&#30340;&#25968;&#25454;&#12290;&#36825;&#31181;&#23616;&#38480;&#24615;&#21361;&#21450;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#22914;&#20309;&#26377;&#25928;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#20173;&#28982;&#32570;&#20047;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00699v1 Announce Type: new  Abstract: With the rise of Large Language Models (LLMs) in recent years, new opportunities are emerging, but also new challenges, and contamination is quickly becoming critical. Business applications and fundraising in AI have reached a scale at which a few percentage points gained on popular question-answering benchmarks could translate into dozens of millions of dollars, placing high pressure on model integrity. At the same time, it is becoming harder and harder to keep track of the data that LLMs have seen; if not impossible with closed-source models like GPT-4 and Claude-3 not divulging any information on the training set. As a result, contamination becomes a critical issue: LLMs' performance may not be reliable anymore, as the high performance may be at least partly due to their previous exposure to the data. This limitation jeopardizes the entire progress in the field of NLP, yet, there remains a lack of methods on how to efficiently address
&lt;/p&gt;</description></item><item><title>ClaimVer&#26159;&#19968;&#20010;&#20154;&#20026;&#20013;&#24515;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22768;&#26126;&#32423;&#39564;&#35777;&#21644;&#35777;&#25454;&#24402;&#22240;&#65292;&#33268;&#21147;&#20110;&#25552;&#39640;&#29992;&#25143;&#23545;&#25991;&#26412;&#39564;&#35777;&#26041;&#27861;&#30340;&#20449;&#20219;&#24182;&#24378;&#35843;&#32454;&#31890;&#24230;&#35777;&#25454;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09724</link><description>&lt;p&gt;
ClaimVer&#65306;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22768;&#26126;&#32423;&#39564;&#35777;&#21644;&#35777;&#25454;&#24402;&#22240;
&lt;/p&gt;
&lt;p&gt;
ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09724
&lt;/p&gt;
&lt;p&gt;
ClaimVer&#26159;&#19968;&#20010;&#20154;&#20026;&#20013;&#24515;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22768;&#26126;&#32423;&#39564;&#35777;&#21644;&#35777;&#25454;&#24402;&#22240;&#65292;&#33268;&#21147;&#20110;&#25552;&#39640;&#29992;&#25143;&#23545;&#25991;&#26412;&#39564;&#35777;&#26041;&#27861;&#30340;&#20449;&#20219;&#24182;&#24378;&#35843;&#32454;&#31890;&#24230;&#35777;&#25454;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#20256;&#25773;&#30340;&#20449;&#24687;&#35823;&#23548;&#21644;&#31038;&#20132;&#23186;&#20307;&#20197;&#21450;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#28608;&#22686;&#20013;&#65292;&#39564;&#35777;&#21644;&#20449;&#20219;&#25152;&#36935;&#21040;&#30340;&#20449;&#24687;&#21464;&#24471;&#26085;&#30410;&#22256;&#38590;&#12290;&#35768;&#22810;&#20107;&#23454;&#26680;&#26597;&#26041;&#27861;&#21644;&#24037;&#20855;&#24050;&#34987;&#24320;&#21457;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#32570;&#20047;&#36866;&#24403;&#30340;&#21487;&#35299;&#37322;&#24615;&#25110;&#32454;&#31890;&#24230;&#65292;&#26080;&#27861;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#21457;&#25381;&#20316;&#29992;&#12290;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#12289;&#21487;&#35775;&#38382;&#19988;&#33021;&#22815;&#25191;&#34892;&#32454;&#31890;&#24230;&#35777;&#25454;&#24402;&#22240;&#30340;&#25991;&#26412;&#39564;&#35777;&#26041;&#27861;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#24314;&#31435;&#29992;&#25143;&#23545;&#36825;&#31181;&#26041;&#27861;&#30340;&#20449;&#20219;&#38656;&#35201;&#21576;&#29616;&#27599;&#20010;&#39044;&#27979;&#32972;&#21518;&#30340;&#29702;&#30001;&#65292;&#22240;&#20026;&#30740;&#31350;&#34920;&#26126;&#36825;&#26174;&#33879;&#24433;&#21709;&#20154;&#20204;&#23545;&#33258;&#21160;&#21270;&#31995;&#32479;&#30340;&#20449;&#20219;&#12290;&#23558;&#29992;&#25143;&#20851;&#27880;&#37325;&#28857;&#25918;&#22312;&#20855;&#20307;&#30340;&#38382;&#39064;&#20869;&#23481;&#19978;&#65292;&#32780;&#19981;&#26159;&#25552;&#20379;&#31616;&#21333;&#30340;&#31548;&#32479;&#26631;&#31614;&#20063;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\textit{ClaimVer&#65292;&#19968;&#20010;&#20197;&#20154;&#20026;&#20013;&#24515;&#30340;&#26694;&#26550;}$&#65292;&#26088;&#22312;&#28385;&#36275;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09724v1 Announce Type: new  Abstract: In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people's belief in automated systems. It is also paramount to localize and bring users' attention to the specific problematic content, instead of providing simple blanket labels. In this paper, we present $\textit{ClaimVer, a human-centric framework}$ tailored to meet users' info
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102; Persona-DB&#65292;&#19968;&#20010;&#31616;&#21333;&#21364;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#32423;&#26500;&#24314;&#36807;&#31243;&#21644;&#21327;&#21516;&#20248;&#21270;&#65292;&#25913;&#21892;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#20013;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26816;&#32034;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.11060</link><description>&lt;p&gt;
Persona-DB&#65306;&#29992;&#20110;&#21709;&#24212;&#39044;&#27979;&#30340;&#39640;&#25928;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#19982;&#21327;&#21516;&#25968;&#25454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11060
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; Persona-DB&#65292;&#19968;&#20010;&#31616;&#21333;&#21364;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#32423;&#26500;&#24314;&#36807;&#31243;&#21644;&#21327;&#21516;&#20248;&#21270;&#65292;&#25913;&#21892;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#20013;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26816;&#32034;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20010;&#24615;&#21270;&#20132;&#20114;&#38656;&#27714;&#30340;&#22686;&#21152;&#65292;&#38656;&#35201;&#24320;&#21457;&#33021;&#22815;&#20934;&#30830;&#24555;&#36895;&#35782;&#21035;&#29992;&#25143;&#24847;&#35265;&#21644;&#20559;&#22909;&#30340;&#26041;&#27861;&#12290;&#26816;&#32034;&#22686;&#24378;&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#31574;&#30053;&#20986;&#29616;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#36866;&#24212;&#22823;&#37327;&#29992;&#25143;&#32780;&#26080;&#38656;&#36827;&#34892;&#24494;&#35843;&#30340;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22686;&#24378;&#26816;&#32034;&#38454;&#27573;&#65292;&#24182;&#23545;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#20248;&#21270;&#36827;&#34892;&#20102;&#26377;&#38480;&#30340;&#25506;&#32034;&#65292;&#36825;&#26159;&#20010;&#24615;&#21270;&#31561;&#20219;&#21153;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#26032;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#30528;&#37325;&#20110;&#22914;&#20309;&#26356;&#26377;&#25928;&#22320;&#34920;&#31034;&#25968;&#25454;&#65292;&#20197;&#20415;&#22312;LLM&#23450;&#21046;&#30340;&#24773;&#22659;&#19979;&#26356;&#26377;&#25928;&#22320;&#36827;&#34892;&#26816;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Persona-DB&#65292;&#36825;&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;&#20998;&#23618;&#26500;&#24314;&#36807;&#31243;&#65292;&#20197;&#25913;&#21892;&#36328;&#20219;&#21153;&#32972;&#26223;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#36827;&#34892;&#21327;&#21516;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11060v1 Announce Type: cross  Abstract: The increasing demand for personalized interactions with large language models (LLMs) calls for the development of methodologies capable of accurately and efficiently identifying user opinions and preferences. Retrieval augmentation emerges as an effective strategy, as it can accommodate a vast number of users without the costs from fine-tuning. Existing research, however, has largely focused on enhancing the retrieval stage and devoted limited exploration toward optimizing the representation of the database, a crucial aspect for tasks such as personalization. In this work, we examine the problem from a novel angle, focusing on how data can be better represented for more efficient retrieval in the context of LLM customization. To tackle this challenge, we introduce Persona-DB, a simple yet effective framework consisting of a hierarchical construction process to improve generalization across task contexts and collaborative refinement to
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20197;&#35299;&#20915;&#35774;&#35745;AI&#31995;&#32479;&#33021;&#22815;&#26381;&#21153;&#20110;&#20154;&#20204;&#20855;&#26377;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#38656;&#27714;&#12290;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#40784;&#23450;&#20041;&#21644;&#23454;&#29616;&#22810;&#20803;&#20027;&#20041;&#30340;&#19977;&#31181;&#26041;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#26469;&#35780;&#20272;&#21644;&#27979;&#35797;&#22810;&#20803;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.05070</link><description>&lt;p&gt;
&#36890;&#24448;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
A Roadmap to Pluralistic Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05070
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20197;&#35299;&#20915;&#35774;&#35745;AI&#31995;&#32479;&#33021;&#22815;&#26381;&#21153;&#20110;&#20154;&#20204;&#20855;&#26377;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#38656;&#27714;&#12290;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#40784;&#23450;&#20041;&#21644;&#23454;&#29616;&#22810;&#20803;&#20027;&#20041;&#30340;&#19977;&#31181;&#26041;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#26469;&#35780;&#20272;&#21644;&#27979;&#35797;&#22810;&#20803;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#26435;&#21147;&#21644;&#26222;&#21450;&#31243;&#24230;&#30340;&#22686;&#21152;&#65292;&#35774;&#35745;&#33021;&#22815;&#20026;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#20154;&#26381;&#21153;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#21464;&#24471;&#24840;&#21457;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23558;&#27169;&#22411;&#23545;&#40784;&#20197;&#26381;&#21153;&#22810;&#20803;&#20154;&#31867;&#20215;&#20540;&#35266;&#20173;&#28982;&#26159;&#19968;&#20010;&#24453;&#35299;&#20915;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20855;&#20307;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#27979;&#35797;&#24179;&#21488;&#12290;&#25105;&#20204;&#30830;&#23450;&#21644;&#24418;&#24335;&#21270;&#20102;&#19977;&#31181;&#21487;&#33021;&#30340;&#26041;&#24335;&#26469;&#23450;&#20041;&#21644;&#23454;&#29616;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#20013;&#30340;&#22810;&#20803;&#20027;&#20041;&#65306;1&#65289;Overton&#22810;&#20803;&#27169;&#22411;&#65292;&#23637;&#31034;&#21512;&#29702;&#21453;&#24212;&#30340;&#20809;&#35889;&#65307;2&#65289;&#21487;&#25805;&#25511;&#30340;&#22810;&#20803;&#27169;&#22411;&#65292;&#21487;&#20197;&#35843;&#25972;&#20197;&#21453;&#26144;&#29305;&#23450;&#30340;&#35266;&#28857;&#65307;3&#65289;&#20998;&#24067;&#22810;&#20803;&#27169;&#22411;&#65292;&#22312;&#20998;&#24067;&#20013;&#24456;&#22909;&#22320;&#26657;&#20934;&#32473;&#23450;&#20154;&#32676;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#21644;&#24418;&#24335;&#21270;&#20102;&#19977;&#31181;&#21487;&#33021;&#30340;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#65306;1&#65289;&#22810;&#30446;&#26631;&#22522;&#20934;&#65307;2&#65289;&#26435;&#34913;&#21487;&#25805;&#25511;&#22522;&#20934;&#65292;&#40723;&#21169;&#27169;&#22411;&#23545;&#20219;&#24847;&#26435;&#34913;&#36827;&#34892;&#35843;&#25972;&#65307;3&#65289;&#38506;&#23457;&#22242;&#22810;&#20803;&#22522;&#20934;&#65292;&#26126;&#30830;&#22320;&#27169;&#25311;&#20102;&#19981;&#21516;&#38506;&#23457;&#22242;&#30340;&#24847;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
With increased power and prevalence of AI systems, it is ever more critical that AI systems are designed to serve all, i.e., people with diverse values and perspectives. However, aligning models to serve pluralistic human values remains an open research question. In this piece, we propose a roadmap to pluralistic alignment, specifically using language models as a test bed. We identify and formalize three possible ways to define and operationalize pluralism in AI systems: 1) Overton pluralistic models that present a spectrum of reasonable responses; 2) Steerably pluralistic models that can steer to reflect certain perspectives; and 3) Distributionally pluralistic models that are well-calibrated to a given population in distribution. We also propose and formalize three possible classes of pluralistic benchmarks: 1) Multi-objective benchmarks, 2) Trade-off steerable benchmarks, which incentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which explicitly m
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;Clarify&#65292;&#19968;&#31181;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#32416;&#27491;&#27169;&#22411;&#38169;&#35823;&#27010;&#24565;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#29992;&#25143;&#25552;&#20379;&#31616;&#30701;&#30340;&#25991;&#26412;&#25551;&#36848;&#26469;&#32416;&#27491;&#27169;&#22411;&#30340;&#19968;&#33268;&#22833;&#36133;&#27169;&#24335;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03715</link><description>&lt;p&gt;
&#28548;&#28165;&#65306;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#32416;&#27491;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Clarify: Improving Model Robustness With Natural Language Corrections
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03715
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;Clarify&#65292;&#19968;&#31181;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#32416;&#27491;&#27169;&#22411;&#38169;&#35823;&#27010;&#24565;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#29992;&#25143;&#25552;&#20379;&#31616;&#30701;&#30340;&#25991;&#26412;&#25551;&#36848;&#26469;&#32416;&#27491;&#27169;&#22411;&#30340;&#19968;&#33268;&#22833;&#36133;&#27169;&#24335;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#34987;&#35757;&#32451;&#20174;&#38745;&#24577;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#30456;&#20851;&#24615;&#12290;&#36825;&#36890;&#24120;&#20250;&#23548;&#33268;&#27169;&#22411;&#20381;&#36182;&#20110;&#39640;&#32423;&#38169;&#35823;&#27010;&#24565;&#12290;&#20026;&#20102;&#38450;&#27490;&#36825;&#31181;&#38169;&#35823;&#27010;&#24565;&#65292;&#25105;&#20204;&#24517;&#39035;&#25552;&#20379;&#39069;&#22806;&#30340;&#20449;&#24687;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#21253;&#25324;&#19968;&#20123;&#39069;&#22806;&#30340;&#23454;&#20363;&#32423;&#30417;&#30563;&#24418;&#24335;&#65292;&#20363;&#22914;&#26631;&#35760;&#34394;&#20551;&#29305;&#24449;&#25110;&#26469;&#33258;&#24179;&#34913;&#20998;&#24067;&#30340;&#39069;&#22806;&#26631;&#35760;&#25968;&#25454;&#12290;&#23545;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#26469;&#35828;&#65292;&#36825;&#20123;&#31574;&#30053;&#21487;&#33021;&#20250;&#21464;&#24471;&#26114;&#36149;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20197;&#25509;&#36817;&#21407;&#22987;&#35757;&#32451;&#25968;&#25454;&#30340;&#35268;&#27169;&#36827;&#34892;&#39069;&#22806;&#27880;&#37322;&#12290;&#25105;&#20204;&#20551;&#35774;&#26377;&#38024;&#23545;&#24615;&#30340;&#20851;&#20110;&#27169;&#22411;&#38169;&#35823;&#27010;&#24565;&#30340;&#33258;&#28982;&#35821;&#35328;&#21453;&#39304;&#26159;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#39069;&#22806;&#30417;&#30563;&#24418;&#24335;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Clarify&#65292;&#19968;&#31181;&#26032;&#22411;&#30028;&#38754;&#21644;&#26041;&#27861;&#26469;&#20132;&#20114;&#24335;&#22320;&#32416;&#27491;&#27169;&#22411;&#30340;&#38169;&#35823;&#27010;&#24565;&#12290;&#36890;&#36807;Clarify&#65292;&#29992;&#25143;&#21482;&#38656;&#35201;&#25552;&#20379;&#19968;&#20010;&#31616;&#30701;&#30340;&#25991;&#26412;&#25551;&#36848;&#26469;&#25551;&#36848;&#27169;&#22411;&#30340;&#19968;&#33268;&#24615;&#22833;&#36133;&#27169;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23436;&#20840;&#33258;&#21160;&#21270;&#22320;&#20351;&#29992;s
&lt;/p&gt;
&lt;p&gt;
In supervised learning, models are trained to extract correlations from a static dataset. This often leads to models that rely on high-level misconceptions. To prevent such misconceptions, we must necessarily provide additional information beyond the training data. Existing methods incorporate forms of additional instance-level supervision, such as labels for spurious features or additional labeled data from a balanced distribution. Such strategies can become prohibitively costly for large-scale datasets since they require additional annotation at a scale close to the original training data. We hypothesize that targeted natural language feedback about a model's misconceptions is a more efficient form of additional supervision. We introduce Clarify, a novel interface and method for interactively correcting model misconceptions. Through Clarify, users need only provide a short text description to describe a model's consistent failure patterns. Then, in an entirely automated way, we use s
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#30740;&#31350;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#24212;&#29992;&#21644;&#32467;&#26524;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#21457;&#29616;&#20854;&#22312;&#35786;&#26029;&#12289;&#27835;&#30103;&#21644;&#24739;&#32773;&#21442;&#19982;&#22686;&#24378;&#31561;&#26041;&#38754;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#35782;&#21035;&#21644;&#35752;&#35770;&#20102;&#22312;&#36825;&#20123;&#19987;&#19994;&#39046;&#22495;&#20013;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.02984</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#39033;&#32508;&#36848;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Language Models in Mental Health Care: a Scoping Review. (arXiv:2401.02984v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#30740;&#31350;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#24212;&#29992;&#21644;&#32467;&#26524;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#21457;&#29616;&#20854;&#22312;&#35786;&#26029;&#12289;&#27835;&#30103;&#21644;&#24739;&#32773;&#21442;&#19982;&#22686;&#24378;&#31561;&#26041;&#38754;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#35782;&#21035;&#21644;&#35752;&#35770;&#20102;&#22312;&#36825;&#20123;&#19987;&#19994;&#39046;&#22495;&#20013;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20351;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#38656;&#35201;&#23545;&#23427;&#20204;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#39046;&#22495;&#30340;&#24212;&#29992;&#21644;&#32467;&#26524;&#36827;&#34892;&#20840;&#38754;&#30340;&#32508;&#36848;&#12290;&#26412;&#32508;&#36848;&#30740;&#31350;&#26088;&#22312;&#23545;LLMs&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#29616;&#26377;&#21457;&#23637;&#21644;&#24212;&#29992;&#36827;&#34892;&#25209;&#21028;&#24615;&#20998;&#26512;&#65292;&#31361;&#20986;&#23427;&#20204;&#30340;&#25104;&#21151;&#65292;&#24182;&#35782;&#21035;&#36825;&#20123;&#19987;&#19994;&#39046;&#22495;&#20013;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26448;&#26009;&#21644;&#26041;&#27861;&#65306;2023&#24180;11&#26376;&#65292;&#22312;PubMed&#12289;Web of Science&#12289;Google Scholar&#12289;arXiv&#12289;medRxiv&#21644;PsyArXiv&#20845;&#20010;&#25968;&#25454;&#24211;&#20013;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25991;&#29486;&#25628;&#32034;&#65292;&#36981;&#24490;2020&#24180;&#29256;&#30340;&#8220;&#31995;&#32479;&#35780;&#20215;&#21644;Meta&#20998;&#26512;&#30340;&#39318;&#36873;&#25253;&#21578;&#39033;&#30446;&#8221;&#65288;PRISMA&#65289;&#25351;&#21335;&#12290;&#26368;&#21021;&#35782;&#21035;&#20102;313&#31687;&#20986;&#29256;&#29289;&#65292;&#25353;&#29031;&#30740;&#31350;&#32435;&#20837;&#26631;&#20934;&#65292;&#26368;&#32456;&#36873;&#25321;&#20102;34&#31687;&#20986;&#29256;&#29289;&#36827;&#34892;&#32508;&#36848;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#21457;&#29616;&#20102;LLMs&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#65292;&#21253;&#25324;&#35786;&#26029;&#12289;&#27835;&#30103;&#12289;&#24739;&#32773;&#21442;&#19982;&#22686;&#24378;&#31561;&#12290;&#20851;&#38190;&#25361;&#25112;&#21644;&#38480;&#21046;&#26041;&#38754;&#30340;&#21457;&#29616;&#23558;&#34987;&#24635;&#32467;&#21644;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objective: The growing use of large language models (LLMs) stimulates a need for a comprehensive review of their applications and outcomes in mental health care contexts. This scoping review aims to critically analyze the existing development and applications of LLMs in mental health care, highlighting their successes and identifying their challenges and limitations in these specialized fields. Materials and Methods: A broad literature search was conducted in November 2023 using six databases (PubMed, Web of Science, Google Scholar, arXiv, medRxiv, and PsyArXiv) following the 2020 version of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A total of 313 publications were initially identified, and after applying the study inclusion criteria, 34 publications were selected for the final review. Results: We identified diverse applications of LLMs in mental health care, including diagnosis, therapy, patient engagement enhancement, etc. Key challen
&lt;/p&gt;</description></item><item><title>InstructERC&#26159;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#29983;&#25104;&#24335;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#26816;&#32034;&#27169;&#26495;&#27169;&#22359;&#21644;&#39069;&#22806;&#30340;&#24773;&#24863;&#23545;&#40784;&#20219;&#21153;&#65292;&#25913;&#38761;&#20102;&#23545;&#35805;&#20013;&#30340;&#24773;&#32490;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2309.11911</link><description>&lt;p&gt;
InstructERC&#65306;&#20511;&#21161;&#26816;&#32034;&#22810;&#20219;&#21153;LLMs&#26694;&#26550;&#25913;&#38761;&#23545;&#35805;&#20013;&#30340;&#24773;&#32490;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework. (arXiv:2309.11911v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11911
&lt;/p&gt;
&lt;p&gt;
InstructERC&#26159;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#29983;&#25104;&#24335;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#26816;&#32034;&#27169;&#26495;&#27169;&#22359;&#21644;&#39069;&#22806;&#30340;&#24773;&#24863;&#23545;&#40784;&#20219;&#21153;&#65292;&#25913;&#38761;&#20102;&#23545;&#35805;&#20013;&#30340;&#24773;&#32490;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24773;&#32490;&#35782;&#21035;(ERC)&#30340;&#21457;&#23637;&#19968;&#30452;&#21463;&#21040;&#31649;&#36947;&#35774;&#35745;&#22797;&#26434;&#24615;&#30340;&#38459;&#30861;&#65292;&#23548;&#33268;ERC&#27169;&#22411;&#24448;&#24448;&#23545;&#29305;&#23450;&#25968;&#25454;&#38598;&#21644;&#23545;&#35805;&#27169;&#24335;&#36807;&#25311;&#21512;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;InstructERC&#65292;&#23558;ERC&#20219;&#21153;&#20174;&#21028;&#21035;&#24335;&#26694;&#26550;&#36716;&#21270;&#20026;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#29983;&#25104;&#24335;&#26694;&#26550;&#12290;InstructERC&#26377;&#20004;&#20010;&#37325;&#35201;&#36129;&#29486;&#65306;&#39318;&#20808;&#65292;InstructERC&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26816;&#32034;&#27169;&#26495;&#27169;&#22359;&#65292;&#36890;&#36807;&#23558;&#21382;&#21490;&#23545;&#35805;&#20869;&#23481;&#12289;&#26631;&#31614;&#35821;&#21477;&#21644;&#24773;&#24863;&#39046;&#22495;&#28436;&#31034;&#19982;&#39640;&#35821;&#20041;&#30456;&#20284;&#24615;&#36827;&#34892;&#25340;&#25509;&#65292;&#24110;&#21161;&#27169;&#22411;&#26126;&#30830;&#22320;&#38598;&#25104;&#22810;&#31890;&#24230;&#23545;&#35805;&#30417;&#30563;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#39069;&#22806;&#30340;&#24773;&#24863;&#23545;&#40784;&#20219;&#21153;&#65292;&#21363;&#35828;&#35805;&#20154;&#35782;&#21035;&#21644;&#24773;&#24863;&#39044;&#27979;&#20219;&#21153;&#65292;&#20197;&#38544;&#24335;&#22320;&#24314;&#27169;&#23545;&#35805;&#35282;&#33394;&#20851;&#31995;&#21644;&#26410;&#26469;&#23545;&#35805;&#24773;&#32490;&#20542;&#21521;&#12290;&#25105;&#20204;&#30340;&#22522;&#20110;LLM&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The development of emotion recognition in dialogue (ERC) has been consistently hindered by the complexity of pipeline designs, leading to ERC models that often overfit to specific datasets and dialogue patterns. In this study, we propose a novel approach, namely  InstructERC, to reformulates the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs) . InstructERC has two significant contributions: Firstly, InstructERC introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information by concatenating the historical dialog content, label statement, and emotional domain demonstrations with high semantic similarity. Furthermore, we introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. Our LLM-based
&lt;/p&gt;</description></item><item><title>Kosmos-2.5&#26159;&#19968;&#20010;&#22810;&#27169;&#24577;&#25991;&#23398;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#26426;&#22120;&#38405;&#35835;&#25991;&#26412;&#23494;&#38598;&#22411;&#22270;&#20687;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#31354;&#38388;&#24863;&#30340;&#25991;&#26412;&#22359;&#21644;&#32467;&#26500;&#21270;&#25991;&#26412;&#36755;&#20986;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#36890;&#29992;&#24615;&#65292;&#21487;&#20197;&#36866;&#24212;&#19981;&#21516;&#25552;&#31034;&#19979;&#20219;&#20309;&#25991;&#26412;&#23494;&#38598;&#22411;&#22270;&#20687;&#29702;&#35299;&#20219;&#21153;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#25193;&#23637;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2309.11419</link><description>&lt;p&gt;
Kosmos-2.5: &#19968;&#20010;&#22810;&#27169;&#24577;&#25991;&#23398;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Kosmos-2.5: A Multimodal Literate Model. (arXiv:2309.11419v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11419
&lt;/p&gt;
&lt;p&gt;
Kosmos-2.5&#26159;&#19968;&#20010;&#22810;&#27169;&#24577;&#25991;&#23398;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#26426;&#22120;&#38405;&#35835;&#25991;&#26412;&#23494;&#38598;&#22411;&#22270;&#20687;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#31354;&#38388;&#24863;&#30340;&#25991;&#26412;&#22359;&#21644;&#32467;&#26500;&#21270;&#25991;&#26412;&#36755;&#20986;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#36890;&#29992;&#24615;&#65292;&#21487;&#20197;&#36866;&#24212;&#19981;&#21516;&#25552;&#31034;&#19979;&#20219;&#20309;&#25991;&#26412;&#23494;&#38598;&#22411;&#22270;&#20687;&#29702;&#35299;&#20219;&#21153;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#25193;&#23637;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;Kosmos-2.5&#65292;&#19968;&#20010;&#29992;&#20110;&#23545;&#25991;&#26412;&#23494;&#38598;&#22411;&#22270;&#20687;&#36827;&#34892;&#26426;&#22120;&#38405;&#35835;&#30340;&#22810;&#27169;&#24577;&#25991;&#23398;&#27169;&#22411;&#12290;Kosmos-2.5&#22312;&#20004;&#20010;&#19981;&#21516;&#20294;&#30456;&#20114;&#21512;&#20316;&#30340;&#36716;&#24405;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65306;(1) &#29983;&#25104;&#20855;&#26377;&#31354;&#38388;&#24863;&#30340;&#25991;&#26412;&#22359;&#65292;&#20854;&#20013;&#27599;&#20010;&#25991;&#26412;&#22359;&#37117;&#34987;&#36171;&#20104;&#20854;&#22312;&#22270;&#20687;&#20013;&#30340;&#31354;&#38388;&#22352;&#26631;&#65292;&#20197;&#21450;(2) &#29983;&#25104;&#20197;Markdown&#26684;&#24335;&#25429;&#25417;&#26679;&#24335;&#21644;&#32467;&#26500;&#30340;&#32467;&#26500;&#21270;&#25991;&#26412;&#36755;&#20986;&#12290;&#36825;&#31181;&#32479;&#19968;&#30340;&#22810;&#27169;&#24577;&#25991;&#23398;&#33021;&#21147;&#26159;&#36890;&#36807;&#20849;&#20139;&#30340;Transformer&#26550;&#26500;&#12289;&#20219;&#21153;&#29305;&#23450;&#30340;&#25552;&#31034;&#21644;&#28789;&#27963;&#30340;&#25991;&#26412;&#34920;&#31034;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#22312;&#31471;&#21040;&#31471;&#30340;&#25991;&#26723;&#32423;&#25991;&#26412;&#35782;&#21035;&#21644;&#22270;&#20687;&#21040;Markdown&#25991;&#26412;&#29983;&#25104;&#19978;&#35780;&#20272;&#20102;Kosmos-2.5&#12290;&#27492;&#22806;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#30417;&#30563;&#24494;&#35843;&#36731;&#26494;&#36866;&#24212;&#20855;&#26377;&#19981;&#21516;&#25552;&#31034;&#30340;&#20219;&#20309;&#25991;&#26412;&#23494;&#38598;&#22411;&#22270;&#20687;&#29702;&#35299;&#20219;&#21153;&#65292;&#20351;&#20854;&#25104;&#20026;&#28041;&#21450;&#25991;&#26412;&#20016;&#23500;&#22270;&#20687;&#30340;&#23454;&#38469;&#24212;&#29992;&#30340;&#36890;&#29992;&#24037;&#20855;&#12290;&#36825;&#39033;&#24037;&#20316;&#36824;&#20026;&#26410;&#26469;&#30340;&#25193;&#23637;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images. Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format. This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations. We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation. Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images. This work also paves the way for the future scaling o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#27979;&#35797;&#65292;&#25361;&#25112;&#24403;&#21069;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#38271;&#25991;&#26723;&#12289;&#21033;&#29992;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#12289;&#22810;&#35821;&#35328;&#29702;&#35299;&#21644;&#22810;&#20219;&#21153;&#22788;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#22522;&#20934;&#27979;&#35797;&#21253;&#21547;&#29790;&#22763;&#27861;&#24459;&#31995;&#32479;&#30340;&#22810;&#26679;&#21270;&#27861;&#24459;NLP&#25968;&#25454;&#38598;&#65292;&#20801;&#35768;&#36827;&#34892;&#23545;&#24213;&#23618;&#38750;&#33521;&#35821;&#12289;&#22266;&#26377;&#22810;&#35821;&#35328;&#30340;&#27861;&#24459;&#31995;&#32479;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2306.09237</link><description>&lt;p&gt;
SCALE: &#25552;&#21319;&#39640;&#32423;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#30340;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
SCALE: Scaling up the Complexity for Advanced Language Model Evaluation. (arXiv:2306.09237v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09237
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#27979;&#35797;&#65292;&#25361;&#25112;&#24403;&#21069;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#38271;&#25991;&#26723;&#12289;&#21033;&#29992;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#12289;&#22810;&#35821;&#35328;&#29702;&#35299;&#21644;&#22810;&#20219;&#21153;&#22788;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#22522;&#20934;&#27979;&#35797;&#21253;&#21547;&#29790;&#22763;&#27861;&#24459;&#31995;&#32479;&#30340;&#22810;&#26679;&#21270;&#27861;&#24459;NLP&#25968;&#25454;&#38598;&#65292;&#20801;&#35768;&#36827;&#34892;&#23545;&#24213;&#23618;&#38750;&#33521;&#35821;&#12289;&#22266;&#26377;&#22810;&#35821;&#35328;&#30340;&#27861;&#24459;&#31995;&#32479;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26041;&#38754;&#21462;&#24471;&#30340;&#36827;&#23637;&#24050;&#32463;&#39281;&#21644;&#20102;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#27979;&#35797;&#65288;&#21253;&#25324;&#19987;&#19994;&#39046;&#22495;&#30340;&#22522;&#20934;&#27979;&#35797;&#65289;&#65292;&#24378;&#35843;&#20102;&#38656;&#35201;&#26032;&#39062;&#12289;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#27979;&#35797;&#26469;&#27491;&#30830;&#35780;&#20272;LLM&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#27979;&#35797;&#65292;&#23545;&#24403;&#21069;LLM&#30340;&#22235;&#20010;&#20851;&#38190;&#26041;&#38754;&#25552;&#20986;&#20102;&#25361;&#25112;&#65306;&#22788;&#29702;&#38271;&#25991;&#26723;&#65288;&#22810;&#36798;50K&#20010;&#26631;&#35760;&#65289;&#12289;&#21033;&#29992;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#65288;&#20307;&#29616;&#22312;&#27861;&#24459;&#25991;&#26412;&#20013;&#65289;&#12289;&#22810;&#35821;&#35328;&#29702;&#35299;&#65288;&#28085;&#30422;&#20116;&#31181;&#35821;&#35328;&#65289;&#21644;&#22810;&#20219;&#21153;&#22788;&#29702;&#65288;&#21253;&#25324;&#27861;&#24459;&#25991;&#20214;&#21040;&#25991;&#20214;&#20449;&#24687;&#26816;&#32034;&#12289;&#27861;&#24237;&#35270;&#22270;&#29983;&#25104;&#12289;&#37325;&#35201;&#20915;&#31574;&#25688;&#35201;&#12289;&#24341;&#29992;&#25552;&#21462;&#21644;&#20843;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#65289;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#21253;&#21547;&#20102;&#26469;&#33258;&#29790;&#22763;&#27861;&#24459;&#31995;&#32479;&#30340;&#22810;&#26679;&#30340;&#27861;&#24459;NLP&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#23545;&#24213;&#23618;&#38750;&#33521;&#35821;&#12289;&#22266;&#26377;&#22810;&#35821;&#35328;&#30340;&#32852;&#37030;&#27861;&#24459;&#31995;&#32479;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;&#12290;&#23613;&#31649;&#26368;&#36817;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#23545;&#20110;&#24378;&#28872;&#30340;&#23457;&#26597;/&#20998;&#26512;&#20219;&#21153;&#65292;&#39640;&#25928;&#22320;&#22788;&#29702;&#38271;&#25991;&#26723;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent strides in Large Language Models (LLMs) have saturated many NLP benchmarks (even professional domain-specific ones), emphasizing the need for novel, more challenging novel ones to properly assess LLM capabilities. In this paper, we introduce a novel NLP benchmark that poses challenges to current LLMs across four key dimensions: processing long documents (up to 50K tokens), utilizing domain specific knowledge (embodied in legal texts), multilingual understanding (covering five languages), and multitasking (comprising legal document to document Information Retrieval, Court View Generation, Leading Decision Summarization, Citation Extraction, and eight challenging Text Classification tasks). Our benchmark comprises diverse legal NLP datasets from the Swiss legal system, allowing for a comprehensive study of the underlying Non-English, inherently multilingual, federal legal system. Despite recent advances, efficiently processing long documents for intense review/analysis tasks remai
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#20998;&#26512;&#26694;&#26550;CALM&#65292;&#36890;&#36807;&#26377;&#38024;&#23545;&#24615;&#30340;&#24178;&#39044;&#26469;&#30772;&#22351;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#35780;&#20272;&#20854;&#22312;&#25191;&#34892;&#20219;&#21153;&#26102;&#23545;&#19981;&#21516;&#34920;&#31034;&#30340;&#20351;&#29992;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#35821;&#35328;&#27169;&#22411;&#23545;&#20851;&#31995;&#23646;&#24615;&#30340;&#21033;&#29992;&#23384;&#22312;&#19968;&#23450;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.00333</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Competence-Based Analysis of Language Models. (arXiv:2303.00333v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00333
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#20998;&#26512;&#26694;&#26550;CALM&#65292;&#36890;&#36807;&#26377;&#38024;&#23545;&#24615;&#30340;&#24178;&#39044;&#26469;&#30772;&#22351;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#35780;&#20272;&#20854;&#22312;&#25191;&#34892;&#20219;&#21153;&#26102;&#23545;&#19981;&#21516;&#34920;&#31034;&#30340;&#20351;&#29992;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#35821;&#35328;&#27169;&#22411;&#23545;&#20851;&#31995;&#23646;&#24615;&#30340;&#21033;&#29992;&#23384;&#22312;&#19968;&#23450;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#22312;&#21508;&#31181;&#25552;&#31034;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#21151;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#23545;&#36755;&#20837;&#25110;&#24212;&#29992;&#29615;&#22659;&#20013;&#30340;&#24494;&#23567;&#21464;&#21270;&#21364;&#24322;&#24120;&#33030;&#24369;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#34892;&#20026;&#24182;&#28608;&#21169;&#35774;&#35745;&#26356;&#20581;&#22766;&#30340;LMs&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#23454;&#39564;&#26694;&#26550;CALM&#65288;&#22522;&#20110;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#20998;&#26512;&#65289;&#65292;&#20854;&#20013;&#21033;&#29992;&#26377;&#38024;&#23545;&#24615;&#30340;&#22240;&#26524;&#24178;&#39044;&#26469;&#30772;&#22351;LM&#22312;&#21508;&#31181;&#35821;&#35328;&#23646;&#24615;&#19978;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#20197;&#35780;&#20272;&#23427;&#22312;&#25191;&#34892;&#32473;&#23450;&#20219;&#21153;&#26102;&#23545;&#27599;&#20010;&#34920;&#31034;&#30340;&#20351;&#29992;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#24178;&#39044;&#23454;&#29616;&#20026;&#22522;&#20110;&#26799;&#24230;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#19982;&#20808;&#21069;&#30340;&#22240;&#26524;&#25506;&#26597;&#26041;&#27861;&#30456;&#27604;&#65292;&#23427;&#20204;&#33021;&#22815;&#38024;&#23545;&#20219;&#24847;&#32534;&#30721;&#30340;&#20851;&#31995;&#23646;&#24615;&#36827;&#34892;&#25915;&#20987;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;BERT-like LMs&#22312;&#25191;&#34892;&#30456;&#20851;&#20851;&#31995;&#25552;&#31034;&#20219;&#21153;&#26102;&#22914;&#20309;&#20351;&#29992;&#22810;&#31181;&#20851;&#31995;&#23646;&#24615;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#34920;&#31034;&#30340;&#36873;&#25321;&#23545;LM&#30340;&#24615;&#33021;&#20135;&#29983;&#20102;&#24433;&#21709;&#65292;&#20294;&#27169;&#22411;&#23545;&#26576;&#20123;&#29305;&#23450;&#20851;&#31995;&#23646;&#24615;&#30340;&#21033;&#29992;&#24182;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the recent success of large pretrained language models (LMs) on a variety of prompting tasks, these models can be alarmingly brittle to small changes in inputs or application contexts. To better understand such behavior and motivate the design of more robust LMs, we propose a general experimental framework, CALM (Competence-based Analysis of Language Models), where targeted causal interventions are utilized to damage an LM's internal representation of various linguistic properties in order to evaluate its use of each representation in performing a given task. We implement these interventions as gradient-based adversarial attacks, which (in contrast to prior causal probing methodologies) are able to target arbitrarily-encoded representations of relational properties, and carry out a case study of this approach to analyze how BERT-like LMs use representations of several relational properties in performing associated relation prompting tasks. We find that, while the representation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20154;&#31867;&#35789;&#27719;&#32852;&#24819;&#30340;&#31038;&#20132;&#32593;&#32476;&#20027;&#39064;&#26816;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#32771;&#34385;&#35821;&#35328;&#32467;&#26500;&#24182;&#35774;&#35745;&#19987;&#38376;&#30340;&#25277;&#21462;&#31639;&#27861;&#65292;&#22312;FA-CUP&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.13066</link><description>&lt;p&gt;
&#22522;&#20110;&#20154;&#31867;&#35789;&#27719;&#32852;&#24819;&#30340;&#31038;&#20132;&#32593;&#32476;&#20027;&#39064;&#26816;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Human Word Association based model for topic detection in social networks. (arXiv:2301.13066v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20154;&#31867;&#35789;&#27719;&#32852;&#24819;&#30340;&#31038;&#20132;&#32593;&#32476;&#20027;&#39064;&#26816;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#32771;&#34385;&#35821;&#35328;&#32467;&#26500;&#24182;&#35774;&#35745;&#19987;&#38376;&#30340;&#25277;&#21462;&#31639;&#27861;&#65292;&#22312;FA-CUP&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31038;&#20132;&#32593;&#32476;&#30340;&#24191;&#27867;&#20351;&#29992;&#65292;&#26816;&#27979;&#36825;&#20123;&#32593;&#32476;&#20013;&#35752;&#35770;&#30340;&#20027;&#39064;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#30446;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#22522;&#20110;&#39057;&#32321;&#27169;&#24335;&#25366;&#25496;&#25110;&#35821;&#20041;&#20851;&#31995;&#65292;&#32780;&#27809;&#26377;&#32771;&#34385;&#35821;&#35328;&#32467;&#26500;&#12290;&#35821;&#35328;&#32467;&#26500;&#26041;&#27861;&#30340;&#24847;&#20041;&#22312;&#20110;&#21457;&#29616;&#35789;&#35821;&#20043;&#38388;&#30340;&#20851;&#31995;&#20197;&#21450;&#20154;&#31867;&#22914;&#20309;&#29702;&#35299;&#23427;&#20204;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#21033;&#29992;&#35789;&#27719;&#32852;&#24819;&#30340;&#24515;&#29702;&#33021;&#21147;&#27169;&#25311;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20154;&#31867;&#35789;&#27719;&#32852;&#24819;&#30340;&#31038;&#20132;&#32593;&#32476;&#20027;&#39064;&#26816;&#27979;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#20154;&#31867;&#35789;&#27719;&#32852;&#24819;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19987;&#38376;&#30340;&#25277;&#21462;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;FA-CUP&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#20027;&#39064;&#26816;&#27979;&#39046;&#22495;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20027;&#39064;&#21484;&#22238;&#29575;&#21644;&#20851;&#38190;&#35789;F1&#20540;&#19978;&#26377;&#36739;&#22909;&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#20027;&#39064;&#26816;&#27979;&#39046;&#22495;&#20013;&#30340;&#22823;&#22810;&#25968;&#20808;&#21069;&#24037;&#20316;&#20027;&#35201;&#22522;&#20110;&#27169;&#24335;&#25366;&#25496;&#25110;&#35821;&#20041;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the widespread use of social networks, detecting the topics discussed in these networks has become a significant challenge. The current works are mainly based on frequent pattern mining or semantic relations, and the language structure is not considered. The meaning of language structural methods is to discover the relationship between words and how humans understand them. Therefore, this paper uses the Concept of the Imitation of the Mental Ability of Word Association to propose a topic detection framework in social networks. This framework is based on the Human Word Association method. A special extraction algorithm has also been designed for this purpose. The performance of this method is evaluated on the FA-CUP dataset. It is a benchmark dataset in the field of topic detection. The results show that the proposed method is a good improvement compared to other methods, based on the Topic-recall and the keyword F1 measure. Also, most of the previous works in the field of topic de
&lt;/p&gt;</description></item></channel></rss>