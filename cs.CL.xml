<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#29992;&#19988;&#20415;&#21033;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#22411;&#32534;&#30721;&#22120;&#35821;&#35328;&#27169;&#22411;&#21644;&#20132;&#21449;&#27880;&#24847;&#21147;&#65292;&#20351;&#21407;&#22987;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#35206;&#30422;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#65292;&#20174;&#32780;&#25552;&#39640;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.02022</link><description>&lt;p&gt;
&#20248;&#21270;&#21521;&#37327;&#21270;&#19978;&#19979;&#25991;&#30340;&#26816;&#32034;&#22686;&#24378;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02022
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#29992;&#19988;&#20415;&#21033;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#22411;&#32534;&#30721;&#22120;&#35821;&#35328;&#27169;&#22411;&#21644;&#20132;&#21449;&#27880;&#24847;&#21147;&#65292;&#20351;&#21407;&#22987;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#35206;&#30422;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#65292;&#20174;&#32780;&#25552;&#39640;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65292;&#24212;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31561;&#25216;&#26415;&#21487;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#38382;&#39064;&#12290;&#30001;&#20110;&#27169;&#22411;&#22823;&#23567;&#21644;&#35745;&#31639;&#36164;&#28304;&#31561;&#32422;&#26463;&#65292;&#19978;&#19979;&#25991;&#38271;&#24230;&#36890;&#24120;&#21463;&#38480;&#65292;&#35753;&#27169;&#22411;&#35206;&#30422;&#36807;&#38271;&#30340;&#19978;&#19979;&#25991;&#24182;&#22238;&#31572;&#26469;&#33258;&#24320;&#25918;&#39046;&#22495;&#30340;&#38382;&#39064;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#20219;&#21153;&#20013;&#35206;&#30422;&#26356;&#38271;&#19978;&#19979;&#25991;&#30340;&#36890;&#29992;&#12289;&#26041;&#20415;&#26041;&#27861;&#12290;&#23427;&#21033;&#29992;&#19968;&#20010;&#23567;&#22411;&#32534;&#30721;&#22120;&#35821;&#35328;&#27169;&#22411;&#26377;&#25928;&#32534;&#30721;&#19978;&#19979;&#25991;&#65292;&#24182;&#23545;&#21407;&#22987;&#36755;&#20837;&#24212;&#29992;&#20132;&#21449;&#27880;&#24847;&#21147;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21407;&#22987;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#35206;&#30422;&#20960;&#20493;&#38271;&#30340;&#19978;&#19979;&#25991;&#65292;&#21516;&#26102;&#20445;&#25345;&#19982;&#22522;&#32447;&#25509;&#36817;&#30340;&#35745;&#31639;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#24494;&#35843;&#21518;&#65292;&#24615;&#33021;&#22312;&#20004;&#20010;&#20445;&#23384;&#30340;&#25968;&#25454;&#38598;&#12289;&#22235;&#20010;&#20445;&#30041;&#30340;&#25968;&#25454;&#38598;&#20197;&#21450;&#20004;&#20010;In Context
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02022v1 Announce Type: new  Abstract: In the era of large language models, applying techniques such as Retrieval Augmented Generation can better address Open-Domain Question-Answering problems. Due to constraints including model sizes and computing resources, the length of context is often limited, and it becomes challenging to empower the model to cover overlong contexts while answering questions from open domains. This paper proposes a general and convenient method to covering longer contexts in Open-Domain Question-Answering tasks. It leverages a small encoder language model that effectively encodes contexts, and the encoding applies cross-attention with origin inputs. With our method, the origin language models can cover several times longer contexts while keeping the computing requirements close to the baseline. Our experiments demonstrate that after fine-tuning, there is improved performance across two held-in datasets, four held-out datasets, and also in two In Contex
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;SR$_{\text{LLM}}$&#65292;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;&#20840;&#38754;&#30340;&#23433;&#20840;&#39118;&#38505;&#20998;&#31867;&#27861;&#21644;&#19987;&#23478;&#26631;&#27880;&#25968;&#25454;&#38598;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#35821;&#35328;&#29983;&#25104;&#20013;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#36890;&#36807;&#25351;&#20196;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#26041;&#27861;&#26377;&#25928;&#20943;&#23569;&#20102;&#19981;&#23433;&#20840;&#20869;&#23481;&#30340;&#29983;&#25104;&#12290;</title><link>https://arxiv.org/abs/2404.01399</link><description>&lt;p&gt;
&#24320;&#21457;&#23433;&#20840;&#21644;&#36127;&#36131;&#20219;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; - &#19968;&#20010;&#20840;&#38754;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Developing Safe and Responsible Large Language Models -- A Comprehensive Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01399
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;SR$_{\text{LLM}}$&#65292;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;&#20840;&#38754;&#30340;&#23433;&#20840;&#39118;&#38505;&#20998;&#31867;&#27861;&#21644;&#19987;&#23478;&#26631;&#27880;&#25968;&#25454;&#38598;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#35821;&#35328;&#29983;&#25104;&#20013;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#36890;&#36807;&#25351;&#20196;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#26041;&#27861;&#26377;&#25928;&#20943;&#23569;&#20102;&#19981;&#23433;&#20840;&#20869;&#23481;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#20154;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#23433;&#20840;&#24615;&#21644;&#39118;&#38505;&#26085;&#30410;&#20851;&#27880;&#65292;&#21457;&#23637;&#20943;&#36731;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23433;&#20840;&#21644;&#36127;&#36131;&#20219;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;SR$_{\text{LLM}}$&#65289;&#65292;&#36825;&#20010;&#27169;&#22411;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;LLM&#26469;&#22686;&#24378;&#35821;&#35328;&#29983;&#25104;&#30340;&#23433;&#20840;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;LLM&#23433;&#20840;&#39118;&#38505;&#20998;&#31867;&#27861;&#65292;&#24182;&#21033;&#29992;&#19987;&#23478;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#19982;&#36825;&#31181;&#20998;&#31867;&#27861;&#30456;&#19968;&#33268;&#12290;SR$_{\text{LLM}}$&#26088;&#22312;&#35782;&#21035;&#28508;&#22312;&#30340;&#19981;&#23433;&#20840;&#20869;&#23481;&#24182;&#20135;&#29983;&#33391;&#24615;&#21464;&#21270;&#12290;&#23427;&#37319;&#29992;&#22522;&#20110;&#25351;&#20196;&#30340;&#21644;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#20351;&#24471;&#35813;&#27169;&#22411;&#19981;&#20165;&#26377;&#25928;&#22320;&#22686;&#24378;&#23433;&#20840;&#24615;&#65292;&#32780;&#19988;&#36164;&#28304;&#39640;&#25928;&#19988;&#26131;&#20110;&#35843;&#25972;&#12290;&#22312;&#25105;&#20204;&#23545;&#20116;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#19987;&#26377;&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#19981;&#23433;&#20840;&#20869;&#23481;&#29983;&#25104;&#30340;&#26174;&#33879;&#20943;&#23569;&#12290;&#27492;&#22806;&#65292;&#22312;&#23454;&#26045;&#23433;&#20840;&#25514;&#26045;&#21518;&#65292;&#20986;&#29616;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01399v1 Announce Type: new  Abstract: Given the growing concerns around the safety and risks of Large Language Models (LLMs), it is essential to develop methods for mitigating these issues. We introduce Safe and Responsible Large Language Model (SR$_{\text{LLM}}$) , a model designed to enhance the safety of language generation using LLMs. Our approach incorporates a comprehensive LLM safety risk taxonomy and utilizes a dataset annotated by experts that align with this taxonomy. SR$_{\text{LLM}}$ is designed to identify potentially unsafe content and produce benign variations. It employs instruction-based and parameter-efficient fine-tuning methods, making the model not only effective in enhancing safety but also resource-efficient and straightforward to adjust. Through our testing on five benchmark datasets and two proprietary datasets, we observed notable reductions in the generation of unsafe content. Moreover, following the implementation of safety measures, there was a s
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25968;&#23383;&#23402;&#29983;&#20307;TWIN-GPT&#65292;&#29992;&#20110;&#25903;&#25345;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#12290;</title><link>https://arxiv.org/abs/2404.01273</link><description>&lt;p&gt;
TWIN-GPT: &#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#20020;&#24202;&#35797;&#39564;&#25968;&#23383;&#23402;&#29983;&#20307;
&lt;/p&gt;
&lt;p&gt;
TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01273
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25968;&#23383;&#23402;&#29983;&#20307;TWIN-GPT&#65292;&#29992;&#20110;&#25903;&#25345;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#34394;&#25311;&#20020;&#24202;&#35797;&#39564;&#20135;&#29983;&#20102;&#26085;&#30410;&#22686;&#38271;&#30340;&#20852;&#36259;&#65292;&#36825;&#20123;&#35797;&#39564;&#27169;&#25311;&#20102;&#29616;&#23454;&#19990;&#30028;&#24773;&#22659;&#65292;&#26377;&#26395;&#26174;&#33879;&#22686;&#24378;&#24739;&#32773;&#23433;&#20840;&#24615;&#65292;&#21152;&#24555;&#24320;&#21457;&#36895;&#24230;&#65292;&#38477;&#20302;&#25104;&#26412;&#65292;&#24182;&#20026;&#21307;&#30103;&#39046;&#22495;&#30340;&#26356;&#24191;&#27867;&#31185;&#23398;&#30693;&#35782;&#36129;&#29486;&#21147;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25968;&#23383;&#23402;&#29983;&#20307;TWIN-GPT&#65292;&#29992;&#20110;&#25903;&#25345;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01273v1 Announce Type: cross  Abstract: Recently, there has been a burgeoning interest in virtual clinical trials, which simulate real-world scenarios and hold the potential to significantly enhance patient safety, expedite development, reduce costs, and contribute to the broader scientific knowledge in healthcare. Existing research often focuses on leveraging electronic health records (EHRs) to support clinical trial outcome prediction. Yet, trained with limited clinical trial outcome data, existing approaches frequently struggle to perform accurate predictions. Some research has attempted to generate EHRs to augment model development but has fallen short in personalizing the generation for individual patient profiles. Recently, the emergence of large language models has illuminated new possibilities, as their embedded comprehensive clinical knowledge has proven beneficial in addressing medical issues. In this paper, we propose a large language model-based digital twin crea
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20174;&#21307;&#23398;&#25945;&#26448;&#25552;&#21462;&#30340;&#25512;&#29702;&#36335;&#24452;&#21644;&#22810;&#26679;&#21270;&#30340;&#36981;&#24490;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20855;&#26377;70&#20159;&#21442;&#25968;&#30340;Meerkat-7B&#21307;&#23398;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#21830;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21307;&#23398;&#20219;&#21153;&#19978;&#38544;&#31169;&#21644;&#25512;&#29702;&#33021;&#21147;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#21462;&#24471;&#20102;&#20248;&#20110;&#20808;&#21069;7B&#27169;&#22411;&#30340;&#26174;&#33879;&#25104;&#26524;&#12290;</title><link>https://arxiv.org/abs/2404.00376</link><description>&lt;p&gt;
&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#21307;&#23398;&#25945;&#26448;&#20013;&#23398;&#20064;&#22686;&#24378;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00376
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20174;&#21307;&#23398;&#25945;&#26448;&#25552;&#21462;&#30340;&#25512;&#29702;&#36335;&#24452;&#21644;&#22810;&#26679;&#21270;&#30340;&#36981;&#24490;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20855;&#26377;70&#20159;&#21442;&#25968;&#30340;Meerkat-7B&#21307;&#23398;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#21830;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21307;&#23398;&#20219;&#21153;&#19978;&#38544;&#31169;&#21644;&#25512;&#29702;&#33021;&#21147;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#21462;&#24471;&#20102;&#20248;&#20110;&#20808;&#21069;7B&#27169;&#22411;&#30340;&#26174;&#33879;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#21830;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#22312;&#21307;&#23398;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#25104;&#26524;&#65292;&#20294;&#20854;&#38381;&#28304;&#24615;&#36136;&#24341;&#21457;&#20102;&#37325;&#35201;&#30340;&#38544;&#31169;&#21644;&#23433;&#20840;&#38382;&#39064;&#65292;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#21307;&#23398;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#38024;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Meerkat-7B&#65292;&#19968;&#20010;&#21253;&#21547;70&#20159;&#21442;&#25968;&#30340;&#26032;&#22411;&#21307;&#23398;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#12290;Meerkat-7B&#20351;&#29992;&#25105;&#20204;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20174;18&#26412;&#21307;&#23398;&#25945;&#26448;&#20013;&#33719;&#21462;&#30340;&#39640;&#36136;&#37327;&#24605;&#32500;&#38142;&#25512;&#29702;&#36335;&#24452;&#65292;&#20197;&#21450;&#22810;&#26679;&#30340;&#36981;&#24490;&#25351;&#20196;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;&#19971;&#20010;&#21307;&#23398;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#65292;&#36229;&#36807;&#20102;GPT-3.5 13.1%&#65292;&#21516;&#26102;&#20063;&#20248;&#20110;&#20197;&#24448;&#26368;&#22909;&#30340;7B&#27169;&#22411;MediTron-7B&#21644;BioMistral-7B&#20998;&#21035;&#36798;&#21040;&#20102;13.4%&#21644;9.8%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00376v1 Announce Type: new  Abstract: While recent advancements in commercial large language models (LM) have shown promising results in medical tasks, their closed-source nature poses significant privacy and security concerns, hindering their widespread use in the medical field. Despite efforts to create open-source models, their limited parameters often result in insufficient multi-step reasoning capabilities required for solving complex medical problems. To address this, we introduce Meerkat-7B, a novel medical AI system with 7 billion parameters. Meerkat-7B was trained using our new synthetic dataset consisting of high-quality chain-of-thought reasoning paths sourced from 18 medical textbooks, along with diverse instruction-following datasets. Our system achieved remarkable accuracy across seven medical benchmarks, surpassing GPT-3.5 by 13.1%, as well as outperforming the previous best 7B models such as MediTron-7B and BioMistral-7B by 13.4% and 9.8%, respectively. Notab
&lt;/p&gt;</description></item><item><title>AttentionStore&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#36890;&#36807;&#23454;&#29616;KV&#32531;&#23384;&#30340;&#22797;&#29992;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#20013;&#26174;&#33879;&#38477;&#20302;&#20102;&#22810;&#36718;&#23545;&#35805;&#20013;&#30340;&#37325;&#22797;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2403.19708</link><description>&lt;p&gt;
AttentionStore: &#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#20013;&#23454;&#29616;&#22810;&#36718;&#23545;&#35805;&#20013;&#30340;&#27880;&#24847;&#21147;&#25104;&#26412;&#25928;&#30410;&#22797;&#29992;
&lt;/p&gt;
&lt;p&gt;
AttentionStore: Cost-effective Attention Reuse across Multi-turn Conversations in Large Language Model Serving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19708
&lt;/p&gt;
&lt;p&gt;
AttentionStore&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#36890;&#36807;&#23454;&#29616;KV&#32531;&#23384;&#30340;&#22797;&#29992;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#20013;&#26174;&#33879;&#38477;&#20302;&#20102;&#22810;&#36718;&#23545;&#35805;&#20013;&#30340;&#37325;&#22797;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#36718;&#23545;&#35805;&#19982;&#20154;&#31867;&#36827;&#34892;&#20132;&#20114;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#22522;&#26412;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38656;&#35201;&#37325;&#22797;&#35745;&#31639;&#21382;&#21490;&#35760;&#21495;&#30340;&#38190;&#20540;&#65288;KV&#65289;&#32531;&#23384;&#65292;&#23548;&#33268;&#29616;&#26377;&#29992;&#20110;&#25191;&#34892;&#22810;&#36718;&#23545;&#35805;&#30340;LLM&#26381;&#21153;&#24341;&#25806;&#25928;&#29575;&#20302;&#19979;&#65292;&#20135;&#29983;&#39640;&#26114;&#30340;&#26381;&#21153;&#25104;&#26412;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;AttentionStore&#65292;&#19968;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#36328;&#22810;&#36718;&#23545;&#35805;&#30340;KV&#32531;&#23384;&#22797;&#29992;&#65288;&#21363; &#27880;&#24847;&#21147;&#22797;&#29992;&#65289;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#37325;&#22797;&#35745;&#31639;&#24320;&#38144;&#12290;AttentionStore&#32500;&#25252;&#20102;&#19968;&#20010;&#23618;&#27425;&#32467;&#26500;&#30340;KV&#32531;&#23384;&#31995;&#32479;&#65292;&#21033;&#29992;&#25104;&#26412;&#25928;&#30410;&#30340;&#20869;&#23384;/&#23384;&#20648;&#20171;&#36136;&#20026;&#25152;&#26377;&#35831;&#27714;&#20445;&#23384;KV&#32531;&#23384;&#12290;&#20026;&#20102;&#20943;&#23569;&#24930;&#36895;&#20171;&#36136;&#30340;KV&#32531;&#23384;&#35775;&#38382;&#24320;&#38144;&#65292;AttentionStore&#37319;&#29992;&#36880;&#23618;&#39044;&#21152;&#36733;&#21644;&#24322;&#27493;&#20445;&#23384;&#26041;&#26696;&#65292;&#23558;KV&#32531;&#23384;&#35775;&#38382;&#19982;GPU&#35745;&#31639;&#37325;&#21472;&#12290;&#20026;&#30830;&#20445;&#35201;&#35775;&#38382;&#30340;KV&#32531;&#23384;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19708v1 Announce Type: new  Abstract: Interacting with humans through multi-turn conversations is a fundamental feature of large language models (LLMs). However, existing LLM serving engines for executing multi-turn conversations are inefficient due to the need to repeatedly compute the key-value (KV) caches of historical tokens, incurring high serving costs. To address the problem, this paper proposes AttentionStore, a new attention mechanism that enables the reuse of KV caches (i.e., attention reuse) across multi-turn conversations, significantly reducing the repetitive computation overheads. AttentionStore maintains a hierarchical KV caching system that leverages cost-effective memory/storage mediums to save KV caches for all requests. To reduce KV cache access overheads from slow mediums, AttentionStore employs layer-wise pre-loading and asynchronous saving schemes to overlap the KV cache access with the GPU computation. To ensure that the KV caches to be accessed are pl
&lt;/p&gt;</description></item><item><title>CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.13583</link><description>&lt;p&gt;
CONLINE: &#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#19982;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#30340;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13583
&lt;/p&gt;
&lt;p&gt;
CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#25442;&#20026;&#21487;&#25191;&#34892;&#20195;&#30721;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#22330;&#26223;&#19979;&#29983;&#25104;&#22797;&#26434;&#20195;&#30721;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21407;&#22240;&#22312;&#20110;&#22797;&#26434;&#30340;&#32467;&#26500;&#12289;&#24494;&#22937;&#30340;&#38169;&#35823;&#12289;&#23545;&#39640;&#32423;&#25968;&#25454;&#31867;&#22411;&#30340;&#29702;&#35299;&#20197;&#21450;&#32570;&#23569;&#36741;&#21161;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CONLINE&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#21010;&#30340;&#22312;&#32447;&#25628;&#32034;&#20449;&#24687;&#26816;&#32034;&#21644;&#33258;&#21160;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#20195;&#30721;&#29983;&#25104;&#65292;&#36827;&#34892;&#36845;&#20195;&#31934;&#28860;&#12290;CONLINE&#36824;&#20018;&#34892;&#21270;&#20102;&#22797;&#26434;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#65292;&#20197;&#25913;&#21892;&#29702;&#35299;&#65292;&#24182;&#29983;&#25104;&#27979;&#35797;&#29992;&#20363;&#65292;&#30830;&#20445;&#26694;&#26550;&#36866;&#29992;&#20110;&#29616;&#23454;&#24212;&#29992;&#12290;CONLINE&#36890;&#36807;&#23545;DS-1000&#21644;ClassEval&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#23454;&#39564;&#39564;&#35777;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;CONLINE&#26174;&#33879;&#25552;&#39640;&#20102;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#36136;&#37327;&#65292;&#31361;&#26174;&#20102;&#20854;&#25552;&#21319;&#23454;&#36341;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13583v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement. CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications. CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets. It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the pra
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#21010;-&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#34920;&#26684;&#19978;&#30340;&#21477;&#23376;&#32972;&#26223;&#20013;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#65292;&#36890;&#36807;&#23545;Llama-2-7B&#36827;&#34892;&#24494;&#35843;&#65292;&#26500;&#24314;&#20102;ProTrix&#27169;&#22411;&#65292;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#34920;&#26684;&#20219;&#21153;&#65292;&#24182;&#34920;&#29616;&#20986;&#19982;GPT-3.5-turbo&#30456;&#24403;&#30340;&#24615;&#33021;&#27700;&#24179;&#65292;&#21487;&#29983;&#25104;&#20934;&#30830;&#19988;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2403.02177</link><description>&lt;p&gt;
ProTrix: &#20351;&#29992;&#21477;&#23376;&#32972;&#26223;&#26500;&#24314;&#29992;&#20110;&#35268;&#21010;&#21644;&#25512;&#29702;&#34920;&#26684;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02177
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#21010;-&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#34920;&#26684;&#19978;&#30340;&#21477;&#23376;&#32972;&#26223;&#20013;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#65292;&#36890;&#36807;&#23545;Llama-2-7B&#36827;&#34892;&#24494;&#35843;&#65292;&#26500;&#24314;&#20102;ProTrix&#27169;&#22411;&#65292;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#34920;&#26684;&#20219;&#21153;&#65292;&#24182;&#34920;&#29616;&#20986;&#19982;GPT-3.5-turbo&#30456;&#24403;&#30340;&#24615;&#33021;&#27700;&#24179;&#65292;&#21487;&#29983;&#25104;&#20934;&#30830;&#19988;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#65292;&#34920;&#26684;&#22312;&#20256;&#36798;&#20449;&#24687;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#26159;&#32452;&#32455;&#21644;&#21576;&#29616;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#19981;&#21487;&#25110;&#32570;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#21010;-&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#22238;&#31572;&#24102;&#26377;&#21477;&#23376;&#32972;&#26223;&#30340;&#34920;&#26684;&#19978;&#30340;&#19981;&#21516;&#31867;&#22411;&#30340;&#29992;&#25143;&#26597;&#35810;&#12290;&#35813;&#26694;&#26550;&#39318;&#20808;&#35268;&#21010;&#19978;&#19979;&#25991;&#20013;&#30340;&#25512;&#29702;&#36335;&#24452;&#65292;&#28982;&#21518;&#23558;&#27599;&#20010;&#27493;&#39588;&#20998;&#37197;&#32473;&#22522;&#20110;&#31243;&#24207;&#25110;&#25991;&#26412;&#30340;&#25512;&#29702;&#65292;&#20197;&#36798;&#21040;&#26368;&#32456;&#31572;&#26696;&#12290;&#25105;&#20204;&#26681;&#25454;&#35813;&#26694;&#26550;&#26500;&#24314;&#20102;&#19968;&#20010;&#25351;&#20196;&#35843;&#25972;&#38598;TrixtInstruct&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#28085;&#30422;&#20102;&#37027;&#20123;&#38656;&#35201;&#32467;&#21512;&#34920;&#26684;&#21644;&#21477;&#23376;&#20449;&#24687;&#26469;&#33719;&#24471;&#35268;&#21010;&#21644;&#25512;&#29702;&#33021;&#21147;&#30340;&#31243;&#24207;&#26080;&#27861;&#35299;&#20915;&#30340;&#26597;&#35810;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;TrixInstruct&#19978;&#30340;Llama-2-7B&#36827;&#34892;&#24494;&#35843;&#65292;&#25552;&#20986;&#20102;ProTrix&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;ProTrix&#23545;&#21508;&#31181;&#34920;&#26684;&#20219;&#21153;&#20855;&#26377;&#26222;&#36941;&#24615;&#65292;&#24182;&#19988;&#36798;&#21040;&#20102;&#19982;GPT-3.5-turbo&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;ProTrix&#21487;&#20197;&#29983;&#25104;&#20934;&#30830;&#21644;&#24544;&#23454;&#30340;&#35299;&#37322;&#26469;&#22238;&#31572;&#22797;&#26434;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02177v1 Announce Type: new  Abstract: Tables play a crucial role in conveying information in various domains, serving as indispensable tools for organizing and presenting data in a structured manner. We propose a Plan-then-Reason framework to answer different types of user queries over tables with sentence context. The framework first plans the reasoning paths over the context, then assigns each step to program-based or textual reasoning to reach the final answer. We construct an instruction tuning set TrixInstruct following the framework. Our dataset cover queries that are program-unsolvable or need combining information from tables and sentences to obtain planning and reasoning abilities. We present ProTrix by finetuning Llama-2-7B on TrixInstruct. Our experiments show that ProTrix generalizes to diverse tabular tasks and achieves comparable performance to GPT-3.5-turbo. We further demonstrate that ProTrix can generate accurate and faithful explanations to answer complex f
&lt;/p&gt;</description></item><item><title>LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.16929</link><description>&lt;p&gt;
LangGPT&#65306;&#37325;&#26032;&#24605;&#32771;&#38754;&#21521;LLMs&#30340;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#20174;&#32534;&#31243;&#35821;&#35328;&#20986;&#21457;
&lt;/p&gt;
&lt;p&gt;
LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16929
&lt;/p&gt;
&lt;p&gt;
LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#24050;&#32463;&#23637;&#31034;&#20986;&#22312;&#19981;&#21516;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#26377;&#25928;&#25351;&#23548;LLMs&#21046;&#23450;&#39640;&#36136;&#37327;&#30340;&#25552;&#31034;&#23545;&#20110;&#38750;AI&#19987;&#23478;&#26469;&#35828;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#25552;&#31034;&#24037;&#31243;&#30740;&#31350;&#24314;&#35758;&#20102;&#19968;&#20123;&#30053;&#26174;&#38646;&#30862;&#30340;&#20248;&#21270;&#21407;&#21017;&#21644;&#35774;&#35745;&#65292;&#20197;&#21450;&#20973;&#32463;&#39564;&#20381;&#36182;&#30340;&#25552;&#31034;&#20248;&#21270;&#22120;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#21162;&#21147;&#32570;&#20047;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#35774;&#35745;&#27169;&#26495;&#65292;&#23548;&#33268;&#23398;&#20064;&#25104;&#26412;&#39640;&#65292;&#37325;&#22797;&#20351;&#29992;&#24615;&#20302;&#12290;&#21463;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LangGPT&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#12290;LangGPT&#20855;&#26377;&#26131;&#20110;&#23398;&#20064;&#30340;&#35268;&#33539;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#25193;&#23637;&#32467;&#26500;&#20197;&#36827;&#34892;&#36801;&#31227;&#21644;&#37325;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#22522;&#20934;&#30456;&#27604;&#65292;LangGPT&#26174;&#33879;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;LangGPT&#24050;&#34987;&#35777;&#26126;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16929v1 Announce Type: cross  Abstract: LLMs have demonstrated commendable performance across diverse domains. Nevertheless, formulating high-quality prompts to effectively instruct LLMs poses a challenge for non-AI experts. Existing research in prompt engineering suggests somewhat fragmented optimization principles and designs empirically dependent prompt optimizers. Unfortunately, these endeavors lack a structured design template, incurring high learning costs and resulting in low reusability. Inspired by structured reusable programming languages, we propose LangGPT, a dual-layer prompt design framework as the programming language for LLMs. LangGPT has an easy-to-learn normative structure and provides an extended structure for migration and reuse. Experiments illustrate that LangGPT significantly enhances the capacity of LLMs to produce responses of superior quality compared to baselines. Moreover, LangGPT has proven effective in guiding LLMs to generate high-quality promp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102; GPT-4 &#21644; MTurk &#31649;&#36947;&#30340;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#23613;&#31649; MTurk &#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;&#20294; GPT-4 &#30340;&#20934;&#30830;&#29575;&#26356;&#39640;&#65292;&#24182;&#19988;&#32467;&#21512; GPT-4 &#21644;&#20247;&#21253;&#26631;&#31614;&#20351;&#29992;&#32858;&#21512;&#31639;&#27861;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.16795</link><description>&lt;p&gt;
&#22914;&#26524;&#22312;&#19968;&#20010;&#20247;&#21253;&#25968;&#25454;&#26631;&#27880;&#31649;&#36947;&#20013;&#65292;GPT-4
&lt;/p&gt;
&lt;p&gt;
If in a Crowdsourced Data Annotation Pipeline, a GPT-4
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16795
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102; GPT-4 &#21644; MTurk &#31649;&#36947;&#30340;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#23613;&#31649; MTurk &#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;&#20294; GPT-4 &#30340;&#20934;&#30830;&#29575;&#26356;&#39640;&#65292;&#24182;&#19988;&#32467;&#21512; GPT-4 &#21644;&#20247;&#21253;&#26631;&#31614;&#20351;&#29992;&#32858;&#21512;&#31639;&#27861;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;GPT-4&#22312;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#22312;&#32447;&#20247;&#21253;&#24037;&#20316;&#32773;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#20122;&#39532;&#36874;&#26426;&#26800;&#22303;&#32819;&#20854;&#65288;MTurk&#65289;&#30340;&#24037;&#20316;&#32773;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#22240;&#20559;&#31163;&#26631;&#20934;&#20247;&#21253;&#23454;&#36341;&#24182;&#24378;&#35843;&#20010;&#21035;&#24037;&#20316;&#32773;&#30340;&#34920;&#29616;&#32780;&#21463;&#21040;&#25209;&#35780;&#65292;&#32780;&#19981;&#26159;&#25972;&#20010;&#25968;&#25454;&#26631;&#27880;&#36807;&#31243;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;GPT-4&#21644;&#19968;&#20010;&#36947;&#24503;&#19988;&#25191;&#34892;&#33391;&#22909;&#30340;MTurk&#31649;&#36947;&#65292;&#20351;&#29992;415&#21517;&#24037;&#20316;&#32773;&#26631;&#27880;&#20102;&#26469;&#33258;200&#31687;&#23398;&#26415;&#25991;&#31456;&#30340;3,177&#20010;&#21477;&#27573;&#65292;&#20351;&#29992;&#20102;CODA-19&#26041;&#26696;&#12290;&#20004;&#20010;&#24037;&#20316;&#32773;&#30028;&#38754;&#20135;&#29983;&#20102;127,080&#20010;&#26631;&#31614;&#65292;&#28982;&#21518;&#36890;&#36807;&#20843;&#31181;&#26631;&#31614;&#32858;&#21512;&#31639;&#27861;&#25512;&#26029;&#20986;&#26368;&#32456;&#30340;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;&#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;MTurk&#31649;&#36947;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#20026;81.5%&#65292;&#32780;GPT-4&#36798;&#21040;&#20102;83.6%&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#24403;&#23558;GPT-4&#30340;&#26631;&#31614;&#19982;&#36890;&#36807;&#20808;&#36827;&#24037;&#20316;&#32773;&#30028;&#38754;&#25910;&#38598;&#30340;&#20247;&#21253;&#26631;&#31614;&#32467;&#21512;&#36215;&#26469;&#36827;&#34892;&#32858;&#21512;&#26102;&#65292;8&#31181;&#31639;&#27861;&#20013;&#26377;2&#31181;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16795v1 Announce Type: cross  Abstract: Recent studies indicated GPT-4 outperforms online crowd workers in data labeling accuracy, notably workers from Amazon Mechanical Turk (MTurk). However, these studies were criticized for deviating from standard crowdsourcing practices and emphasizing individual workers' performances over the whole data-annotation process. This paper compared GPT-4 and an ethical and well-executed MTurk pipeline, with 415 workers labeling 3,177 sentence segments from 200 scholarly articles using the CODA-19 scheme. Two worker interfaces yielded 127,080 labels, which were then used to infer the final labels through eight label-aggregation algorithms. Our evaluation showed that despite best practices, MTurk pipeline's highest accuracy was 81.5%, whereas GPT-4 achieved 83.6%. Interestingly, when combining GPT-4's labels with crowd labels collected via an advanced worker interface for aggregation, 2 out of the 8 algorithms achieved an even higher accuracy (
&lt;/p&gt;</description></item><item><title>GraphWiz&#26159;&#19968;&#20010;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;&#21644;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#26694;&#26550;&#65292;&#33021;&#22815;&#39640;&#25928;&#35299;&#20915;&#21508;&#31181;&#22270;&#38382;&#39064;&#31867;&#22411;&#65292;&#24179;&#22343;&#20934;&#30830;&#29575;&#36798;&#21040;65%&#65292;&#36229;&#36807;&#20102;GPT-4&#30340;43.8%&#12290;</title><link>https://arxiv.org/abs/2402.16029</link><description>&lt;p&gt;
GraphWiz&#65306;&#29992;&#20110;&#22270;&#38382;&#39064;&#30340;&#25351;&#20196;&#36319;&#38543;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
GraphWiz: An Instruction-Following Language Model for Graph Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16029
&lt;/p&gt;
&lt;p&gt;
GraphWiz&#26159;&#19968;&#20010;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;&#21644;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#26694;&#26550;&#65292;&#33021;&#22815;&#39640;&#25928;&#35299;&#20915;&#21508;&#31181;&#22270;&#38382;&#39064;&#31867;&#22411;&#65292;&#24179;&#22343;&#20934;&#30830;&#29575;&#36798;&#21040;65%&#65292;&#36229;&#36807;&#20102;GPT-4&#30340;43.8%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22810;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#22312;&#29702;&#35299;&#21644;&#35299;&#20915;&#22797;&#26434;&#22270;&#38382;&#39064;&#26041;&#38754;&#30340;&#33021;&#21147;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;GraphInstruct&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#32780;&#20840;&#38754;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#22788;&#29702;&#21508;&#31181;&#22270;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#21033;&#29992;&#26126;&#30830;&#30340;&#25512;&#29702;&#36335;&#24452;&#12290;&#21033;&#29992;GraphInstruct&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;GraphWiz&#65292;&#36825;&#26159;&#19968;&#20010;&#33021;&#22815;&#35299;&#20915;&#21508;&#31181;&#22270;&#38382;&#39064;&#31867;&#22411;&#24182;&#29983;&#25104;&#28165;&#26224;&#25512;&#29702;&#36807;&#31243;&#30340;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#12290;&#20026;&#22686;&#24378;&#27169;&#22411;&#30340;&#33021;&#21147;&#21644;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#23558;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#26694;&#26550;&#32435;&#20837;&#22270;&#38382;&#39064;&#27714;&#35299;&#29615;&#22659;&#20013;&#12290;&#22686;&#24378;&#27169;&#22411;GraphWiz-DPO&#22312;&#20061;&#20010;&#20855;&#26377;&#19981;&#21516;&#22797;&#26434;&#24615;&#27700;&#24179;&#30340;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;65%&#30340;&#24179;&#22343;&#20934;&#30830;&#29575;&#65292;&#36229;&#36807;&#20102;&#24179;&#22343;&#20934;&#30830;&#29575;&#20026;43.8%&#30340;GPT-4&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16029v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved impressive success across several fields, but their proficiency in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel and comprehensive instruction-tuning dataset designed to equip language models with the ability to tackle a broad spectrum of graph problems using explicit reasoning paths. Utilizing GraphInstruct, we build GraphWiz, an open-source language model capable of resolving various graph problem types while generating clear reasoning processes. To enhance the model's capability and reliability, we incorporate the Direct Preference Optimization (DPO) framework into the graph problem-solving context. The enhanced model, GraphWiz-DPO, achieves an average accuracy of 65% across nine tasks with different complexity levels, surpassing GPT-4 which has an average accuracy of 43.8%. Moreover, our research delves into the d
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#37329;&#34701;&#20559;&#35265;&#25351;&#26631;&#65288;FBI&#65289;&#26694;&#26550;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#37329;&#34701;&#21512;&#29702;&#24615;&#65292;&#30528;&#37325;&#26816;&#39564;&#23427;&#20204;&#23545;&#37329;&#34701;&#20449;&#24687;&#30340;&#36776;&#21035;&#21644;&#24066;&#22330;&#20998;&#26512;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#38750;&#29702;&#24615;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2402.12713</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#29702;&#24615;&#25237;&#36164;&#32773;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are Large Language Models Rational Investors?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#37329;&#34701;&#20559;&#35265;&#25351;&#26631;&#65288;FBI&#65289;&#26694;&#26550;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#37329;&#34701;&#21512;&#29702;&#24615;&#65292;&#30528;&#37325;&#26816;&#39564;&#23427;&#20204;&#23545;&#37329;&#34701;&#20449;&#24687;&#30340;&#36776;&#21035;&#21644;&#24066;&#22330;&#20998;&#26512;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#38750;&#29702;&#24615;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#27491;&#36880;&#28176;&#34987;&#24341;&#20837;&#37329;&#34701;&#20998;&#26512;&#39046;&#22495;&#65292;&#21033;&#29992;&#20854;&#20016;&#23500;&#30340;&#30693;&#35782;&#24211;&#26469;&#35299;&#37322;&#22797;&#26434;&#30340;&#24066;&#22330;&#25968;&#25454;&#21644;&#36235;&#21183;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#37329;&#34701;&#39046;&#22495;&#30340;&#24212;&#29992;&#21463;&#21040;&#22266;&#26377;&#20559;&#35265;&#65288;&#21363;&#39118;&#38505;&#20559;&#22909;&#20559;&#35265;&#65289;&#21644;&#23545;&#24066;&#22330;&#22797;&#26434;&#24615;&#30340;&#32932;&#27973;&#29702;&#35299;&#30340;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#23545;&#23427;&#20204;&#30340;&#37329;&#34701;&#27934;&#23519;&#21147;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#30340;&#24517;&#35201;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#37329;&#34701;&#20559;&#35265;&#25351;&#26631;&#65288;FBI&#65289;&#65292;&#20197;&#23545;LLMs&#30340;&#37329;&#34701;&#21512;&#29702;&#24615;&#36827;&#34892;&#25209;&#21028;&#24615;&#35780;&#20272;&#65292;&#37325;&#28857;&#20851;&#27880;&#23427;&#20204;&#36776;&#21035;&#21644;&#23548;&#33322;&#37329;&#34701;&#20449;&#24687;&#30340;&#24494;&#22937;&#20043;&#22788;&#30340;&#33021;&#21147;&#65292;&#24182;&#35782;&#21035;&#21487;&#33021;&#25197;&#26354;&#24066;&#22330;&#20998;&#26512;&#30340;&#20219;&#20309;&#38750;&#29702;&#24615;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12713v1 Announce Type: new  Abstract: Large Language Models (LLMs) are progressively being adopted in financial analysis to harness their extensive knowledge base for interpreting complex market data and trends. However, their application in the financial domain is challenged by intrinsic biases (i.e., risk-preference bias) and a superficial grasp of market intricacies, underscoring the need for a thorough assessment of their financial insight. This study introduces a novel framework, Financial Bias Indicators (FBI), to critically evaluate the financial rationality of LLMs, focusing on their ability to discern and navigate the subtleties of financial information and to identify any irrational biases that might skew market analysis.   Our research adopts an innovative methodology to measure financial rationality, integrating principles of behavioral finance to scrutinize the biases and decision-making patterns of LLMs. We conduct a comprehensive evaluation of 19 leading LLMs,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;COmpressive Memory-Enhanced Dialogue sYstems&#65288;COMEDY&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#8220;&#19968;&#23545;&#22810;&#8221;&#26041;&#27861;&#21033;&#29992;&#21333;&#19968;&#35821;&#35328;&#27169;&#22411;&#31649;&#29702;&#35760;&#24518;&#29983;&#25104;&#12289;&#21387;&#32553;&#21644;&#21709;&#24212;&#29983;&#25104;&#65292;&#26680;&#24515;&#27010;&#24565;&#26159;&#21387;&#32553;&#35760;&#24518;&#65292;&#25903;&#25345;&#22823;&#35268;&#27169;&#20013;&#25991;&#25351;&#23548;&#35843;&#20248;&#25968;&#25454;&#38598;Dolphin&#65292;&#27604;&#36739;&#35780;&#20272;&#35777;&#26126;&#20102;COMEDY&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11975</link><description>&lt;p&gt;
&#21387;&#32553;&#20197;&#24341;&#20154;&#27880;&#30446;&#65306;&#37322;&#25918;&#21387;&#32553;&#35760;&#24518;&#22312;&#29616;&#23454;&#19990;&#30028;&#38271;&#26399;&#23545;&#35805;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Compress to Impress: Unleashing the Potential of Compressive Memory in Real-World Long-Term Conversations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11975
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;COmpressive Memory-Enhanced Dialogue sYstems&#65288;COMEDY&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#8220;&#19968;&#23545;&#22810;&#8221;&#26041;&#27861;&#21033;&#29992;&#21333;&#19968;&#35821;&#35328;&#27169;&#22411;&#31649;&#29702;&#35760;&#24518;&#29983;&#25104;&#12289;&#21387;&#32553;&#21644;&#21709;&#24212;&#29983;&#25104;&#65292;&#26680;&#24515;&#27010;&#24565;&#26159;&#21387;&#32553;&#35760;&#24518;&#65292;&#25903;&#25345;&#22823;&#35268;&#27169;&#20013;&#25991;&#25351;&#23548;&#35843;&#20248;&#25968;&#25454;&#38598;Dolphin&#65292;&#27604;&#36739;&#35780;&#20272;&#35777;&#26126;&#20102;COMEDY&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#22522;&#20110;&#26816;&#32034;&#30340;&#26041;&#27861;&#22312;&#32500;&#25252;&#38271;&#26399;&#23545;&#35805;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#35760;&#24518;&#25968;&#25454;&#24211;&#31649;&#29702;&#21644;&#20934;&#30830;&#30340;&#35760;&#24518;&#26816;&#32034;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#21160;&#24577;&#12289;&#30495;&#23454;&#19990;&#30028;&#20114;&#21160;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;COmpressive Memory-Enhanced Dialogue sYstems&#65288;COMEDY&#65289;&#65292;&#23427;&#25682;&#24323;&#20102;&#20256;&#32479;&#30340;&#26816;&#32034;&#27169;&#22359;&#21644;&#35760;&#24518;&#25968;&#25454;&#24211;&#12290;&#30456;&#21453;&#65292;COMEDY&#37319;&#29992;&#20102;&#8220;&#19968;&#23545;&#22810;&#8221;&#26041;&#27861;&#65292;&#21033;&#29992;&#21333;&#19968;&#35821;&#35328;&#27169;&#22411;&#26469;&#31649;&#29702;&#35760;&#24518;&#29983;&#25104;&#12289;&#21387;&#32553;&#21644;&#21709;&#24212;&#29983;&#25104;&#12290;&#36825;&#19968;&#26694;&#26550;&#30340;&#26680;&#24515;&#27010;&#24565;&#26159;&#21387;&#32553;&#35760;&#24518;&#65292;&#23427;&#23558;&#20250;&#35805;&#29305;&#23450;&#25688;&#35201;&#12289;&#29992;&#25143;-&#26426;&#22120;&#20154;&#21160;&#24577;&#21644;&#36807;&#21435;&#20107;&#20214;&#25972;&#21512;&#21040;&#31616;&#27905;&#30340;&#35760;&#24518;&#26684;&#24335;&#20013;&#12290;&#20026;&#20102;&#25903;&#25345;COMEDY&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20013;&#25991;&#25351;&#23548;&#35843;&#20248;&#25968;&#25454;&#38598;Dolphin&#65292;&#20174;&#30495;&#23454;&#29992;&#25143;-&#32842;&#22825;&#26426;&#22120;&#20154;&#20114;&#21160;&#20013;&#24471;&#20986;&#12290;&#27604;&#36739;&#35780;&#20272;&#34920;&#26126;COMEDY&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11975v1 Announce Type: new  Abstract: Existing retrieval-based methods have made significant strides in maintaining long-term conversations. However, these approaches face challenges in memory database management and accurate memory retrieval, hindering their efficacy in dynamic, real-world interactions. This study introduces a novel framework, COmpressive Memory-Enhanced Dialogue sYstems (COMEDY), which eschews traditional retrieval modules and memory databases. Instead, COMEDY adopts a ''One-for-All'' approach, utilizing a single language model to manage memory generation, compression, and response generation. Central to this framework is the concept of compressive memory, which intergrates session-specific summaries, user-bot dynamics, and past events into a concise memory format. To support COMEDY, we curated a large-scale Chinese instruction-tuning dataset, Dolphin, derived from real user-chatbot interactions. Comparative evaluations demonstrate COMEDY's superiority ove
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#38598;&#25104;&#20102;&#29289;&#29702;&#23618;&#36890;&#20449;&#21151;&#33021;&#30340;&#23454;&#29992;&#35774;&#22791;&#38388;&#20154;&#24037;&#26234;&#33021;&#36890;&#20449;&#26694;&#26550;&#65292;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#32467;&#21512;&#20449;&#36947;&#22122;&#22768;&#20197;&#22686;&#24378;&#38887;&#24615;&#65292;&#37319;&#29992;VQ-VAE&#23454;&#29616;&#39640;&#25928;&#31283;&#20581;&#30340;&#36890;&#20449;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;Transformer&#25552;&#21319;&#36890;&#29992;&#24615;&#33021;</title><link>https://arxiv.org/abs/2402.11656</link><description>&lt;p&gt;
&#23558;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#19982;&#29289;&#29702;&#23618;&#36890;&#20449;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Integrating Pre-Trained Language Model with Physical Layer Communications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11656
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#38598;&#25104;&#20102;&#29289;&#29702;&#23618;&#36890;&#20449;&#21151;&#33021;&#30340;&#23454;&#29992;&#35774;&#22791;&#38388;&#20154;&#24037;&#26234;&#33021;&#36890;&#20449;&#26694;&#26550;&#65292;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#32467;&#21512;&#20449;&#36947;&#22122;&#22768;&#20197;&#22686;&#24378;&#38887;&#24615;&#65292;&#37319;&#29992;VQ-VAE&#23454;&#29616;&#39640;&#25928;&#31283;&#20581;&#30340;&#36890;&#20449;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;Transformer&#25552;&#21319;&#36890;&#29992;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35774;&#22791;&#38388;&#20154;&#24037;&#26234;&#33021;&#36890;&#20449;&#30340;&#26032;&#20852;&#39046;&#22495;&#20013;&#65292;&#35774;&#22791;&#30452;&#25509;&#36890;&#36807;&#23884;&#20837;&#24335;&#22522;&#30784;&#27169;&#22411;&#65288;&#22914;&#35821;&#35328;&#27169;&#22411;&#65289;&#20132;&#25442;&#20449;&#24687;&#65292;&#38656;&#35201;&#24378;&#22823;&#12289;&#39640;&#25928;&#19988;&#36890;&#29992;&#30340;&#36890;&#20449;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#23558;&#36825;&#20123;&#26694;&#26550;&#19982;&#29616;&#26377;&#26080;&#32447;&#31995;&#32479;&#38598;&#25104;&#24182;&#26377;&#25928;&#31649;&#29702;&#22122;&#22768;&#21644;&#27604;&#29305;&#35823;&#24046;&#37117;&#38754;&#20020;&#30528;&#37325;&#22823;&#25361;&#25112;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#35774;&#22791;&#38388;&#20154;&#24037;&#26234;&#33021;&#36890;&#20449;&#26694;&#26550;&#65292;&#38598;&#25104;&#20102;&#29289;&#29702;&#23618;&#36890;&#20449;&#21151;&#33021;&#65292;&#24182;&#36890;&#36807;&#38142;&#36335;&#32423;&#27169;&#25311;&#22120;&#23637;&#31034;&#20102;&#20854;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#32467;&#21512;&#20449;&#36947;&#22122;&#22768;&#20197;&#22686;&#24378;&#38887;&#24615;&#65292;&#37319;&#29992;&#21521;&#37327;&#37327;&#21270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VQ-VAE&#65289;&#23454;&#29616;&#39640;&#25928;&#31283;&#20581;&#30340;&#36890;&#20449;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#32534;&#30721;-&#35299;&#30721;Transformer&#25552;&#21319;&#36890;&#29992;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#36890;&#20449;&#22330;&#26223;&#30340;&#27169;&#25311;&#20013;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23637;&#29616;&#20986;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11656v1 Announce Type: cross  Abstract: The burgeoning field of on-device AI communication, where devices exchange information directly through embedded foundation models, such as language models (LMs), requires robust, efficient, and generalizable communication frameworks. However, integrating these frameworks with existing wireless systems and effectively managing noise and bit errors pose significant challenges. In this work, we introduce a practical on-device AI communication framework, integrated with physical layer (PHY) communication functions, demonstrated through its performance on a link-level simulator. Our framework incorporates end-to-end training with channel noise to enhance resilience, incorporates vector quantized variational autoencoders (VQ-VAE) for efficient and robust communication, and utilizes pre-trained encoder-decoder transformers for improved generalization capabilities. Simulations, across various communication scenarios, reveal that our framework
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38754;&#21521;&#25351;&#20196;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#65292;&#21457;&#29616;&#33258;&#21160;&#26041;&#27861;&#22312;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19979;&#19982;&#20154;&#24037;&#35780;&#20272;&#32773;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#23384;&#22312;&#24040;&#22823;&#21464;&#21270;&#65292;&#19988;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#21487;&#33021;&#19981;&#21487;&#38752;&#12290;</title><link>https://arxiv.org/abs/2402.10770</link><description>&lt;p&gt;
&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#22312;&#38754;&#21521;&#25351;&#20196;&#30340;LLM&#20013;&#26377;&#22810;&#21487;&#38752;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38754;&#21521;&#25351;&#20196;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#65292;&#21457;&#29616;&#33258;&#21160;&#26041;&#27861;&#22312;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19979;&#19982;&#20154;&#24037;&#35780;&#20272;&#32773;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#23384;&#22312;&#24040;&#22823;&#21464;&#21270;&#65292;&#19988;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#21487;&#33021;&#19981;&#21487;&#38752;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#21521;&#25351;&#20196;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#30740;&#31350;&#20351;&#29992;&#22522;&#20110;&#25991;&#26412;&#37325;&#21472;&#21644;LLM&#21028;&#26029;&#30340;&#33258;&#21160;&#26041;&#27861;&#20316;&#20026;&#20154;&#24037;&#35780;&#20272;&#30340;&#25104;&#26412;&#26377;&#25928;&#26367;&#20195;&#26041;&#26696;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#24191;&#27867;&#30340;&#20219;&#21153;&#33539;&#22260;&#21644;&#36328;&#35821;&#35328;&#29615;&#22659;&#20013;&#30340;&#21487;&#38752;&#24615;&#12290;&#19982;&#20808;&#21069;&#30340;&#30740;&#31350;&#32467;&#26524;&#30456;&#21453;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#20219;&#21153;&#31867;&#22411;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#21160;&#26041;&#27861;&#19982;&#20154;&#24037;&#35780;&#20272;&#32773;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#23384;&#22312;&#26174;&#33879;&#21464;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;ROUGE-L&#24230;&#37327;&#22312;&#30701;&#31572;&#26696;&#33521;&#35821;&#20219;&#21153;&#20013;&#19982;&#20154;&#31867;&#21028;&#26029;&#24378;&#30456;&#20851;&#65292;&#20294;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#19981;&#21487;&#38752;&#12290;&#20351;&#29992;GPT-4&#20316;&#20026;&#35780;&#20272;&#21592;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#22312;&#35201;&#27714;&#35780;&#20272;&#26102;&#21253;&#21547;&#21442;&#32771;&#31572;&#26696;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#20013;&#35780;&#20272;&#36807;&#20110;&#20005;&#26684;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#21487;&#20197;&#36817;&#20284;&#20154;&#31867;&#21028;&#26029;&#65292;&#20294;&#20854;&#20934;&#30830;&#24615;&#21487;&#33021;&#22240;&#20219;&#21153;&#31867;&#22411;&#21644;&#35780;&#20272;&#35774;&#32622;&#32780;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10770v1 Announce Type: cross  Abstract: Work on instruction-tuned Large Language Models (LLMs) has used automatic methods based on text overlap and LLM judgments as cost-effective alternatives to human evaluation. In this paper, we study the reliability of such methods across a broad range of tasks and in a cross-lingual setting. In contrast to previous findings, we observe considerable variability in correlations between automatic methods and human evaluators when scores are differentiated by task type. Specifically, the widely-used ROUGE-L metric strongly correlates with human judgments for short-answer English tasks but is unreliable in free-form generation tasks and cross-lingual transfer. The effectiveness of GPT-4 as an evaluator depends on including reference answers when prompting for assessments, which can lead to overly strict evaluations in free-form generation tasks. In summary, we find that, while automatic evaluation methods can approximate human judgements und
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24674;&#22797;&#29983;&#25104;&#27169;&#22411;&#39044;&#24494;&#35843;&#26435;&#37325;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23569;&#37327;&#20302;&#31209;&#24494;&#35843;&#27169;&#22411;&#21487;&#20197;&#24674;&#22797;&#20934;&#30830;&#30340;&#39044;&#24494;&#35843;&#26435;&#37325;&#65292;&#21033;&#29992;&#36825;&#20010;&#26032;&#28431;&#27934;&#25915;&#20987;&#22823;&#35268;&#27169;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.10208</link><description>&lt;p&gt;
&#24674;&#22797;&#29983;&#25104;&#27169;&#22411;&#30340;&#39044;&#24494;&#35843;&#26435;&#37325;
&lt;/p&gt;
&lt;p&gt;
Recovering the Pre-Fine-Tuning Weights of Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10208
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24674;&#22797;&#29983;&#25104;&#27169;&#22411;&#39044;&#24494;&#35843;&#26435;&#37325;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23569;&#37327;&#20302;&#31209;&#24494;&#35843;&#27169;&#22411;&#21487;&#20197;&#24674;&#22797;&#20934;&#30830;&#30340;&#39044;&#24494;&#35843;&#26435;&#37325;&#65292;&#21033;&#29992;&#36825;&#20010;&#26032;&#28431;&#27934;&#25915;&#20987;&#22823;&#35268;&#27169;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#65292;&#20027;&#27969;&#27169;&#24335;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;i) &#22312;&#22823;&#35268;&#27169;&#20294;&#19981;&#23433;&#20840;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;ii) &#36890;&#36807;&#24494;&#35843;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#23545;&#40784;&#12290;&#36825;&#31181;&#20570;&#27861;&#34987;&#35748;&#20026;&#26159;&#23433;&#20840;&#30340;&#65292;&#22240;&#20026;&#30446;&#21069;&#27809;&#26377;&#19968;&#31181;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#19981;&#23433;&#20840;&#30340;&#39044;&#24494;&#35843;&#27169;&#22411;&#26435;&#37325;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#36825;&#31181;&#20551;&#35774;&#36890;&#24120;&#26159;&#38169;&#35823;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#35889;&#21453;&#35843;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#23569;&#37327;&#20302;&#31209;&#65288;LoRA&#65289;&#24494;&#35843;&#27169;&#22411;&#24674;&#22797;&#39044;&#24494;&#35843;&#27169;&#22411;&#30340;&#26435;&#37325;&#12290;&#19982;&#20808;&#21069;&#35797;&#22270;&#24674;&#22797;&#39044;&#24494;&#35843;&#33021;&#21147;&#30340;&#25915;&#20987;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#24674;&#22797;&#31934;&#30830;&#30340;&#39044;&#24494;&#35843;&#26435;&#37325;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#36825;&#20010;&#26032;&#30340;&#23545;&#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#28431;&#27934;&#65292;&#20363;&#22914;&#20010;&#24615;&#21270;&#30340;&#31283;&#23450;&#25193;&#25955;&#21644;&#23545;&#40784;&#30340;Mistral&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10208v1 Announce Type: cross  Abstract: The dominant paradigm in generative modeling consists of two steps: i) pre-training on a large-scale but unsafe dataset, ii) aligning the pre-trained model with human values via fine-tuning. This practice is considered safe, as no current method can recover the unsafe, pre-fine-tuning model weights. In this paper, we demonstrate that this assumption is often false. Concretely, we present Spectral DeTuning, a method that can recover the weights of the pre-fine-tuning model using a few low-rank (LoRA) fine-tuned models. In contrast to previous attacks that attempt to recover pre-fine-tuning capabilities, our method aims to recover the exact pre-fine-tuning weights. Our approach exploits this new vulnerability against large-scale models such as a personalized Stable Diffusion and an aligned Mistral.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;LLMs&#21644;&#36923;&#36753;&#20013;&#38388;&#34920;&#31034;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;"&#25991;&#26412;&#21040;&#35745;&#21010;"&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;LLMs&#29992;&#20110;&#29983;&#25104;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#30340;PDDL&#34920;&#31034;&#20197;&#21450;&#32463;&#20856;&#35268;&#21010;&#22120;&#30340;&#20351;&#29992;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#21010;&#20219;&#21153;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.06608</link><description>&lt;p&gt;
TIC&#65306;&#21033;&#29992;LLMs&#21644;&#36923;&#36753;&#20013;&#38388;&#34920;&#31034;&#31934;&#30830;&#36827;&#34892;&#8220;&#25991;&#26412;&#21040;&#35745;&#21010;&#8221;&#30340;&#32763;&#35793;-&#25512;&#26029;-&#32534;&#35793;
&lt;/p&gt;
&lt;p&gt;
TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06608
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;LLMs&#21644;&#36923;&#36753;&#20013;&#38388;&#34920;&#31034;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;"&#25991;&#26412;&#21040;&#35745;&#21010;"&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;LLMs&#29992;&#20110;&#29983;&#25104;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#30340;PDDL&#34920;&#31034;&#20197;&#21450;&#32463;&#20856;&#35268;&#21010;&#22120;&#30340;&#20351;&#29992;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#21010;&#20219;&#21153;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20026;&#32473;&#23450;&#30340;&#33258;&#28982;&#35821;&#35328;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#29983;&#25104;&#35745;&#21010;&#30340;&#38382;&#39064;&#12290;&#19968;&#26041;&#38754;&#65292;LLMs&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#35745;&#21010;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#32463;&#20856;&#35745;&#21010;&#24037;&#20855;&#22312;&#35745;&#21010;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#38656;&#35201;&#20351;&#29992;&#32467;&#26500;&#21270;&#35821;&#35328;&#65288;&#22914;Planning Domain Definition Language&#65288;PDDL&#65289;&#65289;&#20316;&#20026;&#36755;&#20837;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20004;&#31181;&#25216;&#26415;&#30340;&#20248;&#28857;&#65292;&#36890;&#36807;&#20351;&#29992;LLMs&#29983;&#25104;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#30340;PDDL&#34920;&#31034;&#65288;&#20219;&#21153;PDDL&#65289;&#65292;&#28982;&#21518;&#20351;&#29992;&#32463;&#20856;&#35268;&#21010;&#22120;&#35745;&#31639;&#35745;&#21010;&#12290;&#19982;&#30452;&#25509;&#20351;&#29992;LLMs&#29983;&#25104;&#20219;&#21153;PDDL&#30340;&#20808;&#21069;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#65288;a&#65289;&#32763;&#35793;&#65306;&#20165;&#20351;&#29992;LLMs&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#30340;&#36923;&#36753;&#21487;&#35299;&#37322;&#30340;&#20013;&#38388;&#34920;&#31034;&#65292;&#65288;b&#65289;&#25512;&#26029;&#65306;&#20351;&#29992;&#36923;&#36753;&#25512;&#29702;&#22120;&#65288;&#30446;&#21069;&#26159;Answer Set Programming solver&#65289;&#20174;&#20013;&#38388;&#34920;&#31034;&#20013;&#25512;&#23548;&#20986;&#39069;&#22806;&#30340;&#36923;&#36753;&#30456;&#20851;&#20449;&#24687;&#65292;&#20197;&#21450;&#65288;c&#65289;&#32534;&#35793;&#65306;&#29983;&#25104;&#30446;&#26631;&#35745;&#21010;&#30340;PDDL&#25551;&#36848;&#30340;&#32534;&#35793;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of generating plans for given natural language planning task requests. On one hand, LLMs excel at natural language processing but do not perform well on planning. On the other hand, classical planning tools excel at planning tasks but require input in a structured language such as the Planning Domain Definition Language (PDDL). We leverage the strengths of both the techniques by using an LLM for generating the PDDL representation (task PDDL) of planning task requests followed by using a classical planner for computing a plan. Unlike previous approaches that use LLMs for generating task PDDLs directly, our approach comprises of (a) translate: using an LLM only for generating a logically interpretable intermediate representation of natural language task descriptions, (b) infer: deriving additional logically dependent information from the intermediate representation using a logic reasoner (currently, Answer Set Programming solver), and (c) compile: generating the targ
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.05162</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#35780;&#20272;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20854;&#23433;&#20840;&#26426;&#21046;&#26041;&#38754;&#34920;&#29616;&#20986;&#22266;&#26377;&#30340;&#26131;&#30862;&#24615;&#65292;&#36825;&#21487;&#20174;&#23427;&#20204;&#26131;&#21463;&#36234;&#29425;&#21644;&#21363;&#20351;&#26159;&#38750;&#24694;&#24847;&#24494;&#35843;&#20063;&#26131;&#21463;&#24433;&#21709;&#26469;&#35828;&#26126;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#25506;&#35752;&#20102;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#23545;&#20110;&#23433;&#20840;&#38450;&#25252;&#33267;&#20851;&#37325;&#35201;&#65292;&#19988;&#22312;&#31070;&#32463;&#20803;&#21644;&#31209;&#32423;&#21035;&#19978;&#19982;&#25928;&#29992;&#30456;&#20851;&#30340;&#21306;&#22495;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#30340;&#23396;&#31435;&#21306;&#22495;&#26159;&#31232;&#30095;&#30340;&#65292;&#32422;&#21344;&#21442;&#25968;&#32423;&#21035;&#30340;$3\%$&#21644;&#25490;&#21517;&#32423;&#21035;&#30340;$2.5\%$&#12290;&#21435;&#38500;&#36825;&#20123;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#32780;&#23545;&#25928;&#29992;&#30340;&#24433;&#21709;&#19981;&#22823;&#65292;&#20174;&#32780;&#35777;&#23454;&#20102;&#35813;&#27169;&#22411;&#23433;&#20840;&#26426;&#21046;&#30340;&#22266;&#26377;&#26131;&#30862;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#21363;&#20351;&#38480;&#21046;&#23545;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#36827;&#34892;&#20462;&#25913;&#65292;LLMs&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#20302;&#25104;&#26412;&#30340;&#24494;&#35843;&#25915;&#20987;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;LLMs&#20013;&#26356;&#24378;&#22823;&#30340;&#23433;&#20840;&#31574;&#30053;&#30340;&#32039;&#36843;&#24615;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3\%$ at the parameter level and $2.5\%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model's safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.
&lt;/p&gt;</description></item><item><title>CodeIt&#26159;&#19968;&#31181;&#20855;&#22791;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30446;&#26631;&#37325;&#26631;&#35760;&#20026;&#37319;&#26679;&#31243;&#24207;&#30340;&#23454;&#38469;&#36755;&#20986;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#31243;&#24207;&#21512;&#25104;&#20013;&#22870;&#21169;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#19978;&#23454;&#29616;&#20102;&#25104;&#21151;&#30340;&#36328;&#20219;&#21153;&#27867;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.04858</link><description>&lt;p&gt;
CodeIt&#65306;&#20855;&#26377;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04858
&lt;/p&gt;
&lt;p&gt;
CodeIt&#26159;&#19968;&#31181;&#20855;&#22791;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30446;&#26631;&#37325;&#26631;&#35760;&#20026;&#37319;&#26679;&#31243;&#24207;&#30340;&#23454;&#38469;&#36755;&#20986;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#31243;&#24207;&#21512;&#25104;&#20013;&#22870;&#21169;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#19978;&#23454;&#29616;&#20102;&#25104;&#21151;&#30340;&#36328;&#20219;&#21153;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36234;&#26469;&#36234;&#33021;&#22815;&#35299;&#20915;&#36890;&#24120;&#34987;&#35748;&#20026;&#38656;&#35201;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#36890;&#29992;&#26234;&#33021;&#22522;&#20934;&#27979;&#35797;&#20363;&#22914;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#19978;&#34920;&#29616;&#20173;&#28982;&#38750;&#24120;&#24046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;ARC&#35270;&#20026;&#19968;&#20010;&#20197;&#32534;&#31243;&#31034;&#20363;&#20026;&#22522;&#30784;&#30340;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;Code Iteration&#65288;CodeIt&#65289;&#30340;&#26032;&#39062;&#19988;&#21487;&#25193;&#23637;&#30340;&#35821;&#35328;&#27169;&#22411;&#33258;&#25105;&#25913;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;1&#65289;&#31243;&#24207;&#25277;&#26679;&#21644;&#22238;&#39038;&#37325;&#26631;&#35760;&#20197;&#21450;2&#65289;&#22522;&#20110;&#20248;&#20808;&#32423;&#30340;&#32463;&#39564;&#22238;&#25918;&#20043;&#38388;&#36827;&#34892;&#36845;&#20195;&#12290;&#36890;&#36807;&#23558;&#19968;&#20010;episode&#30340;&#30446;&#26631;&#65288;&#21363;&#32473;&#23450;&#36755;&#20837;&#30340;&#30446;&#26631;&#31243;&#24207;&#36755;&#20986;&#65289;&#37325;&#26631;&#35760;&#20026;&#37319;&#26679;&#31243;&#24207;&#20135;&#29983;&#30340;&#23454;&#38469;&#36755;&#20986;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#22788;&#29702;&#20102;&#31243;&#24207;&#21512;&#25104;&#20013;&#22870;&#21169;&#26497;&#24230;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#12290;&#24212;&#29992;CodeIt&#20110;ARC&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#12289;&#39044;&#35757;&#32451;&#21644;&#25968;&#25454;&#22686;&#24378;&#21487;&#20197;&#23454;&#29616;&#25104;&#21151;&#30340;&#36328;&#20219;&#21153;&#27867;&#21270;&#12290;CodeIt&#26159;&#31532;&#19968;&#20010;&#31070;&#32463;&#20803;-&#21512;&#25104;&#26426;&#21046;&#19968;&#20307;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are increasingly solving tasks that are commonly believed to require human-level reasoning ability. However, these models still perform very poorly on benchmarks of general intelligence such as the Abstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as a programming-by-examples problem, and introduce a novel and scalable method for language model self-improvement called Code Iteration (CodeIt). Our method iterates between 1) program sampling and hindsight relabeling, and 2) learning from prioritized experience replay. By relabeling the goal of an episode (i.e., the target program output given input) to the realized output produced by the sampled program, our method effectively deals with the extreme sparsity of rewards in program synthesis. Applying CodeIt to the ARC dataset, we demonstrate that prioritized hindsight replay, along with pre-training and data-augmentation, leads to successful inter-task generalization. CodeIt is the first neuro-sy
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#35782;&#21035;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30693;&#35782;&#30450;&#21306;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;LLM&#21327;&#20316;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#22312;&#38754;&#23545;&#30693;&#35782;&#30450;&#21306;&#26102;&#25918;&#24323;&#22238;&#31572;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#25552;&#39640;&#25918;&#24323;&#20934;&#30830;&#24230;&#26041;&#38754;&#21462;&#24471;&#20102;&#39640;&#36798;19.3&#65285;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.00367</link><description>&lt;p&gt;
&#19981;&#35201;&#24187;&#35273;&#65292;&#25345;&#35266;&#65306;&#36890;&#36807;&#22810;LLM&#21327;&#20316;&#35782;&#21035;LLM&#30693;&#35782;&#30450;&#21306;
&lt;/p&gt;
&lt;p&gt;
Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00367
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#35782;&#21035;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30693;&#35782;&#30450;&#21306;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;LLM&#21327;&#20316;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#22312;&#38754;&#23545;&#30693;&#35782;&#30450;&#21306;&#26102;&#25918;&#24323;&#22238;&#31572;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#25552;&#39640;&#25918;&#24323;&#20934;&#30830;&#24230;&#26041;&#38754;&#21462;&#24471;&#20102;&#39640;&#36798;19.3&#65285;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#23384;&#22312;&#25193;&#23637;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30693;&#35782;&#30340;&#21162;&#21147;&#65292;&#20294;&#30001;&#20110;&#30693;&#35782;&#30340;&#19981;&#26029;&#28436;&#21270;&#65292;LLM&#30693;&#35782;&#30450;&#21306;&#8212;&#8212;LLM&#20013;&#32570;&#22833;&#25110;&#36807;&#26102;&#30340;&#20449;&#24687;&#21487;&#33021;&#20250;&#19968;&#30452;&#23384;&#22312;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#35782;&#21035;LLM&#30693;&#35782;&#30450;&#21306;&#21644;&#22312;&#23384;&#22312;&#30693;&#35782;&#30450;&#21306;&#26102;&#25918;&#24323;&#22238;&#31572;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#27169;&#22411;&#26657;&#20934;&#25110;&#36866;&#24212;&#30340;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#25913;&#36827;&#65292;&#24182;&#20998;&#26512;&#23427;&#20204;&#22312;&#36991;&#20813;&#29983;&#25104;&#20302;&#32622;&#20449;&#24230;&#36755;&#20986;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#21463;&#21040;&#23427;&#20204;&#22312;&#33258;&#25105;&#21453;&#24605;&#21644;&#36807;&#24230;&#20381;&#36182;&#20445;&#30041;&#38598;&#26041;&#38754;&#30340;&#22833;&#36133;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#27169;&#22411;&#21327;&#20316;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;LLM&#25506;&#27979;&#20854;&#20182;LLM&#30340;&#30693;&#35782;&#30450;&#21306;&#65292;&#26080;&#35770;&#26159;&#21512;&#20316;&#36824;&#26159;&#31454;&#20105;&#12290;&#36890;&#36807;&#22312;&#22235;&#20010;&#21253;&#21547;&#22810;&#26679;&#30693;&#35782;&#39046;&#22495;&#30340;&#38382;&#31572;&#20219;&#21153;&#19978;&#23545;&#19977;&#20010;LLM&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#25581;&#31034;LLM&#30693;&#35782;&#30450;&#21306;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#26041;&#27861;&#22312;&#25918;&#24323;&#20934;&#30830;&#24230;&#26041;&#38754;&#21462;&#24471;&#20102;&#39640;&#36798;19.3&#65285;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite efforts to expand the knowledge of large language models (LLMs), knowledge gaps -- missing or outdated information in LLMs -- might always persist given the evolving nature of knowledge. In this work, we study approaches to identify LLM knowledge gaps and abstain from answering questions when knowledge gaps are present. We first adapt existing approaches to model calibration or adaptation through fine-tuning/prompting and analyze their ability to abstain from generating low-confidence outputs. Motivated by their failures in self-reflection and over-reliance on held-out sets, we propose two novel approaches that are based on model collaboration, i.e., LLMs probing other LLMs for knowledge gaps, either cooperatively or competitively. Extensive experiments with three LLMs on four QA tasks featuring diverse knowledge domains demonstrate that both cooperative and competitive approaches to unveiling LLM knowledge gaps achieve up to 19.3% improvements on abstain accuracy against the s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#38382;&#39064;&#23545;&#40784;&#35757;&#32451;&#27169;&#22411;&#23558;&#25512;&#29702;&#38382;&#39064;&#32763;&#35793;&#25104;&#33521;&#35821;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#12289;&#39046;&#22495;&#20869;&#30340;&#35821;&#35328;&#23545;&#40784;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#33521;&#35821;&#25351;&#23548;&#25968;&#25454;&#65292;&#37322;&#25918;&#20102;LLMs&#30340;&#22810;&#35821;&#35328;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2401.07817</link><description>&lt;p&gt;
&#20026;&#20102;&#26356;&#22909;&#30340;&#22810;&#35821;&#35328;&#25512;&#29702;&#33021;&#21147;&#32780;&#36827;&#34892;&#30340;&#38382;&#39064;&#32763;&#35793;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Question Translation Training for Better Multilingual Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.07817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#38382;&#39064;&#23545;&#40784;&#35757;&#32451;&#27169;&#22411;&#23558;&#25512;&#29702;&#38382;&#39064;&#32763;&#35793;&#25104;&#33521;&#35821;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#12289;&#39046;&#22495;&#20869;&#30340;&#35821;&#35328;&#23545;&#40784;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#33521;&#35821;&#25351;&#23548;&#25968;&#25454;&#65292;&#37322;&#25918;&#20102;LLMs&#30340;&#22810;&#35821;&#35328;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#38750;&#33521;&#35821;&#35821;&#35328;&#19978;&#30340;&#34920;&#29616;&#24448;&#24448;&#36739;&#24046;&#12290;&#20256;&#32479;&#35299;&#20915;&#26041;&#26696;&#26159;&#23558;&#25351;&#23548;&#25968;&#25454;&#32763;&#35793;&#25104;&#25152;&#26377;&#24863;&#20852;&#36259;&#30340;&#35821;&#35328;&#65292;&#28982;&#21518;&#22312;&#29983;&#25104;&#30340;&#22810;&#35821;&#35328;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#34987;&#31216;&#20026;&#32763;&#35793;&#35757;&#32451;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#38382;&#39064;&#23545;&#40784;&#30340;&#22909;&#22788;&#65292;&#36890;&#36807;&#22312;X-&#33521;&#35821;&#24179;&#34892;&#38382;&#39064;&#25968;&#25454;&#19978;&#24494;&#35843;&#65292;&#35757;&#32451;&#27169;&#22411;&#23558;&#25512;&#29702;&#38382;&#39064;&#32763;&#35793;&#25104;&#33521;&#35821;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#26377;&#38024;&#23545;&#24615;&#30340;&#12289;&#39046;&#22495;&#20869;&#30340;&#35821;&#35328;&#23545;&#40784;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#33521;&#35821;&#25351;&#23548;&#25968;&#25454;&#65292;&#37322;&#25918;&#20102;LLMs&#30340;&#22810;&#35821;&#35328;&#25512;&#29702;&#33021;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;LLaMA2-13&#19978;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.07817v2 Announce Type: replace  Abstract: Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions. A typical solution is to translate instruction data into all languages of interest, and then train on the resulting multilingual data, which is called translate-training. This approach not only incurs high cost, but also results in poorly translated data due to the non-standard formatting of mathematical chain-of-thought. In this paper, we explore the benefits of question alignment, where we train the model to translate reasoning questions into English by finetuning on X-English parallel question data. In this way we perform targeted, in-domain language alignment which makes best use of English instruction data to unlock the LLMs' multilingual reasoning abilities. Experimental results on LLaMA2-13
&lt;/p&gt;</description></item><item><title>UNER&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#12289;&#31038;&#21306;&#39537;&#21160;&#30340;&#39033;&#30446;&#65292;&#26088;&#22312;&#25552;&#20379;&#39640;&#36136;&#37327;&#12289;&#36328;&#35821;&#35328;&#19968;&#33268;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#22522;&#20934;&#65292;&#20197;&#20419;&#36827;&#21644;&#26631;&#20934;&#21270;&#22810;&#35821;&#35328;NER&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2311.09122</link><description>&lt;p&gt;
&#36890;&#29992;NER:&#19968;&#20010;&#37329;&#26631;&#20934;&#30340;&#22810;&#35821;&#35328;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09122
&lt;/p&gt;
&lt;p&gt;
UNER&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#12289;&#31038;&#21306;&#39537;&#21160;&#30340;&#39033;&#30446;&#65292;&#26088;&#22312;&#25552;&#20379;&#39640;&#36136;&#37327;&#12289;&#36328;&#35821;&#35328;&#19968;&#33268;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#22522;&#20934;&#65292;&#20197;&#20419;&#36827;&#21644;&#26631;&#20934;&#21270;&#22810;&#35821;&#35328;NER&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#36890;&#29992;NER&#65288;UNER&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#65292;&#31038;&#21306;&#39537;&#21160;&#30340;&#39033;&#30446;&#65292;&#26088;&#22312;&#24320;&#21457;&#22810;&#31181;&#35821;&#35328;&#30340;&#37329;&#26631;&#20934;NER&#22522;&#20934;&#12290;UNER&#30340;&#24635;&#20307;&#30446;&#26631;&#26159;&#25552;&#20379;&#39640;&#36136;&#37327;&#12289;&#36328;&#35821;&#35328;&#19968;&#33268;&#30340;&#26631;&#27880;&#65292;&#20197;&#20419;&#36827;&#21644;&#26631;&#20934;&#21270;&#22810;&#35821;&#35328;NER&#30740;&#31350;&#12290;UNER v1&#21253;&#21547;&#20102;&#22312;12&#31181;&#19981;&#21516;&#35821;&#35328;&#20013;&#20351;&#29992;&#36328;&#35821;&#35328;&#19968;&#33268;&#27169;&#24335;&#26631;&#27880;&#30340;18&#20010;&#25968;&#25454;&#38598;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;UNER&#30340;&#25968;&#25454;&#38598;&#21019;&#24314;&#21644;&#32452;&#25104;&#65307;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#38024;&#23545;&#19981;&#21516;&#35821;&#35328;&#21644;&#36328;&#35821;&#35328;&#23398;&#20064;&#35774;&#32622;&#30340;&#21021;&#22987;&#24314;&#27169;&#22522;&#32447;&#12290;&#25105;&#20204;&#21521;&#20844;&#20247;&#21457;&#24067;&#20102;&#25968;&#25454;&#12289;&#20195;&#30721;&#21644;&#25311;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09122v2 Announce Type: replace  Abstract: We introduce Universal NER (UNER), an open, community-driven project to develop gold-standard NER benchmarks in many languages. The overarching goal of UNER is to provide high-quality, cross-lingually consistent annotations to facilitate and standardize multilingual NER research. UNER v1 contains 18 datasets annotated with named entities in a cross-lingual consistent schema across 12 diverse languages. In this paper, we detail the dataset creation and composition of UNER; we also provide initial modeling baselines on both in-language and cross-lingual learning settings. We release the data, code, and fitted models to the public.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#26088;&#22312;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35745;&#31639;&#36777;&#35770;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#35774;&#32622;&#65292;&#26631;&#20934;&#21270;&#20102;14&#20010;&#24320;&#28304;&#25968;&#25454;&#38598;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#21453;&#35328;&#29983;&#25104;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2311.09022</link><description>&lt;p&gt;
&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35745;&#31639;&#36777;&#35770;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Exploring the Potential of Large Language Models in Computational Argumentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09022
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#26088;&#22312;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35745;&#31639;&#36777;&#35770;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#35774;&#32622;&#65292;&#26631;&#20934;&#21270;&#20102;14&#20010;&#24320;&#28304;&#25968;&#25454;&#38598;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#21453;&#35328;&#29983;&#25104;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#36777;&#35770;&#24050;&#25104;&#20026;&#21253;&#25324;&#20154;&#24037;&#26234;&#33021;&#12289;&#27861;&#24459;&#21644;&#20844;&#20849;&#25919;&#31574;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#24037;&#20855;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#26032;&#20852;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#35745;&#31639;&#36777;&#35770;&#21560;&#24341;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#30740;&#31350;&#35745;&#31639;&#36777;&#35770;&#20027;&#35201;&#28041;&#21450;&#20004;&#31867;&#20219;&#21153;&#65306;&#36777;&#35770;&#25366;&#25496;&#21644;&#36777;&#35770;&#29983;&#25104;&#12290;&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#19978;&#19979;&#25991;&#21644;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#35780;&#20272;LLMs&#22312;&#21508;&#31181;&#35745;&#31639;&#36777;&#35770;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#26159;&#20540;&#24471;&#30340;&#12290;&#26412;&#24037;&#20316;&#26088;&#22312;&#35780;&#20272;LLMs&#65288;&#20363;&#22914;ChatGPT&#12289;Flan&#21644;LLaMA2&#27169;&#22411;&#65289;&#22312;&#35745;&#31639;&#36777;&#35770;&#39046;&#22495;&#30340;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#35774;&#32622;&#19979;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#23558;&#29616;&#26377;&#20219;&#21153;&#20998;&#20026;&#20845;&#20010;&#20027;&#35201;&#31867;&#21035;&#65292;&#24182;&#23545;&#21313;&#22235;&#20010;&#24320;&#28304;&#25968;&#25454;&#38598;&#30340;&#26684;&#24335;&#36827;&#34892;&#20102;&#26631;&#20934;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20851;&#20110;&#21453;&#35328;&#29983;&#25104;&#30340;&#26032;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09022v2 Announce Type: replace  Abstract: Computational argumentation has become an essential tool in various fields, including artificial intelligence, law, and public policy. It is an emerging research field in natural language processing that attracts increasing attention. Research on computational argumentation mainly involves two types of tasks: argument mining and argument generation. As large language models have demonstrated strong abilities in understanding context and generating natural language, it is worthwhile to evaluate the performance of LLMs on various computational argumentation tasks. This work aims to embark on an assessment of LLMs, such as ChatGPT, Flan models and LLaMA2 models, under zero-shot and few-shot settings within the realm of computational argumentation. We organize existing tasks into six main categories and standardise the format of fourteen open-sourced datasets. In addition, we present a new benchmark dataset on counter speech generation, 
&lt;/p&gt;</description></item><item><title>&#36739;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#27493;&#39588;&#25968;&#23398;&#25512;&#29702;&#20013;&#36890;&#36807;&#27491;&#30830;&#24320;&#22987;&#21487;&#20197;&#33719;&#24471;&#26174;&#30528;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#24314;&#35758;&#36890;&#36807;&#21021;&#22987;&#25351;&#23548;&#21644;&#33258;&#38382;&#25351;&#23548;&#30340;&#26041;&#24335;&#26469;&#24341;&#23548;&#27169;&#22411;&#24320;&#22987;&#27491;&#30830;&#12290;</title><link>https://arxiv.org/abs/2311.07945</link><description>&lt;p&gt;
&#33391;&#22909;&#30340;&#24320;&#31471;&#26159;&#25104;&#21151;&#30340;&#19968;&#21322;&#65306;&#22810;&#27493;&#39588;&#25968;&#23398;&#25512;&#29702;&#20013;&#24320;&#22987;&#27491;&#30830;&#30340;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Well begun is half done: Importance of Starting Right in Multi-Step Math Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07945
&lt;/p&gt;
&lt;p&gt;
&#36739;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#27493;&#39588;&#25968;&#23398;&#25512;&#29702;&#20013;&#36890;&#36807;&#27491;&#30830;&#24320;&#22987;&#21487;&#20197;&#33719;&#24471;&#26174;&#30528;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#24314;&#35758;&#36890;&#36807;&#21021;&#22987;&#25351;&#23548;&#21644;&#33258;&#38382;&#25351;&#23548;&#30340;&#26041;&#24335;&#26469;&#24341;&#23548;&#27169;&#22411;&#24320;&#22987;&#27491;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36739;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#20026;&#20854;&#39044;&#27979;&#29983;&#25104;&#21407;&#22240;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#22797;&#26434;&#30340;&#25512;&#29702;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#20123;&#36739;&#23567;&#30340;&#27169;&#22411;&#26377;&#26102;&#20250;&#22312;&#24320;&#22987;&#26102;&#36935;&#21040;&#22256;&#38590;&#65292;&#20294;&#22312;&#24471;&#21040;&#32416;&#27491;&#21518;&#65292;&#21487;&#20197;&#35299;&#20915;&#21407;&#26412;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#36739;&#23567;&#27169;&#22411;&#21487;&#20197;&#20174;&#21021;&#22987;&#25351;&#23548;&#20013;&#21463;&#30410;&#30340;&#26041;&#24335;&#65306;1&#65289;&#21521;LLM&#23547;&#27714;&#21021;&#22987;&#25351;&#23548;&#65292;&#21644;2&#65289;&#33258;&#38382;&#25351;&#23548;&#65292;&#23398;&#29983;&#27169;&#22411;&#21487;&#20197;&#39318;&#20808;&#21457;&#36215;&#19968;&#20010;&#20851;&#20110;&#22914;&#20309;&#24320;&#22987;&#30340;&#38382;&#39064;&#65292;&#28982;&#21518;&#32487;&#32493;&#36825;&#19968;&#36830;&#38145;&#12290;&#25105;&#20204;&#23558;&#21021;&#22987;&#22522;&#20110;&#38382;&#39064;&#30340;&#25351;&#23548;&#25193;&#23637;&#21040;&#20102;&#19968;&#31181;&#31216;&#20026;QuestCoT&#30340;&#25552;&#31034;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#22312;&#36827;&#34892;&#25512;&#29702;&#38142;&#20043;&#21069;&#20197;&#19968;&#20010;&#38382;&#39064;&#24320;&#22987;&#26159;&#26377;&#30410;&#30340;&#12290;&#22312;&#20004;&#20010;&#22810;&#27493;&#25968;&#23398;&#25512;&#29702;&#25968;&#25454;&#38598;GSM8K&#21644;SVAMP&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27491;&#30830;&#24320;&#22987;&#21487;&#20197;&#24102;&#26469;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65288;&#36890;&#36807;LLM&#25351;&#23548;&#26368;&#39640;&#39640;&#36798;+14&#20998;&#65292;&#36890;&#36807;QuestCoT&#26368;&#39640;&#39640;&#36798;+6&#20998;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07945v2 Announce Type: replace  Abstract: Smaller language models can solve complex reasoning tasks better by learning to generate rationales for their predictions. However, we observe that these smaller models can sometimes struggle to start correctly, but when corrected, can solve a task that they would otherwise have struggled with. We propose two ways in which a smaller model can benefit from initial guidance: 1) asking an LLM for initial guidance, and 2) self-questioning guidance, where the student model can first initiate a question regarding how to start and then continue that chain. We extend initial question-based guidance to a prompting technique called QuestCoT, where starting with a question before a chain of reasoning proves useful. On two multi-step math reasoning datasets GSM8K and SVAMP, we show that starting correctly can lead to a significant performance gain (up to $+14$ points with LLM guidance and $+6$ points with QuestCoT).
&lt;/p&gt;</description></item><item><title>&#20889;&#20316;&#26102;&#20351;&#29992;InstructGPT&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#26174;&#33879;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65292;&#22686;&#21152;&#19981;&#21516;&#20316;&#32773;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#20943;&#23569;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2309.05196</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20889;&#20316;&#26159;&#21542;&#20250;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Does Writing with Language Models Reduce Content Diversity?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.05196
&lt;/p&gt;
&lt;p&gt;
&#20889;&#20316;&#26102;&#20351;&#29992;InstructGPT&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#26174;&#33879;&#38477;&#20302;&#20869;&#23481;&#22810;&#26679;&#24615;&#65292;&#22686;&#21152;&#19981;&#21516;&#20316;&#32773;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#20943;&#23569;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#21457;&#20102;&#19982;&#27169;&#22411;&#36741;&#21161;&#21512;&#20316;&#20889;&#20316;&#30340;&#28608;&#22686;&#12290;&#24403;&#19981;&#21516;&#29992;&#25143;&#32435;&#20837;&#21516;&#19968;&#27169;&#22411;&#30340;&#24314;&#35758;&#26102;&#65292;&#20250;&#23384;&#22312;&#20869;&#23481;&#22810;&#26679;&#24615;&#20943;&#23569;&#30340;&#39118;&#38505;&#65292;&#21487;&#33021;&#38480;&#21046;&#20844;&#20849;&#35805;&#35821;&#20013;&#30340;&#22810;&#20803;&#35266;&#28857;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#25511;&#21046;&#23454;&#39564;&#27979;&#37327;&#20102;&#21327;&#21516;&#20889;&#20316;&#23545;&#22810;&#26679;&#24615;&#30340;&#24433;&#21709;&#65292;&#22312;&#35813;&#23454;&#39564;&#20013;&#65292;&#29992;&#25143;&#20197;&#19977;&#31181;&#35774;&#32622;&#25776;&#20889;&#35758;&#35770;&#24615;&#25991;&#31456;--&#20351;&#29992;&#22522;&#26412;LLM&#65288;GPT3&#65289;&#12289;&#32463;&#36807;&#21453;&#39304;&#35843;&#25972;&#30340;LLM&#65288;InstructGPT&#65289;&#20197;&#21450;&#19981;&#20351;&#29992;&#27169;&#22411;&#24110;&#21161;&#20889;&#20316;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#32452;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;InstructGPT&#36827;&#34892;&#20889;&#20316;&#65288;&#32780;&#19981;&#26159;GPT3&#65289;&#20250;&#23548;&#33268;&#22810;&#26679;&#24615;&#26126;&#26174;&#38477;&#20302;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#22686;&#21152;&#20102;&#19981;&#21516;&#20316;&#32773;&#30340;&#20889;&#20316;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20943;&#23569;&#20102;&#25972;&#20307;&#30340;&#35789;&#27719;&#21644;&#20869;&#23481;&#22810;&#26679;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#36825;&#31181;&#24433;&#21709;&#20027;&#35201;&#26469;&#28304;&#20110;InstructGPT&#23545;&#20849;&#21516;&#25776;&#20889;&#30340;&#25991;&#26412;&#36129;&#29486;&#36739;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.05196v2 Announce Type: replace  Abstract: Large language models (LLMs) have led to a surge in collaborative writing with model assistance. As different users incorporate suggestions from the same model, there is a risk of decreased diversity in the produced content, potentially limiting diverse perspectives in public discourse. In this work, we measure the impact of co-writing on diversity via a controlled experiment, where users write argumentative essays in three setups -- using a base LLM (GPT3), a feedback-tuned LLM (InstructGPT), and writing without model help. We develop a set of diversity metrics and find that writing with InstructGPT (but not the GPT3) results in a statistically significant reduction in diversity. Specifically, it increases the similarity between the writings of different authors and reduces the overall lexical and content diversity. We additionally find that this effect is mainly attributable to InstructGPT contributing less diverse text to co-writt
&lt;/p&gt;</description></item><item><title>CFMatch&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24320;&#25918;&#22495;&#38382;&#31572;&#20013;&#23558;&#33258;&#21160;&#31572;&#26696;&#31561;&#20215;&#35780;&#20272;&#19982;&#20154;&#24037;&#19987;&#23478;&#21028;&#26029;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#26126;&#30830;&#19968;&#33268;&#30340;&#35780;&#20272;&#25351;&#21335;&#24182;&#24341;&#20837;&#39640;&#25928;&#12289;&#31283;&#20581;&#19988;&#36731;&#37327;&#32423;&#30340;&#21028;&#21035;&#24335;AE&#20998;&#31867;&#22120;&#21305;&#37197;&#26041;&#27861;&#26469;&#35299;&#20915;&#24403;&#21069;&#35780;&#20272;&#25351;&#26631;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.13170</link><description>&lt;p&gt;
CFMatch: &#23558;&#33258;&#21160;&#31572;&#26696;&#31561;&#20215;&#35780;&#20272;&#19982;&#20154;&#24037;&#19987;&#23478;&#21028;&#26029;&#22312;&#24320;&#25918;&#22495;&#38382;&#31572;&#20013;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering. (arXiv:2401.13170v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13170
&lt;/p&gt;
&lt;p&gt;
CFMatch&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24320;&#25918;&#22495;&#38382;&#31572;&#20013;&#23558;&#33258;&#21160;&#31572;&#26696;&#31561;&#20215;&#35780;&#20272;&#19982;&#20154;&#24037;&#19987;&#23478;&#21028;&#26029;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#26126;&#30830;&#19968;&#33268;&#30340;&#35780;&#20272;&#25351;&#21335;&#24182;&#24341;&#20837;&#39640;&#25928;&#12289;&#31283;&#20581;&#19988;&#36731;&#37327;&#32423;&#30340;&#21028;&#21035;&#24335;AE&#20998;&#31867;&#22120;&#21305;&#37197;&#26041;&#27861;&#26469;&#35299;&#20915;&#24403;&#21069;&#35780;&#20272;&#25351;&#26631;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38382;&#31572;&#31995;&#32479;&#21482;&#26377;&#22312;&#25105;&#20204;&#30693;&#36947;&#31572;&#26696;&#26159;&#21542;&#27491;&#30830;&#30340;&#24773;&#20917;&#19979;&#25165;&#33021;&#21462;&#24471;&#36827;&#23637;&#65292;&#20294;&#23545;&#20110;&#35768;&#22810;&#26368;&#20855;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#38382;&#31572;&#31034;&#20363;&#65292;&#24403;&#21069;&#29992;&#20110;&#30830;&#23450;&#31572;&#26696;&#31561;&#20215;&#24615;&#30340;&#35780;&#20272;&#25351;&#26631;&#36890;&#24120;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26356;&#20887;&#38271;&#12289;&#33258;&#30001;&#24418;&#24335;&#30340;&#31572;&#26696;&#12290;&#23384;&#22312;&#20004;&#20010;&#25361;&#25112;&#65306;&#32570;&#20047;&#25968;&#25454;&#21644;&#27169;&#22411;&#36807;&#22823;&#65306;&#22522;&#20110;LLM&#30340;&#35780;&#20998;&#22120;&#21487;&#20197;&#26356;&#22909;&#22320;&#19982;&#20154;&#24037;&#35780;&#21028;&#21592;&#30456;&#20851;&#32852;&#65292;&#20294;&#36825;&#20010;&#20219;&#21153;&#21482;&#22312;&#26377;&#38480;&#30340;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#21363;&#20351;&#21487;&#29992;&#65292;&#23545;&#27169;&#22411;&#30340;&#26356;&#26032;&#20063;&#26377;&#38480;&#65292;&#22240;&#20026;LLM&#36807;&#22823;&#19988;&#24448;&#24448;&#26114;&#36149;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#26126;&#30830;&#19968;&#33268;&#30340;&#25351;&#21335;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#36825;&#20123;&#25351;&#21335;&#29992;&#20110;&#20174;&#19987;&#19994;&#20154;&#24037;&#38382;&#31572;&#27604;&#36187;&#20013;&#37319;&#32435;&#26426;&#22120;&#38382;&#31572;&#22312;&#31572;&#26696;&#31561;&#20215;&#24615;&#35780;&#20272;&#26041;&#38754;&#30340;&#26631;&#20934;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26631;&#20934;&#35780;&#20272;&#21644;&#19968;&#31181;&#26356;&#39640;&#25928;&#12289;&#31283;&#20581;&#19988;&#36731;&#37327;&#32423;&#30340;&#21028;&#21035;&#24335;AE&#20998;&#31867;&#22120;&#21305;&#37197;&#26041;&#27861;&#65288;CFMatch&#65292;&#22823;&#23567;&#23567;&#20110;1MB&#65289;&#65292;&#32463;&#36807;&#35757;&#32451;&#21644;&#39564;&#35777;&#20197;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#31572;&#26696;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive. We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests. We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evalu
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#32467;&#21512;&#20855;&#26377;&#24378;&#22823;&#30340;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#26631;&#35760;&#23884;&#20837;&#21644;&#22522;&#22240;&#22411;-&#34920;&#29616;&#22411;&#26144;&#23556;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#36866;&#24212;&#24615;&#22609;&#36896;&#12289;&#20301;&#32622;&#23884;&#20837;&#21644;&#36873;&#25321;&#12289;&#27880;&#24847;&#21147;&#21644;&#20132;&#21449;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#31361;&#21464;&#12289;&#27169;&#22411;&#35757;&#32451;&#21644;&#21442;&#25968;&#26356;&#26032;&#20197;&#21450;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#31561;&#22810;&#20010;&#26680;&#24515;&#29305;&#24449;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#32806;&#21512;&#30740;&#31350;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#26412;&#36335;&#32447;&#21644;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.10510</link><description>&lt;p&gt;
&#22825;&#20316;&#20043;&#21512;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#36827;&#21270;&#31639;&#27861;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
A match made in consistency heaven: when large language models meet evolutionary algorithms. (arXiv:2401.10510v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10510
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#32467;&#21512;&#20855;&#26377;&#24378;&#22823;&#30340;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#26631;&#35760;&#23884;&#20837;&#21644;&#22522;&#22240;&#22411;-&#34920;&#29616;&#22411;&#26144;&#23556;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#36866;&#24212;&#24615;&#22609;&#36896;&#12289;&#20301;&#32622;&#23884;&#20837;&#21644;&#36873;&#25321;&#12289;&#27880;&#24847;&#21147;&#21644;&#20132;&#21449;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#31361;&#21464;&#12289;&#27169;&#22411;&#35757;&#32451;&#21644;&#21442;&#25968;&#26356;&#26032;&#20197;&#21450;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#31561;&#22810;&#20010;&#26680;&#24515;&#29305;&#24449;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#32806;&#21512;&#30740;&#31350;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#26412;&#36335;&#32447;&#21644;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29983;&#25104;&#21019;&#36896;&#24615;&#30340;&#33258;&#28982;&#25991;&#26412;&#26041;&#38754;&#20855;&#26377;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;&#36827;&#21270;&#31639;&#27861;&#65288;EAs&#65289;&#21487;&#20197;&#21457;&#29616;&#22797;&#26434;&#23454;&#38469;&#38382;&#39064;&#30340;&#22810;&#26679;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#25991;&#26412;&#24207;&#21015;&#29983;&#25104;&#21644;&#36827;&#21270;&#30340;&#20849;&#21516;&#29305;&#28857;&#21644;&#26041;&#21521;&#24615;&#65292;&#38416;&#36848;&#20102;LLMs&#19982;EAs&#20043;&#38388;&#30340;&#24378;&#22823;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#22810;&#20010;&#19968;&#23545;&#19968;&#30340;&#26680;&#24515;&#29305;&#24449;&#65306;&#26631;&#35760;&#23884;&#20837;&#21644;&#22522;&#22240;&#22411;-&#34920;&#29616;&#22411;&#26144;&#23556;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#36866;&#24212;&#24615;&#22609;&#36896;&#12289;&#20301;&#32622;&#23884;&#20837;&#21644;&#36873;&#25321;&#12289;&#27880;&#24847;&#21147;&#21644;&#20132;&#21449;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#31361;&#21464;&#12289;&#27169;&#22411;&#35757;&#32451;&#21644;&#21442;&#25968;&#26356;&#26032;&#20197;&#21450;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#12290;&#22312;&#36825;&#31181;&#19968;&#33268;&#24615;&#35270;&#35282;&#19979;&#65292;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#32806;&#21512;&#30740;&#31350;&#65292;&#21253;&#25324;&#36827;&#21270;&#24494;&#35843;&#21644;LLM&#22686;&#24378;&#22411;EAs&#12290;&#20511;&#21161;&#36825;&#20123;&#27934;&#35265;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#26410;&#26469;&#22312;LLMs&#21644;EAs&#32806;&#21512;&#26041;&#38754;&#30340;&#22522;&#26412;&#30740;&#31350;&#36335;&#32447;&#65292;&#24182;&#31361;&#20986;&#20102;&#20854;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained large language models (LLMs) have powerful capabilities for generating creative natural text. Evolutionary algorithms (EAs) can discover diverse solutions to complex real-world problems. Motivated by the common collective and directionality of text sequence generation and evolution, this paper illustrates the strong consistency of LLMs and EAs, which includes multiple one-to-one key characteristics: token embedding and genotype-phenotype mapping, position encoding and fitness shaping, position embedding and selection, attention and crossover, feed-forward neural network and mutation, model training and parameter update, and multi-task learning and multi-objective optimization. Based on this consistency perspective, existing coupling studies are analyzed, including evolutionary fine-tuning and LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap for future research in coupling LLMs and EAs, while highlighting key challenges along the way. The consist
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#26041;&#27861;&#65288;ZOE&#65289;&#26469;&#38477;&#20302;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#30340;&#26080;&#30417;&#30563;&#21709;&#24212;&#36827;&#34892;&#21435;&#20559;&#12290;&#23454;&#39564;&#35777;&#23454;ZOE&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#20219;&#21153;&#20013;&#22343;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01218</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Position Debiasing for Large Language Models. (arXiv:2401.01218v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#26041;&#27861;&#65288;ZOE&#65289;&#26469;&#38477;&#20302;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#30340;&#26080;&#30417;&#30563;&#21709;&#24212;&#36827;&#34892;&#21435;&#20559;&#12290;&#23454;&#39564;&#35777;&#23454;ZOE&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#20219;&#21153;&#20013;&#22343;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#35843;&#24050;&#34987;&#35777;&#26126;&#26159;&#25913;&#21892;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39046;&#22495;&#24615;&#33021;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;LLMs&#21487;&#33021;&#36866;&#24212;&#25968;&#25454;&#38598;&#20559;&#35265;&#21644;&#39044;&#27979;&#30340;&#25463;&#24452;&#65292;&#23548;&#33268;&#29983;&#25104;&#24615;&#33021;&#24046;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;LLMs&#23481;&#26131;&#34920;&#29616;&#20986;&#20301;&#32622;&#20559;&#24046;&#65292;&#21363;&#21033;&#29992;&#20301;&#20110;&#24320;&#22836;&#25110;&#26411;&#23614;&#25110;&#36755;&#20837;&#20013;&#29305;&#23450;&#20301;&#32622;&#32447;&#32034;&#30340;&#20449;&#24687;&#12290;&#29616;&#26377;&#30340;&#20943;&#36731;&#20301;&#32622;&#20559;&#24046;&#30340;&#24037;&#20316;&#38656;&#35201;&#22806;&#37096;&#20559;&#24046;&#30693;&#35782;&#25110;&#24102;&#27880;&#37322;&#30340;&#38750;&#20559;&#20506;&#26679;&#26412;&#65292;&#22312;&#23454;&#38469;&#20013;&#19981;&#22826;&#23454;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#65288;ZOE&#65289;&#26694;&#26550;&#23545;LLMs&#36827;&#34892;&#20301;&#32622;&#21435;&#20559;&#12290;ZOE&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#30340;&#26080;&#30417;&#30563;&#21709;&#24212;&#36827;&#34892;&#21435;&#20559;&#65292;&#22240;&#27492;&#19981;&#38656;&#35201;&#20219;&#20309;&#22806;&#37096;&#30693;&#35782;&#25110;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#25552;&#39640;&#26080;&#30417;&#30563;&#21709;&#24212;&#30340;&#36136;&#37327;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#20174;&#23545;&#40784;&#65288;MSA&#65289;&#27169;&#22359;&#26469;&#20462;&#21098;&#36825;&#20123;&#21709;&#24212;&#12290;&#23545;&#20843;&#20010;&#25968;&#25454;&#38598;&#21644;&#20116;&#20010;&#20219;&#21153;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;ZOE&#22987;&#32456;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality. In this work, we propose a zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets. To improve the quality of unsupervised responses, we propose a master-slave alignment (MSA) module to prune these responses. Experiments on eight datasets and five tasks show that ZOE consistently outperform
&lt;/p&gt;</description></item><item><title>LQ-LoRA&#26159;&#19968;&#31181;&#20302;&#31209;&#21152;&#37327;&#21270;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#20869;&#23384;&#39640;&#25928;&#30340;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#12290;&#23427;&#36890;&#36807;&#23558;&#27599;&#20010;&#39044;&#35757;&#32451;&#30697;&#38453;&#20998;&#35299;&#20026;&#39640;&#31934;&#24230;&#20302;&#31209;&#37096;&#20998;&#21644;&#20869;&#23384;&#39640;&#25928;&#30340;&#37327;&#21270;&#37096;&#20998;&#65292;&#23454;&#29616;&#20102;&#21160;&#24577;&#37197;&#32622;&#37327;&#21270;&#21442;&#25968;&#20197;&#21450;&#23545;&#37325;&#26500;&#30446;&#26631;&#36827;&#34892;&#21152;&#26435;&#30340;&#20248;&#21270;&#65292;&#24182;&#22312;&#24494;&#35843;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#20110;QLoRA&#21644;GPTQ-LoRA&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.12023</link><description>&lt;p&gt;
LQ-LoRA: &#20302;&#31209;&#21152;&#37327;&#21270;&#30697;&#38453;&#20998;&#35299;&#29992;&#20110;&#26377;&#25928;&#30340;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning. (arXiv:2311.12023v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.12023
&lt;/p&gt;
&lt;p&gt;
LQ-LoRA&#26159;&#19968;&#31181;&#20302;&#31209;&#21152;&#37327;&#21270;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#20869;&#23384;&#39640;&#25928;&#30340;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#12290;&#23427;&#36890;&#36807;&#23558;&#27599;&#20010;&#39044;&#35757;&#32451;&#30697;&#38453;&#20998;&#35299;&#20026;&#39640;&#31934;&#24230;&#20302;&#31209;&#37096;&#20998;&#21644;&#20869;&#23384;&#39640;&#25928;&#30340;&#37327;&#21270;&#37096;&#20998;&#65292;&#23454;&#29616;&#20102;&#21160;&#24577;&#37197;&#32622;&#37327;&#21270;&#21442;&#25968;&#20197;&#21450;&#23545;&#37325;&#26500;&#30446;&#26631;&#36827;&#34892;&#21152;&#26435;&#30340;&#20248;&#21270;&#65292;&#24182;&#22312;&#24494;&#35843;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#20110;QLoRA&#21644;GPTQ-LoRA&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#36866;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#36845;&#20195;&#31639;&#27861;&#23558;&#27599;&#20010;&#39044;&#35757;&#32451;&#30697;&#38453;&#20998;&#35299;&#20026;&#39640;&#31934;&#24230;&#20302;&#31209;&#37096;&#20998;&#21644;&#20869;&#23384;&#39640;&#25928;&#30340;&#37327;&#21270;&#37096;&#20998;&#12290;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#65292;&#37327;&#21270;&#37096;&#20998;&#20445;&#25345;&#22266;&#23450;&#65292;&#21482;&#26377;&#20302;&#31209;&#37096;&#20998;&#34987;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#37327;&#21270;&#37096;&#20998;&#30340;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#34920;&#36798;&#65292;&#21487;&#20197;&#26681;&#25454;&#24635;&#20307;&#20869;&#23384;&#39044;&#31639;&#21160;&#24577;&#37197;&#32622;&#37327;&#21270;&#21442;&#25968;&#65288;&#20363;&#22914;&#27604;&#29305;&#23485;&#24230;&#12289;&#22359;&#22823;&#23567;&#65289;&#32473;&#23450;&#27599;&#20010;&#30697;&#38453;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#32034;&#20102;&#25968;&#25454;&#24863;&#30693;&#29256;&#26412;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#36817;&#20284;&#26469;&#21152;&#26435;&#30697;&#38453;&#20998;&#35299;&#36807;&#31243;&#20013;&#30340;&#37325;&#26500;&#30446;&#26631;&#12290;&#22312;RoBERTa&#21644;LLaMA-2&#65288;7B&#21644;70B&#65289;&#30340;&#24494;&#35843;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#20302;&#31209;&#21152;&#37327;&#21270;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65288;LQ-LoRA&#65289;&#20248;&#20110;&#24378;&#22522;&#32447;&#26041;&#27861;QLoRA&#21644;GPTQ-LoRA&#65292;&#24182;&#23454;&#29616;&#20102;&#28608;&#36827;&#30340;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a simple approach for memory-efficient adaptation of pretrained language models. Our approach uses an iterative algorithm to decompose each pretrained matrix into a high-precision low-rank component and a memory-efficient quantized component. During finetuning, the quantized component remains fixed and only the low-rank component is updated. We present an integer linear programming formulation of the quantization component which enables dynamic configuration of quantization parameters (e.g., bit-width, block size) for each matrix given an overall target memory budget. We further explore a data-aware version of the algorithm which uses an approximation of the Fisher information matrix to weight the reconstruction objective during matrix decomposition. Experiments on finetuning RoBERTa and LLaMA-2 (7B and 70B) demonstrate that our low-rank plus quantized matrix decomposition approach (LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and enables aggressive quantization
&lt;/p&gt;</description></item><item><title>$R^3$-NL2GQL&#26159;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;Foundation Models&#36827;&#34892;&#37325;&#26032;&#25490;&#21517;&#12289;&#37325;&#20889;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#20943;&#36731;&#24187;&#35273;&#65292;&#35299;&#20915;&#20102;NL2GQL&#20219;&#21153;&#20013;GQL&#29983;&#25104;&#33021;&#21147;&#21644;&#36328;&#27169;&#24335;&#36890;&#29992;&#33021;&#21147;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2311.01862</link><description>&lt;p&gt;
$R^3$-NL2GQL:&#19968;&#31181;&#29992;&#20110;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#20943;&#36731;&#24187;&#35273;&#30340;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
$R^3$-NL2GQL: A Hybrid Models Approach for for Accuracy Enhancing and Hallucinations Mitigation. (arXiv:2311.01862v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01862
&lt;/p&gt;
&lt;p&gt;
$R^3$-NL2GQL&#26159;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;Foundation Models&#36827;&#34892;&#37325;&#26032;&#25490;&#21517;&#12289;&#37325;&#20889;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#20943;&#36731;&#24187;&#35273;&#65292;&#35299;&#20915;&#20102;NL2GQL&#20219;&#21153;&#20013;GQL&#29983;&#25104;&#33021;&#21147;&#21644;&#36328;&#27169;&#24335;&#36890;&#29992;&#33021;&#21147;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#20351;&#29992;Foundation Models&#26500;&#24314;&#30340;NL2SQL&#20219;&#21153;&#21462;&#24471;&#20102;&#20196;&#20154;&#31216;&#36190;&#30340;&#32467;&#26524;&#65292;&#28982;&#32780;&#30452;&#25509;&#23558;&#20854;&#24212;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#21040;&#22270;&#26597;&#35810;&#35821;&#35328;&#65288;NL2GQL&#65289;&#20219;&#21153;&#38754;&#20020;&#25361;&#25112;&#65292;&#21407;&#22240;&#26159;GQL&#21644;SQL&#34920;&#36798;&#24335;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#19988;GQL&#23384;&#22312;&#22810;&#31181;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;NL2GQL&#20219;&#21153;&#20013;&#65292;&#26356;&#22823;&#30340;Foundation Models&#23637;&#31034;&#20102;&#20248;&#36234;&#30340;&#36328;&#27169;&#24335;&#36890;&#29992;&#33021;&#21147;&#65292;&#32780;&#36739;&#23567;&#30340;Foundation Models&#21017;&#36890;&#36807;&#24494;&#35843;&#38590;&#20197;&#25552;&#39640;&#20854;GQL&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#24494;&#35843;&#21518;&#65292;&#36739;&#23567;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24847;&#22270;&#29702;&#35299;&#21644;&#26356;&#39640;&#30340;&#35821;&#27861;&#20934;&#30830;&#24615;&#12290;&#19982;&#22522;&#20110;&#35268;&#21017;&#21644;&#27133;&#22635;&#20805;&#25216;&#26415;&#19981;&#21516;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;R3-NL2GQL&#65292;&#35813;&#26041;&#27861;&#23558;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;Foundation Models&#29992;&#20316;&#37325;&#26032;&#25490;&#21517;&#12289;&#37325;&#20889;&#21644;&#32454;&#21270;&#22120;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#36739;&#23567;&#27169;&#22411;&#30340;&#29702;&#35299;&#33021;&#21147;&#36827;&#34892;&#20449;&#24687;&#30340;&#37325;&#26032;&#25490;&#21517;&#21644;&#37325;&#20889;&#65292;&#24182;&#21033;&#29992;&#21331;&#36234;&#30340;&#36890;&#29992;&#21270;&#21644;&#29983;&#25104;&#33021;&#21147;&#36827;&#34892;&#32454;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
While current NL2SQL tasks constructed using Foundation Models have achieved commendable results, their direct application to Natural Language to Graph Query Language (NL2GQL) tasks poses challenges due to the significant differences between GQL and SQL expressions, as well as the numerous types of GQL. Our extensive experiments reveal that in NL2GQL tasks, larger Foundation Models demonstrate superior cross-schema generalization abilities, while smaller Foundation Models struggle to improve their GQL generation capabilities through fine-tuning. However, after fine-tuning, smaller models exhibit better intent comprehension and higher grammatical accuracy. Diverging from rule-based and slot-filling techniques, we introduce R3-NL2GQL, which employs both smaller and larger Foundation Models as reranker, rewriter and refiner. The approach harnesses the comprehension ability of smaller models for information reranker and rewriter, and the exceptional generalization and generation capabiliti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;ConfAIde&#22522;&#20934;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#19978;&#19979;&#25991;&#38544;&#31169;&#25512;&#29702;&#33021;&#21147;&#20013;&#30340;&#37325;&#35201;&#24369;&#28857;&#65292;&#23454;&#39564;&#35777;&#26126;&#21363;&#20351;&#26159;&#26368;&#24378;&#22823;&#30340;&#27169;&#22411;&#20063;&#20250;&#22312;&#20154;&#31867;&#19981;&#20250;&#30340;&#19978;&#19979;&#25991;&#20013;&#27844;&#38706;&#31169;&#20154;&#20449;&#24687;&#65292;&#24378;&#35843;&#20102;&#25506;&#32034;&#26032;&#22411;&#25512;&#29702;&#26102;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.17884</link><description>&lt;p&gt;
LLM&#33021;&#20445;&#23432;&#31192;&#23494;&#21527;&#65311;&#36890;&#36807;&#19978;&#19979;&#25991;&#23436;&#25972;&#24615;&#29702;&#35770;&#27979;&#35797;&#35821;&#35328;&#27169;&#22411;&#30340;&#38544;&#31169;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory. (arXiv:2310.17884v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;ConfAIde&#22522;&#20934;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#19978;&#19979;&#25991;&#38544;&#31169;&#25512;&#29702;&#33021;&#21147;&#20013;&#30340;&#37325;&#35201;&#24369;&#28857;&#65292;&#23454;&#39564;&#35777;&#26126;&#21363;&#20351;&#26159;&#26368;&#24378;&#22823;&#30340;&#27169;&#22411;&#20063;&#20250;&#22312;&#20154;&#31867;&#19981;&#20250;&#30340;&#19978;&#19979;&#25991;&#20013;&#27844;&#38706;&#31169;&#20154;&#20449;&#24687;&#65292;&#24378;&#35843;&#20102;&#25506;&#32034;&#26032;&#22411;&#25512;&#29702;&#26102;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;AI&#21161;&#25163;&#65288;&#24037;&#20316;&#12289;&#23478;&#24237;&#31561;&#65289;&#20013;&#20132;&#20114;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#25512;&#29702;&#26102;&#38544;&#31169;&#39118;&#38505;&#65306;LLMs&#20174;&#22810;&#20010;&#26469;&#28304;&#30340;&#36755;&#20837;&#20013;&#33719;&#21462;&#19981;&#21516;&#31867;&#22411;&#30340;&#20449;&#24687;&#65292;&#24182;&#26399;&#26395;&#22312;&#32473;&#23450;&#30340;&#19978;&#19979;&#25991;&#20013;&#25512;&#29702;&#20986;&#22312;&#20309;&#31181;&#30446;&#30340;&#21644;&#19982;&#35841;&#20998;&#20139;&#30340;&#20869;&#23481;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;ConfAIde&#65292;&#19968;&#20010;&#26088;&#22312;&#35782;&#21035;&#25351;&#20196;&#35843;&#25972;&#30340;LLMs&#38544;&#31169;&#25512;&#29702;&#33021;&#21147;&#20013;&#37325;&#35201;&#24369;&#28857;&#30340;&#22522;&#20934;&#65292;&#26469;&#24341;&#36215;&#20154;&#20204;&#23545;&#19978;&#19979;&#25991;&#38544;&#31169;&#36825;&#19968;&#26497;&#20854;&#20851;&#38190;&#20294;&#32463;&#24120;&#34987;&#24573;&#35270;&#30340;&#27010;&#24565;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#21363;&#20351;&#26159;GPT-4&#21644;ChatGPT&#31561;&#26368;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#22312;&#20154;&#31867;&#19981;&#20250;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#20063;&#20250;&#27844;&#38706;39&#65285;&#21644;57&#65285;&#30340;&#31169;&#20154;&#20449;&#24687;&#12290;&#21363;&#20351;&#25105;&#20204;&#20351;&#29992;&#20445;&#25252;&#38544;&#31169;&#30340;&#25552;&#31034;&#25110;&#24605;&#32500;&#38142;&#25512;&#29702;&#65292;&#36825;&#31181;&#27844;&#28431;&#20063;&#20250;&#25345;&#32493;&#23384;&#22312;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#36843;&#20999;&#38656;&#35201;&#25506;&#32034;&#22522;&#20110;&#25512;&#29702;&#21644;&#29702;&#35770;&#30340;&#26032;&#22411;&#25512;&#29702;&#26102;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#38899;&#39057;&#22686;&#24378;&#20026;&#20302;&#36164;&#28304;&#33258;&#25105;&#30417;&#30563;&#35821;&#38899;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#32508;&#21512;&#22686;&#24378;&#65288;&#22122;&#22768;/&#38899;&#39640;&#65289;&#26159;&#26368;&#20339;&#30340;&#22686;&#24378;&#31574;&#30053;&#65292;&#36229;&#36807;&#20102;&#37325;&#38899;&#21644;&#35821;&#35328;&#30693;&#35782;&#36716;&#31227;&#12290;</title><link>http://arxiv.org/abs/2309.12763</link><description>&lt;p&gt;
&#20943;&#23569;&#12289;&#22797;&#29992;&#12289;&#22238;&#25910;&#65306;&#19982;&#20854;&#20182;&#35821;&#35328;&#22686;&#24378;&#30456;&#27604;&#65292;&#34987;&#25200;&#21160;&#25968;&#25454;&#23545;&#20302;&#36164;&#28304;&#33258;&#25105;&#30417;&#30563;&#35821;&#38899;&#27169;&#22411;&#26356;&#22909;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Reduce, Reuse, Recycle: Is Perturbed Data better than Other Language augmentation for Low Resource Self-Supervised Speech Models. (arXiv:2309.12763v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12763
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#38899;&#39057;&#22686;&#24378;&#20026;&#20302;&#36164;&#28304;&#33258;&#25105;&#30417;&#30563;&#35821;&#38899;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#32508;&#21512;&#22686;&#24378;&#65288;&#22122;&#22768;/&#38899;&#39640;&#65289;&#26159;&#26368;&#20339;&#30340;&#22686;&#24378;&#31574;&#30053;&#65292;&#36229;&#36807;&#20102;&#37325;&#38899;&#21644;&#35821;&#35328;&#30693;&#35782;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#65288;SSRL&#65289;&#24050;&#32463;&#25913;&#21892;&#20102;&#19979;&#28216;&#38899;&#32032;&#35782;&#21035;&#30340;&#24615;&#33021;&#65292;&#30456;&#23545;&#20110;&#21463;&#30417;&#30563;&#30340;&#27169;&#22411;&#12290;&#35757;&#32451;SSRL&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#23545;&#20110;&#20302;&#36164;&#28304;&#35821;&#35328;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#19968;&#31181;&#24120;&#29992;&#30340;&#26041;&#27861;&#26159;&#20174;&#20854;&#20182;&#35821;&#35328;&#20013;&#36716;&#31227;&#30693;&#35782;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#38899;&#39057;&#22686;&#24378;&#22312;&#20302;&#36164;&#28304;&#26465;&#20214;&#19979;&#39044;&#35757;&#32451;SSRL&#27169;&#22411;&#65292;&#24182;&#35780;&#20272;&#19979;&#28216;&#20219;&#21153;&#30340;&#38899;&#32032;&#35782;&#21035;&#12290;&#25105;&#20204;&#23545;&#22686;&#24378;&#25216;&#26415;&#36827;&#34892;&#20102;&#31995;&#32479;&#27604;&#36739;&#65292;&#21253;&#25324;&#38899;&#39640;&#21464;&#21270;&#12289;&#22122;&#22768;&#28155;&#21152;&#12289;&#26377;&#37325;&#38899;&#30340;&#30446;&#26631;&#35821;&#38899;&#21644;&#20854;&#20182;&#35821;&#35328;&#30340;&#35821;&#38899;&#12290;&#25105;&#20204;&#21457;&#29616;&#32508;&#21512;&#22686;&#24378;&#65288;&#22122;&#22768;/&#38899;&#39640;&#65289;&#26159;&#26368;&#22909;&#30340;&#22686;&#24378;&#31574;&#30053;&#65292;&#36229;&#36807;&#20102;&#37325;&#38899;&#21644;&#35821;&#35328;&#30693;&#35782;&#36716;&#31227;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#19981;&#21516;&#25968;&#37327;&#21644;&#31867;&#22411;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#32771;&#23519;&#20102;&#22686;&#24378;&#25968;&#25454;&#30340;&#32553;&#25918;&#22240;&#23376;&#65292;&#20197;&#36798;&#21040;&#19982;&#39044;&#35757;&#32451;&#30446;&#26631;&#22495;&#35821;&#38899;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Self-supervised representation learning (SSRL) has improved the performance on downstream phoneme recognition versus supervised models. Training SSRL models requires a large amount of pre-training data and this poses a challenge for low resource languages. A common approach is transferring knowledge from other languages. Instead, we propose to use audio augmentation to pre-train SSRL models in a low resource condition and evaluate phoneme recognition as downstream task. We performed a systematic comparison of augmentation techniques, namely: pitch variation, noise addition, accented target-language speech and other language speech. We found combined augmentations (noise/pitch) was the best augmentation strategy outperforming accent and language knowledge transfer. We compared the performance with various quantities and types of pre-training data. We examined the scaling factor of augmented data to achieve equivalent performance to models pre-trained with target domain speech. Our findi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26681;&#25454;&#36328;&#23398;&#31185;&#30740;&#31350;&#20013;&#24314;&#31435;&#30340;&#36947;&#24503;&#29702;&#35770;&#36827;&#34892;&#36947;&#24503;&#25512;&#29702;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#38754;&#20020;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.15399</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#26426;&#22120;&#20262;&#29702; - LLM&#33021;&#21542;&#36890;&#36807;&#36947;&#24503;&#29702;&#35770;&#36827;&#34892;&#36947;&#24503;&#25512;&#29702;&#65311;
&lt;/p&gt;
&lt;p&gt;
Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?. (arXiv:2308.15399v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26681;&#25454;&#36328;&#23398;&#31185;&#30740;&#31350;&#20013;&#24314;&#31435;&#30340;&#36947;&#24503;&#29702;&#35770;&#36827;&#34892;&#36947;&#24503;&#25512;&#29702;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#38754;&#20020;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#34892;&#36947;&#24503;&#21028;&#26029;&#26159;&#21457;&#23637;&#20262;&#29702;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#22823;&#22810;&#25968;&#20197;&#33258;&#19979;&#32780;&#19978;&#30340;&#26041;&#24335;&#23454;&#26045;&#65292;&#36890;&#36807;&#20351;&#29992;&#22823;&#37327;&#30340;&#27880;&#37322;&#25968;&#25454;&#26469;&#35757;&#32451;&#22522;&#20110;&#20247;&#21253;&#24847;&#35265;&#30340;&#27169;&#22411;&#65292;&#26469;&#21028;&#26029;&#36947;&#24503;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#22240;&#28508;&#22312;&#36807;&#24230;&#26222;&#36941;&#21270;&#26377;&#38480;&#30340;&#27880;&#37322;&#32773;&#36947;&#24503;&#31435;&#22330;&#24182;&#19988;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#32780;&#21463;&#21040;&#25209;&#35780;&#12290;&#30456;&#21453;&#65292;&#33258;&#19978;&#32780;&#19979;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#19968;&#22871;&#21407;&#21017;&#36827;&#34892;&#36947;&#24503;&#21028;&#26029;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#23384;&#22312;&#38382;&#39064;&#65292;&#22240;&#20026;&#20043;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#26080;&#27861;&#32988;&#20219;&#65292;&#19988;&#36947;&#24503;&#21407;&#21017;&#20043;&#38388;&#23384;&#22312;&#26410;&#35299;&#20915;&#30340;&#36777;&#35770;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26681;&#25454;&#36328;&#23398;&#31185;&#30740;&#31350;&#20013;&#24314;&#31435;&#30340;&#36947;&#24503;&#29702;&#35770;&#36827;&#34892;&#36947;&#24503;&#25512;&#29702;&#12290;&#36825;&#20010;&#33258;&#19978;&#32780;&#19979;&#30340;&#29702;&#35770;&#24341;&#23548;&#26694;&#26550;&#21487;&#20197;&#34701;&#20837;&#21508;&#31181;&#36947;&#24503;&#29702;&#35770;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20010;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#22522;&#20110;&#36947;&#24503;&#29702;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Making moral judgments is an essential step toward developing ethical AI systems. Prevalent approaches are mostly implemented in a bottom-up manner, which uses a large set of annotated data to train models based on crowd-sourced opinions about morality. These approaches have been criticized for potentially overgeneralizing a limited group of annotators' moral stances and lacking explainability. In contrast, top-down approaches make moral judgments grounded in a set of principles. However, it remains conceptual due to the incapability of previous language models and the unsolved debate among moral principles. In this study, we propose a flexible framework to steer Large Language Models (LLMs) to perform moral reasoning with well-established moral theories from interdisciplinary research. The theory-guided top-down framework can incorporate various moral theories. Our experiments demonstrate the effectiveness of the proposed framework on datasets derived from moral theories. Furthermore,
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#23548;&#21521;&#35780;&#20272;&#22522;&#20934; (KoLA)&#65292;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#35748;&#30693;&#26500;&#24314;&#20102;&#22235;&#32423;&#30693;&#35782;&#30456;&#20851;&#33021;&#21147;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#20351;&#29992;&#32500;&#22522;&#30334;&#31185;&#21644;&#26032;&#20852;&#35821;&#26009;&#24211;&#36827;&#34892;&#35780;&#20272;&#12290;&#36825;&#20010;&#22522;&#20934;&#26088;&#22312;&#20840;&#38754;&#12289;&#20844;&#27491;&#21644;&#23454;&#29992;&#22320;&#35780;&#20272;LLM&#30340;&#33021;&#21147;&#65292;&#20197;&#22788;&#29702;&#26410;&#35265;&#25968;&#25454;&#21644;&#19981;&#26029;&#21457;&#23637;&#30340;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2306.09296</link><description>&lt;p&gt;
KoLA: &#35748;&#30495;&#22522;&#20934;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19990;&#30028;&#30693;&#35782;
&lt;/p&gt;
&lt;p&gt;
KoLA: Carefully Benchmarking World Knowledge of Large Language Models. (arXiv:2306.09296v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09296
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#23548;&#21521;&#35780;&#20272;&#22522;&#20934; (KoLA)&#65292;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#35748;&#30693;&#26500;&#24314;&#20102;&#22235;&#32423;&#30693;&#35782;&#30456;&#20851;&#33021;&#21147;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#20351;&#29992;&#32500;&#22522;&#30334;&#31185;&#21644;&#26032;&#20852;&#35821;&#26009;&#24211;&#36827;&#34892;&#35780;&#20272;&#12290;&#36825;&#20010;&#22522;&#20934;&#26088;&#22312;&#20840;&#38754;&#12289;&#20844;&#27491;&#21644;&#23454;&#29992;&#22320;&#35780;&#20272;LLM&#30340;&#33021;&#21147;&#65292;&#20197;&#22788;&#29702;&#26410;&#35265;&#25968;&#25454;&#21644;&#19981;&#26029;&#21457;&#23637;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLM) &#30340;&#21069;&#25152;&#26410;&#26377;&#30340;&#24615;&#33021;&#38656;&#35201;&#25913;&#36827;&#35780;&#20272;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#38500;&#20102;&#25506;&#32034;LLM&#33021;&#21147;&#30340;&#24191;&#24230;&#20043;&#22806;&#65292;&#32454;&#33268;&#21644;&#28145;&#24605;&#29087;&#34385;&#30340;&#35774;&#35745;&#23545;&#20110;&#20840;&#38754;&#12289;&#20844;&#27491;&#21644;&#23454;&#29992;&#30340;&#35780;&#20272;&#26159;&#24517;&#35201;&#30340;&#12290;&#37492;&#20110;&#20840;&#29699;&#30693;&#35782;&#23545;LLM&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#20197;&#30693;&#35782;&#20026;&#23548;&#21521;&#30340;LLM&#35780;&#20272;&#22522;&#20934;(KoLA)&#65292;&#20854;&#20013;&#25105;&#20204;&#31934;&#24515;&#35774;&#35745;&#20102;&#19977;&#20010;&#20851;&#38190;&#22240;&#32032;&#65306;(1) &#23545;&#20110;&#33021;&#21147;&#24314;&#27169;&#65292;&#25105;&#20204;&#27169;&#20223;&#20154;&#31867;&#35748;&#30693;&#26500;&#24314;&#20102;&#19968;&#20010;&#22235;&#32423;&#30693;&#35782;&#30456;&#20851;&#33021;&#21147;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#28085;&#30422;&#20102;19&#20010;&#20219;&#21153;&#12290;(2) &#23545;&#20110;&#25968;&#25454;&#65292;&#20026;&#20102;&#30830;&#20445;&#20844;&#27491;&#27604;&#36739;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#32500;&#22522;&#30334;&#31185;&#20316;&#20026;LLM&#26222;&#36941;&#39044;&#35757;&#32451;&#30340;&#35821;&#26009;&#24211;&#65292;&#21516;&#26102;&#36824;&#20351;&#29992;&#20102;&#25345;&#32493;&#25910;&#38598;&#30340;&#26032;&#20852;&#35821;&#26009;&#24211;&#65292;&#26088;&#22312;&#35780;&#20272;&#22788;&#29702;&#26410;&#35265;&#25968;&#25454;&#21644;&#19981;&#26029;&#21457;&#23637;&#30340;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;(3) &#23545;&#20110;&#35780;&#20272;&#26631;&#20934;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#23545;&#27604;&#31995;&#32479;&#65292;&#21253;&#25324;&#25972;&#20307;&#26631;&#20934;&#20998;&#25968;&#65292;&#20197;&#23454;&#29616;&#22312;&#20219;&#21153;&#21644;&#27169;&#22411;&#20043;&#38388;&#26356;&#22909;&#30340;&#25968;&#20540;&#27604;&#36739;&#24615;&#65292;&#20197;&#21450;&#29420;&#29305;&#30340;&#33258;&#23545;&#29031;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
The unprecedented performance of large language models (LLMs) necessitates improvements in evaluations. Rather than merely exploring the breadth of LLM abilities, we believe meticulous and thoughtful designs are essential to thorough, unbiased, and applicable evaluations. Given the importance of world knowledge to LLMs, we construct a Knowledge-oriented LLM Assessment benchmark (KoLA), in which we carefully design three crucial factors: (1) For ability modeling, we mimic human cognition to form a four-level taxonomy of knowledge-related abilities, covering $19$ tasks. (2) For data, to ensure fair comparisons, we use both Wikipedia, a corpus prevalently pre-trained by LLMs, along with continuously collected emerging corpora, aiming to evaluate the capacity to handle unseen data and evolving knowledge. (3) For evaluation criteria, we adopt a contrastive system, including overall standard scores for better numerical comparability across tasks and models and a unique self-contrast metric f
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#31995;&#32479;&#20013;&#23384;&#22312;&#29992;&#25143;&#29087;&#24713;&#24230;&#20559;&#35265;&#65292;&#32780;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#22330;&#26223;&#24456;&#23569;&#31526;&#21512;&#23553;&#38381;&#30446;&#26631;&#30340;&#35774;&#23450;&#12290;&#22240;&#27492;&#65292;&#22312;&#24320;&#25918;&#30446;&#26631;&#35774;&#32622;&#19979;&#65292;&#31995;&#32479;&#20250;&#20986;&#29616;&#20005;&#37325;&#38382;&#39064;&#65292;&#21516;&#26102;&#30740;&#31350;&#32773;&#21457;&#29616;&#20102;&#8220;&#19981;&#21305;&#37197;&#38169;&#35823;&#8221;&#36825;&#19968;&#26032;&#22411;&#38169;&#35823;&#31867;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.13857</link><description>&lt;p&gt;
&#36890;&#36807;&#20132;&#20114;&#24335;&#35780;&#20272;&#25581;&#31034;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#30340;&#29992;&#25143;&#29087;&#24713;&#24230;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Revealing User Familiarity Bias in Task-Oriented Dialogue via Interactive Evaluation. (arXiv:2305.13857v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#31995;&#32479;&#20013;&#23384;&#22312;&#29992;&#25143;&#29087;&#24713;&#24230;&#20559;&#35265;&#65292;&#32780;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#22330;&#26223;&#24456;&#23569;&#31526;&#21512;&#23553;&#38381;&#30446;&#26631;&#30340;&#35774;&#23450;&#12290;&#22240;&#27492;&#65292;&#22312;&#24320;&#25918;&#30446;&#26631;&#35774;&#32622;&#19979;&#65292;&#31995;&#32479;&#20250;&#20986;&#29616;&#20005;&#37325;&#38382;&#39064;&#65292;&#21516;&#26102;&#30740;&#31350;&#32773;&#21457;&#29616;&#20102;&#8220;&#19981;&#21305;&#37197;&#38169;&#35823;&#8221;&#36825;&#19968;&#26032;&#22411;&#38169;&#35823;&#31867;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;(TOD)&#22522;&#20934;&#20551;&#23450;&#29992;&#25143;&#31934;&#30830;&#22320;&#30693;&#36947;&#22914;&#20309;&#20351;&#29992;&#31995;&#32479;&#65292;&#36890;&#36807;&#23558;&#29992;&#25143;&#34892;&#20026;&#38480;&#21046;&#22312;&#31995;&#32479;&#30340;&#33021;&#21147;&#33539;&#22260;&#20869;&#65292;&#21363;&#8220;&#29992;&#25143;&#29087;&#24713;&#24230;&#8221;&#20559;&#35265;&#12290;&#24403;&#36825;&#31181;&#25968;&#25454;&#20559;&#35265;&#19982;&#25968;&#25454;&#39537;&#21160;&#30340;TOD&#31995;&#32479;&#30456;&#32467;&#21512;&#26102;&#65292;&#35813;&#20559;&#35265;&#21152;&#28145;&#20102;&#65292;&#22240;&#20026;&#20351;&#29992;&#29616;&#26377;&#30340;&#38745;&#24577;&#35780;&#20272;&#26080;&#27861;&#29702;&#35299;&#20854;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#20132;&#20114;&#24335;&#29992;&#25143;&#30740;&#31350;&#65292;&#25581;&#31034;TOD&#31995;&#32479;&#22312;&#30495;&#23454;&#22330;&#26223;&#19979;&#30340;&#33030;&#24369;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20855;&#26377;1&#65289;&#31526;&#21512;&#31995;&#32479;&#36793;&#30028;&#30340;&#35814;&#32454;&#30446;&#26631;&#35828;&#26126;&#65288;&#23553;&#38381;&#30446;&#26631;&#65289;&#21644;2&#65289;&#36890;&#24120;&#19981;&#21463;&#25903;&#25345;&#20294;&#29616;&#23454;&#65288;&#24320;&#25918;&#30446;&#26631;&#65289;&#30340;&#27169;&#31946;&#30446;&#26631;&#35828;&#26126;&#30340;&#29992;&#25143;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#24320;&#25918;&#30446;&#26631;&#35774;&#32622;&#19979;&#30340;&#23545;&#35805;&#20250;&#23548;&#33268;&#31995;&#32479;&#20005;&#37325;&#22833;&#36133;&#65292;92%&#30340;&#23545;&#35805;&#23384;&#22312;&#26174;&#33879;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#65292;&#36890;&#36807;&#38169;&#35823;&#27880;&#37322;&#35782;&#21035;&#20004;&#31181;&#35774;&#32622;&#20043;&#38388;&#30340;&#26174;&#33879;&#29305;&#24449;&#12290;&#20174;&#20013;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;&#38169;&#35823;&#31867;&#22411;&#31216;&#20026;&#8220;&#19981;&#21305;&#37197;&#38169;&#35823;&#8221;&#65292;&#36825;&#34920;&#26126;&#29992;&#25143;&#21644;&#31995;&#32479;&#26080;&#27861;&#24314;&#31435;&#20849;&#20139;&#30340;&#35821;&#22659;&#29702;&#35299;&#12290;&#26412;&#30740;&#31350;&#24378;&#35843;&#20102;&#22312;TOD&#35780;&#20272;&#20013;&#32771;&#34385;&#29992;&#25143;&#29087;&#24713;&#24230;&#20559;&#35265;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#24320;&#21457;&#26356;&#24378;&#22823;&#30340;&#31995;&#32479;&#26469;&#22788;&#29702;&#23454;&#38469;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most task-oriented dialogue (TOD) benchmarks assume users that know exactly how to use the system by constraining the user behaviors within the system's capabilities via strict user goals, namely "user familiarity" bias. This data bias deepens when it combines with data-driven TOD systems, as it is impossible to fathom the effect of it with existing static evaluations. Hence, we conduct an interactive user study to unveil how vulnerable TOD systems are against realistic scenarios. In particular, we compare users with 1) detailed goal instructions that conform to the system boundaries (closed-goal) and 2) vague goal instructions that are often unsupported but realistic (open-goal). Our study reveals that conversations in open-goal settings lead to catastrophic failures of the system, in which 92% of the dialogues had significant issues. Moreover, we conduct a thorough analysis to identify distinctive features between the two settings through error annotation. From this, we discover a no
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24037;&#19994;&#30028;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20013;&#30340;&#23384;&#22312;&#21644;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#36807;&#21435;&#20116;&#24180;&#20013;&#65292;&#24037;&#19994;&#30028;&#30340;&#23384;&#22312;&#19982;&#24433;&#21709;&#21576;&#29616;&#24613;&#21095;&#22686;&#38271;&#65292;&#19968;&#20123;&#20844;&#21496;&#21344;&#25454;&#20102;&#22823;&#37096;&#20998;&#20986;&#29256;&#29289;&#65292;&#24182;&#21521;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#36164;&#37329;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2305.02797</link><description>&lt;p&gt;
&#25151;&#38388;&#37324;&#30340;&#22823;&#35937;&#65306;&#20998;&#26512;&#22823;&#22411;&#31185;&#25216;&#20844;&#21496;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20013;&#30340;&#23384;&#22312;
&lt;/p&gt;
&lt;p&gt;
The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research. (arXiv:2305.02797v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24037;&#19994;&#30028;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20013;&#30340;&#23384;&#22312;&#21644;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#36807;&#21435;&#20116;&#24180;&#20013;&#65292;&#24037;&#19994;&#30028;&#30340;&#23384;&#22312;&#19982;&#24433;&#21709;&#21576;&#29616;&#24613;&#21095;&#22686;&#38271;&#65292;&#19968;&#20123;&#20844;&#21496;&#21344;&#25454;&#20102;&#22823;&#37096;&#20998;&#20986;&#29256;&#29289;&#65292;&#24182;&#21521;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#36164;&#37329;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21019;&#36896;&#20102;&#26032;&#30340;&#21830;&#19994;&#26426;&#20250;&#65292;&#24182;&#19988;&#20351;&#24471;NLP&#30740;&#31350;&#23545;&#20135;&#19994;&#21457;&#23637;&#33267;&#20851;&#37325;&#35201;&#12290;&#20316;&#20026;NLP&#39046;&#22495;&#30340;&#22823;&#29609;&#23478;&#20043;&#19968;&#65292;&#36830;&#21516;&#25919;&#24220;&#21644;&#22823;&#23398;&#19968;&#36215;&#65292;&#36319;&#36394;&#20135;&#19994;&#23545;&#30740;&#31350;&#30340;&#24433;&#21709;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#33268;&#21147;&#20110;&#37327;&#21270;&#21644;&#34920;&#24449;&#24037;&#19994;&#30028;&#22312;NLP&#31038;&#21306;&#20013;&#30340;&#23384;&#22312;&#12290;&#20351;&#29992;&#20855;&#26377;78,187&#31687;NLP&#20986;&#29256;&#29289;&#21644;701&#20010;NLP&#20316;&#32773;&#31616;&#21382;&#30340;&#20840;&#38754;&#20803;&#25968;&#25454;&#35821;&#26009;&#24211;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#33258;&#19978;&#19990;&#32426;90&#24180;&#20195;&#20197;&#26469;&#35813;&#39046;&#22495;&#20013;&#30340;&#24037;&#19994;&#23384;&#22312;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;NLP&#20316;&#32773;&#20013;&#30340;&#24037;&#19994;&#23384;&#22312;&#22312;&#36807;&#21435;&#20116;&#24180;&#20013;&#24613;&#21095;&#22686;&#38271;&#65288;&#20174;2017&#24180;&#21040;2022&#24180;&#30340;&#22686;&#38271;&#29575;&#20026;180&#65285;&#65289;&#12290;&#19968;&#20123;&#20844;&#21496;&#21344;&#25454;&#20102;&#22823;&#37096;&#20998;&#20986;&#29256;&#29289;&#65292;&#24182;&#36890;&#36807;&#25320;&#27454;&#21644;&#23454;&#20064;&#20026;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#36164;&#37329;&#25903;&#25345;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24037;&#19994;&#30028;&#23545;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#30340;&#23384;&#22312;&#21644;&#24433;&#21709;&#26159;&#26174;&#33879;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in deep learning methods for natural language processing (NLP) have created new business opportunities and made NLP research critical for industry development. As one of the big players in the field of NLP, together with governments and universities, it is important to track the influence of industry on research. In this study, we seek to quantify and characterize industry presence in the NLP community over time. Using a corpus with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP publication authors, we explore the industry presence in the field since the early 90s. We find that industry presence among NLP authors has been steady before a steep increase over the past five years (180% growth from 2017 to 2022). A few companies account for most of the publications and provide funding to academic researchers through grants and internships. Our study shows that the presence and impact of the industry on natural language processing research are signi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#27010;&#29575;&#30340;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25552;&#31034;&#26631;&#35760;&#25512;&#21521;&#24544;&#23454;&#25429;&#25417;&#26631;&#31614;&#29305;&#23450;&#30340;&#35270;&#35273;&#27010;&#24565;&#65292;&#32780;&#19981;&#26159;&#36807;&#24230;&#25311;&#21512;&#35757;&#32451;&#31867;&#21035;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#25552;&#31034;&#24037;&#31243;&#30340;&#38382;&#39064;&#12290;&#22312;&#21508;&#31181;&#35270;&#35273;&#35821;&#35328;&#20219;&#21153;&#19978;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.09100</link><description>&lt;p&gt;
&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#34917;&#19969;-&#20196;&#29260;&#23545;&#40784;&#30340;&#36125;&#21494;&#26031;&#25552;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models. (arXiv:2303.09100v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09100
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#27010;&#29575;&#30340;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25552;&#31034;&#26631;&#35760;&#25512;&#21521;&#24544;&#23454;&#25429;&#25417;&#26631;&#31614;&#29305;&#23450;&#30340;&#35270;&#35273;&#27010;&#24565;&#65292;&#32780;&#19981;&#26159;&#36807;&#24230;&#25311;&#21512;&#35757;&#32451;&#31867;&#21035;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#25552;&#31034;&#24037;&#31243;&#30340;&#38382;&#39064;&#12290;&#22312;&#21508;&#31181;&#35270;&#35273;&#35821;&#35328;&#20219;&#21153;&#19978;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35270;&#35273;&#35821;&#35328;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#19979;&#28216;&#24212;&#29992;&#20013;&#65292;&#26500;&#24314;&#26377;&#25928;&#25552;&#31034;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#29616;&#26377;&#30340;&#25552;&#31034;&#24037;&#31243;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#36153;&#26102;&#36153;&#21147;&#30340;&#25163;&#21160;&#35774;&#35745;&#65292;&#35201;&#20040;&#23558;&#25552;&#31034;&#35843;&#20248;&#20316;&#20026;&#28857;&#20272;&#35745;&#38382;&#39064;&#36827;&#34892;&#20248;&#21270;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#25551;&#36848;&#31867;&#21035;&#30340;&#22810;&#26679;&#29305;&#24449;&#24182;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#27010;&#29575;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#20013;&#36890;&#36807;&#20174;&#28508;&#22312;&#20998;&#24067;&#20013;&#39318;&#20808;&#37319;&#26679;&#38544;&#21521;&#37327;&#65292;&#28982;&#21518;&#37319;&#29992;&#36731;&#37327;&#32423;&#29983;&#25104;&#27169;&#22411;&#26469;&#29983;&#25104;&#26631;&#31614;&#29305;&#23450;&#30340;&#38543;&#26426;&#25552;&#31034;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23558;&#35270;&#35273;&#30693;&#35782;&#19982;&#22270;&#20687;&#30340;&#35821;&#20041;&#35268;&#21017;&#21270;&#65292;&#24182;&#23558;&#22270;&#20687;&#21644;&#30456;&#24212;&#30340;&#25552;&#31034;&#35270;&#20026;&#34917;&#19969;&#21644;&#20196;&#29260;&#38598;&#65292;&#36890;&#36807;&#26368;&#20248;&#20256;&#36755;&#23558;&#25552;&#31034;&#26631;&#35760;&#25512;&#21521;&#24544;&#23454;&#25429;&#25417;&#26631;&#31614;&#29305;&#23450;&#30340;&#35270;&#35273;&#27010;&#24565;&#65292;&#32780;&#19981;&#26159;&#36807;&#24230;&#25311;&#21512;&#35757;&#32451;&#31867;&#21035;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#36824;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#39069;&#22806;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#20449;&#24687;&#26469;&#29983;&#25104;&#26356;&#20855;&#20449;&#24687;&#37327;&#21644;&#20934;&#30830;&#24615;&#30340;&#25552;&#31034;&#12290;&#22312;&#21508;&#31181;&#35270;&#35273;&#35821;&#35328;&#20219;&#21153;&#19978;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#34917;&#19969;-&#20196;&#29260;&#23545;&#40784;&#30340;&#36125;&#21494;&#26031;&#25552;&#31034;&#23398;&#20064;&#65288;PTBPL&#65289;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts. Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications. We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model. Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories. Moreover, the proposed model can also be straightforwar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#34588;&#34562;&#31639;&#27861;&#20248;&#21270;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#65292;&#25552;&#39640;&#20102;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#26368;&#39640;&#20934;&#30830;&#29575;&#22312;&#33521;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;99.63%&#65292;&#22312;&#38463;&#25289;&#20271;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;88%&#12290;</title><link>http://arxiv.org/abs/2303.08021</link><description>&lt;p&gt;
&#29992;&#34588;&#34562;&#31639;&#27861;&#20248;&#21270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#65292;&#25552;&#39640;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimizing Deep Learning Model Parameters with the Bees Algorithm for Improved Medical Text Classification. (arXiv:2303.08021v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08021
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#34588;&#34562;&#31639;&#27861;&#20248;&#21270;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#65292;&#25552;&#39640;&#20102;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#26368;&#39640;&#20934;&#30830;&#29575;&#22312;&#33521;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;99.63%&#65292;&#22312;&#38463;&#25289;&#20271;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;88%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#34588;&#34562;&#31639;&#27861;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21442;&#25968;&#20248;&#21270;&#30340;&#26032;&#26426;&#21046;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#36817;&#24456;&#26377;&#21069;&#36884;&#30340;&#32676;&#26234;&#33021;&#31639;&#27861;&#12290;&#20248;&#21270;&#38382;&#39064;&#26159;&#22312;&#32473;&#23450;&#21021;&#22987;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#30830;&#23450;&#30340;&#36845;&#20195;&#27425;&#25968;&#26469;&#26368;&#22823;&#21270;&#22522;&#20110;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#30142;&#30149;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#21253;&#25324;&#20004;&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65306;&#33521;&#35821;&#21644;&#38463;&#25289;&#20271;&#35821;&#12290;&#20351;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518; (LSTM) &#21644;&#34588;&#34562;&#31639;&#27861;&#65292;&#22312;&#33521;&#35821;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#20102;99.63%&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#22312;&#38463;&#25289;&#20271;&#35821;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;AraBERT&#33719;&#24471;&#20102;88%&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel mechanism to obtain the optimal parameters of a deep learning model using the Bees Algorithm, which is a recent promising swarm intelligence algorithm. The optimization problem is to maximize the accuracy of classifying ailments based on medical text given the initial hyper-parameters to be adjusted throughout a definite number of iterations. Experiments included two different datasets: English and Arabic. The highest accuracy achieved is 99.63% on the English dataset using Long Short-Term Memory (LSTM) along with the Bees Algorithm, and 88% on the Arabic dataset using AraBERT.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#31867;&#37325;&#26032;&#21442;&#25968;&#21270;&#25216;&#24039;&#30340;&#22238;&#35793;&#31471;&#21040;&#31471;&#35757;&#32451;&#26041;&#27861;&#65292;&#26469;&#26377;&#25928;&#22320;&#20943;&#23569;&#20004;&#20010;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#38388;&#31163;&#25955;&#23646;&#24615;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#23454;&#29616;&#31471;&#21040;&#31471;&#24335;&#30340;&#35757;&#32451;&#65292;&#33719;&#24471;&#20102;&#27604;&#20197;&#21069;&#22522;&#20934;&#27979;&#35797;&#26356;&#22909;&#30340;BLEU&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2202.08465</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#31867;&#37325;&#26032;&#21442;&#25968;&#21270;&#25216;&#24039;&#30340;&#22238;&#35793;&#31471;&#21040;&#31471;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
End-to-End Training for Back-Translation with Categorical Reparameterization Trick. (arXiv:2202.08465v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.08465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#31867;&#37325;&#26032;&#21442;&#25968;&#21270;&#25216;&#24039;&#30340;&#22238;&#35793;&#31471;&#21040;&#31471;&#35757;&#32451;&#26041;&#27861;&#65292;&#26469;&#26377;&#25928;&#22320;&#20943;&#23569;&#20004;&#20010;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#38388;&#31163;&#25955;&#23646;&#24615;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#23454;&#29616;&#31471;&#21040;&#31471;&#24335;&#30340;&#35757;&#32451;&#65292;&#33719;&#24471;&#20102;&#27604;&#20197;&#21069;&#22522;&#20934;&#27979;&#35797;&#26356;&#22909;&#30340;BLEU&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#35793;&#26159;&#19968;&#31181;&#22312;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#20013;&#26377;&#25928;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#12290;&#39044;&#20808;&#35757;&#32451;&#30340;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#32763;&#35793;&#21333;&#35821;&#21477;&#23376;&#24182;&#29983;&#25104;&#21512;&#25104;&#30340;&#21452;&#35821;&#21477;&#23545;&#20197;&#35757;&#32451;&#21478;&#19968;&#20010;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#23558;&#20004;&#20010;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#20998;&#21035;&#29702;&#35299;&#20026;&#25512;&#29702;&#21644;&#29983;&#25104;&#27169;&#22411;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#37319;&#29992;&#20102;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#22521;&#35757;&#26694;&#26550;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#32763;&#35793;&#21477;&#23376;&#30340;&#31163;&#25955;&#23646;&#24615;&#20351;&#24471;&#26799;&#24230;&#20449;&#24687;&#26080;&#27861;&#22312;&#20004;&#20010;NMT&#27169;&#22411;&#20043;&#38388;&#27969;&#21160;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#37325;&#26032;&#21442;&#25968;&#21270;&#25216;&#24039;&#65292;&#20351;&#24471;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#21487;&#24494;&#20998;&#30340;&#21477;&#23376;&#65292;&#20351;&#24471;VAE&#30340;&#35757;&#32451;&#26694;&#26550;&#21487;&#20197;&#20197;&#31471;&#21040;&#31471;&#26041;&#24335;&#24037;&#20316;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#35757;&#32451;&#20102;NMT&#27169;&#22411;&#65292;&#24182;&#22312;WMT&#32763;&#35793;&#20219;&#21153;&#30340;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#27604;&#20197;&#21069;&#22522;&#20934;&#27979;&#35797;&#26356;&#22909;&#30340;BLEU&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Back-translation is an effective semi-supervised learning framework in neural machine translation (NMT). A pre-trained NMT model translates monolingual sentences and makes synthetic bilingual sentence pairs for the training of the other NMT model, and vice versa. Understanding the two NMT models as inference and generation models, respectively, previous works applied the training framework of variational auto-encoder (VAE). However, the discrete property of translated sentences prevents gradient information from flowing between the two NMT models. In this paper, we propose a categorical reparameterization trick that makes NMT models generate differentiable sentences so that the VAE's training framework can work in the end-to-end fashion. Our experiments demonstrate that our method effectively trains the NMT models and achieves better BLEU scores than the previous baseline on the datasets of the WMT translation task.
&lt;/p&gt;</description></item></channel></rss>