<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.01245</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#26694;&#26550;: &#26530;&#36724;&#12289;&#26816;&#27979;&#25928;&#29575;&#21644;&#26368;&#20248;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01245
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;ChatGPT&#20110;2022&#24180;11&#26376;&#25512;&#20986;&#20197;&#26469;&#65292;&#23558;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#30340;&#32479;&#35745;&#20449;&#21495;&#23884;&#20837;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#65292;&#20063;&#34987;&#31216;&#20026;&#27700;&#21360;&#65292;&#24050;&#34987;&#29992;&#20316;&#20174;&#20854;&#20154;&#31867;&#25776;&#20889;&#23545;&#24212;&#29289;&#19978;&#21487;&#35777;&#26816;&#27979;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290; &#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#29702;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#24182;&#35774;&#35745;&#24378;&#22823;&#30340;&#26816;&#27979;&#35268;&#21017;&#12290;&#21463;&#27700;&#21360;&#26816;&#27979;&#30340;&#20551;&#35774;&#26816;&#39564;&#20844;&#24335;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#39318;&#20808;&#36873;&#25321;&#25991;&#26412;&#30340;&#26530;&#36724;&#32479;&#35745;&#37327;&#21644;&#30001;LLM&#25552;&#20379;&#32473;&#39564;&#35777;&#22120;&#30340;&#31192;&#23494;&#23494;&#38053;&#65292;&#20197;&#23454;&#29616;&#25511;&#21046;&#35823;&#25253;&#29575;&#65288;&#23558;&#20154;&#31867;&#25776;&#20889;&#30340;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;LLM&#29983;&#25104;&#30340;&#38169;&#35823;&#65289;&#12290; &#25509;&#19979;&#26469;&#65292;&#35813;&#26694;&#26550;&#20801;&#35768;&#36890;&#36807;&#33719;&#21462;&#28176;&#36817;&#38169;&#35823;&#36127;&#29575;&#65288;&#23558;LLM&#29983;&#25104;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;&#20154;&#31867;&#25776;&#20889;&#30340;&#38169;&#35823;&#65289;&#30340;&#23553;&#38381;&#24418;&#24335;&#34920;&#36798;&#24335;&#26469;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01245v1 Announce Type: cross  Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22686;&#24378;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#65288;eRST&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#65288;RST&#65289;&#25299;&#23637;&#30340;&#35745;&#31639;&#35805;&#35821;&#20998;&#26512;&#30340;&#26032;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;RST&#21644;&#20854;&#20182;&#29616;&#26377;&#26694;&#26550;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#24037;&#20855;&#21644;&#33521;&#25991;&#35821;&#26009;&#24211;&#12290;</title><link>https://arxiv.org/abs/2403.13560</link><description>&lt;p&gt;
eRST&#65306;&#19968;&#31181;&#34920;&#24449;&#35805;&#35821;&#20851;&#31995;&#21644;&#32452;&#32455;&#30340;&#20449;&#21495;&#22270;&#35770;
&lt;/p&gt;
&lt;p&gt;
eRST: A Signaled Graph Theory of Discourse Relations and Organization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13560
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22686;&#24378;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#65288;eRST&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#65288;RST&#65289;&#25299;&#23637;&#30340;&#35745;&#31639;&#35805;&#35821;&#20998;&#26512;&#30340;&#26032;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;RST&#21644;&#20854;&#20182;&#29616;&#26377;&#26694;&#26550;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#24037;&#20855;&#21644;&#33521;&#25991;&#35821;&#26009;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22686;&#24378;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#65288;eRST&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#65288;RST&#65289;&#25299;&#23637;&#30340;&#35745;&#31639;&#35805;&#35821;&#20998;&#26512;&#30340;&#26032;&#29702;&#35770;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#20855;&#26377;&#26641;&#29366;&#25171;&#26029;&#12289;&#38750;&#25237;&#23556;&#21644;&#24182;&#21457;&#20851;&#31995;&#30340;&#35805;&#35821;&#20851;&#31995;&#22270;&#65292;&#20197;&#21450;&#32473;&#20986;&#25105;&#20204;&#20998;&#26512;&#35299;&#37322;&#24615;&#22522;&#30784;&#30340;&#38544;&#24335;&#21644;&#26174;&#24335;&#20449;&#21495;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;RST&#21644;&#20854;&#20182;&#29616;&#26377;&#26694;&#26550;&#65288;&#22914;&#20998;&#27573;&#35805;&#35821;&#34920;&#31034;&#29702;&#35770;&#65288;SDRT&#65289;&#12289;&#23486;&#22805;&#27861;&#23612;&#20122;&#35805;&#35821;&#26641;&#24211;&#65288;PDTB&#65289;&#21644;&#35805;&#35821;&#20381;&#36182;&#65289;&#30340;&#32570;&#38519;&#65292;&#24182;&#21033;&#29992;&#25152;&#25552;&#20986;&#30340;&#29702;&#35770;&#20013;&#30340;&#26500;&#24314;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#20026;&#25968;&#25454;&#25552;&#20379;&#20102;&#27880;&#37322;&#12289;&#25628;&#32034;&#21644;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#24182;&#25552;&#20379;&#21644;&#35780;&#20272;&#20102;&#19968;&#20010;&#26681;&#25454;&#25105;&#20204;&#30340;&#26694;&#26550;&#26631;&#27880;&#30340;&#33521;&#25991;&#35821;&#26009;&#24211;&#65292;&#21253;&#25324;12&#31181;&#21475;&#22836;&#21644;&#20070;&#38754;&#20307;&#35009;&#65292;&#28085;&#30422;&#20102;&#36229;&#36807;200K&#35789;&#20803;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#33258;&#21160;&#35299;&#26512;&#12289;&#35780;&#20272;&#24230;&#37327;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13560v1 Announce Type: new  Abstract: In this article we present Enhanced Rhetorical Structure Theory (eRST), a new theoretical framework for computational discourse analysis, based on an expansion of Rhetorical Structure Theory (RST). The framework encompasses discourse relation graphs with tree-breaking, nonprojective and concurrent relations, as well as implicit and explicit signals which give explainable rationales to our analyses. We survey shortcomings of RST and other existing frameworks, such as Segmented Discourse Representation Theory (SDRT), the Penn Discourse Treebank (PDTB) and Discourse Dependencies, and address these using constructs in the proposed theory. We provide annotation, search and visualization tools for data, and present and evaluate a freely available corpus of English annotated according to our framework, encompassing 12 spoken and written genres with over 200K tokens. Finally, we discuss automatic parsing, evaluation metrics and applications for 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20915;&#31574;&#24863;&#30693;&#21644;&#21487;&#27867;&#21270;&#30340;&#24037;&#20855;&#20351;&#29992;&#26694;&#26550;&#65292;&#20197;&#24110;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25805;&#20316;&#24037;&#20855;&#26102;&#25552;&#39640;&#28789;&#27963;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;</title><link>https://arxiv.org/abs/2402.16696</link><description>&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23457;&#24910;&#34892;&#20107;&#65306;&#36808;&#21521;&#20915;&#31574;&#24863;&#30693;&#21644;&#21487;&#27867;&#21270;&#30340;&#24037;&#20855;&#20351;&#29992;
&lt;/p&gt;
&lt;p&gt;
Look Before You Leap: Towards Decision-Aware and Generalizable Tool-Usage for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16696
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20915;&#31574;&#24863;&#30693;&#21644;&#21487;&#27867;&#21270;&#30340;&#24037;&#20855;&#20351;&#29992;&#26694;&#26550;&#65292;&#20197;&#24110;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25805;&#20316;&#24037;&#20855;&#26102;&#25552;&#39640;&#28789;&#27963;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#20855;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#33719;&#21462;&#26368;&#26032;&#30693;&#35782;&#21644;&#32531;&#35299;&#20135;&#29983;&#24187;&#35273;&#38382;&#39064;&#26041;&#38754;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#24403;&#21069;&#65292;&#20808;&#36827;&#30340;&#38381;&#28304;LLM&#65288;&#22914;ChatGPT&#65289;&#36890;&#36807;&#25552;&#31034;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#25216;&#26415;&#23637;&#31034;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#24037;&#20855;&#20351;&#29992;&#33021;&#21147;&#12290;&#20026;&#20102;&#22686;&#24378;&#24320;&#28304;LLM&#65288;&#22914;LLaMA&#65289;&#22312;&#25805;&#20316;&#24037;&#20855;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24403;&#21069;&#30340;&#21162;&#21147;&#38598;&#20013;&#20110;&#22522;&#20110;&#27169;&#26495;&#39537;&#21160;&#25110;&#22522;&#20110;&#26631;&#35760;&#35302;&#21457;&#30340;&#24037;&#20855;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#21069;&#32773;&#30001;&#20110;&#21463;&#21040;&#38480;&#21046;&#30340;&#24037;&#20855;&#20132;&#20114;&#65292;&#38480;&#21046;&#20102;LLM&#28789;&#27963;&#22320;&#35299;&#20915;&#21508;&#31181;&#29992;&#25143;&#26597;&#35810;&#65292;&#32780;&#21518;&#32773;&#22312;&#20351;&#29992;&#26032;&#24037;&#20855;&#26102;&#38480;&#21046;&#20102;&#27867;&#21270;&#33021;&#21147;&#65292;&#22240;&#20026;&#24037;&#20855;&#20351;&#29992;&#23398;&#20064;&#22522;&#20110;&#20219;&#21153;&#21644;&#24037;&#20855;&#29305;&#23450;&#30340;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20915;&#31574;&#24863;&#30693;&#21644;&#21487;&#27867;&#21270;&#30340;&#24037;&#20855;&#20351;&#29992;&#26694;&#26550;&#65288;DEER&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#26500;&#24314;&#20855;&#26377;&#22810;&#20010;&#20915;&#31574;&#20998;&#25903;&#30340;&#24037;&#20855;&#20351;&#29992;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16696v1 Announce Type: new  Abstract: Tool-augmented large language models (LLMs) are attracting widespread attention when accessing up-to-date knowledge and alleviating hallucination issues. Nowadays, advanced closed-source LLMs (e.g., ChatGPT) have demonstrated surprising tool-usage capabilities through prompting and in-context learning techniques. To empower the capabilities of open-source LLMs (e.g., LLaMA) in manipulating tools, current efforts focus on either template-driven or token-triggered tool-usage. However, the former hampers LLMs' flexibility to address diverse user's queries due to constrained tool interactions, while the latter limits the generalizability when engaging with new tools, since tool-usage learning is based on task- and tool-specific datasets. To alleviate these concerns, in this paper, we propose a decision-aware and generalizable tool-usage framework (DEER). Specifically, we first construct the tool-usage samples with multiple decision branches 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30740;&#31350;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20010;&#20154;&#20215;&#20540;&#22312;&#19981;&#21516;&#32972;&#26223;&#19979;&#30340;&#34920;&#36798;&#31283;&#23450;&#24615;&#65292;&#36890;&#36807;&#27169;&#25311;&#23545;&#35805;&#30340;&#26041;&#24335;&#36827;&#34892;&#35780;&#20272;&#65292;&#23545;19&#20010;LLMs&#36827;&#34892;&#27604;&#36739;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2402.14846</link><description>&lt;p&gt;
&#22362;&#25345;&#20320;&#30340;&#35282;&#33394;&#65281;&#20010;&#20154;&#20215;&#20540;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Stick to your Role! Stability of Personal Values Expressed in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30740;&#31350;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20010;&#20154;&#20215;&#20540;&#22312;&#19981;&#21516;&#32972;&#26223;&#19979;&#30340;&#34920;&#36798;&#31283;&#23450;&#24615;&#65292;&#36890;&#36807;&#27169;&#25311;&#23545;&#35805;&#30340;&#26041;&#24335;&#36827;&#34892;&#35780;&#20272;&#65292;&#23545;19&#20010;LLMs&#36827;&#34892;&#27604;&#36739;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#25110;&#24515;&#29702;&#38382;&#21367;&#30340;&#26631;&#20934;&#26041;&#24335;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26159;&#25552;&#20379;&#35768;&#22810;&#26469;&#28304;&#20110;&#31867;&#20284;&#26368;&#23567;&#32972;&#26223;&#30340;&#19981;&#21516;&#26597;&#35810;&#65288;&#20363;&#22914;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;&#65289;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLM&#39640;&#24230;&#20381;&#36182;&#20110;&#32972;&#26223;&#65292;&#22240;&#27492;&#20174;&#36825;&#31181;&#26368;&#23567;&#32972;&#26223;&#35780;&#20272;&#20013;&#24471;&#20986;&#30340;&#32467;&#35770;&#21487;&#33021;&#23545;&#27169;&#22411;&#22312;&#37096;&#32626;&#20013;&#30340;&#34892;&#20026;&#65288;&#22312;&#37027;&#37324;&#23427;&#23558;&#26292;&#38706;&#20110;&#35768;&#22810;&#26032;&#32972;&#26223;&#65289;&#30340;&#35828;&#26126;&#24456;&#23569;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20381;&#36182;&#20110;&#32972;&#26223;&#30340;&#29305;&#24615;&#24212;&#35813;&#20316;&#20026;LLM&#27604;&#36739;&#30340;&#21478;&#19968;&#20010;&#32500;&#24230;&#26469;&#30740;&#31350;&#65292;&#32780;&#19981;&#26159;&#20854;&#20182;&#32500;&#24230;&#65292;&#22914;&#35748;&#30693;&#33021;&#21147;&#12289;&#30693;&#35782;&#25110;&#27169;&#22411;&#22823;&#23567;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#22312;&#19981;&#21516;&#32972;&#26223;&#19979;&#65288;&#27169;&#25311;&#23545;&#19981;&#21516;&#35805;&#39064;&#30340;&#23545;&#35805;&#65289;&#20215;&#20540;&#34920;&#36798;&#31283;&#23450;&#24615;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#24182;&#20351;&#29992;&#26631;&#20934;&#24515;&#29702;&#23398;&#38382;&#21367;&#65288;PVQ&#65289;&#21644;&#34892;&#20026;&#19979;&#28216;&#20219;&#21153;&#36827;&#34892;&#27979;&#37327;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#26469;&#33258;&#20116;&#20010;&#23478;&#26063;&#30340;19&#20010;&#24320;&#28304;LLM&#12290;&#20511;&#37492;&#24515;&#29702;&#23398;&#26041;&#27861;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#31561;&#32423;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14846v1 Announce Type: cross  Abstract: The standard way to study Large Language Models (LLMs) through benchmarks or psychology questionnaires is to provide many different queries from similar minimal contexts (e.g. multiple choice questions). However, due to LLM's highly context-dependent nature, conclusions from such minimal-context evaluations may be little informative about the model's behavior in deployment (where it will be exposed to many new contexts). We argue that context-dependence should be studied as another dimension of LLM comparison alongside others such as cognitive abilities, knowledge, or model size. In this paper, we present a case-study about the stability of value expression over different contexts (simulated conversations on different topics), and as measured using a standard psychology questionnaire (PVQ) and a behavioral downstream task. We consider 19 open-sourced LLMs from five families. Reusing methods from psychology, we study Rank-order stabilit
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#20116;&#20010;&#20027;&#35201;&#31867;&#21035;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;48&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#31995;&#32479;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#20123;&#8220;&#39640;&#24433;&#21709;&#25968;&#25454;&#8221;&#65292;&#22914;&#20070;&#31821;&#65292;&#19982;&#27169;&#22411;&#33021;&#21147;&#30456;&#20851;&#32852;&#65292;&#20026;LLMs&#30340;&#20248;&#21270;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.11537</link><description>&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#21435;&#23398;&#20064;&#30740;&#31350;&#39044;&#35757;&#32451;&#25968;&#25454;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Deciphering the lmpact of Pretraining Data on Large Language Models through Machine Unlearning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11537
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#20116;&#20010;&#20027;&#35201;&#31867;&#21035;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;48&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#31995;&#32479;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#20123;&#8220;&#39640;&#24433;&#21709;&#25968;&#25454;&#8221;&#65292;&#22914;&#20070;&#31821;&#65292;&#19982;&#27169;&#22411;&#33021;&#21147;&#30456;&#20851;&#32852;&#65292;&#20026;LLMs&#30340;&#20248;&#21270;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#20855;&#26377;&#21508;&#31181;&#26469;&#28304;&#30340;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#30340;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#24433;&#21709;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#22240;&#27492;&#65292;&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#30340;&#32452;&#32455;&#20173;&#28982;&#26159;&#32463;&#39564;&#24615;&#30340;&#65292;&#24182;&#19988;&#21487;&#33021;&#20559;&#31163;&#26368;&#20339;&#29366;&#24577;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#26469;&#33258;LLMs&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;5&#20010;&#20027;&#35201;&#31867;&#21035;&#30340;48&#20010;&#25968;&#25454;&#38598;&#30340;&#24433;&#21709;&#65292;&#24182;&#20351;&#29992;&#20851;&#20110;&#20061;&#20010;&#20027;&#35201;&#27169;&#22411;&#33021;&#21147;&#31867;&#21035;&#30340;&#22522;&#20934;&#26469;&#34913;&#37327;&#23427;&#20204;&#23545;LLMs&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#20851;&#20110;&#22810;&#20010;&#35821;&#26009;&#24211;&#23545;LLMs&#24615;&#33021;&#36129;&#29486;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#20197;&#21450;&#23427;&#20204;&#30340;&#32852;&#21512;&#24433;&#21709;&#27169;&#24335;&#65292;&#21253;&#25324;&#20114;&#34917;&#30340;&#12289;&#27491;&#20132;&#30340;&#21644;&#30456;&#20851;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#19968;&#32452;&#8220;&#39640;&#24433;&#21709;&#25968;&#25454;&#8221;&#65292;&#22914;&#20070;&#31821;&#65292;&#19982;&#19968;&#32452;&#27169;&#22411;&#33021;&#21147;&#30456;&#20851;&#32852;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#32452;&#32455;&#25968;&#25454;&#20197;&#25903;&#25345;LLMs&#20248;&#21270;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11537v1 Announce Type: cross  Abstract: Through pretraining on a corpus with various sources, Large Language Models (LLMs) have gained impressive performance. However, the impact of each component of the pretraining corpus remains opaque. As a result, the organization of the pretraining corpus is still empirical and may deviate from the optimal. To address this issue, we systematically analyze the impact of 48 datasets from 5 major categories of pretraining data of LLMs and measure their impacts on LLMs using benchmarks about nine major categories of model capabilities. Our analyses provide empirical results about the contribution of multiple corpora on the performances of LLMs, along with their joint impact patterns, including complementary, orthogonal, and correlational relationships. We also identify a set of ``high-impact data'' such as Books that is significantly related to a set of model capabilities. These findings provide insights into the organization of data to sup
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#24230;&#37327;&#24544;&#23454;&#24615;&#30340;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#23558;&#23631;&#34109;&#20196;&#29260;&#20316;&#20026;&#35774;&#35745;&#20351;&#20854;&#25104;&#20026;&#20998;&#24067;&#20869;&#65292;&#20197;&#35299;&#20915;&#35299;&#37322;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#26102;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.07819</link><description>&lt;p&gt;
&#21487;&#24230;&#37327;&#24544;&#23454;&#24615;&#30340;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Faithfulness Measurable Masked Language Models. (arXiv:2310.07819v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#24230;&#37327;&#24544;&#23454;&#24615;&#30340;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#23558;&#23631;&#34109;&#20196;&#29260;&#20316;&#20026;&#35774;&#35745;&#20351;&#20854;&#25104;&#20026;&#20998;&#24067;&#20869;&#65292;&#20197;&#35299;&#20915;&#35299;&#37322;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#26102;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20351;&#29992;&#37325;&#35201;&#24615;&#24230;&#37327;&#26469;&#34920;&#36798;&#21738;&#20123;&#20196;&#29260;&#23545;&#20110;&#39044;&#27979;&#24456;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#36825;&#20123;&#35299;&#37322;&#20855;&#26377;&#35828;&#26381;&#21147;&#65292;&#20294;&#24448;&#24448;&#26159;&#38169;&#35823;&#30340;&#12290;&#22240;&#27492;&#65292;&#27979;&#37327;&#23427;&#20204;&#30340;&#24544;&#23454;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#20854;&#20013;&#19968;&#31181;&#24230;&#37327;&#26631;&#20934;&#26159;&#22914;&#26524;&#20196;&#29260;&#30830;&#23454;&#24456;&#37325;&#35201;&#65292;&#37027;&#20040;&#23631;&#34109;&#23427;&#20204;&#24212;&#35813;&#23548;&#33268;&#27169;&#22411;&#24615;&#33021;&#21464;&#24046;&#12290;&#28982;&#32780;&#65292;&#20196;&#29260;&#23631;&#34109;&#20250;&#24341;&#20837;&#21306;&#22495;&#22806;&#38382;&#39064;&#65292;&#32780;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#35745;&#31639;&#19978;&#24456;&#26114;&#36149;&#24182;&#19988;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20854;&#20182;&#25351;&#26631;&#30340;&#36866;&#29992;&#33539;&#22260;&#38750;&#24120;&#26377;&#38480;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22266;&#26377;&#30340;&#24544;&#23454;&#24615;&#21487;&#24230;&#37327;&#27169;&#22411;&#26469;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#35813;&#26041;&#27861;&#23558;&#23631;&#34109;&#20196;&#29260;&#20316;&#20026;&#35774;&#35745;&#20351;&#20854;&#25104;&#20026;&#20998;&#24067;&#20869;&#12290;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#29616;&#26377;&#26041;&#27861;&#23436;&#20840;&#19982;&#27169;&#22411;&#26080;&#20851;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#19981;&#36866;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common approach to explain NLP models, is to use importance measures that express which tokens are important for a prediction. Unfortunately, such explanations are often wrong despite being persuasive. Therefore, it is essential to measure their faithfulness. One such metric is if tokens are truly important, then masking them should result in worse model performance. However, token masking introduces out-of-distribution issues and existing solutions are computationally expensive and employ proxy-models. Furthermore, other metrics are very limited in scope. In this work, we propose an inherently faithfulness measurable model that addresses these challenges. This is achieved by using a novel fine-tuning method that incorporates masking, such that masking tokens become in-distribution by design. This differs from existing approaches, which are completely model-agnostic but are inapplicable in practice. We demonstrate the generality of our approach by applying it to various tasks and val
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;HC3 Plus&#65292;&#19968;&#20010;&#35821;&#20041;&#19981;&#21464;&#30340;&#20154;&#31867;ChatGPT&#23545;&#27604;&#35821;&#26009;&#24211;&#12290;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#35813;&#35821;&#26009;&#24211;&#32771;&#34385;&#20102;&#26356;&#22810;&#31867;&#22411;&#30340;&#20219;&#21153;&#65292;&#21253;&#25324;&#35821;&#20041;&#19981;&#21464;&#20219;&#21153;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#35821;&#20041;&#19981;&#21464;&#20219;&#21153;&#20013;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#26356;&#21152;&#22256;&#38590;&#12290;&#36890;&#36807;&#22823;&#37327;&#20219;&#21153;&#25351;&#20196;&#24494;&#35843;&#21644;Tk-instruct&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#26356;&#24378;&#22823;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.02731</link><description>&lt;p&gt;
HC3 Plus&#65306;&#19968;&#20010;&#35821;&#20041;&#19981;&#21464;&#30340;&#20154;&#31867;ChatGPT&#23545;&#27604;&#35821;&#26009;&#24211;
&lt;/p&gt;
&lt;p&gt;
HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus. (arXiv:2309.02731v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;HC3 Plus&#65292;&#19968;&#20010;&#35821;&#20041;&#19981;&#21464;&#30340;&#20154;&#31867;ChatGPT&#23545;&#27604;&#35821;&#26009;&#24211;&#12290;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#35813;&#35821;&#26009;&#24211;&#32771;&#34385;&#20102;&#26356;&#22810;&#31867;&#22411;&#30340;&#20219;&#21153;&#65292;&#21253;&#25324;&#35821;&#20041;&#19981;&#21464;&#20219;&#21153;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#35821;&#20041;&#19981;&#21464;&#20219;&#21153;&#20013;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#26356;&#21152;&#22256;&#38590;&#12290;&#36890;&#36807;&#22823;&#37327;&#20219;&#21153;&#25351;&#20196;&#24494;&#35843;&#21644;Tk-instruct&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#26356;&#24378;&#22823;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#22240;&#20854;&#20986;&#33394;&#30340;&#24615;&#33021;&#32780;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#20154;&#20204;&#23545;&#20854;&#28508;&#22312;&#39118;&#38505;&#65292;&#23588;&#20854;&#26159;&#23545;AI&#29983;&#25104;&#20869;&#23481;&#65288;AIGC&#65289;&#30340;&#26816;&#27979;&#36234;&#26469;&#36234;&#20851;&#27880;&#65292;&#36825;&#23545;&#26410;&#32463;&#35757;&#32451;&#30340;&#20154;&#31867;&#26469;&#35828;&#24448;&#24448;&#24456;&#38590;&#35782;&#21035;&#12290;&#30446;&#21069;&#29992;&#20110;&#26816;&#27979;ChatGPT&#29983;&#25104;&#25991;&#26412;&#30340;&#25968;&#25454;&#38598;&#20027;&#35201;&#38598;&#20013;&#22312;&#38382;&#31572;&#26041;&#38754;&#65292;&#20294;&#24448;&#24448;&#24573;&#35270;&#20102;&#20855;&#26377;&#35821;&#20041;&#19981;&#21464;&#24615;&#30340;&#20219;&#21153;&#65292;&#22914;&#25688;&#35201;&#12289;&#32763;&#35793;&#21644;&#25913;&#20889;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35821;&#20041;&#19981;&#21464;&#20219;&#21153;&#19978;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#26356;&#21152;&#22256;&#38590;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26356;&#24191;&#27867;&#12289;&#26356;&#20840;&#38754;&#30340;&#25968;&#25454;&#38598;&#65292;&#32771;&#34385;&#20102;&#27604;&#20197;&#21069;&#30340;&#24037;&#20316;&#26356;&#22810;&#31867;&#22411;&#30340;&#20219;&#21153;&#65292;&#21253;&#25324;&#35821;&#20041;&#19981;&#21464;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#32463;&#36807;&#22823;&#37327;&#20219;&#21153;&#25351;&#20196;&#24494;&#35843;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;&#22522;&#20110;&#20197;&#21069;&#30340;&#25104;&#21151;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25351;&#23548;&#24494;&#35843;&#20102;Tk-instruct&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#26356;&#24378;&#22823;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
ChatGPT has gained significant interest due to its impressive performance, but people are increasingly concerned about its potential risks, particularly around the detection of AI-generated content (AIGC), which is often difficult for untrained humans to identify. Current datasets utilized for detecting ChatGPT-generated text primarily center around question-answering, yet they tend to disregard tasks that possess semantic-invariant properties, such as summarization, translation, and paraphrasing. Our primary studies demonstrate that detecting model-generated text on semantic-invariant tasks is more difficult. To fill this gap, we introduce a more extensive and comprehensive dataset that considers more types of tasks than previous work, including semantic-invariant tasks. In addition, the model after a large number of task instruction fine-tuning shows a strong powerful performance. Owing to its previous success, we further instruct fine-tuning Tk-instruct and built a more powerful det
&lt;/p&gt;</description></item></channel></rss>