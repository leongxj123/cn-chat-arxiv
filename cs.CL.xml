<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#25805;&#20316;&#31995;&#32479;&#20013;&#30340;LLM&#20195;&#29702;&#25805;&#20316;&#31995;&#32479;&#65292;&#26088;&#22312;&#20248;&#21270;&#36164;&#28304;&#20998;&#37197;&#12289;&#20419;&#36827;&#20195;&#29702;&#38388;&#19978;&#19979;&#25991;&#20999;&#25442;&#12289;&#23454;&#29616;&#24182;&#21457;&#25191;&#34892;&#20197;&#21450;&#20026;&#20195;&#29702;&#25552;&#20379;&#24037;&#20855;&#26381;&#21153;&#12290;</title><link>https://arxiv.org/abs/2403.16971</link><description>&lt;p&gt;
LLM Agent Operating System
&lt;/p&gt;
&lt;p&gt;
LLM Agent Operating System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16971
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#25805;&#20316;&#31995;&#32479;&#20013;&#30340;LLM&#20195;&#29702;&#25805;&#20316;&#31995;&#32479;&#65292;&#26088;&#22312;&#20248;&#21270;&#36164;&#28304;&#20998;&#37197;&#12289;&#20419;&#36827;&#20195;&#29702;&#38388;&#19978;&#19979;&#25991;&#20999;&#25442;&#12289;&#23454;&#29616;&#24182;&#21457;&#25191;&#34892;&#20197;&#21450;&#20026;&#20195;&#29702;&#25552;&#20379;&#24037;&#20855;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16971v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#37096;&#32626;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26234;&#33021;&#20195;&#29702;&#23384;&#22312;&#35832;&#22810;&#25361;&#25112;&#65292;&#20250;&#25439;&#23475;&#23427;&#20204;&#30340;&#25928;&#29575;&#21644;&#21151;&#25928;&#12290;&#20854;&#20013;&#21253;&#25324;&#20195;&#29702;&#35831;&#27714;&#22312;LLM&#19978;&#30340;&#27425;&#20248;&#35843;&#24230;&#21644;&#36164;&#28304;&#20998;&#37197;&#12289;&#22312;&#20195;&#29702;&#21644;LLM&#20043;&#38388;&#20132;&#20114;&#26102;&#20445;&#25345;&#19978;&#19979;&#25991;&#30340;&#22256;&#38590;&#65292;&#20197;&#21450;&#23558;&#20855;&#26377;&#19981;&#21516;&#33021;&#21147;&#21644;&#19987;&#19994;&#21270;&#30340;&#24322;&#26500;&#20195;&#29702;&#38598;&#25104;&#22312;&#19968;&#36215;&#30340;&#22797;&#26434;&#24615;&#12290;&#20195;&#29702;&#25968;&#37327;&#21644;&#22797;&#26434;&#24615;&#30340;&#24555;&#36895;&#22686;&#21152;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#36890;&#24120;&#20250;&#23548;&#33268;&#36164;&#28304;&#29942;&#39048;&#21644;&#27425;&#20248;&#36164;&#28304;&#21033;&#29992;&#12290;&#21463;&#21040;&#36825;&#20123;&#25361;&#25112;&#30340;&#21551;&#21457;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;AIOS&#65292;&#19968;&#31181;LLM&#20195;&#29702;&#25805;&#20316;&#31995;&#32479;&#65292;&#23427;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#25805;&#20316;&#31995;&#32479;&#65288;OS&#65289;&#20013;&#12290;&#20855;&#20307;&#22320;&#65292;AIOS&#26088;&#22312;&#20248;&#21270;&#36164;&#28304;&#20998;&#37197;&#65292;&#20419;&#36827;&#20195;&#29702;&#20043;&#38388;&#30340;&#19978;&#19979;&#25991;&#20999;&#25442;&#65292;&#23454;&#29616;&#20195;&#29702;&#30340;&#24182;&#21457;&#25191;&#34892;&#65292;&#20026;&#20195;&#29702;&#25552;&#20379;&#24037;&#20855;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16971v1 Announce Type: cross  Abstract: The integration and deployment of large language model (LLM)-based intelligent agents have been fraught with challenges that compromise their efficiency and efficacy. Among these issues are sub-optimal scheduling and resource allocation of agent requests over the LLM, the difficulties in maintaining context during interactions between agent and LLM, and the complexities inherent in integrating heterogeneous agents with different capabilities and specializations. The rapid increase of agent quantity and complexity further exacerbates these issues, often leading to bottlenecks and sub-optimal utilization of resources. Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS). Specifically, AIOS is designed to optimize resource allocation, facilitate context switch across agents, enable concurrent execution of agents, provide tool service for agents
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;&#20013;&#24341;&#20837;&#20102;&#21452;&#23398;&#20064;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;DualAdapter&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#38754;&#21644;&#36127;&#38754;&#20004;&#26041;&#38754;&#30340;&#21452;&#36335;&#24452;&#36866;&#37197;&#65292;&#21516;&#26102;&#36827;&#34892;&#34917;&#20805;&#27491;&#21521;&#36873;&#25321;&#21644;&#36127;&#21521;&#25490;&#38500;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#25972;&#20307;&#35782;&#21035;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.12964</link><description>&lt;p&gt;
&#36127;&#24471;&#27491;&#65306;&#29992;&#20110;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#32479;&#19968;&#21452;&#36335;&#24452;&#36866;&#37197;&#22120;
&lt;/p&gt;
&lt;p&gt;
Negative Yields Positive: Unified Dual-Path Adapter for Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12964
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;&#20013;&#24341;&#20837;&#20102;&#21452;&#23398;&#20064;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;DualAdapter&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#38754;&#21644;&#36127;&#38754;&#20004;&#26041;&#38754;&#30340;&#21452;&#36335;&#24452;&#36866;&#37197;&#65292;&#21516;&#26102;&#36827;&#34892;&#34917;&#20805;&#27491;&#21521;&#36873;&#25321;&#21644;&#36127;&#21521;&#25490;&#38500;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#25972;&#20307;&#35782;&#21035;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#23637;&#31034;&#20102;&#23398;&#20064;&#24320;&#25918;&#19990;&#30028;&#35270;&#35273;&#34920;&#31034;&#26041;&#38754;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#24182;&#36890;&#36807;&#39640;&#25928;&#24494;&#35843;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21019;&#26032;&#22320;&#23558;&#21452;&#23398;&#20064;&#27010;&#24565;&#24341;&#20837;&#24494;&#35843;VLMs&#20013;&#65292;&#21363;&#25105;&#20204;&#19981;&#20165;&#23398;&#20064;&#22270;&#20687;&#26159;&#20160;&#20040;&#65292;&#36824;&#23398;&#20064;&#22270;&#20687;&#19981;&#26159;&#20160;&#20040;&#12290;&#22522;&#20110;&#36825;&#19968;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;DualAdapter&#26041;&#27861;&#65292;&#20351;VLMs&#33021;&#22815;&#20174;&#27491;&#38754;&#21644;&#36127;&#38754;&#20004;&#26041;&#38754;&#36827;&#34892;&#21452;&#36335;&#24452;&#36866;&#37197;&#65292;&#20165;&#20351;&#29992;&#26377;&#38480;&#30340;&#27880;&#37322;&#26679;&#26412;&#12290;&#22312;&#25512;&#29702;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;DualAdapter&#36890;&#36807;&#38024;&#23545;&#30446;&#26631;&#31867;&#21035;&#21516;&#26102;&#36827;&#34892;&#34917;&#20805;&#27491;&#21521;&#36873;&#25321;&#21644;&#36127;&#21521;&#25490;&#38500;&#65292;&#23454;&#29616;&#20102;&#32479;&#19968;&#39044;&#27979;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;VLMs&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#25972;&#20307;&#35782;&#21035;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#36328;&#36234;15&#20010;&#25968;&#25454;&#38598;&#65292;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;DualAda
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12964v1 Announce Type: cross  Abstract: Recently, large-scale pre-trained Vision-Language Models (VLMs) have demonstrated great potential in learning open-world visual representations, and exhibit remarkable performance across a wide range of downstream tasks through efficient fine-tuning. In this work, we innovatively introduce the concept of dual learning into fine-tuning VLMs, i.e., we not only learn what an image is, but also what an image isn't. Building on this concept, we introduce a novel DualAdapter approach to enable dual-path adaptation of VLMs from both positive and negative perspectives with only limited annotated samples. In the inference stage, our DualAdapter performs unified predictions by simultaneously conducting complementary positive selection and negative exclusion across target classes, thereby enhancing the overall recognition accuracy of VLMs in downstream tasks. Our extensive experimental results across 15 datasets validate that the proposed DualAda
&lt;/p&gt;</description></item><item><title>&#22823;&#22810;&#25968;&#29616;&#20195;LLM&#21463;&#21040;softmax&#29942;&#39048;&#24433;&#21709;&#65292;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#33719;&#21462;API&#20445;&#25252;&#30340;LLM&#30340;&#38750;&#20844;&#24320;&#20449;&#24687;&#21644;&#35299;&#38145;&#22810;&#31181;&#21151;&#33021;</title><link>https://arxiv.org/abs/2403.09539</link><description>&lt;p&gt;
API&#20445;&#25252;&#30340;LLMs&#30340;&#26631;&#24535;&#27844;&#38706;&#19987;&#26377;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Logits of API-Protected LLMs Leak Proprietary Information
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09539
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#20195;LLM&#21463;&#21040;softmax&#29942;&#39048;&#24433;&#21709;&#65292;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#33719;&#21462;API&#20445;&#25252;&#30340;LLM&#30340;&#38750;&#20844;&#24320;&#20449;&#24687;&#21644;&#35299;&#38145;&#22810;&#31181;&#21151;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21830;&#19994;&#21270;&#23548;&#33268;&#20102;&#39640;&#32423;API-only&#25509;&#20837;&#19987;&#26377;&#27169;&#22411;&#30340;&#24120;&#35265;&#23454;&#36341;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#23545;&#20110;&#27169;&#22411;&#26550;&#26500;&#26377;&#20445;&#23432;&#30340;&#20551;&#35774;&#65292;&#20063;&#21487;&#20197;&#20174;&#30456;&#23545;&#36739;&#23569;&#30340;API&#26597;&#35810;&#20013;&#23398;&#20064;&#20851;&#20110;API&#20445;&#25252;&#30340;LLM&#30340;&#22823;&#37327;&#38750;&#20844;&#24320;&#20449;&#24687;&#65288;&#20363;&#22914;&#65292;&#20351;&#29992;OpenAI&#30340;gpt-3.5-turbo&#20165;&#33457;&#36153;&#19981;&#21040;1000&#32654;&#20803;&#65289;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#38598;&#20013;&#22312;&#19968;&#20010;&#20851;&#38190;&#35266;&#23519;&#19978;&#65306;&#22823;&#22810;&#25968;&#29616;&#20195;LLM&#21463;&#21040;&#20102;softmax&#29942;&#39048;&#30340;&#24433;&#21709;&#65292;&#36825;&#38480;&#21046;&#20102;&#27169;&#22411;&#36755;&#20986;&#21040;&#23436;&#25972;&#36755;&#20986;&#31354;&#38388;&#30340;&#32447;&#24615;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#27169;&#22411;&#22270;&#20687;&#25110;&#27169;&#22411;&#31614;&#21517;&#65292;&#20174;&#32780;&#20197;&#36739;&#20302;&#30340;&#25104;&#26412;&#35299;&#38145;&#20102;&#20960;&#31181;&#21151;&#33021;&#65306;&#26377;&#25928;&#21457;&#29616;LLM&#30340;&#38544;&#34255;&#22823;&#23567;&#65292;&#33719;&#21462;&#23436;&#25972;&#35789;&#27719;&#36755;&#20986;&#65292;&#26816;&#27979;&#21644;&#28040;&#38500;&#19981;&#21516;&#27169;&#22411;&#26356;&#26032;&#65292;&#35782;&#21035;&#32473;&#23450;&#21333;&#20010;&#23436;&#25972;LLM&#36755;&#20986;&#30340;&#28304;LLM&#65292;&#20197;&#21450;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09539v1 Announce Type: cross  Abstract: The commercialization of large language models (LLMs) has led to the common practice of high-level API-only access to proprietary models. In this work, we show that even with a conservative assumption about the model architecture, it is possible to learn a surprisingly large amount of non-public information about an API-protected LLM from a relatively small number of API queries (e.g., costing under $1,000 for OpenAI's gpt-3.5-turbo). Our findings are centered on one key observation: most modern LLMs suffer from a softmax bottleneck, which restricts the model outputs to a linear subspace of the full output space. We show that this lends itself to a model image or a model signature which unlocks several capabilities with affordable cost: efficiently discovering the LLM's hidden size, obtaining full-vocabulary outputs, detecting and disambiguating different model updates, identifying the source LLM given a single full LLM output, and eve
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Curry-DPO&#30340;&#26041;&#27861;&#65292;&#22312;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#20013;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#20559;&#22909;&#23545;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#21333;&#19968;&#23545;DPO&#35774;&#32622;&#26377;&#30528;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2403.07230</link><description>&lt;p&gt;
Curry-DPO&#65306;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#21644;&#25490;&#21517;&#20559;&#22909;&#22686;&#24378;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Curry-DPO: Enhancing Alignment using Curriculum Learning &amp; Ranked Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07230
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Curry-DPO&#30340;&#26041;&#27861;&#65292;&#22312;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#20013;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#20559;&#22909;&#23545;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#21333;&#19968;&#23545;DPO&#35774;&#32622;&#26377;&#30528;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#25104;&#23545;&#20559;&#22909;&#25968;&#25454;(&#36890;&#24120;&#26159;&#27599;&#20010;&#29992;&#25143;&#25552;&#31034;&#36873;&#25321;&#21644;&#25298;&#32477;&#30340;&#21709;&#24212;&#23545;)&#23558;LLMs&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#23545;&#20110;&#32473;&#23450;&#25552;&#31034;&#21487;&#33021;&#20250;&#23384;&#22312;&#22810;&#20010;&#21709;&#24212;&#65292;&#36825;&#20123;&#21709;&#24212;&#30340;&#36136;&#37327;&#30456;&#23545;&#20110;&#24444;&#27492;&#32780;&#35328;&#26377;&#25152;&#19981;&#21516;&#12290;&#26377;&#20102;&#36825;&#20123;&#22810;&#20010;&#21709;&#24212;&#30340;&#36136;&#37327;&#35780;&#32423;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#36825;&#20123;&#21709;&#24212;&#20026;&#32473;&#23450;&#25552;&#31034;&#21019;&#24314;&#22810;&#20010;&#20559;&#22909;&#23545;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20391;&#37325;&#20110;&#36890;&#36807;&#35838;&#31243;&#23398;&#20064;&#26041;&#27861;&#31995;&#32479;&#22320;&#21033;&#29992;&#26500;&#24314;&#30340;&#22810;&#20010;&#20559;&#22909;&#23545;&#26469;&#36827;&#34892;DPO&#35757;&#32451;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#26681;&#25454;&#19981;&#21516;&#30340;&#26631;&#20934;&#23558;&#36825;&#20123;&#22810;&#20010;&#20559;&#22909;&#25968;&#25454;&#23545;&#20174;&#26131;&#21040;&#38590;(&#27169;&#25311;&#35838;&#31243;&#35757;&#32451;)&#25490;&#24207;&#12290;&#25105;&#20204;&#35814;&#32454;&#27604;&#36739;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#26631;&#20934;&#21333;&#19968;&#23545;DPO&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;Curry-DPO&#65292;&#22312;MTbench&#12289;Vicuna&#12289;Wiz&#19978;&#22987;&#32456;&#34920;&#29616;&#20986;&#22686;&#24378;&#30340;&#24615;&#33021;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07230v1 Announce Type: cross  Abstract: Direct Preference Optimization (DPO) is an effective technique that leverages pairwise preference data (usually one chosen and rejected response pair per user prompt) to align LLMs to human preferences. In practice, multiple responses can exist for a given prompt with varying quality relative to each other. With availability of such quality ratings for multiple responses, we propose utilizing these responses to create multiple preference pairs for a given prompt. Our work focuses on systematically using the constructed multiple preference pair in DPO training via curriculum learning methodology. In particular, we order these multiple pairs of preference data from easy to hard (emulating curriculum training) according to various criteria. We show detailed comparisons of our proposed approach to the standard single-pair DPO setting. Our method, which we call Curry-DPO consistently shows increased performance gains on MTbench, Vicuna, Wiz
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#25506;&#26597;&#37319;&#26679;&#8221;&#30340;&#26032;&#31639;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#30830;&#23450;&#33609;&#31295;&#27169;&#22411;&#21644;&#30446;&#26631;&#27169;&#22411;&#30340;&#30456;&#20284;&#24230;&#65292;&#26469;&#21152;&#36895;&#36138;&#23146;&#22352;&#26631;&#26799;&#24230;&#31639;&#27861;&#65292;&#23454;&#29616;&#39640;&#36798;5.6&#20493;&#30340;&#21152;&#36895;&#12290;</title><link>https://arxiv.org/abs/2403.01251</link><description>&lt;p&gt;
&#36890;&#36807;&#25506;&#26597;&#37319;&#26679;&#21152;&#36895;&#36138;&#23146;&#22352;&#26631;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Accelerating Greedy Coordinate Gradient via Probe Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01251
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#25506;&#26597;&#37319;&#26679;&#8221;&#30340;&#26032;&#31639;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#30830;&#23450;&#33609;&#31295;&#27169;&#22411;&#21644;&#30446;&#26631;&#27169;&#22411;&#30340;&#30456;&#20284;&#24230;&#65292;&#26469;&#21152;&#36895;&#36138;&#23146;&#22352;&#26631;&#26799;&#24230;&#31639;&#27861;&#65292;&#23454;&#29616;&#39640;&#36798;5.6&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#20013;&#24515;&#38382;&#39064;&#65292;&#32771;&#34385;&#21040;&#23427;&#20204;&#30340;&#24555;&#36895;&#21457;&#23637;&#21644;&#24191;&#27867;&#24212;&#29992;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#36138;&#23146;&#22352;&#26631;&#26799;&#24230;&#65288;GCG&#65289;&#22312;&#26500;&#24314;&#21253;&#21547;&#23545;&#25239;&#21518;&#32512;&#30340;&#25552;&#31034;&#26102;&#38750;&#24120;&#26377;&#25928;&#65292;&#20197;&#30772;&#22351;&#34987;&#35748;&#20026;&#26159;&#23433;&#20840;&#30340;LLMs&#65292;&#20294;GCG&#30340;&#20248;&#21270;&#32791;&#26102;&#36739;&#38271;&#65292;&#38480;&#21046;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;&#20026;&#20102;&#20943;&#23569;GCG&#30340;&#26102;&#38388;&#25104;&#26412;&#24182;&#23454;&#29616;&#23545;LLMs&#23433;&#20840;&#24615;&#26356;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#25506;&#26597;&#37319;&#26679;&#8221;&#30340;&#26032;&#31639;&#27861;&#65292;&#20197;&#21152;&#36895;GCG&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#26426;&#21046;&#65292;&#21160;&#24577;&#30830;&#23450;&#36739;&#23567;&#33609;&#31295;&#27169;&#22411;&#30340;&#39044;&#27979;&#19982;&#30446;&#26631;&#27169;&#22411;&#30340;&#25552;&#31034;&#20505;&#36873;&#39044;&#27979;&#30340;&#30456;&#20284;&#31243;&#24230;&#12290;&#24403;&#30446;&#26631;&#27169;&#22411;&#19982;&#33609;&#31295;&#27169;&#22411;&#30456;&#20284;&#26102;&#65292;&#25105;&#20204;&#22823;&#37327;&#20381;&#36182;&#20110;&#33609;&#31295;&#27169;&#22411;&#26469;&#36807;&#28388;&#22823;&#37327;&#28508;&#22312;&#25552;&#31034;&#20505;&#36873;&#65292;&#20197;&#20943;&#23569;&#35745;&#31639;&#26102;&#38388;&#12290;&#25506;&#26597;&#37319;&#26679;&#20351;&#29992;Llam&#23454;&#29616;&#39640;&#36798;5.6&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01251v1 Announce Type: new  Abstract: Safety of Large Language Models (LLMs) has become a central issue given their rapid progress and wide applications. Greedy Coordinate Gradient (GCG) is shown to be effective in constructing prompts containing adversarial suffixes to break the presumingly safe LLMs, but the optimization of GCG is time-consuming and limits its practicality. To reduce the time cost of GCG and enable more comprehensive studies of LLM safety, in this work, we study a new algorithm called $\texttt{Probe sampling}$ to accelerate the GCG algorithm. At the core of the algorithm is a mechanism that dynamically determines how similar a smaller draft model's predictions are to the target model's predictions for prompt candidates. When the target model is similar to the draft model, we rely heavily on the draft model to filter out a large number of potential prompt candidates to reduce the computation time. Probe sampling achieves up to $5.6$ times speedup using Llam
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#36328;&#35821;&#35328;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#22312;&#20302;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#20013;&#23454;&#29616;&#24773;&#24863;&#20998;&#31867;&#65292;&#23637;&#31034;&#20102;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.18424</link><description>&lt;p&gt;
&#20302;&#36164;&#28304;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#20013;&#30340;&#24773;&#24863;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Emotion Classification in Low and Moderate Resource Languages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18424
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36328;&#35821;&#35328;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#22312;&#20302;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#20013;&#23454;&#29616;&#24773;&#24863;&#20998;&#31867;&#65292;&#23637;&#31034;&#20102;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#20998;&#26512;&#20840;&#29699;&#33539;&#22260;&#20869;&#20154;&#20204;&#24773;&#32490;&#29366;&#24577;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#20840;&#29699;&#26377;7100&#22810;&#31181;&#27963;&#36291;&#35821;&#35328;&#65292;&#20026;&#27599;&#31181;&#35821;&#35328;&#26500;&#24314;&#24773;&#24863;&#20998;&#31867;&#26159;&#19968;&#39033;&#21171;&#21160;&#23494;&#38598;&#22411;&#24037;&#20316;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;&#20302;&#36164;&#28304;&#21644;&#28626;&#21361;&#35821;&#35328;&#65292;&#24314;&#31435;&#24773;&#24863;&#20998;&#31867;&#21487;&#33021;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#25105;&#20204;&#22312;&#36164;&#28304;&#20016;&#23500;&#30340;&#35821;&#35328;&#65288;&#20363;&#22914;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#30340;&#33521;&#35821;&#65289;&#19978;&#35757;&#32451;&#24773;&#24863;&#20998;&#31867;&#22120;&#65292;&#24182;&#23558;&#23398;&#20064;&#36801;&#31227;&#21040;&#20302;&#36164;&#28304;&#21644;&#20013;&#31561;&#36164;&#28304;&#30340;&#35821;&#35328;&#12290;&#25105;&#20204;&#27604;&#36739;&#24182;&#23545;&#27604;&#20102;&#20174;&#39640;&#36164;&#28304;&#35821;&#35328;&#21040;&#20302;&#36164;&#28304;&#25110;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#30340;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#12290;&#19968;&#31181;&#26041;&#27861;&#23558;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#26631;&#27880;&#25237;&#24433;&#21040;&#20302;&#36164;&#28304;&#21644;&#20013;&#31561;&#36164;&#28304;&#35821;&#35328;&#30340;&#24179;&#34892;&#35821;&#26009;&#24211;&#20013;&#65292;&#21478;&#19968;&#31181;&#26041;&#27861;&#30452;&#25509;&#23558;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#23398;&#20064;&#36801;&#31227;&#21040;&#20854;&#20182;&#35821;&#35328;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;6&#31181;&#35821;&#35328;&#19978;&#30340;&#26377;&#25928;&#24615;&#65306;Fa
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18424v1 Announce Type: cross  Abstract: It is important to be able to analyze the emotional state of people around the globe. There are 7100+ active languages spoken around the world and building emotion classification for each language is labor intensive. Particularly for low-resource and endangered languages, building emotion classification can be quite challenging. We present a cross-lingual emotion classifier, where we train an emotion classifier with resource-rich languages (i.e. \textit{English} in our work) and transfer the learning to low and moderate resource languages. We compare and contrast two approaches of transfer learning from a high-resource language to a low or moderate-resource language. One approach projects the annotation from a high-resource language to low and moderate-resource language in parallel corpora and the other one uses direct transfer from high-resource language to the other languages. We show the efficacy of our approaches on 6 languages: Fa
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;Hal-Eval&#65292;&#19968;&#20010;&#36890;&#29992;&#21644;&#32454;&#31890;&#24230;&#30340;&#24187;&#35273;&#35780;&#20272;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#24187;&#35273;&#20998;&#31867;&#27861;&#65292;&#19987;&#27880;&#20110;&#20107;&#20214;&#24187;&#35273;&#65292;&#36890;&#36807;&#29983;&#25104;&#21644;&#36807;&#28388;&#32454;&#31890;&#24230;&#24187;&#35273;&#25968;&#25454;&#26469;&#35780;&#20272;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#23545;&#21508;&#31181;&#24187;&#35273;&#30340;&#22788;&#29702;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.15721</link><description>&lt;p&gt;
Hal-Eval: &#19968;&#31181;&#38754;&#21521;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#21644;&#32454;&#31890;&#24230;&#24187;&#35273;&#35780;&#20272;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;Hal-Eval&#65292;&#19968;&#20010;&#36890;&#29992;&#21644;&#32454;&#31890;&#24230;&#30340;&#24187;&#35273;&#35780;&#20272;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#24187;&#35273;&#20998;&#31867;&#27861;&#65292;&#19987;&#27880;&#20110;&#20107;&#20214;&#24187;&#35273;&#65292;&#36890;&#36807;&#29983;&#25104;&#21644;&#36807;&#28388;&#32454;&#31890;&#24230;&#24187;&#35273;&#25968;&#25454;&#26469;&#35780;&#20272;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#23545;&#21508;&#31181;&#24187;&#35273;&#30340;&#22788;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#38750;&#20961;&#30340;&#33021;&#21147;&#65292;&#20294;&#22312;&#22270;&#29255;&#21644;&#20854;&#25551;&#36848;&#20043;&#38388;&#23384;&#22312;&#24187;&#35273;&#19981;&#19968;&#33268;&#12290;&#20197;&#24448;&#23545;LVLMs&#36827;&#34892;&#30340;&#24187;&#35273;&#35780;&#20272;&#30740;&#31350;&#21457;&#29616;&#20102;&#20851;&#20110;&#23545;&#35937;&#12289;&#23646;&#24615;&#21644;&#20851;&#31995;&#30340;&#24187;&#35273;&#65292;&#20294;&#24573;&#30053;&#20102;&#22260;&#32469;&#34394;&#26500;&#23454;&#20307;&#21019;&#24314;&#25972;&#20010;&#21465;&#20107;&#30340;&#22797;&#26434;&#24187;&#35273;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#31934;&#32454;&#30340;&#24187;&#35273;&#20998;&#31867;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#26032;&#30340;&#31867;&#21035;&#65306;&#20107;&#20214;&#24187;&#35273;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20808;&#36827;&#30340;LLMs&#29983;&#25104;&#21644;&#36807;&#28388;&#30001;&#21508;&#31181;&#31867;&#22411;&#30340;&#24187;&#35273;&#32452;&#25104;&#30340;&#32454;&#31890;&#24230;&#24187;&#35273;&#25968;&#25454;&#65292;&#29305;&#21035;&#20851;&#27880;&#20107;&#20214;&#24187;&#35273;&#65292;&#20026;&#22312;&#25105;&#20204;&#30340;&#36890;&#29992;&#35780;&#20272;&#26694;&#26550;&#20869;&#38598;&#25104;&#36776;&#21035;&#21644;&#29983;&#25104;&#35780;&#20272;&#26041;&#27861;&#22880;&#23450;&#22522;&#30784;&#12290;&#25152;&#25552;&#20986;&#30340;&#22522;&#20934;&#21487;&#20197;&#29420;&#29305;&#22320;&#35780;&#20272;LVLMs&#22788;&#29702;&#24191;&#27867;&#24187;&#35273;&#30340;&#33021;&#21147;&#65292;&#20351;&#20854;&#25104;&#20026;&#19968;&#20010;&#21487;&#38752;&#21644;&#20840;&#38754;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15721v1 Announce Type: new  Abstract: Large Vision Language Models exhibit remarkable capabilities but struggle with hallucinations inconsistencies between images and their descriptions. Previous hallucination evaluation studies on LVLMs have identified hallucinations in terms of objects, attributes, and relations but overlooked complex hallucinations that create an entire narrative around a fictional entity. In this paper, we introduce a refined taxonomy of hallucinations, featuring a new category: Event Hallucination. We then utilize advanced LLMs to generate and filter fine grained hallucinatory data consisting of various types of hallucinations, with a particular focus on event hallucinations, laying the groundwork for integrating discriminative and generative evaluation methods within our universal evaluation framework. The proposed benchmark distinctively assesses LVLMs ability to tackle a broad spectrum of hallucinations, making it a reliable and comprehensive tool fo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#31639;&#27861;&#65288;RPO&#65289;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#65292;&#24182;&#25104;&#21151;&#38477;&#20302;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2401.17263</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17263
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#31639;&#27861;&#65288;RPO&#65289;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#65292;&#24182;&#25104;&#21151;&#38477;&#20302;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#25110;&#30772;&#35299;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#20854;&#20013;&#23545;&#25163;&#20462;&#25913;&#36755;&#20837;&#25552;&#31034;&#20197;&#35825;&#23548;&#26377;&#23475;&#34892;&#20026;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#38450;&#24481;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#20165;&#20851;&#27880;&#29421;&#31364;&#30340;&#23041;&#32961;&#27169;&#22411;&#65292;&#24182;&#19981;&#33021;&#25552;&#20379;&#24378;&#22823;&#30340;&#38450;&#24481;&#12290;&#20026;&#20102;&#23454;&#29616;&#24378;&#22823;&#30340;&#38450;&#24481;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#29992;&#20110;&#23545;&#25239;&#30772;&#35299;&#25915;&#20987;&#30340;&#23545;&#25239;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#40065;&#26834;&#25552;&#31034;&#20248;&#21270;&#65288;RPO&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20196;&#29260;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#26131;&#20110;&#35775;&#38382;&#30340;&#21518;&#32512;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#23545;&#30772;&#35299;&#25915;&#20987;&#30340;&#24378;&#38887;&#24615;&#65292;&#21253;&#25324;&#20248;&#21270;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#30772;&#35299;&#25915;&#20987;&#20197;&#21450;&#26410;&#30693;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#20174;84%&#38477;&#20302;&#21040;8.66%&#65292;&#22312;20&#20010;&#30772;&#35299;&#25915;&#20987;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;RPO&#23545;&#27491;&#24120;LM&#20351;&#29992;&#30340;&#24433;&#21709;&#36739;&#23567;&#65292;&#22312;&#36866;&#24212;&#24615;&#25915;&#20987;&#19979;&#20173;&#28982;&#26377;&#25928;&#65292;&#24182;&#19988;&#21487;&#20197;&#36801;&#31227;&#21040;&#40657;&#30418;&#27169;&#22411;&#20013;&#65292;&#38477;&#20302;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite advances in AI alignment, language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior. While some defenses have been proposed, they focus on narrow threat models and fall short of a strong defense, which we posit should be effective, universal, and practical. To achieve this, we propose the first adversarial objective for defending LMs against jailbreaking attacks and an algorithm, robust prompt optimization (RPO), that uses gradient-based token optimization to enforce harmless outputs. This results in an easily accessible suffix that significantly improves robustness to both jailbreaks seen during optimization and unknown, held-out jailbreaks, reducing the attack success rate on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find that RPO has a minor effect on normal LM use, is successful under adaptive attacks, and can transfer to black-box models, reducing the success
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09254</link><description>&lt;p&gt;
&#29992;&#20110;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#22686;&#24378;&#27169;&#22411;&#21487;&#20449;&#24230;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#30001;&#20110;&#23545;&#29983;&#25104;&#34394;&#26500;&#20107;&#23454;&#30340;&#25285;&#24551;&#65292;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;GLM&#65289;&#29305;&#21035;&#24378;&#35843;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31070;&#32463;&#39044;&#27979;&#38598;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#26041;&#24335;&#37327;&#21270;GLM&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#39044;&#27979;&#38598;&#27169;&#22411;&#36890;&#36807;&#26631;&#37327;&#20540;&#21442;&#25968;&#21270;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#39044;&#27979;&#38598;&#65292;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20173;&#28385;&#36275;PAC&#20445;&#35777;&#12290;&#36890;&#36807;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#20845;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
&lt;/p&gt;</description></item></channel></rss>