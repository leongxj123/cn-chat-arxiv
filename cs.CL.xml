<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#20351;&#29992;Shapley&#20540;&#26041;&#27861;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#25581;&#31034;&#20102;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#20915;&#31574;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#25552;&#31034;&#32452;&#20214;&#30340;&#24433;&#21709;</title><link>https://arxiv.org/abs/2404.01332</link><description>&lt;p&gt;
&#31561;&#31561;&#65292;&#36825;&#37117;&#26159;&#20196;&#29260;&#22122;&#38899;&#65311;&#19968;&#30452;&#23601;&#26159;&#21527;&#65306;&#21033;&#29992; Shapley &#20540;&#35299;&#37322; LLM &#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01332
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;Shapley&#20540;&#26041;&#27861;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#25581;&#31034;&#20102;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#20915;&#31574;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#25552;&#31034;&#32452;&#20214;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#20026;&#27169;&#25311;&#20154;&#31867;&#34892;&#20026;&#21644;&#35748;&#30693;&#36807;&#31243;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#65292;&#28508;&#22312;&#24212;&#29992;&#21253;&#25324;&#24066;&#22330;&#30740;&#31350;&#21644;&#28040;&#36153;&#32773;&#34892;&#20026;&#20998;&#26512;&#31561;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLMs&#30340;&#26174;&#33879;&#24046;&#24322;&#26263;&#31034;&#20102;&#19981;&#21516;&#30340;&#22522;&#30784;&#36807;&#31243;&#22312;&#36215;&#20316;&#29992;&#65292;&#20197;&#21450;LLMs&#23545;&#25552;&#31034;&#21464;&#21270;&#30340;&#25935;&#24863;&#24615;&#65292;&#21033;&#29992;LLMs&#20316;&#20026;&#20154;&#31867;&#20027;&#20307;&#30340;&#26367;&#20195;&#20173;&#28982;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#20013;Shapley&#20540;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#24182;&#37327;&#21270;&#27599;&#20010;&#25552;&#31034;&#32452;&#20214;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#30456;&#23545;&#36129;&#29486;&#12290;&#36890;&#36807;&#20004;&#20010;&#24212;&#29992;--&#19968;&#20010;&#31163;&#25955;&#36873;&#25321;&#23454;&#39564;&#21644;&#19968;&#20010;&#35748;&#30693;&#20559;&#35265;&#35843;&#26597;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Shapley&#20540;&#26041;&#27861;&#22914;&#20309;&#25581;&#31034;&#25105;&#20204;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#21363;LLM&#20915;&#31574;&#21463;&#21040;&#30340;&#24433;&#21709;&#20005;&#37325;&#20559;&#21521;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01332v1 Announce Type: cross  Abstract: The emergence of large language models (LLMs) has opened up exciting possibilities for simulating human behavior and cognitive processes, with potential applications in various domains, including marketing research and consumer behavior analysis. However, the validity of utilizing LLMs as stand-ins for human subjects remains uncertain due to glaring divergences that suggest fundamentally different underlying processes at play and the sensitivity of LLM responses to prompt variations. This paper presents a novel approach based on Shapley values from cooperative game theory to interpret LLM behavior and quantify the relative contribution of each prompt component to the model's output. Through two applications-a discrete choice experiment and an investigation of cognitive biases-we demonstrate how the Shapley value method can uncover what we term "token noise" effects, a phenomenon where LLM decisions are disproportionately influenced by 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22478;&#24066;&#29305;&#23450;&#25968;&#25454;&#19978;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#20026;&#20154;&#20204;&#25552;&#20379;&#20934;&#30830;&#30340;&#25512;&#33616;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#24187;&#35273;&#12290;</title><link>https://arxiv.org/abs/2403.09059</link><description>&lt;p&gt;
LAMP&#65306;&#22320;&#22270;&#19978;&#30340;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LAMP: A Language Model on the Map
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09059
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22478;&#24066;&#29305;&#23450;&#25968;&#25454;&#19978;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#20026;&#20154;&#20204;&#25552;&#20379;&#20934;&#30830;&#30340;&#25512;&#33616;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#24187;&#35273;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25105;&#20204;&#30340;&#29983;&#27963;&#20013;&#25198;&#28436;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#35282;&#33394;&#65292;&#20026;&#25105;&#20204;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#25552;&#20379;&#24110;&#21161;&#12290;&#22312;&#22320;&#29702;&#31354;&#38388;&#39046;&#22495;&#65292;LLMs&#24050;&#32463;&#23637;&#31034;&#20986;&#33021;&#22815;&#22238;&#31572;&#19968;&#33324;&#24615;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#27604;&#22914;&#35782;&#21035;&#19968;&#20010;&#22269;&#23478;&#30340;&#39318;&#37117;&#65307;&#28982;&#32780;&#65292;&#24403;&#28041;&#21450;&#22238;&#31572;&#20851;&#20110;&#29305;&#23450;&#22320;&#28857;&#30340;&#32454;&#31890;&#24230;&#38382;&#39064;&#26102;&#65292;&#27604;&#22914;&#26434;&#36135;&#24215;&#25110;&#39184;&#39302;&#65292;&#36825;&#20123;&#26500;&#25104;&#20102;&#20154;&#20204;&#26085;&#24120;&#29983;&#27963;&#20013;&#37325;&#35201;&#30340;&#26041;&#38754;&#26102;&#65292;&#23427;&#20204;&#30340;&#25928;&#29992;&#21463;&#21040;&#38459;&#30861;&#12290;&#36825;&#20027;&#35201;&#26159;&#22240;&#20026;&#25105;&#20204;&#22478;&#24066;&#20013;&#30340;&#22320;&#28857;&#23578;&#26410;&#34987;&#31995;&#32479;&#22320;&#36755;&#20837;&#21040;LLMs&#20013;&#65292;&#20197;&#20415;&#20110;&#29702;&#35299;&#21644;&#35760;&#24518;&#23427;&#20204;&#12290;&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22478;&#24066;&#29305;&#23450;&#25968;&#25454;&#19978;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#20174;&#32780;&#20351;&#20854;&#33021;&#22815;&#25552;&#20379;&#20934;&#30830;&#30340;&#24314;&#35758;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#24187;&#35273;&#12290;&#25105;&#20204;&#20998;&#20139;&#25105;&#20204;&#30340;&#27169;&#22411;LAMP&#21644;&#29992;&#20110;&#35757;&#32451;&#23427;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#36827;&#34892;&#23454;&#39564;&#20998;&#26512;&#20854;&#27491;&#30830;&#26816;&#32034;&#31354;&#38388;&#23545;&#35937;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09059v1 Announce Type: new  Abstract: Large Language Models (LLMs) are poised to play an increasingly important role in our lives, providing assistance across a wide array of tasks. In the geospatial domain, LLMs have demonstrated the ability to answer generic questions, such as identifying a country's capital; nonetheless, their utility is hindered when it comes to answering fine-grained questions about specific places, such as grocery stores or restaurants, which constitute essential aspects of people's everyday lives. This is mainly because the places in our cities haven't been systematically fed into LLMs, so as to understand and memorize them. This study introduces a novel framework for fine-tuning a pre-trained model on city-specific data, to enable it to provide accurate recommendations, while minimizing hallucinations. We share our model, LAMP, and the data used to train it. We conduct experiments to analyze its ability to correctly retrieving spatial objects, and co
&lt;/p&gt;</description></item><item><title>LINGOLLM&#26159;&#19968;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#25552;&#31034;&#20013;&#23637;&#31034;&#23545;&#30475;&#19981;&#35265;&#35821;&#35328;&#30340;&#35821;&#35328;&#30693;&#35782;&#65292;&#21253;&#25324;&#35789;&#20856;&#12289;&#35821;&#27861;&#20070;&#21644;&#24418;&#24577;&#20998;&#26512;&#30340;&#36755;&#20837;&#25991;&#26412;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#28626;&#21361;&#35821;&#35328;&#26041;&#38754;&#30340;&#32763;&#35793;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.18025</link><description>&lt;p&gt;
&#38599;&#20323;&#19968;&#21517;&#35821;&#35328;&#23398;&#23478;&#65281;&#65306;&#36890;&#36807;&#19978;&#19979;&#25991;&#35821;&#35328;&#25551;&#36848;&#23398;&#20064;&#28626;&#21361;&#35821;&#35328;
&lt;/p&gt;
&lt;p&gt;
Hire a Linguist!: Learning Endangered Languages with In-Context Linguistic Descriptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18025
&lt;/p&gt;
&lt;p&gt;
LINGOLLM&#26159;&#19968;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#25552;&#31034;&#20013;&#23637;&#31034;&#23545;&#30475;&#19981;&#35265;&#35821;&#35328;&#30340;&#35821;&#35328;&#30693;&#35782;&#65292;&#21253;&#25324;&#35789;&#20856;&#12289;&#35821;&#27861;&#20070;&#21644;&#24418;&#24577;&#20998;&#26512;&#30340;&#36755;&#20837;&#25991;&#26412;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#28626;&#21361;&#35821;&#35328;&#26041;&#38754;&#30340;&#32763;&#35793;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv&#65306;2402.18025v1
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18025v1 Announce Type: new  Abstract: How can large language models (LLMs) process and translate endangered languages? Many languages lack a large corpus to train a decent LLM; therefore existing LLMs rarely perform well in unseen, endangered languages. On the contrary, we observe that 2000 endangered languages, though without a large corpus, have a grammar book or a dictionary. We propose LINGOLLM, a training-free approach to enable an LLM to process unseen languages that hardly occur in its pre-training. Our key insight is to demonstrate linguistic knowledge of an unseen language in an LLM's prompt, including a dictionary, a grammar book, and morphologically analyzed input text. We implement LINGOLLM on top of two models, GPT-4 and Mixtral, and evaluate their performance on 5 tasks across 8 endangered or low-resource languages. Our results show that LINGOLLM elevates translation capability from GPT-4's 0 to 10.5 BLEU for 10 language directions. Our findings demonstrate the
&lt;/p&gt;</description></item><item><title>&#23558;&#24694;&#24847;&#25552;&#31034;&#20998;&#35299;&#20026;&#29420;&#31435;&#30340;&#23376;&#25552;&#31034;&#20351;&#24471;LLM&#36234;&#29425;&#25915;&#20987;&#26356;&#38590;&#34987;&#26816;&#27979;</title><link>https://arxiv.org/abs/2402.16914</link><description>&lt;p&gt;
DrAttack: &#25552;&#31034;&#20998;&#35299;&#21644;&#37325;&#26500;&#20351;&#24378;&#22823;&#30340;LLM&#36234;&#29425;&#32773;
&lt;/p&gt;
&lt;p&gt;
DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16914
&lt;/p&gt;
&lt;p&gt;
&#23558;&#24694;&#24847;&#25552;&#31034;&#20998;&#35299;&#20026;&#29420;&#31435;&#30340;&#23376;&#25552;&#31034;&#20351;&#24471;LLM&#36234;&#29425;&#25915;&#20987;&#26356;&#38590;&#34987;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#23558;&#24694;&#24847;&#25552;&#31034;&#20998;&#35299;&#20026;&#29420;&#31435;&#30340;&#23376;&#25552;&#31034;&#33021;&#22815;&#26377;&#25928;&#27169;&#31946;&#20854;&#28508;&#22312;&#30340;&#24694;&#24847;&#24847;&#22270;&#65292;&#20351;&#20043;&#20197;&#29255;&#27573;&#21270;&#12289;&#19981;&#26131;&#26816;&#27979;&#30340;&#24418;&#24335;&#21576;&#29616;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#29992;&#20110;&#36234;&#29425;&#25915;&#20987;&#30340;&#33258;&#21160;&#25552;&#31034;&#20998;&#35299;&#21644;&#37325;&#26500;&#26694;&#26550;&#65288;DrAttack&#65289;&#12290;DrAttack&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#65306;(a) &#23558;&#21407;&#22987;&#25552;&#31034;&#36827;&#34892;&#8220;&#20998;&#35299;&#8221;&#20026;&#23376;&#25552;&#31034;&#65292;(b) &#36890;&#36807;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#35821;&#20041;&#19978;&#30456;&#20284;&#20294;&#38544;&#21547;&#30340;&#8220;&#37325;&#26500;&#8221;&#36825;&#20123;&#23376;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16914v1 Announce Type: cross  Abstract: The safety alignment of Large Language Models (LLMs) is vulnerable to both manual and automated jailbreak attacks, which adversarially trigger LLMs to output harmful content. However, current methods for jailbreaking LLMs, which nest entire harmful prompts, are not effective at concealing malicious intent and can be easily identified and rejected by well-aligned LLMs. This paper discovers that decomposing a malicious prompt into separated sub-prompts can effectively obscure its underlying malicious intent by presenting it in a fragmented, less detectable form, thereby addressing these limitations. We introduce an automatic prompt \textbf{D}ecomposition and \textbf{R}econstruction framework for jailbreak \textbf{Attack} (DrAttack). DrAttack includes three key components: (a) `Decomposition' of the original prompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly by in-context learning with semantically similar but h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#37319;&#29992;&#34164;&#28085;&#23545;&#40784;&#65292;&#20197;&#20248;&#21270;&#21487;&#34892;&#24615;&#65292;&#25552;&#21462;&#26377;&#29702;&#30340;&#26041;&#24335;&#25552;&#20379;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#26367;&#20195;&#27169;&#22411;</title><link>https://arxiv.org/abs/2402.08479</link><description>&lt;p&gt;
&#21487;&#20449;&#30340;&#21462;&#26679;&#21512;&#29702;&#21270;&#36890;&#36807;&#21322;&#30417;&#30563;&#30340;&#34164;&#28085;&#20449;&#21495;
&lt;/p&gt;
&lt;p&gt;
Plausible Extractive Rationalization through Semi-Supervised Entailment Signal
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#37319;&#29992;&#34164;&#28085;&#23545;&#40784;&#65292;&#20197;&#20248;&#21270;&#21487;&#34892;&#24615;&#65292;&#25552;&#21462;&#26377;&#29702;&#30340;&#26041;&#24335;&#25552;&#20379;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#26367;&#20195;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#21644;&#19981;&#36879;&#26126;&#30340;&#40657;&#30418;&#23376;&#27169;&#22411;&#30340;&#22686;&#21152;&#38656;&#35201;&#37319;&#29992;&#21487;&#35299;&#37322;&#30340;&#25514;&#26045;&#65292;&#20854;&#20013;&#19968;&#31181;&#36873;&#25321;&#26159;&#25552;&#21462;&#26377;&#29702;&#30340;&#27169;&#22411;&#65292;&#23427;&#20204;&#20316;&#20026;&#26356;&#21487;&#35299;&#37322;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#36825;&#20123;&#27169;&#22411;&#65292;&#20063;&#31216;&#20026;&#20808;&#35299;&#37322;&#28982;&#21518;&#39044;&#27979;&#27169;&#22411;&#65292;&#20351;&#29992;&#35299;&#37322;&#27169;&#22411;&#26469;&#25552;&#21462;&#26377;&#29702;&#65292;&#28982;&#21518;&#20351;&#29992;&#25552;&#21462;&#30340;&#20449;&#24687;&#26469;&#35843;&#25972;&#39044;&#27979;&#27169;&#22411;&#12290;&#23427;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#25552;&#20379;&#31934;&#30830;&#21644;&#24544;&#23454;&#30340;&#35299;&#37322;&#65292;&#30001;&#25552;&#21462;&#30340;&#26377;&#29702;&#34920;&#31034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#21322;&#30417;&#30563;&#26041;&#27861;&#26469;&#20248;&#21270;&#25552;&#21462;&#26377;&#29702;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#37319;&#29992;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#65288;NLI&#65289;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#20010;&#23567;&#22411;&#30340;&#26377;&#30417;&#30563;&#26377;&#29702;&#38598;&#65288;10%&#65289;&#19978;&#36827;&#19968;&#27493;&#24494;&#35843;&#23427;&#12290;&#36890;&#36807;&#34164;&#28085;&#23545;&#40784;&#65292;NLI&#39044;&#27979;&#27169;&#22411;&#34987;&#21033;&#29992;&#20316;&#20026;&#35299;&#37322;&#27169;&#22411;&#30340;&#19968;&#31181;&#30417;&#30563;&#20449;&#21495;&#28304;&#12290;&#36890;&#36807;&#22312;&#38382;&#31572;&#20219;&#21153;&#20013;&#24378;&#21046;&#35299;&#37322;&#21644;&#31572;&#26696;&#20043;&#38388;&#30340;&#23545;&#40784;&#19968;&#33268;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24615;&#33021;&#24471;&#21040;&#20102;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing use of complex and opaque black box models requires the adoption of interpretable measures, one such option is extractive rationalizing models, which serve as a more interpretable alternative. These models, also known as Explain-Then-Predict models, employ an explainer model to extract rationales and subsequently condition the predictor with the extracted information. Their primary objective is to provide precise and faithful explanations, represented by the extracted rationales. In this paper, we take a semi-supervised approach to optimize for the plausibility of extracted rationales. We adopt a pre-trained natural language inference (NLI) model and further fine-tune it on a small set of supervised rationales ($10\%$). The NLI predictor is leveraged as a source of supervisory signals to the explainer via entailment alignment. We show that, by enforcing the alignment agreement between the explanation and answer in a question-answering task, the performance can be improve
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#21644;&#35782;&#21035;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#65292;&#27169;&#22411;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#33021;&#22815;&#35299;&#37322;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2311.04916</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Explainable Identification of Hate Speech towards Islam using Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04916
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#21644;&#35782;&#21035;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#65292;&#27169;&#22411;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#33021;&#22815;&#35299;&#37322;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#22312;&#22312;&#32447;&#31038;&#20132;&#20114;&#21160;&#24179;&#21488;&#19978;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#35782;&#21035;&#21644;&#28040;&#38500;&#36825;&#31181;&#20167;&#24680;&#26159;&#36808;&#21521;&#21644;&#35856;&#19982;&#21644;&#24179;&#26410;&#26469;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#20363;&#65292;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#35782;&#21035;&#21644;&#35299;&#37322;&#38024;&#23545;&#20234;&#26031;&#20848;&#25945;&#30340;&#20167;&#24680;&#35328;&#35770;&#12290;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21457;&#29616;&#12289;&#25552;&#21462;&#24182;&#21033;&#29992;&#19981;&#21516;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#20869;&#22312;&#33021;&#21147;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22987;&#32456;&#33021;&#22815;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#25552;&#20379;&#23545;&#28508;&#22312;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04916v2 Announce Type: cross  Abstract: Islamophobic language is a prevalent challenge on online social interaction platforms. Identifying and eliminating such hatred is a crucial step towards a future of harmony and peace. This study presents a novel paradigm for identifying and explaining hate speech towards Islam using graph neural networks. Utilizing the intrinsic ability of graph neural networks to find, extract, and use relationships across disparate data points, our model consistently achieves outstanding performance while offering explanations for the underlying correlations and causation.
&lt;/p&gt;</description></item></channel></rss>