<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#35266;&#23519;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19981;&#21516;&#23618;&#23545;&#38544;&#34255;&#29366;&#24577;&#30340;&#24433;&#21709;&#31243;&#24230;&#65292;&#25552;&#20986;&#20102;LLM-Streamline&#26041;&#27861;&#65292;&#21253;&#25324;&#23618;&#21098;&#26525;&#21644;&#23618;&#26367;&#25442;&#65292;&#29992;&#20110;&#21387;&#32553;&#27169;&#22411;&#24182;&#20445;&#25345;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.19135</link><description>&lt;p&gt;
&#36890;&#36807;&#31616;&#21270;&#19981;&#37325;&#35201;&#30340;&#23618;&#21387;&#32553;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Compressing Large Language Models by Streamlining the Unimportant Layer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19135
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35266;&#23519;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19981;&#21516;&#23618;&#23545;&#38544;&#34255;&#29366;&#24577;&#30340;&#24433;&#21709;&#31243;&#24230;&#65292;&#25552;&#20986;&#20102;LLM-Streamline&#26041;&#27861;&#65292;&#21253;&#25324;&#23618;&#21098;&#26525;&#21644;&#23618;&#26367;&#25442;&#65292;&#29992;&#20110;&#21387;&#32553;&#27169;&#22411;&#24182;&#20445;&#25345;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#21644;&#39046;&#22495;&#65292;&#20294;&#20854;&#36866;&#29992;&#24615;&#21463;&#21040;&#27169;&#22411;&#21442;&#25968;&#30340;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#20851;&#27880;&#34920;&#29616;&#20986;&#39640;&#24615;&#33021;&#30340;&#32039;&#20945;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;LLM&#30340;&#19981;&#21516;&#23618;&#23545;&#38544;&#34255;&#29366;&#24577;&#26377;&#19981;&#21516;&#31243;&#24230;&#30340;&#25200;&#21160;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35782;&#21035;&#20986;&#19981;&#37027;&#20040;&#37325;&#35201;&#30340;&#23618;&#12290;&#22522;&#20110;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LLM-Streamline&#65292;&#21253;&#25324;&#20004;&#37096;&#20998;&#65306;&#23618;&#21098;&#26525;&#65292;&#26681;&#25454;&#30446;&#26631;&#31232;&#30095;&#24230;&#31227;&#38500;&#27169;&#22411;&#20013;&#19968;&#32452;&#36830;&#32493;&#30340;&#26368;&#19981;&#37325;&#35201;&#30340;&#23618;&#65307;&#23618;&#26367;&#25442;&#65292;&#35757;&#32451;&#19968;&#20010;&#36731;&#37327;&#32423;&#27169;&#22411;&#26469;&#26367;&#25442;&#34987;&#21098;&#26525;&#30340;&#23618;&#65292;&#20174;&#32780;&#32531;&#35299;&#30001;&#21098;&#26525;&#36896;&#25104;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;(MLP)&#21644;&#19968;&#20010;transformer&#23618;&#31561;&#32467;&#26500;&#20316;&#20026;&#36731;&#37327;&#32423;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19135v1 Announce Type: cross  Abstract: Large language models (LLM) have been extensively applied in various natural language tasks and domains, but their applicability is constrained by the large number of parameters of the models. Consequently, there is an increasing emphasis on compact models that exhibit high performance. In this study, we observe that different layers in LLM have varying degrees of perturbation on the hidden states, which allows us to identify less important layers. Based on this phenomenon, we propose LLM-Streamline, which consists of two parts: layer pruning, where we remove a set of consecutive layers with the lowest importance in the model according to the target sparsity; and layer replacement, where we train a lightweight model to substitute the pruned layers, thereby mitigating the performance degradation caused by pruning. In our experiments, we utilize structures such as a multi-layer perceptron (MLP) and a transformer layer as lightweight mode
&lt;/p&gt;</description></item><item><title>LARA&#26159;&#19968;&#20010;Linguistic-Adaptive Retrieval-Augmented Language Models&#65288;&#35821;&#35328;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;LLMs&#65289;&#65292;&#26088;&#22312;&#36890;&#36807;&#32467;&#21512;&#24494;&#35843;&#36807;&#30340;&#36739;&#23567;&#27169;&#22411;&#19982;&#26816;&#32034;&#22686;&#24378;&#26426;&#21046;&#26469;&#25552;&#39640;&#22810;&#35821;&#35328;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#35805;&#32972;&#26223;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.16504</link><description>&lt;p&gt;
LARA&#65306;&#35821;&#35328;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;LLMs&#29992;&#20110;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16504
&lt;/p&gt;
&lt;p&gt;
LARA&#26159;&#19968;&#20010;Linguistic-Adaptive Retrieval-Augmented Language Models&#65288;&#35821;&#35328;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;LLMs&#65289;&#65292;&#26088;&#22312;&#36890;&#36807;&#32467;&#21512;&#24494;&#35843;&#36807;&#30340;&#36739;&#23567;&#27169;&#22411;&#19982;&#26816;&#32034;&#22686;&#24378;&#26426;&#21046;&#26469;&#25552;&#39640;&#22810;&#35821;&#35328;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#35805;&#32972;&#26223;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#21462;&#24471;&#30340;&#26174;&#33879;&#25104;&#23601;&#65292;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#22312;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#20013;&#37319;&#29992;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#20391;&#37325;&#20110;&#21333;&#35821;&#35328;&#12289;&#21333;&#36718;&#20998;&#31867;&#20219;&#21153;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;LARA&#65288;Linguistic-Adaptive Retrieval-Augmented Language Models&#65289;&#65292;&#26088;&#22312;&#22686;&#24378;&#22810;&#35821;&#35328;&#22810;&#36718;&#20998;&#31867;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#65292;&#20197;&#36866;&#24212;&#32842;&#22825;&#26426;&#22120;&#20154;&#20132;&#20114;&#20013;&#30340;&#20247;&#22810;&#24847;&#22270;&#12290;&#30001;&#20110;&#20250;&#35805;&#32972;&#26223;&#30340;&#22797;&#26434;&#24615;&#21644;&#19981;&#26029;&#21457;&#23637;&#30340;&#24615;&#36136;&#65292;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;&#23588;&#20026;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;LARA&#36890;&#36807;&#23558;&#24494;&#35843;&#36807;&#30340;&#36739;&#23567;&#27169;&#22411;&#19982;&#26816;&#32034;&#22686;&#24378;&#26426;&#21046;&#32467;&#21512;&#65292;&#23884;&#20837;LLMs&#30340;&#26550;&#26500;&#20013;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#36825;&#31181;&#25972;&#21512;&#20351;LARA&#33021;&#22815;&#21160;&#24577;&#21033;&#29992;&#36807;&#21435;&#30340;&#23545;&#35805;&#21644;&#30456;&#20851;&#24847;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#19978;&#19979;&#25991;&#30340;&#29702;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#33258;&#36866;&#24212;&#26816;&#32034;&#25216;&#26415;&#22686;&#24378;&#20102;&#36328;&#35821;&#35328;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16504v1 Announce Type: new  Abstract: Following the significant achievements of large language models (LLMs), researchers have employed in-context learning for text classification tasks. However, these studies focused on monolingual, single-turn classification tasks. In this paper, we introduce LARA (Linguistic-Adaptive Retrieval-Augmented Language Models), designed to enhance accuracy in multi-turn classification tasks across six languages, accommodating numerous intents in chatbot interactions. Multi-turn intent classification is notably challenging due to the complexity and evolving nature of conversational contexts. LARA tackles these issues by combining a fine-tuned smaller model with a retrieval-augmented mechanism, integrated within the architecture of LLMs. This integration allows LARA to dynamically utilize past dialogues and relevant intents, thereby improving the understanding of the context. Furthermore, our adaptive retrieval techniques bolster the cross-lingual
&lt;/p&gt;</description></item><item><title>CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.13583</link><description>&lt;p&gt;
CONLINE: &#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#19982;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#30340;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13583
&lt;/p&gt;
&lt;p&gt;
CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#25442;&#20026;&#21487;&#25191;&#34892;&#20195;&#30721;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#22330;&#26223;&#19979;&#29983;&#25104;&#22797;&#26434;&#20195;&#30721;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21407;&#22240;&#22312;&#20110;&#22797;&#26434;&#30340;&#32467;&#26500;&#12289;&#24494;&#22937;&#30340;&#38169;&#35823;&#12289;&#23545;&#39640;&#32423;&#25968;&#25454;&#31867;&#22411;&#30340;&#29702;&#35299;&#20197;&#21450;&#32570;&#23569;&#36741;&#21161;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CONLINE&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#21010;&#30340;&#22312;&#32447;&#25628;&#32034;&#20449;&#24687;&#26816;&#32034;&#21644;&#33258;&#21160;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#20195;&#30721;&#29983;&#25104;&#65292;&#36827;&#34892;&#36845;&#20195;&#31934;&#28860;&#12290;CONLINE&#36824;&#20018;&#34892;&#21270;&#20102;&#22797;&#26434;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#65292;&#20197;&#25913;&#21892;&#29702;&#35299;&#65292;&#24182;&#29983;&#25104;&#27979;&#35797;&#29992;&#20363;&#65292;&#30830;&#20445;&#26694;&#26550;&#36866;&#29992;&#20110;&#29616;&#23454;&#24212;&#29992;&#12290;CONLINE&#36890;&#36807;&#23545;DS-1000&#21644;ClassEval&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#23454;&#39564;&#39564;&#35777;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;CONLINE&#26174;&#33879;&#25552;&#39640;&#20102;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#36136;&#37327;&#65292;&#31361;&#26174;&#20102;&#20854;&#25552;&#21319;&#23454;&#36341;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13583v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement. CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications. CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets. It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the pra
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;EMBER&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#25506;&#27979;&#20998;&#31867;&#22120;&#23558;&#20449;&#24687;&#25552;&#21462;&#33021;&#21147;&#30452;&#25509;&#23884;&#20837;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#21516;&#26102;&#25991;&#26412;&#29983;&#25104;&#21644;&#20449;&#24687;&#25552;&#21462;&#65292;&#20351;&#24471;&#35299;&#30721;&#22120;-only&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#19981;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2403.11747</link><description>&lt;p&gt;
&#20351;&#29992;&#25506;&#27979;&#20998;&#31867;&#22120;&#30340;&#23884;&#20837;&#24335;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Embedded Named Entity Recognition using Probing Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11747
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;EMBER&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#25506;&#27979;&#20998;&#31867;&#22120;&#23558;&#20449;&#24687;&#25552;&#21462;&#33021;&#21147;&#30452;&#25509;&#23884;&#20837;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#21516;&#26102;&#25991;&#26412;&#29983;&#25104;&#21644;&#20449;&#24687;&#25552;&#21462;&#65292;&#20351;&#24471;&#35299;&#30721;&#22120;-only&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#19981;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#25552;&#21462;&#35821;&#20041;&#20449;&#24687;&#26159;&#33258;&#21160;&#20107;&#23454;&#26816;&#26597;&#25110;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31561;&#24212;&#29992;&#30340;&#26377;&#29992;&#24037;&#20855;&#12290;&#30446;&#21069;&#65292;&#36825;&#35201;&#27714;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20351;&#29992;&#21333;&#29420;&#30340;&#27169;&#22411;&#65292;&#36825;&#20250;&#22686;&#21152;&#35745;&#31639;&#25104;&#26412;&#65292;&#25110;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#30772;&#22351;&#24615;&#24494;&#35843;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#30452;&#25509;&#23558;&#20449;&#24687;&#25552;&#21462;&#21151;&#33021;&#23884;&#20837;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;&#25506;&#27979;&#20998;&#31867;&#22120;&#65292;&#20174;&#32780;&#23454;&#29616;&#39640;&#25928;&#30340;&#21516;&#26102;&#25991;&#26412;&#29983;&#25104;&#21644;&#20449;&#24687;&#25552;&#21462;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;EMBER&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#23427;&#20351;&#35299;&#30721;&#22120;-only&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#19981;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65292;&#24182;&#19988;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#38468;&#21152;&#30340;&#35745;&#31639;&#25104;&#26412;&#26497;&#23567;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20351;&#29992;GPT-2&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;EMBER&#22312;&#27969;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#20445;&#25345;&#39640;&#20196;&#29260;&#29983;&#25104;&#36895;&#29575;&#65292;&#19982;43.64%&#30456;&#27604;&#65292;&#20854;&#36895;&#24230;&#20165;&#30053;&#24494;&#19979;&#38477;&#32422;1%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11747v1 Announce Type: new  Abstract: Extracting semantic information from generated text is a useful tool for applications such as automated fact checking or retrieval augmented generation. Currently, this requires either separate models during inference, which increases computational cost, or destructive fine-tuning of the language model. Instead, we propose directly embedding information extraction capabilities into pre-trained language models using probing classifiers, enabling efficient simultaneous text generation and information extraction. For this, we introduce an approach called EMBER and show that it enables named entity recognition in decoder-only language models without fine-tuning them and while incurring minimal additional computational cost at inference time. Specifically, our experiments using GPT-2 show that EMBER maintains high token generation rates during streaming text generation, with only a negligible decrease in speed of around 1% compared to a 43.64
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#39044;&#27979;&#22522;&#20110;&#35821;&#35328;&#30340;&#35760;&#24518;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#20854;&#23545;&#27169;&#26865;&#20004;&#21487;&#21477;&#23376;&#30340;&#22788;&#29702;&#33021;&#21147;&#22686;&#36827;&#20102;&#23545;&#20154;&#31867;&#35748;&#30693;&#26426;&#21046;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.05152</link><description>&lt;p&gt;
&#26397;&#21521;&#26426;&#22120;&#24515;&#29702;&#23398;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#27979;&#20154;&#31867;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
Towards a Psychology of Machines: Large Language Models Predict Human Memory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#39044;&#27979;&#22522;&#20110;&#35821;&#35328;&#30340;&#35760;&#24518;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#20854;&#23545;&#27169;&#26865;&#20004;&#21487;&#21477;&#23376;&#30340;&#22788;&#29702;&#33021;&#21147;&#22686;&#36827;&#20102;&#23545;&#20154;&#31867;&#35748;&#30693;&#26426;&#21046;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#65292;&#23613;&#31649;&#32570;&#20047;&#20154;&#31867;&#35748;&#30693;&#22522;&#30784;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#38500;&#20102;&#31616;&#21333;&#27169;&#20223;&#20154;&#31867;&#35821;&#35328;&#27169;&#24335;&#65292;&#36825;&#20123;&#27169;&#22411;&#33021;&#21542;&#25552;&#20379;&#20851;&#20110;&#20154;&#31867;&#35748;&#30693;&#26426;&#21046;&#30340;&#27934;&#35265;&#65311;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#22312;&#39044;&#27979;&#22522;&#20110;&#35821;&#35328;&#30340;&#35760;&#24518;&#20219;&#21153;&#20013;&#20154;&#31867;&#34920;&#29616;&#30340;&#33021;&#21147;&#12290;&#22522;&#20110;&#25991;&#26412;&#29702;&#35299;&#29702;&#35770;&#65292;&#25105;&#20204;&#20551;&#35774;&#35782;&#21035;&#27169;&#26865;&#20004;&#21487;&#30340;&#21477;&#23376;&#65288;&#20363;&#22914;&#65292;&#8220;&#22240;&#20026;&#27604;&#23572;&#21917;&#37202;&#65292;&#25152;&#20197;&#37202;&#20174;&#26410;&#30041;&#22312;&#25151;&#23376;&#37324;&#8221;&#65289;&#22312;&#21069;&#38754;&#25552;&#20379;&#19982;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#20250;&#24471;&#21040;&#20419;&#36827;&#12290;&#21442;&#19982;&#32773;&#65292;&#26080;&#35770;&#26159;&#20154;&#31867;&#36824;&#26159;ChatGPT&#65292;&#37117;&#34987;&#21576;&#29616;&#25104;&#23545;&#30340;&#21477;&#23376;&#12290;&#31532;&#20108;&#20010;&#21477;&#23376;&#24635;&#26159;&#19968;&#20010;&#26088;&#22312;&#22266;&#26377;&#22320;&#27169;&#26865;&#20004;&#21487;&#30340;&#33457;&#22253;&#36335;&#24452;&#21477;&#65292;&#32780;&#31532;&#19968;&#20010;&#21477;&#23376;&#21017;&#25552;&#20379;&#20102;&#21512;&#36866;&#30340;&#65288;&#20363;&#22914;&#65292;&#8220;&#27604;&#23572;&#24739;&#26377;&#24930;&#24615;&#37202;&#31934;&#20013;&#27602;&#8221;&#65289;&#25110;&#19981;&#21512;&#36866;&#30340;&#19978;&#19979;&#25991;&#65288;&#20363;&#22914;&#65292;&#8220;&#27604;&#23572;&#21916;&#27426;&#25171;&#39640;&#23572;&#22827;&#8221;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05152v1 Announce Type: cross  Abstract: Large language models (LLMs) are demonstrating remarkable capabilities across various tasks despite lacking a foundation in human cognition. This raises the question: can these models, beyond simply mimicking human language patterns, offer insights into the mechanisms underlying human cognition? This study explores the ability of ChatGPT to predict human performance in a language-based memory task. Building upon theories of text comprehension, we hypothesize that recognizing ambiguous sentences (e.g., "Because Bill drinks wine is never kept in the house") is facilitated by preceding them with contextually relevant information. Participants, both human and ChatGPT, were presented with pairs of sentences. The second sentence was always a garden-path sentence designed to be inherently ambiguous, while the first sentence either provided a fitting (e.g., "Bill has chronic alcoholism") or an unfitting context (e.g., "Bill likes to play golf"
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;In-Dialogue Learning&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#35805;&#21382;&#21490;&#21051;&#30011;&#20010;&#20154;&#35774;&#26469;&#23436;&#25104;&#20010;&#24615;&#21270;&#23545;&#35805;&#29983;&#25104;&#20219;&#21153;&#65292;&#26080;&#38656;&#39044;&#23450;&#20041;&#20010;&#20154;&#36164;&#26009;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#26174;&#33879;&#25913;&#36827;&#23545;&#35805;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.03102</link><description>&lt;p&gt;
&#8220;&#22312;&#23545;&#35805;&#20013;&#23398;&#20064;&#8221;&#65306;&#36890;&#36807;&#23545;&#35805;&#20013;&#23398;&#20064;&#23454;&#29616;&#26080;&#38656;&#39044;&#23450;&#20041;&#20010;&#20154;&#36164;&#26009;&#30340;&#20010;&#24615;&#21270;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
"In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03102
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;In-Dialogue Learning&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#35805;&#21382;&#21490;&#21051;&#30011;&#20010;&#20154;&#35774;&#26469;&#23436;&#25104;&#20010;&#24615;&#21270;&#23545;&#35805;&#29983;&#25104;&#20219;&#21153;&#65292;&#26080;&#38656;&#39044;&#23450;&#20041;&#20010;&#20154;&#36164;&#26009;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#26174;&#33879;&#25913;&#36827;&#23545;&#35805;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#23545;&#35805;&#31995;&#32479;&#36817;&#24180;&#26469;&#22791;&#21463;&#20851;&#27880;&#65292;&#22240;&#20854;&#33021;&#22815;&#29983;&#25104;&#19982;&#19981;&#21516;&#20154;&#35774;&#19968;&#33268;&#30340;&#21709;&#24212;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#39044;&#23450;&#20041;&#30340;&#20010;&#20154;&#36164;&#26009;&#65292;&#36825;&#19981;&#20165;&#32791;&#26102;&#19988;&#21171;&#21160;&#23494;&#38598;&#65292;&#36824;&#32570;&#20047;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;In-Dialogue Learning&#65288;IDL&#65289;&#65292;&#19968;&#31181;&#24494;&#35843;&#26694;&#26550;&#65292;&#22686;&#24378;&#20102;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21033;&#29992;&#23545;&#35805;&#21382;&#21490;&#26469;&#21051;&#30011;&#20010;&#20154;&#35774;&#65292;&#20197;&#23436;&#25104;&#20010;&#24615;&#21270;&#23545;&#35805;&#29983;&#25104;&#20219;&#21153;&#65292;&#32780;&#26080;&#38656;&#39044;&#23450;&#20041;&#20010;&#20154;&#36164;&#26009;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;IDL&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;BLEU&#21644;ROUGE&#20998;&#25968;&#20998;&#21035;&#22686;&#21152;&#20102;&#39640;&#36798;200%&#21644;247%&#12290;&#27492;&#22806;&#65292;&#20154;&#24037;&#35780;&#20272;&#30340;&#32467;&#26524;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03102v1 Announce Type: cross  Abstract: Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#23545;&#35805;&#20013;&#20219;&#21153;&#20999;&#25442;&#23545;LLM&#27169;&#22411;&#24178;&#25200;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20219;&#21153;&#20999;&#25442;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2402.18216</link><description>&lt;p&gt;
LLM&#20219;&#21153;&#24178;&#25200;&#65306;&#20851;&#20110;&#23545;&#35805;&#21382;&#21490;&#20013;&#20219;&#21153;&#20999;&#25442;&#24433;&#21709;&#30340;&#21021;&#27493;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18216
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#23545;&#35805;&#20013;&#20219;&#21153;&#20999;&#25442;&#23545;LLM&#27169;&#22411;&#24178;&#25200;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20219;&#21153;&#20999;&#25442;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#24378;&#22823;&#30340;&#25351;&#20196;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#20986;&#29616;&#65292;&#20351;&#24471;&#21508;&#31181;&#26377;&#29992;&#30340;&#23545;&#35805;&#20154;&#24037;&#26234;&#33021;(AI)&#31995;&#32479;&#24050;&#32463;&#37096;&#32626;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#12290;&#24403;&#29992;&#25143;&#25552;&#20986;&#38382;&#39064;&#26102;&#65292;&#36825;&#20123;AI&#31995;&#32479;&#25104;&#21151;&#22320;&#20316;&#20026;&#23545;&#35805;&#30340;&#19968;&#37096;&#20998;&#25191;&#34892;&#21508;&#31181;&#20219;&#21153;&#12290;&#20026;&#20102;&#25552;&#20379;&#26576;&#31181;&#35760;&#24518;&#21644;&#19978;&#19979;&#25991;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#23558;&#36755;&#20986;&#26465;&#20214;&#38480;&#21046;&#22312;&#25972;&#20010;&#23545;&#35805;&#21382;&#21490;&#19978;&#12290;&#23613;&#31649;&#23545;&#23545;&#35805;&#21382;&#21490;&#30340;&#25935;&#24863;&#24615;&#32463;&#24120;&#20250;&#23548;&#33268;&#22312;&#38543;&#21518;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#25552;&#39640;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#65292;&#23454;&#38469;&#19978;&#22914;&#26524;&#26377;&#20219;&#21153;&#20999;&#25442;&#65292;&#34920;&#29616;&#20063;&#21487;&#33021;&#21463;&#21040;&#36127;&#38754;&#24433;&#21709;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#39318;&#27425;&#23581;&#35797;&#27491;&#24335;&#30740;&#31350;&#23545;&#35805;LLMs&#20013;&#30001;&#20110;&#23545;&#35805;&#21382;&#21490;&#20013;&#30340;&#20219;&#21153;&#20999;&#25442;&#32780;&#24341;&#36215;&#30340;&#20219;&#21153;&#24178;&#25200;&#21644;&#24178;&#25200;&#30340;&#33030;&#24369;&#24615;&#12290;&#25105;&#20204;&#22312;5&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#20351;&#29992;&#20102;&#27969;&#34892;&#30340;LLMs&#36827;&#34892;&#20102;15&#27425;&#20219;&#21153;&#20999;&#25442;&#65292;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18216v1 Announce Type: new  Abstract: With the recent emergence of powerful instruction-tuned large language models (LLMs), various helpful conversational Artificial Intelligence (AI) systems have been deployed across many applications. When prompted by users, these AI systems successfully perform a wide range of tasks as part of a conversation. To provide some sort of memory and context, such approaches typically condition their output on the entire conversational history. Although this sensitivity to the conversational history can often lead to improved performance on subsequent tasks, we find that performance can in fact also be negatively impacted, if there is a task-switch. To the best of our knowledge, our work makes the first attempt to formalize the study of such vulnerabilities and interference of tasks in conversational LLMs caused by task-switches in the conversational history. Our experiments across 5 datasets with 15 task switches using popular LLMs reveal that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32858;&#31867;&#19982;&#25490;&#24207;&#26041;&#27861;&#65288;CaR&#65289;&#65292;&#36890;&#36807;&#19982;&#19987;&#23478;&#20559;&#22909;&#30456;&#19968;&#33268;&#30340;&#35780;&#20998;&#27169;&#22411;&#25490;&#21517;&#25351;&#20196;&#23545;&#65292;&#20445;&#30041;&#20102;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.18191</link><description>&lt;p&gt;
&#32858;&#31867;&#19982;&#25490;&#24207;&#65306;&#36890;&#36807;&#19987;&#23478;&#23450;&#20301;&#36136;&#37327;&#20272;&#35745;&#23454;&#29616;&#20445;&#30041;&#22810;&#26679;&#24615;&#30340;&#25351;&#20196;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32858;&#31867;&#19982;&#25490;&#24207;&#26041;&#27861;&#65288;CaR&#65289;&#65292;&#36890;&#36807;&#19982;&#19987;&#23478;&#20559;&#22909;&#30456;&#19968;&#33268;&#30340;&#35780;&#20998;&#27169;&#22411;&#25490;&#21517;&#25351;&#20196;&#23545;&#65292;&#20445;&#30041;&#20102;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#24320;&#28304;&#31038;&#21306;&#30340;&#36129;&#29486;&#65292;&#28044;&#29616;&#20102;&#22823;&#37327;&#25351;&#20196;&#35843;&#20248;&#65288;IT&#65289;&#25968;&#25454;&#12290;&#37492;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#36164;&#28304;&#20998;&#37197;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#37319;&#29992;&#39640;&#25928;&#30340;&#26041;&#27861;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;IT&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25351;&#20196;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#65292;&#27604;&#22914;&#20381;&#36182;&#33030;&#24369;&#30340;&#22806;&#37096;API&#12289;&#21463;GPT&#27169;&#22411;&#20559;&#35265;&#24433;&#21709;&#65292;&#25110;&#20943;&#23569;&#25152;&#36873;&#25351;&#20196;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#24037;&#19994;&#30340;&#12289;&#19982;&#19987;&#23478;&#23450;&#20301;&#30456;&#21563;&#21512;&#24182;&#20445;&#30041;&#22810;&#26679;&#24615;&#30340;&#25351;&#20196;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#65306;&#32858;&#31867;&#19982;&#25490;&#24207;&#65288;CaR&#65289;&#12290;CaR&#20998;&#20026;&#20004;&#20010;&#27493;&#39588;&#12290;&#31532;&#19968;&#27493;&#28041;&#21450;&#20351;&#29992;&#19982;&#19987;&#23478;&#20559;&#22909;&#24456;&#22909;&#23545;&#40784;&#30340;&#35780;&#20998;&#27169;&#22411;&#23545;&#25351;&#20196;&#23545;&#36827;&#34892;&#25490;&#21517;&#65288;&#20934;&#30830;&#29575;&#36798;&#21040;84.25%&#65289;&#12290;&#31532;&#20108;&#27493;&#36890;&#36807;&#32858;&#31867;&#36807;&#31243;&#20445;&#30041;&#25968;&#25454;&#38598;&#22810;&#26679;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;CaR&#36873;&#25321;&#20102;&#19968;&#20010;&#23376;&#38598;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18191v1 Announce Type: new  Abstract: With contributions from the open-source community, a vast amount of instruction tuning (IT) data has emerged. Given the significant resource allocation required by training and evaluating models, it is advantageous to have an efficient method for selecting high-quality IT data. However, existing methods for instruction data selection have limitations such as relying on fragile external APIs, being affected by biases in GPT models, or reducing the diversity of the selected instruction dataset. In this paper, we propose an industrial-friendly, expert-aligned and diversity-preserved instruction data selection method: Clustering and Ranking (CaR). CaR consists of two steps. The first step involves ranking instruction pairs using a scoring model that is well aligned with expert preferences (achieving an accuracy of 84.25%). The second step involves preserving dataset diversity through a clustering process.In our experiment, CaR selected a sub
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#35757;&#32451;&#21487;&#33021;&#20250;&#36896;&#25104;&#23545;&#25239;&#24615;&#24378;&#21270;&#23398;&#20064;&#30340;&#24187;&#35273;&#65292;&#30740;&#31350;&#34920;&#26126;&#36890;&#36807;&#27979;&#35797;&#26102;&#38388;&#28201;&#24230;&#32553;&#25918;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24187;&#35273;&#12290;</title><link>https://arxiv.org/abs/2402.17509</link><description>&lt;p&gt;
&#26497;&#31471;&#22833;&#35843;&#19982;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Extreme Miscalibration and the Illusion of Adversarial Robustness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17509
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#35757;&#32451;&#21487;&#33021;&#20250;&#36896;&#25104;&#23545;&#25239;&#24615;&#24378;&#21270;&#23398;&#20064;&#30340;&#24187;&#35273;&#65292;&#30740;&#31350;&#34920;&#26126;&#36890;&#36807;&#27979;&#35797;&#26102;&#38388;&#28201;&#24230;&#32553;&#25918;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24187;&#35273;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#24494;&#23567;&#30340;&#25200;&#21160;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#35823;&#20998;&#31867;&#12290;&#23545;&#25239;&#35757;&#32451;&#65288;AT&#65289;&#32463;&#24120;&#34987;&#29992;&#26469;&#25552;&#21319;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#29616;&#35937;&#65306;&#26377;&#24847;&#25110;&#26080;&#24847;&#22320;&#22833;&#35843;&#27169;&#22411;&#20250;&#25513;&#30422;&#26799;&#24230;&#65292;&#20174;&#32780;&#24178;&#25200;&#23545;&#25239;&#25915;&#20987;&#25628;&#32034;&#26041;&#27861;&#65292;&#23548;&#33268;&#34920;&#38754;&#19978;&#30475;&#20284;&#22686;&#21152;&#20102;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#35266;&#23519;&#21040;&#30340;&#40065;&#26834;&#24615;&#22686;&#30410;&#26159;&#19968;&#31181;&#40065;&#26834;&#24615;&#24187;&#35273;&#65288;IOR&#65289;&#65292;&#24182;&#23637;&#31034;&#20102;&#23545;&#25163;&#22914;&#20309;&#25191;&#34892;&#21508;&#31181;&#24418;&#24335;&#30340;&#27979;&#35797;&#26102;&#38388;&#28201;&#24230;&#26657;&#20934;&#26469;&#25269;&#28040;&#19978;&#36848;&#24178;&#25200;&#65292;&#20351;&#23545;&#25239;&#25915;&#20987;&#33021;&#22815;&#25214;&#21040;&#23545;&#25239;&#26679;&#26412;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25958;&#20419;NLP&#31038;&#21306;&#22312;&#20854;&#40065;&#26834;&#24615;&#35780;&#20272;&#20013;&#32435;&#20837;&#27979;&#35797;&#26102;&#38388;&#28201;&#24230;&#32553;&#25918;&#65292;&#20197;&#30830;&#20445;&#35266;&#23519;&#21040;&#30340;&#20219;&#20309;&#22686;&#30410;&#37117;&#26159;&#30495;&#23454;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17509v1 Announce Type: new  Abstract: Deep learning-based Natural Language Processing (NLP) models are vulnerable to adversarial attacks, where small perturbations can cause a model to misclassify. Adversarial Training (AT) is often used to increase model robustness. However, we have discovered an intriguing phenomenon: deliberately or accidentally miscalibrating models masks gradients in a way that interferes with adversarial attack search methods, giving rise to an apparent increase in robustness. We show that this observed gain in robustness is an illusion of robustness (IOR), and demonstrate how an adversary can perform various forms of test-time temperature calibration to nullify the aforementioned interference and allow the adversarial attack to find adversarial examples. Hence, we urge the NLP community to incorporate test-time temperature scaling into their robustness evaluations to ensure that any observed gains are genuine. Finally, we show how the temperature can 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35780;&#20272;&#22120;&#20013;&#30340;&#20284;&#28982;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#36825;&#31181;&#20559;&#24046;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.15987</link><description>&lt;p&gt;
&#22522;&#20110;&#20284;&#28982;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20559;&#24046;&#30340;&#32531;&#35299;
&lt;/p&gt;
&lt;p&gt;
Likelihood-based Mitigation of Evaluation Bias in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15987
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35780;&#20272;&#22120;&#20013;&#30340;&#20284;&#28982;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#36825;&#31181;&#20559;&#24046;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#34987;&#24191;&#27867;&#29992;&#20110;&#35780;&#20272;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#30340;&#33258;&#21160;&#21270;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#20284;&#28982;&#20316;&#20026;&#34913;&#37327;LLM&#23545;&#21477;&#23376;&#21487;&#20449;&#24230;&#30340;&#25351;&#26631;&#65292;&#21487;&#33021;&#20250;&#22240;&#21477;&#23376;&#34920;&#38754;&#24046;&#24322;&#65288;&#22914;&#35789;&#24207;&#21644;&#21477;&#23376;&#32467;&#26500;&#65289;&#32780;&#21464;&#21270;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#23558;LLMs&#29992;&#20110;&#35780;&#20272;&#65292;&#21487;&#33021;&#23384;&#22312;&#20284;&#28982;&#20559;&#24046;&#65306;&#23427;&#20204;&#21487;&#33021;&#20250;&#39640;&#20272;&#20855;&#26377;&#36739;&#39640;&#20284;&#28982;&#24615;&#30340;&#21477;&#23376;&#65292;&#32780;&#20302;&#20272;&#20855;&#26377;&#36739;&#20302;&#20284;&#28982;&#24615;&#30340;&#21477;&#23376;&#12290;&#26412;&#25991;&#23545;LLM&#35780;&#20272;&#22120;&#20013;&#20284;&#28982;&#20559;&#24046;&#30340;&#23384;&#22312;&#21644;&#24433;&#21709;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#20284;&#28982;&#20559;&#24046;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#39640;&#24230;&#20559;&#32622;&#30340;&#23454;&#20363;&#20316;&#20026;&#23569;&#26679;&#26412;&#31034;&#20363;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#25105;&#20204;&#22312;&#35780;&#20272;&#25968;&#25454;&#21040;&#25991;&#26412;&#21644;&#35821;&#27861;&#38169;&#35823;&#32416;&#27491;&#20219;&#21153;&#26102;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#27979;&#35797;&#30340;&#20960;&#31181;LLMs&#26174;&#31034;&#20986;&#20284;&#28982;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#25104;&#21151;&#22320;&#20943;&#36731;&#20102;&#36825;&#31181;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15987v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics. However, the likelihood, a measure of LLM's plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure. It is therefore possible that there might be a likelihood bias if LLMs are used for evaluation: they might overrate sentences with higher likelihoods while underrating those with lower likelihoods. In this paper, we investigate the presence and impact of likelihood bias in LLM-based evaluators. We also propose a method to mitigate the likelihood bias. Our method utilizes highly biased instances as few-shot examples for in-context learning. Our experiments in evaluating the data-to-text and grammatical error correction tasks reveal that several LLMs we test display a likelihood bias. Furthermore, our proposed method successfully mitigates this bias, also impr
&lt;/p&gt;</description></item><item><title>&#31036;&#35980;&#27700;&#24179;&#23545;LLMs&#30340;&#34920;&#29616;&#26377;&#24433;&#21709;&#65292;&#31895;&#40065;&#30340;&#25552;&#31034;&#36890;&#24120;&#23548;&#33268;&#36739;&#24046;&#30340;&#34920;&#29616;&#65292;&#32780;&#36807;&#20110;&#31036;&#35980;&#30340;&#35821;&#35328;&#24182;&#19981;&#33021;&#20445;&#35777;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#26368;&#20339;&#30340;&#31036;&#35980;&#27700;&#24179;&#26681;&#25454;&#35821;&#35328;&#32780;&#24322;&#65292;LLMs&#19981;&#20165;&#21453;&#26144;&#20154;&#31867;&#34892;&#20026;&#65292;&#36824;&#21463;&#35821;&#35328;&#24433;&#21709;&#65292;&#23588;&#20854;&#26159;&#22312;&#19981;&#21516;&#30340;&#25991;&#21270;&#32972;&#26223;&#19979;&#12290;</title><link>https://arxiv.org/abs/2402.14531</link><description>&lt;p&gt;
&#25105;&#20204;&#24212;&#35813;&#23562;&#37325;LLM&#21527;&#65311;&#20851;&#20110;&#25552;&#31034;&#31036;&#35980;&#23545;LLM&#34920;&#29616;&#24433;&#21709;&#30340;&#36328;&#35821;&#35328;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14531
&lt;/p&gt;
&lt;p&gt;
&#31036;&#35980;&#27700;&#24179;&#23545;LLMs&#30340;&#34920;&#29616;&#26377;&#24433;&#21709;&#65292;&#31895;&#40065;&#30340;&#25552;&#31034;&#36890;&#24120;&#23548;&#33268;&#36739;&#24046;&#30340;&#34920;&#29616;&#65292;&#32780;&#36807;&#20110;&#31036;&#35980;&#30340;&#35821;&#35328;&#24182;&#19981;&#33021;&#20445;&#35777;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#26368;&#20339;&#30340;&#31036;&#35980;&#27700;&#24179;&#26681;&#25454;&#35821;&#35328;&#32780;&#24322;&#65292;LLMs&#19981;&#20165;&#21453;&#26144;&#20154;&#31867;&#34892;&#20026;&#65292;&#36824;&#21463;&#35821;&#35328;&#24433;&#21709;&#65292;&#23588;&#20854;&#26159;&#22312;&#19981;&#21516;&#30340;&#25991;&#21270;&#32972;&#26223;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35843;&#26597;&#20102;&#25552;&#31034;&#20013;&#30340;&#31036;&#35980;&#31243;&#24230;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34920;&#29616;&#30340;&#24433;&#21709;&#12290;&#22312;&#20154;&#31867;&#20132;&#27969;&#20013;&#65292;&#31036;&#35980;&#30340;&#35821;&#35328;&#36890;&#24120;&#33021;&#33719;&#24471;&#26356;&#22810;&#30340;&#36981;&#20174;&#21644;&#26377;&#25928;&#24615;&#65292;&#32780;&#31895;&#40065;&#21487;&#33021;&#23548;&#33268;&#21388;&#24694;&#65292;&#24433;&#21709;&#22238;&#24212;&#36136;&#37327;&#12290;&#25105;&#20204;&#35748;&#20026;LLMs&#21453;&#26144;&#20102;&#20154;&#31867;&#30340;&#20132;&#27969;&#29305;&#24449;&#65292;&#26263;&#31034;&#23427;&#20204;&#19982;&#20154;&#31867;&#25991;&#21270;&#35268;&#33539;&#19968;&#33268;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#33521;&#35821;&#12289;&#20013;&#25991;&#21644;&#26085;&#35821;&#20219;&#21153;&#20013;&#25552;&#31034;&#20013;&#30340;&#31036;&#35980;&#23545;LLMs&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#31895;&#40065;&#30340;&#25552;&#31034;&#36890;&#24120;&#23548;&#33268;&#36739;&#24046;&#30340;&#34920;&#29616;&#65292;&#32780;&#36807;&#20110;&#31036;&#35980;&#30340;&#35821;&#35328;&#24182;&#19981;&#33021;&#20445;&#35777;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#26368;&#20339;&#30340;&#31036;&#35980;&#31243;&#24230;&#26681;&#25454;&#35821;&#35328;&#32780;&#24322;&#12290;&#36825;&#19968;&#29616;&#35937;&#34920;&#26126;LLMs&#19981;&#20165;&#21453;&#26144;&#20154;&#31867;&#34892;&#20026;&#65292;&#36824;&#21463;&#35821;&#35328;&#24433;&#21709;&#65292;&#23588;&#20854;&#26159;&#22312;&#19981;&#21516;&#30340;&#25991;&#21270;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#36328;&#25991;&#21270;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;LLM&#20351;&#29992;&#20013;&#32771;&#34385;&#31036;&#35980;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14531v1 Announce Type: new  Abstract: We investigate the impact of politeness levels in prompts on the performance of large language models (LLMs). Polite language in human communications often garners more compliance and effectiveness, while rudeness can cause aversion, impacting response quality. We consider that LLMs mirror human communication traits, suggesting they align with human cultural norms. We assess the impact of politeness in prompts on LLMs across English, Chinese, and Japanese tasks. We observed that impolite prompts often result in poor performance, but overly polite language does not guarantee better outcomes. The best politeness level is different according to the language. This phenomenon suggests that LLMs not only reflect human behavior but are also influenced by language, particularly in different cultural contexts. Our findings highlight the need to factor in politeness for cross-cultural natural language processing and LLM usage.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#32500;&#24230;&#30340;&#20849;&#24773;&#35780;&#20272;&#26694;&#26550;&#65292;&#21516;&#26102;&#34913;&#37327;&#20102;&#35828;&#35805;&#32773;&#35282;&#24230;&#30340;&#34920;&#36798;&#24847;&#22270;&#21644;&#21548;&#32773;&#35282;&#24230;&#30340;&#24863;&#30693;&#20849;&#24773;&#65292;&#30740;&#31350;&#21457;&#29616;&#20108;&#32773;&#26159;&#30456;&#20114;&#20851;&#32852;&#30340;&#65292;&#24863;&#30693;&#20849;&#24773;&#19982;&#23545;&#35805;&#20250;&#35805;&#30340;&#28385;&#24847;&#27700;&#24179;&#21576;&#39640;&#30456;&#20851;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11409</link><description>&lt;p&gt;
&#22810;&#32500;&#24230;&#35780;&#20272;&#20849;&#24773;&#23545;&#35805;&#22238;&#22797;
&lt;/p&gt;
&lt;p&gt;
Multi-dimensional Evaluation of Empathetic Dialog Responses
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11409
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#32500;&#24230;&#30340;&#20849;&#24773;&#35780;&#20272;&#26694;&#26550;&#65292;&#21516;&#26102;&#34913;&#37327;&#20102;&#35828;&#35805;&#32773;&#35282;&#24230;&#30340;&#34920;&#36798;&#24847;&#22270;&#21644;&#21548;&#32773;&#35282;&#24230;&#30340;&#24863;&#30693;&#20849;&#24773;&#65292;&#30740;&#31350;&#21457;&#29616;&#20108;&#32773;&#26159;&#30456;&#20114;&#20851;&#32852;&#30340;&#65292;&#24863;&#30693;&#20849;&#24773;&#19982;&#23545;&#35805;&#20250;&#35805;&#30340;&#28385;&#24847;&#27700;&#24179;&#21576;&#39640;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#24773;&#26159;&#26377;&#25928;&#21644;&#20196;&#20154;&#28385;&#24847;&#30340;&#23545;&#35805;&#27807;&#36890;&#30340;&#20851;&#38190;&#20803;&#32032;&#65292;&#28982;&#32780;&#20808;&#21069;&#30340;&#30740;&#31350;&#22823;&#22810;&#38598;&#20013;&#22312;&#34913;&#37327;&#34920;&#36798;&#30340;&#27807;&#36890;&#24847;&#22270;&#19978;&#8212;&#8212;&#21363;&#20849;&#24773;&#26159;&#22914;&#20309;&#34920;&#36798;&#30340;&#65292;&#24573;&#30053;&#20102;&#23545;&#35805;&#20063;&#26159;&#19968;&#31181;&#28041;&#21450;&#35828;&#35805;&#32773;&#21644;&#32838;&#21548;&#32773;&#30340;&#21327;&#20316;&#23454;&#36341;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#32500;&#24230;&#30340;&#20849;&#24773;&#35780;&#20272;&#26694;&#26550;&#65292;&#25193;&#23637;&#20102;&#29616;&#26377;&#24037;&#20316;&#65292;&#20197;&#34913;&#37327;&#20174;&#35828;&#35805;&#32773;&#35282;&#24230;&#34920;&#36798;&#30340;&#24847;&#22270;&#20197;&#21450;&#20174;&#21548;&#32773;&#35282;&#24230;&#24863;&#30693;&#21040;&#30340;&#20849;&#24773;&#12290;&#23558;&#25552;&#20986;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;&#20998;&#26512;&#25105;&#20204;&#20869;&#37096;&#30340;&#23458;&#25143;&#26381;&#21153;&#23545;&#35805;&#34920;&#26126;&#65292;&#36825;&#20004;&#20010;&#32500;&#24230;&#65288;&#34920;&#36798;&#30340;&#24847;&#22270;&#31867;&#22411;&#21644;&#24863;&#30693;&#21040;&#30340;&#20849;&#24773;&#65289;&#26159;&#30456;&#20114;&#20851;&#32852;&#30340;&#65292;&#32780;&#24863;&#30693;&#21040;&#30340;&#20849;&#24773;&#19982;&#23545;&#35805;&#20250;&#35805;&#30340;&#28385;&#24847;&#27700;&#24179;&#20855;&#26377;&#24456;&#39640;&#30340;&#30456;&#20851;&#24615;&#12290;&#36825;&#20010;&#25552;&#20986;&#30340;&#26694;&#26550;&#20173;&#38656;&#35201;&#21463;&#36807;&#35757;&#32451;&#30340;&#27880;&#37322;&#21592;&#30340;&#20027;&#35266;&#35780;&#20272;&#65292;&#36825;&#21487;&#33021;&#24182;&#19981;&#23481;&#26131;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11409v1 Announce Type: new  Abstract: Empathy is a critical element of effective and satisfactory conversational communication, yet previous studies in measuring conversational empathy mostly focus on expressed communicative intents -- in which way empathy is expressed, ignoring the fact that conversation is also a collaborative practice involving both speakers and listeners. In contrast, we propose a multi-dimensional empathy evaluation framework that extends upon existing work to measure both expressed intents from the speaker's perspective and perceived empathy from the listener's perspective. Applying the proposed framework to analyzing our internal customer-service dialogue shows that the two dimensions (expressed intent types and perceived empathy) are inter-connected, while perceived empathy has high correlation with the satisfactory level of dialogue sessions. This proposed framework still requires subjective assessments from trained annotators, which can be non-triv
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;PANDA&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#35780;&#27979;&#26041;&#24335;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#33258;&#21160;&#35780;&#20272;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.11161</link><description>&lt;p&gt;
PANDA&#65288;Pedantic ANswer-correctness Determination and Adjudication&#65289;&#65306;&#25913;&#36827;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#30340;&#33258;&#21160;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11161
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;PANDA&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#35780;&#27979;&#26041;&#24335;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#33258;&#21160;&#35780;&#20272;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38382;&#31572;&#65288;QA&#65289;&#21482;&#26377;&#22312;&#25105;&#20204;&#30693;&#36947;&#31572;&#26696;&#26159;&#21542;&#27491;&#30830;&#26102;&#25165;&#33021;&#21462;&#24471;&#36827;&#23637;&#65292;&#20294;&#23545;&#20110;&#35768;&#22810;&#26368;&#20855;&#25361;&#25112;&#24615;&#21644;&#26377;&#36259;&#30340;QA&#31034;&#20363;&#65292;&#24403;&#21069;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#65288;AC&#65289;&#25351;&#26631;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#65292;&#29305;&#21035;&#26159;&#26469;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20887;&#38271;&#12289;&#33258;&#30001;&#26684;&#24335;&#31572;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#25361;&#25112;&#65306;&#32570;&#20047;&#25968;&#25454;&#21644;&#27169;&#22411;&#36807;&#22823;&#12290;&#22522;&#20110;LLM&#30340;&#35780;&#20998;&#22120;&#19982;&#20154;&#31867;&#26356;&#22909;&#22320;&#30456;&#20851;&#65292;&#20294;&#36825;&#39033;&#26114;&#36149;&#30340;&#20219;&#21153;&#20165;&#22312;&#26377;&#38480;&#30340;QA&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#28165;&#26224;&#30340;&#25351;&#21335;&#26469;&#35780;&#20272;&#20174;&#20154;&#31867;QA&#27604;&#36187;&#20013;&#37319;&#32435;&#30340;&#26426;&#22120;QA&#65292;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#31934;&#30830;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#30830;&#23450;&#21644;&#35009;&#20915;&#65288;Precise ANswer correctness Determination and Adjudication&#65292;PANDA&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#23567;&#24039;&#12289;&#39640;&#25928;&#12289;&#30830;&#23450;&#24615;&#30340;AC&#20998;&#31867;&#22120;&#65288;812 KB&#65289;&#65292;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#31572;&#26696;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11161v1 Announce Type: cross  Abstract: Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current answer correctness (AC) metrics do not align with human judgments, particularly verbose, free form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big. LLM based scorers correlate better with humans, but this expensive task has only been tested on limited QA datasets. We rectify these issues by providing clear guidelines for evaluating machine QA adopted from human QA contests. We also introduce Precise ANswer correctness Determination and Adjudication (PANDA), a small, efficient, deterministic AC classifier (812 KB) that more accurately evaluates answer correctness.
&lt;/p&gt;</description></item><item><title>BitDelta&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#20449;&#24687;&#20887;&#20313;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BitDelta&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#28155;&#21152;&#30340;&#20449;&#24687;&#37327;&#21270;&#20026;&#19968;&#20010;&#27604;&#29305;&#65292;&#21516;&#26102;&#20445;&#25345;&#24615;&#33021;&#12290;&#36825;&#19968;&#21457;&#29616;&#23545;&#20110;&#22810;&#31199;&#25143;&#27169;&#22411;&#30340;&#26381;&#21153;&#21644;&#23384;&#20648;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;GPU&#20869;&#23384;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.10193</link><description>&lt;p&gt;
BitDelta&#65306;&#20320;&#30340;&#24494;&#35843;&#21487;&#33021;&#21482;&#26377;&#19968;&#20010;&#27604;&#29305;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
BitDelta: Your Fine-Tune May Only Be Worth One Bit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10193
&lt;/p&gt;
&lt;p&gt;
BitDelta&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#20449;&#24687;&#20887;&#20313;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BitDelta&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#28155;&#21152;&#30340;&#20449;&#24687;&#37327;&#21270;&#20026;&#19968;&#20010;&#27604;&#29305;&#65292;&#21516;&#26102;&#20445;&#25345;&#24615;&#33021;&#12290;&#36825;&#19968;&#21457;&#29616;&#23545;&#20110;&#22810;&#31199;&#25143;&#27169;&#22411;&#30340;&#26381;&#21153;&#21644;&#23384;&#20648;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;GPU&#20869;&#23384;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#24120;&#22312;&#20004;&#20010;&#38454;&#27573;&#36827;&#34892;&#35757;&#32451;&#65306;&#22312;&#22823;&#35268;&#27169;&#20114;&#32852;&#32593;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#30340;&#39640;&#35745;&#31639;&#38656;&#27714;&#65292;&#30452;&#35273;&#19978;&#35748;&#20026;&#24494;&#35843;&#23545;&#27169;&#22411;&#30340;&#20449;&#24687;&#28155;&#21152;&#36739;&#23569;&#65292;&#22240;&#27492;&#26356;&#20855;&#26377;&#21487;&#21387;&#32553;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#24494;&#35843;&#27169;&#22411;&#30340;&#26435;&#37325;&#20998;&#35299;&#20026;&#39044;&#35757;&#32451;&#32452;&#20214;&#21644;&#39069;&#22806;&#30340;&#22686;&#37327;&#26469;&#25506;&#31350;&#36825;&#19968;&#20551;&#35774;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#8212;&#8212;BitDelta&#65292;&#25104;&#21151;&#22320;&#23558;&#36825;&#20010;&#22686;&#37327;&#37327;&#21270;&#20026;1&#27604;&#29305;&#32780;&#19981;&#24433;&#21709;&#24615;&#33021;&#12290;&#36825;&#19968;&#26377;&#36259;&#30340;&#21457;&#29616;&#19981;&#20165;&#31361;&#26174;&#20102;&#24494;&#35843;&#36807;&#31243;&#20013;&#28155;&#21152;&#30340;&#20449;&#24687;&#30340;&#28508;&#22312;&#20887;&#20313;&#24615;&#65292;&#32780;&#19988;&#23545;&#20110;&#22810;&#31199;&#25143;&#27169;&#22411;&#30340;&#26381;&#21153;&#21644;&#23384;&#20648;&#20063;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#39640;&#31934;&#24230;&#30340;&#22522;&#30784;&#27169;&#22411;&#20197;&#21450;&#22810;&#20010;1&#27604;&#29305;&#30340;&#22686;&#37327;&#65292;BitDelta&#22823;&#22823;&#38477;&#20302;&#20102;GPU&#20869;&#23384;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10193v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are typically trained in two phases: pre-training on large internet-scale datasets, and fine-tuning for downstream tasks. Given the higher computational demand of pre-training, it's intuitive to assume that fine-tuning adds less new information to the model, and is thus more compressible. We explore this assumption by decomposing the weights of fine-tuned models into their pre-trained components and an additional delta. We introduce a simple method, BitDelta, which successfully quantizes this delta down to 1 bit without compromising performance. This interesting finding not only highlights the potential redundancy of information added during fine-tuning, but also has significant implications for the multi-tenant serving and multi-tenant storage of fine-tuned models. By enabling the use of a single high-precision base model accompanied by multiple 1-bit deltas, BitDelta dramatically reduces GPU memory requir
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#25209;&#21028;&#24615;&#35780;&#20272;&#30740;&#31350;&#20102;23&#20010;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22522;&#20934;&#30340;&#19981;&#36275;&#20043;&#22788;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#30495;&#23454;&#25512;&#29702;&#34913;&#37327;&#22256;&#38590;&#12289;&#23454;&#29616;&#19981;&#19968;&#33268;&#24615;&#31561;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#22312;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#38656;&#35201;&#26631;&#20934;&#21270;&#26041;&#27861;&#12289;&#30417;&#31649;&#30830;&#23450;&#24615;&#21644;&#20262;&#29702;&#25351;&#21335;&#12290;</title><link>https://arxiv.org/abs/2402.09880</link><description>&lt;p&gt;
&#22312;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22522;&#20934;&#30340;&#19981;&#36275;&#20043;&#22788;
&lt;/p&gt;
&lt;p&gt;
Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09880
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#25209;&#21028;&#24615;&#35780;&#20272;&#30740;&#31350;&#20102;23&#20010;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22522;&#20934;&#30340;&#19981;&#36275;&#20043;&#22788;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#30495;&#23454;&#25512;&#29702;&#34913;&#37327;&#22256;&#38590;&#12289;&#23454;&#29616;&#19981;&#19968;&#33268;&#24615;&#31561;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#22312;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#38656;&#35201;&#26631;&#20934;&#21270;&#26041;&#27861;&#12289;&#30417;&#31649;&#30830;&#23450;&#24615;&#21644;&#20262;&#29702;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#38543;&#30528;&#20854;&#26032;&#20852;&#33021;&#21147;&#30340;&#24555;&#36895;&#23835;&#36215;&#65292;&#24341;&#21457;&#20102;&#20844;&#20247;&#30340;&#22909;&#22855;&#24515;&#65292;&#20197;&#35780;&#20272;&#21644;&#27604;&#36739;&#19981;&#21516;&#30340;LLMs&#65292;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#20182;&#20204;&#30340;LLM&#22522;&#20934;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#36825;&#20123;&#22522;&#20934;&#30340;&#21021;&#27493;&#19981;&#36275;&#65292;&#24320;&#22987;&#20102;&#19968;&#39033;&#30740;&#31350;&#65292;&#36890;&#36807;&#20154;&#20204;&#12289;&#36807;&#31243;&#21644;&#25216;&#26415;&#30340;&#35270;&#35282;&#65292;&#20197;&#21151;&#33021;&#21644;&#23433;&#20840;&#20004;&#22823;&#25903;&#26609;&#20026;&#22522;&#30784;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340;&#26032;&#39062;&#32479;&#19968;&#35780;&#20272;&#26694;&#26550;&#23545;23&#20010;&#26368;&#20808;&#36827;&#30340;LLM&#22522;&#20934;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#19968;&#20123;&#37325;&#22823;&#38480;&#21046;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#27979;&#37327;&#30495;&#23454;&#25512;&#29702;&#30340;&#22256;&#38590;&#12289;&#36866;&#24212;&#24615;&#12289;&#23454;&#29616;&#19981;&#19968;&#33268;&#24615;&#12289;&#25552;&#31034;&#24037;&#31243;&#22797;&#26434;&#24615;&#12289;&#35780;&#20272;&#32773;&#22810;&#26679;&#24615;&#20197;&#21450;&#22312;&#19968;&#27425;&#32508;&#21512;&#35780;&#20272;&#20013;&#24573;&#35270;&#20102;&#25991;&#21270;&#21644;&#24847;&#35782;&#24418;&#24577;&#35268;&#33539;&#12290;&#25105;&#20204;&#30340;&#35752;&#35770;&#24378;&#35843;&#20102;&#22312;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#65292;&#36843;&#20999;&#38656;&#35201;&#26631;&#20934;&#21270;&#26041;&#27861;&#12289;&#30417;&#31649;&#30830;&#23450;&#24615;&#21644;&#20262;&#29702;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09880v1 Announce Type: new  Abstract: The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of functionality and security. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligenc
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28176;&#36827;&#23376;&#32593;&#32476;&#35757;&#32451;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#20998;&#38454;&#27573;&#39044;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;&#26089;&#26399;&#38454;&#27573;&#26080;&#27861;&#35780;&#20272;&#23436;&#25972;&#27169;&#22411;&#21644;&#27169;&#22411;&#36136;&#37327;&#19979;&#38477;&#31561;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.05913</link><description>&lt;p&gt;
&#36890;&#36807;&#28176;&#36827;&#23376;&#32593;&#32476;&#23454;&#29616;&#39640;&#25928;&#30340;&#20998;&#38454;&#27573;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Efficient Stagewise Pretraining via Progressive Subnetworks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05913
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28176;&#36827;&#23376;&#32593;&#32476;&#35757;&#32451;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#20998;&#38454;&#27573;&#39044;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;&#26089;&#26399;&#38454;&#27573;&#26080;&#27861;&#35780;&#20272;&#23436;&#25972;&#27169;&#22411;&#21644;&#27169;&#22411;&#36136;&#37327;&#19979;&#38477;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21457;&#23637;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#39640;&#25928;&#39044;&#35757;&#32451;&#26041;&#27861;&#30340;&#20851;&#27880;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#26377;&#25928;&#33539;&#20363;&#26159;&#36827;&#34892;&#20998;&#38454;&#27573;&#35757;&#32451;&#65292;&#21363;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#30340;&#22823;&#23567;&#65288;&#20363;&#22914;&#36880;&#28176;&#21472;&#21152;&#65288;Reddi&#31561;&#20154;&#65292;2023&#24180;&#65289;&#65289;&#12290;&#34429;&#28982;&#36164;&#28304;&#21644;&#22681;&#38047;&#26102;&#38388;&#30340;&#33410;&#30465;&#24456;&#21560;&#24341;&#20154;&#65292;&#20294;&#23427;&#20063;&#26377;&#23616;&#38480;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#26089;&#26399;&#38454;&#27573;&#26080;&#27861;&#35780;&#20272;&#23436;&#25972;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#30001;&#20110;&#21021;&#22987;&#38454;&#27573;&#27169;&#22411;&#23481;&#37327;&#36739;&#23567;&#32780;&#23548;&#33268;&#27169;&#22411;&#36136;&#37327;&#19979;&#38477;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#24615;&#26694;&#26550;&#65292;&#21363;&#28176;&#36827;&#23376;&#32593;&#32476;&#35757;&#32451;&#65292;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#23436;&#25972;&#30340;&#27169;&#22411;&#65292;&#20294;&#27599;&#20010;&#27493;&#39588;&#21482;&#35757;&#32451;&#27169;&#22411;&#20013;&#30340;&#23376;&#32593;&#32476;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#36825;&#20010;&#26694;&#26550;&#30340;&#19968;&#20010;&#31616;&#21333;&#23454;&#20363;&#65292;&#21363;&#38543;&#26426;&#36335;&#24452;&#35757;&#32451;&#65288;RaPTr&#65289;&#65292;&#23427;&#22312;&#27599;&#20010;&#27493;&#39588;&#20013;&#21482;&#35757;&#32451;&#19968;&#26465;&#23376;&#36335;&#24452;&#65292;&#36880;&#28176;&#22686;&#21152;&#36335;&#24452;&#38271;&#24230;&#12290;RaPTr&#22312;BERT&#21644;UL2&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#25439;&#22833;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#21482;&#38656;&#35201;2
&lt;/p&gt;
&lt;p&gt;
Recent developments in large language models have sparked interest in efficient pretraining methods. A recent effective paradigm is to perform stage-wise training, where the size of the model is gradually increased over the course of training (e.g. gradual stacking (Reddi et al., 2023)). While the resource and wall-time savings are appealing, it has limitations, particularly the inability to evaluate the full model during earlier stages, and degradation in model quality due to smaller model capacity in the initial stages. In this work, we propose an alternative framework, progressive subnetwork training, that maintains the full model throughout training, but only trains subnetworks within the model in each step. We focus on a simple instantiation of this framework, Random Path Training (RaPTr) that only trains a sub-path of layers in each step, progressively increasing the path lengths in stages. RaPTr achieves better pre-training loss for BERT and UL2 language models while requiring 2
&lt;/p&gt;</description></item><item><title>AutoTimes&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#36716;&#25442;&#33021;&#21147;&#26469;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#19982;&#20808;&#21069;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02370</link><description>&lt;p&gt;
AutoTimes: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
AutoTimes: Autoregressive Time Series Forecasters via Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02370
&lt;/p&gt;
&lt;p&gt;
AutoTimes&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#36716;&#25442;&#33021;&#21147;&#26469;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#19982;&#20808;&#21069;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#30340;&#26377;&#38480;&#21487;&#29992;&#24615;&#21644;&#21487;&#25193;&#23637;&#39044;&#35757;&#32451;&#30340;&#19981;&#20805;&#20998;&#25506;&#32034;&#65292;&#26102;&#38388;&#24207;&#21015;&#30340;&#22522;&#30784;&#27169;&#22411;&#23578;&#26410;&#23436;&#20840;&#21457;&#23637;&#12290;&#22522;&#20110;&#26102;&#38388;&#24207;&#21015;&#21644;&#33258;&#28982;&#35821;&#35328;&#30340;&#30456;&#20284;&#39034;&#24207;&#32467;&#26500;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#35777;&#26126;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#30340;&#21487;&#34892;&#24615;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#26041;&#27861;&#21487;&#33021;&#24573;&#35270;&#20102;&#26102;&#38388;&#24207;&#21015;&#21644;&#33258;&#28982;&#35821;&#35328;&#23545;&#40784;&#30340;&#19968;&#33268;&#24615;&#65292;&#23548;&#33268;&#23545;LLM&#28508;&#21147;&#30340;&#21033;&#29992;&#19981;&#36275;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#20174;&#35821;&#35328;&#24314;&#27169;&#20013;&#23398;&#21040;&#30340;&#36890;&#29992;&#20196;&#29260;&#36716;&#25442;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AutoTimes&#65292;&#23558;LLM&#37325;&#26032;&#29992;&#20316;&#33258;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22120;&#65292;&#36825;&#19982;LLM&#30340;&#33719;&#21462;&#21644;&#21033;&#29992;&#19968;&#33268;&#65292;&#32780;&#26080;&#38656;&#26356;&#26032;&#21442;&#25968;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#39044;&#27979;&#22120;&#21487;&#20197;&#22788;&#29702;&#28789;&#27963;&#30340;&#31995;&#21015;&#38271;&#24230;&#65292;&#24182;&#23454;&#29616;&#19982;&#27969;&#34892;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20196;&#29260;&#30340;&#25552;&#31034;&#26041;&#27861;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#26102;&#38388;&#25139;&#26469;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation models of time series have not been fully developed due to the limited availability of large-scale time series and the underexploration of scalable pre-training. Based on the similar sequential structure of time series and natural language, increasing research demonstrates the feasibility of leveraging large language models (LLM) for time series. Nevertheless, prior methods may overlook the consistency in aligning time series and natural language, resulting in insufficient utilization of the LLM potentials. To fully exploit the general-purpose token transitions learned from language modeling, we propose AutoTimes to repurpose LLMs as Autoregressive Time series forecasters, which is consistent with the acquisition and utilization of LLMs without updating the parameters. The consequent forecasters can handle flexible series lengths and achieve competitive performance as prevalent models. Further, we present token-wise prompting that utilizes corresponding timestamps to make ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26465;&#20214;&#21644;&#24773;&#24577;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#38500;&#20102;GPT-4&#22806;&#65292;&#20854;&#20182;&#27169;&#22411;&#22312;&#26465;&#20214;&#21477;&#26041;&#38754;&#23384;&#22312;&#22522;&#26412;&#38169;&#35823;&#65292;&#24182;&#19988;&#21363;&#20351;&#26159;GPT-4&#22312;&#28041;&#21450;&#35748;&#35782;&#24773;&#24577;&#30340;&#25512;&#29702;&#27169;&#24335;&#19978;&#20063;&#26174;&#31034;&#20986;&#36923;&#36753;&#19978;&#19981;&#19968;&#33268;&#30340;&#21028;&#26029;&#12290;</title><link>https://arxiv.org/abs/2401.17169</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26465;&#20214;&#21644;&#24773;&#24577;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Conditional and Modal Reasoning in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17169
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26465;&#20214;&#21644;&#24773;&#24577;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#38500;&#20102;GPT-4&#22806;&#65292;&#20854;&#20182;&#27169;&#22411;&#22312;&#26465;&#20214;&#21477;&#26041;&#38754;&#23384;&#22312;&#22522;&#26412;&#38169;&#35823;&#65292;&#24182;&#19988;&#21363;&#20351;&#26159;GPT-4&#22312;&#28041;&#21450;&#35748;&#35782;&#24773;&#24577;&#30340;&#25512;&#29702;&#27169;&#24335;&#19978;&#20063;&#26174;&#31034;&#20986;&#36923;&#36753;&#19978;&#19981;&#19968;&#33268;&#30340;&#21028;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#30340;&#30740;&#31350;&#27491;&#22312;&#20154;&#24037;&#26234;&#33021;&#21644;&#35748;&#30693;&#31185;&#23398;&#39046;&#22495;&#19981;&#26029;&#22686;&#21152;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#21313;&#20960;&#20010;LLM&#33021;&#21542;&#21306;&#20998;&#36923;&#36753;&#19978;&#27491;&#30830;&#30340;&#25512;&#35770;&#21644;&#36923;&#36753;&#19978;&#33618;&#35884;&#30340;&#25512;&#35770;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#28041;&#21450;&#26465;&#20214;&#21477;&#65288;&#20363;&#22914;&#65292;&#8220;&#22914;&#26524;&#23433;&#26377;&#19968;&#20010;&#30343;&#21518;&#65292;&#37027;&#20040;&#40077;&#21187;&#26377;&#19968;&#20010;J&#29260;&#8221;&#65289;&#21644;&#35748;&#35782;&#24773;&#24577;&#65288;&#20363;&#22914;&#65292;&#8220;&#23433;&#21487;&#33021;&#26377;&#19968;&#20010;A&#29260;&#8221;&#65292;&#8220;&#40077;&#21187;&#24517;&#39035;&#26377;&#19968;&#20010;K&#29260;&#8221;&#65289;&#30340;&#25512;&#29702;&#27169;&#24335;&#12290;&#36825;&#20123;&#25512;&#29702;&#27169;&#24335;&#23545;&#20110;&#36923;&#36753;&#23398;&#23478;&#12289;&#21746;&#23398;&#23478;&#21644;&#35821;&#35328;&#23398;&#23478;&#26469;&#35828;&#20855;&#26377;&#29305;&#27530;&#30340;&#20852;&#36259;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#33021;&#22312;&#20154;&#31867;&#25512;&#29702;&#20013;&#25198;&#28436;&#19968;&#20010;&#26680;&#24515;&#35282;&#33394;&#12290;&#22240;&#27492;&#65292;&#35780;&#20272;LLM&#22312;&#36825;&#20123;&#25512;&#29702;&#27169;&#24335;&#19978;&#30340;&#34920;&#29616;&#19982;&#20154;&#31867;&#30340;&#25512;&#29702;&#33021;&#21147;&#26159;&#21542;&#30456;&#21305;&#37197;&#26159;&#38750;&#24120;&#30456;&#20851;&#30340;&#12290;&#22312;&#25105;&#20204;&#27979;&#35797;&#30340;LLM&#20013;&#65292;&#38500;&#20102;GPT-4&#65292;&#20854;&#20182;&#37117;&#24120;&#24120;&#22312;&#26465;&#20214;&#21477;&#26041;&#38754;&#29359;&#22522;&#26412;&#38169;&#35823;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#26159;GPT-4&#65292;&#22312;&#28041;&#21450;&#35748;&#35782;&#24773;&#24577;&#30340;&#25512;&#29702;&#27169;&#24335;&#19978;&#20063;&#26174;&#31034;&#20986;&#36923;&#36753;&#19978;&#19981;&#19968;&#33268;&#30340;&#21028;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reasoning abilities of large language models (LLMs) are the topic of a growing body of research in artificial intelligence and cognitive science. In this paper, we probe the extent to which a dozen LLMs are able to distinguish logically correct inferences from logically fallacious ones. We focus on inference patterns involving conditionals (e.g., 'If Ann has a queen, then Bob has a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob must have a king'). These inference patterns have been of special interest to logicians, philosophers, and linguists, since they plausibly play a central role in human reasoning. Assessing LLMs on these inference patterns is thus highly relevant to the question of how much the reasoning abilities of LLMs match those of humans. Among the LLMs we tested, all but GPT-4 often make basic mistakes with conditionals. Moreover, even GPT-4 displays logically inconsistent judgments across inference patterns involving epistemic modals.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#30697;&#38453;&#29109;&#65292;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#21644;&#20960;&#20309;&#21407;&#29702;&#30340;&#26032;&#22411;&#25351;&#26631;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25968;&#25454;&#21387;&#32553;&#33021;&#21147;&#12290;&#35813;&#25351;&#26631;&#21453;&#26144;&#20102;&#27169;&#22411;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#21644;&#28040;&#38500;&#19981;&#24517;&#35201;&#20803;&#32032;&#30340;&#33021;&#21147;&#65292;&#20026;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#30340;&#22266;&#26377;&#33021;&#21147;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;&#22312;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#35774;&#32622;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17139</link><description>&lt;p&gt;
&#36890;&#36807;&#30697;&#38453;&#29109;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Evaluation via Matrix Entropy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#30697;&#38453;&#29109;&#65292;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#21644;&#20960;&#20309;&#21407;&#29702;&#30340;&#26032;&#22411;&#25351;&#26631;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25968;&#25454;&#21387;&#32553;&#33021;&#21147;&#12290;&#35813;&#25351;&#26631;&#21453;&#26144;&#20102;&#27169;&#22411;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#21644;&#28040;&#38500;&#19981;&#24517;&#35201;&#20803;&#32032;&#30340;&#33021;&#21147;&#65292;&#20026;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#30340;&#22266;&#26377;&#33021;&#21147;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;&#22312;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#35774;&#32622;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#23558;&#24378;&#22823;&#30340;&#33021;&#21147;&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#39046;&#22495;&#65292;&#20351;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#21457;&#29983;&#20102;&#38761;&#21629;&#12290;&#22240;&#27492;&#65292;&#20026;LLMs&#23450;&#20041;&#36866;&#24403;&#19988;&#22810;&#26679;&#21270;&#30340;&#35780;&#20272;&#25351;&#26631;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30697;&#38453;&#29109;&#65292;&#19968;&#31181;&#26681;&#26893;&#20110;&#20449;&#24687;&#35770;&#21644;&#20960;&#20309;&#21407;&#29702;&#30340;&#26032;&#22411;&#25351;&#26631;&#65292;&#29992;&#20110;&#37327;&#21270;LLMs&#20013;&#30340;&#25968;&#25454;&#21387;&#32553;&#33021;&#21147;&#12290;&#23427;&#21453;&#26144;&#20102;&#27169;&#22411;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#21644;&#28040;&#38500;&#19981;&#24517;&#35201;&#20803;&#32032;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#23545;&#35821;&#35328;&#27169;&#22411;&#22266;&#26377;&#33021;&#21147;&#30340;&#27934;&#23519;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#21333;&#27169;&#24577;&#65288;&#35821;&#35328;&#65289;&#21644;&#22810;&#27169;&#24577;&#35774;&#32622;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#23545;&#20110;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20986;&#34920;&#31034;&#30340;&#30697;&#38453;&#29109;&#22312;&#27169;&#22411;&#25193;&#22823;&#26102;&#36981;&#24490;&#19968;&#20010;&#32553;&#25918;&#23450;&#24459;&#31867;&#22411;&#30340;&#38477;&#20302;&#65292;&#36825;&#20316;&#20026;&#20256;&#32479;&#25439;&#22833;&#32553;&#25918;&#23450;&#24459;&#30340;&#34917;&#20805;&#12290;&#23545;&#20110;&#22810;&#27169;&#24577;&#35774;&#32622;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#29109;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#19968;&#20010;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have revolutionized the field of natural language processing, extending their strong capabilities into multi-modal domains. Thus, it is vital to define proper and diversified metrics for the evaluation of LLMs.   In this paper, we introduce matrix entropy, a novel metric rooted in information theory and geometry principles to quantify the data compression proficiency in LLMs. It reflects the model's ability to extract relevant information and eliminate unnecessary elements, thereby providing insight into the language model's intrinsic capability. Specifically, we demonstrate its applicability in both single-modal (language) and multi-modal settings. For language models, our findings reveal that the matrix entropy of representations follows a scaling law type reduction when the model scales up, serving as a complement to the traditional loss scaling law. For the multi-modal setting, we also propose an evaluation method based on matrix entropy for assessing a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;LLMs&#22312;&#29983;&#25104;&#22810;&#20803;&#21270;&#35266;&#28857;&#21644;&#29702;&#30001;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20174;LLMs&#20013;&#26368;&#22823;&#31243;&#24230;&#25552;&#21462;&#22810;&#26679;&#24615;&#35266;&#28857;&#30340;&#26032;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.09799</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#21462;&#22810;&#20803;&#21270;&#35266;&#28857;&#21040;&#20309;&#31181;&#31243;&#24230;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Far Can We Extract Diverse Perspectives from Large Language Models?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09799
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;LLMs&#22312;&#29983;&#25104;&#22810;&#20803;&#21270;&#35266;&#28857;&#21644;&#29702;&#30001;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20174;LLMs&#20013;&#26368;&#22823;&#31243;&#24230;&#25552;&#21462;&#22810;&#26679;&#24615;&#35266;&#28857;&#30340;&#26032;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#38598;&#22810;&#26679;&#21270;&#30340;&#20154;&#31867;&#35266;&#28857;&#25104;&#26412;&#39640;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26368;&#36817;&#30340;&#21512;&#20316;&#21162;&#21147;&#36235;&#21183;&#34920;&#26126;&#65292;&#20154;&#31867;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20043;&#38388;&#36827;&#34892;&#21512;&#20316;&#20026;&#29983;&#25104;&#22810;&#26679;&#21270;&#25968;&#25454;&#25552;&#20379;&#20102;&#28508;&#22312;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;LLMs&#22312;&#20027;&#35266;&#35805;&#39064;&#19978;&#29983;&#25104;&#22810;&#20803;&#21270;&#35266;&#28857;&#30340;&#33021;&#21147;&#31243;&#24230;&#20173;&#26159;&#19968;&#20010;&#26410;&#34987;&#25506;&#35752;&#30340;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;LLMs&#22312;&#29983;&#25104;&#22810;&#20803;&#21270;&#35266;&#28857;&#21644;&#29702;&#30001;&#65288;&#20363;&#22914;&#31038;&#20250;&#35268;&#33539;&#21644;&#36777;&#35770;&#25991;&#26412;&#65289;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;LLMs&#20013;&#25552;&#21462;&#26368;&#22823;&#22810;&#26679;&#24615;&#20449;&#24687;&#30340;&#26032;&#38382;&#39064;&#12290;&#21463;&#20154;&#31867;&#36890;&#36807;&#20854;&#20215;&#20540;&#35266;&#21457;&#23637;&#35266;&#28857;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26631;&#20934;&#30340;&#25552;&#31034;&#25216;&#26415;&#26469;&#30830;&#31435;&#22810;&#26679;&#21270;&#35266;&#28857;&#12290;&#20026;&#20102;&#20102;&#35299;&#25105;&#20204;&#33021;&#20174;LLMs&#20013;&#25552;&#21462;&#22810;&#20803;&#21270;&#35266;&#28857;&#21040;&#20309;&#31181;&#31243;&#24230;&#65292;&#25110;&#32773;&#31216;&#20043;&#20026;&#22810;&#26679;&#24615;&#35206;&#30422;&#29575;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#36880;&#27493;&#22238;&#24518;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#20197;&#22312;&#36845;&#20195;&#26041;&#24335;&#19979;&#20174;&#27169;&#22411;&#20013;&#29983;&#25104;&#26356;&#22810;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09799v2 Announce Type: replace  Abstract: Collecting diverse human opinions is costly and challenging. This leads to a recent trend in collaborative efforts between humans and Large Language Models (LLMs) for generating diverse data, offering potential scalable and efficient solutions. However, the extent of LLMs' capability to generate diverse perspectives on subjective topics remains an unexplored question. In this study, we investigate LLMs' capacity for generating diverse perspectives and rationales on subjective topics, such as social norms and argumentative texts. We formulate a new problem of maximum diversity extraction from LLMs. Motivated by how humans develop their opinions through their values, we propose a criteria-based prompting technique to ground diverse opinions. To see how far we can extract diverse perspectives from LLMs, or called diversity coverage, we employ a step-by-step recall prompting for generating more outputs from the model in an iterative mann
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35745;&#31639;&#26041;&#27861;&#23545;&#29992;&#25143;&#30340;&#28508;&#22312;&#26131;&#24863;&#24615;&#27700;&#24179;&#36827;&#34892;&#24314;&#27169;&#65292;&#21487;&#20197;&#24110;&#21161;&#29702;&#35299;&#26131;&#21463;&#38169;&#35823;&#20449;&#24687;&#24433;&#21709;&#30340;&#31243;&#24230;&#65292;&#20026;&#21518;&#32493;&#30740;&#31350;&#21644;&#24212;&#29992;&#25552;&#20379;&#37325;&#35201;&#21442;&#32771;&#12290;</title><link>https://arxiv.org/abs/2311.09630</link><description>&lt;p&gt;
&#35299;&#30721;&#26131;&#24863;&#24615;&#65306;&#36890;&#36807;&#35745;&#31639;&#26041;&#27861;&#23545;&#38169;&#35823;&#20449;&#24687;&#36827;&#34892;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09630
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35745;&#31639;&#26041;&#27861;&#23545;&#29992;&#25143;&#30340;&#28508;&#22312;&#26131;&#24863;&#24615;&#27700;&#24179;&#36827;&#34892;&#24314;&#27169;&#65292;&#21487;&#20197;&#24110;&#21161;&#29702;&#35299;&#26131;&#21463;&#38169;&#35823;&#20449;&#24687;&#24433;&#21709;&#30340;&#31243;&#24230;&#65292;&#20026;&#21518;&#32493;&#30740;&#31350;&#21644;&#24212;&#29992;&#25552;&#20379;&#37325;&#35201;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26131;&#21463;&#38169;&#35823;&#20449;&#24687;&#24433;&#21709;&#30340;&#31243;&#24230;&#25551;&#36848;&#20102;&#23545;&#19981;&#21487;&#39564;&#35777;&#20027;&#24352;&#30340;&#20449;&#20208;&#31243;&#24230;&#65292;&#36825;&#26159;&#20010;&#20307;&#24605;&#32500;&#36807;&#31243;&#20013;&#30340;&#28508;&#22312;&#22240;&#32032;&#65292;&#19981;&#21487;&#35266;&#23519;&#12290;&#29616;&#26377;&#26131;&#24863;&#24615;&#30740;&#31350;&#20005;&#37325;&#20381;&#36182;&#20110;&#33258;&#25105;&#25253;&#21578;&#30340;&#20449;&#24565;&#65292;&#36825;&#21487;&#33021;&#23384;&#22312;&#20559;&#35265;&#65292;&#25910;&#38598;&#25104;&#26412;&#39640;&#65292;&#24182;&#19988;&#38590;&#20197;&#22312;&#21518;&#32493;&#24212;&#29992;&#20013;&#25193;&#23637;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26041;&#27861;&#26469;&#24314;&#27169;&#29992;&#25143;&#30340;&#28508;&#22312;&#26131;&#24863;&#24615;&#27700;&#24179;&#12290;&#27491;&#22914;&#20808;&#21069;&#30340;&#30740;&#31350;&#25152;&#31034;&#65292;&#26131;&#24863;&#24615;&#21463;&#21040;&#21508;&#31181;&#22240;&#32032;&#30340;&#24433;&#21709;&#65288;&#20363;&#22914;&#20154;&#21475;&#32479;&#35745;&#22240;&#32032;&#12289;&#25919;&#27835;&#24847;&#35782;&#24418;&#24577;&#65289;&#65292;&#24182;&#30452;&#25509;&#24433;&#21709;&#20154;&#20204;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#36716;&#21457;&#34892;&#20026;&#12290;&#20026;&#20102;&#34920;&#31034;&#22522;&#30784;&#24515;&#29702;&#36807;&#31243;&#65292;&#25105;&#20204;&#30340;&#26131;&#24863;&#24615;&#24314;&#27169;&#23558;&#36825;&#20123;&#22240;&#32032;&#20316;&#20026;&#36755;&#20837;&#65292;&#21463;&#21040;&#20154;&#20204;&#20998;&#20139;&#34892;&#20026;&#30417;&#30563;&#30340;&#24341;&#23548;&#12290;&#20351;&#29992;COVID-19&#20316;&#20026;&#23454;&#39564;&#39046;&#22495;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#26131;&#24863;&#24615;&#35780;&#20998;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09630v2 Announce Type: replace  Abstract: Susceptibility to misinformation describes the degree of belief in unverifiable claims, a latent aspect of individuals' mental processes that is not observable. Existing susceptibility studies heavily rely on self-reported beliefs, which can be subject to bias, expensive to collect, and challenging to scale for downstream applications. To address these limitations, in this work, we propose a computational approach to model users' latent susceptibility levels. As shown in previous research, susceptibility is influenced by various factors (e.g., demographic factors, political ideology), and directly influences people's reposting behavior on social media. To represent the underlying mental process, our susceptibility modeling incorporates these factors as inputs, guided by the supervision of people's sharing behavior. Using COVID-19 as a testbed domain, our experiments demonstrate a significant alignment between the susceptibility score
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#26080;&#32541;&#36866;&#24212;Avalon&#28216;&#25103;&#65292;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#27807;&#36890;&#21644;&#20114;&#21160;&#65292;&#35780;&#20272;&#20102;&#26234;&#33021;&#20307;&#30340;&#24615;&#33021;&#21644;&#31038;&#20250;&#34892;&#20026;&#65292;&#23637;&#31034;&#20102;LLM&#26234;&#33021;&#20307;&#22312;&#28216;&#25103;&#20013;&#20855;&#26377;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2310.14985</link><description>&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#20307;&#31038;&#20250;&#34892;&#20026;&#30740;&#31350;&#65306;Avalon&#28216;&#25103;&#20013;&#30340;&#21327;&#20316;&#19982;&#23545;&#25239;
&lt;/p&gt;
&lt;p&gt;
LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.14985
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#26080;&#32541;&#36866;&#24212;Avalon&#28216;&#25103;&#65292;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#27807;&#36890;&#21644;&#20114;&#21160;&#65292;&#35780;&#20272;&#20102;&#26234;&#33021;&#20307;&#30340;&#24615;&#33021;&#21644;&#31038;&#20250;&#34892;&#20026;&#65292;&#23637;&#31034;&#20102;LLM&#26234;&#33021;&#20307;&#22312;&#28216;&#25103;&#20013;&#20855;&#26377;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#25581;&#31034;&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#20307;&#31038;&#20250;&#34892;&#20026;&#30340;&#24320;&#25918;&#24615;&#30740;&#31350;&#38382;&#39064;&#12290;&#20026;&#36798;&#21040;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;Avalon&#20316;&#20026;&#20195;&#34920;&#24615;&#30340;&#27807;&#36890;&#28216;&#25103;&#29615;&#22659;&#65292;&#24182;&#20351;&#29992;&#31995;&#32479;&#25552;&#31034;&#24341;&#23548;LLM&#26234;&#33021;&#20307;&#36827;&#34892;&#28216;&#25103;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#36827;&#34892;&#20102;&#20851;&#20110;LLM&#26234;&#33021;&#20307;&#30340;&#28216;&#25103;&#29609;&#27861;&#30340;&#21021;&#27493;&#30740;&#31350;&#65292;&#20294;&#26159;&#20182;&#20204;&#30340;&#31038;&#20250;&#34892;&#20026;&#20173;&#32570;&#20047;&#30740;&#31350;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#26080;&#32541;&#36866;&#24212;Avalon&#28216;&#25103;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#30340;&#26680;&#24515;&#26159;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#65292;&#21487;&#20197;&#23454;&#29616;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#26377;&#25928;&#27807;&#36890;&#21644;&#20114;&#21160;&#12290;&#25105;&#20204;&#26681;&#25454;&#20004;&#20010;&#35282;&#24230;&#30340;&#24230;&#37327;&#26631;&#20934;&#35780;&#20272;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#24615;&#33021;&#65306;&#36194;&#24471;&#28216;&#25103;&#21644;&#26356;&#20998;&#26512;LLM&#26234;&#33021;&#20307;&#30340;&#31038;&#20250;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#29983;&#25104;&#33258;&#36866;&#24212;&#21644;&#26234;&#33021;&#26234;&#33021;&#20307;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#31361;&#26174;&#20102;LLM&#26234;&#33021;&#20307;&#22312;&#24212;&#23545;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.14985v2 Announce Type: replace  Abstract: This paper aims to investigate the open research problem of uncovering the social behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a representative communication game, as the environment and use system prompts to guide LLM agents to play the game. While previous studies have conducted preliminary investigations into gameplay with LLM agents, there lacks research on their social behaviors. In this paper, we present a novel framework designed to seamlessly adapt to Avalon gameplay. The core of our proposed framework is a multi-agent system that enables efficient communication and interaction among agents. We evaluate the performance of our framework based on metrics from two perspectives: winning the game and analyzing the social behaviors of LLM agents. Our results demonstrate the effectiveness of our framework in generating adaptive and intelligent agents and highlight the potential of LLM-based agents in address
&lt;/p&gt;</description></item><item><title>LLM&#25351;&#20196;&#24494;&#35843;&#20013;&#65292;&#23545;&#20110;&#30701;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#65292;&#25552;&#31034;&#35789;&#26631;&#35760;&#20998;&#31867;&#25439;&#22833;&#21152;&#26435;&#65288;PLW&#65289;&#19982;&#24615;&#33021;&#21576;&#36127;&#20108;&#27425;&#20851;&#31995;&#65292;&#32780;&#38271;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#21017;&#19981;&#21463;PLW&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.13586</link><description>&lt;p&gt;
LLM&#25351;&#20196;&#24494;&#35843;&#20013;&#30340;&#25552;&#31034;&#26435;&#37325;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Prompt Weight Experiments for LLM Instruction Fine-Tuning. (arXiv:2401.13586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13586
&lt;/p&gt;
&lt;p&gt;
LLM&#25351;&#20196;&#24494;&#35843;&#20013;&#65292;&#23545;&#20110;&#30701;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#65292;&#25552;&#31034;&#35789;&#26631;&#35760;&#20998;&#31867;&#25439;&#22833;&#21152;&#26435;&#65288;PLW&#65289;&#19982;&#24615;&#33021;&#21576;&#36127;&#20108;&#27425;&#20851;&#31995;&#65292;&#32780;&#38271;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#21017;&#19981;&#21463;PLW&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#23567;&#22411;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;&#25552;&#31034;&#35789;&#26631;&#35760;&#20998;&#31867;&#25439;&#22833;&#21152;&#26435;&#65288;PLW&#65289;&#22914;&#20309;&#24433;&#21709;&#22312;&#25351;&#20196;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;7B&#22823;&#23567;&#30340;LLaMA&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20351;&#29992;&#22810;&#20010;&#25351;&#20196;&#25968;&#25454;&#38598;&#37325;&#29616;&#20102;&#26031;&#22374;&#31119;&#22823;&#23398;&#30340;Alpaca&#23454;&#39564;&#65292;&#20854;&#20013;&#21253;&#25324;LLaMA 1&#21644;LLaMA 2&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#25105;&#20204;&#30340;&#30701;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#30340;&#27169;&#22411;&#19982;PLW&#20043;&#38388;&#23384;&#22312;&#36127;&#20108;&#27425;&#20851;&#31995;&#65292;&#32780;&#22312;&#38271;&#25552;&#31034;&#23436;&#25104;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#30340;&#27169;&#22411;&#19981;&#21463;PLW&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets. We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;Q&amp;A&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25366;&#25496;&#22270;&#20687;&#20013;&#30340;&#38382;&#39064;-&#22238;&#31572;&#23545;&#26469;&#21457;&#29616;&#20016;&#23500;&#30340;&#35270;&#35273;&#32447;&#32034;&#65292;&#20197;&#24110;&#21161;AI&#27169;&#22411;&#26356;&#22909;&#22320;&#29702;&#35299;&#22797;&#26434;&#35270;&#35273;&#38382;&#39064;&#65292;&#25552;&#39640;&#36328;&#27169;&#24577;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.10712</link><description>&lt;p&gt;
Q&amp;A&#25552;&#31034;&#65306;&#36890;&#36807;&#25366;&#25496;&#38382;&#39064;-&#22238;&#31572;&#25552;&#31034;&#26469;&#21457;&#29616;&#20016;&#23500;&#30340;&#35270;&#35273;&#32447;&#32034;&#65292;&#20197;&#28385;&#36275;&#23545;&#22810;&#26679;&#19990;&#30028;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#30340;&#38656;&#27714;
&lt;/p&gt;
&lt;p&gt;
Q&amp;A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge. (arXiv:2401.10712v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;Q&amp;A&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25366;&#25496;&#22270;&#20687;&#20013;&#30340;&#38382;&#39064;-&#22238;&#31572;&#23545;&#26469;&#21457;&#29616;&#20016;&#23500;&#30340;&#35270;&#35273;&#32447;&#32034;&#65292;&#20197;&#24110;&#21161;AI&#27169;&#22411;&#26356;&#22909;&#22320;&#29702;&#35299;&#22797;&#26434;&#35270;&#35273;&#38382;&#39064;&#65292;&#25552;&#39640;&#36328;&#27169;&#24577;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#65292;&#22238;&#31572;&#38656;&#35201;&#39640;&#32423;&#25512;&#29702;&#33021;&#21147;&#21644;&#19990;&#30028;&#30693;&#35782;&#30340;&#22797;&#26434;&#35270;&#35273;&#38382;&#39064;&#27604;&#20197;&#24448;&#20219;&#20309;&#26102;&#20505;&#37117;&#26356;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20026;AI&#27169;&#22411;&#37197;&#22791;&#24378;&#22823;&#30340;&#36328;&#27169;&#24577;&#25512;&#29702;&#33021;&#21147;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#20154;&#31867;&#30340;&#35748;&#30693;&#26041;&#26696;&#23578;&#26410;&#31995;&#32479;&#22320;&#34987;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30456;&#20449;&#65292;&#22914;&#26524;&#25105;&#20204;&#33021;&#23613;&#21487;&#33021;&#25910;&#38598;&#32473;&#23450;&#22270;&#20687;&#20013;&#30340;&#35270;&#35273;&#32447;&#32034;&#65292;&#25105;&#20204;&#23558;&#33021;&#26356;&#20934;&#30830;&#22320;&#35782;&#21035;&#22270;&#20687;&#65292;&#26356;&#22909;&#22320;&#29702;&#35299;&#38382;&#39064;&#65292;&#26356;&#23481;&#26131;&#22238;&#24518;&#30456;&#20851;&#30693;&#35782;&#65292;&#24182;&#26368;&#32456;&#25512;&#29702;&#20986;&#31572;&#26696;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22270;&#20687;&#20013;&#25366;&#25496;&#38382;&#39064;-&#22238;&#31572;&#23545;&#26469;&#21457;&#29616;&#36825;&#20123;&#20016;&#23500;&#30340;&#35270;&#35273;&#32447;&#32034;&#65292;&#24182;&#23558;&#23427;&#20204;&#20316;&#20026;&#25552;&#31034;&#21457;&#36865;&#21040;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;Q&amp;A&#25552;&#31034;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#35757;&#32451;&#38598;&#20013;&#30340;&#22270;&#20687;-&#31572;&#26696;&#23545;&#21644;&#30456;&#24212;&#30340;&#38382;&#39064;&#20316;&#20026;&#36755;&#20837;&#21644;&#36755;&#20986;&#26469;&#35757;&#32451;&#19968;&#20010;&#35270;&#35273;&#38382;&#39064;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the breakthrough of multi-modal large language models, answering complex visual questions that demand advanced reasoning abilities and world knowledge has become a much more important testbed for developing AI models than ever. However, equipping AI models with robust cross-modality reasoning ability remains challenging since the cognition scheme of humans has not been understood systematically. In this paper, we believe that if we can collect visual clues in the given image as much as possible, we will recognize the image more accurately, understand the question better, recall relevant knowledge more easily, and finally reason out the answer. We discover these rich visual clues by mining question-answer pairs in images and sending them into multi-modal large language models as prompts. We call the proposed method Q&amp;A Prompts. Specifically, we first use the image-answer pairs and the corresponding questions in the training set as inputs and outputs to train a visual question gener
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#23545;&#35805;&#24335;&#35821;&#35328;&#27169;&#22411;ChatGPT&#21644;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#24341;&#25806;&#22312;&#23558;&#20013;&#25991;&#22806;&#20132;&#25991;&#26412;&#32763;&#35793;&#20026;&#33521;&#25991;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#21160;&#35780;&#20215;&#25351;&#26631;&#21644;&#20154;&#24037;&#35780;&#20272;&#26041;&#27861;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2401.05176</link><description>&lt;p&gt;
&#23545;&#35805;&#24335;&#35821;&#35328;&#27169;&#22411;ChatGPT&#19982;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#22312;&#32763;&#35793;&#20013;&#30340;&#31454;&#20105;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Can ChatGPT Rival Neural Machine Translation? A Comparative Study. (arXiv:2401.05176v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#23545;&#35805;&#24335;&#35821;&#35328;&#27169;&#22411;ChatGPT&#21644;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#24341;&#25806;&#22312;&#23558;&#20013;&#25991;&#22806;&#20132;&#25991;&#26412;&#32763;&#35793;&#20026;&#33521;&#25991;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#21160;&#35780;&#20215;&#25351;&#26631;&#21644;&#20154;&#24037;&#35780;&#20272;&#26041;&#27861;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#36234;&#26469;&#36234;&#22810;&#22320;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32763;&#35793;&#30340;&#20852;&#36259;&#19981;&#26029;&#22686;&#21152;&#30340;&#32972;&#26223;&#19979;&#65292;&#26412;&#25991;&#35780;&#20272;&#20102;ChatGPT&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20027;&#27969;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#65288;NMT&#65289;&#24341;&#25806;&#22312;&#23558;&#20013;&#25991;&#22806;&#20132;&#25991;&#26412;&#32763;&#35793;&#20026;&#33521;&#25991;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#22235;&#20010;&#33258;&#21160;&#35780;&#20215;&#25351;&#26631;&#21644;&#22522;&#20110;&#38169;&#35823;&#31867;&#22411;&#21644;&#20845;&#20010;&#20998;&#26512;&#32454;&#21017;&#30340;&#20154;&#24037;&#35780;&#20272;&#65292;&#32771;&#23519;&#20102;ChatGPT&#21644;NMT&#24341;&#25806;&#30340;&#32763;&#35793;&#36136;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#33258;&#21160;&#35780;&#20215;&#25351;&#26631;&#23545;&#20110;ChatGPT&#22312;&#19981;&#21516;&#25552;&#31034;&#21644;NMT&#31995;&#32479;&#19979;&#30340;&#34920;&#29616;&#24471;&#20986;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#65292;&#32780;&#24403;ChatGPT&#25552;&#20379;&#31034;&#20363;&#25110;&#32763;&#35793;&#20219;&#21153;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#26102;&#65292;&#20154;&#24037;&#35780;&#20272;&#32773;&#24448;&#24448;&#20250;&#32473;&#20104;&#26126;&#26174;&#36739;&#39640;&#30340;&#35780;&#20998;&#12290;&#33258;&#21160;&#35780;&#20215;&#25351;&#26631;&#19982;&#20154;&#24037;&#35780;&#20272;&#32500;&#24230;&#20043;&#38388;&#30340;&#20004;&#20004;&#30456;&#20851;&#24615;&#32467;&#26524;&#36739;&#24369;&#19988;&#19981;&#26174;&#33879;&#65292;&#36825;&#34920;&#26126;&#20102;&#20004;&#31181;&#32763;&#35793;&#36136;&#37327;&#35780;&#20272;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inspired by the increasing interest in leveraging large language models for translation, this paper evaluates the capabilities of large language models (LLMs) represented by ChatGPT in comparison to the mainstream neural machine translation (NMT) engines in translating Chinese diplomatic texts into English. Specifically, we examine the translation quality of ChatGPT and NMT engines as measured by four automated metrics and human evaluation based on an error-typology and six analytic rubrics. Our findings show that automated metrics yield similar results for ChatGPT under different prompts and NMT systems, while human annotators tend to assign noticeably higher scores to ChatGPT when it is provided an example or contextual information about the translation task. Pairwise correlation between automated metrics and dimensions of human evaluation produces weak and non-significant results, suggesting the divergence between the two methods of translation quality assessment. These findings pro
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27169;&#22411;&#37096;&#32626;&#21644;&#24182;&#34892;&#26694;&#26550;&#65292;&#29992;&#20110;&#21152;&#36895;RLHF&#35757;&#32451;&#12290;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#20004;&#31181;&#28789;&#27963;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#65292;&#20854;&#20013;&#20132;&#26367;&#31574;&#30053;&#26377;&#21161;&#20110;&#20943;&#23569;&#20869;&#23384;&#20887;&#20313;&#21644;&#36890;&#20449;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2312.11819</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#21152;&#36895;RLHF&#35757;&#32451;&#30340;&#33258;&#36866;&#24212;&#37096;&#32626;&#21644;&#24182;&#34892;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training. (arXiv:2312.11819v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.11819
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27169;&#22411;&#37096;&#32626;&#21644;&#24182;&#34892;&#26694;&#26550;&#65292;&#29992;&#20110;&#21152;&#36895;RLHF&#35757;&#32451;&#12290;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#20004;&#31181;&#28789;&#27963;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#65292;&#20854;&#20013;&#20132;&#26367;&#31574;&#30053;&#26377;&#21161;&#20110;&#20943;&#23569;&#20869;&#23384;&#20887;&#20313;&#21644;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20687;ChatGPT&#25110;InstructGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20135;&#29983;&#20102;&#37325;&#22823;&#24433;&#21709;&#12290;&#35768;&#22810;&#30740;&#31350;&#23581;&#35797;&#22797;&#29616;&#22797;&#26434;&#30340;InstructGPT&#30340;&#35757;&#32451;&#27969;&#31243;&#65292;&#21363;&#22522;&#20110;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#12290;&#28982;&#32780;&#65292;&#20027;&#27969;&#30340;&#20998;&#24067;&#24335;RLHF&#35757;&#32451;&#26041;&#27861;&#36890;&#24120;&#37319;&#29992;&#22266;&#23450;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#65292;&#31216;&#20026;Flattening&#31574;&#30053;&#12290;&#35813;&#31574;&#30053;&#23558;RLHF&#20013;&#28041;&#21450;&#30340;&#22235;&#20010;&#30456;&#20114;&#20381;&#36182;&#30340;&#27169;&#22411;&#35270;&#20026;&#21333;&#20010;&#23454;&#20307;&#65292;&#23558;&#23427;&#20204;&#20998;&#37197;&#21040;&#25152;&#26377;&#35774;&#22791;&#19978;&#65292;&#24182;&#24212;&#29992;&#20110;&#21333;&#20010;&#27169;&#22411;&#35774;&#35745;&#30340;&#24182;&#34892;&#25216;&#26415;&#65292;&#32780;&#19981;&#32771;&#34385;&#27599;&#20010;&#27169;&#22411;&#22266;&#26377;&#30340;&#19981;&#21516;&#24037;&#20316;&#36127;&#36733;&#12290;&#32467;&#26524;&#65292;&#35813;&#31574;&#30053;&#21152;&#21095;&#20102;RLHF&#35757;&#32451;&#20013;&#30340;&#29983;&#25104;&#29942;&#39048;&#65292;&#24182;&#38477;&#20302;&#20102;&#25972;&#20307;&#35757;&#32451;&#25928;&#29575;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27169;&#22411;&#37096;&#32626;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#20004;&#31181;&#28789;&#27963;&#30340;&#27169;&#22411;&#37096;&#32626;&#31574;&#30053;&#12290;&#20132;&#26367;&#31574;&#30053;&#26377;&#21161;&#20110;&#20943;&#23569;&#20869;&#23384;&#20887;&#20313;&#21644;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, ChatGPT or InstructGPT like large language models (LLM) has made a significant impact in the AI world. Many works have attempted to reproduce the complex InstructGPT's training pipeline, namely Reinforcement Learning with Human Feedback (RLHF). However, the mainstream distributed RLHF training methods typically adopt a fixed model placement strategy, referred to as the Flattening strategy. This strategy treats all four interdependent models involved in RLHF as a single entity, distributing them across all devices and applying parallelism techniques designed for a single model, regardless of the different workloads inherent to each model. As a result, this strategy exacerbates the generation bottlenecks in the RLHF training and degrades the overall training efficiency. To address these issues, we propose an adaptive model placement framework that offers two flexible model placement strategies. The Interleaving strategy helps reduce memory redundancy and communication costs of 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#65288;TOA&#65289;&#30340;&#27010;&#24565;&#21644;&#26694;&#26550;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#23545;&#25512;&#29702;&#20219;&#21153;&#26377;&#29992;&#31572;&#26696;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#23454;&#32423;&#36974;&#34109;&#65288;FLM&#65289;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#33258;&#25105;&#30417;&#30563;&#30340;TOA&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2310.11571</link><description>&lt;p&gt;
&#20160;&#20040;&#26159;&#19968;&#20010;&#22909;&#38382;&#39064;&#65311;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#19982;&#20107;&#23454;&#32423;&#36974;&#34109;&#12290;
&lt;/p&gt;
&lt;p&gt;
What is a good question? Task-oriented asking with fact-level masking. (arXiv:2310.11571v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#65288;TOA&#65289;&#30340;&#27010;&#24565;&#21644;&#26694;&#26550;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#23545;&#25512;&#29702;&#20219;&#21153;&#26377;&#29992;&#31572;&#26696;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#23454;&#32423;&#36974;&#34109;&#65288;FLM&#65289;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#33258;&#25105;&#30417;&#30563;&#30340;TOA&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#38382;&#26159;&#29616;&#23454;&#29983;&#27963;&#20013;&#21512;&#20316;&#25512;&#29702;&#20219;&#21153;&#65288;&#22914;&#38382;&#31572;&#65289;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#20363;&#22914;&#65292;&#19968;&#20010;&#27861;&#24459;&#21161;&#25163;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#27809;&#26377;&#29992;&#25143;&#24773;&#20917;&#30340;&#20855;&#20307;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#26080;&#27861;&#25552;&#20379;&#20934;&#30830;&#30340;&#24314;&#35758;&#12290;&#28982;&#32780;&#65292;&#36890;&#24120;&#20250;&#30452;&#25509;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#25512;&#29702;&#20219;&#21153;&#65292;&#32780;&#19981;&#20250;&#21521;&#29992;&#25143;&#25110;&#31532;&#19977;&#26041;&#25552;&#20986;&#21518;&#32493;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31216;&#20026;&#22522;&#20110;&#20219;&#21153;&#30340;&#35810;&#38382;&#65288;TOA&#65289;&#12290;&#38646;-shot&#32842;&#22825;&#27169;&#22411;&#21487;&#20197;&#25191;&#34892;TOA&#65292;&#20294;&#23427;&#20204;&#30340;&#35757;&#32451;&#20027;&#35201;&#22522;&#20110;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#65292;&#32780;&#19981;&#26159;&#38382;&#39064;&#26159;&#21542;&#23545;&#25104;&#21151;&#30340;&#21512;&#20316;&#26377;&#24110;&#21161;&#12290;&#20026;&#20102;&#33021;&#22815;&#35757;&#32451;&#21644;&#35780;&#20272;TOA&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#23548;&#21521;&#35810;&#38382;&#30340;&#23450;&#20041;&#21644;&#26694;&#26550;&#65292;&#21363;&#29983;&#25104;&#33021;&#22815;&#20026;&#25512;&#29702;&#20219;&#21153;&#25552;&#20379;&#26377;&#29992;&#31572;&#26696;&#30340;&#38382;&#39064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20107;&#23454;&#32423;&#36974;&#34109;&#65288;FLM&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30465;&#30053;&#29305;&#23450;&#30340;&#37096;&#20998;&#23558;&#33258;&#28982;&#35821;&#35328;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#33258;&#25105;&#30417;&#30563;&#30340;TOA&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Asking questions is an important element of real-life collaboration on reasoning tasks like question answering. For example, a legal assistant chatbot may be unable to make accurate recommendations without specific information on the user's circumstances. However, large language models are usually deployed to solve reasoning tasks directly without asking follow-up questions to the user or third parties. We term this problem task-oriented asking (TOA). Zero-shot chat models can perform TOA, but their training is primarily based on next-token prediction rather than whether questions contribute to successful collaboration. To enable the training and evaluation of TOA models, we present a definition and framework for natural language task-oriented asking, the problem of generating questions that result in answers useful for a reasoning task. We also present fact-level masking (FLM), a procedure for converting natural language datasets into self-supervised TOA datasets by omitting particula
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#20113;&#27169;&#22411;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#25972;&#21512;&#21040;&#23458;&#25143;&#31471;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#23454;&#26102;&#21709;&#24212;&#30340;&#20316;&#26354;&#36741;&#21161;&#12290;</title><link>http://arxiv.org/abs/2308.04215</link><description>&lt;p&gt;
&#23454;&#26102;&#20316;&#26354;&#36741;&#21161;&#30340;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance. (arXiv:2308.04215v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04215
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#20113;&#27169;&#22411;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#25972;&#21512;&#21040;&#23458;&#25143;&#31471;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#23454;&#26102;&#21709;&#24212;&#30340;&#20316;&#26354;&#36741;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#27169;&#22411;&#22312;&#25552;&#21319;&#20256;&#32479;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#12289;&#25972;&#21512;&#31169;&#20154;&#25968;&#25454;&#21644;&#20943;&#23569;&#24187;&#35273;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#24212;&#29992;&#20110;&#38656;&#35201;&#23454;&#26102;&#21709;&#24212;&#30340;&#20219;&#21153;&#65288;&#22914;&#20316;&#26354;&#36741;&#21161;&#65289;&#26102;&#65292;&#26816;&#32034;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25152;&#38656;&#30340;&#22788;&#29702;&#26102;&#38388;&#23384;&#22312;&#25361;&#25112;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Hybrid Retrieval-Augmented Generation (HybridRAG)&#26694;&#26550;&#65292;&#21033;&#29992;&#20102;&#23558;&#23458;&#25143;&#31471;&#27169;&#22411;&#21644;&#20113;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#30340;&#28151;&#21512;&#35774;&#32622;&#12290;HybridRAG&#36890;&#36807;&#24322;&#27493;&#29983;&#25104;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20113;&#31471;&#29983;&#25104;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#25972;&#21512;&#21040;&#23458;&#25143;&#31471;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#25972;&#21512;&#36825;&#31181;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#65292;&#23458;&#25143;&#31471;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#39640;&#25928;&#30340;&#21709;&#24212;&#65292;&#20174;LLM&#30340;&#33021;&#21147;&#20013;&#21463;&#30410;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24322;&#27493;&#20869;&#23384;&#38598;&#25104;&#65292;&#23458;&#25143;&#31471;&#27169;&#22411;&#33021;&#22815;&#23454;&#26102;&#21709;&#24212;&#29992;&#25143;&#35831;&#27714;&#65292;&#26080;&#38656;&#31561;&#24453;&#20113;&#31471;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval augmented models show promise in enhancing traditional language models by improving their contextual understanding, integrating private data, and reducing hallucination. However, the processing time required for retrieval augmented large language models poses a challenge when applying them to tasks that require real-time responses, such as composition assistance.  To overcome this limitation, we propose the Hybrid Retrieval-Augmented Generation (HybridRAG) framework that leverages a hybrid setting that combines both client and cloud models. HybridRAG incorporates retrieval-augmented memory generated asynchronously by a Large Language Model (LLM) in the cloud. By integrating this retrieval augmented memory, the client model acquires the capability to generate highly effective responses, benefiting from the LLM's capabilities. Furthermore, through asynchronous memory integration, the client model is capable of delivering real-time responses to user requests without the need to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#25216;&#26415;&#26469;&#25552;&#39640;&#38750;&#33258;&#22238;&#24402;&#32763;&#35793;&#27169;&#22411;&#30340;&#32763;&#35793;&#36136;&#37327;&#65292;&#22312;&#20445;&#25345;&#26174;&#30528;&#25512;&#29702;&#36895;&#24230;&#21152;&#36895;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#22810;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12289;&#37319;&#29992;MASK&#25554;&#20837;&#26041;&#26696;&#36827;&#34892;&#19978;&#37319;&#26679;&#12289;&#20197;&#21450;&#37319;&#29992;&#23884;&#20837;&#33976;&#39311;&#26041;&#27861;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#65292;&#27169;&#22411;&#34920;&#29616;&#20248;&#20110;&#22522;&#32447;&#33258;&#22238;&#24402;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.06345</link><description>&lt;p&gt;
&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#12289;&#23884;&#20837;&#33976;&#39311;&#21644;&#19978;&#37319;&#26679;&#31574;&#30053;&#25913;&#21892;&#38750;&#33258;&#22238;&#24402;&#32763;&#35793;&#36136;&#37327;&#65288;arXiv:2306.06345v1 [cs.CL]&#65289;
&lt;/p&gt;
&lt;p&gt;
Improving Non-autoregressive Translation Quality with Pretrained Language Model, Embedding Distillation and Upsampling Strategy for CTC. (arXiv:2306.06345v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#25216;&#26415;&#26469;&#25552;&#39640;&#38750;&#33258;&#22238;&#24402;&#32763;&#35793;&#27169;&#22411;&#30340;&#32763;&#35793;&#36136;&#37327;&#65292;&#22312;&#20445;&#25345;&#26174;&#30528;&#25512;&#29702;&#36895;&#24230;&#21152;&#36895;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#22810;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12289;&#37319;&#29992;MASK&#25554;&#20837;&#26041;&#26696;&#36827;&#34892;&#19978;&#37319;&#26679;&#12289;&#20197;&#21450;&#37319;&#29992;&#23884;&#20837;&#33976;&#39311;&#26041;&#27861;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#65292;&#27169;&#22411;&#34920;&#29616;&#20248;&#20110;&#22522;&#32447;&#33258;&#22238;&#24402;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#33258;&#22238;&#24402;&#26041;&#27861;&#26088;&#22312;&#25552;&#39640;&#32763;&#35793;&#27169;&#22411;&#30340;&#25512;&#29702;&#36895;&#24230;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#21487;&#20197;&#19968;&#27425;&#27491;&#21521;&#20256;&#36882;&#29983;&#25104;&#36755;&#20986;&#30340;&#27169;&#22411;&#12290;&#20294;&#26159;&#65292;&#19982;&#33258;&#22238;&#24402;&#27169;&#22411;&#30456;&#27604;&#65292;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#22312;&#32763;&#35793;&#36136;&#37327;&#19978;&#26377;&#26174;&#33879;&#30340;&#19979;&#38477;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#21019;&#26032;&#25216;&#26415;&#65292;&#20197;&#25552;&#39640;&#38750;&#33258;&#22238;&#24402;&#32763;&#35793;&#27169;&#22411;&#30340;&#32763;&#35793;&#36136;&#37327;&#65292;&#21516;&#26102;&#20445;&#25345;&#25512;&#29702;&#36895;&#24230;&#30340;&#26174;&#33879;&#21152;&#36895;&#12290;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;CTC&#25439;&#22833;&#24494;&#35843;&#39044;&#35757;&#32451;&#22810;&#35821;&#35328;&#27169;&#22411;&#26469;&#26377;&#25928;&#22320;&#35757;&#32451;NAT&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;MASK&#25554;&#20837;&#26041;&#26696;&#36827;&#34892;&#19978;&#37319;&#26679;&#65292;&#32780;&#19981;&#26159;&#20196;&#29260;&#22797;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#20837;&#33976;&#39311;&#26041;&#27861;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#22522;&#32447;&#33258;&#22238;&#24402;&#27169;&#22411;&#65288;Transformer base&#65289;&#65292;&#21253;&#25324;WMT'14 DE $\leftrightarrow$ EN&#12289;WMT'16 RO $\leftrightarrow$ EN&#21644;IWSLT'14 DE $\leftrightarrow$ EN&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-autoregressive approaches aim to improve the inference speed of translation models, particularly those that generate output in a one-pass forward manner. However, these approaches often suffer from a significant drop in translation quality compared to autoregressive models. This paper introduces a series of innovative techniques to enhance the translation quality of Non-Autoregressive Translation (NAT) models while maintaining a substantial acceleration in inference speed. We propose fine-tuning Pretrained Multilingual Language Models (PMLMs) with the CTC loss to train NAT models effectively. Furthermore, we adopt the MASK insertion scheme for up-sampling instead of token duplication, and we present an embedding distillation method to further enhance performance. In our experiments, our model outperforms the baseline autoregressive model (Transformer \textit{base}) on multiple datasets, including WMT'14 DE$\leftrightarrow$EN, WMT'16 RO$\leftrightarrow$EN, and IWSLT'14 DE$\leftright
&lt;/p&gt;</description></item></channel></rss>