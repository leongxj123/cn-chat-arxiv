<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;SR$_{\text{LLM}}$&#65292;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;&#20840;&#38754;&#30340;&#23433;&#20840;&#39118;&#38505;&#20998;&#31867;&#27861;&#21644;&#19987;&#23478;&#26631;&#27880;&#25968;&#25454;&#38598;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#35821;&#35328;&#29983;&#25104;&#20013;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#36890;&#36807;&#25351;&#20196;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#26041;&#27861;&#26377;&#25928;&#20943;&#23569;&#20102;&#19981;&#23433;&#20840;&#20869;&#23481;&#30340;&#29983;&#25104;&#12290;</title><link>https://arxiv.org/abs/2404.01399</link><description>&lt;p&gt;
&#24320;&#21457;&#23433;&#20840;&#21644;&#36127;&#36131;&#20219;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; - &#19968;&#20010;&#20840;&#38754;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Developing Safe and Responsible Large Language Models -- A Comprehensive Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01399
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;SR$_{\text{LLM}}$&#65292;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;&#20840;&#38754;&#30340;&#23433;&#20840;&#39118;&#38505;&#20998;&#31867;&#27861;&#21644;&#19987;&#23478;&#26631;&#27880;&#25968;&#25454;&#38598;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#35821;&#35328;&#29983;&#25104;&#20013;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#36890;&#36807;&#25351;&#20196;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#26041;&#27861;&#26377;&#25928;&#20943;&#23569;&#20102;&#19981;&#23433;&#20840;&#20869;&#23481;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#20154;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#23433;&#20840;&#24615;&#21644;&#39118;&#38505;&#26085;&#30410;&#20851;&#27880;&#65292;&#21457;&#23637;&#20943;&#36731;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23433;&#20840;&#21644;&#36127;&#36131;&#20219;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;SR$_{\text{LLM}}$&#65289;&#65292;&#36825;&#20010;&#27169;&#22411;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;LLM&#26469;&#22686;&#24378;&#35821;&#35328;&#29983;&#25104;&#30340;&#23433;&#20840;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;LLM&#23433;&#20840;&#39118;&#38505;&#20998;&#31867;&#27861;&#65292;&#24182;&#21033;&#29992;&#19987;&#23478;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#19982;&#36825;&#31181;&#20998;&#31867;&#27861;&#30456;&#19968;&#33268;&#12290;SR$_{\text{LLM}}$&#26088;&#22312;&#35782;&#21035;&#28508;&#22312;&#30340;&#19981;&#23433;&#20840;&#20869;&#23481;&#24182;&#20135;&#29983;&#33391;&#24615;&#21464;&#21270;&#12290;&#23427;&#37319;&#29992;&#22522;&#20110;&#25351;&#20196;&#30340;&#21644;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#20351;&#24471;&#35813;&#27169;&#22411;&#19981;&#20165;&#26377;&#25928;&#22320;&#22686;&#24378;&#23433;&#20840;&#24615;&#65292;&#32780;&#19988;&#36164;&#28304;&#39640;&#25928;&#19988;&#26131;&#20110;&#35843;&#25972;&#12290;&#22312;&#25105;&#20204;&#23545;&#20116;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#19987;&#26377;&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#19981;&#23433;&#20840;&#20869;&#23481;&#29983;&#25104;&#30340;&#26174;&#33879;&#20943;&#23569;&#12290;&#27492;&#22806;&#65292;&#22312;&#23454;&#26045;&#23433;&#20840;&#25514;&#26045;&#21518;&#65292;&#20986;&#29616;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01399v1 Announce Type: new  Abstract: Given the growing concerns around the safety and risks of Large Language Models (LLMs), it is essential to develop methods for mitigating these issues. We introduce Safe and Responsible Large Language Model (SR$_{\text{LLM}}$) , a model designed to enhance the safety of language generation using LLMs. Our approach incorporates a comprehensive LLM safety risk taxonomy and utilizes a dataset annotated by experts that align with this taxonomy. SR$_{\text{LLM}}$ is designed to identify potentially unsafe content and produce benign variations. It employs instruction-based and parameter-efficient fine-tuning methods, making the model not only effective in enhancing safety but also resource-efficient and straightforward to adjust. Through our testing on five benchmark datasets and two proprietary datasets, we observed notable reductions in the generation of unsafe content. Moreover, following the implementation of safety measures, there was a s
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#24212;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#20915;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#30340;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#24182;&#25552;&#20986;&#19968;&#31181;&#20351;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#30340;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2403.10795</link><description>&lt;p&gt;
&#20174;&#21333;&#35789;&#21040;&#36335;&#24452;&#65306;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20110;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
From Words to Routes: Applying Large Language Models to Vehicle Routing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10795
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#24212;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#20915;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#30340;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#24182;&#25552;&#20986;&#19968;&#31181;&#20351;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#22312;&#26426;&#22120;&#20154;&#39046;&#22495;&#65288;&#20363;&#22914;&#25805;&#20316;&#21644;&#23548;&#33322;&#65289;&#20013;&#23637;&#31034;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#36827;&#23637;&#65292;&#20854;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#12290;LLMs&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#21462;&#24471;&#25104;&#21151;&#35753;&#25105;&#20204;&#24605;&#32771;&#65306;LLMs&#22312;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#35299;&#20915;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#38382;&#39064;&#65288;VRPs&#65289;&#30340;&#33021;&#21147;&#22914;&#20309;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#19977;&#27493;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;21&#31181;&#21333;&#36710;&#25110;&#22810;&#36710;&#36335;&#24452;&#38382;&#39064;&#30340;&#25968;&#25454;&#38598;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;LLMs&#22312;&#22235;&#31181;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#25991;&#26412;&#21040;&#20195;&#30721;&#29983;&#25104;&#30340;&#24615;&#33021;&#65292;&#27599;&#31181;&#21253;&#25324;&#19981;&#21516;&#31867;&#22411;&#30340;&#25991;&#26412;&#36755;&#20837;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30452;&#25509;&#20174;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#29983;&#25104;&#20195;&#30721;&#30340;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#23545;&#20110;GPT-4&#25928;&#26524;&#26368;&#20339;&#65292;&#23454;&#29616;&#20102;56%&#30340;&#21487;&#34892;&#24615;&#65292;40%&#30340;&#20248;&#21270;&#24615;&#21644;53%&#30340;&#25928;&#29575;&#12290;&#31532;&#19977;&#65292;&#22522;&#20110;&#35266;&#23519;&#21040;LLMs&#21487;&#33021;&#26080;&#27861;&#22312;&#21021;&#22987;&#23581;&#35797;&#20013;&#25552;&#20379;&#27491;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20351;LLMs&#33021;&#22815;&#36827;&#34892;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10795v1 Announce Type: cross  Abstract: LLMs have shown impressive progress in robotics (e.g., manipulation and navigation) with natural language task descriptions. The success of LLMs in these tasks leads us to wonder: What is the ability of LLMs to solve vehicle routing problems (VRPs) with natural language task descriptions? In this work, we study this question in three steps. First, we construct a dataset with 21 types of single- or multi-vehicle routing problems. Second, we evaluate the performance of LLMs across four basic prompt paradigms of text-to-code generation, each involving different types of text input. We find that the basic prompt paradigm, which generates code directly from natural language task descriptions, performs the best for GPT-4, achieving 56% feasibility, 40% optimality, and 53% efficiency. Third, based on the observation that LLMs may not be able to provide correct solutions at the initial attempt, we propose a framework that enables LLMs to refin
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;</title><link>https://arxiv.org/abs/2403.09032</link><description>&lt;p&gt;
CodeUltraFeedback&#65306;&#19968;&#31181;&#29992;&#20110;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09032
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24615;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24037;&#20316;&#65292;&#38656;&#35201;&#35780;&#20272;&#22797;&#26434;&#25991;&#26412;LLMs&#30340;&#36755;&#20986;&#12290;&#29616;&#26377;&#22522;&#20934;&#20208;&#36182;&#33258;&#21160;&#21270;&#25351;&#26631;&#21644;&#38745;&#24577;&#20998;&#26512;&#24037;&#20855;&#65292;&#26410;&#33021;&#35780;&#20272;&#29992;&#25143;&#25351;&#20196;&#21644;LLM&#36755;&#20986;&#20013;&#30340;&#24494;&#22937;&#20043;&#22788;&#65292;&#31361;&#26174;&#20102;&#23545;LLM&#20559;&#22909;&#23545;&#40784;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#30340;&#38656;&#27714;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CodeUltraFeedback&#65292;&#19968;&#20010;&#21253;&#21547;10,000&#20010;&#22797;&#26434;&#25351;&#20196;&#30340;&#20559;&#22909;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;AI&#21453;&#39304;&#26469;&#35843;&#25972;&#21644;&#23545;&#40784;LLMs&#19982;&#32534;&#31243;&#20559;&#22909;&#12290;&#25105;&#20204;&#20351;&#29992;14&#31181;&#19981;&#21516;&#30340;LLMs&#23545;&#36825;&#20123;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#28982;&#21518;&#26681;&#25454;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#36827;&#34892;&#27880;&#37322;&#65292;&#20351;&#29992;GPT-3.5&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#26041;&#27861;&#20135;&#29983;&#25968;&#23383;&#21644;&#25991;&#26412;&#21453;&#39304;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;CODAL-Bench&#65292;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLM&#19982;&#36825;&#20123;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;C
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09032v1 Announce Type: cross  Abstract: Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavour that requires assessing intricate textual LLMs' outputs. By relying on automated metrics and static analysis tools, existing benchmarks fail to assess nuances in user instructions and LLM outputs, highlighting the need for large-scale datasets and benchmarks for LLM preference alignment. In this paper, we introduce CodeUltraFeedback, a preference dataset of 10,000 complex instructions to tune and align LLMs to coding preferences through AI feedback. We generate responses to the instructions using a pool of 14 diverse LLMs, which we then annotate according to their alignment with five coding preferences using the LLM-as-a-Judge approach with GPT-3.5, producing both numerical and textual feedback. We also present CODAL-Bench, a benchmark for assessing LLM alignment with these coding preferences. Our results show that C
&lt;/p&gt;</description></item><item><title>AmbigNLG&#26159;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#25351;&#20196;&#27169;&#31946;&#24615;&#25361;&#25112;&#30340;&#26032;&#20219;&#21153;&#65292;&#36890;&#36807;&#35782;&#21035;&#21644;&#20943;&#36731;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#65292;&#25913;&#36827;&#20102;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#65292;&#24182;&#31361;&#20986;&#20102;&#28165;&#26224;&#21644;&#20855;&#20307;&#25351;&#20196;&#22312;&#25552;&#21319;LLM&#22312;NLG&#20219;&#21153;&#20013;&#34920;&#29616;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.17717</link><description>&lt;p&gt;
AmbigNLG: &#35299;&#20915;NLG&#25351;&#20196;&#20013;&#30340;&#20219;&#21153;&#27169;&#31946;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
AmbigNLG: Addressing Task Ambiguity in Instruction for NLG
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17717
&lt;/p&gt;
&lt;p&gt;
AmbigNLG&#26159;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#25351;&#20196;&#27169;&#31946;&#24615;&#25361;&#25112;&#30340;&#26032;&#20219;&#21153;&#65292;&#36890;&#36807;&#35782;&#21035;&#21644;&#20943;&#36731;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#65292;&#25913;&#36827;&#20102;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#65292;&#24182;&#31361;&#20986;&#20102;&#28165;&#26224;&#21644;&#20855;&#20307;&#25351;&#20196;&#22312;&#25552;&#21319;LLM&#22312;NLG&#20219;&#21153;&#20013;&#34920;&#29616;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;AmbigNLG&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#65288;NLG&#65289;&#20219;&#21153;&#20013;&#25351;&#20196;&#27169;&#31946;&#24615;&#25361;&#25112;&#30340;&#26032;&#20219;&#21153;&#12290;&#23613;&#31649;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29702;&#35299;&#21644;&#25191;&#34892;&#21508;&#31181;&#20219;&#21153;&#26041;&#38754;&#20855;&#26377;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#30340;&#24615;&#33021;&#21463;&#21040;&#29616;&#23454;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#30340;&#26174;&#33879;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;AmbigNLG&#35797;&#22270;&#35782;&#21035;&#24182;&#20943;&#36731;&#36825;&#31181;&#27169;&#31946;&#24615;&#65292;&#26088;&#22312;&#31934;&#32454;&#21270;&#25351;&#20196;&#20197;&#26356;&#22909;&#22320;&#21305;&#37197;&#29992;&#25143;&#26399;&#26395;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21253;&#21547;2,500&#20010;&#23454;&#20363;&#30340;&#25968;&#25454;&#38598;AmbigSNI-NLG&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#27169;&#31946;&#24615;&#20998;&#31867;&#27861;&#65292;&#29992;&#20110;&#23545;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#36827;&#34892;&#20998;&#31867;&#21644;&#27880;&#37322;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#65292;&#31361;&#20986;&#20102;&#28165;&#26224;&#21644;&#20855;&#20307;&#25351;&#20196;&#22312;&#22686;&#24378;LLM&#22312;NLG&#20219;&#21153;&#20013;&#34920;&#29616;&#26041;&#38754;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17717v1 Announce Type: new  Abstract: In this study, we introduce AmbigNLG, a new task designed to tackle the challenge of task ambiguity in instructions for Natural Language Generation (NLG) tasks. Despite the impressive capabilities of Large Language Models (LLMs) in understanding and executing a wide range of tasks through natural language interaction, their performance is significantly hindered by the ambiguity present in real-world instructions. To address this, AmbigNLG seeks to identify and mitigate such ambiguities, aiming to refine instructions to match user expectations better. We introduce a dataset, AmbigSNI-NLG, consisting of 2,500 instances, and develop an ambiguity taxonomy for categorizing and annotating instruction ambiguities. Our approach demonstrates substantial improvements in text generation quality, highlighting the critical role of clear and specific instructions in enhancing LLM performance in NLG tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24773;&#24863;&#24605;&#32500;&#38142;&#65288;ECoT&#65289;&#30340;&#25552;&#31034;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#20154;&#31867;&#24773;&#24863;&#26234;&#24935;&#20934;&#21017;&#23545;&#40784;&#65292;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.06836</link><description>&lt;p&gt;
&#36890;&#36807;&#24773;&#32490;&#24605;&#32500;&#38142;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#32490;&#29983;&#25104;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Enhancing Emotional Generation Capability of Large Language Models via Emotional Chain-of-Thought
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.06836
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24773;&#24863;&#24605;&#32500;&#38142;&#65288;ECoT&#65289;&#30340;&#25552;&#31034;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#20154;&#31867;&#24773;&#24863;&#26234;&#24935;&#20934;&#21017;&#23545;&#40784;&#65292;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#24773;&#32490;&#35782;&#21035;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#24341;&#36215;&#20102;&#30740;&#31350;&#30028;&#23545;&#25506;&#32034;&#23427;&#20204;&#22312;&#24773;&#24863;&#26234;&#33021;&#20013;&#28508;&#21147;&#30340;&#22909;&#22855;&#24515;&#12290;&#28982;&#32780;&#65292;&#24773;&#24863;&#29983;&#25104;&#20219;&#21153;&#39046;&#22495;&#20173;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#65292;&#21253;&#25324;&#20154;&#31867;&#20559;&#22909;&#30340;&#23545;&#40784;&#21644;&#24773;&#24863;&#29983;&#25104;&#35780;&#20272;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24773;&#24863;&#24605;&#32500;&#38142;&#65288;ECoT&#65289;&#30340;&#21363;&#25554;&#21363;&#29992;&#25552;&#31034;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#20154;&#31867;&#24773;&#24863;&#26234;&#21147;&#25351;&#21335;&#23545;&#40784;&#26469;&#22686;&#24378;LLMs&#22312;&#21508;&#31181;&#24773;&#24863;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;&#20026;&#20102;&#35780;&#20272;ECoT&#30340;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#24773;&#24863;&#29983;&#25104;&#24471;&#20998;&#65288;EGS&#65289;&#30340;&#33258;&#21160;&#21270;&#22522;&#20110;&#27169;&#22411;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;EGS&#23558;&#25096;&#23572;&#26364;&#30340;&#24773;&#32490;&#26234;&#21147;&#29702;&#35770;&#20316;&#20026;&#20154;&#31867;&#19987;&#23478;&#20849;&#35782;&#65292;&#20026;&#24773;&#24863;&#29983;&#25104;&#20219;&#21153;&#30340;&#35780;&#20272;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;&#22823;&#37327;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.06836v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown remarkable performance in various emotion recognition tasks, thereby piquing the research community's curiosity for exploring their potential in emotional intelligence. However, several issues in the field of emotional generation tasks remain unresolved, including human preference alignment and emotional generation assessment. In this paper, we propose the Emotional Chain-of-Thought (ECoT), a plug-and-play prompting method that enhances the performance of LLMs on various emotional generation tasks by aligning with human emotional intelligence guidelines. To assess the reliability of ECoT, we propose an automated model-based evaluation method called Emotional Generation Score (EGS). EGS incorporates Goleman's Emotional Intelligence Theory as a consensus of human experts, providing a new perspective on the evaluation of emotional generation tasks. Extensive experimental results demonstrate 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#35268;&#21010;&#26631;&#35760;&#26469;&#24341;&#23548;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25512;&#29702;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20445;&#25345;&#25512;&#29702;&#36807;&#31243;&#20013;&#30340;&#19968;&#33268;&#24615;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#25552;&#21319;&#65292;&#32780;&#22686;&#21152;&#30340;&#35757;&#32451;&#21442;&#25968;&#24456;&#23569;&#12290;</title><link>https://arxiv.org/abs/2310.05707</link><description>&lt;p&gt;
&#29992;&#35268;&#21010;&#26631;&#35760;&#24341;&#23548;&#35821;&#35328;&#27169;&#22411;&#30340;&#25968;&#23398;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Guiding Language Model Math Reasoning with Planning Tokens
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.05707
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#35268;&#21010;&#26631;&#35760;&#26469;&#24341;&#23548;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25512;&#29702;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20445;&#25345;&#25512;&#29702;&#36807;&#31243;&#20013;&#30340;&#19968;&#33268;&#24615;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#25552;&#21319;&#65292;&#32780;&#22686;&#21152;&#30340;&#35757;&#32451;&#21442;&#25968;&#24456;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36817;&#26469;&#22240;&#20854;&#36827;&#34892;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#30340;&#33021;&#21147;&#65288;&#22914;&#24605;&#32500;&#38142;&#25512;&#29702;&#65289;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22686;&#24378;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#26041;&#27861;&#36807;&#20110;&#20381;&#36182;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#24573;&#35270;&#20102;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#30340;&#32467;&#26500;&#21270;&#26041;&#38754;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;LLMs&#21487;&#20197;&#24456;&#22909;&#22320;&#22788;&#29702;&#20010;&#21035;&#25512;&#29702;&#27493;&#39588;&#65292;&#20294;&#22312;&#25972;&#20010;&#25512;&#29702;&#38142;&#19978;&#20445;&#25345;&#19968;&#33268;&#24615;&#26041;&#38754;&#21364;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#27599;&#20010;&#25512;&#29702;&#27493;&#39588;&#30340;&#24320;&#22987;&#22788;&#24341;&#20837;&#35268;&#21010;&#26631;&#35760;&#65292;&#20316;&#20026;&#27169;&#22411;&#30340;&#24341;&#23548;&#65292;&#24182;&#23558;&#23427;&#20204;&#30340;&#23884;&#20837;&#28155;&#21152;&#21040;&#27169;&#22411;&#21442;&#25968;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#22686;&#21152;&#38750;&#24120;&#23567;&#65288;&#20165;&#20026;0.001%&#65289;&#65292;&#21487;&#20197;&#36890;&#36807;&#23436;&#20840;&#24494;&#35843;&#25110;&#26356;&#39640;&#25928;&#30340;&#21442;&#25968;&#26041;&#26696;&#26469;&#24212;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#19977;&#31181;&#19981;&#21516;&#30340;LLMs&#65292;&#22312;&#19977;&#20010;&#25968;&#23398;&#21333;&#35789;&#38382;&#39064;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#30456;&#23545;&#20110;&#26631;&#20934;&#26041;&#27861;&#65292;&#20934;&#30830;&#24615;&#26174;&#33879;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have recently attracted considerable interest for their ability to perform complex reasoning tasks, such as chain-of-thought reasoning. However, most of the existing approaches to enhance this ability rely heavily on data-driven methods, while neglecting the structural aspects of the model's reasoning capacity. We find that while LLMs can manage individual reasoning steps well, they struggle with maintaining consistency across an entire reasoning chain. To solve this, we introduce planning tokens at the start of each reasoning step, serving as a guide for the model, and add their embeddings to the model parameters. Our approach requires a negligible increase in trainable parameters (just 0.001%) and can be applied through either full fine-tuning or a more parameter-efficient scheme. We demonstrate our method's effectiveness by applying it to three different LLMs, showing notable accuracy improvements across three math word problem datasets w.r.t. standard f
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#21517;&#20026;&#8220;&#25105;&#26159;&#19968;&#20010;&#22855;&#24618;&#30340;&#25968;&#25454;&#38598;&#8221;&#65292;&#29992;&#26469;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#33021;&#22815;&#22788;&#29702;&#20803;&#35821;&#35328;&#33258;&#25351;&#30340;&#38472;&#36848;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21508;&#31181;&#24320;&#28304;&#21644;&#38381;&#28304;LLMs&#22312;&#29983;&#25104;&#21644;&#39564;&#35777;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#37117;&#25509;&#36817;&#38543;&#26426;&#29468;&#27979;&#12290;</title><link>http://arxiv.org/abs/2401.05300</link><description>&lt;p&gt;
&#25105;&#26159;&#19968;&#20010;&#22855;&#24618;&#30340;&#25968;&#25454;&#38598;&#65306;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#20803;&#35821;&#35328;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
I am a Strange Dataset: Metalinguistic Tests for Language Models. (arXiv:2401.05300v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05300
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#21517;&#20026;&#8220;&#25105;&#26159;&#19968;&#20010;&#22855;&#24618;&#30340;&#25968;&#25454;&#38598;&#8221;&#65292;&#29992;&#26469;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#33021;&#22815;&#22788;&#29702;&#20803;&#35821;&#35328;&#33258;&#25351;&#30340;&#38472;&#36848;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21508;&#31181;&#24320;&#28304;&#21644;&#38381;&#28304;LLMs&#22312;&#29983;&#25104;&#21644;&#39564;&#35777;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#37117;&#25509;&#36817;&#38543;&#26426;&#29468;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#65292;&#28041;&#21450;&#20803;&#35821;&#35328;&#33258;&#25351;&#30340;&#38472;&#36848;&#65288;&#8220;&#26412;&#35770;&#25991;&#26377;&#20845;&#20010;&#37096;&#20998;&#12290;&#8221;&#65289;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#21542;&#22788;&#29702;&#36825;&#26679;&#30340;&#35821;&#35328;&#65311;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#8220;&#25105;&#26159;&#19968;&#20010;&#22855;&#24618;&#30340;&#25968;&#25454;&#38598;&#8221;&#65292;&#29992;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23427;&#21253;&#21547;&#20004;&#20010;&#23376;&#20219;&#21153;&#65306;&#29983;&#25104;&#21644;&#39564;&#35777;&#12290;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#65292;&#27169;&#22411;&#20250;&#32487;&#32493;&#31867;&#20284;&#20110;&#8220;&#36825;&#20010;&#21477;&#23376;&#20013;&#20498;&#25968;&#31532;&#20108;&#20010;&#35789;&#26159;&#8221;&#30340;&#38472;&#36848;&#65288;&#27491;&#30830;&#30340;&#32487;&#32493;&#24212;&#35813;&#26159;&#8220;&#26159;&#8221;&#65289;&#12290;&#22312;&#39564;&#35777;&#20219;&#21153;&#20013;&#65292;&#27169;&#22411;&#20250;&#21028;&#26029;&#31867;&#20284;&#20110;&#8220;&#36825;&#20010;&#21477;&#23376;&#20013;&#20498;&#25968;&#31532;&#20108;&#20010;&#35789;&#26159;&#21477;&#23376;&#12290;&#8221;&#30340;&#38472;&#36848;&#30340;&#30495;&#23454;&#24615;&#65288;&#26159;&#20551;&#30340;&#65289;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26368;&#23567;&#24046;&#24322;&#30340;&#38750;&#33258;&#25351;&#20803;&#35821;&#35328;&#31034;&#20363;&#65292;&#26469;&#34917;&#20805;&#20027;&#25968;&#25454;&#38598;&#65292;&#20197;&#27979;&#35797;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#22788;&#29702;&#20803;&#35821;&#35328;&#35821;&#35328;&#12290;&#25968;&#25454;&#38598;&#30001;&#19987;&#23478;&#25163;&#24037;&#21046;&#20316;&#65292;&#38750;&#19987;&#23478;&#26631;&#27880;&#21592;&#36827;&#34892;&#39564;&#35777;&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#21508;&#31181;&#24320;&#28304;LLMs&#65288;&#20174;7B&#21040;70B&#30340;&#21442;&#25968;&#65289;&#20197;&#21450;&#36890;&#36807;API&#36827;&#34892;&#27979;&#35797;&#30340;&#38381;&#28304;LLMs&#12290;&#25152;&#26377;&#27169;&#22411;&#22312;&#20004;&#20010;&#23376;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#37117;&#25509;&#36817;&#38543;&#26426;&#29468;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statements involving metalinguistic self-reference ("This paper has six sections.") are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present "I am a Strange Dataset", a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like "The penultimate word in this sentence is" (where a correct continuation is "is"). In verification, models judge the truth of statements like "The penultimate word in this sentence is sentence." (false). We also provide minimally different metalinguistic non-self-reference examples to complement the main dataset by probing for whether models can handle metalinguistic language at all. The dataset is hand-crafted by experts and validated by non-expert annotators. We test a variety of open-source LLMs (7B to 70B parameters) as well as closed-source LLMs through APIs. All models perform close to chance across both subtasks and eve
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#21521;&#37327;&#23884;&#20837;&#21644;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#21457;&#29616;GPT-2&#19982;UMAP&#30340;&#32467;&#21512;&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#20998;&#31163;&#21644;&#32858;&#31867;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#32463;&#36807;&#24494;&#35843;&#30340;DistilBERT&#27169;&#22411;&#21487;&#29992;&#20110;&#35782;&#21035;&#24635;&#32479;&#21644;&#28436;&#35762;&#30340;&#24180;&#20221;&#12290;</title><link>http://arxiv.org/abs/2312.01185</link><description>&lt;p&gt;
&#26102;&#38388;&#20013;&#30340;&#28063;&#28458;&#65306;&#32654;&#22269;&#21382;&#21490;&#20013;&#30340;&#19981;&#36830;&#32493;&#24615;
&lt;/p&gt;
&lt;p&gt;
A ripple in time: a discontinuity in American history. (arXiv:2312.01185v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01185
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#21521;&#37327;&#23884;&#20837;&#21644;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#21457;&#29616;GPT-2&#19982;UMAP&#30340;&#32467;&#21512;&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#20998;&#31163;&#21644;&#32858;&#31867;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#32463;&#36807;&#24494;&#35843;&#30340;DistilBERT&#27169;&#22411;&#21487;&#29992;&#20110;&#35782;&#21035;&#24635;&#32479;&#21644;&#28436;&#35762;&#30340;&#24180;&#20221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;Kaggle&#30340;&#22269;&#24773;&#21672;&#25991;&#25968;&#25454;&#38598;&#23545;&#32654;&#22269;&#21382;&#21490;&#30340;&#24635;&#20307;&#26102;&#38388;&#32447;&#21450;&#21672;&#25991;&#26412;&#36523;&#30340;&#29305;&#28857;&#21644;&#24615;&#36136;&#36827;&#34892;&#20102;&#19968;&#20123;&#20196;&#20154;&#24778;&#35766;&#65288;&#20063;&#26377;&#20123;&#19981;&#37027;&#20040;&#20196;&#20154;&#24778;&#35766;&#65289;&#30340;&#35266;&#23519;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#26041;&#27861;&#26159;&#20351;&#29992;&#21521;&#37327;&#23884;&#20837;&#65292;&#22914;BERT&#65288;DistilBERT&#65289;&#21644;GPT-2&#12290;&#34429;&#28982;&#24191;&#27867;&#35748;&#20026;BERT&#65288;&#21450;&#20854;&#21464;&#20307;&#65289;&#26368;&#36866;&#21512;NLP&#20998;&#31867;&#20219;&#21153;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;GPT-2&#32467;&#21512;UMAP&#31561;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#20998;&#31163;&#21644;&#26356;&#24378;&#30340;&#32858;&#31867;&#25928;&#26524;&#12290;&#36825;&#20351;&#24471;GPT-2 + UMAP&#25104;&#20026;&#19968;&#20010;&#26377;&#36259;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#22312;&#25105;&#20204;&#30340;&#24773;&#20917;&#19979;&#65292;&#19981;&#38656;&#35201;&#23545;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#39044;&#35757;&#32451;&#30340;GPT-2&#27169;&#22411;&#23601;&#36275;&#22815;&#22909;&#29992;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#32463;&#36807;&#24494;&#35843;&#30340;DistilBERT&#27169;&#22411;&#26469;&#26816;&#27979;&#21738;&#20301;&#24635;&#32479;&#21457;&#34920;&#20102;&#21738;&#31687;&#28436;&#35762;&#65292;&#24182;&#21462;&#24471;&#20102;&#38750;&#24120;&#22909;&#30340;&#32467;&#26524;&#65288;&#20934;&#30830;&#29575;&#20026;93\% - 95\%&#65292;&#20855;&#20307;&#21462;&#20915;&#20110;&#36816;&#34892;&#24773;&#20917;&#65289;&#12290;&#20026;&#20102;&#30830;&#23450;&#20889;&#20316;&#24180;&#20221;&#65292;&#25105;&#20204;&#36824;&#25191;&#34892;&#20102;&#19968;&#20010;&#31867;&#20284;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this note we use the State of the Union Address (SOTU) dataset from Kaggle to make some surprising (and some not so surprising) observations pertaining to the general timeline of American history, and the character and nature of the addresses themselves. Our main approach is using vector embeddings, such as BERT (DistilBERT) and GPT-2.  While it is widely believed that BERT (and its variations) is most suitable for NLP classification tasks, we find out that GPT-2 in conjunction with nonlinear dimension reduction methods such as UMAP provide better separation and stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In our case, no model fine-tuning is required, and the pre-trained out-of-the-box GPT-2 model is enough.  We also used a fine-tuned DistilBERT model for classification detecting which President delivered which address, with very good results (accuracy 93\% - 95\% depending on the run). An analogous task was performed to determine the year of writing, an
&lt;/p&gt;</description></item><item><title>CPET&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21387;&#32553;LLM&#30340;&#26377;&#25928;&#21442;&#25968;&#20248;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#30693;&#35782;&#32487;&#25215;&#21644;&#24674;&#22797;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#22312;&#21442;&#25968;&#26377;&#25928;&#35843;&#25972;&#20013;&#21387;&#32553;LLM&#30340;&#25512;&#29702;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07705</link><description>&lt;p&gt;
CPET: &#39640;&#25928;&#21387;&#32553;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21442;&#25968;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
CPET: Effective Parameter-Efficient Tuning for Compressed Large Language Models. (arXiv:2307.07705v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07705
&lt;/p&gt;
&lt;p&gt;
CPET&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21387;&#32553;LLM&#30340;&#26377;&#25928;&#21442;&#25968;&#20248;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#30693;&#35782;&#32487;&#25215;&#21644;&#24674;&#22797;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#22312;&#21442;&#25968;&#26377;&#25928;&#35843;&#25972;&#20013;&#21387;&#32553;LLM&#30340;&#25512;&#29702;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21442;&#25968;&#26377;&#25928;&#35843;&#25972;&#65288;PET&#65289;&#22240;&#20026;&#22312;&#35843;&#25972;&#30456;&#23545;&#36739;&#23569;&#30340;&#21442;&#25968;&#65288;PET&#27169;&#22359;&#65289;&#30340;&#21516;&#26102;&#20173;&#33021;&#28608;&#27963;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36275;&#22815;&#30693;&#35782;&#20197;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#32780;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#24403;PET&#29992;&#20110;&#20026;&#22810;&#20010;&#20219;&#21153;&#25552;&#20379;&#26381;&#21153;&#26102;&#65292;&#21487;&#20197;&#22312;&#20923;&#32467;&#30340;LLM&#19978;&#26500;&#24314;&#19981;&#21516;&#30340;&#20219;&#21153;&#29305;&#23450;PET&#27169;&#22359;&#65292;&#36991;&#20813;&#20887;&#20313;LLM&#37096;&#32626;&#12290;&#34429;&#28982;PET&#26174;&#33879;&#38477;&#20302;&#20102;&#35843;&#20248;&#21644;&#37096;&#32626;LLM&#30340;&#25104;&#26412;&#65292;&#20294;&#20854;&#25512;&#29702;&#20173;&#28982;&#21463;&#21040;LLM&#35745;&#31639;&#29942;&#39048;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21387;&#32553;LLM&#30340;&#26377;&#25928;PET&#26694;&#26550;&#65292;&#31216;&#20026;&#8220;CPET&#8221;&#12290;&#22312;CPET&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#20027;&#27969;LLM&#21387;&#32553;&#25216;&#26415;&#23545;PET&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#28982;&#21518;&#24341;&#20837;&#20102;&#30693;&#35782;&#32487;&#25215;&#21644;&#24674;&#22797;&#31574;&#30053;&#26469;&#24674;&#22797;&#30001;&#36825;&#20123;&#21387;&#32553;&#25216;&#26415;&#24341;&#36215;&#30340;&#30693;&#35782;&#20002;&#22833;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30001;&#20110;CPET&#30340;&#24674;&#22797;&#31574;&#30053;&#65292;&#21512;&#20316;
&lt;/p&gt;
&lt;p&gt;
Parameter-efficient tuning (PET) has been widely explored in recent years because it tunes much fewer parameters (PET modules) than full-parameter fine-tuning (FT) while still stimulating sufficient knowledge from large language models (LLMs) for downstream tasks. Moreover, when PET is employed to serve multiple tasks, different task-specific PET modules can be built on a frozen LLM, avoiding redundant LLM deployments. Although PET significantly reduces the cost of tuning and deploying LLMs, its inference still suffers from the computational bottleneck of LLMs. To address the above issue, we propose an effective PET framework based on compressed LLMs, named "CPET". In CPET, we evaluate the impact of mainstream LLM compression techniques on PET performance and then introduce knowledge inheritance and recovery strategies to restore the knowledge loss caused by these compression techniques. Our experimental results demonstrate that, owing to the restoring strategies of CPET, collaborating
&lt;/p&gt;</description></item></channel></rss>