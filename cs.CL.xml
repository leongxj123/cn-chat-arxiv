<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>LSCD&#22522;&#20934;&#27979;&#35797;&#25552;&#20379;&#20102;&#19968;&#20010;&#26631;&#20934;&#21270;&#30340;LSCD&#35780;&#20272;&#24179;&#21488;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#35780;&#20272;&#21644;&#32467;&#26524;&#22797;&#29616;&#20013;&#23384;&#22312;&#30340;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.00176</link><description>&lt;p&gt;
LSCD&#22522;&#20934;&#27979;&#35797;&#65306;&#21382;&#26102;&#35789;&#20041;&#20219;&#21153;&#30340;&#27979;&#35797;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
The LSCD Benchmark: a Testbed for Diachronic Word Meaning Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00176
&lt;/p&gt;
&lt;p&gt;
LSCD&#22522;&#20934;&#27979;&#35797;&#25552;&#20379;&#20102;&#19968;&#20010;&#26631;&#20934;&#21270;&#30340;LSCD&#35780;&#20272;&#24179;&#21488;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#35780;&#20272;&#21644;&#32467;&#26524;&#22797;&#29616;&#20013;&#23384;&#22312;&#30340;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35789;&#27719;&#35821;&#20041;&#21464;&#21270;&#26816;&#27979;&#65288;LSCD&#65289;&#26159;&#19968;&#39033;&#22797;&#26434;&#30340;&#35789;&#20803;&#32423;&#20219;&#21153;&#65292;&#36890;&#24120;&#22522;&#20110;&#20004;&#20010;&#36830;&#32493;&#24212;&#29992;&#30340;&#20351;&#29992;&#32423;&#20219;&#21153;&#26469;&#25805;&#20316;&#65306;&#39318;&#20808;&#65292;&#20026;&#20351;&#29992;&#23545;&#24471;&#21040;Word-in-Context (WiC)&#26631;&#31614;&#12290;&#28982;&#21518;&#65292;&#22312;&#22270;&#19978;&#34920;&#31034;&#36825;&#20123;&#26631;&#31614;&#65292;&#23545;&#20854;&#24212;&#29992;Word Sense Induction (WSI)&#26469;&#25512;&#23548;&#20986;&#21547;&#20041;&#32858;&#31867;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#27604;&#36739;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#21547;&#20041;&#32858;&#31867;&#26469;&#25512;&#23548;&#20986;LSCD&#26631;&#31614;&#12290;&#36825;&#31181;&#27169;&#22359;&#21270;&#21453;&#26144;&#22312;&#22823;&#22810;&#25968;LSCD&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#20013;&#12290;&#36825;&#20063;&#23548;&#33268;&#20102;&#24314;&#27169;&#36873;&#25321;&#21644;&#20219;&#21153;&#23450;&#20041;&#19978;&#30340;&#22823;&#37327;&#24322;&#36136;&#24615;&#65292;&#36825;&#19968;&#28857;&#21448;&#22240;&#21508;&#31181;&#25968;&#25454;&#38598;&#29256;&#26412;&#12289;&#39044;&#22788;&#29702;&#36873;&#39033;&#21644;&#35780;&#20272;&#25351;&#26631;&#32780;&#21152;&#21095;&#12290;&#36825;&#31181;&#24322;&#36136;&#24615;&#20351;&#24471;&#22312;&#21487;&#27604;&#26465;&#20214;&#19979;&#35780;&#20272;&#27169;&#22411;&#12289;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#32452;&#21512;&#25110;&#22797;&#29616;&#32467;&#26524;&#21464;&#24471;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#24211;&#65292;&#20197;&#35268;&#33539;LSCD&#35780;&#20272;&#12290;&#36890;&#36807;&#36879;&#26126;&#30340;&#23454;&#29616;&#65292;&#32467;&#26524;&#21464;&#24471;&#26131;&#20110;&#22797;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00176v1 Announce Type: new  Abstract: Lexical Semantic Change Detection (LSCD) is a complex, lemma-level task, which is usually operationalized based on two subsequently applied usage-level tasks: First, Word-in-Context (WiC) labels are derived for pairs of usages. Then, these labels are represented in a graph on which Word Sense Induction (WSI) is applied to derive sense clusters. Finally, LSCD labels are derived by comparing sense clusters over time. This modularity is reflected in most LSCD datasets and models. It also leads to a large heterogeneity in modeling options and task definitions, which is exacerbated by a variety of dataset versions, preprocessing options and evaluation metrics. This heterogeneity makes it difficult to evaluate models under comparable conditions, to choose optimal model combinations or to reproduce results. Hence, we provide a benchmark repository standardizing LSCD evaluation. Through transparent implementation results become easily reproducib
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35760;&#24405;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#22870;&#21169;&#22604;&#38519;&#29616;&#35937;&#65292;&#23548;&#33268;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#65292;&#19981;&#21516;&#30340;&#25552;&#31034;&#29983;&#25104;&#30340;&#22870;&#21169;&#20998;&#24067;&#30456;&#21516;&#12290;&#36825;&#20027;&#35201;&#26159;&#22240;&#20026;&#25490;&#21517;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#27861;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#32771;&#34385;&#19982;&#25552;&#31034;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2305.17608</link><description>&lt;p&gt;
&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#22870;&#21169;&#22604;&#32553;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Reward Collapse in Aligning Large Language Models. (arXiv:2305.17608v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35760;&#24405;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#22870;&#21169;&#22604;&#38519;&#29616;&#35937;&#65292;&#23548;&#33268;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#65292;&#19981;&#21516;&#30340;&#25552;&#31034;&#29983;&#25104;&#30340;&#22870;&#21169;&#20998;&#24067;&#30456;&#21516;&#12290;&#36825;&#20027;&#35201;&#26159;&#22240;&#20026;&#25490;&#21517;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#27861;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#32771;&#34385;&#19982;&#25552;&#31034;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#21644;GPT-4&#65292;&#20855;&#26377;&#38750;&#20961;&#30340;&#33021;&#21147;&#65292;&#37096;&#20998;&#21407;&#22240;&#22312;&#20110;&#23558;&#23427;&#20204;&#19982;&#35757;&#32451;&#22312;&#20154;&#31867;&#20559;&#22909;&#19978;&#30340;&#22870;&#21169;&#27169;&#22411;&#23545;&#40784;&#65292;&#36825;&#20123;&#20559;&#22909;&#36890;&#24120;&#34920;&#31034;&#20026;&#23545;&#21709;&#24212;&#25552;&#31034;&#30340;&#25490;&#21517;&#12290;&#26412;&#25991;&#35760;&#24405;&#20102;&#22870;&#21169;&#22604;&#38519;&#29616;&#35937;&#65292;&#36825;&#26159;&#19968;&#31181;&#32463;&#39564;&#35266;&#23519;&#65292;&#20854;&#20013;&#22522;&#20110;&#25490;&#21517;&#30340;&#26041;&#27861;&#23548;&#33268;&#22312;&#35757;&#32451;&#30340;&#32456;&#27490;&#38454;&#27573;&#29983;&#25104;&#30340;&#23436;&#25972;&#22870;&#21169;&#20998;&#24067;\textit{&#26080;&#35770;}\textbf{prompt&#26159;&#20160;&#20040;}&#37117;&#26159;\textit{&#30456;&#21516;&#30340;}&#12290;&#36825;&#31181;&#32467;&#26524;&#26159;&#19981;&#21487;&#21462;&#30340;&#65292;&#22240;&#20026;&#20687;&#8220;&#20889;&#19968;&#31687;&#20851;&#20110;&#20320;&#26368;&#22909;&#30340;&#26379;&#21451;&#30340;&#31616;&#30701;&#25925;&#20107;&#8221;&#36825;&#26679;&#30340;&#24320;&#25918;&#24335;&#25552;&#31034;&#24212;&#29983;&#25104;&#23436;&#25104;&#23427;&#20204;&#30340;&#36830;&#32493;&#22870;&#21169;&#33539;&#22260;&#65292;&#32780;&#20687;&#8220;&#26032;&#35199;&#20848;&#30340;&#39318;&#37117;&#26159;&#20160;&#20040;&#8221;&#36825;&#26679;&#30340;&#29305;&#23450;&#25552;&#31034;&#24212;&#29983;&#25104;&#39640;&#25110;&#20302;&#22870;&#21169;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#35843;&#26597;&#34920;&#26126;&#65292;&#22870;&#21169;&#22604;&#38519;&#20027;&#35201;&#26159;&#30001;&#20110;&#22522;&#20110;&#25490;&#21517;&#30340;&#30446;&#26631;&#20989;&#25968;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#26410;&#33021;&#32435;&#20837;&#19982;&#25552;&#31034;&#30456;&#20851;&#30340;&#20449;&#24687;&#25152;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
The extraordinary capabilities of large language models (LLMs) such as ChatGPT and GPT-4 are in part unleashed by aligning them with reward models that are trained on human preferences, which are often represented as rankings of responses to prompts. In this paper, we document the phenomenon of \textit{reward collapse}, an empirical observation where the prevailing ranking-based approach results in an \textit{identical} reward distribution \textit{regardless} of the prompts during the terminal phase of training. This outcome is undesirable as open-ended prompts like ``write a short story about your best friend'' should yield a continuous range of rewards for their completions, while specific prompts like ``what is the capital of New Zealand'' should generate either high or low rewards. Our theoretical investigation reveals that reward collapse is primarily due to the insufficiency of the ranking-based objective function to incorporate prompt-related information during optimization. Thi
&lt;/p&gt;</description></item></channel></rss>