<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#35299;&#25512;&#29702;&#26041;&#27861;(MCRank)&#65292;&#29992;&#20110;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#26465;&#20214;&#25490;&#24207;&#20219;&#21153;&#20013;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.00211</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19979;&#30340;&#22810;&#26465;&#20214;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Multi-Conditional Ranking with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00211
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#35299;&#25512;&#29702;&#26041;&#27861;(MCRank)&#65292;&#29992;&#20110;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#26465;&#20214;&#25490;&#24207;&#20219;&#21153;&#20013;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23545;&#19968;&#32452;&#39033;&#30446;&#36827;&#34892;&#25490;&#24207;&#24050;&#25104;&#20026;&#25512;&#33616;&#21644;&#26816;&#32034;&#31995;&#32479;&#20013;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#23450;&#20041;&#24182;&#25506;&#35752;&#20102;&#22810;&#26465;&#20214;&#25490;&#24207;&#30340;&#20219;&#21153;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;MCRank&#30340;&#22522;&#20934;&#65292;&#26088;&#22312;&#35780;&#20272;&#36328;&#19981;&#21516;&#39033;&#30446;&#31867;&#22411;&#21644;&#26465;&#20214;&#36827;&#34892;&#22810;&#26465;&#20214;&#25490;&#24207;&#12290;&#25105;&#20204;&#20351;&#29992;MCRank&#23545;LLMs&#36827;&#34892;&#20998;&#26512;&#34920;&#26126;&#65292;&#38543;&#30528;&#39033;&#30446;&#21644;&#26465;&#20214;&#25968;&#37327;&#20197;&#21450;&#22797;&#26434;&#24615;&#30340;&#22686;&#38271;&#65292;&#24615;&#33021;&#26174;&#33879;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#35299;&#25512;&#29702;&#26041;&#27861;&#65292;&#21253;&#25324;&#25552;&#21462;&#21644;&#25490;&#24207;&#26465;&#20214;&#65292;&#28982;&#21518;&#36845;&#20195;&#22320;&#23545;&#26465;&#20214;&#36827;&#34892;&#25490;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00211v1 Announce Type: new  Abstract: Utilizing large language models (LLMs) to rank a set of items has become a common approach in recommendation and retrieval systems. Typically, these systems focus on ordering a substantial number of documents in a monotonic order based on a given query. However, real-world scenarios often present a different challenge: ranking a comparatively smaller set of items, but according to a variety of diverse and occasionally conflicting conditions. In this paper, we define and explore the task of multi-conditional ranking by introducing MCRank, a benchmark tailored for assessing multi-conditional ranking across various item types and conditions. Our analysis of LLMs using MCRank indicates a significant decrease in performance as the number and complexity of items and conditions grow. To overcome this limitation, we propose a novel decomposed reasoning method, consisting of EXtracting and Sorting the conditions, and then Iterativly Ranking the i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20027;&#39064;&#21644;&#37322;&#20041;&#29983;&#25104;&#22522;&#20110;&#38899;&#38901;&#23398;&#30340;&#32469;&#21475;&#20196;&#30340;&#26032;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#32469;&#21475;&#20196;&#25968;&#25454;&#38598;TwistList 2.0&#65292;&#24182;&#36827;&#34892;&#20102;&#33258;&#21160;&#21644;&#20154;&#24037;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2403.13901</link><description>&lt;p&gt;
&#35757;&#32451;&#19982;&#38480;&#21046;&#65306;&#20174;&#20027;&#39064;&#21644;&#37322;&#20041;&#29983;&#25104;&#22522;&#20110;&#38899;&#38901;&#23398;&#30340;&#32469;&#21475;&#20196;
&lt;/p&gt;
&lt;p&gt;
Train &amp; Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20027;&#39064;&#21644;&#37322;&#20041;&#29983;&#25104;&#22522;&#20110;&#38899;&#38901;&#23398;&#30340;&#32469;&#21475;&#20196;&#30340;&#26032;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#32469;&#21475;&#20196;&#25968;&#25454;&#38598;TwistList 2.0&#65292;&#24182;&#36827;&#34892;&#20102;&#33258;&#21160;&#21644;&#20154;&#24037;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#22312;&#38899;&#38901;&#21644;&#35821;&#38899;&#22522;&#30784;&#30340;&#35821;&#35328;&#29983;&#25104;&#26041;&#38754;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#39046;&#22495;&#65292;&#22914;&#21452;&#20851;&#35821;&#21644;&#35799;&#27468;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20135;&#29983;&#32469;&#21475;&#20196;&#30340;&#26032;&#24037;&#20316;-&#36825;&#31181;&#35821;&#35328;&#24418;&#24335;&#38656;&#35201;&#22312;&#38899;&#32032;&#32423;&#21035;&#19978;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#65292;&#20197;&#26368;&#22823;&#31243;&#24230;&#22320;&#23454;&#29616;&#22768;&#38899;&#37325;&#21472;&#65292;&#21516;&#26102;&#19982;&#36755;&#20837;&#20027;&#39064;&#20445;&#25345;&#35821;&#20041;&#19968;&#33268;&#65292;&#20173;&#28982;&#20445;&#25345;&#35821;&#27861;&#27491;&#30830;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;TwisterLister&#65292;&#36825;&#26159;&#19968;&#20010;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#29983;&#25104;&#22522;&#20110;&#38899;&#38901;&#23398;&#30340;&#32469;&#21475;&#20196;&#30340;&#27969;&#31243;&#65292;&#25105;&#20204;&#29992;&#23427;&#26469;&#29983;&#25104;TwistList 2.0&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#26368;&#22823;&#30340;&#19968;&#20010;&#24050;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#26469;&#33258;&#20154;&#31867;&#21644;LLM&#20316;&#32773;&#21512;&#20316;&#30340;&#36229;&#36807;17K&#20010;&#20363;&#23376;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#27969;&#31243;&#28041;&#21450;&#20351;&#29992;&#38899;&#38901;&#21463;&#38480;&#35789;&#27719;&#20197;&#21450;LLM&#25552;&#31034;&#26469;&#29983;&#25104;&#26032;&#39062;&#30340;&#12289;&#38750;&#34893;&#29983;&#30340;&#32469;&#21475;&#20196;&#23454;&#20363;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#23545;&#36739;&#23567;&#35268;&#27169;&#30340;&#33258;&#21160;&#21644;&#20154;&#24037;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13901v1 Announce Type: new  Abstract: Previous work in phonologically and phonetically grounded language generation has mainly focused on domains such as puns and poetry. In this article, we present new work on the generation of tongue-twisters - a form of language that is required to be conditioned on a phoneme level to maximize sound overlap, whilst maintaining semantic consistency with an input topic and still being grammatically correct. We present TwisterLister, a pipeline for generating phonologically informed tongue-twisters from Large Language Models (LLMs) that we use to generate TwistList 2.0, the largest annotated dataset of tongue-twisters to date, consisting of 17K+ examples from a combination of human and LLM authors. Our generation pipeline involves the use of a phonologically constrained vocabulary alongside LLM prompting to generate novel, non-derivative tongue-twister examples. We additionally present the results of automatic and human evaluation of smaller
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#26041;&#27861; GORA &#21644;&#19968;&#31181;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861; SORA&#65292;&#29992;&#20197;&#35299;&#20915;&#27169;&#22411;&#32534;&#36753;&#20013;&#30340;&#38544;&#34255;&#31354;&#38388;&#20013;&#30340;&#28063;&#28458;&#25928;&#24212;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.07825</link><description>&lt;p&gt;
&#27169;&#22411;&#32534;&#36753;&#20013;&#30340;&#36951;&#28431;&#20043;&#22788;&#65306;&#28145;&#20837;&#25506;&#35752;&#27169;&#22411;&#32534;&#36753;&#24102;&#26469;&#30340;&#38544;&#34255;&#25439;&#23475;
&lt;/p&gt;
&lt;p&gt;
The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage Brought By Model Editing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#26041;&#27861; GORA &#21644;&#19968;&#31181;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861; SORA&#65292;&#29992;&#20197;&#35299;&#20915;&#27169;&#22411;&#32534;&#36753;&#20013;&#30340;&#38544;&#34255;&#31354;&#38388;&#20013;&#30340;&#28063;&#28458;&#25928;&#24212;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#20854;&#21331;&#36234;&#30340;&#25928;&#26524;&#24443;&#24213;&#25913;&#21464;&#20102;&#35768;&#22810;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23545;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#32534;&#36753;&#65292;&#20197;&#20462;&#25913;&#36807;&#26102;&#25110;&#38169;&#35823;&#20449;&#24687;&#30340;&#20851;&#38190;&#24615;&#24037;&#20316;&#65292;&#24448;&#24448;&#20250;&#23548;&#33268;&#19968;&#20010;&#31216;&#20026;&#8220;&#38544;&#34255;&#31354;&#38388;&#20013;&#30340;&#28063;&#28458;&#25928;&#24212;&#8221;&#30340;&#22797;&#26434;&#38382;&#39064;&#12290;&#36825;&#31181;&#25928;&#24212;&#34429;&#28982;&#38590;&#20197;&#26816;&#27979;&#65292;&#20294;&#21364;&#20250;&#26174;&#33879;&#38459;&#30861;&#27169;&#22411;&#32534;&#36753;&#20219;&#21153;&#30340;&#25928;&#26524;&#65292;&#24182;&#24694;&#21270;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#22522;&#20110;&#22270;&#24418;&#29305;&#24322;&#20540;&#20851;&#31995;&#30340;&#35780;&#20272;(GORA)&#65292;&#26469;&#24212;&#23545;&#36825;&#19968;&#31185;&#23398;&#25361;&#25112;&#65292;&#37327;&#21270;&#35780;&#20272;&#27169;&#22411;&#30340;&#36866;&#24212;&#24615;&#21644;&#32534;&#36753;&#30340;&#21518;&#32493;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26088;&#22312;&#20943;&#36731;&#36825;&#31181;&#28063;&#28458;&#25928;&#24212;&#30340;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#8212;&#8212;&#36873;&#25321;&#24615;&#24322;&#24120;&#20540;&#37325;&#26032;&#32534;&#36753;&#26041;&#27861;(SORA)&#12290;&#25105;&#20204;&#30340;&#20840;&#38754;&#35780;&#20272;&#25581;&#31034;&#20102;&#38544;&#34255;&#31354;&#38388;&#20013;&#30340;&#28063;&#28458;&#25928;&#24212;&#22312;&#25152;&#26377;&#24403;&#21069;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#20013;&#37117;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;G
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07825v1 Announce Type: new  Abstract: Large Language Models have revolutionized numerous tasks with their remarkable efficacy.However, the editing of these models, crucial for rectifying outdated or erroneous information, often leads to a complex issue known as the ripple effect in the hidden space. This effect, while difficult to detect, can significantly impede the efficacy of model editing tasks and deteriorate model performance.This paper addresses this scientific challenge by proposing a novel evaluation methodology, Graphical Outlier Relation based Assessment(GORA), which quantitatively evaluates the adaptations of the model and the subsequent impact of editing. Furthermore, we introduce the Selective Outlier Re-Editing Approach(SORA), a model editing method designed to mitigate this ripple effect. Our comprehensive evaluations reveal that the ripple effect in the hidden space is a significant issue in all current model editing methods. However, our proposed methods, G
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;AICL&#65289;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#31034;&#20363;&#25968;&#37327;&#26469;&#25552;&#39640;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#65292;&#31867;&#20284;&#20110;k&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20013;&#30340;&#21487;&#21464;&#22823;&#23567;&#37051;&#22495;&#12290;</title><link>https://arxiv.org/abs/2403.06402</link><description>&lt;p&gt;
&#19968;&#20992;&#20999;&#19981;&#36866;&#29992;&#65306;&#23398;&#20064;&#22312;&#25991;&#26412;&#20998;&#31867;&#20013;&#20351;&#29992;&#22810;&#23569;&#20363;&#20026;&#20102;&#25913;&#36827;&#19978;&#19979;&#25991;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
'One size doesn't fit all': Learning how many Examples to use for In-Context Learning for Improved Text Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;AICL&#65289;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#31034;&#20363;&#25968;&#37327;&#26469;&#25552;&#39640;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#65292;&#31867;&#20284;&#20110;k&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20013;&#30340;&#21487;&#21464;&#22823;&#23567;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06402v1 &#21457;&#34920;&#31867;&#22411;&#65306;&#26032; Abstract: &#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#30340;&#39044;&#27979;&#27169;&#22411;&#24050;&#32463;&#20174;&#20174;&#22836;&#35757;&#32451;&#27169;&#22411;&#21457;&#23637;&#21040;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#36825;&#31181;&#24494;&#35843;&#30340;&#26497;&#31471;&#24418;&#24335;&#28041;&#21450;&#21040;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#65292;&#20854;&#20013;&#19968;&#20010;&#39044;&#20808;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#36755;&#20986;&#65288;&#20923;&#32467;&#30340;&#35299;&#30721;&#22120;&#21442;&#25968;&#65289;&#21482;&#21463;&#21040;&#36755;&#20837;&#23383;&#31526;&#20018;&#30340;&#21464;&#21270;&#65288;&#31216;&#20026;&#25351;&#20196;&#25110;&#25552;&#31034;&#65289;&#30340;&#25511;&#21046;&#12290;ICL&#30340;&#19968;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#26159;&#22312;&#25552;&#31034;&#20013;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#23454;&#20363;&#20316;&#20026;&#31034;&#20363;&#12290;&#23613;&#31649;&#29616;&#26377;&#24037;&#20316;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20026;&#27599;&#20010;&#25968;&#25454;&#23454;&#20363;&#20351;&#29992;&#38745;&#24577;&#25968;&#37327;&#30340;&#31034;&#20363;&#65292;&#20294;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#35843;&#25972;&#31034;&#20363;&#25968;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31867;&#20284;&#20110;k&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20998;&#31867;&#22120;&#20013;&#20351;&#29992;&#21487;&#21464;&#22823;&#23567;&#37051;&#22495;&#30340;&#26041;&#27861;&#12290;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#33258;&#36866;&#24212;ICL&#65288;AICL&#65289;&#30340;&#24037;&#20316;&#27969;&#31243;&#20013;&#65292;&#23545;&#20110;&#29305;&#23450;&#25968;&#25454;&#23454;&#20363;&#36827;&#34892;&#25512;&#29702;&#26102;&#20351;&#29992;&#30340;&#28436;&#31034;&#25968;&#37327;&#26159;&#21160;&#24577;&#35843;&#25972;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06402v1 Announce Type: new  Abstract: Predictive models in natural language processing (NLP) have evolved from training models from scratch to fine-tuning pre-trained models with labelled data. An extreme form of this fine-tuning involves in-context learning (ICL), where the output of a pre-trained generative model (frozen decoder parameters) is controlled only with variations in the input strings (called instructions or prompts). An important component of ICL is the use of a small number of labelled data instances as examples in the prompt. While existing work uses a static number of examples during inference for each data instance, in this paper we propose a novel methodology of dynamically adapting the number of examples as per the data. This is analogous to the use of a variable-sized neighborhood in k-nearest neighbors (k-NN) classifier. In our proposed workflow of adaptive ICL (AICL), the number of demonstrations to employ during the inference on a particular data inst
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;MaiBaam&#35821;&#26009;&#24211;&#30340;&#27880;&#37322;&#20934;&#21017;&#65292;&#35814;&#32454;&#20171;&#32461;&#20102;&#22914;&#20309;&#22788;&#29702;&#21644;&#26631;&#35760;&#24052;&#20240;&#21033;&#20122;&#25968;&#25454;&#65292;&#35828;&#26126;&#20102;&#35789;&#24615;&#26631;&#35760;&#21644;&#20381;&#36182;&#20851;&#31995;&#30340;&#20351;&#29992;&#65292;&#20197;&#21450;&#23545;&#24503;&#35821;&#31561;&#30456;&#20851;&#35821;&#35328;&#36866;&#29992;&#30340;&#27880;&#37322;&#20915;&#31574;&#21644;&#23545;&#24052;&#20240;&#21033;&#20122;&#35821;&#27861;&#29305;&#23450;&#20915;&#31574;&#30340;&#20171;&#32461;&#21644;&#25512;&#21160;&#12290;</title><link>https://arxiv.org/abs/2403.05902</link><description>&lt;p&gt;
MaiBaam&#27880;&#37322;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
MaiBaam Annotation Guidelines
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05902
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;MaiBaam&#35821;&#26009;&#24211;&#30340;&#27880;&#37322;&#20934;&#21017;&#65292;&#35814;&#32454;&#20171;&#32461;&#20102;&#22914;&#20309;&#22788;&#29702;&#21644;&#26631;&#35760;&#24052;&#20240;&#21033;&#20122;&#25968;&#25454;&#65292;&#35828;&#26126;&#20102;&#35789;&#24615;&#26631;&#35760;&#21644;&#20381;&#36182;&#20851;&#31995;&#30340;&#20351;&#29992;&#65292;&#20197;&#21450;&#23545;&#24503;&#35821;&#31561;&#30456;&#20851;&#35821;&#35328;&#36866;&#29992;&#30340;&#27880;&#37322;&#20915;&#31574;&#21644;&#23545;&#24052;&#20240;&#21033;&#20122;&#35821;&#27861;&#29305;&#23450;&#20915;&#31574;&#30340;&#20171;&#32461;&#21644;&#25512;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;MaiBaam&#30340;&#27880;&#37322;&#20934;&#21017;&#65292;&#36825;&#26159;&#19968;&#20010;&#27880;&#37322;&#20102;&#35789;&#24615;&#26631;&#35760;&#21644;&#21477;&#27861;&#20381;&#36182;&#20851;&#31995;&#30340;&#24052;&#20240;&#21033;&#20122;&#35821;&#35821;&#26009;&#24211;&#12290;MaiBaam&#23646;&#20110;&#36890;&#29992;&#20381;&#23384;&#20851;&#31995;&#39033;&#30446;&#65288;UD&#65289;&#65292;&#25105;&#20204;&#30340;&#27880;&#37322;&#35814;&#32454;&#35828;&#26126;&#20102;&#19968;&#33324;&#21644;&#24503;&#22269;UD&#31532;2&#29256;&#25351;&#21335;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#22914;&#20309;&#39044;&#22788;&#29702;&#21644;&#26631;&#35760;&#24052;&#20240;&#21033;&#20122;&#25968;&#25454;&#65292;&#27010;&#36848;&#20102;&#25105;&#20204;&#20351;&#29992;&#30340;&#35789;&#24615;&#26631;&#35760;&#21644;&#20381;&#36182;&#20851;&#31995;&#65292;&#35299;&#37322;&#20102;&#20063;&#36866;&#29992;&#20110;&#24503;&#35821;&#31561;&#23494;&#20999;&#30456;&#20851;&#35821;&#35328;&#30340;&#27880;&#37322;&#20915;&#31574;&#65292;&#26368;&#21518;&#20171;&#32461;&#24182;&#25512;&#21160;&#20102;&#36866;&#29992;&#20110;&#24052;&#20240;&#21033;&#20122;&#35821;&#27861;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05902v1 Announce Type: new  Abstract: This document provides the annotation guidelines for MaiBaam, a Bavarian corpus annotated with part-of-speech (POS) tags and syntactic dependencies. MaiBaam belongs to the Universal Dependencies (UD) project, and our annotations elaborate on the general and German UD version 2 guidelines. In this document, we detail how to preprocess and tokenize Bavarian data, provide an overview of the POS tags and dependencies we use, explain annotation decisions that would also apply to closely related languages like German, and lastly we introduce and motivate decisions that are specific to Bavarian grammar.
&lt;/p&gt;</description></item><item><title>WaterMax&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#29983;&#25104;&#25991;&#26412;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#25171;&#30772;&#20102;&#27700;&#21360;&#25216;&#26415;&#20013;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#20256;&#32479;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.04808</link><description>&lt;p&gt;
WaterMax: &#25171;&#30772;LLM&#27700;&#21360;&#21487;&#26816;&#27979;&#24615;-&#31283;&#20581;&#24615;-&#36136;&#37327;&#30340;&#24179;&#34913;
&lt;/p&gt;
&lt;p&gt;
WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04808
&lt;/p&gt;
&lt;p&gt;
WaterMax&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#29983;&#25104;&#25991;&#26412;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#25171;&#30772;&#20102;&#27700;&#21360;&#25216;&#26415;&#20013;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#20256;&#32479;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27700;&#21360;&#26159;&#38459;&#27490;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#24694;&#24847;&#20351;&#29992;&#30340;&#25216;&#26415;&#25163;&#27573;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;WaterMax&#30340;&#26032;&#39062;&#27700;&#21360;&#26041;&#26696;&#65292;&#20855;&#26377;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#21407;&#22987;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#36136;&#37327;&#12290;&#20854;&#26032;&#35774;&#35745;&#19981;&#20250;&#23545;LLM&#36827;&#34892;&#20219;&#20309;&#20462;&#25913;&#65288;&#19981;&#35843;&#25972;&#26435;&#37325;&#12289;&#23545;&#25968;&#12289;&#28201;&#24230;&#25110;&#37319;&#26679;&#25216;&#26415;&#65289;&#12290;WaterMax&#24179;&#34913;&#20102;&#31283;&#20581;&#24615;&#21644;&#22797;&#26434;&#24615;&#65292;&#19982;&#25991;&#29486;&#20013;&#30340;&#27700;&#21360;&#25216;&#26415;&#30456;&#21453;&#65292;&#20174;&#26681;&#26412;&#19978;&#24341;&#21457;&#20102;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#20854;&#24615;&#33021;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#35777;&#26126;&#24182;&#32463;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;&#22312;&#26368;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#19979;&#65292;&#23427;&#32988;&#36807;&#25152;&#26377;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04808v1 Announce Type: cross  Abstract: Watermarking is a technical means to dissuade malfeasant usage of Large Language Models. This paper proposes a novel watermarking scheme, so-called WaterMax, that enjoys high detectability while sustaining the quality of the generated text of the original LLM. Its new design leaves the LLM untouched (no modification of the weights, logits, temperature, or sampling technique). WaterMax balances robustness and complexity contrary to the watermarking techniques of the literature inherently provoking a trade-off between quality and robustness. Its performance is both theoretically proven and experimentally validated. It outperforms all the SotA techniques under the most complete benchmark suite.
&lt;/p&gt;</description></item><item><title>SciAssess&#20171;&#32461;&#20102;&#19968;&#20010;&#19987;&#20026;&#28145;&#24230;&#20998;&#26512;&#31185;&#23398;&#25991;&#29486;&#32780;&#35774;&#35745;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#26088;&#22312;&#20840;&#38754;&#35780;&#20272;LLMs&#22312;&#31185;&#23398;&#39046;&#22495;&#35760;&#24518;&#12289;&#29702;&#35299;&#21644;&#20998;&#26512;&#33021;&#21147;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.01976</link><description>&lt;p&gt;
SciAssess&#65306;&#22522;&#20934;&#27979;&#35797;LLM&#22312;&#31185;&#23398;&#25991;&#29486;&#20998;&#26512;&#20013;&#30340;&#29087;&#32451;&#31243;&#24230;
&lt;/p&gt;
&lt;p&gt;
SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01976
&lt;/p&gt;
&lt;p&gt;
SciAssess&#20171;&#32461;&#20102;&#19968;&#20010;&#19987;&#20026;&#28145;&#24230;&#20998;&#26512;&#31185;&#23398;&#25991;&#29486;&#32780;&#35774;&#35745;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#26088;&#22312;&#20840;&#38754;&#35780;&#20272;LLMs&#22312;&#31185;&#23398;&#39046;&#22495;&#35760;&#24518;&#12289;&#29702;&#35299;&#21644;&#20998;&#26512;&#33021;&#21147;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01976v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#25277;&#35937;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#31361;&#30772;&#24050;&#32463;&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#65292;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#21033;&#29992;&#36825;&#20123;&#25216;&#26415;&#36827;&#34892;&#32454;&#33268;&#31185;&#23398;&#25991;&#29486;&#20998;&#26512;&#30340;&#20852;&#36259;&#28608;&#22686;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#26410;&#33021;&#20805;&#20998;&#35780;&#20272;LLMs&#22312;&#31185;&#23398;&#39046;&#22495;&#30340;&#29087;&#32451;&#31243;&#24230;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#22797;&#26434;&#29702;&#35299;&#21644;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SciAssess&#65292;&#19968;&#20010;&#19987;&#20026;&#28145;&#24230;&#20998;&#26512;&#31185;&#23398;&#25991;&#29486;&#32780;&#35774;&#35745;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#26088;&#22312;&#20840;&#38754;&#35780;&#20272;LLMs&#30340;&#26377;&#25928;&#24615;&#12290;SciAssess&#19987;&#27880;&#20110;&#35780;&#20272;LLMs&#22312;&#31185;&#23398;&#32972;&#26223;&#19979;&#35760;&#24518;&#12289;&#29702;&#35299;&#21644;&#20998;&#26512;&#30340;&#33021;&#21147;&#12290;&#23427;&#21253;&#25324;&#26469;&#33258;&#19981;&#21516;&#31185;&#23398;&#39046;&#22495;&#30340;&#20195;&#34920;&#24615;&#20219;&#21153;&#65292;&#22914;&#19968;&#33324;&#21270;&#23398;&#12289;&#26377;&#26426;&#26448;&#26009;&#21644;&#21512;&#37329;&#26448;&#26009;&#12290;&#20005;&#26684;&#30340;&#36136;&#37327;&#25511;&#21046;&#25514;&#26045;&#30830;&#20445;&#20102;&#20854;&#22312;&#27491;&#30830;&#24615;&#12289;&#21311;&#21517;&#21270;&#21644;&#22797;&#21046;&#26041;&#38754;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01976v1 Announce Type: new  Abstract: Recent breakthroughs in Large Language Models (LLMs) have revolutionized natural language understanding and generation, igniting a surge of interest in leveraging these technologies for the nuanced field of scientific literature analysis. Existing benchmarks, however, inadequately evaluate the proficiency of LLMs in the scientific domain, especially in scenarios involving complex comprehension and multimodal data. In response, we introduced SciAssess, a benchmark tailored for the in-depth analysis of scientific literature, crafted to provide a thorough assessment of LLMs' efficacy. SciAssess focuses on evaluating LLMs' abilities in memorization, comprehension, and analysis within scientific contexts. It includes representative tasks from diverse scientific fields, such as general chemistry, organic materials, and alloy materials. And rigorous quality control measures ensure its reliability in terms of correctness, anonymization, and copy
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#26694;&#26550;&#65292;&#26088;&#22312;&#20998;&#26512;&#20027;&#27969;&#23186;&#20307;&#22312;&#25253;&#36947;&#32463;&#27982;&#28040;&#24687;&#26102;&#30340;&#32534;&#36753;&#36873;&#25321;&#65292;&#36890;&#36807;&#23545;&#32463;&#27982;&#25351;&#26631;&#30340;&#25253;&#36947;&#36827;&#34892;&#26694;&#26550;&#20998;&#26512;&#65292;&#25105;&#20204;&#21487;&#20197;&#29702;&#35299;&#20986;&#29256;&#29289;&#36873;&#25321;&#21644;&#26500;&#26550;&#30340;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2402.14224</link><description>&lt;p&gt;
&#22312;&#25903;&#25345;&#25968;&#25454;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#26694;&#26550;&#26500;&#24314;&#65306;&#20197;&#32654;&#22269;&#32463;&#27982;&#26032;&#38395;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Framing in the Presence of Supporting Data: A Case Study in U.S. Economic News
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#26694;&#26550;&#65292;&#26088;&#22312;&#20998;&#26512;&#20027;&#27969;&#23186;&#20307;&#22312;&#25253;&#36947;&#32463;&#27982;&#28040;&#24687;&#26102;&#30340;&#32534;&#36753;&#36873;&#25321;&#65292;&#36890;&#36807;&#23545;&#32463;&#27982;&#25351;&#26631;&#30340;&#25253;&#36947;&#36827;&#34892;&#26694;&#26550;&#20998;&#26512;&#65292;&#25105;&#20204;&#21487;&#20197;&#29702;&#35299;&#20986;&#29256;&#29289;&#36873;&#25321;&#21644;&#26500;&#26550;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#27969;&#23186;&#20307;&#22312;&#36873;&#25321;&#20309;&#20107;&#29289;&#36827;&#34892;&#25253;&#36947;&#20197;&#21450;&#22914;&#20309;&#36827;&#34892;&#25253;&#36947;&#26041;&#38754;&#26377;&#24456;&#22823;&#30340;&#33258;&#30001;&#35009;&#37327;&#26435;&#12290;&#36825;&#20123;&#36873;&#25321;&#20250;&#23545;&#20154;&#20204;&#25152;&#20102;&#35299;&#30340;&#20449;&#24687;&#21644;&#38543;&#21518;&#30340;&#34892;&#20026;&#20135;&#29983;&#30495;&#23454;&#19990;&#30028;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#23458;&#35266;&#30340;&#35780;&#20272;&#32534;&#36753;&#36873;&#25321;&#30340;&#24230;&#37327;&#20351;&#24471;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#29305;&#21035;&#22256;&#38590;&#12290;&#26412;&#25991;&#35748;&#20026;&#22312;&#19968;&#20123;&#26377;&#25903;&#25345;&#25968;&#25454;&#23384;&#22312;&#30340;&#20540;&#24471;&#25253;&#36947;&#30340;&#35805;&#39064;&#20013;&#65292;&#21487;&#20197;&#25552;&#20986;&#19968;&#20010;&#35745;&#31639;&#26694;&#26550;&#26469;&#20998;&#26512;&#32534;&#36753;&#36873;&#25321;&#12290;&#25105;&#20204;&#36873;&#25321;&#32463;&#27982;&#20316;&#20026;&#30740;&#31350;&#37325;&#28857;&#65292;&#22240;&#20026;&#32463;&#27982;&#25351;&#26631;&#30340;&#25253;&#36947;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#23545;&#23481;&#26131;&#30830;&#23450;&#21508;&#31181;&#20986;&#29256;&#29289;&#36873;&#25321;&#21644;&#26500;&#26550;&#30340;&#26041;&#24335;&#12290;&#36825;&#20123;&#25351;&#26631;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#20851;&#32463;&#27982;&#34920;&#29616;&#30340;&#30495;&#23454;&#24773;&#20917;&#65292;&#30456;&#23545;&#20110;&#20986;&#29256;&#29289;&#23545;&#20854;&#36827;&#34892;&#25253;&#36947;&#30340;&#26041;&#24335;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#23558;&#26694;&#26550;&#39044;&#27979;&#23450;&#20041;&#20026;&#19968;&#32452;&#30456;&#20114;&#20381;&#36182;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14224v1 Announce Type: new  Abstract: The mainstream media has much leeway in what it chooses to cover and how it covers it. These choices have real-world consequences on what people know and their subsequent behaviors. However, the lack of objective measures to evaluate editorial choices makes research in this area particularly difficult. In this paper, we argue that there are newsworthy topics where objective measures exist in the form of supporting data and propose a computational framework to analyze editorial choices in this setup. We focus on the economy because the reporting of economic indicators presents us with a relatively easy way to determine both the selection and framing of various publications. Their values provide a ground truth of how the economy is doing relative to how the publications choose to cover it. To do this, we define frame prediction as a set of interdependent tasks. At the article level, we learn to identify the reported stance towards the gene
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#30340;&#20840;&#38754;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#19994;&#22810;&#35821;&#35328;&#38382;&#31572;&#25968;&#25454;&#38598;&#65292;&#24182;&#30740;&#31350;&#20102;&#36825;&#20123;&#32622;&#20449;&#24230;&#20998;&#25968;&#22914;&#20309;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#65292;&#26368;&#32456;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#32622;&#20449;&#24230;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.13606</link><description>&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13606
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#30340;&#20840;&#38754;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#19994;&#22810;&#35821;&#35328;&#38382;&#31572;&#25968;&#25454;&#38598;&#65292;&#24182;&#30740;&#31350;&#20102;&#36825;&#20123;&#32622;&#20449;&#24230;&#20998;&#25968;&#22914;&#20309;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#65292;&#26368;&#32456;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#32622;&#20449;&#24230;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24187;&#35273;&#24182;&#22312;&#39044;&#27979;&#20013;&#34920;&#29616;&#36807;&#20110;&#33258;&#20449;&#30340;&#20542;&#21521;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#20854;&#21487;&#38752;&#24615;&#30340;&#25285;&#24551;&#12290;&#34920;&#26126;&#27169;&#22411;&#21709;&#24212;&#30340;&#21487;&#20449;&#24230;&#25110;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23545;&#20110;&#24320;&#21457;&#21487;&#38752;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#30446;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#33521;&#35821;&#20013;LLM&#30340;&#32622;&#20449;&#24230;&#20272;&#35745;&#19978;&#65292;&#22312;&#20854;&#20182;&#24191;&#27867;&#20351;&#29992;&#30340;&#35821;&#35328;&#26041;&#38754;&#20173;&#23384;&#22312;&#31354;&#30333;&#65292;&#38459;&#30861;&#20102;&#21487;&#38752;AI&#24212;&#29992;&#30340;&#20840;&#29699;&#21457;&#23637;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#23545;LLM&#19978;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#65288;MlingConf&#65289;&#30340;&#20840;&#38754;&#35843;&#26597;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#32463;&#36807;&#35814;&#32454;&#26816;&#26597;&#30340;&#19987;&#19994;&#22810;&#35821;&#35328;&#38382;&#31572;&#25968;&#25454;&#38598;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#32622;&#20449;&#24230;&#20272;&#35745;&#30340;&#24615;&#33021;&#65292;&#24182;&#30740;&#31350;&#36825;&#20123;&#32622;&#20449;&#24230;&#20998;&#25968;&#22914;&#20309;&#36890;&#36807;&#36328;&#19981;&#21516;&#35821;&#35328;&#30340;&#33258;&#25105;&#23436;&#21892;&#26469;&#22686;&#24378;LLM&#30340;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#32622;&#20449;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13606v1 Announce Type: new  Abstract: The tendency of Large Language Models to generate hallucinations and exhibit overconfidence in predictions raises concerns regarding their reliability. Confidence or uncertainty estimations indicating the extent of trustworthiness of a model's response are essential to developing reliable AI systems. Current research primarily focuses on LLM confidence estimations in English, remaining a void for other widely used languages and impeding the global development of reliable AI applications. This paper introduces a comprehensive investigation of Multi-lingual confidence estimation (MlingConf) on LLMs. First, we introduce an elaborated and expert-checked multilingual QA dataset. Second, we delve into the performance of confidence estimations and examine how these confidence scores can enhance LLM performance through self-refinement across diverse languages. Finally, we propose a cross-lingual confidence estimation method to achieve more preci
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23450;&#20041;&#35745;&#31639;&#29615;&#22659;&#20013;&#29702;&#35299;&#25919;&#27835;&#25991;&#26412;&#20013;&#27169;&#26865;&#20004;&#21487;&#38472;&#36848;&#25152;&#38656;&#32972;&#26223;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#27492;&#26469;&#20998;&#26512;&#21644;&#39044;&#27979;&#25991;&#26412;&#30340;&#30495;&#23454;&#19990;&#30028;&#32972;&#26223;&#12290;</title><link>https://arxiv.org/abs/2311.09106</link><description>&lt;p&gt;
&#8220;&#25105;&#20204;&#35201;&#27714;&#20844;&#27491;&#65281;&#8221;&#65306;&#25919;&#27835;&#25991;&#26412;&#30340;&#31038;&#20250;&#32972;&#26223;&#22880;&#22522;
&lt;/p&gt;
&lt;p&gt;
"We Demand Justice!": Towards Social Context Grounding of Political Texts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23450;&#20041;&#35745;&#31639;&#29615;&#22659;&#20013;&#29702;&#35299;&#25919;&#27835;&#25991;&#26412;&#20013;&#27169;&#26865;&#20004;&#21487;&#38472;&#36848;&#25152;&#38656;&#32972;&#26223;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#27492;&#26469;&#20998;&#26512;&#21644;&#39044;&#27979;&#25991;&#26412;&#30340;&#30495;&#23454;&#19990;&#30028;&#32972;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#35805;&#35821;&#32463;&#24120;&#21253;&#25324;&#8220;&#30475;&#20284;&#30456;&#20284;&#30340;&#35821;&#35328;&#34987;&#25919;&#27835;&#20809;&#35889;&#20004;&#31471;&#20351;&#29992;&#8221;&#65292;&#24448;&#24448;&#36716;&#21270;&#20026;&#25130;&#28982;&#19981;&#21516;&#30340;&#35266;&#28857;&#12290;&#20363;&#22914;&#65292;&#8220;&#24605;&#24565;&#19982;&#31048;&#31095;&#8221;&#21487;&#33021;&#34920;&#36798;&#23545;&#22823;&#35268;&#27169;&#26538;&#20987;&#21463;&#23475;&#32773;&#30340;&#21516;&#24773;&#65292;&#20063;&#21487;&#33021;&#25209;&#35780;&#23545;&#35813;&#38382;&#39064;&#32570;&#20047;&#31435;&#27861;&#34892;&#21160;&#12290;&#26412;&#25991;&#22312;&#35745;&#31639;&#29615;&#22659;&#20013;&#23450;&#20041;&#20102;&#23436;&#20840;&#29702;&#35299;&#27492;&#31867;&#27169;&#26865;&#20004;&#21487;&#38472;&#36848;&#25152;&#38656;&#30340;&#32972;&#26223;&#65292;&#24182;&#20351;&#20854;&#22522;&#20110;&#29616;&#23454;&#19990;&#30028;&#30340;&#23454;&#20307;&#12289;&#34892;&#21160;&#21644;&#24577;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#38656;&#35201;&#29702;&#35299;&#25991;&#26412;&#23454;&#38469;&#32972;&#26223;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#25968;&#25454;&#38598;&#19982;&#22522;&#20110;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;&#22914;RoBERTa&#21644;GPT-3&#65289;&#26500;&#24314;&#30340;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#24182;&#23545;&#29616;&#26377;&#30340;&#8220;&#35758;&#35821;&#24773;&#22659;&#21270;&#26694;&#26550;&#8221;&#21644;&#8220;&#25919;&#27835;&#35282;&#33394;&#34920;&#24449;&#8221;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25968;&#25454;&#38598;&#21644;&#39044;&#27979;&#20197;&#33719;&#24471;&#26356;&#22810;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09106v2 Announce Type: replace  Abstract: Social media discourse frequently consists of 'seemingly similar language used by opposing sides of the political spectrum', often translating to starkly contrasting perspectives. E.g., 'thoughts and prayers', could express sympathy for mass-shooting victims, or criticize the lack of legislative action on the issue. This paper defines the context required to fully understand such ambiguous statements in a computational setting and ground them in real-world entities, actions, and attitudes. We propose two challenging datasets that require an understanding of the real-world context of the text. We benchmark these datasets against models built upon large pre-trained models, such as RoBERTa and GPT-3. Additionally, we develop and benchmark more structured models building upon existing Discourse Contextualization Framework and Political Actor Representation models. We analyze the datasets and the predictions to obtain further insights int
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VTG&#30340;&#21019;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#20855;&#26377;&#36827;&#21270;&#35760;&#24518;&#21644;&#33258;&#25105;&#21453;&#24605;&#30340;&#21487;&#39564;&#35777;&#25991;&#26412;&#29983;&#25104;&#12290;&#36890;&#36807;&#24341;&#20837;&#36827;&#21270;&#22411;&#38271;&#30701;&#26399;&#35760;&#24518;&#21644;&#20004;&#23618;&#39564;&#35777;&#22120;&#65292;VTG&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#20449;&#24687;&#38169;&#35823;&#21644;&#20934;&#30830;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.09075</link><description>&lt;p&gt;
&#23454;&#29616;&#20855;&#26377;&#36827;&#21270;&#35760;&#24518;&#21644;&#33258;&#25105;&#21453;&#24605;&#30340;&#21487;&#39564;&#35777;&#25991;&#26412;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Towards Verifiable Text Generation with Evolving Memory and Self-Reflection. (arXiv:2312.09075v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.09075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VTG&#30340;&#21019;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#20855;&#26377;&#36827;&#21270;&#35760;&#24518;&#21644;&#33258;&#25105;&#21453;&#24605;&#30340;&#21487;&#39564;&#35777;&#25991;&#26412;&#29983;&#25104;&#12290;&#36890;&#36807;&#24341;&#20837;&#36827;&#21270;&#22411;&#38271;&#30701;&#26399;&#35760;&#24518;&#21644;&#20004;&#23618;&#39564;&#35777;&#22120;&#65292;VTG&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#20449;&#24687;&#38169;&#35823;&#21644;&#20934;&#30830;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#20986;&#33394;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#20250;&#20135;&#29983;&#38169;&#35823;&#30340;&#20449;&#24687;&#65292;&#20063;&#34987;&#31216;&#20026;&#24187;&#35273;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#26159;&#21487;&#39564;&#35777;&#30340;&#25991;&#26412;&#29983;&#25104;&#65292;&#23427;&#20419;&#20351;LLMs&#29983;&#25104;&#20855;&#26377;&#24341;&#29992;&#20197;&#36827;&#34892;&#20934;&#30830;&#24615;&#39564;&#35777;&#30340;&#20869;&#23481;&#12290;&#28982;&#32780;&#65292;&#21487;&#39564;&#35777;&#30340;&#25991;&#26412;&#29983;&#25104;&#24182;&#19981;&#31616;&#21333;&#65292;&#22240;&#20026;&#23384;&#22312;&#28966;&#28857;&#36716;&#31227;&#29616;&#35937;&#65292;&#38656;&#35201;&#22797;&#26434;&#30340;&#25512;&#29702;&#26469;&#19982;&#27491;&#30830;&#30340;&#24341;&#25991;&#23545;&#40784;&#65292;&#32780;&#19988;&#22312;&#26816;&#32034;&#25991;&#26723;&#30340;&#31934;&#30830;&#24615;&#21644;&#24191;&#24230;&#20043;&#38388;&#23384;&#22312;&#30528;&#20004;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#20855;&#26377;&#36827;&#21270;&#35760;&#24518;&#21644;&#33258;&#25105;&#21453;&#24605;&#30340;&#21487;&#39564;&#35777;&#25991;&#26412;&#29983;&#25104;&#26694;&#26550;VTG&#12290;VTG&#24341;&#20837;&#20102;&#36827;&#21270;&#22411;&#38271;&#30701;&#26399;&#35760;&#24518;&#20197;&#20445;&#30041;&#26377;&#20215;&#20540;&#30340;&#25991;&#26723;&#21644;&#26368;&#36817;&#30340;&#25991;&#26723;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#37197;&#22791;&#35777;&#25454;&#21457;&#29616;&#22120;&#30340;&#20004;&#23618;&#39564;&#35777;&#22120;&#65292;&#29992;&#20110;&#37325;&#26032;&#24605;&#32771;&#21644;&#21453;&#24605;&#20027;&#24352;&#19982;&#24341;&#25991;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#36824;&#37319;&#29992;&#20027;&#21160;&#26816;&#32034;&#21644;&#22810;&#26679;&#21270;&#30340;&#26041;&#24335;&#26469;&#25552;&#39640;&#35770;&#35777;&#30340;&#36136;&#37327;&#21644;&#24191;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the remarkable ability of large language models (LLMs) in language comprehension and generation, they often suffer from producing factually incorrect information, also known as hallucination. A promising solution to this issue is verifiable text generation, which prompts LLMs to generate content with citations for accuracy verification. However, verifiable text generation is non-trivial due to the focus-shifting phenomenon, the intricate reasoning needed to align the claim with correct citations, and the dilemma between the precision and breadth of retrieved documents. In this paper, we present VTG, an innovative framework for Verifiable Text Generation with evolving memory and self-reflection. VTG introduces evolving long short-term memory to retain both valuable documents and recent documents. A two-tier verifier equipped with an evidence finder is proposed to rethink and reflect on the relationship between the claim and citations. Furthermore, active retrieval and diverse qu
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23454;&#20307;&#21305;&#37197;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;LLMs&#23545;&#35757;&#32451;&#25968;&#25454;&#38656;&#27714;&#36739;&#23569;&#19988;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11244</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#23454;&#20307;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Entity Matching using Large Language Models. (arXiv:2310.11244v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11244
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23454;&#20307;&#21305;&#37197;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;LLMs&#23545;&#35757;&#32451;&#25968;&#25454;&#38656;&#27714;&#36739;&#23569;&#19988;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#21305;&#37197;&#26159;&#21028;&#26029;&#20004;&#20010;&#23454;&#20307;&#25551;&#36848;&#26159;&#21542;&#25351;&#30340;&#26159;&#21516;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#23454;&#20307;&#30340;&#20219;&#21153;&#12290;&#23454;&#20307;&#21305;&#37197;&#26159;&#22823;&#22810;&#25968;&#25968;&#25454;&#38598;&#25104;&#27969;&#31243;&#20013;&#30340;&#26680;&#24515;&#27493;&#39588;&#65292;&#20063;&#26159;&#35768;&#22810;&#30005;&#23376;&#21830;&#21153;&#24212;&#29992;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#36825;&#20123;&#24212;&#29992;&#38656;&#35201;&#23558;&#26469;&#33258;&#19981;&#21516;&#20379;&#24212;&#21830;&#30340;&#20135;&#21697;&#21305;&#37197;&#36215;&#26469;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#23454;&#20307;&#21305;&#37197;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;&#22914;BERT&#25110;RoBERTa&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#23454;&#20307;&#21305;&#37197;&#20013;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#32570;&#28857;&#65306;&#65288;i&#65289;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#29305;&#23450;&#20219;&#21153;&#30340;&#35757;&#32451;&#25968;&#25454;&#65307;&#65288;ii&#65289;&#24494;&#35843;&#21518;&#30340;&#27169;&#22411;&#23545;&#20110;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#30340;&#23454;&#20307;&#19981;&#22815;&#20581;&#22766;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22522;&#20110;PLMs&#30340;&#21305;&#37197;&#22120;&#30340;&#22791;&#36873;&#26041;&#26696;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;LLMs&#23545;&#39046;&#22495;&#29305;&#23450;&#35757;&#32451;&#25968;&#25454;&#38656;&#27714;&#36739;&#23569;&#19988;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#28085;&#30422;&#20102;&#25176;&#31649;&#30340;LLMs&#65292;&#22914;GPT3.5&#21644;GPT4&#65292;&#20197;&#21450;&#22522;&#20110;Llama2&#30340;&#24320;&#28304;LLMs&#65292;&#21487;&#20197;&#22312;&#26412;&#22320;&#36816;&#34892;&#12290;&#25105;&#20204;&#22312;&#38646;&#26679;&#26412;&#22330;&#26223;&#21644;&#8230;
&lt;/p&gt;
&lt;p&gt;
Entity Matching is the task of deciding whether two entity descriptions refer to the same real-world entity. Entity Matching is a central step in most data integration pipelines and an enabler for many e-commerce applications which require to match products offers from different vendors. State-of-the-art entity matching methods often rely on pre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks of these models for entity matching are that (i) the models require significant amounts of task-specific training data and (ii) the fine-tuned models are not robust concerning out-of-distribution entities. In this paper, we investigate using large language models (LLMs) for entity matching as a less domain-specific training data reliant and more robust alternative to PLM-based matchers. Our study covers hosted LLMs, such as GPT3.5 and GPT4, as well as open source LLMs based on Llama2 which can be run locally. We evaluate these models in a zero-shot scenario as well as a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#26597;&#35810;&#37325;&#26500;&#65288;ZeQR&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;&#35299;&#37322;&#24615;&#19981;&#36275;&#21644;&#27495;&#20041;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.09384</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#26597;&#35810;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Zero-shot Query Reformulation for Conversational Search. (arXiv:2307.09384v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09384
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#26597;&#35810;&#37325;&#26500;&#65288;ZeQR&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;&#35299;&#37322;&#24615;&#19981;&#36275;&#21644;&#27495;&#20041;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35821;&#38899;&#21161;&#25163;&#30340;&#26222;&#21450;&#65292;&#23545;&#35805;&#25628;&#32034;&#22312;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#24341;&#36215;&#20102;&#26356;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#20005;&#37325;&#38459;&#30861;&#20102;&#30417;&#30563;&#24335;&#23545;&#35805;&#25628;&#32034;&#26041;&#27861;&#30340;&#36827;&#23637;&#12290;&#22240;&#27492;&#65292;&#30740;&#31350;&#20154;&#21592;&#26356;&#21152;&#20851;&#27880;&#38646;&#26679;&#26412;&#23545;&#35805;&#25628;&#32034;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#38646;&#26679;&#26412;&#26041;&#27861;&#23384;&#22312;&#19977;&#20010;&#20027;&#35201;&#38480;&#21046;&#65306;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#30340;&#26816;&#32034;&#22120;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#32570;&#20047;&#36275;&#22815;&#30340;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#20182;&#20204;&#26080;&#27861;&#35299;&#20915;&#22240;&#30465;&#30053;&#32780;&#23548;&#33268;&#30340;&#24120;&#35265;&#23545;&#35805;&#27495;&#20041;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38646;&#26679;&#26412;&#26597;&#35810;&#37325;&#26500;&#65288;ZeQR&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26681;&#25454;&#20808;&#21069;&#30340;&#23545;&#35805;&#19978;&#19979;&#25991;&#37325;&#26500;&#26597;&#35810;&#65292;&#32780;&#26080;&#38656;&#23545;&#35805;&#25628;&#32034;&#25968;&#25454;&#30340;&#30417;&#30563;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21033;&#29992;&#20102;&#35774;&#35745;&#29992;&#20110;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#26126;&#30830;&#35299;&#20915;&#20004;&#20010;&#24120;&#35265;&#30340;&#27495;&#20041;&#65306;&#21327;&#35843;&#21644;&#30465;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the popularity of voice assistants continues to surge, conversational search has gained increased attention in Information Retrieval. However, data sparsity issues in conversational search significantly hinder the progress of supervised conversational search methods. Consequently, researchers are focusing more on zero-shot conversational search approaches. Nevertheless, existing zero-shot methods face three primary limitations: they are not universally applicable to all retrievers, their effectiveness lacks sufficient explainability, and they struggle to resolve common conversational ambiguities caused by omission. To address these limitations, we introduce a novel Zero-shot Query Reformulation (ZeQR) framework that reformulates queries based on previous dialogue contexts without requiring supervision from conversational search data. Specifically, our framework utilizes language models designed for machine reading comprehension tasks to explicitly resolve two common ambiguities: cor
&lt;/p&gt;</description></item><item><title>WinoQueer&#26159;&#19968;&#20010;&#31038;&#21306;&#21327;&#21516;&#22522;&#20934;&#65292;&#26088;&#22312;&#34913;&#37327;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#23384;&#22312;&#23545;LGBTQ+&#31038;&#21306;&#26377;&#23475;&#30340;&#20559;&#35265;&#12290;&#30740;&#31350;&#21457;&#29616;&#29616;&#25104;&#27169;&#22411;&#26222;&#36941;&#23384;&#22312;&#30456;&#24403;&#22823;&#30340;&#21453;&#21516;&#20559;&#35265;&#65292;&#36890;&#36807;&#22312;&#35813;&#31038;&#21306;&#25776;&#20889;&#25110;&#30001;&#35813;&#31038;&#21306;&#25104;&#21592;&#25776;&#20889;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#21487;&#20197;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#20943;&#36731;&#20559;&#35265;&#12290;</title><link>http://arxiv.org/abs/2306.15087</link><description>&lt;p&gt;
WinoQueer&#65306;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21453;LGBTQ+&#20559;&#35265;&#30340;&#31038;&#21306;&#21327;&#21516;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models. (arXiv:2306.15087v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15087
&lt;/p&gt;
&lt;p&gt;
WinoQueer&#26159;&#19968;&#20010;&#31038;&#21306;&#21327;&#21516;&#22522;&#20934;&#65292;&#26088;&#22312;&#34913;&#37327;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#23384;&#22312;&#23545;LGBTQ+&#31038;&#21306;&#26377;&#23475;&#30340;&#20559;&#35265;&#12290;&#30740;&#31350;&#21457;&#29616;&#29616;&#25104;&#27169;&#22411;&#26222;&#36941;&#23384;&#22312;&#30456;&#24403;&#22823;&#30340;&#21453;&#21516;&#20559;&#35265;&#65292;&#36890;&#36807;&#22312;&#35813;&#31038;&#21306;&#25776;&#20889;&#25110;&#30001;&#35813;&#31038;&#21306;&#25104;&#21592;&#25776;&#20889;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#21487;&#20197;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#20943;&#36731;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;WinoQueer&#65306;&#19968;&#20010;&#19987;&#38376;&#35774;&#35745;&#29992;&#26469;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#23384;&#22312;&#23545;LGBTQ+&#31038;&#21306;&#26377;&#23475;&#30340;&#20559;&#35265;&#30340;&#22522;&#20934;&#12290;&#35813;&#22522;&#20934;&#26159;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#20174;&#31038;&#21306;&#35843;&#26597;&#20013;&#29983;&#25104;&#30340;&#20559;&#35265;&#22522;&#20934;&#12290;&#25105;&#20204;&#23558;&#35813;&#22522;&#20934;&#24212;&#29992;&#20110;&#20960;&#20010;&#27969;&#34892;&#30340;LLMs&#65292;&#24182;&#21457;&#29616;&#29616;&#25104;&#27169;&#22411;&#26222;&#36941;&#23384;&#22312;&#30456;&#24403;&#22823;&#30340;&#21453;&#21516;&#20559;&#35265;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#22312;&#35813;&#31038;&#21306;&#25776;&#20889;&#25110;&#30001;&#35813;&#31038;&#21306;&#25104;&#21592;&#25776;&#20889;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#21487;&#20197;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#20943;&#36731;LLM&#23545;&#36793;&#32536;&#21270;&#31038;&#21306;&#30340;&#20559;&#35265;&#65292;&#24182;&#19988;&#31038;&#21306;&#25104;&#21592;&#25776;&#20889;&#30340;&#31038;&#20132;&#23186;&#20307;&#25991;&#26412;&#27604;&#38750;&#31038;&#21306;&#25104;&#21592;&#25776;&#20889;&#30340;&#26032;&#38395;&#25991;&#26412;&#26356;&#26377;&#25928;&#12290;&#25105;&#20204;&#30340;&#31038;&#21306;&#21327;&#21516;&#22522;&#20934;&#24320;&#21457;&#26041;&#27861;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20010;&#34013;&#22270;&#65292;&#20197;&#24320;&#21457;&#38754;&#21521;&#20854;&#20182;&#36793;&#32536;&#21270;&#31038;&#21306;&#30340;&#12289;&#20197;&#31038;&#21306;&#20026;&#20013;&#24515;&#30340;&#12289;&#22522;&#20110;&#20260;&#23475;&#30340;LLM&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community. The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias. Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members. Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities.
&lt;/p&gt;</description></item></channel></rss>