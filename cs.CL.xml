<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#33258;&#30417;&#30563;&#23398;&#20064;&#30446;&#26631;&#35757;&#32451;&#19968;&#20010;&#29992;&#20110;&#35268;&#21010;&#26410;&#26469;&#20889;&#20316;&#36807;&#31243;&#30340;&#27169;&#22359;&#65292;&#25193;&#23637;&#20102;&#25104;&#21151;&#30340;&#35821;&#35328;&#27169;&#22411;&#20844;&#24335;&#21040;&#26356;&#25277;&#35937;&#30340;&#35268;&#21010;&#20013;&#65292;&#25913;&#21892;&#20102;&#35821;&#35328;&#24314;&#27169;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#25991;&#26412;&#32467;&#26500;&#26041;&#38754;&#65292;&#21516;&#26102;&#26032;&#30340;&#35268;&#21010;&#27169;&#22359;&#21487;&#20197;&#22823;&#35268;&#27169;&#35757;&#32451;&#24182;&#36731;&#26494;&#19982;&#31038;&#21306;&#20849;&#20139;&#12290;</title><link>https://arxiv.org/abs/2404.00614</link><description>&lt;p&gt;
&#20174;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#23398;&#20064;&#35821;&#35328;&#24314;&#27169;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Learning to Plan for Language Modeling from Unlabeled Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00614
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#30417;&#30563;&#23398;&#20064;&#30446;&#26631;&#35757;&#32451;&#19968;&#20010;&#29992;&#20110;&#35268;&#21010;&#26410;&#26469;&#20889;&#20316;&#36807;&#31243;&#30340;&#27169;&#22359;&#65292;&#25193;&#23637;&#20102;&#25104;&#21151;&#30340;&#35821;&#35328;&#27169;&#22411;&#20844;&#24335;&#21040;&#26356;&#25277;&#35937;&#30340;&#35268;&#21010;&#20013;&#65292;&#25913;&#21892;&#20102;&#35821;&#35328;&#24314;&#27169;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#25991;&#26412;&#32467;&#26500;&#26041;&#38754;&#65292;&#21516;&#26102;&#26032;&#30340;&#35268;&#21010;&#27169;&#22359;&#21487;&#20197;&#22823;&#35268;&#27169;&#35757;&#32451;&#24182;&#36731;&#26494;&#19982;&#31038;&#21306;&#20849;&#20139;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35757;&#32451;&#26469;&#39044;&#27979;&#26410;&#26631;&#35760;&#35821;&#26009;&#24211;&#20013;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23398;&#20250;&#25191;&#34892;&#35768;&#22810;&#20219;&#21153;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#26631;&#35760;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30446;&#26631;&#21487;&#20197;&#35828;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#38656;&#35201;&#35268;&#21010;&#30340;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#65292;&#27604;&#22914;&#20889;&#20316;&#19968;&#31687;&#36830;&#36143;&#30340;&#25991;&#31456;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#33258;&#30417;&#30563;&#23398;&#20064;&#30446;&#26631;&#35757;&#32451;&#19968;&#20010;&#29992;&#20110;&#35268;&#21010;&#26410;&#26469;&#20889;&#20316;&#36807;&#31243;&#30340;&#27169;&#22359;&#12290;&#36890;&#36807;&#26681;&#25454;&#29983;&#25104;&#30340;&#28508;&#22312;&#35745;&#21010;&#36827;&#34892;&#26465;&#20214;&#21270;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#23558;&#25104;&#21151;&#30340;&#35821;&#35328;&#27169;&#22411;&#20844;&#24335;&#25193;&#23637;&#21040;&#26356;&#25277;&#35937;&#30340;&#35268;&#21010;&#20013;&#12290;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#25913;&#21892;&#20102;&#35821;&#35328;&#24314;&#27169;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#25991;&#26412;&#32467;&#26500;&#26041;&#38754;&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#30340;&#26159;&#26080;&#30417;&#30563;&#19988;&#22806;&#37096;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#35268;&#21010;&#27169;&#22359;&#65292;&#22240;&#27492;&#26032;&#30340;&#35268;&#21010;&#27169;&#22359;&#21487;&#20197;&#22823;&#35268;&#27169;&#35757;&#32451;&#65292;&#24182;&#19988;&#33021;&#22815;&#36731;&#26494;&#22320;&#19982;&#31038;&#21306;&#20849;&#20139;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00614v1 Announce Type: cross  Abstract: By training to predict the next token in an unlabeled corpus, large language models learn to perform many tasks without any labeled data. However, their next-token-prediction objective arguably limits their performance in scenarios that require planning, such as writing a coherent article. In this paper, we train a module for planning the future writing process via a self-supervised learning objective. By conditioning on generated latent plans, our model extends the successful language model formula to more abstract planning in an unsupervised way. Empirically, we demonstrate that our method improves language modeling performance in general, particularly with respect to the text structure. Because our framework uses a planner module that is unsupervised and external to the language model, new planner modules can be trained at large scale and easily be shared with the community.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#34701;&#21512;&#26694;&#26550;&#23558;Transformer&#27169;&#22411;&#37327;&#21270;&#20026;&#20165;&#20004;&#20301;&#65292;&#20165;&#26377;&#36731;&#24494;&#31934;&#24230;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2403.06082</link><description>&lt;p&gt;
FrameQuant: Transformer&#30340;&#28789;&#27963;&#20302;&#27604;&#29305;&#37327;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
FrameQuant: Flexible Low-Bit Quantization for Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06082
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#34701;&#21512;&#26694;&#26550;&#23558;Transformer&#27169;&#22411;&#37327;&#21270;&#20026;&#20165;&#20004;&#20301;&#65292;&#20165;&#26377;&#36731;&#24494;&#31934;&#24230;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26159;&#35768;&#22810;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#24378;&#22823;&#22522;&#30784;&#27169;&#22411;&#30340;&#25903;&#26609;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;/&#23384;&#20648;&#31354;&#38388;&#21344;&#29992;&#36739;&#22823;&#65292;&#22240;&#27492;&#20026;&#36825;&#20123;&#27169;&#22411;&#25552;&#20379;&#26381;&#21153;&#24448;&#24448;&#38656;&#35201;&#26114;&#36149;&#30340;&#39640;&#31471;&#30828;&#20214;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#19968;&#22256;&#38590;&#65292;&#21518;&#35757;&#32451;&#37327;&#21270;&#35797;&#22270;&#20462;&#25913;&#39044;&#35757;&#32451;&#27169;&#22411;&#24182;&#23558;&#20854;&#37327;&#21270;&#20026;&#20843;&#20301;&#25110;&#26356;&#20302;&#30340;&#20301;&#25968;&#65292;&#26174;&#30528;&#25552;&#39640;&#35745;&#31639;/&#20869;&#23384;/&#24310;&#36831;&#25928;&#29575;&#12290;&#26082;&#21487;&#20197;&#25104;&#21151;&#23558;&#36825;&#20123;&#27169;&#22411;&#37327;&#21270;&#20026;&#22235;&#20301;&#65292;&#20294;&#24615;&#33021;&#26377;&#25152;&#25439;&#22833;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#26696;&#65292;&#23558;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#37327;&#21270;&#20026;&#20165;&#20004;&#20301;&#65288;&#21152;&#19968;&#20123;&#39069;&#22806;&#24320;&#38144;&#65289;&#65292;&#20165;&#20250;&#26377;&#36731;&#24494;&#30340;&#31934;&#24230;&#19979;&#38477;&#12290;&#25105;&#20204;&#30340;&#21046;&#23450;&#20851;&#38190;&#22312;&#20110;&#20174;&#35856;&#27874;&#20998;&#26512;&#20013;&#20511;&#37492;&#20102;&#19968;&#31181;&#31216;&#20026;&#34701;&#21512;&#26694;&#26550;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#65292;&#37327;&#21270;&#19981;&#24212;&#35813;&#22312;&#21407;&#22987;&#26435;&#37325;&#31354;&#38388;&#20013;&#36827;&#34892;&#65292;&#32780;&#26159;&#24212;&#35813;&#22312;&#34701;&#21512;&#26694;&#26550;&#34920;&#31034;&#20013;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06082v1 Announce Type: cross  Abstract: Transformers are the backbone of powerful foundation models for many Vision and Natural Language Processing tasks. But their compute and memory/storage footprint is large, and so, serving such models is expensive often requiring high-end hardware. To mitigate this difficulty, Post-Training Quantization seeks to modify a pre-trained model and quantize it to eight bits or lower, significantly boosting compute/memory/latency efficiency. Such models have been successfully quantized to four bits with some performance loss. In this work, we outline a simple scheme to quantize Transformer-based models to just two bits (plus some overhead) with only a small drop in accuracy. Key to our formulation is a concept borrowed from Harmonic analysis called Fusion Frames. Our main finding is that the quantization must take place not in the original weight space, but instead in the Fusion Frame representations. If quantization is interpreted as the addi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#26434;&#24230;&#30340;&#25552;&#31034;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#31034;&#20363;&#19982;&#27979;&#35797;&#21477;&#23376;&#30340;&#21477;&#27861;-&#35821;&#20041;&#22797;&#26434;&#24230;&#23545;&#40784;&#65292;&#22312;&#23569;&#26679;&#26412;NER&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2403.03861</link><description>&lt;p&gt;
&#20026;&#23569;&#26679;&#26412;&#31034;&#20363;&#36873;&#25321;&#35774;&#35745;&#20449;&#24687;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Designing Informative Metrics for Few-Shot Example Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03861
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#26434;&#24230;&#30340;&#25552;&#31034;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#31034;&#20363;&#19982;&#27979;&#35797;&#21477;&#23376;&#30340;&#21477;&#27861;-&#35821;&#20041;&#22797;&#26434;&#24230;&#23545;&#40784;&#65292;&#22312;&#23569;&#26679;&#26412;NER&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#22312;&#25552;&#20379;&#36866;&#24403;&#26684;&#24335;&#30340;&#31034;&#20363;&#26102;&#23637;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#8220;&#26368;&#20339;&#8221;&#31034;&#20363;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#26434;&#24230;&#30340;&#25552;&#31034;&#36873;&#25321;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24207;&#21015;&#26631;&#27880;&#20219;&#21153;&#12290;&#35813;&#26041;&#27861;&#36991;&#20813;&#20102;&#35757;&#32451;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;&#36873;&#25321;&#31034;&#20363;&#30340;&#27169;&#22411;&#65292;&#32780;&#26159;&#20351;&#29992;&#29305;&#23450;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#23545;&#40784;&#27979;&#35797;&#21477;&#23376;&#21644;&#31034;&#20363;&#30340;&#21477;&#27861;-&#35821;&#20041;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;&#21477;&#23376;&#21644;&#21333;&#35789;&#32423;&#21035;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#23558;&#31034;&#20363;&#30340;&#22797;&#26434;&#24230;&#19982;&#32771;&#34385;&#20013;&#30340;&#65288;&#27979;&#35797;&#65289;&#21477;&#23376;&#36827;&#34892;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20174;PLMs&#20013;&#25552;&#21462;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65306;&#22312;&#23569;&#26679;&#26412;NER&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#22312;CoNLL2003&#25968;&#25454;&#38598;&#19978;&#23545;GPT-4&#30340;F1&#20998;&#25968;&#23454;&#29616;&#20102;5%&#30340;&#32477;&#23545;&#25913;&#21892;&#12290;&#25105;&#20204;&#36824;&#22312;&#20687;GPT-j-6B&#36825;&#26679;&#30340;&#36739;&#23567;&#27169;&#22411;&#20013;&#30475;&#21040;&#20102;&#39640;&#36798;28.85&#20010;&#28857;&#65288;F1/Acc.&#65289;&#30340;&#26174;&#33879;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03861v1 Announce Type: new  Abstract: Pretrained language models (PLMs) have shown remarkable few-shot learning capabilities when provided with properly formatted examples. However, selecting the "best" examples remains an open challenge. We propose a complexity-based prompt selection approach for sequence tagging tasks. This approach avoids the training of a dedicated model for selection of examples, and instead uses certain metrics to align the syntactico-semantic complexity of test sentences and examples. We use both sentence- and word-level metrics to match the complexity of examples to the (test) sentence being considered. Our results demonstrate that our approach extracts greater performance from PLMs: it achieves state-of-the-art performance on few-shot NER, achieving a 5% absolute improvement in F1 score on the CoNLL2003 dataset for GPT-4. We also see large gains of upto 28.85 points (F1/Acc.) in smaller models like GPT-j-6B.
&lt;/p&gt;</description></item><item><title>&#20154;&#24037;&#26234;&#33021;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25112;&#20105;&#28216;&#25103;&#20013;&#19982;&#20154;&#31867;&#21709;&#24212;&#23384;&#22312;&#19968;&#33268;&#24615;&#65292;&#20294;&#20063;&#23384;&#22312;&#26174;&#33879;&#30340;&#24046;&#24322;&#65292;&#36825;&#34920;&#26126;&#22312;&#25919;&#31574;&#21046;&#23450;&#32773;&#20132;&#20986;&#33258;&#20027;&#26435;&#25110;&#21548;&#20174;&#22522;&#20110;AI&#30340;&#25112;&#30053;&#24314;&#35758;&#20043;&#21069;&#24212;&#35880;&#24910;&#23545;&#24453;&#12290;</title><link>https://arxiv.org/abs/2403.03407</link><description>&lt;p&gt;
&#20154;&#31867;&#23545;&#25239;&#26426;&#22120;&#65306;&#35821;&#35328;&#27169;&#22411;&#19982;&#25112;&#20105;&#28216;&#25103;
&lt;/p&gt;
&lt;p&gt;
Human vs. Machine: Language Models and Wargames
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03407
&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25112;&#20105;&#28216;&#25103;&#20013;&#19982;&#20154;&#31867;&#21709;&#24212;&#23384;&#22312;&#19968;&#33268;&#24615;&#65292;&#20294;&#20063;&#23384;&#22312;&#26174;&#33879;&#30340;&#24046;&#24322;&#65292;&#36825;&#34920;&#26126;&#22312;&#25919;&#31574;&#21046;&#23450;&#32773;&#20132;&#20986;&#33258;&#20027;&#26435;&#25110;&#21548;&#20174;&#22522;&#20110;AI&#30340;&#25112;&#30053;&#24314;&#35758;&#20043;&#21069;&#24212;&#35880;&#24910;&#23545;&#24453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25112;&#20105;&#28216;&#25103;&#22312;&#20891;&#20107;&#25112;&#30053;&#30340;&#21457;&#23637;&#21644;&#22269;&#23478;&#23545;&#23041;&#32961;&#25110;&#25915;&#20987;&#30340;&#21709;&#24212;&#20013;&#26377;&#30528;&#24736;&#20037;&#30340;&#21382;&#21490;&#12290;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#30340;&#20986;&#29616;&#25215;&#35834;&#20102;&#26356;&#22909;&#30340;&#20915;&#31574;&#21046;&#23450;&#21644;&#22686;&#24378;&#30340;&#20891;&#20107;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;AI&#31995;&#32479;&#65292;&#23588;&#20854;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#19982;&#20154;&#31867;&#30340;&#34892;&#20026;&#26377;&#20309;&#19981;&#21516;&#20173;&#23384;&#22312;&#20105;&#35758;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#25112;&#20105;&#28216;&#25103;&#23454;&#39564;&#65292;&#20849;&#26377;107&#20301;&#22269;&#23478;&#23433;&#20840;&#19987;&#23478;&#20154;&#31867;&#21442;&#19982;&#32773;&#21442;&#19982;&#65292;&#26088;&#22312;&#30740;&#31350;&#22312;&#19968;&#20010;&#34394;&#26500;&#30340;&#32654;&#20013;&#24773;&#26223;&#20013;&#30340;&#21361;&#26426;&#21319;&#32423;&#65292;&#24182;&#27604;&#36739;&#20154;&#31867;&#21442;&#19982;&#32773;&#19982;LLM&#27169;&#25311;&#21709;&#24212;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#21457;&#29616;LLM&#21644;&#20154;&#31867;&#21709;&#24212;&#23384;&#22312;&#26174;&#33879;&#19968;&#33268;&#24615;&#65292;&#20294;&#22312;&#25112;&#20105;&#28216;&#25103;&#20013;&#27169;&#25311;&#21644;&#20154;&#31867;&#21442;&#19982;&#32773;&#20043;&#38388;&#20063;&#23384;&#22312;&#26174;&#33879;&#30340;&#23450;&#37327;&#21644;&#23450;&#24615;&#24046;&#24322;&#65292;&#36825;&#20419;&#20351;&#20915;&#31574;&#32773;&#22312;&#20132;&#20986;&#33258;&#20027;&#26435;&#25110;&#36981;&#24490;&#22522;&#20110;AI&#30340;&#25112;&#30053;&#24314;&#35758;&#20043;&#21069;&#35880;&#24910;&#23545;&#24453;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03407v1 Announce Type: cross  Abstract: Wargames have a long history in the development of military strategy and the response of nations to threats or attacks. The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness. However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses. We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#19981;&#20462;&#25913;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#65292;&#36890;&#36807;&#36827;&#21270;&#20195;&#29702;&#30340;&#21151;&#33021;&#26469;&#35299;&#20915;&#19979;&#28216;&#20219;&#21153;</title><link>https://arxiv.org/abs/2402.11359</link><description>&lt;p&gt;
&#22312;&#19981;&#20462;&#25913;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Training Language Model Agents without Modifying Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11359
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#19981;&#20462;&#25913;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#65292;&#36890;&#36807;&#36827;&#21270;&#20195;&#29702;&#30340;&#21151;&#33021;&#26469;&#35299;&#20915;&#19979;&#28216;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#26368;&#36817;&#24050;&#32463;&#23558;&#24378;&#22823;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#37325;&#26032;&#23450;&#20041;&#20026;&#20195;&#29702;&#65292;&#20351;&#23427;&#20204;&#33021;&#22815;&#36890;&#36807;&#20351;&#29992;&#19987;&#38376;&#30340;&#21151;&#33021;&#33258;&#21160;&#21270;&#22320;&#23436;&#25104;&#22797;&#26434;&#20219;&#21153;&#12290;&#20026;&#20102;&#20419;&#36827;LLM&#20195;&#29702;&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#20462;&#25913;LLM&#26435;&#37325;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;LLM&#20195;&#29702;&#30340;&#26032;&#33539;&#24335;&#65292;&#24403;LLM&#38590;&#20197;&#25110;&#26080;&#27861;&#36827;&#34892;&#20462;&#25913;&#26102;&#23588;&#20854;&#26377;&#29992;&#12290;&#21463;&#21040;&#20154;&#31867;&#19981;&#26029;&#38203;&#36896;&#24037;&#20855;&#20197;&#36866;&#24212;&#29616;&#23454;&#20219;&#21153;&#30340;&#21551;&#21457;&#65292;&#32780;&#19981;&#26159;&#25913;&#21464;&#25105;&#20204;&#30340;&#29983;&#29289;&#32467;&#26500;&#20197;&#36866;&#24212;&#19968;&#32452;&#38745;&#24577;&#24037;&#20855;&#65292;&#25105;&#20204;&#25552;&#20986;&#36880;&#27493;&#38203;&#36896;&#20195;&#29702;&#30340;&#21151;&#33021;&#65292;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#19979;&#28216;&#20219;&#21153;&#65292;&#32780;&#19981;&#26159;&#20462;&#25913;LLM&#26435;&#37325;&#12290;&#36890;&#36807;&#23558;&#36825;&#20123;&#21151;&#33021;&#35270;&#20026;&#21487;&#23398;&#20064;&#30340;&#8220;&#20195;&#29702;&#21442;&#25968;&#8221;&#24182;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#35757;&#32451;&#30340;&#22522;&#26412;&#24605;&#24819;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;AgentOptimizer&#65292;&#21033;&#29992;LLM&#26356;&#26032;&#20195;&#29702;&#30340;&#21151;&#33021;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#20195;&#29702;&#35757;&#32451;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11359v1 Announce Type: new  Abstract: Researchers and practitioners have recently reframed powerful Large Language Models (LLMs) as agents, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to real-world tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent's functions to better solve the downstream tasks instead of modifying the LLM weights. By treating the functions as learnable `agent parameters' and leveraging the fundamental idea of model training in artificial intelligence, we develop AgentOptimizer that employs the LLM to update agents' functions and devise an agent training algorithm with tw
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#25928;&#26524;&#65292;&#24341;&#20837;&#31895;&#31890;&#24230;&#21644;&#32454;&#31890;&#24230;&#35780;&#20272;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#21644;&#32454;&#33268;&#30340;&#35780;&#20272;&#35282;&#24230;&#65292;&#24182;&#24320;&#21457;&#20102;&#19987;&#38376;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#20316;&#20026;&#22522;&#20934;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#24314;&#31435;&#20102;&#22522;&#30784;&#36164;&#28304;&#12290;</title><link>http://arxiv.org/abs/2401.09002</link><description>&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#25928;&#26524;&#30340;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models. (arXiv:2401.09002v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09002
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#25928;&#26524;&#65292;&#24341;&#20837;&#31895;&#31890;&#24230;&#21644;&#32454;&#31890;&#24230;&#35780;&#20272;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#21644;&#32454;&#33268;&#30340;&#35780;&#20272;&#35282;&#24230;&#65292;&#24182;&#24320;&#21457;&#20102;&#19987;&#38376;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#20316;&#20026;&#22522;&#20934;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#24314;&#31435;&#20102;&#22522;&#30784;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21019;&#24615;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19978;&#36234;&#29425;&#25915;&#20987;&#25928;&#26524;&#30340;&#26032;&#26041;&#27861;&#65292;&#19982;&#20256;&#32479;&#30340;&#20581;&#22766;&#24615;&#35780;&#20272;&#26041;&#27861;&#19981;&#21516;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#20004;&#20010;&#19981;&#21516;&#30340;&#35780;&#20272;&#26694;&#26550;&#65306;&#31895;&#31890;&#24230;&#35780;&#20272;&#21644;&#32454;&#31890;&#24230;&#35780;&#20272;&#12290;&#27599;&#20010;&#26694;&#26550;&#37117;&#20351;&#29992;&#20174;0&#21040;1&#30340;&#35780;&#20998;&#33539;&#22260;&#65292;&#25552;&#20379;&#20102;&#29420;&#29305;&#30340;&#35270;&#35282;&#65292;&#33021;&#22815;&#26356;&#20840;&#38754;&#21644;&#32454;&#33268;&#22320;&#35780;&#20272;&#25915;&#20987;&#25928;&#26524;&#65292;&#24182;&#24110;&#21161;&#25915;&#20987;&#32773;&#26356;&#22909;&#22320;&#20248;&#21270;&#25915;&#20987;&#25552;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;&#36234;&#29425;&#20219;&#21153;&#30340;&#20840;&#38754;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#19981;&#20165;&#26159;&#25105;&#20204;&#24403;&#21069;&#30740;&#31350;&#30340;&#20851;&#38190;&#22522;&#20934;&#65292;&#20063;&#20026;&#26410;&#26469;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20010;&#22522;&#30784;&#36164;&#28304;&#65292;&#21487;&#20197;&#22312;&#36825;&#20010;&#19981;&#26029;&#21457;&#23637;&#30340;&#39046;&#22495;&#20013;&#36827;&#34892;&#19968;&#33268;&#21644;&#27604;&#36739;&#30340;&#20998;&#26512;&#12290;&#36890;&#36807;&#19982;&#20256;&#32479;&#35780;&#20272;&#26041;&#27861;&#30340;&#31934;&#24515;&#27604;&#36739;&#65292;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#35780;&#20272;&#26041;&#27861;&#19982;&#20043;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
In our research, we pioneer a novel approach to evaluate the effectiveness of jailbreak attacks on Large Language Models (LLMs), such as GPT-4 and LLaMa2, diverging from traditional robustness-focused binary evaluations. Our study introduces two distinct evaluation frameworks: a coarse-grained evaluation and a fine-grained evaluation. Each framework, using a scoring range from 0 to 1, offers a unique perspective, enabling a more comprehensive and nuanced evaluation of attack effectiveness and empowering attackers to refine their attack prompts with greater understanding. Furthermore, we have developed a comprehensive ground truth dataset specifically tailored for jailbreak tasks. This dataset not only serves as a crucial benchmark for our current study but also establishes a foundational resource for future research, enabling consistent and comparative analyses in this evolving field. Upon meticulous comparison with traditional evaluation methods, we discovered that our evaluation alig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26377;&#38480;&#20869;&#23384;&#26465;&#20214;&#19979;&#39640;&#25928;&#36816;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#27169;&#22411;&#21442;&#25968;&#23384;&#20648;&#22312;&#38378;&#23384;&#20013;&#24182;&#25353;&#38656;&#20256;&#36755;&#21040;DRAM&#30340;&#26041;&#24335;&#26469;&#35299;&#20915;&#20869;&#23384;&#38480;&#21046;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26500;&#24314;&#25512;&#29702;&#25104;&#26412;&#27169;&#22411;&#24182;&#20248;&#21270;&#25968;&#25454;&#20256;&#36755;&#21644;&#35835;&#21462;&#26041;&#24335;&#65292;&#24341;&#20837;&#20102;&#31383;&#21475;&#21270;&#21644;&#34892;&#21015;&#32465;&#23450;&#20004;&#31181;&#20027;&#35201;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2312.11514</link><description>&lt;p&gt;
&#38378;&#23384;LLM&#65306;&#22312;&#26377;&#38480;&#20869;&#23384;&#19979;&#39640;&#25928;&#36816;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LLM in a flash: Efficient Large Language Model Inference with Limited Memory. (arXiv:2312.11514v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.11514
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26377;&#38480;&#20869;&#23384;&#26465;&#20214;&#19979;&#39640;&#25928;&#36816;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#27169;&#22411;&#21442;&#25968;&#23384;&#20648;&#22312;&#38378;&#23384;&#20013;&#24182;&#25353;&#38656;&#20256;&#36755;&#21040;DRAM&#30340;&#26041;&#24335;&#26469;&#35299;&#20915;&#20869;&#23384;&#38480;&#21046;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26500;&#24314;&#25512;&#29702;&#25104;&#26412;&#27169;&#22411;&#24182;&#20248;&#21270;&#25968;&#25454;&#20256;&#36755;&#21644;&#35835;&#21462;&#26041;&#24335;&#65292;&#24341;&#20837;&#20102;&#31383;&#21475;&#21270;&#21644;&#34892;&#21015;&#32465;&#23450;&#20004;&#31181;&#20027;&#35201;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#29616;&#20195;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#24222;&#22823;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;&#38656;&#27714;&#24102;&#26469;&#20102;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20855;&#26377;&#26377;&#38480;DRAM&#23481;&#37327;&#30340;&#35774;&#22791;&#32780;&#35328;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#27169;&#22411;&#21442;&#25968;&#23384;&#20648;&#22312;&#38378;&#23384;&#20013;&#65292;&#24182;&#25353;&#38656;&#23558;&#20854;&#20256;&#36755;&#21040;DRAM&#30340;&#26041;&#24335;&#65292;&#35299;&#20915;&#20102;&#36229;&#36807;&#21487;&#29992;DRAM&#23481;&#37327;&#30340;LLM&#39640;&#25928;&#36816;&#34892;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#26500;&#24314;&#19968;&#20010;&#32771;&#34385;&#38378;&#23384;&#29305;&#24615;&#30340;&#25512;&#29702;&#25104;&#26412;&#27169;&#22411;&#65292;&#24341;&#23548;&#25105;&#20204;&#22312;&#20004;&#20010;&#20851;&#38190;&#39046;&#22495;&#36827;&#34892;&#20248;&#21270;&#65306;&#20943;&#23569;&#20174;&#38378;&#23384;&#20256;&#36755;&#30340;&#25968;&#25454;&#37327;&#65292;&#24182;&#20197;&#36739;&#22823;&#12289;&#26356;&#36830;&#32493;&#30340;&#22359;&#35835;&#21462;&#25968;&#25454;&#12290;&#22312;&#36825;&#20010;&#21463;&#30828;&#20214;&#21551;&#21457;&#30340;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#20027;&#35201;&#25216;&#26415;&#12290;&#39318;&#20808;&#65292;&#8220;&#31383;&#21475;&#21270;&#8221;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#20043;&#21069;&#28608;&#27963;&#30340;&#31070;&#32463;&#20803;&#26469;&#31574;&#30053;&#24615;&#22320;&#20943;&#23569;&#25968;&#25454;&#20256;&#36755;&#65292;&#20854;&#27425;&#65292;&#8220;&#34892;&#21015;&#32465;&#23450;&#8221;&#36866;&#24212;&#20102;&#38378;&#23384;&#30340;&#39034;&#24207;&#25968;&#25454;&#35775;&#38382;&#29305;&#28857;&#65292;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are central to modern natural language processing, delivering exceptional performance in various tasks. However, their substantial computational and memory requirements present challenges, especially for devices with limited DRAM capacity. This paper tackles the challenge of efficiently running LLMs that exceed the available DRAM capacity by storing the model parameters in flash memory, but bringing them on demand to DRAM. Our method involves constructing an inference cost model that takes into account the characteristics of flash memory, guiding us to optimize in two critical areas: reducing the volume of data transferred from flash and reading data in larger, more contiguous chunks. Within this hardware-informed framework, we introduce two principal techniques. First, "windowing" strategically reduces data transfer by reusing previously activated neurons, and second, "row-column bundling", tailored to the sequential data access strengths of flash memory, 
&lt;/p&gt;</description></item><item><title>&#36817;&#26399;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20135;&#29983;&#20102;&#19968;&#31181;&#20559;&#35265;&#65292;&#20542;&#21521;&#20110;&#23558;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#25490;&#21517;&#36739;&#39640;&#12290;&#36825;&#31181;&#8220;&#26469;&#28304;&#20559;&#35265;&#8221;&#21487;&#33021;&#23545;&#20449;&#24687;&#35775;&#38382;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.20501</link><description>&lt;p&gt;
LLM&#21487;&#33021;&#20027;&#23548;&#20449;&#24687;&#35775;&#38382;&#65306;&#31070;&#32463;&#26816;&#32034;&#22120;&#23545;LLM&#29983;&#25104;&#30340;&#25991;&#26412;&#23384;&#22312;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts. (arXiv:2310.20501v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20501
&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20135;&#29983;&#20102;&#19968;&#31181;&#20559;&#35265;&#65292;&#20542;&#21521;&#20110;&#23558;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#25490;&#21517;&#36739;&#39640;&#12290;&#36825;&#31181;&#8220;&#26469;&#28304;&#20559;&#35265;&#8221;&#21487;&#33021;&#23545;&#20449;&#24687;&#35775;&#38382;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#22312;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#22312;&#32593;&#32476;&#25628;&#32034;&#26041;&#38754;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#33539;&#24335;&#12290;&#30001;&#20110;&#20854;&#22312;&#29983;&#25104;&#31867;&#20154;&#25991;&#26412;&#26041;&#38754;&#30340;&#21331;&#36234;&#33021;&#21147;&#65292;LLMs&#22312;&#20114;&#32852;&#32593;&#19978;&#21019;&#36896;&#20102;&#22823;&#37327;&#30340;&#25991;&#26412;&#12290;&#22240;&#27492;&#65292;LLMs&#26102;&#20195;&#30340;IR&#31995;&#32479;&#38754;&#20020;&#19968;&#20010;&#26032;&#30340;&#25361;&#25112;&#65306;&#32034;&#24341;&#30340;&#25991;&#26723;&#19981;&#20165;&#26159;&#30001;&#20154;&#31867;&#25776;&#20889;&#30340;&#65292;&#32780;&#19988;&#36824;&#21253;&#25324;&#30001;LLMs&#33258;&#21160;&#29983;&#25104;&#30340;&#25991;&#26723;&#12290;&#36825;&#20123;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#22914;&#20309;&#24433;&#21709;IR&#31995;&#32479;&#26159;&#19968;&#20010;&#32039;&#36843;&#19988;&#23578;&#26410;&#25506;&#32034;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#28041;&#21450;&#20154;&#31867;&#32534;&#20889;&#21644;LLM&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#19981;&#21516;IR&#27169;&#22411;&#30340;&#22330;&#26223;&#20013;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#31070;&#32463;&#26816;&#32034;&#27169;&#22411;&#20542;&#21521;&#20110;&#23558;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#25490;&#21517;&#36739;&#39640;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#31070;&#32463;&#26816;&#32034;&#27169;&#22411;&#23545;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#20559;&#35265;&#31216;&#20026;&#8220;&#26469;&#28304;&#20559;&#35265;&#8221;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#20559;&#35265;&#19981;&#20165;&#38480;&#20110;f&#26041;&#30456;&#24403;&#30340;&#24773;&#20917;&#65292;&#32780;&#19988;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#20063;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search. With their remarkable capabilities in generating human-like texts, LLMs have created enormous texts on the Internet. As a result, IR systems in the LLMs era are facing a new challenge: the indexed documents now are not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of different IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that neural retrieval models tend to rank LLM-generated documents higher. We refer to this category of biases in neural retrieval models towards the LLM-generated text as the \textbf{source bias}. Moreover, we discover that this bias is not confined to the f
&lt;/p&gt;</description></item><item><title>CompA&#25552;&#20986;&#20102;&#30001;&#20004;&#20010;&#19987;&#23478;&#27880;&#37322;&#30340;&#38899;&#39057;-&#35821;&#35328;&#27169;&#22411;&#32452;&#21512;&#25512;&#29702;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;ALMs&#22312;&#29702;&#35299;&#38899;&#39057;&#20013;&#22768;&#38899;&#20107;&#20214;&#30340;&#39034;&#24207;&#21644;&#23646;&#24615;&#32465;&#23450;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.08753</link><description>&lt;p&gt;
CompA: &#35299;&#20915;&#38899;&#39057;-&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#32452;&#21512;&#25512;&#29702;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models. (arXiv:2310.08753v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08753
&lt;/p&gt;
&lt;p&gt;
CompA&#25552;&#20986;&#20102;&#30001;&#20004;&#20010;&#19987;&#23478;&#27880;&#37322;&#30340;&#38899;&#39057;-&#35821;&#35328;&#27169;&#22411;&#32452;&#21512;&#25512;&#29702;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;ALMs&#22312;&#29702;&#35299;&#38899;&#39057;&#20013;&#22768;&#38899;&#20107;&#20214;&#30340;&#39034;&#24207;&#21644;&#23646;&#24615;&#32465;&#23450;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#39057;&#30340;&#22522;&#26412;&#29305;&#24615;&#26159;&#20854;&#32452;&#21512;&#24615;&#12290;&#20351;&#29992;&#23545;&#27604;&#26041;&#27861;&#65288;&#20363;&#22914;CLAP&#65289;&#35757;&#32451;&#30340;&#38899;&#39057;-&#35821;&#35328;&#27169;&#22411;&#65288;ALMs&#65289;&#33021;&#22815;&#23398;&#20064;&#38899;&#39057;&#21644;&#35821;&#35328;&#27169;&#24577;&#20043;&#38388;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#20174;&#32780;&#22312;&#35768;&#22810;&#19979;&#28216;&#24212;&#29992;&#20013;&#25552;&#39640;&#24615;&#33021;&#65292;&#21253;&#25324;&#38646;&#26679;&#26412;&#38899;&#39057;&#20998;&#31867;&#12289;&#38899;&#39057;&#26816;&#32034;&#31561;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#26377;&#25928;&#25191;&#34892;&#32452;&#21512;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#36824;&#24456;&#23569;&#34987;&#25506;&#32034;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;CompA&#65292;&#36825;&#26159;&#19968;&#20010;&#30001;&#20004;&#20010;&#19987;&#23478;&#27880;&#37322;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#26159;&#30495;&#23454;&#19990;&#30028;&#30340;&#38899;&#39057;&#26679;&#26412;&#65292;&#29992;&#20110;&#35780;&#20272;ALMs&#30340;&#32452;&#21512;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;CompA-order&#35780;&#20272;ALMs&#22312;&#29702;&#35299;&#38899;&#39057;&#20013;&#22768;&#38899;&#20107;&#20214;&#30340;&#39034;&#24207;&#25110;&#21457;&#29983;&#26102;&#30340;&#34920;&#29616;&#22914;&#20309;&#65292;&#32780;CompA-attribute&#35780;&#20272;&#22768;&#38899;&#20107;&#20214;&#30340;&#23646;&#24615;&#32465;&#23450;&#12290;&#27599;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#30340;&#23454;&#20363;&#21253;&#21547;&#20004;&#20010;&#38899;&#39057;-&#26631;&#39064;&#23545;&#65292;&#20854;&#20013;&#20004;&#20010;&#38899;&#39057;&#20855;&#26377;&#30456;&#21516;&#30340;&#22768;&#38899;&#20107;&#20214;&#65292;&#20294;&#32452;&#21512;&#26041;&#24335;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental characteristic of audio is its compositional nature. Audio-language models (ALMs) trained using a contrastive approach (e.g., CLAP) that learns a shared representation between audio and language modalities have improved performance in many downstream applications, including zero-shot audio classification, audio retrieval, etc. However, the ability of these models to effectively perform compositional reasoning remains largely unexplored and necessitates additional research. In this paper, we propose CompA, a collection of two expert-annotated benchmarks with a majority of real-world audio samples, to evaluate compositional reasoning in ALMs. Our proposed CompA-order evaluates how well an ALM understands the order or occurrence of acoustic events in audio, and CompA-attribute evaluates attribute binding of acoustic events. An instance from either benchmark consists of two audio-caption pairs, where both audios have the same acoustic events but with different compositions. A
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20174;&#20116;&#20010;&#33521;&#35821;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#36816;&#34892;&#20013;&#25552;&#21462;&#23398;&#20064;&#26354;&#32447;&#65292;&#25581;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#39044;&#35757;&#32451;&#26399;&#38388;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#35821;&#35328;&#27169;&#22411;&#22312;&#23398;&#20064;&#29983;&#25104;&#26356;&#38271;&#12289;&#26356;&#36830;&#36143;&#30340;&#25991;&#26412;&#20043;&#21069;&#65292;&#20250;&#29983;&#25104;&#30701;&#32780;&#37325;&#22797;&#30340;&#30701;&#35821;&#12290;&#21516;&#26102;&#65292;&#39057;&#32321;&#20986;&#29616;&#30340;&#26631;&#35760;&#22312;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#26356;&#26089;&#23398;&#20064;&#65292;&#20855;&#26377;&#26356;&#23567;&#30340;&#21464;&#24322;&#24615;&#65292;&#24182;&#19988;&#24456;&#23569;&#34987;&#36951;&#24536;&#12290;&#36739;&#30701;&#12289;&#26356;&#39057;&#32321;&#30340;&#19978;&#19979;&#25991;&#19982;&#31283;&#23450;&#21644;&#24555;&#36895;&#33719;&#24471;&#30340;&#39044;&#27979;&#26377;&#20851;&#12290;&#35789;&#31867;&#30340;&#24433;&#21709;&#36739;&#23567;&#65292;&#20294;&#21517;&#35789;&#20542;&#21521;&#20110;&#36739;&#26202;&#33719;&#24471;&#19988;&#36951;&#24536;&#29575;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2308.15419</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#26354;&#32447;&#30340;&#29305;&#24449;&#21270;&#65306;&#23398;&#20064;&#12289;&#36951;&#24536;&#21644;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability. (arXiv:2308.15419v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20174;&#20116;&#20010;&#33521;&#35821;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#36816;&#34892;&#20013;&#25552;&#21462;&#23398;&#20064;&#26354;&#32447;&#65292;&#25581;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#39044;&#35757;&#32451;&#26399;&#38388;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#35821;&#35328;&#27169;&#22411;&#22312;&#23398;&#20064;&#29983;&#25104;&#26356;&#38271;&#12289;&#26356;&#36830;&#36143;&#30340;&#25991;&#26412;&#20043;&#21069;&#65292;&#20250;&#29983;&#25104;&#30701;&#32780;&#37325;&#22797;&#30340;&#30701;&#35821;&#12290;&#21516;&#26102;&#65292;&#39057;&#32321;&#20986;&#29616;&#30340;&#26631;&#35760;&#22312;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#26356;&#26089;&#23398;&#20064;&#65292;&#20855;&#26377;&#26356;&#23567;&#30340;&#21464;&#24322;&#24615;&#65292;&#24182;&#19988;&#24456;&#23569;&#34987;&#36951;&#24536;&#12290;&#36739;&#30701;&#12289;&#26356;&#39057;&#32321;&#30340;&#19978;&#19979;&#25991;&#19982;&#31283;&#23450;&#21644;&#24555;&#36895;&#33719;&#24471;&#30340;&#39044;&#27979;&#26377;&#20851;&#12290;&#35789;&#31867;&#30340;&#24433;&#21709;&#36739;&#23567;&#65292;&#20294;&#21517;&#35789;&#20542;&#21521;&#20110;&#36739;&#26202;&#33719;&#24471;&#19988;&#36951;&#24536;&#29575;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#20116;&#20010;&#33258;&#22238;&#24402;&#33521;&#35821;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#36816;&#34892;&#20013;&#25552;&#21462;&#23398;&#20064;&#26354;&#32447;&#65292;&#29992;&#20110;&#19978;&#19979;&#25991;&#20013;&#30340;100&#19975;&#20010;&#26631;&#35760;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#23398;&#20064;&#29983;&#25104;&#26356;&#38271;&#12289;&#26356;&#36830;&#36143;&#25991;&#26412;&#20043;&#21069;&#65292;&#35821;&#35328;&#27169;&#22411;&#20250;&#29983;&#25104;&#30701;&#32780;&#37325;&#22797;&#30340;&#30701;&#35821;&#12290;&#25105;&#20204;&#23450;&#37327;&#25551;&#36848;&#20102;&#21333;&#20010;&#19978;&#19979;&#25991;&#20013;&#26631;&#35760;&#30340;&#23398;&#20064;&#26354;&#32447;&#30340;&#26368;&#32456;surprisal&#12289;&#36816;&#34892;&#20869;&#21464;&#24322;&#24615;&#12289;&#33719;&#24471;&#24180;&#40836;&#12289;&#36951;&#24536;&#24230;&#21644;&#36328;&#36816;&#34892;&#21464;&#24322;&#24615;&#12290;&#26356;&#39057;&#32321;&#30340;&#26631;&#35760;&#36798;&#21040;&#36739;&#20302;&#30340;&#26368;&#32456;surprisal&#65292;&#20854;&#20869;&#37096;&#21644;&#39044;&#35757;&#32451;&#36816;&#34892;&#38388;&#21464;&#24322;&#24615;&#36739;&#23567;&#65292;&#23398;&#20064;&#24471;&#26356;&#26089;&#65292;&#24182;&#19988;&#22312;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#24456;&#23569;&#34987;&#8220;&#36951;&#24536;&#8221;&#12290;&#26356;&#39640;&#30340;n-gram&#27010;&#29575;&#36827;&#19968;&#27493;&#21152;&#24378;&#20102;&#36825;&#20123;&#25928;&#26524;&#12290;&#19982;&#30446;&#26631;&#26631;&#35760;&#26080;&#20851;&#65292;&#36739;&#30701;&#12289;&#26356;&#39057;&#32321;&#30340;&#19978;&#19979;&#25991;&#19982;&#36739;&#31283;&#23450;&#21644;&#24555;&#36895;&#33719;&#24471;&#30340;&#39044;&#27979;&#30053;&#26377;&#30456;&#20851;&#12290;&#35789;&#31867;&#30340;&#24433;&#21709;&#20063;&#36739;&#23567;&#65292;&#23613;&#31649;&#21517;&#35789;&#20542;&#21521;&#20110;&#36739;&#26202;&#33719;&#24471;&#19988;&#36951;&#24536;&#29575;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
How do language models learn to make predictions during pre-training? To study this question, we extract learning curves from five autoregressive English language model pre-training runs, for 1M tokens in context. We observe that the language models generate short repetitive phrases before learning to generate longer and more coherent text. We quantify the final surprisal, within-run variability, age of acquisition, forgettability, and cross-run variability of learning curves for individual tokens in context. More frequent tokens reach lower final surprisals, exhibit less variability within and across pre-training runs, are learned earlier, and are less likely to be "forgotten" during pre-training. Higher n-gram probabilities further accentuate these effects. Independent of the target token, shorter and more frequent contexts correlate with marginally more stable and quickly acquired predictions. Effects of part-of-speech are also small, although nouns tend to be acquired later and les
&lt;/p&gt;</description></item><item><title>SILO&#26159;&#19968;&#31181;&#26032;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#23545;&#38750;&#21442;&#25968;&#21270;&#30340;&#25968;&#25454;&#23384;&#20648;&#36827;&#34892;&#26597;&#35810;&#65292;&#23454;&#29616;&#22312;&#38754;&#20020;&#27861;&#24459;&#39118;&#38505;&#21644;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25903;&#25345;&#25968;&#25454;&#24402;&#23646;&#21644;&#25968;&#25454;&#29983;&#20135;&#32773;&#36864;&#20986;&#27169;&#22411;&#30340;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.04430</link><description>&lt;p&gt;
SILO&#35821;&#35328;&#27169;&#22411;&#65306;&#22312;&#38750;&#21442;&#25968;&#21270;&#25968;&#25454;&#23384;&#20648;&#20013;&#38548;&#31163;&#27861;&#24459;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore. (arXiv:2308.04430v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04430
&lt;/p&gt;
&lt;p&gt;
SILO&#26159;&#19968;&#31181;&#26032;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#23545;&#38750;&#21442;&#25968;&#21270;&#30340;&#25968;&#25454;&#23384;&#20648;&#36827;&#34892;&#26597;&#35810;&#65292;&#23454;&#29616;&#22312;&#38754;&#20020;&#27861;&#24459;&#39118;&#38505;&#21644;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25903;&#25345;&#25968;&#25454;&#24402;&#23646;&#21644;&#25968;&#25454;&#29983;&#20135;&#32773;&#36864;&#20986;&#27169;&#22411;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#23558;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#35757;&#32451;&#22312;&#21463;&#29256;&#26435;&#25110;&#21463;&#20854;&#20182;&#38480;&#21046;&#30340;&#25968;&#25454;&#19978;&#30340;&#21512;&#27861;&#24615;&#36827;&#34892;&#28608;&#28872;&#36777;&#35770;&#30340;&#21516;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20165;&#22312;&#20302;&#39118;&#38505;&#25991;&#26412;&#65288;&#20363;&#22914;&#36807;&#26399;&#29256;&#26435;&#22270;&#20070;&#25110;&#25919;&#24220;&#25991;&#20214;&#65289;&#19978;&#35757;&#32451;&#26102;&#65292;&#27169;&#22411;&#24615;&#33021;&#26174;&#33879;&#19979;&#38477;&#30340;&#38382;&#39064;&#65292;&#21407;&#22240;&#26159;&#35813;&#25991;&#26412;&#30340;&#35268;&#27169;&#21644;&#39046;&#22495;&#35206;&#30422;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SILO&#65292;&#19968;&#31181;&#26032;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#31649;&#29702;&#36825;&#31181;&#39118;&#38505;-&#24615;&#33021;&#26435;&#34913;&#12290;SILO&#36890;&#36807;&#20197;&#19979;&#26041;&#24335;&#26500;&#24314;&#65306;&#65288;1&#65289;&#22312;&#25105;&#20204;&#31574;&#21010;&#30340;&#26032;&#35821;&#26009;&#24211;&#8220;&#24320;&#25918;&#35768;&#21487;&#35777;&#35821;&#26009;&#24211;&#8221;&#65288;OLC&#65289;&#19978;&#35757;&#32451;&#21442;&#25968;&#21270;&#30340;LM&#65292;&#35813;&#35821;&#26009;&#24211;&#21253;&#21547;228B&#20010;&#20844;&#20849;&#39046;&#22495;&#21644;&#35768;&#21487;&#25991;&#26412;&#12290;&#65288;2&#65289;&#36890;&#36807;&#38750;&#21442;&#25968;&#21270;&#30340;&#25968;&#25454;&#23384;&#20648;&#65288;&#20363;&#22914;&#21253;&#21547;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#22270;&#20070;&#25110;&#26032;&#38395;&#30340;&#25968;&#25454;&#65289;&#23545;&#20854;&#36827;&#34892;&#25193;&#20805;&#65292;&#35813;&#25968;&#25454;&#23384;&#20648;&#20165;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#34987;&#26597;&#35810;&#12290;&#35813;&#25968;&#25454;&#23384;&#20648;&#20801;&#35768;&#20351;&#29992;&#39640;&#39118;&#38505;&#25968;&#25454;&#32780;&#26080;&#38656;&#23545;&#20854;&#36827;&#34892;&#35757;&#32451;&#65292;&#25903;&#25345;&#21477;&#32423;&#25968;&#25454;&#24402;&#23646;&#65292;&#24182;&#20351;&#25968;&#25454;&#29983;&#20135;&#32773;&#21487;&#20197;&#36890;&#36807;&#20174;&#23384;&#20648;&#20013;&#21024;&#38500;&#20869;&#23481;&#26469;&#36873;&#25321;&#36864;&#20986;&#27169;&#22411;&#12290;&#36825;&#20123;&#21151;&#33021;&#21487;&#20197;&#20419;&#36827;&#23545;&#25968;&#25454;&#20351;&#29992;&#35268;&#33539;&#30340;&#36981;&#24490;&#12290;
&lt;/p&gt;
&lt;p&gt;
The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use
&lt;/p&gt;</description></item></channel></rss>