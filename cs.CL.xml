<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27809;&#26377;&#23454;&#36136;&#24178;&#39044;&#30340;&#24773;&#20917;&#19979;&#24456;&#38590;&#26377;&#25928;&#36827;&#34892;&#25506;&#32034;&#65292;&#38500;&#20102;&#29305;&#23450;&#37197;&#32622;&#19979;&#30340;GPT-4&#20855;&#26377;&#28385;&#24847;&#30340;&#25506;&#32034;&#34892;&#20026;&#22806;&#65292;&#20854;&#20182;&#27169;&#22411;&#34920;&#29616;&#19981;&#31283;&#23450;&#12290;</title><link>https://arxiv.org/abs/2403.15371</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#36827;&#34892;&#19978;&#19979;&#25991;&#20013;&#30340;&#25506;&#32034;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can large language models explore in-context?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15371
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27809;&#26377;&#23454;&#36136;&#24178;&#39044;&#30340;&#24773;&#20917;&#19979;&#24456;&#38590;&#26377;&#25928;&#36827;&#34892;&#25506;&#32034;&#65292;&#38500;&#20102;&#29305;&#23450;&#37197;&#32622;&#19979;&#30340;GPT-4&#20855;&#26377;&#28385;&#24847;&#30340;&#25506;&#32034;&#34892;&#20026;&#22806;&#65292;&#20854;&#20182;&#27169;&#22411;&#34920;&#29616;&#19981;&#31283;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#29616;&#20195;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#36827;&#34892;&#25506;&#32034;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#36825;&#26159;&#24378;&#21270;&#23398;&#20064;&#21644;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#26680;&#24515;&#33021;&#21147;&#12290;&#25105;&#20204;&#20851;&#27880;&#29616;&#26377;LLMs&#30340;&#21407;&#29983;&#24615;&#33021;&#65292;&#27809;&#26377;&#36827;&#34892;&#35757;&#32451;&#24178;&#39044;&#12290;&#25105;&#20204;&#23558;LLMs&#37096;&#32626;&#20026;&#31616;&#21333;&#22810;&#33218;&#32769;&#34382;&#26426;&#29615;&#22659;&#20013;&#30340;&#20195;&#29702;&#65292;&#24182;&#23436;&#20840;&#22312;&#19978;&#19979;&#25991;&#20013;&#25351;&#23450;&#29615;&#22659;&#25551;&#36848;&#21644;&#20132;&#20114;&#21382;&#21490;&#65292;&#21363;&#22312;LLM&#25552;&#31034;&#20869;&#37096;&#36827;&#34892;&#12290;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#35774;&#35745;&#23545;GPT-3.5&#12289;GPT-4&#21644;Llama2&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#22312;&#27809;&#26377;&#23454;&#36136;&#24178;&#39044;&#30340;&#24773;&#20917;&#19979;&#24182;&#27809;&#26377;&#31283;&#20581;&#22320;&#36827;&#34892;&#25506;&#32034;&#65306;i&#65289;&#22312;&#25105;&#20204;&#30340;&#25152;&#26377;&#23454;&#39564;&#20013;&#65292;&#21482;&#26377;&#19968;&#20010;&#37197;&#32622;&#23548;&#33268;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#25506;&#32034;&#34892;&#20026;&#65306;&#20855;&#26377;&#24605;&#32500;&#38142;&#25512;&#29702;&#21644;&#22806;&#37096;&#24635;&#32467;&#30340;&#20132;&#20114;&#21382;&#21490;&#30340;GPT-4&#65292;&#36825;&#20123;&#34987;&#21576;&#29616;&#20026;&#20805;&#20998;&#32479;&#35745;&#30340;&#24773;&#20917;&#65307;ii&#65289;&#25152;&#26377;&#20854;&#20182;&#37197;&#32622;&#37117;&#27809;&#26377;&#20135;&#29983;&#31283;&#20581;&#30340;&#25506;&#32034;&#34892;&#20026;&#65292;&#21253;&#25324;&#20855;&#26377;&#24605;&#32500;&#38142;&#25512;&#29702;&#30340;&#20854;&#20182;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15371v1 Announce Type: cross  Abstract: We investigate the extent to which contemporary Large Language Models (LLMs) can engage in exploration, a core capability in reinforcement learning and decision making. We focus on native performance of existing LLMs, without training interventions. We deploy LLMs as agents in simple multi-armed bandit environments, specifying the environment description and interaction history entirely in-context, i.e., within the LLM prompt. We experiment with GPT-3.5, GPT-4, and Llama2, using a variety of prompt designs, and find that the models do not robustly engage in exploration without substantial interventions: i) Across all of our experiments, only one configuration resulted in satisfactory exploratory behavior: GPT-4 with chain-of-thought reasoning and an externally summarized interaction history, presented as sufficient statistics; ii) All other configurations did not result in robust exploratory behavior, including those with chain-of-thou
&lt;/p&gt;</description></item><item><title>EnvGen&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#33258;&#36866;&#24212;&#21019;&#24314;&#35757;&#32451;&#29615;&#22659;&#65292;&#24110;&#21161;&#23567;&#22411;&#20855;&#36523;&#20307;RL&#20195;&#29702;&#22312;&#24369;&#28857;&#26041;&#38754;&#23398;&#20064;&#26377;&#29992;&#25216;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.12014</link><description>&lt;p&gt;
EnvGen: &#36890;&#36807;LLMs&#29983;&#25104;&#21644;&#35843;&#25972;&#29615;&#22659;&#20197;&#35757;&#32451;&#20855;&#36523;&#20307;&#30340;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12014
&lt;/p&gt;
&lt;p&gt;
EnvGen&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#33258;&#36866;&#24212;&#21019;&#24314;&#35757;&#32451;&#29615;&#22659;&#65292;&#24110;&#21161;&#23567;&#22411;&#20855;&#36523;&#20307;RL&#20195;&#29702;&#22312;&#24369;&#28857;&#26041;&#38754;&#23398;&#20064;&#26377;&#29992;&#25216;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#26377;&#20851;&#36890;&#36807;&#20114;&#21160;&#36827;&#34892;&#20855;&#36523;&#20307;&#23398;&#20064;&#30340;&#26368;&#26032;&#26041;&#27861;&#30452;&#25509;&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#20195;&#29702;&#65292;&#20197;&#30830;&#23450;&#29615;&#22659;&#20013;&#30340;&#19979;&#19968;&#27493;&#12290;LLM&#20195;&#29702;&#30001;&#20110;&#20854;&#19990;&#30028;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#27604;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#20197;&#24448;&#36739;&#23567;&#30340;&#20195;&#29702;&#34920;&#29616;&#26356;&#24378;&#65307;&#20294;&#39057;&#32321;&#35843;&#29992;LLMs&#36895;&#24230;&#24930;&#19988;&#26114;&#36149;&#12290;&#25105;&#20204;&#25552;&#20986;EnvGen&#65292;&#19968;&#20010;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#30340;&#26032;&#26694;&#26550;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#31034;&#19968;&#20010;LLM&#29983;&#25104;&#35757;&#32451;&#29615;&#22659;&#65292;&#20351;&#20195;&#29702;&#21487;&#20197;&#24555;&#36895;&#24182;&#34892;&#23398;&#20064;&#19981;&#21516;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;LLM&#33719;&#24471;&#20219;&#21153;&#25551;&#36848;&#21644;&#27169;&#25311;&#22120;&#30446;&#26631;&#65292;&#28982;&#21518;&#34987;&#35201;&#27714;&#29983;&#25104;&#19968;&#32452;&#29615;&#22659;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12014v1 Announce Type: cross  Abstract: Recent SOTA approaches for embodied learning via interaction directly employ large language models (LLMs) as agents to determine the next steps in an environment. Due to their world knowledge and reasoning capabilities, LLM agents achieve stronger performance than previous smaller agents based on reinforcement learning (RL); however, frequently calling LLMs is slow and expensive. Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller embodied RL agents learn useful skills that they are weak at? We propose EnvGen, a novel framework to address this question. First, we prompt an LLM to generate training environments that allow agents to quickly learn different tasks in parallel. Concretely, the LLM is given the task description and simulator objectives that the agents should learn and is then asked to generate a set of environment configurations (e.g
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#21152;&#36895;&#20102;&#21307;&#23398;&#20013;&#33258;&#28982;&#35821;&#35328;&#21644;&#22270;&#20687;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#24182;&#26631;&#24535;&#30528;&#29983;&#29289;&#21307;&#23398;&#27169;&#22411;&#24320;&#21457;&#21644;&#37096;&#32626;&#26041;&#24335;&#30340;&#37325;&#22823;&#33539;&#24335;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2403.02558</link><description>&lt;p&gt;
&#20026;&#29983;&#25104;&#24314;&#27169;&#30740;&#31350;&#26356;&#26032;&#26377;&#20851;&#20020;&#24202;&#20154;&#24037;&#26234;&#33021;&#65288;MI-CLAIM&#65289;&#26816;&#26597;&#34920;
&lt;/p&gt;
&lt;p&gt;
Updating the Minimum Information about CLinical Artificial Intelligence (MI-CLAIM) checklist for generative modeling research
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02558
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#21152;&#36895;&#20102;&#21307;&#23398;&#20013;&#33258;&#28982;&#35821;&#35328;&#21644;&#22270;&#20687;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#24182;&#26631;&#24535;&#30528;&#29983;&#29289;&#21307;&#23398;&#27169;&#22411;&#24320;&#21457;&#21644;&#37096;&#32626;&#26041;&#24335;&#30340;&#37325;&#22823;&#33539;&#24335;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12289;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#21152;&#36895;&#20102;&#21307;&#23398;&#20013;&#33258;&#28982;&#35821;&#35328;&#21644;&#22270;&#20687;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#24182;&#26631;&#24535;&#30528;&#29983;&#29289;&#21307;&#23398;&#27169;&#22411;&#24320;&#21457;&#21644;&#37096;&#32626;&#26041;&#24335;&#30340;&#37325;&#22823;&#33539;&#24335;&#36716;&#21464;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#38750;&#24120;&#36866;&#24212;&#26032;&#20219;&#21153;&#65292;&#20294;&#22312;&#25193;&#23637;&#21644;&#35780;&#20272;&#23427;&#20204;&#30340;&#20351;&#29992;&#36807;&#31243;&#20013;&#20986;&#29616;&#20102;&#21069;&#20154;&#26694;&#26550;&#26410;&#35299;&#20915;&#30340;&#26032;&#25361;&#25112;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20123;&#27169;&#22411;&#20197;&#23569;&#37327;&#25110;&#26080;&#38656;&#19987;&#38376;&#35757;&#32451;&#25968;&#25454;&#21363;&#21487;&#20135;&#29983;&#26377;&#29992;&#36755;&#20986;&#30340;&#33021;&#21147;&#65288;&#8220;&#38646;&#26679;&#26412;&#8221;&#25110;&#8220;&#23569;&#26679;&#26412;&#8221;&#26041;&#27861;&#65289;&#65292;&#20197;&#21450;&#23427;&#20204;&#36755;&#20986;&#30340;&#24320;&#25918;&#24615;&#36136;&#65292;&#38656;&#35201;&#21046;&#23450;&#26356;&#26032;&#30340;&#20351;&#29992;&#21644;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#30340;&#25351;&#21335;&#12290;&#32654;&#22269;&#34892;&#25919;&#21629;&#20196;141103&#30830;&#23450;&#20102;&#26377;&#20851;&#20020;&#24202;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#24320;&#21457;&#30340;&#26631;&#20934;&#21644;&#26368;&#20339;&#23454;&#36341;&#23384;&#22312;&#30340;&#24046;&#36317;&#65292;&#20197;&#21450;&#20960;&#20010;&#26032;&#20852;&#22269;&#23478;&#20020;&#24202;&#20154;&#24037;&#26234;&#33021;&#35780;&#20272;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02558v1 Announce Type: new  Abstract: Recent advances in generative models, including large language models (LLMs), vision language models (VLMs), and diffusion models, have accelerated the field of natural language and image processing in medicine and marked a significant paradigm shift in how biomedical models can be developed and deployed. While these models are highly adaptable to new tasks, scaling and evaluating their usage presents new challenges not addressed in previous frameworks. In particular, the ability of these models to produce useful outputs with little to no specialized training data ("zero-" or "few-shot" approaches), as well as the open-ended nature of their outputs, necessitate the development of updated guidelines in using and evaluating these models. In response to gaps in standards and best practices for the development of clinical AI tools identified by US Executive Order 141103 and several emerging national networks for clinical AI evaluation, we be
&lt;/p&gt;</description></item><item><title>&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30701;&#31687;&#23567;&#35828;&#25688;&#35201;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#24544;&#23454;&#24615;&#21644;&#35299;&#37322;&#28508;&#21488;&#35789;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#65292;&#20294;&#22312;&#36827;&#34892;&#20027;&#39064;&#20998;&#26512;&#26102;&#34920;&#29616;&#20986;&#24605;&#32771;&#28145;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.01061</link><description>&lt;p&gt;
&#38405;&#35835;&#28508;&#21488;&#35789;&#65306;&#22312;&#30701;&#31687;&#23567;&#35828;&#25688;&#35201;&#19978;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#20316;&#32773;&#21512;&#20316;
&lt;/p&gt;
&lt;p&gt;
Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01061
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30701;&#31687;&#23567;&#35828;&#25688;&#35201;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#24544;&#23454;&#24615;&#21644;&#35299;&#37322;&#28508;&#21488;&#35789;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#65292;&#20294;&#22312;&#36827;&#34892;&#20027;&#39064;&#20998;&#26512;&#26102;&#34920;&#29616;&#20986;&#24605;&#32771;&#28145;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35780;&#20272;&#20102;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25688;&#35201;&#38271;&#31687;&#25991;&#23398;&#20316;&#21697;&#36825;&#19968;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#65292;&#36825;&#20123;&#20316;&#21697;&#21487;&#33021;&#38271;&#24230;&#36739;&#38271;&#65292;&#24182;&#21253;&#21547;&#24494;&#22937;&#30340;&#28508;&#21488;&#35789;&#25110;&#38169;&#32508;&#22797;&#26434;&#30340;&#26102;&#38388;&#32447;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30452;&#25509;&#19982;&#20316;&#32773;&#21512;&#20316;&#65292;&#30830;&#20445;&#36825;&#20123;&#20316;&#21697;&#23578;&#26410;&#22312;&#32593;&#32476;&#19978;&#20998;&#20139;&#36807;&#65288;&#22240;&#27492;&#23545;&#36825;&#20123;&#27169;&#22411;&#26159;&#26410;&#30693;&#30340;&#65289;&#65292;&#24182;&#33719;&#24471;&#20316;&#32773;&#26412;&#20154;&#23545;&#25688;&#35201;&#36136;&#37327;&#30340;&#26126;&#30830;&#35780;&#20215;&#12290;&#36890;&#36807;&#22522;&#20110;&#21465;&#20107;&#29702;&#35770;&#30340;&#23450;&#37327;&#21644;&#23450;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;GPT-4&#12289;Claude-2.1&#21644;LLama-2-70B&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#19977;&#20010;&#27169;&#22411;&#22312;50%&#20197;&#19978;&#30340;&#25688;&#35201;&#20013;&#20250;&#20986;&#29616;&#24544;&#23454;&#24615;&#38169;&#35823;&#65292;&#24182;&#19988;&#38590;&#20197;&#35299;&#37322;&#38590;&#20197;&#29702;&#35299;&#30340;&#28508;&#21488;&#35789;&#12290;&#28982;&#32780;&#65292;&#22312;&#26368;&#20339;&#29366;&#24577;&#19979;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#23545;&#25925;&#20107;&#36827;&#34892;&#26377;&#28145;&#24230;&#30340;&#20027;&#39064;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;LLMs&#23545;&#25688;&#35201;&#36136;&#37327;&#30340;&#21028;&#26029;&#19982;&#20316;&#23478;&#30340;&#21453;&#39304;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01061v1 Announce Type: new  Abstract: We evaluate recent Large language Models (LLMs) on the challenging task of summarizing short stories, which can be lengthy, and include nuanced subtext or scrambled timelines. Importantly, we work directly with authors to ensure that the stories have not been shared online (and therefore are unseen by the models), and to obtain informed evaluations of summary quality using judgments from the authors themselves. Through quantitative and qualitative analysis grounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We find that all three models make faithfulness mistakes in over 50% of summaries and struggle to interpret difficult subtext. However, at their best, the models can provide thoughtful thematic analysis of stories. We additionally demonstrate that LLM judgments of summary quality do not match the feedback from the writers.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#23548;&#33268;&#20102;&#20248;&#21270;&#21160;&#24577;&#19978;&#30340;&#22256;&#38590;&#65292;Adam&#21644;&#22522;&#20110;&#31526;&#21495;&#30340;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20248;&#20110;&#26799;&#24230;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2402.19449</link><description>&lt;p&gt;
Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models
&lt;/p&gt;
&lt;p&gt;
Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19449
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#23548;&#33268;&#20102;&#20248;&#21270;&#21160;&#24577;&#19978;&#30340;&#22256;&#38590;&#65292;Adam&#21644;&#22522;&#20110;&#31526;&#21495;&#30340;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20248;&#20110;&#26799;&#24230;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#20013;&#23384;&#22312;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#20197;&#21450;&#20026;&#20160;&#20040;Adam&#22312;&#20248;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#30340;&#34920;&#29616;&#20248;&#20110;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30001;&#20110;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#20013;&#23384;&#22312;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#65292;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26102;&#65292;&#19982;&#19981;&#24120;&#35265;&#21333;&#35789;&#30456;&#20851;&#30340;&#25439;&#22833;&#19979;&#38477;&#36895;&#24230;&#27604;&#19982;&#24120;&#35265;&#21333;&#35789;&#30456;&#20851;&#30340;&#25439;&#22833;&#19979;&#38477;&#36895;&#24230;&#24930;&#12290;&#30001;&#20110;&#22823;&#22810;&#25968;&#26679;&#26412;&#26469;&#33258;&#30456;&#23545;&#19981;&#24120;&#35265;&#30340;&#21333;&#35789;&#65292;&#24179;&#22343;&#25439;&#22833;&#20540;&#22312;&#26799;&#24230;&#19979;&#38477;&#26102;&#19979;&#38477;&#36895;&#24230;&#36739;&#24930;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;Adam&#21644;&#22522;&#20110;&#31526;&#21495;&#30340;&#26041;&#27861;&#21364;&#19981;&#21463;&#27492;&#38382;&#39064;&#24433;&#21709;&#65292;&#24182;&#25913;&#21892;&#20102;&#25152;&#26377;&#31867;&#21035;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#26550;&#26500;&#21644;&#25968;&#25454;&#31867;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#34892;&#20026;&#30830;&#23454;&#26159;&#30001;&#31867;&#21035;&#19981;&#24179;&#34913;&#24341;&#36215;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19449v1 Announce Type: cross  Abstract: Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear clas
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#37325;&#20889;&#31995;&#32479;&#21551;&#21457;&#30340;&#31070;&#32463;&#26550;&#26500;&#65292;&#29992;&#20110;&#23398;&#20064;&#31639;&#27861;&#20219;&#21153;&#65292;&#36890;&#36807;Selector&#12289;Solver&#21644;Combiner&#19977;&#20010;&#19987;&#38376;&#27169;&#22359;&#23454;&#29616;&#31639;&#27861;&#20219;&#21153;&#30340;&#31616;&#21270;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;</title><link>https://arxiv.org/abs/2402.17407</link><description>&lt;p&gt;
&#29992;&#31070;&#32463;&#37325;&#20889;&#31995;&#32479;&#35299;&#20915;&#31639;&#27861;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A Neural Rewriting System to Solve Algorithmic Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17407
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#37325;&#20889;&#31995;&#32479;&#21551;&#21457;&#30340;&#31070;&#32463;&#26550;&#26500;&#65292;&#29992;&#20110;&#23398;&#20064;&#31639;&#27861;&#20219;&#21153;&#65292;&#36890;&#36807;Selector&#12289;Solver&#21644;Combiner&#19977;&#20010;&#19987;&#38376;&#27169;&#22359;&#23454;&#29616;&#31639;&#27861;&#20219;&#21153;&#30340;&#31616;&#21270;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20173;&#28982;&#38590;&#20197;&#23398;&#20064;&#38656;&#35201;&#31995;&#32479;&#24212;&#29992;&#32452;&#21512;&#35268;&#21017;&#26469;&#35299;&#20915;&#36229;&#20986;&#20998;&#24067;&#38382;&#39064;&#23454;&#20363;&#30340;&#31639;&#27861;&#31243;&#24207;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#21019;&#26041;&#27861;&#26469;&#23398;&#20064;&#21463;&#37325;&#20889;&#31995;&#32479;&#21551;&#21457;&#30340;&#31639;&#27861;&#20219;&#21153;&#65292;&#37325;&#20889;&#31995;&#32479;&#26159;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#32463;&#20856;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#37325;&#20889;&#31995;&#32479;&#21487;&#20197;&#34987;&#23454;&#29616;&#20026;&#19968;&#20010;&#30001;&#19987;&#38376;&#27169;&#22359;&#32452;&#25104;&#30340;&#31070;&#32463;&#26550;&#26500;&#65306;&#36873;&#25321;&#22120;&#35782;&#21035;&#35201;&#22788;&#29702;&#30340;&#30446;&#26631;&#23376;&#34920;&#36798;&#24335;&#65292;&#27714;&#35299;&#22120;&#36890;&#36807;&#35745;&#31639;&#30456;&#24212;&#30340;&#32467;&#26524;&#31616;&#21270;&#23376;&#34920;&#36798;&#24335;&#65292;&#32452;&#21512;&#22120;&#36890;&#36807;&#29992;&#25552;&#20379;&#30340;&#35299;&#20915;&#26041;&#26696;&#26367;&#25442;&#23376;&#34920;&#36798;&#24335;&#29983;&#25104;&#21407;&#22987;&#34920;&#36798;&#24335;&#30340;&#26032;&#29256;&#26412;&#12290;&#25105;&#20204;&#22312;&#19977;&#31181;&#28041;&#21450;&#31616;&#21270;&#28041;&#21450;&#21015;&#34920;&#12289;&#31639;&#26415;&#21644;&#20195;&#25968;&#34920;&#36798;&#24335;&#30340;&#31526;&#21495;&#20844;&#24335;&#30340;&#31639;&#27861;&#20219;&#21153;&#19978;&#35780;&#20272;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#25152;&#25552;&#26550;&#26500;&#30340;&#22806;&#25512;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17407v1 Announce Type: cross  Abstract: Modern neural network architectures still struggle to learn algorithmic procedures that require to systematically apply compositional rules to solve out-of-distribution problem instances. In this work, we propose an original approach to learn algorithmic tasks inspired by rewriting systems, a classic framework in symbolic artificial intelligence. We show that a rewriting system can be implemented as a neural architecture composed by specialized modules: the Selector identifies the target sub-expression to process, the Solver simplifies the sub-expression by computing the corresponding result, and the Combiner produces a new version of the original expression by replacing the sub-expression with the solution provided. We evaluate our model on three types of algorithmic tasks that require simplifying symbolic formulas involving lists, arithmetic, and algebraic expressions. We test the extrapolation capabilities of the proposed architectu
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#29992;&#20110;&#32479;&#19968;&#19981;&#21516;&#27169;&#22411;&#30340;&#20219;&#21153;&#23884;&#20837;&#65292;&#20351;&#24471;&#20219;&#21153;&#23884;&#20837;&#21487;&#20197;&#36328;&#36234;&#21508;&#31181;&#27169;&#22411;&#65292;&#24182;&#22312;&#21333;&#19968;&#21521;&#37327;&#31354;&#38388;&#20869;&#36827;&#34892;&#27604;&#36739;&#21644;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.14522</link><description>&lt;p&gt;
&#36328;&#36234;&#22810;&#20010;&#27169;&#22411;&#30340;&#32479;&#19968;&#20219;&#21153;&#23884;&#20837;&#65306;&#24357;&#21512;&#22522;&#20110;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21450;&#20854;&#23427;&#27169;&#22411;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Towards Unified Task Embeddings Across Multiple Models: Bridging the Gap for Prompt-Based Large Language Models and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14522
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#29992;&#20110;&#32479;&#19968;&#19981;&#21516;&#27169;&#22411;&#30340;&#20219;&#21153;&#23884;&#20837;&#65292;&#20351;&#24471;&#20219;&#21153;&#23884;&#20837;&#21487;&#20197;&#36328;&#36234;&#21508;&#31181;&#27169;&#22411;&#65292;&#24182;&#22312;&#21333;&#19968;&#21521;&#37327;&#31354;&#38388;&#20869;&#36827;&#34892;&#27604;&#36739;&#21644;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20219;&#21153;&#23884;&#20837;&#26159;&#19968;&#31181;&#25429;&#25417;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;&#65292;&#24050;&#32463;&#21464;&#24471;&#27969;&#34892;&#36215;&#26469;&#65292;&#29305;&#21035;&#26159;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#12289;&#27169;&#22411;&#32534;&#36753;&#21644;&#21487;&#35299;&#37322;&#24615;&#31561;&#39046;&#22495;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32479;&#19968;&#20219;&#21153;&#23884;&#20837;&#65288;FUTE&#65289;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#21327;&#35843;&#26469;&#33258;&#21508;&#31181;&#27169;&#22411;&#65288;&#21253;&#25324;&#36739;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#21644;&#20855;&#26377;&#19981;&#21516;&#25552;&#31034;&#30340;LLMs&#65289;&#30340;&#20219;&#21153;&#23884;&#20837;&#65292;&#20351;&#20854;&#22788;&#20110;&#21333;&#19968;&#21521;&#37327;&#31354;&#38388;&#12290;&#36825;&#31181;&#32479;&#19968;&#24615;&#20351;&#24471;&#21487;&#20197;&#27604;&#36739;&#21644;&#20998;&#26512;&#19981;&#21516;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#25193;&#23637;&#20102;&#29616;&#26377;&#20219;&#21153;&#23884;&#20837;&#26041;&#27861;&#22312;&#35299;&#20915;&#22810;&#27169;&#22411;&#24212;&#29992;&#20013;&#30340;&#33539;&#22260;&#21644;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14522v1 Announce Type: new  Abstract: Task embedding, a meta-learning technique that captures task-specific information, has become prevalent, especially in areas such as multi-task learning, model editing, and interpretability. However, it faces challenges with the emergence of prompt-guided Large Language Models (LLMs) operating in a gradientfree manner. Existing task embedding methods rely on fine-tuned, task-specific language models, which hinders the adaptability of task embeddings across diverse models, especially prompt-based LLMs. To unleash the power of task embedding in the era of LLMs, we propose a framework for unified task embeddings (FUTE), harmonizing task embeddings from various models, including smaller language models and LLMs with varied prompts, within a single vector space. Such uniformity enables the comparison and analysis of similarities amongst different models, extending the scope and utility of existing task embedding methods in addressing multi-mo
&lt;/p&gt;</description></item><item><title>STENCIL&#21033;&#29992;&#27425;&#27169;&#20114;&#20449;&#24687;&#36873;&#25321;&#24369;&#26631;&#35760;&#30340;&#31232;&#26377;&#31867;&#23454;&#20363;&#65292;&#24182;&#36890;&#36807;&#26631;&#27880;&#32773;&#24378;&#26631;&#35760;&#65292;&#25552;&#39640;&#20102;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#20934;&#30830;&#29575;&#21644;&#31232;&#26377;&#31867;F-1&#20998;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.13468</link><description>&lt;p&gt;
STENCIL&#65306;&#22522;&#20110;&#27425;&#27169;&#20114;&#20449;&#24687;&#30340;&#20919;&#21551;&#21160;&#20027;&#21160;&#23398;&#20064;&#24369;&#30417;&#30563;
&lt;/p&gt;
&lt;p&gt;
STENCIL: Submodular Mutual Information Based Weak Supervision for Cold-Start Active Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13468
&lt;/p&gt;
&lt;p&gt;
STENCIL&#21033;&#29992;&#27425;&#27169;&#20114;&#20449;&#24687;&#36873;&#25321;&#24369;&#26631;&#35760;&#30340;&#31232;&#26377;&#31867;&#23454;&#20363;&#65292;&#24182;&#36890;&#36807;&#26631;&#27880;&#32773;&#24378;&#26631;&#35760;&#65292;&#25552;&#39640;&#20102;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#20934;&#30830;&#29575;&#21644;&#31232;&#26377;&#31867;F-1&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;NLP&#24212;&#29992;&#20013;&#23545;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#30417;&#30563;&#24494;&#35843;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#38656;&#35201;&#26356;&#22823;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21442;&#25968;&#35745;&#25968;&#22686;&#21152;&#26102;&#12290;&#20027;&#21160;&#23398;&#20064;&#35797;&#22270;&#25366;&#25496;&#21644;&#27880;&#37322;&#26410;&#26631;&#35760;&#30340;&#23454;&#20363;&#20197;&#26368;&#22823;&#38480;&#24230;&#22320;&#24555;&#36895;&#25913;&#21892;&#27169;&#22411;&#24615;&#33021;&#65292;&#26159;&#20943;&#23569;&#27880;&#37322;&#25104;&#26412;&#30340;&#24120;&#35265;&#36873;&#25321;&#65307;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#36890;&#24120;&#24573;&#35270;&#31867;&#21035;&#19981;&#24179;&#34913;&#65292;&#24182;&#19988;&#35201;&#20040;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#21021;&#22987;&#26631;&#27880;&#25968;&#25454;&#65292;&#35201;&#20040;&#35201;&#27714;&#25913;&#36827;&#31232;&#26377;&#31867;&#20043;&#21069;&#38656;&#35201;&#22810;&#36718;&#20027;&#21160;&#23398;&#20064;&#36873;&#25321;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;STENCIL&#65292;&#23427;&#21033;&#29992;&#19968;&#32452;&#25991;&#26412;&#31034;&#20363;&#21644;&#26368;&#36817;&#25552;&#20986;&#30340;&#27425;&#27169;&#20114;&#20449;&#24687;&#26469;&#36873;&#25321;&#19968;&#32452;&#24369;&#26631;&#35760;&#30340;&#31232;&#26377;&#31867;&#23454;&#20363;&#65292;&#28982;&#21518;&#30001;&#26631;&#27880;&#32773;&#23545;&#20854;&#36827;&#34892;&#24378;&#26631;&#35760;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;STENCIL&#22312;&#22810;&#20010;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#23558;&#25972;&#20307;&#20934;&#30830;&#29575;&#25552;&#39640;&#20102;10%-24%&#65292;&#23558;&#31232;&#26377;&#31867;F-1&#20998;&#25968;&#25552;&#39640;&#20102;17%-40%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13468v1 Announce Type: cross  Abstract: As supervised fine-tuning of pre-trained models within NLP applications increases in popularity, larger corpora of annotated data are required, especially with increasing parameter counts in large language models. Active learning, which attempts to mine and annotate unlabeled instances to improve model performance maximally fast, is a common choice for reducing the annotation cost; however, most methods typically ignore class imbalance and either assume access to initial annotated data or require multiple rounds of active learning selection before improving rare classes. We present STENCIL, which utilizes a set of text exemplars and the recently proposed submodular mutual information to select a set of weakly labeled rare-class instances that are then strongly labeled by an annotator. We show that STENCIL improves overall accuracy by $10\%-24\%$ and rare-class F-1 score by $17\%-40\%$ on multiple text classification datasets over commo
&lt;/p&gt;</description></item><item><title>BlendFilter&#36890;&#36807;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#21644;&#30693;&#35782;&#36807;&#28388;&#26041;&#27861;&#25552;&#21319;&#20102;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#22810;&#39046;&#22495;&#30340;&#38382;&#31572;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.11129</link><description>&lt;p&gt;
BlendFilter: &#36890;&#36807;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#21644;&#30693;&#35782;&#36807;&#28388;&#25512;&#36827;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11129
&lt;/p&gt;
&lt;p&gt;
BlendFilter&#36890;&#36807;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#21644;&#30693;&#35782;&#36807;&#28388;&#26041;&#27861;&#25552;&#21319;&#20102;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#22810;&#39046;&#22495;&#30340;&#38382;&#31572;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11129v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#25552;&#21319;&#30693;&#35782;&#23494;&#38598;&#22411;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#32463;&#24120;&#38754;&#20020;&#22797;&#26434;&#36755;&#20837;&#30340;&#25361;&#25112;&#65292;&#24182;&#19988;&#30001;&#20110;&#22024;&#26434;&#30340;&#30693;&#35782;&#26816;&#32034;&#32780;&#36935;&#21040;&#22256;&#38590;&#65292;&#26126;&#26174;&#38459;&#30861;&#20102;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;BlendFilter&#65292;&#19968;&#31181;&#36890;&#36807;&#23558;&#26597;&#35810;&#29983;&#25104;&#28151;&#21512;&#19982;&#30693;&#35782;&#36807;&#28388;&#30456;&#32467;&#21512;&#26469;&#25552;&#21319;&#26816;&#32034;&#22686;&#24378;&#22411;LLM&#30340;&#26032;&#26041;&#27861;&#12290;BlendFilter&#25552;&#20986;&#20102;&#36890;&#36807;&#20854;&#26597;&#35810;&#29983;&#25104;&#26041;&#27861;&#30340;&#28151;&#21512;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#23558;&#22806;&#37096;&#30693;&#35782;&#21644;&#20869;&#37096;&#30693;&#35782;&#22686;&#24378;&#19982;&#21407;&#22987;&#26597;&#35810;&#30456;&#32467;&#21512;&#65292;&#30830;&#20445;&#20840;&#38754;&#25910;&#38598;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#29420;&#29305;&#30340;&#30693;&#35782;&#36807;&#28388;&#27169;&#22359;&#20805;&#20998;&#21033;&#29992;&#20102;LLM&#30340;&#22266;&#26377;&#33021;&#21147;&#65292;&#26377;&#25928;&#28040;&#38500;&#20102;&#22810;&#20313;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#24320;&#25918;&#22495;&#38382;&#31572;&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11129v1 Announce Type: new  Abstract: Retrieval-augmented Large Language Models (LLMs) offer substantial benefits in enhancing performance across knowledge-intensive scenarios. However, these methods often face challenges with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness. To address this issue, we introduce BlendFilter, a novel approach that elevates retrieval-augmented LLMs by integrating query generation blending with knowledge filtering. BlendFilter proposes the blending process through its query generation method, which integrates both external and internal knowledge augmentation with the original query, ensuring comprehensive information gathering. Additionally, our distinctive knowledge filtering module capitalizes on the intrinsic capabilities of the LLM, effectively eliminating extraneous data. We conduct extensive experiments on three open-domain question answering benchmarks, and the findings clea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#32467;&#26500;&#21270;&#21465;&#20107;&#25552;&#31034;&#65292;&#39564;&#35777;&#20102;GPT-4&#29983;&#25104;&#30340;&#21465;&#36848;&#22312;&#20256;&#36798;&#29983;&#27963;&#20107;&#20214;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22823;&#22810;&#25968;&#21465;&#36848;&#33021;&#22815;&#36275;&#22815;&#20256;&#36798;&#25552;&#31034;&#30340;&#24847;&#22270;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#21644;&#39564;&#35777;&#65292;&#21487;&#20197;&#33258;&#21160;&#35782;&#21035;&#26377;&#25928;&#21644;&#26080;&#25928;&#30340;&#21465;&#36848;&#12290;</title><link>https://arxiv.org/abs/2402.05435</link><description>&lt;p&gt;
GPT-4&#20351;&#29992;&#32467;&#26500;&#21270;&#21465;&#20107;&#25552;&#31034;&#29983;&#25104;&#29983;&#27963;&#20107;&#20214;&#30340;&#21465;&#36848;&#65306;&#19968;&#39033;&#39564;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05435
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#32467;&#26500;&#21270;&#21465;&#20107;&#25552;&#31034;&#65292;&#39564;&#35777;&#20102;GPT-4&#29983;&#25104;&#30340;&#21465;&#36848;&#22312;&#20256;&#36798;&#29983;&#27963;&#20107;&#20214;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22823;&#22810;&#25968;&#21465;&#36848;&#33021;&#22815;&#36275;&#22815;&#20256;&#36798;&#25552;&#31034;&#30340;&#24847;&#22270;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#21644;&#39564;&#35777;&#65292;&#21487;&#20197;&#33258;&#21160;&#35782;&#21035;&#26377;&#25928;&#21644;&#26080;&#25928;&#30340;&#21465;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#21508;&#31181;&#21465;&#36848;&#26041;&#38754;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#20419;&#36827;&#20102;&#23545;&#20854;&#22312;&#21465;&#36848;&#24418;&#24335;&#20013;&#20256;&#36798;&#29983;&#27963;&#20107;&#20214;&#25928;&#26524;&#30340;&#31995;&#32479;&#25506;&#32034;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#38646;-shot&#32467;&#26500;&#21270;&#21465;&#20107;&#25552;&#31034;&#65292;&#20351;&#29992;OpenAI&#30340;GPT-4&#29983;&#25104;&#20102;24,000&#20010;&#21465;&#36848;&#12290;&#20174;&#36825;&#20010;&#25968;&#25454;&#38598;&#20013;&#65292;&#25105;&#20204;&#25163;&#21160;&#20998;&#31867;&#20102;2,880&#20010;&#21465;&#36848;&#65292;&#24182;&#35780;&#20272;&#23427;&#20204;&#22312;&#20256;&#36798;&#20986;&#29983;&#12289;&#27515;&#20129;&#12289;&#25307;&#32856;&#21644;&#35299;&#38599;&#20107;&#20214;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;87.43%&#30340;&#21465;&#36848;&#36275;&#22815;&#20256;&#36798;&#32467;&#26500;&#21270;&#25552;&#31034;&#30340;&#24847;&#22270;&#12290;&#20026;&#20102;&#33258;&#21160;&#35782;&#21035;&#26377;&#25928;&#21644;&#26080;&#25928;&#30340;&#21465;&#36848;&#65292;&#25105;&#20204;&#23545;&#20998;&#31867;&#25968;&#25454;&#38598;&#35757;&#32451;&#21644;&#39564;&#35777;&#20102;&#20061;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#23545;&#21097;&#20313;21,120&#20010;&#21465;&#36848;&#30340;&#20998;&#31867;&#39044;&#27979;&#20998;&#26512;&#12290;&#25152;&#26377;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#23558;&#26377;&#25928;&#30340;&#21465;&#36848;&#20998;&#31867;&#20026;&#26377;&#25928;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#21516;&#26102;&#23558;&#26080;&#25928;&#30340;&#21465;&#36848;&#20998;&#31867;&#20026;&#26080;&#25928;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#19981;&#20165;&#25512;&#36827;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#36824;&#25552;&#20379;&#20102;&#33258;&#21160;&#35782;&#21035;&#26377;&#25928;&#21465;&#36848;&#30340;&#26377;&#30410;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) play a pivotal role in generating vast arrays of narratives, facilitating a systematic exploration of their effectiveness for communicating life events in narrative form. In this study, we employ a zero-shot structured narrative prompt to generate 24,000 narratives using OpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and evaluate their validity in conveying birth, death, hiring, and firing events. Remarkably, 87.43% of the narratives sufficiently convey the intention of the structured prompt. To automate the identification of valid and invalid narratives, we train and validate nine Machine Learning models on the classified datasets. Leveraging these models, we extend our analysis to predict the classifications of the remaining 21,120 narratives. All the ML models excelled at classifying valid narratives as valid, but experienced challenges at simultaneously classifying invalid narratives as invalid. Our findings not only advance th
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#22810;&#20010;&#26102;&#38388;&#35270;&#35282;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#22686;&#24378;Transformer RNNs&#23545;&#39034;&#24207;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#22312;&#21442;&#25968;&#25968;&#37327;&#26368;&#23567;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.02625</link><description>&lt;p&gt;
&#29992;&#22810;&#20010;&#26102;&#38388;&#35270;&#35282;&#22686;&#24378;Transformer RNNs
&lt;/p&gt;
&lt;p&gt;
Enhancing Transformer RNNs with Multiple Temporal Perspectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02625
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#22810;&#20010;&#26102;&#38388;&#35270;&#35282;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#22686;&#24378;Transformer RNNs&#23545;&#39034;&#24207;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#22312;&#21442;&#25968;&#25968;&#37327;&#26368;&#23567;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#20010;&#26102;&#38388;&#35270;&#35282;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#26550;&#26500;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22686;&#24378;&#20854;&#23545;&#39034;&#24207;&#25968;&#25454;&#30340;&#29702;&#35299;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#32500;&#25252;&#20808;&#21069;&#36935;&#21040;&#30340;&#25991;&#26412;&#30340;&#22810;&#26679;&#26102;&#38388;&#35270;&#22270;&#65292;&#26174;&#33879;&#20016;&#23500;&#20102;&#35821;&#35328;&#27169;&#22411;&#35299;&#37322;&#19978;&#19979;&#25991;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#32435;&#20837;&#20102;Receptance Weighted Key Value&#65288;RWKV&#65289;&#26550;&#26500;&#65292;&#35299;&#20915;&#20102;&#35813;&#26550;&#26500;&#22312;&#21333;&#20010;&#38544;&#34255;&#29366;&#24577;&#20013;&#20445;&#30041;&#25152;&#26377;&#21382;&#21490;&#20449;&#24687;&#30340;&#22266;&#26377;&#25361;&#25112;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#21363;&#20351;&#21442;&#25968;&#25968;&#37327;&#22686;&#21152;&#26368;&#23569;&#65288;&#20165;&#20026;&#26368;&#21021;&#21442;&#25968;&#25968;&#37327;&#30340;0.04%&#65289;&#65292;&#20063;&#23454;&#29616;&#20102;&#27492;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#22810;&#20010;&#26102;&#38388;&#35270;&#35282;&#25152;&#38656;&#30340;&#39069;&#22806;&#21442;&#25968;&#32463;&#36807;&#24494;&#23567;&#30340;&#35745;&#31639;&#24320;&#38144;&#36827;&#34892;&#24494;&#35843;&#65292;&#36991;&#20813;&#20102;&#23436;&#20840;&#39044;&#35757;&#32451;&#30340;&#38656;&#35201;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#27169;&#22411;&#22312;&#25552;&#31034;&#25512;&#26029;&#36807;&#31243;&#20013;&#20445;&#25345;&#20102;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the concept of multiple temporal perspectives, a novel approach applicable to Recurrent Neural Network (RNN) architectures for enhancing their understanding of sequential data. This method involves maintaining diverse temporal views of previously encountered text, significantly enriching the language models' capacity to interpret context. To show the efficacy of this approach, we incorporate it into the Receptance Weighted Key Value (RWKV) architecture, addressing its inherent challenge of retaining all historical information within a single hidden state. Notably, this improvement is achieved with a minimal increase in the number of parameters --even as little as $0.04\%$ of the original number of parameters. Further, the additional parameters necessary for the multiple temporal perspectives are fine-tuned with minimal computational overhead, avoiding the need for a full pre-training. The resulting model maintains linear computational complexity during prompt inference, en
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#26512;&#32654;&#22269;&#21069;100&#21517;&#22823;&#23398;&#21046;&#23450;&#30340;&#23398;&#26415;&#25919;&#31574;&#21644;&#25351;&#21335;&#65292;&#25581;&#31034;&#20102;&#22823;&#22810;&#25968;&#22823;&#23398;&#23545;&#20110;&#22312;&#39640;&#31561;&#25945;&#32946;&#20013;&#25972;&#21512;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#30340;&#24320;&#25918;&#20294;&#35880;&#24910;&#24577;&#24230;&#65292;&#20027;&#35201;&#20851;&#27880;&#28857;&#22312;&#20110;&#20262;&#29702;&#20351;&#29992;&#12289;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38544;&#31169;&#12290;</title><link>https://arxiv.org/abs/2312.05235</link><description>&lt;p&gt;
&#39640;&#31561;&#25945;&#32946;&#20013;&#30340;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#65306;&#36890;&#36807;&#22823;&#23398;&#30340;&#25919;&#31574;&#12289;&#36164;&#28304;&#21644;&#25351;&#21335;&#20102;&#35299;ChatGPT
&lt;/p&gt;
&lt;p&gt;
Generative AI in Higher Education: Seeing ChatGPT Through Universities' Policies, Resources, and Guidelines
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.05235
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#26512;&#32654;&#22269;&#21069;100&#21517;&#22823;&#23398;&#21046;&#23450;&#30340;&#23398;&#26415;&#25919;&#31574;&#21644;&#25351;&#21335;&#65292;&#25581;&#31034;&#20102;&#22823;&#22810;&#25968;&#22823;&#23398;&#23545;&#20110;&#22312;&#39640;&#31561;&#25945;&#32946;&#20013;&#25972;&#21512;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#30340;&#24320;&#25918;&#20294;&#35880;&#24910;&#24577;&#24230;&#65292;&#20027;&#35201;&#20851;&#27880;&#28857;&#22312;&#20110;&#20262;&#29702;&#20351;&#29992;&#12289;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#65288;GenAI&#65289;&#25216;&#26415;&#30340;&#36827;&#27493;&#65288;&#22914;ChatGPT&#65289;&#20026;&#20016;&#23500;&#25945;&#32946;&#32463;&#39564;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#20294;&#22914;&#26524;&#34987;&#28389;&#29992;&#65292;&#20063;&#20250;&#24341;&#21457;&#26377;&#20851;&#23398;&#26415;&#35802;&#20449;&#30340;&#25285;&#24551;&#12290;&#35813;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#32654;&#22269;&#25490;&#21517;&#21069;100&#30340;&#22823;&#23398;&#21046;&#23450;&#30340;&#23398;&#26415;&#25919;&#31574;&#21644;&#25351;&#21335;&#26469;&#25506;&#35752;&#22823;&#23398;&#21644;&#25945;&#32946;&#32773;&#22914;&#20309;&#22312;&#20854;&#23398;&#26415;&#32972;&#26223;&#20013;&#23545;GenAI&#30340;&#21457;&#23637;&#20570;&#20986;&#21709;&#24212;&#21644;&#36866;&#24212;&#12290;&#25968;&#25454;&#26469;&#28304;&#21253;&#25324;&#36825;&#20123;&#22823;&#23398;&#21046;&#23450;&#30340;&#23398;&#26415;&#25919;&#31574;&#12289;&#22768;&#26126;&#12289;&#25351;&#21335;&#20197;&#21450;&#30456;&#20851;&#36164;&#28304;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22823;&#22810;&#25968;&#22823;&#23398;&#23545;&#20110;&#25972;&#21512;GenAI&#37319;&#21462;&#20102;&#24320;&#25918;&#20294;&#35880;&#24910;&#30340;&#24577;&#24230;&#12290;&#20027;&#35201;&#20851;&#27880;&#28857;&#22312;&#20110;&#20262;&#29702;&#20351;&#29992;&#12289;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38544;&#31169;&#12290;&#22823;&#22810;&#25968;&#22823;&#23398;&#31215;&#26497;&#22238;&#24212;&#24182;&#25552;&#20379;&#22810;&#31181;&#36164;&#28304;&#65292;&#22914;&#35838;&#31243;&#22823;&#32434;&#27169;&#26495;/&#31034;&#20363;&#12289;&#30740;&#35752;&#20250;&#12289;&#20849;&#20139;&#25991;&#31456;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.05235v2 Announce Type: replace  Abstract: The advancements in Generative Artificial Intelligence (GenAI) technologies such as ChatGPT provide opportunities to enrich educational experiences, but also raise concerns about academic integrity if misused. This study aims to explore how universities and educators respond and adapt to the development of GenAI in their academic contexts by analyzing academic policies and guidelines established by top-ranked US universities regarding the use of ChatGPT in higher education. The data sources include academic policies, statements, guidelines as well as relevant resources provided by the top 100 universities in the US. Results show that the majority of these universities adopt an open but cautious approach towards the integration of GenAI. Primary concerns lie in ethical usage, accuracy, and data privacy. Most universities actively respond and provide diverse types of resources, such as syllabus templates/samples, workshops, shared arti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#23545;&#21516;&#24615;&#20851;&#31995;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#21457;&#29616;&#19977;&#20010;&#21463;&#27426;&#36814;&#30340;MT&#26381;&#21153;&#22312;&#20934;&#30830;&#32763;&#35793;&#28041;&#21450;&#21516;&#24615;&#21035;&#21517;&#35789;&#20043;&#38388;&#20851;&#31995;&#30340;&#21477;&#23376;&#26102;&#23384;&#22312;&#36739;&#22823;&#30340;&#38169;&#35823;&#29575;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#22899;&#24615;&#32844;&#19994;&#30340;&#19978;&#19979;&#25991;&#20013;&#34920;&#29616;&#26356;&#24046;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#35780;&#20272;NLP&#31995;&#32479;&#20013;&#22266;&#26377;&#20559;&#35265;&#25552;&#20379;&#20102;&#19968;&#20010;&#31038;&#20250;&#20851;&#31995;&#26041;&#38754;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2401.04972</link><description>&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#20013;&#30340;&#21516;&#24615;&#20851;&#31995;&#20559;&#35265;&#35780;&#20272;&#65306;&#23427;&#31350;&#31455;&#26159;&#35841;&#30340;&#22971;&#23376;&#65311;
&lt;/p&gt;
&lt;p&gt;
Whose wife is it anyway? Assessing bias against same-gender relationships in machine translation. (arXiv:2401.04972v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#23545;&#21516;&#24615;&#20851;&#31995;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#21457;&#29616;&#19977;&#20010;&#21463;&#27426;&#36814;&#30340;MT&#26381;&#21153;&#22312;&#20934;&#30830;&#32763;&#35793;&#28041;&#21450;&#21516;&#24615;&#21035;&#21517;&#35789;&#20043;&#38388;&#20851;&#31995;&#30340;&#21477;&#23376;&#26102;&#23384;&#22312;&#36739;&#22823;&#30340;&#38169;&#35823;&#29575;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#22899;&#24615;&#32844;&#19994;&#30340;&#19978;&#19979;&#25991;&#20013;&#34920;&#29616;&#26356;&#24046;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#35780;&#20272;NLP&#31995;&#32479;&#20013;&#22266;&#26377;&#20559;&#35265;&#25552;&#20379;&#20102;&#19968;&#20010;&#31038;&#20250;&#20851;&#31995;&#26041;&#38754;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#32463;&#24120;&#21463;&#21040;&#26377;&#20559;&#35265;&#30340;&#25968;&#25454;&#21644;&#31639;&#27861;&#30340;&#22256;&#25200;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#31995;&#32479;&#36755;&#20986;&#20013;&#30340;&#19981;&#21487;&#25509;&#21463;&#30340;&#38169;&#35823;&#12290;&#34429;&#28982;&#23545;&#24615;&#21035;&#35268;&#33539;&#30340;&#20559;&#35265;&#36827;&#34892;&#20102;&#35843;&#26597;&#30740;&#31350;&#65292;&#20294;&#23545;MT&#31995;&#32479;&#26159;&#21542;&#23545;&#31038;&#20250;&#20851;&#31995;&#32534;&#30721;&#20559;&#35265;&#30340;&#24773;&#20917;&#20102;&#35299;&#36739;&#23569;&#65292;&#20363;&#22914;&#8220;&#24459;&#24072;&#21563;&#20102;&#22905;&#30340;&#22971;&#23376;&#8221;&#36825;&#26679;&#30340;&#21477;&#23376;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20174;&#20960;&#31181;&#21517;&#35789;&#24615;&#21035;&#35821;&#35328;&#65288;&#20363;&#22914;&#35199;&#29677;&#29273;&#35821;&#65289;&#20013;&#25277;&#21462;&#30340;&#29983;&#25104;&#27169;&#26495;&#21477;&#23376;&#65292;&#35843;&#26597;MT&#31995;&#32479;&#38024;&#23545;&#21516;&#24615;&#20851;&#31995;&#30340;&#20559;&#35265;&#31243;&#24230;&#12290;&#25105;&#20204;&#21457;&#29616;&#19977;&#20010;&#21463;&#27426;&#36814;&#30340;MT&#26381;&#21153;&#22312;&#20934;&#30830;&#32763;&#35793;&#28041;&#21450;&#21516;&#24615;&#21035;&#21517;&#35789;&#20043;&#38388;&#20851;&#31995;&#30340;&#21477;&#23376;&#26102;&#19968;&#30452;&#23384;&#22312;&#38382;&#39064;&#12290;&#38169;&#35823;&#29575;&#26681;&#25454;&#19978;&#19979;&#25991;&#32780;&#21464;&#21270;&#24456;&#22823;&#65292;&#20363;&#22914;&#24341;&#29992;&#22899;&#24615;&#21344;&#27604;&#36739;&#39640;&#32844;&#19994;&#30340;&#21516;&#24615;&#21477;&#23376;&#30340;&#32763;&#35793;&#20934;&#30830;&#24230;&#36739;&#20302;&#12290;&#25105;&#20204;&#25552;&#20379;&#36825;&#39033;&#24037;&#20316;&#20316;&#20026;&#30740;&#31350;NLP&#31995;&#32479;&#20013;&#22266;&#26377;&#20559;&#35265;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#28041;&#21450;&#31038;&#20250;&#20851;&#31995;&#26041;&#38754;&#30340;&#20559;&#35265;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine translation often suffers from biased data and algorithms that can lead to unacceptable errors in system output. While bias in gender norms has been investigated, less is known about whether MT systems encode bias about social relationships, e.g. sentences such as "the lawyer kissed her wife." We investigate the degree of bias against same-gender relationships in MT systems, using generated template sentences drawn from several noun-gender languages (e.g. Spanish). We find that three popular MT services consistently fail to accurately translate sentences concerning relationships between nouns of the same gender. The error rate varies considerably based on the context, e.g. same-gender sentences referencing high female-representation occupations are translated with lower accuracy. We provide this work as a case study in the evaluation of intrinsic bias in NLP systems, with respect to social relationships.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#36830;&#32493;&#25552;&#31034;&#20256;&#36882;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#28304;&#25552;&#31034;&#32534;&#30721;&#21040;&#30456;&#23545;&#31354;&#38388;&#20013;&#65292;&#24182;&#25628;&#32034;&#30456;&#24212;&#30340;&#30446;&#26631;&#25552;&#31034;&#65292;&#22312;&#19981;&#21516;&#30340;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#23454;&#29616;&#20102;&#20219;&#21153;&#35821;&#20041;&#30340;&#27867;&#21270;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.01691</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#36830;&#32493;&#25552;&#31034;&#20256;&#36882;&#65306;&#22312;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#27867;&#21270;&#20219;&#21153;&#35821;&#20041;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models. (arXiv:2310.01691v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01691
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#36830;&#32493;&#25552;&#31034;&#20256;&#36882;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#28304;&#25552;&#31034;&#32534;&#30721;&#21040;&#30456;&#23545;&#31354;&#38388;&#20013;&#65292;&#24182;&#25628;&#32034;&#30456;&#24212;&#30340;&#30446;&#26631;&#25552;&#31034;&#65292;&#22312;&#19981;&#21516;&#30340;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#23454;&#29616;&#20102;&#20219;&#21153;&#35821;&#20041;&#30340;&#27867;&#21270;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#65292;&#36890;&#36807;&#35843;&#25972;&#25552;&#31034;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#29305;&#23450;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25552;&#31034;&#65292;&#29305;&#21035;&#26159;&#36830;&#32493;&#25552;&#31034;&#65292;&#22312;&#19981;&#21516;&#27169;&#22411;&#20043;&#38388;&#30340;&#21487;&#20256;&#36882;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#36830;&#32493;&#25552;&#31034;&#20256;&#36882;&#26041;&#27861;&#65292;&#20854;&#20013;&#28304;&#25552;&#31034;&#34987;&#32534;&#30721;&#21040;&#30456;&#23545;&#31354;&#38388;&#20013;&#65292;&#24182;&#25628;&#32034;&#30456;&#24212;&#30340;&#30446;&#26631;&#25552;&#31034;&#20197;&#23558;&#20854;&#20256;&#36882;&#21040;&#30446;&#26631;&#27169;&#22411;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#34920;&#26126;&#36830;&#32493;&#25552;&#31034;&#20013;&#30340;&#8220;&#20219;&#21153;&#35821;&#20041;&#8221;&#21487;&#20197;&#22312;&#21508;&#31181;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#23558;&#26469;&#33258;&#22810;&#20010;&#28304;&#27169;&#22411;&#30340;&#8220;&#20219;&#21153;&#35821;&#20041;&#8221;&#32467;&#21512;&#21487;&#20197;&#36827;&#19968;&#27493;&#22686;&#24378;&#20256;&#36882;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prompt tuning in natural language processing (NLP) has become an increasingly popular method for adapting large language models to specific tasks. However, the transferability of these prompts, especially continuous prompts, between different models remains a challenge. In this work, we propose a zero-shot continuous prompt transfer method, where source prompts are encoded into relative space and the corresponding target prompts are searched for transferring to target models. Experimental results confirm the effectiveness of our method, showing that 'task semantics' in continuous prompts can be generalized across various language models. Moreover, we find that combining 'task semantics' from multiple source models can further enhance the generalizability of transfer.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#38899;&#30340;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#21407;&#22987;&#35821;&#38899;&#20013;&#24314;&#31435;&#22522;&#30784;&#35821;&#27861;&#27169;&#22411;&#12290;&#20316;&#32773;&#21457;&#29616;&#65292;&#22312;&#22522;&#20110;&#22768;&#38899;&#30340;&#21333;&#35789;&#35760;&#24405;&#19978;&#35757;&#32451;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#33258;&#21457;&#36830;&#25509;&#20004;&#20010;&#25110;&#19977;&#20010;&#21333;&#35789;&#65292;&#24182;&#19988;&#21487;&#20197;&#23398;&#20250;&#23558;&#21333;&#35789;&#23884;&#20837;&#21040;&#26032;&#30340;&#26410;&#35265;&#36807;&#30340;&#21333;&#35789;&#32452;&#21512;&#20013;&#65292;&#36825;&#26159;&#20043;&#21069;&#26410;&#25253;&#36947;&#30340;&#23646;&#24615;&#65292;&#36825;&#19968;&#21457;&#29616;&#23545;&#25105;&#20204;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#26041;&#24335;&#21644;&#24314;&#31435;&#20174;&#21407;&#22987;&#22768;&#23398;&#36755;&#20837;&#20013;&#30340;&#35821;&#27861;&#21450;&#20854;&#28436;&#21270;&#30340;&#27169;&#22411;&#37117;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2305.01626</link><description>&lt;p&gt;
&#22522;&#20110;&#35821;&#38899;&#30340;&#22522;&#30784;&#35821;&#27861;&#65306;&#33258;&#21457;&#32852;&#25509;&#30340;&#33258;&#30417;&#30563;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks. (arXiv:2305.01626v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01626
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#38899;&#30340;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#21407;&#22987;&#35821;&#38899;&#20013;&#24314;&#31435;&#22522;&#30784;&#35821;&#27861;&#27169;&#22411;&#12290;&#20316;&#32773;&#21457;&#29616;&#65292;&#22312;&#22522;&#20110;&#22768;&#38899;&#30340;&#21333;&#35789;&#35760;&#24405;&#19978;&#35757;&#32451;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#33258;&#21457;&#36830;&#25509;&#20004;&#20010;&#25110;&#19977;&#20010;&#21333;&#35789;&#65292;&#24182;&#19988;&#21487;&#20197;&#23398;&#20250;&#23558;&#21333;&#35789;&#23884;&#20837;&#21040;&#26032;&#30340;&#26410;&#35265;&#36807;&#30340;&#21333;&#35789;&#32452;&#21512;&#20013;&#65292;&#36825;&#26159;&#20043;&#21069;&#26410;&#25253;&#36947;&#30340;&#23646;&#24615;&#65292;&#36825;&#19968;&#21457;&#29616;&#23545;&#25105;&#20204;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#26041;&#24335;&#21644;&#24314;&#31435;&#20174;&#21407;&#22987;&#22768;&#23398;&#36755;&#20837;&#20013;&#30340;&#35821;&#27861;&#21450;&#20854;&#28436;&#21270;&#30340;&#27169;&#22411;&#37117;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#27861;&#30340;&#35745;&#31639;&#27169;&#22411;&#20027;&#35201;&#22522;&#20110;&#25991;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#21407;&#22987;&#35821;&#38899;&#20013;&#24314;&#31435;&#22522;&#30784;&#35821;&#27861;&#27169;&#22411;&#12290;&#25105;&#20204;&#37325;&#28857;&#30740;&#31350;&#20102;&#26368;&#26222;&#36941;&#21644;&#22522;&#26412;&#30340;&#35821;&#27861;&#29305;&#24615;&#20043;&#19968;&#8212;&#8212;&#32852;&#25509;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#33258;&#21457;&#32852;&#25509;&#29616;&#35937;&#65306;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#22312;&#20010;&#21035;&#21333;&#35789;&#30340;&#22768;&#23398;&#35760;&#24405;&#19978;&#35757;&#32451;&#26102;&#65292;&#24320;&#22987;&#20135;&#29983;&#36755;&#20986;&#65292;&#36825;&#20123;&#36755;&#20986;&#23558;&#20004;&#20010;&#29978;&#33267;&#19977;&#20010;&#21333;&#35789;&#36830;&#25509;&#22312;&#19968;&#36215;&#65292;&#32780;&#19981;&#20250;&#25509;&#35302;&#21040;&#20855;&#26377;&#22810;&#20010;&#21333;&#35789;&#30340;&#36755;&#20837;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#20004;&#20010;&#21333;&#35789;&#30340;&#32593;&#32476;&#21487;&#20197;&#23398;&#20064;&#23558;&#21333;&#35789;&#23884;&#20837;&#21040;&#26032;&#30340;&#26410;&#35265;&#36807;&#30340;&#21333;&#35789;&#32452;&#21512;&#20013;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#22312;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#29615;&#22659;&#19979;&#35757;&#32451;&#30340;&#21407;&#22987;&#35821;&#38899;CNN&#20197;&#21069;&#26410;&#25253;&#36947;&#30340;&#23646;&#24615;&#65292;&#23427;&#19981;&#20165;&#23545;&#25105;&#20204;&#29702;&#35299;&#36825;&#20123;&#20307;&#31995;&#32467;&#26500;&#30340;&#23398;&#20064;&#26041;&#24335;&#26377;&#24433;&#21709;&#65292;&#36824;&#23545;&#24314;&#31435;&#20174;&#21407;&#22987;&#22768;&#23398;&#36755;&#20837;&#20013;&#30340;&#35821;&#27861;&#21450;&#20854;&#28436;&#21270;&#30340;&#27169;&#22411;&#26377;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computational models of syntax are predominantly text-based. Here we propose that basic syntax can be modeled directly from raw speech in a fully unsupervised way. We focus on one of the most ubiquitous and basic properties of syntax -- concatenation. We introduce spontaneous concatenation: a phenomenon where convolutional neural networks (CNNs) trained on acoustic recordings of individual words start generating outputs with two or even three words concatenated without ever accessing data with multiple words in the input. Additionally, networks trained on two words learn to embed words into novel unobserved word combinations. To our knowledge, this is a previously unreported property of CNNs trained on raw speech in the Generative Adversarial Network setting and has implications both for our understanding of how these architectures learn as well as for modeling syntax and its evolution from raw acoustic inputs.
&lt;/p&gt;</description></item></channel></rss>