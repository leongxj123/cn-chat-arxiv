<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;</title><link>https://arxiv.org/abs/2404.01903</link><description>&lt;p&gt;
&#22312;CodeLLMs&#20013;&#23454;&#29616;&#31867;&#22411;&#39044;&#27979;&#30340;&#40065;&#26834;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Activation Steering for Robust Type Prediction in CodeLLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01903
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#22312;&#20195;&#30721;&#19978;&#30340;&#29616;&#20195;LLMs&#33021;&#22815;&#25104;&#21151;&#22320;&#23436;&#25104;&#21508;&#31181;&#32534;&#31243;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#23545;&#35821;&#27861;&#29305;&#24449;&#38750;&#24120;&#25935;&#24863;&#65292;&#20363;&#22914;&#21464;&#37327;&#21644;&#31867;&#22411;&#30340;&#21517;&#31216;&#12289;&#20195;&#30721;&#32467;&#26500;&#20197;&#21450;&#31867;&#22411;&#25552;&#31034;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25512;&#29702;&#26102;&#25216;&#26415;&#65292;&#20351;CodeLLMs&#26356;&#33021;&#25269;&#24481;&#35821;&#27861;&#24178;&#25200;&#22240;&#32032;&#65292;&#36825;&#20123;&#22240;&#32032;&#19982;&#35821;&#20041;&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#28608;&#27963;&#23548;&#21521;&#65292;&#28041;&#21450;&#32534;&#36753;&#20869;&#37096;&#27169;&#22411;&#28608;&#27963;&#20197;&#23558;&#27169;&#22411;&#24341;&#23548;&#21040;&#27491;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#20174;&#31361;&#21464;&#27979;&#35797;&#20013;&#27762;&#21462;&#28789;&#24863;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#26368;&#23567;&#30340;&#30772;&#22351;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#20174;&#20445;&#30041;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#20013;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#36880;&#28176;&#31867;&#22411;&#21270;&#35821;&#35328;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#20219;&#21153;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#32416;&#27491;&#39640;&#36798;90%&#30340;&#31867;&#22411;&#38169;&#35823;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01903v1 Announce Type: new  Abstract: Contemporary LLMs pretrained on code are capable of succeeding at a wide variety of programming tasks. However, their performance is very sensitive to syntactic features, such as the names of variables and types, the structure of code, and presence of type hints. We contribute an inference-time technique to make CodeLLMs more robust to syntactic distractors that are semantically irrelevant. Our methodology relies on activation steering, which involves editing internal model activations to steer the model towards the correct prediction. We contribute a novel way to construct steering vectors by taking inspiration from mutation testing, which constructs minimal semantics-breaking code edits. In contrast, we construct steering vectors from semantics-preserving code edits. We apply our approach to the task of type prediction for the gradually typed languages Python and TypeScript. This approach corrects up to 90% of type mispredictions. Fina
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;IndoCulture&#39033;&#30446;&#65292;&#26088;&#22312;&#36890;&#36807;&#24403;&#22320;&#20154;&#25163;&#21160;&#25910;&#38598;&#25968;&#25454;&#65292;&#25506;&#32034;&#21360;&#23612;&#21313;&#19968;&#20010;&#30465;&#20221;&#38388;&#22320;&#29702;&#24433;&#21709;&#30340;&#25991;&#21270;&#24120;&#35782;&#25512;&#29702;&#12290;&#35780;&#20272;&#21457;&#29616;&#65292;&#21363;&#20351;&#26159;&#26368;&#22909;&#30340;&#35821;&#35328;&#27169;&#22411;&#20063;&#22312;&#29305;&#23450;&#30465;&#20221;&#19978;&#34920;&#29616;&#26356;&#20934;&#30830;&#65292;&#32780;&#28155;&#21152;&#22320;&#29702;&#20449;&#24687;&#26377;&#21161;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.01854</link><description>&lt;p&gt;
IndoCulture: &#25506;&#32034;&#21360;&#23612;&#21313;&#19968;&#20010;&#30465;&#20221;&#38388;&#22320;&#29702;&#24433;&#21709;&#30340;&#25991;&#21270;&#24120;&#35782;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
IndoCulture: Exploring Geographically-Influenced Cultural Commonsense Reasoning Across Eleven Indonesian Provinces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01854
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;IndoCulture&#39033;&#30446;&#65292;&#26088;&#22312;&#36890;&#36807;&#24403;&#22320;&#20154;&#25163;&#21160;&#25910;&#38598;&#25968;&#25454;&#65292;&#25506;&#32034;&#21360;&#23612;&#21313;&#19968;&#20010;&#30465;&#20221;&#38388;&#22320;&#29702;&#24433;&#21709;&#30340;&#25991;&#21270;&#24120;&#35782;&#25512;&#29702;&#12290;&#35780;&#20272;&#21457;&#29616;&#65292;&#21363;&#20351;&#26159;&#26368;&#22909;&#30340;&#35821;&#35328;&#27169;&#22411;&#20063;&#22312;&#29305;&#23450;&#30465;&#20221;&#19978;&#34920;&#29616;&#26356;&#20934;&#30830;&#65292;&#32780;&#28155;&#21152;&#22320;&#29702;&#20449;&#24687;&#26377;&#21161;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24120;&#35782;&#25512;&#29702;&#21463;&#25991;&#21270;&#21644;&#22320;&#29702;&#22240;&#32032;&#30340;&#26497;&#22823;&#24433;&#21709;&#65292;&#20808;&#21069;&#20851;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#33521;&#35821;&#25991;&#21270;&#19978;&#65292;&#21487;&#33021;&#23548;&#33268;&#19968;&#31181;&#20197;&#33521;&#35821;&#20026;&#20013;&#24515;&#30340;&#20559;&#35265;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;IndoCulture&#65292;&#26088;&#22312;&#29702;&#35299;&#22320;&#29702;&#22240;&#32032;&#23545;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#30340;&#24433;&#21709;&#65292;&#29305;&#21035;&#24378;&#35843;&#20102;&#21313;&#19968;&#20010;&#21360;&#23612;&#30465;&#20221;&#20869;&#25152;&#21457;&#29616;&#30340;&#22810;&#26679;&#25991;&#21270;&#12290;&#19982;&#20808;&#21069;&#20381;&#36182;&#27169;&#26495;&#65288;Yin&#31561;&#65292;2022&#65289;&#21644;&#22312;&#32447;&#25235;&#21462;&#65288;Fung&#31561;&#65292;2024&#65289;&#30340;&#20316;&#21697;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#35810;&#38382;&#24403;&#22320;&#20154;&#25163;&#21160;&#24320;&#21457;&#39044;&#23450;&#20041;&#20027;&#39064;&#30340;&#19978;&#19979;&#25991;&#21644;&#21512;&#29702;&#36873;&#39033;&#26469;&#21019;&#24314;IndoCulture&#12290;&#23545;23&#20010;&#35821;&#35328;&#27169;&#22411;&#30340;&#35780;&#20272;&#25581;&#31034;&#20102;&#20960;&#20010;&#35265;&#35299;&#65306;&#65288;1&#65289;&#21363;&#20351;&#26159;&#26368;&#22909;&#30340;&#24320;&#28304;&#27169;&#22411;&#20063;&#38590;&#20197;&#36798;&#21040;53.2&#65285;&#30340;&#20934;&#30830;&#24615;&#65292;&#65288;2&#65289;&#27169;&#22411;&#36890;&#24120;&#20026;&#29305;&#23450;&#30465;&#20221;&#65288;&#22914;&#24052;&#21400;&#23707;&#21644;&#35199;&#29226;&#21703;&#65289;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#65288;3&#65289;&#21253;&#21547;&#22320;&#29702;&#20449;&#24687;&#21487;&#26174;&#30528;&#25913;&#21892;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01854v1 Announce Type: new  Abstract: Although commonsense reasoning is greatly shaped by cultural and geographical factors, previous studies on language models have predominantly centered on English cultures, potentially resulting in an Anglocentric bias. In this paper, we introduce IndoCulture, aimed at understanding the influence of geographical factors on language model reasoning ability, with a specific emphasis on the diverse cultures found within eleven Indonesian provinces. In contrast to prior works that relied on templates (Yin et al., 2022) and online scrapping (Fung et al., 2024), we created IndoCulture by asking local people to manually develop the context and plausible options based on predefined topics. Evaluations of 23 language models reveal several insights: (1) even the best open-source model struggles with an accuracy of 53.2%, (2) models often provide more accurate predictions for specific provinces, such as Bali and West Java, and (3) the inclusion of l
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;Shapley&#20540;&#26041;&#27861;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#25581;&#31034;&#20102;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#20915;&#31574;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#25552;&#31034;&#32452;&#20214;&#30340;&#24433;&#21709;</title><link>https://arxiv.org/abs/2404.01332</link><description>&lt;p&gt;
&#31561;&#31561;&#65292;&#36825;&#37117;&#26159;&#20196;&#29260;&#22122;&#38899;&#65311;&#19968;&#30452;&#23601;&#26159;&#21527;&#65306;&#21033;&#29992; Shapley &#20540;&#35299;&#37322; LLM &#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01332
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;Shapley&#20540;&#26041;&#27861;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#25581;&#31034;&#20102;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#20915;&#31574;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#25552;&#31034;&#32452;&#20214;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#20026;&#27169;&#25311;&#20154;&#31867;&#34892;&#20026;&#21644;&#35748;&#30693;&#36807;&#31243;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#65292;&#28508;&#22312;&#24212;&#29992;&#21253;&#25324;&#24066;&#22330;&#30740;&#31350;&#21644;&#28040;&#36153;&#32773;&#34892;&#20026;&#20998;&#26512;&#31561;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLMs&#30340;&#26174;&#33879;&#24046;&#24322;&#26263;&#31034;&#20102;&#19981;&#21516;&#30340;&#22522;&#30784;&#36807;&#31243;&#22312;&#36215;&#20316;&#29992;&#65292;&#20197;&#21450;LLMs&#23545;&#25552;&#31034;&#21464;&#21270;&#30340;&#25935;&#24863;&#24615;&#65292;&#21033;&#29992;LLMs&#20316;&#20026;&#20154;&#31867;&#20027;&#20307;&#30340;&#26367;&#20195;&#20173;&#28982;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#20013;Shapley&#20540;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#37322;LLM&#34892;&#20026;&#65292;&#24182;&#37327;&#21270;&#27599;&#20010;&#25552;&#31034;&#32452;&#20214;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#30456;&#23545;&#36129;&#29486;&#12290;&#36890;&#36807;&#20004;&#20010;&#24212;&#29992;--&#19968;&#20010;&#31163;&#25955;&#36873;&#25321;&#23454;&#39564;&#21644;&#19968;&#20010;&#35748;&#30693;&#20559;&#35265;&#35843;&#26597;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Shapley&#20540;&#26041;&#27861;&#22914;&#20309;&#25581;&#31034;&#25105;&#20204;&#25152;&#35859;&#30340;&#8220;&#20196;&#29260;&#22122;&#38899;&#8221;&#25928;&#24212;&#65292;&#21363;LLM&#20915;&#31574;&#21463;&#21040;&#30340;&#24433;&#21709;&#20005;&#37325;&#20559;&#21521;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01332v1 Announce Type: cross  Abstract: The emergence of large language models (LLMs) has opened up exciting possibilities for simulating human behavior and cognitive processes, with potential applications in various domains, including marketing research and consumer behavior analysis. However, the validity of utilizing LLMs as stand-ins for human subjects remains uncertain due to glaring divergences that suggest fundamentally different underlying processes at play and the sensitivity of LLM responses to prompt variations. This paper presents a novel approach based on Shapley values from cooperative game theory to interpret LLM behavior and quantify the relative contribution of each prompt component to the model's output. Through two applications-a discrete choice experiment and an investigation of cognitive biases-we demonstrate how the Shapley value method can uncover what we term "token noise" effects, a phenomenon where LLM decisions are disproportionately influenced by 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#65292;&#23454;&#39564;&#32467;&#26524;&#26377;&#21161;&#20110;&#25552;&#20986;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;</title><link>https://arxiv.org/abs/2403.11793</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65306;&#23545;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#30340;&#28145;&#20837;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11793
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#65292;&#23454;&#39564;&#32467;&#26524;&#26377;&#21161;&#20110;&#25552;&#20986;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25512;&#29702;&#33021;&#21147;&#30340;&#29616;&#26377;&#26041;&#27861;&#20197;&#32467;&#26524;&#20026;&#20013;&#24515;&#65292;&#20351;&#24471;&#35780;&#20272;&#25512;&#29702;&#36807;&#31243;&#21464;&#24471;&#22256;&#38590;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#20197;&#36807;&#31243;&#20026;&#20013;&#24515;&#30340;&#26041;&#24335;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#12290;ARC&#35201;&#27714;&#35299;&#20915;&#38382;&#39064;&#26102;&#20855;&#26377;&#20005;&#35880;&#30340;&#36923;&#36753;&#32467;&#26500;&#65292;&#36825;&#20351;&#24471;&#23427;&#25104;&#20026;&#19968;&#20010;&#33021;&#22815;&#20419;&#36827;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#19982;&#20154;&#31867;&#36827;&#34892;&#27604;&#36739;&#30340;&#22522;&#20934;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#65292;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#31361;&#26174;&#20102;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11793v1 Announce Type: cross  Abstract: The existing methods for evaluating the inference abilities of Large Language Models (LLMs) have been results-centric, making it difficult to assess the inference process. We introduce a new approach using the Abstract and Reasoning Corpus (ARC) dataset to evaluate the inference and contextual understanding abilities of large language models in a process-centric manner. ARC demands rigorous logical structures for problem-solving, making it a benchmark that facilitates the comparison of model inference abilities with humans. Experimental results confirm that while large language models possess weak inference abilities, they still lag in terms of logical coherence, compositionality, and productivity. Our experiments highlight the reasoning capabilities of LLMs, proposing development paths for achieving human-level reasoning.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#65288;PERL&#65289;&#65292;&#33021;&#22815;&#22312;&#19982;&#20256;&#32479;RLHF&#35774;&#32622;&#30456;&#24403;&#30340;&#24615;&#33021;&#19979;&#65292;&#23454;&#29616;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#26356;&#23569;&#30340;&#20869;&#23384;&#21344;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.10704</link><description>&lt;p&gt;
PERL: &#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#23454;&#29616;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PERL: Parameter Efficient Reinforcement Learning from Human Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10704
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#65288;PERL&#65289;&#65292;&#33021;&#22815;&#22312;&#19982;&#20256;&#32479;RLHF&#35774;&#32622;&#30456;&#24403;&#30340;&#24615;&#33021;&#19979;&#65292;&#23454;&#29616;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#26356;&#23569;&#30340;&#20869;&#23384;&#21344;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#23558;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;RLHF&#35757;&#32451;&#27169;&#22411;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#19988;&#25972;&#20010;&#36807;&#31243;&#22797;&#26434;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;RLHF&#65292;&#20854;&#20013;&#22522;&#30784;&#27169;&#22411;&#20351;&#29992;&#32993;&#31561;&#20154;&#25552;&#20986;&#30340;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#21442;&#25968;&#39640;&#25928;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#8220;&#21442;&#25968;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#8221;&#65288;PERL&#65289;&#30340;&#35774;&#32622;&#65292;&#22312;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;LoRA&#36827;&#34892;&#22870;&#21169;&#27169;&#22411;&#35757;&#32451;&#21644;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#23558;PERL&#19982;&#20256;&#32479;&#30340;&#24494;&#35843;&#65288;&#20840;&#35843;&#65289;&#22312;&#21253;&#25324;2&#20010;&#26032;&#25968;&#25454;&#38598;&#22312;&#20869;&#30340;7&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#22870;&#21169;&#24314;&#27169;&#21644;&#24378;&#21270;&#23398;&#20064;&#26041;&#38754;&#30340;&#21508;&#31181;&#37197;&#32622;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;PERL&#30340;&#24615;&#33021;&#19982;&#20256;&#32479;&#30340;RLHF&#35774;&#32622;&#30456;&#24403;&#65292;&#21516;&#26102;&#35757;&#32451;&#36895;&#24230;&#26356;&#24555;&#65292;&#20869;&#23384;&#21344;&#29992;&#26356;&#23569;&#12290;&#36825;&#20351;&#24471;RLHF&#20855;&#26377;&#24456;&#39640;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10704v1 Announce Type: cross  Abstract: Reinforcement Learning from Human Feedback (RLHF) has proven to be a strong method to align Pretrained Large Language Models (LLMs) with human preferences. But training models with RLHF is computationally expensive, and an overall complex process. In this work, we study RLHF where the underlying models are trained using the parameter efficient method of Low-Rank Adaptation (LoRA) introduced by Hu et al. [2021]. We investigate the setup of "Parameter Efficient Reinforcement Learning" (PERL), in which we perform reward model training and reinforcement learning using LoRA. We compare PERL to conventional fine-tuning (full-tuning) across various configurations for 7 benchmarks, including 2 novel datasets, of reward modeling and reinforcement learning. We find that PERL performs on par with the conventional RLHF setting, while training faster, and with less memory. This enables the high performance of RLHF, while reducing the computational 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#30495;&#30456;&#24863;&#30693;&#30340;&#19978;&#19979;&#25991;&#36873;&#25321;&#65288;TACS&#65289;&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#36755;&#20837;&#19978;&#19979;&#25991;&#36827;&#34892;&#30495;&#30456;&#26816;&#27979;&#24182;&#26500;&#24314;&#30456;&#24212;&#30340;&#27880;&#24847;&#21147;&#33945;&#29256;&#26469;&#32531;&#35299;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#19981;&#30495;&#23454;&#19978;&#19979;&#25991;&#35823;&#23548;&#20135;&#29983;&#24187;&#35273;</title><link>https://arxiv.org/abs/2403.07556</link><description>&lt;p&gt;
&#30495;&#30456;&#24863;&#30693;&#30340;&#19978;&#19979;&#25991;&#36873;&#25321;&#65306;&#32531;&#35299;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#19981;&#30495;&#23454;&#19978;&#19979;&#25991;&#35823;&#23548;&#20135;&#29983;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Truth-Aware Context Selection: Mitigating the Hallucinations of Large Language Models Being Misled by Untruthful Contexts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07556
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#30495;&#30456;&#24863;&#30693;&#30340;&#19978;&#19979;&#25991;&#36873;&#25321;&#65288;TACS&#65289;&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#36755;&#20837;&#19978;&#19979;&#25991;&#36827;&#34892;&#30495;&#30456;&#26816;&#27979;&#24182;&#26500;&#24314;&#30456;&#24212;&#30340;&#27880;&#24847;&#21147;&#33945;&#29256;&#26469;&#32531;&#35299;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#19981;&#30495;&#23454;&#19978;&#19979;&#25991;&#35823;&#23548;&#20135;&#29983;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25991;&#26412;&#29983;&#25104;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#24456;&#23481;&#26131;&#34987;&#29992;&#25143;&#25110;&#30693;&#35782;&#35770;&#35777;&#24037;&#20855;&#25552;&#20379;&#30340;&#19981;&#30495;&#23454;&#19978;&#19979;&#25991;&#35823;&#23548;&#65292;&#20174;&#32780;&#20135;&#29983;&#24187;&#35273;&#12290;&#20026;&#20102;&#20943;&#36731;LLMs&#34987;&#19981;&#30495;&#23454;&#20449;&#24687;&#35823;&#23548;&#24182;&#21033;&#29992;&#30693;&#35782;&#35770;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#30495;&#30456;&#24863;&#30693;&#30340;&#19978;&#19979;&#25991;&#36873;&#25321;&#65288;TACS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#36755;&#20837;&#20013;&#23631;&#34109;&#19981;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#12290;TACS&#39318;&#20808;&#23545;&#36755;&#20837;&#19978;&#19979;&#25991;&#36827;&#34892;&#30495;&#30456;&#26816;&#27979;&#65292;&#21033;&#29992;LLM&#20869;&#30340;&#21442;&#25968;&#21270;&#30693;&#35782;&#12290;&#38543;&#21518;&#65292;&#26681;&#25454;&#27599;&#20010;&#20301;&#32622;&#30340;&#30495;&#23454;&#24615;&#26500;&#24314;&#30456;&#24212;&#30340;&#27880;&#24847;&#21147;&#33945;&#29256;&#65292;&#36873;&#25321;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#24182;&#20002;&#24323;&#19981;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#25200;&#21160;&#36866;&#24212;&#29575;&#65292;&#20197;&#36827;&#19968;&#27493;&#30740;&#31350;LLMs&#25509;&#21463;&#30495;&#23454;&#20449;&#24687;&#21644;&#25269;&#21046;&#19981;&#30495;&#23454;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07556v1 Announce Type: new  Abstract: Although large language models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by the untruthful context provided by users or knowledge argumentation tools, thereby producing hallucinations. To alleviate the LLMs from being misled by untruthful information and take advantage of knowledge argumentation, we propose Truth-Aware Context Selection (TACS), a lightweight method to shield untruthful context from the inputs. TACS begins by performing truth detection on the input context, leveraging the parameterized knowledge within the LLM. Subsequently, it constructs a corresponding attention mask based on the truthfulness of each position, selecting the truthful context and discarding the untruthful context. Additionally, we introduce a new evaluation metric, Disturbance Adaption Rate, to further study the LLMs' ability to accept truthful information and resist untruthful information. Experimental resul
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#21450;&#20854;&#35282;&#33394;&#65292;&#25351;&#20986;&#20102;&#26410;&#24320;&#21457;&#39046;&#22495;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.18659</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#28216;&#25103;&#65306;&#35843;&#30740;&#19982;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
Large Language Models and Games: A Survey and Roadmap
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18659
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#21450;&#20854;&#35282;&#33394;&#65292;&#25351;&#20986;&#20102;&#26410;&#24320;&#21457;&#39046;&#22495;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#30740;&#31350;&#24613;&#21095;&#22686;&#21152;&#65292;&#24182;&#20276;&#38543;&#30528;&#20844;&#20247;&#23545;&#35813;&#20027;&#39064;&#30340;&#21442;&#19982;&#12290;&#23613;&#31649;&#36215;&#21021;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#19968;&#23567;&#37096;&#20998;&#65292;LLMs&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#21644;&#39046;&#22495;&#20013;&#23637;&#29616;&#20986;&#26174;&#33879;&#28508;&#21147;&#65292;&#21253;&#25324;&#28216;&#25103;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;LLMs&#22312;&#28216;&#25103;&#20013;&#21450;&#20026;&#28216;&#25103;&#25552;&#20379;&#25903;&#25345;&#30340;&#21508;&#31181;&#24212;&#29992;&#30340;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#65292;&#24182;&#26126;&#30830;&#20102;LLMs&#22312;&#28216;&#25103;&#20013;&#21487;&#20197;&#25198;&#28436;&#30340;&#19981;&#21516;&#35282;&#33394;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23578;&#26410;&#24320;&#21457;&#30340;&#39046;&#22495;&#21644;LLMs&#22312;&#28216;&#25103;&#20013;&#26410;&#26469;&#24212;&#29992;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#65292;&#20197;&#21450;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;LLMs&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;&#20316;&#20026;LLMs&#21644;&#28216;&#25103;&#20132;&#21449;&#39046;&#22495;&#30340;&#31532;&#19968;&#20221;&#32508;&#21512;&#35843;&#26597;&#21644;&#36335;&#32447;&#22270;&#65292;&#25105;&#20204;&#24076;&#26395;&#26412;&#25991;&#33021;&#22815;&#25104;&#20026;&#36825;&#19968;&#28608;&#21160;&#20154;&#24515;&#30340;&#26032;&#39046;&#22495;&#30340;&#24320;&#21019;&#24615;&#30740;&#31350;&#21644;&#21019;&#26032;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18659v1 Announce Type: cross  Abstract: Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#22914;&#20309;&#35753;&#35821;&#35328;&#27169;&#22411;&#38544;&#24335;&#23398;&#20064;&#33258;&#25105;&#25913;&#36827;&#65292;&#24182;&#20943;&#23569;&#23545;&#20154;&#31867;&#26631;&#27880;&#30340;&#20381;&#36182;&#12290;</title><link>http://arxiv.org/abs/2310.00898</link><description>&lt;p&gt;
&#35753;&#35821;&#35328;&#27169;&#22411;&#20174;&#25968;&#25454;&#20013;&#38544;&#24335;&#23398;&#20064;&#33258;&#25105;&#25913;&#36827;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Enable Language Models to Implicitly Learn Self-Improvement From Data. (arXiv:2310.00898v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00898
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#22914;&#20309;&#35753;&#35821;&#35328;&#27169;&#22411;&#38544;&#24335;&#23398;&#20064;&#33258;&#25105;&#25913;&#36827;&#65292;&#24182;&#20943;&#23569;&#23545;&#20154;&#31867;&#26631;&#27880;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24320;&#25918;&#24335;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20219;&#21153;&#30340;&#26412;&#36136;&#20915;&#23450;&#20102;&#27169;&#22411;&#30340;&#22238;&#31572;&#36136;&#37327;&#22987;&#32456;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#28857;&#38598;&#20013;&#22312;&#20351;&#35821;&#35328;&#27169;&#22411;&#33258;&#25105;&#25913;&#36827;&#20854;&#22238;&#31572;&#36136;&#37327;&#19978;&#65292;&#20174;&#32780;&#20943;&#23569;&#23545;&#24191;&#27867;&#30340;&#20154;&#24037;&#26631;&#27880;&#24037;&#20316;&#26469;&#25910;&#38598;&#22810;&#26679;&#21270;&#21644;&#39640;&#36136;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#22240;&#20854;&#26377;&#25928;&#24615;&#12289;&#39640;&#25928;&#24615;&#21644;&#20415;&#21033;&#24615;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#26126;&#30830;&#21644;&#35814;&#23613;&#30340;&#25351;&#31034;&#12290;&#23545;&#20110;&#25163;&#21160;&#25512;&#23548;&#21644;&#25552;&#20379;&#25152;&#26377;&#24517;&#35201;&#30340;&#25351;&#31034;&#26469;&#23454;&#29616;&#29616;&#23454;&#19990;&#30028;&#22797;&#26434;&#30446;&#26631;&#30340;&#25913;&#36827;&#65288;&#20363;&#22914;&#65292;&#26356;&#26377;&#24110;&#21161;&#24615;&#21644;&#26356;&#23569;&#26377;&#23475;&#24615;&#65289;&#65292;&#36825;&#26159;&#26114;&#36149;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated remarkable capabilities in open-ended text generation tasks. However, the inherent open-ended nature of these tasks implies that there is always room for improvement in the quality of model responses. To address this challenge, various approaches have been proposed to enhance the performance of LLMs. There has been a growing focus on enabling LLMs to self-improve their response quality, thereby reducing the reliance on extensive human annotation efforts for collecting diverse and high-quality training data. Recently, prompting-based methods have been widely explored among self-improvement methods owing to their effectiveness, efficiency, and convenience. However, those methods usually require explicitly and thoroughly written rubrics as inputs to LLMs. It is expensive and challenging to manually derive and provide all necessary rubrics with a real-world complex goal for improvement (e.g., being more helpful and less harmful). To this end, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;RRWKV&#26550;&#26500;&#65292;&#23427;&#22312;&#20445;&#25345;&#35760;&#24518;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#21152;&#20837;&#22238;&#39038;&#33021;&#21147;&#26377;&#25928;&#22320;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2306.05176</link><description>&lt;p&gt;
RRWKV&#65306;&#22312;RWKV&#20013;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
RRWKV: Capturing Long-range Dependencies in RWKV. (arXiv:2306.05176v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;RRWKV&#26550;&#26500;&#65292;&#23427;&#22312;&#20445;&#25345;&#35760;&#24518;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#21152;&#20837;&#22238;&#39038;&#33021;&#21147;&#26377;&#25928;&#22320;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;Transformer&#24778;&#20154;&#30340;&#28857;&#31215;&#27880;&#24847;&#21147;&#65292;&#23427;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#30340;&#20027;&#35201;&#26550;&#26500;&#12290;&#26368;&#36817;&#65292;Receptance Weighted Key Value&#65288;RWKV&#65289;&#26550;&#26500;&#36981;&#24490;&#38750;Transformer&#26550;&#26500;&#65292;&#28040;&#38500;&#20102;&#28857;&#31215;&#27880;&#24847;&#21147;&#30340;&#32570;&#28857;&#65292;&#20854;&#20013;&#23384;&#20648;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#21576;&#20108;&#27425;&#25193;&#23637;&#12290;&#23613;&#31649;RWKV&#21033;&#29992;&#20102;&#32447;&#24615;&#24352;&#37327;&#31215;&#27880;&#24847;&#26426;&#21046;&#24182;&#36890;&#36807;&#37096;&#32626;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#23454;&#29616;&#20102;&#24182;&#34892;&#35745;&#31639;&#65292;&#20294;&#19982;&#26631;&#20934;Transformer&#20013;&#30452;&#25509;&#20132;&#20114;&#33719;&#24471;&#30340;&#23436;&#25972;&#20449;&#24687;&#30456;&#27604;&#65292;&#23427;&#26080;&#27861;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#65292;&#22240;&#20026;&#20854;&#21463;&#38480;&#20110;&#21521;&#21518;&#26597;&#30475;&#20808;&#21069;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#36890;&#36807;&#23558;&#22238;&#39038;&#33021;&#21147;&#32435;&#20837;RWKV&#20013;&#26469;&#35774;&#35745;Retrospected Receptance Weighted Key Value&#65288;RRWKV&#65289;&#26550;&#26500;&#65292;&#20197;&#26377;&#25928;&#22320;&#21560;&#25910;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#35760;&#24518;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Owing to the impressive dot-product attention, the Transformers have been the dominant architectures in various natural language processing (NLP) tasks. Recently, the Receptance Weighted Key Value (RWKV) architecture follows a non-transformer architecture to eliminate the drawbacks of dot-product attention, where memory and computational complexity exhibits quadratic scaling with sequence length. Although RWKV has exploited a linearly tensor-product attention mechanism and achieved parallelized computations by deploying the time-sequential mode, it fails to capture long-range dependencies because of its limitation on looking back at previous information, compared with full information obtained by direct interactions in the standard transformer. Therefore, the paper devises the Retrospected Receptance Weighted Key Value (RRWKV) architecture via incorporating the retrospecting ability into the RWKV to effectively absorb information, which maintains memory and computational efficiency as 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;YouTube&#35780;&#35770;&#20013;&#30340;&#25705;&#27931;&#21733;&#26041;&#35328;&#36827;&#34892;&#24773;&#24863;&#20998;&#31867;&#65292;&#37319;&#29992;&#22810;&#31181;&#25991;&#26412;&#39044;&#22788;&#29702;&#21644;&#25968;&#25454;&#34920;&#31034;&#25216;&#26415;&#23545;&#25991;&#26412;&#36827;&#34892;&#20998;&#26512;&#65292;&#30740;&#31350;&#35813;&#26041;&#35328;&#30340;&#24847;&#35265;&#21644;&#24773;&#24863;&#34920;&#36798;&#12290;</title><link>http://arxiv.org/abs/2303.15987</link><description>&lt;p&gt;
&#20851;&#20110;&#25705;&#27931;&#21733;&#26041;&#35328;&#25991;&#26412;&#24773;&#24863;&#20998;&#31867;&#30340;&#23454;&#39564;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Experimental Study on Sentiment Classification of Moroccan dialect texts in the web. (arXiv:2303.15987v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;YouTube&#35780;&#35770;&#20013;&#30340;&#25705;&#27931;&#21733;&#26041;&#35328;&#36827;&#34892;&#24773;&#24863;&#20998;&#31867;&#65292;&#37319;&#29992;&#22810;&#31181;&#25991;&#26412;&#39044;&#22788;&#29702;&#21644;&#25968;&#25454;&#34920;&#31034;&#25216;&#26415;&#23545;&#25991;&#26412;&#36827;&#34892;&#20998;&#26512;&#65292;&#30740;&#31350;&#35813;&#26041;&#35328;&#30340;&#24847;&#35265;&#21644;&#24773;&#24863;&#34920;&#36798;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#32593;&#31449;&#30340;&#36805;&#36895;&#22686;&#38271;&#65292;&#33258;&#21160;&#33719;&#21462;&#29992;&#25143;&#21453;&#39304;&#25104;&#20026;&#35780;&#20272;&#20854;&#22312;&#32447;&#36235;&#21183;&#21644;&#34892;&#20026;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#23613;&#31649;&#20449;&#24687;&#22823;&#37327;&#21487;&#29992;&#65292;&#38463;&#25289;&#20271;&#20351;&#29992;&#32773;&#25968;&#37327;&#22686;&#21152;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#22788;&#29702;&#38463;&#25289;&#20271;&#26041;&#35328;&#12290;&#26412;&#25991;&#26088;&#22312;&#20934;&#30830;&#30740;&#31350;&#22312;YouTube&#35780;&#35770;&#20013;&#34920;&#36798;&#30340;&#30495;&#23454;&#25705;&#27931;&#21733;&#26041;&#35328;&#25991;&#26412;&#30340;&#35266;&#28857;&#21644;&#24773;&#24863;&#65292;&#20351;&#29992;&#19968;&#20123;&#20247;&#25152;&#21608;&#30693;&#19988;&#24120;&#29992;&#30340;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#12290;&#36890;&#36807;&#37319;&#29992;&#35768;&#22810;&#25991;&#26412;&#39044;&#22788;&#29702;&#21644;&#25968;&#25454;&#34920;&#31034;&#25216;&#26415;&#65292;&#25105;&#20204;&#26088;&#22312;&#27604;&#36739;&#25105;&#20204;&#20351;&#29992;&#26368;&#24120;&#29992;&#30340;&#30417;&#30563;&#20998;&#31867;&#22120;&#36827;&#34892;&#20998;&#31867;&#32467;&#26524;&#65306;K&#26368;&#36817;&#37051;&#65288;KNN&#65289;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#12289;&#26420;&#32032;&#36125;&#21494;&#26031;&#65288;NB&#65289;&#21644;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#20998;&#31867;&#22120;&#65292;&#36825;&#20123;&#37117;&#26159;&#22522;&#20110;&#25105;&#20204;&#25910;&#38598;&#21644;&#25163;&#21160;&#27880;&#37322;&#30340;YouTube&#25705;&#27931;&#21733;&#26041;&#35328;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rapid growth of the use of social media websites, obtaining the users' feedback automatically became a crucial task to evaluate their tendencies and behaviors online. Despite this great availability of information, and the increasing number of Arabic users only few research has managed to treat Arabic dialects. The purpose of this paper is to study the opinion and emotion expressed in real Moroccan texts precisely in the YouTube comments using some well-known and commonly used methods for sentiment analysis. In this paper, we present our work of Moroccan dialect comments classification using Machine Learning (ML) models and based on our collected and manually annotated YouTube Moroccan dialect dataset. By employing many text preprocessing and data representation techniques we aim to compare our classification results utilizing the most commonly used supervised classifiers: k-nearest neighbors (KNN), Support Vector Machine (SVM), Naive Bayes (NB), and deep learning (DL) classif
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25972;&#20010;&#23186;&#20307;&#30340;&#32454;&#31890;&#24230;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#25163;&#21160;&#21046;&#20316;&#30340;&#8220;FactNews&#8221;&#25968;&#25454;&#24211;&#19978;&#65292;&#36890;&#36807; fine-tuning BERT &#27169;&#22411;&#39044;&#27979;&#26032;&#38395;&#25253;&#36947;&#30340;&#21477;&#23376;&#32423;&#21035;&#20107;&#23454;&#24615;&#21644;&#23186;&#20307;&#20542;&#21521;&#12290;&#27492;&#26041;&#27861;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;&#20854;&#20182;&#35821;&#35328;&#12290;</title><link>http://arxiv.org/abs/2301.11850</link><description>&lt;p&gt;
&#39044;&#27979;&#26032;&#38395;&#20107;&#23454;&#24615;&#21644;&#23186;&#20307;&#20542;&#21521;&#30340;&#21477;&#23376;&#32423;&#21035;&#21487;&#38752;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Predicting Sentence-Level Factuality of News and Bias of Media Outlets. (arXiv:2301.11850v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11850
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25972;&#20010;&#23186;&#20307;&#30340;&#32454;&#31890;&#24230;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#25163;&#21160;&#21046;&#20316;&#30340;&#8220;FactNews&#8221;&#25968;&#25454;&#24211;&#19978;&#65292;&#36890;&#36807; fine-tuning BERT &#27169;&#22411;&#39044;&#27979;&#26032;&#38395;&#25253;&#36947;&#30340;&#21477;&#23376;&#32423;&#21035;&#20107;&#23454;&#24615;&#21644;&#23186;&#20307;&#20542;&#21521;&#12290;&#27492;&#26041;&#27861;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;&#20854;&#20182;&#35821;&#35328;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#26032;&#38395;&#25253;&#36947;&#30340;&#20107;&#23454;&#24615;&#21644;&#23186;&#20307;&#20542;&#21521;&#23545;&#20110;&#33258;&#21160;&#21270;&#30340;&#26032;&#38395;&#20449;&#35465;&#21644;&#20107;&#23454;&#26680;&#26597;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#25972;&#20010;&#23186;&#20307;&#36827;&#34892;&#32454;&#31890;&#24230;&#21487;&#38752;&#24615;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#39044;&#27979;&#26032;&#38395;&#25253;&#36947;&#30340;&#21477;&#23376;&#32423;&#21035;&#20107;&#23454;&#24615;&#21644;&#23186;&#20307;&#20542;&#21521;&#65292;&#36825;&#21487;&#20197;&#26356;&#31934;&#30830;&#22320;&#35299;&#37322;&#25972;&#20010; source &#30340;&#21487;&#38752;&#31243;&#24230;&#12290;&#25105;&#20204;&#39318;&#20808;&#25163;&#21160;&#21046;&#20316;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#21477;&#23376;&#32423;&#21035;&#25968;&#25454;&#24211;&#65292;&#8220;FactNews&#8221;&#65292;&#30001; 6191 &#20010;&#19987;&#23478;&#27880;&#37322;&#30340;&#21477;&#23376;&#32452;&#25104;&#65292;&#27880;&#37322;&#20381;&#25454;&#26469;&#33258; AllSides &#30340;&#20107;&#23454;&#24615;&#21644;&#23186;&#20307;&#20542;&#21521;&#23450;&#20041;&#12290;&#26368;&#21518;&#65292;&#30001;&#20110;&#24052;&#35199;&#23384;&#22312;&#20005;&#37325;&#30340;&#34394;&#20551;&#26032;&#38395;&#21644;&#25919;&#27835;&#26497;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29992;&#20110;&#33889;&#33796;&#29273;&#35821;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#32447;&#27169;&#22411;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#20854;&#20182;&#35821;&#35328;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting the factuality of news reporting and bias of media outlets is surely relevant for automated news credibility and fact-checking. While prior work has focused on the veracity of news, we propose a fine-grained reliability analysis of the entire media. Specifically, we study the prediction of sentence-level factuality of news reporting and bias of media outlets, which may explain more accurately the overall reliability of the entire source. We first manually produced a large sentence-level dataset, titled "FactNews", composed of 6,191 sentences expertly annotated according to factuality and media bias definitions from AllSides. As a result, baseline models for sentence-level factuality prediction were presented by fine-tuning BERT. Finally, due to the severity of fake news and political polarization in Brazil, both dataset and baseline were proposed for Portuguese. However, our approach may be applied to any other language.
&lt;/p&gt;</description></item></channel></rss>