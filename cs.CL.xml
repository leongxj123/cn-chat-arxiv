<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20316;&#32773;&#35782;&#21035;&#26041;&#38754;&#30340;&#28508;&#21147;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#65292;&#26412;&#25991;&#36890;&#36807;&#20840;&#38754;&#35780;&#20272;&#35299;&#20915;&#20102;LLMs&#22312;&#20316;&#32773;&#39564;&#35777;&#21644;&#24402;&#23646;&#20013;&#30340;&#19977;&#20010;&#20851;&#38190;&#30740;&#31350;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.08213</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#35782;&#21035;&#20316;&#32773;&#36523;&#20221;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Identify Authorship?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08213
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20316;&#32773;&#35782;&#21035;&#26041;&#38754;&#30340;&#28508;&#21147;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#65292;&#26412;&#25991;&#36890;&#36807;&#20840;&#38754;&#35780;&#20272;&#35299;&#20915;&#20102;LLMs&#22312;&#20316;&#32773;&#39564;&#35777;&#21644;&#24402;&#23646;&#20013;&#30340;&#19977;&#20010;&#20851;&#38190;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#20934;&#35782;&#21035;&#20316;&#32773;&#36523;&#20221;&#23545;&#39564;&#35777;&#20869;&#23481;&#30495;&#23454;&#24615;&#21644;&#20943;&#23569;&#35823;&#23548;&#20449;&#24687;&#33267;&#20851;&#37325;&#35201;&#12290; &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#25512;&#29702;&#21644;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#20316;&#32773;&#20998;&#26512;&#65288;&#21253;&#25324;&#20316;&#32773;&#39564;&#35777;&#21644;&#24402;&#23646;&#65289;&#26041;&#38754;&#30340;&#28508;&#21147;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290; &#26412;&#25991;&#23545;LLMs&#22312;&#36825;&#20123;&#20851;&#38190;&#20219;&#21153;&#20013;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#12290; &#20256;&#32479;&#30740;&#31350;&#20381;&#36182;&#20110;&#25163;&#24037;&#21046;&#20316;&#30340;&#25991;&#20307;&#29305;&#24449;&#65292;&#32780;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25991;&#26412;&#23884;&#20837;&#12290; &#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#22312;&#26631;&#35760;&#25968;&#25454;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#28982;&#32780;&#22312;&#36328;&#39046;&#22495;&#24212;&#29992;&#20013;&#24448;&#24448;&#34920;&#29616;&#20986;&#24615;&#33021;&#19979;&#38477;&#65292;&#24182;&#25552;&#20379;&#26377;&#38480;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290; &#26412;&#25991;&#26088;&#22312;&#22238;&#31572;&#19977;&#20010;&#30740;&#31350;&#38382;&#39064;&#65306;&#65288;1&#65289;LLMs&#33021;&#21542;&#26377;&#25928;&#25191;&#34892;&#38646;&#26679;&#26412;&#12289;&#31471;&#21040;&#31471;&#30340;&#20316;&#32773;&#39564;&#35777;&#65311;&#65288;2&#65289;LLMs&#33021;&#21542;&#20934;&#30830;&#36827;&#34892;&#20316;&#32773;&#36523;&#20221;&#24402;&#23646;&#65311;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08213v1 Announce Type: new  Abstract: The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis, encompassing authorship verification and attribution, remains underexplored. This paper conducts a comprehensive evaluation of LLMs in these critical tasks. Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models. These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability. This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively? (2) Are LLMs capable of accurately attributing
&lt;/p&gt;</description></item><item><title>&#21457;&#24067;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#39044;&#35757;&#32451;&#22312;40&#20159;&#20010;C&#28304;&#20195;&#30721;&#21644;&#27719;&#32534;&#20195;&#30721;&#26631;&#35760;&#19978;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.05286</link><description>&lt;p&gt;
LLM4Decompile&#65306;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20108;&#36827;&#21046;&#20195;&#30721;&#36827;&#34892;&#21453;&#32534;&#35793;
&lt;/p&gt;
&lt;p&gt;
LLM4Decompile: Decompiling Binary Code with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05286
&lt;/p&gt;
&lt;p&gt;
&#21457;&#24067;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#39044;&#35757;&#32451;&#22312;40&#20159;&#20010;C&#28304;&#20195;&#30721;&#21644;&#27719;&#32534;&#20195;&#30721;&#26631;&#35760;&#19978;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#32534;&#35793;&#26088;&#22312;&#23558;&#32534;&#35793;&#20195;&#30721;&#24674;&#22797;&#20026;&#21487;&#35835;&#24615;&#24378;&#30340;&#28304;&#20195;&#30721;&#65292;&#20294;&#22312;&#21517;&#31216;&#21644;&#32467;&#26500;&#31561;&#32454;&#33410;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32534;&#31243;&#20219;&#21153;&#20013;&#26174;&#31034;&#20986;&#28508;&#21147;&#65292;&#28608;&#21457;&#20102;&#23427;&#20204;&#22312;&#21453;&#32534;&#35793;&#20013;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#26080;&#29992;&#20110;&#21453;&#32534;&#35793;&#30340;&#24320;&#28304;LLM&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#21453;&#32534;&#35793;&#35780;&#20272;&#31995;&#32479;&#20027;&#35201;&#32771;&#34385;&#26631;&#35760;&#32423;&#20934;&#30830;&#24615;&#65292;&#32780;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#30053;&#20102;&#20195;&#30721;&#30340;&#21487;&#25191;&#34892;&#24615;&#65292;&#36825;&#26159;&#20219;&#20309;&#31243;&#24207;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;&#39318;&#25209;&#24320;&#25918;&#35775;&#38382;&#30340;&#21453;&#32534;&#35793;LLM&#65292;&#33539;&#22260;&#20174;10&#20159;&#21040;330&#20159;&#65292;&#39044;&#20808;&#35757;&#32451;&#20102;40&#20159;&#20010;&#20196;&#29260;&#30340;C&#28304;&#20195;&#30721;&#21644;&#30456;&#24212;&#30340;&#27719;&#32534;&#20195;&#30721;&#12290;&#36825;&#20123;&#24320;&#28304;LLM&#21487;&#20197;&#20316;&#20026;&#35813;&#39046;&#22495;&#36827;&#19968;&#27493;&#21457;&#23637;&#30340;&#22522;&#32447;&#12290;&#20026;&#20102;&#30830;&#20445;&#23454;&#38469;&#31243;&#24207;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Decompile-Eval&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#32771;&#34385;&#37325;&#26032;&#32534;&#35793;&#24615;&#21644;&#37325;&#26032;&#25191;&#34892;&#24615;&#30340;&#21453;&#32534;&#35793;&#25968;&#25454;&#38598;&#12290;&#35813;&#22522;&#20934;&#24378;&#35843;&#20102;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05286v1 Announce Type: cross  Abstract: Decompilation aims to restore compiled code to human-readable source code, but struggles with details like names and structure. Large language models (LLMs) show promise for programming tasks, motivating their application to decompilation. However, there does not exist any open-source LLM for decompilation. Moreover, existing decompilation evaluation systems mainly consider token-level accuracy and largely ignore code executability, which is the most important feature of any program. Therefore, we release the first open-access decompilation LLMs ranging from 1B to 33B pre-trained on 4 billion tokens of C source code and the corresponding assembly code. The open-source LLMs can serve as baselines for further development in the field. To ensure practical program evaluation, we introduce Decompile-Eval, the first dataset that considers re-compilability and re-executability for decompilation. The benchmark emphasizes the importance of eval
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#31034;&#24341;&#21457;&#29305;&#23450;&#20154;&#26684;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24515;&#29702;&#29702;&#35770;&#25512;&#29702;&#33021;&#21147;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#26469;&#33258;&#40657;&#26263;&#19977;&#21512;&#20250;&#30340;&#29305;&#36136;&#23545;&#22810;&#31181;LLMs&#22312;&#19981;&#21516;ToM&#20219;&#21153;&#20013;&#20855;&#26377;&#36739;&#22823;&#25928;&#24212;&#12290;</title><link>https://arxiv.org/abs/2403.02246</link><description>&lt;p&gt;
PHAnToM&#65306;&#20154;&#26684;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24515;&#29702;&#29702;&#35770;&#25512;&#29702;&#20135;&#29983;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02246
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#31034;&#24341;&#21457;&#29305;&#23450;&#20154;&#26684;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24515;&#29702;&#29702;&#35770;&#25512;&#29702;&#33021;&#21147;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#26469;&#33258;&#40657;&#26263;&#19977;&#21512;&#20250;&#30340;&#29305;&#36136;&#23545;&#22810;&#31181;LLMs&#22312;&#19981;&#21516;ToM&#20219;&#21153;&#20013;&#20855;&#26377;&#36739;&#22823;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#34920;&#26126;&#65292;&#23427;&#20204;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#35768;&#22810;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#19982;&#29978;&#33267;&#20248;&#20110;&#20154;&#31867;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#19968;&#36827;&#23637;&#65292;LLMs&#22312;&#31038;&#20250;&#35748;&#30693;&#25512;&#29702;&#26041;&#38754;&#20173;&#28982;&#19981;&#36275;&#65292;&#32780;&#20154;&#31867;&#22312;&#36825;&#26041;&#38754;&#22825;&#29983;&#23601;&#24456;&#25797;&#38271;&#12290;&#21463;&#21040;&#24515;&#29702;&#23398;&#30740;&#31350;&#20013;&#26576;&#20123;&#20154;&#26684;&#29305;&#36136;&#19982;&#24515;&#29702;&#29702;&#35770;&#65288;ToM&#65289;&#25512;&#29702;&#20043;&#38388;&#32852;&#31995;&#30340;&#21551;&#21457;&#65292;&#20197;&#21450;&#20851;&#20110;&#25552;&#31034;&#24037;&#31243;&#30740;&#31350;&#22312;&#24433;&#21709;LLMs&#33021;&#21147;&#26041;&#38754;&#30340;&#36229;&#25935;&#24863;&#24615;&#30340;&#21551;&#21457;&#65292;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#25552;&#31034;&#22312;LLMs&#20013;&#24341;&#21457;&#20154;&#26684;&#22914;&#20309;&#24433;&#21709;&#23427;&#20204;&#30340;ToM&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#26576;&#20123;&#24341;&#21457;&#30340;&#20154;&#26684;&#29305;&#36136;&#21487;&#20197;&#26174;&#33879;&#24433;&#21709;LLMs&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;ToM&#20219;&#21153;&#20013;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#29305;&#21035;&#26159;&#65292;&#26469;&#33258;&#40657;&#26263;&#19977;&#21512;&#20250;(Dark Triad)&#30340;&#29305;&#36136;&#23545;&#20110;&#20687;GPT-3.5&#12289;Llama 2&#21644;Mistral&#36825;&#26679;&#30340;LLMs&#22312;&#19981;&#21516;&#30340;ToM&#20219;&#21153;&#20013;&#20855;&#26377;&#36739;&#22823;&#30340;&#21464;&#37327;&#25928;&#24212;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20855;&#26377;&#26576;&#20123;&#20154;&#26684;&#29305;&#36136;&#30340;LLMs&#22312;&#25191;&#34892;ToM&#20219;&#21153;&#26102;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02246v1 Announce Type: new  Abstract: Recent advances in large language models (LLMs) demonstrate that their capabilities are comparable, or even superior, to humans in many tasks in natural language processing. Despite this progress, LLMs are still inadequate at social-cognitive reasoning, which humans are naturally good at. Drawing inspiration from psychological research on the links between certain personality traits and Theory-of-Mind (ToM) reasoning, and from prompt engineering research on the hyper-sensitivity of prompts in affecting LLMs capabilities, this study investigates how inducing personalities in LLMs using prompts affects their ToM reasoning capabilities. Our findings show that certain induced personalities can significantly affect the LLMs' reasoning capabilities in three different ToM tasks. In particular, traits from the Dark Triad have a larger variable effect on LLMs like GPT-3.5, Llama 2, and Mistral across the different ToM tasks. We find that LLMs tha
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20004;&#31181;&#32454;&#31890;&#24230;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#22810;&#27169;&#24577;&#25688;&#35201;&#27169;&#22411;&#30340;&#20107;&#23454;&#24615;&#65292;&#20854;&#20013;&#26080;&#21442;&#32771;&#20107;&#23454;&#24615;&#35780;&#20272;&#26694;&#26550;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11414</link><description>&lt;p&gt;
&#29992;&#20110;&#22810;&#27169;&#24577;&#25688;&#35201;&#30340;&#32454;&#31890;&#24230;&#21487;&#35299;&#37322;&#20107;&#23454;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Fine-grained and Explainable Factuality Evaluation for Multimodal Summarization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11414
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20004;&#31181;&#32454;&#31890;&#24230;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#22810;&#27169;&#24577;&#25688;&#35201;&#27169;&#22411;&#30340;&#20107;&#23454;&#24615;&#65292;&#20854;&#20013;&#26080;&#21442;&#32771;&#20107;&#23454;&#24615;&#35780;&#20272;&#26694;&#26550;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#25688;&#35201;&#26088;&#22312;&#29983;&#25104;&#22522;&#20110;&#36755;&#20837;&#25991;&#26412;&#21644;&#22270;&#20687;&#30340;&#31616;&#27905;&#25688;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#20107;&#23454;&#24615;&#36755;&#20986;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35780;&#20272;&#22810;&#27169;&#24577;&#25688;&#35201;&#27169;&#22411;&#30340;&#20107;&#23454;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#32454;&#31890;&#24230;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#26694;&#26550;&#65288;FALLACIOUS&#65289;&#29992;&#20110;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#21363;&#22522;&#20110;&#21442;&#32771;&#30340;&#20107;&#23454;&#24615;&#35780;&#20272;&#26694;&#26550;&#21644;&#26080;&#21442;&#32771;&#30340;&#20107;&#23454;&#24615;&#35780;&#20272;&#26694;&#26550;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#26080;&#21442;&#32771;&#20107;&#23454;&#24615;&#35780;&#20272;&#26694;&#26550;&#19981;&#38656;&#35201;&#22522;&#20934;&#30495;&#20540;&#65292;&#22240;&#27492;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#22330;&#26223;&#12290;&#20026;&#20102;&#35780;&#20272;&#25152;&#25552;&#20986;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#35745;&#31639;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#19982;&#20854;&#20182;&#25351;&#26631;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#23558;&#36890;&#36807;GitHub&#21457;&#24067;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11414v1 Announce Type: new  Abstract: Multimodal summarization aims to generate a concise summary based on the input text and image. However, the existing methods potentially suffer from unfactual output. To evaluate the factuality of multimodal summarization models, we propose two fine-grained and explainable evaluation frameworks (FALLACIOUS) for different application scenarios, i.e. reference-based factuality evaluation framework and reference-free factuality evaluation framework. Notably, the reference-free factuality evaluation framework doesn't need ground truth and hence it has a wider application scenario. To evaluate the effectiveness of the proposed frameworks, we compute the correlation between our frameworks and the other metrics. The experimental results show the effectiveness of our proposed method. We will release our code and dataset via github.
&lt;/p&gt;</description></item><item><title>DNABERT-S&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#21019;&#24314;&#29289;&#31181;&#24863;&#30693;&#30340;DNA&#23884;&#20837;&#30340;&#22522;&#22240;&#32452;&#22522;&#30784;&#27169;&#22411;&#12290;&#20026;&#20102;&#25552;&#39640;&#23545;&#38271;&#35835;DNA&#24207;&#21015;&#30340;&#23884;&#20837;&#25928;&#26524;&#65292;&#24341;&#20837;&#20102;Manifold Instance Mixup (MI-Mix)&#23545;&#27604;&#30446;&#26631;&#26041;&#27861;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.08777</link><description>&lt;p&gt;
DNABERT-S: &#23398;&#20064;&#20855;&#26377;&#22522;&#22240;&#32452;&#22522;&#30784;&#27169;&#22411;&#30340;&#29289;&#31181;&#24863;&#30693;DNA&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
DNABERT-S: Learning Species-Aware DNA Embedding with Genome Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08777
&lt;/p&gt;
&lt;p&gt;
DNABERT-S&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#21019;&#24314;&#29289;&#31181;&#24863;&#30693;&#30340;DNA&#23884;&#20837;&#30340;&#22522;&#22240;&#32452;&#22522;&#30784;&#27169;&#22411;&#12290;&#20026;&#20102;&#25552;&#39640;&#23545;&#38271;&#35835;DNA&#24207;&#21015;&#30340;&#23884;&#20837;&#25928;&#26524;&#65292;&#24341;&#20837;&#20102;Manifold Instance Mixup (MI-Mix)&#23545;&#27604;&#30446;&#26631;&#26041;&#27861;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#30340;DNA&#23884;&#20837;&#22312;&#22522;&#22240;&#32452;&#20998;&#26512;&#20013;&#20173;&#28982;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#32570;&#20047;&#29992;&#20110;&#27169;&#22411;&#24494;&#35843;&#30340;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23613;&#31649;&#22522;&#22240;&#32452;&#22522;&#30784;&#27169;&#22411;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;&#20363;&#23376;&#26159;&#23439;&#22522;&#22240;&#32452;&#20998;&#31665;&#65292;&#36825;&#26159;&#24494;&#29983;&#29289;&#32452;&#30740;&#31350;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#36807;&#31243;&#65292;&#26088;&#22312;&#36890;&#36807;&#26469;&#33258;&#21487;&#33021;&#21253;&#21547;&#25104;&#21315;&#19978;&#19975;&#20010;&#19981;&#21516;&#30340;&#12289;&#36890;&#24120;&#27809;&#26377;&#32463;&#36807;&#34920;&#24449;&#30340;&#29289;&#31181;&#30340;&#22797;&#26434;&#28151;&#21512;DNA&#24207;&#21015;&#30340;&#29289;&#31181;&#26469;&#23545;DNA&#24207;&#21015;&#36827;&#34892;&#20998;&#32452;&#12290;&#20026;&#20102;&#22635;&#34917;&#26377;&#25928;&#30340;DNA&#23884;&#20837;&#27169;&#22411;&#30340;&#32570;&#38519;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DNABERT-S&#65292;&#36825;&#26159;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;&#21019;&#24314;&#29289;&#31181;&#24863;&#30693;&#30340;DNA&#23884;&#20837;&#30340;&#22522;&#22240;&#32452;&#22522;&#30784;&#27169;&#22411;&#12290;&#20026;&#20102;&#40723;&#21169;&#23545;&#26131;&#20986;&#38169;&#30340;&#38271;&#35835;DNA&#24207;&#21015;&#36827;&#34892;&#26377;&#25928;&#23884;&#20837;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Manifold Instance Mixup(MI-Mix)&#65292;&#19968;&#31181;&#23545;&#27604;&#30446;&#26631;&#65292;&#23427;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#23618;&#27425;&#20013;&#28151;&#21512;DNA&#24207;&#21015;&#30340;&#38544;&#34255;&#34920;&#31034;&#65292;&#24182;&#35757;&#32451;&#27169;&#22411;&#20197;&#22312;&#36755;&#20986;&#23618;&#35782;&#21035;&#21644;&#21306;&#20998;&#36825;&#20123;&#28151;&#21512;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08777v1 Announce Type: cross Abstract: Effective DNA embedding remains crucial in genomic analysis, particularly in scenarios lacking labeled data for model fine-tuning, despite the significant advancements in genome foundation models. A prime example is metagenomics binning, a critical process in microbiome research that aims to group DNA sequences by their species from a complex mixture of DNA sequences derived from potentially thousands of distinct, often uncharacterized species. To fill the lack of effective DNA embedding models, we introduce DNABERT-S, a genome foundation model that specializes in creating species-aware DNA embeddings. To encourage effective embeddings to error-prone long-read DNA sequences, we introduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes the hidden representations of DNA sequences at randomly selected layers and trains the model to recognize and differentiate these mixed proportions at the output layer. We further enha
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#39640;&#25928;&#30340;&#22870;&#21169;&#27169;&#22411;&#38598;&#25104;&#26469;&#25913;&#36827;&#20154;&#24037;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#30001;&#20110;&#22870;&#21169;&#27169;&#22411;&#39044;&#27979;&#19981;&#20934;&#30830;&#32780;&#23548;&#33268;RLHF&#36755;&#20986;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.16635</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#25928;&#30340;&#22870;&#21169;&#27169;&#22411;&#38598;&#25104;&#25913;&#36827;&#20154;&#24037;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble. (arXiv:2401.16635v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16635
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#39640;&#25928;&#30340;&#22870;&#21169;&#27169;&#22411;&#38598;&#25104;&#26469;&#25913;&#36827;&#20154;&#24037;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#30001;&#20110;&#22870;&#21169;&#27169;&#22411;&#39044;&#27979;&#19981;&#20934;&#30830;&#32780;&#23548;&#33268;RLHF&#36755;&#20986;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#23545;&#40784;&#12290;&#28982;&#32780;&#65292;RLHF&#20381;&#36182;&#20110;&#36890;&#36807;&#26377;&#38480;&#30340;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#35757;&#32451;&#30340;&#22870;&#21169;&#27169;&#22411;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;RLHF&#21487;&#33021;&#20135;&#29983;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#19981;&#19968;&#33268;&#30340;&#36755;&#20986;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22870;&#21169;&#38598;&#25104;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#22870;&#21169;&#27169;&#22411;&#20570;&#20986;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#32771;&#34385;&#21040;&#20351;&#29992;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22870;&#21169;&#27169;&#22411;&#38598;&#25104;&#21487;&#33021;&#20855;&#26377;&#35745;&#31639;&#21644;&#36164;&#28304;&#26114;&#36149;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#21253;&#25324;&#32447;&#24615;&#23618;&#38598;&#25104;&#21644;&#22522;&#20110;LoRA&#30340;&#38598;&#25104;&#22312;&#20869;&#30340;&#39640;&#25928;&#38598;&#25104;&#26041;&#27861;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#38598;&#25104;&#22870;&#21169;&#27169;&#22411;&#36816;&#34892;Best-of-$n$&#21644;Proximal Policy Optimization&#65292;&#24182;&#39564;&#35777;&#25105;&#20204;&#30340;&#38598;&#25104;&#26041;&#27861;&#26377;&#21161;&#20110;&#25913;&#21892;RLHF&#36755;&#20986;&#30340;&#23545;&#40784;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback (RLHF) is a widely adopted approach for aligning large language models with human values. However, RLHF relies on a reward model that is trained with a limited amount of human preference data, which could lead to inaccurate predictions. As a result, RLHF may produce outputs that are misaligned with human values. To mitigate this issue, we contribute a reward ensemble method that allows the reward model to make more accurate predictions. As using an ensemble of large language model-based reward models can be computationally and resource-expensive, we explore efficient ensemble methods including linear-layer ensemble and LoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy Optimization with our ensembled reward models, and verify that our ensemble methods help improve the alignment performance of RLHF outputs.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#20114;&#24335;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22823;&#22411;&#25991;&#26412;&#38598;&#21512;&#20013;&#25581;&#31034;&#28508;&#22312;&#30340;&#12289;&#34987;&#39046;&#22495;&#19987;&#23478;&#35270;&#20026;&#30456;&#20851;&#30340;&#27010;&#24565;&#65292;&#26082;&#23454;&#29616;&#20102;&#33258;&#21160;&#21270;&#21448;&#20943;&#23569;&#20102;&#25163;&#21160;&#32534;&#30721;&#30340;&#24037;&#20316;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.05094</link><description>&lt;p&gt;
&#22823;&#22411;&#25991;&#26412;&#38598;&#21512;&#20013;&#30340;&#20132;&#20114;&#24335;&#27010;&#24565;&#23398;&#20064;&#29992;&#20110;&#25581;&#31034;&#28508;&#22312;&#20027;&#39064;
&lt;/p&gt;
&lt;p&gt;
Interactive Concept Learning for Uncovering Latent Themes in Large Text Collections. (arXiv:2305.05094v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#20114;&#24335;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22823;&#22411;&#25991;&#26412;&#38598;&#21512;&#20013;&#25581;&#31034;&#28508;&#22312;&#30340;&#12289;&#34987;&#39046;&#22495;&#19987;&#23478;&#35270;&#20026;&#30456;&#20851;&#30340;&#27010;&#24565;&#65292;&#26082;&#23454;&#29616;&#20102;&#33258;&#21160;&#21270;&#21448;&#20943;&#23569;&#20102;&#25163;&#21160;&#32534;&#30721;&#30340;&#24037;&#20316;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#36234;&#19981;&#21516;&#23398;&#31185;&#39046;&#22495;&#30340;&#19987;&#23478;&#20204;&#36890;&#24120;&#26377;&#20852;&#36259;&#29702;&#35299;&#22823;&#22411;&#25991;&#26412;&#38598;&#21512;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20010;&#25361;&#25112;&#21487;&#20197;&#36890;&#36807;&#22024;&#26434;&#30340;&#26080;&#30417;&#30563;&#25216;&#26415;&#65288;&#22914;&#20027;&#39064;&#27169;&#22411;&#65289;&#25110;&#25163;&#21160;&#20027;&#39064;&#21457;&#29616;&#27969;&#31243;&#26469;&#22788;&#29702;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#20027;&#39064;&#30340;&#23450;&#20041;&#65292;&#19981;&#20165;&#32771;&#34385;&#35789;&#20998;&#24067;&#65292;&#36824;&#21253;&#25324;&#34987;&#39046;&#22495;&#19987;&#23478;&#35270;&#20026;&#30456;&#20851;&#30340;&#27010;&#24565;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#30340;&#25277;&#35937;&#32423;&#21035;&#19978;&#25509;&#25910;&#21644;&#32534;&#30721;&#19987;&#23478;&#21453;&#39304;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#33258;&#21160;&#21270;&#21644;&#25163;&#21160;&#32534;&#30721;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#20801;&#35768;&#19987;&#23478;&#25511;&#21046;&#20182;&#20204;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#20943;&#23569;&#25152;&#38656;&#30340;&#25163;&#21160;&#24037;&#20316;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experts across diverse disciplines are often interested in making sense of large text collections. Traditionally, this challenge is approached either by noisy unsupervised techniques such as topic models, or by following a manual theme discovery process. In this paper, we expand the definition of a theme to account for more than just a word distribution, and include generalized concepts deemed relevant by domain experts. Then, we propose an interactive framework that receives and encodes expert feedback at different levels of abstraction. Our framework strikes a balance between automation and manual coding, allowing experts to maintain control of their study while reducing the manual effort required.
&lt;/p&gt;</description></item></channel></rss>