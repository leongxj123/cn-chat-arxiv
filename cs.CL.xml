<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20195;&#29702;&#26500;&#25104;&#30340;&#20195;&#29702;&#26694;&#26550;TrustAgent&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#39044;&#20808;&#35268;&#21010;&#12289;&#35268;&#21010;&#36807;&#31243;&#20013;&#21644;&#35745;&#21010;&#21518;&#26816;&#26597;&#19977;&#31181;&#31574;&#30053;&#26469;&#25552;&#39640;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#35782;&#21035;&#21644;&#39044;&#38450;&#28508;&#22312;&#21361;&#38505;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#23433;&#20840;&#24615;&#19982;&#20351;&#29992;&#32773;&#28385;&#24847;&#24230;&#20197;&#21450;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#19982;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01586</link><description>&lt;p&gt;
TrustAgent: &#36890;&#36807;&#20195;&#29702;&#26500;&#25104;&#23454;&#29616;&#23433;&#20840;&#21487;&#20449;&#36182;&#30340;LLM&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20195;&#29702;&#26500;&#25104;&#30340;&#20195;&#29702;&#26694;&#26550;TrustAgent&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#39044;&#20808;&#35268;&#21010;&#12289;&#35268;&#21010;&#36807;&#31243;&#20013;&#21644;&#35745;&#21010;&#21518;&#26816;&#26597;&#19977;&#31181;&#31574;&#30053;&#26469;&#25552;&#39640;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#35782;&#21035;&#21644;&#39044;&#38450;&#28508;&#22312;&#21361;&#38505;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#23433;&#20840;&#24615;&#19982;&#20351;&#29992;&#32773;&#28385;&#24847;&#24230;&#20197;&#21450;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#19982;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#20854;&#21487;&#20449;&#24230;&#20173;&#26410;&#24471;&#21040;&#28145;&#20837;&#25506;&#32034;&#12290;&#30001;&#20110;&#20195;&#29702;&#21487;&#20197;&#30452;&#25509;&#19982;&#29289;&#29702;&#29615;&#22659;&#20132;&#20114;&#65292;&#20854;&#21487;&#38752;&#24615;&#21644;&#23433;&#20840;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20195;&#29702;&#26500;&#25104;&#30340;&#20195;&#29702;&#26694;&#26550;TrustAgent&#65292;&#23545;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#32500;&#24230;&#36827;&#34892;&#20102;&#21021;&#27493;&#30740;&#31350;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#19977;&#31181;&#31574;&#30053;&#65306;&#39044;&#20808;&#35268;&#21010;&#31574;&#30053;&#65292;&#22312;&#29983;&#25104;&#35745;&#21010;&#20043;&#21069;&#21521;&#27169;&#22411;&#27880;&#20837;&#23433;&#20840;&#30693;&#35782;&#65307;&#35268;&#21010;&#36807;&#31243;&#20013;&#31574;&#30053;&#65292;&#22312;&#29983;&#25104;&#35745;&#21010;&#26102;&#22686;&#24378;&#23433;&#20840;&#24615;&#65307;&#35745;&#21010;&#21518;&#26816;&#26597;&#31574;&#30053;&#65292;&#36890;&#36807;&#35745;&#21010;&#21518;&#26816;&#26597;&#30830;&#20445;&#23433;&#20840;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#20998;&#26512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#22914;&#20309;&#36890;&#36807;&#35782;&#21035;&#21644;&#39044;&#38450;&#28508;&#22312;&#21361;&#38505;&#26377;&#25928;&#25552;&#39640;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#23433;&#20840;&#24615;&#19982;&#20351;&#29992;&#32773;&#28385;&#24847;&#24230;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#20197;&#21450;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#20854;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of LLM-based agents has garnered considerable attention, yet their trustworthiness remains an under-explored area. As agents can directly interact with the physical environment, their reliability and safety is critical. This paper presents an Agent-Constitution-based agent framework, TrustAgent, an initial investigation into improving the safety dimension of trustworthiness in LLM-based agents. This framework consists of threefold strategies: pre-planning strategy which injects safety knowledge to the model prior to plan generation, in-planning strategy which bolsters safety during plan generation, and post-planning strategy which ensures safety by post-planning inspection. Through experimental analysis, we demonstrate how these approaches can effectively elevate an LLM agent's safety by identifying and preventing potential dangers. Furthermore, we explore the intricate relationships between safety and helpfulness, and between the model's reasoning ability and its efficac
&lt;/p&gt;</description></item><item><title>&#22823;&#35821;&#35328;&#27169;&#22411;&#19981;&#20165;&#33021;&#22815;&#22312;&#35782;&#21035;&#21644;&#21306;&#20998;&#24378;&#21183;&#21644;&#24369;&#21183;&#35770;&#28857;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#30340;&#20449;&#24565;&#21644;&#20154;&#21475;&#29305;&#24449;&#39044;&#27979;&#20854;&#31435;&#22330;&#65292;&#24182;&#30830;&#23450;&#35770;&#28857;&#23545;&#20010;&#20154;&#30340;&#21560;&#24341;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.00750</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#33021;&#35782;&#21035;&#20196;&#20154;&#20449;&#26381;&#30340;&#35770;&#28857;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Language Models Recognize Convincing Arguments?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00750
&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#19981;&#20165;&#33021;&#22815;&#22312;&#35782;&#21035;&#21644;&#21306;&#20998;&#24378;&#21183;&#21644;&#24369;&#21183;&#35770;&#28857;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#30340;&#20449;&#24565;&#21644;&#20154;&#21475;&#29305;&#24449;&#39044;&#27979;&#20854;&#31435;&#22330;&#65292;&#24182;&#30830;&#23450;&#35770;&#28857;&#23545;&#20010;&#20154;&#30340;&#21560;&#24341;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26174;&#33879;&#19988;&#19981;&#26029;&#22686;&#24378;&#30340;&#33021;&#21147;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#21487;&#33021;&#34987;&#28389;&#29992;&#29992;&#26469;&#21019;&#36896;&#20010;&#24615;&#21270;&#12289;&#20196;&#20154;&#20449;&#26381;&#30340;&#34394;&#20551;&#20449;&#24687;&#21644;&#23459;&#20256;&#30340;&#25285;&#24551;&#12290;&#20026;&#20102;&#28145;&#20837;&#20102;&#35299;LLMs&#30340;&#35828;&#26381;&#33021;&#21147;&#65292;&#32780;&#21448;&#19981;&#30452;&#25509;&#19982;&#20154;&#31867;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#25552;&#20986;&#30740;&#31350;&#23427;&#20204;&#22312;&#26816;&#27979;&#20196;&#20154;&#20449;&#26381;&#30340;&#35770;&#28857;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#36890;&#36807;&#28155;&#21152;&#36777;&#35770;&#12289;&#25237;&#31080;&#21644;&#29992;&#25143;&#29305;&#24449;&#26469;&#25193;&#23637;&#20102;Durmus&#21644;Cardie&#65288;2018&#65289;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#34913;&#37327;LLMs&#33021;&#21147;&#30340;&#20219;&#21153;&#65292;&#21253;&#25324;&#65288;1&#65289;&#21306;&#20998;&#24378;&#21183;&#21644;&#24369;&#21183;&#35770;&#28857;&#65292;&#65288;2&#65289;&#22522;&#20110;&#20449;&#24565;&#21644;&#20154;&#21475;&#29305;&#24449;&#39044;&#27979;&#31435;&#22330;&#65292;&#20197;&#21450;&#65288;3&#65289;&#26681;&#25454;&#20010;&#20154;&#29305;&#24449;&#30830;&#23450;&#23545;&#19968;&#20010;&#35770;&#28857;&#30340;&#21560;&#24341;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;LLMs&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#34920;&#29616;&#19982;&#20154;&#31867;&#19981;&#30456;&#19978;&#19979;&#65292;&#24182;&#19988;&#32467;&#21512;&#19981;&#21516;LLMs&#30340;&#39044;&#27979;&#21487;&#20197;&#33719;&#24471;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#29978;&#33267;&#36229;&#36807;&#20154;&#31867;&#30340;&#34920;&#29616;&#12290;&#38543;&#25991;&#38468;&#24102;&#21457;&#24067;&#30340;&#25968;&#25454;&#21644;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00750v1 Announce Type: new  Abstract: The remarkable and ever-increasing capabilities of Large Language Models (LLMs) have raised concerns about their potential misuse for creating personalized, convincing misinformation and propaganda. To gain insights into LLMs' persuasive capabilities without directly engaging in experimentation with humans, we propose studying their performance on the related task of detecting convincing arguments. We extend a dataset by Durmus &amp; Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs' ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, even surpassing human performance. The data and code released with 
&lt;/p&gt;</description></item><item><title>DeFT&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;IO&#24847;&#35782;&#30340;&#26641;&#27880;&#24847;&#21147;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;QKV&#20934;&#22791;&#21644;&#27880;&#24847;&#21147;&#35745;&#31639;&#38454;&#27573;&#23454;&#29616;&#20869;&#23384;&#39640;&#25928;&#30340;&#35745;&#31639;&#65292;&#38477;&#20302;&#20869;&#23384;&#21360;&#35760;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#26641;&#35299;&#30721;&#31574;&#30053;&#21644;&#25512;&#26029;&#31995;&#32479;&#19981;&#36866;&#37197;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.00242</link><description>&lt;p&gt;
DeFT&#65306;&#24102;IO&#24847;&#35782;&#30340;Flash Tree-attention&#29992;&#20110;&#39640;&#25928;&#30340;&#22522;&#20110;&#26641;&#25628;&#32034;&#30340;LLM&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
DeFT: Flash Tree-attention with IO-Awareness for Efficient Tree-search-based LLM Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00242
&lt;/p&gt;
&lt;p&gt;
DeFT&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;IO&#24847;&#35782;&#30340;&#26641;&#27880;&#24847;&#21147;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;QKV&#20934;&#22791;&#21644;&#27880;&#24847;&#21147;&#35745;&#31639;&#38454;&#27573;&#23454;&#29616;&#20869;&#23384;&#39640;&#25928;&#30340;&#35745;&#31639;&#65292;&#38477;&#20302;&#20869;&#23384;&#21360;&#35760;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#26641;&#35299;&#30721;&#31574;&#30053;&#21644;&#25512;&#26029;&#31995;&#32479;&#19981;&#36866;&#37197;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26641;&#25628;&#32034;&#36827;&#34892;&#35299;&#30721;&#21487;&#20197;&#26497;&#22823;&#22320;&#25552;&#39640;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#26029;&#36136;&#37327;&#12290;&#26681;&#25454;&#24341;&#23548;&#20449;&#21495;&#65292;&#23427;&#36890;&#36807;&#24418;&#25104;LLM&#36755;&#20986;&#20174;&#26681;&#21040;&#21494;&#23376;&#30340;&#26368;&#20339;&#36335;&#24452;&#26469;&#25552;&#39640;&#21487;&#25511;&#24615;&#12289;&#25512;&#29702;&#33021;&#21147;&#12289;&#23545;&#40784;&#31561;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35745;&#31639;&#20887;&#20313;&#12289;&#20869;&#23384;&#21344;&#29992;&#21644;&#20869;&#23384;&#35775;&#38382;&#65292;&#24403;&#21069;&#30340;&#26641;&#35299;&#30721;&#31574;&#30053;&#21450;&#20854;&#25512;&#26029;&#31995;&#32479;&#20114;&#30456;&#19981;&#36866;&#37197;&#65292;&#23548;&#33268;&#25512;&#26029;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DeFT&#65292;&#19968;&#31181;IO&#24863;&#30693;&#26641;&#27880;&#24847;&#21147;&#31639;&#27861;&#65292;&#23427;&#22312;&#20004;&#20010;&#38454;&#27573;&#20013;&#20445;&#25345;&#20869;&#23384;&#39640;&#25928;&#30340;&#27880;&#24847;&#21147;&#35745;&#31639;&#65292;&#38477;&#20302;&#20869;&#23384;&#21360;&#35760;&#65306;&#65288;1&#65289;QKV&#20934;&#22791;&#65306;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;KV&#24341;&#23548;&#26641;&#20998;&#35010;&#31574;&#30053;&#65292;&#20026;GPU&#30340;&#39640;&#21033;&#29992;&#29575;&#21644;&#23613;&#21487;&#33021;&#20943;&#23569;GPU&#20840;&#23616;&#20869;&#23384;&#21644;&#33455;&#29255;&#19978;&#20849;&#20139;&#20869;&#23384;&#20043;&#38388;&#30340;KV&#32531;&#23384;&#30340;&#20869;&#23384;&#35835;/&#20889;; &#65288;2&#65289;&#27880;&#24847;&#21147;&#35745;&#31639;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00242v1 Announce Type: cross  Abstract: Decoding using tree search can greatly enhance the inference quality for transformer-based Large Language Models (LLMs). Depending on the guidance signal, it searches for the best path from root to leaf in the tree by forming LLM outputs to improve controllability, reasoning ability, alignment, et cetera. However, current tree decoding strategies and their inference systems do not suit each other well due to redundancy in computation, memory footprints, and memory access, resulting in inefficient inference. To address this issue, we propose DeFT, an IO-aware tree attention algorithm that maintains memory-efficient attention calculation with low memory footprints in two stages: (1) QKV Preparation: we propose a KV-Guided Tree Split strategy to group QKV wisely for high utilization of GPUs and reduction of memory reads/writes for the KV cache between GPU global memory and on-chip shared memory as much as possible; (2) Attention Calculati
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#20107;&#23454;&#35299;&#30721;&#26041;&#27861;&#25552;&#39640;&#20102;&#20107;&#23454;&#20934;&#30830;&#24615;&#65292;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20351;&#27169;&#22411;&#23545;&#24050;&#30693;&#20107;&#23454;&#36807;&#20110;&#33258;&#20449;&#65292;&#36827;&#19968;&#27493;&#35780;&#20272;&#26174;&#31034;&#22312;&#30693;&#35782;&#32534;&#36753;&#22522;&#20934;&#19978;&#25152;&#26377;&#35299;&#30721;&#26041;&#27861;&#22343;&#26174;&#33879;&#38477;&#20302;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.00216</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20107;&#23454;&#35299;&#30721;&#65306;&#22312;&#30693;&#35782;&#32534;&#36753;&#22522;&#20934;&#19978;&#30340;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Is Factuality Decoding a Free Lunch for LLMs? Evaluation on Knowledge Editing Benchmark
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00216
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#20107;&#23454;&#35299;&#30721;&#26041;&#27861;&#25552;&#39640;&#20102;&#20107;&#23454;&#20934;&#30830;&#24615;&#65292;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20351;&#27169;&#22411;&#23545;&#24050;&#30693;&#20107;&#23454;&#36807;&#20110;&#33258;&#20449;&#65292;&#36827;&#19968;&#27493;&#35780;&#20272;&#26174;&#31034;&#22312;&#30693;&#35782;&#32534;&#36753;&#22522;&#20934;&#19978;&#25152;&#26377;&#35299;&#30721;&#26041;&#27861;&#22343;&#26174;&#33879;&#38477;&#20302;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#20351;&#23427;&#20204;&#33021;&#22815;&#20197;&#26356;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#26041;&#24335;&#20256;&#36798;&#20107;&#23454;&#30693;&#35782;&#12290;&#20154;&#20204;&#24050;&#32463;&#20570;&#20986;&#20102;&#22823;&#37327;&#21162;&#21147;&#26469;&#36890;&#36807;&#20462;&#25913;LLMs&#24182;&#38477;&#20302;&#20107;&#23454;&#24187;&#35273;&#26469;&#25552;&#39640;&#20107;&#23454;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20462;&#25913;&#20063;&#23384;&#22312;&#38459;&#30861;&#30693;&#35782;&#26356;&#26032;&#30340;&#39118;&#38505;&#65292;&#22240;&#20026;&#23427;&#20204;&#20351;&#27169;&#22411;&#23545;&#24050;&#30693;&#20107;&#23454;&#36807;&#20110;&#33258;&#20449;&#12290;&#26412;&#25991;&#39318;&#20808;&#37325;&#26032;&#23457;&#35270;&#24403;&#21069;&#30340;&#20107;&#23454;&#35299;&#30721;&#26041;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#23427;&#20204;&#22312;&#25552;&#39640;&#20107;&#23454;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23545;&#20960;&#31181;&#24378;&#22823;&#30340;&#20107;&#23454;&#35299;&#30721;&#26041;&#27861;&#22312;&#30693;&#35782;&#32534;&#36753;&#22522;&#20934;&#19978;&#36827;&#34892;&#36827;&#19968;&#27493;&#35780;&#20272;&#12290;&#25152;&#26377;&#36825;&#20123;&#35299;&#30721;&#26041;&#27861;&#19982;&#20854;&#21407;&#22987;&#35299;&#30721;&#30456;&#27604;&#22343;&#26174;&#30528;&#38477;&#20302;&#20102;llama2&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#20854;&#20013;&#26368;&#22823;&#30340;&#38477;&#20302;&#24133;&#24230;&#36798;&#21040;&#24778;&#20154;&#30340;81.3\%&#12290;&#36825;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#24403;&#21069;&#30340;&#35299;&#30721;&#26041;&#27861;&#20173;&#26080;&#27861;&#23436;&#20840;&#35299;&#20915;&#20107;&#23454;&#24187;&#35273;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#24573;&#35270;&#20102;&#20808;&#39564;&#30693;&#35782;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00216v1 Announce Type: cross  Abstract: The rapid development of large language models (LLMs) enables them to convey factual knowledge in a more human-like fashion. Extensive efforts have been made to reduce factual hallucinations by modifying LLMs with factuality decoding. However, they also pose risks of hindering knowledge updates, as they make models overly confident in known facts. In this work, we first revisite the current factuality decoding methods and verified their effectiveness in enhancing factual accuracy. Subsequently, we conduct further evaluation of several strong factuality decoding methods on the knowledge editing benchmark. All these decoding methods significantly diminish the performance of llama2 models compared to their original decoding, with the largest decrease being a staggering 81.3\%. This further indicates that the current existing decoding methods still cannot perfectly address the factual hallucinations, as they overlook the importance of pres
&lt;/p&gt;</description></item><item><title>LUQ&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38271;&#25991;&#26412;&#35774;&#35745;&#30340;&#26032;&#22411;&#37319;&#26679;UQ&#26041;&#27861;&#65292;&#20248;&#20110;&#29616;&#26377;&#22522;&#20934;&#26041;&#27861;&#22312;&#19982;&#27169;&#22411;&#30340;&#20107;&#23454;&#24471;&#20998;&#30456;&#20851;&#26041;&#38754;&#12290;</title><link>https://arxiv.org/abs/2403.20279</link><description>&lt;p&gt;
LUQ&#65306;LLM&#27169;&#22411;&#30340;&#38271;&#25991;&#26412;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
LUQ: Long-text Uncertainty Quantification for LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20279
&lt;/p&gt;
&lt;p&gt;
LUQ&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38271;&#25991;&#26412;&#35774;&#35745;&#30340;&#26032;&#22411;&#37319;&#26679;UQ&#26041;&#27861;&#65292;&#20248;&#20110;&#29616;&#26377;&#22522;&#20934;&#26041;&#27861;&#22312;&#19982;&#27169;&#22411;&#30340;&#20107;&#23454;&#24471;&#20998;&#30456;&#20851;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#33021;&#21147;&#12290;&#23613;&#31649;&#23427;&#20204;&#26377;&#25928;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#20542;&#21521;&#20110;&#29983;&#25104;&#38750;&#20107;&#23454;&#20869;&#23481;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#23545;&#20110;&#22686;&#24378;&#25105;&#20204;&#23545;&#27169;&#22411;&#22312;&#29983;&#25104;&#20869;&#23481;&#19978;&#30340;&#20449;&#24515;&#33267;&#20851;&#37325;&#35201;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#20943;&#36731;&#38750;&#20107;&#23454;&#36755;&#20986;&#12290;&#29616;&#26377;&#30340;UQ&#30740;&#31350;&#20027;&#35201;&#38024;&#23545;&#30701;&#25991;&#26412;&#29983;&#25104;&#65292;&#36890;&#24120;&#20135;&#29983;&#31616;&#30701;&#30340;&#12289;&#21463;&#35789;&#38480;&#21046;&#30340;&#21709;&#24212;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#24212;&#29992;&#24448;&#24448;&#38656;&#35201;&#26356;&#38271;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#39318;&#20808;&#24378;&#35843;&#20102;&#24403;&#21069;UQ&#26041;&#27861;&#22312;&#22788;&#29702;&#38271;&#25991;&#26412;&#29983;&#25104;&#20013;&#30340;&#23616;&#38480;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;\textsc{Luq}&#30340;&#26032;&#22411;&#22522;&#20110;&#25277;&#26679;&#30340;UQ&#26041;&#27861;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#38271;&#25991;&#26412;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;\textsc{Luq}&#22312;&#19982;&#27169;&#22411;&#30340;&#20107;&#23454;&#24471;&#20998;&#30456;&#20851;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20934;&#26041;&#27861;&#65288;Gemini Pro&#35266;&#23519;&#21040;-0.85&#30340;&#36127;&#30456;&#20851;&#31995;&#25968;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20279v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable capability in a variety of NLP tasks. Despite their effectiveness, these models are prone to generate nonfactual content. Uncertainty Quantification (UQ) is pivotal in enhancing our understanding of a model's confidence in its generated content, thereby aiding in the mitigation of nonfactual outputs. Existing research on UQ predominantly targets short text generation, typically yielding brief, word-limited responses. However, real-world applications frequently necessitate much longer responses. Our study first highlights the limitations of current UQ methods in handling long text generation. We then introduce \textsc{Luq}, a novel sampling-based UQ approach specifically designed for long text. Our findings reveal that \textsc{Luq} outperforms existing baseline methods in correlating with the model's factuality scores (negative coefficient of -0.85 observed for Gemini Pro). With \t
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#36328;&#35821;&#35328;&#19978;&#19979;&#25991;&#21270;&#30701;&#35821;&#26816;&#32034;&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#23545;&#27604;&#23398;&#20064;&#26469;&#35299;&#20915;&#22810;&#20041;&#24615;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#36328;&#35821;&#35328;&#24212;&#29992;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.16820</link><description>&lt;p&gt;
&#36328;&#35821;&#35328;&#19978;&#19979;&#25991;&#21270;&#30701;&#35821;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Cross-lingual Contextualized Phrase Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16820
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#36328;&#35821;&#35328;&#19978;&#19979;&#25991;&#21270;&#30701;&#35821;&#26816;&#32034;&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#23545;&#27604;&#23398;&#20064;&#26469;&#35299;&#20915;&#22810;&#20041;&#24615;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#36328;&#35821;&#35328;&#24212;&#29992;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#35821;&#32423;&#23494;&#38598;&#26816;&#32034;&#36890;&#36807;&#21033;&#29992;&#30701;&#35821;&#25552;&#20379;&#30340;&#32454;&#31890;&#24230;&#20449;&#24687;&#65292;&#22312;&#19979;&#28216;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#35768;&#22810;&#21560;&#24341;&#20154;&#30340;&#29305;&#24449;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23494;&#38598;&#26816;&#32034;&#20219;&#21153;&#24418;&#24335;&#65292;&#21363;&#36328;&#35821;&#35328;&#19978;&#19979;&#25991;&#21270;&#30701;&#35821;&#26816;&#32034;&#65292;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#22686;&#24378;&#35299;&#20915;&#22810;&#20041;&#24615;&#30340;&#36328;&#35821;&#35328;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#29305;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#27169;&#22411;&#26159;&#23454;&#29616;&#25105;&#20204;&#30446;&#26631;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21033;&#29992;&#20174;&#24179;&#34892;&#21477;&#23376;&#20013;&#33258;&#21160;&#35825;&#23548;&#30340;&#21333;&#35789;&#23545;&#40784;&#20449;&#24687;&#25552;&#21462;&#36328;&#35821;&#35328;&#30701;&#35821;&#23545;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#35757;&#32451;&#25105;&#20204;&#30340;&#36328;&#35821;&#35328;&#19978;&#19979;&#25991;&#21270;&#30701;&#35821;&#26816;&#32034;&#22120;&#65288;CCPR&#65289;&#65292;&#35813;&#23545;&#27604;&#23398;&#20064;&#40723;&#21169;&#20855;&#26377;&#30456;&#20284;&#19978;&#19979;&#25991;&#21644;&#35821;&#20041;&#30340;&#30701;&#35821;&#30340;&#38544;&#34255;&#34920;&#31034;&#32039;&#23494;&#23545;&#40784;&#12290;&#25105;&#20204;&#23545;&#36328;&#35821;&#35328;&#30701;&#35821;&#26816;&#32034;&#20219;&#21153;&#21644;&#19968;&#20010;&#19979;&#28216;&#20219;&#21153;&#65292;&#21363;&#26426;&#22120;&#32763;&#35793;&#65292;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16820v1 Announce Type: new  Abstract: Phrase-level dense retrieval has shown many appealing characteristics in downstream NLP tasks by leveraging the fine-grained information that phrases offer. In our work, we propose a new task formulation of dense retrieval, cross-lingual contextualized phrase retrieval, which aims to augment cross-lingual applications by addressing polysemy using context information. However, the lack of specific training data and models are the primary challenges to achieve our goal. As a result, we extract pairs of cross-lingual phrases using word alignment information automatically induced from parallel sentences. Subsequently, we train our Cross-lingual Contextualized Phrase Retriever (CCPR) using contrastive learning, which encourages the hidden representations of phrases with similar contexts and semantics to align closely. Comprehensive experiments on both the cross-lingual phrase retrieval task and a downstream task, i.e, machine translation, dem
&lt;/p&gt;</description></item><item><title>LARA&#26159;&#19968;&#20010;Linguistic-Adaptive Retrieval-Augmented Language Models&#65288;&#35821;&#35328;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;LLMs&#65289;&#65292;&#26088;&#22312;&#36890;&#36807;&#32467;&#21512;&#24494;&#35843;&#36807;&#30340;&#36739;&#23567;&#27169;&#22411;&#19982;&#26816;&#32034;&#22686;&#24378;&#26426;&#21046;&#26469;&#25552;&#39640;&#22810;&#35821;&#35328;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#35805;&#32972;&#26223;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.16504</link><description>&lt;p&gt;
LARA&#65306;&#35821;&#35328;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;LLMs&#29992;&#20110;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16504
&lt;/p&gt;
&lt;p&gt;
LARA&#26159;&#19968;&#20010;Linguistic-Adaptive Retrieval-Augmented Language Models&#65288;&#35821;&#35328;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;LLMs&#65289;&#65292;&#26088;&#22312;&#36890;&#36807;&#32467;&#21512;&#24494;&#35843;&#36807;&#30340;&#36739;&#23567;&#27169;&#22411;&#19982;&#26816;&#32034;&#22686;&#24378;&#26426;&#21046;&#26469;&#25552;&#39640;&#22810;&#35821;&#35328;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#35805;&#32972;&#26223;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#21462;&#24471;&#30340;&#26174;&#33879;&#25104;&#23601;&#65292;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#22312;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#20013;&#37319;&#29992;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#20391;&#37325;&#20110;&#21333;&#35821;&#35328;&#12289;&#21333;&#36718;&#20998;&#31867;&#20219;&#21153;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;LARA&#65288;Linguistic-Adaptive Retrieval-Augmented Language Models&#65289;&#65292;&#26088;&#22312;&#22686;&#24378;&#22810;&#35821;&#35328;&#22810;&#36718;&#20998;&#31867;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#65292;&#20197;&#36866;&#24212;&#32842;&#22825;&#26426;&#22120;&#20154;&#20132;&#20114;&#20013;&#30340;&#20247;&#22810;&#24847;&#22270;&#12290;&#30001;&#20110;&#20250;&#35805;&#32972;&#26223;&#30340;&#22797;&#26434;&#24615;&#21644;&#19981;&#26029;&#21457;&#23637;&#30340;&#24615;&#36136;&#65292;&#22810;&#36718;&#24847;&#22270;&#20998;&#31867;&#23588;&#20026;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;LARA&#36890;&#36807;&#23558;&#24494;&#35843;&#36807;&#30340;&#36739;&#23567;&#27169;&#22411;&#19982;&#26816;&#32034;&#22686;&#24378;&#26426;&#21046;&#32467;&#21512;&#65292;&#23884;&#20837;LLMs&#30340;&#26550;&#26500;&#20013;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#36825;&#31181;&#25972;&#21512;&#20351;LARA&#33021;&#22815;&#21160;&#24577;&#21033;&#29992;&#36807;&#21435;&#30340;&#23545;&#35805;&#21644;&#30456;&#20851;&#24847;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#19978;&#19979;&#25991;&#30340;&#29702;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#33258;&#36866;&#24212;&#26816;&#32034;&#25216;&#26415;&#22686;&#24378;&#20102;&#36328;&#35821;&#35328;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16504v1 Announce Type: new  Abstract: Following the significant achievements of large language models (LLMs), researchers have employed in-context learning for text classification tasks. However, these studies focused on monolingual, single-turn classification tasks. In this paper, we introduce LARA (Linguistic-Adaptive Retrieval-Augmented Language Models), designed to enhance accuracy in multi-turn classification tasks across six languages, accommodating numerous intents in chatbot interactions. Multi-turn intent classification is notably challenging due to the complexity and evolving nature of conversational contexts. LARA tackles these issues by combining a fine-tuned smaller model with a retrieval-augmented mechanism, integrated within the architecture of LLMs. This integration allows LARA to dynamically utilize past dialogues and relevant intents, thereby improving the understanding of the context. Furthermore, our adaptive retrieval techniques bolster the cross-lingual
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20934;&#30830;&#23450;&#20301;&#21644;&#24809;&#32602;&#24187;&#35273;&#26631;&#35760;&#65292;ESREAL&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#20041;&#37325;&#24314;&#26469;&#25233;&#21046;&#29983;&#25104;&#24187;&#35273;&#65292;&#35299;&#20915;&#20102;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#24187;&#35273;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.16167</link><description>&lt;p&gt;
&#21033;&#29992;&#35821;&#20041;&#37325;&#24314;&#20943;&#23569;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Exploiting Semantic Reconstruction to Mitigate Hallucinations in Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16167
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20934;&#30830;&#23450;&#20301;&#21644;&#24809;&#32602;&#24187;&#35273;&#26631;&#35760;&#65292;ESREAL&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#20041;&#37325;&#24314;&#26469;&#25233;&#21046;&#29983;&#25104;&#24187;&#35273;&#65292;&#35299;&#20915;&#20102;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#24187;&#35273;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#23545;&#20854;&#21487;&#38752;&#24615;&#26500;&#25104;&#37325;&#22823;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#29983;&#25104;&#38271;&#26631;&#39064;&#26102;&#12290;&#24403;&#21069;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#35782;&#21035;&#21644;&#20943;&#36731;&#36825;&#20123;&#24187;&#35273;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ESREAL&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#20934;&#30830;&#23450;&#20301;&#21644;&#24809;&#32602;&#24187;&#35273;&#26631;&#35760;&#26469;&#25233;&#21046;&#24187;&#35273;&#29983;&#25104;&#12290;&#26368;&#21021;&#65292;ESREAL&#26681;&#25454;&#29983;&#25104;&#30340;&#26631;&#39064;&#21019;&#24314;&#19968;&#20010;&#37325;&#24314;&#22270;&#20687;&#65292;&#24182;&#23558;&#20854;&#23545;&#24212;&#21306;&#22495;&#19982;&#21407;&#22987;&#22270;&#20687;&#30340;&#21306;&#22495;&#23545;&#40784;&#12290;&#36825;&#31181;&#35821;&#20041;&#37325;&#24314;&#26377;&#21161;&#20110;&#35782;&#21035;&#29983;&#25104;&#26631;&#39064;&#20013;&#30340;&#26631;&#35760;&#32423;&#24187;&#35273;&#30340;&#23384;&#22312;&#21644;&#31867;&#22411;&#12290;&#38543;&#21518;&#65292;ESREAL&#36890;&#36807;&#35780;&#20272;&#23545;&#40784;&#21306;&#22495;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#26469;&#35745;&#31639;&#26631;&#35760;&#32423;&#24187;&#35273;&#20998;&#25968;&#65292;&#22522;&#20110;&#24187;&#35273;&#30340;&#31867;&#22411;&#12290;&#26368;&#21518;&#65292;ESREAL&#37319;&#29992;&#19968;&#31181;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#36827;&#34892;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16167v1 Announce Type: cross  Abstract: Hallucinations in vision-language models pose a significant challenge to their reliability, particularly in the generation of long captions. Current methods fall short of accurately identifying and mitigating these hallucinations. To address this issue, we introduce ESREAL, a novel unsupervised learning framework designed to suppress the generation of hallucinations through accurate localization and penalization of hallucinated tokens. Initially, ESREAL creates a reconstructed image based on the generated caption and aligns its corresponding regions with those of the original image. This semantic reconstruction aids in identifying both the presence and type of token-level hallucinations within the generated caption. Subsequently, ESREAL computes token-level hallucination scores by assessing the semantic similarity of aligned regions based on the type of hallucination. Finally, ESREAL employs a proximal policy optimization algorithm, wh
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20154;&#24037;&#38169;&#35823;&#29983;&#25104;&#26469;&#25552;&#39640;&#35821;&#27861;&#38169;&#35823;&#32416;&#27491;&#65292;&#36827;&#32780;&#22312;&#22810;&#31181;&#35821;&#35328;&#20013;&#21462;&#24471;&#20248;&#36234;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2403.05493</link><description>&lt;p&gt;
&#20154;&#31867;&#20250;&#29359;&#38169;&#65292;&#20294;&#32650;&#39548;&#20063;&#33021;&#23398;&#20250;
&lt;/p&gt;
&lt;p&gt;
To Err Is Human, but Llamas Can Learn It Too
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05493
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20154;&#24037;&#38169;&#35823;&#29983;&#25104;&#26469;&#25552;&#39640;&#35821;&#27861;&#38169;&#35823;&#32416;&#27491;&#65292;&#36827;&#32780;&#22312;&#22810;&#31181;&#35821;&#35328;&#20013;&#21462;&#24471;&#20248;&#36234;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#36890;&#36807;&#20154;&#24037;&#38169;&#35823;&#29983;&#25104;&#65288;AEG&#65289;&#26469;&#22686;&#24378;&#35821;&#27861;&#38169;&#35823;&#32416;&#27491;&#65288;GEC&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23545;&#22522;&#20110;Llama 2&#30340;LMs&#36827;&#34892;&#24494;&#35843;&#20197;&#29983;&#25104;&#38169;&#35823;&#65292;&#24182;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#20135;&#29983;&#30340;&#21512;&#25104;&#38169;&#35823;&#31867;&#20284;&#20110;&#20154;&#31867;&#38169;&#35823;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#20154;&#24037;&#38169;&#35823;&#35757;&#32451;GEC Llama&#27169;&#22411;&#65292;&#24182;&#22312;&#25152;&#26377;&#27979;&#35797;&#30340;&#35821;&#35328;&#65288;&#24503;&#35821;&#12289;&#20044;&#20811;&#20848;&#35821;&#21644;&#29233;&#27801;&#23612;&#20122;&#35821;&#65289;&#20013;&#21462;&#24471;&#20102;&#36229;&#36807;&#20808;&#21069;&#26368;&#20808;&#36827;&#30340;&#38169;&#35823;&#26657;&#27491;&#27169;&#22411;&#30340;&#34920;&#29616;&#65292;&#20854;&#25910;&#30410;&#22312;0.8&#33267;6 F0.5&#28857;&#20043;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#36890;&#36807;&#24494;&#35843;&#36739;&#23567;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#21644;&#25552;&#31034;&#22823;&#22411;&#21830;&#29992;LMs&#65288;GPT-3.5&#21644;GPT-4&#65289;&#26469;&#29983;&#25104;&#38169;&#35823;&#65292;&#20063;&#20250;&#26377;&#30410;&#22320;&#24433;&#21709;&#38169;&#35823;&#29983;&#25104;&#27169;&#22411;&#30340;&#21512;&#25104;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05493v1 Announce Type: new  Abstract: This study explores enhancing grammatical error correction (GEC) through artificial error generation (AEG) using language models (LMs). Specifically, we fine-tune Llama 2-based LMs for error generation and find that this approach yields synthetic errors akin to human errors. Next, we train GEC Llama models with the help of these artificial errors and outperform previous state-of-the-art error correction models, with gains ranging between 0.8 and 6 F0.5 points across all tested languages (German, Ukrainian, and Estonian). Moreover, we demonstrate that generating errors by fine-tuning smaller sequence-to-sequence models and prompting large commercial LMs (GPT-3.5 and GPT-4) also results in synthetic errors beneficially affecting error generation models.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;LLMs&#36827;&#34892;&#31038;&#20132;&#20114;&#21160;&#30340;&#20840;&#30693;&#27169;&#25311;&#27604;&#38750;&#20840;&#30693;&#27169;&#25311;&#26356;&#23481;&#26131;&#23454;&#29616;&#31038;&#20132;&#30446;&#26631;&#65292;&#23613;&#31649;&#38750;&#20840;&#30693;&#27169;&#25311;&#26356;&#25509;&#36817;&#23454;&#38469;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2403.05020</link><description>&lt;p&gt;
&#27169;&#25311;&#31038;&#20132;&#20114;&#21160;&#25104;&#21151;&#24615;&#30340;&#35823;&#23548;&#24615;&#65306;&#20197;LLMs&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05020
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;LLMs&#36827;&#34892;&#31038;&#20132;&#20114;&#21160;&#30340;&#20840;&#30693;&#27169;&#25311;&#27604;&#38750;&#20840;&#30693;&#27169;&#25311;&#26356;&#23481;&#26131;&#23454;&#29616;&#31038;&#20132;&#30446;&#26631;&#65292;&#23613;&#31649;&#38750;&#20840;&#30693;&#27169;&#25311;&#26356;&#25509;&#36817;&#23454;&#38469;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36827;&#23637;&#20351;&#24471;&#31038;&#20132;&#27169;&#25311;&#26356;&#21152;&#20016;&#23500;&#65292;&#33021;&#22815;&#20351;&#29992;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#20154;&#30740;&#31350;&#21508;&#31181;&#31038;&#20132;&#29616;&#35937;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24037;&#20316;&#22312;&#36825;&#20123;&#27169;&#25311;&#20013;&#37319;&#29992;&#20102;&#19968;&#31181;&#20840;&#30693;&#30340;&#36879;&#35270;&#65288;&#20363;&#22914;&#65292;&#21333;&#20010;LLM&#29983;&#25104;&#25152;&#26377;&#20132;&#35848;&#32773;&#65289;&#65292;&#36825;&#19982;&#20154;&#31867;&#20855;&#26377;&#30340;&#38750;&#20840;&#30693;&#12289;&#20449;&#24687;&#19981;&#23545;&#31216;&#30340;&#20114;&#21160;&#26681;&#26412;&#19981;&#31526;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20123;&#24046;&#24322;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#35780;&#20272;&#26694;&#26550;&#65292;&#22312;&#21508;&#31181;&#35774;&#23450;&#65288;&#20840;&#30693;&#12289;&#38750;&#20840;&#30693;&#65289;&#20013;&#20351;&#29992;LLMs&#27169;&#25311;&#31038;&#20132;&#20114;&#21160;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36890;&#36807;&#20840;&#30693;&#26041;&#24335;&#27169;&#25311;&#30340;&#20132;&#35848;&#32773;&#22312;&#23454;&#29616;&#31038;&#20132;&#30446;&#26631;&#26041;&#38754;&#27604;&#38750;&#20840;&#30693;&#20195;&#29702;&#20154;&#26356;&#25104;&#21151;&#65292;&#23613;&#31649;&#21518;&#32773;&#26356;&#31526;&#21512;&#29616;&#23454;&#35774;&#32622;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#20174;&#20840;&#30693;&#27169;&#25311;&#20013;&#23398;&#20064;&#21487;&#20197;&#25913;&#21892;&#20132;&#20114;&#30340;&#33258;&#28982;&#24615;&#65292;&#20294;&#22312;&#21512;&#20316;&#22330;&#26223;&#20013;&#20960;&#20046;&#19981;&#33021;&#22686;&#24378;&#30446;&#26631;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05020v1 Announce Type: cross  Abstract: Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena with LLM-based agents. However, most work has used an omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally at odds with the non-omniscient, information asymmetric interactions that humans have. To examine these differences, we develop an evaluation framework to simulate social interactions with LLMs in various settings (omniscient, non-omniscient). Our experiments show that interlocutors simulated omnisciently are much more successful at accomplishing social goals compared to non-omniscient agents, despite the latter being the more realistic setting. Furthermore, we demonstrate that learning from omniscient simulations improves the apparent naturalness of interactions but scarcely enhances goal achievement in cooperative scenarios. Our f
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#23545;&#40784;&#22120;&#27169;&#22411;&#26469;&#35299;&#32806;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#23545;&#40784;&#65292;&#20197;&#20943;&#23569;&#23545;&#40784;&#23545;&#24615;&#33021;&#30340;&#28508;&#22312;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.04224</link><description>&lt;p&gt;
Aligners: &#35299;&#32806;LLMs&#21644;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Aligners: Decoupling LLMs and Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04224
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#23545;&#40784;&#22120;&#27169;&#22411;&#26469;&#35299;&#32806;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#23545;&#40784;&#65292;&#20197;&#20943;&#23569;&#23545;&#40784;&#23545;&#24615;&#33021;&#30340;&#28508;&#22312;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#38656;&#35201;&#19982;&#20154;&#31867;&#26399;&#26395;&#23545;&#40784;&#65292;&#20197;&#30830;&#20445;&#23427;&#20204;&#22312;&#22823;&#22810;&#25968;&#24212;&#29992;&#20013;&#30340;&#23433;&#20840;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;&#23545;&#40784;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#25104;&#26412;&#39640;&#26114;&#65292;&#24182;&#19988;&#38656;&#35201;&#20026;&#27599;&#20010;LLM&#21644;&#23545;&#40784;&#26631;&#20934;&#37325;&#22797;&#36827;&#34892;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#35757;&#32451;&#21487;&#20197;&#26681;&#25454;&#38656;&#35201;&#29992;&#20110;&#23545;&#40784;&#32473;&#23450;&#26631;&#20934;&#30340;&#20219;&#20309;LLM&#30340;&#23545;&#40784;&#27169;&#22411;&#26469;&#35299;&#32806;LLMs&#21644;&#23545;&#40784;&#65292;&#20174;&#32780;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#20943;&#23569;&#23545;&#24615;&#33021;&#30340;&#28508;&#22312;&#36127;&#38754;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#23545;&#40784;&#27169;&#22411;&#35757;&#32451;&#37197;&#26041;&#20165;&#20381;&#36182;&#20110;&#20351;&#29992;&#65288;&#25552;&#31034;&#30340;&#65289;LLM &#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#36731;&#26494;&#35843;&#25972;&#20197;&#36866;&#24212;&#21508;&#31181;&#23545;&#40784;&#26631;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#8220;&#36947;&#24503;&#8221;&#23545;&#40784;&#22120;&#24182;&#22312;&#23454;&#39564;&#19978;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#26469;&#38416;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04224v1 Announce Type: cross  Abstract: Large Language Models (LLMs) need to be aligned with human expectations to ensure their safety and utility in most applications. Alignment is challenging, costly, and needs to be repeated for every LLM and alignment criterion. We propose to decouple LLMs and alignment by training aligner models that can be used to align any LLM for a given criteria on an as-needed basis, thus also reducing the potential negative impacts of alignment on performance. Our recipe for training the aligner models solely relies on synthetic data generated with a (prompted) LLM and can be easily adjusted for a variety of alignment criteria. We illustrate our method by training an "ethical" aligner and verify its efficacy empirically.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;BiasBuster&#26694;&#26550;&#65292;&#29992;&#20110;&#25581;&#31034;&#12289;&#35780;&#20272;&#21644;&#20943;&#36731;LLMs&#20013;&#30340;&#35748;&#30693;&#20559;&#35265;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#20219;&#21153;&#20013;&#65292;&#36890;&#36807;&#24320;&#21457;&#21253;&#21547;16,800&#20010;&#25552;&#31034;&#30340;&#25968;&#25454;&#38598;&#21644;&#27979;&#35797;&#22810;&#31181;&#20559;&#35265;&#32531;&#35299;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;LLMs&#33258;&#36523;&#26469;&#28040;&#38500;&#20854;&#25552;&#31034;&#20013;&#20559;&#35265;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.00811</link><description>&lt;p&gt;
LLM&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#20013;&#30340;&#35748;&#30693;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Cognitive Bias in High-Stakes Decision-Making with LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00811
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;BiasBuster&#26694;&#26550;&#65292;&#29992;&#20110;&#25581;&#31034;&#12289;&#35780;&#20272;&#21644;&#20943;&#36731;LLMs&#20013;&#30340;&#35748;&#30693;&#20559;&#35265;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#20219;&#21153;&#20013;&#65292;&#36890;&#36807;&#24320;&#21457;&#21253;&#21547;16,800&#20010;&#25552;&#31034;&#30340;&#25968;&#25454;&#38598;&#21644;&#27979;&#35797;&#22810;&#31181;&#20559;&#35265;&#32531;&#35299;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;LLMs&#33258;&#36523;&#26469;&#28040;&#38500;&#20854;&#25552;&#31034;&#20013;&#20559;&#35265;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25903;&#25345;&#26085;&#30410;&#25193;&#22823;&#30340;&#20915;&#31574;&#20219;&#21153;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#22312;&#20154;&#31867;(&#21019;&#36896;&#30340;)&#25968;&#25454;&#19978;&#35757;&#32451;&#65292;LLMs&#21487;&#33021;&#20250;&#32487;&#25215;&#38024;&#23545;&#21463;&#20445;&#25252;&#32676;&#20307;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#21516;&#26102;&#20063;&#21487;&#33021;&#21463;&#21040;&#35748;&#30693;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;&#36825;&#31181;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#20559;&#35265;&#21487;&#33021;&#20250;&#22952;&#30861;&#21033;&#29992;LLM&#21327;&#21161;&#20570;&#20986;&#20844;&#24179;&#21644;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24341;&#20837;&#20102;BiasBuster&#65292;&#19968;&#20010;&#26088;&#22312;&#25581;&#31034;&#12289;&#35780;&#20272;&#21644;&#20943;&#36731;LLMs&#20013;&#30340;&#35748;&#30693;&#20559;&#35265;&#30340;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#20219;&#21153;&#20013;&#12290;&#21463;&#24515;&#29702;&#23398;&#21644;&#35748;&#30693;&#31185;&#23398;&#20808;&#21069;&#30740;&#31350;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;16,800&#20010;&#25552;&#31034;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#19981;&#21516;&#35748;&#30693;&#20559;&#35265;(&#20363;&#22914;&#65292;&#25552;&#31034;&#35825;&#23548;&#12289;&#39034;&#24207;&#12289;&#22266;&#26377;)&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#21508;&#31181;&#20559;&#35265;&#32531;&#35299;&#31574;&#30053;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;LLMs&#26469;&#28040;&#38500;&#23427;&#20204;&#33258;&#24049;&#30340;&#25552;&#31034;&#20013;&#30340;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#20851;&#20110;&#19981;&#21516;&#39046;&#22495;&#35748;&#30693;&#20559;&#35265;&#23384;&#22312;&#21644;&#24433;&#21709;&#30340;&#20840;&#38754;&#22270;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00811v1 Announce Type: new  Abstract: Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across diffe
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#20013;&#20559;&#35265;&#25918;&#22823;&#30340;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;Seesaw-CF&#65292;&#39318;&#27425;&#28145;&#20837;&#30740;&#31350;&#20102;&#26435;&#37325;&#32534;&#36753;&#26041;&#27861;&#23545;&#27169;&#22411;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.00180</link><description>&lt;p&gt;
"Flex Tape&#19981;&#33021;&#20462;&#22797;&#36825;&#20010;": &#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#21644;&#38169;&#35823;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
"Flex Tape Can't Fix That": Bias and Misinformation in Edited Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00180
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#20013;&#20559;&#35265;&#25918;&#22823;&#30340;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;Seesaw-CF&#65292;&#39318;&#27425;&#28145;&#20837;&#30740;&#31350;&#20102;&#26435;&#37325;&#32534;&#36753;&#26041;&#27861;&#23545;&#27169;&#22411;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#32534;&#36753;&#24050;&#32463;&#25104;&#20026;&#26356;&#26032;&#23384;&#20648;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#30693;&#35782;&#30340;&#19968;&#31181;&#20855;&#26377;&#25104;&#26412;&#25928;&#30410;&#30340;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#22312;&#32534;&#36753;&#24212;&#29992;&#21518;&#65292;&#27169;&#22411;&#32534;&#36753;&#21487;&#33021;&#20250;&#20135;&#29983;&#24847;&#24819;&#19981;&#21040;&#30340;&#21518;&#26524;&#65306;&#19982;&#32534;&#36753;&#26080;&#20851;&#30340;&#20449;&#24687;&#20063;&#21487;&#33021;&#34987;&#26356;&#25913;&#65292;&#24182;&#19988;&#27169;&#22411;&#30340;&#20854;&#20182;&#19968;&#33324;&#34892;&#20026;&#21487;&#33021;&#34987;&#38169;&#35823;&#22320;&#25913;&#21464;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#22914;&#20309;&#24847;&#22806;&#22320;&#21152;&#21095;&#20102;&#27169;&#22411;&#21518;&#32534;&#36753;&#30340;&#20559;&#35265;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;Seesaw-CF&#65292;&#29992;&#20110;&#34913;&#37327;&#27169;&#22411;&#32534;&#36753;&#30340;&#20559;&#35265;&#30456;&#20851;&#20260;&#23475;&#65292;&#24182;&#36827;&#34892;&#20102;&#39318;&#27425;&#28145;&#20837;&#30740;&#31350;&#19981;&#21516;&#26435;&#37325;&#32534;&#36753;&#26041;&#27861;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#20559;&#35265;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#19982;&#31181;&#26063;&#12289;&#22320;&#29702;&#26469;&#28304;&#21644;&#24615;&#21035;&#31561;&#20154;&#21475;&#23646;&#24615;&#30456;&#20851;&#30340;&#20559;&#35265;&#65292;&#20197;&#21450;&#30001;&#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#38271;&#25991;&#26412;&#20013;&#30340;&#23450;&#24615;&#32570;&#38519;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#32534;&#36753;&#27169;&#22411;&#22312;&#21464;&#24471;&#23545;&#20122;&#27954;&#12289;&#38750;&#27954;&#31561;&#23646;&#24615;&#30340;&#23646;&#24615;&#19981;&#30830;&#23450;&#24230;&#24840;&#39640;&#26102;&#34920;&#29616;&#20986;&#19981;&#21516;&#31243;&#24230;&#30340;&#26356;&#20026;&#20559;&#35265;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00180v1 Announce Type: new  Abstract: Model editing has emerged as a cost-effective strategy to update knowledge stored in language models. However, model editing can have unintended consequences after edits are applied: information unrelated to the edits can also be changed, and other general behaviors of the model can be wrongly altered. In this work, we investigate how model editing methods unexpectedly amplify model biases post-edit. We introduce a novel benchmark dataset, Seesaw-CF, for measuring bias-related harms of model editing and conduct the first in-depth investigation of how different weight-editing methods impact model bias. Specifically, we focus on biases with respect to demographic attributes such as race, geographic origin, and gender, as well as qualitative flaws in long-form texts generated by edited language models. We find that edited models exhibit, to various degrees, more biased behavior as they become less confident in attributes for Asian, African,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;</title><link>https://arxiv.org/abs/2402.17512</link><description>&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17512
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#20108;&#27425;&#26041;&#22686;&#38271;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#36890;&#36807;&#23450;&#20041;&#28508;&#22312;&#21521;&#37327;&#30340;&#27880;&#24847;&#21147;&#26469;&#23558;&#20854;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#20316;&#20026;&#26631;&#20934;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#30340;&#8220;Latte Transformer&#8221;&#27169;&#22411;&#21487;&#29992;&#20110;&#21452;&#21521;&#21644;&#21333;&#21521;&#20219;&#21153;&#65292;&#22240;&#26524;&#29256;&#26412;&#20801;&#35768;&#19968;&#31181;&#22312;&#25512;&#29702;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#20869;&#23384;&#21644;&#26102;&#38388;&#39640;&#25928;&#30340;&#36882;&#24402;&#23454;&#29616;&#12290;&#26631;&#20934;transformer&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#32447;&#24615;&#22686;&#38271;&#65292;&#32780;Latte Transformer&#35745;&#31639;&#19979;&#19968;&#20010;&#26631;&#35760;&#25152;&#38656;&#30340;&#26102;&#38388;&#26159;&#24658;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#23454;&#35777;&#34920;&#29616;&#21487;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#23558;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#27880;&#24847;&#21147;&#23454;&#38469;&#21487;&#34892;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17512v1 Announce Type: new  Abstract: The time complexity of the standard attention mechanism in a transformer scales quadratically with the length of the sequence. We introduce a method to reduce this to linear scaling with time, based on defining attention via latent vectors. The method is readily usable as a drop-in replacement for the standard attention mechanism. Our "Latte Transformer" model can be implemented for both bidirectional and unidirectional tasks, with the causal version allowing a recurrent implementation which is memory and time-efficient during inference of language generation tasks. Whilst next token prediction scales linearly with the sequence length for a standard transformer, a Latte Transformer requires constant time to compute the next token. The empirical performance of our method is comparable to standard attention, yet allows scaling to context windows much larger than practical in standard attention.
&lt;/p&gt;</description></item><item><title>Finer&#24037;&#20316;&#25581;&#31034;&#20102;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#22312;&#32454;&#31890;&#24230;&#35270;&#35273;&#20998;&#31867;&#19978;&#30340;&#30701;&#26495;&#65292;&#23588;&#20854;&#26159;&#38590;&#20197;&#29983;&#25104;&#20934;&#30830;&#30340;&#32454;&#33268;&#23646;&#24615;&#35299;&#37322;&#65292;&#23613;&#31649;&#20855;&#26377;&#29983;&#25104;&#39640;&#27700;&#24179;&#22270;&#20687;&#35299;&#37322;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.16315</link><description>&lt;p&gt;
Finer: &#22312;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#20013;&#30740;&#31350;&#21644;&#22686;&#24378;&#32454;&#31890;&#24230;&#35270;&#35273;&#27010;&#24565;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16315
&lt;/p&gt;
&lt;p&gt;
Finer&#24037;&#20316;&#25581;&#31034;&#20102;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#22312;&#32454;&#31890;&#24230;&#35270;&#35273;&#20998;&#31867;&#19978;&#30340;&#30701;&#26495;&#65292;&#23588;&#20854;&#26159;&#38590;&#20197;&#29983;&#25104;&#20934;&#30830;&#30340;&#32454;&#33268;&#23646;&#24615;&#35299;&#37322;&#65292;&#23613;&#31649;&#20855;&#26377;&#29983;&#25104;&#39640;&#27700;&#24179;&#22270;&#20687;&#35299;&#37322;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25351;&#23548;&#35843;&#25972;&#30340;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;LVLMs&#65289;&#30340;&#36827;&#23637;&#20351;&#27169;&#22411;&#33021;&#22815;&#36731;&#26494;&#29983;&#25104;&#39640;&#27700;&#24179;&#30340;&#22522;&#20110;&#22270;&#20687;&#30340;&#35299;&#37322;&#12290;&#23613;&#31649;&#36825;&#31181;&#33021;&#21147;&#20027;&#35201;&#24402;&#22240;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#21253;&#21547;&#30340;&#20016;&#23500;&#19990;&#30028;&#30693;&#35782;&#65292;&#20294;&#25105;&#20204;&#30340;&#24037;&#20316;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#20845;&#20010;&#19981;&#21516;&#22522;&#20934;&#35774;&#32622;&#19979;&#30340;&#32454;&#31890;&#24230;&#35270;&#35273;&#20998;&#31867;&#65288;FGVC&#65289;&#19978;&#30340;&#32570;&#38519;&#12290;&#26368;&#36817;&#30340;LVLMs&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#22914;LLaVa-1.5&#65292;InstructBLIP&#21644;GPT-4V&#65292;&#22312;&#20998;&#31867;&#24615;&#33021;&#26041;&#38754;&#20005;&#37325;&#19979;&#38477;&#65292;&#20363;&#22914;&#65292;LLaVA-1.5&#22312;&#26031;&#22374;&#31119;&#29399;&#30340;EM&#24179;&#22343;&#19979;&#38477;&#20102;65.58&#65292;&#32780;&#19988;&#36824;&#38590;&#20197;&#26681;&#25454;&#20986;&#29616;&#22312;&#36755;&#20837;&#22270;&#20687;&#20013;&#30340;&#27010;&#24565;&#29983;&#25104;&#20855;&#26377;&#35814;&#32454;&#23646;&#24615;&#30340;&#20934;&#30830;&#35299;&#37322;&#65292;&#23613;&#31649;&#23427;&#20204;&#26377;&#29983;&#25104;&#25972;&#20307;&#22270;&#20687;&#32423;&#25551;&#36848;&#30340;&#33021;&#21147;&#12290;&#28145;&#20837;&#20998;&#26512;&#34920;&#26126;&#65292;&#32463;&#36807;&#25351;&#23548;&#35843;&#25972;&#30340;LVLMs&#22312;&#32473;&#23450;&#25991;&#26412;&#26102;&#21576;&#29616;&#20986;&#27169;&#24577;&#24046;&#36317;&#65292;&#26174;&#31034;&#20986;&#23384;&#22312;&#19981;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16315v1 Announce Type: cross  Abstract: Recent advances in instruction-tuned Large Vision-Language Models (LVLMs) have imbued the models with the ability to generate high-level, image-grounded explanations with ease. While such capability is largely attributed to the rich world knowledge contained within the Large Language Models (LLMs), our work reveals their shortcomings in fine-grained visual categorization (FGVC) across six different benchmark settings. Most recent state-of-the-art LVLMs like LLaVa-1.5, InstructBLIP and GPT-4V not only severely deteriorate in terms of classification performance, e.g., average drop of 65.58 in EM for Stanford Dogs for LLaVA-1.5, but also struggle to generate an accurate explanation with detailed attributes based on the concept that appears within an input image despite their capability to generate holistic image-level descriptions. In-depth analyses show that instruction-tuned LVLMs exhibit modality gap, showing discrepancy when given tex
&lt;/p&gt;</description></item><item><title>GreenLLaMA&#26159;&#19968;&#31181;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35299;&#27602;&#26694;&#26550;&#65292;&#36890;&#36807;&#36328;&#24179;&#21488;&#35821;&#26009;&#24211;&#35757;&#32451;&#20986;&#30340;&#27169;&#22411;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.15951</link><description>&lt;p&gt;
GreenLLaMA: &#19968;&#31181;&#24102;&#26377;&#35299;&#37322;&#30340;&#35299;&#27602;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
GreenLLaMA: A Framework for Detoxification with Explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15951
&lt;/p&gt;
&lt;p&gt;
GreenLLaMA&#26159;&#19968;&#31181;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35299;&#27602;&#26694;&#26550;&#65292;&#36890;&#36807;&#36328;&#24179;&#21488;&#35821;&#26009;&#24211;&#35757;&#32451;&#20986;&#30340;&#27169;&#22411;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#20851;&#20110;&#35299;&#27602;&#30340;&#30740;&#31350;&#24037;&#20316;&#20998;&#25955;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#65292;&#22240;&#20026;&#23427;&#20204;&#24182;&#27809;&#26377;&#28085;&#30422;&#21040;&#30495;&#23454;&#22330;&#26223;&#20013;&#25152;&#38656;&#30340;&#25152;&#26377;&#35299;&#27602;&#26041;&#38754;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#23558;&#24320;&#21457;&#35299;&#27602;&#27169;&#22411;&#30340;&#20219;&#21153;&#23616;&#38480;&#22312;&#20165;&#35265;&#36807;&#30340;&#24179;&#21488;&#23376;&#38598;&#19978;&#65292;&#27809;&#26377;&#25506;&#35752;&#27169;&#22411;&#22312;&#26410;&#30693;&#24179;&#21488;&#19978;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#24037;&#20316;&#27809;&#26377;&#35299;&#20915;&#19981;&#21487;&#35299;&#27602;&#24615;&#36825;&#19968;&#29616;&#35937;&#65292;&#21363;&#27602;&#24615;&#25991;&#26412;&#26080;&#27861;&#22312;&#19981;&#25913;&#21464;&#21547;&#20041;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35299;&#27602;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GreenLLaMA&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35299;&#27602;&#26694;&#26550;&#65292;&#26088;&#22312;&#20943;&#36731;&#19978;&#36848;&#38480;&#21046;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#20010;&#36328;&#24179;&#21488;&#20266;&#24182;&#34892;&#35821;&#26009;&#24211;&#65292;&#24212;&#29992;&#22810;&#27493;&#25968;&#25454;&#22788;&#29702;&#21644;&#29983;&#25104;&#31574;&#30053;&#21033;&#29992;ChatGPT&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36328;&#24179;&#21488;&#35821;&#26009;&#24211;&#35757;&#32451;&#19968;&#22871;&#35299;&#27602;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#35299;&#27602;&#27169;&#22411;&#20248;&#20110;&#20351;&#29992;&#20154;&#24037;&#27880;&#37322;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15951v1 Announce Type: cross  Abstract: Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose GreenLLaMA, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated par
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23545;&#31264;&#23494;&#26816;&#32034;&#22120;&#30340;&#20449;&#24687;&#25429;&#33719;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25506;&#35752;&#20102;&#20854;&#19982;&#35821;&#35328;&#27169;&#22411;&#30340;&#27604;&#36739;&#12289;&#20449;&#24687;&#25552;&#21462;&#30340;&#21487;&#34892;&#24615;&#20197;&#21450;&#25552;&#21462;&#24615;&#19982;&#24615;&#33021;&#12289;&#24615;&#21035;&#20559;&#35265;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.15925</link><description>&lt;p&gt;
MultiContrievers: &#31264;&#23494;&#26816;&#32034;&#34920;&#31034;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
MultiContrievers: Analysis of Dense Retrieval Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15925
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#31264;&#23494;&#26816;&#32034;&#22120;&#30340;&#20449;&#24687;&#25429;&#33719;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25506;&#35752;&#20102;&#20854;&#19982;&#35821;&#35328;&#27169;&#22411;&#30340;&#27604;&#36739;&#12289;&#20449;&#24687;&#25552;&#21462;&#30340;&#21487;&#34892;&#24615;&#20197;&#21450;&#25552;&#21462;&#24615;&#19982;&#24615;&#33021;&#12289;&#24615;&#21035;&#20559;&#35265;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31264;&#23494;&#26816;&#32034;&#22120;&#23558;&#28304;&#25991;&#26723;&#21387;&#32553;&#20026;&#65288;&#21487;&#33021;&#26159;&#26377;&#25439;&#30340;&#65289;&#21521;&#37327;&#34920;&#31034;&#65292;&#28982;&#32780;&#30446;&#21069;&#23545;&#20110;&#22833;&#21435;&#21644;&#20445;&#30041;&#30340;&#20449;&#24687;&#20197;&#21450;&#23427;&#20204;&#22914;&#20309;&#24433;&#21709;&#19979;&#28216;&#20219;&#21153;&#30340;&#20998;&#26512;&#36739;&#23569;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#39318;&#27425;&#23545;&#27604;&#31264;&#23494;&#26816;&#32034;&#22120;&#25429;&#33719;&#30340;&#20449;&#24687;&#19982;&#23427;&#20204;&#22522;&#20110;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;BERT&#19982;Contriever&#65289;&#20043;&#38388;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#20351;&#29992;25&#20010;MultiBert&#26816;&#26597;&#28857;&#20316;&#20026;&#38543;&#26426;&#21021;&#22987;&#21270;&#26469;&#35757;&#32451;MultiContrievers&#65292;&#36825;&#26159;&#19968;&#32452;25&#20010;contriever&#27169;&#22411;&#12290;&#25105;&#20204;&#27979;&#35797;&#29305;&#23450;&#20449;&#24687;&#65288;&#22914;&#24615;&#21035;&#21644;&#32844;&#19994;&#65289;&#26159;&#21542;&#21487;&#20197;&#20174;&#31867;&#20284;&#32500;&#22522;&#30334;&#31185;&#30340;&#25991;&#26723;&#30340;contriever&#21521;&#37327;&#20013;&#25552;&#21462;&#12290;&#25105;&#20204;&#36890;&#36807;&#20449;&#24687;&#35770;&#25506;&#27979;&#26469;&#34913;&#37327;&#36825;&#31181;&#21487;&#25552;&#21462;&#24615;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#21487;&#25552;&#21462;&#24615;&#19982;&#24615;&#33021;&#12289;&#24615;&#21035;&#20559;&#35265;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#36825;&#20123;&#32467;&#26524;&#23545;&#35768;&#22810;&#38543;&#26426;&#21021;&#22987;&#21270;&#21644;&#25968;&#25454;&#27927;&#29260;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65288;1&#65289;contriever&#27169;&#22411;&#26377;&#26174;&#33879;&#22686;&#21152;&#30340;&#21487;&#25552;&#21462;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15925v1 Announce Type: cross  Abstract: Dense retrievers compress source documents into (possibly lossy) vector representations, yet there is little analysis of what information is lost versus preserved, and how it affects downstream tasks. We conduct the first analysis of the information captured by dense retrievers compared to the language models they are based on (e.g., BERT versus Contriever). We use 25 MultiBert checkpoints as randomized initialisations to train MultiContrievers, a set of 25 contriever models. We test whether specific pieces of information -- such as gender and occupation -- can be extracted from contriever vectors of wikipedia-like documents. We measure this extractability via information theoretic probing. We then examine the relationship of extractability to performance and gender bias, as well as the sensitivity of these results to many random initialisations and data shuffles. We find that (1) contriever models have significantly increased extracta
&lt;/p&gt;</description></item><item><title>CommVQA&#25968;&#25454;&#38598;&#23558;&#22270;&#20687;&#32622;&#20110;&#33258;&#28982;&#29615;&#22659;&#20013;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;&#30340;VQA&#27169;&#22411;&#65292;&#32467;&#26524;&#34920;&#26126;&#20026;&#27169;&#22411;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#33021;&#22815;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15002</link><description>&lt;p&gt;
&#23558;&#35270;&#35273;&#38382;&#31572;&#32622;&#20110;&#20132;&#38469;&#32972;&#26223;&#20013;&#30340;CommVQA
&lt;/p&gt;
&lt;p&gt;
CommVQA: Situating Visual Question Answering in Communicative Contexts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15002
&lt;/p&gt;
&lt;p&gt;
CommVQA&#25968;&#25454;&#38598;&#23558;&#22270;&#20687;&#32622;&#20110;&#33258;&#28982;&#29615;&#22659;&#20013;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;&#30340;VQA&#27169;&#22411;&#65292;&#32467;&#26524;&#34920;&#26126;&#20026;&#27169;&#22411;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#33021;&#22815;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#35270;&#35273;&#38382;&#31572;&#65288;VQA&#65289;&#27169;&#22411;&#24448;&#24448;&#22312;&#23396;&#31435;&#30340;&#22270;&#20687;-&#38382;&#39064;&#23545;&#19978;&#36827;&#34892;&#35757;&#32451;&#21644;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#20154;&#20204;&#25552;&#20986;&#30340;&#38382;&#39064;&#21462;&#20915;&#20110;&#20182;&#20204;&#30340;&#20449;&#24687;&#38656;&#27714;&#21644;&#23545;&#22270;&#20687;&#20869;&#23481;&#30340;&#20808;&#21069;&#20102;&#35299;&#12290;&#20026;&#20102;&#35780;&#20272;&#23558;&#22270;&#20687;&#32622;&#20110;&#33258;&#28982;&#29615;&#22659;&#20013;&#22914;&#20309;&#22609;&#36896;&#35270;&#35273;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CommVQA&#65292;&#36825;&#26159;&#19968;&#20010;&#21253;&#21547;&#22270;&#20687;&#12289;&#22270;&#20687;&#25551;&#36848;&#12289;&#22270;&#20687;&#21487;&#33021;&#20986;&#29616;&#30340;&#30495;&#23454;&#20132;&#38469;&#22330;&#26223;&#65288;&#20363;&#22914;&#26053;&#34892;&#32593;&#31449;&#65289;&#20197;&#21450;&#20381;&#36182;&#20110;&#22330;&#26223;&#30340;&#21518;&#32493;&#38382;&#39064;&#21644;&#31572;&#26696;&#30340;VQA&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;CommVQA&#23545;&#24403;&#21069;&#27169;&#22411;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#20026;VQA&#27169;&#22411;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#21487;&#24191;&#27867;&#25552;&#39640;&#24615;&#33021;&#65292;&#31361;&#26174;&#23558;&#31995;&#32479;&#32622;&#20110;&#20132;&#38469;&#22330;&#26223;&#20013;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15002v1 Announce Type: new  Abstract: Current visual question answering (VQA) models tend to be trained and evaluated on image-question pairs in isolation. However, the questions people ask are dependent on their informational needs and prior knowledge about the image content. To evaluate how situating images within naturalistic contexts shapes visual questions, we introduce CommVQA, a VQA dataset consisting of images, image descriptions, real-world communicative scenarios where the image might appear (e.g., a travel website), and follow-up questions and answers conditioned on the scenario. We show that CommVQA poses a challenge for current models. Providing contextual information to VQA models improves performance broadly, highlighting the relevance of situating systems within a communicative scenario.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25512;&#29702;&#20219;&#21153;&#20998;&#35299;&#20026;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#21644;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#30340;&#31574;&#30053;&#65292;&#21457;&#29616;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#30456;&#27604;&#38382;&#39064;&#35299;&#20915;&#26356;&#23481;&#26131;&#25552;&#28860;&#20026;&#36739;&#23567;&#27169;&#22411;&#65292;&#24182;&#35777;&#23454;&#35813;&#31574;&#30053;&#32988;&#36807;&#21333;&#38454;&#27573;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.15000</link><description>&lt;p&gt;
&#21010;&#20998;&#36824;&#26159;&#24449;&#26381;&#65311;&#20320;&#24212;&#35813;&#25552;&#28860;LLM&#30340;&#21738;&#19968;&#37096;&#20998;&#65311;
&lt;/p&gt;
&lt;p&gt;
Divide-or-Conquer? Which Part Should You Distill Your LLM?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25512;&#29702;&#20219;&#21153;&#20998;&#35299;&#20026;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#21644;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#30340;&#31574;&#30053;&#65292;&#21457;&#29616;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#30456;&#27604;&#38382;&#39064;&#35299;&#20915;&#26356;&#23481;&#26131;&#25552;&#28860;&#20026;&#36739;&#23567;&#27169;&#22411;&#65292;&#24182;&#35777;&#23454;&#35813;&#31574;&#30053;&#32988;&#36807;&#21333;&#38454;&#27573;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#34987;&#40723;&#21169;&#20808;&#35299;&#20915;&#20027;&#35201;&#20219;&#21153;&#30340;&#23376;&#20219;&#21153;&#26102;&#21487;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#25512;&#29702;&#20219;&#21153;&#12290;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#31867;&#20284;&#30340;&#31574;&#30053;&#65292;&#23558;&#25512;&#29702;&#20219;&#21153;&#20998;&#35299;&#20026;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#21644;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#65292;&#24182;&#23637;&#31034;&#35813;&#31574;&#30053;&#33021;&#22815;&#32988;&#36807;&#21333;&#38454;&#27573;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20551;&#35774;&#19982;&#35299;&#20915;&#38382;&#39064;&#30456;&#27604;&#65292;&#20998;&#35299;&#38454;&#27573;&#26356;&#23481;&#26131;&#34987;&#25552;&#28860;&#20026;&#36739;&#23567;&#30340;&#27169;&#22411;&#65292;&#22240;&#20026;&#21518;&#32773;&#38656;&#35201;&#22823;&#37327;&#30340;&#39046;&#22495;&#30693;&#35782;&#65292;&#32780;&#21069;&#32773;&#21482;&#38656;&#35201;&#23398;&#20064;&#19968;&#33324;&#30340;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25552;&#28860;&#36825;&#20004;&#31181;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#23545;&#25512;&#29702;&#32467;&#26524;&#21644;&#25512;&#29702;&#25104;&#26412;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#21487;&#20197;&#25552;&#28860;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#65292;&#24182;&#21516;&#26102;&#22312;&#20219;&#21153;&#12289;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#20043;&#38388;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#12290;&#28982;&#32780;&#65292;&#35201;&#25552;&#28860;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#23601;&#26356;&#22256;&#38590;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15000v1 Announce Type: new  Abstract: Recent methods have demonstrated that Large Language Models (LLMs) can solve reasoning tasks better when they are encouraged to solve subtasks of the main task first. In this paper we devise a similar strategy that breaks down reasoning tasks into a problem decomposition phase and a problem solving phase and show that the strategy is able to outperform a single stage solution. Further, we hypothesize that the decomposition should be easier to distill into a smaller model compared to the problem solving because the latter requires large amounts of domain knowledge while the former only requires learning general problem solving strategies. We propose methods to distill these two capabilities and evaluate their impact on reasoning outcomes and inference cost. We find that we can distill the problem decomposition phase and at the same time achieve good generalization across tasks, datasets, and models. However, it is harder to distill the pr
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#21033;&#29992;&#24037;&#20855;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#65292;&#35774;&#35745;&#20102;&#23450;&#21046;&#21270;&#24037;&#20855;&#26469;&#36741;&#21161;&#35821;&#35328;&#20195;&#29702;&#22312;&#24222;&#22823;&#29615;&#22659;&#20013;&#36827;&#34892;&#25506;&#32034;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#30693;&#35782;&#24211;&#21644;&#25968;&#25454;&#24211;&#31561;&#22797;&#26434;&#29615;&#22659;&#20013;&#65292;&#20511;&#21161;&#24037;&#20855;&#22686;&#24378;&#35821;&#35328;&#20195;&#29702;&#30340;&#37325;&#35201;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.14672</link><description>&lt;p&gt;
&#35821;&#35328;&#20013;&#38388;&#20214;&#65306;&#24037;&#20855;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#23545;&#35821;&#35328;&#20195;&#29702;&#33267;&#20851;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;
Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14672
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#21033;&#29992;&#24037;&#20855;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#65292;&#35774;&#35745;&#20102;&#23450;&#21046;&#21270;&#24037;&#20855;&#26469;&#36741;&#21161;&#35821;&#35328;&#20195;&#29702;&#22312;&#24222;&#22823;&#29615;&#22659;&#20013;&#36827;&#34892;&#25506;&#32034;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#30693;&#35782;&#24211;&#21644;&#25968;&#25454;&#24211;&#31561;&#22797;&#26434;&#29615;&#22659;&#20013;&#65292;&#20511;&#21161;&#24037;&#20855;&#22686;&#24378;&#35821;&#35328;&#20195;&#29702;&#30340;&#37325;&#35201;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24212;&#29992;&#24050;&#32463;&#36828;&#36828;&#36229;&#20986;&#20102;&#25991;&#26412;&#22788;&#29702;&#30340;&#33539;&#22260;&#65292;&#39044;&#31034;&#30528;&#19968;&#20010;&#26032;&#26102;&#20195;&#30340;&#21040;&#26469;&#65292;&#22312;&#36825;&#20010;&#26102;&#20195;&#65292;LLMs&#34987;&#35774;&#24819;&#20026;&#33021;&#22815;&#22312;&#22797;&#26434;&#29616;&#23454;&#29615;&#22659;&#20013;&#36816;&#34892;&#30340;&#36890;&#29992;&#35821;&#35328;&#20195;&#29702;&#12290;&#36825;&#20123;&#29615;&#22659;&#36890;&#24120;&#38750;&#24120;&#24191;&#38420;&#65292;&#20351;&#24471;LLM&#19981;&#21487;&#33021;&#22312;&#20854;&#30701;&#26399;&#35760;&#24518;&#20013;&#22788;&#29702;&#23427;&#20204;&#12290;&#21463;&#26368;&#36817;&#20851;&#20110;&#36890;&#36807;&#24037;&#20855;&#25193;&#23637;LLMs&#33021;&#21147;&#30340;&#30740;&#31350;&#21551;&#21457;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#24037;&#20855;&#22312;&#22686;&#24378;LLMs&#22788;&#29702;&#36825;&#31181;&#22797;&#26434;&#24615;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#23450;&#21046;&#24037;&#20855;&#65292;&#20197;&#21327;&#21161;&#22312;&#36825;&#20123;&#24222;&#22823;&#29615;&#22659;&#20013;&#36827;&#34892;&#20027;&#21160;&#25506;&#32034;&#12290;&#36825;&#20123;&#24037;&#20855;&#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#20013;&#38388;&#20214;&#23618;&#65292;&#20351;LLM&#20813;&#21463;&#29615;&#22659;&#22797;&#26434;&#24615;&#30340;&#24433;&#21709;&#12290;&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#30340;&#22797;&#26434;&#29615;&#22659;--&#30693;&#35782;&#24211;&#65288;KBs&#65289;&#21644;&#25968;&#25454;&#24211;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#20351;&#29992;&#24037;&#20855;&#22686;&#24378;&#35821;&#35328;&#20195;&#29702;&#30340;&#37325;&#35201;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14672v1 Announce Type: cross  Abstract: The applications of large language models (LLMs) have expanded well beyond the confines of text processing, signaling a new era where LLMs are envisioned as generalist language agents capable of operating within complex real-world environments. These environments are often highly expansive, making it impossible for the LLM to process them within its short-term memory. Motivated by recent research on extending the capabilities of LLMs with tools, this paper investigates the intriguing potential of tools to augment LLMs in handling such complexity. To this end, we design customized tools to aid in the proactive exploration within these massive environments. Such tools can serve as a middleware layer shielding the LLM from environmental complexity. In two representative complex environments -- knowledge bases (KBs) and databases -- we demonstrate the significant potential of augmenting language agents with tools in complex environments. N
&lt;/p&gt;</description></item><item><title>LexC-Gen&#25552;&#20986;&#20102;&#19968;&#31181;&#35789;&#20856;&#26465;&#20214;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#22823;&#35268;&#27169;&#29983;&#25104;&#20302;&#36164;&#28304;&#35821;&#35328;&#20998;&#31867;&#20219;&#21153;&#25968;&#25454;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.14086</link><description>&lt;p&gt;
LexC-Gen: &#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21452;&#35821;&#35789;&#27719;&#34920;&#20026;&#26497;&#20302;&#36164;&#28304;&#35821;&#35328;&#29983;&#25104;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14086
&lt;/p&gt;
&lt;p&gt;
LexC-Gen&#25552;&#20986;&#20102;&#19968;&#31181;&#35789;&#20856;&#26465;&#20214;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#22823;&#35268;&#27169;&#29983;&#25104;&#20302;&#36164;&#28304;&#35821;&#35328;&#20998;&#31867;&#20219;&#21153;&#25968;&#25454;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#25968;&#25454;&#21294;&#20047;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#21452;&#35821;&#35789;&#20856;&#20013;&#20174;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#26631;&#35760;&#20219;&#21153;&#25968;&#25454;&#36827;&#34892;&#36880;&#23383;&#32763;&#35793;&#26469;&#35299;&#20915;&#65292;&#28982;&#32780;&#65292;&#21452;&#35821;&#35789;&#20856;&#36890;&#24120;&#19982;&#20219;&#21153;&#25968;&#25454;&#26377;&#38480;&#30340;&#35789;&#27719;&#37325;&#21472;&#65292;&#23548;&#33268;&#32763;&#35793;&#35206;&#30422;&#21644;&#35789;&#20856;&#21033;&#29992;&#19981;&#20339;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;LexC-Gen&#30340;&#35789;&#20856;&#26465;&#20214;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22823;&#35268;&#27169;&#29983;&#25104;&#20302;&#36164;&#28304;&#35821;&#35328;&#20998;&#31867;&#20219;&#21153;&#25968;&#25454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;LexC-Gen&#39318;&#20808;&#20351;&#29992;&#21452;&#35821;&#35789;&#20856;&#20013;&#30340;&#39640;&#36164;&#28304;&#35821;&#35328;&#21333;&#35789;&#29983;&#25104;&#19982;&#35789;&#20856;&#20860;&#23481;&#30340;&#20219;&#21153;&#25968;&#25454;&#65292;&#28982;&#21518;&#36890;&#36807;&#21333;&#35789;&#32763;&#35793;&#23558;&#20854;&#32763;&#35793;&#25104;&#20302;&#36164;&#28304;&#35821;&#35328;&#12290;&#22312;17&#31181;&#26497;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#65292;LexC-Gen&#29983;&#25104;&#30340;&#25968;&#25454;&#22312;&#24615;&#33021;&#19978;&#19982;&#19987;&#23478;&#32763;&#35793;&#30340;&#40644;&#37329;&#25968;&#25454;&#31454;&#20105;&#21147;&#30456;&#24403;&#65292;&#24182;&#19988;&#22312;&#24773;&#24863;&#20998;&#26512;&#21644;&#20027;&#39064;&#20998;&#31867;&#19978;&#24179;&#22343;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#35789;&#20856;&#30340;&#21333;&#35789;&#32763;&#35793;&#26041;&#27861;&#25552;&#39640;&#20102;5.6&#21644;8.9&#20010;&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14086v1 Announce Type: cross  Abstract: Data scarcity in low-resource languages can be addressed with word-to-word translations from labeled task data in high-resource languages using bilingual lexicons. However, bilingual lexicons often have limited lexical overlap with task data, which results in poor translation coverage and lexicon utilization. We propose lexicon-conditioned data generation (LexC-Gen), a method that generates low-resource-language classification task data at scale. Specifically, LexC-Gen first uses high-resource-language words from bilingual lexicons to generate lexicon-compatible task data, and then it translates them into low-resource languages with bilingual lexicons via word translation. Across 17 extremely low-resource languages, LexC-Gen generated data is competitive with expert-translated gold data, and yields on average 5.6 and 8.9 points improvement over existing lexicon-based word translation methods on sentiment analysis and topic classificati
&lt;/p&gt;</description></item><item><title>&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#30340;&#27169;&#22411;&#39044;&#27979;&#26041;&#27861;&#26377;&#21161;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#30340;&#31574;&#30053;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.13213</link><description>&lt;p&gt;
&#36719;&#26368;&#22823;&#27010;&#29575;&#65288;&#22823;&#37096;&#20998;&#26102;&#20505;&#65289;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#39044;&#27979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27491;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Softmax Probabilities (Mostly) Predict Large Language Model Correctness on Multiple-Choice Q&amp;A
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13213
&lt;/p&gt;
&lt;p&gt;
&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#30340;&#27169;&#22411;&#39044;&#27979;&#26041;&#27861;&#26377;&#21161;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#30340;&#31574;&#30053;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#36807;&#24230;&#33258;&#20449;&#20173;&#28982;&#26159;&#19968;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#35774;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#38169;&#35823;&#31572;&#26696;&#23558;&#19982;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#36739;&#23567;&#30456;&#20851;&#65292;&#30456;&#27604;&#20043;&#19979;&#27491;&#30830;&#31572;&#26696;&#36739;&#22823;&#12290;&#25105;&#20204;&#22312;&#21313;&#20010;&#24320;&#28304;LLMs&#21644;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#20840;&#38754;&#35780;&#20272;&#20102;&#36825;&#19968;&#20551;&#35774;&#65292;&#22312;&#34920;&#29616;&#33391;&#22909;&#30340;&#21407;&#22987;&#38382;&#31572;&#20219;&#21153;&#20013;&#21457;&#29616;&#20102;&#23545;&#25105;&#20204;&#20551;&#35774;&#30340;&#24378;&#26377;&#21147;&#35777;&#25454;&#12290;&#23545;&#20110;&#34920;&#29616;&#26368;&#20339;&#30340;&#20845;&#20010;LLMs&#65292;&#20174;MSP&#23548;&#20986;&#30340;AUROC&#22312;59/60&#20010;&#23454;&#20363;&#20013;&#37117;&#20248;&#20110;&#38543;&#26426;&#26426;&#20250;&#65292;p &lt; 10^{-4}&#12290;&#22312;&#36825;&#20845;&#20010;LLMs&#20013;&#65292;&#24179;&#22343;AUROC&#33539;&#22260;&#22312;60%&#33267;69%&#20043;&#38388;&#12290;&#21033;&#29992;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#24323;&#26435;&#36873;&#39033;&#30340;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#36890;&#36807;&#26681;&#25454;&#21021;&#22987;&#27169;&#22411;&#21709;&#24212;&#30340;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#29992;&#39044;softmax logits&#32780;&#19981;&#26159;softmax&#36827;&#34892;&#20102;&#30456;&#21516;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13213v1 Announce Type: cross  Abstract: Although large language models (LLMs) perform impressively on many tasks, overconfidence remains a problem. We hypothesized that on multiple-choice Q&amp;A tasks, wrong answers would be associated with smaller maximum softmax probabilities (MSPs) compared to correct answers. We comprehensively evaluate this hypothesis on ten open-source LLMs and five datasets, and find strong evidence for our hypothesis among models which perform well on the original Q&amp;A task. For the six LLMs with the best Q&amp;A performance, the AUROC derived from the MSP was better than random chance with p &lt; 10^{-4} in 59/60 instances. Among those six LLMs, the average AUROC ranged from 60% to 69%. Leveraging these findings, we propose a multiple-choice Q&amp;A task with an option to abstain and show that performance can be improved by selectively abstaining based on the MSP of the initial model response. We also run the same experiments with pre-softmax logits instead of sof
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;ELECTRA&#21477;&#23376;&#23884;&#20837;&#21521;&#37327;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25130;&#26029;&#27169;&#22411;&#24494;&#35843;&#26041;&#27861;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#20219;&#21153;&#30340;&#34920;&#29616;</title><link>https://arxiv.org/abs/2402.13130</link><description>&lt;p&gt;
ELECTRA&#30340;&#21477;&#23376;&#23884;&#20837;&#26159;&#21542;&#26080;&#27861;&#20462;&#22797;&#65311;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13130
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;ELECTRA&#21477;&#23376;&#23884;&#20837;&#21521;&#37327;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25130;&#26029;&#27169;&#22411;&#24494;&#35843;&#26041;&#27861;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#20219;&#21153;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;BERT&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#30340;&#21477;&#23376;&#23884;&#20837;&#21521;&#37327;&#65292;&#20294;&#20854;&#39044;&#35757;&#32451;&#35745;&#31639;&#25104;&#26412;&#26159;&#19968;&#20010;&#26126;&#26174;&#30340;&#32570;&#28857;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;ELECTRA&#25552;&#20379;&#20102;&#19968;&#31181;&#32463;&#27982;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#30446;&#26631;&#21644;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#25552;&#21319;&#65292;&#20294;&#20854;&#21477;&#23376;&#23884;&#20837;&#21521;&#37327;&#34920;&#29616;&#19981;&#20339;&#12290;&#31038;&#21306;&#24708;&#28982;&#20572;&#27490;&#20351;&#29992;ELECTRA&#30340;&#21477;&#23376;&#23884;&#20837;&#21521;&#37327;&#36827;&#34892;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#65288;STS&#65289;&#20219;&#21153;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#20351;&#29992;ELECTRA&#37492;&#21035;&#22120;&#30340;&#26368;&#21518;&#19968;&#23618;&#30456;&#23545;&#20110;&#36739;&#26089;&#30340;&#23618;&#26102;&#24615;&#33021;&#26174;&#33879;&#19979;&#38477;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#36825;&#31181;&#19979;&#38477;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#20462;&#22797;ELECTRA&#23884;&#20837;&#21521;&#37327;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25130;&#26029;&#27169;&#22411;&#24494;&#35843;&#65288;TMFT&#65289;&#26041;&#27861;&#12290;&#22312;STS&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#65292;TMFT&#23558;Spearman&#30456;&#20851;&#31995;&#25968;&#25552;&#39640;&#20102;8&#20010;&#22810;&#28857;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#21442;&#25968;&#25928;&#29575;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#21508;&#31181;&#27169;&#22411;&#22823;&#23567;&#21644;&#35821;&#35328;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;ELECTRA&#29983;&#25104;&#27169;&#22411;&#30340;&#24778;&#20154;&#21151;&#25928;&#65292;&#23427;&#30340;&#24615;&#33021;&#19982;BERT&#25345;&#24179;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13130v1 Announce Type: new  Abstract: While BERT produces high-quality sentence embeddings, its pre-training computational cost is a significant drawback. In contrast, ELECTRA delivers a cost-effective pre-training objective and downstream task performance improvements, but not as performant sentence embeddings. The community tacitly stopped utilizing ELECTRA's sentence embeddings for semantic textual similarity (STS). We notice a significant drop in performance when using the ELECTRA discriminator's last layer in comparison to earlier layers. We explore this drop and devise a way to repair ELECTRA's embeddings, proposing a novel truncated model fine-tuning (TMFT) method. TMFT improves the Spearman correlation coefficient by over 8 points while increasing parameter efficiency on the STS benchmark dataset. We extend our analysis to various model sizes and languages. Further, we discover the surprising efficacy of ELECTRA's generator model, which performs on par with BERT, usi
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#38024;&#23545;&#25688;&#35201;&#20013;&#20107;&#23454;&#19981;&#19968;&#33268;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27491;&#30830;&#30340;&#33539;&#24335;&#35774;&#35745;&#19979;&#26080;&#38656;&#35757;&#32451;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#35757;&#32451;&#31574;&#30053;&#20197;&#31934;&#28860;&#26356;&#23567;&#22411;&#30340;&#39640;&#20934;&#30830;&#24615;&#30340;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.12821</link><description>&lt;p&gt;
&#22312;&#25688;&#35201;&#20013;&#35782;&#21035;&#20107;&#23454;&#19981;&#19968;&#33268;&#24615;&#65306;&#26397;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26377;&#25928;&#21033;&#29992;
&lt;/p&gt;
&lt;p&gt;
Identifying Factual Inconsistency in Summaries: Towards Effective Utilization of Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12821
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#38024;&#23545;&#25688;&#35201;&#20013;&#20107;&#23454;&#19981;&#19968;&#33268;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27491;&#30830;&#30340;&#33539;&#24335;&#35774;&#35745;&#19979;&#26080;&#38656;&#35757;&#32451;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#35757;&#32451;&#31574;&#30053;&#20197;&#31934;&#28860;&#26356;&#23567;&#22411;&#30340;&#39640;&#20934;&#30830;&#24615;&#30340;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#23454;&#19978;&#30340;&#19981;&#19968;&#33268;&#24615;&#23545;&#25277;&#35937;&#24615;&#25688;&#35201;&#29983;&#25104;&#22120;&#30340;&#21830;&#19994;&#37096;&#32626;&#26500;&#25104;&#37325;&#35201;&#38556;&#30861;&#12290;&#26412;&#30740;&#31350;&#22260;&#32469;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#23637;&#24320;&#65306;&#22914;&#20309;&#26368;&#22909;&#22320;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#26816;&#27979;&#20107;&#23454;&#19981;&#19968;&#33268;&#24615;&#65292;&#20197;&#21450;&#22914;&#20309;&#31934;&#28860;&#19968;&#20010;&#21516;&#26102;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#21151;&#25928;&#24615;&#30340;&#26356;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#65311;&#39318;&#20808;&#25552;&#20986;&#24182;&#35780;&#20272;&#20102;&#19977;&#31181;&#38646;&#26679;&#26412;&#33539;&#24335;&#65292;&#36328;&#36234;&#20116;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#65306;&#30452;&#25509;&#25512;&#29702;&#25972;&#20010;&#25688;&#35201;&#25110;&#27599;&#20010;&#25688;&#35201;&#31383;&#21475;&#65307;&#36890;&#36807;&#38382;&#39064;&#29983;&#25104;&#21644;&#22238;&#31572;&#36827;&#34892;&#23454;&#20307;&#39564;&#35777;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#33539;&#24335;&#35774;&#35745;&#19979;&#65292;&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#33021;&#22815;&#22312;&#26080;&#38656;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#65292;&#24179;&#22343;&#36229;&#36807;&#24378;&#22823;&#30340;&#35757;&#32451;&#22522;&#32447;2.8%&#12290;&#20026;&#36827;&#19968;&#27493;&#20419;&#36827;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#38024;&#23545;&#31934;&#28860;&#26356;&#23567;&#30340;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#19968;&#27425;&#24615;&#39640;&#20934;&#30830;&#22320;&#35780;&#20998;&#25972;&#20010;&#25688;&#35201;&#65292;&#32988;&#36807;&#38646;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12821v1 Announce Type: new  Abstract: Factual inconsistency poses a significant hurdle for the commercial deployment of abstractive summarizers. Under this Large Language Model (LLM) era, this work focuses around two important questions: what is the best way to leverage LLM for factual inconsistency detection, and how could we distill a smaller LLM with both high efficiency and efficacy? Three zero-shot paradigms are firstly proposed and evaluated across five diverse datasets: direct inference on the entire summary or each summary window; entity verification through question generation and answering. Experiments suggest that LLM itself is capable to resolve this task train-free under the proper paradigm design, surpassing strong trained baselines by 2.8% on average. To further promote practical utility, we then propose training strategies aimed at distilling smaller open-source LLM that learns to score the entire summary at once with high accuracy, which outperforms the zero
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;Standardize&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#26816;&#32034;&#24335;&#19978;&#19979;&#25991;&#23398;&#20064;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#19987;&#23478;&#23450;&#20041;&#30340;&#26631;&#20934;&#23545;&#40784;&#65292;&#25552;&#39640;&#20102;&#20869;&#23481;&#29983;&#25104;&#30340;&#31934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12593</link><description>&lt;p&gt;
&#26631;&#20934;&#21270;: &#23558;&#35821;&#35328;&#27169;&#22411;&#19982;&#19987;&#23478;&#23450;&#20041;&#30340;&#26631;&#20934;&#23545;&#40784;&#65292;&#29992;&#20110;&#20869;&#23481;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12593
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;Standardize&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#26816;&#32034;&#24335;&#19978;&#19979;&#25991;&#23398;&#20064;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#19987;&#23478;&#23450;&#20041;&#30340;&#26631;&#20934;&#23545;&#40784;&#65292;&#25552;&#39640;&#20102;&#20869;&#23481;&#29983;&#25104;&#30340;&#31934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#31243;&#12289;&#21307;&#30103;&#20445;&#20581;&#21644;&#25945;&#32946;&#39046;&#22495;&#65292;&#39046;&#22495;&#19987;&#23478;&#36981;&#24490;&#20005;&#26684;&#30340;&#26631;&#20934;&#26469;&#21046;&#20316;&#36136;&#37327;&#20869;&#23481;&#65292;&#22914;&#25216;&#26415;&#25163;&#20876;&#12289;&#33647;&#29289;&#35828;&#26126;&#21644;&#20799;&#31461;&#35835;&#29289;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#22312;&#21487;&#25511;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#30340;&#30740;&#31350;&#23578;&#26410;&#25506;&#35752;&#20351;&#29992;&#36825;&#20123;&#26631;&#20934;&#20316;&#20026;&#25511;&#21046;&#30340;&#21442;&#32771;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;Standardize&#30340;&#26816;&#32034;&#24335;&#19978;&#19979;&#25991;&#23398;&#20064;&#26694;&#26550;&#65292;&#20197;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#19987;&#23478;&#23450;&#20041;&#30340;&#26631;&#20934;&#23545;&#40784;&#12290;&#20197;&#33521;&#35821;&#35821;&#35328;&#26631;&#20934;&#22312;&#25945;&#32946;&#39046;&#22495;&#20316;&#20026;&#19968;&#20010;&#20351;&#29992;&#26696;&#20363;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#27431;&#27954;&#20849;&#21516;&#35821;&#35328;&#21442;&#32771;&#26694;&#26550;&#65288;CEFR&#65289;&#21644;&#36890;&#29992;&#26680;&#24515;&#26631;&#20934;&#65288;CCS&#65289;&#29992;&#20110;&#24320;&#25918;&#24615;&#20869;&#23481;&#29983;&#25104;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#27169;&#22411;&#30340;&#31934;&#30830;&#24615;&#23545;&#20110;Llama2&#21644;GPT-4&#20998;&#21035;&#21487;&#20197;&#25552;&#39640;40%&#21040;100%&#65292;&#35777;&#26126;&#20102;&#20174;&#26631;&#20934;&#20013;&#25552;&#21462;&#30693;&#35782;&#24037;&#20214;&#24182;&#23558;&#20854;&#25972;&#21512;&#21040;&#29983;&#25104;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12593v1 Announce Type: new  Abstract: Domain experts across engineering, healthcare, and education follow strict standards for producing quality content such as technical manuals, medication instructions, and children's reading materials. However, current works in controllable text generation have yet to explore using these standards as references for control. Towards this end, we introduce Standardize, a retrieval-style in-context learning-based framework to guide large language models to align with expert-defined standards. Focusing on English language standards in the education domain as a use case, we consider the Common European Framework of Reference for Languages (CEFR) and Common Core Standards (CCS) for the task of open-ended content generation. Our findings show that models can gain 40% to 100% increase in precise accuracy for Llama2 and GPT-4, respectively, demonstrating that the use of knowledge artifacts extracted from standards and integrating them in the gener
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;ANALOBENCH&#22522;&#20934;&#26469;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#36827;&#34892;&#31867;&#27604;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#25193;&#23637;LMs&#35268;&#27169;&#23545;&#20110;&#22788;&#29702;&#28041;&#21450;&#38271;&#22330;&#26223;&#25110;&#30456;&#20851;&#32463;&#39564;&#22238;&#24518;&#30340;&#31867;&#27604;&#26102;&#24102;&#26469;&#30340;&#24615;&#33021;&#25552;&#21319;&#36739;&#23567;&#12290;</title><link>https://arxiv.org/abs/2402.12370</link><description>&lt;p&gt;
AnaloBench&#65306;&#35780;&#20272;&#25277;&#35937;&#21644;&#38271;&#19978;&#19979;&#25991;&#31867;&#27604;&#35782;&#21035;&#30340;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12370
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;ANALOBENCH&#22522;&#20934;&#26469;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#36827;&#34892;&#31867;&#27604;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#25193;&#23637;LMs&#35268;&#27169;&#23545;&#20110;&#22788;&#29702;&#28041;&#21450;&#38271;&#22330;&#26223;&#25110;&#30456;&#20851;&#32463;&#39564;&#22238;&#24518;&#30340;&#31867;&#27604;&#26102;&#24102;&#26469;&#30340;&#24615;&#33021;&#25552;&#21319;&#36739;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#32463;&#24120;&#36827;&#34892;&#31867;&#27604;&#24605;&#32500;&#65292;&#23558;&#20010;&#20154;&#32463;&#39564;&#19982;&#24403;&#21069;&#24773;&#20917;&#32852;&#31995;&#36215;&#26469;&#65288;$X$&#31867;&#20284;&#20110;$Y$&#26159;&#22240;&#20026;$Z$&#65289;&#12290;&#31867;&#27604;&#24605;&#32500;&#20351;&#20154;&#31867;&#33021;&#22815;&#29992;&#21019;&#36896;&#24615;&#26041;&#24335;&#35299;&#20915;&#38382;&#39064;&#65292;&#29702;&#35299;&#22256;&#38590;&#27010;&#24565;&#65292;&#26356;&#26377;&#25928;&#22320;&#34920;&#36798;&#24819;&#27861;&#12290;&#33021;&#21542;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#20063;&#33021;&#20570;&#21040;&#36825;&#19968;&#28857;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ANALOBENCH&#65292;&#19968;&#20010;&#29992;&#20110;&#30830;&#23450;LMs&#31867;&#27604;&#25512;&#29702;&#33021;&#21147;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#26041;&#27861;&#19987;&#27880;&#20110;&#20154;&#31867;&#20043;&#38388;&#20849;&#21516;&#30340;&#31867;&#27604;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#65306;&#65288;i&#65289;&#20174;&#22823;&#37327;&#20449;&#24687;&#20013;&#22238;&#24518;&#30456;&#20851;&#32463;&#39564;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#23558;&#31867;&#27604;&#25512;&#29702;&#24212;&#29992;&#20110;&#22797;&#26434;&#21644;&#38271;&#24230;&#36739;&#38271;&#30340;&#22330;&#26223;&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#22823;&#37327;&#19987;&#26377;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;GPT&#31995;&#21015;&#65292;Claude V2&#65289;&#21644;&#24320;&#28304;&#27169;&#22411;&#65292;&#22914;LLaMA2&#12290;&#19982;&#20808;&#21069;&#30340;&#32467;&#26524;&#19968;&#26679;&#65292;&#25193;&#23637;LMs&#20250;&#24102;&#26469;&#19968;&#20123;&#24615;&#33021;&#25552;&#21319;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#31867;&#27604;&#28041;&#21450;&#38271;&#22330;&#26223;&#25110;&#22238;&#24518;&#30456;&#20851;&#32463;&#39564;&#26102;&#65292;&#35268;&#27169;&#30340;&#25552;&#21319;&#24102;&#26469;&#30340;&#22686;&#30410;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12370v1 Announce Type: cross  Abstract: Humans regularly engage in analogical thinking, relating personal experiences to current situations ($X$ is analogous to $Y$ because of $Z$). Analogical thinking allows humans to solve problems in creative ways, grasp difficult concepts, and articulate ideas more effectively. Can language models (LMs) do the same? To answer this question, we propose ANALOBENCH, a benchmark to determine analogical reasoning ability in LMs. Our benchmarking approach focuses on aspects of this ability that are common among humans: (i) recalling related experiences from a large amount of information, and (ii) applying analogical reasoning to complex and lengthy scenarios. We test a broad collection of proprietary models (e.g., GPT family, Claude V2) and open source models such as LLaMA2. As in prior results, scaling up LMs results in some performance boosts. Surprisingly, scale offers minimal gains when, (i) analogies involve lengthy scenarios, or (ii) rec
&lt;/p&gt;</description></item><item><title>KARL&#26159;&#19968;&#31181;&#22522;&#20110;DKT&#30340;&#23398;&#29983;&#27169;&#22411;&#65292;&#21033;&#29992;&#26816;&#32034;&#21644;BERT&#23884;&#20837;&#26469;&#23454;&#29616;&#39640;&#25928;&#20934;&#30830;&#30340;&#23398;&#29983;&#35760;&#24518;&#39044;&#27979;&#65292;&#22312;AUC&#21644;&#26657;&#20934;&#35823;&#24046;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#23398;&#29983;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#25945;&#23398;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.12291</link><description>&lt;p&gt;
KARL: &#30693;&#35782;&#24863;&#30693;&#26816;&#32034;&#21644;&#34920;&#31034;&#24110;&#21161;&#23398;&#29983;&#20445;&#25345;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12291
&lt;/p&gt;
&lt;p&gt;
KARL&#26159;&#19968;&#31181;&#22522;&#20110;DKT&#30340;&#23398;&#29983;&#27169;&#22411;&#65292;&#21033;&#29992;&#26816;&#32034;&#21644;BERT&#23884;&#20837;&#26469;&#23454;&#29616;&#39640;&#25928;&#20934;&#30830;&#30340;&#23398;&#29983;&#35760;&#24518;&#39044;&#27979;&#65292;&#22312;AUC&#21644;&#26657;&#20934;&#35823;&#24046;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#23398;&#29983;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#25945;&#23398;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Flashcard&#35843;&#24230;&#22120;&#26159;&#20381;&#36182;&#20110;&#23398;&#29983;&#27169;&#22411;&#26469;&#39044;&#27979;&#23398;&#29983;&#25484;&#25569;&#30340;&#21333;&#35789;&#21345;&#65292;&#24182;&#20351;&#29992;&#25945;&#23398;&#31574;&#30053;&#26681;&#25454;&#36825;&#20123;&#39044;&#27979;&#23433;&#25490;&#35789;&#21345;&#30340;&#24037;&#20855;&#12290;&#29616;&#26377;&#30340;&#23398;&#29983;&#27169;&#22411;&#20165;&#20351;&#29992;&#21333;&#35789;&#21345;&#32423;&#21035;&#30340;&#29305;&#24449;&#65292;&#27604;&#22914;&#23398;&#29983;&#30340;&#36807;&#21435;&#22238;&#31572;&#65292;&#24573;&#30053;&#20102;&#21333;&#35789;&#21345;&#20043;&#38388;&#30340;&#35821;&#20041;&#32852;&#31995;&#12290;&#28145;&#24230;&#30693;&#35782;&#36319;&#36394;&#65288;DKT&#65289;&#27169;&#22411;&#21487;&#20197;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#25429;&#25417;&#35821;&#20041;&#20851;&#31995;&#65292;&#20294;&#25928;&#29575;&#20302;&#19979;&#65292;&#32570;&#20047;&#20869;&#23481;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#29992;&#20110;&#35780;&#20272;&#65292;&#24182;&#38656;&#35201;&#31283;&#20581;&#30340;&#25945;&#23398;&#31574;&#30053;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;KARL&#65292;&#36825;&#26159;&#21463;DKT&#21551;&#21457;&#30340;&#23398;&#29983;&#27169;&#22411;&#65292;&#21033;&#29992;&#26816;&#32034;&#21644;BERT&#23884;&#20837;&#20197;&#23454;&#29616;&#39640;&#25928;&#20934;&#30830;&#30340;&#23398;&#29983;&#35760;&#24518;&#39044;&#27979;&#12290;&#20026;&#20102;&#27979;&#35797;KARL&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20010;&#21253;&#21547;&#24191;&#27867;&#23398;&#20064;&#21382;&#21490;&#20851;&#20110;&#29712;&#20107;&#38382;&#39064;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;KARL&#22312;AUC&#21644;&#26657;&#20934;&#35823;&#24046;&#26041;&#38754;&#32988;&#36807;&#29616;&#26377;&#30340;&#23398;&#29983;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25945;&#23398;&#31574;&#30053;&#65292;&#21033;&#29992;DKT&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#22312;&#32447;&#37096;&#32626;KARL&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12291v1 Announce Type: new  Abstract: Flashcard schedulers are tools that rely on 1) student models to predict the flashcards a student knows; and 2) teaching policies to schedule cards based on these predictions. Existing student models, however, only use flashcard-level features, like the student's past responses, ignoring the semantic ties of flashcards. Deep Knowledge Tracing (DKT) models can capture semantic relations with language models, but are inefficient, lack content-rich datasets for evaluation, and require robust teaching policies. To address these issues, we design KARL, a DKT-inspired student model that uses retrieval and BERT embeddings for efficient and accurate student recall predictions. To test KARL, we collect a new dataset of diverse study history on trivia questions. KARL bests existing student models in AUC and calibration error. Finally, we propose a novel teaching policy that exploits the predictive power of DKT models to deploy KARL online. Based o
&lt;/p&gt;</description></item><item><title>&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22266;&#26377;&#39118;&#26684;&#30456;&#21305;&#37197;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#23398;&#20064;&#32467;&#26524;&#65292;&#24320;&#21457;&#30340;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#31243;&#24230;&#22320;&#35843;&#25972;&#27169;&#22411;&#21709;&#24212;&#26469;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.11192</link><description>&lt;p&gt;
&#22914;&#26524;&#20320;&#35762;&#25105;&#30340;&#35821;&#35328;&#65292;&#25105;&#20250;&#26356;&#22909;&#22320;&#23398;&#20064;&#65306;&#20351;&#29992;&#39118;&#26684;&#23545;&#40784;&#21709;&#24212;&#35843;&#25972;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
I Learn Better If You Speak My Language: Enhancing Large Language Model Fine-Tuning with Style-Aligned Response Adjustments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11192
&lt;/p&gt;
&lt;p&gt;
&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22266;&#26377;&#39118;&#26684;&#30456;&#21305;&#37197;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#23398;&#20064;&#32467;&#26524;&#65292;&#24320;&#21457;&#30340;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#31243;&#24230;&#22320;&#35843;&#25972;&#27169;&#22411;&#21709;&#24212;&#26469;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#23567;&#25968;&#25454;&#38598;&#20026;&#29305;&#23450;&#20219;&#21153;&#24494;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26159;&#19968;&#20010;&#26222;&#36941;&#36935;&#21040;&#30340;&#20294;&#22797;&#26434;&#30340;&#25361;&#25112;&#12290;&#22312;&#26377;&#38480;&#30340;&#31034;&#20363;&#19978;&#36807;&#22810;&#25311;&#21512;&#21487;&#33021;&#20250;&#23545;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#20445;&#30041;&#21407;&#22987;&#25216;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#22320;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#23558;&#22320;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#19982;LLM&#22266;&#26377;&#39118;&#26684;&#21305;&#37197;&#20250;&#20135;&#29983;&#26356;&#22909;&#30340;&#23398;&#20064;&#32467;&#26524;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#28857;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#26368;&#23567;&#31243;&#24230;&#22320;&#20462;&#25913;LLM&#30340;&#29616;&#26377;&#21709;&#24212;&#20197;&#26356;&#27491;&#38169;&#35823;&#65292;&#20351;&#29992;&#36825;&#20123;&#35843;&#25972;&#21518;&#30340;&#21709;&#24212;&#20316;&#20026;&#35757;&#32451;&#30446;&#26631;&#12290;&#36825;&#31181;&#25216;&#26415;&#33021;&#22815;&#23454;&#29616;&#19982;&#27169;&#22411;&#22266;&#26377;&#21709;&#24212;&#39118;&#26684;&#19968;&#33268;&#30340;&#31934;&#30830;&#26356;&#27491;&#65292;&#32500;&#25252;&#27169;&#22411;&#30340;&#26680;&#24515;&#33021;&#21147;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#22810;&#25311;&#21512;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;LLM&#30340;&#29305;&#23450;&#20219;&#21153;&#20934;&#30830;&#24615;&#65292;&#32780;&#19988;&#20851;&#38190;&#22320;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11192v1 Announce Type: cross  Abstract: Fine-tuning large language models (LLMs) with a small data set for particular tasks is a widely encountered yet complex challenge. The potential for overfitting on a limited number of examples can negatively impact the model's ability to generalize and retain its original skills. Our research explores the impact of the style of ground-truth responses during the fine-tuning process. We found that matching the ground-truth response style with the LLM's inherent style results in better learning outcomes. Building on this insight, we developed a method that minimally alters the LLM's pre-existing responses to correct errors, using these adjusted responses as training targets. This technique enables precise corrections in line with the model's native response style, safeguarding the model's core capabilities and thus avoid overfitting. Our findings show that this approach not only improves the LLM's task-specific accuracy but also crucially
&lt;/p&gt;</description></item><item><title>DPR&#24494;&#35843;&#39044;&#35757;&#32451;&#32593;&#32476;&#20197;&#22686;&#24378;&#26597;&#35810;&#21644;&#30456;&#20851;&#25991;&#26412;&#25968;&#25454;&#20043;&#38388;&#30340;&#23884;&#20837;&#23545;&#40784;&#65292;&#21457;&#29616;&#35757;&#32451;&#20013;&#30693;&#35782;&#21435;&#20013;&#24515;&#21270;&#65292;&#20294;&#20063;&#25581;&#31034;&#20102;&#27169;&#22411;&#20869;&#37096;&#30693;&#35782;&#30340;&#23616;&#38480;&#24615;</title><link>https://arxiv.org/abs/2402.11035</link><description>&lt;p&gt;
&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#65306;&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#26159;&#21542;&#22312;&#26816;&#32034;&#20013;&#65311;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11035
&lt;/p&gt;
&lt;p&gt;
DPR&#24494;&#35843;&#39044;&#35757;&#32451;&#32593;&#32476;&#20197;&#22686;&#24378;&#26597;&#35810;&#21644;&#30456;&#20851;&#25991;&#26412;&#25968;&#25454;&#20043;&#38388;&#30340;&#23884;&#20837;&#23545;&#40784;&#65292;&#21457;&#29616;&#35757;&#32451;&#20013;&#30693;&#35782;&#21435;&#20013;&#24515;&#21270;&#65292;&#20294;&#20063;&#25581;&#31034;&#20102;&#27169;&#22411;&#20869;&#37096;&#30693;&#35782;&#30340;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#65288;DPR&#65289;&#26159;&#25913;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24615;&#33021;&#30340;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#33539;&#24335;&#20013;&#30340;&#31532;&#19968;&#27493;&#12290; DPR&#24494;&#35843;&#39044;&#35757;&#32451;&#32593;&#32476;&#65292;&#20197;&#22686;&#24378;&#26597;&#35810;&#21644;&#30456;&#20851;&#25991;&#26412;&#25968;&#25454;&#20043;&#38388;&#30340;&#23884;&#20837;&#23545;&#40784;&#12290;&#23545;DPR&#24494;&#35843;&#30340;&#28145;&#20837;&#29702;&#35299;&#23558;&#38656;&#35201;&#20174;&#26681;&#26412;&#19978;&#37322;&#25918;&#35813;&#26041;&#27861;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#25506;&#38024;&#12289;&#23618;&#28608;&#27963;&#20998;&#26512;&#21644;&#27169;&#22411;&#32534;&#36753;&#30340;&#32452;&#21512;&#65292;&#26426;&#26800;&#22320;&#25506;&#32034;&#20102;DPR&#35757;&#32451;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;DPR&#35757;&#32451;&#20351;&#32593;&#32476;&#20013;&#23384;&#20648;&#30693;&#35782;&#30340;&#26041;&#24335;&#21435;&#20013;&#24515;&#21270;&#65292;&#21019;&#24314;&#20102;&#35775;&#38382;&#30456;&#21516;&#20449;&#24687;&#30340;&#22810;&#20010;&#36335;&#24452;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#36825;&#31181;&#35757;&#32451;&#39118;&#26684;&#30340;&#23616;&#38480;&#24615;&#65306;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#20869;&#37096;&#30693;&#35782;&#38480;&#21046;&#20102;&#26816;&#32034;&#27169;&#22411;&#21487;&#20197;&#26816;&#32034;&#30340;&#20869;&#23481;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#23494;&#38598;&#26816;&#32034;&#25552;&#20986;&#20102;&#19968;&#20123;&#21487;&#33021;&#30340;&#26041;&#21521;&#65306;&#65288;1&#65289;&#26292;&#38706;DPR&#35757;&#32451;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11035v1 Announce Type: new  Abstract: Dense passage retrieval (DPR) is the first step in the retrieval augmented generation (RAG) paradigm for improving the performance of large language models (LLM). DPR fine-tunes pre-trained networks to enhance the alignment of the embeddings between queries and relevant textual data. A deeper understanding of DPR fine-tuning will be required to fundamentally unlock the full potential of this approach. In this work, we explore DPR-trained models mechanistically by using a combination of probing, layer activation analysis, and model editing. Our experiments show that DPR training decentralizes how knowledge is stored in the network, creating multiple access pathways to the same information. We also uncover a limitation in this training style: the internal knowledge of the pre-trained model bounds what the retrieval model can retrieve. These findings suggest a few possible directions for dense retrieval: (1) expose the DPR training process 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#27965;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#36716;&#24405;&#22120;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#35821;&#38899;&#35782;&#21035;&#20013;&#25552;&#39640;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#19981;&#24433;&#21709;&#24120;&#35265;&#21333;&#35789;&#30340;&#38169;&#35823;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.06592</link><description>&lt;p&gt;
&#33258;&#27965;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#36716;&#24405;&#22120;&#29992;&#20110;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Self-consistent context aware conformer transducer for speech recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06592
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#27965;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#36716;&#24405;&#22120;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#35821;&#38899;&#35782;&#21035;&#20013;&#25552;&#39640;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#19981;&#24433;&#21709;&#24120;&#35265;&#21333;&#35789;&#30340;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36716;&#24405;&#22120;&#30340;&#26032;&#39062;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#20026;ASR&#31995;&#32479;&#28155;&#21152;&#20102;&#19978;&#19979;&#25991;&#20449;&#24687;&#27969;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#39640;&#35782;&#21035;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#19981;&#24433;&#21709;&#24120;&#35265;&#21333;&#35789;&#30340;&#38169;&#35823;&#29575;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#24403;&#25105;&#20204;&#20351;&#29992;&#26032;&#27169;&#22411;&#21644;/&#25110;&#19982;&#19978;&#19979;&#25991;&#35821;&#35328;&#27169;&#22411;&#27973;&#24230;&#34701;&#21512;&#26102;&#65292;&#23545;&#19981;&#24120;&#35265;&#21333;&#35789;&#20934;&#30830;&#24615;&#30340;&#25913;&#21892;&#12290;&#25105;&#20204;&#21457;&#29616;&#20004;&#32773;&#30340;&#32452;&#21512;&#21487;&#20197;&#32047;&#31215;&#25552;&#39640;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#35782;&#21035;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel neural network architecture based on conformer transducer that adds contextual information flow to the ASR systems. Our method improves the accuracy of recognizing uncommon words while not harming the word error rate of regular words. We explore the uncommon words accuracy improvement when we use the new model and/or shallow fusion with context language model. We found that combination of both provides cumulative gain in uncommon words recognition accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#29305;&#23450;&#20107;&#23454;&#26680;&#26597;&#27169;&#22411;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27721;&#35821;&#20107;&#23454;&#26680;&#26597;&#31995;&#32479;&#65292;&#24182;&#23637;&#31034;&#20854;&#20248;&#20110;&#32763;&#35793;&#26041;&#27861;&#21644;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21516;&#26102;&#23545;&#20559;&#35265;&#26356;&#21152;&#31283;&#20581;&#65292;&#24378;&#35843;&#20102;&#35821;&#35328;&#29305;&#23450;&#24615;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.15498</link><description>&lt;p&gt;
&#25105;&#20204;&#26159;&#21542;&#38656;&#35201;&#35821;&#35328;&#29305;&#23450;&#30340;&#20107;&#23454;&#26680;&#26597;&#27169;&#22411;&#65311;&#20197;&#27721;&#35821;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Do We Need Language-Specific Fact-Checking Models? The Case of Chinese
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#29305;&#23450;&#20107;&#23454;&#26680;&#26597;&#27169;&#22411;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27721;&#35821;&#20107;&#23454;&#26680;&#26597;&#31995;&#32479;&#65292;&#24182;&#23637;&#31034;&#20854;&#20248;&#20110;&#32763;&#35793;&#26041;&#27861;&#21644;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21516;&#26102;&#23545;&#20559;&#35265;&#26356;&#21152;&#31283;&#20581;&#65292;&#24378;&#35843;&#20102;&#35821;&#35328;&#29305;&#23450;&#24615;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#29305;&#23450;&#20107;&#23454;&#26680;&#26597;&#27169;&#22411;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#37325;&#28857;&#20851;&#27880;&#27721;&#35821;&#26696;&#20363;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22522;&#20110;&#32763;&#35793;&#26041;&#27861;&#21644;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#20363;&#22914;GPT-4&#65289;&#30340;&#23616;&#38480;&#24615;&#65292;&#31361;&#20986;&#20102;&#23545;&#35821;&#35328;&#29305;&#23450;&#31995;&#32479;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#27721;&#35821;&#20107;&#23454;&#26680;&#26597;&#31995;&#32479;&#65292;&#36890;&#36807;&#25972;&#21512;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#20174;&#25991;&#26723;&#20013;&#26816;&#32034;&#35777;&#25454;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#20998;&#26512;&#19981;&#21516;&#31995;&#32479;&#20013;&#30340;&#20196;&#29260;&#32423;&#20559;&#35265;&#65292;&#25105;&#20204;&#22522;&#20110;CHEF&#25968;&#25454;&#38598;&#26500;&#24314;&#20102;&#19968;&#20010;&#23545;&#25239;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#27599;&#20010;&#23454;&#20363;&#19982;&#21407;&#22987;&#23454;&#20363;&#20855;&#26377;&#36739;&#22823;&#30340;&#35789;&#37325;&#21472;&#65292;&#20294;&#20855;&#26377;&#30456;&#21453;&#30340;&#30495;&#23454;&#24615;&#26631;&#31614;&#12290;&#22312;CHEF&#25968;&#25454;&#38598;&#21644;&#25105;&#20204;&#30340;&#23545;&#25239;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#22522;&#20110;&#32763;&#35793;&#30340;&#26041;&#27861;&#21644;&#22810;&#35821;&#35328;LLM&#65292;&#24182;&#19988;&#23545;&#20559;&#35265;&#26356;&#21152;&#31283;&#20581;&#65292;&#20294;&#20173;&#26377;&#24456;&#22823;&#30340;&#25913;&#36827;&#31354;&#38388;&#65292;&#24378;&#35843;&#20102;&#35821;&#35328;&#29305;&#23450;&#24615;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.15498v2 Announce Type: replace  Abstract: This paper investigates the potential benefits of language-specific fact-checking models, focusing on the case of Chinese. We first demonstrate the limitations of translation-based methods and multilingual large language models (e.g., GPT-4), highlighting the need for language-specific systems. We further propose a Chinese fact-checking system that can better retrieve evidence from a document by incorporating context information. To better analyze token-level biases in different systems, we construct an adversarial dataset based on the CHEF dataset, where each instance has large word overlap with the original one but holds the opposite veracity label. Experimental results on the CHEF dataset and our adversarial dataset show that our proposed method outperforms translation-based methods and multilingual LLMs and is more robust toward biases, while there is still large room for improvement, emphasizing the importance of language-specif
&lt;/p&gt;</description></item><item><title>EHRAgent&#26159;&#19968;&#20010;&#30001;&#20195;&#30721;&#25509;&#21475;&#36171;&#33021;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#65292;&#29992;&#20110;&#33258;&#20027;&#29983;&#25104;&#21644;&#25191;&#34892;&#22810;&#34920;&#26684;&#25512;&#29702;&#20195;&#30721;&#65292;&#36890;&#36807;&#38169;&#35823;&#20449;&#24687;&#23398;&#20064;&#25913;&#36827;&#29983;&#25104;&#30340;&#20195;&#30721;&#65292;&#32467;&#21512;&#38271;&#26399;&#35760;&#24518;&#36873;&#25321;&#24182;&#24314;&#31435;&#22312;&#36807;&#21435;&#32463;&#39564;&#20013;&#30340;&#25104;&#21151;&#26696;&#20363;&#12290;</title><link>https://arxiv.org/abs/2401.07128</link><description>&lt;p&gt;
EHRAgent&#65306;&#20195;&#30721;&#36171;&#33021;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#19978;&#36827;&#34892;&#23569;&#26679;&#26412;&#22797;&#26434;&#34920;&#26684;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.07128
&lt;/p&gt;
&lt;p&gt;
EHRAgent&#26159;&#19968;&#20010;&#30001;&#20195;&#30721;&#25509;&#21475;&#36171;&#33021;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#65292;&#29992;&#20110;&#33258;&#20027;&#29983;&#25104;&#21644;&#25191;&#34892;&#22810;&#34920;&#26684;&#25512;&#29702;&#20195;&#30721;&#65292;&#36890;&#36807;&#38169;&#35823;&#20449;&#24687;&#23398;&#20064;&#25913;&#36827;&#29983;&#25104;&#30340;&#20195;&#30721;&#65292;&#32467;&#21512;&#38271;&#26399;&#35760;&#24518;&#36873;&#25321;&#24182;&#24314;&#31435;&#22312;&#36807;&#21435;&#32463;&#39564;&#20013;&#30340;&#25104;&#21151;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35268;&#21010;&#21644;&#24037;&#20855;&#21033;&#29992;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#21307;&#23398;&#38382;&#39064;&#35299;&#20915;&#26041;&#38754;&#23578;&#26410;&#26377;&#22826;&#22810;&#24320;&#21457;&#12290;&#25105;&#20204;&#25552;&#20986;EHRAgent&#65292;&#36825;&#26159;&#19968;&#20010;&#30001;&#20195;&#30721;&#25509;&#21475;&#36171;&#33021;&#30340;LLM&#20195;&#29702;&#65292;&#29992;&#20110;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHRs&#65289;&#20013;&#33258;&#20027;&#29983;&#25104;&#21644;&#25191;&#34892;&#22810;&#34920;&#26684;&#25512;&#29702;&#30340;&#20195;&#30721;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;EHR&#38382;&#31572;&#20219;&#21153;&#21046;&#23450;&#20026;&#24037;&#20855;&#20351;&#29992;&#35268;&#21010;&#36807;&#31243;&#65292;&#23558;&#19968;&#20010;&#22797;&#26434;&#20219;&#21153;&#39640;&#25928;&#22320;&#20998;&#35299;&#20026;&#19968;&#31995;&#21015;&#21487;&#31649;&#29702;&#30340;&#25805;&#20316;&#12290;&#36890;&#36807;&#38598;&#25104;&#20132;&#20114;&#24335;&#32534;&#30721;&#21644;&#25191;&#34892;&#21453;&#39304;&#65292;EHRAgent&#20174;&#38169;&#35823;&#28040;&#24687;&#20013;&#23398;&#20064;&#24182;&#36890;&#36807;&#36845;&#20195;&#25913;&#36827;&#26368;&#21021;&#29983;&#25104;&#30340;&#20195;&#30721;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#32467;&#21512;&#38271;&#26399;&#35760;&#24518;&#26469;&#22686;&#24378;LLM&#20195;&#29702;&#65292;&#20351;EHRAgent&#33021;&#22815;&#26377;&#25928;&#22320;&#36873;&#25321;&#24182;&#24314;&#31435;&#22312;&#36807;&#21435;&#32463;&#39564;&#20013;&#26368;&#30456;&#20851;&#30340;&#25104;&#21151;&#26696;&#20363;&#19978;&#12290;&#22312;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#22810;&#34920;&#26684;EHR&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#26174;&#31034;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.07128v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on three real-world multi-tabular EHR datasets show t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#23558;&#25991;&#26412;&#29983;&#25104;&#24418;&#24335;&#21270;&#20026;&#26410;&#26469;&#21463;&#38480;&#29983;&#25104;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;&#19981;&#33391;&#34892;&#20026;&#24182;&#24378;&#21046;&#25191;&#34892;&#23545;&#25351;&#20196;&#30340;&#24544;&#23454;&#24615;&#65292;&#24182;&#36890;&#36807;LLMs&#26377;&#25928;&#25351;&#23548;&#25991;&#26412;&#29983;&#25104;&#12290;</title><link>https://arxiv.org/abs/2312.06149</link><description>&lt;p&gt;
&#35299;&#38145;&#39044;&#27979;&#24615;&#25991;&#26412;&#29983;&#25104;&#65306;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#30721;&#30340;&#21463;&#38480;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.06149
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#23558;&#25991;&#26412;&#29983;&#25104;&#24418;&#24335;&#21270;&#20026;&#26410;&#26469;&#21463;&#38480;&#29983;&#25104;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;&#19981;&#33391;&#34892;&#20026;&#24182;&#24378;&#21046;&#25191;&#34892;&#23545;&#25351;&#20196;&#30340;&#24544;&#23454;&#24615;&#65292;&#24182;&#36890;&#36807;LLMs&#26377;&#25928;&#25351;&#23548;&#25991;&#26412;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23637;&#29616;&#20102;&#24378;&#22823;&#30340;&#25991;&#26412;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#32473;&#23450;&#25552;&#31034;&#25110;&#25351;&#20196;&#23454;&#29616;&#26368;&#20339;&#32467;&#26524;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21313;&#20159;&#32423;&#21035;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#19981;&#33391;&#34892;&#20026;&#22914;&#27602;&#24615;&#25110;&#24187;&#35273;&#21487;&#33021;&#20250;&#26174;&#29616;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#25991;&#26412;&#29983;&#25104;&#24418;&#24335;&#21270;&#20026;&#26410;&#26469;&#21463;&#38480;&#29983;&#25104;&#38382;&#39064;&#65292;&#20197;&#26368;&#23567;&#21270;&#19981;&#33391;&#34892;&#20026;&#24182;&#24378;&#21046;&#25191;&#34892;&#23545;&#25351;&#20196;&#30340;&#24544;&#23454;&#24615;&#12290;&#20351;&#29992;LLMs&#23454;&#29616;&#26410;&#26469;&#32422;&#26463;&#28385;&#36275;&#24230;&#30340;&#20272;&#35745;&#24341;&#23548;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#65306;&#20851;&#38190;&#35789;&#21463;&#38480;&#29983;&#25104;&#12289;&#27602;&#24615;&#20943;&#23569;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.06149v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have demonstrated a powerful ability for text generation. However, achieving optimal results with a given prompt or instruction can be challenging, especially for billion-sized models. Additionally, undesired behaviors such as toxicity or hallucinations can manifest. While much larger models (e.g., ChatGPT) may demonstrate strength in mitigating these issues, there is still no guarantee of complete prevention. In this work, we propose formalizing text generation as a future-constrained generation problem to minimize undesirable behaviors and enforce faithfulness to instructions. The estimation of future constraint satisfaction, accomplished using LLMs, guides the text generation process. Our extensive experiments demonstrate the effectiveness of the proposed approach across three distinct text generation tasks: keyword-constrained generation (Lin et al., 2020), toxicity reduction (Gehman et al., 202
&lt;/p&gt;</description></item><item><title>AMRFact&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#21033;&#29992;AMR&#29983;&#25104;&#36127;&#26679;&#26412;&#65292;&#22686;&#24378;&#20102;&#25688;&#35201;&#20107;&#23454;&#24615;&#35780;&#20272;&#65292;&#29983;&#25104;&#30340;&#36830;&#36143;&#19988;&#20107;&#23454;&#19981;&#19968;&#33268;&#30340;&#25688;&#35201;&#20855;&#26377;&#39640;&#38169;&#35823;&#29575;&#12290;</title><link>https://arxiv.org/abs/2311.09521</link><description>&lt;p&gt;
AMRFact&#65306;&#21033;&#29992;AMR&#29983;&#25104;&#36127;&#26679;&#26412;&#22686;&#24378;&#25688;&#35201;&#30340;&#20107;&#23454;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09521
&lt;/p&gt;
&lt;p&gt;
AMRFact&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#21033;&#29992;AMR&#29983;&#25104;&#36127;&#26679;&#26412;&#65292;&#22686;&#24378;&#20102;&#25688;&#35201;&#20107;&#23454;&#24615;&#35780;&#20272;&#65292;&#29983;&#25104;&#30340;&#36830;&#36143;&#19988;&#20107;&#23454;&#19981;&#19968;&#33268;&#30340;&#25688;&#35201;&#20855;&#26377;&#39640;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#20445;&#20107;&#23454;&#19968;&#33268;&#24615;&#23545;&#20110;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#25552;&#21462;&#24335;&#25688;&#35201;&#20013;&#65292;&#20445;&#25345;&#20449;&#24687;&#30340;&#23436;&#25972;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#20197;&#21069;&#20851;&#20110;&#35780;&#20272;&#25688;&#35201;&#30340;&#20107;&#23454;&#19968;&#33268;&#24615;&#30340;&#24037;&#20316;&#36890;&#24120;&#37319;&#29992;&#22522;&#20110;&#34164;&#28085;&#30340;&#26041;&#27861;&#65292;&#39318;&#20808;&#29983;&#25104;&#25200;&#21160;&#65288;&#20107;&#23454;&#19981;&#19968;&#33268;&#65289;&#25688;&#35201;&#65292;&#28982;&#21518;&#22312;&#29983;&#25104;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#19968;&#20010;&#20998;&#31867;&#22120;&#65292;&#22312;&#27979;&#35797;&#26102;&#26816;&#27979;&#20107;&#23454;&#19981;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#29983;&#25104;&#25200;&#21160;&#25688;&#35201;&#30340;&#26041;&#27861;&#35201;&#20040;&#32570;&#20047;&#36830;&#36143;&#24615;&#65292;&#35201;&#20040;&#32570;&#20047;&#38169;&#35823;&#31867;&#22411;&#35206;&#30422;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AMRFact&#65292;&#19968;&#20010;&#21033;&#29992;&#25277;&#35937;&#24847;&#20041;&#34920;&#31034;&#65288;AMR&#65289;&#29983;&#25104;&#25200;&#21160;&#25688;&#35201;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#20107;&#23454;&#19968;&#33268;&#30340;&#25688;&#35201;&#35299;&#26512;&#20026;AMR&#22270;&#65292;&#24182;&#27880;&#20837;&#21487;&#25511;&#30340;&#20107;&#23454;&#19981;&#19968;&#33268;&#65292;&#20197;&#21019;&#24314;&#36127;&#38754;&#31034;&#20363;&#65292;&#20801;&#35768;&#29983;&#25104;&#20855;&#26377;&#39640;&#38169;&#35823;&#29575;&#30340;&#36830;&#36143;&#20107;&#23454;&#19981;&#19968;&#33268;&#30340;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09521v2 Announce Type: replace  Abstract: Ensuring factual consistency is crucial for natural language generation tasks, particularly in abstractive summarization, where preserving the integrity of information is paramount. Prior works on evaluating factual consistency of summarization often take the entailment-based approaches that first generate perturbed (factual inconsistent) summaries and then train a classifier on the generated data to detect the factually inconsistencies during testing time. However, previous approaches generating perturbed summaries are either of low coherence or lack error-type coverage. To address these issues, we propose AMRFact, a framework that generates perturbed summaries using Abstract Meaning Representations (AMRs). Our approach parses factually consistent summaries into AMR graphs and injects controlled factual inconsistencies to create negative examples, allowing for coherent factually inconsistent summaries to be generated with high error
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LINK&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#31995;&#32479;&#24615;&#22320;&#29983;&#25104;&#38271;&#23614;&#25512;&#29702;&#30693;&#35782;&#65292;&#20174;&#32780;&#26356;&#26377;&#25928;&#22320;&#35780;&#20272;LLMs&#22312;&#25512;&#29702;&#31354;&#38388;&#20013;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2311.07237</link><description>&lt;p&gt;
&#22312;&#25628;&#32034;&#38271;&#23614;&#20013;&#65306;&#36890;&#36807;&#36923;&#36753;&#35268;&#21017;&#24341;&#23548;&#25628;&#32034;&#31995;&#32479;&#24615;&#29983;&#25104;&#38271;&#23614;&#25512;&#29702;&#30693;&#35782;
&lt;/p&gt;
&lt;p&gt;
In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07237
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LINK&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#31995;&#32479;&#24615;&#22320;&#29983;&#25104;&#38271;&#23614;&#25512;&#29702;&#30693;&#35782;&#65292;&#20174;&#32780;&#26356;&#26377;&#25928;&#22320;&#35780;&#20272;LLMs&#22312;&#25512;&#29702;&#31354;&#38388;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;LLMs&#22312;&#35832;&#22914;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#31561;&#25512;&#29702;&#20219;&#21153;&#19978;&#32988;&#36807;&#20154;&#31867;&#12290;&#26368;&#36817;&#35780;&#20272;LLMs&#30340;&#30740;&#31350;&#25351;&#20986;&#65292;&#22312;&#26469;&#33258;&#20302;&#27010;&#29575;&#20998;&#24067;&#8212;&#8212;&#21363;&#38271;&#23614;&#30340;&#36755;&#20837;&#25968;&#25454;&#19978;&#34920;&#29616;&#22823;&#24133;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#31995;&#32479;&#29983;&#25104;&#28041;&#21450;&#38271;&#23614;&#25512;&#29702;&#30693;&#35782;&#30340;&#35821;&#21477;&#65292;&#20197;&#26356;&#26377;&#25928;&#22320;&#35780;&#20272;LLMs&#22312;&#25512;&#29702;&#31354;&#38388;&#20013;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;Logic-Induced-Knowledge-Search&#65288;LINK&#65289;&#65292;&#35813;&#26694;&#26550;&#29983;&#25104;&#22522;&#20110;&#31526;&#21495;&#35268;&#21017;&#27169;&#26495;&#30340;&#20107;&#23454;&#27491;&#30830;&#19988;&#38271;&#23614;&#30693;&#35782;&#35821;&#21477;&#65307;LINK&#26377;&#25928;&#22320;&#29983;&#25104;&#38271;&#23614;&#20998;&#24067;&#25968;&#25454;&#65292;&#38646;-shot&#25552;&#31034;&#30340;LLMs&#26080;&#27861;&#21040;&#36798;&#65292;&#24182;&#19988;&#22312;&#20107;&#23454;&#27491;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#38646;-shot GPT4&#36798;&#21040;5%&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20351;&#29992;LINK&#29983;&#25104;&#30340;&#25968;&#25454;&#26500;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;Logic-Induced-Long-Tail&#65288;LINT&#65289;&#30340;&#25968;&#25454;&#38598;&#65292;&#21487;&#29992;&#20110;&#35780;&#20272;&#38271;&#23614;&#20998;&#24067;&#19978;&#30340;&#19979;&#28216;&#27169;&#22411;&#65307;LINT&#21253;&#21547;108K&#20010;&#30693;&#35782;&#26465;&#30446;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07237v2 Announce Type: replace-cross  Abstract: State-of-the-art LLMs outperform humans on reasoning tasks such as Natural Language Inference. Recent works evaluating LLMs note a marked performance drop on input data from the low-probability distribution, i.e., the longtail. Therefore, we focus on systematically generating statements involving long-tail inferential knowledge for more effective evaluation of LLMs in the reasoning space. We first propose a novel framework Logic-Induced- Knowledge-Search (LINK) that generates factually correct and long-tail knowledge statements grounded on symbolic rule templates; LINK effectively generates data in the longtail distribution that zero-shot prompted LLMs are unable to reach, and outperforms zero-shot GPT4 on factual correctness by 5%. We further use the data generated by LINK to construct a dataset Logic-Induced-Long-Tail (LINT) that can be used to evaluate downstream models on the long-tail distribution; LINT contains 108K knowl
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;SLANG&#65292;&#26088;&#22312;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;LLMs&#23545;&#20114;&#32852;&#32593;&#19978;&#26032;&#27010;&#24565;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#20934;&#26041;&#27861;FOCUS&#65292;&#33021;&#24110;&#21161;LLMs&#26356;&#22909;&#22320;&#29702;&#35299;&#26032;&#30340;&#30701;&#35821;&#21644;&#29992;&#27861;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.12585</link><description>&lt;p&gt;
SLANG: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26032;&#27010;&#24565;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
SLANG: New Concept Comprehension of Large Language Models. (arXiv:2401.12585v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;SLANG&#65292;&#26088;&#22312;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;LLMs&#23545;&#20114;&#32852;&#32593;&#19978;&#26032;&#27010;&#24565;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#20934;&#26041;&#27861;FOCUS&#65292;&#33021;&#24110;&#21161;LLMs&#26356;&#22909;&#22320;&#29702;&#35299;&#26032;&#30340;&#30701;&#35821;&#21644;&#29992;&#27861;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#30340;&#21160;&#24577;&#24615;&#65292;&#23588;&#20854;&#22312;&#20114;&#32852;&#32593;&#19978;&#30340;&#20442;&#35821;&#21644;&#34920;&#24773;&#21253;&#31561;&#26041;&#38754;&#30340;&#20307;&#29616;&#65292;&#32473;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36866;&#24212;&#24615;&#24102;&#26469;&#20102;&#20005;&#23803;&#25361;&#25112;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20165;&#32465;&#23450;&#22312;&#38745;&#24577;&#25968;&#25454;&#38598;&#19978;&#65292;&#24456;&#38590;&#36319;&#19978;&#22312;&#32447;&#31038;&#21306;&#20013;&#24555;&#36895;&#35821;&#35328;&#36827;&#21270;&#30340;&#27493;&#20240;&#12290;&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#30340;&#36843;&#20999;&#38656;&#27714;&#65292;&#26088;&#22312;&#22686;&#24378;LLMs&#23545;&#20114;&#32852;&#32593;&#19978;&#26032;&#27010;&#24565;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#21516;&#26102;&#36991;&#20813;&#39640;&#25104;&#26412;&#21644;&#19981;&#20999;&#23454;&#38469;&#30340;&#25345;&#32493;&#37325;&#35757;&#32451;&#12290;&#20026;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35780;&#20272;LLMs&#22312;&#29702;&#35299;&#26032;&#20852;&#35821;&#35328;&#36235;&#21183;&#26041;&#38754;&#33021;&#21147;&#30340;&#22522;&#20934; - SLANG&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#20934;&#26041;&#27861; FOCUS&#65292;&#23427;&#33021;&#22686;&#24378;LLMs&#23545;&#26032;&#30340;&#30701;&#35821;&#21644;&#29992;&#27861;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#23545;&#35821;&#35328;&#36716;&#21464;&#30340;&#30495;&#23454;&#19990;&#30028;&#23454;&#20363;&#36827;&#34892;&#35814;&#32454;&#30740;&#31350;&#65292;&#20316;&#20026;&#32972;&#26223;&#20381;&#25454;&#65292;&#20197;&#24418;&#25104;&#26356;&#31934;&#30830;&#21644;&#20855;&#26377;&#19978;&#19979;&#25991;&#30456;&#20851;&#24615;&#30340;&#26032;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
The dynamic nature of language, particularly evident in the realm of slang and memes on the Internet, poses serious challenges to the adaptability of large language models (LLMs). Traditionally anchored to static datasets, these models often struggle to keep up with the rapid linguistic evolution characteristic of online communities. This research addresses the critical need to bridge this gap, aiming to enhance LLMs' comprehension of evolving new concepts on the internet, without the high cost and impracticality of continual retraining. To address this issue, we propose a new benchmark $\textbf{SLANG}$ to assess LLMs' proficiency in comprehending emerging linguistic trends and a baseline approach $\textbf{FOCUS}$, which uses causal inference to enhance LLMs to understand new phrases and usage patterns. This approach involves scrutinizing real-world instances of linguistic shifts, serving as contextual beacons, to form more precise and contextually relevant connections between newly em
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26469;&#25913;&#21892;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#20195;&#30721;&#32763;&#35793;&#12290;&#36890;&#36807;&#26500;&#24314;&#21487;&#27604;&#36739;&#30340;&#35821;&#26009;&#24211;&#21644;&#22686;&#21152;&#22810;&#20010;&#21442;&#32771;&#32763;&#35793;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;CodeT5&#22312;Java&#12289;Python&#21644;C++&#20043;&#38388;&#30340;&#32763;&#35793;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.00317</link><description>&lt;p&gt;
&#29992;&#21487;&#27604;&#36739;&#30340;&#35821;&#26009;&#21644;&#22810;&#20010;&#21442;&#32771;&#25991;&#29486;&#36827;&#34892;&#20195;&#30721;&#32763;&#35793;&#30340;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Data Augmentation for Code Translation with Comparable Corpora and Multiple References. (arXiv:2311.00317v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00317
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26469;&#25913;&#21892;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#20195;&#30721;&#32763;&#35793;&#12290;&#36890;&#36807;&#26500;&#24314;&#21487;&#27604;&#36739;&#30340;&#35821;&#26009;&#24211;&#21644;&#22686;&#21152;&#22810;&#20010;&#21442;&#32771;&#32763;&#35793;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;CodeT5&#22312;Java&#12289;Python&#21644;C++&#20043;&#38388;&#30340;&#32763;&#35793;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#36827;&#34892;&#20195;&#30721;&#32763;&#35793;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#24179;&#34892;&#35757;&#32451;&#25968;&#25454;&#36890;&#24120;&#26377;&#38480;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#65292;&#19968;&#31181;&#26159;&#26500;&#24314;&#21487;&#27604;&#36739;&#30340;&#35821;&#26009;&#24211;&#65288;&#21363;&#20855;&#26377;&#31867;&#20284;&#21151;&#33021;&#30340;&#20195;&#30721;&#23545;&#65289;&#65292;&#21478;&#19968;&#31181;&#26159;&#29992;&#22810;&#20010;&#21442;&#32771;&#32763;&#35793;&#26469;&#22686;&#24378;&#29616;&#26377;&#30340;&#24179;&#34892;&#25968;&#25454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#24182;&#20998;&#26512;&#20102;&#22810;&#31181;&#31867;&#22411;&#30340;&#21487;&#27604;&#36739;&#30340;&#35821;&#26009;&#24211;&#65292;&#21253;&#25324;&#20351;&#29992;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#20174;&#33258;&#28982;&#35821;&#35328;&#25991;&#26723;&#20013;&#29983;&#25104;&#30340;&#31243;&#24207;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20943;&#23569;&#23545;&#21333;&#20010;&#21442;&#32771;&#32763;&#35793;&#30340;&#36807;&#25311;&#21512;&#65292;&#25105;&#20204;&#33258;&#21160;&#29983;&#25104;&#20102;&#21487;&#29992;&#24179;&#34892;&#25968;&#25454;&#30340;&#39069;&#22806;&#32763;&#35793;&#21442;&#32771;&#65292;&#24182;&#36890;&#36807;&#21333;&#20803;&#27979;&#35797;&#23545;&#32763;&#35793;&#36827;&#34892;&#31579;&#36873;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#30446;&#26631;&#32763;&#35793;&#30340;&#21464;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#26174;&#33879;&#25552;&#39640;&#20102;CodeT5&#22312;Java&#12289;Python&#21644;C++&#20043;&#38388;&#30340;&#32763;&#35793;&#20934;&#30830;&#24615;&#65288;&#24179;&#22343;&#25552;&#21319;&#20102;7.5%&#30340;&#35745;&#31639;&#20934;&#30830;&#24615;&#65288;CA@1&#65289;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
One major challenge of translating code between programming languages is that parallel training data is often limited. To overcome this challenge, we present two data augmentation techniques, one that builds comparable corpora (i.e., code pairs with similar functionality), and another that augments existing parallel data with multiple reference translations. Specifically, we build and analyze multiple types of comparable corpora, including programs generated from natural language documentation using a code generation model. Furthermore, to reduce overfitting to a single reference translation, we automatically generate additional translation references for available parallel data and filter the translations by unit tests, which increases variation in target translations. Experiments show that our data augmentation techniques significantly improve CodeT5 for translation between Java, Python, and C++ by an average of 7.5% Computational Accuracy (CA@1), which verifies the correctness of tr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23398;&#20064;&#20010;&#24615;&#21270;&#25925;&#20107;&#35780;&#20272;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24320;&#25918;&#24335;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#30340;&#35780;&#20272;&#38382;&#39064;&#65292;&#35770;&#25991;&#21019;&#24314;&#20102;&#20004;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25925;&#20107;&#35780;&#20272;&#27169;&#22411;&#65292;&#33021;&#22815;&#26681;&#25454;&#35780;&#23457;&#20154;&#21592;&#30340;&#31034;&#20363;&#35780;&#20215;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.03304</link><description>&lt;p&gt;
&#23398;&#20064;&#20010;&#24615;&#21270;&#25925;&#20107;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Learning Personalized Story Evaluation. (arXiv:2310.03304v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03304
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23398;&#20064;&#20010;&#24615;&#21270;&#25925;&#20107;&#35780;&#20272;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24320;&#25918;&#24335;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#30340;&#35780;&#20272;&#38382;&#39064;&#65292;&#35770;&#25991;&#21019;&#24314;&#20102;&#20004;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25925;&#20107;&#35780;&#20272;&#27169;&#22411;&#65292;&#33021;&#22815;&#26681;&#25454;&#35780;&#23457;&#20154;&#21592;&#30340;&#31034;&#20363;&#35780;&#20215;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#35832;&#22914;&#38382;&#31572;&#21644;&#26816;&#32034;&#31561;&#26356;&#23458;&#35266;&#30340;&#20219;&#21153;&#19978;&#26174;&#31034;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20294;&#35780;&#20272;&#23427;&#20204;&#22312;&#24320;&#25918;&#24335;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#30340;&#34920;&#29616;&#20173;&#28982;&#26159;&#19968;&#20010;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#21407;&#22240;&#21253;&#25324;&#65288;1&#65289;&#25968;&#25454;&#27745;&#26579;&#65307;&#65288;2&#65289;&#22810;&#32500;&#35780;&#20272;&#26631;&#20934;&#65307;&#20197;&#21450;&#65288;3&#65289;&#26469;&#33258;&#35780;&#23457;&#20154;&#21592;&#20010;&#20154;&#20559;&#22909;&#30340;&#20027;&#35266;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#22312;&#19968;&#20010;&#26080;&#27745;&#26579;&#30340;&#24320;&#25918;&#24335;&#29983;&#25104;&#35780;&#20272;&#20013;&#24314;&#27169;&#20010;&#24615;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#36866;&#24403;&#30340;&#21311;&#21517;&#21270;&#21644;&#26032;&#30340;&#20010;&#24615;&#21270;&#26631;&#31614;&#65292;&#37325;&#26032;&#21033;&#29992;&#29616;&#26377;&#25968;&#25454;&#38598;&#21019;&#24314;&#20102;&#20004;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;Per-MPST&#21644;Per-DOC&#29992;&#20110;&#20010;&#24615;&#21270;&#25925;&#20107;&#35780;&#20272;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25925;&#20107;&#35780;&#20272;&#27169;&#22411;PERSE&#26469;&#25512;&#27979;&#35780;&#23457;&#20154;&#21592;&#30340;&#20559;&#22909;&#65292;&#24182;&#25552;&#20379;&#20010;&#24615;&#21270;&#35780;&#20272;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#26576;&#20010;&#35780;&#23457;&#20154;&#21592;&#30340;&#19968;&#20123;&#31034;&#20363;&#35780;&#20215;&#65292;PERSE&#21487;&#20197;&#39044;&#27979;&#35813;&#35780;&#23457;&#20154;&#21592;&#22312;&#26032;&#30340;&#24773;&#33410;&#19978;&#30340;&#35814;&#32454;&#35780;&#23457;&#25110;&#32454;&#31890;&#24230;&#27604;&#36739;&#65288;&#22914;&#36259;&#21619;&#24615;&#21644;&#24778;&#21916;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
While large language models (LLMs) have shown impressive results for more objective tasks such as QA and retrieval, it remains nontrivial to evaluate their performance on open-ended text generation for reasons including (1) data contamination; (2) multi-dimensional evaluation criteria; and (3) subjectiveness stemming from reviewers' personal preferences. To address such issues, we propose to model personalization in an uncontaminated open-ended generation assessment. We create two new datasets Per-MPST and Per-DOC for personalized story evaluation, by re-purposing existing datasets with proper anonymization and new personalized labels. We further develop a personalized story evaluation model PERSE to infer reviewer preferences and provide a personalized evaluation. Specifically, given a few exemplary reviews from a particular reviewer, PERSE predicts either a detailed review or fine-grained comparison in several aspects (such as interestingness and surprise) for that reviewer on a new 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#37319;&#29992;&#29305;&#36136;&#29702;&#35770;&#26694;&#26550;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;ChatGPT&#22987;&#32456;&#34920;&#29616;&#20986;ENFJ&#22411;&#20154;&#26684;&#65292;&#26080;&#35770;&#25351;&#20196;&#25110;&#24773;&#22659;&#22914;&#20309;&#12290;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#30340;&#20010;&#24615;&#21270;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#20154;&#19982;&#26426;&#22120;&#20043;&#38388;&#26356;&#22909;&#30340;&#27807;&#36890;&#21644;&#21327;&#20316;&#12290;</title><link>http://arxiv.org/abs/2305.19926</link><description>&lt;p&gt;
ChatGPT&#26159;ENFJ&#65292;Bard&#26159;ISTJ&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#24615;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
ChatGPT an ENFJ, Bard an ISTJ: Empirical Study on Personalities of Large Language Models. (arXiv:2305.19926v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#37319;&#29992;&#29305;&#36136;&#29702;&#35770;&#26694;&#26550;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;ChatGPT&#22987;&#32456;&#34920;&#29616;&#20986;ENFJ&#22411;&#20154;&#26684;&#65292;&#26080;&#35770;&#25351;&#20196;&#25110;&#24773;&#22659;&#22914;&#20309;&#12290;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#30340;&#20010;&#24615;&#21270;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#20154;&#19982;&#26426;&#22120;&#20043;&#38388;&#26356;&#22909;&#30340;&#27807;&#36890;&#21644;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#22823;&#22823;&#37325;&#22609;&#20102;&#20154;&#26426;&#20132;&#20114;&#12290;&#25105;&#20204;&#19981;&#20165;&#20851;&#27880;LLMs&#30340;&#24615;&#33021;&#65292;&#36824;&#20174;&#24515;&#29702;&#23398;&#35282;&#24230;&#25506;&#32034;&#23427;&#20204;&#30340;&#29305;&#28857;&#65292;&#35748;&#35782;&#21040;&#20102;&#29702;&#35299;&#23427;&#20204;&#34892;&#20026;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#30740;&#31350;&#37319;&#29992;&#24515;&#29702;&#23398;&#30340;&#19968;&#20010;&#26694;&#26550;&#8212;&#8212;&#29305;&#36136;&#29702;&#35770;&#30740;&#31350;LLMs&#25152;&#23637;&#31034;&#30340;&#34892;&#20026;&#27169;&#24335;&#12290;&#25105;&#20204;&#39318;&#20808;&#20851;&#27880;&#35780;&#20272;ChatGPT&#25152;&#23637;&#31034;&#30340;&#20154;&#26684;&#31867;&#22411;&#30340;&#19968;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#23454;&#39564;&#28041;&#21450;&#19971;&#31181;&#38468;&#21152;&#35821;&#35328;&#30340;&#36328;&#35821;&#35328;&#24433;&#21709;&#65292;&#20197;&#21450;&#20845;&#31181;&#20854;&#20182;LLMs&#30340;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#35843;&#26597;&#20102;ChatGPT&#26159;&#21542;&#33021;&#22815;&#23637;&#31034;&#23545;&#25351;&#20196;&#25110;&#24773;&#22659;&#32447;&#32034;&#30340;&#20154;&#26684;&#21464;&#21270;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#26080;&#35770;&#25351;&#20196;&#25110;&#24773;&#22659;&#22914;&#20309;&#65292;ChatGPT&#22987;&#32456;&#20445;&#25345;&#20854;ENFJ&#20154;&#26684;&#12290;&#36890;&#36807;&#25581;&#31034;LLMs&#30340;&#20010;&#24615;&#21270;&#65292;&#25105;&#20204;&#39044;&#35745;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#20419;&#36827;&#20154;&#19982;&#26426;&#22120;&#20043;&#38388;&#26356;&#22909;&#30340;&#27807;&#36890;&#21644;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have made remarkable advancements in the field of artificial intelligence, significantly reshaping the human-computer interaction. We not only focus on the performance of LLMs, but also explore their features from a psychological perspective, acknowledging the importance of understanding their behavioral characteristics. Our study examines the behavioral patterns displayed by LLMs by employing trait theory, a psychological framework. We first focus on evaluating the consistency of personality types exhibited by ChatGPT. Furthermore, experiments include cross-lingual effects on seven additional languages, and the investigation of six other LLMs. Moreover, the study investigates whether ChatGPT can exhibit personality changes in response to instructions or contextual cues. The findings show that ChatGPT consistently maintains its ENFJ personality regardless of instructions or contexts. By shedding light on the personalization of LLMs, we anticipate that our s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;SMILE&#26041;&#27861;&#65292;&#20351;&#29992;ChatGPT&#23558;&#20844;&#20849;&#21333;&#36718;&#23545;&#35805;&#25193;&#23637;&#20026;&#22810;&#36718;&#23545;&#35805;&#65292;&#29983;&#25104;&#20102;&#22823;&#35268;&#27169;&#12289;&#22810;&#26679;&#21270;&#12289;&#25509;&#36817;&#30495;&#23454;&#29983;&#27963;&#30340;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#35821;&#26009;&#24211;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#19987;&#38376;&#30340;&#23545;&#35805;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2305.00450</link><description>&lt;p&gt;
SMILE&#65306;&#21033;&#29992;ChatGPT&#23454;&#29616;&#21333;&#36718;&#21040;&#22810;&#36718;&#21253;&#23481;&#24615;&#35821;&#35328;&#25193;&#23637;&#30340;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support. (arXiv:2305.00450v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;SMILE&#26041;&#27861;&#65292;&#20351;&#29992;ChatGPT&#23558;&#20844;&#20849;&#21333;&#36718;&#23545;&#35805;&#25193;&#23637;&#20026;&#22810;&#36718;&#23545;&#35805;&#65292;&#29983;&#25104;&#20102;&#22823;&#35268;&#27169;&#12289;&#22810;&#26679;&#21270;&#12289;&#25509;&#36817;&#30495;&#23454;&#29983;&#27963;&#30340;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#35821;&#26009;&#24211;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#19987;&#38376;&#30340;&#23545;&#35805;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#19987;&#38376;&#30340;&#23545;&#35805;&#31995;&#32479;&#20197;&#25552;&#20379;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#24050;&#25104;&#20026;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#28857;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20010;&#20154;&#20449;&#24687;&#30340;&#25935;&#24863;&#24615;&#20197;&#21450;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#65292;&#33719;&#21462;&#22823;&#35268;&#27169;&#30340;&#30495;&#23454;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SMILE&#26041;&#27861;&#65292;&#19968;&#31181;&#20351;&#29992;ChatGPT&#23558;&#20844;&#20849;&#21333;&#36718;&#23545;&#35805;&#25193;&#23637;&#20026;&#22810;&#36718;&#23545;&#35805;&#30340;&#21253;&#23481;&#24615;&#35821;&#35328;&#25193;&#23637;&#25216;&#26415;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#21021;&#27493;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#39564;&#35777;&#20102;SMILE&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#20351;&#29992;&#21644;&#26410;&#20351;&#29992;SMILE&#26041;&#27861;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#20840;&#38754;&#31995;&#32479;&#30340;&#23545;&#27604;&#20998;&#26512;&#65292;&#35777;&#26126;SMILE&#26041;&#27861;&#21487;&#20197;&#20135;&#29983;&#22823;&#35268;&#27169;&#12289;&#22810;&#26679;&#21270;&#12289;&#25509;&#36817;&#30495;&#23454;&#29983;&#27963;&#30340;&#22810;&#36718;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#35821;&#26009;&#24211;&#65292;&#21253;&#25324;&#23545;&#35805;&#20027;&#39064;&#12289;&#35789;&#27719;&#21644;&#35821;&#20041;&#29305;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#25910;&#38598;&#30340;&#35821;&#26009;&#24211;&#26469;&#35757;&#32451;&#21644;&#35780;&#20272;&#19987;&#38376;&#30340;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#23545;&#35805;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been an increasing research interest in developing specialized dialogue systems that can offer mental health support. However, gathering large-scale and real-life multi-turn conversations for mental health support poses challenges due to the sensitivity of personal information, as well as the time and cost involved. To address these issues, we introduce the SMILE approach, an inclusive language expansion technique that employs ChatGPT to extend public single-turn dialogues into multi-turn ones. Our research first presents a preliminary exploratory study that validates the effectiveness of the SMILE approach. Furthermore, we conduct a comprehensive and systematic contrastive analysis of datasets generated with and without the SMILE approach, demonstrating that the SMILE method results in a large-scale, diverse, and close-to-real-life multi-turn mental health support conversation corpus, including dialog topics, lexical and semantic features. Finally, we use the collected corpu
&lt;/p&gt;</description></item></channel></rss>