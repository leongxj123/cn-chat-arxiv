<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#38271;&#31687;&#22238;&#24212;&#20998;&#35299;&#20026;&#21333;&#20010;&#20107;&#23454;&#65292;&#24182;&#36890;&#36807;&#21457;&#36865;&#25628;&#32034;&#26597;&#35810;&#21040;Google&#25628;&#32034;&#65292;&#35780;&#20272;&#20107;&#23454;&#20934;&#30830;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;F1&#20998;&#25968;&#20316;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#32858;&#21512;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.18802</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#38271;&#31687;&#20107;&#23454;&#24615;
&lt;/p&gt;
&lt;p&gt;
Long-form factuality in large language models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18802
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#38271;&#31687;&#22238;&#24212;&#20998;&#35299;&#20026;&#21333;&#20010;&#20107;&#23454;&#65292;&#24182;&#36890;&#36807;&#21457;&#36865;&#25628;&#32034;&#26597;&#35810;&#21040;Google&#25628;&#32034;&#65292;&#35780;&#20272;&#20107;&#23454;&#20934;&#30830;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;F1&#20998;&#25968;&#20316;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#32858;&#21512;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22238;&#31572;&#24320;&#25918;&#24615;&#20027;&#39064;&#30340;&#20107;&#23454;&#24615;&#25552;&#31034;&#26102;&#65292;&#32463;&#24120;&#29983;&#25104;&#21253;&#21547;&#20107;&#23454;&#38169;&#35823;&#30340;&#20869;&#23481;&#12290;&#20026;&#20102;&#22312;&#24320;&#25918;&#39046;&#22495;&#20013;&#23545;&#27169;&#22411;&#30340;&#38271;&#31687;&#20107;&#23454;&#24615;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;GPT-4&#29983;&#25104;&#20102;&#19968;&#20010;&#21517;&#20026;LongFact&#30340;&#25552;&#31034;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#25968;&#21315;&#20010;&#22218;&#25324;38&#20010;&#20027;&#39064;&#30340;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;LLM&#20195;&#29702;&#21487;&#20197;&#36890;&#36807;&#19968;&#31181;&#21517;&#20026;Search-Augmented Factuality Evaluator&#65288;SAFE&#65289;&#30340;&#26041;&#27861;&#20316;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#33258;&#21160;&#35780;&#20272;&#22120;&#12290;SAFE&#21033;&#29992;LLM&#23558;&#38271;&#31687;&#22238;&#24212;&#20998;&#35299;&#20026;&#19968;&#32452;&#21333;&#29420;&#30340;&#20107;&#23454;&#65292;&#24182;&#36890;&#36807;&#21457;&#36865;&#25628;&#32034;&#26597;&#35810;&#21040;Google&#25628;&#32034;&#20197;&#21450;&#30830;&#23450;&#19968;&#20010;&#20107;&#23454;&#26159;&#21542;&#24471;&#21040;&#25628;&#32034;&#32467;&#26524;&#25903;&#25345;&#30340;&#22810;&#27493;&#25512;&#29702;&#36807;&#31243;&#26469;&#35780;&#20272;&#27599;&#20010;&#20107;&#23454;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#35758;&#23558;F1&#20998;&#25968;&#25193;&#23637;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#32858;&#21512;&#24230;&#37327;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24179;&#34913;&#20102;&#22238;&#24212;&#20013;&#25903;&#25345;&#20107;&#23454;&#30340;&#30334;&#20998;&#27604;&#65288;&#31934;&#24230;&#65289;&#19982;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18802v1 Announce Type: cross  Abstract: Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.00867</link><description>&lt;p&gt;
&#26799;&#24230;&#34987;&#32602;&#65306;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#38024;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#27491;&#25104;&#20026;&#19968;&#31181;&#31361;&#20986;&#30340;&#29983;&#25104;&#24335;AI&#24037;&#20855;&#65292;&#29992;&#25143;&#36755;&#20837;&#26597;&#35810;&#65292;LLM&#29983;&#25104;&#31572;&#26696;&#12290;&#20026;&#20102;&#20943;&#23569;&#20260;&#23475;&#21644;&#28389;&#29992;&#65292;&#20154;&#20204;&#36890;&#36807;&#20351;&#29992;&#20808;&#36827;&#30340;&#35757;&#32451;&#25216;&#26415;&#22914;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26469;&#23558;&#36825;&#20123;LLMs&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#31361;&#26174;&#20102;LLMs&#23545;&#20110;&#35797;&#22270;&#39072;&#35206;&#23884;&#20837;&#30340;&#23433;&#20840;&#38450;&#25252;&#25514;&#26045;&#30340;&#23545;&#25239;&#24615;&#36234;&#29425;&#23581;&#35797;&#30340;&#33030;&#24369;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#23450;&#20041;&#24182;&#35843;&#26597;&#20102;LLMs&#30340;&#25298;&#32477;&#25439;&#22833;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#36234;&#29425;&#23581;&#35797;&#12290;Gradient Cuff&#21033;&#29992;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#20013;&#35266;&#23519;&#21040;&#30340;&#29420;&#29305;&#29305;&#24615;&#65292;&#21253;&#25324;&#21151;&#33021;&#20540;&#21450;&#20854;&#20809;&#28369;&#24615;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00867v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#24494;&#35843;&#21644;&#38646;&#26679;&#26412;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#22312;&#20027;&#35266;&#20219;&#21153;&#20013;&#21457;&#29616;&#20010;&#24615;&#21270;&#24494;&#35843;&#33021;&#25552;&#39640;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#22312;&#24773;&#24863;&#35782;&#21035;&#21644;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#26041;&#38754;&#20063;&#33719;&#24471;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.09269</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Personalized Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#24494;&#35843;&#21644;&#38646;&#26679;&#26412;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#22312;&#20027;&#35266;&#20219;&#21153;&#20013;&#21457;&#29616;&#20010;&#24615;&#21270;&#24494;&#35843;&#33021;&#25552;&#39640;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#22312;&#24773;&#24863;&#35782;&#21035;&#21644;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#26041;&#38754;&#20063;&#33719;&#24471;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#36890;&#29992;&#24615;&#22312;&#38656;&#35201;&#20010;&#24615;&#21270;&#22238;&#24212;&#30340;&#22330;&#26223;&#65288;&#22914;&#25512;&#33616;&#31995;&#32479;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#65289;&#20013;&#23384;&#22312;&#19968;&#23450;&#30340;&#23616;&#38480;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;LLM&#30340;&#26041;&#27861;&#65292;&#27604;&#36739;&#20102;&#24494;&#35843;&#21644;&#38646;&#26679;&#26412;&#25512;&#29702;&#26041;&#27861;&#22312;&#20027;&#35266;&#20219;&#21153;&#20013;&#30340;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#38750;&#20010;&#24615;&#21270;&#27169;&#22411;&#30456;&#27604;&#65292;&#20010;&#24615;&#21270;&#24494;&#35843;&#25913;&#21892;&#20102;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#22312;&#24773;&#24863;&#35782;&#21035;&#21644;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#20010;&#24615;&#21270;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;LLM&#26550;&#26500;&#19978;&#33719;&#24471;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20027;&#35266;&#25991;&#26412;&#29702;&#35299;&#20219;&#21153;&#20013;&#25552;&#21319;LLM&#33021;&#21147;&#30340;&#20010;&#24615;&#21270;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09269v1 Announce Type: cross Abstract: Large language models (LLMs) have significantly advanced Natural Language Processing (NLP) tasks in recent years. However, their universal nature poses limitations in scenarios requiring personalized responses, such as recommendation systems and chatbots. This paper investigates methods to personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on subjective tasks. Results demonstrate that personalized fine-tuning improves model reasoning compared to non-personalized models. Experiments on datasets for emotion recognition and hate speech detection show consistent performance gains with personalized methods across different LLM architectures. These findings underscore the importance of personalization for enhancing LLM capabilities in subjective text perception tasks.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35757;&#32451;&#21482;&#38656;&#35201;&#20960;&#21313;&#23567;&#26102;&#24179;&#34892;&#35821;&#38899;&#25968;&#25454;&#30340;&#26080;&#25991;&#26412;&#20302;&#36164;&#28304;&#35821;&#38899;&#21040;&#35821;&#38899;&#32763;&#35793;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#21333;&#20803;&#21040;&#21333;&#20803;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#32763;&#35793;&#20219;&#21153;&#21644;&#26080;&#30417;&#30563;&#21453;&#21521;&#32763;&#35793;&#30446;&#26631;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;</title><link>https://arxiv.org/abs/2305.15405</link><description>&lt;p&gt;
&#20855;&#26377;&#21333;&#20803;&#35821;&#35328;&#27169;&#22411;&#30340;&#26080;&#25991;&#26412;&#20302;&#36164;&#28304;&#35821;&#38899;&#21040;&#35821;&#38899;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Textless Low-Resource Speech-to-Speech Translation With Unit Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2305.15405
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35757;&#32451;&#21482;&#38656;&#35201;&#20960;&#21313;&#23567;&#26102;&#24179;&#34892;&#35821;&#38899;&#25968;&#25454;&#30340;&#26080;&#25991;&#26412;&#20302;&#36164;&#28304;&#35821;&#38899;&#21040;&#35821;&#38899;&#32763;&#35793;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#21333;&#20803;&#21040;&#21333;&#20803;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#32763;&#35793;&#20219;&#21153;&#21644;&#26080;&#30417;&#30563;&#21453;&#21521;&#32763;&#35793;&#30446;&#26631;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#35821;&#38899;&#21040;&#35821;&#38899;&#32763;&#35793;&#27169;&#22411;&#22823;&#33268;&#20998;&#20026;&#20004;&#31867;&#65306;&#20351;&#29992;&#25968;&#30334;&#23567;&#26102;&#24179;&#34892;&#35821;&#38899;&#25968;&#25454;&#35757;&#32451;&#30340;&#26080;&#25991;&#26412;&#27169;&#22411;&#65292;&#25110;&#32773;&#23558;&#25991;&#26412;&#20316;&#20026;&#20013;&#38388;&#27493;&#39588;&#30340;&#26080;&#30417;&#30563;&#27169;&#22411;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#38480;&#21046;&#20102;&#20026;&#24191;&#27867;&#35821;&#35328;&#26500;&#24314;&#35821;&#38899;&#21040;&#35821;&#38899;&#32763;&#35793;&#27169;&#22411;&#30340;&#21487;&#33021;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#25490;&#38500;&#20102;&#20027;&#35201;&#21475;&#35821;&#30340;&#35821;&#35328;&#20197;&#21450;&#32570;&#20047;&#22823;&#35268;&#27169;&#24179;&#34892;&#35821;&#38899;&#25968;&#25454;&#30340;&#35821;&#35328;&#23545;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35757;&#32451;&#21482;&#38656;&#35201;&#20960;&#21313;&#23567;&#26102;&#24179;&#34892;&#35821;&#38899;&#25968;&#25454;&#30340;&#26080;&#25991;&#26412;&#20302;&#36164;&#28304;&#35821;&#38899;&#21040;&#35821;&#38899;&#32763;&#35793;&#65288;S2ST&#65289;&#31995;&#32479;&#12290;&#25105;&#20204;&#23558;S2ST&#37325;&#26032;&#26500;&#24314;&#20026;&#19968;&#20010;&#21333;&#20803;&#21040;&#21333;&#20803;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#32763;&#35793;&#20219;&#21153;&#65292;&#24182;&#39318;&#20808;&#22312;&#22823;&#35268;&#27169;&#21333;&#35821;&#35328;&#35821;&#38899;&#25968;&#25454;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#23569;&#37327;&#24179;&#34892;&#35821;&#38899;&#25968;&#25454;&#65288;$20-60$&#23567;&#26102;&#65289;&#23545;&#20854;&#36827;&#34892;&#24494;&#35843;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#26080;&#30417;&#30563;&#21453;&#21521;&#32763;&#35793;&#30446;&#26631;&#25913;&#21892;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#20026;&#33521;&#35821;&#21040;&#24503;&#35821;&#65292;&#24503;&#35821;
&lt;/p&gt;
&lt;p&gt;
arXiv:2305.15405v2 Announce Type: replace  Abstract: Existing speech-to-speech translation models fall into two camps: textless models trained with hundreds of hours of parallel speech data or unsupervised models that leverage text as an intermediate step. Both approaches limit building speech-to-speech translation models for a wide range of languages, as they exclude languages that are primarily spoken and language pairs that lack large-scale parallel speech data. We present a new framework for training textless low-resource speech-to-speech translation (S2ST) systems that only need dozens of hours of parallel speech data. We reformulate S2ST as a unit-to-unit seq2seq translation task, and start by pretraining a model on large-scale monolingual speech data. Then, we finetune it with a small amount of parallel speech data ($20-60$ hours). Lastly, we improve model performance through an unsupervised backtranslation objective. We train and evaluate our models for English-to-German, Germa
&lt;/p&gt;</description></item><item><title>SciEval&#26159;&#19968;&#20010;&#32508;&#21512;&#19988;&#22810;&#23398;&#31185;&#30340;&#35780;&#20272;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31185;&#23398;&#30740;&#31350;&#20013;&#30340;&#33021;&#21147;&#12290;&#23427;&#22522;&#20110;&#24067;&#40065;&#22982;&#30340;&#20998;&#31867;&#27861;&#65292;&#21253;&#25324;&#23458;&#35266;&#21644;&#20027;&#35266;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#38450;&#27490;&#25968;&#25454;&#27844;&#28431;&#30340;&#8220;&#21160;&#24577;&#8221;&#23376;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;GPT-4&#22312;&#26576;&#20123;&#26041;&#38754;&#21462;&#24471;&#20102;&#36739;&#39640;&#30340;&#24471;&#20998;&#65292;&#20294;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.13149</link><description>&lt;p&gt;
SciEval: &#29992;&#20110;&#31185;&#23398;&#30740;&#31350;&#30340;&#22810;&#32423;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research. (arXiv:2308.13149v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13149
&lt;/p&gt;
&lt;p&gt;
SciEval&#26159;&#19968;&#20010;&#32508;&#21512;&#19988;&#22810;&#23398;&#31185;&#30340;&#35780;&#20272;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31185;&#23398;&#30740;&#31350;&#20013;&#30340;&#33021;&#21147;&#12290;&#23427;&#22522;&#20110;&#24067;&#40065;&#22982;&#30340;&#20998;&#31867;&#27861;&#65292;&#21253;&#25324;&#23458;&#35266;&#21644;&#20027;&#35266;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#38450;&#27490;&#25968;&#25454;&#27844;&#28431;&#30340;&#8220;&#21160;&#24577;&#8221;&#23376;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;GPT-4&#22312;&#26576;&#20123;&#26041;&#38754;&#21462;&#24471;&#20102;&#36739;&#39640;&#30340;&#24471;&#20998;&#65292;&#20294;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#31185;&#23398;&#30740;&#31350;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#22522;&#20934;&#26469;&#35780;&#20272;LLMs&#22312;&#31185;&#23398;&#30740;&#31350;&#20013;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#22522;&#20934;&#20027;&#35201;&#22522;&#20110;&#39044;&#20808;&#25910;&#38598;&#30340;&#23458;&#35266;&#38382;&#39064;&#12290;&#36825;&#31181;&#35774;&#35745;&#23384;&#22312;&#25968;&#25454;&#27844;&#28431;&#38382;&#39064;&#65292;&#24182;&#19988;&#32570;&#20047;&#23545;&#20027;&#35266;&#38382;&#31572;&#33021;&#21147;&#30340;&#35780;&#20272;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SciEval&#65292;&#36825;&#26159;&#19968;&#20010;&#32508;&#21512;&#12289;&#22810;&#23398;&#31185;&#30340;&#35780;&#20272;&#22522;&#20934;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#22522;&#20110;&#24067;&#40065;&#22982;&#30340;&#20998;&#31867;&#27861;&#65292;SciEval&#28085;&#30422;&#20102;&#22235;&#20010;&#32500;&#24230;&#26469;&#31995;&#32479;&#35780;&#20272;&#31185;&#23398;&#30740;&#31350;&#33021;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#31185;&#23398;&#21407;&#29702;&#30340;&#8220;&#21160;&#24577;&#8221;&#23376;&#38598;&#65292;&#20197;&#38450;&#27490;&#35780;&#20272;&#20986;&#29616;&#28508;&#22312;&#30340;&#25968;&#25454;&#27844;&#28431;&#12290;SciEval&#21253;&#21547;&#20102;&#23458;&#35266;&#21644;&#20027;&#35266;&#38382;&#39064;&#12290;&#36825;&#20123;&#29305;&#28857;&#20351;SciEval&#25104;&#20026;&#35780;&#20272;LLMs&#31185;&#23398;&#30740;&#31350;&#33021;&#21147;&#30340;&#26356;&#26377;&#25928;&#30340;&#22522;&#20934;&#12290;&#23545;&#26368;&#20808;&#36827;&#30340;LLMs&#36827;&#34892;&#20102;&#20840;&#38754;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;GPT-4&#21462;&#24471;&#20102;&#36739;&#39640;&#30340;&#24471;&#20998;&#65292;&#20294;&#22312;&#26576;&#20123;&#26041;&#38754;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been growing interest in using Large Language Models (LLMs) for scientific research. Numerous benchmarks have been proposed to evaluate the ability of LLMs for scientific research. However, current benchmarks are mostly based on pre-collected objective questions. This design suffers from data leakage problem and lacks the evaluation of subjective Q/A ability. In this paper, we propose SciEval, a comprehensive and multi-disciplinary evaluation benchmark to address these issues. Based on Bloom's taxonomy, SciEval covers four dimensions to systematically evaluate scientific research ability. In particular, we design a "dynamic" subset based on scientific principles to prevent evaluation from potential data leakage. Both objective and subjective questions are included in SciEval. These characteristics make SciEval a more effective benchmark for scientific research ability evaluation of LLMs. Comprehensive experiments on most advanced LLMs show that, although GPT-4 achie
&lt;/p&gt;</description></item></channel></rss>