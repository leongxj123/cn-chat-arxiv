<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20250;&#25552;&#21069;&#20934;&#22791;&#26410;&#26469;&#26631;&#35760;&#25152;&#38656;&#30340;&#20449;&#24687;&#65292;&#21487;&#33021;&#26159;&#36890;&#36807;&#39044;&#32531;&#23384;&#25110;&#38754;&#21253;&#23633;&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2404.00859</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#25552;&#21069;&#20026;&#26410;&#26469;&#26631;&#35760;&#36827;&#34892;&#35268;&#21010;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do language models plan ahead for future tokens?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00859
&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20250;&#25552;&#21069;&#20934;&#22791;&#26410;&#26469;&#26631;&#35760;&#25152;&#38656;&#30340;&#20449;&#24687;&#65292;&#21487;&#33021;&#26159;&#36890;&#36807;&#39044;&#32531;&#23384;&#25110;&#38754;&#21253;&#23633;&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00859v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#22312;&#32473;&#23450;&#20301;&#32622;&#30340;&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#21464;&#21387;&#22120;&#26159;&#21542;&#20250;&#8220;&#25552;&#21069;&#24605;&#32771;&#8221;&#65311;&#24050;&#30693;&#21464;&#21387;&#22120;&#22312;$t$&#30340;&#21069;&#21521;&#20256;&#36882;&#30340;&#38544;&#34255;&#29366;&#24577;&#20013;&#20934;&#22791;&#20449;&#24687;&#65292;&#28982;&#21518;&#22312;&#26410;&#26469;&#30340;&#21069;&#21521;&#20256;&#36882;$t+\tau$&#20013;&#20351;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#35299;&#37322;&#36825;&#31181;&#29616;&#35937;&#30340;&#21487;&#33021;&#24615;&#65306;&#39044;&#32531;&#23384;&#65292;&#21363;&#35757;&#32451;&#20013;&#23384;&#22312;&#30340;&#38750;&#23545;&#35282;&#26799;&#24230;&#39033;&#23548;&#33268;&#27169;&#22411;&#22312;$t$&#35745;&#31639;&#19982;&#24403;&#21069;&#25512;&#29702;&#20219;&#21153;&#26080;&#20851;&#20294;&#23545;&#26410;&#26469;&#26377;&#29992;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#38754;&#21253;&#23633;&#65292;&#21363;&#19982;&#26102;&#38388;&#27493;&#38271;$t$&#26368;&#30456;&#20851;&#30340;&#29305;&#24449;&#24050;&#32463;&#19982;&#37027;&#20123;&#23558;&#26368;&#26377;&#21033;&#20110;&#26102;&#38388;&#27493;&#38271;$t+\tau$&#30340;&#29305;&#24449;&#30456;&#21516;&#12290;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#19981;&#23558;&#26799;&#24230;&#20256;&#25773;&#21040;&#36807;&#21435;&#26102;&#38388;&#27493;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#27979;&#35797;&#36825;&#20123;&#20551;&#35774;&#65292;&#36825;&#31181;&#26041;&#26696;&#25105;&#20204;&#27491;&#24335;&#31216;&#20026;&#30701;&#35270;&#35757;&#32451;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#39044;&#32531;&#23384;&#30340;&#26126;&#30830;&#35777;&#25454;&#12290;&#22312;&#33258;&#22238;&#24402;&#35821;&#35328;&#24314;&#27169;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#26356;&#22810;&#22320;&#25903;&#25345;&#20102;&#38754;&#21253;&#23633;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00859v1 Announce Type: cross  Abstract: Do transformers "think ahead" during inference at a given position? It is known transformers prepare information in the hidden states of the forward pass at $t$ that is then used in future forward passes $t+\tau$. We posit two explanations for this phenomenon: pre-caching, in which off-diagonal gradient terms present in training result in the model computing features at $t$ irrelevant to the present inference task but useful for the future, and breadcrumbs, in which features most relevant to time step $t$ are already the same as those that would most benefit inference at time $t+\tau$. We test these hypotheses by training language models without propagating gradients to past timesteps, a scheme we formalize as myopic training. In a synthetic data setting, we find clear evidence for pre-caching. In the autoregressive language modeling setting, our experiments are more suggestive of the breadcrumbs hypothesis.
&lt;/p&gt;</description></item><item><title>&#39044;&#35757;&#32451;-&#24494;&#35843;&#33539;&#24335;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#23637;&#29616;&#20102;&#26174;&#33879;&#30340;&#25928;&#29575;&#65292;&#23588;&#20854;&#23545;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#20013;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#12290;</title><link>https://arxiv.org/abs/2403.02504</link><description>&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#39044;&#35757;&#32451;-&#24494;&#35843;&#33539;&#24335;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02504
&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;-&#24494;&#35843;&#33539;&#24335;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#23637;&#29616;&#20102;&#26174;&#33879;&#30340;&#25928;&#29575;&#65292;&#23588;&#20854;&#23545;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#20013;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;-&#24494;&#35843;&#33539;&#24335;&#20195;&#34920;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#19968;&#31181;&#21464;&#38761;&#24615;&#26041;&#27861;&#12290;&#35813;&#33539;&#24335;&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21306;&#21035;&#20110;&#20247;&#65292;&#23637;&#31034;&#20102;&#22312;&#24494;&#35843;&#20219;&#21153;&#20013;&#21363;&#20351;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#20063;&#20855;&#26377;&#26174;&#33879;&#30340;&#25928;&#29575;&#12290;&#36825;&#31181;&#25928;&#29575;&#23545;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#29305;&#21035;&#26377;&#30410;&#65292;&#22240;&#20026;&#27880;&#37322;&#26679;&#26412;&#30340;&#25968;&#37327;&#36890;&#24120;&#38750;&#24120;&#26377;&#38480;&#12290;&#25105;&#20204;&#30340;&#25945;&#31243;&#20840;&#38754;&#20171;&#32461;&#20102;&#39044;&#35757;&#32451;-&#24494;&#35843;&#33539;&#24335;&#12290;&#25105;&#20204;&#39318;&#20808;&#28145;&#20837;&#25506;&#35752;&#20102;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#30340;&#22522;&#26412;&#27010;&#24565;&#65292;&#28982;&#21518;&#36827;&#34892;&#20102;&#23454;&#38469;&#24212;&#29992;&#30340;&#26696;&#20363;&#32451;&#20064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#33539;&#24335;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#22810;&#31867;&#21035;&#20998;&#31867;&#21644;&#22238;&#24402;&#12290;&#24378;&#35843;&#20854;&#39640;&#25928;&#24615;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#65292;&#35813;&#25945;&#31243;&#26088;&#22312;&#40723;&#21169;&#26356;&#24191;&#27867;&#22320;&#37319;&#32435;&#36825;&#31181;&#33539;&#24335;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#30340;&#24320;&#25918;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02504v1 Announce Type: cross  Abstract: The pretrain-finetune paradigm represents a transformative approach in natural language processing (NLP). This paradigm distinguishes itself through the use of large pretrained language models, demonstrating remarkable efficiency in finetuning tasks, even with limited training data. This efficiency is especially beneficial for research in social sciences, where the number of annotated samples is often quite limited. Our tutorial offers a comprehensive introduction to the pretrain-finetune paradigm. We first delve into the fundamental concepts of pretraining and finetuning, followed by practical exercises using real-world applications. We demonstrate the application of the paradigm across various tasks, including multi-class classification and regression. Emphasizing its efficacy and user-friendliness, the tutorial aims to encourage broader adoption of this paradigm. To this end, we have provided open access to all our code and datasets
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#21151;&#30340;&#20851;&#38190;&#22312;&#20110;&#20351;&#29992;&#22823;&#35268;&#27169;&#30340;&#25991;&#26412;&#25968;&#25454;&#38598;&#36827;&#34892;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#20294;&#22914;&#20309;&#20248;&#21270;&#36873;&#25321;&#25968;&#25454;&#20197;&#38477;&#20302;&#30899;&#36275;&#36857;&#21644;&#36130;&#21153;&#25104;&#26412;&#20173;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.16827</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#25968;&#25454;&#36873;&#25321;&#27010;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Data Selection for Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16827
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#21151;&#30340;&#20851;&#38190;&#22312;&#20110;&#20351;&#29992;&#22823;&#35268;&#27169;&#30340;&#25991;&#26412;&#25968;&#25454;&#38598;&#36827;&#34892;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#20294;&#22914;&#20309;&#20248;&#21270;&#36873;&#25321;&#25968;&#25454;&#20197;&#38477;&#20302;&#30899;&#36275;&#36857;&#21644;&#36130;&#21153;&#25104;&#26412;&#20173;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21462;&#24471;&#25104;&#21151;&#30340;&#19968;&#20010;&#20027;&#35201;&#22240;&#32032;&#26159;&#21033;&#29992;&#24040;&#22823;&#19988;&#19981;&#26029;&#22686;&#38271;&#30340;&#25991;&#26412;&#25968;&#25454;&#38598;&#36827;&#34892;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#31616;&#21333;&#22320;&#22312;&#25152;&#26377;&#21487;&#29992;&#25968;&#25454;&#19978;&#35757;&#32451;&#27169;&#22411;&#21487;&#33021;&#24182;&#19981;&#26159;&#26368;&#20339;&#36873;&#25321;&#65288;&#25110;&#19981;&#21487;&#34892;&#65289;&#65292;&#22240;&#20026;&#21487;&#29992;&#25991;&#26412;&#25968;&#25454;&#30340;&#36136;&#37327;&#21487;&#33021;&#26377;&#25152;&#19981;&#21516;&#12290;&#25968;&#25454;&#36807;&#28388;&#20063;&#21487;&#20197;&#36890;&#36807;&#20943;&#23569;&#25152;&#38656;&#30340;&#35757;&#32451;&#37327;&#26469;&#38477;&#20302;&#35757;&#32451;&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#21644;&#36130;&#21153;&#25104;&#26412;&#12290;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#26088;&#22312;&#30830;&#23450;&#35201;&#21253;&#25324;&#22312;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30340;&#21738;&#20123;&#20505;&#36873;&#25968;&#25454;&#28857;&#65292;&#20197;&#21450;&#22914;&#20309;&#20174;&#25152;&#36873;&#25968;&#25454;&#28857;&#20013;&#36866;&#24403;&#37319;&#26679;&#12290;&#25913;&#36827;&#30340;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#30340;&#21069;&#26223;&#24050;&#32463;&#23548;&#33268;&#35813;&#39046;&#22495;&#30340;&#30740;&#31350;&#37327;&#36805;&#36895;&#25193;&#22823;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#28145;&#24230;&#23398;&#20064;&#20027;&#35201;&#21463;&#23454;&#35777;&#35777;&#25454;&#39537;&#21160;&#65292;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#25104;&#26412;&#26114;&#36149;&#65292;&#24456;&#23569;&#26377;&#32452;&#32455;&#25317;&#26377;&#36164;&#28304;&#36827;&#34892;&#24191;&#27867;&#30340;&#25968;&#25454;&#36873;&#25321;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#26377;&#25928;&#25968;&#25454;&#36873;&#25321;&#30340;&#30693;&#35782;&#21487;&#33021;&#22823;&#22810;&#23616;&#38480;&#20110;&#22823;&#22411;&#25216;&#26415;&#20844;&#21496;&#25110;&#30740;&#31350;&#26426;&#26500;&#20869;&#37096;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16827v1 Announce Type: new  Abstract: A major factor in the recent success of large language models is the use of enormous and ever-growing text datasets for unsupervised pre-training. However, naively training a model on all available data may not be optimal (or feasible), as the quality of available text data can vary. Filtering out data can also decrease the carbon footprint and financial costs of training models by reducing the amount of training required.   Data selection methods aim to determine which candidate data points to include in the training dataset and how to appropriately sample from the selected data points. The promise of improved data selection methods has caused the volume of research in the area to rapidly expand. However, because deep learning is mostly driven by empirical evidence and experimentation on large-scale data is expensive, few organizations have the resources for extensive data selection research. Consequently, knowledge of effective data se
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#30340;NLI&#25968;&#25454;&#38598;&#25913;&#36827;&#21477;&#23376;&#23884;&#20837;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;STS&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.15132</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#30340;NLI&#25968;&#25454;&#38598;&#25913;&#36827;&#21477;&#23376;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Improving Sentence Embeddings with an Automatically Generated NLI Dataset
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15132
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#30340;NLI&#25968;&#25454;&#38598;&#25913;&#36827;&#21477;&#23376;&#23884;&#20837;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;STS&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35299;&#30721;&#22120;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#35768;&#22810;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#24456;&#39640;&#30340;&#24615;&#33021;&#12290;&#36825;&#22312;&#21477;&#23376;&#23884;&#20837;&#23398;&#20064;&#20013;&#21516;&#26679;&#25104;&#31435;&#65292;&#20854;&#20013;&#22522;&#20110;&#35299;&#30721;&#22120;&#30340;&#27169;&#22411;PromptEOL &#22312;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#65288;STS&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20339;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;PromptEOL &#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21033;&#29992;&#20102;&#23545;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#65288;NLI&#65289;&#25968;&#25454;&#38598;&#30340;&#25163;&#21160;&#26631;&#27880;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;LLM&#33258;&#21160;&#29983;&#25104;&#30340;NLI&#25968;&#25454;&#38598;&#26469;&#25913;&#36827;&#22312;&#26080;&#30417;&#30563;&#35774;&#32622;&#19979;&#23398;&#20064;&#30340;&#21477;&#23376;&#23884;&#20837;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#24494;&#35843;PromptEOL&#12290;&#22312;STS&#20219;&#21153;&#30340;&#23454;&#39564;&#20013;&#65292;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20154;&#31867;&#35780;&#20272;&#26041;&#38754;&#36798;&#21040;&#20102;82.21&#30340;&#24179;&#22343;Spearman&#31561;&#32423;&#30456;&#20851;&#31995;&#25968;&#65292;&#20174;&#32780;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#32780;&#26080;&#38656;&#20351;&#29992;&#22823;&#35268;&#27169;&#25163;&#21160;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15132v1 Announce Type: new  Abstract: Decoder-based large language models (LLMs) have shown high performance on many tasks in natural language processing. This is also true for sentence embedding learning, where a decoder-based model, PromptEOL, has achieved the best performance on semantic textual similarity (STS) tasks. However, PromptEOL makes great use of fine-tuning with a manually annotated natural language inference (NLI) dataset. We aim to improve sentence embeddings learned in an unsupervised setting by automatically generating an NLI dataset with an LLM and using it to fine-tune PromptEOL. In experiments on STS tasks, the proposed method achieved an average Spearman's rank correlation coefficient of 82.21 with respect to human evaluation, thus outperforming existing methods without using large, manually annotated datasets.
&lt;/p&gt;</description></item><item><title>SymBa&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21495;&#21270;&#21521;&#21518;&#25512;&#29702;&#26041;&#27861;&#65292;&#22312;&#22810;&#27493;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#21644;&#25928;&#29575;&#25552;&#21319;&#65292;&#33021;&#22815;&#29983;&#25104;&#21487;&#35299;&#37322;&#30340;&#32467;&#26500;&#21270;&#35777;&#26126;&#12290;</title><link>https://arxiv.org/abs/2402.12806</link><description>&lt;p&gt;
SymBa&#65306;&#31526;&#21495;&#21270;&#21521;&#21518;&#25512;&#29702;&#29992;&#20110;&#22810;&#27493;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
SymBa: Symbolic Backward Chaining for Multi-step Natural Language Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12806
&lt;/p&gt;
&lt;p&gt;
SymBa&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21495;&#21270;&#21521;&#21518;&#25512;&#29702;&#26041;&#27861;&#65292;&#22312;&#22810;&#27493;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#21644;&#25928;&#29575;&#25552;&#21319;&#65292;&#33021;&#22815;&#29983;&#25104;&#21487;&#35299;&#37322;&#30340;&#32467;&#26500;&#21270;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#22312;&#19968;&#31995;&#21015;&#24605;&#32500;&#25552;&#31034;&#20013;&#20986;&#33394;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#24544;&#23454;&#30340;&#22810;&#27493;&#25512;&#29702;&#20381;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#21521;&#21518;&#25512;&#29702;&#65292;&#21363;&#36890;&#36807;&#36923;&#36753;&#35268;&#21017;&#36882;&#24402;&#22320;&#20998;&#35299;&#26597;&#35810;&#65292;&#30452;&#21040;&#35777;&#26126;&#20026;&#27490;&#12290;&#20026;&#20102;&#35299;&#20915;&#24403;&#21069;&#21521;&#21518;&#25512;&#29702;&#23454;&#29616;&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SymBa&#65288;&#31526;&#21495;&#21270;&#21521;&#21518;&#25512;&#29702;&#65289;&#12290;&#22312;SymBa&#20013;&#65292;&#31526;&#21495;&#21270;&#33258;&#39030;&#21521;&#19979;&#27714;&#35299;&#22120;&#25511;&#21046;&#25972;&#20010;&#35777;&#26126;&#36807;&#31243;&#65292;&#24403;&#27714;&#35299;&#22120;&#36935;&#21040;&#27515;&#32993;&#21516;&#26102;&#65292;&#25165;&#35843;&#29992;LLM&#29983;&#25104;&#21333;&#20010;&#25512;&#29702;&#27493;&#39588;&#12290;&#36890;&#36807;&#36825;&#31181;&#26032;&#39062;&#30340;&#27714;&#35299;&#22120;-LLM&#38598;&#25104;&#65292;SymBa&#22312;&#21508;&#31181;&#22810;&#27493;&#25512;&#29702;&#22522;&#20934;&#65288;ProofWriter&#65292;Birds-Electricity&#65292;GSM8k&#65292;CLUTRR-TF&#65292;ECtHR Article 6&#65289;&#20013;&#30456;&#27604;&#21521;&#21518;&#25512;&#29702;&#22522;&#32447;&#21462;&#24471;&#20102;&#24615;&#33021;&#12289;&#35777;&#26126;&#24544;&#23454;&#24615;&#21644;&#25928;&#29575;&#26174;&#33879;&#25552;&#39640;&#65292;&#33021;&#22815;&#29983;&#25104;&#21487;&#35299;&#37322;&#30340;&#32467;&#26500;&#21270;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12806v1 Announce Type: new  Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning ability as in Chain-of-thought prompting, but faithful multi-step reasoning remains a challenge. We specifically focus on backward chaining, where the query is recursively decomposed using logical rules until proven. To address the limitations of current backward chaining implementations, we propose SymBa (Symbolic Backward Chaining). In SymBa, the symbolic top-down solver controls the entire proof process and the LLM is called to generate a single reasoning step only when the solver encounters a dead end. By this novel solver-LLM integration, while being able to produce an interpretable, structured proof, SymBa achieves significant improvement in performance, proof faithfulness, and efficiency in diverse multi-step reasoning benchmarks (ProofWriter, Birds-Electricity, GSM8k, CLUTRR-TF, ECtHR Article 6) compared to backward chaining baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#21442;&#25968;&#21270;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#28789;&#27963;&#24615;&#12289;&#35757;&#32451;&#25216;&#26415;&#21644;&#29983;&#25104;&#25928;&#26524;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#36739;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2302.05737</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#25991;&#26412;&#29983;&#25104;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Reparameterized Discrete Diffusion Model for Text Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.05737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#21442;&#25968;&#21270;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#28789;&#27963;&#24615;&#12289;&#35757;&#32451;&#25216;&#26415;&#21644;&#29983;&#25104;&#25928;&#26524;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#36739;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#30340;&#31163;&#25955;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20174;&#31163;&#25955;&#25193;&#25955;&#36807;&#31243;&#20013;&#37319;&#26679;&#30340;&#21478;&#19968;&#31181;&#31561;&#20215;&#24418;&#24335;&#65292;&#24182;&#21033;&#29992;&#36825;&#19968;&#27934;&#35265;&#24320;&#21457;&#20102;&#19968;&#26063;&#37325;&#26032;&#21442;&#25968;&#21270;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#12290;&#36825;&#20010;&#27966;&#29983;&#30340;&#36890;&#29992;&#26694;&#26550;&#38750;&#24120;&#28789;&#27963;&#65292;&#20026;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#29983;&#25104;&#36807;&#31243;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#24182;&#20855;&#22791;&#26356;&#26377;&#25928;&#30340;&#35757;&#32451;&#21644;&#35299;&#30721;&#25216;&#26415;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#27169;&#22411;&#30340;&#25991;&#26412;&#29983;&#25104;&#33021;&#21147;&#65292;&#22312;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies discrete diffusion probabilistic models with applications to natural language generation. We derive an alternative yet equivalent formulation of the sampling from discrete diffusion processes and leverage this insight to develop a family of reparameterized discrete diffusion models. The derived generic framework is highly flexible, offers a fresh perspective of the generation process in discrete diffusion models, and features more effective training and decoding techniques. We conduct extensive experiments to evaluate the text generation capability of our model, demonstrating significant improvements over existing diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;Leeroo&#32534;&#25490;&#22120;&#30340;&#26550;&#26500;&#65292;&#36890;&#36807;&#38598;&#25104;&#22810;&#20010;&#35757;&#32451;&#36807;&#30340;LLMs&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;&#26032;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;&#35813;&#32534;&#25490;&#22120;&#22312;&#24615;&#33021;&#19978;&#19982;Mixtral&#27169;&#22411;&#30456;&#24403;&#65292;&#24182;&#19988;&#25104;&#26412;&#21482;&#26377;&#20854;&#19977;&#20998;&#20043;&#20108;&#12290;&#24403;&#20801;&#35768;&#26356;&#39640;&#30340;&#25104;&#26412;&#26102;&#65292;Leeroo&#32534;&#25490;&#22120;&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#20102;Mixtral&#27169;&#22411;&#65292;&#24182;&#19988;&#24403;&#38598;&#25104;GPT4&#26102;&#36827;&#19968;&#27493;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2401.13979</link><description>&lt;p&gt;
Leeroo Orchestrator: &#36890;&#36807;&#27169;&#22411;&#38598;&#25104;&#25552;&#39640;LLMs&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Leeroo Orchestrator: Elevating LLMs Performance Through Model Integration. (arXiv:2401.13979v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13979
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;Leeroo&#32534;&#25490;&#22120;&#30340;&#26550;&#26500;&#65292;&#36890;&#36807;&#38598;&#25104;&#22810;&#20010;&#35757;&#32451;&#36807;&#30340;LLMs&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;&#26032;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;&#35813;&#32534;&#25490;&#22120;&#22312;&#24615;&#33021;&#19978;&#19982;Mixtral&#27169;&#22411;&#30456;&#24403;&#65292;&#24182;&#19988;&#25104;&#26412;&#21482;&#26377;&#20854;&#19977;&#20998;&#20043;&#20108;&#12290;&#24403;&#20801;&#35768;&#26356;&#39640;&#30340;&#25104;&#26412;&#26102;&#65292;Leeroo&#32534;&#25490;&#22120;&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#20102;Mixtral&#27169;&#22411;&#65292;&#24182;&#19988;&#24403;&#38598;&#25104;GPT4&#26102;&#36827;&#19968;&#27493;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26550;&#26500;&#65292;&#21033;&#29992;&#22810;&#20010;&#35757;&#32451;&#36807;&#30340;LLMs&#30340;&#38598;&#20307;&#30693;&#35782;&#65292;&#21019;&#24314;&#19968;&#20010;&#26032;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#30340;&#26680;&#24515;&#26159;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#32534;&#25490;&#22120;&#65292;&#33021;&#22815;&#36873;&#25321;&#26368;&#20339;&#30340;&#24213;&#23618;LLM&#19987;&#23478;&#36827;&#34892;&#20219;&#21153;&#25191;&#34892;&#12290;&#21463;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#33258;&#25105;&#23545;&#24328;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#26597;&#35810;&#29983;&#25104;&#12289;&#32534;&#25490;&#21644;&#35780;&#20272;&#30340;&#24490;&#29615;&#65292;&#20026;&#32534;&#25490;&#22120;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#20027;&#35201;&#38024;&#23545;MMLU&#22522;&#20934;&#65292;&#22312;Hugging Face&#19978;&#20351;&#29992;&#20102;&#20855;&#26377;7B&#12289;13B&#21644;34B&#21442;&#25968;&#30340;&#27169;&#22411;&#12290;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;Leeroo&#32534;&#25490;&#22120;&#23454;&#29616;&#20102;&#19982;Mixtral&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#20294;&#21482;&#20135;&#29983;&#20102;&#20854;&#25104;&#26412;&#30340;&#19977;&#20998;&#20043;&#20108;&#12290;&#27492;&#22806;&#65292;&#22686;&#21152;&#20801;&#35768;&#30340;&#25104;&#26412;&#36229;&#36807;&#20102;Mixtral&#30340;&#20934;&#30830;&#24615;&#65292;&#36798;&#21040;&#20102;75.9%&#30340;&#20934;&#30830;&#24615;&#12290;&#24403;&#23558;GPT4&#38598;&#25104;&#21040;&#24213;&#23618;&#27169;&#22411;&#27744;&#20013;&#26102;&#65292;&#36827;&#19968;&#27493;&#25552;&#21319;&#20063;&#24471;&#21040;&#20102;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose an architecture to harness the collective knowledge of multiple trained LLMs to create a new state-of-the-art. At the core of this framework is a LLM-based orchestrator that is adept at picking the right underlying LLM experts for optimal task execution. Inspired by self-play in reinforcement learning, we created a loop of query generation, orchestration, and evaluation to generate training data for the orchestrator. Our evaluation focused on the MMLU benchmark, employing models with 7B, 13B, and 34B parameters available on Hugging Face. The results demonstrate new state-of-the-art open-source models: Our Leeroo orchestrator achieves performance on par with the Mixtral model while incurring only two-thirds of its cost. Moreover, increasing the allowed cost surpasses Mixtral's accuracy by over 5% at the same cost level, reaching an accuracy of 75.9%. Further enhancements were observed when integrating GPT4 into the underlying model pool. The Leeroo orchestrator
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;MERA&#65292;&#19968;&#20010;&#22810;&#27169;&#24577;&#20420;&#35821;&#22522;&#30784;&#27169;&#22411;&#35780;&#20272;&#25351;&#26631;&#12290;&#35813;&#25351;&#26631;&#21253;&#25324;21&#20010;&#35780;&#20272;&#20219;&#21153;&#65292;&#28085;&#30422;&#20102;11&#20010;&#25216;&#33021;&#39046;&#22495;&#20013;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20272;&#12290;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#22266;&#23450;&#25351;&#20196;&#35774;&#32622;&#19979;&#35780;&#20272;FM&#21644;LM&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.04531</link><description>&lt;p&gt;
MERA: &#20420;&#35821;LLM&#32508;&#21512;&#35780;&#20272;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
MERA: A Comprehensive LLM Evaluation in Russian. (arXiv:2401.04531v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04531
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;MERA&#65292;&#19968;&#20010;&#22810;&#27169;&#24577;&#20420;&#35821;&#22522;&#30784;&#27169;&#22411;&#35780;&#20272;&#25351;&#26631;&#12290;&#35813;&#25351;&#26631;&#21253;&#25324;21&#20010;&#35780;&#20272;&#20219;&#21153;&#65292;&#28085;&#30422;&#20102;11&#20010;&#25216;&#33021;&#39046;&#22495;&#20013;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20272;&#12290;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#22266;&#23450;&#25351;&#20196;&#35774;&#32622;&#19979;&#35780;&#20272;FM&#21644;LM&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#26368;&#26174;&#33879;&#30340;&#36827;&#23637;&#20043;&#19968;&#26159;&#22522;&#30784;&#27169;&#22411;&#65288;FM&#65289;&#30340;&#21457;&#23637;&#65292;&#20854;&#20013;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#30340;&#23835;&#36215;&#24341;&#20154;&#27880;&#30446;&#12290;&#38543;&#30528;&#27169;&#22411;&#30340;&#35268;&#27169;&#22686;&#22823;&#65292;LM&#22312;&#21487;&#34913;&#37327;&#30340;&#26041;&#38754;&#23637;&#31034;&#20102;&#25552;&#21319;&#65292;&#24182;&#19988;&#21457;&#23637;&#20986;&#20102;&#26032;&#30340;&#23450;&#24615;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#30740;&#31350;&#20154;&#21592;&#30340;&#20851;&#27880;&#21644;LM&#24212;&#29992;&#30340;&#24555;&#36895;&#22686;&#38271;&#65292;LM&#30340;&#33021;&#21147;&#12289;&#38480;&#21046;&#21644;&#30456;&#20851;&#39118;&#38505;&#20173;&#38656;&#26356;&#22909;&#22320;&#29702;&#35299;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#24320;&#25918;&#30340;&#20420;&#35821;&#22810;&#27169;&#24577;&#26550;&#26500;&#35780;&#20272;&#65288;MERA&#65289;&#25351;&#23548;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#20197;&#20420;&#35821;&#20026;&#23548;&#21521;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;&#35813;&#22522;&#20934;&#28085;&#30422;&#20102;11&#20010;&#25216;&#33021;&#39046;&#22495;&#20013;&#29983;&#25104;&#27169;&#22411;&#30340;21&#20010;&#35780;&#20272;&#20219;&#21153;&#65292;&#24182;&#34987;&#35774;&#35745;&#20026;&#40657;&#30418;&#27979;&#35797;&#65292;&#20197;&#30830;&#20445;&#25490;&#38500;&#25968;&#25454;&#27844;&#28431;&#12290;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#22266;&#23450;&#25351;&#20196;&#35774;&#32622;&#19979;&#35780;&#20272;FM&#21644;LM&#30340;&#26041;&#27861;&#65292;&#24182;&#21487;&#25193;&#23637;&#21040;&#20854;&#20182;&#27169;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). As the models' size increases, LMs demonstrate enhancements in measurable aspects and the development of new qualitative features. However, despite researchers' attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still need to be better understood. To address these issues, we introduce an open Multimodal Evaluation of Russian-language Architectures (MERA), a new instruction benchmark for evaluating foundation models oriented towards the Russian language. The benchmark encompasses 21 evaluation tasks for generative models in 11 skill domains and is designed as a black-box test to ensure the exclusion of data leakage. The paper introduces a methodology to evaluate FMs and LMs in zeroand few-shot fixed instruction settings that can be extended to other modalities. We propose an 
&lt;/p&gt;</description></item><item><title>RCAgent&#26159;&#19968;&#20010;&#24037;&#20855;&#22686;&#24378;&#30340;LLM&#33258;&#20027;&#20195;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#20113;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#33021;&#22815;&#23454;&#29616;&#33258;&#30001;&#26684;&#24335;&#30340;&#25968;&#25454;&#25910;&#38598;&#21644;&#20840;&#38754;&#30340;&#20998;&#26512;&#65292;&#24182;&#22312;&#21508;&#20010;&#26041;&#38754;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.16340</link><description>&lt;p&gt;
RCAgent&#65306;&#22522;&#20110;&#33258;&#20027;&#20195;&#29702;&#21644;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20113;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models. (arXiv:2310.16340v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16340
&lt;/p&gt;
&lt;p&gt;
RCAgent&#26159;&#19968;&#20010;&#24037;&#20855;&#22686;&#24378;&#30340;LLM&#33258;&#20027;&#20195;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#20113;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#33021;&#22815;&#23454;&#29616;&#33258;&#30001;&#26684;&#24335;&#30340;&#25968;&#25454;&#25910;&#38598;&#21644;&#20840;&#38754;&#30340;&#20998;&#26512;&#65292;&#24182;&#22312;&#21508;&#20010;&#26041;&#38754;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20113;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#21463;&#21040;&#20102;&#31215;&#26497;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#26041;&#27861;&#20173;&#28982;&#20381;&#36182;&#20110;&#25163;&#21160;&#24037;&#20316;&#27969;&#35774;&#32622;&#65292;&#24182;&#27809;&#26377;&#20805;&#20998;&#21457;&#25381;LLMs&#30340;&#20915;&#31574;&#21644;&#29615;&#22659;&#20132;&#20114;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;RCAgent&#65292;&#36825;&#26159;&#19968;&#20010;&#23454;&#29992;&#21644;&#27880;&#37325;&#38544;&#31169;&#30340;&#24037;&#20855;&#22686;&#24378;LLM&#33258;&#20027;&#20195;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#38469;&#30340;&#24037;&#19994;RCA&#20351;&#29992;&#12290;RCAgent&#22312;&#20869;&#37096;&#37096;&#32626;&#30340;&#27169;&#22411;&#19978;&#36816;&#34892;&#65292;&#32780;&#19981;&#26159;GPT&#31995;&#21015;&#65292;&#33021;&#22815;&#36827;&#34892;&#33258;&#30001;&#26684;&#24335;&#30340;&#25968;&#25454;&#25910;&#38598;&#21644;&#20840;&#38754;&#30340;&#20998;&#26512;&#65292;&#24182;&#32467;&#21512;&#21508;&#31181;&#22686;&#24378;&#21151;&#33021;&#65292;&#21253;&#25324;&#29420;&#29305;&#30340;&#34892;&#21160;&#36712;&#36857;&#33258;&#19968;&#33268;&#24615;&#21644;&#19968;&#22871;&#29992;&#20110;&#19978;&#19979;&#25991;&#31649;&#29702;&#12289;&#31283;&#23450;&#21270;&#21644;&#23548;&#20837;&#39046;&#22495;&#30693;&#35782;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;RCAgent&#22312;RCA&#30340;&#21508;&#20010;&#26041;&#38754;&#65288;&#39044;&#27979;&#26681;&#26412;&#21407;&#22240;&#12289;&#35299;&#20915;&#26041;&#26696;&#12289;&#35777;&#25454;&#21644;&#36131;&#20219;&#65289;&#20197;&#21450;&#24403;&#21069;&#35268;&#21017;&#26410;&#28085;&#30422;&#30340;&#20219;&#21153;&#19978;&#37117;&#26126;&#26174;&#20248;&#20110;ReAct&#65292;&#24471;&#21040;&#20102;&#33258;&#21160;&#21270;&#21644;&#20154;&#24037;&#39564;&#35777;&#30340;&#30830;&#35748;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language model (LLM) applications in cloud root cause analysis (RCA) have been actively explored recently. However, current methods are still reliant on manual workflow settings and do not unleash LLMs' decision-making and environment interaction capabilities. We present RCAgent, a tool-augmented LLM autonomous agent framework for practical and privacy-aware industrial RCA usage. Running on an internally deployed model rather than GPT families, RCAgent is capable of free-form data collection and comprehensive analysis with tools. Our framework combines a variety of enhancements, including a unique Self-Consistency for action trajectories, and a suite of methods for context management, stabilization, and importing domain knowledge. Our experiments show RCAgent's evident and consistent superiority over ReAct across all aspects of RCA -- predicting root causes, solutions, evidence, and responsibilities -- and tasks covered or uncovered by current rules, as validated by both automate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#32452;&#19987;&#38376;&#38024;&#23545;&#20420;&#35821;&#30340;&#39044;&#35757;&#32451;Transformer&#35821;&#35328;&#27169;&#22411;&#65292;&#21253;&#25324;&#32534;&#30721;&#22120;&#12289;&#35299;&#30721;&#22120;&#21644;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#20420;&#35821;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#23637;&#29616;&#20102;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24076;&#26395;&#33021;&#22815;&#25512;&#21160;&#20420;&#35821;&#39046;&#22495;&#30340;NLP&#30740;&#31350;&#21644;&#24037;&#19994;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2309.10931</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#20420;&#35821;&#30340;&#39044;&#35757;&#32451;Transformer&#35821;&#35328;&#27169;&#22411;&#23478;&#26063;
&lt;/p&gt;
&lt;p&gt;
A Family of Pretrained Transformer Language Models for Russian. (arXiv:2309.10931v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#32452;&#19987;&#38376;&#38024;&#23545;&#20420;&#35821;&#30340;&#39044;&#35757;&#32451;Transformer&#35821;&#35328;&#27169;&#22411;&#65292;&#21253;&#25324;&#32534;&#30721;&#22120;&#12289;&#35299;&#30721;&#22120;&#21644;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#20420;&#35821;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#23637;&#29616;&#20102;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24076;&#26395;&#33021;&#22815;&#25512;&#21160;&#20420;&#35821;&#39046;&#22495;&#30340;NLP&#30740;&#31350;&#21644;&#24037;&#19994;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;Transformer&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30740;&#31350;&#26041;&#27861;&#21644;&#24212;&#29992;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#19987;&#38376;&#38024;&#23545;&#20420;&#35821;&#30340;&#36825;&#31181;&#27169;&#22411;&#30340;&#21457;&#23637;&#21364;&#21463;&#21040;&#20102;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#32452;&#22522;&#20110;&#32534;&#30721;&#22120;&#65288;ruBERT, ruRoBERTa, ruELECTRA&#65289;&#12289;&#35299;&#30721;&#22120;&#65288;ruGPT-3&#65289;&#21644;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#65288;ruT5, FRED-T5&#65289;&#27169;&#22411;&#30340;13&#20010;&#20420;&#35821;Transformer LMs&#65292;&#20855;&#26377;&#22810;&#31181;&#23610;&#23544;&#12290;&#36825;&#20123;&#27169;&#22411;&#21487;&#36890;&#36807;HuggingFace&#24179;&#21488;&#36731;&#26494;&#33719;&#21462;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#27169;&#22411;&#26550;&#26500;&#35774;&#35745;&#21644;&#39044;&#35757;&#32451;&#30340;&#25253;&#21578;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#22312;&#20420;&#35821;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#25968;&#25454;&#38598;&#20197;&#21450;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#21457;&#24067;&#36825;&#20123;&#19987;&#38376;&#30340;Transformer LMs&#65292;&#25105;&#20204;&#24076;&#26395;&#25299;&#23485;NLP&#30740;&#31350;&#26041;&#21521;&#30340;&#33539;&#22260;&#65292;&#24182;&#20419;&#36827;&#38024;&#23545;&#20420;&#35821;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#30340;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays, Transformer language models (LMs) represent a fundamental component of the NLP research methodologies and applications. However, the development of such models specifically for the Russian language has received little attention. This paper presents a collection of 13 Russian Transformer LMs based on the encoder (ruBERT, ruRoBERTa, ruELECTRA), decoder (ruGPT-3), and encoder-decoder (ruT5, FRED-T5) models in multiple sizes. Access to these models is readily available via the HuggingFace platform. We provide a report of the model architecture design and pretraining, and the results of evaluating their generalization abilities on Russian natural language understanding and generation datasets and benchmarks. By pretraining and releasing these specialized Transformer LMs, we hope to broaden the scope of the NLP research directions and enable the development of industrial solutions for the Russian language.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31639;&#26415;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20869;&#37096;&#30340;&#20540;&#31354;&#38388;&#36827;&#34892;&#35745;&#31639;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.01154</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31639;&#26415;&#36816;&#31639;&#65306;&#20174;&#35760;&#24518;&#21040;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31639;&#26415;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20869;&#37096;&#30340;&#20540;&#31354;&#38388;&#36827;&#34892;&#35745;&#31639;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26356;&#22909;&#22320;&#29702;&#35299;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#24615;&#35745;&#31639;&#21644;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#23545;&#20110;&#36827;&#19968;&#27493;&#25913;&#36827;&#23427;&#20204;&#24182;&#25299;&#23485;&#20854;&#36866;&#29992;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#20010;&#35757;&#32451;&#29992;&#20110;&#39044;&#27979;&#19979;&#19968;&#20010;&#26631;&#35760;&#30340;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#22312;&#35757;&#32451;&#25968;&#25454;&#20043;&#22806;&#25191;&#34892;&#31639;&#26415;&#35745;&#31639;&#12290;&#20108;&#36827;&#21046;&#21152;&#27861;&#21644;&#20056;&#27861;&#26159;&#19968;&#20010;&#24456;&#22909;&#30340;&#27979;&#35797;&#22522;&#30784;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#19968;&#20010;&#38750;&#24120;&#23567;&#30340;&#35789;&#27719;&#34920;&#65292;&#24182;&#19988;&#22312;&#36755;&#20837;/&#36755;&#20986;&#19978;&#23637;&#31034;&#20102;&#30456;&#20851;&#30340;&#19981;&#36830;&#32493;&#24615;&#65292;&#20351;&#24471;&#23545;&#26032;&#25968;&#25454;&#36827;&#34892;&#24179;&#28369;&#30340;&#36755;&#20837;&#25554;&#20540;&#26080;&#25928;&#12290;&#25105;&#20204;&#25104;&#21151;&#22320;&#35757;&#32451;&#20102;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#23398;&#20064;&#36825;&#20123;&#20219;&#21153;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#35777;&#26126;&#20854;&#22806;&#25512;&#33021;&#21147;&#21644;&#20869;&#37096;&#20449;&#24687;&#22788;&#29702;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25903;&#25345;&#36825;&#26679;&#19968;&#20010;&#20551;&#35774;&#65292;&#21363;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#19968;&#20010;&#32534;&#30721;-&#22238;&#24402;-&#35299;&#30721;&#26426;&#22120;&#65292;&#19968;&#26086;&#23558;&#36755;&#20837;&#26631;&#35760;&#34920;&#31034;&#26144;&#23556;&#21040;&#21512;&#36866;&#30340;&#20869;&#37096;&#20540;&#31354;&#38388;&#65292;&#35745;&#31639;&#23601;&#22312;&#20540;&#31354;&#38388;&#20013;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate intern
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20803;&#25512;&#29702;&#30340;Multi-Chain Reasoning (MCR)&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26816;&#26597;&#22810;&#20010;&#25512;&#29702;&#38142;&#65292;&#28151;&#21512;&#23427;&#20204;&#20043;&#38388;&#30340;&#20449;&#24687;&#24182;&#36873;&#25321;&#26368;&#30456;&#20851;&#30340;&#20107;&#23454;&#65292;&#20174;&#32780;&#36229;&#36234;&#22810;&#38142;&#24605;&#32500;&#65292;&#35299;&#20915;&#22810;&#36339;QA&#38382;&#39064;&#12290; &#23454;&#39564;&#32467;&#26524;&#34920;&#26126;MCR&#32988;&#36807;&#22810;&#20010;&#24378;&#22522;&#32447;&#65292;&#35299;&#37322;&#36136;&#37327;&#39640;&#12290;</title><link>http://arxiv.org/abs/2304.13007</link><description>&lt;p&gt;
&#36229;&#36234;&#22810;&#38142;&#24605;&#32500;&#65306;&#22522;&#20110;&#20803;&#25512;&#29702;&#30340;&#38382;&#39064;&#35299;&#31572;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Answering Questions by Meta-Reasoning over Multiple Chains of Thought. (arXiv:2304.13007v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20803;&#25512;&#29702;&#30340;Multi-Chain Reasoning (MCR)&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26816;&#26597;&#22810;&#20010;&#25512;&#29702;&#38142;&#65292;&#28151;&#21512;&#23427;&#20204;&#20043;&#38388;&#30340;&#20449;&#24687;&#24182;&#36873;&#25321;&#26368;&#30456;&#20851;&#30340;&#20107;&#23454;&#65292;&#20174;&#32780;&#36229;&#36234;&#22810;&#38142;&#24605;&#32500;&#65292;&#35299;&#20915;&#22810;&#36339;QA&#38382;&#39064;&#12290; &#23454;&#39564;&#32467;&#26524;&#34920;&#26126;MCR&#32988;&#36807;&#22810;&#20010;&#24378;&#22522;&#32447;&#65292;&#35299;&#37322;&#36136;&#37327;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#22810;&#36339;&#38382;&#39064;&#35299;&#31572;&#65288;QA&#65289;&#31995;&#32479;&#36890;&#24120;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#19968;&#31995;&#21015;&#24605;&#32771;&#27493;&#39588;&#65288;CoT&#65289;&#65292;&#28982;&#21518;&#25165;&#24471;&#20986;&#26368;&#32456;&#31572;&#26696;&#12290;&#36890;&#24120;&#26469;&#35828;&#65292;&#22810;&#20010;&#38142;&#26465;&#34987;&#25277;&#26679;&#24182;&#36890;&#36807;&#26368;&#32456;&#31572;&#26696;&#30340;&#25237;&#31080;&#26426;&#21046;&#36827;&#34892;&#32858;&#21512;&#65292;&#20294;&#20013;&#38388;&#27493;&#39588;&#26412;&#36523;&#34987;&#20002;&#24323;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#24182;&#19981;&#32771;&#34385;&#38142;&#20043;&#38388;&#30340;&#20013;&#38388;&#27493;&#39588;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#19988;&#19981;&#25552;&#20379;&#39044;&#27979;&#31572;&#26696;&#30340;&#32479;&#19968;&#35299;&#37322;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20803;&#25512;&#29702;&#30340; Multi-Chain Reasoning (MCR) &#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#36229;&#36234;&#22810;&#20010;&#24605;&#32771;&#38142;&#65292;&#32780;&#19981;&#26159;&#32858;&#21512;&#22238;&#31572;&#12290;MCR&#26816;&#26597;&#19981;&#21516;&#30340;&#25512;&#29702;&#38142;&#65292;&#28151;&#21512;&#23427;&#20204;&#20043;&#38388;&#30340;&#20449;&#24687;&#24182;&#36873;&#25321;&#22312;&#29983;&#25104;&#35299;&#37322;&#21644;&#39044;&#27979;&#31572;&#26696;&#26102;&#26368;&#30456;&#20851;&#30340;&#20107;&#23454;&#12290;MCR&#22312;7&#20010;&#22810;&#36339;QA&#25968;&#25454;&#38598;&#19978;&#32988;&#36807;&#24378;&#22522;&#32447;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;MCR&#30340;&#35299;&#37322;&#20855;&#26377;&#39640;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern systems for multi-hop question answering (QA) typically break questions into a sequence of reasoning steps, termed chain-of-thought (CoT), before arriving at a final answer. Often, multiple chains are sampled and aggregated through a voting mechanism over the final answers, but the intermediate steps themselves are discarded. While such approaches improve performance, they do not consider the relations between intermediate steps across chains and do not provide a unified explanation for the predicted answer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts large language models to meta-reason over multiple chains of thought, rather than aggregating their answers. MCR examines different reasoning chains, mixes information between them and selects the most relevant facts in generating an explanation and predicting the answer. MCR outperforms strong baselines on 7 multi-hop QA datasets. Moreover, our analysis reveals that MCR explanations exhibit high quality, en
&lt;/p&gt;</description></item></channel></rss>