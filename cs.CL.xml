<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#30740;&#31350;&#30740;&#31350;&#20102;&#23545;&#25239;&#22312;&#32447;&#20167;&#24680;&#35328;&#35770;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#26512;&#23545;&#35805;&#20013;&#30340;&#29702;&#30001;&#12289;&#24773;&#24863;&#21644;&#20449;&#35465;&#31561;&#35828;&#26381;&#26041;&#24335;&#65292;&#23545;&#27604;&#23553;&#38381;&#21644;&#24320;&#25918;&#20132;&#20114;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#21644;&#35805;&#39064;&#23618;&#38754;&#65292;&#21457;&#29616;&#20102;&#22312;&#23545;&#25239;&#35328;&#35770;&#20013;&#30340;&#24494;&#22937;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2403.15449</link><description>&lt;p&gt;
&#24974;&#24680;&#28304;&#20110;&#26080;&#30693;&#65281;&#23545;&#25239;&#20250;&#35805;&#24615;&#20167;&#24680;&#35328;&#35770;&#20013;&#35828;&#26381;&#26041;&#24335;&#30340;&#25552;&#28860;
&lt;/p&gt;
&lt;p&gt;
Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15449
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#30740;&#31350;&#20102;&#23545;&#25239;&#22312;&#32447;&#20167;&#24680;&#35328;&#35770;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#26512;&#23545;&#35805;&#20013;&#30340;&#29702;&#30001;&#12289;&#24773;&#24863;&#21644;&#20449;&#35465;&#31561;&#35828;&#26381;&#26041;&#24335;&#65292;&#23545;&#27604;&#23553;&#38381;&#21644;&#24320;&#25918;&#20132;&#20114;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#21644;&#35805;&#39064;&#23618;&#38754;&#65292;&#21457;&#29616;&#20102;&#22312;&#23545;&#25239;&#35328;&#35770;&#20013;&#30340;&#24494;&#22937;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#23545;&#25239;&#35328;&#35770;&#20351;&#29992;&#30340;&#22240;&#32032;&#26159;&#29702;&#35299;&#22312;&#32447;&#23545;&#25239;&#20167;&#24680;&#35328;&#35770;&#30340;&#26368;&#20339;&#26041;&#27861;&#30340;&#26680;&#24515;&#12290;&#21508;&#31181;&#30740;&#31350;&#35780;&#20272;&#23545;&#25239;&#35328;&#35770;&#20013;&#20351;&#29992;&#30340;&#24773;&#24863;&#22522;&#30784;&#22240;&#32032;&#65292;&#22914;&#24773;&#24863;&#20849;&#40483;&#12289;&#20882;&#29359;&#31243;&#24230;&#21644;&#25932;&#24847;&#31243;&#24230;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#20250;&#35805;&#20132;&#20114;&#20013;&#20351;&#29992;&#30340;&#23545;&#25239;&#35328;&#35770;&#65292;&#26412;&#30740;&#31350;&#23558;&#35828;&#26381;&#26041;&#24335;&#20998;&#35299;&#20026;&#29702;&#30001;&#12289;&#24773;&#24863;&#21644;&#20449;&#35465;&#65292;&#28982;&#21518;&#35780;&#20272;&#23427;&#20204;&#22312;&#28041;&#21450;&#31181;&#26063;&#20027;&#20041;&#12289;&#24615;&#21035;&#27495;&#35270;&#21644;&#23447;&#25945;&#38382;&#39064;&#30340;&#20004;&#31181;&#23545;&#35805;&#20132;&#20114;&#31867;&#22411;&#20013;&#30340;&#20351;&#29992;&#12290;&#35780;&#20272;&#28085;&#30422;&#20102;&#20154;&#31867;&#19982;&#29983;&#25104;&#23545;&#25239;&#35328;&#35770;&#30340;&#19981;&#21516;&#34892;&#20026;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#22238;&#22797;&#30340;&#31435;&#22330;&#19982;&#27599;&#31181;&#23545;&#25239;&#35328;&#35770;&#20013;&#30340;&#35828;&#26381;&#26041;&#24335;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#22312;&#24320;&#25918;&#21644;&#23553;&#38381;&#20132;&#20114;&#30340;&#23545;&#25239;&#35328;&#35770;&#35828;&#26381;&#26041;&#24335;&#19978;&#30340;&#24494;&#22937;&#24046;&#24322; -- &#23588;&#20854;&#26159;&#22312;&#35805;&#39064;&#23618;&#38754;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15449v1 Announce Type: cross  Abstract: Examining the factors that the counter-speech uses is at the core of understanding the optimal methods for confronting hate speech online. Various studies assess the emotional base factor used in counter speech, such as emotion-empathy, offensiveness, and level of hostility. To better understand the counter-speech used in conversational interactions, this study distills persuasion modes into reason, emotion, and credibility and then evaluates their use in two types of conversation interactions: closed (multi-turn) and open (single-turn) conversation interactions concerning racism, sexism, and religion. The evaluation covers the distinct behaviors of human versus generated counter-speech. We also assess the interplay between the replies' stance and each mode of persuasion in the counter-speech. Notably, we observe nuanced differences in the counter-speech persuasion modes for open and closed interactions -- especially on the topic level
&lt;/p&gt;</description></item><item><title>MeanCache&#26159;&#19968;&#31181;&#38754;&#21521;LLMs&#30340;&#35821;&#20041;&#32531;&#23384;&#65292;&#33021;&#22815;&#35782;&#21035;&#35821;&#20041;&#19978;&#30456;&#20284;&#30340;&#26597;&#35810;&#65292;&#20174;&#32780;&#20943;&#23569;&#26597;&#35810;&#25104;&#26412;&#65292;&#26381;&#21153;&#25552;&#20379;&#21830;&#36127;&#36733;&#21644;&#29615;&#22659;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.02694</link><description>&lt;p&gt;
&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38544;&#31169;&#24863;&#30693;&#35821;&#20041;&#32531;&#23384;
&lt;/p&gt;
&lt;p&gt;
Privacy-Aware Semantic Cache for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02694
&lt;/p&gt;
&lt;p&gt;
MeanCache&#26159;&#19968;&#31181;&#38754;&#21521;LLMs&#30340;&#35821;&#20041;&#32531;&#23384;&#65292;&#33021;&#22815;&#35782;&#21035;&#35821;&#20041;&#19978;&#30456;&#20284;&#30340;&#26597;&#35810;&#65292;&#20174;&#32780;&#20943;&#23569;&#26597;&#35810;&#25104;&#26412;&#65292;&#26381;&#21153;&#25552;&#20379;&#21830;&#36127;&#36733;&#21644;&#29615;&#22659;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;ChatGPT&#12289;Google Bard&#12289;Claude&#21644;Llama 2&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#25628;&#32034;&#24341;&#25806;&#21160;&#24577;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#36896;&#25104;&#20102;&#24322;&#24120;&#39640;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;MeanCache&#65292;&#19968;&#31181;&#29992;&#20110;LLMs&#30340;&#35821;&#20041;&#32531;&#23384;&#65292;&#23427;&#33021;&#22815;&#35782;&#21035;&#35821;&#20041;&#19978;&#30456;&#20284;&#30340;&#26597;&#35810;&#20197;&#30830;&#23450;&#32531;&#23384;&#21629;&#20013;&#25110;&#26410;&#21629;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02694v1 Announce Type: cross  Abstract: Large Language Models (LLMs) like ChatGPT, Google Bard, Claude, and Llama 2 have revolutionized natural language processing and search engine dynamics. However, these models incur exceptionally high computational costs. For instance, GPT-3 consists of 175 billion parameters and inference on these models also demands billions of floating-point operations. Caching is a natural solution to reduce LLM inference costs on repeated queries. However, existing caching methods are incapable of finding semantic similarities among LLM queries, leading to unacceptable false hit-and-miss rates.   This paper introduces MeanCache, a semantic cache for LLMs that identifies semantically similar queries to determine cache hit or miss. Using MeanCache, the response to a user's semantically similar query can be retrieved from a local cache rather than re-querying the LLM, thus reducing costs, service provider load, and environmental impact. MeanCache lever
&lt;/p&gt;</description></item><item><title>TeacherLM-7.1B&#26159;&#19968;&#20010;&#23567;&#22411;&#27169;&#22411;&#65292;&#36890;&#36807;&#32473;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26679;&#26412;&#36827;&#34892;&#27880;&#37322;&#65292;&#25945;&#20250;&#20854;&#20182;&#27169;&#22411;&#8220;&#20026;&#20160;&#20040;&#8221;&#32780;&#19981;&#20165;&#20165;&#26159;&#8220;&#20160;&#20040;&#8221;&#12290;&#23427;&#22312;MMLU&#19978;&#21462;&#24471;&#20102;52.3&#30340;&#38646;&#26679;&#26412;&#24471;&#20998;&#65292;&#21516;&#26102;&#20855;&#26377;&#20986;&#33394;&#30340;&#25968;&#25454;&#22686;&#24378;&#33021;&#21147;&#12290;&#21457;&#24067;TeacherLM&#31995;&#21015;&#27169;&#22411;&#21644;&#22686;&#24378;&#30340;&#25968;&#25454;&#38598;&#20316;&#20026;&#24320;&#28304;&#39033;&#30446;&#12290;</title><link>http://arxiv.org/abs/2310.19019</link><description>&lt;p&gt;
TeacherLM: &#25945;&#20154;&#25171;&#40060;&#32780;&#19981;&#26159;&#32473;&#40060;&#65292;&#35821;&#35328;&#24314;&#27169;&#21516;&#29702;
&lt;/p&gt;
&lt;p&gt;
TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language Modeling Likewise. (arXiv:2310.19019v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19019
&lt;/p&gt;
&lt;p&gt;
TeacherLM-7.1B&#26159;&#19968;&#20010;&#23567;&#22411;&#27169;&#22411;&#65292;&#36890;&#36807;&#32473;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26679;&#26412;&#36827;&#34892;&#27880;&#37322;&#65292;&#25945;&#20250;&#20854;&#20182;&#27169;&#22411;&#8220;&#20026;&#20160;&#20040;&#8221;&#32780;&#19981;&#20165;&#20165;&#26159;&#8220;&#20160;&#20040;&#8221;&#12290;&#23427;&#22312;MMLU&#19978;&#21462;&#24471;&#20102;52.3&#30340;&#38646;&#26679;&#26412;&#24471;&#20998;&#65292;&#21516;&#26102;&#20855;&#26377;&#20986;&#33394;&#30340;&#25968;&#25454;&#22686;&#24378;&#33021;&#21147;&#12290;&#21457;&#24067;TeacherLM&#31995;&#21015;&#27169;&#22411;&#21644;&#22686;&#24378;&#30340;&#25968;&#25454;&#38598;&#20316;&#20026;&#24320;&#28304;&#39033;&#30446;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#24778;&#20154;&#30340;&#25512;&#29702;&#21644;&#25968;&#25454;&#22686;&#24378;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23567;&#22411;&#27169;&#22411;&#21602;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TeacherLM-7.1B&#65292;&#33021;&#22815;&#32473;&#22823;&#22810;&#25968;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26679;&#26412;&#36827;&#34892;&#30456;&#20851;&#22522;&#30784;&#30693;&#35782;&#12289;&#24605;&#32500;&#38142;&#21644;&#24120;&#35265;&#38169;&#35823;&#30340;&#27880;&#37322;&#65292;&#20351;&#27880;&#37322;&#19981;&#20165;&#20165;&#26159;&#19968;&#20010;&#31572;&#26696;&#65292;&#32780;&#19988;&#20351;&#20854;&#20182;&#27169;&#22411;&#21487;&#20197;&#23398;&#20064;&#8220;&#20026;&#20160;&#20040;&#8221;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#8220;&#20160;&#20040;&#8221;&#12290;TeacherLM-7.1B&#27169;&#22411;&#22312;MMLU&#19978;&#23454;&#29616;&#20102;52.3&#30340;&#38646;&#26679;&#26412;&#24471;&#20998;&#65292;&#36229;&#36807;&#20102;&#25317;&#26377;100B&#21442;&#25968;&#30340;&#22823;&#22810;&#25968;&#27169;&#22411;&#12290;&#26356;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#26159;&#20854;&#25968;&#25454;&#22686;&#24378;&#33021;&#21147;&#12290;&#22522;&#20110;TeacherLM-7.1B&#65292;&#25105;&#20204;&#22312;&#22810;&#20219;&#21153;&#35774;&#32622;&#20013;&#20351;&#29992;&#20102;&#26469;&#33258;OPT&#21644;BLOOM&#31995;&#21015;&#30340;&#19981;&#21516;&#21442;&#25968;&#30340;&#22810;&#20010;&#23398;&#29983;&#27169;&#22411;&#23545;58&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22686;&#24378;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;TeacherLM&#25552;&#20379;&#30340;&#25968;&#25454;&#22686;&#24378;&#24102;&#26469;&#20102;&#26174;&#30528;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#23558;&#20316;&#20026;&#24320;&#28304;&#21457;&#24067;TeacherLM&#31995;&#21015;&#27169;&#22411;&#21644;&#22686;&#24378;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) exhibit impressive reasoning and data augmentation capabilities in various NLP tasks. However, what about small models? In this work, we propose TeacherLM-7.1B, capable of annotating relevant fundamentals, chain of thought, and common mistakes for most NLP samples, which makes annotation more than just an answer, thus allowing other models to learn "why" instead of just "what". The TeacherLM-7.1B model achieved a zero-shot score of 52.3 on MMLU, surpassing most models with over 100B parameters. Even more remarkable is its data augmentation ability. Based on TeacherLM-7.1B, we augmented 58 NLP datasets and taught various student models with different parameters from OPT and BLOOM series in a multi-task setting. The experimental results indicate that the data augmentation provided by TeacherLM has brought significant benefits. We will release the TeacherLM series of models and augmented datasets as open-source.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#25805;&#25511;&#30693;&#35782;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#30693;&#35782;&#26816;&#32034;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#31616;&#21333;&#30340;&#20998;&#31867;&#12289;&#27604;&#36739;&#21644;&#36870;&#21521;&#25628;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#19981;&#20339;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#36825;&#20123;&#20869;&#22312;&#30340;&#24369;&#28857;&#65306;&#35821;&#35328;&#27169;&#22411;&#26080;&#27861;&#39640;&#25928;&#22320;&#25805;&#25511;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2309.14402</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#30340;&#29289;&#29702;&#23398;&#65306;&#31532;3.2&#37096;&#20998;&#65292;&#30693;&#35782;&#25805;&#25511;
&lt;/p&gt;
&lt;p&gt;
Physics of Language Models: Part 3.2, Knowledge Manipulation. (arXiv:2309.14402v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#25805;&#25511;&#30693;&#35782;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#30693;&#35782;&#26816;&#32034;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#31616;&#21333;&#30340;&#20998;&#31867;&#12289;&#27604;&#36739;&#21644;&#36870;&#21521;&#25628;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#19981;&#20339;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#36825;&#20123;&#20869;&#22312;&#30340;&#24369;&#28857;&#65306;&#35821;&#35328;&#27169;&#22411;&#26080;&#27861;&#39640;&#25928;&#22320;&#25805;&#25511;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#23384;&#20648;&#22823;&#37327;&#20107;&#23454;&#30693;&#35782;&#65292;&#20294;&#23427;&#20204;&#22312;&#20351;&#29992;&#36825;&#20123;&#30693;&#35782;&#36827;&#34892;&#36923;&#36753;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#20173;&#28982;&#23384;&#22312;&#38382;&#39064;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#25805;&#25511;&#20854;&#23384;&#20648;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#37325;&#28857;&#30740;&#31350;&#20102;&#22235;&#31181;&#25805;&#25511;&#31867;&#22411;&#65306;&#26816;&#32034;&#65288;&#20363;&#22914;&#65292;&#8220;A&#30340;&#23646;&#24615;X&#26159;&#20160;&#20040;&#8221;&#65289;&#12289;&#20998;&#31867;&#65288;&#20363;&#22914;&#65292;&#8220;A&#30340;&#23646;&#24615;X&#26159;&#22855;&#25968;&#36824;&#26159;&#20598;&#25968;&#8221;&#65289;&#12289;&#27604;&#36739;&#65288;&#20363;&#22914;&#65292;&#8220;&#22312;&#23646;&#24615;X&#20013;A&#26159;&#21542;&#22823;&#20110;B&#8221;&#65289;&#21644;&#36870;&#21521;&#25628;&#32034;&#65288;&#20363;&#22914;&#65292;&#8220;&#21738;&#20010;&#20154;&#30340;&#23646;&#24615;X&#31561;&#20110;T&#8221;&#65289;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#20687;GPT2/3/4&#36825;&#26679;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#22312;&#30693;&#35782;&#26816;&#32034;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#31616;&#21333;&#30340;&#20998;&#31867;&#25110;&#27604;&#36739;&#20219;&#21153;&#20013;&#24456;&#38590;&#32988;&#20219;&#65292;&#38500;&#38750;&#22312;&#35757;&#32451;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#37319;&#29992;&#20102;Chain of Thoughts&#65288;CoTs&#65289;&#12290;&#26080;&#35770;&#25552;&#31034;&#26159;&#20160;&#20040;&#65292;&#23427;&#20204;&#22312;&#36870;&#21521;&#30693;&#35782;&#25628;&#32034;&#20013;&#34920;&#29616;&#37117;&#24456;&#24046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#19968;&#20010;&#20026;&#25511;&#21046;&#23454;&#39564;&#32780;&#35774;&#35745;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#35777;&#23454;&#20102;&#36825;&#20123;&#20869;&#22312;&#30340;&#24369;&#28857;&#65306;&#35821;&#35328;&#27169;&#22411;&#26080;&#27861;&#39640;&#25928;&#22320;&#25805;&#25511;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language models can store vast amounts of factual knowledge, but their ability to use this knowledge for logical reasoning remains questionable. This paper explores a language model's ability to manipulate its stored knowledge during inference. We focus on four manipulation types: retrieval (e.g., "What is person A's attribute X"), classification (e.g., "Is A's attribute X even or odd?"), comparison (e.g., "Is A greater than B in attribute X?") and inverse search (e.g., "Which person's attribute X equals T?")  We observe that pre-trained language models like GPT2/3/4 excel in knowledge retrieval but struggle with simple classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. They also perform poorly in inverse knowledge search, irrespective of the prompts. Our primary contribution is a synthetic dataset for a controlled experiment that confirms these inherent weaknesses: a language model cannot efficiently manipulate knowledge
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22522;&#20110;GPT&#30340;&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#20013;&#23558;&#39046;&#22495;&#30693;&#35782;&#24211;&#19982;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#65292;&#20197;&#25552;&#39640;&#22238;&#31572;&#30340;&#21487;&#38752;&#24615;&#12290;&#36890;&#36807;&#35774;&#35745;&#21487;&#25193;&#23637;&#30340;&#30693;&#35782;&#24211;&#21644;&#35780;&#20272;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#12290;&#23398;&#29983;&#21644;&#39046;&#22495;&#19987;&#23478;&#23545;&#20110;&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#30340;&#22238;&#31572;&#36827;&#34892;&#20102;&#39564;&#35777;&#21644;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2309.12367</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;GPT&#30340;&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#20013;&#30740;&#31350;&#39046;&#22495;&#30693;&#35782;&#24211;&#19981;&#21516;&#31243;&#24230;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Examining the Influence of Varied Levels of Domain Knowledge Base Inclusion in GPT-based Intelligent Tutors. (arXiv:2309.12367v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12367
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22522;&#20110;GPT&#30340;&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#20013;&#23558;&#39046;&#22495;&#30693;&#35782;&#24211;&#19982;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#65292;&#20197;&#25552;&#39640;&#22238;&#31572;&#30340;&#21487;&#38752;&#24615;&#12290;&#36890;&#36807;&#35774;&#35745;&#21487;&#25193;&#23637;&#30340;&#30693;&#35782;&#24211;&#21644;&#35780;&#20272;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#12290;&#23398;&#29983;&#21644;&#39046;&#22495;&#19987;&#23478;&#23545;&#20110;&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#30340;&#22238;&#31572;&#36827;&#34892;&#20102;&#39564;&#35777;&#21644;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36827;&#23637;&#20419;&#36827;&#20102;&#20855;&#26377;&#22797;&#26434;&#23545;&#35805;&#33021;&#21147;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;LLM&#23545;&#26597;&#35810;&#30340;&#22238;&#31572;&#32463;&#24120;&#19981;&#20934;&#30830;&#65292;&#36825;&#38480;&#21046;&#20102;&#22312;&#25945;&#32946;&#29615;&#22659;&#20013;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#19982;LLM&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#38598;&#25104;&#20197;&#22686;&#21152;&#22238;&#31572;&#21487;&#38752;&#24615;&#30340;&#25928;&#26524;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#30693;&#35782;&#24211;&#65292;&#25945;&#32946;&#30417;&#30563;&#21592;&#21487;&#20197;&#26080;&#32541;&#38598;&#25104;&#35838;&#31243;&#65292;&#35813;&#35838;&#31243;&#20250;&#34987;&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#33258;&#21160;&#22788;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#20010;&#35780;&#20272;&#23454;&#39564;&#65292;&#23398;&#29983;&#21442;&#19982;&#32773;&#38656;&#35201;&#22238;&#31572;&#26377;&#20851;&#20154;&#24037;&#26234;&#33021;&#35838;&#31243;&#30340;&#38382;&#39064;&#12290; GPT-4&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#20855;&#26377;&#19981;&#21516;&#23618;&#27425;&#30340;KB&#35775;&#38382;&#26435;&#38480;&#65292;&#24182;&#30001;&#20154;&#31867;&#39046;&#22495;&#19987;&#23478;&#35780;&#20272;&#36825;&#20123;&#22238;&#31572;&#12290;&#26368;&#21518;&#65292;&#23398;&#29983;&#23545;&#26234;&#33021;&#36741;&#23548;&#31995;&#32479;&#30340;&#22238;&#31572;&#36827;&#34892;&#20102;&#19982;&#39046;&#22495;&#19987;&#23478;&#30340;&#20132;&#21449;&#39564;&#35777;&#65292;&#24182;&#23545;&#23427;&#20204;&#30340;&#21508;&#31181;&#25945;&#23398;&#33021;&#21147;&#36827;&#34892;&#20102;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in large language models (LLMs) have facilitated the development of chatbots with sophisticated conversational capabilities. However, LLMs exhibit frequent inaccurate responses to queries, hindering applications in educational settings. In this paper, we investigate the effectiveness of integrating a knowledge base (KB) with LLM intelligent tutors to increase response reliability. To achieve this, we design a scaleable KB that affords educational supervisors seamless integration of lesson curricula, which is automatically processed by the intelligent tutoring system. We then detail an evaluation, where student participants were presented with questions about the artificial intelligence curriculum to respond to. GPT-4 intelligent tutors with varying hierarchies of KB access and human domain experts then assessed these responses. Lastly, students cross-examined the intelligent tutors' responses to the domain experts' and ranked their various pedagogical abilities. Res
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31264;&#23494;&#19977;&#32500;&#24341;&#29992;&#32593;&#32476;ConcreteNet&#65292;&#21253;&#21547;&#19977;&#20010;&#26032;&#27169;&#22359;&#65292;&#26088;&#22312;&#25913;&#21892;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#31867;&#21035;&#24178;&#25200;&#22240;&#32032;&#30340;&#37325;&#22797;&#23454;&#20363;&#30340;&#24341;&#29992;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.04561</link><description>&lt;p&gt;
&#25913;&#36827;&#31264;&#23494;&#19977;&#32500;&#35270;&#35273;&#24341;&#29992;&#30340;&#19977;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Three Ways to Improve Verbo-visual Fusion for Dense 3D Visual Grounding. (arXiv:2309.04561v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04561
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31264;&#23494;&#19977;&#32500;&#24341;&#29992;&#32593;&#32476;ConcreteNet&#65292;&#21253;&#21547;&#19977;&#20010;&#26032;&#27169;&#22359;&#65292;&#26088;&#22312;&#25913;&#21892;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#31867;&#21035;&#24178;&#25200;&#22240;&#32032;&#30340;&#37325;&#22797;&#23454;&#20363;&#30340;&#24341;&#29992;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19977;&#32500;&#35270;&#35273;&#24341;&#29992;&#26159;&#25351;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#26469;&#23450;&#20301;&#19977;&#32500;&#22330;&#26223;&#20013;&#34987;&#24341;&#29992;&#30340;&#29289;&#20307;&#30340;&#20219;&#21153;&#12290;&#35813;&#20219;&#21153;&#22312;&#33258;&#20027;&#23460;&#20869;&#26426;&#22120;&#20154;&#21040;AR/VR&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#30446;&#21069;&#19968;&#31181;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#36890;&#36807;&#26816;&#27979;&#26469;&#23436;&#25104;&#19977;&#32500;&#35270;&#35273;&#24341;&#29992;&#65292;&#21363;&#36890;&#36807;&#36793;&#30028;&#26694;&#26469;&#23450;&#20301;&#12290;&#28982;&#32780;&#65292;&#22312;&#38656;&#35201;&#36827;&#34892;&#29289;&#29702;&#20132;&#20114;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36793;&#30028;&#26694;&#19981;&#36275;&#20197;&#25551;&#36848;&#29289;&#20307;&#30340;&#20960;&#20309;&#23646;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#31264;&#23494;&#19977;&#32500;&#35270;&#35273;&#24341;&#29992;&#30340;&#38382;&#39064;&#65292;&#21363;&#22522;&#20110;&#24341;&#29992;&#30340;&#19977;&#32500;&#23454;&#20363;&#20998;&#21106;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31264;&#23494;&#19977;&#32500;&#24341;&#29992;&#32593;&#32476;ConcreteNet&#65292;&#20854;&#20013;&#21253;&#21547;&#19977;&#20010;&#29420;&#31435;&#30340;&#26032;&#27169;&#22359;&#65292;&#26088;&#22312;&#25913;&#36827;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#31867;&#21035;&#24178;&#25200;&#22240;&#32032;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#37325;&#22797;&#23454;&#20363;&#30340;&#24341;&#29992;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#33258;&#19979;&#32780;&#19978;&#30340;&#27880;&#24847;&#21147;&#34701;&#21512;&#27169;&#22359;&#65292;&#26088;&#22312;&#28040;&#38500;&#23454;&#20363;&#38388;&#20851;&#31995;&#32447;&#32034;&#30340;&#27495;&#20041;&#24615;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#26500;&#36896;&#19968;&#20010;cont
&lt;/p&gt;
&lt;p&gt;
3D visual grounding is the task of localizing the object in a 3D scene which is referred by a description in natural language. With a wide range of applications ranging from autonomous indoor robotics to AR/VR, the task has recently risen in popularity. A common formulation to tackle 3D visual grounding is grounding-by-detection, where localization is done via bounding boxes. However, for real-life applications that require physical interactions, a bounding box insufficiently describes the geometry of an object. We therefore tackle the problem of dense 3D visual grounding, i.e. referral-based 3D instance segmentation. We propose a dense 3D grounding network ConcreteNet, featuring three novel stand-alone modules which aim to improve grounding performance for challenging repetitive instances, i.e. instances with distractors of the same semantic class. First, we introduce a bottom-up attentive fusion module that aims to disambiguate inter-instance relational cues, next we construct a cont
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24037;&#19994;&#30028;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20013;&#30340;&#23384;&#22312;&#21644;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#36807;&#21435;&#20116;&#24180;&#20013;&#65292;&#24037;&#19994;&#30028;&#30340;&#23384;&#22312;&#19982;&#24433;&#21709;&#21576;&#29616;&#24613;&#21095;&#22686;&#38271;&#65292;&#19968;&#20123;&#20844;&#21496;&#21344;&#25454;&#20102;&#22823;&#37096;&#20998;&#20986;&#29256;&#29289;&#65292;&#24182;&#21521;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#36164;&#37329;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2305.02797</link><description>&lt;p&gt;
&#25151;&#38388;&#37324;&#30340;&#22823;&#35937;&#65306;&#20998;&#26512;&#22823;&#22411;&#31185;&#25216;&#20844;&#21496;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20013;&#30340;&#23384;&#22312;
&lt;/p&gt;
&lt;p&gt;
The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research. (arXiv:2305.02797v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24037;&#19994;&#30028;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20013;&#30340;&#23384;&#22312;&#21644;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#36807;&#21435;&#20116;&#24180;&#20013;&#65292;&#24037;&#19994;&#30028;&#30340;&#23384;&#22312;&#19982;&#24433;&#21709;&#21576;&#29616;&#24613;&#21095;&#22686;&#38271;&#65292;&#19968;&#20123;&#20844;&#21496;&#21344;&#25454;&#20102;&#22823;&#37096;&#20998;&#20986;&#29256;&#29289;&#65292;&#24182;&#21521;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#36164;&#37329;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21019;&#36896;&#20102;&#26032;&#30340;&#21830;&#19994;&#26426;&#20250;&#65292;&#24182;&#19988;&#20351;&#24471;NLP&#30740;&#31350;&#23545;&#20135;&#19994;&#21457;&#23637;&#33267;&#20851;&#37325;&#35201;&#12290;&#20316;&#20026;NLP&#39046;&#22495;&#30340;&#22823;&#29609;&#23478;&#20043;&#19968;&#65292;&#36830;&#21516;&#25919;&#24220;&#21644;&#22823;&#23398;&#19968;&#36215;&#65292;&#36319;&#36394;&#20135;&#19994;&#23545;&#30740;&#31350;&#30340;&#24433;&#21709;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#33268;&#21147;&#20110;&#37327;&#21270;&#21644;&#34920;&#24449;&#24037;&#19994;&#30028;&#22312;NLP&#31038;&#21306;&#20013;&#30340;&#23384;&#22312;&#12290;&#20351;&#29992;&#20855;&#26377;78,187&#31687;NLP&#20986;&#29256;&#29289;&#21644;701&#20010;NLP&#20316;&#32773;&#31616;&#21382;&#30340;&#20840;&#38754;&#20803;&#25968;&#25454;&#35821;&#26009;&#24211;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#33258;&#19978;&#19990;&#32426;90&#24180;&#20195;&#20197;&#26469;&#35813;&#39046;&#22495;&#20013;&#30340;&#24037;&#19994;&#23384;&#22312;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;NLP&#20316;&#32773;&#20013;&#30340;&#24037;&#19994;&#23384;&#22312;&#22312;&#36807;&#21435;&#20116;&#24180;&#20013;&#24613;&#21095;&#22686;&#38271;&#65288;&#20174;2017&#24180;&#21040;2022&#24180;&#30340;&#22686;&#38271;&#29575;&#20026;180&#65285;&#65289;&#12290;&#19968;&#20123;&#20844;&#21496;&#21344;&#25454;&#20102;&#22823;&#37096;&#20998;&#20986;&#29256;&#29289;&#65292;&#24182;&#36890;&#36807;&#25320;&#27454;&#21644;&#23454;&#20064;&#20026;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#36164;&#37329;&#25903;&#25345;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24037;&#19994;&#30028;&#23545;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#30340;&#23384;&#22312;&#21644;&#24433;&#21709;&#26159;&#26174;&#33879;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in deep learning methods for natural language processing (NLP) have created new business opportunities and made NLP research critical for industry development. As one of the big players in the field of NLP, together with governments and universities, it is important to track the influence of industry on research. In this study, we seek to quantify and characterize industry presence in the NLP community over time. Using a corpus with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP publication authors, we explore the industry presence in the field since the early 90s. We find that industry presence among NLP authors has been steady before a steep increase over the past five years (180% growth from 2017 to 2022). A few companies account for most of the publications and provide funding to academic researchers through grants and internships. Our study shows that the presence and impact of the industry on natural language processing research are signi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#27169;&#24335;&#20026;&#23548;&#21521;&#30340;&#36127;&#36131;&#20219;AI-by-design&#21442;&#32771;&#26550;&#26500;&#65292;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#65292;&#37325;&#28857;&#20851;&#27880;&#21487;&#35299;&#37322;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#31561;&#20851;&#38190;&#35774;&#35745;&#20803;&#32032;&#12290;</title><link>http://arxiv.org/abs/2304.11090</link><description>&lt;p&gt;
&#22312;ChatGPT&#26102;&#20195;&#36808;&#21521;&#36127;&#36131;&#20219;&#30340;&#20154;&#24037;&#26234;&#33021;&#65306;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#30340;&#21442;&#32771;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#27169;&#24335;&#20026;&#23548;&#21521;&#30340;&#36127;&#36131;&#20219;AI-by-design&#21442;&#32771;&#26550;&#26500;&#65292;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#65292;&#37325;&#28857;&#20851;&#27880;&#21487;&#35299;&#37322;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#31561;&#20851;&#38190;&#35774;&#35745;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#12289;Bard&#21644;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#25512;&#20986;&#22312;&#20840;&#29699;&#33539;&#22260;&#20869;&#24341;&#36215;&#20102;&#24040;&#22823;&#20851;&#27880;&#12290;&#22522;&#30784;&#27169;&#22411;&#23558;&#25104;&#20026;&#26410;&#26469;&#22823;&#22810;&#25968;AI&#31995;&#32479;&#30340;&#22522;&#30784;&#26500;&#24314;&#22359;&#30340;&#36235;&#21183;&#27491;&#22312;&#22686;&#38271;&#12290;&#28982;&#32780;&#65292;&#23558;&#22522;&#30784;&#27169;&#22411;&#32435;&#20837;AI&#31995;&#32479;&#24341;&#21457;&#20102;&#23545;&#36127;&#36131;&#20219;AI&#30340;&#37325;&#22823;&#20851;&#27880;&#65292;&#36825;&#26159;&#30001;&#20110;&#20854;&#40657;&#21283;&#23376;&#24615;&#36136;&#21644;&#24555;&#36895;&#21457;&#23637;&#30340;&#36229;&#32423;&#26234;&#33021;&#24341;&#36215;&#30340;&#12290;&#27492;&#22806;&#65292;&#22522;&#30784;&#27169;&#22411;&#30340;&#22686;&#38271;&#33021;&#21147;&#26368;&#32456;&#21487;&#33021;&#20250;&#21534;&#22124;AI&#31995;&#32479;&#30340;&#20854;&#20182;&#32452;&#20214;&#65292;&#24341;&#20837;&#26550;&#26500;&#35774;&#35745;&#20013;&#30340;&#36816;&#21160;&#36793;&#30028;&#21644;&#25509;&#21475;&#28436;&#21464;&#25361;&#25112;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#27169;&#24335;&#20026;&#23548;&#21521;&#30340;&#36127;&#36131;&#20219;AI-by-design&#21442;&#32771;&#26550;&#26500;&#65292;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#12290;&#29305;&#21035;&#22320;&#65292;&#26412;&#25991;&#39318;&#20808;&#21576;&#29616;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#22312;&#26550;&#26500;&#28436;&#36827;&#26041;&#38754;&#30340;&#21457;&#23637;&#65292;&#20174;"&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#36830;&#25509;&#22120;"&#21040;"&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#21333;&#29255;&#26426;&#26680;"&#12290;&#28982;&#21518;&#65292;&#23427;&#25552;&#20986;&#20102;&#19968;&#20010;&#21442;&#32771;&#26550;&#26500;&#65292;&#21253;&#25324;&#20116;&#20010;&#31867;&#21035;&#30340;&#27169;&#24335;&#65292;&#37325;&#28857;&#20851;&#27880;&#20851;&#38190;&#35774;&#35745;&#20803;&#32032;&#65292;&#20363;&#22914;&#21487;&#35299;&#37322;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#21442;&#32771;&#26550;&#26500;&#20026;&#35774;&#35745;&#36127;&#36131;&#20219;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#25552;&#20379;&#20102;&#31995;&#32479;&#21270;&#21644;&#36879;&#26126;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The release of ChatGPT, Bard, and other large language model (LLM)-based chatbots has drawn huge attention on foundations models worldwide. There is a growing trend that foundation models will serve as the fundamental building blocks for most of the future AI systems. However, incorporating foundation models in AI systems raises significant concerns about responsible AI due to their black box nature and rapidly advancing super-intelligence. Additionally, the foundation model's growing capabilities can eventually absorb the other components of AI systems, introducing the moving boundary and interface evolution challenges in architecture design. To address these challenges, this paper proposes a pattern-oriented responsible-AI-by-design reference architecture for designing foundation model-based AI systems. Specially, the paper first presents an architecture evolution of AI systems in the era of foundation models, from "foundation-model-as-a-connector" to "foundation-model-as-a-monolithi
&lt;/p&gt;</description></item><item><title>LMExplainer&#26159;&#19968;&#31181;&#30693;&#35782;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#35299;&#37322;&#27169;&#22359;&#65292;&#20351;&#29992;&#30693;&#35782;&#22270;&#21644;&#22270;&#27880;&#24847;&#21147;&#31070;&#32463;&#32593;&#32476;&#26469;&#25552;&#21462;&#20851;&#38190;&#20915;&#31574;&#20449;&#21495;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#21487;&#29702;&#35299;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2303.16537</link><description>&lt;p&gt;
LMExplainer&#65306;&#19968;&#31181;&#21152;&#24378;&#35821;&#35328;&#27169;&#22411;&#35299;&#37322;&#33021;&#21147;&#30340;&#30693;&#35782;&#25552;&#21319;&#27169;&#22359;
&lt;/p&gt;
&lt;p&gt;
LMExplainer: a Knowledge-Enhanced Explainer for Language Models. (arXiv:2303.16537v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16537
&lt;/p&gt;
&lt;p&gt;
LMExplainer&#26159;&#19968;&#31181;&#30693;&#35782;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#35299;&#37322;&#27169;&#22359;&#65292;&#20351;&#29992;&#30693;&#35782;&#22270;&#21644;&#22270;&#27880;&#24847;&#21147;&#31070;&#32463;&#32593;&#32476;&#26469;&#25552;&#21462;&#20851;&#38190;&#20915;&#31574;&#20449;&#21495;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#21487;&#29702;&#35299;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24040;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT-4&#65289;&#38750;&#24120;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22810;&#23618;&#38750;&#32447;&#24615;&#27169;&#22411;&#32467;&#26500;&#21644;&#25968;&#30334;&#19975;&#20010;&#21442;&#25968;&#65292;&#24456;&#38590;&#35299;&#37322;&#20854;&#32467;&#26524;&#12290;&#23545;&#20110;&#29992;&#25143;&#32780;&#35328;&#65292;&#20102;&#35299;&#27169;&#22411;&#30340;&#24037;&#20316;&#26041;&#24335;&#32570;&#20047;&#29702;&#35299;&#65292;&#21487;&#33021;&#20351;&#27169;&#22411;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#20855;&#26377;&#19981;&#21487;&#38752;&#24615;&#21644;&#21361;&#38505;&#24615;&#12290;&#22823;&#22810;&#25968;&#26368;&#36817;&#30340;&#24037;&#20316;&#21033;&#29992;&#27880;&#24847;&#21147;&#26435;&#37325;&#26469;&#25552;&#20379;&#27169;&#22411;&#39044;&#27979;&#30340;&#35299;&#37322;&#12290;&#20294;&#26159;&#65292;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#35299;&#37322;&#26080;&#27861;&#25903;&#25345;&#19981;&#26029;&#22686;&#38271;&#30340;&#27169;&#22411;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#26080;&#27861;&#25512;&#29702;&#20854;&#20915;&#31574;&#36807;&#31243;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LMExplainer&#65292;&#19968;&#31181;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#20154;&#31867;&#21487;&#29702;&#35299;&#35299;&#37322;&#30340;&#30693;&#35782;&#22686;&#24378;&#27169;&#22359;&#12290;&#25105;&#20204;&#20351;&#29992;&#30693;&#35782;&#22270;&#21644;&#22270;&#27880;&#24847;&#21147;&#31070;&#32463;&#32593;&#32476;&#26469;&#25552;&#21462;LM&#30340;&#20851;&#38190;&#20915;&#31574;&#20449;&#21495;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25506;&#35752;&#35299;&#37322;&#33021;&#21542;&#20063;&#24110;&#21161;&#20154;&#24037;&#26234;&#33021;&#26356;&#22909;&#22320;&#29702;&#35299;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LMs) such as GPT-4 are very powerful and can process different kinds of natural language processing (NLP) tasks. However, it can be difficult to interpret the results due to the multi-layer nonlinear model structure and millions of parameters. Lack of understanding of how the model works can make the model unreliable and dangerous for everyday users in real-world scenarios. Most recent works exploit the weights of attention to provide explanations for model predictions. However, pure attention-based explanation is unable to support the growing complexity of the models, and cannot reason about their decision-making processes. Thus, we propose LMExplainer, a knowledge-enhanced interpretation module for language models that can provide human-understandable explanations. We use a knowledge graph (KG) and a graph attention neural network to extract the key decision signals of the LM. We further explore whether interpretation can also help AI understand the task better
&lt;/p&gt;</description></item></channel></rss>