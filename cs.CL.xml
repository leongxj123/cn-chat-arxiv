<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#27700;&#21360;&#39046;&#22495;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#25915;&#20987;&#32773;&#26080;&#27861;&#35775;&#38382;&#27700;&#21360;&#27169;&#22411;&#25110;&#26816;&#27979;API&#30340;&#24773;&#20917;&#19979;&#65292;&#27700;&#21360;&#22522;&#30784;&#30340;AI&#29983;&#25104;&#22270;&#20687;&#26816;&#27979;&#22120;&#20063;&#26080;&#27861;&#25269;&#25239;&#23545;&#25239;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2403.15365</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#22270;&#20687;&#27700;&#21360;&#30340;&#36716;&#31227;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
A Transfer Attack to Image Watermarks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15365
&lt;/p&gt;
&lt;p&gt;
&#27700;&#21360;&#39046;&#22495;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#25915;&#20987;&#32773;&#26080;&#27861;&#35775;&#38382;&#27700;&#21360;&#27169;&#22411;&#25110;&#26816;&#27979;API&#30340;&#24773;&#20917;&#19979;&#65292;&#27700;&#21360;&#22522;&#30784;&#30340;AI&#29983;&#25104;&#22270;&#20687;&#26816;&#27979;&#22120;&#20063;&#26080;&#27861;&#25269;&#25239;&#23545;&#25239;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27700;&#21360;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#24037;&#19994;&#39046;&#22495;&#65292;&#29992;&#20110;&#26816;&#27979;&#30001;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#22270;&#20687;&#12290;&#25991;&#29486;&#20013;&#23545;&#36825;&#31181;&#22522;&#20110;&#27700;&#21360;&#30340;&#26816;&#27979;&#22120;&#22312;&#30333;&#30418;&#21644;&#40657;&#30418;&#29615;&#22659;&#19979;&#23545;&#25239;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#26377;&#24456;&#22909;&#30340;&#29702;&#35299;&#12290;&#28982;&#32780;&#65292;&#22312;&#26080;&#30418;&#29615;&#22659;&#19979;&#30340;&#31283;&#20581;&#24615;&#21364;&#30693;&#20043;&#29978;&#23569;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22810;&#39033;&#30740;&#31350;&#22768;&#31216;&#22270;&#20687;&#27700;&#21360;&#22312;&#36825;&#31181;&#29615;&#22659;&#19979;&#26159;&#31283;&#20581;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36716;&#31227;&#23545;&#25239;&#25915;&#20987;&#26469;&#38024;&#23545;&#26080;&#30418;&#29615;&#22659;&#19979;&#30340;&#22270;&#20687;&#27700;&#21360;&#12290;&#25105;&#20204;&#30340;&#36716;&#31227;&#25915;&#20987;&#21521;&#24102;&#27700;&#21360;&#30340;&#22270;&#20687;&#28155;&#21152;&#24494;&#25200;&#65292;&#20197;&#36530;&#36991;&#34987;&#25915;&#20987;&#32773;&#35757;&#32451;&#30340;&#22810;&#20010;&#26367;&#20195;&#27700;&#21360;&#27169;&#22411;&#65292;&#24182;&#19988;&#32463;&#36807;&#25200;&#21160;&#30340;&#24102;&#27700;&#21360;&#22270;&#20687;&#20063;&#33021;&#36530;&#36991;&#30446;&#26631;&#27700;&#21360;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#29702;&#35770;&#19978;&#21644;&#32463;&#39564;&#19978;&#23637;&#31034;&#20102;&#65292;&#22522;&#20110;&#27700;&#21360;&#30340;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#22270;&#20687;&#26816;&#27979;&#22120;&#21363;&#20351;&#25915;&#20987;&#32773;&#27809;&#26377;&#35775;&#38382;&#27700;&#21360;&#27169;&#22411;&#25110;&#26816;&#27979;API&#65292;&#20063;&#19981;&#20855;&#26377;&#23545;&#25239;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15365v1 Announce Type: cross  Abstract: Watermark has been widely deployed by industry to detect AI-generated images. The robustness of such watermark-based detector against evasion attacks in the white-box and black-box settings is well understood in the literature. However, the robustness in the no-box setting is much less understood. In particular, multiple studies claimed that image watermark is robust in such setting. In this work, we propose a new transfer evasion attack to image watermark in the no-box setting. Our transfer attack adds a perturbation to a watermarked image to evade multiple surrogate watermarking models trained by the attacker itself, and the perturbed watermarked image also evades the target watermarking model. Our major contribution is to show that, both theoretically and empirically, watermark-based AI-generated image detector is not robust to evasion attacks even if the attacker does not have access to the watermarking model nor the detection API.
&lt;/p&gt;</description></item><item><title>StyleSinger&#26159;&#38024;&#23545;&#39046;&#22495;&#22806;&#28436;&#21809;&#22768;&#38899;&#21512;&#25104;&#30340;&#39118;&#26684;&#36716;&#31227;&#27169;&#22411;&#65292;&#36890;&#36807;&#27531;&#24046;&#39118;&#26684;&#36866;&#37197;&#22120;&#65288;RSA&#65289;&#25429;&#25417;&#22810;&#26679;&#30340;&#39118;&#26684;&#29305;&#24449;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#28436;&#21809;&#22768;&#38899;&#12290;</title><link>http://arxiv.org/abs/2312.10741</link><description>&lt;p&gt;
StyleSinger: &#38024;&#23545;&#39046;&#22495;&#22806;&#28436;&#21809;&#22768;&#38899;&#21512;&#25104;&#30340;&#39118;&#26684;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis. (arXiv:2312.10741v2 [eess.AS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.10741
&lt;/p&gt;
&lt;p&gt;
StyleSinger&#26159;&#38024;&#23545;&#39046;&#22495;&#22806;&#28436;&#21809;&#22768;&#38899;&#21512;&#25104;&#30340;&#39118;&#26684;&#36716;&#31227;&#27169;&#22411;&#65292;&#36890;&#36807;&#27531;&#24046;&#39118;&#26684;&#36866;&#37197;&#22120;&#65288;RSA&#65289;&#25429;&#25417;&#22810;&#26679;&#30340;&#39118;&#26684;&#29305;&#24449;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#28436;&#21809;&#22768;&#38899;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#39046;&#22495;&#22806;&#28436;&#21809;&#22768;&#38899;&#21512;&#25104;&#65288;SVS&#65289;&#30340;&#39118;&#26684;&#36716;&#31227;&#19987;&#27880;&#20110;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#28436;&#21809;&#22768;&#38899;&#65292;&#35813;&#22768;&#38899;&#20855;&#26377;&#20174;&#21442;&#32771;&#28436;&#21809;&#22768;&#38899;&#26679;&#26412;&#20013;&#34893;&#29983;&#30340;&#26410;&#35265;&#39118;&#26684;&#65288;&#22914;&#38899;&#33394;&#12289;&#24773;&#24863;&#12289;&#21457;&#38899;&#21644;&#21457;&#38899;&#25216;&#24039;&#65289;&#12290;&#28982;&#32780;&#65292;&#27169;&#25311;&#28436;&#21809;&#22768;&#38899;&#39118;&#26684;&#30340;&#31934;&#32454;&#24046;&#24322;&#26159;&#19968;&#39033;&#33392;&#24040;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#28436;&#21809;&#22768;&#38899;&#20855;&#26377;&#38750;&#24120;&#39640;&#30340;&#34920;&#29616;&#21147;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;SVS&#26041;&#27861;&#22312;&#39046;&#22495;&#22806;&#22330;&#26223;&#20013;&#21512;&#25104;&#30340;&#28436;&#21809;&#22768;&#38899;&#36136;&#37327;&#19979;&#38477;&#65292;&#22240;&#20026;&#23427;&#20204;&#22522;&#20110;&#35757;&#32451;&#38454;&#27573;&#21487;&#36776;&#21035;&#20986;&#30446;&#26631;&#22768;&#38899;&#23646;&#24615;&#30340;&#20551;&#35774;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;StyleSinger&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#39046;&#22495;&#22806;&#21442;&#32771;&#28436;&#21809;&#22768;&#38899;&#26679;&#26412;&#30340;&#38646;&#26679;&#24335;&#36716;&#31227;&#30340;&#28436;&#21809;&#22768;&#38899;&#21512;&#25104;&#27169;&#22411;&#12290;StyleSinger&#37319;&#29992;&#20102;&#20004;&#31181;&#20851;&#38190;&#26041;&#27861;&#20197;&#25552;&#39640;&#25928;&#26524;&#65306;1&#65289;&#27531;&#24046;&#39118;&#26684;&#36866;&#37197;&#22120;&#65288;RSA&#65289;&#65292;&#23427;&#20351;&#29992;&#27531;&#24046;&#37327;&#21270;&#27169;&#22359;&#26469;&#25429;&#25417;&#22810;&#26679;&#30340;&#39118;&#26684;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Style transfer for out-of-domain (OOD) singing voice synthesis (SVS) focuses on generating high-quality singing voices with unseen styles (such as timbre, emotion, pronunciation, and articulation skills) derived from reference singing voice samples. However, the endeavor to model the intricate nuances of singing voice styles is an arduous task, as singing voices possess a remarkable degree of expressiveness. Moreover, existing SVS methods encounter a decline in the quality of synthesized singing voices in OOD scenarios, as they rest upon the assumption that the target vocal attributes are discernible during the training phase. To overcome these challenges, we propose StyleSinger, the first singing voice synthesis model for zero-shot style transfer of out-of-domain reference singing voice samples. StyleSinger incorporates two critical approaches for enhanced effectiveness: 1) the Residual Style Adaptor (RSA) which employs a residual quantization module to capture diverse style character
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#20351;&#29992;ChatGPT&#21450;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#30340;&#28508;&#21147;&#65292;&#21457;&#29616;ChatGPT&#30340;&#39044;&#27979;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#32780;&#22522;&#30784;&#27169;&#22411;&#26080;&#27861;&#20934;&#30830;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#21464;&#21270;&#65292;&#34920;&#26126;&#22797;&#26434;&#27169;&#22411;&#21487;&#39044;&#27979;&#33021;&#21147;&#30340;&#23835;&#36215;&#12290;&#36825;&#34920;&#26126;&#22312;&#25237;&#36164;&#20915;&#31574;&#36807;&#31243;&#20013;&#24341;&#20837;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#24182;&#22686;&#24378;&#23450;&#37327;&#20132;&#26131;&#31574;&#30053;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.07619</link><description>&lt;p&gt;
ChatGPT&#26159;&#21542;&#33021;&#22815;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#27874;&#21160;&#65311;&#22238;&#25253;&#21487;&#39044;&#27979;&#24615;&#19982;&#22823;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#20351;&#29992;ChatGPT&#21450;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#30340;&#28508;&#21147;&#65292;&#21457;&#29616;ChatGPT&#30340;&#39044;&#27979;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#32780;&#22522;&#30784;&#27169;&#22411;&#26080;&#27861;&#20934;&#30830;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#21464;&#21270;&#65292;&#34920;&#26126;&#22797;&#26434;&#27169;&#22411;&#21487;&#39044;&#27979;&#33021;&#21147;&#30340;&#23835;&#36215;&#12290;&#36825;&#34920;&#26126;&#22312;&#25237;&#36164;&#20915;&#31574;&#36807;&#31243;&#20013;&#24341;&#20837;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#24182;&#22686;&#24378;&#23450;&#37327;&#20132;&#26131;&#31574;&#30053;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#24773;&#24863;&#20998;&#26512;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#30340;&#28508;&#21147;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;ChatGPT&#20197;&#21450;&#20854;&#20182;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#20351;&#29992;ChatGPT&#21028;&#26029;&#26032;&#38395;&#26631;&#39064;&#23545;&#20844;&#21496;&#32929;&#31080;&#20215;&#26684;&#26159;&#22909;&#28040;&#24687;&#12289;&#22351;&#28040;&#24687;&#25110;&#26080;&#20851;&#28040;&#24687;&#12290;&#36890;&#36807;&#35745;&#31639;&#25968;&#23383;&#20998;&#25968;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;"ChatGPT&#20998;&#25968;"&#21644;&#38543;&#21518;&#30340;&#26085;&#24120;&#32929;&#31080;&#24066;&#22330;&#22238;&#25253;&#20043;&#38388;&#23384;&#22312;&#27491;&#30456;&#20851;&#24615;&#12290;&#32780;&#19988;&#65292;ChatGPT&#30340;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#30340;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-1&#12289;GPT-2&#21644;BERT&#31561;&#22522;&#30784;&#27169;&#22411;&#26080;&#27861;&#20934;&#30830;&#39044;&#27979;&#22238;&#25253;&#65292;&#36825;&#34920;&#26126;&#22238;&#25253;&#21487;&#39044;&#27979;&#24615;&#26159;&#22797;&#26434;&#27169;&#22411;&#30340;&#19968;&#31181;&#26032;&#20852;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#32435;&#20837;&#25237;&#36164;&#20915;&#31574;&#36807;&#31243;&#21487;&#20197;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#24182;&#25552;&#39640;&#23450;&#37327;&#20132;&#26131;&#31574;&#30053;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the potential of ChatGPT, and other large language models, in predicting stock market returns using sentiment analysis of news headlines. We use ChatGPT to indicate whether a given headline is good, bad, or irrelevant news for firms' stock prices. We then compute a numerical score and document a positive correlation between these ``ChatGPT scores'' and subsequent daily stock market returns. Further, ChatGPT outperforms traditional sentiment analysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT cannot accurately forecast returns, indicating return predictability is an emerging capacity of complex models. Our results suggest that incorporating advanced language models into the investment decision-making process can yield more accurate predictions and enhance the performance of quantitative trading strategies.
&lt;/p&gt;</description></item></channel></rss>