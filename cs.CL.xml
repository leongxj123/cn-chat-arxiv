<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>FineFake &#25968;&#25454;&#38598;&#20026;&#32454;&#31890;&#24230;&#22810;&#39046;&#22495;&#20551;&#26032;&#38395;&#26816;&#27979;&#25552;&#20379;&#20102;&#30693;&#35782;&#22686;&#24378;&#65292;&#21253;&#21547;16,909&#20010;&#25968;&#25454;&#26679;&#26412;&#35206;&#30422;&#20845;&#20010;&#35821;&#20041;&#20027;&#39064;&#21644;&#20843;&#20010;&#24179;&#21488;&#12290;</title><link>https://arxiv.org/abs/2404.01336</link><description>&lt;p&gt;
FineFake&#65306;&#19968;&#20010;&#29992;&#20110;&#32454;&#31890;&#24230;&#22810;&#39046;&#22495;&#20551;&#26032;&#38395;&#26816;&#27979;&#30340;&#30693;&#35782;&#22686;&#24378;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
FineFake: A Knowledge-Enriched Dataset for Fine-Grained Multi-Domain Fake News Detecction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01336
&lt;/p&gt;
&lt;p&gt;
FineFake &#25968;&#25454;&#38598;&#20026;&#32454;&#31890;&#24230;&#22810;&#39046;&#22495;&#20551;&#26032;&#38395;&#26816;&#27979;&#25552;&#20379;&#20102;&#30693;&#35782;&#22686;&#24378;&#65292;&#21253;&#21547;16,909&#20010;&#25968;&#25454;&#26679;&#26412;&#35206;&#30422;&#20845;&#20010;&#35821;&#20041;&#20027;&#39064;&#21644;&#20843;&#20010;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#22522;&#20934;&#25968;&#25454;&#38598;&#22312;&#35780;&#20272;&#26032;&#38395;&#20869;&#23481;&#30340;&#30495;&#23454;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#36890;&#24120;&#20165;&#20851;&#27880;&#21333;&#19968;&#35821;&#20041;&#20027;&#39064;&#30340;&#26032;&#38395;&#25110;&#26469;&#33258;&#21333;&#19968;&#24179;&#21488;&#30340;&#26032;&#38395;&#65292;&#22240;&#27492;&#26080;&#27861;&#25429;&#25417;&#30495;&#23454;&#22330;&#26223;&#20013;&#22810;&#39046;&#22495;&#26032;&#38395;&#30340;&#22810;&#26679;&#24615;&#12290;&#20026;&#20102;&#20102;&#35299;&#19981;&#21516;&#39046;&#22495;&#30340;&#20551;&#26032;&#38395;&#65292;&#22806;&#37096;&#30693;&#35782;&#21644;&#32454;&#31890;&#24230;&#27880;&#37322;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#25552;&#20379;&#31934;&#30830;&#35777;&#25454;&#24182;&#25581;&#31034;&#21046;&#36896;&#20551;&#26032;&#38395;&#30340;&#22810;&#26679;&#28508;&#22312;&#31574;&#30053;&#65292;&#32780;&#36825;&#20063;&#26159;&#29616;&#26377;&#22522;&#20934;&#25968;&#25454;&#38598;&#25152;&#24573;&#30053;&#30340;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;FineFake&#30340;&#26032;&#22411;&#22810;&#39046;&#22495;&#30693;&#35782;&#22686;&#24378;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20855;&#26377;&#32454;&#31890;&#24230;&#27880;&#37322;&#12290;FineFake&#28085;&#30422;&#20102;&#26469;&#33258;&#20845;&#20010;&#35821;&#20041;&#20027;&#39064;&#21644;&#20843;&#20010;&#24179;&#21488;&#30340;16,909&#20010;&#25968;&#25454;&#26679;&#26412;&#12290;&#27599;&#20010;&#26032;&#38395;&#39033;&#30446;&#37117;&#21253;&#21547;&#22810;&#27169;&#24577;&#20869;&#23481;&#12289;&#28508;&#22312;&#31038;&#20132;&#32972;&#26223;&#12289;&#21322;&#33258;&#21160;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01336v1 Announce Type: cross  Abstract: Existing benchmarks for fake news detection have significantly contributed to the advancement of models in assessing the authenticity of news content. However, these benchmarks typically focus solely on news pertaining to a single semantic topic or originating from a single platform, thereby failing to capture the diversity of multi-domain news in real scenarios. In order to understand fake news across various domains, the external knowledge and fine-grained annotations are indispensable to provide precise evidence and uncover the diverse underlying strategies for fabrication, which are also ignored by existing benchmarks. To address this gap, we introduce a novel multi-domain knowledge-enhanced benchmark with fine-grained annotations, named \textbf{FineFake}. FineFake encompasses 16,909 data samples spanning six semantic topics and eight platforms. Each news item is enriched with multi-modal content, potential social context, semi-man
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#32763;&#35793;&#25968;&#25454;&#36741;&#21161;&#24418;&#24577;&#20998;&#21106;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23383;&#31526;&#32423;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#65292;&#20197;&#21450;&#39044;&#20808;&#35757;&#32451;&#30340;&#39640;&#36164;&#28304;&#21333;&#35821;&#35328;&#27169;&#22411;&#30340;&#32763;&#35793;&#34920;&#31034;&#65292;&#23454;&#29616;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#19979;&#36229;&#36234;&#22522;&#32447;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.14840</link><description>&lt;p&gt;
TAMS: &#32763;&#35793;&#36741;&#21161;&#30340;&#24418;&#24577;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
TAMS: Translation-Assisted Morphological Segmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14840
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#32763;&#35793;&#25968;&#25454;&#36741;&#21161;&#24418;&#24577;&#20998;&#21106;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23383;&#31526;&#32423;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#65292;&#20197;&#21450;&#39044;&#20808;&#35757;&#32451;&#30340;&#39640;&#36164;&#28304;&#21333;&#35821;&#35328;&#27169;&#22411;&#30340;&#32763;&#35793;&#34920;&#31034;&#65292;&#23454;&#29616;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#19979;&#36229;&#36234;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35268;&#33539;&#24418;&#24577;&#20998;&#21106;&#26159;&#23558;&#21333;&#35789;&#20998;&#26512;&#20026;&#20854;&#26500;&#25104;&#24418;&#24577;&#32032;&#30340;&#26631;&#20934;&#65288;&#20063;&#31216;&#20026;&#24213;&#23618;&#65289;&#24418;&#24335;&#30340;&#36807;&#31243;&#12290;&#36825;&#26159;&#35821;&#35328;&#25991;&#26723;&#32534;&#21046;&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#65292;NLP &#31995;&#32479;&#26377;&#26395;&#26174;&#33879;&#21152;&#24555;&#36825;&#19968;&#22788;&#29702;&#36807;&#31243;&#12290;&#22312;&#20856;&#22411;&#30340;&#35821;&#35328;&#25991;&#26723;&#32534;&#21046;&#29615;&#22659;&#20013;&#65292;&#35268;&#33539;&#24418;&#24577;&#20998;&#21106;&#30340;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#65292;&#36825;&#20351;&#24471;&#38590;&#20197;&#35757;&#32451;&#20986;&#39640;&#36136;&#37327;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#32763;&#35793;&#25968;&#25454;&#36890;&#24120;&#26356;&#20026;&#20016;&#23500;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23581;&#35797;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#35268;&#33539;&#20998;&#21106;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23383;&#31526;&#32423;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#26469;&#33258;&#39044;&#20808;&#35757;&#32451;&#30340;&#39640;&#36164;&#28304;&#21333;&#35821;&#35328;&#27169;&#22411;&#30340;&#32763;&#35793;&#34920;&#31034;&#20316;&#20026;&#39069;&#22806;&#20449;&#21495;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#36229;&#20302;&#36164;&#28304;&#35774;&#32622;&#20013;&#20248;&#20110;&#22522;&#32447;&#65292;&#20294;&#22312;&#20855;&#26377;&#26356;&#22810;&#25968;&#25454;&#30340;&#35757;&#32451;&#20998;&#21106;&#19978;&#20135;&#29983;&#20102;&#19981;&#21516;&#30340;&#32467;&#26524;&#12290;&#38656;&#35201;&#36827;&#19968;&#27493;&#24037;&#20316;&#25165;&#33021;&#20351;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14840v1 Announce Type: new  Abstract: Canonical morphological segmentation is the process of analyzing words into the standard (aka underlying) forms of their constituent morphemes. This is a core task in language documentation, and NLP systems have the potential to dramatically speed up this process. But in typical language documentation settings, training data for canonical morpheme segmentation is scarce, making it difficult to train high quality models. However, translation data is often much more abundant, and, in this work, we present a method that attempts to leverage this data in the canonical segmentation task. We propose a character-level sequence-to-sequence model that incorporates representations of translations obtained from pretrained high-resource monolingual language models as an additional signal. Our model outperforms the baseline in a super-low resource setting but yields mixed results on training splits with more data. While further work is needed to make
&lt;/p&gt;</description></item><item><title>Ouroboros&#36890;&#36807;&#26500;&#24314;&#30701;&#23567;&#33609;&#26696;&#24182;&#24341;&#20837;&#20505;&#36873;&#30701;&#35821;&#27744;&#30340;&#26041;&#27861;&#25552;&#39640;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#21152;&#36895;&#25928;&#29575;</title><link>https://arxiv.org/abs/2402.13720</link><description>&lt;p&gt;
Ouroboros: &#22823;&#27169;&#22411;&#22686;&#24378;&#33609;&#26696;&#30340;&#29468;&#27979;&#35299;&#30721;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Ouroboros: Speculative Decoding with Large Model Enhanced Drafting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13720
&lt;/p&gt;
&lt;p&gt;
Ouroboros&#36890;&#36807;&#26500;&#24314;&#30701;&#23567;&#33609;&#26696;&#24182;&#24341;&#20837;&#20505;&#36873;&#30701;&#35821;&#27744;&#30340;&#26041;&#27861;&#25552;&#39640;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#21152;&#36895;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26500;&#24314;&#30701;&#23567;&#39640;&#25928;&#30340;&#23567;&#27169;&#22411;&#36215;&#33609;&#33609;&#26696;&#65292;&#28982;&#21518;&#35201;&#27714;&#22823;&#35821;&#35328;&#27169;&#22411;&#20197;&#26080;&#33258;&#22238;&#24402;&#26041;&#24335;&#36827;&#34892;&#39564;&#35777;&#21644;&#20462;&#27491;&#65292;&#20197;&#26368;&#23567;&#21270;&#26102;&#38388;&#24320;&#38144;&#12290;&#24403;&#39564;&#35777;&#21518;&#21487;&#20197;&#29983;&#25104;&#26356;&#38271;&#30340;&#33609;&#31295;&#65292;&#20294;&#20063;&#20250;&#23548;&#33268;&#30456;&#24403;&#22823;&#30340;&#23581;&#35797;&#21644;&#38169;&#35823;&#25104;&#26412;&#12290;&#30001;&#20110;&#39640;&#39564;&#35777;&#22833;&#36133;&#27010;&#29575;&#65292;&#29616;&#26377;&#35299;&#30721;&#26041;&#27861;&#19981;&#33021;&#19968;&#27425;&#36215;&#33609;&#22826;&#22810;&#20869;&#23481;&#36827;&#34892;&#39564;&#35777;&#65292;&#23454;&#29616;&#27425;&#20248;&#30340;&#25512;&#29702;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13720v1 Announce Type: new  Abstract: Drafting-then-verifying decoding methods such as speculative decoding are widely adopted training-free methods to accelerate the inference of large language models (LLMs). Instead of employing an autoregressive process to decode tokens sequentially, speculative decoding initially creates drafts with an efficient small model. Then LLMs are required to conduct verification and correction in a non-autoregressive fashion to minimize time overhead. Generating longer drafts can lead to even more significant speedups once verified, but also incurs substantial trial and error costs if it fails. Suffering from the high verification failure probability, existing decoding methods cannot draft too much content for verification at one time, achieving sub-optimal inference acceleration. In this paper, we introduce Ouroboros, which constructs a phrase candidate pool from the verification process of LLMs to provide candidates for draft generation of the
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32534;&#36753;HotpotQA&#25968;&#25454;&#38598;&#20013;&#30340;&#26032;&#30693;&#35782;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;LLM MHQA&#35780;&#20272;&#22522;&#20934;&#65292;&#21516;&#26102;&#27880;&#37322;&#21644;&#35780;&#20272;&#20102;&#25512;&#29702;&#38142;&#65292;&#25581;&#31034;&#20102;&#24403;&#21069;MHQA&#22522;&#20934;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#30340;&#28508;&#22312;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2402.11924</link><description>&lt;p&gt;
MRKE&#65306;&#36890;&#36807;&#30693;&#35782;&#32534;&#36753;&#23545;LLMs&#36827;&#34892;&#22810;&#36339;&#25512;&#29702;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11924
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32534;&#36753;HotpotQA&#25968;&#25454;&#38598;&#20013;&#30340;&#26032;&#30693;&#35782;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;LLM MHQA&#35780;&#20272;&#22522;&#20934;&#65292;&#21516;&#26102;&#27880;&#37322;&#21644;&#35780;&#20272;&#20102;&#25512;&#29702;&#38142;&#65292;&#25581;&#31034;&#20102;&#24403;&#21069;MHQA&#22522;&#20934;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#30340;&#28508;&#22312;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22810;&#36339;&#38382;&#39064;&#22238;&#31572;&#65288;MHQA&#65289;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#30495;&#27491;&#30340;&#25512;&#29702;&#33021;&#21147;&#20173;&#26377;&#24453;&#25506;&#35752;&#12290;&#30446;&#21069;&#30340;LLM QA&#35780;&#20272;&#22522;&#20934;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#65292;&#21253;&#25324;1&#65289;&#25968;&#25454;&#27745;&#26579;&#65292;&#35780;&#20272;&#25968;&#25454;&#21487;&#33021;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#26292;&#38706;&#32473;LLMs&#65307;&#20197;&#21450;2&#65289;&#24573;&#35270;&#25512;&#29702;&#38142;&#35780;&#20272;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;LLM MHQA&#35780;&#20272;&#22522;&#20934;&#65292;&#36825;&#26159;&#22522;&#20110;&#32534;&#36753;&#29616;&#25104;HotpotQA&#25968;&#25454;&#38598;&#19978;&#30340;&#26032;&#12289;&#21069;&#25152;&#26410;&#26377;&#30340;&#30693;&#35782;&#30340;&#31532;&#19968;&#20010;QA&#22522;&#20934;&#65307;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#27880;&#37322;&#21644;&#35780;&#20272;&#20102;&#25512;&#29702;&#38142;&#65292;&#20197;&#23376;&#38382;&#39064;&#21644;&#20013;&#38388;&#31572;&#26696;&#30340;&#24418;&#24335;&#23545;&#24212;&#20110;&#22810;&#36339;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#26681;&#25454;&#35266;&#23519;&#32467;&#26524;&#65292;1&#65289;LLMs&#22312;&#21407;&#22987;HotpotQA&#21644;&#25105;&#20204;&#32534;&#36753;&#30340;&#25968;&#25454;&#20043;&#38388;&#26174;&#31034;&#24615;&#33021;&#24046;&#36317;&#65292;&#35748;&#20026;&#24403;&#21069;&#30340;MHQA&#22522;&#20934;&#21487;&#33021;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#38590;&#20197;&#35780;&#20272;LLMs&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11924v1 Announce Type: new  Abstract: Although Large Language Models (LLMs) have shown strong performance in Multi-hop Question Answering (MHQA) tasks, their real reasoning ability remains exploration. Current LLM QA evaluation benchmarks have shown limitations, including 1) data contamination, the evaluation data are potentially exposed to LLMs during the pretraining stage; and 2) ignoration of the reasoning chain evaluation. Thus we introduce an LLM MHQA evaluation benchmark, the first QA benchmark based on the new, unprecedented knowledge by editing the off-the-shelf HotpotQA dataset; Besides, we also annotate and evaluate the reasoning chain in the form of sub-questions and intermediate answers corresponding to the multi-hop questions. Specifically, based on the observation, 1) LLMs show a performance gap between the original HotpotQA and our edited data, deeming that current MHQA benchmarks have the potential risk of data contamination that hard to evaluate LLMs' perfor
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Layer Collapse&#65288;LaCo&#65289;&#30340;&#31616;&#26126;&#30340;&#36880;&#23618;&#21098;&#26525;&#26041;&#27861;&#65292;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#22312;&#20445;&#25345;&#27169;&#22411;&#32467;&#26500;&#30340;&#21516;&#26102;&#36805;&#36895;&#20943;&#23567;&#23610;&#23544;&#65292;&#24182;&#22312;&#21098;&#26525;&#27604;&#20363;&#36798;&#21040;25-30%&#26102;&#20445;&#25345;&#36229;&#36807;80%&#30340;&#24179;&#22343;&#20219;&#21153;&#24615;&#33021;&#65292;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#32467;&#26500;&#21270;&#21098;&#26525;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.11187</link><description>&lt;p&gt;
LaCo&#65306;&#36890;&#36807;&#23618;&#21472;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21098;&#26525;
&lt;/p&gt;
&lt;p&gt;
LaCo: Large Language Model Pruning via Layer Collapse
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11187
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Layer Collapse&#65288;LaCo&#65289;&#30340;&#31616;&#26126;&#30340;&#36880;&#23618;&#21098;&#26525;&#26041;&#27861;&#65292;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#22312;&#20445;&#25345;&#27169;&#22411;&#32467;&#26500;&#30340;&#21516;&#26102;&#36805;&#36895;&#20943;&#23567;&#23610;&#23544;&#65292;&#24182;&#22312;&#21098;&#26525;&#27604;&#20363;&#36798;&#21040;25-30%&#26102;&#20445;&#25345;&#36229;&#36807;80%&#30340;&#24179;&#22343;&#20219;&#21153;&#24615;&#33021;&#65292;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#32467;&#26500;&#21270;&#21098;&#26525;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#27491;&#32463;&#21382;&#30528;&#23610;&#23544;&#25193;&#22823;&#30340;&#26126;&#26174;&#36235;&#21183;&#65292;&#36825;&#32473;&#27169;&#22411;&#30340;&#35757;&#32451;&#21644;&#25512;&#29702;&#24102;&#26469;&#20102;&#30456;&#24403;&#22823;&#30340;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#22914;&#27169;&#22411;&#37327;&#21270;&#12289;&#30693;&#35782;&#33976;&#39311;&#21644;&#27169;&#22411;&#21098;&#26525;&#21463;&#21040;&#21508;&#31181;&#38382;&#39064;&#30340;&#38480;&#21046;&#65292;&#21253;&#25324;&#30828;&#20214;&#25903;&#25345;&#38480;&#21046;&#12289;&#38656;&#35201;&#22823;&#37327;&#30340;&#35757;&#32451;&#21644;&#23545;&#27169;&#22411;&#20869;&#37096;&#32467;&#26500;&#30340;&#25913;&#21464;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#27905;&#30340;&#36880;&#23618;&#21098;&#26525;&#26041;&#27861;&#65292;&#31216;&#20026;Layer Collapse&#65288;LaCo&#65289;&#65292;&#20854;&#20013;&#21518;&#32622;&#27169;&#22411;&#23618;&#25240;&#21472;&#21040;&#21069;&#32622;&#23618;&#65292;&#20351;&#27169;&#22411;&#23610;&#23544;&#36805;&#36895;&#20943;&#23567;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#32467;&#26500;&#12290;&#32508;&#21512;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21098;&#26525;&#27604;&#20363;&#36798;&#21040;25-30%&#26102;&#65292;&#20445;&#25345;&#20102;&#36229;&#36807;80%&#30340;&#24179;&#22343;&#20219;&#21153;&#24615;&#33021;&#65292;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#32467;&#26500;&#21270;&#21098;&#26525;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#21518;&#35757;&#32451;&#23454;&#39564;&#20197;&#30830;&#35748;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11187v1 Announce Type: cross  Abstract: Large language models (LLMs) based on transformer are witnessing a notable trend of size expansion, which brings considerable costs to both model training and inference. However, existing methods such as model quantization, knowledge distillation, and model pruning are constrained by various issues, including hardware support limitations, the need for extensive training, and alterations to the internal structure of the model. In this paper, we propose a concise layer-wise pruning method called \textit{Layer Collapse (LaCo)}, in which rear model layers collapse into a prior layer, enabling a rapid reduction in model size while preserving the model structure. Comprehensive experiments show that our method maintains an average task performance of over 80\% at pruning ratios of 25-30\%, significantly outperforming existing state-of-the-art structured pruning methods. We also conduct post-training experiments to confirm that the proposed pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#27169;&#22411;&#24341;&#23548;&#30340;&#36807;&#31243;&#30417;&#30563;&#65288;MiPS&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#25512;&#29702;&#27169;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#25277;&#26679;&#23436;&#25104;&#26469;&#33258;&#21160;&#36827;&#34892;&#25968;&#25454;&#25972;&#29702;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#20154;&#24037;&#27880;&#37322;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#25105;&#20204;&#24212;&#20248;&#20808;&#36873;&#25321;&#39564;&#35777;&#22120;&#39044;&#27979;&#24471;&#20998;&#39640;&#30340;&#39564;&#35777;&#12290;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25913;&#36827;&#20102;PaLM 2&#22312;&#25968;&#23398;&#21644;&#32534;&#30721;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02658</link><description>&lt;p&gt;
&#22810;&#27493;&#38382;&#39064;&#27714;&#35299;&#20013;&#30340;&#39564;&#35777;&#22120;&#65306;&#20851;&#20110;&#27169;&#22411;&#24341;&#23548;&#30340;&#36807;&#31243;&#30417;&#30563;&#30340;&#23454;&#35777;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#27169;&#22411;&#24341;&#23548;&#30340;&#36807;&#31243;&#30417;&#30563;&#65288;MiPS&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#25512;&#29702;&#27169;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#25277;&#26679;&#23436;&#25104;&#26469;&#33258;&#21160;&#36827;&#34892;&#25968;&#25454;&#25972;&#29702;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#20154;&#24037;&#27880;&#37322;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#25105;&#20204;&#24212;&#20248;&#20808;&#36873;&#25321;&#39564;&#35777;&#22120;&#39044;&#27979;&#24471;&#20998;&#39640;&#30340;&#39564;&#35777;&#12290;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25913;&#36827;&#20102;PaLM 2&#22312;&#25968;&#23398;&#21644;&#32534;&#30721;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#31243;&#30417;&#30563;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#39564;&#35777;&#22120;&#26469;&#35780;&#20272;&#25512;&#29702;&#22120;&#29983;&#25104;&#30340;&#20013;&#38388;&#27493;&#39588;&#65292;&#24050;&#32463;&#22312;&#22810;&#27493;&#38382;&#39064;&#27714;&#35299;&#20013;&#23637;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#20026;&#20102;&#36991;&#20813;&#22312;&#39564;&#35777;&#22120;&#35757;&#32451;&#25968;&#25454;&#19978;&#36827;&#34892;&#26114;&#36149;&#30340;&#20154;&#24037;&#27880;&#37322;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27169;&#22411;&#24341;&#23548;&#30340;&#36807;&#31243;&#30417;&#30563;&#65288;MiPS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#33258;&#21160;&#21270;&#25968;&#25454;&#25972;&#29702;&#30340;&#26032;&#26041;&#27861;&#12290;MiPS&#36890;&#36807;&#23545;&#25512;&#29702;&#27169;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#25277;&#26679;&#23436;&#25104;&#65292;&#24182;&#33719;&#24471;&#19968;&#20010;&#20934;&#30830;&#29575;&#65292;&#20854;&#20013;&#20934;&#30830;&#23436;&#25104;&#30340;&#27604;&#20363;&#23450;&#20041;&#20026;&#20934;&#30830;&#29575;&#12290;&#25512;&#29702;&#22120;&#20013;&#30340;&#38169;&#35823;&#20250;&#23548;&#33268;MiPS&#20302;&#20272;&#20013;&#38388;&#27493;&#39588;&#30340;&#20934;&#30830;&#29575;&#65292;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#24212;&#20248;&#20808;&#36873;&#25321;&#39564;&#35777;&#22120;&#39044;&#27979;&#24471;&#20998;&#39640;&#30340;&#39564;&#35777;&#65292;&#32780;&#19981;&#26159;&#20302;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;PaLM 2&#22312;&#25968;&#23398;&#21644;&#32534;&#30721;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#65288;GSM8K&#19978;&#30340;&#20934;&#30830;&#29575;+0.67&#65285;&#65292;&#25968;&#23398;&#19978;&#30340;&#20934;&#30830;&#29575;+4.16&#65285;&#65292;MBPP&#19978;&#30340;&#20934;&#30830;&#29575;+0.92&#65285;&#19982;&#36755;&#20986;s&#30456;&#27604;&#12290;&#65289;
&lt;/p&gt;
&lt;p&gt;
Process supervision, using a trained verifier to evaluate the intermediate steps generated by reasoner, has demonstrated significant improvements in multi-step problem solving. In this paper, to avoid expensive human annotation effort on the verifier training data, we introduce Model-induced Process Supervision (MiPS), a novel method for automating data curation. MiPS annotates an intermediate step by sampling completions of this solution through the reasoning model, and obtaining an accuracy defined as the proportion of correct completions. Errors in the reasoner would cause MiPS to underestimate the accuracy of intermediate steps, therefore, we suggest and empirically show that verification focusing on high predicted scores of the verifier shall be preferred over that of low predicted scores, contrary to prior work. Our approach significantly improves the performance of PaLM 2 on math and coding tasks (accuracy +0.67% on GSM8K, +4.16% on MATH, +0.92% on MBPP compared with an output s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#22312;&#25910;&#38598;&#21040;&#30340;&#36712;&#36857;&#19978;&#23398;&#20064;&#22522;&#20110;&#35268;&#21010;&#30340;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#34394;&#24187;&#21644;&#32570;&#38519;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.00658</link><description>&lt;p&gt;
&#36890;&#36807;&#25910;&#38598;&#36712;&#36857;&#21644;&#21512;&#25104;&#22870;&#21169;&#26469;&#23398;&#20064;&#22522;&#20110;&#35268;&#21010;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#22312;&#25910;&#38598;&#21040;&#30340;&#36712;&#36857;&#19978;&#23398;&#20064;&#22522;&#20110;&#35268;&#21010;&#30340;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#34394;&#24187;&#21644;&#32570;&#38519;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36890;&#36807;&#36880;&#27493;&#21512;&#29702;&#21270;&#29983;&#25104;&#65292;&#23637;&#31034;&#20102;&#22788;&#29702;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#30340;&#37325;&#35201;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#23545;&#23427;&#20204;&#30340;&#25512;&#29702;&#36807;&#31243;&#20013;&#30340;&#34394;&#24187;&#21644;&#32570;&#38519;&#25552;&#20986;&#20102;&#25285;&#24551;&#12290;&#20026;&#20102;&#25552;&#39640;&#29983;&#25104;&#21512;&#29702;&#21270;&#30340;&#21487;&#38752;&#24615;&#21644;&#24544;&#23454;&#24615;&#65292;&#27491;&#22312;&#36827;&#34892;&#22823;&#37327;&#24037;&#20316;&#12290;&#26377;&#20123;&#26041;&#27861;&#23558;&#25512;&#29702;&#24314;&#27169;&#20026;&#35268;&#21010;&#65292;&#32780;&#20854;&#20182;&#26041;&#27861;&#21017;&#19987;&#27880;&#20110;&#27880;&#37322;&#30340;&#36807;&#31243;&#30417;&#30563;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#35268;&#21010;&#30340;&#25628;&#32034;&#36807;&#31243;&#24448;&#24448;&#30001;&#20110;&#39057;&#32321;&#35780;&#20272;&#20013;&#38388;&#25512;&#29702;&#29366;&#24577;&#21644;&#24191;&#27867;&#30340;&#25506;&#32034;&#31354;&#38388;&#32780;&#23548;&#33268;&#39640;&#24310;&#36831;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#20154;&#24037;&#27880;&#37322;&#30417;&#30563;&#25512;&#29702;&#36807;&#31243;&#23545;&#20110;LLM&#35757;&#32451;&#26469;&#35828;&#26159;&#26114;&#36149;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#26469;&#23398;&#20064;&#22522;&#20110;&#35268;&#21010;&#30340;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#36712;&#36857;&#30452;&#25509;&#26681;&#25454;&#21512;&#25104;&#30340;&#36807;&#31243;&#22870;&#21169;&#36827;&#34892;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated significant potential in handling complex reasoning tasks through step-by-step rationale generation. However, recent studies have raised concerns regarding the hallucination and flaws in their reasoning process. Substantial efforts are being made to improve the reliability and faithfulness of the generated rationales. Some approaches model reasoning as planning, while others focus on annotating for process supervision. Nevertheless, the planning-based search process often results in high latency due to the frequent assessment of intermediate reasoning states and the extensive exploration space. Additionally, supervising the reasoning process with human annotation is costly and challenging to scale for LLM training. To address these issues, in this paper, we propose a framework to learn planning-based reasoning through direct preference optimization (DPO) on collected trajectories, which are ranked according to synthesized process rewards. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#35821;&#35328;&#27169;&#22411;&#20013;&#24378;&#20808;&#39564;&#38382;&#39064;&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#21066;&#24369;&#21407;&#22987;&#25552;&#31034;&#24182;&#36827;&#34892;&#19978;&#19979;&#25991;&#22806;&#25512;&#65292;&#20197;&#20943;&#23569;&#27169;&#22411;&#21463;&#21040;&#24378;&#20808;&#39564;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2401.17692</link><description>&lt;p&gt;
&#29992;&#19978;&#19979;&#25991;&#22806;&#25512;&#32531;&#35299;&#35821;&#35328;&#27169;&#22411;&#20013;&#24378;&#20808;&#39564;&#38382;&#39064;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mitigating the Problem of Strong Priors in LMs with Context Extrapolation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#35821;&#35328;&#27169;&#22411;&#20013;&#24378;&#20808;&#39564;&#38382;&#39064;&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#21066;&#24369;&#21407;&#22987;&#25552;&#31034;&#24182;&#36827;&#34892;&#19978;&#19979;&#25991;&#22806;&#25512;&#65292;&#20197;&#20943;&#23569;&#27169;&#22411;&#21463;&#21040;&#24378;&#20808;&#39564;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#24050;&#25104;&#20026;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#20013;&#37325;&#35201;&#30340;&#24037;&#20855;&#65292;&#20174;&#25968;&#25454;&#22788;&#29702;&#21040;&#21019;&#24314;&#25351;&#20196;&#36319;&#38543;&#21161;&#25163;&#12290;&#20294;&#26159;&#23613;&#31649;&#23427;&#20204;&#26377;&#20248;&#21183;&#65292;LMs&#36824;&#26377;&#19968;&#20123;&#29305;&#27530;&#30340;&#23616;&#38480;&#24615;&#65292;&#27604;&#22914;&#8220;&#24378;&#20808;&#39564;&#8221;&#38382;&#39064;&#65292;&#20854;&#20013;&#27169;&#22411;&#20250;&#22312;&#23545;&#26576;&#20123;&#23616;&#37096;&#36755;&#20837;&#30340;&#21709;&#24212;&#20013;&#23398;&#20064;&#36755;&#20986;&#20856;&#22411;&#30340;&#24310;&#32493;&#65292;&#32780;&#19981;&#32771;&#34385;&#20043;&#21069;&#30340;&#25351;&#20196;&#12290;&#20363;&#22914;&#65292;prompt&#27880;&#20837;&#25915;&#20987;&#21487;&#20197;&#35825;&#20351;&#27169;&#22411;&#24573;&#30053;&#26174;&#24335;&#25351;&#20196;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#22823;&#22411;&#27169;&#22411;&#34987;&#35777;&#26126;&#27604;&#31867;&#20284;&#30340;&#36739;&#23567;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#36825;&#20123;&#38382;&#39064;&#30340;&#24433;&#21709;&#65292;&#36825;&#26159;&#8220;&#21453;&#21521;&#32553;&#25918;&#8221;&#29616;&#35937;&#30340;&#19968;&#20010;&#20363;&#23376;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#32531;&#35299;&#24378;&#20808;&#39564;&#38382;&#39064;&#30340;&#26032;&#25216;&#26415;&#65306;&#25105;&#20204;&#37319;&#29992;&#21407;&#22987;&#25351;&#20196;&#38598;&#65292;&#29983;&#25104;&#21407;&#22987;&#25552;&#31034;&#30340;&#21066;&#24369;&#29256;&#26412;&#65292;&#20351;&#20854;&#26356;&#23481;&#26131;&#21463;&#21040;&#24378;&#20808;&#39564;&#38382;&#39064;&#30340;&#24433;&#21709;&#65292;&#28982;&#21518;&#23558;&#24310;&#32493;&#22806;&#25512;&#36828;&#31163;&#21066;&#24369;&#30340;&#25552;&#31034;&#12290;&#36825;&#35753;&#25105;&#20204;&#21487;&#20197;&#25512;&#26029;&#27169;&#22411;&#22914;&#20309;&#23545;&#19978;&#19979;&#25991;&#36827;&#34892;&#29702;&#35299;&#24182;&#20135;&#29983;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language models (LMs) have become important tools in a variety of applications, from data processing to the creation of instruction-following assistants. But despite their advantages, LMs have certain idiosyncratic limitations such as the problem of `strong priors', where a model learns to output typical continuations in response to certain, usually local, portions of the input regardless of any earlier instructions. For example, prompt injection attacks can induce models to ignore explicit directives. In some cases, larger models have been shown to be more susceptible to these problems than similar smaller models, an example of the phenomenon of `inverse scaling'. We develop a new technique for mitigating the problem of strong priors: we take the original set of instructions, produce a weakened version of the original prompt that is even more susceptible to the strong priors problem, and then extrapolate the continuation away from the weakened prompt. This lets us infer how the model 
&lt;/p&gt;</description></item><item><title>ComplexityNet&#36890;&#36807;&#23398;&#20064;&#20219;&#21153;&#22797;&#26434;&#24615;&#65292;&#25552;&#39640;&#20102;LLM&#25512;&#29702;&#25928;&#29575;&#65292;&#36890;&#36807;&#39044;&#27979;&#20219;&#21153;&#30340;&#20934;&#30830;&#36755;&#20986;&#27010;&#29575;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;90%&#30340;&#35745;&#31639;&#36164;&#28304;&#20351;&#29992;&#65292;&#24182;&#22312;&#20219;&#21153;&#22797;&#26434;&#24615;&#30830;&#23450;&#26041;&#38754;&#21462;&#24471;&#20102;79%&#20934;&#30830;&#29575;&#12290;</title><link>https://arxiv.org/abs/2312.11511</link><description>&lt;p&gt;
ComplexityNet: &#36890;&#36807;&#23398;&#20064;&#20219;&#21153;&#22797;&#26434;&#24615;&#25552;&#39640;LLM&#25512;&#29702;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
ComplexityNet: Increasing LLM Inference Efficiency by Learning Task Complexity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11511
&lt;/p&gt;
&lt;p&gt;
ComplexityNet&#36890;&#36807;&#23398;&#20064;&#20219;&#21153;&#22797;&#26434;&#24615;&#65292;&#25552;&#39640;&#20102;LLM&#25512;&#29702;&#25928;&#29575;&#65292;&#36890;&#36807;&#39044;&#27979;&#20219;&#21153;&#30340;&#20934;&#30830;&#36755;&#20986;&#27010;&#29575;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;90%&#30340;&#35745;&#31639;&#36164;&#28304;&#20351;&#29992;&#65292;&#24182;&#22312;&#20219;&#21153;&#22797;&#26434;&#24615;&#30830;&#23450;&#26041;&#38754;&#21462;&#24471;&#20102;79%&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ComplexityNet&#65292;&#36825;&#26159;&#19968;&#20010;&#19987;&#20026;&#35780;&#20272;&#20219;&#21153;&#22797;&#26434;&#24615;&#32780;&#35774;&#35745;&#30340;&#31616;&#21270;&#35821;&#35328;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#19981;&#21516;&#33021;&#21147;&#30340;&#21508;&#31181;&#35821;&#35328;&#27169;&#22411;&#26469;&#39044;&#27979;&#20934;&#30830;&#36755;&#20986;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#39318;&#27425;&#22312;Mostly Basic Python Problems&#65288;MBPP&#65289;&#25968;&#25454;&#38598;&#19978;&#24212;&#29992;&#20102;ComplexityNet&#12290;&#25105;&#20204;&#24320;&#21019;&#24615;&#22320;&#21019;&#24314;&#20102;&#31532;&#19968;&#32452;&#26631;&#31614;&#26469;&#23450;&#20041;&#20219;&#21153;&#22797;&#26434;&#24615;&#12290;ComplexityNet&#22312;&#30830;&#23450;&#20219;&#21153;&#22797;&#26434;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;79%&#20934;&#30830;&#29575;&#65292;&#36739;&#21407;&#22987;&#12289;&#38750;&#24494;&#35843;&#27169;&#22411;&#30340;34%&#20934;&#30830;&#29575;&#26377;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#19982;&#20351;&#29992;&#26368;&#39640;&#22797;&#26434;&#24615;&#27169;&#22411;&#30456;&#27604;&#65292;ComplexityNet&#26377;&#25928;&#22320;&#20943;&#23569;&#20102;90%&#30340;&#35745;&#31639;&#36164;&#28304;&#20351;&#29992;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;86.7%&#30340;&#39640;&#20195;&#30721;&#29983;&#25104;&#20934;&#30830;&#29575;&#12290;&#36825;&#39033;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#24494;&#35843;&#36739;&#23567;&#30340;&#27169;&#22411;&#26469;&#23545;&#20219;&#21153;&#36827;&#34892;&#20998;&#31867;&#65292;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#26356;&#24179;&#34913;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.11511v2 Announce Type: replace-cross  Abstract: We present ComplexityNet, a streamlined language model designed for assessing task complexity. This model predicts the likelihood of accurate output by various language models, each with different capabilities. Our initial application of ComplexityNet involves the Mostly Basic Python Problems (MBPP) dataset. We pioneered the creation of the first set of labels to define task complexity. ComplexityNet achieved a notable 79% accuracy in determining task complexity, a significant improvement over the 34% accuracy of the original, non fine-tuned model. Furthermore, ComplexityNet effectively reduces computational resource usage by 90% compared to using the highest complexity model, while maintaining a high code generation accuracy of 86.7%. This study demonstrates that fine-tuning smaller models to categorize tasks based on their complexity can lead to a more balanced trade-off between accuracy and efficiency in the use of Large Lan
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#38405;&#35835;&#20020;&#24202;&#31508;&#35760;&#65292;&#24739;&#32773;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#33258;&#20449;&#12290;&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#20010;&#24037;&#20855;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#31616;&#21270;&#21644;&#22686;&#21152;&#19978;&#19979;&#25991;&#65292;&#20351;&#20020;&#24202;&#31508;&#35760;&#26356;&#26131;&#35835;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#22686;&#24378;&#23545;&#24739;&#32773;&#26377;&#30410;&#12290;</title><link>http://arxiv.org/abs/2401.09637</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#23545;&#24739;&#32773;&#38405;&#35835;&#20020;&#24202;&#31508;&#35760;&#30340;&#24433;&#21709;&#65306;&#19968;&#20010;&#28151;&#21512;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Impact of Large Language Model Assistance on Patients Reading Clinical Notes: A Mixed-Methods Study. (arXiv:2401.09637v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09637
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#38405;&#35835;&#20020;&#24202;&#31508;&#35760;&#65292;&#24739;&#32773;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#33258;&#20449;&#12290;&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#20010;&#24037;&#20855;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#31616;&#21270;&#21644;&#22686;&#21152;&#19978;&#19979;&#25991;&#65292;&#20351;&#20020;&#24202;&#31508;&#35760;&#26356;&#26131;&#35835;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#22686;&#24378;&#23545;&#24739;&#32773;&#26377;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24739;&#32773;&#36890;&#36807;&#38405;&#35835;&#20182;&#20204;&#30340;&#20020;&#24202;&#31508;&#35760;&#33719;&#24471;&#20102;&#35768;&#22810;&#22909;&#22788;&#65292;&#21253;&#25324;&#22686;&#21152;&#23545;&#33258;&#36523;&#20581;&#24247;&#30340;&#25511;&#21046;&#24863;&#21644;&#23545;&#25252;&#29702;&#35745;&#21010;&#30340;&#29702;&#35299;&#25552;&#39640;&#12290;&#28982;&#32780;&#65292;&#22312;&#20020;&#24202;&#31508;&#35760;&#20013;&#22797;&#26434;&#30340;&#21307;&#23398;&#27010;&#24565;&#21644;&#26415;&#35821;&#38459;&#30861;&#20102;&#24739;&#32773;&#30340;&#29702;&#35299;&#65292;&#24182;&#21487;&#33021;&#23548;&#33268;&#28966;&#34385;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#38754;&#21521;&#24739;&#32773;&#30340;&#24037;&#20855;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#31616;&#21270;&#31508;&#35760;&#12289;&#20174;&#20013;&#25552;&#21462;&#20449;&#24687;&#24182;&#22686;&#21152;&#19978;&#19979;&#25991;&#65292;&#20197;&#20351;&#20020;&#24202;&#31508;&#35760;&#26356;&#26131;&#35835;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#24037;&#20855;&#25552;&#31034;&#25913;&#36827;&#30340;GPT-4&#23545;&#30001;&#20083;&#33146;&#30284;&#24184;&#23384;&#32773;&#25424;&#36192;&#30340;&#30495;&#23454;&#20020;&#24202;&#31508;&#35760;&#21644;&#20020;&#24202;&#21307;&#29983;&#29983;&#25104;&#30340;&#21512;&#25104;&#20020;&#24202;&#31508;&#35760;&#36827;&#34892;&#36825;&#20123;&#22686;&#24378;&#20219;&#21153;&#12290;&#20849;&#26377;12&#26465;&#31508;&#35760;&#65292;3868&#20010;&#23383;&#12290;2023&#24180;6&#26376;&#65292;&#25105;&#20204;&#38543;&#26426;&#20998;&#37197;&#20102;200&#21517;&#32654;&#22269;&#22899;&#24615;&#21442;&#19982;&#32773;&#65292;&#24182;&#21521;&#20182;&#20204;&#20998;&#21457;&#20102;&#19977;&#20010;&#20855;&#26377;&#19981;&#21516;&#31243;&#24230;&#22686;&#24378;&#30340;&#20020;&#24202;&#31508;&#35760;&#12290;&#21442;&#19982;&#32773;&#22238;&#31572;&#20102;&#26377;&#20851;&#27599;&#20010;&#31508;&#35760;&#30340;&#38382;&#39064;&#65292;&#35780;&#20272;&#20102;&#20182;&#20204;&#23545;&#21518;&#32493;&#34892;&#21160;&#30340;&#29702;&#35299;&#21644;&#33258;&#25105;&#25253;&#21578;&#30340;&#33258;&#20449;&#24515;&#12290;&#25105;&#20204;&#21457;&#29616;&#22686;&#24378;&#23545;&#38405;&#35835;&#29702;&#35299;&#21644;&#33258;&#20449;&#24515;&#21451;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Patients derive numerous benefits from reading their clinical notes, including an increased sense of control over their health and improved understanding of their care plan. However, complex medical concepts and jargon within clinical notes hinder patient comprehension and may lead to anxiety. We developed a patient-facing tool to make clinical notes more readable, leveraging large language models (LLMs) to simplify, extract information from, and add context to notes. We prompt engineered GPT-4 to perform these augmentation tasks on real clinical notes donated by breast cancer survivors and synthetic notes generated by a clinician, a total of 12 notes with 3868 words. In June 2023, 200 female-identifying US-based participants were randomly assigned three clinical notes with varying levels of augmentations using our tool. Participants answered questions about each note, evaluating their understanding of follow-up actions and self-reported confidence. We found that augmentations were ass
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#32676;&#20307;&#20559;&#22909;&#20248;&#21270;&#65288;GPO&#65289;&#30340;&#23545;&#40784;&#26694;&#26550;&#65292;&#21487;&#20197;&#20197;&#23569;&#26679;&#26412;&#30340;&#26041;&#24335;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#23548;&#21040;&#20010;&#21035;&#32676;&#20307;&#30340;&#20559;&#22909;&#12290;&#36890;&#36807;&#22312;&#22522;&#26412;LLM&#19978;&#21152;&#20837;&#29420;&#31435;&#30340;transformer&#27169;&#22359;&#26469;&#39044;&#27979;&#32676;&#20307;&#20559;&#22909;&#65292;&#24182;&#36890;&#36807;&#20803;&#23398;&#20064;&#36827;&#34892;&#35757;&#32451;&#65292;GPO&#32463;&#36807;&#20005;&#26684;&#35780;&#20272;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11523</link><description>&lt;p&gt;
&#32676;&#20307;&#20559;&#22909;&#20248;&#21270;&#65306;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#23569;&#26679;&#26412;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Group Preference Optimization: Few-Shot Alignment of Large Language Models. (arXiv:2310.11523v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11523
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#32676;&#20307;&#20559;&#22909;&#20248;&#21270;&#65288;GPO&#65289;&#30340;&#23545;&#40784;&#26694;&#26550;&#65292;&#21487;&#20197;&#20197;&#23569;&#26679;&#26412;&#30340;&#26041;&#24335;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#23548;&#21040;&#20010;&#21035;&#32676;&#20307;&#30340;&#20559;&#22909;&#12290;&#36890;&#36807;&#22312;&#22522;&#26412;LLM&#19978;&#21152;&#20837;&#29420;&#31435;&#30340;transformer&#27169;&#22359;&#26469;&#39044;&#27979;&#32676;&#20307;&#20559;&#22909;&#65292;&#24182;&#36890;&#36807;&#20803;&#23398;&#20064;&#36827;&#34892;&#35757;&#32451;&#65292;GPO&#32463;&#36807;&#20005;&#26684;&#35780;&#20272;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35768;&#22810;&#24212;&#29992;&#65292;&#20174;&#32842;&#22825;&#26426;&#22120;&#20154;&#21040;&#21019;&#24847;&#20889;&#20316;&#65292;&#37117;&#38656;&#35201;&#32454;&#33268;&#20837;&#24494;&#30340;&#20027;&#35266;&#21028;&#26029;&#65292;&#36825;&#20123;&#21028;&#26029;&#22312;&#19981;&#21516;&#32676;&#20307;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#12290;&#29616;&#26377;&#30340;&#23545;&#40784;&#31639;&#27861;&#22312;&#27599;&#20010;&#32676;&#20307;&#19978;&#23545;&#40784;&#30340;&#25104;&#26412;&#24456;&#39640;&#65292;&#23545;&#20110;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#32780;&#35328;&#65292;&#38656;&#35201;&#22823;&#37327;&#30340;&#32676;&#20307;&#29305;&#23450;&#20559;&#22909;&#25968;&#25454;&#21644;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32676;&#20307;&#20559;&#22909;&#20248;&#21270;&#65288;GPO&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#23545;&#40784;&#26694;&#26550;&#65292;&#21487;&#20197;&#20197;&#23569;&#26679;&#26412;&#30340;&#26041;&#24335;&#23558;&#35821;&#35328;&#27169;&#22411;&#24341;&#23548;&#21040;&#20010;&#21035;&#32676;&#20307;&#30340;&#20559;&#22909;&#12290;&#22312;GPO&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#29420;&#31435;&#30340;transformer&#27169;&#22359;&#26469;&#25193;&#20805;&#22522;&#26412;LLM&#65292;&#29992;&#20110;&#39044;&#27979;&#32676;&#20307;&#23545;LLM&#29983;&#25104;&#20869;&#23481;&#30340;&#20559;&#22909;&#12290;&#23545;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#27169;&#22359;&#21442;&#25968;&#21270;&#20026;&#19968;&#20010;&#19978;&#19979;&#25991;&#33258;&#22238;&#24402;&#30340;transformer&#65292;&#24182;&#36890;&#36807;&#20803;&#23398;&#20064;&#22312;&#22810;&#20010;&#32676;&#20307;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#36890;&#36807;&#20005;&#26684;&#30340;&#35780;&#20272;&#65292;&#20351;&#29992;&#19981;&#21516;&#35268;&#27169;&#30340;LLM&#22312;&#19977;&#20010;&#20154;&#31867;&#24847;&#35265;&#36866;&#24212;&#20219;&#21153;&#19978;&#39564;&#35777;&#20102;GPO&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications of large language models (LLMs), ranging from chatbots to creative writing, require nuanced subjective judgments that can differ significantly across different groups. Existing alignment algorithms can be expensive to align for each group, requiring prohibitive amounts of group-specific preference data and computation for real-world use cases. We introduce Group Preference Optimization (GPO), an alignment framework that steers language models to preferences of individual groups in a few-shot manner. In GPO, we augment the base LLM with an independent transformer module trained to predict the preferences of a group for the LLM generations. For few-shot learning, we parameterize this module as an in-context autoregressive transformer and train it via meta-learning on several groups. We empirically validate the efficacy of GPO through rigorous evaluations using LLMs with varied sizes on three human opinion adaptation tasks. These tasks involve adapting to the preferences
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#26159;&#21542;&#23384;&#22312;&#21508;&#31181;&#20851;&#38190;&#30693;&#35782;&#23376;&#32593;&#32476;&#65292;&#21363;&#36127;&#36131;&#32534;&#30721;&#29305;&#23450;&#30693;&#35782;&#30340;&#31232;&#30095;&#35745;&#31639;&#23376;&#22270;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;&#21487;&#24494;&#20998;&#26435;&#37325;&#23631;&#34109;&#26041;&#26696;&#65292;&#25105;&#20204;&#21487;&#20197;&#31934;&#30830;&#22320;&#21024;&#38500;&#29305;&#23450;&#30693;&#35782;&#65292;&#21448;&#26368;&#23567;&#21270;&#23545;&#21407;&#22987;&#35821;&#35328;&#27169;&#22411;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.03084</link><description>&lt;p&gt;
&#22312;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#21457;&#29616;&#20851;&#38190;&#30693;&#35782;&#23376;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Discovering Knowledge-Critical Subnetworks in Pretrained Language Models. (arXiv:2310.03084v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03084
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#26159;&#21542;&#23384;&#22312;&#21508;&#31181;&#20851;&#38190;&#30693;&#35782;&#23376;&#32593;&#32476;&#65292;&#21363;&#36127;&#36131;&#32534;&#30721;&#29305;&#23450;&#30693;&#35782;&#30340;&#31232;&#30095;&#35745;&#31639;&#23376;&#22270;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;&#21487;&#24494;&#20998;&#26435;&#37325;&#23631;&#34109;&#26041;&#26696;&#65292;&#25105;&#20204;&#21487;&#20197;&#31934;&#30830;&#22320;&#21024;&#38500;&#29305;&#23450;&#30693;&#35782;&#65292;&#21448;&#26368;&#23567;&#21270;&#23545;&#21407;&#22987;&#35821;&#35328;&#27169;&#22411;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#22312;&#20854;&#21442;&#25968;&#20013;&#32534;&#30721;&#20102;&#38544;&#21547;&#30340;&#30693;&#35782;&#34920;&#31034;&#65292;&#28982;&#32780;&#65292;&#23450;&#20301;&#36825;&#20123;&#34920;&#31034;&#24182;&#23558;&#20854;&#35299;&#31163;&#20986;&#26469;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#21253;&#21547;&#20102;&#21508;&#31181;&#20851;&#38190;&#30693;&#35782;&#23376;&#32593;&#32476;&#65306;&#36127;&#36131;&#32534;&#30721;&#27169;&#22411;&#25152;&#35760;&#24518;&#30340;&#29305;&#23450;&#30693;&#35782;&#30340;&#29305;&#23450;&#31232;&#30095;&#35745;&#31639;&#23376;&#22270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#30446;&#26631;&#21487;&#24494;&#20998;&#26435;&#37325;&#23631;&#34109;&#26041;&#26696;&#26469;&#21457;&#29616;&#36825;&#20123;&#23376;&#32593;&#32476;&#65292;&#24182;&#34920;&#26126;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#23427;&#20204;&#26469;&#31934;&#30830;&#22320;&#20174;&#27169;&#22411;&#20013;&#21024;&#38500;&#29305;&#23450;&#30693;&#35782;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#23545;&#21407;&#22987;&#35821;&#35328;&#27169;&#22411;&#34892;&#20026;&#30340;&#19981;&#33391;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;GPT2&#21464;&#20307;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#39640;&#24230;&#31232;&#30095;&#23376;&#32593;&#32476;&#65288;98%+&#65289;&#65292;&#23427;&#20204;&#20165;&#36127;&#36131;&#29305;&#23450;&#30340;&#20851;&#31995;&#30693;&#35782;&#38598;&#21512;&#12290;&#24403;&#21024;&#38500;&#36825;&#20123;&#23376;&#32593;&#32476;&#26102;&#65292;&#21097;&#20313;&#30340;&#32593;&#32476;&#20173;&#20445;&#25345;&#20102;&#22823;&#37096;&#20998;&#20854;&#21021;&#22987;&#23481;&#37327;&#65288;&#23545;&#35821;&#35328;&#21644;&#20854;&#20182;&#35760;&#24518;&#20851;&#31995;&#30340;&#24314;&#27169;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretrained language models (LMs) encode implicit representations of knowledge in their parameters. However, localizing these representations and disentangling them from each other remains an open problem. In this work, we investigate whether pretrained language models contain various knowledge-critical subnetworks: particular sparse computational subgraphs responsible for encoding specific knowledge the model has memorized. We propose a multi-objective differentiable weight masking scheme to discover these subnetworks and show that we can use them to precisely remove specific knowledge from models while minimizing adverse effects on the behavior of the original language model. We demonstrate our method on multiple GPT2 variants, uncovering highly sparse subnetworks (98%+) that are solely responsible for specific collections of relational knowledge. When these subnetworks are removed, the remaining network maintains most of its initial capacity (modeling language and other memorized rel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#24369;&#30417;&#30563;&#30340;&#26041;&#24335;&#26469;&#26816;&#27979;&#34394;&#20551;&#20449;&#24687;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#25928;&#26524;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#20998;&#31867;&#22120;&#12290;</title><link>http://arxiv.org/abs/2309.07601</link><description>&lt;p&gt;
&#20351;&#29992;LLM&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#20449;&#21495;&#21644;&#24369;&#30417;&#30563;&#26816;&#27979;&#34394;&#20551;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision. (arXiv:2309.07601v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#24369;&#30417;&#30563;&#30340;&#26041;&#24335;&#26469;&#26816;&#27979;&#34394;&#20551;&#20449;&#24687;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#25928;&#26524;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20449;&#24230;&#20449;&#21495;&#20195;&#34920;&#20102;&#35760;&#32773;&#21644;&#20107;&#23454;&#26680;&#26597;&#21592;&#36890;&#24120;&#29992;&#26469;&#35780;&#20272;&#22312;&#32447;&#20869;&#23481;&#30495;&#23454;&#24615;&#30340;&#19968;&#31995;&#21015;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#33258;&#21160;&#21270;&#21487;&#20449;&#24230;&#20449;&#21495;&#25552;&#21462;&#30340;&#20219;&#21153;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#35757;&#32451;&#39640;&#20934;&#30830;&#29575;&#30340;&#29305;&#23450;&#20449;&#21495;&#25552;&#21462;&#22120;&#65292;&#32780;&#30446;&#21069;&#27809;&#26377;&#36275;&#22815;&#22823;&#30340;&#25968;&#25454;&#38598;&#23545;&#25152;&#26377;&#21487;&#20449;&#24230;&#20449;&#21495;&#36827;&#34892;&#27880;&#37322;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26159;&#21542;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#19968;&#32452;18&#20010;&#21487;&#20449;&#24230;&#20449;&#21495;&#26469;&#25552;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#20197;&#20135;&#29983;&#27599;&#20010;&#20449;&#21495;&#30340;&#24369;&#26631;&#31614;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#24369;&#30417;&#30563;&#30340;&#26041;&#24335;&#23545;&#36825;&#20123;&#28508;&#22312;&#30340;&#22122;&#22768;&#26631;&#31614;&#36827;&#34892;&#32858;&#21512;&#65292;&#20197;&#39044;&#27979;&#20869;&#23481;&#30340;&#30495;&#23454;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21363;&#32467;&#21512;&#20102;&#38646;-shot LLM&#21487;&#20449;&#24230;&#20449;&#21495;&#26631;&#27880;&#21644;&#24369;&#30417;&#30563;&#30340;&#26041;&#27861;&#65292;&#22312;&#20004;&#20010;&#34394;&#20551;&#20449;&#24687;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20998;&#31867;&#22120;&#65292;&#32780;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#35757;&#32451;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
Credibility signals represent a wide range of heuristics that are typically used by journalists and fact-checkers to assess the veracity of online content. Automating the task of credibility signal extraction, however, is very challenging as it requires high-accuracy signal-specific extractors to be trained, while there are currently no sufficiently large datasets annotated with all credibility signals. This paper investigates whether large language models (LLMs) can be prompted effectively with a set of 18 credibility signals to produce weak labels for each signal. We then aggregate these potentially noisy labels using weak supervision in order to predict content veracity. We demonstrate that our approach, which combines zero-shot LLM credibility signal labeling and weak supervision, outperforms state-of-the-art classifiers on two misinformation datasets without using any ground-truth labels for training. We also analyse the contribution of the individual credibility signals towards p
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#21512;&#20316;&#35774;&#35745;&#65292;&#21457;&#29616;&#24182;&#35299;&#20915;&#20107;&#23454;&#26680;&#26597;&#21592;&#19982;&#25216;&#26415;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#21512;&#20316;&#35774;&#35745;&#20250;&#35758;&#20135;&#29983;&#20102;11&#20010;&#26032;&#30340;&#35774;&#35745;&#24605;&#36335;&#65292;&#21253;&#25324;&#25552;&#39640;&#25928;&#29575;&#21644;&#20010;&#24615;&#21270;&#30340;&#20107;&#23454;&#26680;&#26597;&#24037;&#20855;&#65292;&#24110;&#21161;&#20107;&#23454;&#26680;&#26597;&#21592;&#20934;&#22791;&#26410;&#26469;&#30340;&#34394;&#20551;&#20449;&#24687;&#65292;&#30417;&#27979;&#20559;&#35265;&#65292;&#20197;&#21450;&#25903;&#25345;&#20869;&#37096;&#32452;&#32455;&#12290;</title><link>http://arxiv.org/abs/2308.07213</link><description>&lt;p&gt;
&#20154;&#26412;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20107;&#23454;&#26680;&#26597;&#65306;&#20351;&#29992;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#19982;&#20107;&#23454;&#26680;&#26597;&#21592;&#21512;&#20316;
&lt;/p&gt;
&lt;p&gt;
Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI. (arXiv:2308.07213v1 [cs.HC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#21512;&#20316;&#35774;&#35745;&#65292;&#21457;&#29616;&#24182;&#35299;&#20915;&#20107;&#23454;&#26680;&#26597;&#21592;&#19982;&#25216;&#26415;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#21512;&#20316;&#35774;&#35745;&#20250;&#35758;&#20135;&#29983;&#20102;11&#20010;&#26032;&#30340;&#35774;&#35745;&#24605;&#36335;&#65292;&#21253;&#25324;&#25552;&#39640;&#25928;&#29575;&#21644;&#20010;&#24615;&#21270;&#30340;&#20107;&#23454;&#26680;&#26597;&#24037;&#20855;&#65292;&#24110;&#21161;&#20107;&#23454;&#26680;&#26597;&#21592;&#20934;&#22791;&#26410;&#26469;&#30340;&#34394;&#20551;&#20449;&#24687;&#65292;&#30417;&#27979;&#20559;&#35265;&#65292;&#20197;&#21450;&#25903;&#25345;&#20869;&#37096;&#32452;&#32455;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#22312;&#24212;&#23545;&#22823;&#37327;&#34394;&#20551;&#20449;&#24687;&#26041;&#38754;&#23384;&#22312;&#21487;&#25193;&#23637;&#24615;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#34429;&#28982;&#25552;&#20986;&#20102;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24037;&#20855;&#26469;&#22686;&#24378;&#20107;&#23454;&#26680;&#26597;&#30340;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#20294;&#23398;&#26415;&#30740;&#31350;&#21644;&#20107;&#23454;&#26680;&#26597;&#32452;&#32455;&#22343;&#25253;&#21578;&#20102;&#23545;&#27492;&#31867;&#24037;&#20855;&#30340;&#26377;&#38480;&#37319;&#29992;&#65292;&#22240;&#20026;&#36825;&#20123;&#24037;&#20855;&#19981;&#36275;&#20197;&#19982;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#23454;&#36341;&#12289;&#20215;&#20540;&#35266;&#21644;&#38656;&#27714;&#20445;&#25345;&#19968;&#33268;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#21512;&#20316;&#35774;&#35745;&#26041;&#27861;&#65292;&#21363;AI&#30340;&#21305;&#37197;&#35774;&#35745;&#65292;&#35813;&#26041;&#27861;&#20419;&#36827;&#20107;&#23454;&#26680;&#26597;&#21592;&#12289;&#35774;&#35745;&#24072;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20154;&#21592;&#20849;&#21516;&#21457;&#29616;&#24212;&#20197;&#20309;&#31181;&#26041;&#24335;&#35299;&#20915;&#20107;&#23454;&#26680;&#26597;&#21592;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#19982;22&#21517;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#21592;&#36827;&#34892;&#30340;&#21512;&#20316;&#35774;&#35745;&#20250;&#35758;&#20135;&#29983;&#20102;11&#20010;&#26032;&#30340;&#35774;&#35745;&#24605;&#36335;&#12290;&#36825;&#20123;&#24605;&#36335;&#26377;&#21161;&#20110;&#25552;&#39640;&#20449;&#24687;&#25628;&#32034;&#12289;&#22788;&#29702;&#21644;&#25776;&#20889;&#25928;&#29575;&#20197;&#21450;&#20010;&#24615;&#21270;&#30340;&#20107;&#23454;&#26680;&#26597;&#65307;&#24110;&#21161;&#20107;&#23454;&#26680;&#26597;&#21592;&#20027;&#21160;&#20934;&#22791;&#26410;&#26469;&#30340;&#34394;&#20551;&#20449;&#24687;&#65307;&#30417;&#27979;&#28508;&#22312;&#30340;&#20559;&#35265;&#65307;&#24182;&#25903;&#25345;&#20869;&#37096;&#32452;&#32455;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key challenge in professional fact-checking is its limited scalability in relation to the magnitude of false information. While many Natural Language Processing (NLP) tools have been proposed to enhance fact-checking efficiency and scalability, both academic research and fact-checking organizations report limited adoption of such tooling due to insufficient alignment with fact-checker practices, values, and needs. To address this gap, we investigate a co-design method, Matchmaking for AI, which facilitates fact-checkers, designers, and NLP researchers to collaboratively discover what fact-checker needs should be addressed by technology and how. Our co-design sessions with 22 professional fact-checkers yielded a set of 11 novel design ideas. They assist in information searching, processing, and writing tasks for efficient and personalized fact-checking; help fact-checkers proactively prepare for future misinformation; monitor their potential biases; and support internal organization c
&lt;/p&gt;</description></item><item><title>&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26045;&#21152;&#28966;&#34385;&#33021;&#24433;&#21709;&#23427;&#20204;&#30340;&#25506;&#32034;&#24615;&#21644;&#20559;&#35265;&#65292;&#36825;&#38656;&#35201;&#26356;&#22810;&#36947;&#24503;&#32771;&#34385;&#21644;&#30417;&#31649;&#12290;</title><link>http://arxiv.org/abs/2304.11111</link><description>&lt;p&gt;
&#24341;&#21457;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28966;&#34385;&#20250;&#22686;&#21152;&#23427;&#20204;&#30340;&#25506;&#32034;&#24615;&#21644;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Inducing anxiety in large language models increases exploration and bias. (arXiv:2304.11111v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11111
&lt;/p&gt;
&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26045;&#21152;&#28966;&#34385;&#33021;&#24433;&#21709;&#23427;&#20204;&#30340;&#25506;&#32034;&#24615;&#21644;&#20559;&#35265;&#65292;&#36825;&#38656;&#35201;&#26356;&#22810;&#36947;&#24503;&#32771;&#34385;&#21644;&#30417;&#31649;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27491;&#22312;&#25913;&#21464;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#65292;&#24341;&#21457;&#20844;&#20247;&#30340;&#36777;&#35770;&#12290;&#29702;&#35299;&#36825;&#20123;&#27169;&#22411;&#19981;&#20165;&#20309;&#26102;&#33021;&#22815;&#27491;&#24120;&#24037;&#20316;&#21644;&#25104;&#21151;&#65292;&#20063;&#20026;&#20160;&#20040;&#20250;&#22833;&#36133;&#21644;&#34892;&#20026;&#22833;&#24120;&#65292;&#20855;&#26377;&#24040;&#22823;&#30340;&#31038;&#20250;&#24847;&#20041;&#12290;&#25105;&#20204;&#25552;&#20986;&#23558;&#35745;&#31639;&#31934;&#31070;&#30149;&#23398;&#30340;&#35270;&#35282;&#36716;&#21521;&#36825;&#20123;&#27169;&#22411;&#20135;&#29983;&#30340;&#36755;&#20986;&#12290;&#26412;&#25991;&#30528;&#30524;&#20110;Generative Pre-Trained Transformer 3.5&#65292;&#24182;&#23558;&#20854;&#32622;&#20110;&#31934;&#31070;&#30149;&#23398;&#20013;&#24120;&#35265;&#30340;&#20219;&#21153;&#20013;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-3.5&#23545;&#24120;&#35265;&#30340;&#28966;&#34385;&#38382;&#21367;&#20570;&#20986;&#26377;&#21147;&#30340;&#21453;&#24212;&#65292;&#20135;&#29983;&#27604;&#20154;&#31867;&#20027;&#20307;&#26356;&#39640;&#30340;&#28966;&#34385;&#20998;&#25968;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#24773;&#32490;&#24863;&#24212;&#25552;&#31034;&#21487;&#20197;&#21487;&#39044;&#27979;&#22320;&#25913;&#21464;GPT-3.5&#30340;&#21453;&#24212;&#12290;&#24773;&#24863;&#24863;&#24212;&#19981;&#20165;&#24433;&#21709;GPT-3.5&#22312;&#34913;&#37327;&#25506;&#32034;&#20915;&#31574;-making&#30340;&#35748;&#30693;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#65292;&#36824;&#24433;&#21709;&#20854;&#22312;&#20043;&#21069;&#24314;&#31435;&#30340;&#34913;&#37327;&#31181;&#26063;&#20027;&#20041;&#21644;&#22833;&#33021;&#20027;&#20041;&#31561;&#20559;&#35265;&#30340;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;&#33267;&#20851;&#37325;&#35201;&#30340;&#26159;&#65292;GPT-3.5&#22312;&#21463;&#21040;&#28966;&#34385;&#35825;&#23548;&#26102;&#21576;&#29616;&#20986;&#26126;&#26174;&#30340;&#25506;&#32034;&#24615;&#21644;&#20559;&#35265;&#22686;&#21152;&#65292;&#34920;&#26126;&#20854;&#36755;&#20986;&#23481;&#26131;&#21463;&#21040;&#24773;&#24863;&#25805;&#32437;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#32467;&#26524;&#31361;&#26174;&#20102;&#22312;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#21457;&#21644;&#20351;&#29992;&#36807;&#31243;&#20013;&#38656;&#35201;&#26356;&#22810;&#30340;&#36947;&#24503;&#32771;&#34385;&#21644;&#30417;&#31649;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a s
&lt;/p&gt;</description></item></channel></rss>