<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20195;&#29702;&#26500;&#25104;&#30340;&#20195;&#29702;&#26694;&#26550;TrustAgent&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#39044;&#20808;&#35268;&#21010;&#12289;&#35268;&#21010;&#36807;&#31243;&#20013;&#21644;&#35745;&#21010;&#21518;&#26816;&#26597;&#19977;&#31181;&#31574;&#30053;&#26469;&#25552;&#39640;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#35782;&#21035;&#21644;&#39044;&#38450;&#28508;&#22312;&#21361;&#38505;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#23433;&#20840;&#24615;&#19982;&#20351;&#29992;&#32773;&#28385;&#24847;&#24230;&#20197;&#21450;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#19982;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01586</link><description>&lt;p&gt;
TrustAgent: &#36890;&#36807;&#20195;&#29702;&#26500;&#25104;&#23454;&#29616;&#23433;&#20840;&#21487;&#20449;&#36182;&#30340;LLM&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20195;&#29702;&#26500;&#25104;&#30340;&#20195;&#29702;&#26694;&#26550;TrustAgent&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#39044;&#20808;&#35268;&#21010;&#12289;&#35268;&#21010;&#36807;&#31243;&#20013;&#21644;&#35745;&#21010;&#21518;&#26816;&#26597;&#19977;&#31181;&#31574;&#30053;&#26469;&#25552;&#39640;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#35782;&#21035;&#21644;&#39044;&#38450;&#28508;&#22312;&#21361;&#38505;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#23433;&#20840;&#24615;&#19982;&#20351;&#29992;&#32773;&#28385;&#24847;&#24230;&#20197;&#21450;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#19982;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#20854;&#21487;&#20449;&#24230;&#20173;&#26410;&#24471;&#21040;&#28145;&#20837;&#25506;&#32034;&#12290;&#30001;&#20110;&#20195;&#29702;&#21487;&#20197;&#30452;&#25509;&#19982;&#29289;&#29702;&#29615;&#22659;&#20132;&#20114;&#65292;&#20854;&#21487;&#38752;&#24615;&#21644;&#23433;&#20840;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20195;&#29702;&#26500;&#25104;&#30340;&#20195;&#29702;&#26694;&#26550;TrustAgent&#65292;&#23545;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#32500;&#24230;&#36827;&#34892;&#20102;&#21021;&#27493;&#30740;&#31350;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#19977;&#31181;&#31574;&#30053;&#65306;&#39044;&#20808;&#35268;&#21010;&#31574;&#30053;&#65292;&#22312;&#29983;&#25104;&#35745;&#21010;&#20043;&#21069;&#21521;&#27169;&#22411;&#27880;&#20837;&#23433;&#20840;&#30693;&#35782;&#65307;&#35268;&#21010;&#36807;&#31243;&#20013;&#31574;&#30053;&#65292;&#22312;&#29983;&#25104;&#35745;&#21010;&#26102;&#22686;&#24378;&#23433;&#20840;&#24615;&#65307;&#35745;&#21010;&#21518;&#26816;&#26597;&#31574;&#30053;&#65292;&#36890;&#36807;&#35745;&#21010;&#21518;&#26816;&#26597;&#30830;&#20445;&#23433;&#20840;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#20998;&#26512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#22914;&#20309;&#36890;&#36807;&#35782;&#21035;&#21644;&#39044;&#38450;&#28508;&#22312;&#21361;&#38505;&#26377;&#25928;&#25552;&#39640;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#23433;&#20840;&#24615;&#19982;&#20351;&#29992;&#32773;&#28385;&#24847;&#24230;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#20197;&#21450;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#20854;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of LLM-based agents has garnered considerable attention, yet their trustworthiness remains an under-explored area. As agents can directly interact with the physical environment, their reliability and safety is critical. This paper presents an Agent-Constitution-based agent framework, TrustAgent, an initial investigation into improving the safety dimension of trustworthiness in LLM-based agents. This framework consists of threefold strategies: pre-planning strategy which injects safety knowledge to the model prior to plan generation, in-planning strategy which bolsters safety during plan generation, and post-planning strategy which ensures safety by post-planning inspection. Through experimental analysis, we demonstrate how these approaches can effectively elevate an LLM agent's safety by identifying and preventing potential dangers. Furthermore, we explore the intricate relationships between safety and helpfulness, and between the model's reasoning ability and its efficac
&lt;/p&gt;</description></item><item><title>&#25512;&#27979;&#35299;&#30721;&#26159;&#19968;&#31181;&#29992;&#20110;&#21152;&#36895;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#26029;&#30340;&#25216;&#26415;&#65292;&#20294;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36873;&#25321;&#30340;&#33609;&#31295;&#27169;&#22411;&#29983;&#25104;&#30340;&#20196;&#29260;&#34987;&#30446;&#26631;&#27169;&#22411;&#25509;&#21463;&#30340;&#27010;&#29575;&#36234;&#39640;&#65292;&#21534;&#21520;&#37327;&#36234;&#20302;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#20998;&#26512;&#20102;&#21508;&#31181;&#22240;&#32032;&#23545;&#25512;&#27979;&#35299;&#30721;&#25928;&#26524;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#26512;&#27169;&#22411;&#26469;&#25552;&#39640;&#25928;&#29575;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01528</link><description>&lt;p&gt;
&#35299;&#30721;&#25512;&#27979;&#35299;&#30721;
&lt;/p&gt;
&lt;p&gt;
Decoding Speculative Decoding
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01528
&lt;/p&gt;
&lt;p&gt;
&#25512;&#27979;&#35299;&#30721;&#26159;&#19968;&#31181;&#29992;&#20110;&#21152;&#36895;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#26029;&#30340;&#25216;&#26415;&#65292;&#20294;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36873;&#25321;&#30340;&#33609;&#31295;&#27169;&#22411;&#29983;&#25104;&#30340;&#20196;&#29260;&#34987;&#30446;&#26631;&#27169;&#22411;&#25509;&#21463;&#30340;&#27010;&#29575;&#36234;&#39640;&#65292;&#21534;&#21520;&#37327;&#36234;&#20302;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#20998;&#26512;&#20102;&#21508;&#31181;&#22240;&#32032;&#23545;&#25512;&#27979;&#35299;&#30721;&#25928;&#26524;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#26512;&#27169;&#22411;&#26469;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#27979;&#35299;&#30721;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#21152;&#36895;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#25512;&#26029;&#65292;&#32780;&#19981;&#20462;&#25913;&#20854;&#32467;&#26524;&#12290;&#22312;&#23545;LLM&#36827;&#34892;&#25512;&#26029;&#26102;&#65292;&#25512;&#27979;&#35299;&#30721;&#20351;&#29992;&#36739;&#23567;&#30340;&#33609;&#31295;&#27169;&#22411;&#29983;&#25104;&#25512;&#27979;&#20196;&#29260;&#65292;&#28982;&#21518;&#20351;&#29992;&#30446;&#26631;LLM&#39564;&#35777;&#36825;&#20123;&#33609;&#31295;&#20196;&#29260;&#12290;&#25512;&#27979;&#35299;&#30721;&#25552;&#20379;&#30340;&#21152;&#36895;&#21462;&#20915;&#20110;&#33609;&#31295;&#27169;&#22411;&#30340;&#36873;&#25321;&#12290;&#26222;&#36941;&#24314;&#35758;&#36873;&#25321;&#19968;&#20010;&#33609;&#31295;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#29983;&#25104;&#30340;&#20196;&#29260;&#34987;LLM&#25509;&#21463;&#30340;&#27010;&#29575;&#24456;&#39640;&#65292;&#20197;&#23454;&#29616;&#26368;&#39640;&#21534;&#21520;&#37327;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#19982;&#20043;&#30456;&#21453;&#65292;&#38543;&#30528;&#29983;&#25104;&#30340;&#20196;&#29260;&#34987;&#30446;&#26631;&#27169;&#22411;&#25509;&#21463;&#30340;&#27010;&#29575;&#22686;&#21152;&#65292;&#21534;&#21520;&#37327;&#20943;&#23569;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#23545;&#24433;&#21709;&#25512;&#27979;&#35299;&#30721;&#30340;&#19981;&#21516;&#22240;&#32032;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#30740;&#31350;&#20102;&#36825;&#20123;&#22240;&#32032;&#22914;&#20309;&#30456;&#20114;&#20316;&#29992;&#21644;&#24433;&#21709;&#21152;&#36895;&#25928;&#26524;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#20998;&#26512;&#27169;&#22411;&#65292;&#21487;&#20197;&#20351;&#29992;&#35813;&#27169;&#22411;&#26469;&#36827;&#34892;&#20915;&#31574;&#65292;&#25552;&#39640;&#25512;&#27979;&#35299;&#30721;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Speculative Decoding is a widely used technique to speed up inference for Large Language Models (LLMs) without modifying its outcome. When performing inference on an LLM, speculative decoding uses a smaller draft model which generates speculative tokens and then uses the target LLM to verify those draft tokens. The speedup provided by speculative decoding heavily depends on the choice of the draft model. It has been widely suggested to select a draft model that provides a high probability of the generated token being accepted by the LLM to achieve the highest throughput. However, our experiments indicate the contrary with throughput diminishing as the probability of generated tokens to be accepted by the target model increases. To understand this phenomenon, we perform extensive experiments to characterize the different factors that affect speculative decoding and how those factors interact and affect the speedups. Based on our experiments we describe an analytical model which can be u
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GRIFFIN&#30340;&#35757;&#32451;-free MoE&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;LLM&#27169;&#22411;&#20013;&#36873;&#25321;&#21807;&#19968;&#30340;FF&#19987;&#23478;&#20197;&#23454;&#29616;&#39640;&#25928;&#29983;&#25104;&#12290;</title><link>https://arxiv.org/abs/2404.01365</link><description>&lt;p&gt;
&#22522;&#20110;&#25552;&#31034;&#30340;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;LLM
&lt;/p&gt;
&lt;p&gt;
Prompt-prompted Mixture of Experts for Efficient LLM Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01365
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GRIFFIN&#30340;&#35757;&#32451;-free MoE&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;LLM&#27169;&#22411;&#20013;&#36873;&#25321;&#21807;&#19968;&#30340;FF&#19987;&#23478;&#20197;&#23454;&#29616;&#39640;&#25928;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22522;&#20110;transformer&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21457;&#23637;&#65292;&#30001;&#20110;&#20854;&#20986;&#33394;&#30340;&#23454;&#29992;&#24615;&#65292;&#23427;&#20204;&#24050;&#34987;&#24212;&#29992;&#20110;&#35768;&#22810;&#39046;&#22495;&#65292;&#20294;&#22312;&#37096;&#32626;&#26102;&#23384;&#22312;&#30456;&#24403;&#22823;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#19968;&#20123;&#26041;&#27861;&#65292;&#22914;&#20462;&#21098;&#25110;&#26500;&#24314;&#28151;&#21512;&#19987;&#23478;&#65288;MoE&#65289;&#65292;&#26088;&#22312;&#21033;&#29992;transformer&#21069;&#39304;&#65288;FF&#65289;&#22359;&#20013;&#30340;&#31232;&#30095;&#24615;&#65292;&#20197;&#25552;&#39640;&#36895;&#24230;&#24182;&#38477;&#20302;&#20869;&#23384;&#38656;&#27714;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#25216;&#26415;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#38750;&#24120;&#26114;&#36149;&#21644;&#19981;&#28789;&#27963;&#65292;&#22240;&#20026;&#23427;&#20204;&#36890;&#24120;&#38656;&#35201;&#35757;&#32451;&#25110;&#20165;&#38480;&#20110;&#29305;&#23450;&#31867;&#22411;&#30340;&#26550;&#26500;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;GRIFFIN&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#38656;&#35757;&#32451;&#30340;MoE&#65292;&#23427;&#22312;&#24207;&#21015;&#32423;&#21035;&#20026;&#19981;&#21516;&#38750;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#22823;&#37327;LLMs&#36873;&#25321;&#29420;&#29305;&#30340;FF&#19987;&#23478;&#20197;&#23454;&#29616;&#39640;&#25928;&#29983;&#25104;&#12290;&#36825;&#26159;&#21487;&#33021;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#20851;&#38190;&#35266;&#23519;&#21040;&#65292;&#35768;&#22810;&#32463;&#36807;&#35757;&#32451;&#30340;LLMs&#22312;&#24207;&#21015;&#20013;&#33258;&#28982;&#20135;&#29983;&#39640;&#24230;&#32467;&#26500;&#21270;&#30340;FF&#28608;&#27963;&#27169;&#24335;&#65292;&#36825;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01365v1 Announce Type: cross  Abstract: With the development of transformer-based large language models (LLMs), they have been applied to many fields due to their remarkable utility, but this comes at a considerable computational cost at deployment. Fortunately, some methods such as pruning or constructing a mixture of experts (MoE) aim at exploiting sparsity in transformer feedforward (FF) blocks to gain boosts in speed and reduction in memory requirements. However, these techniques can be very costly and inflexible in practice, as they often require training or are restricted to specific types of architectures. To address this, we introduce GRIFFIN, a novel training-free MoE that selects unique FF experts at the sequence level for efficient generation across a plethora of LLMs with different non-ReLU activation functions. This is possible due to a critical observation that many trained LLMs naturally produce highly structured FF activation patterns within a sequence, which
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;LITE&#27169;&#22411;&#65292;&#21487;&#20197;&#23558;&#19981;&#21516;&#30340;&#29615;&#22659;&#21464;&#37327;&#36716;&#25442;&#25104;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#21644;&#25240;&#32447;&#22270;&#20687;&#65292;&#24182;&#21033;&#29992;&#32479;&#19968;&#32534;&#30721;&#22120;&#26469;&#25429;&#25417;&#31354;&#38388;-&#26102;&#38388;&#20851;&#31995;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#39044;&#27979;&#29615;&#22659;&#21464;&#37327;&#12290;</title><link>https://arxiv.org/abs/2404.01165</link><description>&lt;p&gt;
&#29992;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#29615;&#22659;&#29983;&#24577;&#31995;&#32479;&#36827;&#34892;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
LITE: Modeling Environmental Ecosystems with Multimodal Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01165
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;LITE&#27169;&#22411;&#65292;&#21487;&#20197;&#23558;&#19981;&#21516;&#30340;&#29615;&#22659;&#21464;&#37327;&#36716;&#25442;&#25104;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#21644;&#25240;&#32447;&#22270;&#20687;&#65292;&#24182;&#21033;&#29992;&#32479;&#19968;&#32534;&#30721;&#22120;&#26469;&#25429;&#25417;&#31354;&#38388;-&#26102;&#38388;&#20851;&#31995;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#39044;&#27979;&#29615;&#22659;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#29615;&#22659;&#29983;&#24577;&#31995;&#32479;&#36827;&#34892;&#24314;&#27169;&#22312;&#21487;&#25345;&#32493;&#31649;&#29702;&#22320;&#29699;&#30340;&#36807;&#31243;&#20013;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#12290;&#31934;&#30830;&#39044;&#27979;&#31354;&#38388;&#21644;&#26102;&#38388;&#19978;&#30340;&#20851;&#38190;&#29615;&#22659;&#21464;&#37327;&#21487;&#20197;&#24110;&#21161;&#21046;&#23450;&#26126;&#26234;&#30340;&#25919;&#31574;&#21644;&#20915;&#31574;&#65292;&#20174;&#32780;&#25913;&#21892;&#20154;&#20204;&#30340;&#29983;&#27963;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#22312;&#24314;&#27169;&#31354;&#38388;-&#26102;&#38388;&#20851;&#31995;&#20197;&#39044;&#27979;&#29615;&#22659;&#21464;&#37327;&#26041;&#38754;&#26174;&#31034;&#20986;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#22312;&#22788;&#29702;&#19981;&#23436;&#25972;&#29305;&#24449;&#21644;&#20998;&#24067;&#21464;&#21270;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#29615;&#22659;&#25968;&#25454;&#20013;&#24120;&#35265;&#36825;&#20123;&#38382;&#39064;&#26159;&#30001;&#20110;&#25968;&#25454;&#25910;&#38598;&#25104;&#26412;&#39640;&#26114;&#21644;&#27979;&#37327;&#20202;&#22120;&#22833;&#28789;&#36896;&#25104;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LITE&#8212;&#8212;&#29992;&#20110;&#29615;&#22659;&#29983;&#24577;&#31995;&#32479;&#24314;&#27169;&#30340;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;LITE&#36890;&#36807;&#23558;&#19981;&#21516;&#29615;&#22659;&#21464;&#37327;&#36716;&#25442;&#25104;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#21644;&#25240;&#32447;&#22270;&#20687;&#26469;&#32479;&#19968;&#23427;&#20204;&#12290;&#28982;&#21518;&#65292;LITE&#21033;&#29992;&#32479;&#19968;&#32534;&#30721;&#22120;&#26469;&#25429;&#25417;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01165v1 Announce Type: new  Abstract: The modeling of environmental ecosystems plays a pivotal role in the sustainable management of our planet. Accurate prediction of key environmental variables over space and time can aid in informed policy and decision-making, thus improving people's livelihood. Recently, deep learning-based methods have shown promise in modeling the spatial-temporal relationships for predicting environmental variables. However, these approaches often fall short in handling incomplete features and distribution shifts, which are commonly observed in environmental data due to the substantial cost of data collection and malfunctions in measuring instruments. To address these issues, we propose LITE -- a multimodal large language model for environmental ecosystems modeling. Specifically, LITE unifies different environmental variables by transforming them into natural language descriptions and line graph images. Then, LITE utilizes unified encoders to capture 
&lt;/p&gt;</description></item><item><title>&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#20174;&#30456;&#20851;&#32467;&#26500;&#65288;&#20363;&#22914;&#8220;a few days&#8221;&#65289;&#36827;&#34892;&#27867;&#21270;&#23398;&#20064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;AANN&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2403.19827</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20174;&#19981;&#24120;&#35265;&#30340;&#29616;&#35937;&#20013;&#23398;&#20064;&#65306;&#32570;&#22833;AANN&#30340;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19827
&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#20174;&#30456;&#20851;&#32467;&#26500;&#65288;&#20363;&#22914;&#8220;a few days&#8221;&#65289;&#36827;&#34892;&#27867;&#21270;&#23398;&#20064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;AANN&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#32597;&#35265;&#30340;&#21477;&#27861;&#29616;&#35937;&#65292;&#20294;&#26377;&#20154;&#35748;&#20026;&#23427;&#20204;&#20381;&#36182;&#20110;&#27515;&#35760;&#30828;&#32972;&#65292;&#32780;&#19981;&#26159;&#35821;&#27861;&#27010;&#25324;&#12290;&#25105;&#20204;&#22312;&#35268;&#27169;&#20026;&#20154;&#31867;&#35268;&#27169;&#30340;&#35821;&#26009;&#24211;&#65288;1&#20159;&#23383;&#65289;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#36845;&#20195;&#35757;&#32451;&#21464;&#21387;&#22120;&#35821;&#35328;&#27169;&#22411;&#65292;&#28982;&#21518;&#35780;&#20272;&#23427;&#20204;&#23545;&#29305;&#23450;&#32597;&#35265;&#35821;&#27861;&#29616;&#35937;&#30340;&#23398;&#20064;&#65306;&#33521;&#35821;&#30340;&#20896;&#35789;+&#24418;&#23481;&#35789;+&#25968;&#23383;+&#21517;&#35789;&#65288;AANN&#65289;&#32467;&#26500;&#65288;&#8220;a beautiful five days&#8221;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19827v1 Announce Type: new  Abstract: Language models learn rare syntactic phenomena, but it has been argued that they rely on rote memorization, as opposed to grammatical generalization. Training on a corpus of human-scale in size (100M words), we iteratively trained transformer language models on systematically manipulated corpora and then evaluated their learning of a particular rare grammatical phenomenon: the English Article+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days''). We first compared how well this construction was learned on the default corpus relative to a counterfactual corpus in which the AANN sentences were removed. AANNs were still learned better than systematically perturbed variants of the construction. Using additional counterfactual corpora, we suggest that this learning occurs through generalization from related constructions (e.g., ``a few days''). An additional experiment showed that this learning is enhanced when there is more 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#26088;&#22312;&#35843;&#26597;&#19981;&#23433;&#20840;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#28216;&#25103;&#20013;&#30340;&#36829;&#27861;&#25512;&#24191;&#23041;&#32961;&#65292;&#25910;&#38598;&#20102;&#19968;&#32452;&#21253;&#21547;&#24615;&#26292;&#21147;&#21644;&#26292;&#21147;&#20869;&#23481;&#30340;&#30495;&#23454;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.18957</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#35268;&#27169;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#35843;&#33410;&#19981;&#23433;&#20840;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#28216;&#25103;&#20013;&#30340;&#36829;&#27861;&#22312;&#32447;&#22270;&#29255;&#25512;&#24191;
&lt;/p&gt;
&lt;p&gt;
Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18957
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#26088;&#22312;&#35843;&#26597;&#19981;&#23433;&#20840;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#28216;&#25103;&#20013;&#30340;&#36829;&#27861;&#25512;&#24191;&#23041;&#32961;&#65292;&#25910;&#38598;&#20102;&#19968;&#32452;&#21253;&#21547;&#24615;&#26292;&#21147;&#21644;&#26292;&#21147;&#20869;&#23481;&#30340;&#30495;&#23454;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#28216;&#25103;&#65288;UGCGs&#65289;&#22312;&#20799;&#31461;&#21644;&#38738;&#23569;&#24180;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#29992;&#20110;&#31038;&#20132;&#20114;&#21160;&#21644;&#26356;&#26377;&#21019;&#24847;&#30340;&#22312;&#32447;&#23089;&#20048;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23384;&#22312;&#30528;&#26356;&#39640;&#30340;&#26292;&#38706;&#19981;&#33391;&#20869;&#23481;&#30340;&#39118;&#38505;&#65292;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#20799;&#31461;&#21644;&#38738;&#23569;&#24180;&#22312;&#32447;&#23433;&#20840;&#30340;&#26085;&#30410;&#20851;&#27880;&#12290;&#25105;&#20204;&#37319;&#21462;&#20102;&#31532;&#19968;&#27493;&#30740;&#31350;&#23545;&#19981;&#23433;&#20840;UGCGs&#30340;&#36829;&#27861;&#25512;&#24191;&#36827;&#34892;&#23041;&#32961;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#32452;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;2,924&#24352;&#23637;&#31034;&#19981;&#21516;&#24615;&#26292;&#21147;&#21644;&#26292;&#21147;&#20869;&#23481;&#30340;&#22270;&#20687;&#65292;&#36825;&#20123;&#20869;&#23481;&#34987;&#28216;&#25103;&#21019;&#24314;&#32773;&#29992;&#20110;&#25512;&#24191;UGCGs&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18957v1 Announce Type: cross  Abstract: Online user-generated content games (UGCGs) are increasingly popular among children and adolescents for social interaction and more creative online entertainment. However, they pose a heightened risk of exposure to explicit content, raising growing concerns for the online safety of children and adolescents. Despite these concerns, few studies have addressed the issue of illicit image-based promotions of unsafe UGCGs on social media, which can inadvertently attract young users. This challenge arises from the difficulty of obtaining comprehensive training data for UGCG images and the unique nature of these images, which differ from traditional unsafe content. In this work, we take the first step towards studying the threat of illicit promotions of unsafe UGCGs. We collect a real-world dataset comprising 2,924 images that display diverse sexually explicit and violent content used to promote UGCGs by their game creators. Our in-depth studi
&lt;/p&gt;</description></item><item><title>&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25104;&#23545;&#20559;&#22909;&#25628;&#32034;&#26041;&#27861;PAIRS&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;LLMs&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#20248;&#20110;&#30452;&#25509;&#25171;&#20998;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.16950</link><description>&lt;p&gt;
&#19982;&#20154;&#31867;&#21028;&#26029;&#30456;&#19968;&#33268;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#25104;&#23545;&#20559;&#22909;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16950
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25104;&#23545;&#20559;&#22909;&#25628;&#32034;&#26041;&#27861;PAIRS&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;LLMs&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#20248;&#20110;&#30452;&#25509;&#25171;&#20998;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#33258;&#21160;&#35780;&#20272;&#22120;&#22312;&#35780;&#20272;&#29983;&#25104;&#30340;&#33258;&#28982;&#35821;&#35328;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#22312;&#35780;&#20272;&#20013;&#20173;&#23384;&#22312;&#20559;&#35265;&#65292;&#24120;&#24120;&#38590;&#20197;&#29983;&#25104;&#19982;&#20154;&#31867;&#35780;&#20272;&#19968;&#33268;&#30340;&#36830;&#36143;&#35780;&#20272;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;LLM&#35780;&#20272;&#22120;&#19982;&#20154;&#31867;&#21028;&#26029;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#36827;&#34892;&#31995;&#32479;&#30740;&#31350;&#65292;&#25581;&#31034;&#29616;&#26377;&#26088;&#22312;&#20943;&#36731;&#20559;&#35265;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#36275;&#20197;&#26377;&#25928;&#23558;LLM&#35780;&#20272;&#22120;&#23545;&#40784;&#12290;&#21463;&#21040;RLHF&#20013;&#23545;&#20559;&#22909;&#25968;&#25454;&#30340;&#20351;&#29992;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#35780;&#20272;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#25490;&#24207;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;Pairwise-preference Search&#65288;PAIRS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20197;LLMs&#36827;&#34892;&#25104;&#23545;&#27604;&#36739;&#24182;&#26377;&#25928;&#23545;&#20505;&#36873;&#25991;&#26412;&#36827;&#34892;&#25490;&#24207;&#30340;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24341;&#23548;&#30340;&#25628;&#32034;&#26041;&#27861;&#12290;PAIRS&#22312;&#20195;&#34920;&#24615;&#35780;&#20272;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#26174;&#31034;&#20986;&#27604;&#30452;&#25509;&#25171;&#20998;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16950v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated promising capabilities as automatic evaluators in assessing the quality of generated natural language. However, LLMs still exhibit biases in evaluation and often struggle to generate coherent evaluations that align with human assessments. In this work, we first conduct a systematic study of the misalignment between LLM evaluators and human judgement, revealing that existing calibration methods aimed at mitigating biases are insufficient for effectively aligning LLM evaluators. Inspired by the use of preference data in RLHF, we formulate the evaluation as a ranking problem and introduce Pairwise-preference Search (PAIRS), an uncertainty-guided search method that employs LLMs to conduct pairwise comparisons and efficiently ranks candidate texts. PAIRS achieves state-of-the-art performance on representative evaluation tasks and demonstrates significant improvements over direct scoring. Furthe
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;</title><link>https://arxiv.org/abs/2403.15740</link><description>&lt;p&gt;
Ghost Sentence&#65306;&#19968;&#31181;&#20379;&#26222;&#36890;&#29992;&#25143;&#20351;&#29992;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#36827;&#34892;&#29256;&#26435;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15740
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Web&#29992;&#25143;&#25968;&#25454;&#22312;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21450;&#20854;&#24494;&#35843;&#21464;&#31181;&#30340;&#29983;&#24577;&#31995;&#32479;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#24314;&#35758;&#29992;&#25143;&#22312;&#20854;&#25991;&#26723;&#20013;&#21453;&#22797;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#65292;&#20351;LLMs&#33021;&#22815;&#35760;&#24518;&#36825;&#20123;&#23494;&#30721;&#12290;&#36825;&#20123;&#29992;&#25143;&#25991;&#26723;&#20013;&#38544;&#34255;&#30340;&#23494;&#30721;&#65292;&#34987;&#31216;&#20026;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#19968;&#26086;&#23427;&#20204;&#20986;&#29616;&#22312;LLMs&#29983;&#25104;&#30340;&#20869;&#23481;&#20013;&#65292;&#29992;&#25143;&#23601;&#21487;&#20197;&#30830;&#20449;&#20182;&#20204;&#30340;&#25968;&#25454;&#34987;&#29992;&#20110;&#35757;&#32451;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#31181;&#29256;&#26435;&#24037;&#20855;&#30340;&#26377;&#25928;&#24615;&#21644;&#29992;&#27861;&#65292;&#25105;&#20204;&#21033;&#29992;&#24189;&#28789;&#21477;&#23376;&#23450;&#20041;&#20102;&#8220;&#29992;&#25143;&#35757;&#32451;&#25968;&#25454;&#35782;&#21035;&#8221;&#20219;&#21153;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#12289;&#19981;&#21516;&#35268;&#27169;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#35268;&#27169;&#30340;LLMs&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26368;&#21518;$k$&#20010;&#21333;&#35789;&#39564;&#35777;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15740v1 Announce Type: new  Abstract: Web user data plays a central role in the ecosystem of pre-trained large language models (LLMs) and their fine-tuned variants. Billions of data are crawled from the web and fed to LLMs. How can \textit{\textbf{everyday web users}} confirm if LLMs misuse their data without permission? In this work, we suggest that users repeatedly insert personal passphrases into their documents, enabling LLMs to memorize them. These concealed passphrases in user documents, referred to as \textit{ghost sentences}, once they are identified in the generated content of LLMs, users can be sure that their data is used for training. To explore the effectiveness and usage of this copyrighting tool, we define the \textit{user training data identification} task with ghost sentences. Multiple datasets from various sources at different scales are created and tested with LLMs of different sizes. For evaluation, we introduce a last $k$ words verification manner along 
&lt;/p&gt;</description></item><item><title>XLAVS-R&#26159;&#19968;&#20010;&#36328;&#35821;&#35328;&#35270;&#21548;&#35821;&#38899;&#34920;&#31034;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#26377;&#38480;&#30340;&#22810;&#35821;&#35328;AV&#39044;&#35757;&#32451;&#25968;&#25454;&#65292;&#31616;&#21270;&#39044;&#35757;&#32451;&#26041;&#26696;&#65292;&#20197;&#25552;&#39640;&#23545;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#65292;&#22312;&#19979;&#28216;&#38899;&#39057;-&#35270;&#35273;&#35821;&#38899;&#35782;&#21035;&#21644;&#32763;&#35793;&#20219;&#21153;&#20013;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#25552;&#21319;&#20102;&#39640;&#36798;18.5% WER&#21644;4.7 BLEU&#12290;</title><link>https://arxiv.org/abs/2403.14402</link><description>&lt;p&gt;
XLAVS-R: &#36328;&#35821;&#35328;&#35270;&#21548;&#35821;&#38899;&#34920;&#31034;&#23398;&#20064;&#29992;&#20110;&#22122;&#22768;&#40065;&#26834;&#35821;&#38899;&#30693;&#35273;
&lt;/p&gt;
&lt;p&gt;
XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14402
&lt;/p&gt;
&lt;p&gt;
XLAVS-R&#26159;&#19968;&#20010;&#36328;&#35821;&#35328;&#35270;&#21548;&#35821;&#38899;&#34920;&#31034;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#26377;&#38480;&#30340;&#22810;&#35821;&#35328;AV&#39044;&#35757;&#32451;&#25968;&#25454;&#65292;&#31616;&#21270;&#39044;&#35757;&#32451;&#26041;&#26696;&#65292;&#20197;&#25552;&#39640;&#23545;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#65292;&#22312;&#19979;&#28216;&#38899;&#39057;-&#35270;&#35273;&#35821;&#38899;&#35782;&#21035;&#21644;&#32763;&#35793;&#20219;&#21153;&#20013;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#25552;&#21319;&#20102;&#39640;&#36798;18.5% WER&#21644;4.7 BLEU&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#38899;&#35782;&#21035;&#21644;&#32763;&#35793;&#31995;&#32479;&#23545;&#22024;&#26434;&#30340;&#36755;&#20837;&#34920;&#29616;&#19981;&#20339;&#65292;&#22312;&#29616;&#23454;&#29615;&#22659;&#20013;&#32463;&#24120;&#20986;&#29616;&#12290;&#36890;&#36807;&#35270;&#35273;&#20449;&#21495;&#22686;&#24378;&#36825;&#20123;&#31995;&#32479;&#26377;&#28508;&#21147;&#25552;&#39640;&#23545;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#35270;&#21548;&#65288;AV&#65289;&#25968;&#25454;&#20165;&#26377;&#38480;&#21487;&#29992;&#65292;&#24182;&#19988;&#27604;&#20165;&#26377;&#38899;&#39057;&#36164;&#28304;&#30340;&#35821;&#35328;&#26356;&#23569;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;XLAVS-R&#65292;&#19968;&#20010;&#36328;&#35821;&#35328;&#35270;&#21548;&#35821;&#38899;&#34920;&#31034;&#27169;&#22411;&#65292;&#29992;&#20110;&#36229;&#36807;100&#31181;&#35821;&#35328;&#30340;&#22122;&#22768;&#40065;&#26834;&#35821;&#38899;&#35782;&#21035;&#21644;&#32763;&#35793;&#12290;&#23427;&#26088;&#22312;&#26368;&#22823;&#31243;&#24230;&#21033;&#29992;&#26377;&#38480;&#30340;&#22810;&#35821;&#35328;AV&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;&#30410;&#22788;&#65292;&#36890;&#36807;&#22312;&#38899;&#39057;-&#20165;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#30340;&#22522;&#30784;&#19978;&#26500;&#24314;&#65292;&#24182;&#31616;&#21270;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#26041;&#26696;&#12290;&#22312;MuAViC&#22522;&#20934;&#35780;&#20272;&#19978;&#23545;XLAVS-R&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#65292;&#26174;&#31034;&#20102;&#20854;&#22312;&#19979;&#28216;&#38899;&#39057;-&#35270;&#35273;&#35821;&#38899;&#35782;&#21035;&#21644;&#32763;&#35793;&#20219;&#21153;&#19978;&#30340;&#20248;&#21183;&#65292;&#22312;&#32473;&#20986;&#22024;&#26434;&#30340;AV&#36755;&#20837;&#26102;&#65292;&#20854;&#20248;&#20110;&#20808;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#26368;&#39640;&#36798;&#21040;18.5% WER&#21644;4.7 BLEU&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14402v1 Announce Type: cross  Abstract: Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is only available in limited amounts and for fewer languages than audio-only resources. To address this gap, we present XLAVS-R, a cross-lingual audio-visual speech representation model for noise-robust speech recognition and translation in over 100 languages. It is designed to maximize the benefits of limited multilingual AV pre-training data, by building on top of audio-only multilingual pre-training and simplifying existing pre-training schemes. Extensive evaluation on the MuAViC benchmark shows the strength of XLAVS-R on downstream audio-visual speech recognition and translation tasks, where it outperforms the previous state of the art by up to 18.5% WER and 4.7 BLEU given noisy AV inputs
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#31934;&#28860;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;LLM&#20013;&#25552;&#21462;&#30693;&#35782;&#26469;&#23454;&#29616;Prompt&#30340;&#21387;&#32553;&#65292;&#30830;&#20445;&#21387;&#32553;&#21518;&#30340;&#25552;&#31034;&#20445;&#25345;&#23545;&#21407;&#22987;&#25552;&#31034;&#30340;&#24544;&#23454;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.12968</link><description>&lt;p&gt;
LLMLingua-2: &#39640;&#25928;&#19988;&#24544;&#23454;&#30340;&#26080;&#20219;&#21153;Prompt&#21387;&#32553;&#30340;&#25968;&#25454;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12968
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#31934;&#28860;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;LLM&#20013;&#25552;&#21462;&#30693;&#35782;&#26469;&#23454;&#29616;Prompt&#30340;&#21387;&#32553;&#65292;&#30830;&#20445;&#21387;&#32553;&#21518;&#30340;&#25552;&#31034;&#20445;&#25345;&#23545;&#21407;&#22987;&#25552;&#31034;&#30340;&#24544;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20851;&#27880;&#20110;&#26080;&#20219;&#21153;&#30340;Prompt&#21387;&#32553;&#65292;&#20197;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#21644;&#25928;&#29575;&#12290;&#32771;&#34385;&#21040;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#20887;&#20313;&#24615;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#26681;&#25454;&#20174;&#22240;&#26524;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;LLaMa-7B&#65289;&#33719;&#24471;&#30340;&#20449;&#24687;&#29109;&#26469;&#21024;&#38500;token&#25110;&#35789;&#27719;&#21333;&#20301;&#26469;&#21387;&#32553;prompt&#12290;&#25361;&#25112;&#22312;&#20110;&#20449;&#24687;&#29109;&#21487;&#33021;&#26159;&#19968;&#20010;&#27425;&#20248;&#30340;&#21387;&#32553;&#24230;&#37327;&#65306;(i)&#23427;&#20165;&#21033;&#29992;&#21333;&#21521;&#19978;&#19979;&#25991;&#65292;&#21487;&#33021;&#26080;&#27861;&#25429;&#33719;&#25152;&#26377;&#29992;&#20110;prompt&#21387;&#32553;&#30340;&#20851;&#38190;&#20449;&#24687;&#65307;(ii)&#23427;&#19982;prompt&#21387;&#32553;&#30446;&#26631;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#31934;&#28860;&#36807;&#31243;&#65292;&#20174;LLM&#20013;&#33719;&#24471;&#30693;&#35782;&#20197;&#21387;&#32553;prompt&#32780;&#19981;&#20002;&#22833;&#20851;&#38190;&#20449;&#24687;&#65292;&#24182;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#20010;&#25277;&#21462;&#24335;&#25991;&#26412;&#21387;&#32553;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23558;prompt&#21387;&#32553;&#26684;&#24335;&#21270;&#20026;&#19968;&#20010;token&#20998;&#31867;&#38382;&#39064;&#65292;&#20197;&#30830;&#20445;&#21387;&#32553;&#21518;&#30340;prompt&#19982;&#21407;&#22987;prompt&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12968v1 Announce Type: new  Abstract: This paper focuses on task-agnostic prompt compression for better generalizability and efficiency. Considering the redundancy in natural language, existing approaches compress prompts by removing tokens or lexical units according to their information entropy obtained from a causal language model such as LLaMa-7B. The challenge is that information entropy may be a suboptimal compression metric: (i) it only leverages unidirectional context and may fail to capture all essential information needed for prompt compression; (ii) it is not aligned with the prompt compression objective.   To address these issues, we propose a data distillation procedure to derive knowledge from an LLM to compress prompts without losing crucial information, and meantime, introduce an extractive text compression dataset. We formulate prompt compression as a token classification problem to guarantee the faithfulness of the compressed prompt to the original one, and 
&lt;/p&gt;</description></item><item><title>RAGGED&#26694;&#26550;&#20998;&#26512;&#21644;&#20248;&#21270;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#36866;&#21512;&#19981;&#21516;RAG&#35774;&#32622;&#30340;&#20107;&#23454;&#65292;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#38543;&#25991;&#26723;&#25968;&#37327;&#22686;&#21152;&#32780;&#25913;&#21892;&#65292;&#32780;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#21482;&#33021;&#26377;&#25928;&#21033;&#29992;&#23569;&#37327;&#25991;&#26723;&#12290;</title><link>https://arxiv.org/abs/2403.09040</link><description>&lt;p&gt;
RAGGED:&#26397;&#30528;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#30340;&#30693;&#24773;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09040
&lt;/p&gt;
&lt;p&gt;
RAGGED&#26694;&#26550;&#20998;&#26512;&#21644;&#20248;&#21270;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#36866;&#21512;&#19981;&#21516;RAG&#35774;&#32622;&#30340;&#20107;&#23454;&#65292;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#38543;&#25991;&#26723;&#25968;&#37327;&#22686;&#21152;&#32780;&#25913;&#21892;&#65292;&#32780;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#21482;&#33021;&#26377;&#25928;&#21033;&#29992;&#23569;&#37327;&#25991;&#26723;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09040v1 &#22768;&#26126;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#36890;&#36807;&#20026;&#25991;&#26723;&#22411;&#38382;&#31572;&#31561;&#20219;&#21153;&#25552;&#20379;&#38468;&#21152;&#19978;&#19979;&#25991;&#65292;&#26497;&#22823;&#22320;&#25552;&#21319;&#20102;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#20855;&#26377;&#28508;&#21147;&#65292;&#20294;RAG&#30340;&#25928;&#21147;&#39640;&#24230;&#20381;&#36182;&#20110;&#20854;&#37197;&#32622;&#65292;&#20174;&#32780;&#24341;&#21457;&#19968;&#20010;&#38382;&#39064;&#65306;&#20160;&#20040;&#26159;&#26368;&#20339;RAG&#37197;&#32622;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;RAGGED&#26694;&#26550;&#26469;&#20998;&#26512;&#21644;&#20248;&#21270;RAG&#31995;&#32479;&#12290;&#22312;&#19968;&#32452;&#20195;&#34920;&#24615;&#30340;&#25991;&#26723;&#22411;&#38382;&#31572;&#20219;&#21153;&#19978;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#32463;&#20856;&#30340;&#31232;&#30095;&#21644;&#23494;&#38598;&#26816;&#32034;&#22120;&#65292;&#20197;&#21450;&#22235;&#31181;&#22312;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#21644;&#20165;&#35299;&#30721;&#22120;&#32467;&#26500;&#20013;&#34920;&#29616;&#20248;&#24322;&#30340;LMs&#12290;&#36890;&#36807;RAGGED&#65292;&#25105;&#20204;&#21457;&#29616;&#19981;&#21516;&#27169;&#22411;&#36866;&#21512;&#23436;&#20840;&#19981;&#21516;&#30340;RAG&#35774;&#32622;&#12290;&#34429;&#28982;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#38543;&#30528;&#26356;&#22810;&#25991;&#26723;&#30340;&#22686;&#21152;&#32780;&#21333;&#35843;&#25552;&#21319;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#21482;&#33021;&#26377;&#25928;&#22320;&#20351;&#29992;&lt;5&#20010;&#25991;&#26723;&#65292;&#23613;&#31649;&#36890;&#24120;&#20855;&#26377;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#12290;RAGGED&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;LMs&#30340;&#19978;&#19979;&#25991;&#21033;&#29992;&#20064;&#24815;&#65292;&#25105;&#20204;&#21457;&#29616;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09040v1 Announce Type: new  Abstract: Retrieval-augmented generation (RAG) greatly benefits language models (LMs) by providing additional context for tasks such as document-based question answering (DBQA). Despite its potential, the power of RAG is highly dependent on its configuration, raising the question: What is the optimal RAG configuration? To answer this, we introduce the RAGGED framework to analyze and optimize RAG systems. On a set of representative DBQA tasks, we study two classic sparse and dense retrievers, and four top-performing LMs in encoder-decoder and decoder-only architectures. Through RAGGED, we uncover that different models suit substantially varied RAG setups. While encoder-decoder models monotonically improve with more documents, we find decoder-only models can only effectively use &lt; 5 documents, despite often having a longer context window. RAGGED offers further insights into LMs' context utilization habits, where we find that encoder-decoder models r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;ConspEmoLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#38598;&#25104;&#24773;&#24863;&#20449;&#24687;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#38452;&#35851;&#29702;&#35770;&#25991;&#26412;&#30340;&#24773;&#24863;&#29305;&#24449;&#36827;&#34892;&#32508;&#21512;&#20998;&#26512;&#65292;&#33021;&#22815;&#25191;&#34892;&#22810;&#39033;&#20219;&#21153;&#65292;&#21253;&#25324;&#38452;&#35851;&#29702;&#35770;&#26816;&#27979;&#12289;&#29702;&#35770;&#31867;&#22411;&#20998;&#31867;&#21644;&#30456;&#20851;&#25991;&#26412;&#26816;&#27979;&#12290;</title><link>https://arxiv.org/abs/2403.06765</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#24773;&#24863;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26816;&#27979;&#38452;&#35851;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;ConspEmoLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#38598;&#25104;&#24773;&#24863;&#20449;&#24687;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#38452;&#35851;&#29702;&#35770;&#25991;&#26412;&#30340;&#24773;&#24863;&#29305;&#24449;&#36827;&#34892;&#32508;&#21512;&#20998;&#26512;&#65292;&#33021;&#22815;&#25191;&#34892;&#22810;&#39033;&#20219;&#21153;&#65292;&#21253;&#25324;&#38452;&#35851;&#29702;&#35770;&#26816;&#27979;&#12289;&#29702;&#35770;&#31867;&#22411;&#20998;&#31867;&#21644;&#30456;&#20851;&#25991;&#26412;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#32852;&#32593;&#32473;&#31038;&#20250;&#24102;&#26469;&#20102;&#22909;&#22788;&#21644;&#20260;&#23475;&#12290;&#21518;&#32773;&#30340;&#19968;&#20010;&#20027;&#35201;&#20363;&#23376;&#26159;&#35823;&#23548;&#20449;&#24687;&#65292;&#21253;&#25324;&#20805;&#26021;&#32593;&#32476;&#30340;&#38452;&#35851;&#29702;&#35770;&#12290; &#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#24050;&#32463;&#25552;&#39640;&#20102;&#20934;&#30830;&#26816;&#27979;&#35823;&#23548;&#20449;&#24687;&#30340;&#21069;&#26223;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#22522;&#20110;LLM&#30340;&#38452;&#35851;&#29702;&#35770;&#26816;&#27979;&#26041;&#27861;&#20165;&#19987;&#27880;&#20110;&#20108;&#20803;&#20998;&#31867;&#65292;&#24182;&#26410;&#32771;&#34385;&#35823;&#23548;&#20449;&#24687;&#19982;&#24773;&#24863;&#29305;&#24449;&#65288;&#21363;&#24773;&#24863;&#21644;&#24773;&#32490;&#65289;&#20043;&#38388;&#30340;&#37325;&#35201;&#20851;&#31995;&#12290;&#36890;&#36807;&#23545;&#25581;&#31034;&#20854;&#29420;&#29305;&#24773;&#24863;&#29305;&#24449;&#30340;&#38452;&#35851;&#25991;&#26412;&#30340;&#20840;&#38754;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ConspEmoLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#38598;&#25104;&#24773;&#24863;&#20449;&#24687;&#19988;&#33021;&#22815;&#25191;&#34892;&#28041;&#21450;&#38452;&#35851;&#29702;&#35770;&#30340;&#22810;&#26679;&#20219;&#21153;&#30340;&#24320;&#28304;LLM&#12290; &#36825;&#20123;&#20219;&#21153;&#19981;&#20165;&#21253;&#25324;&#38452;&#35851;&#29702;&#35770;&#26816;&#27979;&#65292;&#36824;&#21253;&#25324;&#29702;&#35770;&#31867;&#22411;&#20998;&#31867;&#21644;&#30456;&#20851;&#25991;&#26412;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06765v1 Announce Type: new  Abstract: The internet has brought both benefits and harms to society. A prime example of the latter is misinformation, including conspiracy theories, which flood the web. Recent advances in natural language processing, particularly the emergence of large language models (LLMs), have improved the prospects of accurate misinformation detection. However, most LLM-based approaches to conspiracy theory detection focus only on binary classification and fail to account for the important relationship between misinformation and affective features (i.e., sentiment and emotions). Driven by a comprehensive analysis of conspiracy text that reveals its distinctive affective features, we propose ConspEmoLLM, the first open-source LLM that integrates affective information and is able to perform diverse tasks relating to conspiracy theories. These tasks include not only conspiracy theory detection, but also classification of theory type and detection of related d
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35821;&#31687;&#23454;&#20307;&#35782;&#21035;&#19978;&#20855;&#26377;&#22522;&#26412;&#30340;&#33021;&#21147;&#65292;&#20294;&#22312;&#26032;&#39062;&#24615;&#26041;&#38754;&#20173;&#26410;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;</title><link>https://arxiv.org/abs/2403.06301</link><description>&lt;p&gt;
LIEDER: &#29992;&#20110;&#35821;&#31687;&#23454;&#20307;&#35782;&#21035;&#30340;&#35821;&#35328;&#23398;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06301
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35821;&#31687;&#23454;&#20307;&#35782;&#21035;&#19978;&#20855;&#26377;&#22522;&#26412;&#30340;&#33021;&#21147;&#65292;&#20294;&#22312;&#26032;&#39062;&#24615;&#26041;&#38754;&#20173;&#26410;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026; LIEDER &#30340;&#25968;&#25454;&#38598;&#65292;&#20801;&#35768;&#35814;&#32454;&#26816;&#26597;&#35821;&#35328;&#27169;&#22411;&#23545;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#12289;&#22797;&#25968;&#24615;&#21644;&#26032;&#39062;&#24615;&#31561;&#22235;&#20010;&#20851;&#38190;&#35821;&#20041;&#23646;&#24615;&#30340;&#35748;&#30693;&#27700;&#24179;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#25152;&#26377;&#36825;&#20123;&#23646;&#24615;&#37117;&#34920;&#29616;&#20986;&#25935;&#24863;&#24615;&#65292;&#38500;&#20102;&#26032;&#39062;&#24615;&#65292;&#36825;&#34920;&#26126;&#23427;&#20204;&#23578;&#26410;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;&#30340;&#35821;&#35328;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06301v1 Announce Type: new  Abstract: Discourse Entity (DE) recognition is the task of identifying novel and known entities introduced within a text. While previous work has found that large language models have basic, if imperfect, DE recognition abilities (Schuster and Linzen, 2022), it remains largely unassessed which of the fundamental semantic properties that govern the introduction and subsequent reference to DEs they have knowledge of. We propose the Linguistically-Informed Evaluation for Discourse Entity Recognition (LIEDER) dataset that allows for a detailed examination of language models' knowledge of four crucial semantic properties: existence, uniqueness, plurality, and novelty. We find evidence that state-of-the-art large language models exhibit sensitivity to all of these properties except novelty, which demonstrates that they have yet to reach human-level language understanding abilities.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#25351;&#23548;&#24494;&#35843;&#30340;&#28508;&#22312;&#26426;&#21046;&#65292;&#21457;&#29616;&#23581;&#35797;&#36890;&#36807;&#25351;&#23548;&#24494;&#35843;&#23398;&#20064;&#39069;&#22806;&#19990;&#30028;&#30693;&#35782;&#24448;&#24448;&#38590;&#20197;&#20135;&#29983;&#31215;&#26497;&#24433;&#21709;&#65292;&#37325;&#28857;&#22312;&#20110;&#20445;&#25345;&#20869;&#37096;&#30693;&#35782;&#19968;&#33268;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.18243</link><description>&lt;p&gt;
&#23398;&#20064;&#36824;&#26159;&#33258;&#25105;&#35843;&#25972;&#65311;&#37325;&#26032;&#24605;&#32771;&#25351;&#23548;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Learning or Self-aligning? Rethinking Instruction Fine-tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18243
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#25351;&#23548;&#24494;&#35843;&#30340;&#28508;&#22312;&#26426;&#21046;&#65292;&#21457;&#29616;&#23581;&#35797;&#36890;&#36807;&#25351;&#23548;&#24494;&#35843;&#23398;&#20064;&#39069;&#22806;&#19990;&#30028;&#30693;&#35782;&#24448;&#24448;&#38590;&#20197;&#20135;&#29983;&#31215;&#26497;&#24433;&#21709;&#65292;&#37325;&#28857;&#22312;&#20110;&#20445;&#25345;&#20869;&#37096;&#30693;&#35782;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#23548;&#24494;&#35843;&#65288;IFT&#65289;&#26159;&#26500;&#24314;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#38454;&#27573;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;IFT&#22312;&#34892;&#20026;&#35268;&#33539;&#20256;&#36882;&#21644;&#39069;&#22806;&#19990;&#30028;&#30693;&#35782;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;IFT&#28508;&#22312;&#26426;&#21046;&#30340;&#29702;&#35299;&#20173;&#28982;&#30456;&#24403;&#26377;&#38480;&#12290;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#20010;&#30693;&#35782;&#24178;&#39044;&#26694;&#26550;&#65292;&#20197;&#35299;&#32806;IFT&#30340;&#28508;&#22312;&#22240;&#32032;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#19981;&#21516;&#22240;&#32032;&#30340;&#20010;&#20307;&#20998;&#26512;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#65292;&#36890;&#36807;IFT&#35797;&#22270;&#23398;&#20064;&#39069;&#22806;&#30340;&#19990;&#30028;&#30693;&#35782;&#24448;&#24448;&#38590;&#20197;&#20135;&#29983;&#31215;&#26497;&#24433;&#21709;&#65292;&#29978;&#33267;&#21487;&#33021;&#23548;&#33268;&#26126;&#26174;&#36127;&#38754;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;IFT&#20043;&#21069;&#21644;&#20043;&#21518;&#20445;&#25345;&#20869;&#37096;&#30693;&#35782;&#19968;&#33268;&#24615;&#26159;&#23454;&#29616;&#25104;&#21151;IFT&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25581;&#31034;&#20102;IFT&#30340;&#28508;&#22312;&#26426;&#21046;&#65292;&#24182;&#20026;&#26368;&#26032;&#21644;&#28508;&#22312;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#21147;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18243v1 Announce Type: new  Abstract: Instruction Fine-tuning~(IFT) is a critical phase in building large language models~(LLMs). Previous works mainly focus on the IFT's role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains significantly limited. In this paper, we design a knowledge intervention framework to decouple the potential underlying factors of IFT, thereby enabling individual analysis of different factors. Surprisingly, our experiments reveal that attempting to learn additional world knowledge through IFT often struggles to yield positive impacts and can even lead to markedly negative effects. Further, we discover that maintaining internal knowledge consistency before and after IFT is a critical factor for achieving successful IFT. Our findings reveal the underlying mechanisms of IFT and provide robust support for some very recent and potential future works.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#27604;&#36739;LLMs&#19982;&#20256;&#32479;&#27169;&#22411;&#65292;&#21457;&#29616;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;LLMs&#22312;&#39044;&#27979;&#20855;&#26377;&#26126;&#26174;&#27169;&#24335;&#21644;&#36235;&#21183;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#32570;&#20047;&#21608;&#26399;&#24615;&#30340;&#25968;&#25454;&#38598;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#21516;&#26102;&#25351;&#20986;&#34701;&#20837;&#22806;&#37096;&#30693;&#35782;&#21644;&#37319;&#29992;&#33258;&#28982;&#35821;&#35328;&#37322;&#20041;&#26377;&#21161;&#20110;&#25552;&#21319;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.10835</link><description>&lt;p&gt;
LLMs&#19979;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65306;&#29702;&#35299;&#21644;&#22686;&#24378;&#27169;&#22411;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#27604;&#36739;LLMs&#19982;&#20256;&#32479;&#27169;&#22411;&#65292;&#21457;&#29616;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;LLMs&#22312;&#39044;&#27979;&#20855;&#26377;&#26126;&#26174;&#27169;&#24335;&#21644;&#36235;&#21183;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#32570;&#20047;&#21608;&#26399;&#24615;&#30340;&#25968;&#25454;&#38598;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#21516;&#26102;&#25351;&#20986;&#34701;&#20837;&#22806;&#37096;&#30693;&#35782;&#21644;&#37319;&#29992;&#33258;&#28982;&#35821;&#35328;&#37322;&#20041;&#26377;&#21161;&#20110;&#25552;&#21319;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLMs)&#36817;&#24180;&#26469;&#22312;&#35768;&#22810;&#39046;&#22495;&#24471;&#21040;&#36805;&#36895;&#21457;&#23637;&#12290;&#20316;&#20026;&#19968;&#31181;&#32463;&#20856;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26368;&#36817;&#20174;LLMs&#20013;&#33719;&#24471;&#20102;&#25512;&#21160;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#19968;&#39046;&#22495;&#65292;LLMs&#30340;&#20559;&#22909;&#23384;&#22312;&#30740;&#31350;&#31354;&#30333;&#12290;&#36890;&#36807;&#23558;LLMs&#19982;&#20256;&#32479;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#65292;&#21457;&#29616;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#35768;&#22810;&#29305;&#24615;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;LLMs&#22312;&#39044;&#27979;&#20855;&#26377;&#26126;&#26174;&#27169;&#24335;&#21644;&#36235;&#21183;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#32570;&#20047;&#21608;&#26399;&#24615;&#30340;&#25968;&#25454;&#38598;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#25552;&#31034;&#35201;&#27714;LLMs&#21578;&#30693;&#25968;&#25454;&#38598;&#30340;&#21608;&#26399;&#26469;&#35299;&#37322;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#30740;&#31350;&#20102;&#36755;&#20837;&#31574;&#30053;&#65292;&#21457;&#29616;&#34701;&#20837;&#22806;&#37096;&#30693;&#35782;&#21644;&#37319;&#29992;&#33258;&#28982;&#35821;&#35328;&#37322;&#20041;&#31215;&#26497;&#24433;&#21709;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#36825;&#39033;&#30740;&#31350;&#26377;&#21161;&#20110;&#27934;&#23519;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10835v1 Announce Type: new  Abstract: Large language models (LLMs) have been applied in many fields with rapid development in recent years. As a classic machine learning task, time series forecasting has recently received a boost from LLMs. However, there is a research gap in the LLMs' preferences in this field. In this paper, by comparing LLMs with traditional models, many properties of LLMs in time series prediction are found. For example, our study shows that LLMs excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. We explain our findings through designing prompts to require LLMs to tell the period of the datasets. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases positively affects the predictive performance of LLMs for time series. Overall, this study contributes to insight into the advantages and limitations of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;LlaSMol&#65292;&#23427;&#26159;&#19968;&#31181;&#25512;&#36827;&#21270;&#23398;&#39046;&#22495;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#22823;&#35268;&#27169;&#12289;&#20840;&#38754;&#12289;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;LlaSMol&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;GPT-4&#24182;&#25509;&#36817;&#20110;&#20219;&#21153;&#29305;&#23450;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.09391</link><description>&lt;p&gt;
LlaSMol:&#21033;&#29992;&#22823;&#35268;&#27169;&#12289;&#20840;&#38754;&#12289;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;&#25512;&#36827;&#21270;&#23398;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;LlaSMol&#65292;&#23427;&#26159;&#19968;&#31181;&#25512;&#36827;&#21270;&#23398;&#39046;&#22495;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#22823;&#35268;&#27169;&#12289;&#20840;&#38754;&#12289;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;LlaSMol&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;GPT-4&#24182;&#25509;&#36817;&#20110;&#20219;&#21153;&#29305;&#23450;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21270;&#23398;&#22312;&#33647;&#29289;&#30740;&#21457;&#21644;&#26448;&#26009;&#31185;&#23398;&#31561;&#35768;&#22810;&#39046;&#22495;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23613;&#31649;&#35832;&#22914;GPT-4&#20043;&#31867;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#65292;&#20294;&#29616;&#26377;&#24037;&#20316;&#34920;&#26126;&#23427;&#20204;&#22312;&#21270;&#23398;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#20196;&#20154;&#22833;&#26395;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#24320;&#21457;&#30340;LLM&#22312;&#19968;&#31995;&#21015;&#21270;&#23398;&#20219;&#21153;&#19978;&#21487;&#20197;&#21462;&#24471;&#38750;&#24120;&#24378;&#22823;&#30340;&#32467;&#26524;&#65292;&#22312;&#25152;&#26377;&#20219;&#21153;&#19978;&#37117;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;GPT-4&#65292;&#24182;&#25509;&#36817;SoTA&#20219;&#21153;&#29305;&#23450;&#27169;&#22411;&#12290;&#25105;&#20204;&#21462;&#24471;&#25104;&#21151;&#30340;&#20851;&#38190;&#26159;&#19968;&#20010;&#21517;&#20026;SMolInstruct&#30340;&#22823;&#35268;&#27169;&#12289;&#20840;&#38754;&#12289;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;&#12290;&#23427;&#21253;&#21547;&#20102;14&#20010;&#32463;&#36807;&#31934;&#24515;&#25361;&#36873;&#30340;&#21270;&#23398;&#20219;&#21153;&#21644;&#36229;&#36807;&#19977;&#30334;&#19975;&#20010;&#39640;&#36136;&#37327;&#26679;&#26412;&#65292;&#20026;&#35757;&#32451;&#21644;&#35780;&#20272;&#21270;&#23398;LLM&#22880;&#23450;&#20102;&#22362;&#23454;&#22522;&#30784;&#12290;&#22522;&#20110;SMolInstruct&#65292;&#25105;&#20204;&#23545;&#19968;&#32452;&#24320;&#28304;LLM&#36827;&#34892;&#20102;&#24494;&#35843;&#65292;&#20854;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;Mistral ser&#26159;&#26368;&#20339;&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09391v1 Announce Type: new Abstract: Chemistry plays a crucial role in many domains, such as drug discovery and material science. While large language models (LLMs) such as GPT-4 exhibit remarkable capabilities on natural language processing tasks, existing work shows their performance on chemistry tasks is discouragingly low. In this paper, however, we demonstrate that our developed LLMs can achieve very strong results on a comprehensive set of chemistry tasks, outperforming the most advanced GPT-4 across all the tasks by a substantial margin and approaching the SoTA task-specific models. The key to our success is a large-scale, comprehensive, high-quality dataset for instruction tuning named SMolInstruct. It contains 14 meticulously selected chemistry tasks and over three million high-quality samples, laying a solid foundation for training and evaluating LLMs for chemistry. Based on SMolInstruct, we fine-tune a set of open-source LLMs, among which, we find that Mistral ser
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#33258;&#28982;&#35821;&#35328;&#21644;&#24418;&#24335;&#35821;&#35328;&#25972;&#21512;&#30340;&#8220;&#27491;&#24335;-LLM&#8221;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#29616;&#26377;LLM&#26234;&#33021;&#20307;&#26080;&#27861;&#25511;&#21046;&#30340;&#35745;&#21010;&#29983;&#25104;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#25552;&#39640;&#29983;&#25104;&#35745;&#21010;&#24615;&#33021;&#21644;&#30830;&#20445;&#21487;&#25511;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.00798</link><description>&lt;p&gt;
&#27491;&#24335;-LLM&#65306;&#23558;&#24418;&#24335;&#35821;&#35328;&#21644;&#33258;&#28982;&#35821;&#35328;&#38598;&#25104;&#20110;&#21487;&#25511;&#30340;LLM&#26234;&#33021;&#20307;&#20013;
&lt;/p&gt;
&lt;p&gt;
Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00798
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#33258;&#28982;&#35821;&#35328;&#21644;&#24418;&#24335;&#35821;&#35328;&#25972;&#21512;&#30340;&#8220;&#27491;&#24335;-LLM&#8221;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#29616;&#26377;LLM&#26234;&#33021;&#20307;&#26080;&#27861;&#25511;&#21046;&#30340;&#35745;&#21010;&#29983;&#25104;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#25552;&#39640;&#29983;&#25104;&#35745;&#21010;&#24615;&#33021;&#21644;&#30830;&#20445;&#21487;&#25511;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#23637;&#20351;&#24471;&#20154;&#24037;&#26234;&#33021;&#26234;&#33021;&#20307;&#33021;&#22815;&#33258;&#21160;&#29983;&#25104;&#21644;&#25191;&#34892;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#30340;&#22810;&#27493;&#35745;&#21010;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLM&#30340;&#20869;&#23481;&#29983;&#25104;&#36807;&#31243;&#20960;&#20046;&#26080;&#27861;&#25511;&#21046;&#65292;&#24403;&#21069;&#30340;LLM&#26234;&#33021;&#20307;&#32463;&#24120;&#29983;&#25104;&#26080;&#25928;&#25110;&#19981;&#21487;&#25191;&#34892;&#30340;&#35745;&#21010;&#65292;&#36825;&#25439;&#23475;&#20102;&#29983;&#25104;&#35745;&#21010;&#30340;&#24615;&#33021;&#24182;&#30772;&#22351;&#20102;&#29992;&#25143;&#23545;LLM&#26234;&#33021;&#20307;&#30340;&#20449;&#20219;&#12290;&#20026;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#8220;&#27491;&#24335;-LLM&#8221;&#26694;&#26550;&#65292;&#29992;&#20110;LLM&#26234;&#33021;&#20307;&#65292;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#30340;&#34920;&#36798;&#21147;&#21644;&#24418;&#24335;&#35821;&#35328;&#30340;&#31934;&#30830;&#24615;&#36827;&#34892;&#25972;&#21512;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26694;&#26550;&#20801;&#35768;&#20154;&#31867;&#29992;&#25143;&#23558;&#20182;&#20204;&#23545;&#35745;&#21010;&#36807;&#31243;&#30340;&#35201;&#27714;&#25110;&#32422;&#26463;&#34920;&#36798;&#20026;&#33258;&#21160;&#26426;&#12290;&#28982;&#21518;&#65292;&#22312;&#33258;&#21160;&#26426;&#30340;&#30417;&#30563;&#19979;&#65292;&#20351;&#29992;&#22522;&#20110;&#22534;&#26632;&#30340;LLM&#35745;&#21010;&#29983;&#25104;&#36807;&#31243;&#26469;&#30830;&#20445;&#29983;&#25104;&#30340;&#35745;&#21010;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#65292;&#20174;&#32780;&#20351;&#35745;&#21010;&#36807;&#31243;&#21487;&#25511;&#12290;&#25105;&#20204;&#22312;&#22522;&#20934;&#20219;&#21153;&#21644;&#23454;&#38469;&#30340;&#30495;&#23454;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#24182;&#19988;obtained significant improvements over existing LLM-based agents, demonstrating the effectiveness and controllability of the proposed Formal-LLM framework.
&lt;/p&gt;
&lt;p&gt;
Recent advancements on Large Language Models (LLMs) enable AI Agents to automatically generate and execute multi-step plans to solve complex tasks. However, since LLM's content generation process is hardly controllable, current LLM-based agents frequently generate invalid or non-executable plans, which jeopardizes the performance of the generated plans and corrupts users' trust in LLM-based agents. In response, this paper proposes a novel ``Formal-LLM'' framework for LLM-based agents by integrating the expressiveness of natural language and the precision of formal language. Specifically, the framework allows human users to express their requirements or constraints for the planning process as an automaton. A stack-based LLM plan generation process is then conducted under the supervision of the automaton to ensure that the generated plan satisfies the constraints, making the planning process controllable. We conduct experiments on both benchmark tasks and practical real-life tasks, and o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;LLsM&#65292;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#38544;&#20889;&#26415;&#12290;&#36890;&#36807;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#65292;LLM&#33021;&#22815;&#20197;&#21487;&#25511;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#29305;&#23450;&#35805;&#35821;&#29305;&#24449;&#30340;&#38544;&#20889;&#25991;&#26412;&#65292;&#25552;&#39640;&#20102;&#38544;&#34109;&#36890;&#20449;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2401.15656</link><description>&lt;p&gt;
LLsM: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#38544;&#20889;&#26415;
&lt;/p&gt;
&lt;p&gt;
LLsM: Generative Linguistic Steganography with Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;LLsM&#65292;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#38544;&#20889;&#26415;&#12290;&#36890;&#36807;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#65292;LLM&#33021;&#22815;&#20197;&#21487;&#25511;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#29305;&#23450;&#35805;&#35821;&#29305;&#24449;&#30340;&#38544;&#20889;&#25991;&#26412;&#65292;&#25552;&#39640;&#20102;&#38544;&#34109;&#36890;&#20449;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#38544;&#20889;&#26415;&#65288;LS&#65289;&#26088;&#22312;&#26681;&#25454;&#31192;&#23494;&#20449;&#24687;&#29983;&#25104;&#38544;&#20889;&#25991;&#26412;&#65288;stego&#65289;&#12290;&#21482;&#26377;&#25480;&#26435;&#25509;&#25910;&#32773;&#25165;&#33021;&#23519;&#35273;&#25991;&#26412;&#20013;&#31192;&#23494;&#30340;&#23384;&#22312;&#24182;&#25552;&#21462;&#20986;&#26469;&#65292;&#20174;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#26696;&#29983;&#25104;&#30340;&#38544;&#20889;&#25991;&#26412;&#21487;&#25511;&#24615;&#36739;&#24046;&#65292;&#24456;&#38590;&#21253;&#21547;&#29305;&#23450;&#30340;&#35805;&#35821;&#29305;&#24449;&#65292;&#22914;&#39118;&#26684;&#12290;&#32467;&#26524;&#65292;&#38544;&#20889;&#25991;&#26412;&#23481;&#26131;&#34987;&#26816;&#27979;&#20986;&#26469;&#65292;&#21361;&#21450;&#38544;&#34109;&#36890;&#20449;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;LLsM&#65292;&#31532;&#19968;&#20010;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;LS&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21253;&#21547;&#20016;&#23500;&#35805;&#35821;&#29305;&#24449;&#30340;&#22823;&#35268;&#27169;&#26500;&#24314;&#25968;&#25454;&#38598;&#23545;LLaMA2&#36827;&#34892;&#24494;&#35843;&#65292;&#20351;&#24471;&#24494;&#35843;&#21518;&#30340;LLM&#33021;&#22815;&#20197;&#21487;&#25511;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#29305;&#23450;&#35805;&#35821;&#29305;&#24449;&#30340;&#25991;&#26412;&#12290;&#28982;&#21518;&#23558;&#35805;&#35821;&#20316;&#20026;&#24341;&#23548;&#20449;&#24687;&#21644;&#31192;&#23494;&#19968;&#36215;&#36755;&#20837;&#32473;&#24494;&#35843;&#21518;&#30340;LLM&#65292;&#24418;&#24335;&#20026;&#8220;Prompt&#8221;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#26500;&#24314;&#30340;&#20505;&#36873;&#27744;&#23558;&#36827;&#34892;&#33539;&#22260;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linguistic Steganography (LS) tasks aim to generate steganographic text (stego) based on secret information. Only authorized recipients can perceive the existence of secrets in the texts and extract them, thereby preserving privacy. However, the controllability of the stego generated by existing schemes is poor, and the stego is difficult to contain specific discourse characteristics such as style. As a result, the stego is easily detectable, compromising covert communication. To address these problems, this paper proposes LLsM, the first LS with the Large Language Model (LLM). We fine-tuned the LLaMA2 with a large-scale constructed dataset encompassing rich discourse characteristics, which enables the fine-tuned LLM to generate texts with specific discourse in a controllable manner. Then the discourse is used as guiding information and inputted into the fine-tuned LLM in the form of the Prompt together with secret. On this basis, the constructed candidate pool will be range encoded an
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23450;&#20041;&#26032;&#30340;&#35299;&#37322;&#25209;&#35780;&#20219;&#21153;&#12289;&#21019;&#24314;&#20154;&#24037;&#39564;&#35777;&#36807;&#30340;&#25968;&#25454;&#38598;&#24182;&#35757;&#32451;&#24320;&#28304;&#33258;&#21160;&#25209;&#35780;&#27169;&#22411;&#65292;&#25968;&#23383;&#33487;&#26684;&#25289;&#24213;&#26377;&#21161;&#20110;&#25581;&#31034;&#23398;&#29983;&#27169;&#22411;&#30340;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2311.09613</link><description>&lt;p&gt;
&#25968;&#23383;&#33487;&#26684;&#25289;&#24213;&#65306;&#36890;&#36807;&#35299;&#37322;&#25209;&#35780;&#35780;&#20272;LLM
&lt;/p&gt;
&lt;p&gt;
Digital Socrates: Evaluating LLMs through Explanation Critiques
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09613
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23450;&#20041;&#26032;&#30340;&#35299;&#37322;&#25209;&#35780;&#20219;&#21153;&#12289;&#21019;&#24314;&#20154;&#24037;&#39564;&#35777;&#36807;&#30340;&#25968;&#25454;&#38598;&#24182;&#35757;&#32451;&#24320;&#28304;&#33258;&#21160;&#25209;&#35780;&#27169;&#22411;&#65292;&#25968;&#23383;&#33487;&#26684;&#25289;&#24213;&#26377;&#21161;&#20110;&#25581;&#31034;&#23398;&#29983;&#27169;&#22411;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;LLMs&#21487;&#20197;&#25552;&#20379;&#26377;&#29702;&#26377;&#25454;&#30340;&#35299;&#37322;&#20197;&#21450;&#31572;&#26696;&#65292;&#20294;&#36825;&#20123;&#35299;&#37322;&#30340;&#24615;&#36136;&#21644;&#36136;&#37327;&#20173;&#28982;&#30693;&#20043;&#29978;&#23569;&#12290;&#20316;&#20026;&#22238;&#24212;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23450;&#20041;&#19968;&#31181;&#35814;&#32454;&#30340;&#26041;&#24335;&#26469;&#34920;&#24449;&#29616;&#20195;&#27169;&#22411;&#30340;&#35299;&#37322;&#33021;&#21147;&#65292;&#21019;&#24314;&#19968;&#20010;&#32454;&#33268;&#19988;&#21487;&#35299;&#37322;&#30340;&#35299;&#37322;&#35780;&#20272;&#24037;&#20855;&#65292;&#35813;&#24037;&#20855;&#21487;&#20197;&#33258;&#21160;&#29983;&#25104;&#36825;&#31181;&#34920;&#24449;&#65292;&#32780;&#26080;&#38656;&#20381;&#36182;&#26114;&#36149;&#30340;API&#35843;&#29992;&#25110;&#20154;&#31867;&#27880;&#37322;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#65306;(a)&#23450;&#20041;&#35299;&#37322;&#25209;&#35780;&#30340;&#26032;&#20219;&#21153;&#8212;&#8212;&#35782;&#21035;&#21644;&#20998;&#31867;&#35299;&#37322;&#20013;&#30340;&#20219;&#20309;&#20027;&#35201;&#32570;&#38519;&#65292;&#24182;&#25552;&#20379;&#24314;&#35758;&#26469;&#35299;&#20915;&#36825;&#20123;&#32570;&#38519;&#65307;(b)&#20026;&#27492;&#20219;&#21153;&#21019;&#24314;&#19968;&#20010;&#35268;&#27169;&#21487;&#35266;&#19988;&#32463;&#36807;&#20154;&#24037;&#39564;&#35777;&#30340;&#25968;&#25454;&#38598;&#65307;(c)&#20351;&#29992;&#36825;&#20123;&#25968;&#25454;&#35757;&#32451;&#19968;&#20010;&#24320;&#28304;&#30340;&#33258;&#21160;&#25209;&#35780;&#27169;&#22411;&#65288;&#31216;&#20026;&#25968;&#23383;&#33487;&#26684;&#25289;&#24213;&#65289;&#12290;&#36890;&#36807;&#23450;&#37327;&#21644;&#23450;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25968;&#23383;&#33487;&#26684;&#25289;&#24213;&#22914;&#20309;&#26377;&#21161;&#20110;&#36890;&#36807;&#26816;&#26597;&#20854;&#29702;&#30001;&#26469;&#25581;&#31034;&#26377;&#20851;&#23398;&#29983;&#27169;&#22411;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09613v2 Announce Type: replace-cross  Abstract: While LLMs can provide reasoned explanations along with their answers, the nature and quality of those explanations are still poorly understood. In response, our goal is to define a detailed way of characterizing the explanation capabilities of modern models and to create a nuanced, interpretable explanation evaluation tool that can generate such characterizations automatically, without relying on expensive API calls or human annotations. Our approach is to (a) define the new task of explanation critiquing - identifying and categorizing any main flaw in an explanation and providing suggestions to address the flaw, (b) create a sizeable, human-verified dataset for this task, and (c) train an open-source, automatic critique model (called Digital Socrates) using this data. Through quantitative and qualitative analysis, we demonstrate how Digital Socrates is useful for revealing insights about student models by examining their reas
&lt;/p&gt;</description></item><item><title>MambaByte&#26159;&#19968;&#31181;&#26080;&#26631;&#35760;&#30340;&#36873;&#25321;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#23383;&#33410;&#32423;&#21035;&#19978;&#36827;&#34892;&#33258;&#22238;&#24402;&#35757;&#32451;&#65292;&#35299;&#20915;&#20102;&#26631;&#20934;&#33258;&#22238;&#24402;Transformer&#22312;&#22788;&#29702;&#38271;&#24207;&#21015;&#26102;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#23637;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#23376;&#35789;Transformer&#30456;&#23218;&#32654;&#29978;&#33267;&#26356;&#20248;&#30340;&#24615;&#33021;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;MambaByte&#22312;&#26080;&#26631;&#35760;&#35821;&#35328;&#24314;&#27169;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.13660</link><description>&lt;p&gt;
MambaByte: &#26080;&#26631;&#35760;&#36873;&#25321;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
MambaByte: Token-free Selective State Space Model. (arXiv:2401.13660v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13660
&lt;/p&gt;
&lt;p&gt;
MambaByte&#26159;&#19968;&#31181;&#26080;&#26631;&#35760;&#30340;&#36873;&#25321;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#23383;&#33410;&#32423;&#21035;&#19978;&#36827;&#34892;&#33258;&#22238;&#24402;&#35757;&#32451;&#65292;&#35299;&#20915;&#20102;&#26631;&#20934;&#33258;&#22238;&#24402;Transformer&#22312;&#22788;&#29702;&#38271;&#24207;&#21015;&#26102;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#23637;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#23376;&#35789;Transformer&#30456;&#23218;&#32654;&#29978;&#33267;&#26356;&#20248;&#30340;&#24615;&#33021;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;MambaByte&#22312;&#26080;&#26631;&#35760;&#35821;&#35328;&#24314;&#27169;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#26631;&#35760;&#35821;&#35328;&#27169;&#22411;&#30452;&#25509;&#20174;&#21407;&#22987;&#23383;&#33410;&#23398;&#20064;&#65292;&#28040;&#38500;&#20102;&#23376;&#35789;&#26631;&#35760;&#21270;&#30340;&#20559;&#24046;&#12290;&#28982;&#32780;&#65292;&#25805;&#20316;&#23383;&#33410;&#20250;&#23548;&#33268;&#24207;&#21015;&#38271;&#24230;&#26174;&#33879;&#22686;&#21152;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#33258;&#22238;&#24402;Transformer&#30340;&#25193;&#23637;&#24615;&#36739;&#24046;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;MambaByte&#65292;&#23427;&#26159;&#22522;&#20110;&#23383;&#33410;&#24207;&#21015;&#33258;&#22238;&#24402;&#35757;&#32451;&#30340;&#26080;&#26631;&#35760;&#36866;&#24212;Mamba&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20854;&#20182;&#23383;&#33410;&#32423;&#27169;&#22411;&#30456;&#27604;&#65292;MambaByte&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;MambaByte&#22312;&#24615;&#33021;&#19978;&#19982;&#29978;&#33267;&#32988;&#36807;&#26368;&#20808;&#36827;&#30340;&#23376;&#35789;Transformer&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#38271;&#24230;&#30340;&#32447;&#24615;&#25193;&#23637;&#65292;MambaByte&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#33719;&#24471;&#20102;&#24555;&#36895;&#24615;&#33021;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;Transformer&#21017;&#27809;&#26377;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#35777;&#23454;&#20102;MambaByte&#22312;&#23454;&#29616;&#26080;&#26631;&#35760;&#35821;&#35328;&#24314;&#27169;&#26041;&#38754;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Token-free language models learn directly from raw bytes and remove the bias of subword tokenization. Operating on bytes, however, results in significantly longer sequences, and standard autoregressive Transformers scale poorly in such settings. We experiment with MambaByte, a token-free adaptation of the Mamba state space model, trained autoregressively on byte sequences. Our experiments indicate the computational efficiency of MambaByte compared to other byte-level models. We also find MambaByte to be competitive with and even outperform state-of-the-art subword Transformers. Furthermore, owing to linear scaling in length, MambaByte benefits from fast inference compared to Transformers. Our findings establish the viability of MambaByte in enabling token-free language modeling.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;DP-ZO&#65292;&#19968;&#31181;&#36890;&#36807;&#31169;&#26377;&#21270;&#38646;&#38454;&#20248;&#21270;&#26469;&#20445;&#25252;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#25968;&#25454;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.04343</link><description>&lt;p&gt;
&#31169;&#26377;&#38646;&#38454;&#20248;&#21270;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31169;&#26377;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Private Fine-tuning of Large Language Models with Zeroth-order Optimization. (arXiv:2401.04343v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04343
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;DP-ZO&#65292;&#19968;&#31181;&#36890;&#36807;&#31169;&#26377;&#21270;&#38646;&#38454;&#20248;&#21270;&#26469;&#20445;&#25252;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#25968;&#25454;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31169;&#26377;&#25968;&#25454;&#38598;&#19978;&#23545;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#21487;&#33021;&#20250;&#23384;&#22312;&#36829;&#21453;&#38544;&#31169;&#30340;&#39118;&#38505;&#12290;&#24046;&#20998;&#38544;&#31169;&#26159;&#19968;&#31181;&#36890;&#36807;&#24378;&#21046;&#31639;&#27861;&#31283;&#23450;&#24615;&#26469;&#20943;&#36731;&#38544;&#31169;&#39118;&#38505;&#30340;&#26694;&#26550;&#12290;DP-SGD&#21487;&#20197;&#20197;&#20445;&#25252;&#38544;&#31169;&#30340;&#26041;&#24335;&#35757;&#32451;&#20855;&#26377;&#31169;&#26377;&#25968;&#25454;&#30340;&#27169;&#22411;&#65292;&#20294;&#20250;&#24102;&#26469;&#24615;&#33021;&#25439;&#22833;&#21644;&#37325;&#22823;&#24037;&#31243;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;DP-ZO&#65292;&#19968;&#31181;&#36890;&#36807;&#31169;&#26377;&#21270;&#38646;&#38454;&#20248;&#21270;&#26469;&#20445;&#25252;&#35757;&#32451;&#25968;&#25454;&#38544;&#31169;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35774;&#35745;&#30340;&#19968;&#20010;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#25105;&#20204;&#20351;&#29992;&#30340;&#38646;&#38454;&#31639;&#27861;SPSA&#20013;&#30340;&#26799;&#24230;&#26041;&#21521;&#22987;&#32456;&#26159;&#38543;&#26426;&#30340;&#65292;&#32780;&#20165;&#20381;&#36182;&#20110;&#31169;&#26377;&#25968;&#25454;&#30340;&#20449;&#24687;&#26159;&#27493;&#38271;&#65292;&#21363;&#19968;&#20010;&#26631;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21482;&#38656;&#35201;&#23545;&#26631;&#37327;&#27493;&#38271;&#36827;&#34892;&#38544;&#31169;&#22788;&#29702;&#65292;&#36825;&#26159;&#23384;&#20648;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#12290;DP-ZO&#21487;&#20197;&#20351;&#29992;&#25289;&#26222;&#25289;&#26031;&#22122;&#22768;&#25110;&#39640;&#26031;&#22122;&#22768;&#26469;&#23454;&#29616;&#65292;&#22312;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#25552;&#20379;&#20102;&#38544;&#31169;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#24378;&#22823;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning large pretrained models on private datasets may run the risk of violating privacy. Differential privacy is a framework for mitigating privacy risks by enforcing algorithmic stability. DP-SGD enables training models with private data in a privacy-preserving manner, but raises new obstacles in the form of performance loss and significant engineering challenges. We introduce DP-ZO, a new method for fine-tuning large language models that preserves the privacy of training data by privatizing zeroth-order optimization. A key insight into the design of our method is that the direction of the gradient in SPSA, the zeroth-order algorithm we use, is always random and the only information that depends on private data is the step size, i.e., a scalar. Therefore, we only need to privatize the scalar step size, which is memory-efficient. DP-ZO, which can be instantiated with either Laplace or Gaussian noise, provides a strong privacy-utility trade-off across different tasks, and model si
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;15&#20010;&#19981;&#21516;&#22823;&#23567;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21457;&#29616;&#23427;&#20204;&#20316;&#20026;&#35780;&#20272;&#22120;&#23384;&#22312;&#35748;&#30693;&#20559;&#24046;&#65292;&#23588;&#20854;&#22312;&#25991;&#26412;&#36136;&#37327;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#36739;&#24378;&#30340;&#20559;&#35265;&#65292;&#36825;&#23545;&#20854;&#40065;&#26834;&#24615;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#20102;&#20154;&#31867;&#21644;&#26426;&#22120;&#20559;&#22909;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.17012</link><description>&lt;p&gt;
&#20316;&#20026;&#35780;&#20272;&#22120;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#35748;&#30693;&#20559;&#24046;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Cognitive Biases in Large Language Models as Evaluators. (arXiv:2309.17012v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;15&#20010;&#19981;&#21516;&#22823;&#23567;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21457;&#29616;&#23427;&#20204;&#20316;&#20026;&#35780;&#20272;&#22120;&#23384;&#22312;&#35748;&#30693;&#20559;&#24046;&#65292;&#23588;&#20854;&#22312;&#25991;&#26412;&#36136;&#37327;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#36739;&#24378;&#30340;&#20559;&#35265;&#65292;&#36825;&#23545;&#20854;&#40065;&#26834;&#24615;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#20102;&#20154;&#31867;&#21644;&#26426;&#22120;&#20559;&#22909;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#31616;&#21333;&#30340;&#25552;&#31034;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#20316;&#20026;&#33258;&#21160;&#35780;&#20272;&#22120;&#38750;&#24120;&#26377;&#25928;&#12290;&#26412;&#30740;&#31350;&#32452;&#35013;&#20102;15&#20010;&#22823;&#23567;&#19981;&#21516;&#30340;LLMs&#65292;&#24182;&#36890;&#36807;&#20854;&#20182;LLMs&#30340;&#20559;&#22909;&#25490;&#21517;&#26469;&#35780;&#20272;&#23427;&#20204;&#30340;&#36755;&#20986;&#21709;&#24212;&#65292;&#20363;&#22914;System Star&#27604;System Square&#26356;&#22909;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#29992;&#20110;&#35780;&#20272;LLMs&#36755;&#20986;&#20013;&#20845;&#31181;&#19981;&#21516;&#35748;&#30693;&#20559;&#24046;&#30340;&#35748;&#30693;&#20559;&#24046;&#22522;&#20934;&#27979;&#35797;&#65288;CoBBLEr&#65289;&#65292;&#22914;&#33258;&#25105;&#20013;&#24515;&#20559;&#24046;&#65292;&#21363;&#27169;&#22411;&#26356;&#21916;&#27426;&#23558;&#33258;&#24049;&#30340;&#36755;&#20986;&#22312;&#35780;&#20272;&#20013;&#25490;&#21517;&#36739;&#39640;&#12290;&#25105;&#20204;&#21457;&#29616;LLMs&#26159;&#26377;&#20559;&#35265;&#30340;&#25991;&#26412;&#36136;&#37327;&#35780;&#20272;&#22120;&#65292;&#22312;&#27599;&#20010;&#35780;&#20272;&#20013;&#37117;&#34920;&#29616;&#20986;&#23545;&#25105;&#20204;&#20559;&#35265;&#22522;&#20934;&#30340;&#24378;&#28872;&#36857;&#35937;&#65288;&#22312;&#25152;&#26377;&#27169;&#22411;&#19978;&#30340;&#24179;&#22343;&#27604;&#36739;&#32422;&#20026;40%&#65289;&#65292;&#36825;&#23545;&#23427;&#20204;&#20316;&#20026;&#35780;&#20272;&#22120;&#30340;&#40065;&#26834;&#24615;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#20154;&#31867;&#21644;&#26426;&#22120;&#20559;&#22909;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#35745;&#31639;&#20102;&#24179;&#22343;&#30340;Rank-Biased O&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have recently been shown to be effective as automatic evaluators with simple prompting and in-context learning. In this work, we assemble 15 LLMs of four different size ranges and evaluate their output responses by preference ranking from the other LLMs as evaluators, such as System Star is better than System Square. We then evaluate the quality of ranking outputs introducing the Cognitive Bias Benchmark for LLMs as Evaluators (CoBBLEr), a benchmark to measure six different cognitive biases in LLM evaluation outputs, such as the Egocentric bias where a model prefers to rank its own outputs highly in evaluation. We find that LLMs are biased text quality evaluators, exhibiting strong indications on our bias benchmark (average of 40% of comparisons across all models) within each of their evaluations that question their robustness as evaluators. Furthermore, we examine the correlation between human and machine preferences and calculate the average Rank-Biased O
&lt;/p&gt;</description></item><item><title>BiomedGPT&#26159;&#19968;&#31181;&#38754;&#21521;&#35270;&#35273;&#12289;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#20219;&#21153;&#30340;&#36890;&#29992;&#29983;&#29289;&#21307;&#23398;&#29983;&#25104;&#39044;&#35757;&#32451;Transformer&#65292;&#22312;&#22810;&#20010;&#20020;&#24202;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;16&#20010;&#26368;&#26032;&#30340;&#26368;&#20248;&#32467;&#26524;&#65292;&#21253;&#25324;&#36229;&#36807;&#20102;OpenAI&#30340;GPT-4V&#21644;Google&#30340;Med-PaLM M&#65288;12B&#65289;&#12290;&#21516;&#26102;&#65292;BiomedGPT&#36824;&#25903;&#25345;&#38646;-shot&#36801;&#31227;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2305.17100</link><description>&lt;p&gt;
BiomedGPT&#65306;&#19968;&#31181;&#38754;&#21521;&#35270;&#35273;&#12289;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#20219;&#21153;&#30340;&#32479;&#19968;&#19988;&#36890;&#29992;&#30340;&#29983;&#29289;&#21307;&#23398;&#29983;&#25104;&#39044;&#35757;&#32451;Transformer
&lt;/p&gt;
&lt;p&gt;
BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks. (arXiv:2305.17100v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17100
&lt;/p&gt;
&lt;p&gt;
BiomedGPT&#26159;&#19968;&#31181;&#38754;&#21521;&#35270;&#35273;&#12289;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#20219;&#21153;&#30340;&#36890;&#29992;&#29983;&#29289;&#21307;&#23398;&#29983;&#25104;&#39044;&#35757;&#32451;Transformer&#65292;&#22312;&#22810;&#20010;&#20020;&#24202;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;16&#20010;&#26368;&#26032;&#30340;&#26368;&#20248;&#32467;&#26524;&#65292;&#21253;&#25324;&#36229;&#36807;&#20102;OpenAI&#30340;GPT-4V&#21644;Google&#30340;Med-PaLM M&#65288;12B&#65289;&#12290;&#21516;&#26102;&#65292;BiomedGPT&#36824;&#25903;&#25345;&#38646;-shot&#36801;&#31227;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#20219;&#21153;&#21644;&#27169;&#24577;&#29305;&#23450;&#30340;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#30340;&#23454;&#38469;&#24212;&#29992;&#21644;&#32500;&#25252;&#20013;&#19981;&#22815;&#28789;&#27963;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#30340;&#19981;&#26029;&#22686;&#21152;&#65292;&#32467;&#21512;&#29616;&#20195;&#22810;&#27169;&#24577;&#22810;&#20219;&#21153;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#20026;&#36890;&#29992;&#30340;&#29983;&#29289;&#21307;&#23398;&#20154;&#24037;&#26234;&#33021;&#35299;&#20915;&#26041;&#26696;&#30340;&#20986;&#29616;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#26377;&#28508;&#21147;&#35299;&#37322;&#19981;&#21516;&#30340;&#21307;&#30103;&#27169;&#24577;&#65292;&#24182;&#20135;&#29983;&#22914;&#33258;&#30001;&#25991;&#26412;&#25253;&#21578;&#25110;&#30142;&#30149;&#35786;&#26029;&#31561;&#34920;&#36798;&#24615;&#36755;&#20986;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;BiomedGPT&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#38754;&#21521;&#22810;&#26679;&#21270;&#29983;&#29289;&#21307;&#23398;&#20219;&#21153;&#30340;&#24320;&#28304;&#36890;&#29992;&#35270;&#35273;&#35821;&#35328;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#12290;BiomedGPT&#22312;26&#20010;&#25968;&#25454;&#38598;&#30340;&#20116;&#20010;&#20020;&#24202;&#37325;&#35201;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;16&#20010;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#25918;&#23556;&#23398;&#20154;&#21592;&#35780;&#20272;&#20013;&#65292;&#23427;&#36229;&#36234;&#20102;OpenAI&#30340;GPT-4 with vision&#65288;GPT-4V&#65289;&#65292;&#24182;&#22312;&#20083;&#33146;&#30284;&#35786;&#26029;&#21644;&#21307;&#23398;&#35270;&#35273;&#38382;&#39064;&#22238;&#31572;&#26041;&#38754;&#36229;&#36807;&#20102;Google&#30340;Med-PaLM M&#65288;12B&#65289;&#12290;&#27492;&#22806;&#65292;BiomedGPT&#36824;&#25903;&#25345;&#38646;-shot&#36801;&#31227;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conventional task- and modality-specific artificial intelligence (AI) models are inflexible in real-world deployment and maintenance for biomedicine. At the same time, the growing availability of biomedical data, coupled with the advancements in modern multi-modal multi-task AI techniques, has paved the way for the emergence of generalist biomedical AI solutions. These solutions hold the potential to interpret different medical modalities and produce expressive outputs such as free-text reports or disease diagnosis. Here, we propose BiomedGPT, the first open-source and generalist visual language AI for diverse biomedical tasks. BiomedGPT achieved 16 state-of-the-art results across five clinically significant tasks on 26 datasets. Notably, it outperformed OpenAI's GPT-4 with vision (GPT-4V) in radiology human evaluation and surpassed Google's Med-PaLM M (12B) in breast cancer diagnosis and medical visual question answering. Moreover, BiomedGPT facilitates zero-shot transfer learning, gr
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;SparseFit&#65292;&#19968;&#31181;&#23569;&#26679;&#26412;&#21050;&#28608;&#30340;&#31232;&#30095;&#24494;&#35843;&#31574;&#30053;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#39044;&#27979;&#21644;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#21482;&#26377;&#23569;&#37327;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#21487;&#29992;&#26102;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2305.13235</link><description>&lt;p&gt;
SPARSEFIT&#65306;&#23569;&#26679;&#26412;&#21050;&#28608;&#30340;&#31232;&#30095;&#24494;&#35843;&#65292;&#32852;&#21512;&#29983;&#25104;&#39044;&#27979;&#21644;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations. (arXiv:2305.13235v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13235
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;SparseFit&#65292;&#19968;&#31181;&#23569;&#26679;&#26412;&#21050;&#28608;&#30340;&#31232;&#30095;&#24494;&#35843;&#31574;&#30053;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#39044;&#27979;&#21644;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#21482;&#26377;&#23569;&#37327;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#21487;&#29992;&#26102;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#31070;&#32463;&#27169;&#22411;&#30340;&#20915;&#31574;&#23545;&#20110;&#30830;&#20445;&#36825;&#20123;&#27169;&#22411;&#22312;&#37096;&#32626;&#26102;&#30340;&#21487;&#20449;&#24230;&#24456;&#20851;&#38190;&#12290;&#26368;&#36817;&#65292;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#26469;&#35777;&#26126;&#27169;&#22411;&#30340;&#39044;&#27979;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#32534;&#20889;&#30340;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#20316;&#20026;&#30495;&#23454;&#31572;&#26696;&#30340;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#26082;&#26114;&#36149;&#21448;&#21487;&#33021;&#23545;&#20110;&#26576;&#20123;&#24212;&#29992;&#31243;&#24207;&#26469;&#35828;&#19981;&#21487;&#34892;&#12290;&#20026;&#20102;&#20351;&#27169;&#22411;&#22312;&#21482;&#26377;&#23569;&#37327;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#21487;&#29992;&#26102;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#65292;&#26368;&#36817;&#25552;&#20986;&#20102;&#22522;&#20110;&#21050;&#28608;&#23398;&#20064;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36890;&#24120;&#20855;&#26377;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#65292;&#20351;&#24471;&#24494;&#35843;&#21313;&#20998;&#26114;&#36149;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SparseFit&#65292;&#19968;&#31181;&#31232;&#30095;&#30340;&#23569;&#26679;&#26412;&#24494;&#35843;&#31574;&#30053;&#65292;&#21033;&#29992;&#31163;&#25955;&#21050;&#28608;&#26469;&#32852;&#21512;&#29983;&#25104;&#39044;&#27979;&#21644;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#12290;&#25105;&#20204;&#22312;T5&#27169;&#22411;&#21644;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;SparseFit&#65292;&#24182;&#23558;&#20854;&#19982;&#29616;&#26377;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#33258;&#21160;&#21644;&#20154;&#24037;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explaining the decisions of neural models is crucial for ensuring their trustworthiness at deployment time. Using Natural Language Explanations (NLEs) to justify a model's predictions has recently gained increasing interest. However, this approach usually demands large datasets of human-written NLEs for the ground-truth answers, which are expensive and potentially infeasible for some applications. For models to generate high-quality NLEs when only a few NLEs are available, the fine-tuning of Pre-trained Language Models (PLMs) in conjunction with prompt-based learning recently emerged. However, PLMs typically have billions of parameters, making fine-tuning expensive. We propose SparseFit, a sparse few-shot fine-tuning strategy that leverages discrete prompts to jointly generate predictions and NLEs. We experiment with SparseFit on the T5 model and four datasets and compare it against state-of-the-art parameter-efficient fine-tuning techniques. We perform automatic and human evaluations 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;FLAIR&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19968;&#20010;&#38382;&#39064;&#21644;&#22238;&#31572;&#26469;&#26816;&#27979;ChatGPT&#20013;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#30495;&#23454;&#24615;&#65292;&#21487;&#20197;&#20998;&#31867;&#20154;&#21644;&#26426;&#22120;&#20154;&#12290;&#21333;&#38382;&#39064;&#20998;&#20026;&#23545;&#20110;&#20154;&#31867;&#32780;&#35328;&#23481;&#26131;&#20294;&#23545;&#20110;&#26426;&#22120;&#20154;&#24456;&#38590;&#21644;&#23545;&#20110;&#26426;&#22120;&#20154;&#32780;&#35328;&#23481;&#26131;&#20294;&#23545;&#20110;&#20154;&#31867;&#24456;&#38590;&#20004;&#20010;&#31867;&#21035;&#65292;&#20998;&#21035;&#36827;&#34892;&#26816;&#27979;&#12290; &#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06424</link><description>&lt;p&gt;
&#26426;&#22120;&#20154;&#36824;&#26159;&#20154;&#31867;&#65311;&#29992;&#19968;&#20010;&#38382;&#39064;&#26816;&#27979;ChatGPT&#20882;&#21517;&#39030;&#26367;&#32773;
&lt;/p&gt;
&lt;p&gt;
Bot or Human? Detecting ChatGPT Imposters with A Single Question. (arXiv:2305.06424v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;FLAIR&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19968;&#20010;&#38382;&#39064;&#21644;&#22238;&#31572;&#26469;&#26816;&#27979;ChatGPT&#20013;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#30495;&#23454;&#24615;&#65292;&#21487;&#20197;&#20998;&#31867;&#20154;&#21644;&#26426;&#22120;&#20154;&#12290;&#21333;&#38382;&#39064;&#20998;&#20026;&#23545;&#20110;&#20154;&#31867;&#32780;&#35328;&#23481;&#26131;&#20294;&#23545;&#20110;&#26426;&#22120;&#20154;&#24456;&#38590;&#21644;&#23545;&#20110;&#26426;&#22120;&#20154;&#32780;&#35328;&#23481;&#26131;&#20294;&#23545;&#20110;&#20154;&#31867;&#24456;&#38590;&#20004;&#20010;&#31867;&#21035;&#65292;&#20998;&#21035;&#36827;&#34892;&#26816;&#27979;&#12290; &#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;ChatGPT&#26368;&#36817;&#23637;&#31034;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#20351;&#24471;&#32763;&#35793;&#12289;&#20889;&#20316;&#21644;&#38386;&#32842;&#31561;&#21508;&#31181;&#24212;&#29992;&#25104;&#20026;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#20154;&#20204;&#25285;&#24515;&#23427;&#20204;&#21487;&#33021;&#34987;&#28389;&#29992;&#20110;&#27450;&#35784;&#25110;&#25298;&#32477;&#26381;&#21153;&#25915;&#20987;&#31561;&#24694;&#24847;&#29992;&#36884;&#12290;&#22240;&#27492;&#65292;&#24320;&#21457;&#26816;&#27979;&#32842;&#22825;&#20013;&#28041;&#21450;&#30340;&#21478;&#19968;&#26041;&#26159;&#26426;&#22120;&#20154;&#36824;&#26159;&#20154;&#31867;&#30340;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;FLAIR&#30340;&#26694;&#26550;&#65292;&#21363;&#36890;&#36807;&#21333;&#20010;&#38382;&#39064;&#21644;&#22238;&#31572;&#26469;&#26597;&#25214;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#24615;&#65292;&#20197;&#22312;&#32447;&#26041;&#24335;&#26816;&#27979;&#20250;&#35805;&#20013;&#30340;&#23545;&#35805;&#26426;&#22120;&#20154;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#38024;&#23545;&#19968;&#20010;&#21333;&#19968;&#38382;&#39064;&#22330;&#26223;&#65292;&#35813;&#22330;&#26223;&#21487;&#20197;&#26377;&#25928;&#22320;&#21306;&#20998;&#20154;&#31867;&#29992;&#25143;&#21644;&#26426;&#22120;&#20154;&#12290;&#36825;&#20123;&#38382;&#39064;&#20998;&#20026;&#20004;&#31867;&#65306;&#23545;&#20110;&#20154;&#31867;&#32780;&#35328;&#23481;&#26131;&#20294;&#23545;&#20110;&#26426;&#22120;&#20154;&#24456;&#38590;&#65288;&#20363;&#22914;&#35745;&#25968;&#12289;&#26367;&#25442;&#12289;&#23450;&#20301;&#12289;&#22122;&#38899;&#36807;&#28388;&#21644;ASCII&#33402;&#26415;&#65289;&#65292;&#20197;&#21450;&#23545;&#20110;&#26426;&#22120;&#20154;&#32780;&#35328;&#23481;&#26131;&#20294;&#23545;&#20110;&#20154;&#31867;&#24456;&#38590;&#65288;&#20363;&#22914;&#26426;&#22120;&#29983;&#25104;&#25991;&#26412;&#35782;&#21035;&#65289;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;FLAIR&#65292;&#24182;&#22312;&#26426;&#22120;&#20154;&#26816;&#27979;&#26041;&#38754;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models like ChatGPT have recently demonstrated impressive capabilities in natural language understanding and generation, enabling various applications including translation, essay writing, and chit-chatting. However, there is a concern that they can be misused for malicious purposes, such as fraud or denial-of-service attacks. Therefore, it is crucial to develop methods for detecting whether the party involved in a conversation is a bot or a human. In this paper, we propose a framework named FLAIR, Finding Large language model Authenticity via a single Inquiry and Response, to detect conversational bots in an online manner. Specifically, we target a single question scenario that can effectively differentiate human users from bots. The questions are divided into two categories: those that are easy for humans but difficult for bots (e.g., counting, substitution, positioning, noise filtering, and ASCII art), and those that are easy for bots but difficult for humans (e.g., m
&lt;/p&gt;</description></item><item><title>REMEDI&#26159;&#19968;&#31181;&#23558;&#33258;&#28982;&#35821;&#35328;&#35821;&#21477;&#26144;&#23556;&#21040;LM&#20869;&#37096;&#34920;&#31034;&#31995;&#32479;&#20013;&#30340;&#20107;&#23454;&#32534;&#30721;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290; REMEDI&#32534;&#30721;&#21487;&#29992;&#20316;&#30693;&#35782;&#32534;&#36753;&#22120;&#65292;&#20063;&#21487;&#20197;&#29992;&#20316;&#25506;&#38024;&#65292;&#25581;&#31034;&#20102;LM&#24050;&#32463;&#23558;&#21738;&#20123;&#23646;&#24615;&#24402;&#22240;&#20110;&#25552;&#21040;&#30340;&#23454;&#20307;&#65292;&#24182;&#21487;&#20197;&#39044;&#27979;LM&#20250;&#29983;&#25104;&#36755;&#20986;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.00740</link><description>&lt;p&gt;
&#26816;&#26597;&#21644;&#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#30693;&#35782;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Inspecting and Editing Knowledge Representations in Language Models. (arXiv:2304.00740v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00740
&lt;/p&gt;
&lt;p&gt;
REMEDI&#26159;&#19968;&#31181;&#23558;&#33258;&#28982;&#35821;&#35328;&#35821;&#21477;&#26144;&#23556;&#21040;LM&#20869;&#37096;&#34920;&#31034;&#31995;&#32479;&#20013;&#30340;&#20107;&#23454;&#32534;&#30721;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290; REMEDI&#32534;&#30721;&#21487;&#29992;&#20316;&#30693;&#35782;&#32534;&#36753;&#22120;&#65292;&#20063;&#21487;&#20197;&#29992;&#20316;&#25506;&#38024;&#65292;&#25581;&#31034;&#20102;LM&#24050;&#32463;&#23558;&#21738;&#20123;&#23646;&#24615;&#24402;&#22240;&#20110;&#25552;&#21040;&#30340;&#23454;&#20307;&#65292;&#24182;&#21487;&#20197;&#39044;&#27979;LM&#20250;&#29983;&#25104;&#36755;&#20986;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#34920;&#31034;&#26377;&#20851;&#25991;&#26412;&#25152;&#25551;&#36848;&#19990;&#30028;&#30340;&#20107;&#23454;&#12290;&#26377;&#26102;&#36825;&#20123;&#20107;&#23454;&#26469;&#33258;&#35757;&#32451;&#25968;&#25454;&#65288;&#22312;&#22823;&#22810;&#25968;LMs&#20013;&#65292;&#8220;&#39321;&#34121;&#8221;&#19968;&#35789;&#30340;&#34920;&#31034;&#34920;&#31034;&#39321;&#34121;&#26159;&#27700;&#26524;&#30340;&#20107;&#23454;&#65289;&#12290;&#26377;&#26102;&#20107;&#23454;&#26469;&#33258;&#36755;&#20837;&#25991;&#26412;&#26412;&#36523;&#65288;&#8220;&#25105;&#20498;&#20986;&#20102;&#29942;&#23376;&#8221;&#36825;&#20010;&#21477;&#23376;&#30340;&#34920;&#31034;&#34920;&#31034;&#29942;&#23376;&#21464;&#31354;&#20102;&#30340;&#20107;&#23454;&#65289;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;REMEDI&#65292;&#19968;&#31181;&#23398;&#20064;&#23558;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#35821;&#21477;&#26144;&#23556;&#21040;LM&#30340;&#20869;&#37096;&#34920;&#31034;&#31995;&#32479;&#20013;&#30340;&#20107;&#23454;&#32534;&#30721;&#30340;&#26041;&#27861;&#12290; REMEDI&#32534;&#30721;&#21487;&#29992;&#20316;&#30693;&#35782;&#32534;&#36753;&#22120;&#65306;&#24403;&#28155;&#21152;&#21040;LM&#38544;&#34255;&#34920;&#31034;&#26102;&#65292;&#23427;&#20204;&#20250;&#20462;&#25913;&#19979;&#28216;&#29983;&#25104;&#65292;&#20351;&#20854;&#19982;&#26032;&#20107;&#23454;&#19968;&#33268;&#12290; REMEDI&#32534;&#30721;&#20063;&#21487;&#20197;&#29992;&#20316;&#25506;&#38024;&#65306;&#19982;LM&#34920;&#31034;&#36827;&#34892;&#27604;&#36739;&#26102;&#65292;&#23427;&#20204;&#25581;&#31034;&#20102;LM&#24050;&#32463;&#23558;&#21738;&#20123;&#23646;&#24615;&#24402;&#22240;&#20110;&#25552;&#21040;&#30340;&#23454;&#20307;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#36825;&#20351;&#24471;&#21487;&#20197;&#39044;&#27979;LM&#23558;&#29983;&#25104;&#19982;&#32972;&#26223;&#30693;&#35782;&#25110;&#36755;&#20837;&#25991;&#26412;&#20914;&#31361;&#30340;&#36755;&#20986;&#26102;&#12290;&#22240;&#27492;&#65292;REMEDI&#38142;&#25509;&#20102;&#26377;&#20851;&#25506;&#27979;&#65292;PR
&lt;/p&gt;
&lt;p&gt;
Neural language models (LMs) represent facts about the world described by text. Sometimes these facts derive from training data (in most LMs, a representation of the word "banana" encodes the fact that bananas are fruits). Sometimes facts derive from input text itself (a representation of the sentence "I poured out the bottle" encodes the fact that the bottle became empty). We describe REMEDI, a method for learning to map statements in natural language to fact encodings in an LM's internal representation system. REMEDI encodings can be used as knowledge editors: when added to LM hidden representations, they modify downstream generation to be consistent with new facts. REMEDI encodings may also be used as probes: when compared to LM representations, they reveal which properties LMs already attribute to mentioned entities, in some cases making it possible to predict when LMs will generate outputs that conflict with background knowledge or input text. REMEDI thus links work on probing, pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102; ChatGPT &#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126; ChatGPT &#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#65292;&#24182;&#19988;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#12290;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2304.00228</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models can rate news outlet credibility. (arXiv:2304.00228v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102; ChatGPT &#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126; ChatGPT &#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#65292;&#24182;&#19988;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#12290;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#20135;&#29983;&#24187;&#35937;&#12290;&#29616;&#20195;&#26368;&#20808;&#36827;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#22914;&#26032;&#30340; Bing&#65292;&#23581;&#35797;&#36890;&#36807;&#30452;&#25509;&#20174;&#20114;&#32852;&#32593;&#25910;&#38598;&#20449;&#24687;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21306;&#20998;&#20540;&#24471;&#20449;&#36182;&#30340;&#20449;&#24687;&#28304;&#23545;&#20110;&#21521;&#29992;&#25143;&#25552;&#20379;&#36866;&#24403;&#30340;&#20934;&#30830;&#24615;&#32972;&#26223;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#30693;&#21517;&#30340;LLM ChatGPT&#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#12290;&#22312;&#36866;&#24403;&#30340;&#25351;&#23548;&#19979;&#65292;ChatGPT&#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#65288;Spearmam's $\rho=0.54, p&lt;0.001$&#65289;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#65292;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;&#26410;&#26469;&#30340;LLMs&#24212;&#22686;&#24378;&#23427;&#20204;&#30340;&#23545;&#40784;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although large language models (LLMs) have shown exceptional performance in various natural language processing tasks, they are prone to hallucinations. State-of-the-art chatbots, such as the new Bing, attempt to mitigate this issue by gathering information directly from the internet to ground their answers. In this setting, the capacity to distinguish trustworthy sources is critical for providing appropriate accuracy contexts to users. Here we assess whether ChatGPT, a prominent LLM, can evaluate the credibility of news outlets. With appropriate instructions, ChatGPT can provide ratings for a diverse set of news outlets, including those in non-English languages and satirical sources, along with contextual explanations. Our results show that these ratings correlate with those from human experts (Spearmam's $\rho=0.54, p&lt;0.001$). These findings suggest that LLMs could be an affordable reference for credibility ratings in fact-checking applications. Future LLMs should enhance their align
&lt;/p&gt;</description></item><item><title>PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.06674</link><description>&lt;p&gt;
PK-ICR: &#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#36827;&#34892;&#22522;&#20110;&#22330;&#26223;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue. (arXiv:2302.06674v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06674
&lt;/p&gt;
&lt;p&gt;
PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#21035;&#19982;&#23545;&#35805;&#31995;&#32479;&#30456;&#20851;&#30340;&#35282;&#33394;&#21644;&#30693;&#35782;&#23545;&#20110;&#22522;&#20110;&#22330;&#26223;&#30340;&#23545;&#35805;&#24212;&#31572;&#29983;&#25104;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27599;&#20010;&#23545;&#35805;&#22522;&#26412;&#19978;&#37117;&#26159;&#23396;&#31435;&#30740;&#31350;&#30340;&#65292;&#32780;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#24341;&#20837;&#20102;&#26356;&#23454;&#38469;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20219;&#21153;&#12290;&#25105;&#20204;&#23558;&#35282;&#33394;&#21644;&#30693;&#35782;&#21452;&#19978;&#19979;&#25991;&#35782;&#21035;&#23450;&#20041;&#20026;&#20026;&#32473;&#23450;&#30340;&#23545;&#35805;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20219;&#21153;&#65292;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#35774;&#32622;&#20013;&#21487;&#33021;&#20855;&#26377;&#25552;&#21319;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26816;&#32034;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#21033;&#29992;&#23545;&#35805;&#30340;&#25152;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#34913;&#37327;&#19982;&#25968;&#25454;&#22686;&#24378;&#30456;&#20851;&#30340;&#35821;&#20041;&#24046;&#24322;&#26679;&#26412;&#65288;&#21363;&#22256;&#38590;&#36127;&#26679;&#26412;&#65289;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying relevant persona or knowledge for conversational systems is critical to grounded dialogue response generation. However, each grounding has been mostly researched in isolation with more practical multi-context dialogue tasks introduced in recent works. We define Persona and Knowledge Dual Context Identification as the task to identify persona and knowledge jointly for a given dialogue, which could be of elevated importance in complex multi-context dialogue settings. We develop a novel grounding retrieval method that utilizes all contexts of dialogue simultaneously. Our method requires less computational power via utilizing neural QA retrieval models. We further introduce our novel null-positive rank test which measures ranking performance on semantically dissimilar samples (i.e. hard negatives) in relation to data augmentation.
&lt;/p&gt;</description></item><item><title>ChatGPT&#26159;&#19968;&#31181;&#26032;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#31435;&#22330;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#39044;&#27979;&#30340;&#35299;&#37322;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2212.14548</link><description>&lt;p&gt;
ChatGPT&#21457;&#24067;&#21518;&#65292;&#31435;&#22330;&#26816;&#27979;&#25216;&#26415;&#20250;&#22914;&#20309;&#21457;&#23637;&#65311;
&lt;/p&gt;
&lt;p&gt;
How would Stance Detection Techniques Evolve after the Launch of ChatGPT?. (arXiv:2212.14548v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14548
&lt;/p&gt;
&lt;p&gt;
ChatGPT&#26159;&#19968;&#31181;&#26032;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#31435;&#22330;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#39044;&#27979;&#30340;&#35299;&#37322;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31435;&#22330;&#26816;&#27979;&#26159;&#25351;&#20174;&#32473;&#23450;&#25991;&#26412;&#20013;&#25552;&#21462;&#23545;&#30446;&#26631;&#30340;&#31435;&#22330;&#65288;&#25903;&#25345;&#12289;&#21453;&#23545;&#25110;&#20013;&#31435;&#65289;&#30340;&#20219;&#21153;&#12290;&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#20869;&#23481;&#30340;&#22823;&#37327;&#22686;&#21152;&#65292;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#20256;&#32479;&#30340;&#22788;&#29702;&#31435;&#22330;&#26816;&#27979;&#30340;&#26694;&#26550;&#26159;&#23558;&#20854;&#36716;&#21270;&#20026;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#24050;&#32463;&#21462;&#20195;&#20102;&#22522;&#20110;&#35268;&#21017;&#30340;&#27169;&#22411;&#21644;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#35299;&#20915;&#27492;&#31867;&#38382;&#39064;&#12290;&#30446;&#21069;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65292;&#21363;&#26631;&#35760;&#25968;&#25454;&#21644;&#31038;&#20132;&#23186;&#20307;&#24086;&#23376;&#20013;&#30340;&#20449;&#24687;&#19981;&#36275;&#65292;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#19981;&#21487;&#35299;&#37322;&#24615;&#12290;ChatGPT&#26159;&#19968;&#31181;&#26032;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#20110;2022&#24180;11&#26376;30&#26085;&#21457;&#24067;&#12290;&#38024;&#23545;&#31435;&#22330;&#26816;&#27979;&#20219;&#21153;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;ChatGPT&#21487;&#20197;&#22312;&#24120;&#29992;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;SemEval-2016&#21644;P-Stance&#65289;&#19978;&#23454;&#29616;SOTA&#25110;&#31867;&#20284;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;ChatGPT&#21487;&#20197;&#20026;&#20854;&#33258;&#36523;&#30340;&#39044;&#27979;&#25552;&#20379;&#35299;&#37322;&#65292;&#36825;&#36229;&#20986;&#20102;&#20219;&#20309;&#29616;&#26377;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stance detection refers to the task of extracting the standpoint (Favor, Against or Neither) towards a target in given texts. Such research gains increasing attention with the proliferation of social media contents. The conventional framework of handling stance detection is converting it into text classification tasks. Deep learning models have already replaced rule-based models and traditional machine learning models in solving such problems. Current deep neural networks are facing two main challenges which are insufficient labeled data and information in social media posts and the unexplainable nature of deep learning models. A new pre-trained language model chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our experiments show that ChatGPT can achieve SOTA or similar performance for commonly used datasets including SemEval-2016 and P-Stance. At the same time, ChatGPT can provide explanation for its own prediction, which is beyond the capability of any existing mo
&lt;/p&gt;</description></item></channel></rss>