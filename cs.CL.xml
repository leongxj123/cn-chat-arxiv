<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#20171;&#32461;&#20102;&#33258;&#21160;&#20114;&#21160;&#35780;&#20272;&#65288;AIE&#65289;&#26694;&#26550;&#21644;&#29366;&#24577;&#24863;&#30693;&#30149;&#20154;&#27169;&#25311;&#22120;&#65288;SAPS&#65289;&#65292;&#20197;&#21160;&#24577;&#12289;&#30495;&#23454;&#30340;&#24179;&#21488;&#35780;&#20272;LLMs&#65292;&#24357;&#34917;&#20256;&#32479;&#35780;&#20272;&#26041;&#27861;&#26080;&#27861;&#28385;&#36275;&#20020;&#24202;&#20219;&#21153;&#38656;&#27714;&#30340;&#19981;&#36275;&#12290;</title><link>https://arxiv.org/abs/2403.08495</link><description>&lt;p&gt;
&#20855;&#26377;&#29366;&#24577;&#24863;&#30693;&#30149;&#20154;&#27169;&#25311;&#22120;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#20114;&#21160;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08495
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#33258;&#21160;&#20114;&#21160;&#35780;&#20272;&#65288;AIE&#65289;&#26694;&#26550;&#21644;&#29366;&#24577;&#24863;&#30693;&#30149;&#20154;&#27169;&#25311;&#22120;&#65288;SAPS&#65289;&#65292;&#20197;&#21160;&#24577;&#12289;&#30495;&#23454;&#30340;&#24179;&#21488;&#35780;&#20272;LLMs&#65292;&#24357;&#34917;&#20256;&#32479;&#35780;&#20272;&#26041;&#27861;&#26080;&#27861;&#28385;&#36275;&#20020;&#24202;&#20219;&#21153;&#38656;&#27714;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20154;&#26426;&#20114;&#21160;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#21307;&#30103;&#39046;&#22495;&#30340;&#24212;&#29992;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#33258;&#21160;&#20114;&#21160;&#35780;&#20272;&#65288;AIE&#65289;&#26694;&#26550;&#21644;&#29366;&#24577;&#24863;&#30693;&#30149;&#20154;&#27169;&#25311;&#22120;&#65288;SAPS&#65289;&#65292;&#26088;&#22312;&#24357;&#34917;&#20256;&#32479;LLM&#35780;&#20272;&#19982;&#20020;&#24202;&#23454;&#36341;&#30340;&#24494;&#22937;&#38656;&#27714;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08495v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in human interactions, yet their application within the medical field remains insufficiently explored. Previous works mainly focus on the performance of medical knowledge with examinations, which is far from the realistic scenarios, falling short in assessing the abilities of LLMs on clinical tasks. In the quest to enhance the application of Large Language Models (LLMs) in healthcare, this paper introduces the Automated Interactive Evaluation (AIE) framework and the State-Aware Patient Simulator (SAPS), targeting the gap between traditional LLM evaluations and the nuanced demands of clinical practice. Unlike prior methods that rely on static medical knowledge assessments, AIE and SAPS provide a dynamic, realistic platform for assessing LLMs through multi-turn doctor-patient simulations. This approach offers a closer approximation to real clinical scenarios and allows f
&lt;/p&gt;</description></item><item><title>&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#26681;&#25454;&#36755;&#20837;&#23454;&#20363;&#30340;&#19981;&#21516;&#38590;&#26131;&#31243;&#24230;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AdaInfer&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#20351;&#29992;&#27973;&#23618;&#21644;&#28145;&#23618;&#65292;&#20174;&#32780;&#33410;&#30465;&#20102;&#35745;&#31639;&#36164;&#28304;&#12290;</title><link>https://arxiv.org/abs/2403.02181</link><description>&lt;p&gt;
&#25512;&#29702;&#36807;&#31243;&#20013;&#19981;&#26159;&#25152;&#26377;LLMs&#30340;&#23618;&#37117;&#26159;&#24517;&#35201;&#30340;
&lt;/p&gt;
&lt;p&gt;
Not all Layers of LLMs are Necessary during Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02181
&lt;/p&gt;
&lt;p&gt;
&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#26681;&#25454;&#36755;&#20837;&#23454;&#20363;&#30340;&#19981;&#21516;&#38590;&#26131;&#31243;&#24230;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AdaInfer&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#20351;&#29992;&#27973;&#23618;&#21644;&#28145;&#23618;&#65292;&#20174;&#32780;&#33410;&#30465;&#20102;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#38454;&#27573;&#38750;&#24120;&#26114;&#36149;&#12290;&#29702;&#24819;&#30340;LLMs&#25512;&#29702;&#38454;&#27573;&#21487;&#20197;&#21033;&#29992;&#26356;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#21516;&#26102;&#20173;&#20445;&#25345;&#20854;&#33021;&#21147;&#65288;&#20363;&#22914;&#27867;&#21270;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65289;&#12290;&#26412;&#25991;&#23581;&#35797;&#22238;&#31572;&#19968;&#20010;&#38382;&#39064;&#65306;&#8220;&#22312;LLMs&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#20026;&#31616;&#21333;&#23454;&#20363;&#20351;&#29992;&#27973;&#23618;&#65292;&#24182;&#20026;&#38590;&#20197;&#22788;&#29702;&#30340;&#23454;&#20363;&#20351;&#29992;&#28145;&#23618;&#21527;&#65311;&#8221;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#32479;&#35745;&#20998;&#26512;&#36328;&#20219;&#21153;&#28608;&#27963;&#30340;&#23618;&#26469;&#25351;&#20986;&#24182;&#38750;&#25152;&#26377;&#23618;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#37117;&#26159;&#24517;&#35201;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#21517;&#20026;AdaInfer&#65292;&#26681;&#25454;&#36755;&#20837;&#23454;&#20363;&#33258;&#36866;&#24212;&#22320;&#30830;&#23450;&#25512;&#29702;&#32456;&#27490;&#26102;&#21051;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;AdaInfer&#19981;&#25913;&#21464;LLMs&#21442;&#25968;&#65292;&#24182;&#22312;&#20219;&#21153;&#20043;&#38388;&#20445;&#25345;&#27867;&#21270;&#33021;&#21147;&#12290;&#23545;&#30693;&#21517;LLMs&#65288;&#21363;Llama2&#31995;&#21015;&#21644;OPT&#65289;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;AdaInfer&#33410;&#30465;&#20102;&#24179;&#22343;14.8%&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#29978;&#33267;&#22312;&#24773;&#24863;&#26041;&#38754;&#39640;&#36798;50%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02181v1 Announce Type: cross  Abstract: The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, "During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer saves an average of 14.8% of computational resources, even up to 50% on sentiment 
&lt;/p&gt;</description></item><item><title>&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30701;&#31687;&#23567;&#35828;&#25688;&#35201;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#24544;&#23454;&#24615;&#21644;&#35299;&#37322;&#28508;&#21488;&#35789;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#65292;&#20294;&#22312;&#36827;&#34892;&#20027;&#39064;&#20998;&#26512;&#26102;&#34920;&#29616;&#20986;&#24605;&#32771;&#28145;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.01061</link><description>&lt;p&gt;
&#38405;&#35835;&#28508;&#21488;&#35789;&#65306;&#22312;&#30701;&#31687;&#23567;&#35828;&#25688;&#35201;&#19978;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#20316;&#32773;&#21512;&#20316;
&lt;/p&gt;
&lt;p&gt;
Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01061
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30701;&#31687;&#23567;&#35828;&#25688;&#35201;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#24544;&#23454;&#24615;&#21644;&#35299;&#37322;&#28508;&#21488;&#35789;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#65292;&#20294;&#22312;&#36827;&#34892;&#20027;&#39064;&#20998;&#26512;&#26102;&#34920;&#29616;&#20986;&#24605;&#32771;&#28145;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35780;&#20272;&#20102;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25688;&#35201;&#38271;&#31687;&#25991;&#23398;&#20316;&#21697;&#36825;&#19968;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#65292;&#36825;&#20123;&#20316;&#21697;&#21487;&#33021;&#38271;&#24230;&#36739;&#38271;&#65292;&#24182;&#21253;&#21547;&#24494;&#22937;&#30340;&#28508;&#21488;&#35789;&#25110;&#38169;&#32508;&#22797;&#26434;&#30340;&#26102;&#38388;&#32447;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30452;&#25509;&#19982;&#20316;&#32773;&#21512;&#20316;&#65292;&#30830;&#20445;&#36825;&#20123;&#20316;&#21697;&#23578;&#26410;&#22312;&#32593;&#32476;&#19978;&#20998;&#20139;&#36807;&#65288;&#22240;&#27492;&#23545;&#36825;&#20123;&#27169;&#22411;&#26159;&#26410;&#30693;&#30340;&#65289;&#65292;&#24182;&#33719;&#24471;&#20316;&#32773;&#26412;&#20154;&#23545;&#25688;&#35201;&#36136;&#37327;&#30340;&#26126;&#30830;&#35780;&#20215;&#12290;&#36890;&#36807;&#22522;&#20110;&#21465;&#20107;&#29702;&#35770;&#30340;&#23450;&#37327;&#21644;&#23450;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;GPT-4&#12289;Claude-2.1&#21644;LLama-2-70B&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#19977;&#20010;&#27169;&#22411;&#22312;50%&#20197;&#19978;&#30340;&#25688;&#35201;&#20013;&#20250;&#20986;&#29616;&#24544;&#23454;&#24615;&#38169;&#35823;&#65292;&#24182;&#19988;&#38590;&#20197;&#35299;&#37322;&#38590;&#20197;&#29702;&#35299;&#30340;&#28508;&#21488;&#35789;&#12290;&#28982;&#32780;&#65292;&#22312;&#26368;&#20339;&#29366;&#24577;&#19979;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#23545;&#25925;&#20107;&#36827;&#34892;&#26377;&#28145;&#24230;&#30340;&#20027;&#39064;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;LLMs&#23545;&#25688;&#35201;&#36136;&#37327;&#30340;&#21028;&#26029;&#19982;&#20316;&#23478;&#30340;&#21453;&#39304;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01061v1 Announce Type: new  Abstract: We evaluate recent Large language Models (LLMs) on the challenging task of summarizing short stories, which can be lengthy, and include nuanced subtext or scrambled timelines. Importantly, we work directly with authors to ensure that the stories have not been shared online (and therefore are unseen by the models), and to obtain informed evaluations of summary quality using judgments from the authors themselves. Through quantitative and qualitative analysis grounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We find that all three models make faithfulness mistakes in over 50% of summaries and struggle to interpret difficult subtext. However, at their best, the models can provide thoughtful thematic analysis of stories. We additionally demonstrate that LLM judgments of summary quality do not match the feedback from the writers.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22312;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#19978;&#36827;&#34892;&#26463;&#25628;&#32034;&#30340;&#27010;&#29575;&#20581;&#22766;&#26041;&#27861;&#65292;&#34920;&#26126;&#20854;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.15020</link><description>&lt;p&gt;
&#20855;&#26377;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#29575;&#20581;&#22766;&#26463;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Probabilistically-sound beam search with masked language models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15020
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22312;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#19978;&#36827;&#34892;&#26463;&#25628;&#32034;&#30340;&#27010;&#29575;&#20581;&#22766;&#26041;&#27861;&#65292;&#34920;&#26126;&#20854;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65288;MLMs&#65289;&#30340;&#26463;&#25628;&#32034;&#23384;&#22312;&#25361;&#25112;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#30001;&#20110;&#24207;&#21015;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#19981;&#20687;&#33258;&#22238;&#24402;&#27169;&#22411;&#37027;&#26679;readily available&#12290;&#28982;&#32780;&#65292;&#20272;&#31639;&#36825;&#26679;&#30340;&#20998;&#24067;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#20855;&#26377;&#24212;&#29992;&#65292;&#21253;&#25324;&#34507;&#30333;&#24037;&#31243;&#21644;&#21476;&#20195;&#25991;&#26412;&#24674;&#22797;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#27010;&#29575;&#20581;&#22766;&#24615;&#30340;&#20351;&#29992;MLMs&#36827;&#34892;&#26463;&#25628;&#32034;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#22312;&#21738;&#20123;&#26465;&#20214;&#19979;&#20351;&#29992;&#26631;&#20934;&#26463;&#25628;&#32034;&#23545;MLMs&#25191;&#34892;&#25991;&#26412;&#22635;&#20805;&#22312;&#29702;&#35770;&#19978;&#26159;&#21487;&#38752;&#30340;&#12290;&#24403;&#36825;&#20123;&#26465;&#20214;&#22833;&#36133;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20855;&#26377;&#27010;&#29575;&#20581;&#22766;&#24615;&#30340;&#20462;&#25913;&#65292;&#32780;&#19988;&#26080;&#38656;&#39069;&#22806;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#35777;&#26126;&#22312;&#39044;&#26399;&#26465;&#20214;&#19979;&#23427;&#20248;&#20110;&#21069;&#36848;&#30340;&#26463;&#25628;&#32034;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27604;&#36739;&#22810;&#20010;&#39046;&#22495;&#20013;&#20960;&#31181;&#20351;&#29992;MLMs&#36827;&#34892;&#22635;&#20805;&#30340;&#26041;&#27861;&#30340;&#32463;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15020v1 Announce Type: cross  Abstract: Beam search with masked language models (MLMs) is challenging in part because joint probability distributions over sequences are not readily available, unlike for autoregressive models. Nevertheless, estimating such distributions has applications in many domains, including protein engineering and ancient text restoration. We present probabilistically-sound methods for beam search with MLMs. First, we clarify the conditions under which it is theoretically sound to perform text infilling with MLMs using standard beam search. When these conditions fail, we provide a probabilistically-sound modification with no additional computational complexity and demonstrate that it is superior to the aforementioned beam search in the expected conditions. We then present empirical results comparing several infilling approaches with MLMs across several domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22810;&#39033;&#36873;&#25321;&#39064;&#26102;&#65292;&#22522;&#20110;&#27010;&#29575;&#30340;&#35780;&#20272;&#26041;&#27861;&#19982;&#22522;&#20110;&#29983;&#25104;&#30340;&#39044;&#27979;&#19981;&#30456;&#21563;&#21512;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13887</link><description>&lt;p&gt;
&#36229;&#36234;&#27010;&#29575;&#65306;&#25581;&#31034;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#38169;&#20301;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Beyond Probabilities: Unveiling the Misalignment in Evaluating Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22810;&#39033;&#36873;&#25321;&#39064;&#26102;&#65292;&#22522;&#20110;&#27010;&#29575;&#30340;&#35780;&#20272;&#26041;&#27861;&#19982;&#22522;&#20110;&#29983;&#25104;&#30340;&#39044;&#27979;&#19981;&#30456;&#21563;&#21512;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20174;&#26681;&#26412;&#19978;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30740;&#31350;&#30340;&#26684;&#23616;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#35780;&#20272;&#26694;&#26550;&#36890;&#24120;&#20381;&#36182;&#20110;LLMs&#30340;&#36755;&#20986;&#27010;&#29575;&#36827;&#34892;&#39044;&#27979;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#35745;&#31639;&#32422;&#26463;&#65292;&#20559;&#31163;&#20102;&#30495;&#23454;&#19990;&#30028;&#30340;LLMs&#20351;&#29992;&#22330;&#26223;&#12290;&#34429;&#28982;&#34987;&#24191;&#27867;&#37319;&#29992;&#65292;&#22522;&#20110;&#27010;&#29575;&#30340;&#35780;&#20272;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#20173;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#23457;&#26597;&#36825;&#31181;&#22522;&#20110;&#27010;&#29575;&#30340;&#35780;&#20272;&#26041;&#27861;&#22312;&#20351;&#29992;LLMs&#36827;&#34892;&#22810;&#39033;&#36873;&#25321;&#39064;&#65288;MCQs&#65289;&#26102;&#30340;&#26377;&#25928;&#24615;&#65292;&#31361;&#26174;&#20854;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#35843;&#26597;&#26174;&#31034;&#65292;&#26222;&#36941;&#30340;&#22522;&#20110;&#27010;&#29575;&#30340;&#35780;&#20272;&#26041;&#27861;&#26410;&#33021;&#19982;&#22522;&#20110;&#29983;&#25104;&#30340;&#39044;&#27979;&#30456;&#36866;&#24212;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#30340;&#35780;&#20272;&#26694;&#26550;&#36890;&#24120;&#36890;&#36807;&#22522;&#20110;&#36755;&#20986;&#39044;&#27979;&#30340;&#39044;&#27979;&#20219;&#21153;&#26469;&#35780;&#20272;LLMs
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13887v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various applications, fundamentally reshaping the landscape of natural language processing (NLP) research. However, recent evaluation frameworks often rely on the output probabilities of LLMs for predictions, primarily due to computational constraints, diverging from real-world LLM usage scenarios. While widely employed, the efficacy of these probability-based evaluation strategies remains an open research question. This study aims to scrutinize the validity of such probability-based evaluation methods within the context of using LLMs for Multiple Choice Questions (MCQs), highlighting their inherent limitations. Our empirical investigation reveals that the prevalent probability-based evaluation method inadequately aligns with generation-based prediction. Furthermore, current evaluation frameworks typically assess LLMs through predictive tasks based on output pr
&lt;/p&gt;</description></item><item><title>&#35821;&#20041;&#22522;&#30784;&#32622;&#20110;&#36125;&#21494;&#26031;&#24515;&#28789;&#29702;&#35770;&#20013;&#65292;&#36890;&#36807;&#27169;&#25311;&#20154;&#20204;&#20849;&#21516;&#25512;&#26029;&#20986;&#35299;&#37322;&#20195;&#29702;&#20154;&#34892;&#20026;&#30340;&#19968;&#33268;&#24615;&#30446;&#26631;&#12289;&#20449;&#24565;&#21644;&#35745;&#21010;&#38598;&#21512;&#65292;&#20877;&#36890;&#36807;&#35748;&#35782;&#36923;&#36753;&#35780;&#20272;&#26377;&#20851;&#20195;&#29702;&#20154;&#20449;&#24565;&#30340;&#38472;&#36848;&#65292;&#35299;&#37322;&#20102;&#20154;&#31867;&#20449;&#24565;&#24402;&#22240;&#30340;&#20998;&#32423;&#24615;&#21644;&#32452;&#21512;&#24615;&#65292;&#20197;&#21450;&#20854;&#19982;&#30446;&#26631;&#21644;&#35745;&#21010;&#30340;&#23494;&#20999;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.10416</link><description>&lt;p&gt;
&#23558;&#20851;&#20110;&#20449;&#24565;&#30340;&#35821;&#35328;&#25509;&#22320;&#20110;&#36125;&#21494;&#26031;&#24515;&#28789;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Grounding Language about Belief in a Bayesian Theory-of-Mind
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10416
&lt;/p&gt;
&lt;p&gt;
&#35821;&#20041;&#22522;&#30784;&#32622;&#20110;&#36125;&#21494;&#26031;&#24515;&#28789;&#29702;&#35770;&#20013;&#65292;&#36890;&#36807;&#27169;&#25311;&#20154;&#20204;&#20849;&#21516;&#25512;&#26029;&#20986;&#35299;&#37322;&#20195;&#29702;&#20154;&#34892;&#20026;&#30340;&#19968;&#33268;&#24615;&#30446;&#26631;&#12289;&#20449;&#24565;&#21644;&#35745;&#21010;&#38598;&#21512;&#65292;&#20877;&#36890;&#36807;&#35748;&#35782;&#36923;&#36753;&#35780;&#20272;&#26377;&#20851;&#20195;&#29702;&#20154;&#20449;&#24565;&#30340;&#38472;&#36848;&#65292;&#35299;&#37322;&#20102;&#20154;&#31867;&#20449;&#24565;&#24402;&#22240;&#30340;&#20998;&#32423;&#24615;&#21644;&#32452;&#21512;&#24615;&#65292;&#20197;&#21450;&#20854;&#19982;&#30446;&#26631;&#21644;&#35745;&#21010;&#30340;&#23494;&#20999;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20449;&#24565;&#26159;&#26080;&#27861;&#30452;&#25509;&#35266;&#23519;&#30340;&#24515;&#29702;&#29366;&#24577;&#65292;&#20154;&#31867;&#24120;&#24120;&#20351;&#29992;&#20016;&#23500;&#30340;&#32452;&#21512;&#35821;&#35328;&#26469;&#25551;&#36848;&#20182;&#20154;&#30340;&#24819;&#27861;&#21644;&#30693;&#35782;&#12290;&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#23558;&#20449;&#24565;&#38472;&#36848;&#30340;&#35821;&#20041;&#22522;&#30784;&#32622;&#20110;&#36125;&#21494;&#26031;&#24515;&#28789;&#29702;&#35770;&#20013;&#65292;&#20026;&#35299;&#37322;&#20154;&#31867;&#22914;&#20309;&#35299;&#37322;&#20182;&#20154;&#38544;&#34255;&#30340;&#35748;&#35782;&#20869;&#23481;&#36808;&#20986;&#20102;&#19968;&#27493;&#65306;&#36890;&#36807;&#24314;&#27169;&#20154;&#31867;&#22914;&#20309;&#20849;&#21516;&#25512;&#26029;&#20986;&#35299;&#37322;&#19968;&#20010;&#20195;&#29702;&#20154;&#34892;&#21160;&#30340;&#19968;&#33268;&#24615;&#30446;&#26631;&#12289;&#20449;&#24565;&#21644;&#35745;&#21010;&#38598;&#21512;&#65292;&#28982;&#21518;&#36890;&#36807;&#35748;&#35782;&#36923;&#36753;&#23545;&#26377;&#20851;&#20195;&#29702;&#20154;&#20449;&#24565;&#30340;&#38472;&#36848;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20026;&#20449;&#24565;&#25552;&#20379;&#20102;&#19968;&#20010;&#27010;&#24565;&#35282;&#33394;&#35821;&#20041;&#65292;&#35299;&#37322;&#20102;&#20154;&#31867;&#20449;&#24565;&#24402;&#22240;&#30340;&#20998;&#32423;&#24615;&#21644;&#32452;&#21512;&#24615;&#65292;&#20197;&#21450;&#23427;&#20204;&#19982;&#30446;&#26631;&#21644;&#35745;&#21010;&#30340;&#23494;&#20999;&#32852;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#20154;&#20204;&#22312;&#35266;&#23519;&#19968;&#20010;&#20195;&#29702;&#20154;&#35299;&#20915;&#38382;&#39064;&#26102;&#26159;&#22914;&#20309;&#24402;&#22240;&#30446;&#26631;&#21644;&#20449;&#24565;&#30340;&#26469;&#35780;&#20272;&#36825;&#19968;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10416v1 Announce Type: new  Abstract: Despite the fact that beliefs are mental states that cannot be directly observed, humans talk about each others' beliefs on a regular basis, often using rich compositional language to describe what others think and know. What explains this capacity to interpret the hidden epistemic content of other minds? In this paper, we take a step towards an answer by grounding the semantics of belief statements in a Bayesian theory-of-mind: By modeling how humans jointly infer coherent sets of goals, beliefs, and plans that explain an agent's actions, then evaluating statements about the agent's beliefs against these inferences via epistemic logic, our framework provides a conceptual role semantics for belief, explaining the gradedness and compositionality of human belief attributions, as well as their intimate connection with goals and plans. We evaluate this framework by studying how humans attribute goals and beliefs while watching an agent solve
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#31639;&#27861;&#65288;RPO&#65289;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#65292;&#24182;&#25104;&#21151;&#38477;&#20302;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2401.17263</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17263
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#25552;&#31034;&#20248;&#21270;&#31639;&#27861;&#65288;RPO&#65289;&#29992;&#20110;&#23545;&#25239;&#35821;&#35328;&#27169;&#22411;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#65292;&#24182;&#25104;&#21151;&#38477;&#20302;&#20102;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#25110;&#30772;&#35299;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#20854;&#20013;&#23545;&#25163;&#20462;&#25913;&#36755;&#20837;&#25552;&#31034;&#20197;&#35825;&#23548;&#26377;&#23475;&#34892;&#20026;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#38450;&#24481;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#20165;&#20851;&#27880;&#29421;&#31364;&#30340;&#23041;&#32961;&#27169;&#22411;&#65292;&#24182;&#19981;&#33021;&#25552;&#20379;&#24378;&#22823;&#30340;&#38450;&#24481;&#12290;&#20026;&#20102;&#23454;&#29616;&#24378;&#22823;&#30340;&#38450;&#24481;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#29992;&#20110;&#23545;&#25239;&#30772;&#35299;&#25915;&#20987;&#30340;&#23545;&#25239;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#40065;&#26834;&#25552;&#31034;&#20248;&#21270;&#65288;RPO&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20196;&#29260;&#20248;&#21270;&#26469;&#30830;&#20445;&#36755;&#20986;&#30340;&#26080;&#23475;&#24615;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#26131;&#20110;&#35775;&#38382;&#30340;&#21518;&#32512;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#23545;&#30772;&#35299;&#25915;&#20987;&#30340;&#24378;&#38887;&#24615;&#65292;&#21253;&#25324;&#20248;&#21270;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#30772;&#35299;&#25915;&#20987;&#20197;&#21450;&#26410;&#30693;&#30340;&#30772;&#35299;&#25915;&#20987;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#20174;84%&#38477;&#20302;&#21040;8.66%&#65292;&#22312;20&#20010;&#30772;&#35299;&#25915;&#20987;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;RPO&#23545;&#27491;&#24120;LM&#20351;&#29992;&#30340;&#24433;&#21709;&#36739;&#23567;&#65292;&#22312;&#36866;&#24212;&#24615;&#25915;&#20987;&#19979;&#20173;&#28982;&#26377;&#25928;&#65292;&#24182;&#19988;&#21487;&#20197;&#36801;&#31227;&#21040;&#40657;&#30418;&#27169;&#22411;&#20013;&#65292;&#38477;&#20302;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite advances in AI alignment, language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior. While some defenses have been proposed, they focus on narrow threat models and fall short of a strong defense, which we posit should be effective, universal, and practical. To achieve this, we propose the first adversarial objective for defending LMs against jailbreaking attacks and an algorithm, robust prompt optimization (RPO), that uses gradient-based token optimization to enforce harmless outputs. This results in an easily accessible suffix that significantly improves robustness to both jailbreaks seen during optimization and unknown, held-out jailbreaks, reducing the attack success rate on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find that RPO has a minor effect on normal LM use, is successful under adaptive attacks, and can transfer to black-box models, reducing the success
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#36890;&#36807;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#28155;&#21152;&#23383;&#20856;&#38142;&#25552;&#31034;&#30340;&#26041;&#27861;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#32763;&#35793;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#33021;&#26174;&#33879;&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.06575</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23383;&#20856;&#38142;&#25552;&#31034;&#22312;&#32763;&#35793;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Chain-of-Dictionary Prompting Elicits Translation in Large Language Models. (arXiv:2305.06575v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06575
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#36890;&#36807;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#28155;&#21152;&#23383;&#20856;&#38142;&#25552;&#31034;&#30340;&#26041;&#27861;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#32763;&#35793;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#33021;&#26174;&#33879;&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22810;&#35821;&#35328;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;(MNMT)&#20013;&#34920;&#29616;&#20986;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#21363;&#20351;&#27809;&#26377;&#24179;&#34892;&#25968;&#25454;&#20063;&#33021;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35757;&#32451;&#25968;&#25454;&#37327;&#24040;&#22823;&#65292;&#23427;&#20204;&#20173;&#28982;&#38590;&#20197;&#32763;&#35793;&#31232;&#26377;&#35789;&#27719;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20302;&#36164;&#28304;&#35821;&#35328;&#12290;&#26356;&#31967;&#31957;&#30340;&#26159;&#65292;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#19978;&#65292;&#24456;&#38590;&#26816;&#32034;&#21040;&#30456;&#20851;&#31034;&#33539;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#36825;&#38480;&#21046;&#20102;LLMs&#22312;&#32763;&#35793;&#26041;&#38754;&#30340;&#23454;&#38469;&#24212;&#29992;&#8212;&#8212;&#25105;&#20204;&#35813;&#22914;&#20309;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65311;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;CoD&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#35821;&#35328;&#23383;&#20856;&#38142;&#20026;&#19968;&#37096;&#20998;&#36755;&#20837;&#21333;&#35789;&#22686;&#21152;LLMs&#30340;&#20808;&#21069;&#30693;&#35782;&#65292;&#20174;&#32780;&#20419;&#36827;LLMs&#30340;&#32763;&#35793;&#33021;&#21147;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;FLORES-200&#20840;&#24320;&#21457;&#27979;&#35797;&#38598;&#19978;&#65292;&#36890;&#36807;&#23558;CoD&#21644;ChatGPT&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#33719;&#24471;&#39640;&#36798;13&#20493;&#30340;MNMT ChrF++&#20998;&#25968;&#30340;&#25910;&#30410;&#65288;&#33521;&#35821;&#21040;&#22622;&#23572;&#32500;&#20122;&#35821;&#65292;&#35199;&#37324;&#23572;&#23383;&#27597;&#20070;&#20889;&#65292;ChrF ++&#20998;&#25968;&#20174;3.08&#22686;&#21152;&#21040;42.63&#65289;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20854;&#20182;&#25968;&#25454;&#38598;&#19978;&#30340;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown surprisingly good performance in multilingual neural machine translation (MNMT) even when trained without parallel data. Yet, despite the fact that the amount of training data is gigantic, they still struggle with translating rare words, particularly for low-resource languages. Even worse, it is usually unrealistic to retrieve relevant demonstrations for in-context learning with low-resource languages on LLMs, which restricts the practical use of LLMs for translation -- how should we mitigate this problem? To this end, we present a novel method, CoD, which augments LLMs with prior knowledge with the chains of multilingual dictionaries for a subset of input words to elicit translation abilities for LLMs. Extensive experiments indicate that augmenting ChatGPT with CoD elicits large gains by up to 13x ChrF++ points for MNMT (3.08 to 42.63 for English to Serbian written in Cyrillic script) on FLORES-200 full devtest set. We further demonstrate the im
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39046;&#22495;&#8212;&#8212;&#26426;&#22120;&#24515;&#29702;&#23398;&#65292;&#21033;&#29992;&#24515;&#29702;&#23398;&#30340;&#26041;&#27861;&#32771;&#23519;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#35813;&#25991;&#35268;&#33539;&#20102;&#26426;&#22120;&#24515;&#29702;&#23398;&#30740;&#31350;&#30340;&#26041;&#27861;&#35770;&#26631;&#20934;&#65292;&#24182;&#23545;&#24515;&#29702;&#23454;&#39564;&#20013;&#25552;&#31034;&#35774;&#35745;&#25919;&#31574;&#36827;&#34892;&#20102;&#25506;&#35752;&#21644;&#21046;&#23450;&#12290;</title><link>http://arxiv.org/abs/2303.13988</link><description>&lt;p&gt;
&#26426;&#22120;&#24515;&#29702;&#23398;&#65306;&#21033;&#29992;&#24515;&#29702;&#23398;&#26041;&#27861;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#20852;&#33021;&#21147;&#21644;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. (arXiv:2303.13988v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39046;&#22495;&#8212;&#8212;&#26426;&#22120;&#24515;&#29702;&#23398;&#65292;&#21033;&#29992;&#24515;&#29702;&#23398;&#30340;&#26041;&#27861;&#32771;&#23519;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#35813;&#25991;&#35268;&#33539;&#20102;&#26426;&#22120;&#24515;&#29702;&#23398;&#30740;&#31350;&#30340;&#26041;&#27861;&#35770;&#26631;&#20934;&#65292;&#24182;&#23545;&#24515;&#29702;&#23454;&#39564;&#20013;&#25552;&#31034;&#35774;&#35745;&#25919;&#31574;&#36827;&#34892;&#20102;&#25506;&#35752;&#21644;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26159;&#23558;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#19982;&#20154;&#31867;&#20132;&#27969;&#21644;&#26085;&#24120;&#29983;&#27963;&#32039;&#23494;&#32467;&#21512;&#30340;&#20808;&#38155;&#12290;&#30001;&#20110;&#24555;&#36895;&#25216;&#26415;&#36827;&#27493;&#21644;&#20854;&#26497;&#39640;&#30340;&#36890;&#29992;&#24615;&#65292;&#29616;&#20170;LLM&#24050;&#32463;&#25317;&#26377;&#25968;&#30334;&#19975;&#29992;&#25143;&#65292;&#24182;&#27491;&#22788;&#20110;&#25104;&#20026;&#20027;&#35201;&#20449;&#24687;&#26816;&#32034;&#12289;&#20869;&#23481;&#29983;&#25104;&#12289;&#38382;&#39064;&#35299;&#20915;&#31561;&#25216;&#26415;&#30340;&#21069;&#27839;&#12290;&#22240;&#27492;&#65292;&#23545;&#20854;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#21644;&#23457;&#26597;&#26174;&#24471;&#23588;&#20026;&#37325;&#35201;&#12290;&#30001;&#20110;&#24403;&#21069;LLM&#20013;&#20986;&#29616;&#24840;&#21152;&#22797;&#26434;&#21644;&#26032;&#39062;&#30340;&#34892;&#20026;&#27169;&#24335;&#65292;&#21487;&#23558;&#20854;&#35270;&#20026;&#21442;&#19982;&#20154;&#31867;&#24515;&#29702;&#23454;&#39564;&#30340;&#23545;&#35937;&#65292;&#20197;&#20415;&#26356;&#20026;&#20840;&#38754;&#22320;&#35780;&#20272;&#20854;&#33021;&#21147;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;"&#26426;&#22120;&#24515;&#29702;&#23398;"&#30340;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#21508;&#31867;&#24515;&#29702;&#23398;&#20998;&#25903;&#22914;&#20309;&#20026;LLM&#30340;&#34892;&#20026;&#27979;&#35797;&#25552;&#20379;&#26377;&#29992;&#21442;&#32771;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#35268;&#33539;&#20102;&#26426;&#22120;&#24515;&#29702;&#23398;&#30740;&#31350;&#30340;&#26041;&#27861;&#35770;&#26631;&#20934;&#65292;&#29305;&#21035;&#26159;&#19987;&#27880;&#20110;&#25552;&#31034;&#35774;&#35745;&#25919;&#31574;&#30340;&#21046;&#23450;&#12290;&#27492;&#22806;&#65292;&#23427;&#36824;&#25551;&#36848;&#20102;&#34892;&#20026;&#27979;&#35797;&#32467;&#26524;&#22914;&#20309;&#20026;&#26410;&#26469;&#30340;LLM&#21457;&#23637;&#25552;&#20379;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Due to rapid technological advances and their extreme versatility, LLMs nowadays have millions of users and are at the cusp of being the main go-to technology for information retrieval, content generation, problem-solving, etc. Therefore, it is of great importance to thoroughly assess and scrutinize their capabilities. Due to increasingly complex and novel behavioral patterns in current LLMs, this can be done by treating them as participants in psychology experiments that were originally designed to test humans. For this purpose, the paper introduces a new field of research called "machine psychology". The paper outlines how different subfields of psychology can inform behavioral tests for LLMs. It defines methodological standards for machine psychology research, especially by focusing on policies for prompt designs. Additionally, it describes how behaviora
&lt;/p&gt;</description></item></channel></rss>