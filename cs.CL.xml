<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#20195;&#29702;&#30340;&#26032;&#30340;&#35268;&#21010;&#22522;&#20934;TravelPlanner&#65292;&#23427;&#20851;&#27880;&#20110;&#26053;&#34892;&#35268;&#21010;&#36825;&#19968;&#24120;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#12290;&#32463;&#36807;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#30446;&#21069;&#30340;&#35821;&#35328;&#20195;&#29702;&#20173;&#26080;&#27861;&#22788;&#29702;&#22914;&#27492;&#22797;&#26434;&#30340;&#35268;&#21010;&#20219;&#21153;&#65292;&#21363;&#20351;&#26368;&#20808;&#36827;&#30340;GPT-4&#20063;&#21482;&#33021;&#36798;&#21040;0.6%&#30340;&#25104;&#21151;&#29575;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01622</link><description>&lt;p&gt;
TravelPlanner: &#19968;&#31181;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#20195;&#29702;&#30340;&#30495;&#23454;&#19990;&#30028;&#35268;&#21010;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
TravelPlanner: A Benchmark for Real-World Planning with Language Agents
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#20195;&#29702;&#30340;&#26032;&#30340;&#35268;&#21010;&#22522;&#20934;TravelPlanner&#65292;&#23427;&#20851;&#27880;&#20110;&#26053;&#34892;&#35268;&#21010;&#36825;&#19968;&#24120;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#12290;&#32463;&#36807;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#30446;&#21069;&#30340;&#35821;&#35328;&#20195;&#29702;&#20173;&#26080;&#27861;&#22788;&#29702;&#22914;&#27492;&#22797;&#26434;&#30340;&#35268;&#21010;&#20219;&#21153;&#65292;&#21363;&#20351;&#26368;&#20808;&#36827;&#30340;GPT-4&#20063;&#21482;&#33021;&#36798;&#21040;0.6%&#30340;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35268;&#21010;&#36215;&#21021;&#23601;&#26159;&#20154;&#24037;&#26234;&#33021;&#30340;&#26680;&#24515;&#36861;&#27714;&#20043;&#19968;&#65292;&#20294;&#26089;&#26399;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#22823;&#22810;&#38598;&#20013;&#22312;&#21463;&#38480;&#29615;&#22659;&#19979;&#65292;&#22240;&#20026;&#32570;&#20047;&#36827;&#34892;&#20154;&#31867;&#27700;&#24179;&#35268;&#21010;&#25152;&#38656;&#30340;&#35768;&#22810;&#35748;&#30693;&#22522;&#30784;&#12290;&#26368;&#36817;&#65292;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#39537;&#21160;&#30340;&#35821;&#35328;&#20195;&#29702;&#23637;&#29616;&#20986;&#20102;&#24037;&#20855;&#20351;&#29992;&#21644;&#25512;&#29702;&#31561;&#26377;&#36259;&#30340;&#33021;&#21147;&#12290;&#36825;&#20123;&#35821;&#35328;&#20195;&#29702;&#33021;&#21542;&#22312;&#36229;&#20986;&#20808;&#21069;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#33539;&#22260;&#30340;&#26356;&#22797;&#26434;&#29615;&#22659;&#20013;&#36827;&#34892;&#35268;&#21010;&#65311;&#20026;&#20102;&#25512;&#36827;&#36825;&#39033;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TravelPlanner&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#30340;&#35268;&#21010;&#22522;&#20934;&#65292;&#19987;&#27880;&#20110;&#26053;&#34892;&#35268;&#21010;&#36825;&#20010;&#24120;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#35268;&#21010;&#22330;&#26223;&#12290;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#20016;&#23500;&#30340;&#27801;&#30418;&#29615;&#22659;&#65292;&#21508;&#31181;&#29992;&#20110;&#35775;&#38382;&#36817;400&#19975;&#20010;&#25968;&#25454;&#35760;&#24405;&#30340;&#24037;&#20855;&#65292;&#24182;&#21253;&#21547;1225&#20010;&#31934;&#24515;&#31574;&#21010;&#30340;&#35268;&#21010;&#24847;&#22270;&#21644;&#21442;&#32771;&#35745;&#21010;&#12290;&#32508;&#21512;&#35780;&#20272;&#26174;&#31034;&#65292;&#24403;&#21069;&#30340;&#35821;&#35328;&#20195;&#29702;&#23578;&#19981;&#20855;&#22791;&#22788;&#29702;&#22914;&#27492;&#22797;&#26434;&#30340;&#35268;&#21010;&#20219;&#21153;&#30340;&#33021;&#21147;-&#21363;&#20351;&#26159;GPT-4&#30340;&#25104;&#21151;&#29575;&#20063;&#21482;&#26377;0.6%&#12290;
&lt;/p&gt;
&lt;p&gt;
Planning has been part of the core pursuit for artificial intelligence since its conception, but earlier AI agents mostly focused on constrained settings because many of the cognitive substrates necessary for human-level planning have been lacking. Recently, language agents powered by large language models (LLMs) have shown interesting capabilities such as tool use and reasoning. Are these language agents capable of planning in more complex settings that are out of the reach of prior AI agents? To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and 1,225 meticulously curated planning intents and reference plans. Comprehensive evaluations show that the current language agents are not yet capable of handling such complex planning tasks-even GPT-4 only achieves a success rate of 0.6%. La
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23569;&#26679;&#26412;&#23545;&#25239;&#25552;&#31034;&#26694;&#26550;&#65292;&#22312;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#36890;&#36807;&#26377;&#38480;&#25968;&#25454;&#35843;&#25972;&#36755;&#20837;&#24207;&#21015;&#65292;&#26174;&#33879;&#25552;&#21319;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#36890;&#36807;&#31471;&#21040;&#31471;&#23398;&#20064;&#23545;&#25239;&#24615;&#30456;&#20851;&#30340;&#25991;&#26412;&#30417;&#30563;&#12290;</title><link>https://arxiv.org/abs/2403.14774</link><description>&lt;p&gt;
&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#19978;&#30340;&#23569;&#26679;&#26412;&#23545;&#25239;&#25552;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Few-Shot Adversarial Prompt Learning on Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23569;&#26679;&#26412;&#23545;&#25239;&#25552;&#31034;&#26694;&#26550;&#65292;&#22312;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#36890;&#36807;&#26377;&#38480;&#25968;&#25454;&#35843;&#25972;&#36755;&#20837;&#24207;&#21015;&#65292;&#26174;&#33879;&#25552;&#21319;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#36890;&#36807;&#31471;&#21040;&#31471;&#23398;&#20064;&#23545;&#25239;&#24615;&#30456;&#20851;&#30340;&#25991;&#26412;&#30417;&#30563;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#24494;&#19981;&#21487;&#35265;&#30340;&#23545;&#25239;&#24615;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#24050;&#32463;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#21463;&#21040;&#35270;&#35273;-&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#20808;&#21069;&#30340;&#21162;&#21147;&#36890;&#36807;&#23558;&#23545;&#25239;&#24615;&#35270;&#35273;&#29305;&#24449;&#19982;&#25991;&#26412;&#30417;&#30563;&#23545;&#40784;&#26469;&#23454;&#29616;&#38646;&#26679;&#26412;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#30001;&#20110;&#21253;&#25324;&#37325;&#22823;&#36866;&#24212;&#25104;&#26412;&#12289;&#27425;&#20248;&#25991;&#26412;&#30417;&#30563;&#21644;&#26410;&#21463;&#25511;&#21046;&#30340;&#33258;&#28982;&#27867;&#21270;&#33021;&#21147;&#22312;&#20869;&#30340;&#22810;&#20010;&#38382;&#39064;&#65292;&#23427;&#20204;&#20173;&#28982;&#19981;&#23613;&#20154;&#24847;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23569;&#26679;&#26412;&#23545;&#25239;&#25552;&#31034;&#26694;&#26550;&#65292;&#36890;&#36807;&#26377;&#38480;&#30340;&#25968;&#25454;&#35843;&#25972;&#36755;&#20837;&#24207;&#21015;&#20351;&#24471;&#23545;&#25239;&#40065;&#26834;&#24615;&#24471;&#21040;&#26174;&#33879;&#25552;&#21319;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#23545;&#25239;&#30456;&#20851;&#30340;&#25991;&#26412;&#30417;&#30563;&#65292;&#35813;&#30417;&#30563;&#26159;&#20174;&#23545;&#25239;&#24615;&#31034;&#20363;&#20013;&#31471;&#21040;&#31471;&#23398;&#20064;&#30340;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#22810;&#27169;&#24577;&#29305;&#24449;&#19968;&#33268;&#24615;&#24182;&#40723;&#21169;&#19981;&#21516;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14774v1 Announce Type: cross  Abstract: The vulnerability of deep neural networks to imperceptible adversarial perturbations has attracted widespread attention. Inspired by the success of vision-language foundation models, previous efforts achieved zero-shot adversarial robustness by aligning adversarial visual features with text supervision. However, in practice, they are still unsatisfactory due to several issues, including heavy adaptation cost, suboptimal text supervision, and uncontrolled natural generalization capacity. In this paper, to address these issues, we propose a few-shot adversarial prompt framework where adapting input sequences with limited data makes significant adversarial robustness improvement. Specifically, we achieve this by providing adversarially correlated text supervision that is end-to-end learned from adversarial examples. We also propose a novel training objective that enhances the consistency of multi-modal features while encourages differenti
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;Transformer&#20013;&#27880;&#24847;&#21147;&#22836;&#21644;MLP&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25581;&#31034;&#20102;&#29305;&#23450;&#19978;&#19979;&#25991;&#19979;&#28608;&#27963;&#29305;&#23450;token&#39044;&#27979;&#30340;&#26426;&#21046;&#65292;&#20174;&#32780;&#38416;&#26126;&#22312;LLMs&#20013;&#27880;&#24847;&#21147;&#22914;&#20309;&#20419;&#25104;&#20381;&#36182;&#19978;&#19979;&#25991;&#30340;&#19987;&#38376;&#21270;&#22788;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.15055</link><description>&lt;p&gt;
&#22312;Transformer&#20013;&#35299;&#37322;&#19978;&#19979;&#25991;&#26597;&#25214;&#65306;&#25506;&#31350;&#27880;&#24847;&#21147;-MLP&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15055
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;Transformer&#20013;&#27880;&#24847;&#21147;&#22836;&#21644;MLP&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25581;&#31034;&#20102;&#29305;&#23450;&#19978;&#19979;&#25991;&#19979;&#28608;&#27963;&#29305;&#23450;token&#39044;&#27979;&#30340;&#26426;&#21046;&#65292;&#20174;&#32780;&#38416;&#26126;&#22312;LLMs&#20013;&#27880;&#24847;&#21147;&#22914;&#20309;&#20419;&#25104;&#20381;&#36182;&#19978;&#19979;&#25991;&#30340;&#19987;&#38376;&#21270;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27880;&#24847;&#21147;&#22836;&#21644;Multilayer Perceptron&#20013;&#19987;&#38376;&#39044;&#27979;&#29305;&#23450;token&#30340;"next-token"&#31070;&#32463;&#20803;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36890;&#36807;&#20419;&#20351;&#20687;GPT-4&#36825;&#26679;&#30340;LLM&#35299;&#37322;&#36825;&#20123;&#27169;&#22411;&#20869;&#37096;&#65292;&#25105;&#20204;&#21487;&#20197;&#38416;&#26126;&#28608;&#27963;&#26576;&#20123;next-token&#31070;&#32463;&#20803;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#30830;&#23450;&#20102;&#35782;&#21035;&#19982;&#39044;&#27979;&#29305;&#23450;token&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#30340;attention heads&#65292;&#36890;&#36807;&#27531;&#24046;&#36830;&#25509;&#28608;&#27963;&#30456;&#20851;&#32852;&#30340;&#31070;&#32463;&#20803;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#22312;&#36739;&#26089;&#30340;&#23618;&#20013;&#22987;&#32456;&#28608;&#27963;&#30456;&#21516;next-token&#31070;&#32463;&#20803;&#30340;attention heads&#12290;&#25506;&#32034;&#36825;&#20123;&#19981;&#21516;&#30340;&#28608;&#27963;&#27169;&#24335;&#25581;&#31034;&#20102;&#20026;&#19981;&#21516;&#35821;&#35328;&#19978;&#19979;&#25991;&#19987;&#38376;&#21270;&#30340;&#22836;&#19982;&#29983;&#25104;&#26576;&#20123;tokens&#30456;&#20851;&#32852;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#31070;&#32463;&#35299;&#37322;&#21644;&#25506;&#27979;&#23396;&#31435;&#30340;&#32452;&#20214;&#65292;&#20197;&#38416;&#26126;&#27880;&#24847;&#21147;&#22914;&#20309;&#20351;LLMs&#20013;&#30340;&#20381;&#36182;&#19978;&#19979;&#25991;&#30340;&#19987;&#38376;&#22788;&#29702;&#25104;&#20026;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15055v1 Announce Type: cross  Abstract: In this paper, we investigate the interplay between attention heads and specialized "next-token" neurons in the Multilayer Perceptron that predict specific tokens. By prompting an LLM like GPT-4 to explain these model internals, we can elucidate attention mechanisms that activate certain next-token neurons. Our analysis identifies attention heads that recognize contexts relevant to predicting a particular token, activating the associated neuron through the residual connection. We focus specifically on heads in earlier layers consistently activating the same next-token neuron across similar prompts. Exploring these differential activation patterns reveals that heads that specialize for distinct linguistic contexts are tied to generating certain tokens. Overall, our method combines neural explanations and probing isolated components to illuminate how attention enables context-dependent, specialized processing in LLMs.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#31361;&#20986;&#20102;&#20449;&#24687;&#26816;&#32034;&#24341;&#25806;&#22312;&#31185;&#23398;&#30028;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#21270;&#35760;&#24405;&#21644;&#20808;&#36827;&#20449;&#24687;&#25216;&#26415;&#24037;&#20855;&#23454;&#29616;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#38761;&#26032;&#30740;&#31350;&#20154;&#21592;&#35775;&#38382;&#21644;&#36807;&#28388;&#25991;&#31456;&#30340;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2402.14622</link><description>&lt;p&gt;
&#20174;&#20851;&#38190;&#35789;&#21040;&#32467;&#26500;&#21270;&#25688;&#35201;: &#31934;&#31616;&#23398;&#26415;&#30693;&#35782;&#33719;&#21462;
&lt;/p&gt;
&lt;p&gt;
From Keywords to Structured Summaries: Streamlining Scholarly Knowledge Access
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14622
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#31361;&#20986;&#20102;&#20449;&#24687;&#26816;&#32034;&#24341;&#25806;&#22312;&#31185;&#23398;&#30028;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#21270;&#35760;&#24405;&#21644;&#20808;&#36827;&#20449;&#24687;&#25216;&#26415;&#24037;&#20855;&#23454;&#29616;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#38761;&#26032;&#30740;&#31350;&#20154;&#21592;&#35775;&#38382;&#21644;&#36807;&#28388;&#25991;&#31456;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#30701;&#25991;&#24378;&#35843;&#20102;&#20449;&#24687;&#26816;&#32034;&#24341;&#25806;&#22312;&#31185;&#23398;&#30028;&#26085;&#30410;&#37325;&#35201;&#65292;&#25351;&#20986;&#20256;&#32479;&#22522;&#20110;&#20851;&#38190;&#35789;&#30340;&#25628;&#32034;&#24341;&#25806;&#30001;&#20110;&#20986;&#29256;&#29289;&#25968;&#37327;&#19981;&#26029;&#22686;&#21152;&#32780;&#25928;&#29575;&#20302;&#19979;&#12290;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#28041;&#21450;&#32467;&#26500;&#21270;&#35760;&#24405;&#65292;&#25903;&#25345;&#20808;&#36827;&#30340;&#20449;&#24687;&#25216;&#26415;&#24037;&#20855;&#65292;&#21253;&#25324;&#21487;&#35270;&#21270;&#20202;&#34920;&#26495;&#65292;&#20197;&#24443;&#24213;&#25913;&#21464;&#30740;&#31350;&#20154;&#21592;&#22914;&#20309;&#35775;&#38382;&#21644;&#36807;&#28388;&#25991;&#31456;&#65292;&#21462;&#20195;&#20256;&#32479;&#30340;&#25991;&#26412;&#23494;&#38598;&#22411;&#26041;&#27861;&#12290;&#36825;&#19968;&#24895;&#26223;&#36890;&#36807;&#19968;&#20010;&#20197;&#8220;&#20256;&#26579;&#30149;&#30340;&#32321;&#27542;&#25968;&#20272;&#35745;&#8221;&#30740;&#31350;&#20027;&#39064;&#20026;&#20013;&#24515;&#30340;&#27010;&#24565;&#39564;&#35777;&#24471;&#20197;&#20307;&#29616;&#65292;&#20351;&#29992;&#32463;&#36807;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#33258;&#21160;&#21019;&#24314;&#32467;&#26500;&#21270;&#35760;&#24405;&#20197;&#22635;&#20805;&#19968;&#20010;&#36229;&#36234;&#20851;&#38190;&#35789;&#30340;&#21518;&#31471;&#25968;&#25454;&#24211;&#12290;&#32467;&#26524;&#26159;&#19968;&#20010;&#19979;&#19968;&#20195;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#22312;https://orkg.org/usecases/r0-estimates &#19978;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14622v1 Announce Type: cross  Abstract: This short paper highlights the growing importance of information retrieval (IR) engines in the scientific community, addressing the inefficiency of traditional keyword-based search engines due to the rising volume of publications. The proposed solution involves structured records, underpinning advanced information technology (IT) tools, including visualization dashboards, to revolutionize how researchers access and filter articles, replacing the traditional text-heavy approach. This vision is exemplified through a proof of concept centered on the ``reproductive number estimate of infectious diseases'' research theme, using a fine-tuned large language model (LLM) to automate the creation of structured records to populate a backend database that now goes beyond keywords. The result is a next-generation IR method accessible at https://orkg.org/usecases/r0-estimates.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#25511;&#21046;&#22810;&#31181;&#39118;&#26684;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#26435;&#37325;&#35843;&#25972;&#22810;&#37325;&#22870;&#21169;&#65292;&#23454;&#29616;&#20102;&#22312;&#29983;&#25104;&#25991;&#26412;&#26102;&#21516;&#26102;&#25511;&#21046;&#22810;&#31181;&#39118;&#26684;&#12290;</title><link>https://arxiv.org/abs/2402.14146</link><description>&lt;p&gt;
&#20351;&#29992;&#21160;&#24577;&#22810;&#37325;&#22870;&#21169;&#21152;&#26435;&#30340;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#22810;&#26679;&#24335;&#21487;&#25511;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#25511;&#21046;&#22810;&#31181;&#39118;&#26684;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#26435;&#37325;&#35843;&#25972;&#22810;&#37325;&#22870;&#21169;&#65292;&#23454;&#29616;&#20102;&#22312;&#29983;&#25104;&#25991;&#26412;&#26102;&#21516;&#26102;&#25511;&#21046;&#22810;&#31181;&#39118;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39118;&#26684;&#26159;&#34920;&#36798;&#21508;&#31181;&#20449;&#24687;&#30340;&#25991;&#26412;&#20013;&#30340;&#19968;&#20010;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#20154;&#38469;&#21160;&#24577;&#65288;&#20363;&#22914;&#27491;&#24335;&#24615;&#65289;&#21644;&#20316;&#32773;&#30340;&#24773;&#32490;&#25110;&#24577;&#24230;&#65288;&#20363;&#22914;&#21388;&#24694;&#65289;&#12290;&#20154;&#31867;&#32463;&#24120;&#21516;&#26102;&#37319;&#29992;&#22810;&#31181;&#39118;&#26684;&#12290;&#19968;&#20010;&#24453;&#35299;&#20915;&#30340;&#38382;&#39064;&#26159;&#22914;&#20309;&#26126;&#30830;&#25511;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20351;&#23427;&#20204;&#22312;&#29983;&#25104;&#25991;&#26412;&#26102;&#32534;&#32455;&#30446;&#26631;&#39118;&#26684;&#65306;&#20363;&#22914;&#65292;&#29983;&#25104;&#26082;&#28040;&#26497;&#21448;&#26080;&#27602;&#30340;&#25991;&#26412;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#25506;&#35752;&#20102;&#23545;&#21333;&#19968;&#39118;&#26684;&#30340;&#25511;&#21046;&#29983;&#25104;&#65292;&#25110;&#32773;&#23545;&#39118;&#26684;&#21644;&#20854;&#20182;&#23646;&#24615;&#30340;&#25511;&#21046;&#29983;&#25104;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#25193;&#23637;&#21040;&#21516;&#26102;&#25511;&#21046;&#22810;&#31181;&#39118;&#26684;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#21463;&#25511;&#22810;&#26679;&#24335;&#29983;&#25104;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26041;&#27861;&#30340;&#22810;&#31181;&#39118;&#26684;&#22870;&#21169;&#30340;&#21508;&#31181;&#20844;&#24335;&#12290;&#36825;&#20123;&#22870;&#21169;&#20844;&#24335;&#21253;&#25324;&#26469;&#33258;&#37492;&#21035;&#22120;&#30340;&#26657;&#20934;&#36755;&#20986;&#20197;&#21450;&#36890;&#36807;&#37492;&#21035;&#22120;&#26799;&#24230;&#24133;&#24230;&#36827;&#34892;&#21160;&#24577;&#21152;&#26435;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14146v1 Announce Type: new  Abstract: Style is an integral component of text that expresses a diverse set of information, including interpersonal dynamics (e.g. formality) and the author's emotions or attitudes (e.g. disgust). Humans often employ multiple styles simultaneously. An open question is how large language models can be explicitly controlled so that they weave together target styles when generating text: for example, to produce text that is both negative and non-toxic. Previous work investigates the controlled generation of a single style, or else controlled generation of a style and other attributes. In this paper, we expand this into controlling multiple styles simultaneously. Specifically, we investigate various formulations of multiple style rewards for a reinforcement learning (RL) approach to controlled multi-style generation. These reward formulations include calibrated outputs from discriminators and dynamic weighting by discriminator gradient magnitudes. W
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#25968;&#25454;&#27880;&#20837;&#25915;&#20987;&#25915;&#20987;LLMs&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#26799;&#24230;&#24341;&#23548;&#21518;&#38376;&#35302;&#21457;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#34920;&#26126;&#25104;&#21151;&#22320;&#30772;&#22351;&#27169;&#22411;&#36755;&#20986;&#65292;&#20165;&#25913;&#21464;1%&#30340;&#25351;&#23548;&#35843;&#20248;&#26679;&#26412;&#21363;&#21487;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#29575;&#36798;&#21040;&#32422;80&#65285;&#12290;</title><link>https://arxiv.org/abs/2402.13459</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#25351;&#23548;&#35843;&#20248;&#26399;&#38388;&#25805;&#32437;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning to Poison Large Language Models During Instruction Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13459
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#25968;&#25454;&#27880;&#20837;&#25915;&#20987;&#25915;&#20987;LLMs&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#26799;&#24230;&#24341;&#23548;&#21518;&#38376;&#35302;&#21457;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#34920;&#26126;&#25104;&#21151;&#22320;&#30772;&#22351;&#27169;&#22411;&#36755;&#20986;&#65292;&#20165;&#25913;&#21464;1%&#30340;&#25351;&#23548;&#35843;&#20248;&#26679;&#26412;&#21363;&#21487;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#29575;&#36798;&#21040;&#32422;80&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#26631;&#24535;&#30528;&#35821;&#35328;&#22788;&#29702;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#37325;&#22823;&#31361;&#30772;&#12290;&#34429;&#28982;&#23427;&#20204;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;LLMs&#38754;&#20020;&#30528;&#25968;&#25454;&#27880;&#20837;&#25915;&#20987;&#30340;&#28431;&#27934;&#65292;&#20854;&#20013;&#23545;&#25163;&#23558;&#21518;&#38376;&#35302;&#21457;&#22120;&#25554;&#20837;&#35757;&#32451;&#25968;&#25454;&#65292;&#20197;&#25805;&#32437;&#36755;&#20986;&#20197;&#36827;&#34892;&#24694;&#24847;&#34892;&#20026;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#27880;&#20837;&#25915;&#20987;&#65292;&#26088;&#22312;&#21033;&#29992;&#25351;&#23548;&#35843;&#20248;&#36807;&#31243;&#65292;&#36827;&#19968;&#27493;&#35782;&#21035;LLMs&#20013;&#30340;&#39069;&#22806;&#23433;&#20840;&#39118;&#38505;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26799;&#24230;&#24341;&#23548;&#21518;&#38376;&#35302;&#21457;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#26377;&#25928;&#35782;&#21035;&#25932;&#23545;&#35302;&#21457;&#22120;&#65292;&#30830;&#20445;&#23545;&#20256;&#32479;&#38450;&#24481;&#25163;&#27573;&#30340;&#35268;&#36991;&#65292;&#21516;&#26102;&#20445;&#25345;&#20869;&#23481;&#30340;&#23436;&#25972;&#24615;&#12290;&#36890;&#36807;&#23545;&#21508;&#31181;LLMs&#21644;&#20219;&#21153;&#30340;&#23454;&#39564;&#39564;&#35777;&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#34920;&#26126;&#22312;&#30772;&#22351;&#27169;&#22411;&#36755;&#20986;&#26041;&#38754;&#21462;&#24471;&#20102;&#24456;&#39640;&#30340;&#25104;&#21151;&#29575;&#65307;&#20165;&#23545;4,000&#20010;&#25351;&#23548;&#35843;&#20248;&#26679;&#26412;&#20013;&#30340;1&#65285;&#36827;&#34892;&#27880;&#20837;&#23601;&#23548;&#33268;&#24615;&#33021;&#38477;&#20302;&#29575;&#65288;PDR&#65289;&#32422;&#20026;80&#65285;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#39640;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13459v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has marked significant achievements in language processing and reasoning capabilities. Despite their advancements, LLMs face vulnerabilities to data poisoning attacks, where adversaries insert backdoor triggers into training data to manipulate outputs for malicious purposes. This work further identifies additional security risks in LLMs by designing a new data poisoning attack tailored to exploit the instruction tuning process. We propose a novel gradient-guided backdoor trigger learning approach to identify adversarial triggers efficiently, ensuring an evasion of detection by conventional defenses while maintaining content integrity. Through experimental validation across various LLMs and tasks, our strategy demonstrates a high success rate in compromising model outputs; poisoning only 1\% of 4,000 instruction tuning samples leads to a Performance Drop Rate (PDR) of around 80\%. Our work high
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#23433;&#20840;&#25361;&#25112;&#21450;&#23545;&#31574;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2402.12617</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#23433;&#20840;&#65306;&#25361;&#25112;&#19982;&#23545;&#31574;
&lt;/p&gt;
&lt;p&gt;
Generative AI Security: Challenges and Countermeasures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12617
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#23433;&#20840;&#25361;&#25112;&#21450;&#23545;&#31574;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12617v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#22312;&#35768;&#22810;&#34892;&#19994;&#30340;&#19981;&#26029;&#25193;&#23637;&#24341;&#21457;&#20102;&#20154;&#20204;&#30340;&#20852;&#22859;&#21644;&#22686;&#21152;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25152;&#24102;&#26469;&#30340;&#29420;&#29305;&#23433;&#20840;&#25361;&#25112;&#65292;&#24182;&#27010;&#36848;&#20102;&#31649;&#29702;&#36825;&#20123;&#39118;&#38505;&#30340;&#28508;&#22312;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12617v1 Announce Type: cross  Abstract: Generative AI's expanding footprint across numerous industries has led to both excitement and increased scrutiny. This paper delves into the unique security challenges posed by Generative AI, and outlines potential research directions for managing these risks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;</title><link>https://arxiv.org/abs/2402.10601</link><description>&lt;p&gt;
&#20351;&#29992;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#26469;&#36234;&#29425;&#19987;&#26377;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Jailbreaking Proprietary Large Language Models using Word Substitution Cipher
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36981;&#24490;&#36947;&#24503;&#21644;&#20262;&#29702;&#20934;&#21017;&#65292;&#20294;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#21517;&#20026;Jailbreak&#30340;&#21019;&#24847;&#25552;&#31034;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#25552;&#31034;&#21487;&#20197;&#32469;&#36807;&#23545;&#40784;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36234;&#29425;&#25552;&#31034;&#21253;&#21547;&#33258;&#28982;&#35821;&#35328;&#65288;&#20027;&#35201;&#26159;&#33521;&#35821;&#65289;&#20013;&#30340;&#26377;&#23475;&#38382;&#39064;&#65292;&#21487;&#20197;&#34987;LLMs&#33258;&#36523;&#26816;&#27979;&#21040;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#26368;&#20808;&#36827;&#30340;LLM&#65292;GPT-4&#19978;&#36827;&#34892;&#20102;&#19968;&#20010;&#35797;&#28857;&#30740;&#31350;&#65292;&#35299;&#30721;&#20102;&#20351;&#29992;&#21508;&#31181;&#23494;&#30721;&#25216;&#26415;&#21152;&#23494;&#30340;&#20960;&#20010;&#23433;&#20840;&#21477;&#23376;&#65292;&#21457;&#29616;&#31616;&#21333;&#30340;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#21487;&#20197;&#34987;&#26368;&#26377;&#25928;&#22320;&#35299;&#30721;&#12290;&#21463;&#27492;&#32467;&#26524;&#21551;&#21457;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#32534;&#30721;&#25216;&#26415;&#26469;&#32534;&#20889;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23558;&#19981;&#23433;&#20840;&#21333;&#35789;&#26144;&#23556;&#21040;&#23433;&#20840;&#21333;&#35789;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26144;&#23556;&#30340;&#21333;&#35789;&#25552;&#20986;&#19981;&#23433;&#20840;&#38382;&#39064;&#30340;&#26144;&#23556;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#36234;&#29425;&#25915;&#20987;&#25104;&#21151;&#29575;&#65288;&#39640;&#36798;59.42%&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10601v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are aligned to moral and ethical guidelines but remain susceptible to creative prompts called Jailbreak that can bypass the alignment process. However, most jailbreaking prompts contain harmful questions in the natural language (mainly English), which can be detected by the LLM themselves. In this paper, we present jailbreaking prompts encoded using cryptographic techniques. We first present a pilot study on the state-of-the-art LLM, GPT-4, in decoding several safe sentences that have been encrypted using various cryptographic techniques and find that a straightforward word substitution cipher can be decoded most effectively. Motivated by this result, we use this encoding technique for writing jailbreaking prompts. We present a mapping of unsafe words with safe words and ask the unsafe question using these mapped words. Experimental results show an attack success rate (up to 59.42%) of our proposed jailbrea
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24515;&#38382;&#39064;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#36275;&#20197;&#35299;&#20915;&#30001;&#20110;&#20998;&#32452;&#25439;&#22833;&#23548;&#33268;&#30340;&#39044;&#27979;&#20998;&#25968;&#19982;&#23454;&#38469;&#27010;&#29575;&#20559;&#31163;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#37325;&#26032;&#30830;&#23450;LLMs&#65292;&#25913;&#21892;&#23427;&#20204;&#30340;&#33258;&#20449;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.04957</link><description>&lt;p&gt;
&#20174;&#20998;&#32452;&#25439;&#22833;&#30340;&#35282;&#24230;&#37325;&#26500;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24515;
&lt;/p&gt;
&lt;p&gt;
Reconfidencing LLMs from the Grouping Loss Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24515;&#38382;&#39064;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#36275;&#20197;&#35299;&#20915;&#30001;&#20110;&#20998;&#32452;&#25439;&#22833;&#23548;&#33268;&#30340;&#39044;&#27979;&#20998;&#25968;&#19982;&#23454;&#38469;&#27010;&#29575;&#20559;&#31163;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#37325;&#26032;&#30830;&#23450;LLMs&#65292;&#25913;&#21892;&#23427;&#20204;&#30340;&#33258;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#21253;&#25324;ChatGPT&#21644;LLaMA&#65292;&#22312;&#33258;&#20449;&#30340;&#21475;&#21563;&#20013;&#23481;&#26131;&#29983;&#25104;&#34394;&#20551;&#31572;&#26696;&#12290;&#23613;&#31649;&#24341;&#23548;&#21644;&#26657;&#20934;&#20449;&#24515;&#20998;&#25968;&#30340;&#21162;&#21147;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#29992;&#30340;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#25511;&#21046;&#19981;&#30830;&#23450;&#24615;&#24517;&#39035;&#36229;&#36234;&#26657;&#20934;: &#30001;&#20110;&#20998;&#32452;&#25439;&#22833;&#30340;&#24433;&#21709;&#65292;&#39044;&#27979;&#20998;&#25968;&#21487;&#33021;&#26126;&#26174;&#20559;&#31163;&#23454;&#38469;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#65292;&#20174;&#30693;&#35782;&#24211;&#20013;&#33719;&#21462;&#65292;&#20197;&#35780;&#20272;&#23545;Mistral&#21644;LLaMA&#30340;&#31572;&#26696;&#32473;&#20986;&#30340;&#20449;&#24515;&#20998;&#25968;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#20204;&#20542;&#21521;&#20110;&#36807;&#20110;&#33258;&#20449;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#26576;&#20123;&#31572;&#26696;&#19978;&#27604;&#20854;&#20182;&#31572;&#26696;&#26356;&#36807;&#20110;&#33258;&#20449;&#65292;&#20363;&#22914;&#21462;&#20915;&#20110;&#26597;&#35810;&#20013;&#20154;&#30340;&#22269;&#31821;&#12290;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#29702;&#35770;&#20013;&#65292;&#36825;&#23601;&#26159;&#20998;&#32452;&#25439;&#22833;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#30830;&#23450;LLMs&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#19981;&#20165;&#21462;&#28040;&#26657;&#20934;&#65292;&#36824;&#21462;&#28040;&#20998;&#32452;&#25439;&#22833;&#12290;&#32463;&#36807;&#37325;&#26032;&#30830;&#23450;&#30340;LLMs&#32463;&#36807;&#22788;&#29702;&#21518;&#65292;&#34920;&#31034;&#25913;&#36827;&#30340;&#33258;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), including ChatGPT and LLaMA, are susceptible to generating hallucinated answers in a confident tone. While efforts to elicit and calibrate confidence scores have proven useful, recent findings show that controlling uncertainty must go beyond calibration: predicted scores may deviate significantly from the actual posterior probabilities due to the impact of grouping loss. In this work, we construct a new evaluation dataset derived from a knowledge base to assess confidence scores given to answers of Mistral and LLaMA. Experiments show that they tend to be overconfident. Further, we show that they are more overconfident on some answers than others, \emph{eg} depending on the nationality of the person in the query. In uncertainty-quantification theory, this is grouping loss. To address this, we propose a solution to reconfidence LLMs, canceling not only calibration but also grouping loss. The LLMs, after the reconfidencing process, indicate improved confidenc
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#25945;&#32946;&#23398;&#29702;&#24565;&#30340;&#21453;&#39304;&#26694;&#26550;FELT&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#21453;&#39304;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#19982;&#20154;&#31867;&#20559;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#31616;&#21270;&#20102;&#29616;&#26377;&#30340;&#25163;&#24037;&#35774;&#35745;&#21453;&#39304;&#65292;&#36824;&#20026;NLF&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2307.00279</link><description>&lt;p&gt;
&#35753;&#25105;&#26469;&#25945;&#20320;&#65306;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#39304;&#25945;&#32946;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Let Me Teach You: Pedagogical Foundations of Feedback for Language Models. (arXiv:2307.00279v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00279
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#25945;&#32946;&#23398;&#29702;&#24565;&#30340;&#21453;&#39304;&#26694;&#26550;FELT&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#21453;&#39304;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#19982;&#20154;&#31867;&#20559;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#31616;&#21270;&#20102;&#29616;&#26377;&#30340;&#25163;&#24037;&#35774;&#35745;&#21453;&#39304;&#65292;&#36824;&#20026;NLF&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#21453;&#39304;&#65288;NLF&#65289;&#26159;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#19968;&#20010;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#30340;&#36884;&#24452;&#12290;&#23613;&#31649;NLF&#21487;&#20197;&#20256;&#36798;&#20016;&#23500;&#22810;&#26679;&#30340;&#20449;&#24687;&#65292;&#20294;&#24448;&#24448;&#26159;&#25163;&#24037;&#35774;&#35745;&#30340;&#21644;&#38543;&#24847;&#30340;&#12290;&#22312;&#19981;&#21516;&#30340;&#19990;&#30028;&#20013;&#65292;&#25945;&#32946;&#23398;&#30740;&#31350;&#38271;&#26399;&#20197;&#26469;&#24314;&#31435;&#20102;&#20960;&#31181;&#26377;&#25928;&#30340;&#21453;&#39304;&#27169;&#22411;&#12290;&#22312;&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#27719;&#32534;&#20102;&#26469;&#33258;&#25945;&#32946;&#23398;&#30340;&#24605;&#24819;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;FELT&#30340;LLMs&#21453;&#39304;&#26694;&#26550;&#65292;&#27010;&#36848;&#20102;&#21453;&#39304;&#31354;&#38388;&#30340;&#21508;&#31181;&#29305;&#24449;&#20197;&#21450;&#22522;&#20110;&#36825;&#20123;&#21464;&#37327;&#30340;&#21453;&#39304;&#20869;&#23481;&#20998;&#31867;&#27861;&#12290;&#25105;&#20204;&#30340;&#20998;&#31867;&#27861;&#19981;&#20165;&#25552;&#20379;&#20102;&#23545;&#21453;&#39304;&#31354;&#38388;&#30340;&#19968;&#33324;&#26144;&#23556;&#65292;&#36824;&#25552;&#20379;&#20102;&#25945;&#32946;&#23398;&#30830;&#23450;&#30340;&#31163;&#25955;&#31867;&#21035;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20174;&#32463;&#39564;&#19978;&#35777;&#26126;&#19981;&#21516;&#21453;&#39304;&#31867;&#22411;&#23545;&#20462;&#35746;&#29983;&#25104;&#30340;&#24433;&#21709;&#12290;&#38500;&#20102;&#31616;&#21270;&#29616;&#26377;&#30340;NLF&#35774;&#35745;&#65292;FELT&#36824;&#20026;NLF&#30740;&#31350;&#24102;&#26469;&#20102;&#26032;&#30340;&#26410;&#24320;&#21457;&#30340;&#26041;&#21521;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#31867;&#27861;&#25552;&#20379;&#32473;&#31038;&#21306;&#65292;&#20026;&#26144;&#23556;&#25105;&#20204;&#30340;&#31867;&#21035;&#25552;&#20379;&#25351;&#21335;&#21644;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural Language Feedback (NLF) is an increasingly popular avenue to align Large Language Models (LLMs) to human preferences. Despite the richness and diversity of the information it can convey, NLF is often hand-designed and arbitrary. In a different world, research in pedagogy has long established several effective feedback models. In this opinion piece, we compile ideas from pedagogy to introduce FELT, a feedback framework for LLMs that outlines the various characteristics of the feedback space, and a feedback content taxonomy based on these variables. Our taxonomy offers both a general mapping of the feedback space, as well as pedagogy-established discrete categories, allowing us to empirically demonstrate the impact of different feedback types on revised generations. In addition to streamlining existing NLF designs, FELT also brings out new, unexplored directions for research in NLF. We make our taxonomy available to the community, providing guides and examples for mapping our cat
&lt;/p&gt;</description></item><item><title>GPT-SW3&#26159;&#38754;&#21521;&#21271;&#27431;&#35821;&#35328;&#30340;&#31532;&#19968;&#20010;&#26412;&#22320;&#21270;&#22823;&#22411;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#20854;&#24320;&#21457;&#36807;&#31243;&#65292;&#21487;&#20316;&#20026;&#20854;&#20182;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#38754;&#21521;&#36739;&#23567;&#35821;&#35328;&#30340;&#22823;&#22411;&#29983;&#25104;&#27169;&#22411;&#30340;&#25351;&#21335;&#21644;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2305.12987</link><description>&lt;p&gt;
GPT-SW3&#65306;&#19968;&#31181;&#38754;&#21521;&#21271;&#27431;&#35821;&#35328;&#30340;&#33258;&#22238;&#24402;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
GPT-SW3: An Autoregressive Language Model for the Nordic Languages. (arXiv:2305.12987v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12987
&lt;/p&gt;
&lt;p&gt;
GPT-SW3&#26159;&#38754;&#21521;&#21271;&#27431;&#35821;&#35328;&#30340;&#31532;&#19968;&#20010;&#26412;&#22320;&#21270;&#22823;&#22411;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#20854;&#24320;&#21457;&#36807;&#31243;&#65292;&#21487;&#20316;&#20026;&#20854;&#20182;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#38754;&#21521;&#36739;&#23567;&#35821;&#35328;&#30340;&#22823;&#22411;&#29983;&#25104;&#27169;&#22411;&#30340;&#25351;&#21335;&#21644;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#24320;&#21457;&#38754;&#21521;&#21271;&#27431;&#35821;&#35328;&#30340;&#31532;&#19968;&#20010;&#26412;&#22320;&#21270;&#22823;&#22411;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;GPT-SW3&#30340;&#36807;&#31243;&#12290;&#25105;&#20204;&#28085;&#30422;&#20102;&#24320;&#21457;&#36807;&#31243;&#30340;&#25152;&#26377;&#37096;&#20998;&#65292;&#20174;&#25968;&#25454;&#25910;&#38598;&#21644;&#22788;&#29702;&#65292;&#35757;&#32451;&#37197;&#32622;&#21644;&#25351;&#20196;&#24494;&#35843;&#65292;&#21040;&#35780;&#20272;&#21644;&#21457;&#24067;&#31574;&#30053;&#30340;&#32771;&#34385;&#12290;&#25105;&#20204;&#24076;&#26395;&#26412;&#25991;&#33021;&#22815;&#20316;&#20026;&#25351;&#21335;&#21644;&#21442;&#32771;&#65292;&#24110;&#21161;&#20854;&#20182;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#38754;&#21521;&#36739;&#23567;&#35821;&#35328;&#30340;&#22823;&#22411;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper details the process of developing the first native large generative language model for the Nordic languages, GPT-SW3. We cover all parts of the development process, from data collection and processing, training configuration and instruction finetuning, to evaluation and considerations for release strategies. We hope that this paper can serve as a guide and reference for other researchers that undertake the development of large generative models for smaller languages.
&lt;/p&gt;</description></item></channel></rss>