<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25512;&#29702;&#20219;&#21153;&#20998;&#35299;&#20026;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#21644;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#30340;&#31574;&#30053;&#65292;&#21457;&#29616;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#30456;&#27604;&#38382;&#39064;&#35299;&#20915;&#26356;&#23481;&#26131;&#25552;&#28860;&#20026;&#36739;&#23567;&#27169;&#22411;&#65292;&#24182;&#35777;&#23454;&#35813;&#31574;&#30053;&#32988;&#36807;&#21333;&#38454;&#27573;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.15000</link><description>&lt;p&gt;
&#21010;&#20998;&#36824;&#26159;&#24449;&#26381;&#65311;&#20320;&#24212;&#35813;&#25552;&#28860;LLM&#30340;&#21738;&#19968;&#37096;&#20998;&#65311;
&lt;/p&gt;
&lt;p&gt;
Divide-or-Conquer? Which Part Should You Distill Your LLM?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25512;&#29702;&#20219;&#21153;&#20998;&#35299;&#20026;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#21644;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#30340;&#31574;&#30053;&#65292;&#21457;&#29616;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#30456;&#27604;&#38382;&#39064;&#35299;&#20915;&#26356;&#23481;&#26131;&#25552;&#28860;&#20026;&#36739;&#23567;&#27169;&#22411;&#65292;&#24182;&#35777;&#23454;&#35813;&#31574;&#30053;&#32988;&#36807;&#21333;&#38454;&#27573;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#34987;&#40723;&#21169;&#20808;&#35299;&#20915;&#20027;&#35201;&#20219;&#21153;&#30340;&#23376;&#20219;&#21153;&#26102;&#21487;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#25512;&#29702;&#20219;&#21153;&#12290;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#31867;&#20284;&#30340;&#31574;&#30053;&#65292;&#23558;&#25512;&#29702;&#20219;&#21153;&#20998;&#35299;&#20026;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#21644;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#65292;&#24182;&#23637;&#31034;&#35813;&#31574;&#30053;&#33021;&#22815;&#32988;&#36807;&#21333;&#38454;&#27573;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20551;&#35774;&#19982;&#35299;&#20915;&#38382;&#39064;&#30456;&#27604;&#65292;&#20998;&#35299;&#38454;&#27573;&#26356;&#23481;&#26131;&#34987;&#25552;&#28860;&#20026;&#36739;&#23567;&#30340;&#27169;&#22411;&#65292;&#22240;&#20026;&#21518;&#32773;&#38656;&#35201;&#22823;&#37327;&#30340;&#39046;&#22495;&#30693;&#35782;&#65292;&#32780;&#21069;&#32773;&#21482;&#38656;&#35201;&#23398;&#20064;&#19968;&#33324;&#30340;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25552;&#28860;&#36825;&#20004;&#31181;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#23545;&#25512;&#29702;&#32467;&#26524;&#21644;&#25512;&#29702;&#25104;&#26412;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#21487;&#20197;&#25552;&#28860;&#38382;&#39064;&#20998;&#35299;&#38454;&#27573;&#65292;&#24182;&#21516;&#26102;&#22312;&#20219;&#21153;&#12289;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#20043;&#38388;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#12290;&#28982;&#32780;&#65292;&#35201;&#25552;&#28860;&#38382;&#39064;&#35299;&#20915;&#38454;&#27573;&#23601;&#26356;&#22256;&#38590;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15000v1 Announce Type: new  Abstract: Recent methods have demonstrated that Large Language Models (LLMs) can solve reasoning tasks better when they are encouraged to solve subtasks of the main task first. In this paper we devise a similar strategy that breaks down reasoning tasks into a problem decomposition phase and a problem solving phase and show that the strategy is able to outperform a single stage solution. Further, we hypothesize that the decomposition should be easier to distill into a smaller model compared to the problem solving because the latter requires large amounts of domain knowledge while the former only requires learning general problem solving strategies. We propose methods to distill these two capabilities and evaluate their impact on reasoning outcomes and inference cost. We find that we can distill the problem decomposition phase and at the same time achieve good generalization across tasks, datasets, and models. However, it is harder to distill the pr
&lt;/p&gt;</description></item><item><title>&#31532;&#19968;&#23626;&#27169;&#25311;&#23545;&#35805;&#26234;&#33021;&#30740;&#35752;&#20250;&#30340;&#30446;&#26631;&#26159;&#27719;&#38598;&#23545;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#30740;&#31350;&#36827;&#34892;&#23454;&#26102;&#20154;&#31867;&#35780;&#20272;&#30340;&#27169;&#25311;&#26234;&#33021;&#23545;&#35805;&#27169;&#22411;&#12290;&#35770;&#25991;&#20027;&#35201;&#25552;&#20379;&#20102;&#20849;&#20139;&#20219;&#21153;&#30340;&#27010;&#36848;&#65292;&#24182;&#38468;&#19978;&#20102;&#19968;&#20010;&#23558;&#22312;&#30740;&#35752;&#20250;&#21518;&#21457;&#24067;&#30340;&#28145;&#20837;&#20998;&#26512;&#20849;&#20139;&#20219;&#21153;&#32467;&#26524;&#30340;&#38142;&#25509;&#12290;</title><link>https://arxiv.org/abs/2402.06420</link><description>&lt;p&gt;
&#31532;&#19968;&#23626;&#27169;&#25311;&#23545;&#35805;&#26234;&#33021;&#30740;&#35752;&#20250;&#30340;&#30740;&#31350;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Findings of the First Workshop on Simulating Conversational Intelligence in Chat
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06420
&lt;/p&gt;
&lt;p&gt;
&#31532;&#19968;&#23626;&#27169;&#25311;&#23545;&#35805;&#26234;&#33021;&#30740;&#35752;&#20250;&#30340;&#30446;&#26631;&#26159;&#27719;&#38598;&#23545;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#30740;&#31350;&#36827;&#34892;&#23454;&#26102;&#20154;&#31867;&#35780;&#20272;&#30340;&#27169;&#25311;&#26234;&#33021;&#23545;&#35805;&#27169;&#22411;&#12290;&#35770;&#25991;&#20027;&#35201;&#25552;&#20379;&#20102;&#20849;&#20139;&#20219;&#21153;&#30340;&#27010;&#36848;&#65292;&#24182;&#38468;&#19978;&#20102;&#19968;&#20010;&#23558;&#22312;&#30740;&#35752;&#20250;&#21518;&#21457;&#24067;&#30340;&#28145;&#20837;&#20998;&#26512;&#20849;&#20139;&#20219;&#21153;&#32467;&#26524;&#30340;&#38142;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#35752;&#20250;&#26088;&#22312;&#27719;&#38598;&#20174;&#20107;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#30740;&#31350;&#30340;&#19987;&#23478;&#12290;&#22312;&#36825;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#30740;&#31350;&#39046;&#22495;&#20013;&#20173;&#28982;&#23384;&#22312;&#35768;&#22810;&#25361;&#25112;&#65292;&#22914;&#20174;&#23545;&#35805;&#20013;&#23398;&#20064;&#20449;&#24687;&#12289;&#36827;&#34892;&#30495;&#23454;&#21644;&#20196;&#20154;&#20449;&#26381;&#30340;&#20154;&#24037;&#26234;&#33021;&#21644;&#25512;&#29702;&#27169;&#25311;&#12290;SCI-CHAT&#26159;&#20043;&#21069;&#20851;&#20110;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#30340;&#30740;&#35752;&#20250;&#30340;&#24310;&#32493;&#65292;&#20294;&#30528;&#37325;&#20110;&#27169;&#25311;&#26234;&#33021;&#23545;&#35805;&#65292;&#24182;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#26469;&#21028;&#26029;&#20854;&#36136;&#37327;&#12290;&#27169;&#22411;&#30340;&#30446;&#26631;&#26159;&#22312;&#22810;&#36718;&#23545;&#35805;&#20013;&#33021;&#22815;&#36319;&#38543;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20027;&#39064;&#65292;&#21516;&#26102;&#25552;&#20986;&#12289;&#21453;&#39539;&#21644;&#25512;&#29702;&#35770;&#35777;&#12290;&#35813;&#30740;&#35752;&#20250;&#21253;&#25324;&#30740;&#31350;&#36335;&#24452;&#21644;&#20849;&#20139;&#20219;&#21153;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#27010;&#36848;&#20849;&#20139;&#20219;&#21153;&#65292;&#24182;&#25552;&#20379;&#19968;&#20010;&#38142;&#25509;&#65292;&#38142;&#25509;&#23558;&#21253;&#21547;&#22312;&#30740;&#35752;&#20250;&#19978;&#23637;&#31034;&#21518;&#23545;&#20849;&#20139;&#20219;&#21153;&#32467;&#26524;&#36827;&#34892;&#28145;&#20837;&#20998;&#26512;&#30340;&#21478;&#19968;&#31687;&#35770;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;
The aim of this workshop is to bring together experts working on open-domain dialogue research. In this speedily advancing research area many challenges still exist, such as learning information from conversations, engaging in realistic and convincing simulation of human intelligence and reasoning. SCI-CHAT follows previous workshops on open domain dialogue but with a focus on the simulation of intelligent conversation as judged in a live human evaluation. Models aim to include the ability to follow a challenging topic over a multi-turn conversation, while positing, refuting and reasoning over arguments. The workshop included both a research track and shared task. The main goal of this paper is to provide an overview of the shared task and a link to an additional paper that will include an in depth analysis of the shared task results following presentation at the workshop.
&lt;/p&gt;</description></item><item><title>&#35768;&#22810;&#30740;&#31350;&#20851;&#27880;&#20110;&#22914;&#20309;&#24341;&#23548;&#21644;&#32467;&#26500;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#20851;&#27880;&#20110;&#36755;&#20837;&#38382;&#39064;&#26412;&#36523;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#37325;&#26032;&#38405;&#35835;&#8221;&#30340;&#25552;&#31034;&#31574;&#30053;&#65292;&#36890;&#36807;&#28145;&#20837;&#38405;&#35835;&#36755;&#20837;&#25552;&#31034;&#20013;&#30340;&#38382;&#39064;&#20449;&#24687;&#65292;&#25552;&#20379;&#20102;&#26356;&#28145;&#20837;&#30340;&#27934;&#23519;&#12289;&#26356;&#20934;&#30830;&#30340;&#27169;&#24335;&#35782;&#21035;&#21644;&#26356;&#26377;&#25928;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.06275</link><description>&lt;p&gt;
&#37325;&#26032;&#38405;&#35835;&#25913;&#21892;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Re-Reading Improves Reasoning in Language Models. (arXiv:2309.06275v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06275
&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#30740;&#31350;&#20851;&#27880;&#20110;&#22914;&#20309;&#24341;&#23548;&#21644;&#32467;&#26500;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#20851;&#27880;&#20110;&#36755;&#20837;&#38382;&#39064;&#26412;&#36523;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#37325;&#26032;&#38405;&#35835;&#8221;&#30340;&#25552;&#31034;&#31574;&#30053;&#65292;&#36890;&#36807;&#28145;&#20837;&#38405;&#35835;&#36755;&#20837;&#25552;&#31034;&#20013;&#30340;&#38382;&#39064;&#20449;&#24687;&#65292;&#25552;&#20379;&#20102;&#26356;&#28145;&#20837;&#30340;&#27934;&#23519;&#12289;&#26356;&#20934;&#30830;&#30340;&#27169;&#24335;&#35782;&#21035;&#21644;&#26356;&#26377;&#25928;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#29702;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26159;&#19968;&#20010;&#37325;&#35201;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#30446;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24320;&#21457;&#22810;&#26679;&#21270;&#30340;&#25552;&#31034;&#31574;&#30053;&#65292;&#20197;&#24341;&#23548;&#21644;&#32467;&#26500;&#21270;LLM&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22522;&#20110;&#20165;&#35299;&#30721;&#30340;&#22240;&#26524;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#36890;&#24120;&#22312;&#21333;&#20010;&#21069;&#21521;&#20256;&#36882;&#20013;&#25805;&#20316;&#36755;&#20837;&#38382;&#39064;&#65292;&#21487;&#33021;&#20250;&#24573;&#30053;&#20154;&#31867;&#25512;&#29702;&#20013;&#20016;&#23500;&#30340;&#21069;&#21518;&#20132;&#20114;&#12290;&#23545;&#20110;&#23884;&#20837;&#22312;&#25552;&#31034;&#20013;&#30340;&#36755;&#20837;&#38382;&#39064;&#36825;&#19968;&#20851;&#38190;&#32500;&#24230;&#65292;&#30446;&#21069;&#20851;&#27880;&#36739;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#39640;&#25928;&#30340;&#25552;&#31034;&#31574;&#30053;&#65292;&#31216;&#20026;&#8220;&#37325;&#26032;&#38405;&#35835;&#8221;&#12290;&#20174;&#20154;&#31867;&#23398;&#20064;&#21644;&#38382;&#39064;&#35299;&#20915;&#20013;&#27762;&#21462;&#28789;&#24863;&#65292;&#37325;&#26032;&#38405;&#35835;&#24847;&#21619;&#30528;&#37325;&#35775;&#23884;&#22312;&#36755;&#20837;&#25552;&#31034;&#20013;&#30340;&#38382;&#39064;&#20449;&#24687;&#12290;&#36825;&#31181;&#26041;&#27861;&#19982;&#35748;&#30693;&#22686;&#24378;&#30340;&#21407;&#21017;&#23436;&#32654;&#22865;&#21512;&#65292;&#20351;LLM&#33021;&#22815;&#28145;&#20837;&#27934;&#23519;&#12289;&#35782;&#21035;&#22797;&#26434;&#30340;&#27169;&#24335;&#12289;&#24314;&#31435; mor
&lt;/p&gt;
&lt;p&gt;
Reasoning presents a significant and challenging issue for Large Language Models (LLMs). The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs. However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning. Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts. In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question "re-reading". Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts. This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish mor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21021;&#27493;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;&#24320;&#25918;&#22495;&#38382;&#31572;&#20219;&#21153;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#26174;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#34920;&#29616;&#20986;&#33258;&#20449;&#65292;&#24182;&#19988;&#22238;&#31572;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2307.11019</link><description>&lt;p&gt;
&#29992;&#26816;&#32034;&#22686;&#24378;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation. (arXiv:2307.11019v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21021;&#27493;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;&#24320;&#25918;&#22495;&#38382;&#31572;&#20219;&#21153;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#26174;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#34920;&#29616;&#20986;&#33258;&#20449;&#65292;&#24182;&#19988;&#22238;&#31572;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#65288;&#20363;&#22914;&#65292;&#24320;&#25918;&#22495;&#38382;&#31572;&#65288;QA&#65289;&#65289;&#38656;&#35201;&#22823;&#37327;&#30340;&#20107;&#23454;&#30693;&#35782;&#65292;&#24182;&#32463;&#24120;&#20381;&#36182;&#22806;&#37096;&#20449;&#24687;&#36827;&#34892;&#21327;&#21161;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65288;&#20363;&#22914;&#65292;ChatGPT&#65289;&#22312;&#35299;&#20915;&#21253;&#25324;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#22312;&#20869;&#30340;&#21508;&#31181;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;LLMs&#22312;&#24863;&#30693;&#20854;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#26041;&#38754;&#34920;&#29616;&#22914;&#20309;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#26102;&#30340;&#34892;&#20026;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;LLMs&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#36827;&#34892;&#20102;&#21021;&#27493;&#20998;&#26512;&#65292;&#24182;&#30740;&#31350;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;LLMs&#22312;&#24320;&#25918;&#22495;QA&#19978;&#30340;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#20102;&#19977;&#20010;&#20027;&#35201;&#30740;&#31350;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26816;&#26597;LLMs&#30340;QA&#24615;&#33021;&#12289;&#20808;&#39564;&#21028;&#26029;&#21644;&#21518;&#39564;&#21028;&#26029;&#26469;&#36827;&#34892;&#20998;&#26512;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;LLMs&#23545;&#20110;&#33258;&#24049;&#22238;&#31572;&#38382;&#39064;&#30340;&#33021;&#21147;&#21644;&#22238;&#31572;&#30340;&#20934;&#30830;&#24615;&#20805;&#28385;&#20102;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require a substantial amount of factual knowledge and often rely on external information for assistance. Recently, large language models (LLMs) (e.g., ChatGPT), have demonstrated impressive prowess in solving a wide range of tasks with world knowledge, including knowledge-intensive tasks. However, it remains unclear how well LLMs are able to perceive their factual knowledge boundaries, particularly how they behave when incorporating retrieval augmentation. In this study, we present an initial analysis of the factual knowledge boundaries of LLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially, we focus on three primary research questions and analyze them by examining QA performance, priori judgement and posteriori judgement of LLMs. We show evidence that LLMs possess unwavering confidence in their capabilities to respond to questions and the accuracy of their responses. Furthermore, retrieval 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#21457;&#24067;&#20102;MMSMR&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;8&#20010;&#21442;&#32771;&#23545;&#35805;&#65292;&#26088;&#22312;&#20419;&#36827;&#23545;&#35805;&#24230;&#37327;&#21644;&#35780;&#20272;&#30340;&#26410;&#26469;&#24037;&#20316;&#12290;&#35813;&#30740;&#31350;&#20351;&#29992;1750&#20010;&#31995;&#32479;&#23545;&#20854;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#20197;&#20102;&#35299;&#31283;&#20581;&#30456;&#20851;&#24615;&#24182;&#20102;&#35299;&#27979;&#35797;&#38598;&#20013;&#25152;&#38656;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2305.14533</link><description>&lt;p&gt;
&#22914;&#20309;&#36873;&#25321;&#24744;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65306;&#29992;&#20110;&#23545;&#35805;&#25351;&#26631;&#35780;&#20272;&#30340;&#22823;&#35268;&#27169;&#22810;&#31995;&#32479;&#22810;&#21442;&#32771;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
How to Choose How to Choose Your Chatbot: A Massively Multi-System MultiReference Data Set for Dialog Metric Evaluation. (arXiv:2305.14533v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14533
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21457;&#24067;&#20102;MMSMR&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;8&#20010;&#21442;&#32771;&#23545;&#35805;&#65292;&#26088;&#22312;&#20419;&#36827;&#23545;&#35805;&#24230;&#37327;&#21644;&#35780;&#20272;&#30340;&#26410;&#26469;&#24037;&#20316;&#12290;&#35813;&#30740;&#31350;&#20351;&#29992;1750&#20010;&#31995;&#32479;&#23545;&#20854;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#20197;&#20102;&#35299;&#31283;&#20581;&#30456;&#20851;&#24615;&#24182;&#20102;&#35299;&#27979;&#35797;&#38598;&#20013;&#25152;&#38656;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21457;&#24067;&#20102;MMSMR&#65292;&#36825;&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#22810;&#31995;&#32479;&#22810;&#21442;&#32771;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#20419;&#36827;&#23545;&#35805;&#30340;&#24230;&#37327;&#21644;&#35780;&#20272;&#30340;&#26410;&#26469;&#24037;&#20316;&#12290;&#29992;&#20110;&#23545;&#35805;&#35780;&#20272;&#30340;&#33258;&#21160;&#25351;&#26631;&#24212;&#35813;&#26159;&#20154;&#31867;&#21028;&#26029;&#30340;&#21487;&#38752;&#20195;&#29702;&#65307;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20854;&#31283;&#20581;&#24615;&#30340;&#39564;&#35777;&#36824;&#36828;&#36828;&#19981;&#22815;&#20196;&#20154;&#28385;&#24847;&#12290;&#20026;&#20102;&#37327;&#21270;&#31283;&#20581;&#24615;&#30456;&#20851;&#24615;&#24182;&#20102;&#35299;&#27979;&#35797;&#38598;&#20013;&#25152;&#38656;&#30340;&#20869;&#23481;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#21333;&#21442;&#32771;&#35780;&#20272;&#38598;&#65292;&#25512;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;8&#20010;&#21442;&#32771;&#23545;&#35805;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#20171;&#32461;&#20102;&#36825;&#20010;&#26032;&#30340;&#35821;&#35328;&#23398;&#20064;&#23545;&#35805;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#25105;&#20204;&#35757;&#32451;&#20102;1750&#20010;&#31995;&#32479;&#65292;&#24182;&#22312;&#25105;&#20204;&#30340;&#26032;&#27979;&#35797;&#38598;&#21644;DailyDialog&#25968;&#25454;&#38598;&#19978;&#23545;&#23427;&#20204;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#36825;&#20010;&#26032;&#30340;&#27979;&#35797;&#38598;&#65292;&#20197;&#21450;&#27599;&#20010;&#31995;&#32479;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#27169;&#22411;&#36229;&#21442;&#25968;&#12289;&#25512;&#29702;&#36755;&#20986;&#21644;&#25351;&#26631;&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We release MMSMR, a Massively Multi-System MultiReference dataset to enable future work on metrics and evaluation for dialog. Automatic metrics for dialogue evaluation should be robust proxies for human judgments; however, the verification of robustness is currently far from satisfactory. To quantify the robustness correlation and understand what is necessary in a test set, we create and release an 8-reference dialog dataset by extending single-reference evaluation sets and introduce this new language learning conversation dataset. We then train 1750 systems and evaluate them on our novel test set and the DailyDialog dataset. We release the novel test set, and model hyper parameters, inference outputs, and metric scores for each system on a variety of datasets.
&lt;/p&gt;</description></item></channel></rss>