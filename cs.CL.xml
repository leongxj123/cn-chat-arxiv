<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797; NoFunEval&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#38750;&#21151;&#33021;&#24615;&#35201;&#27714;&#21644;&#31616;&#21333;&#20998;&#31867;&#23454;&#20363;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#30446;&#21069;&#30340;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#36825;&#20123;&#35201;&#27714;&#26102;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#30450;&#28857;&#12290;</title><link>https://rss.arxiv.org/abs/2401.15963</link><description>&lt;p&gt;
NoFunEval: &#26377;&#36259;&#30340;&#26159;&#65292;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#36229;&#20986;&#21151;&#33021;&#27491;&#30830;&#24615;&#30340;&#35201;&#27714;&#19978;&#36935;&#21040;&#22256;&#38590;
&lt;/p&gt;
&lt;p&gt;
NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2401.15963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797; NoFunEval&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#38750;&#21151;&#33021;&#24615;&#35201;&#27714;&#21644;&#31616;&#21333;&#20998;&#31867;&#23454;&#20363;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#30446;&#21069;&#30340;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#36825;&#20123;&#35201;&#27714;&#26102;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#30450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#65288;code LMs&#65289;&#30340;&#35780;&#20272;&#22522;&#20934;&#20960;&#20046;&#23436;&#20840;&#38598;&#20013;&#22312;LMs&#26159;&#21542;&#33021;&#22815;&#29983;&#25104;&#21151;&#33021;&#27491;&#30830;&#30340;&#20195;&#30721;&#19978;&#12290;&#22312;&#23454;&#38469;&#30340;&#36719;&#20214;&#24037;&#31243;&#20013;&#65292;&#24320;&#21457;&#20154;&#21592;&#20250;&#32771;&#34385;&#36229;&#20986;&#21151;&#33021;&#27491;&#30830;&#24615;&#30340;&#35201;&#27714;&#12290;&#20182;&#20204;&#23545;&#20110;&#8220;&#22914;&#20309;&#8221;&#23454;&#29616;&#21151;&#33021;&#26377;&#30528;&#23545;&#25972;&#20307;&#31995;&#32479;&#35774;&#35745;&#30446;&#26631;&#65288;&#22914;&#25928;&#29575;&#12289;&#23433;&#20840;&#24615;&#21644;&#21487;&#32500;&#25252;&#24615;&#65289;&#30340;&#35201;&#27714;&#12290;&#22914;&#26524;LMs&#33021;&#22815;&#23637;&#31034;&#23545;&#35201;&#27714;&#21644;&#20195;&#30721;&#35821;&#20041;&#30340;&#24378;&#22823;&#29702;&#35299;&#33021;&#21147;&#65292;&#20182;&#20204;&#20063;&#20250;&#26356;&#21152;&#20449;&#20219;&#36825;&#20123;LMs&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;NoFunEval&#26469;&#35780;&#20272;&#20195;&#30721;LMs&#22312;&#38750;&#21151;&#33021;&#24615;&#35201;&#27714;&#21644;&#31616;&#21333;&#20998;&#31867;&#23454;&#20363;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#26041;&#27861;Coding Concepts (CoCo)&#65292;&#21487;&#20197;&#29992;&#20110;&#24320;&#21457;&#20154;&#21592;&#21521;LMs&#20256;&#36798;&#39046;&#22495;&#30693;&#35782;&#12290;&#25105;&#20204;&#23545;22&#20010;&#20195;&#30721;LMs&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#26222;&#36941;&#34920;&#29616;&#19981;&#20339;&#65292;&#26263;&#31034;&#30528;&#23427;&#20204;&#22312;&#22788;&#29702;&#36825;&#20123;&#38382;&#39064;&#26102;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#30450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing evaluation benchmarks of language models of code (code LMs) focus almost exclusively on whether the LMs can generate functionally-correct code. In real-world software engineering, developers think beyond functional correctness. They have requirements on "how" a functionality should be implemented to meet overall system design objectives like efficiency, security, and maintainability. They would also trust the code LMs more if the LMs demonstrate robust understanding of requirements and code semantics.   We propose a new benchmark NoFunEval to evaluate code LMs on non-functional requirements and simple classification instances for both functional and non-functional requirements. We propose a prompting method, Coding Concepts (CoCo), as a way for a developer to communicate the domain knowledge to the LMs. We conduct an extensive evaluation of twenty-two code LMs. Our finding is that they generally falter when tested on our benchmark, hinting at fundamental blindspots in their tr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#23545;LLM&#29983;&#25104;&#30340;&#34394;&#26500;&#20070;&#31821;&#25688;&#35201;&#36827;&#34892;&#20102;&#24544;&#23454;&#24615;&#21644;&#20869;&#23481;&#36873;&#25321;&#30340;&#22823;&#35268;&#27169;&#20154;&#31867;&#35780;&#20272;&#65292;&#24314;&#31435;&#20102;FABLES&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#23545;26&#26412;&#20070;&#30340;3158&#20010;&#22768;&#26126;&#36827;&#34892;&#20102;&#27880;&#37322;&#65292;&#25104;&#21151;&#23545;LLM&#25688;&#35201;&#36827;&#34892;&#20102;&#22522;&#20110;&#24544;&#23454;&#24615;&#30340;&#25490;&#21517;</title><link>https://arxiv.org/abs/2404.01261</link><description>&lt;p&gt;
FABLES&#65306;&#35780;&#20272;&#20070;&#31821;&#25688;&#35201;&#20013;&#30340;&#24544;&#23454;&#24615;&#21644;&#20869;&#23481;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
FABLES: Evaluating faithfulness and content selection in book-length summarization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#23545;LLM&#29983;&#25104;&#30340;&#34394;&#26500;&#20070;&#31821;&#25688;&#35201;&#36827;&#34892;&#20102;&#24544;&#23454;&#24615;&#21644;&#20869;&#23481;&#36873;&#25321;&#30340;&#22823;&#35268;&#27169;&#20154;&#31867;&#35780;&#20272;&#65292;&#24314;&#31435;&#20102;FABLES&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#23545;26&#26412;&#20070;&#30340;3158&#20010;&#22768;&#26126;&#36827;&#34892;&#20102;&#27880;&#37322;&#65292;&#25104;&#21151;&#23545;LLM&#25688;&#35201;&#36827;&#34892;&#20102;&#22522;&#20110;&#24544;&#23454;&#24615;&#30340;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#38271;&#25991;&#26412;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25216;&#26415;&#19978;&#21487;&#20197;&#24635;&#32467;&#38271;&#36798;100K&#20010;&#26631;&#35760;&#30340;&#20070;&#31821;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;&#25991;&#26723;&#30340;&#38271;&#24230;&#21644;&#22797;&#26434;&#24615;&#38459;&#30861;&#20102;&#23545;&#24544;&#23454;&#24615;&#31561;&#36755;&#20837;&#30456;&#20851;&#26041;&#38754;&#30340;&#35780;&#20272;&#12290;&#26412;&#25991;&#22312;&#34394;&#26500;&#20070;&#31821;&#30340;LLM&#29983;&#25104;&#25688;&#35201;&#19978;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#20154;&#31867;&#35780;&#20272;&#65292;&#36890;&#36807;&#19987;&#27880;&#20110;2023&#25110;2024&#24180;&#20986;&#29256;&#30340;&#20070;&#31821;&#25688;&#35201;&#65292;&#38599;&#20323;&#22312;&#36827;&#34892;&#27880;&#37322;&#20219;&#21153;&#20043;&#21069;&#24050;&#23436;&#20840;&#38405;&#35835;&#27599;&#26412;&#20070;&#30340;&#27880;&#37322;&#32773;&#26469;&#20943;&#23569;&#25104;&#26412;&#21644;&#35748;&#30693;&#36127;&#25285;&#65292;&#20174;&#32780;&#32531;&#35299;&#20102;&#25968;&#25454;&#27745;&#26579;&#38382;&#39064;&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;FABLES&#25968;&#25454;&#38598;&#65292;&#23545;26&#26412;&#20070;&#30340;LLM&#29983;&#25104;&#25688;&#35201;&#20013;&#30340;3158&#20010;&#22768;&#26126;&#36827;&#34892;&#20102;&#27880;&#37322;&#65292;&#33457;&#36153;&#20102;5200&#32654;&#20803;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22522;&#20110;&#24544;&#23454;&#24615;&#23545;LLM&#25688;&#35201;&#36827;&#34892;&#25490;&#21517;&#65306;Claude-3-Opus&#22312;&#24544;&#23454;&#24615;&#26041;&#38754;&#26126;&#26174;&#20248;&#20110;&#25152;&#26377;&#38381;&#28304;LLMs&#65292;&#32780;&#24320;&#28304;&#30340;Mixtral&#19982;GPT-3.5-Turbo&#25345;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01261v1 Announce Type: cross  Abstract: While long-context large language models (LLMs) can technically summarize book-length documents (&gt;100K tokens), the length and complexity of the documents have so far prohibited evaluations of input-dependent aspects like faithfulness. In this paper, we conduct the first large-scale human evaluation of faithfulness and content selection on LLM-generated summaries of fictional books. Our study mitigates the issue of data contamination by focusing on summaries of books published in 2023 or 2024, and we hire annotators who have fully read each book prior to the annotation task to minimize cost and cognitive burden. We collect FABLES, a dataset of annotations on 3,158 claims made in LLM-generated summaries of 26 books, at a cost of $5.2K USD, which allows us to rank LLM summarizers based on faithfulness: Claude-3-Opus significantly outperforms all closed-source LLMs, while the open-source Mixtral is on par with GPT-3.5-Turbo. An analysis o
&lt;/p&gt;</description></item><item><title>Tastle&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#36234;&#29425;&#26694;&#26550;&#65292;&#37319;&#29992;&#24694;&#24847;&#20869;&#23481;&#38544;&#34255;&#21644;&#20869;&#23384;&#37325;&#26500;&#20197;&#21450;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2403.08424</link><description>&lt;p&gt;
Tastle: &#20026;&#33258;&#21160;&#36234;&#29425;&#25915;&#20987;&#24178;&#25200;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tastle: Distract Large Language Models for Automatic Jailbreak Attack
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08424
&lt;/p&gt;
&lt;p&gt;
Tastle&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#36234;&#29425;&#26694;&#26550;&#65292;&#37319;&#29992;&#24694;&#24847;&#20869;&#23481;&#38544;&#34255;&#21644;&#20869;&#23384;&#37325;&#26500;&#20197;&#21450;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#22312;LLMs&#20844;&#24320;&#21457;&#24067;&#20043;&#21069;&#65292;&#20154;&#20204;&#24050;&#32463;&#20570;&#20986;&#20102;&#22823;&#37327;&#21162;&#21147;&#26469;&#23558;&#23427;&#20204;&#30340;&#34892;&#20026;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#12290;&#23545;&#40784;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#30830;&#20445;&#23427;&#20204;&#30340;&#26377;&#30410;&#24615;&#12289;&#35802;&#23454;&#24615;&#21644;&#26080;&#23475;&#24615;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#32463;&#36807;&#32454;&#33268;&#23545;&#40784;&#30340;LLMs&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#24694;&#24847;&#25805;&#32437;&#65292;&#22914;&#36234;&#29425;&#65292;&#23548;&#33268;&#24847;&#22806;&#30340;&#34892;&#20026;&#12290;&#36234;&#29425;&#26159;&#26377;&#24847;&#24320;&#21457;&#24694;&#24847;&#25552;&#31034;&#65292;&#20174;LLM&#23433;&#20840;&#38480;&#21046;&#20013;&#36867;&#33073;&#20197;&#29983;&#25104;&#26410;&#32463;&#23457;&#26597;&#30340;&#26377;&#23475;&#20869;&#23481;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#36234;&#29425;&#26041;&#27861;&#26469;&#23545;LLMs&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#65292;&#20294;&#23427;&#20204;&#22312;&#25928;&#26524;&#21644;&#21487;&#20280;&#32553;&#24615;&#26041;&#38754;&#36935;&#21040;&#20102;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Tastle&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#36234;&#29425;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#23545;LLMs&#36827;&#34892;&#32418;&#38431;&#25915;&#20987;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#24694;&#24847;&#20869;&#23481;&#38544;&#34255;&#21644;&#20869;&#23384;&#37325;&#26500;&#65292;&#24182;&#32467;&#21512;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#26469;&#36234;&#29425;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08424v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved significant advances in recent days. Extensive efforts have been made before the public release of LLMs to align their behaviors with human values. The primary goal of alignment is to ensure their helpfulness, honesty and harmlessness. However, even meticulously aligned LLMs remain vulnerable to malicious manipulations such as jailbreaking, leading to unintended behaviors. The jailbreak is to intentionally develop a malicious prompt that escapes from the LLM security restrictions to produce uncensored detrimental contents. Previous works explore different jailbreak methods for red teaming LLMs, yet they encounter challenges regarding to effectiveness and scalability. In this work, we propose Tastle, a novel black-box jailbreak framework for automated red teaming of LLMs. We designed malicious content concealing and memory reframing with an iterative optimization algorithm to jailbreak LLMs, mo
&lt;/p&gt;</description></item><item><title>VidProM&#26159;&#19968;&#20010;&#21253;&#21547;167&#19975;&#20010;&#29420;&#29305;&#25991;&#26412;&#21040;&#35270;&#39057;&#25552;&#31034;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#23545;&#20110;&#25991;&#26412;&#21040;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#24102;&#26469;&#20102;&#26032;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#25581;&#31034;&#20102;&#30495;&#23454;&#29992;&#25143;&#25552;&#31034;&#23545;&#35270;&#39057;&#29983;&#25104;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.06098</link><description>&lt;p&gt;
VidProM&#65306;&#19968;&#20010;&#30334;&#19975;&#35268;&#27169;&#30340;&#30495;&#23454;&#21363;&#26102;&#22270;&#24211;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#25991;&#26412;&#21040;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06098
&lt;/p&gt;
&lt;p&gt;
VidProM&#26159;&#19968;&#20010;&#21253;&#21547;167&#19975;&#20010;&#29420;&#29305;&#25991;&#26412;&#21040;&#35270;&#39057;&#25552;&#31034;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#23545;&#20110;&#25991;&#26412;&#21040;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#24102;&#26469;&#20102;&#26032;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#25581;&#31034;&#20102;&#30495;&#23454;&#29992;&#25143;&#25552;&#31034;&#23545;&#35270;&#39057;&#29983;&#25104;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sora&#30340;&#21040;&#26469;&#26631;&#24535;&#30528;&#25991;&#26412;&#21040;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26102;&#20195;&#30340;&#21040;&#26469;&#65292;&#24102;&#26469;&#20102;&#35270;&#39057;&#29983;&#25104;&#21644;&#28508;&#22312;&#24212;&#29992;&#26041;&#38754;&#30340;&#26174;&#33879;&#36827;&#27493;&#12290;&#28982;&#32780;&#65292;Sora&#20197;&#21450;&#20854;&#20182;&#25991;&#26412;&#21040;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#39640;&#24230;&#20381;&#36182;&#25552;&#31034;&#65292;&#20294;&#30446;&#21069;&#23578;&#27809;&#26377;&#20844;&#24320;&#21487;&#29992;&#30340;&#21253;&#21547;&#25991;&#26412;&#21040;&#35270;&#39057;&#25552;&#31034;&#30740;&#31350;&#30340;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;VidProM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#30001;167&#19975;&#20010;&#26469;&#33258;&#30495;&#23454;&#29992;&#25143;&#30340;&#29420;&#29305;&#25991;&#26412;&#21040;&#35270;&#39057;&#25552;&#31034;&#32452;&#25104;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#27492;&#22806;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;&#30001;&#22235;&#31181;&#26368;&#20808;&#36827;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;669&#19975;&#20010;&#35270;&#39057;&#20197;&#21450;&#19968;&#20123;&#30456;&#20851;&#25968;&#25454;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#36825;&#19968;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#31574;&#23637;&#36807;&#31243;&#65292;&#36825;&#26159;&#19968;&#20010;&#32791;&#26102;&#19988;&#26114;&#36149;&#30340;&#36807;&#31243;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;VidProM&#19982;DiffusionDB&#20043;&#38388;&#30340;&#21306;&#21035;&#65292;&#21518;&#32773;&#26159;&#19968;&#20010;&#29992;&#20110;&#22270;&#20687;&#29983;&#25104;&#30340;&#22823;&#35268;&#27169;&#25552;&#31034;&#22270;&#24211;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#23545;&#36825;&#20123;&#25552;&#31034;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#19987;&#38376;&#30340;&#26032;&#25552;&#31034;&#25968;&#25454;&#38598;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06098v1 Announce Type: cross  Abstract: The arrival of Sora marks a new era for text-to-video diffusion models, bringing significant advancements in video generation and potential applications. However, Sora, as well as other text-to-video diffusion models, highly relies on the prompts, and there is no publicly available dataset featuring a study of text-to-video prompts. In this paper, we introduce VidProM, the first large-scale dataset comprising 1.67 million unique text-to-video prompts from real users. Additionally, the dataset includes 6.69 million videos generated by four state-of-the-art diffusion models and some related data. We initially demonstrate the curation of this large-scale dataset, which is a time-consuming and costly process. Subsequently, we show how the proposed VidProM differs from DiffusionDB, a large-scale prompt-gallery dataset for image generation. Based on the analysis of these prompts, we identify the necessity for a new prompt dataset specificall
&lt;/p&gt;</description></item><item><title>WaterMax&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#29983;&#25104;&#25991;&#26412;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#25171;&#30772;&#20102;&#27700;&#21360;&#25216;&#26415;&#20013;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#20256;&#32479;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.04808</link><description>&lt;p&gt;
WaterMax: &#25171;&#30772;LLM&#27700;&#21360;&#21487;&#26816;&#27979;&#24615;-&#31283;&#20581;&#24615;-&#36136;&#37327;&#30340;&#24179;&#34913;
&lt;/p&gt;
&lt;p&gt;
WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04808
&lt;/p&gt;
&lt;p&gt;
WaterMax&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27700;&#21360;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#29983;&#25104;&#25991;&#26412;&#36136;&#37327;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#25171;&#30772;&#20102;&#27700;&#21360;&#25216;&#26415;&#20013;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#20256;&#32479;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27700;&#21360;&#26159;&#38459;&#27490;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#24694;&#24847;&#20351;&#29992;&#30340;&#25216;&#26415;&#25163;&#27573;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;WaterMax&#30340;&#26032;&#39062;&#27700;&#21360;&#26041;&#26696;&#65292;&#20855;&#26377;&#39640;&#26816;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#21407;&#22987;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#36136;&#37327;&#12290;&#20854;&#26032;&#35774;&#35745;&#19981;&#20250;&#23545;LLM&#36827;&#34892;&#20219;&#20309;&#20462;&#25913;&#65288;&#19981;&#35843;&#25972;&#26435;&#37325;&#12289;&#23545;&#25968;&#12289;&#28201;&#24230;&#25110;&#37319;&#26679;&#25216;&#26415;&#65289;&#12290;WaterMax&#24179;&#34913;&#20102;&#31283;&#20581;&#24615;&#21644;&#22797;&#26434;&#24615;&#65292;&#19982;&#25991;&#29486;&#20013;&#30340;&#27700;&#21360;&#25216;&#26415;&#30456;&#21453;&#65292;&#20174;&#26681;&#26412;&#19978;&#24341;&#21457;&#20102;&#36136;&#37327;&#21644;&#31283;&#20581;&#24615;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#20854;&#24615;&#33021;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#35777;&#26126;&#24182;&#32463;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;&#22312;&#26368;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#19979;&#65292;&#23427;&#32988;&#36807;&#25152;&#26377;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04808v1 Announce Type: cross  Abstract: Watermarking is a technical means to dissuade malfeasant usage of Large Language Models. This paper proposes a novel watermarking scheme, so-called WaterMax, that enjoys high detectability while sustaining the quality of the generated text of the original LLM. Its new design leaves the LLM untouched (no modification of the weights, logits, temperature, or sampling technique). WaterMax balances robustness and complexity contrary to the watermarking techniques of the literature inherently provoking a trade-off between quality and robustness. Its performance is both theoretically proven and experimentally validated. It outperforms all the SotA techniques under the most complete benchmark suite.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;Distributional Dispreference Optimization (D$^2$O)&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#20154;&#31867;&#27491;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#23545;&#40784;&#65292;&#20943;&#23569;&#20102;&#26377;&#23475;&#20449;&#24687;&#30340;&#20256;&#25773;&#12290;</title><link>https://arxiv.org/abs/2403.03419</link><description>&lt;p&gt;
&#21542;&#23450;&#21542;&#23450;&#65306;&#36890;&#36807;&#20998;&#24067;&#24335;&#21453;&#21916;&#22909;&#20248;&#21270;&#23454;&#29616;&#23545;&#40784;&#32780;&#26080;&#38656;&#20154;&#31867;&#27491;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03419
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;Distributional Dispreference Optimization (D$^2$O)&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#20154;&#31867;&#27491;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#23545;&#40784;&#65292;&#20943;&#23569;&#20102;&#26377;&#23475;&#20449;&#24687;&#30340;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25913;&#21464;&#20102;&#20154;&#24037;&#26234;&#33021;&#30340;&#35282;&#33394;&#65292;&#20294;&#20063;&#21487;&#33021;&#23384;&#22312;&#20256;&#25773;&#19981;&#36947;&#24503;&#20869;&#23481;&#30340;&#28508;&#22312;&#39118;&#38505;&#12290;&#23545;&#40784;&#25216;&#26415;&#34987;&#24341;&#20837;&#20197;&#24341;&#23548;LLM&#26397;&#30528;&#20154;&#31867;&#20559;&#22909;&#26041;&#21521;&#21457;&#23637;&#65292;&#24182;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#23613;&#31649;&#22312;&#36825;&#20010;&#26041;&#21521;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#31361;&#30772;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#39640;&#36136;&#37327;&#30340;&#27491;&#36127;&#35757;&#32451;&#23545;&#65292;&#21463;&#21040;&#22024;&#26434;&#26631;&#31614;&#21644;&#39318;&#36873;&#21644;&#38750;&#39318;&#36873;&#21709;&#24212;&#25968;&#25454;&#20043;&#38388;&#30340;&#36793;&#32536;&#21306;&#21035;&#30340;&#22256;&#25200;&#12290;&#37492;&#20110;&#26368;&#36817;LLM&#22312;&#29983;&#25104;&#26377;&#29992;&#21709;&#24212;&#26041;&#38754;&#30340;&#39640;&#27700;&#24179;&#65292;&#26412;&#25991;&#23558;&#30740;&#31350;&#37325;&#28857;&#36716;&#21521;&#19968;&#20010;&#26032;&#30340;&#26041;&#21521;&#65306;&#20165;&#20351;&#29992;&#20154;&#24037;&#27880;&#37322;&#30340;&#36127;&#26679;&#26412;&#26469;&#23454;&#29616;&#23545;&#40784;&#65292;&#20445;&#30041;&#26377;&#29992;&#24615;&#30340;&#21516;&#26102;&#38477;&#20302;&#26377;&#23475;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#21453;&#21916;&#22909;&#20248;&#21270;&#65288;D$^2$O&#65289;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#29983;&#25104;&#30340;&#21709;&#24212;&#19982;&#38750;&#39318;&#36873;&#21709;&#24212;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#26377;&#25928;&#22320;&#25490;&#38500;&#26377;&#23475;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03419v1 Announce Type: cross  Abstract: Large language models (LLMs) have revolutionized the role of AI, yet also pose potential risks of propagating unethical content. Alignment technologies have been introduced to steer LLMs towards human preference, gaining increasing attention. Despite notable breakthroughs in this direction, existing methods heavily rely on high-quality positive-negative training pairs, suffering from noisy labels and the marginal distinction between preferred and dispreferred response data. Given recent LLMs' proficiency in generating helpful responses, this work pivots towards a new research focus: achieving alignment using solely human-annotated negative samples, preserving helpfulness while reducing harmfulness. For this purpose, we propose Distributional Dispreference Optimization (D$^2$O), which maximizes the discrepancy between the generated responses and the dispreferred ones to effectively eschew harmful information. We theoretically demonstrat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CARE CA&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#36890;&#36807;&#32467;&#21512;&#26174;&#24335;&#22240;&#26524;&#26816;&#27979;&#27169;&#22359;&#21644;&#21453;&#20107;&#23454;&#38472;&#36848;&#12289;&#20197;&#21450;&#38544;&#21547;&#22240;&#26524;&#26816;&#27979;&#27169;&#22359;&#65292;&#26088;&#22312;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.18139</link><description>&lt;p&gt;
&#22240;&#26524;&#20851;&#31995;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30495;&#27491;&#29702;&#35299;&#22240;&#26524;&#20851;&#31995;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Cause and Effect: Can Large Language Models Truly Understand Causality?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CARE CA&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#36890;&#36807;&#32467;&#21512;&#26174;&#24335;&#22240;&#26524;&#26816;&#27979;&#27169;&#22359;&#21644;&#21453;&#20107;&#23454;&#38472;&#36848;&#12289;&#20197;&#21450;&#38544;&#21547;&#22240;&#26524;&#26816;&#27979;&#27169;&#22359;&#65292;&#26088;&#22312;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#65292;&#29702;&#35299;&#23427;&#20204;&#22312;&#35299;&#35835;&#21644;&#35299;&#37322;&#35821;&#35328;&#25152;&#28041;&#21450;&#30340;&#22797;&#26434;&#22240;&#26524;&#20851;&#31995;&#30340;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#20351;&#29992;&#26126;&#30830;&#25110;&#38544;&#21547;&#30340;&#22240;&#26524;&#25512;&#29702;&#65292;&#28982;&#32780;&#36843;&#20999;&#38656;&#35201;&#19968;&#31181;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#23558;&#20004;&#32773;&#32467;&#21512;&#36215;&#26469;&#26356;&#26377;&#25928;&#22320;&#22788;&#29702;&#21508;&#31181;&#22240;&#26524;&#20851;&#31995;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;&#65292;&#31216;&#20026;&#20855;&#26377;&#21453;&#20107;&#23454;&#20998;&#26512;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#25512;&#29702;&#22686;&#24378;&#65288;CARE CA&#65289;&#26694;&#26550;&#65292;&#20197;&#22686;&#24378;&#22240;&#26524;&#25512;&#29702;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558; ConceptNet &#21644;&#21453;&#20107;&#23454;&#38472;&#36848;&#20013;&#30340;&#26126;&#30830;&#22240;&#26524;&#26816;&#27979;&#27169;&#22359;&#20197;&#21450;&#36890;&#36807;LLMs&#36827;&#34892;&#30340;&#38544;&#21547;&#22240;&#26524;&#26816;&#27979;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#19968;&#23618;&#21453;&#20107;&#23454;&#35299;&#37322;&#36827;&#19968;&#27493;&#31361;&#20986;LLMs&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#29702;&#35299;&#12290;ConceptNet &#20013;&#30340;&#30693;&#35782;&#25552;&#39640;&#20102;&#22810;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18139v1 Announce Type: cross  Abstract: With the rise of Large Language Models(LLMs), it has become crucial to understand their capabilities and limitations in deciphering and explaining the complex web of causal relationships that language entails. Current methods use either explicit or implicit causal reasoning, yet there is a strong need for a unified approach combining both to tackle a wide array of causal relationships more effectively. This research proposes a novel architecture called Context Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to enhance causal reasoning and explainability. The proposed framework incorporates an explicit causal detection module with ConceptNet and counterfactual statements, as well as implicit causal detection through LLMs. Our framework goes one step further with a layer of counterfactual explanations to accentuate LLMs understanding of causality. The knowledge from ConceptNet enhances the performance of multi
&lt;/p&gt;</description></item><item><title>AmbigNLG&#26159;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#25351;&#20196;&#27169;&#31946;&#24615;&#25361;&#25112;&#30340;&#26032;&#20219;&#21153;&#65292;&#36890;&#36807;&#35782;&#21035;&#21644;&#20943;&#36731;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#65292;&#25913;&#36827;&#20102;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#65292;&#24182;&#31361;&#20986;&#20102;&#28165;&#26224;&#21644;&#20855;&#20307;&#25351;&#20196;&#22312;&#25552;&#21319;LLM&#22312;NLG&#20219;&#21153;&#20013;&#34920;&#29616;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.17717</link><description>&lt;p&gt;
AmbigNLG: &#35299;&#20915;NLG&#25351;&#20196;&#20013;&#30340;&#20219;&#21153;&#27169;&#31946;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
AmbigNLG: Addressing Task Ambiguity in Instruction for NLG
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17717
&lt;/p&gt;
&lt;p&gt;
AmbigNLG&#26159;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#25351;&#20196;&#27169;&#31946;&#24615;&#25361;&#25112;&#30340;&#26032;&#20219;&#21153;&#65292;&#36890;&#36807;&#35782;&#21035;&#21644;&#20943;&#36731;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#65292;&#25913;&#36827;&#20102;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#65292;&#24182;&#31361;&#20986;&#20102;&#28165;&#26224;&#21644;&#20855;&#20307;&#25351;&#20196;&#22312;&#25552;&#21319;LLM&#22312;NLG&#20219;&#21153;&#20013;&#34920;&#29616;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;AmbigNLG&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#65288;NLG&#65289;&#20219;&#21153;&#20013;&#25351;&#20196;&#27169;&#31946;&#24615;&#25361;&#25112;&#30340;&#26032;&#20219;&#21153;&#12290;&#23613;&#31649;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29702;&#35299;&#21644;&#25191;&#34892;&#21508;&#31181;&#20219;&#21153;&#26041;&#38754;&#20855;&#26377;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#30340;&#24615;&#33021;&#21463;&#21040;&#29616;&#23454;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#30340;&#26174;&#33879;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;AmbigNLG&#35797;&#22270;&#35782;&#21035;&#24182;&#20943;&#36731;&#36825;&#31181;&#27169;&#31946;&#24615;&#65292;&#26088;&#22312;&#31934;&#32454;&#21270;&#25351;&#20196;&#20197;&#26356;&#22909;&#22320;&#21305;&#37197;&#29992;&#25143;&#26399;&#26395;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21253;&#21547;2,500&#20010;&#23454;&#20363;&#30340;&#25968;&#25454;&#38598;AmbigSNI-NLG&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#27169;&#31946;&#24615;&#20998;&#31867;&#27861;&#65292;&#29992;&#20110;&#23545;&#25351;&#20196;&#20013;&#30340;&#27169;&#31946;&#24615;&#36827;&#34892;&#20998;&#31867;&#21644;&#27880;&#37322;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#65292;&#31361;&#20986;&#20102;&#28165;&#26224;&#21644;&#20855;&#20307;&#25351;&#20196;&#22312;&#22686;&#24378;LLM&#22312;NLG&#20219;&#21153;&#20013;&#34920;&#29616;&#26041;&#38754;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17717v1 Announce Type: new  Abstract: In this study, we introduce AmbigNLG, a new task designed to tackle the challenge of task ambiguity in instructions for Natural Language Generation (NLG) tasks. Despite the impressive capabilities of Large Language Models (LLMs) in understanding and executing a wide range of tasks through natural language interaction, their performance is significantly hindered by the ambiguity present in real-world instructions. To address this, AmbigNLG seeks to identify and mitigate such ambiguities, aiming to refine instructions to match user expectations better. We introduce a dataset, AmbigSNI-NLG, consisting of 2,500 instances, and develop an ambiguity taxonomy for categorizing and annotating instruction ambiguities. Our approach demonstrates substantial improvements in text generation quality, highlighting the critical role of clear and specific instructions in enhancing LLM performance in NLG tasks.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;Chain-of-Discussion&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#20010;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#21327;&#21516;&#20316;&#29992;&#65292;&#25552;&#39640;&#20102;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#30340;&#36136;&#37327;</title><link>https://arxiv.org/abs/2402.16313</link><description>&lt;p&gt;
Chain-of-Discussion&#65306;&#22797;&#26434;&#35777;&#25454;&#38382;&#39064;&#22238;&#31572;&#30340;&#22810;&#27169;&#22411;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16313
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;Chain-of-Discussion&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#20010;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#21327;&#21516;&#20316;&#29992;&#65292;&#25552;&#39640;&#20102;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#30340;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#25918;&#24335;&#38382;&#39064;&#22238;&#31572;&#38656;&#35201;&#27169;&#22411;&#25214;&#21040;&#36866;&#24403;&#30340;&#35777;&#25454;&#26469;&#24418;&#25104;&#21512;&#29702;&#12289;&#20840;&#38754;&#21644;&#26377;&#24110;&#21161;&#30340;&#31572;&#26696;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#27169;&#22411;&#36824;&#38656;&#35201;&#21442;&#19982;&#23545;&#19982;&#38382;&#39064;&#23494;&#20999;&#30456;&#20851;&#30340;&#28508;&#22312;&#22330;&#26223;&#36827;&#34892;&#28145;&#20837;&#35752;&#35770;&#12290;&#22312;&#26816;&#32034;&#27169;&#22359;&#30340;&#22686;&#24378;&#19979;&#65292;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#24120;&#33021;&#22815;&#20135;&#29983;&#19968;&#33268;&#30340;&#31572;&#26696;&#65292;&#20294;&#22312;&#21487;&#38752;&#35777;&#25454;&#36873;&#25321;&#21644;&#28145;&#20837;&#38382;&#39064;&#20998;&#26512;&#26041;&#38754;&#20173;&#19981;&#22815;&#29702;&#24819;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Chain-of-Discussion&#26694;&#26550;&#65292;&#26088;&#22312;&#21033;&#29992;&#22810;&#20010;&#24320;&#28304;LLMs&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;&#65292;&#20026;&#24320;&#25918;&#24335;QA&#25552;&#20379;&#26356;&#27491;&#30830;&#12289;&#26356;&#20840;&#38754;&#30340;&#31572;&#26696;&#65292;&#23613;&#31649;&#23427;&#20204;&#22312;&#20010;&#20307;&#19978;&#36824;&#19981;&#22815;&#24378;&#22823;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#22810;&#20010;LLMs&#20043;&#38388;&#30340;&#35752;&#35770;&#23545;&#25552;&#39640;&#31572;&#26696;&#36136;&#37327;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#22312;\url{https://github.com/kobaya}&#19978;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#25968;&#25454;&#21644;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16313v1 Announce Type: cross  Abstract: Open-ended question answering requires models to find appropriate evidence to form well-reasoned, comprehensive and helpful answers. In practical applications, models also need to engage in extended discussions on potential scenarios closely relevant to the question. With augmentation of retrieval module, open-source Large Language Models (LLMs) can produce coherent answers often with different focuses, but are still sub-optimal in terms of reliable evidence selection and in-depth question analysis. In this paper, we propose a novel Chain-of-Discussion framework to leverage the synergy among multiple open-source LLMs aiming to provide \textbf{more correct} and \textbf{more comprehensive} answers for open-ended QA, although they are not strong enough individually. Our experiments show that discussions among multiple LLMs play a vital role in enhancing the quality of answers. We release our data and code at \url{https://github.com/kobaya
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;PANDA&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#35780;&#27979;&#26041;&#24335;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#33258;&#21160;&#35780;&#20272;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.11161</link><description>&lt;p&gt;
PANDA&#65288;Pedantic ANswer-correctness Determination and Adjudication&#65289;&#65306;&#25913;&#36827;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#30340;&#33258;&#21160;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11161
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;PANDA&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#26356;&#31934;&#30830;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#35780;&#27979;&#26041;&#24335;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#33258;&#21160;&#35780;&#20272;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38382;&#31572;&#65288;QA&#65289;&#21482;&#26377;&#22312;&#25105;&#20204;&#30693;&#36947;&#31572;&#26696;&#26159;&#21542;&#27491;&#30830;&#26102;&#25165;&#33021;&#21462;&#24471;&#36827;&#23637;&#65292;&#20294;&#23545;&#20110;&#35768;&#22810;&#26368;&#20855;&#25361;&#25112;&#24615;&#21644;&#26377;&#36259;&#30340;QA&#31034;&#20363;&#65292;&#24403;&#21069;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#65288;AC&#65289;&#25351;&#26631;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#65292;&#29305;&#21035;&#26159;&#26469;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20887;&#38271;&#12289;&#33258;&#30001;&#26684;&#24335;&#31572;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#25361;&#25112;&#65306;&#32570;&#20047;&#25968;&#25454;&#21644;&#27169;&#22411;&#36807;&#22823;&#12290;&#22522;&#20110;LLM&#30340;&#35780;&#20998;&#22120;&#19982;&#20154;&#31867;&#26356;&#22909;&#22320;&#30456;&#20851;&#65292;&#20294;&#36825;&#39033;&#26114;&#36149;&#30340;&#20219;&#21153;&#20165;&#22312;&#26377;&#38480;&#30340;QA&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#28165;&#26224;&#30340;&#25351;&#21335;&#26469;&#35780;&#20272;&#20174;&#20154;&#31867;QA&#27604;&#36187;&#20013;&#37319;&#32435;&#30340;&#26426;&#22120;QA&#65292;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#31934;&#30830;&#30340;&#31572;&#26696;&#27491;&#30830;&#24615;&#30830;&#23450;&#21644;&#35009;&#20915;&#65288;Precise ANswer correctness Determination and Adjudication&#65292;PANDA&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#23567;&#24039;&#12289;&#39640;&#25928;&#12289;&#30830;&#23450;&#24615;&#30340;AC&#20998;&#31867;&#22120;&#65288;812 KB&#65289;&#65292;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#31572;&#26696;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11161v1 Announce Type: cross  Abstract: Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current answer correctness (AC) metrics do not align with human judgments, particularly verbose, free form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big. LLM based scorers correlate better with humans, but this expensive task has only been tested on limited QA datasets. We rectify these issues by providing clear guidelines for evaluating machine QA adopted from human QA contests. We also introduce Precise ANswer correctness Determination and Adjudication (PANDA), a small, efficient, deterministic AC classifier (812 KB) that more accurately evaluates answer correctness.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;Rowen&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#26816;&#32034;&#22686;&#24378;&#36807;&#31243;&#65292;&#37319;&#29992;&#22810;&#35821;&#20041;&#24863;&#30693;&#26816;&#27979;&#27169;&#22359;&#26469;&#24179;&#34913;&#21442;&#25968;&#21270;&#30693;&#35782;&#21644;&#22806;&#37096;&#20449;&#24687;&#65292;&#20197;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.10612</link><description>&lt;p&gt;
&#20165;&#22312;&#38656;&#35201;&#26102;&#26816;&#32034;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#36866;&#24212;&#24615;&#26816;&#32034;&#22686;&#24378;&#20197;&#20943;&#36731;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;Rowen&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#26816;&#32034;&#22686;&#24378;&#36807;&#31243;&#65292;&#37319;&#29992;&#22810;&#35821;&#20041;&#24863;&#30693;&#26816;&#27979;&#27169;&#22359;&#26469;&#24179;&#34913;&#21442;&#25968;&#21270;&#30693;&#35782;&#21644;&#22806;&#37096;&#20449;&#24687;&#65292;&#20197;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24187;&#35273;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23454;&#38469;&#23454;&#26045;&#26500;&#25104;&#20102;&#26174;&#33879;&#25361;&#25112;&#12290;&#29983;&#25104;&#20107;&#23454;&#20869;&#23481;&#26102;&#21033;&#29992;&#21442;&#25968;&#21270;&#30693;&#35782;&#21463;&#21040;LLMs&#26377;&#38480;&#30693;&#35782;&#30340;&#38480;&#21046;&#65292;&#21487;&#33021;&#23548;&#33268;&#20869;&#37096;&#24187;&#35273;&#12290;&#34429;&#28982;&#25972;&#21512;&#22806;&#37096;&#20449;&#24687;&#21487;&#20197;&#22635;&#34917;&#30693;&#35782;&#31354;&#30333;&#65292;&#20294;&#20063;&#20250;&#24341;&#20837;&#26080;&#20851;&#20449;&#24687;&#30340;&#39118;&#38505;&#65292;&#20174;&#32780;&#22686;&#21152;&#22806;&#37096;&#24187;&#35273;&#30340;&#21487;&#33021;&#24615;&#12290;&#22312;LLMs&#20869;&#37096;&#24179;&#34913;&#22320;&#25972;&#21512;&#21442;&#25968;&#21270;&#30693;&#35782;&#21644;&#22806;&#37096;&#20449;&#24687;&#23545;&#32531;&#35299;&#24187;&#35273;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;Rowen&#65292;&#19968;&#31181;&#22686;&#24378;LLMs&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#31181;&#36873;&#25321;&#24615;&#26816;&#32034;&#22686;&#24378;&#36807;&#31243;&#65292;&#26088;&#22312;&#35299;&#20915;&#24187;&#35273;&#36755;&#20986;&#12290;&#35813;&#36807;&#31243;&#30001;&#19968;&#20010;&#22810;&#35821;&#20041;&#24863;&#30693;&#26816;&#27979;&#27169;&#22359;&#31649;&#29702;&#65292;&#35813;&#27169;&#22359;&#35780;&#20272;&#20102;&#23545;&#30456;&#21516;&#26597;&#35810;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#30340;&#25200;&#21160;&#21709;&#24212;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10612v1 Announce Type: new  Abstract: Hallucinations pose a significant challenge for the practical implementation of large language models (LLMs). The utilization of parametric knowledge in generating factual content is constrained by the limited knowledge of LLMs, potentially resulting in internal hallucinations. While incorporating external information can help fill knowledge gaps, it also introduces the risk of irrelevant information, thereby increasing the likelihood of external hallucinations. A careful and balanced integration of the parametric knowledge within LLMs with external information is crucial to alleviate hallucinations. In this study, we present Rowen, a novel approach that enhances LLMs with a selective retrieval augmentation process tailored to address hallucinated outputs. This process is governed by a multilingual semantic-aware detection module, which evaluates the consistency of the perturbed responses across various languages for the same queries. Up
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#35821;&#35328;&#21453;&#39304;&#27169;&#22411;&#65288;LFMs&#65289;&#25913;&#36827;&#25919;&#31574;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35782;&#21035;&#26399;&#26395;&#30340;&#34892;&#20026;&#24182;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#65292;&#25105;&#20204;&#22312;&#20219;&#21153;&#23436;&#25104;&#29575;&#12289;&#27867;&#21270;&#24615;&#33021;&#21644;&#20154;&#31867;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.07876</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#21453;&#39304;&#27169;&#22411;&#26469;&#25913;&#36827;&#25919;&#31574;
&lt;/p&gt;
&lt;p&gt;
Policy Improvement using Language Feedback Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#35821;&#35328;&#21453;&#39304;&#27169;&#22411;&#65288;LFMs&#65289;&#25913;&#36827;&#25919;&#31574;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35782;&#21035;&#26399;&#26395;&#30340;&#34892;&#20026;&#24182;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#65292;&#25105;&#20204;&#22312;&#20219;&#21153;&#23436;&#25104;&#29575;&#12289;&#27867;&#21270;&#24615;&#33021;&#21644;&#20154;&#31867;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#35821;&#35328;&#21453;&#39304;&#27169;&#22411;&#65288;LFMs&#65289;&#65292;&#29992;&#20110;&#22312;&#25351;&#20196;&#36981;&#24490;&#20013;&#35782;&#21035;&#26399;&#26395;&#30340;&#34892;&#20026;-&#26377;&#21161;&#20110;&#23454;&#29616;&#25351;&#20196;&#20013;&#25351;&#23450;&#20219;&#21153;&#30340;&#34892;&#21160;-&#20197;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#12290;&#20026;&#20102;&#35757;&#32451;LFMs&#65292;&#25105;&#20204;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33719;&#21462;&#23545;&#35270;&#35273;&#36712;&#36857;&#36827;&#34892;&#35821;&#35328;&#25551;&#36848;&#30340;&#21453;&#39304;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#20351;&#29992;LFMs&#35782;&#21035;&#26399;&#26395;&#27169;&#20223;&#30340;&#34892;&#20026;&#65292;&#25105;&#20204;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#35821;&#35328;&#22522;&#30784;&#29615;&#22659;&#65288;Touchdown&#65292;ScienceWorld&#21644;ALFWorld&#65289;&#19978;&#65292;&#22312;&#20219;&#21153;&#23436;&#25104;&#29575;&#19978;&#25913;&#21892;&#20102;&#24378;&#34892;&#20026;&#20811;&#38534;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;&#20854;&#27425;&#65292;&#19982;LLMs&#30452;&#25509;&#39044;&#27979;&#34892;&#21160;&#30456;&#27604;&#65292;&#20351;&#29992;LFMs&#22312;LLM&#36755;&#20986;&#26631;&#35760;&#30340;&#25968;&#37327;&#30456;&#21516;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#12290;&#31532;&#19977;&#65292;LFMs&#36866;&#24212;&#26410;&#35265;&#29615;&#22659;&#65292;&#36890;&#36807;&#19968;&#36718;&#36866;&#24212;&#20351;&#20219;&#21153;&#23436;&#25104;&#29575;&#25552;&#39640;&#20102;3.5-12.0&#65285;&#12290;&#26368;&#21518;&#65292;&#21487;&#20197;&#20462;&#25913;LFM&#20197;&#25552;&#20379;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#21453;&#39304;&#65292;&#26080;&#38656;&#24615;&#33021;&#25439;&#22833;&#65292;&#20174;&#32780;&#20801;&#35768;&#20154;&#31867;&#39564;&#35777;&#27169;&#20223;&#23398;&#20064;&#30340;&#26399;&#26395;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Language Feedback Models (LFMs) that identify desirable behaviour - actions that help achieve tasks specified in the instruction - for imitation learning in instruction following. To train LFMs, we obtain feedback from Large Language Models (LLMs) on visual trajectories verbalized to language descriptions. First, by using LFMs to identify desirable behaviour to imitate, we improve in task-completion rate over strong behavioural cloning baselines on three distinct language grounding environments (Touchdown, ScienceWorld, and ALFWorld). Second, LFMs outperform using LLMs as experts to directly predict actions, when controlling for the number of LLM output tokens. Third, LFMs generalize to unseen environments, improving task-completion rate by 3.5-12.0% through one round of adaptation. Finally, LFM can be modified to provide human-interpretable feedback without performance loss, allowing human verification of desirable behaviour for imitation learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#27169;&#25311;&#25919;&#27835;&#36777;&#35770;&#20013;&#23384;&#22312;&#30340;&#31995;&#32479;&#24615;&#20559;&#24046;&#65292;&#23613;&#31649;&#34987;&#25351;&#23450;&#20174;&#29305;&#23450;&#30340;&#25919;&#27835;&#35266;&#28857;&#36827;&#34892;&#36777;&#35770;&#65292;LLMs&#20195;&#29702;&#26426;&#26500;&#20542;&#21521;&#20110;&#36981;&#24490;&#27169;&#22411;&#22266;&#26377;&#30340;&#31038;&#20250;&#20559;&#35265;&#12290;&#36890;&#36807;&#33258;&#21160;&#33258;&#25105;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#23454;&#20102;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.04049</link><description>&lt;p&gt;
&#35770;&#35821;&#26009;&#24211;&#27169;&#25311;&#36777;&#35770;&#20013;&#30340;&#31995;&#32479;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Systematic Biases in LLM Simulations of Debates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#27169;&#25311;&#25919;&#27835;&#36777;&#35770;&#20013;&#23384;&#22312;&#30340;&#31995;&#32479;&#24615;&#20559;&#24046;&#65292;&#23613;&#31649;&#34987;&#25351;&#23450;&#20174;&#29305;&#23450;&#30340;&#25919;&#27835;&#35266;&#28857;&#36827;&#34892;&#36777;&#35770;&#65292;LLMs&#20195;&#29702;&#26426;&#26500;&#20542;&#21521;&#20110;&#36981;&#24490;&#27169;&#22411;&#22266;&#26377;&#30340;&#31038;&#20250;&#20559;&#35265;&#12290;&#36890;&#36807;&#33258;&#21160;&#33258;&#25105;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#23454;&#20102;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#23637;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#20026;&#26500;&#24314;&#33021;&#22815;&#20934;&#30830;&#22797;&#21046;&#20154;&#31867;&#34892;&#20026;&#30340;&#35745;&#31639;&#26426;&#27169;&#25311;&#25552;&#20379;&#20102;&#20196;&#20154;&#20852;&#22859;&#30340;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;LLMs&#26159;&#22797;&#26434;&#30340;&#32479;&#35745;&#23398;&#20064;&#22120;&#65292;&#27809;&#26377;&#30452;&#25509;&#30340;&#28436;&#32462;&#35268;&#21017;&#65292;&#20351;&#20854;&#23481;&#26131;&#20986;&#29616;&#24847;&#22806;&#34892;&#20026;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;LLMs&#22312;&#27169;&#25311;&#20154;&#31867;&#20114;&#21160;&#20013;&#30340;&#38480;&#21046;&#65292;&#29305;&#21035;&#20851;&#27880;LLMs&#22312;&#27169;&#25311;&#25919;&#27835;&#36777;&#35770;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#23613;&#31649;&#34987;&#25351;&#23450;&#20174;&#29305;&#23450;&#30340;&#25919;&#27835;&#35266;&#28857;&#36827;&#34892;&#36777;&#35770;&#65292;LLMs&#20195;&#29702;&#26426;&#26500;&#20542;&#21521;&#20110;&#36981;&#24490;&#27169;&#22411;&#22266;&#26377;&#30340;&#31038;&#20250;&#20559;&#35265;&#12290;&#36825;&#31181;&#20542;&#21521;&#23548;&#33268;&#20986;&#29616;&#34892;&#20026;&#27169;&#24335;&#65292;&#20284;&#20046;&#20559;&#31163;&#20102;&#20154;&#31867;&#20043;&#38388;&#24050;&#32463;&#30830;&#31435;&#30340;&#31038;&#20250;&#21160;&#24577;&#12290;&#25105;&#20204;&#20351;&#29992;&#33258;&#21160;&#33258;&#25105;&#20248;&#21270;&#26041;&#27861;&#21152;&#24378;&#20102;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#35813;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#25805;&#32437;LLMs&#20869;&#37096;&#30340;&#20559;&#35265;&#65292;&#24182;&#35777;&#26126;&#20195;&#29702;&#38543;&#21518;&#19982;&#36825;&#20123;&#35843;&#25972;&#20445;&#25345;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in natural language processing, especially the emergence of Large Language Models (LLMs), have opened exciting possibilities for constructing computational simulations designed to replicate human behavior accurately. However, LLMs are complex statistical learners without straightforward deductive rules, making them prone to unexpected behaviors. In this study, we highlight the limitations of LLMs in simulating human interactions, particularly focusing on LLMs' ability to simulate political debates. Our findings indicate a tendency for LLM agents to conform to the model's inherent social biases despite being directed to debate from certain political perspectives. This tendency results in behavioral patterns that seem to deviate from well-established social dynamics among humans. We reinforce these observations using an automatic self-fine-tuning method, which enables us to manipulate the biases within the LLM and demonstrate that agents subsequently align with the al
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;SLM/LLM&#36335;&#30001;&#26694;&#26550;&#65292;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#22686;&#24378;&#20219;&#21153;&#24615;&#33021;&#65292;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#21270;&#30693;&#35782;&#25552;&#21462;&#20219;&#21153;&#20013;SLMs&#21644;LLMs&#30340;&#20114;&#34917;&#20248;&#21183;&#65292;&#20174;&#32780;&#38477;&#20302;&#25104;&#26412;&#32780;&#19981;&#29306;&#29298;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.09758</link><description>&lt;p&gt;
OrchestraLLM&#65306;&#29992;&#20110;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;&#30340;&#35821;&#35328;&#27169;&#22411;&#39640;&#25928;&#32534;&#25490;
&lt;/p&gt;
&lt;p&gt;
OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;SLM/LLM&#36335;&#30001;&#26694;&#26550;&#65292;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#22686;&#24378;&#20219;&#21153;&#24615;&#33021;&#65292;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#21270;&#30693;&#35782;&#25552;&#21462;&#20219;&#21153;&#20013;SLMs&#21644;LLMs&#30340;&#20114;&#34917;&#20248;&#21183;&#65292;&#20174;&#32780;&#38477;&#20302;&#25104;&#26412;&#32780;&#19981;&#29306;&#29298;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31995;&#32479;&#30340;&#26684;&#23616;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#26114;&#36149;&#12290;&#20026;&#20102;&#38477;&#20302;&#25104;&#26412;&#32780;&#19981;&#25439;&#23475;&#24615;&#33021;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#21033;&#29992;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;SLMs&#65289;&#20316;&#20026;&#20854;&#26356;&#22823;&#22411;&#23545;&#24212;&#29289;&#30340;&#32463;&#27982;&#26377;&#25928;&#26367;&#20195;&#21697;&#12290;&#21463;&#21040;SLMs&#21644;LLMs&#22312;&#32467;&#26500;&#21270;&#30693;&#35782;&#25552;&#21462;&#20219;&#21153;&#20013;&#26174;&#31034;&#20986;&#20114;&#34917;&#20248;&#21183;&#30340;&#21457;&#29616;&#39537;&#21160;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;SLM/LLM&#36335;&#30001;&#26694;&#26550;&#65292;&#26088;&#22312;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#24182;&#22686;&#24378;&#20219;&#21153;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#21019;&#24314;&#31034;&#33539;&#27744;&#20197;&#34920;&#31034;&#27599;&#20010;LM&#25552;&#20379;&#26356;&#21487;&#38752;&#31572;&#26696;&#30340;&#19978;&#19979;&#25991;&#31867;&#22411;&#65292;&#21033;&#29992;&#21477;&#23376;&#23884;&#20837;&#36827;&#34892;&#24494;&#35843;&#65292;&#20351;&#19978;&#19979;&#25991;&#30456;&#20284;&#24615;&#25509;&#36817;&#23545;&#35805;&#29366;&#24577;&#30456;&#20284;&#24615;&#12290;&#28982;&#21518;&#65292;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#26816;&#32034;&#21040;&#27979;&#35797;&#23454;&#20363;&#30340;k&#20010;&#26368;&#36817;&#31034;&#33539;&#65292;&#24182;&#26681;&#25454;&#24773;&#20917;&#36335;&#30001;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09758v2 Announce Type: replace  Abstract: Large language models (LLMs) have revolutionized the landscape of Natural Language Processing systems, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Small Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction task, this work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance. First, exemplar pools are created to represent the types of contexts where each LM provides a more reliable answer, leveraging a sentence embedding fine-tuned so that context similarity is close to dialogue state similarity. Then, during inference, the k-nearest exemplars to the testing instance are retrieved, and the instance is routed according
&lt;/p&gt;</description></item><item><title>TAT-LLM&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#31163;&#25955;&#25512;&#29702;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#38024;&#23545;&#28151;&#21512;&#34920;&#26684;&#21644;&#25991;&#26412;&#25968;&#25454;&#19978;&#30340;&#38382;&#31572;&#20219;&#21153;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#20998;&#27493;&#27969;&#27700;&#32447;&#30340;&#26041;&#24335;&#65292;&#21253;&#25324;&#25552;&#21462;&#22120;&#12289;&#25512;&#29702;&#22120;&#21644;&#25191;&#34892;&#22120;&#65292;&#21033;&#29992;LLMs&#30340;&#24378;&#22823;&#33021;&#21147;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#32780;&#20026;&#20102;&#24212;&#23545;&#25104;&#26412;&#12289;&#24310;&#36831;&#21644;&#25968;&#25454;&#23433;&#20840;&#39118;&#38505;&#31561;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;TAT-LLM&#65292;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#27492;&#20219;&#21153;&#30340;&#36739;&#23567;LLM&#12290;</title><link>http://arxiv.org/abs/2401.13223</link><description>&lt;p&gt;
TAT-LLM: &#19968;&#31181;&#38024;&#23545;&#34920;&#26684;&#21644;&#25991;&#26412;&#25968;&#25454;&#30340;&#19987;&#29992;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#31163;&#25955;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data. (arXiv:2401.13223v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13223
&lt;/p&gt;
&lt;p&gt;
TAT-LLM&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#31163;&#25955;&#25512;&#29702;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#38024;&#23545;&#28151;&#21512;&#34920;&#26684;&#21644;&#25991;&#26412;&#25968;&#25454;&#19978;&#30340;&#38382;&#31572;&#20219;&#21153;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#20998;&#27493;&#27969;&#27700;&#32447;&#30340;&#26041;&#24335;&#65292;&#21253;&#25324;&#25552;&#21462;&#22120;&#12289;&#25512;&#29702;&#22120;&#21644;&#25191;&#34892;&#22120;&#65292;&#21033;&#29992;LLMs&#30340;&#24378;&#22823;&#33021;&#21147;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#32780;&#20026;&#20102;&#24212;&#23545;&#25104;&#26412;&#12289;&#24310;&#36831;&#21644;&#25968;&#25454;&#23433;&#20840;&#39118;&#38505;&#31561;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;TAT-LLM&#65292;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#27492;&#20219;&#21153;&#30340;&#36739;&#23567;LLM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#28151;&#21512;&#34920;&#26684;&#21644;&#25991;&#26412;&#25968;&#25454;&#19978;&#36827;&#34892;&#38382;&#31572;&#30340;&#38382;&#39064;&#65292;&#36825;&#22312;Web&#19978;&#38750;&#24120;&#24120;&#35265;&#65288;&#22914;SEC&#25991;&#20214;&#65289;&#65292;&#36890;&#24120;&#38656;&#35201;&#31163;&#25955;&#25512;&#29702;&#33021;&#21147;&#12290;&#26368;&#36817;&#65292;&#20687;GPT-4&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#22810;&#27493;&#39588;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#32771;&#34385;&#21033;&#29992;LLMs&#30340;&#24378;&#22823;&#33021;&#21147;&#26469;&#35299;&#20915;&#25105;&#20204;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38754;&#21521;&#34920;&#26684;&#21644;&#25991;&#26412;&#38382;&#31572;&#30340;&#20998;&#27493;&#27969;&#27700;&#32447;&#30340;&#25277;&#35937;&#65292;&#21253;&#25324;&#25552;&#21462;&#22120;&#12289;&#25512;&#29702;&#22120;&#21644;&#25191;&#34892;&#22120;&#19977;&#20010;&#20851;&#38190;&#27493;&#39588;&#65292;&#24182;&#39318;&#20808;&#35774;&#35745;&#20102;&#19968;&#20221;&#25351;&#20196;&#26469;&#23454;&#20363;&#21270;&#35813;&#27969;&#27700;&#32447;&#24182;&#39564;&#35777;GPT-4&#20248;&#20110;&#25152;&#26377;&#29616;&#26377;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#21033;&#29992;&#20687;GPT-4&#36825;&#26679;&#30340;&#22312;&#32447;LLM&#23384;&#22312;&#25104;&#26412;&#12289;&#24310;&#36831;&#21644;&#25968;&#25454;&#23433;&#20840;&#39118;&#38505;&#31561;&#21508;&#31181;&#25361;&#25112;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#19987;&#38376;&#38024;&#23545;&#27492;&#20219;&#21153;&#24320;&#21457;&#36739;&#23567;&#30340;LLM&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#29616;&#26377;&#19987;&#23478;&#26631;&#27880;&#25968;&#25454;&#38598;&#33258;&#21160;&#29983;&#25104;&#30340;&#35757;&#32451;&#25968;&#25454;&#23545;LLaMA 2&#36827;&#34892;&#24494;&#35843;&#65292;&#24320;&#21457;&#20102;TAT-LLM&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required. Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities. We then consider harnessing the amazing power of LLMs to solve our task. We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods. However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task. We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-w
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GAAM&#30340;&#22810;&#22836;&#39640;&#26031;&#33258;&#36866;&#24212;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#29992;&#20110;&#22686;&#24378;&#36328;&#22810;&#20010;&#27169;&#24577;&#30340;&#20449;&#24687;&#32858;&#21512;&#12290;&#36890;&#36807;&#23558;&#21487;&#23398;&#20064;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#32435;&#20837;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#65292;GAAM&#33021;&#22815;&#21160;&#24577;&#22320;&#37325;&#26032;&#35843;&#25972;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#22312;&#22788;&#29702;&#38750;&#24179;&#31283;&#25968;&#25454;&#26102;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#36229;&#36807;&#20102;&#30446;&#21069;&#29616;&#26377;&#30340;&#27880;&#24847;&#21147;&#25216;&#26415;&#12290;&#35813;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;&#24378;&#19988;&#21442;&#25968;&#25968;&#37327;&#36739;&#23569;&#65292;&#20855;&#26377;&#25913;&#36827;&#29616;&#26377;&#27880;&#24847;&#21147;&#26694;&#26550;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.11143</link><description>&lt;p&gt;
&#39640;&#26031;&#33258;&#36866;&#24212;&#27880;&#24847;&#21147;&#26159;&#21807;&#19968;&#25152;&#38656;&#30340;&#65306;&#36328;&#22810;&#20010;&#27169;&#24577;&#30340;&#20581;&#22766;&#19978;&#19979;&#25991;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11143
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GAAM&#30340;&#22810;&#22836;&#39640;&#26031;&#33258;&#36866;&#24212;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#29992;&#20110;&#22686;&#24378;&#36328;&#22810;&#20010;&#27169;&#24577;&#30340;&#20449;&#24687;&#32858;&#21512;&#12290;&#36890;&#36807;&#23558;&#21487;&#23398;&#20064;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#32435;&#20837;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#65292;GAAM&#33021;&#22815;&#21160;&#24577;&#22320;&#37325;&#26032;&#35843;&#25972;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#22312;&#22788;&#29702;&#38750;&#24179;&#31283;&#25968;&#25454;&#26102;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#36229;&#36807;&#20102;&#30446;&#21069;&#29616;&#26377;&#30340;&#27880;&#24847;&#21147;&#25216;&#26415;&#12290;&#35813;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;&#24378;&#19988;&#21442;&#25968;&#25968;&#37327;&#36739;&#23569;&#65292;&#20855;&#26377;&#25913;&#36827;&#29616;&#26377;&#27880;&#24847;&#21147;&#26694;&#26550;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#22836;&#39640;&#26031;&#33258;&#36866;&#24212;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GAAM&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#27880;&#24847;&#21147;&#26694;&#26550;&#65292;&#24182;&#35774;&#35745;&#20102;&#39640;&#26031;&#33258;&#36866;&#24212;&#21464;&#21387;&#22120;&#65288;GAT&#65289;&#65292;&#26088;&#22312;&#22686;&#24378;&#36328;&#22810;&#20010;&#27169;&#24577;&#65288;&#21253;&#25324;&#35821;&#38899;&#12289;&#25991;&#26412;&#21644;&#35270;&#35273;&#65289;&#30340;&#20449;&#24687;&#32858;&#21512;&#12290;GAAM&#23558;&#21487;&#23398;&#20064;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#34701;&#20837;&#20854;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#65292;&#37319;&#29992;&#22810;&#22836;&#26694;&#26550;&#23454;&#29616;&#65292;&#20351;&#20854;&#33021;&#22815;&#38598;&#20307;&#24314;&#27169;&#20219;&#20309;&#27010;&#29575;&#20998;&#24067;&#65292;&#20197;&#21160;&#24577;&#37325;&#26032;&#35843;&#25972;&#29305;&#24449;&#37325;&#35201;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#22788;&#29702;&#39640;&#24230;&#38750;&#24179;&#31283;&#25968;&#25454;&#26102;&#34920;&#29616;&#20986;&#26174;&#33879;&#25913;&#36827;&#65292;&#36890;&#36807;&#35782;&#21035;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#20851;&#38190;&#20803;&#32032;&#65292;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#27880;&#24847;&#21147;&#25216;&#26415;&#22312;&#27169;&#22411;&#24615;&#33021;&#19978;&#30340;&#29366;&#24577;&#65288;&#31934;&#24230;&#22686;&#21152;&#32422;20%&#65289;&#12290;GAAM&#19982;&#22522;&#20110;&#28857;&#31215;&#30340;&#27880;&#24847;&#21147;&#27169;&#22411;&#20860;&#23481;&#65292;&#24182;&#20855;&#26377;&#30456;&#23545;&#36739;&#20302;&#30340;&#21442;&#25968;&#25968;&#37327;&#65292;&#23637;&#31034;&#20102;&#20854;&#36866;&#24212;&#24615;&#21644;&#25552;&#21319;&#29616;&#26377;&#27880;&#24847;&#21147;&#26694;&#26550;&#30340;&#28508;&#21147;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;GAAM&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#36866;&#24212;&#24615;&#21644;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#35302;&#21457;&#26465;&#20214;&#25512;&#29702;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20195;&#30721;&#25552;&#31034;&#23558;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#36716;&#21270;&#20026;&#20195;&#30721;&#65292;&#20174;&#32780;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2401.10065</link><description>&lt;p&gt;
&#20195;&#30721;&#25552;&#31034;&#22312;&#25991;&#26412;+&#20195;&#30721;LLMs&#20013;&#24341;&#21457;&#20102;&#26465;&#20214;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs. (arXiv:2401.10065v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#35302;&#21457;&#26465;&#20214;&#25512;&#29702;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20195;&#30721;&#25552;&#31034;&#23558;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#36716;&#21270;&#20026;&#20195;&#30721;&#65292;&#20174;&#32780;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#29702;&#26159;&#23454;&#29616;&#35821;&#35328;&#29702;&#35299;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#12290;&#22312;&#22810;&#31181;&#25512;&#29702;&#31867;&#22411;&#20013;&#65292;&#26465;&#20214;&#25512;&#29702;&#26159;&#19968;&#31181;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#24471;&#20986;&#19981;&#21516;&#32467;&#35770;&#30340;&#33021;&#21147;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#19968;&#30452;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#12290;&#26368;&#36817;&#30340;&#25552;&#31034;&#26041;&#27861;&#65292;&#22914;&#24605;&#32500;&#38142;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#22312;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;LLMs&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#20110;&#20160;&#20040;&#35302;&#21457;&#20102;LLMs&#20013;&#30340;&#25512;&#29702;&#33021;&#21147;&#20173;&#28982;&#30693;&#20043;&#29978;&#23569;&#12290;&#25105;&#20204;&#20551;&#35774;&#20195;&#30721;&#25552;&#31034;&#33021;&#22815;&#35302;&#21457;&#22312;&#25991;&#26412;&#21644;&#20195;&#30721;&#19978;&#35757;&#32451;&#30340;LLMs&#20013;&#30340;&#26465;&#20214;&#25512;&#29702;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#30340;&#25552;&#31034;&#65292;&#23558;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#36716;&#21270;&#20026;&#20195;&#30721;&#65292;&#24182;&#29992;&#29983;&#25104;&#30340;&#20195;&#30721;&#25552;&#31034;LLMs&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#21457;&#29616;&#65292;&#22312;&#38656;&#35201;&#26465;&#20214;&#25512;&#29702;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#65292;&#20195;&#30721;&#25552;&#31034;&#20351;&#24471;GPT 3.5&#30340;&#24615;&#33021;&#25552;&#21319;&#20102;2.6&#21040;7.7&#20010;&#30334;&#20998;&#28857;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#25506;&#32034;&#20102;&#20195;&#30721;&#25552;&#31034;&#22914;&#20309;&#24341;&#21457;&#26465;&#20214;&#25512;&#29702;&#33021;&#21147;&#20197;&#21450;&#36890;&#36807;&#21738;&#20123;&#29305;&#24449;&#36827;&#34892;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#25552;&#31034;&#30340;&#24418;&#24335;&#21644;&#20869;&#23481;&#23545;&#20110;&#24341;&#21457;&#26465;&#20214;&#25512;&#29702;&#33021;&#21147;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reasoning is a fundamental component for achieving language understanding. Among the multiple types of reasoning, conditional reasoning, the ability to draw different conclusions depending on some condition, has been understudied in large language models (LLMs). Recent prompting methods, such as chain of thought, have significantly improved LLMs on reasoning tasks. Nevertheless, there is still little understanding of what triggers reasoning abilities in LLMs. We hypothesize that code prompts can trigger conditional reasoning in LLMs trained on text and code. We propose a chain of prompts that transforms a natural language problem into code and prompts the LLM with the generated code. Our experiments find that code prompts exhibit a performance boost between 2.6 and 7.7 points on GPT 3.5 across multiple datasets requiring conditional reasoning. We then conduct experiments to discover how code prompts elicit conditional reasoning abilities and through which features. We observe that prom
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#21512;&#25512;&#29702;&#30340;&#30142;&#30149;&#38382;&#31572;&#31995;&#32479;&#65292;&#36890;&#36807;&#32467;&#21512;&#35821;&#35328;&#27169;&#22411;&#21644;&#30693;&#35782;&#22270;&#35889;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#22238;&#31572;&#26222;&#36890;&#29992;&#25143;&#30340;&#20581;&#24247;&#30456;&#20851;&#38382;&#39064;&#24182;&#20943;&#36731;&#21307;&#30103;&#20445;&#20581;&#19987;&#19994;&#20154;&#21592;&#30340;&#36127;&#25285;&#12290;</title><link>http://arxiv.org/abs/2401.03181</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#32852;&#21512;&#25512;&#29702;&#30340;&#30142;&#30149;&#38382;&#31572;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Joint-Reasoning based Disease Q&amp;A System. (arXiv:2401.03181v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03181
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#21512;&#25512;&#29702;&#30340;&#30142;&#30149;&#38382;&#31572;&#31995;&#32479;&#65292;&#36890;&#36807;&#32467;&#21512;&#35821;&#35328;&#27169;&#22411;&#21644;&#30693;&#35782;&#22270;&#35889;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#22238;&#31572;&#26222;&#36890;&#29992;&#25143;&#30340;&#20581;&#24247;&#30456;&#20851;&#38382;&#39064;&#24182;&#20943;&#36731;&#21307;&#30103;&#20445;&#20581;&#19987;&#19994;&#20154;&#21592;&#30340;&#36127;&#25285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#23398;&#38382;&#31572;&#65288;QA&#65289;&#21161;&#25163;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#30456;&#20851;&#25216;&#26415;&#20174;&#22810;&#20010;&#20449;&#24687;&#28304;&#21512;&#25104;&#20449;&#24687;&#26469;&#22238;&#31572;&#26222;&#36890;&#29992;&#25143;&#30340;&#20581;&#24247;&#30456;&#20851;&#38382;&#39064;&#12290;&#23427;&#20204;&#21487;&#20197;&#20316;&#20026;&#37325;&#35201;&#24037;&#20855;&#26469;&#32531;&#35299;&#35823;&#23548;&#12289;&#20449;&#24687;&#36807;&#36733;&#21644;&#21307;&#23398;&#26415;&#35821;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#20174;&#32780;&#28385;&#36275;&#26222;&#36890;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#24182;&#20943;&#36731;&#21307;&#30103;&#20445;&#20581;&#19987;&#19994;&#20154;&#21592;&#30340;&#36127;&#25285;&#12290;QA&#31995;&#32479;&#36890;&#24120;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#25110;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#65292;&#23613;&#31649;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#20114;&#34917;&#12290;&#22522;&#20110;LM&#30340;QA&#31995;&#32479;&#25797;&#38271;&#29702;&#35299;&#22797;&#26434;&#38382;&#39064;&#24182;&#25552;&#20379;&#21512;&#36866;&#30340;&#31572;&#26696;&#65292;&#20294;&#26131;&#20110;&#20986;&#29616;&#20107;&#23454;&#38169;&#35823;&#12290;&#22522;&#20110;KG&#30340;QA&#31995;&#32479;&#33021;&#22815;&#24456;&#22909;&#22320;&#34920;&#31034;&#20107;&#23454;&#65292;&#20294;&#22823;&#22810;&#25968;&#20165;&#38480;&#20110;&#22238;&#31572;&#24050;&#39044;&#20808;&#21019;&#24314;&#27169;&#26495;&#30340;&#31616;&#30701;&#38382;&#39064;&#12290;&#34429;&#28982;&#19968;&#20123;&#30740;&#31350;&#24050;&#32463;&#32852;&#21512;&#20351;&#29992;&#20102;LM&#21644;KG&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#25991;&#26412;&#30340;QA&#65292;&#20294;&#36825;&#26159;&#29992;&#20110;&#22238;&#31572;&#22810;&#39033;&#36873;&#25321;&#39064;&#12290;&#29616;&#26377;&#30340;QA&#31995;&#32479;&#20063;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medical question answer (QA) assistants respond to lay users' health-related queries by synthesizing information from multiple sources using natural language processing and related techniques. They can serve as vital tools to alleviate issues of misinformation, information overload, and complexity of medical language, thus addressing lay users' information needs while reducing the burden on healthcare professionals. QA systems, the engines of such assistants, have typically used either language models (LMs) or knowledge graphs (KG), though the approaches could be complementary. LM-based QA systems excel at understanding complex questions and providing well-formed answers, but are prone to factual mistakes. KG-based QA systems, which represent facts well, are mostly limited to answering short-answer questions with pre-created templates. While a few studies have jointly used LM and KG approaches for text-based QA, this was done to answer multiple-choice questions. Extant QA systems also 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32467;&#21512;&#25351;&#23548;&#35843;&#25972;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#31471;&#21040;&#31471;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#65292;&#21033;&#29992;LLM&#30340;&#38646;-shot&#33021;&#21147;&#26469;&#25913;&#21892;&#35821;&#38899;&#35782;&#21035;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.10524</link><description>&lt;p&gt;
&#21457;&#25381;&#25351;&#23548;&#35843;&#25972;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#20013;&#30340;&#38646;-shot&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Harnessing the Zero-Shot Power of Instruction-Tuned Large Language Model in End-to-End Speech Recognition. (arXiv:2309.10524v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10524
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32467;&#21512;&#25351;&#23548;&#35843;&#25972;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#31471;&#21040;&#31471;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#65292;&#21033;&#29992;LLM&#30340;&#38646;-shot&#33021;&#21147;&#26469;&#25913;&#21892;&#35821;&#38899;&#35782;&#21035;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25351;&#23548;&#35843;&#25972;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#31471;&#21040;&#31471;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#30456;&#32467;&#21512;&#30340;&#26032;&#26041;&#27861;&#12290;&#29616;&#20195;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23398;&#20064;&#20013;&#21487;&#20197;&#25191;&#34892;&#21508;&#31181;&#35821;&#35328;&#20219;&#21153;&#65292;&#21482;&#35201;&#25552;&#20379;&#26126;&#30830;&#30340;&#25351;&#23548;&#25110;&#25552;&#31034;&#26469;&#25351;&#23548;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#12290;&#25105;&#20204;&#25506;&#32034;&#20351;&#29992;&#36825;&#31181;&#38646;-shot&#33021;&#21147;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#26469;&#25552;&#21462;&#35821;&#35328;&#20449;&#24687;&#65292;&#20197;&#25913;&#21892;&#35821;&#38899;&#35782;&#21035;&#24615;&#33021;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#22823;&#35821;&#35328;&#27169;&#22411;&#24341;&#23548;&#21435;&#32416;&#27491;&#35821;&#38899;&#35782;&#21035;&#20551;&#35774;&#20013;&#30340;&#35821;&#27861;&#38169;&#35823;&#65292;&#24182;&#21033;&#29992;&#23884;&#20837;&#30340;&#35821;&#35328;&#30693;&#35782;&#36827;&#34892;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22522;&#20110;&#28151;&#21512;&#36830;&#25509;&#20027;&#20041;&#26102;&#38388;&#20998;&#31867;&#21644;&#27880;&#24847;&#21147;&#26550;&#26500;&#65292;&#20854;&#20013;&#25351;&#23548;&#35843;&#25972;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;&#21363;Llama2&#65289;&#34987;&#29992;&#20316;&#35299;&#30721;&#22120;&#30340;&#21069;&#31471;&#12290;&#36890;&#36807;CTC&#35299;&#30721;&#20174;&#32534;&#30721;&#22120;&#33719;&#24471;&#19968;&#20010;&#38656;&#35201;&#32416;&#27491;&#30340;&#35821;&#38899;&#35782;&#21035;&#20551;&#35774;&#65292;&#28982;&#21518;&#23558;&#20854;&#19982;&#25351;&#23548;&#19968;&#36215;&#36755;&#20837;&#22823;&#35821;&#35328;&#27169;&#22411;&#12290;&#35299;&#30721;&#22120;&#38543;&#21518;&#37319;&#21462;...
&lt;/p&gt;
&lt;p&gt;
We present a novel integration of an instruction-tuned large language model (LLM) and end-to-end automatic speech recognition (ASR). Modern LLMs can perform a wide range of linguistic tasks within zero-shot learning when provided with a precise instruction or a prompt to guide the text generation process towards the desired task. We explore using this zero-shot capability of LLMs to extract linguistic information that can contribute to improving ASR performance. Specifically, we direct an LLM to correct grammatical errors in an ASR hypothesis and harness the embedded linguistic knowledge to conduct end-to-end ASR. The proposed model is built on the hybrid connectionist temporal classification (CTC) and attention architecture, where an instruction-tuned LLM (i.e., Llama2) is employed as a front-end of the decoder. An ASR hypothesis, subject to correction, is obtained from the encoder via CTC decoding, which is then fed into the LLM along with an instruction. The decoder subsequently tak
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#25512;&#29702;&#26041;&#27861;&#65292;&#22312;&#38646;&#23556;&#20987;&#21051;&#26495;&#21360;&#35937;&#35782;&#21035;&#20013;&#21462;&#24471;&#20102;&#37325;&#35201;&#30340;&#36827;&#23637;&#65292;&#24182;&#21457;&#29616;&#25512;&#29702;&#30340;&#24615;&#33021;&#22686;&#30410;&#36828;&#36828;&#36229;&#36807;&#27169;&#22411;&#35268;&#27169;&#25193;&#23637;&#30340;&#22686;&#30410;&#12290;&#25512;&#29702;&#19981;&#20165;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#65292;&#36824;&#25552;&#39640;&#20102;&#20915;&#31574;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.00071</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#25512;&#29702;&#26041;&#27861;&#29992;&#20110;&#21051;&#26495;&#21360;&#35937;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Interpretable Stereotype Identification through Reasoning. (arXiv:2308.00071v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#25512;&#29702;&#26041;&#27861;&#65292;&#22312;&#38646;&#23556;&#20987;&#21051;&#26495;&#21360;&#35937;&#35782;&#21035;&#20013;&#21462;&#24471;&#20102;&#37325;&#35201;&#30340;&#36827;&#23637;&#65292;&#24182;&#21457;&#29616;&#25512;&#29702;&#30340;&#24615;&#33021;&#22686;&#30410;&#36828;&#36828;&#36229;&#36807;&#27169;&#22411;&#35268;&#27169;&#25193;&#23637;&#30340;&#22686;&#30410;&#12290;&#25512;&#29702;&#19981;&#20165;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#65292;&#36824;&#25552;&#39640;&#20102;&#20915;&#31574;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#20351;&#29992;&#20102;&#21253;&#21547;&#22266;&#26377;&#20559;&#35265;&#30340;&#22823;&#37327;&#25968;&#25454;&#38598;&#65292;&#21487;&#33021;&#20250;&#19981;&#32463;&#24847;&#22320;&#25345;&#32493;&#31995;&#32479;&#24615;&#27495;&#35270;&#65292;&#22240;&#27492;&#65292;&#23457;&#26597;&#21644;&#35299;&#20915;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#23558;&#20844;&#24179;&#24615;&#25972;&#21512;&#21040;&#23427;&#20204;&#30340;&#21457;&#23637;&#20013;&#65292;&#20197;&#30830;&#20445;&#36825;&#20123;&#27169;&#22411;&#20855;&#26377;&#20844;&#27491;&#21644;&#26080;&#20559;&#30340;&#29305;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;Vicuna-13B-v1.3&#30340;&#38646;&#23556;&#20987;&#21051;&#26495;&#21360;&#35937;&#35782;&#21035;&#20013;&#25512;&#29702;&#30340;&#37325;&#35201;&#24615;&#12290;&#23613;&#31649;&#25105;&#20204;&#35266;&#23519;&#21040;&#20174;13B&#21040;33B&#30340;&#35268;&#27169;&#25193;&#23637;&#20250;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#25512;&#29702;&#30340;&#24615;&#33021;&#22686;&#30410;&#36828;&#36828;&#36229;&#36807;&#35268;&#27169;&#25193;&#23637;&#30340;&#22686;&#30410;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25512;&#29702;&#21487;&#33021;&#26159;&#20351;LLMs&#22312;&#21051;&#26495;&#21360;&#35937;&#31561;&#39046;&#22495;&#20219;&#21153;&#19978;&#36229;&#36234;&#35268;&#27169;&#23450;&#24459;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#23545;&#36873;&#23450;&#30340;&#25512;&#29702;&#36861;&#36394;&#36827;&#34892;&#23450;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#31361;&#20986;&#26174;&#31034;&#20102;&#25512;&#29702;&#19981;&#20165;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#65292;&#36824;&#25552;&#39640;&#20102;&#20915;&#31574;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given that language models are trained on vast datasets that may contain inherent biases, there is a potential danger of inadvertently perpetuating systemic discrimination. Consequently, it becomes essential to examine and address biases in language models, integrating fairness into their development to ensure these models are equitable and free from bias. In this work, we demonstrate the importance of reasoning in zero-shot stereotype identification based on Vicuna-13B-v1.3. While we do observe improved accuracy by scaling from 13B to 33B, we show that the performance gain from reasoning significantly exceeds the gain from scaling up. Our findings suggest that reasoning could be a key factor that enables LLMs to trescend the scaling law on out-of-domain tasks such as stereotype identification. Additionally, through a qualitative analysis of select reasoning traces, we highlight how reasoning enhances not just accuracy but also the interpretability of the decision.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GPT-3&#21644;GPT-4&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#34920;&#29616;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#21487;&#33021;&#20135;&#29983;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2305.16326</link><description>&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#22522;&#20934;&#12289;&#22522;&#32447;&#21644;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GPT-3&#21644;GPT-4&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#34920;&#29616;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#21487;&#33021;&#20135;&#29983;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#25163;&#21160;&#31579;&#36873;&#21644;&#25552;&#21462;&#30693;&#35782;&#21464;&#24471;&#22256;&#38590;&#12290;&#33258;&#21160;&#20174;&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;BioNLP&#65289;&#25216;&#26415;&#26377;&#21161;&#20110;&#20943;&#36731;&#36825;&#31181;&#36127;&#25285;&#12290;&#36817;&#24180;&#26469;&#65292;&#22914;GPT-3&#21644;GPT-4&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22240;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#32780;&#21463;&#21040;&#37325;&#35270;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#22312;BioNLP&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#23545;&#26041;&#27861;&#24320;&#21457;&#21644;&#19979;&#28216;&#29992;&#25143;&#30340;&#24433;&#21709;&#20173;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#65288;1&#65289;&#22312;&#22235;&#20010;&#24212;&#29992;&#31243;&#24207;&#20013;&#22312;&#20843;&#20010;BioNLP&#25968;&#25454;&#38598;&#20013;&#24314;&#31435;&#20102;GPT-3&#21644;GPT-4&#22312;&#38646;-shot&#21644;&#19968;-shot&#35774;&#32622;&#19979;&#30340;&#22522;&#20934;&#34920;&#29616;&#65292;&#21253;&#25324;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65292;&#20851;&#31995;&#25552;&#21462;&#65292;&#22810;&#26631;&#31614;&#25991;&#26723;&#20998;&#31867;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#21644;&#25512;&#29702;&#65307;&#65288;2&#65289;&#23457;&#26597;&#20102;LLMs&#20135;&#29983;&#30340;&#38169;&#35823;&#65292;&#24182;&#23558;&#38169;&#35823;&#20998;&#20026;&#19977;&#31181;&#31867;&#22411;&#65306;&#32570;&#22833;&#65292;&#19981;&#19968;&#33268;&#21644;&#19981;&#38656;&#35201;&#30340;&#20154;&#24037;&#20869;&#23481;&#65307;&#65288;3&#65289;&#25552;&#20986;&#20102;&#20351;&#29992;LLMs&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#23548;&#30693;&#35782;&#33976;&#39311;&#21644;&#37327;&#21270;&#65292;&#23454;&#29616;&#23545;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#38899;&#35782;&#21035;&#27169;&#22411;Whisper&#36827;&#34892;&#21387;&#32553;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#27169;&#22411;&#22823;&#23567;&#32553;&#23567;&#24182;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.10788</link><description>&lt;p&gt;
Whisper-KDQ: &#36890;&#36807;&#24341;&#23548;&#30693;&#35782;&#33976;&#39311;&#21644;&#37327;&#21270;&#23454;&#29616;&#39640;&#25928;ASR&#30340;&#36731;&#22411;Whisper
&lt;/p&gt;
&lt;p&gt;
Whisper-KDQ: A Lightweight Whisper via Guided Knowledge Distillation and Quantization for Efficient ASR. (arXiv:2305.10788v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10788
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#23548;&#30693;&#35782;&#33976;&#39311;&#21644;&#37327;&#21270;&#65292;&#23454;&#29616;&#23545;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#38899;&#35782;&#21035;&#27169;&#22411;Whisper&#36827;&#34892;&#21387;&#32553;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#27169;&#22411;&#22823;&#23567;&#32553;&#23567;&#24182;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35745;&#31639;&#30828;&#20214;&#36164;&#28304;&#30340;&#24555;&#36895;&#21457;&#23637;&#21644;&#25968;&#25454;&#30340;&#26174;&#33879;&#22686;&#38271;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#35821;&#38899;&#35782;&#21035;&#31561;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20855;&#26377;&#24456;&#39640;&#30340;&#35745;&#31639;&#24320;&#38144;&#65292;&#20351;&#20854;&#38590;&#20197;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35774;&#22791;&#19978;&#26377;&#25928;&#25191;&#34892;&#12290;&#20026;&#20102;&#21152;&#36895;&#25512;&#29702;&#12289;&#20943;&#23569;&#27169;&#22411;&#22823;&#23567;&#65292;&#24182;&#20445;&#25345;&#24615;&#33021;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24341;&#23548;&#30693;&#35782;&#33976;&#39311;&#21644;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;Whisper&#12290;&#23398;&#29983;&#27169;&#22411;&#22522;&#20110;&#37327;&#21270;&#25439;&#22833;&#21644;&#33976;&#39311;&#25439;&#22833;&#36873;&#25321;&#33976;&#39311;&#21644;&#37327;&#21270;&#23618;&#12290;&#25105;&#20204;&#23558;$\text{Whisper}_\text{small}$&#21387;&#32553;&#21040;$\text{Whisper}_\text{base}$&#21644;$\text{Whisper}_\text{tiny}$&#32423;&#21035;&#65292;&#20351;$\text{Whisper}_\text{small}$&#20998;&#21035;&#23567;5.18x/10.48x&#12290;&#27492;&#22806;&#65292;&#19982;&#21407;&#22987;$\text{Whisper}_\text{base}$&#21644;$\text{Whisper}_\text{tiny}$&#30456;&#27604;&#65292;&#36824;&#26377;&#30456;&#23545;&#23383;&#31526;&#38169;&#35823;&#29575;&#38477;&#20302;.
&lt;/p&gt;
&lt;p&gt;
Due to the rapid development of computing hardware resources and the dramatic growth of data, pre-trained models in speech recognition, such as Whisper, have significantly improved the performance of speech recognition tasks. However, these models usually have a high computational overhead, making it difficult to execute effectively on resource-constrained devices. To speed up inference and reduce model size while maintaining performance, we propose a novel guided knowledge distillation and quantization for large pre-trained model Whisper. The student model selects distillation and quantization layers based on quantization loss and distillation loss, respectively. We compressed $\text{Whisper}_\text{small}$ to $\text{Whisper}_\text{base}$ and $\text{Whisper}_\text{tiny}$ levels, making $\text{Whisper}_\text{small}$ 5.18x/10.48x smaller, respectively. Moreover, compared to the original $\text{Whisper}_\text{base}$ and $\text{Whisper}_\text{tiny}$, there is also a relative character erro
&lt;/p&gt;</description></item></channel></rss>