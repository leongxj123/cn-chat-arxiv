<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;39&#31687;&#26368;&#26032;&#35770;&#25991;&#65292;&#26088;&#22312;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25991;&#21270;&#34920;&#36798;&#21644;&#21253;&#23481;&#24615;&#65292;&#21457;&#29616;&#24403;&#21069;&#30740;&#31350;&#26410;&#23545;&#8220;&#25991;&#21270;&#8221;&#36827;&#34892;&#23450;&#20041;&#65292;&#32780;&#26159;&#22312;&#29305;&#23450;&#35774;&#35745;&#30340;&#25968;&#25454;&#38598;&#19978;&#23545;&#27169;&#22411;&#36827;&#34892;&#25506;&#31350;&#65292;&#30740;&#31350;&#20102;&#26576;&#20123;&#8220;&#25991;&#21270;&#8221;&#30340;&#26041;&#38754;&#65292;&#30041;&#19979;&#35768;&#22810;&#26410;&#34987;&#25506;&#31350;&#30340;&#26377;&#36259;&#21644;&#37325;&#35201;&#26041;&#38754;&#65292;&#22914;&#35821;&#20041;&#39046;&#22495;&#21644;&#20851;&#20110;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.15412</link><description>&lt;p&gt;
&#22312;LLMs&#20013;&#27979;&#37327;&#21644;&#24314;&#27169;&#8220;&#25991;&#21270;&#8221;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Towards Measuring and Modeling "Culture" in LLMs: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15412
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;39&#31687;&#26368;&#26032;&#35770;&#25991;&#65292;&#26088;&#22312;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25991;&#21270;&#34920;&#36798;&#21644;&#21253;&#23481;&#24615;&#65292;&#21457;&#29616;&#24403;&#21069;&#30740;&#31350;&#26410;&#23545;&#8220;&#25991;&#21270;&#8221;&#36827;&#34892;&#23450;&#20041;&#65292;&#32780;&#26159;&#22312;&#29305;&#23450;&#35774;&#35745;&#30340;&#25968;&#25454;&#38598;&#19978;&#23545;&#27169;&#22411;&#36827;&#34892;&#25506;&#31350;&#65292;&#30740;&#31350;&#20102;&#26576;&#20123;&#8220;&#25991;&#21270;&#8221;&#30340;&#26041;&#38754;&#65292;&#30041;&#19979;&#35768;&#22810;&#26410;&#34987;&#25506;&#31350;&#30340;&#26377;&#36259;&#21644;&#37325;&#35201;&#26041;&#38754;&#65292;&#22914;&#35821;&#20041;&#39046;&#22495;&#21644;&#20851;&#20110;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21576;&#29616;&#20102;&#23545;39&#31687;&#26368;&#26032;&#35770;&#25991;&#30340;&#35843;&#26597;&#65292;&#26088;&#22312;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25991;&#21270;&#34920;&#36798;&#21644;&#21253;&#23481;&#24615;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#27809;&#26377;&#19968;&#31687;&#30740;&#31350;&#23450;&#20041;&#8220;&#25991;&#21270;&#8221;&#65292;&#36825;&#26159;&#19968;&#20010;&#22797;&#26434;&#12289;&#22810;&#23618;&#38754;&#30340;&#27010;&#24565;&#65307;&#30456;&#21453;&#65292;&#23427;&#20204;&#22312;&#19968;&#20123;&#29305;&#21035;&#35774;&#35745;&#30340;&#25968;&#25454;&#38598;&#19978;&#23545;&#27169;&#22411;&#36827;&#34892;&#25506;&#31350;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#20195;&#34920;&#20102;&#26576;&#20123;&#8220;&#25991;&#21270;&#8221;&#30340;&#26041;&#38754;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#38754;&#31216;&#20026;&#25991;&#21270;&#30340;&#20195;&#29702;&#65292;&#24182;&#23558;&#23427;&#20204;&#32452;&#32455;&#22312;&#20154;&#21475;&#32479;&#35745;&#12289;&#35821;&#20041;&#21644;&#35821;&#35328;&#25991;&#21270;&#20132;&#20114;&#20195;&#29702;&#30340;&#19977;&#20010;&#32500;&#24230;&#19978;&#12290;&#25105;&#20204;&#36824;&#23545;&#37319;&#29992;&#30340;&#25506;&#26597;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#21482;&#26377;&#8220;&#25991;&#21270;&#8221;&#30340;&#26576;&#20123;&#26041;&#38754;&#65292;&#22914;&#20215;&#20540;&#35266;&#21644;&#30446;&#26631;&#65292;&#34987;&#30740;&#31350;&#20102;&#65292;&#30041;&#19979;&#20102;&#20960;&#20010;&#20854;&#20182;&#26377;&#36259;&#19988;&#37325;&#35201;&#30340;&#26041;&#38754;&#65292;&#29305;&#21035;&#26159;&#22823;&#37327;&#35821;&#20041;&#39046;&#22495;&#21644;&#20851;&#20110;&#24615;&#65288;Hershcovich&#31561;&#20154;&#65292;2022&#65289;&#30340;&#26410;&#34987;&#25506;&#31350;&#12290;&#21478;&#22806;&#20004;&#20010;&#20851;&#38190;&#30340;&#31354;&#30333;&#26159;&#30446;&#21069;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#24773;&#22659;&#24615;&#30340;&#32570;&#20047;&#12290;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15412v1 Announce Type: cross  Abstract: We present a survey of 39 recent papers that aim to study cultural representation and inclusion in large language models. We observe that none of the studies define "culture," which is a complex, multifaceted concept; instead, they probe the models on some specially designed datasets which represent certain aspects of "culture." We call these aspects the proxies of cultures, and organize them across three dimensions of demographic, semantic and linguistic-cultural interaction proxies. We also categorize the probing methods employed. Our analysis indicates that only certain aspects of "culture," such as values and objectives, have been studied, leaving several other interesting and important facets, especially the multitude of semantic domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps are the lack of robustness and situatedness of the current methods. Based on these observations
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31616;&#21333;&#21644;&#21487;&#25193;&#23637;&#30340;&#23398;&#20064;&#29575;&#35843;&#25972;&#12289;&#37325;&#25918;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#65292;&#25345;&#32493;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#21305;&#37197;&#23436;&#20840;&#37325;&#26032;&#35757;&#32451;&#26102;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.08763</link><description>&lt;p&gt;
&#25345;&#32493;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#21487;&#25193;&#23637;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Simple and Scalable Strategies to Continually Pre-train Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08763
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31616;&#21333;&#21644;&#21487;&#25193;&#23637;&#30340;&#23398;&#20064;&#29575;&#35843;&#25972;&#12289;&#37325;&#25918;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#65292;&#25345;&#32493;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#21305;&#37197;&#23436;&#20840;&#37325;&#26032;&#35757;&#32451;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#24120;&#22312;&#25968;&#21313;&#20159;&#30340;&#26631;&#35760;&#19978;&#36827;&#34892;&#24120;&#35268;&#39044;&#35757;&#32451;&#65292;&#19968;&#26086;&#26377;&#26032;&#25968;&#25454;&#21487;&#29992;&#23601;&#37325;&#26032;&#24320;&#22987;&#35813;&#36807;&#31243;&#12290;&#19968;&#20010;&#26356;&#26377;&#25928;&#29575;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#25345;&#32493;&#39044;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#65292;&#19982;&#37325;&#26032;&#35757;&#32451;&#30456;&#27604;&#33021;&#33410;&#30465;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#26032;&#25968;&#25454;&#24341;&#36215;&#30340;&#20998;&#24067;&#36716;&#31227;&#36890;&#24120;&#20250;&#23548;&#33268;&#22312;&#20197;&#21069;&#25968;&#25454;&#19978;&#38477;&#20302;&#24615;&#33021;&#25110;&#26080;&#27861;&#36866;&#24212;&#26032;&#25968;&#25454;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#23398;&#20064;&#29575;&#65288;LR&#65289;&#37325;&#26032;&#21319;&#28201;&#12289;LR&#37325;&#26032;&#34928;&#20943;&#21644;&#37325;&#25918;&#19978;&#19968;&#25968;&#25454;&#30340;&#32452;&#21512;&#36275;&#20197;&#19982;&#23436;&#20840;&#20174;&#22836;&#24320;&#22987;&#37325;&#26032;&#35757;&#32451;&#22312;&#25152;&#26377;&#21487;&#29992;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#65292;&#20174;&#26368;&#32456;&#25439;&#22833;&#21644;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#35780;&#20272;&#22522;&#20934;&#30340;&#35282;&#24230;&#34913;&#37327;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20004;&#20010;&#24120;&#29992;&#30340;LLM&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#65288;&#33521;&#35821;&#8594;&#33521;&#35821;&#65289;&#20043;&#38388;&#30340;&#24369;&#20294;&#29616;&#23454;&#30340;&#20998;&#24067;&#36716;&#31227;&#20197;&#21450;&#26356;&#24378;&#28872;&#30340;&#20998;&#24067;&#36716;&#31227;&#65288;&#33521;&#35821;&#8594;&#24503;&#35821;&#65289;&#19979;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08763v1 Announce Type: cross  Abstract: Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20379;PSC&#24037;&#20855;&#23558;&#27874;&#26031;&#35821;&#20442;&#35821;&#25991;&#26412;&#36716;&#25442;&#20026;&#27491;&#24335;&#25991;&#26412;&#65292;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#27874;&#26031;&#35821;&#30701;&#25991;&#26412;&#30340;&#24773;&#24863;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.06023</link><description>&lt;p&gt;
&#27874;&#26031;&#35821;&#20442;&#35821;&#25991;&#26412;&#36716;&#25442;&#20026;&#27491;&#24335;&#25991;&#26412;&#20197;&#21450;&#31038;&#20132;&#23186;&#20307;&#19978;&#27874;&#26031;&#35821;&#30701;&#25991;&#26412;&#30340;&#28145;&#24230;&#23398;&#20064;&#29992;&#20110;&#24773;&#24863;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Persian Slang Text Conversion to Formal and Deep Learning of Persian Short Texts on Social Media for Sentiment Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06023
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20379;PSC&#24037;&#20855;&#23558;&#27874;&#26031;&#35821;&#20442;&#35821;&#25991;&#26412;&#36716;&#25442;&#20026;&#27491;&#24335;&#25991;&#26412;&#65292;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#27874;&#26031;&#35821;&#30701;&#25991;&#26412;&#30340;&#24773;&#24863;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#20047;&#36866;&#21512;&#20998;&#26512;&#27874;&#26031;&#35821;&#20250;&#35805;&#25991;&#26412;&#30340;&#24037;&#20855;&#20351;&#24471;&#23545;&#36825;&#20123;&#25991;&#26412;&#65288;&#21253;&#25324;&#24773;&#24863;&#20998;&#26512;&#65289;&#30340;&#21508;&#31181;&#20998;&#26512;&#21464;&#24471;&#22256;&#38590;&#12290;&#26412;&#30740;&#31350;&#23581;&#35797;&#36890;&#36807;&#25552;&#20379;PSC&#65288;&#27874;&#26031;&#35821;&#20442;&#35821;&#36716;&#25442;&#22120;&#65289;&#65292;&#23558;&#20250;&#35805;&#25991;&#26412;&#36716;&#25442;&#20026;&#27491;&#24335;&#25991;&#26412;&#65292;&#24182;&#32467;&#21512;&#26368;&#26032;&#21644;&#26368;&#20339;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#26426;&#22120;&#26356;&#23481;&#26131;&#29702;&#35299;&#36825;&#20123;&#25991;&#26412;&#65292;&#26356;&#22909;&#22320;&#36827;&#34892;&#27874;&#26031;&#35821;&#30701;&#25991;&#26412;&#30340;&#24773;&#24863;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06023v1 Announce Type: new  Abstract: The lack of a suitable tool for the analysis of conversational texts in the Persian language has made various analyses of these texts, including Sentiment Analysis, difficult. In this research, we tried to make the understanding of these texts easier for the machine by providing PSC, Persian Slang Converter, a tool for converting conversational texts into formal ones, and by using the most up-to-date and best deep learning methods along with the PSC, the sentiment learning of short Persian language texts for the machine in a better way. be made More than 10 million unlabeled texts from various social networks and movie subtitles (as Conversational texts) and about 10 million news texts (as formal texts) have been used for training unsupervised models and formal implementation of the tool. 60,000 texts from the comments of Instagram social network users with positive, negative, and neutral labels are considered supervised data for trainin
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;RoFT&#36827;&#34892;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#36793;&#30028;&#26816;&#27979;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#22522;&#20110;&#22256;&#24785;&#24230;&#30340;&#26041;&#27861;&#22312;&#36328;&#39046;&#22495;&#21644;&#36328;&#27169;&#22411;&#35774;&#32622;&#20013;&#26356;&#21152;&#31283;&#20581;&#12290;</title><link>https://arxiv.org/abs/2311.08349</link><description>&lt;p&gt;
&#20351;&#29992;RoFT&#36827;&#34892;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#36793;&#30028;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
AI-generated text boundary detection with RoFT
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08349
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;RoFT&#36827;&#34892;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#36793;&#30028;&#26816;&#27979;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#22522;&#20110;&#22256;&#24785;&#24230;&#30340;&#26041;&#27861;&#22312;&#36328;&#39046;&#22495;&#21644;&#36328;&#27169;&#22411;&#35774;&#32622;&#20013;&#26356;&#21152;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#32463;&#24120;&#36935;&#21040;&#21487;&#33021;&#19968;&#24320;&#22987;&#26159;&#30001;&#20154;&#31867;&#32534;&#20889;&#20294;&#20043;&#21518;&#26159;&#30001;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#12290;&#26816;&#27979;&#36825;&#20123;&#25991;&#26412;&#20013;&#20154;&#31867;&#32534;&#20889;&#21644;&#26426;&#22120;&#29983;&#25104;&#37096;&#20998;&#20043;&#38388;&#30340;&#36793;&#30028;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#22312;&#25991;&#29486;&#20013;&#23578;&#26410;&#21463;&#21040;&#36275;&#22815;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35797;&#22270;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#24182;&#30740;&#31350;&#20960;&#31181;&#26041;&#27861;&#26469;&#23558;&#26368;&#20808;&#36827;&#30340;&#20154;&#24037;&#25991;&#26412;&#26816;&#27979;&#20998;&#31867;&#22120;&#35843;&#25972;&#20026;&#36793;&#30028;&#26816;&#27979;&#35774;&#32622;&#12290;&#25105;&#20204;&#23558;&#25152;&#26377;&#26816;&#27979;&#22120;&#25512;&#21521;&#26497;&#38480;&#65292;&#22312;&#21253;&#21547;&#22810;&#20010;&#20027;&#39064;&#30340;&#30701;&#25991;&#26412;&#30340;Real or Fake&#25991;&#26412;&#22522;&#20934;&#38598;&#19978;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#21253;&#25324;&#21508;&#31181;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#22810;&#26679;&#24615;&#28145;&#20837;&#30740;&#31350;&#25152;&#26377;&#26816;&#27979;&#22120;&#22312;&#36328;&#39046;&#22495;&#21644;&#36328;&#27169;&#22411;&#35774;&#32622;&#20013;&#30340;&#40065;&#26834;&#24615;&#65292;&#20197;&#25552;&#20379;&#26410;&#26469;&#30740;&#31350;&#30340;&#22522;&#32447;&#21644;&#35265;&#35299;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21457;&#29616;&#22522;&#20110;&#22256;&#24785;&#24230;&#30340;&#36793;&#30028;&#26816;&#27979;&#26041;&#27861;&#20542;&#21521;&#20110;&#26356;&#21152;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08349v2 Announce Type: replace  Abstract: Due to the rapid development of large language models, people increasingly often encounter texts that may start as written by a human but continue as machine-generated. Detecting the boundary between human-written and machine-generated parts of such texts is a challenging problem that has not received much attention in literature. We attempt to bridge this gap and examine several ways to adapt state of the art artificial text detection classifiers to the boundary detection setting. We push all detectors to their limits, using the Real or Fake text benchmark that contains short texts on several topics and includes generations of various language models. We use this diversity to deeply examine the robustness of all detectors in cross-domain and cross-model settings to provide baselines and insights for future research. In particular, we find that perplexity-based approaches to boundary detection tend to be more robust to peculiarities 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;transformers&#22312;&#24418;&#24335;&#35821;&#35328;&#35782;&#21035;&#39046;&#22495;&#30340;&#30456;&#20851;&#30740;&#31350;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#26597;&#65292;&#20026;&#29702;&#35299;&#20854;&#34920;&#36798;&#33021;&#21147;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2311.00208</link><description>&lt;p&gt;
Transformers&#20316;&#20026;&#24418;&#24335;&#35821;&#35328;&#35782;&#21035;&#22120;&#65306;&#20851;&#20110;&#34920;&#36798;&#33021;&#21147;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Transformers as Recognizers of Formal Languages: A Survey on Expressivity. (arXiv:2311.00208v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;transformers&#22312;&#24418;&#24335;&#35821;&#35328;&#35782;&#21035;&#39046;&#22495;&#30340;&#30456;&#20851;&#30740;&#31350;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#26597;&#65292;&#20026;&#29702;&#35299;&#20854;&#34920;&#36798;&#33021;&#21147;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;transformers&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#31361;&#20986;&#65292;&#19968;&#20123;&#30740;&#31350;&#20154;&#21592;&#24320;&#22987;&#20174;&#29702;&#35770;&#19978;&#25506;&#35752;&#23427;&#20204;&#33021;&#21542;&#35299;&#20915;&#38382;&#39064;&#65292;&#23558;&#38382;&#39064;&#35270;&#20026;&#24418;&#24335;&#35821;&#35328;&#12290;&#25506;&#32034;&#36825;&#31867;&#38382;&#39064;&#23558;&#26377;&#21161;&#20110;&#27604;&#36739;transformers&#19982;&#20854;&#20182;&#27169;&#22411;&#20197;&#21450;&#19981;&#21516;&#21464;&#31181;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#36825;&#20010;&#23376;&#39046;&#22495;&#30340;&#24037;&#20316;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#36827;&#23637;&#12290;&#26412;&#25991;&#23545;&#36825;&#26041;&#38754;&#30340;&#24037;&#20316;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#26597;&#65292;&#35760;&#24405;&#20102;&#19981;&#21516;&#32467;&#26524;&#32972;&#21518;&#30340;&#21508;&#31181;&#20551;&#35774;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#20197;&#21327;&#35843;&#30475;&#20284;&#30456;&#20114;&#30683;&#30462;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
As transformers have gained prominence in natural language processing, some researchers have investigated theoretically what problems they can and cannot solve, by treating problems as formal languages. Exploring questions such as this will help to compare transformers with other models, and transformer variants with one another, for various tasks. Work in this subarea has made considerable progress in recent years. Here, we undertake a comprehensive survey of this work, documenting the diverse assumptions that underlie different results and providing a unified framework for harmonizing seemingly contradictory findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;CoBa&#65292;&#29992;&#20110;&#20943;&#23569;&#25688;&#35201;&#20013;&#30340;&#24187;&#35273;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#27979;&#37327;&#26465;&#20214;&#35789;&#27010;&#29575;&#21644;&#19978;&#19979;&#25991;&#35789;&#36317;&#31163;&#30340;&#32479;&#35745;&#20449;&#24687;&#36827;&#34892;&#24187;&#35273;&#26816;&#27979;&#65292;&#24182;&#36890;&#36807;&#30452;&#35266;&#30340;&#22238;&#28335;&#27861;&#36827;&#34892;&#20943;&#36731;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;CoBa&#22312;&#20943;&#23569;&#25688;&#35201;&#24187;&#35273;&#26041;&#38754;&#26159;&#26377;&#25928;&#19988;&#39640;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.16176</link><description>&lt;p&gt;
&#36890;&#36807;&#22238;&#28335;&#27861;&#32416;&#27491;&#65292;&#20943;&#23569;&#25688;&#35201;&#20013;&#30340;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Correction with Backtracking Reduces Hallucination in Summarization. (arXiv:2310.16176v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;CoBa&#65292;&#29992;&#20110;&#20943;&#23569;&#25688;&#35201;&#20013;&#30340;&#24187;&#35273;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#27979;&#37327;&#26465;&#20214;&#35789;&#27010;&#29575;&#21644;&#19978;&#19979;&#25991;&#35789;&#36317;&#31163;&#30340;&#32479;&#35745;&#20449;&#24687;&#36827;&#34892;&#24187;&#35273;&#26816;&#27979;&#65292;&#24182;&#36890;&#36807;&#30452;&#35266;&#30340;&#22238;&#28335;&#27861;&#36827;&#34892;&#20943;&#36731;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;CoBa&#22312;&#20943;&#23569;&#25688;&#35201;&#24187;&#35273;&#26041;&#38754;&#26159;&#26377;&#25928;&#19988;&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25688;&#35201;&#29983;&#25104;&#26088;&#22312;&#29983;&#25104;&#28304;&#25991;&#20214;&#30340;&#33258;&#28982;&#35821;&#35328;&#25688;&#35201;&#65292;&#26082;&#31616;&#27905;&#21448;&#20445;&#30041;&#37325;&#35201;&#20803;&#32032;&#12290;&#23613;&#31649;&#26368;&#36817;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#31070;&#32463;&#25991;&#26412;&#25688;&#35201;&#27169;&#22411;&#23481;&#26131;&#20135;&#29983;&#24187;&#35273;&#65288;&#25110;&#26356;&#20934;&#30830;&#22320;&#35828;&#26159;&#28151;&#28102;&#65289;&#65292;&#21363;&#29983;&#25104;&#30340;&#25688;&#35201;&#21253;&#21547;&#28304;&#25991;&#20214;&#20013;&#27809;&#26377;&#26681;&#25454;&#30340;&#32454;&#33410;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;CoBa&#65292;&#29992;&#20110;&#20943;&#23569;&#25688;&#35201;&#20013;&#30340;&#24187;&#35273;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#20004;&#20010;&#27493;&#39588;&#65306;&#24187;&#35273;&#26816;&#27979;&#21644;&#20943;&#36731;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#27979;&#37327;&#26377;&#20851;&#26465;&#20214;&#35789;&#27010;&#29575;&#21644;&#19978;&#19979;&#25991;&#35789;&#36317;&#31163;&#30340;&#31616;&#21333;&#32479;&#35745;&#20449;&#24687;&#21487;&#20197;&#23454;&#29616;&#21069;&#32773;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#30452;&#35266;&#30340;&#22238;&#28335;&#27861;&#22312;&#20943;&#36731;&#24187;&#35273;&#26041;&#38754;&#30340;&#24778;&#20154;&#25928;&#26524;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25991;&#26412;&#25688;&#35201;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23545;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;CoBa&#22312;&#20943;&#23569;&#25688;&#35201;&#24187;&#35273;&#26041;&#38754;&#26159;&#26377;&#25928;&#19988;&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Abstractive summarization aims at generating natural language summaries of a source document that are succinct while preserving the important elements. Despite recent advances, neural text summarization models are known to be susceptible to hallucinating (or more correctly confabulating), that is to produce summaries with details that are not grounded in the source document. In this paper, we introduce a simple yet efficient technique, CoBa, to reduce hallucination in abstractive summarization. The approach is based on two steps: hallucination detection and mitigation. We show that the former can be achieved through measuring simple statistics about conditional word probabilities and distance to context words. Further, we demonstrate that straight-forward backtracking is surprisingly effective at mitigation. We thoroughly evaluate the proposed method with prior art on three benchmark datasets for text summarization. The results show that CoBa is effective and efficient in reducing hall
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#25429;&#25417;&#19978;&#19979;&#25991;&#20449;&#21495;&#21644;&#35821;&#20041;&#32454;&#24494;&#20043;&#22788;&#26041;&#38754;&#30340;&#20248;&#21183;&#21644;&#25361;&#25112;&#65292;&#20197;&#21450;&#19982;&#20256;&#32479;&#26816;&#32034;&#26041;&#27861;&#30340;&#32467;&#21512;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.07107</link><description>&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Large Language Models for Information Retrieval: A Survey. (arXiv:2308.07107v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#25429;&#25417;&#19978;&#19979;&#25991;&#20449;&#21495;&#21644;&#35821;&#20041;&#32454;&#24494;&#20043;&#22788;&#26041;&#38754;&#30340;&#20248;&#21183;&#21644;&#25361;&#25112;&#65292;&#20197;&#21450;&#19982;&#20256;&#32479;&#26816;&#32034;&#26041;&#27861;&#30340;&#32467;&#21512;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#20449;&#24687;&#33719;&#21462;&#30340;&#20027;&#35201;&#25163;&#27573;&#65292;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#31995;&#32479;&#65292;&#22914;&#25628;&#32034;&#24341;&#25806;&#65292;&#24050;&#32463;&#34701;&#20837;&#21040;&#25105;&#20204;&#30340;&#26085;&#24120;&#29983;&#27963;&#20013;&#12290;&#36825;&#20123;&#31995;&#32479;&#36824;&#20316;&#20026;&#23545;&#35805;&#12289;&#38382;&#31572;&#21644;&#25512;&#33616;&#31995;&#32479;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;IR&#30340;&#21457;&#23637;&#36712;&#36857;&#20174;&#22522;&#20110;&#35789;&#39033;&#30340;&#26041;&#27861;&#36215;&#27493;&#65292;&#36880;&#28176;&#21457;&#23637;&#25104;&#19982;&#20808;&#36827;&#30340;&#31070;&#32463;&#27169;&#22411;&#30456;&#34701;&#21512;&#12290;&#23613;&#31649;&#31070;&#32463;&#27169;&#22411;&#25797;&#38271;&#25429;&#25417;&#22797;&#26434;&#30340;&#19978;&#19979;&#25991;&#20449;&#21495;&#21644;&#35821;&#20041;&#32454;&#24494;&#20043;&#22788;&#65292;&#20174;&#32780;&#25913;&#21464;&#20102;IR&#30340;&#26684;&#23616;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#38754;&#20020;&#30528;&#25968;&#25454;&#31232;&#32570;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#29983;&#25104;&#19978;&#19979;&#25991;&#21512;&#29702;&#20294;&#28508;&#22312;&#19981;&#20934;&#30830;&#21709;&#24212;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#28436;&#21464;&#38656;&#35201;&#20256;&#32479;&#26041;&#27861;&#65288;&#22914;&#22522;&#20110;&#35789;&#39033;&#30340;&#31232;&#30095;&#26816;&#32034;&#26041;&#27861;&#19982;&#24555;&#36895;&#21709;&#24212;&#65289;&#21644;&#29616;&#20195;&#31070;&#32463;&#26550;&#26500;&#65288;&#22914;&#20855;&#26377;&#24378;&#22823;&#35821;&#35328;&#29702;&#35299;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#65289;&#30340;&#32467;&#21512;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#21644;GPT-4&#30340;&#20986;&#29616;&#65292;&#24341;&#36215;&#20102;&#19968;&#22330;&#38761;&#21629;
&lt;/p&gt;
&lt;p&gt;
As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#29702;&#35770;&#20449;&#24687;&#20016;&#23500;&#34920;&#31034;&#21644;&#38750;&#29702;&#35770;&#24378;&#22823;&#26426;&#26800;&#24037;&#20855;&#30340;&#36129;&#29486;&#65292;&#24182;&#25351;&#20986;&#24403;&#21069;&#30340;&#27169;&#22411;&#21457;&#23637;&#21644;&#21033;&#29992;&#20013;&#20173;&#28982;&#32570;&#20047;&#20851;&#38190;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.00109</link><description>&lt;p&gt;
&#19968;&#21477;&#35805;&#32988;&#21315;&#24352;&#22270;&#29255;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#29702;&#35299;&#20154;&#31867;&#35821;&#35328;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
A Sentence is Worth a Thousand Pictures: Can Large Language Models Understand Human Language?. (arXiv:2308.00109v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#29702;&#35770;&#20449;&#24687;&#20016;&#23500;&#34920;&#31034;&#21644;&#38750;&#29702;&#35770;&#24378;&#22823;&#26426;&#26800;&#24037;&#20855;&#30340;&#36129;&#29486;&#65292;&#24182;&#25351;&#20986;&#24403;&#21069;&#30340;&#27169;&#22411;&#21457;&#23637;&#21644;&#21033;&#29992;&#20013;&#20173;&#28982;&#32570;&#20047;&#20851;&#38190;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#22312;&#20381;&#36182;&#20110;&#19979;&#19968;&#20010;&#21333;&#35789;&#39044;&#27979;&#30340;&#35821;&#35328;&#30456;&#20851;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#24403;&#21069;&#19968;&#20195;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#35748;&#20026;&#33021;&#22815;&#36798;&#21040;&#31867;&#20154;&#35821;&#35328;&#34920;&#29616;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#24212;&#29992;&#34987;&#35465;&#20026;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#21516;&#26102;&#20063;&#26159;&#23545;&#20154;&#31867;&#35821;&#35328;&#35748;&#30693;&#21644;&#31070;&#32463;&#22522;&#30784;&#30340;&#37325;&#22823;&#36827;&#23637;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#30446;&#26631;&#31995;&#32479;&#30340;&#29702;&#35770;&#20449;&#24687;&#20016;&#23500;&#34920;&#31034;&#19982;&#38750;&#29702;&#35770;&#24378;&#22823;&#26426;&#26800;&#24037;&#20855;&#30340;&#36129;&#29486;&#65292;&#24182;&#30830;&#23450;&#20102;&#24403;&#21069;&#21457;&#23637;&#21644;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#25152;&#32570;&#22833;&#30340;&#20851;&#38190;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence applications show great potential for language-related tasks that rely on next-word prediction. The current generation of large language models have been linked to claims about human-like linguistic performance and their applications are hailed both as a key step towards Artificial General Intelligence and as major advance in understanding the cognitive, and even neural basis of human language. We analyze the contribution of large language models as theoretically informative representations of a target system vs. atheoretical powerful mechanistic tools, and we identify the key abilities that are still missing from the current state of development and exploitation of these models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#22270;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#21487;&#20197;&#23558;&#19978;&#19979;&#25991;&#22686;&#24378;&#30340;&#30693;&#35782;&#32858;&#21512;&#36807;&#31243;&#19982;&#30456;&#20851;&#30693;&#35782;&#22270;&#30340;&#20840;&#23616;&#29305;&#24449;&#26377;&#25928;&#34701;&#21512;&#65292;&#23558;&#22686;&#24378;&#30340;&#22270;&#32467;&#26500;&#30693;&#35782;&#38598;&#25104;&#21040;&#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#23545;&#35805;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#33258;&#21160;&#24230;&#37327;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#38754;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.06294</link><description>&lt;p&gt;
CADGE&#65306;&#22522;&#20110;&#22270;&#32467;&#26500;&#30693;&#35782;&#32858;&#21512;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#23545;&#35805;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
CADGE: Context-Aware Dialogue Generation Enhanced with Graph-Structured Knowledge Aggregation. (arXiv:2305.06294v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#22270;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#21487;&#20197;&#23558;&#19978;&#19979;&#25991;&#22686;&#24378;&#30340;&#30693;&#35782;&#32858;&#21512;&#36807;&#31243;&#19982;&#30456;&#20851;&#30693;&#35782;&#22270;&#30340;&#20840;&#23616;&#29305;&#24449;&#26377;&#25928;&#34701;&#21512;&#65292;&#23558;&#22686;&#24378;&#30340;&#22270;&#32467;&#26500;&#30693;&#35782;&#38598;&#25104;&#21040;&#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#23545;&#35805;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#33258;&#21160;&#24230;&#37327;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#38754;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35782;&#30693;&#35782;&#65288;commonsense knowledge&#65289;&#23545;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#26469;&#35828;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#24120;&#23558;&#22270;&#30693;&#35782;&#19982;&#20256;&#32479;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30456;&#32467;&#21512;&#65292;&#23548;&#33268;&#25991;&#26412;&#21644;&#22270;&#30693;&#35782;&#32534;&#30721;&#36807;&#31243;&#22312;&#20018;&#34892;&#27969;&#27700;&#32447;&#20013;&#34987;&#20998;&#31163;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#20123;&#20998;&#31163;&#30340;&#34920;&#31034;&#23398;&#20064;&#38454;&#27573;&#21487;&#33021;&#23545;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21253;&#21547;&#22312;&#20004;&#31181;&#36755;&#20837;&#30693;&#35782;&#31867;&#22411;&#20013;&#30340;&#25972;&#20307;&#19978;&#19979;&#25991;&#26159;&#27425;&#20248;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#22270;&#27880;&#24847;&#21147;&#27169;&#22411;&#65288;Context-aware GAT&#65289;&#65292;&#23427;&#21487;&#20197;&#22522;&#20110;&#19978;&#19979;&#25991;&#22686;&#24378;&#30340;&#30693;&#35782;&#32858;&#21512;&#36807;&#31243;&#26377;&#25928;&#22320;&#34701;&#21512;&#30456;&#20851;&#30693;&#35782;&#22270;&#30340;&#20840;&#23616;&#29305;&#24449;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21033;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#26469;&#22788;&#29702;&#24322;&#26500;&#29305;&#24449;&#8212;&#8212;&#23558;&#22270;&#30693;&#35782;&#19982;&#25991;&#26412;&#30456;&#32467;&#21512;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#27425;&#23581;&#35797;&#22312;&#36830;&#25509;&#23376;&#22270;&#19978;&#20998;&#23618;&#24212;&#29992;&#22270;&#30693;&#35782;&#32858;&#21512;&#20197;&#21450;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#24182;&#23558;&#22686;&#24378;&#30340;&#22270;&#32467;&#26500;&#30693;&#35782;&#38598;&#25104;&#21040;&#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#23545;&#35805;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#33258;&#21160;&#24230;&#37327;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#38754;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Commonsense knowledge is crucial to many natural language processing tasks. Existing works usually incorporate graph knowledge with conventional graph neural networks (GNNs), leading to the text and graph knowledge encoding processes being separated in a serial pipeline. We argue that these separate representation learning stages may be suboptimal for neural networks to learn the overall context contained in both types of input knowledge. In this paper, we propose a novel context-aware graph-attention model (Context-aware GAT), which can effectively incorporate global features of relevant knowledge graphs based on a context-enhanced knowledge aggregation process. Specifically, our framework leverages a novel representation learning approach to process heterogeneous features - combining flattened graph knowledge with text. To the best of our knowledge, this is the first attempt at hierarchically applying graph knowledge aggregation on a connected subgraph in addition to contextual infor
&lt;/p&gt;</description></item></channel></rss>