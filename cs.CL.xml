<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#20195;&#29702;&#30340;&#26032;&#30340;&#35268;&#21010;&#22522;&#20934;TravelPlanner&#65292;&#23427;&#20851;&#27880;&#20110;&#26053;&#34892;&#35268;&#21010;&#36825;&#19968;&#24120;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#12290;&#32463;&#36807;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#30446;&#21069;&#30340;&#35821;&#35328;&#20195;&#29702;&#20173;&#26080;&#27861;&#22788;&#29702;&#22914;&#27492;&#22797;&#26434;&#30340;&#35268;&#21010;&#20219;&#21153;&#65292;&#21363;&#20351;&#26368;&#20808;&#36827;&#30340;GPT-4&#20063;&#21482;&#33021;&#36798;&#21040;0.6%&#30340;&#25104;&#21151;&#29575;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01622</link><description>&lt;p&gt;
TravelPlanner: &#19968;&#31181;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#20195;&#29702;&#30340;&#30495;&#23454;&#19990;&#30028;&#35268;&#21010;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
TravelPlanner: A Benchmark for Real-World Planning with Language Agents
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#20195;&#29702;&#30340;&#26032;&#30340;&#35268;&#21010;&#22522;&#20934;TravelPlanner&#65292;&#23427;&#20851;&#27880;&#20110;&#26053;&#34892;&#35268;&#21010;&#36825;&#19968;&#24120;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#12290;&#32463;&#36807;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#30446;&#21069;&#30340;&#35821;&#35328;&#20195;&#29702;&#20173;&#26080;&#27861;&#22788;&#29702;&#22914;&#27492;&#22797;&#26434;&#30340;&#35268;&#21010;&#20219;&#21153;&#65292;&#21363;&#20351;&#26368;&#20808;&#36827;&#30340;GPT-4&#20063;&#21482;&#33021;&#36798;&#21040;0.6%&#30340;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35268;&#21010;&#36215;&#21021;&#23601;&#26159;&#20154;&#24037;&#26234;&#33021;&#30340;&#26680;&#24515;&#36861;&#27714;&#20043;&#19968;&#65292;&#20294;&#26089;&#26399;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#22823;&#22810;&#38598;&#20013;&#22312;&#21463;&#38480;&#29615;&#22659;&#19979;&#65292;&#22240;&#20026;&#32570;&#20047;&#36827;&#34892;&#20154;&#31867;&#27700;&#24179;&#35268;&#21010;&#25152;&#38656;&#30340;&#35768;&#22810;&#35748;&#30693;&#22522;&#30784;&#12290;&#26368;&#36817;&#65292;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#39537;&#21160;&#30340;&#35821;&#35328;&#20195;&#29702;&#23637;&#29616;&#20986;&#20102;&#24037;&#20855;&#20351;&#29992;&#21644;&#25512;&#29702;&#31561;&#26377;&#36259;&#30340;&#33021;&#21147;&#12290;&#36825;&#20123;&#35821;&#35328;&#20195;&#29702;&#33021;&#21542;&#22312;&#36229;&#20986;&#20808;&#21069;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#33539;&#22260;&#30340;&#26356;&#22797;&#26434;&#29615;&#22659;&#20013;&#36827;&#34892;&#35268;&#21010;&#65311;&#20026;&#20102;&#25512;&#36827;&#36825;&#39033;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TravelPlanner&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#30340;&#35268;&#21010;&#22522;&#20934;&#65292;&#19987;&#27880;&#20110;&#26053;&#34892;&#35268;&#21010;&#36825;&#20010;&#24120;&#35265;&#30340;&#30495;&#23454;&#19990;&#30028;&#35268;&#21010;&#22330;&#26223;&#12290;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#20016;&#23500;&#30340;&#27801;&#30418;&#29615;&#22659;&#65292;&#21508;&#31181;&#29992;&#20110;&#35775;&#38382;&#36817;400&#19975;&#20010;&#25968;&#25454;&#35760;&#24405;&#30340;&#24037;&#20855;&#65292;&#24182;&#21253;&#21547;1225&#20010;&#31934;&#24515;&#31574;&#21010;&#30340;&#35268;&#21010;&#24847;&#22270;&#21644;&#21442;&#32771;&#35745;&#21010;&#12290;&#32508;&#21512;&#35780;&#20272;&#26174;&#31034;&#65292;&#24403;&#21069;&#30340;&#35821;&#35328;&#20195;&#29702;&#23578;&#19981;&#20855;&#22791;&#22788;&#29702;&#22914;&#27492;&#22797;&#26434;&#30340;&#35268;&#21010;&#20219;&#21153;&#30340;&#33021;&#21147;-&#21363;&#20351;&#26159;GPT-4&#30340;&#25104;&#21151;&#29575;&#20063;&#21482;&#26377;0.6%&#12290;
&lt;/p&gt;
&lt;p&gt;
Planning has been part of the core pursuit for artificial intelligence since its conception, but earlier AI agents mostly focused on constrained settings because many of the cognitive substrates necessary for human-level planning have been lacking. Recently, language agents powered by large language models (LLMs) have shown interesting capabilities such as tool use and reasoning. Are these language agents capable of planning in more complex settings that are out of the reach of prior AI agents? To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and 1,225 meticulously curated planning intents and reference plans. Comprehensive evaluations show that the current language agents are not yet capable of handling such complex planning tasks-even GPT-4 only achieves a success rate of 0.6%. La
&lt;/p&gt;</description></item><item><title>&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#65292;&#36890;&#36807;&#23558;LLMs&#38598;&#25104;&#21040;&#20027;&#21160;&#23398;&#20064;&#24490;&#29615;&#20013;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#65292;&#26377;&#25928;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#37327;&#65292;&#24182;&#21462;&#24471;&#25509;&#36817;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2404.02261</link><description>&lt;p&gt;
&#22312;LLMs&#20013;&#24490;&#29615;&#65306;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27880;&#37322;&#36827;&#34892;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02261
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#65292;&#36890;&#36807;&#23558;LLMs&#38598;&#25104;&#21040;&#20027;&#21160;&#23398;&#20064;&#24490;&#29615;&#20013;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#65292;&#26377;&#25928;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#37327;&#65292;&#24182;&#21462;&#24471;&#25509;&#36817;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#35821;&#35328;&#36164;&#28304;&#21644;&#25968;&#25454;&#26631;&#27880;&#19987;&#19994;&#30693;&#35782;&#26377;&#38480;&#65292;&#20302;&#36164;&#28304;&#35821;&#35328;&#22312;&#20154;&#24037;&#26234;&#33021;&#24320;&#21457;&#20013;&#38754;&#20020;&#30528;&#37325;&#22823;&#38556;&#30861;&#65292;&#20351;&#23427;&#20204;&#21464;&#24471;&#32597;&#35265;&#19988;&#25104;&#26412;&#39640;&#26114;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#19981;&#36275;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;LLMs&#30340;&#28508;&#21147;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#33410;&#20013;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#35780;&#20272;&#20197;&#35780;&#20272;&#27880;&#37322;&#32773;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#36873;&#25321;&#36866;&#24403;&#30340;LLM&#27880;&#37322;&#32773;&#12290;&#28982;&#21518;&#65292;&#36873;&#25321;&#30340;&#27880;&#37322;&#32773;&#34987;&#38598;&#25104;&#21040;&#19968;&#20010;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#24490;&#29615;&#20013;&#65292;&#20351;&#29992;&#20027;&#21160;&#23398;&#20064;&#33539;&#24335;&#65292;&#26368;&#23567;&#21270;&#25152;&#38656;&#30340;&#26597;&#35810;&#25968;&#25454;&#37327;&#12290;&#23454;&#35777;&#35780;&#20272;&#65292;&#29305;&#21035;&#26159;&#20351;&#29992;GPT-4-Turbo&#65292;&#23637;&#31034;&#20102;&#20960;&#20046;&#36798;&#21040;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22823;&#22823;&#20943;&#23569;&#20102;&#25968;&#25454;&#38656;&#27714;&#65292;&#30001;&#20272;&#31639;&#30340;&#28508;&#22312;&#24615;&#33021;&#25351;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02261v1 Announce Type: cross  Abstract: Low-resource languages face significant barriers in AI development due to limited linguistic resources and expertise for data labeling, rendering them rare and costly. The scarcity of data and the absence of preexisting tools exacerbate these challenges, especially since these languages may not be adequately represented in various NLP datasets. To address this gap, we propose leveraging the potential of LLMs in the active learning loop for data annotation. Initially, we conduct evaluations to assess inter-annotator agreement and consistency, facilitating the selection of a suitable LLM annotator. The chosen annotator is then integrated into a training loop for a classifier using an active learning paradigm, minimizing the amount of queried data required. Empirical evaluations, notably employing GPT-4-Turbo, demonstrate near-state-of-the-art performance with significantly reduced data requirements, as indicated by estimated potential co
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Regularized Best-of-N (RBoN)&#65292;&#36890;&#36807;&#24341;&#20837;&#25509;&#36817;&#24615;&#39033;&#26469;&#20943;&#36731;&#22870;&#21169;&#27450;&#39575;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#22312;&#35299;&#30721;&#26102;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2404.01054</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;&#30340;&#26368;&#20339;-N&#37319;&#26679;&#20197;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#20013;&#30340;&#22870;&#21169;&#27450;&#39575;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01054
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Regularized Best-of-N (RBoN)&#65292;&#36890;&#36807;&#24341;&#20837;&#25509;&#36817;&#24615;&#39033;&#26469;&#20943;&#36731;&#22870;&#21169;&#27450;&#39575;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#22312;&#35299;&#30721;&#26102;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Best-of-N (BoN)&#37319;&#26679;&#19982;&#22870;&#21169;&#27169;&#22411;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#29992;&#20110;&#22312;&#35299;&#30721;&#26102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#12290;&#28982;&#32780;&#65292;BoN&#37319;&#26679;&#23481;&#26131;&#21463;&#21040;&#22870;&#21169;&#27450;&#39575;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#38450;&#27490;&#22870;&#21169;&#27450;&#39575;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Regularized Best-of-N (RBoN)&#30340;&#21464;&#20307;&#65292;&#36890;&#36807;&#22312;&#21709;&#24212;&#36873;&#25321;&#20013;&#32467;&#21512;&#25509;&#36817;&#24615;&#39033;&#26469;&#20943;&#36731;&#22870;&#21169;&#27450;&#39575;&#65292;&#31867;&#20284;&#20110;&#20559;&#22909;&#23398;&#20064;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01054v1 Announce Type: cross  Abstract: Best-of-N (BoN) sampling with a reward model has been shown to be an effective strategy for aligning Large Language Models (LLMs) to human preferences at the time of decoding. BoN sampling is susceptible to a problem known as reward hacking. Because the reward model is an imperfect proxy for the true objective, over-optimizing its value can compromise its performance on the true objective. A common solution to prevent reward hacking in preference learning techniques is to optimize a reward using proximity regularization (e.g., KL regularization), which ensures that the language model remains close to the reference model. In this research, we propose Regularized Best-of-N (RBoN), a variant of BoN that aims to mitigate reward hacking by incorporating a proximity term in response selection, similar to preference learning techniques. We evaluate two variants of RBoN on the AlpacaFarm dataset and find that they outperform BoN, especially wh
&lt;/p&gt;</description></item><item><title>&#39318;&#27425;&#24341;&#20837; NaijaHate &#25968;&#25454;&#38598;&#65292;&#22312;&#23612;&#26085;&#21033;&#20122;&#25512;&#29305;&#19978;&#35780;&#20272; HSD&#65292;&#21457;&#29616;&#22312;&#20195;&#34920;&#24615;&#25968;&#25454;&#19978;&#35780;&#20272;&#30340; HSD &#24615;&#33021;&#39640;&#20272;&#20102;&#30495;&#23454;&#19990;&#30028;&#30340;&#34920;&#29616;&#65292;&#25552;&#20986; NaijaXLM-T &#27169;&#22411;&#65292;&#31361;&#20986;&#20102;&#22495;&#33258;&#36866;&#24212;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#22312;&#26368;&#22823;&#21270; HSD &#24615;&#33021;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;</title><link>https://arxiv.org/abs/2403.19260</link><description>&lt;p&gt;
NaijaHate: &#20351;&#29992;&#20195;&#34920;&#24615;&#25968;&#25454;&#35780;&#20272;&#23612;&#26085;&#21033;&#20122; Twitter &#19978;&#30340;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19260
&lt;/p&gt;
&lt;p&gt;
&#39318;&#27425;&#24341;&#20837; NaijaHate &#25968;&#25454;&#38598;&#65292;&#22312;&#23612;&#26085;&#21033;&#20122;&#25512;&#29305;&#19978;&#35780;&#20272; HSD&#65292;&#21457;&#29616;&#22312;&#20195;&#34920;&#24615;&#25968;&#25454;&#19978;&#35780;&#20272;&#30340; HSD &#24615;&#33021;&#39640;&#20272;&#20102;&#30495;&#23454;&#19990;&#30028;&#30340;&#34920;&#29616;&#65292;&#25552;&#20986; NaijaXLM-T &#27169;&#22411;&#65292;&#31361;&#20986;&#20102;&#22495;&#33258;&#36866;&#24212;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#22312;&#26368;&#22823;&#21270; HSD &#24615;&#33021;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#22312;&#32447;&#24179;&#21488;&#19978;&#24694;&#24847;&#20869;&#23481;&#34067;&#24310;&#30340;&#20840;&#29699;&#38382;&#39064;&#65292;&#36890;&#24120;&#20250;&#22312;&#32654;&#22269;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#19978;&#24320;&#21457;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#65288;HSD&#65289;&#27169;&#22411;&#65292;&#20174;&#32780;&#26080;&#27861;&#25512;&#24191;&#21040;&#26469;&#33258;&#22823;&#22810;&#25968;&#19990;&#30028;&#30340;&#33521;&#35821;&#26041;&#35328;&#12290;&#27492;&#22806;&#65292;HSD&#27169;&#22411;&#36890;&#24120;&#22312;&#31574;&#21010;&#26679;&#26412;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#24341;&#21457;&#20102;&#23545;&#22312;&#30495;&#23454;&#29615;&#22659;&#20013;&#39640;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#25285;&#24551;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#29992;&#20110;HSD&#26631;&#27880;&#30340; NaijaHate &#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#23612;&#26085;&#21033;&#20122;&#25512;&#25991;&#30340;&#20195;&#34920;&#24615;&#26679;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;HSD&#22312;&#20256;&#32479;&#25991;&#29486;&#20013;&#20256;&#32479;&#20351;&#29992;&#30340;&#26377;&#20559;&#35265;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#65292;&#22312;&#20195;&#34920;&#24615;&#25968;&#25454;&#19978;&#24456;&#22823;&#31243;&#24230;&#19978;&#39640;&#20272;&#20102;&#30495;&#23454;&#19990;&#30028;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102; NaijaXLM-T&#65292;&#19968;&#20010;&#38024;&#23545;&#23612;&#26085;&#21033;&#20122; Twitter &#19978;&#19979;&#25991;&#37327;&#36523;&#23450;&#21046;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#24314;&#31435;&#20102;&#22495;&#33258;&#36866;&#24212;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#22312;&#26368;&#22823;&#21270;HSD&#24615;&#33021;&#26041;&#38754;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20154;-&#26426;&#28151;&#21512;&#26041;&#27861;&#21457;&#25381;&#20102;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19260v1 Announce Type: new  Abstract: To address the global issue of hateful content proliferating in online platforms, hate speech detection (HSD) models are typically developed on datasets collected in the United States, thereby failing to generalize to English dialects from the Majority World. Furthermore, HSD models are often evaluated on curated samples, raising concerns about overestimating model performance in real-world settings. In this work, we introduce NaijaHate, the first dataset annotated for HSD which contains a representative sample of Nigerian tweets. We demonstrate that HSD evaluated on biased datasets traditionally used in the literature largely overestimates real-world performance on representative data. We also propose NaijaXLM-T, a pretrained model tailored to the Nigerian Twitter context, and establish the key role played by domain-adaptive pretraining and finetuning in maximizing HSD performance. Finally, we show that in this context, a human-in-the-l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#23545;&#40784;&#21015;&#34920;&#25490;&#21517;&#30446;&#26631;&#30340;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65288;ALRO&#65289;&#65292;&#26088;&#22312;&#24357;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#19982;&#25512;&#33616;&#31995;&#32479;&#25490;&#21517;&#20219;&#21153;&#30340;&#35201;&#27714;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.19181</link><description>&lt;p&gt;
&#35753;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#26356;&#22909;&#30340;&#25490;&#21517;&#22120;
&lt;/p&gt;
&lt;p&gt;
Make Large Language Model a Better Ranker
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19181
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#23545;&#40784;&#21015;&#34920;&#25490;&#21517;&#30446;&#26631;&#30340;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65288;ALRO&#65289;&#65292;&#26088;&#22312;&#24357;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#19982;&#25512;&#33616;&#31995;&#32479;&#25490;&#21517;&#20219;&#21153;&#30340;&#35201;&#27714;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21457;&#23637;&#26174;&#33879;&#22686;&#24378;&#20102;&#21508;&#20010;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#65288;RSs&#65289;&#27010;&#24565;&#21644;&#24320;&#21457;&#26041;&#24335;&#21457;&#29983;&#20102;&#36716;&#21464;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#28857;&#23545;&#28857;&#21644;&#25104;&#23545;&#25512;&#33616;&#33539;&#24335;&#19978;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#22120;&#20013;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#19968;&#20123;&#30740;&#31350;&#34429;&#28982;&#28145;&#20837;&#30740;&#31350;&#20102;&#21015;&#34920;&#22411;&#26041;&#27861;&#65292;&#20294;&#22312;&#25490;&#21517;&#20219;&#21153;&#20013;&#34920;&#29616;&#19981;&#20339;&#12290;&#36825;&#19968;&#19981;&#36275;&#24402;&#22240;&#20110;&#25490;&#21517;&#21644;&#35821;&#35328;&#29983;&#25104;&#30446;&#26631;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#20855;&#26377;&#23545;&#40784;&#21015;&#34920;&#25490;&#21517;&#30446;&#26631;&#30340;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65288;ALRO&#65289;&#12290;ALRO&#26088;&#22312;&#24357;&#21512;LLMs&#30340;&#33021;&#21147;&#19982;&#25512;&#33616;&#31995;&#32479;&#25490;&#21517;&#20219;&#21153;&#30340;&#24494;&#22937;&#35201;&#27714;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;ALRO&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#26159;&#24341;&#20837;&#20102;&#36719;lambda&#20540;lo
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19181v1 Announce Type: cross  Abstract: The evolution of Large Language Models (LLMs) has significantly enhanced capabilities across various fields, leading to a paradigm shift in how Recommender Systems (RSs) are conceptualized and developed. However, existing research primarily focuses on point-wise and pair-wise recommendation paradigms. These approaches prove inefficient in LLM-based recommenders due to the high computational cost of utilizing Large Language Models. While some studies have delved into list-wise approaches, they fall short in ranking tasks. This shortfall is attributed to the misalignment between the objectives of ranking and language generation. To this end, this paper introduces the Language Model Framework with Aligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap between the capabilities of LLMs and the nuanced requirements of ranking tasks within recommender systems. A key feature of ALRO is the introduction of soft lambda lo
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23545;25&#31181;&#20302;&#36164;&#28304;&#35821;&#35328;&#21644;7&#31181;&#30456;&#23545;&#36739;&#39640;&#36164;&#28304;&#35821;&#35328;&#19978;&#30340;&#24773;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#21450;&#20854;&#36328;&#35821;&#35328;&#21464;&#20307;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#20351;&#29992;LLMs&#36827;&#34892;ICL&#30340;&#26377;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#26367;&#20195;&#26041;&#27861;&#26597;&#35810;&#23545;&#40784;&#65292;&#24182;&#20026;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;ICL&#25552;&#20379;&#20102;&#23453;&#36149;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.16512</link><description>&lt;p&gt;
LLMs&#26159;&#23569;&#26679;&#26412;&#24773;&#22659;&#20302;&#36164;&#28304;&#35821;&#35328;&#23398;&#20064;&#22120;
&lt;/p&gt;
&lt;p&gt;
LLMs Are Few-Shot In-Context Low-Resource Language Learners
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16512
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;25&#31181;&#20302;&#36164;&#28304;&#35821;&#35328;&#21644;7&#31181;&#30456;&#23545;&#36739;&#39640;&#36164;&#28304;&#35821;&#35328;&#19978;&#30340;&#24773;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#21450;&#20854;&#36328;&#35821;&#35328;&#21464;&#20307;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#20351;&#29992;LLMs&#36827;&#34892;ICL&#30340;&#26377;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#26367;&#20195;&#26041;&#27861;&#26597;&#35810;&#23545;&#40784;&#65292;&#24182;&#20026;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;ICL&#25552;&#20379;&#20102;&#23453;&#36149;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24773;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#30340;&#25903;&#25345;&#19979;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21487;&#20197;&#21033;&#29992;&#30701;&#26102;&#30340;&#24773;&#22659;&#20449;&#24687;&#25191;&#34892;&#21508;&#31181;&#20219;&#21153;&#65292;&#36825;&#20026;&#32553;&#23567;&#39640;&#36164;&#28304;&#35821;&#35328;&#21644;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24046;&#36317;&#25552;&#20379;&#20102;&#37325;&#35201;&#36884;&#24452;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#21482;&#26377;&#23569;&#25968;&#30740;&#31350;&#25506;&#35752;&#20102;&#38024;&#23545;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;ICL&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#38598;&#20013;&#22312;&#30456;&#23545;&#39640;&#36164;&#28304;&#30340;&#35821;&#35328;&#65292;&#27604;&#22914;&#27861;&#35821;&#21644;&#35199;&#29677;&#29273;&#35821;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;25&#31181;&#20302;&#36164;&#28304;&#35821;&#35328;&#21644;7&#31181;&#30456;&#23545;&#36739;&#39640;&#36164;&#28304;&#35821;&#35328;&#19978;&#30340;ICL&#21450;&#20854;&#36328;&#35821;&#35328;&#21464;&#20307;&#65288;X-ICL&#65289;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#19981;&#20165;&#35780;&#20272;&#20102;LLMs&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#20351;&#29992;ICL&#30340;&#26377;&#25928;&#24615;&#65292;&#36824;&#21457;&#29616;&#20102;&#24773;&#22659;&#26631;&#31614;&#23545;&#40784;&#30340;&#32570;&#38519;&#65292;&#24182;&#24341;&#20837;&#20102;&#26356;&#26377;&#25928;&#30340;&#26367;&#20195;&#26041;&#27861;&#65306;&#26597;&#35810;&#23545;&#40784;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;ICL&#30340;&#21508;&#20010;&#26041;&#38754;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24635;&#32467;&#20102;&#23569;&#26679;&#26412;&#24773;&#22659;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16512v1 Announce Type: cross  Abstract: In-context learning (ICL) empowers large language models (LLMs) to perform diverse tasks in underrepresented languages using only short in-context information, offering a crucial avenue for narrowing the gap between high-resource and low-resource languages. Nonetheless, there is only a handful of works explored ICL for low-resource languages with most of them focusing on relatively high-resource languages, such as French and Spanish. In this work, we extensively study ICL and its cross-lingual variation (X-ICL) on 25 low-resource and 7 relatively higher-resource languages. Our study not only assesses the effectiveness of ICL with LLMs in low-resource languages but also identifies the shortcomings of in-context label alignment, and introduces a more effective alternative: query alignment. Moreover, we provide valuable insights into various facets of ICL for low-resource languages. Our study concludes the significance of few-shot in-cont
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22312;&#20013;&#21307;&#39046;&#22495;&#26500;&#24314;&#20102;&#19987;&#19994;&#35821;&#26009;&#24211;&#65292;&#22522;&#20110;LLaMA&#25104;&#21151;&#24320;&#21457;&#20102;&#39318;&#20010;&#32463;&#36807;&#23436;&#25972;&#35757;&#32451;&#30340;Qibo&#27169;&#22411;&#65292;&#24182;&#25512;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272;LLMs&#24615;&#33021;&#30340;Qibo&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>https://arxiv.org/abs/2403.16056</link><description>&lt;p&gt;
Qibo: &#19968;&#31181;&#29992;&#20110;&#20013;&#21307;&#39046;&#22495;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Qibo: A Large Language Model for Traditional Chinese Medicine
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22312;&#20013;&#21307;&#39046;&#22495;&#26500;&#24314;&#20102;&#19987;&#19994;&#35821;&#26009;&#24211;&#65292;&#22522;&#20110;LLaMA&#25104;&#21151;&#24320;&#21457;&#20102;&#39318;&#20010;&#32463;&#36807;&#23436;&#25972;&#35757;&#32451;&#30340;Qibo&#27169;&#22411;&#65292;&#24182;&#25512;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272;LLMs&#24615;&#33021;&#30340;Qibo&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23637;&#31034;&#20102;&#22312;&#29992;&#25143;&#24847;&#22270;&#29702;&#35299;&#21644;&#21709;&#24212;&#26041;&#38754;&#21462;&#24471;&#30340;&#26174;&#33879;&#36827;&#23637;&#65292;&#22312;&#35768;&#22810;&#19987;&#19994;&#39046;&#22495;&#65292;&#21253;&#25324;&#21307;&#23398;&#12289;&#27861;&#24459;&#21644;&#37329;&#34701;&#12290;&#28982;&#32780;&#65292;&#22312;&#20013;&#21307;&#39046;&#22495;&#65292;LLMs&#30340;&#24615;&#33021;&#25552;&#21319;&#21463;&#21040;&#25361;&#25112;&#65292;&#20854;&#21407;&#22240;&#22312;&#20110;&#20013;&#21307;&#29702;&#35770;&#19982;&#29616;&#20195;&#21307;&#23398;&#20043;&#38388;&#30340;&#26681;&#26412;&#24046;&#24322;&#65292;&#20197;&#21450;&#32570;&#20047;&#19987;&#19994;&#35821;&#26009;&#24211;&#36164;&#28304;&#12290;&#26412;&#25991;&#26088;&#22312;&#26500;&#24314;&#21644;&#25972;&#29702;&#20013;&#21307;&#39046;&#22495;&#30340;&#19987;&#19994;&#35821;&#26009;&#24211;&#65292;&#36171;&#20104;&#22823;&#22411;&#27169;&#22411;&#20855;&#26377;&#20013;&#21307;&#29702;&#35770;&#29305;&#33394;&#30340;&#19987;&#19994;&#30693;&#35782;&#65292;&#24182;&#25104;&#21151;&#22522;&#20110;LLaMA&#24320;&#21457;&#20102;Qibo&#27169;&#22411;&#65292;&#36825;&#26159;&#20013;&#21307;&#39046;&#22495;&#31532;&#19968;&#20010;&#32463;&#36807;&#23436;&#25972;&#35757;&#32451;&#36807;&#31243;&#65288;&#20174;&#39044;&#35757;&#32451;&#21040;&#30417;&#30563;&#24494;&#35843;&#65289;&#30340;LLM&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Qibo&#22522;&#20934;&#27979;&#35797;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#24615;&#33021;&#30340;&#19987;&#38376;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16056v1 Announce Type: cross  Abstract: In the field of Artificial Intelligence, Large Language Models (LLMs) have demonstrated significant advances in user intent understanding and response in a number of specialized domains, including medicine, law, and finance. However, in the unique domain of traditional Chinese medicine (TCM), the performance enhancement of LLMs is challenged by the essential differences between its theories and modern medicine, as well as the lack of specialized corpus resources. In this paper, we aim to construct and organize a professional corpus in the field of TCM, to endow the large model with professional knowledge that is characteristic of TCM theory, and to successfully develop the Qibo model based on LLaMA, which is the first LLM in the field of TCM to undergo a complete training process from pre-training to Supervised Fine-Tuning (SFT). Furthermore, we develop the Qibo-benchmark, a specialized tool for evaluating the performance of LLMs, whic
&lt;/p&gt;</description></item><item><title>Fundus&#26159;&#19968;&#20010;&#31616;&#21333;&#26131;&#29992;&#30340;&#26032;&#38395;&#29228;&#34411;&#24037;&#20855;&#65292;&#36890;&#36807;&#25163;&#24037;&#23450;&#21046;&#30340;&#20869;&#23481;&#25552;&#21462;&#22120;&#65292;&#38024;&#23545;&#27599;&#20010;&#25903;&#25345;&#30340;&#22312;&#32447;&#25253;&#32440;&#26684;&#24335;&#25351;&#21335;&#36827;&#34892;&#20248;&#21270;&#65292;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#26032;&#38395;&#25991;&#31456;&#25552;&#21462;&#65292;&#21516;&#26102;&#32467;&#21512;&#29228;&#21462;&#21644;&#20869;&#23481;&#25552;&#21462;&#20110;&#19968;&#20307;&#65292;&#20026;&#38750;&#25216;&#26415;&#29992;&#25143;&#25552;&#20379;&#32479;&#19968;&#20351;&#29992;&#30028;&#38754;&#12290;</title><link>https://arxiv.org/abs/2403.15279</link><description>&lt;p&gt;
Fundus&#65306;&#19968;&#20010;&#31616;&#21333;&#26131;&#29992;&#30340;&#26032;&#38395;&#29228;&#34411;&#65292;&#20248;&#21270;&#39640;&#36136;&#37327;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Fundus: A Simple-to-Use News Scraper Optimized for High Quality Extractions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15279
&lt;/p&gt;
&lt;p&gt;
Fundus&#26159;&#19968;&#20010;&#31616;&#21333;&#26131;&#29992;&#30340;&#26032;&#38395;&#29228;&#34411;&#24037;&#20855;&#65292;&#36890;&#36807;&#25163;&#24037;&#23450;&#21046;&#30340;&#20869;&#23481;&#25552;&#21462;&#22120;&#65292;&#38024;&#23545;&#27599;&#20010;&#25903;&#25345;&#30340;&#22312;&#32447;&#25253;&#32440;&#26684;&#24335;&#25351;&#21335;&#36827;&#34892;&#20248;&#21270;&#65292;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#26032;&#38395;&#25991;&#31456;&#25552;&#21462;&#65292;&#21516;&#26102;&#32467;&#21512;&#29228;&#21462;&#21644;&#20869;&#23481;&#25552;&#21462;&#20110;&#19968;&#20307;&#65292;&#20026;&#38750;&#25216;&#26415;&#29992;&#25143;&#25552;&#20379;&#32479;&#19968;&#20351;&#29992;&#30028;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Fundus&#65292;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#26032;&#38395;&#29228;&#34411;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#20165;&#20973;&#20960;&#34892;&#20195;&#30721;&#33719;&#24471;&#25968;&#30334;&#19975;&#39640;&#36136;&#37327;&#30340;&#26032;&#38395;&#25991;&#31456;&#12290;&#19982;&#29616;&#26377;&#30340;&#26032;&#38395;&#29228;&#34411;&#19981;&#21516;&#65292;&#25105;&#20204;&#20351;&#29992;&#25163;&#24037;&#23450;&#21046;&#30340;&#12289;&#19987;&#38376;&#38024;&#23545;&#27599;&#20010;&#25903;&#25345;&#30340;&#22312;&#32447;&#25253;&#32440;&#30340;&#26684;&#24335;&#25351;&#21335;&#30340;&#20869;&#23481;&#25552;&#21462;&#22120;&#12290;&#36825;&#26679;&#25105;&#20204;&#21487;&#20197;&#20248;&#21270;&#25105;&#20204;&#30340;&#29228;&#21462;&#36136;&#37327;&#65292;&#20197;&#30830;&#20445;&#26816;&#32034;&#21040;&#30340;&#26032;&#38395;&#25991;&#31456;&#23436;&#25972;&#19988;&#27809;&#26377;HTML&#30165;&#36857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#29228;&#21462;&#65288;&#20174;&#32593;&#32476;&#25110;&#22823;&#22411;&#32593;&#32476;&#24402;&#26723;&#20013;&#26816;&#32034;HTML&#65289;&#21644;&#20869;&#23481;&#25552;&#21462;&#32467;&#21512;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#27969;&#27700;&#32447;&#20013;&#12290;&#36890;&#36807;&#20026;&#39044;&#23450;&#20041;&#30340;&#19968;&#32452;&#25253;&#32440;&#25552;&#20379;&#32479;&#19968;&#30340;&#30028;&#38754;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20351;Fundus&#21363;&#20351;&#23545;&#38750;&#25216;&#26415;&#29992;&#25143;&#20063;&#26131;&#20110;&#20351;&#29992;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#26694;&#26550;&#65292;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#35774;&#35745;&#36873;&#25321;&#65292;&#24182;&#38024;&#23545;&#20854;&#20182;&#27969;&#34892;&#30340;&#26032;&#38395;&#29228;&#34411;&#36827;&#34892;&#20102;&#27604;&#36739;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;Fundus&#21462;&#24471;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15279v1 Announce Type: new  Abstract: This paper introduces Fundus, a user-friendly news scraper that enables users to obtain millions of high-quality news articles with just a few lines of code. Unlike existing news scrapers, we use manually crafted, bespoke content extractors that are specifically tailored to the formatting guidelines of each supported online newspaper. This allows us to optimize our scraping for quality such that retrieved news articles are textually complete and without HTML artifacts. Further, our framework combines both crawling (retrieving HTML from the web or large web archives) and content extraction into a single pipeline. By providing a unified interface for a predefined collection of newspapers, we aim to make Fundus broadly usable even for non-technical users. This paper gives an overview of the framework, discusses our design choices, and presents a comparative evaluation against other popular news scrapers. Our evaluation shows that Fundus yie
&lt;/p&gt;</description></item><item><title>&#35780;&#20272;&#22823;&#35268;&#27169;LLM&#20013;&#22240;&#32032;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36890;&#36807;&#20840;&#38754;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25512;&#21160;&#36825;&#20123;&#27169;&#22411;&#30340;&#21457;&#23637;</title><link>https://arxiv.org/abs/2403.15250</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#35780;&#20272;&#32467;&#26524;&#22312;LLM&#20013;&#30340;&#20840;&#38754;&#37325;&#26032;&#35780;&#20272;&#65306;&#19968;&#31181;&#22810;&#26041;&#20301;&#32479;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15250
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#35268;&#27169;LLM&#20013;&#22240;&#32032;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36890;&#36807;&#20840;&#38754;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25512;&#21160;&#36825;&#20123;&#27169;&#22411;&#30340;&#21457;&#23637;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;LLM&#24555;&#36895;&#21457;&#23637;&#30340;&#32972;&#26223;&#19979;&#65292;&#35780;&#20272;&#22312;&#29702;&#35299;&#21644;&#25512;&#21160;&#36825;&#20123;&#27169;&#22411;&#21069;&#36827;&#20013;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#20984;&#26174;&#12290;&#35780;&#20272;&#25581;&#31034;&#20102;&#32553;&#25918;&#12289;&#35757;&#32451;&#31867;&#22411;&#12289;&#26550;&#26500;&#31561;&#22240;&#32032;&#28145;&#21051;&#24433;&#21709;LLM&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22240;&#32032;&#23545;&#24615;&#33021;&#35780;&#20998;&#30340;&#24433;&#21709;&#31243;&#24230;&#21644;&#24615;&#36136;&#20173;&#28982;&#23384;&#22312;&#20105;&#35758;&#65292;&#22240;&#20026;&#22823;&#22810;&#25968;&#35780;&#20272;&#23616;&#38480;&#20110;&#26377;&#38480;&#25968;&#37327;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#28857;&#12290;&#36890;&#36807;&#32479;&#35745;&#35270;&#35282;&#26356;&#26377;&#25928;&#22320;&#28548;&#28165;&#36825;&#20123;&#22240;&#32032;&#23545;&#24615;&#33021;&#24471;&#20998;&#30340;&#24433;&#21709;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#36825;&#20123;LLM&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#37325;&#26032;&#26816;&#26597;&#65292;&#38024;&#23545;&#24403;&#21069;&#35780;&#20272;&#26041;&#27861;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;&#38543;&#30528;&#19968;&#20010;&#32479;&#19968;&#30340;&#35780;&#20272;&#26694;&#26550;&#30340;&#20986;&#29616;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#20102;&#24191;&#27867;&#30340;&#35780;&#20272;&#32467;&#26524;&#25968;&#25454;&#38598;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#32479;&#35745;&#26041;&#27861;&#35770;&#12290;&#20854;&#20013;&#21253;&#25324;ANOVA&#12289;Tukey HSD&#26816;&#39564;&#12289;GAMM&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15250v1 Announce Type: cross  Abstract: Amidst the rapid evolution of LLMs, the significance of evaluation in comprehending and propelling these models forward is increasingly paramount. Evaluations have revealed that factors such as scaling, training types, architectures and other factors profoundly impact the performance of LLMs. However, the extent and nature of these impacts continue to be subjects of debate because most assessments have been restricted to a limited number of models and data points. Clarifying the effects of these factors on performance scores can be more effectively achieved through a statistical lens. Our study embarks on a thorough re-examination of these LLMs, targeting the inadequacies in current evaluation methods. With the advent of a uniform evaluation framework, our research leverages an expansive dataset of evaluation results, introducing a comprehensive statistical methodology. This includes the application of ANOVA, Tukey HSD tests, GAMM, and
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#22823;&#21270;&#20934;&#21017;&#65292;&#29992;&#20110;&#25551;&#36848;&#26377;&#25928;&#30340;&#20154;&#26426;&#23545;&#35805;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340; Grice &#22235;&#20010;&#26368;&#22823;&#21270;&#20934;&#21017;&#20197;&#21450;&#20004;&#20010;&#26032;&#20934;&#21017;&#65292;&#23545;&#20110;&#35299;&#20915;&#29616;&#20195;&#20154;&#26426;&#20114;&#21160;&#20013;&#30340;&#29305;&#27530;&#34892;&#20026;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.15115</link><description>&lt;p&gt;
&#23545;&#35805;&#20013;&#30340;&#35821;&#35328;&#27169;&#22411;&#65306;&#20154;&#26426;&#20132;&#20114;&#30340;&#20250;&#35805;&#26368;&#22823;&#21270;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Language Models in Dialogue: Conversational Maxims for Human-AI Interactions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15115
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#22823;&#21270;&#20934;&#21017;&#65292;&#29992;&#20110;&#25551;&#36848;&#26377;&#25928;&#30340;&#20154;&#26426;&#23545;&#35805;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340; Grice &#22235;&#20010;&#26368;&#22823;&#21270;&#20934;&#21017;&#20197;&#21450;&#20004;&#20010;&#26032;&#20934;&#21017;&#65292;&#23545;&#20110;&#35299;&#20915;&#29616;&#20195;&#20154;&#26426;&#20114;&#21160;&#20013;&#30340;&#29305;&#27530;&#34892;&#20026;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#34429;&#28982;&#22797;&#26434;&#65292;&#20294;&#22312;&#23545;&#35805;&#29615;&#22659;&#20013;&#23384;&#22312;&#19968;&#20123;&#22266;&#26377;&#32570;&#38519;&#12290;&#25105;&#20204;&#35748;&#20026;&#35266;&#23519;&#21040;&#30340;&#35768;&#22810;&#32570;&#38519;&#21487;&#20197;&#24402;&#22240;&#20110;&#36829;&#21453;&#19968;&#20010;&#25110;&#22810;&#20010;&#23545;&#35805;&#21407;&#21017;&#12290;&#36890;&#36807;&#20511;&#37492;&#31038;&#20250;&#31185;&#23398;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24191;&#27867;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#22823;&#21270;&#20934;&#21017; - &#21253;&#25324;&#25968;&#37327;&#12289;&#36136;&#37327;&#12289;&#30456;&#20851;&#24615;&#12289;&#26041;&#24335;&#12289;&#20161;&#24904;&#20197;&#21450;&#36879;&#26126;&#24230; - &#26469;&#25551;&#36848;&#26377;&#25928;&#30340;&#20154;&#26426;&#23545;&#35805;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#20154;&#26426;&#20114;&#21160;&#32972;&#26223;&#19979; Grice &#30340;&#21069;&#22235;&#20010;&#26368;&#22823;&#21270;&#20934;&#21017;&#30340;&#36866;&#29992;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#20004;&#20010;&#26032;&#30340;&#20934;&#21017;&#65292;&#20161;&#24904;&#65288;&#28041;&#21450;&#29983;&#25104;&#21644;&#21442;&#19982;&#26377;&#23475;&#20869;&#23481;&#65289;&#21644;&#36879;&#26126;&#24230;&#65288;&#28041;&#21450;&#35782;&#21035;&#33258;&#24049;&#30340;&#30693;&#35782;&#36793;&#30028;&#12289;&#25805;&#20316;&#32422;&#26463;&#21644;&#24847;&#22270;&#65289;&#65292;&#23545;&#20110;&#35299;&#20915;&#29616;&#20195;&#20154;&#26426;&#20114;&#21160;&#20013;&#29420;&#29305;&#34892;&#20026;&#26159;&#24517;&#35201;&#30340;&#12290;&#25552;&#20986;&#30340;&#20934;&#21017;&#20026;&#22914;&#20309;&#25552;&#20379;&#20855;&#20307;&#25351;&#23548;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15115v1 Announce Type: cross  Abstract: Modern language models, while sophisticated, exhibit some inherent shortcomings, particularly in conversational settings. We claim that many of the observed shortcomings can be attributed to violation of one or more conversational principles. By drawing upon extensive research from both the social science and AI communities, we propose a set of maxims -- quantity, quality, relevance, manner, benevolence, and transparency -- for describing effective human-AI conversation. We first justify the applicability of the first four maxims (from Grice) in the context of human-AI interactions. We then argue that two new maxims, benevolence (concerning the generation of, and engagement with, harmful content) and transparency (concerning recognition of one's knowledge boundaries, operational constraints, and intents), are necessary for addressing behavior unique to modern human-AI interactions. The proposed maxims offer prescriptive guidance on how
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27880;&#24847;&#21147;&#26426;&#21046;&#20248;&#21270;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#23588;&#20854;&#23545;&#20110;&#38750;STEM&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.14932</link><description>&lt;p&gt;
&#19987;&#27880;&#39537;&#21160;&#30340;&#25512;&#29702;:&#37322;&#25918;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Attention-Driven Reasoning: Unlocking the Potential of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14932
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27880;&#24847;&#21147;&#26426;&#21046;&#20248;&#21270;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#23588;&#20854;&#23545;&#20110;&#38750;STEM&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#30340;&#25512;&#29702;&#33021;&#21147;&#21644;&#22522;&#30784;&#26426;&#21046;&#20173;&#19981;&#20026;&#20154;&#25152;&#20102;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27880;&#24847;&#21147;&#26426;&#21046;&#20248;&#21270;&#26469;&#22686;&#24378;LLMs&#25512;&#29702;&#33021;&#21147;&#30340;&#26032;&#26041;&#27861;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#30001;&#38750;&#35821;&#20041;&#26631;&#35760;&#23548;&#33268;&#30340;&#27880;&#24847;&#21147;&#20998;&#24067;&#30340;&#20302;&#25928;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#26469;&#37325;&#26032;&#24179;&#34913;&#20559;&#26012;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#25277;&#35937;&#26356;&#21152;&#24494;&#22937;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25512;&#29702;&#33021;&#21147;&#24471;&#21040;&#20102;&#26174;&#30528;&#25913;&#36827;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#38750;STEM&#38382;&#39064;&#12290;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#27880;&#24847;&#21147;&#27169;&#24335;&#22312;LLMs&#25512;&#29702;&#20013;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#36825;&#20123;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#20026;&#26356;&#24378;&#22823;&#21644;&#22810;&#21151;&#33021;&#30340;&#35821;&#35328;&#27169;&#22411;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14932v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown remarkable capabilities, but their reasoning abilities and underlying mechanisms remain poorly understood. We present a novel approach to enhance LLMs' reasoning through attention mechanism optimization, without additional training data. We identify inefficiencies in the attention distribution caused by non-semantic tokens and propose an algorithm to re-balance the skewed distribution, enabling the model to abstract more nuanced knowledge. Our experiments demonstrate significantly improved reasoning capabilities, particularly for non-STEM questions. We provide insights into the role of attention patterns in LLMs' reasoning and propose a method to enhance these abilities, paving the way for more powerful and versatile language models.
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2403.14734</link><description>&lt;p&gt;
&#19968;&#39033;&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#30340;&#35843;&#26597;&#65306;&#33539;&#24335;&#12289;&#36827;&#23637;&#19982;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14734
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#31070;&#32463;&#20195;&#30721;&#26234;&#33021;--&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#20248;&#21270;&#20195;&#30721;--&#22312;&#25972;&#20010;&#31038;&#20250;&#19978;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21644;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#36825;&#19968;&#39046;&#22495;&#22312;&#36807;&#21435;&#20960;&#24180;&#24341;&#36215;&#20102;&#20004;&#20010;&#30740;&#31350;&#31038;&#21306;&#30740;&#31350;&#20154;&#21592;&#30340;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#35843;&#26597;&#31995;&#32479;&#22320;&#21644;&#25353;&#26102;&#38388;&#39034;&#24207;&#22238;&#39038;&#20102;&#20195;&#30721;&#26234;&#33021;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21450;&#20854;&#21464;&#20307;&#12289;20&#22810;&#31181;&#20219;&#21153;&#31867;&#21035;&#20197;&#21450;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#12290;&#25105;&#20204;&#36981;&#24490;&#21382;&#21490;&#36827;&#23637;&#65292;&#36319;&#36394;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#36716;&#21464;&#65288;&#20363;&#22914;&#65292;&#20174;&#20351;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#20195;&#30721;&#24314;&#27169;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65289;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#19981;&#21516;&#38454;&#27573;&#28085;&#30422;&#30340;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35780;&#20272;&#30340;&#20027;&#35201;&#25216;&#26415;&#36716;&#21464;&#12290;&#23545;&#20110;&#24212;&#29992;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
&lt;/p&gt;</description></item><item><title>&#35821;&#35328;&#27169;&#22411;&#20013;"&#36234;&#29425;"&#25915;&#20987;&#30340;&#20851;&#38190;&#26159;&#36890;&#36807;&#23450;&#20041;&#22909;&#30340;&#19981;&#23433;&#20840;&#21709;&#24212;&#26469;&#36827;&#34892;&#38450;&#24481;&#65292;&#32780;&#19981;&#26159;&#20381;&#36182;&#20110;&#25191;&#34892;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.14725</link><description>&lt;p&gt;
Jailbreaking&#30340;&#26368;&#20339;&#35299;&#20915;&#26041;&#26696;&#26159;&#36890;&#36807;&#23450;&#20041;
&lt;/p&gt;
&lt;p&gt;
Jailbreaking is Best Solved by Definition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14725
&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20013;"&#36234;&#29425;"&#25915;&#20987;&#30340;&#20851;&#38190;&#26159;&#36890;&#36807;&#23450;&#20041;&#22909;&#30340;&#19981;&#23433;&#20840;&#21709;&#24212;&#26469;&#36827;&#34892;&#38450;&#24481;&#65292;&#32780;&#19981;&#26159;&#20381;&#36182;&#20110;&#25191;&#34892;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#19978;"&#36234;&#29425;"&#25915;&#20987;&#30340;&#22686;&#22810;&#24341;&#21457;&#20102;&#22823;&#37327;&#38450;&#24481;&#24037;&#20316;&#65292;&#26088;&#22312;&#38450;&#27490;&#20135;&#29983;&#19981;&#33391;&#22238;&#24212;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25209;&#21028;&#24615;&#22320;&#23457;&#35270;&#20102;&#38450;&#24481;&#31649;&#36947;&#30340;&#20004;&#20010;&#38454;&#27573;&#65306;&#65288;i&#65289;&#23450;&#20041;&#20309;&#20026;&#19981;&#23433;&#20840;&#36755;&#20986;&#65292;&#21644;&#65288;ii&#65289;&#36890;&#36807;&#36755;&#20837;&#22788;&#29702;&#25110;&#24494;&#35843;&#31561;&#26041;&#27861;&#26469;&#25191;&#34892;&#35813;&#23450;&#20041;&#12290;&#25105;&#20204;&#20005;&#37325;&#24576;&#30097;&#29616;&#26377;&#30340;&#25191;&#34892;&#26426;&#21046;&#30340;&#26377;&#25928;&#24615;&#65292;&#36890;&#36807;&#23637;&#31034;&#23427;&#20204;&#21363;&#20351;&#23545;&#20110;&#31616;&#21333;&#30340;&#19981;&#23433;&#20840;&#36755;&#20986;&#23450;&#20041;--&#21253;&#21547;&#21333;&#35789;"purple"&#30340;&#36755;&#20986;&#20063;&#26080;&#27861;&#38450;&#24481;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#23545;&#36755;&#20986;&#36827;&#34892;&#21518;&#22788;&#29702;&#23545;&#20110;&#36825;&#26679;&#30340;&#23450;&#20041;&#26159;&#23436;&#20840;&#20581;&#22766;&#30340;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#25105;&#20204;&#30340;&#35266;&#28857;&#65292;&#21363;&#22312;&#38450;&#24481;&#36234;&#29425;&#25915;&#20987;&#20013;&#30495;&#27491;&#30340;&#25361;&#25112;&#22312;&#20110;&#24471;&#21040;&#19968;&#20010;&#33391;&#22909;&#30340;&#19981;&#23433;&#20840;&#21709;&#24212;&#23450;&#20041;&#65306;&#27809;&#26377;&#33391;&#22909;&#30340;&#23450;&#20041;&#65292;&#20219;&#20309;&#25191;&#34892;&#31574;&#30053;&#37117;&#26080;&#27861;&#25104;&#21151;&#65292;&#20294;&#26377;&#20102;&#33391;&#22909;&#30340;&#23450;&#20041;&#65292;&#36755;&#20986;&#22788;&#29702;&#24050;&#32463;&#20316;&#20026;&#19968;&#20010;&#24378;&#22823;&#30340;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14725v1 Announce Type: cross  Abstract: The rise of "jailbreak" attacks on language models has led to a flurry of defenses aimed at preventing the output of undesirable responses. In this work, we critically examine the two stages of the defense pipeline: (i) the definition of what constitutes unsafe outputs, and (ii) the enforcement of the definition via methods such as input processing or fine-tuning. We cast severe doubt on the efficacy of existing enforcement mechanisms by showing that they fail to defend even for a simple definition of unsafe outputs--outputs that contain the word "purple". In contrast, post-processing outputs is perfectly robust for such a definition. Drawing on our results, we present our position that the real challenge in defending jailbreaks lies in obtaining a good definition of unsafe responses: without a good definition, no enforcement strategy can succeed, but with a good definition, output processing already serves as a robust baseline albeit 
&lt;/p&gt;</description></item><item><title>EthioLLM&#20026;&#22467;&#22622;&#20420;&#27604;&#20122;&#20116;&#31181;&#35821;&#35328;&#65288;&#38463;&#22982;&#21704;&#25289;&#35821;&#12289;&#30422;&#20234;&#20857;&#35821;&#12289;&#38463;&#26041;&#22885;&#32599;&#33707;&#35821;&#12289;&#32034;&#39532;&#37324;&#35821;&#21644;&#25552;&#26684;&#37324;&#23612;&#20122;&#35821;&#65289;&#20197;&#21450;&#33521;&#35821;&#24341;&#20837;&#20102;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;Ethiobenchmark&#65292;&#20026;&#21508;&#31181;&#19979;&#28216;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#35780;&#20272;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13737</link><description>&lt;p&gt;
EthioLLM&#65306;&#29992;&#20110;&#22467;&#22622;&#20420;&#27604;&#20122;&#35821;&#35328;&#30340;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21450;&#20219;&#21153;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13737
&lt;/p&gt;
&lt;p&gt;
EthioLLM&#20026;&#22467;&#22622;&#20420;&#27604;&#20122;&#20116;&#31181;&#35821;&#35328;&#65288;&#38463;&#22982;&#21704;&#25289;&#35821;&#12289;&#30422;&#20234;&#20857;&#35821;&#12289;&#38463;&#26041;&#22885;&#32599;&#33707;&#35821;&#12289;&#32034;&#39532;&#37324;&#35821;&#21644;&#25552;&#26684;&#37324;&#23612;&#20122;&#35821;&#65289;&#20197;&#21450;&#33521;&#35821;&#24341;&#20837;&#20102;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;Ethiobenchmark&#65292;&#20026;&#21508;&#31181;&#19979;&#28216;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#35780;&#20272;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36817;&#26469;&#22240;&#20854;&#22312;&#21508;&#31181;&#19979;&#28216;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#30340;&#20986;&#33394;&#34920;&#29616;&#32780;&#22791;&#21463;&#38738;&#30544;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35757;&#32451;LLMs&#30340;&#36164;&#28304;&#19981;&#36275;&#65292;&#20302;&#36164;&#28304;&#35821;&#35328;&#20173;&#33853;&#21518;&#20110;NLP&#39046;&#22495;&#30340;&#26368;&#26032;&#21457;&#23637;&#12290;&#22467;&#22622;&#20420;&#27604;&#20122;&#35821;&#35328;&#25317;&#26377;&#26174;&#33879;&#30340;&#35821;&#35328;&#22810;&#26679;&#24615;&#65292;&#21253;&#25324;&#24191;&#27867;&#30340;&#25991;&#23383;&#31995;&#32479;&#65292;&#24182;&#23500;&#26377;&#28145;&#36828;&#30340;&#23447;&#25945;&#21644;&#25991;&#21270;&#24847;&#20041;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;EthioLLM - &#20116;&#31181;&#22467;&#22622;&#20420;&#27604;&#20122;&#35821;&#35328;&#65288;&#38463;&#22982;&#21704;&#25289;&#35821;&#12289;&#30422;&#20234;&#20857;&#35821;&#12289;&#38463;&#26041;&#22885;&#32599;&#33707;&#35821;&#12289;&#32034;&#39532;&#37324;&#35821;&#21644;&#25552;&#26684;&#37324;&#23612;&#20122;&#35821;&#65289;&#21644;&#33521;&#35821;&#30340;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#21450;Ethiobenchmark - &#29992;&#20110;&#21508;&#31181;&#19979;&#28216;NLP&#20219;&#21153;&#30340;&#26032;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#36825;&#20123;&#27169;&#22411;&#22312;&#20116;&#20010;&#19979;&#28216;NLP&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#24320;&#28304;&#25105;&#20204;&#30340;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#12289;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#30340;&#26032;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#20219;&#21153;&#29305;&#23450;&#30340;&#31934;&#35843;&#35821;&#35328;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13737v1 Announce Type: new  Abstract: Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned languag
&lt;/p&gt;</description></item><item><title>LlamaFactory&#26159;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#25972;&#21512;&#20102;&#19968;&#31995;&#21015;&#21069;&#27839;&#30340;&#39640;&#25928;&#35757;&#32451;&#26041;&#27861;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#32534;&#30721;&#30340;&#24773;&#20917;&#19979;&#28789;&#27963;&#23450;&#21046;100&#22810;&#31181;LLMs&#30340;&#24494;&#35843;&#12290;</title><link>https://arxiv.org/abs/2403.13372</link><description>&lt;p&gt;
LlamaFactory&#65306;100&#22810;&#31181;&#35821;&#35328;&#27169;&#22411;&#30340;&#32479;&#19968;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13372
&lt;/p&gt;
&lt;p&gt;
LlamaFactory&#26159;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#25972;&#21512;&#20102;&#19968;&#31995;&#21015;&#21069;&#27839;&#30340;&#39640;&#25928;&#35757;&#32451;&#26041;&#27861;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#32534;&#30721;&#30340;&#24773;&#20917;&#19979;&#28789;&#27963;&#23450;&#21046;100&#22810;&#31181;LLMs&#30340;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#30340;&#24494;&#35843;&#23545;&#20110;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36866;&#24212;&#19979;&#28216;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#19981;&#21516;&#27169;&#22411;&#19978;&#23454;&#29616;&#36825;&#20123;&#26041;&#27861;&#38656;&#35201;&#38750;&#24179;&#20961;&#30340;&#21162;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;LlamaFactory&#65292;&#36825;&#26159;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#38598;&#25104;&#20102;&#19968;&#22871;&#21069;&#27839;&#30340;&#39640;&#25928;&#35757;&#32451;&#26041;&#27861;&#12290;&#23427;&#20801;&#35768;&#29992;&#25143;&#36890;&#36807;&#20869;&#32622;&#30340;Web UI LlamaBoard &#28789;&#27963;&#23450;&#21046;100&#22810;&#31181;LLMs&#30340;&#24494;&#35843;&#65292;&#26080;&#38656;&#32534;&#30721;&#12290;&#25105;&#20204;&#22312;&#35821;&#35328;&#24314;&#27169;&#21644;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#19978;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#25928;&#29575;&#21644;&#26377;&#25928;&#24615;&#12290;&#24050;&#21457;&#24067;&#22312; https://github.com/hiyouga/LLaMA-Factory&#65292;&#24182;&#24050;&#33719;&#24471;&#36229;&#36807;13,000&#39063;&#26143;&#21644;1,600&#20010;&#20998;&#25903;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13372v1 Announce Type: new  Abstract: Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It allows users to flexibly customize the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and already received over 13,000 stars and 1,600 forks.
&lt;/p&gt;</description></item><item><title>ClaimVer&#26159;&#19968;&#20010;&#20154;&#20026;&#20013;&#24515;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22768;&#26126;&#32423;&#39564;&#35777;&#21644;&#35777;&#25454;&#24402;&#22240;&#65292;&#33268;&#21147;&#20110;&#25552;&#39640;&#29992;&#25143;&#23545;&#25991;&#26412;&#39564;&#35777;&#26041;&#27861;&#30340;&#20449;&#20219;&#24182;&#24378;&#35843;&#32454;&#31890;&#24230;&#35777;&#25454;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09724</link><description>&lt;p&gt;
ClaimVer&#65306;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22768;&#26126;&#32423;&#39564;&#35777;&#21644;&#35777;&#25454;&#24402;&#22240;
&lt;/p&gt;
&lt;p&gt;
ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09724
&lt;/p&gt;
&lt;p&gt;
ClaimVer&#26159;&#19968;&#20010;&#20154;&#20026;&#20013;&#24515;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22768;&#26126;&#32423;&#39564;&#35777;&#21644;&#35777;&#25454;&#24402;&#22240;&#65292;&#33268;&#21147;&#20110;&#25552;&#39640;&#29992;&#25143;&#23545;&#25991;&#26412;&#39564;&#35777;&#26041;&#27861;&#30340;&#20449;&#20219;&#24182;&#24378;&#35843;&#32454;&#31890;&#24230;&#35777;&#25454;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#20256;&#25773;&#30340;&#20449;&#24687;&#35823;&#23548;&#21644;&#31038;&#20132;&#23186;&#20307;&#20197;&#21450;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#28608;&#22686;&#20013;&#65292;&#39564;&#35777;&#21644;&#20449;&#20219;&#25152;&#36935;&#21040;&#30340;&#20449;&#24687;&#21464;&#24471;&#26085;&#30410;&#22256;&#38590;&#12290;&#35768;&#22810;&#20107;&#23454;&#26680;&#26597;&#26041;&#27861;&#21644;&#24037;&#20855;&#24050;&#34987;&#24320;&#21457;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#32570;&#20047;&#36866;&#24403;&#30340;&#21487;&#35299;&#37322;&#24615;&#25110;&#32454;&#31890;&#24230;&#65292;&#26080;&#27861;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#21457;&#25381;&#20316;&#29992;&#12290;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#12289;&#21487;&#35775;&#38382;&#19988;&#33021;&#22815;&#25191;&#34892;&#32454;&#31890;&#24230;&#35777;&#25454;&#24402;&#22240;&#30340;&#25991;&#26412;&#39564;&#35777;&#26041;&#27861;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#24314;&#31435;&#29992;&#25143;&#23545;&#36825;&#31181;&#26041;&#27861;&#30340;&#20449;&#20219;&#38656;&#35201;&#21576;&#29616;&#27599;&#20010;&#39044;&#27979;&#32972;&#21518;&#30340;&#29702;&#30001;&#65292;&#22240;&#20026;&#30740;&#31350;&#34920;&#26126;&#36825;&#26174;&#33879;&#24433;&#21709;&#20154;&#20204;&#23545;&#33258;&#21160;&#21270;&#31995;&#32479;&#30340;&#20449;&#20219;&#12290;&#23558;&#29992;&#25143;&#20851;&#27880;&#37325;&#28857;&#25918;&#22312;&#20855;&#20307;&#30340;&#38382;&#39064;&#20869;&#23481;&#19978;&#65292;&#32780;&#19981;&#26159;&#25552;&#20379;&#31616;&#21333;&#30340;&#31548;&#32479;&#26631;&#31614;&#20063;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\textit{ClaimVer&#65292;&#19968;&#20010;&#20197;&#20154;&#20026;&#20013;&#24515;&#30340;&#26694;&#26550;}$&#65292;&#26088;&#22312;&#28385;&#36275;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09724v1 Announce Type: new  Abstract: In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people's belief in automated systems. It is also paramount to localize and bring users' attention to the specific problematic content, instead of providing simple blanket labels. In this paper, we present $\textit{ClaimVer, a human-centric framework}$ tailored to meet users' info
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35843;&#26597;&#28145;&#20837;&#20998;&#26512;&#20102;LLMs&#22312;&#34701;&#21512;&#19978;&#19979;&#25991;&#21644;&#21442;&#25968;&#21270;&#30693;&#35782;&#26102;&#25152;&#38754;&#20020;&#30340;&#30693;&#35782;&#20914;&#31361;&#65292;&#25506;&#35752;&#20102;&#19977;&#31867;&#30693;&#35782;&#20914;&#31361;&#23545;&#20854;&#21487;&#20449;&#24230;&#21644;&#24615;&#33021;&#30340;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#25913;&#36827;LLMs&#31283;&#20581;&#24615;&#31574;&#30053;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.08319</link><description>&lt;p&gt;
LLMs&#30340;&#30693;&#35782;&#20914;&#31361;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Knowledge Conflicts for LLMs: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08319
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#28145;&#20837;&#20998;&#26512;&#20102;LLMs&#22312;&#34701;&#21512;&#19978;&#19979;&#25991;&#21644;&#21442;&#25968;&#21270;&#30693;&#35782;&#26102;&#25152;&#38754;&#20020;&#30340;&#30693;&#35782;&#20914;&#31361;&#65292;&#25506;&#35752;&#20102;&#19977;&#31867;&#30693;&#35782;&#20914;&#31361;&#23545;&#20854;&#21487;&#20449;&#24230;&#21644;&#24615;&#33021;&#30340;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#25913;&#36827;LLMs&#31283;&#20581;&#24615;&#31574;&#30053;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#30693;&#35782;&#20914;&#31361;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;&#24403;&#23427;&#20204;&#34701;&#21512;&#19978;&#19979;&#25991;&#21644;&#21442;&#25968;&#21270;&#30693;&#35782;&#26102;&#25152;&#36935;&#21040;&#30340;&#22797;&#26434;&#25361;&#25112;&#12290;&#25105;&#20204;&#20851;&#27880;&#19977;&#31867;&#30693;&#35782;&#20914;&#31361;&#65306;&#19978;&#19979;&#25991;-&#35760;&#24518;&#20914;&#31361;&#12289;&#36328;&#19978;&#19979;&#25991;&#20914;&#31361;&#21644;&#20869;&#37096;&#35760;&#24518;&#20914;&#31361;&#12290;&#36825;&#20123;&#20914;&#31361;&#21487;&#33021;&#20250;&#26174;&#33879;&#24433;&#21709;LLMs&#30340;&#21487;&#20449;&#24230;&#21644;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#65292;&#22122;&#38899;&#21644;&#38169;&#35823;&#20449;&#24687;&#24456;&#24120;&#35265;&#12290;&#36890;&#36807;&#23545;&#36825;&#20123;&#20914;&#31361;&#36827;&#34892;&#20998;&#31867;&#65292;&#25506;&#35752;&#20854;&#21407;&#22240;&#65292;&#30740;&#31350;LLMs&#22312;&#36825;&#20123;&#20914;&#31361;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#22238;&#39038;&#21487;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26412;&#35843;&#26597;&#26088;&#22312;&#20026;&#25913;&#36827;LLMs&#30340;&#31283;&#20581;&#24615;&#31574;&#30053;&#25552;&#20379;&#21551;&#31034;&#65292;&#20174;&#32780;&#25104;&#20026;&#25512;&#21160;&#36825;&#19968;&#19981;&#26029;&#21457;&#23637;&#39046;&#22495;&#30740;&#31350;&#30340;&#23453;&#36149;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08319v1 Announce Type: cross  Abstract: This survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge. Our focus is on three categories of knowledge conflicts: context-memory, inter-context, and intra-memory conflict. These conflicts can significantly impact the trustworthiness and performance of LLMs, especially in real-world applications where noise and misinformation are common. By categorizing these conflicts, exploring the causes, examining the behaviors of LLMs under such conflicts, and reviewing available solutions, this survey aims to shed light on strategies for improving the robustness of LLMs, thereby serving as a valuable resource for advancing research in this evolving area.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;COM2&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#22312;&#24120;&#35782;&#30693;&#35782;&#22270;&#20013;&#25277;&#26679;&#22810;&#36339;&#36923;&#36753;&#26597;&#35810;&#24182;&#32467;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.07398</link><description>&lt;p&gt;
&#22312;&#24120;&#35782;&#30693;&#35782;&#22270;&#19978;&#36827;&#34892;&#36923;&#36753;&#26597;&#35810;&#30340;&#22797;&#26434;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07398
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;COM2&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#22312;&#24120;&#35782;&#30693;&#35782;&#22270;&#20013;&#25277;&#26679;&#22810;&#36339;&#36923;&#36753;&#26597;&#35810;&#24182;&#32467;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#20214;&#24120;&#35782;&#25512;&#29702;&#38656;&#35201;&#20855;&#26377;&#25512;&#29702;&#20107;&#20214;&#20043;&#38388;&#20851;&#31995;&#30340;&#33021;&#21147;&#65292;&#20197;&#21450;&#25512;&#26029;&#22312;&#36825;&#31181;&#20851;&#31995;&#20043;&#19979;&#30340;&#38544;&#21547;&#19978;&#19979;&#25991;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#31232;&#32570;&#20351;&#24471;&#35821;&#35328;&#27169;&#22411;&#38590;&#20197;&#23398;&#20250;&#20026;&#28041;&#21450;&#22797;&#26434;&#20107;&#20214;&#30456;&#20114;&#20316;&#29992;&#30340;&#32972;&#26223;&#21644;&#38382;&#39064;&#29983;&#25104;&#24120;&#35782;&#25512;&#26029;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#31181;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;COM2&#65288;COMplex COMmonsense&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#36807;&#20174;&#29616;&#26377;&#24120;&#35782;&#30693;&#35782;&#22270;&#65288;CSKG&#65289;&#20013;&#25277;&#26679;&#22810;&#36339;&#36923;&#36753;&#26597;&#35810;&#65288;&#20363;&#22914;&#65292;&#20107;&#20214;A&#21644;B&#30340;&#32852;&#21512;&#25928;&#26524;&#25110;&#22240;&#26524;&#20851;&#31995;&#65292;&#25110;&#20107;&#20214;C&#30340;&#25928;&#26524;&#30340;&#25928;&#26524;&#65289;&#65292;&#24182;&#21033;&#29992;&#25163;&#24037;&#21046;&#20316;&#30340;&#35268;&#21017;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#20854;&#29992;&#22810;&#36873;&#21644;&#25991;&#26412;&#29983;&#25104;&#38382;&#39064;&#30340;&#24418;&#24335;&#34920;&#36798;&#20986;&#26469;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;COM2&#19978;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#38646;-shot&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#22312;&#39046;&#22495;&#20869;&#36824;&#26159;&#39046;&#22495;&#22806;&#30340;&#20219;&#21153;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07398v1 Announce Type: cross  Abstract: Event commonsense reasoning requires the ability to reason about the relationship between events, as well as infer implicit context underlying that relationship. However, data scarcity makes it challenging for language models to learn to generate commonsense inferences for contexts and questions involving interactions between complex events. To address this demand, we present COM2 (COMplex COMmonsense), a new dataset created by sampling multi-hop logical queries (e.g., the joint effect or cause of both event A and B, or the effect of the effect of event C) from an existing commonsense knowledge graph (CSKG), and verbalizing them using handcrafted rules and large language models into multiple-choice and text generation questions. Our experiments show that language models trained on COM2 exhibit significant improvements in complex reasoning ability, resulting in enhanced zero-shot performance in both in-domain and out-of-domain tasks for
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#22797;&#26434;&#24615;&#65292;&#25581;&#31034;&#20102;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#21253;&#25324;&#26041;&#21521;&#25506;&#32034;&#21644;&#26041;&#21521;&#27491;&#21017;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.07379</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#29305;&#24449;&#65306;&#38271;&#24230;&#12289;&#25296;&#28857;&#21644;&#27515;&#32993;&#21516;
&lt;/p&gt;
&lt;p&gt;
Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07379
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#22797;&#26434;&#24615;&#65292;&#25581;&#31034;&#20102;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#21253;&#25324;&#26041;&#21521;&#25506;&#32034;&#21644;&#26041;&#21521;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#26032;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#26426;&#21046;&#65292;&#36890;&#36807;&#20998;&#26512;&#20854;&#20248;&#21270;&#36712;&#36857;&#20013;&#21253;&#21547;&#30340;&#20016;&#23500;&#21442;&#25968;&#32467;&#26500;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20123;&#20851;&#20110;&#20248;&#21270;&#36712;&#36857;&#22797;&#26434;&#24615;&#30340;&#33258;&#28982;&#27010;&#24565;&#65292;&#26082;&#23450;&#24615;&#21448;&#23450;&#37327;&#22320;&#25581;&#31034;&#20102;&#21508;&#31181;&#20248;&#21270;&#36873;&#25321;&#65288;&#22914;&#21160;&#37327;&#12289;&#26435;&#37325;&#34928;&#20943;&#21644;&#25209;&#22823;&#23567;&#65289;&#20043;&#38388;&#25152;&#28041;&#21450;&#30340;&#20869;&#22312;&#24494;&#22937;&#21644;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#27010;&#24565;&#26469;&#25552;&#20379;&#20851;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26412;&#36136;&#30340;&#20851;&#38190;&#29305;&#24449;&#65306;&#20309;&#26102;&#39034;&#21033;&#36827;&#34892;&#65292;&#20309;&#26102;&#38519;&#20837;&#27515;&#32993;&#21516;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#25105;&#20204;&#30340;&#36712;&#36857;&#35270;&#35282;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#21160;&#37327;&#21644;&#26435;&#37325;&#34928;&#20943;&#20043;&#38388;&#20419;&#36827;&#26041;&#21521;&#25506;&#32034;&#30340;&#20132;&#32455;&#34892;&#20026;&#65292;&#20197;&#21450;&#20854;&#20182;&#19968;&#20123;&#34892;&#20026;&#30340;&#26041;&#21521;&#27491;&#21017;&#21270;&#34892;&#20026;&#12290;&#25105;&#20204;&#22312;&#22823;&#35268;&#27169;&#35270;&#35273;&#21644;&#35821;&#35328;&#35774;&#32622;&#20013;&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;&#20855;&#26377;&#26368;&#22810;120&#20159;&#20010;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07379v1 Announce Type: cross  Abstract: We propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. Towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. We use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. Further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. We perform experiments over large-scale vision and language settings, including large language models (LLMs) with up to 12 billio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#21387;&#32553;&#22312;&#20998;&#35789;&#36807;&#31243;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#35777;&#26126;&#20102;&#21387;&#32553;&#19982;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21518;&#32493;&#25104;&#21151;&#20043;&#38388;&#30340;&#23454;&#35777;&#37325;&#35201;&#24615;&#65292;&#24182;&#34920;&#26126;&#20998;&#35789;&#22120;&#30340;&#21387;&#32553;&#19982;&#27169;&#22411;&#30340;&#24615;&#33021;&#23384;&#22312;&#30456;&#20851;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.06265</link><description>&lt;p&gt;
&#25286;&#35299;&#20998;&#35789;&#65306;&#35780;&#20272;&#25991;&#26412;&#21387;&#32553;&#21450;&#20854;&#19982;&#27169;&#22411;&#24615;&#33021;&#30340;&#30456;&#20851;&#24615;
&lt;/p&gt;
&lt;p&gt;
Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#21387;&#32553;&#22312;&#20998;&#35789;&#36807;&#31243;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#35777;&#26126;&#20102;&#21387;&#32553;&#19982;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21518;&#32493;&#25104;&#21151;&#20043;&#38388;&#30340;&#23454;&#35777;&#37325;&#35201;&#24615;&#65292;&#24182;&#34920;&#26126;&#20998;&#35789;&#22120;&#30340;&#21387;&#32553;&#19982;&#27169;&#22411;&#30340;&#24615;&#33021;&#23384;&#22312;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21387;&#32553;&#26159;BPE&#26368;&#24120;&#35265;&#30340;&#20998;&#35789;&#31639;&#27861;&#30340;&#37325;&#35201;&#22522;&#30784;&#65292;&#20294;&#20998;&#35789;&#36807;&#31243;&#20013;&#30340;&#21387;&#32553;&#37325;&#35201;&#24615;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#35770;&#36848;&#20102;&#21387;&#32553;&#30340;&#29702;&#35770;&#37325;&#35201;&#24615;&#65292;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;0-gram&#35821;&#35328;&#24314;&#27169;&#65292;&#21363;&#20026;&#25152;&#26377;&#26631;&#35760;&#20998;&#37197;&#30456;&#31561;&#30340;&#27010;&#29575;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21387;&#32553;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21518;&#32493;&#25104;&#21151;&#30340;&#23454;&#35777;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25913;&#21464;&#35757;&#32451;&#36807;&#31243;&#20013;&#21487;&#29992;&#25991;&#26723;&#30340;&#25968;&#37327;&#26469;&#25511;&#21046;&#22810;&#20010;BPE&#20998;&#35789;&#22120;&#30340;&#21387;&#32553;&#33021;&#21147;&#65306;&#20174;100&#19975;&#20010;&#25991;&#26723;&#21040;&#30456;&#24403;&#20110;&#27809;&#26377;&#35757;&#32451;&#25968;&#25454;&#30340;&#22522;&#20110;&#23383;&#31526;&#30340;&#20998;&#35789;&#22120;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#36825;&#20123;&#20998;&#35789;&#22120;&#39044;&#35757;&#32451;&#33521;&#35821;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20998;&#35789;&#22120;&#30340;&#21387;&#32553;&#19982;&#27169;&#22411;&#30340;&#21518;&#32493;&#24615;&#33021;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#34920;&#26126;&#21387;&#32553;&#26159;&#20998;&#35789;&#30340;&#21487;&#38752;&#20869;&#22312;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06265v1 Announce Type: cross  Abstract: Despite it being the cornerstone of BPE, the most common tokenization algorithm, the importance of compression in the tokenization process is still unclear. In this paper, we argue for the theoretical importance of compression, that can be viewed as 0-gram language modeling where equal probability is assigned to all tokens. We also demonstrate the empirical importance of compression for downstream success of pre-trained language models. We control the compression ability of several BPE tokenizers by varying the amount of documents available during their training: from 1 million documents to a character-based tokenizer equivalent to no training data at all. We then pre-train English language models based on those tokenizers and fine-tune them over several tasks. We show that there is a correlation between tokenizers' compression and models' downstream performance, suggesting that compression is a reliable intrinsic indicator of tokeniza
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Deep Prompt Multi-task Network (DPMN)&#29992;&#20110;&#28389;&#29992;&#35821;&#35328;&#26816;&#27979;&#65292;&#36890;&#36807;&#35774;&#35745;&#28145;&#24230;&#25552;&#31034;&#35843;&#25972;&#21644;&#36731;&#25552;&#31034;&#35843;&#25972;&#26469;&#28608;&#21457;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#19968;&#33324;&#30693;&#35782;&#65292;&#24182;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#25552;&#39640;&#26816;&#27979;&#24230;&#37327;&#26631;&#20934;</title><link>https://arxiv.org/abs/2403.05268</link><description>&lt;p&gt;
&#28145;&#24230;&#25552;&#31034;&#22810;&#20219;&#21153;&#32593;&#32476;&#29992;&#20110;&#36785;&#39554;&#35821;&#35328;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Deep Prompt Multi-task Network for Abuse Language Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05268
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Deep Prompt Multi-task Network (DPMN)&#29992;&#20110;&#28389;&#29992;&#35821;&#35328;&#26816;&#27979;&#65292;&#36890;&#36807;&#35774;&#35745;&#28145;&#24230;&#25552;&#31034;&#35843;&#25972;&#21644;&#36731;&#25552;&#31034;&#35843;&#25972;&#26469;&#28608;&#21457;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#19968;&#33324;&#30693;&#35782;&#65292;&#24182;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#25552;&#39640;&#26816;&#27979;&#24230;&#37327;&#26631;&#20934;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28389;&#29992;&#35821;&#35328;&#30340;&#26816;&#27979;&#20173;&#28982;&#26159;&#31038;&#20132;&#32593;&#32476;&#24191;&#27867;&#20351;&#29992;&#20013;&#23384;&#22312;&#30340;&#19968;&#39033;&#38271;&#26399;&#25361;&#25112;&#12290;&#28389;&#29992;&#35821;&#35328;&#26816;&#27979;&#20219;&#21153;&#23384;&#22312;&#30528;&#20934;&#30830;&#24615;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35748;&#20026;&#29616;&#26377;&#30340;&#26816;&#27979;&#26041;&#27861;&#21033;&#29992;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#30340;&#24494;&#35843;&#25216;&#26415;&#26469;&#22788;&#29702;&#19979;&#28216;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#26410;&#33021;&#28608;&#21457;PLMs&#30340;&#19968;&#33324;&#30693;&#35782;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#28389;&#29992;&#35821;&#35328;&#26816;&#27979;&#30340;&#28145;&#24230;&#25552;&#31034;&#22810;&#20219;&#21153;&#32593;&#32476;&#65288;DPMN&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;DPMN&#39318;&#20808;&#23581;&#35797;&#20026;PLMs&#35774;&#35745;&#20004;&#31181;&#24418;&#24335;&#30340;&#28145;&#24230;&#25552;&#31034;&#35843;&#25972;&#21644;&#36731;&#25552;&#31034;&#35843;&#25972;&#12290;&#30740;&#31350;&#20102;&#19981;&#21516;&#25552;&#31034;&#38271;&#24230;&#12289;&#35843;&#25972;&#31574;&#30053;&#21644;&#25552;&#31034;&#21021;&#22987;&#21270;&#26041;&#27861;&#23545;&#20110;&#26816;&#27979;&#28389;&#29992;&#35821;&#35328;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;Bi-LSTM&#21644;FFN&#30340;&#20219;&#21153;&#22836;&#65292;&#21487;&#29992;&#20316;&#30701;&#25991;&#26412;&#20998;&#31867;&#22120;&#12290;&#26368;&#32456;&#65292;DPMN&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#25552;&#39640;&#26816;&#27979;&#24230;&#37327;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05268v1 Announce Type: cross  Abstract: The detection of abusive language remains a long-standing challenge with the extensive use of social networks. The detection task of abusive language suffers from limited accuracy. We argue that the existing detection methods utilize the fine-tuning technique of the pre-trained language models (PLMs) to handle downstream tasks. Hence, these methods fail to stimulate the general knowledge of the PLMs. To address the problem, we propose a novel Deep Prompt Multi-task Network (DPMN) for abuse language detection. Specifically, DPMN first attempts to design two forms of deep prompt tuning and light prompt tuning for the PLMs. The effects of different prompt lengths, tuning strategies, and prompt initialization methods on detecting abusive language are studied. In addition, we propose a Task Head based on Bi-LSTM and FFN, which can be used as a short text classifier. Eventually, DPMN utilizes multi-task learning to improve detection metrics 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;SAFIM&#29992;&#20110;&#35780;&#20272;LLMs&#22312;&#20195;&#30721;&#22635;&#31354;&#20219;&#21153;&#19978;&#30340;&#21477;&#27861;&#24863;&#30693;&#23436;&#25104;&#34920;&#29616;&#65292;&#21457;&#29616;FIM&#39044;&#35757;&#32451;&#19981;&#20165;&#25552;&#39640;&#20102;FIM&#30340;&#29087;&#32451;&#24230;&#65292;&#36824;&#25913;&#21892;&#20102;LLMs&#30340;&#24038;&#21040;&#21491;&#25512;&#29702;&#65292;&#25361;&#25112;&#20102;&#20256;&#32479;&#35266;&#24565;&#24182;&#34920;&#26126;&#39044;&#35757;&#32451;&#26041;&#27861;&#21644;&#25968;&#25454;&#21697;&#36136;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#26356;&#29978;&#20110;&#27169;&#22411;&#22823;&#23567;&#12290;</title><link>https://arxiv.org/abs/2403.04814</link><description>&lt;p&gt;
&#22312;&#21477;&#27861;&#24863;&#30693;&#20195;&#30721;&#22635;&#31354;&#20219;&#21153;&#19978;&#35780;&#20272;LLMs
&lt;/p&gt;
&lt;p&gt;
Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04814
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;SAFIM&#29992;&#20110;&#35780;&#20272;LLMs&#22312;&#20195;&#30721;&#22635;&#31354;&#20219;&#21153;&#19978;&#30340;&#21477;&#27861;&#24863;&#30693;&#23436;&#25104;&#34920;&#29616;&#65292;&#21457;&#29616;FIM&#39044;&#35757;&#32451;&#19981;&#20165;&#25552;&#39640;&#20102;FIM&#30340;&#29087;&#32451;&#24230;&#65292;&#36824;&#25913;&#21892;&#20102;LLMs&#30340;&#24038;&#21040;&#21491;&#25512;&#29702;&#65292;&#25361;&#25112;&#20102;&#20256;&#32479;&#35266;&#24565;&#24182;&#34920;&#26126;&#39044;&#35757;&#32451;&#26041;&#27861;&#21644;&#25968;&#25454;&#21697;&#36136;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#26356;&#29978;&#20110;&#27169;&#22411;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Syntax-Aware Fill-In-the-Middle&#65288;SAFIM&#65289;&#30340;&#26032;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20195;&#30721;&#22635;&#31354;&#65288;FIM&#65289;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;&#35813;&#22522;&#20934;&#20391;&#37325;&#20110;&#31243;&#24207;&#32467;&#26500;&#30340;&#21477;&#27861;&#24863;&#30693;&#23436;&#25104;&#65292;&#22914;&#20195;&#30721;&#22359;&#21644;&#26465;&#20214;&#34920;&#36798;&#24335;&#65292;&#24182;&#21253;&#25324;&#26469;&#33258;&#22810;&#31181;&#32534;&#31243;&#35821;&#35328;&#30340;17,720&#20010;&#31034;&#20363;&#65292;&#26469;&#28304;&#20110;2022&#24180;4&#26376;&#20043;&#21518;&#30340;&#26368;&#26032;&#20195;&#30721;&#25552;&#20132;&#65292;&#20197;&#26368;&#23567;&#21270;&#25968;&#25454;&#27745;&#26579;&#12290; SAFIM&#25552;&#20379;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#20855;&#26377;&#21508;&#31181;&#25552;&#31034;&#35774;&#35745;&#21644;&#26032;&#39062;&#30340;&#21477;&#27861;&#24863;&#30693;&#21518;&#22788;&#29702;&#25216;&#26415;&#65292;&#26377;&#21161;&#20110;&#22312;LLMs&#20043;&#38388;&#36827;&#34892;&#20934;&#30830;&#21644;&#20844;&#24179;&#30340;&#27604;&#36739;&#12290;&#25105;&#20204;&#23545;15&#20010;LLMs&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;FIM&#39044;&#35757;&#32451;&#19981;&#20165;&#25552;&#21319;&#20102;FIM&#30340;&#29087;&#32451;&#31243;&#24230;&#65292;&#36824;&#25913;&#36827;&#20102;LLMs&#30340;&#24038;&#21040;&#21491;&#65288;L2R&#65289;&#25512;&#29702;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25361;&#25112;&#20102;&#20256;&#32479;&#35266;&#24565;&#65292;&#24182;&#34920;&#26126;&#39044;&#35757;&#32451;&#26041;&#27861;&#21644;&#25968;&#25454;&#36136;&#37327;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#22823;&#20110;&#27169;&#22411;&#22823;&#23567;&#12290;&#22240;&#27492;&#65292;SAFIM&#20026;&#26410;&#26469;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04814v1 Announce Type: cross  Abstract: We introduce Syntax-Aware Fill-In-the-Middle (SAFIM), a new benchmark for evaluating Large Language Models (LLMs) on the code Fill-in-the-Middle (FIM) task. This benchmark focuses on syntax-aware completions of program structures such as code blocks and conditional expressions, and includes 17,720 examples from multiple programming languages, sourced from recent code submissions after April 2022 to minimize data contamination. SAFIM provides a robust framework with various prompt designs and novel syntax-aware post-processing techniques, facilitating accurate and fair comparisons across LLMs. Our comprehensive evaluation of 15 LLMs shows that FIM pretraining not only enhances FIM proficiency but also improves Left-to-Right (L2R) inference using LLMs. Our findings challenge conventional beliefs and suggest that pretraining methods and data quality have more impact than model size. SAFIM thus serves as a foundational platform for future 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;GPTopic&#65292;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21019;&#24314;&#21160;&#24577;&#12289;&#20132;&#20114;&#24335;&#20027;&#39064;&#34920;&#31034;&#30340;&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#30452;&#35266;&#30340;&#32842;&#22825;&#30028;&#38754;&#20351;&#20027;&#39064;&#24314;&#27169;&#26356;&#26131;&#29992;&#21644;&#20840;&#38754;&#12290;</title><link>https://arxiv.org/abs/2403.03628</link><description>&lt;p&gt;
&#21160;&#24577;&#20132;&#20114;&#24335;&#20027;&#39064;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
GPTopic: Dynamic and Interactive Topic Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03628
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;GPTopic&#65292;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21019;&#24314;&#21160;&#24577;&#12289;&#20132;&#20114;&#24335;&#20027;&#39064;&#34920;&#31034;&#30340;&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#30452;&#35266;&#30340;&#32842;&#22825;&#30028;&#38754;&#20351;&#20027;&#39064;&#24314;&#27169;&#26356;&#26131;&#29992;&#21644;&#20840;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#39064;&#24314;&#27169;&#20284;&#20046;&#20960;&#20046;&#31561;&#21516;&#20110;&#29983;&#25104;&#21015;&#20986;&#39030;&#37096;&#21333;&#35789;&#20197;&#34920;&#31034;&#22823;&#22411;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#30340;&#20027;&#39064;&#12290;&#28982;&#32780;&#65292;&#20174;&#36825;&#26679;&#19968;&#21015;&#20010;&#21035;&#26415;&#35821;&#20013;&#25512;&#26029;&#20027;&#39064;&#21487;&#33021;&#38656;&#35201;&#22823;&#37327;&#30340;&#19987;&#19994;&#30693;&#35782;&#21644;&#32463;&#39564;&#65292;&#20351;&#24471;&#20027;&#39064;&#24314;&#27169;&#23545;&#20110;&#23545;&#29305;&#23450;&#39030;&#35789;&#35299;&#37322;&#30340;&#32454;&#24494;&#24046;&#21035;&#21644;&#32570;&#38519;&#19981;&#29087;&#24713;&#30340;&#20154;&#32676;&#19981;&#22815;&#26131;&#29992;&#12290;&#20165;&#38480;&#20110;&#39030;&#35789;&#30340;&#20027;&#39064;&#34920;&#31034;&#21487;&#33021;&#36827;&#19968;&#27493;&#26080;&#27861;&#25552;&#20379;&#20027;&#39064;&#21487;&#33021;&#20855;&#26377;&#30340;&#21508;&#20010;&#26041;&#38754;&#12289;&#26041;&#38754;&#21644;&#32454;&#24494;&#24046;&#21035;&#30340;&#20840;&#38754;&#19988;&#26131;&#20110;&#35775;&#38382;&#30340;&#34920;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;GPTopic&#65292;&#19968;&#20010;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21019;&#24314;&#21160;&#24577;&#65292;&#20132;&#20114;&#24335;&#20027;&#39064;&#34920;&#31034;&#30340;&#36719;&#20214;&#21253;&#12290;GPTopic&#25552;&#20379;&#30452;&#35266;&#30340;&#32842;&#22825;&#30028;&#38754;&#65292;&#20379;&#29992;&#25143;&#20132;&#20114;&#22320;&#25506;&#32034;&#12289;&#20998;&#26512;&#21644;&#23436;&#21892;&#20027;&#39064;&#65292;&#20351;&#20027;&#39064;&#24314;&#27169;&#26356;&#26131;&#20351;&#29992;&#21644;&#20840;&#38754;&#12290;&#30456;&#24212;&#30340;&#20195;&#30721;&#21487;&#22312;&#27492;&#22788;&#25214;&#21040;&#65306;https://gith
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03628v1 Announce Type: new  Abstract: Topic modeling seems to be almost synonymous with generating lists of top words to represent topics within large text corpora. However, deducing a topic from such list of individual terms can require substantial expertise and experience, making topic modelling less accessible to people unfamiliar with the particularities and pitfalls of top-word interpretation. A topic representation limited to top-words might further fall short of offering a comprehensive and easily accessible characterization of the various aspects, facets and nuances a topic might have. To address these challenges, we introduce GPTopic, a software package that leverages Large Language Models (LLMs) to create dynamic, interactive topic representations. GPTopic provides an intuitive chat interface for users to explore, analyze, and refine topics interactively, making topic modeling more accessible and comprehensive. The corresponding code is available here: https://gith
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;ConAgents&#26694;&#26550;&#65292;&#36890;&#36807;&#21512;&#20316;&#21644;&#20114;&#21160;&#20195;&#29702;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#20351;&#29992;&#24037;&#20855;&#65292;&#24182;&#24341;&#20837;&#20102;&#36845;&#20195;&#26657;&#20934;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#21333;&#20010;&#20195;&#29702;&#25191;&#34892;&#22810;&#26679;&#21270;&#25805;&#20316;&#33021;&#21147;&#26377;&#38480;&#21644;&#33258;&#36866;&#24212;&#32416;&#27491;&#38169;&#35823;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.03031</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#20316;&#21644;&#20114;&#21160;&#20195;&#29702;&#23398;&#20064;&#20351;&#29992;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Learning to Use Tools via Cooperative and Interactive Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03031
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;ConAgents&#26694;&#26550;&#65292;&#36890;&#36807;&#21512;&#20316;&#21644;&#20114;&#21160;&#20195;&#29702;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#20351;&#29992;&#24037;&#20855;&#65292;&#24182;&#24341;&#20837;&#20102;&#36845;&#20195;&#26657;&#20934;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#21333;&#20010;&#20195;&#29702;&#25191;&#34892;&#22810;&#26679;&#21270;&#25805;&#20316;&#33021;&#21147;&#26377;&#38480;&#21644;&#33258;&#36866;&#24212;&#32416;&#27491;&#38169;&#35823;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#20855;&#23398;&#20064;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#20195;&#29702;&#20154;&#33021;&#22815;&#20351;&#29992;&#22806;&#37096;&#24037;&#20855;&#26469;&#25193;&#23637;&#20854;&#21151;&#33021;&#12290;&#29616;&#26377;&#26041;&#27861;&#21033;&#29992;&#21333;&#20010;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#24490;&#29615;&#36873;&#25321;&#21644;&#25191;&#34892;&#24037;&#20855;&#65292;&#28982;&#21518;&#23558;&#32467;&#26524;&#21512;&#24182;&#21040;&#19979;&#19968;&#20010;&#21160;&#20316;&#39044;&#27979;&#20013;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#26102;&#20173;&#28982;&#23384;&#22312;&#28508;&#22312;&#30340;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#65292;&#21407;&#22240;&#26159;&#65306;&#65288;1&#65289;&#21333;&#20010;LLM&#30340;&#22266;&#26377;&#33021;&#21147;&#25191;&#34892;&#22810;&#26679;&#21270;&#25805;&#20316;&#21463;&#38480;&#65292;&#20197;&#21450;&#65288;2&#65289;&#22312;&#20219;&#21153;&#22833;&#36133;&#26102;&#38590;&#20197;&#33258;&#36866;&#24212;&#22320;&#32416;&#27491;&#38169;&#35823;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ConAgents&#65292;&#21363;&#21512;&#20316;&#21644;&#20114;&#21160;&#20195;&#29702;&#26694;&#26550;&#65292;&#23558;&#24037;&#20855;&#23398;&#20064;&#30340;&#24037;&#20316;&#27969;&#27169;&#22359;&#21270;&#20026;Grounding&#65288;&#22522;&#30784;&#65289;&#12289;Execution&#65288;&#25191;&#34892;&#65289;&#21644;Observing&#65288;&#35266;&#23519;&#65289;&#20195;&#29702;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#36845;&#20195;&#26657;&#20934;&#65288;IterCali&#65289;&#26041;&#27861;&#65292;&#20351;&#20195;&#29702;&#33021;&#22815;&#26681;&#25454;&#26469;&#33258;&#24037;&#20855;&#29615;&#22659;&#30340;&#21453;&#39304;&#23545;&#33258;&#24049;&#36827;&#34892;&#35843;&#25972;&#12290;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#36229;&#36807;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03031v1 Announce Type: new  Abstract: Tool learning empowers large language models (LLMs) as agents to use external tools to extend their capability. Existing methods employ one single LLM-based agent to iteratively select and execute tools, thereafter incorporating the result into the next action prediction. However, they still suffer from potential performance degradation when addressing complex tasks due to: (1) the limitation of the inherent capability of a single LLM to perform diverse actions, and (2) the struggle to adaptively correct mistakes when the task fails. To mitigate these problems, we propose the ConAgents, a Cooperative and interactive Agents framework, which modularizes the workflow of tool learning into Grounding, Execution, and Observing agents. We also introduce an iterative calibration (IterCali) method, enabling the agents to adapt themselves based on the feedback from the tool environment. Experiments conducted on three datasets demonstrate the super
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31169;&#20154;&#22522;&#20934;&#35774;&#23450;&#26041;&#27861;&#65292;&#36890;&#36807;&#20445;&#25345;&#27979;&#35797;&#25968;&#25454;&#30340;&#31169;&#23494;&#24615;&#65292;&#20351;&#27169;&#22411;&#22312;&#19981;&#25581;&#38706;&#27979;&#35797;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35780;&#20272;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#22522;&#20934;&#35774;&#23450;&#20013;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.00393</link><description>&lt;p&gt;
&#38450;&#27490;&#27745;&#26579;&#21644;&#25552;&#39640;LLM&#27604;&#36739;&#35780;&#20272;&#30340;&#31169;&#20154;&#22522;&#20934;&#35774;&#23450;
&lt;/p&gt;
&lt;p&gt;
Private Benchmarking to Prevent Contamination and Improve Comparative Evaluation of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00393
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31169;&#20154;&#22522;&#20934;&#35774;&#23450;&#26041;&#27861;&#65292;&#36890;&#36807;&#20445;&#25345;&#27979;&#35797;&#25968;&#25454;&#30340;&#31169;&#23494;&#24615;&#65292;&#20351;&#27169;&#22411;&#22312;&#19981;&#25581;&#38706;&#27979;&#35797;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35780;&#20272;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#22522;&#20934;&#35774;&#23450;&#20013;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20934;&#35774;&#23450;&#26159;&#35780;&#20272;LLM&#30340;&#20107;&#23454;&#26631;&#20934;&#65292;&#22240;&#20026;&#23427;&#36895;&#24230;&#24555;&#12289;&#21487;&#22797;&#21046;&#19988;&#25104;&#26412;&#20302;&#24265;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25351;&#20986;&#65292;&#20170;&#22825;&#22823;&#22810;&#25968;&#24320;&#28304;&#22522;&#20934;&#35774;&#23450;&#24050;&#32463;&#34987;&#27745;&#26579;&#25110;&#27844;&#38706;&#21040;LLM&#20013;&#65292;&#36825;&#24847;&#21619;&#30528;LLM&#22312;&#39044;&#35757;&#32451;&#21644;/&#25110;&#24494;&#35843;&#26399;&#38388;&#21487;&#20197;&#35775;&#38382;&#27979;&#35797;&#25968;&#25454;&#12290;&#36825;&#23545;&#36804;&#20170;&#20026;&#27490;&#36827;&#34892;&#30340;&#22522;&#20934;&#30740;&#31350;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#26410;&#26469;&#20351;&#29992;&#22522;&#20934;&#36827;&#34892;&#35780;&#20272;&#25552;&#20986;&#20102;&#20005;&#37325;&#20851;&#20999;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Private Benchmarking&#65292;&#36825;&#26159;&#19968;&#20010;&#26041;&#26696;&#65292;&#20854;&#20013;&#27979;&#35797;&#25968;&#25454;&#38598;&#20445;&#25345;&#31169;&#23494;&#65292;&#27169;&#22411;&#22312;&#19981;&#21521;&#27169;&#22411;&#36879;&#38706;&#27979;&#35797;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35780;&#20272;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#21508;&#31181;&#22330;&#26223;&#65288;&#21462;&#20915;&#20110;&#23545;&#27169;&#22411;&#25152;&#26377;&#32773;&#25110;&#25968;&#25454;&#38598;&#25152;&#26377;&#32773;&#30340;&#20449;&#20219;&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;&#31169;&#20154;&#22522;&#20934;&#35774;&#23450;&#36991;&#20813;&#25968;&#25454;&#27745;&#26579;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#38656;&#35201;&#20445;&#25252;&#27169;&#22411;&#26435;&#37325;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#26469;&#33258;&#26426;&#23494;&#35745;&#31639;&#21644;&#23494;&#30721;&#23398;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00393v1 Announce Type: cross  Abstract: Benchmarking is the de-facto standard for evaluating LLMs, due to its speed, replicability and low cost. However, recent work has pointed out that the majority of the open source benchmarks available today have been contaminated or leaked into LLMs, meaning that LLMs have access to test data during pretraining and/or fine-tuning. This raises serious concerns about the validity of benchmarking studies conducted so far and the future of evaluation using benchmarks. To solve this problem, we propose Private Benchmarking, a solution where test datasets are kept private and models are evaluated without revealing the test data to the model. We describe various scenarios (depending on the trust placed on model owners or dataset owners), and present solutions to avoid data contamination using private benchmarking. For scenarios where the model weights need to be kept private, we describe solutions from confidential computing and cryptography t
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#21152;&#36895;&#32858;&#21512;&#29289;&#22826;&#38451;&#33021;&#30005;&#27744;&#26448;&#26009;&#21457;&#29616;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#21457;&#29616;&#26102;&#38388;&#24182;&#39044;&#27979;&#26410;&#34987;&#25253;&#36947;&#30340;&#26377;&#28508;&#21147;&#30340;&#21463;&#20307;-&#32473;&#20307;&#32452;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.19462</link><description>&lt;p&gt;
&#21152;&#36895;&#32858;&#21512;&#29289;&#22826;&#38451;&#33021;&#30005;&#27744;&#26448;&#26009;&#21457;&#29616;&#65306;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#23454;&#29616;&#30340;&#25968;&#25454;&#39537;&#21160;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19462
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#21152;&#36895;&#32858;&#21512;&#29289;&#22826;&#38451;&#33021;&#30005;&#27744;&#26448;&#26009;&#21457;&#29616;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#21457;&#29616;&#26102;&#38388;&#24182;&#39044;&#27979;&#26410;&#34987;&#25253;&#36947;&#30340;&#26377;&#28508;&#21147;&#30340;&#21463;&#20307;-&#32473;&#20307;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27969;&#31243;&#65292;&#29992;&#20110;&#20174;&#25991;&#29486;&#20013;&#25552;&#21462;&#32858;&#21512;&#29289;&#22826;&#38451;&#33021;&#30005;&#27744;&#23646;&#24615;&#25968;&#25454;&#65292;&#24182;&#27169;&#25311;&#21508;&#31181;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#12290;&#34429;&#28982;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#24050;&#32463;&#34987;&#24191;&#27867;&#24314;&#31435;&#36215;&#26469;&#65292;&#21487;&#20197;&#27604;&#29233;&#36842;&#29983;&#35797;&#38169;&#27861;&#26356;&#24555;&#22320;&#21457;&#29616;&#26032;&#26448;&#26009;&#65292;&#20294;&#23427;&#20204;&#30340;&#30410;&#22788;&#23578;&#26410;&#24471;&#21040;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#21457;&#29616;&#26102;&#38388;&#28508;&#22312;&#20943;&#23569;&#32422;75&#65285;&#65292;&#30456;&#24403;&#20110;&#26448;&#26009;&#21019;&#26032;&#21152;&#36895;15&#24180;&#12290;&#25105;&#20204;&#30340;&#27969;&#31243;&#20351;&#25105;&#20204;&#33021;&#22815;&#20174;&#36229;&#36807;3300&#31687;&#35770;&#25991;&#20013;&#25552;&#21462;&#25968;&#25454;&#65292;&#36825;&#27604;&#20854;&#20182;&#20154;&#25253;&#21578;&#30340;&#31867;&#20284;&#25968;&#25454;&#38598;&#22823;&#32422;&#22810;5&#20493;&#12290;&#25105;&#20204;&#36824;&#35757;&#32451;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#39044;&#27979;&#21151;&#29575;&#36716;&#25442;&#25928;&#29575;&#65292;&#24182;&#20351;&#29992;&#25105;&#20204;&#30340;&#27169;&#22411;&#35782;&#21035;&#20102;&#23578;&#26410;&#25253;&#36947;&#30340;&#26377;&#21069;&#36884;&#30340;&#21463;&#20307;-&#32473;&#20307;&#32452;&#21512;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#24037;&#20316;&#27969;&#31243;&#65292;&#20174;&#24050;&#21457;&#34920;&#30340;&#25991;&#29486;&#21040;&#25552;&#21462;&#30340;&#26448;&#26009;&#23646;&#24615;&#25968;&#25454;&#65292;&#36827;&#32780;&#29992;&#20110;&#33719;&#24471;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19462v1 Announce Type: cross  Abstract: We present a natural language processing pipeline that was used to extract polymer solar cell property data from the literature and simulate various active learning strategies. While data-driven methods have been well established to discover novel materials faster than Edisonian trial-and-error approaches, their benefits have not been quantified. Our approach demonstrates a potential reduction in discovery time by approximately 75 %, equivalent to a 15 year acceleration in material innovation. Our pipeline enables us to extract data from more than 3300 papers which is ~5 times larger than similar data sets reported by others. We also trained machine learning models to predict the power conversion efficiency and used our model to identify promising donor-acceptor combinations that are as yet unreported. We thus demonstrate a workflow that goes from published literature to extracted material property data which in turn is used to obtain 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#20851;&#38190;&#25216;&#26415;&#12289;&#25351;&#26631;&#12289;&#25968;&#25454;&#38598;&#12289;&#27169;&#22411;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.17944</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;--&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Large Language Models on Tabular Data -- A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17944
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#20851;&#38190;&#25216;&#26415;&#12289;&#25351;&#26631;&#12289;&#25968;&#25454;&#38598;&#12289;&#27169;&#22411;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#34920;&#26684;&#25968;&#25454;&#24314;&#27169;&#26041;&#38754;&#30340;&#24212;&#29992;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#36827;&#23637;&#65292;&#21253;&#25324;&#39044;&#27979;&#12289;&#34920;&#26684;&#25968;&#25454;&#21512;&#25104;&#12289;&#38382;&#31572;&#21644;&#34920;&#26684;&#29702;&#35299;&#31561;&#22810;&#31181;&#20219;&#21153;&#12290;&#27599;&#20010;&#20219;&#21153;&#37117;&#24102;&#26469;&#29420;&#29305;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#32570;&#20047;&#23545;&#35813;&#30740;&#31350;&#39046;&#22495;&#20013;&#20851;&#38190;&#25216;&#26415;&#12289;&#25351;&#26631;&#12289;&#25968;&#25454;&#38598;&#12289;&#27169;&#22411;&#21644;&#20248;&#21270;&#26041;&#27861;&#30340;&#20840;&#38754;&#23457;&#26597;&#12290;&#26412;&#35843;&#26597;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#24635;&#32467;&#24182;&#27604;&#36739;&#36825;&#20123;&#39046;&#22495;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25552;&#20379;&#23545;&#25968;&#25454;&#38598;&#12289;&#25351;&#26631;&#21644;&#26041;&#27861;&#35770;&#30340;&#20840;&#38754;&#35843;&#26597;&#21644;&#20998;&#31867;&#12290;&#23427;&#35782;&#21035;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#20248;&#21183;&#12289;&#23616;&#38480;&#24615;&#12289;&#26410;&#24320;&#21457;&#39046;&#22495;&#21644;&#31354;&#30333;&#65292;&#21516;&#26102;&#20026;&#36825;&#19968;&#37325;&#35201;&#19988;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#30340;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#25552;&#20379;&#20102;&#19968;&#20123;&#35265;&#35299;&#12290;&#23427;&#36824;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#24341;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17944v1 Announce Type: new  Abstract: Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding. Each task presents unique challenges and opportunities. However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain. This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized. It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field. It also provides relevant code and datasets references. Through this comprehen
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#33258;&#21160;&#32479;&#35745;&#27169;&#22411;&#21457;&#29616;&#26041;&#27861;&#65292;&#19981;&#20877;&#38656;&#35201;&#23450;&#20041;&#29305;&#23450;&#39046;&#22495;&#27169;&#22411;&#35821;&#35328;&#25110;&#35774;&#35745;&#25163;&#24037;&#25628;&#32034;&#31243;&#24207;&#12290;</title><link>https://arxiv.org/abs/2402.17879</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#33258;&#21160;&#32479;&#35745;&#27169;&#22411;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Automated Statistical Model Discovery with Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17879
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#33258;&#21160;&#32479;&#35745;&#27169;&#22411;&#21457;&#29616;&#26041;&#27861;&#65292;&#19981;&#20877;&#38656;&#35201;&#23450;&#20041;&#29305;&#23450;&#39046;&#22495;&#27169;&#22411;&#35821;&#35328;&#25110;&#35774;&#35745;&#25163;&#24037;&#25628;&#32034;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#27169;&#22411;&#21457;&#29616;&#28041;&#21450;&#22312;&#21463;&#39046;&#22495;&#29305;&#23450;&#24314;&#27169;&#32422;&#26463;&#30340;&#24191;&#27867;&#27169;&#22411;&#31354;&#38388;&#19978;&#36827;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25628;&#32034;&#12290;&#39640;&#25928;&#25628;&#32034;&#36825;&#19968;&#31354;&#38388;&#38656;&#35201;&#20855;&#26377;&#24314;&#27169;&#21644;&#38382;&#39064;&#22495;&#20154;&#31867;&#19987;&#38271;&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;&#21463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#39046;&#22495;&#30693;&#35782;&#21644;&#32534;&#31243;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#33258;&#21160;&#32479;&#35745;&#27169;&#22411;&#21457;&#29616;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#33258;&#21160;&#21270;&#27969;&#31243;&#32622;&#20110;Box&#30340;&#24490;&#29615;&#26694;&#26550;&#20043;&#20869;&#65306;LM&#22312;&#25552;&#20986;&#34920;&#31034;&#20026;&#27010;&#29575;&#31243;&#24207;&#30340;&#32479;&#35745;&#27169;&#22411;&#65288;&#20805;&#24403;&#24314;&#27169;&#32773;&#65289;&#20043;&#38388;&#36845;&#20195;&#65292;&#24182;&#25209;&#21028;&#36825;&#20123;&#27169;&#22411;&#65288;&#20805;&#24403;&#39046;&#22495;&#19987;&#23478;&#65289;&#12290;&#36890;&#36807;&#21033;&#29992;LMs&#65292;&#25105;&#20204;&#19981;&#24517;&#23450;&#20041;&#19968;&#20010;&#39046;&#22495;&#29305;&#23450;&#30340;&#27169;&#22411;&#35821;&#35328;&#25110;&#35774;&#35745;&#25163;&#24037;&#25628;&#32034;&#31243;&#24207;&#65292;&#36825;&#26159;&#20808;&#21069;&#31995;&#32479;&#30340;&#37325;&#35201;&#38480;&#21046;&#12290;&#25105;&#20204;&#22312;&#27010;&#29575;&#24314;&#27169;&#30340;&#19977;&#31181;&#24120;&#35265;&#35774;&#32622;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65306;&#22312;&#21463;&#38480;&#27169;&#22411;&#31354;&#38388;&#20869;&#25628;&#32034;&#65292;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17879v1 Announce Type: cross  Abstract: Statistical model discovery involves a challenging search over a vast space of models subject to domain-specific modeling constraints. Efficiently searching over this space requires human expertise in modeling and the problem domain. Motivated by the domain knowledge and programming capabilities of large language models (LMs), we introduce a method for language model driven automated statistical model discovery. We cast our automated procedure within the framework of Box's Loop: the LM iterates between proposing statistical models represented as probabilistic programs, acting as a modeler, and critiquing those models, acting as a domain expert. By leveraging LMs, we do not have to define a domain-specific language of models or design a handcrafted search procedure, key restrictions of previous systems. We evaluate our method in three common settings in probabilistic modeling: searching within a restricted space of models, searching ove
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;MELoRA&#65292;&#19968;&#31181;&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#26356;&#23569;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#21516;&#26102;&#20445;&#25345;&#26356;&#39640;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#20379;&#25913;&#36827;&#30340;&#24615;&#33021;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.17263</link><description>&lt;p&gt;
&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#29992;&#20110;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17263
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;MELoRA&#65292;&#19968;&#31181;&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#26356;&#23569;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#21516;&#26102;&#20445;&#25345;&#26356;&#39640;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#20379;&#25913;&#36827;&#30340;&#24615;&#33021;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#23450;&#21046;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27969;&#34892;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;&#27169;&#22411;&#35268;&#27169;&#21644;&#20219;&#21153;&#22810;&#26679;&#24615;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#12290;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#22522;&#20110;&#36825;&#26679;&#19968;&#20010;&#24605;&#24819;&#65292;&#21363;&#36866;&#24212;&#36807;&#31243;&#22312;&#26412;&#36136;&#19978;&#26159;&#20302;&#32500;&#30340;&#65292;&#21363;&#21487;&#20197;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#21442;&#25968;&#34920;&#31034;&#37325;&#35201;&#30340;&#27169;&#22411;&#21464;&#21270;&#12290;&#28982;&#32780;&#65292;&#19982;&#20840;&#21442;&#25968;&#24494;&#35843;&#30456;&#27604;&#65292;&#38477;&#20302;&#31209;&#20250;&#36935;&#21040;&#29305;&#23450;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;MELoRA&#65292;&#19968;&#31181;&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#65292;&#20351;&#29992;&#26356;&#23569;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#21516;&#26102;&#20445;&#25345;&#26356;&#39640;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#20379;&#25913;&#36827;&#30340;&#24615;&#33021;&#28508;&#21147;&#12290;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#20923;&#32467;&#21407;&#22987;&#30340;&#39044;&#35757;&#32451;&#26435;&#37325;&#65292;&#24182;&#35757;&#32451;&#19968;&#32452;&#20165;&#20855;&#26377;&#23569;&#37327;&#21442;&#25968;&#30340;&#36855;&#20320;LoRA&#12290;&#36825;&#21487;&#20197;&#25429;&#25417;&#36855;&#20320;LoRA&#20043;&#38388;&#30340;&#37325;&#35201;&#22810;&#26679;&#24615;&#31243;&#24230;&#65292;&#20174;&#32780;&#20419;&#36827;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17263v1 Announce Type: new  Abstract: Parameter-efficient fine-tuning (PEFT) is a popular method for tailoring pre-trained large language models (LLMs), especially as the models' scale and the diversity of tasks increase. Low-rank adaptation (LoRA) is based on the idea that the adaptation process is intrinsically low-dimensional, i.e., significant model changes can be represented with relatively few parameters. However, decreasing the rank encounters challenges with generalization errors for specific tasks when compared to full-parameter fine-tuning. We present MELoRA, a mini-ensemble low-rank adapters that uses fewer trainable parameters while maintaining a higher rank, thereby offering improved performance potential. The core idea is to freeze original pretrained weights and train a group of mini LoRAs with only a small number of parameters. This can capture a significant degree of diversity among mini LoRAs, thus promoting better generalization ability. We conduct a theor
&lt;/p&gt;</description></item><item><title>Mirror &#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#35282;&#33258;&#25105;&#21453;&#24605;&#26041;&#27861;&#65292;&#36890;&#36807;&#23548;&#33322;&#32773;&#21644;&#25512;&#29702;&#32773;&#20043;&#38388;&#30340;&#21551;&#21457;&#24335;&#20132;&#20114;&#65292;&#20419;&#36827;&#22810;&#26679;&#24615;&#32780;&#20855;&#26377;&#21487;&#38752;&#24615;&#30340;&#25512;&#29702;&#36712;&#36857;&#21457;&#23637;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#30693;&#35782;&#20016;&#23500;&#38382;&#39064;&#19978;&#30340;&#22256;&#38590;&#12290;</title><link>https://arxiv.org/abs/2402.14963</link><description>&lt;p&gt;
&#38236;&#20687;&#65306;&#19968;&#31181;&#36866;&#29992;&#20110;&#30693;&#35782;&#20016;&#23500;&#25512;&#29702;&#30340;&#22810;&#35270;&#35282;&#33258;&#25105;&#21453;&#24605;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14963
&lt;/p&gt;
&lt;p&gt;
Mirror &#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#35282;&#33258;&#25105;&#21453;&#24605;&#26041;&#27861;&#65292;&#36890;&#36807;&#23548;&#33322;&#32773;&#21644;&#25512;&#29702;&#32773;&#20043;&#38388;&#30340;&#21551;&#21457;&#24335;&#20132;&#20114;&#65292;&#20419;&#36827;&#22810;&#26679;&#24615;&#32780;&#20855;&#26377;&#21487;&#38752;&#24615;&#30340;&#25512;&#29702;&#36712;&#36857;&#21457;&#23637;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#30693;&#35782;&#20016;&#23500;&#38382;&#39064;&#19978;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26377;&#33021;&#21147;&#21453;&#22797;&#21453;&#24605;&#33258;&#24049;&#30340;&#36755;&#20986;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#35266;&#23519;&#21040;&#23427;&#20204;&#22312;&#27809;&#26377;&#22806;&#37096;&#36164;&#28304;&#30340;&#24773;&#20917;&#19979;&#22788;&#29702;&#30693;&#35782;&#20016;&#23500;&#38382;&#39064;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;&#38500;&#20102;LLMs&#22312;&#33258;&#25105;&#35780;&#20272;&#26041;&#38754;&#30340;&#20302;&#25928;&#29575;&#22806;&#65292;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;&#23613;&#31649;&#21463;&#21040;&#26126;&#30830;&#36127;&#38754;&#21453;&#39304;&#65292;LLMs&#20173;&#28982;&#38590;&#20197;&#37325;&#26032;&#23457;&#35270;&#20854;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Mirror&#65292;&#19968;&#31181;&#36866;&#29992;&#20110;&#30693;&#35782;&#20016;&#23500;&#25512;&#29702;&#30340;&#22810;&#35282;&#24230;&#33258;&#25105;&#21453;&#24605;&#26041;&#27861;&#65292;&#20197;&#36991;&#20813;&#22312;&#29305;&#23450;&#21453;&#24605;&#36845;&#20195;&#20013;&#21345;&#20303;&#12290;Mirror&#20351;LLMs&#33021;&#22815;&#36890;&#36807;&#23548;&#33322;&#32773;&#21644;&#25512;&#29702;&#32773;&#20043;&#38388;&#30340;&#21551;&#21457;&#24335;&#20132;&#20114;&#33719;&#24471;&#22810;&#35270;&#35282;&#32447;&#32034;&#30340;&#21453;&#24605;&#65292;&#24341;&#23548;&#20195;&#29702;&#21521;&#22810;&#26679;&#24615;&#32780;&#20855;&#26377;&#21487;&#38752;&#24615;&#30340;&#25512;&#29702;&#36712;&#36857;&#21457;&#23637;&#65292;&#32780;&#26080;&#38656;&#35775;&#38382;&#22320;&#38754;&#30495;&#30456;&#65292;&#36890;&#36807;&#40723;&#21169;&#65288;1&#65289;&#23548;&#33322;&#32773;&#29983;&#25104;&#30340;&#26041;&#21521;&#30340;&#22810;&#26679;&#24615;&#19982;&#65288;2&#65289;&#31574;&#30053;&#24615;&#24341;&#21457;&#30340;&#25200;&#21160;&#22312;&#20135;&#29983;&#30340;&#22238;&#24212;&#20013;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14963v1 Announce Type: cross  Abstract: While Large language models (LLMs) have the capability to iteratively reflect on their own outputs, recent studies have observed their struggles with knowledge-rich problems without access to external resources. In addition to the inefficiency of LLMs in self-assessment, we also observe that LLMs struggle to revisit their predictions despite receiving explicit negative feedback. Therefore, We propose Mirror, a Multiple-perspective self-reflection method for knowledge-rich reasoning, to avoid getting stuck at a particular reflection iteration. Mirror enables LLMs to reflect from multiple-perspective clues, achieved through a heuristic interaction between a Navigator and a Reasoner. It guides agents toward diverse yet plausibly reliable reasoning trajectory without access to ground truth by encouraging (1) diversity of directions generated by Navigator and (2) agreement among strategically induced perturbations in responses generated by 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22312;&#20869;&#23481;&#26465;&#20214;&#19979;&#30830;&#20445;&#25935;&#24863;&#23646;&#24615;&#19982;&#25991;&#26412;&#23884;&#20837;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#25913;&#21892;&#20844;&#24179;&#24615;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#25928;&#29992;&#30340;&#21516;&#26102;&#65292;&#35299;&#20915;&#20102;&#32570;&#20047;&#36866;&#24403;&#35757;&#32451;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.14208</link><description>&lt;p&gt;
&#38754;&#21521;&#20844;&#24179;&#25991;&#26412;&#23884;&#20837;&#30340;&#20869;&#23481;&#26465;&#20214;&#21435;&#20559;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Content Conditional Debiasing for Fair Text Embedding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14208
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#20869;&#23481;&#26465;&#20214;&#19979;&#30830;&#20445;&#25935;&#24863;&#23646;&#24615;&#19982;&#25991;&#26412;&#23884;&#20837;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#25913;&#21892;&#20844;&#24179;&#24615;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#25928;&#29992;&#30340;&#21516;&#26102;&#65292;&#35299;&#20915;&#20102;&#32570;&#20047;&#36866;&#24403;&#35757;&#32451;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#65292;&#20943;&#36731;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#21482;&#26377;&#23569;&#25968;&#30740;&#31350;&#38598;&#20013;&#22312;&#20844;&#24179;&#30340;&#25991;&#26412;&#23884;&#20837;&#19978;&#65292;&#36825;&#23545;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20844;&#24179;&#25991;&#26412;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#30830;&#20445;&#22312;&#20869;&#23481;&#26465;&#20214;&#19979;&#25935;&#24863;&#23646;&#24615;&#19982;&#25991;&#26412;&#23884;&#20837;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26469;&#23454;&#29616;&#20844;&#24179;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#25928;&#29992;&#26435;&#34913;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24378;&#21046;&#35201;&#27714;&#20855;&#26377;&#19981;&#21516;&#25935;&#24863;&#23646;&#24615;&#20294;&#30456;&#21516;&#20869;&#23481;&#30340;&#25991;&#26412;&#30340;&#23884;&#20837;&#19982;&#20854;&#23545;&#24212;&#20013;&#31435;&#25991;&#26412;&#30340;&#23884;&#20837;&#20445;&#25345;&#30456;&#21516;&#30340;&#36317;&#31163;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23558;&#25991;&#26412;&#22686;&#24378;&#20026;&#19981;&#21516;&#30340;&#25935;&#24863;&#32452;&#65292;&#26469;&#35299;&#20915;&#32570;&#20047;&#36866;&#24403;&#35757;&#32451;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#20844;&#24179;&#24615;&#21516;&#26102;&#20445;&#25345;&#20102;&#23884;&#20837;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14208v1 Announce Type: cross  Abstract: Mitigating biases in machine learning models has gained increasing attention in Natural Language Processing (NLP). Yet, only a few studies focus on fair text embeddings, which are crucial yet challenging for real-world applications. In this paper, we propose a novel method for learning fair text embeddings. We achieve fairness while maintaining utility trade-off by ensuring conditional independence between sensitive attributes and text embeddings conditioned on the content. Specifically, we enforce that embeddings of texts with different sensitive attributes but identical content maintain the same distance toward the embedding of their corresponding neutral text. Furthermore, we address the issue of lacking proper training data by using Large Language Models (LLMs) to augment texts into different sensitive groups. Our extensive evaluations demonstrate that our approach effectively improves fairness while preserving the utility of embed
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#20026;&#33258;&#21160;&#21270;&#25968;&#25454;&#26631;&#27880;&#25552;&#20379;&#26426;&#36935;&#65292;&#35813;&#35843;&#26597;&#29420;&#29305;&#20851;&#27880;LLM&#22312;&#25968;&#25454;&#26631;&#27880;&#20013;&#30340;&#25928;&#29992;&#65292;&#36129;&#29486;&#20027;&#35201;&#38598;&#20013;&#22312;LLM-Based&#25968;&#25454;&#26631;&#27880;&#12289;&#35780;&#20272;LLM&#29983;&#25104;&#30340;&#26631;&#27880;&#20197;&#21450;&#20351;&#29992;LLM&#29983;&#25104;&#30340;&#26631;&#27880;&#23398;&#20064;&#31561;&#19977;&#20010;&#26680;&#24515;&#26041;&#38754;&#12290;</title><link>https://arxiv.org/abs/2402.13446</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25968;&#25454;&#26631;&#27880;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Large Language Models for Data Annotation: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13446
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#20026;&#33258;&#21160;&#21270;&#25968;&#25454;&#26631;&#27880;&#25552;&#20379;&#26426;&#36935;&#65292;&#35813;&#35843;&#26597;&#29420;&#29305;&#20851;&#27880;LLM&#22312;&#25968;&#25454;&#26631;&#27880;&#20013;&#30340;&#25928;&#29992;&#65292;&#36129;&#29486;&#20027;&#35201;&#38598;&#20013;&#22312;LLM-Based&#25968;&#25454;&#26631;&#27880;&#12289;&#35780;&#20272;LLM&#29983;&#25104;&#30340;&#26631;&#27880;&#20197;&#21450;&#20351;&#29992;LLM&#29983;&#25104;&#30340;&#26631;&#27880;&#23398;&#20064;&#31561;&#19977;&#20010;&#26680;&#24515;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#26631;&#27880;&#26159;&#23558;&#21407;&#22987;&#25968;&#25454;&#26631;&#35760;&#25110;&#25171;&#26631;&#31614;&#19982;&#30456;&#20851;&#20449;&#24687;&#65292;&#23545;&#20110;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#36807;&#31243;&#21171;&#21160;&#23494;&#38598;&#19988;&#26114;&#36149;&#12290;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#20363;&#22914;GPT-4&#65292;&#20026;&#38761;&#26032;&#21644;&#33258;&#21160;&#21270;&#25968;&#25454;&#26631;&#27880;&#30340;&#22797;&#26434;&#36807;&#31243;&#25552;&#20379;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#26426;&#36935;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#35843;&#26597;&#24050;&#32463;&#24191;&#27867;&#28085;&#30422;&#20102;LLM&#30340;&#26550;&#26500;&#12289;&#35757;&#32451;&#21644;&#19968;&#33324;&#24212;&#29992;&#65292;&#20294;&#26412;&#25991;&#29420;&#29305;&#22320;&#20851;&#27880;&#23427;&#20204;&#22312;&#25968;&#25454;&#26631;&#27880;&#20013;&#30340;&#20855;&#20307;&#25928;&#29992;&#12290;&#35813;&#35843;&#26597;&#23545;LLM-Based&#25968;&#25454;&#26631;&#27880;&#12289;&#35780;&#20272;LLM&#29983;&#25104;&#30340;&#26631;&#27880;&#20197;&#21450;&#20351;&#29992;LLM&#29983;&#25104;&#30340;&#26631;&#27880;&#23398;&#20064;&#36825;&#19977;&#20010;&#26680;&#24515;&#26041;&#38754;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#27492;&#22806;&#65292;&#35770;&#25991;&#21253;&#25324;&#20102;&#19968;&#31181;&#20351;&#29992;LLMs&#36827;&#34892;&#25968;&#25454;&#26631;&#27880;&#30340;&#26041;&#27861;&#23398;&#28145;&#24230;&#20998;&#31867;&#27861;&#65292;&#19968;&#20010;&#23545;&#25972;&#21512;LLM&#29983;&#25104;&#30340;&#26631;&#27880;&#30340;&#27169;&#22411;&#30340;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#20840;&#38754;&#23457;&#26597;&#65292;&#20197;&#21450;&#23545;&#20854;&#36827;&#34892;&#35814;&#32454;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13446v1 Announce Type: new  Abstract: Data annotation is the labeling or tagging of raw data with relevant information, essential for improving the efficacy of machine learning models. The process, however, is labor-intensive and expensive. The emergence of advanced Large Language Models (LLMs), exemplified by GPT-4, presents an unprecedented opportunity to revolutionize and automate the intricate process of data annotation. While existing surveys have extensively covered LLM architecture, training, and general applications, this paper uniquely focuses on their specific utility for data annotation. This survey contributes to three core aspects: LLM-Based Data Annotation, Assessing LLM-generated Annotations, and Learning with LLM-generated annotations. Furthermore, the paper includes an in-depth taxonomy of methodologies employing LLMs for data annotation, a comprehensive review of learning strategies for models incorporating LLM-generated annotations, and a detailed discussi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;PromptKD&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#31034;&#35843;&#25972;&#23454;&#29616;&#20102;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#25552;&#21462;&#23398;&#29983;&#21451;&#22909;&#30693;&#35782;&#30340;&#33976;&#39311;&#65292;&#26080;&#38656;&#24494;&#35843;&#25972;&#25972;&#20010;&#25945;&#24072;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.12842</link><description>&lt;p&gt;
PromptKD&#65306;&#36890;&#36807;&#25552;&#31034;&#35843;&#25972;&#20026;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#25552;&#21462;&#23398;&#29983;&#21451;&#22909;&#30693;&#35782;&#30340;&#33976;&#39311;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12842
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;PromptKD&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#31034;&#35843;&#25972;&#23454;&#29616;&#20102;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#25552;&#21462;&#23398;&#29983;&#21451;&#22909;&#30693;&#35782;&#30340;&#33976;&#39311;&#65292;&#26080;&#38656;&#24494;&#35843;&#25972;&#25972;&#20010;&#25945;&#24072;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21457;&#23637;&#24341;&#36215;&#20102;&#23545;&#25512;&#29702;&#25104;&#26412;&#30340;&#25285;&#24551;&#65292;&#36827;&#19968;&#27493;&#22686;&#21152;&#20102;&#23545;&#27169;&#22411;&#21387;&#32553;&#30740;&#31350;&#30340;&#38656;&#27714;&#12290;&#23613;&#31649;&#30693;&#35782;&#33976;&#39311;&#65288;KD&#65289;&#26159;&#19968;&#31181;&#31361;&#20986;&#30340;&#26041;&#27861;&#65292;&#20294;&#26159;&#38024;&#23545;LLMs&#36825;&#26679;&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;KD&#30740;&#31350;&#30456;&#23545;&#36739;&#23569;&#65292;&#32780;&#25552;&#21462;&#36866;&#21512;&#23398;&#29983;&#30340;&#30693;&#35782;&#30340;&#26041;&#27861;&#65292;&#22312;&#20998;&#31867;&#27169;&#22411;&#30340;KD&#20013;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#24615;&#33021;&#65292;&#22312;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#20013;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PromptKD&#65292;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#25552;&#31034;&#35843;&#25972; - &#22312;KD&#20013;&#39318;&#27425;&#20986;&#29616; - &#20351;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#20256;&#36882;&#36866;&#21512;&#23398;&#29983;&#30340;&#30693;&#35782;&#12290;&#19982;&#20808;&#21069;&#20998;&#31867;&#24037;&#20316;&#19981;&#21516;&#65292;&#20808;&#21069;&#37027;&#20123;&#38656;&#35201;&#24494;&#35843;&#25972;&#25972;&#20010;&#25945;&#24072;&#27169;&#22411;&#20197;&#25552;&#21462;&#36866;&#21512;&#23398;&#29983;&#30340;&#30693;&#35782;&#65292;PromptKD&#36890;&#36807;&#28155;&#21152;&#23569;&#37327;&#25552;&#31034;&#26631;&#35760;&#65292;&#24182;&#20165;&#36890;&#36807;&#23398;&#29983;&#25351;&#23548;&#35843;&#25972;&#25552;&#31034;&#26469;&#36798;&#21040;&#31867;&#20284;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12842v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have raised concerns about inference costs, increasing the need for research into model compression. While knowledge distillation (KD) is a prominent method for this, research on KD for generative language models like LLMs is relatively sparse, and the approach of distilling student-friendly knowledge, which has shown promising performance in KD for classification models, remains unexplored in generative language models. To explore this approach, we propose PromptKD, a simple yet effective method that utilizes prompt tuning - for the first time in KD - to enable generative language models to transfer student-friendly knowledge. Unlike previous works in classification that require fine-tuning the entire teacher model for extracting student-friendly knowledge, PromptKD achieves similar effects by adding a small number of prompt tokens and tuning only the prompt with student guidance. Ex
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#20803;&#32467;&#26500;&#25628;&#32034;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#25163;&#24037;&#35774;&#35745;&#20803;&#32467;&#26500;&#19981;&#26131;&#25193;&#23637;&#20197;&#21450;&#24573;&#35270;&#21487;&#35299;&#37322;&#24615;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2402.11518</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#24322;&#36136;&#20449;&#24687;&#32593;&#32476;&#20013;&#20803;&#32467;&#26500;&#30340;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11518
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#20803;&#32467;&#26500;&#25628;&#32034;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#25163;&#24037;&#35774;&#35745;&#20803;&#32467;&#26500;&#19981;&#26131;&#25193;&#23637;&#20197;&#21450;&#24573;&#35270;&#21487;&#35299;&#37322;&#24615;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#36136;&#20449;&#24687;&#32593;&#32476;&#65288;HIN&#65289;&#22240;&#33021;&#22815;&#25429;&#25417;&#19981;&#21516;&#31867;&#22411;&#33410;&#28857;&#20043;&#38388;&#22797;&#26434;&#20851;&#31995;&#32780;&#26085;&#30410;&#21463;&#21040;&#38738;&#30544;&#12290;&#20803;&#32467;&#26500;&#34987;&#25552;&#20986;&#29992;&#20110;&#35782;&#21035;HIN&#19978;&#30340;&#37325;&#35201;&#20851;&#31995;&#27169;&#24335;&#65292;&#24050;&#35777;&#26126;&#22312;&#25552;&#21462;&#20016;&#23500;&#35821;&#20041;&#20449;&#24687;&#21644;&#20419;&#36827;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#34920;&#36798;&#21147;&#34920;&#31034;&#26041;&#38754;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#25163;&#24037;&#35774;&#35745;&#30340;&#20803;&#32467;&#26500;&#22312;&#25193;&#23637;&#24615;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#65292;&#36825;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20197;&#21457;&#23637;&#33258;&#21160;&#20803;&#32467;&#26500;&#25628;&#32034;&#31639;&#27861;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#38598;&#20013;&#20110;&#23547;&#25214;&#20855;&#26377;&#33391;&#22909;&#32463;&#39564;&#39044;&#27979;&#24615;&#33021;&#30340;&#20803;&#32467;&#26500;&#65292;&#32780;&#24573;&#35270;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;&#22240;&#27492;&#65292;&#20182;&#20204;&#24448;&#24448;&#20135;&#29983;&#26131;&#20110;&#36807;&#24230;&#25311;&#21512;&#21644;&#20154;&#31867;&#38590;&#20197;&#29702;&#35299;&#30340;&#20803;&#32467;&#26500;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26032;&#20852;&#30340;&#25512;&#29702;&#33021;&#21147;&#20013;&#33719;&#21462;&#21551;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;REasoning meta-STRUCTure search&#65288;ReStruct&#65289;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11518v1 Announce Type: new  Abstract: Heterogeneous information networks (HIN) have gained increasing popularity for being able to capture complex relations between nodes of diverse types. Meta-structure was proposed to identify important patterns of relations on HIN, which has been proven effective for extracting rich semantic information and facilitating graph neural networks to learn expressive representations. However, hand-crafted meta-structures pose challenges for scaling up, which draws wide research attention for developing automatic meta-structure search algorithms. Previous efforts concentrate on searching for meta-structures with good empirical prediction performance, overlooking explainability. Thus, they often produce meta-structures prone to overfitting and incomprehensible to humans. To address this, we draw inspiration from the emergent reasoning abilities of large language models (LLMs). We propose a novel REasoning meta-STRUCTure search (ReStruct) framewor
&lt;/p&gt;</description></item><item><title>C-ICL&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#30830;&#21644;&#19981;&#27491;&#30830;&#26679;&#26412;&#26500;&#24314;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#31034;&#33539;&#30340;&#26032;&#39062;&#23569;&#26679;&#26412;&#25216;&#26415;&#65292;&#36890;&#36807;&#25552;&#31034;&#19981;&#20165;&#21253;&#21547;&#27491;&#26679;&#26412;&#36824;&#21253;&#21547;&#32972;&#21518;&#25512;&#29702;&#65292;&#22686;&#24378;&#20102;LLMs&#25552;&#21462;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.11254</link><description>&lt;p&gt;
C-ICL&#65306;&#23545;&#27604;&#19978;&#19979;&#25991;&#23398;&#20064;&#29992;&#20110;&#20449;&#24687;&#25277;&#21462;
&lt;/p&gt;
&lt;p&gt;
C-ICL: Contrastive In-context Learning for Information Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11254
&lt;/p&gt;
&lt;p&gt;
C-ICL&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#30830;&#21644;&#19981;&#27491;&#30830;&#26679;&#26412;&#26500;&#24314;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#31034;&#33539;&#30340;&#26032;&#39062;&#23569;&#26679;&#26412;&#25216;&#26415;&#65292;&#36890;&#36807;&#25552;&#31034;&#19981;&#20165;&#21253;&#21547;&#27491;&#26679;&#26412;&#36824;&#21253;&#21547;&#32972;&#21518;&#25512;&#29702;&#65292;&#22686;&#24378;&#20102;LLMs&#25552;&#21462;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#20110;&#25506;&#32034;&#20808;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20449;&#24687;&#25277;&#21462;&#65288;IE&#65289;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#29305;&#21035;&#26159;&#19987;&#27880;&#20110;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#21644;&#20851;&#31995;&#25552;&#21462;&#65288;RE&#65289;&#30456;&#20851;&#30340;&#20219;&#21153;&#12290;&#23613;&#31649;&#30740;&#31350;&#20154;&#21592;&#27491;&#36890;&#36807;LLMs&#36827;&#34892;&#23569;&#26679;&#26412;&#20449;&#24687;&#25277;&#21462;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#20182;&#20204;&#24448;&#24448;&#21482;&#19987;&#27880;&#20110;&#20351;&#29992;&#27491;&#30830;&#25110;&#27491;&#21521;&#31034;&#20363;&#26469;&#23637;&#31034;&#65292;&#32780;&#24573;&#35270;&#20102;&#23558;&#19981;&#27491;&#30830;&#25110;&#36127;&#21521;&#31034;&#20363;&#32435;&#20837;&#23398;&#20064;&#36807;&#31243;&#30340;&#28508;&#22312;&#20215;&#20540;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;C-ICL&#65292;&#19968;&#31181;&#21033;&#29992;&#27491;&#30830;&#21644;&#19981;&#27491;&#30830;&#26679;&#26412;&#26500;&#24314;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#31034;&#33539;&#30340;&#26032;&#39062;&#23569;&#26679;&#26412;&#25216;&#26415;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#19981;&#20165;&#21253;&#21547;&#27491;&#26679;&#26412;&#36824;&#21253;&#21547;&#32972;&#21518;&#25512;&#29702;&#30340;&#25552;&#31034;&#65292;&#22686;&#24378;&#20102;LLMs&#25552;&#21462;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11254v1 Announce Type: new  Abstract: Recently, there has been increasing interest in exploring the capabilities of advanced large language models (LLMs) in the field of information extraction (IE), specifically focusing on tasks related to named entity recognition (NER) and relation extraction (RE). Although researchers are exploring the use of few-shot information extraction through in-context learning with LLMs, they tend to focus only on using correct or positive examples for demonstration, neglecting the potential value of incorporating incorrect or negative examples into the learning process. In this paper, we present c-ICL, a novel few-shot technique that leverages both correct and incorrect sample constructions to create in-context learning demonstrations. This approach enhances the ability of LLMs to extract entities and relations by utilizing prompts that incorporate not only the positive samples but also the reasoning behind them. This method allows for the identi
&lt;/p&gt;</description></item><item><title>EFUF&#26159;&#19968;&#31181;&#39640;&#25928;&#31934;&#32454;&#21270;&#21435;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#28040;&#38500;&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#29289;&#20307;&#24187;&#35273;&#65292;&#24182;&#19981;&#38656;&#35201;&#20154;&#24037;&#27880;&#37322;&#37197;&#23545;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2402.09801</link><description>&lt;p&gt;
EFUF: &#39640;&#25928;&#31934;&#32454;&#21270;&#21435;&#23398;&#20064;&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#20013;&#20943;&#36731;&#24187;&#20687;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EFUF: Efficient Fine-grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09801
&lt;/p&gt;
&lt;p&gt;
EFUF&#26159;&#19968;&#31181;&#39640;&#25928;&#31934;&#32454;&#21270;&#21435;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#28040;&#38500;&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#29289;&#20307;&#24187;&#35273;&#65292;&#24182;&#19981;&#38656;&#35201;&#20154;&#24037;&#27880;&#37322;&#37197;&#23545;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;MLLMs&#65289;&#36817;&#24180;&#26469;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#20173;&#20250;&#29983;&#25104;&#21253;&#21547;&#22270;&#20687;&#20013;&#19981;&#23384;&#22312;&#30340;&#29289;&#20307;&#30340;&#25551;&#36848;&#65292;&#36825;&#31181;&#29616;&#35937;&#31216;&#20026;&#29289;&#20307;&#24187;&#35273;&#12290;&#20026;&#20102;&#28040;&#38500;&#24187;&#35273;&#65292;&#29616;&#26377;&#26041;&#27861;&#25163;&#21160;&#27880;&#37322;&#21253;&#21547;&#21644;&#19981;&#21253;&#21547;&#24187;&#35273;&#30340;&#37197;&#23545;&#21709;&#24212;&#65292;&#24182;&#37319;&#29992;&#21508;&#31181;&#23545;&#40784;&#31639;&#27861;&#26469;&#25552;&#39640;&#22270;&#20687;&#21644;&#25991;&#26412;&#20043;&#38388;&#30340;&#23545;&#40784;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#19981;&#20165;&#22312;&#24494;&#35843;&#38454;&#27573;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#65292;&#36824;&#38656;&#35201;&#26114;&#36149;&#30340;&#20154;&#24037;&#27880;&#37322;&#26469;&#26500;&#24314;&#23545;&#40784;&#31639;&#27861;&#25152;&#38656;&#30340;&#37197;&#23545;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#21435;&#23398;&#20064;&#30340;&#24605;&#24819;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31934;&#32454;&#21270;&#21435;&#23398;&#20064;&#26694;&#26550;&#65288;EFUF&#65289;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#37197;&#23545;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#28040;&#38500;&#24187;&#35273;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#25345;&#32493;&#20943;&#23569;&#24187;&#35273;&#21516;&#26102;&#20445;&#30041;&#20934;&#30830;&#30340;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09801v1 Announce Type: new  Abstract: Multimodal large language models (MLLMs) have attracted increasing attention in the past few years, but they may still generate descriptions that include objects not present in the corresponding images, a phenomenon known as object hallucination. To eliminate hallucinations, existing methods manually annotate paired responses with and without hallucinations, and then employ various alignment algorithms to improve the alignment capability between images and text. However, they not only demand considerable computation resources during the finetuning stage but also require expensive human annotation to construct paired data needed by the alignment algorithms. To address these issues, we borrow the idea of unlearning and propose an efficient fine-grained unlearning framework (EFUF), which can eliminate hallucinations without the need for paired data. Extensive experiments show that our method consistently reduces hallucinations while preserv
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#20998;&#27835;&#31243;&#24207;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#28041;&#21450;&#37325;&#22797;&#23376;&#20219;&#21153;&#21644;/&#25110;&#20855;&#26377;&#27450;&#39575;&#24615;&#20869;&#23481;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;LLM&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.05359</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#27835;&#31243;&#24207;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#38382;&#39064;&#27714;&#35299;&#36827;&#34892;&#24341;&#23548;
&lt;/p&gt;
&lt;p&gt;
Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05359
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#20998;&#27835;&#31243;&#24207;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#28041;&#21450;&#37325;&#22797;&#23376;&#20219;&#21153;&#21644;/&#25110;&#20855;&#26377;&#27450;&#39575;&#24615;&#20869;&#23481;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;LLM&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#30784;&#27169;&#22411;&#65292;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22240;&#20854;&#24191;&#27867;&#30340;&#24212;&#29992;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36866;&#24403;&#30340;&#25552;&#31034;&#35774;&#35745;&#65292;&#22914;&#24605;&#32500;&#38142;&#65292;&#21487;&#20197;&#37322;&#25918;LLM&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#24378;&#22823;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22788;&#29702;&#28041;&#21450;&#37325;&#22797;&#23376;&#20219;&#21153;&#21644;/&#25110;&#20855;&#26377;&#27450;&#39575;&#24615;&#20869;&#23481;&#30340;&#20219;&#21153;&#65288;&#22914;&#31639;&#26415;&#35745;&#31639;&#21644;&#25991;&#31456;&#32423;&#34394;&#20551;&#26032;&#38395;&#26816;&#27979;&#65289;&#65292;&#29616;&#26377;&#30340;&#25552;&#31034;&#31574;&#30053;&#35201;&#20040;&#34920;&#29616;&#20986;&#34920;&#36798;&#33021;&#21147;&#19981;&#36275;&#65292;&#35201;&#20040;&#30001;&#24187;&#35273;&#24341;&#21457;&#20013;&#38388;&#38169;&#35823;&#12290;&#20026;&#20102;&#20351;LLM&#23545;&#36825;&#20123;&#20013;&#38388;&#38169;&#35823;&#26356;&#20855;&#36776;&#21035;&#21147;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#20998;&#27835;&#31243;&#24207;&#24341;&#23548;LLM&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#30830;&#20445;&#20248;&#36234;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#20219;&#21153;&#20998;&#35299;&#12289;&#23376;&#20219;&#21153;&#35299;&#20915;&#21644;&#35299;&#20915;&#32452;&#35013;&#36807;&#31243;&#30340;&#20998;&#31163;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#21487;&#20197;&#24341;&#23548;LLM&#25193;&#23637;&#22266;&#23450;&#28145;&#24230;Transformer&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM's powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentangles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Transformer. Experiments indicate that our proposed method can achiev
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29983;&#25104;&#35299;&#37322;&#26694;&#26550;&#65288;xLLM&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33258;&#28982;&#35821;&#35328;&#26684;&#24335;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#12290;&#36890;&#36807;&#19968;&#20010;&#35780;&#20272;&#22120;&#26469;&#37327;&#21270;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20248;&#21270;&#36807;&#31243;&#26469;&#25552;&#39640;&#21487;&#20449;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.04678</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#21487;&#20449;&#30340;&#35299;&#37322;&#22120;
&lt;/p&gt;
&lt;p&gt;
Large Language Models As Faithful Explainers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04678
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29983;&#25104;&#35299;&#37322;&#26694;&#26550;&#65288;xLLM&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33258;&#28982;&#35821;&#35328;&#26684;&#24335;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#12290;&#36890;&#36807;&#19968;&#20010;&#35780;&#20272;&#22120;&#26469;&#37327;&#21270;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20248;&#21270;&#36807;&#31243;&#26469;&#25552;&#39640;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#36890;&#36807;&#21033;&#29992;&#20854;&#20016;&#23500;&#30340;&#20869;&#37096;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#24050;&#32463;&#33021;&#22815;&#29087;&#32451;&#35299;&#20915;&#22797;&#26434;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#22797;&#26434;&#24615;&#38459;&#30861;&#20102;&#20256;&#32479;&#30340;&#20197;&#36755;&#20837;&#20026;&#37325;&#28857;&#30340;&#35299;&#37322;&#31639;&#27861;&#26469;&#35299;&#37322;LLMs&#30340;&#22797;&#26434;&#20915;&#31574;&#36807;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26368;&#36817;&#20986;&#29616;&#20102;&#19968;&#31181;&#33258;&#25105;&#35299;&#37322;&#26426;&#21046;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#30340;&#24418;&#24335;&#36827;&#34892;&#21333;&#21521;&#25512;&#29702;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;LLMs&#39044;&#27979;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#32463;&#24120;&#22240;&#20026;&#32570;&#20047;&#21487;&#20449;&#24230;&#32780;&#21463;&#21040;&#25209;&#35780;&#65292;&#22240;&#20026;&#36825;&#20123;&#35299;&#37322;&#21487;&#33021;&#19981;&#20934;&#30830;&#22320;&#21453;&#26144;LLMs&#30340;&#20915;&#31574;&#34892;&#20026;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#29983;&#25104;&#35299;&#37322;&#26694;&#26550;xLLM&#65292;&#20197;&#25552;&#39640;LLMs&#33258;&#28982;&#35821;&#35328;&#26684;&#24335;&#30340;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;&#22120;&#26469;&#37327;&#21270;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#65292;&#24182;&#36890;&#36807;xLLM&#30340;&#36845;&#20195;&#20248;&#21270;&#36807;&#31243;&#26469;&#25552;&#39640;&#21487;&#20449;&#24230;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#31243;&#24230;&#22320;&#25552;&#39640;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have recently become proficient in addressing complex tasks by utilizing their rich internal knowledge and reasoning ability. Consequently, this complexity hinders traditional input-focused explanation algorithms for explaining the complex decision-making processes of LLMs. Recent advancements have thus emerged for self-explaining their predictions through a single feed-forward inference in a natural language format. However, natural language explanations are often criticized for lack of faithfulness since these explanations may not accurately reflect the decision-making behaviors of the LLMs. In this work, we introduce a generative explanation framework, xLLM, to improve the faithfulness of the explanations provided in natural language formats for LLMs. Specifically, we propose an evaluator to quantify the faithfulness of natural language explanation and enhance the faithfulness by an iterative optimization process of xLLM, with the goal of maximizing the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25216;&#33021;&#38598;&#20248;&#21270;&#65288;SSO&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#21644;&#23436;&#21892;&#21487;&#36716;&#31227;&#30340;&#25216;&#33021;&#38598;&#26469;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25552;&#21462;&#39640;&#22870;&#21169;&#30340;&#20849;&#21516;&#23376;&#36712;&#36857;&#65292;&#29983;&#25104;&#23376;&#30446;&#26631;&#21644;&#35828;&#26126;&#65292;&#24182;&#22312;&#19978;&#19979;&#25991;&#20013;&#25552;&#20379;&#32473;LLM&#28436;&#21592;&#65292;&#20197;&#24378;&#21270;&#34892;&#20026;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;SSO&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#33021;&#22815;&#20248;&#21270;&#25216;&#33021;&#38598;&#65292;&#24182;&#23454;&#29616;&#19978;&#19979;&#25991;&#31574;&#30053;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.03244</link><description>&lt;p&gt;
&#25216;&#33021;&#38598;&#20248;&#21270;&#65306;&#36890;&#36807;&#21487;&#36716;&#31227;&#25216;&#33021;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Skill Set Optimization: Reinforcing Language Model Behavior via Transferable Skills
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25216;&#33021;&#38598;&#20248;&#21270;&#65288;SSO&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#21644;&#23436;&#21892;&#21487;&#36716;&#31227;&#30340;&#25216;&#33021;&#38598;&#26469;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25552;&#21462;&#39640;&#22870;&#21169;&#30340;&#20849;&#21516;&#23376;&#36712;&#36857;&#65292;&#29983;&#25104;&#23376;&#30446;&#26631;&#21644;&#35828;&#26126;&#65292;&#24182;&#22312;&#19978;&#19979;&#25991;&#20013;&#25552;&#20379;&#32473;LLM&#28436;&#21592;&#65292;&#20197;&#24378;&#21270;&#34892;&#20026;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;SSO&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#33021;&#22815;&#20248;&#21270;&#25216;&#33021;&#38598;&#65292;&#24182;&#23454;&#29616;&#19978;&#19979;&#25991;&#31574;&#30053;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#34987;&#29992;&#20110;&#20132;&#20114;&#29615;&#22659;&#20013;&#30340;&#39034;&#24207;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#21033;&#29992;&#29615;&#22659;&#22870;&#21169;&#20449;&#21495;&#26469;&#19981;&#26029;&#25913;&#36827;LLM&#28436;&#21592;&#30340;&#34920;&#29616;&#24182;&#19981;&#31616;&#21333;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25216;&#33021;&#38598;&#20248;&#21270;&#65288;SSO&#65289;&#26469;&#36890;&#36807;&#26500;&#24314;&#21644;&#23436;&#21892;&#21487;&#36716;&#31227;&#25216;&#33021;&#38598;&#26469;&#25552;&#39640;LLM&#28436;&#21592;&#30340;&#24615;&#33021;&#12290;SSO&#36890;&#36807;&#25552;&#21462;&#20855;&#26377;&#39640;&#22870;&#21169;&#30340;&#20849;&#21516;&#23376;&#36712;&#36857;&#24182;&#29983;&#25104;&#23376;&#30446;&#26631;&#21644;&#35828;&#26126;&#26469;&#26500;&#24314;&#25216;&#33021;&#12290;&#36825;&#20123;&#25216;&#33021;&#22312;&#19978;&#19979;&#25991;&#20013;&#25552;&#20379;&#32473;LLM&#28436;&#21592;&#65292;&#20197;&#24378;&#21270;&#20855;&#26377;&#39640;&#22870;&#21169;&#30340;&#34892;&#20026;&#12290;&#28982;&#21518;&#65292;SSO&#36890;&#36807;&#20462;&#21098;&#19981;&#20877;&#20135;&#29983;&#39640;&#22870;&#21169;&#30340;&#25216;&#33021;&#26469;&#36827;&#19968;&#27493;&#23436;&#21892;&#25216;&#33021;&#38598;&#12290;&#25105;&#20204;&#22312;&#32463;&#20856;&#35270;&#39057;&#28216;&#25103;NetHack&#21644;&#25991;&#26412;&#29615;&#22659;ScienceWorld&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#23637;&#31034;SSO&#20248;&#21270;&#25216;&#33021;&#38598;&#24182;&#36827;&#34892;&#19978;&#19979;&#25991;&#31574;&#30053;&#25913;&#36827;&#30340;&#33021;&#21147;&#12290;&#22312;&#25105;&#20204;&#30340;&#33258;&#23450;&#20041;NetHack&#20219;&#21153;&#20013;&#65292;SSO&#30340;&#24615;&#33021;&#36229;&#36807;&#22522;&#20934;&#26041;&#27861;40%&#65292;&#24182;&#36229;&#36807;&#20102;&#20808;&#21069;&#30340;&#26368;&#26032;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have recently been used for sequential decision making in interactive environments. However, leveraging environment reward signals for continual LLM actor improvement is not straightforward. We propose Skill Set Optimization (SSO) for improving LLM actor performance through constructing and refining sets of transferable skills. SSO constructs skills by extracting common subtrajectories with high rewards and generating subgoals and instructions to represent each skill. These skills are provided to the LLM actor in-context to reinforce behaviors with high rewards. Then, SSO further refines the skill set by pruning skills that do not continue to result in high rewards. We evaluate our method in the classic videogame NetHack and the text environment ScienceWorld to demonstrate SSO's ability to optimize a set of skills and perform in-context policy improvement. SSO outperforms baselines by 40% in our custom NetHack task and outperforms the previous state-of-the-
&lt;/p&gt;</description></item><item><title>EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.03049</link><description>&lt;p&gt;
EasyInstruct&#65306;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03049
&lt;/p&gt;
&lt;p&gt;
EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#25351;&#20196;&#35843;&#25972;&#24050;&#32463;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24182;&#25104;&#20026;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#21147;&#30340;&#19968;&#31181;&#20851;&#38190;&#25216;&#26415;&#12290;&#20026;&#20102;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#25968;&#25454;&#25968;&#37327;&#21644;&#25968;&#25454;&#36136;&#37327;&#20043;&#38388;&#36798;&#21040;&#31934;&#24039;&#30340;&#24179;&#34913;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#20043;&#38388;&#20173;&#28982;&#23384;&#22312;&#19981;&#19968;&#33268;&#65292;&#30446;&#21069;&#27809;&#26377;&#26631;&#20934;&#30340;&#24320;&#28304;&#25351;&#20196;&#22788;&#29702;&#23454;&#29616;&#26694;&#26550;&#21487;&#20379;&#31038;&#21306;&#20351;&#29992;&#65292;&#36825;&#20351;&#24471;&#20174;&#19994;&#32773;&#26080;&#27861;&#36827;&#19968;&#27493;&#24320;&#21457;&#21644;&#25512;&#36827;&#12290;&#20026;&#20102;&#20419;&#36827;&#25351;&#20196;&#22788;&#29702;&#30340;&#30740;&#31350;&#21644;&#24320;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyInstruct&#65292;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;LLMs&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#23427;&#23558;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#27169;&#22359;&#21270;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#12290;EasyInstruct&#24050;&#32463;&#22312;https://github.com/zjunlp/EasyInstruct&#19978;&#20844;&#24320;&#21457;&#24067;&#65292;&#24182;&#24471;&#21040;&#20102;&#31215;&#26497;&#32500;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#31616;&#21333;&#30340;&#28145;&#24230;&#20462;&#21098;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#36895;&#24230;&#65292;&#22312;&#20869;&#23384;&#21463;&#38480;&#30340;&#26465;&#20214;&#19979;&#34920;&#29616;&#33391;&#22909;&#65292;&#23545;&#37096;&#32626;&#22312;&#26412;&#22320;&#21644;&#36793;&#32536;&#35774;&#22791;&#19978;&#30340;LLMs&#26377;&#24110;&#21161;&#12290;</title><link>https://arxiv.org/abs/2402.02834</link><description>&lt;p&gt;
&#31616;&#21270;&#30340;LLaMA: &#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#28145;&#24230;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Shortened LLaMA: A Simple Depth Pruning for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02834
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#31616;&#21333;&#30340;&#28145;&#24230;&#20462;&#21098;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#36895;&#24230;&#65292;&#22312;&#20869;&#23384;&#21463;&#38480;&#30340;&#26465;&#20214;&#19979;&#34920;&#29616;&#33391;&#22909;&#65292;&#23545;&#37096;&#32626;&#22312;&#26412;&#22320;&#21644;&#36793;&#32536;&#35774;&#22791;&#19978;&#30340;LLMs&#26377;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411; (LLMs) &#30340;&#32467;&#26500;&#21270;&#20462;&#21098;&#24050;&#25104;&#20026;&#38477;&#20302;&#20854;&#39640;&#35745;&#31639;&#38656;&#27714;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#23485;&#24230;&#20462;&#21098;&#20943;&#23567;&#25237;&#24433;&#26435;&#37325;&#30697;&#38453;&#30340;&#22823;&#23567; (&#20363;&#22914;&#36890;&#36807;&#21024;&#38500;&#27880;&#24847;&#21147;&#22836;)&#65292;&#21516;&#26102;&#20445;&#25345;&#23618;&#25968;&#19981;&#21464;&#12290;&#19982;&#27492;&#30456;&#21453;&#65292;&#28145;&#24230;&#20462;&#21098;&#21017;&#21024;&#38500;&#25972;&#20010;&#23618;&#25110;&#22359;&#65292;&#21516;&#26102;&#20445;&#25345;&#21097;&#20313;&#26435;&#37325;&#30340;&#22823;&#23567;&#19981;&#21464;&#12290;&#30446;&#21069;&#30340;&#22823;&#22810;&#25968;&#30740;&#31350;&#38598;&#20013;&#22312;&#23485;&#24230;&#20462;&#21098;&#25110;&#23485;&#24230;&#21644;&#28145;&#24230;&#20462;&#21098;&#30340;&#28151;&#21512;&#19978;&#65292;&#24456;&#23569;&#23545;&#20004;&#32773; (&#23485;&#24230;&#19982;&#28145;&#24230;) &#22312;&#23545;LLM&#25512;&#29702;&#25928;&#29575;&#30340;&#24433;&#21709;&#26041;&#38754;&#36827;&#34892;&#27604;&#36739;&#20998;&#26512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#28145;&#24230;&#20462;&#21098;&#26041;&#27861;&#21487;&#20197;&#19982;&#26368;&#26032;&#30340;&#23485;&#24230;&#20462;&#21098;&#26041;&#27861;&#22312;&#38646;-shot&#20219;&#21153;&#24615;&#33021;&#26041;&#38754;&#31454;&#20105;&#12290;&#25105;&#20204;&#30340;&#20462;&#21098;&#26041;&#27861;&#25552;&#39640;&#20102;&#25512;&#29702;&#36895;&#24230;&#65292;&#29305;&#21035;&#26159;&#22312;&#20869;&#23384;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#38656;&#35201;&#23545;&#36816;&#34892;LLMs&#36827;&#34892;&#26377;&#38480;&#25209;&#27425;&#22823;&#23567;&#30340;&#26465;&#20214;&#65292;&#27492;&#26102;&#23485;&#24230;&#20462;&#21098;&#26080;&#25928;&#12290;&#25105;&#20204;&#24076;&#26395;&#36825;&#39033;&#24037;&#20316;&#33021;&#22815;&#24110;&#21161;&#23558;LLMs&#37096;&#32626;&#22312;&#26412;&#22320;&#21644;&#36793;&#32536;&#35774;&#22791;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structured pruning of modern large language models (LLMs) has emerged as a way of decreasing their high computational needs. Width pruning reduces the size of projection weight matrices (e.g., by removing attention heads) while maintaining the number of layers. Depth pruning, in contrast, removes entire layers or blocks, while keeping the size of the remaining weights unchanged. Most current research focuses on either width-only or a blend of width and depth pruning, with little comparative analysis between the two units (width vs. depth) concerning their impact on LLM inference efficiency. In this work, we show that a simple depth pruning approach can compete with recent width pruning methods in terms of zero-shot task performance. Our pruning method boosts inference speeds, especially under memory-constrained conditions that require limited batch sizes for running LLMs, where width pruning is ineffective. We hope this work can help deploy LLMs on local and edge devices.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Adversarial In-Context Learning (adv-ICL)&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#22120;&#12289;&#37492;&#21035;&#22120;&#21644;&#25552;&#31034;&#20462;&#25913;&#22120;&#20043;&#38388;&#30340;&#23545;&#25239;&#23398;&#20064;&#20248;&#21270;&#25552;&#31034;&#65292;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#21462;&#24471;&#26174;&#30528;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2312.02614</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#23398;&#20064;&#20248;&#21270;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Prompt Optimization via Adversarial In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02614
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Adversarial In-Context Learning (adv-ICL)&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#22120;&#12289;&#37492;&#21035;&#22120;&#21644;&#25552;&#31034;&#20462;&#25913;&#22120;&#20043;&#38388;&#30340;&#23545;&#25239;&#23398;&#20064;&#20248;&#21270;&#25552;&#31034;&#65292;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#21462;&#24471;&#26174;&#30528;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;Adversarial In-Context Learning&#65288;adv-ICL&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#19968;&#20010;LLM&#20316;&#20026;&#29983;&#25104;&#22120;&#65292;&#21478;&#19968;&#20010;&#20316;&#20026;&#37492;&#21035;&#22120;&#65292;&#31532;&#19977;&#20010;&#20316;&#20026;&#25552;&#31034;&#20462;&#25913;&#22120;&#65292;&#26469;&#20248;&#21270;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#30340;&#25552;&#31034;&#12290;&#31867;&#20284;&#20110;&#20256;&#32479;&#30340;&#23545;&#25239;&#24615;&#23398;&#20064;&#65292;adv-ICL&#34987;&#23454;&#29616;&#20026;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#20043;&#38388;&#30340;&#21452;&#20154;&#21338;&#24328;&#65292;&#20854;&#20013;&#29983;&#25104;&#22120;&#35797;&#22270;&#29983;&#25104;&#36275;&#22815;&#36924;&#30495;&#30340;&#36755;&#20986;&#20197;&#27450;&#39575;&#37492;&#21035;&#22120;&#12290; &#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#32473;&#23450;&#30001;&#20219;&#21153;&#35828;&#26126;&#21069;&#32512;&#21644;&#20960;&#20010;&#31034;&#20363;&#32452;&#25104;&#30340;&#36755;&#20837;&#65292;&#29983;&#25104;&#22120;&#20135;&#29983;&#19968;&#20010;&#36755;&#20986;&#12290;&#28982;&#21518;&#65292;&#37492;&#21035;&#22120;&#36127;&#36131;&#23558;&#29983;&#25104;&#22120;&#30340;&#36755;&#20837;-&#36755;&#20986;&#23545;&#20998;&#31867;&#20026;&#27169;&#22411;&#29983;&#25104;&#30340;&#36824;&#26159;&#30495;&#23454;&#25968;&#25454;&#12290;&#26681;&#25454;&#37492;&#21035;&#22120;&#25439;&#22833;&#65292;&#25552;&#31034;&#20462;&#25913;&#22120;&#25552;&#20986;&#20102;&#21487;&#33021;&#23545;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#25552;&#31034;&#36827;&#34892;&#30340;&#32534;&#36753;&#65292;&#24182;&#36873;&#25321;&#26368;&#22823;&#31243;&#24230;&#25913;&#21892;&#23545;&#25239;&#25439;&#22833;&#30340;&#32534;&#36753;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;adv-ICL&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#25552;&#31034;&#20248;&#21270;&#26377;&#26174;&#30528;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02614v2 Announce Type: replace-cross  Abstract: We propose a new method, Adversarial In-Context Learning (adv-ICL), to optimize prompt for in-context learning (ICL) by employing one LLM as a generator, another as a discriminator, and a third as a prompt modifier. As in traditional adversarial learning, adv-ICL is implemented as a two-player game between the generator and discriminator, where the generator tries to generate realistic enough output to fool the discriminator. In each round, given an input prefixed by task instructions and several exemplars, the generator produces an output. The discriminator is then tasked with classifying the generator input-output pair as model-generated or real data. Based on the discriminator loss, the prompt modifier proposes possible edits to the generator and discriminator prompts, and the edits that most improve the adversarial loss are selected. We show that adv-ICL results in significant improvements over state-of-the-art prompt optim
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#26816;&#27979;&#21644;&#25277;&#35937;&#65292;&#26412;&#30740;&#31350;&#38477;&#20302;&#20102;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#25552;&#20986;&#20102;&#33258;&#25105;&#25259;&#38706;&#25277;&#35937;&#30340;&#20219;&#21153;&#65292;&#24182;&#25506;&#32034;&#20102;&#22810;&#31181;&#24494;&#35843;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2311.09538</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#38477;&#20302;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30340;&#38544;&#31169;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Reducing Privacy Risks in Online Self-Disclosures with Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09538
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#26816;&#27979;&#21644;&#25277;&#35937;&#65292;&#26412;&#30740;&#31350;&#38477;&#20302;&#20102;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#25552;&#20986;&#20102;&#33258;&#25105;&#25259;&#38706;&#25277;&#35937;&#30340;&#20219;&#21153;&#65292;&#24182;&#25506;&#32034;&#20102;&#22810;&#31181;&#24494;&#35843;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#25259;&#38706;&#22312;&#31038;&#20132;&#23186;&#20307;&#20114;&#21160;&#20013;&#26082;&#26222;&#36941;&#21448;&#26377;&#22238;&#25253;&#65292;&#20294;&#20063;&#23384;&#22312;&#38544;&#31169;&#39118;&#38505;&#12290;&#26412;&#25991;&#36890;&#36807;&#26816;&#27979;&#21644;&#25277;&#35937;&#20027;&#21160;&#20445;&#25252;&#19982;&#22312;&#32447;&#33258;&#25105;&#25259;&#38706;&#30456;&#20851;&#30340;&#29992;&#25143;&#38544;&#31169;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#21253;&#21547;4.8K&#20010;&#26631;&#27880;&#25259;&#38706;&#27573;&#30340;19&#31181;&#33258;&#25105;&#25259;&#38706;&#31867;&#21035;&#30340;&#20998;&#31867;&#27861;&#12290;&#28982;&#21518;&#20026;&#26816;&#27979;&#24494;&#35843;&#20102;&#19968;&#20010;&#35821;&#35328;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;65%&#20197;&#19978;&#30340;&#23616;&#37096;&#36328;&#24230;F$_1$&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36827;&#34892;&#20102;&#19968;&#39033;&#20154;&#26426;&#20132;&#20114;&#29992;&#25143;&#30740;&#31350;&#65292;82%&#30340;&#21442;&#19982;&#32773;&#23545;&#35813;&#27169;&#22411;&#25345;&#31215;&#26497;&#24577;&#24230;&#65292;&#31361;&#20986;&#20102;&#20854;&#23454;&#38469;&#24212;&#29992;&#24615;&#12290;&#22312;&#29992;&#25143;&#21453;&#39304;&#30340;&#25512;&#21160;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#25105;&#25259;&#38706;&#25277;&#35937;&#30340;&#20219;&#21153;&#65292;&#21363;&#23558;&#25259;&#38706;&#37325;&#36848;&#20026;&#19981;&#22826;&#20855;&#20307;&#30340;&#26415;&#35821;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#23454;&#29992;&#24615;&#65292;&#20363;&#22914;&#23558;"Im 16F"&#37325;&#36848;&#20026;"I'm a teenage girl"&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#21508;&#31181;&#24494;&#35843;&#31574;&#30053;&#65292;&#25105;&#20204;&#30340;&#26368;&#20339;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#19981;&#21516;&#30340;&#25277;&#35937;&#65292;&#20174;&#32780;&#36866;&#24230;&#20943;&#23569;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09538v2 Announce Type: replace  Abstract: Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure categories and curate a large corpus consisting of 4.8K annotated disclosure spans. We then fine-tune a language model for detection, achieving over 65% partial span F$_1$. We further conduct an HCI user study, with 82% of participants viewing the model positively, highlighting its real-world applicability. Motivated by the user feedback, we introduce the task of self-disclosure abstraction, which is paraphrasing disclosures into less specific terms while preserving their utility, e.g., "Im 16F" to "I'm a teenage girl". We explore various fine-tuning strategies, and our best model can generate diverse abstractions that moderately reduce privacy 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#25506;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#31038;&#20250;&#20559;&#35265;&#30340;&#21407;&#21019;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#19968;&#33324;&#20851;&#32852;&#21644;&#31038;&#20250;&#31867;&#21035;&#12289;&#36523;&#20221;&#20197;&#21450;&#21051;&#26495;&#21360;&#35937;&#30340;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2311.09090</link><description>&lt;p&gt;
&#31038;&#20250;&#20559;&#35265;&#25506;&#27979;&#65306;&#35821;&#35328;&#27169;&#22411;&#30340;&#20844;&#24179;&#22522;&#20934;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Social Bias Probing: Fairness Benchmarking for Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#25506;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#31038;&#20250;&#20559;&#35265;&#30340;&#21407;&#21019;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#19968;&#33324;&#20851;&#32852;&#21644;&#31038;&#20250;&#31867;&#21035;&#12289;&#36523;&#20221;&#20197;&#21450;&#21051;&#26495;&#21360;&#35937;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#34987;&#35777;&#26126;&#32534;&#30721;&#20102;&#21508;&#31181;&#31038;&#20250;&#20559;&#35265;&#65292;&#36825;&#24102;&#26469;&#20102;&#19979;&#28216;&#39118;&#38505;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#25506;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#31038;&#20250;&#20559;&#35265;&#30340;&#21407;&#21019;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#35821;&#35328;&#27169;&#22411;&#30340;&#19968;&#33324;&#20851;&#32852;&#20197;&#21450;&#31038;&#20250;&#31867;&#21035;&#12289;&#36523;&#20221;&#21644;&#21051;&#26495;&#21360;&#35937;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09090v2 Announce Type: replace  Abstract: Large language models have been shown to encode a variety of social biases, which carries the risk of downstream harms. While the impact of these biases has been recognized, prior methods for bias evaluation have been limited to binary association tests on small datasets, offering a constrained view of the nature of societal biases within language models. In this paper, we propose an original framework for probing language models for societal biases. We collect a probing dataset to analyze language models' general associations, as well as along the axes of societal categories, identities, and stereotypes. To this end, we leverage a novel perplexity-based fairness score. We curate a large-scale benchmarking dataset addressing drawbacks and limitations of existing fairness collections, expanding to a variety of different identities and stereotypes. When comparing our methodology with prior work, we demonstrate that biases within langua
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#37327;&#21270;&#25351;&#26631;&#26469;&#34913;&#37327;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#35299;&#37322;&#30340;&#21487;&#20449;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#26469;&#25913;&#21892;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#35299;&#37322;&#30340;&#19968;&#33268;&#24615;&#21644;&#20445;&#30495;&#24230;&#12290;</title><link>https://arxiv.org/abs/2310.04910</link><description>&lt;p&gt;
&#20851;&#20110;&#24120;&#35782;&#25512;&#29702;&#30340;&#30693;&#35782;&#22270;&#35889;&#35299;&#37322;&#30340;&#21487;&#20449;&#24615;
&lt;/p&gt;
&lt;p&gt;
Faithful Knowledge Graph Explanations for Commonsense Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.04910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#37327;&#21270;&#25351;&#26631;&#26469;&#34913;&#37327;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#35299;&#37322;&#30340;&#21487;&#20449;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#26469;&#25913;&#21892;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#35299;&#37322;&#30340;&#19968;&#33268;&#24615;&#21644;&#20445;&#30495;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34701;&#21512;&#35821;&#35328;&#27169;&#22411;(LMs)&#21644;&#30693;&#35782;&#22270;&#35889;(KGs)&#24050;&#25104;&#20026;&#24120;&#35782;&#38382;&#31572;&#30740;&#31350;&#20013;&#30340;&#24120;&#35265;&#26041;&#27861;&#65292;&#20294;&#22312;&#36825;&#20123;&#27169;&#22411;&#20013;&#23454;&#29616;&#31934;&#30830;&#30340;&#24605;&#36335;&#38142;&#35299;&#37322;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#24403;&#21069;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#35299;&#37322;&#25216;&#26415;&#30340;&#19968;&#20010;&#20027;&#35201;&#24369;&#28857;&#26159;&#22312;&#35780;&#20272;&#36807;&#31243;&#20013;&#24573;&#35270;&#20102;&#29983;&#25104;&#35299;&#37322;&#30340;&#21487;&#20449;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#39564;&#35777;&#20102;&#20004;&#20010;&#37327;&#21270;&#25351;&#26631; - &#22270;&#19968;&#33268;&#24615;&#21644;&#22270;&#20445;&#30495;&#24230; - &#26469;&#34913;&#37327;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#35299;&#37322;&#30340;&#21487;&#20449;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;Consistent GNN (CGNN)&#65292;&#35813;&#26041;&#27861;&#28155;&#21152;&#20102;&#19968;&#39033;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#39033;&#26469;&#25913;&#21892;&#35299;&#37322;&#30340;&#21487;&#20449;&#24230;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;KG&#30340;&#39044;&#27979;&#32463;&#24120;&#20559;&#31163;&#21407;&#22987;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#25152;&#25552;&#20986;&#30340;CGNN&#26041;&#27861;&#25552;&#39640;&#20102;&#19968;&#33268;&#24615;&#21644;&#20445;&#30495;&#24230;&#65292;&#23637;&#31034;&#20102;&#23427;&#20135;&#29983;&#26356;&#21487;&#20449;&#35299;&#37322;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#26126;&#30830;&#35780;&#20272;&#35299;&#37322;&#21487;&#20449;&#24615;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While fusing language models (LMs) and knowledge graphs (KGs) has become common in commonsense question answering research, enabling faithful chain-of-thought explanations in these models remains an open problem. One major weakness of current KG-based explanation techniques is that they overlook the faithfulness of generated explanations during evaluation. To address this gap, we make two main contributions: (1) We propose and validate two quantitative metrics - graph consistency and graph fidelity - to measure the faithfulness of KG-based explanations. (2) We introduce Consistent GNN (CGNN), a novel training method that adds a consistency regularization term to improve explanation faithfulness. Our analysis shows that predictions from KG often diverge from original model predictions. The proposed CGNN approach boosts consistency and fidelity, demonstrating its potential for producing more faithful explanations. Our work emphasises the importance of explicitly evaluating suggest a path
&lt;/p&gt;</description></item><item><title>EasyEdit&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;&#65292;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#25130;&#26029;&#25110;&#35884;&#35823;&#38382;&#39064;&#65292;&#25903;&#25345;&#21508;&#31181;&#26368;&#26032;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#22810;&#20010;&#30693;&#21517;&#30340;LLMs&#12290;</title><link>https://arxiv.org/abs/2308.07269</link><description>&lt;p&gt;
EasyEdit&#65306;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2308.07269
&lt;/p&gt;
&lt;p&gt;
EasyEdit&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;&#65292;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#25130;&#26029;&#25110;&#35884;&#35823;&#38382;&#39064;&#65292;&#25903;&#25345;&#21508;&#31181;&#26368;&#26032;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#22810;&#20010;&#30693;&#21517;&#30340;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#24120;&#36973;&#21463;&#30693;&#35782;&#25130;&#26029;&#25110;&#35884;&#35823;&#38382;&#39064;&#65292;&#36825;&#24847;&#21619;&#30528;&#23427;&#20204;&#23545;&#26410;&#35265;&#20107;&#20214;&#19981;&#30693;&#24773;&#25110;&#29983;&#25104;&#20855;&#26377;&#19981;&#27491;&#30830;&#20107;&#23454;&#30340;&#25991;&#26412;&#65292;&#21407;&#22240;&#26159;&#25968;&#25454;&#36807;&#26102;/&#22024;&#26434;&#12290;&#20026;&#27492;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#38024;&#23545;LLMs&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#26088;&#22312;&#24494;&#22937;&#22320;&#27880;&#20837;/&#32534;&#36753;&#26356;&#26032;&#30340;&#30693;&#35782;&#25110;&#35843;&#25972;&#19981;&#33391;&#34892;&#20026;&#65292;&#21516;&#26102;&#23558;&#23545;&#19981;&#30456;&#20851;&#36755;&#20837;&#30340;&#24433;&#21709;&#26368;&#23567;&#21270;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#20197;&#21450;&#20219;&#21153;&#35774;&#32622;&#20013;&#30340;&#21464;&#21270;&#65292;&#31038;&#21306;&#20013;&#27809;&#26377;&#21487;&#29992;&#20110;&#30693;&#35782;&#32534;&#36753;&#30340;&#26631;&#20934;&#23454;&#26045;&#26694;&#26550;&#65292;&#36825;&#22952;&#30861;&#20102;&#20174;&#19994;&#32773;&#23558;&#30693;&#35782;&#32534;&#36753;&#24212;&#29992;&#20110;&#24212;&#29992;&#31243;&#24207;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyEdit&#65292;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;LLMs&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;&#12290;&#23427;&#25903;&#25345;&#21508;&#31181;&#23574;&#31471;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#24182;&#21487;&#20197;&#36731;&#26494;&#24212;&#29992;&#20110;&#35768;&#22810;&#33879;&#21517;&#30340;LLMs&#65292;&#22914;T5&#12289;GPT-J&#12289;LlaMA&#31561;&#12290;&#20174;&#32463;&#39564;&#19978;&#26469;&#30475;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;kno
&lt;/p&gt;
&lt;p&gt;
arXiv:2308.07269v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy issues, which means they are unaware of unseen events or generate text with incorrect facts owing to outdated/noisy data. To this end, many knowledge editing approaches for LLMs have emerged -- aiming to subtly inject/edit updated knowledge or adjust undesired behavior while minimizing the impact on unrelated inputs. Nevertheless, due to significant differences among various knowledge editing methods and the variations in task setups, there is no standard implementation framework available for the community, which hinders practitioners from applying knowledge editing to applications. To address these issues, we propose EasyEdit, an easy-to-use knowledge editing framework for LLMs. It supports various cutting-edge knowledge editing approaches and can be readily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc. Empirically, we report the kno
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35843;&#30740;&#20102;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#23545;&#20110;&#30701;&#25991;&#26412;&#21644;&#36328;&#35821;&#35328;&#25991;&#26723;&#31561;&#21508;&#31181;&#22330;&#26223;&#25552;&#20379;&#20102;&#31995;&#32479;&#24615;&#30340;&#32452;&#32455;&#21644;&#20171;&#32461;&#65292;&#24182;&#35752;&#35770;&#20102;&#24191;&#27867;&#24212;&#29992;&#30340;&#19968;&#31995;&#21015;&#28909;&#38376;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15351</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#32508;&#36848;&#65306;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A Survey on Neural Topic Models: Methods, Applications, and Challenges. (arXiv:2401.15351v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15351
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35843;&#30740;&#20102;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#23545;&#20110;&#30701;&#25991;&#26412;&#21644;&#36328;&#35821;&#35328;&#25991;&#26723;&#31561;&#21508;&#31181;&#22330;&#26223;&#25552;&#20379;&#20102;&#31995;&#32479;&#24615;&#30340;&#32452;&#32455;&#21644;&#20171;&#32461;&#65292;&#24182;&#35752;&#35770;&#20102;&#24191;&#27867;&#24212;&#29992;&#30340;&#19968;&#31995;&#21015;&#28909;&#38376;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#39064;&#27169;&#22411;&#20960;&#21313;&#24180;&#26469;&#19968;&#30452;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#26080;&#30417;&#30563;&#26041;&#24335;&#19979;&#21457;&#29616;&#28508;&#22312;&#20027;&#39064;&#21644;&#25512;&#26029;&#25991;&#26723;&#30340;&#20027;&#39064;&#27604;&#20363;&#12290;&#23427;&#20204;&#22312;&#25991;&#26412;&#20998;&#26512;&#21644;&#19978;&#19979;&#25991;&#25512;&#33616;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#36817;&#24180;&#26469;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#23835;&#36215;&#20419;&#25104;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#39046;&#22495;&#8212;&#8212;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;(NTMs)&#30340;&#20986;&#29616;&#12290;&#19982;&#20256;&#32479;&#30340;&#20027;&#39064;&#27169;&#22411;&#19981;&#21516;&#65292;NTMs&#30452;&#25509;&#20248;&#21270;&#21442;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#27169;&#22411;&#29305;&#23450;&#30340;&#25512;&#23548;&#12290;&#36825;&#20351;&#24471;NTMs&#20855;&#26377;&#26356;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#28789;&#27963;&#24615;&#65292;&#21560;&#24341;&#20102;&#22823;&#37327;&#30340;&#30740;&#31350;&#20851;&#27880;&#24182;&#20135;&#29983;&#20102;&#20016;&#23500;&#30340;&#26032;&#26041;&#27861;&#21644;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#30740;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26681;&#25454;&#32593;&#32476;&#32467;&#26500;&#31995;&#32479;&#22320;&#32452;&#32455;&#20102;&#24403;&#21069;NTM&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#38024;&#23545;&#30701;&#25991;&#26412;&#21644;&#36328;&#35821;&#35328;&#25991;&#26723;&#31561;&#21508;&#31181;&#22330;&#26223;&#30340;NTMs&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#24191;&#27867;&#24212;&#29992;&#30340;&#19968;&#31995;&#21015;&#28909;&#38376;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topic models have been prevalent for decades to discover latent topics and infer topic proportions of documents in an unsupervised fashion. They have been widely used in various applications like text analysis and context recommendation. Recently, the rise of neural networks has facilitated the emergence of a new research field -- Neural Topic Models (NTMs). Different from conventional topic models, NTMs directly optimize parameters without requiring model-specific derivations. This endows NTMs with better scalability and flexibility, resulting in significant research attention and plentiful new methods and applications. In this paper, we present a comprehensive survey on neural topic models concerning methods, applications, and challenges. Specifically, we systematically organize current NTM methods according to their network structures and introduce the NTMs for various scenarios like short texts and cross-lingual documents. We also discuss a wide range of popular applications built 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#32599;&#39532;&#21270;&#24418;&#24335;&#30340;&#25991;&#26412;&#20316;&#20026;&#25509;&#21475;&#65292;&#26377;&#25928;&#22320;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#21360;&#22320;&#35821;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#32599;&#39532;&#21270;&#25991;&#26412;&#19981;&#20165;&#25552;&#39640;&#20102;&#25512;&#29702;&#25928;&#29575;&#65292;&#36824;&#22312;&#26377;&#38480;&#30340;&#39044;&#35757;&#32451;&#19979;&#23454;&#29616;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#32599;&#39532;&#21270;&#26377;&#28508;&#21147;&#24357;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20013;&#30340;&#35821;&#35328;&#38556;&#30861;&#12290;</title><link>http://arxiv.org/abs/2401.14280</link><description>&lt;p&gt;
RomanSetu: &#36890;&#36807;&#32599;&#39532;&#21270;&#26377;&#25928;&#22320;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization. (arXiv:2401.14280v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#32599;&#39532;&#21270;&#24418;&#24335;&#30340;&#25991;&#26412;&#20316;&#20026;&#25509;&#21475;&#65292;&#26377;&#25928;&#22320;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#21360;&#22320;&#35821;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#32599;&#39532;&#21270;&#25991;&#26412;&#19981;&#20165;&#25552;&#39640;&#20102;&#25512;&#29702;&#25928;&#29575;&#65292;&#36824;&#22312;&#26377;&#38480;&#30340;&#39044;&#35757;&#32451;&#19979;&#23454;&#29616;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#32599;&#39532;&#21270;&#26377;&#28508;&#21147;&#24357;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20013;&#30340;&#35821;&#35328;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25193;&#23637;&#21040;&#38750;&#33521;&#35821;&#35821;&#35328;&#65288;&#29305;&#21035;&#26159;&#20351;&#29992;&#38750;&#25289;&#19969;&#23383;&#27597;&#34920;&#30340;&#35821;&#35328;&#65289;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#32599;&#39532;&#21270;&#24418;&#24335;&#30340;&#25991;&#26412;&#20316;&#20026;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25509;&#21475;&#65292;&#20551;&#35774;&#39057;&#32321;&#30340;&#38750;&#27491;&#24335;&#20351;&#29992;&#21644;&#19982;&#33521;&#35821;&#20849;&#20139;&#30340;&#26631;&#35760;&#26377;&#21161;&#20110;&#36328;&#35821;&#35328;&#23545;&#40784;&#12290;&#25105;&#20204;&#20197;&#21360;&#22320;&#35821;&#20026;&#37325;&#28857;&#65292;&#36890;&#36807;&#21360;&#22320;&#35821;&#21040;&#33521;&#35821;&#30340;&#32763;&#35793;&#21644;&#24773;&#24863;&#20998;&#26512;&#20219;&#21153;&#65292;&#35777;&#26126;&#32599;&#39532;&#21270;&#25991;&#26412;&#19981;&#20165;&#30001;&#20110;&#20854;&#36739;&#20302;&#30340;&#29983;&#20135;&#21147;&#32780;&#26174;&#33879;&#25913;&#21892;&#20102;&#25512;&#29702;&#25928;&#29575;&#65292;&#36824;&#22312;&#26377;&#38480;&#30340;&#39044;&#35757;&#32451;&#20013;&#23454;&#29616;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26032;&#39062;&#30340;&#22810;&#33050;&#26412;&#25552;&#31034;&#26041;&#27861;&#32467;&#21512;&#20102;&#32599;&#39532;&#21270;&#21644;&#21407;&#29983;&#25991;&#26412;&#65292;&#22312;&#36827;&#19968;&#27493;&#25552;&#39640;&#20219;&#21153;&#24615;&#33021;&#26041;&#38754;&#26174;&#31034;&#20986;&#28508;&#21147;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#32599;&#39532;&#21270;&#22312;&#24357;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20013;&#30340;&#35821;&#35328;&#38556;&#30861;&#26041;&#38754;&#20855;&#26377;&#28508;&#21147;&#65292;&#26410;&#26469;&#30340;&#24037;&#20316;&#23558;&#33268;&#21147;&#20110;&#23558;&#27492;&#26041;&#27861;&#25193;&#23637;&#21040;&#26356;&#22810;&#30340;&#35821;&#35328;&#21644;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study addresses the challenge of extending Large Language Models (LLMs) to non-English languages, specifically those using non-Latin scripts. We propose an innovative approach that utilizes the romanized form of text as an interface for LLMs, hypothesizing that its frequent informal use and shared tokens with English enhance cross-lingual alignment. Focusing on Hindi, we demonstrate through Hindi-to-English translation and sentiment analysis tasks that romanized text not only significantly improves inference efficiency due to its lower fertility compared to native text but also achieves competitive performance with limited pre-training. Additionally, our novel multi-script prompting approach, which combines romanized and native texts, shows promise in further enhancing task performance. These findings suggest the potential of romanization in bridging the language gap for LLM applications, with future work aimed at expanding this approach to more languages and tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#25512;&#29702;&#27493;&#38271;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#22312;&#25552;&#31034;&#20013;&#22686;&#21152;&#25512;&#29702;&#27493;&#39588;&#33021;&#26174;&#33879;&#25552;&#39640;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#32780;&#20943;&#23569;&#25512;&#29702;&#27493;&#39588;&#21017;&#20250;&#38477;&#20302;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.04925</link><description>&lt;p&gt;
&#25512;&#29702;&#27493;&#38271;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#25512;&#29702;&#27493;&#38271;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#22312;&#25552;&#31034;&#20013;&#22686;&#21152;&#25512;&#29702;&#27493;&#39588;&#33021;&#26174;&#33879;&#25552;&#39640;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#32780;&#20943;&#23569;&#25512;&#29702;&#27493;&#39588;&#21017;&#20250;&#38477;&#20302;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24605;&#32500;&#38142;&#26465;&#65288;CoT&#65289;&#23545;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#20855;&#26377;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;CoT&#30340;&#26377;&#25928;&#24615;&#19982;&#25552;&#31034;&#20013;&#25512;&#29702;&#27493;&#39588;&#30340;&#38271;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#20026;&#20102;&#25581;&#31034;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#20010;&#23454;&#35777;&#23454;&#39564;&#26469;&#25506;&#32034;&#36825;&#20123;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20123;&#23454;&#39564;&#65292;&#25193;&#23637;&#21644;&#21387;&#32553;CoT&#28436;&#31034;&#20013;&#30340;&#21512;&#29702;&#25512;&#29702;&#27493;&#39588;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#20182;&#22240;&#32032;&#19981;&#21464;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#20197;&#19979;&#20027;&#35201;&#21457;&#29616;&#12290;&#39318;&#20808;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#25552;&#31034;&#20013;&#24310;&#38271;&#25512;&#29702;&#27493;&#39588;&#65292;&#21363;&#20351;&#27809;&#26377;&#21521;&#25552;&#31034;&#20013;&#28155;&#21152;&#26032;&#20449;&#24687;&#65292;&#20063;&#20250;&#26174;&#33879;&#25552;&#39640;LLM&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#30456;&#21453;&#65292;&#32553;&#30701;&#25512;&#29702;&#27493;&#39588;&#65292;&#21363;&#20351;&#20445;&#30041;&#20851;&#38190;&#20449;&#24687;&#65292;&#20063;&#20250;&#26174;&#33879;&#38477;&#20302;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#36825;&#19968;&#21457;&#29616;&#31361;&#26174;&#20102;CoT&#25552;&#31034;&#20013;&#27493;&#39588;&#25968;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#38469;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make 
&lt;/p&gt;</description></item><item><title>LAMPAT&#26159;&#31532;&#19968;&#20010;&#26080;&#30417;&#30563;&#30340;&#22810;&#35821;&#35328;&#25913;&#20889;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#25239;&#35757;&#32451;&#65292;&#23427;&#33021;&#22815;&#22312;&#27809;&#26377;&#24179;&#34892;&#35821;&#26009;&#24211;&#30340;&#35821;&#35328;&#29615;&#22659;&#19979;&#29983;&#25104;&#25913;&#20889;&#12290;</title><link>http://arxiv.org/abs/2401.04348</link><description>&lt;p&gt;
LAMPAT&#65306;&#20351;&#29992;&#23545;&#25239;&#35757;&#32451;&#36827;&#34892;&#20302;&#31209;&#22810;&#35821;&#35328;&#25913;&#20889;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
LAMPAT: Low-Rank Adaption for Multilingual Paraphrasing Using Adversarial Training. (arXiv:2401.04348v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04348
&lt;/p&gt;
&lt;p&gt;
LAMPAT&#26159;&#31532;&#19968;&#20010;&#26080;&#30417;&#30563;&#30340;&#22810;&#35821;&#35328;&#25913;&#20889;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#25239;&#35757;&#32451;&#65292;&#23427;&#33021;&#22815;&#22312;&#27809;&#26377;&#24179;&#34892;&#35821;&#26009;&#24211;&#30340;&#35821;&#35328;&#29615;&#22659;&#19979;&#29983;&#25104;&#25913;&#20889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25913;&#20889;&#26159;&#25351;&#20351;&#29992;&#19981;&#21516;&#30340;&#35789;&#35821;&#25110;&#21477;&#23376;&#32467;&#26500;&#26469;&#20256;&#36798;&#30456;&#21516;&#21547;&#20041;&#30340;&#25991;&#26412;&#12290;&#23427;&#21487;&#20197;&#29992;&#20316;&#33258;&#21160;&#25968;&#25454;&#22686;&#24378;&#24037;&#20855;&#65292;&#29305;&#21035;&#26159;&#22312;&#22788;&#29702;&#25968;&#25454;&#19981;&#36275;&#30340;&#20302;&#36164;&#28304;&#35821;&#35328;&#26102;&#12290;&#20026;&#20102;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#29983;&#25104;&#25913;&#20889;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#21033;&#29992;&#20102;&#26426;&#22120;&#32763;&#35793;&#39046;&#22495;&#30340;&#30693;&#35782;&#65292;&#36890;&#36807;&#22312;&#30456;&#21516;&#35821;&#35328;&#20013;&#36827;&#34892;&#38646;&#26679;&#26412;&#26426;&#22120;&#32763;&#35793;&#26469;&#24418;&#25104;&#25913;&#20889;&#12290;&#23613;&#31649;&#22312;&#20154;&#24037;&#35780;&#20272;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38656;&#35201;&#24179;&#34892;&#32763;&#35793;&#25968;&#25454;&#38598;&#65292;&#22240;&#27492;&#26080;&#27861;&#24212;&#29992;&#20110;&#27809;&#26377;&#24179;&#34892;&#35821;&#26009;&#24211;&#30340;&#35821;&#35328;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#26080;&#30417;&#30563;&#30340;&#22810;&#35821;&#35328;&#25913;&#20889;&#27169;&#22411;&#65292;LAMPAT&#65288;&#20302;&#31209;&#22810;&#35821;&#35328;&#25913;&#20889;&#30340;&#36866;&#24212;&#24615;&#20302;&#31209;&#22810;&#35821;&#35328;&#25913;&#20889;&#27169;&#22411;&#65289;&#65292;&#20854;&#20013;&#21333;&#35821;&#25968;&#25454;&#38598;&#24050;&#32463;&#36275;&#22815;&#12290;
&lt;/p&gt;
&lt;p&gt;
Paraphrases are texts that convey the same meaning while using different words or sentence structures. It can be used as an automatic data augmentation tool for many Natural Language Processing tasks, especially when dealing with low-resource languages, where data shortage is a significant problem. To generate a paraphrase in multilingual settings, previous studies have leveraged the knowledge from the machine translation field, i.e., forming a paraphrase through zero-shot machine translation in the same language. Despite good performance on human evaluation, those methods still require parallel translation datasets, thus making them inapplicable to languages that do not have parallel corpora. To mitigate that problem, we proposed the first unsupervised multilingual paraphrasing model, LAMPAT ($\textbf{L}$ow-rank $\textbf{A}$daptation for $\textbf{M}$ultilingual $\textbf{P}$araphrasing using $\textbf{A}$dversarial $\textbf{T}$raining), by which monolingual dataset is sufficient enough 
&lt;/p&gt;</description></item><item><title>AST-T5&#26159;&#19968;&#31181;&#32467;&#26500;&#24863;&#30693;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#25277;&#35937;&#35821;&#27861;&#26641;&#65288;AST&#65289;&#26469;&#22686;&#24378;&#20195;&#30721;&#29983;&#25104;&#12289;&#36716;&#25442;&#21644;&#29702;&#35299;&#30340;&#33021;&#21147;&#12290;&#23427;&#20248;&#20110;&#20854;&#20182;&#21516;&#31561;&#22823;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#22312;&#20195;&#30721;&#21040;&#20195;&#30721;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2401.03003</link><description>&lt;p&gt;
AST-T5&#65306;&#38754;&#21521;&#20195;&#30721;&#29983;&#25104;&#21644;&#29702;&#35299;&#30340;&#32467;&#26500;&#24863;&#30693;&#39044;&#35757;&#32451;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
AST-T5: Structure-Aware Pretraining for Code Generation and Understanding. (arXiv:2401.03003v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03003
&lt;/p&gt;
&lt;p&gt;
AST-T5&#26159;&#19968;&#31181;&#32467;&#26500;&#24863;&#30693;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#25277;&#35937;&#35821;&#27861;&#26641;&#65288;AST&#65289;&#26469;&#22686;&#24378;&#20195;&#30721;&#29983;&#25104;&#12289;&#36716;&#25442;&#21644;&#29702;&#35299;&#30340;&#33021;&#21147;&#12290;&#23427;&#20248;&#20110;&#20854;&#20182;&#21516;&#31561;&#22823;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#22312;&#20195;&#30721;&#21040;&#20195;&#30721;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20195;&#30721;&#30456;&#20851;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#28982;&#32780;&#35768;&#22810;&#27169;&#22411;&#23558;&#20195;&#30721;&#35270;&#20026;&#31616;&#21333;&#24207;&#21015;&#65292;&#24573;&#30053;&#20102;&#20854;&#32467;&#26500;&#21270;&#29305;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;AST-T5&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#33539;&#24335;&#65292;&#21033;&#29992;&#25277;&#35937;&#35821;&#27861;&#26641;&#65288;AST&#65289;&#22686;&#24378;&#20102;&#20195;&#30721;&#29983;&#25104;&#12289;&#36716;&#25442;&#21644;&#29702;&#35299;&#12290;&#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#65292;&#25105;&#20204;&#30340;AST&#24863;&#30693;&#20998;&#21106;&#20445;&#30041;&#20102;&#20195;&#30721;&#32467;&#26500;&#65292;&#32780;AST&#24863;&#30693;&#36328;&#24230;&#30772;&#22351;&#30446;&#26631;&#20351;&#27169;&#22411;&#33021;&#22815;&#37325;&#24314;&#21508;&#31181;&#20195;&#30721;&#32467;&#26500;&#12290;&#19982;&#20854;&#20182;&#27169;&#22411;&#19981;&#21516;&#65292;AST-T5&#36991;&#20813;&#20102;&#22797;&#26434;&#30340;&#31243;&#24207;&#20998;&#26512;&#25110;&#26550;&#26500;&#26356;&#25913;&#65292;&#22240;&#27492;&#21487;&#20197;&#19982;&#20219;&#20309;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;Transformer&#26080;&#32541;&#38598;&#25104;&#12290;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;AST-T5&#22312;&#21508;&#31181;&#20195;&#30721;&#30456;&#20851;&#20219;&#21153;&#20013;&#22987;&#32456;&#20248;&#20110;&#21516;&#31561;&#22823;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#12290;&#32467;&#26500;&#24863;&#30693;&#20351;&#24471;AST-T5&#22312;&#20195;&#30721;&#21040;&#20195;&#30721;&#20219;&#21153;&#20013;&#29305;&#21035;&#24378;&#22823;&#65292;&#22312;Bugs2Fix&#20219;&#21153;&#30340;&#31934;&#30830;&#21305;&#37197;&#24471;&#20998;&#19978;&#36229;&#36807;CodeT5 2&#20010;&#28857;&#65292;&#24182;&#22312;CodeXGLUE&#20013;&#30340;Java-C#&#36716;&#25442;&#20219;&#21153;&#30340;&#31934;&#30830;&#21305;&#37197;&#24471;&#20998;&#19978;&#36229;&#36807;CodeT5 3&#20010;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have made significant advancements in code-related tasks, yet many LLMs treat code as simple sequences, neglecting its structured nature. We introduce AST-T5, a novel pretraining paradigm that leverages the Abstract Syntax Tree (AST) for enhanced code generation, transpilation, and understanding. Using dynamic programming, our AST-Aware Segmentation retains code structure, while our AST-Aware Span Corruption objective equips the model to reconstruct various code structures. Unlike other models, AST-T5 avoids intricate program analyses or architectural changes, so it integrates seamlessly with any encoder-decoder Transformer. Evaluations show that AST-T5 consistently outperforms similar-sized LMs across various code-related tasks. Structure-awareness makes AST-T5 particularly powerful in code-to-code tasks, surpassing CodeT5 by 2 points in exact match score for the Bugs2Fix task and by 3 points in exact match score for Java-C# Transpilation in CodeXGLUE. Our
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;&#31034;&#33539;&#36873;&#25321;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38646;&#26679;&#26412;&#38142;&#24335;&#24605;&#32500;&#25512;&#29702;&#26469;&#36873;&#25321;&#19982;&#27979;&#35797;&#26679;&#26412;&#19981;&#21516;&#20294;&#20173;&#19982;&#20043;&#24378;&#30456;&#20851;&#30340;&#31034;&#33539;&#20316;&#20026;&#23398;&#20064;&#30340;&#19978;&#19979;&#25991;&#12290;</title><link>http://arxiv.org/abs/2310.09881</link><description>&lt;p&gt;
&#22522;&#20110;&#36845;&#20195;&#31034;&#33539;&#36873;&#25321;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
In-Context Learning with Iterative Demonstration Selection. (arXiv:2310.09881v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09881
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;&#31034;&#33539;&#36873;&#25321;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38646;&#26679;&#26412;&#38142;&#24335;&#24605;&#32500;&#25512;&#29702;&#26469;&#36873;&#25321;&#19982;&#27979;&#35797;&#26679;&#26412;&#19981;&#21516;&#20294;&#20173;&#19982;&#20043;&#24378;&#30456;&#20851;&#30340;&#31034;&#33539;&#20316;&#20026;&#23398;&#20064;&#30340;&#19978;&#19979;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#35268;&#27169;&#30340;&#36827;&#23637;&#30340;&#25512;&#21160;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#36890;&#36807;&#19978;&#19979;&#25991;&#23398;&#20064;(ICL)&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;ICL&#30340;&#24615;&#33021;&#24050;&#34987;&#35777;&#26126;&#23545;&#20110;&#31034;&#33539;&#30340;&#36873;&#25321;&#38750;&#24120;&#25935;&#24863;&#12290;&#36873;&#25321;&#26368;&#21512;&#36866;&#30340;&#31034;&#33539;&#20316;&#20026;&#19978;&#19979;&#25991;&#20173;&#28982;&#26159;&#19968;&#20010;&#25345;&#32493;&#25361;&#25112;&#21644;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#25991;&#29486;&#24050;&#32463;&#24378;&#35843;&#20102;&#36873;&#25321;&#37027;&#20123;&#19982;&#27979;&#35797;&#26679;&#26412;&#19981;&#21516;&#25110;&#35821;&#20041;&#30456;&#20284;&#24615;&#30340;&#31034;&#33539;&#30340;&#37325;&#35201;&#24615;&#65292;&#32780;&#24573;&#35270;&#20102;&#26368;&#20248;&#31034;&#33539;&#36873;&#25321;&#32500;&#24230;&#26159;&#20219;&#21153;&#29305;&#23450;&#30340;&#20107;&#23454;&#12290;&#20511;&#37492;&#20004;&#20010;&#32500;&#24230;&#30340;&#20248;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36845;&#20195;&#31034;&#33539;&#36873;&#25321;(IDS)&#12290;&#20351;&#29992;&#38646;&#26679;&#26412;&#38142;&#24335;&#24605;&#32500;&#25512;&#29702;(Zero-shot-CoT)&#65292;IDS&#36845;&#20195;&#22320;&#36873;&#25321;&#37027;&#20123;&#19982;&#27979;&#35797;&#26679;&#26412;&#19981;&#21516;&#20294;&#20173;&#19982;&#20043;&#24378;&#30456;&#20851;&#30340;&#31034;&#33539;&#20316;&#20026;ICL&#30340;&#31034;&#33539;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;IDS&#22312;&#31034;&#33539;&#36873;&#25321;&#20043;&#21069;&#23558;Zero-shot-CoT&#24212;&#29992;&#20110;&#27979;&#35797;&#26679;&#26412;&#12290;&#36755;&#20986;&#30340;&#25512;&#29702;&#36335;&#24452;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Spurred by advancements in scale, large language models (LLMs) have demonstrated strong few-shot learning ability via in-context learning (ICL). However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as context remains an ongoing challenge and an open problem. Existing literature has highlighted the importance of selecting examples that are diverse or semantically similar to the test sample while ignoring the fact that the optimal selection dimension, i.e., diversity or similarity, is task-specific. Leveraging the merits of both dimensions, we propose Iterative Demonstration Selection (IDS). Using zero-shot chain-of-thought reasoning (Zero-shot-CoT), IDS iteratively selects examples that are diverse but still strongly correlated with the test sample as ICL demonstrations. Specifically, IDS applies Zero-shot-CoT to the test sample before demonstration selection. The output reasoning path is 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#25506;&#27979;&#22120;&#21644;&#36716;&#25442;&#22120;&#20248;&#21270;&#25351;&#20196;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.02905</link><description>&lt;p&gt;
&#20351;&#29992;&#24744;&#30340;&#26412;&#33021;&#65306;&#20351;&#29992;&#31070;&#32463;&#25506;&#27979;&#22120;&#19982;&#36716;&#25442;&#22120;&#36827;&#34892;&#25351;&#20196;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers. (arXiv:2310.02905v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02905
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#25506;&#27979;&#22120;&#21644;&#36716;&#25442;&#22120;&#20248;&#21270;&#25351;&#20196;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#25351;&#20196;&#36319;&#38543;&#33021;&#21147;&#65292;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;LLMs&#30340;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#32473;&#20104;&#23427;&#20204;&#30340;&#25351;&#20196;&#65292;&#36825;&#20123;&#25351;&#20196;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#20154;&#21147;&#36827;&#34892;&#25163;&#21160;&#35843;&#25972;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20351;&#29992;&#20102;&#39640;&#25928;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#31639;&#27861;&#26469;&#33258;&#21160;&#20248;&#21270;&#32473;&#20104;&#40657;&#30418;LLMs&#30340;&#25351;&#20196;&#12290;&#28982;&#32780;&#65292;&#22312;&#20248;&#21270;&#39640;&#24230;&#22797;&#26434;&#65288;&#20363;&#22914;&#39640;&#32500;&#65289;&#30340;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#22914;&#23558;&#25351;&#20196;&#26144;&#23556;&#21040;LLM&#24615;&#33021;&#30340;&#20989;&#25968;&#65292;BO&#36890;&#24120;&#34920;&#29616;&#19981;&#20339;&#12290;&#36825;&#20027;&#35201;&#26159;&#30001;&#20110;BO&#20351;&#29992;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#26377;&#38480;&#65292;&#35813;&#27169;&#22411;&#34987;&#29992;&#20316;BO&#30340;&#20195;&#29702;&#26469;&#24314;&#27169;&#30446;&#26631;&#20989;&#25968;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#24050;&#32463;&#22810;&#27425;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#65288;NNs&#65289;&#65292;&#23588;&#20854;&#26159;&#39044;&#35757;&#32451;&#30340;&#36716;&#25442;&#22120;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#21487;&#20197;&#24314;&#27169;&#39640;&#24230;&#22797;&#26434;&#30340;&#20989;&#25968;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#31070;&#32463;&#25506;&#27979;&#22120;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown remarkable instruction-following capabilities and achieved impressive performances in various applications. However, the performances of LLMs depend heavily on the instructions given to them, which are typically manually tuned with substantial human efforts. Recent work has used the query-efficient Bayesian optimization (BO) algorithm to automatically optimize the instructions given to black-box LLMs. However, BO usually falls short when optimizing highly sophisticated (e.g., high-dimensional) objective functions, such as the functions mapping an instruction to the performance of an LLM. This is mainly due to the limited expressive power of the Gaussian process (GP) model which is used by BO as a surrogate to model the objective function. Meanwhile, it has been repeatedly shown that neural networks (NNs), especially pre-trained transformers, possess strong expressive power and can model highly complex functions. So, we adopt a neural bandit algor
&lt;/p&gt;</description></item><item><title>ReConcile&#26159;&#19968;&#20010;&#36890;&#36807;&#22810;&#36718;&#35752;&#35770;&#21644;&#25237;&#31080;&#26426;&#21046;&#26469;&#22686;&#24378;LLM&#25512;&#29702;&#33021;&#21147;&#30340;&#22810;&#27169;&#22411;&#22810;&#20195;&#29702;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2309.13007</link><description>&lt;p&gt;
ReConcile&#65306;&#22278;&#26700;&#20250;&#35758;&#36890;&#36807;&#22810;&#20803;LLM&#30340;&#20849;&#35782;&#25913;&#36827;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs. (arXiv:2309.13007v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13007
&lt;/p&gt;
&lt;p&gt;
ReConcile&#26159;&#19968;&#20010;&#36890;&#36807;&#22810;&#36718;&#35752;&#35770;&#21644;&#25237;&#31080;&#26426;&#21046;&#26469;&#22686;&#24378;LLM&#25512;&#29702;&#33021;&#21147;&#30340;&#22810;&#27169;&#22411;&#22810;&#20195;&#29702;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20173;&#28982;&#22312;&#22797;&#26434;&#30340;&#25512;&#29702;&#20219;&#21153;&#19978;&#36935;&#21040;&#22256;&#38590;&#12290;&#21463;&#21040;&#24515;&#26234;&#31038;&#20250;&#29702;&#35770;&#65288;Minsky, 1988&#65289;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ReConcile&#65292;&#36825;&#26159;&#19968;&#20010;&#22810;&#27169;&#22411;&#22810;&#20195;&#29702;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22810;&#26679;&#30340;LLM&#20195;&#29702;&#20154;&#20043;&#38388;&#30340;&#22278;&#26700;&#20250;&#35758;&#26469;&#20419;&#36827;&#22810;&#26679;&#30340;&#24605;&#24819;&#21644;&#35752;&#35770;&#65292;&#20174;&#32780;&#25913;&#36827;&#19968;&#33268;&#24615;&#12290;ReConcile&#36890;&#36807;&#36827;&#34892;&#22810;&#36718;&#35752;&#35770;&#12289;&#23398;&#20064;&#35828;&#26381;&#20854;&#20182;&#20195;&#29702;&#20154;&#25913;&#36827;&#31572;&#26696;&#20197;&#21450;&#37319;&#29992;&#32622;&#20449;&#24230;&#21152;&#26435;&#25237;&#31080;&#26426;&#21046;&#26469;&#22686;&#24378;LLM&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;ReConcile&#36890;&#36807;&#8220;&#35752;&#35770;&#25552;&#31034;&#8221;&#26469;&#21551;&#21160;&#20195;&#29702;&#20154;&#38388;&#30340;&#35752;&#35770;&#65292;&#20854;&#20013;&#21253;&#25324;&#19978;&#19968;&#36718;&#27599;&#20010;&#20195;&#29702;&#20154;&#29983;&#25104;&#30340;&#31572;&#26696;&#21644;&#35299;&#37322;&#30340;&#20998;&#32452;&#12289;&#23427;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#20197;&#21450;&#29992;&#20110;&#35828;&#26381;&#20854;&#20182;&#20195;&#29702;&#20154;&#30340;&#31572;&#26696;&#20462;&#27491;&#20154;&#31867;&#35299;&#37322;&#30340;&#28436;&#31034;&#12290;&#36825;&#20010;&#35752;&#35770;&#25552;&#31034;&#20351;&#27599;&#20010;&#20195;&#29702;&#20154;&#33021;&#22815;&#26681;&#25454;&#20854;&#20182;&#20195;&#29702;&#20154;&#30340;&#35265;&#35299;&#20462;&#35746;&#33258;&#24049;&#30340;&#22238;&#31572;&#12290;&#19968;&#26086;&#36798;&#25104;&#19968;&#33268;&#24182;&#32467;&#26463;&#35752;&#35770;&#65292;ReConcile&#25191;&#34892;&#19968;&#27425;&#20840;&#20307;&#25237;&#31080;&#20197;&#30830;&#23450;&#26368;&#32456;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) still struggle with complex reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents to foster diverse thoughts and discussion for improved consensus. ReConcile enhances the reasoning capabilities of LLMs by holding multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their uncertainties, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. This discussion prompt enables each agent to revise their responses in light of insights from other agents. Once a consensus is reached and the discussion ends, ReConcil
&lt;/p&gt;</description></item><item><title>LMDX&#26159;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26723;&#20449;&#24687;&#25552;&#21462;&#19982;&#23450;&#20301;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#24067;&#23616;&#32534;&#30721;&#21644;&#31572;&#26696;&#34394;&#26500;&#30340;&#22256;&#38590;&#65292;&#33021;&#22815;&#22312;&#21322;&#32467;&#26500;&#21270;&#25991;&#26723;&#20013;&#25552;&#21462;&#20851;&#38190;&#23454;&#20307;&#12290;</title><link>http://arxiv.org/abs/2309.10952</link><description>&lt;p&gt;
LMDX&#65306;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26723;&#20449;&#24687;&#25552;&#21462;&#19982;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
LMDX: Language Model-based Document Information Extraction and Localization. (arXiv:2309.10952v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10952
&lt;/p&gt;
&lt;p&gt;
LMDX&#26159;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26723;&#20449;&#24687;&#25552;&#21462;&#19982;&#23450;&#20301;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#24067;&#23616;&#32534;&#30721;&#21644;&#31572;&#26696;&#34394;&#26500;&#30340;&#22256;&#38590;&#65292;&#33021;&#22815;&#22312;&#21322;&#32467;&#26500;&#21270;&#25991;&#26723;&#20013;&#25552;&#21462;&#20851;&#38190;&#23454;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#65292;&#25913;&#36827;&#20102;&#35768;&#22810;&#29616;&#26377;&#20219;&#21153;&#30340;&#26368;&#26032;&#25216;&#26415;&#65292;&#24182;&#23637;&#31034;&#20102;&#26032;&#20852;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLM&#23578;&#26410;&#25104;&#21151;&#24212;&#29992;&#20110;&#21322;&#32467;&#26500;&#21270;&#25991;&#26723;&#20449;&#24687;&#25552;&#21462;&#65292;&#36825;&#26159;&#35768;&#22810;&#25991;&#26723;&#22788;&#29702;&#24037;&#20316;&#27969;&#30340;&#26680;&#24515;&#65292;&#21253;&#25324;&#20174;&#35270;&#35273;&#20016;&#23500;&#30340;&#25991;&#26723;&#65288;VRD&#65289;&#20013;&#25552;&#21462;&#20851;&#38190;&#23454;&#20307;&#65292;&#32473;&#23450;&#39044;&#23450;&#20041;&#30340;&#30446;&#26631;&#27169;&#24335;&#12290;LLM&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;LLM&#20013;&#32570;&#20047;&#24067;&#23616;&#32534;&#30721;&#65292;&#36825;&#23545;&#20110;&#39640;&#36136;&#37327;&#30340;&#25552;&#21462;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#21450;&#32570;&#20047;&#19968;&#20010;&#22522;&#20110;&#29702;&#35770;&#30340;&#26426;&#21046;&#65292;&#30830;&#20445;&#31572;&#26696;&#19981;&#26159;&#34394;&#26500;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26723;&#20449;&#24687;&#25552;&#21462;&#19982;&#23450;&#20301;&#65288;LMDX&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#20219;&#24847;LLM&#36866;&#24212;&#25991;&#26723;&#20449;&#24687;&#25552;&#21462;&#12290;LMDX&#21487;&#20197;&#25552;&#21462;&#21333;&#19968;&#12289;&#37325;&#22797;&#21644;&#23618;&#27425;&#32467;&#26500;&#23454;&#20307;&#65292;&#26080;&#35770;&#26159;&#21542;&#26377;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#22522;&#20110;&#29702;&#35770;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art on many existing tasks and exhibiting emergent capabilities. However, LLMs have not yet been successfully applied on semi-structured document information extraction, which is at the core of many document processing workflows and consists of extracting key entities from a visually rich document (VRD) given a predefined target schema. The main obstacles to LLM adoption in that task have been the absence of layout encoding within LLMs, critical for a high quality extraction, and the lack of a grounding mechanism ensuring the answer is not hallucinated. In this paper, we introduce Language Model-based Document Information Extraction and Localization (LMDX), a methodology to adapt arbitrary LLMs for document information extraction. LMDX can do extraction of singular, repeated, and hierarchical entities, both with and without training data, while providing grounding guarantees and lo
&lt;/p&gt;</description></item><item><title>SafetyBench&#26159;&#19968;&#20010;&#20840;&#38754;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#12290;&#23427;&#21253;&#25324;&#20102;11,435&#20010;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;7&#20010;&#19981;&#21516;&#30340;&#23433;&#20840;&#38382;&#39064;&#31867;&#21035;&#65292;&#24182;&#19988;&#36824;&#25552;&#20379;&#20013;&#33521;&#25991;&#25968;&#25454;&#12290;&#36890;&#36807;&#23545;25&#20010;&#28909;&#38376;&#20013;&#33521;&#25991;LLM&#36827;&#34892;&#27979;&#35797;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-4&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#20294;&#24403;&#21069;LLM&#30340;&#23433;&#20840;&#24615;&#20173;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.07045</link><description>&lt;p&gt;
SafetyBench: &#29992;&#22810;&#39033;&#36873;&#25321;&#39064;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;
&lt;/p&gt;
&lt;p&gt;
SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions. (arXiv:2309.07045v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07045
&lt;/p&gt;
&lt;p&gt;
SafetyBench&#26159;&#19968;&#20010;&#20840;&#38754;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#12290;&#23427;&#21253;&#25324;&#20102;11,435&#20010;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;7&#20010;&#19981;&#21516;&#30340;&#23433;&#20840;&#38382;&#39064;&#31867;&#21035;&#65292;&#24182;&#19988;&#36824;&#25552;&#20379;&#20013;&#33521;&#25991;&#25968;&#25454;&#12290;&#36890;&#36807;&#23545;25&#20010;&#28909;&#38376;&#20013;&#33521;&#25991;LLM&#36827;&#34892;&#27979;&#35797;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-4&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#20294;&#24403;&#21069;LLM&#30340;&#23433;&#20840;&#24615;&#20173;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#23427;&#20204;&#30340;&#23433;&#20840;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#35780;&#20272;LLM&#30340;&#23433;&#20840;&#24615;&#24050;&#25104;&#20026;&#20419;&#36827;&#20854;&#24191;&#27867;&#24212;&#29992;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#20840;&#38754;&#30340;&#23433;&#20840;&#35780;&#20272;&#22522;&#20934;&#26126;&#26174;&#38459;&#30861;&#20102;&#23545;LLM&#23433;&#20840;&#24615;&#30340;&#26377;&#25928;&#35780;&#20272;&#21644;&#25552;&#21319;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SafetyBench&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#23433;&#20840;&#24615;&#30340;&#20840;&#38754;&#22522;&#20934;&#65292;&#21253;&#25324;11,435&#20010;&#19981;&#21516;&#30340;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;7&#20010;&#19981;&#21516;&#30340;&#23433;&#20840;&#38382;&#39064;&#31867;&#21035;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;SafetyBench&#36824;&#21253;&#25324;&#20013;&#33521;&#25991;&#25968;&#25454;&#65292;&#26041;&#20415;&#20004;&#31181;&#35821;&#35328;&#30340;&#35780;&#20272;&#12290;&#25105;&#20204;&#22312;25&#20010;&#28909;&#38376;&#20013;&#33521;&#25991;LLM&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27979;&#35797;&#65292;&#21253;&#25324;&#38646;-shot&#21644;&#23569;-shot&#35774;&#32622;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;GPT-4&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#24182;&#19988;&#24403;&#21069;LLM&#30340;&#23433;&#20840;&#24615;&#36824;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We believe Saf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#20851;&#31995;&#25277;&#21462;&#39046;&#22495;&#30340;&#24212;&#29992;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#35752;&#35770;&#20102;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#24212;&#23545;&#30340;&#25216;&#26415;&#65292;&#24182;&#23637;&#26395;&#20102;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2306.02051</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#20851;&#31995;&#25277;&#21462;&#39046;&#22495;&#30340;&#32508;&#36848;&#65306;&#26368;&#26032;&#36827;&#23637;&#19982;&#26032;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Survey on Deep Learning for Relation Extraction: Recent Advances and New Frontiers. (arXiv:2306.02051v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#20851;&#31995;&#25277;&#21462;&#39046;&#22495;&#30340;&#24212;&#29992;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#35752;&#35770;&#20102;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#24212;&#23545;&#30340;&#25216;&#26415;&#65292;&#24182;&#23637;&#26395;&#20102;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#31995;&#25277;&#21462;&#26159;&#25351;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#35782;&#21035;&#23454;&#20307;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20851;&#31995;&#25277;&#21462;&#26159;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#30340;&#22522;&#30784;&#65292;&#20363;&#22914;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#12289;&#38382;&#31572;&#21644;&#20449;&#24687;&#26816;&#32034;&#12290;&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20851;&#31995;&#25277;&#21462;&#39046;&#22495;&#21344;&#25454;&#20102;&#20027;&#23548;&#22320;&#20301;&#65292;&#24182;&#21462;&#24471;&#20102;&#26174;&#30528;&#36827;&#23637;&#12290;&#38543;&#21518;&#65292;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#23558;&#20851;&#31995;&#25277;&#21462;&#30340;&#26368;&#26032;&#25216;&#26415;&#25512;&#21521;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#24230;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#29616;&#26377;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20851;&#31995;&#25277;&#21462;&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20851;&#31995;&#25277;&#21462;&#36164;&#28304;&#65292;&#21253;&#25324;&#20851;&#31995;&#25277;&#21462;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#20174;&#25991;&#26412;&#34920;&#31034;&#12289;&#19978;&#19979;&#25991;&#32534;&#30721;&#21644;&#19977;&#20803;&#32452;&#39044;&#27979;&#19977;&#20010;&#26041;&#38754;&#23545;&#29616;&#26377;&#24037;&#20316;&#36827;&#34892;&#20998;&#31867;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20851;&#31995;&#25277;&#21462;&#38754;&#20020;&#30340;&#19968;&#20123;&#37325;&#35201;&#25361;&#25112;&#65292;&#24182;&#24635;&#32467;&#20102;&#21487;&#33021;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#25216;&#26415;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#19968;&#20123;&#20855;&#26377;&#28508;&#22312;&#21069;&#26223;&#30340;&#26410;&#26469;&#26041;&#21521;&#21644;&#23637;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relation extraction (RE) involves identifying the relations between entities from unstructured texts. RE serves as the foundation for many natural language processing (NLP) applications, such as knowledge graph completion, question answering, and information retrieval. In recent years, deep neural networks have dominated the field of RE and made noticeable progress. Subsequently, the large pre-trained language models (PLMs) have taken the state-of-the-art of RE to a new level. This survey provides a comprehensive review of existing deep learning techniques for RE. First, we introduce RE resources, including RE datasets and evaluation metrics. Second, we propose a new taxonomy to categorize existing works from three perspectives (text representation, context encoding, and triplet prediction). Third, we discuss several important challenges faced by RE and summarize potential techniques to tackle these challenges. Finally, we outline some promising future directions and prospects in this 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102; Mix Prompt Tuning&#65288;MPT&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25163;&#21160;&#25552;&#31034;&#27169;&#26495;&#19982;&#33258;&#21160;&#23398;&#20064;&#30340;&#36830;&#32493;&#25552;&#31034;&#27169;&#26495;&#30456;&#32467;&#21512;&#65292;&#25552;&#39640;&#22810;&#31890;&#24230;&#23398;&#26415;&#21151;&#33021;&#35782;&#21035;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#24182;&#20943;&#36731;&#23545;&#27880;&#37322;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;</title><link>http://arxiv.org/abs/2305.03287</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#20010;&#25552;&#31034;&#30693;&#35782;&#30340;&#20302;&#36164;&#28304;&#22810;&#31890;&#24230;&#23398;&#26415;&#21151;&#33021;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Low-Resource Multi-Granularity Academic Function Recognition Based on Multiple Prompt Knowledge. (arXiv:2305.03287v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102; Mix Prompt Tuning&#65288;MPT&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25163;&#21160;&#25552;&#31034;&#27169;&#26495;&#19982;&#33258;&#21160;&#23398;&#20064;&#30340;&#36830;&#32493;&#25552;&#31034;&#27169;&#26495;&#30456;&#32467;&#21512;&#65292;&#25552;&#39640;&#22810;&#31890;&#24230;&#23398;&#26415;&#21151;&#33021;&#35782;&#21035;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#24182;&#20943;&#36731;&#23545;&#27880;&#37322;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#39046;&#22495;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#65292;Fine-tuning &#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;&#22914; SciBERT&#65292;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#27880;&#37322;&#25968;&#25454;&#25165;&#33021;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#33719;&#21462;&#31185;&#23398; NLP &#20219;&#21153;&#30340; fine-tune &#25968;&#25454;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#21644;&#26114;&#36149;&#24615;&#12290;&#21463;&#25552;&#31034;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#21551;&#21457;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102; Mix Prompt Tuning&#65288;MPT&#65289;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#36731;&#23545;&#27880;&#37322;&#25968;&#25454;&#30340;&#20381;&#36182;&#65292;&#24182;&#20351;&#29992;&#24456;&#23569;&#25968;&#37327;&#30340;&#26631;&#35760;&#31034;&#20363;&#25552;&#39640;&#22810;&#31890;&#24230;&#23398;&#26415;&#21151;&#33021;&#35782;&#21035;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#23558;&#25163;&#21160;&#25552;&#31034;&#27169;&#26495;&#19982;&#33258;&#21160;&#23398;&#20064;&#30340;&#36830;&#32493;&#25552;&#31034;&#27169;&#26495;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#22810;&#26041;&#38754;&#30340;&#34920;&#31034;&#65292;&#20197;&#24110;&#21161;&#32473;&#23450;&#30340;&#23398;&#26415;&#21151;&#33021;&#35782;&#21035;&#20219;&#21153;&#20805;&#20998;&#21033;&#29992; PLMs &#20013;&#30340;&#30693;&#35782;&#12290;&#22522;&#20110;&#36825;&#20123;&#25552;&#31034;&#27169;&#26495;&#21644; fine-tuned PLM&#65292;&#22823;&#37327;&#30340;&#20266;&#26631;&#31614;&#34987;&#20998;&#37197;&#32473;&#26410;&#26631;&#35760;&#30340;&#23454;&#20363;&#65292;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning pre-trained language models (PLMs), e.g., SciBERT, generally requires large numbers of annotated data to achieve state-of-the-art performance on a range of NLP tasks in the scientific domain. However, obtaining the fine-tune data for scientific NLP task is still challenging and expensive. Inspired by recent advancement in prompt learning, in this paper, we propose the Mix Prompt Tuning (MPT), which is a semi-supervised method to alleviate the dependence on annotated data and improve the performance of multi-granularity academic function recognition tasks with a small number of labeled examples. Specifically, the proposed method provides multi-perspective representations by combining manual prompt templates with automatically learned continuous prompt templates to help the given academic function recognition task take full advantage of knowledge in PLMs. Based on these prompt templates and the fine-tuned PLM, a large number of pseudo labels are assigned to the unlabeled exam
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CLIPPINGS&#30340;&#22810;&#27169;&#24577;&#26694;&#26550;&#65292;&#29992;&#20110;&#35760;&#24405;&#38142;&#25509;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#23545;&#31216;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#32534;&#30721;&#22120;&#65292;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#30456;&#36817;&#25110;&#19981;&#21516;&#31867;&#21035;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#20010;&#24212;&#29992;&#22330;&#26223;&#65292;&#22914;&#26500;&#24314;&#20840;&#38754;&#30340;&#34917;&#20805;&#19987;&#21033;&#27880;&#20876;&#34920;&#21644;&#35782;&#21035;&#19981;&#21516;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#30340;&#20010;&#20154;&#12290;</title><link>http://arxiv.org/abs/2304.03464</link><description>&lt;p&gt;
&#29992;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#36830;&#25509;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Linking Representations with Multimodal Contrastive Learning. (arXiv:2304.03464v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CLIPPINGS&#30340;&#22810;&#27169;&#24577;&#26694;&#26550;&#65292;&#29992;&#20110;&#35760;&#24405;&#38142;&#25509;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#23545;&#31216;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#32534;&#30721;&#22120;&#65292;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#30456;&#36817;&#25110;&#19981;&#21516;&#31867;&#21035;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#20010;&#24212;&#29992;&#22330;&#26223;&#65292;&#22914;&#26500;&#24314;&#20840;&#38754;&#30340;&#34917;&#20805;&#19987;&#21033;&#27880;&#20876;&#34920;&#21644;&#35782;&#21035;&#19981;&#21516;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#30340;&#20010;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24212;&#29992;&#38656;&#35201;&#23558;&#21253;&#21547;&#22312;&#21508;&#31181;&#25991;&#26723;&#25968;&#25454;&#38598;&#20013;&#30340;&#23454;&#20363;&#20998;&#32452;&#25104;&#31867;&#12290;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#19981;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#65292;&#20063;&#19981;&#21033;&#29992;&#25991;&#26723;&#22266;&#26377;&#30340;&#22810;&#27169;&#24577;&#24615;&#36136;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#35760;&#24405;&#38142;&#25509;&#36890;&#24120;&#34987;&#27010;&#24565;&#21270;&#20026;&#23383;&#31526;&#20018;&#21305;&#37197;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#24320;&#21457;&#20102; CLIPPINGS&#65292;&#19968;&#31181;&#29992;&#20110;&#35760;&#24405;&#38142;&#25509;&#30340;&#22810;&#27169;&#24577;&#26694;&#26550;&#12290;CLIPPINGS &#37319;&#29992;&#31471;&#21040;&#31471;&#35757;&#32451;&#23545;&#31216;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#21452;&#32534;&#30721;&#22120;&#65292;&#36890;&#36807;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#36827;&#34892;&#23545;&#40784;&#65292;&#23398;&#20064;&#19968;&#20010;&#24230;&#37327;&#31354;&#38388;&#65292;&#20854;&#20013;&#32473;&#23450;&#23454;&#20363;&#30340;&#27719;&#24635;&#22270;&#20687;-&#25991;&#26412;&#34920;&#31034;&#38752;&#36817;&#21516;&#19968;&#31867;&#20013;&#30340;&#34920;&#31034;&#65292;&#24182;&#36828;&#31163;&#19981;&#21516;&#31867;&#20013;&#30340;&#34920;&#31034;&#12290;&#22312;&#25512;&#29702;&#26102;&#65292;&#21487;&#20197;&#36890;&#36807;&#20174;&#31163;&#32447;&#31034;&#20363;&#23884;&#20837;&#32034;&#24341;&#20013;&#26816;&#32034;&#23427;&#20204;&#26368;&#36817;&#30340;&#37051;&#23621;&#25110;&#32858;&#31867;&#23427;&#20204;&#30340;&#34920;&#31034;&#26469;&#38142;&#25509;&#23454;&#20363;&#12290;&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20004;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24212;&#29992;&#65306;&#36890;&#36807;&#23558;&#19987;&#21033;&#19982;&#20854;&#23545;&#24212;&#30340;&#30417;&#31649;&#25991;&#20214;&#38142;&#25509;&#26469;&#26500;&#24314;&#20840;&#38754;&#30340;&#34917;&#20805;&#19987;&#21033;&#27880;&#20876;&#34920;&#65292;&#20197;&#21450;&#22312;&#19981;&#21516;&#30340;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#35782;&#21035;&#20010;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications require grouping instances contained in diverse document datasets into classes. Most widely used methods do not employ deep learning and do not exploit the inherently multimodal nature of documents. Notably, record linkage is typically conceptualized as a string-matching problem. This study develops CLIPPINGS, (Contrastively Linking Pooled Pre-trained Embeddings), a multimodal framework for record linkage. CLIPPINGS employs end-to-end training of symmetric vision and language bi-encoders, aligned through contrastive language-image pre-training, to learn a metric space where the pooled image-text representation for a given instance is close to representations in the same class and distant from representations in different classes. At inference time, instances can be linked by retrieving their nearest neighbor from an offline exemplar embedding index or by clustering their representations. The study examines two challenging applications: constructing comprehensive suppl
&lt;/p&gt;</description></item></channel></rss>