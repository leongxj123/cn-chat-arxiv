<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#65292;&#36890;&#36807;&#32467;&#26500;&#21270;&#20998;&#31867;&#21644;&#35282;&#33394;&#20998;&#26512;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#25351;&#23548;&#12290;</title><link>https://arxiv.org/abs/2404.00282</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#24378;&#21270;&#23398;&#20064;&#30340;&#35843;&#26597;:&#27010;&#24565;&#12289;&#20998;&#31867;&#21644;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00282
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#65292;&#36890;&#36807;&#32467;&#26500;&#21270;&#20998;&#31867;&#21644;&#35282;&#33394;&#20998;&#26512;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;(LLMs)&#25317;&#26377;&#24191;&#27867;&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#21644;&#39640;&#32423;&#36890;&#29992;&#33021;&#21147;&#65292;&#23427;&#20204;&#22312;&#22686;&#24378;&#23398;&#20064;&#26041;&#38754;&#22914;&#22810;&#20219;&#21153;&#23398;&#20064;&#12289;&#26679;&#26412;&#25928;&#29575;&#21644;&#20219;&#21153;&#35268;&#21010;&#31561;&#26041;&#38754;&#23637;&#29616;&#20986;&#28508;&#21147;&#12290;&#26412;&#35843;&#26597;&#32508;&#36848;&#20102;&#29616;&#26377;$\textit{LLM&#22686;&#24378;RL}$&#25991;&#29486;&#65292;&#24635;&#32467;&#20102;&#20854;&#19982;&#20256;&#32479;RL&#26041;&#27861;&#30340;&#29305;&#24449;&#65292;&#26088;&#22312;&#28548;&#28165;&#30740;&#31350;&#33539;&#22260;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;&#21033;&#29992;&#32463;&#20856;&#30340;Agent-&#29615;&#22659;&#20132;&#20114;&#33539;&#20363;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#20998;&#31867;&#27861;&#65292;&#31995;&#32479;&#22320;&#23558;LLMs&#22312;RL&#20013;&#30340;&#21151;&#33021;&#20998;&#31867;&#65292;&#21253;&#25324;&#22235;&#31181;&#35282;&#33394;&#65306;&#20449;&#24687;&#22788;&#29702;&#22120;&#12289;&#22870;&#21169;&#35774;&#35745;&#32773;&#12289;&#20915;&#31574;&#32773;&#21644;&#29983;&#25104;&#22120;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#27599;&#20010;&#35282;&#33394;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#26041;&#27861;&#35770;&#65292;&#20998;&#26512;&#20102;&#32531;&#35299;&#30340;&#29305;&#23450;RL&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#26410;&#26469;&#26041;&#21521;&#30340;&#35265;&#35299;&#12290;&#26368;&#21518;&#65292;&#28508;&#22312;&#24212;&#29992;&#12289;&#21069;&#26223;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00282v1 Announce Type: cross  Abstract: With extensive pre-trained knowledge and high-level general capabilities, large language models (LLMs) emerge as a promising avenue to augment reinforcement learning (RL) in aspects such as multi-task learning, sample efficiency, and task planning. In this survey, we provide a comprehensive review of the existing literature in $\textit{LLM-enhanced RL}$ and summarize its characteristics compared to conventional RL methods, aiming to clarify the research scope and directions for future studies. Utilizing the classical agent-environment interaction paradigm, we propose a structured taxonomy to systematically categorize LLMs' functionalities in RL, including four roles: information processor, reward designer, decision-maker, and generator. Additionally, for each role, we summarize the methodologies, analyze the specific RL challenges that are mitigated, and provide insights into future directions. Lastly, potential applications, prospecti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24443;&#24213;&#37325;&#26657;&#20934;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#30340;&#20215;&#20540;&#35266;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#38382;&#39064;&#30340;&#38887;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.02745</link><description>&lt;p&gt;
CURATRON&#65306;&#23436;&#25972;&#20581;&#22766;&#20559;&#22909;&#25968;&#25454;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20581;&#22766;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24443;&#24213;&#37325;&#26657;&#20934;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#30340;&#20215;&#20540;&#35266;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#38382;&#39064;&#30340;&#38887;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35299;&#20915;&#20102;&#36890;&#36807;&#20559;&#22909;&#23398;&#20064;&#65288;PL&#65289;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#23545;&#40784;&#30340;&#25361;&#25112;&#65292;&#37325;&#28857;&#20851;&#27880;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#19981;&#23436;&#25972;&#21644;&#25439;&#22351;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24443;&#24213;&#21644;&#23436;&#20840;&#22320;&#37325;&#26032;&#26657;&#20934;&#36825;&#20123;&#25968;&#25454;&#38598;&#20013;&#30340;&#20215;&#20540;&#35266;&#65292;&#20197;&#22686;&#24378;LLMs&#23545;&#38382;&#39064;&#30340;&#38887;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26377;&#20445;&#35777;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#25490;&#21517;&#31639;&#27861;&#65292;&#21487;&#20197;&#22686;&#24378;&#20960;&#31181;&#29616;&#26377;&#27169;&#22411;&#30340;&#20581;&#22766;&#24615;&#65292;&#27604;&#22914;&#32463;&#20856;&#30340;Bradley&#8211;Terry&#8211;Luce&#65288;BTL&#65289;&#65288;Bradley&#21644;Terry&#65292;1952&#65289;&#27169;&#22411;&#20197;&#21450;&#23545;&#20854;&#26576;&#20123;&#25512;&#24191;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#31532;&#19968;&#20010;&#25552;&#20986;&#19968;&#31181;&#21487;&#35777;&#26126;&#22312;&#39640;&#27010;&#29575;&#19979;&#24674;&#22797;{\epsilon}-&#26368;&#20248;&#25490;&#24207;&#30340;&#31639;&#27861;&#65292;&#21516;&#26102;&#20801;&#35768;&#27599;&#20010;&#27169;&#22411;&#21709;&#24212;&#22810;&#36798;O(n)&#25200;&#21160;&#30340;&#25104;&#23545;&#27604;&#36739;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#37096;&#20998;&#35266;&#23519;&#35774;&#32622;&#19979;&#30340;&#20581;&#22766;&#24674;&#22797;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02745v1 Announce Type: new  Abstract: This paper addresses the challenges of aligning large language models (LLMs) with human values via preference learning (PL), with a focus on the issues of incomplete and corrupted data in preference datasets. We propose a novel method for robustly and completely recalibrating values within these datasets to enhance LLMs resilience against the issues. In particular, we devise a guaranteed polynomial time ranking algorithm that robustifies several existing models, such as the classic Bradley--Terry--Luce (BTL) (Bradley and Terry, 1952) model and certain generalizations of it. To the best of our knowledge, our present work is the first to propose an algorithm that provably recovers an {\epsilon}-optimal ranking with high probability while allowing as large as O(n) perturbed pairwise comparison results per model response. Furthermore, we show robust recovery results in the partially observed setting. Our experiments confirm that our algorith
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#25506;&#32034;LLMs&#22312;&#26032;&#38395;&#26631;&#39064;&#26377;&#38024;&#23545;&#24615;&#24773;&#24863;&#20998;&#26512;&#20013;&#19981;&#21516;&#32423;&#21035;&#25552;&#31034;&#35268;&#33539;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.00418</link><description>&lt;p&gt;
LLMs&#29992;&#20110;&#26032;&#38395;&#26631;&#39064;&#30340;&#26377;&#38024;&#23545;&#24615;&#24773;&#24863;&#20998;&#26512;&#65306;&#25506;&#32034;&#19981;&#21516;&#32423;&#21035;&#30340;&#25552;&#31034;&#35268;&#33539;&#21270;
&lt;/p&gt;
&lt;p&gt;
LLMs for Targeted Sentiment in News Headlines: Exploring Different Levels of Prompt Prescriptiveness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00418
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#25506;&#32034;LLMs&#22312;&#26032;&#38395;&#26631;&#39064;&#26377;&#38024;&#23545;&#24615;&#24773;&#24863;&#20998;&#26512;&#20013;&#19981;&#21516;&#32423;&#21035;&#25552;&#31034;&#35268;&#33539;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#38395;&#26631;&#39064;&#24120;&#24120;&#36890;&#36807;&#26377;&#24847;&#35782;&#22320;&#20197;&#29305;&#23450;&#26041;&#24335;&#25551;&#32472;&#23454;&#20307;&#26469;&#24341;&#21457;&#24773;&#24863;&#65292;&#36825;&#20351;&#24471;&#26032;&#38395;&#26631;&#39064;&#30340;&#26377;&#38024;&#23545;&#24615;&#24773;&#24863;&#20998;&#26512;(TSA)&#25104;&#20026;&#19968;&#39033;&#20540;&#24471;&#20570;&#20294;&#20855;&#26377;&#25361;&#25112;&#30340;&#20219;&#21153;&#12290;&#24494;&#35843;&#30340;&#32534;&#30721;&#22120;&#27169;&#22411;&#23637;&#29616;&#20986;&#20196;&#20154;&#28385;&#24847;&#30340;TSA&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#30340;&#32972;&#26223;&#30693;&#35782;&#26377;&#38480;&#65292;&#38656;&#35201;&#26377;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#12290;LLMs&#30001;&#20110;&#20854;&#24191;&#27867;&#30340;&#35821;&#35328;&#21644;&#19990;&#30028;&#30693;&#35782;&#20197;&#21450;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#20026;TSA&#25552;&#20379;&#20102;&#19968;&#20010;&#28508;&#22312;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65292;&#28982;&#32780;&#23427;&#20204;&#30340;&#24615;&#33021;&#21463;&#25552;&#31034;&#35774;&#35745;&#30340;&#24433;&#21709;&#24456;&#22823;&#12290;&#36890;&#36807;&#19982;&#20027;&#35266;&#20219;&#21153;&#30340;&#27880;&#37322;&#33539;&#24335;&#36827;&#34892;&#31867;&#27604;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#25552;&#31034;&#35774;&#35745;&#23545;LLMs&#22312;&#26032;&#38395;&#26631;&#39064;TSA&#20013;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20351;&#29992;&#19981;&#21516;&#32423;&#21035;&#30340;&#35268;&#33539;&#25552;&#31034;&#65288;&#20174;&#32431;&#31929;&#30340;&#38646;&#26679;&#26412;&#21040;&#31526;&#21512;&#27880;&#37322;&#25351;&#21335;&#30340;&#31934;&#24515;&#20934;&#22791;&#30340;&#23569;&#26679;&#26412;&#25552;&#31034;&#65289;&#30340;&#26368;&#20808;&#36827;LLMs&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#35748;&#35782;&#21040;TSA&#30340;&#20027;&#35266;&#24615;&#36136;&#65292;&#25105;&#20204;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00418v1 Announce Type: new  Abstract: News headlines often evoke sentiment by intentionally portraying entities in particular ways, making targeted sentiment analysis (TSA) of headlines a worthwhile but difficult task. Fine-tuned encoder models show satisfactory TSA performance, but their background knowledge is limited, and they require a labeled dataset. LLMs offer a potentially universal solution for TSA due to their broad linguistic and world knowledge along with in-context learning abilities, yet their performance is heavily influenced by prompt design. Drawing parallels with annotation paradigms for subjective tasks, we explore the influence of prompt design on the performance of LLMs for TSA of news headlines. We evaluate the predictive accuracy of state-of-the-art LLMs using prompts with different levels of prescriptiveness, ranging from plain zero-shot to elaborate few-shot prompts matching annotation guidelines. Recognizing the subjective nature of TSA, we evaluate
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22810;&#36718;&#23545;&#35805;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#28431;&#27934;&#65292;&#25351;&#20986;&#20154;&#31867;&#21487;&#20197;&#36890;&#36807;&#22810;&#36718;&#23545;&#35805;&#35825;&#20351;&#20854;&#29983;&#25104;&#26377;&#23475;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2402.17262</link><description>&lt;p&gt;
&#22833;&#35328;&#65306;&#22810;&#36718;&#23545;&#35805;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#28431;&#27934;
&lt;/p&gt;
&lt;p&gt;
Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22810;&#36718;&#23545;&#35805;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#28431;&#27934;&#65292;&#25351;&#20986;&#20154;&#31867;&#21487;&#20197;&#36890;&#36807;&#22810;&#36718;&#23545;&#35805;&#35825;&#20351;&#20854;&#29983;&#25104;&#26377;&#23475;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#34987;&#35777;&#26126;&#22312;&#38754;&#20020;"&#36234;&#29425;"&#26102;&#20250;&#20135;&#29983;&#38750;&#27861;&#25110;&#19981;&#36947;&#24503;&#30340;&#22238;&#24212;&#12290; "&#36234;&#29425;"&#30740;&#31350;&#24378;&#35843;&#20102;LLMs&#30340;&#23433;&#20840;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#21333;&#36718;&#23545;&#35805;&#19978;&#65292;&#24573;&#35270;&#20102;&#22810;&#36718;&#23545;&#35805;&#21487;&#33021;&#24102;&#26469;&#30340;&#22797;&#26434;&#24615;&#21644;&#39118;&#38505;&#65292;&#36825;&#26159;&#20154;&#31867;&#20174;LLMs&#33719;&#21462;&#20449;&#24687;&#30340;&#20851;&#38190;&#26041;&#24335;&#12290;&#26412;&#25991;&#35748;&#20026;&#20154;&#31867;&#21487;&#20197;&#21033;&#29992;&#22810;&#36718;&#23545;&#35805;&#35825;&#20351;LLMs&#29983;&#25104;&#26377;&#23475;&#20449;&#24687;&#12290;LLMs&#21487;&#33021;&#19981;&#20250;&#25298;&#32477;&#35686;&#21578;&#24615;&#25110;&#36793;&#30028;&#19981;&#23433;&#20840;&#30340;&#26597;&#35810;&#65292;&#21363;&#20351;&#22312;&#22810;&#36718;&#23545;&#35805;&#20013;&#27599;&#20010;&#22238;&#21512;&#37117;&#34987;&#26381;&#21153;&#20110;&#19968;&#20010;&#24694;&#24847;&#30446;&#30340;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#23558;&#19968;&#20010;&#19981;&#23433;&#20840;&#26597;&#35810;&#20998;&#35299;&#20026;&#22810;&#20010;&#23376;&#26597;&#35810;&#29992;&#20110;&#22810;&#36718;&#23545;&#35805;&#65292;&#25105;&#20204;&#36880;&#28176;&#35825;&#20351;LLMs&#22238;&#31572;&#26377;&#23475;&#30340;&#23376;&#38382;&#39064;&#65292;&#26368;&#32456;&#23548;&#33268;&#24635;&#20307;&#26377;&#23475;&#21709;&#24212;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#36328;&#36234;&#20102;&#24191;&#27867;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17262v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have been demonstrated to generate illegal or unethical responses, particularly when subjected to "jailbreak." Research on jailbreak has highlighted the safety issues of LLMs. However, prior studies have predominantly focused on single-turn dialogue, ignoring the potential complexities and risks presented by multi-turn dialogue, a crucial mode through which humans derive information from LLMs. In this paper, we argue that humans could exploit multi-turn dialogue to induce LLMs into generating harmful information. LLMs may not intend to reject cautionary or borderline unsafe queries, even if each turn is closely served for one malicious purpose in a multi-turn dialogue. Therefore, by decomposing an unsafe query into several sub-queries for multi-turn dialogue, we induced LLMs to answer harmful sub-questions incrementally, culminating in an overall harmful response. Our experiments, conducted across a wide ra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#36890;&#29992;LM&#23545;&#40784;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#26126;&#30830;&#27880;&#37322;&#30340;&#22870;&#21169;&#25968;&#25454;&#65292;&#24182;&#19988;&#25193;&#23637;&#20102;&#24403;&#21069;&#30340;&#23545;&#40784;&#29702;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.05369</link><description>&lt;p&gt;
&#20197;&#26174;&#24335;&#22870;&#21169;&#30340;&#22122;&#22768;&#23545;&#27604;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Noise Contrastive Alignment of Language Models with Explicit Rewards
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05369
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#36890;&#29992;LM&#23545;&#40784;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#26126;&#30830;&#27880;&#37322;&#30340;&#22870;&#21169;&#25968;&#25454;&#65292;&#24182;&#19988;&#25193;&#23637;&#20102;&#24403;&#21069;&#30340;&#23545;&#40784;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#24847;&#22270;&#36890;&#24120;&#34987;&#24418;&#24335;&#21270;&#20026;&#38656;&#35201;&#22312;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#26102;&#26368;&#22823;&#21270;&#30340;&#35780;&#20272;&#22870;&#21169;&#12290;&#29616;&#26377;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#22914;&#30452;&#25509;&#20248;&#21270;&#20559;&#22909;&#65288;DPO&#65289;&#65292;&#20027;&#35201;&#36866;&#29992;&#20110;&#38544;&#21547;&#23450;&#20041;&#32780;&#38750;&#26126;&#30830;&#32473;&#23450;&#22870;&#21169;&#30340;&#20004;&#20004;&#20559;&#22909;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;LM&#23545;&#40784;&#26694;&#26550;&#65292;&#21033;&#29992;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#65288;NCE&#65289;&#26469;&#35299;&#20915;&#26126;&#30830;&#27880;&#37322;&#26377;&#26631;&#37327;&#35780;&#20272;&#30340;&#22870;&#21169;&#25968;&#25454;&#22788;&#29702;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#20004;&#20010;&#24182;&#34892;&#31639;&#27861;&#65292;NCA&#21644;InfoNCA&#65292;&#20004;&#32773;&#37117;&#33021;&#20174;&#22870;&#21169;&#25968;&#25454;&#21644;&#20559;&#22909;&#25968;&#25454;&#20013;&#30452;&#25509;&#25552;&#21462;LM&#31574;&#30053;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;DPO&#25439;&#22833;&#26159;&#25105;&#20204;&#25552;&#20986;&#30340;InfoNCA&#30446;&#26631;&#22312;&#20004;&#20004;&#20559;&#22909;&#35774;&#32622;&#19979;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#20174;&#32780;&#38598;&#25104;&#21644;&#25193;&#23637;&#20102;&#24403;&#21069;&#30340;&#23545;&#40784;&#29702;&#35770;&#12290;&#36890;&#36807;&#23545;&#27604;NCA&#21644;InfoNCA&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;InfoNCA&#21644;DPO&#22914;&#20309;&#22312;&#19981;&#21516;&#21709;&#24212;&#23545;&#20110;&#21333;&#20010;&#25351;&#20196;&#30340;&#30456;&#23545;&#21487;&#33021;&#24615;&#19978;&#36827;&#34892;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
User intentions are typically formalized as evaluation rewards to be maximized when fine-tuning language models (LMs). Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given. In this paper, we introduce a general framework for LM alignment, leveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling reward datasets explicitly annotated with scalar evaluations. Our framework comprises two parallel algorithms, NCA and InfoNCA, both enabling the direct extraction of an LM policy from reward data as well as preference data. Notably, we show that the DPO loss is a special case of our proposed InfoNCA objective under pairwise preference settings, thereby integrating and extending current alignment theories. By contrasting NCA and InfoNCA, we show that InfoNCA and DPO adjust relative likelihood across different responses to a single instruction,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#22522;&#20110;&#27169;&#26495;&#21644;&#38750;&#27169;&#26495;&#35821;&#35328;&#27169;&#22411;&#30340;&#25506;&#27979;&#26041;&#27861;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#27169;&#22411;&#25490;&#21517;&#12289;&#32477;&#23545;&#24471;&#20998;&#21644;&#19982;&#22256;&#24785;&#24230;&#30340;&#20851;&#31995;&#31561;&#26041;&#38754;&#23384;&#22312;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.00123</link><description>&lt;p&gt;
&#27604;&#36739;&#22522;&#20110;&#27169;&#26495;&#21644;&#38750;&#27169;&#26495;&#35821;&#35328;&#27169;&#22411;&#30340;&#25506;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Comparing Template-based and Template-free Language Model Probing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#22522;&#20110;&#27169;&#26495;&#21644;&#38750;&#27169;&#26495;&#35821;&#35328;&#27169;&#22411;&#30340;&#25506;&#27979;&#26041;&#27861;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#27169;&#22411;&#25490;&#21517;&#12289;&#32477;&#23545;&#24471;&#20998;&#21644;&#19982;&#22256;&#24785;&#24230;&#30340;&#20851;&#31995;&#31561;&#26041;&#38754;&#23384;&#22312;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#19987;&#23478;&#21046;&#20316;&#30340;&#27169;&#26495;&#21644;&#33258;&#28982;&#21457;&#29983;&#30340;&#25991;&#26412;&#20026;&#22522;&#30784;&#30340;&#35821;&#35328;&#27169;&#22411;&#25506;&#27979;&#26041;&#27861;&#30340;&#24046;&#24322;&#32463;&#24120;&#34987;&#24573;&#35270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;16&#31181;&#19981;&#21516;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;10&#20010;&#33521;&#25991;&#25506;&#27979;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#20854;&#20013;&#21253;&#25324;4&#20010;&#22522;&#20110;&#27169;&#26495;&#30340;&#21644;6&#20010;&#38750;&#27169;&#26495;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#38024;&#23545;&#20197;&#19979;&#30740;&#31350;&#38382;&#39064;&#36827;&#34892;&#20102;&#22238;&#31572;&#65306;&#65288;RQ1&#65289;&#27169;&#22411;&#25490;&#21517;&#22312;&#20004;&#31181;&#26041;&#27861;&#20013;&#26159;&#21542;&#19981;&#21516;&#65311;&#65288;RQ2&#65289;&#27169;&#22411;&#30340;&#32477;&#23545;&#24471;&#20998;&#22312;&#20004;&#31181;&#26041;&#27861;&#20013;&#26159;&#21542;&#19981;&#21516;&#65311;&#65288;RQ3&#65289;RQ1&#21644;RQ2&#30340;&#31572;&#26696;&#22312;&#19968;&#33324;&#21644;&#39046;&#22495;&#29305;&#23450;&#27169;&#22411;&#20043;&#38388;&#26159;&#21542;&#19981;&#21516;&#65311;&#25105;&#20204;&#30340;&#21457;&#29616;&#26159;&#65306;1&#65289;&#38500;&#20102;&#39030;&#32423;&#30340;&#39046;&#22495;&#29305;&#23450;&#27169;&#22411;&#22806;&#65292;&#22522;&#20110;&#27169;&#26495;&#21644;&#38750;&#27169;&#26495;&#26041;&#27861;&#36890;&#24120;&#25490;&#21517;&#19981;&#21516;&#12290;2&#65289;&#19982;&#24179;&#34892;&#30340;&#38750;&#27169;&#26495;&#21644;&#27169;&#26495;&#25552;&#31034;&#30456;&#27604;&#65292;&#20934;&#30830;&#24230;&#19979;&#38477;&#20102;&#26368;&#22810;42%&#12290;3&#65289;&#22312;&#38750;&#27169;&#26495;&#26041;&#27861;&#20013;&#65292;&#22256;&#24785;&#24230;&#19982;&#20934;&#30830;&#24230;&#21576;&#36127;&#30456;&#20851;&#65292;&#20294;&#26159;&#22312;&#22522;&#20110;&#27169;&#26495;&#30340;&#25506;&#27979;&#20013;&#65292;&#23427;&#20204;&#21576;&#27491;&#30456;&#20851;&#65292;&#36825;&#19982;&#30452;&#35273;&#30456;&#21453;&#12290;4&#65289;&#27169;&#22411;&#20542;&#21521;&#20110;&#39044;&#27979;&#30456;&#21516;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
The differences between cloze-task language model (LM) probing with 1) expert-made templates and 2) naturally-occurring text have often been overlooked. Here, we evaluate 16 different LMs on 10 probing English datasets -- 4 template-based and 6 template-free -- in general and biomedical domains to answer the following research questions: (RQ1) Do model rankings differ between the two approaches? (RQ2) Do models' absolute scores differ between the two approaches? (RQ3) Do the answers to RQ1 and RQ2 differ between general and domain-specific models? Our findings are: 1) Template-free and template-based approaches often rank models differently, except for the top domain-specific models. 2) Scores decrease by up to 42% Acc@1 when comparing parallel template-free and template-based prompts. 3) Perplexity is negatively correlated with accuracy in the template-free approach, but, counter-intuitively, they are positively correlated for template-based probing. 4) Models tend to predict the same
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#25968;&#25454;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;</title><link>https://arxiv.org/abs/2311.16466</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#35821;&#35328;&#29305;&#24449;&#23545;&#40784;&#21487;&#20197;&#22686;&#24378;&#35828;&#26381;&#21147;
&lt;/p&gt;
&lt;p&gt;
Large language models can enhance persuasion through linguistic feature alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#25968;&#25454;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs)&#27491;&#22312;&#37325;&#26032;&#22609;&#36896;&#20154;&#31867;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#20294;&#25105;&#20204;&#23545;&#23427;&#20204;&#30340;&#24433;&#21709;&#30340;&#29702;&#35299;&#20173;&#28982;&#26377;&#20123;&#21463;&#38480;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;LLMs&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#30340;&#25968;&#25454;&#12290;&#36890;&#36807;&#23545;&#28040;&#36153;&#32773;&#37329;&#34701;&#20445;&#25252;&#23616; (CFPB) &#25910;&#38598;&#30340;&#36229;&#36807;820,000&#20010;&#25237;&#35785;&#36827;&#34892;AI&#26816;&#27979;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;ChatGPT&#21457;&#24067;&#21518;&#19981;&#20037;&#65292;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#24615;&#24613;&#21095;&#22686;&#21152;&#12290;&#27492;&#22806;&#65292;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#24615;&#19982;&#20449;&#24687;&#35828;&#26381;&#21147;&#65288;&#21363;&#20174;&#37329;&#34701;&#20844;&#21496;&#33719;&#24471;&#25937;&#27982;&#30340;&#21487;&#33021;&#24615;&#22686;&#21152;&#65289;&#21576;&#27491;&#30456;&#20851;&#12290;&#35745;&#31639;&#35821;&#35328;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#31181;&#27491;&#30456;&#20851;&#21487;&#33021;&#26159;&#30001;LLMs&#22686;&#24378;&#20102;&#21508;&#31181;&#35821;&#35328;&#29305;&#24449;&#25152;&#35299;&#37322;&#30340;&#12290;&#26681;&#25454;&#36825;&#20123;&#35266;&#23519;&#30740;&#31350;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#20551;&#35774;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#23545;&#20855;&#26377;&#19981;&#21516;&#35821;&#35328;&#32972;&#26223;&#30340;&#25509;&#25910;&#32773;&#30340;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although large language models (LLMs) are reshaping various aspects of human life, our current understanding of their impacts remains somewhat constrained. Here we investigate the impact of LLMs on human communication, using data on consumer complaints in the financial industry. By employing an AI detection tool on more than 820K complaints gathered by the Consumer Financial Protection Bureau (CFPB), we find a sharp increase in the likely use of LLMs shortly after the release of ChatGPT. Moreover, the likely LLM usage was positively correlated with message persuasiveness (i.e., increased likelihood of obtaining relief from financial firms). Computational linguistic analyses suggest that the positive correlation may be explained by LLMs' enhancement of various linguistic features. Based on the results of these observational studies, we hypothesize that LLM usage may enhance a comprehensive set of linguistic features, increasing message persuasiveness to receivers with heterogeneous ling
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#32508;&#21512;&#35843;&#26597;&#24635;&#32467;&#20102;&#26368;&#36817;&#22312;&#20167;&#24680;&#35328;&#35770;&#23457;&#26680;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#37325;&#28857;&#20171;&#32461;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;&#20316;&#29992;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#25991;&#26412;&#12289;&#35270;&#35273;&#21644;&#21548;&#35273;&#20803;&#32032;&#22312;&#20256;&#25773;&#20167;&#24680;&#35328;&#35770;&#20013;&#30340;&#24494;&#22937;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#24378;&#35843;&#20102;&#22823;&#22411;&#27169;&#22411;&#23545;&#23457;&#26680;&#33021;&#21147;&#30340;&#37325;&#26032;&#23450;&#20041;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#22312;&#23569;&#25968;&#35821;&#35328;&#21644;&#25991;&#21270;&#32972;&#26223;&#19979;&#30340;&#30740;&#31350;&#24046;&#36317;&#21644;&#22788;&#29702;&#20302;&#36164;&#28304;&#29615;&#22659;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.16727</link><description>&lt;p&gt;
&#26368;&#36817;&#22312;&#20167;&#24680;&#35328;&#35770;&#23457;&#26680;&#26041;&#38754;&#30340;&#36827;&#23637;&#65306;&#22810;&#27169;&#24577;&#21644;&#22823;&#22411;&#27169;&#22411;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models. (arXiv:2401.16727v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16727
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#32508;&#21512;&#35843;&#26597;&#24635;&#32467;&#20102;&#26368;&#36817;&#22312;&#20167;&#24680;&#35328;&#35770;&#23457;&#26680;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#37325;&#28857;&#20171;&#32461;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;&#20316;&#29992;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#25991;&#26412;&#12289;&#35270;&#35273;&#21644;&#21548;&#35273;&#20803;&#32032;&#22312;&#20256;&#25773;&#20167;&#24680;&#35328;&#35770;&#20013;&#30340;&#24494;&#22937;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#24378;&#35843;&#20102;&#22823;&#22411;&#27169;&#22411;&#23545;&#23457;&#26680;&#33021;&#21147;&#30340;&#37325;&#26032;&#23450;&#20041;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#22312;&#23569;&#25968;&#35821;&#35328;&#21644;&#25991;&#21270;&#32972;&#26223;&#19979;&#30340;&#30740;&#31350;&#24046;&#36317;&#21644;&#22788;&#29702;&#20302;&#36164;&#28304;&#29615;&#22659;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32593;&#32476;&#20132;&#27969;&#30340;&#19981;&#26029;&#21457;&#23637;&#20013;&#65292;&#23457;&#26680;&#20167;&#24680;&#35328;&#35770;&#65288;HS&#65289;&#38754;&#20020;&#30528;&#22797;&#26434;&#30340;&#25361;&#25112;&#65292;&#36825;&#26159;&#30001;&#25968;&#23383;&#20869;&#23481;&#30340;&#22810;&#27169;&#24577;&#29305;&#24615;&#25152;&#24102;&#26469;&#30340;&#12290;&#36825;&#39033;&#32508;&#21512;&#35843;&#26597;&#28145;&#20837;&#30740;&#31350;&#20102;HS&#23457;&#26680;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#30528;&#37325;&#20171;&#32461;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;LMMs&#65289;&#30340;&#23835;&#36215;&#35282;&#33394;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20174;&#23545;&#24403;&#21069;&#25991;&#29486;&#30340;&#20840;&#38754;&#20998;&#26512;&#24320;&#22987;&#65292;&#25581;&#31034;&#20102;&#25991;&#26412;&#12289;&#35270;&#35273;&#21644;&#21548;&#35273;&#20803;&#32032;&#22312;&#20256;&#25773;HS&#20013;&#30340;&#24494;&#22937;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20010;&#26126;&#26174;&#30340;&#36235;&#21183;&#65292;&#21363;&#23558;&#36825;&#20123;&#27169;&#24577;&#25972;&#21512;&#22312;&#19968;&#36215;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;HS&#30340;&#20256;&#25773;&#20855;&#26377;&#22797;&#26434;&#24615;&#21644;&#24494;&#22937;&#24615;&#12290;&#23545;&#20110;&#30001;LLMs&#21644;LMMs&#24102;&#26469;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#29305;&#21035;&#24378;&#35843;&#20102;&#20854;&#23545;&#26816;&#27979;&#21644;&#23457;&#26680;&#33021;&#21147;&#36793;&#30028;&#30340;&#37325;&#26032;&#23450;&#20041;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#29616;&#26377;&#24046;&#36317;&#65292;&#29305;&#21035;&#26159;&#22312;&#23569;&#25968;&#35821;&#35328;&#21644;&#25991;&#21270;&#30340;&#32972;&#26223;&#19979;&#65292;&#20197;&#21450;&#22312;&#22788;&#29702;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#38656;&#35201;&#35299;&#20915;&#26041;&#26696;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the evolving landscape of online communication, moderating hate speech (HS) presents an intricate challenge, compounded by the multimodal nature of digital content. This comprehensive survey delves into the recent strides in HS moderation, spotlighting the burgeoning role of large language models (LLMs) and large multimodal models (LMMs). Our exploration begins with a thorough analysis of current literature, revealing the nuanced interplay between textual, visual, and auditory elements in propagating HS. We uncover a notable trend towards integrating these modalities, primarily due to the complexity and subtlety with which HS is disseminated. A significant emphasis is placed on the advances facilitated by LLMs and LMMs, which have begun to redefine the boundaries of detection and moderation capabilities. We identify existing gaps in research, particularly in the context of underrepresented languages and cultures, and the need for solutions to handle low-resource settings. The survey
&lt;/p&gt;</description></item><item><title>ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2401.10225</link><description>&lt;p&gt;
ChatQA: &#26500;&#24314;GPT-4&#32423;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10225
&lt;/p&gt;
&lt;p&gt;
ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChatQA&#65292;&#19968;&#31995;&#21015;&#20855;&#26377;GPT-4&#32423;&#21035;&#20934;&#30830;&#24615;&#30340;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#22788;&#29702;&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#26816;&#32034;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#22810;&#36718;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#24494;&#35843;&#65292;&#36825;&#26679;&#21487;&#20197;&#25552;&#20379;&#19982;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22823;&#22823;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;ChatQA-70B&#21487;&#20197;&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24179;&#22343;&#20998;&#19978;&#36229;&#36807;GPT-4&#65288;54.14 vs. 53.90&#65289;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;OpenAI GPT&#27169;&#22411;&#30340;&#20219;&#20309;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.
&lt;/p&gt;</description></item><item><title>ChatKBQA&#26159;&#19968;&#20010;&#22522;&#20110;&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;-&#26816;&#32034;&#26694;&#26550;&#65292;&#29992;&#20110;&#25913;&#36827;&#30693;&#35782;&#24211;&#38382;&#31572;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.08975</link><description>&lt;p&gt;
ChatKBQA: &#19968;&#20010;&#22522;&#20110;&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;-&#26816;&#32034;&#26694;&#26550;&#29992;&#20110;&#30693;&#35782;&#24211;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models. (arXiv:2310.08975v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08975
&lt;/p&gt;
&lt;p&gt;
ChatKBQA&#26159;&#19968;&#20010;&#22522;&#20110;&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;-&#26816;&#32034;&#26694;&#26550;&#65292;&#29992;&#20110;&#25913;&#36827;&#30693;&#35782;&#24211;&#38382;&#31572;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#24211;&#38382;&#31572;&#65288;KBQA&#65289;&#26088;&#22312;&#36890;&#36807;&#22823;&#35268;&#27169;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#33719;&#21462;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#30340;&#31572;&#26696;&#65292;&#36890;&#24120;&#20998;&#20026;&#20004;&#20010;&#30740;&#31350;&#32452;&#25104;&#37096;&#20998;&#65306;&#30693;&#35782;&#26816;&#32034;&#21644;&#35821;&#20041;&#35299;&#26512;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#19977;&#20010;&#26680;&#24515;&#25361;&#25112;&#65292;&#21253;&#25324;&#20302;&#25928;&#30340;&#30693;&#35782;&#26816;&#32034;&#12289;&#26816;&#32034;&#38169;&#35823;&#23545;&#35821;&#20041;&#35299;&#26512;&#30340;&#19981;&#21033;&#24433;&#21709;&#20197;&#21450;&#20043;&#21069;&#30340;KBQA&#26041;&#27861;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26102;&#20195;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChatKBQA&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#31934;&#35843;&#24320;&#28304;LLMs&#65288;&#22914;Llama-2&#12289;ChatGLM2&#21644;Baichuan2&#65289;&#26500;&#24314;&#30340;&#29983;&#25104;-&#26816;&#32034;KBQA&#26694;&#26550;&#12290;ChatKBQA&#25552;&#35758;&#39318;&#20808;&#20351;&#29992;&#31934;&#35843;&#30340;LLMs&#29983;&#25104;&#36923;&#36753;&#24418;&#24335;&#65292;&#28982;&#21518;&#36890;&#36807;&#26080;&#30417;&#30563;&#26816;&#32034;&#26041;&#27861;&#26816;&#32034;&#21644;&#26367;&#25442;&#23454;&#20307;&#21644;&#20851;&#31995;&#65292;&#20174;&#32780;&#26356;&#30452;&#35266;&#22320;&#25913;&#36827;&#20102;&#29983;&#25104;&#21644;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ChatKBQA&#22312;&#26631;&#20934;KBQA&#25968;&#25454;&#38598;WebQSP&#21644;ComplexWebQuestions (CWQ)&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge Base Question Answering (KBQA) aims to derive answers to natural language questions over large-scale knowledge bases (KBs), which are generally divided into two research components: knowledge retrieval and semantic parsing. However, three core challenges remain, including inefficient knowledge retrieval, retrieval errors adversely affecting semantic parsing, and the complexity of previous KBQA methods. In the era of large language models (LLMs), we introduce ChatKBQA, a novel generate-then-retrieve KBQA framework built on fine-tuning open-source LLMs such as Llama-2, ChatGLM2 and Baichuan2. ChatKBQA proposes generating the logical form with fine-tuned LLMs first, then retrieving and replacing entities and relations through an unsupervised retrieval method, which improves both generation and retrieval more straightforwardly. Experimental results reveal that ChatKBQA achieves new state-of-the-art performance on standard KBQA datasets, WebQSP, and ComplexWebQuestions (CWQ). This
&lt;/p&gt;</description></item><item><title>Text2NKG&#26159;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26694;&#26550;&#65292;&#25903;&#25345;&#22810;&#31181;NKG&#27169;&#24335;&#65292;&#20855;&#26377;&#39640;&#28789;&#27963;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05185</link><description>&lt;p&gt;
Text2NKG: &#38754;&#21521;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#26500;&#24314;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;
&lt;/p&gt;
&lt;p&gt;
Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction. (arXiv:2310.05185v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05185
&lt;/p&gt;
&lt;p&gt;
Text2NKG&#26159;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26694;&#26550;&#65292;&#25903;&#25345;&#22810;&#31181;NKG&#27169;&#24335;&#65292;&#20855;&#26377;&#39640;&#28789;&#27963;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#20256;&#32479;&#30340;&#20108;&#20803;&#20851;&#31995;&#20107;&#23454;&#22806;&#65292;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;(NKGs)&#30001;&#21253;&#21547;&#20004;&#20010;&#20197;&#19978;&#23454;&#20307;&#30340;N&#20803;&#20851;&#31995;&#20107;&#23454;&#32452;&#25104;&#65292;&#26356;&#25509;&#36817;&#20110;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#30495;&#23454;&#19990;&#30028;&#20107;&#23454;&#12290;&#28982;&#32780;&#65292;NKG&#30340;&#26500;&#24314;&#20173;&#28982;&#20005;&#37325;&#20381;&#36182;&#20110;&#20154;&#24037;&#21171;&#21160;&#65292;&#24182;&#19988;N&#20803;&#20851;&#31995;&#25277;&#21462;&#20173;&#28982;&#20572;&#30041;&#22312;&#31895;&#31890;&#24230;&#27700;&#24179;&#65292;&#36890;&#24120;&#26159;&#22312;&#21333;&#19968;&#27169;&#24335;&#21644;&#22266;&#23450;&#30340;&#23454;&#20307;&#25968;&#37327;&#19978;&#25805;&#20316;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Text2NKG&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#38754;&#21521;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#26500;&#24314;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26694;&#26550;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36328;&#24230;&#20803;&#32452;&#20998;&#31867;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#24322;&#26500;&#25490;&#24207;&#21512;&#24182;&#26469;&#23454;&#29616;&#19981;&#21516;&#24230;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#12290;&#27492;&#22806;&#65292;Text2NKG&#25903;&#25345;&#22235;&#31181;&#20856;&#22411;&#30340;NKG&#27169;&#24335;&#65306;&#36229;&#20851;&#31995;&#27169;&#24335;&#12289;&#22522;&#20110;&#20107;&#20214;&#30340;&#27169;&#24335;&#12289;&#22522;&#20110;&#35282;&#33394;&#30340;&#27169;&#24335;&#21644;&#36229;&#22270;&#27169;&#24335;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#28789;&#27963;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Text2NKG&#30340;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#30340;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Beyond traditional binary relational facts, n-ary relational knowledge graphs (NKGs) are comprised of n-ary relational facts containing more than two entities, which are closer to real-world facts with broader applications. However, the construction of NKGs still significantly relies on manual labor, and n-ary relation extraction still remains at a course-grained level, which is always in a single schema and fixed arity of entities. To address these restrictions, we propose Text2NKG, a novel fine-grained n-ary relation extraction framework for n-ary relational knowledge graph construction. We introduce a span-tuple classification approach with hetero-ordered merging to accomplish fine-grained n-ary relation extraction in different arity. Furthermore, Text2NKG supports four typical NKG schemas: hyper-relational schema, event-based schema, role-based schema, and hypergraph-based schema, with high flexibility and practicality. Experimental results demonstrate that Text2NKG outperforms the
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;KV&#32531;&#23384;&#21387;&#32553;&#26041;&#27861;&#65292;&#29992;&#20110;&#20943;&#23569;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#23384;&#28040;&#32791;&#12290;&#36890;&#36807;&#26377;&#38024;&#23545;&#24615;&#30340;&#20998;&#26512;&#21644;&#32467;&#26500;&#35782;&#21035;&#65292;&#26500;&#24314;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#24615;&#30340;KV&#32531;&#23384;&#65292;&#36890;&#36807;&#28165;&#38500;&#21644;&#20002;&#24323;&#29305;&#23450;&#30340;&#19978;&#19979;&#25991;&#65292;&#20197;&#21450;&#21482;&#23545;&#29305;&#23450;&#30340;&#27880;&#24847;&#21147;&#22836;&#20351;&#29992;&#26631;&#20934;KV&#32531;&#23384;&#65292;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#20869;&#23384;&#21344;&#29992;&#20943;&#23569;&#12290;</title><link>http://arxiv.org/abs/2310.01801</link><description>&lt;p&gt;
&#27169;&#22411;&#21578;&#35785;&#20320;&#35813;&#20002;&#24323;&#20160;&#20040;&#65306;&#36866;&#24212;&#24615;KV&#32531;&#23384;&#21387;&#32553;&#29992;&#20110;LLMs
&lt;/p&gt;
&lt;p&gt;
Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs. (arXiv:2310.01801v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01801
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;KV&#32531;&#23384;&#21387;&#32553;&#26041;&#27861;&#65292;&#29992;&#20110;&#20943;&#23569;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#23384;&#28040;&#32791;&#12290;&#36890;&#36807;&#26377;&#38024;&#23545;&#24615;&#30340;&#20998;&#26512;&#21644;&#32467;&#26500;&#35782;&#21035;&#65292;&#26500;&#24314;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#24615;&#30340;KV&#32531;&#23384;&#65292;&#36890;&#36807;&#28165;&#38500;&#21644;&#20002;&#24323;&#29305;&#23450;&#30340;&#19978;&#19979;&#25991;&#65292;&#20197;&#21450;&#21482;&#23545;&#29305;&#23450;&#30340;&#27880;&#24847;&#21147;&#22836;&#20351;&#29992;&#26631;&#20934;KV&#32531;&#23384;&#65292;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#20869;&#23384;&#21344;&#29992;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;KV&#32531;&#23384;&#21387;&#32553;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#20943;&#23569;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#25512;&#29702;&#30340;&#20869;&#23384;&#21344;&#29992;&#12290;&#19982;&#20256;&#32479;&#30340;KV&#32531;&#23384;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#26377;&#38024;&#23545;&#24615;&#30340;&#20998;&#26512;&#26469;&#35782;&#21035;&#27880;&#24847;&#21147;&#27169;&#22359;&#30340;&#20869;&#22312;&#32467;&#26500;&#12290;&#22522;&#20110;&#35782;&#21035;&#20986;&#30340;&#32467;&#26500;&#65292;&#25105;&#20204;&#20197;&#33258;&#36866;&#24212;&#30340;&#26041;&#24335;&#26500;&#24314;KV&#32531;&#23384;&#65306;&#22312;&#24378;&#35843;&#26412;&#22320;&#19978;&#19979;&#25991;&#30340;&#27880;&#24847;&#21147;&#22836;&#19978;&#28165;&#38500;&#38271;&#36317;&#31163;&#19978;&#19979;&#25991;&#65292;&#22312;&#20197;&#29305;&#27530;&#26631;&#35760;&#20026;&#20013;&#24515;&#30340;&#27880;&#24847;&#21147;&#22836;&#19978;&#20002;&#24323;&#38750;&#29305;&#27530;&#26631;&#35760;&#65292;&#24182;&#19988;&#20165;&#23545;&#24191;&#27867;&#20851;&#27880;&#25152;&#26377;&#26631;&#35760;&#30340;&#27880;&#24847;&#21147;&#22836;&#20351;&#29992;&#26631;&#20934;&#30340;KV&#32531;&#23384;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20351;&#29992;&#36731;&#37327;&#32423;&#30340;&#27880;&#24847;&#21147;&#20998;&#26512;&#26469;&#25351;&#23548;&#33258;&#36866;&#24212;KV&#32531;&#23384;&#30340;&#26500;&#24314;&#65292;FastGen&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#36164;&#28304;&#23494;&#38598;&#22411;&#30340;&#24494;&#35843;&#25110;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#37096;&#32626;&#12290;&#22312;&#21508;&#31181;&#20219;&#21153;&#30340;&#23454;&#39564;&#20013;&#65292;FastGen&#22312;GPU&#20869;&#23384;&#28040;&#32791;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#24335;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#32852;&#37030;&#23398;&#20064;&#23454;&#29616;&#20998;&#25955;&#25968;&#25454;&#30340;&#20849;&#21516;&#35757;&#32451;&#20849;&#20139;&#27169;&#22411;&#65292;&#20197;&#24212;&#23545;&#20844;&#20849;&#25968;&#25454;&#21487;&#29992;&#24615;&#30340;&#38480;&#21046;&#21644;&#31169;&#26377;&#25968;&#25454;&#30340;&#38544;&#31169;&#20445;&#25252;&#38656;&#27714;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#39044;&#35757;&#32451;&#12289;&#24494;&#35843;&#21644;&#25552;&#31034;&#24037;&#31243;&#36825;&#19977;&#20010;&#32452;&#20214;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#26045;&#31574;&#30053;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;FL&#21644;LLM&#38598;&#25104;&#24102;&#26469;&#30340;&#26032;&#25361;&#25112;&#65292;&#24182;&#20998;&#26512;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#21644;&#28508;&#22312;&#38556;&#30861;&#12290;</title><link>http://arxiv.org/abs/2307.08925</link><description>&lt;p&gt;
&#32852;&#37030;&#24335;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65306;&#19968;&#20010;&#31435;&#22330;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Federated Large Language Model: A Position Paper. (arXiv:2307.08925v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08925
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#24335;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#32852;&#37030;&#23398;&#20064;&#23454;&#29616;&#20998;&#25955;&#25968;&#25454;&#30340;&#20849;&#21516;&#35757;&#32451;&#20849;&#20139;&#27169;&#22411;&#65292;&#20197;&#24212;&#23545;&#20844;&#20849;&#25968;&#25454;&#21487;&#29992;&#24615;&#30340;&#38480;&#21046;&#21644;&#31169;&#26377;&#25968;&#25454;&#30340;&#38544;&#31169;&#20445;&#25252;&#38656;&#27714;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#39044;&#35757;&#32451;&#12289;&#24494;&#35843;&#21644;&#25552;&#31034;&#24037;&#31243;&#36825;&#19977;&#20010;&#32452;&#20214;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#26045;&#31574;&#30053;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;FL&#21644;LLM&#38598;&#25104;&#24102;&#26469;&#30340;&#26032;&#25361;&#25112;&#65292;&#24182;&#20998;&#26512;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#21644;&#28508;&#22312;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#33719;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#24182;&#25214;&#21040;&#20102;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#65292;&#20294;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#24320;&#21457;&#26102;&#38754;&#20020;&#25361;&#25112;&#12290;&#36825;&#20123;&#25361;&#25112;&#28304;&#20110;&#20844;&#20849;&#39046;&#22495;&#25968;&#25454;&#21487;&#29992;&#24615;&#30340;&#21294;&#20047;&#20197;&#21450;&#23545;&#31169;&#26377;&#39046;&#22495;&#25968;&#25454;&#30340;&#38544;&#31169;&#20445;&#25252;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20316;&#20026;&#19968;&#39033;&#26377;&#21069;&#26223;&#30340;&#25216;&#26415;&#20986;&#29616;&#20102;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#20998;&#25955;&#25968;&#25454;&#30340;&#21516;&#26102;&#23454;&#29616;&#20849;&#21516;&#35757;&#32451;&#20849;&#20139;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#24335;LLM&#30340;&#27010;&#24565;&#65292;&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;&#32852;&#37030;&#24335;LLM&#39044;&#35757;&#32451;&#12289;&#32852;&#37030;&#24335;LLM&#24494;&#35843;&#21644;&#32852;&#37030;&#24335;LLM&#25552;&#31034;&#24037;&#31243;&#12290;&#23545;&#20110;&#27599;&#20010;&#32452;&#20214;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#30456;&#23545;&#20110;&#20256;&#32479;LLM&#35757;&#32451;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#20307;&#30340;&#24037;&#31243;&#31574;&#30053;&#26469;&#23454;&#26045;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;FL&#21644;LLM&#38598;&#25104;&#24102;&#26469;&#30340;&#26032;&#25361;&#25112;&#12290;&#25105;&#20204;&#20998;&#26512;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#30830;&#23450;&#21487;&#33021;&#30340;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
Large scale language models (LLM) have received significant attention and found diverse applications across various domains, but their development encounters challenges in real-world scenarios. These challenges arise due to the scarcity of public domain data availability and the need to maintain privacy with respect to private domain data. To address these issues, federated learning (FL) has emerged as a promising technology that enables collaborative training of shared models while preserving decentralized data. We propose the concept of federated LLM, which comprises three key components, i.e., federated LLM pre-training, federated LLM fine-tuning, and federated LLM prompt engineering. For each component, we discuss its advantage over traditional LLM training methods and propose specific engineering strategies for implementation. Furthermore, we explore the novel challenges introduced by the integration of FL and LLM. We analyze existing solutions and identify potential obstacles fac
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39046;&#22495;&#25193;&#23637;&#30340;ASTE&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#29983;&#25104;&#26041;&#27861;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.14434</link><description>&lt;p&gt;
&#38754;&#21521;&#39046;&#22495;&#25193;&#23637;&#30340;ASTE&#65306;&#37325;&#26032;&#23457;&#35270;&#24773;&#24863;&#19977;&#20803;&#32452;&#25552;&#21462;&#20013;&#30340;&#27867;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Domain-Expanded ASTE: Rethinking Generalization in Aspect Sentiment Triplet Extraction. (arXiv:2305.14434v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14434
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39046;&#22495;&#25193;&#23637;&#30340;ASTE&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#29983;&#25104;&#26041;&#27861;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#21521;&#39046;&#22495;&#25193;&#23637;&#30340;Aspect Sentiment Triplet Extraction (ASTE) &#26159;Aspect-Based Sentiment Analysis (ABSA) &#20013;&#30340;&#19968;&#20010;&#23376;&#20219;&#21153;&#65292;&#32771;&#34385;&#27599;&#20010;&#35266;&#28857;&#26415;&#35821;&#12289;&#23427;&#20204;&#34920;&#36798;&#30340;&#24773;&#24863;&#21450;&#30456;&#24212;&#30340;&#26041;&#38754;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20165;&#38480;&#20110;&#20004;&#20010;&#39046;&#22495;&#20869;&#30340;&#22330;&#26223;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39046;&#22495;&#25193;&#23637;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20197;&#24212;&#23545;&#39046;&#22495;&#20869;&#12289;&#39046;&#22495;&#38388;&#21644;&#36328;&#39046;&#22495;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#22522;&#20110;&#37202;&#24215;&#21644;&#21270;&#22918;&#21697;&#35780;&#35770;&#65292;&#26631;&#27880;&#20102;&#36229;&#36807;4000&#20010;&#25968;&#25454;&#26679;&#26412;&#26469;&#25903;&#25345;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23545;&#20116;&#31181;&#29616;&#26377;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;&#39046;&#22495;&#20869;&#21644;&#39046;&#22495;&#22806;&#30340;&#24615;&#33021;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#65292;&#20294;&#29983;&#25104;&#26041;&#27861;&#22312;&#39046;&#22495;&#27867;&#21270;&#26041;&#38754;&#20855;&#26377;&#24456;&#24378;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#12289;&#20195;&#30721;&#23454;&#29616;&#21644;&#27169;&#22411;&#22343;&#21487;&#22312;https://github.com/DAMO-NLP-SG/domain-expanded-aste &#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Aspect Sentiment Triplet Extraction (ASTE) is a subtask of Aspect-Based Sentiment Analysis (ABSA) that considers each opinion term, their expressed sentiment, and the corresponding aspect targets. However, existing methods are limited to the in-domain setting with two domains. Hence, we propose a domain-expanded benchmark to address the in-domain, out-of-domain and cross-domain settings. We support the new benchmark by annotating more than 4000 data samples for two new domains based on hotel and cosmetics reviews. Our analysis of five existing methods shows that while there is a significant gap between in-domain and out-of-domain performance, generative methods have a strong potential for domain generalization. Our datasets, code implementation and models are available at https://github.com/DAMO-NLP-SG/domain-expanded-aste .
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17475</link><description>&lt;p&gt;
&#36229;&#36234;&#36127;&#37319;&#26679;&#30340;&#39640;&#25928;&#20998;&#24067;&#24335;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#20063;&#31216;&#20026;&#23884;&#20837;&#65289;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#31867;&#20284;&#20110;Word2Vec&#31639;&#27861;&#20013;&#24341;&#20837;&#24182;&#22312;&#22810;&#20010;&#24037;&#20316;&#20013;&#37319;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#23454;&#29616;&#12290;&#20248;&#21270;&#35745;&#31639;&#30340;&#29942;&#39048;&#26159;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#35745;&#31639;&#65292;&#36825;&#38656;&#35201;&#19982;&#26679;&#26412;&#22823;&#23567;&#21576;&#20108;&#27425;&#27604;&#20363;&#30340;&#25805;&#20316;&#25968;&#12290;&#36825;&#31181;&#22797;&#26434;&#24230;&#19981;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#25152;&#20197;&#36127;&#37319;&#26679;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19982;&#26679;&#26412;&#22823;&#23567;&#32447;&#24615;&#30456;&#20851;&#30340;&#26102;&#38388;&#20869;&#33719;&#24471;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36127;&#37319;&#26679;&#20250;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#65292;&#22240;&#27492;&#35299;&#20915;&#30340;&#26159;&#19982;&#26368;&#21021;&#25552;&#20986;&#30340;&#19981;&#21516;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22312;&#20110;&#23637;&#31034;&#22914;&#20309;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#20174;&#32780;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23884;&#20837;&#36136;&#37327;&#21644;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#20248;&#20110;&#36127;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
&lt;/p&gt;</description></item></channel></rss>