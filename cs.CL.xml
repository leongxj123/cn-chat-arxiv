<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>NumeroLogic&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#23383;&#34920;&#31034;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#25968;&#23383;&#21069;&#21253;&#21547;&#25968;&#23383;&#30340;&#20301;&#25968;&#35745;&#25968;&#65292;&#20026;&#35821;&#35328;&#27169;&#22411;&#30340;&#25968;&#23383;&#25512;&#29702;&#33021;&#21147;&#25552;&#20379;&#20102;&#22686;&#24378;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#29983;&#25104;&#23454;&#38469;&#25968;&#23383;&#20043;&#21069;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2404.00459</link><description>&lt;p&gt;
NumeroLogic&#65306;&#22686;&#24378;LLMs&#25968;&#23383;&#25512;&#29702;&#30340;&#25968;&#23383;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00459
&lt;/p&gt;
&lt;p&gt;
NumeroLogic&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#23383;&#34920;&#31034;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#25968;&#23383;&#21069;&#21253;&#21547;&#25968;&#23383;&#30340;&#20301;&#25968;&#35745;&#25968;&#65292;&#20026;&#35821;&#35328;&#27169;&#22411;&#30340;&#25968;&#23383;&#25512;&#29702;&#33021;&#21147;&#25552;&#20379;&#20102;&#22686;&#24378;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#29983;&#25104;&#23454;&#38469;&#25968;&#23383;&#20043;&#21069;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25351;&#20986;&#65292;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#25968;&#20540;&#25968;&#25454;&#21644;&#25191;&#34892;&#31639;&#26415;&#36816;&#31639;&#26102;&#38754;&#20020;&#22256;&#38590;&#12290;&#25105;&#20204;&#20551;&#35774;&#36825;&#31181;&#38480;&#21046;&#37096;&#20998;&#24402;&#22240;&#20110;&#38750;&#30452;&#35266;&#30340;&#25991;&#26412;&#25968;&#23383;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#35843;&#25972;&#26041;&#27861;&#65292;&#21363;&#22312;&#27599;&#20010;&#25968;&#23383;&#21069;&#21253;&#21547;&#25968;&#23383;&#30340;&#20301;&#25968;&#35745;&#25968;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;"{2:42}"&#20195;&#26367;"42"&#20316;&#20026;&#26032;&#30340;&#26684;&#24335;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#31216;&#20026;NumeroLogic&#65292;&#23427;&#22312;&#25968;&#23383;&#29983;&#25104;&#20013;&#20316;&#20026;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#20379;&#20102;&#39069;&#22806;&#20248;&#21183;&#12290;&#36890;&#36807;&#35201;&#27714;&#27169;&#22411;&#39318;&#20808;&#32771;&#34385;&#25968;&#23383;&#30340;&#20301;&#25968;&#65292;&#23427;&#22686;&#24378;&#20102;&#29983;&#25104;&#23454;&#38469;&#25968;&#23383;&#20043;&#21069;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#25105;&#20204;&#20351;&#29992;&#31639;&#26415;&#20219;&#21153;&#26469;&#23637;&#31034;NumeroLogic&#26684;&#24335;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00459v1 Announce Type: new  Abstract: Language models struggle with handling numerical data and performing arithmetic operations. We hypothesize that this limitation can be partially attributed to non-intuitive textual numbers representation. When a digit is read or generated by a causal language model it does not know its place value (e.g. thousands vs. hundreds) until the entire number is processed. To address this issue, we propose a simple adjustment to how numbers are represented by including the count of digits before each number. For instance, instead of "42", we suggest using "{2:42}" as the new format. This approach, which we term NumeroLogic, offers an added advantage in number generation by serving as a Chain of Thought (CoT). By requiring the model to consider the number of digits first, it enhances the reasoning process before generating the actual number. We use arithmetic tasks to demonstrate the effectiveness of the NumeroLogic formatting. We further demonstr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#31639;&#26415;&#30005;&#36335;&#32422;&#26463;&#32534;&#30721;&#20026;&#22810;&#39033;&#24335;&#26041;&#31243;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#35745;&#31639;&#22312;&#26377;&#38480;&#22495;&#19978;&#35299;&#20915;&#22810;&#39033;&#24335;&#26041;&#31243;&#31995;&#32479;&#65292;&#20197;&#31934;&#30830;&#23450;&#20301;ZKP&#30005;&#36335;&#20013;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#38169;&#35823;&#12290;</title><link>https://arxiv.org/abs/2403.15676</link><description>&lt;p&gt;
AC4&#65306;&#29992;&#20110;ZKP&#20013;&#30005;&#36335;&#32422;&#26463;&#30340;&#20195;&#25968;&#35745;&#31639;&#26816;&#26597;&#22120;
&lt;/p&gt;
&lt;p&gt;
AC4: Algebraic Computation Checker for Circuit Constraints in ZKPs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15676
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#31639;&#26415;&#30005;&#36335;&#32422;&#26463;&#32534;&#30721;&#20026;&#22810;&#39033;&#24335;&#26041;&#31243;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#35745;&#31639;&#22312;&#26377;&#38480;&#22495;&#19978;&#35299;&#20915;&#22810;&#39033;&#24335;&#26041;&#31243;&#31995;&#32479;&#65292;&#20197;&#31934;&#30830;&#23450;&#20301;ZKP&#30005;&#36335;&#20013;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ZKP&#31995;&#32479;&#24050;&#32463;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#22312;&#24403;&#20195;&#23494;&#30721;&#23398;&#20013;&#21457;&#25381;&#30528;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290; Zk-SNARK&#21327;&#35758;&#20027;&#23548;&#20102;ZKP&#30340;&#20351;&#29992;&#65292;&#36890;&#24120;&#36890;&#36807;&#31639;&#26415;&#30005;&#36335;&#32534;&#31243;&#33539;&#24335;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#27424;&#32422;&#26463;&#25110;&#36807;&#32422;&#26463;&#30340;&#30005;&#36335;&#21487;&#33021;&#23548;&#33268;&#38169;&#35823;&#12290; &#27424;&#32422;&#26463;&#30340;&#30005;&#36335;&#25351;&#30340;&#26159;&#32570;&#20047;&#24517;&#35201;&#32422;&#26463;&#30340;&#30005;&#36335;&#65292;&#23548;&#33268;&#30005;&#36335;&#20013;&#20986;&#29616;&#24847;&#22806;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#23548;&#33268;&#39564;&#35777;&#32773;&#25509;&#21463;&#38169;&#35823;&#35265;&#35777;&#12290; &#36807;&#32422;&#26463;&#30340;&#30005;&#36335;&#26159;&#25351;&#32422;&#26463;&#36807;&#24230;&#30340;&#30005;&#36335;&#65292;&#23548;&#33268;&#30005;&#36335;&#32570;&#20047;&#24517;&#35201;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#23548;&#33268;&#39564;&#35777;&#32773;&#25509;&#21463;&#27809;&#26377;&#35265;&#35777;&#65292;&#20351;&#30005;&#36335;&#27627;&#26080;&#24847;&#20041;&#12290; &#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#25214;&#20986;ZKP&#30005;&#36335;&#20013;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#38169;&#35823;&#12290; &#35813;&#26041;&#27861;&#28041;&#21450;&#23558;&#31639;&#26415;&#30005;&#36335;&#32422;&#26463;&#32534;&#30721;&#20026;&#22810;&#39033;&#24335;&#26041;&#31243;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#35745;&#31639;&#22312;&#26377;&#38480;&#22495;&#19978;&#35299;&#20915;&#22810;&#39033;&#24335;&#26041;&#31243;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15676v1 Announce Type: cross  Abstract: ZKP systems have surged attention and held a fundamental role in contemporary cryptography. Zk-SNARK protocols dominate the ZKP usage, often implemented through arithmetic circuit programming paradigm. However, underconstrained or overconstrained circuits may lead to bugs. Underconstrained circuits refer to circuits that lack the necessary constraints, resulting in unexpected solutions in the circuit and causing the verifier to accept a bogus witness. Overconstrained circuits refer to circuits that are constrained excessively, resulting in the circuit lacking necessary solutions and causing the verifier to accept no witness, rendering the circuit meaningless. This paper introduces a novel approach for pinpointing two distinct types of bugs in ZKP circuits. The method involves encoding the arithmetic circuit constraints to polynomial equation systems and solving polynomial equation systems over a finite field by algebraic computation. T
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#24314;&#31569;&#22914;&#20309;&#24433;&#21709;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#26412;&#33021;&#21147;&#65292;&#21457;&#29616;&#20102;FFN-Wider&#21464;&#21387;&#22120;&#27169;&#22411;&#38477;&#20302;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#36129;&#29486;&#27604;&#65292;&#20174;&#32780;&#23548;&#33268;&#22522;&#26412;&#33021;&#21147;&#30340;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2403.02436</link><description>&lt;p&gt;
&#24314;&#31569;&#22914;&#20309;&#24433;&#21709;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#26412;&#33021;&#21147;&#65311;&#22522;&#20110;FFN-Wider&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How does Architecture Influence the Base Capabilities of Pre-trained Language Models? A Case Study Based on FFN-Wider Transformer Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#24314;&#31569;&#22914;&#20309;&#24433;&#21709;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#26412;&#33021;&#21147;&#65292;&#21457;&#29616;&#20102;FFN-Wider&#21464;&#21387;&#22120;&#27169;&#22411;&#38477;&#20302;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#36129;&#29486;&#27604;&#65292;&#20174;&#32780;&#23548;&#33268;&#22522;&#26412;&#33021;&#21147;&#30340;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#24378;&#22823;&#30340;&#22522;&#26412;&#33021;&#21147;&#65292;&#19981;&#20165;&#22312;&#20998;&#24067;&#24335;&#35821;&#35328;&#24314;&#27169;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#19988;&#22312;&#36229;&#20986;&#20998;&#24067;&#24335;&#35821;&#35328;&#24314;&#27169;&#12289;&#36801;&#31227;&#23398;&#20064;&#21644;&#23569;&#26679;&#26412;&#23398;&#20064;&#26041;&#38754;&#20063;&#23637;&#29616;&#20986;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;&#19982;&#29616;&#26377;&#30740;&#31350;&#20391;&#37325;&#20110;&#35268;&#27169;&#23545;&#22522;&#26412;&#33021;&#21147;&#30340;&#24433;&#21709;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#37325;&#28857;&#25918;&#22312;&#20102;&#26550;&#26500;&#23545;&#20854;&#24433;&#21709;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20851;&#24515;&#30340;&#26159;&#65306;&#24314;&#31569;&#22914;&#20309;&#24433;&#21709;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#26412;&#33021;&#21147;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#35299;&#37322;&#24182;&#36870;&#36716;FFN-Wider&#21464;&#21387;&#22120;&#30340;&#26550;&#26500;&#23548;&#33268;&#22522;&#26412;&#33021;&#21147;&#19979;&#38477;&#30340;&#24773;&#20917;&#65292;&#21147;&#27714;&#25552;&#20379;&#19968;&#20123;&#35265;&#35299;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#22810;&#22836;&#27880;&#24847;&#21147;&#65288;&#19968;&#31181;&#32452;&#21512;&#20989;&#25968;&#65289;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#24314;&#27169;&#30340;&#36129;&#29486;&#27604;&#26159;&#24433;&#21709;&#22522;&#26412;&#33021;&#21147;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;FFN-Wider&#21464;&#21387;&#22120;&#20943;&#23569;&#20102;&#36825;&#31181;&#32452;&#21512;&#20989;&#25968;&#30340;&#36129;&#29486;&#27604;&#65292;&#23548;&#33268;&#19968;&#31181;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02436v1 Announce Type: new  Abstract: Pre-trained language models have been proven to possess strong base capabilities, which not only excel in in-distribution language modeling but also show powerful abilities in out-of-distribution language modeling, transfer learning and few-shot learning. Unlike existing work focusing on the influence of scale on base capabilities, our work examines the influence of architecture on those. Specifically, our concern is: How does architecture influence the base capabilities of pre-trained language models? In this work, we attempt to explain and reverse the decline in base capabilities caused by the architecture of FFN-Wider Transformers, seeking to provide some insights. Through analysis, we found the contribution ratio of Multi-Head Attention (a combination function) to pre-trained language modeling is a key factor affecting base capabilities. FFN-Wider Transformers reduce the contribution ratio of this combination function, leading to a d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24494;&#35843;&#21644;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20004;&#31181;&#26041;&#27861;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#20302;&#39057;&#23454;&#20307;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24494;&#35843;&#26174;&#33879;&#25552;&#39640;&#20102;&#21508;&#31181;&#21463;&#27426;&#36814;&#31243;&#24230;&#30340;&#23454;&#20307;&#30340;&#24615;&#33021;&#65292;&#32780;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#26041;&#27861;&#21017;&#36229;&#36807;&#20102;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.01432</link><description>&lt;p&gt;
&#24494;&#35843;&#19982;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#29992;&#20110;&#19981;&#22826;&#27969;&#34892;&#30693;&#35782;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24494;&#35843;&#21644;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20004;&#31181;&#26041;&#27861;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#20302;&#39057;&#23454;&#20307;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24494;&#35843;&#26174;&#33879;&#25552;&#39640;&#20102;&#21508;&#31181;&#21463;&#27426;&#36814;&#31243;&#24230;&#30340;&#23454;&#20307;&#30340;&#24615;&#33021;&#65292;&#32780;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#26041;&#27861;&#21017;&#36229;&#36807;&#20102;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#35760;&#24518;&#20102;&#22823;&#37327;&#30340;&#20107;&#23454;&#30693;&#35782;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#21644;&#39046;&#22495;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#35266;&#23519;&#21040;&#24403;&#22788;&#29702;&#19981;&#22826;&#27969;&#34892;&#25110;&#20302;&#39057;&#27010;&#24565;&#21644;&#23454;&#20307;&#26102;&#65292;&#24615;&#33021;&#20250;&#19979;&#38477;&#65292;&#20363;&#22914;&#22312;&#39046;&#22495;&#29305;&#23450;&#24212;&#29992;&#20013;&#12290;&#26412;&#25991;&#25506;&#35752;&#21644;&#35780;&#20272;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#21644;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#65288;FT&#65289;&#23545;&#23450;&#21046;LLMs&#22788;&#29702;&#20302;&#39057;&#23454;&#20307;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;FT&#26174;&#33879;&#25552;&#21319;&#20102;&#21508;&#31181;&#21463;&#27426;&#36814;&#31243;&#24230;&#30340;&#23454;&#20307;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#21463;&#27426;&#36814;&#21644;&#26368;&#19981;&#21463;&#27426;&#36814;&#30340;&#32676;&#20307;&#20013;&#65292;&#32780;RAG&#36229;&#36234;&#20102;&#20854;&#20182;&#26041;&#27861;&#12290;&#21478;&#22806;&#65292;&#26816;&#32034;&#21644;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#30340;&#36827;&#27493;&#21152;&#24378;&#20102;RAG&#21644;FT&#26041;&#27861;&#30340;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01432v1 Announce Type: new  Abstract: Large language models (LLMs) memorize a vast amount of factual knowledge, exhibiting strong performance across diverse tasks and domains. However, it has been observed that the performance diminishes when dealing with less-popular or low-frequency concepts and entities, for example in domain specific applications. The two prominent approaches to enhance the performance of LLMs on low-frequent topics are: Retrieval Augmented Generation (RAG) and fine-tuning (FT) over synthetic data. This paper explores and evaluates the impact of RAG and FT on customizing LLMs in handling low-frequency entities on question answering task. Our findings indicate that FT significantly boosts the performance across entities of varying popularity, especially in the most and least popular groups, while RAG surpasses other methods. Additionally, the success of both RAG and FT approaches is amplified by advancements in retrieval and data augmentation techniques. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;ICON&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#25913;&#21892;&#25918;&#23556;&#23398;&#25253;&#21578;&#29983;&#25104;&#30340;&#25253;&#21578;&#38388;&#19968;&#33268;&#24615;&#65292;&#25552;&#21319;&#31995;&#32479;&#25429;&#25417;&#35821;&#20041;&#31561;&#25928;&#30149;&#21464;&#30456;&#20284;&#24615;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.12844</link><description>&lt;p&gt;
ICON&#65306;&#36890;&#36807;&#30149;&#21464;&#24863;&#30693;&#28151;&#21512;&#22686;&#24378;&#25913;&#21892;&#25918;&#23556;&#23398;&#25253;&#21578;&#29983;&#25104;&#30340;&#25253;&#21578;&#38388;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
ICON: Improving Inter-Report Consistency of Radiology Report Generation via Lesion-aware Mix-up Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12844
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;ICON&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#25913;&#21892;&#25918;&#23556;&#23398;&#25253;&#21578;&#29983;&#25104;&#30340;&#25253;&#21578;&#38388;&#19968;&#33268;&#24615;&#65292;&#25552;&#21319;&#31995;&#32479;&#25429;&#25417;&#35821;&#20041;&#31561;&#25928;&#30149;&#21464;&#30456;&#20284;&#24615;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25918;&#23556;&#23398;&#25253;&#21578;&#29983;&#25104;&#30340;&#20808;&#21069;&#30740;&#31350;&#22312;&#22686;&#21152;&#29983;&#25104;&#25253;&#21578;&#30340;&#20020;&#24202;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#26412;&#25991;&#24378;&#35843;&#20102;&#20854;&#24212;&#20855;&#22791;&#30340;&#21478;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#29305;&#36136;&#65292;&#21363;&#25253;&#21578;&#38388;&#19968;&#33268;&#24615;&#65292;&#25351;&#30340;&#26159;&#23545;&#35821;&#20041;&#19978;&#31561;&#25928;&#30340;X&#23556;&#32447;&#29031;&#29255;&#29983;&#25104;&#19968;&#33268;&#24615;&#25253;&#21578;&#30340;&#33021;&#21147;&#12290;ICON&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#25913;&#21892;&#25918;&#23556;&#23398;&#25253;&#21578;&#29983;&#25104;&#30340;&#25253;&#21578;&#38388;&#19968;&#33268;&#24615;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12844v1 Announce Type: cross  Abstract: Previous research on radiology report generation has made significant progress in terms of increasing the clinical accuracy of generated reports. In this paper, we emphasize another crucial quality that it should possess, i.e., inter-report consistency, which refers to the capability of generating consistent reports for semantically equivalent radiographs. This quality is even of greater significance than the overall report accuracy in terms of ensuring the system's credibility, as a system prone to providing conflicting results would severely erode users' trust. Regrettably, existing approaches struggle to maintain inter-report consistency, exhibiting biases towards common patterns and susceptibility to lesion variants. To address this issue, we propose ICON, which improves the inter-report consistency of radiology report generation. Aiming at enhancing the system's ability to capture the similarities in semantically equivalent lesion
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#21508;&#31181;&#36328;&#35821;&#35328;&#35789;&#27719;&#36866;&#24212;&#26041;&#27861;&#23545;&#25552;&#39640;&#29983;&#25104;LLM&#25512;&#29702;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.10712</link><description>&lt;p&gt;
&#19968;&#39033;&#20851;&#20110;&#36328;&#35821;&#35328;&#35789;&#27719;&#36866;&#24212;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;LLM&#25512;&#29702;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Generative LLM Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10712
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#21508;&#31181;&#36328;&#35821;&#35328;&#35789;&#27719;&#36866;&#24212;&#26041;&#27861;&#23545;&#25552;&#39640;&#29983;&#25104;LLM&#25512;&#29702;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10712v1 &#36890;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#26368;&#20808;&#36827;&#30340;&#29983;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#21457;&#23637;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#33521;&#35821;&#20026;&#20013;&#24515;&#30340;&#20998;&#35789;&#22120;&#12289;&#35789;&#27719;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#12290;&#23613;&#31649;&#19968;&#20123;LLMs&#20855;&#26377;&#22810;&#35821;&#35328;&#33021;&#21147;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#29983;&#25104;&#33521;&#35821;&#20197;&#22806;&#30340;&#20854;&#20182;&#35821;&#35328;&#26102;&#65292;&#23427;&#20204;&#30340;&#25512;&#29702;&#25928;&#29575;&#20250;&#19979;&#38477;&#12290;&#36825;&#23548;&#33268;&#25512;&#29702;&#26102;&#38388;&#21644;&#25104;&#26412;&#22686;&#21152;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#36328;&#35821;&#35328;&#35789;&#27719;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#27169;&#22411;&#35843;&#25972;&#21040;&#30446;&#26631;&#35821;&#35328;&#65292;&#26088;&#22312;&#25552;&#39640;&#19979;&#28216;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#25552;&#39640;&#29983;&#25104;LLM&#25512;&#29702;&#25928;&#29575;&#30340;&#26377;&#25928;&#24615;&#23578;&#26410;&#24471;&#21040;&#25506;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#20116;&#31181;&#29983;&#25104;LLMs&#65288;&#21253;&#25324;&#21333;&#35821;&#21644;&#22810;&#35821;&#27169;&#22411;&#65289;&#22312;&#22235;&#31181;&#35821;&#35328;&#31867;&#22411;&#22810;&#26679;&#19988;&#22235;&#31181;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#21508;&#31181;&#36328;&#35821;&#35328;&#35789;&#27719;&#36866;&#24212;&#26041;&#27861;&#30340;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10712v1 Announce Type: cross  Abstract: The development of state-of-the-art generative large language models (LLMs) disproportionately relies on English-centric tokenizers, vocabulary and pre-training data. Despite the fact that some LLMs have multilingual capabilities, recent studies have shown that their inference efficiency deteriorates when generating text in languages other than English. This results in increased inference time and costs. Cross-lingual vocabulary adaptation methods have been proposed for adapting models to a target language aiming to improve downstream performance. However, the effectiveness of these methods on increasing inference efficiency of generative LLMs has yet to be explored. In this paper, we perform an empirical study of various cross-lingual vocabulary adaptation methods on five generative LLMs (including monolingual and multilingual models) across four typologically-diverse languages and four natural language understanding tasks. We find th
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;&#26469;&#30740;&#31350;LLM&#21644;&#20154;&#31867;&#35009;&#21028;&#30340;&#20559;&#35265;&#65292;&#25581;&#31034;&#20154;&#31867;&#21644;LLM&#35009;&#21028;&#22312;&#38754;&#23545;&#24178;&#25200;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;&#24378;&#35843;&#35780;&#20272;&#29616;&#26377;LLM&#24615;&#33021;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.10669</link><description>&lt;p&gt;
&#20154;&#31867;&#36824;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#35009;&#21028;&#65311;&#19968;&#39033;&#20851;&#20110;&#21028;&#20915;&#20559;&#35265;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Humans or LLMs as the Judge? A Study on Judgement Biases
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10669
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;&#26469;&#30740;&#31350;LLM&#21644;&#20154;&#31867;&#35009;&#21028;&#30340;&#20559;&#35265;&#65292;&#25581;&#31034;&#20154;&#31867;&#21644;LLM&#35009;&#21028;&#22312;&#38754;&#23545;&#24178;&#25200;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;&#24378;&#35843;&#35780;&#20272;&#29616;&#26377;LLM&#24615;&#33021;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#20154;&#31867;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20316;&#20026;&#35009;&#21028;&#65288;&#21363;&#20154;&#31867;&#21644;LLM&#20316;&#20026;&#35009;&#21028;&#65289;&#26469;&#35780;&#20272;&#29616;&#26377;LLM&#24615;&#33021;&#30340;&#20570;&#27861;&#36817;&#26469;&#22791;&#21463;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#21516;&#26102;&#21487;&#33021;&#24341;&#20837;&#20154;&#31867;&#21644;LLM&#35009;&#21028;&#30340;&#28508;&#22312;&#20559;&#35265;&#65292;&#36136;&#30097;&#35780;&#20272;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#30740;&#31350;LLM&#21644;&#20154;&#31867;&#35009;&#21028;&#30340;5&#31181;&#20559;&#35265;&#12290;&#25105;&#20204;&#25972;&#29702;&#20102;&#19968;&#20010;&#21253;&#21547;142&#20010;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#65292;&#28041;&#21450;&#20462;&#35746;&#30340;&#24067;&#21346;&#22982;&#20998;&#31867;&#27861;&#65292;&#24182;&#36827;&#34892;&#20102;&#25104;&#21315;&#19978;&#19975;&#27425;&#30340;&#20154;&#31867;&#21644;LLM&#35780;&#20272;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20154;&#31867;&#21644;LLM&#35009;&#21028;&#22312;&#19981;&#21516;&#31243;&#24230;&#19978;&#37117;&#23481;&#26131;&#21463;&#21040;&#24178;&#25200;&#65292;&#21363;&#20351;&#26368;&#23574;&#31471;&#30340;&#35009;&#21028;&#20063;&#23384;&#22312;&#30456;&#24403;&#22823;&#30340;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21033;&#29992;&#20182;&#20204;&#30340;&#24369;&#28857;&#23545;LLM&#35009;&#21028;&#36827;&#34892;&#25915;&#20987;&#12290;&#24076;&#26395;&#25105;&#20204;&#30340;&#24037;&#20316;&#33021;&#25552;&#37266;&#31038;&#32676;&#20851;&#20110;&#20154;&#31867;&#21644;LLM&#20316;&#20026;&#35009;&#21028;&#22312;&#38754;&#23545;&#24178;&#25200;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;&#20197;&#21450;&#21457;&#23637;&#30340;&#32039;&#36843;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10669v1 Announce Type: new  Abstract: Adopting human and large language models (LLM) as judges (\textit{a.k.a} human- and LLM-as-a-judge) for evaluating the performance of existing LLMs has recently gained attention. Nonetheless, this approach concurrently introduces potential biases from human and LLM judges, questioning the reliability of the evaluation results. In this paper, we propose a novel framework for investigating 5 types of biases for LLM and human judges. We curate a dataset with 142 samples referring to the revised Bloom's Taxonomy and conduct thousands of human and LLM evaluations. Results show that human and LLM judges are vulnerable to perturbations to various degrees, and that even the most cutting-edge judges possess considerable biases. We further exploit their weakness and conduct attacks on LLM judges. We hope that our work can notify the community of the vulnerability of human- and LLM-as-a-judge against perturbations, as well as the urgency of develop
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#26080;&#30417;&#30563;&#25688;&#35201;&#30340;&#26368;&#26032;&#25216;&#26415;&#21644;&#27169;&#22411;&#65292;&#21253;&#25324;&#25277;&#21462;&#24335;&#12289;&#29983;&#25104;&#24335;&#21644;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26041;&#27861;&#30340;&#20998;&#31867;&#27861;&#12290;&#26412;&#25991;&#36824;&#20171;&#32461;&#20102;&#19968;&#20123;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.11231</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#25688;&#35201;&#30340;&#26368;&#26032;&#36235;&#21183;
&lt;/p&gt;
&lt;p&gt;
Recent Trends in Unsupervised Summarization. (arXiv:2305.11231v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#26080;&#30417;&#30563;&#25688;&#35201;&#30340;&#26368;&#26032;&#25216;&#26415;&#21644;&#27169;&#22411;&#65292;&#21253;&#25324;&#25277;&#21462;&#24335;&#12289;&#29983;&#25104;&#24335;&#21644;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26041;&#27861;&#30340;&#20998;&#31867;&#27861;&#12290;&#26412;&#25991;&#36824;&#20171;&#32461;&#20102;&#19968;&#20123;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#25688;&#35201;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#25688;&#35201;&#27169;&#22411;&#12290;&#26412;&#32508;&#36848;&#28085;&#30422;&#20102;&#29992;&#20110;&#26080;&#30417;&#30563;&#25688;&#35201;&#30340;&#19981;&#21516;&#25216;&#26415;&#21644;&#27169;&#22411;&#12290;&#25105;&#20204;&#28085;&#30422;&#20102;&#25277;&#21462;&#24335;&#12289;&#29983;&#25104;&#24335;&#21644;&#28151;&#21512;&#27169;&#22411;&#20197;&#21450;&#29992;&#20110;&#23454;&#29616;&#26080;&#30417;&#30563;&#25688;&#35201;&#30340;&#31574;&#30053;&#12290;&#23613;&#31649;&#26412;&#32508;&#36848;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#26368;&#26032;&#30740;&#31350;&#65292;&#20294;&#25105;&#20204;&#20063;&#20171;&#32461;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#30740;&#31350;&#23545;&#26080;&#30417;&#30563;&#35757;&#32451;&#30340;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#24403;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#21040;&#20102;&#19968;&#20123;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised summarization is a powerful technique that enables training summarizing models without requiring labeled datasets. This survey covers different recent techniques and models used for unsupervised summarization. We cover extractive, abstractive, and hybrid models and strategies used to achieve unsupervised summarization. While the main focus of this survey is on recent research, we also cover some of the important previous research. We additionally introduce a taxonomy, classifying different research based on their approach to unsupervised training. Finally, we discuss the current approaches and mention some datasets and evaluation methods.
&lt;/p&gt;</description></item></channel></rss>