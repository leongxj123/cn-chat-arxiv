<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#33976;&#39311;&#23545;&#27604;&#35299;&#30721;&#65288;DCD&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#23545;&#27604;&#25552;&#31034;&#19982;&#33976;&#39311;&#25216;&#26415;&#65292;&#26377;&#25928;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#23545;&#27604;&#35299;&#30721;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.14874</link><description>&lt;p&gt;
&#33976;&#39311;&#23545;&#27604;&#35299;&#30721;&#65306;&#21033;&#29992;&#23545;&#27604;&#35299;&#30721;&#21644;&#33976;&#39311;&#25552;&#21319;LLM&#30340;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14874
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#33976;&#39311;&#23545;&#27604;&#35299;&#30721;&#65288;DCD&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#23545;&#27604;&#25552;&#31034;&#19982;&#33976;&#39311;&#25216;&#26415;&#65292;&#26377;&#25928;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#23545;&#27604;&#35299;&#30721;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33976;&#39311;&#23545;&#27604;&#35299;&#30721;&#65288;DCD&#65289;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#19982;&#20808;&#21069;&#20381;&#36182;&#20110;&#36739;&#23567;&#30340;&#19994;&#20313;&#27169;&#22411;&#25110;&#38544;&#34255;&#29366;&#24577;&#24046;&#24322;&#20998;&#26512;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;DCD&#37319;&#29992;&#20102;&#23545;&#27604;&#24335;&#24605;&#32500;&#24341;&#23548;&#21644;&#20808;&#36827;&#30340;&#33976;&#39311;&#25216;&#26415;&#65292;&#21253;&#25324;Dropout&#21644;&#37327;&#21270;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#23545;&#27604;&#35299;&#30721;&#65288;CD&#65289;&#30340;&#23616;&#38480;&#24615;&#65292;&#21518;&#32773;&#36890;&#24120;&#38656;&#35201;&#19987;&#23478;&#21644;&#19994;&#20313;&#27169;&#22411;&#65292;&#20174;&#32780;&#22686;&#21152;&#35745;&#31639;&#36164;&#28304;&#38656;&#27714;&#12290;&#36890;&#36807;&#23558;&#23545;&#27604;&#25552;&#31034;&#19982;&#33976;&#39311;&#30456;&#32467;&#21512;&#65292;DCD&#28040;&#38500;&#20102;&#23545;&#19994;&#20313;&#27169;&#22411;&#30340;&#38656;&#27714;&#24182;&#20943;&#23569;&#20102;&#20869;&#23384;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;DCD&#26174;&#33879;&#22686;&#24378;&#20102;LLM&#22312;&#21508;&#31181;&#25512;&#29702;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#65292;&#22312;GSM8K&#21644;StrategyQA&#25968;&#25454;&#38598;&#20013;&#22343;&#36229;&#36807;&#20102;CD&#21644;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14874v1 Announce Type: cross  Abstract: We propose a straightforward approach called Distillation Contrastive Decoding (DCD) to enhance the reasoning capabilities of Large Language Models (LLMs) during inference. In contrast to previous approaches that relied on smaller amateur models or analysis of hidden state differences, DCD employs Contrastive Chain-of-thought Prompting and advanced distillation techniques, including Dropout and Quantization. This approach effectively addresses the limitations of Contrastive Decoding (CD), which typically requires both an expert and an amateur model, thus increasing computational resource demands. By integrating contrastive prompts with distillation, DCD obviates the need for an amateur model and reduces memory usage. Our evaluations demonstrate that DCD significantly enhances LLM performance across a range of reasoning benchmarks, surpassing both CD and existing methods in the GSM8K and StrategyQA datasets.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#20195;&#29702;&#35843;&#25972;&#30340;&#36731;&#37327;&#32423;&#35299;&#30721;&#26102;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#23567;&#22411;&#35843;&#25972;&#21518;&#30340;LM&#30340;&#39044;&#27979;&#19982;&#26410;&#35843;&#25972;LM&#30340;&#39044;&#27979;&#20043;&#38388;&#30340;&#24046;&#24322;&#26469;&#35843;&#25972;&#22823;&#22411;&#39044;&#35757;&#32451;LM&#30340;&#39044;&#27979;&#65292;&#20174;&#32780;&#23454;&#29616;&#36164;&#28304;&#33410;&#32422;&#21644;&#20445;&#30041;&#26356;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#22909;&#22788;&#12290;</title><link>https://arxiv.org/abs/2401.08565</link><description>&lt;p&gt;
&#36890;&#36807;&#20195;&#29702;&#35843;&#25972;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tuning Language Models by Proxy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.08565
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#20195;&#29702;&#35843;&#25972;&#30340;&#36731;&#37327;&#32423;&#35299;&#30721;&#26102;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#23567;&#22411;&#35843;&#25972;&#21518;&#30340;LM&#30340;&#39044;&#27979;&#19982;&#26410;&#35843;&#25972;LM&#30340;&#39044;&#27979;&#20043;&#38388;&#30340;&#24046;&#24322;&#26469;&#35843;&#25972;&#22823;&#22411;&#39044;&#35757;&#32451;LM&#30340;&#39044;&#27979;&#65292;&#20174;&#32780;&#23454;&#29616;&#36164;&#28304;&#33410;&#32422;&#21644;&#20445;&#30041;&#26356;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#19968;&#33324;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22987;&#32456;&#21463;&#30410;&#20110;&#36827;&#19968;&#27493;&#35843;&#25972;&#20197;&#26356;&#22909;&#22320;&#23454;&#29616;&#25152;&#38656;&#30340;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#35843;&#25972;&#36825;&#20123;&#27169;&#22411;&#21464;&#24471;&#36234;&#26469;&#36234;&#28040;&#32791;&#36164;&#28304;&#65292;&#25110;&#32773;&#22312;&#27169;&#22411;&#26435;&#37325;&#26159;&#31169;&#26377;&#30340;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20195;&#29702;&#35843;&#25972;&#65292;&#36825;&#26159;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#35299;&#30721;&#26102;&#31639;&#27861;&#65292;&#23427;&#22312;&#40657;&#30418;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36816;&#34892;&#65292;&#20197;&#23454;&#29616;&#19982;&#30452;&#25509;&#35843;&#25972;&#30456;&#21516;&#30340;&#30446;&#30340;&#65292;&#20294;&#21482;&#35775;&#38382;&#20854;&#22312;&#36755;&#20986;&#35789;&#27719;&#19978;&#30340;&#39044;&#27979;&#65292;&#32780;&#19981;&#26159;&#20854;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35843;&#25972;&#20102;&#19968;&#20010;&#36739;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#28982;&#21518;&#23558;&#32463;&#36807;&#35843;&#25972;&#21644;&#26410;&#32463;&#35843;&#25972;&#30340;&#23567;&#27169;&#22411;&#30340;&#39044;&#27979;&#20043;&#38388;&#30340;&#24046;&#24322;&#24212;&#29992;&#20110;&#23558;&#26356;&#22823;&#30340;&#26410;&#35843;&#25972;&#27169;&#22411;&#30340;&#21407;&#22987;&#39044;&#27979;&#36716;&#31227;&#21040;&#35843;&#25972;&#26041;&#21521;&#65292;&#21516;&#26102;&#20445;&#30041;&#36739;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#22909;&#22788;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#24403;&#25105;&#20204;&#20351;&#29992;&#20165;&#20026;7B&#22823;&#23567;&#30340;&#20195;&#29702;&#23545;Llama2-70B&#24212;&#29992;&#20195;&#29702;&#35843;&#25972;&#26102;&#65292;&#25105;&#20204;&#21487;&#20197;&#20851;&#38381;88% Llama2-70B &#19982;&#20854;&#30495;&#27491;&#35843;&#25972;&#36807;&#30340;&#32842;&#22825;&#29256;&#26412;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.08565v2 Announce Type: replace  Abstract: Despite the general capabilities of large pretrained language models, they consistently benefit from further adaptation to better achieve desired behaviors. However, tuning these models has become increasingly resource-intensive, or impossible when model weights are private. We introduce proxy-tuning, a lightweight decoding-time algorithm that operates on top of black-box LMs to achieve the same end as direct tuning, but by accessing only its predictions over the output vocabulary, not its parameters. Our method tunes a smaller LM, then applies the difference between the predictions of the small tuned and untuned LMs to shift the original predictions of the larger untuned model in the direction of tuning, while retaining the benefits of larger-scale pretraining. In experiments, when we apply proxy-tuning to Llama2-70B using proxies of only 7B size, we can close 88% of the gap between Llama2-70B and its truly-tuned chat version, when 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#26799;&#24230;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#21512;&#24182;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#33021;&#22815;&#20943;&#23569;&#26799;&#24230;&#19981;&#21305;&#37197;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#21512;&#24182;&#30340;&#24615;&#33021;&#24182;&#23545;&#36229;&#21442;&#25968;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12808</link><description>&lt;p&gt;
&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#26799;&#24230;&#21305;&#37197;&#30340;&#27169;&#22411;&#21512;&#24182;
&lt;/p&gt;
&lt;p&gt;
Model Merging by Uncertainty-Based Gradient Matching. (arXiv:2310.12808v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#26799;&#24230;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#21512;&#24182;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#33021;&#22815;&#20943;&#23569;&#26799;&#24230;&#19981;&#21305;&#37197;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#21512;&#24182;&#30340;&#24615;&#33021;&#24182;&#23545;&#36229;&#21442;&#25968;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#21442;&#25968;&#30340;&#21152;&#26435;&#24179;&#22343;&#26469;&#21512;&#24182;&#65292;&#20294;&#20026;&#20160;&#20040;&#20250;&#36215;&#20316;&#29992;&#65292;&#20160;&#20040;&#24773;&#20917;&#19979;&#20250;&#22833;&#36133;&#65311;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23558;&#21152;&#26435;&#24179;&#22343;&#30340;&#19981;&#20934;&#30830;&#24615;&#19982;&#26799;&#24230;&#19981;&#21305;&#37197;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#20943;&#23569;&#19981;&#21305;&#37197;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#36825;&#31181;&#32852;&#31995;&#36824;&#25581;&#31034;&#20102;&#20854;&#20182;&#26041;&#26696;&#65288;&#22914;&#24179;&#22343;&#20540;&#12289;&#20219;&#21153;&#31639;&#26415;&#21644;Fisher&#21152;&#26435;&#24179;&#22343;&#65289;&#20013;&#30340;&#38544;&#21547;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#26041;&#38754;&#37117;&#22312;&#24615;&#33021;&#21644;&#36229;&#21442;&#25968;&#40065;&#26834;&#24615;&#26041;&#38754;&#24471;&#21040;&#20102;&#19968;&#33268;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Models trained on different datasets can be merged by a weighted-averaging of their parameters, but why does it work and when can it fail? Here, we connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a new uncertainty-based scheme to improve the performance by reducing the mismatch. The connection also reveals implicit assumptions in other schemes such as averaging, task arithmetic, and Fisher-weighted averaging. Our new method gives consistent improvements for large language models and vision transformers, both in terms of performance and robustness to hyperparameters.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SPICED&#30340;&#26032;&#38395;&#30456;&#20284;&#24615;&#26816;&#27979;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#19971;&#20010;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#26032;&#38395;&#12290;</title><link>http://arxiv.org/abs/2309.13080</link><description>&lt;p&gt;
SPICED: &#20855;&#26377;&#22810;&#20010;&#20027;&#39064;&#21644;&#22797;&#26434;&#31243;&#24230;&#30340;&#26032;&#38395;&#30456;&#20284;&#24615;&#26816;&#27979;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
SPICED: News Similarity Detection Dataset with Multiple Topics and Complexity Levels. (arXiv:2309.13080v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13080
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SPICED&#30340;&#26032;&#38395;&#30456;&#20284;&#24615;&#26816;&#27979;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#19971;&#20010;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#26032;&#38395;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#20351;&#29992;&#26234;&#33021;&#31995;&#32479;&#26469;&#26816;&#27979;&#26032;&#38395;&#25991;&#31456;&#20013;&#30340;&#20887;&#20313;&#20449;&#24687;&#24050;&#32463;&#21464;&#24471;&#38750;&#24120;&#26222;&#36941;&#65292;&#20197;&#22686;&#24378;&#29992;&#25143;&#20307;&#39564;&#65292;&#23588;&#20854;&#26159;&#38543;&#30528;&#26032;&#38395;&#23186;&#20307;&#30340;&#34028;&#21187;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#26032;&#38395;&#30340;&#24322;&#36136;&#24615;&#21487;&#33021;&#23548;&#33268;&#36825;&#20123;&#31995;&#32479;&#20013;&#30340;&#34394;&#20551;&#21457;&#29616;&#65306;&#31616;&#21333;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#27604;&#22914;&#19968;&#23545;&#26032;&#38395;&#26159;&#21542;&#37117;&#28041;&#21450;&#25919;&#27835;&#38382;&#39064;&#65292;&#21487;&#20197;&#25552;&#20379;&#24378;&#22823;&#20294;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#19979;&#28216;&#24615;&#33021;&#12290;&#23558;&#26032;&#38395;&#30456;&#20284;&#24615;&#25968;&#25454;&#38598;&#20998;&#21106;&#25104;&#20027;&#39064;&#21487;&#20197;&#36890;&#36807;&#24378;&#21046;&#27169;&#22411;&#23398;&#20064;&#22914;&#20309;&#22312;&#26356;&#29421;&#31364;&#30340;&#39046;&#22495;&#20013;&#21306;&#20998;&#26174;&#33879;&#29305;&#24449;&#26469;&#25913;&#36827;&#36825;&#20123;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#36825;&#38656;&#35201;&#23384;&#22312;&#30446;&#21069;&#32570;&#20047;&#30340;&#19987;&#39064;&#29305;&#23450;&#25968;&#25454;&#38598;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30456;&#20284;&#26032;&#38395;&#25968;&#25454;&#38598;SPICED&#65292;&#20854;&#20013;&#21253;&#25324;&#19971;&#20010;&#20027;&#39064;&#65306;&#29359;&#32618;&#19982;&#27861;&#24459;&#12289;&#25991;&#21270;&#19982;&#23089;&#20048;&#12289;&#28798;&#38590;&#19982;&#20107;&#25925;&#12289;&#32463;&#27982;&#19982;&#21830;&#19994;&#12289;&#25919;&#27835;&#19982;&#20914;&#31361;&#12289;&#31185;&#23398;&#19982;&#25216;&#26415;&#20197;&#21450;&#20307;&#32946;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#26032;&#38395;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays, the use of intelligent systems to detect redundant information in news articles has become especially prevalent with the proliferation of news media outlets in order to enhance user experience. However, the heterogeneous nature of news can lead to spurious findings in these systems: Simple heuristics such as whether a pair of news are both about politics can provide strong but deceptive downstream performance. Segmenting news similarity datasets into topics improves the training of these models by forcing them to learn how to distinguish salient characteristics under more narrow domains. However, this requires the existence of topic-specific datasets, which are currently lacking. In this article, we propose a new dataset of similar news, SPICED, which includes seven topics: Crime &amp; Law, Culture &amp; Entertainment, Disasters &amp; Accidents, Economy &amp; Business, Politics &amp; Conflicts, Science &amp; Technology, and Sports. Futhermore, we present four distinct approaches for generating news 
&lt;/p&gt;</description></item></channel></rss>