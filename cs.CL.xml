<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;StateFlow&#30340;&#26032;&#39062;LLM&#20219;&#21153;&#35299;&#20915;&#33539;&#24335;&#65292;&#23558;&#22797;&#26434;&#20219;&#21153;&#35299;&#20915;&#36807;&#31243;&#27010;&#24565;&#21270;&#20026;&#29366;&#24577;&#26426;&#65292;&#36890;&#36807;&#29366;&#24577;&#36716;&#25442;&#30830;&#20445;LLM&#21709;&#24212;&#30340;&#28165;&#26224;&#36319;&#36394;&#21644;&#31649;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.11322</link><description>&lt;p&gt;
&#20351;&#29992;StateFlow&#22686;&#24378;LLM&#20219;&#21153;&#35299;&#20915;&#33021;&#21147;&#36890;&#36807;&#29366;&#24577;&#39537;&#21160;&#24037;&#20316;&#27969;
&lt;/p&gt;
&lt;p&gt;
StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11322
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;StateFlow&#30340;&#26032;&#39062;LLM&#20219;&#21153;&#35299;&#20915;&#33539;&#24335;&#65292;&#23558;&#22797;&#26434;&#20219;&#21153;&#35299;&#20915;&#36807;&#31243;&#27010;&#24565;&#21270;&#20026;&#29366;&#24577;&#26426;&#65292;&#36890;&#36807;&#29366;&#24577;&#36716;&#25442;&#30830;&#20445;LLM&#21709;&#24212;&#30340;&#28165;&#26224;&#36319;&#36394;&#21644;&#31649;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#30340;&#36235;&#21183;&#26085;&#30410;&#26126;&#26174;&#65292;&#20363;&#22914;&#38656;&#35201;&#19968;&#31995;&#21015;&#25805;&#20316;&#21644;&#19982;&#24037;&#20855;&#29615;&#22659;&#21160;&#24577;&#20132;&#20114;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;StateFlow&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;LLM&#30340;&#20219;&#21153;&#27714;&#35299;&#33539;&#24335;&#65292;&#23558;&#30001;LLM&#25903;&#25345;&#30340;&#22797;&#26434;&#20219;&#21153;&#35299;&#20915;&#36807;&#31243;&#27010;&#24565;&#21270;&#20026;&#29366;&#24577;&#26426;&#12290;&#36890;&#36807;&#27491;&#30830;&#26500;&#24314;&#29366;&#24577;&#21644;&#23450;&#20041;&#29366;&#24577;&#36716;&#25442;&#65292;StateFlow&#30830;&#23450;&#20102;&#20219;&#21153;&#27714;&#35299;&#30340;&#36827;&#23637;&#65292;&#30830;&#20445;&#28165;&#26224;&#36319;&#36394;&#21644;&#31649;&#29702;LLM&#22312;&#25972;&#20010;&#20219;&#21153;&#27714;&#35299;&#36807;&#31243;&#20013;&#30340;&#21709;&#24212;&#12290;&#22312;&#27599;&#20010;&#29366;&#24577;&#20013;&#65292;StateFlow&#20801;&#35768;&#25191;&#34892;&#19968;&#31995;&#21015;&#21160;&#20316;&#65292;&#19981;&#20165;&#21253;&#25324;&#26681;&#25454;&#29305;&#23450;&#25552;&#31034;&#25351;&#23548;&#29983;&#25104;LLM&#21709;&#24212;&#65292;&#36824;&#21253;&#25324;&#26681;&#25454;&#38656;&#35201;&#21033;&#29992;&#22806;&#37096;&#24037;&#20855;&#12290;&#29366;&#24577;&#36716;&#25442;&#30001;LLM&#20570;&#20986;&#30340;&#29305;&#23450;&#35268;&#21017;&#25110;&#20915;&#31574;&#25511;&#21046;&#65292;&#20801;&#35768;&#36890;&#36807;&#20219;&#21153;&#30340;&#39044;&#23450;&#20041;StateFlow&#27169;&#22411;&#21160;&#24577;&#33258;&#36866;&#24212;&#22320;&#36827;&#34892;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11322v1 Announce Type: cross  Abstract: It is a notable trend to use Large Language Models (LLMs) to tackle complex tasks, e.g., tasks that require a sequence of actions and dynamic interaction with tools and environments. In this paper, we propose StateFlow, a novel LLM-based task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines. With proper construction of states and definition of state transitions, StateFlow grounds the progress of task-solving, ensuring clear tracking and management of LLMs' responses throughout the task-solving process. Within each state, StateFlow allows execution of a series of actions, involving not only the generation of LLM's responses guided by a specific prompt, but also the utilization of external tools as needed. State transitions are controlled by specific rules or decisions made by the LLM, allowing for a dynamic and adaptive progression through the task's pre-defined StateFlow model. Evalua
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;CodeAttack&#26694;&#26550;&#29992;&#20110;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#27867;&#21270;&#65292;&#30740;&#31350;&#21457;&#29616;GPT-4&#12289;Claude-2&#21644;Llama-2&#31995;&#21015;&#31561;&#26368;&#26032;&#27169;&#22411;&#23384;&#22312;&#20195;&#30721;&#36755;&#20837;&#30340;&#23433;&#20840;&#28431;&#27934;&#12290;</title><link>https://arxiv.org/abs/2403.07865</link><description>&lt;p&gt;
&#36890;&#36807;&#20195;&#30721;&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#27867;&#21270;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Exploring Safety Generalization Challenges of Large Language Models via Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;CodeAttack&#26694;&#26550;&#29992;&#20110;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#27867;&#21270;&#65292;&#30740;&#31350;&#21457;&#29616;GPT-4&#12289;Claude-2&#21644;Llama-2&#31995;&#21015;&#31561;&#26368;&#26032;&#27169;&#22411;&#23384;&#22312;&#20195;&#30721;&#36755;&#20837;&#30340;&#23433;&#20840;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#24102;&#26469;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#30340;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#20063;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#28508;&#22312;&#35823;&#29992;&#30340;&#25285;&#24551;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;CodeAttack&#65292;&#19968;&#20010;&#23558;&#33258;&#28982;&#35821;&#35328;&#36755;&#20837;&#36716;&#25442;&#20026;&#20195;&#30721;&#36755;&#20837;&#30340;&#26694;&#26550;&#65292;&#20026;&#27979;&#35797;LLMs&#30340;&#23433;&#20840;&#27867;&#21270;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29615;&#22659;&#12290;&#25105;&#20204;&#23545;&#21253;&#25324;GPT-4&#12289;Claude-2&#21644;Llama-2&#31995;&#21015;&#22312;&#20869;&#30340;&#26368;&#26032;LLMs&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#23545;&#20110;&#20195;&#30721;&#36755;&#20837;&#23384;&#22312;&#20849;&#21516;&#30340;&#23433;&#20840;&#28431;&#27934;&#65306;CodeAttack&#22312;&#36229;&#36807;80%&#30340;&#26102;&#38388;&#20869;&#22987;&#32456;&#32469;&#36807;&#25152;&#26377;&#27169;&#22411;&#30340;&#23433;&#20840;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07865v1 Announce Type: cross  Abstract: The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to we
&lt;/p&gt;</description></item><item><title>HaluEval-Wild&#26159;&#31532;&#19968;&#20010;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;&#23454;&#38469;&#29615;&#22659;&#20013;LLM&#24187;&#35273;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#25910;&#38598;&#20102;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29992;&#25143;&#26597;&#35810;&#24182;&#20998;&#31867;&#20026;&#20116;&#31181;&#19981;&#21516;&#31867;&#22411;&#65292;&#21487;&#20197;&#23545;LLM&#34920;&#29616;&#20986;&#30340;&#24187;&#35273;&#31867;&#22411;&#36827;&#34892;&#32454;&#31890;&#24230;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2403.04307</link><description>&lt;p&gt;
HaluEval-Wild&#65306;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#30340;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04307
&lt;/p&gt;
&lt;p&gt;
HaluEval-Wild&#26159;&#31532;&#19968;&#20010;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;&#23454;&#38469;&#29615;&#22659;&#20013;LLM&#24187;&#35273;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#25910;&#38598;&#20102;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29992;&#25143;&#26597;&#35810;&#24182;&#20998;&#31867;&#20026;&#20116;&#31181;&#19981;&#21516;&#31867;&#22411;&#65292;&#21487;&#20197;&#23545;LLM&#34920;&#29616;&#20986;&#30340;&#24187;&#35273;&#31867;&#22411;&#36827;&#34892;&#32454;&#31890;&#24230;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24187;&#35273;&#23545;&#20110;&#20851;&#38190;&#39046;&#22495;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21487;&#38752;&#24615;&#26500;&#25104;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#26368;&#36817;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;LLM&#22312;&#20256;&#32479;NLP&#20219;&#21153;&#20013;&#30340;&#24187;&#35273;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#22914;&#30693;&#35782;&#23494;&#38598;&#22411;&#38382;&#31572;&#65288;QA&#65289;&#21644;&#25688;&#35201;&#65292;&#19981;&#36275;&#20197;&#25429;&#25417;&#21160;&#24577;&#23454;&#38469;&#29615;&#22659;&#20013;&#29992;&#25143;-LLM&#20132;&#20114;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;HaluEval-Wild&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;&#23454;&#38469;&#29615;&#22659;&#20013;LLM&#24187;&#35273;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#25105;&#20204;&#31934;&#24515;&#25910;&#38598;&#20102;&#26469;&#33258;&#29616;&#26377;&#23454;&#38469;&#29992;&#25143;-LLM&#20132;&#20114;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;ShareGPT&#65289;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65288;&#32463;Alpaca&#23545;&#25239;&#24615;&#36807;&#28388;&#30340;&#65289;&#29992;&#25143;&#26597;&#35810;&#65292;&#20197;&#35780;&#20272;&#21508;&#31181;LLM&#30340;&#24187;&#35273;&#29575;&#12290;&#22312;&#20998;&#26512;&#25910;&#38598;&#21040;&#30340;&#26597;&#35810;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#20998;&#31867;&#20026;&#20116;&#31181;&#19981;&#21516;&#31867;&#22411;&#65292;&#36825;&#20351;&#24471;&#21487;&#20197;&#23545;LLM&#34920;&#29616;&#20986;&#30340;&#24187;&#35273;&#31867;&#22411;&#36827;&#34892;&#32454;&#31890;&#24230;&#20998;&#26512;&#65292;&#24182;&#23558;&#24341;&#29992;&#31572;&#26696;&#19982;&#24378;&#22823;&#30340;GP&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04307v1 Announce Type: new  Abstract: Hallucinations pose a significant challenge to the reliability of large language models (LLMs) in critical domains. Recent benchmarks designed to assess LLM hallucinations within conventional NLP tasks, such as knowledge-intensive question answering (QA) and summarization, are insufficient for capturing the complexities of user-LLM interactions in dynamic, real-world settings. To address this gap, we introduce HaluEval-Wild, the first benchmark specifically designed to evaluate LLM hallucinations in the wild. We meticulously collect challenging (adversarially filtered by Alpaca) user queries from existing real-world user-LLM interaction datasets, including ShareGPT, to evaluate the hallucination rates of various LLMs. Upon analyzing the collected queries, we categorize them into five distinct types, which enables a fine-grained analysis of the types of hallucinations LLMs exhibit, and synthesize the reference answers with the powerful GP
&lt;/p&gt;</description></item><item><title>Apollo&#39033;&#30446;&#24320;&#21457;&#20102;&#22810;&#35821;&#35328;&#21307;&#23398;LLMs&#65292;&#21019;&#24314;&#20102;&#20840;&#29699;&#20154;&#21475;61&#20159;&#30340;&#21307;&#23398;&#25968;&#25454;&#38598;&#65292;&#24182;&#21457;&#24067;&#20102;&#21508;&#31181;&#23610;&#23544;&#30340;&#26368;&#20339;&#24615;&#33021;&#27169;&#22411;&#65292;&#20854;&#20013;Apollo-7B&#26159;&#26368;&#20808;&#36827;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;LLMs&#65292;&#21487;&#25913;&#21892;&#26356;&#22823;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.03640</link><description>&lt;p&gt;
Apollo&#65306;&#36731;&#37327;&#32423;&#22810;&#35821;&#35328;&#21307;&#23398;LLMs&#65306;&#35753;&#21307;&#23398;&#20154;&#24037;&#26234;&#33021;&#26222;&#24800;60&#20159;&#20154;
&lt;/p&gt;
&lt;p&gt;
Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03640
&lt;/p&gt;
&lt;p&gt;
Apollo&#39033;&#30446;&#24320;&#21457;&#20102;&#22810;&#35821;&#35328;&#21307;&#23398;LLMs&#65292;&#21019;&#24314;&#20102;&#20840;&#29699;&#20154;&#21475;61&#20159;&#30340;&#21307;&#23398;&#25968;&#25454;&#38598;&#65292;&#24182;&#21457;&#24067;&#20102;&#21508;&#31181;&#23610;&#23544;&#30340;&#26368;&#20339;&#24615;&#33021;&#27169;&#22411;&#65292;&#20854;&#20013;Apollo-7B&#26159;&#26368;&#20808;&#36827;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;LLMs&#65292;&#21487;&#25913;&#21892;&#26356;&#22823;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20840;&#29699;&#21307;&#23398;&#30693;&#35782;&#30340;&#24222;&#22823;&#23384;&#20648;&#24211;&#20027;&#35201;&#26159;&#20197;&#33521;&#35821;&#20026;&#20027;&#65292;&#20294;&#22312;&#20256;&#36882;&#37327;&#36523;&#23450;&#21046;&#21307;&#30103;&#26381;&#21153;&#26041;&#38754;&#65292;&#26412;&#22320;&#35821;&#35328;&#23545;&#20110;&#22312;&#21307;&#30103;&#36164;&#28304;&#26377;&#38480;&#30340;&#22320;&#21306;&#23588;&#20026;&#37325;&#35201;&#12290;&#20026;&#20102;&#23558;&#21307;&#23398;&#20154;&#24037;&#26234;&#33021;&#30340;&#36827;&#23637;&#25193;&#23637;&#21040;&#26356;&#24191;&#27867;&#30340;&#20154;&#32676;&#65292;&#25105;&#20204;&#26088;&#22312;&#24320;&#21457;&#28085;&#30422;&#20840;&#29699;61&#20159;&#20154;&#21475;&#30340;&#20845;&#31181;&#26368;&#24120;&#29992;&#35821;&#35328;&#30340;&#21307;&#23398;LLMs&#12290;&#36825;&#19968;&#21162;&#21147;&#26368;&#32456;&#20419;&#25104;&#20102;ApolloCorpora&#22810;&#35821;&#35328;&#21307;&#23398;&#25968;&#25454;&#38598;&#21644;XMedBench&#22522;&#20934;&#30340;&#21019;&#24314;&#12290;&#22312;&#22810;&#35821;&#35328;&#21307;&#23398;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#21457;&#24067;&#30340;Apollo&#27169;&#22411;&#65292;&#22312;&#21508;&#31181;&#30456;&#23545;&#36739;&#23567;&#23610;&#23544;&#65288;&#21363;0.5B&#12289;1.8B&#12289;2B&#12289;6B&#21644;7B&#65289;&#19978;&#21462;&#24471;&#20102;&#19982;&#21516;&#31561;&#22823;&#23567;&#27169;&#22411;&#26368;&#20339;&#24615;&#33021;&#12290;&#29305;&#21035;&#22320;&#65292;Apollo-7B&#26159;&#36804;&#20170;&#20026;&#27490;&#36798;&#21040;70B&#30340;&#26368;&#20808;&#36827;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;LLMs&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#36731;&#37327;&#32423;&#27169;&#22411;&#21487;&#29992;&#20110;&#22312;&#19981;&#38656;&#35201;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#25913;&#36827;&#36739;&#22823;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03640v1 Announce Type: cross  Abstract: Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources. To extend the reach of medical AI advancements to a broader population, we aim to develop medical LLMs across the six most widely spoken languages, encompassing a global population of 6.1 billion. This effort culminates in the creation of the ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the multilingual medical benchmark, the released Apollo models, at various relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best performance among models of equivalent size. Especially, Apollo-7B is the state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite models could be used to improve the multi-lingual medical capabilities of larger models without fine-tuning in a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ChatGPT&#29983;&#25104;&#21512;&#25104;&#35757;&#32451;&#25968;&#25454;&#26469;&#22686;&#24378;LLMs&#21435;&#20559;&#35265;&#21270;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#21435;&#38500;&#24050;&#30693;&#20559;&#35265;&#24182;&#36328;&#36234;&#19981;&#21516;&#31867;&#21035;&#36827;&#34892;&#21435;&#20559;&#35265;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.11764</link><description>&lt;p&gt;
&#22522;&#20110;ChatGPT&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#29992;&#20110;&#25913;&#21892;LLMs&#30340;&#21442;&#25968;&#39640;&#25928;&#21435;&#20559;&#35265;&#21270;
&lt;/p&gt;
&lt;p&gt;
ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ChatGPT&#29983;&#25104;&#21512;&#25104;&#35757;&#32451;&#25968;&#25454;&#26469;&#22686;&#24378;LLMs&#21435;&#20559;&#35265;&#21270;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#21435;&#38500;&#24050;&#30693;&#20559;&#35265;&#24182;&#36328;&#36234;&#19981;&#21516;&#31867;&#21035;&#36827;&#34892;&#21435;&#20559;&#35265;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34429;&#28982;&#21151;&#33021;&#24378;&#22823;&#65292;&#20294;&#23384;&#22312;&#26377;&#23475;&#30340;&#31038;&#20250;&#20559;&#35265;&#12290;&#30001;&#20110;&#35745;&#31639;&#25104;&#26412;&#12289;&#25968;&#25454;&#32422;&#26463;&#21644;&#21487;&#33021;&#38477;&#20302;&#22810;&#20219;&#21153;&#35821;&#35328;&#33021;&#21147;&#65292;&#21435;&#20559;&#35265;&#21270;&#36890;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;ChatGPT&#29983;&#25104;&#21512;&#25104;&#35757;&#32451;&#25968;&#25454;&#30340;&#26032;&#26041;&#27861;&#65292;&#26088;&#22312;&#22686;&#24378;LLMs&#30340;&#21435;&#20559;&#35265;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#65306;&#30446;&#26631;&#25552;&#31034;&#65292;&#23545;&#24050;&#30693;&#20559;&#35265;&#25552;&#20379;&#26377;&#25928;&#30340;&#21435;&#20559;&#35265;&#21270;&#65292;&#20294;&#38656;&#35201;&#20107;&#20808;&#25351;&#23450;&#38382;&#39064;&#20013;&#30340;&#20559;&#35265;; &#19968;&#33324;&#25552;&#31034;&#65292;&#34429;&#28982;&#25928;&#26524;&#31245;&#36874;&#65292;&#20294;&#33021;&#22815;&#36328;&#21508;&#31181;&#31867;&#21035;&#36827;&#34892;&#21435;&#20559;&#35265;&#21270;&#12290;&#25105;&#20204;&#21033;&#29992;&#36866;&#37197;&#22120;&#35843;&#25972;&#26469;&#23454;&#29616;&#36164;&#28304;&#39640;&#25928;&#30340;LLM&#21435;&#20559;&#35265;&#21270;&#65292;&#24182;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#21512;&#25104;&#25968;&#25454;&#19982;&#29616;&#26377;&#21435;&#20559;&#35265;&#21270;&#25968;&#25454;&#38598;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65306;&#65288;1&#65289;ChatGPT&#21487;&#20197;&#39640;&#25928;&#22320;&#29983;&#25104;&#29992;&#20110;&#21435;&#20559;&#35265;&#21270;&#20854;&#20182;LLMs&#30340;&#39640;&#36136;&#37327;&#35757;&#32451;&#25968;&#25454;&#65307;&#65288;2&#65289;&#36890;&#36807;&#25105;&#20204;&#30340;&#26041;&#27861;&#29983;&#25104;&#30340;&#25968;&#25454;&#36229;&#36234;&#20102;&#29616;&#26377;&#25968;&#25454;&#38598;&#22312;&#21435;&#20559;&#35265;&#21270;&#19978;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11764v1 Announce Type: cross  Abstract: Large Language models (LLMs), while powerful, exhibit harmful social biases. Debiasing is often challenging due to computational costs, data constraints, and potential degradation of multi-task language capabilities. This work introduces a novel approach utilizing ChatGPT to generate synthetic training data, aiming to enhance the debiasing of LLMs. We propose two strategies: Targeted Prompting, which provides effective debiasing for known biases but necessitates prior specification of bias in question; and General Prompting, which, while slightly less effective, offers debiasing across various categories. We leverage resource-efficient LLM debiasing using adapter tuning and compare the effectiveness of our synthetic data to existing debiasing datasets. Our results reveal that: (1) ChatGPT can efficiently produce high-quality training data for debiasing other LLMs; (2) data produced via our approach surpasses existing datasets in debias
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21046;&#31070;&#32463;&#25512;&#29702;&#22120;&#32500;&#25252;&#25191;&#34892;&#36712;&#36857;&#20316;&#20026;&#26377;&#38480;&#39044;&#23450;&#20041;&#29366;&#24577;&#32452;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#31639;&#27861;&#29366;&#24577;&#36716;&#25442;&#30340;&#30417;&#30563;&#35757;&#32451;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#19982;&#21407;&#22987;&#31639;&#27861;&#23436;&#32654;&#23545;&#40784;&#65292;&#24182;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#23436;&#32654;&#30340;&#27979;&#35797;&#25104;&#32489;&#12290;</title><link>https://arxiv.org/abs/2402.11628</link><description>&lt;p&gt;
&#31163;&#25955;&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Discrete Neural Algorithmic Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11628
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21046;&#31070;&#32463;&#25512;&#29702;&#22120;&#32500;&#25252;&#25191;&#34892;&#36712;&#36857;&#20316;&#20026;&#26377;&#38480;&#39044;&#23450;&#20041;&#29366;&#24577;&#32452;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#31639;&#27861;&#29366;&#24577;&#36716;&#25442;&#30340;&#30417;&#30563;&#35757;&#32451;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#19982;&#21407;&#22987;&#31639;&#27861;&#23436;&#32654;&#23545;&#40784;&#65292;&#24182;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#23436;&#32654;&#30340;&#27979;&#35797;&#25104;&#32489;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#26088;&#22312;&#36890;&#36807;&#23398;&#20064;&#27169;&#20223;&#32463;&#20856;&#31639;&#27861;&#30340;&#25191;&#34892;&#26469;&#25429;&#25417;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#35745;&#31639;&#12290;&#23613;&#31649;&#24120;&#35265;&#30340;&#26550;&#26500;&#36275;&#22815;&#34920;&#36798;&#27491;&#30830;&#30340;&#27169;&#22411;&#22312;&#26435;&#37325;&#31354;&#38388;&#20013;&#65292;&#20294;&#24403;&#21069;&#30340;&#31070;&#32463;&#25512;&#29702;&#22120;&#22312;&#22788;&#29702;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#26102;&#38754;&#20020;&#27867;&#21270;&#22256;&#38590;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#32463;&#20856;&#35745;&#31639;&#19981;&#21463;&#20998;&#24067;&#21464;&#21270;&#30340;&#24433;&#21709;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#25551;&#36848;&#20026;&#31163;&#25955;&#35745;&#31639;&#29366;&#24577;&#20043;&#38388;&#30340;&#36716;&#25442;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24378;&#21046;&#31070;&#32463;&#25512;&#29702;&#22120;&#23558;&#25191;&#34892;&#36712;&#36857;&#20316;&#20026;&#26377;&#38480;&#39044;&#23450;&#20041;&#29366;&#24577;&#30340;&#32452;&#21512;&#36827;&#34892;&#32500;&#25252;&#12290;&#36890;&#36807;&#23545;&#31639;&#27861;&#29366;&#24577;&#36716;&#25442;&#30340;&#30417;&#30563;&#35757;&#32451;&#65292;&#36825;&#31181;&#27169;&#22411;&#33021;&#22815;&#19982;&#21407;&#22987;&#31639;&#27861;&#23436;&#32654;&#23545;&#40784;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#22312;SALSA-CLRS&#22522;&#20934;&#27979;&#35797;&#19978;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#22312;&#37027;&#37324;&#25105;&#20204;&#20026;&#25152;&#26377;&#20219;&#21153;&#33719;&#24471;&#20102;&#23436;&#32654;&#30340;&#27979;&#35797;&#25104;&#32489;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#26550;&#26500;&#36873;&#25321;&#20351;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11628v1 Announce Type: new  Abstract: Neural algorithmic reasoning aims to capture computations with neural networks via learning the models to imitate the execution of classical algorithms. While common architectures are expressive enough to contain the correct model in the weights space, current neural reasoners are struggling to generalize well on out-of-distribution data. On the other hand, classical computations are not affected by distribution shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on the SALSA-CLRS benchmark, where we get perfect test scores for all tasks. Moreover, the proposed architectural choice allows us to prove the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#36890;&#36807;&#23558;&#38590;&#39064;&#20998;&#20026;&#22522;&#20110;&#35268;&#21017;&#21644;&#26080;&#35268;&#21017;&#20004;&#31867;&#30340;&#29420;&#29305;&#20998;&#31867;&#27861;&#65292;&#36890;&#36807;&#21508;&#31181;&#26041;&#27861;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#34920;&#29616;&#65292;&#24378;&#35843;&#20102;&#22312;&#22797;&#26434;&#38590;&#39064;&#24773;&#22659;&#20013;LLMs&#30340;&#25361;&#25112;&#21644;&#20154;&#31867;&#31867;&#20284;&#25512;&#29702;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#31361;&#20986;&#20102;&#25512;&#21160;LLMs&#35299;&#35868;&#33021;&#21147;&#21644;&#36129;&#29486;&#20110;&#20154;&#24037;&#26234;&#33021;&#21457;&#23637;&#30340;&#24517;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11291</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#35299;&#20915;&#38590;&#39064;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Puzzle Solving using Reasoning of Large Language Models: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11291
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#36890;&#36807;&#23558;&#38590;&#39064;&#20998;&#20026;&#22522;&#20110;&#35268;&#21017;&#21644;&#26080;&#35268;&#21017;&#20004;&#31867;&#30340;&#29420;&#29305;&#20998;&#31867;&#27861;&#65292;&#36890;&#36807;&#21508;&#31181;&#26041;&#27861;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#34920;&#29616;&#65292;&#24378;&#35843;&#20102;&#22312;&#22797;&#26434;&#38590;&#39064;&#24773;&#22659;&#20013;LLMs&#30340;&#25361;&#25112;&#21644;&#20154;&#31867;&#31867;&#20284;&#25512;&#29702;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#31361;&#20986;&#20102;&#25512;&#21160;LLMs&#35299;&#35868;&#33021;&#21147;&#21644;&#36129;&#29486;&#20110;&#20154;&#24037;&#26234;&#33021;&#21457;&#23637;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35299;&#20915;&#38590;&#39064;&#20013;&#30340;&#33021;&#21147;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#65292;&#26631;&#24535;&#30528;&#29702;&#35299;&#23427;&#20204;&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#36866;&#29992;&#24615;&#36808;&#20986;&#20102;&#37325;&#35201;&#30340;&#19968;&#27493;&#12290;&#26412;&#35843;&#26597;&#21033;&#29992;&#29420;&#29305;&#30340;&#20998;&#31867;&#27861;&#23558;&#38590;&#39064;&#20998;&#20026;&#22522;&#20110;&#35268;&#21017;&#21644;&#26080;&#35268;&#21017;&#20004;&#31867;&#65292;&#36890;&#36807;&#21508;&#31181;&#26041;&#27861;&#35780;&#20272;LLMs&#65292;&#21253;&#25324;&#25552;&#31034;&#25216;&#26415;&#12289;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#21644;&#24494;&#35843;&#12290;&#36890;&#36807;&#23545;&#30456;&#20851;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#30340;&#25209;&#21028;&#24615;&#23457;&#26597;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;LLMs&#22312;&#22797;&#26434;&#38590;&#39064;&#22330;&#26223;&#20013;&#30340;&#34920;&#29616;&#65292;&#35782;&#21035;&#20986;&#22797;&#26434;&#38590;&#39064;&#24773;&#22659;&#20013;&#30340;&#26174;&#33879;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#31361;&#20986;&#20102;LLMs&#33021;&#21147;&#21450;&#31867;&#20154;&#25512;&#29702;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#39640;&#32423;&#36923;&#36753;&#25512;&#26029;&#30340;&#24773;&#20917;&#19979;&#12290;&#35843;&#26597;&#24378;&#35843;&#20102;&#38656;&#35201;&#26032;&#39062;&#31574;&#30053;&#21644;&#26356;&#20016;&#23500;&#25968;&#25454;&#38598;&#26469;&#25552;&#21319;LLMs&#30340;&#35299;&#35868;&#33021;&#21147;&#24182;&#20419;&#36827;&#20154;&#24037;&#26234;&#33021;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11291v1 Announce Type: cross  Abstract: Exploring the capabilities of Large Language Models (LLMs) in puzzle solving unveils critical insights into their potential and challenges in artificial intelligence, marking a significant step towards understanding their applicability in complex reasoning tasks. This survey leverages a unique taxonomy -- dividing puzzles into rule-based and rule-less categories -- to critically assess LLMs through various methodologies, including prompting techniques, neuro-symbolic approaches, and fine-tuning. Through a critical review of relevant datasets and benchmarks, we assess LLMs' performance, identifying significant challenges in complex puzzle scenarios. Our findings highlight the disparity between LLM capabilities and human-like reasoning, particularly in those requiring advanced logical inference. The survey underscores the necessity for novel strategies and richer datasets to advance LLMs' puzzle-solving proficiency and contribute to AI's
&lt;/p&gt;</description></item><item><title>&#22312;&#29983;&#29289;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#36827;&#34892;&#38646;&#26679;&#26412;&#37319;&#26679;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#21457;&#29616;&#21508;&#31181;&#23545;&#25239;&#23454;&#20307;&#20316;&#20026;&#24178;&#25200;&#22240;&#32032;&#65292;&#30456;&#27604;&#38543;&#26426;&#37319;&#26679;&#65292;&#22312;&#23545;&#25239;&#38382;&#31572;&#20013;&#34920;&#29616;&#20986;&#26126;&#26174;&#20248;&#21183;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#29305;&#24449;&#30340;&#20004;&#31181;&#23545;&#25239;&#24615;&#23454;&#20307;&#21046;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.10527</link><description>&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#38646;&#26679;&#26412;&#37319;&#26679;&#23545;&#25239;&#23454;&#20307;
&lt;/p&gt;
&lt;p&gt;
Zero-shot sampling of adversarial entities in biomedical question answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10527
&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#29289;&#21307;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#36827;&#34892;&#38646;&#26679;&#26412;&#37319;&#26679;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#21457;&#29616;&#21508;&#31181;&#23545;&#25239;&#23454;&#20307;&#20316;&#20026;&#24178;&#25200;&#22240;&#32032;&#65292;&#30456;&#27604;&#38543;&#26426;&#37319;&#26679;&#65292;&#22312;&#23545;&#25239;&#38382;&#31572;&#20013;&#34920;&#29616;&#20986;&#26126;&#26174;&#20248;&#21183;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#29305;&#24449;&#30340;&#20004;&#31181;&#23545;&#25239;&#24615;&#23454;&#20307;&#21046;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#21442;&#25968;&#22495;&#30693;&#35782;&#30340;&#22686;&#21152;&#28145;&#24230;&#25512;&#21160;&#23427;&#20204;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#24555;&#36895;&#37096;&#32626;&#12290;&#22312;&#39640;&#39118;&#38505;&#21644;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#20013;&#65292;&#29702;&#35299;&#27169;&#22411;&#30340;&#28431;&#27934;&#23545;&#20110;&#37327;&#21270;&#27169;&#22411;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#21644;&#35268;&#33539;&#20854;&#20351;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#21457;&#29616;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#20316;&#20026;&#23545;&#25239;&#31034;&#20363;&#30340;&#21629;&#21517;&#23454;&#20307;&#24341;&#21457;&#20102;&#20851;&#20110;&#23427;&#20204;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#21487;&#33021;&#30340;&#20266;&#35013;&#30340;&#30097;&#38382;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#24130;&#32553;&#25918;&#36317;&#31163;&#21152;&#26435;&#37319;&#26679;&#26041;&#26696;&#65292;&#20197;&#21457;&#29616;&#22810;&#26679;&#21270;&#30340;&#23545;&#25239;&#23454;&#20307;&#20316;&#20026;&#24178;&#25200;&#22240;&#32032;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#29983;&#29289;&#21307;&#23398;&#20027;&#39064;&#30340;&#23545;&#25239;&#24615;&#38382;&#39064;&#22238;&#31572;&#20013;&#20248;&#20110;&#38543;&#26426;&#37319;&#26679;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#21487;&#20197;&#25506;&#32034;&#25915;&#20987;&#34920;&#38754;&#19978;&#30340;&#19981;&#21516;&#21306;&#22495;&#65292;&#36825;&#25581;&#31034;&#20102;&#20004;&#31181;&#22312;&#29305;&#24449;&#19978;&#26126;&#26174;&#19981;&#21516;&#30340;&#23545;&#25239;&#24615;&#23454;&#20307;&#30340;&#21046;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25915;&#20987;&#26041;&#24335;&#22914;&#20309;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10527v1 Announce Type: new  Abstract: The increasing depth of parametric domain knowledge in large language models (LLMs) is fueling their rapid deployment in real-world applications. In high-stakes and knowledge-intensive tasks, understanding model vulnerabilities is essential for quantifying the trustworthiness of model predictions and regulating their use. The recent discovery of named entities as adversarial examples in natural language processing tasks raises questions about their potential guises in other settings. Here, we propose a powerscaled distance-weighted sampling scheme in embedding space to discover diverse adversarial entities as distractors. We demonstrate its advantage over random sampling in adversarial question answering on biomedical topics. Our approach enables the exploration of different regions on the attack surface, which reveals two regimes of adversarial entities that markedly differ in their characteristics. Moreover, we show that the attacks su
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;Strategy-Relevant Attention&#65288;SRA&#65289;&#24230;&#37327;&#65292;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#36981;&#24490;&#25112;&#30053;&#25552;&#31034;&#30340;&#26377;&#25928;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#24212;&#29992;SRA&#25351;&#23548;&#30340;&#25552;&#31034;&#21487;&#25552;&#39640;&#25112;&#30053;&#20381;&#20174;&#24615;&#65292;&#20174;&#32780;&#20351;&#38271;&#26102;&#38388;&#23545;&#35805;&#26356;&#21487;&#38752;&#22320;&#23637;&#31034;&#25152;&#38656;&#30340;&#24773;&#24863;&#25903;&#25345;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.10453</link><description>&lt;p&gt;
&#24341;&#23548;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38271;&#26102;&#38388;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
Steering Conversational Large Language Models for Long Emotional Support Conversations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10453
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;Strategy-Relevant Attention&#65288;SRA&#65289;&#24230;&#37327;&#65292;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#36981;&#24490;&#25112;&#30053;&#25552;&#31034;&#30340;&#26377;&#25928;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#24212;&#29992;SRA&#25351;&#23548;&#30340;&#25552;&#31034;&#21487;&#25552;&#39640;&#25112;&#30053;&#20381;&#20174;&#24615;&#65292;&#20174;&#32780;&#20351;&#38271;&#26102;&#38388;&#23545;&#35805;&#26356;&#21487;&#38752;&#22320;&#23637;&#31034;&#25152;&#38656;&#30340;&#24773;&#24863;&#25903;&#25345;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#38271;&#26102;&#38388;&#23545;&#35805;&#20013;&#19968;&#36143;&#36981;&#24490;&#24773;&#24863;&#25903;&#25345;&#31574;&#30053;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Strategy-Relevant Attention&#65288;SRA&#65289;&#24230;&#37327;&#65292;&#36825;&#26159;&#19968;&#20010;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#25351;&#26631;&#65292;&#26088;&#22312;&#35780;&#20272;LLMs&#22312;&#24773;&#24863;&#25903;&#25345;&#29615;&#22659;&#20013;&#36981;&#24490;&#25112;&#30053;&#25552;&#31034;&#30340;&#26377;&#25928;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;LLaMA&#27169;&#22411;&#20998;&#26512;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#25968;&#25454;&#38598;&#65288;ESConv&#65289;&#20013;&#30340;&#23545;&#35805;&#65292;&#25105;&#20204;&#35777;&#26126;SRA&#19982;&#27169;&#22411;&#22312;&#25972;&#20010;&#20114;&#21160;&#36807;&#31243;&#20013;&#32500;&#25345;&#25152;&#36848;&#31574;&#30053;&#33021;&#21147;&#23494;&#20999;&#30456;&#20851;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#24212;&#29992;&#22522;&#20110;SRA&#30340;&#25552;&#31034;&#21487;&#25552;&#39640;&#25112;&#30053;&#20381;&#20174;&#24615;&#65292;&#23548;&#33268;&#23545;&#35805;&#26356;&#21487;&#38752;&#22320;&#23637;&#31034;&#38271;&#26102;&#38388;&#23545;&#35805;&#20013;&#25152;&#38656;&#30340;&#24773;&#24863;&#25903;&#25345;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36129;&#29486;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#12289;&#22810;&#20998;&#25903;&#30340;&#21512;&#25104;&#23545;&#35805;&#25968;&#25454;&#38598;&#65292;&#36866;&#29992;&#20110;ESConv&#65292;&#20854;&#20013;&#21253;&#21547;&#21508;&#31181;&#31574;&#30053;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10453v1 Announce Type: new  Abstract: In this study, we address the challenge of consistently following emotional support strategies in long conversations by large language models (LLMs). We introduce the Strategy-Relevant Attention (SRA) metric, a model-agnostic measure designed to evaluate the effectiveness of LLMs in adhering to strategic prompts in emotional support contexts. By analyzing conversations within the Emotional Support Conversations dataset (ESConv) using LLaMA models, we demonstrate that SRA is significantly correlated with a model's ability to sustain the outlined strategy throughout the interactions. Our findings reveal that the application of SRA-informed prompts leads to enhanced strategic adherence, resulting in conversations that more reliably exhibit the desired emotional support strategies over longer conversations. Furthermore, we contribute a comprehensive, multi-branch synthetic conversation dataset for ESConv, featuring a variety of strategy cont
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#19977;&#20010;&#25104;&#29087;&#30340;&#20154;&#31867;&#20915;&#31574;&#29702;&#35770;&#25972;&#21512;&#21040;&#19968;&#36215;&#65292;&#24418;&#25104;&#20102;&#19968;&#20010;&#30446;&#30340;&#24615;&#20154;&#31867;&#34892;&#21160;&#27169;&#22411;&#12290;&#21516;&#26102;&#65292;&#23558;&#35821;&#35328;&#20316;&#20026;&#34892;&#21160;&#30340;&#35266;&#28857;&#24212;&#29992;&#20110;&#23545;&#35805;&#29992;&#25143;&#30028;&#38754;&#12290;&#36890;&#36807;&#29702;&#35299;ChatGPT&#30340;&#26234;&#33021;&#26469;&#28304;&#65292;&#21487;&#20197;&#22312;&#20943;&#23569;&#36164;&#28304;&#30340;&#21516;&#26102;&#33719;&#24471;&#23545;&#25105;&#20204;&#20043;&#38388;&#20851;&#31995;&#30340;&#35748;&#35782;&#12290;</title><link>https://arxiv.org/abs/2402.08403</link><description>&lt;p&gt;
LLMs&#21644;&#20154;&#31867;&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
LLMs and the Human Condition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#19977;&#20010;&#25104;&#29087;&#30340;&#20154;&#31867;&#20915;&#31574;&#29702;&#35770;&#25972;&#21512;&#21040;&#19968;&#36215;&#65292;&#24418;&#25104;&#20102;&#19968;&#20010;&#30446;&#30340;&#24615;&#20154;&#31867;&#34892;&#21160;&#27169;&#22411;&#12290;&#21516;&#26102;&#65292;&#23558;&#35821;&#35328;&#20316;&#20026;&#34892;&#21160;&#30340;&#35266;&#28857;&#24212;&#29992;&#20110;&#23545;&#35805;&#29992;&#25143;&#30028;&#38754;&#12290;&#36890;&#36807;&#29702;&#35299;ChatGPT&#30340;&#26234;&#33021;&#26469;&#28304;&#65292;&#21487;&#20197;&#22312;&#20943;&#23569;&#36164;&#28304;&#30340;&#21516;&#26102;&#33719;&#24471;&#23545;&#25105;&#20204;&#20043;&#38388;&#20851;&#31995;&#30340;&#35748;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20154;&#31867;&#20915;&#31574;&#30340;&#19977;&#20010;&#25104;&#29087;&#29702;&#35770;&#65292;&#24182;&#25551;&#36848;&#20102;&#22914;&#20309;&#23558;&#23427;&#20204;&#25972;&#21512;&#36215;&#26469;&#25552;&#20379;&#19968;&#20010;&#30446;&#30340;&#24615;&#20154;&#31867;&#34892;&#21160;&#30340;&#27169;&#22411;&#12290;&#21516;&#26102;&#65292;&#23558;&#35821;&#35328;&#20316;&#20026;&#34892;&#21160;&#30340;&#35266;&#28857;&#24212;&#29992;&#20110;&#23545;&#35805;&#29992;&#25143;&#30028;&#38754;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#29702;&#35770;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#36935;&#21040;&#20102;&#22256;&#38590;&#65292;&#26412;&#25991;&#26088;&#22312;&#37325;&#26032;&#28608;&#21457;&#23545;&#29702;&#35299;LLMs&#23454;&#38469;&#25191;&#34892;&#30340;&#20852;&#36259;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22312;&#25152;&#26377;&#25968;&#25454;&#19978;&#36816;&#34892;&#38590;&#20197;&#29702;&#35299;&#30340;&#26426;&#22120;&#23398;&#20064;&#20363;&#31243;&#12290;&#24403;&#19968;&#21488;&#21806;&#20215;&#19981;&#21040;50&#32654;&#20803;&#30340;&#26641;&#33683;&#27966;&#30005;&#33041;&#27604;&#31532;&#19968;&#21488;&#21830;&#19994;Cray&#36229;&#32423;&#35745;&#31639;&#26426;&#24555;400&#20493;&#26102;&#65292;&#22823;&#22411;&#31185;&#25216;&#20844;&#21496;&#21487;&#20197;&#25509;&#36817;&#25317;&#26377;&#26080;&#25968;&#38543;&#26426;&#25171;&#23383;&#24182;&#29983;&#25104;&#26377;&#24847;&#20041;&#25991;&#23383;&#30340;&#29492;&#23376;&#12290;&#36890;&#36807;&#29702;&#35299;ChatGPT&#30340;&#34920;&#29616;&#26234;&#33021;&#30340;&#26469;&#28304;&#65292;&#20063;&#35768;&#25105;&#20204;&#21487;&#20197;&#29992;&#26356;&#23569;&#30340;&#36164;&#28304;&#36827;&#34892;&#21516;&#26679;&#30340;&#39764;&#26415;&#65292;&#24182;&#22312;&#27492;&#36807;&#31243;&#20013;&#33719;&#24471;&#19968;&#20123;&#20851;&#20110;&#25105;&#20204;&#20043;&#38388;&#20851;&#31995;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents three established theories of human decision-making and describes how they can be integrated to provide a model of purposive human action. Taking seriously the idea of language as action the model is then applied to the conversational user interfaces. Theory based AI research has had a hard time recently and the aim here is to revitalise interest in understanding what LLMs are actually doing other than running poorly understood machine learning routines over all the data the relevant Big Tech company can hoover up. When a raspberry pi computer for under 50USD is up to 400 times faster than the first commercial Cray super computer~\cite{crayVpi}, Big Tech can get really close to having an infinite number of monkeys typing at random and producing text, some of which will make sense. By understanding where ChatGPT's apparent intelligence comes from, perhaps we can perform the magic with fewer resources and at the same time gain some understanding about our relationship
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#22312;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#19978;&#23545;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#35774;&#32622;&#20013;&#65292;&#25915;&#20987;&#20960;&#20046;&#21482;&#33021;&#27604;&#38543;&#26426;&#29468;&#27979;&#31245;&#22909;&#65292;&#36825;&#31181;&#31967;&#31957;&#30340;&#24615;&#33021;&#26159;&#30001;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#21644;&#23569;&#37327;&#35757;&#32451;&#36845;&#20195;&#30340;&#32452;&#21512;&#65292;&#20197;&#21450;&#25104;&#21592;&#21644;&#38750;&#25104;&#21592;&#20043;&#38388;&#30340;&#36793;&#30028;&#22256;&#24785;&#25152;&#23548;&#33268;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.07841</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26159;&#21542;&#22863;&#25928;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do Membership Inference Attacks Work on Large Language Models?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07841
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#22312;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#19978;&#23545;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#35774;&#32622;&#20013;&#65292;&#25915;&#20987;&#20960;&#20046;&#21482;&#33021;&#27604;&#38543;&#26426;&#29468;&#27979;&#31245;&#22909;&#65292;&#36825;&#31181;&#31967;&#31957;&#30340;&#24615;&#33021;&#26159;&#30001;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#21644;&#23569;&#37327;&#35757;&#32451;&#36845;&#20195;&#30340;&#32452;&#21512;&#65292;&#20197;&#21450;&#25104;&#21592;&#21644;&#38750;&#25104;&#21592;&#20043;&#38388;&#30340;&#36793;&#30028;&#22256;&#24785;&#25152;&#23548;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIAs&#65289;&#35797;&#22270;&#39044;&#27979;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#23646;&#20110;&#30446;&#26631;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#23613;&#31649;&#23545;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#19978;&#23545;MIA&#30340;&#30740;&#31350;&#24037;&#20316;&#20173;&#26377;&#38480;&#12290;&#25105;&#20204;&#23545;&#22312;Pile&#19978;&#35757;&#32451;&#30340;&#19968;&#31995;&#21015;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#30340;MIA&#35780;&#20272;&#65292;&#21442;&#25968;&#33539;&#22260;&#20174;160M&#21040;12B&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19981;&#21516;&#30340;LLM&#22823;&#23567;&#21644;&#39046;&#22495;&#30340;&#22823;&#22810;&#25968;&#35774;&#32622;&#20013;&#65292;MIAs&#20960;&#20046;&#21482;&#33021;&#27604;&#38543;&#26426;&#29468;&#27979;&#31245;&#22909;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#21457;&#29616;&#65292;&#36825;&#31181;&#31967;&#31957;&#30340;&#24615;&#33021;&#21487;&#20197;&#24402;&#22240;&#20110;&#65288;1&#65289;&#22823;&#22411;&#25968;&#25454;&#38598;&#21644;&#23569;&#37327;&#35757;&#32451;&#36845;&#20195;&#30340;&#32452;&#21512;&#65292;&#20197;&#21450;&#65288;2&#65289;&#25104;&#21592;&#21644;&#38750;&#25104;&#21592;&#20043;&#38388;&#30340;&#36793;&#30028;&#22256;&#24785;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;LLMs&#26131;&#21463;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#29305;&#23450;&#35774;&#32622;&#65292;&#24182;&#34920;&#26126;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#21462;&#24471;&#30340;&#34920;&#38754;&#19978;&#30340;&#25104;&#21151;&#21487;&#20197;&#24402;&#22240;&#20110;&#20998;&#24067;&#30340;&#36716;&#21464;&#65292;&#20363;&#22914;&#24403;&#25104;&#21592;&#21644;&#38750;&#25104;&#21592;&#34987;&#32472;&#21046;&#20986;&#26469;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Membership inference attacks (MIAs) attempt to predict whether a particular datapoint is a member of a target model's training data. Despite extensive research on traditional machine learning models, there has been limited work studying MIA on the pre-training data of large language models (LLMs). We perform a large-scale evaluation of MIAs over a suite of language models (LMs) trained on the Pile, ranging from 160M to 12B parameters. We find that MIAs barely outperform random guessing for most settings across varying LLM sizes and domains. Our further analyses reveal that this poor performance can be attributed to (1) the combination of a large dataset and few training iterations, and (2) an inherently fuzzy boundary between members and non-members. We identify specific settings where LLMs have been shown to be vulnerable to membership inference and show that the apparent success in such settings can be attributed to a distribution shift, such as when members and non-members are drawn
&lt;/p&gt;</description></item><item><title>GPT-3.5&#34987;&#29992;&#20110;&#29983;&#25104;&#21644;&#26631;&#27880;&#21307;&#30103;&#25991;&#20214;&#20197;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;&#32467;&#26524;&#26174;&#31034;&#20854;&#23545;ICD-10&#20195;&#30721;&#30340;&#32534;&#30721;&#24615;&#33021;&#33391;&#22909;&#65292;&#24182;&#19988;&#29983;&#25104;&#30340;&#25991;&#20214;&#22312;&#20020;&#24202;&#21487;&#25509;&#21463;&#24615;&#35780;&#20272;&#20013;&#24471;&#21040;&#20102;&#35748;&#21487;&#12290;</title><link>http://arxiv.org/abs/2401.13512</link><description>&lt;p&gt;
GPT-3.5&#33021;&#21542;&#29983;&#25104;&#21644;&#26631;&#27880;&#20986;&#38498;&#25688;&#35201;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can GPT-3.5 Generate and Code Discharge Summaries?. (arXiv:2401.13512v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13512
&lt;/p&gt;
&lt;p&gt;
GPT-3.5&#34987;&#29992;&#20110;&#29983;&#25104;&#21644;&#26631;&#27880;&#21307;&#30103;&#25991;&#20214;&#20197;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;&#32467;&#26524;&#26174;&#31034;&#20854;&#23545;ICD-10&#20195;&#30721;&#30340;&#32534;&#30721;&#24615;&#33021;&#33391;&#22909;&#65292;&#24182;&#19988;&#29983;&#25104;&#30340;&#25991;&#20214;&#22312;&#20020;&#24202;&#21487;&#25509;&#21463;&#24615;&#35780;&#20272;&#20013;&#24471;&#21040;&#20102;&#35748;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#25506;&#31350;GPT-3.5&#22312;&#29983;&#25104;&#21644;&#26631;&#27880;&#20855;&#26377;ICD-10&#20195;&#30721;&#30340;&#21307;&#30103;&#25991;&#20214;&#26041;&#38754;&#30340;&#24212;&#29992;&#65292;&#29992;&#20110;&#20302;&#36164;&#28304;&#26631;&#31614;&#30340;&#25968;&#25454;&#22686;&#24378;&#12290;&#26448;&#26009;&#21644;&#26041;&#27861;&#65306;&#21033;&#29992;GPT-3.5&#22522;&#20110;MIMIC-IV&#25968;&#25454;&#38598;&#20013;&#32597;&#35265;&#65288;&#29983;&#25104;&#65289;&#20195;&#30721;&#30340;ICD-10&#20195;&#30721;&#25551;&#36848;&#21015;&#34920;&#29983;&#25104;&#21644;&#26631;&#27880;&#20102;9,606&#20221;&#20986;&#38498;&#25688;&#35201;&#12290;&#23558;&#20854;&#19982;&#22522;&#32447;&#35757;&#32451;&#38598;&#32467;&#21512;&#65292;&#24418;&#25104;&#19968;&#20010;&#22686;&#24378;&#35757;&#32451;&#38598;&#12290;&#20351;&#29992;&#31070;&#32463;&#32534;&#30721;&#27169;&#22411;&#22312;&#22522;&#32447;&#21644;&#22686;&#24378;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#22312;MIMIC-IV&#27979;&#35797;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#20840;&#20195;&#30721;&#38598;&#12289;&#29983;&#25104;&#20195;&#30721;&#21450;&#20854;&#25152;&#23646;&#20195;&#30721;&#26063;&#30340;&#24494;&#35266;&#21644;&#23439;&#35266;F1&#24471;&#20998;&#12290;&#37319;&#29992;&#24369;&#23618;&#27425;&#28151;&#28102;&#30697;&#38453;&#26469;&#30830;&#23450;&#21518;&#38754;&#20004;&#20010;&#20195;&#30721;&#38598;&#20013;&#30340;&#20195;&#30721;&#26063;&#20869;&#21644;&#20195;&#30721;&#26063;&#22806;&#30340;&#32534;&#30721;&#38169;&#35823;&#12290;&#23545;GPT-3.5&#30340;&#32534;&#30721;&#24615;&#33021;&#36827;&#34892;&#20102;&#33258;&#34892;&#29983;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;MIMIC-IV&#25968;&#25454;&#30340;&#35780;&#20272;&#12290;&#20020;&#24202;&#19987;&#19994;&#20154;&#21592;&#23545;&#29983;&#25104;&#30340;&#25991;&#20214;&#36827;&#34892;&#20102;&#20020;&#24202;&#21487;&#25509;&#21463;&#24615;&#35780;&#20272;&#12290;&#32467;&#26524;&#21644;&#32467;&#35770;&#65306;&#22686;&#24378;&#24494;&#23567;
&lt;/p&gt;
&lt;p&gt;
Objective: To investigate GPT-3.5 in generating and coding medical documents with ICD-10 codes for data augmentation on low-resources labels.  Materials and Methods: Employing GPT-3.5 we generated and coded 9,606 discharge summaries based on lists of ICD-10 code descriptions of patients with infrequent (generation) codes within the MIMIC-IV dataset. Combined with the baseline training set, this formed an augmented training set. Neural coding models were trained on baseline and augmented data and evaluated on a MIMIC-IV test set. We report micro- and macro-F1 scores on the full codeset, generation codes, and their families. Weak Hierarchical Confusion Matrices were employed to determine within-family and outside-of-family coding errors in the latter codesets. The coding performance of GPT-3.5 was evaluated both on prompt-guided self-generated data and real MIMIC-IV data. Clinical professionals evaluated the clinical acceptability of the generated documents.  Results: Augmentation slight
&lt;/p&gt;</description></item><item><title>VideoDrafter&#26159;&#19968;&#20010;&#21033;&#29992;LLM&#23454;&#29616;&#20869;&#23481;&#19968;&#33268;&#30340;&#22810;&#22330;&#26223;&#35270;&#39057;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#26681;&#25454;&#36755;&#20837;&#25552;&#31034;&#29983;&#25104;&#36923;&#36753;&#36830;&#36143;&#30340;&#22810;&#22330;&#26223;&#33050;&#26412;&#65292;&#24182;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35270;&#39057;&#12290;</title><link>http://arxiv.org/abs/2401.01256</link><description>&lt;p&gt;
VideoDrafter: &#21033;&#29992;LLM&#23454;&#29616;&#20869;&#23481;&#19968;&#33268;&#30340;&#22810;&#22330;&#26223;&#35270;&#39057;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM. (arXiv:2401.01256v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01256
&lt;/p&gt;
&lt;p&gt;
VideoDrafter&#26159;&#19968;&#20010;&#21033;&#29992;LLM&#23454;&#29616;&#20869;&#23481;&#19968;&#33268;&#30340;&#22810;&#22330;&#26223;&#35270;&#39057;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#26681;&#25454;&#36755;&#20837;&#25552;&#31034;&#29983;&#25104;&#36923;&#36753;&#36830;&#36143;&#30340;&#22810;&#22330;&#26223;&#33050;&#26412;&#65292;&#24182;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35270;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25193;&#23637;&#27169;&#22411;&#30340;&#21019;&#26032;&#21644;&#31361;&#30772;&#26174;&#33879;&#25193;&#22823;&#20102;&#26681;&#25454;&#32473;&#23450;&#25552;&#31034;&#29983;&#25104;&#39640;&#36136;&#37327;&#35270;&#39057;&#30340;&#21487;&#33021;&#24615;&#12290;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#20316;&#21697;&#20165;&#22788;&#29702;&#22312;&#21333;&#20010;&#32972;&#26223;&#20013;&#21457;&#29983;&#21333;&#20010;&#35270;&#39057;&#20107;&#20214;&#30340;&#21333;&#22330;&#26223;&#24773;&#20917;&#12290;&#28982;&#32780;&#65292;&#25193;&#23637;&#21040;&#29983;&#25104;&#22810;&#22330;&#26223;&#35270;&#39057;&#24182;&#19988;&#22312;&#20445;&#25345;&#21508;&#20010;&#22330;&#26223;&#20043;&#38388;&#30340;&#36923;&#36753;&#19968;&#33268;&#21516;&#26102;&#20445;&#25345;&#35270;&#35273;&#22806;&#35266;&#19968;&#33268;&#24615;&#26041;&#38754;&#24182;&#19981;&#31616;&#21333;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#21363;VideoDrafter&#65292;&#29992;&#20110;&#20869;&#23481;&#19968;&#33268;&#30340;&#22810;&#22330;&#26223;&#35270;&#39057;&#29983;&#25104;&#12290;&#25216;&#26415;&#19978;&#65292;VideoDrafter&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23558;&#36755;&#20837;&#25552;&#31034;&#36716;&#21270;&#20026;&#32508;&#21512;&#30340;&#22810;&#22330;&#26223;&#33050;&#26412;&#65292;&#35813;&#33050;&#26412;&#20174;LLM&#23398;&#21040;&#30340;&#36923;&#36753;&#30693;&#35782;&#20013;&#21463;&#30410;&#12290;&#27599;&#20010;&#22330;&#26223;&#30340;&#33050;&#26412;&#21253;&#25324;&#25551;&#36848;&#20107;&#20214;&#12289;&#21069;&#26223;/&#32972;&#26223;&#23454;&#20307;&#20197;&#21450;&#25668;&#20687;&#26426;&#36816;&#21160;&#30340;&#25552;&#31034;&#12290;VideoDrafter&#35782;&#21035;&#33050;&#26412;&#20013;&#30340;&#20849;&#21516;&#23454;&#20307;&#65292;&#24182;&#35810;&#38382;LLM&#26469;&#36873;&#25321;&#29983;&#25104;&#36923;&#36753;&#36830;&#36143;&#30340;&#35270;&#39057;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM
&lt;/p&gt;</description></item><item><title>&#21322;&#28151;&#21512;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#36890;&#36807;&#20998;&#31163;&#22768;&#23398;&#27169;&#22411;&#21644;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#23454;&#29616;&#23545;&#20256;&#32479;&#25991;&#26412;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#25216;&#26415;&#30340;&#21033;&#29992;&#12290;&#22312;&#20351;&#29992;&#22495;&#22806;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#26102;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#33719;&#24471;21\%&#30340;&#35789;&#38169;&#35823;&#29575;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2309.07369</link><description>&lt;p&gt;
&#21322;&#28151;&#21512;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#29992;&#20110;&#39640;&#25928;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Hybrid Attention-based Encoder-decoder Model for Efficient Language Model Adaptation. (arXiv:2309.07369v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07369
&lt;/p&gt;
&lt;p&gt;
&#21322;&#28151;&#21512;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#36890;&#36807;&#20998;&#31163;&#22768;&#23398;&#27169;&#22411;&#21644;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#23454;&#29616;&#23545;&#20256;&#32479;&#25991;&#26412;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#25216;&#26415;&#30340;&#21033;&#29992;&#12290;&#22312;&#20351;&#29992;&#22495;&#22806;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#26102;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#33719;&#24471;21\%&#30340;&#35789;&#38169;&#35823;&#29575;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#35821;&#38899;&#35782;&#21035;&#27169;&#22411;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#24191;&#27867;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22312;&#31471;&#21040;&#31471;&#26041;&#24335;&#20013;&#32852;&#21512;&#20248;&#21270;&#22768;&#23398;&#27169;&#22411;&#21644;&#35821;&#35328;&#27169;&#22411;&#23545;&#20110;&#25991;&#26412;&#36866;&#24212;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#29305;&#21035;&#26159;&#65292;&#26377;&#25928;&#12289;&#24555;&#36895;&#21644;&#24265;&#20215;&#22320;&#36866;&#24212;&#25991;&#26412;&#24050;&#25104;&#20026;&#22312;&#24037;&#19994;&#20013;&#37096;&#32626;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#31995;&#32479;&#30340;&#20027;&#35201;&#20851;&#27880;&#28857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#21363;&#21322;&#28151;&#21512;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#35821;&#38899;&#35782;&#21035;&#27169;&#22411;&#65292;&#20445;&#30041;&#20102;&#20256;&#32479;&#28151;&#21512;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#31995;&#32479;&#30340;&#27169;&#22359;&#21270;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#21322;&#28151;&#21512;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#23558;&#22768;&#23398;&#27169;&#22411;&#21644;&#35821;&#35328;&#27169;&#22411;&#20998;&#31163;&#65292;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#25216;&#26415;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#22495;&#22806;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#21322;&#28151;&#21512;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#27169;&#22411;&#22312;&#35789;&#38169;&#35823;&#29575;&#19978;&#23454;&#29616;&#20102;21\%&#30340;&#25913;&#36827;&#65292;&#24182;&#19988;&#22312;&#24120;&#35268;&#27979;&#35797;&#38598;&#19978;&#30340;&#35789;&#38169;&#35823;&#29575;&#21482;&#26377;&#36731;&#24494;&#30340;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention-based encoder-decoder (AED) speech recognition model has been widely successful in recent years. However, the joint optimization of acoustic model and language model in end-to-end manner has created challenges for text adaptation. In particular, effectively, quickly and inexpensively adapting text has become a primary concern for deploying AED systems in industry. To address this issue, we propose a novel model, the hybrid attention-based encoder-decoder (HAED) speech recognition model that preserves the modularity of conventional hybrid automatic speech recognition systems. Our HAED model separates the acoustic and language models, allowing for the use of conventional text-based language model adaptation techniques. We demonstrate that the proposed HAED model yields 21\% Word Error Rate (WER) improvements in relative when out-of-domain text data is used for language model adaptation, and with only a minor degradation in WER on a general test set compared with conventional AE
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36923;&#36753;&#25512;&#29702;&#33021;&#21147;&#65292;&#36873;&#25321;&#20102;15&#20010;&#20856;&#22411;&#25968;&#25454;&#38598;&#65292;&#32771;&#34385;&#20102;&#28436;&#32462;&#12289;&#24402;&#32435;&#12289;&#38463;&#24067;&#36798;&#26031;&#21644;&#28151;&#21512;&#25512;&#29702;&#24418;&#24335;&#65292;&#24182;&#36873;&#25321;&#20102;&#19977;&#20010;&#20195;&#34920;&#24615;&#30340;LLMs&#36827;&#34892;&#38646;&#26679;&#26412;&#12289;&#19968;&#27425;&#21644;&#19977;&#27425;&#30340;&#35774;&#32622;&#19979;&#35780;&#20272;&#12290;&#25552;&#20986;&#31934;&#32454;&#32423;&#21035;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.09841</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30495;&#30340;&#26159;&#33391;&#22909;&#30340;&#36923;&#36753;&#25512;&#29702;&#32773;&#21527;&#65311;&#22522;&#20110;&#28436;&#32462;&#12289;&#24402;&#32435;&#21644;&#38463;&#24067;&#36798;&#26031;&#35266;&#28857;&#30340;&#20840;&#38754;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views. (arXiv:2306.09841v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36923;&#36753;&#25512;&#29702;&#33021;&#21147;&#65292;&#36873;&#25321;&#20102;15&#20010;&#20856;&#22411;&#25968;&#25454;&#38598;&#65292;&#32771;&#34385;&#20102;&#28436;&#32462;&#12289;&#24402;&#32435;&#12289;&#38463;&#24067;&#36798;&#26031;&#21644;&#28151;&#21512;&#25512;&#29702;&#24418;&#24335;&#65292;&#24182;&#36873;&#25321;&#20102;&#19977;&#20010;&#20195;&#34920;&#24615;&#30340;LLMs&#36827;&#34892;&#38646;&#26679;&#26412;&#12289;&#19968;&#27425;&#21644;&#19977;&#27425;&#30340;&#35774;&#32622;&#19979;&#35780;&#20272;&#12290;&#25552;&#20986;&#31934;&#32454;&#32423;&#21035;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#23545;LLMs&#30340;&#20855;&#20307;&#25512;&#29702;&#33021;&#21147;&#36827;&#34892;&#35780;&#20272;&#65292;&#22914;&#22810;&#35821;&#35328;&#25512;&#29702;&#21644;&#25968;&#23398;&#25512;&#29702;&#65292;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#20851;&#38190;&#25512;&#29702;&#35270;&#35282;&#20043;&#19968;&#65292;&#36923;&#36753;&#25512;&#29702;&#33021;&#21147;&#36824;&#27809;&#26377;&#24471;&#21040;&#24443;&#24213;&#35780;&#20272;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#20123;&#24046;&#36317;&#24182;&#25552;&#20379;&#20840;&#38754;&#30340;&#35780;&#20272;&#12290;&#39318;&#20808;&#65292;&#20026;&#20102;&#36827;&#34892;&#31995;&#32479;&#21270;&#35780;&#20272;&#65292;&#26412;&#25991;&#36873;&#25321;&#20102;15&#20010;&#20856;&#22411;&#30340;&#36923;&#36753;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#24182;&#23558;&#23427;&#20204;&#32452;&#32455;&#25104;&#28436;&#32462;&#12289;&#24402;&#32435;&#12289;&#38463;&#24067;&#36798;&#26031;&#21644;&#28151;&#21512;&#24418;&#24335;&#30340;&#25512;&#29702;&#35774;&#32622;&#12290;&#32771;&#34385;&#35780;&#20272;&#30340;&#20840;&#38754;&#24615;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;&#19977;&#20010;&#20195;&#34920;&#24615;&#30340;LLMs&#65288;text-davinci-003&#65292;ChatGPT&#21644;BARD&#65289;&#65292;&#24182;&#22312;&#38646;&#26679;&#26412;&#12289;&#19968;&#27425;&#21644;&#19977;&#27425;&#30340;&#35774;&#32622;&#19979;&#23545;&#25152;&#26377;&#36873;&#25321;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#12290;&#20854;&#27425;&#65292;&#19982;&#20197;&#24448;&#20165;&#20381;&#36182;&#31616;&#21333;&#25351;&#26631;&#65288;&#22914;&#20934;&#30830;&#24615;&#65289;&#30340;&#35780;&#20272;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#30446;&#26631;&#25512;&#29702;&#35282;&#24230;&#36827;&#34892;&#30340;&#31934;&#32454;&#32423;&#21035;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have achieved great success in various natural language tasks. It has aroused much interest in evaluating the specific reasoning capability of LLMs, such as multilingual reasoning and mathematical reasoning. However, as one of the key reasoning perspectives, logical reasoning capability has not yet been thoroughly evaluated. In this work, we aim to bridge those gaps and provide comprehensive evaluations. Firstly, to offer systematic evaluations, this paper selects fifteen typical logical reasoning datasets and organizes them into deductive, inductive, abductive and mixed-form reasoning settings. Considering the comprehensiveness of evaluations, we include three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD) and evaluate them on all selected datasets under zero-shot, one-shot and three-shot settings. Secondly, different from previous evaluations relying only on simple metrics (e.g., accuracy), we propose fine-level evaluations from objective 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;Few-shot Intent Classification&#20219;&#21153;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#22312;&#22806;&#37096;&#36164;&#28304;&#19978;&#36830;&#32493;&#39044;&#35757;&#32451;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#30452;&#25509;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#24773;&#20917;&#19979;&#24050;&#32463;&#21487;&#20197;&#21462;&#24471;&#19981;&#38169;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#36830;&#32493;&#39044;&#35757;&#32451;&#24182;&#38750;&#24517;&#35201;&#12290;</title><link>http://arxiv.org/abs/2306.05278</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#20351;&#29992;PLMs&#30340;Few-shot Intent Classification: &#30452;&#25509;&#24494;&#35843; vs &#36830;&#32493;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Revisit Few-shot Intent Classification with PLMs: Direct Fine-tuning vs. Continual Pre-training. (arXiv:2306.05278v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;Few-shot Intent Classification&#20219;&#21153;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#22312;&#22806;&#37096;&#36164;&#28304;&#19978;&#36830;&#32493;&#39044;&#35757;&#32451;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#30452;&#25509;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#24773;&#20917;&#19979;&#24050;&#32463;&#21487;&#20197;&#21462;&#24471;&#19981;&#38169;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#36830;&#32493;&#39044;&#35757;&#32451;&#24182;&#38750;&#24517;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;Few-shot Intent Classification&#20219;&#21153;&#65292;&#35813;&#20219;&#21153;&#28041;&#21450;&#20165;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20197;&#22522;&#20110;&#20854;&#22522;&#30784;&#24847;&#22270;&#20998;&#31867;&#35805;&#35821;&#12290;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#24403;&#21069;&#26041;&#27861;&#26159;&#36890;&#36807;&#36830;&#32493;&#39044;&#35757;&#32451;&#65292;&#21363;&#22312;&#22806;&#37096;&#36164;&#28304;&#65288;&#20363;&#22914;&#20250;&#35805;&#35821;&#26009;&#24211;&#12289;&#20844;&#20849;&#24847;&#22270;&#26816;&#27979;&#25968;&#25454;&#38598;&#25110;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#25968;&#25454;&#38598;&#65289;&#19978;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;&#28982;&#21518;&#20351;&#29992;&#23427;&#20204;&#20316;&#20026;&#35805;&#35821;&#32534;&#30721;&#22120;&#26469;&#35757;&#32451;&#24847;&#22270;&#20998;&#31867;&#22120;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36830;&#32493;&#39044;&#35757;&#32451;&#21487;&#33021;&#24182;&#38750;&#24517;&#35201;&#65292;&#22240;&#20026;PLMs&#22312;&#27492;&#20219;&#21153;&#19978;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#21487;&#33021;&#24182;&#19981;&#20687;&#39044;&#26399;&#30340;&#37027;&#26679;&#20005;&#37325;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#30452;&#25509;&#23545;&#20165;&#26377;&#23569;&#37327;&#26631;&#35760;&#31034;&#20363;&#30340;PLMs&#36827;&#34892;&#24494;&#35843;&#24050;&#32463;&#21487;&#20197;&#20135;&#29983;&#30456;&#24403;&#19981;&#38169;&#30340;&#32467;&#26524;&#65292;&#32780;&#32489;&#25928;&#24046;&#36317;&#38543;&#30528;&#26631;&#35760;&#25968;&#25454;&#37327;&#30340;&#22686;&#21152;&#36805;&#36895;&#32553;&#23567;&#12290;&#20026;&#20102;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24494;&#35843;&#31574;&#30053;&#65292;&#21363;&#27880;&#24847;&#21147;&#27969;&#25511;&#65288;Attention Flow Control&#65289;&#65292;&#20854;&#20801;&#35768;&#22312;&#19981;&#21516;&#30340;&#39044;&#35757;&#32451;&#23618;&#20043;&#38388;&#21160;&#24577;&#20998;&#37197;&#24494;&#35843;&#30340;&#37325;&#24515;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the task of few-shot intent detection, which involves training a deep learning model to classify utterances based on their underlying intents using only a small amount of labeled data. The current approach to address this problem is through continual pre-training, i.e., fine-tuning pre-trained language models (PLMs) on external resources (e.g., conversational corpora, public intent detection datasets, or natural language understanding datasets) before using them as utterance encoders for training an intent classifier. In this paper, we show that continual pre-training may not be essential, since the overfitting problem of PLMs on this task may not be as serious as expected. Specifically, we find that directly fine-tuning PLMs on only a handful of labeled examples already yields decent results compared to methods that employ continual pre-training, and the performance gap diminishes rapidly as the number of labeled data increases. To maximize the utilization of the limited a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36923;&#36753;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#31070;&#32463;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#21487;&#35299;&#37322;&#24615;&#36923;&#36753;&#23376;&#21477;&#34920;&#36798;&#30446;&#26631;&#20219;&#21153;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#34920;&#24449;&#21442;&#25968;&#21270;&#31526;&#21495;&#36923;&#36753;&#20803;&#32032;&#65292;&#20174;&#32780;&#20415;&#20110;&#33258;&#21160;&#29983;&#25104;&#21644;&#35780;&#20272;&#26377;&#24847;&#20041;&#30340;&#36923;&#36753;&#23376;&#21477;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#20102;&#20116;&#20010;&#20803;&#39044;&#27979;&#22120;&#26469;&#25429;&#33719;&#34394;&#20551;&#20449;&#24687;&#30340;&#22522;&#26412;&#27169;&#24335;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#19981;&#20165;&#24615;&#33021;&#26174;&#33879;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#65292;&#32780;&#19988;&#25552;&#20379;&#20102;&#36879;&#26126;&#19988;&#21487;&#35299;&#37322;&#30340;&#36923;&#36753;&#25512;&#29702;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.05964</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#35299;&#37322;&#24615;&#26816;&#27979;&#19982;&#36923;&#36753;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Interpretable Multimodal Misinformation Detection with Logic Reasoning. (arXiv:2305.05964v1 [cs.MM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05964
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36923;&#36753;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#31070;&#32463;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#21487;&#35299;&#37322;&#24615;&#36923;&#36753;&#23376;&#21477;&#34920;&#36798;&#30446;&#26631;&#20219;&#21153;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#34920;&#24449;&#21442;&#25968;&#21270;&#31526;&#21495;&#36923;&#36753;&#20803;&#32032;&#65292;&#20174;&#32780;&#20415;&#20110;&#33258;&#21160;&#29983;&#25104;&#21644;&#35780;&#20272;&#26377;&#24847;&#20041;&#30340;&#36923;&#36753;&#23376;&#21477;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#20102;&#20116;&#20010;&#20803;&#39044;&#27979;&#22120;&#26469;&#25429;&#33719;&#34394;&#20551;&#20449;&#24687;&#30340;&#22522;&#26412;&#27169;&#24335;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#19981;&#20165;&#24615;&#33021;&#26174;&#33879;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#65292;&#32780;&#19988;&#25552;&#20379;&#20102;&#36879;&#26126;&#19988;&#21487;&#35299;&#37322;&#30340;&#36923;&#36753;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#31038;&#20132;&#24179;&#21488;&#19978;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#30001;&#20110;&#22810;&#23186;&#20307;&#20869;&#23481;&#30340;&#21487;&#20449;&#24230;&#21644;&#20256;&#25773;&#26356;&#23481;&#26131;&#32780;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#22810;&#27169;&#24577;&#26816;&#27979;&#26041;&#27861;&#24050;&#32463;&#36798;&#21040;&#20102;&#36739;&#39640;&#30340;&#24615;&#33021;&#65292;&#20294;&#32570;&#20047;&#35299;&#37322;&#24615;&#38459;&#30861;&#20102;&#36825;&#20123;&#31995;&#32479;&#30340;&#21487;&#38752;&#24615;&#21644;&#23454;&#38469;&#37096;&#32626;&#12290;&#21463;&#21040; NeuralSymbolic AI &#30340;&#21551;&#21457;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#33021;&#21147;&#21644;&#31526;&#21495;&#23398;&#20064;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36923;&#36753;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#31070;&#32463;&#27169;&#22411;&#65292;&#23427;&#38598;&#25104;&#20102;&#21487;&#35299;&#37322;&#24615;&#36923;&#36753;&#23376;&#21477;&#20197;&#34920;&#36798;&#30446;&#26631;&#20219;&#21153;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20026;&#20102;&#20351;&#23398;&#20064;&#26377;&#25928;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#34920;&#24449;&#26469;&#21442;&#25968;&#21270;&#31526;&#21495;&#36923;&#36753;&#20803;&#32032;&#65292;&#20174;&#32780;&#20415;&#20110;&#33258;&#21160;&#29983;&#25104;&#21644;&#35780;&#20272;&#26377;&#24847;&#20041;&#30340;&#36923;&#36753;&#23376;&#21477;&#12290;&#21478;&#22806;&#65292;&#20026;&#20102;&#20351;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#36866;&#29992;&#20110;&#21508;&#31181;&#34394;&#20551;&#20449;&#24687;&#26469;&#28304;&#65292;&#25105;&#20204;&#22312;&#22810;&#27169;&#24577;&#34701;&#21512;&#32593;&#32476;&#20013;&#24341;&#20837;&#20102;&#20116;&#20010;&#20803;&#39044;&#27979;&#22120;&#26469;&#25429;&#33719;&#34394;&#20551;&#20449;&#24687;&#30340;&#22522;&#26412;&#27169;&#24335;&#12290;&#25105;&#20204;&#22312;&#23454;&#38469;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#19981;&#20165;&#26174;&#30528;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#36824;&#20026;&#27599;&#20010;&#39044;&#27979;&#25552;&#20379;&#20102;&#36879;&#26126;&#19988;&#21487;&#35299;&#37322;&#30340;&#36923;&#36753;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal misinformation on online social platforms is becoming a critical concern due to increasing credibility and easier dissemination brought by multimedia content, compared to traditional text-only information. While existing multimodal detection approaches have achieved high performance, the lack of interpretability hinders these systems' reliability and practical deployment. Inspired by NeuralSymbolic AI which combines the learning ability of neural networks with the explainability of symbolic learning, we propose a novel logic-based neural model for multimodal misinformation detection which integrates interpretable logic clauses to express the reasoning process of the target task. To make learning effective, we parameterize symbolic logical elements using neural representations, which facilitate the automatic generation and evaluation of meaningful logic clauses. Additionally, to make our framework generalizable across diverse misinformation sources, we introduce five meta-pre
&lt;/p&gt;</description></item></channel></rss>