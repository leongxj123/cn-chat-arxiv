<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>LLM&#21463;&#21040;&#27745;&#26579;&#21487;&#33021;&#23548;&#33268;&#20854;&#24615;&#33021;&#19981;&#21487;&#38752;&#65292;&#25361;&#25112;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2404.00699</link><description>&lt;p&gt;
LLM&#21463;&#21040;&#22810;&#23569;&#27745;&#26579;&#65311;&#19968;&#39033;&#20840;&#38754;&#35843;&#26597;&#21644;LLMSanitize&#24211;
&lt;/p&gt;
&lt;p&gt;
How Much are LLMs Contaminated? A Comprehensive Survey and the LLMSanitize Library
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00699
&lt;/p&gt;
&lt;p&gt;
LLM&#21463;&#21040;&#27745;&#26579;&#21487;&#33021;&#23548;&#33268;&#20854;&#24615;&#33021;&#19981;&#21487;&#38752;&#65292;&#25361;&#25112;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#36817;&#24180;&#26469;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23835;&#36215;&#65292;&#26032;&#30340;&#26426;&#20250;&#27491;&#22312;&#20986;&#29616;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#27745;&#26579;&#38382;&#39064;&#36805;&#36895;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#20225;&#19994;&#24212;&#29992;&#21644;&#20154;&#24037;&#26234;&#33021;&#31609;&#27454;&#24050;&#32463;&#36798;&#21040;&#19968;&#23450;&#35268;&#27169;&#65292;&#27969;&#34892;&#30340;&#38382;&#31572;&#22522;&#20934;&#25552;&#39640;&#20960;&#20010;&#30334;&#20998;&#28857;&#21487;&#33021;&#24847;&#21619;&#30528;&#25968;&#30334;&#19975;&#32654;&#20803;&#65292;&#23545;&#27169;&#22411;&#30340;&#23436;&#25972;&#24615;&#26045;&#21152;&#20102;&#24040;&#22823;&#21387;&#21147;&#12290;&#21516;&#26102;&#65292;&#36861;&#36394;LLMs&#35265;&#36807;&#30340;&#25968;&#25454;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#65307;&#23545;&#20110;&#20687;GPT-4&#21644;Claude-3&#36825;&#26679;&#30340;&#38381;&#28304;&#27169;&#22411;&#65292;&#20182;&#20204;&#19981;&#36879;&#38706;&#20219;&#20309;&#26377;&#20851;&#35757;&#32451;&#38598;&#30340;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#27745;&#26579;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;LLMs&#30340;&#24615;&#33021;&#21487;&#33021;&#19981;&#20877;&#21487;&#38752;&#65292;&#22240;&#20026;&#20854;&#39640;&#24615;&#33021;&#33267;&#23569;&#37096;&#20998;&#24402;&#22240;&#20110;&#20854;&#20808;&#21069;&#25509;&#35302;&#21040;&#30340;&#25968;&#25454;&#12290;&#36825;&#31181;&#23616;&#38480;&#24615;&#21361;&#21450;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#22914;&#20309;&#26377;&#25928;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#20173;&#28982;&#32570;&#20047;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00699v1 Announce Type: new  Abstract: With the rise of Large Language Models (LLMs) in recent years, new opportunities are emerging, but also new challenges, and contamination is quickly becoming critical. Business applications and fundraising in AI have reached a scale at which a few percentage points gained on popular question-answering benchmarks could translate into dozens of millions of dollars, placing high pressure on model integrity. At the same time, it is becoming harder and harder to keep track of the data that LLMs have seen; if not impossible with closed-source models like GPT-4 and Claude-3 not divulging any information on the training set. As a result, contamination becomes a critical issue: LLMs' performance may not be reliable anymore, as the high performance may be at least partly due to their previous exposure to the data. This limitation jeopardizes the entire progress in the field of NLP, yet, there remains a lack of methods on how to efficiently address
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29616;&#26377;&#20998;&#31867;&#23398;&#36827;&#34892;&#23454;&#20307;&#20851;&#31995;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#23454;&#20307;&#38598;&#25193;&#23637;&#12289;&#20998;&#31867;&#23398;&#25193;&#23637;&#21644;&#31181;&#23376;&#24341;&#23548;&#20998;&#31867;&#23398;&#26500;&#24314;&#19977;&#20010;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.13405</link><description>&lt;p&gt;
&#19968;&#20010;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#21644;&#20998;&#31867;&#23398;&#25193;&#23637;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13405
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29616;&#26377;&#20998;&#31867;&#23398;&#36827;&#34892;&#23454;&#20307;&#20851;&#31995;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#23454;&#20307;&#38598;&#25193;&#23637;&#12289;&#20998;&#31867;&#23398;&#25193;&#23637;&#21644;&#31181;&#23376;&#24341;&#23548;&#20998;&#31867;&#23398;&#26500;&#24314;&#19977;&#20010;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#38598;&#25193;&#23637;&#12289;&#20998;&#31867;&#23398;&#25193;&#23637;&#21644;&#31181;&#23376;&#24341;&#23548;&#20998;&#31867;&#23398;&#26500;&#24314;&#26159;&#19977;&#20010;&#20195;&#34920;&#24615;&#20219;&#21153;&#65292;&#21487;&#20197;&#29992;&#26469;&#33258;&#21160;&#21521;&#29616;&#26377;&#20998;&#31867;&#23398;&#22635;&#20805;&#26032;&#23454;&#20307;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#24322;&#36136;&#25216;&#26415;&#20998;&#21035;&#35299;&#20915;&#36825;&#20123;&#20219;&#21153;&#65292;&#32570;&#20047;&#32479;&#19968;&#30340;&#35270;&#35282;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#20998;&#31867;&#23398;&#32467;&#26500;&#30340;&#35270;&#35282;&#30830;&#35748;&#20102;&#36825;&#20123;&#20219;&#21153;&#25152;&#38656;&#30340;&#20849;&#21516;&#20851;&#38190;&#25216;&#33021;&#8212;&#8212;&#25214;&#21040;&#8220;&#20804;&#24351;&#8221;&#21644;&#25214;&#21040;&#8220;&#29238;&#27597;&#8221;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;&#26469;&#20849;&#21516;&#35299;&#20915;&#36825;&#19977;&#20010;&#20219;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#26377;&#20998;&#31867;&#23398;&#20316;&#20026;&#20016;&#23500;&#30340;&#23454;&#20307;&#20851;&#31995;&#28304;&#65292;&#25105;&#20204;&#21033;&#29992;&#25351;&#23548;&#35843;&#25972;&#26469;&#24494;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#29983;&#25104;&#29238;&#27597;&#21644;&#20804;&#24351;&#23454;&#20307;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;TaxoInstruct&#30340;&#26377;&#25928;&#24615;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#39033;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13405v1 Announce Type: new  Abstract: Entity Set Expansion, Taxonomy Expansion, and Seed-Guided Taxonomy Construction are three representative tasks that can be used to automatically populate an existing taxonomy with new entities. However, previous approaches often address these tasks separately with heterogeneous techniques, lacking a unified perspective. To tackle this issue, in this paper, we identify the common key skills needed for these tasks from the view of taxonomy structures -- finding 'siblings' and finding 'parents' -- and propose a unified taxonomy-guided instruction tuning framework to jointly solve the three tasks. To be specific, by leveraging the existing taxonomy as a rich source of entity relationships, we utilize instruction tuning to fine-tune a large language model to generate parent and sibling entities. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of TaxoInstruct, which outperforms task-specific baselines across 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#27604;&#25552;&#31034;&#33258;&#25105;&#22870;&#21169;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#21160;&#23545;&#40784;&#26041;&#27861;&#65292;&#26080;&#38656;&#20381;&#36182;&#20154;&#24037;&#27880;&#37322;&#30340;&#20559;&#22909;&#25968;&#25454;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;RLHF&#12290;</title><link>https://arxiv.org/abs/2402.11907</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#25105;&#22870;&#21169;&#23545;&#27604;&#25552;&#31034;&#31934;&#28860;&#30452;&#25509;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11907
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#25552;&#31034;&#33258;&#25105;&#22870;&#21169;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#21160;&#23545;&#40784;&#26041;&#27861;&#65292;&#26080;&#38656;&#20381;&#36182;&#20154;&#24037;&#27880;&#37322;&#30340;&#20559;&#22909;&#25968;&#25454;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;RLHF&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#27604;&#25552;&#31034;&#23545;&#21709;&#24212;&#23545;&#30340;&#36755;&#20986;&#27010;&#29575;&#36827;&#34892;&#35780;&#20272;&#65292;&#20174;&#32780;&#22312;LLaMA2-7B&#21644;LLaMA2-13B&#19978;&#23454;&#29616;&#20102;&#27604;RLAIF&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#23545;&#40784;&#26041;&#27861;&#65292;&#21363;&#30452;&#25509;&#22823;&#22411;&#27169;&#22411;&#23545;&#40784;&#65288;DLMA&#65289;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20351;&#29992;&#23545;&#27604;&#25552;&#31034;&#23545;&#33258;&#21160;&#29983;&#25104;&#30340;&#20559;&#22909;&#25968;&#25454;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32487;&#32493;&#20351;&#29992;&#23545;&#27604;&#25552;&#31034;&#23545;&#29983;&#25104;&#30340;&#20559;&#22909;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#24182;&#35745;&#31639;&#33258;&#25105;&#22870;&#21169;&#20998;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;DPO&#31639;&#27861;&#36890;&#36807;&#32467;&#21512;&#36825;&#31181;&#33258;&#25105;&#22870;&#21169;&#20998;&#25968;&#26469;&#26377;&#25928;&#22320;&#23545;&#40784;LLMs&#12290;&#22312;&#23454;&#39564;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;DLMA&#26041;&#27861;&#33021;&#22815;&#22312;&#19981;&#20381;&#36182;&#20154;&#24037;&#27880;&#37322;&#30340;&#20559;&#22909;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36229;&#36234;RLHF&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11907v1 Announce Type: new  Abstract: Aligning large language models (LLMs) with human expectations without human-annotated preference data is an important problem. In this paper, we propose a method to evaluate the response preference by using the output probabilities of response pairs under contrastive prompt pairs, which could achieve better performance on LLaMA2-7B and LLaMA2-13B compared to RLAIF. Based on this, we propose an automatic alignment method, Direct Large Model Alignment (DLMA). First, we use contrastive prompt pairs to automatically generate preference data. Then, we continue to evaluate the generated preference data using contrastive prompt pairs and calculate a self-rewarding score. Finally, we use the DPO algorithm to effectively align LLMs by combining this self-rewarding score. In the experimental stage, our DLMA method could surpass the \texttt{RLHF} method without relying on human-annotated preference data.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#21462;&#20195;&#32463;&#27982;&#23454;&#39564;&#23460;&#36827;&#34892;&#36873;&#25321;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17435</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#21462;&#20195;&#32463;&#27982;&#36873;&#25321;&#39044;&#27979;&#23454;&#39564;&#23460;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Replace Economic Choice Prediction Labs?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17435
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#21462;&#20195;&#32463;&#27982;&#23454;&#39564;&#23460;&#36827;&#34892;&#36873;&#25321;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#27982;&#36873;&#25321;&#39044;&#27979;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#37325;&#35201;&#20219;&#21153;&#65292;&#24448;&#24448;&#21463;&#38480;&#20110;&#33719;&#21462;&#20154;&#31867;&#36873;&#25321;&#25968;&#25454;&#30340;&#22256;&#38590;&#12290;&#23454;&#39564;&#32463;&#27982;&#23398;&#30740;&#31350;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#19987;&#27880;&#20110;&#31616;&#21333;&#30340;&#36873;&#25321;&#29615;&#22659;&#12290;&#26368;&#36817;&#65292;&#20154;&#24037;&#26234;&#33021;&#30028;&#20197;&#20004;&#31181;&#26041;&#24335;&#20026;&#35813;&#21162;&#21147;&#20570;&#20986;&#20102;&#36129;&#29486;&#65306;&#32771;&#34385;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#21487;&#20197;&#20195;&#26367;&#20154;&#31867;&#22312;&#19978;&#36848;&#31616;&#21333;&#36873;&#25321;&#39044;&#27979;&#29615;&#22659;&#20013;&#65292;&#20197;&#21450;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#35270;&#35282;&#30740;&#31350;&#26356;&#22797;&#26434;&#20294;&#20173;&#20005;&#26684;&#30340;&#23454;&#39564;&#32463;&#27982;&#23398;&#29615;&#22659;&#65292;&#21253;&#25324;&#19981;&#23436;&#20840;&#20449;&#24687;&#12289;&#37325;&#22797;&#21338;&#24328;&#21644;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#30340;&#35828;&#26381;&#28216;&#25103;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#28789;&#24863;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#23436;&#20840;&#27169;&#25311;&#32463;&#27982;&#29615;&#22659;&#65292;&#24182;&#29983;&#25104;&#29992;&#20110;&#39640;&#25928;&#20154;&#31867;&#36873;&#25321;&#39044;&#27979;&#30340;&#25968;&#25454;&#65292;&#26367;&#20195;&#22797;&#26434;&#30340;&#32463;&#27982;&#23454;&#39564;&#23460;&#30740;&#31350;&#65311;&#25105;&#20204;&#22312;&#36825;&#20010;&#20027;&#39064;&#19978;&#24320;&#21019;&#20102;&#30740;&#31350;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#34920;&#26126;&#20165;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Economic choice prediction is an essential challenging task, often constrained by the difficulties in acquiring human choice data. Indeed, experimental economics studies had focused mostly on simple choice settings. The AI community has recently contributed to that effort in two ways: considering whether LLMs can substitute for humans in the above-mentioned simple choice prediction settings, and the study through ML lens of more elaborated but still rigorous experimental economics settings, employing incomplete information, repetitive play, and natural language communication, notably language-based persuasion games. This leaves us with a major inspiration: can LLMs be used to fully simulate the economic environment and generate data for efficient human choice prediction, substituting for the elaborated economic lab studies? We pioneer the study of this subject, demonstrating its feasibility. In particular, we show that a model trained solely on LLM-generated data can effectively predic
&lt;/p&gt;</description></item><item><title>CoTFormer&#26159;&#19968;&#31181;transformer&#21464;&#20307;&#65292;&#36890;&#36807;&#20351;&#29992;&#38544;&#21547;&#30340;&#38142;&#24605;&#32771;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#19982;&#26356;&#28145;&#27169;&#22411;&#30456;&#24403;&#30340;&#23481;&#37327;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#20013;&#26174;&#33879;&#20248;&#20110;&#26356;&#22823;&#30340;&#26631;&#20934;transformers&#12290;</title><link>http://arxiv.org/abs/2310.10845</link><description>&lt;p&gt;
CoTFormer&#65306;&#26356;&#22810;&#30340;&#20851;&#27880;&#20196;&#29260;&#24357;&#34917;&#20102;&#26356;&#23569;&#30340;&#28145;&#24230;
&lt;/p&gt;
&lt;p&gt;
CoTFormer: More Tokens With Attention Make Up For Less Depth. (arXiv:2310.10845v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10845
&lt;/p&gt;
&lt;p&gt;
CoTFormer&#26159;&#19968;&#31181;transformer&#21464;&#20307;&#65292;&#36890;&#36807;&#20351;&#29992;&#38544;&#21547;&#30340;&#38142;&#24605;&#32771;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#19982;&#26356;&#28145;&#27169;&#22411;&#30456;&#24403;&#30340;&#23481;&#37327;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#20013;&#26174;&#33879;&#20248;&#20110;&#26356;&#22823;&#30340;&#26631;&#20934;transformers&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#21457;&#23637;&#36234;&#26469;&#36234;&#22823;&#21644;&#26356;&#28145;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#31454;&#36187;&#27491;&#22312;&#36827;&#34892;&#20013;&#12290;&#28982;&#32780;&#65292;&#20687;&#38142;&#24605;&#32771;&#65288;CoT&#65289;&#26041;&#27861;&#36825;&#26679;&#30340;&#25216;&#26415;&#22312;&#23454;&#29616;&#26368;&#20339;&#19979;&#28216;&#24615;&#33021;&#26041;&#38754;&#20173;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20351;&#29992;&#38142;&#24605;&#32771;&#21644;&#20351;&#29992;&#26356;&#28145;&#30340;transformer&#20043;&#38388;&#30340;&#36817;&#20284;&#24179;&#34892;&#20851;&#31995;&#12290;&#22522;&#20110;&#36825;&#19968;&#27934;&#35265;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CoTFormer&#65292;&#19968;&#31181;&#20351;&#29992;&#38544;&#21547;&#38142;&#24605;&#32771;&#26426;&#21046;&#26469;&#23454;&#29616;&#19982;&#26356;&#28145;&#27169;&#22411;&#30456;&#24403;&#23481;&#37327;&#30340;transformer&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#21457;&#29616;&#35777;&#26126;&#20102;CoTFormer&#30340;&#26377;&#25928;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#26126;&#26174;&#20248;&#20110;&#26356;&#22823;&#30340;&#26631;&#20934;transformers&#12290;
&lt;/p&gt;
&lt;p&gt;
The race to continually develop ever larger and deeper foundational models is underway. However, techniques like the Chain-of-Thought (CoT) method continue to play a pivotal role in achieving optimal downstream performance. In this work, we establish an approximate parallel between using chain-of-thought and employing a deeper transformer. Building on this insight, we introduce CoTFormer, a transformer variant that employs an implicit CoT-like mechanism to achieve capacity comparable to a deeper model. Our empirical findings demonstrate the effectiveness of CoTFormers, as they significantly outperform larger standard transformers.
&lt;/p&gt;</description></item></channel></rss>