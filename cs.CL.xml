<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25361;&#25112;&#24615;&#25968;&#25454;&#38598;MORE&#65292;&#21516;&#26102;&#25552;&#20986;&#20004;&#31181;&#20943;&#36731;&#21333;&#27169;&#24577;&#20559;&#24046;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.18346</link><description>&lt;p&gt;
&#22312;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#37327;&#21270;&#21644;&#20943;&#36731;&#21333;&#27169;&#24577;&#20559;&#24046;&#65306;&#22240;&#26524;&#20851;&#31995;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18346
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25361;&#25112;&#24615;&#25968;&#25454;&#38598;MORE&#65292;&#21516;&#26102;&#25552;&#20986;&#20004;&#31181;&#20943;&#36731;&#21333;&#27169;&#24577;&#20559;&#24046;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#20419;&#36827;&#20102;&#22810;&#27169;&#24577;LLMs&#65288;MLLMs&#65289;&#30340;&#21457;&#23637;&#12290;&#23613;&#31649;&#23427;&#20204;&#20855;&#26377;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#65292;&#20294;MLLMs&#36890;&#24120;&#36807;&#24230;&#20381;&#36182;&#21333;&#27169;&#24577;&#20559;&#24046;&#65288;&#20363;&#22914;&#35821;&#35328;&#20559;&#24046;&#21644;&#35270;&#35273;&#20559;&#24046;&#65289;&#65292;&#23548;&#33268;&#22312;&#22797;&#26434;&#22810;&#27169;&#24577;&#20219;&#21153;&#20013;&#32473;&#20986;&#19981;&#27491;&#30830;&#31572;&#26696;&#12290;&#20026;&#20102;&#35843;&#26597;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26694;&#26550;&#26469;&#35299;&#37322;&#35270;&#35273;&#38382;&#31572;&#65288;VQA&#65289;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22240;&#26524;&#22270;&#26469;&#38416;&#26126;MLLMs&#23545;VQA&#38382;&#39064;&#30340;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#28145;&#20837;&#30340;&#22240;&#26524;&#20998;&#26512;&#35780;&#20272;&#20559;&#24046;&#30340;&#22240;&#26524;&#25928;&#26524;&#12290;&#21463;&#22240;&#26524;&#22270;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;MORE&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;12,000&#20010;VQA&#23454;&#20363;&#12290;&#35813;&#25968;&#25454;&#38598;&#26088;&#22312;&#25361;&#25112;MLLMs&#30340;&#33021;&#21147;&#65292;&#38656;&#35201;&#22810;&#36339;&#25512;&#29702;&#21644;&#20811;&#26381;&#21333;&#27169;&#24577;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#26469;&#20943;&#36731;&#21333;&#27169;&#24577;&#20559;&#24046;&#24182;&#22686;&#24378;MLLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18346v1 Announce Type: new  Abstract: Recent advancements in Large Language Models (LLMs) have facilitated the development of Multimodal LLMs (MLLMs). Despite their impressive capabilities, MLLMs often suffer from an over-reliance on unimodal biases (e.g., language bias and vision bias), leading to incorrect answers in complex multimodal tasks. To investigate this issue, we propose a causal framework to interpret the biases in Visual Question Answering (VQA) problems. Within our framework, we devise a causal graph to elucidate the predictions of MLLMs on VQA problems, and assess the causal effect of biases through an in-depth causal analysis. Motivated by the causal graph, we introduce a novel MORE dataset, consisting of 12,000 VQA instances. This dataset is designed to challenge MLLMs' abilities, necessitating multi-hop reasoning and the surmounting of unimodal biases. Furthermore, we propose two strategies to mitigate unimodal biases and enhance MLLMs' reasoning capabiliti
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#34701;&#21512;&#26041;&#27861;&#65292;&#23558;&#22797;&#26434;&#29615;&#22659;&#20013;&#30340;&#30693;&#35782;&#34701;&#20837;LLMs&#20013;&#65292;&#29992;&#20110;&#26356;&#26032;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.15736</link><description>&lt;p&gt;
LLMs&#25351;&#23548;LLMs&#65306;&#19968;&#31181;&#25552;&#21462;&#21644;&#32534;&#36753;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
LLMs Instruct LLMs:An Extraction and Editing Method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15736
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#34701;&#21512;&#26041;&#27861;&#65292;&#23558;&#22797;&#26434;&#29615;&#22659;&#20013;&#30340;&#30693;&#35782;&#34701;&#20837;LLMs&#20013;&#65292;&#29992;&#20110;&#26356;&#26032;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15736v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#20852;&#36259;&#28857;&#22312;&#20110;&#26080;&#38656;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#21363;&#21487;&#26356;&#26032;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#20294;&#26159;&#36825;&#20063;&#24102;&#26469;&#20102;&#19968;&#20123;&#25361;&#25112;&#12290;&#23588;&#20854;&#26159;&#23545;&#20110;&#38656;&#35201;&#29992;&#26377;&#38480;&#26679;&#26412;&#36827;&#34892;&#22797;&#26434;&#25512;&#29702;&#30340;&#24773;&#20917;&#26469;&#35828;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#36866;&#29992;&#20110;LLMs&#30340;&#36139;&#20047;&#32422;&#26463;&#22797;&#26434;&#25512;&#29702;&#65288;PCRA-LLM&#65289;&#30340;&#24773;&#20917;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#21644;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#23545;&#36825;&#19968;&#20851;&#38190;&#38382;&#39064;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#23588;&#20854;&#22312;&#25105;&#20204;&#25506;&#32034;&#29305;&#23450;&#21307;&#23398;&#32972;&#26223;&#26102;&#23588;&#20026;&#26126;&#26174;&#65292;&#36825;&#20307;&#29616;&#20102;PCRA-LLM&#30340;&#29420;&#29305;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#34701;&#21512;&#26041;&#27861;&#65292;&#23558;&#22797;&#26434;&#29615;&#22659;&#20013;&#30340;&#30693;&#35782;&#34701;&#20837;LLMs&#20013;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#20004;&#38454;&#27573;&#26694;&#26550;&#65306;&#39318;&#20808;&#65292;&#21033;&#29992;&#36890;&#29992;LLMs&#26500;&#24314;&#30693;&#35782;&#22270;&#35889;&#65288;KGs&#65289;&#26469;&#20174;&#22797;&#26434;&#25991;&#26412;&#20013;&#25552;&#21462;&#30693;&#35782;&#65307;&#38543;&#21518;&#65292;&#36890;&#36807;&#30693;&#35782;&#32534;&#36753;&#26469;&#26356;&#26032;&#39046;&#22495;LLMs&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#39046;&#22495;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15736v1 Announce Type: new  Abstract: The interest in updating Large Language Models (LLMs) without retraining from scratch is substantial, yet it comes with some challenges.This is especially true for situations demanding complex reasoning with limited samples, a scenario we refer to as the Paucity-Constrained Complex Reasoning Adaptation for LLMs (PCRA-LLM).Traditional methods like Low-Rank Adaptation (LoRA) and Retrieval-Augmented Generation (RAG) are inadequate for this critical issue, particularly evident in our exploration of a specific medical context that epitomize the PCRA-LLM's distinct needs.To address the issue, we propose a Sequential Fusion method to incorporate knowledge from complex context into LLMs. This method employs a two-stage framework: initially, it leverages general LLMs to construct knowledge graphs (KGs) for extracting knowledge from complex texts; subsequently, it updates the domain LLMs through knowledge edit. According to our method, the domain 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;GlossLM&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#36328;&#35821;&#35328;&#36716;&#31227;&#21644;&#22823;&#35268;&#27169;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#20302;&#36164;&#28304;&#35821;&#35328;&#25991;&#23383;&#38388;&#27880;&#37322;&#30340;&#26377;&#25928;&#29983;&#25104;&#12290;</title><link>https://arxiv.org/abs/2403.06399</link><description>&lt;p&gt;
GlossLM: &#20302;&#36164;&#28304;&#35821;&#35328;&#25991;&#23383;&#38388;&#27880;&#37322;&#30340;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
GlossLM: Multilingual Pretraining for Low-Resource Interlinear Glossing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06399
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;GlossLM&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#36328;&#35821;&#35328;&#36716;&#31227;&#21644;&#22823;&#35268;&#27169;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#20302;&#36164;&#28304;&#35821;&#35328;&#25991;&#23383;&#38388;&#27880;&#37322;&#30340;&#26377;&#25928;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#25991;&#29486;&#23398;&#30340;&#19968;&#20010;&#20851;&#38190;&#26041;&#38754;&#26159;&#20197;&#24418;&#24335;&#22914;&#25991;&#23383;&#38388;&#27880;&#37322;&#25991;&#26412;&#65288;IGT&#65289;&#30340;&#26041;&#24335;&#21019;&#24314;&#24102;&#27880;&#37322;&#30340;&#25991;&#26412;&#65292;IGT&#20197;&#36880;&#35789;&#32032;&#30340;&#26684;&#24335;&#25429;&#25417;&#20102;&#31934;&#32454;&#30340;&#24418;&#24577;&#21477;&#27861;&#20998;&#26512;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#25506;&#32034;&#20102;&#33258;&#21160;&#29983;&#25104;IGT&#30340;&#26041;&#27861;&#65292;&#20197;&#20943;&#23569;&#35821;&#35328;&#20998;&#26512;&#30340;&#26102;&#38388;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#35821;&#35328;&#65288;&#23588;&#20854;&#26159;&#38656;&#35201;&#20445;&#25252;&#30340;&#35821;&#35328;&#65289;&#32570;&#20047;&#36275;&#22815;&#30340;IGT&#25968;&#25454;&#26469;&#35757;&#32451;&#26377;&#25928;&#30340;&#27169;&#22411;&#65292;&#36328;&#35821;&#35328;&#36716;&#31227;&#34987;&#25552;&#20986;&#20316;&#20026;&#20811;&#26381;&#36825;&#19968;&#23616;&#38480;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#32534;&#21046;&#20102;&#26469;&#33258;&#21508;&#31181;&#26469;&#28304;&#30340;&#26368;&#22823;&#24050;&#26377;IGT&#25968;&#25454;&#35821;&#26009;&#24211;&#65292;&#28085;&#30422;&#20102;&#26469;&#33258;1.8k&#31181;&#35821;&#35328;&#30340;&#36229;&#36807;45&#19975;&#20010;&#20363;&#23376;&#65292;&#20197;&#20415;&#36827;&#34892;&#36328;&#35821;&#35328;&#36716;&#31227;&#21644;IGT&#29983;&#25104;&#26041;&#38754;&#30340;&#30740;&#31350;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#37096;&#20998;&#35821;&#26009;&#24211;&#19978;&#23545;&#19968;&#20010;&#22823;&#22411;&#22810;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#24182;&#36827;&#19968;&#27493;&#23545;&#29305;&#23450;&#35821;&#35328;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#20998;&#21106;&#25968;&#25454;&#21644;&#22823;&#22411;&#21333;&#35821;&#25968;&#25454;&#26041;&#38754;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06399v1 Announce Type: new  Abstract: A key aspect of language documentation is the creation of annotated text in a format such as interlinear glossed text (IGT), which captures fine-grained morphosyntactic analyses in a morpheme-by-morpheme format. Prior work has explored methods to automatically generate IGT in order to reduce the time cost of language analysis. However, many languages (particularly those requiring preservation) lack sufficient IGT data to train effective models, and crosslingual transfer has been proposed as a method to overcome this limitation.   We compile the largest existing corpus of IGT data from a variety of sources, covering over 450k examples across 1.8k languages, to enable research on crosslingual transfer and IGT generation. Then, we pretrain a large multilingual model on a portion of this corpus, and further finetune it to specific languages. Our model is competitive with state-of-the-art methods for segmented data and large monolingual datas
&lt;/p&gt;</description></item><item><title>&#29616;&#26377;&#30340;LLM&#27700;&#21360;&#31995;&#32479;&#34429;&#28982;&#20855;&#26377;&#36136;&#37327;&#20445;&#30041;&#12289;&#40065;&#26834;&#24615;&#21644;&#20844;&#24320;&#26816;&#27979;API&#31561;&#20248;&#28857;&#65292;&#20294;&#20063;&#22240;&#27492;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#25915;&#20987;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#22871;&#23454;&#29992;&#25351;&#21335;&#20197;&#32531;&#35299;&#36825;&#20123;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2402.16187</link><description>&lt;p&gt;
&#21033;&#29992;&#20854;&#20248;&#21183;&#25915;&#20987;LLM&#27700;&#21360;
&lt;/p&gt;
&lt;p&gt;
Attacking LLM Watermarks by Exploiting Their Strengths
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16187
&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;LLM&#27700;&#21360;&#31995;&#32479;&#34429;&#28982;&#20855;&#26377;&#36136;&#37327;&#20445;&#30041;&#12289;&#40065;&#26834;&#24615;&#21644;&#20844;&#24320;&#26816;&#27979;API&#31561;&#20248;&#28857;&#65292;&#20294;&#20063;&#22240;&#27492;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#25915;&#20987;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#22871;&#23454;&#29992;&#25351;&#21335;&#20197;&#32531;&#35299;&#36825;&#20123;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#23637;&#20351;&#24471;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#25991;&#26412;&#12289;&#20195;&#30721;&#21644;&#22270;&#29255;&#33021;&#22815;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#27169;&#20223;&#20154;&#31867;&#29983;&#25104;&#30340;&#20869;&#23481;&#12290;&#27700;&#21360;&#25216;&#26415;&#26088;&#22312;&#23558;&#20449;&#24687;&#23884;&#20837;&#27169;&#22411;&#30340;&#36755;&#20986;&#20013;&#20197;&#39564;&#35777;&#20854;&#26469;&#28304;&#65292;&#23545;&#20110;&#20943;&#23569;&#23545;&#36825;&#20123;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#30340;&#28389;&#29992;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#27700;&#21360;&#26041;&#26696;&#20173;&#28982;&#20196;&#20154;&#24847;&#22806;&#22320;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;LLM&#27700;&#21360;&#31995;&#32479;&#20849;&#20139;&#30340;&#21487;&#21462;&#29305;&#24615;&#65292;&#20363;&#22914;&#36136;&#37327;&#20445;&#30041;&#12289;&#40065;&#26834;&#24615;&#21644;&#20844;&#24320;&#26816;&#27979;API&#65292;&#21453;&#36807;&#26469;&#21364;&#20351;&#36825;&#20123;&#31995;&#32479;&#23481;&#26131;&#36973;&#21463;&#21508;&#31181;&#25915;&#20987;&#12290;&#25105;&#20204;&#22312;&#24120;&#35265;&#27700;&#21360;&#35774;&#35745;&#36873;&#25321;&#26041;&#38754;&#20005;&#26684;&#30740;&#31350;&#28508;&#22312;&#25915;&#20987;&#65292;&#24182;&#25552;&#20986;&#20102;&#32531;&#35299;&#25915;&#20987;&#30340;&#26368;&#20339;&#23454;&#36341;&#21644;&#38450;&#24481;&#25514;&#26045;&#8212;&#8212;&#24314;&#31435;&#20102;&#19968;&#22871;&#23884;&#20837;&#21644;&#26816;&#27979;LLM&#27700;&#21360;&#30340;&#23454;&#29992;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16187v1 Announce Type: cross  Abstract: Advances in generative models have made it possible for AI-generated text, code, and images to mirror human-generated content in many applications. Watermarking, a technique that aims to embed information in the output of a model to verify its source, is useful for mitigating misuse of such AI-generated content. However, existing watermarking schemes remain surprisingly susceptible to attack. In particular, we show that desirable properties shared by existing LLM watermarking systems such as quality preservation, robustness, and public detection APIs can in turn make these systems vulnerable to various attacks. We rigorously study potential attacks in terms of common watermark design choices, and propose best practices and defenses for mitigation -- establishing a set of practical guidelines for embedding and detection of LLM watermarks.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#65288;UoT&#65289;&#31639;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#27169;&#25311;&#26410;&#26469;&#22330;&#26223;&#12289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#21644;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20248;&#21270;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2402.03271</link><description>&lt;p&gt;
&#24819;&#27861;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24687;&#25628;&#32034;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03271
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#65288;UoT&#65289;&#31639;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#27169;&#25311;&#26410;&#26469;&#22330;&#26223;&#12289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#21644;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20248;&#21270;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#27604;&#22914;&#21307;&#23398;&#35786;&#26029;&#21644;&#25925;&#38556;&#25490;&#38500;&#65292;&#35299;&#20915;&#20219;&#21153;&#25152;&#38656;&#30340;&#20449;&#24687;&#19981;&#26159;&#21021;&#22987;&#32473;&#23450;&#30340;&#65292;&#32780;&#38656;&#35201;&#36890;&#36807;&#35810;&#38382;&#21518;&#32493;&#38382;&#39064;&#26469;&#20027;&#21160;&#23547;&#27714;&#65288;&#20363;&#22914;&#65292;&#21307;&#29983;&#21521;&#24739;&#32773;&#35810;&#38382;&#30151;&#29366;&#30340;&#26356;&#22810;&#32454;&#33410;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24605;&#24819;&#30340;&#19981;&#30830;&#23450;&#24615;&#65288;UoT&#65289;&#65292;&#19968;&#31181;&#31639;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#19982;&#20027;&#21160;&#25552;&#38382;&#20449;&#24687;&#30340;&#33021;&#21147;&#30456;&#32467;&#21512;&#12290;UoT&#32467;&#21512;&#20102;1&#65289;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#20223;&#30495;&#26041;&#27861;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#27169;&#25311;&#21487;&#33021;&#30340;&#26410;&#26469;&#22330;&#26223;&#65292;&#24182;&#20272;&#35745;&#20854;&#21457;&#29983;&#30340;&#21487;&#33021;&#24615;&#65307;2&#65289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#65292;&#28608;&#21169;&#27169;&#22411;&#23547;&#27714;&#20449;&#24687;&#65307;3&#65289;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20197;&#26368;&#22823;&#21270;&#39044;&#26399;&#22870;&#21169;&#30340;&#26041;&#24335;&#36873;&#25321;&#26368;&#20339;&#30340;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;&#22312;&#21307;&#23398;&#35786;&#26029;&#12289;&#25925;&#38556;&#25490;&#38500;&#21644;'20&#30340;&#23454;&#39564;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the face of uncertainty, the ability to seek information is of fundamental importance. In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms). In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions. UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertainty-based rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. In experiments on medical diagnosis, troubleshooting and the '20 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#21487;&#25509;&#21463;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.02549</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#36866;&#21512;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are Large Language Models Table-based Fact-Checkers?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#21487;&#25509;&#21463;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#39564;&#35777;&#65288;TFV&#65289;&#26088;&#22312;&#25552;&#21462;&#35821;&#21477;&#21644;&#32467;&#26500;&#21270;&#34920;&#26684;&#20043;&#38388;&#30340;&#34164;&#28085;&#20851;&#31995;&#12290;&#29616;&#26377;&#22522;&#20110;&#23567;&#35268;&#27169;&#27169;&#22411;&#30340;TFV&#26041;&#27861;&#22312;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#21644;&#38646;&#26679;&#26412;&#33021;&#21147;&#34180;&#24369;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#30740;&#31350;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#23427;&#20204;&#22312;&#20960;&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#38646;&#26679;&#26412;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;TFV&#39046;&#22495;&#30340;&#28508;&#21147;&#36824;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20851;&#20110;LLMs&#26159;&#21542;&#36866;&#21512;&#20316;&#20026;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#22120;&#30340;&#21021;&#27493;&#30740;&#31350;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22810;&#26679;&#21270;&#30340;&#25552;&#31034;&#35821;&#26469;&#25506;&#32034;&#19978;&#19979;&#25991;&#23398;&#20064;&#22914;&#20309;&#24110;&#21161;LLMs&#22312;TFV&#26041;&#38754;&#65292;&#21363;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;TFV&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#31934;&#24515;&#35774;&#35745;&#21644;&#26500;&#24314;&#20102;TFV&#25351;&#23548;&#20197;&#30740;&#31350;LLMs&#30340;&#25351;&#23548;&#35843;&#25972;&#24102;&#26469;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;LLMs&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;TFV&#26041;&#38754;&#21487;&#20197;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#32467;&#26524;&#65292;&#32780;&#25351;&#23548;&#35843;&#25972;&#21017;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Table-based Fact Verification (TFV) aims to extract the entailment relation between statements and structured tables. Existing TFV methods based on small-scaled models suffer from insufficient labeled data and weak zero-shot ability. Recently, the appearance of Large Language Models (LLMs) has gained lots of attraction in research fields. They have shown powerful zero-shot and in-context learning abilities on several NLP tasks, but their potential on TFV is still unknown. In this work, we implement a preliminary study about whether LLMs are table-based fact-checkers. In detail, we design diverse prompts to explore how the in-context learning can help LLMs in TFV, i.e., zero-shot and few-shot TFV capability. Besides, we carefully design and construct TFV instructions to study the performance gain brought by the instruction tuning of LLMs. Experimental results demonstrate that LLMs can achieve acceptable results on zero-shot and few-shot TFV with prompt engineering, while instruction-tun
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#35782;&#21035;&#26377;&#27602;&#12289;&#20882;&#29359;&#21644;&#20196;&#20154;&#35752;&#21388;&#30340;&#20869;&#23481;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#24182;&#25506;&#35752;&#20102;&#36825;&#20123;&#25913;&#36827;&#26159;&#21542;&#30495;&#27491;&#28385;&#36275;&#20102;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#22312;&#24037;&#20316;&#20013;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2311.07879</link><description>&lt;p&gt;
&#27602;&#24615;&#26816;&#27979;&#24182;&#19981;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#20840;&#37096;&#65306;&#24357;&#21512;&#25903;&#25345;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#35782;&#21035;&#26377;&#27602;&#12289;&#20882;&#29359;&#21644;&#20196;&#20154;&#35752;&#21388;&#30340;&#20869;&#23481;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#24182;&#25506;&#35752;&#20102;&#36825;&#20123;&#25913;&#36827;&#26159;&#21542;&#30495;&#27491;&#28385;&#36275;&#20102;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#22312;&#24037;&#20316;&#20013;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#35782;&#21035;&#26377;&#27602;&#12289;&#20882;&#29359;&#21644;&#20196;&#20154;&#35752;&#21388;&#30340;&#20869;&#23481;&#26041;&#38754;&#21462;&#24471;&#20102;&#38271;&#36275;&#30340;&#36827;&#23637;&#65292;&#26088;&#22312;&#20943;&#36731;&#31649;&#29702;&#21592;&#30340;&#24037;&#20316;&#36127;&#25285;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#36825;&#20123;&#20219;&#21153;&#30340;&#25913;&#36827;&#26159;&#21542;&#30495;&#27491;&#28385;&#36275;&#20102;&#31649;&#29702;&#21592;&#22312;&#24037;&#20316;&#20013;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#36807;&#21435;&#30740;&#31350;&#21162;&#21147;&#33268;&#21147;&#20110;&#20026;&#20869;&#23481;&#31649;&#29702;&#30340;&#21508;&#20010;&#26041;&#38754;&#25552;&#20379;&#33258;&#21160;&#21270;&#25903;&#25345;&#19982;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#30340;&#38656;&#27714;&#20043;&#38388;&#23384;&#22312;&#30340;&#24046;&#36317;&#65292;&#23588;&#20854;&#26159;&#22312;&#35782;&#21035;&#36829;&#21453;&#21508;&#31181;&#31649;&#29702;&#35268;&#21017;&#26041;&#38754;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;Hugging Face&#19978;&#23545;&#27169;&#22411;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20197;&#25581;&#31034;&#28085;&#30422;&#19977;&#20010;&#31034;&#33539;&#35770;&#22363;&#30340;&#21508;&#31181;&#31649;&#29702;&#35268;&#21017;&#21644;&#25351;&#21335;&#30340;&#27169;&#22411;&#30340;&#21487;&#29992;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23545;&#26368;&#20808;&#36827;&#30340;LLM&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#22312;&#26631;&#35760;&#26576;&#20010;&#29305;&#23450;&#35770;&#22363;&#30340;&#24179;&#21488;&#35268;&#21017;&#36829;&#35268;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#29992;&#25143;&#35843;&#26597;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07879v2 Announce Type: replace-cross  Abstract: Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks have truly addressed moderators' needs in accomplishing their work. In this paper, we surface gaps between past research efforts that have aimed to provide automation for aspects of content moderation and the needs of volunteer content moderators, regarding identifying violations of various moderation rules. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines from three exemplar forums. We further put state-of-the-art LLMs to the test, evaluating how well these models perform in flagging violations of platform rules from one particular forum. Finally, we conduct a user survey stud
&lt;/p&gt;</description></item></channel></rss>