<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;Multi-Grain Stereotype&#65288;MGS&#65289;&#25968;&#25454;&#38598;&#65292;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#24314;&#31435;&#38472;&#35268;&#26816;&#27979;&#30340;&#22522;&#32447;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;MGS&#25968;&#25454;&#35757;&#32451;&#30340;&#33521;&#25991;&#25991;&#26412;&#30340;&#38472;&#35268;&#20998;&#31867;&#22120;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2404.01768</link><description>&lt;p&gt;
&#29992;&#20110;&#22686;&#24378;&#22522;&#20110;&#25991;&#26412;&#30340;&#38472;&#35268;&#26816;&#27979;&#21644;&#22522;&#20110;&#25506;&#27979;&#30340;&#20559;&#35265;&#35780;&#20272;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01768
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;Multi-Grain Stereotype&#65288;MGS&#65289;&#25968;&#25454;&#38598;&#65292;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#24314;&#31435;&#38472;&#35268;&#26816;&#27979;&#30340;&#22522;&#32447;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;MGS&#25968;&#25454;&#35757;&#32451;&#30340;&#33521;&#25991;&#25991;&#26412;&#30340;&#38472;&#35268;&#20998;&#31867;&#22120;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#26174;&#33879;&#25552;&#39640;&#20102;&#23427;&#20204;&#22312;&#38754;&#21521;&#20154;&#31867;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#24212;&#29992;&#20013;&#30340;&#24433;&#21709;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#21487;&#33021;&#20250;&#22797;&#21046;&#29978;&#33267;&#21152;&#21095;&#33258;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#38472;&#35268;&#36755;&#20986;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;Multi-Grain Stereotype&#65288;MGS&#65289;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;51,867&#20010;&#23454;&#20363;&#65292;&#28085;&#30422;&#24615;&#21035;&#12289;&#31181;&#26063;&#12289;&#32844;&#19994;&#12289;&#23447;&#25945;&#21644;&#38472;&#35268;&#25991;&#26412;&#65292;&#36890;&#36807;&#34701;&#21512;&#22810;&#20010;&#20808;&#21069;&#20844;&#24320;&#30340;&#38472;&#35268;&#26816;&#27979;&#25968;&#25454;&#38598;&#25910;&#38598;&#32780;&#26469;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#26088;&#22312;&#20026;&#38472;&#35268;&#26816;&#27979;&#24314;&#31435;&#22522;&#32447;&#30340;&#19981;&#21516;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24494;&#35843;&#20102;&#22810;&#31181;&#26550;&#26500;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#20960;&#20010;&#35821;&#35328;&#27169;&#22411;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;MGS&#35757;&#32451;&#30340;&#33521;&#25991;&#25991;&#26412;&#30340;&#38472;&#35268;&#20998;&#31867;&#22120;&#27169;&#22411;&#12290;&#20026;&#20102;&#20102;&#35299;&#25105;&#20204;&#30340;&#38472;&#35268;&#26816;&#27979;&#22120;&#26159;&#21542;&#25429;&#25417;&#21040;&#19982;&#20154;&#31867;&#24120;&#35782;&#19968;&#33268;&#30340;&#30456;&#20851;&#29305;&#24449;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#21508;&#31181;&#21487;&#35299;&#37322;&#30340;AI&#24037;&#20855;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01768v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs) have significantly increased their presence in human-facing Artificial Intelligence (AI) applications. However, LLMs could reproduce and even exacerbate stereotypical outputs from training data. This work introduces the Multi-Grain Stereotype (MGS) dataset, encompassing 51,867 instances across gender, race, profession, religion, and stereotypical text, collected by fusing multiple previously publicly available stereotype detection datasets. We explore different machine learning approaches aimed at establishing baselines for stereotype detection, and fine-tune several language models of various architectures and model sizes, presenting in this work a series of stereotypes classifier models for English text trained on MGS. To understand whether our stereotype detectors capture relevant features (aligning with human common sense) we utilise a variety of explanainable AI tools, including 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#37197;&#32622;&#65292;&#31216;&#20026;prompt-in-decoder&#65288;PiD&#65289;&#65292;&#21487;&#20197;&#19968;&#27425;&#32534;&#30721;&#36755;&#20837;&#24182;&#24182;&#34892;&#35299;&#30721;&#36755;&#20986;&#65292;&#22312;&#32467;&#26500;&#21270;&#36755;&#20986;&#21644;&#38382;&#31572;&#20219;&#21153;&#20013;&#21462;&#24471;&#39640;&#25928;&#29575;&#65292;&#36991;&#20813;&#20102;&#37325;&#22797;&#36755;&#20837;&#32534;&#30721;&#65292;&#22823;&#24133;&#20943;&#23569;&#20102;&#35299;&#30721;&#22120;&#30340;&#20869;&#23384;&#21344;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.13112</link><description>&lt;p&gt;
&#19968;&#27425;&#32534;&#30721;&#65292;&#22810;&#27425;&#24182;&#34892;&#35299;&#30721;&#65306;&#39640;&#25928;Transformer&#35299;&#30721;
&lt;/p&gt;
&lt;p&gt;
Encode Once and Decode in Parallel: Efficient Transformer Decoding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13112
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#37197;&#32622;&#65292;&#31216;&#20026;prompt-in-decoder&#65288;PiD&#65289;&#65292;&#21487;&#20197;&#19968;&#27425;&#32534;&#30721;&#36755;&#20837;&#24182;&#24182;&#34892;&#35299;&#30721;&#36755;&#20986;&#65292;&#22312;&#32467;&#26500;&#21270;&#36755;&#20986;&#21644;&#38382;&#31572;&#20219;&#21153;&#20013;&#21462;&#24471;&#39640;&#25928;&#29575;&#65292;&#36991;&#20813;&#20102;&#37325;&#22797;&#36755;&#20837;&#32534;&#30721;&#65292;&#22823;&#24133;&#20943;&#23569;&#20102;&#35299;&#30721;&#22120;&#30340;&#20869;&#23384;&#21344;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#21151;&#33021;&#24378;&#22823;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#38480;&#21046;&#20102;&#37096;&#32626;&#22330;&#26223;&#12290;&#22312;&#19987;&#19994;&#39046;&#22495;&#20013;&#65292;&#24494;&#35843;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#22791;&#21463;&#38738;&#30544;&#65292;&#21487;&#20197;&#32988;&#36807;&#26356;&#22823;&#26356;&#36890;&#29992;&#30340;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#20363;&#22914;GPT-4&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#37197;&#32622;&#65292;&#21487;&#20197;&#25552;&#39640;&#22312;&#32467;&#26500;&#21270;&#36755;&#20986;&#21644;&#38382;&#31572;&#20219;&#21153;&#20013;&#30340;&#25928;&#29575;&#65292;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#65292;&#38656;&#35201;&#20174;&#21333;&#20010;&#36755;&#20837;&#20013;&#20135;&#29983;&#22810;&#20010;&#36755;&#20986;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;prompt-in-decoder&#65288;PiD&#65289;&#65292;&#21482;&#23545;&#36755;&#20837;&#36827;&#34892;&#19968;&#27425;&#32534;&#30721;&#65292;&#24182;&#19988;&#24182;&#34892;&#35299;&#30721;&#36755;&#20986;&#65292;&#36890;&#36807;&#36991;&#20813;&#37325;&#22797;&#36755;&#20837;&#32534;&#30721;&#65292;&#20174;&#32780;&#20943;&#23569;&#35299;&#30721;&#22120;&#30340;&#20869;&#23384;&#21344;&#29992;&#65292;&#25552;&#21319;&#20102;&#35757;&#32451;&#21644;&#25512;&#26029;&#25928;&#29575;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#35745;&#31639;&#20943;&#23569;&#65292;&#22823;&#33268;&#38543;&#23376;&#20219;&#21153;&#25968;&#37327;&#22686;&#21152;&#32780;&#25193;&#23637;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#27169;&#22411;&#65292;&#22312;&#23545;&#35805;&#29366;&#24577;&#36861;&#36394;&#12289;&#25688;&#35201;&#21644;&#38382;&#31572;&#20219;&#21153;&#20013;&#33719;&#24471;&#39640;&#36798;4.6&#20493;&#30340;&#36895;&#24230;&#25552;&#21319;&#65292;&#24182;&#19988;&#24615;&#33021;&#30456;&#24403;&#25110;&#26356;&#22909;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#35757;&#32451;/&#25512;&#26029;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13112v1 Announce Type: new  Abstract: Transformer-based NLP models are powerful but have high computational costs that limit deployment scenarios. Finetuned encoder-decoder models are popular in specialized domains and can outperform larger more generalized decoder-only models, such as GPT-4. We introduce a new configuration for encoder-decoder models that improves efficiency on structured output and question-answering tasks where multiple outputs are required of a single input. Our method, prompt-in-decoder (PiD), encodes the input once and decodes output in parallel, boosting both training and inference efficiency by avoiding duplicate input encoding, thereby reducing the decoder's memory footprint. We achieve computation reduction that roughly scales with the number of subtasks, gaining up to 4.6x speed-up over state-of-the-art models for dialogue state tracking, summarization, and question-answering tasks with comparable or better performance. We release our training/inf
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#21160;&#24577;&#24494;&#35843;&#21442;&#25968;&#36873;&#25321;&#31574;&#30053;&#65292;&#38024;&#23545;FISH Mask&#25552;&#20986;&#20102;IRD&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#19981;&#31283;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#19979;&#21160;&#24577;&#36873;&#25321;&#26368;&#20339;&#21442;&#25968;&#35774;&#32622;&#12290;</title><link>https://arxiv.org/abs/2403.08484</link><description>&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#21160;&#24577;&#24494;&#35843;&#21442;&#25968;&#36873;&#25321;&#31574;&#30053;&#65292;&#29992;&#20110;&#22522;&#20110;FISH Mask&#30340;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH Mask based Efficient Fine-tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08484
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#21160;&#24577;&#24494;&#35843;&#21442;&#25968;&#36873;&#25321;&#31574;&#30053;&#65292;&#38024;&#23545;FISH Mask&#25552;&#20986;&#20102;IRD&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#19981;&#31283;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#19979;&#21160;&#24577;&#36873;&#25321;&#26368;&#20339;&#21442;&#25968;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#21442;&#25968;&#25968;&#37327;&#24040;&#22823;&#65292;&#35843;&#25972;&#25152;&#26377;&#21442;&#25968;&#25104;&#26412;&#24456;&#39640;&#65292;&#22240;&#27492;&#26356;&#26126;&#26234;&#30340;&#20570;&#27861;&#26159;&#23545;&#29305;&#23450;&#21442;&#25968;&#36827;&#34892;&#24494;&#35843;&#12290;&#22823;&#22810;&#25968;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;(PEFT)&#38598;&#20013;&#22312;&#21442;&#25968;&#36873;&#25321;&#31574;&#30053;&#19978;&#65292;&#20363;&#22914;&#21152;&#27861;&#26041;&#27861;&#12289;&#36873;&#25321;&#24615;&#26041;&#27861;&#21644;&#22522;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#26041;&#27861;&#32771;&#34385;&#25968;&#25454;&#26679;&#26412;&#23545;&#21442;&#25968;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#20363;&#22914;&#22522;&#20110;Fish Mask&#30340;&#26041;&#27861;&#12290;Fish Mask&#38543;&#26426;&#36873;&#25321;&#37096;&#20998;&#25968;&#25454;&#26679;&#26412;&#65292;&#24182;&#22312;&#21442;&#25968;&#36873;&#25321;&#36807;&#31243;&#20013;&#23545;&#23427;&#20204;&#36827;&#34892;&#21516;&#31561;&#22788;&#29702;&#65292;&#36825;&#26080;&#27861;&#20026;&#19981;&#31283;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#21160;&#24577;&#36873;&#25321;&#26368;&#20339;&#21442;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#25968;&#25454;&#39537;&#21160;&#30340;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;IRD(&#36845;&#20195;&#26679;&#26412;&#21442;&#25968;&#33539;&#22260;&#20943;&#23567;)&#31639;&#27861;&#65292;&#20197;&#25628;&#32034;FISH Mask&#30340;&#26368;&#20339;&#26679;&#26412;&#21442;&#25968;&#23545;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08484v1 Announce Type: new  Abstract: In view of the huge number of parameters of Large language models (LLMs) , tuning all parameters is very costly, and accordingly fine-tuning specific parameters is more sensible. Most of parameter efficient fine-tuning (PEFT) concentrate on parameter selection strategies, such as additive method, selective method and reparametrization-based method. However, there are few methods that consider the impact of data samples on parameter selecting, such as Fish Mask based method. Fish Mask randomly choose a part of data samples and treat them equally during parameter selection, which is unable to dynamically select optimal parameters for inconstant data distributions. In this work, we adopt a data-oriented perspective, then proposing an IRD ($\mathrm{\underline I}$terative sample-parameter $\mathrm{\underline R}$ange $\mathrm{\underline D}$ecreasing) algorithm to search the best setting of sample-parameter pair for FISH Mask. In each iteration
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32858;&#31867;&#19982;&#25490;&#24207;&#26041;&#27861;&#65288;CaR&#65289;&#65292;&#36890;&#36807;&#19982;&#19987;&#23478;&#20559;&#22909;&#30456;&#19968;&#33268;&#30340;&#35780;&#20998;&#27169;&#22411;&#25490;&#21517;&#25351;&#20196;&#23545;&#65292;&#20445;&#30041;&#20102;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.18191</link><description>&lt;p&gt;
&#32858;&#31867;&#19982;&#25490;&#24207;&#65306;&#36890;&#36807;&#19987;&#23478;&#23450;&#20301;&#36136;&#37327;&#20272;&#35745;&#23454;&#29616;&#20445;&#30041;&#22810;&#26679;&#24615;&#30340;&#25351;&#20196;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32858;&#31867;&#19982;&#25490;&#24207;&#26041;&#27861;&#65288;CaR&#65289;&#65292;&#36890;&#36807;&#19982;&#19987;&#23478;&#20559;&#22909;&#30456;&#19968;&#33268;&#30340;&#35780;&#20998;&#27169;&#22411;&#25490;&#21517;&#25351;&#20196;&#23545;&#65292;&#20445;&#30041;&#20102;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#24320;&#28304;&#31038;&#21306;&#30340;&#36129;&#29486;&#65292;&#28044;&#29616;&#20102;&#22823;&#37327;&#25351;&#20196;&#35843;&#20248;&#65288;IT&#65289;&#25968;&#25454;&#12290;&#37492;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#36164;&#28304;&#20998;&#37197;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#37319;&#29992;&#39640;&#25928;&#30340;&#26041;&#27861;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;IT&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25351;&#20196;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#65292;&#27604;&#22914;&#20381;&#36182;&#33030;&#24369;&#30340;&#22806;&#37096;API&#12289;&#21463;GPT&#27169;&#22411;&#20559;&#35265;&#24433;&#21709;&#65292;&#25110;&#20943;&#23569;&#25152;&#36873;&#25351;&#20196;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#24037;&#19994;&#30340;&#12289;&#19982;&#19987;&#23478;&#23450;&#20301;&#30456;&#21563;&#21512;&#24182;&#20445;&#30041;&#22810;&#26679;&#24615;&#30340;&#25351;&#20196;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#65306;&#32858;&#31867;&#19982;&#25490;&#24207;&#65288;CaR&#65289;&#12290;CaR&#20998;&#20026;&#20004;&#20010;&#27493;&#39588;&#12290;&#31532;&#19968;&#27493;&#28041;&#21450;&#20351;&#29992;&#19982;&#19987;&#23478;&#20559;&#22909;&#24456;&#22909;&#23545;&#40784;&#30340;&#35780;&#20998;&#27169;&#22411;&#23545;&#25351;&#20196;&#23545;&#36827;&#34892;&#25490;&#21517;&#65288;&#20934;&#30830;&#29575;&#36798;&#21040;84.25%&#65289;&#12290;&#31532;&#20108;&#27493;&#36890;&#36807;&#32858;&#31867;&#36807;&#31243;&#20445;&#30041;&#25968;&#25454;&#38598;&#22810;&#26679;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;CaR&#36873;&#25321;&#20102;&#19968;&#20010;&#23376;&#38598;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18191v1 Announce Type: new  Abstract: With contributions from the open-source community, a vast amount of instruction tuning (IT) data has emerged. Given the significant resource allocation required by training and evaluating models, it is advantageous to have an efficient method for selecting high-quality IT data. However, existing methods for instruction data selection have limitations such as relying on fragile external APIs, being affected by biases in GPT models, or reducing the diversity of the selected instruction dataset. In this paper, we propose an industrial-friendly, expert-aligned and diversity-preserved instruction data selection method: Clustering and Ranking (CaR). CaR consists of two steps. The first step involves ranking instruction pairs using a scoring model that is well aligned with expert preferences (achieving an accuracy of 84.25%). The second step involves preserving dataset diversity through a clustering process.In our experiment, CaR selected a sub
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#25351;&#20196;&#20013;&#24515;&#21709;&#24212;&#30340;&#23481;&#24525;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#22797;&#26434;&#26597;&#35810;&#30340;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#25581;&#31034;&#35302;&#21457;&#19981;&#36947;&#24503;&#21709;&#24212;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.15302</link><description>&lt;p&gt;
&#26377;&#20851;LLMs&#25351;&#20196;&#20013;&#24515;&#21709;&#24212;&#30340;&#65288;&#19981;&#36947;&#24503;&#65289;&#31243;&#24230;&#26377;&#22810;&#39640;&#65311;&#25581;&#31034;&#23433;&#20840;&#38450;&#25252;&#26639;&#23545;&#26377;&#23475;&#26597;&#35810;&#30340;&#28431;&#27934;
&lt;/p&gt;
&lt;p&gt;
How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#25351;&#20196;&#20013;&#24515;&#21709;&#24212;&#30340;&#23481;&#24525;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#22797;&#26434;&#26597;&#35810;&#30340;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#25581;&#31034;&#35302;&#21457;&#19981;&#36947;&#24503;&#21709;&#24212;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19968;&#20010;&#22260;&#32469;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23433;&#20840;&#21644;&#36947;&#24503;&#20351;&#29992;&#26085;&#30410;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#20855;&#26377;&#28508;&#21147;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#20250;&#34987;&#21508;&#31181;&#22797;&#26434;&#30340;&#26041;&#27861;&#27450;&#39575;&#65292;&#20135;&#29983;&#26377;&#23475;&#25110;&#19981;&#36947;&#24503;&#20869;&#23481;&#65292;&#21253;&#25324;&#8220;&#36234;&#29425;&#8221;&#25216;&#26415;&#21644;&#26377;&#38024;&#23545;&#24615;&#30340;&#25805;&#32437;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#38598;&#20013;&#22312;&#19968;&#20010;&#29305;&#23450;&#38382;&#39064;&#19978;&#65306;LLMs&#22312;&#35201;&#27714;&#23427;&#20204;&#29983;&#25104;&#20197;&#20266;&#20195;&#30721;&#12289;&#31243;&#24207;&#25110;&#36719;&#20214;&#29255;&#27573;&#20026;&#20013;&#24515;&#30340;&#21709;&#24212;&#26102;&#65292;&#26377;&#22810;&#22823;&#31243;&#24230;&#19978;&#21487;&#33021;&#20250;&#34987;&#35823;&#23548;&#65292;&#32780;&#19981;&#26159;&#29983;&#25104;&#26222;&#36890;&#25991;&#26412;&#12290;&#20026;&#20102;&#35843;&#26597;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;TechHazardQA&#65292;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#24212;&#20197;&#25991;&#26412;&#21644;&#20197;&#25351;&#20196;&#20026;&#20013;&#24515;&#26684;&#24335;&#65288;&#20363;&#22914;&#20266;&#20195;&#30721;&#65289;&#22238;&#31572;&#30340;&#22797;&#26434;&#26597;&#35810;&#65292;&#26088;&#22312;&#35782;&#21035;&#19981;&#36947;&#24503;&#21709;&#24212;&#30340;&#35302;&#21457;&#22120;&#12290;&#25105;&#20204;&#26597;&#35810;&#20102;&#19968;&#31995;&#21015;LLMs-- Llama-2-13b&#65292;Llama-2-7b&#65292;Mistral-V2&#21644;Mistral 8X7B--&#24182;&#35201;&#27714;&#23427;&#20204;&#29983;&#25104;&#25991;&#26412;&#21644;&#25351;&#20196;&#20026;&#20013;&#24515;&#30340;&#21709;&#24212;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15302v1 Announce Type: new  Abstract: In this study, we tackle a growing concern around the safety and ethical use of large language models (LLMs). Despite their potential, these models can be tricked into producing harmful or unethical content through various sophisticated methods, including 'jailbreaking' techniques and targeted manipulation. Our work zeroes in on a specific issue: to what extent LLMs can be led astray by asking them to generate responses that are instruction-centric such as a pseudocode, a program or a software snippet as opposed to vanilla text. To investigate this question, we introduce TechHazardQA, a dataset containing complex queries which should be answered in both text and instruction-centric formats (e.g., pseudocodes), aimed at identifying triggers for unethical responses. We query a series of LLMs -- Llama-2-13b, Llama-2-7b, Mistral-V2 and Mistral 8X7B -- and ask them to generate both text and instruction-centric responses. For evaluation we rep
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#21333;&#35789;&#24207;&#21015;&#29109;&#65288;WSE&#65289;&#65292;&#29992;&#20110;&#22312;&#33258;&#30001;&#24418;&#24335;&#21307;&#23398;&#38382;&#31572;&#20219;&#21153;&#20013;&#37327;&#21270;&#31572;&#26696;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#30456;&#27604;&#20854;&#20182;&#22522;&#32447;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#31168;&#12290;</title><link>https://arxiv.org/abs/2402.14259</link><description>&lt;p&gt;
&#21333;&#35789;&#24207;&#21015;&#29109;&#65306;&#36208;&#21521;&#33258;&#30001;&#24418;&#24335;&#21307;&#23398;&#38382;&#31572;&#24212;&#29992;&#21450;&#20854;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#21333;&#35789;&#24207;&#21015;&#29109;&#65288;WSE&#65289;&#65292;&#29992;&#20110;&#22312;&#33258;&#30001;&#24418;&#24335;&#21307;&#23398;&#38382;&#31572;&#20219;&#21153;&#20013;&#37327;&#21270;&#31572;&#26696;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#30456;&#27604;&#20854;&#20182;&#22522;&#32447;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22312;&#30830;&#20445;&#23433;&#20840;&#20851;&#38190;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#19982;&#20154;&#31867;&#20114;&#21160;&#30340;&#21487;&#38752;&#24615;&#20013;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#65292;&#23588;&#20854;&#22312;&#21307;&#30103;&#39046;&#22495;&#23588;&#20026;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#33258;&#30001;&#24418;&#24335;&#30340;&#21307;&#23398;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#23578;&#26410;&#24314;&#31435;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#26469;&#37327;&#21270;&#31572;&#26696;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20854;&#20013;&#26080;&#20851;&#30340;&#35789;&#27719;&#21644;&#35821;&#24207;&#21547;&#26377;&#26377;&#38480;&#30340;&#35821;&#20041;&#20449;&#24687;&#21487;&#33021;&#26159;&#19981;&#30830;&#23450;&#24615;&#30340;&#20027;&#35201;&#26469;&#28304;&#65292;&#36825;&#26159;&#30001;&#20110;&#29983;&#25104;&#19981;&#24179;&#31561;&#30340;&#23384;&#22312;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#21333;&#35789;&#24207;&#21015;&#29109;&#65288;WSE&#65289;&#65292;&#35813;&#26041;&#27861;&#26681;&#25454;&#35821;&#20041;&#30456;&#20851;&#24615;&#22312;&#21333;&#35789;&#21644;&#24207;&#21015;&#32423;&#21035;&#19978;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#27604;&#20363;&#65292;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26102;&#26356;&#21152;&#24378;&#35843;&#20851;&#38190;&#35789;&#21644;&#26356;&#30456;&#20851;&#30340;&#24207;&#21015;&#12290;&#25105;&#20204;&#22312;5&#20010;&#33258;&#30001;&#24418;&#24335;&#21307;&#23398;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#65292;&#21033;&#29992;7&#31181;&#8220;&#29616;&#25104;&#30340;&#8221;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23558;WSE&#19982;6&#31181;&#22522;&#32447;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#20102;WSE&#22312;&#24615;&#33021;&#19978;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14259v1 Announce Type: cross  Abstract: Uncertainty estimation plays a pivotal role in ensuring the reliability of safety-critical human-AI interaction systems, particularly in the medical domain. However, a general method for quantifying the uncertainty of free-form answers has yet to be established in open-ended medical question-answering (QA) tasks, where irrelevant words and sequences with limited semantic information can be the primary source of uncertainty due to the presence of generative inequality. In this paper, we propose the Word-Sequence Entropy (WSE), which calibrates the uncertainty proportion at both the word and sequence levels according to the semantic relevance, with greater emphasis placed on keywords and more relevant sequences when performing uncertainty quantification. We compare WSE with 6 baseline methods on 5 free-form medical QA datasets, utilizing 7 "off-the-shelf" large language models (LLMs), and show that WSE exhibits superior performance on ac
&lt;/p&gt;</description></item><item><title>MultiPoT &#25552;&#20986;&#20102;&#19968;&#31181;&#20219;&#21153;&#21644;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#31181;&#32534;&#31243;&#35821;&#35328;&#30340;&#20248;&#21183;&#21644;&#22810;&#26679;&#24615;&#65292;&#22312;&#34920;&#29616;&#19978;&#26174;&#33879;&#20248;&#20110; Python &#33258;&#19968;&#33268;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10691</link><description>&lt;p&gt;
MultiPoT: &#22810;&#35821;&#35328;&#24605;&#32500;&#31243;&#24207;&#21033;&#29992;&#22810;&#31181;&#32534;&#31243;&#35821;&#35328;
&lt;/p&gt;
&lt;p&gt;
MultiPoT: Multilingual Program of Thoughts Harnesses Multiple Programming Languages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10691
&lt;/p&gt;
&lt;p&gt;
MultiPoT &#25552;&#20986;&#20102;&#19968;&#31181;&#20219;&#21153;&#21644;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#31181;&#32534;&#31243;&#35821;&#35328;&#30340;&#20248;&#21183;&#21644;&#22810;&#26679;&#24615;&#65292;&#22312;&#34920;&#29616;&#19978;&#26174;&#33879;&#20248;&#20110; Python &#33258;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10691v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#30340; &#25688;&#35201;&#65306;&#24605;&#32500;&#31243;&#24207;&#65288;PoT&#65289;&#26159;&#19968;&#31181;&#20197;&#20854;&#21487;&#25191;&#34892;&#20013;&#38388;&#27493;&#39588;&#20026;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#20854;&#30830;&#20445;&#25512;&#29702;&#36807;&#31243;&#20013;&#25968;&#20540;&#35745;&#31639;&#30340;&#20934;&#30830;&#24615;&#12290;&#30446;&#21069;&#65292;PoT&#20027;&#35201;&#20351;&#29992;Python&#12290;&#28982;&#32780;&#65292;&#20165;&#20381;&#36182;&#21333;&#19968;&#35821;&#35328;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#65292;&#24573;&#35270;&#20854;&#20182;&#32534;&#31243;&#35821;&#35328;&#30340;&#28508;&#22312;&#20248;&#21183;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;PoT&#20013;&#20351;&#29992;&#30340;&#32534;&#31243;&#35821;&#35328;&#36827;&#34892;&#20102;&#20840;&#38754;&#23454;&#39564;&#65292;&#21457;&#29616;&#27809;&#26377;&#19968;&#31181;&#21333;&#19968;&#35821;&#35328;&#22312;&#25152;&#26377;&#20219;&#21153;&#21644;&#27169;&#22411;&#19978;&#22987;&#32456;&#25552;&#20379;&#26368;&#20339;&#24615;&#33021;&#12290;&#27599;&#31181;&#35821;&#35328;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20855;&#20307;&#24773;&#26223;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;MultiPoT&#30340;&#20219;&#21153;&#21644;&#27169;&#22411;&#26080;&#20851;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20174;&#21508;&#31181;&#35821;&#35328;&#20013;&#33719;&#21462;&#24378;&#22823;&#21644;&#22810;&#26679;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;MultiPoT &#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20248;&#20110;Python &#33258;&#19968;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#19982;&#26368;&#20339;&#27169;&#22411;&#30456;&#27604;&#65292;&#23427;&#23454;&#29616;&#20102;&#21487;&#27604;&#25110;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10691v1 Announce Type: new  Abstract: Program of Thoughts (PoT) is an approach characterized by its executable intermediate steps, which ensure the accuracy of the numerical calculations in the reasoning process. Currently, PoT primarily uses Python. However, relying solely on a single language may result in suboptimal solutions and overlook the potential benefits of other programming languages. In this paper, we conduct comprehensive experiments on the programming languages used in PoT and find that no single language consistently delivers optimal performance across all tasks and models. The effectiveness of each language varies depending on the specific scenarios. Inspired by this, we propose a task and model agnostic approach called MultiPoT, which harnesses strength and diversity from various languages. Experimental results reveal that it significantly outperforms Python Self-Consistency. Furthermore, it achieves comparable or superior performance compared to the best mo
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#24120;&#35782;&#30693;&#35782;&#22270;&#35889;&#19982;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25913;&#36827;&#39044;&#27979;&#22810;&#27169;&#24577;&#33829;&#38144;&#27963;&#21160;&#25928;&#26524;&#30340;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26089;&#26399;&#26816;&#27979;&#21487;&#33021;&#20855;&#26377;&#35828;&#26381;&#21147;&#30340;&#22810;&#27169;&#24577;&#27963;&#21160;&#24182;&#35780;&#20272;&#21644;&#22686;&#24378;&#33829;&#38144;&#29702;&#35770;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.03607</link><description>&lt;p&gt;
&#25552;&#39640;&#22810;&#27169;&#24577;&#33829;&#38144;&#30340;&#19978;&#19979;&#25991;&#19968;&#33268;&#24615;&#65306;&#30693;&#35782;&#22522;&#30784;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving Contextual Congruence Across Modalities for Effective Multimodal Marketing using Knowledge-infused Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03607
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#24120;&#35782;&#30693;&#35782;&#22270;&#35889;&#19982;&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25913;&#36827;&#39044;&#27979;&#22810;&#27169;&#24577;&#33829;&#38144;&#27963;&#21160;&#25928;&#26524;&#30340;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26089;&#26399;&#26816;&#27979;&#21487;&#33021;&#20855;&#26377;&#35828;&#26381;&#21147;&#30340;&#22810;&#27169;&#24577;&#27963;&#21160;&#24182;&#35780;&#20272;&#21644;&#22686;&#24378;&#33829;&#38144;&#29702;&#35770;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26234;&#33021;&#35774;&#22791;&#30340;&#26222;&#21450;&#20351;&#29992;&#25143;&#33021;&#22815;&#22312;&#32447;&#20307;&#39564;&#22810;&#27169;&#24577;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#35270;&#35273;&#27169;&#22411;&#65288;LVM&#65289;&#20173;&#28982;&#21463;&#21040;&#25429;&#25417;&#36328;&#27169;&#24577;&#35821;&#20041;&#20851;&#31995;&#30340;&#25972;&#20307;&#24847;&#20041;&#30340;&#38480;&#21046;&#12290;&#32570;&#20047;&#26126;&#30830;&#30340;&#24120;&#35782;&#30693;&#35782;&#65288;&#20363;&#22914;&#65292;&#20316;&#20026;&#19968;&#20010;&#30693;&#35782;&#22270;&#35889;&#65289;&#65292;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLM&#65289;&#20165;&#36890;&#36807;&#25429;&#25417;&#24222;&#22823;&#30340;&#35821;&#26009;&#24211;&#20013;&#30340;&#39640;&#32423;&#27169;&#24335;&#26469;&#23398;&#20064;&#38544;&#24335;&#34920;&#31034;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#37325;&#35201;&#30340;&#19978;&#19979;&#25991;&#36328;&#27169;&#24577;&#32447;&#32034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#26174;&#24335;&#30340;&#24120;&#35782;&#30693;&#35782;&#20197;&#30693;&#35782;&#22270;&#35889;&#30340;&#24418;&#24335;&#19982;&#22823;&#22411;&#30340;VLM&#30456;&#32467;&#21512;&#65292;&#20197;&#25552;&#39640;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#21363;&#39044;&#27979;&#22810;&#27169;&#24577;&#33829;&#38144;&#27963;&#21160;&#30340;&#26377;&#25928;&#24615;&#12290;&#34429;&#28982;&#33829;&#38144;&#24212;&#29992;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#35828;&#26381;&#21147;&#30340;&#25351;&#26631;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20294;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#26089;&#26399;&#21457;&#29616;&#21487;&#33021;&#20855;&#26377;&#35828;&#26381;&#21147;&#30340;&#22810;&#27169;&#24577;&#27963;&#21160;&#25104;&#20026;&#21487;&#33021;&#65292;&#24182;&#35780;&#20272;&#21644;&#22686;&#24378;&#33829;&#38144;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The prevalence of smart devices with the ability to capture moments in multiple modalities has enabled users to experience multimodal information online. However, large Language (LLMs) and Vision models (LVMs) are still limited in capturing holistic meaning with cross-modal semantic relationships. Without explicit, common sense knowledge (e.g., as a knowledge graph), Visual Language Models (VLMs) only learn implicit representations by capturing high-level patterns in vast corpora, missing essential contextual cross-modal cues. In this work, we design a framework to couple explicit commonsense knowledge in the form of knowledge graphs with large VLMs to improve the performance of a downstream task, predicting the effectiveness of multi-modal marketing campaigns. While the marketing application provides a compelling metric for assessing our methods, our approach enables the early detection of likely persuasive multi-modal campaigns and the assessment and augmentation of marketing theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38646;&#23556;&#20987;&#25552;&#31034;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#38169;&#35823;&#20449;&#24687;&#26469;&#25351;&#23548;&#27169;&#22411;&#36827;&#34892;&#20219;&#21153;&#65292;&#20197;&#25552;&#39640;&#20219;&#21153;&#34920;&#29616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#65292;&#21253;&#25324;&#38405;&#35835;&#29702;&#35299;&#12289;&#31639;&#26415;&#25512;&#29702;&#21644;&#38381;&#21367;&#38382;&#31572;&#65292;&#27169;&#22411;&#24615;&#33021;&#26377;&#25152;&#25552;&#21319;&#12290;&#36825;&#20123;&#32467;&#26524;&#20063;&#26174;&#31034;&#20986;&#19981;&#21516;&#27169;&#22411;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#31243;&#24230;&#30340;&#38169;&#35823;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2401.08273</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#26159;&#38646;&#23556;&#20987;&#23398;&#20064;&#22120;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Null-Shot Learners
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.08273
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38646;&#23556;&#20987;&#25552;&#31034;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#38169;&#35823;&#20449;&#24687;&#26469;&#25351;&#23548;&#27169;&#22411;&#36827;&#34892;&#20219;&#21153;&#65292;&#20197;&#25552;&#39640;&#20219;&#21153;&#34920;&#29616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#65292;&#21253;&#25324;&#38405;&#35835;&#29702;&#35299;&#12289;&#31639;&#26415;&#25512;&#29702;&#21644;&#38381;&#21367;&#38382;&#31572;&#65292;&#27169;&#22411;&#24615;&#33021;&#26377;&#25152;&#25552;&#21319;&#12290;&#36825;&#20123;&#32467;&#26524;&#20063;&#26174;&#31034;&#20986;&#19981;&#21516;&#27169;&#22411;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#31243;&#24230;&#30340;&#38169;&#35823;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38646;&#23556;&#20987;&#25552;&#31034;&#26041;&#27861;&#12290;&#38646;&#23556;&#20987;&#25552;&#31034;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#30340;&#38169;&#35823;&#20449;&#24687;&#65292;&#36890;&#36807;&#25351;&#31034;LLMs&#21033;&#29992;&#20174;&#8220;&#31034;&#20363;&#8221;&#37096;&#20998;&#20013;&#33719;&#21462;&#30340;&#20449;&#24687;&#65288;&#35813;&#20449;&#24687;&#22312;&#25152;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#20013;&#19981;&#23384;&#22312;&#65289;&#26469;&#23436;&#25104;&#20219;&#21153;&#12290;&#34429;&#28982;&#20943;&#23569;&#38169;&#35823;&#20449;&#24687;&#23545;&#20110;LLMs&#30340;&#26085;&#24120;&#21644;&#37325;&#35201;&#29992;&#36884;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#22312;&#30446;&#21069;&#30340;&#29615;&#22659;&#20013;&#65292;&#36825;&#20123;LLMs&#20173;&#28982;&#20855;&#26377;&#38169;&#35823;&#20449;&#24687;&#65292;&#23454;&#38469;&#19978;&#21487;&#20197;&#21033;&#29992;&#38169;&#35823;&#20449;&#24687;&#26469;&#25552;&#39640;&#19982;&#26631;&#20934;&#38646;&#23556;&#20987;&#25552;&#31034;&#30456;&#27604;&#30340;&#20219;&#21153;&#34920;&#29616;&#12290;&#23545;&#20843;&#20010;LLMs&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#22312;&#22823;&#22810;&#25968;&#20843;&#20010;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#38405;&#35835;&#29702;&#35299;&#12289;&#31639;&#26415;&#25512;&#29702;&#21644;&#38381;&#21367;&#38382;&#31572;&#65289;&#20013;&#65292;&#24615;&#33021;&#26377;&#25152;&#25552;&#21319;&#12290;&#35266;&#23519;&#21040;&#30340;&#19981;&#19968;&#33268;&#24615;&#22686;&#21152;&#30456;&#23545;&#24615;&#33021;&#22312;LLMs&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#20063;&#21487;&#33021;&#34920;&#31034;&#27599;&#20010;&#27169;&#22411;&#20013;&#23384;&#22312;&#19981;&#21516;&#31243;&#24230;&#30340;&#38169;&#35823;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.08273v2 Announce Type: replace-cross Abstract: This paper presents null-shot prompting. Null-shot prompting exploits hallucination in large language models (LLMs) by instructing LLMs to utilize information from the "Examples" section that never exists within the provided context to perform a task. While reducing hallucination is crucial and non-negligible for daily and critical uses of LLMs, we propose that in the current landscape in which these LLMs still hallucinate, it is possible, in fact, to exploit hallucination to increase performance in performing tasks compared to standard zero-shot prompting. Experiments with eight LLMs show improvements in performance across the majority of eight datasets, including reading comprehension, arithmetic reasoning, and closed-book question answering. The observed inconsistency in increased relative performance across the LLMs also potentially indicates a different degree of inherent hallucination in each model. These differences show 
&lt;/p&gt;</description></item><item><title>SciGLM&#24341;&#20837;&#20102;&#33258;&#25105;&#21453;&#24605;&#25351;&#23548;&#27880;&#37322;&#26694;&#26550;&#65292;&#29992;&#20110;&#24357;&#34917;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#22797;&#26434;&#31185;&#23398;&#27010;&#24565;&#12289;&#25512;&#23548;&#31526;&#21495;&#26041;&#31243;&#24335;&#21644;&#35299;&#20915;&#39640;&#32423;&#25968;&#20540;&#35745;&#31639;&#26041;&#38754;&#30340;&#19981;&#36275;&#65292;&#20197;&#35757;&#32451;&#33021;&#22815;&#36827;&#34892;&#22823;&#23398;&#27700;&#24179;&#31185;&#23398;&#25512;&#29702;&#30340;&#31185;&#23398;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2401.07950</link><description>&lt;p&gt;
SciGLM: &#29992;&#33258;&#25105;&#21453;&#24605;&#25351;&#23548;&#27880;&#37322;&#21644;&#35843;&#25972;&#35757;&#32451;&#31185;&#23398;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.07950
&lt;/p&gt;
&lt;p&gt;
SciGLM&#24341;&#20837;&#20102;&#33258;&#25105;&#21453;&#24605;&#25351;&#23548;&#27880;&#37322;&#26694;&#26550;&#65292;&#29992;&#20110;&#24357;&#34917;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#22797;&#26434;&#31185;&#23398;&#27010;&#24565;&#12289;&#25512;&#23548;&#31526;&#21495;&#26041;&#31243;&#24335;&#21644;&#35299;&#20915;&#39640;&#32423;&#25968;&#20540;&#35745;&#31639;&#26041;&#38754;&#30340;&#19981;&#36275;&#65292;&#20197;&#35757;&#32451;&#33021;&#22815;&#36827;&#34892;&#22823;&#23398;&#27700;&#24179;&#31185;&#23398;&#25512;&#29702;&#30340;&#31185;&#23398;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#26174;&#31034;&#20986;&#22312;&#21327;&#21161;&#31185;&#23398;&#21457;&#29616;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;LLMs&#22312;&#29702;&#35299;&#22797;&#26434;&#31185;&#23398;&#27010;&#24565;&#12289;&#25512;&#23548;&#31526;&#21495;&#26041;&#31243;&#24335;&#21644;&#35299;&#20915;&#39640;&#32423;&#25968;&#20540;&#35745;&#31639;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#20123;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SciGLM&#65292;&#19968;&#22871;&#33021;&#22815;&#36827;&#34892;&#22823;&#23398;&#27700;&#24179;&#31185;&#23398;&#25512;&#29702;&#30340;&#31185;&#23398;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#25105;&#21453;&#24605;&#25351;&#23548;&#27880;&#37322;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#31185;&#23398;&#39046;&#22495;&#20013;&#25968;&#25454;&#31232;&#32570;&#25361;&#25112;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#29616;&#26377;LLMs&#20026;&#26410;&#26631;&#35760;&#30340;&#31185;&#23398;&#38382;&#39064;&#29983;&#25104;&#36880;&#27493;&#25512;&#29702;&#65292;&#38543;&#21518;&#32463;&#36807;&#33258;&#25105;&#21453;&#24605;&#30340;&#25209;&#35780;&#21644;&#20462;&#25913;&#36807;&#31243;&#12290;&#24212;&#29992;&#36825;&#19968;&#26694;&#26550;&#65292;&#25105;&#20204;&#25972;&#29702;&#20102;SciInstruct&#65292;&#36825;&#26159;&#19968;&#20010;&#28085;&#30422;&#29289;&#29702;&#12289;&#21270;&#23398;&#12289;&#25968;&#23398;&#21644;&#24418;&#24335;&#35777;&#26126;&#30340;&#22810;&#26679;&#21270;&#12289;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#21033;&#29992;SciInstruct&#23545;ChatGLM&#31995;&#21015;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#24494;&#35843;&#65292;&#22686;&#24378;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.07950v2 Announce Type: replace  Abstract: Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving advanced numerical calculations. To bridge these gaps, we introduce SciGLM, a suite of scientific language models able to conduct college-level scientific reasoning. Central to our approach is a novel self-reflective instruction annotation framework to address the data scarcity challenge in the science domain. This framework leverages existing LLMs to generate step-by-step reasoning for unlabelled scientific questions, followed by a process of self-reflective critic-and-revise. Applying this framework, we curated SciInstruct, a diverse and high-quality dataset encompassing physics, chemistry, math, and formal proofs. We fine-tuned the ChatGLM family of language models with SciInstruct, enhancing
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20840;&#38754;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#32534;&#36753;&#65292;&#26088;&#22312;&#26377;&#25928;&#20462;&#25913;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#21516;&#26102;&#20445;&#25345;&#25972;&#20307;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01286</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#32534;&#36753;&#20840;&#38754;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20840;&#38754;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#32534;&#36753;&#65292;&#26088;&#22312;&#26377;&#25928;&#20462;&#25913;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#21516;&#26102;&#20445;&#25345;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#29702;&#35299;&#21644;&#29983;&#25104;&#19982;&#20154;&#31867;&#20132;&#27969;&#32039;&#23494;&#30456;&#20284;&#30340;&#25991;&#26412;&#26041;&#38754;&#23637;&#29616;&#20986;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20854;&#20027;&#35201;&#38480;&#21046;&#22312;&#20110;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#26174;&#33879;&#35745;&#31639;&#38656;&#27714;&#65292;&#36825;&#26159;&#30001;&#20110;&#20854;&#24191;&#27867;&#30340;&#21442;&#25968;&#21270;&#36896;&#25104;&#30340;&#12290;&#36825;&#19968;&#25361;&#25112;&#22312;&#20110;&#19990;&#30028;&#30340;&#21160;&#24577;&#24615;&#65292;&#38656;&#35201;&#39057;&#32321;&#26356;&#26032;LLM&#20197;&#20462;&#27491;&#36807;&#26102;&#30340;&#20449;&#24687;&#25110;&#38598;&#25104;&#26032;&#30693;&#35782;&#65292;&#20174;&#32780;&#30830;&#20445;&#20854;&#25345;&#32493;&#30340;&#30456;&#20851;&#24615;&#12290;&#35768;&#22810;&#24212;&#29992;&#38656;&#35201;&#22312;&#35757;&#32451;&#21518;&#36827;&#34892;&#25345;&#32493;&#30340;&#27169;&#22411;&#35843;&#25972;&#65292;&#20197;&#35299;&#20915;&#32570;&#38519;&#25110;&#19981;&#33391;&#34892;&#20026;&#12290;&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;LLM&#30340;&#30693;&#35782;&#32534;&#36753;&#25216;&#26415;&#30340;&#20852;&#36259;&#36234;&#26469;&#36234;&#39640;&#65292;&#22312;&#29305;&#23450;&#39046;&#22495;&#20869;&#26377;&#25928;&#22320;&#20462;&#25913;LLM&#30340;&#34892;&#20026;&#65292;&#21516;&#26102;&#20445;&#25345;&#25972;&#20307;&#24615;&#33021;&#22312;&#21508;&#31181;&#36755;&#20837;&#20013;&#30340;&#34920;&#29616;&#12290;&#26412;&#25991;&#39318;&#20808;&#23450;&#20041;&#20102;&#30693;&#35782;&#32534;&#36753;&#30340;&#30446;&#26631;&#21644;&#25361;&#25112;&#65292;&#28982;&#21518;&#32508;&#36848;&#20102;&#29616;&#26377;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#21644;&#25216;&#26415;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#24212;&#29992;&#21644;&#26410;&#26469;&#21457;&#23637;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the kno
&lt;/p&gt;</description></item><item><title>Transformers&#23398;&#20250;&#20102;&#39640;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#36890;&#36807;&#23454;&#29616;&#31867;&#20284;&#20110;&#36845;&#20195;&#29275;&#39039;&#27861;&#30340;&#31639;&#27861;&#65292;&#32780;&#19981;&#26159;&#26799;&#24230;&#19979;&#38477;&#12290;</title><link>http://arxiv.org/abs/2310.17086</link><description>&lt;p&gt;
Transformers&#23398;&#20250;&#20102;&#39640;&#38454;&#20248;&#21270;&#26041;&#27861;&#29992;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#65306;&#19968;&#39033;&#19982;&#32447;&#24615;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models. (arXiv:2310.17086v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17086
&lt;/p&gt;
&lt;p&gt;
Transformers&#23398;&#20250;&#20102;&#39640;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#36890;&#36807;&#23454;&#29616;&#31867;&#20284;&#20110;&#36845;&#20195;&#29275;&#39039;&#27861;&#30340;&#31639;&#27861;&#65292;&#32780;&#19981;&#26159;&#26799;&#24230;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformers&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#26159;&#23427;&#20204;&#26159;&#22914;&#20309;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#20173;&#28982;&#26159;&#19968;&#20010;&#35868;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;Transformers&#21487;&#33021;&#36890;&#36807;&#20869;&#37096;&#36816;&#34892;&#26799;&#24230;&#19979;&#38477;&#65292;&#21363;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Transformers&#23398;&#20250;&#20102;&#23454;&#29616;&#39640;&#38454;&#20248;&#21270;&#26041;&#27861;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#25105;&#20204;&#20197;&#19978;&#19979;&#25991;&#32447;&#24615;&#22238;&#24402;&#20026;&#37325;&#28857;&#65292;&#23637;&#31034;&#20102;Transformers&#23398;&#20250;&#20102;&#23454;&#29616;&#19968;&#20010;&#38750;&#24120;&#31867;&#20284;&#20110;&#36845;&#20195;&#29275;&#39039;&#27861;&#30340;&#31639;&#27861;&#65292;&#32780;&#19981;&#26159;&#26799;&#24230;&#19979;&#38477;&#12290;&#20174;&#23454;&#35777;&#19978;&#26469;&#30475;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36830;&#32493;&#30340;Transformer&#23618;&#30340;&#39044;&#27979;&#19982;&#29275;&#39039;&#27861;&#30340;&#19981;&#21516;&#36845;&#20195;&#38750;&#24120;&#25509;&#36817;&#65292;&#27599;&#20010;&#20013;&#38388;&#23618;&#22823;&#33268;&#35745;&#31639;&#20102;3&#27425;&#36845;&#20195;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38656;&#35201;&#25351;&#25968;&#32423;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#25165;&#33021;&#21305;&#37197;&#39069;&#22806;&#30340;Transformer&#23618;&#65307;&#36825;&#34920;&#26126;Transformers&#20855;&#26377;&#30456;&#24403;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers are remarkably good at in-context learning (ICL) -- learning from demonstrations without parameter updates -- but how they perform ICL remains a mystery. Recent work suggests that Transformers may learn in-context by internally running Gradient Descent, a first-order optimization method. In this paper, we instead demonstrate that Transformers learn to implement higher-order optimization methods to perform ICL. Focusing on in-context linear regression, we show that Transformers learn to implement an algorithm very similar to Iterative Newton's Method, a higher-order optimization method, rather than Gradient Descent. Empirically, we show that predictions from successive Transformer layers closely match different iterations of Newton's Method linearly, with each middle layer roughly computing 3 iterations. In contrast, exponentially more Gradient Descent steps are needed to match an additional Transformers layer; this suggests that Transformers have an comparable rate of conv
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#24110;&#21161;&#24739;&#32773;&#21644;&#36716;&#35786;&#21307;&#29983;&#35782;&#21035;&#21512;&#36866;&#30340;&#20020;&#24202;&#35797;&#39564;&#30340;&#28508;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;TrialGPT&#26550;&#26500;&#65292;&#35813;&#26550;&#26500;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#21512;&#26684;&#24615;&#24182;&#25552;&#20379;&#35299;&#37322;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.15051</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#24739;&#32773;&#19982;&#20020;&#24202;&#35797;&#39564;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Matching Patients to Clinical Trials with Large Language Models. (arXiv:2307.15051v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#24110;&#21161;&#24739;&#32773;&#21644;&#36716;&#35786;&#21307;&#29983;&#35782;&#21035;&#21512;&#36866;&#30340;&#20020;&#24202;&#35797;&#39564;&#30340;&#28508;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;TrialGPT&#26550;&#26500;&#65292;&#35813;&#26550;&#26500;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#21512;&#26684;&#24615;&#24182;&#25552;&#20379;&#35299;&#37322;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#35797;&#39564;&#22312;&#25512;&#21160;&#33647;&#29289;&#30740;&#21457;&#21644;&#22522;&#20110;&#35777;&#25454;&#30340;&#21307;&#23398;&#26041;&#38754;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#24739;&#32773;&#25307;&#21215;&#24120;&#24120;&#21463;&#21040;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#24110;&#21161;&#24739;&#32773;&#21644;&#36716;&#35786;&#21307;&#29983;&#35782;&#21035;&#21512;&#36866;&#30340;&#20020;&#24202;&#35797;&#39564;&#30340;&#28508;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;TrialGPT&#65292;&#37319;&#29992;LLMs&#39044;&#27979;&#22522;&#20110;&#26631;&#20934;&#30340;&#21512;&#26684;&#24615;&#65292;&#24182;&#25552;&#20379;&#35814;&#32454;&#30340;&#35299;&#37322;&#65292;&#24182;&#26681;&#25454;&#24739;&#32773;&#30149;&#21382;&#20013;&#30340;&#33258;&#30001;&#25991;&#26412;&#26469;&#23545;&#20505;&#36873;&#20020;&#24202;&#35797;&#39564;&#36827;&#34892;&#25490;&#21517;&#21644;&#25490;&#38500;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;184&#21517;&#24739;&#32773;&#21644;18,238&#20010;&#27880;&#37322;&#30340;&#20020;&#24202;&#35797;&#39564;&#30340;&#38431;&#21015;&#19978;&#35780;&#20272;&#20102;TrialGPT&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20960;&#20010;&#20851;&#38190;&#21457;&#29616;&#65306;&#31532;&#19968;&#65292;TrialGPT&#22312;&#26631;&#20934;&#32423;&#21035;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#20934;&#30830;&#29575;&#65292;&#24182;&#25552;&#20379;&#20934;&#30830;&#30340;&#35299;&#37322;&#12290;&#31532;&#20108;&#65292;TrialGPT&#30340;&#32508;&#21512;&#35797;&#39564;&#32423;&#21035;&#35780;&#20998;&#19982;&#19987;&#23478;&#26631;&#27880;&#30340;&#21512;&#26684;&#24615;&#39640;&#24230;&#30456;&#20851;&#12290;&#31532;&#19977;&#65292;&#36825;&#20123;&#35780;&#20998;
&lt;/p&gt;
&lt;p&gt;
Clinical trials are vital in advancing drug development and evidence-based medicine, but their success is often hindered by challenges in patient recruitment. In this work, we investigate the potential of large language models (LLMs) to assist individual patients and referral physicians in identifying suitable clinical trials from an extensive selection. Specifically, we introduce TrialGPT, a novel architecture employing LLMs to predict criterion-level eligibility with detailed explanations, which are then aggregated for ranking and excluding candidate clinical trials based on free-text patient notes. We evaluate TrialGPT on three publicly available cohorts of 184 patients and 18,238 annotated clinical trials. The experimental results demonstrate several key findings: First, TrialGPT achieves high criterion-level prediction accuracy with faithful explanations. Second, the aggregated trial-level TrialGPT scores are highly correlated with expert eligibility annotations. Third, these scor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#26426;&#22120;&#32763;&#35793;&#21487;&#35299;&#37322;&#24615;&#35780;&#20272;&#25351;&#26631;&#65292;&#25552;&#20379;&#32508;&#21512;&#32508;&#36848;&#21644;&#26368;&#26032;&#26041;&#27861;&#65292;&#24182;&#36129;&#29486;&#19979;&#19968;&#20195;&#26041;&#27861;&#30340;&#24895;&#26223;&#12290;</title><link>http://arxiv.org/abs/2306.13041</link><description>&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#21487;&#35299;&#37322;&#24615;&#35780;&#20272;&#25351;&#26631;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Towards Explainable Evaluation Metrics for Machine Translation. (arXiv:2306.13041v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#26426;&#22120;&#32763;&#35793;&#21487;&#35299;&#37322;&#24615;&#35780;&#20272;&#25351;&#26631;&#65292;&#25552;&#20379;&#32508;&#21512;&#32508;&#36848;&#21644;&#26368;&#26032;&#26041;&#27861;&#65292;&#24182;&#36129;&#29486;&#19979;&#19968;&#20195;&#26041;&#27861;&#30340;&#24895;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20256;&#32479;&#30340;&#35789;&#27719;&#37325;&#21472;&#24230;&#37327;&#65288;&#22914;BLEU&#65289;&#19981;&#21516;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#35780;&#20272;&#30340;&#25351;&#26631;&#65288;&#20363;&#22914;COMET&#25110;BERTScore&#65289;&#22522;&#20110;&#40657;&#30418;&#23376;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#23427;&#20204;&#36890;&#24120;&#19982;&#20154;&#31867;&#21028;&#26029;&#20855;&#26377;&#24378;&#30456;&#20851;&#24615;&#65292;&#20294;&#26159;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36739;&#20302;&#36136;&#37327;&#30340;&#20256;&#32479;&#25351;&#26631;&#20173;&#28982;&#21344;&#20027;&#23548;&#22320;&#20301;&#65292;&#20854;&#20013;&#19968;&#20010;&#28508;&#22312;&#21407;&#22240;&#26159;&#23427;&#20204;&#30340;&#20915;&#31574;&#36807;&#31243;&#26356;&#36879;&#26126;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#20419;&#36827;&#26032;&#30340;&#39640;&#36136;&#37327;&#25351;&#26631;&#30340;&#26356;&#24191;&#27867;&#25509;&#21463;&#65292;&#35299;&#37322;&#24615;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#31687;&#27010;&#24565;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#21487;&#35299;&#37322;&#26426;&#22120;&#32763;&#35793;&#25351;&#26631;&#30340;&#20851;&#38190;&#23646;&#24615;&#21644;&#30446;&#26631;&#65292;&#24182;&#25552;&#20379;&#20102;&#26368;&#36817;&#25216;&#26415;&#30340;&#32508;&#21512;&#32508;&#36848;&#65292;&#23558;&#23427;&#20204;&#19982;&#25105;&#20204;&#30830;&#31435;&#30340;&#30446;&#26631;&#21644;&#23646;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;ChatGPT&#21644;GPT4&#65289;&#30340;&#21487;&#35299;&#37322;&#25351;&#26631;&#30340;&#26368;&#26032;&#20808;&#36827;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36129;&#29486;&#20102;&#19979;&#19968;&#20195;&#26041;&#27861;&#30340;&#24895;&#26223;&#65292;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;e&#12290;
&lt;/p&gt;
&lt;p&gt;
Unlike classical lexical overlap metrics such as BLEU, most current evaluation metrics for machine translation (for example, COMET or BERTScore) are based on black-box large language models. They often achieve strong correlations with human judgments, but recent research indicates that the lower-quality classical metrics remain dominant, one of the potential reasons being that their decision processes are more transparent. To foster more widespread acceptance of novel high-quality metrics, explainability thus becomes crucial. In this concept paper, we identify key properties as well as key goals of explainable machine translation metrics and provide a comprehensive synthesis of recent techniques, relating them to our established goals and properties. In this context, we also discuss the latest state-of-the-art approaches to explainable metrics based on generative models such as ChatGPT and GPT4. Finally, we contribute a vision of next-generation approaches, including natural language e
&lt;/p&gt;</description></item></channel></rss>