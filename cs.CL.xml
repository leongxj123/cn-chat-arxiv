<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#65292;&#23454;&#29616;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#20351;&#29992;&#35821;&#38899;&#25968;&#25454;&#65292;&#19988;&#30456;&#27604;&#20808;&#21069;&#31995;&#32479;&#21462;&#24471;10%&#30340;Recall@1&#32477;&#23545;&#25913;&#36827;</title><link>https://arxiv.org/abs/2404.01616</link><description>&lt;p&gt;
&#23558;LLMs&#36716;&#21270;&#20026;&#36328;&#27169;&#24577;&#21644;&#36328;&#35821;&#35328;&#26816;&#32034;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Transforming LLMs into Cross-modal and Cross-lingual RetrievalSystems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01616
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#65292;&#23454;&#29616;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#20351;&#29992;&#35821;&#38899;&#25968;&#25454;&#65292;&#19988;&#30456;&#27604;&#20808;&#21069;&#31995;&#32479;&#21462;&#24471;10%&#30340;Recall@1&#32477;&#23545;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#22312;&#20165;&#22522;&#20110;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#65292;&#36825;&#36229;&#20986;&#20102;&#20855;&#26377;&#37197;&#23545;&#35821;&#38899;&#21644;&#25991;&#26412;&#25968;&#25454;&#30340;&#35821;&#35328;&#33539;&#22260;&#12290;&#21516;&#26102;&#65292;&#22522;&#20110;&#21452;&#32534;&#30721;&#22120;&#65288;DE&#65289;&#30340;&#26816;&#32034;&#31995;&#32479;&#23558;&#26597;&#35810;&#21644;&#25991;&#26723;&#25237;&#24433;&#21040;&#30456;&#21516;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#24182;&#22312;&#26816;&#32034;&#21644;&#21452;&#35821;&#25991;&#26412;&#25366;&#25496;&#20013;&#23637;&#31034;&#20102;&#25104;&#21151;&#12290;&#20026;&#20102;&#22312;&#35768;&#22810;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#19981;&#38656;&#35201;&#35821;&#38899;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#21033;&#29992;LLM&#30340;&#22810;&#35821;&#35328;&#25991;&#26412;&#29702;&#35299;&#33021;&#21147;&#26469;&#21305;&#37197;&#26816;&#32034;&#35757;&#32451;&#26399;&#38388;&#30475;&#19981;&#35265;&#30340;&#35821;&#35328;&#20013;&#30340;&#35821;&#38899;&#21644;&#25991;&#26412;&#12290;&#25105;&#20204;&#30340;&#22810;&#27169;&#24577;LLM-based&#26816;&#32034;&#31995;&#32479;&#33021;&#22815;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#65292;&#23613;&#31649;&#21482;&#22312;21&#31181;&#35821;&#35328;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#20248;&#20110;&#20808;&#21069;&#19987;&#38376;&#22312;&#25152;&#26377;102&#31181;&#35821;&#35328;&#19978;&#35757;&#32451;&#30340;&#31995;&#32479;&#12290;&#22312;&#36825;&#20123;&#35821;&#35328;&#20013;&#65292;&#25105;&#20204;&#22312;Recall@1&#19978;&#23454;&#29616;&#20102;10&#65285;&#30340;&#32477;&#23545;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01616v1 Announce Type: new  Abstract: Large language models (LLMs) are trained on text-only data that go far beyond the languages with paired speech and text data. At the same time, Dual Encoder (DE) based retrieval systems project queries and documents into the same embedding space and have demonstrated their success in retrieval and bi-text mining. To match speech and text in many languages, we propose using LLMs to initialize multi-modal DE retrieval systems. Unlike traditional methods, our system doesn't require speech data during LLM pre-training and can exploit LLM's multilingual text understanding capabilities to match speech and text in languages unseen during retrieval training. Our multi-modal LLM-based retrieval system is capable of matching speech and text in 102 languages despite only training on 21 languages. Our system outperforms previous systems trained explicitly on all 102 languages. We achieve a 10% absolute improvement in Recall@1 averaged across these l
&lt;/p&gt;</description></item><item><title>CHOPS&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CHOPS&#30340;LLM&#20195;&#29702;&#65292;&#26088;&#22312;&#26356;&#39640;&#25928;&#22320;&#21033;&#29992;&#29616;&#26377;&#25968;&#25454;&#24211;&#25110;&#31995;&#32479;&#26469;&#35775;&#38382;&#29992;&#25143;&#20449;&#24687;&#65292;&#25552;&#20379;&#20934;&#30830;&#21512;&#29702;&#30340;&#21709;&#24212;&#25110;&#25191;&#34892;&#25152;&#38656;&#25805;&#20316;&#65292;&#21516;&#26102;&#36991;&#20813;&#26377;&#23475;&#25805;&#20316;&#12290;</title><link>https://arxiv.org/abs/2404.01343</link><description>&lt;p&gt;
CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs
&lt;/p&gt;
&lt;p&gt;
CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01343
&lt;/p&gt;
&lt;p&gt;
CHOPS&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CHOPS&#30340;LLM&#20195;&#29702;&#65292;&#26088;&#22312;&#26356;&#39640;&#25928;&#22320;&#21033;&#29992;&#29616;&#26377;&#25968;&#25454;&#24211;&#25110;&#31995;&#32479;&#26469;&#35775;&#38382;&#29992;&#25143;&#20449;&#24687;&#65292;&#25552;&#20379;&#20934;&#30830;&#21512;&#29702;&#30340;&#21709;&#24212;&#25110;&#25191;&#34892;&#25152;&#38656;&#25805;&#20316;&#65292;&#21516;&#26102;&#36991;&#20813;&#26377;&#23475;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;&#21644;&#36719;&#20214;&#24179;&#21488;&#36234;&#26469;&#36234;&#20542;&#21521;&#20110;&#20351;&#29992;&#20687;GPT-3.5&#12289;GPT-4&#12289;GLM-3&#21644;LLaMa-2&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23458;&#25143;&#26381;&#21153;&#30340;&#32842;&#22825;&#36741;&#21161;&#25110;&#25512;&#29702;&#20195;&#29702;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#22522;&#20110;LLM&#30340;&#23458;&#25143;&#26381;&#21153;&#27169;&#22411;&#22312;&#19982;&#23458;&#25143;&#37197;&#32622;&#25991;&#20214;&#30340;&#38598;&#25104;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#65292;&#24182;&#19988;&#32570;&#20047;&#26377;&#25928;&#26381;&#21153;&#25152;&#38656;&#30340;&#25805;&#20316;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CHOPS&#65288;CHat with custOmer Profile in existing System&#65289;&#30340;LLM&#20195;&#29702;&#65292;&#26088;&#22312;&#65306;&#65288;1&#65289;&#39640;&#25928;&#21033;&#29992;&#29616;&#26377;&#25968;&#25454;&#24211;&#25110;&#31995;&#32479;&#20197;&#35775;&#38382;&#29992;&#25143;&#20449;&#24687;&#25110;&#25353;&#29031;&#29616;&#26377;&#25351;&#21335;&#19982;&#36825;&#20123;&#31995;&#32479;&#20132;&#20114;&#65307;&#65288;2&#65289;&#25552;&#20379;&#20934;&#30830;&#21512;&#29702;&#30340;&#21709;&#24212;&#25110;&#22312;&#31995;&#32479;&#20013;&#25191;&#34892;&#25152;&#38656;&#25805;&#20316;&#65292;&#21516;&#26102;&#36991;&#20813;&#26377;&#23475;&#25805;&#20316;&#65307;&#65288;3&#65289;&#21033;&#29992;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01343v1 Announce Type: cross  Abstract: Businesses and software platforms are increasingly turning to Large Language Models (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistance with file access or as reasoning agents for customer service. However, current LLM-based customer service models have limited integration with customer profiles and lack the operational capabilities necessary for effective service. Moreover, existing API integrations emphasize diversity over the precision and error avoidance essential in real-world customer service scenarios. To address these issues, we propose an LLM agent named CHOPS (CHat with custOmer Profile in existing System), designed to: (1) efficiently utilize existing databases or systems for accessing user information or interacting with these systems following existing guidelines; (2) provide accurate and reasonable responses or carry out required operations in the system while avoiding harmful operations; and (3) leverag
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PrimeVul&#65292;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#28431;&#27934;&#26816;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#22871;&#26032;&#39062;&#30340;&#25968;&#25454;&#26631;&#35760;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#19982;&#20154;&#24037;&#39564;&#35777;&#22522;&#20934;&#30456;&#24403;&#30340;&#26631;&#31614;&#20934;&#30830;&#24615;&#65292;&#26174;&#33879;&#25193;&#22823;&#20102;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.18624</link><description>&lt;p&gt;
&#20351;&#29992;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#28431;&#27934;&#26816;&#27979;&#65306;&#25105;&#20204;&#31163;&#30446;&#26631;&#26377;&#22810;&#36828;&#65311;
&lt;/p&gt;
&lt;p&gt;
Vulnerability Detection with Code Language Models: How Far Are We?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18624
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PrimeVul&#65292;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#28431;&#27934;&#26816;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#22871;&#26032;&#39062;&#30340;&#25968;&#25454;&#26631;&#35760;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#19982;&#20154;&#24037;&#39564;&#35777;&#22522;&#20934;&#30456;&#24403;&#30340;&#26631;&#31614;&#20934;&#30830;&#24615;&#65292;&#26174;&#33879;&#25193;&#22823;&#20102;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#65288;code LMs&#65289;&#21644;&#28431;&#27934;&#26816;&#27979;&#22791;&#21463;&#20851;&#27880;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#26816;&#27979;&#28431;&#27934;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#29616;&#26377;&#28431;&#27934;&#25968;&#25454;&#38598;&#23384;&#22312;&#30340;&#37325;&#22823;&#32570;&#38519;&#65292;&#21253;&#25324;&#25968;&#25454;&#36136;&#37327;&#20302;&#12289;&#26631;&#31614;&#20934;&#30830;&#24615;&#24046;&#20197;&#21450;&#39640;&#37325;&#22797;&#29575;&#65292;&#23548;&#33268;&#22312;&#29616;&#23454;&#28431;&#27934;&#26816;&#27979;&#22330;&#26223;&#20013;&#27169;&#22411;&#24615;&#33021;&#19981;&#21487;&#38752;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#20351;&#29992;&#30340;&#35780;&#20272;&#26041;&#27861;&#20063;&#19981;&#33021;&#20195;&#34920;&#30495;&#23454;&#19990;&#30028;&#30340;&#28431;&#27934;&#26816;&#27979;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18624v1 Announce Type: cross  Abstract: In the context of the rising interest in code language models (code LMs) and vulnerability detection, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection.   To address these challenges, we introduce PrimeVul, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to human-verified benchmarks while significantly expanding the dataset. It also implements a rigorous data de-duplication and chronological data splitting strategy to miti
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#22810;&#32422;&#26463;&#20998;&#23376;&#29983;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;TSMMG&#65292;&#36890;&#36807;&#25972;&#21512;&#22810;&#20010;&#23567;&#27169;&#22411;&#21644;&#24037;&#20855;&#26469;&#24110;&#21161;&#29983;&#25104;&#31526;&#21512;&#25551;&#36848;&#30340;&#26032;&#20998;&#23376;&#65292;&#22312;&#21508;&#31181;&#32422;&#26463;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#31168;&#12290;</title><link>https://arxiv.org/abs/2403.13244</link><description>&lt;p&gt;
&#20351;&#29992;&#24072;&#29983;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22810;&#32422;&#26463;&#20998;&#23376;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13244
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#22810;&#32422;&#26463;&#20998;&#23376;&#29983;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;TSMMG&#65292;&#36890;&#36807;&#25972;&#21512;&#22810;&#20010;&#23567;&#27169;&#22411;&#21644;&#24037;&#20855;&#26469;&#24110;&#21161;&#29983;&#25104;&#31526;&#21512;&#25551;&#36848;&#30340;&#26032;&#20998;&#23376;&#65292;&#22312;&#21508;&#31181;&#32422;&#26463;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#27169;&#22411;&#21644;&#35745;&#31639;&#24037;&#20855;&#29992;&#20110;&#20998;&#23376;&#30340;&#32467;&#26500;&#21644;&#24615;&#36136;&#20998;&#26512;&#65292;&#20294;&#29983;&#25104;&#31526;&#21512;&#25152;&#26377;&#26399;&#26395;&#32467;&#26500;&#21644;&#24615;&#36136;&#30340;&#20998;&#23376;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#22810;&#32422;&#26463;&#20998;&#23376;&#29983;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;TSMMG&#65292;&#31867;&#20284;&#20110;&#23398;&#29983;&#65292;&#35813;&#27169;&#22411;&#25972;&#21512;&#20102;&#26469;&#33258;&#21508;&#31181;&#23567;&#27169;&#22411;&#21644;&#24037;&#20855;&#65288;&#21363;&#8220;&#32769;&#24072;&#8221;&#65289;&#30340;&#30693;&#35782;&#12290;&#20026;&#20102;&#35757;&#32451;TSMMG&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;&#36825;&#20123;&#8216;&#32769;&#24072;&#8217;&#20013;&#25552;&#21462;&#30340;&#20998;&#23376;&#30693;&#35782;&#26500;&#24314;&#20102;&#22823;&#37327;&#25991;&#26412;-&#20998;&#23376;&#23545;&#65292;&#20351;&#20854;&#33021;&#22815;&#36890;&#36807;&#21508;&#31181;&#25991;&#26412;&#25552;&#31034;&#29983;&#25104;&#31526;&#21512;&#25551;&#36848;&#30340;&#26032;&#20998;&#23376;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;TSMMG&#22312;&#29983;&#25104;&#31526;&#21512;&#22797;&#26434;&#12289;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#20004;&#12289;&#19977;&#21644;&#22235;&#32422;&#26463;&#20219;&#21153;&#30340;&#20998;&#23376;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24179;&#22343;&#20998;&#23376;&#26377;&#25928;&#24615;&#36229;&#36807;99&#65285;&#65292;&#25104;&#21151;&#29575;&#20998;&#21035;&#20026;88.08&#65285;&#12289;65.27&#65285;&#21644;61.44&#65285;&#12290;&#35813;&#27169;&#22411;&#36824;ex
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13244v1 Announce Type: new  Abstract: While various models and computational tools have been proposed for structure and property analysis of molecules, generating molecules that conform to all desired structures and properties remains a challenge. Here, we introduce a multi-constraint molecular generation large language model, TSMMG, which, akin to a student, incorporates knowledge from various small models and tools, namely, the 'teachers'. To train TSMMG, we construct a large set of text-molecule pairs by extracting molecular knowledge from these 'teachers', enabling it to generate novel molecules that conform to the descriptions through various text prompts. We experimentally show that TSMMG remarkably performs in generating molecules meeting complex, natural language-described property requirements across two-, three-, and four-constraint tasks, with an average molecular validity of over 99% and success ratio of 88.08%, 65.27%, and 61.44%, respectively. The model also ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25991;&#26412;&#23884;&#20837;&#21512;&#25104;&#22120;&#65288;TES&#65289;&#65292;&#29992;&#20110;&#20026;&#26080;&#26631;&#31614;&#25968;&#25454;&#29983;&#25104;&#20266;&#25991;&#26412;&#23884;&#20837;&#65292;&#20197;&#35299;&#38145;CLIP&#29992;&#20110;&#24191;&#20041;&#31867;&#21035;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#22810;&#27169;&#24577;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.09974</link><description>&lt;p&gt;
GET&#65306;&#35299;&#38145;CLIP&#30340;&#22810;&#27169;&#24577;&#28508;&#21147;&#65292;&#29992;&#20110;&#24191;&#20041;&#31867;&#21035;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09974
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25991;&#26412;&#23884;&#20837;&#21512;&#25104;&#22120;&#65288;TES&#65289;&#65292;&#29992;&#20110;&#20026;&#26080;&#26631;&#31614;&#25968;&#25454;&#29983;&#25104;&#20266;&#25991;&#26412;&#23884;&#20837;&#65292;&#20197;&#35299;&#38145;CLIP&#29992;&#20110;&#24191;&#20041;&#31867;&#21035;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#22810;&#27169;&#24577;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#21253;&#21547;&#26087;&#31867;&#21035;&#21644;&#26032;&#31867;&#21035;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#65292;&#24191;&#20041;&#31867;&#21035;&#21457;&#29616;&#65288;GCD&#65289;&#26088;&#22312;&#20934;&#30830;&#21457;&#29616;&#26032;&#31867;&#21035;&#65292;&#24182;&#27491;&#30830;&#20998;&#31867;&#26087;&#31867;&#21035;&#65292;&#21033;&#29992;&#20174;&#26377;&#26631;&#31614;&#26679;&#26412;&#20013;&#23398;&#20064;&#30340;&#31867;&#21035;&#27010;&#24565;&#12290;&#24403;&#21069;&#30340;GCD&#26041;&#27861;&#21482;&#20351;&#29992;&#21333;&#19968;&#30340;&#35270;&#35273;&#20449;&#24687;&#27169;&#24577;&#65292;&#23548;&#33268;&#22312;&#35270;&#35273;&#19978;&#30456;&#20284;&#31867;&#21035;&#30340;&#20998;&#31867;&#25928;&#26524;&#19981;&#20339;&#12290;&#34429;&#28982;&#26576;&#20123;&#31867;&#21035;&#22312;&#35270;&#35273;&#19978;&#23481;&#26131;&#28151;&#28102;&#65292;&#20294;&#23427;&#20204;&#30340;&#25991;&#26412;&#20449;&#24687;&#21487;&#33021;&#26159;&#19981;&#21516;&#30340;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#23558;&#25991;&#26412;&#20449;&#24687;&#24341;&#20837;&#21040;GCD&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#26080;&#26631;&#31614;&#25968;&#25454;&#32570;&#20047;&#31867;&#21035;&#21517;&#31216;&#65292;&#20351;&#24471;&#21033;&#29992;&#25991;&#26412;&#20449;&#24687;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25991;&#26412;&#23884;&#20837;&#21512;&#25104;&#22120;&#65288;TES&#65289;&#65292;&#29992;&#20110;&#20026;&#26080;&#26631;&#31614;&#26679;&#26412;&#29983;&#25104;&#20266;&#25991;&#26412;&#23884;&#20837;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;TES&#21033;&#29992;CLIP&#21487;&#20197;&#29983;&#25104;&#23545;&#40784;&#30340;&#35270;&#35273;-&#35821;&#35328;&#29305;&#24449;&#36825;&#19968;&#29305;&#24615;&#65292;&#23558;&#35270;&#35273;&#23884;&#20837;&#36716;&#25442;&#20026;CLIP&#25991;&#26412;&#27169;&#22411;&#30340;&#26631;&#35760;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09974v1 Announce Type: cross  Abstract: Given unlabelled datasets containing both old and new categories, generalized category discovery (GCD) aims to accurately discover new classes while correctly classifying old classes, leveraging the class concepts learned from labeled samples. Current GCD methods only use a single visual modality of information, resulting in poor classification of visually similar classes. Though certain classes are visually confused, their text information might be distinct, motivating us to introduce text information into the GCD task. However, the lack of class names for unlabelled data makes it impractical to utilize text information. To tackle this challenging problem, in this paper, we propose a Text Embedding Synthesizer (TES) to generate pseudo text embeddings for unlabelled samples. Specifically, our TES leverages the property that CLIP can generate aligned vision-language features, converting visual embeddings into tokens of the CLIP's text e
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;Composition Score&#65292;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20110;&#37327;&#21270;&#21477;&#23376;&#29702;&#35299;&#20013;&#30340;&#21547;&#20041;&#21512;&#25104;&#31243;&#24230;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#19968;&#24230;&#37327;&#19982;&#22823;&#33041;&#21306;&#22495;&#30456;&#20851;&#65292;&#25581;&#31034;&#20102;&#21547;&#20041;&#21512;&#25104;&#22312;&#20154;&#31867;&#21477;&#23376;&#29702;&#35299;&#20013;&#30340;&#22810;&#26041;&#38754;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04325</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#32452;&#21512;&#20998;&#25968;&#27979;&#37327;&#20154;&#33041;&#20013;&#30340;&#21547;&#20041;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04325
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;Composition Score&#65292;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20110;&#37327;&#21270;&#21477;&#23376;&#29702;&#35299;&#20013;&#30340;&#21547;&#20041;&#21512;&#25104;&#31243;&#24230;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#19968;&#24230;&#37327;&#19982;&#22823;&#33041;&#21306;&#22495;&#30456;&#20851;&#65292;&#25581;&#31034;&#20102;&#21547;&#20041;&#21512;&#25104;&#22312;&#20154;&#31867;&#21477;&#23376;&#29702;&#35299;&#20013;&#30340;&#22810;&#26041;&#38754;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21547;&#20041;&#21512;&#25104;&#30340;&#36807;&#31243;&#26159;&#25351;&#26356;&#23567;&#30340;&#21333;&#20301;&#22914;&#35821;&#32032;&#25110;&#21333;&#35789;&#32452;&#21512;&#24418;&#25104;&#30701;&#35821;&#21644;&#21477;&#23376;&#30340;&#21547;&#20041;&#65292;&#23545;&#20110;&#20154;&#31867;&#21477;&#23376;&#29702;&#35299;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#31070;&#32463;&#35821;&#35328;&#23398;&#23545;&#28041;&#21450;&#21547;&#20041;&#21512;&#25104;&#30340;&#22823;&#33041;&#21306;&#22495;&#36827;&#34892;&#20102;&#22823;&#37327;&#30740;&#31350;&#65292;&#20294;&#20173;&#32570;&#20047;&#19968;&#31181;&#35745;&#31639;&#24230;&#37327;&#26469;&#37327;&#21270;&#21512;&#25104;&#30340;&#31243;&#24230;&#12290;&#20511;&#37492;&#21464;&#21387;&#22120;&#21069;&#39304;&#32593;&#32476;&#22359;&#30340;&#38190;&#20540;&#20869;&#23384;&#35299;&#37322;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32452;&#21512;&#20998;&#25968;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#26088;&#22312;&#37327;&#21270;&#21477;&#23376;&#29702;&#35299;&#36807;&#31243;&#20013;&#30340;&#21547;&#20041;&#21512;&#25104;&#31243;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#19968;&#24230;&#37327;&#19982;&#22823;&#33041;&#31751;&#30456;&#20851;&#32852;&#65292;&#36825;&#20123;&#22823;&#33041;&#31751;&#19982;&#35789;&#39057;&#29575;&#12289;&#32467;&#26500;&#22788;&#29702;&#21644;&#23545;&#21333;&#35789;&#30340;&#19968;&#33324;&#25935;&#24863;&#24615;&#26377;&#20851;&#65292;&#36825;&#34920;&#26126;&#20102;&#20154;&#31867;&#21477;&#23376;&#29702;&#35299;&#36807;&#31243;&#20013;&#21547;&#20041;&#21512;&#25104;&#30340;&#22810;&#26041;&#38754;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04325v1 Announce Type: cross  Abstract: The process of meaning composition, wherein smaller units like morphemes or words combine to form the meaning of phrases and sentences, is essential for human sentence comprehension. Despite extensive neurolinguistic research into the brain regions involved in meaning composition, a computational metric to quantify the extent of composition is still lacking. Drawing on the key-value memory interpretation of transformer feed-forward network blocks, we introduce the Composition Score, a novel model-based metric designed to quantify the degree of meaning composition during sentence comprehension. Experimental findings show that this metric correlates with brain clusters associated with word frequency, structural processing, and general sensitivity to words, suggesting the multifaceted nature of meaning composition during human sentence comprehension.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;LLM&#20195;&#29702;&#30340;&#22522;&#20110;&#25506;&#32034;&#30340;&#36712;&#36857;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20801;&#35768;&#20195;&#29702;&#20174;&#25506;&#32034;&#22833;&#36133;&#20013;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#24615;&#33021;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2403.02502</link><description>&lt;p&gt;
&#35797;&#38169;&#27861;&#65306;&#38754;&#21521;LLM&#20195;&#29702;&#30340;&#22522;&#20110;&#25506;&#32034;&#30340;&#36712;&#36857;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02502
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;LLM&#20195;&#29702;&#30340;&#22522;&#20110;&#25506;&#32034;&#30340;&#36712;&#36857;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20801;&#35768;&#20195;&#29702;&#20174;&#25506;&#32034;&#22833;&#36133;&#20013;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#24615;&#33021;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#33258;&#20027;&#20195;&#29702;&#31995;&#32479;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#25506;&#32034;&#30340;&#36712;&#36857;&#20248;&#21270;&#26041;&#27861;&#65292;&#31216;&#20026;ETO&#12290;&#36825;&#31181;&#23398;&#20064;&#26041;&#27861;&#26088;&#22312;&#25552;&#39640;&#24320;&#25918;LLM&#20195;&#29702;&#30340;&#24615;&#33021;&#12290;&#19982;&#20808;&#21069;&#19987;&#38376;&#35757;&#32451;&#25104;&#21151;&#19987;&#23478;&#36712;&#36857;&#30340;&#30740;&#31350;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#20195;&#29702;&#20174;&#20854;&#25506;&#32034;&#22833;&#36133;&#20013;&#23398;&#20064;&#12290;&#36825;&#36890;&#36807;&#36845;&#20195;&#20248;&#21270;&#26694;&#26550;&#23454;&#29616;&#20102;&#24615;&#33021;&#30340;&#25913;&#36827;&#12290;&#22312;&#25506;&#32034;&#38454;&#27573;&#65292;&#20195;&#29702;&#19982;&#29615;&#22659;&#20114;&#21160;&#65292;&#23436;&#25104;&#25351;&#23450;&#20219;&#21153;&#65292;&#25910;&#38598;&#22833;&#36133;&#36712;&#36857;&#20197;&#21019;&#24314;&#23545;&#27604;&#36712;&#36857;&#23545;&#12290;&#22312;&#38543;&#21518;&#30340;&#35757;&#32451;&#38454;&#27573;&#65292;&#20195;&#29702;&#21033;&#29992;&#36825;&#20123;&#36712;&#36857;&#20559;&#22909;&#23545;&#26356;&#26032;&#20854;&#31574;&#30053;&#65292;&#20351;&#29992;&#31867;&#20284;DPO&#30340;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#12290;&#36825;&#31181;&#25506;&#32034;&#21644;&#35757;&#32451;&#30340;&#36845;&#20195;&#24490;&#29615;&#20419;&#36827;&#20102;&#20195;&#29702;&#30340;&#25345;&#32493;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02502v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have become integral components in various autonomous agent systems. In this study, we present an exploration-based trajectory optimization approach, referred to as ETO. This learning method is designed to enhance the performance of open LLM agents. Contrary to previous studies that exclusively train on successful expert trajectories, our method allows agents to learn from their exploration failures. This leads to improved performance through an iterative optimization framework. During the exploration phase, the agent interacts with the environment while completing given tasks, gathering failure trajectories to create contrastive trajectory pairs. In the subsequent training phase, the agent utilizes these trajectory preference pairs to update its policy using contrastive learning methods like DPO. This iterative cycle of exploration and training fosters continued improvement in the agents. Our experiments o
&lt;/p&gt;</description></item><item><title>TMMLU+&#26159;&#20256;&#32479;&#20013;&#25991;&#22823;&#35268;&#27169;&#22810;&#20219;&#21153;&#35821;&#35328;&#29702;&#35299;&#25968;&#25454;&#38598;&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#35268;&#27169;&#26159;&#21069;&#32773;&#30340;&#20845;&#20493;&#65292;&#21253;&#21547;66&#20010;&#22810;&#26679;&#21270;&#20027;&#39064;&#12290;&#30740;&#31350;&#26174;&#31034;&#20256;&#32479;&#20013;&#25991;&#27169;&#22411;&#20173;&#28982;&#33853;&#21518;&#20110;&#31616;&#20307;&#20013;&#25991;&#27169;&#22411;&#65292;&#24182;&#19988;&#30446;&#21069;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#24179;&#22343;&#24471;&#20998;&#19978;&#23578;&#26410;&#36229;&#36807;&#20154;&#31867;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2403.01858</link><description>&lt;p&gt;
&#19968;&#31181;&#25913;&#36827;&#30340;&#20256;&#32479;&#20013;&#25991;&#22522;&#37329;&#27169;&#22411;&#35780;&#20272;&#22871;&#20214;
&lt;/p&gt;
&lt;p&gt;
An Improved Traditional Chinese Evaluation Suite for Foundation Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01858
&lt;/p&gt;
&lt;p&gt;
TMMLU+&#26159;&#20256;&#32479;&#20013;&#25991;&#22823;&#35268;&#27169;&#22810;&#20219;&#21153;&#35821;&#35328;&#29702;&#35299;&#25968;&#25454;&#38598;&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#35268;&#27169;&#26159;&#21069;&#32773;&#30340;&#20845;&#20493;&#65292;&#21253;&#21547;66&#20010;&#22810;&#26679;&#21270;&#20027;&#39064;&#12290;&#30740;&#31350;&#26174;&#31034;&#20256;&#32479;&#20013;&#25991;&#27169;&#22411;&#20173;&#28982;&#33853;&#21518;&#20110;&#31616;&#20307;&#20013;&#25991;&#27169;&#22411;&#65292;&#24182;&#19988;&#30446;&#21069;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#24179;&#22343;&#24471;&#20998;&#19978;&#23578;&#26410;&#36229;&#36807;&#20154;&#31867;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;TMMLU+&#65292;&#36825;&#26159;&#19968;&#20010;&#20026;&#20256;&#32479;&#20013;&#25991;&#22823;&#35268;&#27169;&#22810;&#20219;&#21153;&#35821;&#35328;&#29702;&#35299;&#25968;&#25454;&#38598;&#35774;&#35745;&#30340;&#32508;&#21512;&#25968;&#25454;&#38598;&#12290; TMMLU+&#26159;&#19968;&#20010;&#21253;&#21547;66&#20010;&#20174;&#22522;&#30784;&#21040;&#19987;&#19994;&#27700;&#24179;&#30340;&#36873;&#25321;&#39064;&#31572;&#39064;&#25968;&#25454;&#38598;&#12290;&#19982;&#20854;&#21069;&#36523;TMMLU&#30456;&#27604;&#65292;TMMLU+&#30340;&#35268;&#27169;&#22823;&#20845;&#20493;&#65292;&#20027;&#39064;&#20998;&#24067;&#26356;&#21152;&#24179;&#34913;&#12290;&#25105;&#20204;&#22312;TMMLU+&#20013;&#21253;&#21547;&#20102;&#26469;&#33258;&#38381;&#28304;&#27169;&#22411;&#20197;&#21450;24&#20010;&#21442;&#25968;&#33539;&#22260;&#20174;1.8B&#21040;72B&#30340;&#24320;&#28304;&#20013;&#25991;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#20934;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#20256;&#32479;&#20013;&#25991;&#27169;&#22411;&#20173;&#28982;&#33853;&#21518;&#20110;&#31616;&#20307;&#20013;&#25991;&#23545;&#24212;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#30446;&#21069;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#24179;&#22343;&#20998;&#25968;&#19978;&#20173;&#26410;&#36229;&#36807;&#20154;&#31867;&#34920;&#29616;&#12290;&#25105;&#20204;&#20844;&#24320;&#21457;&#24067;&#20102;&#25968;&#25454;&#38598;&#21450;&#30456;&#24212;&#30340;&#22522;&#20934;&#28304;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01858v1 Announce Type: new  Abstract: We present TMMLU+, a comprehensive dataset designed for the Traditional Chinese massive multitask language understanding dataset. TMMLU+ is a multiple-choice question-answering dataset with 66 subjects from elementary to professional level. Compared to its predecessor, TMMLU, TMMLU+ is six times larger and boasts a more balanced subject distribution. We included benchmark results in TMMLU+ from closed-source models and 24 open-weight Chinese large language models of parameters ranging from 1.8B to 72B. Our findings reveal that Traditional Chinese models still trail behind their Simplified Chinese counterparts. Additionally, current large language models have yet to outperform human performance in average scores. We publicly release our dataset and the corresponding benchmark source code.
&lt;/p&gt;</description></item><item><title>&#36755;&#20837;&#38271;&#24230;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#65292;&#38477;&#32423;&#36235;&#21183;&#20986;&#29616;&#22312;&#27604;&#25216;&#26415;&#26368;&#22823;&#20540;&#30701;&#24471;&#22810;&#30340;&#36755;&#20837;&#38271;&#24230;&#19979;&#12290;</title><link>https://arxiv.org/abs/2402.14848</link><description>&lt;p&gt;
&#20219;&#21153;&#30456;&#21516;&#65292;&#20196;&#29260;&#26356;&#22810;&#65306;&#36755;&#20837;&#38271;&#24230;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#24615;&#33021;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14848
&lt;/p&gt;
&lt;p&gt;
&#36755;&#20837;&#38271;&#24230;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#65292;&#38477;&#32423;&#36235;&#21183;&#20986;&#29616;&#22312;&#27604;&#25216;&#26415;&#26368;&#22823;&#20540;&#30701;&#24471;&#22810;&#30340;&#36755;&#20837;&#38271;&#24230;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#25193;&#23637;&#36755;&#20837;&#38271;&#24230;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;&#23613;&#31649;LLMs&#22312;&#26368;&#36817;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#22312;&#19981;&#21516;&#36755;&#20837;&#38271;&#24230;&#19979;&#30340;&#24615;&#33021;&#19968;&#33268;&#24615;&#23578;&#19981;&#26126;&#30830;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#39062;&#30340;&#38382;&#31572;&#25512;&#29702;&#26694;&#26550;&#26469;&#30740;&#31350;&#27492;&#26041;&#38754;&#65292;&#35813;&#26694;&#26550;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;&#36755;&#20837;&#38271;&#24230;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#21516;&#19968;&#26679;&#26412;&#30340;&#22810;&#20010;&#29256;&#26412;&#65292;&#27599;&#20010;&#29256;&#26412;&#37117;&#36890;&#36807;&#19981;&#21516;&#38271;&#24230;&#12289;&#31867;&#22411;&#21644;&#20301;&#32622;&#30340;&#22635;&#20805;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#20174;&#32780;&#20998;&#31163;&#20102;&#36755;&#20837;&#38271;&#24230;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#27604;&#23427;&#20204;&#30340;&#25216;&#26415;&#26368;&#22823;&#20540;&#30701;&#24471;&#22810;&#30340;&#36755;&#20837;&#38271;&#24230;&#19979;&#65292;LLMs&#30340;&#25512;&#29702;&#24615;&#33021;&#26126;&#26174;&#38477;&#20302;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#38477;&#32423;&#36235;&#21183;&#20986;&#29616;&#22312;&#25105;&#20204;&#25968;&#25454;&#38598;&#30340;&#27599;&#20010;&#29256;&#26412;&#20013;&#65292;&#23613;&#31649;&#24378;&#24230;&#19981;&#21516;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20256;&#32479;&#30340;&#22256;&#24785;&#24230;&#24230;&#37327;&#19982;LLMs&#22312;&#38271;&#36755;&#20837;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#27809;&#26377;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#24182;&#35782;&#21035;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14848v1 Announce Type: cross  Abstract: This paper explores the impact of extending input lengths on the capabilities of Large Language Models (LLMs). Despite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood. We investigate this aspect by introducing a novel QA reasoning framework, specifically designed to assess the impact of input length. We isolate the effect of input length using multiple versions of the same sample, each being extended with padding of different lengths, types and locations. Our findings show a notable degradation in LLMs' reasoning performance at much shorter input lengths than their technical maximum. We show that the degradation trend appears in every version of our dataset, although at different intensities. Additionally, our study reveals that traditional perplexity metrics do not correlate with performance of LLMs' in long input reasoning tasks. We analyse our results and identif
&lt;/p&gt;</description></item><item><title>Agent Lumos&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#21644;&#27169;&#22359;&#21270;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35268;&#21010;&#27169;&#22359;&#23398;&#20064;&#39640;&#32423;&#23376;&#30446;&#26631;&#29983;&#25104;&#65292;&#35757;&#32451;&#25509;&#22320;&#27169;&#22359;&#23558;&#20854;&#36716;&#21270;&#20026;&#21160;&#20316;&#65292;&#20419;&#36827;&#24191;&#27867;&#20114;&#21160;&#20219;&#21153;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2311.05657</link><description>&lt;p&gt;
Agent Lumos: &#32479;&#19968;&#21644;&#27169;&#22359;&#21270;&#35757;&#32451;&#24320;&#28304;&#35821;&#35328;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Agent Lumos: Unified and Modular Training for Open-Source Language Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.05657
&lt;/p&gt;
&lt;p&gt;
Agent Lumos&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#21644;&#27169;&#22359;&#21270;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35268;&#21010;&#27169;&#22359;&#23398;&#20064;&#39640;&#32423;&#23376;&#30446;&#26631;&#29983;&#25104;&#65292;&#35757;&#32451;&#25509;&#22320;&#27169;&#22359;&#23558;&#20854;&#36716;&#21270;&#20026;&#21160;&#20316;&#65292;&#20419;&#36827;&#24191;&#27867;&#20114;&#21160;&#20219;&#21153;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38381;&#28304;&#20195;&#29702;&#23384;&#22312;&#35832;&#22810;&#38382;&#39064;&#65292;&#22914;&#32570;&#20047;&#36127;&#25285;&#24471;&#36215;&#24615;&#12289;&#36879;&#26126;&#24230;&#21644;&#21487;&#37325;&#22797;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#22797;&#26434;&#30340;&#20114;&#21160;&#20219;&#21153;&#20013;&#12290;&#36825;&#20419;&#20351;&#20102;&#24320;&#28304;&#26367;&#20195;&#26041;&#26696;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102; LUMOS&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20026;&#35757;&#32451;&#24320;&#28304; LLM-based &#20195;&#29702;&#32780;&#35774;&#35745;&#30340;&#26694;&#26550;&#20043;&#19968;&#12290;LUMOS&#20855;&#26377;&#21487;&#23398;&#20064;&#12289;&#32479;&#19968;&#21644;&#27169;&#22359;&#21270;&#30340;&#26550;&#26500;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#23398;&#20064;&#39640;&#32423;&#23376;&#30446;&#26631;&#29983;&#25104;&#30340;&#35268;&#21010;&#27169;&#22359;&#65292;&#20197;&#21450;&#19968;&#20010;&#35757;&#32451;&#26377;&#32032;&#30340;&#25509;&#22320;&#27169;&#22359;&#65292;&#29992;&#20110;&#20351;&#29992;&#25191;&#34892;&#27169;&#22359;&#20013;&#30340;&#21508;&#31181;&#24037;&#20855;&#23558;&#36825;&#20123;&#36716;&#21270;&#20026;&#21160;&#20316;&#12290;&#36825;&#31181;&#35774;&#35745;&#20801;&#35768;&#27169;&#22359;&#21270;&#21319;&#32423;&#65292;&#24182;&#26356;&#24191;&#27867;&#22320;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#20114;&#21160;&#20219;&#21153;&#12290;&#20026;&#20102;&#20419;&#36827;&#36890;&#29992;&#20195;&#29702;&#23398;&#20064;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#28304;&#33258;&#21508;&#31181;&#22797;&#26434;&#20114;&#21160;&#20219;&#21153;&#20013;&#19981;&#21516;&#22320;&#38754;&#30495;&#23454;&#25512;&#29702;&#21407;&#29702;&#30340;&#22823;&#35268;&#27169;&#12289;&#32479;&#19968;&#21644;&#39640;&#36136;&#37327;&#30340;&#35757;&#32451;&#27880;&#37322;&#12290;&#22312;9&#20010;&#25968;&#25454;&#38598;&#19978;&#65292;LUMOS&#34920;&#29616;&#20986;&#20102;&#20960;&#20010;&#20851;&#38190;&#20248;&#21183;&#65306;&#65288;1&#65289;LUMOS&#22312;&#22810;&#20010;&#36739;&#22823;&#30340;&#24320;&#28304;a
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.05657v2 Announce Type: replace  Abstract: Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce LUMOS, one of the first frameworks for training open-source LLM-based agents. LUMOS features a learnable, unified, and modular architecture with a planning module that learns high-level subgoal generation, and a grounding module trained to translate these into actions using various tools in the execution module. The design allows for modular upgrades and wider applicability to diverse interactive tasks. To foster generalizable agent learning, we collect large-scale, unified, and high-quality training annotations derived from diverse ground-truth reasoning rationales across various complex interactive tasks. On 9 datasets, LUMOS exhibits several key advantages: (1) LUMOS excels multiple larger open-source a
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27169;&#25311;&#32467;&#26500;&#36716;&#25442;&#22312;Seq2Seq&#27169;&#22411;&#20013;&#27880;&#20837;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#27867;&#21270;&#21644;FST&#31867;&#20284;&#20219;&#21153;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2310.00796</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#25311;&#23558;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#27880;&#20837;Seq2Seq&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.00796
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27169;&#25311;&#32467;&#26500;&#36716;&#25442;&#22312;Seq2Seq&#27169;&#22411;&#20013;&#27880;&#20837;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#27867;&#21270;&#21644;FST&#31867;&#20284;&#20219;&#21153;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#24046;&#26377;&#21161;&#20110;&#20174;&#23569;&#37327;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#24182;&#24110;&#21161;&#22312;&#35757;&#32451;&#20998;&#24067;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#12290;&#27969;&#34892;&#30340;&#31070;&#32463;&#26550;&#26500;&#22914;Transformers&#26412;&#36523;&#32570;&#20047;seq2seq NLP&#20219;&#21153;&#30340;&#24378;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#12290;&#22240;&#27492;&#65292;&#21363;&#20351;&#22312;&#22823;&#37327;&#25991;&#26412;&#19978;&#36827;&#34892;&#20102;&#39044;&#35757;&#32451;&#65292;&#23427;&#20204;&#20063;&#22312;&#31995;&#32479;&#27867;&#21270;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#65292;&#20363;&#22914;&#22312;&#22806;&#25512;&#21040;&#26356;&#38271;&#30340;&#36755;&#20837;&#26102;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#39044;&#35757;&#32451;&#26469;&#26377;&#25928;&#22320;&#23558;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#27880;&#20837;seq2seq&#27169;&#22411;&#65292;&#20197;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#27169;&#25311;&#32467;&#26500;&#36716;&#25442;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#39044;&#35757;&#32451;&#27169;&#25311;FST&#25551;&#36848;&#26469;&#23558;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#27880;&#20837;&#21040;Transformer&#20013;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#32473;&#20104;&#20102;&#25152;&#38656;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#31995;&#32479;&#27867;&#21270;&#33021;&#21147;&#21644;FST&#31867;&#20284;&#20219;&#21153;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26174;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.00796v2 Announce Type: replace  Abstract: Strong inductive biases enable learning from little data and help generalization outside of the training distribution. Popular neural architectures such as Transformers lack strong structural inductive biases for seq2seq NLP tasks on their own. Consequently, they struggle with systematic generalization beyond the training distribution, e.g. with extrapolating to longer inputs, even when pre-trained on large amounts of text. We show how a structural inductive bias can be efficiently injected into a seq2seq model by pre-training it to simulate structural transformations on synthetic data. Specifically, we inject an inductive bias towards Finite State Transducers (FSTs) into a Transformer by pre-training it to simulate FSTs given their descriptions. Our experiments show that our method imparts the desired inductive bias, resulting in improved systematic generalization and better few-shot learning for FST-like tasks. Our analysis shows t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20840;&#38754;&#25506;&#35752;&#20102;&#19982;&#35821;&#35328;&#23398;&#20064;&#27169;&#22411;&#65288;LLMs&#65289;&#38754;&#20020;&#30340;&#23433;&#20840;&#23041;&#32961;&#30456;&#20851;&#30340;&#20262;&#29702;&#25361;&#25112;&#12290;&#20998;&#26512;&#20102;&#20116;&#31181;&#20027;&#35201;&#23041;&#32961;&#30340;&#20262;&#29702;&#21518;&#26524;&#65292;&#24182;&#24378;&#35843;&#20102;&#30830;&#20445;&#36825;&#20123;&#31995;&#32479;&#22312;&#20262;&#29702;&#35268;&#33539;&#33539;&#22260;&#20869;&#36816;&#20316;&#30340;&#32039;&#36843;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12273</link><description>&lt;p&gt;
&#20132;&#20114;&#30340;&#20262;&#29702;&#38382;&#39064;&#65306;&#32531;&#35299;LLMs&#20013;&#30340;&#23433;&#20840;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
The Ethics of Interaction: Mitigating Security Threats in LLMs. (arXiv:2401.12273v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12273
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20840;&#38754;&#25506;&#35752;&#20102;&#19982;&#35821;&#35328;&#23398;&#20064;&#27169;&#22411;&#65288;LLMs&#65289;&#38754;&#20020;&#30340;&#23433;&#20840;&#23041;&#32961;&#30456;&#20851;&#30340;&#20262;&#29702;&#25361;&#25112;&#12290;&#20998;&#26512;&#20102;&#20116;&#31181;&#20027;&#35201;&#23041;&#32961;&#30340;&#20262;&#29702;&#21518;&#26524;&#65292;&#24182;&#24378;&#35843;&#20102;&#30830;&#20445;&#36825;&#20123;&#31995;&#32479;&#22312;&#20262;&#29702;&#35268;&#33539;&#33539;&#22260;&#20869;&#36816;&#20316;&#30340;&#32039;&#36843;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#25506;&#35752;&#20102;&#19982;&#35821;&#35328;&#23398;&#20064;&#27169;&#22411;&#65288;LLMs&#65289;&#38754;&#20020;&#30340;&#23433;&#20840;&#23041;&#32961;&#30456;&#20851;&#30340;&#20262;&#29702;&#25361;&#25112;&#12290;&#36825;&#20123;&#22797;&#26434;&#30340;&#25968;&#23383;&#23384;&#20648;&#24211;&#26085;&#30410;&#34701;&#20837;&#21040;&#25105;&#20204;&#30340;&#26085;&#24120;&#29983;&#27963;&#20013;&#65292;&#22240;&#27492;&#25104;&#20026;&#25915;&#20987;&#30340;&#20027;&#35201;&#30446;&#26631;&#65292;&#21487;&#33021;&#21361;&#21450;&#20854;&#35757;&#32451;&#25968;&#25454;&#21644;&#25968;&#25454;&#28304;&#30340;&#26426;&#23494;&#24615;&#12290;&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#36825;&#20123;&#23433;&#20840;&#23041;&#32961;&#23545;&#31038;&#20250;&#21644;&#20010;&#20154;&#38544;&#31169;&#30340;&#24494;&#22937;&#20262;&#29702;&#24433;&#21709;&#12290;&#25105;&#20204;&#23545;&#20116;&#20010;&#20027;&#35201;&#23041;&#32961;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65306;&#25552;&#31034;&#27880;&#20837;&#12289;&#36234;&#29425;&#12289;&#20010;&#20154;&#21487;&#35782;&#21035;&#20449;&#24687;&#65288;PII&#65289;&#26333;&#38706;&#12289;&#24615;&#21035;&#26174;&#38706;&#20869;&#23481;&#21644;&#22522;&#20110;&#20167;&#24680;&#30340;&#20869;&#23481;&#12290;&#25105;&#20204;&#19981;&#20165;&#20165;&#36827;&#34892;&#20102;&#35782;&#21035;&#65292;&#36824;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#20851;&#38190;&#20262;&#29702;&#21518;&#26524;&#20197;&#21450;&#23545;&#24378;&#21270;&#38450;&#24481;&#31574;&#30053;&#30340;&#32039;&#36843;&#24615;&#12290;&#23545;LLMs&#30340;&#19981;&#26029;&#20381;&#36182;&#20984;&#26174;&#20102;&#30830;&#20445;&#36825;&#20123;&#31995;&#32479;&#22312;&#20262;&#29702;&#35268;&#33539;&#33539;&#22260;&#20869;&#36816;&#20316;&#30340;&#37325;&#35201;&#24615;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#23427;&#20204;&#30340;&#28389;&#29992;&#21487;&#33021;&#23548;&#33268;&#37325;&#22823;&#31038;&#20250;&#21644;&#20010;&#20154;&#20260;&#23475;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23558;&#36825;&#20123;&#31995;&#32479;&#27010;&#24565;&#21270;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper comprehensively explores the ethical challenges arising from security threats to Language Learning Models (LLMs). These intricate digital repositories are increasingly integrated into our daily lives, making them prime targets for attacks that can compromise their training data and the confidentiality of their data sources. The paper delves into the nuanced ethical repercussions of such security threats on society and individual privacy. We scrutinize five major threats: prompt injection, jailbreaking, Personal Identifiable Information (PII) exposure, sexually explicit content, and hate based content, going beyond mere identification to assess their critical ethical consequences and the urgency they create for robust defensive strategies. The escalating reliance on LLMs underscores the crucial need for ensuring these systems operate within the bounds of ethical norms, particularly as their misuse can lead to significant societal and individual harm. We propose conceptualizin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#19981;&#24895;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#23548;&#33268;&#39640;&#38169;&#35823;&#29575;&#12290;&#23454;&#39564;&#36824;&#34920;&#26126;&#29992;&#25143;&#26080;&#35770;&#26159;&#21542;&#26631;&#35760;&#20102;&#30830;&#23450;&#24615;&#37117;&#20250;&#20005;&#37325;&#20381;&#36182;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.06730</link><description>&lt;p&gt;
&#19981;&#21487;&#38752;&#30340;&#20381;&#36182;&#65306;&#35821;&#35328;&#27169;&#22411;&#19981;&#24895;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty. (arXiv:2401.06730v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06730
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#19981;&#24895;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#23548;&#33268;&#39640;&#38169;&#35823;&#29575;&#12290;&#23454;&#39564;&#36824;&#34920;&#26126;&#29992;&#25143;&#26080;&#35770;&#26159;&#21542;&#26631;&#35760;&#20102;&#30830;&#23450;&#24615;&#37117;&#20250;&#20005;&#37325;&#20381;&#36182;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#20132;&#20114;&#30340;&#40664;&#35748;&#25509;&#21475;&#65292;&#35821;&#35328;&#27169;&#22411;&#36866;&#24403;&#22320;&#20256;&#36798;&#19979;&#28216;&#24212;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#23545;&#20854;&#22238;&#31572;&#30340;&#32622;&#20449;&#24230;&#65292;&#20197;&#21450;&#19979;&#28216;&#29992;&#25143;&#23545;&#35821;&#35328;&#27169;&#22411;&#34920;&#36798;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#21453;&#24212;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#20844;&#24320;&#37096;&#32626;&#30340;&#27169;&#22411;&#65292;&#21457;&#29616;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#65292;&#21363;&#20351;&#20135;&#29983;&#20102;&#38169;&#35823;&#31572;&#26696;&#65292;&#35821;&#35328;&#27169;&#22411;&#20063;&#26080;&#27861;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#12290;&#34429;&#28982;&#21487;&#20197;&#26126;&#30830;&#35201;&#27714;&#35821;&#35328;&#27169;&#22411;&#34920;&#36798;&#32622;&#20449;&#24230;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#23548;&#33268;&#22312;&#32622;&#20449;&#30340;&#22238;&#31572;&#20013;&#38169;&#35823;&#29575;&#39640;&#36798;&#24179;&#22343;47%&#12290;&#25105;&#20204;&#36890;&#36807;&#20154;&#31867;&#23454;&#39564;&#27979;&#35797;&#20102;&#35821;&#35328;&#27169;&#22411;&#36807;&#24230;&#33258;&#20449;&#30340;&#39118;&#38505;&#65292;&#24182;&#35777;&#26126;&#29992;&#25143;&#26080;&#35770;&#26159;&#21542;&#26631;&#35760;&#20102;&#30830;&#23450;&#24615;&#37117;&#20250;&#20005;&#37325;&#20381;&#36182;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;RLHF&#23545;&#40784;&#20013;&#20351;&#29992;&#30340;&#20559;&#22909;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#24182;&#21457;&#29616;&#20154;&#31867;&#23545;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25991;&#26412;&#26377;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#31361;&#20986;&#20102;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
As natural language becomes the default interface for human-AI interaction, there is a critical need for LMs to appropriately communicate uncertainties in downstream applications. In this work, we investigate how LMs incorporate confidence about their responses via natural language and how downstream users behave in response to LM-articulated uncertainties. We examine publicly deployed models and find that LMs are unable to express uncertainties when answering questions even when they produce incorrect responses. LMs can be explicitly prompted to express confidences, but tend to be overconfident, resulting in high error rates (on average 47%) among confident responses. We test the risks of LM overconfidence by running human experiments and show that users rely heavily on LM generations, whether or not they are marked by certainty. Lastly, we investigate the preference-annotated datasets used in RLHF alignment and find that humans have a bias against texts with uncertainty. Our work hig
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#24212;&#23545;&#30740;&#31350;&#27700;&#24179;&#30340;&#25968;&#23398;&#33258;&#21160;&#24418;&#24335;&#21270;&#20219;&#21153;&#65292;&#36890;&#36807;&#23558;&#20219;&#21153;&#20998;&#35299;&#25104;&#26356;&#23481;&#26131;&#22788;&#29702;&#30340;&#23376;&#20219;&#21153;&#65292;&#21253;&#25324;&#26410;&#38142;&#25509;&#24418;&#24335;&#21270;&#12289;&#23454;&#20307;&#38142;&#25509;&#21644;&#31867;&#22411;&#35843;&#25972;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#26410;&#38142;&#25509;&#24418;&#24335;&#21270;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598; arXiv2Formal&#12290;</title><link>http://arxiv.org/abs/2310.07957</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#30340;&#33258;&#21160;&#24418;&#24335;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A New Approach Towards Autoformalization. (arXiv:2310.07957v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07957
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#24212;&#23545;&#30740;&#31350;&#27700;&#24179;&#30340;&#25968;&#23398;&#33258;&#21160;&#24418;&#24335;&#21270;&#20219;&#21153;&#65292;&#36890;&#36807;&#23558;&#20219;&#21153;&#20998;&#35299;&#25104;&#26356;&#23481;&#26131;&#22788;&#29702;&#30340;&#23376;&#20219;&#21153;&#65292;&#21253;&#25324;&#26410;&#38142;&#25509;&#24418;&#24335;&#21270;&#12289;&#23454;&#20307;&#38142;&#25509;&#21644;&#31867;&#22411;&#35843;&#25972;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#26410;&#38142;&#25509;&#24418;&#24335;&#21270;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598; arXiv2Formal&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39564;&#35777;&#25968;&#23398;&#35777;&#26126;&#26159;&#22256;&#38590;&#30340;&#65292;&#20294;&#21487;&#20197;&#36890;&#36807;&#35745;&#31639;&#26426;&#30340;&#36741;&#21161;&#23454;&#29616;&#33258;&#21160;&#21270;&#12290;&#33258;&#21160;&#24418;&#24335;&#21270;&#26159;&#23558;&#33258;&#28982;&#35821;&#35328;&#25968;&#23398;&#33258;&#21160;&#36716;&#21270;&#20026;&#21487;&#20197;&#30001;&#31243;&#24207;&#39564;&#35777;&#30340;&#24418;&#24335;&#35821;&#35328;&#30340;&#20219;&#21153;&#12290;&#36825;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#23588;&#20854;&#23545;&#20110;&#30740;&#31350;&#35770;&#25991;&#20013;&#30340;&#39640;&#32423;&#25968;&#23398;&#26469;&#35828;&#12290;&#30740;&#31350;&#35770;&#25991;&#20013;&#30340;&#25968;&#23398;&#38656;&#35201;&#22823;&#37327;&#30340;&#32972;&#26223;&#21644;&#19978;&#19979;&#25991;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#23545;&#30740;&#31350;&#27700;&#24179;&#25968;&#23398;&#33258;&#21160;&#24418;&#24335;&#21270;&#30340;&#26041;&#27861;&#65292;&#23558;&#20219;&#21153;&#20998;&#35299;&#20026;&#26356;&#26131;&#20110;&#22788;&#29702;&#30340;&#23376;&#20219;&#21153;&#65306;&#26410;&#38142;&#25509;&#24418;&#24335;&#21270;&#65288;&#21253;&#21547;&#26410;&#38142;&#25509;&#30340;&#23450;&#20041;&#21644;&#23450;&#29702;&#30340;&#24418;&#24335;&#21270;&#65289;&#12289;&#23454;&#20307;&#38142;&#25509;&#65288;&#38142;&#25509;&#21040;&#27491;&#30830;&#30340;&#23450;&#29702;&#21644;&#23450;&#20041;&#65289;&#20197;&#21450;&#35843;&#25972;&#31867;&#22411;&#20197;&#36890;&#36807;&#31867;&#22411;&#26816;&#26597;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;arXiv2Formal&#65292;&#19968;&#20010;&#29992;&#20110;&#26410;&#38142;&#25509;&#24418;&#24335;&#21270;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#20174;arXiv.org&#30340;&#35770;&#25991;&#20013;&#25277;&#21462;&#30340;50&#20010;&#23450;&#29702;&#22312;Lean&#23450;&#29702;&#35777;&#26126;&#22120;&#20013;&#36827;&#34892;&#24418;&#24335;&#21270;&#12290;&#25105;&#20204;&#27426;&#36814;&#20219;&#20309;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Verifying mathematical proofs is difficult, but can be automated with the assistance of a computer. Autoformalization is the task of automatically translating natural language mathematics into a formal language that can be verified by a program. This is a challenging task, and especially for higher-level mathematics found in research papers. Research paper mathematics requires large amounts of background and context. In this paper, we propose an avenue towards tackling autoformalization for research-level mathematics, by breaking the task into easier and more approachable subtasks: unlinked formalization (formalization with unlinked definitions and theorems), entity linking (linking to the proper theorems and definitions), and finally adjusting types so it passes the type checker. In addition, we present arXiv2Formal, a benchmark dataset for unlinked formalization consisting of 50 theorems formalized for the Lean theorem prover sampled from papers on arXiv.org. We welcome any contribut
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23545;&#20302;&#36164;&#28304;&#38405;&#35835;&#29702;&#35299;&#25968;&#25454;&#38598;&#36827;&#34892;&#22686;&#24378;&#30340;&#21487;&#33021;&#24615;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;GPT-4&#21487;&#20197;&#29992;&#20316;&#20302;&#36164;&#28304;&#35835;&#35299;&#20219;&#21153;&#20013;&#20154;&#24037;&#27880;&#37322;&#32773;&#30340;&#26367;&#20195;&#21697;&#12290;&#36825;&#39033;&#24037;&#20316;&#31361;&#20986;&#20102;LLMs&#20316;&#20026;&#21512;&#25104;&#25968;&#25454;&#22686;&#24378;&#22120;&#30340;&#26426;&#36935;&#21644;&#25361;&#25112;&#65292;&#24182;&#21457;&#24067;&#20102;&#22686;&#24378;&#29256;&#26412;&#30340;&#20302;&#36164;&#28304;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2309.12426</link><description>&lt;p&gt;
LLMs&#33021;&#22686;&#24378;&#20302;&#36164;&#28304;&#38405;&#35835;&#29702;&#35299;&#25968;&#25454;&#38598;&#21527;&#65311;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges. (arXiv:2309.12426v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23545;&#20302;&#36164;&#28304;&#38405;&#35835;&#29702;&#35299;&#25968;&#25454;&#38598;&#36827;&#34892;&#22686;&#24378;&#30340;&#21487;&#33021;&#24615;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;GPT-4&#21487;&#20197;&#29992;&#20316;&#20302;&#36164;&#28304;&#35835;&#35299;&#20219;&#21153;&#20013;&#20154;&#24037;&#27880;&#37322;&#32773;&#30340;&#26367;&#20195;&#21697;&#12290;&#36825;&#39033;&#24037;&#20316;&#31361;&#20986;&#20102;LLMs&#20316;&#20026;&#21512;&#25104;&#25968;&#25454;&#22686;&#24378;&#22120;&#30340;&#26426;&#36935;&#21644;&#25361;&#25112;&#65292;&#24182;&#21457;&#24067;&#20102;&#22686;&#24378;&#29256;&#26412;&#30340;&#20302;&#36164;&#28304;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#24191;&#27867;&#30340;NLP&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#38646;-shot&#24615;&#33021;&#65292;&#33021;&#22815;&#36827;&#34892;&#25512;&#29702;&#21644;&#24212;&#29992;&#24120;&#35782;&#12290;&#19968;&#20010;&#30456;&#20851;&#30340;&#24212;&#29992;&#26159;&#23558;&#23427;&#20204;&#29992;&#20110;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#20197;&#20379;&#21518;&#32493;&#20219;&#21153;&#20351;&#29992;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#26159;&#21542;&#33021;&#22815;&#20351;&#29992;GPT-4&#26469;&#22686;&#24378;&#29616;&#26377;&#30340;&#25277;&#21462;&#24335;&#38405;&#35835;&#29702;&#35299;&#25968;&#25454;&#38598;&#12290;&#33258;&#21160;&#21270;&#30340;&#25968;&#25454;&#27880;&#37322;&#36807;&#31243;&#26377;&#28508;&#21147;&#33410;&#30465;&#22823;&#37327;&#26102;&#38388;&#12289;&#37329;&#38065;&#21644;&#31934;&#21147;&#65292;&#36825;&#20123;&#37117;&#26159;&#29992;&#20110;&#25163;&#21160;&#26631;&#27880;&#25968;&#25454;&#38598;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#24494;&#35843;&#21518;&#30340;&#24615;&#33021;&#20197;&#21450;&#27880;&#37322;&#30340;&#25104;&#26412;&#65292;&#35780;&#20272;&#20102;GPT-4&#20316;&#20026;&#20302;&#36164;&#28304;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#20154;&#24037;&#27880;&#37322;&#26367;&#20195;&#32773;&#30340;&#24615;&#33021;&#12290;&#36825;&#39033;&#24037;&#20316;&#26159;&#23545;LLMs&#20316;&#20026;QA&#31995;&#32479;&#21512;&#25104;&#25968;&#25454;&#22686;&#24378;&#22120;&#30340;&#39318;&#27425;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;&#29420;&#29305;&#30340;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#20302;&#36164;&#28304;&#25968;&#25454;&#38598;&#30340;&#22686;&#24378;&#29256;&#26412;&#65292;&#36825;&#23558;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#37325;&#26032;&#35780;&#20272;LLMs&#22312;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated impressive zero shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply commonsense. A relevant application is to use them for creating high quality synthetic datasets for downstream tasks. In this work, we probe whether GPT-4 can be used to augment existing extractive reading comprehension datasets. Automating data annotation processes has the potential to save large amounts of time, money and effort that goes into manually labelling datasets. In this paper, we evaluate the performance of GPT-4 as a replacement for human annotators for low resource reading comprehension tasks, by comparing performance after fine tuning, and the cost associated with annotation. This work serves to be the first analysis of LLMs as synthetic data augmenters for QA systems, highlighting the unique opportunities and challenges. Additionally, we release augmented versions of low resource datasets, that will allow the researc
&lt;/p&gt;</description></item><item><title>CIDER&#26159;&#19968;&#31181;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#30701;&#25991;&#26412;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#25972;&#20010;&#35821;&#26009;&#24211;&#20013;&#25512;&#26029;&#20986;&#24773;&#24863;&#35789;&#30340;&#20542;&#21521;&#26469;&#35780;&#20998;&#20010;&#21035;&#25991;&#26412;&#65292;&#30456;&#27604;&#36890;&#29992;&#26041;&#27861;&#22312;&#22825;&#27668;&#25512;&#25991;&#38598;&#21512;&#19978;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2307.07864</link><description>&lt;p&gt;
CIDER: &#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#30701;&#25991;&#26412;&#24773;&#24863;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
CIDER: Context sensitive sentiment analysis for short-form text. (arXiv:2307.07864v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07864
&lt;/p&gt;
&lt;p&gt;
CIDER&#26159;&#19968;&#31181;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#30701;&#25991;&#26412;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#25972;&#20010;&#35821;&#26009;&#24211;&#20013;&#25512;&#26029;&#20986;&#24773;&#24863;&#35789;&#30340;&#20542;&#21521;&#26469;&#35780;&#20998;&#20010;&#21035;&#25991;&#26412;&#65292;&#30456;&#27604;&#36890;&#29992;&#26041;&#27861;&#22312;&#22825;&#27668;&#25512;&#25991;&#38598;&#21512;&#19978;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#23545;&#22823;&#37327;&#20851;&#20110;&#29305;&#23450;&#20027;&#39064;&#12289;&#20027;&#39064;&#25110;&#20107;&#20214;&#30340;&#30701;&#25991;&#26412;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#65292;&#22914;&#25512;&#25991;&#12289;Reddit&#24086;&#23376;&#25110;&#25253;&#32440;&#22836;&#26465;&#12290;&#36890;&#24120;&#20351;&#29992;&#36890;&#29992;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#24179;&#22343;&#24847;&#20041;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20250;&#24573;&#30053;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#21457;&#29983;&#30340;&#24847;&#20041;&#21464;&#21270;&#65292;&#20363;&#22914;&#65292;&#8220;active&#8221;&#19968;&#35789;&#22312;&#8220;active lifestyle&#8221;&#21644;&#8220;active volcano&#8221;&#20013;&#20855;&#26377;&#38750;&#24120;&#19981;&#21516;&#30340;&#24847;&#22270;&#21644;&#20542;&#21521;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;CIDER&#65288;&#19978;&#19979;&#25991;&#24863;&#30693;&#35789;&#20856;&#21644;&#24773;&#24863;&#25512;&#29702;&#22120;&#65289;&#65292;&#23427;&#36827;&#34892;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#24773;&#24863;&#20998;&#26512;&#65292;&#20854;&#20013;&#20174;&#25972;&#20010;&#35821;&#26009;&#24211;&#20013;&#25512;&#26029;&#20986;&#24773;&#24863;&#35789;&#30340;&#20542;&#21521;&#65292;&#28982;&#21518;&#20877;&#29992;&#20110;&#35780;&#20998;&#20010;&#21035;&#25991;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;CIDER&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#23427;&#22312;&#22823;&#37327;&#20851;&#20110;&#22825;&#27668;&#30340;&#25512;&#25991;&#38598;&#21512;&#19978;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#36890;&#29992;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#12290;&#25105;&#20204;&#24050;&#23558;CIDER&#30340;&#23454;&#29616;&#20197;python&#20195;&#30721;&#30340;&#24418;&#24335;&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
Researchers commonly perform sentiment analysis on large collections of short texts like tweets, Reddit posts or newspaper headlines that are all focused on a specific topic, theme or event. Usually, general purpose sentiment analysis methods are used which perform well on average but miss the variation in meaning that happens across different contexts, for example, the word "active" has a very different intention and valence in the phrase "active lifestyle" versus "active volcano". This work presents a new approach, CIDER (Context Informed Dictionary and sEntiment Reasoner), which performs context sensitive sentiment analysis, where the valence of sentiment laden terms is inferred from the whole corpus before being used to score the individual texts. In this paper we detail the CIDER algorithm and demonstrate that it outperforms state-of-the-art generalist sentiment analysis on a large collection of tweets about the weather. We have made our implementation of CIDER available as a pyth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#26469;&#35843;&#25972;&#26631;&#27880;&#32773;&#20043;&#38388;&#23384;&#22312;&#30340;&#23610;&#24230;&#19981;&#19968;&#33268;&#65292;&#35299;&#20915;&#20102;&#20027;&#35266;NLP&#20219;&#21153;&#20013;&#26631;&#27880;&#32773;&#20043;&#38388;&#20998;&#27495;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.14770</link><description>&lt;p&gt;
&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#37325;&#26032;&#35843;&#25972;&#20154;&#31867;&#35780;&#20215;
&lt;/p&gt;
&lt;p&gt;
Using Natural Language Explanations to Rescale Human Judgments. (arXiv:2305.14770v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#26469;&#35843;&#25972;&#26631;&#27880;&#32773;&#20043;&#38388;&#23384;&#22312;&#30340;&#23610;&#24230;&#19981;&#19968;&#33268;&#65292;&#35299;&#20915;&#20102;&#20027;&#35266;NLP&#20219;&#21153;&#20013;&#26631;&#27880;&#32773;&#20043;&#38388;&#20998;&#27495;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20986;&#29616;&#24102;&#26469;&#20102;&#38656;&#35201;&#39640;&#36136;&#37327;&#20154;&#26631;&#35760;&#25968;&#25454;&#30340;&#32039;&#36843;&#38656;&#27714;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20154;&#30340;&#21453;&#39304;&#21644;&#35780;&#20272;&#31561;&#36807;&#31243;&#12290;&#19968;&#31181;&#24120;&#35265;&#30340;&#20570;&#27861;&#26159;&#36890;&#36807;&#22810;&#20010;&#20247;&#21253;&#24037;&#20316;&#32773;&#30340;&#20849;&#35782;&#26469;&#26631;&#27880;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#30340;&#26631;&#27880;&#32773;&#21487;&#33021;&#23545;&#26631;&#27880;&#26041;&#26696;&#26377;&#19981;&#21516;&#30340;&#35299;&#37322;&#65292;&#38500;&#38750;&#25509;&#21463;&#20102;&#24191;&#27867;&#30340;&#22521;&#35757;&#65292;&#21542;&#21017;&#23545;&#20110;&#20027;&#35266;&#30340;NLP&#20219;&#21153;&#65292;&#29978;&#33267;&#21463;&#36807;&#35757;&#32451;&#30340;&#19987;&#23478;&#26631;&#27880;&#32773;&#20063;&#21487;&#33021;&#20250;&#20986;&#29616;&#24040;&#22823;&#30340;&#20998;&#27495;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#32454;&#24494;&#24046;&#21035;&#21487;&#20197;&#36890;&#36807;&#39640;&#36136;&#37327;&#30340;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#36827;&#34892;&#25429;&#25417;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;LLM&#22312;&#23384;&#22312;&#20998;&#27495;&#26102;&#37325;&#26032;&#35843;&#25972;&#22823;&#23567;&#25490;&#24207;&#27880;&#37322;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;Likert&#35780;&#20998;&#21644;&#30456;&#24212;&#30340;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#36755;&#20837;LLM&#65292;&#24182;&#25552;&#31034;&#23427;&#20135;&#29983;&#19968;&#20010;&#25968;&#23383;&#24471;&#20998;&#12290;&#36825;&#20010;&#24471;&#20998;&#24212;&#35813;&#21453;&#26144;&#27880;&#37322;&#32773;&#23545;&#31034;&#20363;&#30340;&#22522;&#26412;&#35780;&#20272;&#12290;&#35299;&#37322;&#30340;&#23384;&#22312;&#20351;LLM&#33021;&#22815;&#22312;&#23610;&#24230;&#20351;&#29992;&#24046;&#24322;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20351;&#35780;&#32423;&#22312;&#26631;&#27880;&#32773;&#20043;&#38388;&#21516;&#36136;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rise of large language models (LLMs) has brought a critical need for high-quality human-labeled data, particularly for processes like human feedback and evaluation. A common practice is to label data via consensus annotation over the judgments of multiple crowdworkers. However, different annotators may have different interpretations of labeling schemes unless given extensive training, and for subjective NLP tasks, even trained expert annotators can diverge heavily. We show that these nuances can be captured by high quality natural language explanations, and propose a method to rescale ordinal annotation in the presence of disagreement using LLMs. Specifically, we feed Likert ratings and corresponding natural language explanations into an LLM and prompt it to produce a numeric score. This score should reflect the underlying assessment of the example by the annotator. The presence of explanations allows the LLM to homogenize ratings across annotators in spite of scale usage differenc
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#36890;&#36807;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#28155;&#21152;&#23383;&#20856;&#38142;&#25552;&#31034;&#30340;&#26041;&#27861;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#32763;&#35793;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#33021;&#26174;&#33879;&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.06575</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23383;&#20856;&#38142;&#25552;&#31034;&#22312;&#32763;&#35793;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Chain-of-Dictionary Prompting Elicits Translation in Large Language Models. (arXiv:2305.06575v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06575
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#36890;&#36807;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#28155;&#21152;&#23383;&#20856;&#38142;&#25552;&#31034;&#30340;&#26041;&#27861;&#26469;&#25913;&#36827;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#32763;&#35793;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#33021;&#26174;&#33879;&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22810;&#35821;&#35328;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;(MNMT)&#20013;&#34920;&#29616;&#20986;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#21363;&#20351;&#27809;&#26377;&#24179;&#34892;&#25968;&#25454;&#20063;&#33021;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35757;&#32451;&#25968;&#25454;&#37327;&#24040;&#22823;&#65292;&#23427;&#20204;&#20173;&#28982;&#38590;&#20197;&#32763;&#35793;&#31232;&#26377;&#35789;&#27719;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20302;&#36164;&#28304;&#35821;&#35328;&#12290;&#26356;&#31967;&#31957;&#30340;&#26159;&#65292;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#19978;&#65292;&#24456;&#38590;&#26816;&#32034;&#21040;&#30456;&#20851;&#31034;&#33539;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#36825;&#38480;&#21046;&#20102;LLMs&#22312;&#32763;&#35793;&#26041;&#38754;&#30340;&#23454;&#38469;&#24212;&#29992;&#8212;&#8212;&#25105;&#20204;&#35813;&#22914;&#20309;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65311;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;CoD&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#35821;&#35328;&#23383;&#20856;&#38142;&#20026;&#19968;&#37096;&#20998;&#36755;&#20837;&#21333;&#35789;&#22686;&#21152;LLMs&#30340;&#20808;&#21069;&#30693;&#35782;&#65292;&#20174;&#32780;&#20419;&#36827;LLMs&#30340;&#32763;&#35793;&#33021;&#21147;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;FLORES-200&#20840;&#24320;&#21457;&#27979;&#35797;&#38598;&#19978;&#65292;&#36890;&#36807;&#23558;CoD&#21644;ChatGPT&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#33719;&#24471;&#39640;&#36798;13&#20493;&#30340;MNMT ChrF++&#20998;&#25968;&#30340;&#25910;&#30410;&#65288;&#33521;&#35821;&#21040;&#22622;&#23572;&#32500;&#20122;&#35821;&#65292;&#35199;&#37324;&#23572;&#23383;&#27597;&#20070;&#20889;&#65292;ChrF ++&#20998;&#25968;&#20174;3.08&#22686;&#21152;&#21040;42.63&#65289;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20854;&#20182;&#25968;&#25454;&#38598;&#19978;&#30340;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown surprisingly good performance in multilingual neural machine translation (MNMT) even when trained without parallel data. Yet, despite the fact that the amount of training data is gigantic, they still struggle with translating rare words, particularly for low-resource languages. Even worse, it is usually unrealistic to retrieve relevant demonstrations for in-context learning with low-resource languages on LLMs, which restricts the practical use of LLMs for translation -- how should we mitigate this problem? To this end, we present a novel method, CoD, which augments LLMs with prior knowledge with the chains of multilingual dictionaries for a subset of input words to elicit translation abilities for LLMs. Extensive experiments indicate that augmenting ChatGPT with CoD elicits large gains by up to 13x ChrF++ points for MNMT (3.08 to 42.63 for English to Serbian written in Cyrillic script) on FLORES-200 full devtest set. We further demonstrate the im
&lt;/p&gt;</description></item></channel></rss>