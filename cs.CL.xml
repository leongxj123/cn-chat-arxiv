<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#24341;&#20837;SCEN&#26041;&#27861;&#65292;&#20351;&#29992;&#23450;&#21046;&#30340;&#19987;&#23478;&#32593;&#32476;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#27169;&#22411;&#32534;&#36753;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#21644;&#36807;&#26102;&#30693;&#35782;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#23454;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2404.02699</link><description>&lt;p&gt;
&#36890;&#36807;&#23450;&#21046;&#21270;&#19987;&#23478;&#32593;&#32476;&#23454;&#29616;&#21487;&#25193;&#23637;&#30340;&#27169;&#22411;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Scalable Model Editing via Customized Expert Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02699
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;SCEN&#26041;&#27861;&#65292;&#20351;&#29992;&#23450;&#21046;&#30340;&#19987;&#23478;&#32593;&#32476;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#27169;&#22411;&#32534;&#36753;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#21644;&#36807;&#26102;&#30693;&#35782;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#23454;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23384;&#22312;&#24187;&#35273;&#21644;&#36807;&#26102;&#30693;&#35782;&#30340;&#38382;&#39064;&#23545;&#20110;&#20854;&#21487;&#38752;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#27169;&#22411;&#32534;&#36753;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#36884;&#24452;&#65292;&#21487;&#20197;&#20197;&#25104;&#26412;&#25928;&#30410;&#30340;&#26041;&#24335;&#20943;&#36731;&#36825;&#20123;&#25361;&#25112;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#32463;&#24120;&#21463;&#21040;&#19981;&#20196;&#20154;&#28385;&#24847;&#30340;&#27867;&#21270;&#21644;&#23545;&#19981;&#30456;&#20851;&#26679;&#26412;&#30340;&#24847;&#22806;&#24433;&#21709;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65306;&#36890;&#36807;&#23450;&#21046;&#21270;&#19987;&#23478;&#32593;&#32476;&#23454;&#29616;&#21487;&#25193;&#23637;&#30340;&#27169;&#22411;&#32534;&#36753;&#65288;SCEN&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26377;&#20004;&#20010;&#38454;&#27573;&#30340;&#36830;&#32493;&#35757;&#32451;&#33539;&#24335;&#12290;&#20855;&#20307;&#22320;&#65292;&#22312;&#31532;&#19968;&#20010;&#38454;&#27573;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#38656;&#35201;&#26356;&#26032;&#30340;&#30693;&#35782;&#29255;&#27573;&#21333;&#29420;&#35757;&#32451;&#36731;&#37327;&#32423;&#19987;&#23478;&#32593;&#32476;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#35757;&#32451;&#27599;&#20010;&#19987;&#23478;&#23545;&#24212;&#30340;&#31070;&#32463;&#20803;&#26469;&#25511;&#21046;&#35813;&#19987;&#23478;&#30340;&#28608;&#27963;&#29366;&#24577;&#12290;&#25105;&#20204;&#22312;&#20004;&#31181;&#19981;&#21516;&#35268;&#27169;&#30340;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;Llama2 7B &#21644; 13B &#19978;&#30340;&#23454;&#39564;&#35777;&#23454;&#65292;&#30456;&#27604;&#29616;&#26377;&#20027;&#27969;&#30340;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02699v1 Announce Type: new  Abstract: Addressing the issue of hallucinations and outdated knowledge in large language models is critical for their reliable application. Model Editing presents a promising avenue for mitigating these challenges in a cost-effective manner. However, existing methods often suffer from unsatisfactory generalization and unintended effects on unrelated samples. To overcome these limitations, we introduce a novel approach: Scalable Model Editing via Customized Expert Networks (SCEN), which is a two-stage continuous training paradigm. Specifically, in the first stage, we train lightweight expert networks individually for each piece of knowledge that needs to be updated. Subsequently, we train a corresponding neuron for each expert to control the activation state of that expert. Our experiments on two different sizes of open-source large language models, the Llama2 7B and 13B, achieve state-of-the-art results compared to existing mainstream Model Editi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29983;&#25104;&#21463;&#25968;&#23383;&#20998;&#24067;&#35268;&#24459;&#25511;&#21046;&#30340;&#38170;&#28857;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;&#35821;&#20041;&#19978;&#24341;&#23548;&#25968;&#23383;&#30340;&#31574;&#30053;&#65292;&#22312;&#24191;&#27867;&#33539;&#22260;&#30340;&#25968;&#23383;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#25968;&#23398;&#22522;&#30784;&#34920;&#31034;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2404.01536</link><description>&lt;p&gt;
&#25918;&#32622;&#38170;&#28857;&#65306;&#22312;&#35821;&#35328;&#24314;&#27169;&#20013;&#32473;&#25968;&#23383;&#35821;&#20041;&#19978;&#30340;&#24341;&#23548;
&lt;/p&gt;
&lt;p&gt;
Laying Anchors: Semantically Priming Numerals in Language Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01536
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29983;&#25104;&#21463;&#25968;&#23383;&#20998;&#24067;&#35268;&#24459;&#25511;&#21046;&#30340;&#38170;&#28857;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;&#35821;&#20041;&#19978;&#24341;&#23548;&#25968;&#23383;&#30340;&#31574;&#30053;&#65292;&#22312;&#24191;&#27867;&#33539;&#22260;&#30340;&#25968;&#23383;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#25968;&#23398;&#22522;&#30784;&#34920;&#31034;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#22823;&#37327;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31649;&#32447;&#20013;&#30340;&#20107;&#23454;&#26631;&#20934;&#65292;&#28982;&#32780;&#36825;&#20123;&#27169;&#22411;&#26410;&#33021;&#27491;&#30830;&#32534;&#30721;&#25968;&#23383;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#38656;&#35201;&#25968;&#23383;&#29702;&#35299;&#30340;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31574;&#30053;&#65292;&#36890;&#36807;&#22312;&#20219;&#20309;&#35821;&#26009;&#24211;&#20013;&#29983;&#25104;&#21463;&#25968;&#23383;&#20998;&#24067;&#35268;&#24459;&#25511;&#21046;&#30340;&#38170;&#28857;&#26469;&#22312;&#35821;&#20041;&#19978;&#24341;&#23548;&#25968;&#23383;&#65292;&#20174;&#32780;&#23454;&#29616;&#36825;&#20123;&#25968;&#23383;&#26631;&#35760;&#30340;&#25968;&#23398;&#22522;&#30784;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19968;&#31995;&#21015;&#25968;&#20540;&#20219;&#21153;&#36827;&#34892;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#25216;&#26415;&#30340;&#20248;&#36234;&#24615;&#65292;&#23545;&#39046;&#22495;&#20869;&#65288;&#24050;&#35265;&#65289;&#21644;&#39046;&#22495;&#22806;&#65288;&#26410;&#35265;&#65289;&#30340;&#25968;&#23383;&#37117;&#36866;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23454;&#35777;&#35780;&#20272;&#25193;&#23637;&#21040;&#20174;1&#21040;10&#20159;&#30340;&#25968;&#23383;&#33539;&#22260;&#65292;&#27604;&#20197;&#24448;&#30456;&#21516;&#31867;&#22411;&#30740;&#31350;&#30340;&#33539;&#22260;&#24191;&#24471;&#22810;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#23398;&#24471;&#30340;&#23884;&#20837;&#21521;&#25968;&#23398;&#19978;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01536v1 Announce Type: cross  Abstract: Off-the-shelf pre-trained language models have become the de facto standard in NLP pipelines for a multitude of downstream tasks. However, the inability of these models to properly encode numerals limits their performance on tasks requiring numeric comprehension. We introduce strategies to semantically prime numerals in any corpus by generating anchors governed by the distribution of numerals in said corpus, thereby enabling mathematically grounded representations of these numeral tokens. We establish the superiority of our proposed techniques through evaluation on a range of numeracy tasks for both in-domain (seen) and out-domain (unseen) numerals. Further, we expand our empirical evaluations to numerals ranging from 1 to 10 billion, a significantly broader range compared to previous studies of the same nature, and we demonstrate significant improvements in the mathematical grounding of our learned embeddings.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#35748;&#30693;&#37325;&#35780;&#65292;&#36825;&#39033;&#24037;&#20316;&#23558;&#24515;&#29702;&#23398;&#21407;&#21017;&#34701;&#20837;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20026;&#20854;&#25552;&#20379;&#20808;&#36827;&#30340;&#24515;&#29702;&#23398;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.01288</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#25552;&#20379;&#35748;&#30693;&#37325;&#35780;&#65292;&#22914;&#24471;&#21040;&#25351;&#23548;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01288
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#35748;&#30693;&#37325;&#35780;&#65292;&#36825;&#39033;&#24037;&#20316;&#23558;&#24515;&#29702;&#23398;&#21407;&#21017;&#34701;&#20837;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20026;&#20854;&#25552;&#20379;&#20808;&#36827;&#30340;&#24515;&#29702;&#23398;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#24773;&#24863;&#25903;&#25345;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23427;&#20204;&#21487;&#20197;&#23545;&#22788;&#20110;&#22256;&#22659;&#20013;&#30340;&#20154;&#20135;&#29983;&#20849;&#24773;&#22238;&#24212;&#12290;&#28982;&#32780;&#65292;&#38271;&#26399;&#30340;&#24515;&#29702;&#20581;&#24247;&#38656;&#35201;&#24773;&#32490;&#33258;&#25105;&#35843;&#33410;&#65292;&#32780;&#19968;&#27425;&#24615;&#30340;&#20849;&#24773;&#22238;&#24212;&#21017;&#26174;&#24471;&#21147;&#19981;&#20174;&#24515;&#12290;&#26412;&#25991;&#36890;&#36807;&#21442;&#19982;&#35748;&#30693;&#37325;&#35780;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#65292;&#35748;&#30693;&#37325;&#35780;&#26159;&#24515;&#29702;&#23398;&#20174;&#19994;&#32773;&#20351;&#29992;&#35821;&#35328;&#26377;&#38024;&#23545;&#24615;&#22320;&#25913;&#21464;&#20010;&#20307;&#23545;&#24773;&#22659;&#30340;&#36127;&#38754;&#35780;&#20215;&#30340;&#31574;&#30053;&#65307;&#36825;&#31181;&#35780;&#20215;&#34987;&#35748;&#20026;&#26159;&#20154;&#31867;&#24773;&#24863;&#20307;&#39564;&#30340;&#26681;&#28304;&#12290;&#25105;&#20204;&#20551;&#35774;&#24515;&#29702;&#23398;&#19978;&#30340;&#21407;&#21017;&#21487;&#20197;&#20351;LLMs&#20855;&#22791;&#36825;&#31181;&#20808;&#36827;&#30340;&#24515;&#29702;&#23398;&#33021;&#21147;&#65292;&#24182;&#35774;&#35745;&#20102;RESORT&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#31995;&#21015;&#36328;&#22810;&#20010;&#32500;&#24230;&#30340;&#37325;&#35780;&#26500;&#25104;&#65292;&#21487;&#29992;&#20316;LLM&#30340;&#25351;&#23548;&#12290;&#25105;&#20204;&#23545;LLM&#36827;&#34892;&#20102;&#39318;&#27425;&#19987;&#23478;&#35780;&#20272;&#65288;&#30001;&#25345;&#26377;&#30805;&#22763;&#25110;&#21338;&#22763;&#23398;&#20301;&#30340;&#20020;&#24202;&#24515;&#29702;&#23398;&#23478;&#36827;&#34892;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01288v1 Announce Type: new  Abstract: Large language models (LLMs) have offered new opportunities for emotional support, and recent work has shown that they can produce empathic responses to people in distress. However, long-term mental well-being requires emotional self-regulation, where a one-time empathic response falls short. This work takes a first step by engaging with cognitive reappraisals, a strategy from psychology practitioners that uses language to targetedly change negative appraisals that an individual makes of the situation; such appraisals is known to sit at the root of human emotional experience. We hypothesize that psychologically grounded principles could enable such advanced psychology capabilities in LLMs, and design RESORT which consists of a series of reappraisal constitutions across multiple dimensions that can be used as LLM instructions. We conduct a first-of-its-kind expert evaluation (by clinical psychologists with M.S. or Ph.D. degrees) of an LLM
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25191;&#34892;&#25991;&#26412;&#26144;&#23556;&#21644;&#23548;&#33322;&#33021;&#21147;&#30340;MANGO&#22522;&#20934;&#65292;&#21457;&#29616;&#21363;&#20351;&#26159;&#36804;&#20170;&#20026;&#27490;&#26368;&#22909;&#30340;&#35821;&#35328;&#27169;&#22411;GPT-4&#22312;&#22238;&#31572;&#28041;&#21450;&#26144;&#23556;&#21644;&#23548;&#33322;&#30340;&#38382;&#39064;&#26102;&#34920;&#29616;&#19981;&#20339;&#12290;</title><link>https://arxiv.org/abs/2403.19913</link><description>&lt;p&gt;
MANGO&#65306;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26144;&#23556;&#21644;&#23548;&#33322;&#33021;&#21147;&#30340;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19913
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25191;&#34892;&#25991;&#26412;&#26144;&#23556;&#21644;&#23548;&#33322;&#33021;&#21147;&#30340;MANGO&#22522;&#20934;&#65292;&#21457;&#29616;&#21363;&#20351;&#26159;&#36804;&#20170;&#20026;&#27490;&#26368;&#22909;&#30340;&#35821;&#35328;&#27169;&#22411;GPT-4&#22312;&#22238;&#31572;&#28041;&#21450;&#26144;&#23556;&#21644;&#23548;&#33322;&#30340;&#38382;&#39064;&#26102;&#34920;&#29616;&#19981;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;ChatGPT&#21644;GPT-4&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26368;&#36817;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#24778;&#20154;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;MANGO&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#23427;&#20204;&#25191;&#34892;&#22522;&#20110;&#25991;&#26412;&#26144;&#23556;&#21644;&#23548;&#33322;&#33021;&#21147;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#21253;&#25324;&#26469;&#33258;&#19968;&#22871;&#25991;&#26412;&#28216;&#25103;&#30340;53&#20010;&#36855;&#23467;&#65306;&#27599;&#20010;&#36855;&#23467;&#37117;&#19982;&#19968;&#20010;&#28216;&#35272;&#35828;&#26126;&#37197;&#23545;&#65292;&#20854;&#20013;&#21253;&#21547;&#27599;&#20010;&#20301;&#32622;&#30340;&#35775;&#38382;&#20294;&#19981;&#28085;&#30422;&#25152;&#26377;&#21487;&#33021;&#30340;&#36335;&#24452;&#12290;&#20219;&#21153;&#26159;&#38382;&#31572;&#65306;&#23545;&#20110;&#27599;&#20010;&#36855;&#23467;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35835;&#21462;&#28216;&#35272;&#35828;&#26126;&#24182;&#22238;&#31572;&#25968;&#30334;&#20010;&#26144;&#23556;&#21644;&#23548;&#33322;&#38382;&#39064;&#65292;&#20363;&#22914;&#8220;&#20320;&#24212;&#35813;&#20174;&#25151;&#23376;&#35199;&#37096;&#22914;&#20309;&#21435;&#38401;&#27004;&#65311;&#8221;&#21644;&#8220;&#22914;&#26524;&#25105;&#20204;&#20174;&#22320;&#19979;&#23460;&#21521;&#21271;&#21644;&#19996;&#36208;&#65292;&#25105;&#20204;&#20250;&#22312;&#21738;&#37324;&#65311;&#8221;&#12290;&#23613;&#31649;&#36825;&#20123;&#38382;&#39064;&#23545;&#20154;&#31867;&#26469;&#35828;&#24456;&#23481;&#26131;&#65292;&#20294;&#20107;&#23454;&#35777;&#26126;&#65292;&#36804;&#20170;&#20026;&#27490;&#26368;&#22909;&#30340;&#35821;&#35328;&#27169;&#22411;GPT-4&#29978;&#33267;&#22312;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#26102;&#34920;&#29616;&#19981;&#20339;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24378;&#22823;&#30340;&#26144;&#23556;&#21644;&#23548;&#33322;&#33021;&#21147;&#23558;&#26377;&#21033;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19913v1 Announce Type: cross  Abstract: Large language models such as ChatGPT and GPT-4 have recently achieved astonishing performance on a variety of natural language processing tasks. In this paper, we propose MANGO, a benchmark to evaluate their capabilities to perform text-based mapping and navigation. Our benchmark includes 53 mazes taken from a suite of textgames: each maze is paired with a walkthrough that visits every location but does not cover all possible paths. The task is question-answering: for each maze, a large language model reads the walkthrough and answers hundreds of mapping and navigation questions such as "How should you go to Attic from West of House?" and "Where are we if we go north and east from Cellar?". Although these questions are easy to humans, it turns out that even GPT-4, the best-to-date language model, performs poorly at answering them. Further, our experiments suggest that a strong mapping and navigation ability would benefit large languag
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22870;&#21169;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#26377;&#29992;&#38382;&#39064;&#26469;&#33258;&#25105;&#25913;&#36827;&#30340;&#26041;&#27861;&#65292;&#25552;&#38382;&#32773;&#36890;&#36807;&#35810;&#38382;&#35282;&#33394;&#25198;&#28436;&#32773;&#26469;&#24341;&#20986;&#20559;&#22909;&#65292;&#20174;&#32780;&#36845;&#20195;&#24494;&#35843;&#20197;&#22686;&#21152;&#20219;&#21153;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#27010;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.19154</link><description>&lt;p&gt;
STaR-GATE: &#25945;&#25480;&#35821;&#35328;&#27169;&#22411;&#35810;&#38382;&#28548;&#28165;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
STaR-GATE: Teaching Language Models to Ask Clarifying Questions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19154
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22870;&#21169;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#26377;&#29992;&#38382;&#39064;&#26469;&#33258;&#25105;&#25913;&#36827;&#30340;&#26041;&#27861;&#65292;&#25552;&#38382;&#32773;&#36890;&#36807;&#35810;&#38382;&#35282;&#33394;&#25198;&#28436;&#32773;&#26469;&#24341;&#20986;&#20559;&#22909;&#65292;&#20174;&#32780;&#36845;&#20195;&#24494;&#35843;&#20197;&#22686;&#21152;&#20219;&#21153;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#23436;&#25104;&#20219;&#21153;&#26102;&#65292;&#29992;&#25143;&#36890;&#24120;&#20250;&#36951;&#28431;&#37325;&#35201;&#30340;&#32454;&#33410;&#12290;&#34429;&#28982;&#25552;&#38382;&#21487;&#20197;&#35299;&#20915;&#36825;&#31181;&#27495;&#20041;&#65292;&#20294;&#27169;&#22411;&#24448;&#24448;&#24456;&#38590;&#25552;&#20986;&#22909;&#38382;&#39064;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#22870;&#21169;&#27169;&#22411;&#29983;&#25104;&#26377;&#29992;&#38382;&#39064;&#26469;&#33258;&#25105;&#25913;&#36827;&#30340;&#33021;&#21147;&#65292;&#36825;&#26159;&#19968;&#31181;&#31616;&#21333;&#26041;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;STaR-GATE&#12290;&#25105;&#20204;&#29983;&#25104;&#20102;&#19968;&#20010;&#21253;&#21547;25,500&#20010;&#29420;&#29305;&#20154;&#29289;-&#20219;&#21153;&#25552;&#31034;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20197;&#27169;&#25311;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;--&#25552;&#38382;&#32773;--&#19982;&#19968;&#20010;&#20854;&#20559;&#22909;&#26410;&#30693;&#30340;&#35282;&#33394;&#25198;&#28436;&#32773;&#20043;&#38388;&#30340;&#23545;&#35805;&#12290;&#36890;&#36807;&#25552;&#38382;&#65292;&#25552;&#38382;&#32773;&#20174;&#35282;&#33394;&#25198;&#28436;&#32773;&#37027;&#37324;&#24341;&#20986;&#20559;&#22909;&#12290;&#25552;&#38382;&#32773;&#22312;&#37027;&#20123;&#22686;&#21152;&#39640;&#36136;&#37327;&#21709;&#24212;&#27010;&#29575;&#30340;&#38382;&#39064;&#19978;&#36827;&#34892;&#36845;&#20195;&#24494;&#35843;&#65292;&#36825;&#20123;&#38382;&#39064;&#26159;&#30001;&#20855;&#26377;&#23545;&#35282;&#33394;&#25198;&#28436;&#32773;&#35775;&#38382;&#26435;&#38480;&#30340;&#39044;&#35328;&#32773;&#29983;&#25104;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19154v1 Announce Type: cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity \citep[GATE;][]{li2023eliciting}, models often struggle to ask good questions. We explore a language model's ability to self-improve \citep[STaR;][]{zelikman2022star} by rewarding the model for generating useful questions -- a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model -- the \texttt{Questioner} -- and a \texttt{Roleplayer} whose preferences are unknown to the \texttt{Questioner}. By asking questions, the \texttt{Questioner} elicits preferences from the \texttt{Roleplayer}. The \texttt{Questioner} is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an \texttt{Oracle} with access to the \texttt{Ro
&lt;/p&gt;</description></item><item><title>&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;: &#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25298;&#32477;&#26426;&#21046;&#22312;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#38752;&#24615;&#20013;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;RLKF&#12290;</title><link>https://arxiv.org/abs/2403.18349</link><description>&lt;p&gt;
&#25298;&#32477;&#25552;&#39640;&#21487;&#38752;&#24615;&#65306;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#20174;&#30693;&#35782;&#21453;&#39304;&#35757;&#32451;LLMs&#25298;&#32477;&#26410;&#30693;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18349
&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;: &#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25298;&#32477;&#26426;&#21046;&#22312;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#38752;&#24615;&#20013;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;RLKF&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#32463;&#24120;&#29983;&#25104;&#38169;&#35823;&#36755;&#20986;&#65292;&#34987;&#31216;&#20026;&#24187;&#24819;&#65292;&#36825;&#26159;&#30001;&#20110;&#23427;&#20204;&#22312;&#36776;&#21035;&#36229;&#20986;&#20854;&#30693;&#35782;&#33539;&#22260;&#30340;&#38382;&#39064;&#26102;&#30340;&#23616;&#38480;&#24615;&#12290;&#34429;&#28982;&#35299;&#20915;&#24187;&#24819;&#19968;&#30452;&#26159;&#30740;&#31350;&#30340;&#28966;&#28857;&#65292;&#20197;&#24448;&#30340;&#21162;&#21147;&#20027;&#35201;&#38598;&#20013;&#22312;&#25552;&#39640;&#27491;&#30830;&#24615;&#32780;&#26410;&#20805;&#20998;&#32771;&#34385;&#25298;&#32477;&#26426;&#21046;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#25991;&#20840;&#38754;&#30740;&#31350;&#20102;&#25298;&#32477;&#30340;&#20316;&#29992;&#65292;&#24341;&#20837;&#20102;&#27169;&#22411;&#21487;&#38752;&#24615;&#30340;&#27010;&#24565;&#20197;&#21450;&#30456;&#24212;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#36825;&#20123;&#24230;&#37327;&#26631;&#20934;&#34913;&#37327;&#20102;&#27169;&#22411;&#22312;&#25552;&#20379;&#20934;&#30830;&#21709;&#24212;&#30340;&#21516;&#26102;&#65292;&#28789;&#27963;&#25298;&#32477;&#36229;&#20986;&#20854;&#30693;&#35782;&#36793;&#30028;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#26368;&#23567;&#21270;&#24187;&#24819;&#12290;&#20026;&#20102;&#25552;&#39640;LLMs&#22266;&#26377;&#30340;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#30693;&#35782;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#65288;RLKF&#65289;&#30340;&#26032;&#23545;&#40784;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18349v1 Announce Type: new  Abstract: Large Language Models (LLMs) often generate erroneous outputs, known as hallucinations, due to their limitations in discerning questions beyond their knowledge scope. While addressing hallucination has been a focal point in research, previous efforts primarily concentrate on enhancing correctness without giving due consideration to the significance of rejection mechanisms. In this paper, we conduct a comprehensive examination of the role of rejection, introducing the notion of model reliability along with corresponding metrics. These metrics measure the model's ability to provide accurate responses while adeptly rejecting questions exceeding its knowledge boundaries, thereby minimizing hallucinations. To improve the inherent reliability of LLMs, we present a novel alignment framework called Reinforcement Learning from Knowledge Feedback (RLKF). RLKF leverages knowledge feedback to dynamically determine the model's knowledge boundary and 
&lt;/p&gt;</description></item><item><title>Duwak&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23884;&#20837;&#21452;&#37325;&#31192;&#23494;&#27169;&#24335;&#30340;&#27700;&#21360;&#25216;&#26415;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#27700;&#21360;&#30340;&#25928;&#29575;&#21644;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.13000</link><description>&lt;p&gt;
Duwak: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#21452;&#37325;&#27700;&#21360;
&lt;/p&gt;
&lt;p&gt;
Duwak: Dual Watermarks in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13000
&lt;/p&gt;
&lt;p&gt;
Duwak&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23884;&#20837;&#21452;&#37325;&#31192;&#23494;&#27169;&#24335;&#30340;&#27700;&#21360;&#25216;&#26415;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#27700;&#21360;&#30340;&#25928;&#29575;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#26085;&#30410;&#20351;&#29992;&#65292;&#23457;&#35745;&#23427;&#20204;&#30340;&#29992;&#36884;&#12289;&#31649;&#29702;&#23427;&#20204;&#30340;&#24212;&#29992;&#24182;&#20943;&#36731;&#20854;&#28508;&#22312;&#21361;&#23475;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;Duwak&#65292;&#36890;&#36807;&#22312;&#20196;&#29260;&#27010;&#29575;&#20998;&#24067;&#21644;&#25277;&#26679;&#26041;&#26696;&#20013;&#23884;&#20837;&#21452;&#37325;&#31192;&#23494;&#27169;&#24335;&#65292;&#20174;&#26681;&#26412;&#19978;&#25552;&#39640;&#20102;&#27700;&#21360;&#30340;&#25928;&#29575;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13000v1 Announce Type: cross  Abstract: As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable patterns without significantly affecting generated text quality and semantics. However, the efficiency in detecting watermarks, i.e., the minimum number of tokens required to assert detection with significance and robustness against post-editing, is still debatable. In this paper, we propose, Duwak, to fundamentally enhance the efficiency and quality of watermarking by embedding dual secret patterns in both token probability distribution and sampling schemes. To mitigate expression degradation caused by biasing toward certain tokens, we design a contrastive search to watermark the sampling scheme, which minimizes the token repetition and enhances 
&lt;/p&gt;</description></item><item><title>Gemini 1.5 Pro&#26159;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#30340;&#22810;&#27169;&#24577;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22312;&#25968;&#30334;&#19975;&#26631;&#35760;&#30340;&#19978;&#19979;&#25991;&#20013;&#22238;&#24518;&#21644;&#25512;&#29702;&#20449;&#24687;&#65292;&#36798;&#21040;&#36817;&#20046;&#23436;&#32654;&#30340;&#38271;&#19978;&#19979;&#25991;&#26816;&#32034;&#20219;&#21153;&#21484;&#22238;&#29575;&#65292;&#25913;&#36827;&#20102;&#38271;&#25991;&#26723;&#38382;&#31572;&#12289;&#38271;&#35270;&#39057;&#38382;&#31572;&#21644;&#38271;&#19978;&#19979;&#25991;ASR&#30340;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2403.05530</link><description>&lt;p&gt;
Gemini 1.5&#65306;&#35299;&#38145;&#36328;&#25968;&#30334;&#19975;&#26631;&#35760;&#19978;&#19979;&#25991;&#30340;&#22810;&#27169;&#24577;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05530
&lt;/p&gt;
&lt;p&gt;
Gemini 1.5 Pro&#26159;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#30340;&#22810;&#27169;&#24577;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22312;&#25968;&#30334;&#19975;&#26631;&#35760;&#30340;&#19978;&#19979;&#25991;&#20013;&#22238;&#24518;&#21644;&#25512;&#29702;&#20449;&#24687;&#65292;&#36798;&#21040;&#36817;&#20046;&#23436;&#32654;&#30340;&#38271;&#19978;&#19979;&#25991;&#26816;&#32034;&#20219;&#21153;&#21484;&#22238;&#29575;&#65292;&#25913;&#36827;&#20102;&#38271;&#25991;&#26723;&#38382;&#31572;&#12289;&#38271;&#35270;&#39057;&#38382;&#31572;&#21644;&#38271;&#19978;&#19979;&#25991;ASR&#30340;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#20221;&#25253;&#21578;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Gemini&#23478;&#26063;&#30340;&#26368;&#26032;&#27169;&#22411;Gemini 1.5 Pro&#65292;&#36825;&#26159;&#19968;&#20010;&#39640;&#25928;&#35745;&#31639;&#30340;&#22810;&#27169;&#24577;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22815;&#22238;&#24518;&#21644;&#25512;&#29702;&#25968;&#30334;&#19975;&#26631;&#35760;&#19978;&#19979;&#25991;&#20013;&#30340;&#32454;&#31890;&#24230;&#20449;&#24687;&#65292;&#21253;&#25324;&#22810;&#20010;&#38271;&#25991;&#26723;&#21644;&#20960;&#23567;&#26102;&#30340;&#35270;&#39057;&#21644;&#38899;&#39057;&#12290;Gemini 1.5 Pro&#22312;&#21508;&#31181;&#24418;&#24335;&#30340;&#38271;&#19978;&#19979;&#25991;&#26816;&#32034;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#36817;&#20046;&#23436;&#32654;&#30340;&#21484;&#22238;&#29575;&#65292;&#25913;&#36827;&#20102;&#38271;&#25991;&#26723;&#38382;&#31572;&#12289;&#38271;&#35270;&#39057;&#38382;&#31572;&#21644;&#38271;&#19978;&#19979;&#25991;ASR&#30340;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#65292;&#24182;&#22312;&#24191;&#27867;&#19968;&#31995;&#21015;&#22522;&#20934;&#27979;&#35797;&#20013;&#19982;Gemini 1.0 Ultra&#30340;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#30456;&#21305;&#25932;&#29978;&#33267;&#36229;&#36807;&#12290;&#22312;&#30740;&#31350;Gemini 1.5 Pro&#38271;&#19978;&#19979;&#25991;&#33021;&#21147;&#30340;&#26497;&#38480;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#33267;&#23569;10M&#26631;&#35760;&#30340;&#33539;&#22260;&#20869;&#32487;&#32493;&#25913;&#36827;&#19979;&#19968;&#20010;&#26631;&#35760;&#30340;&#39044;&#27979;&#65292;&#24182;&#19988;&#20960;&#20046;&#23436;&#32654;&#22320;&#36798;&#21040;&#20102;&#36229;&#36807;99%&#30340;&#26816;&#32034;&#29575;&#65292;&#36825;&#26159;&#23545;&#29616;&#26377;&#27169;&#22411;&#22914;Claude 2.1&#65288;200k&#65289;&#21644;GPT-4 Turbo&#65288;128k&#65289;&#30340;&#19990;&#20195;&#24615;&#39134;&#36291;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#31361;&#20986;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#26032;&#39046;&#22495;&#30340;&#20196;&#20154;&#24778;&#35766;&#30340;&#26032;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05530v1 Announce Type: cross  Abstract: In this report, we present the latest model of the Gemini family, Gemini 1.5 Pro, a highly compute-efficient multimodal mixture-of-experts model capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. Gemini 1.5 Pro achieves near-perfect recall on long-context retrieval tasks across modalities, improves the state-of-the-art in long-document QA, long-video QA and long-context ASR, and matches or surpasses Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5 Pro's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (&gt;99%) up to at least 10M tokens, a generational leap over existing models such as Claude 2.1 (200k) and GPT-4 Turbo (128k). Finally, we highlight surprising new capabilities of large language models at the
&lt;/p&gt;</description></item><item><title>MediSwift&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#24341;&#20837;&#20102;&#39640;&#25928;&#31232;&#30095;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#36890;&#36807;75%&#30340;&#26435;&#37325;&#31232;&#30095;&#24615;&#23454;&#29616;&#20102;2-2.5&#20493;&#30340;&#35757;&#32451;FLOPs&#20943;&#23569;&#65292;&#20174;&#32780;&#26174;&#33879;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.00952</link><description>&lt;p&gt;
MediSwift&#65306;&#39640;&#25928;&#31232;&#30095;&#39044;&#35757;&#32451;&#29983;&#29289;&#21307;&#23398;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
MediSwift: Efficient Sparse Pre-trained Biomedical Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00952
&lt;/p&gt;
&lt;p&gt;
MediSwift&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#24341;&#20837;&#20102;&#39640;&#25928;&#31232;&#30095;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#36890;&#36807;75%&#30340;&#26435;&#37325;&#31232;&#30095;&#24615;&#23454;&#29616;&#20102;2-2.5&#20493;&#30340;&#35757;&#32451;FLOPs&#20943;&#23569;&#65292;&#20174;&#32780;&#26174;&#33879;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#24120;&#22312;&#36890;&#29992;&#28304;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#29992;&#20110;&#21508;&#31181;&#39046;&#22495;&#65292;&#20294;&#26368;&#36817;&#39046;&#22495;&#29305;&#23450;&#30340;LLMs&#28608;&#22686;&#34920;&#26126;&#23427;&#20204;&#22312;&#39046;&#22495;&#29305;&#23450;&#20219;&#21153;&#65288;&#20363;&#22914;&#29983;&#29289;&#21307;&#23398;&#65289;&#20013;&#30340;&#28508;&#21147;&#36229;&#36807;&#20102;&#36890;&#29992;&#22411;&#27169;&#22411;&#12290;&#34429;&#28982;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#25552;&#39640;&#20102;&#25928;&#29575;&#24182;&#23548;&#33268;&#27169;&#22411;&#26356;&#23567;&#65292;&#20294;&#36825;&#20123;LLMs&#30340;&#35757;&#32451;&#35745;&#31639;&#25104;&#26412;&#20173;&#28982;&#24456;&#39640;&#65292;&#26500;&#25104;&#20102;&#39044;&#31639;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;MediSwift&#65292;&#19968;&#22871;&#21033;&#29992;&#39046;&#22495;&#29305;&#23450;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#25968;&#25454;&#19978;&#30340;&#31232;&#30095;&#39044;&#35757;&#32451;&#30340;&#29983;&#29289;&#21307;&#23398;LM&#12290;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#24341;&#20837;&#39640;&#36798;75&#65285;&#30340;&#26435;&#37325;&#31232;&#30095;&#24615;&#65292;MediSwift&#22312;&#35757;&#32451;FLOPs&#26041;&#38754;&#23454;&#29616;&#20102;2-2.5&#20493;&#30340;&#20943;&#23569;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#26377;&#30340;&#31232;&#30095;&#39044;&#35757;&#32451;&#22343;&#22312;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#23454;&#29616;&#26469;&#33258;&#38750;&#32467;&#26500;&#21270;&#26435;&#37325;&#31232;&#30095;&#24615;&#30340;&#21152;&#36895;&#22909;&#22788;&#30340;Cerebras CS-2&#31995;&#32479;&#19978;&#36827;&#34892;&#65292;&#20174;&#32780;&#26174;&#30528;&#25552;&#39640;&#20102;MediSwift&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00952v1 Announce Type: new  Abstract: Large language models (LLMs) are typically trained on general source data for various domains, but a recent surge in domain-specific LLMs has shown their potential to outperform general-purpose models in domain-specific tasks (e.g., biomedicine). Although domain-specific pre-training enhances efficiency and leads to smaller models, the computational costs of training these LLMs remain high, posing budgeting challenges. We introduce MediSwift, a suite of biomedical LMs that leverage sparse pre-training on domain-specific biomedical text data. By inducing up to 75% weight sparsity during the pre-training phase, MediSwift achieves a 2-2.5x reduction in training FLOPs. Notably, all sparse pre-training was performed on the Cerebras CS-2 system, which is specifically designed to realize the acceleration benefits from unstructured weight sparsity, thereby significantly enhancing the efficiency of the MediSwift models. Through subsequent dense f
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#26032;&#21160;&#20316;&#30340;&#33021;&#21147;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#30340;&#23398;&#20064;&#36827;&#27493;&#33267;&#20851;&#37325;&#35201;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#24320;&#25918;&#24335;&#34892;&#20026;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#36845;&#20195;&#23398;&#20064;&#31574;&#30053;&#25913;&#36827;&#21160;&#20316;&#65292;&#22686;&#24378;&#20195;&#29702;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.15809</link><description>&lt;p&gt;
&#36890;&#36807;&#34892;&#20026;&#23398;&#20064;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Empowering Large Language Model Agents through Action Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15809
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#26032;&#21160;&#20316;&#30340;&#33021;&#21147;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#30340;&#23398;&#20064;&#36827;&#27493;&#33267;&#20851;&#37325;&#35201;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#24320;&#25918;&#24335;&#34892;&#20026;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#36845;&#20195;&#23398;&#20064;&#31574;&#30053;&#25913;&#36827;&#21160;&#20316;&#65292;&#22686;&#24378;&#20195;&#29702;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20195;&#29702;&#36817;&#26469;&#24341;&#36215;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#28982;&#32780;&#23427;&#20204;&#22312;&#20174;&#35797;&#38169;&#20013;&#23398;&#20064;&#30340;&#33021;&#21147;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#65292;&#36825;&#26159;&#26234;&#33021;&#34892;&#20026;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#26412;&#30740;&#31350;&#35748;&#20026;&#65292;&#20174;&#32463;&#39564;&#20013;&#23398;&#20064;&#26032;&#21160;&#20316;&#30340;&#33021;&#21147;&#23545;&#20110;LLM&#20195;&#29702;&#30340;&#23398;&#20064;&#36827;&#27493;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#20154;&#31867;&#33258;&#28982;&#22320;&#25193;&#23637;&#20182;&#20204;&#30340;&#21160;&#20316;&#31354;&#38388;&#24182;&#36890;&#36807;&#32463;&#39564;&#23398;&#20064;&#21457;&#23637;&#25216;&#33021;&#65292;&#20294;LLM&#20195;&#29702;&#36890;&#24120;&#22312;&#22266;&#23450;&#30340;&#21160;&#20316;&#31354;&#38388;&#20869;&#25805;&#20316;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#25104;&#38271;&#28508;&#21147;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#35821;&#35328;&#20195;&#29702;&#30340;&#24320;&#25918;&#24335;&#34892;&#20026;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LearnAct&#30340;&#26694;&#26550;&#65292;&#37319;&#29992;&#36845;&#20195;&#23398;&#20064;&#31574;&#30053;&#26469;&#21019;&#24314;&#21644;&#25913;&#36827;Python&#20989;&#25968;&#24418;&#24335;&#30340;&#21160;&#20316;&#12290;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;LLM&#26681;&#25454;&#22312;&#22833;&#36133;&#30340;&#35757;&#32451;&#20219;&#21153;&#20013;&#35782;&#21035;&#20986;&#30340;&#38169;&#35823;&#65292;&#20462;&#35746;&#21644;&#26356;&#26032;&#24403;&#21069;&#21487;&#29992;&#30340;&#21160;&#20316;&#65292;&#20174;&#32780;&#22686;&#24378;&#21160;&#20316;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35780;&#20272;&#26159;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15809v1 Announce Type: new  Abstract: Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior. In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents. While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth. To address these challenges, our study explores open-action learning for language agents. We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions. In each iteration, LLM revises and updates the currently available actions based on the errors identified in unsuccessful training tasks, thereby enhancing action effectiveness. Our experimental evaluations acr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#35268;&#27169;&#21270;&#38544;&#31169;&#24863;&#30693;&#25163;&#35821;&#32763;&#35793;&#12290;&#25105;&#20204;&#21033;&#29992;&#33258;&#30417;&#30563;&#35270;&#39057;&#39044;&#35757;&#32451;&#21644;&#26377;&#30417;&#30563;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#31232;&#32570;&#21644;&#38544;&#31169;&#39118;&#38505;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25163;&#35821;&#32763;&#35793;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09611</link><description>&lt;p&gt;
&#23454;&#29616;&#35268;&#27169;&#21270;&#38544;&#31169;&#24863;&#30693;&#25163;&#35821;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Towards Privacy-Aware Sign Language Translation at Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#35268;&#27169;&#21270;&#38544;&#31169;&#24863;&#30693;&#25163;&#35821;&#32763;&#35793;&#12290;&#25105;&#20204;&#21033;&#29992;&#33258;&#30417;&#30563;&#35270;&#39057;&#39044;&#35757;&#32451;&#21644;&#26377;&#30417;&#30563;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#31232;&#32570;&#21644;&#38544;&#31169;&#39118;&#38505;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25163;&#35821;&#32763;&#35793;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25163;&#35821;&#32763;&#35793;&#30340;&#19968;&#20010;&#20027;&#35201;&#38556;&#30861;&#26159;&#25968;&#25454;&#31232;&#32570;&#12290;&#30446;&#21069;&#22312;&#32593;&#32476;&#19978;&#21487;&#29992;&#30340;&#22823;&#37096;&#20998;&#25163;&#35821;&#25968;&#25454;&#30001;&#20110;&#32570;&#20047;&#23545;&#40784;&#30340;&#23383;&#24149;&#32780;&#26080;&#27861;&#29992;&#20110;&#35757;&#32451;&#30417;&#30563;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#22823;&#35268;&#27169;&#32593;&#32476;&#25235;&#21462;&#30340;&#25968;&#25454;&#38598;&#26469;&#25193;&#23637;&#25163;&#35821;&#32763;&#35793;&#23384;&#22312;&#38544;&#31169;&#39118;&#38505;&#65292;&#22240;&#20026;&#20854;&#20013;&#21253;&#21547;&#29983;&#29289;&#29305;&#24449;&#20449;&#24687;&#65292;&#36127;&#36131;&#20219;&#22320;&#24320;&#21457;&#25163;&#35821;&#32763;&#35793;&#25216;&#26415;&#24212;&#35813;&#32771;&#34385;&#36825;&#19968;&#28857;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35268;&#27169;&#21270;&#38544;&#31169;&#24863;&#30693;&#25163;&#35821;&#32763;&#35793;&#30340;&#20004;&#38454;&#27573;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;SSVP-SLT&#65292;&#23427;&#21033;&#29992;&#21311;&#21517;&#21644;&#26410;&#27880;&#37322;&#30340;&#35270;&#39057;&#36827;&#34892;&#33258;&#30417;&#30563;&#35270;&#39057;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#21033;&#29992;&#32463;&#36807;&#31579;&#36873;&#30340;&#24179;&#34892;&#25968;&#25454;&#38598;&#36827;&#34892;&#26377;&#30417;&#30563;&#30340;&#25163;&#35821;&#32763;&#35793;&#24494;&#35843;&#12290; SSVP-SLT&#22312;How2Sign&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#26032;&#30340;&#24494;&#35843;&#21644;&#38646;&#27425;gloss-free&#25163;&#35821;&#32763;&#35793;&#24615;&#33021;&#65292;&#27604;&#26368;&#24378;&#30340;&#22522;&#32447;&#27169;&#22411;&#25552;&#39640;&#20102;3&#20010;BLEU-4&#12290;&#36890;&#36807;&#21463;&#25511;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#35821;&#35328;&#21644;&#25163;&#35821;&#35789;&#27719;&#19978;&#37117;&#20855;&#26377;&#36739;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09611v1 Announce Type: new  Abstract: A major impediment to the advancement of sign language translation (SLT) is data scarcity. Much of the sign language data currently available on the web cannot be used for training supervised models due to the lack of aligned captions. Furthermore, scaling SLT using large-scale web-scraped datasets bears privacy risks due to the presence of biometric information, which the responsible development of SLT technologies should account for. In this work, we propose a two-stage framework for privacy-aware SLT at scale that addresses both of these issues. We introduce SSVP-SLT, which leverages self-supervised video pretraining on anonymized and unannotated videos, followed by supervised SLT finetuning on a curated parallel dataset. SSVP-SLT achieves state-of-the-art finetuned and zero-shot gloss-free SLT performance on the How2Sign dataset, outperforming the strongest respective baselines by over 3 BLEU-4. Based on controlled experiments, we fu
&lt;/p&gt;</description></item><item><title>&#26816;&#32034;&#22686;&#24378;&#24605;&#32500;&#36807;&#31243;&#65288;RATP&#65289;&#36890;&#36807;&#22810;&#27493;&#20915;&#31574;&#21644;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65292;&#20197;&#21450;Q&#20540;&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38544;&#31169;&#12289;&#20135;&#29983;&#24187;&#35273;&#21644;&#22788;&#29702;&#38271;&#25991;&#26412;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#22788;&#29702;&#31169;&#20154;&#25968;&#25454;&#30340;&#38382;&#31572;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;50%&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.07812</link><description>&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#30340;&#24605;&#32500;&#36807;&#31243;&#20316;&#20026;&#24207;&#21015;&#20915;&#31574;&#21046;&#23450;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Thought Process as Sequential Decision Making
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07812
&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#24605;&#32500;&#36807;&#31243;&#65288;RATP&#65289;&#36890;&#36807;&#22810;&#27493;&#20915;&#31574;&#21644;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65292;&#20197;&#21450;Q&#20540;&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38544;&#31169;&#12289;&#20135;&#29983;&#24187;&#35273;&#21644;&#22788;&#29702;&#38271;&#25991;&#26412;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#22788;&#29702;&#31169;&#20154;&#25968;&#25454;&#30340;&#38382;&#31572;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;50%&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#23637;&#31034;&#20102;&#20854;&#24378;&#22823;&#30340;&#36741;&#21161;&#20154;&#31867;&#24182;&#23637;&#29616;&#20986;"&#26234;&#33021;&#30340;&#28779;&#33457;"&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20960;&#20010;&#24320;&#25918;&#25361;&#25112;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#65306;&#22914;&#23545;&#38544;&#31169;&#30340;&#20851;&#27880;&#12289;&#20542;&#21521;&#20110;&#20135;&#29983;&#24187;&#35273;&#12289;&#38590;&#20197;&#22788;&#29702;&#38271;&#25991;&#26412;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#26816;&#32034;&#22686;&#24378;&#24605;&#32500;&#36807;&#31243;(RATP)&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#36890;&#36807;&#33719;&#21462;&#22806;&#37096;&#30693;&#35782;&#65292;RATP&#23558;LLM&#30340;&#24605;&#32771;&#29983;&#25104;&#36807;&#31243;&#23450;&#24335;&#20026;&#22810;&#27493;&#20915;&#31574;&#36807;&#31243;&#12290;&#20026;&#20102;&#20248;&#21270;&#36825;&#31181;&#24605;&#32771;&#36807;&#31243;&#65292;RATP&#21033;&#29992;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65292;&#24182;&#23398;&#20064;&#20102;&#19968;&#20010;Q&#20540;&#20272;&#35745;&#22120;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25512;&#29702;&#12290;&#22312;&#22788;&#29702;&#20855;&#26377;&#31169;&#20154;&#25968;&#25454;&#30340;&#38382;&#31572;&#20219;&#21153;&#26102;&#65292;LLM&#35757;&#32451;&#26041;&#27861;&#21463;&#21040;&#20262;&#29702;&#21644;&#23433;&#20840;&#38382;&#39064;&#30340;&#38480;&#21046;&#12290;RATP&#22312;&#19978;&#19979;&#25991;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#23454;&#29616;&#20102;50%&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated their strong ability to assist people and show "sparks of intelligence". However, several open challenges hinder their wider application: such as concerns over privacy, tendencies to produce hallucinations, and difficulties in handling long contexts. In this work, we address those challenges by introducing the Retrieval-Augmented Thought Process (RATP). Given access to external knowledge, RATP formulates the thought generation of LLMs as a multiple-step decision process. To optimize such a thought process, RATP leverages Monte-Carlo Tree Search, and learns a Q-value estimator that permits cost-efficient inference. In addressing the task of question-answering with private data, where ethical and security concerns limit LLM training methods, RATP achieves a 50% improvement over existing in-context retrieval-augmented language models.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21551;&#21457;&#24335;&#39537;&#21160;&#30340;&#31867;&#27604;&#38142;&#25509;&#20419;&#36827;&#26041;&#27861;&#65292;&#35813;&#30740;&#31350;&#22686;&#24378;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25991;&#26723;&#32423;&#20107;&#20214;&#35770;&#35777;&#25552;&#21462;&#65292;&#20351;&#20854;&#33021;&#22815;&#20174;&#31034;&#20363;&#20013;&#23398;&#20064;&#20219;&#21153;&#29305;&#23450;&#21551;&#21457;&#24335;&#65292;&#24182;&#36890;&#36807;&#31867;&#27604;&#25512;&#29702;&#22788;&#29702;&#26032;&#24773;&#20917;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.06555</link><description>&lt;p&gt;
&#21551;&#21457;&#39537;&#21160;&#30340;&#31867;&#27604;&#38142;&#25509;&#20419;&#36827;&#65306;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25991;&#26723;&#32423;&#20107;&#20214;&#35770;&#35777;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Heuristic-Driven Link-of-Analogy Prompting: Enhancing Large Language Models for Document-Level Event Argument Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.06555
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21551;&#21457;&#24335;&#39537;&#21160;&#30340;&#31867;&#27604;&#38142;&#25509;&#20419;&#36827;&#26041;&#27861;&#65292;&#35813;&#30740;&#31350;&#22686;&#24378;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25991;&#26723;&#32423;&#20107;&#20214;&#35770;&#35777;&#25552;&#21462;&#65292;&#20351;&#20854;&#33021;&#22815;&#20174;&#31034;&#20363;&#20013;&#23398;&#20064;&#20219;&#21153;&#29305;&#23450;&#21551;&#21457;&#24335;&#65292;&#24182;&#36890;&#36807;&#31867;&#27604;&#25512;&#29702;&#22788;&#29702;&#26032;&#24773;&#20917;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#25991;&#26723;&#32423;&#20107;&#20214;&#35770;&#35777;&#25552;&#21462;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#65292;&#20197;&#20943;&#36731;&#36825;&#19968;&#20219;&#21153;&#23545;&#22823;&#35268;&#27169;&#26631;&#35760;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#21551;&#21457;&#39537;&#21160;&#30340;&#31867;&#27604;&#38142;&#25509;&#65288;HD-LoA&#65289;&#25552;&#31034;&#65292;&#20197;&#35299;&#20915;&#31034;&#20363;&#36873;&#25321;&#30340;&#25361;&#25112;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#20026;EAE&#37327;&#36523;&#23450;&#21046;&#30340;&#25552;&#31034;&#31574;&#30053;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20551;&#35774;&#24182;&#39564;&#35777;&#20102;LLMs&#36890;&#36807;ICL&#20174;&#31034;&#33539;&#20013;&#23398;&#20064;&#20219;&#21153;&#29305;&#23450;&#21551;&#21457;&#24335;&#12290;&#22522;&#20110;&#36825;&#19968;&#20551;&#35774;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26174;&#24335;&#30340;&#21551;&#21457;&#24335;&#39537;&#21160;&#31034;&#33539;&#26500;&#24314;&#26041;&#27861;&#65292;&#23558;&#26434;&#20081;&#30340;&#31034;&#20363;&#36873;&#25321;&#36807;&#31243;&#36716;&#21270;&#20026;&#24378;&#35843;&#20219;&#21153;&#21551;&#21457;&#24335;&#30340;&#26377;&#26465;&#19981;&#32010;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#21463;&#20154;&#31867;&#31867;&#27604;&#25512;&#29702;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31867;&#27604;&#38142;&#25509;&#25552;&#31034;&#65292;&#20351;LLMs&#33021;&#22815;&#36890;&#36807;&#23558;&#26032;&#24773;&#20917;&#31867;&#27604;&#20110;&#24050;&#30693;&#24773;&#20917;&#26469;&#22788;&#29702;&#26032;&#24773;&#20917;&#65292;&#20174;&#32780;&#25552;&#39640;&#23427;&#20204;&#22312;&#26377;&#38480;ICL&#31034;&#20363;&#20197;&#22806;&#30340;&#26410;&#35265;&#31867;&#21035;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.06555v2 Announce Type: replace-cross  Abstract: In this study, we investigate in-context learning (ICL) in document-level event argument extraction (EAE) to alleviate the dependency on large-scale labeled data for this task. We introduce the Heuristic-Driven Link-of-Analogy (HD-LoA) prompting to address the challenge of example selection and to develop a prompting strategy tailored for EAE. Specifically, we hypothesize and validate that LLMs learn task-specific heuristics from demonstrations via ICL. Building upon this hypothesis, we introduce an explicit heuristic-driven demonstration construction approach, which transforms the haphazard example selection process into a methodical method that emphasizes task heuristics. Additionally, inspired by the analogical reasoning of human, we propose the link-of-analogy prompting, which enables LLMs to process new situations by drawing analogies to known situations, enhancing their performance on unseen classes beyond limited ICL exa
&lt;/p&gt;</description></item><item><title>TarGEN&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#22810;&#27493;&#25552;&#31034;&#31574;&#30053;&#65292;&#36890;&#36807;&#33258;&#25105;&#20462;&#27491;&#26041;&#27861;&#30830;&#20445;&#21487;&#38752;&#30340;&#26631;&#31614;&#12290;&#22312;SuperGLUE&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#27169;&#22411;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#25928;&#26524;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2310.17876</link><description>&lt;p&gt;
TarGEN: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30446;&#26631;&#25968;&#25454;&#29983;&#25104;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
TarGEN: Targeted Data Generation with Large Language Models. (arXiv:2310.17876v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17876
&lt;/p&gt;
&lt;p&gt;
TarGEN&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#22810;&#27493;&#25552;&#31034;&#31574;&#30053;&#65292;&#36890;&#36807;&#33258;&#25105;&#20462;&#27491;&#26041;&#27861;&#30830;&#20445;&#21487;&#38752;&#30340;&#26631;&#31614;&#12290;&#22312;SuperGLUE&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#27169;&#22411;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#25928;&#26524;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#24341;&#21457;&#20102;&#23545;&#25968;&#25454;&#21512;&#25104;&#25216;&#26415;&#30340;&#20852;&#36259;&#65292;&#26088;&#22312;&#29983;&#25104;&#22810;&#26679;&#19988;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#21512;&#25104;&#25968;&#25454;&#38598;&#24448;&#24448;&#32570;&#20047;&#22810;&#26679;&#24615;&#24182;&#19988;&#23384;&#22312;&#22122;&#22768;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TarGEN&#65292;&#19968;&#31181;&#21033;&#29992;LLM&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#22810;&#27493;&#25552;&#31034;&#31574;&#30053;&#12290;TarGEN&#30340;&#19968;&#20010;&#20248;&#28857;&#26159;&#26080;&#38656;&#31181;&#23376;&#65307;&#23427;&#19981;&#38656;&#35201;&#29305;&#23450;&#30340;&#20219;&#21153;&#23454;&#20363;&#65292;&#25193;&#22823;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#19968;&#31181;&#31216;&#20026;&#33258;&#25105;&#20462;&#27491;&#30340;&#26041;&#27861;&#65292;&#20351;LLM&#33021;&#22815;&#22312;&#21019;&#24314;&#25968;&#25454;&#38598;&#36807;&#31243;&#20013;&#32416;&#27491;&#26631;&#35760;&#38169;&#35823;&#30340;&#23454;&#20363;&#65292;&#30830;&#20445;&#21487;&#38752;&#30340;&#26631;&#31614;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#27169;&#25311;&#20102;SuperGLUE&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;8&#20010;&#20219;&#21153;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#21407;&#22987;&#35757;&#32451;&#38598;&#19978;&#24494;&#35843;&#20102;&#21508;&#31181;&#35821;&#35328;&#27169;&#22411;&#65292;&#21253;&#25324;&#20165;&#32534;&#30721;&#22120;&#12289;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#21644;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#12290;&#22312;&#21407;&#22987;&#27979;&#35797;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#25928;&#26524;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid advancement of large language models (LLMs) has sparked interest in data synthesis techniques, aiming to generate diverse and high-quality synthetic datasets. However, these synthetic datasets often suffer from a lack of diversity and added noise. In this paper, we present TarGEN, a multi-step prompting strategy for generating high-quality synthetic datasets utilizing a LLM. An advantage of TarGEN is its seedless nature; it does not require specific task instances, broadening its applicability beyond task replication. We augment TarGEN with a method known as self-correction empowering LLMs to rectify inaccurately labeled instances during dataset creation, ensuring reliable labels. To assess our technique's effectiveness, we emulate 8 tasks from the SuperGLUE benchmark and finetune various language models, including encoder-only, encoder-decoder, and decoder-only models on both synthetic and original training sets. Evaluation on the original test set reveals that models traine
&lt;/p&gt;</description></item><item><title>CALM&#26159;&#19968;&#20010;&#29992;&#20110;&#37327;&#21270;&#35821;&#35328;&#27169;&#22411;&#20559;&#35265;&#30340;&#22810;&#20219;&#21153;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#30456;&#27604;&#20808;&#21069;&#25968;&#25454;&#38598;&#26356;&#21152;&#22810;&#26679;&#21644;&#21487;&#38752;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#35780;&#20272;&#27169;&#22411;&#20559;&#35265;&#25152;&#38656;&#30340;&#35821;&#35328;&#21464;&#21270;&#30340;&#24191;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.12539</link><description>&lt;p&gt;
CALM: &#19968;&#31181;&#29992;&#20110;&#20840;&#38754;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#20559;&#35265;&#30340;&#22810;&#20219;&#21153;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12539
&lt;/p&gt;
&lt;p&gt;
CALM&#26159;&#19968;&#20010;&#29992;&#20110;&#37327;&#21270;&#35821;&#35328;&#27169;&#22411;&#20559;&#35265;&#30340;&#22810;&#20219;&#21153;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#30456;&#27604;&#20808;&#21069;&#25968;&#25454;&#38598;&#26356;&#21152;&#22810;&#26679;&#21644;&#21487;&#38752;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#35780;&#20272;&#27169;&#22411;&#20559;&#35265;&#25152;&#38656;&#30340;&#35821;&#35328;&#21464;&#21270;&#30340;&#24191;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#19981;&#26029;&#22686;&#24378;&#65292;&#37327;&#21270;&#21644;&#27604;&#36739;&#23427;&#20204;&#22312;&#31038;&#20250;&#21644;&#20154;&#21475;&#23398;&#20559;&#35265;&#26041;&#38754;&#30340;&#33021;&#21147;&#20197;&#21450;&#28508;&#22312;&#30340;&#21361;&#23475;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20808;&#21069;&#30340;&#20559;&#35265;&#27979;&#37327;&#25968;&#25454;&#38598;&#23545;&#20110;&#20154;&#24037;&#35774;&#35745;&#27169;&#26495;&#30340;&#25200;&#21160;&#25935;&#24863;&#65292;&#22240;&#27492;&#19981;&#21487;&#38752;&#12290;&#20026;&#20102;&#20445;&#35777;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20840;&#38754;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#20559;&#35265;&#65288;CALM&#65289;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#37327;&#21270;LMs&#22312;&#19977;&#20010;&#20219;&#21153;&#19978;&#30340;&#20559;&#35265;&#12290;&#25105;&#20204;&#25972;&#21512;&#20102;&#26469;&#33258;&#19981;&#21516;&#39046;&#22495;&#65288;&#22914;&#32500;&#22522;&#30334;&#31185;&#21644;&#26032;&#38395;&#25991;&#31456;&#65289;&#30340;16&#20010;&#29616;&#26377;&#25968;&#25454;&#38598;&#65292;&#36807;&#28388;&#20986;224&#20010;&#27169;&#26495;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;78,400&#20010;&#31034;&#20363;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#36890;&#36807;&#24179;&#22343;&#35821;&#20041;&#30456;&#20284;&#24615;&#21644;&#27169;&#26495;&#38271;&#24230;&#30340;&#21464;&#24322;&#31243;&#24230;&#31561;&#25351;&#26631;&#65292;&#27604;&#36739;CALM&#19982;&#20808;&#21069;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#65292;&#24182;&#27979;&#35797;&#20854;&#23545;&#32454;&#24494;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#30456;&#23545;&#20110;&#20808;&#21069;&#25968;&#25454;&#38598;&#26356;&#21152;&#22810;&#26679;&#21644;&#21487;&#38752;&#65292;&#22240;&#27492;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#35780;&#20272;&#27169;&#22411;&#20559;&#35265;&#25152;&#38656;&#30340;&#35821;&#35328;&#21464;&#21270;&#30340;&#24191;&#24230;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;20&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#22320;&#34913;&#37327;&#25552;&#31034;&#25552;&#21462;&#25915;&#20987;&#25104;&#21151;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#21457;&#29616;&#65292;&#21363;&#20351;&#25552;&#31034;&#34987;&#20445;&#23494;&#65292;&#31616;&#21333;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#25915;&#20987;&#20173;&#28982;&#21487;&#20197;&#39640;&#27010;&#29575;&#22320;&#25581;&#31034;&#25552;&#31034;&#12290;</title><link>http://arxiv.org/abs/2307.06865</link><description>&lt;p&gt;
&#25552;&#31034;&#19981;&#24212;&#34987;&#35270;&#20026;&#31192;&#23494;&#65306;&#31995;&#32479;&#22320;&#34913;&#37327;&#25552;&#31034;&#25552;&#21462;&#25915;&#20987;&#30340;&#25104;&#21151;&#24615;
&lt;/p&gt;
&lt;p&gt;
Prompts Should not be Seen as Secrets: Systematically Measuring Prompt Extraction Attack Success. (arXiv:2307.06865v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#22320;&#34913;&#37327;&#25552;&#31034;&#25552;&#21462;&#25915;&#20987;&#25104;&#21151;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#21457;&#29616;&#65292;&#21363;&#20351;&#25552;&#31034;&#34987;&#20445;&#23494;&#65292;&#31616;&#21333;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#25915;&#20987;&#20173;&#28982;&#21487;&#20197;&#39640;&#27010;&#29575;&#22320;&#25581;&#31034;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#36890;&#24120;&#36890;&#36807;&#25552;&#31034;&#25216;&#26415;&#26469;&#25511;&#21046;&#65292;&#20854;&#20013;&#29992;&#25143;&#23545;&#27169;&#22411;&#30340;&#26597;&#35810;&#20197;&#26088;&#22312;&#25351;&#23548;&#27169;&#22411;&#22312;&#35813;&#26597;&#35810;&#19978;&#30340;&#34892;&#20026;&#30340;&#25552;&#31034;&#20316;&#20026;&#21069;&#32512;&#12290;&#20844;&#21496;&#29992;&#20110;&#25351;&#23548;&#20854;&#27169;&#22411;&#30340;&#25552;&#31034;&#36890;&#24120;&#34987;&#35270;&#20026;&#31192;&#23494;&#65292;&#38544;&#34255;&#22312;&#26597;&#35810;&#30340;&#29992;&#25143;&#20043;&#22806;&#12290;&#23427;&#20204;&#29978;&#33267;&#34987;&#35270;&#20026;&#21487;&#20197;&#20080;&#21334;&#30340;&#21830;&#21697;&#12290;&#28982;&#32780;&#65292;&#26377;&#32463;&#39564;&#24615;&#30340;&#35777;&#25454;&#26174;&#31034;&#65292;&#21363;&#20351;&#25552;&#31034;&#34987;&#20445;&#23494;&#65292;&#29992;&#25143;&#20173;&#28982;&#21487;&#20197;&#25552;&#21462;&#23427;&#20204;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#22320;&#34913;&#37327;&#25552;&#31034;&#25552;&#21462;&#25915;&#20987;&#25104;&#21151;&#30340;&#26694;&#26550;&#12290;&#22312;&#20351;&#29992;&#22810;&#20010;&#25552;&#31034;&#28304;&#21644;&#22810;&#20010;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#31616;&#21333;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#25915;&#20987;&#23454;&#38469;&#19978;&#21487;&#20197;&#39640;&#27010;&#29575;&#22320;&#25581;&#31034;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generations of large language models are commonly controlled through prompting techniques, where a user's query to the model is prefixed with a prompt that aims to guide the model's behaviour on the query. The prompts used by companies to guide their models are often treated as secrets, to be hidden from the user making the query. They have even been treated as commodities to be bought and sold. However, there has been anecdotal evidence showing that the prompts can be extracted by a user even when they are kept secret. In this paper, we present a framework for systematically measuring the success of prompt extraction attacks. In experiments with multiple sources of prompts and multiple underlying language models, we find that simple text-based attacks can in fact reveal prompts with high probability.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#36229;&#32593;&#32476;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#32467;&#26500;&#36335;&#30001;&#30340;&#19987;&#23478;&#28151;&#21512;&#26469;&#22686;&#24378;&#36229;&#32423;&#32593;&#32476;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#25913;&#21892;&#20102;&#23376;&#32593;&#32476;&#30340;&#36136;&#37327;&#38382;&#39064;&#21644;&#24615;&#33021;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.04845</link><description>&lt;p&gt;
&#28151;&#21512;&#36229;&#32593;&#32476;&#65306;&#36890;&#36807;&#22522;&#20110;&#32467;&#26500;&#36335;&#30001;&#30340;&#19987;&#23478;&#28151;&#21512;&#25913;&#36827;&#20849;&#20139;&#26435;&#37325;&#36229;&#32593;&#32476;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with Architecture-Routed Mixture-of-Experts. (arXiv:2306.04845v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04845
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#36229;&#32593;&#32476;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#32467;&#26500;&#36335;&#30001;&#30340;&#19987;&#23478;&#28151;&#21512;&#26469;&#22686;&#24378;&#36229;&#32423;&#32593;&#32476;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#25913;&#21892;&#20102;&#23376;&#32593;&#32476;&#30340;&#36136;&#37327;&#38382;&#39064;&#21644;&#24615;&#33021;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#20139;&#26435;&#37325;&#30340;&#36229;&#32423;&#32593;&#32476;&#24050;&#32463;&#25104;&#20026;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#20307;&#31995;&#32467;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#26694;&#26550;&#20013;&#24615;&#33021;&#35780;&#20272;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26435;&#37325;&#20849;&#20139;&#65292;&#36229;&#32423;&#32593;&#32476;&#30452;&#25509;&#29983;&#25104;&#30340;&#19981;&#21516;&#23376;&#32593;&#32476;&#30340;&#36136;&#37327;&#26080;&#27861;&#20445;&#35777;&#12290;&#22312;&#26426;&#22120;&#32763;&#35793;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#24314;&#27169;&#31561;NLP&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#30456;&#21516;&#30340;&#27169;&#22411;&#26550;&#26500;&#19979;&#65292;&#36229;&#32423;&#32593;&#32476;&#19982;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#20043;&#38388;&#23384;&#22312;&#36739;&#22823;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;&#22240;&#27492;&#65292;&#22312;&#25214;&#21040;&#26368;&#20339;&#26550;&#26500;&#21518;&#65292;&#19981;&#33021;&#30452;&#25509;&#20351;&#29992;&#36229;&#32423;&#32593;&#32476;&#65292;&#24517;&#39035;&#36827;&#34892;&#37325;&#26032;&#35757;&#32451;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#28151;&#21512;&#36229;&#32593;&#32476;&#65292;&#36825;&#26159;&#19968;&#31181;&#24191;&#20041;&#30340;&#36229;&#32423;&#32593;&#32476;&#20844;&#24335;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#19987;&#23478;&#28151;&#21512;&#65288;MoE&#65289;&#26469;&#22686;&#24378;&#36229;&#32423;&#32593;&#32476;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35757;&#32451;&#24320;&#38144;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#19981;&#21516;&#30340;&#23376;&#32593;&#32476;&#19981;&#26159;&#30452;&#25509;&#20849;&#20139;&#27169;&#22411;&#26435;&#37325;&#65292;&#32780;&#26159;&#36890;&#36807;&#22522;&#20110;&#32467;&#26500;&#30340;&#36335;&#30001;&#26426;&#21046;&#20849;&#20139;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#24615;&#33021;&#24471;&#21040;&#20102;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Weight-sharing supernet has become a vital component for performance estimation in the state-of-the-art (SOTA) neural architecture search (NAS) frameworks. Although supernet can directly generate different subnetworks without retraining, there is no guarantee for the quality of these subnetworks because of weight sharing. In NLP tasks such as machine translation and pre-trained language modeling, we observe that given the same model architecture, there is a large performance gap between supernet and training from scratch. Hence, supernet cannot be directly used and retraining is necessary after finding the optimal architectures.  In this work, we propose mixture-of-supernets, a generalized supernet formulation where mixture-of-experts (MoE) is adopted to enhance the expressive power of the supernet model, with negligible training overhead. In this way, different subnetworks do not share the model weights directly, but through an architecture-based routing mechanism. As a result, model 
&lt;/p&gt;</description></item></channel></rss>