<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#21160;&#24577;&#20915;&#31574;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;"K&#32423;&#25512;&#29702;"&#30340;&#26032;&#39062;&#25512;&#29702;&#26041;&#27861;&#12290;&#36890;&#36807;&#21338;&#24328;&#35770;&#30340;&#35797;&#39564;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#25512;&#29702;&#26041;&#27861;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#23481;&#26131;&#20986;&#38169;&#65292;&#32780;"K&#32423;&#25512;&#29702;"&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01521</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;K&#32423;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
K-Level Reasoning with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01521
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#21160;&#24577;&#20915;&#31574;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;"K&#32423;&#25512;&#29702;"&#30340;&#26032;&#39062;&#25512;&#29702;&#26041;&#27861;&#12290;&#36890;&#36807;&#21338;&#24328;&#35770;&#30340;&#35797;&#39564;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#25512;&#29702;&#26041;&#27861;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#23481;&#26131;&#20986;&#38169;&#65292;&#32780;"K&#32423;&#25512;&#29702;"&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#23637;&#31034;&#20102;&#20854;&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#33021;&#21147;&#65292;&#20294;&#22312;&#21160;&#24577;&#12289;&#20132;&#20114;&#21644;&#31454;&#20105;&#22330;&#26223;&#65288;&#22914;&#21830;&#19994;&#25112;&#30053;&#21644;&#32929;&#31080;&#24066;&#22330;&#20998;&#26512;&#65289;&#20013;&#30340;&#24615;&#33021;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#27491;&#24335;&#25506;&#32034;LLMs&#22312;&#24555;&#36895;&#21464;&#21270;&#29615;&#22659;&#20013;&#30340;&#20915;&#31574;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#22522;&#20110;&#21338;&#24328;&#35770;&#30340;&#35797;&#39564;&#65292;&#20197;&#27169;&#25311;&#29616;&#23454;&#19990;&#30028;&#20013;&#21160;&#24577;&#20915;&#31574;&#30340;&#22797;&#26434;&#24615;&#12290;&#36825;&#20123;&#25361;&#25112;&#20855;&#26377;&#26126;&#30830;&#23450;&#20041;&#65292;&#21487;&#20197;&#23545;LLMs&#30340;&#21160;&#24577;&#25512;&#29702;&#33021;&#21147;&#36827;&#34892;&#28165;&#26224;&#12289;&#21487;&#25511;&#21644;&#31934;&#30830;&#30340;&#35780;&#20272;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#29616;&#26377;&#30340;&#25512;&#29702;&#26041;&#27861;&#22312;&#38656;&#35201;k&#32423;&#24605;&#32771;&#30340;&#21160;&#24577;&#29615;&#22659;&#20013;&#23481;&#26131;&#20986;&#38169; - &#36825;&#26159;&#20043;&#21069;&#30740;&#31350;&#20013;&#26410;&#35299;&#20915;&#30340;&#20851;&#38190;&#27010;&#24565;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;LLMs&#25512;&#29702;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;&#8220;K&#32423;&#25512;&#29702;&#8221;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#23545;&#25163;&#30340;&#35270;&#35282;&#65292;&#20174;&#36882;&#24402;&#35282;&#24230;&#36816;&#29992;&#22522;&#20110;k&#32423;&#24605;&#32771;&#30340;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
While Large Language Models (LLMs) have demonstrated their proficiency in complex reasoning tasks, their performance in dynamic, interactive, and competitive scenarios - such as business strategy and stock market analysis - remains underexplored. To bridge this gap, we formally explore the dynamic reasoning capabilities of LLMs for decision-making in rapidly evolving environments. We introduce two game theory-based pilot challenges that mirror the complexities of real-world dynamic decision-making. These challenges are well-defined, enabling clear, controllable, and precise evaluation of LLMs' dynamic reasoning abilities. Through extensive experiments, we find that existing reasoning methods tend to falter in dynamic settings that require k-level thinking - a key concept not tackled by previous works. To address this, we propose a novel reasoning approach for LLMs, named "K-Level Reasoning". This approach adopts the perspective of rivals to recursively employ k-level thinking based on 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;PROMPT-SAW&#27169;&#22411;&#65292;&#21033;&#29992;&#20851;&#31995;&#24863;&#30693;&#22270;&#26469;&#23454;&#29616;&#25991;&#26412;&#25552;&#31034;&#30340;&#21387;&#32553;&#65292;&#25552;&#39640;&#20102;&#25552;&#31034;&#30340;&#21487;&#35835;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.00489</link><description>&lt;p&gt;
PROMPT-SAW&#65306;&#21033;&#29992;&#20851;&#31995;&#24863;&#30693;&#22270;&#36827;&#34892;&#25991;&#26412;&#25552;&#31034;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
PROMPT-SAW: Leveraging Relation-Aware Graphs for Textual Prompt Compression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00489
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;PROMPT-SAW&#27169;&#22411;&#65292;&#21033;&#29992;&#20851;&#31995;&#24863;&#30693;&#22270;&#26469;&#23454;&#29616;&#25991;&#26412;&#25552;&#31034;&#30340;&#21387;&#32553;&#65292;&#25552;&#39640;&#20102;&#25552;&#31034;&#30340;&#21487;&#35835;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22810;&#31181;&#19981;&#21516;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#33021;&#21147;&#12290;&#25552;&#31034;&#26159;LLM&#25512;&#29702;&#20013;&#30340;&#22522;&#26412;&#24037;&#20855;&#65292;&#20294;&#25105;&#20204;&#35266;&#23519;&#21040;&#36229;&#38271;&#25552;&#31034;&#20250;&#24102;&#26469;&#26174;&#33879;&#30340;&#25104;&#26412;&#12290;&#29616;&#26377;&#30340;&#21387;&#32553;&#38271;&#25552;&#31034;&#30340;&#23581;&#35797;&#23548;&#33268;&#21387;&#32553;&#25552;&#31034;&#22312;&#21487;&#35835;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#23545;&#25552;&#31034;&#25928;&#29992;&#20135;&#29983;&#26377;&#23475;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PROMPT-SAW&#65306;&#36890;&#36807;&#20851;&#31995;&#24863;&#30693;&#22270;&#36827;&#34892;&#25552;&#31034;&#21387;&#32553;&#65292;&#36825;&#26159;&#19968;&#31181;&#38024;&#23545;&#20219;&#21153;&#19981;&#21487;&#30693;&#21644;&#20219;&#21153;&#24863;&#30693;&#25552;&#31034;&#30340;&#26377;&#25928;&#31574;&#30053;&#12290;PROMPT-SAW&#20351;&#29992;&#25552;&#31034;&#30340;&#25991;&#26412;&#20449;&#24687;&#26500;&#24314;&#22270;&#24418;&#65292;&#22312;&#22270;&#24418;&#20013;&#25552;&#21462;&#20851;&#38190;&#20449;&#24687;&#20803;&#32032;&#65292;&#20174;&#32780;&#24471;&#20986;&#21387;&#32553;&#25552;&#31034;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;GSM8K-AUG&#65292;&#21363;&#29616;&#26377;GSM8k&#22522;&#20934;&#30340;&#25193;&#23637;&#29256;&#26412;&#65292;&#29992;&#20110;&#20219;&#21153;&#19981;&#21487;&#30693;&#25552;&#31034;&#65292;&#20197;&#25552;&#20379;&#20840;&#38754;&#30340;&#35780;&#20272;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00489v1 Announce Type: cross  Abstract: Large language models (LLMs) have shown exceptional abilities for multiple different natural language processing tasks. While prompting is a crucial tool for LLM inference, we observe that there is a significant cost associated with exceedingly lengthy prompts. Existing attempts to compress lengthy prompts lead to sub-standard results in terms of readability and interpretability of the compressed prompt, with a detrimental impact on prompt utility. To address this, we propose PROMPT-SAW: Prompt compresSion via Relation AWare graphs, an effective strategy for prompt compression over task-agnostic and task-aware prompts. PROMPT-SAW uses the prompt's textual information to build a graph, later extracts key information elements in the graph to come up with the compressed prompt. We also propose GSM8K-AUG, i.e., an extended version of the existing GSM8k benchmark for task-agnostic prompts in order to provide a comprehensive evaluation platf
&lt;/p&gt;</description></item><item><title>CoLLEGe&#26159;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#28789;&#27963;&#30340;&#26032;&#27010;&#24565;&#23884;&#20837;&#65292;&#29992;&#20110;&#29616;&#20195;&#21270;&#23569;&#26679;&#26412;&#27010;&#24565;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.15362</link><description>&lt;p&gt;
CoLLEGe: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#23884;&#20837;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
CoLLEGe: Concept Embedding Generation for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15362
&lt;/p&gt;
&lt;p&gt;
CoLLEGe&#26159;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#28789;&#27963;&#30340;&#26032;&#27010;&#24565;&#23884;&#20837;&#65292;&#29992;&#20110;&#29616;&#20195;&#21270;&#23569;&#26679;&#26412;&#27010;&#24565;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#35821;&#35328;&#27169;&#22411;&#26080;&#27861;&#24555;&#36895;&#23398;&#20064;&#26032;&#27010;&#24565;&#65292;&#36890;&#24120;&#38656;&#35201;&#26356;&#22797;&#26434;&#30340;&#24494;&#35843;&#36807;&#31243;&#25165;&#33021;&#23398;&#20064;&#24471;&#26356;&#31283;&#20581;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;CoLLEGe&#65288;Concept Learning with Language Embedding Generation&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#29616;&#20195;&#21270;&#30340;&#23569;&#26679;&#26412;&#27010;&#24565;&#23398;&#20064;&#12290;CoLLEGe&#26159;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#20351;&#29992;&#23569;&#37327;&#31034;&#20363;&#21477;&#23376;&#25110;&#23450;&#20041;&#29983;&#25104;&#26032;&#27010;&#24565;&#30340;&#28789;&#27963;&#23884;&#20837;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#20803;&#23398;&#20064;&#30446;&#26631;&#21482;&#26159;&#20419;&#36827;&#35821;&#35328;&#27169;&#22411;&#22312;&#38543;&#21518;&#30340;&#21477;&#23376;&#20013;&#36827;&#34892;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#65292;&#20351;&#20854;&#19982;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15362v1 Announce Type: cross  Abstract: Current language models are unable to quickly learn new concepts on the fly, often requiring a more involved finetuning process to learn robustly. Prompting in-context is not robust to context distractions, and often fails to confer much information about the new concepts. Classic methods for few-shot word learning in NLP, relying on global word vectors, are less applicable to large language models. In this paper, we introduce a novel approach named CoLLEGe (Concept Learning with Language Embedding Generation) to modernize few-shot concept learning. CoLLEGe is a meta-learning framework capable of generating flexible embeddings for new concepts using a small number of example sentences or definitions. Our primary meta-learning objective is simply to facilitate a language model to make next word predictions in forthcoming sentences, making it compatible with language model pretraining. We design a series of tasks to test new concept lear
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35780;&#20272;&#20174;&#23545;&#23884;&#20837;&#30693;&#35782;&#30340;&#22522;&#20934;&#25299;&#23637;&#21040;&#20102;&#25506;&#32034;&#35821;&#29992;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#22312;&#38889;&#35821;&#29615;&#22659;&#19979;&#65292;GPT-4&#22312;&#20256;&#32479;&#21644;&#20154;&#24037;&#35780;&#20272;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;HyperCLOVA X&#20063;&#22312;&#24320;&#25918;&#24335;&#38382;&#39064;&#35780;&#20272;&#20013;&#21462;&#24471;&#20102;&#19981;&#38169;&#30340;&#25104;&#32489;&#12290;</title><link>https://arxiv.org/abs/2403.12675</link><description>&lt;p&gt;
&#23545;&#38889;&#35821;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#29992;&#33021;&#21147;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Pragmatic Competence Evaluation of Large Language Models for Korean
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12675
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35780;&#20272;&#20174;&#23545;&#23884;&#20837;&#30693;&#35782;&#30340;&#22522;&#20934;&#25299;&#23637;&#21040;&#20102;&#25506;&#32034;&#35821;&#29992;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#22312;&#38889;&#35821;&#29615;&#22659;&#19979;&#65292;GPT-4&#22312;&#20256;&#32479;&#21644;&#20154;&#24037;&#35780;&#20272;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;HyperCLOVA X&#20063;&#22312;&#24320;&#25918;&#24335;&#38382;&#39064;&#35780;&#20272;&#20013;&#21462;&#24471;&#20102;&#19981;&#38169;&#30340;&#25104;&#32489;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#20027;&#35201;&#20381;&#36182;&#20110;&#30528;&#37325;&#20110;&#27979;&#35797;&#20854;&#23884;&#20837;&#30693;&#35782;&#30340;&#22522;&#20934;&#65292;&#36890;&#36807;&#22810;&#39033;&#36873;&#25321;&#39064;&#65288;MCQs&#65289;&#26469;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#31181;&#26684;&#24335;&#38750;&#24120;&#36866;&#21512;&#33258;&#21160;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23558;&#27492;&#35780;&#20272;&#25299;&#23637;&#21040;&#25506;&#32034;LLM&#30340;&#35821;&#29992;&#33021;&#21147;--&#22312;&#20808;&#36827;&#30340;LLM&#20986;&#29616;&#20043;&#21069;&#40092;&#26377;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#22312;&#38889;&#35821;&#29615;&#22659;&#19979;&#12290;&#25105;&#20204;&#37319;&#29992;&#20004;&#31181;&#19981;&#21516;&#30340;&#35780;&#20272;&#35774;&#32622;&#65306;&#20256;&#32479;&#30340;&#33258;&#21160;&#35780;&#20272;&#36866;&#37197;&#30340;MCQ&#26684;&#24335;&#65292;&#20197;&#21450;&#30001;&#20154;&#31867;&#19987;&#23478;&#35780;&#20272;&#30340;&#24320;&#25918;&#24335;&#38382;&#39064;&#65288;OEQs&#65289;&#65292;&#29992;&#20197;&#26816;&#26597;LLM&#30340;&#21465;&#20107;&#22238;&#24212;&#33021;&#21147;&#65292;&#32780;&#26080;&#38656;&#39044;&#20808;&#23450;&#20041;&#36873;&#39033;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;GPT-4&#34920;&#29616;&#20248;&#24322;&#65292;&#22312;MCQ&#21644;OEQ&#35774;&#32622;&#20013;&#24471;&#20998;&#20998;&#21035;&#20026;81.11&#21644;85.69&#65292;&#32780;&#20197;&#38889;&#35821;&#20026;&#20248;&#21270;&#30446;&#26631;&#30340;HyperCLOVA X&#22312;OEQ&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#24471;&#20998;&#20026;81.56&#65292;&#19982;GPT-4&#30456;&#27604;&#65292;&#20165;&#26377;4.13&#20998;&#30340;&#24494;&#23567;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12675v1 Announce Type: new  Abstract: The current evaluation of Large Language Models (LLMs) predominantly relies on benchmarks focusing on their embedded knowledge by testing through multiple-choice questions (MCQs), a format inherently suited for automated evaluation. Our study extends this evaluation to explore LLMs' pragmatic competence--a facet previously underexamined before the advent of sophisticated LLMs, specifically in the context of Korean. We employ two distinct evaluation setups: the conventional MCQ format, adapted for automatic evaluation, and Open-Ended Questions (OEQs), assessed by human experts, to examine LLMs' narrative response capabilities without predefined options. Our findings reveal that GPT-4 excels, scoring 81.11 and 85.69 in the MCQ and OEQ setups, respectively, with HyperCLOVA X, an LLM optimized for Korean, closely following, especially in the OEQ setup, demonstrating a score of 81.56 with a marginal difference of 4.13 points compared to GPT-4
&lt;/p&gt;</description></item><item><title>ActiveRAG&#26159;&#19968;&#20010;&#21019;&#26032;&#30340;RAG&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#20027;&#21160;&#23398;&#20064;&#26426;&#21046;&#65292;&#21033;&#29992;&#30693;&#35782;&#26500;&#24314;&#21644;&#35748;&#30693;&#32852;&#32467;&#26426;&#21046;&#26469;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20869;&#22312;&#35748;&#30693;&#65292;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.13547</link><description>&lt;p&gt;
ActiveRAG: &#36890;&#36807;&#20027;&#21160;&#23398;&#20064;&#25581;&#31034;&#30693;&#35782;&#30340;&#23453;&#34255;
&lt;/p&gt;
&lt;p&gt;
ActiveRAG: Revealing the Treasures of Knowledge via Active Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13547
&lt;/p&gt;
&lt;p&gt;
ActiveRAG&#26159;&#19968;&#20010;&#21019;&#26032;&#30340;RAG&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#20027;&#21160;&#23398;&#20064;&#26426;&#21046;&#65292;&#21033;&#29992;&#30693;&#35782;&#26500;&#24314;&#21644;&#35748;&#30693;&#32852;&#32467;&#26426;&#21046;&#26469;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20869;&#22312;&#35748;&#30693;&#65292;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13547v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#33539;&#20363;&#65292;&#26377;&#21161;&#20110;&#35299;&#20915;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;RAG&#27169;&#22411;&#23558;LLMs&#23450;&#20301;&#20026;&#34987;&#21160;&#30340;&#30693;&#35782;&#25509;&#25910;&#22120;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#23398;&#20064;&#21644;&#29702;&#35299;&#22806;&#37096;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;ActiveRAG&#65292;&#23427;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;RAG&#26694;&#26550;&#65292;&#20174;&#34987;&#21160;&#30693;&#35782;&#33719;&#21462;&#36716;&#21464;&#20026;&#20027;&#21160;&#23398;&#20064;&#26426;&#21046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#30693;&#35782;&#26500;&#24314;&#26426;&#21046;&#36890;&#36807;&#23558;&#22806;&#37096;&#30693;&#35782;&#19982;&#20808;&#21069;&#33719;&#21462;&#25110;&#35760;&#24518;&#30340;&#30693;&#35782;&#30456;&#20851;&#32852;&#26469;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#22806;&#37096;&#30693;&#35782;&#12290;&#38543;&#21518;&#65292;&#23427;&#35774;&#35745;&#20102;&#35748;&#30693;&#32852;&#32467;&#26426;&#21046;&#20197;&#21512;&#24182;&#26469;&#33258;&#24605;&#32500;&#21644;&#30693;&#35782;&#26500;&#24314;&#38142;&#30340;&#25104;&#26524;&#65292;&#20174;&#32780;&#26657;&#20934;LLMs&#30340;&#20869;&#22312;&#35748;&#30693;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ActiveRAG&#36229;&#36234;&#20102;&#20808;&#21069;&#30340;RAG&#27169;&#22411;&#65292;&#22312;&#38382;&#39064;&#22238;&#31572;&#19978;&#23454;&#29616;&#20102;5%&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13547v1 Announce Type: new  Abstract: Retrieval Augmented Generation (RAG) has introduced a new paradigm for Large Language Models (LLMs), aiding in the resolution of knowledge-intensive tasks. However, current RAG models position LLMs as passive knowledge receptors, thereby restricting their capacity for learning and comprehending external knowledge. In this paper, we present ActiveRAG, an innovative RAG framework that shifts from passive knowledge acquisition to an active learning mechanism. This approach utilizes the Knowledge Construction mechanism to develop a deeper understanding of external knowledge by associating it with previously acquired or memorized knowledge. Subsequently, it designs the Cognitive Nexus mechanism to incorporate the outcomes from both chains of thought and knowledge construction, thereby calibrating the intrinsic cognition of LLMs. Our experimental results demonstrate that ActiveRAG surpasses previous RAG models, achieving a 5% improvement on qu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;LLM&#22312;&#35299;&#37322;&#34920;&#26684;&#25968;&#25454;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#27604;&#36739;&#20102;&#25991;&#26412;&#21644;&#22270;&#20687;&#34920;&#26684;&#34920;&#31034;&#23545;LLM&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#20026;&#22312;&#34920;&#26684;&#30456;&#20851;&#20219;&#21153;&#19978;&#26377;&#25928;&#20351;&#29992;LLM&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.12424</link><description>&lt;p&gt;
&#34920;&#26684;&#20316;&#20026;&#22270;&#29255;&#65311;&#25506;&#35752;LLM&#22312;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#34920;&#31034;&#19978;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;LLM&#22312;&#35299;&#37322;&#34920;&#26684;&#25968;&#25454;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#27604;&#36739;&#20102;&#25991;&#26412;&#21644;&#22270;&#20687;&#34920;&#26684;&#34920;&#31034;&#23545;LLM&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#20026;&#22312;&#34920;&#26684;&#30456;&#20851;&#20219;&#21153;&#19978;&#26377;&#25928;&#20351;&#29992;LLM&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#19981;&#21516;&#30340;&#25552;&#31034;&#31574;&#30053;&#21644;&#25968;&#25454;&#26684;&#24335;&#30740;&#31350;&#20102;&#21508;&#31181;LLM&#22312;&#35299;&#37322;&#34920;&#26684;&#25968;&#25454;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#28085;&#30422;&#20102;&#20845;&#20010;&#38024;&#23545;&#19982;&#34920;&#26684;&#30456;&#20851;&#20219;&#21153;&#30340;&#22522;&#20934;&#65292;&#22914;&#38382;&#31572;&#21644;&#20107;&#23454;&#26680;&#26597;&#12290;&#25105;&#20204;&#39318;&#27425;&#20171;&#32461;&#20102;LLM&#22312;&#22522;&#20110;&#22270;&#20687;&#30340;&#34920;&#26684;&#34920;&#31034;&#19978;&#30340;&#34920;&#29616;&#35780;&#20272;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20116;&#31181;&#22522;&#20110;&#25991;&#26412;&#21644;&#19977;&#31181;&#22522;&#20110;&#22270;&#20687;&#30340;&#34920;&#26684;&#34920;&#31034;&#65292;&#23637;&#31034;&#20102;&#34920;&#31034;&#21644;&#25552;&#31034;&#23545;LLM&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#22312;&#34920;&#26684;&#30456;&#20851;&#20219;&#21153;&#19978;&#26377;&#25928;&#20351;&#29992;LLM&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12424v1 Announce Type: cross  Abstract: In this paper, we investigate the effectiveness of various LLMs in interpreting tabular data through different prompting strategies and data formats. Our analysis extends across six benchmarks for table-related tasks such as question-answering and fact-checking. We introduce for the first time the assessment of LLMs' performance on image-based table representations. Specifically, we compare five text-based and three image-based table representations, demonstrating the influence of representation and prompting on LLM performance. Our study provides insights into the effective use of LLMs on table-related tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#25216;&#26415;&#24212;&#29992;&#20110;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#31163;&#25955;&#25552;&#31034;&#20248;&#21270;&#65292;&#20026;&#35299;&#20915;&#22870;&#21169;&#24179;&#34913;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#35270;&#35282;&#12290;</title><link>https://arxiv.org/abs/2402.11711</link><description>&lt;p&gt;
MORL-Prompt: &#31163;&#25955;&#25552;&#31034;&#20248;&#21270;&#30340;&#22810;&#30446;&#26631;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#25216;&#26415;&#24212;&#29992;&#20110;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#31163;&#25955;&#25552;&#31034;&#20248;&#21270;&#65292;&#20026;&#35299;&#20915;&#22870;&#21169;&#24179;&#34913;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;RL&#30340;&#25216;&#26415;&#21487;&#20197;&#29992;&#20110;&#25628;&#32034;&#25552;&#31034;&#65292;&#23558;&#20854;&#36755;&#20837;&#30446;&#26631;&#35821;&#35328;&#27169;&#22411;&#20197;&#26368;&#22823;&#21270;&#19968;&#32452;&#29992;&#25143;&#25351;&#23450;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#30446;&#26631;&#24212;&#29992;&#20013;&#65292;&#33258;&#28982;&#22870;&#21169;&#20989;&#25968;&#24444;&#27492;&#20043;&#38388;&#23384;&#22312;&#32039;&#24352;&#20851;&#31995;--&#20363;&#22914;&#65292;&#22312;&#39118;&#26684;&#36716;&#31227;&#20219;&#21153;&#20013;&#65292;&#20869;&#23481;&#20445;&#30041;&#19982;&#39118;&#26684;&#21305;&#37197;&#20043;&#38388;&#23384;&#22312;&#30683;&#30462;&#12290;&#24403;&#21069;&#25216;&#26415;&#20391;&#37325;&#20110;&#26368;&#22823;&#21270;&#22870;&#21169;&#20989;&#25968;&#30340;&#24179;&#22343;&#20540;&#65292;&#36825;&#26410;&#24517;&#20250;&#23548;&#33268;&#21462;&#24471;&#21508;&#31181;&#22870;&#21169;&#24179;&#34913;&#30340;&#25552;&#31034;--&#36825;&#20010;&#38382;&#39064;&#22312;&#22810;&#30446;&#26631;&#21644;&#40065;&#26834;&#20248;&#21270;&#25991;&#29486;&#20013;&#24471;&#21040;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;&#26412;&#25991;&#23558;&#20960;&#31181;&#22810;&#30446;&#26631;&#20248;&#21270;&#25216;&#26415;&#35843;&#25972;&#20026;&#22522;&#20110;RL&#30340;&#31163;&#25955;&#25552;&#31034;&#20248;&#21270;--&#20854;&#20013;&#26377;&#20004;&#31181;&#32771;&#34385;&#24085;&#32047;&#25176;&#22870;&#21169;&#38754;&#31215;&#30340;&#26041;&#27861;&#65292;&#21478;&#22806;&#19968;&#31181;&#36873;&#25321;&#26377;&#30410;&#20110;&#25152;&#26377;&#22870;&#21169;&#30340;&#26356;&#26032;&#26041;&#21521;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;NLP&#20219;&#21153;&#19978;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65306;&#39118;&#26684;&#36716;&#31227;&#21644;&#26426;&#22120;&#32763;&#35793;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11711v1 Announce Type: new  Abstract: RL-based techniques can be used to search for prompts that when fed into a target language model maximize a set of user-specified reward functions. However, in many target applications, the natural reward functions are in tension with one another -- for example, content preservation vs. style matching in style transfer tasks. Current techniques focus on maximizing the average of reward functions, which does not necessarily lead to prompts that achieve balance across rewards -- an issue that has been well-studied in the multi-objective and robust optimization literature. In this paper, we adapt several techniques for multi-objective optimization to RL-based discrete prompt optimization -- two that consider volume of the Pareto reward surface, and another that chooses an update direction that benefits all rewards simultaneously. We conduct an empirical analysis of these methods on two NLP tasks: style transfer and machine translation, each
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#22522;&#30784;&#27861;&#24459;&#25991;&#26412;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#20294;&#36890;&#36807;&#38024;&#23545;&#24615;&#24494;&#35843;&#65292;&#29978;&#33267;&#36739;&#23567;&#30340;&#27169;&#22411;&#20063;&#33021;&#22312;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#21319;&#20102;&#30456;&#20851;&#27861;&#24459;&#20219;&#21153;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2311.09693</link><description>&lt;p&gt;
BLT: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22788;&#29702;&#22522;&#30784;&#27861;&#24459;&#25991;&#26412;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
BLT: Can Large Language Models Handle Basic Legal Text?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09693
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#22522;&#30784;&#27861;&#24459;&#25991;&#26412;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#20294;&#36890;&#36807;&#38024;&#23545;&#24615;&#24494;&#35843;&#65292;&#29978;&#33267;&#36739;&#23567;&#30340;&#27169;&#22411;&#20063;&#33021;&#22312;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#21319;&#20102;&#30456;&#20851;&#27861;&#24459;&#20219;&#21153;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21457;&#29616;&#20687;GPT-4&#12289;Claude&#21644;{PaLM 2}&#36825;&#26679;&#30340;&#26368;&#22909;&#30340;&#20844;&#24320;&#21487;&#29992;&#30340;LLM&#22312;&#22788;&#29702;&#22522;&#30784;&#27861;&#24459;&#25991;&#26412;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20934;&#65292;&#20854;&#20013;&#21253;&#21547;&#24459;&#24072;&#21644;&#27861;&#24459;&#21161;&#29702;&#26399;&#26395;LLM&#38646;-shot&#22788;&#29702;&#30340;&#20219;&#21153;&#65292;&#27604;&#22914;&#26597;&#25214;&#35777;&#35789;&#25991;&#20214;&#30340;&#26576;&#19968;&#34892;&#25110;&#21512;&#21516;&#30340;&#26576;&#20010;&#23376;&#37096;&#20998;&#30340;&#25991;&#26412;&#12290;LLM&#22312;&#36825;&#20010;&#22522;&#20934;&#19978;&#30340;&#24046;&#21170;&#34920;&#29616;&#23545;&#23427;&#20204;&#22312;&#27861;&#24459;&#23454;&#36341;&#20013;&#30340;&#21487;&#38752;&#24615;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;&#36825;&#20123;&#20219;&#21153;&#36827;&#34892;&#24494;&#35843;&#29978;&#33267;&#20351;&#19968;&#20010;&#36739;&#23567;&#30340;&#27169;&#22411;&#22312;&#25105;&#20204;&#30340;&#27979;&#35797;&#38598;&#19978;&#34920;&#29616;&#25509;&#36817;&#23436;&#32654;&#65292;&#24182;&#19988;&#36824;&#25552;&#21319;&#20102;&#30456;&#20851;&#27861;&#24459;&#20219;&#21153;&#30340;&#34920;&#29616;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#35768;&#22810;&#39046;&#22495;&#25152;&#38656;&#30340;&#31616;&#21333;&#34892;&#20026;&#22312;&#22522;&#30784;LLM&#20013;&#21487;&#33021;&#19981;&#23384;&#22312;&#65292;&#38500;&#38750;&#26377;&#39046;&#22495;&#19987;&#23478;&#30340;&#39069;&#22806;&#21442;&#19982;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09693v2 Announce Type: replace-cross  Abstract: We find that the best publicly available LLMs like GPT-4, Claude, and {PaLM 2} currently perform poorly at basic legal text handling. We introduce a benchmark consisting of tasks that lawyers and paralegals would expect LLMs to handle zero-shot, such as looking up the text at a line of a witness deposition or at a subsection of a contract. LLMs' poor performance on this benchmark casts into doubt their reliability as-is for legal practice. However, fine-tuning for these tasks brings even a smaller model to near-perfect performance on our test set and also raises performance on a related legal task. These results suggest that many simple behaviors needed for a domain may not be present in foundational LLMs, without additional engagement from subject matter experts.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25511;&#21046;&#23454;&#39564;&#29615;&#22659;&#30340;&#26041;&#24335;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#22312;&#23646;&#24615;&#32487;&#25215;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#19968;&#23450;&#30340;&#38750;&#24179;&#20961;&#33021;&#21147;&#65292;&#20294;&#36825;&#31181;&#33021;&#21147;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;</title><link>http://arxiv.org/abs/2401.06640</link><description>&lt;p&gt;
&#23454;&#39564;&#29615;&#22659;&#33021;&#22815;&#20419;&#36827;&#35821;&#35328;&#27169;&#22411;&#22312;&#31283;&#20581;&#30340;&#35821;&#20041;&#23646;&#24615;&#25512;&#26029;&#20013;&#30340;&#34920;&#29616;&#65292;&#20294;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently. (arXiv:2401.06640v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06640
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25511;&#21046;&#23454;&#39564;&#29615;&#22659;&#30340;&#26041;&#24335;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#22312;&#23646;&#24615;&#32487;&#25215;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#19968;&#23450;&#30340;&#38750;&#24179;&#20961;&#33021;&#21147;&#65292;&#20294;&#36825;&#31181;&#33021;&#21147;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#26080;&#20154;&#30417;&#30563;&#35780;&#20272;&#20984;&#26174;&#20102;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#22312;&#25191;&#34892;&#24847;&#20041;&#25552;&#21462;&#26041;&#38754;&#30340;&#37325;&#35201;&#38480;&#21046;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#22312;&#24341;&#20837;&#23454;&#39564;&#29615;&#22659;&#65288;&#22914;&#19978;&#19979;&#25991;&#31034;&#20363;&#21644;&#25351;&#23548;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;LMs&#30340;&#34920;&#29616;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#12290;&#37027;&#20040;&#36825;&#26159;&#21542;&#36866;&#29992;&#20110;&#20808;&#21069;&#30740;&#31350;&#30340;&#24847;&#20041;&#25935;&#24863;&#20219;&#21153;&#21602;&#65311;&#25105;&#20204;&#22312;&#25511;&#21046;&#19978;&#19979;&#25991;&#31034;&#20363;&#21644;&#25351;&#23548;&#20869;&#23481;&#30340;&#21069;&#25552;&#19979;&#65292;&#23545;&#23454;&#39564;&#29615;&#22659;&#23545;&#20110;&#25552;&#39640;LMs&#22312;&#25191;&#34892;&#23646;&#24615;&#32487;&#25215;&#20219;&#21153;&#20013;&#30340;&#40065;&#26834;&#24615;&#30340;&#31243;&#24230;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#65292;&#35813;&#20219;&#21153;&#26159;&#39044;&#20808;&#34920;&#26126;LMs&#26080;&#27861;&#23436;&#25104;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#23454;&#39564;&#29615;&#22659;&#30830;&#23454;&#21487;&#20197;&#23548;&#33268;LMs&#22312;&#23646;&#24615;&#32487;&#25215;&#34892;&#20026;&#26041;&#38754;&#34920;&#29616;&#20986;&#38750;&#24179;&#20961;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#33021;&#21147;&#26159;&#19981;&#19968;&#33268;&#30340;&#65306;&#36890;&#36807;&#23545;&#20219;&#21153;&#36827;&#34892;&#26368;&#23567;&#25913;&#20889;&#65292;&#21457;&#29616;&#19968;&#20123;LMs&#20174;&#36755;&#20837;&#20013;&#25429;&#25417;&#21040;&#27973;&#23618;&#30340;&#38750;&#35821;&#20041;&#24335;&#21551;&#21457;&#24335;&#20449;&#24687;&#65292;&#36825;&#34920;&#26126;&#35745;&#31639;&#26426;&#30340;&#34892;&#20026;&#20855;&#26377;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent zero-shot evaluations have highlighted important limitations in the abilities of language models (LMs) to perform meaning extraction. However, it is now well known that LMs can demonstrate radical improvements in the presence of experimental contexts such as in-context examples and instructions. How well does this translate to previously studied meaning-sensitive tasks? We present a case-study on the extent to which experimental contexts can improve LMs' robustness in performing property inheritance -- predicting semantic properties of novel concepts, a task that they have been previously shown to fail on. Upon carefully controlling the nature of the in-context examples and the instructions, our work reveals that they can indeed lead to non-trivial property inheritance behavior in LMs. However, this ability is inconsistent: with a minimal reformulation of the task, some LMs were found to pick up on shallow, non-semantic heuristics from their inputs, suggesting that the computati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;ChatGPT&#36827;&#34892;&#31435;&#22330;&#26816;&#27979;&#20013;&#65292;&#26080;&#21442;&#25968;&#30340;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#35777;&#26126;&#20854;&#34920;&#29616;&#20248;&#36234;&#65292;&#24182;&#25506;&#35752;&#20102;&#30456;&#20851;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2304.03087</link><description>&lt;p&gt;
&#21033;&#29992;ChatGPT&#25506;&#31350;&#24605;&#32500;&#38142;&#22312;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#31435;&#22330;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media. (arXiv:2304.03087v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;ChatGPT&#36827;&#34892;&#31435;&#22330;&#26816;&#27979;&#20013;&#65292;&#26080;&#21442;&#25968;&#30340;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#35777;&#26126;&#20854;&#34920;&#29616;&#20248;&#36234;&#65292;&#24182;&#25506;&#35752;&#20102;&#30456;&#20851;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31435;&#22330;&#26816;&#27979;&#26159;&#39044;&#27979;&#25991;&#26412;&#20013;&#38024;&#23545;&#30446;&#26631;&#30340;&#24577;&#24230;&#65292;&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#30340;&#20852;&#36215;&#24050;&#21463;&#21040;&#20851;&#27880;&#12290;&#20256;&#32479;&#26041;&#27861;&#21253;&#25324;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#12289;&#26089;&#26399;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#39044;&#35757;&#32451;&#24494;&#35843;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#38750;&#24120;&#22823;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;VLPLMs&#65289;&#22914;ChatGPT&#65288;GPT-3.5&#65289;&#30340;&#21457;&#23637;&#65292;&#20256;&#32479;&#26041;&#27861;&#38754;&#20020;&#37096;&#32626;&#25361;&#25112;&#12290;&#19981;&#38656;&#35201;&#21453;&#21521;&#20256;&#25773;&#35757;&#32451;&#30340;&#26080;&#21442;&#25968;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#26041;&#27861;&#24050;&#25104;&#20026;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;CoT&#22312;&#31435;&#22330;&#26816;&#27979;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#30340;&#31934;&#24230;&#24182;&#35752;&#35770;&#20102;&#30456;&#20851;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media. Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models. However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative. This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges.
&lt;/p&gt;</description></item></channel></rss>