<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Zigzag Mamba&#30340;&#38646;&#21442;&#25968;&#26041;&#27861;&#65292;&#36890;&#36807;&#32416;&#27491;&#24403;&#21069;Mamba-based&#35270;&#35273;&#26041;&#27861;&#20013;&#23545;&#31354;&#38388;&#36830;&#32493;&#24615;&#30340;&#24573;&#35270;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#36895;&#24230;&#21644;&#20869;&#23384;&#21033;&#29992;&#65292;&#21516;&#26102;&#22312;&#22823;&#20998;&#36776;&#29575;&#35270;&#35273;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13802</link><description>&lt;p&gt;
ZigMa&#65306;&#34623;&#34578;&#26364;&#24052;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ZigMa: Zigzag Mamba Diffusion Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Zigzag Mamba&#30340;&#38646;&#21442;&#25968;&#26041;&#27861;&#65292;&#36890;&#36807;&#32416;&#27491;&#24403;&#21069;Mamba-based&#35270;&#35273;&#26041;&#27861;&#20013;&#23545;&#31354;&#38388;&#36830;&#32493;&#24615;&#30340;&#24573;&#35270;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#36895;&#24230;&#21644;&#20869;&#23384;&#21033;&#29992;&#65292;&#21516;&#26102;&#22312;&#22823;&#20998;&#36776;&#29575;&#35270;&#35273;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#21463;&#21040;&#21487;&#20280;&#32553;&#24615;&#21644;&#20108;&#27425;&#22797;&#26434;&#24615;&#38382;&#39064;&#30340;&#22256;&#25200;&#65292;&#29305;&#21035;&#26159;&#22312;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#32467;&#26500;&#20869;&#37096;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#21033;&#29992;&#19968;&#31181;&#31216;&#20026;&#26364;&#24052;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#38271;&#24207;&#21015;&#24314;&#27169;&#33021;&#21147;&#65292;&#20197;&#25193;&#23637;&#20854;&#22312;&#35270;&#35273;&#25968;&#25454;&#29983;&#25104;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#22823;&#22810;&#25968;&#24403;&#21069;&#22522;&#20110;&#26364;&#24052;&#30340;&#35270;&#35273;&#26041;&#27861;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#30095;&#24573;&#65292;&#21363;&#26364;&#24052;&#30340;&#25195;&#25551;&#26041;&#26696;&#20013;&#32570;&#20047;&#23545;&#31354;&#38388;&#36830;&#32493;&#24615;&#30340;&#32771;&#34385;&#12290;&#20854;&#27425;&#65292;&#22522;&#20110;&#36825;&#19968;&#27934;&#23519;&#21147;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Zigzag Mamba&#30340;&#31616;&#21333;&#12289;&#21363;&#25554;&#21363;&#29992;&#12289;&#38646;&#21442;&#25968;&#26041;&#27861;&#65292;&#23427;&#20248;&#20110;&#22522;&#20110;&#26364;&#24052;&#30340;&#22522;&#32447;&#65292;&#24182;&#34920;&#29616;&#20986;&#27604;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#22522;&#32447;&#26356;&#24555;&#36895;&#21644;&#26356;&#22909;&#30340;&#20869;&#23384;&#21033;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;Zigzag Mamba&#38598;&#25104;&#21040;&#38543;&#26426;&#25554;&#20540;&#26694;&#26550;&#20013;&#65292;&#20197;&#30740;&#31350;&#27169;&#22411;&#22312;&#22823;&#20998;&#36776;&#29575;&#35270;&#35273;&#25968;&#25454;&#38598;&#65288;&#20363;&#22914;FacesHQ $1024\times 1024$&#21644;UCF101&#65292;MultiModal-CelebA-HQ&#65289;&#19978;&#30340;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13802v1 Announce Type: cross  Abstract: The diffusion model has long been plagued by scalability and quadratic complexity issues, especially within transformer-based structures. In this study, we aim to leverage the long sequence modeling capability of a State-Space Model called Mamba to extend its applicability to visual data generation. Firstly, we identify a critical oversight in most current Mamba-based vision methods, namely the lack of consideration for spatial continuity in the scan scheme of Mamba. Secondly, building upon this insight, we introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba, which outperforms Mamba-based baselines and demonstrates improved speed and memory utilization compared to transformer-based baselines. Lastly, we integrate Zigzag Mamba with the Stochastic Interpolant framework to investigate the scalability of the model on large-resolution visual datasets, such as FacesHQ $1024\times 1024$ and UCF101, MultiModal-CelebA-HQ
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#65292;&#23454;&#39564;&#32467;&#26524;&#26377;&#21161;&#20110;&#25552;&#20986;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;</title><link>https://arxiv.org/abs/2403.11793</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65306;&#23545;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#30340;&#28145;&#20837;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11793
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#65292;&#23454;&#39564;&#32467;&#26524;&#26377;&#21161;&#20110;&#25552;&#20986;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25512;&#29702;&#33021;&#21147;&#30340;&#29616;&#26377;&#26041;&#27861;&#20197;&#32467;&#26524;&#20026;&#20013;&#24515;&#65292;&#20351;&#24471;&#35780;&#20272;&#25512;&#29702;&#36807;&#31243;&#21464;&#24471;&#22256;&#38590;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#25968;&#25454;&#38598;&#20197;&#36807;&#31243;&#20026;&#20013;&#24515;&#30340;&#26041;&#24335;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#12290;ARC&#35201;&#27714;&#35299;&#20915;&#38382;&#39064;&#26102;&#20855;&#26377;&#20005;&#35880;&#30340;&#36923;&#36753;&#32467;&#26500;&#65292;&#36825;&#20351;&#24471;&#23427;&#25104;&#20026;&#19968;&#20010;&#33021;&#22815;&#20419;&#36827;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#19982;&#20154;&#31867;&#36827;&#34892;&#27604;&#36739;&#30340;&#22522;&#20934;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#65292;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#36739;&#24369;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#36923;&#36753;&#36830;&#36143;&#24615;&#12289;&#32452;&#21512;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20173;&#28982;&#33853;&#21518;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#31361;&#26174;&#20102;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11793v1 Announce Type: cross  Abstract: The existing methods for evaluating the inference abilities of Large Language Models (LLMs) have been results-centric, making it difficult to assess the inference process. We introduce a new approach using the Abstract and Reasoning Corpus (ARC) dataset to evaluate the inference and contextual understanding abilities of large language models in a process-centric manner. ARC demands rigorous logical structures for problem-solving, making it a benchmark that facilitates the comparison of model inference abilities with humans. Experimental results confirm that while large language models possess weak inference abilities, they still lag in terms of logical coherence, compositionality, and productivity. Our experiments highlight the reasoning capabilities of LLMs, proposing development paths for achieving human-level reasoning.
&lt;/p&gt;</description></item><item><title>&#22312;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#20381;&#27425;&#24494;&#35843;&#30340;LLMs&#34920;&#29616;&#20986;&#39044;&#26399;&#34892;&#20026;&#65292;&#33021;&#22815;&#20174;&#36951;&#24536;&#20013;&#24674;&#22797;&#65292;&#25581;&#31034;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#26032;&#35265;&#35299;</title><link>https://arxiv.org/abs/2403.09613</link><description>&lt;p&gt;
&#36890;&#36807;&#32467;&#26500;&#21270;&#35757;&#32451;&#37325;&#26032;&#21796;&#37266;&#30693;&#35782;&#65306;&#20174;&#28798;&#38590;&#24615;&#24178;&#25200;&#20013;&#36827;&#34892;&#39044;&#26399;&#24615;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Reawakening knowledge: Anticipatory recovery from catastrophic interference via structured training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09613
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#20381;&#27425;&#24494;&#35843;&#30340;LLMs&#34920;&#29616;&#20986;&#39044;&#26399;&#34892;&#20026;&#65292;&#33021;&#22815;&#20174;&#36951;&#24536;&#20013;&#24674;&#22797;&#65292;&#25581;&#31034;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#26032;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#20854;&#20013;&#25991;&#26723;&#20197;&#22266;&#23450;&#37325;&#22797;&#24207;&#21015;&#30340;&#26041;&#24335;&#21576;&#29616;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22312;&#19968;&#31995;&#21015;&#25991;&#26723;&#19978;&#35757;&#32451;&#26102;&#65292;&#32593;&#32476;&#20250;&#36973;&#21463;&#28798;&#38590;&#24615;&#24178;&#25200;&#65307;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#20381;&#27425;&#24494;&#35843;&#30340;LLMs&#34920;&#29616;&#20986;&#19968;&#31181;&#22855;&#29305;&#19988;&#21331;&#36234;&#30340;&#29305;&#24615;&#65306;&#23427;&#20204;&#34920;&#29616;&#20986;&#39044;&#26399;&#30340;&#34892;&#20026;&#65292;&#22312;&#20877;&#27425;&#36935;&#21040;&#20043;&#21069;&#30340;&#25991;&#26723;&#26102;&#20174;&#36951;&#24536;&#20013;&#24674;&#22797;&#36807;&#26469;&#12290;&#36825;&#31181;&#34892;&#20026;&#22312;&#26550;&#26500;&#25193;&#23637;&#20854;&#21442;&#25968;&#25968;&#37327;&#26102;&#36880;&#28176;&#20986;&#29616;&#24182;&#21464;&#24471;&#26356;&#21152;&#31283;&#20581;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23454;&#39564;&#21644;&#21487;&#35270;&#21270;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#22312;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#35757;&#32451;&#36229;&#21442;&#25968;&#32593;&#32476;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09613v1 Announce Type: cross  Abstract: We explore the training dynamics of neural networks in a structured non-IID setting where documents are presented cyclically in a fixed, repeated sequence. Typically, networks suffer from catastrophic interference when training on a sequence of documents; however, we discover a curious and remarkable property of LLMs fine-tuned sequentially in this setting: they exhibit anticipatory behavior, recovering from the forgetting on documents before encountering them again. The behavior emerges and becomes more robust as the architecture scales up its number of parameters. Through comprehensive experiments and visualizations, we uncover new insights into training over-parameterized networks in structured environments.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20174;&#31038;&#20132;&#23186;&#20307;&#30340;&#25991;&#26412;&#20013;&#35745;&#31639;&#24773;&#32490;&#32454;&#31890;&#24230;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20854;&#22312;&#24515;&#29702;&#20581;&#24247;&#26465;&#20214;&#20013;&#20316;&#20026;&#25351;&#26631;&#30340;&#26377;&#25928;&#24615;</title><link>https://arxiv.org/abs/2403.02281</link><description>&lt;p&gt;
&#25991;&#26412;&#20013;&#30340;&#24773;&#32490;&#32454;&#31890;&#24230;&#65306;&#24515;&#29702;&#20581;&#24247;&#30340;&#27719;&#24635;&#32423;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02281
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20174;&#31038;&#20132;&#23186;&#20307;&#30340;&#25991;&#26412;&#20013;&#35745;&#31639;&#24773;&#32490;&#32454;&#31890;&#24230;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20854;&#22312;&#24515;&#29702;&#20581;&#24247;&#26465;&#20214;&#20013;&#20316;&#20026;&#25351;&#26631;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24773;&#32490;&#23545;&#22609;&#36896;&#25105;&#20204;&#30340;&#32463;&#21382;&#20013;&#26377;&#20849;&#21516;&#28857;&#65292;&#28982;&#32780;&#65292;&#27599;&#20010;&#20154;&#22312;&#22914;&#20309;&#35782;&#21035;&#12289;&#20998;&#31867;&#21644;&#34920;&#36798;&#24773;&#32490;&#26041;&#38754;&#26377;&#24456;&#22823;&#24046;&#24322;&#12290;&#22312;&#24515;&#29702;&#23398;&#20013;&#65292;&#20010;&#20307;&#21306;&#20998;&#24773;&#32490;&#27010;&#24565;&#30340;&#33021;&#21147;&#21464;&#21270;&#34987;&#31216;&#20026;&#24773;&#32490;&#32454;&#31890;&#24230;&#65288;&#36890;&#36807;&#20010;&#20307;&#23545;&#33258;&#24049;&#24773;&#32490;&#30340;&#33258;&#25105;&#25253;&#21578;&#26469;&#30830;&#23450;&#65289;&#12290;&#39640;&#24773;&#32490;&#32454;&#31890;&#24230;&#24050;&#19982;&#26356;&#22909;&#30340;&#24515;&#29702;&#21644;&#36523;&#20307;&#20581;&#24247;&#32852;&#31995;&#22312;&#19968;&#36215;&#65307;&#32780;&#20302;&#24773;&#32490;&#32454;&#31890;&#24230;&#24050;&#19982;&#24212;&#28608;&#24773;&#32490;&#35843;&#33410;&#31574;&#30053;&#21644;&#19981;&#33391;&#20581;&#24247;&#32467;&#26524;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20174;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#26102;&#38388;&#39034;&#24207;&#28436;&#35762;&#32773;&#35805;&#35821;&#20013;&#35745;&#31639;&#24773;&#32490;&#32454;&#31890;&#24230;&#30340;&#35745;&#31639;&#26041;&#27861;&#65288;&#20195;&#26367;&#21508;&#31181;&#20559;&#35265;&#30340;&#33258;&#25105;&#25253;&#21578;&#65289;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#36825;&#31181;&#25991;&#26412;&#34893;&#29983;&#24773;&#32490;&#32454;&#31890;&#24230;&#25514;&#26045;&#22312;&#20316;&#20026;&#21508;&#31181;&#24515;&#29702;&#20581;&#24247;&#26465;&#20214;&#65288;MHCs&#65289;&#30340;&#26631;&#35760;&#26102;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#24773;&#32490;&#32454;&#31890;&#24230;&#30340;&#22522;&#32447;&#25514;&#26045;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02281v1 Announce Type: new  Abstract: We are united in how emotions are central to shaping our experiences; and yet, individuals differ greatly in how we each identify, categorize, and express emotions. In psychology, variation in the ability of individuals to differentiate between emotion concepts is called emotion granularity (determined through self-reports of one's emotions). High emotion granularity has been linked with better mental and physical health; whereas low emotion granularity has been linked with maladaptive emotion regulation strategies and poor health outcomes. In this work, we propose computational measures of emotion granularity derived from temporally-ordered speaker utterances in social media (in lieu of self-reports that suffer from various biases). We then investigate the effectiveness of such text-derived measures of emotion granularity in functioning as markers of various mental health conditions (MHCs). We establish baseline measures of emotion gran
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#22788;&#29702;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#30340;&#26041;&#27861;&#65292;&#23454;&#26045;&#20102;&#20351;&#29992;&#29109;&#20998;&#25968;&#21644;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#26469;&#25351;&#23548;&#27169;&#22411;&#30340;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#35777;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30456;&#23545;&#20110;&#25932;&#23545;&#29702;&#30001;&#30340;&#31283;&#20581;&#24615;&#33021;&#20248;&#21183;</title><link>https://arxiv.org/abs/2402.14337</link><description>&lt;p&gt;
AURA&#65306;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#30340;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
AURA: Natural Language Reasoning for Aleatoric Uncertainty in Rationales
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14337
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#22788;&#29702;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#30340;&#26041;&#27861;&#65292;&#23454;&#26045;&#20102;&#20351;&#29992;&#29109;&#20998;&#25968;&#21644;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#26469;&#25351;&#23548;&#27169;&#22411;&#30340;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#35777;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30456;&#23545;&#20110;&#25932;&#23545;&#29702;&#30001;&#30340;&#31283;&#20581;&#24615;&#33021;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#31574;&#32972;&#21518;&#30340;&#29702;&#30001;&#19981;&#20165;&#35299;&#37322;&#20102;&#27169;&#22411;&#20915;&#31574;&#65292;&#32780;&#19988;&#25552;&#21319;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#33719;&#24471;&#26080;&#25032;&#21487;&#20987;&#30340;&#29702;&#30001;&#36890;&#24120;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#27492;&#22806;&#65292;&#20272;&#35745;&#29702;&#30001;&#36275;&#22815;&#24544;&#23454;&#20197;&#40723;&#21169;&#27169;&#22411;&#34920;&#29616;&#30340;&#31243;&#24230;&#24182;&#19981;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#25512;&#29702;&#20219;&#21153;&#36890;&#24120;&#36843;&#20351;&#27169;&#22411;&#22312;&#19981;&#29702;&#24819;&#30340;&#29702;&#30001;&#19979;&#36755;&#20986;&#27491;&#30830;&#31572;&#26696;&#65292;&#24182;&#19988;&#19982;&#27169;&#22411;&#23436;&#20840;&#26377;&#33021;&#21147;&#30340;&#24773;&#20917;&#30456;&#27604;&#26159;&#27425;&#20248;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22914;&#20309;&#24212;&#23545;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#12290;&#25105;&#20204;&#39318;&#20808;&#29992;&#32473;&#23450;&#29702;&#30001;&#30340;&#29109;&#20998;&#25968;&#26469;&#23450;&#20041;&#27169;&#31946;&#30340;&#29702;&#30001;&#65292;&#20351;&#29992;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#20316;&#20026;&#20449;&#24687;&#37327;&#12290;&#28982;&#21518;&#26681;&#25454;&#29702;&#30001;&#30340;&#27169;&#31946;&#24615;&#26469;&#24341;&#23548;&#27169;&#22411;&#36873;&#25321;&#20004;&#31181;&#19981;&#21516;&#30340;&#25512;&#29702;&#27169;&#22411;&#20013;&#30340;&#19968;&#31181;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#19978;&#35770;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#29702;&#30001;&#30340;&#25932;&#23545;&#36136;&#37327;&#20135;&#29983;&#20102;&#31283;&#20581;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14337v1 Announce Type: new  Abstract: Rationales behind answers not only explain model decisions but boost language models to reason well on complex reasoning tasks. However, obtaining impeccable rationales is often impossible. Besides, it is non-trivial to estimate the degree to which the rationales are faithful enough to encourage model performance. Thus, such reasoning tasks often compel models to output correct answers under undesirable rationales and are sub-optimal compared to what the models are fully capable of. In this work, we propose how to deal with imperfect rationales causing aleatoric uncertainty. We first define the ambiguous rationales with entropy scores of given rationales, using model prior beliefs as informativeness. We then guide models to select one of two different reasoning models according to the ambiguity of rationales. We empirically argue that our proposed method produces robust performance superiority against the adversarial quality of rationale
&lt;/p&gt;</description></item><item><title>TinyLLM&#26159;&#19968;&#31181;&#20174;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23398;&#20064;&#23567;&#22411;&#23398;&#29983;&#27169;&#22411;&#30340;&#30693;&#35782;&#33976;&#39311;&#33539;&#24335;&#65292;&#26088;&#22312;&#35299;&#20915;&#30693;&#35782;&#22810;&#26679;&#24615;&#26377;&#38480;&#21644;&#32570;&#20047;&#19978;&#19979;&#25991;&#20449;&#24687;&#31561;&#38382;&#39064;&#65292;&#24182;&#40723;&#21169;&#23398;&#29983;&#27169;&#22411;&#29702;&#35299;&#31572;&#26696;&#32972;&#21518;&#30340;&#21407;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.04616</link><description>&lt;p&gt;
TinyLLM: &#20174;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#19968;&#20010;&#23567;&#22411;&#23398;&#29983;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
TinyLLM: Learning a Small Student from Multiple Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04616
&lt;/p&gt;
&lt;p&gt;
TinyLLM&#26159;&#19968;&#31181;&#20174;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23398;&#20064;&#23567;&#22411;&#23398;&#29983;&#27169;&#22411;&#30340;&#30693;&#35782;&#33976;&#39311;&#33539;&#24335;&#65292;&#26088;&#22312;&#35299;&#20915;&#30693;&#35782;&#22810;&#26679;&#24615;&#26377;&#38480;&#21644;&#32570;&#20047;&#19978;&#19979;&#25991;&#20449;&#24687;&#31561;&#38382;&#39064;&#65292;&#24182;&#40723;&#21169;&#23398;&#29983;&#27169;&#22411;&#29702;&#35299;&#31572;&#26696;&#32972;&#21518;&#30340;&#21407;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26356;&#24378;&#22823;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#36716;&#31227;&#21040;&#36739;&#23567;&#30340;&#27169;&#22411;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#36739;&#23567;&#30340;LLMs&#26356;&#28789;&#27963;&#65292;&#25104;&#26412;&#26356;&#20302;&#12290;&#22312;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#20013;&#65292;&#30693;&#35782;&#33976;&#39311;&#22240;&#20854;&#20986;&#33394;&#30340;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#32780;&#33073;&#39062;&#32780;&#20986;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#32570;&#28857;&#65292;&#21253;&#25324;&#30693;&#35782;&#22810;&#26679;&#24615;&#26377;&#38480;&#21644;&#32570;&#20047;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#24182;&#20419;&#36827;&#32039;&#20945;&#35821;&#35328;&#27169;&#22411;&#30340;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TinyLLM&#65292;&#19968;&#31181;&#20174;&#22810;&#20010;&#22823;&#22411;&#25945;&#24072;LLMs&#20013;&#23398;&#20064;&#23567;&#22411;&#23398;&#29983;LLM&#30340;&#26032;&#22411;&#30693;&#35782;&#33976;&#39311;&#33539;&#24335;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#40723;&#21169;&#23398;&#29983;LLM&#19981;&#20165;&#29983;&#25104;&#27491;&#30830;&#31572;&#26696;&#65292;&#32780;&#19988;&#29702;&#35299;&#36825;&#20123;&#31572;&#26696;&#32972;&#21518;&#30340;&#21407;&#29702;&#12290;&#37492;&#20110;&#19981;&#21516;&#30340;LLMs&#20855;&#26377;&#19981;&#21516;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#23548;&#23398;&#29983;&#27169;&#22411;&#21560;&#25910;&#26469;&#33258;&#22810;&#20010;&#25945;&#24072;LLMs&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24341;&#20837;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#31034;&#20363;&#29983;&#25104;&#22120;&#21644;&#19968;&#20010;&#32769;&#24072;&#24378;&#21046;&#27169;&#22359;...
&lt;/p&gt;
&lt;p&gt;
Transferring the reasoning capability from stronger large language models (LLMs) to smaller ones has been quite appealing, as smaller LLMs are more flexible to deploy with less expense. Among the existing solutions, knowledge distillation stands out due to its outstanding efficiency and generalization. However, existing methods suffer from several drawbacks, including limited knowledge diversity and the lack of rich contextual information. To solve the problems and facilitate the learning of compact language models, we propose TinyLLM, a novel knowledge distillation paradigm to learn a small student LLM from multiple large teacher LLMs. In particular, we encourage the student LLM to not only generate the correct answers but also understand the rationales behind these answers. Given that different LLMs possess diverse reasoning skills, we guide the student model to assimilate knowledge from various teacher LLMs. We further introduce an in-context example generator and a teacher-forcing 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Octavius&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;MoE&#21644;LoRA&#25216;&#26415;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;LLM&#35299;&#30721;&#22120;LoRA-MoE&#65292;&#29992;&#20110;&#22810;&#27169;&#24577;&#23398;&#20064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#21508;&#31181;2D&#21644;3D&#19979;&#28216;&#20219;&#21153;&#20013;&#20855;&#26377;&#32422;20%&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2311.02684</link><description>&lt;p&gt;
Octavius&#65306;&#36890;&#36807;MoE&#20943;&#36731;MLLM&#20013;&#30340;&#20219;&#21153;&#24178;&#25200;
&lt;/p&gt;
&lt;p&gt;
Octavius: Mitigating Task Interference in MLLMs via MoE
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02684
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Octavius&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;MoE&#21644;LoRA&#25216;&#26415;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;LLM&#35299;&#30721;&#22120;LoRA-MoE&#65292;&#29992;&#20110;&#22810;&#27169;&#24577;&#23398;&#20064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#21508;&#31181;2D&#21644;3D&#19979;&#28216;&#20219;&#21153;&#20013;&#20855;&#26377;&#32422;20%&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21487;&#20197;&#36890;&#36807;&#25351;&#23548;&#35843;&#25972;&#23558;&#23427;&#20204;&#30340;&#38646;-shot&#27867;&#21270;&#33021;&#21147;&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#23398;&#20064;&#12290;&#38543;&#30528;&#24341;&#20837;&#26356;&#22810;&#30340;&#24418;&#24335;&#21644;&#19979;&#28216;&#20219;&#21153;&#65292;&#36127;&#38754;&#20914;&#31361;&#21644;&#24178;&#25200;&#21487;&#33021;&#23545;&#24615;&#33021;&#20135;&#29983;&#26356;&#20005;&#37325;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#36825;&#31181;&#29616;&#35937;&#22312;&#20197;&#21069;&#30340;&#24037;&#20316;&#20013;&#34987;&#24573;&#35270;&#20102;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;\mname &#30340;&#26032;&#39062;&#19988;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#19982;Multimodal Large Language Models&#65288;MLLMs&#65289;&#19968;&#36215;&#36827;&#34892;&#22810;&#27169;&#24577;&#23398;&#20064;&#30340;&#20840;&#38754;&#30740;&#31350;&#21644;&#23454;&#39564;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32467;&#21512;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#19987;&#23478;&#28151;&#21512;&#65288;MoE&#65289;&#21644;&#20195;&#34920;&#24615;PEFT&#25216;&#26415;&#20043;&#19968;&#65292;&#21363;LoRA&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;LLM&#30340;&#35299;&#30721;&#22120;&#65292;&#31216;&#20026;LoRA-MoE&#65292;&#29992;&#20110;&#22810;&#27169;&#24577;&#23398;&#20064;&#12290;&#23454;&#39564;&#32467;&#26524;&#65288;&#32422;20\%&#30340;&#25913;&#36827;&#65289;&#34920;&#26126;&#20102;&#25105;&#20204;&#35774;&#35745;&#22312;&#21508;&#31181;2D&#21644;3D&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#21644;&#22810;&#21151;&#33021;&#24615;&#12290;&#20195;&#30721;&#21644;&#30456;&#24212;&#25968;&#25454;&#38598;&#23558;&#24456;&#24555;&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02684v1 Announce Type: cross  Abstract: Recent studies have demonstrated Large Language Models (LLMs) can extend their zero-shot generalization capabilities to multimodal learning through instruction tuning. As more modalities and downstream tasks are introduced, negative conflicts and interference may have a worse impact on performance. While this phenomenon has been overlooked in previous work, we propose a novel and extensible framework, called \mname, for comprehensive studies and experimentation on multimodal learning with Multimodal Large Language Models (MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and one of the representative PEFT techniques, \emph{i.e.,} LoRA, designing a novel LLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental results (about 20\% improvement) have shown the effectiveness and versatility of our design in various 2D and 3D downstream tasks. Code and corresponding dataset will be available soon.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#20998;&#31867;&#27861;&#65292;&#23558;&#25991;&#26412;&#20998;&#31867;&#31639;&#27861;&#23618;&#27425;&#21270;&#22320;&#20998;&#20026;&#31934;&#32454;&#30340;&#31867;&#21035;&#21644;&#20855;&#20307;&#25216;&#26415;&#65292;&#29992;&#20197;&#35299;&#20915;&#29616;&#26377;&#32508;&#36848;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12982</link><description>&lt;p&gt;
&#25991;&#26412;&#20998;&#31867;&#65306;&#19968;&#39033;&#22238;&#39038;&#12289;&#23454;&#35777;&#21644;&#23454;&#39564;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Text Classification: A Review, Empirical, and Experimental Evaluation. (arXiv:2401.12982v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#20998;&#31867;&#27861;&#65292;&#23558;&#25991;&#26412;&#20998;&#31867;&#31639;&#27861;&#23618;&#27425;&#21270;&#22320;&#20998;&#20026;&#31934;&#32454;&#30340;&#31867;&#21035;&#21644;&#20855;&#20307;&#25216;&#26415;&#65292;&#29992;&#20197;&#35299;&#20915;&#29616;&#26377;&#32508;&#36848;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#30340;&#29190;&#28856;&#24615;&#21644;&#24191;&#27867;&#22686;&#38271;&#20351;&#24471;&#20351;&#29992;&#25991;&#26412;&#20998;&#31867;&#20174;&#22823;&#37327;&#25968;&#25454;&#20013;&#25552;&#21462;&#20851;&#38190;&#20449;&#24687;&#25104;&#20026;&#24517;&#35201;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#32463;&#20856;&#21644;&#28145;&#24230;&#23398;&#20064;&#30340;&#25991;&#26412;&#20998;&#31867;&#26041;&#27861;&#30340;&#30740;&#31350;&#20986;&#29616;&#20102;&#28608;&#22686;&#12290;&#23613;&#31649;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#65292;&#20294;&#20173;&#28982;&#36843;&#20999;&#38656;&#35201;&#19968;&#20221;&#20840;&#38754;&#21644;&#26368;&#26032;&#30340;&#32508;&#36848;&#12290;&#29616;&#26377;&#30340;&#32508;&#36848;&#25991;&#31456;&#23558;&#25991;&#26412;&#20998;&#31867;&#31639;&#27861;&#20998;&#20026;&#24191;&#27867;&#30340;&#31867;&#21035;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#23545;&#26080;&#20851;&#31639;&#27861;&#30340;&#38169;&#35823;&#20998;&#31867;&#65292;&#20197;&#21450;&#20351;&#29992;&#30456;&#21516;&#24230;&#37327;&#26631;&#20934;&#23545;&#20854;&#36136;&#37327;&#21644;&#34892;&#20026;&#36827;&#34892;&#38169;&#35823;&#35780;&#20272;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#30340;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#20998;&#31867;&#27861;&#65292;&#23558;&#31639;&#27861;&#23618;&#27425;&#21270;&#22320;&#20998;&#20026;&#31934;&#32454;&#30340;&#31867;&#21035;&#21644;&#20855;&#20307;&#25216;&#26415;&#12290;&#35813;&#20998;&#31867;&#27861;&#21253;&#25324;&#26041;&#27861;&#23398;&#31867;&#21035;&#12289;&#26041;&#27861;&#23398;&#25216;&#26415;&#21644;&#26041;&#27861;&#23398;&#23376;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26159;&#39318;&#27425;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#20998;&#31867;&#27861;&#23545;&#31639;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
The explosive and widespread growth of data necessitates the use of text classification to extract crucial information from vast amounts of data. Consequently, there has been a surge of research in both classical and deep learning text classification methods. Despite the numerous methods proposed in the literature, there is still a pressing need for a comprehensive and up-to-date survey. Existing survey papers categorize algorithms for text classification into broad classes, which can lead to the misclassification of unrelated algorithms and incorrect assessments of their qualities and behaviors using the same metrics. To address these limitations, our paper introduces a novel methodological taxonomy that classifies algorithms hierarchically into fine-grained classes and specific techniques. The taxonomy includes methodology categories, methodology techniques, and methodology sub-techniques. Our study is the first survey to utilize this methodological taxonomy for classifying algorithm
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#26469;&#26816;&#27979;&#32511;&#33394;&#34394;&#20551;&#23459;&#20256;&#39118;&#38505;&#12290;&#24320;&#21457;&#20102;&#19968;&#31181;&#37327;&#21270;&#32511;&#33394;&#34394;&#20551;&#23459;&#20256;&#39118;&#38505;&#30340;&#25968;&#23398;&#24418;&#24335;&#65292;&#24314;&#31435;&#20102;&#20248;&#21270;&#30340;ClimateBERT&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#20102;&#32467;&#26524;&#27604;&#36739;&#20998;&#26512;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#36825;&#19968;&#20219;&#21153;&#20855;&#26377;&#33391;&#22909;&#30340;&#25506;&#32034;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2311.01469</link><description>&lt;p&gt;
&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#26816;&#27979;&#29615;&#20445;&#34394;&#20551;&#23459;&#20256;
&lt;/p&gt;
&lt;p&gt;
Leveraging Language Models to Detect Greenwashing. (arXiv:2311.01469v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#26469;&#26816;&#27979;&#32511;&#33394;&#34394;&#20551;&#23459;&#20256;&#39118;&#38505;&#12290;&#24320;&#21457;&#20102;&#19968;&#31181;&#37327;&#21270;&#32511;&#33394;&#34394;&#20551;&#23459;&#20256;&#39118;&#38505;&#30340;&#25968;&#23398;&#24418;&#24335;&#65292;&#24314;&#31435;&#20102;&#20248;&#21270;&#30340;ClimateBERT&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#20102;&#32467;&#26524;&#27604;&#36739;&#20998;&#26512;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#36825;&#19968;&#20219;&#21153;&#20855;&#26377;&#33391;&#22909;&#30340;&#25506;&#32034;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#27668;&#20505;&#21464;&#21270;&#30340;&#21518;&#26524;&#36234;&#26469;&#36234;&#24341;&#36215;&#20844;&#20247;&#30340;&#20851;&#27880;&#12290;&#22240;&#27492;&#65292;&#20225;&#19994;&#22312;&#21487;&#25345;&#32493;&#21457;&#23637;&#25253;&#21578;&#20013;&#24378;&#35843;&#20854;&#29615;&#20445;&#21162;&#21147;&#20197;&#22686;&#24378;&#20844;&#20247;&#24418;&#35937;&#12290;&#28982;&#32780;&#65292;&#23545;&#27492;&#31867;&#25253;&#21578;&#30340;&#23457;&#26680;&#32570;&#20047;&#20005;&#26684;&#30340;&#30417;&#31649;&#65292;&#21487;&#33021;&#23548;&#33268;&#32511;&#33394;&#34394;&#20551;&#23459;&#20256;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#23545;&#32511;&#33394;&#34394;&#20551;&#23459;&#20256;&#39118;&#38505;&#36827;&#34892;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#21253;&#25324;&#65306;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#26469;&#37327;&#21270;&#32511;&#33394;&#34394;&#20551;&#23459;&#20256;&#39118;&#38505;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#35813;&#38382;&#39064;&#30340;&#20248;&#21270;ClimateBERT&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#20102;&#32467;&#26524;&#30340;&#27604;&#36739;&#20998;&#26512;&#12290;&#22312;&#19968;&#20010;&#21253;&#21547;&#21487;&#25345;&#32493;&#21457;&#23637;&#25253;&#21578;&#30340;&#27979;&#35797;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#26368;&#20339;&#27169;&#22411;&#23454;&#29616;&#20102;&#24179;&#22343;&#20934;&#30830;&#29575;86.34%&#21644;F1&#20540;0.67&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#36825;&#19968;&#20219;&#21153;&#20855;&#26377;&#25506;&#32034;&#30340;&#33391;&#22909;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, climate change repercussions have increasingly captured public interest. Consequently, corporations are emphasizing their environmental efforts in sustainability reports to bolster their public image. Yet, the absence of stringent regulations in review of such reports allows potential greenwashing. In this study, we introduce a novel methodology to train a language model on generated labels for greenwashing risk. Our primary contributions encompass: developing a mathematical formulation to quantify greenwashing risk, a fine-tuned ClimateBERT model for this problem, and a comparative analysis of results. On a test set comprising of sustainability reports, our best model achieved an average accuracy score of 86.34% and F1 score of 0.67, demonstrating that our methods show a promising direction of exploration for this task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24418;&#24335;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#65292;&#24182;&#31995;&#32479;&#21270;&#38450;&#24481;&#36825;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2310.12815</link><description>&lt;p&gt;
LLM-&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#21644;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24418;&#24335;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#65292;&#24182;&#31995;&#32479;&#21270;&#38450;&#24481;&#36825;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20316;&#21508;&#31181;&#31216;&#20026;LLM-&#38598;&#25104;&#24212;&#29992;&#30340;&#23454;&#38469;&#24212;&#29992;&#31243;&#24207;&#30340;&#21518;&#31471;&#12290;&#26368;&#36817;&#30340;&#22810;&#39033;&#30740;&#31350;&#34920;&#26126;&#65292;LLM-&#38598;&#25104;&#24212;&#29992;&#23481;&#26131;&#21463;&#21040;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#23041;&#32961;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#23558;&#24694;&#24847;&#25351;&#20196;/&#25968;&#25454;&#27880;&#20837;&#36825;&#20123;&#24212;&#29992;&#31243;&#24207;&#30340;&#36755;&#20837;&#20013;&#65292;&#20197;&#36798;&#21040;&#25915;&#20987;&#32773;&#30340;&#39044;&#26399;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30740;&#31350;&#20165;&#38480;&#20110;&#26696;&#20363;&#30740;&#31350;&#65292;&#32570;&#20047;&#23545;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#21450;&#20854;&#38450;&#24481;&#30340;&#31995;&#32479;&#29702;&#35299;&#12290;&#26412;&#35770;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24418;&#24335;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#65292;&#24182;&#23558;&#30740;&#31350;&#35770;&#25991;&#21644;&#21338;&#23458;&#25991;&#31456;&#20013;&#35752;&#35770;&#30340;&#29616;&#26377;&#25915;&#20987;&#35270;&#20026;&#25105;&#20204;&#26694;&#26550;&#30340;&#29305;&#20363;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#32452;&#21512;&#29616;&#26377;&#25915;&#20987;&#35774;&#35745;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#21270;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#38450;&#24481;&#30340;&#26694;&#26550;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#39044;&#38450;&#21644;&#32531;&#35299;&#36825;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are increasingly deployed as the backend for a variety of real-world applications called LLM-Integrated Applications. Multiple recent works showed that LLM-Integrated Applications are vulnerable to prompt injection attacks, in which an attacker injects malicious instruction/data into the input of those applications such that they produce results as the attacker desires. However, existing works are limited to case studies. As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses. We aim to bridge the gap in this work. In particular, we propose a general framework to formalize prompt injection attacks. Existing attacks, which are discussed in research papers and blog posts, are special cases in our framework. Our framework enables us to design a new attack by combining existing attacks. Moreover, we also propose a framework to systematize defenses against prompt injection attacks. Using our frameworks, we con
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;Neural PG-RANK&#65292;&#36890;&#36807;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12289;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2310.04407</link><description>&lt;p&gt;
&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Policy-Gradient Training of Language Models for Ranking. (arXiv:2310.04407v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04407
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;Neural PG-RANK&#65292;&#36890;&#36807;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12289;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#26816;&#32034;&#22312;&#23558;&#20107;&#23454;&#30693;&#35782;&#32435;&#20837;&#21040;&#35821;&#35328;&#22788;&#29702;&#27969;&#31243;&#20013;&#30340;&#20915;&#31574;&#36807;&#31243;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#20174;&#32842;&#22825;&#24335;&#32593;&#39029;&#25628;&#32034;&#21040;&#38382;&#31572;&#31995;&#32479;&#12290;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#26816;&#32034;&#27169;&#22411;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#36798;&#21040;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#65292;&#20294;&#36890;&#36807;&#20856;&#22411;&#30340;&#23545;&#27604;&#25439;&#22833;&#35757;&#32451;&#22522;&#20110;LLM&#30340;&#26816;&#32034;&#22120;&#38656;&#35201;&#22797;&#26434;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21253;&#25324;&#36873;&#25321;&#22256;&#38590;&#30340;&#36127;&#26679;&#26412;&#21644;&#20351;&#29992;&#39069;&#22806;&#30340;&#30417;&#30563;&#20316;&#20026;&#23398;&#20064;&#20449;&#21495;&#12290;&#36825;&#31181;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#21407;&#22240;&#26159;&#23545;&#27604;&#25439;&#22833;&#26412;&#36523;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#19981;&#33021;&#30452;&#25509;&#20248;&#21270;&#22788;&#29702;&#27969;&#31243;&#26411;&#31471;&#20915;&#31574;&#36136;&#37327;&#30340;&#19979;&#28216;&#25351;&#26631;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31070;&#32463;PG-RANK&#65292;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;LLM&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23398;&#20064;&#25490;&#24207;&#12290;&#31070;&#32463;PG-RANK&#20026;&#26816;&#32034;&#27169;&#22411;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#25552;&#20379;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#20316;&#20026;&#26356;&#22823;&#30340;&#20915;&#31574;&#31995;&#32479;&#30340;&#19968;&#37096;&#20998;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text retrieval plays a crucial role in incorporating factual knowledge for decision making into language processing pipelines, ranging from chat-based web search to question answering systems. Current state-of-the-art text retrieval models leverage pre-trained large language models (LLMs) to achieve competitive performance, but training LLM-based retrievers via typical contrastive losses requires intricate heuristics, including selecting hard negatives and using additional supervision as learning signals. This reliance on heuristics stems from the fact that the contrastive loss itself is heuristic and does not directly optimize the downstream metrics of decision quality at the end of the processing pipeline. To address this issue, we introduce Neural PG-RANK, a novel training algorithm that learns to rank by instantiating a LLM as a Plackett-Luce ranking policy. Neural PG-RANK provides a principled method for end-to-end training of retrieval models as part of larger decision systems vi
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#36164;&#26009;&#39044;&#27979;&#20010;&#20154;&#20449;&#24687;&#30340;&#20010;&#24615;&#21270;&#20998;&#26512;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#22810;&#29992;&#36884;&#24615;&#65292;&#24182;&#21457;&#29616;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#39044;&#27979;&#20010;&#24615;&#31867;&#22411;&#26041;&#38754;&#20855;&#26377;&#26368;&#20339;&#20934;&#30830;&#29575;&#65292;&#32780;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#36739;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.13065</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#20998;&#26512;&#65306;&#31038;&#20132;&#23186;&#20307;&#36164;&#26009;&#22312;&#39044;&#27979;&#20010;&#20154;&#20449;&#24687;&#26041;&#38754;&#26377;&#22810;&#26377;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Personality Profiling: How informative are social media profiles in predicting personal information?. (arXiv:2309.13065v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13065
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#36164;&#26009;&#39044;&#27979;&#20010;&#20154;&#20449;&#24687;&#30340;&#20010;&#24615;&#21270;&#20998;&#26512;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#22810;&#29992;&#36884;&#24615;&#65292;&#24182;&#21457;&#29616;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#39044;&#27979;&#20010;&#24615;&#31867;&#22411;&#26041;&#38754;&#20855;&#26377;&#26368;&#20339;&#20934;&#30830;&#29575;&#65292;&#32780;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#36739;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#21496;&#21033;&#29992;&#20010;&#24615;&#21270;&#20998;&#26512;&#36827;&#34892;&#23450;&#21521;&#24191;&#21578;&#12289;&#25919;&#27835;&#23459;&#20256;&#21644;&#30123;&#33495;&#23459;&#20256;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#22810;&#29992;&#36884;&#24615;&#20173;&#28982;&#30456;&#23545;&#26410;&#30693;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#32034;&#20154;&#20204;&#30340;&#22312;&#32447;&#25968;&#23383;&#36275;&#36857;&#33021;&#22815;&#34987;&#29992;&#26469;&#20998;&#26512;&#20854;&#36808;&#23572;&#26031;-&#24067;&#37324;&#26684;&#26031;&#20154;&#26684;&#31867;&#22411;&#30340;&#31243;&#24230;&#12290;&#25105;&#20204;&#20998;&#26512;&#21644;&#27604;&#36739;&#20102;&#22235;&#20010;&#27169;&#22411;&#30340;&#32467;&#26524;&#65306;&#36923;&#36753;&#22238;&#24402;&#12289;&#26420;&#32032;&#36125;&#21494;&#26031;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#21644;&#38543;&#26426;&#26862;&#26519;&#12290;&#25105;&#20204;&#21457;&#29616;SVM&#27169;&#22411;&#22312;&#39044;&#27979;&#26576;&#20154;&#30340;&#23436;&#25972;&#20010;&#24615;&#31867;&#22411;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20339;&#20934;&#30830;&#29575;20.95%&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#30340;&#34920;&#29616;&#21482;&#31245;&#24494;&#24046;&#19968;&#20123;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#21644;&#36827;&#34892;&#39044;&#27979;&#26102;&#36895;&#24230;&#26356;&#24555;&#12290;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#26631;&#35760;&#25968;&#25454;&#38598;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#21576;&#29616;&#20986;&#20010;&#20154;&#29305;&#24449;&#30340;&#20005;&#37325;&#31867;&#21035;&#19981;&#24179;&#34913;&#65292;&#21253;&#25324;&#25105;&#20204;&#33258;&#24049;&#30340;&#25968;&#25454;&#38598;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24378;&#35843;&#38656;&#35201;&#22312;&#25253;&#21578;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#27169;&#22411;&#24615;&#33021;&#26102;&#36827;&#34892;&#20180;&#32454;&#32771;&#34385;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personality profiling has been utilised by companies for targeted advertising, political campaigns and vaccine campaigns. However, the accuracy and versatility of such models still remains relatively unknown. Consequently, we aim to explore the extent to which peoples' online digital footprints can be used to profile their Myers-Briggs personality type. We analyse and compare the results of four models: logistic regression, naive Bayes, support vector machines (SVMs) and random forests. We discover that a SVM model achieves the best accuracy of 20.95% for predicting someones complete personality type. However, logistic regression models perform only marginally worse and are significantly faster to train and perform predictions. We discover that many labelled datasets present substantial class imbalances of personal characteristics on social media, including our own. As a result, we highlight the need for attentive consideration when reporting model performance on these datasets and com
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#25991;&#26412;&#20013;&#30340;&#25991;&#23383;&#30340;&#21147;&#37327;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#22320;&#23558;&#25277;&#35937;&#30340;&#25991;&#26412;&#25551;&#36848;&#26144;&#23556;&#21040;&#20855;&#20307;&#30340;&#22270;&#20687;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#20154;&#29289;&#26816;&#32034;&#12290;</title><link>http://arxiv.org/abs/2307.09059</link><description>&lt;p&gt;
&#25991;&#23383;&#24819;&#35937;&#30340;&#37322;&#25918;&#65306;&#36890;&#36807;&#25506;&#32034;&#25991;&#23383;&#30340;&#21147;&#37327;&#23454;&#29616;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#20154;&#29289;&#26816;&#32034;&#30340;&#26032;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Unleashing the Imagination of Text: A Novel Framework for Text-to-image Person Retrieval via Exploring the Power of Words. (arXiv:2307.09059v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#25991;&#26412;&#20013;&#30340;&#25991;&#23383;&#30340;&#21147;&#37327;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#22320;&#23558;&#25277;&#35937;&#30340;&#25991;&#26412;&#25551;&#36848;&#26144;&#23556;&#21040;&#20855;&#20307;&#30340;&#22270;&#20687;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#20154;&#29289;&#26816;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#20154;&#29289;&#26816;&#32034;&#30340;&#30446;&#26631;&#26159;&#20174;&#22823;&#22411;&#22270;&#24211;&#20013;&#26816;&#32034;&#19982;&#32473;&#23450;&#25991;&#26412;&#25551;&#36848;&#30456;&#21305;&#37197;&#30340;&#20154;&#29289;&#22270;&#20687;&#12290;&#36825;&#20010;&#20219;&#21153;&#30340;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#35270;&#35273;&#21644;&#25991;&#26412;&#27169;&#24577;&#20043;&#38388;&#20449;&#24687;&#34920;&#31034;&#30340;&#26174;&#33879;&#24046;&#24322;&#12290;&#25991;&#26412;&#27169;&#24577;&#36890;&#36807;&#35789;&#27719;&#21644;&#35821;&#27861;&#32467;&#26500;&#20256;&#36882;&#25277;&#35937;&#21644;&#31934;&#30830;&#30340;&#20449;&#24687;&#65292;&#32780;&#35270;&#35273;&#27169;&#24577;&#36890;&#36807;&#22270;&#20687;&#20256;&#36882;&#20855;&#20307;&#21644;&#30452;&#35266;&#30340;&#20449;&#24687;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#25991;&#23383;&#34920;&#31034;&#30340;&#34920;&#36798;&#21147;&#65292;&#20934;&#30830;&#22320;&#23558;&#25277;&#35937;&#30340;&#25991;&#26412;&#25551;&#36848;&#26144;&#23556;&#21040;&#20855;&#20307;&#22270;&#20687;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#21477;&#23376;&#20013;&#30340;&#25991;&#23383;&#30340;&#21147;&#37327;&#65292;&#37322;&#25918;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#20154;&#29289;&#26816;&#32034;&#20013;&#30340;&#25991;&#23383;&#24819;&#35937;&#21147;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#20840;&#38754;CLIP&#27169;&#22411;&#20316;&#20026;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#21452;&#32534;&#30721;&#22120;&#65292;&#21033;&#29992;&#20808;&#21069;&#30340;&#36328;&#27169;&#24577;&#23545;&#40784;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of Text-to-image person retrieval is to retrieve person images from a large gallery that match the given textual descriptions. The main challenge of this task lies in the significant differences in information representation between the visual and textual modalities. The textual modality conveys abstract and precise information through vocabulary and grammatical structures, while the visual modality conveys concrete and intuitive information through images. To fully leverage the expressive power of textual representations, it is essential to accurately map abstract textual descriptions to specific images.  To address this issue, we propose a novel framework to Unleash the Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully explore the power of words in sentences. Specifically, the framework employs the pre-trained full CLIP model as a dual encoder for the images and texts , taking advantage of prior cross-modal alignment knowledge. The Text-guided Imag
&lt;/p&gt;</description></item><item><title>HQP&#26159;&#19968;&#20010;&#20154;&#24037;&#26631;&#27880;&#30340;&#32593;&#32476;&#23459;&#20256;&#26816;&#27979;&#25968;&#25454;&#38598;&#65292;&#19982;&#29616;&#26377;&#30340;&#24369;&#26631;&#31614;&#25968;&#25454;&#38598;&#30456;&#27604;&#65292;&#20351;&#29992;HQP&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#25552;&#39640;44%&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.14931</link><description>&lt;p&gt;
HQP&#65306;&#19968;&#20221;&#20154;&#24037;&#26631;&#27880;&#30340;&#29992;&#20110;&#26816;&#27979;&#32593;&#32476;&#23459;&#20256;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
HQP: A Human-Annotated Dataset for Detecting Online Propaganda. (arXiv:2304.14931v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14931
&lt;/p&gt;
&lt;p&gt;
HQP&#26159;&#19968;&#20010;&#20154;&#24037;&#26631;&#27880;&#30340;&#32593;&#32476;&#23459;&#20256;&#26816;&#27979;&#25968;&#25454;&#38598;&#65292;&#19982;&#29616;&#26377;&#30340;&#24369;&#26631;&#31614;&#25968;&#25454;&#38598;&#30456;&#27604;&#65292;&#20351;&#29992;HQP&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#25552;&#39640;44%&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#23459;&#20256;&#23545;&#31038;&#20250;&#30340;&#23436;&#25972;&#24615;&#26500;&#25104;&#20102;&#20005;&#37325;&#23041;&#32961;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26816;&#27979;&#32593;&#32476;&#23459;&#20256;&#30340;&#25968;&#25454;&#38598;&#23384;&#22312;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#65306;&#23427;&#20204;&#26159;&#20351;&#29992;&#24369;&#26631;&#31614;&#36827;&#34892;&#27880;&#37322;&#30340;&#65292;&#21487;&#33021;&#23384;&#22312;&#22122;&#38899;&#29978;&#33267;&#38169;&#35823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#65292;&#26412;&#30740;&#31350;&#20570;&#20986;&#20102;&#20197;&#19979;&#36129;&#29486;&#65306;&#65288;1&#65289;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;HQP&#65288;N=30,000&#65289;&#65292;&#29992;&#20110;&#26816;&#27979;&#32593;&#32476;&#23459;&#20256;&#65292;&#20855;&#26377;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36890;&#36807;&#20154;&#24037;&#27880;&#37322;&#32780;&#21019;&#24314;&#30340;&#29992;&#20110;&#26816;&#27979;&#32593;&#32476;&#23459;&#20256;&#30340;&#25968;&#25454;&#38598;&#12290;&#65288;2&#65289;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#20351;&#29992;&#24369;&#26631;&#31614;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#26368;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#26816;&#27979;&#32593;&#32476;&#23459;&#20256;&#26041;&#38754;&#22833;&#36133;&#65288;AUC&#65306;64.03&#65289;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#24403;&#20351;&#29992;&#25105;&#20204;&#30340;&#39640;&#36136;&#37327;&#26631;&#31614;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#26368;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#20934;&#30830;&#22320;&#26816;&#27979;&#32593;&#32476;&#23459;&#20256;&#65288;AUC&#65306;92.25&#65289;&#65292;&#25552;&#39640;&#20102;&#32422;44%&#12290;&#65288;3&#65289;&#20026;&#20102;&#35299;&#20915;&#26631;&#27880;&#25104;&#26412;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#24037;&#20316;&#25193;&#23637;&#21040;&#20102;&#23569;&#26679;&#26412;&#23398;&#20064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#25968;&#25454;&#38598;&#36827;&#34892;&#25552;&#31034;&#24335;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following contributions: (1) We present \dataset: a novel dataset (N=30,000) for detecting online propaganda with high-quality labels. To the best of our knowledge, \dataset is the first dataset for detecting online propaganda that was created through human annotation. (2) We show empirically that state-of-the-art language models fail in detecting online propaganda when trained with weak labels (AUC: 64.03). In contrast, state-of-the-art language models can accurately detect online propaganda when trained with our high-quality labels (AUC: 92.25), which is an improvement of ~44%. (3) To address the cost of labeling, we extend our work to few-shot learning. Specifically, we show that prompt-based learning using a sm
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#20851;&#20110;&#20351;&#29992;Transformer&#26550;&#26500;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;LaMDA&#26159;&#21542;&#20855;&#26377;&#24847;&#35782;&#30340;&#35828;&#27861;&#12290;&#20316;&#32773;&#35748;&#20026;&#35821;&#35328;&#27169;&#22411;&#19981;&#21487;&#33021;&#20855;&#26377;&#24847;&#35782;&#65292;&#32780;LaMDA&#27809;&#26377;&#27604;&#20854;&#20182;&#31867;&#20284;&#27169;&#22411;&#26356;&#20855;&#20808;&#36827;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.11483</link><description>&lt;p&gt;
Deanthropomorphising NLP&#65306;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#24847;&#35782;&#21040;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Deanthropomorphising NLP: Can a Language Model Be Conscious?. (arXiv:2211.11483v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#20851;&#20110;&#20351;&#29992;Transformer&#26550;&#26500;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;LaMDA&#26159;&#21542;&#20855;&#26377;&#24847;&#35782;&#30340;&#35828;&#27861;&#12290;&#20316;&#32773;&#35748;&#20026;&#35821;&#35328;&#27169;&#22411;&#19981;&#21487;&#33021;&#20855;&#26377;&#24847;&#35782;&#65292;&#32780;LaMDA&#27809;&#26377;&#27604;&#20854;&#20182;&#31867;&#20284;&#27169;&#22411;&#26356;&#20855;&#20808;&#36827;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#23545;&#26368;&#36817;&#26377;&#20851;&#20351;&#29992;Transformer&#27169;&#22411;&#26550;&#26500;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;LaMDA&#20855;&#26377;&#24847;&#35782;&#30340;&#35828;&#27861;&#36827;&#34892;&#35752;&#35770;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#26679;&#30340;&#35821;&#35328;&#27169;&#22411;&#19981;&#21487;&#33021;&#20855;&#26377;&#24847;&#35782;&#65292;&#32780;LaMDA&#24182;&#27809;&#26377;&#27604;&#20854;&#20182;&#31867;&#20284;&#27169;&#22411;&#26356;&#20855;&#20808;&#36827;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#32508;&#21512;&#20449;&#24687;&#29702;&#35770;&#23545;Transformer&#26550;&#26500;&#36827;&#34892;&#20998;&#26512;&#26469;&#35777;&#26126;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#20123;&#26377;&#24847;&#35782;&#30340;&#35828;&#27861;&#26159;NLP&#25253;&#36947;&#20013;&#20351;&#29992;&#25311;&#20154;&#21270;&#35821;&#35328;&#30340;&#26356;&#24191;&#27867;&#20542;&#21521;&#30340;&#19968;&#37096;&#20998;&#12290;&#26080;&#35770;&#36825;&#20123;&#35828;&#27861;&#30340;&#30495;&#23454;&#24615;&#22914;&#20309;&#65292;&#25105;&#20204;&#35748;&#20026;&#29616;&#22312;&#26159;&#35780;&#20272;&#35821;&#35328;&#24314;&#27169;&#36827;&#23637;&#24182;&#32771;&#34385;&#35813;&#20219;&#21153;&#30340;&#20262;&#29702;&#24433;&#21709;&#30340;&#36866;&#24403;&#26102;&#26426;&#12290;&#20026;&#20102;&#20351;&#26412;&#25991;&#26377;&#21161;&#20110;NLP&#31038;&#21306;&#20197;&#22806;&#30340;&#35835;&#32773;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20123;NLP&#22522;&#30784;&#30693;&#35782;&#30340;&#20171;&#32461;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work is intended as a voice in the discussion over the recent claims that LaMDA, a pretrained language model based on the Transformer model architecture, is sentient. This claim, if confirmed, would have serious ramifications in the Natural Language Processing (NLP) community due to wide-spread use of similar models. However, here we take the position that such a language model cannot be sentient, or conscious, and that LaMDA in particular exhibits no advances over other similar models that would qualify it. We justify this by analysing the Transformer architecture through Integrated Information Theory. We see the claims of consciousness as part of a wider tendency to use anthropomorphic language in NLP reporting. Regardless of the veracity of the claims, we consider this an opportune moment to take stock of progress in language modelling and consider the ethical implications of the task. In order to make this work helpful for readers outside the NLP community, we also present the
&lt;/p&gt;</description></item></channel></rss>