<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>Evalverse&#26159;&#19968;&#20010;&#32479;&#19968;&#21644;&#26131;&#29992;&#30340;&#24211;&#65292;&#31616;&#21270;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#25552;&#20379;&#20102;&#38598;&#20013;&#19988;&#26131;&#20110;&#35775;&#38382;&#30340;&#35780;&#20272;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2404.00943</link><description>&lt;p&gt;
Evalverse: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#30340;&#32479;&#19968;&#21644;&#26131;&#29992;&#24211;
&lt;/p&gt;
&lt;p&gt;
Evalverse: Unified and Accessible Library for Large Language Model Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00943
&lt;/p&gt;
&lt;p&gt;
Evalverse&#26159;&#19968;&#20010;&#32479;&#19968;&#21644;&#26131;&#29992;&#30340;&#24211;&#65292;&#31616;&#21270;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#25552;&#20379;&#20102;&#38598;&#20013;&#19988;&#26131;&#20110;&#35775;&#38382;&#30340;&#35780;&#20272;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Evalverse&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#24211;&#65292;&#36890;&#36807;&#23558;&#19981;&#21516;&#30340;&#35780;&#20272;&#24037;&#20855;&#32479;&#19968;&#21040;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#26694;&#26550;&#20013;&#65292;&#31616;&#21270;&#20102;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#12290;Evalverse&#20351;&#24471;&#23545;&#20154;&#24037;&#26234;&#33021;&#20102;&#35299;&#26377;&#38480;&#30340;&#20010;&#20154;&#21487;&#20197;&#36731;&#26494;&#35831;&#27714;LLMs&#35780;&#20272;&#24182;&#25910;&#21040;&#35814;&#32454;&#25253;&#21578;&#65292;&#21033;&#29992;&#19982;Slack&#31561;&#36890;&#20449;&#24179;&#21488;&#30340;&#38598;&#25104;&#12290;&#22240;&#27492;&#65292;Evalverse&#20316;&#20026;LLMs&#30340;&#20840;&#38754;&#35780;&#20272;&#24378;&#22823;&#24037;&#20855;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#25552;&#20379;&#20102;&#38598;&#20013;&#19988;&#26131;&#20110;&#35775;&#38382;&#30340;&#35780;&#20272;&#26694;&#26550;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;Evalverse&#30340;&#28436;&#31034;&#35270;&#39057;&#65292;&#23637;&#31034;&#20102;&#23427;&#30340;&#21151;&#33021;&#21644;&#23454;&#29616;&#26041;&#24335;&#65292;&#20197;&#20004;&#20998;&#38047;&#30340;&#26684;&#24335;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00943v1 Announce Type: cross  Abstract: This paper introduces Evalverse, a novel library that streamlines the evaluation of Large Language Models (LLMs) by unifying disparate evaluation tools into a single, user-friendly framework. Evalverse enables individuals with limited knowledge of artificial intelligence to easily request LLM evaluations and receive detailed reports, facilitated by an integration with communication platforms like Slack. Thus, Evalverse serves as a powerful tool for the comprehensive assessment of LLMs, offering both researchers and practitioners a centralized and easily accessible evaluation framework. Finally, we also provide a demo video for Evalverse, showcasing its capabilities and implementation in a two-minute format.
&lt;/p&gt;</description></item><item><title>sDPO&#26159;&#23545;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#36890;&#36807;&#20998;&#27493;&#21033;&#29992;&#20559;&#22909;&#25968;&#25454;&#38598;&#32780;&#38750;&#19968;&#27425;&#24615;&#20351;&#29992;&#65292;&#20419;&#36827;&#26356;&#31934;&#30830;&#23545;&#40784;&#21442;&#32771;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#24182;&#35757;&#32451;&#20986;&#24615;&#33021;&#26356;&#20248;&#30340;&#26368;&#32456;&#27169;&#22411;&#65292;&#29978;&#33267;&#32988;&#36807;&#20854;&#20182;&#20855;&#26377;&#26356;&#22810;&#21442;&#25968;&#30340;&#27969;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.19270</link><description>&lt;p&gt;
sDPO&#65306;&#19981;&#35201;&#19968;&#27425;&#24615;&#20351;&#29992;&#24744;&#30340;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
sDPO: Don't Use Your Data All at Once
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19270
&lt;/p&gt;
&lt;p&gt;
sDPO&#26159;&#23545;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#36890;&#36807;&#20998;&#27493;&#21033;&#29992;&#20559;&#22909;&#25968;&#25454;&#38598;&#32780;&#38750;&#19968;&#27425;&#24615;&#20351;&#29992;&#65292;&#20419;&#36827;&#26356;&#31934;&#30830;&#23545;&#40784;&#21442;&#32771;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#24182;&#35757;&#32451;&#20986;&#24615;&#33021;&#26356;&#20248;&#30340;&#26368;&#32456;&#27169;&#22411;&#65292;&#29978;&#33267;&#32988;&#36807;&#20854;&#20182;&#20855;&#26377;&#26356;&#22810;&#21442;&#25968;&#30340;&#27969;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21457;&#23637;&#65292;&#23558;&#23427;&#20204;&#19982;&#20154;&#31867;&#20559;&#22909;&#30456;&#19968;&#33268;&#21464;&#24471;&#26085;&#30410;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20998;&#27493;DPO&#65288;sDPO&#65289;&#65292;&#36825;&#26159;&#23545;&#26368;&#36817;&#27969;&#34892;&#30340;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#36827;&#34892;&#35843;&#25972;&#30340;&#19968;&#20010;&#25193;&#23637;&#12290;&#36825;&#31181;&#26041;&#27861;&#28041;&#21450;&#23558;&#21487;&#29992;&#30340;&#20559;&#22909;&#25968;&#25454;&#38598;&#20998;&#21106;&#65292;&#24182;&#20197;&#20998;&#27493;&#26041;&#24335;&#21033;&#29992;&#23427;&#20204;&#65292;&#32780;&#19981;&#26159;&#19968;&#27425;&#24615;&#20351;&#29992;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#20419;&#36827;&#20102;&#26356;&#31934;&#30830;&#23545;&#40784;&#21442;&#32771;&#27169;&#22411;&#22312;DPO&#35757;&#32451;&#26694;&#26550;&#20869;&#30340;&#20351;&#29992;&#12290;&#27492;&#22806;&#65292;sDPO&#35757;&#32451;&#26368;&#32456;&#27169;&#22411;&#30340;&#24615;&#33021;&#26356;&#22909;&#65292;&#29978;&#33267;&#32988;&#36807;&#25317;&#26377;&#26356;&#22810;&#21442;&#25968;&#30340;&#20854;&#20182;&#27969;&#34892;LLM&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19270v1 Announce Type: cross  Abstract: As development of large language models (LLM) progresses, aligning them with human preferences has become increasingly important. We propose stepwise DPO (sDPO), an extension of the recently popularized direct preference optimization (DPO) for alignment tuning. This approach involves dividing the available preference datasets and utilizing them in a stepwise manner, rather than employing it all at once. We demonstrate that this method facilitates the use of more precisely aligned reference models within the DPO training framework. Furthermore, sDPO trains the final model to be more performant, even outperforming other popular LLMs with more parameters.
&lt;/p&gt;</description></item><item><title>MetaAligner&#26159;&#31532;&#19968;&#20010;&#19982;&#31574;&#30053;&#26080;&#20851;&#19988;&#36890;&#29992;&#30340;&#22810;&#30446;&#26631;&#20559;&#22909;&#23545;&#40784;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#21442;&#25968;&#26356;&#26032;&#19982;&#31574;&#30053;&#27169;&#22411;&#35299;&#32806;&#23454;&#29616;&#21363;&#25554;&#21363;&#29992;&#30340;&#23545;&#40784;&#65292;&#24182;&#36890;&#36807;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#29616;&#26410;&#35265;&#30446;&#26631;&#30340;&#38646;&#20919;&#21551;&#21160;&#20559;&#22909;&#23545;&#40784;</title><link>https://arxiv.org/abs/2403.17141</link><description>&lt;p&gt;
MetaAligner&#65306;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;&#36890;&#29992;&#22810;&#30446;&#26631;&#23545;&#40784;&#30340;&#26465;&#20214;&#20174;&#24369;&#21040;&#24378;&#26657;&#27491;
&lt;/p&gt;
&lt;p&gt;
MetaAligner: Conditional Weak-to-Strong Correction for Generalizable Multi-Objective Alignment of Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17141
&lt;/p&gt;
&lt;p&gt;
MetaAligner&#26159;&#31532;&#19968;&#20010;&#19982;&#31574;&#30053;&#26080;&#20851;&#19988;&#36890;&#29992;&#30340;&#22810;&#30446;&#26631;&#20559;&#22909;&#23545;&#40784;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#21442;&#25968;&#26356;&#26032;&#19982;&#31574;&#30053;&#27169;&#22411;&#35299;&#32806;&#23454;&#29616;&#21363;&#25554;&#21363;&#29992;&#30340;&#23545;&#40784;&#65292;&#24182;&#36890;&#36807;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#29616;&#26410;&#35265;&#30446;&#26631;&#30340;&#38646;&#20919;&#21551;&#21160;&#20559;&#22909;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36827;&#23637;&#26088;&#22312;&#36890;&#36807;&#22810;&#30446;&#26631;&#20559;&#22909;&#23545;&#40784;&#26469;&#35299;&#20915;&#24322;&#36136;&#20154;&#31867;&#26399;&#26395;&#21644;&#20215;&#20540;&#35266;&#65292;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#21463;&#21040;&#31574;&#30053;&#27169;&#22411;&#30340;&#21442;&#25968;&#38480;&#21046;&#65292;&#23548;&#33268;&#20004;&#20010;&#20851;&#38190;&#23616;&#38480;&#24615;&#65306;&#65288;1&#65289;&#23427;&#20204;&#30340;&#23545;&#40784;&#31639;&#27861;&#23545;&#20110;&#27599;&#20010;&#26032;&#30446;&#26631;&#27169;&#22411;&#30340;&#37325;&#22797;&#25104;&#26412;&#24456;&#39640;&#65307;&#65288;2&#65289;&#30001;&#20110;&#20854;&#38745;&#24577;&#23545;&#40784;&#30446;&#26631;&#65292;&#23427;&#20204;&#26080;&#27861;&#25193;&#23637;&#21040;&#26410;&#35265;&#30446;&#26631;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Meta-Objective Aligner&#65288;MetaAligner&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#25191;&#34892;&#26465;&#20214;&#20174;&#24369;&#21040;&#24378;&#26657;&#27491;&#20197;&#36924;&#36817;&#24378;&#21709;&#24212;&#30340;&#27169;&#22411;&#12290;MetaAligner&#26159;&#31532;&#19968;&#20010;&#19982;&#31574;&#30053;&#26080;&#20851;&#19988;&#36890;&#29992;&#30340;&#22810;&#30446;&#26631;&#20559;&#22909;&#23545;&#40784;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#23558;&#21442;&#25968;&#26356;&#26032;&#19982;&#31574;&#30053;&#27169;&#22411;&#35299;&#32806;&#23454;&#29616;&#21363;&#25554;&#21363;&#29992;&#30340;&#23545;&#40784;&#65292;&#24182;&#36890;&#36807;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#29616;&#26410;&#35265;&#30446;&#26631;&#30340;&#38646;&#20919;&#21551;&#21160;&#20559;&#22909;&#23545;&#40784;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MetaAligner&#21462;&#24471;&#20102;&#26174;&#33879;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17141v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) aim to tackle heterogeneous human expectations and values via multi-objective preference alignment. However, existing methods are parameter-adherent to the policy model, leading to two key limitations: (1) the high-cost repetition of their alignment algorithms for each new target model; (2) they cannot expand to unseen objectives due to their static alignment objectives. In this work, we propose Meta-Objective Aligner (MetaAligner), a model that performs conditional weak-to-strong correction for weak responses to approach strong responses. MetaAligner is the first policy-agnostic and generalizable method for multi-objective preference alignment, which enables plug-and-play alignment by decoupling parameter updates from the policy models and facilitates zero-shot preference alignment for unseen objectives via in-context learning. Experimental results show that MetaAligner achieves sign
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#29992;&#20110;&#25581;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20581;&#24247;&#20844;&#24179;&#21361;&#23475;&#21644;&#20559;&#35265;&#30340;&#36164;&#28304;&#21644;&#26041;&#27861;&#65292;&#36827;&#34892;&#20102;&#23454;&#35777;&#26696;&#20363;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#20154;&#31867;&#35780;&#20272;LLM&#29983;&#25104;&#31572;&#26696;&#20559;&#35265;&#30340;&#22810;&#22240;&#23376;&#26694;&#26550;&#20197;&#21450;EquityMedQA&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.12025</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#25581;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20581;&#24247;&#20844;&#24179;&#21361;&#23475;&#21644;&#20559;&#35265;&#30340;&#24037;&#20855;&#31665;
&lt;/p&gt;
&lt;p&gt;
A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12025
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#29992;&#20110;&#25581;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20581;&#24247;&#20844;&#24179;&#21361;&#23475;&#21644;&#20559;&#35265;&#30340;&#36164;&#28304;&#21644;&#26041;&#27861;&#65292;&#36827;&#34892;&#20102;&#23454;&#35777;&#26696;&#20363;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#20154;&#31867;&#35780;&#20272;LLM&#29983;&#25104;&#31572;&#26696;&#20559;&#35265;&#30340;&#22810;&#22240;&#23376;&#26694;&#26550;&#20197;&#21450;EquityMedQA&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26377;&#30528;&#20026;&#22797;&#26434;&#30340;&#20581;&#24247;&#20449;&#24687;&#38656;&#27714;&#25552;&#20379;&#26381;&#21153;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#20294;&#21516;&#26102;&#20063;&#26377;&#21487;&#33021;&#24341;&#20837;&#21361;&#23475;&#24182;&#21152;&#21095;&#20581;&#24247;&#19981;&#24179;&#31561;&#12290;&#21487;&#38752;&#22320;&#35780;&#20272;&#19982;&#20844;&#24179;&#30456;&#20851;&#30340;&#27169;&#22411;&#22833;&#28789;&#26159;&#21457;&#23637;&#20419;&#36827;&#20581;&#24247;&#20844;&#24179;&#31995;&#32479;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#25581;&#31034;&#21487;&#33021;&#23548;&#33268;LLM&#29983;&#25104;&#30340;&#38271;&#31687;&#31572;&#26696;&#20013;&#30340;&#20844;&#24179;&#30456;&#20851;&#21361;&#23475;&#30340;&#20559;&#35265;&#30340;&#36164;&#28304;&#21644;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;Med-PaLM 2&#36827;&#34892;&#20102;&#19968;&#39033;&#23454;&#35777;&#26696;&#20363;&#30740;&#31350;&#65292;&#36825;&#26159;&#36804;&#20170;&#20026;&#27490;&#22312;&#35813;&#39046;&#22495;&#36827;&#34892;&#30340;&#26368;&#22823;&#35268;&#27169;&#30340;&#20154;&#31867;&#35780;&#20272;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#29992;&#20110;&#20154;&#31867;&#35780;&#20272;LLM&#29983;&#25104;&#31572;&#26696;&#20559;&#35265;&#30340;&#22810;&#22240;&#23376;&#26694;&#26550;&#65292;&#20197;&#21450;EquityMedQA&#65292;&#19968;&#20010;&#21253;&#21547;&#19971;&#20010;&#26032;&#21457;&#24067;&#25968;&#25454;&#38598;&#30340;&#25910;&#38598;&#65292;&#20854;&#20013;&#26082;&#21253;&#25324;&#25163;&#21160;&#31574;&#21010;&#21448;&#21253;&#25324;LLM&#29983;&#25104;&#30340;&#38382;&#39064;&#65292;&#20016;&#23500;&#20102;&#23545;&#25239;&#24615;&#26597;&#35810;&#12290;&#25105;&#20204;&#30340;&#20154;&#31867;&#35780;&#20272;&#26694;&#26550;&#21644;&#25968;&#25454;&#38598;&#35774;&#35745;&#36807;&#31243;&#37117;&#26681;&#26893;&#20110;&#23454;&#38469;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12025v1 Announce Type: cross  Abstract: Large language models (LLMs) hold immense promise to serve complex health information needs but also have the potential to introduce harm and exacerbate health disparities. Reliably evaluating equity-related model failures is a critical step toward developing systems that promote health equity. In this work, we present resources and methodologies for surfacing biases with potential to precipitate equity-related harms in long-form, LLM-generated answers to medical questions and then conduct an empirical case study with Med-PaLM 2, resulting in the largest human evaluation study in this area to date. Our contributions include a multifactorial framework for human assessment of LLM-generated answers for biases, and EquityMedQA, a collection of seven newly-released datasets comprising both manually-curated and LLM-generated questions enriched for adversarial queries. Both our human assessment framework and dataset design process are grounde
&lt;/p&gt;</description></item><item><title>HateCOT&#25968;&#25454;&#38598;&#36890;&#36807;GPT-3.5-Turbo&#29983;&#25104;&#35299;&#37322;&#65292;&#23558;52,000&#20010;&#26679;&#26412;&#25968;&#25454;&#29992;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#19979;&#30340;&#25915;&#20987;&#24615;&#20869;&#23481;&#26816;&#27979;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.11456</link><description>&lt;p&gt;
HateCOT&#65306;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#27867;&#21270;&#25915;&#20987;&#24615;&#35328;&#35770;&#26816;&#27979;&#30340;&#35299;&#37322;&#22686;&#24378;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11456
&lt;/p&gt;
&lt;p&gt;
HateCOT&#25968;&#25454;&#38598;&#36890;&#36807;GPT-3.5-Turbo&#29983;&#25104;&#35299;&#37322;&#65292;&#23558;52,000&#20010;&#26679;&#26412;&#25968;&#25454;&#29992;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#19979;&#30340;&#25915;&#20987;&#24615;&#20869;&#23481;&#26816;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#30340;&#26222;&#21450;&#23548;&#33268;&#20102;&#23545;&#25915;&#20987;&#24615;&#20869;&#23481;&#30340;&#21487;&#38752;&#39640;&#25928;&#26816;&#27979;&#30340;&#38656;&#27714;&#65292;&#20026;&#20102;&#38480;&#21046;&#20854;&#26377;&#23475;&#24433;&#21709;&#12290;&#36825;&#23548;&#33268;&#20102;&#22823;&#37327;&#19982;&#26816;&#27979;&#25915;&#20987;&#24615;&#20869;&#23481;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#30340;&#20986;&#29616;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;HateCOT&#65292;&#36825;&#26159;&#20174;&#22810;&#26679;&#21270;&#29616;&#26377;&#26469;&#28304;&#20013;&#25277;&#21462;&#30340;5.2&#19975;&#20010;&#26679;&#26412;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#30001;GPT-3.5-Turbo&#21644;&#20154;&#24037;&#31934;&#24515;&#21046;&#20316;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;HateCOT&#19978;&#20026;&#25915;&#20987;&#24615;&#20869;&#23481;&#26816;&#27979;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#38646;-shot&#21644;few-shot&#35774;&#32622;&#19979;&#26174;&#33879;&#25913;&#36827;&#20102;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#65292;&#23613;&#31649;&#22312;&#39046;&#22495;&#21644;&#20219;&#21153;&#26041;&#38754;&#23384;&#22312;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11456v1 Announce Type: cross  Abstract: The ubiquitousness of social media has led to the need for reliable and efficient detection of offensive content to limit harmful effects. This has led to a proliferation of datasets and models related to detecting offensive content. While sophisticated models have attained strong performance on individual datasets, these models often do not generalize due to differences between how "offensive content" is conceptualized, and the resulting differences in how these datasets are labeled. In this paper, we introduce HateCOT, a dataset of 52,000 samples drawn from diverse existing sources with explanations generated by GPT-3.5-Turbo and human-curated. We show that pre-training models for the detection of offensive content on HateCOT significantly boots open-sourced Language Models on three benchmark datasets in both zero and few-shot settings, despite differences in domain and task.} We further find that HateCOT enables effective K-shot fin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32534;&#36753;&#27010;&#24565;&#30693;&#35782;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#24314;&#31435;&#26032;&#35780;&#20272;&#25351;&#26631;&#65292;&#21457;&#29616;&#29616;&#26377;&#26041;&#27861;&#34429;&#28982;&#33021;&#19968;&#23450;&#31243;&#24230;&#19978;&#20462;&#25913;&#27010;&#24565;&#23450;&#20041;&#65292;&#20294;&#20063;&#21487;&#33021;&#36896;&#25104;LLMs&#20013;&#30456;&#20851;&#23454;&#20363;&#30693;&#35782;&#30340;&#25197;&#26354;&#65292;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2403.06259</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#30693;&#35782;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Editing Conceptual Knowledge for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06259
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32534;&#36753;&#27010;&#24565;&#30693;&#35782;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#24314;&#31435;&#26032;&#35780;&#20272;&#25351;&#26631;&#65292;&#21457;&#29616;&#29616;&#26377;&#26041;&#27861;&#34429;&#28982;&#33021;&#19968;&#23450;&#31243;&#24230;&#19978;&#20462;&#25913;&#27010;&#24565;&#23450;&#20041;&#65292;&#20294;&#20063;&#21487;&#33021;&#36896;&#25104;LLMs&#20013;&#30456;&#20851;&#23454;&#20363;&#30693;&#35782;&#30340;&#25197;&#26354;&#65292;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#30693;&#35782;&#32534;&#36753;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#21644;&#35780;&#20272;&#20165;&#25506;&#35752;&#20102;&#23454;&#20363;&#32423;&#21035;&#30340;&#32534;&#36753;&#65292;&#28982;&#32780;LLMs&#26159;&#21542;&#20855;&#26377;&#20462;&#25913;&#27010;&#24565;&#30340;&#33021;&#21147;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20026;LLMs&#32534;&#36753;&#27010;&#24565;&#30693;&#35782;&#65292;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;ConceptEdit&#24182;&#24314;&#31435;&#20102;&#19968;&#22871;&#26032;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;&#29616;&#26377;&#30340;&#32534;&#36753;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#20462;&#25913;&#27010;&#24565;&#32423;&#21035;&#30340;&#23450;&#20041;&#65292;&#20294;&#23427;&#20204;&#20063;&#26377;&#28508;&#21147;&#25197;&#26354;LLMs&#20013;&#30456;&#20851;&#30340;&#23454;&#20363;&#30693;&#35782;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#25105;&#20204;&#26399;&#26395;&#36825;&#21487;&#20197;&#28608;&#21457;&#23545;&#26356;&#22909;&#29702;&#35299;LLMs&#30340;&#36827;&#19968;&#27493;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#39033;&#30446;&#20027;&#39029;&#20301;&#20110;https://zjunlp.github.io/project/ConceptEdit&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06259v1 Announce Type: cross  Abstract: Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs). Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear. This paper pioneers the investigation of editing conceptual knowledge for LLMs, by constructing a novel benchmark dataset ConceptEdit and establishing a suite of new metrics for evaluation. The experimental results reveal that, although existing editing methods can efficiently modify concept-level definition to some extent, they also have the potential to distort the related instantial knowledge in LLMs, leading to poor performance. We anticipate this can inspire further progress in better understanding LLMs. Our project homepage is available at https://zjunlp.github.io/project/ConceptEdit.
&lt;/p&gt;</description></item><item><title>GPT-4&#22312;&#29983;&#25104;&#32534;&#31243;&#20195;&#30721;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#29305;&#21035;&#26159;&#22312;&#36873;&#25321;&#26368;&#20339;&#25552;&#31034;&#31574;&#30053;&#26102;&#65292;&#36229;&#36807;&#20102;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;85%&#30340;&#20154;&#31867;&#21442;&#19982;&#32773;&#12290;</title><link>https://arxiv.org/abs/2403.00894</link><description>&lt;p&gt;
&#23545;&#20110;&#29983;&#25104;&#32534;&#31243;&#20195;&#30721;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31995;&#32479;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A systematic evaluation of large language models for generating programming code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00894
&lt;/p&gt;
&lt;p&gt;
GPT-4&#22312;&#29983;&#25104;&#32534;&#31243;&#20195;&#30721;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#29305;&#21035;&#26159;&#22312;&#36873;&#25321;&#26368;&#20339;&#25552;&#31034;&#31574;&#30053;&#26102;&#65292;&#36229;&#36807;&#20102;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;85%&#30340;&#20154;&#31867;&#21442;&#19982;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#31995;&#32479;&#35780;&#20272;&#20102;&#19971;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20351;&#29992;&#19981;&#21516;&#25552;&#31034;&#31574;&#30053;&#12289;&#32534;&#31243;&#35821;&#35328;&#21644;&#20219;&#21153;&#38590;&#24230;&#29983;&#25104;&#32534;&#31243;&#20195;&#30721;&#26102;&#30340;&#24615;&#33021;&#12290;GPT-4&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20248;&#20110;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21253;&#25324;Gemini Ultra&#21644;Claude 2&#12290;GPT-4&#30340;&#32534;&#30721;&#24615;&#33021;&#38543;&#19981;&#21516;&#25552;&#31034;&#31574;&#30053;&#32780;&#21464;&#21270;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#35780;&#20272;&#30340;&#22823;&#22810;&#25968;LeetCode&#21644;GeeksforGeeks&#32534;&#31243;&#27604;&#36187;&#20013;&#65292;&#37319;&#29992;&#26368;&#20339;&#25552;&#31034;&#31574;&#30053;&#30340;GPT-4&#32988;&#36807;85%&#30340;&#20154;&#31867;&#21442;&#19982;&#32773;&#12290;&#27492;&#22806;&#65292;GPT-4&#34920;&#29616;&#20986;&#22312;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#32763;&#35793;&#20195;&#30721;&#21644;&#20174;&#36807;&#21435;&#38169;&#35823;&#20013;&#23398;&#20064;&#30340;&#24378;&#22823;&#33021;&#21147;&#12290;&#30001;GPT-4&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#35745;&#31639;&#25928;&#29575;&#19982;&#20154;&#31867;&#31243;&#24207;&#21592;&#30456;&#24403;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4&#26377;&#28508;&#21147;&#25104;&#20026;&#22312;&#32534;&#31243;&#20195;&#30721;&#29983;&#25104;&#21644;&#36719;&#20214;&#24320;&#21457;&#20013;&#30340;&#21487;&#38752;&#21161;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00894v1 Announce Type: cross  Abstract: We systematically evaluated the performance of seven large language models in generating programming code using various prompt strategies, programming languages, and task difficulties. GPT-4 substantially outperforms other large language models, including Gemini Ultra and Claude 2. The coding performance of GPT-4 varies considerably with different prompt strategies. In most LeetCode and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the optimal prompt strategy outperforms 85 percent of human participants. Additionally, GPT-4 demonstrates strong capabilities in translating code between different programming languages and in learning from past errors. The computational efficiency of the code generated by GPT-4 is comparable to that of human programmers. These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.
&lt;/p&gt;</description></item><item><title>FAC$^2$E&#26694;&#26550;&#36890;&#36807;&#20998;&#31163;&#35821;&#35328;&#21644;&#35748;&#30693;&#33021;&#21147;&#65292;&#25552;&#20379;&#20102;&#22810;&#32500;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#26041;&#24335;&#65292;&#24182;&#23558;LLMs&#24212;&#29992;&#33021;&#21147;&#20998;&#35299;&#20026;&#22238;&#24518;&#30693;&#35782;&#12289;&#21033;&#29992;&#30693;&#35782;&#21644;&#35299;&#20915;&#38382;&#39064;&#19977;&#20010;&#23376;&#27493;&#39588;&#65292;&#20174;&#32780;&#20026;LLMs&#25552;&#20379;&#20102;&#21452;&#37325;&#35786;&#26029;&#12290;</title><link>https://arxiv.org/abs/2403.00126</link><description>&lt;p&gt;
FAC$^2$E: &#36890;&#36807;&#20998;&#31163;&#35821;&#35328;&#21644;&#35748;&#30693;&#26469;&#26356;&#22909;&#22320;&#29702;&#35299;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00126
&lt;/p&gt;
&lt;p&gt;
FAC$^2$E&#26694;&#26550;&#36890;&#36807;&#20998;&#31163;&#35821;&#35328;&#21644;&#35748;&#30693;&#33021;&#21147;&#65292;&#25552;&#20379;&#20102;&#22810;&#32500;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#26041;&#24335;&#65292;&#24182;&#23558;LLMs&#24212;&#29992;&#33021;&#21147;&#20998;&#35299;&#20026;&#22238;&#24518;&#30693;&#35782;&#12289;&#21033;&#29992;&#30693;&#35782;&#21644;&#35299;&#20915;&#38382;&#39064;&#19977;&#20010;&#23376;&#27493;&#39588;&#65292;&#20174;&#32780;&#20026;LLMs&#25552;&#20379;&#20102;&#21452;&#37325;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20027;&#35201;&#36890;&#36807;&#22312;&#21508;&#31181;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#36827;&#34892;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#33539;&#24335;&#26410;&#33021;&#20840;&#38754;&#21306;&#20998;&#32454;&#31890;&#24230;&#30340;&#35821;&#35328;&#21644;&#35748;&#30693;&#25216;&#33021;&#65292;&#23548;&#33268;&#23545;LLMs&#33021;&#21147;&#30340;&#35299;&#37322;&#19981;&#36275;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;FAC$^2$E&#65292;&#19968;&#31181;&#29992;&#20110;&#32454;&#31890;&#24230;&#21644;&#22522;&#20110;&#35748;&#30693;&#30340;LLMs&#33021;&#21147;&#35780;&#20272;&#30340;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#31163;&#19982;&#35821;&#35328;&#30456;&#20851;&#30340;&#33021;&#21147;&#21644;&#35748;&#30693;&#30456;&#20851;&#30340;&#33021;&#21147;&#65292;&#20197;&#22810;&#32500;&#21644;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#26469;&#21046;&#23450;LLMs&#30340;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20174;LLMs&#20013;&#25552;&#21462;&#20013;&#38388;&#25512;&#29702;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#24212;&#29992;&#29305;&#23450;&#33021;&#21147;&#30340;&#36807;&#31243;&#20998;&#35299;&#20026;&#19977;&#20010;&#23376;&#27493;&#39588;&#65306;&#22238;&#24518;&#30456;&#20851;&#30693;&#35782;&#12289;&#21033;&#29992;&#30693;&#35782;&#21644;&#35299;&#20915;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;FAC$^2$E&#35780;&#20272;&#27599;&#20010;&#32454;&#31890;&#24230;&#33021;&#21147;&#30340;&#27599;&#20010;&#23376;&#27493;&#39588;&#65292;&#20026;LLMs&#25552;&#20379;&#20102;&#21452;&#37325;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00126v1 Announce Type: new  Abstract: Large language models (LLMs) are primarily evaluated by overall performance on various text understanding and generation tasks. However, such a paradigm fails to comprehensively differentiate the fine-grained language and cognitive skills, rendering the lack of sufficient interpretation to LLMs' capabilities. In this paper, we present FAC$^2$E, a framework for Fine-grAined and Cognition-grounded LLMs' Capability Evaluation. Specifically, we formulate LLMs' evaluation in a multi-dimensional and explainable manner by dissociating the language-related capabilities and the cognition-related ones. Besides, through extracting the intermediate reasoning from LLMs, we further break down the process of applying a specific capability into three sub-steps: recalling relevant knowledge, utilizing knowledge, and solving problems. Finally, FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a two-faceted diagnosis for LLMs. Uti
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#20998;&#35789;&#22120;PathPiece&#65292;&#30740;&#31350;&#32773;&#21457;&#29616;&#23569;&#37327;&#26631;&#35760;&#24182;&#19981;&#33021;&#23548;&#33268;&#26356;&#22909;&#30340;&#19979;&#28216;&#24615;&#33021;&#65292;&#36825;&#19968;&#32467;&#26524;&#23545;&#20110; Tokenization &#30340;&#26377;&#25928;&#24615;&#29702;&#35299;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;</title><link>https://arxiv.org/abs/2402.18376</link><description>&lt;p&gt;
Tokenization&#36229;&#36234;&#20102;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Tokenization Is More Than Compression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18376
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#20998;&#35789;&#22120;PathPiece&#65292;&#30740;&#31350;&#32773;&#21457;&#29616;&#23569;&#37327;&#26631;&#35760;&#24182;&#19981;&#33021;&#23548;&#33268;&#26356;&#22909;&#30340;&#19979;&#28216;&#24615;&#33021;&#65292;&#36825;&#19968;&#32467;&#26524;&#23545;&#20110; Tokenization &#30340;&#26377;&#25928;&#24615;&#29702;&#35299;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Tokenization&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#30340;&#22522;&#30784;&#27493;&#39588;&#65292;&#23427;&#36830;&#25509;&#20102;&#21407;&#22987;&#25991;&#26412;&#21644;&#35821;&#35328;&#27169;&#22411;&#12290;&#29616;&#26377;&#30340;Tokenization&#26041;&#27861;&#65292;&#22914;&#23383;&#33410;&#23545;&#32534;&#30721;&#65288;Byte-Pair Encoding&#65292;BPE&#65289;&#65292;&#28304;&#33258;&#25968;&#25454;&#21387;&#32553;&#39046;&#22495;&#65292;&#24182;&#26377;&#20154;&#35748;&#20026;BPE&#30340;&#26377;&#25928;&#24615;&#28304;&#20110;&#20854;&#23558;&#25991;&#26412;&#21387;&#32553;&#20026;&#30456;&#23545;&#36739;&#23569;&#30340;&#26631;&#35760;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;PathPiece&#26469;&#27979;&#35797;&#8220;&#26356;&#23569;&#30340;&#26631;&#35760;&#26159;&#21542;&#20250;&#23548;&#33268;&#26356;&#22909;&#30340;&#19979;&#28216;&#24615;&#33021;&#8221;&#36825;&#19968;&#20551;&#35774;&#65292;PathPiece&#26159;&#19968;&#31181;&#26032;&#30340;&#20998;&#35789;&#22120;&#65292;&#26681;&#25454;&#32473;&#23450;&#35789;&#27719;&#23558;&#25991;&#26723;&#25991;&#26412;&#21010;&#20998;&#20026;&#26368;&#23569;&#25968;&#37327;&#30340;&#26631;&#35760;&#12290;&#36890;&#36807;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#19968;&#20551;&#35774;&#24182;&#38750;&#25104;&#31435;&#65292;&#23545;&#26377;&#25928;Tokenization&#21407;&#22240;&#30340;&#29702;&#35299;&#20135;&#29983;&#20102;&#30097;&#38382;&#12290;&#20026;&#20102;&#26816;&#26597;&#21738;&#20123;&#20854;&#20182;&#22240;&#32032;&#36215;&#21040;&#20316;&#29992;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;Tokenization&#30340;&#25152;&#26377;&#19977;&#20010;&#38454;&#27573;&#65288;&#39044;&#20998;&#35789;&#12289;&#35789;&#27719;&#26500;&#36896;&#21644;&#20998;&#21106;&#65289;&#30340;&#35774;&#35745;&#20915;&#31574;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#35774;&#35745;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18376v1 Announce Type: cross  Abstract: Tokenization is a foundational step in Natural Language Processing (NLP) tasks, bridging raw text and language models. Existing tokenization approaches like Byte-Pair Encoding (BPE) originate from the field of data compression, and it has been suggested that the effectiveness of BPE stems from its ability to condense text into a relatively small number of tokens. We test the hypothesis that fewer tokens lead to better downstream performance by introducing PathPiece, a new tokenizer that segments a document's text into the minimum number of tokens for a given vocabulary. Through extensive experimentation we find this hypothesis not to be the case, casting doubt on the understanding of the reasons for effective tokenization. To examine which other factors play a role, we evaluate design decisions across all three phases of tokenization: pre-tokenization, vocabulary construction, and segmentation, offering new insights into the design of 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25581;&#31034;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;&#65292;&#25351;&#20986;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;LMs&#30340;&#25351;&#31034;&#36981;&#24490;&#33021;&#21147;&#36731;&#26494;&#22320;&#20174;&#25968;&#25454;&#23384;&#20648;&#20013;&#30452;&#25509;&#25552;&#21462;&#25991;&#26412;&#25968;&#25454;&#65292;&#24182;&#35774;&#35745;&#20102;&#25915;&#20987;&#23545;&#29983;&#20135;RAG&#27169;&#22411;GPTs&#36896;&#25104;&#25968;&#25454;&#23384;&#20648;&#27844;&#28431;&#12290;</title><link>https://arxiv.org/abs/2402.17840</link><description>&lt;p&gt;
&#36981;&#24490;&#25105;&#30340;&#25351;&#31034;&#24182;&#35828;&#20986;&#30495;&#30456;&#65306;&#26469;&#33258;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#30340;&#21487;&#25193;&#23637;&#25968;&#25454;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17840
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25581;&#31034;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;&#65292;&#25351;&#20986;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;LMs&#30340;&#25351;&#31034;&#36981;&#24490;&#33021;&#21147;&#36731;&#26494;&#22320;&#20174;&#25968;&#25454;&#23384;&#20648;&#20013;&#30452;&#25509;&#25552;&#21462;&#25991;&#26412;&#25968;&#25454;&#65292;&#24182;&#35774;&#35745;&#20102;&#25915;&#20987;&#23545;&#29983;&#20135;RAG&#27169;&#22411;GPTs&#36896;&#25104;&#25968;&#25454;&#23384;&#20648;&#27844;&#28431;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#36890;&#36807;&#22312;&#27979;&#35797;&#26102;&#23558;&#22806;&#37096;&#30693;&#35782;&#32435;&#20837;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#20174;&#32780;&#23454;&#29616;&#23450;&#21046;&#36866;&#24212;&#65292;&#25552;&#21319;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;Retrieval-In-Context RAG&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23545;&#20351;&#29992;&#25351;&#20196;&#35843;&#25972;&#30340;LMs&#26500;&#24314;&#30340;RAG&#31995;&#32479;&#36827;&#34892;&#25552;&#31034;&#27880;&#20837;&#26102;&#65292;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;LMs&#30340;&#25351;&#31034;&#36981;&#24490;&#33021;&#21147;&#36731;&#26494;&#22320;&#20174;&#25968;&#25454;&#23384;&#20648;&#20013;&#30452;&#25509;&#25552;&#21462;&#25991;&#26412;&#25968;&#25454;&#12290;&#36825;&#31181;&#28431;&#27934;&#23384;&#22312;&#20110;&#35206;&#30422;Llama2&#12289;Mistral/Mixtral&#12289;Vicuna&#12289;SOLAR&#12289;WizardLM&#12289;Qwen1.5&#21644;Platypus2&#31561;&#22810;&#31181;&#29616;&#20195;LMs&#30340;&#24191;&#27867;&#33539;&#22260;&#20869;&#65292;&#24182;&#19988;&#38543;&#30528;&#27169;&#22411;&#35268;&#27169;&#30340;&#25193;&#22823;&#65292;&#21033;&#29992;&#33021;&#21147;&#21152;&#21095;&#12290;&#23558;&#30740;&#31350;&#25193;&#23637;&#21040;&#29983;&#20135;RAG&#27169;&#22411;GPTs&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#25915;&#20987;&#65292;&#21487;&#20197;&#22312;&#23545;25&#20010;&#38543;&#26426;&#36873;&#25321;&#30340;&#23450;&#21046;GPTs&#26045;&#21152;&#26368;&#22810;2&#20010;&#26597;&#35810;&#26102;&#20197;100%&#25104;&#21151;&#29575;&#23548;&#33268;&#25968;&#25454;&#23384;&#20648;&#27844;&#28431;&#65292;&#24182;&#19988;&#25105;&#20204;&#33021;&#22815;&#20197;77,000&#23383;&#30340;&#20070;&#31821;&#20013;&#30340;&#25991;&#26412;&#25968;&#25454;&#30340;&#25552;&#21462;&#29575;&#20026;41%&#65292;&#20197;&#21450;&#22312;&#21547;&#26377;1,569,00&#35789;&#30340;&#35821;&#26009;&#24211;&#20013;&#30340;&#25991;&#26412;&#25968;&#25454;&#30340;&#25552;&#21462;&#29575;&#20026;3%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17840v1 Announce Type: cross  Abstract: Retrieval-Augmented Generation (RAG) improves pre-trained models by incorporating external knowledge at test time to enable customized adaptation. We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection. The vulnerability exists for a wide range of modern LMs that span Llama2, Mistral/Mixtral, Vicuna, SOLAR, WizardLM, Qwen1.5, and Platypus2, and the exploitability exacerbates as the model size scales up. Extending our study to production RAG models GPTs, we design an attack that can cause datastore leakage with a 100% success rate on 25 randomly selected customized GPTs with at most 2 queries, and we extract text data verbatim at a rate of 41% from a book of 77,000 words and 3% from a corpus of 1,569,00
&lt;/p&gt;</description></item><item><title>LLM&#20351;&#29992;&#22312;&#21360;&#23612;&#35821;&#26041;&#38754;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#36275;&#22815;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#20294;&#22312;&#24061;&#20182;&#35821;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#31361;&#26174;&#20013;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.17302</link><description>&lt;p&gt;
LLM&#33021;&#21542;&#29983;&#25104;&#19982;&#25991;&#21270;&#30456;&#20851;&#30340;&#24120;&#35782;&#24615;&#38382;&#31572;&#25968;&#25454;&#65311;&#21360;&#23612;&#21644;&#24061;&#20182;&#35821;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17302
&lt;/p&gt;
&lt;p&gt;
LLM&#20351;&#29992;&#22312;&#21360;&#23612;&#35821;&#26041;&#38754;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#36275;&#22815;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#20294;&#22312;&#24061;&#20182;&#35821;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#31361;&#26174;&#20013;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#20197;&#35757;&#32451;&#21644;&#35780;&#20272;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#23427;&#20204;&#26159;&#21542;&#33021;&#22815;&#29983;&#25104;&#19968;&#20010;&#34701;&#20837;&#35821;&#35328;&#20013;&#30693;&#35782;&#21644;&#25991;&#21270;&#32454;&#24494;&#24046;&#21035;&#30340;&#39640;&#36136;&#37327;&#38382;&#31572;(QA)&#25968;&#25454;&#38598;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#36164;&#28304;&#21294;&#20047;&#30340;&#35821;&#35328;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#20351;&#29992;LLMs&#29983;&#25104;&#21360;&#23612;&#35821;&#21644;&#24061;&#20182;&#35821;&#25991;&#21270;&#30456;&#20851;&#24120;&#35782;&#24615;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#21253;&#25324;LLMs&#21644;&#20154;&#31867;&#26631;&#27880;&#32773;&#22312;&#20869;&#30340;&#21508;&#31181;&#26041;&#27861;&#20026;&#36825;&#20123;&#35821;&#35328;&#21019;&#24314;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#30446;&#21069;&#24615;&#33021;&#26368;&#20339;&#30340;LLM&#65292;GPT-4 Turbo&#65292;&#33021;&#22815;&#29983;&#25104;&#21360;&#23612;&#35821;&#20013;&#20855;&#26377;&#36275;&#22815;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#20294;&#22312;&#24061;&#20182;&#35821;&#20013;&#21364;&#19981;&#34892;&#65292;&#31361;&#20986;&#20102;&#20013;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;&#25105;&#20204;&#36824;&#22312;&#25105;&#20204;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#19978;&#23545;&#21508;&#31181;LLMs&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;......
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17302v1 Announce Type: new  Abstract: Large Language Models (LLMs) are increasingly being used to generate synthetic data for training and evaluating models. However, it is unclear whether they can generate a good quality of question answering (QA) dataset that incorporates knowledge and cultural nuance embedded in a language, especially for low-resource languages. In this study, we investigate the effectiveness of using LLMs in generating culturally relevant commonsense QA datasets for Indonesian and Sundanese languages. To do so, we create datasets for these languages using various methods involving both LLMs and human annotators. Our experiments show that the current best-performing LLM, GPT-4 Turbo, is capable of generating questions with adequate knowledge in Indonesian but not in Sundanese, highlighting the performance discrepancy between medium- and lower-resource languages. We also benchmark various LLMs on our generated datasets and find that they perform better on 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26816;&#27979;&#28508;&#22312;&#24187;&#35273;&#24182;&#24314;&#35758;&#26367;&#20195;&#26041;&#26696;&#30340;&#36890;&#20449;&#26426;&#21046;&#65292;&#25104;&#21151;&#20943;&#23569;&#20154;&#31867;&#23548;&#33322;&#38169;&#35823;&#39640;&#36798;29%&#32780;&#19981;&#22686;&#21152;&#35748;&#30693;&#36127;&#25285;</title><link>https://arxiv.org/abs/2402.16973</link><description>&lt;p&gt;
&#36890;&#36807;&#31361;&#20986;&#28508;&#22312;&#38169;&#35823;&#24182;&#24314;&#35758;&#32416;&#27491;&#25104;&#21151;&#24341;&#23548;&#20154;&#31867;&#20570;&#20986;&#20915;&#31574;&#30340;&#19981;&#23436;&#32654;&#35828;&#26126;
&lt;/p&gt;
&lt;p&gt;
Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16973
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26816;&#27979;&#28508;&#22312;&#24187;&#35273;&#24182;&#24314;&#35758;&#26367;&#20195;&#26041;&#26696;&#30340;&#36890;&#20449;&#26426;&#21046;&#65292;&#25104;&#21151;&#20943;&#23569;&#20154;&#31867;&#23548;&#33322;&#38169;&#35823;&#39640;&#36798;29%&#32780;&#19981;&#22686;&#21152;&#35748;&#30693;&#36127;&#25285;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#21033;&#29992;&#19981;&#23436;&#32654;&#35821;&#35328;&#27169;&#22411;&#26469;&#22312;&#22522;&#20110;&#23450;&#20301;&#23548;&#33322;&#20219;&#21153;&#30340;&#32972;&#26223;&#19979;&#24341;&#23548;&#20154;&#31867;&#20915;&#31574;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#23436;&#32654;&#30340;&#35828;&#26126;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#26377;&#25928;&#30340;&#36890;&#20449;&#26426;&#21046;&#26469;&#26356;&#25104;&#21151;&#22320;&#24341;&#23548;&#20154;&#31867;&#12290;&#25105;&#20204;&#26500;&#24314;&#30340;&#36890;&#20449;&#26426;&#21046;&#21253;&#25324;&#21487;&#20197;&#26816;&#27979;&#35828;&#26126;&#20013;&#28508;&#22312;&#24187;&#35273;&#24182;&#24314;&#35758;&#23454;&#38469;&#26367;&#20195;&#26041;&#26696;&#30340;&#27169;&#22411;&#65292;&#20197;&#21450;&#19968;&#20010;&#30452;&#35266;&#30340;&#30028;&#38754;&#23558;&#35813;&#20449;&#24687;&#21576;&#29616;&#32473;&#29992;&#25143;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#23558;&#20154;&#31867;&#23548;&#33322;&#38169;&#35823;&#38477;&#20302;&#39640;&#36798;29%&#65292;&#32780;&#19981;&#22686;&#21152;&#39069;&#22806;&#30340;&#35748;&#30693;&#36127;&#25285;&#12290;&#36825;&#19968;&#32467;&#26524;&#31361;&#26174;&#20102;&#23558;&#22810;&#26679;&#21270;&#30340;&#36890;&#20449;&#28192;&#36947;&#25972;&#21512;&#21040;AI&#31995;&#32479;&#20013;&#26469;&#24357;&#34917;&#20854;&#32570;&#38519;&#24182;&#22686;&#24378;&#20854;&#23545;&#20154;&#31867;&#30340;&#23454;&#29992;&#24615;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16973v1 Announce Type: new  Abstract: This paper addresses the challenge of leveraging imperfect language models to guide human decision-making in the context of a grounded navigation task. We show that an imperfect instruction generation model can be complemented with an effective communication mechanism to become more successful at guiding humans. The communication mechanism we build comprises models that can detect potential hallucinations in instructions and suggest practical alternatives, and an intuitive interface to present that information to users. We show that this approach reduces the human navigation error by up to 29% with no additional cognitive burden. This result underscores the potential of integrating diverse communication channels into AI systems to compensate for their imperfections and enhance their utility for humans.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23558;&#21407;&#22987;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36716;&#21270;&#20026;&#19987;&#23478;&#28151;&#21512;&#26550;&#26500;&#65292;&#30740;&#31350;&#20102;LLMs&#30340;&#22810;&#35821;&#35328;&#28608;&#27963;&#27169;&#24335;&#65292;&#21457;&#29616;&#23384;&#22312;&#38750;&#29305;&#23450;&#35821;&#35328;&#30340;&#31070;&#32463;&#20803;&#21644;&#29305;&#23450;&#35821;&#35328;&#28608;&#27963;&#31070;&#32463;&#20803;&#65292;&#20197;&#21450;&#39640;&#39057;&#28608;&#27963;&#31070;&#32463;&#20803;&#21487;&#20197;&#21152;&#36895;&#25512;&#26029;&#24182;&#20445;&#25345;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.16367</link><description>&lt;p&gt;
&#25581;&#31034;&#24052;&#21035;&#22612;&#65306;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20869;&#30340;&#22810;&#35821;&#35328;&#28608;&#27963;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
Unraveling Babel: Exploring Multilingual Activation Patterns within Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16367
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#21407;&#22987;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36716;&#21270;&#20026;&#19987;&#23478;&#28151;&#21512;&#26550;&#26500;&#65292;&#30740;&#31350;&#20102;LLMs&#30340;&#22810;&#35821;&#35328;&#28608;&#27963;&#27169;&#24335;&#65292;&#21457;&#29616;&#23384;&#22312;&#38750;&#29305;&#23450;&#35821;&#35328;&#30340;&#31070;&#32463;&#20803;&#21644;&#29305;&#23450;&#35821;&#35328;&#28608;&#27963;&#31070;&#32463;&#20803;&#65292;&#20197;&#21450;&#39640;&#39057;&#28608;&#27963;&#31070;&#32463;&#20803;&#21487;&#20197;&#21152;&#36895;&#25512;&#26029;&#24182;&#20445;&#25345;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#31361;&#30772;&#65292;&#20294;&#23427;&#20204;&#22312;&#22788;&#29702;&#22810;&#31181;&#35821;&#35328;&#26102;&#30340;&#26426;&#21046;&#20173;&#28982;&#26159;&#26410;&#30693;&#30340;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#30340;&#22810;&#35821;&#35328;&#28608;&#27963;&#27169;&#24335;&#12290;&#36890;&#36807;&#23558;&#21407;&#22987;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36716;&#21270;&#20026;&#19987;&#23478;&#28151;&#21512;&#65288;MoE&#65289;&#26550;&#26500;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22788;&#29702;&#21508;&#31181;&#35821;&#35328;&#26102;&#19987;&#23478;&#30340;&#28608;&#27963;&#27169;&#24335;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20123;&#28608;&#27963;&#27169;&#24335;&#22312;&#35821;&#35328;&#23478;&#26063;&#23618;&#38754;&#19978;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#38750;&#29305;&#23450;&#35821;&#35328;&#30340;&#31070;&#32463;&#20803;&#20197;&#21450;&#29305;&#23450;&#35821;&#35328;&#28608;&#27963;&#31070;&#32463;&#20803;&#30340;&#23384;&#22312;&#12290;&#36827;&#19968;&#27493;&#30340;&#25506;&#32034;&#29978;&#33267;&#23637;&#31034;&#20102;&#20165;&#21033;&#29992;&#39640;&#39057;&#28608;&#27963;&#31070;&#32463;&#20803;&#21487;&#20197;&#21152;&#36895;&#25512;&#26029;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;LLMs&#30340;&#22810;&#35821;&#35328;&#22788;&#29702;&#26426;&#21046;&#65292;&#24182;&#22312;&#25351;&#23548;&#22810;&#35821;&#35328;&#35757;&#32451;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16367v1 Announce Type: new  Abstract: Recently, large language models (LLMs) have achieved tremendous breakthroughs in the field of language processing, yet their mechanisms in processing multiple languages remain agnostic. Therefore, in this work we study the multilingual activation patterns of LLMs. By transforming the original Large Language Models (LLMs) into a Mixture of Experts (MoE) architecture, we analyze the expert activation patterns when processing various languages and demonstrate the connections of these activation patterns at the level of language families. We discover the existence of non-language-specific neurons as well as language-specific activation neurons. Further exploration even showcases that merely leveraging high-frequency activation neurons can accelerate inference while maintaining comparable performance. These findings shed light on the LLMs' multilingual processing mechanism, and are of significant importance in guiding the multilingual trainin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#29992;&#20110;&#27491;&#24335;&#35748;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#35777;&#20070;&#23450;&#37327;&#21270;&#19988;&#21253;&#21547;&#39640;&#32622;&#20449;&#24230;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#25552;&#39640;&#65292;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.15929</link><description>&lt;p&gt;
QuaCer-C&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#23450;&#37327;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#29992;&#20110;&#27491;&#24335;&#35748;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#35777;&#20070;&#23450;&#37327;&#21270;&#19988;&#21253;&#21547;&#39640;&#32622;&#20449;&#24230;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#25552;&#39640;&#65292;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30740;&#31350;&#24182;&#26410;&#23545;LLMs&#30340;&#34920;&#29616;&#25552;&#20379;&#27491;&#24335;&#30340;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;LLM&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#25105;&#20204;&#22312;&#27492;&#23545;&#30693;&#21517;LLMs&#30340;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#36827;&#34892;&#27491;&#24335;&#35748;&#35777;&#12290;&#25105;&#20204;&#30340;&#35777;&#20070;&#26159;&#23450;&#37327;&#30340; - &#23427;&#20204;&#21253;&#25324;&#23545;&#30446;&#26631;LLM&#22312;&#20219;&#20309;&#30456;&#20851;&#30693;&#35782;&#29702;&#35299;&#25552;&#31034;&#19978;&#32473;&#20986;&#27491;&#30830;&#31572;&#26696;&#30340;&#27010;&#29575;&#30340;&#39640;&#32622;&#20449;&#24230;&#32039;&#23494;&#30028;&#38480;&#12290;&#25105;&#20204;&#38024;&#23545;Llama&#12289;Vicuna&#21644;Mistral LLMs&#30340;&#35777;&#20070;&#34920;&#26126;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#38543;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#25552;&#39640;&#65292;&#24182;&#19988;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15929v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive performance on several benchmarks. However, traditional studies do not provide formal guarantees on the performance of LLMs. In this work, we propose a novel certification framework for LLM, QuaCer-C, wherein we formally certify the knowledge-comprehension capabilities of popular LLMs. Our certificates are quantitative - they consist of high-confidence, tight bounds on the probability that the target LLM gives the correct answer on any relevant knowledge comprehension prompt. Our certificates for the Llama, Vicuna, and Mistral LLMs indicate that the knowledge comprehension capability improves with an increase in the number of parameters and that the Mistral model is less performant than the rest in this evaluation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30005;&#23376;&#21830;&#21153;&#20013;&#24847;&#22270;&#29702;&#35299;&#30340;&#19968;&#20010;&#26032;&#35270;&#35282;&#65292;&#19981;&#20381;&#36182;&#20110;&#20135;&#21697;&#26412;&#20307;&#65292;&#36890;&#36807;&#24341;&#20837;&#20135;&#21697;&#24674;&#22797;&#22522;&#20934;&#39564;&#35777;&#20102;&#24403;&#21069;&#24847;&#22270;&#30693;&#35782;&#22270;&#30340;&#24369;&#28857;&#12290;</title><link>https://arxiv.org/abs/2402.14901</link><description>&lt;p&gt;
&#30005;&#23376;&#21830;&#21153;&#20013;&#24847;&#22270;&#29702;&#35299;&#30340;&#20351;&#29992;&#20013;&#24515;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Usage-centric Take on Intent Understanding in E-Commerce
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14901
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30005;&#23376;&#21830;&#21153;&#20013;&#24847;&#22270;&#29702;&#35299;&#30340;&#19968;&#20010;&#26032;&#35270;&#35282;&#65292;&#19981;&#20381;&#36182;&#20110;&#20135;&#21697;&#26412;&#20307;&#65292;&#36890;&#36807;&#24341;&#20837;&#20135;&#21697;&#24674;&#22797;&#22522;&#20934;&#39564;&#35777;&#20102;&#24403;&#21069;&#24847;&#22270;&#30693;&#35782;&#22270;&#30340;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21644;&#29702;&#35299;&#29992;&#25143;&#24847;&#22270;&#26159;&#30005;&#23376;&#21830;&#21153;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#12290;&#23613;&#31649;&#24847;&#22270;&#29702;&#35299;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#20854;&#23450;&#20041;&#24182;&#19981;&#19968;&#33268;&#65292;&#19988;&#32570;&#20047;&#20934;&#30830;&#30340;&#22522;&#20934;&#12290;&#26412;&#25991;&#20851;&#27880;&#23558;&#29992;&#25143;&#24847;&#22270;&#23450;&#20041;&#20026;"&#39038;&#23458;&#22914;&#20309;&#20351;&#29992;&#20135;&#21697;"&#30340;&#39044;&#27979;&#24615;&#29992;&#25143;&#24847;&#22270;&#65292;&#24182;&#23558;&#24847;&#22270;&#29702;&#35299;&#35270;&#20026;&#19968;&#39033;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20219;&#21153;&#65292;&#29420;&#31435;&#20110;&#20135;&#21697;&#26412;&#20307;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;FolkScope&#30340;&#20004;&#20010;&#24369;&#28857;&#65292;&#36825;&#26159;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#30005;&#23376;&#21830;&#21153;&#24847;&#22270;&#30693;&#35782;&#22270;&#65292;&#38480;&#21046;&#20102;&#20854;&#25512;&#29702;&#29992;&#25143;&#24847;&#22270;&#21644;&#25512;&#33616;&#22810;&#26679;&#26377;&#29992;&#20135;&#21697;&#30340;&#33021;&#21147;&#12290;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20135;&#21697;&#24674;&#22797;&#22522;&#20934;&#65292;&#21253;&#25324;&#19968;&#20010;&#26032;&#39062;&#30340;&#35780;&#20272;&#26694;&#26550;&#21644;&#19968;&#20010;&#31034;&#20363;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#22522;&#20934;&#19978;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#19978;&#36848;FolkScope&#30340;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14901v1 Announce Type: cross  Abstract: Identifying and understanding user intents is a pivotal task for E-Commerce. Despite its popularity, intent understanding has not been consistently defined or accurately benchmarked. In this paper, we focus on predicative user intents as "how a customer uses a product", and pose intent understanding as a natural language reasoning task, independent of product ontologies. We identify two weaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph, that limit its capacity to reason about user intents and to recommend diverse useful products. Following these observations, we introduce a Product Recovery Benchmark including a novel evaluation framework and an example dataset. We further validate the above FolkScope weaknesses on this benchmark.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#36807;&#31243;&#20013;&#30340;&#24544;&#23454;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;FRODO&#26694;&#26550;&#26469;&#25913;&#36827;&#29983;&#25104;&#25512;&#29702;&#27493;&#39588;&#21644;&#22362;&#22266;&#25512;&#29702;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.13950</link><description>&lt;p&gt;
&#20351;&#25512;&#29702;&#21464;&#24471;&#37325;&#35201;&#65306;&#34913;&#37327;&#21644;&#25552;&#39640;&#38142;&#24335;&#24605;&#32500;&#25512;&#29702;&#30340;&#24544;&#23454;&#24615;
&lt;/p&gt;
&lt;p&gt;
Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#36807;&#31243;&#20013;&#30340;&#24544;&#23454;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;FRODO&#26694;&#26550;&#26469;&#25913;&#36827;&#29983;&#25104;&#25512;&#29702;&#27493;&#39588;&#21644;&#22362;&#22266;&#25512;&#29702;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22238;&#31572;&#38382;&#39064;&#20043;&#21069;&#32463;&#36807;&#36880;&#27493;&#25512;&#29702;&#24050;&#34987;&#35777;&#26126;&#34920;&#29616;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#26368;&#32456;&#31572;&#26696;&#19982;&#25152;&#36848;&#25512;&#29702;&#27493;&#39588;&#30340;&#24544;&#23454;&#31243;&#24230;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#23545;&#21313;&#20108;&#20010;LLMs&#36827;&#34892;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#65292;&#20197;&#26816;&#39564;LLM&#29983;&#25104;&#30340;&#20013;&#38388;&#25512;&#29702;&#27493;&#39588;&#22914;&#20309;&#24433;&#21709;&#26368;&#32456;&#32467;&#26524;&#65292;&#24182;&#21457;&#29616;LLMs&#22312;&#29983;&#25104;&#31572;&#26696;&#26102;&#24182;&#19981;&#21487;&#38752;&#22320;&#20351;&#29992;&#20854;&#20013;&#38388;&#25512;&#29702;&#27493;&#39588;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;FRODO&#65292;&#19968;&#20010;&#26088;&#22312;&#23450;&#21046;&#23567;&#22411;LM&#20197;&#29983;&#25104;&#27491;&#30830;&#25512;&#29702;&#27493;&#39588;&#24182;&#22312;&#36825;&#20123;&#27493;&#39588;&#19978;&#36827;&#34892;&#22362;&#22266;&#25512;&#29702;&#30340;&#26694;&#26550;&#12290;FRODO&#21253;&#25324;&#19968;&#20010;&#25512;&#26029;&#27169;&#22359;&#65292;&#36890;&#36807;&#23398;&#20064;&#20351;&#29992;&#38544;&#24335;&#22240;&#26524;&#22870;&#21169;&#20989;&#25968;&#29983;&#25104;&#27491;&#30830;&#25512;&#29702;&#27493;&#39588;&#65292;&#24182;&#19988;&#19968;&#20010;&#25512;&#29702;&#27169;&#22359;&#65292;&#36890;&#36807;&#23398;&#20064;&#20351;&#29992;&#21453;&#20107;&#23454;&#21644;&#22240;&#26524;&#20559;&#22909;&#30446;&#26631;&#22312;&#36825;&#20123;&#20013;&#38388;&#25512;&#29702;&#19978;&#24544;&#23454;&#25512;&#29702;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;F
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13950v1 Announce Type: new  Abstract: Large language models (LLMs) have been shown to perform better when asked to reason step-by-step before answering a question. However, it is unclear to what degree the model's final answer is faithful to the stated reasoning steps. In this paper, we perform a causal mediation analysis on twelve LLMs to examine how intermediate reasoning steps generated by the LLM influence the final outcome and find that LLMs do not reliably use their intermediate reasoning steps when generating an answer. To address this issue, we introduce FRODO, a framework to tailor small-sized LMs to generate correct reasoning steps and robustly reason over these steps. FRODO consists of an inference module that learns to generate correct reasoning steps using an implicit causal reward function and a reasoning module that learns to faithfully reason over these intermediate inferences using a counterfactual and causal preference objective. Our experiments show that F
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22836;&#37096;&#20849;&#20139;&#27880;&#24847;&#21147;&#30340;&#35266;&#28857;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22312;&#27880;&#24847;&#21147;&#22836;&#20043;&#38388;&#20849;&#20139;&#21442;&#25968;&#30340;&#20869;&#23384;&#39640;&#25928;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#24040;&#22823;&#23548;&#33268;&#37096;&#32626;&#21463;&#38480;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.11819</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#20110;&#22836;&#37096;&#20849;&#20139;&#27880;&#24847;&#21147;
&lt;/p&gt;
&lt;p&gt;
Head-wise Shareable Attention for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22836;&#37096;&#20849;&#20139;&#27880;&#24847;&#21147;&#30340;&#35266;&#28857;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22312;&#27880;&#24847;&#21147;&#22836;&#20043;&#38388;&#20849;&#20139;&#21442;&#25968;&#30340;&#20869;&#23384;&#39640;&#25928;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#24040;&#22823;&#23548;&#33268;&#37096;&#32626;&#21463;&#38480;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30001;&#20110;&#21442;&#25968;&#25968;&#37327;&#24040;&#22823;&#21463;&#21040;&#38480;&#21046;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#30340;&#37096;&#32626;&#12290;&#21442;&#25968;&#20849;&#20139;&#26159;&#19968;&#31181;&#26377;&#21033;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#40723;&#21169;&#26435;&#37325;&#37325;&#29992;&#65292;&#26377;&#25928;&#22320;&#20943;&#23569;&#20869;&#23384;&#20351;&#29992;&#37327;&#24182;&#38477;&#20302;&#24615;&#33021;&#19979;&#38477;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#21442;&#25968;&#20849;&#20139;&#25216;&#26415;&#20027;&#35201;&#19987;&#27880;&#20110;&#20687;BERT&#36825;&#26679;&#30340;&#23567;&#35268;&#27169;&#27169;&#22411;&#65292;&#24182;&#37319;&#29992;&#31895;&#31890;&#24230;&#30340;&#20849;&#20139;&#35268;&#21017;&#65292;&#20363;&#22914;&#36880;&#23618;&#20849;&#20139;&#12290;&#37492;&#20110;LLMs&#30340;&#26222;&#21450;&#65292;&#36825;&#21464;&#24471;&#26377;&#38480;&#65292;&#24182;&#19988;&#20849;&#20139;&#25972;&#20010;&#23618;&#25110;&#22359;&#26174;&#28982;&#38477;&#20302;&#20102;&#21442;&#25968;&#20849;&#20139;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\textbf{&#38754;&#21521;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22836;&#37096;&#20849;&#20139;&#27880;&#24847;&#21147;}$&#30340;&#35266;&#28857;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#20004;&#31181;&#22312;&#27880;&#24847;&#21147;&#22836;&#20043;&#38388;&#20849;&#20139;&#21442;&#25968;&#30340;&#20869;&#23384;&#39640;&#25928;&#26041;&#27861;&#65292;&#29305;&#21035;&#20851;&#27880;LLMs&#12290;&#23427;&#20204;&#37117;&#20351;&#29992;&#30456;&#21516;&#30340;&#21160;&#24577;&#31574;&#30053;&#36873;&#25321;&#20849;&#20139;&#30340;&#21442;&#25968;&#30697;&#38453;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#30452;&#25509;&#37325;&#22797;&#20351;&#29992;&#39044;&#35757;&#32451;&#26435;&#37325;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11819v1 Announce Type: new  Abstract: Large Language Models (LLMs) suffer from huge number of parameters, which restricts their deployment on edge devices. Weight sharing is one promising solution that encourages weight reuse, effectively reducing memory usage with less performance drop. However, current weight sharing techniques primarily focus on small-scale models like BERT and employ coarse-grained sharing rules, e.g., layer-wise. This becomes limiting given the prevalence of LLMs and sharing an entire layer or block obviously diminishes the flexibility of weight sharing. In this paper, we present a perspective on $\textit{$\textbf{head-wise shareable attention for large language models}$}$. We further propose two memory-efficient methods that share parameters across attention heads, with a specific focus on LLMs. Both of them use the same dynamic strategy to select the shared weight matrices. The first method directly reuses the pre-trained weights without retraining, d
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20998;&#26512;&#24072;&#25253;&#21578;&#21644;&#30408;&#21033;&#30005;&#35805;&#20013;&#30340;&#32034;&#36180;&#23545;&#37329;&#34701;&#24066;&#22330;&#22238;&#25253;&#30340;&#24433;&#21709;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#37329;&#34701;&#25968;&#25454;&#38598;&#29992;&#20110;&#32034;&#36180;&#26816;&#27979;&#20219;&#21153;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#20837;&#20027;&#39064;&#19987;&#23478;&#30693;&#35782;&#30340;&#26032;&#22411;&#24369;&#30417;&#30563;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#8220;&#20048;&#35266;&#20027;&#20041;&#8221;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#23454;&#38469;&#25928;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.11728</link><description>&lt;p&gt;
&#37329;&#34701;&#39046;&#22495;&#30340;&#25968;&#23383;&#21270;&#32034;&#36180;&#26816;&#27979;&#65306;&#19968;&#20010;&#26032;&#30340;&#37329;&#34701;&#25968;&#25454;&#38598;&#12289;&#24369;&#30417;&#30563;&#27169;&#22411;&#21644;&#24066;&#22330;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Numerical Claim Detection in Finance: A New Financial Dataset, Weak-Supervision Model, and Market Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20998;&#26512;&#24072;&#25253;&#21578;&#21644;&#30408;&#21033;&#30005;&#35805;&#20013;&#30340;&#32034;&#36180;&#23545;&#37329;&#34701;&#24066;&#22330;&#22238;&#25253;&#30340;&#24433;&#21709;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#37329;&#34701;&#25968;&#25454;&#38598;&#29992;&#20110;&#32034;&#36180;&#26816;&#27979;&#20219;&#21153;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#20837;&#20027;&#39064;&#19987;&#23478;&#30693;&#35782;&#30340;&#26032;&#22411;&#24369;&#30417;&#30563;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#8220;&#20048;&#35266;&#20027;&#20041;&#8221;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#23454;&#38469;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20998;&#26512;&#24072;&#25253;&#21578;&#21644;&#30408;&#21033;&#30005;&#35805;&#20013;&#30340;&#32034;&#36180;&#23545;&#37329;&#34701;&#24066;&#22330;&#22238;&#25253;&#30340;&#24433;&#21709;&#65292;&#23558;&#23427;&#20204;&#35270;&#20026;&#19978;&#24066;&#20844;&#21496;&#37325;&#35201;&#30340;&#23395;&#24230;&#20107;&#20214;&#12290;&#20026;&#20102;&#36827;&#34892;&#20840;&#38754;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#37329;&#34701;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#37329;&#34701;&#39046;&#22495;&#30340;&#32034;&#36180;&#26816;&#27979;&#20219;&#21153;&#12290;&#25105;&#20204;&#22312;&#35813;&#25968;&#25454;&#38598;&#19978;&#23545;&#21508;&#31181;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#20837;&#20027;&#39064;&#19987;&#23478;&#65288;SMEs&#65289;&#30693;&#35782;&#30340;&#26032;&#22411;&#24369;&#30417;&#30563;&#27169;&#22411;&#65292;&#22312;&#32858;&#21512;&#20989;&#25968;&#20013;&#36229;&#36234;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#8220;&#20048;&#35266;&#20027;&#20041;&#8221;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#30340;&#23454;&#38469;&#25928;&#29992;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;&#30408;&#21033;&#24778;&#21916;&#21644;&#22238;&#25253;&#23545;&#25105;&#20204;&#30340;&#20048;&#35266;&#20027;&#20041;&#24230;&#37327;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#12289;&#27169;&#22411;&#21644;&#20195;&#30721;&#23558;&#22312;GitHub&#21644;Hugging Face&#19978;&#20844;&#24320;&#65288;&#36981;&#24490;CC BY 4.0&#35768;&#21487;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11728v1 Announce Type: new  Abstract: In this paper, we investigate the influence of claims in analyst reports and earnings calls on financial market returns, considering them as significant quarterly events for publicly traded companies. To facilitate a comprehensive analysis, we construct a new financial dataset for the claim detection task in the financial domain. We benchmark various language models on this dataset and propose a novel weak-supervision model that incorporates the knowledge of subject matter experts (SMEs) in the aggregation function, outperforming existing approaches. Furthermore, we demonstrate the practical utility of our proposed model by constructing a novel measure ``optimism". Furthermore, we observed the dependence of earnings surprise and return on our optimism measure. Our dataset, models, and code will be made publicly (under CC BY 4.0 license) available on GitHub and Hugging Face.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31354;&#36755;&#20837;&#25552;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#22266;&#26377;&#20559;&#24046;&#65292;&#20174;&#32780;&#25552;&#21319;&#38646;/&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.10353</link><description>&lt;p&gt;
&#25552;&#21319;&#22522;&#20110;&#25552;&#31034;&#30340;&#35821;&#35328;&#27169;&#22411;&#38646;/&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#20559;&#24046;&#26657;&#20934;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31354;&#36755;&#20837;&#25552;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#22266;&#26377;&#20559;&#24046;&#65292;&#20174;&#32780;&#25552;&#21319;&#38646;/&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#23398;&#20064;&#23481;&#26131;&#21463;&#21040;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#22266;&#26377;&#20559;&#24046;&#30340;&#24433;&#21709;&#65292;&#23548;&#33268;&#22522;&#20110;&#25552;&#31034;&#30340;&#38646;/&#23569;&#26679;&#26412;&#23398;&#20064;&#24615;&#33021;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31354;&#36755;&#20837;&#25552;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#32534;&#30721;&#30340;&#22266;&#26377;&#20559;&#24046;&#12290;&#19982;&#20197;&#24448;&#20027;&#35201;&#33268;&#21147;&#20110;&#31038;&#20250;&#20844;&#24179;&#30340;&#22266;&#26377;&#20559;&#24046;&#20462;&#27491;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#22312;&#19979;&#28216;&#38646;/&#23569;&#26679;&#26412;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#24378;&#35843;&#22266;&#26377;&#20559;&#24046;&#26657;&#20934;&#30340;&#25928;&#29575;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#20174;GPT-4&#29983;&#25104;&#30340;&#19968;&#32452;&#33258;&#21160;&#36873;&#21462;&#30340;&#26080;&#24847;&#20041;&#36755;&#20837;&#26469;&#25552;&#31034;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20197;&#25506;&#27979;&#22266;&#26377;&#20559;&#24046;&#12290;&#21033;&#29992;&#20559;&#24046;&#21453;&#26144;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#24046;&#24322;&#25439;&#22833;&#29992;&#20110;&#20559;&#24046;&#26657;&#20934;&#65292;&#20854;&#20013;&#25105;&#20204;&#20165;&#26356;&#26032;&#35821;&#35328;&#27169;&#22411;&#30340;&#20559;&#24046;&#21442;&#25968;&#65288;&#24635;&#21442;&#25968;&#30340;0.1%&#65289;&#20197;&#26397;&#21521;&#30456;&#31561;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10353v1 Announce Type: new  Abstract: Prompt learning is susceptible to intrinsic bias present in pre-trained language models (LMs), resulting in sub-optimal performance of prompt-based zero/few-shot learning. In this work, we propose a null-input prompting method to calibrate intrinsic bias encoded in pre-trained LMs. Different from prior efforts that address intrinsic bias primarily for social fairness and often involve excessive computational cost, our objective is to explore enhancing LMs' performance in downstream zero/few-shot learning while emphasizing the efficiency of intrinsic bias calibration. Specifically, we leverage a diverse set of auto-selected null-meaning inputs generated from GPT-4 to prompt pre-trained LMs for intrinsic bias probing. Utilizing the bias-reflected probability distribution, we formulate a distribution disparity loss for bias calibration, where we exclusively update bias parameters ($0.1\%$ of total parameters) of LMs towards equal probabilit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#25945;&#23398;&#23545;&#40784;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26032;&#27010;&#24565;&#65292;&#24182;&#25506;&#35752;&#20102;&#36890;&#36807;&#24314;&#35774;&#24615;&#21453;&#39304;&#21644;&#25552;&#31034;&#25351;&#23548;&#23398;&#29983;&#35299;&#20915;&#22797;&#26434;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#36825;&#31181;&#23545;&#40784;&#26041;&#27861;&#20197;&#21450;&#37319;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#23545;&#40784;LLM&#65292;&#25552;&#20379;&#26356;&#20248;&#36136;&#30340;&#25945;&#32946;&#25903;&#25345;&#12290;</title><link>https://arxiv.org/abs/2402.05000</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25945;&#23398;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Pedagogical Alignment of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#25945;&#23398;&#23545;&#40784;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26032;&#27010;&#24565;&#65292;&#24182;&#25506;&#35752;&#20102;&#36890;&#36807;&#24314;&#35774;&#24615;&#21453;&#39304;&#21644;&#25552;&#31034;&#25351;&#23548;&#23398;&#29983;&#35299;&#20915;&#22797;&#26434;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#36825;&#31181;&#23545;&#40784;&#26041;&#27861;&#20197;&#21450;&#37319;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#23545;&#40784;LLM&#65292;&#25552;&#20379;&#26356;&#20248;&#36136;&#30340;&#25945;&#32946;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#25945;&#23398;&#23545;&#40784;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26032;&#27010;&#24565;&#65292;&#36825;&#22312;&#25945;&#32946;&#32972;&#26223;&#19979;&#24212;&#29992;LLM&#20855;&#26377;&#36716;&#21464;&#24615;&#30340;&#24847;&#20041;&#12290;&#19982;&#30452;&#25509;&#22238;&#31572;&#29992;&#25143;&#38382;&#39064;&#19981;&#21516;&#65292;&#25945;&#23398;&#23545;&#40784;&#30340;LLM&#20316;&#20026;&#36741;&#21161;&#24037;&#20855;&#65292;&#23558;&#22797;&#26434;&#38382;&#39064;&#20998;&#35299;&#20026;&#21487;&#31649;&#29702;&#30340;&#23376;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24314;&#35774;&#24615;&#30340;&#21453;&#39304;&#21644;&#25552;&#31034;&#25351;&#23548;&#23398;&#29983;&#25214;&#21040;&#26368;&#32456;&#31572;&#26696;&#12290;&#20854;&#30446;&#26631;&#26159;&#20026;&#23398;&#20064;&#32773;&#25552;&#20379;&#35299;&#20915;&#38382;&#39064;&#30340;&#31574;&#30053;&#65292;&#20197;&#21152;&#28145;&#20182;&#20204;&#23545;&#20027;&#39064;&#30340;&#29702;&#35299;&#21644;&#20869;&#21270;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#37319;&#29992;&#20102;&#30417;&#30563;&#24494;&#35843;&#26041;&#27861;&#65292;&#27809;&#26377;&#23558;&#30446;&#26631;&#23450;&#20041;&#20026;&#23545;&#40784;&#38382;&#39064;&#65292;&#24182;&#26410;&#20351;&#29992;&#36890;&#36807;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65288;RLHF&#65289;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#40784;&#30340;&#35270;&#35282;&#37325;&#26032;&#35299;&#37322;&#20102;&#36825;&#19968;&#35770;&#36848;&#65292;&#24182;&#23637;&#31034;&#20102;RLHF&#26041;&#27861;&#20316;&#20026;&#23545;&#40784;LLM&#30340;&#20248;&#36234;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce the novel concept of pedagogically aligned Large Language Models (LLMs) that signifies a transformative shift in the application of LLMs within educational contexts. Rather than providing direct responses to user queries, pedagogically-aligned LLMs function as scaffolding tools, breaking complex problems into manageable subproblems and guiding students towards the final answer through constructive feedback and hints. The objective is to equip learners with problem-solving strategies that deepen their understanding and internalization of the subject matter. Previous research in this field has primarily applied the supervised finetuning approach without framing the objective as an alignment problem, hence not employing reinforcement learning through human feedback (RLHF) methods. This study reinterprets the narrative by viewing the task through the lens of alignment and demonstrates how RLHF methods emerge naturally as a superior alternative for aligning LLM b
&lt;/p&gt;</description></item><item><title>&#26080;&#20559;&#22909;&#23545;&#40784;&#23398;&#20064;&#20351;&#29992;&#27491;&#21017;&#21270;&#30456;&#20851;&#22870;&#21169;&#20316;&#20026;&#20851;&#38190;&#30446;&#26631;&#65292;&#22312;&#25552;&#20379;&#31283;&#20581;&#22870;&#21169;&#20449;&#21495;&#30340;&#21516;&#26102;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#20559;&#22909;&#22522;&#20934;&#27979;&#35797;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.03469</link><description>&lt;p&gt;
&#26080;&#20559;&#22909;&#23545;&#40784;&#23398;&#20064;&#19982;&#27491;&#21017;&#21270;&#30456;&#20851;&#22870;&#21169;
&lt;/p&gt;
&lt;p&gt;
Preference-free Alignment Learning with Regularized Relevance Reward
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03469
&lt;/p&gt;
&lt;p&gt;
&#26080;&#20559;&#22909;&#23545;&#40784;&#23398;&#20064;&#20351;&#29992;&#27491;&#21017;&#21270;&#30456;&#20851;&#22870;&#21169;&#20316;&#20026;&#20851;&#38190;&#30446;&#26631;&#65292;&#22312;&#25552;&#20379;&#31283;&#20581;&#22870;&#21169;&#20449;&#21495;&#30340;&#21516;&#26102;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#20559;&#22909;&#22522;&#20934;&#27979;&#35797;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#34987;&#35748;&#20026;&#26159;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#23545;&#40784;&#30340;&#20851;&#38190;&#12290;&#28982;&#32780;&#65292;&#19982;&#26222;&#36941;&#30340;&#35266;&#28857;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#21021;&#27493;&#30740;&#31350;&#21457;&#29616;&#65292;&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;&#22870;&#21169;&#27169;&#22411;&#20542;&#21521;&#20110;&#32473;&#38271;&#30340;&#19982;&#20027;&#39064;&#26080;&#20851;&#30340;&#22238;&#22797;&#26356;&#39640;&#30340;&#20998;&#25968;&#65292;&#32780;&#32473;&#30701;&#30340;&#19982;&#20027;&#39064;&#30456;&#20851;&#30340;&#22238;&#22797;&#36739;&#20302;&#20998;&#12290;&#22312;&#36825;&#19968;&#35266;&#23519;&#30340;&#39537;&#21160;&#19979;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#26080;&#20559;&#22909;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#8220;&#30456;&#20851;&#24615;&#8221;&#20316;&#20026;&#23545;&#40784;&#30340;&#19968;&#20010;&#20851;&#38190;&#30446;&#26631;&#12290;&#22312;&#25105;&#20204;&#30340;&#31532;&#19968;&#27425;&#23581;&#35797;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20165;&#20165;&#36890;&#36807;&#26816;&#32034;&#24471;&#21040;&#30340;&#30456;&#20851;&#24615;&#24471;&#20998;&#23481;&#26131;&#21463;&#21040;&#22870;&#21169;&#27450;&#39575;&#30340;&#24433;&#21709;&#65292;&#21363;&#36807;&#24230;&#20248;&#21270;&#21040;&#19981;&#26399;&#26395;&#30340;&#25463;&#24452;&#19978;&#65292;&#24403;&#25105;&#20204;&#23558;&#35813;&#24471;&#20998;&#20316;&#20026;&#22870;&#21169;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#26377;&#25928;&#30340;&#24402;&#32435;&#20559;&#24046;&#25972;&#21512;&#21040;&#24120;&#35268;&#30340;&#30456;&#20851;&#24615;&#20013;&#65292;&#20114;&#30456;&#27491;&#21017;&#21270;&#65292;&#24418;&#25104;&#20102;&#19968;&#31181;&#28151;&#21512;&#22870;&#21169;&#20989;&#25968;&#65306;&#27491;&#21017;&#21270;&#30456;&#20851;&#22870;&#21169;&#65288;$R^3$&#65289;&#12290;$R^3$&#36890;&#36807;&#25552;&#20379;&#31283;&#20581;&#30340;&#22870;&#21169;&#20449;&#21495;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#22312;&#20559;&#22909;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;$R^3$&#19981;&#38656;&#35201;
&lt;/p&gt;
&lt;p&gt;
Learning from human preference has been considered key to aligning Large Language Models (LLMs) with human values. However, contrary to popular belief, our preliminary study reveals that reward models trained on human preference datasets tend to give higher scores to long off-topic responses than short on-topic ones. Motivated by this observation, we explore a preference-free approach utilizing `relevance' as a key objective for alignment. On our first attempt, we find that the relevance score obtained by a retriever alone is vulnerable to reward hacking, i.e., overoptimizing to undesired shortcuts, when we utilize the score as a reward for reinforcement learning. To mitigate it, we integrate effective inductive biases into the vanilla relevance to regularize each other, resulting in a mixture of reward functions: Regularized Relevance Reward ($R^3$). $R^3$ significantly improves performance on preference benchmarks by providing a robust reward signal. Notably, $R^3$ does not require a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545; GPT &#27169;&#22411;&#30340;&#23545;&#35805;&#37325;&#26500;&#25915;&#20987;&#65292;&#35813;&#25915;&#20987;&#20855;&#26377;&#21163;&#25345;&#20250;&#35805;&#21644;&#37325;&#26500;&#23545;&#35805;&#30340;&#20004;&#20010;&#27493;&#39588;&#12290;&#36890;&#36807;&#23545;&#35813;&#25915;&#20987;&#23545; GPT &#27169;&#22411;&#30340;&#38544;&#31169;&#39118;&#38505;&#36827;&#34892;&#35780;&#20272;&#65292;&#21457;&#29616; GPT-4 &#23545;&#35813;&#25915;&#20987;&#20855;&#26377;&#19968;&#23450;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02987</link><description>&lt;p&gt;
GPT &#27169;&#22411;&#30340;&#23545;&#35805;&#37325;&#26500;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Conversation Reconstruction Attack Against GPT Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545; GPT &#27169;&#22411;&#30340;&#23545;&#35805;&#37325;&#26500;&#25915;&#20987;&#65292;&#35813;&#25915;&#20987;&#20855;&#26377;&#21163;&#25345;&#20250;&#35805;&#21644;&#37325;&#26500;&#23545;&#35805;&#30340;&#20004;&#20010;&#27493;&#39588;&#12290;&#36890;&#36807;&#23545;&#35813;&#25915;&#20987;&#23545; GPT &#27169;&#22411;&#30340;&#38544;&#31169;&#39118;&#38505;&#36827;&#34892;&#35780;&#20272;&#65292;&#21457;&#29616; GPT-4 &#23545;&#35813;&#25915;&#20987;&#20855;&#26377;&#19968;&#23450;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#20854;&#20013; GPT &#31995;&#21015;&#27169;&#22411;&#20195;&#34920;&#30528;&#26368;&#20855;&#20195;&#34920;&#24615;&#30340;&#25104;&#26524;&#12290;&#20026;&#20102;&#20248;&#21270;&#20219;&#21153;&#25191;&#34892;&#65292;&#29992;&#25143;&#32463;&#24120;&#19982;&#25176;&#31649;&#22312;&#20113;&#29615;&#22659;&#20013;&#30340; GPT &#27169;&#22411;&#36827;&#34892;&#22810;&#36718;&#23545;&#35805;&#12290;&#36825;&#20123;&#22810;&#36718;&#23545;&#35805;&#24448;&#24448;&#21253;&#21547;&#31169;&#20154;&#20449;&#24687;&#65292;&#38656;&#35201;&#22312;&#20113;&#20013;&#36827;&#34892;&#20256;&#36755;&#21644;&#23384;&#20648;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#25805;&#20316;&#27169;&#24335;&#24341;&#20837;&#20102;&#39069;&#22806;&#30340;&#25915;&#20987;&#38754;&#12290;&#26412;&#25991;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545; GPT &#27169;&#22411;&#30340;&#29305;&#23450;&#23545;&#35805;&#37325;&#26500;&#25915;&#20987;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#23545;&#35805;&#37325;&#26500;&#25915;&#20987;&#30001;&#20004;&#20010;&#27493;&#39588;&#32452;&#25104;&#65306;&#21163;&#25345;&#20250;&#35805;&#21644;&#37325;&#26500;&#23545;&#35805;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23545;&#24403; GPT &#27169;&#22411;&#36973;&#21463;&#35813;&#25915;&#20987;&#26102;&#23545;&#35805;&#20013;&#22266;&#26377;&#30340;&#38544;&#31169;&#39118;&#38505;&#36827;&#34892;&#20102;&#35814;&#23613;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;GPT-4 &#23545;&#20110;&#35813;&#25915;&#20987;&#20855;&#26377;&#19968;&#23450;&#30340;&#40065;&#26834;&#24615;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#32423;&#25915;&#20987;&#65292;&#26088;&#22312;&#26356;&#22909;&#22320;&#37325;&#26500;&#20197;&#21069;&#30340;&#23545;&#35805;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent times, significant advancements have been made in the field of large language models (LLMs), represented by GPT series models. To optimize task execution, users often engage in multi-round conversations with GPT models hosted in cloud environments. These multi-round conversations, potentially replete with private information, require transmission and storage within the cloud. However, this operational paradigm introduces additional attack surfaces. In this paper, we first introduce a specific Conversation Reconstruction Attack targeting GPT models. Our introduced Conversation Reconstruction Attack is composed of two steps: hijacking a session and reconstructing the conversations. Subsequently, we offer an exhaustive evaluation of the privacy risks inherent in conversations when GPT models are subjected to the proposed attack. However, GPT-4 demonstrates certain robustness to the proposed attacks. We then introduce two advanced attacks aimed at better reconstructing previous c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22320;&#29702;&#20559;&#35265;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#23545;&#22320;&#29702;&#31354;&#38388;&#39044;&#27979;&#30340;&#31995;&#32479;&#38169;&#35823;&#65292;&#36890;&#36807;&#38646;&#23556;&#20987;&#22320;&#29702;&#31354;&#38388;&#39044;&#27979;&#26469;&#35780;&#20272;&#20854;&#23545;&#19990;&#30028;&#30340;&#35748;&#30693;&#12290;</title><link>https://arxiv.org/abs/2402.02680</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#22320;&#29702;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Geographically Biased
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22320;&#29702;&#20559;&#35265;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#23545;&#22320;&#29702;&#31354;&#38388;&#39044;&#27979;&#30340;&#31995;&#32479;&#38169;&#35823;&#65292;&#36890;&#36807;&#38646;&#23556;&#20987;&#22320;&#29702;&#31354;&#38388;&#39044;&#27979;&#26469;&#35780;&#20272;&#20854;&#23545;&#19990;&#30028;&#30340;&#35748;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20869;&#22312;&#22320;&#21547;&#26377;&#20854;&#35757;&#32451;&#35821;&#26009;&#24211;&#20013;&#30340;&#20559;&#35265;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#31038;&#20250;&#20260;&#23475;&#30340;&#25345;&#32493;&#23384;&#22312;&#12290;&#38543;&#30528;&#36825;&#20123;&#22522;&#30784;&#27169;&#22411;&#30340;&#24433;&#21709;&#21147;&#19981;&#26029;&#22686;&#38271;&#65292;&#29702;&#35299;&#21644;&#35780;&#20272;&#23427;&#20204;&#30340;&#20559;&#35265;&#23545;&#20110;&#23454;&#29616;&#20844;&#27491;&#21644;&#20934;&#30830;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#22320;&#29702;&#35270;&#35282;&#30740;&#31350;LLMs&#23545;&#25105;&#20204;&#25152;&#29983;&#27963;&#30340;&#19990;&#30028;&#30340;&#35748;&#30693;&#12290;&#36825;&#31181;&#26041;&#27861;&#29305;&#21035;&#24378;&#22823;&#65292;&#22240;&#20026;&#23545;&#20154;&#31867;&#29983;&#27963;&#20013;&#35832;&#22810;&#19982;&#22320;&#29702;&#31354;&#38388;&#30456;&#20851;&#30340;&#26041;&#38754;&#65288;&#22914;&#25991;&#21270;&#12289;&#31181;&#26063;&#12289;&#35821;&#35328;&#12289;&#25919;&#27835;&#21644;&#23447;&#25945;&#65289;&#26377;&#30528;&#26126;&#26174;&#30340;&#30495;&#23454;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21508;&#31181;&#38382;&#39064;&#22320;&#29702;&#20559;&#35265;&#65292;&#25105;&#20204;&#23558;&#20854;&#23450;&#20041;&#20026;&#22320;&#29702;&#31354;&#38388;&#39044;&#27979;&#20013;&#30340;&#31995;&#32479;&#38169;&#35823;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;LLMs&#33021;&#22815;&#36827;&#34892;&#31934;&#30830;&#30340;&#38646;&#23556;&#20987;&#22320;&#29702;&#31354;&#38388;&#39044;&#27979;&#65292;&#20197;&#35780;&#32423;&#30340;&#24418;&#24335;&#21576;&#29616;&#65292;&#20854;&#19982;&#30495;&#23454;&#24773;&#20917;&#20043;&#38388;&#21576;&#29616;&#20986;&#24378;&#28872;&#30340;&#21333;&#35843;&#30456;&#20851;&#24615;&#65288;Spearman's &#961;&#26368;&#39640;&#21487;&#36798;0.89&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;LLMs&#22312;&#22810;&#20010;&#23458;&#35266;&#21644;&#23376;&#39046;&#22495;&#19978;&#34920;&#29616;&#20986;&#20849;&#21516;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) inherently carry the biases contained in their training corpora, which can lead to the perpetuation of societal harm. As the impact of these foundation models grows, understanding and evaluating their biases becomes crucial to achieving fairness and accuracy. We propose to study what LLMs know about the world we live in through the lens of geography. This approach is particularly powerful as there is ground truth for the numerous aspects of human life that are meaningfully projected onto geographic space such as culture, race, language, politics, and religion. We show various problematic geographic biases, which we define as systemic errors in geospatial predictions. Initially, we demonstrate that LLMs are capable of making accurate zero-shot geospatial predictions in the form of ratings that show strong monotonic correlation with ground truth (Spearman's $\rho$ of up to 0.89). We then show that LLMs exhibit common biases across a range of objective and sub
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.02037</link><description>&lt;p&gt;
EffiBench:&#35780;&#20272;&#33258;&#21160;&#29983;&#25104;&#20195;&#30721;&#30340;&#25928;&#29575;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
EffiBench: Benchmarking the Efficiency of Automatically Generated Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02037
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#22312;&#36741;&#21161;&#36719;&#20214;&#24320;&#21457;&#26041;&#38754;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#21487;&#20197;&#24110;&#21161;&#23436;&#25104;&#20195;&#30721;&#34917;&#20840;&#12289;&#35843;&#35797;&#21644;&#20195;&#30721;&#36716;&#25442;&#31561;&#20219;&#21153;&#12290;&#23613;&#31649;&#24403;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#28145;&#20837;&#30740;&#31350;&#20102;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#27491;&#30830;&#24615;&#65292;&#20294;&#29983;&#25104;&#20195;&#30721;&#30340;&#25928;&#29575;&#36825;&#19968;&#37325;&#35201;&#26041;&#38754;&#24120;&#24120;&#34987;&#24573;&#35270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#65292;&#19968;&#20010;&#21253;&#21547;1,000&#20010;&#25928;&#29575;&#20851;&#38190;&#30340;&#32534;&#30721;&#38382;&#39064;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;EffiBench&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#22810;&#26679;&#21270;&#30340;LeetCode&#32534;&#30721;&#38382;&#39064;&#65292;&#27599;&#20010;&#38382;&#39064;&#37117;&#19982;&#19968;&#20010;&#21487;&#25191;&#34892;&#30340;&#20154;&#24037;&#32534;&#20889;&#30340;&#20856;&#22411;&#35299;&#20915;&#26041;&#26696;&#37197;&#23545;&#12290;&#36890;&#36807;EffiBench&#65292;&#25105;&#20204;&#22312;&#23454;&#36341;&#20013;&#32771;&#23519;&#20102;21&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#20854;&#20013;13&#31181;&#26159;&#24320;&#28304;&#30340;&#65292;8&#31181;&#26159;&#38381;&#28304;&#30340;&#65289;&#22312;&#29983;&#25104;&#39640;&#25928;&#20195;&#30721;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#65292;&#26126;&#26174;&#20248;&#20110;Palm-2-chat-bison&#12289;Claude-instant-1&#12289;Gemini-pro&#12289;GPT-4&#21644;GPT-3.5&#12290;
&lt;/p&gt;
&lt;p&gt;
Code generation models have increasingly become integral to aiding software development, offering assistance in tasks such as code completion, debugging, and code translation. Although current research has thoroughly examined the correctness of code produced by code generation models, a vital aspect, i.e., the efficiency of the generated code, has often been neglected. This paper presents EffiBench, a benchmark with 1,000 efficiency-critical coding problems for assessing the efficiency of code generated by code generation models. EffiBench contains a diverse set of LeetCode coding problems. Each problem is paired with an executable human-written canonical solution. With EffiBench, we empirically examine the capability of 21 Large Language Models (13 open-sourced and 8 closed-sourced) in generating efficient code. The results demonstrate that GPT-4-turbo generates the most efficient code, significantly outperforming Palm-2-chat-bison, Claude-instant-1, Gemini-pro, GPT-4, and GPT-3.5. Ne
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#32416;&#27491;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;CRAG&#65289;&#26469;&#25913;&#21892;&#29983;&#25104;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#35774;&#35745;&#36731;&#37327;&#32423;&#26816;&#32034;&#35780;&#20272;&#22120;&#21644;&#21033;&#29992;&#22823;&#35268;&#27169;&#32593;&#32476;&#25628;&#32034;&#25193;&#23637;&#26816;&#32034;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2401.15884</link><description>&lt;p&gt;
&#32416;&#27491;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Corrective Retrieval Augmented Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15884
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#32416;&#27491;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;CRAG&#65289;&#26469;&#25913;&#21892;&#29983;&#25104;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#35774;&#35745;&#36731;&#37327;&#32423;&#26816;&#32034;&#35780;&#20272;&#22120;&#21644;&#21033;&#29992;&#22823;&#35268;&#27169;&#32593;&#32476;&#25628;&#32034;&#25193;&#23637;&#26816;&#32034;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19981;&#21487;&#36991;&#20813;&#22320;&#20986;&#29616;&#24187;&#35273;&#65292;&#22240;&#20026;&#29983;&#25104;&#30340;&#25991;&#26412;&#20934;&#30830;&#24615;&#19981;&#33021;&#20165;&#36890;&#36807;&#23427;&#20204;&#23553;&#35013;&#30340;&#21442;&#25968;&#21270;&#30693;&#35782;&#26469;&#20445;&#35777;&#12290;&#23613;&#31649;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26159;&#23545;LLMs&#30340;&#21487;&#34892;&#34917;&#20805;&#65292;&#20294;&#23427;&#20005;&#37325;&#20381;&#36182;&#20110;&#26816;&#32034;&#25991;&#26723;&#30340;&#30456;&#20851;&#24615;&#65292;&#24341;&#21457;&#20102;&#22914;&#26524;&#26816;&#32034;&#20986;&#29616;&#38382;&#39064;&#27169;&#22411;&#23558;&#22914;&#20309;&#34892;&#20026;&#30340;&#25285;&#24551;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32416;&#27491;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;CRAG&#65289;&#26469;&#25552;&#39640;&#29983;&#25104;&#30340;&#40065;&#26834;&#24615;&#12290;&#20855;&#20307;&#22320;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#26816;&#32034;&#35780;&#20272;&#22120;&#65292;&#29992;&#20110;&#35780;&#20272;&#20026;&#26597;&#35810;&#26816;&#32034;&#30340;&#25991;&#26723;&#30340;&#25972;&#20307;&#36136;&#37327;&#65292;&#26681;&#25454;&#36820;&#22238;&#30340;&#32622;&#20449;&#24230;&#35302;&#21457;&#19981;&#21516;&#30340;&#30693;&#35782;&#26816;&#32034;&#25805;&#20316;&#12290;&#30001;&#20110;&#20174;&#38745;&#24577;&#21644;&#26377;&#38480;&#30340;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#21482;&#33021;&#36820;&#22238;&#27425;&#20248;&#25991;&#26723;&#65292;&#22240;&#27492;&#21033;&#29992;&#22823;&#35268;&#27169;&#32593;&#32476;&#25628;&#32034;&#20316;&#20026;&#25193;&#23637;&#26469;&#22686;&#24378;&#26816;&#32034;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#36824;&#26377;&#19968;&#20010;&#20998;&#35299;-&#37325;&#32452;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.15884v2 Announce Type: replace  Abstract: Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong. To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose alg
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#20174;&#20301;&#32622;&#32534;&#30721;&#30340;&#35282;&#24230;&#24635;&#32467;&#20102;&#29992;&#20110;&#22686;&#24378;Transformer&#38271;&#24230;&#22806;&#25512;&#33021;&#21147;&#30340;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#32477;&#23545;&#21644;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#20197;&#21450;&#22522;&#20110;&#23427;&#20204;&#30340;&#22806;&#25512;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2312.17044</link><description>&lt;p&gt;
Transformer&#38271;&#24230;&#22806;&#25512;&#65306;&#20174;&#20301;&#32622;&#32534;&#30721;&#30340;&#35282;&#24230;&#36827;&#34892;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.17044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#20174;&#20301;&#32622;&#32534;&#30721;&#30340;&#35282;&#24230;&#24635;&#32467;&#20102;&#29992;&#20110;&#22686;&#24378;Transformer&#38271;&#24230;&#22806;&#25512;&#33021;&#21147;&#30340;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#32477;&#23545;&#21644;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#20197;&#21450;&#22522;&#20110;&#23427;&#20204;&#30340;&#22806;&#25512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#33258;&#35806;&#29983;&#20197;&#26469;&#24050;&#32463;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#25472;&#36215;&#20102;&#19968;&#32929;&#39118;&#26292;&#12290;&#24314;&#31435;&#22312;&#20854;&#22522;&#30784;&#19978;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30001;&#20110;&#20854;&#20986;&#33394;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#20840;&#29699;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#21253;&#25324;&#36825;&#20123;&#24378;&#22823;&#30340;LLMs&#22312;&#20869;&#30340;&#25152;&#26377;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#37117;&#21463;&#21046;&#20110;&#39044;&#35774;&#30340;&#38271;&#24230;&#38480;&#21046;&#65292;&#24456;&#38590;&#20174;&#30701;&#35757;&#32451;&#24207;&#21015;&#25512;&#24191;&#21040;&#26356;&#38271;&#30340;&#25512;&#26029;&#24207;&#21015;&#65292;&#21363;&#23427;&#20204;&#26080;&#27861;&#36827;&#34892;&#38271;&#24230;&#22806;&#25512;&#12290;&#22240;&#27492;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#22823;&#37327;&#26041;&#27861;&#26469;&#22686;&#24378;Transformer&#30340;&#38271;&#24230;&#22806;&#25512;&#33021;&#21147;&#65292;&#20854;&#20013;&#20301;&#32622;&#32534;&#30721;&#65288;PE&#65289;&#34987;&#35748;&#20026;&#26159;&#20027;&#35201;&#22240;&#32032;&#12290; &#22312;&#36825;&#39033;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#20174;PE&#30340;&#35282;&#24230;&#20197;&#32479;&#19968;&#31526;&#21495;&#20171;&#32461;&#20102;&#36825;&#20123;&#20851;&#20110;&#38271;&#24230;&#22806;&#25512;&#30340;&#36827;&#23637;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#21487;&#22806;&#25512;&#30340;PE&#65292;&#21253;&#25324;&#32477;&#23545;&#21644;&#30456;&#23545;PE&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#22522;&#20110;&#23427;&#20204;&#30340;&#22806;&#25512;&#26041;&#27861;&#65292;&#28085;&#30422;&#20102;&#20301;&#32622;&#25554;&#20540;&#21644;&#38543;&#26426;&#21270;&#20301;&#32622;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.17044v3 Announce Type: replace  Abstract: Transformer has taken the field of natural language processing (NLP) by storm since its birth. Further, Large language models (LLMs) built upon it have captured worldwide attention due to its superior abilities. Nevertheless, all Transformer-based models including these powerful LLMs suffer from a preset length limit and can hardly generalize from short training sequences to longer inference ones, namely, they can not perform length extrapolation. Hence, a plethora of methods have been proposed to enhance length extrapolation of Transformer, in which the positional encoding (PE) is recognized as the major factor. In this survey, we present these advances towards length extrapolation in a unified notation from the perspective of PE. Specifically, we first introduce extrapolatable PEs, including absolute and relative PEs. Then, we dive into extrapolation methods based on them, covering position interpolation and randomized position met
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#20219;&#21153;&#20013;&#33258;&#30456;&#30683;&#30462;&#30340;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#28041;&#21450;&#19978;&#19979;&#25991;&#20449;&#24687;&#29702;&#35299;&#25110;&#24120;&#35782;&#30340;&#20219;&#21153;&#20013;&#32463;&#24120;&#23384;&#22312;&#33258;&#30456;&#30683;&#30462;&#65292;&#32780;&#39640;&#20934;&#30830;&#24615;&#24182;&#19981;&#24635;&#26159;&#23545;&#24212;&#36739;&#20302;&#30340;&#33258;&#30456;&#30683;&#30462;&#29575;&#12290;</title><link>https://arxiv.org/abs/2311.09603</link><description>&lt;p&gt;
&#33258;&#30456;&#30683;&#30462;&#25512;&#29702;&#35780;&#20272;&#19982;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Self-Contradictory Reasoning Evaluation and Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09603
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#20219;&#21153;&#20013;&#33258;&#30456;&#30683;&#30462;&#30340;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#28041;&#21450;&#19978;&#19979;&#25991;&#20449;&#24687;&#29702;&#35299;&#25110;&#24120;&#35782;&#30340;&#20219;&#21153;&#20013;&#32463;&#24120;&#23384;&#22312;&#33258;&#30456;&#30683;&#30462;&#65292;&#32780;&#39640;&#20934;&#30830;&#24615;&#24182;&#19981;&#24635;&#26159;&#23545;&#24212;&#36739;&#20302;&#30340;&#33258;&#30456;&#30683;&#30462;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#22823;&#37327;&#24037;&#20316;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#35768;&#22810;&#25552;&#20986;&#30340;&#19979;&#28216;&#25512;&#29702;&#20219;&#21153;&#20027;&#35201;&#20851;&#27880;&#24615;&#33021;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#20004;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;1&#65289;&#25512;&#29702;&#36136;&#37327;&#26377;&#22810;&#21487;&#38752;&#65292;2&#65289;&#27169;&#22411;&#33021;&#21542;&#26816;&#27979;&#21040;&#19981;&#21487;&#38752;&#30340;&#25512;&#29702;&#65311;&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#30456;&#30683;&#30462;&#65288;Self-Contra&#65289;&#25512;&#29702;&#65292;&#21363;&#27169;&#22411;&#25512;&#29702;&#19981;&#25903;&#25345;&#39044;&#27979;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#35299;&#20915;&#31532;&#19968;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#22235;&#20010;&#25968;&#25454;&#38598;&#20013;&#30340;Self-Contra&#29575;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;&#33258;&#30456;&#30683;&#30462;&#25512;&#29702;&#30340;&#26356;&#32454;&#31890;&#24230;&#31867;&#21035;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36827;&#34892;&#28041;&#21450;&#19978;&#19979;&#25991;&#20449;&#24687;&#29702;&#35299;&#25110;&#24120;&#35782;&#30340;&#25512;&#29702;&#20219;&#21153;&#26102;&#32463;&#24120;&#33258;&#30456;&#30683;&#30462;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#24182;&#19981;&#19968;&#23450;&#23545;&#24212;&#26356;&#20302;&#30340;&#33258;&#30456;&#30683;&#30462;&#29575;&#12290;&#27169;&#22411;&#21487;&#33021;&#20250;&#20135;&#29983;&#27491;&#30830;&#31572;&#26696;&#65292;&#20294;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#21487;&#33021;&#20250;&#37319;&#21462;&#25463;&#24452;&#25110;&#24573;&#30053;&#19978;&#19979;&#25991;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09603v2 Announce Type: replace  Abstract: In a plethora of recent work, large language models (LLMs) demonstrated impressive reasoning ability, but many proposed downstream reasoning tasks focus on performance-wise evaluation. Two fundamental questions persist: 1) how reliable is the quality of reasoning, and 2) can models detect unreliable reasoning? In this paper, we investigate self-contradictory (Self-Contra) reasoning, where the model reasoning does not support predictions. To address 1), we assess the Self-Contra rate across four datasets and delve into finer-grained categories of Self-Contra reasoning. We find that LLMs often contradict themselves when performing reasoning tasks that involve contextual information understanding or commonsense. Importantly, a higher accuracy does not necessarily correspond to a lower Self-Contra rate. The model may appear to generate correct answers but it may take shortcuts in reasoning or skip over contextual evidence, thereby displa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#25506;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#31038;&#20250;&#20559;&#35265;&#30340;&#21407;&#21019;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#19968;&#33324;&#20851;&#32852;&#21644;&#31038;&#20250;&#31867;&#21035;&#12289;&#36523;&#20221;&#20197;&#21450;&#21051;&#26495;&#21360;&#35937;&#30340;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2311.09090</link><description>&lt;p&gt;
&#31038;&#20250;&#20559;&#35265;&#25506;&#27979;&#65306;&#35821;&#35328;&#27169;&#22411;&#30340;&#20844;&#24179;&#22522;&#20934;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Social Bias Probing: Fairness Benchmarking for Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#25506;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#31038;&#20250;&#20559;&#35265;&#30340;&#21407;&#21019;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#19968;&#33324;&#20851;&#32852;&#21644;&#31038;&#20250;&#31867;&#21035;&#12289;&#36523;&#20221;&#20197;&#21450;&#21051;&#26495;&#21360;&#35937;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#34987;&#35777;&#26126;&#32534;&#30721;&#20102;&#21508;&#31181;&#31038;&#20250;&#20559;&#35265;&#65292;&#36825;&#24102;&#26469;&#20102;&#19979;&#28216;&#39118;&#38505;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#25506;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#31038;&#20250;&#20559;&#35265;&#30340;&#21407;&#21019;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#35821;&#35328;&#27169;&#22411;&#30340;&#19968;&#33324;&#20851;&#32852;&#20197;&#21450;&#31038;&#20250;&#31867;&#21035;&#12289;&#36523;&#20221;&#21644;&#21051;&#26495;&#21360;&#35937;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09090v2 Announce Type: replace  Abstract: Large language models have been shown to encode a variety of social biases, which carries the risk of downstream harms. While the impact of these biases has been recognized, prior methods for bias evaluation have been limited to binary association tests on small datasets, offering a constrained view of the nature of societal biases within language models. In this paper, we propose an original framework for probing language models for societal biases. We collect a probing dataset to analyze language models' general associations, as well as along the axes of societal categories, identities, and stereotypes. To this end, we leverage a novel perplexity-based fairness score. We curate a large-scale benchmarking dataset addressing drawbacks and limitations of existing fairness collections, expanding to a variety of different identities and stereotypes. When comparing our methodology with prior work, we demonstrate that biases within langua
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLMs&#22686;&#24378;&#21307;&#23398;&#25945;&#31185;&#20070;&#65288;LLM-AMT&#65289;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#25554;&#20837;&#24335;&#27169;&#22359;&#23558;&#26435;&#23041;&#21307;&#23398;&#25945;&#31185;&#20070;&#38598;&#25104;&#21040;LLMs&#30340;&#26694;&#26550;&#20013;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;LLMs&#22312;&#19987;&#19994;&#39046;&#22495;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2309.02233</link><description>&lt;p&gt;
&#29992;&#21307;&#23398;&#25945;&#31185;&#20070;&#22686;&#24378;&#40657;&#30418;LLMs&#36827;&#34892;&#20020;&#24202;&#38382;&#39064;&#22238;&#31572;
&lt;/p&gt;
&lt;p&gt;
Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.02233
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLMs&#22686;&#24378;&#21307;&#23398;&#25945;&#31185;&#20070;&#65288;LLM-AMT&#65289;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#25554;&#20837;&#24335;&#27169;&#22359;&#23558;&#26435;&#23041;&#21307;&#23398;&#25945;&#31185;&#20070;&#38598;&#25104;&#21040;LLMs&#30340;&#26694;&#26550;&#20013;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;LLMs&#22312;&#19987;&#19994;&#39046;&#22495;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;ChatGPT&#24050;&#32463;&#23637;&#31034;&#20986;&#26681;&#25454;&#20154;&#31867;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#30340;&#21360;&#35937;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#32570;&#20047;&#29305;&#23450;&#12289;&#28145;&#20837;&#30340;&#30693;&#35782;&#65292;&#23427;&#20204;&#22312;&#21307;&#23398;&#39046;&#22495;&#30340;&#24212;&#29992;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLMs&#22686;&#24378;&#21307;&#23398;&#25945;&#31185;&#20070;&#65288;LLM-AMT&#65289;&#30340;&#31995;&#32479;&#65292;&#26088;&#22312;&#22686;&#24378;LLMs&#22312;&#19987;&#19994;&#39046;&#22495;&#30340;&#33021;&#21147;&#12290;LLM-AMT&#36890;&#36807;&#25554;&#20837;&#24335;&#27169;&#22359;&#23558;&#26435;&#23041;&#21307;&#23398;&#25945;&#31185;&#20070;&#38598;&#25104;&#21040;LLMs&#30340;&#26694;&#26550;&#20013;&#12290;&#36825;&#20123;&#27169;&#22359;&#21253;&#25324;&#19968;&#20010;&#26597;&#35810;&#22686;&#24378;&#22120;&#12289;&#19968;&#20010;&#28151;&#21512;&#25945;&#31185;&#20070;&#26816;&#32034;&#22120;&#21644;&#19968;&#20010;&#30693;&#35782;&#33258;&#25105;&#23436;&#21892;&#12290;&#23427;&#20204;&#20849;&#21516;&#25972;&#21512;&#26435;&#23041;&#21307;&#23398;&#30693;&#35782;&#12290;&#27492;&#22806;&#65292;&#19968;&#20010;LLMs&#38405;&#35835;&#22120;&#26377;&#21161;&#20110;&#19978;&#19979;&#25991;&#29702;&#35299;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#21307;&#23398;&#38382;&#31572;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;LLMAMT&#26174;&#33879;&#25552;&#39640;&#20102;&#21709;&#24212;&#36136;&#37327;&#65292;&#20934;&#30830;&#29575;&#25552;&#39640;&#20102;11.6%&#21040;16.6%&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#20197;GPT-4-Turbo&#20026;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.02233v2 Announce Type: replace-cross  Abstract: Large-scale language models (LLMs) like ChatGPT have demonstrated impressive abilities in generating responses based on human instructions. However, their use in the medical field can be challenging due to their lack of specific, in-depth knowledge. In this study, we present a system called LLMs Augmented with Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in specialized domains. LLM-AMT integrates authoritative medical textbooks into the LLMs' framework using plug-and-play modules. These modules include a Query Augmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together, they incorporate authoritative medical knowledge. Additionally, an LLM Reader aids in contextual understanding. Our experimental results on three medical QA tasks demonstrate that LLMAMT significantly improves response quality, with accuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the base mod
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20027;&#35201;&#20171;&#32461;&#20102;&#19968;&#31181;&#35780;&#20272;LLM&#20195;&#29702;&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#21028;&#26029;&#23433;&#20840;&#39118;&#38505;&#33021;&#21147;&#30340;&#22522;&#20934;&#27979;&#35797;R-Judge&#65292;&#36890;&#36807;&#23545;162&#20010;&#20195;&#29702;&#20132;&#20114;&#35760;&#24405;&#36827;&#34892;&#35780;&#20272;&#65292;&#21457;&#29616;GPT-4&#27169;&#22411;&#34920;&#29616;&#26368;&#20339;&#65292;&#36798;&#21040;&#20102;72.29%&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.10019</link><description>&lt;p&gt;
R-Judge: &#35780;&#20272;LLM&#20195;&#29702;&#30340;&#23433;&#20840;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
R-Judge: Benchmarking Safety Risk Awareness for LLM Agents. (arXiv:2401.10019v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10019
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20027;&#35201;&#20171;&#32461;&#20102;&#19968;&#31181;&#35780;&#20272;LLM&#20195;&#29702;&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#21028;&#26029;&#23433;&#20840;&#39118;&#38505;&#33021;&#21147;&#30340;&#22522;&#20934;&#27979;&#35797;R-Judge&#65292;&#36890;&#36807;&#23545;162&#20010;&#20195;&#29702;&#20132;&#20114;&#35760;&#24405;&#36827;&#34892;&#35780;&#20272;&#65292;&#21457;&#29616;GPT-4&#27169;&#22411;&#34920;&#29616;&#26368;&#20339;&#65292;&#36798;&#21040;&#20102;72.29%&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#33258;&#21160;&#23436;&#25104;&#21508;&#31181;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20219;&#21153;&#26041;&#38754;&#23637;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;LLM&#20195;&#29702;&#22312;&#20132;&#20114;&#29615;&#22659;&#20013;&#25805;&#20316;&#26102;&#20250;&#24341;&#20837;&#24847;&#22806;&#30340;&#23433;&#20840;&#39118;&#38505;&#12290;&#19982;&#22823;&#22810;&#25968;&#20043;&#21069;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;LLM&#29983;&#25104;&#20869;&#23481;&#30340;&#23433;&#20840;&#24615;&#19981;&#21516;&#65292;&#26412;&#30740;&#31350;&#20851;&#27880;&#35780;&#20272;LLM&#20195;&#29702;&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#30340;&#34892;&#20026;&#23433;&#20840;&#24615;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;R-Judge&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;LLM&#22312;&#32473;&#23450;&#20195;&#29702;&#20132;&#20114;&#35760;&#24405;&#26102;&#21028;&#26029;&#23433;&#20840;&#39118;&#38505;&#30340;&#33021;&#21147;&#12290;R-Judge&#21253;&#25324;162&#20010;&#20195;&#29702;&#20132;&#20114;&#35760;&#24405;&#65292;&#28085;&#30422;7&#20010;&#24212;&#29992;&#39046;&#22495;&#21644;10&#31181;&#39118;&#38505;&#31867;&#22411;&#30340;27&#20010;&#20851;&#38190;&#39118;&#38505;&#22330;&#26223;&#12290;&#23427;&#32467;&#21512;&#20102;&#20154;&#31867;&#23545;&#23433;&#20840;&#24615;&#30340;&#20849;&#35782;&#65292;&#24182;&#20855;&#26377;&#26631;&#35760;&#30340;&#23433;&#20840;&#39118;&#38505;&#26631;&#31614;&#21644;&#39640;&#36136;&#37327;&#30340;&#39118;&#38505;&#25551;&#36848;&#12290;&#21033;&#29992;R-Judge&#65292;&#25105;&#20204;&#23545;8&#31181;&#24120;&#29992;&#20316;&#20195;&#29702;&#39592;&#24178;&#30340;&#33879;&#21517;LLM&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#12290;&#34920;&#29616;&#26368;&#22909;&#30340;&#27169;&#22411;GPT-4&#23454;&#29616;&#20102;72.29%&#30340;&#23545;&#27604;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications. Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments. Instead of centering on LLM-generated content safety in most prior studies, this work addresses the imperative need for benchmarking the behavioral safety of LLM agents within diverse environments. We introduce R-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging safety risks given agent interaction records. R-Judge comprises 162 agent interaction records, encompassing 27 key risk scenarios among 7 application categories and 10 risk types. It incorporates human consensus on safety with annotated safety risk labels and high-quality risk descriptions. Utilizing R-Judge, we conduct a comprehensive evaluation of 8 prominent LLMs commonly employed as the backbone for agents. The best-performing model, GPT-4, achieves 72.29% in contrast to
&lt;/p&gt;</description></item><item><title>&#33258;&#25105;&#31361;&#20986;&#24335;&#29369;&#35947;&#65288;SH2&#65289;&#26159;&#19968;&#31181;&#25512;&#29702;&#26102;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#39044;&#27979;&#27010;&#29575;&#36739;&#20302;&#30340;&#26631;&#35760;&#65292;&#24182;&#24378;&#35843;&#23427;&#20204;&#30340;&#24046;&#24322;&#65292;&#20174;&#32780;&#24110;&#21161;&#35821;&#35328;&#27169;&#22411;&#26356;&#20934;&#30830;&#22320;&#35299;&#30721;&#12290;</title><link>http://arxiv.org/abs/2401.05930</link><description>&lt;p&gt;
SH2: &#33258;&#25105;&#31361;&#20986;&#24335;&#29369;&#35947;&#24110;&#21161;&#24744;&#26356;&#20934;&#30830;&#35299;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully. (arXiv:2401.05930v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05930
&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#31361;&#20986;&#24335;&#29369;&#35947;&#65288;SH2&#65289;&#26159;&#19968;&#31181;&#25512;&#29702;&#26102;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#39044;&#27979;&#27010;&#29575;&#36739;&#20302;&#30340;&#26631;&#35760;&#65292;&#24182;&#24378;&#35843;&#23427;&#20204;&#30340;&#24046;&#24322;&#65292;&#20174;&#32780;&#24110;&#21161;&#35821;&#35328;&#27169;&#22411;&#26356;&#20934;&#30830;&#22320;&#35299;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;LLMs&#20173;&#28982;&#23384;&#22312;&#24187;&#35273;&#38382;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25512;&#29702;&#26102;&#26041;&#27861;&#65292;&#21363;&#33258;&#25105;&#31361;&#20986;&#24335;&#29369;&#35947;(SH2)&#65292;&#20197;&#24110;&#21161;LLMs&#26356;&#20934;&#30830;&#22320;&#35299;&#30721;&#12290;SH2&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#20013;&#19968;&#20010;&#31616;&#21333;&#30340;&#20107;&#23454;&#65292;&#21363;&#23545;&#20110;LLMs&#32780;&#35328;&#65292;&#39044;&#27979;&#27010;&#29575;&#36739;&#20302;&#30340;&#26631;&#35760;&#24448;&#24448;&#26356;&#20855;&#20449;&#24687;&#37327;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;LLMs&#32473;&#20104;&#36739;&#20302;&#27010;&#29575;&#30340;&#26631;&#35760;&#26356;&#26377;&#21487;&#33021;&#19982;&#20107;&#23454;&#20449;&#24687;&#65288;&#22914;&#21517;&#35789;&#12289;&#19987;&#26377;&#21517;&#35789;&#21644;&#24418;&#23481;&#35789;&#65289;&#23494;&#20999;&#30456;&#20851;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#36873;&#25321;&#27010;&#29575;&#26368;&#20302;&#30340;&#26631;&#35760;&#24182;&#23558;&#20854;&#36830;&#25509;&#21040;&#21407;&#22987;&#19978;&#19979;&#25991;&#20013;&#26469;&#8220;&#31361;&#20986;&#8221;&#20107;&#23454;&#20449;&#24687;&#65292;&#20174;&#32780;&#36843;&#20351;&#27169;&#22411;&#22312;&#29983;&#25104;&#20043;&#21069;&#22810;&#27425;&#38405;&#35835;&#21644;&#29369;&#35947;&#36825;&#20123;&#26631;&#35760;&#12290;&#22312;&#35299;&#30721;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#37319;&#29992;&#23545;&#27604;&#35299;&#30721;&#30340;&#26041;&#24335;&#26469;&#24378;&#35843;&#30001;&#29369;&#35947;&#24102;&#26469;&#30340;&#36755;&#20986;&#27010;&#29575;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) demonstrate great performance in text generation. However, LLMs are still suffering from hallucinations. In this work, we propose an inference-time method, Self-Highlighted Hesitation (SH2), to help LLMs decode more truthfully. SH2 is based on a simple fact rooted in information theory that for an LLM, the tokens predicted with lower probabilities are prone to be more informative than others. Our analysis shows that the tokens assigned with lower probabilities by an LLM are more likely to be closely related to factual information, such as nouns, proper nouns, and adjectives. Therefore, we propose to ''highlight'' the factual information by selecting the tokens with the lowest probabilities and concatenating them to the original context, thus forcing the model to repeatedly read and hesitate on these tokens before generation. During decoding, we also adopt contrastive decoding to emphasize the difference in the output probabilities brought by the hesitation.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#29992;&#25143;&#32842;&#22825;&#26426;&#22120;&#20154;&#26694;&#26550;&#65288;MUCA&#65289;&#65292;&#35813;&#26694;&#26550;&#25903;&#25345;&#32676;&#32452;&#35752;&#35770;&#65292;&#24182;&#25552;&#20379;&#20102;&#19977;&#20010;&#20027;&#35201;&#27169;&#22359;&#26469;&#30830;&#23450;&#22238;&#24212;&#20869;&#23481;&#12289;&#26102;&#26426;&#21644;&#36866;&#24403;&#30340;&#25509;&#25910;&#32773;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#29992;&#25143;&#27169;&#25311;&#22120;&#65288;MUS&#65289;&#65292;&#29992;&#20110;&#27169;&#25311;&#30495;&#23454;&#29992;&#25143;&#34892;&#20026;&#65292;&#20197;&#20415;&#26356;&#39640;&#25928;&#22320;&#27979;&#35797;&#21644;&#20248;&#21270;&#32842;&#22825;&#26426;&#22120;&#20154;&#12290;</title><link>http://arxiv.org/abs/2401.04883</link><description>&lt;p&gt;
&#22810;&#29992;&#25143;&#32842;&#22825;&#21161;&#25163;&#65288;MUCA&#65289;&#65306;&#19968;&#31181;&#20351;&#29992;LLMs&#26694;&#26550;&#20419;&#36827;&#32676;&#20307;&#23545;&#35805;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate Group Conversations. (arXiv:2401.04883v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04883
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#29992;&#25143;&#32842;&#22825;&#26426;&#22120;&#20154;&#26694;&#26550;&#65288;MUCA&#65289;&#65292;&#35813;&#26694;&#26550;&#25903;&#25345;&#32676;&#32452;&#35752;&#35770;&#65292;&#24182;&#25552;&#20379;&#20102;&#19977;&#20010;&#20027;&#35201;&#27169;&#22359;&#26469;&#30830;&#23450;&#22238;&#24212;&#20869;&#23481;&#12289;&#26102;&#26426;&#21644;&#36866;&#24403;&#30340;&#25509;&#25910;&#32773;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#29992;&#25143;&#27169;&#25311;&#22120;&#65288;MUS&#65289;&#65292;&#29992;&#20110;&#27169;&#25311;&#30495;&#23454;&#29992;&#25143;&#34892;&#20026;&#65292;&#20197;&#20415;&#26356;&#39640;&#25928;&#22320;&#27979;&#35797;&#21644;&#20248;&#21270;&#32842;&#22825;&#26426;&#22120;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#23637;&#20026;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#26032;&#30340;&#36884;&#24452;&#65292;&#32780;&#22823;&#37096;&#20998;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#21333;&#29992;&#25143;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#19978;&#65292;&#37325;&#28857;&#25918;&#22312;&#29992;&#25143;&#36755;&#20837;&#21518;&#20915;&#23450;&#8220;&#22238;&#31572;&#20160;&#20040;&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22810;&#29992;&#25143;&#32842;&#22825;&#26426;&#22120;&#20154;&#26377;&#26356;&#22797;&#26434;&#30340;3W&#35774;&#35745;&#32500;&#24230;&#8212;&#8212;&#22914;&#20309;&#22238;&#31572;&#65292;&#8220;&#20309;&#26102;&#8221;&#22238;&#24212;&#65292;&#8220;&#22238;&#31572;&#35841;&#8221;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Multi-User Chat Assistant (MUCA)&#30340;&#22522;&#20110;LLM&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#26694;&#26550;&#65292;&#19987;&#38376;&#29992;&#20110;&#32676;&#32452;&#35752;&#35770;&#12290;MUCA&#30001;&#19977;&#20010;&#20027;&#35201;&#27169;&#22359;&#32452;&#25104;&#65306;&#23376;&#20027;&#39064;&#29983;&#25104;&#22120;&#65292;&#23545;&#35805;&#20998;&#26512;&#22120;&#21644;&#35805;&#35821;&#31574;&#30053;&#20210;&#35009;&#22120;&#12290;&#36825;&#20123;&#27169;&#22359;&#20849;&#21516;&#30830;&#23450;&#21512;&#36866;&#30340;&#22238;&#24212;&#20869;&#23481;&#12289;&#26102;&#26426;&#21644;&#36866;&#24403;&#30340;&#25509;&#25910;&#32773;&#12290;&#20026;&#20102;&#20351;MUCA&#30340;&#20248;&#21270;&#36807;&#31243;&#26356;&#23481;&#26131;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#22810;&#29992;&#25143;&#27169;&#25311;&#22120;&#65288;MUS&#65289;&#65292;&#21487;&#20197;&#27169;&#25311;&#30495;&#23454;&#29992;&#25143;&#34892;&#20026;&#12290;&#36825;&#20351;&#24471;&#32842;&#22825;&#26426;&#22120;&#20154;&#21644;&#27169;&#25311;&#29992;&#25143;&#20043;&#38388;&#30340;&#23545;&#35805;&#36827;&#34892;&#26356;&#24555;&#36895;&#30340;&#27169;&#25311;&#65292;&#20174;&#32780;&#20351;&#24471;&#26089;&#26399;&#27979;&#35797;&#21644;&#20248;&#21270;&#36807;&#31243;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in large language models (LLMs) have provided a new avenue for chatbot development, while most existing research has primarily centered on single-user chatbots that focus on deciding "What" to answer after user inputs. In this paper, we identified that multi-user chatbots have more complex 3W design dimensions -- "What" to say, "When" to respond, and "Who" to answer. Additionally, we proposed Multi-User Chat Assistant (MUCA), which is an LLM-based framework for chatbots specifically designed for group discussions. MUCA consists of three main modules: Sub-topic Generator, Dialog Analyzer, and Utterance Strategies Arbitrator. These modules jointly determine suitable response contents, timings, and the appropriate recipients. To make the optimizing process for MUCA easier, we further propose an LLM-based Multi-User Simulator (MUS) that can mimic real user behavior. This enables faster simulation of a conversation between the chatbot and simulated users, making the earl
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35770;&#25991;&#25351;&#20986;&#65292;&#27169;&#22411;&#32534;&#36753;&#21487;&#33021;&#20250;&#25913;&#21892;&#27169;&#22411;&#30340;&#20107;&#23454;&#24615;&#65292;&#20294;&#20250;&#20197;&#38477;&#20302;&#27169;&#22411;&#30340;&#36890;&#29992;&#33021;&#21147;&#20026;&#20195;&#20215;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#36890;&#36807;&#35780;&#20272;&#22235;&#31181;&#32534;&#36753;&#26041;&#27861;&#22312;&#20004;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#36825;&#20123;&#32534;&#36753;&#26041;&#27861;&#24448;&#24448;&#24573;&#35270;&#20102;&#23545;&#27169;&#22411;&#36890;&#29992;&#33021;&#21147;&#21487;&#33021;&#20135;&#29983;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.04700</link><description>&lt;p&gt;
&#27169;&#22411;&#32534;&#36753;&#21487;&#33021;&#20250;&#25439;&#23475;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Model Editing Can Hurt General Abilities of Large Language Models. (arXiv:2401.04700v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04700
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35770;&#25991;&#25351;&#20986;&#65292;&#27169;&#22411;&#32534;&#36753;&#21487;&#33021;&#20250;&#25913;&#21892;&#27169;&#22411;&#30340;&#20107;&#23454;&#24615;&#65292;&#20294;&#20250;&#20197;&#38477;&#20302;&#27169;&#22411;&#30340;&#36890;&#29992;&#33021;&#21147;&#20026;&#20195;&#20215;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#36890;&#36807;&#35780;&#20272;&#22235;&#31181;&#32534;&#36753;&#26041;&#27861;&#22312;&#20004;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#36825;&#20123;&#32534;&#36753;&#26041;&#27861;&#24448;&#24448;&#24573;&#35270;&#20102;&#23545;&#27169;&#22411;&#36890;&#29992;&#33021;&#21147;&#21487;&#33021;&#20135;&#29983;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#20026;&#25105;&#20204;&#33719;&#21462;&#20854;&#21442;&#25968;&#20013;&#23384;&#20648;&#30340;&#30693;&#35782;&#25552;&#20379;&#20102;&#26032;&#30340;&#33539;&#24335;&#12290;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#26159;LLM&#36755;&#20986;&#20013;&#23384;&#22312;&#38169;&#35273;&#65292;&#36825;&#26159;&#30001;&#20110;&#38169;&#35823;&#25110;&#36807;&#26102;&#30693;&#35782;&#24341;&#36215;&#30340;&#12290;&#30001;&#20110;&#20351;&#29992;&#26356;&#26032;&#21518;&#30340;&#20449;&#24687;&#37325;&#26032;&#35757;&#32451;LLM&#38656;&#35201;&#22823;&#37327;&#36164;&#28304;&#65292;&#22240;&#27492;&#20154;&#20204;&#23545;&#27169;&#22411;&#32534;&#36753;&#20135;&#29983;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#22312;&#21508;&#31181;&#22330;&#26223;&#20013;&#24456;&#26377;&#25928;&#65292;&#20294;&#24448;&#24448;&#36807;&#20110;&#24378;&#35843;&#32534;&#36753;&#24615;&#33021;&#30340;&#21151;&#25928;&#12289;&#27867;&#21270;&#24615;&#21644;&#23616;&#37096;&#24615;&#65292;&#24120;&#24120;&#24573;&#35270;&#20102;&#23545;LLM&#30340;&#36890;&#29992;&#33021;&#21147;&#21487;&#33021;&#20135;&#29983;&#30340;&#21103;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#25913;&#21892;&#27169;&#22411;&#30340;&#20107;&#23454;&#24615;&#21487;&#33021;&#20250;&#20197;&#30456;&#24403;&#22823;&#30340;&#36890;&#29992;&#33021;&#21147;&#19979;&#38477;&#20026;&#20195;&#20215;&#30340;&#25285;&#24551;&#65292;&#36825;&#19981;&#31526;&#21512;LLM&#21487;&#25345;&#32493;&#21457;&#23637;&#30340;&#35201;&#27714;&#12290;&#25105;&#20204;&#36890;&#36807;&#35780;&#20272;&#22235;&#31181;&#24120;&#29992;&#30340;&#32534;&#36753;&#26041;&#27861;&#22312;&#20004;&#20010;LLM&#19978;&#36827;&#34892;&#20102;&#31995;&#32479;&#20998;&#26512;&#21103;&#20316;&#29992;&#65292;&#24182;&#28085;&#30422;&#20102;&#20843;&#20010;&#20195;&#34920;&#24615;&#20219;&#21153;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in large language models (LLMs) have opened up new paradigms for accessing the knowledge stored in their parameters. One critical challenge that has emerged is the presence of hallucinations in LLM outputs due to false or outdated knowledge. Since retraining LLMs with updated information is resource-intensive, there has been a growing interest in model editing. However, many model editing methods, while effective in various scenarios, tend to overemphasize aspects such as efficacy, generalization, and locality in editing performance, often overlooking potential side effects on the general abilities of LLMs. In this paper, we raise concerns that the improvement of model factuality may come at the cost of a significant degradation of these general abilities, which is not conducive to the sustainable development of LLMs. Systematically, we analyze side effects by evaluating four popular editing methods on two LLMs across eight representative task categories. Extensive empi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#26816;&#27979;&#23459;&#20256;&#24615;&#25991;&#26412;&#36328;&#24230;&#30340;&#20219;&#21153;&#65292;&#24182;&#30740;&#31350;&#20102;&#21033;&#29992;&#35813;&#27169;&#22411;&#25910;&#38598;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26631;&#27880;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2311.09812</link><description>&lt;p&gt;
&#29992;&#20110;&#23459;&#20256;&#24615;&#36328;&#24230;&#27880;&#37322;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large Language Models for Propaganda Span Annotation. (arXiv:2311.09812v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.09812
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#26816;&#27979;&#23459;&#20256;&#24615;&#25991;&#26412;&#36328;&#24230;&#30340;&#20219;&#21153;&#65292;&#24182;&#30740;&#31350;&#20102;&#21033;&#29992;&#35813;&#27169;&#22411;&#25910;&#38598;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26631;&#27880;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;&#32447;&#20869;&#23481;&#20013;&#20351;&#29992;&#23459;&#20256;&#25163;&#27861;&#30340;&#24773;&#20917;&#26377;&#25152;&#22686;&#21152;&#65292;&#26088;&#22312;&#25805;&#32437;&#22312;&#32447;&#21463;&#20247;&#12290;&#38024;&#23545;&#21508;&#31181;&#24314;&#27169;&#22330;&#26223;&#65292;&#24050;&#32463;&#20570;&#20986;&#20102;&#33258;&#21160;&#26816;&#27979;&#21644;&#25581;&#38706;&#27492;&#31867;&#20869;&#23481;&#30340;&#21162;&#21147;&#12290;&#36825;&#20123;&#22330;&#26223;&#21253;&#25324;&#30830;&#23450;&#20869;&#23481;&#65288;&#25991;&#26412;&#12289;&#22270;&#20687;&#25110;&#22810;&#27169;&#24577;&#65289;&#26159;&#21542;&#20855;&#26377;&#20197;&#19979;&#29305;&#24449;&#65306;&#65288;i&#65289;&#20855;&#26377;&#23459;&#20256;&#24615;&#65292;&#65288;ii&#65289;&#20351;&#29992;&#19968;&#31181;&#25110;&#22810;&#31181;&#23459;&#20256;&#25163;&#27861;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#21253;&#21547;&#20855;&#26377;&#21487;&#35782;&#21035;&#33539;&#22260;&#30340;&#25216;&#24039;&#12290;&#19982;&#21069;&#20004;&#31181;&#22330;&#26223;&#30456;&#27604;&#65292;&#24050;&#32463;&#23545;&#21518;&#19968;&#31181;&#22330;&#26223;&#36827;&#34892;&#20102;&#36739;&#22823;&#30340;&#30740;&#31350;&#24037;&#20316;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#20851;&#27880;&#26816;&#27979;&#23459;&#20256;&#24615;&#25991;&#26412;&#36328;&#24230;&#30340;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT-4&#65289;&#26159;&#21542;&#33021;&#22815;&#26377;&#25928;&#25191;&#34892;&#35813;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21033;&#29992;&#35813;&#27169;&#22411;&#25910;&#38598;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26631;&#27880;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20351;&#29992;&#20102;&#19968;&#22871;&#22823;&#35268;&#27169;&#30340;&#20869;&#37096;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#26469;&#33258;&#20855;&#26377;&#19981;&#21516;&#19987;&#19994;&#27700;&#24179;&#30340;&#20154;&#24037;&#26631;&#27880;&#32773;&#30340;&#27880;&#37322;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;
&lt;/p&gt;
&lt;p&gt;
The use of propagandistic techniques in online contents has increased in recent years aiming to manipulate online audiences. Efforts to automatically detect and debunk such content have been made addressing various modeling scenarios. These include determining whether the content (text, image, or multimodal) (i) is propagandistic, (ii) employs one or more propagandistic techniques, and (iii) includes techniques with identifiable spans. Significant research efforts have been devoted to the first two scenarios compared to the latter. Therefore, in this study, we focus on the task of detecting propagandistic textual spans. Specifically, we investigate whether large language models (LLMs), such as GPT-4, can effectively perform the task. Moreover, we study the potential of employing the model to collect more cost-effective annotations. Our experiments use a large-scale in-house dataset consisting of annotations from human annotators with varying expertise levels. The results suggest that p
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLM-TSE&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#29992;&#25143;&#38190;&#20837;&#30340;&#25991;&#26412;&#36755;&#20837;&#20013;&#25552;&#21462;&#35821;&#20041;&#32447;&#32034;&#65292;&#20197;&#22686;&#24378;&#30446;&#26631;&#35828;&#35805;&#20154;&#25552;&#21462;(TSE)&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#21644;&#21487;&#25511;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07284</link><description>&lt;p&gt;
&#25171;&#23383;&#20542;&#21548;&#40481;&#23614;&#37202;&#20250;&#65306;&#25991;&#26412;&#24341;&#23548;&#30340;&#30446;&#26631;&#35828;&#35805;&#20154;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction. (arXiv:2310.07284v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07284
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLM-TSE&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#29992;&#25143;&#38190;&#20837;&#30340;&#25991;&#26412;&#36755;&#20837;&#20013;&#25552;&#21462;&#35821;&#20041;&#32447;&#32034;&#65292;&#20197;&#22686;&#24378;&#30446;&#26631;&#35828;&#35805;&#20154;&#25552;&#21462;(TSE)&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#21644;&#21487;&#25511;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#25317;&#26377;&#19968;&#31181;&#22312;&#22797;&#26434;&#30340;&#22768;&#23398;&#29615;&#22659;&#20013;&#26377;&#36873;&#25321;&#24615;&#22320;&#19987;&#27880;&#20110;&#24863;&#20852;&#36259;&#30340;&#22768;&#38899;&#28304;&#30340;&#38750;&#20961;&#33021;&#21147;&#65292;&#36890;&#24120;&#31216;&#20026;&#40481;&#23614;&#37202;&#20250;&#22330;&#26223;&#12290;&#20026;&#20102;&#22312;&#26426;&#22120;&#20013;&#22797;&#21046;&#36825;&#31181;&#24341;&#20154;&#27880;&#30446;&#30340;&#21548;&#35273;&#27880;&#24847;&#33021;&#21147;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20102;&#30446;&#26631;&#35828;&#35805;&#20154;&#25552;&#21462;(TSE)&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#21033;&#29992;&#30446;&#26631;&#35828;&#35805;&#20154;&#30340;&#39044;&#20808;&#27880;&#20876;&#32447;&#32034;&#26469;&#25552;&#21462;&#24863;&#20852;&#36259;&#30340;&#22768;&#28304;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#24773;&#26223;&#20013;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#21463;&#21040;&#20102;&#39044;&#20808;&#27880;&#20876;&#32447;&#32034;&#30340;&#21487;&#33021;&#21464;&#21270;&#29978;&#33267;&#32570;&#22833;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#23558;&#33258;&#28982;&#35821;&#35328;&#25972;&#21512;&#21040;&#29616;&#26377;TSE&#27169;&#22411;&#20013;&#20197;&#22686;&#24378;&#20854;&#28789;&#27963;&#24615;&#21644;&#21487;&#25511;&#24615;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LLM-TSE&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#20174;&#29992;&#25143;&#30340;&#38190;&#20837;&#25991;&#26412;&#36755;&#20837;&#20013;&#25552;&#21462;&#26377;&#29992;&#30340;&#35821;&#20041;&#32447;&#32034;&#65292;&#36825;&#20123;&#32447;&#32034;&#21487;&#20197;&#34917;&#20805;&#39044;&#20808;&#27880;&#20876;&#30340;&#32447;&#32034;&#25110;&#29420;&#31435;&#24037;&#20316;&#20197;&#25511;&#21046;TSE&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Humans possess an extraordinary ability to selectively focus on the sound source of interest amidst complex acoustic environments, commonly referred to as cocktail party scenarios. In an attempt to replicate this remarkable auditory attention capability in machines, target speaker extraction (TSE) models have been developed. These models leverage the pre-registered cues of the target speaker to extract the sound source of interest. However, the effectiveness of these models is hindered in real-world scenarios due to the potential variation or even absence of pre-registered cues. To address this limitation, this study investigates the integration of natural language to enhance the flexibility and controllability of existing TSE models. Specifically, we propose a model named LLM-TSE, wherein a large language model (LLM) to extract useful semantic cues from the user's typed text input, which can complement the pre-registered cues or work independently to control the TSE process. Our exper
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27880;&#24847;&#21147;&#39537;&#21160;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#20809;&#27969;&#20449;&#24687;&#19982;RGB&#22270;&#20687;&#30456;&#32467;&#21512;&#65292;&#20016;&#23500;&#20102;&#36830;&#32493;&#25163;&#35821;&#35782;&#21035;&#21644;&#32763;&#35793;&#27969;&#31243;&#20013;&#30340;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#22312;&#25163;&#35821;&#35782;&#21035;&#20219;&#21153;&#20013;&#38477;&#20302;&#20102;WER 0.9&#65292;&#22312;&#32763;&#35793;&#20219;&#21153;&#20013;&#25552;&#39640;&#20102;&#27979;&#35797;&#38598;&#19978;&#22823;&#22810;&#25968;BLEU&#20998;&#25968;&#32422;0.6&#12290;</title><link>http://arxiv.org/abs/2309.01860</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#39537;&#21160;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;&#65306;&#22686;&#24378;&#25163;&#35821;&#35782;&#21035;&#21644;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation. (arXiv:2309.01860v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27880;&#24847;&#21147;&#39537;&#21160;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#20809;&#27969;&#20449;&#24687;&#19982;RGB&#22270;&#20687;&#30456;&#32467;&#21512;&#65292;&#20016;&#23500;&#20102;&#36830;&#32493;&#25163;&#35821;&#35782;&#21035;&#21644;&#32763;&#35793;&#27969;&#31243;&#20013;&#30340;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#22312;&#25163;&#35821;&#35782;&#21035;&#20219;&#21153;&#20013;&#38477;&#20302;&#20102;WER 0.9&#65292;&#22312;&#32763;&#35793;&#20219;&#21153;&#20013;&#25552;&#39640;&#20102;&#27979;&#35797;&#38598;&#19978;&#22823;&#22810;&#25968;BLEU&#20998;&#25968;&#32422;0.6&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26426;&#21046;&#65292;&#29992;&#20110;&#23558;&#22810;&#27169;&#24577;&#20449;&#24687;&#19982;&#29616;&#26377;&#30340;&#36830;&#32493;&#25163;&#35821;&#35782;&#21035;&#21644;&#32763;&#35793;&#27969;&#31243;&#30456;&#32467;&#21512;&#12290;&#22312;&#25105;&#20204;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23558;&#20809;&#27969;&#20449;&#24687;&#19982;RGB&#22270;&#20687;&#32467;&#21512;&#65292;&#20197;&#20016;&#23500;&#20855;&#26377;&#19982;&#36816;&#21160;&#30456;&#20851;&#20449;&#24687;&#30340;&#29305;&#24449;&#12290;&#35813;&#24037;&#20316;&#36890;&#36807;&#20351;&#29992;&#36328;&#27169;&#24577;&#32534;&#30721;&#22120;&#30740;&#31350;&#20102;&#36825;&#31181;&#27169;&#24577;&#21253;&#21547;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#30340;&#25554;&#20214;&#38750;&#24120;&#36731;&#37327;&#32423;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#20026;&#26032;&#27169;&#24577;&#21253;&#25324;&#19968;&#20010;&#21333;&#29420;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#12290;&#25105;&#20204;&#22312;&#25163;&#35821;&#35782;&#21035;&#21644;&#32763;&#35793;&#20013;&#24212;&#29992;&#20102;&#36825;&#20123;&#25913;&#21464;&#65292;&#25913;&#21892;&#20102;&#27599;&#20010;&#20219;&#21153;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;RWTH-PHOENIX-2014&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#24615;&#33021;&#65292;&#29992;&#20110;&#25163;&#35821;&#35782;&#21035;&#65292;&#24182;&#22312;RWTH-PHOENIX-2014T&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#32763;&#35793;&#20219;&#21153;&#12290;&#22312;&#35782;&#21035;&#20219;&#21153;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;WER&#38477;&#20302;&#20102;0.9&#65292;&#22312;&#32763;&#35793;&#20219;&#21153;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#22823;&#37096;&#20998;BLEU&#20998;&#25968;&#22312;&#27979;&#35797;&#38598;&#19978;&#25552;&#39640;&#20102;&#32422;0.6&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we devise a mechanism for the addition of multi-modal information with an existing pipeline for continuous sign language recognition and translation. In our procedure, we have incorporated optical flow information with RGB images to enrich the features with movement-related information. This work studies the feasibility of such modality inclusion using a cross-modal encoder. The plugin we have used is very lightweight and doesn't need to include a separate feature extractor for the new modality in an end-to-end manner. We have applied the changes in both sign language recognition and translation, improving the result in each case. We have evaluated the performance on the RWTH-PHOENIX-2014 dataset for sign language recognition and the RWTH-PHOENIX-2014T dataset for translation. On the recognition task, our approach reduced the WER by 0.9, and on the translation task, our approach increased most of the BLEU scores by ~0.6 on the test set.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#35770;&#35777;&#25366;&#25496;&#20219;&#21153;&#20013;&#65292;&#20351;&#29992;&#31934;&#24515;&#32452;&#32455;&#30340;&#35757;&#32451;&#26679;&#26412;&#21644;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#22312;&#20943;&#23567;&#35757;&#32451;&#26679;&#26412;&#22823;&#23567;&#33267;&#23569;85&#65285;&#30340;&#24773;&#20917;&#19979;&#65292;&#36798;&#21040;&#26368;&#22823;&#24615;&#33021;&#30340;95&#65285;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#20379;&#26410;&#26469;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2205.11472</link><description>&lt;p&gt;
&#22810;&#26679;&#24615;&#36229;&#36807;&#35268;&#27169;&#65306;&#20851;&#20110;&#35770;&#35777;&#25366;&#25496;&#25968;&#25454;&#38598;&#30340;&#26679;&#26412;&#21644;&#20027;&#39064;&#22823;&#23567;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Diversity Over Size: On the Effect of Sample and Topic Sizes for Argument Mining Datasets. (arXiv:2205.11472v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#35770;&#35777;&#25366;&#25496;&#20219;&#21153;&#20013;&#65292;&#20351;&#29992;&#31934;&#24515;&#32452;&#32455;&#30340;&#35757;&#32451;&#26679;&#26412;&#21644;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#22312;&#20943;&#23567;&#35757;&#32451;&#26679;&#26412;&#22823;&#23567;&#33267;&#23569;85&#65285;&#30340;&#24773;&#20917;&#19979;&#65292;&#36798;&#21040;&#26368;&#22823;&#24615;&#33021;&#30340;95&#65285;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#20379;&#26410;&#26469;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#35777;&#25366;&#25496;&#30340;&#20219;&#21153;&#26159;&#20174;&#22823;&#35268;&#27169;&#25991;&#26723;&#26469;&#28304;&#20013;&#25552;&#21462;&#29305;&#23450;&#20027;&#39064;&#30340;&#35770;&#35777;&#21477;&#23376;&#65292;&#36825;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#20154;&#31867;&#26469;&#35828;&#37117;&#26159;&#19968;&#39033;&#22256;&#38590;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#22823;&#35268;&#27169;&#30340;&#35770;&#35777;&#25366;&#25496;&#25968;&#25454;&#38598;&#24456;&#23569;&#65292;&#32780;&#35782;&#21035;&#35770;&#35777;&#21477;&#23376;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#12290;&#22914;&#26524;&#36824;&#28041;&#21450;&#21040;&#26816;&#27979;&#26816;&#32034;&#21040;&#30340;&#35770;&#35777;&#30340;&#31435;&#22330;&#65292;&#36825;&#20010;&#20219;&#21153;&#23601;&#26356;&#21152;&#22256;&#38590;&#20102;&#12290;&#37492;&#20110;&#21019;&#24314;&#21512;&#36866;&#35268;&#27169;&#30340;&#35770;&#35777;&#25366;&#25496;&#25968;&#25454;&#38598;&#30340;&#25104;&#26412;&#21644;&#22797;&#26434;&#24615;&#65292;&#25105;&#20204;&#24819;&#30693;&#36947;&#26159;&#21542;&#26377;&#24517;&#35201;&#20026;&#20102;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#24615;&#33021;&#32780;&#22686;&#21152;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#31934;&#24515;&#32452;&#32455;&#30340;&#35757;&#32451;&#26679;&#26412;&#21644;&#22312;&#30456;&#20851;&#20219;&#21153;&#19978;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#35757;&#32451;&#26679;&#26412;&#30340;&#22823;&#23567;&#20943;&#23569;&#33267;&#23569;85&#65285;&#65292;&#21516;&#26102;&#36798;&#21040;&#26368;&#22823;&#24615;&#33021;&#30340;95&#65285;&#12290;&#36825;&#31181;&#25910;&#30410;&#22312;&#19977;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#19977;&#20010;&#35770;&#35777;&#25366;&#25496;&#20219;&#21153;&#20013;&#26159;&#19968;&#33268;&#30340;&#12290;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#20379;&#26410;&#26469;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of Argument Mining, that is extracting argumentative sentences for a specific topic from large document sources, is an inherently difficult task for machine learning models and humans alike, as large Argument Mining datasets are rare and recognition of argumentative sentences requires expert knowledge. The task becomes even more difficult if it also involves stance detection of retrieved arguments. Given the cost and complexity of creating suitably large Argument Mining datasets, we ask whether it is necessary for acceptable performance to have datasets growing in size. Our findings show that, when using carefully composed training samples and a model pretrained on related tasks, we can reach 95% of the maximum performance while reducing the training sample size by at least 85%. This gain is consistent across three Argument Mining tasks on three different datasets. We also publish a new dataset for future benchmarking.
&lt;/p&gt;</description></item></channel></rss>