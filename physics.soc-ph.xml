<rss version="2.0"><channel><title>Chat Arxiv physics.soc-ph</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for physics.soc-ph</description><item><title>&#36890;&#36807;&#20351;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#23558;&#34892;&#20154;&#23454;&#29616;&#20026;MARL&#20195;&#29702;&#65292;&#30740;&#31350;&#20102;&#20182;&#20204;&#23398;&#20064;&#36991;&#35753;&#20854;&#20182;&#20195;&#29702;&#21521;&#21069;&#31227;&#21160;&#30340;&#33021;&#21147;&#65292;&#22312;&#23494;&#24230;&#19981;&#22826;&#39640;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#25104;&#21151;&#12290;</title><link>https://arxiv.org/abs/2312.11834</link><description>&lt;p&gt;
&#20351;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#21450;&#20854;&#22312;&#34892;&#20154;&#21160;&#24577;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11834
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#23558;&#34892;&#20154;&#23454;&#29616;&#20026;MARL&#20195;&#29702;&#65292;&#30740;&#31350;&#20102;&#20182;&#20204;&#23398;&#20064;&#36991;&#35753;&#20854;&#20182;&#20195;&#29702;&#21521;&#21069;&#31227;&#21160;&#30340;&#33021;&#21147;&#65292;&#22312;&#23494;&#24230;&#19981;&#22826;&#39640;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30740;&#31350;&#20351;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#27169;&#25311;&#34892;&#20154;&#12290;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#32593;&#26684;&#19990;&#30028;&#29615;&#22659;&#20013;&#30340;&#36947;&#36335;&#65292;&#24182;&#23558;&#34892;&#20154;&#23454;&#29616;&#20026;&#20351;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#21644;&#26368;&#23567;&#20108;&#20056;&#31574;&#30053;&#36845;&#20195;&#26041;&#27861;&#30340;MARL&#20195;&#29702;&#12290;&#22312;&#36825;&#20010;&#29615;&#22659;&#19979;&#65292;&#30740;&#31350;&#20102;&#36825;&#20123;&#20195;&#29702;&#23398;&#20064;&#36991;&#24320;&#20854;&#20182;&#20195;&#29702;&#21521;&#21069;&#31227;&#21160;&#30340;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#20219;&#21153;&#65306;&#31364;&#30452;&#25509;&#36335;&#24452;&#21644;&#23485;&#32469;&#36947;&#20043;&#38388;&#30340;&#36873;&#25321;&#65292;&#20197;&#21450;&#36208;&#24266;&#20013;&#30340;&#21452;&#21521;&#34892;&#20154;&#27969;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#20195;&#29702;&#23494;&#24230;&#19981;&#22826;&#39640;&#26102;&#65292;&#23398;&#20064;&#26159;&#25104;&#21151;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.11834v2 Announce Type: replace-cross  Abstract: In recent years, simulations of pedestrians using the multi-agent reinforcement learning (MARL) have been studied. This study considered the roads on a grid-world environment, and implemented pedestrians as MARL agents using an echo-state network and the least squares policy iteration method. Under this environment, the ability of these agents to learn to move forward by avoiding other agents was investigated. Specifically, we considered two types of tasks: the choice between a narrow direct route and a broad detour, and the bidirectional pedestrian flow in a corridor. The simulations results indicated that the learning was successful when the density of the agents was not that high.
&lt;/p&gt;</description></item></channel></rss>