<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#26368;&#20248;&#24615;&#21407;&#29702;&#30740;&#31350;&#20102;&#20998;&#23618;&#20449;&#24687;&#20849;&#20139;&#30340;&#20998;&#24067;&#24335;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#38382;&#39064;&#20998;&#35299;&#25104;&#21333;&#38454;&#27573;&#23376;&#28216;&#25103;&#65292;&#24182;&#36890;&#36807;&#36827;&#19968;&#27493;&#20998;&#35299;&#23376;&#28216;&#25103;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#35299;&#24320;&#20102;&#20915;&#31574;&#21464;&#37327;&#30340;&#32416;&#32544;&#65292;&#21516;&#26102;&#26174;&#33879;&#20943;&#23569;&#20102;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.02954</link><description>&lt;p&gt;
&#35299;&#20915;&#20998;&#23618;&#20449;&#24687;&#20849;&#20139;&#30340;&#20998;&#24067;&#24335;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65306;&#19968;&#31181;&#24191;&#20041;&#21338;&#24328;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Solving Hierarchical Information-Sharing Dec-POMDPs: An Extensive-Form Game Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#26368;&#20248;&#24615;&#21407;&#29702;&#30740;&#31350;&#20102;&#20998;&#23618;&#20449;&#24687;&#20849;&#20139;&#30340;&#20998;&#24067;&#24335;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#38382;&#39064;&#20998;&#35299;&#25104;&#21333;&#38454;&#27573;&#23376;&#28216;&#25103;&#65292;&#24182;&#36890;&#36807;&#36827;&#19968;&#27493;&#20998;&#35299;&#23376;&#28216;&#25103;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#35299;&#24320;&#20102;&#20915;&#31574;&#21464;&#37327;&#30340;&#32416;&#32544;&#65292;&#21516;&#26102;&#26174;&#33879;&#20943;&#23569;&#20102;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#22810;&#20154;&#20998;&#25955;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#21487;&#20197;&#36716;&#21270;&#20026;&#31561;&#25928;&#30340;&#21333;&#20154;&#28216;&#25103;&#65292;&#20351;&#24471;&#21487;&#20197;&#24212;&#29992;&#36125;&#23572;&#26364;&#30340;&#26368;&#20248;&#24615;&#21407;&#29702;&#36890;&#36807;&#23558;&#20854;&#20998;&#35299;&#20026;&#21333;&#38454;&#27573;&#23376;&#28216;&#25103;&#26469;&#35299;&#20915;&#21333;&#20154;&#28216;&#25103;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#27599;&#20010;&#21333;&#38454;&#27573;&#23376;&#28216;&#25103;&#20013;&#32416;&#32544;&#20102;&#25152;&#26377;&#29609;&#23478;&#30340;&#20915;&#31574;&#21464;&#37327;&#65292;&#23548;&#33268;&#25351;&#25968;&#22797;&#26434;&#24230;&#30340;&#22791;&#20221;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#20445;&#25345;&#20998;&#23618;&#20449;&#24687;&#20849;&#20139;&#30340;&#21069;&#25552;&#19979;&#35299;&#24320;&#36825;&#20123;&#20915;&#31574;&#21464;&#37327;&#30340;&#32416;&#32544;&#65292;&#36825;&#26159;&#25105;&#20204;&#31038;&#20250;&#20013;&#19968;&#31181;&#31361;&#20986;&#30340;&#31649;&#29702;&#39118;&#26684;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#24212;&#29992;&#26368;&#20248;&#24615;&#21407;&#29702;&#36890;&#36807;&#36827;&#19968;&#27493;&#23558;&#20219;&#20309;&#21333;&#38454;&#27573;&#23376;&#28216;&#25103;&#20998;&#35299;&#20026;&#26356;&#23567;&#30340;&#23376;&#28216;&#25103;&#26469;&#35299;&#20915;&#23427;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#36880;&#27425;&#36827;&#34892;&#21333;&#20154;&#20915;&#31574;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25581;&#31034;&#20102;&#23384;&#22312;&#20110;&#21333;&#38454;&#27573;&#23376;&#28216;&#25103;&#20013;&#30340;&#24191;&#20041;&#21338;&#24328;&#35299;&#20915;&#26041;&#26696;&#65292;&#26497;&#22823;&#22320;&#20943;&#23569;&#20102;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#35777;&#26126;&#23427;&#21487;&#20197;&#22312;&#35299;&#20915;&#20998;&#23618;&#20449;&#24687;&#20849;&#20139;&#30340;&#20998;&#24067;&#24335;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recent theory shows that a multi-player decentralized partially observable Markov decision process can be transformed into an equivalent single-player game, enabling the application of \citeauthor{bellman}'s principle of optimality to solve the single-player game by breaking it down into single-stage subgames. However, this approach entangles the decision variables of all players at each single-stage subgame, resulting in backups with a double-exponential complexity. This paper demonstrates how to disentangle these decision variables while maintaining optimality under hierarchical information sharing, a prominent management style in our society. To achieve this, we apply the principle of optimality to solve any single-stage subgame by breaking it down further into smaller subgames, enabling us to make single-player decisions at a time. Our approach reveals that extensive-form games always exist with solutions to a single-stage subgame, significantly reducing time complexity. Our expe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#36890;&#29992;&#27169;&#22411;&#30340;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#21033;&#28070;&#20998;&#20139;&#38382;&#39064;&#65292;&#20026;&#19968;&#33324;&#31867;&#30340;&#25104;&#26412;&#21644;&#25910;&#20837;&#20989;&#25968;&#25551;&#36848;&#20102;&#35299;&#20915;&#26041;&#26696;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2308.04399</link><description>&lt;p&gt;
Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models
&lt;/p&gt;
&lt;p&gt;
Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models. (arXiv:2308.04399v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#36890;&#29992;&#27169;&#22411;&#30340;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#21033;&#28070;&#20998;&#20139;&#38382;&#39064;&#65292;&#20026;&#19968;&#33324;&#31867;&#30340;&#25104;&#26412;&#21644;&#25910;&#20837;&#20989;&#25968;&#25551;&#36848;&#20102;&#35299;&#20915;&#26041;&#26696;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#21644;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#26041;&#38754;&#30340;&#37325;&#22823;&#36827;&#23637;&#36234;&#26469;&#36234;&#22810;&#22320;&#37319;&#29992;&#24320;&#21457;&#21644;&#21457;&#24067;&#36890;&#29992;&#27169;&#22411;&#30340;&#24418;&#24335;&#12290;&#36825;&#20123;&#27169;&#22411;&#26088;&#22312;&#30001;&#20854;&#20182;&#20225;&#19994;&#21644;&#26426;&#26500;&#36827;&#34892;&#36866;&#24212;&#65292;&#20197;&#25191;&#34892;&#29305;&#23450;&#30340;&#39046;&#22495;&#19987;&#29992;&#21151;&#33021;&#12290;&#36825;&#20010;&#36807;&#31243;&#34987;&#31216;&#20026;&#36866;&#24212;&#25110;&#24494;&#35843;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#24494;&#35843;&#36807;&#31243;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20301;&#36890;&#29992;&#19987;&#23478;&#23558;&#25216;&#26415;&#20135;&#21697;&#65288;&#21363;ML&#27169;&#22411;&#65289;&#25552;&#21319;&#21040;&#19968;&#23450;&#30340;&#24615;&#33021;&#27700;&#24179;&#65292;&#24182;&#19988;&#19968;&#20301;&#25110;&#22810;&#20301;&#39046;&#22495;&#19987;&#23478;&#23558;&#20854;&#35843;&#25972;&#36866;&#29992;&#20110;&#29305;&#23450;&#39046;&#22495;&#12290;&#36825;&#20004;&#20010;&#23454;&#20307;&#37117;&#26159;&#36861;&#27714;&#21033;&#28070;&#30340;&#65292;&#24403;&#20182;&#20204;&#25237;&#36164;&#20110;&#25216;&#26415;&#26102;&#20250;&#20135;&#29983;&#25104;&#26412;&#65292;&#22312;&#25216;&#26415;&#36827;&#20837;&#24066;&#22330;&#21069;&#65292;&#20182;&#20204;&#24517;&#39035;&#23601;&#22914;&#20309;&#20998;&#20139;&#25910;&#20837;&#36798;&#25104;&#35848;&#21028;&#21327;&#35758;&#12290;&#23545;&#20110;&#30456;&#23545;&#19968;&#33324;&#30340;&#25104;&#26412;&#21644;&#25910;&#20837;&#20989;&#25968;&#31867;&#65292;&#25105;&#20204;&#21051;&#30011;&#20102;&#24494;&#35843;&#21338;&#24328;&#20135;&#29983;&#21033;&#28070;&#20998;&#20139;&#35299;&#20915;&#26041;&#26696;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#20219;&#20309;&#28508;&#22312;&#30340;&#39046;&#22495;&#19987;&#19994;&#21270;&#37117;&#20250;&#20135;&#29983;...
&lt;/p&gt;
&lt;p&gt;
Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models. These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function. This process has become known as adaptation or fine-tuning. This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain. Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market. For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution. We observe that any potential domain-specialization will either contri
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.16695</link><description>&lt;p&gt;
&#23547;&#27714;&#31283;&#23450;&#24615;&#65306;&#20855;&#26377;&#21021;&#22987;&#25991;&#20214;&#30340;&#25112;&#30053;&#20986;&#29256;&#21830;&#30340;&#23398;&#20064;&#21160;&#24577;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Search for Stability: Learning Dynamics of Strategic Publishers with Initial Documents. (arXiv:2305.16695v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#21338;&#24328;&#35770;&#27169;&#22411;&#65292;&#20854;&#20013;&#25112;&#30053;&#20986;&#29256;&#21830;&#26088;&#22312;&#22312;&#20445;&#25345;&#21407;&#22987;&#25991;&#26723;&#23436;&#25972;&#24615;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#33258;&#24049;&#25490;&#21517;&#31532;&#19968;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24120;&#29992;&#30340;PRP&#25490;&#21517;&#26041;&#26696;&#23548;&#33268;&#29615;&#22659;&#19981;&#31283;&#23450;&#65292;&#28216;&#25103;&#32463;&#24120;&#26080;&#27861;&#36798;&#21040;&#32431;&#32435;&#20160;&#22343;&#34913;&#12290;&#25105;&#20204;&#23558;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#24182;&#20171;&#32461;&#20004;&#20010;&#25490;&#21517;&#20989;&#25968;&#65292;&#23427;&#20204;&#26159;RRP&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#65292;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#23548;&#33268;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#30340;&#31215;&#26497;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23450;&#20041;&#20986;&#29256;&#21830;&#21644;&#29992;&#25143;&#30340;&#31119;&#21033;&#65292;&#24182;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#65292;&#31361;&#26174;&#20102;&#30830;&#23450;&#25628;&#32034;&#24341;&#25806;&#35774;&#35745;&#24072;&#24212;&#36873;&#25321;&#21738;&#31181;&#25490;&#21517;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a game-theoretic model of information retrieval, in which strategic publishers aim to maximize their chances of being ranked first by the search engine, while maintaining the integrity of their original documents. We show that the commonly used PRP ranking scheme results in an unstable environment where games often fail to reach pure Nash equilibrium. We propose the Relative Ranking Principle (RRP) as an alternative ranking principle, and introduce two ranking functions that are instances of the RRP. We provide both theoretical and empirical evidence that these methods lead to a stable search ecosystem, by providing positive results on the learning dynamics convergence. We also define the publishers' and users' welfare, and demonstrate a possible publisher-user trade-off, which highlights the complexity of determining which ranking function should be selected by the search engine designer.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24102;&#25903;&#25345;&#20449;&#24687;&#30340;&#25293;&#21334;&#35774;&#35745;&#65292;&#36890;&#36807;&#20248;&#21270;DSIC&#26426;&#21046;&#24182;&#23558;&#26368;&#22351;&#24773;&#20917;&#19982;oracle&#36827;&#34892;&#27604;&#36739;&#65292;&#35762;&#36848;&#20102;&#19977;&#31181;&#25903;&#25345;&#20449;&#24687;&#30340;&#21306;&#22495;&#65292;&#24471;&#20986;&#20102;&#26368;&#20248;&#26426;&#21046;&#30340;&#38381;&#21512;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.09065</link><description>&lt;p&gt;
&#24102;&#25903;&#25345;&#20449;&#24687;&#30340;&#40065;&#26834;&#25293;&#21334;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Auction Design with Support Information. (arXiv:2305.09065v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24102;&#25903;&#25345;&#20449;&#24687;&#30340;&#25293;&#21334;&#35774;&#35745;&#65292;&#36890;&#36807;&#20248;&#21270;DSIC&#26426;&#21046;&#24182;&#23558;&#26368;&#22351;&#24773;&#20917;&#19982;oracle&#36827;&#34892;&#27604;&#36739;&#65292;&#35762;&#36848;&#20102;&#19977;&#31181;&#25903;&#25345;&#20449;&#24687;&#30340;&#21306;&#22495;&#65292;&#24471;&#20986;&#20102;&#26368;&#20248;&#26426;&#21046;&#30340;&#38381;&#21512;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#21334;&#23478;&#24819;&#35201;&#23558;&#21830;&#21697;&#21334;&#32473;$n$&#20010;&#20080;&#23478;&#65292;&#20080;&#23478;&#30340;&#20272;&#20540;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20294;&#26159;&#21334;&#23478;&#24182;&#19981;&#30693;&#36947;&#36825;&#20010;&#20998;&#24067;&#12290;&#20026;&#20102;&#25269;&#24481;&#29615;&#22659;&#21644;&#20080;&#23478;&#34892;&#20026;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21334;&#23478;&#22312;DSIC&#26426;&#21046;&#20013;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#23558;&#26368;&#22351;&#24773;&#20917;&#30340;&#34920;&#29616;&#19982;&#20855;&#26377;&#23436;&#20840;&#20080;&#23478;&#20272;&#20540;&#30693;&#35782;&#30340;oracle&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21253;&#25324;&#36951;&#25022;&#21644;&#27604;&#29575;&#20004;&#20010;&#30446;&#26631;&#12290;&#23545;&#20110;&#36825;&#20123;&#30446;&#26631;&#65292;&#25105;&#20204;&#20197;&#25903;&#25345;&#21644;&#20080;&#23478;&#25968;$n$&#30340;&#20989;&#25968;&#24418;&#24335;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#30340;&#26368;&#20248;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#19977;&#20010;&#25903;&#25345;&#20449;&#24687;&#30340;&#21306;&#22495;&#21644;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#26426;&#21046;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
A seller wants to sell an item to $n$ buyers. The buyer valuations are drawn i.i.d. from a distribution, but the seller does not know this distribution; the seller only knows the support $[a,b]$. To be robust against the lack of knowledge of the environment and buyers' behavior, the seller optimizes over DSIC mechanisms, and measures the worst-case performance relative to an oracle with complete knowledge of buyers' valuations. Our analysis encompasses both the regret and the ratio objectives.  For these objectives, we derive an optimal mechanism in closed form as a function of the support and the number of buyers $n$. Our analysis reveals three regimes of support information and a new class of robust mechanisms. i.) With "low" support information, the optimal mechanism is a second-price auction (SPA) with a random reserve, a focal class in the earlier literature. ii.) With "high" support information, we show that second-price auctions are strictly suboptimal, and an optimal mechanism 
&lt;/p&gt;</description></item></channel></rss>