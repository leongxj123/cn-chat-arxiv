<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#25913;&#36827;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#38646;&#21644;&#32447;&#24615;&#20108;&#27425;&#21338;&#24328;&#65292;&#24182;&#21457;&#29616;&#20102;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#23646;&#24615;&#12290;&#22312;&#26080;&#27169;&#22411;&#21442;&#25968;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#20182;&#20204;&#36824;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24615;&#31639;&#27861;&#26469;&#36798;&#21040;Nash&#22343;&#34913;&#12290;</title><link>http://arxiv.org/abs/2309.04272</link><description>&lt;p&gt;
&#23398;&#20064;&#25913;&#36827;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#38646;&#21644;&#32447;&#24615;&#20108;&#27425;&#21338;&#24328;
&lt;/p&gt;
&lt;p&gt;
Learning Zero-Sum Linear Quadratic Games with Improved Sample Complexity. (arXiv:2309.04272v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04272
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#25913;&#36827;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#38646;&#21644;&#32447;&#24615;&#20108;&#27425;&#21338;&#24328;&#65292;&#24182;&#21457;&#29616;&#20102;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#23646;&#24615;&#12290;&#22312;&#26080;&#27169;&#22411;&#21442;&#25968;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#20182;&#20204;&#36824;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24615;&#31639;&#27861;&#26469;&#36798;&#21040;Nash&#22343;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38646;&#21644;&#32447;&#24615;&#20108;&#27425;&#65288;LQ&#65289;&#21338;&#24328;&#22312;&#26368;&#20248;&#25511;&#21046;&#20013;&#26159;&#22522;&#30784;&#24615;&#30340;&#65292;&#21487;&#20197;&#29992;&#20110;&#65288;i&#65289;&#39118;&#38505;&#25935;&#24863;&#25110;&#40065;&#26834;&#25511;&#21046;&#30340;&#21160;&#24577;&#21338;&#24328;&#24418;&#24335;&#65292;&#25110;&#32773;&#65288;ii&#65289;&#20316;&#20026;&#36830;&#32493;&#29366;&#24577;-&#25511;&#21046;&#31354;&#38388;&#20013;&#20004;&#20010;&#31454;&#20105;&#26234;&#33021;&#20307;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#20934;&#35774;&#32622;&#12290;&#19982;&#24191;&#27867;&#30740;&#31350;&#30340;&#21333;&#26234;&#33021;&#20307;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#38382;&#39064;&#19981;&#21516;&#65292;&#38646;&#21644;LQ&#21338;&#24328;&#28041;&#21450;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#32570;&#20047;&#24378;&#21046;&#24615;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38750;&#20984;&#38750;&#20985;&#26368;&#23567;-&#26368;&#22823;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;&#24352;&#31561;&#20154;&#21457;&#29616;&#20102;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#23646;&#24615;&#65292;&#36825;&#23545;&#20110;&#23433;&#20840;&#20851;&#38190;&#30340;&#25511;&#21046;&#31995;&#32479;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#20445;&#25345;&#20102;&#25511;&#21046;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#22312;&#27809;&#26377;&#27169;&#22411;&#21442;&#25968;&#30693;&#35782;&#30340;&#27169;&#22411;&#26080;&#20851;&#35774;&#32622;&#20013;&#65292;&#24352;&#31561;&#20154;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24615;&#31639;&#27861;&#65292;&#20197;&#36798;&#21040;Nash&#22343;&#34913;&#30340;&#949;-&#37051;&#22495;&#65292;&#21516;&#26102;&#20445;&#25345;&#29702;&#24819;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Zero-sum Linear Quadratic (LQ) games are fundamental in optimal control and can be used (i) as a dynamic game formulation for risk-sensitive or robust control, or (ii) as a benchmark setting for multi-agent reinforcement learning with two competing agents in continuous state-control spaces. In contrast to the well-studied single-agent linear quadratic regulator problem, zero-sum LQ games entail solving a challenging nonconvex-nonconcave min-max problem with an objective function that lacks coercivity. Recently, Zhang et al. discovered an implicit regularization property of natural policy gradient methods which is crucial for safety-critical control systems since it preserves the robustness of the controller during learning. Moreover, in the model-free setting where the knowledge of model parameters is not available, Zhang et al. proposed the first polynomial sample complexity algorithm to reach an $\epsilon$-neighborhood of the Nash equilibrium while maintaining the desirable implicit 
&lt;/p&gt;</description></item></channel></rss>