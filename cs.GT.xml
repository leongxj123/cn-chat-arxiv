<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#19978;&#38271;&#26399;&#29702;&#24615;&#20195;&#29702;&#21830;&#30340;&#23398;&#20064;&#26041;&#24335;&#65292;&#34920;&#26126;&#26080;&#35770;&#32593;&#32476;&#35268;&#27169;&#12289;&#25928;&#29992;&#20989;&#25968;&#21450;&#20195;&#29702;&#30340;&#32784;&#24515;&#22914;&#20309;&#65292;&#23398;&#20064;&#36895;&#24230;&#37117;&#26377;&#20854;&#19978;&#38480;&#12290;</title><link>http://arxiv.org/abs/2112.14265</link><description>&lt;p&gt;
&#31038;&#20132;&#32593;&#32476;&#19978;&#30340;&#37325;&#22797;&#20114;&#21160;&#20013;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning in Repeated Interactions on Networks. (arXiv:2112.14265v3 [econ.TH] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.14265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#19978;&#38271;&#26399;&#29702;&#24615;&#20195;&#29702;&#21830;&#30340;&#23398;&#20064;&#26041;&#24335;&#65292;&#34920;&#26126;&#26080;&#35770;&#32593;&#32476;&#35268;&#27169;&#12289;&#25928;&#29992;&#20989;&#25968;&#21450;&#20195;&#29702;&#30340;&#32784;&#24515;&#22914;&#20309;&#65292;&#23398;&#20064;&#36895;&#24230;&#37117;&#26377;&#20854;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38271;&#26399;&#30340;&#12289;&#29702;&#24615;&#30340;&#20195;&#29702;&#21830;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#23398;&#20064;&#26041;&#24335;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#20013;&#65292;&#27599;&#20010;&#20195;&#29702;&#21830;&#22312;&#35266;&#23519;&#21040;&#37051;&#23621;&#30340;&#36807;&#21435;&#34892;&#21160;&#20043;&#21518;&#65292;&#25910;&#21040;&#19968;&#20010;&#31169;&#20154;&#20449;&#21495;&#65292;&#24182;&#36873;&#25321;&#19968;&#31181;&#20165;&#20381;&#36182;&#20110;&#29366;&#24577;&#30340;&#34892;&#21160;&#12290;&#30001;&#20110;&#24179;&#34913;&#34892;&#21160;&#20381;&#36182;&#20110;&#26356;&#39640;&#23618;&#27425;&#30340;&#20449;&#24565;&#65292;&#22240;&#27492;&#24456;&#38590;&#34920;&#24449;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#19981;&#35770;&#32593;&#32476;&#30340;&#22823;&#23567;&#21644;&#24418;&#29366;&#12289;&#25928;&#29992;&#20989;&#25968;&#21644;&#20195;&#29702;&#30340;&#32784;&#24515;&#22914;&#20309;&#65292;&#20219;&#20309;&#24179;&#34913;&#20013;&#30340;&#23398;&#20064;&#36895;&#24230;&#37117;&#26377;&#19968;&#20010;&#19978;&#30028;&#65292;&#22312;&#35813;&#19978;&#30028;&#20043;&#20869;&#38480;&#21046;&#21482;&#21462;&#20915;&#20110;&#31169;&#20154;&#20449;&#21495;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how long-lived, rational agents learn in a social network. In every period, after observing the past actions of his neighbors, each agent receives a private signal, and chooses an action whose payoff depends only on the state. Since equilibrium actions depend on higher order beliefs, it is difficult to characterize behavior. Nevertheless, we show that regardless of the size and shape of the network, the utility function, and the patience of the agents, the speed of learning in any equilibrium is bounded from above by a constant that only depends on the private signal distribution.
&lt;/p&gt;</description></item></channel></rss>