<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25191;&#34892;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25214;&#21040;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#30340;&#20998;&#31867;&#22120;&#26469;&#36866;&#29992;&#20110;&#25968;&#25454;&#20998;&#24067;&#12290;&#36890;&#36807;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#30456;&#23545;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#20540;&#21487;Lipschitz&#36830;&#32493;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#25918;&#23485;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20551;&#35774;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2304.06879</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#19979;&#30340;&#25191;&#34892;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Performative Prediction with Neural Networks. (arXiv:2304.06879v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25191;&#34892;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25214;&#21040;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#30340;&#20998;&#31867;&#22120;&#26469;&#36866;&#29992;&#20110;&#25968;&#25454;&#20998;&#24067;&#12290;&#36890;&#36807;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#30456;&#23545;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#20540;&#21487;Lipschitz&#36830;&#32493;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#25918;&#23485;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20551;&#35774;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25191;&#34892;&#39044;&#27979;&#26159;&#19968;&#31181;&#23398;&#20064;&#27169;&#22411;&#24182;&#24433;&#21709;&#20854;&#39044;&#27979;&#25968;&#25454;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#26088;&#22312;&#25214;&#21040;&#20998;&#31867;&#22120;&#65292;&#20351;&#20854;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#65292;&#21363;&#36866;&#29992;&#20110;&#20854;&#20135;&#29983;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#26368;&#20339;&#20998;&#31867;&#22120;&#12290;&#22312;&#20351;&#29992;&#37325;&#22797;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#25214;&#21040;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#30340;&#20998;&#31867;&#22120;&#30340;&#26631;&#20934;&#25910;&#25947;&#32467;&#26524;&#20013;&#65292;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#23545;&#20110;&#27169;&#22411;&#21442;&#25968;&#26159;&#21487;Lipschitz&#36830;&#32493;&#30340;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25439;&#22833;&#24517;&#39035;&#23545;&#36825;&#20123;&#21442;&#25968;&#24378;&#20984;&#21644;&#24179;&#28369;&#65307;&#21542;&#21017;&#65292;&#35813;&#26041;&#27861;&#23558;&#22312;&#26576;&#20123;&#38382;&#39064;&#19978;&#21457;&#25955;&#12290;&#28982;&#32780;&#26412;&#25991;&#21017;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#26159;&#30456;&#23545;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#20540;&#21487;Lipschitz&#36830;&#32493;&#30340;&#65292;&#36825;&#26159;&#25191;&#34892;&#31995;&#32479;&#30340;&#26356;&#21152;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#32467;&#26524;&#65292;&#25105;&#20204;&#33021;&#22815;&#26174;&#33879;&#25918;&#23485;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20551;&#35774;&#35201;&#27714;&#12290;&#20316;&#20026;&#19968;&#20010;&#35828;&#26126;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#24314;&#27169;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#37325;&#37319;&#26679;&#36807;&#31243;&#65292;&#24182;&#20351;&#29992;&#20854;&#26469;&#23454;&#35777;&#25191;&#34892;&#31283;&#23450;&#24615;&#30456;&#23545;&#20110;&#20854;&#20182;&#30446;&#26631;&#30340;&#25928;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performative prediction is a framework for learning models that influence the data they intend to predict. We focus on finding classifiers that are performatively stable, i.e. optimal for the data distribution they induce. Standard convergence results for finding a performatively stable classifier with the method of repeated risk minimization assume that the data distribution is Lipschitz continuous to the model's parameters. Under this assumption, the loss must be strongly convex and smooth in these parameters; otherwise, the method will diverge for some problems. In this work, we instead assume that the data distribution is Lipschitz continuous with respect to the model's predictions, a more natural assumption for performative systems. As a result, we are able to significantly relax the assumptions on the loss function. In particular, we do not need to assume convexity with respect to the model's parameters. As an illustration, we introduce a resampling procedure that models realisti
&lt;/p&gt;</description></item></channel></rss>