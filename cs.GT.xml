<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#30740;&#31350;&#20102;&#22312;&#23433;&#20840;&#28216;&#25103;&#20013;&#31616;&#21333;&#21270;&#25509;&#36817;&#26368;&#20248;&#35299;&#65292;&#35299;&#20915;&#20102;&#27450;&#35784;&#34892;&#20026;&#23545;&#29992;&#25143;&#21644;&#31649;&#29702;&#32773;&#21487;&#33021;&#36896;&#25104;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.11209</link><description>&lt;p&gt;
&#24403;&#31616;&#21333;&#21270;&#22312;&#23433;&#20840;&#28216;&#25103;&#20013;&#25509;&#36817;&#26368;&#20248;
&lt;/p&gt;
&lt;p&gt;
When Simple in Near-Optimal in Security Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11209
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#23433;&#20840;&#28216;&#25103;&#20013;&#31616;&#21333;&#21270;&#25509;&#36817;&#26368;&#20248;&#35299;&#65292;&#35299;&#20915;&#20102;&#27450;&#35784;&#34892;&#20026;&#23545;&#29992;&#25143;&#21644;&#31649;&#29702;&#32773;&#21487;&#33021;&#36896;&#25104;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#24212;&#29992;&#31243;&#24207;&#20013;&#26222;&#36941;&#23384;&#22312;&#27450;&#35784;&#25110;&#38750;&#27861;&#27963;&#21160;&#65292;&#24182;&#28041;&#21450;&#29992;&#25143;&#32469;&#36807;&#27861;&#24459;&#65292;&#36890;&#24120;&#20197;&#33719;&#21462;&#19968;&#20123;&#22312;&#21512;&#27861;&#34892;&#20026;&#33539;&#22260;&#20869;&#26080;&#27861;&#33719;&#24471;&#30340;&#21033;&#30410;&#20026;&#25112;&#30053;&#30446;&#30340;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#27450;&#35784;&#20855;&#26377;&#36127;&#38754;&#24433;&#21709;&#65292;&#21487;&#33021;&#21361;&#23475;&#23433;&#20840;&#25110;&#23545;&#29305;&#23450;&#20154;&#32676;&#26045;&#21152;&#19981;&#25104;&#27604;&#20363;&#30340;&#36127;&#38754;&#22806;&#37096;&#24615;&#12290;&#20026;&#20943;&#36731;&#29992;&#25143;&#27450;&#35784;&#30340;&#28508;&#22312;&#21361;&#23475;&#65292;&#25105;&#20204;&#23558;&#27450;&#35784;&#34892;&#20026;&#30417;&#31649;&#38382;&#39064;&#35270;&#20026;&#31649;&#29702;&#21592;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#23433;&#20840;&#28216;&#25103;&#12290;&#22312;&#36825;&#20010;&#28216;&#25103;&#20013;&#65292;&#31649;&#29702;&#21592;&#36890;&#36807;$R$&#20010;&#23433;&#20840;&#36164;&#28304;&#65288;&#20363;&#22914;&#35686;&#23519;&#65289;&#22312;$L$&#20010;&#20301;&#32622;&#37096;&#32626;&#65292;&#24182;&#23545;&#22312;&#36825;&#20123;&#20301;&#32622;&#36827;&#34892;&#27450;&#35784;&#30340;&#29992;&#25143;&#24449;&#25910;&#32602;&#27454;&#12290;&#23545;&#20110;&#36825;&#20010;&#23433;&#20840;&#28216;&#25103;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#31649;&#29702;&#21592;&#30340;&#31119;&#21033;&#21644;&#25910;&#20837;&#26368;&#22823;&#21270;&#30446;&#26631;&#12290;&#22312;&#20004;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35745;&#31639;&#26368;&#20248;&#31649;&#29702;&#21592;&#31574;&#30053;&#26159;NP&#38590;&#39064;&#65292;&#24182;&#20026;&#27492;&#24320;&#21457;&#20102;&#33258;&#28982;&#30340;&#36138;&#23146;&#31639;&#27861;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11209v1 Announce Type: cross  Abstract: Fraudulent or illegal activities are ubiquitous across applications and involve users bypassing the rule of law, often with the strategic aim of obtaining some benefit that would otherwise be unattainable within the bounds of lawful conduct. However, user fraud is detrimental, as it may compromise safety or impose disproportionate negative externalities on particular population groups.   To mitigate the potential harms of user fraud, we study the problem of policing such fraud as a security game between an administrator and users. In this game, an administrator deploys $R$ security resources (e.g., police officers) across $L$ locations and levies fines against users engaging in fraud at those locations. For this security game, we study both welfare and revenue maximization administrator objectives. In both settings, we show that computing the optimal administrator strategy is NP-hard and develop natural greedy algorithm variants for th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#21462;&#20195;&#32463;&#27982;&#23454;&#39564;&#23460;&#36827;&#34892;&#36873;&#25321;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17435</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#21462;&#20195;&#32463;&#27982;&#36873;&#25321;&#39044;&#27979;&#23454;&#39564;&#23460;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Replace Economic Choice Prediction Labs?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17435
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#21462;&#20195;&#32463;&#27982;&#23454;&#39564;&#23460;&#36827;&#34892;&#36873;&#25321;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#27982;&#36873;&#25321;&#39044;&#27979;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#37325;&#35201;&#20219;&#21153;&#65292;&#24448;&#24448;&#21463;&#38480;&#20110;&#33719;&#21462;&#20154;&#31867;&#36873;&#25321;&#25968;&#25454;&#30340;&#22256;&#38590;&#12290;&#23454;&#39564;&#32463;&#27982;&#23398;&#30740;&#31350;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#19987;&#27880;&#20110;&#31616;&#21333;&#30340;&#36873;&#25321;&#29615;&#22659;&#12290;&#26368;&#36817;&#65292;&#20154;&#24037;&#26234;&#33021;&#30028;&#20197;&#20004;&#31181;&#26041;&#24335;&#20026;&#35813;&#21162;&#21147;&#20570;&#20986;&#20102;&#36129;&#29486;&#65306;&#32771;&#34385;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#21487;&#20197;&#20195;&#26367;&#20154;&#31867;&#22312;&#19978;&#36848;&#31616;&#21333;&#36873;&#25321;&#39044;&#27979;&#29615;&#22659;&#20013;&#65292;&#20197;&#21450;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#35270;&#35282;&#30740;&#31350;&#26356;&#22797;&#26434;&#20294;&#20173;&#20005;&#26684;&#30340;&#23454;&#39564;&#32463;&#27982;&#23398;&#29615;&#22659;&#65292;&#21253;&#25324;&#19981;&#23436;&#20840;&#20449;&#24687;&#12289;&#37325;&#22797;&#21338;&#24328;&#21644;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#30340;&#35828;&#26381;&#28216;&#25103;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#28789;&#24863;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#23436;&#20840;&#27169;&#25311;&#32463;&#27982;&#29615;&#22659;&#65292;&#24182;&#29983;&#25104;&#29992;&#20110;&#39640;&#25928;&#20154;&#31867;&#36873;&#25321;&#39044;&#27979;&#30340;&#25968;&#25454;&#65292;&#26367;&#20195;&#22797;&#26434;&#30340;&#32463;&#27982;&#23454;&#39564;&#23460;&#30740;&#31350;&#65311;&#25105;&#20204;&#22312;&#36825;&#20010;&#20027;&#39064;&#19978;&#24320;&#21019;&#20102;&#30740;&#31350;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#34920;&#26126;&#20165;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Economic choice prediction is an essential challenging task, often constrained by the difficulties in acquiring human choice data. Indeed, experimental economics studies had focused mostly on simple choice settings. The AI community has recently contributed to that effort in two ways: considering whether LLMs can substitute for humans in the above-mentioned simple choice prediction settings, and the study through ML lens of more elaborated but still rigorous experimental economics settings, employing incomplete information, repetitive play, and natural language communication, notably language-based persuasion games. This leaves us with a major inspiration: can LLMs be used to fully simulate the economic environment and generate data for efficient human choice prediction, substituting for the elaborated economic lab studies? We pioneer the study of this subject, demonstrating its feasibility. In particular, we show that a model trained solely on LLM-generated data can effectively predic
&lt;/p&gt;</description></item></channel></rss>