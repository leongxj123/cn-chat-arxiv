<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26159;&#26631;&#20934;&#21270;&#30340;&#65292;&#35780;&#20272;&#25152;&#26377;&#20010;&#20307;&#26102;&#36890;&#36807;&#22266;&#23450;&#30340;&#20849;&#21464;&#37327;&#65292;&#32780;&#20154;&#31867;&#35780;&#20272;&#32773;&#36890;&#36807;&#23450;&#21046;&#20849;&#21464;&#37327;&#30340;&#33719;&#21462;&#23545;&#27599;&#20010;&#20010;&#20307;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#22312;&#39640;&#32500;&#25968;&#25454;&#29615;&#22659;&#20013;&#65292;&#19978;&#19979;&#25991;&#30340;&#23450;&#21046;&#21270;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.11157</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#30340;&#20215;&#20540;&#65306;&#20154;&#31867;&#35780;&#20272;&#32773;&#19982;&#40657;&#21283;&#23376;&#35780;&#20272;&#32773;
&lt;/p&gt;
&lt;p&gt;
The Value of Context: Human versus Black Box Evaluators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11157
&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26159;&#26631;&#20934;&#21270;&#30340;&#65292;&#35780;&#20272;&#25152;&#26377;&#20010;&#20307;&#26102;&#36890;&#36807;&#22266;&#23450;&#30340;&#20849;&#21464;&#37327;&#65292;&#32780;&#20154;&#31867;&#35780;&#20272;&#32773;&#36890;&#36807;&#23450;&#21046;&#20849;&#21464;&#37327;&#30340;&#33719;&#21462;&#23545;&#27599;&#20010;&#20010;&#20307;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#22312;&#39640;&#32500;&#25968;&#25454;&#29615;&#22659;&#20013;&#65292;&#19978;&#19979;&#25991;&#30340;&#23450;&#21046;&#21270;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#26366;&#32463;&#21482;&#22312;&#20154;&#31867;&#19987;&#23478;&#39046;&#22495;&#20869;&#36827;&#34892;&#65288;&#20363;&#22914;&#21307;&#29983;&#36827;&#34892;&#30340;&#21307;&#23398;&#35786;&#26029;&#65289;&#65292;&#29616;&#22312;&#20063;&#21487;&#20197;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#27010;&#24565;&#38382;&#39064;&#65306;&#34987;&#20154;&#31867;&#21644;&#31639;&#27861;&#35780;&#20272;&#20043;&#38388;&#26377;&#20160;&#20040;&#21306;&#21035;&#65292;&#22312;&#20160;&#20040;&#26102;&#20505;&#20010;&#20154;&#24212;&#35813;&#26356;&#21916;&#27426;&#20854;&#20013;&#19968;&#31181;&#24418;&#24335;&#30340;&#35780;&#20272;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#24418;&#24335;&#21270;&#20102;&#36825;&#20004;&#31181;&#35780;&#20272;&#24418;&#24335;&#20043;&#38388;&#30340;&#19968;&#20010;&#20851;&#38190;&#21306;&#21035;&#65306;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26159;&#26631;&#20934;&#21270;&#30340;&#65292;&#36890;&#36807;&#22266;&#23450;&#30340;&#20849;&#21464;&#37327;&#26469;&#35780;&#20272;&#25152;&#26377;&#20010;&#20307;&#65292;&#32780;&#20154;&#31867;&#35780;&#20272;&#32773;&#21017;&#26681;&#25454;&#20010;&#20307;&#23450;&#21046;&#33719;&#21462;&#21738;&#20123;&#20849;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23450;&#20041;&#24182;&#20998;&#26512;&#20102;&#36825;&#31181;&#23450;&#21046;&#21270;&#30340;&#20248;&#21183;&#8212;&#8212;&#19978;&#19979;&#25991;&#30340;&#20215;&#20540;&#65292;&#22312;&#20855;&#26377;&#38750;&#24120;&#39640;&#32500;&#25968;&#25454;&#30340;&#29615;&#22659;&#20013;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#38500;&#38750;&#20195;&#29702;&#20154;&#23545;&#20849;&#21464;&#37327;&#30340;&#32852;&#21512;&#20998;&#24067;&#26377;&#31934;&#30830;&#30340;&#30693;&#35782;&#65292;&#26356;&#22810;&#20849;&#21464;&#37327;&#30340;&#20215;&#20540;&#36229;&#36807;&#20102;&#19978;&#19979;&#25991;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11157v1 Announce Type: new  Abstract: Evaluations once solely within the domain of human experts (e.g., medical diagnosis by doctors) can now also be carried out by machine learning algorithms. This raises a new conceptual question: what is the difference between being evaluated by humans and algorithms, and when should an individual prefer one form of evaluation over the other? We propose a theoretical framework that formalizes one key distinction between the two forms of evaluation: Machine learning algorithms are standardized, fixing a common set of covariates by which to assess all individuals, while human evaluators customize which covariates are acquired to each individual. Our framework defines and analyzes the advantage of this customization -- the value of context -- in environments with very high-dimensional data. We show that unless the agent has precise knowledge about the joint distribution of covariates, the value of more covariates exceeds the value of context
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#31526;&#21495;&#21270;&#37096;&#20998;&#21487;&#35266;&#27979;&#38543;&#26426;&#21338;&#24328;&#65288;NS-POSGs&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#34701;&#21512;&#24863;&#30693;&#26426;&#21046;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#24207;&#21015;&#20915;&#31574;&#20013;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#19968;&#31181;&#21482;&#26377;&#37096;&#20998;&#35266;&#27979;&#20449;&#24687;&#30340;&#26234;&#33021;&#20307;&#21644;&#19968;&#31181;&#23436;&#20840;&#35266;&#27979;&#30340;&#26234;&#33021;&#20307;&#30340;&#21333;&#26041;&#38754;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;NS-POSGs&#20540;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.11566</link><description>&lt;p&gt;
&#20855;&#26377;&#31070;&#32463;&#24863;&#30693;&#26426;&#21046;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#38543;&#26426;&#21338;&#24328;
&lt;/p&gt;
&lt;p&gt;
Partially Observable Stochastic Games with Neural Perception Mechanisms. (arXiv:2310.11566v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#31526;&#21495;&#21270;&#37096;&#20998;&#21487;&#35266;&#27979;&#38543;&#26426;&#21338;&#24328;&#65288;NS-POSGs&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#34701;&#21512;&#24863;&#30693;&#26426;&#21046;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#24207;&#21015;&#20915;&#31574;&#20013;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#19968;&#31181;&#21482;&#26377;&#37096;&#20998;&#35266;&#27979;&#20449;&#24687;&#30340;&#26234;&#33021;&#20307;&#21644;&#19968;&#31181;&#23436;&#20840;&#35266;&#27979;&#30340;&#26234;&#33021;&#20307;&#30340;&#21333;&#26041;&#38754;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;NS-POSGs&#20540;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21338;&#24328;&#26159;&#19968;&#20010;&#20026;&#22810;&#26234;&#33021;&#20307;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#36827;&#34892;&#24207;&#21015;&#20915;&#31574;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#22312;&#29616;&#23454;&#20013;&#65292;&#26234;&#33021;&#20307;&#23545;&#29615;&#22659;&#21482;&#26377;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#65292;&#36825;&#20351;&#24471;&#38382;&#39064;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21363;&#20351;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#21333;&#26234;&#33021;&#20307;&#29615;&#22659;&#20013;&#20063;&#26159;&#22914;&#27492;&#12290;&#27492;&#22806;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#26234;&#33021;&#20307;&#36234;&#26469;&#36234;&#22810;&#22320;&#20351;&#29992;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;&#36830;&#32493;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#24863;&#30693;&#29615;&#22659;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31070;&#32463;&#31526;&#21495;&#21270;&#37096;&#20998;&#21487;&#35266;&#27979;&#38543;&#26426;&#21338;&#24328;&#65288;NS-POSGs&#65289;&#30340;&#27169;&#22411;&#65292;&#36825;&#26159;&#36830;&#32493;&#31354;&#38388;&#24182;&#21457;&#38543;&#26426;&#21338;&#24328;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#26126;&#30830;&#22320;&#34701;&#20837;&#20102;&#24863;&#30693;&#26426;&#21046;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#21333;&#26041;&#38754;&#30340;&#35774;&#32622;&#65292;&#21253;&#21547;&#20102;&#19968;&#20010;&#20855;&#26377;&#31163;&#25955;&#12289;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#35266;&#27979;&#21644;&#19968;&#20010;&#20855;&#26377;&#36830;&#32493;&#35266;&#27979;&#30340;&#20805;&#20998;&#20102;&#35299;&#30340;&#26234;&#33021;&#20307;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21333;&#36793;NS-HSVI&#30340;&#22522;&#20110;&#28857;&#30340;&#26041;&#27861;&#65292;&#29992;&#26469;&#36817;&#20284;&#35745;&#31639;&#21333;&#26041;&#38754;NS-POSGs&#30340;&#20540;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic games are a well established model for multi-agent sequential decision making under uncertainty. In reality, though, agents have only partial observability of their environment, which makes the problem computationally challenging, even in the single-agent setting of partially observable Markov decision processes. Furthermore, in practice, agents increasingly perceive their environment using data-driven approaches such as neural networks trained on continuous data. To tackle this problem, we propose the model of neuro-symbolic partially-observable stochastic games (NS-POSGs), a variant of continuous-space concurrent stochastic games that explicitly incorporates perception mechanisms. We focus on a one-sided setting, comprising a partially-informed agent with discrete, data-driven observations and a fully-informed agent with continuous observations. We present a new point-based method, called one-sided NS-HSVI, for approximating values of one-sided NS-POSGs and implement it ba
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20551;&#35774;&#22312;&#19981;&#21516;&#28216;&#25103;&#20013;&#20855;&#26377;&#19968;&#33268;&#30340;&#34892;&#20026;&#65292;&#32473;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#32435;&#20160;&#22343;&#34913;&#29305;&#24449;&#21270;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#32435;&#20160;&#22343;&#34913;&#26159;&#21807;&#19968;&#28385;&#36275;&#32467;&#26524;&#20027;&#20041;&#12289;&#19968;&#33268;&#24615;&#21644;&#21512;&#29702;&#24615;&#30340;&#35299;&#27010;&#24565;&#12290;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#21508;&#31181;&#33258;&#28982;&#23376;&#31867;&#30340;&#28216;&#25103;&#12290;</title><link>http://arxiv.org/abs/2307.03079</link><description>&lt;p&gt;
&#19968;&#31181;&#40065;&#26834;&#30340;&#32435;&#20160;&#22343;&#34913;&#29305;&#24449;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Robust Characterization of Nash Equilibrium. (arXiv:2307.03079v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20551;&#35774;&#22312;&#19981;&#21516;&#28216;&#25103;&#20013;&#20855;&#26377;&#19968;&#33268;&#30340;&#34892;&#20026;&#65292;&#32473;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#32435;&#20160;&#22343;&#34913;&#29305;&#24449;&#21270;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#32435;&#20160;&#22343;&#34913;&#26159;&#21807;&#19968;&#28385;&#36275;&#32467;&#26524;&#20027;&#20041;&#12289;&#19968;&#33268;&#24615;&#21644;&#21512;&#29702;&#24615;&#30340;&#35299;&#27010;&#24565;&#12290;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#21508;&#31181;&#33258;&#28982;&#23376;&#31867;&#30340;&#28216;&#25103;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20551;&#35774;&#22312;&#19981;&#21516;&#28216;&#25103;&#20013;&#20855;&#26377;&#19968;&#33268;&#30340;&#34892;&#20026;&#26469;&#32473;&#20986;&#32435;&#20160;&#22343;&#34913;&#30340;&#40065;&#26834;&#29305;&#24449;&#21270;&#26041;&#27861;&#65306;&#32435;&#20160;&#22343;&#34913;&#26159;&#21807;&#19968;&#28385;&#36275;&#32467;&#26524;&#20027;&#20041;&#12289;&#19968;&#33268;&#24615;&#21644;&#21512;&#29702;&#24615;&#30340;&#35299;&#27010;&#24565;&#12290;&#22240;&#27492;&#65292;&#27599;&#20010;&#22343;&#34913;&#25913;&#36827;&#26041;&#27861;&#37117;&#33267;&#23569;&#36829;&#21453;&#20854;&#20013;&#19968;&#31181;&#24615;&#36136;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#27599;&#20010;&#36817;&#20284;&#28385;&#36275;&#32467;&#26524;&#20027;&#20041;&#12289;&#19968;&#33268;&#24615;&#21644;&#21512;&#29702;&#24615;&#30340;&#35299;&#27010;&#24565;&#37117;&#20250;&#20135;&#29983;&#36817;&#20284;&#30340;&#32435;&#20160;&#22343;&#34913;&#12290;&#36890;&#36807;&#22686;&#21152;&#20844;&#29702;&#30340;&#36924;&#36817;&#31243;&#24230;&#65292;&#21518;&#32773;&#30340;&#36924;&#36817;&#31243;&#24230;&#21487;&#20197;&#20219;&#24847;&#25552;&#39640;&#12290;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#20004;&#20154;&#38646;&#21644;&#28216;&#25103;&#12289;&#21183;&#20989;&#25968;&#28216;&#25103;&#21644;&#22270;&#24418;&#28216;&#25103;&#31561;&#21508;&#31181;&#33258;&#28982;&#23376;&#31867;&#30340;&#28216;&#25103;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give a robust characterization of Nash equilibrium by postulating coherent behavior across varying games: Nash equilibrium is the only solution concept that satisfies consequentialism, consistency, and rationality. As a consequence, every equilibrium refinement violates at least one of these properties. We moreover show that every solution concept that approximately satisfies consequentialism, consistency, and rationality returns approximate Nash equilibria. The latter approximation can be made arbitrarily good by increasing the approximation of the axioms. This result extends to various natural subclasses of games such as two-player zero-sum games, potential games, and graphical games.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#21487;&#20197;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#21306;&#20998;&#32454;&#24494;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#26041;&#38754;&#30340;&#33021;&#21147;&#21463;&#21040;&#38480;&#21046;&#65292;&#20026;&#20351;&#29992;LLMs&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#32972;&#26223;&#19979;&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2305.07970</link><description>&lt;p&gt;
&#21033;&#29992;&#23454;&#39564;&#32463;&#27982;&#23398;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#31867;&#20284;&#30446;&#26631;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Investigating Emergent Goal-Like Behaviour in Large Language Models Using Experimental Economics. (arXiv:2305.07970v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#21487;&#20197;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#21306;&#20998;&#32454;&#24494;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#26041;&#38754;&#30340;&#33021;&#21147;&#21463;&#21040;&#38480;&#21046;&#65292;&#20026;&#20351;&#29992;LLMs&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#32972;&#26223;&#19979;&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#29305;&#21035;&#26159;GPT-3.5&#65292;&#23454;&#29616;&#21512;&#20316;&#12289;&#31454;&#20105;&#12289;&#21033;&#20182;&#21644;&#33258;&#31169;&#34892;&#20026;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#22312;&#31038;&#20250;&#22256;&#22659;&#19979;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#36845;&#20195;&#22234;&#24466;&#22256;&#22659;&#65292;&#36825;&#26159;&#19968;&#20010;&#38750;&#38646;&#21644;&#20114;&#21160;&#30340;&#32463;&#20856;&#20363;&#23376;&#65292;&#20294;&#25105;&#20204;&#30340;&#26356;&#24191;&#27867;&#30740;&#31350;&#35745;&#21010;&#21253;&#25324;&#19968;&#31995;&#21015;&#23454;&#39564;&#32463;&#27982;&#23398;&#22330;&#26223;&#65292;&#21253;&#25324;&#26368;&#21518;&#36890;&#29266;&#21338;&#24328;&#12289;&#29420;&#35009;&#32773;&#21338;&#24328;&#21644;&#20844;&#20849;&#29289;&#21697;&#28216;&#25103;&#12290;&#20351;&#29992;&#34987;&#35797;&#20869;&#23454;&#39564;&#35774;&#35745;&#65292;&#25105;&#20204;&#36816;&#29992;&#19981;&#21516;&#30340;&#25552;&#31034;&#20449;&#24687;&#23454;&#20363;&#21270;&#30001;LLM&#29983;&#25104;&#30340;&#26234;&#33021;&#20307;&#65292;&#34920;&#36798;&#19981;&#21516;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#31435;&#22330;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#26234;&#33021;&#20307;&#22312;&#36845;&#20195;&#22234;&#24466;&#22256;&#22659;&#20013;&#30340;&#21512;&#20316;&#27700;&#24179;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#23427;&#20204;&#23545;&#21512;&#20316;&#25110;&#20986;&#23572;&#21453;&#23572;&#30340;&#20249;&#20276;&#34892;&#21160;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#21487;&#20197;&#23558;&#21033;&#20182;&#21644;&#33258;&#31169;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#23637;&#31034;&#20986;&#21306;&#20998;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#30340;&#32972;&#26223;&#19979;&#20351;&#29992;LLMs&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#25552;&#20379;&#20102;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we investigate the capacity of large language models (LLMs), specifically GPT-3.5, to operationalise natural language descriptions of cooperative, competitive, altruistic, and self-interested behavior in social dilemmas. Our focus is on the iterated Prisoner's Dilemma, a classic example of a non-zero-sum interaction, but our broader research program encompasses a range of experimental economics scenarios, including the ultimatum game, dictator game, and public goods game. Using a within-subject experimental design, we instantiated LLM-generated agents with various prompts that conveyed different cooperative and competitive stances. We then assessed the agents' level of cooperation in the iterated Prisoner's Dilemma, taking into account their responsiveness to the cooperative or defection actions of their partners. Our results provide evidence that LLMs can translate natural language descriptions of altruism and selfishness into appropriate behaviour to some extent, but e
&lt;/p&gt;</description></item></channel></rss>