<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#26412;&#30740;&#31350;&#20027;&#35201;&#30740;&#31350;&#20102;&#25903;&#25345;AI&#29983;&#25104;&#20869;&#23481;&#30340;&#25293;&#21334;&#26426;&#21046;&#35774;&#35745;&#65292;&#36890;&#36807;&#25552;&#20986;&#20196;&#29260;&#25293;&#21334;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#20197;&#28608;&#21169;&#20860;&#23481;&#30340;&#26041;&#24335;&#32858;&#21512;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#29992;&#20110;&#32467;&#21512;&#19981;&#21516;&#24191;&#21578;&#21830;&#30340;&#36755;&#20837;&#12290;&#36825;&#20010;&#26426;&#21046;&#35774;&#35745;&#26377;&#29420;&#29305;&#30340;&#29305;&#28857;&#65292;&#24182;&#36890;&#36807;&#21046;&#23450;&#33258;&#28982;&#30340;&#28608;&#21169;&#29305;&#24615;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10826</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26426;&#21046;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mechanism Design for Large Language Models. (arXiv:2310.10826v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20027;&#35201;&#30740;&#31350;&#20102;&#25903;&#25345;AI&#29983;&#25104;&#20869;&#23481;&#30340;&#25293;&#21334;&#26426;&#21046;&#35774;&#35745;&#65292;&#36890;&#36807;&#25552;&#20986;&#20196;&#29260;&#25293;&#21334;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#20197;&#28608;&#21169;&#20860;&#23481;&#30340;&#26041;&#24335;&#32858;&#21512;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#29992;&#20110;&#32467;&#21512;&#19981;&#21516;&#24191;&#21578;&#21830;&#30340;&#36755;&#20837;&#12290;&#36825;&#20010;&#26426;&#21046;&#35774;&#35745;&#26377;&#29420;&#29305;&#30340;&#29305;&#28857;&#65292;&#24182;&#36890;&#36807;&#21046;&#23450;&#33258;&#28982;&#30340;&#28608;&#21169;&#29305;&#24615;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#25293;&#21334;&#26426;&#21046;&#20197;&#25903;&#25345;&#26032;&#20852;&#30340;AI&#29983;&#25104;&#20869;&#23481;&#30340;&#26684;&#24335;&#12290;&#25105;&#20204;&#29305;&#21035;&#30740;&#31350;&#22914;&#20309;&#20197;&#28608;&#21169;&#20860;&#23481;&#30340;&#26041;&#24335;&#32858;&#21512;&#22810;&#20010;LLM&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#27599;&#20010;&#20195;&#29702;&#23545;&#38543;&#26426;&#29983;&#25104;&#30340;&#20869;&#23481;&#30340;&#20559;&#22909;&#34987;&#25551;&#36848;/&#32534;&#30721;&#20026;&#19968;&#20010;LLM&#12290;&#35774;&#35745;&#19968;&#20010;&#29992;&#20110;AI&#29983;&#25104;&#30340;&#24191;&#21578;&#21019;&#24847;&#30340;&#25293;&#21334;&#26684;&#24335;&#26469;&#32467;&#21512;&#26469;&#33258;&#19981;&#21516;&#24191;&#21578;&#21830;&#30340;&#36755;&#20837;&#26159;&#19968;&#20010;&#20851;&#38190;&#21160;&#26426;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#36825;&#20010;&#38382;&#39064;&#36890;&#24120;&#23646;&#20110;&#26426;&#21046;&#35774;&#35745;&#30340;&#33539;&#30068;&#65292;&#20294;&#23427;&#20855;&#26377;&#19968;&#20123;&#29420;&#29305;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#24418;&#24335;&#21270;&#26041;&#27861;&#8212;&#8212;&#20196;&#29260;&#25293;&#21334;&#27169;&#22411;&#8212;&#8212;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20010;&#27169;&#22411;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#28857;&#26159;&#23427;&#20197;&#20196;&#29260;&#20026;&#21333;&#20301;&#36827;&#34892;&#25805;&#20316;&#65292;&#24182;&#20801;&#35768;LLM&#20195;&#29702;&#36890;&#36807;&#19968;&#32500;&#20986;&#20215;&#24433;&#21709;&#29983;&#25104;&#30340;&#20869;&#23481;&#12290;&#25105;&#20204;&#39318;&#20808;&#25506;&#35752;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#25293;&#21334;&#35774;&#35745;&#26041;&#27861;&#65292;&#20854;&#20013;&#25105;&#20204;&#20551;&#35774;&#30340;&#26159;&#20195;&#29702;&#20154;&#30340;&#20559;&#22909;&#28041;&#21450;&#21040;&#32467;&#26524;&#20998;&#24067;&#30340;&#20559;&#24207;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#20004;&#20010;&#33258;&#28982;&#30340;&#28608;&#21169;&#29305;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#29305;&#24615;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate auction mechanisms to support the emerging format of AI-generated content. We in particular study how to aggregate several LLMs in an incentive compatible manner. In this problem, the preferences of each agent over stochastically generated contents are described/encoded as an LLM. A key motivation is to design an auction format for AI-generated ad creatives to combine inputs from different advertisers. We argue that this problem, while generally falling under the umbrella of mechanism design, has several unique features. We propose a general formalism -- the token auction model -- for studying this problem. A key feature of this model is that it acts on a token-by-token basis and lets LLM agents influence generated contents through single dimensional bids.  We first explore a robust auction design approach, in which all we assume is that agent preferences entail partial orders over outcome distributions. We formulate two natural incentive properties, and show that these 
&lt;/p&gt;</description></item></channel></rss>