<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q&#30340;&#31574;&#30053;&#35268;&#21017;&#26063;&#20013;&#30340;&#22343;&#34913;&#20559;&#24046;&#65288;&#25110; Qb-equilibria&#65289;&#65292;&#21363;Q&#20540;&#22312;&#19981;&#21516;&#30417;&#27979;&#25216;&#26415;&#19979;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.12647</link><description>&lt;p&gt;
&#22522;&#20110;Q&#30340;&#22343;&#34913;
&lt;/p&gt;
&lt;p&gt;
Q-based Equilibria. (arXiv:2304.12647v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12647
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q&#30340;&#31574;&#30053;&#35268;&#21017;&#26063;&#20013;&#30340;&#22343;&#34913;&#20559;&#24046;&#65288;&#25110; Qb-equilibria&#65289;&#65292;&#21363;Q&#20540;&#22312;&#19981;&#21516;&#30417;&#27979;&#25216;&#26415;&#19979;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#65292;Q&#23398;&#20064;&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#35268;&#21017;&#65292;&#20854;&#20026;&#27599;&#20010;&#26367;&#20195;&#26041;&#26696;&#25552;&#20379;&#20272;&#35745;&#20540;(&#21363;Q&#20540;)&#65292;&#35813;&#20540;&#19982;&#20043;&#21069;&#30340;&#20915;&#31574;&#30456;&#20851;&#12290;&#19968;&#20010;&#26420;&#32032;&#30340;&#31574;&#30053;&#26159;&#22987;&#32456;&#36873;&#25321;&#20855;&#26377;&#26368;&#39640;Q&#20540;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#26063;&#22522;&#20110;Q&#30340;&#31574;&#30053;&#35268;&#21017;&#65292;&#36825;&#20123;&#35268;&#21017;&#21487;&#33021;&#31995;&#32479;&#22320;&#25903;&#25345;&#26576;&#20123;&#26367;&#20195;&#26041;&#26696;&#32780;&#19981;&#26159;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#65292;&#20363;&#22914;&#21253;&#21547;&#26377;&#21033;&#21512;&#20316;&#30340;&#23485;&#23481;&#20559;&#24046;&#30340;&#35268;&#21017;&#12290;&#22312; Compte &#21644; Postlewaite [2018] &#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#22312;&#36825;&#20010; Q-based &#35268;&#21017;&#26063;&#20013;&#23547;&#25214;&#22343;&#34913;&#20559;&#24046;&#65288;&#25110; Qb-equilibria&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#30417;&#27979;&#25216;&#26415;&#19979;&#30340;&#32463;&#20856;&#21338;&#24328;&#12290;
&lt;/p&gt;
&lt;p&gt;
In dynamic environments, Q-learning is an adaptative rule that provides an estimate (a Q-value) of the continuation value associated with each alternative. A naive policy consists in always choosing the alternative with highest Q-value. We consider a family of Q-based policy rules that may systematically favor some alternatives over others, for example rules that incorporate a leniency bias that favors cooperation. In the spirit of Compte and Postlewaite [2018], we look for equilibrium biases (or Qb-equilibria) within this family of Q-based rules. We examine classic games under various monitoring technologies.
&lt;/p&gt;</description></item></channel></rss>