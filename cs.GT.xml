<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#31181;&#25293;&#21334;&#26041;&#24335;&#19979;&#28385;&#36275;&#39044;&#31639;&#21644;ROI&#32422;&#26463;&#65292;&#24182;&#36798;&#21040;&#20010;&#20307;&#21518;&#24724;&#36880;&#28176;&#20943;&#23567;&#65307;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21508;&#33258;&#31454;&#20105;&#26102;&#65292;&#26399;&#26395;&#36164;&#37329;&#27969;&#21160;&#33267;&#23569;&#36798;&#21040;&#26368;&#20248;&#20998;&#37197;&#30340;&#26399;&#26395;&#27969;&#21160;&#30340;&#19968;&#21322;&#12290;</title><link>http://arxiv.org/abs/2301.13306</link><description>&lt;p&gt;
&#24102;&#26377;&#39044;&#31639;&#21644;ROI&#32422;&#26463;&#30340;&#33258;&#21160;&#20986;&#20215;&#31639;&#27861;&#65306;&#25928;&#29575;&#12289;&#21518;&#24724;&#21644;&#33410;&#22863;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Autobidders with Budget and ROI Constraints: Efficiency, Regret, and Pacing Dynamics. (arXiv:2301.13306v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#31181;&#25293;&#21334;&#26041;&#24335;&#19979;&#28385;&#36275;&#39044;&#31639;&#21644;ROI&#32422;&#26463;&#65292;&#24182;&#36798;&#21040;&#20010;&#20307;&#21518;&#24724;&#36880;&#28176;&#20943;&#23567;&#65307;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21508;&#33258;&#31454;&#20105;&#26102;&#65292;&#26399;&#26395;&#36164;&#37329;&#27969;&#21160;&#33267;&#23569;&#36798;&#21040;&#26368;&#20248;&#20998;&#37197;&#30340;&#26399;&#26395;&#27969;&#21160;&#30340;&#19968;&#21322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#21160;&#20986;&#20215;&#31639;&#27861;&#22312;&#22312;&#32447;&#24191;&#21578;&#24179;&#21488;&#19978;&#36827;&#34892;&#21338;&#24328;&#30340;&#24773;&#20917;&#12290;&#27599;&#20010;&#33258;&#21160;&#20986;&#20215;&#31639;&#27861;&#34987;&#36171;&#20104;&#20219;&#21153;&#65292;&#22312;&#22810;&#36718;&#37325;&#22797;&#25293;&#21334;&#20013;&#65292;&#26368;&#22823;&#21270;&#20854;&#24191;&#21578;&#20027;&#30340;&#24635;&#20215;&#20540;&#65292;&#21516;&#26102;&#21463;&#21040;&#39044;&#31639;&#21644;/&#25110;&#25237;&#36164;&#22238;&#25253;&#29575;&#32422;&#26463;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#20445;&#35777;&#28385;&#36275;&#25152;&#26377;&#32422;&#26463;&#26465;&#20214;&#65292;&#24182;&#36798;&#21040;&#36880;&#28176;&#20943;&#23567;&#30340;&#20010;&#20307;&#21518;&#24724;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20165;&#20351;&#29992;&#33258;&#21161;&#21453;&#39304;&#65292;&#24182;&#21487;&#19982;&#31532;&#19968;&#25110;&#31532;&#20108;&#20215;&#26684;&#25293;&#21334;&#20197;&#21450;&#20219;&#20309;&#8220;&#20013;&#38388;&#8221;&#25293;&#21334;&#26684;&#24335;&#19968;&#36215;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;&#24403;&#36825;&#20123;&#33258;&#21160;&#20986;&#20215;&#31639;&#27861;&#30456;&#20114;&#31454;&#20105;&#26102;&#65292;&#25152;&#26377;&#36718;&#27425;&#30340;&#26399;&#26395;&#36164;&#37329;&#27969;&#21160; welfare &#37117;&#33267;&#23569;&#36798;&#21040;&#20102;&#20219;&#20309;&#20998;&#37197;&#25152;&#23454;&#29616;&#30340;&#26399;&#26395;&#26368;&#20248;&#27969;&#21160; welfare &#30340;&#19968;&#21322;&#12290;&#36825;&#22312;&#20986;&#20215;&#21160;&#24577;&#26159;&#21542;&#25910;&#25947;&#21040;&#22343;&#34913;&#20197;&#21450;&#24191;&#21578;&#20027;&#20272;&#20540;&#20043;&#38388;&#30340;&#30456;&#20851;&#32467;&#26500;&#22914;&#20309;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#22343;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a game between autobidding algorithms that compete in an online advertising platform. Each autobidder is tasked with maximizing its advertiser's total value over multiple rounds of a repeated auction, subject to budget and/or return-on-investment constraints. We propose a gradient-based learning algorithm that is guaranteed to satisfy all constraints and achieves vanishing individual regret. Our algorithm uses only bandit feedback and can be used with the first- or second-price auction, as well as with any "intermediate" auction format. Our main result is that when these autobidders play against each other, the resulting expected liquid welfare over all rounds is at least half of the expected optimal liquid welfare achieved by any allocation. This holds whether or not the bidding dynamics converges to an equilibrium and regardless of the correlation structure between advertiser valuations.
&lt;/p&gt;</description></item></channel></rss>