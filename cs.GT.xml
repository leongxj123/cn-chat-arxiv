<rss version="2.0"><channel><title>Chat Arxiv cs.GT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GT</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#24102;&#26377;&#22024;&#26434;&#36125;&#21494;&#26031;&#21453;&#39304;&#30340;&#38646;&#21644;&#30697;&#38453;&#21338;&#24328;&#20013;&#65292;&#23454;&#29616;&#20102;&#23545;&#25968;&#36951;&#25022;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2306.13233</link><description>&lt;p&gt;
&#22522;&#20110;&#24102;&#26377;&#22024;&#26434;&#36125;&#21494;&#26031;&#21453;&#39304;&#30340;&#38646;&#21644;&#30697;&#38453;&#21338;&#24328;&#30340;&#23545;&#25968;&#36951;&#25022;&#23545;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Logarithmic Regret for Matrix Games against an Adversary with Noisy Bandit Feedback. (arXiv:2306.13233v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#24102;&#26377;&#22024;&#26434;&#36125;&#21494;&#26031;&#21453;&#39304;&#30340;&#38646;&#21644;&#30697;&#38453;&#21338;&#24328;&#20013;&#65292;&#23454;&#29616;&#20102;&#23545;&#25968;&#36951;&#25022;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38646;&#21644;&#30697;&#38453;&#21338;&#24328;&#30340;&#21464;&#31181;&#65292;&#20854;&#20013;&#27599;&#27493;&#34892;&#36873;&#25163;&#36873;&#25321;&#19968;&#34892;$i$&#65292;&#21015;&#36873;&#25163;&#36873;&#25321;&#19968;&#21015;$j$&#65292;&#34892;&#36873;&#25163;&#25910;&#21040;&#24179;&#22343;&#20540;&#20026;$A_{i,j}$&#30340;&#22024;&#26434;&#22870;&#21169;&#12290;&#34892;&#36873;&#25163;&#30340;&#30446;&#26631;&#26159;&#23613;&#21487;&#33021;&#22320;&#32047;&#31215;&#22870;&#21169;&#65292;&#21363;&#20351;&#23545;&#25163;&#26159;&#19968;&#20010;&#23545;&#25163;&#24615;&#21015;&#36873;&#25163;&#12290;&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#35777;&#26126;&#22312;$m \times n$&#30697;&#38453;&#21338;&#24328;&#20013;&#65292;&#23454;&#29616;&#20102;$O(\sqrt{mnT})$&#23545;&#25968;&#36951;&#25022;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;UCB&#39118;&#26684;&#31639;&#27861;&#25152;&#33719;&#24471;&#30340;$O(m\sqrt{nT})$&#23545;&#25968;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers a variant of zero-sum matrix games where at each timestep the row player chooses row $i$, the column player chooses column $j$, and the row player receives a noisy reward with mean $A_{i,j}$. The objective of the row player is to accumulate as much reward as possible, even against an adversarial column player. If the row player uses the EXP3 strategy, an algorithm known for obtaining $\sqrt{T}$ regret against an arbitrary sequence of rewards, it is immediate that the row player also achieves $\sqrt{T}$ regret relative to the Nash equilibrium in this game setting. However, partly motivated by the fact that the EXP3 strategy is myopic to the structure of the game, O'Donoghue et al. (2021) proposed a UCB-style algorithm that leverages the game structure and demonstrated that this algorithm greatly outperforms EXP3 empirically. While they showed that this UCB-style algorithm achieved $\sqrt{T}$ regret, in this paper we ask if there exists an algorithm that provably ach
&lt;/p&gt;</description></item></channel></rss>