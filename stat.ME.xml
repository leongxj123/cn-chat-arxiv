<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#26469;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;</title><link>https://arxiv.org/abs/2404.01595</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#25968;&#25454;&#26080;&#37197;&#23545;&#20542;&#21521;&#24471;&#20998;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Propensity Score Alignment of Unpaired Multimodal Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#26469;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#36890;&#24120;&#20381;&#36182;&#20110;&#37197;&#23545;&#26679;&#26412;&#26469;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#65292;&#20294;&#22312;&#29983;&#29289;&#23398;&#31561;&#39046;&#22495;&#65292;&#24448;&#24448;&#38590;&#20197;&#25910;&#38598;&#37197;&#23545;&#26679;&#26412;&#65292;&#22240;&#20026;&#27979;&#37327;&#35774;&#22791;&#36890;&#24120;&#20250;&#30772;&#22351;&#26679;&#26412;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#28508;&#22312;&#32467;&#26524;&#19982;&#22810;&#27169;&#24577;&#35266;&#23519;&#20013;&#30340;&#28508;&#22312;&#35270;&#22270;&#36827;&#34892;&#31867;&#27604;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;Rubin&#30340;&#26694;&#26550;&#26469;&#20272;&#35745;&#19968;&#20010;&#20849;&#21516;&#30340;&#31354;&#38388;&#65292;&#20197;&#21305;&#37197;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20551;&#35774;&#25105;&#20204;&#25910;&#38598;&#20102;&#32463;&#36807;&#22788;&#29702;&#23454;&#39564;&#24178;&#25200;&#30340;&#26679;&#26412;&#65292;&#24182;&#21033;&#29992;&#27492;&#26469;&#20174;&#27599;&#31181;&#27169;&#24577;&#20013;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#65292;&#20854;&#20013;&#21253;&#25324;&#28508;&#22312;&#29366;&#24577;&#21644;&#22788;&#29702;&#20043;&#38388;&#30340;&#25152;&#26377;&#20849;&#20139;&#20449;&#24687;&#65292;&#24182;&#21487;&#29992;&#20110;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#20004;&#31181;&#21033;&#29992;&#36825;&#19968;&#26041;&#27861;&#30340;&#23545;&#40784;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01595v1 Announce Type: new  Abstract: Multimodal representation learning techniques typically rely on paired samples to learn common representations, but paired samples are challenging to collect in fields such as biology where measurement devices often destroy the samples. This paper presents an approach to address the challenge of aligning unpaired samples across disparate modalities in multimodal representation learning. We draw an analogy between potential outcomes in causal inference and potential views in multimodal observations, which allows us to use Rubin's framework to estimate a common space in which to match samples. Our approach assumes we collect samples that are experimentally perturbed by treatments, and uses this to estimate a propensity score from each modality, which encapsulates all shared information between a latent state and treatment and can be used to define a distance between samples. We experiment with two alignment techniques that leverage this di
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2402.11652</link><description>&lt;p&gt;
&#22240;&#26524;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#21452;&#37325;&#31283;&#20581;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Inference in Causal Latent Factor Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11652
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#26032;&#26694;&#26550;&#65292;&#35813;&#29615;&#22659;&#20855;&#26377;&#22823;&#37327;&#21333;&#20301;&#21644;&#32467;&#26524;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#37327;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#65292;&#32467;&#21512;&#20102;&#32467;&#26524;&#22635;&#34917;&#12289;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#20197;&#21450;&#19968;&#31181;&#29992;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#26032;&#22411;&#20132;&#21449;&#37197;&#23545;&#31243;&#24207;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26032;&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#25910;&#25947;&#21040;&#21442;&#25968;&#36895;&#29575;&#19979;&#30340;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;&#27169;&#25311;&#32467;&#26524;&#23637;&#31034;&#20102;&#26412;&#25991;&#20998;&#26512;&#30340;&#20272;&#35745;&#37327;&#30340;&#24418;&#24335;&#29305;&#24615;&#30340;&#23454;&#38469;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11652v1 Announce Type: cross  Abstract: This article introduces a new framework for estimating average treatment effects under unobserved confounding in modern data-rich environments featuring large numbers of units and outcomes. The proposed estimator is doubly robust, combining outcome imputation, inverse probability weighting, and a novel cross-fitting procedure for matrix completion. We derive finite-sample and asymptotic guarantees, and show that the error of the new estimator converges to a mean-zero Gaussian distribution at a parametric rate. Simulation results demonstrate the practical relevance of the formal properties of the estimators analyzed in this article.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#36817;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25991;&#26412;&#25968;&#25454;&#20998;&#21106;&#24182;&#20351;&#29992;&#38646;&#26679;&#26412;&#27169;&#22411;&#25512;&#26029;&#20986;&#20195;&#29702;&#21464;&#37327;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#36817;&#37051; g-formula&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28151;&#28102;&#21464;&#37327;&#23436;&#20840;&#26410;&#35266;&#23519;&#21040;&#30340;&#24773;&#20917;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20135;&#29983;&#20102;&#20302;&#20559;&#24046;&#30340;&#20272;&#35745;&#20540;&#12290;</title><link>http://arxiv.org/abs/2401.06687</link><description>&lt;p&gt;
&#20351;&#29992;&#25991;&#26412;&#25968;&#25454;&#30340;&#36817;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Proximal Causal Inference With Text Data. (arXiv:2401.06687v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#36817;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25991;&#26412;&#25968;&#25454;&#20998;&#21106;&#24182;&#20351;&#29992;&#38646;&#26679;&#26412;&#27169;&#22411;&#25512;&#26029;&#20986;&#20195;&#29702;&#21464;&#37327;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#36817;&#37051; g-formula&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28151;&#28102;&#21464;&#37327;&#23436;&#20840;&#26410;&#35266;&#23519;&#21040;&#30340;&#24773;&#20917;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20135;&#29983;&#20102;&#20302;&#20559;&#24046;&#30340;&#20272;&#35745;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#22240;&#26524;&#26041;&#27861;&#35797;&#22270;&#36890;&#36807;&#23558;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#25968;&#25454;&#20316;&#20026;&#20542;&#21521;&#20110;&#21253;&#21547;&#37096;&#20998;&#25110;&#19981;&#23436;&#20840;&#27979;&#37327;&#30340;&#28151;&#28102;&#21464;&#37327;&#30340;&#20195;&#29702;&#26469;&#20943;&#36731;&#28151;&#28102;&#20559;&#24046;&#12290;&#36825;&#20123;&#26041;&#27861;&#20551;&#35774;&#20998;&#26512;&#20154;&#21592;&#22312;&#19968;&#37096;&#20998;&#23454;&#20363;&#30340;&#25991;&#26412;&#20013;&#20855;&#26377;&#26377;&#30417;&#30563;&#30340;&#28151;&#28102;&#21464;&#37327;&#26631;&#31614;&#65292;&#20294;&#30001;&#20110;&#25968;&#25454;&#38544;&#31169;&#25110;&#25104;&#26412;&#65292;&#36825;&#31181;&#32422;&#26463;&#24182;&#19981;&#24635;&#26159;&#21487;&#34892;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#28151;&#28102;&#21464;&#37327;&#23436;&#20840;&#26410;&#35266;&#23519;&#21040;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#23558;&#22788;&#29702;&#21069;&#25991;&#26412;&#25968;&#25454;&#20998;&#21106;&#65292;&#24182;&#20351;&#29992;&#20004;&#20010;&#38646;&#26679;&#26412;&#27169;&#22411;&#20174;&#20998;&#21106;&#30340;&#20004;&#20010;&#37096;&#20998;&#25512;&#26029;&#20986;&#20004;&#20010;&#20195;&#29702;&#65292;&#24182;&#23558;&#36825;&#20123;&#20195;&#29702;&#24212;&#29992;&#20110;&#36817;&#37051; g-formula&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#22522;&#20110;&#25991;&#26412;&#30340;&#20195;&#29702;&#26041;&#27861;&#28385;&#36275;&#36817;&#37051; g-formula&#25152;&#38656;&#30340;&#35782;&#21035;&#26465;&#20214;&#65292;&#32780;&#20854;&#20182;&#30475;&#20284;&#21512;&#29702;&#30340;&#25552;&#35758;&#21017;&#19981;&#28385;&#36275;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#29615;&#22659;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#23427;&#20135;&#29983;&#20102;&#20302;&#20559;&#24046;&#30340;&#20272;&#35745;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent text-based causal methods attempt to mitigate confounding bias by including unstructured text data as proxies of confounding variables that are partially or imperfectly measured. These approaches assume analysts have supervised labels of the confounders given text for a subset of instances, a constraint that is not always feasible due to data privacy or cost. Here, we address settings in which an important confounding variable is completely unobserved. We propose a new causal inference method that splits pre-treatment text data, infers two proxies from two zero-shot models on the separate splits, and applies these proxies in the proximal g-formula. We prove that our text-based proxy method satisfies identification conditions required by the proximal g-formula while other seemingly reasonable proposals do not. We evaluate our method in synthetic and semi-synthetic settings and find that it produces estimates with low bias. This combination of proximal causal inference and zero-sh
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#40657;&#30418;&#27169;&#22411;&#21644;&#30333;&#30418;&#27169;&#22411;&#30340;&#20449;&#24687;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#20272;&#35745;&#20986;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2401.06447</link><description>&lt;p&gt;
&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#24102;&#26377;&#22122;&#22768;&#25968;&#25454;&#65306;&#20174;&#28784;&#30418;&#30340;&#35282;&#24230;&#26469;&#30475;
&lt;/p&gt;
&lt;p&gt;
A comprehensive framework for multi-fidelity surrogate modeling with noisy data: a gray-box perspective. (arXiv:2401.06447v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06447
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#40657;&#30418;&#27169;&#22411;&#21644;&#30333;&#30418;&#27169;&#22411;&#30340;&#20449;&#24687;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#20272;&#35745;&#20986;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#26426;&#27169;&#25311;&#65288;&#21363;&#30333;&#30418;&#27169;&#22411;&#65289;&#22312;&#27169;&#25311;&#22797;&#26434;&#24037;&#31243;&#31995;&#32479;&#26041;&#38754;&#27604;&#20197;&#24448;&#20219;&#20309;&#26102;&#20505;&#37117;&#26356;&#21152;&#24517;&#19981;&#21487;&#23569;&#12290;&#28982;&#32780;&#65292;&#20165;&#20973;&#35745;&#31639;&#27169;&#22411;&#24448;&#24448;&#26080;&#27861;&#23436;&#20840;&#25429;&#25417;&#29616;&#23454;&#30340;&#22797;&#26434;&#24615;&#12290;&#24403;&#29289;&#29702;&#23454;&#39564;&#21487;&#34892;&#26102;&#65292;&#22686;&#24378;&#35745;&#31639;&#27169;&#22411;&#25552;&#20379;&#30340;&#19981;&#23436;&#25972;&#20449;&#24687;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#12290;&#28784;&#30418;&#24314;&#27169;&#28041;&#21450;&#21040;&#23558;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#65288;&#21363;&#40657;&#30418;&#27169;&#22411;&#65289;&#21644;&#30333;&#30418;&#27169;&#22411;&#65288;&#21363;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#65289;&#30340;&#20449;&#24687;&#34701;&#21512;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#27169;&#22411;&#65288;MFSMs&#65289;&#26469;&#25191;&#34892;&#36825;&#20010;&#20219;&#21153;&#12290;MFSM&#23558;&#19981;&#21516;&#35745;&#31639;&#20445;&#30495;&#24230;&#30340;&#27169;&#22411;&#30340;&#20449;&#24687;&#38598;&#25104;&#21040;&#19968;&#20010;&#26032;&#30340;&#20195;&#29702;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#33021;&#22815;&#22788;&#29702;&#34987;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#33021;&#22815;&#20272;&#35745;&#24213;&#23618;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24378;&#35843;&#20197;&#32622;&#20449;&#24230;&#30340;&#24418;&#24335;&#25552;&#20379;&#20854;&#39044;&#27979;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#31934;&#30830;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computer simulations (a.k.a. white-box models) are more indispensable than ever to model intricate engineering systems. However, computational models alone often fail to fully capture the complexities of reality. When physical experiments are accessible though, it is of interest to enhance the incomplete information offered by computational models. Gray-box modeling is concerned with the problem of merging information from data-driven (a.k.a. black-box) models and white-box (i.e., physics-based) models. In this paper, we propose to perform this task by using multi-fidelity surrogate models (MFSMs). A MFSM integrates information from models with varying computational fidelity into a new surrogate model. The multi-fidelity surrogate modeling framework we propose handles noise-contaminated data and is able to estimate the underlying noise-free high-fidelity function. Our methodology emphasizes on delivering precise estimates of the uncertainty in its predictions in the form of confidence 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14763</link><description>&lt;p&gt;
&#22806;&#37096;&#39564;&#35777;&#31574;&#30053;&#35780;&#20272;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Externally Valid Policy Evaluation Combining Trial and Observational Data. (arXiv:2310.14763v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14763
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#35797;&#39564;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#35780;&#20272;&#20915;&#31574;&#31574;&#30053;&#24433;&#21709;&#30340;&#37329; standard&#12290;&#28982;&#32780;&#65292;&#35797;&#39564;&#25968;&#25454;&#26469;&#33258;&#21487;&#33021;&#19982;&#30446;&#26631;&#20154;&#32676;&#19981;&#21516;&#30340;&#20154;&#32676;&#65292;&#36825;&#24341;&#21457;&#20102;&#22806;&#37096;&#25928;&#24230;&#65288;&#20063;&#31216;&#20026;&#27867;&#21270;&#33021;&#21147;&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#30446;&#26631;&#20154;&#32676;&#30340;&#39069;&#22806;&#21327;&#21464;&#37327;&#25968;&#25454;&#29992;&#20110;&#27169;&#25311;&#35797;&#39564;&#30740;&#31350;&#20013;&#20010;&#20307;&#30340;&#25277;&#26679;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#25351;&#23450;&#30340;&#27169;&#22411;&#26410;&#26657;&#20934;&#33539;&#22260;&#20869;&#20135;&#29983;&#21487;&#39564;&#35777;&#30340;&#22522;&#20110;&#35797;&#39564;&#30340;&#25919;&#31574;&#35780;&#20272;&#12290;&#35813;&#26041;&#27861;&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#21363;&#20351;&#26679;&#26412;&#26159;&#26377;&#38480;&#30340;&#65292;&#26377;&#25928;&#24615;&#20063;&#24471;&#21040;&#20445;&#35777;&#12290;&#20351;&#29992;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#35828;&#26126;&#20102;&#35748;&#35777;&#30340;&#25919;&#31574;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized trials are widely considered as the gold standard for evaluating the effects of decision policies. Trial data is, however, drawn from a population which may differ from the intended target population and this raises a problem of external validity (aka. generalizability). In this paper we seek to use trial data to draw valid inferences about the outcome of a policy on the target population. Additional covariate data from the target population is used to model the sampling of individuals in the trial study. We develop a method that yields certifiably valid trial-based policy evaluations under any specified range of model miscalibrations. The method is nonparametric and the validity is assured even with finite samples. The certified policy evaluations are illustrated using both simulated and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.07852</link><description>&lt;p&gt;
&#20851;&#20110;&#36890;&#36807;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#39640;&#32500;&#31169;&#26377;&#27169;&#22411;&#36873;&#25321;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#25928;&#29992;&#20445;&#35777;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#24191;&#20026;&#20154;&#30693;&#30340;&#25351;&#25968;&#26426;&#21046;&#26469;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20854;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#25351;&#25968;&#26426;&#21046;&#30340;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#23548;&#33268;&#20102;&#20005;&#37325;&#30340;&#35745;&#31639;&#29942;&#39048;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#36827;&#34892;&#37319;&#26679;&#27493;&#39588;&#65292;&#24182;&#22312;&#38382;&#39064;&#21442;&#25968;$n$&#12289;$p$&#21644;$s$&#20013;&#24314;&#31435;&#20102;&#20854;&#21040;&#31283;&#24577;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20854;&#28151;&#21512;&#24615;&#36136;&#24314;&#31435;&#20102;Metropolis-Hastings&#38543;&#26426;&#34892;&#36208;&#30340;&#26368;&#32456;&#20272;&#35745;&#30340;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#35828;&#26126;&#24615;&#27169;&#25311;&#65292;&#21360;&#35777;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29109;&#27491;&#21017;&#21270;&#20316;&#20026;&#19968;&#31181;&#24179;&#28369;&#26041;&#27861;&#22312;Wasserstein&#20272;&#35745;&#22120;&#20013;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#36890;&#36807;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#23454;&#29616;&#12290;&#20027;&#35201;&#21457;&#29616;&#26159;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.06934</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#29109;&#27491;&#21017;&#21270;&#24179;&#28369;Wasserstein&#20272;&#35745;&#22120;&#30340;&#28508;&#22312;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
On the potential benefits of entropic regularization for smoothing Wasserstein estimators. (arXiv:2210.06934v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29109;&#27491;&#21017;&#21270;&#20316;&#20026;&#19968;&#31181;&#24179;&#28369;&#26041;&#27861;&#22312;Wasserstein&#20272;&#35745;&#22120;&#20013;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#36890;&#36807;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#23454;&#29616;&#12290;&#20027;&#35201;&#21457;&#29616;&#26159;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#19987;&#27880;&#20110;&#30740;&#31350;&#29109;&#27491;&#21017;&#21270;&#22312;&#26368;&#20248;&#36755;&#36816;&#20013;&#20316;&#20026;Wasserstein&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#35745;&#23398;&#20013;&#36924;&#36817;&#35823;&#24046;&#21644;&#20272;&#35745;&#35823;&#24046;&#30340;&#32463;&#20856;&#26435;&#34913;&#12290;Wasserstein&#20272;&#35745;&#22120;&#34987;&#23450;&#20041;&#20026;&#35299;&#20915;&#21464;&#20998;&#38382;&#39064;&#30340;&#35299;&#65292;&#20854;&#30446;&#26631;&#20989;&#25968;&#28041;&#21450;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#20351;&#29992;&#12290;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#36890;&#36807;&#29992;&#29109;&#24809;&#32602;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#20174;&#32780;&#23545;&#32467;&#26524;&#20272;&#35745;&#22120;&#20135;&#29983;&#28508;&#22312;&#30340;&#24179;&#28369;&#25928;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#29109;&#27491;&#21017;&#21270;&#23545;&#27491;&#21017;&#21270;Wasserstein&#20272;&#35745;&#22120;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#24615;&#36136;&#21487;&#33021;&#24102;&#26469;&#30340;&#30410;&#22788;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#35752;&#35770;&#29109;&#27491;&#21017;&#21270;&#22914;&#20309;&#20197;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is focused on the study of entropic regularization in optimal transport as a smoothing method for Wasserstein estimators, through the prism of the classical tradeoff between approximation and estimation errors in statistics. Wasserstein estimators are defined as solutions of variational problems whose objective function involves the use of an optimal transport cost between probability measures. Such estimators can be regularized by replacing the optimal transport cost by its regularized version using an entropy penalty on the transport plan. The use of such a regularization has a potentially significant smoothing effect on the resulting estimators. In this work, we investigate its potential benefits on the approximation and estimation properties of regularized Wasserstein estimators. Our main contribution is to discuss how entropic regularization may reach, at a lower computational cost, statistical performances that are comparable to those of un-regularized Wasserstein esti
&lt;/p&gt;</description></item></channel></rss>