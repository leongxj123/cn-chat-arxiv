<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#21644;&#20855;&#26377;&#22797;&#26434;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#32416;&#27491;&#22240;&#27835;&#30103;&#21464;&#37327;&#19981;&#20934;&#30830;&#27979;&#37327;&#24341;&#36215;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20559;&#24046;&#30340;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#21644;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2306.10614</link><description>&lt;p&gt;
&#24102;&#26377;&#22024;&#26434;&#27835;&#30103;&#21644;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#30340;&#21487;&#35782;&#21035;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Identifiable causal inference with noisy treatment and no side information. (arXiv:2306.10614v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#21644;&#20855;&#26377;&#22797;&#26434;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#32416;&#27491;&#22240;&#27835;&#30103;&#21464;&#37327;&#19981;&#20934;&#30830;&#27979;&#37327;&#24341;&#36215;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20559;&#24046;&#30340;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#21644;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26576;&#20123;&#22240;&#26524;&#25512;&#26029;&#22330;&#26223;&#20013;&#65292;&#27835;&#30103;&#65288;&#21363;&#21407;&#22240;&#65289;&#21464;&#37327;&#30340;&#27979;&#37327;&#23384;&#22312;&#19981;&#20934;&#30830;&#24615;&#65292;&#20363;&#22914;&#22312;&#27969;&#34892;&#30149;&#23398;&#25110;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#12290;&#26410;&#33021;&#32416;&#27491;&#27979;&#37327;&#35823;&#24046;&#30340;&#24433;&#21709;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#27809;&#26377;&#20174;&#22240;&#26524;&#35270;&#35282;&#30740;&#31350;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20801;&#35768;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#24182;&#19988;&#19981;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#20391;&#38754;&#20449;&#24687;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#22330;&#26223;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#23427;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#36830;&#32493;&#30340;&#27835;&#30103;&#21464;&#37327;&#65292;&#35813;&#21464;&#37327;&#27979;&#37327;&#19981;&#20934;&#30830;&#12290;&#24314;&#31435;&#22312;&#29616;&#26377;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#21363;&#20351;&#27809;&#26377;&#27979;&#37327;&#35823;&#24046;&#26041;&#24046;&#25110;&#20854;&#20182;&#20391;&#38754;&#20449;&#24687;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#65292;&#20854;&#20013;&#39640;&#26031;&#26465;&#20214;&#30001;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#26469;&#35757;&#32451;&#35813;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In some causal inference scenarios, the treatment (i.e. cause) variable is measured inaccurately, for instance in epidemiology or econometrics. Failure to correct for the effect of this measurement error can lead to biased causal effect estimates. Previous research has not studied methods that address this issue from a causal viewpoint while allowing for complex nonlinear dependencies and without assuming access to side information. For such as scenario, this paper proposes a model that assumes a continuous treatment variable which is inaccurately measured. Building on existing results for measurement error models, we prove that our model's causal effect estimates are identifiable, even without knowledge of the measurement error variance or other side information. Our method relies on a deep latent variable model where Gaussian conditionals are parameterized by neural networks, and we develop an amortized importance-weighted variational objective for training the model. Empirical resul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.10025</link><description>&lt;p&gt;
&#29992;&#20110;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#35782;&#21035;&#21644;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance. (arXiv:2304.10025v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#39564;&#21644;&#35266;&#23519;&#30740;&#31350;&#20013;&#65292;&#20154;&#20204;&#36890;&#24120;&#23545;&#20102;&#35299;&#24178;&#39044;&#26041;&#26696;&#22914;&#20309;&#25913;&#21892;&#26368;&#32456;&#32467;&#26524;&#30340;&#28508;&#22312;&#26426;&#21046;&#24863;&#20852;&#36259;&#12290;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#26088;&#22312;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20294;&#20027;&#35201;&#38480;&#20110;&#27835;&#30103;&#23436;&#20840;&#26381;&#20174;&#30340;&#24773;&#20917;&#65292;&#21482;&#26377;&#23569;&#25968;&#24773;&#20917;&#38656;&#35201;&#25490;&#38500;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#21322;&#21442;&#25968;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26080;&#38656;&#25490;&#38500;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#25972;&#20010;&#30740;&#31350;&#20154;&#32676;&#30340;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#65292;&#24182;&#36827;&#19968;&#27493;&#38024;&#23545;&#30001;&#28508;&#22312;&#26381;&#20174;&#34892;&#20026;&#29305;&#24449;&#21270;&#30340;&#20122;&#20154;&#32676;&#20013;&#30340;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#36827;&#34892;&#35782;&#21035;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#20272;&#35745;&#37327;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#65292;&#36825;&#28608;&#21169;&#20102;&#19968;&#32452;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;&#22120;&#36827;&#34892;&#25512;&#35770;&#12290;&#36825;&#20123;&#34987;&#35782;&#21035;&#20272;&#35745;&#37327;&#30340;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In experimental and observational studies, there is often interest in understanding the potential mechanism by which an intervention program improves the final outcome. Causal mediation analyses have been developed for this purpose but are primarily restricted to the case of perfect treatment compliance, with a few exceptions that require exclusion restriction. In this article, we establish a semiparametric framework for assessing causal mediation in the presence of treatment noncompliance without exclusion restriction. We propose a set of assumptions to identify the natural mediation effects for the entire study population and further, for the principal natural mediation effects within subpopulations characterized by the potential compliance behaviour. We derive the efficient influence functions for the principal natural mediation effect estimands, which motivate a set of multiply robust estimators for inference. The semiparametric efficiency theory for the identified estimands is der
&lt;/p&gt;</description></item><item><title>&#26426;&#22120;&#23398;&#20064;&#22522;&#20934;&#24615;&#33021;&#35780;&#20272;&#20013;&#65292;&#26368;&#20808;&#36827;&#30340;&#65288;SOTA&#65289;&#24615;&#33021;&#30340;&#20272;&#35745;&#20540;&#36807;&#20110;&#20048;&#35266;&#65292;&#23481;&#26131;&#23548;&#33268;&#26041;&#27861;&#30340;&#24573;&#35270;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#26657;&#27491;&#22810;&#37325;&#24615;&#20559;&#24046;&#24182;&#27604;&#36739;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.07272</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22522;&#20934;&#24615;&#33021;&#35780;&#20272;&#20013;&#30340;&#22810;&#37325;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
What is the state of the art? Accounting for multiplicity in machine learning benchmark performance. (arXiv:2303.07272v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07272
&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22522;&#20934;&#24615;&#33021;&#35780;&#20272;&#20013;&#65292;&#26368;&#20808;&#36827;&#30340;&#65288;SOTA&#65289;&#24615;&#33021;&#30340;&#20272;&#35745;&#20540;&#36807;&#20110;&#20048;&#35266;&#65292;&#23481;&#26131;&#23548;&#33268;&#26041;&#27861;&#30340;&#24573;&#35270;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#26657;&#27491;&#22810;&#37325;&#24615;&#20559;&#24046;&#24182;&#27604;&#36739;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#36890;&#36807;&#22312;&#20844;&#20849;&#25968;&#25454;&#24211;&#20013;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#26469;&#36827;&#34892;&#35780;&#20272;&#21644;&#27604;&#36739;&#12290;&#36825;&#20801;&#35768;&#22810;&#31181;&#26041;&#27861;&#65292;&#22312;&#30456;&#21516;&#26465;&#20214;&#19979;&#24182;&#36328;&#36234;&#26102;&#38388;&#36827;&#34892;&#35780;&#20272;&#12290;&#22312;&#38382;&#39064;&#20013;&#25490;&#21517;&#26368;&#39640;&#30340;&#24615;&#33021;&#34987;&#31216;&#20026;&#26368;&#20808;&#36827;&#30340;&#65288;SOTA&#65289;&#24615;&#33021;&#65292;&#24182;&#19988;&#34987;&#29992;&#20316;&#26032;&#26041;&#27861;&#20986;&#29256;&#30340;&#21442;&#32771;&#28857;&#12290;&#20294;&#20351;&#29992;&#26368;&#39640;&#25490;&#21517;&#30340;&#24615;&#33021;&#20316;&#20026;SOTA&#30340;&#20272;&#35745;&#20540;&#26159;&#19968;&#31181;&#26377;&#20559;&#30340;&#20272;&#35745;&#22120;&#65292;&#20250;&#32473;&#20986;&#36807;&#20110;&#20048;&#35266;&#30340;&#32467;&#26524;&#12290;&#36825;&#31181;&#22810;&#37325;&#24615;&#30340;&#26426;&#21046;&#26159;&#22810;&#37325;&#27604;&#36739;&#21644;&#22810;&#37325;&#26816;&#39564;&#20013;&#24191;&#27867;&#30740;&#31350;&#30340;&#20027;&#39064;&#65292;&#20294;&#22312;&#20851;&#20110;SOTA&#20272;&#35745;&#30340;&#35752;&#35770;&#20013;&#20960;&#20046;&#27809;&#26377;&#24471;&#21040;&#25552;&#21450;&#12290;&#36807;&#20110;&#20048;&#35266;&#30340;&#26368;&#20808;&#36827;&#20272;&#35745;&#20540;&#34987;&#29992;&#20316;&#35780;&#20272;&#26032;&#26041;&#27861;&#30340;&#26631;&#20934;&#65292;&#32780;&#20855;&#26377;&#26126;&#26174;&#21155;&#21183;&#32467;&#26524;&#30340;&#26041;&#27861;&#24456;&#23481;&#26131;&#34987;&#24573;&#35270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#26657;&#27491;&#22810;&#37325;&#24615;&#20559;&#24046;&#24182;&#27604;&#36739;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning methods are commonly evaluated and compared by their performance on data sets from public repositories. This allows for multiple methods, oftentimes several thousands, to be evaluated under identical conditions and across time. The highest ranked performance on a problem is referred to as state-of-the-art (SOTA) performance, and is used, among other things, as a reference point for publication of new methods. Using the highest-ranked performance as an estimate for SOTA is a biased estimator, giving overly optimistic results. The mechanisms at play are those of multiplicity, a topic that is well-studied in the context of multiple comparisons and multiple testing, but has, as far as the authors are aware of, been nearly absent from the discussion regarding SOTA estimates. The optimistic state-of-the-art estimate is used as a standard for evaluating new methods, and methods with substantial inferior results are easily overlooked. In this article, we provide a probability 
&lt;/p&gt;</description></item></channel></rss>