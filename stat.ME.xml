<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02211</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Machine Learning with Multi-source Data. (arXiv:2309.02211v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#30446;&#26631;&#20998;&#24067;&#19982;&#28304;&#25968;&#25454;&#38598;&#19981;&#21516;&#26102;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#36739;&#24046;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#21033;&#29992;&#22810;&#20010;&#25968;&#25454;&#28304;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#20248;&#21270;&#20851;&#20110;&#30446;&#26631;&#20998;&#24067;&#31867;&#30340;&#21487;&#35299;&#37322;&#26041;&#24046;&#30340;&#23545;&#25239;&#24615;&#22870;&#21169;&#12290;&#19982;&#20256;&#32479;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#25913;&#21892;&#20102;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26159;&#28304;&#25968;&#25454;&#38598;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340;&#21152;&#26435;&#24179;&#22343;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#37492;&#21035;&#32467;&#26524;&#26469;&#25552;&#39640;&#20219;&#24847;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#31561;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#22120;&#26469;&#20272;&#35745;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;c&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal aggregation weight for general machine-learning algorithms and demonstrate its improvement in the c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20998;&#24067;&#23545;&#31216;&#24615;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#38598;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#27979;&#35797;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#12290;</title><link>http://arxiv.org/abs/2307.15834</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#23545;&#20998;&#37197;&#32676;&#23545;&#31216;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Non-parametric Hypothesis Tests for Distributional Group Symmetry. (arXiv:2307.15834v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15834
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20998;&#24067;&#23545;&#31216;&#24615;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#38598;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#27979;&#35797;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#24615;&#22312;&#31185;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#36215;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23545;&#20110;&#24050;&#30693;&#36981;&#24490;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#65292;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#35768;&#22810;&#21033;&#29992;&#23545;&#31216;&#24615;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26222;&#36941;&#32676;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#25110;&#19981;&#23384;&#22312;&#30340;&#32479;&#35745;&#26816;&#39564;&#20960;&#20046;&#19981;&#23384;&#22312;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#22522;&#20110;&#21333;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#65292;&#29992;&#20110;&#38024;&#23545;&#29305;&#23450;&#32676;&#30340;&#20998;&#24067;&#23545;&#31216;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36866;&#29992;&#20110;&#20004;&#31181;&#24191;&#27867;&#24773;&#20917;&#30340;&#23545;&#31216;&#24615;&#26816;&#39564;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#31532;&#19968;&#31181;&#24773;&#20917;&#26159;&#27979;&#35797;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#30340;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#19968;&#20010;&#28176;&#36817;&#26080;&#20559;&#30340;&#26816;&#39564;&#21482;&#38656;&#35201;&#19968;&#20010;&#21487;&#35745;&#31639;&#30340;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#19978;&#30340;&#24230;&#37327;&#21644;&#33021;&#22815;&#22343;&#21248;&#38543;&#26426;&#37319;&#26679;&#32676;&#20803;&#32032;&#30340;&#33021;&#21147;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#65292;&#24182;&#35777;&#26126;&#23427;&#21487;&#20197;&#23454;&#29616;&#31934;&#30830;&#30340;p&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetry plays a central role in the sciences, machine learning, and statistics. For situations in which data are known to obey a symmetry, a multitude of methods that exploit symmetry have been developed. Statistical tests for the presence or absence of general group symmetry, however, are largely non-existent. This work formulates non-parametric hypothesis tests, based on a single independent and identically distributed sample, for distributional symmetry under a specified group. We provide a general formulation of tests for symmetry that apply to two broad settings. The first setting tests for the invariance of a marginal or joint distribution under the action of a compact group. Here, an asymptotically unbiased test only requires a computable metric on the space of probability distributions and the ability to sample uniformly random group elements. Building on this, we propose an easy-to-implement conditional Monte Carlo test and prove that it achieves exact $p$-values with finitel
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#27714;&#35299;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;OED&#38382;&#39064;&#65292;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#26356;&#23569;&#30340;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.10430</link><description>&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Variational Sequential Optimal Experimental Design using Reinforcement Learning. (arXiv:2306.10430v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10430
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#27714;&#35299;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;OED&#38382;&#39064;&#65292;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#26356;&#23569;&#30340;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745; (vsOED) &#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#26469;&#26368;&#20248;&#22320;&#35774;&#35745;&#26377;&#38480;&#24207;&#21015;&#30340;&#23454;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#19979;&#30028;&#20272;&#35745;&#26399;&#26395;&#25928;&#29992;&#12290;&#36890;&#36807;&#21516;&#26102;&#26368;&#22823;&#21270;&#21464;&#20998;&#19979;&#30028;&#21644;&#25191;&#34892;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#26469;&#25968;&#20540;&#35299;&#20915;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#31995;&#21015;&#38754;&#21521;&#21442;&#25968;&#25512;&#26029;&#12289;&#27169;&#22411;&#21306;&#20998;&#21644;&#30446;&#26631;&#23548;&#21521;&#39044;&#27979;&#30340;OED&#38382;&#39064;&#12290;&#36825;&#20123;&#26696;&#20363;&#28085;&#30422;&#20102;&#26174;&#24335;&#21644;&#38544;&#24335;&#20284;&#28982;&#20989;&#25968;&#12289;&#40635;&#28902;&#21442;&#25968;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;vsOED&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20197;&#21069;&#30340;&#39034;&#24207;&#35774;&#35745;&#31639;&#27861;&#30456;&#27604;&#65292;&#26679;&#26412;&#25928;&#29575;&#22823;&#22823;&#25552;&#39640;&#65292;&#25152;&#38656;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#20943;&#23569;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce variational sequential Optimal Experimental Design (vsOED), a new method for optimally designing a finite sequence of experiments under a Bayesian framework and with information-gain utilities. Specifically, we adopt a lower bound estimator for the expected utility through variational approximation to the Bayesian posteriors. The optimal design policy is solved numerically by simultaneously maximizing the variational lower bound and performing policy gradient updates. We demonstrate this general methodology for a range of OED problems targeting parameter inference, model discrimination, and goal-oriented prediction. These cases encompass explicit and implicit likelihoods, nuisance parameters, and physics-based partial differential equation models. Our vsOED results indicate substantially improved sample efficiency and reduced number of forward model simulations compared to previous sequential design algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2205.14568</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#65306;&#22312;&#38134;&#27827;&#32418;&#31227;&#20272;&#35745;&#21644;&#27010;&#29575;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting. (arXiv:2205.14568v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#35780;&#20272;AI&#31639;&#27861;&#30340;&#39044;&#27979;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#25551;&#36848;&#30446;&#26631;&#21464;&#37327;$y \in \mathbb{R}$&#22312;&#32473;&#23450;&#22797;&#26434;&#36755;&#20837;&#29305;&#24449;$\mathbf{x} \in \mathcal{X}$&#30340;&#26465;&#20214;&#19979;&#30340;&#39044;&#27979;&#20998;&#24067;$F(y|\mathbf{x})$&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#20998;&#24067;&#65288;&#20363;&#22914;&#65292;&#24402;&#19968;&#21270;&#27969;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65289;&#24448;&#24448;&#32570;&#20047;&#26465;&#20214;&#26657;&#20934;&#65292;&#21363;&#32473;&#23450;&#36755;&#20837;$\mathbf{x}$&#30340;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#19982;&#39044;&#27979;&#27010;&#29575;&#26174;&#33879;&#19981;&#21516;&#12290;&#24403;&#21069;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#33021;&#23436;&#20840;&#35780;&#20272;&#21644;&#23454;&#26045;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20174;&#26657;&#20934;&#25968;&#25454;&#20013;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#26469;&#21516;&#26102;&#35299;&#20915;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23545;&#27010;&#29575;&#31215;&#20998;&#21464;&#25442;&#20998;&#25968;&#36827;&#34892;$\mathbf{x}$&#30340;&#22238;&#24402;&#12290;&#20272;&#35745;&#30340;&#22238;&#24402;&#25552;&#20379;&#20102;&#23545;&#29305;&#24449;&#31354;&#38388;&#20013;&#26465;&#20214;&#35206;&#30422;&#30340;&#21487;&#35299;&#37322;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is crucial for assessing the predictive ability of AI algorithms. Much research has been devoted to describing the predictive distribution (PD) $F(y|\mathbf{x})$ of a target variable $y \in \mathbb{R}$ given complex input features $\mathbf{x} \in \mathcal{X}$. However, off-the-shelf PDs (from, e.g., normalizing flows and Bayesian neural networks) often lack conditional calibration with the probability of occurrence of an event given input $\mathbf{x}$ being significantly different from the predicted probability. Current calibration methods do not fully assess and enforce conditionally calibrated PDs. Here we propose \texttt{Cal-PIT}, a method that addresses both PD diagnostics and recalibration by learning a single probability-probability map from calibration data. The key idea is to regress probability integral transform scores against $\mathbf{x}$. The estimated regression provides interpretable diagnostics of conditional coverage across the feature space. 
&lt;/p&gt;</description></item></channel></rss>