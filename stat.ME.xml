<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#26469;&#38477;&#20302;&#28176;&#36817;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.03589</link><description>&lt;p&gt;
&#29992;&#20110;&#22788;&#29702;&#22240;&#21464;&#37327;&#36873;&#25321;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03589
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#26469;&#38477;&#20302;&#28176;&#36817;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATEs&#65289;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#20854;&#20013;&#23454;&#39564;&#32773;&#25353;&#39034;&#24207;&#20174;&#30001;&#23454;&#39564;&#32773;&#20915;&#23450;&#30340;&#21327;&#21464;&#37327;&#23494;&#24230;&#20013;&#25277;&#26679;&#19968;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#24182;&#20998;&#37197;&#19968;&#31181;&#22788;&#29702;&#12290;&#22312;&#20998;&#37197;&#22788;&#29702;&#21518;&#65292;&#23454;&#39564;&#32773;&#31435;&#21363;&#35266;&#23519;&#30456;&#24212;&#30340;&#32467;&#26524;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#23454;&#39564;&#32773;&#21033;&#29992;&#25910;&#38598;&#30340;&#26679;&#26412;&#20272;&#31639;&#20986;&#19968;&#20010;ATE&#12290;&#23454;&#39564;&#32773;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#36739;&#23567;&#30340;&#28176;&#36817;&#26041;&#24046;&#20272;&#35745;ATE&#12290;&#29616;&#26377;&#30740;&#31350;&#24050;&#32463;&#35774;&#35745;&#20102;&#19968;&#20123;&#33021;&#22815;&#33258;&#36866;&#24212;&#20248;&#21270;&#20542;&#21521;&#24471;&#20998;&#65288;&#22788;&#29702;&#20998;&#37197;&#27010;&#29575;&#65289;&#30340;&#23454;&#39564;&#12290;&#20316;&#20026;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#27010;&#25324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#19979;&#23454;&#39564;&#32773;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#20197;&#21450;&#20542;&#21521;&#24471;&#20998;&#65292;&#24182;&#21457;&#29616;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#27604;&#20165;&#20248;&#21270;&#20542;&#21521;&#24471;&#20998;&#21487;&#20197;&#20943;&#23569;&#28176;&#36817;&#26041;&#24046;&#26356;&#22810;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03589v1 Announce Type: cross  Abstract: This study designs an adaptive experiment for efficiently estimating average treatment effect (ATEs). We consider an adaptive experiment where an experimenter sequentially samples an experimental unit from a covariate density decided by the experimenter and assigns a treatment. After assigning a treatment, the experimenter observes the corresponding outcome immediately. At the end of the experiment, the experimenter estimates an ATE using gathered samples. The objective of the experimenter is to estimate the ATE with a smaller asymptotic variance. Existing studies have designed experiments that adaptively optimize the propensity score (treatment-assignment probability). As a generalization of such an approach, we propose a framework under which an experimenter optimizes the covariate density, as well as the propensity score, and find that optimizing both covariate density and propensity score reduces the asymptotic variance more than o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20026;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#25552;&#20379;&#20102;&#26032;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.12949</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#26684;&#25289;&#22982;&#30697;&#38453;&#36827;&#34892;&#22810;&#20803;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the use of the Gram matrix for multivariate functional principal components analysis. (arXiv:2306.12949v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20026;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#25552;&#20379;&#20102;&#26032;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#38477;&#32500;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#38477;&#32500;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#12290;&#29616;&#26377;&#30340;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#36890;&#24120;&#28041;&#21450;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23545;&#35282;&#21270;&#12290;&#38543;&#30528;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20272;&#35745;&#21464;&#24471;&#26356;&#21152;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#29305;&#24449;&#21521;&#37327;&#12290;&#22522;&#20110;&#35266;&#27979;&#31354;&#38388;&#21644;&#20989;&#25968;&#29305;&#24449;&#31354;&#38388;&#30340;&#23545;&#20598;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#26354;&#32447;&#20043;&#38388;&#30340;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#12290;&#24314;&#31435;&#20102;&#21327;&#26041;&#24046;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#21644;&#20869;&#31215;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#20960;&#20010;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#35774;&#32622;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25552;&#20379;&#20102;&#23427;&#20204;&#30340;&#36890;&#29992;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dimension reduction is crucial in functional data analysis (FDA). The key tool to reduce the dimension of the data is functional principal component analysis. Existing approaches for functional principal component analysis usually involve the diagonalization of the covariance operator. With the increasing size and complexity of functional datasets, estimating the covariance operator has become more challenging. Therefore, there is a growing need for efficient methodologies to estimate the eigencomponents. Using the duality of the space of observations and the space of functional features, we propose to use the inner-product between the curves to estimate the eigenelements of multivariate and multidimensional functional datasets. The relationship between the eigenelements of the covariance operator and those of the inner-product matrix is established. We explore the application of these methodologies in several FDA settings and provide general guidance on their usability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.14484</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#32570;&#22833;&#20540;&#30340;&#25554;&#34917;&#38382;&#39064;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Imputation of missing values in multi-view data. (arXiv:2210.14484v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#26159;&#25351;&#30001;&#22810;&#20010;&#19981;&#21516;&#29305;&#24449;&#38598;&#25551;&#36848;&#30340;&#25968;&#25454;&#12290;&#22312;&#22788;&#29702;&#22810;&#35270;&#35282;&#25968;&#25454;&#26102;&#65292;&#33509;&#20986;&#29616;&#32570;&#22833;&#20540;&#65292;&#21017;&#19968;&#20010;&#35270;&#35282;&#20013;&#30340;&#25152;&#26377;&#29305;&#24449;&#26497;&#26377;&#21487;&#33021;&#21516;&#26102;&#32570;&#22833;&#65292;&#22240;&#32780;&#23548;&#33268;&#38750;&#24120;&#22823;&#37327;&#30340;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#35270;&#35282;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#25554;&#34917;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#22534;&#21472;&#24809;&#32602;&#36923;&#36753;&#22238;&#24402;(StaPLR)&#31639;&#27861;&#65292;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#65292;&#20197;&#35299;&#20915;&#22266;&#26377;&#30340;&#22810;&#35270;&#35282;&#35745;&#31639;&#25361;&#25112;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#31454;&#20105;&#24615;&#32467;&#26524;&#65292;&#32780;&#19988;&#20855;&#26377;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20808;&#36827;&#30340;&#25554;&#34917;&#31639;&#27861;&#65292;&#20363;&#22914;missForest&#12290;
&lt;/p&gt;
&lt;p&gt;
Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest 
&lt;/p&gt;</description></item></channel></rss>