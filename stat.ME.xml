<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20943;&#23569;&#27835;&#30103;&#25928;&#26524;&#39044;&#27979;&#25152;&#38656;&#30340;&#35757;&#32451;&#38598;&#22823;&#23567;&#65292;&#26377;&#25928;&#21033;&#29992;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#30340;&#22270;&#32467;&#26500;&#65292;&#20026;&#27835;&#30103;&#25928;&#26524;&#39044;&#27979;&#24102;&#26469;&#26032;&#30340;&#21487;&#33021;&#24615;</title><link>https://arxiv.org/abs/2403.19289</link><description>&lt;p&gt;
&#29992;&#20110;&#27835;&#30103;&#25928;&#26524;&#39044;&#27979;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks for Treatment Effect Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19289
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20943;&#23569;&#27835;&#30103;&#25928;&#26524;&#39044;&#27979;&#25152;&#38656;&#30340;&#35757;&#32451;&#38598;&#22823;&#23567;&#65292;&#26377;&#25928;&#21033;&#29992;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#30340;&#22270;&#32467;&#26500;&#65292;&#20026;&#27835;&#30103;&#25928;&#26524;&#39044;&#27979;&#24102;&#26469;&#26032;&#30340;&#21487;&#33021;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#24448;&#24448;&#28041;&#21450;&#26114;&#36149;&#30340;&#27835;&#30103;&#20998;&#37197;&#65292;&#36825;&#22312;&#22823;&#35268;&#27169;&#35774;&#32622;&#20013;&#21487;&#33021;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#26469;&#39044;&#27979;&#36825;&#31181;&#27835;&#30103;&#25928;&#26524;&#32780;&#26080;&#38656;&#23454;&#38469;&#24178;&#39044;&#26159;&#20943;&#23569;&#39118;&#38505;&#30340;&#19968;&#31181;&#26631;&#20934;&#20570;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#27835;&#30103;&#25928;&#26524;&#39044;&#27979;&#26041;&#27861;&#24448;&#24448;&#20381;&#36182;&#20110;&#22823;&#35268;&#27169;&#23454;&#39564;&#26500;&#24314;&#30340;&#35757;&#32451;&#38598;&#65292;&#22240;&#27492;&#20174;&#26681;&#26412;&#19978;&#23384;&#22312;&#39118;&#38505;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#20943;&#23569;&#25152;&#38656;&#30340;&#35757;&#32451;&#38598;&#22823;&#23567;&#65292;&#20381;&#36182;&#20110;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#20013;&#24120;&#35265;&#30340;&#22270;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#35270;&#20026;&#20855;&#26377;&#26377;&#38480;&#25968;&#37327;&#26631;&#35760;&#23454;&#20363;&#30340;&#33410;&#28857;&#22238;&#24402;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#31867;&#20284;&#20110;&#20808;&#21069;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#21452;&#27169;&#22411;&#31070;&#32463;&#26550;&#26500;&#65292;&#24182;&#27979;&#35797;&#20102;&#19981;&#21516;&#30340;&#28040;&#24687;&#20256;&#36882;&#23618;&#36827;&#34892;&#32534;&#30721;&#12290;&#27492;&#22806;&#65292;&#20316;&#20026;&#39069;&#22806;&#27493;&#39588;&#65292;&#25105;&#20204;&#23558;&#27169;&#22411;&#19982;&#33719;&#21462;&#20989;&#25968;&#30456;&#32467;&#21512;&#65292;&#20197;&#24341;&#23548;&#20449;&#24687;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19289v1 Announce Type: cross  Abstract: Estimating causal effects in e-commerce tends to involve costly treatment assignments which can be impractical in large-scale settings. Leveraging machine learning to predict such treatment effects without actual intervention is a standard practice to diminish the risk. However, existing methods for treatment effect prediction tend to rely on training sets of substantial size, which are built from real experiments and are thus inherently risky to create. In this work we propose a graph neural network to diminish the required training set size, relying on graphs that are common in e-commerce data. Specifically, we view the problem as node regression with a restricted number of labeled instances, develop a two-model neural architecture akin to previous causal effect estimators, and test varying message-passing layers for encoding. Furthermore, as an extra step, we combine the model with an acquisition function to guide the creation of th
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#26862;&#26519;&#65288;ASBF&#65289;&#65292;&#21487;&#22312;&#23398;&#20064;&#26641;&#34920;&#31034;&#30340;&#21516;&#26102;&#65292;&#22312;&#22797;&#26434;&#24773;&#20917;&#19979;&#23454;&#29616;&#26497;&#23567;&#26497;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26412;&#22320;&#21270;&#29256;&#26412;&#65292;&#22312;H\"older&#31867;&#19979;&#36798;&#21040;&#26368;&#23567;&#26497;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11228</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#20248;&#21270;&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Adaptive Split Balancing for Optimal Random Forest
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11228
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#26862;&#26519;&#65288;ASBF&#65289;&#65292;&#21487;&#22312;&#23398;&#20064;&#26641;&#34920;&#31034;&#30340;&#21516;&#26102;&#65292;&#22312;&#22797;&#26434;&#24773;&#20917;&#19979;&#23454;&#29616;&#26497;&#23567;&#26497;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26412;&#22320;&#21270;&#29256;&#26412;&#65292;&#22312;H\"older&#31867;&#19979;&#36798;&#21040;&#26368;&#23567;&#26497;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#38543;&#26426;&#26862;&#26519;&#36890;&#24120;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#22312;&#22797;&#26434;&#24773;&#20917;&#19979;&#32570;&#20047;&#36866;&#24212;&#24615;&#65292;&#25110;&#22312;&#31616;&#21333;&#12289;&#24179;&#28369;&#24773;&#26223;&#19979;&#22833;&#21435;&#26368;&#20248;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#26862;&#26519;&#65288;ASBF&#65289;&#65292;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#26641;&#34920;&#31034;&#65292;&#21516;&#26102;&#22312;Lipschitz&#31867;&#19979;&#23454;&#29616;&#26497;&#23567;&#26497;&#20248;&#24615;&#12290;&#20026;&#20102;&#21033;&#29992;&#26356;&#39640;&#38454;&#30340;&#24179;&#28369;&#24615;&#27700;&#24179;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#26412;&#22320;&#21270;&#29256;&#26412;&#65292;&#35813;&#29256;&#26412;&#22312;&#20219;&#24847;$q \in \mathbb{N}$&#21644;$\beta \in (0,1]$&#30340;H&#246;lder&#31867;$\mathcal{H}^{q,\beta}$&#19979;&#36798;&#21040;&#26368;&#23567;&#26497;&#20248;&#24615;&#12290;&#19982;&#24191;&#27867;&#20351;&#29992;&#30340;&#38543;&#26426;&#29305;&#24449;&#36873;&#25321;&#19981;&#21516;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23545;&#29616;&#26377;&#26041;&#27861;&#30340;&#24179;&#34913;&#20462;&#25913;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36807;&#24230;&#20381;&#36182;&#36741;&#21161;&#38543;&#26426;&#24615;&#21487;&#33021;&#20250;&#25439;&#23475;&#26641;&#27169;&#22411;&#30340;&#36924;&#36817;&#33021;&#21147;&#65292;&#23548;&#33268;&#27425;&#20248;&#32467;&#26524;&#12290;&#30456;&#21453;&#65292;&#19968;&#20010;&#26356;&#24179;&#34913;&#12289;&#26356;&#23569;&#38543;&#26426;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11228v1 Announce Type: cross  Abstract: While random forests are commonly used for regression problems, existing methods often lack adaptability in complex situations or lose optimality under simple, smooth scenarios. In this study, we introduce the adaptive split balancing forest (ASBF), capable of learning tree representations from data while simultaneously achieving minimax optimality under the Lipschitz class. To exploit higher-order smoothness levels, we further propose a localized version that attains the minimax rate under the H\"older class $\mathcal{H}^{q,\beta}$ for any $q\in\mathbb{N}$ and $\beta\in(0,1]$. Rather than relying on the widely-used random feature selection, we consider a balanced modification to existing approaches. Our results indicate that an over-reliance on auxiliary randomness may compromise the approximation power of tree models, leading to suboptimal results. Conversely, a less random, more balanced approach demonstrates optimality. Additionall
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20811;&#26381;&#20272;&#35745;&#22810;&#39033;&#24335;&#21709;&#24212;&#27169;&#22411;&#20013;&#25351;&#25968;&#32423;&#25903;&#25345;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#21015;&#32852;&#34920;&#27010;&#29575;&#20998;&#24067;&#30340;&#32771;&#34385;&#38598;&#27010;&#29575;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.12470</link><description>&lt;p&gt;
&#21487;&#20280;&#32553;&#20272;&#35745;&#20855;&#26377;&#19981;&#30830;&#23450;&#30340;&#36873;&#39033;&#38598;&#30340;&#22810;&#39033;&#24335;&#21709;&#24212;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Scalable Estimation of Multinomial Response Models with Uncertain Consideration Sets. (arXiv:2308.12470v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12470
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20811;&#26381;&#20272;&#35745;&#22810;&#39033;&#24335;&#21709;&#24212;&#27169;&#22411;&#20013;&#25351;&#25968;&#32423;&#25903;&#25345;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#21015;&#32852;&#34920;&#27010;&#29575;&#20998;&#24067;&#30340;&#32771;&#34385;&#38598;&#27010;&#29575;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20132;&#21449;&#25110;&#32437;&#21521;&#25968;&#25454;&#30340;&#26080;&#24207;&#22810;&#39033;&#24335;&#21709;&#24212;&#27169;&#22411;&#25311;&#21512;&#20013;&#30340;&#19968;&#20010;&#26631;&#20934;&#20551;&#35774;&#26159;&#65292;&#21709;&#24212;&#26469;&#33258;&#20110;&#30456;&#21516;&#30340;J&#20010;&#31867;&#21035;&#38598;&#21512;&#12290;&#28982;&#32780;&#65292;&#24403;&#21709;&#24212;&#24230;&#37327;&#20027;&#20307;&#20570;&#20986;&#30340;&#36873;&#25321;&#26102;&#65292;&#26356;&#36866;&#21512;&#20551;&#35774;&#22810;&#39033;&#24335;&#21709;&#24212;&#30340;&#20998;&#24067;&#26159;&#22312;&#20027;&#20307;&#29305;&#23450;&#30340;&#32771;&#34385;&#38598;&#26465;&#20214;&#19979;&#65292;&#20854;&#20013;&#36825;&#20010;&#32771;&#34385;&#38598;&#26159;&#20174;{1,2, ..., J}&#30340;&#24130;&#38598;&#20013;&#25277;&#21462;&#30340;&#12290;&#30001;&#20110;&#36825;&#20010;&#24130;&#38598;&#30340;&#22522;&#25968;&#22312;J&#20013;&#26159;&#25351;&#25968;&#32423;&#30340;&#65292;&#19968;&#33324;&#26469;&#35828;&#20272;&#35745;&#26159;&#26080;&#27861;&#23454;&#29616;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#27493;&#39588;&#26159;&#22522;&#20110;&#22312;&#21015;&#32852;&#34920;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#19968;&#33324;&#34920;&#31034;&#30340;&#32771;&#34385;&#38598;&#30340;&#27010;&#29575;&#27169;&#22411;&#12290;&#23613;&#31649;&#36825;&#20010;&#20998;&#24067;&#30340;&#25903;&#25345;&#26159;&#25351;&#25968;&#32423;&#22823;&#30340;&#65292;&#20294;&#32473;&#23450;&#21442;&#25968;&#30340;&#32771;&#34385;&#38598;&#30340;&#21518;&#39564;&#20998;&#24067;&#36890;&#24120;&#26159;&#31232;&#30095;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
A standard assumption in the fitting of unordered multinomial response models for J mutually exclusive nominal categories, on cross-sectional or longitudinal data, is that the responses arise from the same set of J categories between subjects. However, when responses measure a choice made by the subject, it is more appropriate to assume that the distribution of multinomial responses is conditioned on a subject-specific consideration set, where this consideration set is drawn from the power set of {1,2,...,J}. Because the cardinality of this power set is exponential in J, estimation is infeasible in general. In this paper, we provide an approach to overcoming this problem. A key step in the approach is a probability model over consideration sets, based on a general representation of probability distributions on contingency tables. Although the support of this distribution is exponentially large, the posterior distribution over consideration sets given parameters is typically sparse, and
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#32452;&#21512;&#35299;&#20915;&#20102;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#35782;&#21035;&#21644;&#20272;&#35745;&#20013;&#30340;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#21644;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2202.07234</link><description>&lt;p&gt;
&#38271;&#26399;&#25345;&#32493;&#28151;&#28102;&#24773;&#20917;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#19982;&#25968;&#25454;&#32452;&#21512;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Long-term Causal Inference Under Persistent Confounding via Data Combination. (arXiv:2202.07234v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.07234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#32452;&#21512;&#35299;&#20915;&#20102;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#35782;&#21035;&#21644;&#20272;&#35745;&#20013;&#30340;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#21644;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#23454;&#39564;&#25968;&#25454;&#21644;&#35266;&#23519;&#25968;&#25454;&#21516;&#26102;&#23384;&#22312;&#26102;&#65292;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#30340;&#35782;&#21035;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#30001;&#20110;&#38271;&#26399;&#32467;&#26524;&#20165;&#22312;&#38271;&#26102;&#38388;&#24310;&#36831;&#21518;&#25165;&#35266;&#23519;&#21040;&#65292;&#22312;&#23454;&#39564;&#25968;&#25454;&#20013;&#26080;&#27861;&#27979;&#37327;&#65292;&#20294;&#22312;&#35266;&#23519;&#25968;&#25454;&#20013;&#26377;&#35760;&#24405;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#37117;&#21253;&#21547;&#23545;&#19968;&#20123;&#30701;&#26399;&#32467;&#26524;&#30340;&#35266;&#23519;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#29420;&#29305;&#22320;&#35299;&#20915;&#20102;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#30340;&#25361;&#25112;&#65292;&#21363;&#19968;&#20123;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#21487;&#20197;&#21516;&#26102;&#24433;&#21709;&#27835;&#30103;&#12289;&#30701;&#26399;&#32467;&#26524;&#21644;&#38271;&#26399;&#32467;&#26524;&#65292;&#32780;&#36825;&#20250;&#20351;&#24471;&#20043;&#21069;&#25991;&#29486;&#20013;&#30340;&#35782;&#21035;&#31574;&#30053;&#26080;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#21033;&#29992;&#22810;&#20010;&#30701;&#26399;&#32467;&#26524;&#30340;&#36830;&#32493;&#32467;&#26500;&#65292;&#20026;&#24179;&#22343;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19977;&#31181;&#23545;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20272;&#35745;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the identification and estimation of long-term treatment effects when both experimental and observational data are available. Since the long-term outcome is observed only after a long delay, it is not measured in the experimental data, but only recorded in the observational data. However, both types of data include observations of some short-term outcomes. In this paper, we uniquely tackle the challenge of persistent unmeasured confounders, i.e., some unmeasured confounders that can simultaneously affect the treatment, short-term outcomes and the long-term outcome, noting that they invalidate identification strategies in previous literature. To address this challenge, we exploit the sequential structure of multiple short-term outcomes, and develop three novel identification strategies for the average long-term treatment effect. We further propose three corresponding estimators and prove their asymptotic consistency and asymptotic normality. We finally apply our methods to esti
&lt;/p&gt;</description></item></channel></rss>