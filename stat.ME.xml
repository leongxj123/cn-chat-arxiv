<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#36890;&#36807;&#20351;&#29992;&#25289;&#32454;&#23391;&#21010;&#20998;&#38598;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#22240;&#23376;&#25968;&#25454;&#20013;&#31283;&#20581;&#22320;&#20272;&#35745;&#24322;&#36136;&#24615;&#65292;&#24182;&#23558;&#22240;&#23376;&#31354;&#38388;&#21010;&#20998;&#25104;&#21327;&#21464;&#37327;&#32452;&#21512;&#30340;&#8220;&#27744;&#8221;&#65292;&#20197;&#20415;&#21306;&#20998;&#32467;&#26524;&#30340;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2404.02141</link><description>&lt;p&gt;
&#20351;&#29992;&#25289;&#32454;&#23391;&#21010;&#20998;&#22312;&#22240;&#23376;&#25968;&#25454;&#20013;&#31283;&#20581;&#20272;&#35745;&#24322;&#36136;&#24615;
&lt;/p&gt;
&lt;p&gt;
Robustly estimating heterogeneity in factorial data using Rashomon Partitions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02141
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#25289;&#32454;&#23391;&#21010;&#20998;&#38598;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#22240;&#23376;&#25968;&#25454;&#20013;&#31283;&#20581;&#22320;&#20272;&#35745;&#24322;&#36136;&#24615;&#65292;&#24182;&#23558;&#22240;&#23376;&#31354;&#38388;&#21010;&#20998;&#25104;&#21327;&#21464;&#37327;&#32452;&#21512;&#30340;&#8220;&#27744;&#8221;&#65292;&#20197;&#20415;&#21306;&#20998;&#32467;&#26524;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#32479;&#35745;&#20998;&#26512;&#65292;&#26080;&#35770;&#26159;&#22312;&#35266;&#27979;&#25968;&#25454;&#36824;&#26159;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#65292;&#37117;&#20250;&#38382;&#65306;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#22914;&#20309;&#38543;&#21487;&#35266;&#23519;&#21327;&#21464;&#37327;&#32452;&#21512;&#21464;&#21270;&#65311;&#19981;&#21516;&#30340;&#33647;&#29289;&#32452;&#21512;&#22914;&#20309;&#24433;&#21709;&#20581;&#24247;&#32467;&#26524;&#65292;&#31185;&#25216;&#37319;&#32435;&#22914;&#20309;&#20381;&#36182;&#28608;&#21169;&#21644;&#20154;&#21475;&#32479;&#35745;&#23398;&#65311;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23558;&#36825;&#20010;&#22240;&#23376;&#31354;&#38388;&#21010;&#20998;&#25104;&#21327;&#21464;&#37327;&#32452;&#21512;&#30340;&#8220;&#27744;&#8221;&#65292;&#22312;&#36825;&#20123;&#27744;&#20013;&#32467;&#26524;&#20250;&#21457;&#29983;&#24046;&#24322;&#65288;&#20294;&#27744;&#20869;&#37096;&#19981;&#20250;&#21457;&#29983;&#65289;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#23547;&#25214;&#19968;&#20010;&#21333;&#19968;&#30340;&#8220;&#26368;&#20248;&#8221;&#20998;&#21106;&#65292;&#35201;&#20040;&#20174;&#21487;&#33021;&#20998;&#21106;&#30340;&#25972;&#20010;&#38598;&#21512;&#20013;&#25277;&#26679;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#24573;&#35270;&#20102;&#36825;&#26679;&#19968;&#20010;&#20107;&#23454;&#65306;&#29305;&#21035;&#26159;&#22312;&#21327;&#21464;&#37327;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#32467;&#26500;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#33021;&#20197;&#35768;&#22810;&#31181;&#26041;&#24335;&#21010;&#20998;&#21327;&#21464;&#37327;&#31354;&#38388;&#65292;&#22312;&#32479;&#35745;&#19978;&#26159;&#26080;&#27861;&#21306;&#20998;&#30340;&#65292;&#23613;&#31649;&#23545;&#25919;&#31574;&#25110;&#31185;&#23398;&#26377;&#30528;&#38750;&#24120;&#19981;&#21516;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#25289;&#32454;&#23391;&#21010;&#20998;&#38598;&#30340;&#26367;&#20195;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02141v1 Announce Type: cross  Abstract: Many statistical analyses, in both observational data and randomized control trials, ask: how does the outcome of interest vary with combinations of observable covariates? How do various drug combinations affect health outcomes, or how does technology adoption depend on incentives and demographics? Our goal is to partition this factorial space into ``pools'' of covariate combinations where the outcome differs across the pools (but not within a pool). Existing approaches (i) search for a single ``optimal'' partition under assumptions about the association between covariates or (ii) sample from the entire set of possible partitions. Both these approaches ignore the reality that, especially with correlation structure in covariates, many ways to partition the covariate space may be statistically indistinguishable, despite very different implications for policy or science. We develop an alternative perspective, called Rashomon Partition Set
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#26469;&#35299;&#20915;&#20851;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#22240;&#26524;&#38382;&#39064;&#65292;&#36890;&#36807;&#28155;&#21152;&#20869;&#37096;&#26495;&#26469;&#25193;&#23637;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#27169;&#22411;&#12290;&#21457;&#29616;&#20998;&#23618;&#25968;&#25454;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#65292;&#21363;&#20351;&#20351;&#29992;&#38750;&#20998;&#23618;&#25968;&#25454;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#24320;&#21457;&#20102;&#29992;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#20272;&#35745;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2401.05330</link><description>&lt;p&gt;
&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Causal Models. (arXiv:2401.05330v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05330
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#26469;&#35299;&#20915;&#20851;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#22240;&#26524;&#38382;&#39064;&#65292;&#36890;&#36807;&#28155;&#21152;&#20869;&#37096;&#26495;&#26469;&#25193;&#23637;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#27169;&#22411;&#12290;&#21457;&#29616;&#20998;&#23618;&#25968;&#25454;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#65292;&#21363;&#20351;&#20351;&#29992;&#38750;&#20998;&#23618;&#25968;&#25454;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#24320;&#21457;&#20102;&#29992;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#20272;&#35745;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#23478;&#20204;&#32463;&#24120;&#24819;&#35201;&#20174;&#20998;&#23618;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#36825;&#20123;&#25968;&#25454;&#26159;&#20174;&#23884;&#22871;&#22312;&#21333;&#20301;&#20869;&#37096;&#30340;&#23376;&#21333;&#20803;&#25910;&#38598;&#30340;&#12290;&#27604;&#22914;&#23398;&#26657;&#20013;&#30340;&#23398;&#29983;&#12289;&#30149;&#20154;&#30340;&#32454;&#32990;&#25110;&#24030;&#20013;&#30340;&#22478;&#24066;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21333;&#20301;&#32423;&#21464;&#37327;&#65288;&#20363;&#22914;&#27599;&#20010;&#23398;&#26657;&#30340;&#39044;&#31639;&#65289;&#21487;&#33021;&#20250;&#24433;&#21709;&#23376;&#21333;&#20301;&#32423;&#21464;&#37327;&#65288;&#20363;&#22914;&#27599;&#20010;&#23398;&#26657;&#27599;&#20010;&#23398;&#29983;&#30340;&#32771;&#35797;&#25104;&#32489;&#65289;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#20026;&#20102;&#35299;&#20915;&#20851;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#22240;&#26524;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#28155;&#21152;&#20869;&#37096;&#26495;&#26469;&#25193;&#23637;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#27169;&#22411;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#30340;&#36890;&#29992;&#22270;&#24418;&#35782;&#21035;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#25193;&#23637;&#20102;do-&#35745;&#31639;&#12290;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#20351;&#29992;&#38750;&#20998;&#23618;&#25968;&#25454;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20998;&#23618;&#25968;&#25454;&#20063;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#22914;&#26524;&#25105;&#20204;&#21482;&#26377;&#23376;&#21333;&#20301;&#32423;&#21464;&#37327;&#30340;&#21333;&#20301;&#32423;&#27719;&#24635;&#65288;&#20363;&#22914;&#23398;&#26657;&#30340;&#24179;&#22343;&#32771;&#35797;&#25104;&#32489;&#65292;&#32780;&#19981;&#26159;&#27599;&#20010;&#23398;&#29983;&#30340;&#25104;&#32489;&#65289;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#29992;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#20272;&#35745;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientists often want to learn about cause and effect from hierarchical data, collected from subunits nested inside units. Consider students in schools, cells in patients, or cities in states. In such settings, unit-level variables (e.g. each school's budget) may affect subunit-level variables (e.g. the test scores of each student in each school) and vice versa. To address causal questions with hierarchical data, we propose hierarchical causal models, which extend structural causal models and causal graphical models by adding inner plates. We develop a general graphical identification technique for hierarchical causal models that extends do-calculus. We find many situations in which hierarchical data can enable causal identification even when it would be impossible with non-hierarchical data, that is, if we had only unit-level summaries of subunit-level variables (e.g. the school's average test score, rather than each student's score). We develop estimation techniques for hierarchical 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#65292;&#20197;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#30446;&#21069;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36827;&#34892;&#29305;&#24449;&#26500;&#24314;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23384;&#22312;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.16297</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#26102;&#21464;&#35843;&#33410;&#22240;&#32032;&#30340;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#20272;&#35745;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Meta-Learning Method for Estimation of Causal Excursion Effects to Assess Time-Varying Moderation. (arXiv:2306.16297v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16297
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#65292;&#20197;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#30446;&#21069;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36827;&#34892;&#29305;&#24449;&#26500;&#24314;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23384;&#22312;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#31359;&#25140;&#25216;&#26415;&#21644;&#26234;&#33021;&#25163;&#26426;&#25552;&#20379;&#30340;&#25968;&#23383;&#21270;&#20581;&#24247;&#24178;&#39044;&#30340;&#21452;&#37325;&#38761;&#21629;&#26174;&#33879;&#22686;&#21152;&#20102;&#31227;&#21160;&#20581;&#24247;&#65288;mHealth&#65289;&#24178;&#39044;&#22312;&#21508;&#20010;&#20581;&#24247;&#31185;&#23398;&#39046;&#22495;&#30340;&#21487;&#21450;&#24615;&#21644;&#37319;&#32435;&#29575;&#12290;&#39034;&#24207;&#38543;&#26426;&#23454;&#39564;&#31216;&#20026;&#24494;&#38543;&#26426;&#35797;&#39564;&#65288;MRTs&#65289;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#29992;&#20110;&#23454;&#35777;&#35780;&#20272;&#36825;&#20123;mHealth&#24178;&#39044;&#32452;&#25104;&#37096;&#20998;&#30340;&#26377;&#25928;&#24615;&#12290;MRTs&#20135;&#29983;&#20102;&#19968;&#31867;&#26032;&#30340;&#22240;&#26524;&#20272;&#35745;&#37327;&#65292;&#31216;&#20026;&#8220;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#8221;&#65292;&#20351;&#20581;&#24247;&#31185;&#23398;&#23478;&#33021;&#22815;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#29992;&#20110;&#20272;&#35745;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#12290;&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#33258;&#21160;&#29305;&#24449;&#26500;&#24314;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23548;&#33268;&#20102;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Twin revolutions in wearable technologies and smartphone-delivered digital health interventions have significantly expanded the accessibility and uptake of mobile health (mHealth) interventions across various health science domains. Sequentially randomized experiments called micro-randomized trials (MRTs) have grown in popularity to empirically evaluate the effectiveness of these mHealth intervention components. MRTs have given rise to a new class of causal estimands known as "causal excursion effects", which enable health scientists to assess how intervention effectiveness changes over time or is moderated by individual characteristics, context, or responses in the past. However, current data analysis methods for estimating causal excursion effects require pre-specified features of the observed high-dimensional history to construct a working model of an important nuisance parameter. While machine learning algorithms are ideal for automatic feature construction, their naive application
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;STEEL&#65292;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#19981;&#20381;&#36182;&#20110;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#36890;&#36807;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.13152</link><description>&lt;p&gt;
STEEL: &#22855;&#24322;&#24615;&#24863;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
STEEL: Singularity-aware Reinforcement Learning. (arXiv:2301.13152v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;STEEL&#65292;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#19981;&#20381;&#36182;&#20110;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#36890;&#36807;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#21033;&#29992;&#39044;&#20808;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#20197;&#26368;&#22823;&#21270;&#26399;&#26395;&#24635;&#22238;&#25253;&#12290;&#28982;&#32780;&#65292;&#20960;&#20046;&#25152;&#26377;&#29616;&#26377;&#31639;&#27861;&#37117;&#20381;&#36182;&#20110;&#30446;&#26631;&#31574;&#30053;&#35825;&#23548;&#30340;&#20998;&#24067;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#20197;&#20415;&#36890;&#36807;&#21464;&#25442;&#27979;&#24230;&#20351;&#29992;&#25209;&#37327;&#25968;&#25454;&#26469;&#26657;&#20934;&#30446;&#26631;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#32477;&#23545;&#36830;&#32493;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#31216;&#36825;&#20010;&#31639;&#27861;&#20026;STEEL&#65306;SingulariTy-awarE rEinforcement Learning&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21463;&#21040;&#20851;&#20110;&#31163;&#32447;&#35780;&#20272;&#30340;&#26032;&#35823;&#24046;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#20102;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#65292;&#20197;&#21450;&#24102;&#26377;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31574;&#30053;&#23450;&#21521;&#35823;&#24046;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#22855;&#24322;&#24773;&#20917;&#30340;&#23450;&#21521;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batch reinforcement learning (RL) aims at leveraging pre-collected data to find an optimal policy that maximizes the expected total rewards in a dynamic environment. Nearly all existing algorithms rely on the absolutely continuous assumption on the distribution induced by target policies with respect to the data distribution, so that the batch data can be used to calibrate target policies via the change of measure. However, the absolute continuity assumption could be violated in practice (e.g., no-overlap support), especially when the state-action space is large or continuous. In this paper, we propose a new batch RL algorithm without requiring absolute continuity in the setting of an infinite-horizon Markov decision process with continuous states and actions. We call our algorithm STEEL: SingulariTy-awarE rEinforcement Learning. Our algorithm is motivated by a new error analysis on off-policy evaluation, where we use maximum mean discrepancy, together with distributionally robust opti
&lt;/p&gt;</description></item></channel></rss>