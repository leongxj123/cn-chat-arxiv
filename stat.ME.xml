<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie &#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20391;&#20449;&#24687;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#22312;&#32771;&#34385;&#20102;&#36741;&#21161;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#27491;&#24577;&#22343;&#20540;&#30340;&#22797;&#21512;&#20272;&#35745;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05883</link><description>&lt;p&gt;
&#20351;&#29992;&#20391;&#20449;&#24687;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#65306;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie &#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Empirical Bayes Estimation with Side Information: A Nonparametric Integrative Tweedie Approach. (arXiv:2308.05883v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie &#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20391;&#20449;&#24687;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#22312;&#32771;&#34385;&#20102;&#36741;&#21161;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#27491;&#24577;&#22343;&#20540;&#30340;&#22797;&#21512;&#20272;&#35745;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32771;&#34385;&#21040;&#20391;&#20449;&#24687;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#27491;&#24577;&#22343;&#20540;&#30340;&#22797;&#21512;&#20272;&#35745;&#38382;&#39064;&#12290;&#21033;&#29992;&#32463;&#39564;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie&#65288;NIT&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#22810;&#21464;&#37327;&#36741;&#21161;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#32467;&#26500;&#30693;&#35782;&#21512;&#24182;&#21040;&#22797;&#21512;&#20272;&#35745;&#30340;&#31934;&#24230;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#20984;&#20248;&#21270;&#24037;&#20855;&#30452;&#25509;&#20272;&#35745;&#23545;&#25968;&#23494;&#24230;&#30340;&#26799;&#24230;&#65292;&#20174;&#32780;&#33021;&#22815;&#23558;&#32467;&#26500;&#32422;&#26463;&#32435;&#20837;&#32771;&#34385;&#12290;&#25105;&#20204;&#23545; NIT &#30340;&#28176;&#36817;&#39118;&#38505;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#30830;&#23450;&#20102; NIT &#25910;&#25947;&#21040; Oracle &#20272;&#35745;&#22120;&#30340;&#36895;&#29575;&#12290;&#38543;&#30528;&#36741;&#21161;&#25968;&#25454;&#30340;&#32500;&#24230;&#22686;&#21152;&#65292;&#25105;&#20204;&#20934;&#30830;&#22320;&#37327;&#21270;&#20102;&#20272;&#35745;&#39118;&#38505;&#30340;&#25913;&#21892;&#20197;&#21450;&#25910;&#25947;&#36895;&#24230;&#30340;&#24694;&#21270;&#12290;&#36890;&#36807;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102; NIT &#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the problem of compound estimation of normal means while accounting for the presence of side information. Leveraging the empirical Bayes framework, we develop a nonparametric integrative Tweedie (NIT) approach that incorporates structural knowledge encoded in multivariate auxiliary data to enhance the precision of compound estimation. Our approach employs convex optimization tools to estimate the gradient of the log-density directly, enabling the incorporation of structural constraints. We conduct theoretical analyses of the asymptotic risk of NIT and establish the rate at which NIT converges to the oracle estimator. As the dimension of the auxiliary data increases, we accurately quantify the improvements in estimation risk and the associated deterioration in convergence rate. The numerical performance of NIT is illustrated through the analysis of both simulated and real data, demonstrating its superiority over existing methods.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25193;&#23637;&#26041;&#27861;&#21644;&#24046;&#24322;&#20989;&#25968;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#30340;&#40065;&#26834;&#24615;&#24378;&#30340;&#35823;&#24046;&#20998;&#24067;&#33258;&#30001;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2002.09377</link><description>&lt;p&gt;
&#39640;&#32500;&#24773;&#24418;&#19979;&#40065;&#26834;&#24615;&#24378;&#30340;&#35823;&#24046;&#20998;&#24067;&#33258;&#30001;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Misspecification-robust likelihood-free inference in high dimensions. (arXiv:2002.09377v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.09377
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25193;&#23637;&#26041;&#27861;&#21644;&#24046;&#24322;&#20989;&#25968;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#30340;&#40065;&#26834;&#24615;&#24378;&#30340;&#35823;&#24046;&#20998;&#24067;&#33258;&#30001;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#22120;&#30340;&#32479;&#35745;&#27169;&#22411;&#30340;&#35823;&#24046;&#20998;&#24067;&#33258;&#30001;&#25512;&#26029;&#24050;&#32463;&#21457;&#23637;&#25104;&#20026;&#23454;&#36341;&#20013;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#22810;&#20010;&#21442;&#25968;&#30340;&#27169;&#22411;&#20173;&#28982;&#26159;&#36924;&#36817;&#36125;&#21494;&#26031;&#35745;&#31639;&#65288;ABC&#65289;&#25512;&#26029;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#20013;&#36827;&#34892;&#35823;&#24046;&#20998;&#24067;&#33258;&#30001;&#25512;&#26029;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25193;&#23637;&#26041;&#27861;&#26469;&#27010;&#29575;&#21270;&#22320;&#36924;&#36817;&#24046;&#24322;&#20989;&#25968;&#65292;&#36825;&#31181;&#26041;&#27861;&#36866;&#21512;&#20110;&#23545;&#21442;&#25968;&#31354;&#38388;&#30340;&#39640;&#25928;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20026;&#27599;&#20010;&#21442;&#25968;&#20351;&#29992;&#21333;&#29420;&#30340;&#37319;&#38598;&#20989;&#25968;&#21644;&#24046;&#24322;&#20989;&#25968;&#26469;&#23454;&#29616;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#30340;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#12290;&#26377;&#25928;&#30340;&#21152;&#24615;&#37319;&#38598;&#32467;&#26500;&#19982;&#25351;&#25968;&#25439;&#22833;-&#20284;&#28982;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#35823;&#24046;&#27169;&#22411;&#35828;&#26126;&#30340;&#40065;&#26834;&#24615;&#24378;&#30340;&#36793;&#38469;&#21518;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Likelihood-free inference for simulator-based statistical models has developed rapidly from its infancy to a useful tool for practitioners. However, models with more than a handful of parameters still generally remain a challenge for the Approximate Bayesian Computation (ABC) based inference. To advance the possibilities for performing likelihood-free inference in higher dimensional parameter spaces, we introduce an extension of the popular Bayesian optimisation based approach to approximate discrepancy functions in a probabilistic manner which lends itself to an efficient exploration of the parameter space. Our approach achieves computational scalability for higher dimensional parameter spaces by using separate acquisition functions and discrepancies for each parameter. The efficient additive acquisition structure is combined with exponentiated loss -likelihood to provide a misspecification-robust characterisation of the marginal posterior distribution for all model parameters. The me
&lt;/p&gt;</description></item></channel></rss>