<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#23545;&#20110;&#22240;&#26524;&#26426;&#21046;&#30340;&#25512;&#26029;&#65292;&#24182;&#25351;&#20986;&#20102;&#23384;&#22312;&#30340;&#25361;&#25112;&#21644;&#23616;&#38480;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.01566</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#21644;&#22240;&#26524;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous Treatment Effects and Causal Mechanisms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01566
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#23545;&#20110;&#22240;&#26524;&#26426;&#21046;&#30340;&#25512;&#26029;&#65292;&#24182;&#25351;&#20986;&#20102;&#23384;&#22312;&#30340;&#25361;&#25112;&#21644;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01566v1 &#20844;&#21578;&#31867;&#22411;:&#26032;&#25688;&#35201;:&#21487;&#20449;&#24230;&#38761;&#21629;&#25512;&#21160;&#20102;&#21033;&#29992;&#30740;&#31350;&#35774;&#35745;&#26469;&#35782;&#21035;&#21644;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#20102;&#35299;&#21738;&#20123;&#26426;&#21046;&#20135;&#29983;&#20102;&#27979;&#37327;&#30340;&#22240;&#26524;&#25928;&#24212;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#30446;&#21069;&#20851;&#20110;&#23450;&#37327;&#35780;&#20272;&#26426;&#21046;&#30340;&#20027;&#35201;&#26041;&#27861;&#20381;&#36182;&#20110;&#26816;&#27979;&#19982;&#22788;&#29702;&#21069;&#21327;&#21464;&#37327;&#30456;&#20851;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#22312;&#20309;&#31181;&#24773;&#20917;&#19979;&#36825;&#31181;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#23384;&#22312;&#33021;&#22815;&#25903;&#25345;&#26377;&#20851;&#26426;&#21046;&#28608;&#27963;&#30340;&#25512;&#26029;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#65292;&#36825;&#31181;&#35774;&#35745;&#22312;&#27809;&#26377;&#39069;&#22806;&#12289;&#36890;&#24120;&#26159;&#38544;&#21547;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#26080;&#27861;&#20026;&#26426;&#21046;&#28608;&#27963;&#25552;&#20379;&#35777;&#25454;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#36825;&#20123;&#20551;&#35774;&#24471;&#21040;&#28385;&#36275;&#65292;&#22914;&#26524;&#19968;&#20010;&#27979;&#37327;&#32467;&#26524;&#26159;&#36890;&#36807;&#30452;&#25509;&#21463;&#24433;&#21709;&#30340;&#24863;&#20852;&#36259;&#29702;&#35770;&#32467;&#26524;&#30340;&#38750;&#32447;&#24615;&#36716;&#25442;&#20135;&#29983;&#30340;&#65292;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#20063;&#19981;&#36275;&#20197;&#25512;&#26029;&#26426;&#21046;&#28608;&#27963;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;n
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01566v1 Announce Type: new  Abstract: The credibility revolution advances the use of research designs that permit identification and estimation of causal effects. However, understanding which mechanisms produce measured causal effects remains a challenge. A dominant current approach to the quantitative evaluation of mechanisms relies on the detection of heterogeneous treatment effects with respect to pre-treatment covariates. This paper develops a framework to understand when the existence of such heterogeneous treatment effects can support inferences about the activation of a mechanism. We show first that this design cannot provide evidence of mechanism activation without additional, generally implicit, assumptions. Further, even when these assumptions are satisfied, if a measured outcome is produced by a non-linear transformation of a directly-affected outcome of theoretical interest, heterogeneous treatment effects are not informative of mechanism activation. We provide n
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.00833</link><description>&lt;p&gt;
&#33258;&#19979;&#32780;&#19978;&#20309;&#26102;&#20987;&#36133;&#33258;&#19978;&#32780;&#19979;&#36827;&#34892;&#20998;&#23618;&#31038;&#21306;&#26816;&#27979;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Bottom-up Beat Top-down in Hierarchical Community Detection?. (arXiv:2306.00833v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#30340;&#20998;&#23618;&#32858;&#31867;&#26159;&#25351;&#26597;&#25214;&#19968;&#32452;&#31038;&#21306;&#30340;&#26641;&#24418;&#32467;&#26500;&#65292;&#20854;&#20013;&#23618;&#27425;&#32467;&#26500;&#30340;&#36739;&#20302;&#32423;&#21035;&#26174;&#31034;&#26356;&#32454;&#31890;&#24230;&#30340;&#31038;&#21306;&#32467;&#26500;&#12290;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#31639;&#27861;&#26377;&#20004;&#20010;&#20027;&#35201;&#31867;&#21035;&#65306;&#33258;&#19978;&#32780;&#19979;&#30340;&#31639;&#27861;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;&#20998;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#36825;&#31181;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24674;&#22797;&#26465;&#20214;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#33258;&#19978;&#32780;&#19979;&#31639;&#27861;&#30340;&#26465;&#20214;&#26469;&#35828;&#65292;&#38480;&#21046;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering of networks consists in finding a tree of communities, such that lower levels of the hierarchy reveal finer-grained community structures. There are two main classes of algorithms tackling this problem. Divisive ($\textit{top-down}$) algorithms recursively partition the nodes into two communities, until a stopping rule indicates that no further split is needed. In contrast, agglomerative ($\textit{bottom-up}$) algorithms first identify the smallest community structure and then repeatedly merge the communities using a $\textit{linkage}$ method. In this article, we establish theoretical guarantees for the recovery of the hierarchical tree and community structure of a Hierarchical Stochastic Block Model by a bottom-up algorithm. We also establish that this bottom-up algorithm attains the information-theoretic threshold for exact recovery at intermediate levels of the hierarchy. Notably, these recovery conditions are less restrictive compared to those existing for to
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2206.02340</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#20135;&#29983;&#20102;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;
&lt;/p&gt;
&lt;p&gt;
Minimising the Expected Posterior Entropy Yields Optimal Summary Statistics. (arXiv:2206.02340v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02340
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#23545;&#20110;&#39640;&#25928;&#65288;&#26080;&#20284;&#28982;&#65289;&#25512;&#26029;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#31867;&#21035;&#30340;&#25688;&#35201;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#23545;&#20110;&#27491;&#30830;&#20998;&#26512;&#38477;&#32500;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#22312;&#27169;&#22411;&#30340;&#20808;&#39564;&#39044;&#27979;&#20998;&#24067;&#19979;&#26368;&#23567;&#21270;&#26399;&#26395;&#21518;&#39564;&#29109;&#65288;EPE&#65289;&#26469;&#33719;&#21462;&#25688;&#35201;&#12290;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#31561;&#25928;&#20110;&#25110;&#26159;&#26368;&#23567;&#21270;EPE&#30340;&#29305;&#27530;&#25110;&#26497;&#38480;&#24773;&#20917;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#33719;&#21462;&#26368;&#23567;&#21270;EPE&#30340;&#39640;&#20445;&#30495;&#25688;&#35201;&#65307;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#22522;&#20934;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#26082;&#25552;&#20379;&#20102;&#33719;&#21462;&#26377;&#25928;&#25688;&#35201;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#21448;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#20855;&#20307;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extracting low-dimensional summary statistics from large datasets is essential for efficient (likelihood-free) inference. We characterise different classes of summaries and demonstrate their importance for correctly analysing dimensionality reduction algorithms. We propose obtaining summaries by minimising the expected posterior entropy (EPE) under the prior predictive distribution of the model. Many existing methods are equivalent to or are special or limiting cases of minimising the EPE. We develop a method to obtain high-fidelity summaries that minimise the EPE; we apply it to benchmark and real-world examples. We both offer a unifying perspective for obtaining informative summaries and provide concrete recommendations for practitioners.
&lt;/p&gt;</description></item></channel></rss>