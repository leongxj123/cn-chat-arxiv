<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39640;&#25928;&#30340;&#22240;&#26524;&#22270;&#21457;&#29616;&#65292;&#37319;&#29992;&#20102;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#32447;&#24615;&#25968;&#37327;&#30340;&#26597;&#35810;&#65292;&#21516;&#26102;&#33021;&#36731;&#26494;&#32467;&#21512;&#35266;&#23519;&#25968;&#25454;&#20197;&#25552;&#39640;&#24615;&#33021;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#25968;&#25454;&#25928;&#29575;&#65292;&#24182;&#22312;&#30495;&#23454;&#22240;&#26524;&#22270;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#28508;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01207</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39640;&#25928;&#22240;&#26524;&#22270;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Efficient Causal Graph Discovery Using Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01207
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39640;&#25928;&#30340;&#22240;&#26524;&#22270;&#21457;&#29616;&#65292;&#37319;&#29992;&#20102;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#32447;&#24615;&#25968;&#37327;&#30340;&#26597;&#35810;&#65292;&#21516;&#26102;&#33021;&#36731;&#26494;&#32467;&#21512;&#35266;&#23519;&#25968;&#25454;&#20197;&#25552;&#39640;&#24615;&#33021;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#25968;&#25454;&#25928;&#29575;&#65292;&#24182;&#22312;&#30495;&#23454;&#22240;&#26524;&#22270;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;LLMs&#36827;&#34892;&#23436;&#25972;&#30340;&#22240;&#26524;&#22270;&#21457;&#29616;&#12290;&#20043;&#21069;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#37319;&#29992;&#20102;&#25104;&#23545;&#26597;&#35810;&#30340;&#26041;&#27861;&#65292;&#20294;&#36825;&#38656;&#35201;&#20108;&#27425;&#26597;&#35810;&#30340;&#25968;&#37327;&#65292;&#23545;&#20110;&#36739;&#22823;&#30340;&#22240;&#26524;&#22270;&#26469;&#35828;&#24456;&#24555;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#30456;&#21453;&#65292;&#25552;&#20986;&#30340;&#26694;&#26550;&#37319;&#29992;&#20102;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#65288;BFS&#65289;&#30340;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#32447;&#24615;&#25968;&#37327;&#30340;&#26597;&#35810;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#24403;&#26377;&#25152;&#35266;&#23519;&#25968;&#25454;&#21487;&#29992;&#26102;&#65292;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#22320;&#36827;&#34892;&#32467;&#21512;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#38500;&#20102;&#26356;&#20855;&#26102;&#38388;&#21644;&#25968;&#25454;&#25928;&#29575;&#22806;&#65292;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#19981;&#21516;&#22823;&#23567;&#30340;&#30495;&#23454;&#22240;&#26524;&#22270;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#32467;&#26524;&#35777;&#26126;&#20102;&#25552;&#20986;&#26041;&#27861;&#22312;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#22240;&#26524;&#22270;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework that leverages LLMs for full causal graph discovery. While previous LLM-based methods have used a pairwise query approach, this requires a quadratic number of queries which quickly becomes impractical for larger causal graphs. In contrast, the proposed framework uses a breadth-first search (BFS) approach which allows it to use only a linear number of queries. We also show that the proposed method can easily incorporate observational data when available, to improve performance. In addition to being more time and data-efficient, the proposed framework achieves state-of-the-art results on real-world causal graphs of varying sizes. The results demonstrate the effectiveness and efficiency of the proposed method in discovering causal relationships, showcasing its potential for broad applicability in causal graph discovery tasks across different domains.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;&#65292;&#24182;&#22312;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#26041;&#38754;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.03058</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#25552;&#21319;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Machine Learning Assisted Adjustment Boosts Inferential Efficiency of Randomized Controlled Trials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03058
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;&#65292;&#24182;&#22312;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#26041;&#38754;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#37319;&#29992;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#35843;&#25972;&#26041;&#27861;&#65292;&#29992;&#20110;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#12290;&#35813;&#26041;&#27861;&#26159;&#22312;&#32599;&#26862;&#40077;&#22982;&#30340;&#22522;&#20110;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#38543;&#26426;&#23454;&#39564;&#30340;&#30830;&#20999;&#26816;&#39564;&#26694;&#26550;&#19979;&#24320;&#21457;&#30340;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#27169;&#25311;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#31283;&#20581;&#22320;&#25511;&#21046;&#31532;&#19968;&#31867;&#38169;&#35823;&#65292;&#24182;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;(RCT)&#30340;&#25512;&#26029;&#25928;&#29575;&#12290;&#36825;&#19968;&#20248;&#21183;&#22312;&#19968;&#20010;&#30495;&#23454;&#26696;&#20363;&#20013;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#31616;&#21333;&#24615;&#21644;&#31283;&#20581;&#24615;&#20351;&#20854;&#25104;&#20026;&#19968;&#31181;&#31454;&#20105;&#24615;&#20505;&#36873;&#20316;&#20026;RCT&#30340;&#24120;&#35268;&#25512;&#26029;&#31243;&#24207;&#65292;&#29305;&#21035;&#26159;&#24403;&#22522;&#32447;&#21327;&#21464;&#37327;&#30340;&#25968;&#37327;&#36739;&#22810;&#65292;&#19988;&#39044;&#35745;&#23384;&#22312;&#38750;&#32447;&#24615;&#20851;&#32852;&#25110;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#26102;&#12290;&#20854;&#24212;&#29992;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;RCT&#30340;&#25152;&#38656;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#65292;&#20363;&#22914;&#19977;&#26399;&#20020;&#24202;&#35797;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03058v1 Announce Type: cross  Abstract: In this work, we proposed a novel inferential procedure assisted by machine learning based adjustment for randomized control trials. The method was developed under the Rosenbaum's framework of exact tests in randomized experiments with covariate adjustments. Through extensive simulation experiments, we showed the proposed method can robustly control the type I error and can boost the inference efficiency for a randomized controlled trial (RCT). This advantage was further demonstrated in a real world example. The simplicity and robustness of the proposed method makes it a competitive candidate as a routine inference procedure for RCTs, especially when the number of baseline covariates is large, and when nonlinear association or interaction among covariates is expected. Its application may remarkably reduce the required sample size and cost of RCTs, such as phase III clinical trials.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#20849;&#21516;&#21407;&#22240;$C$&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#65292;&#35299;&#20915;&#20102;&#36763;&#26222;&#26862;&#24726;&#35770;&#65292;&#25512;&#24191;&#20102;&#24726;&#35770;&#65292;&#24182;&#34920;&#26126;&#22312;&#20108;&#20803;&#20849;&#21516;&#21407;&#22240;$C$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30340;&#20851;&#32852;&#26041;&#21521;&#19982;&#21407;&#22987;$B$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30456;&#21516;</title><link>https://arxiv.org/abs/2403.00957</link><description>&lt;p&gt;
&#21033;&#29992;&#20849;&#22240;&#21407;&#21017;&#35299;&#20915;&#36763;&#26222;&#26862;&#24726;&#35770;
&lt;/p&gt;
&lt;p&gt;
Resolution of Simpson's paradox via the common cause principle
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00957
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#20849;&#21516;&#21407;&#22240;$C$&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#65292;&#35299;&#20915;&#20102;&#36763;&#26222;&#26862;&#24726;&#35770;&#65292;&#25512;&#24191;&#20102;&#24726;&#35770;&#65292;&#24182;&#34920;&#26126;&#22312;&#20108;&#20803;&#20849;&#21516;&#21407;&#22240;$C$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30340;&#20851;&#32852;&#26041;&#21521;&#19982;&#21407;&#22987;$B$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30456;&#21516;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36763;&#26222;&#26862;&#24726;&#35770;&#26159;&#24314;&#31435;&#20004;&#20010;&#20107;&#20214;$a_1$&#21644;$a_2$&#20043;&#38388;&#30340;&#27010;&#29575;&#20851;&#32852;&#26102;&#30340;&#38556;&#30861;&#65292;&#32473;&#23450;&#31532;&#19977;&#20010;&#65288;&#28508;&#22312;&#30340;&#65289;&#38543;&#26426;&#21464;&#37327;$B$&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#24773;&#26223;&#26159;&#38543;&#26426;&#21464;&#37327;$A$&#65288;&#27719;&#24635;&#20102;$a_1$&#12289;$a_2$&#21450;&#20854;&#34917;&#38598;&#65289;&#21644;$B$&#26377;&#19968;&#20010;&#21487;&#33021;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#20849;&#21516;&#21407;&#22240;$C$&#12290;&#25110;&#32773;&#65292;&#25105;&#20204;&#21487;&#20197;&#20551;&#35774;$C$&#23558;$A$&#20174;$B$&#20013;&#31579;&#36873;&#20986;&#21435;&#12290;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#27491;&#30830;&#30340;$a_1$&#21644;$a_2$&#20043;&#38388;&#30340;&#20851;&#32852;&#24212;&#35813;&#36890;&#36807;&#23545;$C$&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#26469;&#23450;&#20041;&#12290;&#36825;&#19968;&#35774;&#32622;&#23558;&#21407;&#22987;&#36763;&#26222;&#26862;&#24726;&#35770;&#25512;&#24191;&#20102;&#12290;&#29616;&#22312;&#23427;&#30340;&#20004;&#20010;&#30456;&#20114;&#30683;&#30462;&#30340;&#36873;&#39033;&#31616;&#21333;&#22320;&#25351;&#30340;&#26159;&#20004;&#20010;&#29305;&#23450;&#19988;&#19981;&#21516;&#30340;&#21407;&#22240;$C$&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;$B$&#21644;$C$&#26159;&#20108;&#36827;&#21046;&#30340;&#65292;$A$&#26159;&#22235;&#36827;&#21046;&#30340;&#65288;&#23545;&#20110;&#26377;&#25928;&#30340;&#36763;&#26222;&#26862;&#24726;&#35770;&#26469;&#35828;&#26159;&#26368;&#23567;&#19988;&#26368;&#24120;&#35265;&#30340;&#24773;&#20917;&#65289;&#65292;&#22312;&#20219;&#20309;&#20108;&#20803;&#20849;&#21516;&#21407;&#22240;$C$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#23558;&#24314;&#31435;&#19982;&#22312;&#21407;&#22987;$B$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30456;&#21516;&#30340;$a_1$&#21644;$a_2$&#20043;&#38388;&#30340;&#20851;&#32852;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00957v1 Announce Type: cross  Abstract: Simpson's paradox is an obstacle to establishing a probabilistic association between two events $a_1$ and $a_2$, given the third (lurking) random variable $B$. We focus on scenarios when the random variables $A$ (which combines $a_1$, $a_2$, and their complements) and $B$ have a common cause $C$ that need not be observed. Alternatively, we can assume that $C$ screens out $A$ from $B$. For such cases, the correct association between $a_1$ and $a_2$ is to be defined via conditioning over $C$. This set-up generalizes the original Simpson's paradox. Now its two contradicting options simply refer to two particular and different causes $C$. We show that if $B$ and $C$ are binary and $A$ is quaternary (the minimal and the most widespread situation for valid Simpson's paradox), the conditioning over any binary common cause $C$ establishes the same direction of the association between $a_1$ and $a_2$ as the conditioning over $B$ in the original
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#20272;&#35745;&#33258;&#22238;&#24402;&#27169;&#22411;&#26102;&#24341;&#20837;&#28508;&#22312;&#38750;&#24179;&#31283;&#22238;&#24402;&#21464;&#37327;&#30340;&#26435;&#37325;&#65292;&#33719;&#24471;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#36825;&#31181;&#26041;&#27861;&#22312;&#26816;&#27979;&#24179;&#31283;&#24615;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.16580</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;Lasso&#36873;&#25321;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#20449;&#24687;&#22686;&#24378;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Information-Enriched Selection of Stationary and Non-Stationary Autoregressions using the Adaptive Lasso
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16580
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#20272;&#35745;&#33258;&#22238;&#24402;&#27169;&#22411;&#26102;&#24341;&#20837;&#28508;&#22312;&#38750;&#24179;&#31283;&#22238;&#24402;&#21464;&#37327;&#30340;&#26435;&#37325;&#65292;&#33719;&#24471;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#36825;&#31181;&#26041;&#27861;&#22312;&#26816;&#27979;&#24179;&#31283;&#24615;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;Lasso&#65292;&#22312;&#19968;&#33268;&#21644;&#22885;&#25289;&#20811;&#23572;&#25928;&#29575;&#20272;&#35745;&#33258;&#22238;&#24402;&#27169;&#22411;&#26102;&#24341;&#20837;&#19968;&#20010;&#28508;&#22312;&#38750;&#24179;&#31283;&#22238;&#24402;&#21464;&#37327;&#30340;&#26435;&#37325;&#12290;&#22686;&#24378;&#30340;&#26435;&#37325;&#24314;&#31435;&#22312;&#19968;&#20010;&#32479;&#35745;&#37327;&#19978;&#65292;&#35813;&#32479;&#35745;&#37327;&#21033;&#29992;OLS&#20272;&#35745;&#22120;&#22312;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#20013;&#30340;&#27010;&#29575;&#39034;&#24207;&#19981;&#21516;&#30340;&#29305;&#28857;&#65292;&#24403;&#31215;&#20998;&#31243;&#24230;&#19981;&#21516;&#26102;&#12290;&#25105;&#20204;&#22312;&#36873;&#25321;$\ell_1$&#24809;&#32602;&#21442;&#25968;&#26102;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26816;&#27979;&#24179;&#31283;&#24615;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#25552;&#35758;&#20248;&#20110;&#20351;&#29992;OLS&#22522;&#30784;&#26435;&#37325;&#65292;&#27491;&#22914;Kock&#24314;&#35758;&#30340;&#37027;&#26679;&#12290;&#25105;&#20204;&#23558;&#20462;&#25913;&#21518;&#30340;&#20272;&#35745;&#22120;&#24212;&#29992;&#20110;&#27431;&#20803;&#25512;&#20986;&#21518;&#24503;&#22269;&#36890;&#36135;&#33192;&#32960;&#29575;&#30340;&#27169;&#22411;&#36873;&#25321;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#33021;&#28304;&#21830;&#21697;&#20215;&#26684;&#36890;&#36135;&#33192;&#32960;&#21644;&#25972;&#20307;&#36890;&#36135;&#33192;&#32960;&#26368;&#22909;&#30001;&#24179;&#31283;&#33258;&#22238;&#24402;&#27169;&#22411;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16580v1 Announce Type: cross  Abstract: We propose a novel approach to elicit the weight of a potentially non-stationary regressor in the consistent and oracle-efficient estimation of autoregressive models using the adaptive Lasso. The enhanced weight builds on a statistic that exploits distinct orders in probability of the OLS estimator in time series regressions when the degree of integration differs. We provide theoretical results on the benefit of our approach for detecting stationarity when a tuning criterion selects the $\ell_1$ penalty parameter. Monte Carlo evidence shows that our proposal is superior to using OLS-based weights, as suggested by Kock [Econom. Theory, 32, 2016, 243-259]. We apply the modified estimator to model selection for German inflation rates after the introduction of the Euro. The results indicate that energy commodity price inflation and headline inflation are best described by stationary autoregressions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#35782;&#21035;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#33268;&#24615;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2203.06056</link><description>&lt;p&gt;
&#20351;&#29992;&#24037;&#20855;&#26102;&#38388;&#24207;&#21015;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#65306;&#26080;&#20851; IV &#21644;&#32416;&#27491;&#21382;&#21490;
&lt;/p&gt;
&lt;p&gt;
Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.06056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#35782;&#21035;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#33268;&#24615;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20202;&#22120;&#21464;&#37327;&#65288;IV&#65289;&#22238;&#24402;&#20381;&#36182;&#20110;&#24037;&#20855;&#26469;&#25512;&#26029;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#20854;&#20013;&#23384;&#22312;&#26410;&#35266;&#27979;&#30340;&#28151;&#28102;&#22240;&#32032;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#65292;&#20363;&#22914;&#30690;&#37327;&#33258;&#22238;&#24402;&#65288;VAR&#65289;&#36807;&#31243;&#12290;&#30452;&#25509;&#24212;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#25216;&#26415;&#36890;&#24120;&#19981;&#19968;&#33268;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#33021;&#27491;&#30830;&#35843;&#25972;&#36807;&#21435;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#30001;&#20110;&#26102;&#38388;&#32467;&#26500;&#32780;&#24341;&#36215;&#30340;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#26500;&#24314;&#21487;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#19968;&#33268;&#21442;&#25968;&#20272;&#35745;&#30340;&#30830;&#35748;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#19968;&#31181;&#26041;&#27861;&#20351;&#29992;&#39069;&#22806;&#30340;&#26080;&#20851;&#21327;&#21464;&#37327;&#26469;&#33719;&#24471;&#21487;&#35782;&#21035;&#24615;&#65288;&#21363;&#20351;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#24773;&#20917;&#19979;&#20063;&#26159;&#26377;&#36259;&#30340;&#24819;&#27861;&#65289;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#22270;&#36793;&#32536;&#21270;&#26694;&#26550;&#65292;&#20801;&#35768;&#25105;&#20204;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#23545;&#26102;&#38388;&#24207;&#21015;&#24212;&#29992;&#26080;&#20851; IV &#21644;&#20854;&#20182; IV &#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#20840;&#23616;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#30340;&#19968;&#20010;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.06056v2 Announce Type: replace-cross  Abstract: Instrumental variable (IV) regression relies on instruments to infer causal effects from observational data with unobserved confounding. We consider IV regression in time series models, such as vector auto-regressive (VAR) processes. Direct applications of i.i.d. techniques are generally inconsistent as they do not correctly adjust for dependencies in the past. In this paper, we outline the difficulties that arise due to time structure and propose methodology for constructing identifying equations that can be used for consistent parametric estimation of causal effects in time series data. One method uses extra nuisance covariates to obtain identifiability (an idea that can be of interest even in the i.i.d. case). We further propose a graph marginalization framework that allows us to apply nuisance IV and other IV methods in a principled way to time series. Our methods make use of a version of the global Markov property, which w
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#65292;&#36827;&#34892;&#27169;&#22411;&#25490;&#24207;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20854;&#20182;&#31639;&#27861;&#30340;&#27604;&#36739;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.16943</link><description>&lt;p&gt;
&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#20013;&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Dynamical System Identification, Model Selection and Model Uncertainty Quantification by Bayesian Inference. (arXiv:2401.16943v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#65292;&#36827;&#34892;&#27169;&#22411;&#25490;&#24207;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20854;&#20182;&#31639;&#27861;&#30340;&#27604;&#36739;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575; (MAP) &#26694;&#26550;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#24674;&#22797;&#31995;&#32479;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31561;&#20215;&#20110;&#24191;&#20041;&#30340;&#38646;&#38454; Tikhonov &#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36127;&#23545;&#25968;&#20284;&#28982;&#21644;&#20808;&#39564;&#20998;&#24067;&#26469;&#21512;&#29702;&#36873;&#25321;&#27531;&#24046;&#21644;&#27491;&#21017;&#21270;&#39033;&#12290;&#38500;&#20102;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#22806;&#65292;&#36125;&#21494;&#26031;&#35299;&#37322;&#36824;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#24037;&#20855;&#65292;&#21253;&#25324;&#27169;&#22411;&#25490;&#24207;&#12289;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#24102;&#26377;&#22122;&#22768;&#30340;&#20960;&#20010;&#21160;&#21147;&#31995;&#32479;&#65292;&#27604;&#36739;&#20102;&#20004;&#31181;&#36125;&#21494;&#26031;&#31639;&#27861;&#65292;&#21363;&#32852;&#21512;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575; (JMAP) &#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#36817;&#20284; (VBA)&#65292;&#19982;&#27969;&#34892;&#30340;&#38408;&#20540;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#31639;&#27861;SINDy&#12290;&#23545;&#20110;&#22810;&#20803;&#39640;&#26031;&#20284;&#28982;&#21644;&#20808;&#39564;&#20998;&#24067;&#65292;
&lt;/p&gt;
&lt;p&gt;
This study presents a Bayesian maximum \textit{a~posteriori} (MAP) framework for dynamical system identification from time-series data. This is shown to be equivalent to a generalized zeroth-order Tikhonov regularization, providing a rational justification for the choice of the residual and regularization terms, respectively, from the negative logarithms of the likelihood and prior distributions. In addition to the estimation of model coefficients, the Bayesian interpretation gives access to the full apparatus for Bayesian inference, including the ranking of models, the quantification of model uncertainties and the estimation of unknown (nuisance) hyperparameters. Two Bayesian algorithms, joint maximum \textit{a~posteriori} (JMAP) and variational Bayesian approximation (VBA), are compared to the popular SINDy algorithm for thresholded least-squares regression, by application to several dynamical systems with added noise. For multivariate Gaussian likelihood and prior distributions, the
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.00127</link><description>&lt;p&gt;
&#39640;&#32500;&#36125;&#21494;&#26031;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Bayesian Structure Learning in Gaussian Graphical Models using Marginal Pseudo-Likelihood. (arXiv:2307.00127v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00127
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#22270;&#27169;&#22411;&#20197;&#22270;&#24418;&#24418;&#24335;&#25551;&#32472;&#20102;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#12290;&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#26469;&#24212;&#23545;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#22312;&#26631;&#20934;&#35745;&#31639;&#26426;&#19978;&#22312;&#20960;&#20998;&#38047;&#20869;&#24555;&#36895;&#29983;&#25104;&#23545;&#21253;&#21547;1000&#20010;&#21464;&#37327;&#30340;&#38382;&#39064;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#23545;&#20110;&#23545;&#23454;&#38469;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#20154;&#65292;&#25903;&#25345;&#36825;&#31181;&#26032;&#26041;&#27861;&#30340;&#20195;&#30721;&#36890;&#36807;R&#36719;&#20214;&#21253;BDgraph&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian graphical models depict the conditional dependencies between variables within a multivariate normal distribution in a graphical format. The identification of these graph structures is an area known as structure learning. However, when utilizing Bayesian methodologies in structure learning, computational complexities can arise, especially with high-dimensional graphs surpassing 250 nodes. This paper introduces two innovative search algorithms that employ marginal pseudo-likelihood to address this computational challenge. These methods can swiftly generate reliable estimations for problems encompassing 1000 variables in just a few minutes on standard computers. For those interested in practical applications, the code supporting this new approach is made available through the R package BDgraph.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26679;&#26412;&#20998;&#23618;&#23454;&#39564;&#20013;&#30340;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#20998;&#23618;&#35774;&#35745;&#65292;&#20256;&#32479;&#22238;&#24402;&#20272;&#35745;&#37327;&#36890;&#24120;&#26159;&#20302;&#25928;&#30340;&#12290;&#26681;&#25454;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#38024;&#23545;&#32473;&#23450;&#20998;&#23618;&#30340;&#28176;&#36817;&#26368;&#20248;&#32447;&#24615;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#24182;&#26500;&#24314;&#20102;&#20960;&#20010;&#21487;&#34892;&#30340;&#22823;&#26679;&#26412;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2302.03687</link><description>&lt;p&gt;
&#26679;&#26412;&#20998;&#23618;&#23454;&#39564;&#20013;&#30340;&#21327;&#21464;&#37327;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Covariate Adjustment in Stratified Experiments. (arXiv:2302.03687v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26679;&#26412;&#20998;&#23618;&#23454;&#39564;&#20013;&#30340;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#20998;&#23618;&#35774;&#35745;&#65292;&#20256;&#32479;&#22238;&#24402;&#20272;&#35745;&#37327;&#36890;&#24120;&#26159;&#20302;&#25928;&#30340;&#12290;&#26681;&#25454;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#38024;&#23545;&#32473;&#23450;&#20998;&#23618;&#30340;&#28176;&#36817;&#26368;&#20248;&#32447;&#24615;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#24182;&#26500;&#24314;&#20102;&#20960;&#20010;&#21487;&#34892;&#30340;&#22823;&#26679;&#26412;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26679;&#26412;&#20998;&#23618;&#23454;&#39564;&#20013;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#36827;&#34892;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#20013;&#24037;&#20316;&#65292;&#21253;&#25324;&#21305;&#37197;&#20803;&#32452;&#35774;&#35745;&#12289;&#31895;&#20998;&#23618;&#35774;&#35745;&#21644;&#23436;&#20840;&#38543;&#26426;&#21270;&#35774;&#35745;&#20316;&#20026;&#29305;&#20363;&#12290;&#24050;&#30693;&#23545;&#20110;&#23436;&#20840;&#38543;&#26426;&#21270;&#35774;&#35745;&#65292;&#21327;&#21464;&#37327;&#35843;&#25972;&#19982;&#22788;&#29702;-&#21327;&#21464;&#37327;&#20132;&#20114;&#39033;&#21487;&#20197;&#24369;&#21270;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#20998;&#23618;&#35774;&#35745;&#65292;&#36825;&#31181;&#22238;&#24402;&#20272;&#35745;&#37327;&#36890;&#24120;&#26159;&#20302;&#25928;&#30340;&#65292;&#29978;&#33267;&#21487;&#33021;&#30456;&#23545;&#20110;&#26410;&#35843;&#25972;&#30340;&#22522;&#20934;&#20272;&#35745;&#37327;&#22686;&#21152;&#20272;&#35745;&#26041;&#24046;&#12290;&#22312;&#27492;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#38024;&#23545;&#32473;&#23450;&#20998;&#23618;&#30340;&#28176;&#36817;&#26368;&#20248;&#32447;&#24615;&#21327;&#21464;&#37327;&#35843;&#25972;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20960;&#20010;&#21487;&#34892;&#30340;&#20272;&#35745;&#22120;&#65292;&#20197;&#20351;&#22823;&#26679;&#26412;&#20013;&#23454;&#29616;&#36825;&#31181;&#39640;&#25928;&#35843;&#25972;&#12290;&#20363;&#22914;&#65292;&#22312;&#21305;&#37197;&#23545;&#30340;&#29305;&#20363;&#20013;&#65292;&#21253;&#25324;&#22788;&#29702;&#12289;&#21327;&#21464;&#37327;&#21644;&#23545;&#22266;&#23450;&#25928;&#24212;&#30340;&#22238;&#24402;&#22312;&#28176;&#36817;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#28176;&#36817;&#31934;&#30830;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies covariate adjusted estimation of the average treatment effect in stratified experiments. We work in a general framework that includes matched tuples designs, coarse stratification, and complete randomization as special cases. Regression adjustment with treatment-covariate interactions is known to weakly improve efficiency for completely randomized designs. By contrast, we show that for stratified designs such regression estimators are generically inefficient, potentially even increasing estimator variance relative to the unadjusted benchmark. Motivated by this result, we derive the asymptotically optimal linear covariate adjustment for a given stratification. We construct several feasible estimators that implement this efficient adjustment in large samples. In the special case of matched pairs, for example, the regression including treatment, covariates, and pair fixed effects is asymptotically optimal. We also provide novel asymptotically exact inference methods tha
&lt;/p&gt;</description></item></channel></rss>