<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#38169;&#37197;&#30340;Copula&#27169;&#22411;&#20013;&#38480;&#21046;&#21453;&#39304;&#30340;&#21098;&#20999;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#21482;&#26377;&#19968;&#20010;&#27169;&#22359;&#38169;&#37197;&#30340;&#24773;&#20917;&#19979;&#65292;&#36866;&#24403;&#30340;&#21098;&#20999;&#21518;&#39564;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.03521</link><description>&lt;p&gt;
&#22312;&#38169;&#37197;&#30340;Copula&#27169;&#22411;&#20013;&#38480;&#21046;&#21453;&#39304;&#30340;&#21098;&#20999;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Cutting Feedback in Misspecified Copula Models. (arXiv:2310.03521v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03521
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#38169;&#37197;&#30340;Copula&#27169;&#22411;&#20013;&#38480;&#21046;&#21453;&#39304;&#30340;&#21098;&#20999;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#21482;&#26377;&#19968;&#20010;&#27169;&#22359;&#38169;&#37197;&#30340;&#24773;&#20917;&#19979;&#65292;&#36866;&#24403;&#30340;&#21098;&#20999;&#21518;&#39564;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;Copula&#27169;&#22411;&#20013;&#65292;&#36793;&#32536;&#20998;&#24067;&#21644;Copula&#20989;&#25968;&#34987;&#20998;&#21035;&#25351;&#23450;&#12290;&#25105;&#20204;&#23558;&#23427;&#20204;&#35270;&#20026;&#27169;&#22359;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#26694;&#26550;&#20013;&#30340;&#20004;&#20010;&#27169;&#22359;&#65292;&#24182;&#25552;&#20986;&#36890;&#36807;&#8220;&#21098;&#20999;&#21453;&#39304;&#8221;&#36827;&#34892;&#20462;&#25913;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;&#21098;&#20999;&#21453;&#39304;&#38480;&#21046;&#20102;&#21518;&#39564;&#25512;&#26029;&#20013;&#28508;&#22312;&#38169;&#37197;&#27169;&#22359;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#32771;&#34385;&#20004;&#31181;&#31867;&#22411;&#30340;&#21098;&#20999;&#26041;&#27861;&#12290;&#31532;&#19968;&#31181;&#38480;&#21046;&#20102;&#38169;&#37197;Copula&#23545;&#36793;&#32536;&#25512;&#26029;&#30340;&#24433;&#21709;&#65292;&#36825;&#26159;&#27969;&#34892;&#30340;&#36793;&#38469;&#25512;&#26029;&#65288;IFM&#65289;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#31867;&#20284;&#26041;&#27861;&#12290;&#31532;&#20108;&#31181;&#36890;&#36807;&#20351;&#29992;&#31209;&#20284;&#28982;&#23450;&#20041;&#21098;&#20999;&#27169;&#22411;&#26469;&#38480;&#21046;&#38169;&#37197;&#36793;&#32536;&#23545;Copula&#21442;&#25968;&#25512;&#26029;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#21482;&#26377;&#19968;&#20010;&#27169;&#22359;&#38169;&#37197;&#65292;&#37027;&#20040;&#36866;&#24403;&#30340;&#21098;&#20999;&#21518;&#39564;&#22312;&#21478;&#19968;&#20010;&#27169;&#22359;&#30340;&#21442;&#25968;&#30340;&#28176;&#36817;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#26159;&#20934;&#30830;&#30340;&#12290;&#35745;&#31639;&#21098;&#20999;&#21518;&#39564;&#24456;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In copula models the marginal distributions and copula function are specified separately. We treat these as two modules in a modular Bayesian inference framework, and propose conducting modified Bayesian inference by ``cutting feedback''. Cutting feedback limits the influence of potentially misspecified modules in posterior inference. We consider two types of cuts. The first limits the influence of a misspecified copula on inference for the marginals, which is a Bayesian analogue of the popular Inference for Margins (IFM) estimator. The second limits the influence of misspecified marginals on inference for the copula parameters by using a rank likelihood to define the cut model. We establish that if only one of the modules is misspecified, then the appropriate cut posterior gives accurate uncertainty quantification asymptotically for the parameters in the other module. Computation of the cut posteriors is difficult, and new variational inference methods to do so are proposed. The effic
&lt;/p&gt;</description></item><item><title>&#22312;&#22823;&#22411;&#36817;&#20284;&#22240;&#23376;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20027;&#25104;&#20998;&#20272;&#35745;&#30340;&#22240;&#23376;&#36733;&#33655;&#19982;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#36733;&#33655;&#31561;&#20215;&#65292;&#21516;&#26102;&#36825;&#20004;&#31181;&#20272;&#35745;&#20063;&#19982;&#19981;&#21487;&#34892;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#36733;&#33655;&#31561;&#20215;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#19982;&#19981;&#21487;&#34892;&#26368;&#23567;&#20108;&#20056;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#31561;&#20215;&#65292;&#20174;&#32780;&#21487;&#20197;&#31616;&#21270;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#20272;&#35745;&#36807;&#31243;&#12290;&#25152;&#26377;&#32467;&#26524;&#37117;&#36866;&#29992;&#20110;&#20551;&#35774;&#24322;&#26041;&#24046;&#36328;&#25130;&#38754;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2307.09864</link><description>&lt;p&gt;
&#22823;&#22411;&#36817;&#20284;&#22240;&#23376;&#27169;&#22411;&#20013;&#20027;&#25104;&#20998;&#21644;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#31561;&#20215;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Asymptotic equivalence of Principal Component and Quasi Maximum Likelihood estimators in Large Approximate Factor Models. (arXiv:2307.09864v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09864
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#36817;&#20284;&#22240;&#23376;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20027;&#25104;&#20998;&#20272;&#35745;&#30340;&#22240;&#23376;&#36733;&#33655;&#19982;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#36733;&#33655;&#31561;&#20215;&#65292;&#21516;&#26102;&#36825;&#20004;&#31181;&#20272;&#35745;&#20063;&#19982;&#19981;&#21487;&#34892;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#36733;&#33655;&#31561;&#20215;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#19982;&#19981;&#21487;&#34892;&#26368;&#23567;&#20108;&#20056;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#31561;&#20215;&#65292;&#20174;&#32780;&#21487;&#20197;&#31616;&#21270;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#20272;&#35745;&#36807;&#31243;&#12290;&#25152;&#26377;&#32467;&#26524;&#37117;&#36866;&#29992;&#20110;&#20551;&#35774;&#24322;&#26041;&#24046;&#36328;&#25130;&#38754;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#22312;&#19968;&#20010;$n$&#32500;&#30340;&#31283;&#23450;&#26102;&#38388;&#24207;&#21015;&#21521;&#37327;&#30340;&#36817;&#20284;&#22240;&#23376;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20027;&#25104;&#20998;&#20272;&#35745;&#30340;&#22240;&#23376;&#36733;&#33655;&#22312;$n\to\infty$&#26102;&#19982;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#24471;&#21040;&#30340;&#36733;&#33655;&#31561;&#20215;&#12290;&#36825;&#20004;&#31181;&#20272;&#35745;&#37327;&#22312;$n\to\infty$&#26102;&#20063;&#19982;&#22914;&#26524;&#35266;&#23519;&#21040;&#22240;&#23376;&#26102;&#30340;&#19981;&#21487;&#34892;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#31561;&#20215;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20256;&#32479;&#19977;&#26126;&#27835;&#24418;&#24335;&#19982;&#19981;&#21487;&#34892;&#26368;&#23567;&#20108;&#20056;&#30340;&#31616;&#21333;&#28176;&#36817;&#21327;&#26041;&#24046;&#30697;&#38453;&#31561;&#20215;&#12290;&#36825;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#20934;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#28176;&#36817;&#32622;&#20449;&#21306;&#38388;&#65292;&#32780;&#19981;&#38656;&#35201;&#20272;&#35745;&#22797;&#26434;&#30340;&#28023;&#26862;&#30697;&#38453;&#21644;&#36153;&#35874;&#23572;&#20449;&#24687;&#30697;&#38453;&#12290;&#25152;&#26377;&#32467;&#26524;&#22343;&#36866;&#29992;&#20110;&#20551;&#35774;&#24322;&#26041;&#24046;&#36328;&#25130;&#38754;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove that in an approximate factor model for an $n$-dimensional vector of stationary time series the factor loadings estimated via Principal Components are asymptotically equivalent, as $n\to\infty$, to those estimated by Quasi Maximum Likelihood. Both estimators are, in turn, also asymptotically equivalent, as $n\to\infty$, to the unfeasible Ordinary Least Squares estimator we would have if the factors were observed. We also show that the usual sandwich form of the asymptotic covariance matrix of the Quasi Maximum Likelihood estimator is asymptotically equivalent to the simpler asymptotic covariance matrix of the unfeasible Ordinary Least Squares. This provides a simple way to estimate asymptotic confidence intervals for the Quasi Maximum Likelihood estimator without the need of estimating the Hessian and Fisher information matrices whose expressions are very complex. All our results hold in the general case in which the idiosyncratic components are cross-sectionally heteroskedast
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36827;&#34892;&#21327;&#21464;&#37327;&#25928;&#24212;&#20272;&#35745;&#26102;&#38750;&#24120;&#39640;&#25928;&#65292;&#19981;&#38656;&#35201;&#24378;&#28872;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#22343;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#20449;&#24230;&#20445;&#35777;&#21644;&#25928;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.06756</link><description>&lt;p&gt;
&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#39640;&#32500;&#21322;&#21442;&#25968;&#25512;&#29702;&#30340;&#24809;&#32602;&#27850;&#26494;&#20284;&#28982;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Penalized Poisson Likelihood Approach to High-Dimensional Semi-Parametric Inference for Doubly-Stochastic Point Processes. (arXiv:2306.06756v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36827;&#34892;&#21327;&#21464;&#37327;&#25928;&#24212;&#20272;&#35745;&#26102;&#38750;&#24120;&#39640;&#25928;&#65292;&#19981;&#38656;&#35201;&#24378;&#28872;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#22343;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#20449;&#24230;&#20445;&#35777;&#21644;&#25928;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#23558;&#31354;&#38388;&#22495;&#20869;&#20107;&#20214;&#30340;&#21457;&#29983;&#24314;&#27169;&#20026;&#22312;&#23454;&#29616;&#38543;&#26426;&#24378;&#24230;&#20989;&#25968;&#30340;&#26465;&#20214;&#19979;&#65292;&#19981;&#22343;&#21248;&#27850;&#26494;&#36807;&#31243;&#12290;&#23427;&#20204;&#26159;&#25429;&#25417;&#31354;&#38388;&#24322;&#36136;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#28789;&#27963;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#21452;&#38543;&#26426;&#31354;&#38388;&#27169;&#22411;&#30340;&#23454;&#29616;&#22312;&#35745;&#31639;&#19978;&#26159;&#26377;&#35201;&#27714;&#30340;&#65292;&#24448;&#24448;&#20855;&#26377;&#26377;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;/&#25110;&#20381;&#36182;&#20110;&#20855;&#26377;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#20013;&#30340;&#21327;&#21464;&#37327;&#25928;&#24212;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#19988;&#19981;&#38656;&#35201;&#22522;&#30784;&#24378;&#24230;&#30340;&#21442;&#25968;&#24418;&#24335;&#25110;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#23548;&#33268;&#20445;&#23432;&#30340;&#32479;&#35745;&#25512;&#26029;&#31243;&#24207;&#12290;&#27169;&#25311;&#30740;&#31350;&#26174;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#38480;&#21046;&#24615;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#22312;&#35199;&#38597;&#22270;&#29359;&#32618;&#20107;&#20214;&#30340;&#24212;&#29992;&#20013;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Doubly-stochastic point processes model the occurrence of events over a spatial domain as an inhomogeneous Poisson process conditioned on the realization of a random intensity function. They are flexible tools for capturing spatial heterogeneity and dependence. However, implementations of doubly-stochastic spatial models are computationally demanding, often have limited theoretical guarantee, and/or rely on restrictive assumptions. We propose a penalized regression method for estimating covariate effects in doubly-stochastic point processes that is computationally efficient and does not require a parametric form or stationarity of the underlying intensity. We establish the consistency and asymptotic normality of the proposed estimator, and develop a covariance estimator that leads to a conservative statistical inference procedure. A simulation study shows the validity of our approach under less restrictive assumptions on the data generating mechanism, and an application to Seattle crim
&lt;/p&gt;</description></item></channel></rss>