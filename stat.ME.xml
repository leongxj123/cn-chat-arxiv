<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#31232;&#30095;&#24615;&#30340;&#32447;&#24615;&#22238;&#24402;&#20272;&#35745;&#22312;&#36873;&#25321;&#22238;&#24402;&#30697;&#38453;&#21644;&#20551;&#35774;&#26816;&#39564;&#19978;&#23384;&#22312;&#33030;&#24369;&#24615;&#65292;OLS&#33021;&#22815;&#25552;&#20379;&#26356;&#20581;&#22766;&#30340;&#32467;&#26524;&#32780;&#25928;&#29575;&#25439;&#22833;&#36739;&#23567;&#12290;</title><link>http://arxiv.org/abs/2311.02299</link><description>&lt;p&gt;
&#31232;&#30095;&#24615;&#30340;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Fragility of Sparsity. (arXiv:2311.02299v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02299
&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24615;&#30340;&#32447;&#24615;&#22238;&#24402;&#20272;&#35745;&#22312;&#36873;&#25321;&#22238;&#24402;&#30697;&#38453;&#21644;&#20551;&#35774;&#26816;&#39564;&#19978;&#23384;&#22312;&#33030;&#24369;&#24615;&#65292;OLS&#33021;&#22815;&#25552;&#20379;&#26356;&#20581;&#22766;&#30340;&#32467;&#26524;&#32780;&#25928;&#29575;&#25439;&#22833;&#36739;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#19977;&#20010;&#23454;&#35777;&#24212;&#29992;&#23637;&#31034;&#20102;&#32447;&#24615;&#22238;&#24402;&#20272;&#35745;&#22312;&#20381;&#36182;&#31232;&#30095;&#24615;&#20551;&#35774;&#26102;&#23384;&#22312;&#20004;&#31181;&#33030;&#24369;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#19981;&#24433;&#21709;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;(OLS)&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#22522;&#32447;&#31867;&#21035;&#30340;&#36873;&#25321;&#19982;&#20998;&#31867;&#25511;&#21046;&#30456;&#20851;&#65292;&#21487;&#33021;&#20250;&#20351;&#31232;&#30095;&#24615;&#20272;&#35745;&#20540;&#31227;&#21160;&#36229;&#36807;&#20004;&#20010;&#26631;&#20934;&#35823;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#20010;&#22522;&#20110;&#23558;&#31232;&#30095;&#24615;&#20272;&#35745;&#19982;OLS&#20272;&#35745;&#36827;&#34892;&#27604;&#36739;&#30340;&#31232;&#30095;&#24615;&#20551;&#35774;&#26816;&#39564;&#12290;&#22312;&#25152;&#26377;&#19977;&#20010;&#24212;&#29992;&#20013;&#65292;&#36825;&#20123;&#26816;&#39564;&#20542;&#21521;&#20110;&#25298;&#32477;&#31232;&#30095;&#24615;&#20551;&#35774;&#12290;&#38500;&#38750;&#33258;&#21464;&#37327;&#30340;&#25968;&#37327;&#19982;&#26679;&#26412;&#37327;&#30456;&#24403;&#25110;&#36229;&#36807;&#26679;&#26412;&#37327;&#65292;&#21542;&#21017;OLS&#33021;&#22815;&#20197;&#36739;&#23567;&#30340;&#25928;&#29575;&#25439;&#22833;&#20135;&#29983;&#26356;&#20581;&#22766;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show, using three empirical applications, that linear regression estimates which rely on the assumption of sparsity are fragile in two ways. First, we document that different choices of the regressor matrix that do not impact ordinary least squares (OLS) estimates, such as the choice of baseline category with categorical controls, can move sparsity-based estimates two standard errors or more. Second, we develop two tests of the sparsity assumption based on comparing sparsity-based estimators with OLS. The tests tend to reject the sparsity assumption in all three applications. Unless the number of regressors is comparable to or exceeds the sample size, OLS yields more robust results at little efficiency cost.
&lt;/p&gt;</description></item></channel></rss>