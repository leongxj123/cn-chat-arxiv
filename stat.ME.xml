<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#38024;&#23545;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#39044;&#26399;&#26465;&#20214;&#21327;&#26041;&#24046;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#25286;&#20998;&#35757;&#32451;&#25968;&#25454;&#24182;&#22312;&#29420;&#31435;&#26679;&#26412;&#19978;&#19979;&#35843;nuisance&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#32467;&#26500;&#26080;&#20851;&#30340;&#38169;&#35823;&#20998;&#26512;&#20197;&#21450;&#26356;&#24378;&#20551;&#35774;&#30340;&#32467;&#26524;&#65292;&#25552;&#20986;&#20102;&#26356;&#31934;&#30830;&#30340;DCDR&#20272;&#35745;&#22120;&#12290;</title><link>https://arxiv.org/abs/2403.15175</link><description>&lt;p&gt;
&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#65306;&#36229;&#36234;&#20018;&#34892;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Double Cross-fit Doubly Robust Estimators: Beyond Series Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15175
&lt;/p&gt;
&lt;p&gt;
&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#38024;&#23545;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#39044;&#26399;&#26465;&#20214;&#21327;&#26041;&#24046;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#25286;&#20998;&#35757;&#32451;&#25968;&#25454;&#24182;&#22312;&#29420;&#31435;&#26679;&#26412;&#19978;&#19979;&#35843;nuisance&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#32467;&#26500;&#26080;&#20851;&#30340;&#38169;&#35823;&#20998;&#26512;&#20197;&#21450;&#26356;&#24378;&#20551;&#35774;&#30340;&#32467;&#26524;&#65292;&#25552;&#20986;&#20102;&#26356;&#31934;&#30830;&#30340;DCDR&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#36328;&#25311;&#21512;&#20132;&#21449;&#30340;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22240;&#20854;&#33391;&#22909;&#30340;&#32467;&#26500;&#26080;&#20851;&#38169;&#35823;&#20445;&#35777;&#32780;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#22791;&#21463;&#38738;&#30544;&#12290;&#28982;&#32780;&#65292;&#24403;&#23384;&#22312;&#39069;&#22806;&#32467;&#26500;&#65292;&#20363;&#22914;H\"{o}lder&#24179;&#28369;&#26102;&#65292;&#21487;&#20197;&#36890;&#36807;&#22312;&#29420;&#31435;&#26679;&#26412;&#19978;&#23545;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#25286;&#20998;&#21644;&#19979;&#35843;nuisance&#20989;&#25968;&#20272;&#35745;&#22120;&#26469;&#26500;&#24314;&#26356;&#31934;&#30830;&#30340;&#8220;&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#8221;&#65288;DCDR&#65289;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#39044;&#26399;&#26465;&#20214;&#21327;&#26041;&#24046;&#30340;DCDR&#20272;&#35745;&#22120;&#65292;&#22312;&#22240;&#26524;&#25512;&#26029;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#20013;&#26159;&#19968;&#20010;&#24863;&#20852;&#36259;&#30340;&#20989;&#25968;&#65292;&#24182;&#24471;&#20986;&#20102;&#19968;&#31995;&#21015;&#36880;&#28176;&#26356;&#24378;&#20551;&#35774;&#30340;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;DCDR&#20272;&#35745;&#22120;&#25552;&#20379;&#26080;&#38656;&#23545;nuisance&#20989;&#25968;&#25110;&#23427;&#20204;&#30340;&#20272;&#35745;&#22120;&#20570;&#20986;&#20551;&#35774;&#30340;&#32467;&#26500;&#26080;&#20851;&#38169;&#35823;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#20551;&#35774;nuisance&#20989;&#25968;&#26159;H\"{o}lder&#24179;&#28369;&#65292;&#20294;&#19981;&#20551;&#35774;&#30693;&#26195;&#30495;&#23454;&#24179;&#28369;&#32423;&#21035;&#25110;&#21327;&#21464;&#37327;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15175v1 Announce Type: cross  Abstract: Doubly robust estimators with cross-fitting have gained popularity in causal inference due to their favorable structure-agnostic error guarantees. However, when additional structure, such as H\"{o}lder smoothness, is available then more accurate "double cross-fit doubly robust" (DCDR) estimators can be constructed by splitting the training data and undersmoothing nuisance function estimators on independent samples. We study a DCDR estimator of the Expected Conditional Covariance, a functional of interest in causal inference and conditional independence testing, and derive a series of increasingly powerful results with progressively stronger assumptions. We first provide a structure-agnostic error analysis for the DCDR estimator with no assumptions on the nuisance functions or their estimators. Then, assuming the nuisance functions are H\"{o}lder smooth, but without assuming knowledge of the true smoothness level or the covariate densit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65292;&#20854;&#22312;&#19968;&#31867;&#26925;&#29699;&#19978;&#23454;&#29616;&#20102;&#65288;&#36817;&#20046;&#65289;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#24212;&#26410;&#30693;&#36870;&#38382;&#39064;&#24230;&#30340;&#25552;&#21069;&#20572;&#27490;&#35268;&#21017;&#12290;</title><link>https://arxiv.org/abs/2402.11134</link><description>&lt;p&gt;
&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#27861;&#65306;&#26368;&#20248;&#25910;&#25947;&#29575;&#21644;&#33258;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Functional Partial Least-Squares: Optimal Rates and Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11134
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65292;&#20854;&#22312;&#19968;&#31867;&#26925;&#29699;&#19978;&#23454;&#29616;&#20102;&#65288;&#36817;&#20046;&#65289;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#24212;&#26410;&#30693;&#36870;&#38382;&#39064;&#24230;&#30340;&#25552;&#21069;&#20572;&#27490;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#26631;&#37327;&#21709;&#24212;&#21644; Hilbert &#31354;&#38388;&#20540;&#39044;&#27979;&#21464;&#37327;&#30340;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#21453;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#20849;&#36717;&#26799;&#24230;&#26041;&#27861;&#30456;&#20851;&#30340;&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#20272;&#35745;&#30340;&#26032;&#20844;&#24335;&#12290;&#25105;&#20204;&#23558;&#23637;&#31034;&#35813;&#20272;&#35745;&#22120;&#22312;&#19968;&#31867;&#26925;&#29699;&#19978;&#23454;&#29616;&#20102;&#65288;&#36817;&#20046;&#65289;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#36870;&#38382;&#39064;&#24230;&#30340;&#25552;&#21069;&#20572;&#27490;&#35268;&#21017;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20272;&#35745;&#22120;&#19982;&#20027;&#25104;&#20998;&#22238;&#24402;&#20272;&#35745;&#22120;&#20043;&#38388;&#30340;&#19968;&#20123;&#29702;&#35770;&#21644;&#20223;&#30495;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11134v1 Announce Type: cross  Abstract: We consider the functional linear regression model with a scalar response and a Hilbert space-valued predictor, a well-known ill-posed inverse problem. We propose a new formulation of the functional partial least-squares (PLS) estimator related to the conjugate gradient method. We shall show that the estimator achieves the (nearly) optimal convergence rate on a class of ellipsoids and we introduce an early stopping rule which adapts to the unknown degree of ill-posedness. Some theoretical and simulation comparison between the estimator and the principal component regression estimator is provided.
&lt;/p&gt;</description></item></channel></rss>