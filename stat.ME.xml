<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.13966</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26368;&#20248;&#26497;&#23567;&#21270;&#20256;&#36882;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Transfer Learning for Kernel-based Nonparametric Regression. (arXiv:2310.13966v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20256;&#36882;&#23398;&#20064;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#21463;&#21040;&#20102;&#24456;&#22823;&#20851;&#27880;&#12290;&#23427;&#33021;&#22815;&#21033;&#29992;&#30456;&#20851;&#30740;&#31350;&#30340;&#30693;&#35782;&#26469;&#25552;&#39640;&#30446;&#26631;&#30740;&#31350;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20351;&#20854;&#20855;&#26377;&#24456;&#39640;&#30340;&#21560;&#24341;&#21147;&#12290;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#30446;&#30340;&#26159;&#32553;&#23567;&#23454;&#38469;&#25928;&#26524;&#19982;&#29702;&#35770;&#20445;&#35777;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32771;&#34385;&#20102;&#20004;&#31181;&#24773;&#20917;&#65306;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#21644;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#26680;&#20272;&#35745;&#22120;&#65292;&#20165;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#12290;&#23545;&#20110;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#25928;&#32858;&#21512;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26816;&#27979;&#24182;&#20943;&#36731;&#36127;&#38754;&#26469;&#28304;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25152;&#38656;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#65292;&#24182;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, transfer learning has garnered significant attention in the machine learning community. Its ability to leverage knowledge from related studies to improve generalization performance in a target study has made it highly appealing. This paper focuses on investigating the transfer learning problem within the context of nonparametric regression over a reproducing kernel Hilbert space. The aim is to bridge the gap between practical effectiveness and theoretical guarantees. We specifically consider two scenarios: one where the transferable sources are known and another where they are unknown. For the known transferable source case, we propose a two-step kernel-based estimator by solely using kernel ridge regression. For the unknown case, we develop a novel method based on an efficient aggregation algorithm, which can automatically detect and alleviate the effects of negative sources. This paper provides the statistical properties of the desired estimators and establishes the 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#30701;&#38754;&#26495;&#20013;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#30340;&#25512;&#29702;&#24037;&#20855;&#65292;&#29983;&#25104;&#20284;&#28982;&#27604;&#32479;&#35745;&#37327;&#24182;&#24471;&#20986;&#20102;AUMPI&#29305;&#24449;&#65292;&#32463;&#23454;&#35777;&#24212;&#29992;&#21457;&#29616;&#30701;&#23376;&#26399;&#29305;&#26377;&#27874;&#21160;&#29575;&#21576;&#19978;&#21319;&#36235;&#21183;&#12290;</title><link>http://arxiv.org/abs/2306.14004</link><description>&lt;p&gt;
&#30701;&#38754;&#26495;&#20013;&#30340;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Latent Factor Analysis in Short Panels. (arXiv:2306.14004v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14004
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#30701;&#38754;&#26495;&#20013;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#30340;&#25512;&#29702;&#24037;&#20855;&#65292;&#29983;&#25104;&#20284;&#28982;&#27604;&#32479;&#35745;&#37327;&#24182;&#24471;&#20986;&#20102;AUMPI&#29305;&#24449;&#65292;&#32463;&#23454;&#35777;&#24212;&#29992;&#21457;&#29616;&#30701;&#23376;&#26399;&#29305;&#26377;&#27874;&#21160;&#29575;&#21576;&#19978;&#21319;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#30701;&#38754;&#26495;&#20013;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#30340;&#25512;&#29702;&#24037;&#20855;&#12290; &#22312;&#22823;&#30340;&#27178;&#25130;&#38754;&#32500;&#24230;n&#21644;&#22266;&#23450;&#26102;&#38388;&#24207;&#21015;&#32500;&#24230;T&#30340;&#20266;&#26368;&#22823;&#20284;&#28982;&#35774;&#32622;&#20013;&#65292;&#20381;&#36182;&#20110;&#38169;&#35823;&#30340;&#23545;&#35282;&#32447;T&#215;T&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#32780;&#19981;&#24378;&#21152;&#29699;&#24418;&#25110;&#39640;&#26031;&#24615;&#12290; &#25105;&#20204;&#27010;&#36848;&#20102;&#28508;&#22312;&#22240;&#23376;&#21644;&#35823;&#24046;&#21327;&#26041;&#24046;&#20272;&#35745;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;&#20197;&#21450;&#22522;&#20110;&#20284;&#28982;&#27604;&#32479;&#35745;&#37327;&#30340;&#28176;&#36817;&#19968;&#33268;&#26368;&#26377;&#21147;&#19981;&#21464;&#65288;AUMPI&#65289;&#27979;&#35797;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;&#27979;&#35797;&#22240;&#23376;&#30340;&#25968;&#37327;&#12290; &#25105;&#20204;&#20174;&#30830;&#20445;&#27491;&#24577;&#21464;&#37327;&#20013;&#27491;&#23450;&#20108;&#27425;&#24418;&#24335;&#30340;&#21333;&#35843;&#20284;&#28982;&#27604;&#23646;&#24615;&#30340;&#19981;&#31561;&#24335;&#20013;&#23548;&#20986;&#20102;AUMPI&#29305;&#24449;&#12290; &#23545;&#32654;&#22269;&#19968;&#22823;&#25209;&#26376;&#24230;&#32929;&#31080;&#25910;&#30410;&#30340;&#23454;&#35777;&#24212;&#29992;&#22522;&#20110;&#25152;&#36873;&#22240;&#23376;&#25968;&#37327;&#65292;&#23558;&#30701;&#23376;&#26399;&#30340;&#29275;&#24066;&#19982;&#29066;&#24066;&#20043;&#21518;&#30340;&#26085;&#26399;&#31995;&#32479;&#21644;&#29305;&#26377;&#39118;&#38505;&#20998;&#24320;&#12290; &#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#26679;&#26412;&#26399;&#38388;&#29305;&#26377;&#27874;&#21160;&#29575;&#21576;&#19978;&#21319;&#36235;&#21183;&#65292;&#32780;&#31995;&#32479;&#39118;&#38505;&#20445;&#25345;&#31283;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop inferential tools for latent factor analysis in short panels. The pseudo maximum likelihood setting under a large cross-sectional dimension $n$ and a fixed time series dimension $T$ relies on a diagonal $T \times T$ covariance matrix of the errors without imposing sphericity or Gaussianity. We outline the asymptotic distributions of the latent factor and error covariance estimates as well as of an asymptotically uniformly most powerful invariant (AUMPI) test based on the likelihood ratio statistic for tests of the number of factors. We derive the AUMPI characterization from inequalities ensuring the monotone likelihood ratio property for positive definite quadratic forms in normal variables. An empirical application to a large panel of monthly U.S. stock returns separates date after date systematic and idiosyncratic risks in short subperiods of bear vs. bull market based on the selected number of factors. We observe an uptrend in idiosyncratic volatility while the systematic
&lt;/p&gt;</description></item></channel></rss>