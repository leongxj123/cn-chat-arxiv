<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#25511;&#21046;&#30340;&#36164;&#28304;&#20998;&#37197;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;$O(\sqrt{T})$&#30340;&#21518;&#24724;&#29575;&#65292;&#24182;&#25351;&#20986;&#36825;&#31181;&#21518;&#24724;&#29575;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#25913;&#36827;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.11425</link><description>&lt;p&gt;
&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#25511;&#21046;&#65306;&#19968;&#31181;&#36164;&#28304;&#20998;&#37197;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Local False Discovery Rate Control: A Resource Allocation Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11425
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#25511;&#21046;&#30340;&#36164;&#28304;&#20998;&#37197;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;$O(\sqrt{T})$&#30340;&#21518;&#24724;&#29575;&#65292;&#24182;&#25351;&#20986;&#36825;&#31181;&#21518;&#24724;&#29575;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#25913;&#36827;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#25511;&#21046;&#38382;&#39064;&#65292;&#20854;&#20013;&#22810;&#20010;&#27979;&#35797;&#34987;&#39034;&#24207;&#36827;&#34892;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#24635;&#26399;&#26395;&#30340;&#21457;&#29616;&#27425;&#25968;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19968;&#31181;&#22312;&#32447;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#65292;&#28041;&#21450;&#25509;&#21463;/&#25298;&#32477;&#20915;&#31574;&#65292;&#20174;&#39640;&#23618;&#27425;&#26469;&#30475;&#65292;&#36825;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#24102;&#26377;&#39069;&#22806;&#19981;&#30830;&#23450;&#24615;&#30340;&#22312;&#32447;&#32972;&#21253;&#38382;&#39064;&#65292;&#21363;&#38543;&#26426;&#39044;&#31639;&#34917;&#20805;&#12290;&#25105;&#20204;&#20174;&#19968;&#33324;&#30340;&#21040;&#36798;&#20998;&#24067;&#24320;&#22987;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;$O(\sqrt{T})$&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#36825;&#31181;&#21518;&#24724;&#29575;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#25913;&#36827;&#30340;&#26469;&#34917;&#20805;&#36825;&#19968;&#32467;&#26524;&#12290;&#28982;&#21518;&#25105;&#20204;&#23558;&#28966;&#28857;&#36716;&#21521;&#31163;&#25955;&#21040;&#36798;&#20998;&#24067;&#12290;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#29616;&#26377;&#30340;&#22312;&#32447;&#36164;&#28304;&#20998;&#37197;&#25991;&#29486;&#20013;&#30340;&#37325;&#26032;&#35299;&#20915;&#21551;&#21457;&#24335;&#34429;&#28982;&#22312;&#20856;&#22411;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#26377;&#30028;&#30340;&#25439;&#22833;&#65292;&#20294;&#21487;&#33021;&#20250;&#36896;&#25104;$\Omega(\sqrt{T})$&#29978;&#33267;$\Omega(T)$&#30340;&#21518;&#24724;&#12290;&#36890;&#36807;&#35266;&#23519;&#21040;&#20856;&#22411;&#31574;&#30053;&#24448;&#24448;&#22826;&#36807;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11425v1 Announce Type: cross  Abstract: We consider the problem of online local false discovery rate (FDR) control where multiple tests are conducted sequentially, with the goal of maximizing the total expected number of discoveries. We formulate the problem as an online resource allocation problem with accept/reject decisions, which from a high level can be viewed as an online knapsack problem, with the additional uncertainty of random budget replenishment. We start with general arrival distributions and propose a simple policy that achieves a $O(\sqrt{T})$ regret. We complement the result by showing that such regret rate is in general not improvable. We then shift our focus to discrete arrival distributions. We find that many existing re-solving heuristics in the online resource allocation literature, albeit achieve bounded loss in canonical settings, may incur a $\Omega(\sqrt{T})$ or even a $\Omega(T)$ regret. With the observation that canonical policies tend to be too op
&lt;/p&gt;</description></item></channel></rss>