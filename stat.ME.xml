<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#27010;&#29575;&#35770;&#20026;&#23545;&#31216;&#21333;&#35843;&#33539;&#30068;&#30340;&#26367;&#20195;&#22522;&#30784;&#65292;&#21487;&#20197;&#25193;&#23637;&#22240;&#26524;&#35782;&#21035;&#25216;&#26415;&#21040;&#26356;&#22810;&#22240;&#26524;&#35774;&#32622;&#20013;&#12290;</title><link>https://arxiv.org/abs/2403.09580</link><description>&lt;p&gt;
&#31639;&#27861;&#21477;&#27861;&#22240;&#26524;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Algorithmic syntactic causal identification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09580
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#27010;&#29575;&#35770;&#20026;&#23545;&#31216;&#21333;&#35843;&#33539;&#30068;&#30340;&#26367;&#20195;&#22522;&#30784;&#65292;&#21487;&#20197;&#25193;&#23637;&#22240;&#26524;&#35782;&#21035;&#25216;&#26415;&#21040;&#26356;&#22810;&#22240;&#26524;&#35774;&#32622;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;CBN&#65289;&#20013;&#36827;&#34892;&#22240;&#26524;&#35782;&#21035;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#19968;&#39033;&#37325;&#35201;&#24037;&#20855;&#65292;&#20801;&#35768;&#20174;&#29702;&#35770;&#19978;&#21487;&#33021;&#30340;&#24773;&#20917;&#19979;&#30340;&#35266;&#27979;&#20998;&#24067;&#25512;&#23548;&#24178;&#39044;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22240;&#26524;&#35782;&#21035;&#24418;&#24335;&#65292;&#22914;&#20351;&#29992;d&#20998;&#31163;&#21644;do-&#28436;&#31639;&#30340;&#25216;&#26415;&#37117;&#26159;&#22312;CBN&#19978;&#21033;&#29992;&#32463;&#20856;&#27010;&#29575;&#35770;&#30340;&#25968;&#23398;&#35821;&#35328;&#34920;&#36798;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#22240;&#26524;&#35774;&#32622;&#20013;&#65292;&#27010;&#29575;&#35770;&#21644;&#22240;&#27492;&#30446;&#21069;&#30340;&#22240;&#26524;&#35782;&#21035;&#25216;&#26415;&#19981;&#36866;&#29992;&#65292;&#22914;&#20851;&#31995;&#25968;&#25454;&#24211;&#12289;&#25968;&#25454;&#27969;&#31243;&#24207;&#65288;&#20363;&#22914;&#30828;&#20214;&#25551;&#36848;&#35821;&#35328;&#65289;&#12289;&#20998;&#24067;&#24335;&#31995;&#32479;&#21644;&#22823;&#22810;&#25968;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#29992;&#23545;&#31216;&#21333;&#35843;&#33539;&#30068;&#30340;&#26367;&#20195;&#20844;&#29702;&#22522;&#30784;&#26469;&#28040;&#38500;&#36825;&#31181;&#38480;&#21046;&#12290;&#22312;&#36825;&#31181;&#26367;&#20195;&#20844;&#29702;&#21270;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#33719;&#24471;&#19968;&#20010;&#26126;&#30830;&#19988;&#28165;&#26224;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09580v1 Announce Type: new  Abstract: Causal identification in causal Bayes nets (CBNs) is an important tool in causal inference allowing the derivation of interventional distributions from observational distributions where this is possible in principle. However, most existing formulations of causal identification using techniques such as d-separation and do-calculus are expressed within the mathematical language of classical probability theory on CBNs. However, there are many causal settings where probability theory and hence current causal identification techniques are inapplicable such as relational databases, dataflow programs such as hardware description languages, distributed systems and most modern machine learning algorithms. We show that this restriction can be lifted by replacing the use of classical probability theory with the alternative axiomatic foundation of symmetric monoidal categories. In this alternative axiomatization, we show how an unambiguous and clean
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#20123;&#19981;&#31561;&#24335;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#25104;&#31435;&#65292;&#22312;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15567</link><description>&lt;p&gt;
&#30697;&#38453;&#36229;&#38789;&#21644;&#38543;&#26426;&#30697;&#38453;&#38598;&#20013;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Matrix Supermartingales and Randomized Matrix Concentration Inequalities. (arXiv:2401.15567v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#20123;&#19981;&#31561;&#24335;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#25104;&#31435;&#65292;&#22312;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#21253;&#25324;&#26631;&#20934;&#30340;&#20999;&#23572;&#35834;&#22827;&#19978;&#30028;&#21644;&#33258;&#24402;&#19968;&#21270;&#37325;&#23614;&#35774;&#32622;&#12290;&#36825;&#20123;&#19981;&#31561;&#24335;&#36890;&#24120;&#20197;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#25104;&#31435;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#30697;&#38453;&#36229;&#38789;&#21644;&#26497;&#20540;&#19981;&#31561;&#24335;&#30340;&#29702;&#35770;&#65292;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#30740;&#31350;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present new concentration inequalities for either martingale dependent or exchangeable random symmetric matrices under a variety of tail conditions, encompassing standard Chernoff bounds to self-normalized heavy-tailed settings. These inequalities are often randomized in a way that renders them strictly tighter than existing deterministic results in the literature, are typically expressed in the Loewner order, and are sometimes valid at arbitrary data-dependent stopping times.  Along the way, we explore the theory of matrix supermartingales and maximal inequalities, potentially of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#22823;&#35268;&#27169;&#31354;&#38388;&#38754;&#26495;&#32593;&#32476;&#19978;&#25552;&#20986;&#20102;&#19968;&#31181;&#22343;&#21248;&#25512;&#26029;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#33021;&#22815;&#23545;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#36827;&#34892;&#20551;&#35774;&#26816;&#39564;&#65292;&#21253;&#25324;&#32593;&#32476;&#32467;&#26500;&#20013;&#30340;&#38646;&#25110;&#38750;&#38646;&#20803;&#32032;&#12290;</title><link>http://arxiv.org/abs/2105.07424</link><description>&lt;p&gt;
&#39640;&#32500;&#31354;&#38388;&#38754;&#26495;&#32593;&#32476;&#19978;&#30340;&#22343;&#21248;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Uniform Inference on High-dimensional Spatial Panel Networks. (arXiv:2105.07424v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.07424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#22823;&#35268;&#27169;&#31354;&#38388;&#38754;&#26495;&#32593;&#32476;&#19978;&#25552;&#20986;&#20102;&#19968;&#31181;&#22343;&#21248;&#25512;&#26029;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#33021;&#22815;&#23545;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#36827;&#34892;&#20551;&#35774;&#26816;&#39564;&#65292;&#21253;&#25324;&#32593;&#32476;&#32467;&#26500;&#20013;&#30340;&#38646;&#25110;&#38750;&#38646;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20559;&#24046;-&#27491;&#21017;&#21270;&#30340;&#39640;&#32500;&#24191;&#20041;&#30697;&#26041;&#27861;&#65288;GMM&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#22823;&#35268;&#27169;&#31354;&#38388;&#38754;&#26495;&#32593;&#32476;&#36827;&#34892;&#25512;&#26029;&#12290;&#29305;&#21035;&#26159;&#65292;&#21033;&#29992;&#20559;&#24046;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20272;&#35745;&#20855;&#26377;&#28789;&#27963;&#31232;&#30095;&#20559;&#24046;&#30340;&#32593;&#32476;&#32467;&#26500;&#65292;&#36825;&#21487;&#20197;&#34987;&#35270;&#20026;&#28508;&#22312;&#30340;&#25110;&#32773;&#19982;&#39044;&#23450;&#30340;&#37051;&#25509;&#30697;&#38453;&#19981;&#21305;&#37197;&#12290;&#29702;&#35770;&#20998;&#26512;&#30830;&#31435;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#32771;&#34385;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#19968;&#33324;&#26102;&#38388;&#21644;&#31354;&#38388;&#20381;&#36182;&#24615;&#12290;&#35752;&#35770;&#20102;&#20381;&#36182;&#24615;&#23384;&#22312;&#26102;&#30340;&#32500;&#24230;&#20801;&#35768;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#19968;&#20010;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20102;&#19968;&#31181;&#22343;&#21248;&#25512;&#26029;&#29702;&#35770;&#65292;&#33021;&#22815;&#23545;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#36827;&#34892;&#20551;&#35774;&#26816;&#39564;&#65292;&#21253;&#25324;&#32593;&#32476;&#32467;&#26500;&#20013;&#30340;&#38646;&#25110;&#38750;&#38646;&#20803;&#32032;&#12290;&#27492;&#22806;&#65292;&#23545;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#24615;&#36136;&#36827;&#34892;&#20102;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#26102;&#21051;&#30340;&#25512;&#23548;&#12290;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose employing a debiased-regularized, high-dimensional generalized method of moments (GMM) framework to perform inference on large-scale spatial panel networks. In particular, network structure with a flexible sparse deviation, which can be regarded either as latent or as misspecified from a predetermined adjacency matrix, is estimated using debiased machine learning approach. The theoretical analysis establishes the consistency and asymptotic normality of our proposed estimator, taking into account general temporal and spatial dependency inherent in the data-generating processes. The dimensionality allowance in presence of dependency is discussed. A primary contribution of our study is the development of uniform inference theory that enables hypothesis testing on the parameters of interest, including zero or non-zero elements in the network structure. Additionally, the asymptotic properties for the estimator are derived for both linear and nonlinear moments. Simulations demonst
&lt;/p&gt;</description></item></channel></rss>