<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;&#24207;&#21015;&#65292;&#21487;&#20197;&#21516;&#26102;&#39640;&#27010;&#29575;&#22320;&#21253;&#21547;&#21508;&#31181;&#26679;&#26412;&#37327;&#19979;&#38543;&#26426;&#21521;&#37327;&#30340;&#22343;&#20540;&#65292;&#24182;&#38024;&#23545;&#19981;&#21516;&#20998;&#24067;&#20551;&#35774;&#36827;&#34892;&#20102;&#25193;&#23637;&#21644;&#32479;&#19968;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2311.08168</link><description>&lt;p&gt;
&#38543;&#26426;&#21521;&#37327;&#22343;&#20540;&#30340;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;
&lt;/p&gt;
&lt;p&gt;
Time-Uniform Confidence Spheres for Means of Random Vectors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08168
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;&#24207;&#21015;&#65292;&#21487;&#20197;&#21516;&#26102;&#39640;&#27010;&#29575;&#22320;&#21253;&#21547;&#21508;&#31181;&#26679;&#26412;&#37327;&#19979;&#38543;&#26426;&#21521;&#37327;&#30340;&#22343;&#20540;&#65292;&#24182;&#38024;&#23545;&#19981;&#21516;&#20998;&#24067;&#20551;&#35774;&#36827;&#34892;&#20102;&#25193;&#23637;&#21644;&#32479;&#19968;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#24182;&#30740;&#31350;&#20102;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;&#8212;&#8212;&#21253;&#21547;&#38543;&#26426;&#21521;&#37327;&#22343;&#20540;&#24182;&#19988;&#36328;&#36234;&#25152;&#26377;&#26679;&#26412;&#37327;&#20855;&#26377;&#24456;&#39640;&#27010;&#29575;&#30340;&#32622;&#20449;&#29699;&#24207;&#21015;&#65288;CSSs&#65289;&#12290;&#21463;Catoni&#21644;Giulini&#21407;&#22987;&#24037;&#20316;&#21551;&#21457;&#65292;&#25105;&#20204;&#32479;&#19968;&#24182;&#25193;&#23637;&#20102;&#20182;&#20204;&#30340;&#20998;&#26512;&#65292;&#28085;&#30422;&#39034;&#24207;&#35774;&#32622;&#24182;&#22788;&#29702;&#21508;&#31181;&#20998;&#24067;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21253;&#25324;&#26377;&#30028;&#38543;&#26426;&#21521;&#37327;&#30340;&#32463;&#39564;&#20271;&#24681;&#26031;&#22374;CSS&#65288;&#23548;&#33268;&#26032;&#39062;&#30340;&#32463;&#39564;&#20271;&#24681;&#26031;&#22374;&#32622;&#20449;&#21306;&#38388;&#65292;&#28176;&#36817;&#23485;&#24230;&#25353;&#29031;&#30495;&#23454;&#26410;&#30693;&#26041;&#24046;&#25104;&#27604;&#20363;&#32553;&#25918;&#65289;&#12289;&#29992;&#20110;&#23376;-$\psi$&#38543;&#26426;&#21521;&#37327;&#30340;CSS&#65288;&#21253;&#25324;&#23376;&#20285;&#39532;&#12289;&#23376;&#27850;&#26494;&#21644;&#23376;&#25351;&#25968;&#20998;&#24067;&#65289;&#12289;&#21644;&#29992;&#20110;&#37325;&#23614;&#38543;&#26426;&#21521;&#37327;&#65288;&#20165;&#26377;&#20004;&#38454;&#30697;&#65289;&#30340;CSS&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#25269;&#25239;Huber&#22122;&#22768;&#27745;&#26579;&#30340;CSS&#12290;&#31532;&#19968;&#20010;&#26159;&#25105;&#20204;&#32463;&#39564;&#20271;&#24681;&#26031;&#22374;CSS&#30340;&#40065;&#26834;&#29256;&#26412;&#65292;&#31532;&#20108;&#20010;&#25193;&#23637;&#20102;&#21333;&#21464;&#37327;&#24207;&#21015;&#26368;&#36817;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08168v2 Announce Type: replace-cross  Abstract: We derive and study time-uniform confidence spheres -- confidence sphere sequences (CSSs) -- which contain the mean of random vectors with high probability simultaneously across all sample sizes. Inspired by the original work of Catoni and Giulini, we unify and extend their analysis to cover both the sequential setting and to handle a variety of distributional assumptions. Our results include an empirical-Bernstein CSS for bounded random vectors (resulting in a novel empirical-Bernstein confidence interval with asymptotic width scaling proportionally to the true unknown variance), CSSs for sub-$\psi$ random vectors (which includes sub-gamma, sub-Poisson, and sub-exponential), and CSSs for heavy-tailed random vectors (two moments only). Finally, we provide two CSSs that are robust to contamination by Huber noise. The first is a robust version of our empirical-Bernstein CSS, and the second extends recent work in the univariate se
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#24314;&#31435;&#20102;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#65292;&#25581;&#31034;&#20102;&#31232;&#30095;&#24615;&#21644;&#20989;&#25968;&#31354;&#38388;&#36873;&#25321;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#21644;&#20854;&#22312;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;Sobolev&#31354;&#38388;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#23545;&#31232;&#30095;&#24615;&#21644;&#24179;&#28369;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.09398</link><description>&lt;p&gt;
&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#26497;&#23567;&#26497;&#22823;&#20449;&#21495;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Minimax Signal Detection in Sparse Additive Models. (arXiv:2304.09398v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09398
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#24314;&#31435;&#20102;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#65292;&#25581;&#31034;&#20102;&#31232;&#30095;&#24615;&#21644;&#20989;&#25968;&#31354;&#38388;&#36873;&#25321;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#21644;&#20854;&#22312;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;Sobolev&#31354;&#38388;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#23545;&#31232;&#30095;&#24615;&#21644;&#24179;&#28369;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#30340;&#24314;&#27169;&#38656;&#27714;&#20013;&#65292;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#26159;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#31232;&#30095;&#21152;&#24615;&#20449;&#21495;&#26816;&#27979;&#30340;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#38750;&#28176;&#36817;&#30340;&#65292;&#24182;&#36866;&#29992;&#20110;&#21333;&#21464;&#37327;&#20998;&#37327;&#20989;&#25968;&#23646;&#20110;&#19968;&#33324;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#24773;&#20917;&#12290;&#19982;&#20272;&#35745;&#29702;&#35770;&#19981;&#21516;&#65292;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#25581;&#31034;&#20102;&#31232;&#30095;&#24615;&#21644;&#20989;&#25968;&#31354;&#38388;&#36873;&#25321;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20132;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#30340;&#33258;&#36866;&#24212;&#27979;&#35797;&#36895;&#29575;&#65307;&#22312;&#26576;&#20123;&#31354;&#38388;&#20013;&#65292;&#33258;&#36866;&#24212;&#24615;&#26159;&#21487;&#33021;&#30340;&#65292;&#32780;&#22312;&#20854;&#20182;&#31354;&#38388;&#20013;&#21017;&#20250;&#20135;&#29983;&#19981;&#21487;&#36991;&#20813;&#30340;&#20195;&#20215;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;Sobolev&#31354;&#38388;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#21644;&#24179;&#28369;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#65292;&#24182;&#26356;&#27491;&#20102;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#19968;&#20123;&#35828;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse additive models are an attractive choice in circumstances calling for modelling flexibility in the face of high dimensionality. We study the signal detection problem and establish the minimax separation rate for the detection of a sparse additive signal. Our result is nonasymptotic and applicable to the general case where the univariate component functions belong to a generic reproducing kernel Hilbert space. Unlike the estimation theory, the minimax separation rate reveals a nontrivial interaction between sparsity and the choice of function space. We also investigate adaptation to sparsity and establish an adaptive testing rate for a generic function space; adaptation is possible in some spaces while others impose an unavoidable cost. Finally, adaptation to both sparsity and smoothness is studied in the setting of Sobolev space, and we correct some existing claims in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;MCMC&#31639;&#27861;IIT&#21450;&#20854;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;&#35813;&#31639;&#27861;&#22987;&#32456;&#25509;&#21463;&#26377;&#20449;&#24687;&#30340;&#25552;&#35758;&#65292;&#21487;&#19982;&#20854;&#20182;MCMC&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#24182;&#24102;&#26469;&#26032;&#30340;&#20248;&#21270;&#25277;&#26679;&#22120;&#30340;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2304.06251</link><description>&lt;p&gt;
&#23454;&#29992;&#25351;&#21335;&#65306;&#20851;&#20110;&#30693;&#24773;&#37325;&#35201;&#24615;&#35843;&#33410;&#26041;&#27861;&#30340;&#35814;&#32454;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
Importance is Important: A Guide to Informed Importance Tempering Methods. (arXiv:2304.06251v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;MCMC&#31639;&#27861;IIT&#21450;&#20854;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;&#35813;&#31639;&#27861;&#22987;&#32456;&#25509;&#21463;&#26377;&#20449;&#24687;&#30340;&#25552;&#35758;&#65292;&#21487;&#19982;&#20854;&#20182;MCMC&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#24182;&#24102;&#26469;&#26032;&#30340;&#20248;&#21270;&#25277;&#26679;&#22120;&#30340;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#24773;&#37325;&#35201;&#24615;&#35843;&#33410; (IIT) &#26159;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;MCMC&#31639;&#27861;&#65292;&#21487;&#35270;&#20026;&#36890;&#24120;&#30340;Metropolis-Hastings&#31639;&#27861;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#22987;&#32456;&#25509;&#21463;&#26377;&#20449;&#24687;&#30340;&#25552;&#35758;&#30340;&#29305;&#27530;&#21151;&#33021;&#65292;&#22312;Zhou&#21644;Smith&#65288;2022&#24180;&#65289;&#30340;&#30740;&#31350;&#20013;&#34920;&#26126;&#22312;&#19968;&#20123;&#24120;&#35265;&#24773;&#20917;&#19979;&#25910;&#25947;&#26356;&#24555;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#12289;&#20840;&#38754;&#30340;&#25351;&#21335;&#65292;&#20171;&#32461;&#20102;IIT&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;IIT&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#22312;&#31163;&#25955;&#31354;&#38388;&#19978;&#30340;&#36816;&#34892;&#36895;&#24230;&#27604;&#29616;&#26377;&#30340;&#30693;&#24773;MCMC&#26041;&#27861;&#26356;&#24555;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#38656;&#35201;&#35745;&#31639;&#25152;&#26377;&#30456;&#37051;&#29366;&#24577;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23558;IIT&#19982;&#20854;&#20182;MCMC&#25216;&#26415;&#65288;&#21253;&#25324;&#27169;&#25311;&#22238;&#28779;&#12289;&#20266;&#36793;&#32536;&#21644;&#22810;&#37325;&#23581;&#35797;&#26041;&#27861;&#65292;&#22312;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;&#19978;&#23454;&#26045;&#20026;Metropolis-Hastings&#26041;&#26696;&#65292;&#21487;&#33021;&#36973;&#21463;&#20302;&#25509;&#21463;&#29575;&#30340;&#38382;&#39064;&#65289;&#36827;&#34892;&#20102;&#25972;&#21512;&#12290;&#20351;&#29992;IIT&#20351;&#25105;&#20204;&#33021;&#22815;&#22987;&#32456;&#25509;&#21463;&#25552;&#35758;&#65292;&#24182;&#24102;&#26469;&#20102;&#20248;&#21270;&#25277;&#26679;&#22120;&#30340;&#26032;&#26426;&#20250;&#65292;&#36825;&#26159;&#22312;Metropolis-Hastings&#31639;&#27861;&#19979;&#19981;&#21487;&#33021;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#25351;&#21335;&#65292;&#20197;&#36873;&#25321;IIT&#26041;&#26696;&#21644;&#35843;&#25972;&#31639;&#27861;&#21442;&#25968;&#12290;&#23545;&#21508;&#31181;&#27169;&#22411;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Informed importance tempering (IIT) is an easy-to-implement MCMC algorithm that can be seen as an extension of the familiar Metropolis-Hastings algorithm with the special feature that informed proposals are always accepted, and which was shown in Zhou and Smith (2022) to converge much more quickly in some common circumstances. This work develops a new, comprehensive guide to the use of IIT in many situations. First, we propose two IIT schemes that run faster than existing informed MCMC methods on discrete spaces by not requiring the posterior evaluation of all neighboring states. Second, we integrate IIT with other MCMC techniques, including simulated tempering, pseudo-marginal and multiple-try methods (on general state spaces), which have been conventionally implemented as Metropolis-Hastings schemes and can suffer from low acceptance rates. The use of IIT allows us to always accept proposals and brings about new opportunities for optimizing the sampler which are not possible under th
&lt;/p&gt;</description></item></channel></rss>