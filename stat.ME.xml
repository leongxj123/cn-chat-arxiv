<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#24182;&#19988;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#32473;&#20986;&#20272;&#35745;&#26631;&#31614;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#12290;&#24182;&#19988;&#65292;&#21333;&#27493;&#35889;&#31639;&#27861;&#21487;&#20197;&#22312;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;</title><link>http://arxiv.org/abs/2306.06845</link><description>&lt;p&gt;
&#23545;&#31216;&#20108;&#20803;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#19982;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Strong consistency and optimality of spectral clustering in symmetric binary non-uniform Hypergraph Stochastic Block Model. (arXiv:2306.06845v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06845
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#24182;&#19988;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#32473;&#20986;&#20272;&#35745;&#26631;&#31614;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#12290;&#24182;&#19988;&#65292;&#21333;&#27493;&#35889;&#31639;&#27861;&#21487;&#20197;&#22312;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32771;&#34385;&#20102;&#22312;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#65292;&#20004;&#20010;&#31561;&#22823;&#23567;&#30340;&#31038;&#21306;&#65288;n/2&#65289;&#20013;&#30340;&#38543;&#26426;&#36229;&#22270;&#19978;&#30340;&#26080;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#36793;&#21482;&#20381;&#36182;&#20110;&#20854;&#39030;&#28857;&#30340;&#26631;&#31614;&#65292;&#36793;&#20197;&#19968;&#23450;&#27010;&#29575;&#29420;&#31435;&#20986;&#29616;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#24314;&#31435;&#20102;&#24378;&#19968;&#33268;&#24615;&#30340;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#65292;&#20219;&#20309;&#31639;&#27861;&#37117;&#26377;&#24456;&#39640;&#27010;&#29575;&#20250;&#35823;&#20998;&#31867;&#33267;&#23569;&#20004;&#20010;&#39030;&#28857;&#65292;&#32780;&#29305;&#24449;&#21521;&#37327;&#20272;&#35745;&#37327;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#20026;$n$&#30340;&#38408;&#20540;&#30340;&#36127;&#25351;&#25968;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#24403;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#65292;&#23613;&#31649;&#24352;&#37327;&#25910;&#32553;&#24341;&#36215;&#20102;&#20449;&#24687;&#25439;&#22833;&#65292;&#20294;&#21333;&#27493;&#35889;&#31639;&#27861;&#20165;&#22312;&#32473;&#23450;&#25910;&#32553;&#30340;&#37051;&#25509;&#30697;&#38453;&#26102;&#65292;&#21363;&#20351;SDP&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22833;&#36133;&#65292;&#20063;&#21487;&#20197;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#20998;&#37197;&#26631;&#31614;&#12290;&#27492;&#22806;&#65292;&#24378;&#19968;&#33268;&#24615;&#21487;&#20197;&#36890;&#36807;&#23545;&#25152;&#26377;&#27425;&#20248;&#32858;&#21512;&#20449;&#24687;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the unsupervised classification problem in random hypergraphs under the non-uniform \emph{Hypergraph Stochastic Block Model} (HSBM) with two equal-sized communities ($n/2$), where each edge appears independently with some probability depending only on the labels of its vertices. In this paper, an \emph{information-theoretical} threshold for strong consistency is established. Below the threshold, every algorithm would misclassify at least two vertices with high probability, and the expected \emph{mismatch ratio} of the eigenvector estimator is upper bounded by $n$ to the power of minus the threshold. On the other hand, when above the threshold, despite the information loss induced by tensor contraction, one-stage spectral algorithms assign every vertex correctly with high probability when only given the contracted adjacency matrix, even if \emph{semidefinite programming} (SDP) fails in some scenarios. Moreover, strong consistency is achievable by aggregating information from al
&lt;/p&gt;</description></item></channel></rss>