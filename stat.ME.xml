<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#20989;&#25968;&#37325;&#26500;&#38543;&#26426;&#21464;&#37327;X&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#25968;&#25454;&#31232;&#21270;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#65292;&#24182;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.12931</link><description>&lt;p&gt;
&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#24191;&#20041;&#25968;&#25454;&#31232;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalized Data Thinning Using Sufficient Statistics. (arXiv:2303.12931v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#20989;&#25968;&#37325;&#26500;&#38543;&#26426;&#21464;&#37327;X&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#25968;&#25454;&#31232;&#21270;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#65292;&#24182;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#31181;&#23558;&#38543;&#26426;&#21464;&#37327;X&#20998;&#35299;&#20026;&#22810;&#20010;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#32780;&#19981;&#20250;&#20002;&#22833;&#20219;&#20309;&#26377;&#20851;&#26410;&#30693;&#21442;&#25968;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#19968;&#20123;&#24050;&#30693;&#30340;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#30340;&#20989;&#25968;&#23436;&#20840;&#37325;&#26500;X&#26469;&#25512;&#24191;&#20102;&#26368;&#36817;&#19968;&#31687;&#35770;&#25991;&#30340;&#36807;&#31243;&#12290;&#35813;&#36807;&#31243;&#30340;&#25512;&#24191;&#26377;&#20004;&#20010;&#30446;&#30340;&#12290;&#39318;&#20808;&#65292;&#23427;&#26497;&#22823;&#22320;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#12290;&#20854;&#27425;&#65292;&#23427;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#65292;&#23427;&#20204;&#22312;&#34920;&#38754;&#19978;&#20284;&#20046;&#38750;&#24120;&#19981;&#21516;&#65292;&#20294;&#24212;&#29992;&#20102;&#21516;&#26679;&#30340;&#21407;&#29702;&#12290;&#36825;&#20010;&#20849;&#21516;&#30340;&#21407;&#29702;&#26159;&#20805;&#20998;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#35748;&#35782;&#23545;&#21508;&#31181;&#19981;&#21516;&#30340;&#23478;&#26063;&#36827;&#34892;&#24191;&#20041;&#31232;&#30095;&#21270;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our goal is to develop a general strategy to decompose a random variable $X$ into multiple independent random variables, without sacrificing any information about unknown parameters. A recent paper showed that for some well-known natural exponential families, $X$ can be "thinned" into independent random variables $X^{(1)}, \ldots, X^{(K)}$, such that $X = \sum_{k=1}^K X^{(k)}$. In this paper, we generalize their procedure by relaxing this summation requirement and simply asking that some known function of the independent random variables exactly reconstruct $X$. This generalization of the procedure serves two purposes. First, it greatly expands the families of distributions for which thinning can be performed. Second, it unifies sample splitting and data thinning, which on the surface seem to be very different, as applications of the same principle. This shared principle is sufficiency. We use this insight to perform generalized thinning operations for a diverse set of families.
&lt;/p&gt;</description></item></channel></rss>