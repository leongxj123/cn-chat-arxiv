<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#26469;&#22238;&#31572;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2401.01426</link><description>&lt;p&gt;
&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference. (arXiv:2401.01426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#26469;&#22238;&#31572;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Pearl&#30340;&#22240;&#26524;&#23618;&#27425;&#32467;&#26500;&#22312;&#35266;&#27979;&#12289;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#38382;&#39064;&#20043;&#38388;&#24314;&#31435;&#20102;&#26126;&#30830;&#30340;&#20998;&#31163;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#35745;&#31639;&#21487;&#36776;&#35782;&#22240;&#26524;&#26597;&#35810;&#30340;&#22768;&#38899;&#21644;&#23436;&#25972;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#23618;&#27425;&#30340;&#22240;&#26524;&#32467;&#26500;&#21644;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#36739;&#20302;&#23618;&#27425;&#30340;&#23618;&#27425;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#31639;&#27861;&#20551;&#35774;&#25105;&#20204;&#21487;&#20197;&#20934;&#30830;&#20272;&#35745;&#25968;&#25454;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#36825;&#23545;&#20110;&#22914;&#22270;&#20687;&#36825;&#26679;&#30340;&#39640;&#32500;&#21464;&#37327;&#26159;&#19968;&#20010;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29616;&#20195;&#29983;&#25104;&#24335;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#21487;&#20197;&#34987;&#35757;&#32451;&#26469;&#23398;&#20064;&#22914;&#20309;&#20934;&#30830;&#22320;&#20174;&#36825;&#26679;&#30340;&#39640;&#32500;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#29305;&#21035;&#26159;&#38543;&#30528;&#22270;&#20687;&#22522;&#27169;&#22411;&#30340;&#26368;&#36817;&#20852;&#36215;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26469;&#22238;&#31572;&#24102;&#26377;&#36825;&#26679;&#39640;&#32500;&#25968;&#25454;&#30340;&#22240;&#26524;&#26597;&#35810;&#26159;&#38750;&#24120;&#26377;&#21560;&#24341;&#21147;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#35757;&#32451;&#31639;&#27861;&#65292;&#32473;&#23450;&#22240;&#26524;&#32467;&#26500;&#21644;&#39044;&#35757;&#32451;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#35757;&#32451;&#19968;&#20010;&#27169;&#22411;&#26469;&#20272;&#35745;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pearl's causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. Researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. However, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. On the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. Especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. To address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.16638</link><description>&lt;p&gt;
&#36866;&#24212;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Covariate Shift Adaptation Robust to Density-Ratio Estimation. (arXiv:2310.16638v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16638
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#20855;&#26377;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#32780;&#27979;&#35797;&#25968;&#25454;&#21482;&#21253;&#21547;&#21327;&#21464;&#37327;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#39044;&#27979;&#27979;&#35797;&#25968;&#25454;&#20013;&#32570;&#22833;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#35757;&#32451;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#20998;&#24067;&#19981;&#21516;&#12290;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20986;&#20102;&#36890;&#36807;&#20351;&#29992;&#23494;&#24230;&#27604;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26469;&#36827;&#34892;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#35757;&#32451;&#25968;&#25454;&#25439;&#22833;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#27599;&#20010;&#26435;&#37325;&#26159;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#65292;&#20197;&#36817;&#20284;&#27979;&#35797;&#25968;&#25454;&#30340;&#39118;&#38505;&#12290;&#23613;&#31649;&#23427;&#20801;&#35768;&#25105;&#20204;&#33719;&#24471;&#19968;&#20010;&#26368;&#23567;&#21270;&#27979;&#35797;&#25968;&#25454;&#39118;&#38505;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#23494;&#24230;&#27604;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#35823;&#24046;&#20063;&#20250;&#23548;&#33268;&#22238;&#24402;&#27169;&#22411;&#30340;&#20272;&#35745;&#22120;&#20135;&#29983;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model's 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.01111</link><description>&lt;p&gt;
&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#22312;MCMC&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Theoretical guarantees for neural control variates in MCMC. (arXiv:2304.01111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#24615;&#25511;&#21046;&#21464;&#37327;&#21644;&#26368;&#23567;&#21270;&#28176;&#36817;&#26041;&#24046;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#25511;&#21046;&#21464;&#37327;&#34920;&#31034;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#23450;&#24773;&#20917;&#12290;&#22312;&#22522;&#30784;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#65292;&#25512;&#23548;&#20102;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#21644;&#20989;&#25968;&#36924;&#36817;&#29702;&#35770;&#30340;&#38543;&#26426;&#35823;&#24046;&#30340;&#26368;&#26032;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a variance reduction approach for Markov chains based on additive control variates and the minimization of an appropriate estimate for the asymptotic variance. We focus on the particular case when control variates are represented as deep neural networks. We derive the optimal convergence rate of the asymptotic variance under various ergodicity assumptions on the underlying Markov chain. The proposed approach relies upon recent results on the stochastic errors of variance reduction algorithms and function approximation theory.
&lt;/p&gt;</description></item></channel></rss>