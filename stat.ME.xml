<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01454</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#19968;&#31181;&#32479;&#35745;&#22240;&#26524;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#30340;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#65288;SCD&#65289;&#20013;&#65292;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#20316;&#20026;&#32422;&#26463;&#23884;&#20837;&#21040;&#31639;&#27861;&#20013;&#34987;&#24191;&#27867;&#25509;&#21463;&#65292;&#22240;&#20026;&#36825;&#23545;&#20110;&#21019;&#24314;&#19968;&#33268;&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#27169;&#22411;&#26159;&#37325;&#35201;&#30340;&#65292;&#23613;&#31649;&#35782;&#21035;&#32972;&#26223;&#30693;&#35782;&#30340;&#25361;&#25112;&#34987;&#35748;&#21487;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#23558;LLM&#30340;&#8220;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#65288;SCP&#65289;&#8221;&#19982;SCD&#26041;&#27861;&#21644;&#22522;&#20110;&#30693;&#35782;&#30340;&#22240;&#26524;&#25512;&#26029;&#65288;KBCI&#65289;&#30456;&#32467;&#21512;&#65292;&#23545;SCD&#36827;&#34892;&#20808;&#39564;&#30693;&#35782;&#22686;&#24378;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4&#21487;&#20197;&#20351;LLM-KBCI&#30340;&#36755;&#20986;&#19982;&#24102;&#26377;LLM-KBCI&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;SCD&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#65292;&#22914;&#26524;GPT-4&#32463;&#21382;&#20102;SCP&#65292;&#37027;&#20040;SCD&#30340;&#32467;&#26524;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;LLM&#19981;&#21547;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;LLM&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#20854;&#32972;&#26223;&#30693;&#35782;&#26469;&#25913;&#36827;SCD&#12290;
&lt;/p&gt;
&lt;p&gt;
In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;QoIs&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26469;&#30830;&#23450;&#23454;&#39564;&#35774;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.18072</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#30446;&#26631;&#23548;&#21521;&#36125;&#21494;&#26031;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Goal-Oriented Bayesian Optimal Experimental Design for Nonlinear Models using Markov Chain Monte Carlo
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18072
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;QoIs&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26469;&#30830;&#23450;&#23454;&#39564;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#65288;OED&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#21270;&#30340;&#26041;&#27861;&#26469;&#37327;&#21270;&#21644;&#26368;&#22823;&#21270;&#23454;&#39564;&#25968;&#25454;&#30340;&#20215;&#20540;&#12290;&#22312;&#36125;&#21494;&#26031;&#26041;&#27861;&#19979;&#65292;&#20256;&#32479;&#30340;OED&#20250;&#26368;&#22823;&#21270;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65288;EIG&#65289;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#24120;&#24863;&#20852;&#36259;&#30340;&#19981;&#26159;&#21442;&#25968;&#26412;&#36523;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#21442;&#25968;&#30340;&#38750;&#32447;&#24615;&#26041;&#24335;&#30340;&#39044;&#27979;&#24863;&#20852;&#36259;&#37327;&#65288;QoIs&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#35266;&#27979;&#21644;&#39044;&#27979;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;OED&#65288;GO-OED&#65289;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23547;&#27714;&#25552;&#20379;&#23545;QoIs&#30340;&#26368;&#22823;EIG&#30340;&#23454;&#39564;&#35774;&#35745;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;QoI EIG&#30340;&#23884;&#22871;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#65292;&#21033;&#29992;&#26680;&#23494;&#24230;&#20272;&#35745;&#26469;&#35780;&#20272;&#21518;&#39564;&#39044;&#27979;&#23494;&#24230;&#21450;&#20854;&#19982;&#20808;&#39564;&#39044;&#27979;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#12290;GO-OED&#35774;&#35745;&#36890;&#36807;&#22312;&#35774;&#35745;&#31354;&#38388;&#20013;&#26368;&#22823;&#21270;EIG&#26469;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18072v1 Announce Type: cross  Abstract: Optimal experimental design (OED) provides a systematic approach to quantify and maximize the value of experimental data. Under a Bayesian approach, conventional OED maximizes the expected information gain (EIG) on model parameters. However, we are often interested in not the parameters themselves, but predictive quantities of interest (QoIs) that depend on the parameters in a nonlinear manner. We present a computational framework of predictive goal-oriented OED (GO-OED) suitable for nonlinear observation and prediction models, which seeks the experimental design providing the greatest EIG on the QoIs. In particular, we propose a nested Monte Carlo estimator for the QoI EIG, featuring Markov chain Monte Carlo for posterior sampling and kernel density estimation for evaluating the posterior-predictive density and its Kullback-Leibler divergence from the prior-predictive. The GO-OED design is then found by maximizing the EIG over the des
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;</title><link>http://arxiv.org/abs/2310.12140</link><description>&lt;p&gt;
&#22312;&#32447;&#20272;&#35745;&#19982;&#28378;&#21160;&#39564;&#35777;&#65306;&#36866;&#24212;&#24615;&#38750;&#21442;&#25968;&#20272;&#35745;&#19982;&#25968;&#25454;&#27969;
&lt;/p&gt;
&lt;p&gt;
Online Estimation with Rolling Validation: Adaptive Nonparametric Estimation with Stream Data. (arXiv:2310.12140v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#39640;&#25928;&#35745;&#31639;&#21644;&#31454;&#20105;&#24615;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#32447;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#20363;&#23376;&#26159;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21464;&#20307;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#19968;&#27425;&#21482;&#21462;&#19968;&#20010;&#26679;&#26412;&#28857;&#65292;&#24182;&#31435;&#21363;&#26356;&#26032;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20123;&#22312;&#32447;&#31639;&#27861;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#65292;&#19968;&#31181;&#22312;&#32447;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#21464;&#20307;&#65292;&#23545;&#20110;&#35768;&#22810;&#20856;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#26469;&#35828;&#65292;&#39069;&#22806;&#30340;&#35745;&#31639;&#25104;&#26412;&#26368;&#23567;&#12290;&#31867;&#20284;&#20110;&#25209;&#37327;&#20132;&#21449;&#39564;&#35777;&#65292;&#23427;&#21487;&#20197;&#25552;&#21319;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#24456;&#31616;&#21333;&#65292;&#20027;&#35201;&#20381;&#36182;&#20110;&#19968;&#20123;&#19968;&#33324;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#20551;&#35774;&#12290;&#27169;&#25311;&#30740;&#31350;&#24378;&#35843;&#20102;&#28378;&#21160;&#39564;&#35777;&#20013;&#21457;&#25955;&#26435;&#37325;&#22312;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#21363;&#20351;&#21482;&#26377;&#19968;&#20010;&#24456;&#23567;&#30340;&#20559;&#24046;&#65292;&#23427;&#30340;&#25935;&#24863;&#24615;&#20063;&#24456;&#39640;
&lt;/p&gt;
&lt;p&gt;
Online nonparametric estimators are gaining popularity due to their efficient computation and competitive generalization abilities. An important example includes variants of stochastic gradient descent. These algorithms often take one sample point at a time and instantly update the parameter estimate of interest. In this work we consider model selection and hyperparameter tuning for such online algorithms. We propose a weighted rolling-validation procedure, an online variant of leave-one-out cross-validation, that costs minimal extra computation for many typical stochastic gradient descent estimators. Similar to batch cross-validation, it can boost base estimators to achieve a better, adaptive convergence rate. Our theoretical analysis is straightforward, relying mainly on some general statistical stability assumptions. The simulation study underscores the significance of diverging weights in rolling validation in practice and demonstrates its sensitivity even when there is only a slim
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.05026</link><description>&lt;p&gt;
&#24102;&#26377;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#21512;&#25104;&#23545;&#29031;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification in Synthetic Controls with Staggered Treatment Adoption. (arXiv:2210.05026v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05026
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#21407;&#21017;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#29992;&#20110;&#37327;&#21270;&#22312;&#38169;&#20301;&#22788;&#29702;&#37319;&#29992;&#30340;&#24773;&#20917;&#19979;&#22823;&#31867;&#21512;&#25104;&#23545;&#29031;&#39044;&#27979;&#25110;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20379;&#31934;&#30830;&#30340;&#38750;&#28176;&#36817;&#35206;&#30422;&#27010;&#29575;&#20445;&#35777;&#12290;&#20174;&#26041;&#27861;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#38656;&#35201;&#39044;&#27979;&#30340;&#19981;&#21516;&#22240;&#26524;&#37327;&#36827;&#34892;&#35814;&#32454;&#35752;&#35770;&#65292;&#25105;&#20204;&#31216;&#20854;&#20026;&#8220;&#22240;&#26524;&#39044;&#27979;&#37327;&#8221;&#65292;&#20801;&#35768;&#22312;&#21487;&#33021;&#19981;&#21516;&#26102;&#21051;&#36827;&#34892;&#22810;&#20010;&#22788;&#29702;&#21333;&#20803;&#30340;&#22788;&#29702;&#37319;&#29992;&#12290;&#20174;&#29702;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#25552;&#39640;&#20102;&#20043;&#21069;&#25991;&#29486;&#30340;&#27700;&#24179;&#65292;&#20855;&#20307;&#34920;&#29616;&#22312;&#65306;&#65288;i&#65289;&#35206;&#30422;&#20102;&#38169;&#20301;&#37319;&#29992;&#35774;&#32622;&#20013;&#30340;&#22823;&#31867;&#22240;&#26524;&#39044;&#27979;&#37327;&#65292;&#65288;ii&#65289;&#20801;&#35768;&#20855;&#26377;&#21487;&#33021;&#38750;&#32447;&#24615;&#32422;&#26463;&#30340;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#65292;&#65288;iii&#65289;&#25552;&#20986;&#21487;&#25193;&#23637;&#30340;&#40065;&#26834;&#38181;&#20248;&#21270;&#26041;&#27861;&#21644;&#22522;&#20110;&#21407;&#21017;&#30340;&#25968;&#25454;&#39537;&#21160;&#35843;&#21442;&#36873;&#25321;&#65292;&#65288;iv&#65289;&#25552;&#20379;&#20102;&#22312;&#21518;&#22788;&#29702;&#26399;&#38388;&#36827;&#34892;&#26377;&#25928;&#22343;&#21248;&#25512;&#26029;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#24212;&#29992;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose principled prediction intervals to quantify the uncertainty of a large class of synthetic control predictions or estimators in settings with staggered treatment adoption, offering precise non-asymptotic coverage probability guarantees. From a methodological perspective, we provide a detailed discussion of different causal quantities to be predicted, which we call `causal predictands', allowing for multiple treated units with treatment adoption at possibly different points in time. From a theoretical perspective, our uncertainty quantification methods improve on prior literature by (i) covering a large class of causal predictands in staggered adoption settings, (ii) allowing for synthetic control methods with possibly nonlinear constraints, (iii) proposing scalable robust conic optimization methods and principled data-driven tuning parameter selection, and (iv) offering valid uniform inference across post-treatment periods. We illustrate our methodology with an empirical appl
&lt;/p&gt;</description></item></channel></rss>