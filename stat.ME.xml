<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;-SINDy&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#30340;&#27169;&#22411;&#26041;&#31243;&#65292;&#24182;&#19988;&#23545;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2402.15357</link><description>&lt;p&gt;
&#20174;&#31232;&#30095;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#24555;&#36895;&#35782;&#21035;&#31232;&#30095;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Rapid Bayesian identification of sparse nonlinear dynamics from scarce and noisy data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15357
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;-SINDy&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#30340;&#27169;&#22411;&#26041;&#31243;&#65292;&#24182;&#19988;&#23545;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#35782;&#21035;&#25511;&#21046;&#35266;&#27979;&#25968;&#25454;&#21160;&#24577;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#23558;SINDy&#26041;&#27861;&#37325;&#26032;&#26500;&#24314;&#21040;&#36125;&#21494;&#26031;&#26694;&#26550;&#20013;&#65292;&#24182;&#20351;&#29992;&#39640;&#26031;&#36924;&#36817;&#26469;&#21152;&#36895;&#35745;&#31639;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#26041;&#27861;&#65292;&#36125;&#21494;&#26031;-SINDy&#65292;&#19981;&#20165;&#37327;&#21270;&#20102;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19988;&#22312;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#27169;&#22411;&#26102;&#26356;&#21152;&#31283;&#20581;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#20363;&#23376;&#65292;&#22914;&#29470;&#29441;-&#37326;&#20820;&#31181;&#32676;&#21160;&#24577;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26032;&#26694;&#26550;&#22312;&#23398;&#20064;&#27491;&#30830;&#27169;&#22411;&#26041;&#31243;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#29616;&#26377;&#26041;&#27861;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#25928;&#29575;&#12290;&#30001;&#20110;&#36125;&#21494;&#26031;-SINDy&#21487;&#20197;&#24555;&#36895;&#21560;&#25910;&#25968;&#25454;&#24182;&#23545;&#22122;&#22768;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#22240;&#27492;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#25511;&#21046;&#20013;&#30340;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;&#20854;&#27010;&#29575;&#26694;&#26550;&#36824;&#20351;&#24471;&#21487;&#20197;&#35745;&#31639;&#20449;&#24687;&#29109;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15357v1 Announce Type: cross  Abstract: We propose a fast probabilistic framework for identifying differential equations governing the dynamics of observed data. We recast the SINDy method within a Bayesian framework and use Gaussian approximations for the prior and likelihood to speed up computation. The resulting method, Bayesian-SINDy, not only quantifies uncertainty in the parameters estimated but also is more robust when learning the correct model from limited and noisy data. Using both synthetic and real-life examples such as Lynx-Hare population dynamics, we demonstrate the effectiveness of the new framework in learning correct model equations and compare its computational and data efficiency with existing methods. Because Bayesian-SINDy can quickly assimilate data and is robust against noise, it is particularly suitable for biological data and real-time system identification in control. Its probabilistic framework also enables the calculation of information entropy, 
&lt;/p&gt;</description></item><item><title>Yurinskii&#30340;&#32806;&#21512;&#26041;&#27861;&#22312;$\ell^p$-&#33539;&#25968;&#19979;&#25552;&#20379;&#20102;&#26356;&#24369;&#26465;&#20214;&#19979;&#30340;&#36924;&#36817;&#39532;&#19969;&#26684;&#23572;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#26356;&#19968;&#33324;&#30340;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19977;&#38454;&#32806;&#21512;&#26041;&#27861;&#20197;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#32039;&#23494;&#30340;&#36924;&#36817;&#12290;</title><link>https://arxiv.org/abs/2210.00362</link><description>&lt;p&gt;
Yurinskii&#30340;&#39532;&#19969;&#26684;&#23572;&#32806;&#21512;
&lt;/p&gt;
&lt;p&gt;
Yurinskii's Coupling for Martingales
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.00362
&lt;/p&gt;
&lt;p&gt;
Yurinskii&#30340;&#32806;&#21512;&#26041;&#27861;&#22312;$\ell^p$-&#33539;&#25968;&#19979;&#25552;&#20379;&#20102;&#26356;&#24369;&#26465;&#20214;&#19979;&#30340;&#36924;&#36817;&#39532;&#19969;&#26684;&#23572;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#26356;&#19968;&#33324;&#30340;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19977;&#38454;&#32806;&#21512;&#26041;&#27861;&#20197;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#32039;&#23494;&#30340;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Yurinskii&#30340;&#32806;&#21512;&#26159;&#25968;&#23398;&#32479;&#35745;&#21644;&#24212;&#29992;&#27010;&#29575;&#20013;&#19968;&#31181;&#24120;&#29992;&#30340;&#38750;&#28176;&#36817;&#20998;&#24067;&#20998;&#26512;&#29702;&#35770;&#24037;&#20855;&#65292;&#25552;&#20379;&#20102;&#22312;&#26131;&#20110;&#39564;&#35777;&#26465;&#20214;&#19979;&#20855;&#26377;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#30340;&#39640;&#26031;&#24378;&#36924;&#36817;&#12290;&#26368;&#21021;&#22312;&#29420;&#31435;&#38543;&#26426;&#21521;&#37327;&#21644;&#20026;&#30340;$\ell^2$-&#33539;&#25968;&#20013;&#38472;&#36848;&#65292;&#26368;&#36817;&#24050;&#23558;&#20854;&#25193;&#23637;&#21040;$1 \leq p \leq \infty$&#26102;&#30340;$\ell^p$-&#33539;&#25968;&#65292;&#20197;&#21450;&#22312;&#26576;&#20123;&#24378;&#26465;&#20214;&#19979;&#30340;$\ell^2$-&#33539;&#25968;&#30340;&#21521;&#37327;&#20540;&#38789;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#22312;&#36828;&#27604;&#20043;&#21069;&#26045;&#21152;&#30340;&#26465;&#20214;&#26356;&#24369;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;$\ell^p$-&#33539;&#25968;&#19979;&#25552;&#20379;&#20102;&#36924;&#36817;&#39532;&#19969;&#26684;&#23572;&#30340;Yurinskii&#32806;&#21512;&#12290;&#25105;&#20204;&#30340;&#20844;&#24335;&#36827;&#19968;&#27493;&#20801;&#35768;&#32806;&#21512;&#21464;&#37327;&#36981;&#24490;&#26356;&#19968;&#33324;&#30340;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65292;&#24182;&#19988;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31532;&#19977;&#38454;&#32806;&#21512;&#26041;&#27861;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#36924;&#36817;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#19987;&#38376;&#24212;&#29992;&#20110;&#28151;&#21512;&#39532;&#19969;&#26684;&#23572;&#65292;&#39532;&#19969;&#26684;&#23572;&#21644;&#20854;&#20182;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.00362v2 Announce Type: replace-cross  Abstract: Yurinskii's coupling is a popular theoretical tool for non-asymptotic distributional analysis in mathematical statistics and applied probability, offering a Gaussian strong approximation with an explicit error bound under easily verified conditions. Originally stated in $\ell^2$-norm for sums of independent random vectors, it has recently been extended both to the $\ell^p$-norm, for $1 \leq p \leq \infty$, and to vector-valued martingales in $\ell^2$-norm, under some strong conditions. We present as our main result a Yurinskii coupling for approximate martingales in $\ell^p$-norm, under substantially weaker conditions than those previously imposed. Our formulation further allows for the coupling variable to follow a more general Gaussian mixture distribution, and we provide a novel third-order coupling method which gives tighter approximations in certain settings. We specialize our main result to mixingales, martingales, and in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.15878</link><description>&lt;p&gt;
&#20998;&#37197;&#31119;&#21033;&#30340;&#25919;&#31574;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Policy Learning with Distributional Welfare. (arXiv:2311.15878v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.15878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#12290;&#22823;&#37096;&#20998;&#20851;&#20110;&#27835;&#30103;&#36873;&#25321;&#30340;&#25991;&#29486;&#37117;&#32771;&#34385;&#20102;&#22522;&#20110;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#21151;&#21033;&#31119;&#21033;&#12290;&#34429;&#28982;&#24179;&#22343;&#31119;&#21033;&#26159;&#30452;&#35266;&#30340;&#65292;&#20294;&#22312;&#20010;&#20307;&#24322;&#36136;&#21270;&#65288;&#20363;&#22914;&#65292;&#23384;&#22312;&#31163;&#32676;&#20540;&#65289;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#20135;&#29983;&#19981;&#29702;&#24819;&#30340;&#20998;&#37197; - &#36825;&#27491;&#26159;&#20010;&#24615;&#21270;&#27835;&#30103;&#24341;&#20837;&#30340;&#21407;&#22240;&#20043;&#19968;&#12290;&#36825;&#20010;&#35266;&#23519;&#35753;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65288;QoTE&#65289;&#26469;&#20998;&#37197;&#27835;&#30103;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#26681;&#25454;&#20998;&#20301;&#25968;&#27010;&#29575;&#30340;&#36873;&#25321;&#65292;&#36825;&#20010;&#20934;&#21017;&#21487;&#20197;&#36866;&#24212;&#35880;&#24910;&#25110;&#31895;&#24515;&#30340;&#20915;&#31574;&#32773;&#12290;&#30830;&#23450;QoTE&#30340;&#25361;&#25112;&#22312;&#20110;&#20854;&#38656;&#35201;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#30340;&#32852;&#21512;&#20998;&#24067;&#26377;&#25152;&#20102;&#35299;&#65292;&#20294;&#21363;&#20351;&#20351;&#29992;&#23454;&#39564;&#25968;&#25454;&#65292;&#36890;&#24120;&#20063;&#24456;&#38590;&#24674;&#22797;&#20986;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore optimal treatment allocation policies that target distributional welfare. Most literature on treatment choice has considered utilitarian welfare based on the conditional average treatment effect (ATE). While average welfare is intuitive, it may yield undesirable allocations especially when individuals are heterogeneous (e.g., with outliers) - the very reason individualized treatments were introduced in the first place. This observation motivates us to propose an optimal policy that allocates the treatment based on the conditional quantile of individual treatment effects (QoTE). Depending on the choice of the quantile probability, this criterion can accommodate a policymaker who is either prudent or negligent. The challenge of identifying the QoTE lies in its requirement for knowledge of the joint distribution of the counterfactual outcomes, which is generally hard to recover even with experimental data. Therefore, we introduce minimax policies that are robust 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item></channel></rss>