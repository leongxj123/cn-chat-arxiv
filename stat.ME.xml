<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#22788;&#29702;&#30340;&#22238;&#24402;&#31995;&#25968;&#36890;&#24120;&#19981;&#31561;&#20110;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#65292;&#19988;&#21487;&#33021;&#19981;&#26159;&#30452;&#25509;&#31185;&#23398;&#25110;&#25919;&#31574;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#21508;&#31181;&#35299;&#37322;&#12289;&#36793;&#30028;&#21644;&#35786;&#26029;&#36741;&#21161;&#24037;&#20855;&#26469;&#35299;&#37322;&#36825;&#31181;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2403.03299</link><description>&lt;p&gt;
&#29702;&#35299;&#21644;&#36991;&#20813;&#8220;&#22238;&#24402;&#26435;&#37325;&#8221;&#65306;&#24322;&#36136;&#25928;&#24212;&#12289;&#35823;&#35774;&#21644;&#38271;&#20037;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Understanding and avoiding the "weights of regression": Heterogeneous effects, misspecification, and longstanding solutions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03299
&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#30340;&#22238;&#24402;&#31995;&#25968;&#36890;&#24120;&#19981;&#31561;&#20110;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#65292;&#19988;&#21487;&#33021;&#19981;&#26159;&#30452;&#25509;&#31185;&#23398;&#25110;&#25919;&#31574;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#21508;&#31181;&#35299;&#37322;&#12289;&#36793;&#30028;&#21644;&#35786;&#26029;&#36741;&#21161;&#24037;&#20855;&#26469;&#35299;&#37322;&#36825;&#31181;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#21162;&#21147;&#36890;&#36807;&#22312;&#22788;&#29702;&#65288;D&#65289;&#21644;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#22240;&#32032;&#65288;X&#65289;&#19978;&#23545;&#32467;&#26524;&#25968;&#25454;&#65288;Y&#65289;&#36827;&#34892;&#22238;&#24402;&#26469;&#20272;&#35745;&#27835;&#30103;&#25928;&#24212;&#12290;&#21363;&#20351;&#19981;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#22240;&#32032;&#65292;&#22788;&#29702;&#30340;&#22238;&#24402;&#31995;&#25968;&#20063;&#20250;&#25253;&#21578;&#20998;&#23618;&#29305;&#23450;&#22788;&#29702;&#25928;&#24212;&#30340;&#21152;&#26435;&#24179;&#22343;&#20540;&#12290;&#24403;&#26080;&#27861;&#25490;&#38500;&#24322;&#36136;&#22788;&#29702;&#25928;&#24212;&#26102;&#65292;&#24471;&#21040;&#30340;&#31995;&#25968;&#36890;&#24120;&#19981;&#31561;&#20110;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#65292;&#20063;&#19981;&#22826;&#21487;&#33021;&#26159;&#30452;&#25509;&#31185;&#23398;&#25110;&#25919;&#31574;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#12290;&#31995;&#25968;&#19982;ATE&#20043;&#38388;&#30340;&#24046;&#24322;&#23548;&#33268;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#21508;&#31181;&#35299;&#37322;&#12289;&#36793;&#30028;&#21644;&#35786;&#26029;&#36741;&#21161;&#24037;&#20855;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#65292;&#22312;&#22788;&#29702;&#25928;&#24212;&#22312;X&#20013;&#26159;&#24322;&#36136;&#30340;&#26102;&#65292;&#23545;Y&#20851;&#20110;D&#21644;X&#30340;&#32447;&#24615;&#22238;&#24402;&#21487;&#33021;&#23384;&#22312;&#35823;&#35774;&#12290;&#22238;&#24402;&#30340;&#8220;&#26435;&#37325;&#8221;&#65292;&#23545;&#27492;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03299v1 Announce Type: cross  Abstract: Researchers in many fields endeavor to estimate treatment effects by regressing outcome data (Y) on a treatment (D) and observed confounders (X). Even absent unobserved confounding, the regression coefficient on the treatment reports a weighted average of strata-specific treatment effects (Angrist, 1998). Where heterogeneous treatment effects cannot be ruled out, the resulting coefficient is thus not generally equal to the average treatment effect (ATE), and is unlikely to be the quantity of direct scientific or policy interest. The difference between the coefficient and the ATE has led researchers to propose various interpretational, bounding, and diagnostic aids (Humphreys, 2009; Aronow and Samii, 2016; Sloczynski, 2022; Chattopadhyay and Zubizarreta, 2023). We note that the linear regression of Y on D and X can be misspecified when the treatment effect is heterogeneous in X. The "weights of regression", for which we provide a new (m
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item></channel></rss>