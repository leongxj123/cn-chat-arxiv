<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#37325;&#22797;&#27979;&#37327;&#30340;&#35270;&#35273;&#27169;&#25311;&#37327;&#34920;&#25968;&#25454;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21709;&#24212;&#39118;&#26684;&#65288;RP&#65289;&#34920;&#24449;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;VAS&#20013;&#22788;&#29702;RP&#30340;&#22256;&#38590;&#12290;</title><link>https://arxiv.org/abs/2403.10136</link><description>&lt;p&gt;
&#21033;&#29992;&#35270;&#35273;&#27169;&#25311;&#37327;&#34920;&#23545;&#37325;&#22797;&#27979;&#37327;&#30340;&#21709;&#24212;&#39118;&#26684;&#36827;&#34892;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
Response Style Characterization for Repeated Measures Using the Visual Analogue Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10136
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#37325;&#22797;&#27979;&#37327;&#30340;&#35270;&#35273;&#27169;&#25311;&#37327;&#34920;&#25968;&#25454;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21709;&#24212;&#39118;&#26684;&#65288;RP&#65289;&#34920;&#24449;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;VAS&#20013;&#22788;&#29702;RP&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#25253;&#21578;&#27979;&#37327;&#65288;&#20363;&#22914;&#65292;&#21033;&#20811;&#29305;&#37327;&#34920;&#65289;&#34987;&#24191;&#27867;&#29992;&#20110;&#35780;&#20272;&#20027;&#35266;&#20581;&#24247;&#24863;&#30693;&#12290;&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#31934;&#30830;&#19988;&#20415;&#20110;&#35780;&#20272;&#20154;&#20204;&#24863;&#21463;&#30340;&#33021;&#21147;&#65292;&#35270;&#35273;&#27169;&#25311;&#37327;&#34920;&#65288;VAS&#65289;&#65292;&#19968;&#31181;&#28369;&#21160;&#26465;&#37327;&#34920;&#65292;&#21464;&#24471;&#27969;&#34892;&#36215;&#26469;&#12290;&#36825;&#20123;&#25968;&#25454;&#21487;&#33021;&#20250;&#21463;&#21040;&#21709;&#24212;&#39118;&#26684;&#65288;RS&#65289;&#30340;&#24433;&#21709;&#65292;RS&#26159;&#19968;&#31181;&#29992;&#25143;&#20381;&#36182;&#30340;&#31995;&#32479;&#24615;&#20542;&#21521;&#65292;&#26080;&#35770;&#38382;&#21367;&#35828;&#26126;&#22914;&#20309;&#37117;&#20250;&#21457;&#29983;&#12290;&#23613;&#31649;&#22312;&#20010;&#20307;&#38388;&#20998;&#26512;&#20013;&#23588;&#20026;&#37325;&#35201;&#65292;&#20294;&#23545;VAS&#20013;RS&#65288;&#34920;&#31034;&#20026;&#21709;&#24212;&#21078;&#38754;&#65288;RP&#65289;&#65289;&#30340;&#22788;&#29702;&#24182;&#26410;&#21463;&#21040;&#36275;&#22815;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#20027;&#35201;&#29992;&#20110;&#20010;&#20307;&#20869;&#30417;&#27979;&#19988;&#19981;&#22826;&#21463;RP&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;VAS&#27979;&#37327;&#36890;&#24120;&#38656;&#35201;&#23545;&#21516;&#19968;&#38382;&#21367;&#39033;&#30446;&#36827;&#34892;&#37325;&#22797;&#33258;&#25105;&#25253;&#21578;&#65292;&#36825;&#20351;&#24471;&#38590;&#20197;&#22312;&#21033;&#20811;&#29305;&#37327;&#34920;&#19978;&#24212;&#29992;&#20256;&#32479;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;RP&#34920;&#24449;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#37325;&#22797;&#27979;&#37327;&#30340;VAS&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10136v1 Announce Type: cross  Abstract: Self-report measures (e.g., Likert scales) are widely used to evaluate subjective health perceptions. Recently, the visual analog scale (VAS), a slider-based scale, has become popular owing to its ability to precisely and easily assess how people feel. These data can be influenced by the response style (RS), a user-dependent systematic tendency that occurs regardless of questionnaire instructions. Despite its importance, especially in between-individual analysis, little attention has been paid to handling the RS in the VAS (denoted as response profile (RP)), as it is mainly used for within-individual monitoring and is less affected by RP. However, VAS measurements often require repeated self-reports of the same questionnaire items, making it difficult to apply conventional methods on a Likert scale. In this study, we developed a novel RP characterization method for various types of repeatedly measured VAS data. This approach involves t
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#20294;&#26159;&#20854;&#40065;&#26834;&#24615;&#20173;&#28982;&#23384;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.00050</link><description>&lt;p&gt;
&#22240;&#26524;&#25512;&#29702;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#24320;&#21551;&#22240;&#26524;&#30740;&#31350;&#30340;&#26032;&#31687;&#31456;
&lt;/p&gt;
&lt;p&gt;
Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00050
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#20294;&#26159;&#20854;&#40065;&#26834;&#24615;&#20173;&#28982;&#23384;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22240;&#26524;&#33021;&#21147;&#22791;&#21463;&#20105;&#35758;&#65292;&#24182;&#19988;&#23545;&#23558;&#20854;&#24212;&#29992;&#20110;&#21307;&#23398;&#12289;&#31185;&#23398;&#12289;&#27861;&#24459;&#21644;&#25919;&#31574;&#31561;&#20855;&#26377;&#31038;&#20250;&#24433;&#21709;&#21147;&#30340;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#35752;&#20102;LLMs&#21450;&#20854;&#22240;&#26524;&#25512;&#29702;&#30340;&#21306;&#21035;&#65292;&#20197;&#21450;&#28508;&#22312;&#30340;&#24314;&#26500;&#21644;&#27979;&#37327;&#25928;&#24230;&#23041;&#32961;&#12290;&#22522;&#20110;GPT-3.5&#21644;4&#30340;&#31639;&#27861;&#22312;&#22810;&#20010;&#22240;&#26524;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;LLMs&#23637;&#31034;&#20102;&#38590;&#20197;&#39044;&#27979;&#30340;&#22833;&#36133;&#27169;&#24335;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#25216;&#26415;&#26469;&#35299;&#37322;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#38453;&#20998;&#20301;&#22240;&#23376;&#27169;&#22411;&#65292;&#38024;&#23545;&#30697;&#38453;&#22411;&#25968;&#25454;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#20248;&#21270;&#32463;&#39564;&#26680;&#25439;&#22833;&#20989;&#25968;&#20272;&#35745;&#34892;&#21644;&#21015;&#30340;&#22240;&#23376;&#31354;&#38388;&#65292;&#35777;&#26126;&#20102;&#20272;&#35745;&#20540;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#21512;&#29702;&#30340;&#22240;&#23376;&#25968;&#23545;&#30830;&#23450;&#26041;&#27861;&#65292;&#24182;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#35777;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2208.08693</link><description>&lt;p&gt;
&#30697;&#38453;&#20998;&#20301;&#22240;&#23376;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Matrix Quantile Factor Model. (arXiv:2208.08693v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#38453;&#20998;&#20301;&#22240;&#23376;&#27169;&#22411;&#65292;&#38024;&#23545;&#30697;&#38453;&#22411;&#25968;&#25454;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#20248;&#21270;&#32463;&#39564;&#26680;&#25439;&#22833;&#20989;&#25968;&#20272;&#35745;&#34892;&#21644;&#21015;&#30340;&#22240;&#23376;&#31354;&#38388;&#65292;&#35777;&#26126;&#20102;&#20272;&#35745;&#20540;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#21512;&#29702;&#30340;&#22240;&#23376;&#25968;&#23545;&#30830;&#23450;&#26041;&#27861;&#65292;&#24182;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#30340;&#30697;&#38453;&#22411;&#25968;&#25454;&#24341;&#20837;&#20102;&#30697;&#38453;&#20998;&#20301;&#22240;&#23376;&#27169;&#22411;&#12290;&#36890;&#36807;&#22312;&#25152;&#26377;&#38754;&#26495;&#19978;&#26368;&#23567;&#21270;&#32463;&#39564;&#26680;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#20272;&#35745;&#20102;&#34892;&#21644;&#21015;&#22240;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20272;&#35745;&#25910;&#25947;&#20110;&#36895;&#29575;$1/\min\{\sqrt{p_1p_2}, \sqrt{p_2T}, \sqrt{p_1T}\}$&#22312;&#24179;&#22343;Frobenius&#33539;&#25968;&#19979;&#65292;&#20854;&#20013;$p_1$&#65292;$p_2$&#21644;$T$&#20998;&#21035;&#34920;&#31034;&#30697;&#38453;&#24207;&#21015;&#30340;&#34892;&#32500;&#25968;&#12289;&#21015;&#32500;&#25968;&#21644;&#38271;&#24230;&#12290;&#35813;&#36895;&#29575;&#27604;&#23558;&#30697;&#38453;&#27169;&#22411;&#8220;&#23637;&#24179;&#8221;&#20026;&#22823;&#21521;&#37327;&#27169;&#22411;&#30340;&#20998;&#20301;&#20272;&#35745;&#36895;&#29575;&#26356;&#24555;&#12290;&#32473;&#20986;&#20102;&#24179;&#28369;&#30340;&#20272;&#35745;&#37327;&#65292;&#24182;&#22312;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#23548;&#20986;&#20102;&#23427;&#20204;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19977;&#20010;&#19968;&#33268;&#30340;&#26631;&#20934;&#26469;&#30830;&#23450;&#34892;&#21644;&#21015;&#22240;&#23376;&#25968;&#23545;&#12290;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#35777;&#30740;&#31350;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a matrix quantile factor model for matrix-valued data with a low-rank structure. We estimate the row and column factor spaces via minimizing the empirical check loss function over all panels. We show the estimates converge at rate $1/\min\{\sqrt{p_1p_2}, \sqrt{p_2T},$ $\sqrt{p_1T}\}$ in average Frobenius norm, where $p_1$, $p_2$ and $T$ are the row dimensionality, column dimensionality and length of the matrix sequence. This rate is faster than that of the quantile estimates via ``flattening" the matrix model into a large vector model. Smoothed estimates are given and their central limit theorems are derived under some mild condition. We provide three consistent criteria to determine the pair of row and column factor numbers. Extensive simulation studies and an empirical study justify our theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#24037;&#20855;&#20197;&#23454;&#29616;&#22240;&#26524;&#21457;&#29616;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#30456;&#21516;&#25968;&#25454;&#36816;&#34892;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21518;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#23548;&#33268;&#32463;&#20856;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#20445;&#35777;&#26080;&#25928;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2208.05949</link><description>&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Valid Inference after Causal Discovery. (arXiv:2208.05949v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#24037;&#20855;&#20197;&#23454;&#29616;&#22240;&#26524;&#21457;&#29616;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#30456;&#21516;&#25968;&#25454;&#36816;&#34892;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21518;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#23548;&#33268;&#32463;&#20856;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#20445;&#35777;&#26080;&#25928;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#21644;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#20004;&#20010;&#22522;&#26412;&#20219;&#21153;&#12290;&#34429;&#28982;&#24050;&#32463;&#38024;&#23545;&#27599;&#20010;&#20219;&#21153;&#21333;&#29420;&#24320;&#21457;&#20102;&#35768;&#22810;&#26041;&#27861;&#65292;&#20294;&#26159;&#21516;&#26102;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#26102;&#20250;&#20986;&#29616;&#32479;&#35745;&#19978;&#30340;&#25361;&#25112;&#65306;&#22312;&#23545;&#30456;&#21516;&#25968;&#25454;&#36816;&#34892;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21518;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#20250;&#23548;&#33268;"&#21452;&#37325;&#25361;&#36873;"&#65292;&#20174;&#32780;&#20351;&#32463;&#20856;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#20445;&#35777;&#26080;&#25928;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#38024;&#23545;&#22240;&#26524;&#21457;&#29616;&#21518;&#26377;&#25928;&#30340;&#25512;&#26029;&#24037;&#20855;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#22825;&#30495;&#32452;&#21512;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21644;&#38543;&#21518;&#25512;&#26029;&#31639;&#27861;&#20250;&#23548;&#33268;&#39640;&#24230;&#33192;&#32960;&#30340;&#35823;&#35206;&#30422;&#29575;&#65292;&#32780;&#24212;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#21017;&#25552;&#20379;&#21487;&#38752;&#30340;&#35206;&#30422;&#24182;&#23454;&#29616;&#27604;&#25968;&#25454;&#20998;&#21106;&#26356;&#20934;&#30830;&#30340;&#22240;&#26524;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery and causal effect estimation are two fundamental tasks in causal inference. While many methods have been developed for each task individually, statistical challenges arise when applying these methods jointly: estimating causal effects after running causal discovery algorithms on the same data leads to "double dipping," invalidating the coverage guarantees of classical confidence intervals. To this end, we develop tools for valid post-causal-discovery inference. Across empirical studies, we show that a naive combination of causal discovery and subsequent inference algorithms leads to highly inflated miscoverage rates; on the other hand, applying our method provides reliable coverage while achieving more accurate causal discovery than data splitting.
&lt;/p&gt;</description></item></channel></rss>