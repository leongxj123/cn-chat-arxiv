<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#30340;&#32858;&#31867;&#21450;&#24449;&#26381;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#30456;&#20851;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#22312;&#22823;&#35268;&#27169;AI&#24212;&#29992;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.02196</link><description>&lt;p&gt;
&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#30340;&#26679;&#26412;&#39640;&#25928;&#32858;&#31867;&#21450;&#24449;&#26381;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample-Efficient Clustering and Conquer Procedures for Parallel Large-Scale Ranking and Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02196
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#30340;&#32858;&#31867;&#21450;&#24449;&#26381;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#30456;&#20851;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#22312;&#22823;&#35268;&#27169;AI&#24212;&#29992;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;"&#32858;&#31867;&#21644;&#24449;&#26381;"&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#30456;&#20851;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#25171;&#30772;&#26679;&#26412;&#25928;&#29575;&#30340;&#29942;&#39048;&#12290;&#22312;&#24182;&#34892;&#35745;&#31639;&#29615;&#22659;&#20013;&#65292;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#32858;&#31867;&#21487;&#20197;&#23454;&#29616;O(p)&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20943;&#23569;&#36895;&#24230;&#65292;&#36825;&#26159;&#29702;&#35770;&#19978;&#21487;&#36798;&#21040;&#30340;&#26368;&#20339;&#20943;&#23569;&#36895;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#26159;&#36890;&#29992;&#30340;&#65292;&#22312;&#22266;&#23450;&#39044;&#31639;&#21644;&#22266;&#23450;&#31934;&#24230;&#30340;&#33539;&#24335;&#19979;&#65292;&#21487;&#20197;&#26080;&#32541;&#38598;&#25104;&#21508;&#31181;&#24120;&#35265;&#30340;&#25490;&#24207;&#21644;&#36873;&#25321;&#26041;&#27861;&#12290;&#23427;&#21487;&#20197;&#22312;&#26080;&#38656;&#39640;&#31934;&#30830;&#24230;&#30456;&#20851;&#20272;&#35745;&#21644;&#31934;&#30830;&#32858;&#31867;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#25913;&#36827;&#12290;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#20013;&#65292;&#22914;&#31070;&#32463;&#32467;&#26500;&#25628;&#32034;&#65292;&#25105;&#20204;&#30340;&#26080;&#31579;&#36873;&#29256;&#26412;&#30340;&#26041;&#27861;&#24778;&#20154;&#22320;&#36229;&#36807;&#20102;&#23436;&#20840;&#39034;&#24207;&#21270;&#30340;&#22522;&#20934;&#65292;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;&#36825;&#34920;&#26126;&#21033;&#29992;&#26377;&#20215;&#20540;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#22914;&#30456;&#20851;&#24615;&#65292;&#26159;&#32469;&#36807;&#20256;&#32479;&#26041;&#27861;&#30340;&#19968;&#26465;&#21487;&#34892;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose novel "clustering and conquer" procedures for the parallel large-scale ranking and selection (R&amp;S) problem, which leverage correlation information for clustering to break the bottleneck of sample efficiency. In parallel computing environments, correlation-based clustering can achieve an $\mathcal{O}(p)$ sample complexity reduction rate, which is the optimal reduction rate theoretically attainable. Our proposed framework is versatile, allowing for seamless integration of various prevalent R&amp;S methods under both fixed-budget and fixed-precision paradigms. It can achieve improvements without the necessity of highly accurate correlation estimation and precise clustering. In large-scale AI applications such as neural architecture search, a screening-free version of our procedure surprisingly surpasses fully-sequential benchmarks in terms of sample efficiency. This suggests that leveraging valuable structural information, such as correlation, is a viable path to bypassing the trad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#24191;&#20041;&#30697;&#37327;&#26041;&#27861;&#65288;GMM&#65289;&#26694;&#26550;&#19979;&#21464;&#37327;&#35823;&#24046;&#65288;EIV&#65289;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#21021;&#22987;&#30697;&#26465;&#20214;&#65292;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#32416;&#27491;&#21518;&#23545;EIV&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#30697;&#26465;&#20214;&#38598;&#65292;&#36825;&#20351;&#24471;GMM&#20272;&#35745;&#37327;&#26159;&#26681;&#21495;&#19979;n&#19968;&#33268;&#30340;&#65292;&#26631;&#20934;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#25552;&#20379;&#26377;&#25928;&#30340;&#25512;&#35770;&#65292;&#23545;&#20110;&#20855;&#26377;&#22810;&#20010;&#21327;&#21464;&#37327;&#21644;&#22810;&#20803;&#30340;&#65292;&#24207;&#36143;&#30456;&#20851;&#25110;&#38750;&#32463;&#20856;EIV&#30340;&#24212;&#29992;&#31243;&#24207;&#29305;&#21035;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2306.14311</link><description>&lt;p&gt;
&#27979;&#37327;&#35823;&#24046;&#20013;&#21322;&#21442;&#25968;&#27169;&#22411;&#30340;&#31616;&#21333;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Simple Estimation of Semiparametric Models with Measurement Errors. (arXiv:2306.14311v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#24191;&#20041;&#30697;&#37327;&#26041;&#27861;&#65288;GMM&#65289;&#26694;&#26550;&#19979;&#21464;&#37327;&#35823;&#24046;&#65288;EIV&#65289;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#21021;&#22987;&#30697;&#26465;&#20214;&#65292;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#32416;&#27491;&#21518;&#23545;EIV&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#30697;&#26465;&#20214;&#38598;&#65292;&#36825;&#20351;&#24471;GMM&#20272;&#35745;&#37327;&#26159;&#26681;&#21495;&#19979;n&#19968;&#33268;&#30340;&#65292;&#26631;&#20934;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#25552;&#20379;&#26377;&#25928;&#30340;&#25512;&#35770;&#65292;&#23545;&#20110;&#20855;&#26377;&#22810;&#20010;&#21327;&#21464;&#37327;&#21644;&#22810;&#20803;&#30340;&#65292;&#24207;&#36143;&#30456;&#20851;&#25110;&#38750;&#32463;&#20856;EIV&#30340;&#24212;&#29992;&#31243;&#24207;&#29305;&#21035;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24191;&#20041;&#30697;&#37327;&#26041;&#27861;&#65288;GMM&#65289;&#26694;&#26550;&#19979;&#24320;&#21457;&#20102;&#19968;&#31181;&#35299;&#20915;&#21464;&#37327;&#35823;&#24046;&#65288;EIV&#65289;&#38382;&#39064;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;EIV&#30340;&#21487;&#21464;&#24615;&#26159;&#27979;&#37327;&#35823;&#24046;&#21464;&#37327;&#30340;&#19968;&#23567;&#37096;&#20998;&#30340;&#24773;&#20917;&#65292;&#36825;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#12290;&#23545;&#20110;&#20219;&#20309;&#21021;&#22987;&#30697;&#26465;&#20214;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#32416;&#27491;&#21518;&#23545;EIV&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#30697;&#26465;&#20214;&#38598;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22522;&#20110;&#36825;&#20123;&#30697;&#30340;GMM&#20272;&#35745;&#37327;&#26159;&#26681;&#21495;&#19979;n&#19968;&#33268;&#30340;&#65292;&#26631;&#20934;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#25552;&#20379;&#26377;&#25928;&#30340;&#25512;&#35770;&#12290;&#21363;&#20351;EIV&#24456;&#22823;&#65292;&#26420;&#32032;&#20272;&#35745;&#37327;&#65288;&#24573;&#30053;EIV&#38382;&#39064;&#65289;&#21487;&#33021;&#20005;&#37325;&#20559;&#35823;&#24182;&#19988;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#20026;0&#65285;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#33021;&#22788;&#29702;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#28041;&#21450;&#38750;&#21442;&#25968;&#20272;&#35745;&#65292;&#36825;&#23545;&#20110;&#20855;&#26377;&#22810;&#20010;&#21327;&#21464;&#37327;&#21644;&#22810;&#20803;&#30340;&#65292;&#24207;&#36143;&#30456;&#20851;&#25110;&#38750;&#32463;&#20856;EIV&#30340;&#24212;&#29992;&#31243;&#24207;&#29305;&#21035;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a practical way of addressing the Errors-In-Variables (EIV) problem in the Generalized Method of Moments (GMM) framework. We focus on the settings in which the variability of the EIV is a fraction of that of the mismeasured variables, which is typical for empirical applications. For any initial set of moment conditions our approach provides a corrected set of moment conditions that are robust to the EIV. We show that the GMM estimator based on these moments is root-n-consistent, with the standard tests and confidence intervals providing valid inference. This is true even when the EIV are so large that naive estimators (that ignore the EIV problem) may be heavily biased with the confidence intervals having 0% coverage. Our approach involves no nonparametric estimation, which is particularly important for applications with multiple covariates, and settings with multivariate, serially correlated, or non-classical EIV.
&lt;/p&gt;</description></item></channel></rss>