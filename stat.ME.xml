<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#20998;&#26512;&#20102;&#22240;&#26524;&#20844;&#24179;&#24615;&#23545;&#26410;&#35266;&#23519;&#21040;&#28151;&#26434;&#30340;&#25935;&#24863;&#24615;&#65292;&#25512;&#23548;&#20986;&#22240;&#26524;&#20844;&#24179;&#24615;&#25351;&#26631;&#30340;&#30028;&#38480;&#65292;&#25552;&#20986;&#31070;&#32463;&#26694;&#26550;&#29992;&#20110;&#23398;&#20064;&#20844;&#24179;&#39044;&#27979;&#65292;&#23637;&#31034;&#20102;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;</title><link>https://arxiv.org/abs/2311.18460</link><description>&lt;p&gt;
&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#19979;&#30340;&#22240;&#26524;&#20844;&#24179;&#24615;&#65306;&#19968;&#31181;&#31070;&#32463;&#25935;&#24863;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.18460
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#20102;&#22240;&#26524;&#20844;&#24179;&#24615;&#23545;&#26410;&#35266;&#23519;&#21040;&#28151;&#26434;&#30340;&#25935;&#24863;&#24615;&#65292;&#25512;&#23548;&#20986;&#22240;&#26524;&#20844;&#24179;&#24615;&#25351;&#26631;&#30340;&#30028;&#38480;&#65292;&#25552;&#20986;&#31070;&#32463;&#26694;&#26550;&#29992;&#20110;&#23398;&#20064;&#20844;&#24179;&#39044;&#27979;&#65292;&#23637;&#31034;&#20102;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#20013;&#30340;&#20844;&#24179;&#24615;&#30001;&#20110;&#27861;&#24459;&#12289;&#36947;&#24503;&#21644;&#31038;&#20250;&#21407;&#22240;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#35201;&#27714;&#12290;&#29616;&#26377;&#24037;&#20316;&#36890;&#24120;&#38598;&#20013;&#22312;&#27809;&#26377;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#30340;&#35774;&#32622;&#19978;&#65292;&#23613;&#31649;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21487;&#33021;&#23548;&#33268;&#20005;&#37325;&#36829;&#21453;&#22240;&#26524;&#20844;&#24179;&#24615;&#65292;&#20174;&#32780;&#20135;&#29983;&#19981;&#20844;&#24179;&#30340;&#39044;&#27979;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22240;&#26524;&#20844;&#24179;&#24615;&#23545;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#19977;&#20010;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19981;&#21516;&#26469;&#28304;&#30340;&#26410;&#35266;&#23519;&#21040;&#28151;&#26434;&#19979;&#22240;&#26524;&#20844;&#24179;&#24615;&#25351;&#26631;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#20174;&#19994;&#32773;&#33021;&#22815;&#26816;&#26597;&#20854;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#22312;&#20844;&#24179;&#20851;&#38190;&#24212;&#29992;&#20013;&#30340;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#30340;&#25935;&#24863;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#20844;&#24179;&#39044;&#27979;&#30340;&#26032;&#22411;&#31070;&#32463;&#26694;&#26550;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20379;&#23545;&#22240;&#26524;&#20844;&#24179;&#24615;&#21487;&#33021;&#30001;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#32780;&#21463;&#21040;&#36829;&#21453;&#30340;&#31243;&#24230;&#30340;&#26368;&#22351;&#24773;&#20917;&#20445;&#35777;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.18460v2 Announce Type: replace-cross  Abstract: Fairness for machine learning predictions is widely required in practice for legal, ethical, and societal reasons. Existing work typically focuses on settings without unobserved confounding, even though unobserved confounding can lead to severe violations of causal fairness and, thus, unfair predictions. In this work, we analyze the sensitivity of causal fairness to unobserved confounding. Our contributions are three-fold. First, we derive bounds for causal fairness metrics under different sources of unobserved confounding. This enables practitioners to examine the sensitivity of their machine learning models to unobserved confounding in fairness-critical applications. Second, we propose a novel neural framework for learning fair predictions, which allows us to offer worst-case guarantees of the extent to which causal fairness can be violated due to unobserved confounding. Third, we demonstrate the effectiveness of our framewor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;Node2Vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#65288;&#32463;&#36807;&#24230;&#20462;&#27491;&#30340;&#65289;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;k-means&#32858;&#31867;&#26041;&#27861;&#23545;&#36825;&#20123;&#23884;&#20837;&#36827;&#34892;&#31038;&#21306;&#24674;&#22797;&#26159;&#24369;&#19968;&#33268;&#30340;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#24182;&#25506;&#35752;&#20102;&#23884;&#20837;&#22312;&#33410;&#28857;&#21644;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.17712</link><description>&lt;p&gt;
&#20351;&#29992;Node2Vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#21644;&#20998;&#31867;&#30340;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Community Detection and Classification Guarantees Using Embeddings Learned by Node2Vec. (arXiv:2310.17712v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;Node2Vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#65288;&#32463;&#36807;&#24230;&#20462;&#27491;&#30340;&#65289;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;k-means&#32858;&#31867;&#26041;&#27861;&#23545;&#36825;&#20123;&#23884;&#20837;&#36827;&#34892;&#31038;&#21306;&#24674;&#22797;&#26159;&#24369;&#19968;&#33268;&#30340;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#24182;&#25506;&#35752;&#20102;&#23884;&#20837;&#22312;&#33410;&#28857;&#21644;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#32593;&#32476;&#30340;&#33410;&#28857;&#23884;&#20837;&#21040;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#26159;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24120;&#35265;&#30446;&#26631;&#65292;&#26377;&#21508;&#31181;&#24037;&#20855;&#21487;&#29992;&#12290;&#36825;&#20123;&#23884;&#20837;&#21487;&#20197;&#29992;&#20316;&#31038;&#21306;&#26816;&#27979;/&#33410;&#28857;&#32858;&#31867;&#25110;&#38142;&#25509;&#39044;&#27979;&#31561;&#20219;&#21153;&#30340;&#29305;&#24449;&#65292;&#20854;&#24615;&#33021;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;&#38500;&#20102;&#35889;&#32858;&#31867;&#26041;&#27861;&#20043;&#22806;&#65292;&#23545;&#20110;&#20854;&#20182;&#24120;&#29992;&#30340;&#23398;&#20064;&#23884;&#20837;&#26041;&#27861;&#65292;&#32570;&#20047;&#29702;&#35770;&#19978;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#23519;&#20102;&#30001;node2vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#30340;&#29702;&#35770;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;node2vec&#29983;&#25104;&#30340;&#23884;&#20837;&#21521;&#37327;&#24212;&#29992;k-means&#32858;&#31867;&#21487;&#20197;&#23545;&#65288;&#32463;&#36807;&#24230;&#20462;&#27491;&#30340;&#65289;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#33410;&#28857;&#36827;&#34892;&#24369;&#19968;&#33268;&#30340;&#31038;&#21306;&#24674;&#22797;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#36825;&#20123;&#23884;&#20837;&#22312;&#33410;&#28857;&#21644;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20010;&#32467;&#26524;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#19982;&#32593;&#32476;&#25968;&#25454;&#30340;&#20854;&#20182;&#23884;&#20837;&#24037;&#20855;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Embedding the nodes of a large network into an Euclidean space is a common objective in modern machine learning, with a variety of tools available. These embeddings can then be used as features for tasks such as community detection/node clustering or link prediction, where they achieve state of the art performance. With the exception of spectral clustering methods, there is little theoretical understanding for other commonly used approaches to learning embeddings. In this work we examine the theoretical properties of the embeddings learned by node2vec. Our main result shows that the use of k-means clustering on the embedding vectors produced by node2vec gives weakly consistent community recovery for the nodes in (degree corrected) stochastic block models. We also discuss the use of these embeddings for node and link prediction tasks. We demonstrate this result empirically, and examine how this relates to other embedding tools for network data.
&lt;/p&gt;</description></item></channel></rss>