<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2404.00221</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#24378;&#20581;&#23398;&#20064;&#20197;&#33719;&#24471;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00221
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#30103;&#24178;&#39044;&#28041;&#21450;&#20854;&#27835;&#30103;&#20998;&#37197;&#20013;&#30340;&#21160;&#24577;&#24615;&#65292;&#27835;&#30103;&#36890;&#24120;&#20381;&#25454;&#20808;&#21069;&#27835;&#30103;&#30340;&#21382;&#21490;&#21644;&#30456;&#20851;&#29305;&#24449;&#23545;&#27599;&#20010;&#38454;&#27573;&#30340;&#25928;&#26524;&#20855;&#26377;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#32479;&#35745;&#23398;&#20064;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;(DTR)&#65292;&#26681;&#25454;&#20010;&#20307;&#30340;&#21382;&#21490;&#25351;&#23548;&#27599;&#20010;&#38454;&#27573;&#30340;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#22312;&#39034;&#24207;&#21487;&#24573;&#30053;&#24615;&#20551;&#35774;&#19979;&#23398;&#20064;&#26368;&#20339;DTR&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#39034;&#24207;&#27835;&#30103;&#20998;&#37197;&#38382;&#39064;&#65292;&#22312;&#27599;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#32467;&#21512;&#20542;&#21521;&#35780;&#20998;&#21644;&#34892;&#21160;&#20540;&#20989;&#25968;(Q&#20989;&#25968;)&#30340;&#20272;&#35745;&#37327;&#65292;&#26500;&#24314;&#20102;&#25919;&#31574;&#20215;&#20540;&#30340;&#22686;&#24378;&#21453;&#21521;&#27010;&#29575;&#21152;&#26435;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00221v1 Announce Type: cross  Abstract: Many public policies and medical interventions involve dynamics in their treatment assignments, where treatments are sequentially assigned to the same individuals across multiple stages, and the effect of treatment at each stage is usually heterogeneous with respect to the history of prior treatments and associated characteristics. We study statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's history. We propose a step-wise doubly-robust approach to learn the optimal DTR using observational data under the assumption of sequential ignorability. The approach solves the sequential treatment assignment problem through backward induction, where, at each step, we combine estimators of propensity scores and action-value functions (Q-functions) to construct augmented inverse probability weighting estimators of values of policies 
&lt;/p&gt;</description></item></channel></rss>