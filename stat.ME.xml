<rss version="2.0"><channel><title>Chat Arxiv stat.ME</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ME</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.01054</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference using surjective sequential neural likelihood estimation. (arXiv:2308.01054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01054
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#65288;SSNL&#65289;&#20272;&#35745;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#21487;&#20197;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#30340;&#27169;&#25311;&#22120;&#26102;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#12290;SSNL&#25311;&#21512;&#19968;&#20010;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#21253;&#25324;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#25110;&#21464;&#20998;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#20302;&#32500;&#31354;&#38388;&#20013;&#65292;SSNL&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#24212;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#26102;&#36935;&#21040;&#30340;&#20960;&#20010;&#38382;&#39064;&#65292;&#20363;&#22914;&#21253;&#21547;&#26080;&#20449;&#24687;&#25968;&#25454;&#32500;&#24230;&#25110;&#20301;&#20110;&#36739;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#23545;SSNL&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#34920;&#26126;&#23427;&#36890;&#24120;&#20248;&#20110;&#22312;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#20013;&#20351;&#29992;&#30340;&#29616;&#20195;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;&#19968;&#39033;&#26469;&#33258;&#22825;&#20307;&#29289;&#29702;&#23398;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#19990;&#30028;&#20363;&#23376;&#19978;&#23545;&#30913;&#22330;&#27169;&#22411;&#30340;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Surjective Sequential Neural Likelihood (SSNL) estimation, a novel method for simulation-based inference in models where the evaluation of the likelihood function is not tractable and only a simulator that can generate synthetic data is available. SSNL fits a dimensionality-reducing surjective normalizing flow model and uses it as a surrogate likelihood function which allows for conventional Bayesian inference using either Markov chain Monte Carlo methods or variational inference. By embedding the data in a low-dimensional space, SSNL solves several issues previous likelihood-based methods had when applied to high-dimensional data sets that, for instance, contain non-informative data dimensions or lie along a lower-dimensional manifold. We evaluate SSNL on a wide variety of experiments and show that it generally outperforms contemporary methods used in simulation-based inference, for instance, on a challenging real-world example from astrophysics which models the magnetic fi
&lt;/p&gt;</description></item></channel></rss>