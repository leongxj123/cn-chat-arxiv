<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;TF-Codec&#20026;&#19968;&#31181;&#36866;&#29992;&#20110;&#20302;&#24310;&#36831;&#30340;&#31471;&#21040;&#31471;&#31070;&#32463;&#35821;&#38899;&#32534;&#30721;&#22120;&#65292;&#36890;&#36807;&#28508;&#22495;&#39044;&#27979;&#32534;&#30721;&#23436;&#20840;&#28040;&#38500;&#20102;&#26102;&#38388;&#20887;&#20313;&#65292;&#37319;&#29992;&#21487;&#23398;&#20064;&#30340;&#26102;&#38388;&#39057;&#29575;&#36755;&#20837;&#21387;&#32553;&#21644;&#22522;&#20110;&#36317;&#31163;&#21040;&#36719;&#26144;&#23556;&#21644;Gumbel-Softmax&#30340;&#21487;&#24494;&#37327;&#21270;&#26041;&#26696;&#65292;&#30456;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#35821;&#38899;&#32534;&#35299;&#30721;&#22120;&#22312;&#23458;&#35266;&#21644;&#20027;&#35266;&#25351;&#26631;&#19978;&#22343;&#26377;&#26174;&#33879;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2207.08363</link><description>&lt;p&gt;
&#28508;&#22495;&#39044;&#27979;&#31070;&#32463;&#35821;&#38899;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Latent-Domain Predictive Neural Speech Coding. (arXiv:2207.08363v2 [cs.SD] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08363
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;TF-Codec&#20026;&#19968;&#31181;&#36866;&#29992;&#20110;&#20302;&#24310;&#36831;&#30340;&#31471;&#21040;&#31471;&#31070;&#32463;&#35821;&#38899;&#32534;&#30721;&#22120;&#65292;&#36890;&#36807;&#28508;&#22495;&#39044;&#27979;&#32534;&#30721;&#23436;&#20840;&#28040;&#38500;&#20102;&#26102;&#38388;&#20887;&#20313;&#65292;&#37319;&#29992;&#21487;&#23398;&#20064;&#30340;&#26102;&#38388;&#39057;&#29575;&#36755;&#20837;&#21387;&#32553;&#21644;&#22522;&#20110;&#36317;&#31163;&#21040;&#36719;&#26144;&#23556;&#21644;Gumbel-Softmax&#30340;&#21487;&#24494;&#37327;&#21270;&#26041;&#26696;&#65292;&#30456;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#35821;&#38899;&#32534;&#35299;&#30721;&#22120;&#22312;&#23458;&#35266;&#21644;&#20027;&#35266;&#25351;&#26631;&#19978;&#22343;&#26377;&#26174;&#33879;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#31070;&#32463;&#38899;&#39057;/&#35821;&#38899;&#32534;&#30721;&#23637;&#29616;&#20986;&#22312;&#36828;&#20302;&#20110;&#20256;&#32479;&#26041;&#27861;&#27604;&#29305;&#29575;&#19979;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#31070;&#32463;&#38899;&#39057;/&#35821;&#38899;&#32534;&#35299;&#30721;&#22120;&#37319;&#29992;&#22768;&#23398;&#29305;&#24449;&#25110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#30450;&#30446;&#29305;&#24449;&#36827;&#34892;&#32534;&#30721;&#65292;&#20173;&#23384;&#22312;&#32534;&#30721;&#29305;&#24449;&#20013;&#30340;&#26102;&#38388;&#20887;&#20313;&#65292;&#26412;&#25991;&#23558;&#28508;&#22495;&#39044;&#27979;&#32534;&#30721;&#24341;&#20837;VQ-VAE&#26694;&#26550;&#20013;&#65292;&#20197;&#23436;&#20840;&#28040;&#38500;&#36825;&#20123;&#20887;&#20313;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#20302;&#24310;&#36831;&#30340;&#31471;&#21040;&#31471;&#31070;&#32463;&#35821;&#38899;&#32534;&#30721;&#22120;TF-Codec&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26681;&#25454;&#36807;&#21435;&#37327;&#21270;&#28508;&#24577;&#24103;&#30340;&#39044;&#27979;&#65292;&#23545;&#25552;&#21462;&#30340;&#29305;&#24449;&#36827;&#34892;&#32534;&#30721;&#65292;&#20174;&#32780;&#36827;&#19968;&#27493;&#28040;&#38500;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#26102;&#38388;&#39057;&#29575;&#36755;&#20837;&#21387;&#32553;&#65292;&#20197;&#36866;&#24212;&#19981;&#21516;&#27604;&#29305;&#29575;&#19979;&#23545;&#20027;&#35201;&#39057;&#29575;&#21644;&#32454;&#33410;&#30340;&#20851;&#27880;&#12290;&#22522;&#20110;&#36317;&#31163;&#21040;&#36719;&#26144;&#23556;&#21644;Gumbel-Softmax&#30340;&#21487;&#24494;&#37327;&#21270;&#26041;&#26696;&#29992;&#20110;&#37327;&#21270;/&#35299;&#30721;&#28508;&#22495;&#29305;&#24449;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;TF-Codec&#22312;&#23458;&#35266;&#21644;&#20027;&#35266;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#31070;&#32463;&#35821;&#38899;&#32534;&#35299;&#30721;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural audio/speech coding has recently demonstrated its capability to deliver high quality at much lower bitrates than traditional methods. However, existing neural audio/speech codecs employ either acoustic features or learned blind features with a convolutional neural network for encoding, by which there are still temporal redundancies within encoded features. This paper introduces latent-domain predictive coding into the VQ-VAE framework to fully remove such redundancies and proposes the TF-Codec for low-latency neural speech coding in an end-to-end manner. Specifically, the extracted features are encoded conditioned on a prediction from past quantized latent frames so that temporal correlations are further removed. Moreover, we introduce a learnable compression on the time-frequency input to adaptively adjust the attention paid to main frequencies and details at different bitrates. A differentiable vector quantization scheme based on distance-to-soft mapping and Gumbel-Softmax is 
&lt;/p&gt;</description></item></channel></rss>