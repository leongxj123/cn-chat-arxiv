<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>&#26412;&#25253;&#21578;&#24341;&#20837;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#23548;&#38382;&#39064;&#20351;&#29992;&#31227;&#21160;&#24212;&#29992;&#31243;&#24207;&#25429;&#33719;&#20581;&#24247;&#25968;&#25454;&#30340;&#26032;&#30340;&#38899;&#39057;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;voice EHR&#65289;&#65292;&#21487;&#33021;&#21253;&#21547;&#22797;&#26434;&#30340;&#20581;&#24247;&#29983;&#29289;&#26631;&#24535;&#29289;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#21333;&#19968;&#27169;&#24577;&#20020;&#24202;&#25968;&#25454;&#30340;&#20856;&#22411;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2404.01620</link><description>&lt;p&gt;
Voice EHR:&#24341;&#20837;&#22810;&#27169;&#24335;&#38899;&#39057;&#25968;&#25454;&#29992;&#20110;&#20581;&#24247;
&lt;/p&gt;
&lt;p&gt;
Voice EHR: Introducing Multimodal Audio Data for Health
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01620
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25253;&#21578;&#24341;&#20837;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#23548;&#38382;&#39064;&#20351;&#29992;&#31227;&#21160;&#24212;&#29992;&#31243;&#24207;&#25429;&#33719;&#20581;&#24247;&#25968;&#25454;&#30340;&#26032;&#30340;&#38899;&#39057;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;voice EHR&#65289;&#65292;&#21487;&#33021;&#21253;&#21547;&#22797;&#26434;&#30340;&#20581;&#24247;&#29983;&#29289;&#26631;&#24535;&#29289;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#21333;&#19968;&#27169;&#24577;&#20020;&#24202;&#25968;&#25454;&#30340;&#20856;&#22411;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38899;&#39057;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#22823;&#22411;AI&#27169;&#22411;&#21487;&#33021;&#20855;&#26377;&#24555;&#36895;&#20998;&#31867;&#24739;&#32773;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;&#26089;&#26399;&#26816;&#27979;&#22686;&#24378;&#21307;&#30103;&#20915;&#31574;&#65292;&#24182;&#21487;&#33021;&#36890;&#36807;&#26089;&#26399;&#26816;&#27979;&#25913;&#21892;&#32467;&#26524;&#12290;&#29616;&#26377;&#25216;&#26415;&#20381;&#36182;&#20110;&#22312;&#39640;&#25910;&#20837;&#12289;&#33521;&#35821;&#22269;&#23478;&#20351;&#29992;&#26114;&#36149;&#35760;&#24405;&#35774;&#22791;&#30340;&#26377;&#38480;&#25968;&#25454;&#38598;&#65292;&#36825;&#31181;&#25216;&#26415;&#38754;&#20020;&#36164;&#28304;&#21463;&#38480;&#12289;&#39640;&#25910;&#20837;&#22330;&#25152;&#30340;&#37096;&#32626;&#25361;&#25112;&#65292;&#38899;&#39057;&#25968;&#25454;&#21487;&#33021;&#20855;&#26377;&#28145;&#36828;&#24433;&#21709;&#12290;&#26412;&#25253;&#21578;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#30456;&#24212;&#30340;&#25910;&#38598;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#23548;&#38382;&#39064;&#20165;&#20351;&#29992;&#31227;&#21160;&#24212;&#29992;/&#32593;&#32476;&#24212;&#29992;&#31243;&#24207;&#25429;&#33719;&#20581;&#24247;&#25968;&#25454;&#12290;&#35813;&#24212;&#29992;&#31243;&#24207;&#26368;&#32456;&#20135;&#29983;&#19968;&#20010;&#38899;&#39057;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;voice EHR&#65289;&#65292;&#23427;&#21487;&#33021;&#21253;&#21547;&#26469;&#33258;&#20256;&#32479;&#35821;&#38899;/&#21628;&#21560;&#29305;&#24449;&#12289;&#35821;&#38899;&#27169;&#24335;&#21644;&#20855;&#26377;&#35821;&#20041;&#24847;&#20041;&#30340;&#35821;&#35328;&#30340;&#22797;&#26434;&#29983;&#29289;&#26631;&#24535;&#29289;&#65292;&#34917;&#20607;&#21333;&#19968;&#27169;&#24577;&#20020;&#24202;&#25968;&#25454;&#30340;&#20856;&#22411;&#38480;&#21046;&#12290;&#26412;&#25253;&#21578;&#20171;&#32461;&#20102;&#19968;&#20010;&#21512;&#20316;&#20249;&#20276;&#36130;&#22242;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01620v1 Announce Type: cross  Abstract: Large AI models trained on audio data may have the potential to rapidly classify patients, enhancing medical decision-making and potentially improving outcomes through early detection. Existing technologies depend on limited datasets using expensive recording equipment in high-income, English-speaking countries. This challenges deployment in resource-constrained, high-volume settings where audio data may have a profound impact. This report introduces a novel data type and a corresponding collection system that captures health data through guided questions using only a mobile/web application. This application ultimately results in an audio electronic health record (voice EHR) which may contain complex biomarkers of health from conventional voice/respiratory features, speech patterns, and language with semantic meaning - compensating for the typical limitations of unimodal clinical datasets. This report introduces a consortium of partner
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#38899;&#39057;&#24674;&#22797;&#31639;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#35821;&#38899;&#22686;&#24378;&#21644;&#38899;&#20048;&#24674;&#22797;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.09821</link><description>&lt;p&gt;
&#38899;&#39057;&#24674;&#22797;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models for Audio Restoration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#38899;&#39057;&#24674;&#22797;&#31639;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#35821;&#38899;&#22686;&#24378;&#21644;&#38899;&#20048;&#24674;&#22797;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#38899;&#39057;&#25773;&#25918;&#35774;&#22791;&#21644;&#24555;&#36895;&#25968;&#25454;&#20256;&#36755;&#30340;&#21457;&#23637;&#65292;&#23545;&#39640;&#38899;&#36136;&#30340;&#38656;&#27714;&#22312;&#23089;&#20048;&#21644;&#36890;&#20449;&#39046;&#22495;&#19981;&#26029;&#22686;&#38271;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#24405;&#21046;&#36807;&#31243;&#20013;&#30340;&#22833;&#30495;&#21644;&#24178;&#25200;&#65292;&#25110;&#32773;&#30001;&#20110;&#19981;&#23436;&#21892;&#30340;&#20256;&#36755;&#31649;&#36947;&#65292;&#38899;&#39057;&#36136;&#37327;&#38754;&#20020;&#35768;&#22810;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#38899;&#39057;&#24674;&#22797;&#26041;&#27861;&#26088;&#22312;&#20174;&#25439;&#22351;&#30340;&#36755;&#20837;&#25968;&#25454;&#20013;&#24674;&#22797;&#20986;&#28165;&#26224;&#30340;&#38899;&#39057;&#20449;&#21495;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#38899;&#39057;&#24674;&#22797;&#31639;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#35821;&#38899;&#22686;&#24378;&#21644;&#38899;&#20048;&#24674;&#22797;&#20219;&#21153;&#12290;&#20256;&#32479;&#26041;&#27861;&#36890;&#24120;&#22522;&#20110;&#25163;&#24037;&#35268;&#21017;&#21644;&#32479;&#35745;&#21551;&#21457;&#27861;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#25105;&#20204;&#23545;&#38899;&#39057;&#20449;&#21495;&#30340;&#35748;&#35782;&#12290;&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#36716;&#21521;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#24314;&#27169;&#33021;&#21147;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#12290;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#25104;&#20026;&#19968;&#31181;&#26032;&#20852;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09821v1 Announce Type: cross  Abstract: With the development of audio playback devices and fast data transmission, the demand for high sound quality is rising, for both entertainment and communications. In this quest for better sound quality, challenges emerge from distortions and interferences originating at the recording side or caused by an imperfect transmission pipeline. To address this problem, audio restoration methods aim to recover clean sound signals from the corrupted input data. We present here audio restoration algorithms based on diffusion models, with a focus on speech enhancement and music restoration tasks. Traditional approaches, often grounded in handcrafted rules and statistical heuristics, have shaped our understanding of audio signals. In the past decades, there has been a notable shift towards data-driven methods that exploit the modeling capabilities of deep neural networks (DNNs). Deep generative models, and among them diffusion models, have emerged 
&lt;/p&gt;</description></item></channel></rss>