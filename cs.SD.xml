<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31471;&#21040;&#31471;TTS&#31995;&#32479;&#20013;&#65292;&#21152;&#20837;&#35821;&#35843;&#26029;&#28857;&#39044;&#27979;&#27169;&#22411;&#26159;&#21542;&#26377;&#29992;&#20197;&#21450;&#22914;&#20309;&#34913;&#37327;&#20854;&#26377;&#25928;&#24615;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#35821;&#35843;&#27169;&#22411;&#39044;&#27979;&#26029;&#28857;&#30340;&#25925;&#20107;&#27604;&#26410;&#20351;&#29992;&#39044;&#27979;&#26029;&#28857;&#30340;&#25925;&#20107;&#26356;&#21463;&#27426;&#36814;&#12290;</title><link>http://arxiv.org/abs/2304.04157</link><description>&lt;p&gt;
&#22312;&#31471;&#21040;&#31471;&#30340;TTS&#31995;&#32479;&#20013;&#65292;&#35828;&#35805;&#20154;&#29420;&#31435;&#35821;&#35843;&#26029;&#28857;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An investigation of speaker independent phrase break models in End-to-End TTS systems. (arXiv:2304.04157v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31471;&#21040;&#31471;TTS&#31995;&#32479;&#20013;&#65292;&#21152;&#20837;&#35821;&#35843;&#26029;&#28857;&#39044;&#27979;&#27169;&#22411;&#26159;&#21542;&#26377;&#29992;&#20197;&#21450;&#22914;&#20309;&#34913;&#37327;&#20854;&#26377;&#25928;&#24615;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#35821;&#35843;&#27169;&#22411;&#39044;&#27979;&#26029;&#28857;&#30340;&#25925;&#20107;&#27604;&#26410;&#20351;&#29992;&#39044;&#27979;&#26029;&#28857;&#30340;&#25925;&#20107;&#26356;&#21463;&#27426;&#36814;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25105;&#20204;&#23545;&#20110;&#31471;&#21040;&#31471;TTS&#31995;&#32479;&#20013;&#35821;&#35843;&#26029;&#28857;&#39044;&#27979;&#30340;&#30740;&#31350;&#65292;&#30740;&#31350;&#21160;&#26426;&#26159;&#65306;&#65288;&#19968;&#65289;&#22312;&#31471;&#21040;&#31471;TTS&#31995;&#32479;&#20013;&#34701;&#20837;&#26126;&#30830;&#30340;&#35821;&#35843;&#27169;&#22411;&#26159;&#21542;&#26377;&#29992;&#65311;&#65288;&#20108;&#65289;&#22914;&#20309;&#35780;&#20272;&#31471;&#21040;&#31471;TTS&#31995;&#32479;&#30340;&#35821;&#35843;&#27169;&#22411;&#26159;&#21542;&#26377;&#25928;&#65311;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23558;&#23545;&#20799;&#31461;&#25925;&#20107;&#21512;&#25104;&#30340;&#35821;&#22659;&#19979;&#30701;&#35821;&#26029;&#28857;&#39044;&#27979;&#27169;&#22411;&#30340;&#25928;&#29992;&#21644;&#26377;&#25928;&#24615;&#36827;&#34892;&#35780;&#20272;&#65292;&#20351;&#29992;&#30340;&#35780;&#20272;&#25351;&#26631;&#20026;&#21548;&#20247;&#29702;&#35299;&#24230;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#21548;&#21147;&#35780;&#20272;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;&#32463;&#36807;&#35757;&#32451;&#30340;&#35821;&#35843;&#27169;&#22411;&#39044;&#27979;&#30701;&#35821;&#26029;&#28857;&#20301;&#32622;&#21512;&#25104;&#30340;&#25925;&#20107;&#27604;&#30452;&#25509;&#21512;&#25104;&#30340;&#25925;&#20107;&#26356;&#21463;&#27426;&#36814;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents our work on phrase break prediction in the context of end-to-end TTS systems, motivated by the following questions: (i) Is there any utility in incorporating an explicit phrasing model in an end-to-end TTS system?, and (ii) How do you evaluate the effectiveness of a phrasing model in an end-to-end TTS system? In particular, the utility and effectiveness of phrase break prediction models are evaluated in in the context of childrens story synthesis, using listener comprehension. We show by means of perceptual listening evaluations that there is a clear preference for stories synthesized after predicting the location of phrase breaks using a trained phrasing model, over stories directly synthesized without predicting the location of phrase breaks.
&lt;/p&gt;</description></item></channel></rss>