<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CIF-Transducer&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23558;&#36830;&#32493;&#31215;&#20998;&#21644;&#28779;&#26426;&#21046;&#19982;RNN-T&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#23545;&#40784;&#65292;&#24182;&#25918;&#24323;&#20102;RNN-T Loss&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#65292;&#24182;&#20351;&#39044;&#27979;&#32593;&#32476;&#21457;&#25381;&#26356;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;CIF-T&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.14132</link><description>&lt;p&gt;
&#21578;&#21035;RNN-T Loss&#65306;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;CIF&#30340;&#36716;&#24405;&#22120;&#26550;&#26500;&#29992;&#20110;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition. (arXiv:2307.14132v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CIF-Transducer&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23558;&#36830;&#32493;&#31215;&#20998;&#21644;&#28779;&#26426;&#21046;&#19982;RNN-T&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#23545;&#40784;&#65292;&#24182;&#25918;&#24323;&#20102;RNN-T Loss&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#65292;&#24182;&#20351;&#39044;&#27979;&#32593;&#32476;&#21457;&#25381;&#26356;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;CIF-T&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
RNN-T&#27169;&#22411;&#22312;ASR&#20013;&#24191;&#27867;&#20351;&#29992;&#65292;&#20381;&#38752;RNN-T Loss&#23454;&#29616;&#36755;&#20837;&#38899;&#39057;&#21644;&#30446;&#26631;&#24207;&#21015;&#30340;&#38271;&#24230;&#23545;&#40784;&#12290;&#28982;&#32780;&#65292;RNN-T Loss&#30340;&#23454;&#29616;&#22797;&#26434;&#24615;&#21644;&#22522;&#20110;&#23545;&#40784;&#30340;&#20248;&#21270;&#30446;&#26631;&#23548;&#33268;&#35745;&#31639;&#20887;&#20313;&#21644;&#39044;&#27979;&#32593;&#32476;&#35282;&#33394;&#30340;&#20943;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CIF-Transducer&#65288;CIF-T&#65289;&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23427;&#23558;&#36830;&#32493;&#31215;&#20998;&#21644;&#28779;&#65288;CIF&#65289;&#26426;&#21046;&#19982;RNN-T&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#23454;&#29616;&#39640;&#25928;&#30340;&#23545;&#40784;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25918;&#24323;&#20102;RNN-T Loss&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#65292;&#24182;&#20351;&#39044;&#27979;&#32593;&#32476;&#21457;&#25381;&#26356;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;Funnel-CIF&#12289;Context Blocks&#12289;Unified Gating&#21644;Bilinear Pooling&#32852;&#21512;&#32593;&#32476;&#20197;&#21450;&#36741;&#21161;&#35757;&#32451;&#31574;&#30053;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;178&#23567;&#26102;&#30340;AISHELL-1&#21644;10000&#23567;&#26102;&#30340;WenetSpeech&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;RNN-T&#27169;&#22411;&#30456;&#27604;&#65292;CIF-T&#20197;&#26356;&#20302;&#30340;&#35745;&#31639;&#24320;&#38144;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve length alignment between input audio and target sequence. However, the implementation complexity and the alignment-based optimization target of RNN-T loss lead to computational redundancy and a reduced role for predictor network, respectively. In this paper, we propose a novel model named CIF-Transducer (CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism with the RNN-T model to achieve efficient alignment. In this way, the RNN-T loss is abandoned, thus bringing a computational reduction and allowing the predictor network a more significant role. We also introduce Funnel-CIF, Context Blocks, Unified Gating and Bilinear Pooling joint network, and auxiliary training strategy to further improve performance. Experiments on the 178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves state-of-the-art results with lower computational overhead compared to RNN-T models.
&lt;/p&gt;</description></item></channel></rss>