<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>SPMamba&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#36827;&#34892;&#35821;&#38899;&#20998;&#31163;&#30340;&#26032;&#32593;&#32476;&#26550;&#26500;&#65292;&#36890;&#36807;&#26367;&#25442;Transformer&#32452;&#20214;&#20026;Mamba&#27169;&#22359;&#65292;&#26088;&#22312;&#25552;&#39640;&#24615;&#33021;&#24182;&#20943;&#23569;&#35745;&#31639;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2404.02063</link><description>&lt;p&gt;
SPMamba&#65306;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#26159;&#35821;&#38899;&#20998;&#31163;&#20013;&#25152;&#38656;&#30340;&#19968;&#20999;
&lt;/p&gt;
&lt;p&gt;
SPMamba: State-space model is all you need in speech separation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02063
&lt;/p&gt;
&lt;p&gt;
SPMamba&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#36827;&#34892;&#35821;&#38899;&#20998;&#31163;&#30340;&#26032;&#32593;&#32476;&#26550;&#26500;&#65292;&#36890;&#36807;&#26367;&#25442;Transformer&#32452;&#20214;&#20026;Mamba&#27169;&#22359;&#65292;&#26088;&#22312;&#25552;&#39640;&#24615;&#33021;&#24182;&#20943;&#23569;&#35745;&#31639;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35821;&#38899;&#20998;&#31163;&#39046;&#22495;&#65292;CNN&#21644;Transformer&#27169;&#22411;&#37117;&#23637;&#31034;&#20102;&#31283;&#20581;&#30340;&#20998;&#31163;&#33021;&#21147;&#65292;&#24341;&#36215;&#20102;&#30740;&#31350;&#31038;&#21306;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;CNN&#30340;&#26041;&#27861;&#23545;&#20110;&#38271;&#24207;&#21015;&#38899;&#39057;&#30340;&#24314;&#27169;&#33021;&#21147;&#26377;&#38480;&#65292;&#23548;&#33268;&#20998;&#31163;&#24615;&#33021;&#19981;&#20339;&#12290;&#30456;&#21453;&#65292;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21463;&#21040;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#36827;&#34892;&#35821;&#38899;&#20998;&#31163;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#21363;SPMamba&#12290;&#25105;&#20204;&#37319;&#29992;TF-GridNet&#27169;&#22411;&#20316;&#20026;&#22522;&#30784;&#26694;&#26550;&#65292;&#24182;&#23558;&#20854;Transformer&#32452;&#20214;&#26367;&#25442;&#20026;&#19968;&#20010;&#21452;&#21521;Mamba&#27169;&#22359;&#65292;&#26088;&#22312;&#25429;&#33719;&#26356;&#24191;&#27867;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#25581;&#31034;&#20102;Mamba&#22522;&#20110;&#26041;&#27861;&#22312;&#25552;&#39640;&#24615;&#33021;&#21644;&#20943;&#23569;&#35745;&#31639;&#38656;&#27714;&#26041;&#38754;&#30340;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02063v1 Announce Type: cross  Abstract: In speech separation, both CNN- and Transformer-based models have demonstrated robust separation capabilities, garnering significant attention within the research community. However, CNN-based methods have limited modelling capability for long-sequence audio, leading to suboptimal separation performance. Conversely, Transformer-based methods are limited in practical applications due to their high computational complexity. Notably, within computer vision, Mamba-based methods have been celebrated for their formidable performance and reduced computational requirements. In this paper, we propose a network architecture for speech separation using a state-space model, namely SPMamba. We adopt the TF-GridNet model as the foundational framework and substitute its Transformer component with a bidirectional Mamba module, aiming to capture a broader range of contextual information. Our experimental results reveal an important role in the performa
&lt;/p&gt;</description></item></channel></rss>