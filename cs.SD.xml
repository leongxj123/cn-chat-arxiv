<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#27965;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#36716;&#24405;&#22120;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#35821;&#38899;&#35782;&#21035;&#20013;&#25552;&#39640;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#19981;&#24433;&#21709;&#24120;&#35265;&#21333;&#35789;&#30340;&#38169;&#35823;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.06592</link><description>&lt;p&gt;
&#33258;&#27965;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#36716;&#24405;&#22120;&#29992;&#20110;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Self-consistent context aware conformer transducer for speech recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06592
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#27965;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#36716;&#24405;&#22120;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#35821;&#38899;&#35782;&#21035;&#20013;&#25552;&#39640;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#19981;&#24433;&#21709;&#24120;&#35265;&#21333;&#35789;&#30340;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36716;&#24405;&#22120;&#30340;&#26032;&#39062;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#20026;ASR&#31995;&#32479;&#28155;&#21152;&#20102;&#19978;&#19979;&#25991;&#20449;&#24687;&#27969;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#39640;&#35782;&#21035;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#19981;&#24433;&#21709;&#24120;&#35265;&#21333;&#35789;&#30340;&#38169;&#35823;&#29575;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#24403;&#25105;&#20204;&#20351;&#29992;&#26032;&#27169;&#22411;&#21644;/&#25110;&#19982;&#19978;&#19979;&#25991;&#35821;&#35328;&#27169;&#22411;&#27973;&#24230;&#34701;&#21512;&#26102;&#65292;&#23545;&#19981;&#24120;&#35265;&#21333;&#35789;&#20934;&#30830;&#24615;&#30340;&#25913;&#21892;&#12290;&#25105;&#20204;&#21457;&#29616;&#20004;&#32773;&#30340;&#32452;&#21512;&#21487;&#20197;&#32047;&#31215;&#25552;&#39640;&#19981;&#24120;&#35265;&#21333;&#35789;&#30340;&#35782;&#21035;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel neural network architecture based on conformer transducer that adds contextual information flow to the ASR systems. Our method improves the accuracy of recognizing uncommon words while not harming the word error rate of regular words. We explore the uncommon words accuracy improvement when we use the new model and/or shallow fusion with context language model. We found that combination of both provides cumulative gain in uncommon words recognition accuracy.
&lt;/p&gt;</description></item></channel></rss>