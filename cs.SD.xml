<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#27169;&#22411;&#30340;&#21333;&#22768;&#36947;&#22810;&#20154;&#28436;&#35762;&#20998;&#31163;&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#23569;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2308.00010</link><description>&lt;p&gt;
&#21333;&#22768;&#36947;&#22810;&#20154;&#28436;&#35762;&#20998;&#31163;&#20351;&#29992;&#39640;&#25928;Transformer&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Monaural Multi-Speaker Speech Separation Using Efficient Transformer Model. (arXiv:2308.00010v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00010
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#27169;&#22411;&#30340;&#21333;&#22768;&#36947;&#22810;&#20154;&#28436;&#35762;&#20998;&#31163;&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#23569;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20154;&#32858;&#20250;&#38382;&#39064;&#26159;&#19968;&#20010;&#38590;&#20197;&#20998;&#31163;&#25110;&#21306;&#20998;&#26469;&#33258;&#20960;&#20010;&#35828;&#35805;&#32773;&#30340;&#28151;&#21512;&#35821;&#38899;&#20013;&#30340;&#20010;&#21035;&#35828;&#35805;&#32773;&#30340;&#22330;&#26223;&#12290;&#22312;&#36825;&#20010;&#39046;&#22495;&#24050;&#32463;&#36827;&#34892;&#20102;&#20960;&#39033;&#30740;&#31350;&#65292;&#20294;&#27169;&#22411;&#30340;&#22823;&#23567;&#21644;&#22797;&#26434;&#24615;&#27491;&#22312;&#19982;&#35821;&#38899;&#20998;&#31163;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#36827;&#34892;&#26435;&#34913;&#12290;"&#21333;&#22768;&#36947;&#22810;&#20154;&#28436;&#35762;&#20998;&#31163;"&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#26550;&#26500;&#21450;&#20854;&#39640;&#25928;&#24418;&#24335;&#30340;&#28436;&#35762;&#20998;&#31163;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#20351;&#29992;&#21253;&#21547;&#22810;&#26679;&#21270;&#35828;&#35805;&#32773;&#35805;&#35821;&#30340;LibriMix&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#20174;&#28151;&#21512;&#38899;&#39057;&#36755;&#20837;&#20013;&#20998;&#31163;&#20986;2&#20010;&#19981;&#21516;&#30340;&#35828;&#35805;&#32773;&#28304;&#12290;&#35813;&#27169;&#22411;&#30340;&#24320;&#21457;&#30446;&#26631;&#26159;&#20943;&#23569;&#35821;&#38899;&#20998;&#31163;&#27169;&#22411;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#19982;&#29616;&#26377;&#35821;&#38899;&#20998;&#31163;&#27169;&#22411;&#24615;&#33021;&#26368;&#23567;&#21270;&#26435;&#34913;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#35813;&#39033;&#30446;&#39044;&#35745;&#23558;&#20026;&#35821;&#38899;&#20998;&#31163;&#39046;&#22495;&#30340;&#25345;&#32493;&#30740;&#31350;&#20570;&#20986;&#36129;&#29486;&#65292;&#21516;&#26102;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cocktail party problem is the scenario where it is difficult to separate or distinguish individual speaker from a mixed speech from several speakers. There have been several researches going on in this field but the size and complexity of the model is being traded off with the accuracy and robustness of speech separation. "Monaural multi-speaker speech separation" presents a speech-separation model based on the Transformer architecture and its efficient forms. The model has been trained with the LibriMix dataset containing diverse speakers' utterances. The model separates 2 distinct speaker sources from a mixed audio input. The developed model approaches the reduction in computational complexity of the speech separation model, with minimum tradeoff with the performance of prevalent speech separation model and it has shown significant movement towards that goal. This project foresees, a rise in contribution towards the ongoing research in the field of speech separation with computationa
&lt;/p&gt;</description></item></channel></rss>