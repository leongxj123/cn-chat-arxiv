<rss version="2.0"><channel><title>Chat Arxiv cs.SD</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SD</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;BAT&#65292;&#23427;&#32467;&#21512;&#20102;&#21452;&#32819;&#22768;&#38899;&#22330;&#26223;&#20998;&#26512;&#27169;&#22411;&#30340;&#31354;&#38388;&#22768;&#38899;&#24863;&#30693;&#33021;&#21147;&#21644;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#33021;&#21147;&#65292;&#20197;&#22797;&#21046;&#20154;&#31867;&#30340;&#31354;&#38388;&#22768;&#38899;&#25512;&#29702;&#33021;&#21147;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#30340;&#21452;&#32819;&#38899;&#39057;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#31354;&#38388;&#22768;&#38899;&#30340;&#38382;&#31572;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;BAT&#22312;&#31354;&#38388;&#22768;&#38899;&#24863;&#30693;&#21644;&#25512;&#29702;&#26041;&#38754;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01591</link><description>&lt;p&gt;
BAT: &#20351;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#20851;&#20110;&#31354;&#38388;&#22768;&#38899;&#30340;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
BAT: Learning to Reason about Spatial Sounds with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;BAT&#65292;&#23427;&#32467;&#21512;&#20102;&#21452;&#32819;&#22768;&#38899;&#22330;&#26223;&#20998;&#26512;&#27169;&#22411;&#30340;&#31354;&#38388;&#22768;&#38899;&#24863;&#30693;&#33021;&#21147;&#21644;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#33021;&#21147;&#65292;&#20197;&#22797;&#21046;&#20154;&#31867;&#30340;&#31354;&#38388;&#22768;&#38899;&#25512;&#29702;&#33021;&#21147;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#30340;&#21452;&#32819;&#38899;&#39057;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#31354;&#38388;&#22768;&#38899;&#30340;&#38382;&#31572;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;BAT&#22312;&#31354;&#38388;&#22768;&#38899;&#24863;&#30693;&#21644;&#25512;&#29702;&#26041;&#38754;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31354;&#38388;&#22768;&#38899;&#25512;&#29702;&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#20154;&#31867;&#25216;&#33021;&#65292;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#22768;&#38899;&#26469;&#23548;&#33322;&#21644;&#35299;&#37322;&#25105;&#20204;&#30340;&#21608;&#22260;&#29615;&#22659;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;BAT&#65292;&#23427;&#23558;&#21452;&#32819;&#22768;&#38899;&#22330;&#26223;&#20998;&#26512;&#27169;&#22411;&#30340;&#31354;&#38388;&#22768;&#38899;&#24863;&#30693;&#33021;&#21147;&#19982;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#33021;&#21147;&#30456;&#32467;&#21512;&#65292;&#20197;&#22797;&#21046;&#36825;&#31181;&#22266;&#26377;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#29616;&#26377;&#37326;&#22806;&#31354;&#38388;&#22768;&#38899;&#25968;&#25454;&#38598;&#30340;&#32570;&#20047;&#65292;&#25105;&#20204;&#20351;&#29992;AudioSet&#21644;SoundSpaces 2.0&#21512;&#25104;&#20102;&#19968;&#20010;&#21452;&#32819;&#38899;&#39057;&#25968;&#25454;&#38598;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#22768;&#38899;&#30340;&#38382;&#31572;&#25968;&#25454;&#38598;SpatialSoundQA&#65292;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;QA&#20219;&#21153;&#65292;&#20197;&#35757;&#32451;BAT&#22312;&#31354;&#38388;&#22768;&#38899;&#24863;&#30693;&#21644;&#25512;&#29702;&#30340;&#21508;&#20010;&#26041;&#38754;&#12290;BAT&#30340;&#22768;&#23398;&#21069;&#31471;&#32534;&#30721;&#22120;&#26159;&#19968;&#31181;&#21517;&#20026;Spatial Audio Spectrogram Transformer&#65288;Spatial-AST&#65289;&#30340;&#21019;&#26032;&#31354;&#38388;&#38899;&#39057;&#32534;&#30721;&#22120;&#65292;&#23427;&#26412;&#36523;&#22312;&#22768;&#38899;&#20107;&#20214;&#26816;&#27979;&#12289;&#31354;&#38388;&#23450;&#20301;&#21644;&#36317;&#31163;&#20272;&#35745;&#31561;&#26041;&#38754;&#20855;&#26377;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#23558;Spatial-AST&#19982;LLaMA-2 7B&#38598;&#25104;&#65292;
&lt;/p&gt;
&lt;p&gt;
Spatial sound reasoning is a fundamental human skill, enabling us to navigate and interpret our surroundings based on sound. In this paper we present BAT, which combines the spatial sound perception ability of a binaural acoustic scene analysis model with the natural language reasoning capabilities of a large language model (LLM) to replicate this innate ability. To address the lack of existing datasets of in-the-wild spatial sounds, we synthesized a binaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed SpatialSoundQA, a spatial sound-based question-answering dataset, offering a range of QA tasks that train BAT in various aspects of spatial sound perception and reasoning. The acoustic front end encoder of BAT is a novel spatial audio encoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by itself achieves strong performance across sound event detection, spatial localization, and distance estimation. By integrating Spatial-AST with LLaMA-2 7B
&lt;/p&gt;</description></item><item><title>STAR&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;Transformer&#27169;&#22411;&#65292;&#36890;&#36807;&#21160;&#24577;&#21387;&#32553;&#21644;&#20248;&#21270;&#24310;&#36831;&#12289;&#20869;&#23384;&#21344;&#29992;&#21644;&#36136;&#37327;&#65292;&#23454;&#29616;&#23545;&#27969;&#30340;&#39640;&#25928;&#24207;&#21015;&#36716;&#23548;&#65292;&#24182;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#39046;&#22495;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01172</link><description>&lt;p&gt;
&#27969;&#24335;&#24207;&#21015;&#36716;&#23548;&#36890;&#36807;&#21160;&#24577;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Streaming Sequence Transduction through Dynamic Compression
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01172
&lt;/p&gt;
&lt;p&gt;
STAR&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;Transformer&#27169;&#22411;&#65292;&#36890;&#36807;&#21160;&#24577;&#21387;&#32553;&#21644;&#20248;&#21270;&#24310;&#36831;&#12289;&#20869;&#23384;&#21344;&#29992;&#21644;&#36136;&#37327;&#65292;&#23454;&#29616;&#23545;&#27969;&#30340;&#39640;&#25928;&#24207;&#21015;&#36716;&#23548;&#65292;&#24182;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#39046;&#22495;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;STAR&#65288;&#24102;&#26377;&#38170;&#23450;&#34920;&#31034;&#30340;&#27969;&#24335;&#36716;&#23548;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;&#27969;&#30340;&#39640;&#25928;&#24207;&#21015;&#36716;&#23548;&#12290;STAR&#21160;&#24577;&#22320;&#23545;&#36755;&#20837;&#27969;&#36827;&#34892;&#20998;&#27573;&#65292;&#21019;&#24314;&#21387;&#32553;&#30340;&#38170;&#23450;&#34920;&#31034;&#65292;&#23454;&#29616;&#36817;&#20046;&#26080;&#25439;&#30340;&#21387;&#32553;&#65288;12&#20493;&#65289;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#20013;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;STAR&#22312;&#21516;&#26102;&#36827;&#34892;&#35821;&#38899;&#21040;&#25991;&#26412;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20248;&#36234;&#30340;&#20998;&#21106;&#21644;&#24310;&#36831;-&#36136;&#37327;&#25240;&#34935;&#65292;&#20248;&#21270;&#24310;&#36831;&#12289;&#20869;&#23384;&#21344;&#29992;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce STAR (Stream Transduction with Anchor Representations), a novel Transformer-based model designed for efficient sequence-to-sequence transduction over streams. STAR dynamically segments input streams to create compressed anchor representations, achieving nearly lossless compression (12x) in Automatic Speech Recognition (ASR) and outperforming existing methods. Moreover, STAR demonstrates superior segmentation and latency-quality trade-offs in simultaneous speech-to-text tasks, optimizing latency, memory footprint, and quality.
&lt;/p&gt;</description></item><item><title>WikiMT++&#26159;&#19968;&#20010;&#25193;&#23637;&#21644;&#31934;&#32454;&#29256;&#26412;&#30340;WikiMusicText&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#20102;1010&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;ABC&#35760;&#35889;&#27861;&#30340;&#20027;&#39064;&#26354;&#12290;&#23427;&#28155;&#21152;&#20102;&#23458;&#35266;&#23646;&#24615;&#21644;&#20027;&#35266;&#24773;&#24863;&#23646;&#24615;&#65292;&#22686;&#24378;&#20102;&#25968;&#25454;&#38598;&#30340;&#24212;&#29992;&#22330;&#26223;&#21644;&#21487;&#29992;&#24615;&#65292;&#24182;&#36890;&#36807;CLaMP&#26469;&#32416;&#27491;&#23646;&#24615;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13259</link><description>&lt;p&gt;
WikiMT++&#25968;&#25454;&#38598;&#21345;&#29255;
&lt;/p&gt;
&lt;p&gt;
WikiMT++ Dataset Card. (arXiv:2309.13259v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13259
&lt;/p&gt;
&lt;p&gt;
WikiMT++&#26159;&#19968;&#20010;&#25193;&#23637;&#21644;&#31934;&#32454;&#29256;&#26412;&#30340;WikiMusicText&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#20102;1010&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;ABC&#35760;&#35889;&#27861;&#30340;&#20027;&#39064;&#26354;&#12290;&#23427;&#28155;&#21152;&#20102;&#23458;&#35266;&#23646;&#24615;&#21644;&#20027;&#35266;&#24773;&#24863;&#23646;&#24615;&#65292;&#22686;&#24378;&#20102;&#25968;&#25454;&#38598;&#30340;&#24212;&#29992;&#22330;&#26223;&#21644;&#21487;&#29992;&#24615;&#65292;&#24182;&#36890;&#36807;CLaMP&#26469;&#32416;&#27491;&#23646;&#24615;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
WikiMT++&#26159;WikiMusicText&#65288;WikiMT&#65289;&#30340;&#25193;&#23637;&#21644;&#31934;&#32454;&#29256;&#26412;&#65292;&#21253;&#21547;&#20102;1010&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;ABC&#35760;&#35889;&#27861;&#30340;&#20027;&#39064;&#26354;&#12290;&#20026;&#20102;&#25193;&#23637;WikiMT&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#25105;&#20204;&#28155;&#21152;&#20102;&#23458;&#35266;&#23646;&#24615;&#65288;&#19987;&#36753;&#12289;&#27468;&#35789;&#12289;&#35270;&#39057;&#65289;&#21644;&#20027;&#35266;&#24773;&#24863;&#23646;&#24615;&#65288;12&#20010;&#24773;&#24863;&#24418;&#23481;&#35789;&#65289;&#21644;&#24773;&#24863;4Q&#65288;Russell 4Q&#65289;&#65292;&#22686;&#24378;&#20102;&#20854;&#22312;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#12289;&#26465;&#20214;&#38899;&#20048;&#29983;&#25104;&#12289;&#33258;&#21160;&#20316;&#26354;&#21644;&#24773;&#24863;&#20998;&#31867;&#31561;&#26041;&#38754;&#30340;&#21487;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23454;&#29616;&#20102;CLaMP&#26469;&#32416;&#27491;&#20174;WikiMT&#32487;&#25215;&#30340;&#23646;&#24615;&#65292;&#20197;&#20943;&#23569;&#21407;&#22987;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20013;&#24341;&#20837;&#30340;&#38169;&#35823;&#65292;&#22686;&#24378;&#20102;&#25968;&#25454;&#38598;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT), featuring 1010 curated lead sheets in ABC notation. To expand application scenarios of WikiMT, we add both objective (album, lyrics, video) and subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes, enhancing its usability for music information retrieval, conditional music generation, automatic composition, and emotion classification, etc. Additionally, CLaMP is implemented to correct the attributes inherited from WikiMT to reduce errors introduced during original data collection and enhance the accuracy and completeness of our dataset.
&lt;/p&gt;</description></item></channel></rss>