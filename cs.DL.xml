<rss version="2.0"><channel><title>Chat Arxiv cs.DL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DL</description><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#31185;&#23398;&#25968;&#25454;&#25991;&#26723;&#22914;&#20309;&#28385;&#36275;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#21644;&#30417;&#31649;&#26426;&#26500;&#23545;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20013;&#20351;&#29992;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#22871;&#24314;&#35758;&#25351;&#21335;&#12290;</title><link>http://arxiv.org/abs/2401.10304</link><description>&lt;p&gt;
&#35770;&#31185;&#23398;&#25968;&#25454;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20844;&#27491;&#21644;&#36879;&#26126;&#20351;&#29992;&#30340;&#20934;&#22791;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
On the Readiness of Scientific Data for a Fair and Transparent Use in Machine Learning. (arXiv:2401.10304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#31185;&#23398;&#25968;&#25454;&#25991;&#26723;&#22914;&#20309;&#28385;&#36275;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#21644;&#30417;&#31649;&#26426;&#26500;&#23545;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20013;&#20351;&#29992;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#22871;&#24314;&#35758;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#30830;&#20445;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#21644;&#21487;&#20449;&#24615;&#65292;&#26368;&#36817;&#30340;&#31435;&#27861;&#20030;&#25514;&#21644;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#30340;&#30456;&#20851;&#30740;&#31350;&#25351;&#20986;&#38656;&#35201;&#35760;&#24405;&#29992;&#20110;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#23454;&#29616;&#21487;&#37325;&#22797;&#24615;&#65292;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#30340;&#25968;&#25454;&#20849;&#20139;&#23454;&#36341;&#36817;&#24180;&#26469;&#20063;&#26377;&#20102;&#21457;&#23637;&#12290;&#22312;&#36825;&#20010;&#24847;&#20041;&#19978;&#65292;&#23398;&#26415;&#26426;&#26500;&#37319;&#29992;&#20102;&#36825;&#20123;&#23454;&#36341;&#65292;&#40723;&#21169;&#30740;&#31350;&#20154;&#21592;&#23558;&#20182;&#20204;&#30340;&#25968;&#25454;&#21644;&#25216;&#26415;&#25991;&#20214;&#21457;&#24067;&#22312;&#21516;&#34892;&#35780;&#35758;&#30340;&#20986;&#29256;&#29289;&#19978;&#65292;&#22914;&#25968;&#25454;&#35770;&#25991;&#12290;&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#31185;&#23398;&#25968;&#25454;&#25991;&#26723;&#22914;&#20309;&#28385;&#36275;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#21644;&#30417;&#31649;&#26426;&#26500;&#23545;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20013;&#20351;&#29992;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#23545;4041&#31687;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#35770;&#25991;&#26679;&#26412;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#35780;&#20272;&#20854;&#23436;&#25972;&#24615;&#21644;&#35206;&#30422;&#33539;&#22260;&#65292;&#24182;&#30740;&#31350;&#20102;&#36817;&#24180;&#26469;&#30340;&#36235;&#21183;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#26368;&#22810;&#21644;&#26368;&#23569;&#34987;&#35760;&#24405;&#30340;&#26041;&#38754;&#12290;&#20316;&#20026;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#22871;&#25968;&#25454;&#21019;&#24314;&#32773;&#30340;&#24314;&#35758;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
To ensure the fairness and trustworthiness of machine learning (ML) systems, recent legislative initiatives and relevant research in the ML community have pointed out the need to document the data used to train ML models. Besides, data-sharing practices in many scientific domains have evolved in recent years for reproducibility purposes. In this sense, the adoption of these practices by academic institutions has encouraged researchers to publish their data and technical documentation in peer-reviewed publications such as data papers. In this study, we analyze how this scientific data documentation meets the needs of the ML community and regulatory bodies for its use in ML technologies. We examine a sample of 4041 data papers of different domains, assessing their completeness and coverage of the requested dimensions, and trends in recent years, putting special emphasis on the most and least documented dimensions. As a result, we propose a set of recommendation guidelines for data creato
&lt;/p&gt;</description></item></channel></rss>