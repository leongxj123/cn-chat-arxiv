# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [BERT-Enhanced Retrieval Tool for Homework Plagiarism Detection System](https://arxiv.org/abs/2404.01582) | 本文提出了一种基于GPT-3.5的抄袭文本数据生成方法和一种基于Faiss和BERT的高效高准确性的抄袭识别方法，填补了高水平抄袭检测研究数据集缺失的空白，实验证明该模型在多个指标上表现优异 |
| [^2] | [Enhancing Content-based Recommendation via Large Language Model](https://arxiv.org/abs/2404.00236) | 本文提出了一种名为LoID的语义知识传递方法，旨在提取多方面的语义信息以增强不同领域，并对齐用户/项目ID和内容语义特征空间。 |
| [^3] | [LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning](https://arxiv.org/abs/2404.00027) | 探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。 |
| [^4] | [Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs](https://arxiv.org/abs/2404.00026) | 研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。 |
| [^5] | [Large Language Models in Biomedical and Health Informatics: A Bibliometric Review](https://arxiv.org/abs/2403.16303) | LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。 |
| [^6] | [Emotion Detection with Transformers: A Comparative Study](https://arxiv.org/abs/2403.15454) | 本研究探索了在文本数据情感分类中应用基于Transformer的模型，并发现常用技术如去除标点符号和停用词可能会阻碍模型的性能，因为这些元素仍然能够传达情感或强调，而Transformer的优势在于理解文本内的语境关系。 |
| [^7] | [Extracting Emotion Phrases from Tweets using BART](https://arxiv.org/abs/2403.14050) | 本文提出了一种基于BART的情感分析方法，利用问答框架从文本中提取特定情绪短语，并通过分类器预测答案跨度位置，实现对情绪短语的精确提取。 |
| [^8] | [Authorship Style Transfer with Policy Optimization](https://arxiv.org/abs/2403.08043) | 提出了一种简单的两步调整和优化技术，用于低资源文本风格转移，在作者转移和母语风格任务方面均优于最先进的基准模型。 |
| [^9] | [HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy](https://arxiv.org/abs/2403.05574) | 这一创新心理治疗模型HealMe通过基于心理治疗框架的共情对话，有效解决了根深蒂固的负面思维，并促进了理性、平衡的观点。 |
| [^10] | [RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records](https://arxiv.org/abs/2403.00815) | RAM-EHR通过增强检索并利用总结知识，提高了针对电子健康记录的临床预测效果。 |
| [^11] | [Technical Report on the Checkfor.ai AI-Generated Text Classifier](https://arxiv.org/abs/2402.14873) | Checkfor.ai AI生成文本分类器在区分大型语言模型生成文本和人类编写文本方面表现优异，提出了硬负挖掘与合成镜像训练算法，具有高准确性和泛化能力。 |
| [^12] | [Agent-OM: Leveraging LLM Agents for Ontology Matching](https://arxiv.org/abs/2312.00326) | 本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。 |
| [^13] | [Red Teaming Game: A Game-Theoretic Framework for Red Teaming Language Models.](http://arxiv.org/abs/2310.00322) | 本文提出了红队游戏（RTG）框架，利用博弈论分析了红队语言模型（RLM）与蓝队语言模型（BLM）之间的多轮攻防互动。同时引入了游戏化红队求解器（GRTS）来提供自动化的红队技术。 |
| [^14] | [MVMR: Evaluating Natural Language Video Localization Bias over Multiple Reliable Videos Pool.](http://arxiv.org/abs/2309.16701) | 本文提出了一个名为MVMR的任务，旨在给定文本查询从大量视频集中定位视频帧。我们通过已有数据集进行相似性筛选来构建数据集，并引入三个MVMR数据集。我们采用了嵌入式文本相似度匹配和视频-语言对齐技术来计算相关性得分，并为MVMR任务开发了一个强大的模型，Reliable Mutual Matching Network (RMMN)。 |
| [^15] | [LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins.](http://arxiv.org/abs/2309.10254) | 本文提出了一个框架，用于分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性。在应用框架于OpenAI的插件生态系统时，我们发现了一些具体证明了潜在问题的插件。 |
| [^16] | [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes.](http://arxiv.org/abs/2309.00237) | 使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。 |
| [^17] | [Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive Summarization.](http://arxiv.org/abs/2308.02270) | 本文提出了一种冗余感知的Sem-nCG度量，用于评估模型摘要与多个参考摘要进行对比。实验结果表明，这种新度量具有更高的相关性。 |
| [^18] | [Instruction Mining: High-Quality Instruction Data Selection for Large Language Models.](http://arxiv.org/abs/2307.06290) | 本文提出了InstructMining，一种用于选择高质量指令数据的线性规则，以增强大语言模型的解释和响应指令能力。通过特定的自然语言指标建模，研究结果表明，即使只有少量高质量的指令跟随数据，语言模型也可以进行良好的微调。 |
| [^19] | [Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding.](http://arxiv.org/abs/2307.05908) | 本论文提出了一种预测性流水线解码（PPD）方法，通过并行启动后续令牌解码来加速大型语言模型（LLMs）中的贪婪解码过程，同时保持完全相同的输出。该方法在减少解码延迟方面具有潜力，提供了新的LLM解码策略权衡理解。 |
| [^20] | [Personality testing of GPT-3: Limited temporal reliability, but highlighted social desirability of GPT-3's personality instruments results.](http://arxiv.org/abs/2306.04308) | 本研究探讨了GPT-3 Davinci-003聊天机器人的人格特质，发现其具有良好的社交渴望和亲社会特质，但在不同时间的一致性存在限制。 |
| [^21] | [InstructIE: A Chinese Instruction-based Information Extraction Dataset.](http://arxiv.org/abs/2305.11527) | 介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。 |
| [^22] | [Cost-efficient Crowdsourcing for Span-based Sequence Labeling: Worker Selection and Data Augmentation.](http://arxiv.org/abs/2305.06683) | 本文介绍了面向基于跨度的序列标注任务的成本效益众包算法，使用了组合多臂老虎机方法进行工人选择，并用移位、扩展和收缩的数据增强方法进行测试，提高了注释质量和降低成本，F1得分相对于仅专家的基线提高了100.04％，成本节约高达65.97％。 |

# 详细

[^1]: 基于BERT增强的作业抄袭检测系统

    BERT-Enhanced Retrieval Tool for Homework Plagiarism Detection System

    [https://arxiv.org/abs/2404.01582](https://arxiv.org/abs/2404.01582)

    本文提出了一种基于GPT-3.5的抄袭文本数据生成方法和一种基于Faiss和BERT的高效高准确性的抄袭识别方法，填补了高水平抄袭检测研究数据集缺失的空白，实验证明该模型在多个指标上表现优异

    

    文本抄袭检测任务是一项常见的自然语言处理任务，旨在检测给定文本是否包含从其他文本中抄袭或复制的内容。在现有研究中，由于缺乏高质量的数据集，检测高水平的抄袭仍然是一个挑战。本文提出了一种基于GPT-3.5的抄袭文本数据生成方法，产生了32,927对文本抄袭检测数据集，涵盖了各种抄袭方法，填补了这一研究领域的空白。同时，我们提出了一种基于Faiss和BERT的高效高准确性的抄袭识别方法。我们的实验证明，这种模型在准确率、精确率、召回率和F1分数等多个指标上的表现优于其他模型，分别达到了98.86％、98.90％、98.86％和0.9888。最后，我们还提供了一个用户友好的演示平台，允许用户上传文本。

    arXiv:2404.01582v1 Announce Type: cross  Abstract: Text plagiarism detection task is a common natural language processing task that aims to detect whether a given text contains plagiarism or copying from other texts. In existing research, detection of high level plagiarism is still a challenge due to the lack of high quality datasets. In this paper, we propose a plagiarized text data generation method based on GPT-3.5, which produces 32,927 pairs of text plagiarism detection datasets covering a wide range of plagiarism methods, bridging the gap in this part of research. Meanwhile, we propose a plagiarism identification method based on Faiss with BERT with high efficiency and high accuracy. Our experiments show that the performance of this model outperforms other models in several metrics, including 98.86\%, 98.90%, 98.86%, and 0.9888 for Accuracy, Precision, Recall, and F1 Score, respectively. At the end, we also provide a user-friendly demo platform that allows users to upload a text 
    
[^2]: 通过大型语言模型增强基于内容的推荐

    Enhancing Content-based Recommendation via Large Language Model

    [https://arxiv.org/abs/2404.00236](https://arxiv.org/abs/2404.00236)

    本文提出了一种名为LoID的语义知识传递方法，旨在提取多方面的语义信息以增强不同领域，并对齐用户/项目ID和内容语义特征空间。

    

    在现实世界的应用中，用户在与不同项目互动时表现出不同的行为，包括隐式的点击/点赞互动以及显式的评论/评价互动。然而，几乎所有的推荐工作都集中在如何通过隐式的点击/点赞互动来描述用户偏好，以找到人们之间的协同。对于基于内容的显式评论/评价互动，一些工作尝试利用它们来挖掘语义知识以增强推荐模型。然而，它们仍然忽视了以下两点：（1）内容语义是普适的世界知识；我们如何提取多方面的语义信息以增强不同领域？（2）用户/项目ID特征是推荐模型的基础要素；我们如何对齐ID和内容语义特征空间？在本文中，我们提出了一种“插件”语义知识传递方法LoID。

    arXiv:2404.00236v1 Announce Type: cross  Abstract: In real-world applications, users express different behaviors when they interact with different items, including implicit click/like interactions, and explicit comments/reviews interactions. Nevertheless, almost all recommender works are focused on how to describe user preferences by the implicit click/like interactions, to find the synergy of people. For the content-based explicit comments/reviews interactions, some works attempt to utilize them to mine the semantic knowledge to enhance recommender models. However, they still neglect the following two points: (1) The content semantic is a universal world knowledge; how do we extract the multi-aspect semantic information to empower different domains? (2) The user/item ID feature is a fundamental element for recommender models; how do we align the ID and content semantic feature space? In this paper, we propose a `plugin' semantic knowledge transferring method \textbf{LoID}, which inclu
    
[^3]: LLM作为写作助手：探讨所有权感和推理的视角

    LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning

    [https://arxiv.org/abs/2404.00027](https://arxiv.org/abs/2404.00027)

    探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。

    

    写作中的所有权感限制了我们对思想、时间和贡献的投入，导致对产出物的依恋。然而，使用写作助手引入了一种心理困境，因为一些内容并非直接我们的创作。我们往往更倾向于在创造性任务中更多地归功于大型语言模型（LLMs），尽管它们对所有任务都是平等的。此外，虽然我们可能不会完全声称对由LLM生成的内容拥有所有权，但却自由地声称作者身份。我们进行了一项简短调查来研究这些问题，并了解潜在的认知过程，以更好地了解人机交互在写作中的应用并改进写作辅助系统。

    arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
    
[^4]: 墨水与个性：在LLMs时代塑造个性化叙事

    Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs

    [https://arxiv.org/abs/2404.00026](https://arxiv.org/abs/2404.00026)

    研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。

    

    个性和个性化构成了使每个作家独特并影响其文字以有效吸引读者同时传达真实性的独特特征。然而，我们日益依赖基于LLM的写作助手可能会危及我们的创造力和个性。我们经常忽视这一趋势对我们的创造力和独特性的负面影响，尽管可能会造成后果。本研究通过进行简要调查探索不同的观点和概念，以及尝试理解人们的观点，结合以往在该领域的研究，来研究这些问题。解决这些问题对于改进人机交互系统和增强个性化和个性化写作助手至关重要。

    arXiv:2404.00026v1 Announce Type: cross  Abstract: Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality.
    
[^5]: 生物医学与健康信息学中的大型语言模型：一项文献计量学综述

    Large Language Models in Biomedical and Health Informatics: A Bibliometric Review

    [https://arxiv.org/abs/2403.16303](https://arxiv.org/abs/2403.16303)

    LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。

    

    大型语言模型（LLMs）迅速成为生物医学与健康信息学（BHI）中的重要工具，为分析数据、治疗患者和开展研究提供了新的方式。本文献计量学综述旨在通过检查自2022年至2023年的研究文章和合作网络，全面展示LLMs在BHI中的应用情况。它进一步探讨了LLMs如何可以改进各种BHI领域中的自然语言处理（NLP）应用，如医学诊断、患者参与、电子健康记录管理和个性化医学。为此，我们的文献计量学综述确定了关键趋势，绘制了研究网络，并突出了这个快速发展领域的主要进展。最后，它讨论了在BHI中使用LLMs的伦理关切和实际挑战，如数据隐私和可靠的医疗建议。展望未来，我们考虑LLMs如何进一步改变生物医学研究。

    arXiv:2403.16303v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have rapidly become important tools in Biomedical and Health Informatics (BHI), enabling new ways to analyze data, treat patients, and conduct research. This bibliometric review aims to provide a panoramic view of how LLMs have been used in BHI by examining research articles and collaboration networks from 2022 to 2023. It further explores how LLMs can improve Natural Language Processing (NLP) applications in various BHI areas like medical diagnosis, patient engagement, electronic health record management, and personalized medicine. To do this, our bibliometric review identifies key trends, maps out research networks, and highlights major developments in this fast-moving field. Lastly, it discusses the ethical concerns and practical challenges of using LLMs in BHI, such as data privacy and reliable medical recommendations. Looking ahead, we consider how LLMs could further transform biomedical research as we
    
[^6]: 使用Transformer进行情感检测：一项比较研究

    Emotion Detection with Transformers: A Comparative Study

    [https://arxiv.org/abs/2403.15454](https://arxiv.org/abs/2403.15454)

    本研究探索了在文本数据情感分类中应用基于Transformer的模型，并发现常用技术如去除标点符号和停用词可能会阻碍模型的性能，因为这些元素仍然能够传达情感或强调，而Transformer的优势在于理解文本内的语境关系。

    

    在这项研究中，我们探讨了基于Transformer模型在文本数据情感分类中的应用。我们使用不同变体的Transformer对Emotion数据集进行训练和评估。论文还分析了一些影响模型性能的因素，比如Transformer层的微调、层的可训练性以及文本数据的预处理。我们的分析表明，常用技术如去除标点符号和停用词可能会阻碍模型的性能。这可能是因为Transformer的优势在于理解文本内的语境关系。像标点符号和停用词这样的元素仍然可以传达情感或强调，去除它们可能会破坏这种上下文。

    arXiv:2403.15454v1 Announce Type: new  Abstract: In this study, we explore the application of transformer-based models for emotion classification on text data. We train and evaluate several pre-trained transformer models, on the Emotion dataset using different variants of transformers. The paper also analyzes some factors that in-fluence the performance of the model, such as the fine-tuning of the transformer layer, the trainability of the layer, and the preprocessing of the text data. Our analysis reveals that commonly applied techniques like removing punctuation and stop words can hinder model performance. This might be because transformers strength lies in understanding contextual relationships within text. Elements like punctuation and stop words can still convey sentiment or emphasis and removing them might disrupt this context.
    
[^7]: 使用BART从推文中提取情绪短语

    Extracting Emotion Phrases from Tweets using BART

    [https://arxiv.org/abs/2403.14050](https://arxiv.org/abs/2403.14050)

    本文提出了一种基于BART的情感分析方法，利用问答框架从文本中提取特定情绪短语，并通过分类器预测答案跨度位置，实现对情绪短语的精确提取。

    

    情感分析是一项旨在识别和提取文本中情绪方面的自然语言处理任务。然而，许多现有的情感分析方法主要是对文本的整体极性进行分类，忽略了传达情绪的具体短语。在本文中，我们应用了一种基于问答框架的情感分析方法。我们利用双向自回归变换器（BART），一个预训练的序列到序列模型，从给定文本中提取放大给定情感极性的短语。我们创建一个自然语言问题，确定要提取的特定情绪，然后引导BART专注于文本中相关的情感线索。我们在BART中使用一个分类器来预测文本中答案跨度的开始和结束位置，从而帮助确定提取的情绪短语的精确边界。

    arXiv:2403.14050v2 Announce Type: replace  Abstract: Sentiment analysis is a natural language processing task that aims to identify and extract the emotional aspects of a text. However, many existing sentiment analysis methods primarily classify the overall polarity of a text, overlooking the specific phrases that convey sentiment. In this paper, we applied an approach to sentiment analysis based on a question-answering framework. Our approach leverages the power of Bidirectional Autoregressive Transformer (BART), a pre-trained sequence-to-sequence model, to extract a phrase from a given text that amplifies a given sentiment polarity. We create a natural language question that identifies the specific emotion to extract and then guide BART to pay attention to the relevant emotional cues in the text. We use a classifier within BART to predict the start and end positions of the answer span within the text, which helps to identify the precise boundaries of the extracted emotion phrase. Our
    
[^8]: 基于策略优化的作者风格转移

    Authorship Style Transfer with Policy Optimization

    [https://arxiv.org/abs/2403.08043](https://arxiv.org/abs/2403.08043)

    提出了一种简单的两步调整和优化技术，用于低资源文本风格转移，在作者转移和母语风格任务方面均优于最先进的基准模型。

    

    作者风格转移的目标是将给定的文本重写成指定的目标，同时保留原始文本的含义。现有方法依赖于大量目标风格示例进行模型训练。然而，这些方法忽视了目标风格示例数量有限的情况。参数高效的迁移学习技术和策略优化方法的发展表明，轻量级的策略优化是一种可行的低资源风格转移方法。在这项工作中，我们提出了一个简单的两步调整和优化技术，用于低资源文本风格转移。我们将该技术应用于作者转移以及更大数据的母语风格任务，在两种情况下都发现它优于最先进的基准模型。

    arXiv:2403.08043v1 Announce Type: new  Abstract: Authorship style transfer aims to rewrite a given text into a specified target while preserving the original meaning in the source. Existing approaches rely on the availability of a large number of target style exemplars for model training. However, these overlook cases where a limited number of target style examples are available. The development of parameter-efficient transfer learning techniques and policy optimization (PO) approaches suggest lightweight PO is a feasible approach to low-resource style transfer. In this work, we propose a simple two step tune-and-optimize technique for low-resource textual style transfer. We apply our technique to authorship transfer as well as a larger-data native language style task and in both cases find it outperforms state-of-the-art baseline models.
    
[^9]: 利用大型语言模型在心理治疗中进行认知重构

    HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy

    [https://arxiv.org/abs/2403.05574](https://arxiv.org/abs/2403.05574)

    这一创新心理治疗模型HealMe通过基于心理治疗框架的共情对话，有效解决了根深蒂固的负面思维，并促进了理性、平衡的观点。

    

    大型语言模型（LLMs）在心理治疗中可以发挥重要作用，熟练处理认知重构等关键任务，克服羞耻、不信任、治疗师技能差异和资源稀缺等挑战。在先前的认知重构中，主要将负面情绪转化为积极的，但这些方法效果有限，经常不能促进客户自我发现替代视角。在本文中，我们揭示了帮助和赋能通过自适应语言在心理增强（HealMe）模型。这种新颖的认知重构疗法方法有效地解决了根深蒂固的负面想法，并促进理性、平衡的视角。HealMe与传统LLM方法不同，采用基于心理治疗框架的共情对话。它通过系统指导客户区分情境和感受，集思广益寻找替代视角，并制定...

    arXiv:2403.05574v1 Announce Type: cross  Abstract: Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative emotions to positive ones, but these approaches have limited efficacy, often not promoting clients' self-discovery of alternative perspectives. In this paper, we unveil the Helping and Empowering through Adaptive Language in Mental Enhancement (HealMe) model. This novel cognitive reframing therapy method effectively addresses deep-rooted negative thoughts and fosters rational, balanced perspectives. Diverging from traditional LLM methods, HealMe employs empathetic dialogue based on psychotherapeutic frameworks. It systematically guides clients through distinguishing circumstances from feelings, brainstorming alternative viewpoints, and developing 
    
[^10]: RAM-EHR: 电子健康记录上的检索增强与临床预测相遇

    RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records

    [https://arxiv.org/abs/2403.00815](https://arxiv.org/abs/2403.00815)

    RAM-EHR通过增强检索并利用总结知识，提高了针对电子健康记录的临床预测效果。

    

    我们提出了RAM-EHR，这是一个用于改善电子健康记录（EHR）上临床预测的检索增强（Retrieval Augmentation）流程。RAM-EHR首先收集多个知识来源，将它们转换为文本格式，并使用密集检索来获取与医学概念相关的信息。这一策略解决了与复杂概念名称相关的困难。RAM-EHR然后增广了与一致性正则化代码联合训练的本地EHR预测模型，以捕获来自患者就诊和总结知识的互补信息。在两个EHR数据集上的实验表明，RAM-EHR相对于之前的知识增强基线效果显著（AUROC增益3.4％，AUPR增益7.2％），强调了RAM-EHR的总结知识对临床预测任务的有效性。代码将发布在\url{https://github.com/ritaranx/RAM-EHR}。

    arXiv:2403.00815v1 Announce Type: cross  Abstract: We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \url{https://github.com/ritaranx/RAM-EHR}.
    
[^11]: Checkfor.ai AI生成文本分类器技术报告

    Technical Report on the Checkfor.ai AI-Generated Text Classifier

    [https://arxiv.org/abs/2402.14873](https://arxiv.org/abs/2402.14873)

    Checkfor.ai AI生成文本分类器在区分大型语言模型生成文本和人类编写文本方面表现优异，提出了硬负挖掘与合成镜像训练算法，具有高准确性和泛化能力。

    

    我们提出了Checkfor.ai文本分类器，这是一个基于Transformer的神经网络，经过训练可以区分由大型语言模型编写的文本和由人类编写的文本。Checkfor.ai在由十种文本领域（学生写作、创意写作、科学写作、书籍、百科全书、新闻、电子邮件、科学论文、简答问答）和8个开源闭源大型语言模型组成的综合基准测试中，表现优于零冲击方法如DetectGPT以及主流商业AI检测工具，误差率降低了9倍以上。我们提出了一种训练算法，即硬负挖掘与合成镜像，使我们的分类器能够在评论等高数据领域实现几个数量级的更低误报率。最后，我们展示了Checkfor.ai不对非母语英语人士产生偏见，并推广到训练过程中未见的领域和模型。

    arXiv:2402.14873v1 Announce Type: cross  Abstract: We present the Checkfor.ai text classifier, a transformer-based neural network trained to distinguish text written by large language models from text written by humans. Checkfor.ai outperforms zero-shot methods such as DetectGPT as well as leading commercial AI detection tools with over 9 times lower error rates on a comprehensive benchmark comprised of ten text domains (student writing, creative writing, scientific writing, books, encyclopedias, news, email, scientific papers, short-form Q\&A) and 8 open- and closed-source large language models. We propose a training algorithm, hard negative mining with synthetic mirrors, that enables our classifier to achieve orders of magnitude lower false positive rates on high-data domains such as reviews. Finally, we show that Checkfor.ai is not biased against nonnative English speakers and generalizes to domains and models unseen during training.
    
[^12]: Agent-OM：利用LLM代理进行本体匹配

    Agent-OM: Leveraging LLM Agents for Ontology Matching

    [https://arxiv.org/abs/2312.00326](https://arxiv.org/abs/2312.00326)

    本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。

    

    本体匹配（OM）能够实现不同本体之间的语义互操作性，通过对齐相关实体来解决其概念异构性。本研究引入了一种新颖的基于代理的LLM设计范式，命名为Agent-OM，包括两个用于检索和匹配的同体代理以及一组基于提示的简单OM工具。

    arXiv:2312.00326v2 Announce Type: replace  Abstract: Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAE
    
[^13]: 红队游戏：红队语言模型的博弈论框架

    Red Teaming Game: A Game-Theoretic Framework for Red Teaming Language Models. (arXiv:2310.00322v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00322](http://arxiv.org/abs/2310.00322)

    本文提出了红队游戏（RTG）框架，利用博弈论分析了红队语言模型（RLM）与蓝队语言模型（BLM）之间的多轮攻防互动。同时引入了游戏化红队求解器（GRTS）来提供自动化的红队技术。

    

    可部署的大型语言模型（LLM）必须符合有益和无害性的标准，从而实现LLM输出与人类价值的一致性。红队技术是实现这一标准的关键途径。现有的研究仅依赖于手动红队设计和启发式对抗提示进行漏洞检测和优化。这些方法缺乏严格的数学形式化，限制了在可量化度量和收敛保证下对LLM进行多样攻击策略的探索和优化。在本文中，我们提出了红队游戏（RTG），这是一个通用的无需手动标注的博弈论框架。RTG旨在分析红队语言模型（RLM）与蓝队语言模型（BLM）之间的多轮攻防互动。在RTG中，我们提出了具有语义空间多样性度量的游戏化红队求解器（GRTS）。GRTS是一种自动化的红队技术，用于解决红队游戏问题。

    Deployable Large Language Models (LLMs) must conform to the criterion of helpfulness and harmlessness, thereby achieving consistency between LLMs outputs and human values. Red-teaming techniques constitute a critical way towards this criterion. Existing work rely solely on manual red team designs and heuristic adversarial prompts for vulnerability detection and optimization. These approaches lack rigorous mathematical formulation, thus limiting the exploration of diverse attack strategy within quantifiable measure and optimization of LLMs under convergence guarantees. In this paper, we present Red-teaming Game (RTG), a general game-theoretic framework without manual annotation. RTG is designed for analyzing the multi-turn attack and defense interactions between Red-team language Models (RLMs) and Blue-team Language Model (BLM). Within the RTG, we propose Gamified Red-teaming Solver (GRTS) with diversity measure of the semantic space. GRTS is an automated red teaming technique to solve 
    
[^14]: MVMR: 在多个可靠视频集中评估自然语言视频定位偏差

    MVMR: Evaluating Natural Language Video Localization Bias over Multiple Reliable Videos Pool. (arXiv:2309.16701v1 [cs.CV])

    [http://arxiv.org/abs/2309.16701](http://arxiv.org/abs/2309.16701)

    本文提出了一个名为MVMR的任务，旨在给定文本查询从大量视频集中定位视频帧。我们通过已有数据集进行相似性筛选来构建数据集，并引入三个MVMR数据集。我们采用了嵌入式文本相似度匹配和视频-语言对齐技术来计算相关性得分，并为MVMR任务开发了一个强大的模型，Reliable Mutual Matching Network (RMMN)。

    

    随着近年来多媒体内容的激增，自然语言视频定位成为一个关键问题，它致力于检测与给定自然语言查询匹配的视频片段。然而，以往的研究都没有探索在存在多个正负视频的大量语料库中定位一个时刻。本文提出了一个名为MVMR（Massive Videos Moment Retrieval）的任务，旨在给定文本查询从大量视频集中定位视频帧。对于这个任务，我们提出了一种通过对现有视频定位数据集进行相似性筛选来构建数据集的方法，并引入了三个MVMR数据集。具体来说，我们采用基于嵌入的文本相似度匹配和视频-语言对齐技术来计算目标查询与视频之间的相关性得分，从而定义正负集。针对提出的MVMR任务，我们进一步开发了一个强大的模型，Reliable Mutual Matching Network (RMMN)。

    With the explosion of multimedia content in recent years, natural language video localization, which focuses on detecting video moment that matches a given natural language query, has become a critical problem. However, none of the previous research explores localizing a moment from a large corpus where multiple positive and negative videos exist. In this paper, we propose an MVMR (Massive Videos Moment Retrieval) task, which aims to localize video frames from a massive set of videos given a text query. For this task, we suggest methods for constructing datasets by employing similarity filtering on the existing video localization datasets and introduce three MVMR datasets. Specifically, we employ embedding-based text similarity matching and video-language grounding techniques to calculate the relevance score between a target query and videos to define positive and negative sets. For the proposed MVMR task, we further develop a strong model, Reliable Mutual Matching Network (RMMN), whic
    
[^15]: LLM平台安全：将系统评估框架应用于OpenAI的ChatGPT插件

    LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins. (arXiv:2309.10254v1 [cs.CR])

    [http://arxiv.org/abs/2309.10254](http://arxiv.org/abs/2309.10254)

    本文提出了一个框架，用于分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性。在应用框架于OpenAI的插件生态系统时，我们发现了一些具体证明了潜在问题的插件。

    

    近期，如ChatGPT等大型语言模型（LLM）平台开始提供插件生态系统，以与互联网上的第三方服务进行交互。虽然这些插件扩展了LLM平台的功能，但它们是由任意的第三方开发的，因此不能隐式信任。插件还使用自然语言与LLM平台和用户进行交互，这可能导致模糊的解释。本文提出了一个框架，为LLM平台设计者分析和改进当前和未来与插件集成的LLM平台的安全性、隐私和安全性奠定了基础。我们的框架是一个攻击分类法的表述，通过迭代地探索LLM平台相关方如何利用他们的能力和责任对彼此进行攻击来开发的。作为我们迭代过程的一部分，我们将我们的框架应用于OpenAI的插件生态系统。我们揭示了一些具体证明了潜在问题的插件。

    Large language model (LLM) platforms, such as ChatGPT, have recently begun offering a plugin ecosystem to interface with third-party services on the internet. While these plugins extend the capabilities of LLM platforms, they are developed by arbitrary third parties and thus cannot be implicitly trusted. Plugins also interface with LLM platforms and users using natural language, which can have imprecise interpretations. In this paper, we propose a framework that lays a foundation for LLM platform designers to analyze and improve the security, privacy, and safety of current and future plugin-integrated LLM platforms. Our framework is a formulation of an attack taxonomy that is developed by iteratively exploring how LLM platform stakeholders could leverage their capabilities and responsibilities to mount attacks against each other. As part of our iterative process, we apply our framework in the context of OpenAI's plugin ecosystem. We uncover plugins that concretely demonstrate the poten
    
[^16]: 基于合成临床记录的公开可共享的临床大语言模型

    Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes. (arXiv:2309.00237v1 [cs.CL])

    [http://arxiv.org/abs/2309.00237](http://arxiv.org/abs/2309.00237)

    使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。

    

    基于合成的临床案例报告，我们首先创建了大规模的合成临床记录，以解决临床记录的有限可及性和可用性的问题。然后，我们使用这些合成记录来训练我们的专门的临床大语言模型Asclepius。虽然Asclepius是在合成数据上训练的，但我们通过使用真实临床记录对其进行评估，以评估其在现实应用中的潜在性能。我们将Asclepius与包括GPT-3.5-turbo和其他开源替代方案在内的几种其他大语言模型进行了基准测试。为了进一步验证我们使用合成记录的方法，我们还将Asclepius与其在真实临床记录上训练的变体进行了比较。我们的发现有力地证明，合成临床记录在构建临床大语言模型时可以作为可行的替代品。

    The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructi
    
[^17]: 基于冗余感知的多参考增益评估提取性摘要

    Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive Summarization. (arXiv:2308.02270v1 [cs.CL])

    [http://arxiv.org/abs/2308.02270](http://arxiv.org/abs/2308.02270)

    本文提出了一种冗余感知的Sem-nCG度量，用于评估模型摘要与多个参考摘要进行对比。实验结果表明，这种新度量具有更高的相关性。

    

    尽管ROUGE指标在评估提取性摘要任务中非常流行，但长期以来被批评缺乏语义意识，并对摘要生成器的排名质量无视。感谢之前的研究通过提出一种称为Sem-nCG的基于增益的自动度量来解决这些问题，它既具有排名和语义的意识。然而，Sem-nCG不考虑模型生成的摘要中存在的冗余数量，目前也不支持使用多个参考摘要进行评估。不幸的是，同时解决这两个限制并不容易。因此，在本文中，我们提出了一种冗余感知的Sem-nCG度量，并展示了如何使用这个新度量来评估模型摘要与多个参考摘要进行对比。我们还通过大量实验探索了将冗余纳入原始度量中的不同方式。实验结果表明，这种新的冗余感知度量具有更高的相关性。

    While very popular for evaluating extractive summarization task, the ROUGE metric has long been criticized for its lack of semantic awareness and its ignorance about the ranking quality of the summarizer. Thanks to previous research that has addressed these issues by proposing a gain-based automated metric called Sem-nCG, which is both rank and semantic aware. However, Sem-nCG does not consider the amount of redundancy present in a model-generated summary and currently does not support evaluation with multiple reference summaries. Unfortunately, addressing both these limitations simultaneously is not trivial. Therefore, in this paper, we propose a redundancy-aware Sem-nCG metric and demonstrate how this new metric can be used to evaluate model summaries against multiple references. We also explore different ways of incorporating redundancy into the original metric through extensive experiments. Experimental results demonstrate that the new redundancy-aware metric exhibits a higher corr
    
[^18]: 指令挖掘：大语言模型的高质量指令数据选择

    Instruction Mining: High-Quality Instruction Data Selection for Large Language Models. (arXiv:2307.06290v1 [cs.CL])

    [http://arxiv.org/abs/2307.06290](http://arxiv.org/abs/2307.06290)

    本文提出了InstructMining，一种用于选择高质量指令数据的线性规则，以增强大语言模型的解释和响应指令能力。通过特定的自然语言指标建模，研究结果表明，即使只有少量高质量的指令跟随数据，语言模型也可以进行良好的微调。

    

    大型语言模型通常经历预训练和微调两个训练阶段。尽管大规模预训练赋予模型强大的生成自然语言回应的能力，但这些预训练模型有时仍然无法理解人类指令。为了增强语言模型解释和响应指令的能力，指令微调已成为该领域的关键方法。最近的研究发现，即使只有少量高质量的指令跟随数据，大型语言模型也可以进行良好的微调。然而，选择用于微调语言模型的高质量数据集仍缺乏明确的指导方针。在本文中，我们提出了InstructMining，一个用于评估指令跟随数据质量的线性规则。我们使用具体的自然语言指标来进行InstructMining的建模。为了研究数据质量与这些指标之间的关系，我们还进行了广泛的细致研究。

    Large language models typically undergo two training stages, pretraining and finetuning. Despite that large-scale pretraining endows the model with strong capabilities to generate natural language responses, these pretrained models can still fail to understand human instructions at times. To enhance language models' ability of interpreting and responding to instructions, instruction finetuning has emerged as a critical method in this area. Recent studies found that large language models can be finetuned to perform well even with a small amount of high-quality instruction-following data. However, the selection of high-quality datasets for finetuning language models still lacks clear guidelines to follow. In this paper, we propose InstructMining, a linear rule for evaluating instruction-following data quality. We formulate InstructMining using specific natural language indicators. To investigate the relationship between data quality and these indicators, we further conduct extensive fine
    
[^19]: 预测性流水线解码：准确LLM解码中的计算延迟权衡

    Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding. (arXiv:2307.05908v1 [cs.CL])

    [http://arxiv.org/abs/2307.05908](http://arxiv.org/abs/2307.05908)

    本论文提出了一种预测性流水线解码（PPD）方法，通过并行启动后续令牌解码来加速大型语言模型（LLMs）中的贪婪解码过程，同时保持完全相同的输出。该方法在减少解码延迟方面具有潜力，提供了新的LLM解码策略权衡理解。

    

    本论文提出了一种名为"预测性流水线解码（PPD）"的方法，该方法可以加速大型语言模型（LLMs）中的贪婪解码，同时保持与原始解码完全相同的输出。与传统策略不同，PPD利用额外的计算资源在当前令牌解码期间并行启动后续令牌解码。这种创新方法减少了解码延迟，并重新塑造了LLM解码策略中的权衡理解。我们开发了一个理论框架，可以分析计算和延迟之间的权衡关系。使用这个框架，我们可以通过评估匹配率（表示为p_correct）来对我们提出的方法可能的延迟减少进行分析估计。结果表明，使用额外的计算资源有潜力加速LLM的贪婪解码过程。

    This paper presents "Predictive Pipelined Decoding (PPD)," an approach that speeds up greedy decoding in Large Language Models (LLMs) while maintaining the exact same output as the original decoding. Unlike conventional strategies, PPD employs additional compute resources to parallelize the initiation of subsequent token decoding during the current token decoding. This innovative method reduces decoding latency and reshapes the understanding of trade-offs in LLM decoding strategies. We have developed a theoretical framework that allows us to analyze the trade-off between computation and latency. Using this framework, we can analytically estimate the potential reduction in latency associated with our proposed method, achieved through the assessment of the match rate, represented as p_correct. The results demonstrate that the use of extra computational resources has the potential to accelerate LLM greedy decoding.
    
[^20]: GPT-3的人格测试：时间可靠性有限，但凸显了社交渴望的人格工具结果。

    Personality testing of GPT-3: Limited temporal reliability, but highlighted social desirability of GPT-3's personality instruments results. (arXiv:2306.04308v1 [cs.AI])

    [http://arxiv.org/abs/2306.04308](http://arxiv.org/abs/2306.04308)

    本研究探讨了GPT-3 Davinci-003聊天机器人的人格特质，发现其具有良好的社交渴望和亲社会特质，但在不同时间的一致性存在限制。

    

    为了评估聊天机器人GPT-3 Davinci-003的潜在应用和限制，本研究探讨了应用于聊天机器人及其个性化资料的人格问卷的时间可靠性。在两个不同的场合，心理问卷被应用于聊天机器人，然后将回答与人类基准数据进行比较。研究结果显示，聊天机器人的回答有不同程度的一致性，有些量表表现出良好的一致性，而有些则表现出较差的一致性。总体而言，Davinci-003显示出一个社交渴望和亲社会的人格特质，尤其是在亲和力领域。然而，聊天机器人回答的基础，无论是由主观自我反思还是预定算法驱动，尚不确定。

    To assess the potential applications and limitations of chatbot GPT-3 Davinci-003, this study explored the temporal reliability of personality questionnaires applied to the chatbot and its personality profile. Psychological questionnaires were administered to the chatbot on two separate occasions, followed by a comparison of the responses to human normative data. The findings revealed varying levels of agreement in the chatbot's responses over time, with some scales displaying excellent while others demonstrated poor agreement. Overall, Davinci-003 displayed a socially desirable and pro-social personality profile, particularly in the domain of communion. However, the underlying basis of the chatbot's responses, whether driven by conscious self-reflection or predetermined algorithms, remains uncertain.
    
[^21]: InstructIE: 一份基于指令的中文信息提取数据集

    InstructIE: A Chinese Instruction-based Information Extraction Dataset. (arXiv:2305.11527v1 [cs.CL])

    [http://arxiv.org/abs/2305.11527](http://arxiv.org/abs/2305.11527)

    介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。

    

    我们引入了一项新的信息提取任务，称为基于指令的信息提取 (Instruction-based IE)，它旨在要求系统遵循特定的指令或指南来提取信息。为了促进该领域的研究，我们构建了一个数据集，称为InstructIE，其中包括来自中文维基百科的 270,000 个弱监督数据和 1,000 个高质量众包注释实例。我们进一步评估了各种基线模型在InstructIE数据集上的表现。结果表明，尽管当前的模型表现很有希望，但仍有改进的空间。此外，我们进行了全面的案例研究分析，强调了基于指令的信息提取任务中固有的挑战。代码和数据集可在 https://github.com/zjunlp/DeepKE/tree/main/example/llm 找到。

    We introduce a new Information Extraction (IE) task dubbed Instruction-based IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task. Code and dataset are available at https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^22]: 面向基于跨度的序列标注的成本效益众包：工人选择和数据增强

    Cost-efficient Crowdsourcing for Span-based Sequence Labeling: Worker Selection and Data Augmentation. (arXiv:2305.06683v1 [cs.CL])

    [http://arxiv.org/abs/2305.06683](http://arxiv.org/abs/2305.06683)

    本文介绍了面向基于跨度的序列标注任务的成本效益众包算法，使用了组合多臂老虎机方法进行工人选择，并用移位、扩展和收缩的数据增强方法进行测试，提高了注释质量和降低成本，F1得分相对于仅专家的基线提高了100.04％，成本节约高达65.97％。

    

    本文介绍了一种新的工人选择算法，提高了自然语言处理中具有挑战性的基于跨度的序列标注任务的注释质量并降低了成本。与以前针对简单任务的研究不同，本研究涉及序列标注任务中的标签相互依赖性复杂性。所提议的算法使用组合多臂老虎机（CMAB）方法进行工人选择。解决了处理不平衡和小规模数据集的挑战，该挑战阻碍了工人选择的离线模拟，使用一种称为移位、扩展和收缩（SES）的创新数据增强方法来解决。SES方法专门为序列标注任务设计。在CoNLL 2003 NER和中文OEI数据集上进行的严格测试展示了算法的效率，F1得分相对于仅专家的基线提高了100.04％，成本节约高达65.97％。本文还包括一个独立于数据集的测试。

    This paper introduces a novel worker selection algorithm, enhancing annotation quality and reducing costs in challenging span-based sequence labeling tasks in Natural Language Processing (NLP). Unlike previous studies targeting simpler tasks, this study contends with the complexities of label interdependencies in sequence labeling tasks. The proposed algorithm utilizes a Combinatorial Multi-Armed Bandit (CMAB) approach for worker selection. The challenge of dealing with imbalanced and small-scale datasets, which hinders offline simulation of worker selection, is tackled using an innovative data augmentation method termed shifting, expanding, and shrinking (SES). The SES method is designed specifically for sequence labeling tasks. Rigorous testing on CoNLL 2003 NER and Chinese OEI datasets showcased the algorithm's efficiency, with an increase in F1 score up to 100.04% of the expert-only baseline, alongside cost savings up to 65.97%. The paper also encompasses a dataset-independent test
    

