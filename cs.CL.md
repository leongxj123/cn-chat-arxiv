# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Topic-based Watermarks for LLM-Generated Text](https://arxiv.org/abs/2404.02138) | 提出了一种新的基于主题的水印算法，旨在解决当前水印方案的局限性，为区分LLM生成的文本和人类生成的文本提供了新的思路。 |
| [^2] | [IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic Representations](https://arxiv.org/abs/2404.01266) | IsoBench提出了一个基准数据集，用于评估基于不同同构表示的多模态基础模型的性能差异，发现大多数模型更偏好文本表示。 |
| [^3] | [ReALM: Reference Resolution As Language Modeling](https://arxiv.org/abs/2403.20329) | 本论文展示了如何利用LLMs创建一个极其有效的系统来解决各种类型的引用问题，通过将参考解析转化为语言建模问题，尽管涉及到屏幕上的实体等不易约简为纯文本形式的实体。 |
| [^4] | [MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?](https://arxiv.org/abs/2403.14624) | MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。 |
| [^5] | [TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning](https://arxiv.org/abs/2403.08694) | TeaMs-RL通过强化学习直接生成基础指导数据集，减少对人类的依赖，提供高质量数据，为单一微调步骤铺平了道路。 |
| [^6] | [In Search of Truth: An Interrogation Approach to Hallucination Detection](https://arxiv.org/abs/2403.02889) | 提出了一种用于在大型语言模型中检测幻觉的新方法，解决了这些模型在各种现实场景中应用时遇到的关键问题，通过对多个数据集和LLMs进行广泛评估，展示了该方法的有效性。 |
| [^7] | [Proving membership in LLM pretraining data via data watermarks](https://arxiv.org/abs/2402.10892) | 使用数据水印在LLM预训练中检测版权持有人作品的方法，可以进行合理检测且提供误检率保证，研究了水印设计对假设检验能力的影响以及在模型和数据集缩放下的检测强度变化。 |
| [^8] | [G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German](https://arxiv.org/abs/2402.06584) | G-SciEdBERT是一种上下文化德语科学教育BERT，用于评分德语科学任务的书面回答。通过在大规模德语科学回答语料库上进行预训练，并在评分准确性方面取得了10%的改善。 |
| [^9] | [CIC: A framework for Culturally-aware Image Captioning](https://arxiv.org/abs/2402.05374) | CIC是一种面向文化感知图像字幕的框架，通过结合视觉问答和大型语言模型，它能够生成能描述图像中文化元素的详细字幕。 |
| [^10] | [UniMem: Towards a Unified View of Long-Context Large Language Models](https://arxiv.org/abs/2402.03009) | 本文引入UniMem，一个统一的框架，以记忆增强的角度重新制定了现有的长上下文方法，并提出了UniMix来提高长上下文处理能力。 |
| [^11] | [Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework](https://arxiv.org/abs/2312.00029) | Bergeron提出了一个基于良知的对齆框架，能够提高大型语言模型对抗攻击的鲁棒性，无需额外参数微调。 |
| [^12] | [Towards A Unified View of Answer Calibration for Multi-Step Reasoning](https://arxiv.org/abs/2311.09101) | 本文总结了最近答案校准技术的分类法，从统一视角对步级和路径级答案校准进行了彻底评估，结果显示整合两种策略的优势倾向于产生最佳结果。 |
| [^13] | [LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities](https://arxiv.org/abs/2305.13168) | 本研究全面评估了LLMs在知识图谱构建和推理领域的性能，发现GPT-4更适合作为推理助手，并在某些情况下超越了精调模型。 |
| [^14] | [Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption.](http://arxiv.org/abs/2401.13444) | 该论文介绍了一种以低计算资源消耗为中心的高效知识库问答框架，通过引入线索引导路径探索的方式，将知识库与大型语言模型高效地融合，从而降低了对模型能力的要求，并在实验证明了其优越性能。 |
| [^15] | [Effects of diversity incentives on sample diversity and downstream model performance in LLM-based text augmentation.](http://arxiv.org/abs/2401.06643) | 本研究评估了三种文本多样性激励方法对LLM文本增强中生成文本的词汇多样性和下游模型性能的影响。结果表明，使用禁忌词能够最大程度地增加多样性，而使用先前创建的改写作为提示时，下游模型的性能最高。 |
| [^16] | [Linguistic and Structural Basis of Engineering Design Knowledge.](http://arxiv.org/abs/2312.06355) | 本文通过分析33881份专利文件的样本，将工程设计知识阐释为知识图谱，从而揭示工程设计知识的语言和结构基础。 |
| [^17] | [ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models.](http://arxiv.org/abs/2310.18208) | ArcheType是一种使用大型语言模型进行开源列类型注释的新框架，通过改进上下文采样和标签重新映射，实现了全面的零样本解决方案。 |
| [^18] | [Learning Using Generated Privileged Information by Text-to-Image Diffusion Models.](http://arxiv.org/abs/2309.15238) | 本研究提出了一种利用生成的特权信息进行学习的框架，通过文本到图像扩散模型生成合成数据作为特权信息，进一步提升了学生模型在文本分类任务中的性能。 |
| [^19] | [Transformer Compression via Subspace Projection.](http://arxiv.org/abs/2308.16475) | Transformer压缩通过子空间投影，在减小模型隐藏大小的同时实现了较大的模型参数和计算资源的减少，并且与其他方法兼容。 |
| [^20] | [RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models.](http://arxiv.org/abs/2308.07922) | RAVEN是一种结合了检索增强的蒙特卡洛语言建模和前缀语言建模的模型，通过引入上下文融合学习，它能够在上下文学习方面取得比ATLAS更好的性能。 |
| [^21] | [Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation.](http://arxiv.org/abs/2308.01831) | 本文提出了一种使用统一模型学习多语种语音和文本的表示的方法，重点关注语音合成。通过使用自监督语音模型编码的语音特征的量化表示语音音频，并将其视为伪文本来建立统一的语音和文本表示。然后通过训练编码器-解码器结构模型，利用单元到单元翻译目标将口语语言翻译为目标语言。这种方法能够建立对口语语言的理解并将其相关联到不同的语言。 |
| [^22] | [LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition.](http://arxiv.org/abs/2307.13269) | 本文研究了LoRA组合在跨任务通用性上的可行性，并提出了LoraHub框架，能够通过组合不同任务上训练的LoRA模块，实现对未见任务的可适应性性能。实验结果表明，LoraHub在少样本场景中能够有效模拟上下文学习的性能，而无需上下文示例。 |
| [^23] | [IncDSI: Incrementally Updatable Document Retrieval.](http://arxiv.org/abs/2307.10323) | IncDSI是一种递增可更新的文档检索方法，它通过最小改变网络参数的约束优化问题，实现实时添加文档而无需重新训练整个模型，具有与重新训练模型相竞争的速度，能够实时更新的文档检索系统的开发。 |
| [^24] | [A Formal Perspective on Byte-Pair Encoding.](http://arxiv.org/abs/2306.16837) | 这篇论文从形式化的角度对Byte-Pair编码进行了研究，将其形式化为组合优化问题，证明了迭代贪婪版本是对最优合并序列的近似解，并优化了算法的运行时间复杂度。 |
| [^25] | [Could a Large Language Model be Conscious?.](http://arxiv.org/abs/2303.07103) | 本文分析了大型语言模型是否具有意识的可能性，目前的模型存在着意识的显著障碍，但未来十年随着障碍被克服，后继的大型语言模型可能会具有意识。 |

# 详细

[^1]: 基于主题的LLM生成文本的水印

    Topic-based Watermarks for LLM-Generated Text

    [https://arxiv.org/abs/2404.02138](https://arxiv.org/abs/2404.02138)

    提出了一种新的基于主题的水印算法，旨在解决当前水印方案的局限性，为区分LLM生成的文本和人类生成的文本提供了新的思路。

    

    大型语言模型（LLMs）的最新进展导致了生成的文本输出与人类生成的文本相似度难以分辨。水印算法是潜在工具，通过在LLM生成的输出中嵌入可检测的签名，可以区分LLM生成的文本和人类生成的文本。然而，当前的水印方案在已知攻击下缺乏健壮性。此外，考虑到LLM每天生成数万个文本输出，水印算法需要记忆每个输出才能让检测正常工作，这是不切实际的。本文针对当前水印方案的局限性，提出了针对LLMs的“基于主题的水印算法”概念。

    arXiv:2404.02138v1 Announce Type: cross  Abstract: Recent advancements of large language models (LLMs) have resulted in indistinguishable text outputs comparable to human-generated text. Watermarking algorithms are potential tools that offer a way to differentiate between LLM- and human-generated text by embedding detectable signatures within LLM-generated output. However, current watermarking schemes lack robustness against known attacks against watermarking algorithms. In addition, they are impractical considering an LLM generates tens of thousands of text outputs per day and the watermarking algorithm needs to memorize each output it generates for the detection to work. In this work, focusing on the limitations of current watermarking schemes, we propose the concept of a "topic-based watermarking algorithm" for LLMs. The proposed algorithm determines how to generate tokens for the watermarked LLM output based on extracted topics of an input prompt or the output of a non-watermarked 
    
[^2]: IsoBench：基于同构表示对多模态基础模型进行基准测试

    IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic Representations

    [https://arxiv.org/abs/2404.01266](https://arxiv.org/abs/2404.01266)

    IsoBench提出了一个基准数据集，用于评估基于不同同构表示的多模态基础模型的性能差异，发现大多数模型更偏好文本表示。

    

    当前的基础模型在仅文本或图像和文本输入同时提示时表现出令人印象深刻的能力。但它们的能力是否会根据输入方式而改变呢？在这项工作中，我们提出了一个名为$\textbf{IsoBench}$的基准数据集，其中包含来自四个主要领域的问题: 数学、科学、算法和游戏。每个示例呈现了多个输入的同构表示，如视觉、文本和数学展示。IsoBench提供了细粒度的反馈，以诊断由表示形式造成的性能差距。在各种基础模型中，我们观察到在相同问题上，模型一贯偏好文本表示。最突出的是，在所有IsoBench问题上进行评估时，Claude-3 Opus在提供图像而不是文本时性能下降28.7分；同样，GPT-4 Turbo性能下降18.7分，Gemini Pro下降14.9分。

    arXiv:2404.01266v1 Announce Type: new  Abstract: Current foundation models exhibit impressive capabilities when prompted either with text only or with both image and text inputs. But do their capabilities change depending on the input modality? In this work, we propose $\textbf{IsoBench}$, a benchmark dataset containing problems from four major areas: math, science, algorithms, and games. Each example is presented with multiple $\textbf{isomorphic representations}$ of inputs, such as visual, textual, and mathematical presentations. IsoBench provides fine-grained feedback to diagnose performance gaps caused by the form of the representation. Across various foundation models, we observe that on the same problem, models have a consistent preference towards textual representations. Most prominently, when evaluated on all IsoBench problems, Claude-3 Opus performs 28.7 points worse when provided with images instead of text; similarly, GPT-4 Turbo is 18.7 points worse and Gemini Pro is 14.9 p
    
[^3]: ReALM: 参考解析作为语言建模

    ReALM: Reference Resolution As Language Modeling

    [https://arxiv.org/abs/2403.20329](https://arxiv.org/abs/2403.20329)

    本论文展示了如何利用LLMs创建一个极其有效的系统来解决各种类型的引用问题，通过将参考解析转化为语言建模问题，尽管涉及到屏幕上的实体等不易约简为纯文本形式的实体。

    

    参考解析是一个重要的问题，对于理解和成功处理各种上下文至关重要。 这种上下文既包括先前的对话，也包括与非对话实体相关的上下文，例如用户屏幕上的实体或后台运行的实体。 尽管已经证明了LLMs在各种任务中非常强大，但它们在参考解析中的运用，特别是对于非对话实体，仍未充分利用。 本文展示了LLMs如何被用来创建一个极其有效的系统来解决各种类型的引用问题，通过展示如何将参考解析转化为语言建模问题，尽管其中涉及屏幕上的这种实体等传统上不易约简为纯文本形式的实体。 我们展示了在不同类型的参考解析中相对于已有类似功能的系统的显着改进。

    arXiv:2403.20329v1 Announce Type: cross  Abstract: Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user's screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of re
    
[^4]: MathVerse：您的多模式LLM是否真正看到了视觉数学问题中的图表？

    MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?

    [https://arxiv.org/abs/2403.14624](https://arxiv.org/abs/2403.14624)

    MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。

    

    多模式大型语言模型（MLLMs）取得了显著进展，在视觉环境中表现出色，然而它们在视觉数学问题解决方面的能力仍未充分评估和理解。本研究调查了当前基准测试，将过多的视觉内容融入文本问题中，这有助于MLLM在不真正解释输入图表的情况下推导答案。为此，我们介绍了MathVerse，这是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs。我们精心收集了2,612个高质量的多学科数学问题，其中包含图表，来源于公开渠道。然后，每个问题由人工注释者转化为六个不同版本，每个版本在多模式中提供不同程度的信息内容，共贡献了15K个测试样本。这种方法使得MathVerse能够同时

    arXiv:2403.14624v1 Announce Type: cross  Abstract: The remarkable progress of Multi-modal Large Language Models (MLLMs) has garnered unparalleled attention, due to their superior performance in visual contexts. However, their capabilities in visual math problem-solving remain insufficiently evaluated and understood. We investigate current benchmarks to incorporate excessive visual content within textual questions, which potentially assist MLLMs in deducing answers without truly interpreting the input diagrams. To this end, we introduce MathVerse, an all-around visual math benchmark designed for an equitable and in-depth evaluation of MLLMs. We meticulously collect 2,612 high-quality, multi-subject math problems with diagrams from publicly available sources. Each problem is then transformed by human annotators into six distinct versions, each offering varying degrees of information content in multi-modality, contributing to 15K test samples in total. This approach allows MathVerse to co
    
[^5]: TeaMs-RL：通过强化学习教授LLMs更好地自我指导方法

    TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning

    [https://arxiv.org/abs/2403.08694](https://arxiv.org/abs/2403.08694)

    TeaMs-RL通过强化学习直接生成基础指导数据集，减少对人类的依赖，提供高质量数据，为单一微调步骤铺平了道路。

    

    大型语言模型（LLMs）的发展通常面临着在强化学习与人类反馈（RLHF）框架中对人类标注员的严重依赖或与自我指导范式相关的频繁且昂贵的外部查询的挑战。在这项工作中，我们转向强化学习（RL）-- 但有所不同。我们偏离了典型的RLHF，后者在指导数据训练后优化LLMs，而我们使用RL直接生成单独足以进行微调的基础指导数据集。我们的方法TeaMs-RL使用一系列文本操作和规则，优先考虑训练数据集的多样化。它促进了高质量数据的生成，而不过于依赖外部先进模型，为单一微调步骤铺平了道路，消除了随后的RLHF阶段的必要性。我们的发现突出了我们方法的关键优势：减少对人类的依赖

    arXiv:2403.08694v1 Announce Type: new  Abstract: The development of Large Language Models (LLMs) often confronts challenges stemming from the heavy reliance on human annotators in the reinforcement learning with human feedback (RLHF) framework, or the frequent and costly external queries tied to the self-instruct paradigm. In this work, we pivot to Reinforcement Learning (RL) -- but with a twist. Diverging from the typical RLHF, which refines LLMs following instruction data training, we use RL to directly generate the foundational instruction dataset that alone suffices for fine-tuning. Our method, TeaMs-RL, uses a suite of textual operations and rules, prioritizing the diversification of training datasets. It facilitates the generation of high-quality data without excessive reliance on external advanced models, paving the way for a single fine-tuning step and negating the need for subsequent RLHF stages. Our findings highlight key advantages of our approach: reduced need for human inv
    
[^6]: 在寻找真相：一种审问方法用于幻觉检测

    In Search of Truth: An Interrogation Approach to Hallucination Detection

    [https://arxiv.org/abs/2403.02889](https://arxiv.org/abs/2403.02889)

    提出了一种用于在大型语言模型中检测幻觉的新方法，解决了这些模型在各种现实场景中应用时遇到的关键问题，通过对多个数据集和LLMs进行广泛评估，展示了该方法的有效性。

    

    尽管大型语言模型（LLMs）取得了许多进展并且以前所未有的速度快速发展，但由于各种原因，它们对我们日常生活的各个方面的影响和整合仍然有限。一个阻碍它们广泛应用的关键因素是幻觉的发生，即LLMs创造出听起来真实但偏离事实真相的答案。在本文中，我们提出了一种新颖的方法用于检测大型语言模型中的幻觉，这解决了这些模型在各种现实场景中应用的一个关键问题。通过对多个数据集和LLMs进行广泛评估，包括Llama-2，我们研究了各种最新LLMs的幻觉水平，并展示了我们的方法在自动检测它们方面的有效性。值得注意的是，我们在一个特定实验中观察到Llama-2达到62%的幻觉水平，而我们的方法在没有依赖的情况下实现了87%的平衡准确率（B-ACC）。

    arXiv:2403.02889v1 Announce Type: new  Abstract: Despite the many advances of Large Language Models (LLMs) and their unprecedented rapid evolution, their impact and integration into every facet of our daily lives is limited due to various reasons. One critical factor hindering their widespread adoption is the occurrence of hallucinations, where LLMs invent answers that sound realistic, yet drift away from factual truth. In this paper, we present a novel method for detecting hallucinations in large language models, which tackles a critical issue in the adoption of these models in various real-world scenarios. Through extensive evaluations across multiple datasets and LLMs, including Llama-2, we study the hallucination levels of various recent LLMs and demonstrate the effectiveness of our method to automatically detect them. Notably, we observe up to 62% hallucinations for Llama-2 in a specific experiment, where our method achieves a Balanced Accuracy (B-ACC) of 87%, all without relying 
    
[^7]: 通过数据水印证明LLM预训练数据的成员资格

    Proving membership in LLM pretraining data via data watermarks

    [https://arxiv.org/abs/2402.10892](https://arxiv.org/abs/2402.10892)

    使用数据水印在LLM预训练中检测版权持有人作品的方法，可以进行合理检测且提供误检率保证，研究了水印设计对假设检验能力的影响以及在模型和数据集缩放下的检测强度变化。

    

    检测版权持有人的作品是否在LLM预训练中使用是一个重要问题，本文提出使用数据水印实现基于黑盒模型访问的合理检测，前提是版权持有人在公开发布之前贡献了多个训练文档并对其进行了水印处理。通过应用随机采样的数据水印，检测可以被构造为假设检验，从而提供对误检率的保证。研究了两种水印：一种插入随机序列，另一种随机用Unicode类似字符替换字符。首先展示了水印设计的三个方面--水印长度、复制次数和干扰--如何影响假设检验的能力。接着研究了水印在模型和数据集缩放下的检测强度如何变化：增加数据集大小会降低水印的强度，水印...

    arXiv:2402.10892v1 Announce Type: cross  Abstract: Detecting whether copyright holders' works were used in LLM pretraining is poised to be an important problem. This work proposes using data watermarks to enable principled detection with only black-box model access, provided that the rightholder contributed multiple training documents and watermarked them before public release. By applying a randomly sampled data watermark, detection can be framed as hypothesis testing, which provides guarantees on the false detection rate. We study two watermarks: one that inserts random sequences, and another that randomly substitutes characters with Unicode lookalikes. We first show how three aspects of watermark design -- watermark length, number of duplications, and interference -- affect the power of the hypothesis test. Next, we study how a watermark's detection strength changes under model and dataset scaling: while increasing the dataset size decreases the strength of the watermark, watermarks
    
[^8]: G-SciEdBERT: 用于德语科学评估任务的上下文化大型语言模型

    G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German

    [https://arxiv.org/abs/2402.06584](https://arxiv.org/abs/2402.06584)

    G-SciEdBERT是一种上下文化德语科学教育BERT，用于评分德语科学任务的书面回答。通过在大规模德语科学回答语料库上进行预训练，并在评分准确性方面取得了10%的改善。

    

    自然语言处理的进步为各种语言（例如德语中的德语BERT [G-BERT]）的自动评分系统铺平了道路。自动评分德语科学问题的书面回答是一项复杂的任务，对于标准的G-BERT来说具有挑战性，因为它们缺乏科学领域的上下文知识，并且可能与学生的写作风格不一致。本文开发了一种上下文化德语科学教育BERT（G-SciEdBERT），一个创新的大型语言模型，专门用于评分德语科学任务的书面回答。我们使用G-BERT，在5M个标记的PISA 2015国际学生评估的50K个德语科学回答语料库上对G-SciEdBERT进行了预训练。然后，我们在59个评估项目上对G-SciEdBERT进行了微调，并检查了评分准确性。然后，我们将其性能与G-BERT进行了比较。我们的研究结果显示，G-SciEdBERT在评分准确性方面取得了显著的改进，表明其评分准确性提高了10%。

    The advancement of natural language processing has paved the way for automated scoring systems in various languages, such as German (e.g., German BERT [G-BERT]). Automatically scoring written responses to science questions in German is a complex task and challenging for standard G-BERT as they lack contextual knowledge in the science domain and may be unaligned with student writing styles. This paper developed a contextualized German Science Education BERT (G-SciEdBERT), an innovative large language model tailored for scoring German-written responses to science tasks. Using G-BERT, we pre-trained G-SciEdBERT on a corpus of 50K German written science responses with 5M tokens to the Programme for International Student Assessment (PISA) 2015. We fine-tuned G-SciEdBERT on 59 assessment items and examined the scoring accuracy. We then compared its performance with G-BERT. Our findings reveal a substantial improvement in scoring accuracy with G-SciEdBERT, demonstrating a 10% increase of quad
    
[^9]: CIC：一种面向文化感知图像字幕的框架

    CIC: A framework for Culturally-aware Image Captioning

    [https://arxiv.org/abs/2402.05374](https://arxiv.org/abs/2402.05374)

    CIC是一种面向文化感知图像字幕的框架，通过结合视觉问答和大型语言模型，它能够生成能描述图像中文化元素的详细字幕。

    

    图像字幕通过使用视觉-语言预训练模型（VLPs）如BLIP从图像生成描述性句子，这种方法已经取得了很大的改进。然而，当前的方法缺乏对图像中所描绘的文化元素（例如亚洲文化群体的传统服装）生成详细描述性字幕的能力。在本文中，我们提出了一种新的框架，\textbf{面向文化感知图像字幕（CIC）}，该框架能够从代表不同文化的图像中生成字幕并描述文化元素。受到将视觉模态和大型语言模型（LLMs）通过适当的提示进行组合的方法的启发，我们的框架（1）根据图像中的文化类别生成问题，（2）利用生成的问题从视觉问答（VQA）中提取文化视觉元素，（3）使用带有提示的LLMs生成文化感知字幕。我们在4个不同大学的45名参与者上进行了人工评估。

    Image Captioning generates descriptive sentences from images using Vision-Language Pre-trained models (VLPs) such as BLIP, which has improved greatly. However, current methods lack the generation of detailed descriptive captions for the cultural elements depicted in the images, such as the traditional clothing worn by people from Asian cultural groups. In this paper, we propose a new framework, \textbf{Culturally-aware Image Captioning (CIC)}, that generates captions and describes cultural elements extracted from cultural visual elements in images representing cultures. Inspired by methods combining visual modality and Large Language Models (LLMs) through appropriate prompts, our framework (1) generates questions based on cultural categories from images, (2) extracts cultural visual elements from Visual Question Answering (VQA) using generated questions, and (3) generates culturally-aware captions using LLMs with the prompts. Our human evaluation conducted on 45 participants from 4 dif
    
[^10]: UniMem：迈向长上下文大语言模型统一视图

    UniMem: Towards a Unified View of Long-Context Large Language Models

    [https://arxiv.org/abs/2402.03009](https://arxiv.org/abs/2402.03009)

    本文引入UniMem，一个统一的框架，以记忆增强的角度重新制定了现有的长上下文方法，并提出了UniMix来提高长上下文处理能力。

    

    长上下文处理是限制大语言模型应用能力的关键能力。虽然存在各种致力于增强大语言模型的长上下文处理能力的方法，但它们是孤立地开发的，缺乏对它们的优点的系统分析和整合，从而阻碍了进一步的发展。在本文中，我们引入了UniMem，一个统一的框架，从LLM的记忆增强的角度重新制定了现有的长上下文方法。 UniMem的特点是四个关键维度：内存管理，内存写入，内存读取和内存注入，为了理解各种长上下文方法提供了系统理论。我们基于UniMem重新制定了16种现有方法，并分析了Transformer-XL，记忆化Transformer，RMT和Longformer中的四种代表性方法，以揭示它们的设计原则和优势。基于这些分析，我们提出了UniMix，一种新的方法来提高长上下文处理能力。

    Long-context processing is a critical ability that constrains the applicability of large language models. Although there exist various methods devoted to enhancing the long-context processing ability of large language models (LLMs), they are developed in an isolated manner and lack systematic analysis and integration of their strengths, hindering further developments. In this paper, we introduce UniMem, a unified framework that reformulates existing long-context methods from the view of memory augmentation of LLMs. UniMem is characterized by four key dimensions: Memory Management, Memory Writing, Memory Reading, and Memory Injection, providing a systematic theory for understanding various long-context methods. We reformulate 16 existing methods based on UniMem and analyze four representative methods: Transformer-XL, Memorizing Transformer, RMT, and Longformer into equivalent UniMem forms to reveal their design principles and strengths. Based on these analyses, we propose UniMix, an inn
    
[^11]: 通过基于良知的对准框架抵御对抗性攻击

    Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework

    [https://arxiv.org/abs/2312.00029](https://arxiv.org/abs/2312.00029)

    Bergeron提出了一个基于良知的对齆框架，能够提高大型语言模型对抗攻击的鲁棒性，无需额外参数微调。

    

    近年来，随着越来越强大的大型语言模型（LLMs）的引入，人工智能对齐的研究取得了可观的进展。不幸的是，现代对齐方法仍然无法完全防止在模型被蓄意攻击时产生有害应对。为了帮助缓解这一问题，我们引入了Bergeron：一个旨在提高LLMs对抗攻击鲁棒性的框架，无需进行额外的参数微调。Bergeron分为两个层次；次要LLM模拟受保护的主要LLM的良知。该框架在监视输出以检测任何有害内容的同时，更好地保护主要模型免受入侵攻击。实证分析表明，使用Bergeron来补充现有对齐训练的模型

    arXiv:2312.00029v2 Announce Type: replace-cross  Abstract: Research into AI alignment has grown considerably since the recent introduction of increasingly capable Large Language Models (LLMs). Unfortunately, modern methods of alignment still fail to fully prevent harmful responses when models are deliberately attacked. These attacks can trick seemingly aligned models into giving manufacturing instructions for dangerous materials, inciting violence, or recommending other immoral acts. To help mitigate this issue, we introduce Bergeron: a framework designed to improve the robustness of LLMs against attacks without any additional parameter fine-tuning. Bergeron is organized into two tiers; with a secondary LLM emulating the conscience of a protected, primary LLM. This framework better safeguards the primary model against incoming attacks while monitoring its output for any harmful content. Empirical analysis shows that, by using Bergeron to complement models with existing alignment traini
    
[^12]: 朝向多步推理的答案校准统一视图

    Towards A Unified View of Answer Calibration for Multi-Step Reasoning

    [https://arxiv.org/abs/2311.09101](https://arxiv.org/abs/2311.09101)

    本文总结了最近答案校准技术的分类法，从统一视角对步级和路径级答案校准进行了彻底评估，结果显示整合两种策略的优势倾向于产生最佳结果。

    

    大型语言模型（LLMs）使用“思维链”提示扩展了改进多步推理能力的范围。我们通常将多步推理分为两个阶段：路径生成以生成推理路径；和答案校准后处理推理路径以获得最终答案。然而，现有文献缺乏对不同答案校准方法的系统分析。本文总结了最近答案校准技术的分类法，并将其分解为步级和路径级策略。然后，我们从统一视角对这些策略进行了彻底评估，系统地审查了多路径上的步级和路径级答案校准。实验结果表明，整合两种策略的优势倾向于产生最佳结果。我们的研究有可能启示优化多步推理系统的关键见解。

    arXiv:2311.09101v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) employing Chain-of-Thought (CoT) prompting have broadened the scope for improving multi-step reasoning capabilities. We generally divide multi-step reasoning into two phases: path generation to generate the reasoning path(s); and answer calibration post-processing the reasoning path(s) to obtain a final answer. However, the existing literature lacks systematic analysis on different answer calibration approaches. In this paper, we summarize the taxonomy of recent answer calibration techniques and break them down into step-level and path-level strategies. We then conduct a thorough evaluation on these strategies from a unified view, systematically scrutinizing step-level and path-level answer calibration across multiple paths. Experimental results reveal that integrating the dominance of both strategies tends to derive optimal outcomes. Our study holds the potential to illuminate key insights for opti
    
[^13]: LLMs用于知识图谱构建和推理：最新功能与未来机遇

    LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities

    [https://arxiv.org/abs/2305.13168](https://arxiv.org/abs/2305.13168)

    本研究全面评估了LLMs在知识图谱构建和推理领域的性能，发现GPT-4更适合作为推理助手，并在某些情况下超越了精调模型。

    

    本文对大规模语言模型（LLMs）在知识图谱（KG）构建和推理中的数量化和质化评估进行了详尽的研究。我们在八个不同的数据集上进行了实验，重点关注涵盖实体和关系提取、事件提取、链接预测和问答四个典型任务，从而全面探索了LLMs在构建和推理领域的表现。经验性研究发现，以GPT-4为代表的LLMs更适合作为推理助手，而不是少样本信息提取器。具体而言，虽然GPT-4在与KG构建相关的任务中表现出色，但在推理任务中表现更出色，在某些情况下超越了精调模型。此外，我们的调查还扩展到LLMs在信息提取方面的潜在泛化能力，提出了虚拟知识提取的构想。

    arXiv:2305.13168v2 Announce Type: replace-cross  Abstract: This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We engage in experiments across eight diverse datasets, focusing on four representative tasks encompassing entity and relation extraction, event extraction, link prediction, and question-answering, thereby thoroughly exploring LLMs' performance in the domain of construction and inference. Empirically, our findings suggest that LLMs, represented by GPT-4, are more suited as inference assistants rather than few-shot information extractors. Specifically, while GPT-4 exhibits good performance in tasks related to KG construction, it excels further in reasoning tasks, surpassing fine-tuned models in certain cases. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, leading to the proposition of a Virtual Knowledge Extr
    
[^14]: 以低计算资源消耗为中心的高效知识库问答框架：基于线索引导路径探索

    Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption. (arXiv:2401.13444v1 [cs.CL])

    [http://arxiv.org/abs/2401.13444](http://arxiv.org/abs/2401.13444)

    该论文介绍了一种以低计算资源消耗为中心的高效知识库问答框架，通过引入线索引导路径探索的方式，将知识库与大型语言模型高效地融合，从而降低了对模型能力的要求，并在实验证明了其优越性能。

    

    在最近的研究中，大型语言模型（LLMs）展示了出色的能力。然而，更新它们的知识面会带来挑战，当面对不熟悉的查询时可能导致不准确性。虽然已经研究了将知识图谱与LLMs集成的方法，但现有方法将LLMs视为主要的决策者，对其能力提出了较高的要求。对于计算成本较低且性能相对较差的LLMs来说，这是不太合适的。本文介绍了一种以线索引导路径探索为核心的知识库问答框架（CGPE），它将知识库与LLMs高效地融合，对模型的能力要求较低。受人类手动检索知识的方法启发，CGPE利用问题中的信息作为线索，系统地探索知识库中所需的知识路径。开源数据集上的实验证明，CGPE优于先前的方法，并且非常适用于计算成本较低且性能较差的LLMs。

    In recent times, large language models (LLMs) have showcased remarkable capabilities. However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries. While integrating knowledge graphs with LLMs has been explored, existing approaches treat LLMs as primary decision-makers, imposing high demands on their capabilities. This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance. In this paper, we introduce a Clue-Guided Path Exploration framework (CGPE) that efficiently merges a knowledge base with an LLM, placing less stringent requirements on the model's capabilities. Inspired by the method humans use to manually retrieve knowledge, CGPE employs information from the question as clues to systematically explore the required knowledge path within the knowledge base. Experiments on open-source datasets reveal that CGPE outperforms previous methods and is highly applicable to LLMs w
    
[^15]: 多样性激励对LLM文本增强中样本多样性和下游模型性能的影响

    Effects of diversity incentives on sample diversity and downstream model performance in LLM-based text augmentation. (arXiv:2401.06643v1 [cs.CL])

    [http://arxiv.org/abs/2401.06643](http://arxiv.org/abs/2401.06643)

    本研究评估了三种文本多样性激励方法对LLM文本增强中生成文本的词汇多样性和下游模型性能的影响。结果表明，使用禁忌词能够最大程度地增加多样性，而使用先前创建的改写作为提示时，下游模型的性能最高。

    

    最新的生成式大型语言模型（LLM）在数据增强任务中找到了应用，其中少量文本样本被LLM改写，然后用于模型的微调。然而，需要进一步研究不同提示、种子数据选择策略、过滤方法或模型设置对改写数据（和下游模型）质量的影响。在本研究中，我们调查了在众包中已经建立良好的三种文本多样性激励方法：禁忌词、通过先前异常解的提示和通过先前异常解的链接。使用这些激励方法作为指导LLM增补文本数据集的一部分，我们探测它们对生成的文本的词汇多样性和下游模型性能的影响。我们比较了5种不同的LLM和6个数据集的影响。结果显示，禁忌词能够最大程度地增加多样性，而使用先前创建的改写作为提示时，下游模型的性能最高。

    The latest generative large language models (LLMs) have found their application in data augmentation tasks, where small numbers of text samples are LLM-paraphrased and then used to fine-tune the model. However, more research is needed to assess how different prompts, seed data selection strategies, filtering methods, or model settings affect the quality of paraphrased data (and downstream models). In this study, we investigate three text diversity incentive methods well established in crowdsourcing: taboo words, hints by previous outlier solutions, and chaining on previous outlier solutions. Using these incentive methods as part of instructions to LLMs augmenting text datasets, we measure their effects on generated texts' lexical diversity and downstream model performance. We compare the effects over 5 different LLMs and 6 datasets. We show that diversity is most increased by taboo words, while downstream model performance is highest when previously created paraphrases are used as hint
    
[^16]: 工程设计知识的语言和结构基础

    Linguistic and Structural Basis of Engineering Design Knowledge. (arXiv:2312.06355v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.06355](http://arxiv.org/abs/2312.06355)

    本文通过分析33881份专利文件的样本，将工程设计知识阐释为知识图谱，从而揭示工程设计知识的语言和结构基础。

    

    物品描述是工程设计知识的主要载体，既是设计过程的产物，也是驱动设计过程的因素。尽管物品可以以不同的内涵进行描述，但设计过程需要一种描述来体现工程设计知识，这通过实体和关系的复杂安排在文本中表现出来。虽然大型语言模型可以从各种文本中学习，但它们尚未生成体现明确的工程设计事实的文本。现有的本体论设计理论很少能指导目前仅限于构思和学习目的的大型语言模型的应用。本文从33881份专利文件的大样本中将工程设计知识阐释为知识图谱。我们研究这些知识图谱的组成部分，以理解工程设计知识的语言和结构基础。

    Artefact descriptions are the primary carriers of engineering design knowledge that is both an outcome and a driver of the design process. While an artefact could be described in different connotations, the design process requires a description to embody engineering design knowledge, which is expressed in the text through intricate placement of entities and relationships. As large-language models learn from all kinds of text merely as a sequence of characters/tokens, these are yet to generate text that embodies explicit engineering design facts. Existing ontological design theories are less likely to guide the large-language models whose applications are currently limited to ideation and learning purposes. In this article, we explicate engineering design knowledge as knowledge graphs from a large sample of 33,881 patent documents. We examine the constituents of these knowledge graphs to understand the linguistic and structural basis of engineering design knowledge. In terms of linguist
    
[^17]: ArcheType：一种使用大型语言模型进行开源列类型注释的新框架

    ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models. (arXiv:2310.18208v1 [cs.CL])

    [http://arxiv.org/abs/2310.18208](http://arxiv.org/abs/2310.18208)

    ArcheType是一种使用大型语言模型进行开源列类型注释的新框架，通过改进上下文采样和标签重新映射，实现了全面的零样本解决方案。

    

    现有的深度学习方法在语义列类型注释（CTA）方面存在重要缺点：它们依赖于在训练时固定的语义类型；需要大量的每个类型的训练样本并产生大量运行时推断成本；即使类型保持不变，它们的性能也可能在评估新数据集时下降。大型语言模型在广泛的任务上展示了强大的零样本分类性能，本文探讨了它们在CTA中的应用。我们介绍了ArcheType，一种简单实用的方法，用于上下文采样、提示序列化、模型查询和标签重新映射，从而使大型语言模型能够完全以零样本方式解决列类型注释问题。我们分别对我们方法的每个组成部分进行了分析，并确定出改进上下文采样和标签重新映射提供了最一致的性能提升。

    Existing deep-learning approaches to semantic column type annotation (CTA) have important shortcomings: they rely on semantic types which are fixed at training time; require a large number of training samples per type and incur large run-time inference costs; and their performance can degrade when evaluated on novel datasets, even when types remain constant. Large language models have exhibited strong zero-shot classification performance on a wide range of tasks and in this paper we explore their use for CTA. We introduce ArcheType, a simple, practical method for context sampling, prompt serialization, model querying, and label remapping, which enables large language models to solve column type annotation problems in a fully zero-shot manner. We ablate each component of our method separately, and establish that improvements to context sampling and label remapping provide the most consistent gains. ArcheType establishes new state-of-the-art performance on both zero-shot and fine-tuned C
    
[^18]: 使用生成的特权信息学习通过文本到图像扩散模型

    Learning Using Generated Privileged Information by Text-to-Image Diffusion Models. (arXiv:2309.15238v1 [cs.CL])

    [http://arxiv.org/abs/2309.15238](http://arxiv.org/abs/2309.15238)

    本研究提出了一种利用生成的特权信息进行学习的框架，通过文本到图像扩散模型生成合成数据作为特权信息，进一步提升了学生模型在文本分类任务中的性能。

    

    使用生成的特权信息进行学习是一种特殊类型的知识蒸馏，其中教师模型在训练过程中从额外的数据表示中获益，这被称为特权信息，并改善了不看到额外表示的学生模型。然而，在实践中很少可获得特权信息。为此，我们提出了一种文本分类框架，利用文本到图像扩散模型生成人工特权信息。生成的图像和原始文本样本进一步用于基于最先进的基于转换器的架构来训练多模态教师模型。最后，多模态教师的知识被蒸馏到基于文本的（单模态）学生模型中。因此，通过使用生成模型产生合成数据作为特权信息，我们引导学生模型的训练。我们的框架称为利用生成的特权信息进行学习（LUGPI），可以显著提高性能。

    Learning Using Privileged Information is a particular type of knowledge distillation where the teacher model benefits from an additional data representation during training, called privileged information, improving the student model, which does not see the extra representation. However, privileged information is rarely available in practice. To this end, we propose a text classification framework that harnesses text-to-image diffusion models to generate artificial privileged information. The generated images and the original text samples are further used to train multimodal teacher models based on state-of-the-art transformer-based architectures. Finally, the knowledge from multimodal teachers is distilled into a text-based (unimodal) student. Hence, by employing a generative model to produce synthetic data as privileged information, we guide the training of the student model. Our framework, called Learning Using Generated Privileged Information (LUGPI), yields noticeable performance g
    
[^19]: Transformer压缩通过子空间投影

    Transformer Compression via Subspace Projection. (arXiv:2308.16475v1 [cs.CL])

    [http://arxiv.org/abs/2308.16475](http://arxiv.org/abs/2308.16475)

    Transformer压缩通过子空间投影，在减小模型隐藏大小的同时实现了较大的模型参数和计算资源的减少，并且与其他方法兼容。

    

    我们提出了一种名为TCSP的新方法，用于通过减少模型的隐藏大小来压缩Transformer模型。通过将整个转换模型投影到一个子空间中，我们使模型中的权重矩阵与减小维度空间中的特征之间可以进行矩阵操作，从而显著减少了模型参数和计算资源。为了建立这个子空间，我们将来自不同层次的采样数据实例的特征矩阵分解为一个投影矩阵。为了评估效果，我们在GLUE和SQuAD基准测试上应用TCSP来压缩T5和BERT模型。实验结果表明，TCSP在保证最多1.6%的准确度降低的情况下实现了44%的压缩比，超过或者达到了先前的压缩方法。此外，TCSP还与其他目标过滤器和注意力头大小压缩的方法相兼容。

    We propose TCSP, a novel method for compressing a transformer model by focusing on reducing the hidden size of the model. By projecting the whole transform model into a subspace, we enable matrix operations between the weight matrices in the model and features in a reduced-dimensional space, leading to significant reductions in model parameters and computing resources. To establish this subspace, we decompose the feature matrix, derived from different layers of sampled data instances, into a projection matrix. For evaluation, TCSP is applied to compress T5 and BERT models on the GLUE and SQuAD benchmarks. Experimental results demonstrate that TCSP achieves a compression ratio of 44\% with at most 1.6\% degradation in accuracy, surpassing or matching prior compression methods. Furthermore, TCSP exhibits compatibility with other methods targeting filter and attention head size compression.
    
[^20]: RAVEN：上下文学习与检索增强的编码器-解码器语言模型

    RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models. (arXiv:2308.07922v1 [cs.CL])

    [http://arxiv.org/abs/2308.07922](http://arxiv.org/abs/2308.07922)

    RAVEN是一种结合了检索增强的蒙特卡洛语言建模和前缀语言建模的模型，通过引入上下文融合学习，它能够在上下文学习方面取得比ATLAS更好的性能。

    

    本文研究了检索增强的编码器-解码器语言模型在上下文学习方面的能力。我们首先对现有的ATLAS模型进行全面分析，发现其在上下文学习方面存在限制，主要原因是预训练和测试之间存在不匹配，以及上下文长度受限。为了解决这些问题，我们提出了RAVEN模型，该模型结合了检索增强的蒙特卡洛语言建模和前缀语言建模。我们还引入了上下文融合学习，通过使模型能够利用更多上下文示例而无需额外训练或模型修改来提高少样本性能。通过大量实验，我们证明了RAVEN在某些场景下明显优于ATLAS，并达到了与最先进的语言模型相当的结果，尽管参数数量显著较少。我们的工作强调了检索增强的编码器-解码器语言模型的潜力。

    In this paper, we investigate the in-context learning ability of retrieval-augmented encoder-decoder language models. We first conduct a comprehensive analysis of the state-of-the-art ATLAS model and identify its limitations in in-context learning, primarily due to a mismatch between pretraining and testing, as well as a restricted context length. To address these issues, we propose RAVEN, a model that combines retrieval-augmented masked language modeling and prefix language modeling. We further introduce Fusion-in-Context Learning to enhance the few-shot performance by enabling the model to leverage more in-context examples without requiring additional training or model modifications. Through extensive experiments, we demonstrate that RAVEN significantly outperforms ATLAS and achieves results comparable to the most advanced language models in certain scenarios, despite having substantially fewer parameters. Our work underscores the potential of retrieval-augmented encoder-decoder lang
    
[^21]: 通过统一的语音和文本表示学习以及单元到单元的翻译实现多对多口语翻译

    Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation. (arXiv:2308.01831v1 [cs.CL])

    [http://arxiv.org/abs/2308.01831](http://arxiv.org/abs/2308.01831)

    本文提出了一种使用统一模型学习多语种语音和文本的表示的方法，重点关注语音合成。通过使用自监督语音模型编码的语音特征的量化表示语音音频，并将其视为伪文本来建立统一的语音和文本表示。然后通过训练编码器-解码器结构模型，利用单元到单元翻译目标将口语语言翻译为目标语言。这种方法能够建立对口语语言的理解并将其相关联到不同的语言。

    

    在本文中，我们提出了一种使用单个模型学习多语种语音和文本的统一表示的方法，特别关注语音合成的目的。我们使用语音单元表示多语种语音音频，这些语音单元是从自监督语音模型编码的语音特征的量化表示。因此，我们可以将音频视为伪文本并专注于其语言内容，从而构建语音和文本的统一表示。然后，我们提出使用多语种数据训练编码器-解码器结构模型，并采用单元到单元翻译（UTUT）目标。具体而言，通过将编码器与源语言标记和解码器与目标语言标记相关联，优化模型以将口语语言翻译为目标语言的语言。因此，该模型可以建立对口语语言的理解以及如何将其与不同语言相关联的知识。

    In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages
    
[^22]: LoraHub: 通过动态LoRA组合实现高效的任务通用性

    LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition. (arXiv:2307.13269v1 [cs.CL])

    [http://arxiv.org/abs/2307.13269](http://arxiv.org/abs/2307.13269)

    本文研究了LoRA组合在跨任务通用性上的可行性，并提出了LoraHub框架，能够通过组合不同任务上训练的LoRA模块，实现对未见任务的可适应性性能。实验结果表明，LoraHub在少样本场景中能够有效模拟上下文学习的性能，而无需上下文示例。

    

    低秩适应（LoRA）常常被用于对新任务进行大型语言模型（LLM）的微调。本文研究了LoRA组合在跨任务通用性上的可行性，并介绍了LoraHub，这是一个为目的性组装在不同给定任务上训练的LoRA模块的战略框架，旨在实现对未见任务的可适应性性能。仅凭借来自新任务的几个示例，LoraHub可以灵活地组合多个LoRA模块，消除了对人类专业知识的需求。值得注意的是，这种组合既不需要额外的模型参数，也不需要梯度。我们从Big-Bench Hard（BBH）基准测试中得出的实证结果表明，LoraHub在少样本场景中可以有效地模拟上下文学习的性能，在每个推理输入旁边不需要上下文示例。我们的研究的一个重要贡献是培育一个LoRA社区，用户可以在其中分享他们训练的LoRA模块。

    Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks. This paper investigates LoRA composability for cross-task generalization and introduces LoraHub, a strategic framework devised for the purposive assembly of LoRA modules trained on diverse given tasks, with the objective of achieving adaptable performance on unseen tasks. With just a few examples from a novel task, LoraHub enables the fluid combination of multiple LoRA modules, eradicating the need for human expertise. Notably, the composition requires neither additional model parameters nor gradients. Our empirical results, derived from the Big-Bench Hard (BBH) benchmark, suggest that LoraHub can effectively mimic the performance of in-context learning in few-shot scenarios, excluding the necessity of in-context examples alongside each inference input. A significant contribution of our research is the fostering of a community for LoRA, where users can share their trained LoRA module
    
[^23]: IncDSI：递增可更新的文档检索

    IncDSI: Incrementally Updatable Document Retrieval. (arXiv:2307.10323v1 [cs.IR])

    [http://arxiv.org/abs/2307.10323](http://arxiv.org/abs/2307.10323)

    IncDSI是一种递增可更新的文档检索方法，它通过最小改变网络参数的约束优化问题，实现实时添加文档而无需重新训练整个模型，具有与重新训练模型相竞争的速度，能够实时更新的文档检索系统的开发。

    

    不同iable搜索索引是最近提出的一种文档检索范例，它将文档语料库的信息编码在神经网络的参数中，并直接将查询映射到相应的文档。这些模型在许多基准测试中取得了最先进的性能。这些模型具有一个重要限制：在训练模型之后添加新文档并不容易。我们提出了IncDSI，一种实时添加文档的方法（每个文档约20-50毫秒），而无需对整个数据集（甚至部分数据集）重新训练模型。相反，我们将添加文档的过程形式化为一个在网络参数上进行最小改变的约束优化问题。虽然速度更快几个数量级，但我们的方法与在整个数据集上重新训练模型相竞争，并且可以实时更新的文档检索系统的开发。我们的IncDSI代码

    Differentiable Search Index is a recently proposed paradigm for document retrieval, that encodes information about a corpus of documents within the parameters of a neural network and directly maps queries to corresponding documents. These models have achieved state-of-the-art performances for document retrieval across many benchmarks. These kinds of models have a significant limitation: it is not easy to add new documents after a model is trained. We propose IncDSI, a method to add documents in real time (about 20-50ms per document), without retraining the model on the entire dataset (or even parts thereof). Instead we formulate the addition of documents as a constrained optimization problem that makes minimal changes to the network parameters. Although orders of magnitude faster, our approach is competitive with re-training the model on the whole dataset and enables the development of document retrieval systems that can be updated with new information in real-time. Our code for IncDSI
    
[^24]: Byte-Pair编码的形式化视角

    A Formal Perspective on Byte-Pair Encoding. (arXiv:2306.16837v1 [cs.CL])

    [http://arxiv.org/abs/2306.16837](http://arxiv.org/abs/2306.16837)

    这篇论文从形式化的角度对Byte-Pair编码进行了研究，将其形式化为组合优化问题，证明了迭代贪婪版本是对最优合并序列的近似解，并优化了算法的运行时间复杂度。

    

    Byte-Pair编码（BPE）是一种用于自然语言处理中的数据标记算法，尽管最初是作为一种压缩方法而设计的。BPE表面上看起来是一种贪婪算法，但是BPE寻求解决的底层优化问题尚未明确。我们将BPE形式化为组合优化问题。通过子模函数，我们证明了迭代贪婪版本是一个对于最优合并序列的$\frac{1}{{\sigma(\boldsymbol{\mu}^\star)}}(1-e^{-{\sigma(\boldsymbol{\mu}^\star)}})$-近似解，其中${\sigma(\boldsymbol{\mu}^\star)}$是相对于最优合并序列$\boldsymbol{\mu}^\star$的总向后曲率。经验证近似解的下界约为$\approx 0.37$。我们提供了一个更快的BPE实现，将运行时间复杂度从$\mathcal{O}\left(N M\right)$优化为$\mathcal{O}\left(N \log M\right)$，其中$N$是序列长度，$M$是合并次数。最后，我们优化了暴力搜索法。

    Byte-Pair Encoding (BPE) is a popular algorithm used for tokenizing data in NLP, despite being devised initially as a compression method. BPE appears to be a greedy algorithm at face value, but the underlying optimization problem that BPE seeks to solve has not yet been laid down. We formalize BPE as a combinatorial optimization problem. Via submodular functions, we prove that the iterative greedy version is a $\frac{1}{{\sigma(\boldsymbol{\mu}^\star)}}(1-e^{-{\sigma(\boldsymbol{\mu}^\star)}})$-approximation of an optimal merge sequence, where ${\sigma(\boldsymbol{\mu}^\star)}$ is the total backward curvature with respect to the optimal merge sequence $\boldsymbol{\mu}^\star$. Empirically the lower bound of the approximation is $\approx 0.37$.  We provide a faster implementation of BPE which improves the runtime complexity from $\mathcal{O}\left(N M\right)$ to $\mathcal{O}\left(N \log M\right)$, where $N$ is the sequence length and $M$ is the merge count. Finally, we optimize the brute
    
[^25]: 大型语言模型可能会具有意识吗？

    Could a Large Language Model be Conscious?. (arXiv:2303.07103v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.07103](http://arxiv.org/abs/2303.07103)

    本文分析了大型语言模型是否具有意识的可能性，目前的模型存在着意识的显著障碍，但未来十年随着障碍被克服，后继的大型语言模型可能会具有意识。

    

    最近普遍讨论了大型语言模型是否具有感知或意识。我们是否应该认真考虑这个想法？本文将分析支持和反对这个想法的最有力的理由。根据意识科学中的主流假设，目前的模型存在着意识的显著障碍，例如缺乏循环处理、全局的工作空间和统一的智能机构等等。与此同时，这些障碍在未来十年左右都可能被克服。作者得出的结论是，虽然目前大型语言模型具有意识的可能性较小，但我们应该认真考虑后继的大型语言模型在不久的将来可能会具有意识。

    There has recently been widespread discussion of whether large language models might be sentient or conscious. Should we take this idea seriously? I will break down the strongest reasons for and against. Given mainstream assumptions in the science of consciousness, there are significant obstacles to consciousness in current models: for example, their lack of recurrent processing, a global workspace, and unified agency. At the same time, it is quite possible that these obstacles will be overcome in the next decade or so. I conclude that while it is somewhat unlikely that current large language models are conscious, we should take seriously the possibility that successors to large language models may be conscious in the not-too-distant future.
    

