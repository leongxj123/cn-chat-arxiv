# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Shape of Word Embeddings: Recognizing Language Phylogenies through Topological Data Analysis](https://arxiv.org/abs/2404.00500) | 通过拓扑数据分析识别语言谱系，研究了单词嵌入的形状如何传递信息，重建的语言谱系树与参考树展现出强烈的相似性。 |
| [^2] | [Entity Alignment with Unlabeled Dangling Cases](https://arxiv.org/abs/2403.10978) | 提出了一种基于GNN的框架，在实体对齐中解决了无标签悬挂案例的问题，通过设计注意机制和正样本-无标签损失来实现更好的对齐性能 |
| [^3] | [MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling](https://arxiv.org/abs/2403.10691) | MYTE是一种基于形态学的字节编码范式，通过使用具有一致大小的片段来实现跨不同语言的信息编码，为99种语言提供了更短的编码，特别是对非欧洲语言和非拉丁文字的改进最为显著。 |
| [^4] | [Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance](https://arxiv.org/abs/2403.09085) | 设计了一个抽象推理数据集和有意义学习范式，教导大型语言模型如何利用通用事实进行推理，有效提升了抽象推理能力。 |
| [^5] | [SPAWNing Structural Priming Predictions from a Cognitively Motivated Parser](https://arxiv.org/abs/2403.07202) | 提出了一个框架，利用实证启动模式来建立理论，使用认知驱动解析器SPAWN生成量化启动预测并评估，并以简化的定语从句为案例研究，发现一个理论的启动预测与实证启动模式一致 |
| [^6] | [Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media](https://arxiv.org/abs/2403.00037) | 提出了面向未知事件的适应性假新闻检测框架FADE，通过自适应增强和图对比学习训练目标预测器，同时独立训练事件预测器，最终减轻事件偏见。 |
| [^7] | [How do Large Language Models Handle Multilingualism?](https://arxiv.org/abs/2402.18815) | 大型语言模型展示了处理多语言任务的出色性能，研究发现在不同层次中处理多语言输入的策略，以及处理特定语言时的语言特定神经元存在。 |
| [^8] | [EHRNoteQA: A Patient-Specific Question Answering Benchmark for Evaluating Large Language Models in Clinical Settings](https://arxiv.org/abs/2402.16040) | 该研究介绍了EHRNoteQA，这是一个新颖的患者特定问题回答基准，旨在评估临床环境中的大型语言模型（LLMs），具有采用多项选择问题回答格式和需要分析多篇临床笔记的特点。 |
| [^9] | [AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning](https://arxiv.org/abs/2402.15506) | AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。 |
| [^10] | [Do Efficient Transformers Really Save Computation?](https://arxiv.org/abs/2402.13934) | 本研究旨在理解高效Transformer（例如稀疏Transformer和线性Transformer）的能力和限制，发现它们适合解决一般DP任务，但不同于标准Transformer。 |
| [^11] | [On Provable Length and Compositional Generalization](https://arxiv.org/abs/2402.04875) | 本研究针对包括深度集合、变压器、状态空间模型和简单递归神经网络等多种架构，探索了可证明的长度和组合泛化，认为对于长度和组合泛化，不同架构需要不同程度的表示识别。 |
| [^12] | [NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation](https://arxiv.org/abs/2312.11361) | 建立了用于评估大型语言模型在多语言环境中检索增强生成中的鲁棒性的NoMIRACL数据集，并提出了两个衡量模型鲁棒性的指标：幻觉率和错误率。 |
| [^13] | [Data Diversity Matters for Robust Instruction Tuning](https://arxiv.org/abs/2311.14736) | 数据多样性对鲁棒指令调整非常重要，我们提出了一种新算法(QDIT)，通过同时控制数据集的多样性和质量，我们深入研究了多样性和质量对指令调整性能的影响，并得出了两个关键观点。 |
| [^14] | [StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving](https://arxiv.org/abs/2311.08803) | StrategyLLM提出了一个框架，利用大型语言模型的能力自动构建可推广和一致的少次提示，优于竞争基线，不需要人工参与。 |
| [^15] | [Deep Augmentation: Self-Supervised Learning with Transformations in Activation Space](https://arxiv.org/abs/2303.14537) | 深度增强是一种利用dropout或PCA在神经网络中转换目标层的方法，有效改善性能和泛化能力。在对比学习任务中，在Transformers、ResNets和图神经网络等基础模型上，通过深度增强实现了显著的性能提升，但在监督问题上效果相反。 |
| [^16] | [Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning.](http://arxiv.org/abs/2401.15043) | 该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。 |
| [^17] | [ChemDFM: Dialogue Foundation Model for Chemistry.](http://arxiv.org/abs/2401.14818) | ChemDFM是首个面向化学智能的大型语言模型，它通过对化学文献和数据的训练，具备了存储、理解和推理化学知识和语言的能力，并且在化学领域的性能上优于其他开源模型。 |
| [^18] | [A survey on recent advances in named entity recognition.](http://arxiv.org/abs/2401.10825) | 这篇综述调查了最近的命名实体识别研究进展，并提供了对不同算法性能的深度比较，还探讨了数据集特征对方法行为的影响。 |
| [^19] | [DeepEdit: Knowledge Editing as Decoding with Constraints.](http://arxiv.org/abs/2401.10471) | DeepEdit是一种神经符号方法，通过更好的推理一致性和对更新知识的意识，提高了大型语言模型的知识编辑能力，对多跳问题数据集MQuaKE取得了显著的进展。 |
| [^20] | [Learning from Emotions, Demographic Information and Implicit User Feedback in Task-Oriented Document-Grounded Dialogues.](http://arxiv.org/abs/2401.09248) | 本论文介绍了FEDI，这是第一个用人口统计信息、用户情绪和隐含反馈对任务导向的文档对话进行注释的英文对话数据集，实验证明这些数据有潜力改善任务完成情况、生成响应的事实一致性和用户接受程度。 |
| [^21] | [UstanceBR: a multimodal language resource for stance prediction.](http://arxiv.org/abs/2312.06374) | UstanceBR是一个多模态语言资源，用于目标立场预测，包含巴西葡萄牙语Twitter领域的86.8k标记立场和发布者的网络信息。这个研究为未来的研究提供了初始基准结果。 |
| [^22] | [Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection.](http://arxiv.org/abs/2309.11896) | FiADD是一种新颖的焦点推理注入与易处理密度区分框架，通过将隐性仇恨言论的表面形式与暗示的形式更接近，同时增加不同类别标签之间的集群间距，显著改进了隐性仇恨分类任务的性能。 |
| [^23] | [RoCar: A Relationship Network-based Evaluation Method to Large Language Models.](http://arxiv.org/abs/2307.15997) | RoCar是一种利用关系网络构建任务图并生成自然语言评估任务的方法，用于评估大型语言模型的推理和记忆能力。该方法通过极大的随机性确保了评估的公平性。 |

# 详细

[^1]: 单词嵌入的形状：通过拓扑数据分析识别语言谱系

    The Shape of Word Embeddings: Recognizing Language Phylogenies through Topological Data Analysis

    [https://arxiv.org/abs/2404.00500](https://arxiv.org/abs/2404.00500)

    通过拓扑数据分析识别语言谱系，研究了单词嵌入的形状如何传递信息，重建的语言谱系树与参考树展现出强烈的相似性。

    

    arXiv:2404.00500v1 类型：新 原文摘要：单词嵌入将语言词汇表示为$d$维空间的点云。我们研究了这些点云的一般形状在除了表示每个令牌的语义意义之外传递信息的方式。具体而言，我们使用拓扑数据分析(TDA)中的持久同调概念来测量从它们未标记的嵌入形状计算的语言对之间的距离。我们使用这些距离矩阵在81种印欧语言之间构建语言谱系树。仔细评估表明我们重建的谱系树与参考树呈现出强烈的相似性。

    arXiv:2404.00500v1 Announce Type: new  Abstract: Word embeddings represent language vocabularies as clouds of $d$-dimensional points. We investigate how information is conveyed by the general shape of these clouds, outside of representing the semantic meaning of each token. Specifically, we use the notion of persistent homology from topological data analysis (TDA) to measure the distances between language pairs from the shape of their unlabeled embeddings. We use these distance matrices to construct language phylogenetic trees over 81 Indo-European languages. Careful evaluation shows that our reconstructed trees exhibit strong similarities to the reference tree.
    
[^2]: 具有无标签悬挂案例的实体对齐

    Entity Alignment with Unlabeled Dangling Cases

    [https://arxiv.org/abs/2403.10978](https://arxiv.org/abs/2403.10978)

    提出了一种基于GNN的框架，在实体对齐中解决了无标签悬挂案例的问题，通过设计注意机制和正样本-无标签损失来实现更好的对齐性能

    

    我们研究了具有无标签悬挂案例的实体对齐问题，这意味着源图或目标图中有一些实体在另一方中没有对应实体，并且这些实体保持未标记状态。该问题出现在源图和目标图的规模不同，并且标记可匹配实体的成本远低于悬挂实体的情况下。为了解决这个问题，我们提出了一种新颖的基于GNN的悬挂检测和实体对齐框架。虽然这两个任务共享相同的GNN，并且一起训练，但检测到的悬挂实体在对齐中被移除。我们的框架特点是具有用于选择性邻域聚合的设计实体和关系注意机制，以及用于对悬挂实体进行无偏估计的正样本-无标签学习损失。实验结果表明我们设计的每个组件都对整体对齐性能有贡献

    arXiv:2403.10978v1 Announce Type: new  Abstract: We investigate the entity alignment problem with unlabeled dangling cases, meaning that there are entities in the source or target graph having no counterparts in the other, and those entities remain unlabeled. The problem arises when the source and target graphs are of different scales, and it is much cheaper to label the matchable pairs than the dangling entities. To solve the issue, we propose a novel GNN-based dangling detection and entity alignment framework. While the two tasks share the same GNN and are trained together, the detected dangling entities are removed in the alignment. Our framework is featured by a designed entity and relation attention mechanism for selective neighborhood aggregation in representation learning, as well as a positive-unlabeled learning loss for an unbiased estimation of dangling entities. Experimental results have shown that each component of our design contributes to the overall alignment performance
    
[^3]: MYTE：形态学驱动的字节编码，用于更好、更公平的多语言语言建模

    MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling

    [https://arxiv.org/abs/2403.10691](https://arxiv.org/abs/2403.10691)

    MYTE是一种基于形态学的字节编码范式，通过使用具有一致大小的片段来实现跨不同语言的信息编码，为99种语言提供了更短的编码，特别是对非欧洲语言和非拉丁文字的改进最为显著。

    

    多语言语言建模中的一个主要考虑因素是如何最好地表示具有不同词汇和文字的语言。尽管当代文本编码方法涵盖了大多数世界文字系统，但它们存在偏向于全球西方高资源语言的问题。因此，少数语言的文本往往被分割为一长串在语言学上毫无意义的单元。为了解决这种不平等，我们引入了一种新的范式，用跨不同语言具有一致大小的片段来编码相同的信息。我们的编码约定（MYTE）基于形态素，因为它们的库存在各种语言中比字符更平衡，而以前的方法使用字符。我们展示MYTE为所有99种分析语言产生了更短的编码，其中非欧洲语言和非拉丁文字的改进最为显著。这进而改善了多语言语言建模的性能。

    arXiv:2403.10691v1 Announce Type: cross  Abstract: A major consideration in multilingual language modeling is how to best represent languages with diverse vocabularies and scripts. Although contemporary text encoding methods cover most of the world's writing systems, they exhibit bias towards the high-resource languages of the Global West. As a result, texts of underrepresented languages tend to be segmented into long sequences of linguistically meaningless units. To address the disparities, we introduce a new paradigm that encodes the same information with segments of consistent size across diverse languages. Our encoding convention (MYTE) is based on morphemes, as their inventories are more balanced across languages than characters, which are used in previous methods. We show that MYTE produces shorter encodings for all 99 analyzed languages, with the most notable improvements for non-European languages and non-Latin scripts. This, in turn, improves multilingual LM performance and di
    
[^4]: 有意义学习：通过通用事实引导推进大型语言模型的抽象推理

    Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance

    [https://arxiv.org/abs/2403.09085](https://arxiv.org/abs/2403.09085)

    设计了一个抽象推理数据集和有意义学习范式，教导大型语言模型如何利用通用事实进行推理，有效提升了抽象推理能力。

    

    大型语言模型（LLMs）在各种推理场景中取得了令人印象深刻的性能和强大的可解释性，标志着朝着模拟人类智能迈出了重要的一步。然而，当面对由通用事实支持的简单问题时，LLMs经常未能提供一致和准确的答案，表明其存在抽象推理能力的不足。这引发了关于LLMs到底是在真正推理还是仅仅在记忆的激烈争论。鉴此，我们设计了一个初步研究来量化并深入探讨现有LLMs的抽象推理能力。我们的研究发现显示出它们的一般推理和抽象推理表现之间存在实质性差异。为了缓解这一问题，我们为大型语言模型定制了一个抽象推理数据集（AbsR），结合有意义的学习范式，教会LLMs如何利用通用事实进行推理。结果表明我们的方法能够显着改善LLMs在抽象推理中的表现。

    arXiv:2403.09085v1 Announce Type: cross  Abstract: Large language models (LLMs) have developed impressive performance and strong explainability across various reasoning scenarios, marking a significant stride towards mimicking human-like intelligence. Despite this, when tasked with simple questions supported by a generic fact, LLMs often fail to provide consistent and precise answers, indicating a deficiency in abstract reasoning abilities. This has sparked a vigorous debate about whether LLMs are genuinely reasoning or merely memorizing. In light of this, we design a preliminary study to quantify and delve into the abstract reasoning abilities of existing LLMs. Our findings reveal a substantial discrepancy between their general reasoning and abstract reasoning performances. To relieve this problem, we tailor an abstract reasoning dataset (AbsR) together with a meaningful learning paradigm to teach LLMs how to leverage generic facts for reasoning purposes. The results show that our app
    
[^5]: 从认知驱动的解析器中预测结构启动的生成

    SPAWNing Structural Priming Predictions from a Cognitively Motivated Parser

    [https://arxiv.org/abs/2403.07202](https://arxiv.org/abs/2403.07202)

    提出了一个框架，利用实证启动模式来建立理论，使用认知驱动解析器SPAWN生成量化启动预测并评估，并以简化的定语从句为案例研究，发现一个理论的启动预测与实证启动模式一致

    

    结构启动是一种广泛使用的心理语言学范式，用于研究人类句子表征。在这项工作中，我们提出了一个框架，用于利用实证启动模式来建立理论，描述人类处理句子时构建的结构表征。该框架使用一种新的认知驱动解析器SPAWN，根据理论句法生成量化启动预测，并用实证人类行为评估这些预测。作为一个案例研究，我们应用这一框架来研究英语中简化的定语从句表征。我们使用SPAWN从两个理论解释中生成启动预测，这两个解释对定语从句的结构做出了不同的假设。我们发现，仅有一个理论（参与式-相位）的预测与实证启动模式一致，从而突出显示出哪些对定语从句的假设更好地捕捉了人类句子表征

    arXiv:2403.07202v1 Announce Type: new  Abstract: Structural priming is a widely used psycholinguistic paradigm to study human sentence representations. In this work we propose a framework for using empirical priming patterns to build a theory characterizing the structural representations humans construct when processing sentences. This framework uses a new cognitively motivated parser, SPAWN, to generate quantitative priming predictions from theoretical syntax and evaluate these predictions with empirical human behavior. As a case study, we apply this framework to study reduced relative clause representations in English. We use SPAWN to generate priming predictions from two theoretical accounts which make different assumptions about the structure of relative clauses. We find that the predictions from only one of these theories (Participial-Phase) align with empirical priming patterns, thus highlighting which assumptions about relative clause better capture human sentence representation
    
[^6]: 未来发展：社交媒体上看不见事件的适应性假新闻检测

    Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media

    [https://arxiv.org/abs/2403.00037](https://arxiv.org/abs/2403.00037)

    提出了面向未知事件的适应性假新闻检测框架FADE，通过自适应增强和图对比学习训练目标预测器，同时独立训练事件预测器，最终减轻事件偏见。

    

    随着社交媒体的快速发展，假新闻在社交媒体上的广泛传播日益威胁个人和社会。在社交媒体动态环境中，假新闻检测旨在开发一个模型，该模型在新闻报道过去事件的基础上进行训练。目标是预测和识别有关未来事件的假新闻，这些事件通常与过去完全不同。然而，现有的假新闻检测方法存在鲁棒性不足，无法泛化到看不见的事件。为了解决这个问题，我们引入了基于未来自适应事件的假新闻检测（FADE）框架。具体来说，我们通过自适应增强策略和图对比学习训练目标预测器，以进行更稳健的整体预测。同时，我们独立训练一个仅事件的预测器以获得有偏见的预测。然后，我们通过获得最终预测来进一步减轻事件偏见。

    arXiv:2403.00037v1 Announce Type: cross  Abstract: With the rapid development of social media, the wide dissemination of fake news on social media is increasingly threatening both individuals and society. In the dynamic landscape of social media, fake news detection aims to develop a model trained on news reporting past events. The objective is to predict and identify fake news about future events, which often relate to subjects entirely different from those in the past. However, existing fake detection methods exhibit a lack of robustness and cannot generalize to unseen events. To address this, we introduce Future ADaptive Event-based Fake news Detection (FADE) framework. Specifically, we train a target predictor through an adaptive augmentation strategy and graph contrastive learning to make more robust overall predictions. Simultaneously, we independently train an event-only predictor to obtain biased predictions. Then we further mitigate event bias by obtaining the final prediction
    
[^7]: 大型语言模型如何处理多语言？

    How do Large Language Models Handle Multilingualism?

    [https://arxiv.org/abs/2402.18815](https://arxiv.org/abs/2402.18815)

    大型语言模型展示了处理多语言任务的出色性能，研究发现在不同层次中处理多语言输入的策略，以及处理特定语言时的语言特定神经元存在。

    

    大型语言模型（LLMs）展现出在各种语言上出色的性能。本文探讨了一个问题：大型语言模型如何处理多语言？我们引入了一个框架，描述了LLMs处理多语言输入的过程：在前几层中，LLMs理解问题，将多语言输入转换为英语以便促进任务解决阶段。在中间层中，LLMs通过以英语思考并整合多语言知识来进行解决问题，利用自注意力和前馈结构，分别获取事实内容。在最后几层中，LLMs生成与查询的原始语言一致的响应。此外，我们研究了处理特定语言时特定语言神经元的存在。为了检测由输入语言激活的神经元，即使没有标签，我们创新性地设计了一个并行语言特定的

    arXiv:2402.18815v1 Announce Type: cross  Abstract: Large language models (LLMs) demonstrate remarkable performance across a spectrum of languages. In this work, we delve into the question: How do LLMs handle multilingualism? We introduce a framework that depicts LLMs' processing of multilingual inputs: In the first several layers, LLMs understand the question, converting multilingual inputs into English to facilitate the task-solving phase. In the intermediate layers, LLMs engage in problem-solving by thinking in English and incorporating multilingual knowledge to obtain factual content, leveraging the self-attention and feed-forward structures, respectively. In the last several layers, LLMs generate responses that align with the original language of the query. In addition, we investigate the existence of language-specific neurons when processing a certain language. To detect neurons activated by the input language, even without labels, we innovatively design a Parallel Language specif
    
[^8]: EHRNoteQA：用于在临床环境中评估大型语言模型的患者特定问题回答基准

    EHRNoteQA: A Patient-Specific Question Answering Benchmark for Evaluating Large Language Models in Clinical Settings

    [https://arxiv.org/abs/2402.16040](https://arxiv.org/abs/2402.16040)

    该研究介绍了EHRNoteQA，这是一个新颖的患者特定问题回答基准，旨在评估临床环境中的大型语言模型（LLMs），具有采用多项选择问题回答格式和需要分析多篇临床笔记的特点。

    

    该研究介绍了EHRNoteQA，这是一个新颖的患者特定问题回答基准，旨在评估临床环境中的大型语言模型（LLMs）。在MIMIC-IV电子健康记录（EHR）的基础上，由三位医疗专家团队精心策划了包含962个独特问题的数据集，每个问题都与特定患者的EHR临床笔记相关联。与现有基于EHR的基准不同的是：首先，它是第一个采用多项选择问题回答格式的数据集，这种设计选择在自动评估的背景下有效评估LLMs的得分性能，与其他格式相比。其次，它需要分析多篇临床笔记才能回答一个问题，反映了实际临床决策制定的复杂性，医生需要审查大量患者病史记录。我们对各种大型语言模型进行了全面评估。

    arXiv:2402.16040v1 Announce Type: new  Abstract: This study introduces EHRNoteQA, a novel patient-specific question answering benchmark tailored for evaluating Large Language Models (LLMs) in clinical environments. Based on MIMIC-IV Electronic Health Record (EHR), a team of three medical professionals has curated the dataset comprising 962 unique questions, each linked to a specific patient's EHR clinical notes. What makes EHRNoteQA distinct from existing EHR-based benchmarks is as follows: Firstly, it is the first dataset to adopt a multi-choice question answering format, a design choice that effectively evaluates LLMs with reliable scores in the context of automatic evaluation, compared to other formats. Secondly, it requires an analysis of multiple clinical notes to answer a single question, reflecting the complex nature of real-world clinical decision-making where clinicians review extensive records of patient histories. Our comprehensive evaluation on various large language models
    
[^9]: AgentOhana：为有效智能体学习设计统一数据和训练流水线

    AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning

    [https://arxiv.org/abs/2402.15506](https://arxiv.org/abs/2402.15506)

    AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。

    

    由大型语言模型（LLMs）提供支持的自主智能体引起了重大研究关注。然而，充分利用LLMs的潜力进行基于智能体的任务面临困难，这是由于具有多轮轨迹的多样化数据源的异构性。在本文中，我们介绍AgentOhana作为解决这些挑战的综合解决方案。AgentOhana从不同环境中聚合智能体轨迹，涵盖了各种情景。它精心地将这些轨迹标准化和统一到一致的格式中，简化了为智能体训练优化的通用数据加载器的创建。通过数据统一，我们的训练流水线在不同数据源之间保持平衡，并在数据集划分和模型训练过程中保持设备之间的独立随机性。此外，我们还介绍了xLAM-v0.1，一个大动作模式

    arXiv:2402.15506v1 Announce Type: new  Abstract: Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce \textbf{AgentOhana} as a comprehensive solution to address these challenges. \textit{AgentOhana} aggregates agent trajectories from distinct environments, spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format, streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification, our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally, we present \textbf{xLAM-v0.1}, a large action mode
    
[^10]: 确实高效的Transformer能够节约计算吗？

    Do Efficient Transformers Really Save Computation?

    [https://arxiv.org/abs/2402.13934](https://arxiv.org/abs/2402.13934)

    本研究旨在理解高效Transformer（例如稀疏Transformer和线性Transformer）的能力和限制，发现它们适合解决一般DP任务，但不同于标准Transformer。

    

    随着基于Transformer的语言模型在越来越大的数据集上训练，并拥有大量参数，找到更高效的替代标准Transformer变得非常有价值。虽然已经提出了许多高效的Transformer和Transformer的替代方案，但没有一个能够提供它们适合替代标准Transformer的理论保证。这使得很难确定何时使用特定模型以及进一步研究的重点。在本文中，我们旨在理解高效Transformer的能力和局限性，特别是稀疏Transformer和线性Transformer。我们专注于它们在Chain-of-Thought (CoT)提示中展示的推理能力，并遵循先前的研究将它们建模为动态规划（DP）问题。我们的结果表明，虽然这些模型足够表达解决一般DP任务的能力，但与标准Transformer不同

    arXiv:2402.13934v1 Announce Type: cross  Abstract: As transformer-based language models are trained on increasingly large datasets and with vast numbers of parameters, finding more efficient alternatives to the standard Transformer has become very valuable. While many efficient Transformers and Transformer alternatives have been proposed, none provide theoretical guarantees that they are a suitable replacement for the standard Transformer. This makes it challenging to identify when to use a specific model and what directions to prioritize for further investigation. In this paper, we aim to understand the capabilities and limitations of efficient Transformers, specifically the Sparse Transformer and the Linear Transformer. We focus on their reasoning capability as exhibited by Chain-of-Thought (CoT) prompts and follow previous works to model them as Dynamic Programming (DP) problems. Our results show that while these models are expressive enough to solve general DP tasks, contrary to ex
    
[^11]: 关于可证明的长度和组合泛化

    On Provable Length and Compositional Generalization

    [https://arxiv.org/abs/2402.04875](https://arxiv.org/abs/2402.04875)

    本研究针对包括深度集合、变压器、状态空间模型和简单递归神经网络等多种架构，探索了可证明的长度和组合泛化，认为对于长度和组合泛化，不同架构需要不同程度的表示识别。

    

    长度泛化——对训练时未见到的更长序列的泛化能力，以及组合泛化——对训练时未见到的令牌组合的泛化能力，在序列到序列模型中是重要的非分布化泛化形式。在这项工作中，我们在包括深度集合、变压器、状态空间模型和简单递归神经网络在内的一系列架构中，朝着可证明的长度和组合泛化迈出了第一步。根据架构的不同，我们证明了不同程度的表示识别的必要性，例如与真实表示具有线性或排列关系。

    Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization.
    
[^12]: NoMIRACL: 知道自己不知道的鲁棒多语言检索增强生成

    NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation

    [https://arxiv.org/abs/2312.11361](https://arxiv.org/abs/2312.11361)

    建立了用于评估大型语言模型在多语言环境中检索增强生成中的鲁棒性的NoMIRACL数据集，并提出了两个衡量模型鲁棒性的指标：幻觉率和错误率。

    

    arXiv:2312.11361v2 公告类型: 替换 摘要: 检索增强生成（RAG）通过利用外部知识源来将大型语言模型（LLM）输出与现实联系起来，以减少事实幻觉。然而，先前的研究缺乏对不同语言族的全面评估，这使得很难评估LLM对外部检索知识错误的鲁棒性。为了克服这一问题，我们建立了NoMIRACL，这是一个人类注释的数据集，用于评估RAG中LLM对18种在类型上多样化的语言的鲁棒性。NoMIRACL包括一个非相关子集和一个相关子集。非相关子集中的查询包含被判断为不相关的段落，而相关子集中的查询至少包含一个被判断为相关的段落。我们使用两个指标来衡量LLM的鲁棒性：（i）幻觉率，衡量模型倾向于在非相关子集的段落中产生幻觉答案的程度，以及（ii）错误率，衡量模型的不准确度。

    arXiv:2312.11361v2 Announce Type: replace  Abstract: Retrieval-augmented generation (RAG) grounds large language model (LLM) output by leveraging external knowledge sources to reduce factual hallucinations. However, prior works lack a comprehensive evaluation of different language families, making it challenging to evaluate LLM robustness against errors in external retrieved knowledge. To overcome this, we establish NoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across 18 typologically diverse languages. NoMIRACL includes both a non-relevant and a relevant subset. Queries in the non-relevant subset contain passages judged as non-relevant, whereas queries in the relevant subset include at least a single judged relevant passage. We measure LLM robustness using two metrics: (i) hallucination rate, measuring model tendency to hallucinate an answer, when the answer is not present in passages in the non-relevant subset, and (ii) error rate, measuring model inaccurac
    
[^13]: 数据多样性对鲁棒指令调整至关重要

    Data Diversity Matters for Robust Instruction Tuning

    [https://arxiv.org/abs/2311.14736](https://arxiv.org/abs/2311.14736)

    数据多样性对鲁棒指令调整非常重要，我们提出了一种新算法(QDIT)，通过同时控制数据集的多样性和质量，我们深入研究了多样性和质量对指令调整性能的影响，并得出了两个关键观点。

    

    最近的研究表明，通过精选高质量且多样化的指令调整数据集，我们可以显著提高指令跟随能力。然而，创建这样的数据集非常困难，大多数研究依赖于手动精选或专有语言模型。自动数据精选很困难，因为仍不清楚如何为指令调整定义多样性，多样性和质量如何相互关联，以及如何优化数据集的质量和多样性。为解决这些问题，我们提出了一种新算法，质量-多样性指令调整(QDIT)。QDIT提供了一种简单的方法来同时控制数据集的多样性和质量，使我们能够深入研究多样性和质量对指令调整性能的影响。从这项研究中，我们得出了两个关键观点：(1)数据多样性和质量之间存在自然的权衡关系，(2)增加数据多样性显著提高最坏情况下的指令跟随性能。

    Recent works have shown that by curating high quality and diverse instruction tuning datasets, we can significantly improve instruction-following capabilities. However, creating such datasets is difficult and most works rely on manual curation or proprietary language models. Automatic data curation is difficult as it is still not clear how we can define diversity for instruction tuning, how diversity and quality depend on one other, and how we can optimize dataset quality and diversity. To resolve these issue, we propose a new algorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT provides a simple method to simultaneously control dataset diversity and quality, allowing us to conduct an in-depth study on the effect of diversity and quality on instruction tuning performance. From this study we draw two key insights (1) there is a natural tradeoff between data diversity and quality and (2) increasing data diversity significantly improves the worst case instruction following perform
    
[^14]: StrategyLLM：大型语言模型作为问题解决的策略生成器、执行器、优化器和评估器

    StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving

    [https://arxiv.org/abs/2311.08803](https://arxiv.org/abs/2311.08803)

    StrategyLLM提出了一个框架，利用大型语言模型的能力自动构建可推广和一致的少次提示，优于竞争基线，不需要人工参与。

    

    大多数现有的思维链 (CoT) 提示方法存在泛化和一致性问题，因为它们常常依赖于特定实例的解决方案，这些解决方案可能不适用于其他情况，并缺乏在推理步骤中的任务级一致性。为解决这些限制，我们提出了一个全面的框架，StrategyLLM，利用LLM的能力自动构建可推广和一致的少次提示以用于各种任务。为此，StrategyLLM 使用四个基于LLM的代理：策略生成器、执行器、优化器和评估器，共同工作以为给定任务生成、评估和选择有前途的策略。实验结果表明，在13个数据集上跨4个挑战性任务上，不需要人工参与，StrategyLLM 在数学推理（34.21%->38.79%）、常见推理等任务上优于竞争基线CoT-SC，该基线需要人工注释的解决方案。

    arXiv:2311.08803v2 Announce Type: replace  Abstract: Most existing chain-of-thought (CoT) prompting methods suffer from the issues of generalizability and consistency, as they often rely on instance-specific solutions that may not be applicable to other cases and lack task-level consistency in their reasoning steps. To address these limitations, we propose a comprehensive framework, StrategyLLM, harnessing the capabilities of LLMs to construct generalizable and consistent few-shot prompts for various tasks automatically. To this end, StrategyLLM employs four LLM-based agents: strategy generator, executor, optimizer, and evaluator, working together to generate, evaluate, and select promising strategies for a given task. The experimental results demonstrate that StrategyLLM outperforms the competitive baseline CoT-SC that requires human-annotated solutions on 13 datasets across 4 challenging tasks without human involvement, including math reasoning (34.21% $\rightarrow$ 38.79%), commonse
    
[^15]: 深度增强：在激活空间中使用自监督学习进行数据增强

    Deep Augmentation: Self-Supervised Learning with Transformations in Activation Space

    [https://arxiv.org/abs/2303.14537](https://arxiv.org/abs/2303.14537)

    深度增强是一种利用dropout或PCA在神经网络中转换目标层的方法，有效改善性能和泛化能力。在对比学习任务中，在Transformers、ResNets和图神经网络等基础模型上，通过深度增强实现了显著的性能提升，但在监督问题上效果相反。

    

    我们提出了一种称为深度增强的方法，通过使用辍学或PCA来转换神经网络中的目标层，以提高性能和泛化能力。我们通过在自然语言处理、计算机视觉和图学习中的对比学习任务上进行大量实验来展示深度增强。 我们观察到在对比学习的基础模型中，如Transformers、ResNets和图神经网络上深度增强能够带来显著的性能提升，但在相应的监督问题上观察到相反的效果。 我们的分析表明，深度增强减轻了层之间的相互适应，即"崩溃"形式的问题。 我们利用这一观察结果制定了一种选择目标层的方法；特别是，我们的实验表明，用深度增强定位更深层次的层要优于增强输入数据。 这种方法的简单网络和模态无关性使其

    arXiv:2303.14537v2 Announce Type: replace-cross  Abstract: We introduce Deep Augmentation, an approach to implicit data augmentation using dropout or PCA to transform a targeted layer within a neural network to improve performance and generalization. We demonstrate Deep Augmentation through extensive experiments on contrastive learning tasks in NLP, computer vision, and graph learning. We observe substantial performance gains with Transformers, ResNets, and Graph Neural Networks as the underlying models in contrastive learning, but observe inverse effects on the corresponding supervised problems. Our analysis suggests that Deep Augmentation alleviates co-adaption between layers, a form of "collapse." We use this observation to formulate a method for selecting which layer to target; in particular, our experimentation reveals that targeting deeper layers with Deep Augmentation outperforms augmenting the input data. The simple network- and modality-agnostic nature of this approach enables
    
[^16]: 健康文本简化：消化癌症教育的注释语料库和增强学习的新策略

    Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning. (arXiv:2401.15043v1 [cs.CL])

    [http://arxiv.org/abs/2401.15043](http://arxiv.org/abs/2401.15043)

    该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。

    

    目标：健康教育材料的阅读水平显著影响信息的可理解性和可接触性，特别是对于少数族裔人群。许多患者教育资源超过了广泛接受的标准的阅读水平和复杂性。在健康信息中，急需高性能的文本简化模型以增强传播和识字能力。这种需要在癌症教育中尤为迫切，有效的预防和筛查教育可以大大减少发病率和死亡率。方法：我们引入了简化的消化癌症（SimpleDC）并行语料库，用于健康文本简化研究。利用SimpleDC和现有的Med-EASi语料库，我们探索了基于大型语言模型（LLM）的简化方法，包括微调、增强学习（RL）、增强学习与人类反馈（RLHF）、领域自适应和基于提示的应用。

    Objective: The reading level of health educational materials significantly influences information understandability and accessibility, particularly for minoritized populations. Many patient educational resources surpass the reading level and complexity of widely accepted standards. There is a critical need for high-performing text simplification models in health information to enhance dissemination and literacy. This need is particularly acute in cancer education, where effective prevention and screening education can substantially reduce morbidity and mortality.  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel corpus of cancer education materials tailored for health text simplification research. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore Large Language Model (LLM)-based simplification methods, including fine-tuning, reinforcement learning (RL), reinforcement learning with human feedback (RLHF), domain adaptation, and prompt-based app
    
[^17]: ChemDFM: 化学领域对话基础模型

    ChemDFM: Dialogue Foundation Model for Chemistry. (arXiv:2401.14818v1 [cs.CL])

    [http://arxiv.org/abs/2401.14818](http://arxiv.org/abs/2401.14818)

    ChemDFM是首个面向化学智能的大型语言模型，它通过对化学文献和数据的训练，具备了存储、理解和推理化学知识和语言的能力，并且在化学领域的性能上优于其他开源模型。

    

    大型语言模型(LLMs)在自然语言处理的一般领域取得了巨大成功。它们的任务概括和自由对话能力可以极大地帮助设计化学智能(CGI)，以协助化学领域的实际研究。然而，在化学领域中存在专业语言和知识，如高度信息化的SMILES符号表示法，阻碍了一般领域LLMs在化学领域的性能。为此，我们开发了ChemDFM，这是首个面向CGI的LLM。ChemDFM-13B是在化学文献、教科书、说明书以及各种一般领域的数据中训练的34B令牌。因此，它可以存储、理解和推理化学知识和语言，同时具有先进的自由形式语言理解能力。广泛的定量评估表明，ChemDFM可以明显优于代表性的开源LLMs。此外，ChemDFM还可以...

    Large language models (LLMs) have established great success in the general domain of natural language processing. Their emerging task generalization and free-form dialogue capabilities can greatly help to design Chemical General Intelligence (CGI) to assist real-world research in chemistry. However, the existence of specialized language and knowledge in the field of chemistry, such as the highly informative SMILES notation, hinders the performance of general-domain LLMs in chemistry. To this end, we develop ChemDFM, the first LLM towards CGI. ChemDFM-13B is trained on 34B tokens from chemical literature, textbooks, and instructions as well as various data from the general domain. Therefore, it can store, understand, and reason over chemical knowledge and languages while still possessing advanced free-form language comprehension capabilities. Extensive quantitative evaluation shows that ChemDFM can significantly outperform the representative open-sourced LLMs. Moreover, ChemDFM can also
    
[^18]: 最新进展的命名实体识别综述

    A survey on recent advances in named entity recognition. (arXiv:2401.10825v1 [cs.CL])

    [http://arxiv.org/abs/2401.10825](http://arxiv.org/abs/2401.10825)

    这篇综述调查了最近的命名实体识别研究进展，并提供了对不同算法性能的深度比较，还探讨了数据集特征对方法行为的影响。

    

    命名实体识别旨在从文本中提取出命名真实世界对象的子字符串，并确定其类型（例如，是否指人物或组织）。在本综述中，我们首先概述了最近流行的方法，同时还关注了基于图和变换器的方法，包括很少在其他综述中涉及的大型语言模型（LLMs）。其次，我们重点介绍了针对稀缺注释数据集设计的方法。第三，我们评估了主要命名实体识别实现在各种具有不同特征（领域、规模和类别数）的数据集上的性能。因此，我们提供了一种从未同时考虑的算法的深度比较。我们的实验揭示了数据集特征如何影响我们比较的方法的行为。

    Named Entity Recognition seeks to extract substrings within a text that name real-world objects and to determine their type (for example, whether they refer to persons or organizations). In this survey, we first present an overview of recent popular approaches, but we also look at graph- and transformer- based methods including Large Language Models (LLMs) that have not had much coverage in other surveys. Second, we focus on methods designed for datasets with scarce annotations. Third, we evaluate the performance of the main NER implementations on a variety of datasets with differing characteristics (as regards their domain, their size, and their number of classes). We thus provide a deep comparison of algorithms that are never considered together. Our experiments shed some light on how the characteristics of datasets affect the behavior of the methods that we compare.
    
[^19]: DeepEdit: 带有约束的解码式知识编辑

    DeepEdit: Knowledge Editing as Decoding with Constraints. (arXiv:2401.10471v1 [cs.CL])

    [http://arxiv.org/abs/2401.10471](http://arxiv.org/abs/2401.10471)

    DeepEdit是一种神经符号方法，通过更好的推理一致性和对更新知识的意识，提高了大型语言模型的知识编辑能力，对多跳问题数据集MQuaKE取得了显著的进展。

    

    我们将大型语言模型（LLMs）的知识编辑视为带有约束的解码过程。我们提出了DeepEdit（基于深度优先搜索的渐进式解码知识编辑），这是一种神经符号方法，通过更好的推理一致性、问题相关性和对更新知识的意识来改进知识编辑。DeepEdit可灵活应用于所有黑盒LLMs：不需要访问模型参数、表示或输出词汇分布。DeepEdit逐步产生高质量的推理步骤，以实现有效的知识编辑。它利用深度优先搜索来修改LLMs的输出，从而提高输出对问题的相关性和对更新知识的意识。在知识编辑方面，DeepEdit在控制LLMs产生更简洁的推理方面表现出色。在MQuaKE上，DeepEdit在定量上取得了显著的进展，这是一个具有挑战性的多跳问题数据集。

    We develop a new perspective of knowledge editing for large language models (LLMs) as decoding with constraints. We propose DeepEdit (Depth-first Search based Progressive Decoding for Knowledge Editing), a neuro-symbolic method that improves knowledge editing with better coherence of reasoning, relevance to the question, and awareness of updated knowledge. DeepEdit can be flexibly applied to all black-box LLMs: it does not require any access to the model parameters, representations, or output vocabulary distributions. DeepEdit progressively produces the high-quality reasoning steps towards effective knowledge editing. It utilizes a depth-first search to revise the LLMs' output, which improves the output's informativeness to the input question and awareness of the updated knowledge. Qualitatively, DeepEdit effectively controls LLMs to produce more succinct reasoning in accord with knowledge editing. Quantitatively, DeepEdit yields significant gains on MQuaKE, a challenging multi-hop que
    
[^20]: 从情绪、人口统计信息和隐含用户反馈中学习任务导向的文档对话

    Learning from Emotions, Demographic Information and Implicit User Feedback in Task-Oriented Document-Grounded Dialogues. (arXiv:2401.09248v1 [cs.CL])

    [http://arxiv.org/abs/2401.09248](http://arxiv.org/abs/2401.09248)

    本论文介绍了FEDI，这是第一个用人口统计信息、用户情绪和隐含反馈对任务导向的文档对话进行注释的英文对话数据集，实验证明这些数据有潜力改善任务完成情况、生成响应的事实一致性和用户接受程度。

    

    任务导向和文档对话系统的成功取决于用户接受和享受使用它们。为了实现这一目标，人机交互领域的最新研究表明，考虑人口统计信息、用户情绪并从他们的话语中学习隐含反馈的组合尤为重要。然而，这些发现尚未转移到自然语言处理领域，这些数据主要是分别研究的。因此，目前没有足够注释的数据集可用。为了填补这一空白，我们引入了FEDI，这是第一个用人口统计信息、用户情绪和隐含反馈对任务导向的文档对话进行注释的英文对话数据集。我们使用FLAN-T5、GPT-2和LLaMA-2进行的实验证明，这些数据有潜力改善任务完成情况、生成响应的事实一致性和用户接受程度。

    The success of task-oriented and document-grounded dialogue systems depends on users accepting and enjoying using them. To achieve this, recently published work in the field of Human-Computer Interaction suggests that the combination of considering demographic information, user emotions and learning from the implicit feedback in their utterances, is particularly important. However, these findings have not yet been transferred to the field of Natural Language Processing, where these data are primarily studied separately. Accordingly, no sufficiently annotated dataset is available. To address this gap, we introduce FEDI, the first English dialogue dataset for task-oriented document-grounded dialogues annotated with demographic information, user emotions and implicit feedback. Our experiments with FLAN-T5, GPT-2 and LLaMA-2 show that these data have the potential to improve task completion and the factual consistency of the generated responses and user acceptance.
    
[^21]: UstanceBR:一种用于目标立场预测的多模态语言资源

    UstanceBR: a multimodal language resource for stance prediction. (arXiv:2312.06374v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.06374](http://arxiv.org/abs/2312.06374)

    UstanceBR是一个多模态语言资源，用于目标立场预测，包含巴西葡萄牙语Twitter领域的86.8k标记立场和发布者的网络信息。这个研究为未来的研究提供了初始基准结果。

    

    本研究介绍了UstanceBR，这是一个用于巴西葡萄牙语Twitter领域的多模态语料库，用于目标立场预测。该语料库包含对所选目标主题的86.8k标记立场，并且包含了发布这些立场的社交媒体用户的广泛网络信息。在本文中，我们描述了语料库的多模态数据，并提供了基于文本和网络相关信息的领域内和零样本立场预测的多个使用示例，旨在为未来的研究提供初始基准结果。

    This work introduces UstanceBR, a multimodal corpus in the Brazilian Portuguese Twitter domain for target-based stance prediction. The corpus comprises 86.8 k labelled stances towards selected target topics, and extensive network information about the users who published these stances on social media. In this article we describe the corpus multimodal data, and a number of usage examples in both in-domain and zero-shot stance prediction based on textand network-related information, which are intended to provide initial baseline results for future studies in the field.
    
[^22]: 针对隐性仇恨言论的焦点推理注入与易处理密度区分

    Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection. (arXiv:2309.11896v1 [cs.CL])

    [http://arxiv.org/abs/2309.11896](http://arxiv.org/abs/2309.11896)

    FiADD是一种新颖的焦点推理注入与易处理密度区分框架，通过将隐性仇恨言论的表面形式与暗示的形式更接近，同时增加不同类别标签之间的集群间距，显著改进了隐性仇恨分类任务的性能。

    

    虽然预训练的大型语言模型（PLMs）在许多NLP任务上取得了最先进的成果，但它们缺乏对隐性仇恨言论微妙表达的理解。这样微妙而隐性的仇恨经常被错误地分类为非仇恨。通过增加外部的上下文或通过基于距离的度量强制标签分离，已经尝试过各种方法来增强（隐性）仇恨内容的检测。我们将这两种方法结合起来并引入了一种新颖的焦点推理适应密度区分框架（FiADD）。FiADD通过将隐性仇恨言论的表面形式与暗示的形式更接近，同时增加不同类别标签之间的集群间距，来增强PLM微调管道。我们在三个隐性仇恨数据集上测试了FiADD，并观察到在两类和三类仇恨分类任务中的显著改进。我们进一步对FiADD在三个其他任务上的泛化性进行了实验，即检测讽刺、讽刺和立场。

    Although pre-trained large language models (PLMs) have achieved state-of-the-art on many NLP tasks, they lack understanding of subtle expressions of implicit hate speech. Such nuanced and implicit hate is often misclassified as non-hate. Various attempts have been made to enhance the detection of (implicit) hate content by augmenting external context or enforcing label separation via distance-based metrics. We combine these two approaches and introduce FiADD, a novel Focused Inferential Adaptive Density Discrimination framework. FiADD enhances the PLM finetuning pipeline by bringing the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks. We further experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in whic
    
[^23]: RoCar:一种基于关系网络的大型语言模型评估方法

    RoCar: A Relationship Network-based Evaluation Method to Large Language Models. (arXiv:2307.15997v1 [cs.CL])

    [http://arxiv.org/abs/2307.15997](http://arxiv.org/abs/2307.15997)

    RoCar是一种利用关系网络构建任务图并生成自然语言评估任务的方法，用于评估大型语言模型的推理和记忆能力。该方法通过极大的随机性确保了评估的公平性。

    

    大型语言模型（LLMs）受到越来越多的关注。然而，由于其能力的复杂性，如何合理评估LLMs的能力仍然是一个需要解决的任务。我们提出了RoCar方法，利用定义的基本模式随机构建一个任务图，并基于任务图生成自然语言评估任务，分别评估LLMs的推理和记忆能力。由于任务构建过程的极大随机性，可以确保被测试的LLMs中没有一个直接学习了评估任务，从而保证了评估方法的公平性。

    Large language models (LLMs) have received increasing attention. However, due to the complexity of its capabilities, how to rationally evaluate the capabilities of LLMs is still a task to be solved. We propose the RoCar method, which utilizes the defined basic schemas to randomly construct a task graph and generates natural language evaluation tasks based on the task graph to evaluate the reasoning and memory abilities of LLMs respectively. Due to the very large randomness of the task construction process, it is possible to ensure that none of the LLMs to be tested has directly learned the evaluation tasks, guaranteeing the fairness of the evaluation method.
    

