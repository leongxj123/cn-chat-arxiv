# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs](https://arxiv.org/abs/2404.01343) | CHOPS提出了一个名为CHOPS的LLM代理，旨在更高效地利用现有数据库或系统来访问用户信息，提供准确合理的响应或执行所需操作，同时避免有害操作。 |
| [^2] | [On the Fragility of Active Learners](https://arxiv.org/abs/2403.15744) | 本研究发现主动学习技术只在特定情境下有效，对文本分类从业者的建议是选择适当的文本表示和分类器同样重要。 |
| [^3] | [The First to Know: How Token Distributions Reveal Hidden Knowledge in Large Vision-Language Models?](https://arxiv.org/abs/2403.09037) | 本研究利用线性探测揭示了大型视觉语言模型的隐藏知识，发现首个令牌的logit分布包含足够信息，可以识别无法回答的视觉问题、防范多模态越狱攻击以及识别欺骗性问题，并提出了一个简单的解码策略以有效改善生成内容。 |
| [^4] | [Hierarchical Indexing for Retrieval-Augmented Opinion Summarization](https://arxiv.org/abs/2403.00435) | HIRO 是一种用于无监督抽象意见摘要的方法，通过学习索引结构来提取输入评论中流行意见的句子簇，并利用预训练的大型语言模型生成相关的摘要，得到更具语义结构的编码空间和更具代表性的摘要。 |
| [^5] | [Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment](https://arxiv.org/abs/2402.13956) | 作者调查了神经LM是否可以通过下一个词预测来解码蕴涵判断，发现它们可以远高于随机几率地解码自然句子之间的蕴涵关系，暗示LM隐含地模拟了语义的某些方面。 |
| [^6] | [Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity](https://arxiv.org/abs/2402.13130) | 该研究探索了ELECTRA句子嵌入向量性能问题，并提出了一种新的截断模型微调方法，显著提高了语义文本相似性任务的表现 |
| [^7] | [EmoBench: Evaluating the Emotional Intelligence of Large Language Models](https://arxiv.org/abs/2402.12071) | EmoBench是一个基于心理学理论的基准测试，旨在评估大型语言模型的情感智能，包括情感理解和情感应用。 |
| [^8] | [BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains](https://arxiv.org/abs/2402.10373) | BioMistral是一种面向生物医学领域的开源预训练大型语言模型集合，在医学问答任务中表现出优越性能并具有竞争优势。 |
| [^9] | [Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following](https://arxiv.org/abs/2402.06559) | 本文提出了一种Diffusion-ES方法，它结合了无梯度优化和轨迹去噪技术，用于优化黑盒非可微目标。该方法通过从扩散模型中采样轨迹，并使用黑盒奖励函数对其进行评分，实现了更高的多样性和可解释性。 |
| [^10] | [Continuously Learning New Words in Automatic Speech Recognition.](http://arxiv.org/abs/2401.04482) | 该论文提出了一种自我监督的持续学习方法，用于解决自动语音识别中识别新词的问题。通过对讲座录音进行推理和收集包含新词的话语，然后在自适应数据集上进行持续学习，可以在新词出现频率较高时提高性能，同时保持整体性能。 |
| [^11] | [Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization.](http://arxiv.org/abs/2310.05506) | 本文调查了在数学推理中使用数据增强的效果，并通过创建新的数据集和微调模型取得了显著成果。 |
| [^12] | [Auto-Regressive Next-Token Predictors are Universal Learners.](http://arxiv.org/abs/2309.06979) | 自回归的下一个标记预测器可以有效地近似图灵机计算的任何函数，并且在文本生成和算术任务上展现出非平凡的性能。 |
| [^13] | [End-to-End Evaluation for Low-Latency Simultaneous Speech Translation.](http://arxiv.org/abs/2308.03415) | 本文提出了一个端到端的评估框架，用于评估低延迟语音翻译的各个方面。通过该框架，我们比较了不同方法的性能，并进行了全面的评估。 |
| [^14] | [Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models.](http://arxiv.org/abs/2308.00304) | 本文介绍了一种名为技能指导 (SKiC) 的提示策略，通过在上下文中演示基本技能和组合性示例，使大型语言模型具备解决更复杂问题的能力，并在泛化能力上取得几乎完美的表现。 |
| [^15] | [GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study.](http://arxiv.org/abs/2305.13062) | 本文设计了一个基准测试来评估大型语言模型（LLMs）对结构化表格数据的理解能力，并发现不同的输入选择会对性能产生影响。在基准测试的基础上，提出了“自我增强”技术以改善理解能力。 |
| [^16] | [Towards Understanding and Improving Knowledge Distillation for Neural Machine Translation.](http://arxiv.org/abs/2305.08096) | 本文揭示了神经机器翻译中知识蒸馏的本质，即来自于教师模型的top-1预测。同时，指出了当前基于词级别的知识蒸馏存在的问题，并提出了一种新方法——Top-1 Information。 |

# 详细

[^1]: CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs

    CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs

    [https://arxiv.org/abs/2404.01343](https://arxiv.org/abs/2404.01343)

    CHOPS提出了一个名为CHOPS的LLM代理，旨在更高效地利用现有数据库或系统来访问用户信息，提供准确合理的响应或执行所需操作，同时避免有害操作。

    

    商业和软件平台越来越倾向于使用像GPT-3.5、GPT-4、GLM-3和LLaMa-2这样的大型语言模型（LLMs）作为客户服务的聊天辅助或推理代理。然而，当前基于LLM的客户服务模型在与客户配置文件的集成方面存在局限，并且缺乏有效服务所需的操作能力。为了解决这些问题，我们提出了一个名为CHOPS（CHat with custOmer Profile in existing System）的LLM代理，旨在：（1）高效利用现有数据库或系统以访问用户信息或按照现有指南与这些系统交互；（2）提供准确合理的响应或在系统中执行所需操作，同时避免有害操作；（3）利用

    arXiv:2404.01343v1 Announce Type: cross  Abstract: Businesses and software platforms are increasingly turning to Large Language Models (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistance with file access or as reasoning agents for customer service. However, current LLM-based customer service models have limited integration with customer profiles and lack the operational capabilities necessary for effective service. Moreover, existing API integrations emphasize diversity over the precision and error avoidance essential in real-world customer service scenarios. To address these issues, we propose an LLM agent named CHOPS (CHat with custOmer Profile in existing System), designed to: (1) efficiently utilize existing databases or systems for accessing user information or interacting with these systems following existing guidelines; (2) provide accurate and reasonable responses or carry out required operations in the system while avoiding harmful operations; and (3) leverag
    
[^2]: 论主动学习者的脆弱性

    On the Fragility of Active Learners

    [https://arxiv.org/abs/2403.15744](https://arxiv.org/abs/2403.15744)

    本研究发现主动学习技术只在特定情境下有效，对文本分类从业者的建议是选择适当的文本表示和分类器同样重要。

    

    主动学习（AL）技术旨在通过迭代选择最有可能提高预测准确性的实例，最大程度地利用标注预算。然而，与随机抽样相比，在不同设置下（例如不同数据集，分类器），它们的益处并不一致。在这项实证研究中，我们研究了不同因素的组合如何可能掩盖主动学习技术的任何收益。专注于文本分类，我们在大约1000个实验中严格评估了进行分类，我们在大约1000个实验中严格评估了AL技术，这些实验在数据集、批大小、文本表示和分类器方面变化。我们表明，AL只在一组有限的情境中有效。我们还解决了使用与现实世界期望更好对齐的度量的问题。这项研究的影响在于对从业者的洞察：(a) 文本表示和分类器的选择与AL技术的选择一样重要，(b) 选择的

    arXiv:2403.15744v1 Announce Type: cross  Abstract: Active learning (AL) techniques aim to maximally utilize a labeling budget by iteratively selecting instances that are most likely to improve prediction accuracy. However, their benefit compared to random sampling has not been consistent across various setups, e.g., different datasets, classifiers. In this empirical study, we examine how a combination of different factors might obscure any gains from an AL technique.   Focusing on text classification, we rigorously evaluate AL techniques over around 1000 experiments that vary wrt the dataset, batch size, text representation and the classifier. We show that AL is only effective in a narrow set of circumstances. We also address the problem of using metrics that are better aligned with real world expectations.   The impact of this study is in its insights for a practitioner: (a) the choice of text representation and classifier is as important as that of an AL technique, (b) choice of the 
    
[^3]: 第一个知道：令牌分布如何揭示大型视觉语言模型中的隐藏知识？

    The First to Know: How Token Distributions Reveal Hidden Knowledge in Large Vision-Language Models?

    [https://arxiv.org/abs/2403.09037](https://arxiv.org/abs/2403.09037)

    本研究利用线性探测揭示了大型视觉语言模型的隐藏知识，发现首个令牌的logit分布包含足够信息，可以识别无法回答的视觉问题、防范多模态越狱攻击以及识别欺骗性问题，并提出了一个简单的解码策略以有效改善生成内容。

    

    大型视觉语言模型（LVLMs）旨在解释和响应人类指令，但由于不当指令而偶尔生成幻觉或有害内容。本研究使用线性探测来揭示LVLMs输出层的隐藏知识。我们证明了首个令牌的logit分布包含足够信息，可以确定是否应对指令作出响应，包括识别无法回答的视觉问题、防范多模态越狱攻击以及识别欺骗性问题。这种隐藏知识在响应生成过程中随后令牌的logit逐渐丢失。然后，我们演示了一种简单的解码策略在生成第一个令牌时，有效改善生成的内容。在实验中，我们发现了一些有趣的见解：首先，CLIP模型已经包含解决这些任务的强烈信号，表明潜力

    arXiv:2403.09037v1 Announce Type: cross  Abstract: Large vision-language models (LVLMs), designed to interpret and respond to human instructions, occasionally generate hallucinated or harmful content due to inappropriate instructions. This study uses linear probing to shed light on the hidden knowledge at the output layer of LVLMs. We demonstrate that the logit distributions of the first tokens contain sufficient information to determine whether to respond to the instructions, including recognizing unanswerable visual questions, defending against multi-modal jailbreaking attack, and identifying deceptive questions. Such hidden knowledge is gradually lost in logits of subsequent tokens during response generation. Then, we illustrate a simple decoding strategy at the generation of the first token, effectively improving the generated content. In experiments, we find a few interesting insights: First, the CLIP model already contains a strong signal for solving these tasks, indicating poten
    
[^4]: 用于检索增强意见摘要的分层索引

    Hierarchical Indexing for Retrieval-Augmented Opinion Summarization

    [https://arxiv.org/abs/2403.00435](https://arxiv.org/abs/2403.00435)

    HIRO 是一种用于无监督抽象意见摘要的方法，通过学习索引结构来提取输入评论中流行意见的句子簇，并利用预训练的大型语言模型生成相关的摘要，得到更具语义结构的编码空间和更具代表性的摘要。

    

    我们提出了一种用于无监督抽象意见摘要的方法，结合了抽取方法的可归因性和可扩展性以及大型语言模型(LLMs)的连贯性和流畅性。我们的方法，HIRO，学习了一个将句子映射到通过语义组织的离散层次结构路径的索引结构。在推断时，我们填充索引并使用它来识别和检索包含输入评论中流行意见的句子簇。然后，我们使用一个预训练的LLM生成一个基于这些提取的证据簇的可读摘要。我们的方法的模块化性允许我们在每个阶段评估其有效性。我们展示了HIRO学习了比先前工作更具语义结构的编码空间，并生成了更符合输入评论中意见的摘要。人类评估证实，HIRO生成的摘要更连贯、详细和准确。

    arXiv:2403.00435v1 Announce Type: new  Abstract: We propose a method for unsupervised abstractive opinion summarization, that combines the attributability and scalability of extractive approaches with the coherence and fluency of Large Language Models (LLMs). Our method, HIRO, learns an index structure that maps sentences to a path through a semantically organized discrete hierarchy. At inference time, we populate the index and use it to identify and retrieve clusters of sentences containing popular opinions from input reviews. Then, we use a pretrained LLM to generate a readable summary that is grounded in these extracted evidential clusters. The modularity of our approach allows us to evaluate its efficacy at each stage. We show that HIRO learns an encoding space that is more semantically structured than prior work, and generates summaries that are more representative of the opinions in the input reviews. Human evaluation confirms that HIRO generates more coherent, detailed and accur
    
[^5]: 你能通过下一个词预测学习语义吗？以蕴涵为例

    Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment

    [https://arxiv.org/abs/2402.13956](https://arxiv.org/abs/2402.13956)

    作者调查了神经LM是否可以通过下一个词预测来解码蕴涵判断，发现它们可以远高于随机几率地解码自然句子之间的蕴涵关系，暗示LM隐含地模拟了语义的某些方面。

    

    Merrill等人（2022）认为，在理论上，最优LM预测的概率编码了关于蕴涵关系的语义信息，但是由于Merrill等人提出的强烈理想化假设，不清楚神经LM在训练语料库上是否通过这种方式学习蕴涵。在这项工作中，我们调查了他们的理论是否可以用于从神经LM中解码蕴涵判断。我们发现类似于他们的测试可以在许多数据集和LM中解码自然句子之间的蕴涵关系，远远超过随机机会，尽管不是完美的。这表明LM隐含地模拟了语义的某些方面，以预测句子共现模式上的语义效应。但是，我们发现实际上预测蕴涵的测试与理论测试的方向相反。因此，我们重新审视了潜在的理论假设。

    arXiv:2402.13956v1 Announce Type: new  Abstract: Do LMs infer the semantics of text from co-occurrence patterns in their training data? Merrill et al. (2022) argue that, in theory, probabilities predicted by an optimal LM encode semantic information about entailment relations, but it is unclear whether neural LMs trained on corpora learn entailment in this way because of strong idealizing assumptions made by Merrill et al. In this work, we investigate whether their theory can be used to decode entailment judgments from neural LMs. We find that a test similar to theirs can decode entailment relations between natural sentences, well above random chance, though not perfectly, across many datasets and LMs. This suggests LMs implicitly model aspects of semantics to predict semantic effects on sentence co-occurrence patterns. However, we find the test that predicts entailment in practice works in the opposite direction to the theoretical test. We thus revisit the assumptions underlying the o
    
[^6]: ELECTRA的句子嵌入是否无法修复？语义文本相似性案例

    Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity

    [https://arxiv.org/abs/2402.13130](https://arxiv.org/abs/2402.13130)

    该研究探索了ELECTRA句子嵌入向量性能问题，并提出了一种新的截断模型微调方法，显著提高了语义文本相似性任务的表现

    

    虽然BERT生成具有高质量的句子嵌入向量，但其预训练计算成本是一个明显的缺点。相比之下，ELECTRA提供了一种经济高效的预训练目标和下游任务性能提升，但其句子嵌入向量表现不佳。社区悄然停止使用ELECTRA的句子嵌入向量进行语义文本相似性（STS）任务。我们注意到使用ELECTRA鉴别器的最后一层相对于较早的层时性能显著下降。我们探索了这种下降，并设计了一种修复ELECTRA嵌入向量的方法，提出了一种新颖的截断模型微调（TMFT）方法。在STS基准数据集上，TMFT将Spearman相关系数提高了8个多点，同时提高了参数效率。我们将我们的分析扩展到各种模型大小和语言。此外，我们发现了ELECTRA生成模型的惊人功效，它的性能与BERT持平

    arXiv:2402.13130v1 Announce Type: new  Abstract: While BERT produces high-quality sentence embeddings, its pre-training computational cost is a significant drawback. In contrast, ELECTRA delivers a cost-effective pre-training objective and downstream task performance improvements, but not as performant sentence embeddings. The community tacitly stopped utilizing ELECTRA's sentence embeddings for semantic textual similarity (STS). We notice a significant drop in performance when using the ELECTRA discriminator's last layer in comparison to earlier layers. We explore this drop and devise a way to repair ELECTRA's embeddings, proposing a novel truncated model fine-tuning (TMFT) method. TMFT improves the Spearman correlation coefficient by over 8 points while increasing parameter efficiency on the STS benchmark dataset. We extend our analysis to various model sizes and languages. Further, we discover the surprising efficacy of ELECTRA's generator model, which performs on par with BERT, usi
    
[^7]: EmoBench: 评估大型语言模型的情感智能

    EmoBench: Evaluating the Emotional Intelligence of Large Language Models

    [https://arxiv.org/abs/2402.12071](https://arxiv.org/abs/2402.12071)

    EmoBench是一个基于心理学理论的基准测试，旨在评估大型语言模型的情感智能，包括情感理解和情感应用。

    

    近年来，大型语言模型（LLMs）的快速发展凸显了需要稳健、全面和具有挑战性的基准测试的重要性。然而，对它们的情感智能（EI）进行评估的研究相当有限。现有的基准测试存在两个主要缺点：首先，它们主要关注情感识别，忽视了情感调节等重要的情感智能能力，而情感理解则促进情感; 其次，它们主要基于现有数据集构建，这些数据集包含频繁模式、明确信息和注释错误，导致评估不可靠。我们提出了EmoBench，这是一个基准测试，借鉴了已建立的心理理论，并为机器EI提出了综合定义，包括情感理解和情感应用。EmoBench包括一组400个用英语和中文手工制作的问题，经过精心设计，需要深入推理。

    arXiv:2402.12071v1 Announce Type: cross  Abstract: Recent advances in Large Language Models (LLMs) have highlighted the need for robust, comprehensive, and challenging benchmarks. Yet, research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings: first, they mainly focus on emotion recognition, neglecting essential EI capabilities such as emotion regulation and thought facilitation through emotion understanding; second, they are primarily constructed from existing datasets, which include frequent patterns, explicit information, and annotation errors, leading to unreliable evaluation. We propose EmoBench, a benchmark that draws upon established psychological theories and proposes a comprehensive definition for machine EI, including Emotional Understanding and Emotional Application. EmoBench includes a set of 400 hand-crafted questions in English and Chinese, which are meticulously designed to require thorough reasoning
    
[^8]: BioMistral：面向医学领域的开源预训练大型语言模型集合

    BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains

    [https://arxiv.org/abs/2402.10373](https://arxiv.org/abs/2402.10373)

    BioMistral是一种面向生物医学领域的开源预训练大型语言模型集合，在医学问答任务中表现出优越性能并具有竞争优势。

    

    大型语言模型（LLMs）近年来展示出卓越的多功能性，为医疗保健和医学等专业领域提供潜在应用。尽管有各种针对健康领域定制的开源LLMs可用，但将通用LLMs调整到医学领域仍面临重大挑战。本文介绍了BioMistral，一种专为生物医学领域量身定制的开源LLM，采用Mistral作为基础模型，并在PubMed Central上进一步进行预训练。我们在包含10个已建立的英文医学问答（QA）任务的基准上对BioMistral进行了全面评估。我们还探讨通过量化和模型合并方法获得的轻量级模型。我们的结果表明，BioMistral相较于现有开源医学模型具有优越性能，并与专有对手具有竞争优势。最后，为了解决

    arXiv:2402.10373v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges. In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central. We conduct a comprehensive evaluation of BioMistral on a benchmark comprising 10 established medical question-answering (QA) tasks in English. We also explore lightweight models obtained through quantization and model merging approaches. Our results demonstrate BioMistral's superior performance compared to existing open-source medical models and its competitive edge against proprietary counterparts. Finally, to address
    
[^9]: Diffusion-ES:基于扩散的零梯度规划用于自动驾驶和零阶指令跟随

    Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following

    [https://arxiv.org/abs/2402.06559](https://arxiv.org/abs/2402.06559)

    本文提出了一种Diffusion-ES方法，它结合了无梯度优化和轨迹去噪技术，用于优化黑盒非可微目标。该方法通过从扩散模型中采样轨迹，并使用黑盒奖励函数对其进行评分，实现了更高的多样性和可解释性。

    

    扩散模型在决策和控制中对复杂和多模态轨迹分布建模有很强优势。最近提出了奖励梯度引导去噪方法，用于产生在扩散模型所捕获的数据分布下，同时最大化可微分奖励函数和似然性的轨迹。奖励梯度引导去噪需要一个适合于清洁和噪声样本的可微分奖励函数，从而限制了其作为一种通用轨迹优化器的适用性。在本文中，我们提出了DiffusionES，一种将无梯度优化和轨迹去噪相结合的方法，用于在数据流形中优化黑盒非可微目标。Diffusion-ES从扩散模型中采样轨迹，并使用黑盒奖励函数对其进行评分。它通过截断扩散过程对得分高的轨迹进行变异，该过程应用少量的噪声和去噪步骤，从而实现了更高的多样性和更好的可解释性。

    Diffusion models excel at modeling complex and multimodal trajectory distributions for decision-making and control. Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model. Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer. In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much mo
    
[^10]: 在自动语音识别中持续学习新词

    Continuously Learning New Words in Automatic Speech Recognition. (arXiv:2401.04482v1 [cs.CL])

    [http://arxiv.org/abs/2401.04482](http://arxiv.org/abs/2401.04482)

    该论文提出了一种自我监督的持续学习方法，用于解决自动语音识别中识别新词的问题。通过对讲座录音进行推理和收集包含新词的话语，然后在自适应数据集上进行持续学习，可以在新词出现频率较高时提高性能，同时保持整体性能。

    

    尽管最近取得了进展，但自动语音识别（ASR）系统仍然远未完美。典型的错误包括缩写词、命名实体和领域特定的专用词，这些词几乎没有或没有数据可用来训练。为了解决识别这些词的问题，我们提出了一种自我监督的持续学习方法。给定带有对应幻灯片的讲座录音，我们通过使用先前工作中的记忆增强型ASR模型来将模型偏向于从幻灯片中解码新词。然后，我们对讲座进行推理，将包含检测到的新词的话语收集到自适应数据集中。接着，对这个集合进行持续学习，通过调整添加到模型的每个权重矩阵的低秩矩阵权重。整个过程对多个讲座进行迭代。我们展示了通过这种方法，我们在新词出现频率较高时获得了性能的提升（超过80%的召回率），同时保持了模型的整体性能。

    Despite recent advances, Automatic Speech Recognition (ASR) systems are still far from perfect. Typical errors include acronyms, named entities and domain-specific special words for which little or no data is available. To address the problem of recognizing these words, we propose an self-supervised continual learning approach. Given the audio of a lecture talk with corresponding slides, we bias the model towards decoding new words from the slides by using a memory-enhanced ASR model from previous work. Then, we perform inference on the talk, collecting utterances that contain detected new words into an adaptation dataset. Continual learning is then performed on this set by adapting low-rank matrix weights added to each weight matrix of the model. The whole procedure is iterated for many talks. We show that with this approach, we obtain increasing performance on the new words when they occur more frequently (more than 80% recall) while preserving the general performance of the model.
    
[^11]: 查询和应答增强不能帮助领域外数学推理的泛化

    Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization. (arXiv:2310.05506v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05506](http://arxiv.org/abs/2310.05506)

    本文调查了在数学推理中使用数据增强的效果，并通过创建新的数据集和微调模型取得了显著成果。

    

    在使用大型语言模型（LLM）进行数学推理时，通过查询演化和多样化推理路径的数据增强在经验上被验证为有效，极大地缩小了开源LLMs和顶尖专有LLMs之间的差距。本文对数学推理中的数据增强进行了调查，并旨在回答：（1）哪些数据增强策略更有效；（2）增强数据量与模型性能之间的缩放关系如何；（3）数据增强能否激励领域外数学推理任务的泛化？为此，我们通过增加GSM8K查询的复杂性和多样性以及采样多个推理路径，创建了一个新的数据集AugGSM8K。我们通过在AugGSM8K的子集上进行微调获得了一系列LLMs，称为MuggleMath。MuggleMath在GSM8K上取得了显著的最新研究成果（在7B规模上从54%提高到68.4%，在扩放到63.9%到74.0%之间）。

    In math reasoning with large language models (LLMs), fine-tuning data augmentation by query evolution and diverse reasoning paths is empirically verified effective, profoundly narrowing the gap between open-sourced LLMs and cutting-edge proprietary LLMs. In this paper, we conduct an investigation for such data augmentation in math reasoning and are intended to answer: (1) What strategies of data augmentation are more effective; (2) What is the scaling relationship between the amount of augmented data and model performance; and (3) Can data augmentation incentivize generalization to out-of-domain mathematical reasoning tasks? To this end, we create a new dataset, AugGSM8K, by complicating and diversifying the queries from GSM8K and sampling multiple reasoning paths. We obtained a series of LLMs called MuggleMath by fine-tuning on subsets of AugGSM8K. MuggleMath substantially achieves new state-of-the-art on GSM8K (from 54% to 68.4% at the scale of 7B, and from 63.9% to 74.0% at the scal
    
[^12]: 自回归的下一个标记预测器是通用学习器。

    Auto-Regressive Next-Token Predictors are Universal Learners. (arXiv:2309.06979v1 [cs.LG])

    [http://arxiv.org/abs/2309.06979](http://arxiv.org/abs/2309.06979)

    自回归的下一个标记预测器可以有效地近似图灵机计算的任何函数，并且在文本生成和算术任务上展现出非平凡的性能。

    

    大型语言模型展现出在逻辑和数学推理方面的非凡能力，使其能够解决复杂任务。有趣的是，这些能力在训练于下一个标记预测的简单任务上的网络中出现。在这项工作中，我们提出了一个用于研究自回归下一个标记预测器的理论框架。我们证明了即使是简单的模型，如线性下一个标记预测器，当其在思维链数据上训练时，可以有效地近似图灵机计算的任何函数。我们引入了一个新的复杂度度量——长度复杂度，它衡量了在近似某个目标函数时，思维链序列中所需的中间标记的数量，并分析了长度复杂度和其他复杂性概念之间的相互关系。最后，我们通过实验证明简单的下一个标记预测器，如线性网络和浅层多层感知机（MLP），在文本生成和算术任务上展示出非平凡的性能。

    Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks. Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction. In this work, we present a theoretical framework for studying auto-regressive next-token predictors. We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine. We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity. Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks. Our resul
    
[^13]: 低延迟同时语音翻译的端到端评估

    End-to-End Evaluation for Low-Latency Simultaneous Speech Translation. (arXiv:2308.03415v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03415](http://arxiv.org/abs/2308.03415)

    本文提出了一个端到端的评估框架，用于评估低延迟语音翻译的各个方面。通过该框架，我们比较了不同方法的性能，并进行了全面的评估。

    

    近年来，低延迟语音翻译的挑战引起了研究界的广泛关注，许多出版物和共享任务也证明了这一点。因此，在实际场景中评估这些不同的方法非常重要。然而，目前只有系统的特定方面被评估，并且往往无法比较不同的方法。在这项工作中，我们提出了第一个在实际条件下执行和评估低延迟语音翻译各个方面的框架。评估是以端到端的方式进行的，包括音频的分段以及不同组成部分的运行时间。其次，我们使用该框架比较了不同的低延迟语音翻译方法。我们评估了具有修订输出选项的模型以及具有固定输出方法。此外，我们直接比较了最先进的级联系统和端到端系统。最后，该框架基于一个统一的度量来评估低延迟语音翻译性能，并提供了一个全面的评估结果。

    The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches.  In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components.  Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. Finally, the framework all
    
[^14]: 在大型语言模型中解锁组合性的上下文提示: 技能指导策略

    Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models. (arXiv:2308.00304v1 [cs.CL])

    [http://arxiv.org/abs/2308.00304](http://arxiv.org/abs/2308.00304)

    本文介绍了一种名为技能指导 (SKiC) 的提示策略，通过在上下文中演示基本技能和组合性示例，使大型语言模型具备解决更复杂问题的能力，并在泛化能力上取得几乎完美的表现。

    

    本文考虑了如何通过一种新颖的提示策略，在大型语言模型（LLMs）中激发组合性泛化能力的问题。组合性泛化使得LLMs能够解决比它们所见过的问题更困难的问题（即易于难的泛化），这是人类智能的关键推理能力。然而，即使是当前最先进的LLMs在这种形式的推理上仍然存在困难。为了弥合这一差距，我们提出了在上下文中的技能指导（SKiC）提示，它指导LLMs如何组合基本技能来解决更复杂的问题。我们发现，在相同的提示上展示技能和组合性示例是至关重要的。仅仅通过两个示例，我们的SKiC提示在技能和它们的组合能力之间形成了强大的协同效应。值得注意的是，它赋予了LLMs解决需要创新技能组合的未见问题的能力，实现了几乎完美的泛化。

    We consider the problem of eliciting compositional generalization capabilities in large language models (LLMs) with a novel type of prompting strategy. Compositional generalization empowers the LLMs to solve problems that are harder than the ones they have seen (i.e., easy-to-hard generalization), which is a critical reasoning capability of human-like intelligence. However, even the current state-of-the-art LLMs still struggle with this form of reasoning. To bridge this gap, we propose skills-in-context (SKiC) prompting, which instructs LLMs how to compose basic skills to resolve more complex problems. We find that it is crucial to demonstrate both the skills and the compositional examples within the same prompting context. With as few as two examplars, our SKiC prompting initiates strong synergies between skills and their composition capabilities. Notably, it empowers LLMs to solve unseen problems that require innovative skill compositions, achieving near-perfect generalization on a b
    
[^15]: GPT4Table：大型语言模型能理解结构化表格数据吗？一项基准测试和实证研究

    GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study. (arXiv:2305.13062v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13062](http://arxiv.org/abs/2305.13062)

    本文设计了一个基准测试来评估大型语言模型（LLMs）对结构化表格数据的理解能力，并发现不同的输入选择会对性能产生影响。在基准测试的基础上，提出了“自我增强”技术以改善理解能力。

    

    大型语言模型（LLMs）作为少样本推理器来解决与自然语言相关的任务越来越具吸引力。然而，关于LLMs对结构化数据（例如表格）的理解程度还有很多需要学习的地方。尽管可以使用表格序列化作为LLMs的输入，但目前还缺乏对LLMs是否真正能够理解这类数据的全面研究。本文通过设计一个基准测试来评估LLMs的结构理解能力（SUC）来解决这个问题。我们创建的基准测试包括七个任务，每个任务都有其独特的挑战，例如单元格查找、行检索和大小检测。我们对GPT-3.5和GPT-4进行了一系列评估。我们发现性能因多种输入选择而异，包括表格输入格式、内容顺序、角色提示和分区标记等。根据基准测试评估所得的见解，我们提出了“自我增强”技术以改善性能。

    Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, there is still much to learn about how well LLMs understand structured data, such as tables. While it is true that tables can be used as inputs to LLMs with serialization, there lack of comprehensive studies examining whether LLMs can truly comprehend such data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities (SUC) of LLMs. The benchmark we create includes seven tasks, each with its own unique challenges, \eg, cell lookup, row retrieval, and size detection. We run a series of evaluations on GPT-3.5 and GPT-4. We discover that the performance varied depending on a number of input choices, including table input format, content order, role prompting, and partition marks. Drawing from the insights gained through the benchmark evaluations, we then propose \textit{self-augmentation} for effect
    
[^16]: 探究和改进神经机器翻译中知识蒸馏

    Towards Understanding and Improving Knowledge Distillation for Neural Machine Translation. (arXiv:2305.08096v1 [cs.CL])

    [http://arxiv.org/abs/2305.08096](http://arxiv.org/abs/2305.08096)

    本文揭示了神经机器翻译中知识蒸馏的本质，即来自于教师模型的top-1预测。同时，指出了当前基于词级别的知识蒸馏存在的问题，并提出了一种新方法——Top-1 Information。

    

    知识蒸馏在神经机器翻译领域中是一种有前途的模型压缩技术。然而，知识在哪里隐藏的问题仍不清楚，这可能会阻碍知识蒸馏的发展。在本研究中，我们首先从实证角度揭开了这个谜团，并展示了知识来自教师的top-1预测，这也帮助我们建立了词级和序列级蒸馏之间的潜在连接。此外，我们基于这一发现指出了基础词级蒸馏中存在的两个问题。首先，知识的当前目标是将注意力扩散到整个分布上学习知识，但缺乏对最关键的top-1信息的特殊处理。其次，由于大多数教师的top-1预测与地面实况标记重叠，因此知识被黄金信息所占据，进一步限制了知识蒸馏的潜力。为解决这些问题，我们提出了一种名为\textbf{T}op-1 \textbf{I}nformation的新方法。

    Knowledge distillation (KD) is a promising technique for model compression in neural machine translation. However, where the knowledge hides in KD is still not clear, which may hinder the development of KD. In this work, we first unravel this mystery from an empirical perspective and show that the knowledge comes from the top-1 predictions of teachers, which also helps us build a potential connection between word- and sequence-level KD. Further, we point out two inherent issues in vanilla word-level KD based on this finding. Firstly, the current objective of KD spreads its focus to whole distributions to learn the knowledge, yet lacks special treatment on the most crucial top-1 information. Secondly, the knowledge is largely covered by the golden information due to the fact that most top-1 predictions of teachers overlap with ground-truth tokens, which further restricts the potential of KD. To address these issues, we propose a novel method named \textbf{T}op-1 \textbf{I}nformation \te
    

