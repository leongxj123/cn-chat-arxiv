# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Visually-Grounded Descriptions Improve Zero-Shot Image Classification.](http://arxiv.org/abs/2306.06077) | 本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。 |
| [^2] | [Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2303.15647) | 本文综述了40多种缩小模型规模进行超大模型参数微调的方法，旨在解决大型语言模型训练的不可行性和不切实际性。提供了分类法和方法比较，并重点关注实际效率和千亿级语言模型微调。 |

# 详细

[^1]: 视觉词汇描述提升零样本图像分类

    Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v1 [cs.CV])

    [http://arxiv.org/abs/2306.06077](http://arxiv.org/abs/2306.06077)

    本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。

    

    语言视觉模型如CLIP在零样本视觉任务（例如零样本图像分类ZSIC）方面取得了显著进展。然而，生成具体和富有表现力的类别描述仍然是一个主要挑战。现有方法存在粒度和标签歧义等问题。为了解决这些挑战，我们提出了一种新方法V-GLOSS：Visual Glosses，它利用现代语言模型和语义知识库来生成具有视觉基础的类别描述。我们通过在基准ZSIC数据集（包括ImageNet和STL-10）上实现最先进的结果来展示V-GLOSS的有效性。此外，我们引入了一个由V-GLOSS生成的带有类别描述的银标准数据集，并展示其用于视觉任务的有用性。我们提供了源代码和数据集。

    Language-vision models like CLIP have made significant progress in zero-shot vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive class descriptions remains a major challenge. Existing approaches suffer from granularity and label ambiguity issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel method leveraging modern language models and semantic knowledge bases to produce visually-grounded class descriptions. We demonstrate V-GLOSS's effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets including ImageNet and STL-10. In addition, we introduce a silver dataset with class descriptions generated by V-GLOSS, and show its usefulness for vision tasks. We make available our code and dataset.
    
[^2]: 缩小规模以实现超大语言模型的参数有效微调指南

    Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning. (arXiv:2303.15647v1 [cs.CL])

    [http://arxiv.org/abs/2303.15647](http://arxiv.org/abs/2303.15647)

    本文综述了40多种缩小模型规模进行超大模型参数微调的方法，旨在解决大型语言模型训练的不可行性和不切实际性。提供了分类法和方法比较，并重点关注实际效率和千亿级语言模型微调。

    

    本文提供了一份系统化的综述和比较，覆盖了2019年2月至2023年2月期间发布的40多篇参数有效微调方法的论文。这些方法旨在通过仅训练小部分参数来解决微调大型语言模型的不可行和不切实际性。我们提供了一个分类法，涵盖了广泛的方法，并对实现效率和微调千亿级语言模型进行了详细的方法比较。

    This paper presents a systematic overview and comparison of parameter-efficient fine-tuning methods covering over 40 papers published between February 2019 and February 2023. These methods aim to resolve the infeasibility and impracticality of fine-tuning large language models by only training a small set of parameters. We provide a taxonomy that covers a broad range of methods and present a detailed method comparison with a specific focus on real-life efficiency and fine-tuning multibillion-scale language models.
    

