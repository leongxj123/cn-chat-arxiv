# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation.](http://arxiv.org/abs/2307.11019) | 本研究初步分析了大型语言模型的事实知识边界，并研究了检索增强对开放域问答任务中大型语言模型的影响。结果显示大型语言模型在回答问题时表现出自信，并且回答准确。 |

# 详细

[^1]: 用检索增强研究大型语言模型的事实知识边界

    Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation. (arXiv:2307.11019v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.11019](http://arxiv.org/abs/2307.11019)

    本研究初步分析了大型语言模型的事实知识边界，并研究了检索增强对开放域问答任务中大型语言模型的影响。结果显示大型语言模型在回答问题时表现出自信，并且回答准确。

    

    知识密集型任务（例如，开放域问答（QA））需要大量的事实知识，并经常依赖外部信息进行协助。最近，大型语言模型（LLMs）（例如，ChatGPT）在解决包括知识密集型任务在内的各种任务上展现出了惊人的能力。然而，目前尚不清楚LLMs在感知其事实知识边界方面表现如何，特别是在使用检索增强时的行为。在本研究中，我们对LLMs的事实知识边界进行了初步分析，并研究了检索增强对LLMs在开放域QA上的影响。具体而言，我们关注了三个主要研究问题，并通过检查LLMs的QA性能、先验判断和后验判断来进行分析。我们提供了证据表明LLMs对于自己回答问题的能力和回答的准确性充满了自信。

    Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require a substantial amount of factual knowledge and often rely on external information for assistance. Recently, large language models (LLMs) (e.g., ChatGPT), have demonstrated impressive prowess in solving a wide range of tasks with world knowledge, including knowledge-intensive tasks. However, it remains unclear how well LLMs are able to perceive their factual knowledge boundaries, particularly how they behave when incorporating retrieval augmentation. In this study, we present an initial analysis of the factual knowledge boundaries of LLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially, we focus on three primary research questions and analyze them by examining QA performance, priori judgement and posteriori judgement of LLMs. We show evidence that LLMs possess unwavering confidence in their capabilities to respond to questions and the accuracy of their responses. Furthermore, retrieval 
    

