# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Cross-Modal Retrieval: A Systematic Review of Methods and Future Directions.](http://arxiv.org/abs/2308.14263) | 本文提供了一篇关于跨模态检索的方法和未来方向的系统综述，从浅层统计分析到视觉-语言预训练模型，深入探讨了现有跨模态检索方法的原理和架构。 |
| [^2] | [Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations.](http://arxiv.org/abs/2305.16326) | 本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。 |

# 详细

[^1]: 跨模态检索：方法和未来方向的系统综述

    Cross-Modal Retrieval: A Systematic Review of Methods and Future Directions. (arXiv:2308.14263v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2308.14263](http://arxiv.org/abs/2308.14263)

    本文提供了一篇关于跨模态检索的方法和未来方向的系统综述，从浅层统计分析到视觉-语言预训练模型，深入探讨了现有跨模态检索方法的原理和架构。

    

    随着多样化多模态数据的爆炸性增长，传统的单模态检索方法难以满足用户对不同模态数据访问的需求。为解决这个问题，跨模态检索应运而生，它能够实现跨模态交互，促进语义匹配，并利用不同模态数据之间的互补性和一致性。尽管以往的文献对跨模态检索领域进行了综述，但存在着关于及时性、分类体系和全面性等方面的缺陷。本文对跨模态检索的发展进行了全面的综述，涵盖了从浅层统计分析技术到视觉-语言预训练模型的演进。文章首先从机器学习范式、机制和模型的角度构建了一个全面的分类体系，然后深入探讨了现有跨模态检索方法的原理和架构。此外，文章还概述了当前广泛使用的评估数据集、性能评价指标和常见问题。

    With the exponential surge in diverse multi-modal data, traditional uni-modal retrieval methods struggle to meet the needs of users demanding access to data from various modalities. To address this, cross-modal retrieval has emerged, enabling interaction across modalities, facilitating semantic matching, and leveraging complementarity and consistency between different modal data. Although prior literature undertook a review of the cross-modal retrieval field, it exhibits numerous deficiencies pertaining to timeliness, taxonomy, and comprehensiveness. This paper conducts a comprehensive review of cross-modal retrieval's evolution, spanning from shallow statistical analysis techniques to vision-language pre-training models. Commencing with a comprehensive taxonomy grounded in machine learning paradigms, mechanisms, and models, the paper then delves deeply into the principles and architectures underpinning existing cross-modal retrieval methods. Furthermore, it offers an overview of widel
    
[^2]: 生物医学自然语言处理中的大型语言模型: 基准、基线和建议

    Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])

    [http://arxiv.org/abs/2305.16326](http://arxiv.org/abs/2305.16326)

    本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。

    

    生物医学文献呈指数级增长，手动筛选和提取知识变得困难。自动从生物医学文献中提取信息的生物医学自然语言处理（BioNLP）技术有助于减轻这种负担。近年来，如GPT-3和GPT-4等大型语言模型（LLMs）因其卓越的性能而受到重视。但是，它们在BioNLP任务中的有效性以及对方法开发和下游用户的影响仍未得到研究。本研究（1）在四个应用程序中在八个BioNLP数据集中建立了GPT-3和GPT-4在零-shot和一-shot设置下的基准表现，包括命名实体识别，关系提取，多标签文档分类和语义相似性和推理；（2）审查了LLMs产生的错误，并将错误分为三种类型：缺失，不一致和不需要的人工内容；（3）提出了使用LLMs的建议。

    Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
    

