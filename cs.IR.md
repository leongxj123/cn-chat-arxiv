# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multi-Tower Multi-Interest Recommendation with User Representation Repel](https://arxiv.org/abs/2403.05122) | 提出了一种具有用户表示排斥的新型多塔多兴趣框架，解决了多兴趣学习方法面临的训练和部署目标差异、无法访问商品信息以及难以工业采用等问题。 |
| [^2] | [LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts.](http://arxiv.org/abs/2310.20501) | 近期的研究发现，大型语言模型（LLMs）对信息检索系统产生了一种偏见，倾向于将LLM生成的文档排名较高。这种“来源偏见”可能对信息访问产生重大影响。 |

# 详细

[^1]: 具有用户表示排斥的多塔多兴趣推荐

    Multi-Tower Multi-Interest Recommendation with User Representation Repel

    [https://arxiv.org/abs/2403.05122](https://arxiv.org/abs/2403.05122)

    提出了一种具有用户表示排斥的新型多塔多兴趣框架，解决了多兴趣学习方法面临的训练和部署目标差异、无法访问商品信息以及难以工业采用等问题。

    

    在信息过载的时代，学术界和工业界都深刻认识到推荐系统的价值。特别是多兴趣序列推荐是近年来受到越来越多关注的一个子领域。通过生成多用户表示，多兴趣学习模型在理论上和经验上都比单用户表示模型具有更强的表达能力。尽管该领域取得了重大进展，但仍存在三个主要问题困扰着多兴趣学习方法的性能和可采用性，即训练和部署目标之间的差异、无法访问商品信息以及由于其单塔架构而难以工业采用。我们通过提出一种具有用户表示排斥的新型多塔多兴趣框架来解决这些挑战。通过跨多个大规模实验结果，我们证明了我们的方法的有效性。

    arXiv:2403.05122v1 Announce Type: cross  Abstract: In the era of information overload, the value of recommender systems has been profoundly recognized in academia and industry alike. Multi-interest sequential recommendation, in particular, is a subfield that has been receiving increasing attention in recent years. By generating multiple-user representations, multi-interest learning models demonstrate superior expressiveness than single-user representation models, both theoretically and empirically. Despite major advancements in the field, three major issues continue to plague the performance and adoptability of multi-interest learning methods, the difference between training and deployment objectives, the inability to access item information, and the difficulty of industrial adoption due to its single-tower architecture. We address these challenges by proposing a novel multi-tower multi-interest framework with user representation repel. Experimental results across multiple large-scale 
    
[^2]: LLM可能主导信息访问：神经检索器对LLM生成的文本存在偏见。

    LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts. (arXiv:2310.20501v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.20501](http://arxiv.org/abs/2310.20501)

    近期的研究发现，大型语言模型（LLMs）对信息检索系统产生了一种偏见，倾向于将LLM生成的文档排名较高。这种“来源偏见”可能对信息访问产生重大影响。

    

    最近，大型语言模型（LLMs）的出现在信息检索（IR）应用，尤其是在网络搜索方面，彻底改变了范式。由于其在生成类人文本方面的卓越能力，LLMs在互联网上创造了大量的文本。因此，LLMs时代的IR系统面临一个新的挑战：索引的文档不仅是由人类撰写的，而且还包括由LLMs自动生成的文档。这些LLM生成的文档如何影响IR系统是一个紧迫且尚未探索的问题。在这项工作中，我们在涉及人类编写和LLM生成的文本的不同IR模型的场景中进行了定量评估。令人惊讶的是，我们的研究结果表明，神经检索模型倾向于将LLM生成的文档排名较高。我们将这种神经检索模型对LLM生成文本的偏见称为“来源偏见”。此外，我们发现这种偏见不仅限于f方相当的情况，而且在分类任务上也存在。

    Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search. With their remarkable capabilities in generating human-like texts, LLMs have created enormous texts on the Internet. As a result, IR systems in the LLMs era are facing a new challenge: the indexed documents now are not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of different IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that neural retrieval models tend to rank LLM-generated documents higher. We refer to this category of biases in neural retrieval models towards the LLM-generated text as the \textbf{source bias}. Moreover, we discover that this bias is not confined to the f
    

