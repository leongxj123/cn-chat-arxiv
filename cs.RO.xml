<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#24212;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#20915;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#30340;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#24182;&#25552;&#20986;&#19968;&#31181;&#20351;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#30340;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2403.10795</link><description>&lt;p&gt;
&#20174;&#21333;&#35789;&#21040;&#36335;&#24452;&#65306;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20110;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
From Words to Routes: Applying Large Language Models to Vehicle Routing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10795
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#24212;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#20915;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#30340;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#24182;&#25552;&#20986;&#19968;&#31181;&#20351;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#22312;&#26426;&#22120;&#20154;&#39046;&#22495;&#65288;&#20363;&#22914;&#25805;&#20316;&#21644;&#23548;&#33322;&#65289;&#20013;&#23637;&#31034;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#36827;&#23637;&#65292;&#20854;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#12290;LLMs&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#21462;&#24471;&#25104;&#21151;&#35753;&#25105;&#20204;&#24605;&#32771;&#65306;LLMs&#22312;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#35299;&#20915;&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#38382;&#39064;&#65288;VRPs&#65289;&#30340;&#33021;&#21147;&#22914;&#20309;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#19977;&#27493;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;21&#31181;&#21333;&#36710;&#25110;&#22810;&#36710;&#36335;&#24452;&#38382;&#39064;&#30340;&#25968;&#25454;&#38598;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;LLMs&#22312;&#22235;&#31181;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#25991;&#26412;&#21040;&#20195;&#30721;&#29983;&#25104;&#30340;&#24615;&#33021;&#65292;&#27599;&#31181;&#21253;&#25324;&#19981;&#21516;&#31867;&#22411;&#30340;&#25991;&#26412;&#36755;&#20837;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30452;&#25509;&#20174;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#29983;&#25104;&#20195;&#30721;&#30340;&#22522;&#26412;&#25552;&#31034;&#33539;&#20363;&#23545;&#20110;GPT-4&#25928;&#26524;&#26368;&#20339;&#65292;&#23454;&#29616;&#20102;56%&#30340;&#21487;&#34892;&#24615;&#65292;40%&#30340;&#20248;&#21270;&#24615;&#21644;53%&#30340;&#25928;&#29575;&#12290;&#31532;&#19977;&#65292;&#22522;&#20110;&#35266;&#23519;&#21040;LLMs&#21487;&#33021;&#26080;&#27861;&#22312;&#21021;&#22987;&#23581;&#35797;&#20013;&#25552;&#20379;&#27491;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20351;LLMs&#33021;&#22815;&#36827;&#34892;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10795v1 Announce Type: cross  Abstract: LLMs have shown impressive progress in robotics (e.g., manipulation and navigation) with natural language task descriptions. The success of LLMs in these tasks leads us to wonder: What is the ability of LLMs to solve vehicle routing problems (VRPs) with natural language task descriptions? In this work, we study this question in three steps. First, we construct a dataset with 21 types of single- or multi-vehicle routing problems. Second, we evaluate the performance of LLMs across four basic prompt paradigms of text-to-code generation, each involving different types of text input. We find that the basic prompt paradigm, which generates code directly from natural language task descriptions, performs the best for GPT-4, achieving 56% feasibility, 40% optimality, and 53% efficiency. Third, based on the observation that LLMs may not be able to provide correct solutions at the initial attempt, we propose a framework that enables LLMs to refin
&lt;/p&gt;</description></item></channel></rss>