<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#25552;&#20986;&#20102;&#35774;&#23450;&#26426;&#22120;&#20154;&#30446;&#30340;&#30340;&#27010;&#24565;&#65292;&#20197;&#24110;&#21161;&#26426;&#22120;&#20154;&#26356;&#21152;&#20851;&#27880;&#33719;&#21462;&#19982;&#30446;&#30340;&#30456;&#20851;&#30340;&#30693;&#35782;&#12290;</title><link>https://arxiv.org/abs/2403.02514</link><description>&lt;p&gt;
&#20026;&#24320;&#25918;&#24335;&#23398;&#20064;&#26426;&#22120;&#20154;&#35774;&#23450;&#30446;&#30340;&#65306;&#19968;&#20010;&#35745;&#31639;&#20998;&#31867;&#12289;&#23450;&#20041;&#21644;&#25805;&#20316;&#21270;
&lt;/p&gt;
&lt;p&gt;
Purpose for Open-Ended Learning Robots: A Computational Taxonomy, Definition, and Operationalisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02514
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#35774;&#23450;&#26426;&#22120;&#20154;&#30446;&#30340;&#30340;&#27010;&#24565;&#65292;&#20197;&#24110;&#21161;&#26426;&#22120;&#20154;&#26356;&#21152;&#20851;&#27880;&#33719;&#21462;&#19982;&#30446;&#30340;&#30456;&#20851;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02514v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#33258;&#20027;&#24320;&#25918;&#24335;&#23398;&#20064;(OEL)&#26426;&#22120;&#20154;&#33021;&#22815;&#36890;&#36807;&#19982;&#29615;&#22659;&#30340;&#30452;&#25509;&#20132;&#20114;&#32047;&#31215;&#33719;&#21462;&#26032;&#25216;&#33021;&#21644;&#30693;&#35782;&#65292;&#20363;&#22914;&#20381;&#38752;&#20869;&#22312;&#21160;&#26426;&#21644;&#33258;&#21160;&#29983;&#25104;&#30340;&#30446;&#26631;&#30340;&#25351;&#23548;&#12290;OEL&#26426;&#22120;&#20154;&#23545;&#24212;&#29992;&#20855;&#26377;&#24456;&#39640;&#30340;&#30456;&#20851;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#20351;&#29992;&#33258;&#20027;&#33719;&#21462;&#30340;&#30693;&#35782;&#26469;&#23436;&#25104;&#23545;&#20154;&#31867;&#29992;&#25143;&#26377;&#20851;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;OEL&#26426;&#22120;&#20154;&#38754;&#20020;&#19968;&#20010;&#37325;&#35201;&#38480;&#21046;&#65306;&#36825;&#21487;&#33021;&#23548;&#33268;&#33719;&#21462;&#30340;&#30693;&#35782;&#23545;&#23436;&#25104;&#29992;&#25143;&#20219;&#21153;&#24182;&#19981;&#37027;&#20040;&#37325;&#35201;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#21487;&#33021;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#22260;&#32469;&#8220;&#30446;&#30340;&#8221;&#36825;&#19968;&#26032;&#27010;&#24565;&#23637;&#24320;&#12290;&#30446;&#30340;&#34920;&#31034;&#35774;&#35745;&#32773;&#21644;/&#25110;&#29992;&#25143;&#24076;&#26395;&#26426;&#22120;&#20154;&#20174;&#20013;&#33719;&#24471;&#20160;&#20040;&#12290;&#26426;&#22120;&#20154;&#24212;&#20351;&#29992;&#30446;&#30340;&#30340;&#20869;&#37096;&#34920;&#24449;&#65292;&#36825;&#37324;&#31216;&#20026;&#8220;&#24895;&#26395;&#8221;&#65292;&#26469;&#23558;&#20854;&#24320;&#25918;&#24335;&#25506;&#32034;&#38598;&#20013;&#20110;&#33719;&#21462;&#19982;&#20854;&#23436;&#25104;&#30446;&#30340;&#30456;&#20851;&#30340;&#30693;&#35782;&#12290;&#36825;&#39033;&#24037;&#20316;&#26377;&#21161;&#20110;&#21457;&#23637;&#19968;&#20010;&#20849;&#21516;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02514v1 Announce Type: cross  Abstract: Autonomous open-ended learning (OEL) robots are able to cumulatively acquire new skills and knowledge through direct interaction with the environment, for example relying on the guidance of intrinsic motivations and self-generated goals. OEL robots have a high relevance for applications as they can use the autonomously acquired knowledge to accomplish tasks relevant for their human users. OEL robots, however, encounter an important limitation: this may lead to the acquisition of knowledge that is not so much relevant to accomplish the users' tasks. This work analyses a possible solution to this problem that pivots on the novel concept of `purpose'. Purposes indicate what the designers and/or users want from the robot. The robot should use internal representations of purposes, called here `desires', to focus its open-ended exploration towards the acquisition of knowledge relevant to accomplish them. This work contributes to develop a co
&lt;/p&gt;</description></item><item><title>SoftMAC&#25552;&#20986;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#20197;&#24448;&#30340;&#21487;&#24494;&#20223;&#30495;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#36719;&#20307;&#12289;&#20851;&#33410;&#21018;&#20307;&#21644;&#34915;&#29289;&#32806;&#21512;&#22312;&#19968;&#36215;&#65292;&#24182;&#37319;&#29992;&#22522;&#20110;&#39044;&#27979;&#30340;&#25509;&#35302;&#27169;&#22411;&#21644;&#31359;&#36879;&#36861;&#36394;&#31639;&#27861;&#65292;&#26377;&#25928;&#22320;&#20943;&#23569;&#20102;&#31359;&#36879;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2312.03297</link><description>&lt;p&gt;
SoftMAC&#65306;&#22522;&#20110;&#39044;&#27979;&#25509;&#35302;&#27169;&#22411;&#21644;&#19982;&#20851;&#33410;&#21018;&#20307;&#21644;&#34915;&#29289;&#21452;&#21521;&#32806;&#21512;&#30340;&#21487;&#24494;&#36719;&#20307;&#20223;&#30495;
&lt;/p&gt;
&lt;p&gt;
SoftMAC: Differentiable Soft Body Simulation with Forecast-based Contact Model and Two-way Coupling with Articulated Rigid Bodies and Clothes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03297
&lt;/p&gt;
&lt;p&gt;
SoftMAC&#25552;&#20986;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#20197;&#24448;&#30340;&#21487;&#24494;&#20223;&#30495;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#36719;&#20307;&#12289;&#20851;&#33410;&#21018;&#20307;&#21644;&#34915;&#29289;&#32806;&#21512;&#22312;&#19968;&#36215;&#65292;&#24182;&#37319;&#29992;&#22522;&#20110;&#39044;&#27979;&#30340;&#25509;&#35302;&#27169;&#22411;&#21644;&#31359;&#36879;&#36861;&#36394;&#31639;&#27861;&#65292;&#26377;&#25928;&#22320;&#20943;&#23569;&#20102;&#31359;&#36879;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#24494;&#29289;&#29702;&#20223;&#30495;&#36890;&#36807;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35299;&#20915;&#26426;&#22120;&#20154;&#30456;&#20851;&#38382;&#39064;&#30340;&#25928;&#29575;&#12290;&#20026;&#22312;&#21508;&#31181;&#26426;&#22120;&#20154;&#25805;&#32437;&#22330;&#26223;&#20013;&#24212;&#29992;&#21487;&#24494;&#20223;&#30495;&#65292;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#23558;&#21508;&#31181;&#26448;&#26009;&#38598;&#25104;&#21040;&#32479;&#19968;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SoftMAC&#65292;&#19968;&#20010;&#21487;&#24494;&#20223;&#30495;&#26694;&#26550;&#65292;&#23558;&#36719;&#20307;&#19982;&#20851;&#33410;&#21018;&#20307;&#21644;&#34915;&#29289;&#32806;&#21512;&#22312;&#19968;&#36215;&#12290;SoftMAC&#20351;&#29992;&#22522;&#20110;&#36830;&#32493;&#21147;&#23398;&#30340;&#26448;&#26009;&#28857;&#27861;&#26469;&#27169;&#25311;&#36719;&#20307;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#39044;&#27979;&#30340;MPM&#25509;&#35302;&#27169;&#22411;&#65292;&#26377;&#25928;&#20943;&#23569;&#20102;&#31359;&#36879;&#65292;&#32780;&#19981;&#20250;&#24341;&#20837;&#20854;&#20182;&#24322;&#24120;&#29616;&#35937;&#65292;&#22914;&#19981;&#33258;&#28982;&#30340;&#21453;&#24377;&#12290;&#20026;&#20102;&#23558;MPM&#31890;&#23376;&#19982;&#21487;&#21464;&#24418;&#21644;&#38750;&#20307;&#31215;&#34915;&#29289;&#32593;&#26684;&#32806;&#21512;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31359;&#36879;&#36861;&#36394;&#31639;&#27861;&#65292;&#37325;&#24314;&#23616;&#37096;&#21306;&#22495;&#30340;&#26377;&#31526;&#21495;&#36317;&#31163;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03297v2 Announce Type: replace-cross  Abstract: Differentiable physics simulation provides an avenue to tackle previously intractable challenges through gradient-based optimization, thereby greatly improving the efficiency of solving robotics-related problems. To apply differentiable simulation in diverse robotic manipulation scenarios, a key challenge is to integrate various materials in a unified framework. We present SoftMAC, a differentiable simulation framework that couples soft bodies with articulated rigid bodies and clothes. SoftMAC simulates soft bodies with the continuum-mechanics-based Material Point Method (MPM). We provide a novel forecast-based contact model for MPM, which effectively reduces penetration without introducing other artifacts like unnatural rebound. To couple MPM particles with deformable and non-volumetric clothes meshes, we also propose a penetration tracing algorithm that reconstructs the signed distance field in local area. Diverging from prev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#22312;&#32447;POMDP&#35268;&#21010;&#20013;&#19968;&#20010;&#31616;&#21270;&#35299;&#20915;&#26041;&#26696;&#19982;&#29702;&#35770;&#19978;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#30830;&#23450;&#24615;&#20851;&#31995;&#65292;&#20197;&#35299;&#20915;&#30446;&#21069;&#36817;&#20284;&#31639;&#27861;&#21482;&#33021;&#25552;&#20379;&#27010;&#29575;&#24615;&#21644;&#36890;&#24120;&#21576;&#29616;&#28176;&#36827;&#24615;&#20445;&#35777;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.01791</link><description>&lt;p&gt;
&#20855;&#26377;&#20219;&#24847;&#30830;&#23450;&#24615;&#20445;&#35777;&#30340;&#22312;&#32447;POMDP&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Online POMDP Planning with Anytime Deterministic Guarantees. (arXiv:2310.01791v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#22312;&#32447;POMDP&#35268;&#21010;&#20013;&#19968;&#20010;&#31616;&#21270;&#35299;&#20915;&#26041;&#26696;&#19982;&#29702;&#35770;&#19978;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#30830;&#23450;&#24615;&#20851;&#31995;&#65292;&#20197;&#35299;&#20915;&#30446;&#21069;&#36817;&#20284;&#31639;&#27861;&#21482;&#33021;&#25552;&#20379;&#27010;&#29575;&#24615;&#21644;&#36890;&#24120;&#21576;&#29616;&#28176;&#36827;&#24615;&#20445;&#35777;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#33258;&#20027;&#26234;&#33021;&#20307;&#32463;&#24120;&#36935;&#21040;&#19981;&#30830;&#23450;&#24615;&#24182;&#22522;&#20110;&#19981;&#23436;&#25972;&#20449;&#24687;&#20570;&#20986;&#20915;&#31574;&#12290;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#35268;&#21010;&#21487;&#20197;&#20351;&#29992;&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#36827;&#34892;&#25968;&#23398;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#23547;&#25214;POMDP&#30340;&#26368;&#20248;&#35268;&#21010;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#65292;&#21482;&#26377;&#22312;&#23567;&#35268;&#27169;&#20219;&#21153;&#20013;&#21487;&#34892;&#12290;&#36817;&#24180;&#26469;&#65292;&#36817;&#20284;&#31639;&#27861;&#65288;&#22914;&#26641;&#25628;&#32034;&#21644;&#22522;&#20110;&#37319;&#26679;&#30340;&#26041;&#27861;&#65289;&#24050;&#32463;&#25104;&#20026;&#35299;&#20915;&#36739;&#22823;&#38382;&#39064;&#30340;&#20808;&#36827;POMDP&#27714;&#35299;&#22120;&#12290;&#23613;&#31649;&#36825;&#20123;&#31639;&#27861;&#26377;&#25928;&#65292;&#20294;&#23427;&#20204;&#20165;&#25552;&#20379;&#27010;&#29575;&#24615;&#21644;&#36890;&#24120;&#21576;&#29616;&#28176;&#36827;&#24615;&#20445;&#35777;&#65292;&#36825;&#26159;&#30001;&#20110;&#23427;&#20204;&#20381;&#36182;&#20110;&#37319;&#26679;&#30340;&#32536;&#25925;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#31616;&#21270;&#35299;&#20915;&#26041;&#26696;&#19982;&#29702;&#35770;&#19978;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#30830;&#23450;&#24615;&#20851;&#31995;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#36873;&#25321;&#19968;&#32452;&#35266;&#27979;&#20197;&#22312;&#35745;&#31639;&#27599;&#20010;&#21518;&#39564;&#33410;&#28857;&#26102;&#20998;&#25903;&#30340;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autonomous agents operating in real-world scenarios frequently encounter uncertainty and make decisions based on incomplete information. Planning under uncertainty can be mathematically formalized using partially observable Markov decision processes (POMDPs). However, finding an optimal plan for POMDPs can be computationally expensive and is feasible only for small tasks. In recent years, approximate algorithms, such as tree search and sample-based methodologies, have emerged as state-of-the-art POMDP solvers for larger problems. Despite their effectiveness, these algorithms offer only probabilistic and often asymptotic guarantees toward the optimal solution due to their dependence on sampling. To address these limitations, we derive a deterministic relationship between a simplified solution that is easier to obtain and the theoretically optimal one. First, we derive bounds for selecting a subset of the observations to branch from while computing a complete belief at each posterior nod
&lt;/p&gt;</description></item></channel></rss>