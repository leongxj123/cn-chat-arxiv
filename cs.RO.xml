<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#22238;&#39038;&#20102;40&#22810;&#31687;&#30740;&#31350;&#35770;&#25991;&#65292;&#24635;&#32467;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#33258;&#21160;&#39550;&#39542;&#22312;&#35268;&#21010;&#12289;&#20223;&#30495;&#21644;&#20851;&#38190;&#20219;&#21153;&#26041;&#38754;&#30340;&#37325;&#35201;&#36129;&#29486;&#65292;&#24378;&#35843;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#32763;&#35793;&#33021;&#21147;&#65292;&#35270;&#35273;&#22522;&#30784;&#27169;&#22411;&#22312;&#29289;&#20307;&#26816;&#27979;&#21644;&#39550;&#39542;&#22330;&#26223;&#21019;&#24314;&#26041;&#38754;&#30340;&#24212;&#29992;&#65292;&#20197;&#21450;&#22810;&#27169;&#24577;&#22522;&#30784;&#27169;&#22411;&#30340;&#35270;&#35273;&#29702;&#35299;&#21644;&#31354;&#38388;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01105</link><description>&lt;p&gt;
&#33258;&#21160;&#39550;&#39542;&#39046;&#22495;&#22522;&#30784;&#27169;&#22411;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey for Foundation Models in Autonomous Driving
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#22238;&#39038;&#20102;40&#22810;&#31687;&#30740;&#31350;&#35770;&#25991;&#65292;&#24635;&#32467;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#33258;&#21160;&#39550;&#39542;&#22312;&#35268;&#21010;&#12289;&#20223;&#30495;&#21644;&#20851;&#38190;&#20219;&#21153;&#26041;&#38754;&#30340;&#37325;&#35201;&#36129;&#29486;&#65292;&#24378;&#35843;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#32763;&#35793;&#33021;&#21147;&#65292;&#35270;&#35273;&#22522;&#30784;&#27169;&#22411;&#22312;&#29289;&#20307;&#26816;&#27979;&#21644;&#39550;&#39542;&#22330;&#26223;&#21019;&#24314;&#26041;&#38754;&#30340;&#24212;&#29992;&#65292;&#20197;&#21450;&#22810;&#27169;&#24577;&#22522;&#30784;&#27169;&#22411;&#30340;&#35270;&#35273;&#29702;&#35299;&#21644;&#31354;&#38388;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#21457;&#29983;&#20102;&#38761;&#21629;&#65292;&#20026;&#33258;&#21160;&#39550;&#39542;&#24212;&#29992;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;40&#22810;&#31687;&#30740;&#31350;&#35770;&#25991;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#22238;&#39038;&#65292;&#23637;&#31034;&#20102;&#22522;&#30784;&#27169;&#22411;&#22312;&#25552;&#21319;&#33258;&#21160;&#39550;&#39542;&#20013;&#30340;&#20316;&#29992;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#33258;&#21160;&#39550;&#39542;&#30340;&#35268;&#21010;&#21644;&#20223;&#30495;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#20854;&#22312;&#25512;&#29702;&#12289;&#20195;&#30721;&#29983;&#25104;&#21644;&#32763;&#35793;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#35270;&#35273;&#22522;&#30784;&#27169;&#22411;&#22312;&#20851;&#38190;&#20219;&#21153;&#20013;&#24471;&#21040;&#36234;&#26469;&#36234;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#19977;&#32500;&#29289;&#20307;&#26816;&#27979;&#21644;&#36319;&#36394;&#65292;&#20197;&#21450;&#20026;&#20223;&#30495;&#21644;&#27979;&#35797;&#21019;&#24314;&#36924;&#30495;&#30340;&#39550;&#39542;&#22330;&#26223;&#12290;&#22810;&#27169;&#24577;&#22522;&#30784;&#27169;&#22411;&#21487;&#20197;&#25972;&#21512;&#22810;&#26679;&#30340;&#36755;&#20837;&#65292;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#35270;&#35273;&#29702;&#35299;&#21644;&#31354;&#38388;&#25512;&#29702;&#33021;&#21147;&#65292;&#23545;&#20110;&#31471;&#21040;&#31471;&#33258;&#21160;&#39550;&#39542;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#32508;&#36848;&#19981;&#20165;&#25552;&#20379;&#20102;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#20998;&#31867;&#65292;&#26681;&#25454;&#27169;&#24577;&#21644;&#33258;&#21160;&#39550;&#39542;&#39046;&#22495;&#20013;&#30340;&#21151;&#33021;&#23545;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#65292;&#36824;&#28145;&#20837;&#30740;&#31350;&#20102;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of foundation models has revolutionized the fields of natural language processing and computer vision, paving the way for their application in autonomous driving (AD). This survey presents a comprehensive review of more than 40 research papers, demonstrating the role of foundation models in enhancing AD. Large language models contribute to planning and simulation in AD, particularly through their proficiency in reasoning, code generation and translation. In parallel, vision foundation models are increasingly adapted for critical tasks such as 3D object detection and tracking, as well as creating realistic driving scenarios for simulation and testing. Multi-modal foundation models, integrating diverse inputs, exhibit exceptional visual understanding and spatial reasoning, crucial for end-to-end AD. This survey not only provides a structured taxonomy, categorizing foundation models based on their modalities and functionalities within the AD domain but also delves into the meth
&lt;/p&gt;</description></item><item><title>PhysORD&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#23450;&#24459;&#34701;&#20837;&#31070;&#32463;&#27169;&#22411;&#20013;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#22312;&#36234;&#37326;&#39550;&#39542;&#20013;&#30340;&#36816;&#21160;&#39044;&#27979;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.01596</link><description>&lt;p&gt;
PhysORD&#65306;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#29992;&#20110;&#36234;&#37326;&#39550;&#39542;&#20013;&#27880;&#20837;&#29289;&#29702;&#23398;&#30340;&#36816;&#21160;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01596
&lt;/p&gt;
&lt;p&gt;
PhysORD&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#23450;&#24459;&#34701;&#20837;&#31070;&#32463;&#27169;&#22411;&#20013;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#22312;&#36234;&#37326;&#39550;&#39542;&#20013;&#30340;&#36816;&#21160;&#39044;&#27979;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36816;&#21160;&#39044;&#27979;&#23545;&#20110;&#33258;&#20027;&#36234;&#37326;&#39550;&#39542;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#19982;&#22312;&#36947;&#36335;&#19978;&#39550;&#39542;&#30456;&#27604;&#65292;&#23427;&#38754;&#20020;&#30528;&#26356;&#22810;&#25361;&#25112;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#36710;&#36742;&#19982;&#22320;&#24418;&#20043;&#38388;&#22797;&#26434;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;&#29289;&#29702;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24314;&#27169;&#21160;&#24577;&#31995;&#32479;&#21644;&#22806;&#37096;&#24178;&#25200;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#12290;&#30456;&#21453;&#65292;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#22823;&#37327;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#38590;&#20197;&#26126;&#30830;&#25429;&#25417;&#22522;&#26412;&#30340;&#29289;&#29702;&#23450;&#24459;&#65292;&#36825;&#24456;&#23481;&#26131;&#23548;&#33268;&#27867;&#21270;&#33021;&#21147;&#24046;&#12290;&#36890;&#36807;&#34701;&#21512;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#12290;&#36825;&#20123;&#26041;&#27861;&#23558;&#29289;&#29702;&#23450;&#24459;&#23884;&#20837;&#31070;&#32463;&#27169;&#22411;&#20013;&#65292;&#21487;&#33021;&#26174;&#33879;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#30740;&#31350;&#37117;&#27809;&#26377;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#36234;&#37326;&#39550;&#39542;&#29615;&#22659;&#20013;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986; PhysORD&#65292;&#36825;&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#65292;&#38598;&#25104;&#20102;&#23432;&#24658;&#23450;&#24459;&#65292;&#21363;&#27431;&#25289;-&#25289;&#26684;&#26391;&#26085;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01596v1 Announce Type: cross  Abstract: Motion prediction is critical for autonomous off-road driving, however, it presents significantly more challenges than on-road driving because of the complex interaction between the vehicle and the terrain. Traditional physics-based approaches encounter difficulties in accurately modeling dynamic systems and external disturbance. In contrast, data-driven neural networks require extensive datasets and struggle with explicitly capturing the fundamental physical laws, which can easily lead to poor generalization. By merging the advantages of both methods, neuro-symbolic approaches present a promising direction. These methods embed physical laws into neural models, potentially significantly improving generalization capabilities. However, no prior works were evaluated in real-world settings for off-road driving. To bridge this gap, we present PhysORD, a neural-symbolic approach integrating the conservation law, i.e., the Euler-Lagrange equa
&lt;/p&gt;</description></item><item><title>&#35813;&#39033;&#30446;&#23558;&#38750;&#32447;&#24615;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#20195;&#29702;&#24341;&#20837;&#26080;&#20154;&#26426;&#25511;&#21046;&#20013;&#65292;&#21462;&#20195;&#20256;&#32479;&#32447;&#24615;PID&#25511;&#21046;&#22120;&#65292;&#23454;&#29616;&#20102;&#26080;&#32541;&#36807;&#28193;&#12289;&#25552;&#39640;&#21709;&#24212;&#36895;&#24230;&#21644;&#31283;&#23450;&#24615;&#65292;&#21516;&#26102;&#32467;&#21512;PPO&#31574;&#30053;&#35757;&#32451;DRL&#20195;&#29702;&#65292;&#24182;&#21033;&#29992;&#39640;&#31934;&#24230;&#36319;&#36394;&#31995;&#32479;&#25552;&#39640;&#33258;&#20027;&#39134;&#34892;&#31934;&#24230;&#12290;</title><link>https://arxiv.org/abs/2404.00204</link><description>&lt;p&gt;
&#22522;&#20110;PPO&#30340;DRL&#33258;&#35843;PID&#38750;&#32447;&#24615;&#26080;&#20154;&#26426;&#25511;&#21046;&#22120;&#29992;&#20110;&#31283;&#20581;&#33258;&#20027;&#39134;&#34892;
&lt;/p&gt;
&lt;p&gt;
A PPO-based DRL Auto-Tuning Nonlinear PID Drone Controller for Robust Autonomous Flights
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00204
&lt;/p&gt;
&lt;p&gt;
&#35813;&#39033;&#30446;&#23558;&#38750;&#32447;&#24615;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#20195;&#29702;&#24341;&#20837;&#26080;&#20154;&#26426;&#25511;&#21046;&#20013;&#65292;&#21462;&#20195;&#20256;&#32479;&#32447;&#24615;PID&#25511;&#21046;&#22120;&#65292;&#23454;&#29616;&#20102;&#26080;&#32541;&#36807;&#28193;&#12289;&#25552;&#39640;&#21709;&#24212;&#36895;&#24230;&#21644;&#31283;&#23450;&#24615;&#65292;&#21516;&#26102;&#32467;&#21512;PPO&#31574;&#30053;&#35757;&#32451;DRL&#20195;&#29702;&#65292;&#24182;&#21033;&#29992;&#39640;&#31934;&#24230;&#36319;&#36394;&#31995;&#32479;&#25552;&#39640;&#33258;&#20027;&#39134;&#34892;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#39033;&#30446;&#26088;&#22312;&#36890;&#36807;&#23558;&#38750;&#32447;&#24615;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#20195;&#29702;&#20316;&#20026;&#20256;&#32479;&#32447;&#24615;&#27604;&#20363;&#31215;&#20998;&#24494;&#20998;&#65288;PID&#65289;&#25511;&#21046;&#22120;&#30340;&#26367;&#20195;&#21697;&#65292;&#20174;&#32780;&#24443;&#24213;&#25913;&#21464;&#26080;&#20154;&#26426;&#39134;&#34892;&#25511;&#21046;&#12290;&#20027;&#35201;&#30446;&#26631;&#26159;&#22312;&#25163;&#21160;&#21644;&#33258;&#20027;&#27169;&#24335;&#20043;&#38388;&#23454;&#29616;&#26080;&#32541;&#36807;&#28193;&#65292;&#25552;&#39640;&#21709;&#24212;&#36895;&#24230;&#21644;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#22312;Gazebo&#27169;&#25311;&#22120;&#20013;&#21033;&#29992;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;PPO&#65289;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#26469;&#35757;&#32451;DRL&#20195;&#29702;&#12290;&#28155;&#21152;20000&#32654;&#20803;&#30340;&#23460;&#20869;Vicon&#36319;&#36394;&#31995;&#32479;&#25552;&#20379;&lt;1mm&#30340;&#23450;&#20301;&#31934;&#24230;&#65292;&#26174;&#30528;&#25552;&#39640;&#20102;&#33258;&#20027;&#39134;&#34892;&#31934;&#24230;&#12290;&#20026;&#20102;&#22312;&#26368;&#30701;&#30340;&#26080;&#30896;&#25758;&#36712;&#36857;&#20013;&#23548;&#33322;&#26080;&#20154;&#26426;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#19977;&#32500;A*&#36335;&#24452;&#35268;&#21010;&#22120;&#24182;&#25104;&#21151;&#22320;&#23558;&#20854;&#23454;&#26045;&#21040;&#23454;&#38469;&#39134;&#34892;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00204v1 Announce Type: cross  Abstract: This project aims to revolutionize drone flight control by implementing a nonlinear Deep Reinforcement Learning (DRL) agent as a replacement for traditional linear Proportional Integral Derivative (PID) controllers. The primary objective is to seamlessly transition drones between manual and autonomous modes, enhancing responsiveness and stability. We utilize the Proximal Policy Optimization (PPO) reinforcement learning strategy within the Gazebo simulator to train the DRL agent. Adding a $20,000 indoor Vicon tracking system offers &lt;1mm positioning accuracy, which significantly improves autonomous flight precision. To navigate the drone in the shortest collision-free trajectory, we also build a 3 dimensional A* path planner and implement it into the real flight successfully.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;SIM-FSVGD&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#20445;&#30495;&#24230;&#30340;&#29289;&#29702;&#20808;&#39564;&#65292;&#25104;&#21151;&#32553;&#23567;&#27169;&#25311;&#21040;&#29616;&#23454;&#30340;&#24046;&#36317;&#65292;&#33021;&#22815;&#22312;&#20302;&#25968;&#25454;&#37327;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20934;&#30830;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#22312;&#39640;&#24615;&#33021;&#36187;&#36710;&#31995;&#32479;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.16644</link><description>&lt;p&gt;
&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#32553;&#23567;&#27169;&#25311;&#21040;&#29616;&#23454;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Bridging the Sim-to-Real Gap with Bayesian Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16644
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;SIM-FSVGD&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#20445;&#30495;&#24230;&#30340;&#29289;&#29702;&#20808;&#39564;&#65292;&#25104;&#21151;&#32553;&#23567;&#27169;&#25311;&#21040;&#29616;&#23454;&#30340;&#24046;&#36317;&#65292;&#33021;&#22815;&#22312;&#20302;&#25968;&#25454;&#37327;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20934;&#30830;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#22312;&#39640;&#24615;&#33021;&#36187;&#36710;&#31995;&#32479;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SIM-FSVGD&#26469;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#26426;&#22120;&#20154;&#21160;&#21147;&#23398;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;SIM-FSVGD&#21033;&#29992;&#20302;&#20445;&#30495;&#24230;&#30340;&#29289;&#29702;&#20808;&#39564;&#65292;&#22914;&#27169;&#25311;&#22120;&#30340;&#24418;&#24335;&#65292;&#26469;&#35268;&#33539;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;&#22312;&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#24050;&#32463;&#23398;&#20064;&#20934;&#30830;&#30340;&#21160;&#21147;&#23398;&#65292;SIM-FSVGD&#22312;&#26356;&#22810;&#25968;&#25454;&#21487;&#29992;&#26102;&#20063;&#33021;&#22815;&#25193;&#23637;&#21644;&#34920;&#29616;&#20986;&#33394;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#23398;&#20064;&#38544;&#24335;&#29289;&#29702;&#20808;&#39564;&#23548;&#33268;&#20934;&#30830;&#30340;&#24179;&#22343;&#27169;&#22411;&#20272;&#35745;&#20197;&#21450;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;SIM-FSVGD&#22312;&#39640;&#24615;&#33021;RC&#36187;&#36710;&#31995;&#32479;&#19978;&#32553;&#23567;&#27169;&#25311;&#21040;&#29616;&#23454;&#24046;&#36317;&#30340;&#26377;&#25928;&#24615;&#12290;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;RL&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#39640;&#24230;&#21160;&#24577;&#30340;&#20572;&#36710;&#36716;&#21521;&#21160;&#20316;&#65292;&#20351;&#29992;&#30340;&#25968;&#25454;&#37327;&#20165;&#20026;&#29616;&#26377;&#25216;&#26415;&#30340;&#19968;&#21322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16644v1 Announce Type: cross  Abstract: We present SIM-FSVGD for learning robot dynamics from data. As opposed to traditional methods, SIM-FSVGD leverages low-fidelity physical priors, e.g., in the form of simulators, to regularize the training of neural network models. While learning accurate dynamics already in the low data regime, SIM-FSVGD scales and excels also when more data is available. We empirically show that learning with implicit physical priors results in accurate mean model estimation as well as precise uncertainty quantification. We demonstrate the effectiveness of SIM-FSVGD in bridging the sim-to-real gap on a high-performance RC racecar system. Using model-based RL, we demonstrate a highly dynamic parking maneuver with drifting, using less than half the data compared to the state of the art.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;Agent Actor Critic&#27169;&#22411;&#65292;&#26088;&#22312;&#21033;&#29992;&#21333;Agent&#24378;&#21270;&#23398;&#20064;&#23398;&#20064;&#33258;&#20027;&#36710;&#36742;&#30340;&#21435;&#20013;&#24515;&#21270;&#21512;&#20316;&#39550;&#39542;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23545;&#21508;&#31181;&#20132;&#36890;&#22330;&#26223;&#30340;&#24191;&#27867;&#35780;&#20272;&#23637;&#29616;&#20102;&#25913;&#21892;&#36947;&#36335;&#31995;&#32479;&#20869;&#19981;&#21516;&#29942;&#39048;&#20301;&#32622;&#20132;&#36890;&#27969;&#37327;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.11914</link><description>&lt;p&gt;
&#21333;Agent Actor Critic&#29992;&#20110;&#21435;&#20013;&#24515;&#21270;&#21512;&#20316;&#39550;&#39542;
&lt;/p&gt;
&lt;p&gt;
Single-Agent Actor Critic for Decentralized Cooperative Driving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11914
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;Agent Actor Critic&#27169;&#22411;&#65292;&#26088;&#22312;&#21033;&#29992;&#21333;Agent&#24378;&#21270;&#23398;&#20064;&#23398;&#20064;&#33258;&#20027;&#36710;&#36742;&#30340;&#21435;&#20013;&#24515;&#21270;&#21512;&#20316;&#39550;&#39542;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23545;&#21508;&#31181;&#20132;&#36890;&#22330;&#26223;&#30340;&#24191;&#27867;&#35780;&#20272;&#23637;&#29616;&#20102;&#25913;&#21892;&#36947;&#36335;&#31995;&#32479;&#20869;&#19981;&#21516;&#29942;&#39048;&#20301;&#32622;&#20132;&#36890;&#27969;&#37327;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#20132;&#36890;&#31649;&#29702;&#32467;&#21512;&#33258;&#20027;&#36710;&#36742;&#65288;AVs&#65289;&#25215;&#35834;&#26410;&#26469;&#25317;&#26377;&#20943;&#23569;&#25317;&#22581;&#21644;&#22686;&#24378;&#20132;&#36890;&#27969;&#37327;&#12290;&#28982;&#32780;&#65292;&#20026;&#23454;&#38469;&#24212;&#29992;&#24320;&#21457;&#31639;&#27861;&#38656;&#35201;&#35299;&#20915;&#36830;&#32493;&#20132;&#36890;&#27969;&#37327;&#21644;&#37096;&#20998;&#21487;&#35266;&#23519;&#24615;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25512;&#21160;&#20027;&#21160;&#20132;&#36890;&#31649;&#29702;&#39046;&#22495;&#26397;&#30528;&#26356;&#22823;&#31243;&#24230;&#30340;&#21435;&#20013;&#24515;&#21270;&#21457;&#23637;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#19981;&#23545;&#31216;actor-critic&#27169;&#22411;&#65292;&#26088;&#22312;&#21033;&#29992;&#21333;Agent&#24378;&#21270;&#23398;&#20064;&#23398;&#20064;&#33258;&#20027;&#36710;&#36742;&#30340;&#21435;&#20013;&#24515;&#21270;&#21512;&#20316;&#39550;&#39542;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#20855;&#26377;&#25513;&#30721;&#30340;&#27880;&#24847;&#21147;&#31070;&#32463;&#32593;&#32476;&#26469;&#22788;&#29702;&#23454;&#38469;&#20132;&#36890;&#27969;&#37327;&#30340;&#21160;&#24577;&#29305;&#24615;&#21644;&#37096;&#20998;&#21487;&#35266;&#23519;&#24615;&#12290;&#36890;&#36807;&#22312;&#21508;&#31181;&#20132;&#36890;&#22330;&#26223;&#20013;&#38024;&#23545;&#22522;&#32447;&#25511;&#21046;&#22120;&#30340;&#24191;&#27867;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26174;&#31034;&#20986;&#22312;&#36947;&#36335;&#31995;&#32479;&#20869;&#19981;&#21516;&#29942;&#39048;&#20301;&#32622;&#25913;&#21892;&#20132;&#36890;&#27969;&#37327;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11914v1 Announce Type: new  Abstract: Active traffic management incorporating autonomous vehicles (AVs) promises a future with diminished congestion and enhanced traffic flow. However, developing algorithms for real-world application requires addressing the challenges posed by continuous traffic flow and partial observability. To bridge this gap and advance the field of active traffic management towards greater decentralization, we introduce a novel asymmetric actor-critic model aimed at learning decentralized cooperative driving policies for autonomous vehicles using single-agent reinforcement learning. Our approach employs attention neural networks with masking to handle the dynamic nature of real-world traffic flow and partial observability. Through extensive evaluations against baseline controllers across various traffic scenarios, our model shows great potential for improving traffic flow at diverse bottleneck locations within the road system. Additionally, we explore t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#31283;&#23450;&#31070;&#32463;&#21160;&#21147;&#31995;&#32479;&#65288;SNDS&#65289;&#30340;&#20223;&#30495;&#23398;&#20064;&#21046;&#24230;&#65292;&#21487;&#29983;&#25104;&#20855;&#26377;&#27491;&#24335;&#31283;&#23450;&#24615;&#20445;&#35777;&#30340;&#25919;&#31574;&#65292;&#24182;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;&#25919;&#31574;&#21644;&#20854;&#23545;&#24212;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20505;&#36873;&#32773;&#30830;&#20445;&#20840;&#23616;&#31283;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04118</link><description>&lt;p&gt;
&#20840;&#23616;&#31283;&#23450;&#30340;&#31070;&#32463;&#20223;&#30495;&#25919;&#31574;
&lt;/p&gt;
&lt;p&gt;
Globally Stable Neural Imitation Policies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04118
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31283;&#23450;&#31070;&#32463;&#21160;&#21147;&#31995;&#32479;&#65288;SNDS&#65289;&#30340;&#20223;&#30495;&#23398;&#20064;&#21046;&#24230;&#65292;&#21487;&#29983;&#25104;&#20855;&#26377;&#27491;&#24335;&#31283;&#23450;&#24615;&#20445;&#35777;&#30340;&#25919;&#31574;&#65292;&#24182;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;&#25919;&#31574;&#21644;&#20854;&#23545;&#24212;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20505;&#36873;&#32773;&#30830;&#20445;&#20840;&#23616;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20223;&#30495;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#32531;&#35299;&#20174;&#22836;&#24320;&#22987;&#22312;&#35299;&#20915;&#31354;&#38388;&#20013;&#23398;&#20064;&#25919;&#31574;&#30340;&#36164;&#28304;&#23494;&#38598;&#21644;&#32791;&#26102;&#30340;&#29305;&#24615;&#12290;&#23613;&#31649;&#32467;&#26524;&#25919;&#31574;&#21487;&#20197;&#21487;&#38752;&#22320;&#27169;&#20223;&#19987;&#23478;&#28436;&#31034;&#65292;&#20294;&#22312;&#29366;&#24577;&#31354;&#38388;&#30340;&#26410;&#25506;&#32034;&#21306;&#22495;&#20013;&#24120;&#24120;&#32570;&#20047;&#21487;&#39044;&#27979;&#24615;&#65292;&#36825;&#32473;&#22312;&#38754;&#23545;&#25200;&#21160;&#26102;&#24102;&#26469;&#20102;&#37325;&#22823;&#23433;&#20840;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31283;&#23450;&#31070;&#32463;&#21160;&#21147;&#31995;&#32479;&#65288;SNDS&#65289;&#65292;&#19968;&#31181;&#29983;&#25104;&#20855;&#26377;&#27491;&#24335;&#31283;&#23450;&#24615;&#20445;&#35777;&#30340;&#25919;&#31574;&#30340;&#20223;&#30495;&#23398;&#20064;&#21046;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#25919;&#31574;&#26550;&#26500;&#65292;&#20419;&#36827;&#22522;&#20110;&#26446;&#20122;&#26222;&#35834;&#22827;&#23450;&#29702;&#30340;&#31283;&#23450;&#24615;&#34920;&#31034;&#65292;&#24182;&#32852;&#21512;&#35757;&#32451;&#25919;&#31574;&#21450;&#20854;&#30456;&#24212;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20505;&#36873;&#32773;&#65292;&#20197;&#30830;&#20445;&#20840;&#23616;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#20223;&#30495;&#20013;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#25104;&#21151;&#23558;&#32463;&#36807;&#35757;&#32451;&#30340;&#25919;&#31574;&#37096;&#32626;&#21040;&#29616;&#23454;&#19990;&#30028;&#30340;&#26426;&#26800;&#25163;&#33218;&#19978;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;SNDS&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#20840;&#23616;&#31283;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04118v1 Announce Type: cross  Abstract: Imitation learning presents an effective approach to alleviate the resource-intensive and time-consuming nature of policy learning from scratch in the solution space. Even though the resulting policy can mimic expert demonstrations reliably, it often lacks predictability in unexplored regions of the state-space, giving rise to significant safety concerns in the face of perturbations. To address these challenges, we introduce the Stable Neural Dynamical System (SNDS), an imitation learning regime which produces a policy with formal stability guarantees. We deploy a neural policy architecture that facilitates the representation of stability based on Lyapunov theorem, and jointly train the policy and its corresponding Lyapunov candidate to ensure global stability. We validate our approach by conducting extensive experiments in simulation and successfully deploying the trained policies on a real-world manipulator arm. The experimental resu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;Di-Long&#65292;&#29992;&#20110;&#35299;&#20915;&#38271;&#26399;&#36712;&#36857;&#39044;&#27979;&#20013;&#36234;&#26469;&#36234;&#19981;&#30830;&#23450;&#21644;&#19981;&#21487;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#33976;&#39311;&#30701;&#26399;&#36712;&#36857;&#27169;&#22411;&#39044;&#27979;&#22120;&#26469;&#25351;&#23548;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#38271;&#26399;&#36712;&#36857;&#39044;&#27979;&#23398;&#29983;&#32593;&#32476;&#12290;&#23398;&#29983;&#32593;&#32476;&#35266;&#23519;&#30701;&#24207;&#21015;&#24182;&#39044;&#27979;&#38271;&#36712;&#36857;&#65292;&#25945;&#24072;&#32593;&#32476;&#35266;&#23519;&#26356;&#38271;&#24207;&#21015;&#24182;&#39044;&#27979;&#21097;&#20313;&#30701;&#30446;&#26631;&#36712;&#36857;&#12290;</title><link>http://arxiv.org/abs/2305.08553</link><description>&lt;p&gt;
&#23558;&#30693;&#35782;&#33976;&#39311;&#29992;&#20110;&#30701;&#26399;&#21040;&#38271;&#26399;&#36712;&#36857;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Distilling Knowledge for Short-to-Long Term Trajectory Prediction. (arXiv:2305.08553v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;Di-Long&#65292;&#29992;&#20110;&#35299;&#20915;&#38271;&#26399;&#36712;&#36857;&#39044;&#27979;&#20013;&#36234;&#26469;&#36234;&#19981;&#30830;&#23450;&#21644;&#19981;&#21487;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#33976;&#39311;&#30701;&#26399;&#36712;&#36857;&#27169;&#22411;&#39044;&#27979;&#22120;&#26469;&#25351;&#23548;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#38271;&#26399;&#36712;&#36857;&#39044;&#27979;&#23398;&#29983;&#32593;&#32476;&#12290;&#23398;&#29983;&#32593;&#32476;&#35266;&#23519;&#30701;&#24207;&#21015;&#24182;&#39044;&#27979;&#38271;&#36712;&#36857;&#65292;&#25945;&#24072;&#32593;&#32476;&#35266;&#23519;&#26356;&#38271;&#24207;&#21015;&#24182;&#39044;&#27979;&#21097;&#20313;&#30701;&#30446;&#26631;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#36712;&#36857;&#39044;&#27979;&#26159;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#26426;&#22120;&#20154;&#39046;&#22495;&#20013;&#19968;&#20010;&#37325;&#35201;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#20854;&#20013;&#19968;&#20010;&#22522;&#26412;&#22256;&#38590;&#22312;&#20110;&#38543;&#30528;&#26102;&#38388;&#33539;&#22260;&#30340;&#22686;&#38271;&#65292;&#36712;&#36857;&#30340;&#28436;&#21464;&#21464;&#24471;&#36234;&#26469;&#36234;&#19981;&#30830;&#23450;&#21644;&#19981;&#21487;&#39044;&#27979;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Di-Long&#65292;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#33976;&#39311;&#30701;&#26399;&#36712;&#36857;&#27169;&#22411;&#39044;&#27979;&#22120;&#26469;&#25351;&#23548;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#38271;&#26399;&#36712;&#36857;&#39044;&#27979;&#23398;&#29983;&#32593;&#32476;&#12290;&#32473;&#23450;&#19968;&#20010;&#21253;&#21547;&#23398;&#29983;&#32593;&#32476;&#20801;&#35768;&#30340;&#35266;&#27979;&#24207;&#21015;&#21644;&#34917;&#20805;&#30446;&#26631;&#24207;&#21015;&#30340;&#24635;&#24207;&#21015;&#38271;&#24230;&#65292;&#25105;&#20204;&#35753;&#23398;&#29983;&#21644;&#25945;&#24072;&#23545;&#21516;&#19968;&#20010;&#23436;&#25972;&#36712;&#36857;&#23450;&#20041;&#20004;&#20010;&#19981;&#21516;&#20294;&#30456;&#20851;&#30340;&#20219;&#21153;&#65306;&#23398;&#29983;&#35266;&#23519;&#19968;&#20010;&#30701;&#24207;&#21015;&#24182;&#39044;&#27979;&#19968;&#20010;&#38271;&#36712;&#36857;&#65292;&#32780;&#25945;&#24072;&#35266;&#23519;&#19968;&#20010;&#26356;&#38271;&#30340;&#24207;&#21015;&#24182;&#39044;&#27979;&#21097;&#19979;&#30340;&#30701;&#30446;&#26631;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Long-term trajectory forecasting is an important and challenging problem in the fields of computer vision, machine learning, and robotics. One fundamental difficulty stands in the evolution of the trajectory that becomes more and more uncertain and unpredictable as the time horizon grows, subsequently increasing the complexity of the problem. To overcome this issue, in this paper, we propose Di-Long, a new method that employs the distillation of a short-term trajectory model forecaster that guides a student network for long-term trajectory prediction during the training process. Given a total sequence length that comprehends the allowed observation for the student network and the complementary target sequence, we let the student and the teacher solve two different related tasks defined over the same full trajectory: the student observes a short sequence and predicts a long trajectory, whereas the teacher observes a longer sequence and predicts the remaining short target trajectory. The
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#38750;&#32447;&#24615;&#26426;&#22120;&#20154;&#31995;&#32479;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#31163;&#32447;&#21644;&#22312;&#32447;&#23398;&#20064;&#65292;&#33021;&#22815;&#22312;&#23454;&#26102;&#20013;&#20934;&#30830;&#25512;&#26029;&#27169;&#22411;&#21160;&#21147;&#23398;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#22120;&#12290;</title><link>http://arxiv.org/abs/2210.12583</link><description>&lt;p&gt;
&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#30340;&#31163;&#25955;&#26102;&#38388;&#21160;&#21147;&#23398;&#30340;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active Learning of Discrete-Time Dynamics for Uncertainty-Aware Model Predictive Control. (arXiv:2210.12583v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#38750;&#32447;&#24615;&#26426;&#22120;&#20154;&#31995;&#32479;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#31163;&#32447;&#21644;&#22312;&#32447;&#23398;&#20064;&#65292;&#33021;&#22815;&#22312;&#23454;&#26102;&#20013;&#20934;&#30830;&#25512;&#26029;&#27169;&#22411;&#21160;&#21147;&#23398;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#39537;&#21160;&#30340;&#25511;&#21046;&#38656;&#35201;&#23545;&#31995;&#32479;&#21160;&#21147;&#23398;&#36827;&#34892;&#20934;&#30830;&#24314;&#27169;&#65292;&#20197;&#20415;&#22312;&#22797;&#26434;&#21644;&#21160;&#24577;&#29615;&#22659;&#20013;&#31934;&#30830;&#19988;&#23433;&#20840;&#22320;&#25511;&#21046;&#26426;&#22120;&#20154;&#12290;&#27492;&#22806;&#65292;&#22312;&#25805;&#20316;&#26465;&#20214;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#24212;&#35813;&#19981;&#26029;&#35843;&#25972;&#20197;&#24357;&#34917;&#21160;&#21147;&#23398;&#21464;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#26469;&#20027;&#21160;&#24314;&#27169;&#38750;&#32447;&#24615;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#32467;&#21512;&#20102;&#31163;&#32447;&#23398;&#20064;&#20197;&#24448;&#32463;&#39564;&#21644;&#22312;&#32447;&#23398;&#20064;&#24403;&#21069;&#26426;&#22120;&#20154;&#19982;&#26410;&#30693;&#29615;&#22659;&#30340;&#20132;&#20114;&#12290;&#36825;&#20004;&#20010;&#22240;&#32032;&#20351;&#24471;&#23398;&#20064;&#36807;&#31243;&#39640;&#25928;&#19988;&#33258;&#36866;&#24212;&#65292;&#33021;&#22815;&#22312;&#23454;&#26102;&#20013;&#20934;&#30830;&#25512;&#26029;&#27169;&#22411;&#21160;&#21147;&#23398;&#65292;&#21363;&#20351;&#22312;&#22823;&#22823;&#19981;&#21516;&#20110;&#35757;&#32451;&#20998;&#24067;&#30340;&#25805;&#20316;&#33539;&#22260;&#20869;&#20063;&#21487;&#34892;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#23545;&#23398;&#20064;&#21040;&#30340;&#21160;&#21147;&#23398;&#30340;aleatoric&#65288;&#25968;&#25454;&#65289;&#19981;&#30830;&#23450;&#24615;&#21551;&#21457;&#24335;&#26465;&#20214;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#22120;&#12290;&#35813;&#25511;&#21046;&#22120;&#21487;&#20197;&#20027;&#21160;&#36873;&#25321;&#26368;&#20248;&#30340;&#25511;&#21046;&#21160;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based control requires an accurate model of the system dynamics for precisely and safely controlling the robot in complex and dynamic environments. Moreover, in the presence of variations in the operating conditions, the model should be continuously refined to compensate for dynamics changes. In this paper, we present a self-supervised learning approach that actively models the dynamics of nonlinear robotic systems. We combine offline learning from past experience and online learning from current robot interaction with the unknown environment. These two ingredients enable a highly sample-efficient and adaptive learning process, capable of accurately inferring model dynamics in real-time even in operating regimes that greatly differ from the training distribution. Moreover, we design an uncertainty-aware model predictive controller that is heuristically conditioned to the aleatoric (data) uncertainty of the learned dynamics. This controller actively chooses the optimal control act
&lt;/p&gt;</description></item></channel></rss>