<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#20351;&#29992;&#20851;&#38190;&#21160;&#20316;&#20196;&#29260;&#65288;KAT&#65289;&#26694;&#26550;&#65292;&#30740;&#31350;&#23637;&#31034;&#20102;&#25991;&#26412;&#39044;&#35757;&#32451;&#30340;&#21464;&#24418;&#22120;&#65288;GPT-4 Turbo&#65289;&#22312;&#26426;&#22120;&#20154;&#39046;&#22495;&#21487;&#23454;&#29616;&#35270;&#35273;&#27169;&#20223;&#23398;&#20064;&#65292;&#23558;&#35270;&#35273;&#35266;&#27979;&#26144;&#23556;&#20026;&#27169;&#25311;&#31034;&#33539;&#32773;&#34892;&#20026;&#30340;&#21160;&#20316;&#24207;&#21015;&#65292;&#34920;&#29616;&#20248;&#36234;&#20110;&#29616;&#26377;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19578</link><description>&lt;p&gt;
&#20851;&#38190;&#21160;&#20316;&#20196;&#29260;&#22312;&#26426;&#22120;&#20154;&#23398;&#20013;&#23454;&#29616;&#19978;&#19979;&#25991;&#27169;&#20223;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Keypoint Action Tokens Enable In-Context Imitation Learning in Robotics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19578
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20851;&#38190;&#21160;&#20316;&#20196;&#29260;&#65288;KAT&#65289;&#26694;&#26550;&#65292;&#30740;&#31350;&#23637;&#31034;&#20102;&#25991;&#26412;&#39044;&#35757;&#32451;&#30340;&#21464;&#24418;&#22120;&#65288;GPT-4 Turbo&#65289;&#22312;&#26426;&#22120;&#20154;&#39046;&#22495;&#21487;&#23454;&#29616;&#35270;&#35273;&#27169;&#20223;&#23398;&#20064;&#65292;&#23558;&#35270;&#35273;&#35266;&#27979;&#26144;&#23556;&#20026;&#27169;&#25311;&#31034;&#33539;&#32773;&#34892;&#20026;&#30340;&#21160;&#20316;&#24207;&#21015;&#65292;&#34920;&#29616;&#20248;&#36234;&#20110;&#29616;&#26377;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#25104;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#21464;&#24418;&#22120;&#65292;&#26080;&#38656;&#39069;&#22806;&#35757;&#32451;&#65292;&#23601;&#21487;&#20197;&#25191;&#34892;&#23569;&#26679;&#26412;&#19978;&#19979;&#25991;&#20869;&#35270;&#35273;&#27169;&#20223;&#23398;&#20064;&#65292;&#23558;&#35270;&#35273;&#35266;&#27979;&#26144;&#23556;&#20026;&#27169;&#25311;&#31034;&#33539;&#32773;&#34892;&#20026;&#30340;&#21160;&#20316;&#24207;&#21015;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#35270;&#35273;&#35266;&#27979;&#65288;&#36755;&#20837;&#65289;&#21644;&#21160;&#20316;&#36712;&#36857;&#65288;&#36755;&#20986;&#65289;&#36716;&#25442;&#20026;&#19968;&#31995;&#21015;&#20196;&#29260;&#65292;&#36825;&#20123;&#20196;&#29260;&#21487;&#20197;&#34987;&#25991;&#26412;&#39044;&#35757;&#32451;&#30340;&#21464;&#24418;&#22120;&#65288;GPT-4 Turbo&#65289;&#25509;&#25910;&#21644;&#29983;&#25104;&#65292;&#36890;&#36807;&#25105;&#20204;&#31216;&#20043;&#20026;&#20851;&#38190;&#21160;&#20316;&#20196;&#29260;&#65288;KAT&#65289;&#30340;&#26694;&#26550;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#23613;&#31649;&#20165;&#22312;&#35821;&#35328;&#19978;&#35757;&#32451;&#65292;&#25105;&#20204;&#23637;&#31034;&#36825;&#20123;&#21464;&#24418;&#22120;&#25797;&#38271;&#23558;&#26631;&#35760;&#21270;&#30340;&#35270;&#35273;&#20851;&#38190;&#28857;&#35266;&#23519;&#32763;&#35793;&#20026;&#34892;&#20026;&#36712;&#36857;&#65292;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#26085;&#24120;&#20219;&#21153;&#22871;&#20214;&#20013;&#65292;&#22312;&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#34920;&#29616;&#19982;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#27169;&#20223;&#23398;&#20064;&#65288;&#25193;&#25955;&#31574;&#30053;&#65289;&#12290;KAT&#19981;&#21516;&#20110;&#36890;&#24120;&#22312;&#35821;&#35328;&#39046;&#22495;&#25805;&#20316;&#65292;&#23427;&#21033;&#29992;&#22522;&#20110;&#25991;&#26412;&#30340;&#21464;&#24418;&#22120;&#22312;&#35270;&#35273;&#21644;&#21160;&#20316;&#39046;&#22495;&#20013;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19578v1 Announce Type: cross  Abstract: We show that off-the-shelf text-based Transformers, with no additional training, can perform few-shot in-context visual imitation learning, mapping visual observations to action sequences that emulate the demonstrator's behaviour. We achieve this by transforming visual observations (inputs) and trajectories of actions (outputs) into sequences of tokens that a text-pretrained Transformer (GPT-4 Turbo) can ingest and generate, via a framework we call Keypoint Action Tokens (KAT). Despite being trained only on language, we show that these Transformers excel at translating tokenised visual keypoint observations into action trajectories, performing on par or better than state-of-the-art imitation learning (diffusion policies) in the low-data regime on a suite of real-world, everyday tasks. Rather than operating in the language domain as is typical, KAT leverages text-based Transformers to operate in the vision and action domains to learn ge
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20559;&#24207;&#26102;&#24207;&#30446;&#26631;&#65292;&#23558;&#37096;&#20998;&#26377;&#24207;&#20559;&#22909;&#26144;&#23556;&#21040;MDP&#31574;&#30053;&#20559;&#22909;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#24207;&#29702;&#35770;&#23454;&#29616;&#26368;&#20248;&#31574;&#30053;&#30340;&#21512;&#25104;&#12290;</title><link>https://arxiv.org/abs/2403.18212</link><description>&lt;p&gt;
&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#22522;&#20110;&#20559;&#24207;&#26102;&#24207;&#30446;&#26631;&#30340;&#39318;&#36873;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Preference-Based Planning in Stochastic Environments: From Partially-Ordered Temporal Goals to Most Preferred Policies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18212
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20559;&#24207;&#26102;&#24207;&#30446;&#26631;&#65292;&#23558;&#37096;&#20998;&#26377;&#24207;&#20559;&#22909;&#26144;&#23556;&#21040;MDP&#31574;&#30053;&#20559;&#22909;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#24207;&#29702;&#35770;&#23454;&#29616;&#26368;&#20248;&#31574;&#30053;&#30340;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#20559;&#22909;&#24182;&#38750;&#24635;&#26159;&#36890;&#36807;&#23436;&#20840;&#30340;&#32447;&#24615;&#39034;&#24207;&#26469;&#34920;&#31034;&#65306;&#20351;&#29992;&#37096;&#20998;&#26377;&#24207;&#20559;&#22909;&#26469;&#34920;&#36798;&#19981;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#26159;&#33258;&#28982;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#38543;&#26426;&#31995;&#32479;&#20013;&#20570;&#20915;&#31574;&#21644;&#27010;&#29575;&#35268;&#21010;&#65292;&#36825;&#20123;&#31995;&#32479;&#34987;&#24314;&#27169;&#20026;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#65292;&#32473;&#23450;&#19968;&#32452;&#26377;&#24207;&#20559;&#22909;&#30340;&#26102;&#38388;&#24310;&#20280;&#30446;&#26631;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#27599;&#20010;&#26102;&#38388;&#24310;&#20280;&#30446;&#26631;&#37117;&#26159;&#20351;&#29992;&#32447;&#24615;&#26102;&#24207;&#36923;&#36753;&#26377;&#38480;&#36712;&#36857;&#65288;LTL$_f$&#65289;&#20013;&#30340;&#20844;&#24335;&#26469;&#34920;&#31034;&#30340;&#12290;&#20026;&#20102;&#26681;&#25454;&#37096;&#20998;&#26377;&#24207;&#20559;&#22909;&#36827;&#34892;&#35268;&#21010;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24207;&#29702;&#35770;&#26469;&#23558;&#23545;&#26102;&#38388;&#30446;&#26631;&#30340;&#20559;&#22909;&#26144;&#23556;&#21040;&#23545;MDP&#31574;&#30053;&#30340;&#20559;&#22909;&#12290;&#22240;&#27492;&#65292;&#22312;&#38543;&#26426;&#39034;&#24207;&#19979;&#30340;&#19968;&#20010;&#26368;&#20248;&#36873;&#31574;&#30053;&#23558;&#23548;&#33268;MDP&#20013;&#26377;&#38480;&#36335;&#24452;&#19978;&#30340;&#19968;&#20010;&#38543;&#26426;&#38750;&#25903;&#37197;&#27010;&#29575;&#20998;&#24067;&#12290;&#20026;&#20102;&#21512;&#25104;&#19968;&#20010;&#26368;&#20248;&#36873;&#31574;&#30053;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#20851;&#38190;&#27493;&#39588;&#12290;&#22312;&#31532;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31243;&#24207;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18212v1 Announce Type: cross  Abstract: Human preferences are not always represented via complete linear orders: It is natural to employ partially-ordered preferences for expressing incomparable outcomes. In this work, we consider decision-making and probabilistic planning in stochastic systems modeled as Markov decision processes (MDPs), given a partially ordered preference over a set of temporally extended goals. Specifically, each temporally extended goal is expressed using a formula in Linear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially ordered preference, we introduce order theory to map a preference over temporal goals to a preference over policies for the MDP. Accordingly, a most preferred policy under a stochastic ordering induces a stochastic nondominated probability distribution over the finite paths in the MDP. To synthesize a most preferred policy, our technical approach includes two key steps. In the first step, we develop a procedure to
&lt;/p&gt;</description></item></channel></rss>