<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#38656;&#35201;&#22312;&#20154;&#24037;&#31995;&#32479;&#20013;&#24179;&#34913;&#35752;&#35770;&#24847;&#35782;&#30340;&#21487;&#33021;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#24847;&#35782;&#30340;&#32500;&#24230;&#21644;&#29305;&#24449;&#26469;&#36827;&#34892;&#35752;&#35770;&#30340;&#24517;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.20177</link><description>&lt;p&gt;
&#20154;&#24037;&#24847;&#35782;&#12290;&#19968;&#20123;&#36923;&#36753;&#21644;&#27010;&#24565;&#21021;&#27493;
&lt;/p&gt;
&lt;p&gt;
Artificial consciousness. Some logical and conceptual preliminaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20177
&lt;/p&gt;
&lt;p&gt;
&#38656;&#35201;&#22312;&#20154;&#24037;&#31995;&#32479;&#20013;&#24179;&#34913;&#35752;&#35770;&#24847;&#35782;&#30340;&#21487;&#33021;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#24847;&#35782;&#30340;&#32500;&#24230;&#21644;&#29305;&#24449;&#26469;&#36827;&#34892;&#35752;&#35770;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20177v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#20154;&#24037;&#24847;&#35782;&#22312;&#29702;&#35770;&#19978;&#26159;&#21542;&#21487;&#33021;&#65311;&#26159;&#21542;&#21512;&#20046;&#24773;&#29702;&#65311;&#22914;&#26524;&#26159;&#65292;&#37027;&#20040;&#25216;&#26415;&#19978;&#21487;&#34892;&#21527;&#65311;&#35201;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26377;&#24517;&#35201;&#22880;&#23450;&#19968;&#20123;&#22522;&#30784;&#65292;&#38416;&#26126;&#20154;&#24037;&#24847;&#35782;&#20135;&#29983;&#30340;&#36923;&#36753;&#21644;&#32463;&#39564;&#26465;&#20214;&#20197;&#21450;&#28041;&#21450;&#30340;&#30456;&#20851;&#26415;&#35821;&#30340;&#21547;&#20041;&#12290;&#24847;&#35782;&#26159;&#19968;&#20010;&#22810;&#20041;&#35789;&#65306;&#26469;&#33258;&#19981;&#21516;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#65292;&#21253;&#25324;&#31070;&#32463;&#31185;&#23398;&#12289;&#20154;&#24037;&#26234;&#33021;&#12289;&#26426;&#22120;&#20154;&#25216;&#26415;&#21644;&#21746;&#23398;&#31561;&#65292;&#26377;&#26102;&#20250;&#20351;&#29992;&#19981;&#21516;&#26415;&#35821;&#26469;&#25351;&#31216;&#30456;&#21516;&#29616;&#35937;&#65292;&#25110;&#32773;&#20351;&#29992;&#30456;&#21516;&#26415;&#35821;&#26469;&#25351;&#31216;&#19981;&#21516;&#29616;&#35937;&#12290;&#20107;&#23454;&#19978;&#65292;&#22914;&#26524;&#25105;&#20204;&#24819;&#25506;&#35752;&#20154;&#24037;&#24847;&#35782;&#65292;&#23601;&#38656;&#35201;&#24688;&#24403;&#30028;&#23450;&#20851;&#38190;&#27010;&#24565;&#12290;&#22312;&#27492;&#65292;&#32463;&#36807;&#19968;&#20123;&#36923;&#36753;&#21644;&#27010;&#24565;&#21021;&#27493;&#24037;&#20316;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#26377;&#24517;&#35201;&#20351;&#29992;&#24847;&#35782;&#30340;&#32500;&#24230;&#21644;&#29305;&#24449;&#36827;&#34892;&#24179;&#34913;&#35752;&#35770;&#65292;&#25506;&#35752;&#23427;&#20204;&#22312;&#20154;&#24037;&#31995;&#32479;&#20013;&#30340;&#21487;&#33021;&#23454;&#20363;&#21270;&#25110;&#23454;&#29616;&#12290;&#25105;&#20204;&#22312;&#36825;&#39033;&#24037;&#20316;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20177v1 Announce Type: new  Abstract: Is artificial consciousness theoretically possible? Is it plausible? If so, is it technically feasible? To make progress on these questions, it is necessary to lay some groundwork clarifying the logical and empirical conditions for artificial consciousness to arise and the meaning of relevant terms involved. Consciousness is a polysemic word: researchers from different fields, including neuroscience, Artificial Intelligence, robotics, and philosophy, among others, sometimes use different terms in order to refer to the same phenomena or the same terms to refer to different phenomena. In fact, if we want to pursue artificial consciousness, a proper definition of the key concepts is required. Here, after some logical and conceptual preliminaries, we argue for the necessity of using dimensions and profiles of consciousness for a balanced discussion about their possible instantiation or realisation in artificial systems. Our primary goal in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#24378;&#21270;&#23398;&#20064;&#19982;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#38598;&#25104;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#20572;&#36710;&#20219;&#21153;&#20013;&#30340;&#22312;&#32447;&#36335;&#24452;&#35268;&#21010;&#65292;&#26088;&#22312;&#21152;&#36895;&#36335;&#24452;&#35268;&#21010;&#36807;&#31243;&#65292;&#25552;&#39640;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.17234</link><description>&lt;p&gt;
&#22312;&#33258;&#21160;&#20572;&#36710;&#20013;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#22312;MCTS&#20013;&#21152;&#36895;&#36335;&#24452;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#24378;&#21270;&#23398;&#20064;&#19982;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#38598;&#25104;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#20572;&#36710;&#20219;&#21153;&#20013;&#30340;&#22312;&#32447;&#36335;&#24452;&#35268;&#21010;&#65292;&#26088;&#22312;&#21152;&#36895;&#36335;&#24452;&#35268;&#21010;&#36807;&#31243;&#65292;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#35813;&#26041;&#27861;&#23558;&#24378;&#21270;&#23398;&#20064;&#25972;&#21512;&#21040;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#20013;&#65292;&#20197;&#25552;&#21319;&#22312;&#20840;&#21487;&#35266;&#27979;&#29615;&#22659;&#19979;&#36827;&#34892;&#33258;&#21160;&#20572;&#36710;&#20219;&#21153;&#30340;&#22312;&#32447;&#36335;&#24452;&#35268;&#21010;&#12290;&#22312;&#39640;&#32500;&#31354;&#38388;&#19979;&#22522;&#20110;&#37319;&#26679;&#30340;&#35268;&#21010;&#26041;&#27861;&#21487;&#33021;&#20855;&#26377;&#35745;&#31639;&#24320;&#38144;&#22823;&#12289;&#32791;&#26102;&#38271;&#30340;&#29305;&#28857;&#12290;&#29366;&#24577;&#35780;&#20272;&#26041;&#27861;&#36890;&#36807;&#23558;&#20808;&#39564;&#30693;&#35782;&#24212;&#29992;&#20110;&#25628;&#32034;&#27493;&#39588;&#20013;&#65292;&#20351;&#23454;&#26102;&#31995;&#32479;&#20013;&#30340;&#36807;&#31243;&#26356;&#24555;&#36895;&#12290;&#37492;&#20110;&#33258;&#21160;&#20572;&#36710;&#20219;&#21153;&#36890;&#24120;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#25191;&#34892;&#65292;&#20256;&#32479;&#20998;&#26512;&#26041;&#24335;&#38590;&#20197;&#26500;&#24314;&#22362;&#23454;&#20294;&#36731;&#37327;&#32423;&#30340;&#21551;&#21457;&#24335;&#25351;&#23548;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#36335;&#24452;&#35268;&#21010;&#26694;&#26550;&#19979;&#20855;&#26377;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#30340;&#24378;&#21270;&#23398;&#20064;&#27969;&#27700;&#32447;&#12290;&#36890;&#36807;&#36845;&#20195;&#22320;&#23398;&#20064;&#29366;&#24577;&#30340;&#20215;&#20540;&#20197;&#21450;&#26368;&#20339;&#21160;&#20316;&#65292;&#22312;&#21069;&#19968;&#20010;&#21608;&#26399;&#32467;&#26524;&#30340;&#26679;&#26412;&#20013;&#36873;&#25321;&#26368;&#20339;&#21160;&#20316;&#65292;&#25105;&#20204;&#33021;&#22815;&#24314;&#27169;&#19968;&#20010;&#20540;&#20272;&#35745;&#22120;&#20197;&#21450;&#19968;&#20010;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17234v1 Announce Type: new  Abstract: In this paper, we address a method that integrates reinforcement learning into the Monte Carlo tree search to boost online path planning under fully observable environments for automated parking tasks. Sampling-based planning methods under high-dimensional space can be computationally expensive and time-consuming. State evaluation methods are useful by leveraging the prior knowledge into the search steps, making the process faster in a real-time system. Given the fact that automated parking tasks are often executed under complex environments, a solid but lightweight heuristic guidance is challenging to compose in a traditional analytical way. To overcome this limitation, we propose a reinforcement learning pipeline with a Monte Carlo tree search under the path planning framework. By iteratively learning the value of a state and the best action among samples from its previous cycle's outcomes, we are able to model a value estimator and a 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;EC-IoU&#24230;&#37327;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#23450;&#21521;&#23433;&#20840;&#24615;&#29289;&#20307;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#20013;&#25552;&#39640;&#29289;&#20307;&#26816;&#27979;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;KITTI&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;IoU&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.15474</link><description>&lt;p&gt;
EC-IoU: &#36890;&#36807;&#33258;&#25105;&#20013;&#24515;&#20132;&#24182;&#32852;&#35843;&#25972;&#29289;&#20307;&#26816;&#27979;&#22120;&#30340;&#23433;&#20840;&#24615;
&lt;/p&gt;
&lt;p&gt;
EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15474
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;EC-IoU&#24230;&#37327;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#23450;&#21521;&#23433;&#20840;&#24615;&#29289;&#20307;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#20013;&#25552;&#39640;&#29289;&#20307;&#26816;&#27979;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;KITTI&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;IoU&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#25105;&#20013;&#24515;&#20132;&#24182;&#32852;&#65288;EC-IoU&#65289;&#24230;&#37327;&#26469;&#23450;&#21521;&#23433;&#20840;&#24615;&#29289;&#20307;&#26816;&#27979;&#65292;&#35299;&#20915;&#20102;&#22312;&#33258;&#21160;&#39550;&#39542;&#31561;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#24212;&#29992;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#24863;&#30693;&#27169;&#22411;&#26102;&#38754;&#20020;&#30340;&#23454;&#38469;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#26426;&#21046;&#26469;&#20248;&#21270;&#24191;&#27867;&#20351;&#29992;&#30340;IoU&#24230;&#37327;&#65292;&#20351;&#20854;&#33021;&#22815;&#26681;&#25454;&#33258;&#25105;&#20195;&#29702;&#20154;&#30340;&#35270;&#35282;&#35206;&#30422;&#26356;&#36817;&#30340;&#22320;&#38754;&#30495;&#23454;&#23545;&#35937;&#28857;&#30340;&#39044;&#27979;&#20998;&#37197;&#26356;&#39640;&#30340;&#20998;&#25968;&#12290;&#25152;&#25552;&#20986;&#30340;EC-IoU&#24230;&#37327;&#21487;&#20197;&#29992;&#20110;&#20856;&#22411;&#30340;&#35780;&#20272;&#36807;&#31243;&#65292;&#36873;&#25321;&#26377;&#26356;&#39640;&#23433;&#20840;&#24615;&#34920;&#29616;&#30340;&#29289;&#20307;&#26816;&#27979;&#22120;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#12290;&#23427;&#36824;&#21487;&#20197;&#38598;&#25104;&#21040;&#24120;&#35265;&#25439;&#22833;&#20989;&#25968;&#20013;&#36827;&#34892;&#27169;&#22411;&#24494;&#35843;&#12290;&#23613;&#31649;&#38754;&#21521;&#23433;&#20840;&#24615;&#65292;&#20294;&#25105;&#20204;&#22312;KITTI&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#20351;&#29992;EC-IoU&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#22343;&#20540;&#24179;&#22343;&#31934;&#24230;&#26041;&#38754;&#30340;&#24615;&#33021;&#21487;&#33021;&#20250;&#20248;&#20110;&#20351;&#29992;IoU&#35757;&#32451;&#30340;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15474v1 Announce Type: cross  Abstract: This paper presents safety-oriented object detection via a novel Ego-Centric Intersection-over-Union (EC-IoU) measure, addressing practical concerns when applying state-of-the-art learning-based perception models in safety-critical domains such as autonomous driving. Concretely, we propose a weighting mechanism to refine the widely used IoU measure, allowing it to assign a higher score to a prediction that covers closer points of a ground-truth object from the ego agent's perspective. The proposed EC-IoU measure can be used in typical evaluation processes to select object detectors with higher safety-related performance for downstream tasks. It can also be integrated into common loss functions for model fine-tuning. While geared towards safety, our experiment with the KITTI dataset demonstrates the performance of a model trained on EC-IoU can be better than that of a variant trained on IoU in terms of mean Average Precision as well.
&lt;/p&gt;</description></item></channel></rss>