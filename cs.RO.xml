<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#36890;&#36807;&#23450;&#20041;"&#20219;&#21153;"&#30340;&#26041;&#24335;&#21644;&#24341;&#20837;&#20855;&#26377;&#29289;&#29702;&#21644;&#22240;&#26524;&#20851;&#31995;&#29702;&#35299;&#30340;&#30417;&#30563;&#27169;&#22359;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#22266;&#26377;&#29289;&#29702;&#30693;&#35782;&#30340;&#31283;&#24577;&#36816;&#21160;&#35268;&#21010;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#26426;&#22120;&#20154;&#19978;&#23454;&#29616;&#22797;&#26434;&#35745;&#21010;&#12290;</title><link>https://arxiv.org/abs/2402.15384</link><description>&lt;p&gt;
&#20855;&#26377;&#22266;&#26377;&#29289;&#29702;&#30693;&#35782;&#30340;&#31283;&#24577;&#36816;&#21160;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Homeostatic motion planning with innate physics knowledge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15384
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23450;&#20041;"&#20219;&#21153;"&#30340;&#26041;&#24335;&#21644;&#24341;&#20837;&#20855;&#26377;&#29289;&#29702;&#21644;&#22240;&#26524;&#20851;&#31995;&#29702;&#35299;&#30340;&#30417;&#30563;&#27169;&#22359;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#22266;&#26377;&#29289;&#29702;&#30693;&#35782;&#30340;&#31283;&#24577;&#36816;&#21160;&#35268;&#21010;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#26426;&#22120;&#20154;&#19978;&#23454;&#29616;&#22797;&#26434;&#35745;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#20307;&#20197;&#38381;&#29615;&#26041;&#24335;&#19982;&#21608;&#22260;&#29615;&#22659;&#36827;&#34892;&#20114;&#21160;&#65292;&#20854;&#20013;&#24863;&#23448;&#36755;&#20837;&#20915;&#23450;&#34892;&#20026;&#30340;&#21551;&#21160;&#21644;&#32456;&#27490;&#12290;&#21363;&#20351;&#26159;&#31616;&#21333;&#30340;&#21160;&#29289;&#20063;&#33021;&#21046;&#23450;&#24182;&#25191;&#34892;&#22797;&#26434;&#35745;&#21010;&#65292;&#20294;&#32431;&#38381;&#29615;&#36755;&#20837;&#25511;&#21046;&#30340;&#26426;&#22120;&#20154;&#23578;&#26410;&#22797;&#21046;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#23450;&#20041;&#19968;&#32452;&#31163;&#25955;&#20020;&#26102;&#38381;&#29615;&#25511;&#21046;&#22120;&#65292;&#31216;&#20026;&#8220;&#20219;&#21153;&#8221;&#65292;&#27599;&#20010;&#20219;&#21153;&#20195;&#34920;&#19968;&#20010;&#38381;&#29615;&#34892;&#20026;&#65292;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24341;&#20837;&#20102;&#19968;&#20010;&#20855;&#26377;&#22266;&#26377;&#29289;&#29702;&#21644;&#22240;&#26524;&#20851;&#31995;&#29702;&#35299;&#30340;&#30417;&#30563;&#27169;&#22359;&#65292;&#36890;&#36807;&#35813;&#27169;&#22359;&#21487;&#20197;&#27169;&#25311;&#38543;&#26102;&#38388;&#25191;&#34892;&#20219;&#21153;&#24207;&#21015;&#24182;&#23558;&#32467;&#26524;&#23384;&#20648;&#22312;&#29615;&#22659;&#27169;&#22411;&#20013;&#12290;&#22522;&#20110;&#36825;&#20010;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#38142;&#25509;&#20020;&#26102;&#38381;&#29615;&#25511;&#21046;&#22120;&#36827;&#34892;&#21046;&#23450;&#35745;&#21010;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#24050;&#22312;&#23454;&#38469;&#26426;&#22120;&#20154;&#20013;&#23454;&#26045;&#65292;&#24182;&#22312;&#20004;&#31181;&#22330;&#26223;&#19979;&#20316;&#20026;&#27010;&#24565;&#39564;&#35777;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15384v1 Announce Type: cross  Abstract: Living organisms interact with their surroundings in a closed-loop fashion, where sensory inputs dictate the initiation and termination of behaviours. Even simple animals are able to develop and execute complex plans, which has not yet been replicated in robotics using pure closed-loop input control. We propose a solution to this problem by defining a set of discrete and temporary closed-loop controllers, called "tasks", each representing a closed-loop behaviour. We further introduce a supervisory module which has an innate understanding of physics and causality, through which it can simulate the execution of task sequences over time and store the results in a model of the environment. On the basis of this model, plans can be made by chaining temporary closed-loop controllers. The proposed framework was implemented for a real robot and tested in two scenarios as proof of concept.
&lt;/p&gt;</description></item><item><title>BackpropTools&#26159;&#19968;&#27454;&#24555;&#36895;&#12289;&#21487;&#31227;&#26893;&#30340;&#36830;&#32493;&#25511;&#21046;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24211;&#65292;&#23427;&#36890;&#36807;&#27169;&#26495;&#20803;&#32534;&#31243;&#25552;&#20379;&#32039;&#23494;&#38598;&#25104;&#30340;&#21487;&#32452;&#21512;&#32452;&#20214;&#65292;&#24182;&#22312;&#24322;&#26500;&#24179;&#21488;&#38598;&#21512;&#19978;&#26080;&#32541;&#20351;&#29992;&#65292;&#21516;&#26102;&#22312;&#36830;&#32493;&#25511;&#21046;&#38382;&#39064;&#30340;&#28145;&#24230;RL&#20195;&#29702;&#39640;&#25928;&#21487;&#25193;&#23637;&#35757;&#32451;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;&#30001;&#20110;&#20854;&#21487;&#31227;&#26893;&#24615;&#21644;&#23454;&#26102;&#20445;&#35777;&#65292;&#23427;&#25104;&#20026;&#20102;&#22312;&#23884;&#20837;&#24335;&#35774;&#22791;&#19978;&#37096;&#32626;&#23398;&#26469;&#30340;&#31574;&#30053;&#30340;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2306.03530</link><description>&lt;p&gt;
BackpropTools: &#19968;&#27454;&#24555;&#36895;&#12289;&#21487;&#31227;&#26893;&#30340;&#36830;&#32493;&#25511;&#21046;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24211;
&lt;/p&gt;
&lt;p&gt;
BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control. (arXiv:2306.03530v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03530
&lt;/p&gt;
&lt;p&gt;
BackpropTools&#26159;&#19968;&#27454;&#24555;&#36895;&#12289;&#21487;&#31227;&#26893;&#30340;&#36830;&#32493;&#25511;&#21046;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24211;&#65292;&#23427;&#36890;&#36807;&#27169;&#26495;&#20803;&#32534;&#31243;&#25552;&#20379;&#32039;&#23494;&#38598;&#25104;&#30340;&#21487;&#32452;&#21512;&#32452;&#20214;&#65292;&#24182;&#22312;&#24322;&#26500;&#24179;&#21488;&#38598;&#21512;&#19978;&#26080;&#32541;&#20351;&#29992;&#65292;&#21516;&#26102;&#22312;&#36830;&#32493;&#25511;&#21046;&#38382;&#39064;&#30340;&#28145;&#24230;RL&#20195;&#29702;&#39640;&#25928;&#21487;&#25193;&#23637;&#35757;&#32451;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;&#30001;&#20110;&#20854;&#21487;&#31227;&#26893;&#24615;&#21644;&#23454;&#26102;&#20445;&#35777;&#65292;&#23427;&#25104;&#20026;&#20102;&#22312;&#23884;&#20837;&#24335;&#35774;&#22791;&#19978;&#37096;&#32626;&#23398;&#26469;&#30340;&#31574;&#30053;&#30340;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#20135;&#29983;&#20986;&#20855;&#26377;&#33021;&#21147;&#30340;&#20195;&#29702;&#21644;&#25511;&#21046;&#31574;&#30053;&#65292;&#20294;&#24120;&#24120;&#21463;&#21040;&#35757;&#32451;&#26102;&#38388;&#36807;&#38271;&#30340;&#22256;&#25200;&#12290;&#27492;&#22806;&#65292;&#22312;&#36830;&#32493;&#25511;&#21046;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#28145;&#24230;&#23398;&#20064;&#24211;&#30340;&#23454;&#26102;&#24615;&#21644;&#21487;&#31227;&#26893;&#24615;&#30340;&#32570;&#20047;&#38480;&#21046;&#20102;&#23398;&#20064;&#31574;&#30053;&#22312;&#23454;&#38469;&#23884;&#20837;&#24335;&#35774;&#22791;&#19978;&#30340;&#24212;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;BackpropTools&#65292;&#19968;&#31181;&#20381;&#36182;&#24615;-free&#12289;header-only&#12289;pure C++&#30340;&#28145;&#24230;&#30417;&#30563;&#21644;&#24378;&#21270;&#23398;&#20064;&#24211;&#12290;&#21033;&#29992;&#26368;&#36817;C++&#26631;&#20934;&#30340;&#27169;&#26495;&#20803;&#32534;&#31243;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21487;&#20197;&#30001;&#32534;&#35793;&#22120;&#32039;&#23494;&#38598;&#25104;&#30340;&#21487;&#32452;&#21512;&#32452;&#20214;&#12290;&#20854;&#26032;&#39062;&#30340;&#26550;&#26500;&#20801;&#35768;BackpropTools&#22312;&#24322;&#26500;&#24179;&#21488;&#38598;&#21512;&#19978;&#26080;&#32541;&#20351;&#29992;&#65292;&#20174;HPC&#38598;&#32676;&#12289;&#24037;&#20316;&#31449;&#21644;&#31508;&#35760;&#26412;&#30005;&#33041;&#21040;&#26234;&#33021;&#25163;&#26426;&#12289;&#26234;&#33021;&#25163;&#34920;&#21644;&#24494;&#25511;&#21046;&#22120;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#30001;&#20110;RL&#31639;&#27861;&#19982;&#27169;&#25311;&#29615;&#22659;&#30340;&#32039;&#23494;&#38598;&#25104;&#65292;BackpropTools&#22312;&#36830;&#32493;&#25511;&#21046;&#38382;&#39064;&#30340;&#28145;&#24230;RL&#20195;&#29702;&#30340;&#39640;&#25928;&#21487;&#25193;&#23637;&#35757;&#32451;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#23427;&#30340;&#21487;&#31227;&#26893;&#24615;&#21644;&#23454;&#26102;&#20445;&#35777;&#20351;&#20854;&#25104;&#20026;&#22312;&#23884;&#20837;&#24335;&#35774;&#22791;&#19978;&#37096;&#32626;&#23398;&#26469;&#30340;&#31574;&#30053;&#30340;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Reinforcement Learning (RL) has been demonstrated to yield capable agents and control policies in several domains but is commonly plagued by prohibitively long training times. Additionally, in the case of continuous control problems, the applicability of learned policies on real-world embedded devices is limited due to the lack of real-time guarantees and portability of existing deep learning libraries. To address these challenges, we present BackpropTools, a dependency-free, header-only, pure C++ library for deep supervised and reinforcement learning. Leveraging the template meta-programming capabilities of recent C++ standards, we provide composable components that can be tightly integrated by the compiler. Its novel architecture allows BackpropTools to be used seamlessly on a heterogeneous set of platforms, from HPC clusters over workstations and laptops to smartphones, smartwatches, and microcontrollers. Specifically, due to the tight integration of the RL algorithms with simu
&lt;/p&gt;</description></item></channel></rss>